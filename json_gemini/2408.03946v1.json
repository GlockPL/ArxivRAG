{"title": "PROMPTING FOR PRODUCTS: INVESTIGATING DESIGN SPACE EXPLORATION STRATEGIES FOR\nTEXT-TO-IMAGE GENERATIVE MODELS", "authors": ["Leah Chong", "I-Ping Lo", "Jude Rayan", "Steven Dow", "Faez Ahmed", "Ioanna Lykourentzou"], "abstract": "Text-to-image models are enabling efficient design space ex-\nploration, rapidly generating images from text prompts. However,\nmany generative AI tools are imperfect for product design appli-\ncations as they are not built for the goals and requirements of\nproduct design. The unclear link between text input and image\noutput further complicates their application. This work empir-\nically investigates design space exploration strategies that can\nsuccessfully yield product images that are feasible, novel, and\naesthetic - three common goals in product design. Specifically,\nusers' actions within the global and local editing modes, in-\ncluding their time spent, prompt length, mono vs. multi-criteria\nprompts, and goal orientation of prompts, are analyzed. Key\nfindings reveal the pivotal role of mono vs. multi-criteria and\ngoal orientation of prompts in achieving specific design goals\nover time and prompt length. The study recommends prioritizing\nthe use of multi-criteria prompts for feasibility and novelty during\nglobal editing, while favoring mono-criteria prompts for aesthet-\nics during local editing. Overall, this paper underscores the\nnuanced relationship between the AI-driven text-to-image mod-\nels and their effectiveness in product design, urging designers\nto carefully structure prompts during different editing modes to\nbetter meet the unique demands of product design.\nKeywords: text-to-image generative AI, product design,\nprompt engineering, design space exploration", "sections": [{"title": "1. INTRODUCTION", "content": "Rapid advancements in generative artificial intelligence\n(GenAI) have enabled the generation of novel and innovative\ncontent, such as texts and images, from simple text prompts. In\nproduct design applications, text-to-image models can produce\nimages of designs from text prompts, enabling the exploration of\nmultiple designs in shorter spans of time compared to the tradi-\ntional method of manually rendering new designs. This function-\nality holds great potential for streamlining the iterative creative\nprocess in product design, particularly by facilitating design space\nexploration (DSE).\nWhile text-to-image GenAI can enable the rapid exploration\nof diverse product design concepts, most existing tools are not\nengineered to account for the multifaceted goals and requirements\nof product design, such as feasibility and aesthetics. For example,\ncurrent GenAI tools can generate a large number of designs,\nmany of which are infeasible [1-3]. Chong and Yang presented\na list of 16 different design objectives that are prevalent in design\nresearch and practice [4]. This long \u2013 and yet non-exhaustive\nlist, underscores the complexity of parameters essential for\ndesigning a successful product. Unfortunately, current GenAI\npossesses Al's inherent vagueness in the relationship between\nthe input (i.e., communicated goal) and the generated output\n(i.e., images of designs), a property that renders GenAI tools\ninsufficient for generating reliable product designs. For example,\nwhen the text prompt is \"design of a mug that is ergonomic,\nsleek, and modern\", it is unclear how the GenAI understands and\nmaps the meaning of \u201cergonomic\u201d, \u201csleek\u201d, and \u201cmodern\u201d onto\nthe generated images. While one way to address this problem\nis to develop new models specifically trained for product design,\ncurrent models possess a creative advantage, given the vast range\nof available image datasets compared to design-specific datasets\nlike computer-aided design files. Therefore, this work aims to\nunderstand how off-the-shelf, promising yet imperfect text-to-\nimage GenAI tools can be used to explore and refine product\ndesigns that are novel, aesthetically pleasing, and feasible.\nThis work conducts a controlled human subject experiment\nin which participants are asked to design bikes that are feasible,\nnovel, and aesthetic at the same time using Stable Diffusion 1.5\non an online platform called Leonardo.AI. At the time of running\nthe experiment, Leonardo.AI was one of the few interactive tools\nthat allowed the participants to easily use text-to-image genera-\ntive models, such as various versions of Stable Diffusion, without\nthe need to run custom Python scripts. The evaluations of the\nfeasibility, novelty, and aesthetics of the generated designs are\ncollected via crowdsourcing. The relationship between the par-\nticipants' DSE strategies when using Stable Diffusion and the\nevaluation scores of their generated designs are analyzed. Key\nresults from this study show that the goal orientation and the\nnumber of goals targeted by the prompts are more closely corre-\nlated with the design evaluation scores than the time users spend\nediting globally versus locally and their length of prompts. Dur-\ning early, broader exploration stages, multi-criteria prompts with\nfeasibility and/or novelty goal orientation are found to be effec-\ntive. Later in more refinement-focused stages, mono-criteria,\naesthetics-oriented prompts are suggested to be used.\nThe rest of this paper is organized as follows. The next\nsection provides a review of the background literature on DSE\nand text-to-image GenAI, identifying the research gap. Then, the\npurpose and the impact of this work are discussed, followed by\nthe Method section, illustrating the study design, including de-\nscriptions of the task, participants, and experimental procedure.\nThen, the results are presented and discussed, including a discus-\nsion of the limitations of this work. The paper concludes with\na summary of the main findings and its implications for design\nresearch and practice."}, {"title": "2. BACKGROUND", "content": "2.1 Design Space Exploration\nDSE is a crucial step in the product design process, dur-\ning which designers explore a wide range of potential designs\n(divergence) and select and refine a fewer selection of designs\n(convergence) [5, 41]. Divergence is important for successful de-\nsign as it expands designers' creativity and increases the novelty\nand quality of their designs [44]. It aims to prevent designers\nfrom limiting themselves to one or few viable solutions too early\nby encouraging the formulation of a variety of potential solutions.\nAlong with divergence, convergence is an equally important as-\npect of DSE. Once designers have explored enough, they must\nevaluate, select, and refine the final solution(s) based on various\ndesign requirements, goals, and preferences.\nDuring DSE, designers engage in divergent thinking through\nvarious methods like problem reframing [33, 34] and analogies\n[45]. Generation and consideration of a large number of design\noptions can be encouraged through the manipulation of a vari-\nety of characteristics, such as flexibility and imagery [36]. This\nprocess not only allows designers to maximize their creative out-\nput, but also provides an opportunity to gain more insights into\nthe problem and the design space. Prior research has attempted\nto find effective inspirations and methods to assist designers'\ndivergent thinking using non-AI-based methods. For example,\nThinklets [39] is a creativity support tool that guides designers\nto think of ideas from multiple angles through open-ended ques-\ntions. Ideation Decks [37] is another example, a set of cards that\nprompts designers to think about their design space from differ-\nent angles. While these tools have shown some effectiveness,\ntext-to-image GenAI can enable a much more efficient DSE and\nsignificantly reduce designers' cognitive load by quickly generat-\ning multiple designs from text prompts. However, adopting this\nmethodology means that designers must sacrifice some level of\ncontrol in the design generation process (between text prompt and\ngenerated image).\nConvergence is also a crucial aspect of DSE, during which\ndesigners make selections and/or mark preferences for certain\naspects of generated designs [45]. Often informed by data, de-\nsigners choose specific design directions and make refinements\nto the designs as the most important dimensions of the problem\nspace come into focus. Tools to support generative design explo-\nration apply convergence methods in different ways. For example,\nthe workflow in Dream Lens [40] starts with the user defining the\nproblem space. Then, the constraints and requirements from the\nresulting definition are used by the algorithm to generate a de-\nsign. Additionally, GANCollage [38] updates its backend with\nthe \"user selection\" every time the user requests \"similar images\"\nto accomplish the objective of choosing one final image. For\neffective design convergence, it is crucial to understand various\nuser interactions during image exploration that could drive this\nprocess. Leonardo.AI, the tool used in this study, also includes\nvarious features that aim to facilitate design convergence, which\nwill be explored in this work."}, {"title": "2.2 Image Generative Al", "content": "With the recent advances in GenAI, there is great potential for\nthese tools to effectively support creative processes. GenAI is a\nrapidly evolving field that involves the creation of algorithms and\nmodels capable of generating novel content in various domains,\nsuch as images, text, and music. Its primary goal is to imitate the\nintricate creative process by leveraging existing datasets to iden-\ntify underlying patterns and yield outputs that closely resemble\nthe characteristics of the training examples. Since 2020, discus-\nsions of various applications of GenAI, such as human resources,\nliterature, and art, have emerged. Specifically in product design,\nthe potential of image GenAI as a tool for the early stages of the\ndesign process has been explored in some recent design litera-\nture [47]. There are primarily two types of models employed\nfor image GenAI: Generative Adversarial Networks (GANs) and\ndiffusion models.\nGANs were introduced by Goodfellow in 2014 in the field of\nmachine learning (ML). GANs are built using a pair of neural net-\nworks: a generator and a discriminator, operating on the principle\nthat one network's gain is another network's loss. The generator\nis trained to generate new data samples, while the discriminator\ndetermines whether these samples are real or generated. Training\ncontinues until the discriminator's performance is above a certain\nthreshold. Over the years, GANs have undergone significant re-\nfinement, incorporating methods such as injecting noise into the\ngenerator's input [7], employing diverse loss functions [8], and\napplying regularization methods [9], to promote the diversity of\nthe generated data and improve the overall quality of the model\noutputs. With this refinement, the practical applications of GANS\nhave expanded, serving as an effective model for image-to-image\nGenAI for DSE by rapidly creating a large number of possible\ndesigns [10, 11].\nThe diffusion model was introduced by Sohl-Dickstein, et al.\nin 2015 as an alternative paradigm for GenAI [15]. The diffu-\nsion model works by adding small random noise to the training\ndata over multiple steps to produce a sequence of samples, then\nlearning to recover the data by reversing this process. The per-\nformance of the model has been advanced continuously, giving\nrise to a flow-based generative model employing invertible trans-\nformations [16], a continuous-time diffusion process called the\nFree-form Jacobian of Reversible Dynamics (FFJORD) model ca-\npable of generating high-quality samples with efficient inference\n[17], and a new architecture that combined flow-based models\nwith invertible 1x1 convolutions [18]. Ho, et al. further im-\nproved flow-based generative models, enhancing the quality and\ndiversity of generated samples [19]. Most of the current, widely-\nused text-to-image GenAI tools like DALL\u00b7E 2, Stable Diffusion,\nand Midjourney are founded on diffusion models.\nDiffusion models offer unique advantages compared to\nGANs. They guarantee a more fine-grained control over the\ngenerated images, permit data quality and diversity manipulation\n[20], and avoid mode collapse via a stable training process. A pa-\nper by OpenAI researchers [21] has indicated that diffusion mod-\nels can achieve image sample quality superior to the GAN models.\nHowever, some main drawbacks of diffusion models are that they\nrequire longer training times and are computationally expensive\nbecause of the model's inherent complexity and the sequential\nnature of the diffusion process. This work uses Leonardo.AI, an\nonline GenAI platform that provides an interface to work with\nvarious text-to-image diffusion models. Leonardo.AI is a partic-\nularly appropriate tool for this work as it offers global and local\nediting modes that are useful for investigating the users' DSE\nprocess. At the time of the experiment, Leonardo.AI was one of\nthe few, if any, online text-to-image GenAI platforms that allowed\nthe users to seamlessly transition between global and local editing\nmodes."}, {"title": "2.3 Research Gap", "content": "Despite the promises of text-to-image GenAI in aiding the\nengineering design process, many current tools are imperfect\ntools for product design applications because of the various design\ngoals and requirements, as well as Al's inherent vagueness in the\nrelationship between the input (i.e., communicated goal) and the\ngenerated output. Therefore, there is an open question on how\nto use these promising yet imperfect GenAI tools for DSE and\nyield desirable designs. Only when this question is answered\ncan people successfully utilize text-to-image GenAI for product\ndesign."}, {"title": "3. RESEARCH AIMS AND SIGNIFICANCE", "content": "The purpose of this work is to close this gap in knowledge by\ninvestigating different DSE strategies using text-to-image GenAI\nand their impact on the generated outcome, specifically feasibility,\nnovelty, and aesthetics. The strategies are observed through the\nusers' interaction with and during the global and local editing\nmodes on Leonardo.AI. The research question of this work is:\nHow do users' design space exploration strategies when\nusing text-to-image generative AI influence the feasi-\nbility, novelty, and aesthetics of the generated product\ndesigns?\nSpecifically, we want to understand whether and how the time\nusers spend and the characteristics of prompts used in global and\nlocal editing modes have significant impact on the feasibility, nov-\nelty, and aesthetics of the generated outcomes. It is hypothesized\nthat the more time spent in the global editing mode exploring\nthe design space, the better the ratings of the generated outcome.\nAdditionally, it is expected that the more prompting is focused on\na goal, the more likely the rating for that goal will be higher. This\nwork is expected to contribute to the design research commu-\nnity by suggesting what DSE strategies are effective when using\nGenAI for product design, specifically for designing feasible,\nnovel, and asethetic products."}, {"title": "4. METHOD", "content": "A human subject experiment is designed and conducted to\nexamine how users leverage global and local editing modes in\nLeonardo.AI, an online GenAI platform, to explore and create\nfeasible, novel, and aesthetic designs. The collected data are\nanalyzed to find DSE strategies that yield outcomes that success-\nfully meet the design goals. The feasibility, novelty, and aesthetic\nratings for generated designs are collected via crowd-sourced\nevaluations.\n4.1 Human Subject Experiment\nThe entire experimental process is recorded and transcribed,\nfacilitating the observation and analyses of user actions. During\nthe experiment, the participants interact with Stable Diffusion via\nthe Leonardo. Al platform to complete a design task. Leonardo.AI\noffers a wide range of features, as shown in Fig. 1.\n4.1.1 Participants. Total 15 participants are recruited and\nhave completed the experiment. They range over ages between\n25 and 33 years and vary in their level of experience with GenAI\ntools. Regarding the level of experience with text-to-image\nGenAI, nine participants are first time users, three are somewhat\ninexperienced, two are neither inexperienced or experienced, and\none is somewhat experienced. Six of the participants are male,\nand nine are female. Their educational backgrounds range from\nbachelors to doctorate degrees. Additionally, all participants\ndemonstrate proficiency in English above level C1 and use En-\nglish on a day-to-day basis.\nA Google form for recruitment is employed to gather essen-\ntial participant information, such as age, email address, education,\nand level of experience with GenAI tools. It is also ensured that\nthey viewed the tutorial video on Leonardo. AI and that their con-\nsent is obtained for participation and recording. Every participant\nare compensated with a 20 euro voucher for their participation in\nthe experiment.\n4.1.2 Experimental Task. The participants are asked to\ncreate feasible, novel, and aesthetically-pleasing bike design(s)\nusing Stable Diffusion on Leonardo.AI in 30 minutes. Feasibility\nis a crucial design goal as it assures that the tools align with real-\nworld constraints. It examines whether the AI-generated images\ncan realistically be implemented within the context of a product.\nThis is essential to avoid unattainable designs. This work also\nconsiders novelty to ensure that users harness the potential of\ntext-to-image GenAI in producing creative designs [27]. Finally,\naesthetics goal is demanded in this work as well it is a significant\ncomponent in design as a major factor of product popularity [26]."}, {"title": "4.1.3 Procedure", "content": "At the start of the experiment, the partic-\nipants are given a comprehensive pre-task tutorial. This tutorial\naims to familiarize the participants with Leonardo.AI, explain the\nexperimental task, and ensure that they possess adequate knowl-\nedge about bikes. First, to facilitate the participants' usage of\nLeonardo.Al's features, all features are demonstrated to them\nwithin the tool itself. Additionally, the participants are provided\nwith a wiki page containing information about bike parts and\ntypes. Then, they are asked to complete a practice task on cre-\nating a vase for tulips using Leonardo.AI, giving the participants\na chance to engage with the software and get their questions\nanswered.\nAfter the pre-task tutorial session, the main task begins. The\nparticipants are provided with the task description and are given\n30 minutes to complete the task. Once the task is completed,\nthe participants undergo a post-experiment interview and a brief\nquestionnaire. The three interview questions are:\n\u2022 Can you briefly describe your experience using Leonado. AI?\nWhat did you like about it? What did you dislike about it?\n\u2022 Did you encounter any difficulties using the tool? If so, can\nyou describe what they were?\n\u2022 Are there any additional features or functionalities you would\nlike to see added to the tool to improve?\nThese additional measures aim to gather qualitative data to un-\nderstand the quantitative results further. Then, the questions in\nthe post-experiment questionnaire ask the participants to report\nhow easy it was to use each feature of the tool, how important\nthey think each feature of the tool is, and how feasible, novel, and\naesthetic they think their final designs are. These questions are\nanswered in a 5-point Likert scale."}, {"title": "4.2 Crowd-Sourced Design Evaluations", "content": "The final set of 18 images is submitted by the 15 participants\n(one image each by 12 participants and two images each by three).\nCrowd-sourced evaluations are conducted using Google Forms\nto assess the feasibility, novelty, and aesthetics of these designs.\nThe evaluation questionnaire asked raters to evaluate each bike\nimage on its feasibility, novelty, and aesthetics based on a 5-\npoint Likert scale ranging from 'Strongly Disagree' to 'Strongly\nAgree'. Some example questions are shown in Fig. 2.\nRaters are recruited from the Prolific platform, which is a\nplatform for researchers to recruit and manage participants from a\nlarge, global participant pool for online studies. In total, 10 raters\nevaluated the images, allowing for a broader range of perspectives\nand opinions to be considered."}, {"title": "5. RESULTS", "content": "In this work, DSE strategies are observed by the partici-\npants' actions the global and local editing modes in Leonardo.AI.\nWithin each editing mode, the participants' actions are mostly\ndone via text prompting. Therefore, this work examines the par-\nticipants' prompting action characteristics to gain insight into\ntheir exploration strategies. Along with the participants' explo-\nration strategies, this section also presents the correlation results\nbetween these strategies and the feasibility, novelty, and aesthetics\nratings of the generated outcomes.\nThree major action characteristics in the global and local edit-\ning modes are examined: length, goal orientation, and multi vs.\nmono-criteria of prompt. These three characteristics have been\nselected because they are frequently discussed in the prompt en-\ngineering literature. For instance, Xie, et al. performed a log\nanalysis from participants from a text-to-image and found a cor-\nrelation between the length of the prompt and the quality of the\ngenerated image [29]. From a prompt construction perspective,\nstudies have discussed about mono-criteria prompts having higher\naccuracy than multi-criteria prompts [30, 31], meaning that tar-\ngeting multiple design objectives in a single prompt might not\naccurately express the designer's intentions. Finally, PromptMa-\ngician is a tool that suggests keywords to be added to the text\nprompt to enhance the alignment of the generated images with\nthe intended vision of the creator [32].\nIt is important to note that three out of the 15 participants\nsubmitted two bike designs and none more than two. For these\nthree participants, the average data of their two bike creation\nprocesses are used throughout the analyses. Therefore, in this\nwork, one data point consistently represents each participant.\nBefore conducting each statistical analysis presented in this\nsection, normality of the included data is tested via Shapiro-Wilk\ntest. If the data are normal, two-sample t-test and Pearson's\ncorrelation test are conducted for two sample comparison and\ncorrelation analyses respectively. If the data are not normal,\nWilcoxon signed-rank test and Spearman's rho test are conducted."}, {"title": "5.1 Global vs. Local Editing", "content": "One notable aspect of users' exploration strategy with respect\nto Leonardo.AI is how they choose to allocate their time between\nthe global and local editing modes. As shown in Fig. 1, the\nglobal and local editing modes are available on Leonardo.AI for\nthe participants to either change the entirety of the AI-generated\nimage using text prompts or to change only a part of this image\nusing various features like masking and erasing, respectively. The\nvisualization of each participant's time distribution among global\nand local editing modes is shown in Fig. 3.\nMost participants (14 out of 15) engage in both global and\nlocal editing, while only one user exclusively focused on global\nediting. It is observed that participants all start in the global\nediting mode, and after 4.0 prompts in the global editing mode\non average, are inclined to select an image for local refinement.\nFurthermore, it was observed that the participants who entered\nthe local editing mode never reverted back to the global editing\nmode, unless they are starting a new design.\nOn average, the participants allocate about 38.5% of their\ntime to global editing, concentrating on general modifications,\nand the remaining time (61.5%) to local editing, refining specific\ndetails to meet the design goals. To investigate the split between\nglobal and local editing modes further, the number of prompts\nthe participants enter in the two modes are observed. About\n36.7% of the prompts (on average 4.0 prompts) are entered in\nthe global editing mode and the rest (63.3%) in the local mode,\na fairly consistent result with the time split result. Overall, the\nparticipants spend more time in the local editing mode than in\nthe global editing mode, though without statistical significance\n(Wilcoxon signed-rank test, p=0.2 for time and p=0.1 for number\nof prompts)."}, {"title": "5.2 Prompt Length", "content": "The participants' actions via prompting in the global and lo-\ncal editing modes are explored to extract their exploration strate-\ngies. The first action characteristic is the length of prompts. The\naverage length of prompts are demonstrated in Fig. 4. On aver-\nage, the participants' prompts are about 7.7 words long, and the\nprompts they use in the global editing mode (13.4 words long on\naverage) tend to be longer than those in the local editing mode\n(3.9 words long on average) (t-test, p=1.1e-3). The length of the\nlongest prompt is 47 words, and the shortest has only one word."}, {"title": "5.3 Mono vs. Multi-Criteria Prompts", "content": "Given that the participants are asked to design for three dif-\nferent goals simultaneously, it is important to examine how they\norient their prompts for the goals in the global and local editing\nmodes. For this purpose, every prompt by the participants is\nlabeled by the authors as feasibility, novelty, and/or aesthetics-\noriented. Prior to labeling, the three authors agree on the de-\nscriptions of the three orientations of prompts shown in Table 1,\nwhich are used to guide the labeling process.\nThe authors label the prompts separately according to the\ndescriptions in Table 1, and the final labels are determined based\non the majority agreement. Multi-criteria labeling is allowed.\nFor example, if a prompt is relevant to both feasibility and nov-\nelty, it will be labeled as a both feasibility and novelty-oriented\nprompt. When there are negative prompts (prompts to elimi-\nnate components from an image), they are considered together\nwith the main prompts. For instance, if the main prompt is pri-\nmarily feasibility-oriented and the negative prompt is aesthetics-\noriented, these prompts are considered as a single prompt that is\nboth feasibility and aesthetics-oriented.\nMany participants employ prompts that are oriented to-\nwards multiple design goals (i.e. multi-criteria prompts), such\nas \"square tire bike with bottle cage and red chain ring\" which is\nboth novelty and aesthetics-oriented, while others concentrated\non prompting for a single goal (i.e., mono-criteria prompts), such\nas \"a bike with special design\" which is only novelty-oriented.\nTherefore, the average percentage split of multi- vs. mono-criteria\nprompts in the global and local editing modes are observed to un-\nderstand the participants' exploration strategy. Figure 5 shows\nthe results.\nOverall, 52.0% of the prompts are mono-criteria, and the rest\n(48.0%) are multi-criteria, therefore showing a relatively equal\nsplit (t-test, p=0.7). This overall split is most likely because of\nthe contrasting split in the global and local editing modes. In\nthe global editing mode, there are more, though not statistically\nsignificant, multi-criteria prompts (75.0%) than mono-criteria\nprompts (22.9% = 11.3% + 11.6% + 0.0%) (Wilcoxon signed-\nranks test, p=0.07), while in the local editing mode, there are more,\nthough not statistically significant, percentage of mono-criteria\nprompts (63.4% = 35.1% + 13.4% + 14.9%) (Wilcoxon signed-\nranks test, p=0.1) than multi-criteria prompts (34.1%). Therefore,\nthe results show a tendency among the participants to tackle\nmultiple design goals at once in the global editing mode, while\ntaking one goal at at time in the local editing mode."}, {"title": "5.4 Goal Orientation of Prompts", "content": "Figure 6 shows the percentage split of feasibility, novelty,\nand aesthetics-oriented prompts. It is important to note that both\nmono and multi-criteria prompts are considered in these results;\nfor example, the percentage of feasibility-oriented prompts in-\ncludes the mono-criteria ones that are only feasibility-oriented,\nas well as the multi-criteria ones that target feasibility along with\nother goals.\nIn the global editing mode, all three goals are tar-\ngeted often in the participants' prompts without any statisti-\ncal difference between the percentages of these orientations\n(78.5% feasibility-oriented, 73.8% novelty-oriented, and 68.7%\naesthetics-oriented). In contrast, in the local editing mode,\nthe participants use a much higher percentage of feasibility-\noriented prompts (59.4%) than novelty-oriented prompts (19.8%)\n(Wilcoxon signed-rank test, p=0.02). Comparing the results in\nthe global and local editing modes, it is observed that the prompts\nin the global editing mode often target all three goals, while the\nprompts in the local editing mode are more likely to target feasi-\nbility over the other two goals."}, {"title": "5.5 Correlation with the Design Outcome", "content": "Correlation analyses between the observations above and the\nfeasibility, novelty, and aesthetic ratings of the generated images\nare conducted to identify the exploration strategies that yield\ndesirable design outcomes. The ratings are determined by the\ncrowd-sourced evaluations described in the Method section.\n5.5.1 Global vs. Local Editing and Prompt Length.\nThe correlations of the time the participants spent and their\nprompt length in the global and local editing modes with the\ndesign outcome are examined. No statistically significant corre-\nlations are found, meaning that neither how much time is spent\nnor how many prompts are used in the global versus local editing\nmodes are related to any ratings of the design outcome.\n5.5.2 Mono vs. Multi-Criteria and Goal Orientation\nof Prompts. The participants' exploration strategy is also stud-\nied via two of their prompting characteristics in the global and\nlocal editing modes: mono versus multi-criteria and goal orien-\ntation of prompts. The correlations between these characteristics\nand the feasibility, novelty, and aesthetic ratings of the bikes are\ncomputed, as demonstrated in Fig. 7.\nDuring the global editing mode, the percentage of feasibility-\noriented prompts is significantly correlated to the feasibility rating\nof the generated image (Spearman's rho test, rho=0.6, p=0.02).\nThis means that using more feasibility-oriented prompts during\nthe global editing mode can significantly boost feasibility rat-\nings. Therefore, if you want to enhance novelty in your prompts,\nit would be beneficial to use more prompts specifically targeting\nnovelty-related aspects. Such correlations are not shown between\nnovelty and aesthetics-orientated prompts and their correspond-\ning ratings (Spearman's rho test, rho=0.3, p=0.3 for both).\nInterestingly, however, the percentage of novelty-oriented\nprompts in the global editing mode is negatively correlated to the\naesthetics rating (Spearman's rho test, rho=-0.6, p=0.02). When\nmore novelty-oriented prompts are used in the global editing\nmode, the generated design are less aesthetically-pleasing.\nFinally, the percentage split between mono and multi-criteria\nprompts in the global editing mode is found to be negatively\ncorrelated to the feasibility rating (Spearman's rho test, rho=-0.5,\np=0.03), as well as the average rating (Spearman's rho test, rho=-\n0.6, p=0.01). More multi-criteria prompts and less mono-criteria\nprompts can help increase the feasibility and average ratings of\nthe design outcome.\nIn the local editing mode, the only significant correlation is\nfound between the percentage of aesthetics-oriented prompts and\nthe feasibility rating of the outcome. This correlation is positive,\nmeaning that the more aesthetics-oriented prompts are used in\nthe local editing mode, the higher the feasibility rating of the\ngenerated image is (Spearman's rho test, rho=0.6, p=0.02).\nThe final result to note is the general positive relationship be-\ntween feasibility and aesthetics, while they both show a negative\nrelationship with novelty. The results regarding goal orientation\nof prompts in Fig. 7 mostly demonstrate positive correlation co-\nefficients between feasibility and aesthetics. Novelty has negative\ncorrelation coefficients with feasibility and aesthetics. This result\nis supported by the positive correlation between the percentage\nof feasibility-oriented and aesthetics-oriented prompts found in\nthe Goal Orientation of Prompts section."}, {"title": "6. DISCUSSION", "content": "The purpose of this work is to address the research question:\nHow do users' design exploration strategies when us-\ning image generation AI tools influence the feasibility,\nnovelty, and aesthetics of the generated outcomes?\nThis section discusses the answers to this question with the results\nfound in this work, as well as their implications for design research\nand the use of text-to-image GenAI in product design. Then, the\nlimitations of this work and the areas for future research are\ndiscussed.\nThe results in this work first show that people commonly\nemploy a combination of global and local editing with a signif-\nicant focus on local refinements, spending approximately 61.5%\nof their time locally editing the images. Once in the local editing\nmode, they do not return to the global editing mode. This behav-\nior may be because of the complexity of the steps on Leonardo.AI\nto return to the global editing mode, especially given the time con-\nstraint. It could also be a reflection of \"design fixation\" [22, 23", "43": "."}]}