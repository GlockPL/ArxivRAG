{"title": "Few-Shot Learning Approach on Tuberculosis\nClassification Based on Chest X-Ray Images", "authors": ["A.A.G. Yogi Pramana", "Faiz Ihza Permana", "Muhammad Fazil Maulana", "Dzikri Rahadian Fudholi"], "abstract": "Tuberculosis (TB) is caused by the bacterium Mycobacterium tuberculosis, primarily affecting the lungs. Early detection is crucial for improving treatment effectiveness and reducing transmission risk. Artificial intelligence (AI), particularly through image classification of chest X-rays, can assist in TB detection. However, class imbalance in TB chest X-ray datasets presents a challenge for accurate classification. In this paper, we propose a few-shot learning (FSL) approach using the Prototypical Network algorithm to address this issue. We compare the performance of ResNet-18, ResNet-50, and VGG16 in feature extraction from the TBX11K Chest X-ray dataset. Experimental results demonstrate classification accuracies of 98.93% for ResNet-18, 98.60% for ResNet-50, and 33.33% for VGG16. These findings indicate that the proposed method outperforms others in mitigating data imbalance, which is particularly beneficial for disease classification applications.\nIndex Terms-TBX11K, Prototypical Network, Data Imbalance, Transfer Learning", "sections": [{"title": "I. INTRODUCTION", "content": "Tuberculosis (TB) is an infectious disease caused by the\nbacterium Mycobacterium tuberculosis and is the leading\ncause of death from a single infectious disease [1]. The bac-\nteria commonly invade the lungs leading to reduced efficiency\nof lung function. It can also cause damage to other parts of the\nbody such as the brain or spine [2]. The potential spread of\nTB can be very high through the medium of air when people\nwith TB cough and sneeze.\nEarly diagnosis of TB can help increase the chances of a\nperson with TB to recover. Early diagnosis of TB means that\ntreatment can be initiated earlier, leading to less chance of\ntransmission and better outcomes for patients [3]. One of the\nways for early diagnosis of TB is by using image analysis\nwith X-ray modality, especially on the lungs. X-ray images\ncan reveal several findings that may indicate the presence of\nTB, with symptoms such as nodules, cavities, or infiltrates in\nthe patient's lung tissue.\nTB diagnosis can be categorised into active and latent\ntypes. Active TB infection is risky and this type of TB is\ndistinguished by consolidation of cavitary lesions in the lungs,\nhas a strong likelihood of spreading the disease [4], while\nlatent TB infection is the presence of immunoreactivity to\ntuberculosis antigens in the absence of clinical and radiological\nsymptoms of TB. However, latent TB infection can reactivate\nand cause infectious disease [5]. In addition, there are also\ncases of active and latent TB. In this case, both active and\nlatent TB can be seen in an X-ray image. This is a rare\ncase, where the rarity of the case causes data imbalance.\nData imbalance can be resolved by data augmentation such\nas zooming, flipping, and rotating the chest X-Ray image for\nTB detection [6].\nHowever, data augmentation can produce variations that do\nnot reflect the original conditions, which can make the model\nevaluation experience overfitting. The prototypical network\nalgorithm based on the few-shot learning (FSL) approach\ncan overcome this problem. The working principle of this\nalgorithm is that the classifier should generalise to new classes\nnot seen in the training set, with only a small number of\nexamples of each new class through metric space learning\nwhere classification can be performed by calculating the\ndistance to the prototype representation of each class with a\nsimpler inductive bias [7].\nTherefore, a FSL approach through prototypical\nnetwork algorithm is used to handle the data imbalance\nproblem of active-latent tuberculosis disease. The\nmethod was tested using the TBX11K dataset\n(https://www.kaggle.com/datasets/usmanshams/tbx-11) which\ncontains patient X-ray image data. This dataset contains data\nof 3800 TB negative patients and 800 TB positive patients,\nwith the percentage of TB positive patients reaching 17% of\nthe total data."}, {"title": "B. Problem Definition", "content": "This research focuses on addressing the issue of class\nimbalance within the TBX11K chest X-ray image dataset, a\ncommon challenge encountered in medical imaging datasets.\nIn particular, the dataset exhibits a significant disproportion\nbetween the negative TB class, which is substantially larger,\nand the positive TB class. This imbalance poses a challenge for\nclassification models, as they tend to prioritize learning from\nthe majority class, ultimately leading to reduced accuracy in\npredicting instances of the minority class."}, {"title": "C. Research Constraints", "content": "In this study, several problem constraints are provided as\nfollows:\n1) The TBX11K dataset, obtained from Kaggle, serves as\nthe primary dataset for analysis.\n2) mage feature extraction is performed using three distinct\nmodels: VGG16, ResNet-18, and ResNet-50.\n3) The classification task is implemented using the Proto-\ntypical Learning algorithm.\n4) The objective of the study is to examine the impact of\nvarying shot numbers and feature extraction methods on\nclassification performance in the context of imbalanced\nimage data."}, {"title": "D. Research Contributions", "content": "The literature review indicates that previous research has\naddressed the challenge of data imbalance through the appli-\ncation of various data sampling techniques and classification\nmethods, including Random Forest and XGBoost, as high-\nlighted in the surveyed studies. However, there is a notable\ngap in the literature concerning the use of a few-shot learning\napproach, specifically Prototypical Networks, to address class\nimbalance in chest X-ray (CXR) image datasets."}, {"title": "II. LITERATURE REVIEW", "content": "Data imbalance is common in medical machine learning,\nimpacting model accuracy in disease diagnosis. One approach\nto address this is data augmentation, involving techniques like\nzooming, flipping, and rotating, as used by Oltu et al. [6] for\nTB detection in chest X-rays, achieving 96.6% accuracy and\na 0.99 AUC. Similar augmentation methods were applied by\nKotei [8] and Bista [9], preventing overfitting. However, data\naugmentation risks generating unrealistic variations, leading to\noverly optimistic evaluations.\nAnother method, SMOTE, addresses data imbalance by\noversampling minority classes. Fadhlullah [10] used SMOTE\non the TBX11K dataset, improving accuracy from 94.11%\nto 94.33% with XGBoost. Similarly, Fonseca [11] achieved\n99.74% accuracy using SMOTE. However, SMOTE can intro-\nduce issues such as data overlap, noise, and small disjuncts\n[12] [13].\nTo overcome the weaknesses of those methods, the use of\nprototypical network algorithm, which is a few-shot learning\napproach, is considered. This algorithm proposed in [7] is used\nto solve the problem of few-shot classification. This algorithm\nis able to cover the weaknesses in other techniques so it can\nsolve the problems of few-shot learning, especially overfitting.\nThus, this study aims to explore the impact of prototypical\nnetwork algorithm which is a few-shot learning approach\non imbalanced chest X-ray image dataset. This research is\nexpected to provide a comparison of model prediction results\nwith and without the use of prototypical network algorithms."}, {"title": "III. METHODOLOGY", "content": "This research aims to support neurosurgeons in more accu-\nrately diagnosing tuberculosis types by addressing the data\nimbalance issue in TB X-ray images without resorting to\noversampling methods. By integrating meta-learning and ma-\nchine learning, the proposed classification model enhances the\nprecision of distinguishing between TB classes, crucial for\nimproving diagnostic accuracy and treatment decisions.\nThe success of classification models depends heavily on\ndata volume and distribution across classes [14]. In imbal-\nanced datasets, a high overall accuracy often masks poor\nperformance in minority classes, leading to misclassification\nof critical cases. To tackle this, few-shot learning offers a\nrobust solution. Designed for scenarios with limited data, it\nleverages knowledge from related tasks and advanced tech-\nniques like metric and transfer learning to improve minority\nclass representation. This approach not only enhances classifi-\ncation accuracy for underrepresented classes but also improves\noverall model performance, making it particularly effective for\nreal-world imbalanced datasets."}, {"title": "B. Data Acquisition", "content": "The second stage of this research is the data acquisition\nstage. The data used in this study is the TBX11K dataset,\nwhich is a public dataset available on Kaggle. TBX11K con-\nsists of chest X-ray (CXR) images of TB patients from various\nsources. In this study, the TBX11K dataset elaborated by [15]\nwas used, where each image is annotated with bounding boxes\nfor classifying the detected type of TB. The image resolution\nin this dataset is 512\u00d7512. The dataset comprises a total of\n11,200 CXR images with a strong bias to the number of\nHealthy and Sick non-TB X-ray images. Therefore, before\nmodelling, it is necessary to apply a data balancing technique\non the training data to ensure that the number of samples in\neach class is treated as balanced."}, {"title": "C. Algorithm Overview", "content": "The next stage is modelling. The model in this study are\ndivided into two. First, model without training, as shown in\nFigure 3. In this model, the test image is directly tested to\nthe model without training. In the other hand, in model with\ntraining, Figure 4, the dataset train is being trained in the first\nplace, then the test train is tested after the training process\nis done. In this third stage, the processes involved include\nresizing and feature extraction using different backbones for\nthe prototypical algorithm. To address the imbalanced dataset,\nwhich includes only three classes (TB, Sick, Healthy), a few-\nshot learning approach was utilized with the Prototypical\nNetwork algorithm. This algorithm required a backbone, so\nResNet18, ResNet50, and VGG16 were employed as varying\nbackbones. Each backbone was tested across four different\nvariations: 3-Way 20-Shot, 3-Way 10-Shot, 3-Way 5-Shot, and\n3-Way 1-Shot. All variations were evaluated using a query\nset of 10. samples. This methodology aimed to improve the\nmodel's ability to generalize across the different classes despite\nthe limited data available for some categories."}, {"title": "D. Preprocessing Model", "content": "At this phase, the image data undergoes preprocessing\nin preparation for feature extraction utilizing the VGG16,\nResNet-18, and ResNet-50 architectures. The preprocessing\npipeline involves resizing the images to 224x224 pixels and\ntransforming the color space to RGB format. Furthermore,\ndata augmentation methods, including cropping, flipping, and\nrotation, are implemented to increase the variability of the\ndataset for improved model robustness."}, {"title": "E. Feature Extraction", "content": "Feature extraction is performed using three pre-trained CNN\nmodels: VGG16, ResNet-18, and ResNet-50. VGG16 consists of 16 layers, ResNet-18 has 18 layers,\nand ResNet-50 contains 50 layers. For this study,\nfully connected layers and dropout are removed from all\nmodels, as they are used solely for feature extraction, not\nclassification. Specifically, the last 3 layers of VGG16 and\nthe last 2 layers of ResNet-18 and ResNet-50 are omitted."}, {"title": "F. Prototypical Network", "content": "One of the most well-liked and successful methods in\nthe few-shot learning literature is prototypical networks [7].\nPrototypical Networks were developed as an answer to the\nenduring problem of few-shot learning overfitting. Prototypical\nNetworks use non-linear mappings to embed spaces, working\nunder the premise that classifiers ought to possess a straight-\nforward inductive bias [16]. Prototypical networks compute an\nM-dimensional representation $c_k \\in \\mathbb{R}^M$ (or prototype) of each\nclass via an embedding function $f_{\\phi} : \\mathbb{R}^M \\to \\mathbb{R}^M$ with learnable\nparameters $\\phi$ [7]. For Each prototype is the mean vector of\nthe embedded support points that belong to its class:\n$c_k = \\frac{1}{ \\lvert S_k \\rvert} \\sum_{(x_i,y_i) \\in S_k} f_{\\phi}(x)$\n$S_k$ denotes the set of examples labelled with class\nk, with a supporting set of N labelled examples $S =\\{(x_1, y_1), ..., (x_N, y_N) \\}$ where each $X_i \\in \\mathbb{R}^D$ is a D-\ndimensional feature vector of an example and $y_i \\in \\{1, ..., K\\}$\nis the corresponding label. As illustrated in Figure 5, this\napproach is simpler and more efficient than many other\nmeta-learning algorithms, making it an attractive solution for\naddressing few-shot learning tasks. [17].\nFew-shot learning is essential in medical image classifica-\ntion, due to limited labeled data, adapting to new imaging\nmodalities, and reducing the anotation burden [16]. To gen-\nerate a prototype vector for each class, the vectors of the"}, {"title": "G. Classification Model", "content": "The classification process employs a Prototypical Network\nfor few-shot learning, leveraging feature vectors extracted\nfrom VGG16, ResNet-18, and ResNet-50. The network op-\nerates with a support set for training and a query set for\ntesting, aiming to classify query images into three categories:\nTB, Sick, and Health.\nClass prototypes are generated by averaging the feature\nvectors of support set examples for each class. For instance, the\nprototype for the \"TB\" class is the mean of the feature vectors\nfrom its support examples, with the same procedure applied\nfor Sick and Health classes. Query image classification is\nperformed by comparing the query's feature vector, extracted\nby the CNNs, to the class prototypes using Euclidean distance.\nThe query image is assigned to the class with the closest\nprototype. Model performance is then evaluated by comparing\nthe predicted labels with the true labels, with accuracy used as\nthe key metric for assessing classification effectiveness across\nthe three classes."}, {"title": "H. Model Testing", "content": "1) Validation Technique: In the model creation process,\nthe training data is divided with a composition of 80:20,\nwith 80 percent allocated for training and 20 percent for\nmodel validation. This division aims to measure the model's\nperformance during the training and classification process.\n2) Model Evaluation: After validation, testing is conducted\nusing a confusion matrix to evaluate the model's ability to\nclassify data into each class. The model's performance is tested\nboth with and without FSL resampling to compare outcomes.\nThe dataset is split into training and testing sets, where the\ntraining data is used to develop the model, and the testing\ndata is used for an objective performance evaluation.\nModel evaluation includes calculating accuracy as a\nweighted average, accounting for the ratio of test samples in\neach class. These evaluation metrics are then used to compare\nthe overall performance of each model."}, {"title": "IV. RESULT AND DISCUSSION", "content": "Data preprocessing was performed to prepare the dataset\nfor feature extraction. This process involved normalizing the\npixel values by dividing each value by 255, resulting in a\nstandardized range between 0 and 1. This normalization en-\nhances stability and improves the convergence of the training\nprocess. Additionally, all images were resized to 224x224\npixels to align with the input size requirements of the VGG16\nin the accuracy performance and offer possible insights into\nthe underlying mechanisms.\nIn the VGG16 backbone, Figure 8, without meta-training,\nthe accuracy increases significantly as the number of shots\nincreases. Starting from 48.30% with 1 shot, it reaches 71.77%\nwith 20 shots. This trend indicates that VGG16, a relatively\nolder architecture, benefits greatly from additional data, as the\nnumber of support samples per class increases.\nHowever, the VGG16 results with meta-training are remark-\nably different. The accuracy remains constant at 33.33% across\nall shots, suggesting that meta-training fails to adaptively\nimprove the model's performance. This might be due to the\narchitectural limitations of VGG16, as it is known to have\nfewer representational capabilities compared to more modern\narchitectures like ResNet. This could also imply that the\nmeta-training process may not be effectively utilizing the\ninductive bias introduced by the VGG16 feature space, or the\noptimization is stuck in a poor local minima during meta-\ntraining.\nResNet-18, a lighter model in the ResNet family, demon-\nstrates significant accuracy gains without meta-training, im-\nproving from 55.53% with 1 shot to 74.80% with 20 shots.\nIts residual connections enhance generalization even with few\nsamples, and its computational efficiency makes it ideal for\nfew-shot learning without meta-training.\nWith meta-training, ResNet-18 achieves 96.80% accuracy\nwith just 1 shot, reaching 98.93% with 20 shots. This suggests\nthat meta-training enables ResNet-18 to quickly adapt to new\ntasks, with minimal accuracy gains from additional data, as the\nmodel generalizes effectively after seeing only a few examples.\nResNet-50 backbone, being a deeper and more\ncomplex architecture compared to ResNet-18, shows strong\nperformance in both meta-trained and non-meta-trained sce-\nnarios. Without meta-training, the accuracy increases from\n51.60% with 1 shot to 73.43% with 20 shots. Similar to\nResNet-18, ResNet-50 shows a consistent improvement in\nperformance as more examples are available, but the higher\nstarting point suggests that ResNet-50 has better representa-\ntional capacity even without meta-training. With meta-training,\nResNet-50 demonstrates high starting accuracy (95.50% with\n1 shot) and continues to increase, reaching 98.60% at 20\nshots. This is similar to ResNet-18 but with a slight edge in\nperformance, likely due to its deeper layers, which can capture\nmore abstract features. The diminishing increase in accuracy\nwith more shots suggests that ResNet-50, when meta-trained,\nhas already generalized well with just a few examples, and\nadding more examples provides minimal additional benefit."}, {"title": "V. CONCLUSION", "content": "The comparative analysis of VGG16, ResNet-18, and\nResNet-50 in FSL tasks highlights the significance of both\nmodel architecture and meta-training in addressing imbalanced\ndatasets in TB X-ray images. While VGG16 shows limitations\nin adapting during meta-training, ResNet-18 and ResNet-\n50 deliver superior performance, particularly when integrated\nwith meta-learning. Meta-training enhances the model's abil-\nity to generalize from minimal data, leading to improved\nclassification accuracy for underrepresented TB classes. This\nunderscores that deep architectures with residual connections,\ncombined with meta-learning, are the most effective strategy\nfor rapidly adapting to new tasks with limited data, aligning\nwith the aim of developing a reliable TB diagnosis model."}]}