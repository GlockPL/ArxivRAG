{"title": "Illegal Waste Detection in Remote Sensing Images: A Case Study", "authors": ["Federico Gibellini", "Piero Fraternali", "Giacomo Boracchi", "Luca Morandini", "Andrea Diecidue", "Simona Malegori"], "abstract": "Environmental crime currently represents the third largest criminal activity worldwide while threatening ecosystems as well as human health. Among the crimes related to this activity, improper waste management can nowadays be countered more easily thanks to the increasing availability and decreasing cost of Very-High-Resolution Remote Sensing images, which enable semi-automatic territory scanning in search of illegal landfills. This paper proposes a pipeline, developed in collaboration with professionals from a local environmental agency, for detecting candidate illegal dumping sites leveraging a classifier of Remote Sensing images. To identify the best configuration for such classifier, an extensive set of experiments was conducted and the impact of diverse image characteristics and training settings was thoroughly analyzed. The local environmental agency was then involved in an experimental exercise where outputs from the developed classifier were integrated in the experts' everyday work, resulting in time savings with respect to manual photo-interpretation. The classifier was eventually run with valuable results on a location outside of the training area, highlighting potential for cross-border applicability of the proposed pipeline.", "sections": [{"title": "Introduction", "content": "Improper waste management is a severely dangerous activity which threatens both the ecosystems and human health, being accountable for extensive air, soil and water pollution (Dabrowska, et al., 2023; Vaverkov\u00e1, et al., 2019). Moreover, illegal waste disposals might alter the natural evolution of ecological systems and boost the diffusion of alien or dangerous species. In this context, a correlation has been recently demonstrated between the presence of landfills and the incidence of mosquito-borne illnesses, such as dengue and chikungunya (Khan, et al., 2023). On top of health hazards, illegal waste handling is among the most fruitful activities for environmental crime organizations. In 2020, the annual revenues for hazardous waste trafficking in the EU were estimated between 1.5 and 1.8 EUR billions, whereas profits from non-hazardous waste trafficking ranged between 1.3 and 10.3 EUR billions (Europol, 2022). Two years later, environmental crime was reckoned as the third largest criminal activity in the world, with a growth rate of 5-7% and an estimated yearly turnover of 280 USD billions\u00b9. All these threats highlight the need for innovation in the investigation and crime fight processes implemented by environmental and law enforcement agencies.\nLately, advances in Computer Vision (CV) and Deep Learning (DL) technologies, as well as the increasing availability of Very-High-Resolution (VHR, \u2264 0.5m GSD) Remote Sensing (RS) images, have opened new opportunities to create tools for fighting environmental crime. The conjunction of such factors enables automatic analysis of wide regions while significantly reducing the need for expensive infrastructures and on-site inspections. This paper illustrates how these tools can be exploited by environmental agencies to let operators scan large territories in search of illegal landfills as part of their complex investigation processes. The contributions of this paper can be summarized as follows.\nThe paper firstly proposes a custom pipeline to support professionals from environmental agencies in their everyday investigation. The pipeline is composed of two phases: in the first one, a binary classifier is used to scan large areas and discover waste disposals via satellite imagery, whereas in the second phase, drone missions are deployed to collect additional images describing the detected sites, to estimate the dangerousness level of the disposal. This paper specifically addresses the first of these phases, which is thoroughly detailed in Section 3.1.\nThe second contribution of this paper is a thorough empirical study to identify the best configuration for the binary classifier. With this aim, an extensive set of experiments was conducted to evaluate the performance impact of various factors. These include: i) the Network Architecture, ii) the image GSD, iii) the Context Size of the area portrayed in the picture, and iv) the adopted Pretraining Weights. All experiments were conducted on a data set composed with support from expert photo-interpreters from an independent environmental agency, thus providing reliable annotations. These annotated data were published as version 3.0 of the AerialWaste data set (Torres, et al., 2021; Torres, et al., 2023). Experiments highlight that the best classifier is a Swin-T model trained with images at 20 cm GSD and portraying a squared area of 150x150m. This model achieves 95.01% Accuracy and 92.47% F1-Score."}, {"title": "Related Work", "content": "Automated waste detection in RS images has received increasing attention over the recent years, thanks to the latest advancements in RS technologies and the performance gains introduced by modern DL architectures, which allow to remotely detect and monitor waste landfills. Modern satellite sensors offer sub-meter resolution imaging at accessible costs, thus enabling accurate detection of waste disposal sites in a wide range of scenarios. Researchers developed several specialized approaches to detect dumping sites by leveraging various solid waste characteristics (e.g., visible content (Ulloa-Torrealba, et al., 2023), spectral signatures (Devesa, et al., 2021), vegetation stress (Silvestri, et al., 2008)) and combining RS imagery with other information such as geographical variables (Jord\u00e1-Borrell, et al., 2014) or historical maps (Lyon, 1987). Such methodological improvements fueled the transition from expensive in-situ inspections to innovative approaches based on scanning large regions to quickly detect potential waste sites, eventually maximizing operational efficiency by focusing in-person investigations only on the most suspicious locations.\nEarly works in this field employed manual photo-interpretation of Earth Observation images (Lyon, 1987) and were published when automatic image processing was beyond practical feasibility. These approaches required a significant human effort, which motivated the shift towards computer-aided techniques.\nSeveral techniques have been proposed in literature to combine satellite and GIS data (Notarnicola, et al., 2004), to apply traditional CV based on spectral or textural features on RS images (Parrilli, et al., 2021; Vambol, et al., 2019) and, recently, to exploit Convolutional Neural Networks (CNN) to address advanced tasks, such as scene classification (Lavender, 2022; Parrilli, et al., 2021; Torres, et al., 2021) or accurate waste localization (Kruse, et al., 2023; Sun, et al., 2023; Yailymova, et al., 2022; Yang, et al., 2022; Zhou, et al., 2023).\nLarge-scale landfills usually have a measurable negative impact on the surrounding environment, being accountable for stressed vegetation (Silvestri, et al., 2008) or for significant increases in the surface temperature, especially during summer (Beaumont, et al., 2014). Therefore, detecting large waste disposals does not require designing of particularly accurate techniques and can be tackled even with lower-resolution data. Multispectral imagery is used in (Gill, et al., 2019) to identify heat fluxes emitted by the decomposition process that occurs inside landfills. Alternatively, spectral indices are computed from multispectral bands to identify unhealthy vegetation (Silvestri, et al., 2008) or to localize olive oil mill waste (Agapiou, et al., 2016). Recent approaches identify large-scale landfills by means of DL-based models, such as semantic segmentation networks trained on multispectral imagery (Devesa, et al., 2021) or RGB pan-sharpened images (Rajkumar, et al., 2022).\nThe identification of smaller urban waste sites requires instead High-Resolution RS images, since relevant features are usually fine-grained and the typical site extension is constrained to a limited space. Therefore, traditional CV techniques and more advanced DL architectures are exploited to process satellite images and obtain precise locations. In (Faizi, et al., 2020) urban waste disposals are localized using a pixel-based multispectral image classification approach, whereas in (Didelija, et al., 2022; Ulloa-Torrealba, et al., 2023) segmentation approaches are used to merge nearby pixels into objects which are eventually classified as waste. In (Yong, et al., 2023) a segmentation model based on the DeepLabv3+ architecture (Chen, et al., 2018) is applied to high-resolution optical images to detect construction and demolition waste in urban areas. In (Torres, et al., 2021), a binary scene classification model based on a ResNet backbone (He, et al., 2015) architecture is trained on optical images at different ground resolutions. In (Li, et al., 2023; Sun, et al., 2023; Zhou, et al., 2023), object detectors are trained to localize waste dumps in urban scenarios. A modified YOLO (Redmon, et al., 2016) network is used in (Zhou, et al., 2023) to localize industrial and household waste, while in (Li, et al., 2023) a Key Point Network (Law, et al., 2018) is adopted to predict the set of keypoints that localize instances of urban solid waste. The pipeline proposed in this paper is designed instead to process VHR RGB RS images to detect clues of illegal waste disposal activities.\nDespite the vivid research on waste detection from RS images, all the solutions in literature are limited to training and testing models on private or public data sets. Our work is the first providing outputs from a waste classifier to professional operators of a large environmental agency for independent assessment as well as exploring how some practical design choices affect the classification performance.\nMore details on the topic of solid waste detection in remote sensing images can be found in recent surveys. (Papale, et al., 2023) reviews the relevant methods based on satellite data for landfill identification with a focus on case studies. (Fraternali, et al., 2024) provides a comprehensive review of the approaches for detecting and monitoring large-scale landfills or urban waste dumps discussing methods based both on traditional CV techniques and on more recent DL models."}, {"title": "Material and Methods", "content": "This section details the devised pipeline for aiding photo-interpretation professionals in detecting potential dumping sites leveraging a binary classifier of RS images. This section also describes the data set and the setup adopted for training such classifier.\nProfessional photo-interpreters interested in discovering illegal waste sites for fighting environmental crime usually invest a significant effort in visually scanning their competence areas in search of candidate dumping locations. This task is, however, both highly repetitive and time-consuming, thus representing fertile ground for process automation. With the introduction of the proposed pipeline, professionals can save up on temporal resources, which could be better devoted to tasks strictly requiring human intervention or expertise, such as assessing the risk level of each detected site.\nThe designed pipeline was developed in collaboration with some of these professionals from a local environmental agency and composes of 2 phases, both strongly leveraging CV techniques. In the first phase (Figure 2), which is the focus of this paper, large areas are scanned via satellite images to detect clues of illegal disposal activity, producing a restricted list of locations at risk. In the second stage, which is not addressed by this work, the most dangerous sites in from the list are inspected in Unmanned Aerial Vehicles (UAV) survey missions with the aim of precisely characterizing the overflown sites in terms of disposed materials and estimated volume."}, {"title": "Pipeline Overview", "content": "Figure 2 (left) illustrates the first stage of the pipeline, which receives as input a RS image covering the area of interest to the experts. To automatically scan large areas, the RS image is divided into smaller geo-referenced square tiles based on two parameters: i) the GSD of the input RS image and ii) the of the geographic Context Size (in meters) to be covered by each tile. The combination of these parameters determines the size in pixels of each tile to extract from the input image. As an example, given a satellite image with 30 cm/px GSD, a tile covering a squared area of 150x150m would have a size of 500x500px. Each of these tiles is then provided as input to a binary classifier, which identifies as positive tiles with clues of solid waste materials, and as negatives tiles with no visible waste. The classifier returns two outputs: i) a percentage score, stating the confidence with which each tile belongs to the positive class, and ii) a saliency map, computed via Grad-CAM (Selvaraju, et al., 2017) and highlighting the image pixels where the classifier focused to deliver a positive prediction. These saliency maps are obtained with a weakly-supervised localization approach requiring only image-label annotation. This constraint on the annotation format, which was requested by the environmental agency professionals, allowed to accelerate the annotation procedures while yet guaranteeing the opportunity to obtain detailed and precise outputs.\nTo ease the adoption of this pipeline by environmental agencies and, possibly, by law enforcement agencies, all the resources produced by the classifier have been geo-referenced. This implies that the outputs can easily be visualized in any GIS software, where they can also be overlayed to the input satellite images. This is visible in the last image of the left column of Figure 2 (left), where the colored squares represent the border of the analyzed tiles. The color of each tile depending on the confidence score output by the classifier on a yellow-to-red scale. This approach should enable end-users to double-check the visual appearance of the site and assign a risk level to the detected locations by taking into account additional information from the area, such as the population density and proximity to protected areas or water bodies. Such procedure might be adopted for shortlisting and prioritization of candidate locations for the following investigation stages, which should involve the deployment of UAVs for in-person survey missions."}, {"title": "Data Set Preparation", "content": "The employed data set was also prepared as a joint effort with professionals from a local environmental agency following the procedure illustrated in Figure 2 (right) with the aim of composing a data set with precise and reliable annotations. The data set was initially created with a location-based approach: the experts provided in the first place a list of waste locations in Lombardy (Italy) from previous investigation campaigns, thus providing an initial set of positive samples. Negatives were then randomly sampled starting from the positive locations in areas sufficiently close to the positive, to guarantee context similarity, but also far enough to avoid overlaps. Given this initial set of positive and negative locations, to foster diversity in the data set, RGB tiles were extracted in these locations from various sources: Google Earth (\u224821cm GSD in the target area), WorldView-3 (\u224830 cm GSD) and aerial flights (\u224820 cm GSD) conducted between 2021 and 2023 by AGEA, a national agricultural agency which periodically acquires ortho-photos of the territory.\nThis approach allowed to obtain a large set of labeled tiles for training a binary classifier. Each tile was then visually inspected by the professional photo-interpreters in search of large disposal sites, to ensure correct labeling. After this visual inspection process, which provided the final set of samples, the number of negative samples was chosen to be twice the number of positives, to reproduce the intrinsic class imbalance of this detection problem: in practice, indeed, waste locations are significantly outnumbered by non-suspicious sites. The final data set consists of \u224811,700 RGB tiles and coincides with version 3.0 of AerialWaste (Torres, et al., 2023)."}, {"title": "Experimental Setup", "content": "In the process to identify the best binary classifier on the designed task, various factors might be decisive for altering the model performance. These parameters might either describe specific features of the processed images, such as their content or size, or characterize the implemented training process. The following subsections describe the reasons behind the choice of each parameter addressed in the experiments."}, {"title": "Image Factors: GSD, Context Size, and Image Size", "content": "Two factors primarily influence the content of tiles fed to the classifier: i) the GSD, which is expressed in (centi)meters per pixel and indicates the scale of the objects present in an image, and ii) the geographic Context Size, which is expressed in meters and describes the dimensions of the squared geographic area represented in the picture. The ratio between these factors determines the Image Size, which is expressed in pixels and represents the actual size of the images input to the networks.\nThe combination of these factors might strongly affect the network performance, thus requiring investigation before the pipeline implementation. On the one hand, as illustrated in Figure 3.a, increasing the Context Size implies portraying a wider region in a single image, thus providing the network with additional information. This might benefit the classification performance, since the evaluation of a specific object might be affected by the surrounding context: for instance, a car in a regular parking lot should not be reckoned as waste, whereas an abandoned car in a forest should. However, if the GSD is not adjusted across the various Context Size values, increasing the Context Size implies increasing the Image Size, thus potentially hindering the model classification capabilities. On the other hand, increasing the GSD while adopting the same Context Size (Figure 3.b-e), implies reducing the Image Size at the cost of producing coarser images. This might however result in losing the distinctive pattern of some specific objects, such as asbestos plates, whose characteristic corrugated pattern may be unnoticeable when they appear at a smaller size.\nGiven the primary importance of the GSD, experiments were conducted after defining the range of values worth exploring for this factor. The chosen values are 20, 30, 40 and 50 cm/px, with the lowest being the most common value among images in the training set, whereas the latter 3 are the most widely-adopted among commercially-available VHR satellite images. Then, 3 values for the Context Size factor were chosen,"}, {"title": "Training Factors: Network Architectures and Training Procedure", "content": "Experiments were conducted to compare two Network Architectures, ResNet-50 and Swin-T, which were identified as valuable representatives of the architectures most frequently adopted for image classification, i.e., respectively, CNNs and Vision Transformers. In addition, these networks share a comparable number of parameters, 23M for ResNet-50 and 27M for Swin-T, as well as a similar 4-staged architecture which required only slight adjustments to fit the task of binary classification. In this context, the network head was replaced to be a single Fully-Connected layer with a single output neuron, followed by a Sigmoid activation to eventually produce the classification score for the positive class.\nFor the selected architectures, two initializations with different Pretraining Weights were tested: traditional ImageNet (Deng, et al., 2009) Pretraining (INP) and pretraining on a large data set of RS images for aerial scene recognition (Wang, et al., 2023), henceforth Remote Sensing Pretraining (RSP). According to Deep Learning best practices, training was performed following a 2-phase procedure. In the first phase, Transfer Learning (TL), the weights of the pretrained model are loaded for the entire network, except for the classification head, the backbone is frozen, and only the head is trained. In the second stage, Fine Tuning (FT), the model obtained from the previous step is unfrozen and all the layers are trained.\nDuring the experiments, both Network Architectures were trained under all possible combinations of GSD, Context Size and Pretraining Weights, with the results shown in Table 2. To align at best the experiment hyperparameters and, therefore, to precisely study the impact of each image and training factor, all training experiments were executed with a batch size of 120 and with a phase-dependent learning rate: 0.001 during TL and 0.0001 during FT. Experiments were executed on a single node of a High-Performance Computing cluster, where each node is endowed with 8 Nvidia A100 GPUs. For FT experiments, 8 GPUs were used independently of the network to train whereas, during TL, 1 GPU was used for ResNet-50 experiments and 2 GPUs were used for Swin-T experiments."}, {"title": "Results and Discussion", "content": "This section first illustrates the results of the training experiments, with a focus on the performance impact of each factor from the experimental setup presented in Section 3.3. Then, two additional experiments are presented, to evaluate the practical applicability of the designed pipeline in the real world. The first of these experiments aims at defining the time savings stemming from the introduction of the pipeline in the everyday life of environmental monitoring professionals (Section 4.2). The latter explores the generalization capabilities of the developed model to an area outside of the training region (Section 4.3)."}, {"title": "Training experiments", "content": "Experiments were conducted covering all the possible combinations of Network Architecture (2), GSD (4), Context Size (3) and Pretraining Weights (2), to assess the impact of each factor in terms of performance. This approach led to 48 experiments (2*4*3*2), which are all summarized in Table 2 and shown in Figure 4, where each experiment coincides with a point on the drawn lines. In the rest of this section, results from these experiments are analyzed, with a focus on the F1-Score metric, since Accuracy values closely follow those in F1-Score, albeit with a slight difference in scale.\nFirst and foremost, experiments highlight that both networks achieve excellent results on the addressed task, consistently averaging around 90% F1-Score. However, for each combination of GSD and Context Size, Swin-T yields better values than ResNet-50. This is apparent in Figure 4.a, where all the solid lines associated to Swin-T experiments are higher than any dashed line, which represents ResNet-50 experiments. Figure 4.b, instead, shows that adopting RSP can be beneficial for ResNet-50, leading to a better average of the highest values, closer to the related Swin-T results. Therefore, it is less apparent that training with the transformer-based architecture and RSP still provides higher F1-Scores, even though each plain line is higher than its dashed counterpart with the same color.\nRegarding the impact of RSP, Figure 4.b clearly highlights a characteristic behavior for experiments with a Context Size of 210m. In this case, both networks achieve high scores with the central GSD values, whereas they obtain much lower results with the extreme GSD values. This behavior might be motivated by the disproportion between the Context Size and the GSD: adopting the widest context and the extreme GSD values might lead to either too much or too little detail to eventually benefit classification. In this context, it is worth noting that, also with INP, the just-analyzed combinations do not yield the highest results. Alternatively, the phenomenon might be justified by considering that RSP weights were obtained by training the network with a data set of RS images. Therefore, the pretraining weights might have already learnt relevant features at a specific GSD, thus benefitting training at the same or similar GSD values.\nThe network behavior in relation to GSD when training with INP (Figure 4.a) is more difficult to interpret, with no clear suggestions about a specific distribution of the scores. However, the comparison between the two networks highlights an interesting phenomenon: increasing GSD seems to benefit ResNet-50, whereas it hinders the performance of Swin-T. This might be explained by the relationship of GSD and Image Size: keeping the Context Size fixed and reducing the GSD implies increasing the Image Size, to which ResNet-50 might be more sensitive than Swin-T. Therefore, lowering the GSD implies feeding the ResNet-50 with larger images, which might hinder the performance of this network.\nFinally, the best model overall was found to be Swin-T when trained with a GSD of 20 cm/px, a Context Size of 150 m and pretrained on ImageNet. This model, as visible in Table 2, achieves the highest results both in F1-Score (92.47%) and Accuracy (95.01%)."}, {"title": "Field Validation", "content": "The practical utility of the proposed pipeline has been evaluated with an informal study executed in collaboration with the professionals of the environmental agency that provided the database of waste locations used to build the data set. The goal was to assess time savings when scanning a large territory with the support of the designed pipeline rather than with traditional methods.\nThe study was conducted on the territory of 12 municipalities in Lombardy (Italy), which were scanned following two methodologies: the traditional manual photo-interpretation and the Al-supported approach. The former methodology consisted in manually inspecting the satellite imagery covering the region of interest using a GIS tool, without further assistance. With the latter method, instead, the proposed pipeline was used to scan the entire territory by dividing it into squared tiles with a side of 210 m, following a specific preference of the professionals involved in the experiment. The tiles were analyzed with an early version of the classifier with ResNet backbone, developed before conducting the exhaustive investigation in Section 4.1 and achieving comparable performance with respect to the best classifiers. Then, the interpreters scanned the territory by visualizing on a GIS tool the prediction scores and saliency maps output by the classifier, after filtering the tiles to only those with a higher confidence score than a threshold value of 0.2.\nThe photo-interpretation activity involved 4 professionals, each analyzing 6 municipalities with the traditional method and 6 with the support of the classifier. As reported in Table 3, exploiting the classifier predictions allowed the personnel of the environmental agency to detect a greater number of sites, 155 critical sites against the 95 identified without Al support, and to focus their attention on a smaller portion of territory, reducing by 60.2% the area to be examined. The scanning times were recorded to compare the manual and the computer-aided methodologies based on the time necessary for the operators to detect and verify a site. As expected, given the higher number of detected sites, the measured total time increased as well. Nevertheless, the average time employed for each site lowered by 12.2%, thus demonstrating the benefits of adopting the proposed pipeline for scanning the territory and detecting waste sites.\nThe entire procedure was repeated in a more conservative settings where the filtering threshold is set to a value of 0.7, i.e., only tiles with a high probability of containing waste sites are inspected. In this case, the area to be inspected drops by 64% and the number of sites decreases by 32%, thus providing a reduction in the site identification time of approximately 30%. Consequently, the threshold value of 0.7 was reckoned as the most appropriate for detecting high-risk sites while minimizing the likelihood of missing potential sites. Unfortunately, the number of municipalities involved in the study did not allow to assess the impact of operators' fatigue, a relevant phenomenon occurring when analyzing a significant quantity of images. Therefore, the observed time savings can be considered a lower bound to what could be achieved in real conditions when analyzing hundreds of municipalities."}, {"title": "Generalization to other regions", "content": "The proposed pipeline aims at becoming a valuable support tool for environmental monitoring professionals from all around the world. Therefore, an experiment was designed to test the classifier generalization ability in a different region with respect to the one providing training samples. The chosen region is a portion of Attica (Greece) with apparent geographical differences compared to Lombardy (Italy): indeed, outside of residential areas, instead of green forests and fields, the Greek region mostly covers a hill territory with a large amount of brownish dry lands.\nThe test set for this experiment was composed following a location-based approach. At first, more than 100 positive and 100 negative locations were identified on Google Maps, as an operator would without support from our pipeline. Then, for the selected locations, squared tiles with a side of 150 m were extracted from a recent WV3 acquisition, formerly pan-sharpened to provide RGB imagery at 30 cm GSD and, therefore, compatible with images in the training set, since they share source and GSD with some of the training samples. The extracted tiles were later visually double-checked and their label was corrected in case the portrayed location had changed in the interval between the image acquisition time for the two different sources. This process provided a small test set (Figure 5) of 241 images, divided into 119 positive and 122 negative samples.\nOn the composed test set, the best model from Section 4.1, i.e., a Swin-T pretrained with ImageNet weights and trained on images with Context Size of 150 m and GSD of 20 cm/px, was run for inference and traditional classification metrics were extracted. The achieved scores of 89.21% Accuracy and 88.29% F1-Score, losing respectively 4.18% and 5.80% from metrics on the standard test set, demonstrate that the classifier generalizes well to regions outside of the training area, thus supporting the pipeline as a valuable tool for landfill detection in various locations."}, {"title": "Conclusions", "content": "This paper illustrates a pipeline for detecting waste landfills and demonstrates its potential in aiding environmental monitoring experts in their everyday job, by relieving the effort needed for cumbersome tasks such as manual photo-interpretation. At the core of the proposed pipeline is a deep neural network which classifies RS tiles based on the presence or absence of waste and localizes potential waste piles. This network was thoroughly assessed with a set of experiments aimed at defining the impact on its performance of various design factors, such as GSD and Context Size of training images, Network Architecture, and Pretraining Weights. These experiments identify as the best classifier a Swin-T model trained with INP on images with a GSD of 20 cm/px and portraying a squared area with a side of 150 m. This classifier achieves 92.47% F1-Score and 95.01% Accuracy on the adopted data set.\nThe pipeline was then assessed with an experiment in collaboration with experts from a local environmental agency, providing an independent validation of its utility in terms of the acceleration and consequent temporal cost reduction of the territory scanning activity. The classifier at the core of the pipeline was also tested to analyze a different region than the one providing training images, demonstrating good generalization performance and the pipeline potential to support monitoring experts from various locations on Earth.\nFuture work might focus on the development of technologies to aid prioritization of on-site inspection campaigns, for example by automatically identifying the materials contained in a landfill at risk. In this context, crucial support might come from the adoption of multi- or hyper-spectral data, as well as from the introduction of multi-modal information, such as cadaster, land use and other non-visual data. In addition, work could be conducted in the field of multi-temporal analysis with the eventual aim of monitoring the evolution of landfills over time."}]}