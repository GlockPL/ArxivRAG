{"title": "Basic Research, Lethal Effects:\nMilitary AI Research Funding as Enlistment", "authors": ["David Gray Widder", "Sireesh Gururaja", "Lucy Suchman"], "abstract": "In the context of unprecedented U.S. Department of Defense (DoD) budgets, this paper examines the\nrecent history of DoD funding for academic research in algorithmically based warfighting. We draw\nfrom a corpus of DoD grant solicitations from 2007 to 2023, focusing on those addressed to\nresearchers in the field of artificial intelligence (AI). Considering the implications of DoD funding for\nacademic research, the paper proceeds through three analytic sections. In the first, we offer a critical\nexamination of the distinction between basic and applied research, showing how funding calls framed\nas basic research nonetheless enlist researchers in a war fighting agenda. In the second, we offer a\ndiachronic analysis of the corpus, showing how a \u2018one small problem' caveat, in which affirmation of\nprogress in military technologies is qualified by acknowledgement of outstanding problems, becomes\njustification for additional investments in research. We close with an analysis of DoD aspirations\nbased on a subset of Defense Advanced Research Projects Agency (DARPA) grant solicitations for the\nuse of AI in battlefield applications. Taken together, we argue that grant solicitations work as a vehicle\nfor the mutual enlistment of DoD funding agencies and the academic AI research community in\nsetting research agendas. The trope of basic research in this context offers shelter from significant\nmoral questions that military applications of one's research would raise, by obscuring the connections\nthat implicate researchers in U.S. militarism.", "sections": [{"title": "Introduction", "content": "The United States Department of Defense (DoD) was arguably the first major investor in the field of\nartificial intelligence (AI), and remains one even amidst the ascendance of corporate players. Defense\nspending on AI nearly tripled from 2022 to 2023 (Henshall 2024), and in 2024 the DoD requested\n$1.8 billion for AI research, development, testing and evaluation. As corporate capture of AI research\nreceives increasing scrutiny, the close association between academic AI research and the DoD has\nendured. What is funded affects what is created, but also the norms of the wider AI research\necosystem: in one example, research on the incentives governing academic Natural Language\nProcessing (NLP) research shows how the DoD's switch from \u201cpatient\u201d funding approaches to a\nbenchmark culture meaningfully affected the course and culture of the NLP field (Gururaja et al.\n2023).\nIn this paper, we explore a corpus of DoD grant solicitations issued between 2007 and 2023 (Bateyko\n& Levy, 2024), aided by NLP and information retrieval tools, selecting for calls that reference Artificial\nIntelligence and associated technologies. Focusing on the implications of DoD funding for academic\nresearch, we read these grant solicitations as a vehicle for the mutual enlistment of academic\nresearchers and DoD research agencies in each others' agendas. Broad Agency Announcements and\nother funding calls outline joint projects that align interests in the research community with military\npriorities, at the same time that those priorities are shaped by the promissory technologies on offer\nfrom academic and commercial research laboratories.\nIn what follows we set out our discussion in four parts. We begin with a description of the corpus and\nour methodological experiments with NLP-enabled search as a resource for interpretive analysis. We\nthen proceed through three analytic sections. In the first, we offer a critical examination of the\ndistinction between \u201cbasic\u201d and \u201capplied\u201d research, showing how funding calls targeted towards the\nformer, while they may make it easier for researchers to avoid thinking of their work as being directed\ntowards lethal ends, nonetheless enlist researchers in a military agenda. In the second, we offer a\ndiachronic analysis of the corpus, taking three series of Broad Agency Announcements calling for basic\nresearch as cases. Reading across these funding programs, we track a recurring formulation that we\ncall the \"one small problem\u201d caveat. This is a rhetorical move in which affirmation of progress in\nmilitary technologies is qualified by acknowledgement of outstanding problems, which become\njustification for additional investments in research. The third analytic section offers an analysis based\non a subset of Defense Advanced Research Projects Agency (DARPA) grant solicitations making\nexplicit reference to the use of AI in battlefield applications, attending to the agency's problem\nframings and imagined technological solutions."}, {"title": "Interpretive methods with models", "content": "This paper offers an interpretive analysis supported by computational methods of a corpus of grant\nsolicitations issued between late 2007 and late 2023 from the US Department of Defense. Solicitations\nare calls for academics to submit research proposals for possible funding, thus aspirationally\ndescribing research a DoD agency hopes to fund. Our original corpus comprised 46,175 solicitations\nautomatically downloaded in bulk from the publicly available US government grants.gov database,\nwhich we filtered for those originating from the Department of Defense, narrowing our corpus down\nto 9292. We retained only documents in PDF format, discarding other formats, most but not all\ncontaining budget, worksheets, and other details, creating a final dataset of 7187 documents.\nWe then made use of three computational methods to help examine the 7187 documents: (1) a\nsearchable database of the dataset content, (2) a clustering method to identify temporal sequences of\nreleases of the same solicitation, and (3) a topic model to help us characterize the types of language\nthat appear in these documents. In identifying documents for closer reading, our aim was not a\nquantitative, distributional analysis but rather an examination of the aspirations articulated by the\nsolicitations, as informed by prevalent directions in academic research in computer science. Our\nanalyses are intended to be indicative, opening lines of investigation rather than offering a\ncomprehensive survey of the corpus.\nTo elaborate briefly on these computational methods, we begin with tools for search. As even simple\nkeyword searches of that many PDF documents quickly overwhelmed our personal computers, we\nuploaded the documents to an ElasticSearch database hosted on a central server. This allowed us to"}, {"title": "\u201cBasic Research\u201d is morally intertwined with the battlefield", "content": "There are a variety of morally relevant distinctions that researchers draw when choosing whether to\naccept military funding, and if so, what particular projects to work on. Chief among them is the\nbasic/applied distinction, where basic research is considered to be conducted without ostensible\nintentions for particular end uses, or more specifically in the case of DoD funding not connected to\nweapons or war as applied research might be (Kuipers 2021). The DoD's \u201cBasic Research Office\u201d\nwebsite quotes Vannevar Bush's notorious report \u201cScience: the Endless Frontier\" to say that basic\nresearch \u201ccreates the fund from which the practical applications of knowledge must be drawn\u201d\n(Department of Defense, n.d.). Our dataset provides examples of how the imagined distinction"}, {"title": "Context for the Basic / Applied distinction", "content": "The Congressional Research Service shows how DoD science and technology funding is broken into\neight \"budget activity\u201d categories (Sargent, Jr, 2022). Categories 6.1 and 6.2 are \u201cBasic\u201d and \u201cApplied\"\nresearch respectively. Numbers from 2022 show that DoD funding makes up 41.2% of the entire\nfederal budget for research and development, and within this DoD portion, Basic and Applied research\ntogether make up less than 10% of the expenditure, with the lion's share going to \u201coperational systems\ndevelopment\u201d and \u201cadvanced component development and prototypes\" (Sargent, Jr, 2022). And yet\nwithin the overall small fraction, \u201cbasic\u201d research is funded at about one third the level of \u201capplied\"\nresearch. Even if basic research is to be considered in some way morally exempt, in other words, it is\nat best a tiny adornment on a much larger arsenal of R&D funding directed more explicitly towards\nmilitary ends.\nUniversity policies attempt to support free exchange of ideas while accepting military funding. As one\nexample, Carnegie Mellon University (CMU) derives 42% of its research funding from the DoD\n(Carnegie Mellon University, 2023), accruing the third most DoD funding of any university (Folts,\n2024). The university has a policy that by default this funding must be \u201cunrestricted\u201d in terms of\npublication, though it allows explicitly restricted and military-funded research to occur in its\n\u201cnonacademic\u201d \u201csemi-autonomous units\u201d, and even in academic units by exception (Carnegie Mellon\nUniversity, 1988). Debate within CMU's School of Computer Science about the ethics of such funding\naffirms an apparently morally relevant distinction between \u201cweapons\u201d and \u201cnon-weapons R&D\u201d, but\ncapaciously defines the latter to include the development of the autonomous tactical vehicle named\n\u201cCrusher\u201d, because no literal weapons were built onto it by the university (Carnegie Mellon University,\nn.d.) CMU also hosted a listening session for the DOD's Defense Innovation Board, which affirmed the\nDoD's goal to use AI to \u201cfight and win in future wars\" (Defense Innovation Board, 2019).\nRecommendations from the Defense Innovation Board included strengthening private sector and\nuniversity connections, held up top tech companies and Elon Musk (by name) as inspiration, and\nrecommended a \u201cfocus on exploratory research\u201d. In short, while basic/applied distinctions are seen as\ncore to the university's mission and to the maintenance of academic ethics, our dataset allows us to\nexamine how the basic/applied distinction works in DoD funding calls and the questions that this\nraises."}, {"title": "How basic research is directed to military ends", "content": "Even when a program is framed as funding for basic research, there are indications that positioning a\nproposal in relation to DoD objectives will increase its chances of success. For example, the 2024\nVannevar Bush Faculty Fellowship call (#1) says, in bold text, that the fellowship is intended for\n\u201cambitious 'blue sky' research", "basic research\", as\n\\\"systematic study directed toward greater knowledge": "without specific applications [...] or products\nin mind.\\\" This is immediately followed, however, by the qualification that such work must be \u201crelated\nto long-term national security needs.", "future\nrevolutionary new capabilities for DoD,": "s well as training students \u201cfor the defense workforce\u201d to\nenable \u201clong-term relationships between university researchers and the DoD\u201d. In short, while it is\nasserted that proposals for basic research are welcome, it also becomes clear that successful proposals\nwill articulate outcomes relevant to defense interests.\nBasic research is also often discussed with explicit reference to battlefield and military applications. In\nthe same Vannevar Bush fellowship cited above, scientific areas set out in the solicitation include\nnumerous examples of the language of warfighting, for example \u201cFundamental research in neural\nactivity [...] can also lead to the development of brain-machine interfaces (BMIs) to facilitate the\nintegration of the warfighters and future AI agents.\u201d (p.12) In another example, a funding call from the\nArmy Research Office, for its Historically Black Colleges and Universities program, calls for research\non Lidar Remote Sensing, which the call says \u201ccould be used\u201d for \u201cremote sensing over the battlefield,\ne.g., in support of field artillery targeting\" (#3). Finally, another \u201cbasic research\u201d solicitation promises\nfunding for the so-called \u201cInternet of Battlefield Things,", "dynamics that exceed human\nop-tempos\" the \u201csurvivability of mission assets": "nd handling the exigencies of an \u201cIoBT-enabled\nbattlespace\" (#4). This solicitation notes that while the \u201ccore\u201d research is to be funded as basic\nresearch, there is also a path to funding for applied research as an \u201cEnhanced Program"}, {"title": "How the basic/applied distinction is obviated", "content": "Finally, there are many programs funded as either Basic or Applied research, with little apparent\ndistinction made between the two. A Navy funding call states that \u201cONR is interested in receiving\nwhite papers and proposals in support of advancing artificial intelligence for future naval applications.\nWork under this program will consist of basic and applied research...\u201d, including \u201cAI enabled training\nenvironments that test warfighter skill\" (#5) Many other solicitations invite proposals addressed\nexplicitly to military applications; for example a funding call for \u201cAir Delivered Effects\u201d from the Air\nForce Research Laboratory's Munitions Directorate includes a research funding area on \u201cAutonomous\nTarget Recognition.\" Subgoals include \"Approaches for training AI/ML or traditional algorithms with\nsynthetic target data that result in good target recognition performance when using real target data\",\nand \u201cautonomous handoff of target cue information from intelligence, surveillance, and\nreconnaissance (ISR) or fire control sensors to weapon[s]\u201d (#6). The Army Corps of Engineers asks for\nbetter \"sensor payloads\u201d for \u201cdrone swarms\u201d to \u201cmonitor human [...movement...]\u201d (#7).\nWe look in more depth at calls for research directed towards military applications below, in our\nexamination of Defense Advanced Research Projects Agency (DARPA) calls for research in AI/ML.\nHere the point is to underscore the extent to which DoD grant solicitations, including those framed as\nbasic research, are saturated with reminders of the department's aim of expanding the warfighting\ncapacities of the U.S. military. Research characterized within university laboratories as basic, relevant\nto a wide and possibly indeterminate range of applications, is effectively steered towards military ends\nthrough indications that proposals will be ranked in terms of their relevance to DoD priorities. At the\nsame time, DoD investments extend beyond funding for particular research projects, to building out\nand securing the network of relations, and financial dependencies, that hold the military-academic\ncomplex in place. In the following section we look at a series of grant solicitations over time, to trace\nother devices through which cycles of problem formulation and promised technological solution are\nsustained."}, {"title": "From problem to solution, or solution to problem?", "content": "Our dataset spans 16 years, allowing us to track trends in AI research topics across this period. To\nground our analysis, we examine grant solicitations in three programs, each with a different\ndisciplinary focus, all explicitly categorized as \u201cbasic research\". Firstly, the Multidisciplinary\nUniversity Research Initiative (MURI) solicits research yearly on \"high priority topics and\nopportunities, primarily in STEM fields. Secondly, solicitations for the Vannevar Bush Faculty\nFellowship (VBFF) fund faculty fellows each year, typically on the same topics year-to-year ranging\nfrom artificial intelligence to materials science to quantum computing (though with some major\nchanges discussed below). Finally, the Minerva Research Initiative is devoted to \u201csupporting social\nscience for a safer world\", focusing on topics of \u201cstrategic importance to the U.S. national security\npolicy.\" The fact that these three programs do not focus solely on AI or even computer science, but\ninstead reflect broad areas of military research interest, allows us to examine AI's position in the\nmilitary imagination, its relative importance among other fields of study, and its impact as a method\nwithin other fields and relative to outside trends in academic and industrial AI research. Notably, we\nsee how, especially after 2021, AI increasingly becomes entangled with other fields, where it is seen\neither as a necessary part of those areas of research, or even their ultimate goal.\""}, {"title": "One small problem", "content": "Solicitations that outline an aspirational capability employ a recurring rhetorical move that we call the\n\"one small problem\u201d caveat. Here, affirmation of the promise of an existing approach is followed by\nassertions of its limited scope, and the need for research that would allow the approach to work under\nmore \u201crealistic\" conditions. For example, when discussing approaches based on game theory,\nsolicitations assert that it models how \"emotionless geniuses\" behave, rather than \"average people\nwith emotions\" (MURI 2011, #14), and assumes a \"stable world/environment", "may not be\nguaranteed\" (MURI 2015, #15). Similarly, reinforcement learning, despite its \"dramatic success": "t\ngames like chess or Go, is of uncertain applicability to \"problems of practical interest.\" (MURI 2021,\n#16). This framing balances two competing incentives: emphasizing certain methods' promise and\npast successes and thus presenting them as viable directions for future work, while at the same time\ndirecting that future work towards military contexts in which their \u201cone small problem", "one small problem": "aveat increasingly narrows its focus to machine\nlearning approaches within AI. In 2011, MURI topic 22 solicits work on game theory with the"}, {"title": "AI as a durable frame", "content": "This narrowing of focus to specific techniques reflects the increasing prominence of AI, as even the\nconception of problems is set out in the terms, methods, and affordances of AI and machine learning.\nAI then becomes a durable frame: a way of conceptualizing problems over the span of multiple years,\nand a precedent that any new approach should reference.\nIn the MURI series, the most notable early example of a durable frame is control theory, prominent in\nthe late 2000s, which faded as big data and network science took over around 2012. Network science\nremains a durable frame in the VBFF dataset as AI emerges: the 2021 rewrite of topics in the VBFF\nseries (#19) elevates \"Networks and Artificial Intelligence", "more consistent and reproducible": "han qualitative methods, offering\n\"well-defined comparisons\" (2013, #20). This holds even as the authors of later Minerva solicitations\nacknowledge that \u201cquantitative\u201d does not mean \u201cobjective,\u201d that changes in quantification and metrics\nresult in different insights, and that quantitative work may not be \"grounded and ethnographically\nrepresentative", "cognitive effectiveness and emotional resilience": "or warfighters in the face of sleep\ndeprivation and the \"growing volume of data presented by today's weapon systems,"}, {"title": "Inevitability amid ambivalence", "content": "Durable frames, in their conception, require successes to point at in order to justify their continued\nfunding and interest. The successes attributed to AI in the series often rely on discourse familiar in\nmore consumer-facing applications, including the inevitability of the revolution that it brings. AI's\ninevitability, however, is based in claims of its progress\" that are, at best, only vaguely connected to\nthe solicitation's intended field of application. One MURI topic in 2020 (#23), \"Adaptive and\nAdversarial Machine Learning,\" rests its assertions that machine learning \"improves overall\neffectiveness\" on the \"success of autonomous cars on US roads,\" despite the fact that no autonomous\ncars in 2020 had moved beyond trial programs in narrowly defined environments (Piper 2020).\nFurther, as the solicitation notes, deep learning can be \"easily defeated by minute perturbations\" in\noperating conditions. Similarly, another MURI topic in the following year (#16) states baldly that \"in\n10 years, many cyber tasks will be carried out by autonomous systems,\" without citing any evidence or\nsource for this prediction, while noting that deep learning provides few behavioral guarantees, and key\ntechnical assumptions are \"commonly [...] violated in the real world.\" In these cases, the authors of the\nsolicitations appear firmly convinced that AI and deep learning are inevitable, despite their own\narticulation of the (potentially fundamental) flaws with these approaches.\nThe juxtaposition of inevitability with the acknowledgement of outstanding problems represents a\nsignificant and recent rehabilitation of AI's image in the military imagination. Until about 2020, the\ntechnology undergirding the modern conception of AI, deep learning, was considered wholly\nunsuitable for military problems. Solicitations discussing deep learning in 2017 and 2018, rather than\nposit it as promising using \u201cthe one small problem\u201d caveat, instead point at its \"crippling fragility\u201d,\nand imply that deep learning with its large data requirements is not \"physically viable", "like": "regardless of whether possessing AI capabilities equates with power, the world finds\nitself in a race to develop and deploy these technologies\" (2020, #25).\nIn its growing prominence in the framing of DoD grant solicitations, AI demonstrates a departure\nfrom previous forms. Despite the lack of clear (public) successes in the military domain, it is still\nincreasingly seen as inevitable by multiple communities, who at the same time demonstrate their\nawareness of the fundamental, deeply rooted pitfalls in adopting it: the lack of behavioral guarantees\nand \"crippling fragility\" of deep learning systems, the potential for ungrounded quantitative analyses\nthat bear the sheen of objectivity, and the massive costs of data and computational resources. These\""}, {"title": "Constructing the (AI) battlefield", "content": "Along with the positioning of DoD-sponsored programs in relation to topics of interest framed as basic\nresearch, grant solicitations include explicit calls for imagined applications of artificial intelligence\ntechnologies to the battlefield. In this section we offer a reading of documents selected from the\nresults of a Segmented Document Search on the keyword \u2018AI,' filtered for the agency name DARPA.\nThe 101 results returned by the search include Broad Agency Announcements issued from March 2010\nto June 2023.\nThe Calls discussed below include direct reference to AI or ML, as well as explicit indications of\nanticipated battlefield use. We approached our reading of these documents with three overlapping\nquestions in mind. Firstly, what \u201csmall problems\" in existing warfighting capacities do the calls\nreference in order to motivate further research and development in AI/ML? Secondly, how do the calls\nframe the future of warfighting, whether as necessary responses to the operations of others or as\naspirational optimizations of US military strategy? And finally, how are these problems and their\nimagined solutions located in histories of modern warfighting and its contemporary formations? We\naddress these questions under three themes that mark both longstanding and emergent areas of\nmilitary interest: Situational Awareness,\nHuman-Machine Teaming, and Distributed\nWarfighting/Lethality.\""}, {"title": "Situational awareness", "content": "Continually confounded by the \"fog of war\" (Shapiro 2005), situational awareness (SA) is a\nfoundational concern of military doctrine. SA is defined by Micah Endsley, former Chief Scientist of\nthe United States Air Force, as \u201cthe perception of environmental elements and events with respect to\ntime or space, the comprehension of their meaning, and the projection of their future states\u201d (1988;\nfor a critique see Suchman 2023). Military doctrine takes information gathering, formalized as\nIntelligence, Surveillance, and Reconnaissance (ISR), as key to enabling situational awareness through\nnetwork infrastructures and targeted surveillance. Consistent with the automation of computation in\nthe mid-twentieth century, these capabilities are conceptualized as recursive procedures that follow\nthe hierarchical ordering of command and control. This runs from the formulation of strategy by\nsenior officers, to the tactical operations of front-line commanders, through to the perceptions and\nactions of individual warfighters. In the contemporary moment, our corpus shows how optimization of\nsituational awareness is to be achieved through increasing reliance on the application of AI\n(principally ML) in ISR.\nIn March 2010, DARPA issues a Broad Agency Announcement (BAA) for the \u201cMind's Eye Program,\u201d\nwith the aspiration to develop machine capabilities in \u201cvisual intelligence.\u201d (#26) The announcement\nopens with a review of the limits of the current state of computer vision, in its reliance on statistical\ncomputations based on benchmark datasets rather than models of perception and cognition in"}, {"title": "Human-machine teaming", "content": "Along with the aim of greater machine autonomy, contemporary investment in AI is justified within\nthe research and development community as a step toward \u201charmonious partnership between humans\nand AI.\" Embraced by the DoD, the aspiration to what is named \"human-machine teaming\" is a\ncontinuation of a cybernetic imaginary that positions the human as the \u201cmachine in the middle", "Science of\nArtificial Intelligence and Learning for Open-world Novelty (SAIL-ON).": 28, "understanding the most important\ncomponent of the environments in which they operate: humans.": "he BAA returns to a paradigm of\nmental models as the basis for successful interaction. Among other deliverables, the BAA asks for\nsimulations of \u201cagents\u201d that demonstrate the requisite social skills, implemented in a virtual testbed\nwith input from standardized \u201csensing channels", "communication/action\nchannels\" made available to human teammates through standardized interfaces. The testbed should\ndemonstrate agents' capacities to \u201coperate in increasingly complex and specialized environments, be\nadaptable to sudden perturbations in the mission or team (like the loss of communication with a key\nteammate), and use noisy multi-channel observations to represent the world and do complex\ninference and prediction.": "y confining the demonstration to a simulation, rendering contingency as\ncomplexity, specialization, perturbations, and noise (all terms with familiar computational\ntranslations), and defining social skills as the alignment of mental models, the call for \u201copen-world\nnovelty", "ego-centric video captured from\nhead-mounted cameras.\"(#29) The premise is that \u201cestimating and modeling user emotions is\nimportant for effective human-computer teaming.\" More specifically, the aspirational capability\ninvolves \u201cnew techniques to determine the emotional state of a user of a head-mounted camera based\non the ego-centric video, audio, and inertial data it collects [...] The goal of this project is to develop\nnew techniques that integrate any and all cues to a user's emotional state into a continuous, real-time\nestimate of user affect.\" Applicants are reminded that this \u201cego-centric video data": "oes not include"}, {"title": "Distributed warfighting/lethality", "content": "In the years following the terrorist attacks of September 11, 2001 the focus of US military strategy\nshifted from superpower conflict to what critical scholars have designated as \u201ceverywhere war\u201d and\nthe increasing use of Special Operations Forces (Chamayou 2014; Masco 2014). The turn to Special\nOperations and a program of continuous, distributed counterinsurgency is accompanied now by the\nrevival of competition for military dominance, framed as a new arms race between the US and China.\nBoth developments support a shift from a traditional focus on maneuvers at \u201cthe front\u201d to operations\nconducted \u201con the edge,\u201d which in turn require new modes of \u201ccommand and control\u201d across forces.\nConjoined with the aspiration to greater distribution of command and control is a growing concern for\nintegration across the longstanding divisions between the various armed forces, intensified by the\nincreasing expansion of all forces into multiple 'domains' of warfighting (air, land, sea, space, and\ncyber), imagined in the vision of Joint All Domain Command and Control (JADC2) as a set of\ninterlocking and interoperable \u2018systems' (U.S.Department of Defense 2022a).\nConsonant with these developments, a June 2017 BAA from DARPA's Tactical Technology Office\n(TTO) titled 'Innovative Systems for Military Missions' (#32) calls for demonstrations and research\nprograms aimed at \u201ccross domain systems\" that \"validate revolutionary precision engagement\ncapabilities.", "the development of persistent,\nglobal surveillance architectures; real-time data updates, at scale; provision of real-time, decision\nquality information; and the demonstration of novel approaches that support rapid and affordable\nintegration,": "ith a focus on the deployment of \u201cswarm technologies.\u201d Two years later, in March 2019,\nthe aspiration to command and control \u201cat the edge", "new datasets in the field.\" (#33) A joint effort with the National Science\nFoundation (NSF), the aim is the \u201crapid development of energy efficient hardware and ML\narchitectures that can learn from a continuous stream of new data in real time.\"\nIn a February 2019 BAA, DARPA's Strategic Technology Office (STO) goes directly to the point, stating\nthat the STO \u201cis seeking innovative ideas and disruptive technologies that provide the U.S. military\nincreased lethality in an era of eroding dominance.": 34, "challenged by peer\ncompetitors.\" The response must be a \u201cnew paradigm that values \u2018lethality' over monolithic system\ndominance. Whereas dominance is measured by comparing capabilities across systems, lethality is\nmeasured by the ability to deliver a desired effect at will, regardless of the system or systems of\nsystems involved.": "his lethality is to be delivered through \u2018Mosaic Warfare', enabling \u201cfast, scalable,\nadaptive joint multi-domain lethality. It is the disaggregation of effects chain functions (e.g., Find, Fix,\nTarget, Track, Engage, and Assess or F2T2EA) across a heterogeneous mix of manned and unmanned\nplatforms from all domains.\u201d A BAA in October 2021 from the STO on Mosaic Warfare continues the\nprogram (#35), with an emphasis on the achievement of a \"disaggregation of capabilities and\nre-composition of adaptable effects chains at mission speed.\u201d In military doctrine the most prominent\n\u201ceffects chain\u201d is a successful \u201ckill chain,\u201d a sequence of intelligence analyses and decisions leading up\nto a potential strike, in a process promoted as an appropriate application of AI-enabled optimization."}, {"title": "Conclusion: Al research and militarism", "content": "Our examination of a selection of documents from the U.S. Department of Defense grant solicitation\ncorpus is aimed at tracing how requests for proposed research help to secure the institutional relations\nthat form the military-academic complex. Our characterization of those relations as a form of mutual\nenlistment is meant to emphasize the two-way traffic through which technopolitical imaginaries are\nformed out of shared interests in the promotion of research agendas that, however loosely coupled, are\npositioned as serving U.S. national security interests. We have argued that rather than delineating two\nseparable arenas of research and development, the distinction of \u201cbasic\u201d and \u201capplied\" effects a\ntrading zone in which research and development can be steered in the direction of military\nimaginaries of future warfighting, which in turn are shaped by promises advanced within academic\nand commercial research and development networks. The trope of basic research in this context offers\nshelter from engagement with moral questions raised by military applications, while obscuring the\nconnections that implicate researchers in the wider complex of U.S. militarism. A time series analysis\nof programs framed as basic research illustrates the rhetorical moves through which the results of\nprevious investment are affirmed, at the same time that new problems requiring further investment\nare identified. And, an indicative analysis of a subset of DARPA calls focused specifically on AI's\npromise for the battlefield highlights DoD imaginaries of technological solutions to longstanding\nproblems, refigured and arguably exacerbated by previous investments in data-driven warfighting.\""}, {"title": "", "content": "Within the US Department of Defense and wider national security establishment the premise that\n\"[t", "Department of\nDefense, the defense industrial base and the array of private sector and academic enterprises that\ncreate and sharpen the Joint Force's technological edge": "U.S. Department of Defense 2022b). As\nPentagon expert William Hartung (2024) observes, taken together this comprises \u201ca military conquest\n(so to speak) of America's research and security agendas.\u201d Recent media coverage of the incorporation\nof computer vision systems into the control of armed drones in Ukraine, and of ML systems into target\ngeneration in Gaza, along with pronouncements about the threat of China's investments in AI,\nreinforce the premise that an Al arms race is inevitable and that the acceleration of AI-enabled\nwarfighting must be a DoD priority. Alex Karp, CEO of military contractor Palantir (and clearly an\ninterested actor), has declared that AI-enabled warfare and autonomous weapons systems have\nreached their \u201cOppenheimer moment.\u201d It is perhaps appropriate, then, to remember the legacy of\nnuclear weapons development, including the emergence of scientific fora dedicated to nuclear arms\ncontrol and disarmament (Hartung 2024).\nOur aim in this analysis is less to attribute intent to actors within the DoD's research funding agencies\nor in the academy, than to trace the circuits through which obstacles to military dominance are\nformulated as problems for which the AI research community can offer solutions. Academic research\nis considered an integral part of the \u201cDoD Innovation Ecosystem,\u201d currently itself the target of highly\npublicized initiatives to re-engineer its operations in ways aimed at facilitating returns on DoD R&D\ninvestments in data-driven, AI-enabled warfighting. Grant solicitations are a key site for the\narticulation of intersecting interests that not only inform, but are in important respects constituted\nthrough, resulting networks and relations. This mutual enlistment is crucial to the perpetuation of the\nmilitary-"}]}