{"title": "Developing an Algorithm Selector for Green Configuration in Scheduling Problems", "authors": ["Carlos March", "Christian P\u00e9rez", "Miguel Salido"], "abstract": "The Job Shop Scheduling Problem (JSP) is central to operations research, primarily optimizing energy efficiency due to its profound environmental and economic implications. Efficient scheduling enhances production metrics and mitigates energy consumption, thus effectively balancing productivity and sustainability objectives. Given the intricate and diverse nature of JSP instances, along with the array of algorithms developed to tackle these challenges, an intelligent algorithm selection tool becomes paramount. This paper introduces a framework designed to identify key problem features that characterize its complexity and guide the selection of suitable algorithms. Leveraging machine learning techniques, particularly XGBoost, the framework recommends optimal solvers such as GUROBI, CPLEX, and GECODE for efficient JSP scheduling. GUROBI excels with smaller instances, while GECODE demonstrates robust scalability for complex scenarios. The proposed algorithm selector achieves an accuracy of 84.51% in recommending the best algorithm for solving new JSP instances, highlighting its efficacy in algorithm selection. By refining feature extraction methodologies, the framework aims to broaden its applicability across diverse JSP scenarios, thereby advancing efficiency and sustainability in manufacturing logistics.", "sections": [{"title": "1. Introduction", "content": "The Job Shop Scheduling Problem (JSP) is a cornerstone issue in operations research and optimization, serving as a critical benchmark for assessing the performance of various algorithms. JSP entails the complex task of scheduling jobs on machines in a manufacturing environment to optimize several performance metrics, such as makespan, flow time, tardiness, resource utilization, and energy consumption [1]. Effective benchmarking of JSP solutions requires a multi-faceted evaluation of these metrics, particularly focusing on makespan, energy consumption, and tardiness to gauge scheduling efficiency and resource utilization [2]. Tools like JSPLIB play a vital role in these benchmarking efforts by providing researchers with diverse instances derived from significant studies and experiments, thereby enhancing the evaluation of algorithms [3].\nUnderstanding the characteristics of problem instances is essential for effective benchmarking in JSP. Critical factors include the number of jobs and machines, variability in processing times, machine availability, and precedence relationships, all of which significantly impact algorithm performance [4]. Additionally, considering energy consumption, which varies based on machine speed and operational factors, adds another layer of complexity [5]. Achieving a balance between energy consumption and scheduling decisions is crucial for attaining energy efficiency without compromising production goals [6].\nJSP's focus on energy efficiency has intensified in recent years due to its substantial environmental and economic impacts [7]. Researchers have investigated strategies such as employing speed-adjustable machines and vehicles to minimize energy consumption while maintaining productivity [8]. Advanced algorithms and optimization techniques have been developed to address these energy-related challenges, taking into account factors like machine speed, idle time, and energy requirements [9]. Real-world implementations of these strategies have demonstrated tangible benefits, including cost savings and positive environmental effects [10].\nIn addition to traditional optimization methods, machine learning techniques are increasingly being utilized to recommend algorithms for solving problems within the JSP family. For instance, M\u00fcller et al. designed a system capable of selecting the most suitable solver for addressing Flexible JSP by leveraging machine learning approaches [11]. Similarly, Strassl and Musliu [12] analyzed JSP instances without energy consumption from the literature to extract features that inform algorithm performance, resulting in a homogeneous set of instances with consistent characteristics. These features were then used to train various models, with Random Forest achieving the highest accuracy at 90% [12].\nIn conclusion, the integration of machine learning techniques into JSP research provides new avenues for improving algorithm selection and performance, particularly in handling complex and varied instances. This integration enhances the efficiency and effectiveness of job shop scheduling by combining the strengths of traditional optimization approaches with innovative machine learning methods. The ongoing advancements in this field are driving both academic research and practical applications toward more sustainable and innovative solutions."}, {"title": "2. Problem Description and Model Formulation", "content": "The JSP tackled in this study emphasizes its intricate energy considerations. The JSP poses a significant computational challenge, being NP-complete due to its difficulty finding optimal solutions within reasonable time frames. The core challenge of the JSP involves optimizing task allocation across multiple jobs and machines while minimizing key criteria, notably the total job completion time. However, achieving this optimization is complex due to various real-world constraints and dependencies, contributing to the JSP's NP-completeness. The combinatorial explosion of possible job and machine combinations further complicates the problem, making exhaustive exploration impractical as the number of jobs and machines grows."}, {"title": "2.1. Mixed Integer Programming", "content": "The JSP involves various sets, parameters, variables, and constraints crucial for formulation and solution:\nSets:\nVariables:\n\\$^* = arg min [MK(\\varphi), EC(\\varphi),TT(\\varphi)] \\\\\n\nsubject to:\n$\\sum_{m \\in M}Xmjts = 1$\nVj\\in J, Vt \\in T; Vs \\in S\n$\\sum_{MEM} Ymijpq = 1$\nVi, j\\in J, Vp, q \\in Ti, Tj, i \u2260 j, p\u2264 q\nttmjt \u2265 Cmjt \u2212 Djt\nVm\u2208 M, Vj\u2208 J,\nVt \u2208 Tj, Xmjt = 1\nCmjt\u2265Rjt+Pmjts\nVmE M, Vj \u2208 J,\nVt e Tj, Vs \u2208 S, Xmjts = 1\nCmjs\u2265 Cmip + Pmips\nVm\u2208 M, Vi, j\u2208 J,\nVp, q \u2208 Ti, Tj, Vs \u2208 S,\ni\u2260j>p<qYmijps = 1\nCmjt\u22650, tmjt \u2265 0\nVm\u2208 M, Vj\u2208 JVt \u2208 T;"}, {"title": "2.2. Mono-objective optimization", "content": "This section presents the mono-objective optimization for a specific scheduling problem involving multiple jobs and machines, emphasizing key performance metrics such as makespan, energy consumption, and total tardiness.\n$fm = max(cjm)$\n$JEJ\nMEM$\n$fe = \\sum\\sum Ejt$\n$JEJ TET;$\n$ftt = \\sum\\sum\\sum ttmjt$\n$MEM JEJ TET;$\nEquation 8 represents the makespan, which is the maximum completion time among all machines, by calculating the total processing time of all job tasks on each machine and selecting the maximum value across all machines. Equation 9 describes energy consumption by computing the total energy consumed by all job tasks across all machines. Lastly, Equation 10 is formulated to show the total tardiness, which represents the number of time units of each job or operation that are performed outside its time window, i.e., the period of time between the release date and the due date.\nmin $fm$ $/$ $m+$ + $fe/m\u2082 + ftt/$m+$\nMinimizing the objective Function 11 aims to find a solution that achieves a balanced trade-off among the components. The values m1,2 and m\u012b,2 are used to normalize the $* solution obtained in the three-dimensional objective space. This allows a correct comparison between the values of the objective function in minimizing the problem, giving the same weight to all the parts, and avoiding any of the variables dominating the search.\nm+ = $\\sum$(max(Pjms))\n$JEJ MEM$\n$m\u00b2 = \\sum$(max(Ejms))\n$MEM JEJ\nm\u2081 = max($\\sum$ min(Pjms))\n$JEJ\nSES\nMEM\nm\u2082 = $\\sum$(min(Ejms))\n$SES\nMEM JEJ\nEquations between 12 and 15 determine both maximum (m+ and m\u2082) and minimum (m\u012b and m\u2082) values for makespan and energy consumption respectively. For makespan, these values signify the maximum and minimum completion times across all machines, accounting for the maximum and minimum processing times of job tasks on each machine. Similarly, in terms of energy consumption, they represent the maximum and minimum energy utilized among all machines, considering the maximum and minimum energy consumption of all job tasks on each machine."}, {"title": "3. Algorithm Selector", "content": "The selection of algorithms for a given problem JSP involves identifying the most appropriate algorithm from a collection capable of solving JSP, taking into account the specific characteristics of JSP. Rubinoff [13] formalized this process of algorithm selection. Rubinoff defined key elements, including the problem space X, representing all instances of JSP; the algorithm space A, encompassing algorithms capable of solving any jsp \u2208 X; and a performance metric y, which quantifies algorithm effectiveness for solving jsp \u2208 \u03a7.\nThe core objective is to establish a function S:X \u2192 A that, for each problem instance jsp \u2208 X, selects the optimal algorithm from A based on metric y. To effectively characterize each jsp, a feature set F is constructed to represent p and assist in the decision-making process for S. Consequently, S is defined as a composite function S = TG, where G : X \u2192 RF maps p to its feature vector in RF, and T : RF \u2192 A selects the algorithm from A based on this feature representation. The choice of F is critical as it must be informative and accurately represent the characteristics of JSP.\nConsidering the modeling of algorithm selectors in Figure 1, an algorithm selector structure is proposed, where it can be seen that it is composed of a training phase, in which the features of a set of instances are processed to generate a set of data and are solved using three solvers: GECODE, CPLEX, and GUROBI. Once the instances have been solved, the extracted features are related to the best algorithm that has solved that instance, and different machine learning models are trained in order to validate which is the one that obtains the best accuracy and thus use it to recommend future instances. The following subsections detail each of the training processes."}, {"title": "3.1. Feature processing", "content": "For each instance, we extract the typical characteristics of a JSP (Job Shop Scheduling) problem, such as the number of jobs J, the number of machines M, the type of Release date, and Due date constraint Rd/Dd, and the number of speeds |S|. Additionally, we extract other features that are obtained in a less direct manner and aim to be as informative as possible about the complexity of the instance they represent. The extra features extracted are:\nmax(P)\nmean(P)\nmin(P)\nThe maximum processing time (16) represents the longest time required to complete any single operation within the job set. The mean processing time (Equation 17) gives the average duration of the operations, providing an overall sense of the job length. The minimum processing time (Equation 18) shows the shortest time needed for any operation, indicating the fastest job segment.\nmax(E)\nmean(E)\nmin(E)\nThe maximum energy consumption (Equation 19) indicates the highest energy required for any single operation. The mean energy consumption (Equation 20) provides the average energy used across all operations, reflecting the overall energy profile. The minimum energy consumption (Equation 21) shows the lowest energy usage for an operation, highlighting the least energy-intensive job segment.\n$\\sum$($\\sum$$SES$\\sum max(Pjms)\nJEJ MEM\n))\nMaximum makespan (Equation 22) represents the maximum makespan of the instance obtained, assuming that all operations are performed serially with their maximum processing time. This value gives the longest possible duration to complete all jobs, assuming no parallel processing.\nmax(min(Pyma))\nMEM\nSES\nMinimum makespan (Equation 23) represents the makespan of the solution obtained by considering that the operations can be performed in parallel and do not overlap. This makespan represents a lower bound of the possible makespan in a solution, indicating the shortest time to complete all jobs if perfectly parallelized.\n-1\n$\\sum$ max(0, min (Ddj1, Ddj2) - max(Rdj1, Rd.j2))\n11,12 EJ\nDdj1 - Rdj1\nJ(J-1)\n$\\sum$\\sum max(0, min(Ddj1m, Ddj2m) - max(Rdj1m, Rdj2m))\n11,12EJ MEM\nDdj1m - Rdj1m\n|J|.(J-1).|M|\n$\\sum$\\sum max(Ejms)\nMEM\nJEJ\n$\\sum$min(Ejms)\nMEM\nJEJ\n$\\sum max(Pjms)\njEJ MEM\n-1\nDdj - Rdj\n$\\sum$Pim\n|J|\n$\\sum$\\sum Dd.jm - Rdjm\nPjm\nJEJ MEM\nJ-M\nOverlap (Equation 28) represents the degree of overlap between the time windows of the jobs or operations. This metric assesses how much the scheduling windows for different jobs or operations coincide, which impacts the complexity and difficulty of scheduling."}, {"title": "3.2. Machine Learning Models", "content": "Once the instances have been vectorized and solved, a tabular data set is constructed with the characteristics of each instance and the solver that has found the best solution, that is, the one that has obtained the lowest value of the objective function.\nThis dataset has been separated into two subsets, a training subset with a size of 80% and a test subset with the remaining 20%. In addition, it has been ensured that the same number in proportion of instances exists in the two subsets.\nThe training dataset has been used to validate different models using five-fold cross-validation. The validated models are the following:\n\u2022 Logistic Regression: This is a statistical method for analyzing a dataset in which one or more independent variables determine an outcome. The outcome is measured with a dichotomous variable (i.e., two possible outcomes). Logistic regression is particularly useful for binary classification problems and provides insights into the relationships between the variables and the probability of the outcomes.\n\u2022 Decision Tree: This is a decision support tool that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. A decision tree is built by splitting the dataset into subsets based on the value of input features, with the goal of making the most informative splits. This method is easy to interpret and visualize, making it useful for understanding the structure of the data.\n\u2022 Gaussian Naive Bayes: This is a probabilistic classifier based on Bayes' theorem, with the assumption that the features are independent given the class label and that they follow a Gaussian distribution. Despite its simplicity, Gaussian Naive Bayes can perform well in various situations, especially when the assumption of independence roughly holds true.\n\u2022 K-Nearest Neighbors (KNN): This is a non-parametric method used for classification and regression. For classification, the input consists of the k closest training examples in the feature space, and the output is a class membership. The object is assigned to the class most common among its k nearest neighbors.\n\u2022 Random Forest: This is an ensemble learning method for classification and regression that constructs multiple decision trees during training and outputs the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random forests improve the predictive accuracy and control over-fitting by averaging multiple trees, reducing the model's variance.\n\u2022 XGBoost [14]: This is an optimized distributed gradient boosting library designed to be highly efficient, flexible, and portable. It implements machine learning algorithms under the gradient boosting framework, which builds models in a stage-wise fashion and generalizes them by optimizing for a differentiable loss function. XGBoost is known for its speed and performance, making it a popular choice for structured/tabular data.\n\u2022 Multi-Layer Perceptron (MLP): This is a class of feedforward artificial neural networks that consist of at least three layers of nodes: an input layer, a hidden layer, and an output layer. Except for the input nodes, each node (or neuron) uses a nonlinear activation function. MLPs are capable of learning complex mappings from inputs to outputs and are trained using backpropagation."}, {"title": "4. Evaluation", "content": "All experiments were conducted on a system equipped with an Intel 3.60 GHz 12th generation Core i7 CPU and 64 GB of RAM. The implementation was developed in Python 3.11. Well-known solvers such as GUROBI [15], CPLEX [16], and GECODE [17], which are implemented on Minizinc, were utilized.\nTo evaluate the quality of the solutions obtained, the mono-objective function shown in Equation 11 is used to compare the best solutions from the solvers. Other important results, such as the average objective function, solving time, optimum, satisfaction rate, and the number of unsolved solutions, are presented above."}, {"title": "4.1. Instances", "content": "Instance creation is one of the most important aspects of evaluation as it allows a specific number of instances to be configured to ensure the most comprehensive evaluation possible, taking into account all possible combinations the problem may encounter in real-life scenarios.\nThe JSP Benchmark used for testing is composed of the number of jobs (J) and machines (M) to determine each job's tasks. These variables can take any natural number. In this test set, the set {5, 10, 20, 25, 50, 100} is considered for J. The release and due date can take values {0,1,2}, speed scaling can take values {1,3,5}, and statistical distributions considered are uniform, normal, exponential}. For each configuration, 10 instances are generated with different seeds to ensure substantial variation between them. Therefore, a total of 6(J) \u00d7 6(M) \u00d7 3(rddd) \u00d7 3(ss) \u00d7 3(dist) \u00d7 10(Q) = 9720 instances are obtained.\nThe time allocated for resolving each instance depends on the specific characteristics of the problem. An example of this allocation is illustrated in Figure 2. In this example, an instance with 50 jobs, 10 machines, no Release Date or Due Date, and a single speed per machine is allocated 149 seconds. The principle is that if the maximum allocation time for an instance is 300,000 milliseconds, each characteristic's impact on the allocation should be equivalent. Therefore, each characteristic contributes at most 300, 000/4 = 75, 000 milliseconds. In this manner, for the given example, if the Release Date and Due Date are assigned at the operation level (RDDD = 2), they contribute 75,000 milliseconds. If they are absent (RDDD = 0), they contribute 50 milliseconds. When assigned at the"}, {"title": "4.2. Results", "content": "Upon defining the problem instances and setting appropriate search time limits for each solver, the focus shifted toward analyzing and interpreting the outcomes. This involved evaluating the efficacy of the solvers employed, assessing solution quality, and considering the broader implications within the problem domain.\nFigure 3 illustrates the distribution of solved instances among GUROBI, CPLEX, and GECODE across three categories: optimal (best solution), satisfied (feasible but not optimal), and unresolved (not solved).\nGUROBI emerged as the top performer overall, solving the highest number of optimal solutions and consistently demonstrating its ability to find acceptable solutions even when optimal ones were unfeasible. This underscores GUROBI's robust capability in efficiently managing a diverse array of problem types. Conversely, GECODE excelled in finding feasible solutions, significantly outperforming other solvers in achieving satisfactory solutions. Moreover, GECODE showed the fewest instances left unresolved, highlighting its reliability in tackling complex problems without abandoning them.\nIn contrast, CPLEX, while proficient, faced challenges with more complex problem instances, leading to a higher incidence of unresolved cases. Although it achieved reasonable numbers of optimal and satisfactory solutions, its performance consistency was observed to be less reliable compared to GUROBI and GECODE.\nTable 1 compares solution times and objective function values from GUROBI, CPLEX, and GECODE across different job and machine configurations. This analysis reveals insights into each solver's performance characteristics, highlighting strengths and limitations in solving optimization problems.\nFor 5 to 20 jobs, GUROBI consistently shows shorter solution times and competitive objective values compared to CPLEX and GECODE. Its efficiency and precision make it highly effective in simpler problem instances.\nIn medium-sized scenarios (20 to 50 jobs), GUROBI maintains an edge, particularly with fewer machines, though CPLEX occasionally performs better in specific configurations. GUROBI generally achieves superior objective function values in varied problem setups.\nIn complex cases (50 to 100 jobs), GECODE demonstrates exceptional scalability despite encountering timeouts in some instances. GUROBI and CPLEX struggle more often with timeouts as problem size and complexity increase, yet GUROBI often maintains competitive objective values.\nThese insights underscore the importance of selecting solvers based on problem specifics. GUROBI excels in smaller to medium-sized instances, balancing efficiency and high-quality solutions. CPLEX performs well in certain medium-sized setups but faces scalability challenges. GECODE shines in complex problems, offering robust scalability and reliability despite occasional computational hurdles. These findings aid practitioners in optimizing solver choices and considering trade-offs between solution quality, efficiency, and problem complexity."}, {"title": "4.3. Complexity analysis", "content": "Observing the results obtained by the methods used, a relationship is observed between the parameters employed and the complexity of the instances. This part of the study focuses on the in-depth analysis of each parameter to observe its contribution to the overall complexity of the instances.\nTo delve deeper into the data presented in Table 1, Figure 4 provides a general overview of the number of solved instances. Organizing the data by the number of machines, as shown in subfigure 4a, it is evident that as the number of machines increases, the number of solved instances progressively decreases except for the case of 5 machines, where all instances are solved for all possible job configurations. Looking at subfigure 4b, which is organized by the number of jobs for all possible machine configurations, it can be seen that all instances are solved for 5 and 10 jobs, but there is a notable decrease for the rest. Focusing on the set of 20 and 25 jobs, it can be observed that there is a slight decrease from 25 machines onwards; later, the reasons for this are analyzed. For instances with 50 and 100 jobs, the decrease in the number of solved instances is exponential. Only all instances are solved for a configuration of 5 machines for 100 jobs and 5 and 10 machines for 50 jobs. This figure illustrates how the number of jobs and machines affects the possibility of obtaining a solution to the problem at hand."}, {"title": "4.4. Algorithm selector results", "content": "Table 2 shows the validation results of the tested models. As can be seen, XGBoost is the model with the best validation accuracy. Training this model with the total training data set and testing it with the test set finally yields an accuracy of 84.51%. This indicates that XGBoost performs well during the validation phase and generalizes effectively to unseen data. The high accuracy suggests that XGBoost's ensemble learning approach, which combines multiple decision trees to improve performance, is particularly well-suited to this dataset. Moreover, the performance difference between XGBoost and other models like Random Forest and MLP, which also showed strong results,\nThe confusion matrix in Figure 5 presents the algorithm selector's classification results. Each cell value represents the number of instances where the algorithm selector predicted the algorithm in the corresponding column for a problem best solved by the algorithm in the corresponding row. For instance, the selector correctly identified GUROBI for 611 out of the total instances where GUROBI was the best choice. Similarly, GECODE was correctly identified 396 times. However, there are misclassifications, such as predicting GUROBI when CPLEX was optimal, which occurred 70 times.\nAn in-depth analysis of the precision and recall metrics provides further insights into the performance of the algorithm selector. GECODE achieved a precision of 90.20%, indicating that 90.20% of the instances predicted as GECODE were correctly identified. Its recall was 86.84%, signifying that 86.84% of the actual GECODE instances were correctly detected. This high precision and recall demonstrate the algorithm selector's robustness in identifying GECODE instances accurately.\nOn the other hand, CPLEX showed a precision of 62.76%, meaning that only 62.76% of the predictions for CPLEX were accurate, and a recall of 73.75%, which indicates that 73.75% of the actual CPLEX instances were correctly classified. The lower precision for CPLEX suggests a higher rate of false positives, which could imply that the algorithm selector often misclassifies other algorithms as CPLEX.\nFor GUROBI, the precision was 89.85%, reflecting that 89.85% of the GUROBI predictions were correct, and the recall was 86.66%, meaning that 86.66% of the actual GUROBI instances were identified correctly. These values indicate a strong performance, similar to GECODE, highlighting the selector's efficiency in recognizing GUROBI accurately.\nThese metrics, precision, and recall, are crucial for evaluating the algorithm selector's effectiveness, as they provide a more comprehensive understanding of its performance beyond simple accuracy. They highlight the selector's strengths in accurately identifying certain algorithms while also pointing out areas where misclassification occurs, thus providing a clear direction for further improvements."}, {"title": "5. Conclusions", "content": "This study explores the complexities of JSP, emphasizing its NP-completeness and diverse optimization goals such as makespan, energy consumption, and tardiness. The problem presents significant computational challenges due to its combinatorial nature, making timely optimal solutions crucial in operations research and manufacturing.\nAn innovative aspect of this research is integrating machine learning techniques to enhance algorithm selection for JSP instances. By extracting comprehensive features like job and machine characteristics, release dates, and energy requirements, models such as XGBoost and Random Forest were effectively trained. These models accurately recommend suitable solvers like GUROBI, CPLEX, and GECODE, streamlining decision-making for solving diverse and complex scheduling problems.\nGUROBI proved particularly efficient for smaller to medium-sized instances, consistently delivering optimal and satisfactory solutions across different configurations. Meanwhile, GECODE demonstrated robust scalability, excelling in complex scenarios despite occasional computational challenges. This analysis underscores the importance of selecting solvers based on specific problem parameters to optimize solution quality and computational efficiency.\nLooking ahead, the study suggests refining feature extraction methodologies to enhance the algorithm selector's accuracy across a broader range of JSP scenarios. Advancements in solver performance under varying constraints promise to expand the practical utility of scheduling optimization tools in real-world manufacturing settings, emphasizing efficiency and sustainability.\nAlthough the results obtained are not as high as those reported in the literature, it should be noted that the energy-aware JSP constitutes a more complex problem compared to the standard JSP and flexible JSP found in the literature. Furthermore, this study uses a smaller set of features than those used in other studies, yet the accuracy achieved is not significantly lower.\nIn conclusion, this work advances both academic understanding and practical applications by integrating traditional optimization techniques with modern machine-learning approaches. It offers tools that can significantly benefit research and industrial practices, addressing contemporary challenges in operations management and manufacturing logistics."}]}