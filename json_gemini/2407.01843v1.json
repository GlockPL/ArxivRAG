{"title": "My part is bigger than yours - assessment within a group\nof peers using the pairwise comparisons method", "authors": ["Konrad Ku\u0142akowski", "Jacek Szybowski"], "abstract": "A project (e.g. writing a collaborative research paper) is often a group effort. At\nthe end, each contributor identifies his or her contribution, often verbally. The\nreward, however, is quite often financial in nature. This leads to the question of\nwhat (percentage) share in the creation of the paper is due to individual authors.\nDifferent authors may have various opinions on the matter, and, even worse,\ntheir opinions may have different relevance. In this paper, we present a simple\nmodels that allows aggregation of experts' opinions linking the priority of his\npreference directly to the assessment made by other experts. In this approach,\nthe greater the contribution of a given expert, the greater the importance of\nhis opinion. The presented method can be considered as an attempt to find\nconsensus among a group of peers involved in the same project. Hence, its\napplications may go beyond the proposed study example of writing a scientific\npaper.", "sections": [{"title": "1. Introduction", "content": "From time to time, we observe behind-the-scenes discussions about which\nauthor in a scientific paper is the most relevant. The answers can vary. First,\nlast, correspondence, first three authors, it doesn't matter, etc. At its core, it\nis a question about the value of the contribution, the effort, the effort that an\nauthor has made to the paper. Very often, scientific journals try to help answer\nthis question by making it possible to determine the workload of a given author\nby describing descriptively what that author did. Such a description makes it\npossible, to some extent, to form an opinion about the significance of an au-\nthor's contribution.\nHowever, there are times when such a description is insufficient and a precise,\npercentage determination of \"contribution to the work\" for each author sepa-\nrately is necessary. This is the case when a certain amount of money is awarded\nfor the creation of a work to be distributed among the authors. In such a situa-\ntion, quite often the \"distribution of percentages\" is done on a dictatorial basis,\nwith the corresponding author playing the role of dictator. In a situation where\nthe authority of all authors is comparable, or worse, where the corresponding\nauthor is a less recognized researcher than some other researchers on the author\nlist, misunderstandings and irritations can easily arise. On the one hand, the\ncorrespondent (or lead) author should have the best knowledge of the other au-\nthors' contributions to the work. On the other hand, other authors of greater\nesteem can easily question his or her decisions.\nA way out of this somewhat uncomfortable situation may be to adopt arbitrary\nregulations for the distribution of the award. E.g. dividing the prize equally be-\ntween all participants, or setting rigid proportions between the prize for the first\nand subsequent authors. These types of solutions, unless they arouse personal\nanimosity between the authors, leave a certain feeling of injustice. The question\ntherefore arises as to whether a dictatorial approach on the one hand and the\nestablishment of a rigid framework for the distribution of the prize on the other\ncan be avoided. It seems to us that with a team of peers this is possible.\nIn this paper we propose an approach based on aggregating the opinions of\nindividual authors/experts using prioritization of opinions. Since team members\nwho were more involved in the project usually have a better understanding of\nthe project and the contribution of other team members to the work done we\npropose that prioritization should be related to the size of this contribution.\nIn this way, we avoid a situation where those whose participation is small or\nmarginal have the same share in the decision as those whose participation is\nsignificant. The latter, by virtue of their significant and large contribution, are\ngiven greater priority in determining the distribution of the award.\nIn doing so, we assume that the work took place in a team of peers i.e. that\nthere is no obvious dictator whose opinion everyone naturally aligns with, and,\nthat there is a real opportunity for the contribution of each team member to\nbe assessed by others. The absence of a dictator results in the need for team\ndecisions on the distribution of the prize. The possibility of mutual evaluation,\non the other hand, enables group decision-making. This is the case, for example,\nwhen a team of researchers of similar experience and reputation work together\non a project having from time to time stand-up meetings where the progress of\nthe work is discussed.\nThe problem outlined above does not only apply to the creation of scientific\narticles. A similar situation occurs with the distribution of awards for various\nother team achievements, such as grants, organizational projects or software\nprojects in IT companies.\nThe solution proposed in this paper is based on the aggregation procedure"}, {"title": "2. Preliminaries", "content": "Many methods including AHP, HRE, MACBETH, BWM, outranking meth-\nods like e.g. PROMETHEE [25, 20] and various hybrid solutions use pairwise\ncomparisons (PC) as a source of information about decision makers' preferences.\nThe approach has its extensions to cover different data representations includ-\ning intervals [21], fuzzy numbers [23] or grey numbers [15]. The best-known\nmethod based on pairwise comparisons of alternatives is AHP. It is also the\nmost criticized, although the criticism is often constructive and leads to many\nimprovements and extensions of the original proposal. Of the more important\nareas of improvement, it is worth mentioning: methods for calculating the vector\nof weights [22] including calculating rankings for incomplete matrices [6, 7, 24],\nmethods for measuring inconsistencies [8] and others. An interesting critical\nanalysis of the AHP method can be found in Munier and Hontoria [30].\nIn the PC method, experts, also known as decision-makers, compare al-\nternatives in pairs. Let $A = \\{a_1,...,a_n\\}$ be finite set of alternatives and\n$E = \\{e_1,...,e_k\\}$ be a set of experts. Each expert compares the alternatives\nwith each other to form a set of comparisons represented in the form of a square\nmatrix $C_q = \\{c_{ij}^q \\in R^+ : i,j = 1,...,n\\}$ where $1 \\leq q \\leq k$, and q indicates\nthe number of expert. A single $c_{ij}^q$ denotes the relative importance of the i-th\nalternative compared to the j-th alternative according to the experts opinion $e_q$.\nFor the sake of legibility of notation, whenever possible we will omit the expert\nindex q by writing the PC matrix as $C = [c_{ij}]$. PC matrix is used to synthesize\na vector of weights. Let us define the function resulting from this calculation."}, {"title": "2.1. Pairwise comparisons", "content": "Many methods including AHP, HRE, MACBETH, BWM, outranking meth-\nods like e.g. PROMETHEE [25, 20] and various hybrid solutions use pairwise\ncomparisons (PC) as a source of information about decision makers' preferences.\nThe approach has its extensions to cover different data representations includ-\ning intervals [21], fuzzy numbers [23] or grey numbers [15]. The best-known\nmethod based on pairwise comparisons of alternatives is AHP. It is also the\nmost criticized, although the criticism is often constructive and leads to many\nimprovements and extensions of the original proposal. Of the more important\nareas of improvement, it is worth mentioning: methods for calculating the vector\nof weights [22] including calculating rankings for incomplete matrices [6, 7, 24],\nmethods for measuring inconsistencies [8] and others. An interesting critical\nanalysis of the AHP method can be found in Munier and Hontoria [30].\nIn the PC method, experts, also known as decision-makers, compare al-\nternatives in pairs. Let $A = \\{a_1,...,a_n\\}$ be finite set of alternatives and\n$E = \\{e_1,...,e_k\\}$ be a set of experts. Each expert compares the alternatives\nwith each other to form a set of comparisons represented in the form of a square\nmatrix $C_q = \\{c_{ij}^q \\in R^+ : i,j = 1,...,n\\}$ where $1 \\leq q \\leq k$, and q indicates\nthe number of expert. A single $c_{ij}^q$ denotes the relative importance of the i-th\nalternative compared to the j-th alternative according to the experts opinion $e_q$.\nFor the sake of legibility of notation, whenever possible we will omit the expert\nindex q by writing the PC matrix as $C = [c_{ij}]$. PC matrix is used to synthesize\na vector of weights. Let us define the function resulting from this calculation."}, {"title": "Definition 1.", "content": "Let A be a set of alternatives. The priority function for A is the\nmapping $w: A \\rightarrow R_+$ assigning a real and positive number to each alternative.\nThe priority vector for A resulting from $C_q$ takes the form:\n$w_q = [w_q(a_1), ..., w_q(a_n)].\\qquad(1)$\nMany methods have been described in the literature to calculate the value of\npriority vector w. The first and so far quite popular is the eigenvalue method"}, {"title": "2.2 Group decision-making", "content": "(EVM). This approach was proposed by Saaty in his seminal paper [33], and\nconsists in calculating a principal eigenvector, and then normalizing it so that\nthe sum of entries is one. Another method is based on calculating the geometric\nmeans of the matrix rows and taking the result of the i-th row as the priority\nof the i-th alternative [12]. The result, thus, obtained is also subject to normal-\nization at the end of the calculation. In addition to the two mentioned, there\nare quite a few other methods for calculating the priority vector. A comparison\nof the performance of the six popular priority deriving methods can be found\nin [37]. Another overview of prioritization methods can be found in [9]."}, {"title": "2.2.1. Aggregation procedures", "content": "When more than one expert participates in the decision-making process,\ntheir opinions need to be aggregated. As with a single PC matrix, the end\nresult should be a vector of weights assigning real numbers to each alternative.\nAggregation of expert opinions can be done both at the level of individual com-\nparisons and at the level of individual weight vectors. An example of the first\napproach can be the AIJ (aggregating of individual judgments) [17] procedure,\naccording to which each comparison of the i-th and j-th alternatives by each of\nk experts is averaged and then a vector of weights is calculated for the matrix\ncomposed of such averaged values. In addition to AIJ, there are a number of op-\ntimization methods that directly use comparison results from different experts.\nThe previously mentioned model based on minimization of group Euclidean dis-\ntance (GED) values [5] can serve as an example. A different approach is the\nAIP procedure according to which priority vectors for individual experts are\ncalculated first and only then are the results aggregated. Compared to AIJ, the\nAIP approach has several significant advantages. The second does not impose\nthe need for a group of experts to act as a unit, leaving them more freedom to\nmake individual judgments [17]. It can be easily implemented in the situation\nof having incomplete data from different experts. In such a case, it is enough\nto use appropriate prioritization methods for incomplete PC matrices [6, 24] to\ncalculate individual weight vectors. The weight vectors obtained in this way\nmay then be subjected to aggregation. In addition, AIP satisfies the Pareto\nprinciple with an arithmetic or geometric mean [17].\nAggregation procedures allow each expert's opinion to be assigned different\nstrengths (priorities). Thus, experts who are considered less competent can\nhave less influence on the final opinion, while experts who are more recognized\ncan have a greater impact on the final outcome. In the next two sections, we\nwill look at two variants of the AIP method that allow for assigning different\npriorities to individual experts."}, {"title": "2.2 Group decision-making", "content": "The most popular AIP approach is based on the use of a weighted geometric\nmean. Let the vector of weights calculated from the pairwise comparison matrix\n$C_q$ provided by the q-th expert be denoted as follows:\n$w_q =\\begin{cases}\nw_q(a_1)\\\\\nw_q(a_2)\\\\\n:\\\\\\nw_q(a_n)\n\\end{cases}\\qquad for q = 1,..., k. \\qquad(2)$\nThen, let $W$ be a matrix of weights vectors so that\n$W = (w_1,..., w_k)$,\ni.e.\n$W = \\begin{pmatrix}\nw_1(a_1) & w_2(a_1) & ... & w_k(a_1)\\\\\nw_1(a_2) & w_2(a_2) & ... & w_k(a_2)\\\\\n... & ... & ... & ...\\\\\\nw_1(a_n) & w_2(a_n) & ... & w_k(a_n)\n\\end{pmatrix} \\qquad(3)$\nand, let p be the vector of priorities for individual experts i.e.\n$p = \\begin{cases}\np_1\\\\\\np_2\\\\\\n:\\\\\\np_k\n\\end{cases} \\qquad(4)$\nso that $\\sum_{i=1}^{k} p_i = 1$. Then\n$GAIP(W, p) = \\begin{cases}\n\\prod_{i=1}^{k} w_i^{p_i}(a_1)\\\\\n\\prod_{i=1}^{k} w_i^{p_i}(a_2)\\\\\n:\\\\\\n\\prod_{i=1}^{k} w_i^{p_i}(a_n)\n\\end{cases} \\qquad(5)$\ndenotes AIP procedure using a weighted geometric mean, where W is the\nmatrix of priority vectors derived by individual experts and p is the vector of\npriorities of those experts."}, {"title": "2.3 Constrained global optimization", "content": "Ranking methods very often use optimization methods to determine the best\nvector of weights corresponding to the alternatives under consideration. If the\nformulated optimization problem is linear in nature then the Simplex algorithm\ncan be used and the problem is expressed using linear programming [38]. The\napproach has a rich literature and many extensions. Linear programming un-\nderlies many other methods and solutions. An example of a method that grew\nout of the idea of linear programming is Data Envelopment Analysis (DEA) [11].\nWhen the problem is nonlinear then, depending on the properties of the function\nunder analysis (e.g. convexity), other optimization techniques can be used. For\nthe purpose of testing the solution proposed in this paper we propose the three\nmost popular, well established, heuristic constrained global optimization tech-\nniques: Nelder-Mead method, Differential Evolution and Simulated Annealing.\nThe goal of each of the three algorithms is to find the minimum of some function\n$f: R \\rightarrow R$. Finding the minimum is equivalent to proposing the desired vector\nof weights.\nThe first of these, the Nelder-Mead method [31], is a direct search method\ni.e. in its search it does not take into account information, for example, about\nthe direction of the decreasing gradient. For function f, in every iteration the\nalgorithm keeps n + 1 points $x_1,x_2,...,x_{n+1}$ forming a polytope. The points\nare ordered so that $f(x_1) \\leq f(x_2) \\leq ... \\leq f(x_{n+1})$. Then, the centroid of the\nn worst points is generated, and the next point is generated by reflecting the\nworst point through the centroid. Depending on the quality of the generated\nsolution, the procedure can iteratively continue (other points may be selected,\nor other points removed) or end if the obtained solution is good enough.\nThe second method, Differential Evolution [40, p. 187], minimizes a func-\ntion using the genetic programming paradigm. The algorithm works with a\npopulation of m candidate solutions, denoted as $\\{x_1,x_2,...,x_j, ..., x_m\\}$, where\nusually m is much larger than the number of variables (denoted by n). During"}, {"title": "2.2.3. Additive profile aggregation", "content": "An alternative way to aggregate the resulting weight vectors is to use a\nweighted arithmetic mean. Let priority vector provided by q-th expert be $w_q$ (2),\nmatrix of priority vectors be given as $W$ (3) and the vector of expert priorities\nis p (4) so that so that $\\sum_{i=1}^{k} p_i = 1$. Then\n$AAIP(W, p) = \\begin{cases}\n\\sum_{i=1}^{k} p_i w_i(a_1)\\\\\n\\sum_{i=1}^{k} p_i w_i(a_2)\\\\\n:\\\\\\n\\sum_{i=1}^{k} p_i w_i(a_n)\n\\end{cases} \\qquad(6)$\ndenotes AIP procedure using a weighted arithmetic mean."}, {"title": "3. Peer ranking aggregation", "content": "The immediate inspiration to take up the topic of aggregation of opinions in a\ngroup of peers was the introduction of changes in the regulations for rewarding\nemployees of a certain university, according to which the reward depends on\nthe level of contribution of each author of a paper. Of course, this level must\nbe numerical (percentage) and allow for an unambiguous distribution of money\nbetween the parties involved. It must also be based on some compromise because\nall authors must sign a declaration in which they agree to the assigned share.\nIn practice, most teams deal with this problem by selecting one person who,"}, {"title": "3.2 Model", "content": "The above observations led us to propose a peer review model in a group of\npeers based on pairwise comparison of alternatives. Group members have a dual\nrole. They are simultaneously the object of comparison, i.e. the alternatives $A =$\n$\\{a_1,..., a_n\\}$ in the PC method, and the experts providing their judgments i.e.\n$E = \\{e_1, ..., e_n\\}$. Each of the experts, i.e. team members, provides comparisons\nin the form of a PC matrix $C = [c_{ij}]$, where $c_{ij} \\in R^+$ in which he assesses the\nrelative level of contribution of the other members of the group. Based on the\ncollected ratings $C_1,...,C_n$, vectors of weights $w_1,...,w_n$ for individual experts\nare created. The calculated vectors are then subjected to aggregation, resulting\nin the formation of a final priority vector\n$w = \\begin{cases}\nw(a_1)\\\\\n:\\\\\\nw(a_n)\n\\end{cases}$\nreflecting the share of each evaluated person in the award. However, in line with\nthe observation that those more involved in a project are often more competent\nto assess the engagement of others, the priorities given to expert opinions during\naggregation may not be identical. They must reflect this regularity. Let $p: A \\rightarrow$\n$R$ be an expert priority function such that for two experts $e_i$ and $e_j$ if their\nfinal evaluation share meets $w(a_i) \\geq w(a_j)$ then also their priorities during\nthe aggregation process meet $p(a_i) \\geq p(a_j)$. This regularity comes out of the\nobservation that the one who contributed more to the success than the other"}, {"title": "3.3 Multiplicative profile aggregation", "content": "When proceeding to aggregate the results, we assume that each team member\n$e_q \\in E$ provided a PC matrix $C_q$ based on which the ranking vector $w_q =$\n$(w_q(a_1),..., w_q(a_n))^T$ was calculated. These vectors form a matrix W of the\nform:\n$W = \\begin{pmatrix}\nw_1(a_1) & w_2(a_1) & ... & w_n(a_1)\\\\\nw_1(a_2) & w_2(a_2) & ... & w_n(a_2)\\\\\n... & ... & ... & ...\\\\\\nw_1(a_n) & w_2(a_n) & ... & w_n(a_n)\n\\end{pmatrix}$\nDenoting vector of experts' priorities as $p = (p(a_1), ...,p(a_n))^T$ we get an extra\ncondition that the final solution must satisfy:\n$GAIP(W, p) = \\begin{cases}\n\\prod_{i=1}^{k} w_i^{p(a_i)}(a_1)\\\\\n\\prod_{i=1}^{k} w_i^{p(a_i)}(a_2)\\\\\n:\\\\\\n\\prod_{i=1}^{k} w_i^{p(a_i)}(a_n)\n\\end{cases} \\qquad(7)$\nFor the purposes of the calculation, we will also want $p(a_i) > 0$ for $i = 1, . . ., n$\nand $\\sum_{i=1}^{n} p(a_i) = 1$. The introduction of (7) leads directly to the formulation\nof a nonlinear optimization problem in the form:\n$ming(W,p) s.t.$\n$g(W,p) = \\sum_{i=1}^{n} \\bigg(\\dfrac{\\sum_{j=1}^{n} w_j^{p(a_j)}(a_i)}{y_i} - \\gamma_i\\bigg)^2 \\qquad(8)$\n$\\gamma_i = \\dfrac{y_i}{\\sum_{j=1}^{n} y_j}$ and $p(a_i) > 0$ for $i = 1, . . ., n$.\nThe above (8) can be solved using constrained global optimization methods\n(Section 2.3).\nOne can also attempt to find the final vector of weights using a direct iter-"}, {"title": "3.4 Additive profile aggregation", "content": "The aggregation model outlined above (Section 3.3) in which experts' prior-\nity is linked to their ranking score naturally has an additive version. Thus, the"}, {"title": "3.5 Pareto principle", "content": "solution must satisfy an additional condition of the form:\n$AAIP(W, p) = \\begin{cases}\n\\sum_{i=1}^{k} p(a_i)w_i(a_1)\\\\\n\\sum_{i=1}^{k} p(a_i)w_i(a_2)\\\\\n:\\\\\\n\\sum_{i=1}^{k} p(a_i)w_i(a_n)\n\\end{cases} \\qquad(9)$\nAs before, we also assume that $p(a_i) > 0$ for $i = 1,...,n$ and $\\sum_{i=1}^{n} p(a_i) = 1$.\nThe optimization problem induced by condition (9) gets the form:\n$minh(W,p) s.t.$\n$h(W,p) = \\sum_{i=1}^{n} \\bigg(\\dfrac{\\sum_{j=1}^{n} p(a_j)w_j(a_i)}{\\gamma_i} - \\gamma_i\\bigg)^2 \\qquad(10)$\n$\\gamma_i = \\dfrac{y_i}{\\sum_{j=1}^{n} y_j}$ and $p(a_i) > 0$ for $i = 1, ..., n$.\nDIA algorithm itself undergoes a cosmetic change of replacing GAIP with AAIP\nin the lines 2 and 6."}, {"title": "Theorem 2.", "content": "Both modified aggregation methods GAIP and AAIP satisfy the\nPareto principle [3] i.e. if for any two alternatives i, j all experts prefer the i-th\nalternative over the j-th alternative i.e. $w_k(a_i) > w_k(a_j)$ for $k = 1,...,n$ then\nthis relationship holds in the aggregated vector of weights i.e. $w(a_i) > w(a_j)$.\nProof. Let GAIP and AAIP be as defined in (5) and (6) correspondingly. Then\n$||GAIP(W,p)|| =$\n$= \\sqrt{(w_1^{p(a_1)}(a_1) \\cdot \\cdot \\cdot w_k^{p(a_k)}(a_1))^2 + ... + (w_1^{p(a_1)}(a_n) \\cdot \\cdot \\cdot w_k^{p(a_k)}(a_n))^2 } <$\n$\\leq \\sqrt{(p_1w_1(a_1) + . . . + p_nw_n(a_1))^2 + . . . + (p_1w_1(a_n) + ... + p_nw_n(a_n))^2} =$\n$= ||AAIP(W, p)|| =$\n$= \\sqrt{ <p, w_1>^2 + . . . <p, w_n>^2 } \\leq \\sqrt{||p||^2||w_1||^2 + . . . + ||p||^2||w_n||^2 } =$\n$= ||p||\\sqrt{||w_1||^2 + ... + ||w_n||^2 } \\leq ||p||\\sqrt{n} \\leq \\sqrt{n}.$\nObviously, the mapping AAIP(W,\u00b7) is linear, so for each $p, p \\in R^n$\n$AAIP(W, p) \u2013 AAIP(W,\\hat{p}) = AAIP(W,p \u2013 \\hat{p}) < \\sqrt{n}||p-\\hat{p}||.$"}, {"title": "Notice that", "content": "Notice that for $p = (\\frac{1}{\\sqrt{n}},...,\\frac{1}{\\sqrt{n}})$ the norm\n$||p|| = \\frac{1}{\\sqrt{n}},$\nso\n$||GAIP(W,p)|| \\leq ||AAIP(W,p)|| \\leq 1.$\nOn the other hand, if for each i \u2208 {1, ..., n} we have\n$w_1(a_i) = w_2(a_i) = ... = w_n(a_i)$,\nthen for each j\u2208 {1, ..., n} and each p it follows that\n$GAIP(W,p) = AAIP(W,p) = (w_j(a_1), ..., w_j(a_n))^T$.\nNow fix i, j \u2208 {1,...,n}. Both mappings satisfy the Pareto principle, i.e.\nfor each p\u2208 R\" and for each k \u2208 {1, ..., n}\n$w_k(a_i) \\leq w_k(a_i) \\Rightarrow (w_k^{p_k}(a_i) < w_k^{p_k}(a_j)$ and $p_kw_k(a_i) \\leq p_kw_k(a_j))$,\nwhich implies that\n$w_1^{p_1}(a_i) \\cdot w_2^{p_2}(a_i) \\cdot \\cdot \\cdot w_n^{p_n}(a_i) < w_1^{p_1}(a_j) \\cdot w_2^{p_2}(a_j) \\cdot \\cdot \\cdot w_n^{p_n}(a_j)$\nand\n$p_1w_1(a_i) + p_2w_2(a_i) + \\cdot \\cdot \\cdot + p_nw_n(a_i) \\leq p_1w_1(a_j) + p_2w_2(a_j) + \\cdot \\cdot \\cdot + p_nw_n(a_j)$.\nThis means that if all the experts scored the i-th one equally or lower than\nthe j-th one, then the resulting ranking of the i-th expert cannot be higher than\nthe ranking of the j-th one."}, {"title": "4. Summary", "content": "In the work presented here, we proposed two new priority aggregation models\nfor group decision-making in the pairwise comparison method, in which experts'\npriorities are linked to the aggregation score. Both models satisfy the Pareto\nprinciple, according to which, for two alternatives, $a_i$ and $a_j$, if each group\nmember prefers $a_i$ to $a_j$, then the group must also prefer $a_i$ to $a_j$.\nThese models correspond to the situation in which the experts being eval-\nuated are the object of evaluation. A study example is determining the dis-\ntribution of a team achievement award. Such an achievement could be the\npreparation and publication of a scientific article. However, the presented ap-\nproach can have many other applications, such as the distribution of bonuses\namong team members for achieving milestones in an IT project.\nWe have also indicated methods for calculating the solution to the problem\ndescribed by such models. Very often, such a solution can be calculated using\nan iterative process. When this fails, global optimization methods such as the\nNelder-Mead method and others come to the rescue. In future research, we\nwill focus on the properties of the proposed models. In particular, we intend to\nresearch the safety and robustness of such models against manipulative behavior."}]}