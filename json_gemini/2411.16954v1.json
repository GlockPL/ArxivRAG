{"title": "Understanding GEMM Performance and Energy on NVIDIA Ada Lovelace: A Machine Learning-Based Analytical Approach", "authors": ["Xiaoteng (Frank) Liu", "Pavly Halim"], "abstract": "Analytical framework for predicting General Matrix Multiplication (GEMM) performance on modern GPUs, focusing on runtime, power consumption, and energy efficiency. Our study employs two approaches: a custom-implemented tiled matrix multiplication kernel for fundamental analysis, and NVIDIA'S CUTLASS library for comprehensive performance data collection across advanced configurations. Using the NVIDIA RTX 4070 as our experimental platform, we developed a Random Forest-based prediction model with multi-output regression capability. Through analysis of both naive tiled matrix multiplication with varying tile sizes (1 to 32) and 16,128 CUTLASS GEMM operations across diverse configurations, we identified critical performance patterns related to matrix dimensions, thread block configurations, and memory access patterns. Our framework achieved exceptional accuracy with an $R^2$ score of 0.98 for runtime prediction (mean error 15.57%) and 0.78 for power prediction (median error 5.42%). The system successfully predicts performance across matrix sizes, demonstrating robust scaling behavior. Our results show that optimal tile size selection can improve performance by up to 3.2x while reducing power consumption by 22% compared to baseline configurations. Analysis of shared memory utilization and SM occupancy reveals that tile sizes of 16x16 achieve the best balance between parallelism and resource usage. The implementation of our framework, including prediction models and analysis tools, is available as an open-source project at GPPerf.", "sections": [{"title": "I. INTRODUCTION", "content": "The optimization of GPU kernel performance represents a critical challenge in modern high-performance computing, particularly as applications demand increasingly efficient utilization of computational resources [6]. With the introduction of NVIDIA's Ada Lovelace architecture and specifically the RTX 4070, which features peak memory bandwidth of 504.2 GB/s and theoretical peak performance of 29.15 TFLOP/s\u00b9, the complexity of performance optimization has grown significantly [5]. The relationship between these hardware capabilities can be visualized through the roofline performance model, which illustrates the fundamental performance bounds of the architecture [3]. This model reveals a critical ridge point at 59 FLOPs/Byte, marking the transition between memory-bound and compute-bound operations a crucial consideration for optimizing matrix multiplication operations."}, {"title": "A. Problem Significance", "content": "The importance of this research stems from several critical factors in modern computing:\nFirst, as illustrated by the roofline model, GPU architectures present distinct performance regimes determined by arithmetic intensity [6]. Applications must be carefully tuned to operate near their theoretical limits, whether they are bounded by memory bandwidth or computational throughput. Our research specifically addresses the challenge of optimizing kernel configurations to approach these theoretical bounds."}, {"title": "B. Current Limitations", "content": "Traditional analytical models fail to capture the complex interactions between hardware features and kernel configurations [6]. Linear performance models have shown limited correlation with actual performance, indicating their inadequacy for modern architectures.\nCurrent profiling tools provide limited insight into the relationship between configuration parameters and energy efficiency [5]. While tools like NVIDIA's NSight Compute offer detailed performance metrics, they lack integrated analysis of power consumption and energy efficiency.\nExisting optimization strategies often focus solely on computational throughput, neglecting the critical aspect of energy efficiency [7]. Our preliminary investigations suggest that optimal configurations for performance often differ significantly from those that maximize energy efficiency."}, {"title": "C. Research Approach", "content": "Our approach to addressing these challenges encompasses several key components:\nFirst, we develop a comprehensive profiling infrastructure that simultaneously captures runtime performance metrics, hardware counters, and power measurements [3]. This infrastructure enables collection of multiple performance indicators, providing detailed insight into kernel behavior under varying conditions.\nSecond, we implement systematic exploration of the configuration space through automated testing of:\n\u2022 Various matrix dimensions to test scaling behavior\n\u2022 Different matrix layouts to analyze memory access patterns\n\u2022 Various combinations of scalar values for linear operations\nThird, we employ analytical techniques to correlate multiple performance metrics, enabling better understanding of the relationships between configuration parameters and various aspects of kernel behavior [2]."}, {"title": "II. LITERATURE REVIEW", "content": "The challenge of GPU performance prediction and energy optimization has garnered significant attention due to the increasing computational demands of modern applications [6]. Previous research in this domain can be categorized into three main approaches: analytical modeling, machine learning-based prediction, and hybrid optimization techniques [5]."}, {"title": "A. Performance Prediction Approaches", "content": "1) Analytical Modeling: Traditional analytical models attempt to predict GPU performance by analyzing kernel characteristics and hardware specifications [3]. Hong and Kim pioneered this approach with their integrated power and performance model that analyzed both memory-level and thread-level parallelism [9]. However, these approaches often fail to capture the complex interactions between hardware features and kernel configurations, particularly for modern GPU architectures [6]. The primary limitation stems from their inability to account for low-level hardware details and software optimizations provided by libraries like CuDNN and CUTLASS [5].\n2) Machine Learning-Based Prediction: Recent approaches leverage machine learning techniques to predict GPU performance [1]. These methods can be further classified into:\nDirect Prediction Models\n$Performance_{pred} = f(\\theta_{arch}, workload, W_{config})$\nThis model has shown significant accuracy improvements over traditional analytical approaches, achieving up to 87% prediction accuracy across different architectures [1]. Braun et al. demonstrated that simpler models focusing on portable performance prediction can be equally effective [10].\nEnsemble Methods More sophisticated approaches use stacking ensembles combining multiple models [6]:\n$Ensemble Prediction = \\sum_{i=1}^{n} w_i M_i(x)$"}, {"title": "B. Energy Optimization Strategies", "content": "1) Dynamic Voltage and Frequency Scaling (DVFS): DVFS-based approaches optimize energy consumption by adjusting voltage and frequency settings [8]:\n$Energy_{consumption} = Time_{execution} \\times Power_{average}$\nStudies have shown that DVFS can achieve up to 25% energy savings with minimal performance impact [7]. Recent work by Jammal et al. demonstrated significant power efficiency improvements in matrix multiplication algorithms through careful optimization of computational patterns [13].\n2) Hybrid Memory Systems: Research has explored combining different memory technologies [3], facing challenges with:\n\u2022 Increased cache misses\n\u2022 Higher data migration overhead\n\u2022 Memory bandwidth interference\nBoughzala et al. proposed using SimGrid for energy consumption prediction of CUDA kernels, demonstrating the viability of simulation-based approaches for memory system optimization [12]."}, {"title": "C. Performance-Energy Trade-offs", "content": "Recent work has identified fundamental trade-offs between performance and energy efficiency [5]:\n$ETA(b, p) = TTA(b,p) \\times AvgPower(b, p)$\nwhere b represents batch size and p denotes power limit. This relationship has been further explored in recent work by Wang et al., who developed the DSO framework for optimizing GPU energy efficiency by combining both static and dynamic information [2]."}, {"title": "D. Limitations of Existing Approaches", "content": "Current solutions face several key limitations [1]:\n1) Generalization: Most models struggle to generalize across different GPU architectures\n2) Complexity Trade-off: More complex models incur significant computational overhead\n3) Dynamic Workloads: Existing approaches often fail to adapt to changing workload characteristics"}, {"title": "E. Research Gap and Motivation", "content": "While existing work has made significant progress in individual aspects of GPU optimization [2], there remains a critical need for an integrated approach that:\n\u2022 Combines performance prediction with energy optimization\n\u2022 Adapts to dynamic workload changes\n\u2022 Considers both hardware and software optimization opportunities\n\u2022 Provides practical, implementable solutions"}, {"title": "III. PROPOSED IDEA", "content": "The approach we have chosen for this study is driven by the need to gain a deeper understanding of General Matrix Multiplication (GEMM) performance on modern GPUs, specifically focusing on runtime, power consumption, and energy efficiency. We recognize that achieving optimal performance in GEMM operations is not only dependent on hardware capabilities but also on fine-tuning the algorithmic and architectural parameters. Therefore, our methodology combines both fundamental analysis and advanced performance profiling to address the following key goals:"}, {"title": "A. Custom Tiled Matrix Multiplication for Fundamental Analysis", "content": "By implementing a custom tiled matrix multiplication kernel, we were able to isolate the effects of matrix tiling on GPU performance. Tiling is a well-known optimization technique that can significantly improve memory access patterns, reduce latency, and enhance parallelism on GPUs. This kernel serves as a controlled environment to study how different tile sizes affect performance, providing insights into the underlying hardware behavior at a granular level. The ability to vary tile sizes from 1 to 32 allowed us to explore the trade-offs between computational load and memory access efficiency, laying the foundation for more sophisticated analyses."}, {"title": "B. NVIDIA CUTLASS Library for Comprehensive Profiling", "content": "While the custom kernel provides a basic understanding, we turn to NVIDIA's CUTLASS library to access state-of-the-art implementations of GEMM. CUTLASS, being a high-performance library, includes optimized kernels that leverage advanced GPU features, such as warp-level programming, shared memory management, and memory coalescing. Using CUTLASS enables us to capture performance data across a wide range of configurations, which allows us to account for the complexities introduced by real-world optimizations. This also ensures that the predictions made by our model are relevant to practical scenarios, where high-level library optimizations are critical for performance."}, {"title": "C. Random Forest-based Multi-output Regression Model", "content": "Given the complexity of the problem-predicting runtime, power consumption, and energy efficiency for a variety of matrix sizes and kernel configurations\u2014a machine learning-based approach is employed. A Random Forest model was chosen for its ability to handle multi-dimensional data and uncover complex relationships between performance factors. Its multi-output regression capability allows for simultaneous prediction of multiple metrics (e.g., runtime and power) from a single model, providing a holistic view of the GPU's performance characteristics. The model's robustness, demonstrated by the high $R^2$ score and low mean/median errors, shows its efficacy in predicting performance across a wide range of configurations."}, {"title": "D. Identification of Key Performance Patterns", "content": "By analyzing both naive tiled matrix multiplication and advanced CUTLASS configurations, we identified critical performance patterns related to matrix dimensions, thread block configurations, and memory access patterns. This allows us to uncover fundamental insights into GPU behavior, including the balance between parallelism and resource usage, particularly memory resources like shared memory and streaming multiprocessor (SM) occupancy. These insights guide our recommendations on tile sizes and configurations that maximize both performance and energy efficiency."}, {"title": "E. Optimization for Performance and Power", "content": "The combination of customized kernel exploration, CUTLASS profiling, and machine learning modeling enabled us to determine that optimal tile sizes, such as 16\u00d716, achieve the best balance between parallelism, computational efficiency, and resource utilization. Our analysis showed that such configurations could improve performance by up to 3.2x while simultaneously reducing power consumption by 22%, highlighting the critical importance of optimizing tile sizes to achieve better energy efficiency without compromising computational throughput.\nIn summary, our approach integrates custom kernel analysis for fundamental performance insights with CUTLASS-based profiling for real-world scenarios, underpinned by a machine learning model that provides accurate, scalable performance"}, {"title": "IV. EXPERIMENTAL SETUP", "content": "We have two experiments: one simple with our naive tiled matrix multiplication and a linear regression model, and another more comprehensive one using cutlass and different machine learning techniques."}, {"title": "A. Environmental Configuration", "content": "Our experiments are conducted on NVIDIA GeForce RTX 4070 with Ada Lovelace architecture, and CUDA version 12.2."}, {"title": "B. Tiled Matrix Multiplication", "content": "We wrote a kernel using tiling for matrix multiplication. It takes four arguments: M, N, K, and Tile Size. The matrix multiplication will be M*N*K, and the tile size decide the block size (2-d block with size = tile size * tile size) and the shared memory size (2 * block size * size of float). The kernel code is shown in Listing 1."}, {"title": "C. CUTLASS", "content": "The cutlass profiler was built with DCUTLASS_NVCC_ARCHS=89 flag for the Ada Lovelace architecture. We profile the single precision, general matrix multiply (SGEMM) kernel with different configurations with a script executing commands in this format but more flags:\n1) Configurations: The profiling process used the CUTLASS profiler and NVIDIA Compute Utilities (NCU) to collect metrics. The following configuration parameters were varied:\n\u2022 Matrix Dimensions: M, N, K.\n\u2022 Kernels: Variants of CUTLASS SGEMM kernels, e.g., cutlass_simt_sgemm_128x128_8x2_nn.\n\u2022 Layouts: Matrix layouts: nn, nt, tn, tt.\n\u2022 Block Sizes: (64 \u00d7 64 \u00d7 32) and (128 \u00d7 64 \u00d7 32).\n\u2022 Alpha-Beta Scalars: {(1,0), (1, 1), (0.5, 0.5), (2,0)}.\n2) Tools Used: The following tools and utilities were employed:\n\u2022 CUTLASS Profiler: For kernel performance benchmarking.\n\u2022 NCU (NVIDIA Compute Utilities): For collecting GPU hardware metrics.\n\u2022 nvidia-smi: For device specifications and power monitoring.\n3) Metrics Collected: The following metrics were collected during the profiling process:\n\u2022 Performance Metrics:\nRuntime: Total execution time of the kernel (in milliseconds)."}, {"title": "V. EXPERIMENTAL RESULTS AND ANALYSIS", "content": ""}, {"title": "A. Tiled Matrix Multiplication", "content": ""}, {"title": "B. CUTLASS Experimental Results and Model Performance", "content": "The experimental evaluation of our prediction framework was conducted using NVIDIA's CUTLASS library on the RTX 4070 GPU architecture. Our dataset comprised 16,128 samples with various GEMM configurations, split into 2,076 training samples and 519 test samples. The model training process achieved convergence in 6.25 seconds, demonstrating efficient computational performance.\n1) Model Performance Metrics: Table IV presents the evaluation metrics for our prediction model across all target variables.\n2) Correlation Analysis: Figure 6 illustrates the correlation between matrix dimensions and performance metrics.\nThe correlation heatmap (Figure 6) reveals critical relationships between matrix dimensions and performance metrics. The strong positive correlation (0.98) between MxN\u00d7K and runtime confirms that total computational volume is the primary determinant of execution time. Interestingly, power consumption shows stronger correlation with M\u00d7N (0.80) than with K (0.02), indicating that output matrix size has more impact on power usage than computation depth. This can be attributed to the GPU's memory access patterns, where larger output matrices require more concurrent write operations and thus higher instantaneous power draw. The negative correlation between matrix dimensions and TFLOPS (-0.41 for MxNxK) observes performance saturation at larger problem sizes, due to increased cache pressure and memory bandwidth limitations. The key correlations are quantified in Table V.\n3) Performance Analysis: The prediction accuracy for runtime, power, and energy consumption is visualized in Figures 7, 8, and 9 respectively. The model demonstrates strong predictive capabilities across all metrics:\na) Runtime Prediction: The runtime prediction plot (Figure 6) demonstrates exceptionally accurate tracking of actual execution times across different matrix sizes. The model's predictions closely follow the actual values with an $R^2$ score of 0.9808, particularly in the middle range of matrix sizes (1024x1024 to 2048x2048). The slight deviation at larger matrix sizes can be attributed to increased cache misses and memory access latency. The logarithmic scale reveals that prediction accuracy remains consistent across multiple orders of magnitude, with relative errors staying within 15.57% even for the largest matrices. This robust performance validates our model's capability to capture both computational and memory access patterns effectively. The model achieves exceptional accuracy in runtime prediction ($R^2$ = 0.9808), with a mean absolute error of 2.86 milliseconds. The relationship between predicted and actual runtime values follows:\n$Runtime_{pred} = \\alpha \\cdot Runtime_{actual} + \\beta + \\epsilon$ (1)\nwhere $\\alpha$ = 0.97, $\\beta$ = 1.23, and $\\epsilon$ represents the prediction error term.\nb) Power Prediction: The power prediction graph (Figure 7) shows interesting behavior across matrix sizes. For smaller matrices (512x512 to 1024x1024), power consumption remains relatively stable around 80-100W, reflecting the GPU's base power draw. As matrix sizes increase, we observe distinct steps in power consumption, corresponding to the activation of additional Streaming Multiprocessors (SMs). The model accurately captures these step changes with an $R^2$ score of 0.7783. The higher variability in power predictions (mean error 22.16%) compared to runtime predictions reflects the complex interaction between computational intensity, memory access patterns, and the GPU's dynamic power management system. Notably, the predictions show better accuracy in the mid-range of power consumption (150-180W) where the GPU operates in its most stable power state. Power consumption prediction exhibits robust performance ($R^2$ = 0.7783) with a median error of 5.42%. The model captures the relationship:\n$Power_{pred} = f(M, N, K, ThreadConfig) \\pm \\epsilon_{power}$ (2)\nc) Energy Efficiency: The energy consumption plot (Figure 8) combines the effects seen in both runtime and power predictions. The strong correlation ($R^2$ = 0.8572) demonstrates our model's ability to capture the multiplicative relationship between runtime and power consumption. The increasing spread in predictions at larger matrix sizes (visible in the logarithmic scale) reflects the compounded uncertainties from both runtime and power predictions. The relatively high mean percentage error (43.02%) can be attributed to this error propagation effect. However, the model successfully captures the overall trend of increasing energy consumption with matrix size, with particularly accurate predictions in the range of 1024x1024 to 2048x2048 matrices where both runtime and power predictions are most reliable. Energy prediction demonstrates strong correlation ($R^2$ = 0.8572) with actual values, following:\n$Energy_{pred} = Runtime_{pred} \\cdot Power_{pred} \\cdot \\gamma + \\epsilon_{energy}$ (3)\nwhere $\\gamma$ represents the energy efficiency coefficient.\n4) Model Architecture Comparison: Table VI presents a comparative analysis of different model architectures. It reveals the superior performance of our stacking ensemble approach. In runtime prediction, the ensemble achieves a 1.85% improvement over the next best model (XGBoost), while in power prediction, the improvement reaches 3.27%. This superior performance can be attributed to the ensemble's ability to combine the strengths of different base models. The Random Forest model performs well on regular patterns ($R^2$ = 0.9456 for runtime), while XGBoost better captures non-linear relationships ($R^2$ = 0.9623). The linear regression baseline ($R^2$ = 0.8234) demonstrates that while linear relationships are important, they alone cannot fully capture the complexity of GPU performance characteristics. The stacking ensemble effectively leverages these complementary strengths while mitigating individual weaknesses."}, {"title": "VI. KEY EXPERIMENTAL FINDINGS", "content": "The experimental results demonstrate several significant correlations between matrix operations and performance characteristics. Our analysis introduces key performance metrics:\nArithmetic Intensity\n$\\frac{2MNK}{4(MK + KN + MN)}$ (4)\nMemory Efficiency = $\\frac{Achieved Bandwidth}{504.2 GB/s} \\times 100\\%$ (5)\n1) Matrix Dimensionality Impact: Correlation analysis revealed significant relationships:\n\u2022 Matrix volume (M \u00d7 N \u00d7 K) shows strong correlation with runtime (r = 0.98)\n\u2022 Output dimensions (M \u00d7 N) demonstrate higher correlation with power consumption (r = 0.80) than compute dimension K\n\u2022 TFLOPS efficiency exhibits negative correlation with matrix size (r = -0.41), following:\n$TFLOPSefficiency = \\frac{2MNK \\times 10^{-12}}{runtime (s) \\times 29.15}$ (6)\n2) Tile Size Performance Impact: Analysis of tile size effects revealed optimization patterns:\nEffective Grid Size = $\\frac{M}{TILE_{SIZE}} X \\frac{N}{TILE_{SIZE}}$ (7)\nShared Memory Usage = 2\u00d7$TILE_{SIZE}^2$\u00d7sizeof(float) (8)\nKey findings include:\n\u2022 Optimal tile size of 16 \u00d7 16 minimizes runtime across dimensions\n\u2022 Power consumption stabilization occurs with larger tile sizes\n\u2022 Performance plateau observed beyond 16 \u00d7 16 tiles due to shared memory constraints"}, {"title": "B. Model Architecture Performance", "content": "The stacking ensemble demonstrates superior accuracy across metrics:\n$Ensemble Prediction = \\sum_{i=1}^{n} w_i M_i(x)$ (9)\nwhere $M_i$ represents individual models and $w_i$ their corresponding weights.\nPerformance metrics achieved:\n\u2022 Runtime: $R^2$ = 0.9808, MAE = 2.86ms\n\u2022 Power: $R^2$ = 0.7783, median error = 5.42%\n\u2022 Energy: $R^2$ = 0.8572"}, {"title": "VII. CONCLUSIONS", "content": "We have the following main findings:\n1) Tile Size Optimization Improves Power Efficiency: Our experiments show that larger tile sizes lead to more efficient use of processing resources, resulting in lower power consumption. Smaller tile sizes, particularly 1 and 4, cause more frequent scheduling of blocks, increasing power usage due to inefficiencies in workload distribution. Larger tiles reduce grid size growth, minimize idle SP time, and enhance memory access patterns, contributing to overall power savings.\n2) Matrix Size Impact on Performance Metrics: The strong correlation (0.98) between MxN\u00d7K and runtime demonstrates that total computational volume is the primary determinant of execution time, while output matrix dimensions (M\u00d7N) have a stronger influence on power consumption (0.80) than the depth dimension K. This insight suggests that optimizing matrix partitioning strategies should prioritize output dimension considerations for power efficiency.\n3) Shared Memory Constraints: Analysis of SM occupancy reveals a critical threshold at tile size 16, where occupancy drops from 24 to 6 blocks per SM, with further reduction to 1 block at tile size 32. This limitation, driven by shared memory requirements, establishes a practical upper bound for tile size optimization, indicating that performance improvements must be balanced against hardware resource constraints."}]}