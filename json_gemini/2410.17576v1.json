{"title": "Real-time Vehicle-to-Vehicle Communication Based Network Cooperative Control System through Distributed Database and Multimodal Perception: Demonstrated in Crossroads", "authors": ["Xinwen Zhu", "Zihao Li", "Yuxuan Jiang", "Jiazhen Xu", "Jie Wang", "Xuyang Bai"], "abstract": "The autonomous driving industry is rapidly advancing, with Vehicle-to-Vehicle (V2V) communication systems highlighting as a key component of enhanced road safety and traffic efficiency. This paper introduces a novel Real-time Vehicle-to-Vehicle Communication Based Network Cooperative Control System (VVCCS), designed to revolutionize macro-scope traffic planning and collision avoidance in autonomous driving. Implemented on Quanser Car (Qcar) hardware platform, our system integrates the distributed databases into individual autonomous vehicles and an optional central server. We also developed a comprehensive multi-modal perception system with multi-objective tracking and radar sensing. Through a demonstration within a physical crossroad environment, our system showcases its potential to be applied in congested and complex urban environments. The implementations are open-sourced at https://github.com/Essoz/Distributed-Intersection-Traffic-Coordination-With-Lease", "sections": [{"title": "1 Introduction", "content": "Crossroads, also known as traffic intersections, represent critical nodes of transportation networks. However, they also pose a significant risk to transportation safety,erving as hotspots for severe traffic accidents. Statistically, intersections are disproportionately dangerous: approximately 43% of all vehicular crashes in the United States occur at or near intersections [14], with similar trends observed globally, such as 40% of all casualty crashes in Norway and 33% in Singaporeoccurring at these junctions [20]. More alarmingly, these percentages have shown an increasing trend over the years, reflecting a growing concern in urban traffic management.\nThis situation primarily arises from the following two reasons. First, it's a common case that vehicles traveling in orthogonal directions cannot notice each other due to the obstruction of buildings. Second, non-motor vehicles and pedestrians are more likely to appear in the blind spot vision of vehicles since there are usually plenty of them gathering in the intersection. These two facts create difficulties for a single vehicle to observe potential collisions and avoid them. Additionally, today, most urban intersections are under passive control mechanisms such as stop signs, which require vehicles to come to a complete stop even when there are no other cars at the intersection. This reduces efficiency by causing unnecessary deceleration. According to a conservative calculation performed by Victor Miller at Stanford University [16], unnecessary traffic stops in the United States can account for 1.2 billion gallons of consumption per year. Such passive intersection control mechanisms have led to a significant amount of energy waste and call for autonomous and adaptive control mechanisms.\nIn response to these challenges, this research proposes the V2V-based Network Cooperative Control System (VVCCS), implementing on Quanser Car [1](Qcar) Simulation platform. Aiming at helping the vehicle to get a holistic view of intersection conditions our system make intelligent decisions accordingly. Thereby it enhances safety and operational efficiency V2V autonomous system design while reducing energy consumption."}, {"title": "2 Related Work", "content": "The development of Autonomous Driving(AD) represents a critical intersection of multiple domain, including communication technologies, autonomous vehicle control, distributed database systems, and multi-modal perception. This section"}, {"title": "2.1 Vehicular Wireless communication", "content": "According to the survey on vehicular communication by Zeadally et al. [24], the typical applications based on the V2V can be divided into highly critical and non-critical scenario. VVCCS focused on solving the Pre-crash sensing and Forward collision, which requires effort from both ego car perception and environment infrastructure.\nVehicle-to-Server (V2S) Communication: V2S involve the exchange of data between vehicles and a centralized server. This architecture is instrumental in traffic management, enabling the aggregation and analysis of vehicular data for real-time traffic optimization. Studies by Wang et al. [22] and Qian et al. [18] have demonstrated V2S's role in reducing congestion and optimizing traffic flow in urban environments.\nVehicle-to-Vehicle(V2V) Communication: V2V communications facilitate wireless signals to exchange information between vehicles about accidents, weather, roadblocks, and traffic [24]. This method is crucial for real-time, decentralized decision-making, particularly in situations requiring rapid response, such as collision avoidance [25]. Research by Metzner et al. [15] highlights how V2V can significantly enhance the situational awareness of autonomous vehicles, leading to safer navigation, especially in complex environments like intersections."}, {"title": "2.2 Distributed Databases in Cooperative Communication System", "content": "The use of distributed databases like Etch Distributed(etcd) [7] in AD is increasingly popular due to their high resilience and scalability. Feng [8] provided an extensive analysis of distributed database performance in vehicular networks, emphasizing the importance of data consistency and fault tolerance in ensuring reliable communication. Furthermore, the work by Juan et al. [17] showcases the application of distributed databases in forecasting large-scale traffic data, highlighting the advantages of distributed computing in real-time traffic management and analysis."}, {"title": "2.3 Multi-modal Perception in Autonomous Vehicles", "content": "Multi-modal perception systems, combining inputs from various sensors such as cameras and LiDAR, are vital in enhancing the situational awareness of autonomous vehicles. Wei et al. [23] presented a fusion algorithm that integrates camera and LiDAR data for accurate object detection in real time. And Bansal et al. [3] classified the collision risk into three level metric. Their method significantly improved the detection accuracy and modeling in complex urban environments. Similarly, Han et al. [9] focused on the improvment of You Only Look Once (YOLO) algorithm [21] in driving sensor fusion, reaching the highly"}, {"title": "2.4 Real-time Hardware Platform in Vehicular Technology", "content": "The deployment of real-time systems in vehicular technology is essential for autonomous driving algorithm verification. As demonstrated by Craig et al. [4], simulation is a cornerstone of autonomous driving, allowing testing to occur more rapidly and with significantly less risk than is possible with hardware platforms alone. While Felipe et al. [6] argued the simulation methods like Behavior Cloning have many limitation and are hard to generalize into the real-world scenario. Retrofitting autonomous driving test platforms like Robosense [19], Baidu Apollo D-kit [2] seem to be a more realistic approach. However, for V2V communication scenarios specifically, the expensiveness limit their potential to simulate extreme cases like crossroad accident. Quanser Car(Qcar) is a 1/10th scale autonomous vehicle platform designed for research and education in the field of autonomous vehicle technology [1]. It is a self-contained system that includes all the necessary hardware and software components to enable autonomous navigation. It stands out as the best balance between safe simulation and algorithm deployment. Its scale and comprehensive integration of necessary technologies make it an ideal platform for experimenting V2V communication protocols and systems in a controlled yet realistic environment. The detailed feature and specification of Qcar is recorded in Appendix A.\nIn conclusion, the integration of these diverse yet interconnected domains forms the backbone of VVCCS. The ongoing research in these areas continuously contributes to the development of autonmous driving, paving the way for safer, more efficient, and intelligent urban transportation."}, {"title": "3 System Design: Overview", "content": "We present the overview of our system in Figure 2, consisting of four subsystems:"}, {"title": "3.1 Subsystem Decomposition", "content": "We present the overview of our system in Figure 2, consisting of four subsystems:\nControl Subsystem. The control subsystem ensures that the vehicle can run at the desired speed and accelerates/decelerates in time. The vehicle will be controlled by commands with the parameters of pulse-width modulation (PWM) and steering angle. Localization is implemented via the control subsystem by estimating the motor state to infer the position of the vehicle.\nInformation Sensing and Multimodal Fusing Subsystem. We use cameras and the Lidar to sense the environment. Approaching vehicles and pedestrians at the intersection will be recognized and tracked. To realize better precision, information from the camera modality and Lidar modality will be fused before being sent to other vehicles within the V2V network.\nCommunication Subsystem. All vehicles equipped with V2V communication technology will be able to share their current state (e.g., location, velocity, acceleration, and heading) and their perceptions (locations of detected objects) with each other in real time. In the implementation, we set up a distributed database to store the shared information and conduct read-write style communication.\nCollision Avoidance. Respectively, the avoidance algorithm running on the server and vehicles will analyze the data from the shared distributed database and single-car recognition subsystems. Global and local decisions will be made on the best course of action to avoid potential collisions."}, {"title": "3.2 Hardware and Software Stacks", "content": "Our team uses the Quanser Car [1] (Qcar) as the experimental car to finish the design. The Qcar (Figure 3) is equipped with a LIDAR, an RGBD camera,"}, {"title": "4 System Details", "content": "This section shows the design and implementation details of the control subsystem of VVCCS. Each physical autonomous driving system requires individual fine-tuning in order to reproduce our experiments. Basically, to apply our system,\nthe following three requirements must be fulfilled:"}, {"title": "4.1 Control subsystem", "content": "This section shows the design and implementation details of the control subsystem of VVCCS. Each physical autonomous driving system requires individual fine-tuning in order to reproduce our experiments. Basically, to apply our system,\nthe following three requirements must be fulfilled:\nThe vehicle goes straight when no wheel control command is passed in.\nThe vehicle can run at a given speed and hold that speed.\nThe vehicle has the ability to measure the location of itself so that the relative position of different vehicles can be calculated after they receive messages from each other.\nMinor deviation problems might occur because the diameters of the wheels on the two sides are not perfectly equal, and the suspension may not be perfectly horizontal. As the motor of Qcar is controlled by PWM instead of voltage change, it is needed to build a map from the duty cycle to the actual speed. In our case,\nwe sample and analyze a linear relation of them as shown in Equation 1\n$$dutyCycle = k \\cdot U_{target}, k = 0.1$$\nHowever, the Qcar takes too much time to achieve the desired speed when we want to enforce the collision avoidance algorithm in such a control system. Hence we add feedback terms to realize faster convergence. In Equation 3, we introduce a proportional error and an integral error so that the system can provide additional power to approach the desired speed.\n$$e(k) = U_{target} - U_{current}$$\n$$dutyCycle = k_{ff} \\cdot U_{target} + (k_{p}.e(k) + k_{i}\\sum_{i=0}^{k} e(i)))$$\nLastly, we need to handle the localization issue since Qcar is not equipped with a GPS module. We let the Qcar measure the distance it traveled by mon-itoring the state of the motor. Once the Qcar can estimate its real-time speed with the state of the motor, we integrate the speed to calculate the distance. Additionally, we hard-code the initial position of Qcars into the system and al-ways run it from there, so that the Qcar can calculate its location accordingly. For an industrial-use autonomous driving car, the process can be simplified by installing GPS."}, {"title": "4.2 Multimodal Sensing subsystem", "content": "In this section, we will present a detailed description of the sensing subsystem, including its primary components, information processing procedure, and refinement for better performance.\nPrimary Components Camera. Qcar contains an Intel D435 RGBD Camera and a 360\u00b02D CSI (Camera Serial Interface) Camera system, as shown in Figure 3. There are four 8MP 2D CSI cameras at the front, left, rear, and right sides. Each camera has a wide-angle lens providing up to 160\u00b0 Horizontal-FOV (field of view) and 120\u00b0 Vertical-FOV. The blind spots are shown in Figure 4.\nLIDAR. The Qcar platform provides RPLIDAR A2M8, an enhanced version of the 2D laser range scanner (LIDAR). It can perform 2D 360-degree scans within\na 12-meter range(8-meter range of A2M8-R3 and the below models). It takes up to 8000 samples of laser ranging per second with high rotation speed. The typical scanning frequency of the RPLIDAR A2 is 10hz (600rpm). Under this condition,\nthe resolution will be 0.45\u00b0. During every ranging process, the RPLIDAR emits modulated infrared laser signal and the laser signal is then reflected by the object\nto be detected. Figure 5 provides an example output of RPLIDAR.\nObject Detection Model. For object detection, the Qcar hardware supports 256 CUDA Core NVIDIA Pascal\u2122 GPU architecture, with 1.3 TFLOPS (FP16) NVIDIA\u00ae Jetson\u2122 TX2. We construct one image containing the four initial images from the four cameras as sub-images. We then stream the combined image into the Yolo5 object detection model in real-time. An example figure\nis shown in Figure 6. We tested multiple models and chose the one that has the best performance in our domain. We also tuned the hyper-parameters to 10 frames per second to achieve our real-time requirement.\nImage Coordinates to Angle Conversion. To get the accurate position of surrounding cars, we need the relationship between the image coordinates of objects and their angle to the Qcar frame. After experiments, we linearly approximate the relationship as angle = 0.1840*pixel+bias. We measured the pixel-to-angle correspondence and angle-to-pixel correspondence and concluded that the fitted curve can be approximated linearly on an accurate scale.\nData Fusion. The angle of surrounding cars to the Qcar can be obtained by processing images from four cameras. In the meantime, LIDAR will provide a point cloud map containing the angle and distance of each point. By extracting points in the range of angles obtained before, we can get type and relative position of the surround objects.\nPerformance Optimization: Multi-thread Optimization. Each loop of our perception system includes four steps: fetching data from each sensor (camera,"}, {"title": "Elimination for Duplicates.", "content": "In some cases, surrounding objects will be de-tected by two adjacent cameras at the same time. If they are simply treated\nas two objects and calculate their relative position separately, the result will be inaccurate. So that we can extract their label box from the prediction list of\ntwo adjacent cameras and merge them into one large box. On the other hand, surrounding objects may be detected as two due to the non-max-suppression\nalgorithm of the object detection model. In our code, if two detected objects'\nrelative positions are too close, they will be merged and there will be only one\nobject finally.\nData Smoothing: Kalman Filter. Kalman Filter is an algorithm to com-pute smoothed time-evolving data given the measured non-smooth data. KF is useful given the noised measured time-varying position."}, {"title": "4.3 Communication subsystem", "content": "In this section, we present the communication subsystem of VVCCS that sup-ports real-time communication while supporting multi-object tracking.\nThe etcd Database. etcd [7] is a strongly consistent, distributed key-value store that provides a reliable way to store data that needs to be accessed by a distributed system or cluster of machines [13]. etcd exploits the Raft con-sistency algorithm to coordinate nodes in the cluster. The algorithm elects a master node as leader, who is responsible for synchronization and distribution. When the leader fails, the cluster automatically selects another node as the lead to synchronize the data. Hence, etcd is highly resistant to potential client or communication failure and guarantees the robustness of VVCCS.\nTo implement the communication between vehicles while isolating private data, we construct the following data structure in etcd, as shown in Figure\n7. For each vehicle, there are two fields, state and surrounding, recording the state of the vehicle itself and detected objects, respectively. As etcd provides the functionality of synchronization, the vehicle only needs to update relevant information to its fields. When the vehicle needs to make a decision, it will fetch\ndata from all surrounding fields in the etcd, thereby realizing the interaction with other vehicles. An advantage of such implementation is that the communication and planning modules are decoupled.\nVerification. Bandwidth and latency are critical criteria for designing the communication module. We consider a synchronization latency of less than 100ms to be acceptable. In our experiment case, upload and download speed can remain stable at 30MB/s in the WIFI6 local area network. For the commu-nication protocol using method 2, each vehicle updates to etcd by sending a 4KB package every 100ms. A full synchronization among all vehicles takes 2000KB/s, while occasional location updates should take 1/10 of the maximum bandwidth, 200KB/s. Therefore, the estimated bandwidth of our method in the real intersec-tion scenario is approximately 2MB/s, which shows that the laboratory network can support 60 Qcars communicating at the same time. On the other hand, the"}, {"title": "4.4 Collision Avoidance algorithm", "content": "This section presents an innovative collision avoidance algorithm. We will de-lineate the input and output of the algorithm, and expound on how it ensures efficiency and safety in scenarios involving both V2V and non-V2V vehicles.\nAlgorithm Specification. Our algorithm incorporates two subsystems: the lease-based scheduling subsystem and the planning subsystem. The scheduling algorithm employs a series of discrete snapshots capturing the intersection state at given timestamps. Each snapshot records the speed, location, type, and a unique identifier for every traffic participant. From this data, a lease, delineat-ing the temporal duration of a vehicle's intersection occupancy, is created for each vehicle. A lease can be extended, canceled, or reapplied in response to un-predictable circumstances. The planning subsystem evaluates the lease assigned to each vehicle, modulating the vehicle's speed to adhere to the lease terms. In essence, the algorithm processes intersection snapshots as input to produce corresponding vehicle movements as output.\nLease-based Scheduling Subsystem. This subsection provides a comprehen-sive understanding of the elegance, simplicity, and adaptability of our solution. The ingenuity of our design stems from its ability to strike a balance between efficiency, safety, and timeliness depending on specific application scenarios and\ncomputational resources. Our design hinges on the proven and effective FIFO\n(First In First Out) algorithm [12] used for obstacle avoidance.\nThe Lock-based Algorithm. Previous algorithms metaphorically treat the intersection as a computer science lock. Vehicles attempt to acquire the lock"}, {"title": "Abrupt halts:", "content": "Vehicles cannot anticipate when a lock might be obtained by others, leading to sudden stops or reduced efficiency."}, {"title": "Efficiency conundrums:", "content": "Without advance knowledge of lock release, vehi-cles can't adjust their speed to seamlessly traverse the intersection immedi-ately upon lock availability. This issue exacerbates traffic congestion under\nheavy traffic conditions."}, {"title": "Our Lease-based Algorithm.", "content": "A lease is akin to a lock, supplemented with a\nconservative estimation of the duration when a traffic participant is expected to occupy a block. Traffic participants holding currently active leases are permitted to enter the intersections. Safety is guaranteed by ensuring leases do not overlap in time for conflicting paths in the intersection. Our lease-based approach grants a temporal window of safe intersection traversal to each vehicle, allowing them to adjust their speed in anticipation of their assigned lease and improve efficiency.\nIn a nutshell, every traffic participant's action will be divided into three phases depending on their location.\nPlanning (before crossing the intersection)\nCrossing (inside the intersection)\nPost-crossing (after crossing the intersection)"}, {"title": "The Planning Phase.", "content": "In this phase, traffic participants will have two kinds of ac-tions, depending on whether it has made a lease or not. Every traffic participant starts with no lease. To apply for a lease, they must follow these steps:\nEstimate the expected time of entering and leaving the intersection area.\nCheck if there are any conflicting leases.\nIf there are no conflicting leases, register its lease into etcd, using the ex-pected time.\nElse, postpone its lease to the next available slot and register the lease into etcd.\nThese steps guarantee no two leases can overlap during the application phase. After a lease has been acquired, the traffic participant should constantly check the following:\nIf the current lease can be brought forward? If yes, bring the lease forward to the first available slot. This step is necessary as sometimes, a previous lease can get canceled. In this case, we want to actively check if a lease can be put forward for efficiency concerns.\nCheck if the current lease is still possible to satisfy within the car's mechan-ical capabilities. If it is impossible to catch up with a lease anymore or the lease has expired, we want to cancel the lease and reapply the lease."}, {"title": "The Crossing Phase.", "content": "In this phase, traffic participants mainly do the following for lease management:\nCheck if its lease is about to expire. If yes, extend the lease and postpone other participants' leases if necessary, to avoid other participants from entering the intersection before completing leaving."}, {"title": "The Post-crossing Phase.", "content": "In this phase, traffic participants mainly do the following for lease management:\nCancel the lease if it is still active. A lease might still be active after the participant has left the intersections because of many factors such as con-servative time prediction. We want to cancel the lease early so that other traffic participants can bring their lease forward."}, {"title": "Managing Non-V2V Traffic Participants.", "content": "Not all traffic participants are equipped\nwith V2V communication capabilities and as such, they may be unable to apply for leases autonomously. In the event of a conflict, we prioritize non-V2V leases by postponing V2V leases instead. This strategy is implemented to minimize the impact of unpredictability from non-V2V participants.\nEnforcement Once the lease for each vehicle is assigned, the planning subsys-tem acts as the intermediary between the lease-based scheduling subsystem and\nthe physical layer of vehicle motors, regulating speed and trajectory to meet the\nscheduling requirements.\nPlanning: If there is not a lease, the traffic participants should keep going at their current speed. If there is a lease, the participant changes its speed according to the requirement of the lease. If the participant is about to arrive at the intersection but still does not have a lease available, it stops until the\nleasing system makes a lease.\nCrossing: Keep its speed at the advised speed (often set by the government), and stop if the current lease is preempted by a non-V2V traffic participant.\nPost-crossing: Keep its speed at the advised speed (often set by the gov-ernment)\nThe control subsystem and the leasing algorithm, together, will make inter-section collision efficient and safe.\nVerification To verify the properties of the system, we have designed 4 experi-ments. One for showing the efficiency of the algorithm, and two for showing the safety of the algorithm. The first one is a comparison experiment, the experiment setup contains two V2V vehicles trying to cross the intersection at the same time from different directions and compare the total time for both cars to cross the intersection under our lease-based scheduling algorithm and the lock-based al-gorithm. We show that our algorithm is consistently 30% faster. The second one consists of two V2V vehicles trying to cross the intersection at the same time. We show that the lease-based scheduling system can let both cars cross without crashing into each other. The third one consists of two V2V vehicles and one"}, {"title": "Engineering Feasibility and Future Improvements.", "content": "In this project, we\nhave shown that the \"lease\" concept can have great potential in advanced in-tersection traffic scheduling with a minimum working example. Simple as it is, we want to show that the \"lease\" concept actually enables further space utiliza-tion optimization. For example, we can split the intersection into multiple blocks which have independent lease management systems, to increase the space uti-lization. Since lease application and the collision avoidance algorithm are largely\nlimited by the accuracy of the prediction algorithm and the movement planning algorithm, the engineering team can easily, based on their specific needs, swap the existing prediction and movement planning algorithms with better ones or\nsimpler ones to balance between performance and amount of computing resource\navailable."}, {"title": "5 Demonstration in Physical Environments", "content": "We set up a physical intersection environment in our lab with a 4.5 \u00d7 4.5 meter canvas depicting the crossroads. The demonstration videos can be found at ht\ntps://drive.google.com/drive/folders/1tqCEgUyZGuE_PuScPbvGTvdxDFfr\nMOGJ?usp=sharing"}, {"title": "6 Discussion", "content": ""}, {"title": "6.1 System Limitation", "content": "Despite the innovative approach of VVCCS, there are inherent limitations that\nneed addressing in future developments. One primary constraint comes from\nthe sensor and CPU computing capabillity of the Qcar platform. The current\nsensor suite and computation resource, while effective for basic navigation and perception tasks, may not be sufficient for more complex scenarios encountered in real-world driving. Technical advancements are necessary to improve system\nreal-time performance, accuracy, scalability, and reliability."}, {"title": "6.2 Future work", "content": "The VVCCS's current implementation offers a safe and controlled environment\nfor testing emergent driving scenarios without ethical or safety concerns. Future\nwork includes expanding the number and variety of simulations, as well as up-grading the system. One potential direction is to iterate and migrate the system\nto larger-scale simulation vehicles such as the Baidu Apollo D-kit [2], providing a more comprehensive testing ground.\nTesting and Validation: Plans for extensive testing and validation in real-world conditions are crucial. This includes trials in diverse environments and weather conditions, along with long-term assessments of operational stability.\nInterdisciplinary Integration: Consideration should be given to integrat-ing the VVCCS with technologies from other fields, such as smart city manage-ment and environmental monitoring. This approach could broaden the applica-tion scope of the research findings."}, {"title": "7 Conclusions", "content": "In summary, VVCCS achieves successful collision avoidance in all our experi-ments at intersections. The overall energy consumption is much lower than that required by traditional traffic control mechanisms, such as traffic lights and stop signs. In this work, We implement the\nprecise control of the speed of Qcar by combining the feed-forward and feed-back terms in the command to drive the motor and realize the localization by converting the motor state to real speed and conducting the integration. The\nvision-based object detection subsystem achieves the detection of other vehicles\nand pedestrians in the complex environment. Moreover, We exploit the etcd dis-tributed database to make vehicles communicate with each other. Lastly, We\npropose the idea of the lease to help schedule the timeline for each to pass through the intersection."}]}