{"title": "Benchmarking LLMs for Translating Classical Chinese Poetry: Evaluating Adequacy, Fluency, and Elegance", "authors": ["Andong Chen", "Lianzhang Lou", "Kehai Chen", "Xuefeng Bai", "Yang Xiang", "Muyun Yang", "Tiejun Zhao", "Min Zhang"], "abstract": "Large language models (LLMs) have shown remarkable performance in general translation tasks. However, the increasing demand for high-quality translations that are not only adequate but also fluent and elegant. To assess the extent to which current LLMs can meet these demands, we introduce a suitable benchmark for translating classical Chinese poetry into English. This task requires not only adequacy in translating culturally and historically significant content but also a strict adherence to linguistic fluency and poetic elegance. Our study reveals that existing LLMs fall short of this task. To address these issues, we propose RAT, a Retrieval-Augmented machine Translation method that enhances the translation process by incorporating knowledge related to classical poetry. Additionally, we propose an automatic evaluation metric based on GPT-4, which better assesses translation quality in terms of adequacy, fluency, and elegance, overcoming the limitations of traditional metrics. Our dataset and code will be made available.", "sections": [{"title": "1 Introduction", "content": "The three difficulties in translation are: adequate, fluent, and elegant.\n Yan, 1898\nThe emergence of large language models (LLMs), especially ChatGPT, has demonstrated impressive performance in general translation tasks (Tyen et al., 2023; Liang et al., 2023; Guerreiro et al., 2023; Ranaldi et al., 2023). The extensive knowledge and strong reasoning abilities of these LLMs open new possibilities in the field of translation (Ouyang et al., 2022; Moslem et al., 2023b; Chen et al., 2023; He et al., 2023; Liang et al., 2023; Ghazvininejad et al., 2023; Lu et al., 2023; Chen et al., 2024a). As the demand for translation quality continues to rise, translated results must not only be adequate but also fluent and elegant (Wang et al., 2024; Huang et al., 2024; Gao et al., 2024). This raises a question: can existing LLMs meet such translation requirements, and if so, to what extent can they achieve this performance?\nTo address this question, we introduced a suitable benchmark: translating classical Chinese poetry into English. Firstly, these poems carry culture and history, so the translation needs to adequately convey the original meaning. Secondly, classical Chinese poetry has strict rules on rhyme, tone, and structure, making fluent translation a significant challenge. Lastly, classical Chinese poetry has aesthetic value, with the concise expressions of the Chinese language showing unique elegance, which needs to be preserved in translation.\nBased on the proposed classical poetry trans- lation benchmark, current methods often lack historical and cultural knowledge, fluency, and elegance. To address these issues, we introduce RAT, a retrieval-augmented machine translation method. This method enhances the translation process by retrieving knowledge related to classical poetry, ensuring the translated output remains adequate to the original text while also achieving fluency and elegance. Furthermore, previous automatic evaluation metrics for machine translation (Papineni et al., 2002; Rei et al., 2022; Sellam et al., 2020a) have primarily relied on n-gram and semantic analysis to assess entire sentences, making them unsuitable for the task of classical poetry translation. To address this issue, we propose an automatic evaluation metric based on GPT-4 (OpenAI 2024), which better assesses translation quality from the perspectives"}, {"title": "2 Related Work", "content": "Poetry Machine Translation The initial attempts at poetry machine translation utilized phrase- based machine translation systems to translate French poetry into metrical English poetry (Genzel et al., 2010). This study demonstrated how statistical machine translation systems can produce translations while adhering to the rhythmic and rhyming rules of poetry. Chakrabarty et al. (2021) conducted an empirical study that highlighted a critical but often overlooked issue: even though they can maintain meaning and fluency, advanced machine translation systems trained on large amounts of non-poetry data struggle to preserve the original style of poetry. To address the issue of style preservation, some studies have managed to generate diverse styles by inputting sentences with specific styles into the encoder and embedding the target style into the decoder (Zhang et al., 2018; Liu and Wang, 2012). Considering that poetry often contains richly stylized semantic information and deep historical and cultural connotations, such as in classical Chinese poetry, Rajesh Kumar Chakrawarti and Bansal (2022) proposed a Hybrid Machine Translation (HBMT) model to improve the semantic and syntactic accuracy of poetry translations. Recently, Wang et al. (2024) have successfully implemented translations of modern poems from English to Chinese using the knowledge and multilingual capabilities of ChatGPT.\nChinese Classical Poetry Dataset Chinese classical poetry has several open datasets. Chen et al. (2019) published the first fine-grained dataset, annotating a manually fine-grained emotional poetry corpus containing 5,000 Chinese quatrains. Yutong et al. (2020) released a dataset containing 3,940 quatrains with automatically annotated themes and 1,917 quatrains with automatically annotated emotions, using a template-based method. Additionally, Liu et al. (2020) collected a parallel bilingual dataset of ancient and modern Chinese and aligned the lines using a string matching algorithm. Based on these bilingual pairs, Li et al. (2021) constructed a matching dataset to evaluate models' semantic understanding capabilities. To our knowledge, this is the first dataset for English translation of Chinese classical poetry, aimed at evaluating the translation performance of current large models in terms of adequate, fluent, and elegant."}, {"title": "3 Classical Chinese Poetry Dataset Construction", "content": "In this section, we discuss the design and construction of the MT benchmark, including the rules and steps for building this benchmark.\n3.1 Discourse-Level Poetry Translation\nWe collected a batch of classical Chinese poetry data and corresponding English translations from online resources. The classical Chinese poetry database contains 1200 poems from Tang Poems, Song Poems, and Yuan Opera. Then, We manually screened 608 classical Chinese poems and their corresponding translations to serve as gold standards for translation source and target alignment.\nThe statistics of this benchmark are shown in Table 1. We present the number of classical Chinese poetry, the number of unique tokens, the average number of tokens per sentence, and the total number of tokens in different poetry types. The source sentences in this benchmark have a moderate length, and the selected target translation sentences are well-aligned with the source in terms of length, indirectly reflecting the high quality of the reference sentences.\n3.2 Adequacy in Sentence-Level Translation\nTo construct this test set, we selected sentences containing historical knowledge and commonsense from the collected data of classical Chinese poetry. To maintain the diversity of the test set, we avoided choosing semantically similar words and those that, despite having multiple meanings in Chinese, translate to the same word in English. We preferred to select words that translate to completely different English words in different contexts, requiring disambiguation based on understanding various contexts, historical backgrounds, writing styles, and commonsense. This test set consists of 500 sentences, with each translated sentence represented as a triplet $(s, t_c, t_e)$. As shown in Figure 2, $s$ contains the source sentence with ambiguous words, $t_e$ and $t_e$ are the contrast translations, with the former being correct and the latter incorrect. The selected ambiguous words are used only once in each translated sentence.\n3.3 Classical Chinese Poetry Knowledge Base\nClassical Chinese Poetry holds rich historical and cultural nuances, but with limited resources for Classical Chinese, modern Chinese knowledge can greatly improve translation quality. We collected a Classical Chinese Poetry Knowledge Base using open-source projects and internet resources. This Knowledge Base consists of 30,000 entries, including 30,000 Classical Chinese Poems along with their corresponding historical background, dynasty names, modern Chinese translations, author introductions, modern Chinese analysis, and poetry type information.\n3.4 Human Annotation\nAlthough collected poetry translation data were created by humans, the randomness still affects data quality. To mitigate this, we invite human annotators to assess the quality of translation parallel sentence pairs and eliminate any problematic instances."}, {"title": "4 Proposed Method: RAT", "content": "Translation of classical Chinese poetry requires un- derstanding of language style, cultural background, and author information. The RAT (Retrieval Augmented Translate) method was introduced to enhance translation outcomes by leveraging rich contextual information from the Classical Chinese Poetry Knowledge Base. We will now introduce the two workflows implemented in the RAT method in detail (in Figure 1). The first workflow (in Figure 1(a)) uses poetry as input and retrieves relevant knowledge about the poetry from the Classical Chinese Poetry Knowledge Base through text matching methods, obtaining different views of the relevant knowledge. The second workflow (in Figure 1(b)) translates based on the relevant knowledge from different views and integrates these to produce the final translation result.\n4.1 The First Workflow\nIn the first workflow of RAT, there are two modules: Retriever and Selector. The Retriever is used to retrieve relevant knowledge from diverse perspectives based on the poetry, while the Selector filters the retrieved knowledge to enhance its relevance to the poetry.\n1. Retriever. We propose a retrieval augmentation method to obtain knowledge relevant to translating classical Chinese poetry. Based on the Classical Chinese Poetry Knowledge Base we constructed, we use text-matching methods to retrieve uniquely relevant knowledge from multiple perspectives. These perspectives include historical background, dynasty name, modern Chinese translation, author introduction, modern Chinese analysis, and poetry type.\n2. Selector. The goal of the selector is to filter out irrelevant content from the results of the retriever that are unrelated to the translated sentences and passages. As an agent set by the LLM, the selector first understands the historical background, author introduction, and modern Chinese analysis based on the source sentences, and then outputs content relevant to the translated source sentences, with a limit on the output length (max_len).\n4.2 The Second Workflow\nIn the second workflow of RAT, there are three modules: Translator, Voter, and Extractor. The Translator module translates different English verses based on classical Chinese poetry and the retrieved knowledge. The Voter module then votes on each translated sentence to determine the optimal translation. Finally, the Extractor module extracts the voted translation results to form the final translated version.\n1.Translator. The goal of the Translator is to translate different types of retrieved content. The LLM uses its translation capabilities to process both source content and retrieved content separately. This time, six types of related content were retrieved for classical Chinese poetry, resulting in six different translation outputs.\n2.Voter. The purpose of the Voter is to integrate translations based on different retrieval results to improve translation quality. As an agent of the LLM, Voter votes on each sentence of all translation outputs based on the source input, selects the highest-quality translations, and concatenates these selected sentences to form the final translation result.\n3.Extractor. The goal of the Extractor is to extract the final translation results generated by the Voter. As an agent of the LLM, the Extractor filters out noise from the content generated by the Voter based on the source input, and outputs the final translation results."}, {"title": "5 Evaluation Methods", "content": "5.1 Evaluation Criteria\nThe translation of classical poetry requires not only artistic expression but also an understanding of the cultural background, making it nearly impossible to produce a single, universally correct translation. Therefore, multiple translations of the same classical poem can coexist, each offering a unique perspective and interpretation. Following this line of thought, we evaluate the quality of classical poetry translations through three aspects: \"Adequate,\" \"Fluent,\" and \"Elegant.\" The specific evaluation methods are as follows:\n(a) Accuracy (Acc)\u2020: Focus on the preci- sion of each element in the translation, accurately translating historical, cultural, and factual aspects, including words and phrases, to maintain the correct semantic and logical relationships of the poem.\n(a) Beauty of Sound (BS)\u2191: The beauty of sound in Chinese classical poetry is primarily reflected in its rhyme and meter. This standard examines whether the translation achieves harmonious sound, precise wording, adherence to strict metrical rules, and a rhythm that is both smooth and dynamic.\n(b) Beauty of Form (BF)\u2191: Chinese clas- sical poetry emphasizes balanced struc- ture, with common forms such as \"four- character quatrains,\" \"seven-character quatrains,\" and \"seven-character regu- lated verse,\" each exhibiting distinct aesthetic characteristics of Chinese po- etry. This standard evaluates whether the translation maintains consistency with the source poem's structure, including the alignment of line numbers and balanced phrasing.\n(a) Beauty of Meaning (BM)\u2191: Chinese classical poetry uses concise and precise language to create vivid imagery and a rich atmosphere for readers. This standard assesses the depth and richness of the translation, focusing on the effec- tiveness of conveying themes, emotions, and messages.\n5.2 LLM-based Classical Poetry Metric\nIn this section, we aim to establish a method for evaluating the translation of classical Chinese poetry based on LLMs assessments. Drawing from current QE (Quality Estimation) research, we have developed an approach to utilize LLM in determining the quality of classical Chinese poetry translations. As shown in Figure 5, we designed a 1-5 scoring prompt to help LLM focus on the translation quality in terms of Beauty of Sound (LLM-BS). In the evaluation criteria, a score of 1 reflects a poor translation of classical Chinese poetry, a score of 3 indicates a basic but imperfect translation result and a score of 5 represents an excellent and accurate translation in this aspect. Subsequently, test data is provided to the LLM, and the LLM is asked to generate an assessment with scores only. Additionally, we calculate the average scores of BF, BF, and BM (LLM-Avg) to evaluate the overall translation performance."}, {"title": "5.3 Traditional Automatic Evaluation", "content": "In evaluating our translation methodology, we initially employ COMET\u00b9 (Rei et al., 2022) and BLEURT2 (Sellam et al., 2020b) as automatic metrics, aligning with the established standards in LLM-based translation literature (He et al., 2023; Huang et al., 2024). For traditional translation evaluation, we use BLEU 3 (Papineni et al., 2002)."}, {"title": "6 Experiment Setup", "content": "6.1 Comparing Systems\nIn our evaluation, RAT is compared with a range of translation methods, including Zero- shot (Wei et al., 2022), 5-shot (Brown et al., 2020; Hendy et al., 2023), Rerank (Moslem et al., 2023a), Refine (Chen et al., 2023), MAD (Liang et al., 2023), and MAPS (He et al., 2023). \u03a4\u03bf validate its generalizability, we utilize three LLMs, which include closed-source models such as ChatGPT(Ouyang et al., 2022) and GPT-4(Achiam et al., 2023) 4, as well as open-source models like Alpaca-7B (Taori et al., 2023) 5 and Vicuna-7B (Chiang et al., 2023) 6. The following content will provide detailed descriptions of these comparisons:\n\u2022 Baseline, standard zero-shot translation is performed in ChatGPT (Ouyang et al., 2022) and GPT-4 (Achiam et al., 2023). The temperature parameter set to 0, which is the default value for our experiments.\n\u2022 5-Shot (Hendy et al., 2023), involves prepend- ing five high-quality labelled examples from the training data to the test input.\n\u2022 Rerank (Moslem et al., 2023a) was con- ducted with the identical prompt as the baseline, employing a temperature of 0.3 (Moslem et al., 2023b). Three random samples were generated and combined with the baseline to yield four candidates. The optimal candidate was chosen through GPT-4.\n\u2022 Renfie (Chen et al., 2023) first requests a translation from ChatGPT, then provides the source text and translation results, and obtains a refined translation through multiple rounds of modifications by mimicking the human correction process.\n\u2022 MAD (Liang et al., 2023) enhance the capabilities of large language models (LLMs) by encouraging divergent thinking. In this method, multiple agents engage in a debate, while an agent oversees the process to derive a final solution.\n\u2022 Dual-Reflect(Chen et al., 2024b) provide supervisory signals for large models to reflect on translation results through dual learning, thereby iteratively improving translation performance (the maximum number of iterations is set to 5).\n\u2022 RAT, is proposed method in this work."}, {"title": "7 Experimental Results", "content": "7.1 Can LLM evaluate Chinese classical Poetry?\nWe first randomly select N chapter-level Chinese classical poetry pieces from each source language dataset and translate them using the RAT method. We then compare the evaluation results of the large language model with human-annotated results to calculate the Pearson correlation coefficient (Pearson, 1920), Spearman correlation coefficient (Spearman, 1961), and Kendall correlation coef- ficient (Kendall, 1948) to determine the level of consistency.\nThe results in Table N indicate that large language models can serve as effective tools for evaluating the translation quality of idioms across different language pairs. In contrast, BLEU, COMET, and BLEURT were found to be less consistent with human evaluations, highlighting the advantages of our proposed evaluation method in the translation of classical poetry.\n7.2 Main Results\nWe compare various different LLM-based methods on the Classical Chinese Poetry Benchmark with RAT. The analysis of the experimental results is as follows:\n\u2022 The task of translating Classical Chinese Poetry is challenging. The experiment shows that translating Classical Chinese Poetry is difficult, with low COMET/BLEURT/BLEU scores for current LLM-MT methods. This is because the translation is challenging and n- gram-based evaluation methods are not ideal for poetry. Additionally, GPT-4-based evalua- tion metrics, particularly in BS/BM/BF/AVG aspects, still need considerable improvement.\n\u2022 The effectiveness of RAT method. The proposed RAT method consistently outper- forms other comparative methods across all evaluation metrics, demonstrating the effectiveness of our approach.\n\u2022 The effectiveness of different LLMs. Among all comparative methods, closed- source models perform better on this task than open-source models, possibly implying that closed-source models benefit from richer pre-training data, thus enabling higher-quality translations. This also suggests that the Chinese Classical Poetry translation task is more challenging.\n\u2022 The effectiveness of retrieved knowledge. For EAPMT, which relies on LLMs' self- generated knowledge, the RAT method, which uses retrieval-based knowledge, pro- vides more accurate information and further improves translation quality. This suggests that translating Chinese Classical Poetry demands stricter knowledge. However, the results from RAT still do not reach the level of human translation, indicating significant room for improvement in this task.\n7.3 Evaluation of Adequacy\nTo evaluate the translation performance of LLMs in terms of Adequacy, we employed a constructed dataset of 500 Classical Chinese Sentence-Level Translations to assess various translation methods. This experiment follows the method of Liang et al., 2023, assessing translation results from two main dimensions: manual evaluation of ambiguous translation accuracy and direct evaluation of translation quality using the LLM-BM.\nThe experimental results are shown in Table 2. In terms of ambiguity resolution accuracy, RAT performed the best, indicating that retrieving accurate information helps to better eliminate ambiguities in translation tasks. In the human evaluation, RAT received the highest score, further demonstrating that this method achieves excellent translation quality."}, {"title": "8 Analysis", "content": "8.1 LLM-based Metric Consistency\nIn this experiment, we evaluated whether the proposed LLM-based metrics, including LLM-BS, LLM-B, LLM-BM, and LLM-AVG, could reflect the evaluation characteristics of Beauty of Sound, Beauty of Form, Beauty of Meaning, and overall translation quality, while also demonstrating variability. We conducted pairwise correlation tests between human evaluation results and LLM- based results, employing the Pearson correlation coefficient, Spearman correlation coefficient, and Kendall correlation coefficient.\nThe experimental results indicate that, among all correlation coefficients, the consistency results based on the same annotations are significantly higher than the other results. This demonstrates the rationality of the evaluation settings for LLM- BS, LLM-B, LLM-BM, and LLM-AVG in the experiment.\n8.2 Impact of Different Knowledge on Translation Performance\nThe RAT method utilized knowledge from the Classical Chinese Poetry Knowledge Base for translation. To investigate which specific knowledge is more effective in translating Classical Chinese Poems within knowledge-based transla- tion methods, this experiment employed a modified RAT method that used only one type of retrieved knowledge at a time and removed the Voter module (Figure 4). The experimental results are presented in Figure 7.\nOn the one hand, retrieval-based translation methods showed overall performance improve- ment, indicating that knowledge plays a significant role in the task of translating Classical Chinese Poetry. On the other hand, the results revealed that knowledge of modern Chinese translation contributed the most to performance enhancement. This suggests that there are differences in form, semantics, and rhythm between Classical Chinese Poems and modern Chinese, further demonstrating the considerable challenges of directly translating Classical Chinese Poetry.\n8.3 Translation Challenges Across Different Types of Classical Chinese Poetry\nTo explore the translation difficulty of different types of poems (Tang, Song, and Yuan) in the collected 608 Chinese Classical Poems, we employed the RAT method to generate translation results for each poetry type. These results were then evaluated using LLM-BF, LLM-BM, LLM- BS, and LLM-AVG. From the experimental results, we can observe that the translation trends are consistent across different types. Firstly, the translation of Tang poetry is relatively easier compared to other types, likely due to its stricter format and fewer words. Secondly, the lower scores of LLM-BF and LLM- BS indicate that the translation of poetic structure and rhythm remains a significant challenge for LLMs. Lastly, the generally higher results of LLM-BM suggest that retrieval-based methods can produce more adequate translations."}, {"title": "9 Conclusion", "content": "Our research reveals the challenges LLMs face in translating classical Chinese poetry, especially in cultural knowledge, fluency, and elegance. We introduced the Retrieval-Augmented Translation (RAT) method and a GPT-4-based evaluation metric to improve translation quality. This first comprehensive evaluation exposes LLMs\u2019 limitations and suggests areas for improvement, aiming to inspire better culturally informed translations."}, {"title": "A Human Evaluations", "content": "In this section, we conduct a human evaluation to measure translation quality. We assess ambiguity resolution. Four native English speakers were invited to participate. In the Adequacy sentence- level task, the four experts scored each sentence for ambiguity resolution against the reference, awarding 1 point for resolved and 0 points for unresolved."}]}