{"title": "Joint Knowledge Editing for Information Enrichment and Probability Promotion", "authors": ["Wenhang Shi", "Yiren Chen", "Shuqing Bian", "Xinyi Zhang*", "Zhe Zhao*", "Pengfei Hu", "Wei Lu", "Xiaoyong Du"], "abstract": "Knowledge stored in large language models requires timely updates to reflect the dynamic nature of real-world information. To update the knowledge, most knowledge editing methods focus on the low layers, since recent probes into the knowledge recall process reveal that the answer information is enriched in low layers. However, these probes only and could only reveal critical recall stages for the original answers, while the goal of editing is to rectify model's prediction for the target answers. This inconsistency indicates that both the probe approaches and the associated editing methods are deficient. To mitigate the inconsistency and identify critical editing regions, we propose a contrast-based probe approach, and locate two crucial stages where the model behavior diverges between the original and target answers: Information Enrichment in low layers and Probability Promotion in high layers. Building upon the insights, we develop the Joint knowledge Editing for information Enrichment and probability Promotion (JEEP) method, which jointly edits both the low and high layers to modify the two critical recall stages. Considering the mutual interference and growing forgetting due to dual modifications, JEEP is designed to ensure that updates to distinct regions share the same objectives and are complementary. We rigorously evaluate JEEP by editing up to thousands of facts on various models, i.e., GPT-J (6B) and LLAMA (7B), and addressing diverse editing objectives, i.e., adding factual and counterfactual knowledge. In all tested scenarios, JEEP achieves best performances, validating the effectiveness of the revealings of our probe approach and the designs of our editing method. Our code and data are available at https://github.com/Eric8932/JEEP.", "sections": [{"title": "Introduction", "content": "Large Language Models (LLMs) are renowned for their extensive knowledge storage, addressing queries by recalling the encoded knowledge (Petroni et al. 2019; Touvron et al. 2023). However, their original knowledge might be incorrect or outdated due to the swift pace of global events, demanding timely updates to this stored information (Jang et al. 2022). For instance, the answer \"France\" to the query \"World Cup's winner is\" remains valid until year 2022, but now \"Argentina\u201d is the correct response. Common methods like retraining model with revised corpora is prohibitively costly, while continually fine-tuning on the corrected dataset causes catastrophic forgetting (McCloskey and Cohen 1989; Kirkpatrick et al. 2017; Shi et al. 2023). Consequently, there is a growing interest in Knowledge Edit, whose goal is to update the model's original knowledge to the target knowledge both efficiently and accurately (De Cao, Aziz, and Titov 2021; Mitchell et al. 2022).\nKnowledge editing methods can be categorized based on whether they modify model parameters (Yao et al. 2023). Weight-preserved methods incorporate additional structures to handle each editing requirement, facing scalability issues as the number of edits increases. (Huang et al. 2023; Hartvigsen et al. 2024; Yu et al. 2024). Therefore, we focus on weight-modified methods, which could accommodate considerable updates in a single operation, and include two distinct methods (Meng et al. 2022b; Tan, Zhang, and Fu 2023; Li et al. 2024). Meta-learning methods train hyper-networks for generating updated parameters, suffering from poor generalization when edits increase (Mitchell et al. 2021; Tan, Zhang, and Fu 2023). Locate-then-edit methods locate primary storage locations of knowledge, by probing into model's recall process of the original answers, then edit the specific locations (Dai et al. 2021; Meng et al. 2022a). Recent explorations show that the output answer processing in LLMs involves two critical phases: information enrichment in low layers and answer extraction in middle layers (Meng et al. 2022a; Geva et al. 2023). Building on the insights, locate-then-edit methods all focus updates on the low layers (Meng et al. 2022a,b; Li et al. 2024).\nDespite the demonstrated capability of existing locate-then-edit methods for large-scale knowledge editing (Meng et al. 2022b; Li et al. 2024), their effectiveness is hampered by the inconsistency between the probe approaches for original answers and the editing goals for target answers. Previous probes assess the impact of ablating specific modules by comparing the probabilities of the original answers in model's predictions before and after such interventions. This reliance on final probabilities limits their applicability to the target answers, which have low probabilities in the predictions. However, the stages vital for effective knowledge editing do not merely align with those critical for recalling original answers, but are distinctively associated with the stages where the model's behavior diverges between the original and target answers. To rectify the inconsistency, we propose a contrast-based probe approach. It observes the answer's probability across different representations as in Fig. 1, which depicts the original answer's information flow through each layer (nostalgebraist 2020). By contrasting information changes of the original and target answers, we identify two critical stages for knowledge editing: Information Enrichment in low layers and Probability Promotion in high layers. The low layers enrich answer-related information to the representations, and the high layers promote answer's probability to make it the final output.\nBuilding on these insights, we develop the JEEP method, which strategically targets both low and high layers for a holistic alternation of knowledge recall process. It jointly edits layers responsible for information enrichment and probability promotion stages. However, modifications to different model regions can interact in complex ways, potentially leading to conflicting outcomes. To ensure the updates are not only cohesively integrated but also complementary, JEEP first synergizes the optimization objectives of both updates. It then adaptively adjusts the update degree for different layers based on the information changes required at each recall stage, thereby effectively altering model's predictions with minimal parameter changes. To validate our method, we conduct extensive experiments involving edits ranging from 1 to 10,000 across various model architectures, including GPT-J (6B) and LLaMA (7B) (Wang and KomatsuzaKi 2021; Touvron et al. 2023), and datasets such as zsRE and Multi-COUNTERFACT (Levy et al. 2017; Meng et al. 2022b). In all tested scenarios, JEEP consistently delivers the optimal performances, confirming the effectiveness of our methodological designs and validating our probe approach to identify critical editing stages."}, {"title": "Related Work", "content": "Probe approaches into knowledge recall process try to elucidate a model's internal processing of the output answers (Olah 2022; Gurnee et al. 2023; Bills et al. 2023), where our focus is on critical regions for knowledge editing (Katz and Belinkov 2023). It is widely believed that the Multi-Layer Perceptron (MLP) module serves as a primary repository of knowledge (Geva et al. 2020; Dai et al. 2021; Kobayashi et al. 2023), and numerous studies analyze its behavior as key-value memories (Geva et al. 2022; Dar et al. 2022). By restoring corrupted hidden states, (Meng et al. 2022a) reveals that early-to-middle MLP layers enrich subject-related factual information in representations of subject's last token, thereby pinpointing a more specific knowledge storage location. Regarding the Multi-Head-Self-Attention (MHSA) module, (Dar et al. 2022) shows that MHSA parameters also encapsulate knowledge. Further, (Geva et al. 2023) blocks the attention computations to trace detailed information flows of final predictions, underscoring MHSA's role in extracting answers to the prediction position. These findings outline the critical stages of the knowledge recall process. However, the used ablation-based probes only and could only reveal critical stages for the original answers, failing to provide complete critical regions for knowledge editing, which aims to edit for the target answers. By observing and contrasting the original and target answers' information changes across layers, we endeavor to resolve the inconsistency and provide a more comprehensive understanding of the knowledge recall process for effective editing.\nKnowledge editing methods can be categorized into two lines based on whether they modify model parameters. Weight-preserved methods incorporate additional structures to handle incoming editing demands, such as new neurons (Huang et al. 2023), scope classifiers with counter-factual models (Mitchell et al. 2022), adapters (Hartvigsen et al. 2024), LORA modules (Yu et al. 2024), and in-context learning examples (Zheng et al. 2023). But they are not scalable, as they become more costly and less effective"}, {"title": "Preliminaries", "content": "In a decoder-only language model $F_\\theta$ (Brown et al. 2020), the input sequence $[X_1,X_2, ..., X_E]$ goes through $D$-layer computations, and the last token representation in the final layer $h_D$ would be mapped to the vocab distribution through the language model (LM) head $W_{lm}$, to decode the probabilities of the next token $X_{E+1}$:\n$F_\\theta([X_1,X_2...X_E]) \\simeq P_E = softmax(W_{lm}(h_D)).$ \nSo the representation $h_D$ encodes information of the next token. This information is accumulated during $D$-layer residual connections:\n$h_D = h_0 + \\sum_{l=1}^{D} (a_l + m_l)$,\nwhere $a_l = W_O^{MHSA}MHSA(LN(h^{l-1}), h^{l-1},...,h^{l-1})$\n$m_l = W_O^{MLP}MLP(LN(W_I^{MLP}(h^{l})))$,\nand $h_0$ is the embedding and $LN$ denotes layer normalization.\nLLM $F$ has encoded abundant knowledge in its parameters:\n$K_F = \\{(x_i, y_i)_{i=1}^n, F(x_i) = y_i\\}$,\nwhere $K_F$ is the original knowledge in the model and $(x_i, y_i)$ denotes a input prompt and answer pair. Given a knowledge pair $(x, y)$, such as (World Cup's winner is, France), there are two responding sets: Equivalent Set $E(x, y)$, containing all semantically equivalent knowledge pairs to $(x, y)$, an example would be (Who is the World"}, {"title": "Method", "content": "Exploring the knowledge recall process aids in designing effective knowledge editing methods (Meng et al. 2022b; Li et al. 2024). But existing probes could only locate prominent regions for original answers, which is inconsistent to the knowledge editing for target answers. To mitigate this, we propose a contrast-based probe approach and identify two critical recall stages for editing (\u00a74.1). Based on our discoveries, we develop JEEP to more thoroughly modify the knowledge recall process to alter model predictions, while addressing the issues associated with joint updates (\u00a74.2).\nOur probe contrasts the detailed information flow of the original and target answers across different representations. Guided by the probe, we identify two critical editing stages: Information Enrichment in low layers and Probability Promotion in high layers.\nSince previous ablation-based probes fail to analyze the target answers, we directly observe and contrast the differences in the information flow between the original and target answers. Extended from Eq. 2, representation at any position i and any layer l is refined by residual connections. So the LM head's mapping could be applied to any representation $h_i^l$ (nostalgebraist 2020):\n$P_i^l = softmax(W_{lm}(h_i^l))$.\nRecording the probability $P(t)$ of the answer's first token $t$ within the distribution $P_i^l$, we can observe the complete information flow of answers inside the model. But probability only reflects absolute information and are often very low for the target answers. Therefore, we further calculate the rank of the target token $t$ in the distribution:\n$rank(t/P) = \\sum_{t' \\neq t} 1(P(t') > P(t))$.\nNote that the subsequent \"increase\u201d for rank indicates the rank value is approaching 0, and the representation contains"}, {"title": "Joint Knowledge Editing", "content": "Based on the observations above, we develop the JEEP method, which edits both the low and high layers, specifically targeting the MLP modules therein, to simultaneously modify the stages of information enrichment and probability promotion. Initially, we outline the comprehensive process of the joint editing. Subsequently, we present two challenges associated with dual updates, mutual interference and increased forgetting, and our tailored designs to solve them.\nTo revise the knowledge recall process more completely, we edit the MLP modules in both low layers $[l', L']$ and high layers $[l^*, L^*]$. We analyze the MLP module as a key-value memory, where $W_I^l$ encodes input into key vectors and $W_O^l$ maps keys to output values containing knowledge. Suppose the model memorizes n pieces of original knowledge $(x_i, y_i)_{i=1}^n$, we have n mappings encoded in $W_O^l$:\n$W_O^lK_O = V_O, \\quad K_O = [k_1|k_2|...k_n], \\quad V_O = [v_1 | v_2 |... | v_n]$.\nTo edit m knowledge pairs, we update the model in three steps as shown in Fig. 3. Firstly, for every target knowledge pair $(x_i, y')$, we calculate the corresponding value vector $v_i$ (i \u2208 {i', i*}, L \u2208 {L', L*}) to replace the current hidden state $h_i^l$, at subject last position i' and prediction position i* in last critical layer L' and L*. We optimize the residual vector $\u03b4$ ($\u03b4 \u2208 {\u03b4', \u03b4*}$) by gradient descend to alter model's prediction on $x$ to $y'$ (Step1):\n$v_i^l = h_i^l + argmin_\\delta \\frac{1}{P} \\sum_{j=1}^P L_F(h_i^l + \\delta) [Y' | P_j + x]$.\nDifferent prefixes $p_j$ are used to bolster generalization. We formulate the editing to adding m new mappings while preserving the existing n ones with minor change $\u0394$ to $W_O^l$:\n$(W_O^l + \\Delta)[K_O|K_1] = [V_O|V_1], \\quad K_1 \\simeq [k_{n+1}|...|k_{n+m}], \\quad V_1 = [v_{n+1} |... | v_{n+m}]$.\nBy derivation in (Meng et al. 2022b), we could obtain:\n$\\Delta = R K_1^T (C_O + K_1 K_1^T)^{-1}$,"}, {"title": "Experimental Setup", "content": "We conduct experiments on two models, GPT-J (6B) (Wang and KomatsuzaKi 2021) and LLaMA (7B) (Touvron et al. 2023), which feature parallel and sequential MHSA and MLP modules, respectively. Based on the three objectives of knowledge editing, we evaluate three corresponding key metrics: Efficacy Success (ES), Generalization Success (GS) and Locality Success (LS), then compute their harmonic mean Score as in (Meng et al. 2022b) (see Appendix C for detailed descriptions). For baselines, we first consider FT-WD, fine-tuning with weight decay to prevent forgetting (Zhu et al. 2020). Next, for meta-learning-based methods, we include MEND and its improved version MALMEN, which further supports multiple facts' editing at once (Mitchell et al. 2021; Tan, Zhang, and Fu 2023). Finally, we compare with locate-then-edit methods: ROME, MEMIT and PMET (Meng et al. 2022a,b; Li et al. 2024). Since ROME originally targets one fact at a time, we adapt it to a sequential version to accommodate massive edits (Meng et al. 2022b). We evaluate editors' ability to add factual knowledge (\u00a75.2), and further evaluate the capability to add counterfactual knowledge (\u00a75.3), which is a more challenging scenario. Implementation details are in Appendix D."}, {"title": "Adding Factual Knowledge", "content": "The primary goal of Knowledge Edit is to correct inaccuracies in the model's original knowledge. Initially, we evaluate the editing methods' abilities to"}, {"title": "Adding Counter-Factual Knowledge", "content": "We next shift to a more challenging scenario: evaluating methods' capabilities in injecting counterfactual information. We edit 10,000 samples from the Multi-COUNTERFACT dataset (Meng et al. 2022b), where the editing updates original correct answers to target incorrect answers. The evaluation for successful editing is more lenient, and the metrics calculate the proportion of cases where the generation probability of the target incorrect answer exceeds that of the original correct answer (Appendix C). But as for locality, a higher probability of the original correct answer is considered successful. Given the difficulty for adding this artificially constructed erroneous knowledge, it's challenging for editing methods to excel in the efficacy, generalization, and locality simultaneously. As illustrated in Table 3, no method consistently exceeds the others across all metrics. In this unnatural setting, our JEEP method achieves the best efficacy and near-best generalization and locality, leading to optimal overall performance. This indicates that more comprehensive modifications of critical knowledge recall stages are also beneficial for adding counterfactual knowledge, validating the effectiveness of our probe findings and editing method.\nTo evaluate the scalability of our method, we compare the performance of methods capable of handling 10,000 edits as the number of edits m increases1. As shown in Fig. 4, JEEP consistently delivers better overall results, with the improvements becoming more pronounced"}, {"title": "Ablation Study", "content": "To elucidate the contributions of updates from different regions and various designs in JEEP, Table 4 presents the results of different ablation variants, editing 10,000 samples from Multi-COUNTERFACT on LLaMA.\n1) Initially, to assess JEEP's design of dual-region modifications, we examine single-region editing. In w/o \u03b4' & Step2 and w/o \u03b4*& Step3, only one residual vector in Eq. 8, either \u03b4* or \u03b4', is computed and used to update the high or low layers respectively. They both underperform compared to JEEP, underscoring the advantage of updating both regions. Notably, editing the lower layers along performs better, suggesting that without the information enrichment from the lower MLP, modifying probability promotion alone is less effective. Additionally, w/o Step2 or w/o Step3 keeps the simultaneous computation of \u03b4' and \u03b4*, but subsequently updates only one region. This approach considers the interplay between updates but limits the actual modification to one regions. As with previous findings, single-region editing yields inferior results compared to JEEP, with lower-layer editing still shows better outcomes. However, compared to computing only one \u03b4, the dual computations of \u03b4 performs worse, suggesting a more holistic consideration of the critical recall stages without corresponding updates may instead harm the editing effect. JEEP improves this by adaptively updating both regions, achieving a more balanced distribution of information changes and superior performance.\n2) Moreover, we ablate the designs in JEEP. Separate Optimization deviates from JEEP's synergistic design in Eq. 11, by independently computing \u03b4' and updating the low layers before computing \u03b4* and updating the high layers. Its performance is not only inferior to JEEP but also worse than single-region editing, indicating that isolating the optimization of two regions leads to mutual interference between them. In addition, Even Spread in Step2 replaces the excessive updates to the low layers by spreading the residual errors evenly: $r = \\frac{r}{L'-l'+1}$. It performs worse than JEEP, achieving better locality at the cost of efficacy and generalization, but still outperforms updating one region. Furthermore, considering the computational similarities between $W_O$ in MLP and MHSA, w/MHSA in Step3 instead edits MHSA in high layers. Although this adjustment does not outperform JEEP, it shows improved performance over single-region editing, indicating that both MLP and MHSA could promote answer's probability in the upper layers.\nThese ablation studies not only validate the insights from our probe experiments but also demonstrate the effectiveness of the design choices in JEEP."}, {"title": "Conclusion", "content": "In this study, we discover the inconsistency between existing probe approaches for the original answers and the knowledge editing goal for the target answers. To address the inconsistency, we propose a contrast-based probe approach, identifying two critical knowledge recall stages for editing: Information Enrichment in low layers and Probability Promotion in high layers. Based on these insights, we develop JEEP, a joint editing method targeting both low and high layers to modify the information enrichment and probability promotion stages simultaneously. Through synergistic optimization and adaptive updates, JEEP addresses the challenges of mutual interference and increased forgetting associated with updating different model regions, consistently achieving superior performance across various edit scales, models, and datasets."}, {"title": "Appendix", "content": "In \u00a74.1, we investigate the fine-grained information changes of the original and target answers during the knowledge recall process within the model. We utilize the Multi-COUNTERFACT dataset (Meng et al. 2022b), in which each editing sample includes an input prompt, the corresponding correct answer and incorrect answer as shown in Fig. 8. We use the correct answer as the model's original answer and the incorrect answer as the target editing answer, the same as the original usage of this dataset. The incorrect answer is related to the correct answer, satisfying the relation. By comparing the information changes in the representations of these two answers, our exploratory experiments not only corroborate previous findings on model interpretability but also uncover a critical process for knowledge editing: Probability Promotion. However, in the higher layers, the probability of the final output at the prediction position does not consistently increase, instead, it decreases in the topmost layers. To investigate the mechanisms behind this prediction elimination phenomenon, we extend our probing method to additional categories of information."}, {"title": "Probe on Related Information", "content": "In addition to the original correct answers, we construct word sets representing different information related to each input prompt (<subject, relation, object>). Below we elaborate the process of formulating these sets. Firstly, we collect all the words related to the current factual statement. Using the subject and relation as query, we extract the top 100 relevant paragraphs from English Wikipedia by BM25, keeping paragraphs where the subject appears in either the title or content (Geva et al. 2023). After dedeuplicating and removing the object, we get a word set $S_{related}$ to the specific factual statement. factual words by using GPT-4. For the subject, we ask GPT-4 to generate factual information related to it, including potential relations and their corresponding objects. Similarly, for each relation, GPT-4 is tasked with producing lists of subjects and objects sharing the specified relation. GPT-4 generates 50 candidates for each subject or relation. The resulting deduplicated collection forms the factual-related word set $S_{factual}$. We observe that stopwords are indispensable regardless of whether a sentence related to factual information. Therefore, we construct $S_{stop}$, comprising various non-informative words such as punctuation, conjunctions, prepositions, and others. Set. Excluding $S_{factual}$ and $S_{stop}$ from $S_{related}$ results in the non-factual word set $S_{non-factual}$. Notably, while there is no overlap in the words among the $S_{factual}$, $S_{non-factual}$ and $S_{stop}$, tokenization may introduce overlapping tokens, which does not substantially alter the general trend of information variation.\nAs in \u00a74.1, we input the 10,000 factual prompts to LLaMA (7B) and record the information changes of these sets at the last prediction position in Fig. 5, indicated by"}, {"title": "Probe on Unrelated Information", "content": "Apart from the related information, we also investigate the change of unrelated information. We apply the same probe approach to examine the variations in information content within the left token set $S_{unrelated}$. This set is derived by excluding the aforementioned four word sets and the original correct answer from the entire vocabulary, followed by tokenization and deduplication. In Fig. 5, initially, a considerable amount of non-relevant information is present, as anticipated. With the progression to higher layers, this information continually diminishes. Intriguingly, in the high layers, such non-relevant information experiences a resurgence. This observation corroborates our hypothesis that the model's higher layers function to regulate and balance the overall information. However, this resurgence of irrelevant information is not as pronounced as that of stopwords at higher levels, implying there is a focus in the model's smoothing mechanism. Given that stopwords are ubiquitous in all texts, the model's tendency to smooth the distribution at higher levels seems aimed at aligning the output more closely with an realistic information distribution."}, {"title": "Analysis of Joint Updates", "content": "In Section 4.3, we argue that changes in the low layers' information enrichment should be greater than the changes in the high layers' probability promotion, meaning the clamp ratio \u03b3 corresponding to the lower layers should be larger"}]}