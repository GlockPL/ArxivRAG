{"title": "MCDDPM: Multichannel Conditional Denoising Diffusion Model for Unsupervised Anomaly Detection in Brain MRI", "authors": ["Vivek Kumar Trivedi", "Bheeshm Sharma", "P. Balamurugan"], "abstract": "Detecting anomalies in brain MRI scans using supervised deep learning methods presents challenges due to anatomical diversity and labor-intensive requirement of pixel-level annotations. Generative models like Denoising Diffusion Probabilistic Model (DDPM) [1] and their variants like Patch-based DDPM (pDDPM) [2], Masked DDPM (mDDPM) [3], Conditional DDPM (cDDPM) [4] have recently emerged to be powerful alternatives to perform unsupervised anomaly detection in brain MRI scans. These methods leverage frame-level labels of healthy brains to generate healthy tissues in brain MRI scans. During inference, when an anomalous (or unhealthy) scan image is presented as an input, these models generate a healthy scan image corresponding to the input anomalous scan, and the difference map between the generated healthy scan image and the original anomalous scan image provide the necessary pixel level identification of abnormal tissues. The generated healthy images from the DDPM, pDDPM and mDDPM models however suffer from fidelity issues and contain artifacts that do not have medical significance. While CDDPM achieves slightly better fidelity and artifact suppression, it requires huge memory footprint and is computationally expensive than the other DDPM based models. In this work, we propose an improved version of DDPM called Multichannel Conditional Denoising Diffusion Probabilistic Model (MCDDPM) for unsupervised anomaly detection in brain MRI scans. Our proposed model achieves high fidelity by making use of additional information from the healthy images during the training process, enriching the representation power of DDPM models, with a computational cost and memory requirements on par with DDPM, pDDPM and mDDPM models. Experimental results on multiple datasets (e.g. BraTS20, BraTS21) demonstrate promising performance of the proposed method.", "sections": [{"title": "I. INTRODUCTION", "content": "Medical imaging systems are essential for radiologists, aiding in precise diagnosis and patient care decisions by offering detailed visualizations [5]. Magnetic Resonance Imaging (MRI) segmentation is crucial to identify anomalies like necrosis and edema [6], which are often clearly visible on T2-weighted (T2w) images [7]. When extensive pixel level labeling is not available, Unsupervised Anomaly Detection (UAD) is useful where several techniques like level sets [8], graph cuts [9], AutoEncoders (AEs), Variational AutoEncoders (VAEs) [10], and Generative Adversarial Networks (GANs) [11] are available.\nRecently, generative models like denoising diffusion probabilistic models (DDPMs) [1] have garnered significant attention for their capability to produce high-quality images by removing noise from corrupted inputs. DDPM uses the idea of diffusion [12], and preserves spatial information in its hidden layer representations, crucial for maintaining the structural integrity, sharpness and high fidelity of the generated images [13]. Patch-based DDPM (pDDPM) [2] improves the preservation of anatomical consistency by reconstructing separate patches of the MRI scans, ensuring that particular brain structures maintain their position consistently between input and reconstructed images. Another improved variant called mDDPM [3] integrates Masked Image Modeling (MIM) and Masked Frequency Modeling (MFM) techniques within DDPM framework, offering superior generalization abilities. Context-conditioned DDPM (cDDPM) [4] improves anatomical coherence and aligned intensity characteristics in MRI scans by incorporating latent feature representations of noise-free input images into the denoising process and conditioning the model on contextual information. However, cDDPM requires a separate model for contextual information, leading to increased parameter count and computational complexity. Despite slight improvements, CDDPM too suffers from similar challenges as the other DDPM models in accurate reconstruction of MRI scans.\nOur Contributions: In this work, we propose an approach called Multichannel Conditional DDPM (MCDDPM) which addresses the shortcomings of other DDPM models by incorporating multichannel information (latent representations of noisy images derived from a suitable network) and robust conditioning mechanisms. This extra context, provided through multiple channels, improves the accuracy and realism of the final images. The proposed MCDDPM integrates the contextual information directly without the need for separate models and extra trainable parameters, thus simplifying model design. Our experiments on several benchmark datasets show that MCDDPM is efficient and effective in producing high-quality reconstructions, aiding in precise pixel level localization of anomalous regions in brain MRI scans."}, {"title": "II. RECENT WORK", "content": "UAD in brain MRI using AutoEncoders (AEs) for reconstruction has been popular; however, blurry reconstructions limit the effectiveness of AEs in UAD [10]. Incorporating skip connections with dropout [14] and employing feature activation maps [15] have shown to improve the quality of both the learned representations and reconstructions of AEs. Furthermore, [16] proposed online outlier removal for AEs to enhance their UAD performance. Despite this, AEs can fall prey to a \"copy task\" phenomenon, where AEs unintentionally reconstruct abnormal anatomies, hindering their UAD efficacy [17]. Regularizing AEs with an additional denoising task [18] has helped in tackling this copy task issue. Variational AutoEncoder (VAE) based approaches with stronger contextual understanding based on 3D MRI data have also emerged popular [19], along with restoration techniques [20] and the fusion of VAEs with GANs [21].\nRecent advancements in DDPM have shown promise in comprehensive tissue reconstruction in brain MRI [13]. While DDPM excels in fidelity, it often encounters information loss during the noising process. Patch-based DDPM (pDDPM) [2] mitigates this drawback by incorporating original image content for reconstruction. However, pDDPM introduces complexity and computational overhead in processing multiple patches of the same image, resulting in artifacts in regions with overlapping patches. Alternatively, conditioning DDPM with input image knowledge has demonstrated efficacy in various tasks [4], however at the cost of leveraging a secondary model for latent representation acquisition. Due to these limitations, none of these models alone can completely reconstruct healthy tissue. Our proposed MCDDPM aims to address the challenges of DDPM variants and avoids reliance on a secondary architecture for conditioning."}, {"title": "III. PROPOSED METHODOLOGY", "content": "In this section, we first briefly introduce DDPM architecture, followed by details of our proposed model called MCDDPM."}, {"title": "A. DDPM", "content": "Denoising Diffusion Probabilistic Model (DDPM) serves as a generative model aimed at learning the underlying data distribution. Consider an underlying (unknown) image data distribution $q(x)$ and let $X_0$ denote an image sampled from $q(x)$, where $X_0 \\in \\mathbb{R}^{h \\times w}$, with $h$ denoting height and $w$ representing width. Training DDPM involves a two-step process comprising a forward and backward phase.\nIn the forward phase, input image $X_0$ undergoes iterative noise addition resulting in successive noisy images $X_t, t\\in [T] := \\{1,2,...,T\\}$, where $T$ denotes the total number of time-steps. At T-th time-step, the image becomes completely Gaussian noise, hence $X_T = \\epsilon_T \\sim \\mathcal{N}(0, I)$. Noise addition at time-step t is characterized using a Gaussian as follows:\n$q(X_t|X_{t-1}) = \\mathcal{N}(X_t; \\mu_t = \\sqrt{1 - \\beta_t}X_{t-1}, \\sigma^2 = \\beta_t I)$\nwhere $\\beta_t$ represents a predefined variance scheduler. Typically, $\\beta_0 = 10^{-4}$ and $\\beta_T = 0.02$ [1], with $\\beta_t = \\frac{t}{T}(\\beta_T - \\beta_0)$. The time-step t sampled from $t \\sim \\text{Uniform}([T])$ controls the amount of noise. After applying parameterization trick, we obtain:\n$X_t \\sim q(X_t|X_0) = \\mathcal{N}(X_t; \\mu_t = \\sqrt{\\bar{a}_t} X_0, \\Sigma^2 = (1 - \\bar{a}_t)I)$\nwhere $\\bar{a}_t = \\prod_{i=1}^t a_i$ and $a_t = 1 - \\beta_t$.\nIn the backward phase, the aim is to generate a denoised $X_0$ from noisy $X_t$, by sampling from the conditional probability distribution $p_\\theta(X_0|X_t) = \\mathcal{N}(\\mu_\\theta(X_t, t), \\Sigma_\\theta(X_t, t))$. Following [1], $\\mu_\\theta$ is approximated using a U-Net architecture [22] with learnable parameters denoted by $\\theta$, while $\\Sigma_\\theta(X_t, t) = \\Sigma(t) = \\frac{1-a_t}{1-\\bar{a}_{t-1}} \\beta_t I$ is directly computed. Then a suitable variational lower bound (VLB) is formulated, which leads to the reconstruction of noise at time-step t using a reconstruction error $[1]: L_{rec} = ||\\epsilon_t - \\epsilon_\\theta(X_t, t)||^2$, where $\\epsilon_t = \\frac{X_t - \\sqrt{\\bar{a}_t} X_0}{\\sqrt{1-\\bar{a}_t}}$ and $\\epsilon_\\theta$ is obtained using the U-Net architecture parametrized by $\\theta$. Instead of directly predicting the noise, the estimation of $X_0 = \\frac{X_t - \\sqrt{1-\\bar{a}_t} \\epsilon_t}{\\sqrt{\\bar{a}_t}}$ is pursued in [2], leading to the loss function $L_{rec} = ||X_0 - \\hat{X}_0||^2$. The major goal of DDPM is to generate images, hence the backward process usually involves refining a random noise vector through incremental backward steps to reduce noise. However, in the context of UAD task at hand, our objective is not to generate images, but to predict brain tissue anatomy based on an input image. As a result, during inference, we directly predict $X_0$ from $X_t$ by following the methodology outlined in [4]."}, {"title": "B. MCDDPM", "content": "Now we illustrate details of our proposed method called Multichannel Conditional DDPM (MCDDPM), which improves DDPM [1] and their variants, by introducing controlled noise into brain MRI imaging data. Typically brain MRI scans are available as 3D volumetric data of shape $\\mathbb{R}^{h\\times w \\times d}$ (e.g. NIfTI volumes [23]). We propose to use the 2D slices (or frames) of shape $\\mathbb{R}^{h\\times w}$ sampled from the 3D volumes in our approach. Initially, a slice denoted as $X_0$ is extracted from the volumetric data and using the forward diffusion process, we generate a fully noisy image ($X^*$) of shape $\\mathbb{R}^{h\\times w}$, where the noise is added to all pixels of $X_0$. Along with $X^*$, we also generate a patched noisy image using the forward diffusion, where noise is added only to a patch of $X_0$, resulting in $X^P$ of shape $\\mathbb{R}^{h\\times w}$. Thus before invoking the backward diffusion phase, we have information from three different sources, including the fully noisy image ($X^*$), the original image ($X_0$), and a patched noisy image ($X^P$). To facilitate effective reconstruction of brain anatomy from the noisy data, note that we used patched noisy image $X^P$ in our forward diffusion, inspired from pDDPM [2]. For this purpose, we designed patches with varying sizes ($h_k < h$ and $w_k < w$, for $k\\in[1,2,3...K]$) along with their corresponding binary masks $M_k$ of shape $\\mathbb{R}^{h \\times w}$, to locate specific patch regions within the larger images marked for noise addition. Further $X^*$ is fed into a multichannel bridge network $B_\\theta$ parametrized by $\\theta$, which provides a multichannel latent representation $Z$, capturing multiple intermediate representations of $X^*$. Our multichannel diffusion process leverages a U-Net architecture [22] for image reconstruction. We propose a conditioning approach to enhance the performance of DDPM by integrating a context vector $C$ (construction of $C$ will be described later) into the backward process. This integration is realized through a modification of the denoising U-Net architecture within the DDPM framework. Specifically, we substitute the bottleneck self-attention layer in the U-Net with a cross-attention (CA) layer (see Attention Block in Fig. 1), enabling the model to attend to both information-rich intermediate representations of input data and other contextual information. To facilitate this modification, we partition the U-Net into two segments: the downsampling steps leading up to the bottleneck stage ($U_\\downarrow(.)$) and the steps following the bottleneck stage ($U_\\uparrow(.)$). By doing so, we can delineate the processing steps before and after integrating the context vector.\nNow we are ready for the backward diffusion process. First, the contextual information is obtained in the following manner. The original clean image $X_0$ is concatenated with the multichannel latent representation $Z$ and fed into the encoder $U_\\downarrow$, along with the time embedding corresponding to zero-th time-step (associated with clean image $X_0$), leading to encoding of the form $U_\\downarrow(X_0 \\oplus Z, t_0)$. This encoding serves as the contextual information from the clean image and will be subsequently employed for the cross-attention. Next, the patched noisy image $X^P$ is concatenated with $Z$ and fed into the encoder $U_\\downarrow$ to yield encoding of the form $U_\\downarrow(X^P \\oplus Z, t)$, where appropriate time embedding is used in the encoder, corresponding to the time step t used in noise addition during the forward diffusion process to create $X^P$. Note that the multichannel information from two different sources $X_0 \\oplus Z$ and $X^P \\oplus Z$, corresponding respectively to the clean image $X_0$ and the patched noisy image $X^P$ provide the encoder with sufficiently rich information, which can be useful for learning effective structural information of tissue anatomy of brain MRI images. The context vector $C$ is then taken to be the contextual encoding $U_\\downarrow(X_0 \\oplus Z, t_0)$. Subsequently, a cross-attention is performed on the context vector $C$ and $U_\\downarrow(X^P \\oplus Z, t)$ to extract correlations between the different encodings. This cross-attended information is passed to the decoder $U_\\uparrow$ to decode the reconstructed clean image $\\hat{X_0} \\sim p(X_T) \\prod_{t=1}^T p_\\theta(X_{t-1}|X_t, C)$. Thus the entire backward process can be represented as: $\\hat{X_0} = U_\\uparrow(CA(U_\\downarrow(X^P \\oplus Z, t), C))$ where $C \\sim U_\\downarrow(X_0 \\oplus Z, t_0)$.\nTo enhance the bridge network $B_\\theta$'s representational power, we feed the latent representation $Z$ obtained from the completely noisy image $X^*$ into another residual network $B_\\theta$, tasked with constructing $\\tilde{X} \\in \\mathbb{R}^{h \\times w}$ that retains the original characteristics and dimensions of $X_0$. Thus the overall loss for the proposed MCDDPM architecture consists of two components: a loss function for the reconstruction obtained at the decoder of U-Net and another for the reconstruction obtained at $B_\\theta$ (denoted by $L_U$ and $L_B$ in Fig. 1):\n$L = ||U_\\uparrow(CA(U_\\downarrow(X^P \\oplus Z, t), C)) - X_0||_p + \\lambda ||\\tilde{X} - X_0||_p$\nwhere $||.||_p$ denotes $l_p$ norm. This dual-term loss function ensures that the model captures both the contextual information through cross-attention and the essential features through the bridge network, enhancing the fidelity of the reconstructed image. The hyperparameter $\\lambda$ allows for balancing the importance of each term, providing flexibility in optimizing the reconstruction process tailored to specific applications or datasets."}, {"title": "IV. EXPERIMENTAL SETUP", "content": "In this section, we describe the datasets used and the data pre-processing and post-processing procedures used in our experiments."}, {"title": "A. Datasets", "content": "In this study, we leveraged four publicly available datasets to thoroughly evaluate our proposed methodology. Firstly, for training our proposed model, we utilized the IXI Dataset [24], which consists of 560 pairs of T1 and T2-weighted 3D volumes of brain MRI scans sourced from various institutions. Notably, this dataset exclusively comprises images of only healthy brains, making it particularly suitable for our training purposes. For evaluating the effectiveness of our approach, we integrated three additional datasets. The first one, namely the BraTS20 dataset [23], comprises brain MRI scans from patients diagnosed with brain tumors, namely gliomas. This dataset contains 369 3D brain MRI volumes and varies in clinical protocols and scanners from n = 19 different institutions. Secondly, we used the BraTS21 dataset [25], which is a widely used resource in the field, encompassing 2040 3D brain MRI scans obtained from patients diagnosed with gliomas. Importantly, both BraTS20 and BraTS21 datasets include detailed annotations in the form of pixel-level binary segmentation masks from expert neuro-radiologists, delineating tumor sub-regions with four different weightings (T1, T1-CE, T2, FLAIR). Thirdly, we utilized the multiple sclerosis dataset from the University Hospital of Ljubljana (MSLUB) [26], which includes 3D brain MRI scans from 30 patients diagnosed with multiple sclerosis. Each scan in this dataset is accompanied by T1, T2, and FLAIR-weighted images, with ground truth annotations derived from multi-rater consensus. From all these datasets, we used scans corresponding only to T2 modality."}, {"title": "B. Pre-processing", "content": "In the pre-processing stage, specific procedures were implemented to ensure the consistency and quality of the imaging data obtained from different sources. The IXI dataset [24] exhibits variations across MRI centers, hence measures were taken to standardize resolution and orientation. Initially, the resolution was adjusted to 1.0 \u00d7 1.0 \u00d7 1.0 and orientation to right anterior inferior (RAI) using B-Spline interpolation techniques. Due to the absence of skull stripping in the dataset, the HD-BET [27] architecture was used to perform this task efficiently. Following skull stripping, each volume underwent affine transformation to align it with the T2 modality volume of SRI24-Atlas [28], enhancing data compatibility. To further enhance data quality, non-relevant black regions within the volumes were eliminated, and N4 Bias field correction [29] was systematically applied to mitigate noise effects. For the BraTS20 [23], BraTS21 [25] and MSLUB [26] datasets, wherein skull stripping and registration had already been conducted, similar pre-processing steps were employed, including the removal of non-relevant black regions and the application of N4 Bias field correction for noise reduction. Moreover, for computational efficiency, the volume resolution was reduced by half, resulting in dimensions of [96 \u00d7 96 \u00d7 80] voxels. Additionally, to streamline the data, 15 slices from both the top and bottom, parallel to the transverse plane, were removed."}, {"title": "C. Implementation Details", "content": "In this study, all models are implemented using Pytorch (v2.1.2), with data handling and augmentation facilitated by torchio [30]. Intensity ranges are resampled between the 1st and 99th percentiles. During training, time steps are uniformly sampled from the interval [1, T], where T is set to 1000, while at test time, a fixed time step of $t_{test} = \\frac{T}{2} = 500$ is chosen. The model incorporates a linear schedule for $\\beta_t$, ranging from $10^{-4}$ to $2 \\times 10^{-2}$. Training proceeds for a maximum of 1600 epochs, where an epoch is defined based on processing one slice per volume randomly. The best-performing model checkpoint was selected based on the performance on the validation set containing only healthy images for BraTS21 and MSLUB datasets. However for BraTS20 dataset, we used the same checkpoint model obtained for BraTS21 dataset. Volumes are processed slice-wise, with slices uniformly sampled with replacement during training. Utilizing an NVIDIA RTX A5000 (24GB) GPU, training is performed using Adam optimizer [31], a learning rate of $10^{-5}$, and a batch size of 8. For the loss function, we utilize the formulation described in III-B. For the patched noisy image $X^P$, we employed k = 4, resulting in the patched shape h \u00d7 w was 48 \u00d7 48. For the multichannel bridge network (both $B_\\theta$ and $B_{\\theta'}$), we used two residual blocks, with each residual block being the same as described in [32]. For pDDPM [2], cDDPM [4] and mDDPM [3] models, the same setup as mentioned in their official GitHub repositories is adopted."}, {"title": "D. Post-processing", "content": "During the inference phase of anomaly detection in medical imaging, the input volume V, encompassing both healthy and unhealthy regions, is subjected to a reconstruction process, resulting in the reconstructed volume $\\hat{V}$. Following this step, anomaly maps $E_V$ are computed by measuring the residual between the input volume V and its reconstructed counterpart $\\hat{V}$ ($||E_V||_p = ||V - \\hat{V}||_p$), where higher values of $||E_V||_p$ indicate greater reconstruction errors. To mitigate false positives, a series of post-processing techniques are deployed on $E_V$, based on [2]. Initially, a 5 \u00d7 5 \u00d7 5 median filter is employed to eliminate minor residual regions, followed by a three-iteration erosion procedure using a brain mask derived from binarizing the input volume V. Subsequently, a binary map is obtained by thresholding the residual. In previous methods such as pDDPM [2], cDDPM [4] and mDDPM [3], the optimal threshold for segmentation was ascertained using a greedy search strategy on the validation dataset. However, it is improper to utilize segmentation masks from the validation data in an unsupervised setup. Hence, a fixed threshold from the set {0.1, 0.2, 0.3, 0.4, 0.5} was chosen, with results reported for the best threshold for all methods, consistently found to be 0.2."}, {"title": "V. RESULTS", "content": "In Table II, a comprehensive evaluation of segmentation methods across BraTS20, BraTS21 and MSLUB datasets is presented, emphasizing two primary metrics: the Dice coefficient and area under the precision-recall curve (AUPRC). Evaluation includes recent methodologies like DDPM [1], pDDPM [2], cDDPM [4] and mDDPM [3], initially trained on the IXI dataset for generation-based segmentation. These methods were trained on healthy brain images and tested on datasets containing both healthy and unhealthy brain images.\nThe evaluation setup for existing methods was consistent with their official repositories, and for MCDDPM, two loss functions corresponding to the p-norm values of p = 1 and p = 2, and $\\lambda = 0.5$ were employed, providing a comparative analysis. For IXI dataset, the reconstruction error obtained by all methods are reported.\nThe summarized results, as shown in Table II, demonstrate the performance of MCDDPM alongside existing methods across various datasets. MCDDPM with p = 1 outperforms existing methods on BraTS20, BraTS21 in terms of both Dice and AUPRC metrics. MCDDPM with p = 2 exhibits even higher performance than p = 1 achieving impressive Dice and AUPRC metrics on BraTS20 and BraTS21 datasets. Moreover, the reconstruction errors for MCDDPM (p = 1) and MCDDPM (p = 2) on the IXI dataset further validate their efficacy in image reconstruction. Qualitative results on a sample image from BraTS21 dataset provided in Fig. 2 show improved anomaly localization of MCDDPM. These findings underscore the superior performance of MCDDPM over existing methods across diverse datasets, suggesting its potential for various medical imaging applications. We conducted a separate analysis on the MSLUB data, calculating the dice score between the original masks and randomly generated binary masks. The resulting Dice score was approximately 4%. Considering that our model and other models in Table II achieved dice score \u2248 5%, these slight improvements may be attributed to impact of random noise and do not reflect actual model efficacy. Hence interpreting results obtained for MSLUB dataset should be done carefully."}, {"title": "VI. ABLATION STUDY", "content": "We first explored the effect of different $\\lambda$ values on the reconstruction performance of the bridge network. By experimenting with $\\lambda$ values in {0.5, 1,2}, we aimed to identify a suitable $\\lambda$ value that maximizes the bridge network's reconstruction capabilities. Secondly, to evaluate the significance of the bridge network within our architecture, we conducted experiments by excluding it and subsequently assessing the model's ability to reconstruct. This step allowed us to quantify the contribution of the bridge network to the overall performance. Lastly, we delved into the role of conditional features, specifically examining the importance of integrating the context vector C in the denoising U-Net architecture. By comparing the performance of the model with and without this integration, we sought to determine the impact of conditional features on the model's reconstruction efficacy. All ablation studies were performed with p = 2."}, {"title": "VII. CONCLUSION", "content": "In this paper, we have proposed MCDDPM, that employs a tailored U-Net architecture combined with a bridge network to improve image reconstruction in denoising diffusion probabilistic models (DDPM). Two key features of our approach stand out, namely the enhanced bridge network capable of extracting multichannel information from different forms of noisy images, and the integration of a context vector into the denoising process of DDPM enabled by substituting the bottleneck self-attention layer with a cross-attention layer in the U-Net, with no extra trainable parameters. These modifications allow the model to effectively incorporate both enhanced input data representations and contextual information, improving its adaptability and performance. Our comprehensive evaluation against state-of-the-art competing methods on diverse datasets demonstrates MCDDPM's superiority in terms of reconstruction capability and anomaly detection efficacy."}]}