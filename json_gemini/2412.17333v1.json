{"title": "Broadband Ground Motion Synthesis by Diffusion Model with Minimal Condition*", "authors": ["Jaeheun Jung", "Jaehyuk Lee\u2020", "Chang-Hae Jung", "Hanyoung Kim", "Bosung Jung", "Donghun Lee\u2260"], "abstract": "Earthquakes are rare. Hence there is a fundamental call for reliable methods to generate realistic ground motion data for data-driven approaches in seismology. Recent GAN-based methods fall short of the call, as the methods either require special information such as geological traits or generate subpar waveforms that fail to satisfy seismological constraints such as phase arrival times. We propose a specialized Latent Diffusion Model (LDM) that reliably generates realistic waveforms after learning from real earthquake data with minimal conditions: location and magnitude. We also design a domain-specific training method that exploits the traits of earthquake dataset: multiple observed waveforms time-aligned and paired to each earthquake source that are tagged with seismological metadata comprised of earthquake magnitude, depth of focus, and the locations of epicenter and seismometers. We construct the time-aligned earthquake dataset using Southern California Earthquake Data Center (SCEDC) API, and train our model with the dataset and our proposed training method for performance evaluation. Our model surpasses all comparable data-driven methods in various test criteria not only from waveform generation domain but also from seismology such as phase arrival time, GMPE analysis, and spectrum analysis. Our result opens new future research directions for deep learning applications in seismology.", "sections": [{"title": "Introduction", "content": "Broadband ground motion by seismic waves is crucial in the study of earthquakes and geology, since it includes important features related to subsurface structures of the Earth. At the same time, it is a great challenge from signal processing perspective, since observed ground motion time series data are noisy, covers a wide frequency band, and caused by rare and unevenly distributed earthquake events.\nVarious seismological applications were constructed by analyzing historically observed seismic waveforms. For example, as systematically recorded seismic waveform dataset grew, the accuracy of earthquake analysis were improved, early warning systems for earthquake-prone areas were polished, and earthquake-resistant architectural designs became more robust. In recent years, there has been significant success in applying deep learning in seismology (Mousavi and Beroza 2022), such as seismic signal denoising (Zhu, Mousavi, and Beroza 2019), fault recognition (An et al. 2021), and earthquake event detection (Mousavi et al. 2020; Saad et al. 2023).\nHowever, the field still faces a shortage of data, particularly for large-scale earthquakes (Shi et al. 2024; Katsanos, Sextos, and Manolis 2010). Recently, deep-learning based synthesis of seismic waveforms has emerged as a potential solution, mostly employing GAN-based generative models conditioned with various geological information and seismological desiderata (Wang, Trugman, and Lin 2021; Florez et al. 2022; Li et al. 2024; Chen, Li, and Guo 2024). However, the synthesized waveforms often lacks seismological realism, such as phase arrival times and amplitude of ground motion, especially when conditioning information is not reliable. We perceive this problem as an artifact of conditioned generation analogous to what GAN based models were suffering in image generation. Hence, we consider adaptation of diffusion models (Sohl-Dickstein et al. 2015; Ho, Jain, and Abbeel 2020) to seismic waveform data, in order to generate seismologically realistic ground motion waveforms with minimal condition."}, {"title": "Our Contribution", "content": "\u2022 We design a diffusion model for seismic waveform synthesis, which requires a minimal set of conditional information comprised of magnitude and location of hypocenter and observation station.\n\u2022 We propose a training framework that allows us to efficiently learn the seismic features from multiple observations of earthquake events.\n\u2022 We construct a new evaluation dataset from an openly available seismic dataset (SCEDC), such that the observations are paired, with each pair coming from the same earthquake and aligned to the earthquake's origin time.\n\u2022 We demonstrate the effectiveness of the our generative model against benchmark models in various perspectives including domain-specific metrics such as GMPE and quantitative analysis on phase arrival times."}, {"title": "Problem Statement", "content": "Our goal is to generate the broadband ground motion data of seismic waves caused by existing earthquakes and observed at arbitrary locations, with high level of seismological realism, but without hard-to-obtain conditional information.\nWe consider this seismic waveform synthesis problem as conditional generation problem, which can be solved by data-driven methods with deep learning. Avoiding dependency on expensive-to-measure information, we define the following variables as the minimal condition for generation:\n1. $s_{lat}$, $s_{lon}$: latitude and longitude of the station to observe the waveform data.\n2. $e_{lat}$, $e_{lon}$: latitude and longitude of epicenter.\n3. $e_{dep}$: depth of the hypocenter, unit of kilometers.\n4. $e_M$: magnitude of the earthquake.\nThe above conditional information is usually considered to be insufficient for the ground motion synthesis, since seismological characteristics of earthquake such as focal mechanism or local geological characteristics of target site such as Vs30 are not included. Instead of providing expensive additional information on earthquake, we suggest learning by waveform data directly, including the location information. To achieve this, we limit the region of interest, encode the latitude and longitude information of station and epicenter to local coordinates and learn the relation between location and waveform with hidden local features. Under these constraints, we construct a deep-learning-based generative method with minimal condition for seismic waveforms."}, {"title": "Seismic Dataset", "content": "Seismic observations, comprising waveform data recorded by seismometers, possess distinct characteristics. Depending on the seismometer's configuration, earthquake signals are captured in a specific format and at a defined sampling rate, typically classified as acceleration, velocity, or displacement. These seismograms contain vital information about the earthquake; for instance, the arrival times of P waves and S waves can be used to determine the epicentral distance and the depth of the hypocenter, while the waveform amplitude correlates with the earthquake's magnitude.\nHowever, seismic observations often include ambient noise from the surrounding environment and may be influenced by local geological conditions, which affect the accuracy of the data. As a result, seismic datasets exhibit unique properties, being a compilation of multiple noisy recordings of the same source, and the observed waveforms collectively retain the essential characteristics of the earthquake.\nIn this study, we take advantage of the property of seismic dataset that the multiple datapoints can be paired with a single earthquake. The paired observations would share properties of the same source earthquake, and hence generating one from another would be easier. For implementation, we select earthquakes since 2016 from the earthquake catalog of SCEDC dataset provided by SeisBench (Woollam et al. 2022), and collect waveform and corresponding metadata including locations, earthquake ID, magnitude and P/S arrival time. We split the collected raw data for training and evaluation with respect to earthquake ID. Removing the datum with unknown seismic instrument response, total 89,366 traces are collected through 2,623 earthquakes and 149 stations. After raw dataset collection, we trim the waveform to have a duration of 60 seconds and apply detrend and bandpass filter (1 ~ 45Hz) sequentially. More details can be found in Appendix B.\nDuring the training, we sample two paired waveforms ($W_{tgt}$, $W_{src}$) from the dataset, which are distinct observations of same earthquake, and construct conditional vector $C_{tgt}$ from metadata by pre-processing stage, whose details are explained in Appendix A. In the next section, we explain how the waveforms are used to train the diffusion model."}, {"title": "Method", "content": "Our approach builds on a music generation method (Ghosal et al. 2023) that initially creates spectrograms with its generative model and convert them into waveforms. We adapt the base model and construct a specialized training method to learn from the paired seismic waveform dataset."}, {"title": "Diffusion Model Training with Paired Data", "content": "For each earthquake event, we sample a pair of waveforms ($W_{src}$, $W_{tgt}$) from dataset and convert it to spectrograms ($X_{src}$, $X_{tgt}$) and construct conditional vector of target station $C_{tgt}$ by preprocessing.\nLet $q(x_{1:T}; X)$ be the forward process of the diffusion model, and consider two trajectories $q(x_{1:T}|X_{src})$ and $q(x_{1:T}|X_{tgt})$. Recall that $X_{src}$ and $X_{tgt}$ shares the property of earthquake, we may assume that from $X_{src}$ and $C_{tgt}$ we can gather enough features of earthquake to generate $X_{tgt}$. In this approach, we may consider the transform map $\\eta(x_{T}^{src}, C_{tgt}, t)$ for $t > 0$ which maps the latent of input $X_{src}$ to the latent of target $X_{tgt}$ as a random variable, with following assumption:\n$\\eta(x_{T}^{src}, C_{tgt}, t) \\sim q(x_{T}^{tgt}|X_{tgt})$.\nReferring (Salimans and Ho 2022), the loss function $L_{DM}$ of diffusion model in x-space (sample space) is:\n$L_{DM} = E_{(X_{tgt},C_{tgt}), \\epsilon,t}||X_{tgt} - x_{\\theta}(x_{t}^{tgt}, C_{tgt}, t)||^2$. \nwhile the SNR weight is simplified.\nConsidering the Eq. (1), we rewrite the loss function as\n$L'_{DM} = E_{(X_{src},X_{tgt},C_{tgt}), \\epsilon,t}||X_{tgt} - m_{\\theta}(x_{T}^{src}, C_{tgt}, t)||^2$\nwhere\n$m_{\\theta}(x, C, t) = x_{\\theta}(\\eta(x, C, t), c,t)$.\nHence, we predict $m_{\\theta}$ by neural network, which is a composition of latent transform function and denoising model.\nFor the sampling of the reverse process, we exploit the same procedure of the denoising process of diffusion, as\n$x_{t-1}^{tgt} = \\rho_t(x_t^{tgt}, m_{\\theta}( \\eta (x_t^{tgt}, C_{tgt}, t))) + \\sigma_t z, z \\sim N(0, I)$\nwhere $\\mu_t(x_t, x_0)$ is mean vector of $q(x_{t-1}|X_t, x_0)$, introduced in Eq. (7) of (Ho, Jain, and Abbeel 2020)."}, {"title": "Latent Diffusion", "content": "From the idea of LDM (Rombach et al. 2022), we may consider the autoencoder consist of downsampling module $E_{AE}$ and upsampling module $D_{AE}$ and construct diffusion model on latent space with smaller dimension. If there is pretrained autoencoder, the LDM loss would be\n$L'_{LDM} = E_{(Z_{src},Z_{tgt},C_{tgt}),\\epsilon,t}||Z_{tgt} - m_{\\theta}(z_T^{src}, C_{tgt}, t) ||^2$\nwhere $Z = E_{AE}(X)$, $z_T^{src}$ is latent of diffusion process of $Z_{src}$\nSince we have no pretrained autoencoder trained on seismic waveforms, we propose the following end-to-end training loss, by further modifying the loss Eq. (8) to train both autoencoder and diffusion model.\n$L_{ours} = E_{(X_{src},X_{tgt},C_{tgt}),\\epsilon,t}||X_{tgt} \u2013 D_{AE}(m_{\\theta} (z_{T}^{src}, C_{tgt}, t)) ||^2$\nwhere $z_T^{src} = \\sqrt{\\bar{\\alpha}_t}E_{AE}(X_{src}) + \\sqrt{1 \u2013\\bar{\\alpha}_t}\\epsilon_t$."}, {"title": "Neural Network Architecture", "content": "We utilize the U-Net backbone with cross-attention architecture similar to (Rombach et al. 2022; Ghosal et al. 2023), to represent $m_{\\theta}$, with modification in the domain-specific encoder $\\tau_{\\theta}$ to map $C_{tgt}$ to hidden feature $\\tau_{\\theta}(C_{tgt})$. For the implementation, we construct $\\tau_{\\theta}$ by 5-layer FFN model.\nThe encoded conditional vector $\\tau_{\\theta}(C_{tgt})$ will be provided as a value and key of cross attention module $Attn(Q, K, V)$ while U-Net feature is provided as query Q.\nFor $E_{AE}$ and $D_{AE}$, we take same architectures from VAE of (Esser, Rombach, and Ommer 2020) and give a modification on $D_{AE}$. With the vanilla module $D_{AE}$, we find that the proposed model is not effective in accurately predicting the amplitude of the output waveform. Therefore, we propose to attach an additional module ACM after $D_{AE}$ to predict the amplitude correction feature and multiply it to the predicted spectrogram. In detail, we utilize the encoder, TSConformer blocks and Magnitude mask decoder module from MP-SeNet (Lu, Ai, and Ling 2023) and provide output of $D_{AE}$ and auxiliary phase spectrogram induced by GriffinLim algorithm to correct the amplitude and enhance the quality of generation. Improving the original implementation (Lu, Ai, and Ling 2023) that allows only reducing the output, we add four TSConformer blocks and replace the final sigmoid activation function with Softplus function to provide the ability to increase as well."}, {"title": "Empirical Verification", "content": "The proposed model is trained with a single NVIDIA-RTX A6000 with 48GB memory. We set the number of epochs to 500 and the training batch size to 4. To enhance training efficiency, we apply an accumulation step of 4, resulting in an effective batch size of 16. Training completes in 65 hours, with more implementation details in Appendix C."}, {"title": "Quantitative Evaluation", "content": "To assess the effectiveness of the diffusion model in synthesizing seismic waves, we conducted a comprehensive quantitative analysis focusing on key parameters including P-"}, {"title": "Similarity Measures", "content": "In this section, we compare the synthesized waveform and corresponding spectrogram directly to the observations, with general-purpose similarity measures, the envelope correlation, MSE, SNR and PSNR.\nEnvelope correlation was calculated to measure the similarity between the envelopes of synthesized and observed seismic waves, providing insights into the overall waveform fidelity. And we apply Savitzky-Golay Filtering (Savitzky and Golay 1964) technique with polyorder 3 before calculate the envelope correlation.\nAdditionally, we compare the synthesized spectrogram $X_{syn}$ and spectrogram of observed seismic signals $X_{tgt}$ to quantify their similarity using image similarity. The comparison of spectrograms would provide evidence of self-consistency of synthesized waveforms since the proposed method aims to synthesize a seismic signal in the frequency domain by generating a spectrogram.\nFurthermore, SNR and PSNR metrics were employed to evaluate the quality of the synthesized seismic waves in terms of signal clarity and fidelity to the original data.\nThese quantitative analyses provide a comprehensive assessment of the performance of the proposed model in accurately reproducing seismic waveforms and will be crucial in validating its applicability in seismic simulations."}, {"title": "GMPE Analysis", "content": "Ground Motion Prediction Equation (GMPE) is a powerful mathematical model used in seismology to predict the ground shaking intensity resulting from earthquakes, and it is crucial for seismic hazard assessment and earthquake engineering. The GMPE model relates earthquake parameters, like local Magnitude $M_L$ and hypocentral distance $R_{hypo}$, to ground motion characteristics, such as Peak Ground Acceleration (PGA). Since $M_L$ is obtained from the peak amplitude of the waveforms, the GMPE analysis shows how the scale of the synthesized waveform matches the real observations.\nGiven the waveform $W$, we first compute the local magnitude $M_L$ using the following formula (equations 1 to 6 of (Uhrhammer et al. 2011))\n$M_L = log A - log A_0(R_{hypo})$\nwhere $A_0(r)$ is attenuation function of southern california peninsula. For detailed computation, we refer the equation 4 to 6 of (Uhrhammer et al. 2011). The station adjustment term was not applied due to a lack of values for recently installed stations.\nAfter determining the local magnitude $M_L$, we obtain the PGA value by equation 1 of (Boore et al. 2014), with pynga (Wang 2012) implementation. Since our model doesn't exploit the focal mechanism information, we set mech and rake to be 0, which represents unspecified."}, {"title": "Qualitative Evaluation", "content": "In this section, we present a qualitative analysis of the synthesized seismic waveforms to evaluate the accuracy and reliability of our waveform synthesis methodology.\nWe generate synthetic waveform on existing station with its location information and compare it against the real waveform. First, we assess the similarity in amplitude and the arrival times of the P and S phases. Next, we evaluate how closely our synthesized spectrograms match the real spectrograms in both the time and frequency domains. Finally, we analyze the frequency content to compare the similarity between synthetic and real waveforms across different magnitudes and to explore the frequency characteristics of the energy released for each magnitude.\nAdditionally, we generate waveforms using both actual and virtual station locations at various distances to investigate how seismic characteristics vary with distance."}, {"title": "Waveform Analysis", "content": "We visually inspect the synthetic waveforms alongside real seismic waveforms to evaluate their similarity in terms of waveform morphology, including the amplitude, shape, and duration of seismic signals. Notably, both synthesized waveform and real waveform depict similar patterns of seismic activity, including distinct seismic phases and their corresponding arrivals. This alignment underscores the effectiveness of our synthesis approach in accurately replicating the seismic signal\u2019s morphology and temporal evolution."}, {"title": "Spectrogram Comparison", "content": "We also show the output spectrogram of proposed model, compared to the real spectrogram to examine their time-frequency characteristics, providing insights into the distribution of energy across different frequency bands over time. Upon comparing the synthesized spectrogram with the real spectrogram, several key observations come to light. Both spectrograms exhibit remarkable similarities in terms of phase arrival times and frequency band distribution, indicative of the efficacy of our synthesis approach in capturing essential seismic signal characteristics. However, it is discernible that the synthesized spectrogram exhibits a slightly lower resolution compared to the real spectrogram, with some details appearing less defined. This reduction in resolution is particularly evident in the depiction of fine-scale frequency variations and subtle signal features. Despite this difference, the overall agreement between the synthesized and real spectrograms underscores the fidelity of our synthesis method in reproducing the fundamental characteristics of seismic signals."}, {"title": "Frequency Content Analysis", "content": "In this section, we analyze how the energy released during an earthquake using frequencies. This analysis is closely related to the concept of corner frequency (Boore 1983) and the seismic moment ($M_o$). The corner frequency is generally associated with the earthquake's magnitude. Specifically, the corner frequency identifies the point at which high-frequency energy begins to decline sharply, indicating that larger earthquakes generally have lower corner frequencies. The $M_o$ represents the total energy released by the earthquake, which corresponds to an increase in amplitude on the spectrum as the earthquake's magnitude increases. By comparing synthetic and observed seismic signals, we aim to evaluate the similarity between the two characteristics of corner frequency and $M_o$ across different magnitudes. We apply both Fast Fourier Transform (FFT) and Konno-Ohmachi-smoothing (Konno and Ohmachi 1998) technique to enhance our comparison. Also, we apply Wood-Anderson simulations (Havskov and Ottem\u00f6ller 2010) to compare results from distinct stations. We observe significant differences in corner frequency and $M_o$ across different earthquake magnitudes, that the corner frequency reduces and $M_o$ increases when the magnitude grows."}, {"title": "Waveform Analysis on Synthetic Stations", "content": "By arranging virtual observation stations in a linear manner, spatial variations of seismic waves could be observed, facilitating an understanding of seismic event characteristics. The synthesized seismic waves reflected seismic activity at the virtual observation stations, enabling exploration of subsurface structures and seismic wave propagation characteristics. The sections represented the positions of observation stations horizontally and represented the temporal and frequency characteristics of seismic activity vertically. Through such visualization, comparisons between synthesized and observed seismic waves could be conducted, assessing the fidelity of the synthesized seismic waves in reflecting seismic events. Results from section plots clearly visualized spatial and temporal variations of seismic activity, serving as crucial criteria for evaluating the extent to which our synthesis method accurately reproduces actual observed results."}, {"title": "Ablation Studies", "content": "Compared to the conventional latent diffusion model, we introduced two major components, the efficient learning framework and amplitude correction module, to generate high-quality seismic waveforms. In this section, we present the results of the ablation study to evaluate the role of each component."}, {"title": "Discussion", "content": "While our training method use paired dataset, our models can generate waveform without $W_{src}$. Generating without $W_{src}$ allows the model to simulate synthetic earthquake to improve the diversity of earthquake catalog, but there's negligible trade-off on generation quality, as shown in Table 2 and Fig. 2.\nOur method successfully generates seismic waveforms with accurate phase arrival times, amplitude, and low-frequency features, which are crucial for understanding geophysics. However, for large-magnitude earthquake synthesis with magnitude > 5, the synthesized waveform fits the real observation in phase arrival time and amplitude, but shows a drawback in high-frequency features (> 10Hz). This drawback may be due to the natural shortage of large-magnitude earthquake observations.\nOur model is local, since the generation process would work on limited region, since we encode the latitude and longitude to relative positional encodings. The limitation of the generation area allowed us to learn the local geological properties and generate accurate seismic signals without providing them, but is also hindered the development of a global model that could cover the entire Earth.\nSuboptimal artifacts on synthesized waveforms are observed, such as in high frequency features, for far-away station locations, or with earthquakes with large magnitude. The artifacts may be caused by our seismic dataset limited to the region and frequency range (1 ~ 45Hz). In this case, expanding the geographic area and the frequency range of trained dataset, which would be a potential future work, may improve the generation quality.\nAnother future research direction is to apply our generative model in improving performance of downstream seismological tasks. Augmenting waveform datasets directly or injecting waveforms from vicinity may improve deep learning based phase picking methods. Also, the identification of subterranean structures may benefit from comparing real waveforms and synthesized counterparts."}, {"title": "Conclusion", "content": "In this paper, we propose an efficient training framework for seismic waveform synthesis utilizing a diffusion model and a minimal set of conditions. Our approach generates seismic waveforms using only readily accessible information, such as location and magnitude, thereby avoiding the need for impractical conditions.\nTo empirically validate the proposed method, we constructed a seismic dataset from the SCEDC API by collecting simultaneously paired observations aligned with the earthquake's origin time.\nWe demonstrate that our model produces more realistic waveforms than existing benchmark models by applying seismic domain-specific metrics, such as envelope correlation and P/S phase arrival times, for expert-level comparison."}, {"title": "A Pre-processing Recipe", "content": "We explain the process of $C_{tgt}$ constuction. Recall the variables that we are used to synthesize waveform are:\n1. $s_{lat}$, $s_{lon}$: latitude and longitude of the station to observe the waveform data.\n2. $e_{lat}$, $e_{lon}$: latitude and longitude of epicenter.\n3. $e_{dep}$: depth of the hypocenter, unit of kilometers.\n4. $e_M$: magnitude of the earthquake.\nWe preprocessed those variables to construct an 11-dimensional condition vector and later provide it to our condition encoder module $\\tau_{\\theta}$.\nFirst of all, we encode locational information $s_{lat}$, $s_{lon}$, $e_{lat}$ and $e_{lon}$ with the following process:\n1. Normalize the values to get $s'_{lat}$, $s'_{lon}$, $e'_{lat}$ and $e'_{lon}$ with following:\n$s'_{lat} = \\frac{s_{lat}-l_{lat}}{U_{lat}-l_{lat}}, s'_{elon} = \\frac{e_{lat}-l_{lat}}{U_{lat}-l_{lat}}, s'_{lon} = \\frac{s_{lon}-l_{lon}}{U_{lon}-l_{lon}}, e'_{elon} = \\frac{e_{lon}-l_{lon}}{U_{lon}-l_{lon}},$\nwhere ($(l_{lat}$, $U_{lat})$) and ($(l_{lon}$, $U_{lon})$) represent the lower and upper bounds of latitude and longitude, respectively, for the region of interest. In our dataset, which was collected from the SCEDC API, the region of interest is Southern California, with\n($(l_{lat}$, $U_{lat})$) = (32.024809, 36.151200) and ($(l_{lon}$, $U_{lon})$) = (-120.444000, -115.222300)\n2. Motivated from polar coordinate transformation(Coo 2007), which is commonly used in GPS field, we further encode normalized coordinate to following:\n$C_{sta} = (cos(s'_{lat})cos(s'_{lon}), sin(s'_{lat})cos(s'_{lon}), sin(s'_{lon}))$\n$C_{epi} = (cos(e'_{lat})cos(e'_{lon}), sin(e'_{lat})cos(e'_{lon}), sin(e'_{lon}))$\nSecondly, we compute the back azimuth angle $Azi$ and encode by\n$C_{azi} = (cos(Azi), sin(Azi))$\nLastly, we compute and normalized epicentral distance $R_{epi}$, focus depth $d_f$ and magnitude $M_L$. Each are normalized by following formula:\n$R'_{epi} = (R_{epi} - 125.542401)/55.810322$\n$d'_{f} = (d_f - 8.564146)/4.658161$\n$M'_{L} = (M_{L} - 2.0)/6.4$\nConcatenating the processed features $C_{sta}$, $C_{epi}$, $C_{azi}$, $R'_{epi}$, $d'_{f}$, and $M'_{L}$, we get an 11-dimensional conditional vector $\\hat c_{tgt}$ for our problem, the synthesis of seismic ground motion."}, {"title": "spectrogram construction", "content": "The generation target of out model is spectrogram, which is in time-frequency domain. We report the process of spectrogram construction as pre-processing. We employed the STFT (Short-Time Fourier Transform) with a hiop length 16. Given that the spectrogram's scale is closely related to the earthquake's amplitude, we used an $n_{fft}$ and window length of 128 and applied a logarithmic scale transformation for better scale adjustment. Consequently, the original waveform data of size 3 \u00d7 6000 was reshaped into 3 \u00d7 64 \u00d7 376."}, {"title": "Dataset Construction", "content": "We used the SCEDC (SCEDC 2013) dataset provided by SeisBench (Woollam et al. 2022). From this dataset, we selected waveforms with a sampling rate of 100Hz that included 60 seconds from the earthquake and applied a bandpass filter in the 1 ~ 45Hz range to construct our data. However, each source initially had fewer than 13 stations on average. To address this, we utilized the obspy API (Beyreuther et al. 2010) to save waveforms. By using source_id from SCEDC during the years 2016 to 2019, we constructed a new dataset with approximately 30 stations per source. The station list in (Uhrhammer et al. 2011) was used to calculate the local magnitude. The final dataset used for training averaged 34 stations per source. The shows the count of datasets we used.\nThe $V_{S30}$ information was sourced from (McPhillips et al. 2020) and used only during the GMPE analysis, not during the training or model inference processes. The average value was used if multiple $V_{S30}$ values were present for a single station code. For station codes without $V_{S30}$ data, 760m/s was assigned to negate the influence of $V_{S30}$ during GMPE analysis."}, {"title": "Implementation details", "content": "We implement the proposed model with following implementation details.\nDuring the training, $W_{src}$ is fixed for a specific earthquake source ID, and $W_{tgt}$ is sampled from earthquakes with the same source ID. Among these, if metadata contained P/S phase labels, samples are randomly selected from those with labels. If P/S phase labels are absent, samples are chosen randomly without considering P/S phase labels. And also we conduct preprocessing of seismic data.\nWe implement using single NVIDIA-RTX A6000 with 48GB memory. For training, we set the number of epochs to 500 and the training batch size to 4. To enhance training efficiency, we apply an accumulation step 4, resulting in an effective batch size of 16. For the loss, we set the maximum diffusion steps to $T = 1000$ and SNR weight 5. We minimize the loss by AdamW optimizer with learning rate $10^{-5}$ and $pytorch.optim$ defaults. During the training, we applied learning rate decaying technique with linear scheduler. The total duration of training is approximately 65 hours."}, {"title": "DEQT Training Details", "content": "We used EQTransformer (Mousavi et al. 2020) provided by SeisBench (Woollam et al. 2022). Starting from pre-trained model provided by SeisBench, we finetune the model with our dataset, with the same training protocol. After standardizing the waveforms, we trained the model using the Adam optimizer, with a batch size of 512 and a learning rate of $10^{-3}$, for 100 epochs. Other hyperparameters of the optimizer were set to default. For hyperparameter search, the learning rate ranged from $10^{-2}$ to $10^{-5}$, and the performance was best when it was $10^{-3}$."}, {"title": "Details on Benchmark Models", "content": ""}, {"title": "SeismoGen", "content": "SeismoGen is a CGAN-based model that generates waveforms conditioned on the presence of seismic events (e.g., P or S waves). The Discriminator takes both the waveform and the presence of seismic events as inputs. It then divides the waveform into high and low frequency components, analyzing each to determine if waveform is real or synthetic. SeismoGen used data from three stations in Oklahoma: V34A, V35A, and V36A, while we used data from 149 stations from SCEDC. Our synthesis approach used station and earthquake information instead of presence of seismic events. SeismoGen generated waveforms as 40 seconds at 40Hz, but we aimed for 60 seconds at 100Hz. We used an input noise length of 1500 and added upsampling at the end of the first convolution layer. The basic training used noise as input, and for comparison with our model, we also trained using waveform. When using waveforms, we modified each pipeline to utilize one ENZ channel. The hyper-parameters we used included the Generator learning rate and Discriminator learning rate are set to $10^{-4}$ and $10^{-6}$, using the RMSprop optimizer over 3000 epochs. The $\u03bb_{L1}$ is set to 10 when using noise and 15 when using the input waveform. We saved the best model based on envelope correlation. We experimented with learning rates ranging from $10^{-4}$ to $10^{-7}$, using both Adam and RMSprop optimizers. The value of $\u03bb_{L1}$ was tested at 5, 10, and 15. The best-performing combination of these parameters was selected for the final model. Additionally, the results reported reflect the best performance achieved across 30 iterations. Addressing the instability of the original method, we added the L1 loss\n$L_{L1}(G) = E_{x,y,z} [||X_{tgt} - G(z,y)||_1]$\nfrom pix2pix(Isola et al. 2017) as an additional loss term to improve training stability."}, {"title": "ConSeisGen", "content": "ConSeisGen is an ACGAN-based model that generates waveforms conditioned on the epicentral distance. The Discriminator consists of two components: $D_p$, which learn determining whether the waveform is real or synthetic, and $D_d$, which learn regression estimating the distance between the epicenter and the station. While ConSeisGen generated waveforms with 3 channels and a length of 4096, we aimed to generate waveforms with 3 channels and a length of 6000. We modified the first linear layer and removed upsampling in the final layer. ConSeisGen used KiK-net data, which began recording shortly before the arrival of the P-wave. However, the SCEDC data utilized in this model was recorded from the onset of the earthquake for a duration of 60 seconds. ConSeisGen generates waveforms based on the epicentral distance. However, waveforms can vary even at the same distance due to factors like magnitude and geological conditions. To generate waveforms for specific locations, we utilized minimal additional condition such as station data and source data along with the epicentral distance. The hyper-parameters we used included the Generator learning rate and Discriminator learning rate are set to $2 \u00d7 10^{\u20134}$ and $10^{\u20135}$, using the Adam optimizer over 5000 epochs. Referring eq.4 of (Li et al. 2024), the loss function consists of Adversarial Loss, Regression Loss($L_{reg}$), and Diversity Improvement Loss($L_{di}$). The $L_{reg}$ computes the l1 loss between $D_d$'s output and the condition vector, with the $\u03bb_{reg}$ set to 1. The $L_{di}$ aims to prevent mode collapse by maximizing the distance between feature maps, with $\u03bb_{di}$ set to 10 when using noise and 5 when using waveforms. We experimented with learning rates ranging from $10^{-4}$ to $10^{-6}$, using both Adam and RMSprop optimizers. The value of $\u03bb_{di}$ was tested at 5, 10, and 15, while $\u03bb_{reg}$ was fixed at 1. The best-performing combination of these parameters was selected for the final model. Additionally, the results reflect the best performance achieved across 30 iterations. Addressing the instability of the original method, we added the L1 loss Eq. (16) from pix2pix(Isola et al. 2017) as an additional loss term to improve training stability.\n$L_{L1}(G) = E_{x,y,z} [||X_{tgt} - G(z,y)||_1]$"}, {"title": "BBGAN"}]}