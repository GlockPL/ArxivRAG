{"title": "Benchmarking Quantum Convolutional Neural Networks for Signal Classification in Simulated Gamma-Ray Burst Detection", "authors": ["Farida Farsian", "Nicol\u00f3 Parmiggiani", "Alessandro Rizzo", "Gabriele Panebianco", "Andrea Bulgarelli", "Francesco Schillir\u00f3", "Carlo Burigana", "Vincenzo Cardone", "Luca Cappelli", "Massimo Meneghetti", "Giuseppe Murante", "Giuseppe Sarracino", "Roberto Scaramella", "Vincenzo Testa", "Tiziana Trombetti"], "abstract": "This study evaluates the use of Quantum Convolutional Neural Networks (QCNNs) for identifying signals resembling Gamma-Ray Bursts (GRBs) within simulated astrophysical datasets in the form of light curves. The task addressed here focuses on distinguishing GRB-like signals from background noise in simulated Cherenkov Telescope Array Observatory (CTAO) data, the next-generation astrophysical observatory for very high-energy gamma-ray science. QCNNs, a quantum counterpart of classical Convolutional Neural Networks (CNNs), leverage quantum principles to process and analyze high-dimensional data efficiently. We implemented a hybrid quantum-classical machine learning technique using the Qiskit framework, with the QCNNs trained on a quantum simulator. Several QCNN architectures were tested, employing different encoding methods such as Data Reuploading and Amplitude encoding. Key findings include that QCNNs achieved accuracy comparable to classical CNNs, often surpassing 90%, while using fewer parameters, potentially leading to more efficient models in terms of computational resources. A benchmark study further examined how hyperparameters like the number of qubits and encoding methods affected performance, with more qubits and advanced encoding methods generally enhancing accuracy but increasing complexity. QCNNS showed robust performance on time-series datasets, successfully detecting GRB signals with high precision. The research is a pioneering effort in applying QCNNs to astrophysics, offering insights into their potential and limitations. This work sets the stage for future investigations to fully realize the advantages of QCNNs in astrophysical data analysis.", "sections": [{"title": "I. INTRODUCTION", "content": "In the last decade the advancement of quantum computing hardware and its availability to public, prepared the playground to investigate the potential of quantum computing in different scientific cases. Quantum computers offers an incredible potential in speed up and performance on calculation prime numbers [1], simulating quantum systems [2], or solving linear systems of equations [3]. This rapid advancements in quantum computing have opened new avenues for tackling complex computational problems across various scientific disciplines. Among the most promising applications is Quantum Machine Learning (QML), which merges the computational power of quantum mechanics with the established frameworks of classical machine learning [4]. QML offers powerful tools to explore the frontiers of science, particularly in Astrophysics.\nIn the field of astrophysics, detecting and analyzing transient astrophysical events, such as Gamma-Ray Bursts (GRBs), presents a significant challenge. GRBs are among the most energetic and enigmatic phenomena in the universe, requiring sophisticated techniques to capture, process, and interpret their fleeting signals.\nQuantum Convolutional Neural Networks (QCNNs) represent an innovative hybrid quantum-classical machine learning framework inspired by the hierarchical structure of classical convolutional neural networks (CNNs). Unlike classical CNNS, QCNNs utilize parameterized quantum circuits to exploit the advantages of quantum mechanics, enabling efficient representation and processing of complex data. The QCNN architecture combines translationally invariant unitary operations and pooling mechanisms that reduce the system's degrees of freedom, allowing for scalable learning with O(log(N)) variational parameters for input sizes of N qubits. This makes QCNNs particularly well-suited for near-term quantum devices and applications requiring both computational efficiency and robust pattern recognition [5].\nRecent developments in QML have demonstrated its potential in various areas of physics. In high-energy physics, for instance, QML algorithms have been proposed to address computational challenges associated with large-scale data analysis, as highlighted in a review of quantum approaches to particle physics applications [6]. Similarly, astrophysics and cosmology have seen emerging applications of QML. For instance, quantum-enhanced support vector machines have been successfully applied to galaxy classification, demonstrating the ability to process high-dimensional astronomical datasets [7]. In another study, QML was utilized in radio astronomy, where a quantum neural network was developed for pulsar classification, leveraging quantum-specific encoding methods to achieve comparable accuracy to classical techniques [8]. Despite these advances, the potential of QCNNs in astrophysics remains largely unexplored. This paper aims to fill this gap by systematically studying the capabilities of QCNNs for analyzing astrophysical data, specifically in the context of Gamma-Ray Burst (GRB) detection.\nDespite all the potentials, QML faces key challenges, including the trainability of quantum models, which can be hindered by barren plateaus-regions of exponentially flat loss landscapes\u2014as well as noise in quantum hardware that can corrupt results and complicate optimization processes. Additionally, embedding classical data into quantum states remains a non-trivial task, requiring efficient encoding methods that preserve the computational advantages of the quantum system [9]. Therefore, it is crucial to systematically benchmark different quantum architectures to identify the most effective models for specific applications. Benchmarking these different architectures, including the data encoding, is essential to understanding their relative strengths and weaknesses in real-world tasks. In the same line, [10] have done a extensive work on benchmarking different QML architecture for the binary classification task.\nIn the context of GRB detection with CNN, there has been previous works to detect GRBs using classical deep learning methods [11]-[13]. These approaches utilize CNNs to process time-series data from GRB signals, aiming to classify and analyze transient astrophysical phenomena. The CNN models used in these works show an advantage respect to standard method used in AGILE space mission [14] data analysis pipeline and can recognize more GRBs. Classical models have demonstrated success in automating GRB detection with very high accuracy. In this work we would like to explore the potential of quantum machine learning techniques for advancing GRB studies. It is important to note that in this study, the task of GRB detection is framed as a binary classification problem, where the goal is to distinguish GRB signals from background noise. The performance of our method is evaluated using accuracy, which, as commonly defined in the machine learning context, serves as a measure of the model's correctness in correctly classifying the GRB signals and background noise.\nIn our previous study [15], we investigated the feasibility of employing QCNNs for GRB detection using datasets from the AGILE space mission [14]. This initial work evaluated the QCNN's performance in processing both time-series data and sky maps, utilizing the Qiskit and Pennylane [16] quantum computing platforms. The results demonstrated the potential of QCNNs for this application, indicating promising capabilities in GRB detection tasks.\nBuilding on these findings, the present study aims to thoroughly assess the QCNN's strengths and limitations in this context. Specifically, we explore its full potential by systematically evaluating its performance across various configurations and parameters, with the goal of identifying both the robust aspects of the model and areas that require optimization or improvement. This comprehensive evaluation seeks to advance our understanding of QCNNs' applicability to real-world astrophysical signal detection challenges.\nThe structure of this paper is as follows: Section II provides an overview of QML, including its foundational principles and integration with classical methods. Section III describes the dataset used for QCNN training and testing, focusing on simulated GRB signals and background noise. Section IV outlines the QCNN architecture, detailing the variational circuits, data encoding methods, and benchmarking configurations. Section V presents the experimental results, including performance comparisons with classical CNNs, the impact of hyperparameters, and the generalization capability with limited training data. Finally, Section VI summarizes the findings and explores future directions in QML for astrophysical applications."}, {"title": "II. QUANTUM MACHINE LEARNING", "content": "QML is an emerging interdisciplinary field that combines the principles of quantum computing with the methodologies of classical machine learning. As quantum computing leverages the unique properties of quantum mechanics such as superposition, entanglement, and quantum parallelism, it offers the potential to significantly accelerate computational tasks that are traditionally challenging for classical computers.\nQML algorithms are designed to operate on quantum data or use quantum circuits to process classical data in ways that classical algorithms cannot easily replicate. These quantum algorithms are often expressed through parameterized quantum circuits (PQCs), which can be optimized similarly to classical neural networks. PQCs consist of parameterized quantum gates, which are quantum operations whose behavior is controlled by tunable parameters. Examples of such gates include rotation gates Rx (0), Ry(0), and Rz(0), where the angle @ serves as the parameter. By combining these gates into a circuit, PQCs provide a flexible framework for representing quantum states [17].\nPQCs bridge quantum and classical computing: the quantum computer estimates a quantity, while the classical computer optimizes the parameters. This process iterates, continually refining the quantum state [18]. By tuning these parameters using classical optimization methods, QML aims to find quantum states that provide better solutions to specific problems, ranging from classification and clustering to more complex pattern recognition tasks.\nThe primary advantage of QML lies in its ability to potentially solve certain problems with exponentially fewer resources compared to classical approaches. However, the field is still in its infancy, with ongoing research focused on developing practical algorithms, understanding their computational advantages, and exploring real-world applications in various domains such as chemistry, finance, and, as this paper explores, astrophysical signal detection."}, {"title": "A. Variational Quantum Algorithm", "content": "One of the most widely used algorithms in quantum machine learning (QML) is the Variational Quantum Algorithm (VQA), a hybrid quantum-classical approach designed to work effectively on Noisy, Intermediate-Scale Quantum (NISQ) devices. A VQA consists of a parameterized quantum circuit (variational ansatz) whose parameters are optimized using a classical optimization algorithm to minimize a cost function. The cost function encodes the problem to be solved and is evaluated using measurements from the quantum circuit. VQAs have demonstrated versatility across tasks such as quantum system simulation, combinatorial optimization, and eigenvalue estimation. Their success is attributed to their ability to balance quantum resources such as entanglement and superposition-with classical computational power to mitigate errors and noise. By leveraging problem-specific ansatz designs and advanced optimization techniques, VQAs can achieve efficient parameterization, reducing the quantum circuit depth and the number of measurements required for convergence [19]."}, {"title": "B. Data Encoding methods", "content": "Quantum data encoding is the process of mapping classical data into a quantum state to leverage quantum computational advantages. This step is foundational in QML as it determines how efficiently and accurately classical data can be represented and processed within a quantum system. Depending on the nature of the data and the quantum algorithm, different encoding strategies are used, each with trade-offs in terms of resource requirements, scalability, and expressivity. Here we explain two well-known data encoding methods used in QML and in this work:\nAmplitude Encoding maps classical data into the amplitudes of a quantum state. For a normalized classical vector X = (x1,x2,..., X2n), the corresponding quantum state is:\n[\u03c8) = \u2211 Xii).\ni=0\nThis approach is highly efficient in terms of qubit usage, as it allows 2n data points to be encoded using only n qubits. However, preparing such states can be computationally expensive, as it often involves complex unitary transformations, especially for large datasets.\nData Re-uploading method extends the encoding capabilities by repeatedly embedding classical data into the quantum circuit at multiple layers of the quantum computation process. This iterative re-encoding is achieved by applying data-dependent rotations (e.g., Rx, Ry, Rz) or parameterized gates in multiple rounds. For example, a single data point x can influence gates across multiple layers of a parameterized quantum circuit:\nU(0, 2) = UL(0L, f (x)) ... U\u2081 (01, f(x)).\nwhere: U represents the overall unitary transformation applied by the quantum circuit, which evolves the quantum state based on the input data and tunable parameters. L is the number of layers in the circuit, indicating how many times the data x is re-embedded. 0 = {01,02,...,0L} represents the set of trainable parameters that adjust the behavior of the parameterized gates at each layer. f(x) is a feature mapping function that transforms the input data x into a form compatible with the quantum gates (e.g., scaling or encoding as rotation angles). U\u017c(\u03b8i, f(x)) corresponds to the parameterized quantum gates applied in the i-th layer, which depend both on the trainable parameter 0\u2081 and the feature-transformed data f(x). This method is particularly powerful in scenarios where qubit resources are limited, as it allows a smaller number of qubits to process complex or high-dimensional data by leveraging the circuit depth. It enhances expressivity and has shown success in tasks such as quantum classification and regression. However, it increases the circuit complexity, which might affect execution fidelity on near-term quantum hardware [20]."}, {"title": "III. DATASET", "content": "GRBs are extremely energetic explosions that occur in distant galaxies, emitting intense bursts of gamma rays, the most energetic form of light. They are typically classified into two types: short-duration GRBs, lasting less than 2 seconds, likely caused by the merger of neutron stars, and long-duration GRBs, lasting over 2 seconds, usually associated with the collapse of massive stars into black holes [21]. GRBs are among the brightest and most powerful events in the universe, often followed by an afterglow that can be observed in other wavelengths like X-rays, visible light, and radio waves. They serve as probes for studying the early universe and testing fundamental physics, including general relativity and Lorentz invariance violationsnables advancements in multimessenger astronomy by linking electromagnetic signals with gravitational waves and neutrinos [22], [23]. In this work, we focus on studying long-duration GRBs detection.\nOver the last decade, numerous satellites and telescopes have significantly advanced the observation of gamma rays and GRBs, enabling groundbreaking discoveries. The Fermi Gamma-ray Space Telescope (launched in 2008) and its Large Area Telescope (LAT) and Gamma-ray Burst Monitor (GBM) have been instrumental in GRB detection and spectral analysis [24]-[26]. NASA's Swift Observatory continues to play a crucial role in the localization and multi-wavelength follow-up of GRBs [27]. The AGILE satellite, launched by the Italian Space Agency, focuses on transient gamma-ray phenomena, including GRBs [14], [28]. The Cherenkov Telescope Array Observatory (CTAO), the next generation of ground-based observatories for high and very-high energy science, will enhance gamma-ray astronomy with over a hundred highly sensitive, fast-reacting Cherenkov telescopes. The facility will be equipped with real-time analysis software that automatically generates science alerts and analyzes ongoing observational data in real-time [29], [30]."}, {"title": "A. The simulation specification", "content": "For our simulations, we utilized the gammapy framework, a widely used Python library for high-level gamma-ray astronomy analysis [31]. Gammapy provides robust tools for simulating, analyzing, and modeling gamma-ray data in formats compatible with Gamma Astronomy Data Format (GADF) [32]. It also includes support for instrument response functions (IRFs) and event processing, making it suitable for detailed astrophysical studies [33].\nThis simulation approach allowed us to generate a diverse dataset, capturing realistic transient source variability and incorporating features critical for training and evaluating our QCNN. We generated 600 simulated light curves in total from which 440 and 160 are used for training and test set accordingly. Our simulated dataset is balanced, meaning half of the dataset includes the GRB signal and the other half contains only background noise. The simulation details is as follows:\nSource Model: The simulated source was a transient point-like gamma-ray emitter located at a 0.4\u00b0 offset from the center of the field of view, which is a standard configuration for very high energies observations. The spectral model was defined as a power law with an index of 2.25, characteristic of Crab-like sources. It is important to note that no prompt TeV gamma-ray emission has been conclusively observed to date. Consequently, a \"typical\" spectrum was adopted, with the Crab serving as a standard candle for TeV astronomy. This work does not aim to simulate a realistic GRB prompt emission spectrum, as population studies for GRBs at TeV energies are ongoing [34]. Developing a fully realistic spectrum is a complex task and lies beyond the scope of this study. The default power-law amplitude was set to 3 \u00d7 10-10 cm-2 s-1 TeV-1, calibrated to the chosen IRFs. To introduce variability, the amplitude was scaled by a random factor uniformly sampled between 0.1 and 3.0.\nTemporal Model: The temporal evolution of the source followed a Gaussian pulse model. This model is motivated by the first-order approximation of real prompt light curves observed by the Fermi GBM at MeV energies. The prompt emission, usually, is highly irregular, made up by one or more pulses, so to simplify the task, we are using a single smooth pulse model. The pulse's duration and peak position along the time axis were randomly selected for each simulation. Detecting a GRB signal is important to capture the complete shape of the light curve; therefore, to ensure the inclusion of both the rise and the decline phases of the signal, the Gaussian peak was constrained to avoid the first and last 200s of the time axis.\nSimulated Data Products: The simulations generated event lists, which include individual photon events recorded over time. These event lists were subsequently binned to produce counts maps, necessary for downstream analysis. Here we considered 1200 seconds as the duration of our event list which can be binned differently.\nInstrument Response Functions (IRF): The simulated dataset was generated using the Prod5 IRFs, corresponding to the four Large-Sized Telescopes (LSTs) configuration of the CTAO, with a zenith angle of 20\u00b0. The LSTs, with their wide field of view and low-energy detection threshold, are particularly well-suited for observing GRBs, as these features enable the efficient detection of transient, high-energy phenomena across large areas of the sky. These IRFs provide high-precision modeling for gamma-ray observations under standard CTAO performance conditions [35]."}, {"title": "IV. ARCHITECTURE", "content": "In this section, we detail the implemented architecture for the QCNN as well as the CNN utilized for benchmarking. We also outline the training procedures and hyperparameter configurations employed in our study. By conducting a comprehensive evaluation of different QCNN configurations, including variations in data encoding, qubit count, and network depth, we aim to provide a robust comparison between the quantum and classical approaches. It is important to note that in the context of our work, the binary classification task is designed to distinguish between GRB signals and background noise."}, {"title": "A. Quantum Convolutional Neural Network", "content": "In this study, we utilized hybrid quantum-classical machine learning, implementing our Quantum Neural Network using Parametrized Quantum Circuits. We adapt the quantum circuit presented in [36] according to our needs. We explored the performance of our QCNN using Qiskit\u00b9 library. Qiskit is an open-source quantum computing framework developed by IBM that provides a comprehensive set of tools for building, simulating, and executing quantum circuits on both simulators and real quantum hardware. Designed for accessibility and flexibility, Qiskit supports a range of quantum algorithms, including those for machine learning, and optimization, making it a versatile platform for both research and practical applications in quantum computing.\nThe feature map shown in the Figure 2 is an integral component of the QCNN architecture. This feature map architecture uses parameterized single-qubit rotation gates to encode information at the qubit level. Controlled operations are then applied to introduce entanglement between qubits, enabling the quantum representation to capture correlations across qubits. This feature map includes following operations:\n\u2022 Single-Qubit Rotations: Each qubit (qo, Q1,..., q4) is subjected to a parameterized single-qubit rotation gate R(\u03b8, \u03c0/2), where di are trainable parameters. These rotations initialize the qubits with data-encoded angles, effectively embedding classical input information into the quantum state.\n\u2022 Entanglement Structure: Following the rotation gates, a series of controlled operations (depicted as \"+\" symbols connected by lines) are applied to create entanglement between neighboring qubits. These operations ensure that the information encoded in one qubit is correlated with others, a key requirement for capturing global patterns and dependencies in the input data.\n\u2022 Layered Connectivity: The entanglement is progressively built across multiple layers, with later connections involving more distant qubits. This hierarchical structure mirrors the pooling or filtering operations in classical CNNs, where localized features are aggregated into more global representations.\nThis feature map plays a critical role in the overall performance of the QCNN, as it determines the quality of the initial quantum representation of the data by embedding data in a way that preserves both individual qubit-level information and inter-qubit correlations. The inclusion of parameterized gates also allows for optimization during training, enabling the network to adaptively learn an optimal embedding for the input data. The use of entanglement ensures that the quantum system leverages its intrinsic advantages over classical systems, particularly in representing high-dimensional and complex data."}, {"title": "B. Classical CNN", "content": "The classical CNN employed in this study is a minimalistic architecture specifically designed to align with the constraints and capabilities of the Quantum QCNN, ensuring a meaningful comparison. The network consists of an input layer followed by a single 1D convolutional layer (Conv1D) with 2 filters and a kernel size of 3, chosen to match the quantum model in terms of complexity and number of trainable parameters. Batch normalization is applied after the convolutional layer to stabilize and accelerate training, followed by a ReLU activation function to introduce non-linearity. The feature maps are then passed through a global average pooling (GAP) layer to reduce dimensionality, followed by a flattening operation to prepare the data for dense layers. The dense layer is activated with a ReLU activation function, followed by the output layer, which has as many neurons as the number of classes, using a softmax activation function. The model is trained using a categorical cross-entropy loss function, optimized with the Adam optimizer. This simplified design was chosen to minimize the number of trainable parameters, ensuring that the comparison focuses on the intrinsic capabilities of QCNN and CNN rather than the complexity of the architecture. By keeping the classical CNN architecture as simple as possible, the study avoids introducing biases that could arise from highly parameterized models."}, {"title": "C. Benchmarking parameters", "content": "To analyze the network performance under varying configurations, we conducted a benchmarking study focusing on the following hyperparameters: the number of qubits, the number of data reuploading layers, the type of data encoding, and the size of the training dataset. We discuss these parameters variation effect in the result section."}, {"title": "D. Training", "content": "Figure 3 illustrates the convergence of the objective function during the training of the QCNN over 150 iterations. For optimization, we used the COBYLA (Constrained Optimization BY Linear Approximations) algorithm, with a custom callback function to monitor the training process. QCNN was implemented using the Qiskit SamplerQNN framework and trained on the Aer simulator, which efficiently handles NISQ devices. The initial weights for the variational circuit were initialized randomly within a small range to ensure a well-conditioned starting point for optimization. The convergence curve shows a general downward trend, indicating that the objective function consistently decreases as the optimization progresses. However, there are fluctuations in the early iterations, due to the randomized initialization of parameters and the non-convex nature of the optimization landscape. After approximately 60 iterations, the curve stabilizes, suggesting that the QCNN has reached a region near the optimal solution. These patterns highlight the importance of a well-tuned optimization process to achieve effective convergence.\nInstead, for the classical CNN, we used a batch size of 16 and a variable learning rate when the minimum learning rate is set to 0.00001. To prevent overfitting and reduce computational cost, the early stopping method was employed, which halted training once the validation loss stopped improving. This method compares the loss value in each epoch, and if the loss starts to increase, which is an indication of overfitting, stops the training. The classical CNN converged in fewer than 400 epochs, demonstrating efficient training under these conditions."}, {"title": "V. RESULTS", "content": "In this section, we present the evaluation of the benchmarking results for the implemented models, focusing on the effects of hyperparameters, training sample size, computational time, and model complexity."}, {"title": "A. The General Trend", "content": "The performance evaluation of the QCNN demonstrates that it achieves an accuracy of 97.5% (as detailed in Table I), which is comparable to the 97.35% accuracy achieved by the classical CNN. However, this level of accuracy is attained using fewer parameters, highlighting the potential of QCNNS for parameter-efficient modeling. This efficiency suggests that QCNNs leverage the inherent properties of quantum systems, such as superposition and entanglement, to represent and process data more compactly than classical architectures."}, {"title": "B. The Qubit number effect", "content": "The results indicated in Table I show a clear trend where increasing the number of qubits in the QCNN architecture enhances the model's accuracy. In this context, accuracy is defined as the proportion of correctly identified events relative to the total number of events in the dataset. This improvement can be attributed to the larger Hilbert space enabling the network to capture more complex patterns and correlations within the data. As demonstrated, the model with 6 qubits at best reaches 90% and 87.7% accuracy in the training and test phase, while the same model with 12 qubits can detect the GRB signal with 99. 38% and 97.5% accuracy in the training and test dataset. However, this gain in accuracy comes at the cost of an increased training time, as the computational complexity increases with the number of qubits, as the 6 qubit model performs faster with a factor of 33. Conversely, reducing the number of qubits below a critical threshold negatively impacts the model's performance, as it becomes insufficient to encode the underlying structure of the data effectively. Therefore, selecting an optimal number of qubits is crucial to balance accuracy and computational efficiency, ensuring the best trade-off between model performance and resource requirements."}, {"title": "C. The data encoding effect", "content": "A performance comparison of the QCNN model using amplitude encoding and the data re-uploading method was conducted, Table II. The results indicate that the accuracy of the network drops to 76% when employing amplitude encoding. This highlights the advantage of the data re-uploading method, which enhances the expressiveness of the variational quantum circuit by iteratively embedding input data at multiple stages of the circuit. This iterative embedding allows the circuit to perform more complex and nonlinear transformations on the input data, making it more capable of capturing intricate patterns and relationships inherent in the dataset. This increased representational power makes the data re-uploading method particularly well-suited for machine learning tasks that require modeling high-dimensional or complex data distributions."}, {"title": "D. Few Training Samples", "content": "In the present context, the QCNN has achieved accuracy comparable to that of classical CNNs. To establish a clear quantum advantage, this study focuses on sample complexity, which refers to the ability of a model to perform a given task, such as detecting GRB signals, with significantly fewer labeled training samples. Quantum algorithms are theoretically expected to exhibit superior generalization capabilities compared to classical counterparts [9]. This advantage arises from their ability to leverage quantum phenomena like superposition and entanglement to encode and process information more efficiently, allowing them to identify underlying patterns and relationships within datasets with fewer data samples [37]. Therefore, this study evaluates the QCNN's performance under conditions of limited training data to explore this potential.\nThe results in Table III demonstrate the remarkable generalization capability of the QCNN model when trained on a limited dataset. Specifically, the QCNN achieves high accuracy (95%) using only 20 light curves in the training set and 180 in the test set. In contrast, the classical CNN fails to reliably detect GRB signals under the same conditions due to the insufficient size of the training dataset. This highlights the strength of QML approaches in scenarios with limited data availability. The observed performance of the QCNN reflects its inherent advantage in sample complexity, showcasing a form of quantum advantage where fewer training samples suffice to achieve superior detection capabilities compared to classical methods. This result is particularly valuable in astrophysical detection tasks, where the rarity of phenomena or observational limitations often result in very few labeled data points for training."}, {"title": "E. Performance on Real Data", "content": "To evaluate the robustness of the implemented QCNN beyond simulated datasets, we tested its performance on real observational data from the AGILE satellite. This dataset comprises 43 GRB samples and 101 background samples, presenting significant class imbalance and reflecting the challenges of real-world astrophysical data analysis. This dataset is divided to the training, test and validation set with the rate of 70%, 20% and 10%. For details on the preparation and composition of the AGILE dataset, readers are referred to our previous work [15]. As shown in Table IV the QCNN demonstrated strong performance on this dataset, achieving 91% accuracy on the training set and 90% accuracy on the test set, underscoring its ability to generalize effectively to real data. Also in this case we can observe that Classical CNN reaches very high accuracy (96% for the training and 93% for the test set) in detecting the GRB signal. These results indicate that the QCNN is not only capable of detecting GRB signals in simulated datasets but also performs well in real observational scenarios, further highlighting its potential for astrophysical applications."}, {"title": "VI. CONCLUSION AND FUTURE WORK", "content": "This study represents one of the pioneering efforts to implement QCNN for astrophysical data analysis, specifically for the detection of GRBs. In this context, the detection of GRBs refers to performing a binary classification task using machine learning methods to distinguish GRB signals from background noise. Different QCNN architectures and various data encoding methods were tested to systematically explore the network's performance. The results demonstrate that QCNNs achieve comparable or superior accuracy to classical CNNs in specific scenarios while requiring fewer parameters, highlighting their efficiency and the potential of QML algorithms.\nA key finding is the generalization power of QCNNs, particularly in cases with limited training data. With only 20 light curves in the training set, the QCNN outperformed classical CNNs, showcasing quantum advantage in terms of sample complexity. Furthermore, the study illustrates the robustness of QCNNs in handling diverse configurations and datasets, including unbalanced, real-world data from the AGILE satellite.\nDespite these promising results, QCNNs face limitations, particularly when implemented on real quantum hardware. The increasing circuit complexity required for larger QCNN architectures can exacerbate the effects of noise and hardware imperfections, potentially degrading model performance. Moreover, the depth of parameterized circuits must be carefully managed to balance representational power and noise resilience. These challenges highlight the need for hardware-aware circuit design and error mitigation techniques to unlock the full potential of QCNNs.\nFuture research will aim to build on these findings by running the analysis on real quantum hardware to further validate the QCNN's performance. Additionally, efforts will focus on simulating signals with greater complexity, bringing them closer to real GRB signals and backgrounds to better evaluate the QCNN's capabilities in realistic astrophysical scenarios. This work lays the groundwork for the future integration of quantum computing techniques in astrophysics."}]}