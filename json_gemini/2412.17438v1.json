{"title": "Markov Process-Based Graph Convolutional Networks for Entity Classification in Knowledge Graphs", "authors": ["Johannes M\u00e4kelburg", "Yiwen Peng", "Mehwish Alam", "Tobias Weller", "Maribel Acosta"], "abstract": "Despite the vast amount of information encoded in Knowledge Graphs (KGs), information about the class affiliation of entities remains often incomplete. Graph Convolutional Networks (GCNs) have been shown to be effective predictors of complete information about the class affiliation of entities in KGs. However, these models do not learn the class affiliation of entities in KGs incorporating the complexity of the task, which negatively affects the models' prediction capabilities. To address this problem, we introduce a Markov process-based architecture into well-known GCN architectures. This end-to-end network learns the prediction of class affiliation of entities in KGs within a Markov process. The number of computational steps is learned during training using a geometric distribution. At the same time, the loss function combines insights from the field of evidential learning. The experiments show a performance improvement over existing models in several studied architectures and datasets. Based on the chosen hyperparameters for the geometric distribution, the expected number of computation steps can be adjusted to improve efficiency and accuracy during training.", "sections": [{"title": "1 Introduction", "content": "Knowledge Graphs (KGs) encode factual knowledge in the form of triples (subject-relation-object) and have emerged as a compelling abstraction for organizing semi-structured data, capturing relationships among entities. The facts available in KGs are used in many application areas such as recommendation (Wang et al., 2019), information retrieval (Xiong and Callan, 2015), and question answering (Yasunaga et al., 2021) for improving the performance of these systems by providing background or auxiliary information. This relevance imposes a significant importance on a KG providing comprehensive information about the encoded entities. In particular, encoding knowledge about the class affiliation of entities is of great importance for automatic reasoning and inferencing of information contained in a KG. Despite the enormous effort made to keep the knowledge encoded in the KGs up-to-date and consistent (Heist et al., 2020), KGs are often incomplete majorly due to automated constructions of KGs. To complete missing knowledge, in particular missing class affiliation of entities in KGs, various methods based on machine learning have been introduced (Bordes et al., 2013a; Kipf and Welling, 2016). Neural networks, especially Graph Convolutional Neural Networks (GCNs), have proven to be very effective in completing class affiliation of entities in KGs (Schlichtkrull et al., 2018). However, in neural network based methods, the computation cost grows with the size of the input data, but not with the complexity of the problem being learned. In recent developments in automated machine learning, models perform conditional computation based on probabilistic variables that are used to dynamically adjust the number of computation steps (Banino et al., 2021). The adjustment of the computational budget, in particular the computation steps, is known as pondering. Yet, existing graph-based machine learning algorithms do not consider the complexity of the task to adjust the number of computation steps to learn the parameters. We address this issue and introduce a GCN-based model that learns to adapt the amount of computational steps based on the task at hand.\nIn this work, we propose Markov Process and Evidential with Regularization Loss (MPERL) that builds upon the previous idea of dynamically adjusting the number of computational steps based on the input of the model. We introduce an end-to-end Graph Convolutional Network (GCN) model that is learned within a Markov process and use recent developments in the field of evidential learning (Sensoy et al., 2018; Amini et al., 2020). Previous work has demonstrated the high performance of evidence-based models. Unlike models using a softmax function, evidence-based models are effective predictors that do not make overconfident predictions. We therefore follow an evidence-based approach as well. The Markov process in which the model is learned consists of two states: (i) the continue state, indicating further computational steps, and (ii) the halt state, indicating the end of the computational steps. The overall probability of halting at each step is modeled as a geometric distribution. Unlike previous work for entity classification in KGs, MPERL is a graph-based model that dynamically adjusts the number of computational steps according to complexity. MPERL further shows its feasibility on the task of entity type prediction, i.e., inferring the knowledge about the class affiliation of an entity. In the rest of this paper, we are treating entity type prediction as a classification task where we perform single-label classification for smaller datasets (specifically designed for this purpose) and multi-label classification on larger datasets. The experimental results show that MPERL (GCN with markov process and evidential loss) outperforms vanilla GCN as well as various other baselines. The ablation studies show that the use of both markov process and the evidential learning loss provide significant increase in the performance of the MPERL. Overall our paper makes the following contributions:\n\u2022 We introduce a Graph Convolutional Network based model trained within a Markov process, using an evidential loss function.\n\u2022 We demonstrate the performance of the model in predicting missing class affiliations of entities using single- and multi-label classification.\n\u2022 We show the effect on the model when adapting the number of computational or Markov steps.\n\u2022 We show the effectiveness of each of the components of the model on the overall results with the help of an ablation study.\nThe paper is structured as follows: Section 2 discusses the recent works related to representation learning over KGs for entity classification. Section 3 details the proposed approach while Section 4 shows the effectiveness of MPERL with the help of thorough experimentation over various sizes of the datasets as well as the ablation study. Finally, Section 5 concludes the study and discusses future directions."}, {"title": "2 Related Work", "content": "Different learning approaches have been applied to the problem of entity classification in KGs. Relational Graph Convolutional Networks (R-GCN) (Schlichtkrull et al., 2018) uses the structure of KGs to generate embeddings based on local neighbors in order to predict classes (Kipf and Welling, 2016; Hamilton et al., 2017). Due to their strong performance on graph-structured data, GCN models have been particularly used and extended in recent years to tackle entity classification (Schlichtkrull et al., 2018; Chen et al., 2019; Zangari et al., 2021), relation classification (Long et al., 2021), and KG alignment (Berrendorf et al., 2020; Wang et al., 2018).\nGated Relational Graph Neural Network (GRGNN) (Chen et al., 2019) introduced a gate mechanism to leverage hidden states of current node and its neighbors to target entity classification problem in KGs. Whereas Relational Graph Attention Networks (Busbridge et al., 2019) and Multilayer Graph Attention Network (Zangari et al., 2021) use masked self-attentional layers to learn the weighting factor of neighboring node\u2019s features and were extended with intra- and interlayer connections between nodes. Evidential Relational-Graph Convolutional Networks (E-R-GCN) (Weller and Paulheim, 2021) extend R-GCN (Schlichtkrull et al., 2018) with an evidential loss to represent the predictions of the model as a distribution over possible softmax outputs and estimate the associated evidence to learn both aleatory and epistemic uncertainty in entity classification. In contrast to these approaches, our work also implements a Markov process to learn the model. Moreover, translational KG embeddings (e.g, TransE (Bordes et al., 2013a) and extensions) and factorization-based KG embeddings (e.g., DistMult (Yang et al., 2015) and RESCAL (Nickel et al., 2011)) have been proposed. In general, these embeddings are particularly effective for link prediction, but less for entity classification (Dong et al., 2019). TransET (Wang et al., 2021) is an extension of TransE (Bordes et al., 2013a) that implements a convolution-based projection of entities into a type-specific representation to address entity classification. ConnectE (Zhao et al., 2020) is also a translational-based approach that learns two distinct embedding models of the entities and connects them via a joint model to predict entity types. Ridle (Weller and Acosta, 2021) computes a distribution over the use of relations of entities using a stochastic factorization model. Besides translational and factorization-based embeddings, RDF2Vec (Ristoski and Paulheim, 2016) generates a sequence of nodes using random walks and Weisfeiler-Lehman subtree RDF graph kernels that are passed to Word2Vec language model for learning low-dimensional numerical representations of entities. The learned embeddings preserve similar entities closer in the vector space, which makes RDF2Vec suitable for entity classification (Sofronova et al., 2020; Biswas et al., 2018; Kejriwal and Szekely, 2017). Our solution differs from these approaches in the combination of evidential learning with a Markov process. This allows our approach to learn embeddings tailored to entity classification while adjusting the number of computational steps according to the complexity of the task at hand.\nOther KG representations for entity classification have also been proposed which utilize semantic information related to an entity. Cat2Type (Biswas et al., 2021) creates representations for entities based on the textual information available in the Wikipedia category names using language models and the category network information. In addition to textual information related to entities, GRAND (Biswas et al., 2022) uses several kinds of graphs such as entity based, relation based, and random walks for considering the strcutured contextual information of an entity. In (Riaz et al., 2023), the authors perform entity typing based only on the labels as well as descriptions of the entities using BERT-based models. These approaches can only be applied to KGs where class affiliation can be predicted by the relation distribution (Weller and Acosta, 2021) or where additional semantic information is available. Relational aggregation graph attention network (RACE2T) (Zou et al., 2022) proposes a method consisting of an encoder which consists of the attention coefficient between entities further used to aggregate the information of relations and entities in the neighborhood of the entity. The decoder is based on a convolutional neural network. Lastly, ASSET (Zahera et al., 2021) is a semi-supervised approach that learns from massive unlabeled data for entity classification. Compared to our work and the related work above, ASSET does not learn embeddings itself, but uses existing ConnectE (Zhao et al., 2020) embeddings learned beforehand on the KG."}, {"title": "3 Our Approach: MPERL", "content": "In this section, we introduce our method Markov Process and Evidential with Regularization Loss (MPERL), that extends current Graph Convolutional Networks (GCN) to perform entity classification in KGs. For this purpose, we first introduce the definition of a KG and the associated research problem.\nDefinition 1. A Knowledge Graph KG is a tuple (E, R, L, C), where the pair-wise disjoint sets E, R, L, and C correspond to the set of entities, relations, literals, and types or classes, respectively. A statement in KG is modelled as a triple (s,r,o), with s \\in E \\cup R \\cup L \\cup C, r \\in R, and o \\in E \\cup R \\cup L \\cup C.\nThe problem of entity classification in a KG is to predict statements (e,r,C) that should be in KG, where e \\in E, r \\in R denotes the class affiliation relationship, and C \\in C is a class. To address this problem, we present both the architecture and the learning process of MPERL in Section 3.1. In Section 3.2, the loss function for learning the parameters of the model is presented."}, {"title": "3.1 Markov Process Extensions for Entity Classification", "content": "Overview.\nWe model the entity classification problem as a supervised learning problem. Figure 1 shows the overall architecture of our proposed solution MPERL, which integrates a Markov process into a GCN-based model, e.g., R-GCN (Schlichtkrull et al., 2018). First, a representation of the entities in the KG is learned (cf. Eqs. 1-3), which relies on GCNs to represent entities from the KG and are used in each step of the Markov process to calculate the hidden layers. The Markov process in which the model is learned is defined in Eqs. 4-6. We use a generalized geometric distribution to model the transition probabilities of the two states (halt and continue) of the Markov process. We learn with parameter $\\lambda$ (cf. Eq. 5) a parameter from which we can derive the probability in which step of the Markov process the halt state is reached (cf. Eq. 6). By learning this parameter, the number of Markov steps and, thus, the number of epochs is adapted based on the input of the model. The final output of MPERL is given in Eqs. 7-9. In Eq. 7, the features of the individual steps of the Markov process are aggregated by weighted means and used to parameterize a Dirichlet distribution (Eq. 8). We use a Dirichlet distribution since this is the only conjugate prior for a categorical distribution used to indicate the probability of class affiliation of an entity in a KG. The prediction of a sample i is described by the expected probability of the Dirichlet distribution in Eq. 9. We use the expected probability as prediction for entity types due to its property of unbiased manners.\nLearning Process. For each entity $e^{(i)} \\in E$ of the KG KG we initialize each entity representation by concatenating one hot encoding with hidden state of previous markov step. We denote this vector as $x^{(i)}$. This vector is concatenated with the hidden feature representation of the entity $e^{(i)}$ of the previous Markov step denoted as $h_{n-1}^{(i)}$. Initially, in step n = 1, h is a null vector, so the feature representation is $h^{(i)}_{0}= d$. $n \\in [1,N]$ denotes the current step of the Markov process where N is the maximum number of Markov steps. The concatenation of the two vectors $x^{(i)}$ and $h^{(i)}_{n-1}$ is used as input to the neural network in step n in the Markov process. We denote the neural network input, i.e., in layer l = 0, of a sample i in Markov step n as follows:\n$h_{n}^{(i)}[0] = [x^{(i)} || h_{n-1}^{(i)}]$\t\t(1)\nwhere [ ||] is the concatenation operation and the number in square brackets in superscript denotes the considered layer.\nBy incorporating the hidden feature representation $h^{(i)}_{n-1}$ from the previous step, the learned features are reused to enable faster convergence. The fundamental concept is similar to GCRNN, although rather than using $h^{(i)}_{n-1}$ as the only input to MPERL, the concatenation of $x^{(i)}$ and $h^{(i)}_{n-1}$, is used to avoid overfitting.\nThe hidden representation of an entity $e^{(i)} \\in E$ in layer l + 1 is then computed using a simple propagation model to calculate the forward pass update. For updating the entity representation, we apply full sampling or partial neighbourhood sampling (for larger datasets) during message passing phase in graph neural networks.\n$h_{n}^{(i)}[l+1] = \\phi (\\sum_{r\\in R} \\sum_{j \\in N'_{i}} \\frac{1}{\\sqrt{|N'_{i}|}} W_{r}^{(l)} h_{n}^{(j)} [l] + W_{r}^{(l)} h_{n}^{(i)} [l])$ \t\t(2)\n$\\phi$ denotes the ReLU function and $N'_{i}$ denotes the indices of neighboring nodes with relation $r\\in R$ to the node with index i. $l \\in [1,L]$ denotes the layer with L as the number of layers in the neural network. In Eq. 2, the feature representations of the neighboring nodes of the node with index i are relation-specifically aggregated with the weight matrix $W_{r}^{(l)}$, and normalized by the number of neighboring nodes $(\\sqrt{|N'_{i}|})$. This relation-specific transformation is summed up and extended by a self-loop to include the current representation of the node itself. The ReLU function $\\phi$ is applied as a non-linear activation function. For regularizing the network layers\u2019 weights, basis decomposition is used to avoid a rapid growth in the number of parameters with the number of relations in the graph. Basis decomposition uses a linear combination of basis transformations $V_{b}^{(l)} \\in \\mathbb{R}^{[d^{l+1}] \\times d^{[l]}}$ with coefficients $a_{rb}$, such that only the coefficients depend on r.\n$W_{r}^{(l)} = \\sum_{b=1}^{B} a_{rb} V_{b}^{(l)}$  (3)\nFor ease of reading, we denote the hidden representation of the last layer of sample i in step n as $h^{(i)}_{n}$. MPERL learns a function $S(x^{(i)}, h_{n-1}^{(i)})$ that outputs the parameters of a Dirichlet distribution $\\alpha^{(i)}$, used as conjugate prior of a categorical distribution from which the predictions $\\hat{y}^{(i)}$ are drawn, the hidden features $h_{n}^{(i)}$ and the probability of halting $\\lambda^{(i)}$ at current step. The function $S(x^{(i)}, h_{n-1}^{(i)})$ is learned within a Markov process. We use $\\lambda^{(i)}$ to learn the optimal value n. The Markov process uses a Bernoulli random variable, which we denote as $A_{n}$, to represent the two states continue ($A_{n}$ = 0) and halt ($A_{n}$ = 1). halt is an absorbing state, meaning that, once entered, cannot be left. This defines the end of learning within the Markov process. The Markov process initially starts in the continue state, therefore $A_{0}$ = 0 holds. The transition probability of a sample i that the state halt is assumed in step n, given that the previous step was continue is expressed by the following conditional probability:\n$P(A_{n} = 1 | A_{n-1} = 0) = \\lambda_{n}^{(i)} \\sqrt{} 1 \\leq n \\leq N$   (4)\nThe conditional probability $\\lambda_{n}^{(i)}$ is computed using a sigmoid function $\\sigma$ with parameters $U \\in \\mathbb{R}^{d^{[L]} \\times 1}$ and $h^{(i)}_{n} \\in \\mathbb{R}^{d^{[L]} \\times 1}$, where $d^{[L]}$ denotes the number of dimensions of the hidden features of $h_{n}^{(i)}$ in the last layer.\n$\\lambda_{n}^{(i)} = \\sigma(h_{n}^{(i)}) = \\frac{1}{1+e^{-U^{T}h_{n}^{(i)}}}$\t\t(5)\nThe probability of entering the state halt in step $n \\in [1,N]$ can be derived by means of the following generalized geometric distribution $p_{n}$.\n$p_{n}^{(i)} = \\lambda_{n}^{(i)} \\prod_{s=1}^{n-1} (1 - \\lambda_{s}^{(i)})$  (6)\n$p_{n}^{(i)}$ defines for sample (i.e., entity) i the probability of entering the absorbing state $A_{n} = 1$ for the first time in step n, based on $\\lambda^{(i)}."}, {"title": "3.2 Evidential with Regularization Loss", "content": "Based on existing work (Weller and Paulheim, 2021), we have chosen to use an evidential loss function rather than a cross-entropy function (Banino et al., 2021; Schlichtkrull et al., 2018). However, to simultaneously control the number of steps within the Markov process, our loss function $L$ consists of two terms $L_{Ev}$ and $L_{reg}$. The evidential loss $L_{Ev}$ optimizes the parameter for fitting the predictions $\\hat{y}$ to the target values y, and the regularization loss $L_{Reg}$ optimizes the parameter for the number of Markov steps. For the sake of readability, the following equation defines the loss function for one sample.\nThe loss function $L$ combines fundamental concepts of E-R-GCN (Weller and Paulheim, 2021), PonderNet (Banino et al., 2021), and uncertainty quantification in neural networks (Sensoy et al., 2018). The loss $L$ and the corresponding adjustment of the parameters of the model is computed and adjusted after each epoch and not after each step of the Markov process. The reason for this is that if the weights are adjusted after each Markov step, the rates of convergence are lower, because the network adjusts itself in each Markov step and, thus, produces volatile results. In contrast, computing the loss and adjusting the parameters of the model after each epoch is more natural and allows smoother convergence of the parameters.\n$L=\\sum_{k=1}^{K} \\frac{(y_{k}-\\hat{y}_{k})^{2}+\\frac{\\hat{y}_{k}(1-\\hat{y}_{k})}{\\sum_{k=1}^{K} \\alpha_{k}+1}}{L_{err}} + \\underbrace{\\delta_{1} K L(D(\\tilde{\\alpha}) || D((1,...,1)))}_{L_{unc}} \\Big) \\Big] + \\underbrace{\\beta K L (p_{n} || P_{G}(\\lambda_{p}))}_{Regularization \\ loss \\ L_{Reg}}$  (10)\nIn our loss function, $L_{Ev}$ is the evidential loss across halting steps. Consistent with previous work in evidential learning, the evidential loss $L_{Ev}$ consists of three components: minimizing the error of prediction $\\hat{y}$ ($L_{E}$), minimizing the variance of the Dirichlet distribution to reduce uncertainty ($L_{V}$), and a regularization term which penalizes the predictive distribution, which does not contribute to data fit ($L_{U}$). In order to ensure that the evidential loss is stable even for samples that do not follow the predicted distribution and, therefore, cannot be correctly classified but the loss still decreases towards zero, the Kullback-Leibler (KL) divergence is built into the evidential loss $L_{Ev}$. In related work, it has been shown that using the KL divergence for out-of-distribution samples provides more stable performance in prediction (Sensoy et al., 2018; Weller and Paulheim, 2021), which is why we also use it in our loss $L_{Ev}$ and define it as $L_{unc}$ in Eq. 10. $L_{unc}$ is multiplied by an annealing coefficient $\\delta_{1} = min(1.0,t/10) \\in [0,1]$. We gradually increase this coefficient within the first 10 epochs and keep it fixed afterwards to ensure that the influence of the annealing coefficient increases over the epochs but does not exceed. In this way, we prevent an early convergence to a uniform distribution for the misclassified samples and allow the network to explore the parameter space at the beginning.\nIn $L_{unc}$, $D(\\tilde{\\alpha})$ denotes the Dirichlet distribution with parameter $\\tilde{\\alpha}$ and $D((1,...,1))$ denotes the uniform Dirichlet distribution. $\\tilde{\\alpha}$ is the adjusted evidence of the previous parameter $\\alpha$ and is defined as follows.\n$\\tilde{\\alpha} = y + (1 -y)\\alpha$\t\t(11)\nThe regularization term $L_{unc}$ of the evidential loss with annealing coefficient $\\delta_{1}$, epoch t, gamma function $\\Gamma(\\cdot)$ and digamma function $\\psi(\\cdot)$ is as follows.\nThe goal of KL in the regularization term $L_{reg}$ is to approximate the distribution of $p_{n}$ to the geometric prior probability distribution $P_{G}(\\lambda_{p})$, which is defined by the hyperparameter $\\lambda_{p}$. This distribution describes the probability that the model enters the absorbing state ($A_{n}$ = 1) in step n as follows.\n$P_{G}(\\lambda_{p}) = (1 - \\lambda_{p})^{n-1} \\lambda_{p}$  (13)\nUsing the geometric prior probability distribution $P_{G}(\\lambda_{p})$, an incentive is given to the network to approximate the number of Markov steps to the expected value of the geometric prior probability distribution $E(p_{G}(\\lambda_{p})) = \\frac{1}{\\lambda_{p}}$, i.e. promotes exploration. This incentive can be controlled by the hyperparameter $\\beta$ and is 0.01 in our study. $L_{reg}$ in Eq. 10 is defined as follows.\n$KL(p_{n}||P_{G}(\\lambda_{p})) = log\\frac{\\lambda_{n}}{\\lambda_{p}} + (n-1) \\frac{1-\\lambda_{n}}{1-\\lambda_{p}}$  (14)\nIn summary, the loss function $L$ (see Eq. 10) thus has two functions. On the one hand, the conjugate prior, which in our case is a Dirichlet distribution, is to be fitted in such a way that the deviations between the target values y and the predictions $\\hat{y}$ are minimized by $L_{Ev}$. And on the other hand, the number of Markov steps should be controlled by $L_{Reg}."}, {"title": "4 Experiments", "content": "First, we provide the experimental configuration (\u00a74.1). In our experimental study, we investigate the following questions: (Q1) How effective is MPERL on state-of-the-art benchmarks? (\u00a74.2) (Q2) What are the effects of the hyperparameter $\\lambda_{p}$ of MPERL? (\u00a74.3) (Q3) What is the impact of the MPERL components on the performance? (\u00a74.4) The source code and the datasets are available online\u00b9."}, {"title": "4.1 Experimental Setup", "content": "Datasets. The evaluation is performed using the standard SOTA datasets used for entity classification, i.e., AIFB, MUTAG, BGS, and AM for evaluation (Ristoski et al., 2016). In AIFB, the class affiliation is modeled by the relation employs and affiliation, MUTAG by isMutagenic, BGS by hasLithogenesis, and AM by material. The triples containing these relations have been removed from training. We use predefined train/test splits, which are provided with the datasets. In addition to these benchmark datasets we consider two additional larger benchmarks derived from real-world knowledge graphs, i.e., FB15kET (Bordes et al., 2013b) and YAGO43kET (Moon et al., 2017). We follow the proposed train/valid/test split. The dataset statistics are summarized in Table 1, and the degree of distribution among the entities in the graphs is shown in Figure 2.\nMetrics. We report on the accuracy and F1-macro score for the four smaller datasets. For the larger datasets, we use two ranking-based metrics in a filtered setting\u00b2: Mean Reciprocal Rank (MRR) and proportion of correct entity types predicted in top k (HIT@k, k = 1,3,10). Each experiment is run ten times, and we present the average performance over the test splits.\nApproaches. We implemented MPERL using R-GCN as the GCN-based model in the architecture. Therefore, our experiments report on MPERL+R-GCN as our approach. The baselines used in the experiments include well-known models for entity classification in KGs. For the four smaller datasets, these baselines comprise both GCN-based models, such as R-GCN, E-R-GCN and CompGCN, and embedding-based models including RDF2Vec, ConnectE, and ASSET. In addition, we include Feat (Paulheim and F\u00fcmkranz, 2012), which uses hand-designed feature extractors, and WL (Shervashidze et al., 2011; de Vries and de Rooij, 2015), which uses graph kernels that count substructures in graphs. For all baselines, we used the recommended hyperparameter settings. As reported in previous work (Schlichtkrull et al., 2018; Ristoski and Paulheim, 2016; Ristoski et al., 2019), a linear SVM was used to classify the entities using RDF2Vec, WL, ConnectE, and ASSET. On the larger datasets, we also compare our approach with both GCN-based and embedding-based models. For the GCN-based models, we consider HMGCN, RACE2T, E-R-GCN, RGCN and CompGCN, with R-GCN and CompGCN both using Binary Cross Entropy (BCE) loss. The baselines for the embedding-based models consist of ETE (Moon et al., 2017), ConnectE, RDF2Vec, and ASSET. We reuse the hyperparameters for CompGCN, R-GCN, and E-R-GCN as suggested by their respective authors."}, {"title": "4.2 Accuracy Results", "content": "Results on Small Datasets. These datasets are designed for single-label classification, i.e., every entity belongs to one class. The hyperparameters used for MPERL across the different datasets can be found in the GitHub repository. The results for entity classification are shown in Table 2. We see that MPERL+R-GCN outperforms all the baseline methods. First, we analyse the performance of MPERL+R-GCN with respect to other GNN-based methods. Compared to R-GCN, MPERL+R-GCN does not use a softmax function but a probabilistic loss function consisting of two parts. As a result, our approach\u2019s performance is higher than R-GCN, as the loss used in MPERL+R-GCN captures the information loss between ground truth and predicted distribution. Even though E-R-GCN uses the concept of an evidential loss function as well, the end-to-end learning of R-GCN within a Markov process demonstrates a lower sensitivity to noisy neighbors due to the aggregation of the hidden features of each step in the Markov process, as well as a faster convergence over epochs due to the reuse of the hidden feature $h_{n-1}$ in step n.\nCompared to other methods, WL performs well, especially on MUTAG, which matches the highest accuracy achieved by MPERL. WL also performs well on BGS and AM, making it one of the stronger non-GNN methods. From the embeddings-based method, RDF2Vec performs better in terms of the F1-Macro score than other embeddings. When comparing results across datasets, the embeddings- and GNN-based perform worse for the MUTAG dataset. MUTAG is relatively smaller than other datasets (e.g., BGS and AM) in terms of number of entities, relations, and classes (cf. Table 1). The approaches\u2019 performance indicates that learning effective representations for entities in MUTAG is difficult since the connectivity of the entities is rather irregular, as shown in the degree distribution in Figure 2b. These results show that even in smaller datasets, entity classification can be challenging for state-of-the-art methods.\nResults on Large Datasets. Next, we assess the performance of our studied approach on commonly used large KGs to mimic real-world scenarios, such as YAGO (Suchanek et al., 2007), Freebase (Bollacker et al., 2008), in which each entity can have multiple classes but some of which may be missing. Therefore, in this study, entity classification corresponds to a multi-label classification problem. This task is more challenging than single-label classification, as it requires handling multiple labels for each entity rather than assigning just a single type. Both benchmarks include a significantly higher number of types and labeled entities than those in single-label entity classification, leading to potential GPU memory problems during our experiments. To mitigate this problem, we restrict the maximum number of Markov steps to 2 and apply partial neighborhood sampling. This sampling strategy randomly selects a subset of neighbors for a given entity during message passing in graph neural networks, speeding up training and preventing overfitting. However, it may risk performance degradation if important featured neighbors are not sampled. In practice, we only conduct neighbor sampling during training, while all neighbors of the entity are used during inference. The graphs of large datasets are also augmented with type triples (e, hastype,te) when training embeddings, as proposed by (Pan et al., 2021), which increases the prediction accuracy.\nTable 3 shows the performance of our model and the results of the baselines for both benchmarks. For the FB15kET dataset, MPERL+R-GCN achieves competitive results and especially outperforms all baselines in terms of the Hit@1 metric, indicating its higher accuracy in the top prediction of the missing types. We observe that MPERL+R-GCN shows significant gains in prediction performance compared to its fundamental model, R-GCN, and slightly performs better than E-R-GCN, showing the usefulness of Markov steps in our proposed model. However, regarding YAGO43kET datasets, the performance of MPERL+R-GCN is less powerful compared to the FB15kET dataset. This discrepancy may arise due to key differences between the benchmarks. First, as shown in Figure 2, YAGO contains more higher-degree hub entities (with degrees exceeding 104), which distorts information aggregated from neighbors and reduces model performance, thereby decreasing the performance of our model. Second, as highlighted in Table 1, YAGO43kET contains approximately 12 times more classes than FB15kET, further amplifying the decline in performance. Additionally, due to limited GPU memory, the batch size is set to a small number (16 in practice) for the YAGO43kET dataset, which may potentially lead MPERL to converge to sub-optimal solutions. Overall, MPERL+R-GCN consistently outperforms E-R-GCN in both benchmarks. This demonstrates the benefits of incorporating the Markov process, which can reduce sensitivity to noisy neighbors due to the aggregation of hidden features at each Markov step. The results also show that GNN-based methods tend to yield superior outcomes overall compared to embedding-based approaches. These observations show the potential of graph neural networks as a promising technique for addressing entity-type prediction challenges.\nIn summary, MPERL outperforms the state-of-the-art in small datasets. The consistently high F1-Macro scores indicate that MPERL can effectively classify entities that belong to least represented classes. In large datasets, MPERL showed very good performance in FB15kET but not in YAGO43kET. The sampling techniques implemented to scale MPERL to large datasets may have affected the learning process. These results suggest that our proposed solution is more suitable for smaller knowledge graphs, where learning meaningful representations is challenging due to the limited information contained in these datasets (Q1)."}, {"title": "4.3 Impact of the Hyperparameter Ap", "content": "In the following, we study the impact of the hyperparameter $\\lambda_{p} \\in (0,1"}]}