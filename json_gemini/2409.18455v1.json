{"title": "REVIEW OF DIGITAL ASSET DEVELOPMENT WITH GRAPH\nNEURAL NETWORK UNLEARNING", "authors": ["Zara Lisbon"], "abstract": "In the rapidly evolving landscape of digital assets, the imperative for robust data privacy and compli-\nance with regulatory frameworks has intensified. This paper investigates the critical role of Graph\nNeural Networks (GNNs) in the management of digital assets and introduces innovative unlearn-\ning techniques specifically tailored to GNN architectures. We categorize unlearning strategies into\ntwo primary classes: data-driven approximation, which manipulates the graph structure to isolate\nand remove the influence of specific nodes, and model-driven approximation, which modifies the\ninternal parameters and architecture of the GNN itself. By examining recent advancements in these\nunlearning methodologies, we highlight their applicability in various use cases, including fraud de-\ntection, risk assessment, token relationship prediction, and decentralized governance. We discuss\nthe challenges inherent in balancing model performance with the requirements for data unlearning,\nparticularly in the context of real-time financial applications. Furthermore, we propose a hybrid\napproach that combines the strengths of both unlearning strategies to enhance the efficiency and\neffectiveness of GNNs in digital asset ecosystems. Ultimately, this paper aims to provide a com-\nprehensive framework for understanding and implementing GNN unlearning techniques, paving the\nway for secure and compliant deployment of machine learning in the digital asset domain.", "sections": [{"title": "1 Introduction", "content": "The rise of digital assets, including cryptocurrencies, decentralized finance (DeFi) tokens, and non-fungible tokens\n(NFTs), has revolutionized the global financial landscape. Digital assets operate on decentralized networks, primarily\nusing blockchain technology, which enables secure, transparent, and immutable record-keeping. However, as the use\nof blockchain and digital assets grows, so do concerns related to data privacy, security, and compliance with regulatory\nframeworks like the General Data Protection Regulation (GDPR). These regulations often require users to have control\nover their data, including the ability to have it removed or forgotten\u2014a notion seemingly at odds with blockchain's\nimmutable nature.\nOne of the emerging approaches to addressing these challenges is Graph Neural Network (GNN) unlearning, a method\ndesigned to enable machine learning models, particularly GNNs, to \"forget\" specific data points after they have been\nincorporated into a trained model. GNNs are particularly relevant in the digital asset space due to their capacity to\nmodel complex relationships in blockchain transaction networks, which often take the form of graphs. This paper\nexplores the concept of Graph Neural Network Unlearning for digital assets, focusing on the importance of privacy,\npotential use cases, and methods to implement effective unlearning without compromising the integrity and utility of\nGNNs."}, {"title": "2 Literature Review", "content": "There are two main types of unlearning techniques in the context of machine learning models, including Graph Neural\nNetworks (GNNs): 1. Exact Unlearning and 2. Approximate Unlearning. According to [1], the basic goal for exact\nunlearning is to align the unlearned model's distribution with that of a restrained model, while approximate unlearning\nhas indistinguishable parameters between the unlearned and retrained model.\nExact unlearning involves completely removing the influence of specific data points from a trained machine learning\nmodel. This is typically done by retraining the model from scratch without the data that needs to be forgotten. In the\ncase of GNNs, this would require retraining the entire graph model after removing the nodes or edges corresponding\nto the data that should be unlearned ([2]). The model is guaranteed to no longer retain any information about the\nremoved data, providing strong privacy guarantees. The retrained model is as if the deleted data was never included\nin the first place. The drawbacks of exact unlearning is that retraining can be computationally expensive, especially\nfor large graphs in digital asset applications (e.g., cryptocurrency transaction networks or DeFi systems). This method\nalso requires significant resources and time, making it impractical for real-time or large-scale systems.\nApproximate unlearning aims to minimize the impact of specific data points without completely retraining the model.\nInstead of starting over, the model is incrementally updated to \"forget\" the data in question. This can be achieved\nby reversing the gradients of the data that need to be forgotten or selectively updating the affected parts of the model.\nApproximate unlearning is far more efficient and scalable than exact unlearning. It saves computational resources and\ntime, making it a more feasible solution for real-time applications and large-scale systems like digital asset networks.\nHowever, this method may leave behind residual information about the deleted data, raising concerns about privacy\nin highly sensitive applications. The model might not completely \"forget\" the data, which could be problematic for\nmeeting strict privacy regulations such as GDPR.\nGNN was originally focusing on image and tabular data ([1]). [3] proposes the first GNN exact unlearning approach\ncalled GraphEraser. GraphEraser introduces two balanced partition methods to retain graph structural information.\nLater, [4] created GUIDE that ensures fairness and balance constraints in graph partitioning. GNN has many mature\napplication in representing complex structure like in [5]."}, {"title": "3 Exact Unlearning for GNN", "content": "Exact unlearning utilize a machine learning model in which individual components are trained on disjoint subsets of the\ndata. During deletion, exact unlearning approaches only retrain the affected components rather than the entire model.\n[1] classifies exact unlearning with conventional model with convex function and complex model with non-convex\nfunction. Convex function models are like those introduced in [6] and [7]. Complex models are like optimization\nproblem in [8], where non-convex may produce local optimal solutions, that leads to more computation resourced\nrequired than convex optimization. GNN comes into the picture to help with those non-convex structure.\nFor GNNs, exact unlearning requires retraining the entire graph model from the beginning without the specific nodes,\nedges, or subgraphs that were originally included. This guarantees that the model behaves as if the data had never\nbeen part of the training process."}, {"title": "4 Approximate Unlearning for GNN", "content": "[1] and [9] categorize approximate unlearning into two classes: data-driven approximation and model-driven approx-\nimation. Strategies that focus on manipulating the data are categorized as data driven approximation. [10], [11] and\n[12] use data isolation strategy for data-driven approximate unlearning. Model-driven approximation, on the other\nhand, focuses on the internal components of the model itself rather than the data. This approach modifies the learned\nparameters of the model or its architecture to approximate the removal of data influence. Both approaches aim to\nremove the influence of specific data points from machine learning models, but they differ in their methodologies and\nthe specific components of the learning system they target."}, {"title": "4.1 Data-Driven Approximation in GNNS", "content": "Data-driven approximation focuses on manipulating the training data itself to achieve unlearning. In the context of\nGNNs, this can involve techniques that isolate or modify the graph structure to remove specific nodes (representing\ndata points) and their corresponding edges (representing relationships or interactions). As noted in works like [10],\n[11], and [12], data isolation can be implemented in GNNs by selectively removing nodes from the graph. This means\nthat when a specific user or transaction needs to be unlearned, the corresponding node and its connections can be\nremoved without affecting the remaining graph."}, {"title": "4.2 Model-Driven Approximation in GNNS", "content": "Model-driven approximation, on the other hand, centers around modifying the model's internal components rather\nthan the data itself. In the context of GNNs, this could involve adjusting the learned parameters or architecture of the\nmodel to achieve the desired unlearning effects."}, {"title": "4.3 Comparative Analysis and Relationship to GNNs", "content": "The primary difference between data-driven and model-driven approximations lies in their focus: data-driven ap-\nproaches emphasize modifications to the dataset and its structure, while model-driven strategies concentrate on the\ninternal mechanics of the model.\nInfluence on Performance In GNNs, data-driven unlearning may lead to performance degradation due to the loss of\nstructural information inherent in the graph. In contrast, model-driven unlearning might preserve more of the graph's\nrelational properties while achieving the same objective.\nSuitability for Different Applications The choice between these methods often depends on the application. For\ninstance, in contexts requiring stringent privacy compliance (like financial transactions), data-driven unlearning may\nbe preferred for its directness. In scenarios where computational efficiency is paramount (such as real-time risk\nassessment), model-driven techniques may be more suitable.\nComplementary Approaches Both strategies can be viewed as complementary. Hybrid approaches that incorpo-\nrate aspects of both data-driven and model-driven unlearning may provide the best outcomes, allowing for a balance\nbetween structural integrity, computational efficiency, and compliance with unlearning requirements."}, {"title": "5 GNN Unlearning for Digital Assets", "content": ""}, {"title": "5.0.1 Motivation and Importance", "content": "The core motivation behind GNN unlearning in the context of digital assets stems from the need to balance trans-\nparency and immutability with data privacy and security [13]. While blockchain transactions are inherently designed\nto be permanent and publicly accessible, personal and sensitive data linked to these transactions might need to be\nerased or forgotten in some instances. For example, if a user's wallet data or a transaction that contains sensitive\ninformation is accidentally included in a publicly accessible GNN-based fraud detection model, the user might have\nthe right to request its removal under various privacy regulations. Achieving this in a decentralized and immutable\nenvironment is challenging, especially when the data is integrated into machine learning models such as GNNs.\nAdditionally, digital assets often involve highly dynamic graphs. A cryptocurrency transaction network, for instance,\ncan expand and contract in real-time as new transactions and wallets are created, and as older transactions lose rele-\nvance. Unlearning specific nodes (e.g., user wallets or transactions) or edges (e.g., relationships between wallets) from\na GNN model trained on such a network without retraining the entire model is critical for maintaining operational\nefficiency. The ability to selectively unlearn data ensures that digital asset models stay compliant with evolving regula-\ntory environments while continuing to provide accurate and real-time predictions, such as risk assessments or market\nforecasts.\nThe Role of GNNs in Digital Asset Applications Graph Neural Networks have become a powerful tool for understand-\ning and predicting patterns in blockchain networks. A GNN can model the interactions between wallets, transactions,\nsmart contracts, and digital asset exchanges, allowing for a deeper understanding of the financial ecosystem. For in-\nstance, GNNs are used for fraud detection in cryptocurrency transactions by identifying suspicious patterns of behavior\nacross related entities. Similarly, GNNs can analyze the flow of tokens within decentralized finance applications to\nprovide better credit scoring and assess risks in lending markets.\nIn these applications, nodes represent entities such as wallets, transactions, or contracts, while edges represent the\nrelationships between them, such as token exchanges, transaction histories, or trust ratings. This graph structure\nis well-suited for detecting patterns that would be difficult to recognize using traditional machine learning models.\nHowever, the very nature of this data poses unique challenges when it comes to compliance with privacy regulations.\nFor example, if a GNN model has learned from a set of transactions that involve a user who later requests their data\nto be erased, simply deleting the user's data from the model is insufficient due to the complex relational dependencies\nthat GNNs leverage."}, {"title": "5.1 Core Challenges in GNN Unlearning for Digital Assets", "content": "Unlearning in GNNs, particularly for digital asset applications, faces unique challenges that make the process more\ncomplex compared to traditional unlearning tasks. These challenges stem from both the structure of blockchain net-\nworks and the real-time, dynamic nature of digital asset markets."}, {"title": "5.2 Methods for GNN Unlearning in Digital Assets", "content": "Addressing the challenges of GNN unlearning for digital asset applications requires a range of techniques that balance\nefficiency, scalability, and privacy. Below are some of the potential methods for achieving effective unlearning in this\ndomain:"}, {"title": "5.3 Use Cases for GNN Unlearning in Digital Assets", "content": "Graph Neural Network unlearning for digital assets has several key use cases, each with its own set of privacy and\nsecurity requirements. Below, we explore some of the most important applications of GNN unlearning in this domain:"}, {"title": "5.4 Technical Methods for Implementing GNN Unlearning in Digital Assets", "content": "To effectively implement GNN unlearning in digital asset applications, several technical methods can be employed.\nThe goal is to balance model accuracy, computational efficiency, and compliance with privacy regulations. Below\nare the leading technical approaches for GNN unlearning, particularly in the context of blockchain-based financial\nsystems:"}, {"title": "5.5 Evaluation Metrics for GNN Unlearning in Digital Assets", "content": "For GNN unlearning methods to be effectively integrated into digital asset applications, their performance must be\nrigorously evaluated across several dimensions. Below are the key metrics used to assess GNN unlearning techniques:"}, {"title": "6 Conclusion and Future Direction", "content": "Graph Neural Network (GNN) unlearning for digital assets represents a critical intersection of privacy, regulatory\ncompliance, and performance in decentralized finance and blockchain applications. As digital assets become more\npervasive, and as regulatory frameworks continue to evolve, the need for sophisticated unlearning techniques will only\ngrow. Whether in fraud detection, risk assessment, token relationship prediction, or decentralized governance, GNNs\nplay a pivotal role in analyzing the vast and intricate networks of relationships that underpin these systems.\nBy incorporating robust unlearning techniques, organizations can ensure that their GNN models remain compliant\nwith privacy regulations while maintaining the high levels of performance needed for real-time financial applications.\nMethods such as graph modification, selective retraining, and federated GNN unlearning provide practical solutions\nfor achieving this balance, allowing digital asset ecosystems to grow without compromising privacy or security. As\nGNN unlearning continues to advance, it will unlock new possibilities for data privacy in decentralized networks,\nultimately shaping the future of blockchain-based financial systems."}]}