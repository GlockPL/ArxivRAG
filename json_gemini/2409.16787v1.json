{"title": "Enhancing Feature Selection and Interpretability in AI Regression Tasks Through Feature Attribution", "authors": ["Alexander Hinterleitner", "Thomas Bartz-Beielstein", "Richard Schulz", "Sebastian Spengler", "Thomas Winter", "Christoph Leitenmeier"], "abstract": "Research in Explainable Artificial Intelligence (XAI) is increasing, aiming to make deep learning models more transparent. Most XAI methods focus on justifying the decisions made by Artificial Intelligence (AI) systems in security-relevant applications. However, relatively little attention has been given to using these methods to improve the performance and robustness of deep learning algorithms. Additionally, much of the existing XAI work primarily addresses classification problems. In this study, we investigate the potential of feature attribution methods to filter out uninformative features in input data for regression problems, thereby improving the accuracy and stability of predictions. We introduce a feature selection pipeline that combines Integrated Gradients with k-means clustering to select an optimal set of variables from the initial data space. To validate the effectiveness of this approach, we apply it to a real-world industrial problem \u2013 blade vibration analysis in the development process of turbo machinery.", "sections": [{"title": "1. Introduction", "content": "Neural networks have proven to be universal function approximators, especially for high dimensional and complex data sets [1][2]. However, despite their powerful capabilities, they often require substantial computational resources, and their predictions lack interpretability due to their black-box nature. While neural networks can learn complex representations, feature selection may enhance efficiency and performance [3] [4]. In the context of neural networks, classical approaches such as wrapper methods are often computationally prohibitive due to the necessity of multiple training and evaluation cycles. Filter methods select features by looking at their statistical properties (e.g., correlation, mutual information) with respect to the target variable. These methods do not involve the model itself and tend to capture only linear or simple relationships between features and the target. Since neural networks are known for their ability to model complex, non-linear patterns in data, filter methods are often not sufficient in such cases, as they may not be able to detect important feature interactions that only become apparent when modeling more complex structures."}, {"title": "2. Related Work", "content": ""}, {"title": "2.1. Classical Feature Selection Methods", "content": "Feature selection is an important part of the preprocessing stage in machine learning applications. Especially for high-dimensional problems, the reduction of input features can speed up the training of the algorithm and make the problem more interpretable. The prediction quality of the model can also be improved by eliminating disturbance variables. Classic feature selection methods can be categorized as filters, wrappers, and embedded methods [15][16][17].\nFilter methods for feature selection are computationally efficient techniques that evaluate the relevance of features independently of any specific learning algorith. These methods typically employ statistical measures to score and rank features based on their correlation with the target variable. Common filter approaches include the Pearson correlation coefficient [18], mutual information [19], Chi-squared test [20], and information gain [21]. The key advantage of filter methods is their speed and scalability, making them suitable for high-dimensional datasets. However, they usually do not consider feature interactions or complex non-linear correlations. These methods are often used as preprocessing steps or baselines for more sophisticated methods [22][23].\nThe second category of feature selection algorithms is wrapper methods. These methods are model-dependent and use the model's performance as a criterion to evaluate feature subsets, effectively \"wrapping\" the selection process around the model itself [24]. One common approach within this category is forward selection, where the process begins with an empty feature set and iteratively adds features that maximize model performance. At each iteration, the model is trained on the current feature subset along with each remaining feature individually, and the feature that yields the highest performance improvement is permanently added to the subset. This continues until no significant improvement is observed or a predetermined number of features is"}, {"title": "2.2. Feature Attribution", "content": "Feature attribution methods have become essential tools for interpreting complex machine learning models. These methods aim to quantify the importance of input features on a model's predictions, thereby increasing model transparency and aiding feature selection. In this section, we review state-of-the-art feature attribution methods, highlighting both model-agnostic and model-specific approaches.\nIntroduced by Lundberg and Lee (2017) [6], SHAP (SHapley Additive exPlanations) consolidates several prior attribution methods into a unified framework based on Shapley values from cooperative game theory. This approach provides a consistent and theoretically sound method for feature attribution, maintaining properties such as local accuracy and consistency. Its versatility allows it to effectively analyze feature importance across various machine learning models. However, it is important to note that SHAP's computational demands can sometimes be prohibitive, especially with large datasets and complex models, as it requires evaluating numerous feature combinations to compute the Shapley values. Another model-agnostic approach is proposed by Ribeiro et al. (2016) [7]. LIME (Local Interpretable Model-agnostic Explanations) explains individual predictions by approximating the model locally with an interpretable model, often linear regression. While LIME's flexibility and user-friendly nature contribute to its popularity, it may exhibit less stability and consistency compared to SHAP, primarily due to its reliance on local approximations. A third notable model-agnostic method is permutation-based variable importance [32]. It assesses how the model's prediction error changes when the values of a feature are permuted. This technique offers a global measure of feature importance applicable to any model. However, Feature Permutation can be computationally intensive for high-dimensional data and may not fully capture complex feature interactions.\nOther attribution methods have been developed specifically for certain models, utilizing components inherent to their architectures, such as gradients in neural networks. DeepLIFT, proposed by Shrikumar et al. (2017) [8], calculates importance scores by comparing neuron activations to reference activations. Effective for non-linear models, DeepLIFT captures complex feature interactions, particularly beneficial for high-dimensional problems. It serves as a faster alternative to SHAP values while maintaining interpretability. Introduced by Bach et al. (2015) [10], Layer-Wise Relavance Propagation (LRP) decomposes the output of a neural network recursively, layer by layer, assigning relevance to each input feature. While originally developed for image classification, it has been adapted for other tasks. LRP provides detailed attributions at the input feature level, but can be computationally intensive for deep networks. IG, developed by Sundararajan et al. (2017) [9], attributes predictions of deep networks by accumulating gradients along a straight-line path from a baseline to the input. This method satisfies essential axioms such as completeness and sensitivity, making it well-suited for neural network models. IG leverages gradient information inherent in neural networks, ensuring efficient computation and scalability to high-dimensional data.\nWhile the majority of XAI investigations in real-world scenarios have focused on classification problems, there are some publications exploring the application of these techniques to regression tasks. Recent studies have demonstrated the potential of XAI methods in several domains where regression models are prevalent. Mamalakis et al. (2023) conducted a comprehensive analysis of feature attribution methods in climate science [11]. Their work highlights the importance of carefully selecting baselines when applying XAI techniques to regression problems in geoscientific applications. The authors showed that different baselines can lead to substantially different attributions, both in magnitude and spatial patterns, emphasising the need for"}, {"title": "2.3. Neural Networks for Turbo Machinery", "content": "Turbomachines are inherently complex systems characterized by highly nonlinear physical processes. The vibration behavior of these machines is influenced by numerous unknown variables, making accurate modeling and analysis challenging. Additionally, the presence of measurement noise further complicates the identification of underlying patterns and behaviors. Therefore, the integration of Deep Learning and Machine Learning into turbomachinery design has garnered significant attention in recent years, with various studies exploring their potential to enhance design efficiency and performance."}, {"title": "3. Background of the Real World Problem", "content": ""}, {"title": "3.1. High-Cycle Fatigue in Turbo Charging Systems", "content": "Modern turbocharging systems are critical for enhancing the efficiency and power of engines. Beside the classic automotive domain this technology is intensively developing in the marine and power industry. There is a growing need to push the technological boundaries of these systems, optimizing layout parameters beyond traditional applications. The market demands turbochargers capable of achieving higher pressure ratios and increased flow capacities while maintaining the highest efficiencies. These features are crucial not only for the competitiveness of the turbocharger itself but also for the engine manufacturers who significantly benefit from this new generation of turbochargers [38].\nHowever, these advancements come with substantial challenges. Components such as compressors and turbines must withstand higher loads, requiring robust designs that account for various fatigue conditions, including low-cycle fatigue, thermo-mechanical fatigue, and especially high-cycle fatigue (HCF) [37][38][39]. As pressure levels rise, the vibrations get stronger, and the faster air flow makes the conditions more complex, causing more stress on the parts. To meet thermodynamic demands for efficiency and pressure, bladed nozzle rings with minimal clearance to rotating parts are used. This design choice focuses on the related excitation orders (EOs) and the blade design itself to ensure an HCF-safe design. Additionally, the wide variety of differing variation parts used in turbochargers to meet specific medium- and low-speed engine requirements adds another layer of complexity. This complexity is particularly pronounced in the area of vibration analysis, where complex interactions must be thoroughly understood. Engineers often focus on determining resonant frequencies with their vibration behavior and assessing the effects of various physical parameters [38][40].\nTraditionally, this process relies heavily on extensive numerical simulations and physical testing, the latter of which can be particularly costly and time-consuming. Due to the high cost of testing these configurations, data-driven approaches are being explored to complement and partially replace traditional methods in determining HCF-safe designs. This involves predicting amplitudes, as discussed in this paper."}, {"title": "3.2. Description of Experiment Data", "content": "The data was provided by MAN Energy Solutions. Due to confidentiality and the high level of competition in this domain, we are not authorized to publish the data. The data set is based on a test setup for"}, {"title": "4. Methods", "content": ""}, {"title": "4.1. Data Preprocessing", "content": "In our experiments, we utilize 86 features. The target variable we aim to predict is the upgraded oscillation amplitude at the rotor blades of the system. Most of the data consists of numerical values, except for two features that contain categorical data: the labels of the strain gauges and the measurement series. First, we remove data points that contain NA entries or are labeled with insufficient measurement quality. We also exclude data with implausible values, such as negative values for modes or frequencies that are too low and were not part of the measurement process. After this filtering process, we retain 27,857 data samples."}, {"title": "4.2. Neural Network Architecture and Hyperparameter Tuning with spotpython", "content": ""}, {"title": "4.2.1. Introduction to spotpython", "content": "Surrogate model-based optimization methods are widely used in the fields of simulation and optimization. The Sequential Parameter Optimization Toolbox (SPOT) was developed to address the need for robust statistical analysis of simulation and optimization algorithms. It is freely available on GitHub as a Python package, spotpython. SPOT offers advanced methodologies for optimization (tuning), based on classical regression techniques and analysis of variance. It includes state-of-the-art tree-based models such as classification and regression trees, and random forests, as well as Bayesian optimization models like Gaussian processes, also known as Kriging. Additionally, SPOT allows for the integration and combination of different meta-modeling approaches.\nSPOT comes equipped with a sophisticated surrogate model-based optimization method capable of handling both discrete and continuous inputs. Furthermore, any model implemented in scikit-learn can be seamlessly used as a surrogate within spotpython, providing extensive flexibility to users.\nSPOT also implements crucial techniques such as exploratory fitness landscape analysis and sensitivity analysis. These features enable users to comprehensively understand the performance and underlying behavior of various algorithms, thus enriching algorithmic insights and enhancing optimization outcomes. Hyperparameter tuning can be performed using SPOT, which is particularly useful for optimizing neural network architectures.\nThe spot loop consists of the following steps:\n1. Init: Build initial design X\n2. Evaluate initial design on real objective f: y = f(X)\n3. Build surrogate: S = S(X, y)\n4. Optimize on surrogate: X\u2081 = optimize(S)\n5. Evaluate on real objective: yo = f(Xo)\n6. Impute (Infill) new points: X = XU Xo, y = y U yo.\n7. Goto 3."}, {"title": "4.2.2. The Neural-Network Architecture", "content": "A neural network class for regression tasks implemented in spotpython is used for the neural network for both dummy data and real-world experiments. The network is a multi-layer perceptron (MLP) that is constructed using the Python frameworks PyTorch and PyTorch-Lightning [41] [42]. This network consists of four hidden layers. The input layer has the same dimension as the feature space. The optimal number of neurons in the first hidden layer is determined through hyperparameter tuning. The second and third hidden layers have half of the neurons of the first hidden layer, while the third hidden layer has only a quarter of the neurons of the first hidden layer. After each of these layers, there is a dropout layer. The output layer of the network is a linear layer with one neuron, as we want to predict one target variable. During hyperparameter optimization, the activation functions of the hidden layers, the batch size, the dropout probabilities of the dropout layers, the number of training epochs, and the number of neurons in the first hidden layer are optimized. In addition, the best optimizer and the number of epochs that the training is continued without improvement in performance are determined. Instead of tuning the learning rate itself, a multiplication factor"}, {"title": "4.3. Integrated Gradients", "content": "Introduced by Sundararajan et al. (2017), IG is a feature attribution method that aims to attribute the prediction of a deep learning model to its input features by integrating gradients along the path from a baseline input to the actual input [9]. The key idea is to compute the integral of the gradients of the model's output with respect to the input features, taken along a straight path from a baseline (typically an input with no information, such as a black image or a zero vector) to the actual input. The algorithm fulfills the two axioms of sensitivity and implementation invariance. Sensitivity means that if an input feature changes the model's prediction, the attribution for that feature should be non-zero. Implementation invariance means that if two models produce the same prediction for the same input, the attribution values should also be the same. IG can be described by the following formula:\n$IG_i(x) = (x_i - x') \\times \\int_{\\alpha=0}^{1} \\frac{\\partial F(x' + \\alpha \\times (x - x'))}{\\partial x_i} d\\alpha$\nwhere:\n\u2022 x is the input for which the attributions are computed.\n\u2022 x' is a baseline input.\n\u2022 \u03b1 is a scalar that scales the interpolation between the baseline input x' and the input x.\n\u2022 $\\frac{\\partial F(x)}{\\partial x_i}$ is the gradient of the model output F(x) with respect to the i-th input feature.\nSince calculating the integral directly can be computationally intensive, it is often approximated using methods like the Riemann sum or Gauss-Legendre quadrature rule. For our specific problem of selecting the most relevant features to improve neural network regression performance, we argue that IG is the most suitable approach. This choice is supported by several key advantages that IG offers in the context of complex neural network models. Firstly, IG stands on a solid theoretical foundation. It satisfies important axioms such as completeness and sensitivity, ensuring that the attributions it provides are both reliable and consistent [9] [43]. This theoretical soundness is crucial when dealing with the intricate decision-making processes of neural networks. Secondly, IG demonstrates excellent scalability, a critical factor in our high-dimensional regression tasks. Its computational efficiency allows it to handle large-scale datasets without compromising performance, making it particularly well-suited for complex regression problems that often involve numerous input features. As a model-specific method, IG provides insights that are directly tied to the neural network's internal workings. This characteristic allows for more accurate and relevant attributions compared to model-agnostic approaches, which may not capture the nuances of the neural network's decision-making process. Furthermore, IG's gradient-based approach aligns well with the architecture of neural networks. By leveraging the gradient information that is readily available in these models, IG can efficiently perform attributions by quantifying how infinitesimal changes in input features affect the prediction, making it a natural fit for our neural network-based regression tasks [43]. Lastly, IG excels in handling non-linearity, a common characteristic of complex neural network models. Unlike simpler attribution methods, IG can effectively capture and represent non-linear relationships between inputs and outputs, providing a more comprehensive understanding of feature importance in our regression tasks."}, {"title": "4.4. KernelSHAP", "content": "Kernel SHAP is an estimation method for Shapley values using a weighted linear regression. The Shapley value for a feature (i) can be approximated as [6]:\n$\\Phi_i = \\sum_{z' \\subseteq z} \\frac{|Z|-1}{(2 \\atop |z'|)} [f(z'\\cup x_i) - f(z')]$\nwhere:\n\u2022 i is the Shapley value for feature i.\n\u2022 z' represents a subset of the feature set x'.\n\u2022 Z is the total number of features.\n\u2022 z' is the number of features in subset z'.\n\u2022 f(z' \u222axi) is the model output when feature i is added to subset z'.\n\u2022 f(z') is the model output for subset z'.\nWe use this approach to compare the feature selection abilities with our approach that relies on IG. We chose this method because Shapley values are one of the most well-known XAI methods. For our real-world experiments, where we have an initial data set of 86 features, computing the classical Shapley values would be computationally unfeasible, due to their exponential time complexity [44]. Therefore, we decided to use KernelShap as an approximator."}, {"title": "5. Experimental Setup", "content": "To underline the reliability of our methods, we start by applying IG to a dummy dataset that we generated. This allows us to determine the ground truth regarding the importance of the variables and to test whether"}, {"title": "5.1. Dummy", "content": "To generate the dummy data, we have written a function based on a linear model. The coefficients are generated using a uniform distribution. To resemble the real-world experiment, 86 coefficients are generated. It is assumed that 29 of the coefficients are positively correlated with the target variable (coefficients between 0.1 and 1), and another 29 are negatively correlated (coefficients between -0.1 and -1). The remaining 28 coefficients have no significance for predicting the target variable and therefore have a value of 0. The coefficients are multiplied by randomly generated X values, which add up to the target variable. Analogous to our real-world experiments, 27,857 data points are generated in this manner. No feature interactions are considered, as this information is not available for the real-world data either. The source code for generating the data, as well as the data itself, can be found on GitHub\u00b2. In the dummy experiments, the aim is to filter out these insignificant values using IG. Therefore we start by optimizing the neural network based on the tuning setup as described in Section 4.2, followed by the IG analysis."}, {"title": "5.2. Real World Experiment", "content": ""}, {"title": "5.2.1. Baseline with linear Model", "content": "For some engineering problems, classical regression models are better suited than more advanced algorithms. Classical models also have the advantage that the results are often much easier to interpret. For complex problems involving non-linearities and noisy data, more complex black box models such as neural networks are the better choice [45][1]. To ensure that our problem is non-trivial and necessitates advanced methods, such as a neural network, we first attempt to predict the oscillation amplitudes using simple linear regression, employing the sklearn implementation [46]. We utilize all 86 features, as described in Chapter X, and split the data into 70% training and 30% test sets. Additionally, we perform five fold cross-validation to ensure robust and reliable results."}, {"title": "5.2.2. Feature Selection Pipeline", "content": "Our novel feature selection process can be described as a data-driven reverse engineering approach. First, the neural network is tuned, taking into account all available features. This ensures that we have a suitable architecture for the corresponding data. This step is particularly important because feature attribution methods, such as IG, examine the extent to which features contribute to the prediction of the target variables. Therefore, the trustworthiness of these methods depends on the performance of the network. After optimizing the hyperparameters, the model is tested using a k-fold cross-validation with five folds. Model performance for all experiments in this article is measured using Mean Squared Error (MSE). This metric is particularly suitable for our use case, where predicting oscillation amplitudes accurately, including extreme values or outliers, is crucial. MSE is the preferred choice because it penalizes outliers more heavily during training, thus encouraging the model to improve its predictions for these extreme values. The attribution values are calculated using an IG implementation that uses a Gaussian Legendre quadrature with 50 approximation steps from the Python package Captum [47]. The algorithm computes local attribution values for each sample in the dataset. To make a global statement about the importance of the features, the mean of all local attribution values is determined. The baseline can be viewed as a state where all features are absent, which in our case means that the system is in a state where it does not vibrate at all. Since we aim to determine the features generally relevant for predicting upgraded vibration amplitudes, we set the baseline for IG to a null vector. Changing the baseline to a state of expected vibration would be more appropriate if we wanted to explain individual predictions that deviate from the expected behavior. After aggregating the attribution values, they are grouped using a K-Means clustering algorithm [48]. The number of clusters (k) is varied to categorize the features into different importance classes. Following each clustering procedure, the cluster containing the least important features is removed from the dataset. This process results in n"}, {"title": "5.2.3. Feature Selection Validation Experiments", "content": "As this work serves as a proof of concept for utilizing feature attribution for explainable feature selection, we aim to validate our approach by conducting four additional comparative experiments.\nIn the first experiment, we perform a Cross-Check by taking the best performing feature subset identified previously and then tune and evaluate a network using the remaining features from the initial feature set, which were identified as having the lowest information density. It is hypothesized that the performance of this model should be significantly worse compared to the model utilizing the important features. This procedure is designed to verify that the feature importance methods have a meaningful impact and do not"}, {"title": "6. Results and Discussion", "content": "The \"Results and Discussion\" chapter is divided into two sections: the results related to the dummy data and the results of the real-world experiments. The first section validates the ability of IG to detect the most important features based on the known ground truth of the dummy data. The second section discusses the outcomes of the real-world experiments."}, {"title": "6.1. Results and Discussion of the Dummy Data Experiments", "content": "Figure 3 demonstrates the neural network's ability to capture the behavior of the dummy data. This is visualized by comparing the actual and predicted values, as well as by showing the residuals of the predicted values. Due to the simple linear characteristics of the dummy data, the network predicts the target values with high accuracy, as indicated by the very small residuals compared to the target values. The average MSE after cross-validation is 0.00073. Ensuring suitable performance is crucial because the quality of the attribution methods highly depends on the network's prediction accuracy."}, {"title": "6.2. Results and Discussion Real World Experiment", "content": "The linear model, which serves as a baseline for our real-world experiments, achieves an average MSE of 32,993 across five folds during cross-validation. This performance is significantly worse than that of our initial neural network, which achieves an average MSE of 8.718. This result demonstrates that employing neural networks to capture the complex non-linear patterns inherent in the underlying real-world problem is a more effective approach.\nWhen applying our feature selection pipeline, the attribution values, which are based on the IG analysis of the initially tuned network with all features, were clustered several times. The value of k was changed for each clustering. In total, clustering was performed nine times with k values ranging from two to ten. For each clustering run, the cluster with the lowest attribution values, and therefore the lowest relevance for the prediction, was removed from the initial feature set. An examplary plot of the clustering process for k = 6 can be seen in Figure 5. The points below and on the red dotted line correspond to the lowest attribution values. The features that are related to these points are removed during the feature selection process. The visualization of all clustering runs for all different k-values can be seen in the appendix. This visualizations show that these clusters are identical for k values four and five, as well as six to ten. This reduces the number of tunings and evaluations performed with different feature sets from ten to five (including the initial evaluation with all features)."}, {"title": "6.2.1. Results and Discussion of the Feature Selection Validation Experiments", "content": "The results of the cross-validation experiments suggest that our approach outperforms the other methods used for comparison in the feature selection process. The experiment using the least important features identified by our approach yields a MSE nearly three times higher than that of the 64 most significant features determined by IG (see Table 5). This outcome serves as a plausibility check for our method, confirming its effectiveness. Utilizing Pearson correlation for selecting the top 64 informative features results in poor performance. This can be explained by the fact that all Pearson correlation values are below 0.15. It is important to note that Pearson correlation only accounts for linear relationships, which appears inadequate for accurately capturing the complexities of a real-world dataset. Lasso Regression, as a standard feature selection technique, performs better than Pearson correlation but does not achieve as low an MSE as the IG approach. However, the standard deviation of the results is relatively low, indicating that the algorithm successfully captures global importances. By introducing the regularization term, Lasso Regression builds a more stable model compared to other approaches. The KernelShap method serves as a direct competitor to IG, as both are feature attribution techniques. The results indicate that the neural network utilizing the 64 most important features identified by KernelShap performs better than those relying on classical feature selection approaches. However, the average MSE is higher than that of the IG experiment, and the standard deviation is more than twice as high. The results underline our assumption that the feature selection loop based on IG is a suitable approach for identifying the most important features. IG considers the gradient information of the network, which is essential for the algorithm's decision-making process. This can be particularly beneficial when working with high-dimensional and complex data in the domain of neural networks, compared to other feature selection methods."}, {"title": "6.3. Feature Importance Discussion", "content": "While our primary goal is to use feature attribution for feature selection, these methods also provide valuable insights into the decision-making process of the network, potentially revealing previously unknown aspects of the underlying physical process. Figure 7 illustrates the feature importance across various feature categories as outlined in Section 3.2. It is evident from the figure that IG identifies the oscillation mode (index 8) from the \"Oscillation Characteristics\" group as the most significant variable for predicting the updated oscillation amplitude. From an engineering perspective, this is entirely logical, as the mode (the natural frequency) is a key characteristic of the oscillation. Within the same group, another crucial feature is the excitation order (index 5). From the category of thermodynamic variables, several features stand out as influential in the neural network's prediction process. These include two temperatures measured on the drive train (indices 80 and 83), the mass flow of air in front of the compressor (index 30), the volume flow of air in front of the compressor (index 29), and the pressure of the lubricating oil (index 72). The high importance of the temperature values measured on the drivetrain is particularly interesting. This could be"}, {"title": "7. Conclusion", "content": "Even though neural networks possess structural feature engineering capabilities, this work demonstrates that feature attribution serves as an effective tool for explainable feature selection. This approach enhances model performance and stability by identifying informative features and filtering out noise and disturbances in the data. By combining feature attribution with clustering techniques, we present a data-driven method for categorizing features based on their importance, thereby eliminating the need for arbitrary thresholds in feature selection.\nOur approach serves as an embedded feature selection method for neural networks, utilizing the model's gradient information to evaluate feature importance directly from its decision-making processes. This strategy enhances predictive accuracy and robustness by eliminating noise in the input, which in turn reduces the standard deviation of the error. Additionally, it offers valuable insights into the model's reasoning, promoting the development of more transparent and interpretable AI systems."}]}