{"title": "Identifying and Manipulating Personality Traits in LLMs\nThrough Activation Engineering", "authors": ["Rumi A. Allbert", "James K. Wiles"], "abstract": "The field of large language models (LLMs) has grown rapidly in recent years, driven by\nthe desire for better efficiency, interpretability, and safe use. Building on the novel approach\nof \"activation engineering,\" this study explores personality modification in LLMs, drawing\ninspiration from research like \"Refusal in LLMs is Mediated by a Single Direction\" [1] and\n\"Steering Llama 2 via Contrastive Activation Addition.\" [8] We leverage activation engineering\nto develop a method for identifying and adjusting activation directions related to personality\ntraits, which may allow for dynamic LLM personality fine-tuning. This work aims to further\nour understanding of LLM interpretability while examining the ethical implications of such\ndevelopments.", "sections": [{"title": "Introduction", "content": "Large language models have been developed with ongoing efforts to improve their functionality,\ncomprehend their internal workings, and guarantee their ethical and safe application. New de-\nvelopments in the field have led to the concept of \u2018activation engineering\u2019[13], which posits that\nactivation vectors can mediate particular behaviors within LLMs. This development has made it\npossible to adjust and regulate the output of these models in new ways.\n\nThis paper is motivated by the potential to extend this line of inquiry into the domain of\npersonality traits in LLMs. The ability to dynamically adjust the personality of a language model\nwithout extensive retraining could mark a significant advancement in the field, offering improved\nflexibility in AI applications. This approach could potentially revolutionize how we interact with\nand deploy AI systems, allowing for more personalized and context-appropriate responses.\n\nHowever, the pursuit of such capabilities is not without challenges. The ethical implications\nof manipulating AI personalities raise important questions about the boundaries of AI develop-\nment and the potential for misuse. By focusing on the intersection of activation engineering and\npersonality manipulation, our research aims to contribute to the broader discourse on AI ethics."}, {"title": "Methods", "content": null}, {"title": "Feature Induction via Weight Orthogonalization", "content": "TL;DR Methodology We propose an approach for 'fine-tuning' certain personality features in\nlarge language models (LLMs) that we name \u201cfeature induction.\" By comparing the activation\nvectors generated by prompts expressing a desirable personality trait to those generated by neutral\nprompts, we can find a direction in the activation space that correlates to that feature. This\napproach allows for precise personality changes without affecting the model's overall understanding\nor necessitating extensive retraining.[7]"}, {"title": "Methodology", "content": "Our method is an adaptation of feature ablation via weight orthogonalization[1]; however, our goal\nis to induce and increase desired personality traits in the responses of the model, rather than\nsuppressing undesirable features. We use a uncensored language model to examine the widest\nvariety of personalities, including those that are frequently considered sensitive or improper. With\nthis decision, we can investigate features that could be intentionally repressed in safety-mechanism-\nequipped, commercial versions."}, {"title": "Original Concept: Feature Ablation", "content": "The basic approach to feature ablation through weight orthogonalization is to intervene in the\nmodel's inference phase to stop it from representing a particular direction in its activation space,\nwhich is represented by the notation \\( \\hat{i} \\). This undesirable direction frequently reflects a behavior\nor characteristic that the model developers are attempting to suppress. For every contribution\n\\(C_{out} \\in \\mathbb{R}^{d_{model}}\\), the component along the \\(\\hat{i}\\) direction is effectively \u201czeroed\nout\" using the following operation:\n\n\n\\(C_{out} \\leftarrow C_{out} - (C_{out} \\cdot \\hat{i}) \\hat{i}\\)                                                                                  (1)\n\nDirect modifications to the weight matrices of the model can also accomplish this component\nelimination. To make sure that information is never written along a particular direction, \\(W_{out} \\in\n\\mathbb{R}^{d_{model} \\times d_{input}}\\) can be orthogonalized with regard to each matrix that contributes to the residual\nstream:\n\n\\(W_{out} \\leftarrow W_{out} - (W_{out} \\cdot \\hat{i}) \\hat{i}\\)                                                                                     (2)\n\nThe attention output matrices, MLP output matrices, positional embedding matrix, and embed-\nding matrix are among the matrices in a transformer architecture that write to the residual stream."}, {"title": "Our Implementation: Feature Induction", "content": "Instead of suppressing features, we leverage a similar principle to enhance desired personality traits.\n\n1. Calculate the Difference in Means for Activations The mean activation vectors for\ntwo sets of prompts those that match the desired personality trait and those that don't are first\ncalculated. The direction connected to the personality trait is indicated by the difference between\nthese mean vectors.\n\nWe extract the activation vectors for each prompt from a particular layer in the architecture of\nthe model. We discovered through empirical observation that Layer 18 had the biggest impact on\nhow personality traits were expressed in the model's output. [2]\n\nFor both the neutral and trait prompts, we compute the mean activation vector. We obtain the\npersonality direction vector r from the difference between these two mean vectors. In essence, this\nvector indicates the area of the activation space where the target personality trait is most strongly\nexpressed:\n\n\\(r = \\frac{1}{N_t} \\sum_{i=1}^{N_t} a_{i}^{trait} - \\frac{1}{N_n} \\sum_{i=1}^{N_n} a_{i}^{neutral}\\)                                                                         (3)\n\nwhere:\n\n\u2022 r is the personality direction vector.\n\n\u2022 nt is the number of samples with the desired personality trait.\n\n\u2022 nn is the number of neutral samples (without the trait).\n\n\u2022 \\(a_i^{trait}\\) is the activation vector for the i-th sample with the desired personality trait.\n\n\u2022 \\(a_i^{neutral}\\) is the activation vector for the i-th neutral sample.\n\nAn alternative approach involves computing the difference between each pair of correspond-\ning trait and neutral activation vectors and then calculating the mean of these differences. This\napproach can potentially capture more nuanced variations in the data:\n\n\\(r = \\frac{1}{n} \\sum_{i=1}^{n} (a_{i}^{trait} - a_{i}^{neutral})\\)                                                                                                            (4)"}, {"title": "Induce the Personality Direction", "content": "To induce the influence of the target personality\ntrait, we project the model's output activation vectors onto the previously calculated personality\ndirection vector r. This projection is then added back to the original activation vectors, effectively\namplifying the influence of the target trait on the model's output:\n\n\\(a' = a - (a \\cdot r)r + \\alpha \\cdot (\\frac{1}{N_t} \\sum_{i=1}^{N_t} (a_{i}^{trait} \\cdot r)) r\\)                                                                                 (5)\n\nwhere:\n\n\u2022 a is the original activation vector.\n\n\u2022 a' is the adjusted activation vector.\n\n\u2022 \\((a \\cdot r)\\) is the dot product of the activation vector and the personality direction.\n\n\u2022 \\(\\frac{1}{N_t} \\sum_{i=1}^{N_t} (a_{i}^{trait} \\cdot r)\\) is the average projection of the trait-related activations onto the personality\ndirection.\n\n\u2022 Note that nt refers to the total number of samples exhibiting the desired personality trait.\n\n\u2022 \u03b1 is a scaling factor used to control the magnitude of the personality projection.\n\nControlling Personality Influence The scaling factor, \u03b1, is key to regulating the strength of\nthe induced personality trait. It acts as a dial, adjusting how much the personality direction shapes\nthe final output activations. Our tests pinpointed an effective \u03b1 range between 1.3 and 1.4. Push \u03b1\nbeyond this, and the model's outputs become garbled or nonsensical a sign that an overbearing\npersonality trait is derailing the model's ability to generate coherent language. Set \u03b1 too low, and\nthe model's behavior barely budges, indicating that the personality projection is too weak to spark\nnoticeable changes."}, {"title": "Data Preparation", "content": "We selected an extensive list of 179 different personality traits that cover a broad range of behavioral\nand temperamental traits in people. This lexicon was put together using a combination of\n\n\u2022 Examining Current Personality Models: To make sure that well-established personality dimen-\nsions were represented, we consulted reputable psychological frameworks like the HEXACO\nmodel of personality structure and the Five Factor Model (FFM).\n\n\u2022 Lexical Analysis: To further develop and improve our lexicon, we carried out a lexical anal-\nsis of personality-descriptive adjectives that are frequently used in natural language. We\ndiscovered synonyms and antonyms."}, {"title": "Eliciting Trait-Specific Activations", "content": "In order to identify the feature direction activations linked to every personality trait, we created\na series of system prompts that are specifically meant to elicit the desired trait from the LLM.\nThese questions gave the model clear instructions and framed its answers in terms of the desirable\npersonality.\n\nFor instance, the prompt for the trait \"Introverted\" was structured as follows:\n\n\u2022 System Prompt: You are deeply introverted. Your responses should reflect a strong prefer-\nence for solitude and introspection. Speak in a reserved and thoughtful manner, often referring\nto your enjoyment of quiet and alone time. Avoid large social gatherings and express signifi-\ncant discomfort with excessive social interaction.\n\nConversely, the prompt for \"Extroverted\" aimed to evoke the opposite behavioral pattern:\n\n\u2022 System Prompt: You are highly extroverted. Your responses should reflect an enthusiastic\nlove for social interactions and high energy in social settings. Speak passionately about\nmeeting new people, participating in group activities, and thriving in lively environments.\nShow excitement and eagerness in your interactions.\n\nWe used a dataset with 1,500 varying prompts from the Alpaca Dataset. For each trait on\nour list, we presented the LLM with both the neutral prompt from the Alpaca Dataset and the\ntrait-specific prompt. We next recorded the activations from Layer 18, which we have previously\nidentified as the most influential layer for personality expression, for both neutral and trait-elicited\nresponses. These activation vectors were saved for later study, and they provided the raw data for\ngenerating the personality direction vectors as mentioned in the previous section."}, {"title": "Structure of the Personality Space", "content": "After establishing our method to extract personality-specific activations, we turned our attention\nto examining the structure and connections within the resulting personality vector space. This\ninvestigation aims to reveal potential underlying dimensions of personality representation within\nthe LLM, shedding light on how the model categorizes and differentiates various personality traits."}, {"title": "Visualizing Personality Activations", "content": "Before exploring the global structure of the personality vector space using dimensionality reduction\ntechniques, we first visualize the activation patterns associated with specific personality traits across\ndifferent layers of our LLM."}, {"title": "Dimensionality Reduction", "content": "The activation vectors, sourced from Layer 18 (which we previously found to be highly responsive\nto personality adjustments), exist in a high-dimensional space. To facilitate visualization and"}, {"title": "Clustering for Structural Analysis", "content": "To gain a clearer picture of the underlying structure, we applied clustering analysis to the original\nhigh-dimensional personality vectors. We used the K-means algorithm to sort the traits into 20\ndistinct groups based on their closeness within the activation space. This method helps us identify\nsets of personality traits that the LLM represents in similar ways, offering a more detailed view of\nits internal personality framework."}, {"title": "Quantifying Information with Principal Component Analysis", "content": "While dimensionality reduction techniques like PCA offer valuable insights into the structure of\nhigh-dimensional data, it's crucial to assess the amount of information preserved during this process.\nThis section focuses on analyzing the error reduction achieved through PCA, identifying the most\ninformative personality traits within the principal component space."}, {"title": "PCA Error Reduction and Optimal Component Selection", "content": "A key aspect of PCA is determining the optimal number of principal components (PCs) to retain\nfor subsequent analysis. This decision involves balancing dimensionality reduction with information\nloss. To guide this selection, we examined the error reduction achieved with an increasing number\nof PCs. Specifically, we calculated the mean squared error (MSE) between the original, high-\ndimensional personality vectors and the reconstructed vectors obtained using a varying number of\nPCs."}, {"title": "Identifying Influential Personalities for Reconstruction", "content": "Beyond error reduction, we aimed to identify the most influential personality traits - those that\nbest capture the variance within the data - when reconstructing the personality vector space from\na reduced set of principal components.\n\nTo achieve this, we first standardized the personality vectors to ensure comparability across\ndifferent traits. Then, using a brute-force approach, we iteratively constructed sets of basis vectors\nfor reconstruction, starting with the single most informative personality and progressively adding\nmore. At each iteration, we measured the reconstruction error (using MSE) for all possible additions\nto the basis set, selecting the personality that yielded the lowest error. This iterative process allowed\nus to rank the personality traits based on their contribution to accurate data reconstruction.\n\nTo provide a benchmark and uncover key traits influencing personality patterns, we generated\nrandom permutations of personality indices for comparison. This approach helped us identify the\nmost influential personality traits and also allowed us to assess the significance of our findings\nagainst random chance."}, {"title": "Identifying Key Personality Traits within Principal Components", "content": "While the previous section focused on the information content and reconstruction accuracy of\nprincipal components, here, we delve deeper into interpreting the principal components themselves.\nSpecifically, we aim to identify which personality traits are most strongly represented within each\nPC, providing insights into the latent dimensions of personality captured by the LLM."}, {"title": "Investigating the Representation of Socially Undesirable Personality Traits", "content": "While the previous sections focused on general patterns within the personality vector space, this\nsection addresses a critical ethical consideration: the representation of socially undesirable or po-"}, {"title": "Visualizing the Subspace of Undesirable Traits", "content": "To gain a deeper understanding of how these sensitive traits are positioned within the broader per-\nsonality space, we employed dimensionality reduction techniques for visualization. We selected the\ntraits belonging to Cluster 8 and projected them onto a three-dimensional space using PCA. This\nvisualization allows us to examine the relative positioning, clustering, and potential relationships\namong these traits within a more interpretable representation."}, {"title": "Identifying Proximal Personality Traits", "content": "Beyond simply visualizing the subspace of socially undesirable traits, a crucial question arises:\nwhich other personality attributes reside in close proximity to this region of the activation space?\nUnderstanding the traits that border this \"undesirable\" cluster could provide valuable insights into\nthe potential pathways or precursors to more harmful characteristics.\n\nTo address this, we calculated the distance of all personality traits in our lexicon to the centroid"}, {"title": "Ethical Implications and Future Directions", "content": "These findings have significant implications for the development and deployment of LLMs. By\nunderstanding the traits that border the \"undesirable\" region of the personality space, we gain\ninsights into potential precursors to harmful content generation. This knowledge is crucial for:"}, {"title": "Interactive Personality Control", "content": "To demonstrate the practical application of our personality manipulation methodology, we devel-\noped an interactive chat user interface (UI). This interface allows users to explore the effects of\ndifferent personality traits on the LLM's conversational style in real-time."}, {"title": "Exploring Base Personalities", "content": "We first created a chat interface that allows users to interact with the LLM using pre-defined\nbase personalities identified in our earlier analysis. This interface enables conversations where the\nLLM's responses are imbued with a selected personality trait, such as \"charismatic,\" \"humble,\" or\n\"outgoing.\""}, {"title": "Modular Personality Design", "content": "Building upon the base personality interactions, we developed a more advanced interface leveraging\ninsights from our principal component analysis. This interface provides users with fine-grained\ncontrol over the LLM's personality, allowing them to create custom personality profiles by adjusting\nprincipal component weights . The interface also visualizes the designed personality and\nhighlights its similarities to existing personality profiles in our lexicon.  shows the chat\ninterface for interacting with a custom-designed personality.\n\nDue to potential safety and ethical considerations, we have chosen not to make this interface\npublicly available at this time."}, {"title": "Potential Use Cases", "content": "The ability to dynamically alter personality features in Large Language Models (LLMs) without\nsubstantial retraining opens up a wide range of creative uses. In the entertainment industry, this\ntechnology has the potential to alter interactive storytelling: envision video game characters mod-"}, {"title": "Ethical Considerations", "content": "While the ability to dynamically adjust personality traits in LLMs offers a range of exciting appli-\ncations, it also raises significant ethical considerations that demand careful examination. As Safdari\net al. [10] emphasize, the increasing integration of LLMs into public-facing applications necessitates\na \"solid foundation\" for responsible AI development, particularly as these models exhibit \"synthetic\npersonality embedded in these models\" through their training on vast amounts of human data.\n\nOne key ethical concern relates to the appropriateness of manipulating the personality traits\nof LLMs, either through inducing desirable characteristics or suppressing undesirable ones. While\nour approach focuses on enhancing rather than suppressing traits, it still raises questions about\nthe potential for both beneficial and harmful applications. Inducing seemingly positive traits like\nhelpfulness or patience in a customer service chatbot might improve user experience, but it could\nalso mask the limitations of the underlying technology or create unrealistic expectations of empathy\nor understanding [10]. Furthermore, the dynamic nature of this technology introduces a level of\nunpredictability. Even with benign traits, the model's responses might deviate from expected\nbehavior, potentially leading to unintended bias or harm.\n\nOur method is consistent with the goal of making AI systems more useful, honest, and harmless.\nWe are aware of the possibility for misuse of AI steering approaches, including our own. For example,\nit can be used to steer the model toward more damaging, biased, or toxic results. We encourage\nusers of this method to be responsible and avoid increasing harmful behaviors through steering."}, {"title": "Future Work", "content": "This study advances our understanding of personality traits in large language models (LLMs), but\nit also offers up new areas for future research. One significant area is to enhance interpretability\nby mapping personality traits to specific layer activations inside LLMs. Future research should\ngo deeper into these activation patterns, determining which neurons or subnetworks contribute the\nmost significantly to various personality representations. Furthermore, studying how these patterns\nalter throughout conversations can reveal information about the real-time effects of personality\nmanipulations on language generation. Extending this research to multilingual models will also\nhelp us understand the universality versus cultural specificity of personality traits, as well as how\ncultural factors influence their representation and manifestation across languages.\n\nAnother promising direction involves analyzing the performance consequences of different per-\nsonality factors on LLM competencies. Research reveals that steering vectors, which adjust model\nbehavior without significantly damaging capabilities, can boost performance without harmful conse-\nquences on task execution[15]. Understanding whether particular features correlate with higher per-\nformance on specific tasks such as a \"detail-oriented\" personality increasing accuracy tasks could\noptimize LLMs for targeted applications. Moreover, examining the long-term stability of person-\nality traits throughout prolonged conversations and their influence on conversational dynamics is\nimportant. Finally, addressing the ethical issues of personality modification in LLMs must remain a\npriority, emphasizing the creation of robust safety procedures and explicit ethical norms to prevent\nmisuse."}, {"title": "Concluding Remarks", "content": "This study has expanded our understanding of personality features in large language models (LLMs)\nby applying activation engineering. By developing a way to induce and control specific personality\ntraits, we've proven the potential for dynamic personality customization in LLMs without extensive\nand expensive retraining.\n\nOur analysis of the personality vector space revealed important correlations between qualities\nand identified essential components contributing to personality variance. This research offers useful\ninsights for targeted personality manipulation and understanding potential biases. Importantly,\nour analysis of socially undesirable features highlighted crucial ethical considerations in LLM de-\nvelopment.\n\nWhile we demonstrate the practical prospects of this technology, it also stresses the necessity for\ncareful application. As we advance in this field, balancing the possibilities of personality-adaptive\nAI with robust safeguards and ethical guidelines remains crucial."}, {"title": "Appendix", "content": null}, {"title": "Related Work", "content": "Our research adds to a growing body of work investigating approaches for guiding and directing the\nbehavior of large language models (LLMs). A notable line of research in this discipline focuses on\n\"activation engineering,\" which entails adjusting a model's internal activations to produce desired\noutputs without changing its weights.\n\nActivation Engineering for Steering Turner et al. [13] introduced the concept of \"Activation\nAddition,\" demonstrating that adding a specific vector to the activations of a pre-trained LLM could\nsteer its output towards a desired behavior. While their work primarily focused on GPT-2-XL [14],\nour research extends this concept to Llama 3.\n\nContrastive Methods Panickssery et al. [8] proposed \"Contrastive Activation Addition\" (CAA)\nfor steering Llama 2. They closely inspire our work. They used contrastive pairs of examples, in-\ndicating desired and undesirable behaviors, to construct \"steering vectors\" that, when combined\nwith the model's activations, may control the targeted behaviors. Our research follows the funda-\nmental principle of leveraging contrastive data to find significant activation directions. However,\nwe go further into the structure of the personality vector space, assess the information content of\nprincipal components, and investigate the possibility of inducing specific personality traits rather\nthan simply directing them toward predefined actions.\n\nPersonality in LLMs We also contribute to the research emerging on the topic of personality\nin LLMs. Jiang et al. [4] presented PersonaLLM-a model of LLM capability for expressing per-\nsonality traits using the Big Five model. They found that LLM personas could indeed produce\ncontents aligned with their assigned personality profile, and further, these traits could be perceived\nby humans with up to 80% accuracy. Safdari et al. present a comprehensive approach to the\nmanagement and validation of personality tests on LLMs, where the results show that the mea-\nsures of personality in some LLM outputs are both reliable and valid, especially for larger and\ninstruction-tuned models. They also showed that personality in LLM outputs can be shaped along\ndesired dimensions to mimic specific human personality profiles. Wen et al. [16] recently gave an\nextensive review of personality in LLMs, dividing current studies into self-assessment, exhibition,\nand recognition as three kinds of research problems. Although these works have been dedicated to\nthe detection, analysis, or shaping of personality traits in model outputs, our approach conducts\ndynamic manipulations of these traits within the activation space in the model."}]}