{"title": "Controllable Unlearning for Image-to-Image Generative Models via \u025b-Constrained Optimization", "authors": ["Xiaohua Feng", "Yuyuan Li", "Chaochao Chen", "Li Zhang"], "abstract": "While generative models have made significant advancements in recent years, they also raise concerns such as privacy breaches and biases. Machine unlearning has emerged as a viable solution, aiming to remove specific training data, e.g., containing private information and bias, from models. In this paper, we study the machine unlearning problem in Image-to-Image (I2I) generative models. Previous studies mainly treat it as a single objective optimization problem, offering a solitary solution, thereby neglecting the varied user expectations towards the trade-off between complete unlearning and model utility. To address this issue, we propose a controllable unlearning framework that uses a control coefficient \u025b to control the trade-off. We reformulate the I2I generative model unlearning problem into a \u025b-constrained optimization problem and solve it with a gradient-based method to find optimal solutions for unlearning boundaries. These boundaries define the valid range for the control coefficient. Within this range, every yielded solution is theoretically guaranteed with Pareto optimality. We also analyze the convergence rate of our framework under various control functions. Extensive experiments on two benchmark datasets across three mainstream I2I models demonstrate the effectiveness of our controllable unlearning framework.", "sections": [{"title": "Introduction", "content": "Generative models have recently made significant progress in fields such as image recognition [27, 15] and natural language processing [44, 59], capturing significant academic interest due to their boundless generative potential. Typically trained on vast datasets from the Internet, generative models inevitably assimilate latent biases and expose private information [53]. Existing studies [32, 58, 8] have revealed that generative models have a strong tendency to recall specific instances encountered during training, raising concerns that the models might output biases and leak private information when put into practical situations. Machine unlearning [42] presents a viable solution to address this issue. It aims to eliminate the knowledge learned from specific training data (forget set) while preserving the knowledge learned from the remaining data (retain set).\nImplementing unlearning for generative models serves dual objectives, i.e., fulfilling privacy re-quirements and enhancing model reliability. On the one hand, legislation such as the General Data Protection Regulation [61] grants individuals the right to be forgotten. Consequently, service providers must unlearn specific private information from the model in response to an individual's request. On the other hand, the data available on the Internet is rife with biases and inaccuracies, which compromises model performance when used for training. By proactively unlearning the biased and inaccurate data, the service providers can improve the liability of their models.\nIn this paper, we focus on the unlearning problem in Image-to-Image (I2I) generative models [67], where unlearning is defined by the model's incapacity to reconstruct the full image from a partially cropped one [34], as shown in Figure 1. Previous study [34] frames machine unlearning in generative models as a single-objective optimization problem, with the loss defined as a combination of performance on both the forget and retain sets. However, this approach faces three main challenges: i) First and foremost, this approach offers a solitary resolution, ignoring the real-world need for flexible trade-offs between model utility and unlearning completeness aligned with varying user expectations. Regrettably, this challenge remains overlooked in the majority of current research on unlearning. ii) This approach relies wholly on fine-tuning with manual terminating conditions, lacking a theoretical guarantee for convergence. iii) This approach integrates two optimization objectives into a single loss function, which compromises unlearning efficiency due to the competition or conflict between different objectives.\nTo address these challenges, we propose a controllable unlearning approach that provides a set of Pareto optimal solutions to cater to varied user expectations. Users can select a solution based on the degree of unlearning completeness through a simple control coefficient 8. Specifically, we reframe machine unlearning of I2I generative models into a bi-objective optimization problem [29], i.e., unlearning the forget set (1st objective, unlearning completeness) while preserving the retain set (2nd objective, model utility). Due to legislation requirements, the first objective prioritizes the second objective, meaning that minimizing the negative impact on the retain set only arises once the unlearning objective is sufficiently optimized. Therefore, we reformulate the bi-objective optimization problem into a \u025b-constrained optimization problem, where the unlearning objective is treated as a constraint (primary to satisfy) and \u025b is the control coefficient. Utilizing gradient-based methods to solve this \u025b-constrained optimization, we can obtain two Pareto optimal solutions for the boundaries of unlearning with theoretical guarantee, which can be used to determine the valid range of values for \u025b. Subsequently, we select the value of \u025b within its valid range and relax the constraints on the unlearning objective by increasing \u025b. As a result, we obtain a set of solutions that dynamically fulfill user's varied expectations regarding the trade-off between unlearning completeness and model utility. Finally, to enhance the efficiency of unlearning, we analyze the convergence rates of our unlearning framework under various settings of the control function which is utilized to govern the direction of parameter updates. The main contributions of this paper are summarized as follows:\n\u2022 We focus on I2I generative models, and propose a controllable unlearning approach that balances unlearning completeness and model utility, providing a set of solutions to fulfill varied user expectations. To the best of our knowledge, we are the first to study controllable unlearning.\n\u2022 We reformulate the machine unlearning of generative models as a \u025b-constrained optimization problem with unlearning the forget set as the constraint, guaranteeing optimal theoretical solutions for the boundaries of unlearning. By progressively relaxing the unlearning constraint, we obtain the Pareto set and plot the corresponding Pareto front."}, {"title": "Related Work", "content": "Many computer vision tasks can be formulated as I2I generation processes, e.g., style transfer [72], image extension [9], restoration [57], and image synthesis [69]. There are mainly three architectures for I2I generative models, i.e., Auto-Encoders (AEs) [1], Generative Adversarial Networks (GANs) [22], and diffusion models [27]. AEs mainly aim to reduce the mean squared error between generated and ground truth images but often produce lower-quality outputs [16, 18]. GANs, through adversarial training, significantly improve generation quality, despite their unstable training [2, 24, 7]. Diffusion models, which use a diffusion-then-denoising approach, aim for stable training and high-quality generation by minimizing the distributional distance between generated images and ground truth images [27, 55, 52]. However, diffusion models require a greater amount of data and computational resources [50, 48]. In this paper, we aim to design a universal unlearning method that can be applied across different I2I models."}, {"title": "Machine Unlearning", "content": "Machine unlearning aims to eliminate the influence of specific training data (unlearning target) from a trained model. A naive approach is to retrain the model from scratch using a modified dataset that excludes the unlearning target. However, this approach can be computationally prohibitive in practice. Based on the degree of unlearning completeness, machine unlearning can be categorized into exact unlearning and approximate unlearning [65].\nExact unlearning aims to ensure that the unlearning target is fully unlearned, i.e., as complete as retraining from scratch [5, 66, 36]. This approach, which typically relies on retraining, is limited to unlearning specific instances and cannot be readily extended to generative models with strong feature generalizations. Approximate unlearning aims to obtain an approximate model, whose performance closely aligns with a retrained model [20, 54]. This approach estimates the influence of unlearning targets, and updates the model accordingly, usually through gradient-based updates, avoiding full retraining [3, 38]. However, accurate influence estimation is still challenging [23], reducing the applicability of this approach to generative models.\nIn generative models, the exploration of unlearning is accomplished by minimizing a composite loss, which is a combination of training loss on the retain and the forget sets [34]. This approach is highly dependent on manual parameter tuning and cannot guarantee unlearning completeness. As for comparison, the solutions yielded by our proposed controllable unlearning framework are theoretically guaranteed with Pareto optimality."}, {"title": "Preliminary", "content": "As outlined in [11, 37], an unlearning task typically has three main principles: i) unlearning completeness, which involves eliminating the influence of specific data from an already trained model; ii) unlearning efficiency, which focuses on enhancing the speed of the unlearning process; and iii) model utility, which aims to ensure that the performance of the unlearned model remains comparable to that of a model retrained from scratch."}, {"title": "Pareto Optimality", "content": "Consider a multi-objective optimization problem formulated as: $mine f(\u03b8) = (f_1(\u03b8), f_2(\u03b8),\u2026\u2026, f_m(\u03b8))$, where $f_i(\u03b8)$ denotes the loss for the i-th objective.\nPareto dominance. Let $\u03b8^a, \u03b8^b$ be two points in feasible set \u03a9, $\u03b8^a$ is said to dominate $\u03b8^b$ ($\u03b8^a \u227a \u03b8^b$) if and only if $f_i(\u03b8^a) \u2264 f_i(\u03b8^b), \u2200i \u2208 {1, ..., m}$ and $f_j(\u03b8^a) < f_j(\u03b8^b), \u2203j \u2208 {1, ...,m}$.\nPareto optimality [39]. A point $\u03b8^\u2217$ is Pareto optimal if there is no $\u03b8 \u2208 \u03a9$ for which $\u03b8 \u227a \u03b8^\u2217$. The collection of all such Pareto optimal points forms the Pareto set, and the surface of this set in the loss space is called the Pareto front."}, {"title": "I2I Generative Model Unlearning", "content": "Model architecture. Encoder-decoder structures are widely used in I2I models, with: i) an encoder $E_\u03b3$ reducing images to the latent space, and ii) a decoder $D_\u03c6$ reconstructing images from the latent space. For model $I_\u03b8$ with input image $x$, the output is:\n$I_\u03b8(x) = D_\u03c6(E_\u03b3(T(x)))$, (1)\nwhere $T(x)$ denotes the cropping operation (such as center cropping or random cropping), and $\u03b8 = {\u03b3, \u03c6}$ denotes the full parameter set.\nUnlearning objective. Define the unlearning task for an I2I generative model $I_{\u03b8_0}$ involving data partitions $D_f$ (forget set) and $D_r$ (retain set). Consider an $I_{\u03b8_0}$, i.e., the original model, with training data $D = D_f \u222a D_r$. Assume that $I_{\u03b8_0}$ is proficiently trained to generate satisfactory results on both $D_f$ and $D_r$. The objective of unlearning is to obtain an unlearned model $I_\u03b8$ that cannot generate satisfactory results on $D_f$ (1st objective, unlearning completeness) while maintaining comparable performance on $D_R$ (2nd objective, model utility). Formally,\n$max_\u03b8 (Div(P_{X_f}||P(I_\u03b8(T(X_f)))))$, and $min_\u03b8 (Div (P_{X_r}||P(I_\u03b8(T(X_r)))))$, (2)\nwhere $X_f$ and $X_r$ are the variables for ground truth images in $D_f$ and $D_r$, $P(I_\u03b8(X))$ is the model output distribution for input variable $X$, and $Div(\u00b7||\u00b7)$ represents distributional distance, measured by Kullback-Leibler (KL) divergence in this paper.\nFollowing prior work [30, 64, 62], as the model is proficiently trained, we hypothesize that $I_{\u03b8_0}$ can approximately replicate the distributions over both forget and retain sets [30, 64, 62], i.e., $P(X_f) \u2248 P(I_{\u03b8_0}(T(X_f)))$, and $P(X_r) \u2248 P(I_{\u03b8_0}(T(X_r)))$. Let $P_{X'_f} := P(I_{\u03b8_0}(T(X_f)))$ and $P_{X'_r} := P(I_{\u03b8_0}(T(X_r)))$. Then, Eq. (2) can be simplified to:\n$max_\u03b8 Div(P_{X_f}||P'_{X_f})$, and $min_\u03b8 Div(P_{X_r}||P'_{X_r})$, (3)\nwhere $P_{X_f}$ and $P'_{X_f}$, represent the output distributions of the forget set before and after unlearning respectively. Similarly, $P_{X_r}$ and $P'_{X_r}$ represent those for the retain set."}, {"title": "Methodology", "content": "In this section, we first introduce a controllable unlearning framework for I2I generative models, which formulates unlearning as a constrained optimization with the unlearning objective as a constraint. We utilize a gradient-based method to obtain the boundaries of unlearning. Then we relax the constraint within the boundaries to derive a set of Pareto optimal solutions to fulfill varied user expectations."}, {"title": "\u025b-Constrained Optimization Formulation", "content": "The unlearning task for I2I models is reformulated as a bi-objective optimization (Eq. (3)), with the first objective to maximize $Div(P_{X_f}||P'_{X_f})$. Nonetheless, the value of $Div(\u00b7||\u00b7)$ can theoretically be maximized to infinity, yielding an infinite number of possible $P'_{X_f}$ [34], consequently resulting in extremely diminished model utility. To balance unlearning completeness and model utility, we bound $Div(P_{X_f}||P'_{X_f})$ by Lemma 1."}, {"title": "Solving the \u025b-Constraint Optimization", "content": "To solve the 8-constrained optimization problem in Eq. (6), approaches such as Sequential Quadratic Programming (SQP) [43, 4], penalty function method [68], and interior point method [47] are commonly employed. Given the extensive parameter set of the I2I generative model, we select a special variant of the SQP algorithm for its lower complexity and comparable convergence guarantee [43, 40].\nSpecifically, we employ a gradient-based method to solve Eq. (6), updating the parameter by $\u03b8_{\u03c4+1} \u2190 \u03b8_\u03c4 + \u00b5_t g_t$. Here, $\u00b5_t$ denotes the step size, and $g_t$ represents the direction of the parameter update, which is determined by solving a convex quadratic programming problem w.r.t. $g$:\n$g_t = min_{g \u2208 R^d} {f_2'(\u03b8_t) - g||^2_2 s.t. f_1'(\u03b8_t) g\u2265 \u03c8(\u03b8_t)},$ (7)\nwhere $\u03c8(\u03b8_t)$ is a control function that associates $g_t$ to the constraints in Eq. (6). We provide a summary of our proposed unlearning algorithm in Algorithm 1 (see Appendix B).\nAssumption 1. Assume $f_1(\u03b8)$ and $f_2(\u03b8)$ are continuously differentiable, with $sign(\u03c8(\u03b8)) = sign(f_1(\u03b8) \u2212 \u03b5)$, where $sign(x) = \\begin{cases} 1 & \\text{for } x > 0, \\ 0 & \\text{for } x = 0, \\ -1 & \\text{for } x < 0, \\end{cases}$, and the trajectory $\\{\u03b8_t : t \u2208 [0,+\u221e)\\}$ follows the continuous-time dynamics $\\frac{d \u03b8_t}{dt} = \u2212g_t$, where $g_t$ is defined in Eq. (7) and $max_{t\u2208[0,+\u221e)} N_t < +\u221e$.\nThe convergence analysis of Algorithm 1 regarding Eq. (6) utilizes the continuous-time framework given by $\\frac{d \u03b8_t}{dt} = \u2212g_t$, as mentioned in Assumption 1. Please refer to Lemma 2 in Appendix C.1 for further details of convergence."}, {"title": "A Controllable Unlearning Framework", "content": "Our controllable unlearning framework consists of two phases. In Phase I, we reformulate Eq. (6) into a special form to obtain the solution for the boundaries of unlearning. In Phase II, we adjust the value & within its valid range to relax the unlearning constraint and obtain the Pareto optimal solutions for controllable unlearning. This relaxation of unlearning completeness allows for a controllable trade-off between completeness and model utility, thereby catering to varied user expectations."}, {"title": "Experiments", "content": "We evaluate our proposed method on three mainstream I2I generative models, i.e., Masked Autoen-coder (MAE) [25], Vector Quantized Generative Adversarial Networks (VQ-GAN) [35], and diffusion probabilistic models [49]. Datasets: Following [34], we conduct experiments on the following two large-scale datasets: i) ImageNet-1K [14], from which we randomly select 200 classes, designating 100 of these as the forget set and the remaining 100 as the retain set. Each class contains 150 images, with 100 allocated for training and the remaining for validation; and ii) Places-365 [71], from which we randomly select 100 classes, designating 50 of these as the forget set and the remaining 50 as the retain set. Each class contains 5500 images, with 5000 allocated for training and the remaining 500 for validation. Baselines: We first report the performance of the original model (i.e., before unlearning) as a reference. Following [34], we set the following baselines: i) Max Loss [63, 19], which maximizes the training loss on the forget set; ii) Retain Label [31], which minimizes training loss by setting the true values of the retain samples as those of the forget set; iii) Noisy Label [23, 19], which minimizes the training loss by introducing Gaussian noise to the ground truth images of the forget set; and iv) Composite Loss [34], the State-Of-The-Art (SOTA) method, which builds upon Noisy Label by calculating the loss on the retain set and obtaining their weighted sum, thereby minimizing this weighted training loss. Evaluation metrics. We adopt three different types of metrics to comprehensively compare our method with other baselines: i) Inception Score (IS) of the generated images [51]; ii) the Frech\u00e9t Inception Distance (FID) between the generated images and the ground truth images [26]; and iii) the cosine similarity between the CLIP embeddings of the"}, {"title": "Unlearning Performance", "content": "We test our method on image extension, inpainting, and reconstruction tasks. We report the results for center uncropping (i.e., inpainting) in Tabel 1, and the others in Appendix H.1. Baseline comparison: As shown in Table 1, compared to the original model, our method retains almost the same performance on the retain set or only exhibits minor degradation. Meanwhile, there is a significant reduction in the three metrics on the forget set. In contrast, these baselines generally cannot perform well simultaneously on both the forget set and the retain set. For instance, in MAE, Composite Loss has the least performance degradation on the retain set, but its performance on the forget set is also the worst. We also observe similar findings for Max Loss in VQ-GAN. Furthermore, we provide some examples of generated images in Figure 3, and more images in Appendix F. T-SNE analysis: Following [34], we conduct a T-SNE analysis [60] to further analyze our method's effectiveness. Using our unlearned model, we generate 50 images for both the retain set and the forget set. We then calculate the CLIP embedding vectors for these images and their corresponding ground truth images. As illustrated in Figure 4, after unlearning, the embeddings of retain set are close to that of the ground truth images, while most of the generated images on the forget set diverge significantly from the ground truth one. Unlearning robustness: We validate the performance of our controllable unlearning framework in different image generation tasks by changing the cropping patterns. The results indicate that our framework is robust to various image generation tasks and generally outperforms baselines, with detailed results provided in Appendix H.1. Moreover, we examine the unlearning effects of our controllable unlearning framework under different crop ratios. The results in Appendix H.3 demonstrate that our framework is robust to different crop ratios. Furthermore, we find that the visual effects of unlearning control are more prominent with larger crop ratios. Summary: These results validate the effectiveness of our proposed method, which is universally applicable to mainstream I2I generative models as well as a variety of image generation tasks, consistently achieving favorable outcomes across all these tasks."}, {"title": "Controllable Unlearning", "content": "We also evaluate the controllability of our method which provides a set of solutions for varied user expectations. First, we obtain two boundary points of unlearning, thereby establishing the valid range of values for \u025b. We linearly increase the value of & within this range, adding 25% of the range interval each time, to obtain optimum solutions corresponding to different \u025b values. We provide some generated images corresponding to these solutions in Figure 1. Due to the space limit, please refer to Appendix G for more examples. For results of more fine-grained control (i.e., smaller increments of the linear increase of 8), please refer to Appendix H.2.\nWe verify the unlearned models at different \u025b values, and report results in Table 2. As & increases, we observe a trade-off: the unlearning completeness decreases, while the generated images' performance on the forget set progressively improves, and, simultaneously, the performance on the retain set also improves. This observation clearly demonstrates the controllability of our proposed method, which can cater to varied user expectations. Please refer to Appendix I for additional results of the generated images and T-SNE analysis, which corroborates the above numerical results."}, {"title": "Unlearning Efficiency", "content": "To enhance the efficiency of our controllable unlearning framework, we modify the selections of control function \u03c8(0) during various phases. Specifically, we empirically examine the convergence under these conditions to assess the framework's unlearning performance of efficiency. In Phase I, with the control function satisfying $\u03c8(\u03b8) = \u03b1||\u2207f_1(\u03b8)||^\u03b4$, we manipulate the value of the exponent \u03b4 to change the control function. Additionally, we verify the changes in the convergence rates of $f_1(\u03b8)$ and $f_2(\u03b8)$ under four different d values across three models, with results shown in Appendix J. It is evident that $f_1(\u03b8)$ and $f_2(\u03b8)$ achieve an optimal balance in convergence rates when \u03b4 = 2, and the overall rate of convergence is fastest. In Phase II, where the control function satisfies $\u03c8(\u03b8) = \u03b2(f_1(\u03b8) \u2212 \u03b5)$, we test the changes in the convergence rates of $f_1(\u03b8)$ and $f_2(\u03b8)$ for two different & values on three models. To stabilize the optimization process, we scale the form of the control function (i.e., $\u03c8(\u03b8) = \u03b2(f_1(\u03b8) \u2212 \u03b5)^\u03b4||\u2207f_1(\u03b8)||^2)$, selecting two different d values, with results presented in Appendix J. It can be observed that at d = 1 the overall rate of convergence was optimized."}, {"title": "Conclusion", "content": "In this paper, we propose a controllable unlearning framework for I2I generative models to overcome the limitation of the existing method's incapability to fulfill varied user expectations. Our approach allows for a controllable trade-off between unlearning completeness and model utility by introducing a control coefficient & to control the degrees of unlearning completeness. We reformulate unlearning as a \u025b-constrained optimization problem and solve it with a gradient-based method to find two boundary points that guide the valid range for 8. Within this range, every chosen value of \u025b will lead to a Pareto optimal solution, addressing the existing method's issue of lacking theoretical guarantee. Extensive experiments on two large datasets (i.e., ImageNet-1K and Places-365) across three mainstream I2I models (i.e., MAE, VQ-GAN, diffusion model) demonstrate significant advantages of our method over the SOTA methods with higher unlearning efficiency, and a controllable balance between the unlearning completeness and model utility."}, {"title": "Broader Impacts and Limitations", "content": "The abundance of training data not only enhances the performance of generative models but also introduces issues with privacy, unfairness, and bias. Our proposed controllable unlearning framework offers a viable solution to these issues. Our proposed framework is not limited to unlearning in"}, {"title": "Algorithm Procedure of Controllable Unlearning Framework", "content": "To address the \u025b-constrained optimization problem Eq. (6), we employ a gradient-based method. Specifically, the detailed algorithmic procedure of our controllable unlearning framework is as follows.\nRequire: Original model Ie, forget set Df, retain set Dr, control function \u03c8(\u03b8), step size \u03bc, covariance matrix \u2211, numerical stability variable $w = le-7$.\n1: Initial: Initialize $t = 0$, $I_{\u03b8_1} = I_{\u03b8_0}$;\n2: for t = 0 to T-1 do\n3: Sample $\\{x_f\\}$, $\\{x_r\\}$ and $\\{X_n\\}$ from $D_f$, $D_r$ and $\\mathcal{N}(0, \u03b5)$ respectively, ensuring that $|\\{x_f\\}| = |\\{x_r\\}| = |\\{X_n\\}|$;\n4: Compute loss:\n5: $f_1(\u03b8_t) = ||I_{\u03b8_t} (T(D_f)) \u2013 I_{\u03b8_0}(T(X_n))||_2$\n6: $f_2(\u03b8_t) = ||I_{\u03b8_t}(T(D_r)) \u2013 I_{\u03b8_0}(T(D_r))||_2$\n7: Compute gradient: \u2207 f_1(\u03b8_t), \u2207 f_2(\u03b8_t);\n8: Compute the solution to the dual problem of Eq. (7): $\u03b7_t = max(\\frac{\u03c8(\u03b8_t)- f_2'(\u03b8_t) \u2207f_1(\u03b8_t)}{||f_1'(\u03b8_t)||^2},0)$;\n9: Compute parameter update direction: $g_t = \u2207 f_2(\u03b8_t) + \u03b7_t \u2207f_1(\u03b8_t)$;\n10: Update the parameter of the target model $I_{\u03b8_{t+1}} : \u03b8_{t+1} \u2190 \u03b8_t + \u00b5_t g_t$;\n11: end for\n12: Return Unlearned model $I_{\u03b8_T}$;"}, {"title": "Theoretical Validation", "content": "Before exploring the proofs of Propositions 1 and 2, it is essential to define some fundamental concepts and lemmas. This references some works [6, 45, 21] mentioned earlier; for the sake of readability, we will reiterate them here.\nPenalty Function. An alternative method to evaluate the optimality of Algorithm 1 involves the L1 penalty function given by:\n$P_\u03b5(\u03b8) = f_2(\u03b8) + \u03be[f_1(\u03b8) \u2212 \u03b5]_+,$ (10)\nwhere \u03be > 0 is a scaling coefficient. The minima of Eq. (10) align with the solutions to Eq. (6) for sufficiently large values of \u03be [43].\nFirst-order KKT Condition and KKT Function. We revisit the first-order KKT condition [43] for the constrained optimization described in Eq. (9). Assume $\u03b8^\u2217$ is a local optimum with continuously differentiable $f_1(\u03b8)$ and $f_2(\u03b8)$, and $||\u2207f_1(\u03b8^\u2217)|| \u2260 0$. There exists a Lagrange multiplier $\u03c9^\u2217 \u2208 [0,+\u221e)$ such that:\n$\u2207f_2(\u03b8^\u2217) + \u03c9^\u2217\u2207f_1(\u03b8^\u2217) = 0, f_1(\u03b8^\u2217) \u2264 \u03b5, \u03c9^\u2217 (f_1(\u03b8^\u2217) \u2013 \u03b5) = 0.$ (11)\nThis setup highlights the importance of $||\u2207f_1(\u03b8^\u2217) || \u2260 0$ as a constraint qualification condition.\nUtilizing Algorithm 1 for Eq. (9), and for \u03b7 \u2265 0, the KKT function [21] to verify the first-order KKT condition is defined as:\n$K_\u03c4(\u03b8_t, \u03b7_t) = ||\u2207f_2(\u03b8_t) + \u03b7_t\u2207f_1(\u03b8_t)||^2 + \u03c4[\u03c8(\u03b8_t)]_+ + \u03b7_t[\u2212\u03c8(\u03b8_t)]_+ ,$ (12)\nwhere \u03c4 > 0, and $[x]_+ = max(x,0)$. It is clear that $K_\u03c4(\u03b8_t, \u03b7_t) \u2265 0$ for all $\u03b8_t \u2208 R^d$ and $\u03b7_t \u2265 0$, achieving $K_\u03c4(\u03b8_t, \u03b7_t) = 0$ iff $(\u03b8_t, \u03b7_t)$ satisfies the first-order KKT condition."}, {"title": "Second-order KKT Condition and KKT Function", "content": "In the context of Algorithm 1 applied to Eq. (8), we expect that $||\u2207f_1(\u03b8_t)||$ approaches zero, leading to $\u03b7_t$ potentially diverging to infinity. This scenario indicates a violation of the first-order KKT condition, potentially interpreted as $\u03b7^\u2217 = +\u221e$.\nWhile the first-order condition (Eq. (11)) is inadequate, the second-order KKT conditions involving the Hessian $\u2207^2 f_1 (\u03b8)$ are applicable [13]. Consider the relaxed form of Eq. (8) as:\n$min_{\u03b8 \u2208 R^d} f_2(\u03b8) s.t. f_1(\u03b8) = 0.$ (13)\nIf $\u03b8^\u2217$ is a local minimum of Eq. (8), it coincides with a local minimum of Eq. (13). Assuming $f_2(\u03b8)$ and $f_1(\u03b8)$ are continuously differentiable, with the Hessian $\u2207^2 f_1(\u03b8)$ maintaining constant rank near $\u03b8^\u2217$ [28], the first-order KKT condition for Eq. (13) can be formulated. There exists a vector $\u03c9^\u2217 \u2208 R^d$ such that:\n$\u2207^2 f_2 (\u03b8^\u2217) + \u2207^2 f_1 (\u03b8^\u2217) \u03c9^\u2217 = 0.$ (14)\nThis condition implies that $\u2207^2 f_2(\u03b8^\u2217)$ is orthogonal to the null space of $\u2207^2 f_1 (\u03b8^\u2217)$, defining the tangent space of the stationary manifold $\\{\u03b8 : \u2207^2 f_1 (\u03b8) = 0\\}$ for $f_1 (\u03b8)$.\nFor verifying local optimality under the constraints of Eq. (8) where $\u03c8(\u03b8) \u2265 0$, the KKT function is proposed as:\n$K_\u03c4^+(\u03b8_t, \u03b7_t) = ||\u2207f_2 (\u03b8_t) + \u03b7_t\u2207f_1 (\u03b8_t)||^2 + \u03c4\u03c8 (\u03b8_t),$ (15)\nwhere $\u03c8(\u03b8_t) = 0$ asserts that $\u03b8_t$ is stationary for $f_1(\u03b8)$, and $||\u2207f_2(\u03b8_t) + \u03b7_t\u2207f_1(\u03b8_t) || = 0$ signifies local optimality with respect to $f_2(\u03b8)$, aligning with the KKT condition for the relaxed problem $min_\u03b8{f_2(\u03b8) s.t. f_1(\u03b8) \u2264 \u03b5_t}$, with $\u03b5_t = f_1(\u03b8_t)$.\nIn the analysis of Algorithm 1, a fundamental lemma concerning the behavior of the penalty function $P_E(\u03b8)$ and the KKT function $K_\u03c4(\u03b8, \u03b7)$, given in Eqs. (12) and (15), is essential for understanding the algorithm's convergence and feasibility characteristics. This lemma is stated as follows:\nLemma 2. Theorem 3.2 of Gong et al. (2021) [21]. Assume Assumption 1 holds, for any \u03be \u2265 0, we have\n$\\frac{d}{dt} P_\u03b5(\u03b8_t) \u2264 \u2212 K_{\u03be-\u03b7_t}(\u03b8_t, \u03b7_t), t \u2208 [0, +\u221e).$ (16)\nThis equation indicates that $P_\u03b5(\u03b8_t)$ is non-increasing w.r.t. time t provided that $K_{\u03be-\u03b7_t}(\u03b8_t, \u03b7_t) \u2265 0$. This condition is satisfied if $g_t$ is sufficiently large such that $g_t \u03b7_t \u2265 0$, or when the constraint is met, i.e., $f_1(\u03b8_t) \u2264 \u03b5$, ensuring $[\u03c8(\u03b8_t)]_+ = 0$.\nThis lemma facilitates further deductions about the behavior of the algorithm under different settings of the parameter \u03be. For instance, setting \u03be \u2192 +\u221e allows us to demonstrate that the constraint $[f_1(\u03b8_t) \u2013 \u03b5]_+$ is non-increasing w.r.t. time t. This implies that $f_1(\u03b8_t)$ is decreasing w.r.t. time t outside the feasible region, and once et enters the feasible region, it remains therein. Conversely, setting \u03be = 0 reveals that $f_2(\u03b8_t)$ monotonically decreases w.r.t. time t within the feasible set, progressing towards a KKT point. These observations are critical for understanding both the feasibility and optimality properties of Algorithm 1 under different operational scenarios.\nLemma 3. Under Assumption 1, the following two propositions hold:\n1. For any time $t \u2208 [0, +\u221e)$, $min_{s\u2208[0,t]} [\u03c8(\u03b8_s)]_+ = O(\\frac{1}{t})$.\n2. If $\u03c8(\u03b8_t) \u2265 0$ holds, then $min_{s\u2208[0,t]} \u03c8 (\u03b8_s) \u2264 \\frac{1}{t} (f_1 (\u03b8_0) \u2212 f_1^*)$ for any time $t \u2208 [0, +\u221e)$.\nProof of Lemma 3-1. At each time point $t \u2208 [0, +\u221e)$, dividing both sides of Eq. (16) by \u03be > 0 and taking \u03be \u2192 +\u221e gives\n$\\frac{d}{dt} [f_1 (\u03b8_t) - \u03b5]_+ \u2264 - \\frac{1}{\u03be} [\u03c8 (\u03b8_t)]_+ \u2264 0.$"}, {"title": "Proof of Proposition", "content": "Integrating this on time interval [0, t", "0,t": ""}, ["\u03c8 (\u03b8_s)"], "frac{1}{t} \u222b_0^t [\u03c8 (\u03b8_s)"]}