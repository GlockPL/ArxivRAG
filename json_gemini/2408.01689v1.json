{"title": "Controllable Unlearning for Image-to-Image Generative Models via \u025b-Constrained Optimization", "authors": ["Xiaohua Feng", "Yuyuan Li", "Chaochao Chen", "Li Zhang"], "abstract": "While generative models have made significant advancements in recent years, they also raise concerns such as privacy breaches and biases. Machine unlearning has emerged as a viable solution, aiming to remove specific training data, e.g., containing private information and bias, from models. In this paper, we study the machine unlearning problem in Image-to-Image (I2I) generative models. Previous studies mainly treat it as a single objective optimization problem, offering a solitary solution, thereby neglecting the varied user expectations towards the trade-off between complete unlearning and model utility. To address this issue, we propose a controllable unlearning framework that uses a control coefficient \\( \\varepsilon \\) to control the trade-off. We reformulate the I2I generative model unlearning problem into a \\( \\varepsilon \\)-constrained optimization problem and solve it with a gradient-based method to find optimal solutions for unlearning boundaries. These boundaries define the valid range for the control coefficient. Within this range, every yielded solution is theoretically guaranteed with Pareto optimality. We also analyze the convergence rate of our framework under various control functions. Extensive experiments on two benchmark datasets across three mainstream I2I models demonstrate the effectiveness of our controllable unlearning framework.", "sections": [{"title": "Introduction", "content": "Generative models have recently made significant progress in fields such as image recognition [27, 15] and natural language processing [44, 59], capturing significant academic interest due to their boundless generative potential. Typically trained on vast datasets from the Internet, generative models inevitably assimilate latent biases and expose private information [53]. Existing studies [32, 58, 8] have revealed that generative models have a strong tendency to recall specific instances encountered during training, raising concerns that the models might output biases and leak private information when put into practical situations. Machine unlearning [42] presents a viable solution to address this issue. It aims to eliminate the knowledge learned from specific training data (forget set) while preserving the knowledge learned from the remaining data (retain set).\nImplementing unlearning for generative models serves dual objectives, i.e., fulfilling privacy re-\nquirements and enhancing model reliability. On the one hand, legislation such as the General Data Protection Regulation [61] grants individuals the right to be forgotten. Consequently, service providers must unlearn specific private information from the model in response to an individual's request. On the other hand, the data available on the Internet is rife with biases and inaccuracies, which compromises model performance when used for training. By proactively unlearning the biased and inaccurate data, the service providers can improve the liability of their models.\nIn this paper, we focus on the unlearning problem in Image-to-Image (I2I) generative models [67], where unlearning is defined by the model's incapacity to reconstruct the full image from a partially cropped one [34], as shown in Figure 1. Previous study [34] frames machine unlearning in generative models as a single-objective optimization problem, with the loss defined as a combination of performance on both the forget and retain sets. However, this approach faces three main challenges: i) First and foremost, this approach offers a solitary resolution, ignoring the real-world need for flexible trade-offs between model utility and unlearning completeness aligned with varying user expectations. Regrettably, this challenge remains overlooked in the majority of current research on unlearning. ii) This approach relies wholly on fine-tuning with manual terminating conditions, lacking a theoretical guarantee for convergence. iii) This approach integrates two optimization objectives into a single loss function, which compromises unlearning efficiency due to the competition or conflict between different objectives.\nTo address these challenges, we propose a controllable unlearning approach that provides a set of Pareto optimal solutions to cater to varied user expectations. Users can select a solution based on the degree of unlearning completeness through a simple control coefficient \\( \\varepsilon \\). Specifically, we reframe machine unlearning of I2I generative models into a bi-objective optimization problem [29], i.e., unlearning the forget set (1st objective, unlearning completeness) while preserving the retain set (2nd objective, model utility). Due to legislation requirements, the first objective prioritizes the second objective, meaning that minimizing the negative impact on the retain set only arises once the unlearning objective is sufficiently optimized. Therefore, we reformulate the bi-objective optimization problem into a \\( \\varepsilon \\)-constrained optimization problem, where the unlearning objective is treated as a constraint (primary to satisfy) and \\( \\varepsilon \\) is the control coefficient. Utilizing gradient-based methods to solve this \\( \\varepsilon \\)-constrained optimization, we can obtain two Pareto optimal solutions for the boundaries of unlearning with theoretical guarantee, which can be used to determine the valid range of values for \\( \\varepsilon \\). Subsequently, we select the value of \\( \\varepsilon \\) within its valid range and relax the constraints on the unlearning objective by increasing \\( \\varepsilon \\). As a result, we obtain a set of solutions that dynamically fulfill user's varied expectations regarding the trade-off between unlearning completeness and model utility. Finally, to enhance the efficiency of unlearning, we analyze the convergence rates of our unlearning framework under various settings of the control function which is utilized to govern the direction of parameter updates. The main contributions of this paper are summarized as follows:\n\u2022 We focus on I2I generative models, and propose a controllable unlearning approach that balances unlearning completeness and model utility, providing a set of solutions to fulfill varied user expectations. To the best of our knowledge, we are the first to study controllable unlearning.\n\u2022 We reformulate the machine unlearning of generative models as a \\( \\varepsilon \\)-constrained optimization problem with unlearning the forget set as the constraint, guaranteeing optimal theoretical solutions for the boundaries of unlearning. By progressively relaxing the unlearning constraint, we obtain the Pareto set and plot the corresponding Pareto front.\n\u2022 We utilize gradient-based methods to solve the \\( \\varepsilon \\)-constrained optimization problem. To enhance the efficiency of unlearning, we analyze our framework's performance across different settings of the control function and validate with multiple combinations.\n\u2022 We conduct extensive experiments to evaluate our proposed method over diverse I2I generative models. The results from two large datasets demonstrate that the Pareto optimal solutions yielded by our method significantly outperform baseline methods. Additionally, the solution set achieves controllable unlearning to fulfill varied expectations regarding the trade-off between unlearning completeness and model utility."}, {"title": "Related Work", "content": "2.1 I2I Generative Models\nMany computer vision tasks can be formulated as I2I generation processes, e.g., style transfer [72], im-age extension [9], restoration [57], and image synthesis [69]. There are mainly three architectures for I2I generative models, i.e., Auto-Encoders (AEs) [1], Generative Adversarial Networks (GANs) [22], and diffusion models [27]. AEs mainly aim to reduce the mean squared error between generated and ground truth images but often produce lower-quality outputs [16, 18]. GANs, through adversarial training, significantly improve generation quality, despite their unstable training [2, 24, 7]. Diffusion models, which use a diffusion-then-denoising approach, aim for stable training and high-quality generation by minimizing the distributional distance between generated images and ground truth images [27, 55, 52]. However, diffusion models require a greater amount of data and computational resources [50, 48]. In this paper, we aim to design a universal unlearning method that can be applied across different I2I models.\n2.2 Machine Unlearning\nMachine unlearning aims to eliminate the influence of specific training data (unlearning target) from a trained model. A naive approach is to retrain the model from scratch using a modified dataset that excludes the unlearning target. However, this approach can be computationally prohibitive in practice. Based on the degree of unlearning completeness, machine unlearning can be categorized into exact unlearning and approximate unlearning [65].\nExact unlearning aims to ensure that the unlearning target is fully unlearned, i.e., as complete as retraining from scratch [5, 66, 36]. This approach, which typically relies on retraining, is limited to unlearning specific instances and cannot be readily extended to generative models with strong feature generalizations. Approximate unlearning aims to obtain an approximate model, whose performance closely aligns with a retrained model [20, 54]. This approach estimates the influence of unlearning targets, and updates the model accordingly, usually through gradient-based updates, avoiding full retraining [3, 38]. However, accurate influence estimation is still challenging [23], reducing the applicability of this approach to generative models.\nIn generative models, the exploration of unlearning is accomplished by minimizing a composite loss, which is a combination of training loss on the retain and the forget sets [34]. This approach is highly dependent on manual parameter tuning and cannot guarantee unlearning completeness. As for comparison, the solutions yielded by our proposed controllable unlearning framework are theoretically guaranteed with Pareto optimality."}, {"title": "Preliminary", "content": "3.1 Unlearning Principles\nAs outlined in [11, 37], an unlearning task typically has three main principles: i) unlearning com-pleteness, which involves eliminating the influence of specific data from an already trained model; ii) unlearning efficiency, which focuses on enhancing the speed of the unlearning process; and iii) model utility, which aims to ensure that the performance of the unlearned model remains comparable to that of a model retrained from scratch."}, {"title": "Pareto Optimality", "content": "Consider a multi-objective optimization problem formulated as: \n\\[\\min \\mathbf{f}(\\theta) = (f_1(\\theta), f_2(\\theta),\\dots, f_m(\\theta)),\\]\nwhere \\( f_i(\\theta) \\) denotes the loss for the \\( i \\)-th objective.\nPareto dominance. Let \\( \\theta^a, \\theta^b \\) be two points in feasible set \\( \\Omega \\), \\( \\theta^a \\) is said to dominate \\( \\theta^b \\) (\\( \\theta^a \\prec \\theta^b \\)) if and only if \\( f_i(\\theta^a) \\le f_i(\\theta^b), \\forall i \\in \\{1, ..., m\\} \\) and \\( f_j(\\theta^a) < f_j(\\theta^b), \\exists j \\in \\{1, ...,m\\} \\).\nPareto optimality [39]. A point \\( \\theta^* \\) is Pareto optimal if there is no \\( \\theta \\in \\Omega \\) for which \\( \\theta \\prec \\theta^* \\). The collection of all such Pareto optimal points forms the Pareto set, and the surface of this set in the loss space is called the Pareto front.\n3.3 I2I Generative Model Unlearning\nModel architecture. Encoder-decoder structures are widely used in I2I models, with: i) an encoder \\( E_{\\gamma} \\) reducing images to the latent space, and ii) a decoder \\( D_{\\phi} \\) reconstructing images from the latent space. For model \\( I_{\\theta} \\) with input image \\( x \\), the output is:\n\\[I_\\theta(x) = D_\\phi(E_\\gamma(T(x))),\\]\nwhere \\( T(x) \\) denotes the cropping operation (such as center cropping or random cropping), and \\( \\theta = \\{\\gamma, \\phi\\} \\) denotes the full parameter set.\nUnlearning objective. Define the unlearning task for an I2I generative model \\( I_{\\theta_0} \\) involving data partitions \\( D_f \\) (forget set) and \\( D_r \\) (retain set). Consider an \\( I_{\\theta_0} \\), i.e., the original model, with training data \\( D = D_f \\cup D_r \\). Assume that \\( I_{\\theta_0} \\) is proficiently trained to generate satisfactory results on both \\( D_f \\) and \\( D_r \\). The objective of unlearning is to obtain an unlearned model \\( I_\\theta \\) that cannot generate satisfactory results on \\( D_f \\) (1st objective, unlearning completeness) while maintaining comparable performance on \\( D_R \\) (2nd objective, model utility). Formally,\n\\[\\max_\\theta (Div(P_{X_f}||P_{I_\\theta(T(X_f))})), \\text{ and } \\min_\\theta (Div (P_{X_r}||P_{I_\\theta(T(X_r))))),\\]\nwhere \\( X_f \\) and \\( X_r \\) are the variables for ground truth images in \\( D_f \\) and \\( D_r \\), \\( P(I_\\theta(X)) \\) is the model output distribution for input variable \\( X \\), and \\( Div(\\cdot||\\cdot) \\) represents distributional distance, measured by Kullback-Leibler (KL) divergence in this paper.\nFollowing prior work [30, 64, 62], as the model is proficiently trained, we hypothesize that \\( I_{\\theta_0} \\) can approximately replicate the distributions over both forget and retain sets [30, 64, 62], i.e., \\( P(X_f) \\approx P(I_{\\theta_0}(T(X_f))) \\), and \\( P(X_r) \\approx P(I_{\\theta_0}(T(X_r))) \\). Let \\( P_{X_f} := P(I_{\\theta_0}(T(X_f))) \\) and \\( P_{X_r} := P(I_{\\theta_0}(T(X_r))) \\). Then, Eq. (2) can be simplified to:\n\\[\\max_\\theta Div(P_{X_f}||P^{\\theta}_{X_f}), \\text{ and } \\min_\\theta Div(P_{X_r}||P^{\\theta}_{X_r}),\\]\nwhere \\( P_{X_f} \\) and \\( P^{\\theta}_{X_f} \\) represent the output distributions of the forget set before and after unlearning respectively. Similarly, \\( P_{X_r} \\) and \\( P^{\\theta}_{X_r} \\) represent those for the retain set."}, {"title": "Methodology", "content": "In this section, we first introduce a controllable unlearning framework for I2I generative models, which formulates unlearning as a constrained optimization with the unlearning objective as a constraint. We utilize a gradient-based method to obtain the boundaries of unlearning. Then we relax the constraint within the boundaries to derive a set of Pareto optimal solutions to fulfill varied user expectations.\n4.1 \\( \\varepsilon \\)-Constrained Optimization Formulation\nThe unlearning task for I2I models is reformulated as a bi-objective optimization (Eq. (3)), with the first objective to maximize \\( Div(P_{X_f}||P^{\\theta}_{X_f}) \\). Nonetheless, the value of \\( Div(\\cdot||\\cdot) \\) can theoretically be maximized to infinity, yielding an infinite number of possible \\( P^{\\theta}_{X_f} \\) [34], consequently resulting in extremely diminished model utility. To balance unlearning completeness and model utility, we bound \\( Div(P_{X_f}||P^{\\theta}_{X_f}) \\) by Lemma 1."}, {"title": "Pareto Optimality", "content": "Lemma 1 (Divergence Upper Bound [12]). Assuming the forget set with distribution \\( P_{X_f} \\), characterized by a zero-mean and covariance matrix \\( \\Sigma \\), and a signal \\( P_{\\hat{X}_f} \\), with the same statistical properties, the maximal KL divergence is realized when \\( P^{\\theta}_{X_f} = \\mathcal{N}(0, \\Sigma) \\).\n\\[Div(P_{X_f}||P^{\\theta}_{X_f}) \\le Div(P_{X_f}||\\mathcal{N}(0, \\Sigma)).\\]\nAs image normalization typically involves mean subtraction [17], we can assume \\( P_{X_f} \\) and \\( P^{\\theta}_{X_f} \\) follow zero-mean distributions for conciseness without sacrificing generality. Lemma 1 reveals that the upper bound of \\( Div(P_{X_f}||P^{\\theta}_{X_f}) \\) is achieved when \\( P^{\\theta}_{X_f} \\sim \\mathcal{N}(0, \\Sigma) \\). This suggests that maximizing \\( Div(P_{X_f}||P^{\\theta}_{X_f}) \\) equates to minimizing \\( Div(P^{\\theta}_{X_f}||\\mathcal{N}(0, \\Sigma)) \\). Consequently, we rewrite Eq. (3) as:\n\\[\\min_\\theta Div(\\mathcal{N}(0, \\Sigma)||P^{\\theta}_{X_f}), \\text{ and } \\min_\\theta Div(P_{X_r}||P^{\\theta}_{X_r}).\\]\nAs both terms in Eq. (5) depend on \\( \\theta \\), we define \\( f_1(\\theta) := Div(\\mathcal{N}(0, \\Sigma)||P^{\\theta}_{X_f}) \\) and \\( f_2(\\theta) := Div(P_{X_r}||P^{\\theta}_{X_r}) \\) for conciseness. However, unlike classification models where their outputs are precisely univariate discrete distributions [33, 70], high-dimensional KL divergence calculations in I2I generative models are intractable. Thus, following [34], we adopt the \\( L_2 \\) loss as a surrogate. Due to privacy legal requirements, unlearning objectives typically takes precedence. Thus, we set \\( f_1(\\theta) \\) as the primary constraint and treat Eq. (5) as a \\( \\varepsilon \\)-constrained optimization problem:\n\\[\\min_{\\theta \\in \\mathbb{R}^d} f_2(\\theta) \\text{ s.t. } f_1(\\theta) \\le \\varepsilon,\\]\nwhere \\( \\varepsilon \\) is a parameter to control the completeness of unlearning. We minimize \\( f_2(\\theta) \\) inside the feasible set \\( \\Omega = \\{\\theta : f_1(\\theta) \\le \\varepsilon\\} \\), which implies that our priority lies in unlearning the forget set rather than mitigating performance degradation on the retain set.\n4.2 Solving the \\( \\varepsilon \\)-Constraint Optimization\nTo solve the \\( \\varepsilon \\)-constrained optimization problem in Eq. (6), approaches such as Sequential Quadratic Programming (SQP) [43, 4], penalty function method [68], and interior point method [47] are commonly employed. Given the extensive parameter set of the I2I generative model, we select a special variant of the SQP algorithm for its lower complexity and comparable convergence guarantee [43, 40].\nSpecifically, we employ a gradient-based method to solve Eq. (6), updating the parameter by \\( \\theta_{\\tau+1} \\leftarrow \\theta_{\\tau} + \\mu_\\tau g_\\tau \\). Here, \\( \\mu_\\tau \\) denotes the step size, and \\( g_\\tau \\) represents the direction of the parameter update, which is determined by solving a convex quadratic programming problem w.r.t. \\( g \\):\n\\[g_\\tau = \\arg\\min_{g \\in \\mathbb{R}^d} \\{\\nabla f_2(\\theta_\\tau) \\cdot g - \\frac{1}{2}||g||^2 \\text{ s.t. } \\nabla f_1(\\theta_\\tau) \\cdot g \\ge \\psi(\\theta_\\tau)\\},\\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ (7)\\]\nwhere \\( \\psi(\\theta_\\tau) \\) is a control function that associates \\( g_t \\) to the constraints in Eq. (6). We provide a summary of our proposed unlearning algorithm in Algorithm 1 (see Appendix B).\nAssumption 1. Assume \\( f_1(\\theta) \\) and \\( f_2(\\theta) \\) are continuously differentiable, with \\( sign(\\psi(\\theta)) = sign(f_1(\\theta) - \\varepsilon) \\), where \\( sign(x) = \\begin{cases} 1 & \\text{for } x \\neq 0\\\\ 0 & \\text{sign(0)} = 0 \\end{cases} \\), and the trajectory \\( \\{\\theta_t : t \\in [0,+\\infty)\\} \\) follows the continuous-time dynamics \\( \\frac{d\\theta_t}{dt} = -g_t \\), where \\( g_t \\) is defined in Eq. (7) and \\( \\max_{t \\in [0,+\\infty)} \\mathcal{N}_t < +\\infty \\).\nThe convergence analysis of Algorithm 1 regarding Eq. (6) utilizes the continuous-time framework given by \\( \\frac{d\\theta_t}{dt} = -g_t \\), as mentioned in Assumption 1. Please refer to Lemma 2 in Appendix C.1 for further details of convergence.\n4.3 A Controllable Unlearning Framework\nOur controllable unlearning framework consists of two phases. In Phase I, we reformulate Eq. (6) into a special form to obtain the solution for the boundaries of unlearning. In Phase II, we adjust the value \\( \\varepsilon \\) within its valid range to relax the unlearning constraint and obtain the Pareto optimal solutions for controllable unlearning. This relaxation of unlearning completeness allows for a controllable trade-off between completeness and model utility, thereby catering to varied user expectations."}, {"title": "Controllable Unlearning", "content": "Phase I: Boundaries of unlearning. The boundaries of unlearning refer to the two Pareto optimal solutions with the highest and lowest degrees of unlearning completeness.\nTo obtain the Pareto optimal solutions with the highest degrees of unlearning completeness, we reformulate Eq. (6)into the following special form:\n\\[\\min_{\\theta \\in \\mathbb{R}^d} f_2(\\theta) \\text{ s.t. } f_1(\\theta) \\le \\varepsilon,\\]\nwhere \\( \\varepsilon = f_1^* \\), and \\( f_1^* := \\inf_{\\theta \\in \\mathbb{R}^d} f_1(\\theta) \\).\nThe solution of this optimization problem can be obtained by Algorithm 1. According to Assumption 1, we need to ensure that \\( \\psi(\\theta) \\ge 0 \\) in Eq. (8) to guarantee the same sign with \\( f_1(\\theta) - \\varepsilon \\). In this paper, we we simply define \\( \\psi(\\theta) = a||\\nabla f_1(\\theta)||^\\delta \\) with \\( a > 0 \\) and \\( \\delta \\ge 1 \\).\nProposition 1 (Boundary of Pareto Set). Under Assumption 1, let \\( f_1^* > -\\infty \\) and \\( f_2^* > -\\infty \\) be the infimum of \\( f_1(\\theta) \\), \\( f_2(\\theta) \\), respectively. Further, let \\( \\psi(\\theta) \\) be continuous and \\( \\nabla f_1(\\theta) \\) be continuously differentiable. If \\( \\theta_t \\rightarrow \\theta^* \\) and \\( g_t \\rightarrow 0 \\) as \\( t \\rightarrow +\\infty \\), with \\( \\nabla^2 f_1(\\theta) \\) of constant rank near \\( \\theta^* \\) and \\( f_1(\\theta), f_2(\\theta) \\) being convex near \\( \\theta_t \\), then \\( \\theta^* \\) is a Pareto optimal solution and \\( f_1(\\theta^*) = f_1^* \\).\nProposition 1 ensures that the solution \\( \\theta^1 \\) obtained by Algorithm 1 for solving Eq. (8) is on the boundary of the Pareto set, specifically refer to the highest degree of unlearning completeness. Meanwhile, \\( f_1(\\theta^1) \\) achieve the infimum of \\( f_1(\\theta) \\).\nObtaining the Pareto optimal solution with the lowest unlearning completeness is similar to the process mentioned above, with the difference of exchanging the positions of \\( f_1(\\theta) \\) and \\( f_2(\\theta) \\) in Eq. (8). This new problem is formulated as \\( \\min_{\\theta \\in \\mathbb{R}^d} f_1(\\theta) \\text{, s.t. } f_2(\\theta) \\le \\varepsilon \\), where \\( \\varepsilon = f_2^* \\), and \\( f_2^* := \\inf_{\\theta \\in \\mathbb{R}^d} f_2(\\theta) \\). The solution \\( \\theta^2 \\) obtained by solving this problem is another boundary the Pareto set, i.e., the Pareto optimal solution with the lowest unlearning completeness, with \\( f_2(\\theta^2) \\) achieving the infimum of \\( f_2(\\theta) \\).\nPhase II: Controllable unlearning. To adjust the trade-off between unlearning completeness and model utility, we relax the unlearning constraint by defining \\( f_1(\\theta^1) < \\varepsilon < f_1(\\theta^2) \\) in Eq. (6), where \\( \\theta^1 \\) and \\( \\theta^2 \\) have already been obtained in Phase I. Then we rewrite Eq. (8) for controllable unlearning:\n\\[\\min_{\\theta \\in \\mathbb{R}^d} f_2(\\theta) \\text{ s.t. } f_1(\\theta) \\le \\varepsilon,\\]\nwhere \\( \\varepsilon > f_1^* \\), and \\( f_1^* := \\inf_{\\theta \\in \\mathbb{R}^d} f_1(\\theta) \\)."}, {"title": "Efficiency of Unlearning", "content": "where \\( \\varepsilon \\in \\mathbb{R} \\) is used to adjust the completeness of unlearning. In Phase II, according to the sign condition in Assumption 1, we simply set \\( \\psi(\\theta) = \\beta (f_1(\\theta) - \\varepsilon)^\\delta \\) with \\( \\beta > 0, \\delta = 2n + 1 \\) and \\( n \\in \\mathbb{N} \\).\nProposition 2 (Interior of Paret Set). Under Assumption 1, let \\( f_2^* = \\inf_{\\theta \\in \\mathbb{R}^d} f_2(\\theta) > -\\infty \\) and \\( \\sup_{t \\in [0,+\\infty)} \\mathcal{N}_t = \\mathcal{N}_{max} < +\\infty \\). If \\( \\theta^+ \\) is a stationary point with \\( g_t = 0 \\) and \\( \\mathcal{N}_t < +\\infty \\), and both \\( f_1(\\theta) \\) and \\( f_2(\\theta) \\) are convex at \\( \\theta_t \\), then \\( \\theta_t \\) is a Pareto optimal solution w.r.t. \\( \\varepsilon \\).\nFrom Proposition 2, Eq. (9) provides a Pareto optimal solution w.r.t. \\( \\varepsilon \\). By progressively increasing \\( \\varepsilon \\) from \\( f_1^* \\), which is estimated by \\( f_1(\\theta^1) \\) in Phase I, we can trace a path of Pareto optimal solutions for different completeness of unlearning. As a result, this path offers controllable unlearning for varied user expectations.\n4.4 Enhancing the Efficiency of Unlearning\nTo enhance the efficiency of unlearning, we investigate the influence of the control function \\( \\psi(\\theta) \\) on convergence rates across different phases, as outlined in the proposition below:\nProposition 3. Under Assumption 1, with \\( f_2^* = \\inf_{\\theta \\in \\mathbb{R}^d} f_2(\\theta) > -\\infty \\), then:\n1. For Phase I, if \\( \\psi(\\theta) = a||\\nabla f_1(\\theta)||^\\delta \\) with \\( a > 0 \\) and \\( \\delta > 1 \\), the convergence rates of \\( f_1(\\theta) \\) and \\( f_2(\\theta) \\) are \\( O(\\frac{1}{t}) \\) and \\( O(\\frac{1}{t^{\\frac{2}{\\delta}}}) \\), respectively.\n2. For Phase II, if \\( \\psi(\\theta) = \\beta (f_1(\\theta) - \\varepsilon)^\\delta \\) with \\( \\beta > 0, \\delta = 2n+1, n \\in \\mathbb{N} \\), and \\( \\sup_{t \\in [0,+\\infty)} \\mathcal{N}_t = \\mathcal{N}_{max} < +\\infty \\), the convergence rate of \\( [f_1(\\theta) - \\varepsilon]_+ \\) is \\( O(\\frac{1}{t}) \\).\nProposition 3 demonstrates that the convergence rate depends on the exponent \\( \\delta \\) in \\( \\psi(\\theta) \\), where higher values of \\( \\delta \\) result in a faster convergence rate of \\( f_1(\\theta) \\). However, excessively large \\( \\delta \\) can also lead to a slower convergence rate of \\( f_2(\\theta) \\) and instabilities in training. To balance convergence rate and training stability, we explore various \\( \\varepsilon \\) in \\( \\psi(\\theta) \\) in both phases with extensive empirical studies. The results can be found in Section 5.4."}, {"title": "Experiments", "content": "5.1 Experimental Settings\nWe evaluate our proposed method on three mainstream I2I generative models", "25": "Vector Quantized Generative Adversarial Networks (VQ-GAN) [35", "49": ".", "Datasets": "Following [34", "datasets": "i) ImageNet-1K [14", "71": "from which we randomly select 100 classes", "Baselines": "We first report the performance of the original model (i.e.", "34": "we set the following baselines: i) Max Loss [63", "19": "which maximizes the training loss on the forget set; ii) Retain Label [31"}, {"19": "which minimizes the training loss by introducing Gaussian noise to the ground truth images of the forget set; and iv) Composite Loss [34", "baselines": "i) Inception Score (IS) of the generated images [51", "26": "and iii) the cosine similarity between the CLIP embeddings of the generated images and the ground truth images [46", "comparison": "As shown in Table 1", "analysis": "Following [34", "60": "to further analyze our method's effectiveness. Using our unlearned model", "robustness": "We validate the performance of our controllable unlearning framework in different image generation tasks by changing the cropping patterns. The results indicate that our framework is robust to various image generation tasks and generally outperforms baselines", "Summary": "These results validate the effectiveness of our proposed method", "trade-off": "the unlearning completeness decreases, while the generated images' performance on the forget set progressively improves, and, simultaneously, the performance on the retain set also improves. This observation clearly demonstrates the controllability of our proposed method, which can cater to varied user expectations. Please refer to Appendix I for additional results of the generated images and T-SNE analysis, which corroborates the above numerical results.\n5.4 Unlearning Efficiency\nTo enhance the efficiency"}]}