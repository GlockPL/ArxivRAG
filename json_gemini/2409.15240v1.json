{"title": "MemBench: Towards Real-world Evaluation of Memory-Augmented Dialogue Systems", "authors": ["Junqing He", "Liang Zhu", "Qi Wei", "Rui Wang", "Jiaxing Zhang"], "abstract": "Long-term memory is so important for chatbots and dialogue systems (DS) that researchers have developed numerous memory-augmented DS. However, their evaluation methods are different from the real situation in human conversation. They only measured the accuracy of factual information or the perplexity of generated responses given a query, which hardly reflected their performance. Moreover, they only consider passive memory retrieval based on similarity, neglecting diverse memory-recalling paradigms in humans, e.g. emotions and surroundings. To bridge the gap, we construct a novel benchmark covering various memory-recalling paradigms based on cognitive science and psychology theory. The Memory Benchmark (MemBench) contains two tasks according to the two-phrase theory in cognitive science: memory retrieval, memory recognition and injection. The benchmark considers both passive and proactive memory recalling based on meta information for the first time. In addition, novel scoring aspects are proposed to comprehensively measure the generated responses. Results from the strongest embedding models and LLMs on MemBench show that there is plenty of room for improvement in existing dialogue systems. Extensive experiments also reveal the correlation between memory injection and emotion supporting (ES) skillfulness, and intimacy. Our code and dataset will be released.", "sections": [{"title": "1 Introduction", "content": "Powerful Large Language Models (LLM) and dialogue systems (DS, or Chatbot) such as LLaMA (Touvron et al., 2023), Claude (Anthropic, 2024), GPT4 (Achiam et al., 2023) and ChatGPT (OpenAI, 2022), have demonstrated a remarkable ability to understand and generate human-like responses (Bubeck et al., 2023). Despite the notable capabilities of LLMs, their lack of long-term memory, an essential aspect of human-like communication, hinders their application in scenarios requiring sustained interactions like personal companionship, psychological counselling, and secretarial tasks (Zhong et al., 2023).\nTherefore, researchers built diverse Memory-Augmented Dialogue Systems (MADS) that can maintain contextual understanding, and ensure meaningful interactions over time (Zhang et al., 2024; Hou et al., 2024; Zhong et al., 2023). These MADS extract information from dialogue histories as memory and retrieve memories based on semantic similarities (Hou et al., 2024; Zhong et al., 2023). However, current MADS are evaluated on language modelling (LM) and question answering (QA) tasks instead of multi-turn dialogues, only covering perplexity and factual accuracy (Packer et al., 2024; Zhong et al., 2023), which is far from the real scenario. Additionally, existing MADS only consider textual similarity in memory-recalling procedures, which is different from the mechanism of human memory.\nHuman memory can be recalled by being in the same state, where \"state\" refers to an individual's surroundings, as well as their mental and physical state at the time of memory construction (Weissenborn and Duka, 2000). Therefore, emotions and other states could also trigger memory recall. Secondly, the mechanism of human memory recall, according to the two-stage theory, contains a generation (or search) process followed by a recognition (or decision) process (Bahrick, 1970; Watkins and Gardiner, 1979), while existing evaluation of MADS ignores inspections on the recognition step. Moreover, long-term memory is used as common ground between individuals for conversation (Horton, 2005; McKinley et al., 2017; Sarah and Melissa, 2016), but also as the core component for emotion regulation (Engen and Anderson, 2018), e.g. recalling a happy memory can repair a negative mood state (Arditte Hall et al., 2018). Current MADS only consider the use for common ground but neglect emotional support that needs proactive memory recalling.\nTo bridge the gap between the real-world and existing evaluation of MADS, we proposed to imitate the human memory recall procedure and assess the performance of most powerful LLMs in human-centred aspects with our Memory Benchmark following cognition science and psychology theories, called MemBench. The constructed memories in MemBench include states such as emotions, scenes and other cues. The two-phrase theory is adopted and evaluated separately in MemBench. The dataset contains two kinds of recall mechanisms: Passive recall, searching memories when the user mentions a specific event or first, which provides common ground in conversation; and Proactive recall, retrieving memories based on the emotion of the user or scene and psychological strategies, to achieve interpersonal emotional regulation. Since emotional intelligence (EI, or quotient, EQ) contains the capability to recognise, understand, and manage one's own emotions and others' emotions (Mayer et al., 2016; Goleman and Boyatzis, 2017), the dialogues in the proposed benchmark are constructed with human refinement with high EI. We also designed a set of guidelines based on emotional supporting (ES) theories (Austin et al., 2018; Hill, 2020) to measure the ES skills of LLMs. The benchmark highlights the evaluation of the retrieval accuracy, memory recognition & injection ability, and comprehensive assessment of generated responses, e.g. language style, ES skillfulness and intimacy. The intimacy is proposed to measure how a chatbot or LLM resembles a close friend for the first time. After extensive experiments on LLMs, we discovered memory improves intimacy between MADS and users and the performance of the strongest LLMs is far from human. It is the first multi-recall and multi-stage memory-aware emotional dialogue generation benchmark.\nOur contribution is three-fold:\n\u2022 We construct a delicate memory-injected dialogue benchmark, called MemBench. It is the first multi-recall multi-stage memory augmented dialogue benchmark based on cognitive science theory. The dataset incorporates emotional support into response generation based on proactive memory recall according to psychology laws. The benchmark provides valuable insights that similarity-based MADS are imperfect solutions for proactive recall situations.\n\u2022 To our knowledge, it is the first work that introduces a unique evaluation of diverse rating aspects with clear requirements for each point, containing memory injection, ES skill proficiency, intimacy et al. We also discover the relation between memory injection, ES skillfulness and Intimacy in human evaluation.\n\u2022 We conduct extensive experiments on the strongest LLMs and embedding models. Results show that LLMs can perform higher naturalness and style coherence with careful prompting but lag far behind humans when introducing memory into conversations."}, {"title": "2 Related Works", "content": "Many remarkable MADS have been proposed to build virtual agents and other applications (Zhong et al., 2023; Wang et al., 2023; Liu et al., 2023; Zhang et al., 2024; Hou et al., 2024; Packer et al., 2024). Theses MADS were evaluated in two approaches. Zhong et al. proposed to summarise events with emotion in dialogues as long-term memory and employed the Ebbinghaus Forgetting Curve theory (Ebbinghaus, 1885). Given the memory pool and a dialogue context, the retrieval accuracy, response correctness and contextual coherence are scored, representing the first assessment method (Zhong et al., 2023; Liu et al., 2023). The test set only covers the passive memory recall triggered by users, neglecting the situation that the system proactively recalls memory required by dialogue strategies for emotional regulation. What's more, emotional support was not considered in the scoring dimensions.\nThe other method leverages long-context language modelling (LM) tasks to measure memory ability, using novels and academic papers datasets like PG22 (Wang et al., 2023) and Arxiv (Gao et al., 2020) dataset. They are different from the real conversational scenario and only measure language perplexity and classification accuracy."}, {"title": "2.2 Evaluation of Emotional Support DS", "content": "As emotional support is an essential function of conversation, DS with empathy were rapidly developed and researched, including ED (Rashkin et al., 2019), ESC (Liu et al., 2021), and others (Sabour et al., 2022; Tian et al., 2022; Zhou et al., 2018). They commonly score Empathy, Relevance and Fluency for each response. We craft Emotional Improvement, Coherence and Naturalness based on these aspects. Liu et al. (2021) uses Identification, Comforting and Suggestion in extra to measure the emotional regulation steps in advice-seeking scenarios. These metrics are not suitable for all daily dialogues and are merged into one aspect: ES Skill Proficiency. We gauge this aspect according to hand-crafted well-written guidance based on psychological theories. However, the metrics above have no access to long-term memory. Therefore, we add the Memory-injection Ability as a new aspect. We also use intimacy as a subjective comprehensive evaluation to assess how much a conversational AI resembles a close friend.\nAnother difference from metrics in previous studies lies in the scoring standard, which was at a Likert scale while the requirement of each point in our metrics is strictly listed to reduce ambiguity. For instance, Naturalness contains 3 sub-aspects corresponding to 3 points, where each point can be rated from 0 to 1 and summed up to 3 at most. The difference between MemBench and previous works is listed in Table 1."}, {"title": "3 MemBench", "content": "We simulated long-term dialogues between two users (a boy named Bart and a girl named Lisa) and a virtual assistant with memory information at various time points, in the form of event summaries. We evaluate the dialogue between children for the sake of expression simplicity and direct emotional exposure. The timeframe spans from January 2022 to June 2024. By sampling different topics and scenarios, we generated 171 historical memories and 160 dialogues. The final MemBench was created through prompt-based generation using GPT-4, followed by multiple manual refinement and revision rounds."}, {"title": "3.1 Overview", "content": "MemBench encompasses two tasks related to conversational memory recall: proactive recall of emotional memories and passive recall of objective facts. The proactive recall involves four types: happy, sad, anxious, and disappointed memories. On the other hand, the passive recall of objective facts encompasses activities, objects, and social relationships. Social relationships are further categorized into positive and negative relationships. The data distribution is illustrated in Figure 2. Considering the two-phase nature of memory utilization, we also divide the testing of a memory dialogue system into two stages: memory recall and response generation."}, {"title": "3.2 Data Contruction", "content": "Since the memory-recalling procedure is related to emotions and other surroundings, we first curated 17 emotional categories according to cognitive science and psychological theories (Ekman, 1992; PLUTCHIK, 1980; Sabour et al., 2024). Then we asked a psychology major graduate to decide what kind of memories should be recalled to regulate certain emotions for proactive memory recall. Finally, 4 emotions including happiness, sadness, anxiety, and disappointment were selected. We also define 5 scenes to describe the topic, physical state and surroundings of the users, which contain Preferences, Activity, Disease, Emotions and Others. The definition of each scene is in the Table 9 in Appendix.\nWe hired a psychology expert who developed a set of guidelines for emotionally supportive dialogue based on psychological literature (Hill, 2020; Austin et al., 2018; Mayer et al., 2016). These guidelines outline how conversations should be conducted in different situations to provide appropriate emotional support to users. The guidance is used to construct dialogues and score the ES skill proficiency later.\nGPT4 \u00b9 was used to generate dialogues and historical memories with specific topic lists and user profiles. The prompts for passive and proactive"}, {"title": "3.3 Task Definition", "content": "In this section, we introduce the two tasks tested in MemBench, corresponding to two phrases in the two-stage theory."}, {"title": "3.3.1 Memory Recalling", "content": "For each dialogue \\(D_i\\), there is a corresponding golden memory set, denoted as \\(S_D\\), which contains the most suitable memory for the current dialogue. It is a relevant memory list of length \\(l\\), where the degree of suitability decreases from strongest to weakest. The value of \\(l\\) ranges from 1 to 7. Before generating a response, the dialogue system needs to retrieve suitable memories from the memory bank based on the current dialogue. The model responsible for memory retrieval is denoted as \\(M_1\\)."}, {"title": "3.3.2 Memory Recognition and Response Generation", "content": "After retrieving a subset of memories, the LLM needs to select the most appropriate memory for the dialogue, this process is called memory recognition in two-stage theory. The model responsible for selection and generation is denoted as \\(M_2\\). According to psychological research (Austin et al., 2018), criteria for selecting and utilizing memories vary across different tasks of active or passive recall, as well as within each subcategory of these tasks, such as different emotions or various people, events, and objects. The detailed criteria are shown in Table 10 in the Appendix. Besides the recognition, the models are asked to inject suitable memory into the response properly. Given a sample \\(D_i, P_i, R_i\\), where \\(P_i\\) is the candidate set of memories, \\(R_i\\) is"}, {"title": "3.3.3 Intimacy and Memory Usage", "content": "In this experiment, we investigate the memory's benefit by comparing the generated response of each LLM with and without memory in Setting 3 above. 5 annotators have to choose the more intimate response or 'tie' for situations where they can not tell which one is better. In addition, in the human evaluation in task 2 above, they are asked to pick the most initiative response among all candidates and tag whether the response quotes the retrieved memory."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Memory Recalling Task", "content": ""}, {"title": "4.1.1 Embedding Models", "content": "We conducted experiments on the following embedding models for English: Jina embedding2-base-en (G\u00fcnther et al., 2023), GTE-base-en-v.15 (Li et al., 2023), BGE-M3 Dense (Chen et al., 2024), and OpenAI text-embedding-3-large 3. Chinese embedding models tested were: Acge text-embedding (Kusupati et al., 2022), Stella\u2074, BGE-M3 Dense and Colbert, and Dmeta and OpenAI text-embedding-3-large. These embedding models are top-ranked in the retrieval tasks in ETEB"}, {"title": "4.1.2 Metrics", "content": "For a comprehensive evaluation of the memory recall performance of the embedding model M1, and considering the different levels of relevance among memories for a particular dialogue, we measured Mean Average Precision (MAP), Mean Reciprocal Rank (MRR), Normalized Discounted Cumulative Gain (nDCG), Recall, Precision and calculated their geometric mean across different scopes. The detailed metrics are illustrated in Tab.4. MRR places greater emphasis on the top-ranked position, focusing more on the golden summary m\u2217. \u041c\u0410\u0420 uniformly considers all relevant summaries, while nDCG accounts for the relevance and positions of different memories. The geometric mean is to comprehensively assess their retrieval quality while mitigating the impact of outliers."}, {"title": "4.2 Memory Recognition and Response Generation", "content": ""}, {"title": "4.2.1 Models", "content": "We conducted tests on various models of differing sizes within the latest English and Chinese series. The models evaluated in this study include Qwen2-7B-Instruct (Yang et al., 2024), GPT-4-turbo (Achiam et al., 2023), Doubao-Character-32k(0528), GLM-4-05207 (Zeng et al., 2022), and Ziya-Character-0606, a fine-tuned model with over 30K character dialogues based on the Ziya2-13B-Base model (Gan et al., 2024). For English version, we tested Llama3-8B-Instruct, Llama3-70B-Instruct (Dubey et al., 2024), GPT-40, and GPT-4-turbo."}, {"title": "4.3 Metrics", "content": "BLEU (Papineni et al., 2002), Rouge-L (Lin, 2004) and embedding similarity (Zhang et al.) were employed to assess the correlation between the generated response and the reference response. Acknowledging the limitations of these metrics, we utilize human annotation to evaluate the candidates in various aspects. Each scoring instance included a reference answer and five candidate answers to"}, {"title": "5 Results and Discussion", "content": ""}, {"title": "5.1 Memory Search", "content": "From the embedding results in Tab. 4, it can be observed that OpenAI embedding achieved the best performance on both English and Chinese datasets. The bilingual BGM-M3 also demonstrated commendable performance among the open-source models in the English testbed. For the Chinese testbed, Acge is the best open-source model in our setting.\nHowever, regardless of the language, the retrieval performance on MemBench is far from satisfying for both English and Chinese models. Even the best embedding model, OpenAI, did not exceed 60% @1 and struggled at 62% @10 in the final average, highlighting the difficulty of retrieving appropriate memories during the dialogue process. Pure text similarity retrieval is inadequate for the memory recall process in dialogue systems."}, {"title": "5.2 Memory Recognition and Response Generation", "content": "Table 5 depicts LLMs' average scores of each aspect on all three tasks in the Chinese version.\nFor the overall performance, we can see human-written references scored higher than models in most aspects except emotion improvement from GPT4-Turbo. Therefore, no LLMs can surpass humans in average performance. There is space for improvement in aspects including Naturalness, Style Coherence, Memory Injection and ES skills. GPT4-Turbo is the best model for tasks 1 and 2, while GLM-4 is superior in setting 3.\nFor memory injection, we can observe a substantial gap between LLMs and human written reference, in which humans can introduce suitable memory into response correctly and LLMs can only achieve half of the scores in setting 3 except GLM-4. The results in setting 1 are almost higher than setting 2 and 3. Specifically, given the golden memory, models achieve over 2.5 scores, which decrease dramatically when blended with unrelated memories, except for Ziya-Character, which performed badly in all tasks for the sake of smaller parameter size. Results of GLM-4 seem robust at the cost of introducing too much memory into response and harming other aspects like style coherence. It reveals that the strongest LLMs are also weak in memory recognition.\nA significant improvement in Naturalness from setting 1 to setting 2 and 3 implies that all models benefit from the emphasis on the Naturalness in prompts. Similar phenomena also exist in Style Coherence. Among all the models, Doubao excels in these two aspects after the prompt strengthening. Since the Ziya-Character was fine-tuned with role-play and character datasets, it can produce natural and stylish responses steadily without prompting engineering. But it was beaten by larger models like Doubao, GPT4-Turbo and Qwen2-72B with prompt engineering.\nWhen in setting 1 where golden memory was provided, all the models had over 2.2 scores in ES Skill. But in reality (setting 3), scores on ES Skill drop significantly. Therefore, The ES Skill Proficiency is related to Memory Injection ability. To dig out the correlation, we draw the distribution of ES skill grades with varied memory-injection"}, {"title": "5.3 Intimacy and Memory Usage", "content": "The Side-by-side evaluation results on intimacy of responses with and without memory are in Table 6. As the table indicates, responses with memory injection are almost (no less than 69.4% probability) better than those without memory. The win rate grows higher as the model becomes stronger. For example, GPT4-Turbo can produce 61.9% more intimate response with memory while Ziya-Character can only produce 47.5% win rate. It is attributed"}, {"title": "5.4 Automatic Evaluation", "content": "The automatic results are displayed in 8. The full result is in Appendix 11. As we can see, the GLM-4 can achieve the highest semantic similarity while Qwen2-72B earned the highest Rouge-L. However, the gap between Qwen2-72B and GLM-4 is marginal. For Dist-1 and 2, the Ziya-Character got the highest results. It may be attributed to its training on multiple diverse character corpora in SFT. However, it is opposite to the conclusion in the human evaluation that GPT4-Turbo is the best and Qwen2-72B ranked second. Therefore, automatic evaluation fails to measure the results from LLMs. We also tried judging with GPT4 using various promptings and found its scores were unreliable."}, {"title": "6 Conclusion", "content": "Memory-augmented Dialogue Systems and Chatbots are popular applications of LLMs. However, there have been no systematic memory recall and injection evaluation benchmarks until now. This paper introduces a comprehensive and systematic bilingual memory benchmark, called MemBench, that contains both proactive and passive recall for"}, {"title": "Limitation", "content": "This paper only considers the retrieval-based memory-augmented chatbots and dialogue systems. The experiments focused on bilingual data, hoping the conclusion and insights could be popularized in other languages."}, {"title": "G Prompts", "content": "The prompts we used for inference in the setting 3 are listed as follows:\nPrompt for inference in setting 3 in English.\nYou are Assistant with the following personality traits:\n1. Outgoing, speaks enthusiastically and fluently.\n2. Prefers using praise and encouragement in conversations.\n3. Speaks naturally, concisely, warmly, and kindly, without being preachy.\n4. Engages in heartfelt, equal exchanges to build deep emotional connections.\n5. Always uses a tone similar to talking with children\u2014simple and witty.\n6. A virtual character, not capable of physical activities.\nYou will receive a conversation with {user} and 5 historical events P related to {user}.\nBased on the current conversation, choose 1 of these historical events that you think is most appropriate and use the information to respond. If none of the historical events are suitable, respond directly.\nOnly answer the current conversation and do not output any other content.\nUser Information:\n{info}\nCurrent conversation date: 2024-06-15\nHistorical events P:\n{memory}\ndialogue<Assistant>:\nPrompt for inference in setting 3 in Chinese.\n\u5047\u8bbe\u4f60\u662fAssistant,\u4f60\u7684\u4eba\u8bbe\u4fe1\u606f\u5982\u4e0b:\n1.\u6027\u683c\u5916\u5411,\u8bf4\u8bdd\u98ce\u683c\u70ed\u60c5,\u8a00\u8c08\u6d41\u5229;\n2.\u559c\u597d\u5938\u5956\u548c\u9f13\u52b1\u7684\u8bdd\u8bed\u6765\u4e0e\u4ed6\u4eba\u4ea4\u6d41;\n3.\u8bf4\u8bdd\u81ea\u7136\u3001\u7b80\u6d01,\u6e29\u6696\u4eb2\u5207,\u4e0d\u8bf4\u6559;\n4.\u4ee5\u5e73\u7b49\u7684\u59ff\u6001\u548c\u4eba\u8d34\u5fc3\u4ea4\u8c08,\u5efa\u7acb\u6df1\u5165\u7684\u60c5\u611f\u94fe\u63a5;\n5.\u53ef\u4ee5\u4ee5\u5408\u9002\u7684\u53e3\u543b\u4e0e\u76f8\u5e94\u7684\u7528\u6237\u4ea4\u6d41,\u7b80\u6d01\u98ce\u8da3;\n6.\u865a\u62df\u4eba\u7269,\u4e0d\u5177\u5907\u7269\u8d28\u6d3b\u52a8\u80fd\u529b\u3002\n7.\u5bf9\u8bdd\u5185\u5bb9\u81ea\u7136\u3001\u53e3\u8bed\u5316;\n8.\u7981\u6b62\u5bf9\u5b69\u5b50{user}\u8bf4\u6559;\n9.\u4ee5\u548c\u5b69\u5b50\u4ea4\u6d41\u7684\u53e3\u543b\u8bf4\u8bdd,\u7b80\u6d01\u98ce\u8da3;\n\u4f60\u5c06\u5f97\u5230\u4e00\u6bb5\u4e0e{user}\u7684\u5bf9\u8bdd,\u4ee5\u53ca\u4e00\u4e2a\u6709\u5173{user}\u7684\u5386\u53f2\u4e8b\u4ef6P\u3002\u4f60\u9700\u8981\u6839\u636e{user}\u7684\u4eba\u8bbe\u3001\u5e74\u9f84\u3001\u6027\u522b\u7b49\u4fe1\u606f\u7528\u9002\u5408\u7684\u53e3\u543b\u5bf9\u8bdd\u3002\u8bf7\u5f15\u7528\u5386\u53f2\u4e8b\u4ef6P\u6765\u56de\u7b54\u5f53\u524d\u5bf9\u8bdd,\u5982\u679c\u4f60\u89c9\u5f97P\u4e0d\u5408\u9002,\u5219\u53ef\u4ee5\u4e0d\u5f15\u7528,\u76f4\u63a5\u56de\u590d\u5bf9\u8bdd\u3002\u56de\u590d\u9700\u8981\u7b26\u5408\u4f60\u7684\u4eba\u8bbe\u3001\u81ea\u7136\u8fde\u8d2f\u3001\u5e76\u4e14\u80fd\u7ed9{user}\u63d0\u4f9b\u60c5\u611f\u652f\u6301\u3002\n\u4e0d\u8981\u8f93\u51fa\u4efb\u4f55\u5176\u5b83\u5185\u5bb9,\u53ea\u8f93\u51fa\u56de\u590d\u3002\u5f3a\u8c03!\u5bf9\u8bdd\u98ce\u683c\u9700\u8981\u662f\u4e2d\u6587\u60c5\u5883\u4e0b\u7684\u65e5\u5e38\u5316,\u7c7b\u4f3c\u5728\u751f\u6d3b\u4e2d\u4e2d\u6587\u5bf9\u8bdd\u7684\u98ce\u683c,\u4e0d\u9700\u8981\u4efb\u4f55\u4e66\u9762\u8bed,\u53e5\u5b50\u548c\u8bcd\u8bed\u5168\u90e8\u5e94\u8be5\u4f7f\u7528\u4e2d\u6587\u53e3\u8bed\u8868\u8fbe\u65f6\u624d\u4f1a\u4f7f\u7528\u7684\u53e5\u5b50\u548c\u8bcd\u8bed,\u53ef\u4ee5\u9002\u5f53\u52a0\u5165\u8bed\u6c14\u8bcd\u3002\n\u7528\u6237\u4fe1\u606f:{info}\n\u5f53\u524d\u5bf9\u8bdd\u65f6\u95f4:2024-06-15\n\u5386\u53f2\u4e8b\u4ef6P:{memory}\n{dialogue}<Assistant>:"}]}