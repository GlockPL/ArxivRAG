{"title": "Local Descriptors Weighted Adaptive Threshold Filtering For Few-Shot Learning", "authors": ["Bingchen Yan"], "abstract": "Few-shot image classification is a challenging task in the field of machine learning, involving the identification of new categories using a limited number of labeled samples. In recent years, methods based on local descriptors have made significant progress in this area. However, the key to improving classification accuracy lies in effectively filtering background noise and accurately selecting critical local descriptors highly relevant to image category information.\nTo address this challenge, we propose an innovative weighted adaptive threshold filtering (WATF) strategy for local descriptors. This strategy can dynamically adjust based on the current task and image context, thereby selecting local descriptors most relevant to the image category. This enables the model to better focus on category-related information while effectively mitigating interference from irrelevant background regions.\nTo evaluate the effectiveness of our method, we adopted the N-way K-shot experimental framework. Experimental results show that our method not only improves the clustering effect of selected local descriptors but also significantly enhances the discriminative ability between image categories. Notably, our method maintains a simple and lightweight design philosophy without introducing additional learnable parameters. This feature ensures consistency in filtering capability during both training and testing phases, further enhancing the reliability and practicality of the method.", "sections": [{"title": "I. INTRODUCTION", "content": "Deep learning Deep learning models have achieved remarkable success across various computer vision domains when trained on large-scale manually annotated datasets [1]-[5]. However, these models continue to face significant challenges when dealing with novel classes containing only a few labeled samples, often resulting in overfitting or convergence failure. In contrast, humans can effortlessly recognize new classes from a limited number of labeled samples by leveraging prior knowledge. Few-shot learning aims to bridge this gap by generalizing knowledge acquired from base classes (with abundant labeled samples) to novel classes (with limited labeled samples), thus garnering increasing attention [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15].\nThe field has witnessed the emergence of various exemplary few-shot learning methods, broadly categorized into three types: metric learning-based [2, 3, 4, 5, 11, 12, 13, 14, 15], meta-learning-based [8, 9, 10], and transfer-based [16, 17, 18, 19, 20, 21, 22] approaches. Notably, metric learning-based methods have achieved significant success due to their simplicity and efficacy. This paper primarily focuses on this approach. The typical pipeline of metric learning-based few-shot learning methods encompasses three steps: 1) Feature extraction from all query and support images; 2) Distance computation between the query image and each support image, prototype, or class center using a specific metric; 3) Label assignment to query images through nearest neighbor search. Despite the impressive performance of metric learning-based few-shot learning methods, they are persistently plagued by noisy local regions irrelevant to image category information, as the semantics of local regions within images can vary significantly [14, 23]. As illustrated in Figure 1, some regions contain critical semantics consistent with image category information, i.e., category-relevant information (e.g., the \"dog\" area in a \"dog\" image, or the \"bird\" area in a \"bird\" image). Conversely, other regions may contain semantics irrelevant to image category information, i.e., category-irrelevant information (e.g., the \"sky\" area in a \"dog\" image, or the \"grass\" area in a \"bird\" image).\nTo address this issue, GLIML[7] and KLSANet [5]employ a dual-branch architecture to simultaneously learn global and local features of images, selecting local features by measuring their similarity to the image's global features. Although"}, {"title": "II. RELATED WORKS", "content": "Few-shot learning algorithms can be broadly categorized into three main classes: initialization-based methods, methods rooted in transfer learning and metric-based methods."}, {"title": "A. Initialization-based methods", "content": "Initialization-based methods [8, 9, 10, 24, 25, 26] utilize gradient updates to achieve effective initialization. MAML [8] introduced a powerful initialization technique that significantly enhances performance with just a few gradient steps, employing a bi-level optimization strategy where the outer loop learns to generalize across tasks and the inner loop adapts to specific tasks. LEO [24] extends MAML by operating in a low-dimensional space to improve generalization in FSL tasks. Proto-MAML [25] combines the strong inductive bias of ProtoNet [11] with the flexible adaptation mechanism of MAML [8]. However, the MAML family typically uses a simple cross-entropy function for inner loop optimization, which can result in limited generalization performance. To address this, Baik et al. (2021) [27] proposed a task-specific loss function to update meta-learner parameters during the meta-training process. Wang et al. (2022) [26]provided a theoretical analysis of how MAML with deep neural networks converges to the global optimum and developed a specialized neural architecture search algorithm for FSL."}, {"title": "B. Methods rooted in transfer learning", "content": "Methods rooted in transfer learning frameworks have demonstrated competitive performance in the realm of few-shot learning, often rivaling meta-learning techniques. The general methodology of these approaches follows a distinct pattern:\nInitially, a classification model is trained on the entire available training dataset. Subsequently, the classification layer is discarded, preserving only the feature extraction component. Finally, utilizing the support set from the test data, a new classifier is developed and trained. This strategy has proven effective, with several notable implementations gaining traction in the field. Among these, Dynamic Classifier [28], Baseline++ [17], and RFS [30] stand out as particularly influential contributions."}, {"title": "C. Metric-Based Methods", "content": "Metric-based methods [2, 3, 4, 5, 11, 12, 13, 14, 15] aim to learn a universal metric space to measure the relationship between query images and support sets, thereby quantifying their similarity. Matching Networks [12] determine the similarity between each support set sample and a query sample, predicting the query sample's label by computing a weighted sum of these similarities. Prototypical Networks innovatively average the support set features to form class prototypes and evaluate the Euclidean distance between the query and class prototypes in the embedding space [11]. Relation Networks compare the relation between images by learning a deep nonlinear metric. TADAM [28]enhances few-shot learning (FSL) by learning a task-dependent metric space through metric scaling.\nDespite their potential, current methods largely depend on image-level global features, assuming their transferability across seen and unseen classes, which is often unrealistic. In contrast, low-level features like local descriptors and local features are more likely to be shared among different classes and are expected to transfer better to unseen classes have demonstrated the superiority of local descriptors over global representations in few-shot image classification.\nFor instance, LMP-Net [13]leverages local descriptor-level features rather than global features in Prototypical Networks, learning multiple class prototypes for each class to capture the complex distribution of the class more comprehensively. DN4 [4] employs deep local descriptor representation and explicitly uses local descriptors through k-nearest neighbors"}, {"title": "III. \u041c\u0415\u041d\u0422OD", "content": ""}, {"title": "A. Problem Definition", "content": "Few-shot learning aims to develop models that excel with minimal data while maintaining robust generalization. We tackle the N-way K-shot challenge, where N represents class count and K denotes samples per class, typically a small number like 1 or 5.\nOur goal is to train model parameters 0, for swift adaptation to unseen data using episodic training. Each episode in both training and test datasets contains a support set S (N classes, K labeled images each) and a query set Q for evaluation.\nThe data is split into non-overlapping training, validation, and testing sets, each containing more classes and samples than N and K. These sets are then further divided into episodes with distinct support and query sets sharing the same label space.\nTo simulate real-world scenarios, all phases employ this episodic mechanism. For example, during training, random episodes are selected for parameter updates until convergence. In validation and testing, the model classifies the query set based on the support set."}, {"title": "B. Overview", "content": "As illustrated in Figure [X], our proposed approach comprises three principal components: the Embedding Feature Extraction Module (EFEM), the Weighted Adaptive Threshold Filtering Module (WATFM), and the Key Local Descriptors Classification Module (KLDCM).\nInitially, we employ an embedding network constructed on the episodic learning mechanism to extract local descriptor-level embedding features from both the support set and query set images. Subsequently, the WATFM computes weight information for each local descriptor of the images in the support and query sets. This process enables the identification and selection of key local descriptors while eliminating background noise, thereby enhancing few-shot classification performance."}, {"title": "C. EFEM", "content": "We utilize a widely-used neural network, typically a Convolutional Neural Network (CNN) or ResNet, following previous work, to serve as a local descriptor feature extractor. This local descriptor feature extractor can be implemented by removing the last pooling layer or the fully connected layer of the neural network. To illustrate with a CNN as an example:\nEach image X is passed through the CNN to obtain a three-dimensional (3D) tensor $F_{\\theta}(X) \\in R^{C \\times H \\times W}$. This tensor represents the image, where $F(X)$ is the hypothesized function learned by the CNN, $\\theta$ stands for the parameters of the CNN, and C, H, and W denote the channel, height, and width of the 3D tensor, respectively. This can be expressed as:\n$F_{\\theta}(X) = [x_1,...,x_M] \\in R^{C \\times M}$                                                                            (1)\nHere, M = H \u00d7 W, maps all images to a representational space. Each 3D tensor contains M units of C dimensions, with each unit representing a local descriptor of the image."}, {"title": "D. WATFM", "content": "Due to the large intra-class variation and background clutter, the measurement of using all local descriptors directly for few-shot image classification is far from satisfactory. Therefore, it is more reasonable to filter out the local descriptors most relevant to the category and then carry out subsequent operations.\nOur local descriptor filtering strategy is based on the following premise: As shown in Figure X, in a typical few-shot task, the support set usually consists of five categories, with N typically set to 5. For K support set images of a category, if a local descriptor in one of the K support set images is category-relevant (containing exact representative features of that category), then similar local descriptors should exist in the other (K- 1) support set images. Conversely, if a local descriptor comes from a background area irrelevant to the category of the support set image, the likelihood of similar local descriptors appearing in the other (K - 1) support set images of the same category is low, and they may even appear in support set images of other categories.\nFollowing the approach of ProtoNet [11], we calculate the category prototype for each support set category by averaging, which possesses more comprehensive and representative information related to the support set category, used for key local descriptor filtering. The filtering process includes two main steps. First, we compute the similarity between each candidate local descriptor of the support sample and its support set category prototype. In the feature embedding space, we denote the prototype representation of the nth category as $C_n$, where n \u2208 [1, \u039d].\nFor a support set image, we obtain the local descriptor representation as follows:"}, {"title": "E. KLDCM", "content": "To predict the category of a query image, we extend the concept of image-to-class measure, utilizing the selected local descriptors for classification. Specifically,\nThe key local descriptors of a given query image q selected after WATFM filtering are represented as:\n$F_{oitered}(X_q) = [x_1,...,x_H^q] \\in R^{C \\times H}$                                                                         (9)\nwhere H < M. After WATFM filtering, each category in the support set can be represented as class i (i = 1,2,3,...,5). For each filtered key local descriptor $x^q_h$ of q, where $h\\in [1,H]$, we find its k nearest neighbors denoted as $n_1,......,n_k$ in each filtered support set local descriptor and compute the corresponding cosine similarities as $cos(x^q_h, n_1),......, cos(x^q_h, n_k)$. The similarity score between image q and class i is defined as:"}, {"title": "IV. EXPERIMENT", "content": ""}, {"title": "A. Datasets", "content": "CUB-200 is a fine-grained bird image classification dataset involving 200 different bird species. The number of images per category varies, with 130 categories used for training, 20 for validation, and the remaining 50 for testing.\nThe Stanford Dogs dataset focuses on fine-grained dog image classification, comprising 20,580 photographs of 120 different dog breeds. 70 dog breeds are used for training, 20 for validation, and the remaining 30 for testing.\nThe Stanford Cars dataset is designed for fine-grained car image classification, containing 16,185 images of 196 different car categories, defined by make, model, and year of manufacture. 130 categories are used for training, 17 for validation, and the remaining 49 for testing."}, {"title": "B. Implementation Details", "content": "In our experiments, we primarily focus on 5-way 1-shot and 5-shot classification tasks. To ensure fair comparison with other methods, we employ two commonly used backbone network structures in few-shot learning: Conv4 and ResNet-12, following the implementation details outlined in DN4 [4]and CovaMNet [29].\nDuring the training phase, we use the Adam optimization algorithm (Kingma & Ba, 2014) with an initial learning rate of 0.001, which is halved every 100,000 episodes.\nIn the testing phase, to ensure the reliability of the experimental results, we randomly construct 600 episodes from the test set of each dataset to evaluate the model's performance. We select the best model based on the accuracy on the"}, {"title": "V. CONCLUSION", "content": "In this study, we propose a effective WATF method to enhance the performance of few-shot learning."}]}