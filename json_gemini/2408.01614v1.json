{"title": "Advancing Mental Health Pre-Screening: A New Custom GPT for Psychological Distress Assessment", "authors": ["Jinwen Tang", "Yi Shang"], "abstract": "This study introduces 'Psycho Analyst', a custom GPT model based on OpenAI's GPT-4, optimized for pre-screening mental health disorders. Enhanced with DSM-5, PHQ-8, detailed data descriptions, and extensive training data, the model adeptly decodes nuanced linguistic indicators of mental health disorders. It utilizes a dual-task framework that includes binary classification and a three-stage PHQ-8 score computation involving initial assessment, detailed breakdown, and independent assessment, showcasing refined analytic capabilities. Validation with the DAIC-WOZ dataset reveals F1 and Macro-F1 scores of 0.929 and 0.949, respectively, along with the lowest MAE and RMSE of 2.89 and 3.69 in PHQ-8 scoring. These results highlight the model's precision and transformative potential in enhancing public mental health support, improving accessibility, cost-effectiveness, and serving as a second opinion for professionals.", "sections": [{"title": "I. INTRODUCTION", "content": "The development of Generative Pre-trained Transformers (GPTs) has marked a significant advancement in artificial intelligence [1]. In the realm of public health, mental well-being has become increasingly recognized as a crucial aspect, yet it faces challenges in terms of recognition and accessibility. Societal barriers, including stigma and reluctance to discuss psychological distress, hinder individuals from seeking timely and effective clinical intervention [2] [3]. These challenges are further compounded by economic constraints and limited availability of mental health services. In this context, the ad-vancements of Large Language Models (LLMs), such as GPT-3.5 and GPT-4, offer new possibilities for discreet, accessible, and non-judgmental mental health support.\nOur study explores the potential of GPT-4 and specialized GPT variants in mental health research, particularly focusing on their ability to facilitate empathetic and nuanced interac-tions that are conducive to preliminary mental health screen-ings and emotional support. We implemented 'Psycho Ana-lyst', a custom GPT model specifically designed for mental health pre-screening through textual analysis. We conducted a comprehensive evaluation of this model using the DAIC-WOZ database [4], measuring its efficacy in identifying current men-tal health issues, and demonstrating the model's high precision.\nThese results not only highlight the capability of Psycho Analyst GPT in detecting mental health concerns but also mark a crucial step in early intervention strategies. Furthermore, the Psycho Analyst GPT's ability to analyze extensive data from clinical dialogues and studies positions it as an essential tool for discerning trends and patterns in mental health, thereby enriching research and understanding of various psychological conditions. The model's ability to be fine-tuned with specific therapeutic approaches and psychological theories paves the way for more individualized therapeutic interventions.\nThis paper contributes to the field in several areas:\n1) Innovative Model Development: We developed 'Psy-cho Analyst,' a custom GPT model optimized for men-tal health pre-screening, utilizing OpenAI's ChatGPT-4 service. This model uniquely integrates the DSM-5 and PHQ-8, both of which are globally recognized for their clinical validity. Additionally, it incorporates detailed data descriptions and training data from the DAIC-WOZ database. This comprehensive integration significantly enhances the model's capacity to accurately interpret nuanced language, enabling it to effectively identify various mental health conditions.\n2) Dual Task Framework: 'Psycho Analyst' operates through a sophisticated dual-task framework designed to handle both classification of mental health status and computation of PHQ-8 scores. This dual approach allows for a more comprehensive evaluation of mental health conditions, offering both binary classification and detailed severity assessments.\n3) Empirical Evaluation and Validation: The Psycho Analyst model has been rigorously validated using the DAIC-WOZ clinical transcript dataset. Our evaluations confirm the model's effectiveness in real-world clinical environments, reinforcing its practical applicability for mental health diagnostics. This empirical assessment not only underscores the robustness of Psycho Analyst but also highlights its superior performance in comparison to other large language models such as GPT-40 and Mixtral-8*7B.\n4) Innovative Application in Learning Scenarios: The model's superior performance in zero-shot and few-shot learning scenarios highlights its capability to adapt to varied data with minimal training. This feature is particularly valuable in mental health settings where the model can quickly adjust to the nuances of different patient interactions without extensive retraining.\n5) New potential for Public Mental Health: By suc-cessfully integrating DSM-5 and PHQ-8 criteria into the generative Al analysis process, the Psycho Ana-lyst model opens new possibilities for early interven-tion and tailored mental health care. This integration enables more precise, personalized, and cost-effective assessments, significantly improving the potential for early detection and customized treatment plans in public health settings.\nIn summary, this work underscores the advanced capabilities of custom GPT models in mental health diagnostics and heralds new pathways for accessible and personalized mental health care.\nIn the rest of this paper, we will delve into the background and related work to provide context and foundation for our study. We will then introduce our data and methodology, detailing the development and configuration of the Psycho Analyst GPT model. This is followed by a presentation of our analyses and results, where we evaluate the model's performance. Finally, we will discuss the implications of our findings, addressing the limitations of our study, and exploring future research directions."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "In the realm of mental health research, leveraging machine learning and advanced natural language processing methods has become increasingly prevalent. These technologies have been used to analyze a range of data types, including brain imaging, clinical notes, mobile sensor data, and surveys. Studies have aimed at identifying individuals at risk of suicide, classifying mental health conditions such as major depressive disorder (MDD) [5] and schizophrenia [6], differentiating between disorders with similar symptoms [7], and predicting the severity of mental health issues [8]. These efforts signify a paradigm shift toward data-driven insights for enhancing mental health outcomes.\nDespite these advancements, a significant challenge persists in effectively reaching and assisting the majority of individuals grappling with mental health concerns. Approximately two-thirds of such individuals are hesitant to seek professional help, with an even smaller fraction consulting mental health specialists [9], [10]. This reluctance often stems from societal stigma and discomfort in openly discussing mental health issues.\nIn response to these challenges, recent research has in-creasingly focused on utilizing text data from social media platforms, including blogs, Twitter, Reddit, and Chinese Weibo [11]. These platforms offer a rich, publicly accessible source of personal expressions, enabling researchers to detect and mon-itor mental health states more effectively [12], [13]. However, the majority of these studies do not directly involve clinical diagnoses, which limits the precision of their findings.\nTraditionally, mental health research has relied heavily on Electronic Health Records (EHRs) and clinical notes [14], [15]. These sources, while rich in professional and structured content, often lack the natural expressions of patients, as they are typically summaries or rephrasings by healthcare professionals. Despite their value, access to these records is generally restricted, and they may not fully capture the personal linguistic nuances associated with various mental health conditions.\nRecognizing the limitations of both social media data and traditional clinical records, the DAIC-WOZ dataset and its extensions [4], [16], [17] provide a unique blend of narrative speech and clinical interview transcripts, offering insights into natural linguistic expressions coupled with clinical diagnoses. This approach allows for a more nuanced analysis of language related to anxiety, depression, and PTSD, bridging the gap between clinical accuracy and natural expression.\nVillatoro et al. [18] used a mental lexicon approach to differentiate between depressed and non-depressed individuals in clinical interviews, achieving macro F1 scores of 0.83 in the DAIC-WOZ and E-DAIC datasets.\nSolieman et al. [19] extended this research by diagnosing depression through audio recordings, using two models that processed data from the DAIC-WOZ database, yielding F1-scores of 0.8 and 0.76. Belser et al. [20] compared three NLP models BGRU, HAN, and Long-sequence Transformer for screening depression in the DAIC-WOZ dataset, with both Transformer and HAN models achieving accuracies of 0.77 and F1-scores of 0.76.\nMilintsevich et al. [21] developed a multi-target hierarchical regression model for predicting individual depression symp-toms from interviews in the DAIC-WOZ corpus, achieving a macro-F1 score of 73.9 and MAE of 3.78 for total depression score prediction.\nYadav et al. [22] proposed a novel automated depression detection approach using linguistic content from patient in-terviews. This approach comprised a Bidirectional Gated Re-current Unit (BGRU) network for linguistic information pro-cessing and a fully connected network to assess the depressed state. Validated using the Distress Analysis Interview Corpus-Wizard-of-Oz interviews dataset, the approach achieved an impressive F1 score of 0.92, outperforming previous models. This study highlighted the effectiveness of BGRU over Long Short Term Memory models in recognizing depression."}, {"title": "III. DATA DESCRIPTION AND PREPROCESSING", "content": "In this paper, we utilized the DAIC-WOZ dataset, a subset of the larger Distress Analysis Interview Corpus (DAIC) [16], extensively described in [4]. This dataset is distinguished by its integration of audio and video recordings alongside compre-hensive questionnaire responses, obtained from Wizard-of-Oz style interviews. These interviews were facilitated by 'Ellie,' an animated virtual interviewer operated remotely by a human interviewer. The primary focus of the DAIC-WOZ database lies in its clinical interviews, which are specifically designed to facilitate the diagnosis of psychological distress conditions such as anxiety, depression, and PTSD."}, {"title": "IV. METHODS", "content": "A. Model Development\nWe developed 'Psycho Analyst,' a custom GPT utilizing OpenAI's ChatGPT-4 service, tailored for mental health pre-screening. This model is designed to identify signs of mental health disorders such as anxiety, depression, stress, and bipolar within textual data. It integrates the Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition (DSM-5), and the Patient Health Questionnaire-8 (PHQ-8) as foundational elements. These standards are globally recognized for their clinical validity and provide structured diagnostic criteria, thereby enhancing the model's capability to accurately inter-pret nuanced language indicative of mental health conditions.\nB. Dual Task Framework\nPsycho Analyst operated through structured prompts that guided its analytical processes. Its evaluation framework was based on two distinct tasks: (1) classification and (2) PHQ-8 score computation. Its performance was evaluated using various settings of background knowledge, as discussed later.\n1) Task 1: Classification: To accurately reflect the com-plexities of mental health assessments, we used a nuanced 7-point scale for classifying mental health conditions. This scale ranged from 1, indicating 'not at all likely,' to 7, representing 'extremely likely.' This method allowed for a more detailed representation of the likelihood of a condition, accommodating the often nuanced and uncertain nature of mental health diagnostics. The final classification into binary outcomes was computed based on a threshold value determined through careful evaluation of the likelihood scores.\nThe single comprehensive prompt guided the model to:\n\u2022 Assess Mental Health Status: Determine whether each patient, referenced by their ID, was likely to have mental health issues. This included a detailed analysis of the conditions present, using linguistic indicators found in the text data.\n\u2022 Quantify Condition Severity: Calculate the severity on a 7-point scale. This approach provided a more refined assessment compared to a simple binary outcome, better capturing the subtleties and uncertainties inherent in mental health evaluations.\nThis framework enhanced the model's ability to conduct de-tailed and context-sensitive analyses, furthering the application of generative AI in mental health evaluations.\nillustrates how Psycho Analyst processed clinical interview tran-scripts to assess mental health conditions and assign likelihood scores. These examples emphasize the model's capability to move beyond mere yes/no classifications, thus accommodating the often ambiguous and complex nature of psychological symptoms for more clinically relevant and precise evaluations.\n2) Task 2: PHQ-8 Score Computation: The PHQ-8 as-sessment task, a comprehensive three-step process, evaluates how effectively our model, Psycho Analyst, analyzes mental health symptoms from individual transcripts. A detailed visual representation of this task is shown in Figure 2. The PHQ-8 tool measures mental health challenges on a scale from 0 to 24. Scores of 10 or higher might indicate significant mental health concerns, while scores of 20 or higher suggest more severe issues.\na) Stage 1: Initial Analysis: In the first stage, Psycho An-alyst is tasked with conducting a detailed analysis of a clinical interview transcript to determine the mental health status of an individual. This analysis is comprehensive, utilizing both the content of the transcript and the specific evaluation criteria outlined in the background materials provided. The evaluation focuses on two primary objectives:\n\u2022 Mental Health Assessment: Analyze the transcript to determine if the individual has mental health issues, providing a reasoned explanation for the assessment. The analysis should cite relevant portions of the transcript and illustrate how these align with the criteria provided in the background knowledge, including the PHQ-8 items.\n\u2022 PHQ-8 Score Estimation: Estimate the PHQ-8 score for the individual based on the transcript's content and the evaluation guidelines from the background materials. The PHQ-8 score is crucial for assessing the severity of mental health symptoms.\nb) Stage 2: Detailed Breakdown: In the second stage, the model is asked to break down how it derives the PHQ-8 score for each symptom. This involves a step-by-step explanation of the scoring process, ensuring transparency and clarity in how the PHQ-8 score is computed based on the individual's responses in the transcript.\nc) Stage 3: Independent Assessment: The third stage evaluates the model's capacity for independent reasoning. Psycho Analyst is presented with a PHQ-8 score previously assigned to an individual by another evaluator, extracted from the original dataset. The tasks for the model in this stage are as follows:"}, {"title": "V. RESULTS AND ANALYSIS", "content": "This section evaluates the performance of the models for both tasks, beginning with an examination of execution times across different AI models.\nExecution times varied significantly among the models tested. OpenAI's models, including GPT-4 and GPT-40, pro-cessed Task 1 in approximately 10-20 seconds and completed the three-stage Task 2 in about 1.5 to 2 minutes. In contrast, Mixtral-8*7B, despite utilizing an NVIDIA A100 GPU with 80GB of memory, took an average of 12 minutes to produce a single output for both Task 1 and each stage of Task 2. To maintain the integrity of the test conditions, any single output from Mixtral-8*7B that exceeded three hours were excluded from the analysis.\nA. Task 1: Classification Result\nIn the evaluation of Psycho Analyst's performance, the 7-point likelihood scores provided by Psycho Analyst were binarized to classify subjects as either having or not having mental health issues. To determine the optimal threshold that would reflect the most accurate classification by the model, we tried threshold values from 3 to 7 (cut off at >= the threshold value) The results indicate that score threshold 5 consistently yielded the highest model accuracy. Therefore, we used score 5 as the cut-off point to binarized the 7-point likelihood scores provided by Psycho Analyst in subsequent evaluations of Psycho Analyst's performance.\ncompares Psycho Analyst's performance across four configurations of background knowledge in the complete DAIC-WOZ dataset, assessing metrics such as F1 score, Macro-F1 score, Accuracy, Recall, Precision, and ROC-AUC score.\nWith no background knowledge, the model achieves an F1 score of 0.769 and an Accuracy of 0.872. Adding PHQ-8 slightly lowers all performance metrics, while incorporating DSM-5 alone enhances them, yielding an F1 score of 0.792 and an Accuracy of 0.888. The combination of DSM-5 and PHQ-8 results in the highest improvements, achieving an F1 score of 0.929, Accuracy of 0.957, Recall of 0.945, Precision of 0.912, and ROC-AUC of 0.968, highlighting the synergistic effect of these tools in boosting diagnostic accuracy and reliability.\nFurther insights are provided in Table VII, which compares the performance of the Psycho Analyst model on the DAIC-WOZ Test Set across various configurations. This includes an enhanced configuration that integrates DSM-5, PHQ-8, a detailed data description from the dataset's curator, and an expanded training set. Performance is also compared with two baseline models.\nThe GPT-4 model without background knowledge shows moderate performance, with an F1 score of 0.759 and an Accuracy of 0.851. Adding PHQ-8 decreases performance to an F1 score of 0.690 and an Accuracy of 0.808, while including DSM-5 enhances outcomes to an F1 score of 0.786 and an Accuracy of 0.872. The combined use of DSM-5 and PHQ-8 significantly boosts performance, similar to previous results, achieving an F1 score of 0.857 and Accuracy of 0.915. Additional enhancements from incorporating detailed data descriptions and an expanded training set further improve metrics, elevating the F1 score to 0.929 and Accuracy to 0.957. Comparative analysis with GPT-40 and Mixtral-8*7B, both lacking background knowledge, highlights Psycho Analyst's superior performance. GPT-40 reaches an F1 score of 0.667 and accuracy of 0.702, while Mixtral-8*7B shows slightly lower scores, emphasizing Psycho Analyst's advantages even without enhanced configurations.\nThese results indicate that the incorporation of diverse back-ground knowledge, along with relevant data descriptions and training data, significantly enhances Psycho Analyst GPT's di-agnostic capabilities. The improved performance demonstrates its potential as a robust tool for mental health pre-screening.\nB. Task 2: PHQ-8 Score Computation Result\nFigure 4 illustrates the distribution of absolute differences for the three-stage PHQ-8 score computation. The histograms depict the frequency of absolute differences between the true PHQ-8 scores and those estimated by various configurations of the GPT-4 model, the GPT-40 model, and the Mixtral-8*7B model. Each bar represents the frequency of a specific range of differences, demonstrating the accuracy of each configuration in accurately estimating mental health statuses.\nWhen GPT-4 is enhanced with the PHQ-8 tool, both the initial assessment in Stage 1 and the detailed breakdown in Stage 2 exhibit similar performance, with minimal variation in the distribution of absolute differences. This consistency suggests that the inclusion of PHQ-8 provides a stable and reliable basis for both the initial analysis and the subsequent detailed scoring breakdown.\nFor other configurations of GPT models excluding PHQ-8, a noticeable improvement in performance during the detailed breakdown (Stage 2) is observed compared to the initial analysis (Stage 1). This indicates that a reassessment and detailed exploration of the initial model's assessment can significantly refine the accuracy of the models' evaluations, correcting any deficiencies noted in the initial analysis.\nMoreover, in Stage 3, where other evaluators' opinions were provided as a reference, the GPT models still demonstrated a significant degree of autonomy. Despite the influence of external assessments, these models maintained a substantial level of self-decision, indicating their robustness in integrating and yet independently assessing complex clinical information.\nThe performance of Mixtral-8*7B is markedly different from the other models. A significant number of assessments were marked as 'NA' (not available), indicating that the model failed to complete the 3-stage task in many instances. Only a few cases reached all the way through Stage 3, suggesting substantial issues with data handling or model capability. This extensive occurrence of missing values undermines the value of Mixtral-87B's computations in this task, rendering it less valuable.\npresents detailed metrics of these assessments, including Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and R-squared values for each model config-uration. The results indicate that the Psycho Analyst model equipped with both DSM-5 and PHQ-8 significantly outper-forms other configurations. This performance is further en-hanced when additional data descriptions and training data are included. This table allows for a comprehensive comparison of performance across all stages of the PHQ-8 score computation task."}, {"title": "VI. CONCLUSION AND DISCUSSION", "content": "The results from our evaluation of the Psycho Analyst custom GPT model represent a significant advancement in the use of GPT technology for mental health pre-screening. The model's enhanced performance, particularly when integrated with DSM-5, PHQ-8, detailed data descriptions, and robust training data, demonstrates its ability to handle nuanced lan-guage processing and its potential for precise mental health diagnostics, both in binary classification and PHQ-8 compu-tation. The findings underscore that leveraging comprehensive background knowledge markedly improves the model's diag-nostic capabilities, as evidenced by the notable increase in accuracy detailed in the tables and figures presented.\nOur results also reveal that providing the PHQ-8 criteria as background enhances the stability of the initial PHQ-8 score computations. Conversely, for models without this background, prompting the model to explain its assessments significantly improves performance. Furthermore, the Psycho Analyst model demonstrates an ability to think independently, as evidenced by its occasional disagreements with other assessments. This independence is crucial for reliable and unbiased mental health evaluations.\nThe superior performance of the Psycho Analyst model, indicated by high F1, Macro-F1 scores, and low error metrics, confirms its reliability for initial mental health screenings. This reliability is vital in clinical settings where early detection can profoundly impact patient outcomes. By providing a robust tool for early diagnosis, Psycho Analyst could potentially streamline the diagnostic process, reduce the workload on mental health professionals, and enhance accessibility for patients. This model not only enhances diagnostic precision but also ensures that interventions are timely and contextually appropriate, significantly advancing the field of mental health care.\nWhen compared to recent approaches in DAIC-WOZ tran-script analysis, the Psycho Analyst model demonstrated supe-rior performance not only in accuracy but also in functionality, as shown in Table IX.\nLooking forward, the application of the Psycho Analyst model promises substantial benefits. Integrated into an AI-driven conversational chatbot familiar with mental health criteria, it enables at-risk populations to receive timely, low-cost, and barrier-free assessments at home. This capability is poised to significantly enhance public mental health out-comes by facilitating early detection and intervention. Fur-thermore, leveraging the advanced language capabilities of large language models (LLMs), the Psycho Analyst can also assist clinical professionals by providing a second opinion. This independent thinking ability can aid clinicians in self-checking their evaluations, contributing to more standardized and objective assessments in clinical settings.\nOur next steps with the Psycho Analyst model involve expanding its capabilities to analyze social media data. This advancement will allow us to identify and understand mental health trends and indicators from the vast, unstructured data available online, in real time. Adopting this proactive approach to mental health surveillance promises to transform how we monitor well-being on a large scale. Additionally, we are in the process of developing a conversational interview chatbot."}, {"title": "ACKNOWLEDGMENT", "content": "ChatGPT was used to revise the writing to improve the spelling, grammar, and overall readability."}]}