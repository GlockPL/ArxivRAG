{"title": "Dynamic Detection of Relevant Objectives and\nAdaptation to Preference Drifts in Interactive\nEvolutionary Multi-Objective Optimization", "authors": ["Seyed Mahdi Shavarani", "Mahmoud Golabi", "Lhassane Idoumghar", "Richard Allmendinger"], "abstract": "Evolutionary Multi-Objective Optimization Algo-\nrithms (EMOAs) are widely employed to tackle problems with\nmultiple conflicting objectives. Recent research indicates that not\nall objectives are equally important to the decision-maker (DM).\nIn the context of interactive EMOAs, preference information\nelicited from the DM during the optimization process can be\nleveraged to identify and discard irrelevant objectives, a crucial\nstep when objective evaluations are computationally expensive.\nHowever, much of the existing literature fails to account for the\ndynamic nature of DM preferences, which can evolve throughout\nthe decision-making process and affect the relevance of objectives.\nThis study addresses this limitation by simulating dynamic shifts\nin DM preferences within a ranking-based interactive algorithm.\nAdditionally, we propose methods to discard outdated or con-\nflicting preferences when such shifts occur. Building on prior\nresearch, we also introduce a mechanism to safeguard relevant\nobjectives that may become trapped in local or global optima due\nto the diminished correlation with the DM-provided rankings.\nOur experimental results demonstrate that the proposed methods\neffectively manage evolving preferences and significantly enhance\nthe quality and desirability of the solutions produced by the\nalgorithm.", "sections": [{"title": "I. INTRODUCTION", "content": "In many real-world optimization problems, candidate solu-\ntions often involve numerous numerical features that need si-\nmultaneous optimization. Each of these features holds varying\ndegrees of importance for decision makers, making it challeng-\ning to prioritize objectives. This often leads to the inclination\nto model as many objectives as possible [1]. However, such\nan approach significantly increases computational time, which\nincreases exponentially with the number of objectives [2-4].\nOn the other hand, multi-objective problems are character-\nized by conflicting objective functions, aiming to identify a\nset of solutions that offer compelling trade-offs, termed non-\ndominated or Pareto-optimal solutions. The count of Pareto-\noptimal solutions grows exponentially with the number of\nobjectives [5, 6], further complicating the decision-making\nprocess [7]. Thus, it is essential to reduce the number of\nobjectives, if possible.\nPrevious studies on objective reduction have focused mainly\non eliminating objectives that are highly correlated with oth-\ners [1, 7] or those that do not significantly impact the domi-\nnance relations among solutions [8, 9]. However, irrespective\nof the problem structure, certain objectives may be \u201cirrelevant\u201d\nto the decision maker (DM) and can be excluded from the\noptimization model. In addition, there are instances where\nthe DM preferences are influenced by factors beyond the\noptimized objectives, including numerical features observed\nby the DM but not explicitly targeted by the system. These\nfeatures, which are \"hidden\" from the optimizer but relevant\nto the DM, can affect the satisfaction of the DM if neglected\nduring optimization [10, 11]. The concept of hidden objectives\nwas previously discussed under the term \u201cunmodeled criteria\"\nby Stewart [12] and was defined as objectives that exist within\nthe internal utility function (UF) of the DM, but are not\nincluded in the preference model. Later, formal definitions of\nhidden and irrelevant objectives were proposed in [13].\nThe detection of hidden and irrelevant objectives is possible\nusing the preference information obtained in interactive evolu-\ntionary multi-objective optimization algorithms (iEMOA) [14].\n\u00a1EMOAs are designed to address the significant performance\ndecline in traditional EMOAs caused by the increase in\nthe number of objectives, which reduces the selection pres-\nsure [15-17]. iEMOAs overcome this issue by utilizing the\nDM's preferences and discrimination information to develop\na preference model. This preference model is used mainly\nto break the ties between solutions in the same rank and\nto generate only the parts of the Pareto front (PF) that\nare interesting to the DM [18, 19]. By alternating between\ndecision-making and optimization phases and exploiting the\nDM's preference information, iEMOAs minimize computa-\ntional costs and support the DM in finding a desirable solution\nwith minimal cognitive effort.\nIt's common for a decision maker (DM) to adjust pref-\nerences during the optimization process, often as a result\nof learning and exploring the solution space through inter-"}, {"title": "II. DEFINITIONS", "content": "This section provides a set of key definitions to ensure a\nclear understanding of the concepts discussed in this paper. For\ncompleteness reasons and due to the novelty of the problem\nsetting, we will recap relevant definitions as defined in our\nprevious work [13].\nWithout loss of generality, this study focuses on a minimiza-\ntion multi-objective optimization problem, which is commonly\nformulated as follows [29]:\nMinimize $f(x) = f_1(x),..., f_m(x)$\nsubject to $x\u0395\u03a9$\nIn this context, x \u2208 R is a solution vector comprising n\ndecision variables, and \u03a9\u2208R\" represents the feasible region,\ndefined by constraints on decision variables. For each x, a set\nof m numerical features, denoted as F = {$f_1$,..., $f_m$}, can be\ncalculated and optimized as objective functions. The function\nf: \u03a9 \u2192 Rm maps each solution vector in Rn to an objective\nvector in Rm.\nDefinition II.1 (Potential objectives). The set of all features\nF, where |F| = m, is known as the potential objectives.\nDefinition II.2 (Active objectives). Assume that due to mod-\neling decisions or efficiency considerations, only a subset\nF C F (m = |F| \u2264 m) of the potential objectives need\nto be minimized. The objectives in set F are called active.\nInactive objectives (F \\ F) are either evaluated but ignored or\nnot evaluated at all. Inactive objectives do not participate in\nthe optimization process.\nDefinition II.3 (Objective evaluation). In the EMOA liter-\nature, computational cost is typically measured by solution\nevaluations, where each evaluation includes the evaluation of\nall active objectives. However, since different solutions can be\nevaluated against varying subsets of objectives, we use objec-\ntive evaluations instead. Each evaluation of an objective $f_i$ for\na solution x counts as one objective evaluation. Consequently,\nthe cost of a solution evaluation is m objective evaluations."}, {"title": "III. BACKGROUND AND LITERATURE REVIEW", "content": "A comprehensive literature review of methods for reducing\nthe number of objectives has been conducted and is sum-\nmarized in this section. Many of these studies use the term\ndimension reduction to denote this concept. However, to avoid\nconfusion with methods that reduce the number of decision\nvariables [39], the term \"objective reduction\" is preferred.\nBefore discussing the research studies delving into objec-\ntive reduction, it is essential to outline some key concepts\nrelated to multi-objective optimization. The primary goal\nin multi-objective problem-solving is to identify satisfactory\nnon-dominated solutions from the PF. This process typically\ninvolves two distinct phases [40]: (1) the optimization phase,\nwhich aims to approximate the PF, and (2) the decision-making\nphase, focused on determining the DM's Most Preferred\nSolution (MPS). Depending on when the decision-making\nphase is applied, multi-objective optimization methods are\nclassified into several classes [40]. A priori methods require\nthe DM to state their preferences in advance, often by assign-\ning weights to different objectives. This can be challenging\nwithout knowing the possibilities and the complex nature of\nthe data involved. On the other hand, a posteriori methods\ninvolve the algorithm generating a representative subset of\nPareto-optimal solutions, from which the DM can make a\nselection. These methods require the DM to choose from\na potentially large pool of solutions, which can be labor-\nintensive or even impractical, especially in high-dimensional\nproblems [41, 42].\nMost of the research on objective reduction concentrates on\nselecting a subset of objectives a priori to streamline the opti-\nmization process while preserving Pareto optimal solutions as\nmuch as possible. Early proposals [31, 43] imposed stringent\nassumptions about the problem structure that are impractical\nfor real-world problems. More recent approaches [6, 8] com-\npromise on exactly identifying the correct subset of objectives\nand capturing the entire Pareto front to improve applicability.\nVarious methodologies aim to consolidate similar objectives\ninto a single one. For example, harmonic levels [44] and\naggregation trees [45] are used to identify objectives that\nimprove together without causing detriment to each other.\nAggregation trees, in particular, are utilized a posteriori to aid\nin the decision-making process. Principal component analysis\n(PCA) is also used to recognize correlated objectives that can\nbe combined into one, either a posteriori to facilitate decision\nmaking [46] or during the optimization process to improve\ncomputational efficiency [47]. However, Costa and Oliveira\n[48] demonstrated that objectives considered redundant by\nPCA might still be \"informative\u201d, meaning that they contain\ntrade-off information that could be lost if excluded."}, {"title": "IV. METHODS", "content": "This section outlines the methodology used in our study,\nstarting with an overview of the detection of hidden and\nirrelevant objectives as proposed in [13]. Detailed formulations\nand discussions are available in the original study. We then\nelaborate on the modifications introduced to simulate and\nmanage dynamic changes in the DM's preferences.\n\nThe previous study used the BCEMOA Algorithm, as in-\ntroduced in [61], and enhanced it with Hidden and Irrelevant\nObjective Detection (BCEMOA-HD). The algorithm is based\non NSGA-II and involves several key steps:\n1) Initialization and Population Evolution: The algorithm\ncommenced with an initial population of randomly gener-\nated solutions, which are then evolved using the NSGA-II\nalgorithm for a predefined number of generations (gen1).\n2) Interaction with the DM: At each interaction step, a\nsubset of solutions with size Nexa was selected and pre-\nsented to the DM. The DM ranked these solutions based"}, {"title": "V. EXPERIMENTAL SETUP", "content": "We conduct a comprehensive set of experiments to eval-\nuate the performance of the algorithm concerning several\nkey aspects, including the detection of hidden and irrelevant\nobjectives, handling the dynamic nature of DM's preferences,\nexamining the effects of different levels of preference changes,\nmanaging potential changes in relevant objectives through\nthe proposed noise disturbance, and assessing the impact of\nobjective reduction. To achieve this, we include experiments\non various benchmark problems with different dimensions and\nlevels of difficulty.\nWe utilize two renowned numerical benchmark problem\nsets to evaluate our method: multi-objective NK landscape\nproblems with correlated objectives (pMNK) [62] and DTLZ\nproblems [63], considering cases with m \u2208 4,10,20 objec-\ntives.\nThe pMNK problems enable us to analyze how the cor-\nrelations among the objectives and the smoothness of the\nlandscape affect the performance of the proposed method.\nWe examine pMNK instances with varying correlation values\namong objectives (p \u2208 0,0.9), adhering to the constraint\np \u2265 \u22121/(m - 1) [62]. The dimension of the solution space\nis determined by n = (round(m/10) + 1) * 10 [13]. We\nalso explore different values for the parameter K, which\ndictates landscape smoothness: K \u2208 1,8 for problems with\n4 objectives and K \u2208 1,15 for many-objective problems (10\nand 20 objectives), ensuring K < n [62]. Higher values of K\ncorrespond to more rugged fitness landscapes. The variable n\nis fixed at 10 for m = 4, 20 for m = 10, and 30 for m = 20\nin pMNK problems.\nAdhering to the original BCEMOA experiments [61] and\nstudies on hidden objectives and objective reduction [13, 64],\nwe focus on DTLZ1, DTLZ2, and DTLZ7 from the DTLZ test"}, {"title": "VI. EXPERIMENTAL RESULTS", "content": "The results section provides a detailed analysis of the exper-\niments conducted to evaluate the proposed dynamic approach\nfor detecting hidden and irrelevant objectives in iEMOAs. The\nanalysis focuses on several key aspects, including the effect of\ndifferent detection methods, the impact of noise addition, and\nthe behavior of the algorithm under varying preference change\nintensities. The results are detailed through a series of figures\nand tables, discussed in this section. The reported p-values are\nobtained from ANOVA tests conducted at a significance level\nof 0.05 to assess statistical significance."}]}