{"title": "LEARNING PHASE-SPACE FLOWS USING TIME-DISCRETE\nIMPLICIT RUNGE-KUTTA PINNS", "authors": ["\u00c1lvaro Fern\u00e1ndez Corral", "Nicol\u00e1s Mendoza", "Armin Iske", "Andrey Yachmenev", "Jochen K\u00fcpper"], "abstract": "We present a computational framework for obtaining multidimensional phase-space solutions of\nsystems of non-linear coupled differential equations, using high-order implicit Runge-Kutta Physics-\nInformed Neural Networks (IRK-PINNs) schemes. Building upon foundational work originally\nsolving differential equations for fields depending on coordinates [J. Comput. Phys. 378, 686 (2019)],\nwe adapt the scheme to a context where the coordinates are treated as functions. This modification\nenables us to efficiently solve equations of motion for a particle in an external field. Our scheme is\nparticularly useful for explicitly time-independent and periodic fields. We apply this approach to\nsuccessfully solve the equations of motion for a mass particle placed in a central force field and a\ncharged particle in a periodic electric field.", "sections": [{"title": "1 Introduction", "content": "Physics-Informed Neural Networks (PINNs) have emerged as a prominent and dynamic area of research for solving\ndifferential equations [1, 2], for example, for modeling the physics of fluid dynamics [3-5] or quantum mechanics [6].\nUnlike traditional neural networks, that learn solely from data, PINNs use both data and physical equations to guide the\nlearning process [7-9].\nPINNs can be effectively employed using continuous and discrete representations of time. The time-continuous\napproach uses space and time variables as inputs, and learn to satisfy the differential equations across the entire domain\nof interest. This can be impractical without data distributed across multiple time slices. In addition, time-continuous\nPINNs also encounter difficulties with high-frequency oscillations and stiff problems, lacking a clear strategy to deal\nwith them. On the other hand, the discrete-time PINNs learn to model changes within a fixed discrete time step, utilizing\nonly spatial information from a single time slice. This approach improves the accuracy in solving stiff problems [10] by\nleveraging the A-stability of implicit Runge-Kutta (IRK) methods [11]. This is especially significant for tackling the\nstiff problems prevalent in particle trajectory simulations and Differential Algebraic Equations (DAEs), known for their\ninherent infinite stiffness [11, 12].\nIn this paper, we extend the discrete-time IRK-PINN scheme [1] by generalizing it to a larger number of dimensions\nin both input variables and output quantities. Importantly, we have adapted this approach to develop a new efficient\nnumerical scheme tailored to finding phase-space flows of classical particle trajectories, described by second-order\ndifferential equations of motions. The new algorithm enables the simultaneous learning of all possible trajectories\nwithin the specified phase-space and is particularly suited for explicitly time-independent and time-periodic forces."}, {"title": "2 Phase-space flows with IRK-PINNS", "content": "In applications to physics problems, the IRK-PINN method was primarily applied to functions $u : \\mathbb{R}^{1+d} \\rightarrow \\mathbb{R}^{m}$ which\nrepresent background \u201cfields\u201d of the system, such as the temperature, pressure, velocity flow, heat convection, etc., see\nAppendix A for details. The literature on applying PINN-based IRK schemes to particle trajectory analysis in physical\nsystems is limited, with the exception of work focusing on first-order differential equations [13]. We are interested in\nsolving differential equations of the general form\n$F(x, \\dot{x}, \\ddot{x}, ..., t) = 0$,\nwhich encompass, for example, Newton's equation, expressed as $\\ddot{x} = f(x,\\dot{x}, t)$. Our goal is to adapt and apply\nthe IRK-PINNs scheme to effectively compute particle flows $x(t)$ resulting from a force $f(x, \\dot{x}, t)$. We begin by\ntransforming the second-order Newton-type differential equation into a system of first-order differential equations\nusing the 2d-dimensional phase-space coordinates, denoted as $\\bm{x} = (x, \\dot{x})$, with the dimensionality $d$ of the vector $x$.\nWe define our function of interest as $u(t, x_i) = \\Xi_i(t)$, with $\\Xi_i: \\mathbb{R} \\rightarrow \\mathbb{R}^{2d}$ representing the flow function. This flow\nfunction defines the trajectory of any point in phase-space \u2013 a one parameter curve in our phase-space manifold \u2013 that\nsatisfies the condition $\\Xi_i(t_n) = x_i$. By adhering to the equations of motions, this condition ensures a unique solution.\nIndeed, since the value of $u(t_n, x_i)$ at the initial time $t_n$ is $u_n(x_i) = x_i$, we can determine the phase-space values at\ntime $t_{n+1}$ by employing the IRK-PINNs time propagation method. By applying the IRK scheme, see (5) in Appendix A,\nusing a fully connected feedforward neural network (FNN) also known as a multilayer perceptron (MLP), to the general\ntrajectory equation (1), we thus determine the trajectories that satisfy the following set of differential equations\n$0 = N \\begin{bmatrix} \\Xi \\\\ \\dot{\\Xi} \\end{bmatrix} + \\begin{bmatrix} \\dot{\\Xi} \\\\ \\ddot{\\Xi} \\end{bmatrix} =  \\begin{bmatrix} \\dot{\\Xi} \\\\ f(\\Xi, \\dot{\\Xi}, t) \\end{bmatrix}$,\nAny additional boundary conditions that may be essential for the well-defined nature of the problem can also be\naccommodated.\nThe algorithm's strength lies in its ability to predict the future state of every point in the phase-space at time $t_{n+1}$ by\nlearning from only a limited sample of phase-space data at the initial time $t_n$. In addition, as a high-order IRK algorithm,\nit is well suited to solve stiff problems, enhancing computational efficiency in the propagation of numerous trajectories.\nMoreover, this algorithm is particularly effective for forces that are explicitly time-independent and/or periodic in time.\nIf the force doesn't explicitly change over time and only relies on the position or velocity of the particle, both being\nimplicitly time-dependent vector fields, the neural network can effectively predict the trajectories by learning from a\ntraining set in the phase-space. For periodic forces, we impose the time-propagation step size to match the period of\nthe force $\\Delta t := T$, so that the neural network output $\\Xi(t_{n+1})$ would reside on a phase-space manifold identical to the\ninitial one at $t_n$. The periodic nature of the force is essential, as the phase-space manifold is entirely dependent on the\nforce governing the particles' motions, necessitating that $f(x, t_n + \\Delta t)$ remains equivalent to $f(x, t_n)$. In both cases, or\na combination, the phase-space manifold remains unchanged after a single time step propagation. Consequently, to\npredict trajectories for subsequent time slices, the IRK-PINN algorithm can be recurrently applied after training."}, {"title": "3 Results", "content": ""}, {"title": "3.1 Keplerian orbits", "content": "A massive body under the action of a central potential moves according to Newton's equation of gravity. The trajectories\nthat orbiting objects follow are called Keplerian orbits. The analytical solution of N-body problems is complicated due\nto the implicit time-dependency of the force $F \\sim 1/r^{2}; r(t)$, arising from the varying distances between different objects\n$r(t)$. For this reason, low-order IRK schemes with small time stepping were used to propagate these systems [14].\nFollowing the discussion in the previous section, our phase-space flows approach offers an efficient alternative for\npropagating these explicitly time-independent systems. This is achieved by recurrently applying the neural network,\nrequiring only a single training session of the IRK-PINN and thus eliminating the need for additional approximations.\nWe focus on central forces, which conserve angular momentum, leading to the confinement of trajectories within a\ntwo-dimensional plane defined by the initial momentum and the radial vector [15]. Initially, our efforts were directed at"}, {"title": "3.2 Charged particle under the action of a sinusoidal laser", "content": "In this example, we consider the motion of a charged particle under the influence of a periodic external electric field, i. e.,\na laser field. The force exerted on a particle with charge $q$ by an external field $E(x, t)$ is given by $F(x, t) = qE(x, t)$.\nAs in the previous example, we continue to work within a 4-dimensional phase space defined by $(x, \\dot{x}) \\in \\Omega = \\mathbb{R}^2 \\times \\mathbb{R}^2$,\nalso corresponding to a 4-dimensional output space.\nFor simplicity, we assume that the wavelength of the laser\nfield is much larger than the scale of particle movement.\nThe electric field, characterised by an angular frequency\n$\\omega$ and incident at an angle $\\alpha$ relative to the x-axis, is\nrepresented by the function $E(x, t) = (E_x(t), E_y(t)) =$\n$(A \\cos(\\omega t) \\cos(\\alpha), A \\cos(\\omega t) \\sin(\\alpha))$, where $A$ denotes\nfield's amplitude. Choosing the unit system $M = q = 1$,\nthe differential equation of motion can be expressed as\n$N[x] = \\begin{bmatrix} \\ddot{x} \\\\ \\ddot{y} \\end{bmatrix} = \\begin{bmatrix} A \\cos(\\omega t) \\cos(\\alpha) \\\\ A \\cos(\\omega t) \\sin(\\alpha) \\end{bmatrix}$,\nThis particular form of the laser field is chosen for its\nanalytical solvability, substantive complexity, and pe-\nriodic behaviour in time. Given any initial conditions\n$(x_0, y_0, \\dot{x}_0, \\dot{y}_0)$ at time $t_0$, the analytical solution can be\nreadily obtained. We examine the system with a laser of\nperiod $T = 1 := \\Delta t$, amplitude $A = 10$ and incident\nangle $\\alpha = 0.5$. To benchmark our IRK-PINNs implemen-\ntation, we compare its results for different Runge-Kutta\norders with the analytical solution. The results of the\nsimulations and the details of the neural networks used\nare presented in FIG. 2. These results were obtained for\nmultiple periods of the electric field by recurrently apply-\ning the neural network, which was trained only once, for\nthe first period, using a set of training points distributed\nacross a subset of the phase-space. For the purpose of\nillustration and avoiding overfitting, a validation set con-\ntained in a different subset of the phase-space was used\nto generate the plots."}, {"title": "4 Conclusions", "content": "We introduced a versatile algorithm designed to effectively solve a broad range of differential equations. The algorithm\nwas validated by generating accurate results for both functional PDEs and equations of motion. Notably, the application\nof PINNs as a propagator for explicitly time-independent and periodic forces represents a significant advancement over\nconventional low-order IRK methods.\nFurther work should focus on addressing the problem of divergent trajectories, particularly in cases like Keplerian\norbits under a Coulomb $ \\sim 1/|x|$ potential. Overcoming this divergences would particularly enhance the algorithm's\nutility in solving stiff dynamical systems, such as the N-body problem [14] and the dynamics of charged particles in\ntime-independent or periodic external fields [17, 18]."}, {"title": "A High-order implicit Runge-Kutta scheme", "content": "We start by examining a vector-valued function $u : \\Sigma \\rightarrow \\mathbb{R}^{m}$, which is defined over spacetime vectors $(t, x) \\in \\Sigma :=$\n$\\mathbb{R} \\times \\Omega \\subset \\mathbb{R}^{1+d}$ in the domain formed by a combination of 1-dimensional time and d-dimensional space. This function\nis defined to be the solution of a set of non-linear coupled differential equations, represented as $\\partial_t u + N[u] = 0, \\forall (t, x)$\nin $\\Omega$. Additionally, we considered the possibility of incorporating boundary conditions, denoted as $B_\\alpha[u(\\Omega)] = 0$,\nwhich could depend on the derivatives of $u$ at the boundary.\nWe sought to develop an algorithm that utilizes the dataset $\\{x_k, u(t_n, x_k)\\}_{k=1}^{N}$ at a specific time slice $t_n$ and the\ndifferential equations representing the time evolution to accurately predict $u(t_{n+1}, x)$ at the next time slice $t_{n+1}$. To\ndescribe the time propagation from $t_n$ to $t_{n+1}$, we introduced an IRK scheme of $q$-th order, defined by a set of coupled\nequations\n$u_{n+c_i} = u_n - \\Delta t \\sum_{j=1}^{q} a_{ij}N[u_{n+c_j}] \\quad \\forall i \\in \\{1,...,q\\}$,\n$u_{n+1} = u_n - \\Delta t \\sum_{j=1}^{q} b_{j}N[u_{n+c_j}]$,\nwhere $u_{n+c_i} (x) := u(t_n + c_i\\Delta t, x)$, $\\Delta t = t_{n+1} - t_n$ and $a_{ij}$, $b_j$, and $c_i$ are the Butcher-tableau coefficients for a\nchosen IRK order $q$. The computation of the Butcher tableau involves expanding the solution into a Taylor series and\nmatching the coefficients to the actual solution up to the desired order of accuracy. The choice of this coefficients is\nnot unique, and it specifies the particular IRK method. We chose the Gauss-Legendre Runge-Kutta method, which is\nA-stable for all orders [23], to find the coefficients throughout our implementation. However, other methods, such as the\nLobatto [24], the Radau [25], or the diagonally implicit Runge-Kutta methods [26], result in different accuracy, stability,\nand efficiency properties. Testing the pros and cons of using different Butcher-tableau coefficients in applications with\nIRK-PINNs is beyond the scope of this manuscript, although it should be further explored in the future.\nThe theoretical analysis of the IRK algorithm suggests that the deviation from the exact result scales as $O(\\Delta t^{2q})$ [23].\nAlthough it may initially appear that the error would grow with increasing $q$ for time steps $\\Delta t > 1$, it is important to\nrecognize that this error is dimensionful and requires a constant to render it dimensionless for proper interpretation.\nFor a chosen IRK order $q$, we place a neural network prior on all intermediate calculations and the final output\n$U := (u_{n+c_1}, ..., u_{n+c_q}, u_{n+1})$.\nWe observe that $U(x) \\in \\mathbb{R}^{m\\times(q+1)}$ can be conceptualized as an $m \\times (q + 1)$ matrix, where $m$ is the output dimension\nof $u$ which is not necessarily equal 1. Consequently, we employ an MLP denoted by $U^\\theta : \\mathbb{R}^{d} \\rightarrow \\mathbb{R}^{m\\times(q+1)}$, to\nclosely approximate the desired function $U$. We define $u^\\theta$ in a manner analogous to (6) as the parameter-dependent\napproximation. Subsequently, we define a set of parameter-dependent quantities to be used in the loss function as\n$k_i^\\theta = u_{n+c_i}^\\theta + \\Delta t \\sum_{j=1}^{q} a_{ij}N[u_{n+c_j}^\\theta] \\quad \\forall i \\in \\{1,...,q\\}$\n$k_{q+1}^\\theta = u_{n+1}^\\theta + \\Delta t \\sum_{j=1}^{q} b_{j}N[u_{n+c_j}^\\theta]$.\nComparing (7) with (5), it is evident that if $U^\\theta$ effectively approximates $U$, then the earlier definition implies\n$k_i^\\theta \\approx u_n \\quad \\forall i \\in \\{1, ..., q + 1\\}$. Using this relationship, we can express the loss function as\n$L_N(\\theta, \\{x_k\\}_{k=1}^{N}) = \\frac{1}{N} \\sum_{k=1}^{N} \\sum_{i=1}^{q+1} ||k_i^\\theta(x_k) - u_i^\\theta(x_k)||^2$,\nwhere $\\{x_k\\}_{k=1}^{N}$ is a set of spatial points randomly distributed in the phase-space $\\Omega$.\nFurthermore, if the differential equations include $A$ boundary conditions of the type $B_\\alpha[u(\\Omega)] = 0$, an additional term\ncan be added to the loss function\n$L_B(\\theta, \\{x_b\\}_{b=1}^{B}) = \\frac{1}{B} \\sum_{b=1}^{B} \\sum_{\\alpha=1}^{A} ||B_\\alpha[u(x_b)]||^2$,"}, {"title": "B Methodology", "content": "We implemented the IRK-PINNs using the JAX [27] and Flax [28] Python libraries and optimized the weights of the\nPINN by initially approaching the minimum using Optax [29] with the Adam first-order optimizer [30] and then refined\nthe result by switching to the second-order optimization L-BFGS-B [31] available in the Jaxopt library [32]. For the\nPINN, we employed a fully-connected dense MLP with different number and structure of hidden layers and types of\nactivation functions, depending on the problem addressed. We found that $SiLU(x) = \\frac{x}{1+exp(-x)}$ and bipolar sigmoid\n$f(x) = \\frac{exp(x)-1}{exp(x)+1}$ [33] activation functions work best for the problems considered in this study.\nFor benchmarking, we obtained accurate results using the low-order Runge-Kutta approach from the Diffrax library [22],\nwhich provides various implicit and explicit Runge-Kutta methods of different orders.\nOur developed model is highly versatile and easy to use. Using just one class type, it successfully handled a range of\napplications, some of which are highlighted in Appendix C."}, {"title": "C Additional results", "content": "In this section, we present the performance of the IRK-PINNs scheme applied to systems that handle fields $u : \\mathbb{R}^{1+d} \\rightarrow$\n$\\mathbb{R}^{m}$, similar to those investigated previously [1]. These differ conceptually from a particle's equations of motion, which\ndeal with coordinates $(x, \\dot{x}) : \\mathbb{R} \\rightarrow \\mathbb{R}^{2d}$, in the manner that fields do not have to follow a direct relation with the\nphase-space of the system.\nIn the following, we selected a number of functional PDEs with different input/output dimensions to illustrate the\nversatility of the algorithm."}, {"title": "C.1 Heat Equation in a 2D Plate", "content": "We deal with a system with a 2-dimensional input: the heat equation over a surface. This equation describes the\nevolution of a scalar field $T : \\mathbb{R}^{2+1} \\rightarrow \\mathbb{R}$, representing the temperature of a 2D system in time. Using our formalism,\nthe heat equation is given by\n$N[T] = -c^2\\nabla^2T$,\nwhere c is the thermal diffusivity, a constant that measures the rate of heat transfer inside the material.\nWe will deal with the system shown in [34], which is a two dimensional sheet $(x, y) \\in \\Omega = [0, 2]^2$ with $c = 1/3$ and\nperiodic boundary conditions for the temperature given by $T(t, 0, y) = T(t, 2, y) = T(t, x, 0) = T(t, x, 2) = 0$. We\nwill also impose the initial condition of a heated lower half plane $T(0, x, y) = 50(1 - \\Theta(y - 1))$, with $\\Theta$ being the unit\n(Heaviside) step function. In essence, this represents a 2 \u00d7 2 square that is initially heated and in contact with a cold\nresevoir at its boundary with $T = 0$. The solution to this equation is given by\n$T(t,x,y) = \\sum_{m,n=1}^{\\infty} \\frac{200}{\\pi^2} \\frac{(1 + (-1)^{m+1})(1 - cos(\\frac{n \\pi}{2}))}{mn}  \\cdot sin(\\frac{m\\pi x}{2}) sin(\\frac{n\\pi y}{2}) e^{-\\frac{c^2\\pi^2}{4}(m^2+n^2)t}$\nThe results of our IRK-PINN prediction, compared to (12) and the description of the used neural network, are shown in\nFIG. 3. The IRK-PINN is able to learn the solution of the heat equation, even for relatively small neural network and\nsample size."}, {"title": "C.2 Incompressible Navier-Stokes equation: Taylor-Green vortices", "content": "The Navier-Stokes Equations describe the motion of Newtonian fluids. In these equations, the variation of the quantity\nof fluid and its velocity are studied, usually in a compact or periodic domain. The pressure, temperature and density\n$\\frac{1}{\\rho} \\frac{\\partial p}{\\partial x} - \\nu(\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2})$\n$N[v] = u \\frac{\\partial v}{\\partial x} + v \\frac{\\partial v}{\\partial y} + \\frac{1}{\\rho} \\frac{\\partial p}{\\partial y} - \\nu(\\frac{\\partial^2 v}{\\partial x^2} + \\frac{\\partial^2 v}{\\partial y^2})$\nwhere $u(t, x, y)$ and $v(t, x, y)$ are respectively the x and y components of the velocity fields of the fluid, $\\nu$ is the\nviscosity, $\\rho$ is the mass density, and $p(t, x, y)$ is the pressure of the fluid. To account for the continuity equation for\nthese velocities, which is $\\frac{\\partial u}{\\partial x} + \\frac{\\partial v}{\\partial y} = 0$, we treat it as a boundary condition and add it to our algorithm as an extra\nterm to the loss function."}, {"title": "D Data availability", "content": "The code and data used of all example simulations is available at https://gitlab.desy.de/CMI/CMI-public/\nrunge-kutta-pinn."}]}