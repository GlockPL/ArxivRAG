{"title": "Do Large Language Models Understand Verbal Indicators of Romantic Attraction?", "authors": ["Sandra C. Matz", "Heinrich Peters", "Paul W. Eastwick", "Moran Cerf", "Eli J. Finkel"], "abstract": "What makes people \u201cclick\u201d on a first date and become mutually attracted to one another? While understanding and predicting the dynamics of romantic interactions used to be exclusive to human judgment, we show that Large Language Models (LLMs) can detect romantic attraction during brief getting-to-know-you interactions. Examining data from 964 speed dates, we show that ChatGPT (and Claude 3) can predict both objective and subjective indicators of speed dating success (r=0.12-0.23). ChatGPT's predictions of actual matching (i.e., the exchange of contact information) were not only on par with those of human judges who had access to the same information but incremental to speed daters' own predictions. While some of the variance in ChatGPT's predictions can be explained by common content dimensions \u2013 such as the valence of the conversations \u2013 the fact that there remains a substantial proportion of unexplained variance suggests that ChatGPT also picks up on conversational dynamics. In addition, ChatGPT's judgments showed substantial overlap with those made by the human observers (mean r=0.29), highlighting similarities in their representation of romantic attraction that is, partially, independent of accuracy.", "sections": [{"title": "Introduction", "content": "The dynamics of human interaction have long been a subject of interest for researchers seeking to understand romantic attraction (Berscheid & Walster, 1969). Can we predict whether two people are going to say \"yes\" to each other after an initial encounter? And what factors predict the elusive \"clicking\" that sparks interest between two people and prompts the possibility of a partnership?\nThe ability to analyze and interpret interpersonal dynamics has historically been confined to human perception, with research showing that observers can accurately predict romantic interest (Eastwick et al., 2010; Place et al., 2012) and long-term relationship success (Gottman et al., 1998). Important language-based predictors of these outcomes are related to the smoothness of conversational interactions (Eastwick et al., 2010), language style matching (Ireland et al., 2011), and active listening (Gottman et al., 1998). While past research has heavily relied on human judgments, rapid advances in computers' capacity to represent unstructured data\u2014including text and (moving) images\u2014have made them viable contestants with respect to understanding conversational dynamics and predicting the success of initial romantic encounters (Huang et al., 2017; McFarland et al., 2013).\nThe most notable of these technological advances is the emergence of Large Language Models (LLMs; Anthropic, 2023; Gemini Team et al., 2023; OpenAI, 2023; Touvron et al., 2023; Vaswani et al., 2017). LLMs are trained on vast corpora of textual data to learn statistical patterns in language (Vaswani et al., 2017) and produce novel text that is often indistinguishable from that created by humans (Jakesch et al., 2023). By using probabilistic estimates for which words (or groups of words) are most likely to follow a particular prompt, LLMs can answer open-ended questions, summarize content, or translate text from one language to another.\nHowever, LLMs are capable of far more than merely generating text. As a growing body of research suggests, they possess human-like abilities to \u201cunderstand\u201d language and solve a wide range of tasks they were never explicitly trained on (Radford et al., 2019). For example, LLMs can exhibit properties resembling theory of mind (Kosinski, 2023) or predict personality traits from social media posts (Peters & Matz, 2024) and free-form user interactions (Peters et al., 2024) with similar levels of accuracy as supervised machine learning models. In addition, they can generate persuasive content that is both personalized and more persuasive than that created by humans (Bai et al., 2023; Matz et al., 2024).\nThe current study is the first to investigate whether LLMs can detect romantic attraction during brief getting-to-know-you interactions (speed-dates). The speed-dating context offers an interesting testing ground for the power of LLMs for multiple reasons (Finkel et al., 2007). First, speed dates are highly structured and time-limited in format, allowing for a direct comparison across multiple dyads. Second, the brevity of interactions makes our test a conservative estimate of LLMs' capacity to interpret the content of social interactions."}, {"title": "Results", "content": "We analyzed 1,039 speed dates involving 187 undergraduate students (93 women and 94 men; age = 19.6\u00b01.2 years old) who attended one of eight speed dating events at a large Midwestern University in 2007. Participants were recruited via flyers and e-mails and engaged in approximately 12 speed dates, each lasting four minutes and consisting of a man and a woman (see Fig. 1 for an overview of the Study Design and Appendix A in the SI for recruitment materials). Immediately following each speed date, participants evaluated the experience (see the Methods section for more details and refer to Finkel et al., 2007 for the original publication of the dataset)."}, {"title": "Can ChatGPT predict speed dating outcomes and experiences?", "content": "Our primary analysis tested whether LLMs can predict the objective matching outcome, comparing the accuracy of ChatGPT's predictions to those made by speed-dating participants (baseline) and the human judges (Fig. 2A) With a correlation of r=0.12 (p<.001), ChatGPT performed on par with the human raters who had access to the same information (i.e., transcripts only; r=0.13, p=.003), but both were outperformed by the human coders who could also draw on the non-verbal cues observable in the video recordings (r=0.31, p< .001).\nNotably, ChatGPT successfully predicted matching above and beyond participants' self-reported intentions (B=0.19, SE=0.09, z=2.17, p=.030). In contrast, we did not observe incremental predictive power for the ratings of the human judges who had access to transcripts only (B=0.03, SE=0.16, z=0.19, p=0.853). This suggests that ChatGPT observed unique variance that was neither accessible to the speed-dating participants nor the coders who evaluated the same transcripts (note that human coders in the video condition did provide incremental predictive power: B=0.46, SE=0.10, z=4.62, p<.001.).\nNext, we examined the ability of ChatGPT and human judges to predict participants' self-reported outcomes and experiences at the end of the speed-date. ChatGPT predicted participants' ratings with correlations ranging between r = 0.13 to r = 0.23 (all p<.001; Fig. 2B), even after accounting for word count. The correlations were markedly lower than those made by human judges in both conditions (average correlation for observers with access to videos r = 0.46, and transcript only r = 0.33), suggesting that human judges reading the transcripts might be able to better at predicting participants' stated reaction to the speed-date but not their actual commitment to exchanging contact information (actual matching). Notably, the relative levels of accuracy across predicted metrics appeared largely consistent across all judges, with participants' experiences being easier to predict (in particular, whether they had a lot in common) than outcomes."}, {"title": "Which textual features are driving the predictions of ChatGPT?", "content": "To better understand how ChatGPT arrived at its predictions and to test whether the predictions were merely driven by the emotional tone of the conversation (rather than conversational dynamics), we extracted the content of each of the transcripts using LIWC (11). LIWC is a widely used, dictionary-based text analysis tool that categorizes and quantifies psychological, emotional, and cognitive aspects of a document using 117 validated dictionaries.\nFig. 2C displays the ten LIWC dimensions that showed the highest absolute correlations with GPT's predicted likelihood of saying \u201cyes.\u201d The examples suggest that GPT indeed relied on the affective valence of conversations, but also highlight the importance of other dimensions unrelated to emotional valence (e.g., high levels of certitude and a reduced focus on the present). To further support the proposition that ChatGPT did not merely pick up on readily available content features we trained a supervised model predicting ChatGPT's judgments from a linear combination of the 117 LIWC dimensions (see Methods for more details). An out-of-sample validation of the model suggests that LIWC accounted for only ~7% of the variance in ChatGPT's predictions (r=0.27). This suggests that a substantial amount of the variance in the predictions made by ChatGPT cannot be captured by the relatively comprehensive set of content dimensions included in the LIWC dictionaries."}, {"title": "How aligned are ChatGPT's predictions with those of human judges?", "content": "In addition to comparing the predictive accuracies of ChatGPT and human raters, we also investigated the extent to which ChatGPT and human judges relied on similar cues when making their predictions. As the correlations in Fig. 2D show, there was meaningful overlap between the predictions of ChatGPT and the human judges (mean r = 0.29 across all metrics and conditions). The fact that these correlations were higher than those observed with participants' self-reported scores (Fig. 2B) suggests that both ChatGPT and human judges utilize cues that are commonly considered markers of successful interactions but are not empirically associated with actual speed-dating outcomes or experiences. For example, we found that both human raters and ChatGPT consider a positive tone and the expression of positive emotions as strong indicators for a successful match (i.e., high correlations between the predicted matching ratings and the respective LIWC dimensions), even though these dimensions are not strongly associated with actual matching. That is, the correlations between positive emotions and the predicted matching scores of ChatGPT and human raters were r = 0.20 and r = 0.30 respectively, with positive emotions ranking among the top five predictors in both cases. However, positive emotion was only correlated at r = 0.06 with actual matching, ranking number 34 among all 117 predictors. In contrast, references to money, health and family were among the strongest predictors of actual matching (with money showing a negative relationship), but neither ChatGPT nor the human raters considered them important predictors."}, {"title": "Discussion", "content": "Taken together, our findings suggest that LLMs can \u201cinterpret\u201d some of the conversational nuances that lead strangers to \u201cclick\u201d during romantic getting-to-know-you interactions. The accuracies were modest in magnitude (r=0.12-0.23). Yet, when predicting whether two people will eventually exchange contact information, the predictions made by ChatGPT were not only on par with those of human judges who had access to the same information (transcripts) but incremental to participants' own ratings at the end of the speed date. In addition, they were moderately correlated with the predictions made by human raters (r=0.21-0.35), suggesting that LLMs might pick up on the same cues, even if those cues are not necessarily valid (compare to Brunswick's lens model; Brunswik, 1956).\nOur findings contribute to the growing literature capturing the remarkable abilities of LLMs at solving tasks that were previously considered to be the exclusive domain of human agents (e.g., Bai et al., 2023; Kosinski, 2023; Orr\u00f9 et al., 2023; Peters & Matz, 2024). While much of the existing literature has focused on mimicking and interpreting the behavior of individuals, our work expands this literature by highlighting the ability of LLMs to capture social dynamics playing out between multiple individuals. In addition, our work contributes to the literature on relationships and romantic attraction, by showing that the content of conversations alone \u2013 without traditional indicators such as body language, eye contact, tone of voice, or perceived physical attractiveness -- predicts whether two people \u201cclick\u201d when they first meet each other (McFarland et al., 2013). Moreover, from a practical perspective, our work suggests that the labor-intensive process of coding human interactions (e.g., Bakeman & Gottman, 1997), could potentially be automated if the capacities of LLMs continue to improve at the current rate.\nIt has not escaped our notice that our study has a number of important limitations that should be addressed by future research. First, as speed-dates are by definition brief, it is possible that LLMs might yield more accurate judgments when observing longer initial interactions. This is particularly true as speed dates might be rather similar in structure and content and remain more superficial than other types of conversations due to their introductory nature (i.e., most people will start with brief introductions and small talk). Future research should investigate different types of social interactions (e.g. couples' text messages) and explore whether the accuracy of predictions can be improved by analyzing longer text excerpts.\nSecond, our analyses focused exclusively on short-term success metrics, such as self-reported liking or the exchange of contact information. Future research should investigate the ability of LLMs and human judges to predict longer-term success metrics (e.g., the likelihood of entering into a relationship). Third, our study exclusively relied on language models and conversation transcripts, which omit crucial information such as smiles, eye contact, body language, and paralinguistic cues. As generative AI continues expanding in the domains of computer vision and multimodal interfaces (e.g., OpenAI's next generation of ChatGPT, which processes both spoken language and images), future research should test whether artificial agents can reach or even surpass -- the level of accuracy obtained by the human raters with access to the speed dating videos.\nTaken together, our work suggests that LLMs like ChatGPT have the capacity to interpret social dynamics in natural conversations. As we have noted above, we consider our findings a conservative estimate of AI's capacity to understand human interactions and predict that its ability to interpret conversational dynamics on a much more holistic level is poised to increase significantly over the coming years."}, {"title": "Methods", "content": "Participants rated the speed dates using the following five statements: (1) I am likely to say yes to my interaction partner, (2) I really liked my interaction partner, (3) My interaction partner and I seemed to have a lot in common, (4) My interaction partner and I seemed to have similar personalities, and (5) My interaction partner and I had a real connection. We considered the first two statements indicators of speed dating outcomes and the last three as indicators of speed dating experiences. All responses were recorded using a 9-point Likert scale ranging from 1 = Strongly Disagree to 9 = Strongly Agree.\nAll human judges and ChatGPT responded to equivalent statements (see Appendix A in the SI for the full set of questions). For example, we used the following prompt for ChatGPT and human raters (transcript only) to rate the likelihood of saying yes to one another: \u201cOn a scale from 1-9, how likely do you think the interaction partners will say \u201cyes\u201d to each other and exchange contact information?\u201d"}, {"title": "LIWC Modeling", "content": "We randomly selected 50% of the data (training dataset with 501 speed dates) to train a LASSO model (1) that predicts ChatGPT's predicted likelihood of saying yes from a linear combination of the 117 LIWC dimensions. The model parameter lambda was tuned using 10-fold cross-validation. We subsequently applied the model to the remaining 50% of the data (testing dataset with 463 speed dates). The correlation between the predictions made by LIWC and the actual ChatGPT ratings of r = 0.39 (variance explained of 15%) is based on the observations in the testing data only."}]}