{"title": "AssemblyComplete: 3D Combinatorial Construction with Deep Reinforcement Learning", "authors": ["Alan Chen", "Changliu Liu"], "abstract": "A critical goal in robotics and autonomy is to teach robots to adapt to real-world collaborative tasks, particularly in automatic assembly. The ability of a robot to understand the original intent of an incomplete assembly and complete missing features without human instruction is valuable but challenging. This paper introduces 3D combinatorial assembly completion, which is demonstrated using combinatorial unit primitives (i.e., Lego bricks). Combinatorial assembly is challenging due to the possible assembly combinations and complex physical constraints (e.g., no brick collisions, structure stability, inventory constraints, etc.). To address these challenges, we propose a two-part deep reinforcement learning (DRL) framework that tackles teaching the robot to understand the objective of an incomplete assembly and learning a construction policy to complete the assembly. The robot queries a stable object library to facilitate assembly inference and guide learning. In addition to the robot policy, an action mask is developed to rule out invalid actions that violate physical constraints for object-orientated construction. We demonstrate the proposed framework's feasibility and robustness in a variety of assembly scenarios in which the robot satisfies real-life assembly with respect to both solution and runtime quality. Furthermore, results demonstrate that the proposed framework effectively infers and assembles incomplete structures for unseen and unique object types.", "sections": [{"title": "I. INTRODUCTION", "content": "Recent advancements in robotics and computer vision research have enabled robots to learn valuable skills for collaborative manufacturing tasks, such as learning from human demonstration [1], [2], collaborative robots [3], [4], and assembly sequence planning [5], [6], [7], which are important in achieving a fully autonomous assembly line.\n3D assembly completion remains relatively unexplored, yet it is essential for robot autonomy and collaboration. If given the capability to infer and finish incomplete 3D assemblies, robots can master human-robot collaboration. For instance, consider a scenario where a human is assembling a chair but cannot finish it due to limitations. In this case, a robot could take over, analyze the incomplete assembly, and finish it without human guidance. This skill extends to enhancing the efficiency of multi-robot systems as well, as it allows robots to be more flexible and access complicated skills like streamlined collaboration with other robots.\nIn this paper, we introduce the problem of 3D combinatorial assembly completion. This task is challenging as the robot's goal is to finish the incomplete assembly without prior knowledge about the structure's end goal. Moreover,"}, {"title": "II. RELATED WORKS", "content": "A. 3D Shape Completion\n3D shape completion is a deeply studied field in computer vision and robotics as it aims to reconstruct incomplete objects by filling in missing features. However, it is chal- lenging to process and understand 3D geometric shapes. Early works [13], [14] relied heavily on 3D geometric methods like symmetry and template matching but were limited when dealing with complex shapes and noisy data. Recent advancements have introduced deep-learning and generative-based techniques for improved accuracy of re- constructed shapes. [15] introduces a point set generation network that outperformed previous state-of-the-art methods for 3D reconstruction. Generative methods [16], [17], [18], like generative adversarial networks and variational auto- encoders, are favored in shape reconstruction. Recent works have also explored a diffusion-based approach [19], [20], which progressively refines shape details and showcases the effectiveness of text-to-image models. In relation to these works, we use a similar 3D PCD representation to model features and geometry. However, our work differs as we aim to reconstruct 3D shapes in a dynamic environment where we consider real-world assembly and physical constraints, as shown in Fig. 2.\nB. 3D Assembly Completion\n3D assembly completion aims to reconstruct objects while considering constraints that model manufacturing and assem- bly line applications. Current assembly completion works tackle in-process part assembly. Similar to shape completion, generative and encoder methods are favored solutions for the 3D part assembly task. For example, Wu et al. [21] developed PQ-NET, a generative network for 3D shapes via sequential part assembly. Zhang et al. [22] focus on 3D part assembly generation using an instance-encoded transformer. Wang et al. [9] proposed FiT, a transformer approach to complete incomplete part assemblies. However, these works tackle part assembly where the action space is very limited. In comparison, we formulate 3D assembly completion as a combinatorial assembly task where unit primitives can create up to billions of possible sequences in a simple 48x48 workspace. [23] uses graph transformers, Legos, and an input target structure graph to predict a sequence for in-process assembly but fails in medium-length sequences because of the vast combinations. DRL proves to be more effective in combinatorial works [12], [24]. However, [12] relies on a 2D image/graph and demonstrates surface-level assemblies. Previous work [24] tackles combinatorial assembly sequence planning (ASP) which is much different from combinatorial assembly completion. The goal of the previous work is to sequentially assemble a stable, pre-defined target voxel with a given inventory. In this paper, the goal is to take an in-process assembly, understand what is being built, and finish it accordingly. Since assembly completion is fairly similar, we create a similar definition to [24] with the inventory constraint and action definition. However, because of the"}, {"title": "III. PROBLEM FORMULATION", "content": "Given an incomplete 3D structure $V_{cur}$, the overall goal is to complete the incomplete structure using $I$, a dictionary that tracks an inventory of available bricks.\nFirst, we formulate intention inference as an optimization problem where the robot must infer by matching the incom- plete structure with the most similar object from an object library of complete stable assemblies to obtain $V_{tar}$, a 3D reference $h \\times w \\times d$ binary matrix.\nThen we formulate assembly completion as a DRL prob- lem using the Markov Decision Process (MDP), denoted as $M = (S, A, P, R)$. In this MDP, the state representation is defined as $S = (V_{cur}, V_{tar}, I)$, while $A$ denotes the set of actions, each placing a brick of unique location, orientation, and size in a 3D space. The transition function $P: S \\times A \\rightarrow S$ defines the next state given the current state and action, and the reward function $R : S \\times A \\rightarrow \\mathbb{R}$ provides a reward based on the agent's selected action. The discount factor $\\gamma \\in [0,1)$ accounts for future rewards. The objective is for the agent to learn a policy $\\pi(a_t | s_t)$ that maximizes the expected cumulative discounted reward $J(\\pi) = E[\\sum_{t=0}^{T} \\gamma^t r_t]$, where $r_t$ is the reward at timestep $t$."}, {"title": "IV. METHOD", "content": "The proposed framework in Fig. 1 consists of two major components: 1) inferring the intent of and matching the incomplete structure using 3D PCD and 2) completing the assembly using DRL. First, we model the incomplete struc- ture as PCD and apply feature registration and a similarity search on an object library to identify a matched assembly. We scale and transform the matched assembly to guide the incomplete assembly. Second, we train a DRL agent to un- derstand the incomplete structure and sequentially assemble unit primitives under constraints to finish the structure with features similar to those of the matched assembly target.\nA. Inference and Matching Step\nIn this section, we explain how we teach the robot to infer the incomplete assembly's end goal and process it to be used for DRL. We convert the incomplete assembly voxel into a 3D PCD and query against an object library to find the best match to determine the intent of the incomplete assembly. Refer to parts (a)&(b) in Fig. 1.\n1) Point Cloud Scaling: To begin, we assume that the 3D incomplete assembly cannot be scaled or rotated, as it has al- ready been physically constructed. In the real world, objects have distinct scales and rotations, making it impractical to constrain all structures to a preset configuration. Therefore, we adjust the target PCD to fit the incomplete assembly, focusing on object features for comparison.\nWe use Principal Component Analysis (PCA) to scale the target structure to fit the incomplete structure.\n$P_{scaled} = P_2 \\cdot max(\\frac{\\sqrt{\\sigma_{1,1}}}{\\sqrt{\\sigma_{2,1}}}, \\frac{\\sqrt{\\sigma_{1,2}}}{\\sqrt{\\sigma_{2,2}}}, \\frac{\\sigma_{1,3}}{\\sigma_{2,3}})$ (1)\nHere, $\\sigma_{1,i}$ and $\\sigma_{2,i}$ represent the first and second structures' explained variance along the $i$-th principal component, re- spectively. The explained variance indicates how much of the data's variability is captured by each principal component.\n2) Point Cloud Registration: After scaling the target PCD, we need to align the incomplete and target structures through their geometric features. However, this is challenging as the incomplete structures may have entirely missing fea- tures. Therefore, feature descriptors are employed as local descriptors for the object's geometric features. FPFH encodes information about neighbor nodes and direct pairs between query points, which is crucial for feature matching.\nFor initial alignment, RANSAC is used to align the incom- plete and target structures. Then, ICP is used to refine the alignment across multiple iterations, progressively reducing the distance threshold to achieve precision. The resulting transformation matrix is then applied to the target PCD and converted back to a voxel representation for the DRL to process. The 3D point cloud registration methods are implemented using the Open3D library [25].\n3) Similarity Matching: Then, we compare stable and complete assemblies from an object library with the incom- plete assembly to find the reference. This reference structure is found through the highest combined similarity between an incomplete and complete assembly. The structural feature similarity between two structures $V_1$ and $V_2$ is defined as:\n$S_{feat}(V_1, V_2) = \\frac{1}{2}(S_{comp} + S_{dens})$ (2)\nwhere\n$S_{comp} = 1 - \\frac{|CC(V_1) - CC(V_2)|}{max(CC(V_1), CC(V_2))}$\n$S_{dens} = 1 - \\frac{|\\rho(V_1) - \\rho(V_2)|}{max(\\rho(V_1), \\rho(V_2))}$\nHere, $CC(V)$ is the number of connected components in the structure $V$, and $\\rho(V)$ is the voxel density and the"}, {"title": "B. Combinatorial Deep Reinforcement Learning", "content": "This section introduces our proposed framework of com- binatorial DRL for the completion task. We explain how our agent learns from an incomplete and complete structure to select optimal actions at each sequential step. In addition, we propose a validity action mask to filter invalid actions and demonstrate it in a discrete Lego assembly environment. Refer to the right side of Fig. 1 for the DRL pipeline.\nState: For every $t$-th state $s_t$, the MDP is defined as $s_t = (V_{cur}, V_{tar}, I_t)$ as represented at the top right of Fig. 1. $V_{cur}$ is a 3D binary matrix that represents the incomplete voxel being assembled. $V_{tar}$ is a 3D binary matrix voxel that represents the complete target voxel that $V_{cur}$ is trying to replicate. $I_t$ is a dictionary that tracks the assembly inventory of available bricks.\nAction: At each $t$-th state $s_t$, we define an action space of all feasible placements of Lego bricks within the current voxel matrix $V_{cur}$. Since $V_{tar}$ is not a predefined assembly blueprint but rather a reference for constructing missing features, the agent has to output a decision $a_t = (B_t, p_t, w_t)$ in a vast number of invalid and valid actions generated by the action space, which the actor determines at a given $t$-th step in order to satisfy sequential assembly: $B_t \\in [1,N]$ defines the brick type/size. $p_t = (x_t, y_t, z_t)$, $x_t \\in [1, h]$, $y_t \\in [1,w]$, $z_t \\in [1,d]$, defines the brick's position within the action space. $w_t \\in [0, 1]$ defines either a horizontal or vertical orientation for each Lego brick. In choosing a valid action, we define a validity action mask, which utilizes heuristics to mask out all invalid action probabilities from the probability distribution that the actor selects from.\nTransition Function: The state transition function $P$ maps the current state $s_t$ and action $a_t$ to the next state $s_{t+1}$, updating the current voxel representation $V_{cur}$ with the newly placed brick and adjusting the brick inventory accordingly. The brick inventory is represented as $I_{t+1} [B_i] = I_{B_i} - 1$.\nFormally, this can be represented as: $s_{t+1} = P(s_t, a_t) = (V_{cur} \\cup a_t, V_{tar}, I_{t+1})$. The state transition accounts for the addition of the selected brick in the specified position and orientation and the decrement in its inventory count.\nReward Function: The goal for 3D Assembly Completion is to construct an object $V_t$ that is as similar as possible to the target object $V_{tar}$. Thus, we define the accumulated reward as a measure of the space utilization of the target voxel as well as the similarity metric defined in (3):\n$r(a_t, s_t) = V_{cur} \\cap V_{tar} \\times c + S_{com} \\times d$ (4)\nwhere the first half of the equation represents the number of overlapping voxels between the current and target voxel grid. $c$ and $d$ represent weight parameters that guide the agent's learning.\n1) Action Validity Mask: To quantify why training DRL for combinatorial 3D assembly completion is difficult, we want to emphasize that we define our environment as a 48x48x48 width, height, and depth, along with 8 unique bricks and 2 orientations for each brick. This would mean that at each state $s_t$, the action space would total up to 48*48*48*8*2=1,769,472 unique actions. Similar works ad- dressed at combinatorial planning like [12], [23] have an exact end voxel to fill out, whereas, in assembly completion, the end target is not exact, which creates a greater need for invalid action filtering and constraining heuristics. If ASP heuristics or only a reward is used, training the agent is impossible due to the sheer number of actions created from the assembly completion task. Therefore, we consider mul- tiple heuristics that prevent invalid actions such as floating, unstable bricks, or colliding bricks.\nObject Boundary: To elaborate further, the agent has no definitive done condition (e.g., $V_{cur} == V_{tar}$) and needs the ability to place bricks outside of $V_{tar}$ to achieve a higher similarity, whereas traditional ASP works hard-constrain the action space to $V_{tar}$. Therefore, by scaling and aligning in section IV-A, we assume the target voxel $V_{tar}$ to roughly match the incomplete assembly and define a tolerance bound- ary so that bricks further outside the target area are not considered. This is defined as:\n$O(a_t, s_t, s_{t+1}) = V_{tar} \\cup \\text{tol}(V_{tar}, X)}$ (5)\nThe function $\\text{tol}(V_{tar}, X)$ generates a boundary of X grid spaces outward from the target voxel around the entire object itself.\nCollision: Since real-world assembly does not allow for collisions between objects, we filter out all possible actions that intersect with any existing bricks.\nInventory: Since real-world assembly has a finite inven- tory, the agent may only use a certain brick type if still available.\n$I(a_t, s_t, s_{t+1}) = I_{B_t} > 0,$ (6)\nHooking Mechanism: As illustrated in Fig. 2, a brick $B_t$ is only considered valid if there exists one adjacent brick $B_{t-1}$ such that the bottom face of $B_t$ is directly above or the top face of $B_t$ is hanging below.\nMathematically, the hooking condition can be expressed as:\n$H(a_t, s_t) = \\begin{cases}\n(x_t...x_t+h, y_t...y_t+w, z_t-1) \\in B_{t-1}\\\\\n(x_t...x_t+h, y_t...y_t+w, z_t+1) \\in B_{t-1}\n\\end{cases}$ (7)\nAdditionally, the hooking mechanism restricts the place- ment of bricks to eliminate floating bricks which are not feasible in practical scenarios. By enforcing this rule, we guide the agent to construct more practical 3D assemblies."}, {"title": "V. EXPERIMENTS", "content": "We evaluate the performance of our method through similarity and stability metrics defined in (3), [26] and visualize results in Fig. 3. Then, we perform two ablation studies on our proposed method to highlight the effectiveness of the robot inference and completion steps. Finally, we evaluate our finished assemblies using stability analysis to demonstrate real-world feasibility and validate our approach.\nTo demonstrate our proposed framework, we define a 48x48x48 LEGO base plate environment with a brick storage inventory of 8 unique bricks (1x1, 1x2, 1x4, 1x6, 1x8, 2x2, 2x4, 2x6) and 2 orientations for each brick. We evaluate our framework across multiple object categories and visualize the result. We implement PPO [27] for stable training and develop the action validity mask using [28] in Python. All models are trained on a Ubuntu 20.04 PC with a 48-core Intel(R) Xeon(R) Silver 4214 CPU @ 2.2GHz with an Nvidia RTX A4000 GPU with 16GB memory.\nDuring training, the DRL agent takes a set of incomplete structures (e.g., Fig. 3(1)), finds the reference assembly with the highest similarity from a library (e.g., Fig. 3(6)), and then sequentially builds to complete the structure (e.g., Fig. 3(11)). Then, we test the model's performance on vari- ous unseen incomplete structures in multiple different object categories with dramatically different dimensions, shapes, complexities, etc.\nA. Qualitative Analysis\nThe trained model demonstrates great generalizability dur- ing testing. In Fig. 3, multiple unseen incomplete structures"}, {"title": "VI. CONCLUSION AND FUTURE WORK", "content": "This paper proposes a novel formulation of the 3D assembly completion task. Our approach combines PCD techniques with DRL to enable robots to infer assembly intent and optimize action sequencing. We develop heuristics for action masking and a custom reward to assist agent training. Experiments validate the framework's capability in various construction scenarios, overcoming real-world constraints. However, a limitation is that if the reference is significantly larger than the incomplete assembly, stability is not absolutely guaranteed throughout. We aim to explore further optimization solutions to maximize stability in the future. In addition, we aim to incorporate temporary and permanent removal operations to allow for greater flexibility and efficiency in handling pre-existing problematic features."}]}