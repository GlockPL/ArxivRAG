{"title": "DISCLOSURE OF AI-GENERATED NEWS INCREASES\nENGAGEMENT BUT DOES NOT REDUCE AVERSION, DESPITE\nPOSITIVE QUALITY RATINGS", "authors": ["Fabrizio Gilardi", "Sabrina Di Lorenzo", "Juri Ezzaini", "Beryl Santa", "Benjamin Streiff", "Eric Zurfluh", "Emma Hoest"], "abstract": "The advancement of artificial intelligence (AI) has led to its application in many\nareas, including journalism. One key issue is the public's perception of AI-generated\ncontent. This preregistered study investigates (i) the perceived quality of AI-assisted\nand AI-generated versus human-generated news articles, (ii) whether disclosure\nof AI's involvement in generating these news articles influences engagement with\nthem, and (iii) whether such awareness affects the willingness to read AI-generated\narticles in the future. We employed a between-subjects survey experiment with\n599 participants from the German-speaking part of Switzerland, who evaluated the\ncredibility, readability, and expertise of news articles. These articles were either\nwritten by journalists (control group), rewritten by AI (AI-assisted group), or entirely\ngenerated by AI (AI-generated group). Our results indicate that all news articles,\nregardless of whether they were written by journalists or AI, were perceived to\nbe of equal quality. When participants in the treatment groups were subsequently\nmade aware of AI's involvement in generating the articles, they expressed a higher\nwillingness to engage with (i.e., continue reading) the articles than participants in\nthe control group. However, they were not more willing to read AI-generated news\nin the future. These results suggest that aversion to AI usage in news media is not\nprimarily rooted in a perceived lack of quality, and that by disclosing using AI,\njournalists could attract more immediate engagement with their content, at least in\nthe short term.", "sections": [{"title": "Introduction", "content": "The landscape of journalism is evolving significantly with the advancement of artificial intelligence\n(AI). Traditionally, journalists have used computers primarily for research and data analysis, but this\nrole is rapidly expanding. Modern AI, particularly generative AI, now matches or even surpasses\nhuman capabilities in tasks like text composition. This has led to the emergence of \u201cautomated\" or\n\"robot\" journalism (Carlson, 2018; Clerwall, 2014; Graefe et al., 2018), a key aspect of the broader\ncomputational journalism trend that underscores the increasing role of computation and data in\nnews production (Anderson, 2013; Cohen, Hamilton and Turner, 2011; Lewis and Westlund, 2015).\nAI applications, especially in natural language generation, have become integral in practical jour-\nnalism. These applications include news writing for media organizations such as the Associated\nPress and Forbes, summarizing scientific data via platforms like the Open Research Knowledge\nGraph, and narrative writing using tools like ChatGPT-4. These advancements enable AI to produce\ncontent that is virtually indistinguishable from human writing, demonstrating AI's potential in\nvarious writing-intensive domains.\nThe integration of AI-generated content in journalism presents several implications. On one hand, it\noffers opportunities for faster, multilingual, and expanded content production with potentially fewer\nerrors, which could enhance news quality and help combat misinformation (Graefe et al., 2018). AI\ncan also handle routine reporting tasks, allowing journalists to focus on investigative stories. On\nthe other hand, however, there are concerns about job losses in the journalism sector and doubts\nregarding algorithms' ability to fulfill the \u201cwatchdog\u201d role traditionally associated with journalists\n(Str\u00f6mb\u00e4ck, 2005; Latar, 2015).\nA crucial issue is the public's perception of AI-assisted journalism. Understanding attitudes towards\nAI-generated journalism is essential as it may directly impact the public's political knowledge.\nIndeed, if the public distrusts AI-generated content and chooses not to engage with it, they may miss\nout on important political information, leading to a less informed citizenry. A recent study revealed\nthat only 29% of Swiss respondents would read fully AI-generated news, 55% would read news\nif AI assisted in its creation, and 84% would prefer news created without AI involvement (Vogler\net al., 2023). This highlights skepticism towards AI-generated news amongst the Swiss population,\nconsistent with surveys from other countries (Fletcher and Nielsen, 2024). Such aversion could\nbe problematic because it could undermine the credibility and effectiveness of news organizations.\nTherefore, transparent and responsible use of AI in journalism is essential to build trust and ensure\nthat the public remains informed and engaged with credible news sources.\nIn this preregistered study, we investigate the perceived quality of AI-assisted and AI-generated\nversus human-generated news articles prior to disclosing whether the articles were created by\nhumans, AI-assisted processes, or entirely by AI, and whether subsequent disclosure of the source\ninfluences self-reported willingness to engage with those articles as well as the willingness to read\nAI-assisted or AI-generated articles in the future. Our results indicate that all kinds of news articles,\nregardless of whether they were written by journalists or (assisted by) AI, were perceived to be of\nsimilar quality in terms of credibility, readability, and expertise. When participants in the treatment\ngroups were subsequently informed about AI's role in generating the articles, they expressed a\nhigher willingness to read the full news article than participants in the control group, who saw"}, {"title": "Previous Research", "content": "Several strands of literature have explored the perception of human versus AI-generated news. The\nfirst strand involves research on public opinions about human versus computer-generated news,\nrelying on respondents' prior experiences or perceptions (e.g., Vogler et al., 2023; Chuan, Tsai and\nCho, 2019). A recent survey conducted across six countries (Argentina, Denmark, France, Japan,\nthe UK, and the USA) revealed that public opinion on the use of generative AI in journalism is\nmixed (Fletcher and Nielsen, 2024). While people expect AI-produced news to be cheaper and\nmore up-to-date, they also anticipate it to be less trustworthy and transparent. Most respondents are\nwary of AI-generated news, especially on hard topics like politics and international affairs, but show\nmore acceptance for soft news like fashion and sports. A large majority favors disclosure when AI\nis used, but opinions differ on which specific uses should be labeled. Uncertainty remains, with\nmany respondents unsure or neutral about AI's role in journalism. A limitation of these kinds of\nopinion-based studies is that they could reflect respondents' preconceptions or lack of familiarity\nwith AI-generated texts, which may not align with actual behaviors when confronted with AI news.\nThe second strand consists of surveys where respondents directly evaluate news stories labeled as\neither \u201chuman-written\u201d or \u201ccomputer-written.\u201d For instance, Haim and Graefe (2017) found that\nrespondents rated human-written news higher in readability but lower in credibility compared to\nAI-generated news. However, when participants were only given a single article without information\non its origin, the differences in their evaluations were minimal, indicating that the perception of the\nauthor (human or AI) plays as significant a role in the assessment as the content itself.\nThe third strand focuses on experiments where participants are presented with identical articles\nbut with different stated authors, to measure the effect of the source. For example, Van der Kaa\nand Krahmer (2014) found that while news consumers rated the credibility of both human and\ncomputer-generated articles equally, journalists perceived human-labeled articles as significantly\nmore trustworthy. This effect varied with the topic, as sports articles were rated as less trustworthy\nthan financial ones. Jung et al. (2017) used a 2 \u00d7 2 design to explore perceptions of article quality\nbased on authorship labels, finding that both journalists and the public rated AI-written articles\nhigher when they were correctly labeled as such. Another experiment by Tandoc Jr, Yao and\nWu (2020) varied the attributed author of a human-written text, finding no significant difference\nin perceived credibility across different labels. Additionally, Altay and Gilardi (2023) explored\nhow labeling news headlines as \u201cAI-generated\" affects accuracy ratings and sharing intentions,"}, {"title": "Research Questions and Hypotheses", "content": "Our study addresses the following research questions:\nRQ1: How do respondents rate the quality (expertise, readability, and credibility) of AI-assisted\nand AI-generated news articles, compared to human-generated news articles?\nRQ2: What impact does disclosing AI's role in generating an article have on respondents' willing-\nness to read AI-assisted or AI-generated news after they have rated the article for quality?\nBy answering these two research questions, we extend the literature in important ways. First, we\ncombine a detailed measurement of \u201cquality\u201d with three realistic levels of AI-involvement in news\ngeneration, reflecting current capabilities and practices. Second, we make sure that respondents'\nviews on AI are not asked in the abstract, which may reflect inaccurate preconceptions, but are\nrooted in specific examples we provide. Third, we separate quality evaluations from willingness to"}, {"title": "Experimental Design", "content": "To explore the public's perceptions of AI-generated and AI-assisted news articles compared to\ntraditional human-generated articles, we conducted an online between-subjects survey experiment.\nWe recruited 599 participants from the age of 18 from the German-speaking part of Switzerland\nthrough the survey company Bilendi, using quotas based on age and gender to ensure balance across\nthese dimensions. Sample size was determined by a power analysis, assuming an effect size of\nCohen's d = 0.3 for the primary outcomes and d = 0.15 for the secondary outcomes.\nFirst, participants completed a pre-survey to determine their socio-demographic characteristics,\nincluding age, gender, education level, and political orientation. Participants were then randomly\nassigned to one of three conditions: a control group that read excerpts from human-generated\narticles (\u201chuman-generated\u201d group), a first treatment group that read excerpts that were rewritten\nwith the help of ChatGPT (\u201cAI-assisted\u201d group), and another treatment group that read excerpts that\nwere entirely generated by ChatGPT (\u201cAI-generated\" group).\nTo ensure consistency and create a set of texts that is comparable across the three groups, all articles\nare derived from the human-generated articles that are shown to the control group. We used the\nfollowing procedure to generate the articles. For AI-assisted articles, we copy-pasted the original\narticle into ChatGPT and asked it to rewrite the article without losing any information. This resulted\nin articles for the AI-assisted group that are similar to the originals, but are rewritten by the AI\nsystem. For AI-generated articles, we only provided ChatGPT with the title and lead of the original\narticle. We then asked ChatGPT to generate a short article in the same style as the source of the\nhuman-generated articles.\nEach participant read two excerpts, randomly drawn from a pool of ten articles on Swiss politics,\nwith each excerpt having a hard cutoff at 150 words to maintain consistency, avoid bias due to article\nlength, and simulate a paywall for the purposes of our third outcome (willingness to \u201ccontinue\nreading\" the article). The random selection of two articles from a pool of ten texts for each group\nminimizes the risk that the outcomes depend on specific topics. Moreover, for each article, we\nasked respondents to answer a simple question on the article's content. This allows us to check that\nrespondents have read the text in sufficient detail.\nThe first outcome measures how participants evaluate the quality of the articles. Following Sundar\n(1999), we ask respondents to rate three dimensions of quality: expertise, readability, and credibility.\nEach dimension is based on specific items, expressed as adjectives (Haim and Graefe, 2017): \u201cclear\u201d,\n\"coherent\u201d, \u201ccomprehensive\u201d, \u201cconcise\u201d, and \u201cwell-written\u201d for expertise; \u201cboring\u201d, \u201cenjoyable\u201d,\n\u201cinteresting\u201d, \u201clively\u201d, and \u201cpleasing' for readability; and \u201cbiased\u201d, \u201cfair\u201d, and \u201cobjective\u201d for\ncredibility. Participants rated the articles on each of these items on a 1-5 Likert-scale, and we then\naggregate the scores for each dimension. Following our pre-registered procedure, we then computed\na single measure of quality because Cronbach's alpha was above 0.7. However, results are robust to\nusing separate scores for each dimension.\nFollowing the initial rating, participants were then informed about the true creation process of the\narticles. After learning how the texts they read were actually created, respondents were asked if"}, {"title": "Results", "content": "Figure 1 presents the mean ratings for the first outcome, which assesses the perceived quality\n(credibility, expertise, and readability) of the articles across the three groups: control, AI-assisted,\nand AI-generated. The mean credibility ratings were 3.39 for the control group, 3.37 for the\nAI-assisted group, and 3.38 for the AI-generated group. In addition to the minimal variation,\nthe overlapping confidence intervals suggest no significant differences between the groups. For\nexpertise, the mean ratings were 3.56 for the control group, 3.63 for the AI-assisted group, and 3.62\nfor the AI-generated group, with overlapping confidence intervals again indicating no significant\ndifferences. Readability ratings were 3.15 for the control group, 3.14 for the AI-assisted group,\nand 3.19 for the AI-generated group, with no significant differences observed, as evidenced by the\noverlapping confidence intervals.\nthey would be willing to continue reading the full articles after reviewing the excerpts again. In\naddition, all respondents were asked to report if they would be willing to read AI-generated news\narticles in the future, on a 1-5 Likert-scale.\nFollowing our pre-registration, we use linear regression models to analyze the data, controlling for\nsocio-demographic variables and using the Benjamini-Hochberg procedure to adjust for multiple\ncomparisons.\nTable 1 provides a more detailed analysis of the first outcome. The table presents regression\ncoefficients for the AI-assisted and AI-generated groups, with controls for age, gender, education,\nand political orientation. Each column corresponds to a separate regression model aligned with one\nof the hypotheses. The coefficients for the AI-assisted and AI-generated groups across expertise,\nreadability, and credibility are not statistically significant, reinforcing the findings from Figure 1\nthat there are no substantial differences in the perceived quality of the articles between the groups.\nAmong the control variables, only age and political orientation yielded statistically significant\ncoefficients in some models; however, the effect sizes for these variables are very small. These\nresults remain unchanged when estimating the models only for the subset of respondents who passed\nthe manipulation check.\nThese results indicate that there are no significant differences in perceived credibility, expertise, and\nreadability between AI-assisted, AI-generated, and human-generated articles. Consequently, we\nreject the first set of hypotheses (H1-H6), which expected lower perceptions of these attributes in the\nAI-assisted and AI-generated groups compared to the control group. In other words, news articles\ngenerated either with the assistance of AI or entirely by AI are perceived to match the quality of\ntraditional articles written by journalists.\nFigure 2 illustrates the mean ratings for the second set of outcomes, which measure participants'\nwillingness to continue reading the articles they were exposed to and their willingness to read AI-\ngenerated news in the future. The control group, which read article excerpts written by journalists,\nhad a mean rating of 2.48 for willingness to continue reading, while the AI-assisted group had\na rating of 3.08, and the AI-generated group 3.18. The confidence intervals for the AI-assisted\nand AI-generated groups do not overlap with those of the control group, indicating statistically\nsignificant increases in willingness to continue reading for these groups. Additionally, no significant"}, {"title": "Conclusion", "content": "The primary aim of this paper was to examine the perceived quality of AI-assisted and AI-generated\nnews articles compared to human-generated ones, and to assess how subsequent disclosure of AI\ninvolvement influences readers' willingness to engage with these articles and their openness to\nAI-generated news in the future. The research design involved a preregistered experimental study\nwhere participants evaluated the perceived quality of news articles without knowing their source,\nfollowed by disclosure of whether the articles were AI-assisted, AI-generated, or human-written, to\nmeasure changes in willingness to engage with the content and future openness to AI-generated\nnews.\nWe found no significant differences in perceived credibility, expertise, and readability between\narticles created by AI, those assisted by AI, and those written by humans. However, participants\nshowed a significantly higher willingness to continue reading articles when aware of AI involvement,\nwhether assisted or fully generated, compared to human-written articles. This suggests that AI does\nnot reduce perceived article quality and enhances readers' engagement once AI origin is disclosed.\nHowever, no significant effect was observed regarding future willingness to read AI-generated news,\nindicating that AI's role may positively influence immediate engagement, possibly through a novelty\neffect, but not long-term preferences."}, {"title": "", "content": "The results regarding our second set of outcomes are particularly noteworthy. We found significant\nand positive effects on respondents' willingness to continue reading the articles after the true source\nwas revealed, applicable to both treatment groups (AI-assisted and AI-generated). This suggests\nthat readers may not be opposed to engaging with AI-generated or AI-assisted texts and may even\nbe curious to learn more about AI. However, it is important to consider that the increased interest\nin reading the full article may not be a lasting effect changing preferences for AI-generated news.\nParticipants might have become curious about AI involvement after learning the true authorship,\nbut they have not become more (nor less) open towards reading AI news in general. Future research\ncould explore this increased interest using more targeted intervention research designs, which could\nprovide valuable insights for news producers on how to enhance specific target audiences' interest\nand increase article engagement.\nRegarding respondents' willingness to read AI-generated news articles in the future, we found\nno significant differences between the treatment groups. Simply reading two AI-assisted or AI-\ngenerated texts does not appear to alleviate concerns about AI involvement in news production, as\noverall willingness scores remained below 2.5 across all groups. These findings may indicate a\ngradual familiarization process with AI among readers. Over time and with further technological\nadvancements, AI might become more integrated into journalism, particularly in news production,\nwith readers becoming more accustomed to it. Therefore, future research should continue monitoring\npublic attitudes toward AI to detect potential familiarization effects.\nFuture research could focus on tracking changes in public perception and engagement with AI-\ngenerated news over time through longitudinal studies, which would provide insights into whether\ninitial curiosity leads to long-term acceptance or trust. Exploring the role of transparency in\ndisclosing AI involvement would also be important, as different types of transparency might\ninfluence how readers perceive and trust AI-generated content. Intervention studies could test\ndifferent strategies to enhance reader engagement to determine what factors increase willingness to\nengage with AI-produced news. Expanding this research to include diverse cultural and linguistic\ncontexts would be important, to assess whether these findings are generalizable across different\npopulations. Additionally, studying the impact of AI-generated news on public knowledge could\nreveal how well readers retain and understand information from AI versus human-written articles."}]}