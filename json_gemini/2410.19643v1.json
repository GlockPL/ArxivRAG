{"title": "Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites.", "authors": ["Nicol\u00e1s Nieto", "Simon B. Eickhoff", "Christian Jung", "Martin Reuter", "Kersten Diers", "Malte Kelm", "Artur Lichtenberg", "Federico Raimondo", "Kaustubh R. Patil"], "abstract": "Machine learning (ML) models benefit from large datasets. Collecting data in biomedical domains is costly and challenging, hence, combining datasets has become a common practice. However, datasets obtained under different conditions could present undesired site-specific variability. Data harmonization methods aim to remove site-specific variance while retaining biologically relevant information. This study evaluates the effectiveness of popularly used ComBat-based methods for harmonizing data in scenarios where the class balance is not equal across sites. We find that these methods struggle with data leakage issues. To overcome this problem, we propose a novel approach \u201cPrettYharmonize\u201d, designed to harmonize data by pretending the target labels. We validate our approach using controlled datasets designed to benchmark the utility of harmonization. Finally, using real-world MRI and clinical data, we compare leakage-prone methods with \u201cPrettYharmonize\u201d and show that it achieves comparable performance while avoiding data leakage, particularly in site-target-dependence scenarios.", "sections": [{"title": "Introduction", "content": "Many research fields have greatly benefited from machine learning (ML) approaches. ML models can extract important values from large amounts of data. Having vast data benefits the model's classification performance and helps capture the underlying patterns, promoting better generalization to new unseen data. This makes combining multiple datasets an appealing approach, especially in domains where obtaining data in a uniform setting is challenging\u00b9. Moreover, small health or research centers that can not afford to collect a large number in-house data, using data acquired in different sites is the only possibility for train ML models. However, different datasets obtained under different conditions often present variability due to differences in the acquisition procedure that are unrelated to relevant biological information\u00b2. This undesired variability, also known as Effects of Site (EoS), can induce biased results if present or not correctly removed\u00b3. These differences may come from systematic differences, which can be corrected, or random variations, which can not be modeled or corrected by harmonization. This problem is of common occurrence in many biomedical domains. For example, clinical data is affected by the acquisition site, as different hospitals have different laboratory machines, procedures, and criteria. Another example is the medical imaging field, as images are affected by acquisition protocol, scanner drifts, and time of the day, just to name a few factors 3,4. Within this field, Magnetic Resonance Imaging (MRI) images are particularly susceptible to this site-related variance, like the magnetic field strength, room temperature fluctuation or changes in the electromagnetic noise, which makes even images obtained from scanners with the same manufacturer and the same parameters exhibit different characteristics 5,6. Many works showed that removing this undesired systematic variability, which is only related to the acquisition site and has no biological information, can benefit further analysis made with the data 7-11. To this end, several Methods Aiming to Remove the Effects of Site (MAREoS) have been proposed and developed4,12. These MAREoS methods are typically used as a pre-processing step, where the site effects are removed and the \u201csite-effect free\u201d data, also known as harmonized data, is used for statistical analysis or to train and evaluate ML models.\nAmong these MAREoS, the ones based on \u201cComBat\u201d are extensively used in several domains. The ComBat method was originally proposed for correcting batch differences in genomic data 13 and was later adapted to other domains like MRI data 7,14. ComBat uses Bayesian regression to find additive (location) and multiplicative (scale) corrections for each feature in each site. Within the ComBat-based methods, \u201cneuroHarmonize\u201d was proposed 15 to allow for the preservation of non-linear covariate effects and has been widely used since4,12,16,17. Although ComBat and its derivations have been widely applied in medical imaging data, several concerns have been raised, mainly because ComBat's hypothesis and assumptions only hold for genomic data, where it was originally proposed, and may not be fulfilled in other applications fields 18. Additionally, concerns had been raised on the integration of ComBat into ML models, as the location and scale parameters of the model could not be learned in a subset of data (train data) and then applied to a new unseen subset of data (test data) 19.\nEarly implementations of ComBat14,20 used the whole dataset to estimate the model's parameters and create a harmonized dataset that is then used from all the downstream analyses. This approach was used in several works 7,8,21\u201324. While this approach is valid when performing statistical analyses, it is not consistent with machine learning applications where the training and test data must be separate 19,25. Specifically, the parameters of the models, including preprocessing models, must be obtained on a training set and then applied to the test set. This separation is important to get realistic estimates of generalization performance (e.g. using cross-validation) and to ensure deployability of the model in the real world where the test data is not yet available 26,27.\nComBat-MAGA28, neuroHarmonize15, and \"harmonizer\u201d19, which is based on neuroHarmo-nize, allow the estimation of the model's parameters in a training set and apply them to the test samples, however, a critical assumption of ComBat is that all variance not shared across sites is unwanted site-related variance. Consequently, ComBat removes any variance that is not common to all sites, including the relevant biological variance. This poses a new problem, as this assumption is broken when a class imbalance occurs across sites and a target-site dependence exists, for example when the control patients are acquired in one site and target patients in a different one 29. This could also be extended to other possible biological information like co-morbidities or disease severity, for example, if more severe patients are consistently treated or acquired only in one site. In these cases, even though ComBat will provide harmonized data, it will remove the variance related to the target (control versus patient) as the assumption is that only non-relevant factors change between sites.\nComBat allows to retain the biologically relevant variables, for example, a diagnosis, the age, or the sex of a patient, by providing these variables as covariates to be retained. Nonetheless, this information is needed both when training the model and when applying the model to the test data. Thus, if target labels need to be preserved, this inevitably leads to the model requiring the test labels preventing the model's use in real-world applications where test labels are not available or known 18. This phenomenon where information of the test set is presented to the models is commonly known as data leakage. It is also well described that leaking the test target information would produce overconfident results, which could be misleading and can jeopardize the progress of an entire research field, as researchers who avoid data leakage would not be able to outperform the models that present data leakage 25\u201327.\nIn this work, we aim to empirically demonstrate a shortcoming of ComBat-based harmonization in site-target dependence scenarios, i.e., that the model can properly harmonize the data only when test labels are used and data leakage happens. To do so, we performed controlled experiments for age regression and sex classification using real MRI data for healthy control individuals. Also using MRI data, a dementia and mild cognitive impairment (MCI) classification experiment was performed. Additionally, an outcome prediction of septic patients was performed using clinical data. All experiments were conducted both in site-target dependence and independence scenarios. Several harmonization schemes were used and compared, allowing and not allowing leakage, to harmonize the data.\nFinally, to overcome the aforementioned problem, we propose a new harmonization method, called PRETended Target Y Harmonize (PrettYHarmonize), which allows the users to integrate ComBat in an ML pipeline, harmonizing the data and generating a prediction without using the test labels and thus avoiding data leakage. We validated our method using benchmark datasets\u00b3. Additionally, the proposed method was compared with the other harmonization schemes on the site-target dependence and independence scenarios to comprehensively compare no harmonization, leakage, and no-leakage methods. The corresponding Python package is publicly available via GitHub https://github.com/juaml/PrettYharmonize."}, {"title": "Results", "content": ""}, {"title": "0.1 PrettYharmonize validation", "content": "The proposed PrettYharmonize method is based on a neuroHarmonize model15 but uses the combination of two ML models, a Predictive and a Stack model to harmonize the data without using test labels, preventing data leakage by design. To avoid using the test data labels, the proposed methods rest on the use of pretended target values, which are used to harmonize the test data and generate a prediction with the Predictive model. Our main assumption is that when harmonizing the test data with the correct label, e.g. when the pretended label matches the real test label, the neuroHarmonize model will preserve the relevant information. On the contrary, when the pretended label doesn't correspond with the real label, the all information will be removed, both effects of site and biological information, as it was harmonized under the wrong test label assumption. Then, the Predictive model will generates a more accurate and Using these predictions as input features, the Stack model generates a final unique prediction for each sample. As test labels are pretended and not used, predictions can be generated without requiring test target values. A detailed description of the method workflow is presented in the Method-PrettYharmonize section.\nPrettYharmonize was validated using the datasets specially designed to validate MAREoS3. This dataset consists of eight internal datasets simulating eighteen MRI features (cortical thick-"}, {"title": "0.2 Forced site-target dependence and independence.", "content": "To investigate the impact of the harmonization when site and target are dependent or independent, different scenarios were generated by thoroughly sampling data from different datasets. To force site-target dependence, for each site, we retained the majority of samples from one class and a small number of samples from the other classes. For example, let's assume a binary classification problem where only two sites are presented. In this case, from site A, mainly samples from class one were retained, and only a few samples from class two. For site B, an opposite sampling strategy was used, retaining mainly samples from class two and just a few from class one. The small number of samples from the minority class were retained to avoid singular matrices, which the algorithms cannot support. In this case, we hypothesize that the traditional harmonization will remove important information, as the biological variance is related (or dependent) to the sites, unless test labels are leaked to the harmonization model. In contrast, site-target independence scenarios were generated by retaining the same amount of samples for each class sampled from each site. We hypothesize that in this case, the harmonization scheme will not remove important information, as the biological variance is common to all sites."}, {"title": "0.2.1 Age prediction", "content": "For the site-target dependence scenario, from four MRI datasets that contain healthy participants [AOMIC, ENKI, CamCAN, and 1000Brains] 200 images were extracted from each site in disjoint age ranges, forcing a site-target dependence. The same proportion of male and female participants was retained in each age range. The unharmonized method obtained a Mean Average Error (MAE) of 6.20, which is in an expected range according to the literature 36. The predictions using the WDH and TTL schemes showed an improvement in the performance of about 2 years, compared with the unharmonized scheme. The harmonization scheme that does not use the test labels (No Target) showed the highest error. As expected, the harmonization process removed the age-related signal in the features and therefore the ML model was unable to learn the feature-target relationship and failed to generate accurate predictions. In this case, the model just predicts the mean population age for all individuals, predicting the individuals to be older in the AOMIC and eNKI datasets and younger in the CamCAN and 1000Brains datasets. PrettYharmonize made better predictions, on average, compared with the unharmonized and No Target methods, improving the MAE, R2, and age bias, and without inducing leakage. PrettYharmonize's performance was similar to the two methods that allowed leakage. The individuals' predictions can be found in the Supplementary Information Figures Supp 1-5.\nFor the site-target independence scenario, three datasets [eNKI, CamCAN, and SALD] containing healthy controls were used. The same number of images from each dataset was retained in the 18-80 age range, maintaining an equal proportion of males/females. The unharmonized model obtained an MAE of 6.3144, similar to the performance obtained in the site-target dependence scenario. Neither PrettYharmonize nor any of the leakage-prone harmonization schemes (WDH and TTL) showed a performance improvement for any of the sites, compared to the unharmonized model. Moreover, the average performance was similar for all the harmonization schemes including the No Target scheme. This result suggests that the EoS signal was also discarded by the ML model, as it was not related to the target. Notably, consistent with our hypothesis, the No Target scheme did not remove important biological information, as this biologically relevant variance was presented across all sites."}, {"title": "0.2.2 Sex classification", "content": "Two datasets [eNKI and CamCAN] containing healthy controls were used in this experiment were used for the forced site-target dependence. From the first one, 95% of females were retained, whereas for the second dataset only 5%, forcing a site-target dependence. In this case, the age range of the individuals was completely overlapped. The unharmonized scheme obtained a high performance (AUC = 0.97), which is similar to the performance reported in the literature37. The harmonization schemes that allow leakage (WDH and TTL) and PrettYharmonize did not show improvement compared to the unharmonized scheme. This can be mainly because the features carry a strong signal related to the participant's sex, yielding high performance, even using unharmonized data. Consistent with the age regression experiment, the harmonization scheme without test labels (No Target), removed sex-related information significantly reducing the model's classification performance.\nUsing the same generated dataset as in the age regression problem for site-target independence, a sex classification experiment was performed. The unharmonized scheme obtained a slightly lower (AUC=0.918) classification performance compared to the sex classification experiment with site-target dependence. The harmonization schemes did not show classification improvement compared with the unharmonized model. The No Target scheme does not remove target-related variance while harmonizing the features, explaining the similar performance of this model compared to the other schemes."}, {"title": "0.2.3 Dementia and mild cognitive impairment classification", "content": "For the site-target dependence scenarios, 100 dementia-MCI patients and 10 controls from one site and 100 controls and 10 dementia-MCI on a second site were selected from the ADNI dataset. The unharmonized method obtained an AUC of 0.81, consistent with other findings in the literature 38. PrettYharmonize and the leakage-prone methods showed a slightly higher classification performance than the unharmonized method. As observed before, No Target removed important biological information, jeopardizing the ML model's performance.\nFor the site-target independence scenario, the same number of control and patients were selected from both sites. In this scenario, all methods obtained a similar classification performance in all metrics. Noteworthy, an important performance drop in all schemes is presented, compared with the site-target dependant experiment."}, {"title": "0.2.4 Discharge status prediction of septic patients", "content": "From the eICU dataset, 20 sites with more than 50 patients were selected. From these selected sites, the \"Alive\u201d patients were removed from 10 sites and the Expired patients were removed from the other 10 sites, forcing a site-target relationship. The unharmonized method obtained an AUC of 0.76, slightly lower than the one obtained in39. However, this difference is expected, as fewer patients were used in our experiments, compared with the reference study. PrettYharmonize obtained an important AUC performance improvement compared with all the benchmarked schemes. No Target scheme removed almost all the relevant information, obtaining a practically by-chance performance.\nFor the site-target independence scenario, the same 20 sites selected were used, but the same number of Alive and Expired patients were retained in each site. All methods obtained the same classification performance in all metrics. The unharmonized method obtained a slightly lower classification performance (0.72 AUC) compared with the site-target dependence scenario (0.76 AUC). Furthermore, PrettYharmonize and the leakage-prone schemes (WDH and TTL) showed a great drop in classification performance, compared with the site-target dependence scenario. Finally, the No Target method did not remove important information while harmonizing the features, obtaining a similar performance as the rest of the benchmarked methods."}, {"title": "Discussion", "content": "Combining data from differing acquisitions is an appealing, and sometimes only, option for building ML models as they typically benefit from greater sample sizes. However, it is important to correctly integrate data harmonization methods, like the widely used ComBat, in ML pipelines 19. In this study, we evaluated several ML pipelines incorporating ComBat-based data harmonization using a wide variety of biomedical data from different domains for both classification and regression tasks. Regarding the use of ComBat, feature distribution before and after harmonization is often analyzed to assess the effectiveness of the harmonization process. While this analysis can confirm that the features have been adjusted to exhibit more similar distributions, this analysis alone does not provide sufficient insight into how these adjustments impact the performance of ML models.\nFor all the evaluated scenarios, the ML pipelines using unharmonized data showed a performance close to the reported in the literature 36-39. Importantly, for the site-target dependence scenarios, all the unharmonized models showed a better performance compared with the site-target independent scenarios. This is expected as the ML models can to pick EoS signal, which is related to the target in the site-target dependence scenarios, and use it to fraudulently increase the classification performance.\nWe observed that ComBat-based harmonization struggles to provide benefits when the site and target variables are independent, even when allowing leakage and the target variance was preserved in ComBat modelling. None of the harmonization-based ML pipelines showed performance improvement over the baseline of pooling the data together with site-target independence. This can be explained because the harmonization may be removing a signal that it is also discarded by the ML models, as it is not related to the target. In this case, the benefit of removing the Effect of Site (EoS), did not improve the signal-to-noise ratio of the signal enough to benefit the performance of the ML models. Despite the wide variety of tasks and data from different domains we tested, ComBat-based harmonization does not seem to provide an advantage. Nevertheless, it is possible that our data and task selection, albeit comprehensive, does not include cases where harmonization can be indeed beneficial.\nOn the other hand, on the site-target dependence senarios, a performance improvement was observed when when applying ComBat and allowing the target variance to be preserved. Problematically, in conventional ways to integrate ComBat in ML pipelines (Whole Data Harmonization and Test Target Leakage), this leads to data leakage as the test labels are used. Whereas not explicitly preserving the target (No Target), the performance was consistently worse. These observations can be explained as ComBat works on the assumption that the site-specific variance and variance of interest are independent. However, this assumption is violated when the site and target are dependent. Consequently, when the site and target are dependent, using ComBat without explicitly preserving the target variance can remove variance related to the target.\nThe proposed a new method called PrettYharmonize avoids leakage by design, as it relays in the harmonization using pretended target labels and a Stack model, which combines the predictions made with the different harmonized data. In this way, the method can circumvent the need for target values of the test samples. PrettYharmonize was validated on the MAREoS datasets which were specifically devised for this purpose. The solid results obtained in this dataset indicate that the proposed method effectively harmonizes data without compromising model integrity. The method provides a leakage-free pipeline which in our evaluations showed performs at par with leakage-prone pipelines. These findings suggest that PrettYharmonize holds promise for real-world deployment, particularly in contexts where data leakage is a critical concern. Therefore, we recommend PrettYharmonize for future use cases. Overall, our results suggest that future studies should carefully evaluate their ML pipelines and follow reproducible and open science practices for the benefit of the community.\nAlternative approaches such as calculating ComBat parameters using phantoms 18 can harmonize data independent of biological variability. By doing so, the location and scale parameters specific to each MRI setup and parameter setting can be accurately estimated and applied to real data. This approach mitigates the risk of inadvertently removing meaningful biological variation during harmonization. However, such approaches are domain-specific and incur challenges such as measuring additional data.\nFinally, although our study focused on widely used ComBat-based methods, it is important to acknowledge the existence of other harmonization techniques, such as deep learning-based methods like style-matching generative models or variational autoencoders4. These approaches may offer promising alternatives, particularly in complex scenarios where traditional methods may fall short though they tend to be data and compute-intensive."}, {"title": "Limitations of the study", "content": "This study has some limitations that should be considered when interpreting the results. First, our analysis focuses primarily on ComBat-based harmonization methods due to their widespread use; however, we did not extensively explore other emerging techniques such as deep learning, optimal transport, or style-matching generative models, which offer different strengths and weaknesses.\nSecond, the impact of harmonization on feature selection and model interpretability was not deeply explored, warranting further investigation into how these methods influence model behavior in different contexts.\nThird, even though in a controlled fashion we simulated somewhat extreme site-target dependence and independence scenarios, it is safe to assume that any real-case scenario will fall in between. Our aim in this study was to empirically demonstrate the problems that may occur while harmonizing the data without factoring in appropriate considerations. Further research should be conducted to better measure the relationship between the site-target dependence degree and the harmonization impact.\nFinally, regarding PrettYharmonize, the proposed method is more computationally expensive than the traditional harmonization schemes because in the \u201cpretending\u201d process the data need to be harmonized several times."}, {"title": "Experimental procedures", "content": ""}, {"title": "Resource availability", "content": ""}, {"title": "Lead contact", "content": "Please send any inquiry to the corresponding author, Nicol\u00e1s Nieto (n.nieto@fz-juelich.de)"}, {"title": "Materials availability", "content": "No materials were used in this work."}, {"title": "Data and code availability", "content": "All used MRI datasets are publicly available possibly upon registration. For the elCU dataset, data is publicly available at https://physionet.org/content/eicu-crd/2.0/ after registration. Registration includes the completion of a training course in research with human individuals at https://about.citiprogram.org/and signing of a data use agreement mandating responsible handling of the data and adhering to the principle of collaborative research.\nThe library is publicly available at: https://github.com/juaml/juharmonize. The scripts to replicate the experiments and replicate the processing of the datasets are available at: https://github.com/juaml/harmonize_project"}, {"title": "Data description", "content": ""}, {"title": "MAREoS dataset", "content": "To ensure the validity of PrettYharmonize, we benchmarked it in a classification problem using the datasets specifically designed to evaluate harmonization models\u00b3. This MAREoS dataset consists of eight datasets simulating 18 MRI features (cortical thickness, cortical surface area, or subcortical volumes). Four datasets contain a \u201cTrue\u201d signal and four only contain an Effect of Site (\"EoS\") signal related to a binary target. In that sense, an ML model that learns the \u201cEoS\u201d signal can fraudulently achieve a good classification performance. The signal, both the True or EoS, are called \"Simple\u201d and \u201cInteractions\u201d, depending on a linear or non-linear effect, respectively. Within each dataset, approximately 1000 samples, coming from 8 sites, were simulated. The datasets are provided as 10 train and test fold pairs. For the dataset containing only the EoS, the methods should be able to remove this effect and the classification performance should be at the chance level, i.e. balanced accuracy (bACC) of 50%. On the other hand, in the dataset with only the True signal, the harmonization models should not degrade the signal, and the bACC is expected to be a high value (bACC \u2248 80%)."}, {"title": "MRI data", "content": "To empirically compare different harmonization schemes with and without site-target dependence, age regression, and sex classification were performed using MRI data. These targets were used as they are highly reliable and can be easily obtained. For all T1-weighted MR images, Voxel-Based Morphometry was performed using CAT12.840 to obtain modulated gray matter (GM) volume, which was then linearly resampled to 8x8x8 mm3 voxels, resulting in 3747 voxels that were used as features. Five datasets were used: Amsterdam Open MRI Collection (AOMIC-ID1000)41, The Enhanced Nathan Kline Institute (eNKI)42, Cambridge Centre for Ageing Neuroscience (CamCAN)43, 1000Brains44, and the Southwest University Adult Lifespan"}, {"title": "0.2.4.1 Forced site-target dependence.", "content": "Four datasets, AOMIC-ID1000, eNKI, CamCAN, and 1000Brains, were randomly subsampled in different age ranges forcing a site-target dependence. The subsample was performed to ensure the same amount of subjects by each sex in each dataset."}, {"title": "0.2.4.2 Forced site-target independence.", "content": "Three datasets, CamCAN, eNIKI, and SALD, were used. The datasets were selected as they contain individuals covering a wide range of ages above 18. The AOMIC and 1000Brains datasets were excluded as those datasets mainly included young and old participants, respectively. Each dataset was balanced in terms of sex and age. This was achieved by retaining the same number of subjects for each sex in 10 equally distributed age ranges, from the minimum to the maximum age in each dataset."}, {"title": "0.2.5 Sex classification", "content": "For this experiment, only the eNKI and CamCAN datasets were used, as those present a broad and similar age range. In this case, the percentages of females in each dataset were forced to be 95% in eNKI and 5% in CamCAN. Additionally, the same number of images for each dataset was retained."}, {"title": "0.2.5.1 Forced site-target independence", "content": "The same dataset generated in the site-target independence scenario for age regression was used for sex classification."}, {"title": "0.2.6 Dementia and mild cognitive impairment classification", "content": ""}, {"title": "0.2.6.1 Forced site-target dependence", "content": "Using the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, where the data were acquired in different sites, we selected 100 dementia-MCI patients and 10 controls from one site. We selected 100 control patients and 10 dementia-MCi patients from another site, again forcing the site-target relationship. The images were processed with FreeSurfer46. The thickness from 74 cerebral and sub-cerebral structures were extracted as features."}, {"title": "0.2.6.2 Forced site-target independence", "content": "Using the ADNI dataset the same extracted features were used. From the dataset, 126 dementia-MCI and control patients were randomly selected from the first site while 56 dementia-MCI and control patients were randomly selected from the second site."}, {"title": "0.2.7 Discharge status prediction of septic patients", "content": ""}, {"title": "0.2.8 Forced site-target dependence", "content": "The eICU31,32,47 dataset was used for the experiments, which contains 200859 ICU stays from 139367 patients in 208 different ICUs across the United States. We use a well-known problem of classified hospital discharge (Expired or Alive), in septic patients 48,49. The approach described in39 was followed for selecting the features and extracting the patient cohort. The features used were arterial blood gases: paO2, paCO2, pH, base excess, Hgb, glucose, bicarbonate, and"}, {"title": "0.2.9 Forced site-target independence", "content": "From the elCU, the same features extraction and patient selection were made (496 Expired and 3021 Alive patients). The same 20 sites, with more than 50 images, were used.\nFrom all sites, the same number of \u201cAlive\u201d and \u201cExpired\u201d patients were retained. A total of 324 Expired and 324 Alive patients were used in this experiment."}, {"title": "Methods", "content": ""}, {"title": "PrettYHarmonize", "content": "The proposed method rests on the use of \u201cpretended\u201d target values on the harmonization process, thereby enabling predictions without requiring test target values. For our experiments, the available data is divided into train and test, simulating a real use case. The training fold is further divided into inner train and validation folds. A neuroHarmonize model is trained on the inner training data to learn to remove the site's effect. The inner training data is harmonized and a Predictive model is trained on the harmonized inner train data to predict the target. This model needs to be chosen as the best possible model to solve the problem at hand.\nUsing the trained neuroHarmonize model, the validation samples are harmonized while \u201cpretending\" their target value. For example, for a binary classification problem, all the validation labels are set as the first class, pretending that all validation samples belong to the first class. Using these \u201cpretended\u201d labels, the validation data is harmonized and a prediction is made using the trained Predictive model. Later, the validation labels are set to the second class and the validation data is harmonized again and a new prediction is generated. In general, for a classification task, the set of available classes is pretended, while for a regression task, the values are linearly sampled in the target's range. All the predictions, generated with the pretended harmonized data, are concatenated and a \u201cScore matrix\u201d is created. This matrix has a dimension of number of validation samples times the number of labels. To effectively utilize the training dataset, a K-fold cross-validation (CV) procedure was employed, generating out-of-sample predictions for the entire dataset. Using this Score matrix as input features, a \u201cStack\u201d model is trained to predict the target and give a final prediction.\nAt the test time, when the test label is not available, the same procedure is followed. For example, in a binary classification problem, a test sample will be harmonized using the neuro-Harmonize model first pretending that the test label belongs to the first class. The Predict model will generate a prediction using the harmonized data and the process will be repeated pretending the test sample belongs to the second class. Both predictions generated by the Predictive model are concatenated and a test Score matrix is built. This matrix is used by the Stack model, which generates the final prediction."}, {"title": "Declaration of interests", "content": "The authors declare no competing interests."}]}