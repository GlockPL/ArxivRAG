{"title": "EA-RAS: Towards Efficient and Accurate End-to-End Reconstruction of Anatomical Skeleton", "authors": ["Zhiheng Peng", "Kai Zhao", "Xiaoran Chen", "Li Ma", "Siyu Xia", "Changjie Fan", "Weijian Shang", "Wei Jing"], "abstract": "Efficient, accurate and low-cost estimation of human skeletal information is crucial for a range of applications such as biology education and human-computer interaction. However, current simple skeleton models, which are typically based on 2D-3D joint points, fall short in terms of anatomical fidelity, restricting their utility in fields. On the other hand, more complex models while anatomically precise, are hindered by sophisticate multi-stage processing and the need for extra data like skin meshes, making them unsuitable for real-time applications. To this end, we propose the EA-RAS (Towards Efficient and Accurate End-to-End Reconstruction of Anatomical Skeleton), a single-stage, lightweight, and plug-and-play anatomical skeleton estimator that can provide real-time, accurate anatomically realistic skeletons with arbitrary pose using only a single RGB image input. Additionally, EA-RAS estimates the conventional human-mesh model explicitly, which not only enhances the functionality but also leverages the outside skin information by integrating features into the inside skeleton modeling process. In this work, we also develop a progressive training strategy and integrated it with an enhanced optimization process, enabling the network to obtain initial weights using only a small skin dataset and achieve self-supervision in skeleton reconstruction. Besides, we also provide an optional lightweight post-processing optimization strategy to further improve accuracy for scenarios that prioritize precision over real-time processing. The experiments demonstrated that our regression method is over 800 times faster than existing methods, meeting real-time requirements. Additionally, the post-processing optimization strategy provided can enhance reconstruction accuracy by over 50% and achieve a speed increase of more than 7 times.", "sections": [{"title": "I. INTRODUCTION", "content": "Estimating and modeling the human skeletal system is crucial for various applications [1]\u2013[3], including robotics, gaming, person re-identification, and etc. Most skeletal reconstruction work uses interconnected keypoints with lines to represents human skeleton [4]\u2013[6]. This representation enables the recognition of semantic postures and actions such as sitting, standing, and running. However, the simple representation fails to describe the anatomical details of real human skeletons. For applications in biological fields like physical therapy robots [7], [8], biological education [9], and game simulations [10] that requires accurate skeletal reconstruction, the abovementioned methods could be insufficient. As is well known, obtaining the accurate skeleton information requires the medical equipment, such as dual-energy X-ray absorptiometry (DXA). But such an equipment is expensive, poses radiation risks, and is not suitable for use in daily environments. Therefore, researchers have introduced anatomical skeletal reconstruction. Various methods can be used to reconstruct the anatomical structure through modeling and simulation [11]\u2013[14]. While incorporating complex anatomical constraints to ensure realism, these methods have encountered a trade-off, leading to an inability to fulfill real-time processing requirements. To address these limitations, this work focus on lightweight anatomical skeletal reconstruction, which uses low-cost visual methods to generate accurate skeletal reconstruction results at a faster speed.\nA primary challenge in employing conventional end-to-end training methods for lightweight anatomical skeletal reconstruction is the collection of data. Due to privacy concerns and medical ethical restrictions, there is currently a lack of large-scale real data mapping DXA images to anatomical skeletons. Moreover, because of the complex structure of the actual skeleton and the connection between bones and skin, manually labeling RGB images directly can be challenging.\nIn response to the abovementioned limitations, several multi-stage methods can also successfully achieve this task without using the end-to-end single-stage method. For instance, researchers can predict human skin mesh from images"}, {"title": "II. RELATED WORK", "content": null}, {"title": "A. Skeleton Reconstruction by Keypoints", "content": "Existing skeletal reconstruction methods mainly emphasize action recognition and pose estimation, rather than predicting the physiological state of bones. The typical method for representing poses is to display human joint positions through 2D keypoints that show body movement. Earlier exploration of human pose heavily relied on handcrafted features [24], [25]. Recently, many deep learning-based methods have been employed to significantly enhance the performance of human pose estimation [26]\u2013[28]. In terms of network architecture, these methods are mainly divided into two categories: single-stage methods [29], [30] and multi-stage methods [31], [32]. Single-stage methods primarily involve training a backbone network for image classification to generate heatmaps or corresponding offsets for human keypoints, thereby obtaining the final estimation of keypoints [30]. Multi-stage methods predict image keypoints and then associating these keypoints with human instances [33]. Wei et al. [32] use detectors to locate individuals, followed by using convolutional encoders to accomplish joint dependency and sequential prediction [31], [32]. As the emerging of transformers, the above method has also achieved significant performance improvements. TransPose [34] utilizes CNN-extracted features to directly capture the overall relationship. TokenPose [35] introduces additional tokens to estimate occluded keypoint locations and model inter-keypoint relationships through token-based representations. However, these methods require a large amount of annotated data for training. Although current 2D keypoints exhibit good performance, the mere keypoints makes it difficult to construct the internal skeleton structure effectively."}, {"title": "B. Skeleton Reconstruction by Anatomical Models", "content": "Most approaches to obtaining skeletal anatomical models are achieved by supervising the sparse correspondence between the outer skin and the inner part of the skeleton, such as [36], [37]. Some work achieves a dense displacement field for the physical pose by completing regularization [38], [39]. AT [12] proposes the first semi-automated method for creating anatomy, passing it into the target skin while preserving the skeletal structure, and mapping the internal anatomy of the source model by harmonic deformation. Based on this, [40] adds constraints to position the bones inside. Although these methods have shown the more detailed approach for local modeling, the complex constraints, displacement fields and the complex calculation of interpolation processing have brought serious shortcomings in universality. In addition, these methods are not validated on real data. OSSO [13] uses the DXA scan data to convert the body shape model to the inside skeleton. However, the body model must be obtained in advance, and the pose adaption requires a large optimization time.\nAlthough anatomically informed skeletal reconstruction techniques offer high fidelity in depicting physiological skeletal structures, the high computational demands and prerequisite body model specifications they require make their application in real-time settings challenging."}, {"title": "C. Human Body Recovery", "content": "As mentioned in previous section, inferring the anatomical skeleton may require human body models and prior information. There are some methods to recovery the human body from RGB images, roughly divided into two categories: optimization-based and regression-based. To estimate a 3D body skin mesh that contains human pose and shape, the optimization-based approach involves forecasting the pertinent parameters and necessitates alignment with two-dimensional observational data.\nEarly work [41], [42] based on SCAPE restricted the area of pixels and punished non-overlapping conditions. SMPLify [43] minimizes the reprojection error between 2D joints and SMPL joints and uses several regularization terms to keep the joint rotation and shape naturally. However, the optimization-based method is sensitive to the initial value and has iteration time overhead. Xiang et al. [44], Hassan et al. [45], Zhang et al. [46] analyzed the relationship between the image and the objects related to the human body. The regression-based method directly predicts the human body model through deep learning. The parametric output methods regress the parameters of models and use them to reconstruct the human body [47]. The non-parametric methods predict the mesh vertices [48], [49] or body shape [50], and then fit them to a human model [51]. With the development of Transformer [52] in recent years, many human reconstruction methods based on it have also achieved good results [52]\u2013[54]. Moreover, some work has implemented more effective supervision and introduced alignment constraints, such as meshes aligned [55], surface landmarks [22], pose keypoints and contours [56], semantic part segmentation [57] or raw pixels [58].\nAlthough these methods provide significant skin information, errors in the body recovery process can interfere with the subsequent skeleton reconstruction, leading to inaccuracies. Additionally, the statistical relationship between the skin and the internal skeleton has not been fully taken into account in the body recovery stage, potentially resulting in information loss during the skeleton reconstruction stage."}, {"title": "III. METHODOLOGY", "content": "As shown in Figure 2, the proposed one-stage method uses optimization to achieve self-supervision of regression results and efficiently complete the parameters prediction of human and skeleton. The human and skeleton information is fused both in regression (HTS) and optimisation (OHTS)."}, {"title": "A. Human Modeling", "content": "Human Body Model: SMPL [59] provides a parameterized human model $HM(\\beta_{body}, p)$ with a learned human skin. The reconstruction is completed with 6,890 vertices using the pose parameter $p$ and the shape parameter $\\beta_{body}$.\nAnatomical Skeletal Model: In order to move, rotate and scale the bones freely and flexibly, we use the stitched puppet [60] model with anatomical skeleton. The stitched puppet provides an ideal graphic model formula and is conducive to optimization under anatomical constraints. Skeleton model $SM(\\beta_{skel},t,r)$ can be obtained by providing the skeleton shape parameter $\\beta_{skel}$, the translation parameter $t$ and rotating parameter $r$. Similar to the human body model, the skeleton vertexes can determine the position of skeleton joints."}, {"title": "B. Network Structure", "content": "1) Human To Skeleton (HTS) Matching Module:\na) Module Structure: To make the model understand the mutual inference relationship between the anatomical skeleton and the human body, we designed the HTS (human body to skeleton) module.\nAs shown in Fig 2, the Convolutional Neural Network (CNN) is utilized to extract features from RGB images, generating shared features (a). Subsequently, a is combined with parameter information (skeleton and human). Initially, these features are initialized from the mean parameter model. The combined feature is then forwarded to a regressor to obtain the human and skeleton parameters. These parameters are also fed back to the combined feature for further iterations. This iterative process can be repeated N times to derive the ultimate human (SK) and skeleton parameters (SP). In more detail, the camera parameters $cam$ are the same for both the skin and bones. These parameters are integrated into the human body parameters, denoted as $SP = \\{cam, \\beta_{body}, P\\}$, and $SK = \\{t,r\\}$. The parameter $(\\beta_{skel})$ for adjusting the shape of the skeleton $(SM(\\beta_{skel}, SP))$ is generated by $\\beta_{body}$, with further details described subsequently.\nThe parameter extraction of human body is detailed as:\n$\\Theta_{reg}^i = R_{body}(concat(a, \\Theta_{reg}^{i-1}))$                                                   (1)\nwhere $R_{body}$ is the self-regressor for the human body branch in HTS. $\\Theta_{reg}^{0}$ represents the initial parameter value of standard human and initial camera parameter. $i \\in [1,3]$ means current number of regression iterations.\nSimilarly, deviation from the human body parameters is to obtain the skeleton parameter:\n$\\Xi_{reg}^{i-1}= R_{skeleton}(concat(a, \\Xi_{reg}^{i-1}, \\Xi_{res}^{i-1}))$                                                         (2)\nwhere $R_{skeleton}$ is the self-regressor for skeleton parameter in HTS, and $\\Xi_{reg}$ is the skeleton parameter in SK(.) including the translation $t$ and rotation $r$ parameters. $\\Xi_{reg}^{0}$ is set to zero before the training.\nb) Bidirectional Adjustment: The human body parame- ters are obtained through the regression network, and the loss function is:\n$L_{hum} = \\lambda_{hj} || J_{reg} - J_{gt}|| + L_{e}$                                                    (3)\nwhere $\\lambda_{hj}$ is the weight. $J_{reg}$ represents the 2D joints obtained by reprojecting the 3D joints to the image using the predicted camera parameters. The $J_{reg}$ is forced to align with $J_{gt}$ which represents the ground truth 2D joints. $L_{e}$ is the straight supervision of human parameters calculated in the following optimization step.\nIn addition, we can also perform the regression to infer the skeleton joints position to provide posture supervision. However, rather than the common human keypoints in human body model, the anatomical skeleton joints are more complicated."}, {"title": "2) Optimized Human To Skeleton (OHTS):", "content": "a) Module Structure: As shown in Figure 3, the human body ($SP = \\Theta_{reg}$) and skeletal parameter ($SK = \\Xi_{reg}$) obtained by HTS is recombined and supervised in this process. In the figure, solid and dashed lines represent the forward chaining and the supervision processes, respectively. To be more specific, we construct the human body model $HM(\\Theta_{reg})$ and skeleton model $SM(\\Xi_{reg})$ through the HTS module. Then the HM(.) generates body keypoints $J$ and projects them to the image using camera parameter $cam$. The 2D ground truth $J_{gt}$ of the skin dataset provides supervision. Meanwhile, skeleton keypoints $L$ are supervised by the ground truth $L_{gt}$ by Anatomical joint reg module.\nThis module, derived from work [13], trained with real data, and map human body $HM(.)$ to keypoints $L$ through Vertices Attention Map. Similarly, the shape parameters $(\\beta_{skel})$ of the skeleton (SK) is inferred through the keypoint prediction matrix (KP):\n$\\beta_{skel} = KP(\\beta_{body})$                                                             (5)"}, {"title": "Obtain Skeleton Fast (OSF+)", "content": "Inspired by OSSO [13], We propose the OSF (Obtain Skeleton Fast) to speed up the optimization. With the T-pose state skeleton as the initial state, the whole process of OSSO passes through three stages: register body point cloud to model, inferring the skeleton to lying human, and jointly optimize body with skeleton to the input pose. This approach incurs significant overhead and presents challenges when integrated into regression-based networks. The proposed OSF uses the skeleton regression prediction as the initial value, which is a single-stage process, and extracts the important anatomical constraints mentioned in OSSO with the transfer puppet loss [61]. The final objective function is:\n$\\begin{aligned} E(t, r) = & \\lambda_{l} ||L_{skel}(SM(\\beta_{skel}, t, r)) - L_{body}(HM(\\beta_{body},P))|| \\ & + \\lambda_{ct} E_{ct}(\\beta_{skel}, t, r; SM_{0}) + \\lambda_{j} E_{j}(\\beta_{skel}, t, r; SM_{0}) \\ & + \\lambda_{clv} E_{clv}(\\beta_{skel}, t, r; SM_{0}) \\end{aligned}$                                                             (7)\nwhere $L_{skel}(.)$ represents the joints obtained from the skeleton, and $L_{body}(.)$ represents the joints inferred from the human body mesh. $SM_{0} = SM(\\beta_{skel}^{opt}, t_{0}, r_{0})$ represents the skeleton with the initial standard T-pose and the inferred shape. $E_{ct}(.)$ is the anatomical constraint which is designed of more than 3,000 points to restrain the relative distance of skeletons [13]. $E_{j}$ is the penalization term to ensure the same connection distance between different bones. $E_{clv}$ means the anatomical constraints of the clavicle relative to the thorax. $\\lambda$ represents corresponding weight coefficients. The first term in Equation 7 establishes a robust linkage between the skeletal structure and the human form. Subsequent terms concentrate on the skeleton's intrinsic properties, compelling it to adhere to anatomical constraints. In Figure 4 (Cost Control), we visualize the constraint about control point connections (red), human body cross-sectional view (green), MP (blue), and comprehensive vertices (deep blue), respectively.\nIn this function, we optimize the shape parameters of skeleton $\\beta_{skel}^{opt}$ to represent the corresponding shape relationship between different human body and skeletons, which is achieved through the following formula:\n$\\beta_{skel}^{opt} = \\beta_{skel} + \\gamma(\\beta_{min} + \\beta_{max})/2$                                                                       (8)\nwhere $\\beta_{min}$ and $\\beta_{max}$ are the maximum and minimum parameters for the skeleton model $SM(.)$. $\\gamma$ is optimized to adjust vertex displacement between the different shapes. As mentioned above, the KP which to get $\\beta_{reg}$ is also optimized.\nFor the exploration of this method, we progressively designed four different optimization processes (OSSO*, OSSO**, OSF, OSF+) to get the skeleton from the obtained human body. The details of the four specific methods are introduced in the experiment section. Here we only briefly introduce the OSF by Formula 7 and OSF+ used in our model training and prediction method. OSF used the model parameters obtained by network regression, while OSF+ is an extra option to improve the accuracy and speed. It removes supervision of the last three terms in Formula 7 and"}, {"title": "3) Self-Supervision:", "content": "Our model performs multi-steps joint optimization and supervision processes for the skeleton learning process. In order to achieve self-supervised single-stage methods, we generate regression supervision through optimization methods. The optimization only requires the rule-based information to generate the supervised values for reconstruction. By employing different optimization methods for the human body output and skeleton output, we achieve complementary advantages of both optimization and regression. This enables one-stage inference and training for the skeleton without the need for additional labels."}, {"title": "SMPLify", "content": "After the human body regression process, an optimization process is adopted to supervise the related parameter directly. Here we use the SMPLify [43], which is similar to the work of SPIN [23]. As in Equation 3, the optimization process is used to obtain the $L_{e}$, which can be calculated as follows:\n$L_{e} = ||\\Theta_{reg} - \\Theta_{opt}||$                                                                (6)"}, {"title": "C. Training and Inference", "content": "The entire training process is carried out in an end-to-end method. Specifically, the entire loss function satisfies the following formula.\n$L_{entire} = L_{hum} + L_{skel}$                                                             (9)\nwhere $L_{hum}$ is the loss of human mesh and $L_{skel}$ is the loss of skeleton mesh.\nTo improve the train efficiency, we propose a progressive training method, including the position demonstration stage (stage one), weak supervision stage (stage two), and collaborative improvement stage (stage three).\nIn stage one, we train the model using a subset of a smaller dataset, and use the final value as the ground truth after multiple iterations of skeleton optimization. In this stage, model convergence quickly about the skeleton roughly position. During the weak supervision stage, we gradually weaken"}, {"title": "IV. EXPERIMENTS", "content": null}, {"title": "A. Experiment Setup", "content": "Datasets: We use a small-scale LSP [16] skin dataset to train the network. To evaluate the effectiveness of the proposed skeletal self-supervised training method, we also tested it on the large-scale 3DPW [15] dataset.\nTraining details: Our three-stage progressive approach involves updating parameters in the Equation 4 during training. In the position demonstration stage (stage 1), our model is firstly trained on the 50% LSP [16] for 500 epochs. In this state, we set $\\lambda_{l} = 0$, $\\lambda_{r} = 0.1$, and $\\lambda_{t}$ is set to 10 to adjust the model learning of skeleton locations and features. In the weak supervision stage (stage 2), we increase $\\lambda_{l}$ to 10, proving that the network can understand the correlation between skeletons in the training stage and ensure the connectivity between skeletons. In the collaborative improvement stage (stage 3), we restore $\\lambda_{l} = 5$, $\\lambda_{r} = 0.1$, $\\lambda_{t} = 10$, and perform training on whole LSP to ensure the generalization of the network and avoid overfitting. Optimizer is set to Adam, and the initial learning rate is set to le-5, which is attenuated 0.9 times every 1500 steps.\nExperimental platform: Experiments are performed on a single workstation with 4.20 GHz Intel I7 CPU and NVIDIA 2080.\nEvaluation metrics: The performance of our method on datasets is shown in Figure 6. In the following section, we quantitatively analyze skeleton reconstruction using metrics such as computation time, reconstruction error, and $D_{mean}$ (Euclidean Distance). For the generated human body skin, we evaluate it using common Per Vertex Error (PVE) [63] and Mean Per Joint Position Error (MPJPE) [64] metrics for comparison. Additionally, we analyze the time consumption of our proposed iterative optimization method. Moreover, we qualitatively evaluate some representative examples and share the results."}, {"title": "B. Comparison with the Relevant Methods", "content": "1) Skeleton Reconstruction Result: To test our approach, we use the human body skin mesh from the 3DPW dataset [15], and obtained the skeleton ground truth using the same method as OSSO [13]. We conduct the experiment with two groups: one group uses a multi-stage skeleton reconstruction method with OSSO [13] completing the bone generation part and different methods [65]\u2013[67] for skin reconstruction, while the other group uses our single-stage method EA-RAS with optional subsequent optimization. As shown in Table I, our method produces regression results of 83.2mm, 68.1mm with OSF+, and 34.7mm with the OSF full version (PLUS). EA-RAS achieves comparable accuracy to multi-stage based methods but significantly outperforms them in speed, completing the task in only 0.2 seconds compared to 173.0 seconds, over 800 times faster. Our OSF+ and PLUS versions significantly reduced reconstruction errors by up to 34.7mm compared to the previous 73.1mm, representing a more than 50% improvement. Additionally, the speed increased by over 7 times (173.0 / 23.0). The experimental results show that our method significantly improves the speed to meet real-time requirements. For scenarios with low real-time demands, our method greatly enhances accuracy while still ensuring effective speed improvement.\nTo further demonstrate our method, we also conduct skeletal comparison experiments on the LSP dataset. As the LSP [16] dataset does not contain human body mesh, we annotate skeletal point regression using EA-RAS's human body mesh to obtain ground truth. For fairness, we utilize the human body mesh obtained from EA-RAS for the mesh input required by OSSO [13]. Results is reported in TABLE II. It can be observed that, with minimal difference in regression results, the introduction of our designed OSF+ resulted in a reconstruction error of 49.6mm (vs. 52.9mm) within 5.2 seconds (vs. 140.8 seconds). Our PLUS version has achieved a reconstruction error of 6.4mm (vs. 52.9mm) within 22.8s (vs. 140.8s). Our optimization phase effectively integrates and guides the network, constraining and defining the search space during the learning process, resulting in closer outcomes. The method effectively combines the network and optimization.\nTo verify the difference with real skeleton, we verified on a bone density data. As shown in Figure 7, the model input is the DXA image of the human body (as shown in the image at the upper left corner of the figure).\nWe control the threshold for the DXA image and obtain the bone density map. Because the DXA image is human anatomy illustration, it cannot clearly present the external human body. This error cause the OSSO algorithm to deviate from the correct skeleton because it relying on a correct human mesh in advance. Although the real bone density map cannot fully show the external contour of the bone subject to the physical occlusion of the machine, our output results are still 0.03 higher than the OSSO output and mask similarity.\nThe skeleton model of the EA-RAS is directly deduced from the original image, in contrast to the OSSO model, which is generated based on the outcomes of human body reconstruction. As depicted in Figure 8, our model aligns more"}, {"title": "2) Lightweight Skeleton Optimization:", "content": "As described in the Methodology section, we aim to develop a lightweight self-supervised approach for training regression skeletal parameters. We improve lightweight and optimization strategy to enhancing the speed.\nThe following comparison versions are set:\nOSSO [13]: The original OSSO method has three steps: register body mesh point cloud to STAR model, infer the skeleton shape of lying pose and optimize the skeleton to the input pose.\nOSSO* (Ours): To speed up the OSSO process, we remove step-3 in OSSO, just fit the input mesh to the STAR model with the corresponding pose directly, and then infer the skeleton.\nOSSO** (Ours): To avoid unconstrained shift of skeleton position, the necessary migratory puppet [61] loss mentioned in OSSO step-3 and clavicle joint control was added to OSSO*.\nOSF (Ours): We skipped the process of registering STAR parameters from human mesh in OSSO**, and directly used the model parameters obtained by network regression and passed through transition.\nOSF+ (Ours): It is once option to improve accuracy and speed. It removes supervision of the last three terms in Formula 7 and optimizes only once after the regression."}, {"title": "C. Ablation Study", "content": "1) Progressive training method: For the proposed three-stage progressive training method, we compare it with the direct training method (i.e. supervised the network with ground truth during the whole stage). Figure 10 displays the time consumption for ablation comparison experiments. We examine the effect of varying batch sizes on speed and depicted the loss convergence results in the same figure.\nBy gradually improving the network results step by step in a forward iterative manner, we find the process can lead the network convergence quickly and stably, while the direct data-driven method may lead to the unstable training effect. The experimental results show that the proposed progressive training process helps the network gradually learn information, reduces the complexity of the search process, and avoids the overfitting."}, {"title": "2) Extra Optimization Performance:", "content": "Given that the input image provides solely two-dimensional information, the skeletal connections are inherently decoupled. Minor visual artifacts"}, {"title": "3) Skeleton Helps Human Reconstruction:", "content": "As previously discussed, the reconstruction of anatomical skeletons necessitates the integration of skin surface data. In this section, we delve into the potential of the skeleton reconstruction process to concurrently enhance the precision of human body skin reconstruction. To this end, we conduct ablation studies utilizing the 3DPW dataset [15], thereby assessing the interplay between skeletal and skin reconstruction accuracy.\nTable V show the results of three sets of experiments. The first set involved removing the skeletal branch from the original model and predicting human and camera parameters directly. In the other two sets, we assessed if the skeletal branch could offer improved initial values for different human body optimization algorithm. The results show that the branch with skeletal reconstruction can achieve better skin reconstruction effects. This suggests that in our model, the intrinsic information represented by the skeleton and the extrinsic information represented by the skin has been effectively fused. Benefit from the anatomical position of the bones, the process of extracting bone features helps to refine and decompose human features. This process plays a crucial role in human prediction. Figure 12 shows the attention map of $\\beta$, pose, and cam parameters and find that EA-RAS is more focused on the position of the human compared with the case of reconstruction of branch roads by a single human body."}, {"title": "D. Visualization of Training and Optimization Process", "content": "The human body and skeleton output are decoupled structures. While ensuring the correlation, our HTS has well inte-"}, {"title": "E. Application and Portability Experiment", "content": "To further validate the proposed method, we conduct user studies with a robot massage application [7], [81], [82]. In this application, accurately locating the acupoints is a key requirement, since acupoints are typically located along the visceral meridians circulating around the skeleton and vertebrae in the human body [83], [84]. Precise identification of these acupoints is referred to as the Acupoint Recognition (OAR) problem. Previous methods [7], [85], [86] typically employed key point recognition algorithms to identify skeletal key points, thereby obtaining acupoint information. We view the OAR problem as a novel assessment of skeletal precision."}, {"title": "V. CONCLUSION", "content": "In this paper, we propose a single-stage, lightweight, and plug-and-play anatomical skeleton estimator, which achieves real-time, accurate anatomically realistic skeleton reconstruction with arbitrary pose using only a single RGB image input. We also introduce a dual-branch mechanism to fuse skin information in the skeleton estimation process to avoid the information loss and inaccuracies that exists in multi-stage methods. The dual-branch mechanism considers the human anatomical constraints and forms a tight connection between the human body and the anatomical skeleton. Moreover, we propose a three-stage progressive training method to eliminates the need for complex full skeleton annotation and ensure fast convergence. our training method can achieve self-supervision subsequently through a enhanced optimization process. Experiments show that our method has significant advantages over the relevant methods in terms of speed and accuracy."}]}