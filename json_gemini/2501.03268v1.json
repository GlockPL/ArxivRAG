{"title": "Heterogeneous Graph Pre-training Based Model for Secure and Efficient Prediction of Default Risk Propagation among Bond Issuers", "authors": ["Xurui Li", "Xin Shan", "Wenhao Yin", "Haijiao Wang"], "abstract": "Efficient prediction of default risk for bond-issuing enterprises is pivotal for maintaining stability and fostering growth in the bond market. Conventional methods usually rely solely on an enterprise's internal data for risk assessment. In contrast, graph-based techniques leverage interconnected corporate information to enhance default risk identification for targeted bond issuers. Traditional graph techniques such as label propagation algorithm or deepwalk fail to effectively integrate a enterprise's inherent attribute information with its topological network data. Additionally, due to data scarcity and security privacy concerns between enterprises, end-to-end graph neural network (GNN) algorithms may struggle in delivering satisfactory performance for target tasks. To address these challenges, we present a novel two-stage model. In the first stage, we employ an innovative Masked Autoencoders for Heterogeneous Graph (HGMAE) to pre-train on a vast enterprise knowledge graph. Subsequently, in the second stage, a specialized classifier model is trained to predict default risk propagation probabilities. The classifier leverages concatenated feature vectors derived from the pre-trained encoder with the enterprise's task-specific feature vectors. Through the two-stage training approach, our model not only boosts the importance of unique bond characteristics for specific default prediction tasks, but also securely and efficiently leverage the global information pre-trained from other enterprises. Experimental results demonstrate that our proposed model outperforms existing approaches in predicting default risk for bond issuers.", "sections": [{"title": "I. INTRODUCTION", "content": "Bond issuer default risk, a critical aspect of financial anal-ysis, refers to the likelihood that the enterprise which issues a bond will become unable to fulfill its financial obligations, leading to a default [1]. To make informed investment deci-sions and maintain market stability, it is crucial to comprehend and assess this risk. When assessing default risk for a bond issuer, traditional methods usually utilize its own operational data for prediction. However, real-world risk encompasses various factors such as the issuer's financial health, market conditions, industry-specific risks, and overall economic sta-bility, etc. There are often intricate interconnections among enterprises, leading to the spread of risks across the bond issuer landscape [2].\nTo effectively utilize information from associate enterprises to assist in assessing default risk for a target enterprise, a common approach is to employ graph-based risk propagation methods such as label propagation algorithm. However, these algorithms merely propagate known risk labels across the graph without effectively incorporating the inherent charac-teristics of each enterprise into the comprehensive prediction. To address this issue, one solution is to leverage graph embed-ding information besides the enterprises' own features when predicting risk propagation probabilities. While this approach merges the enterprises' inherent traits with their relational topology to some extent, it awkwardly combines these two types of information without fully capturing the dynamic propagation and evolution effects of the enterprises' features upon the entire corporate network structure.\nThe recently popular graph neural network (GNN) methods such as GAT or Graphsage can well learn the diffusion pattern of node features in the graph [3]. However, there are several problems with directly using end-to-end GNN algorithms for our scenario. On the one hand, the performance of existing GNNs significantly suffers when distribution shifts occur between training and testing data, or when data scarcity is present. Bond issuers, typically large or even listed enterprises, possess a wealth of business information. However, other non-bond enterprises in the massive graph often lack such detailed features. GNN algorithms struggle to learn effective information from this kind of graph for training specific risk propagation tasks, because they cannot fully leverage the differences between bond issuers and other enterprises. On the other hand, in terms of security and privacy, it is not advisable for some information providers to disclose detailed operational information of related enterprises to business parties.\nIn this paper, we present a two-stage framework that uti-lizes graph pre-training techniques to predict the propagation probability of default risks among bond issuers. Initially, our model is pre-trained on a comprehensive enterprise knowledge graph (EKG). Subsequently, the embedding from the pre-trained encoder is combined with the unique information of the bond-issuing enterprise to train the default risk prediction model. The main contributions are summarized as follows:\n\u2022 The proposed two-stage method can not only safely and effectively utilize the encrypted information from the massive"}, {"title": "II. RELATED WORKS", "content": "Pre-trained Graph Embeddings. The first-generation pre-trained graph models aim to produce effective graph embed-dings for diverse tasks [4]. DeepWalk, a pioneer in this field, introduced the concept of graph embedding by treating the paths traversed by random walks over graphs as sentences. It utilizes skip-gram to learn latent node representations. Following in DeepWalk's footsteps, Node2vec developed a flexible approach to define a node's network neighborhood and designed a biased random walk procedure to efficiently explore diverse neighborhoods. Furthermore, several researchers have also attempted to learn embeddings for heterogeneous graphs, sub-graphs, and molecular graphs, such as sub2vec [5], sub-graph2vec, etc.\nPre-trained Graph Encoders. With the emergence of expres-sive GNNs and Transformer, recent methods have embraced a transfer learning setting where the goal is to pre-train a generic encoder that can deal with different tasks. Compared to the pre-trained graph embedding methods, pre-trained graph en-coders can provide a better model initialization, which usually leads to a better generalization performance and speeds up convergence on the target tasks. In addition, the modern mod-els are usually trained with larger scale database, more pow-erful or deeper architectures, and new pre-training tasks [4], [6]. Their architectures broadly fall into two categories: graph neural networks (e.g., GIN, HAN) [7] and hybrid of GNNs and Transformer (e.g., MPG, HGT) [8]. Their pre-training strategies can be widely divided into supervised and unsu-pervised ones. Although the supervised pre-training brings remarkable improvements, they often require domain-specific knowledge which significantly limits their wider applications. More importantly, some supervised pre-training tasks might be unrelated to the downstream task of interest and can even hurt the downstream performance. As for unsupervised graph pre-training, it can be mainly divided into four categories: 1) Graph autoencoders: typical models such as GAE, VGAE, SIGVAE use self-supervised graph reconstruction for learning discriminative representations [9]. 2) Graph autoregressive modeling: typical models such as GPT-GNN, MGSSL perform the autoregressive reconstruction on given graphs iteratively instead of reconstruct the graph all at once [10]. 3) Masked components modeling: typical model such as GROVER [11] masks out some components from the graph and then trains the model to predict them. 4) Graph contrastive learning: typical models such as InfoGraph [12], GMI [13] use deep infoMax"}, {"title": "III. METHODOLOGY", "content": "Our objective is to predict the defaulting probability of a target bond issuer enterprise when its associated source bond issuer defaults. To achieve this goal, we have employed the following strategies.\nConstruct Enterprise Knowledge Graph. To begin, we develop an extensive enterprise knowledge graph (EKG) as a foundation for graph pre-training [17]. This EKG connects var-ious enterprises through diverse edge types, including \u201cparent-subsidiary\", \"share-investor\u201d, \u201cshare-manager\u201d, \u201cshare-legal-person\" and \"invest-by\u201d, etc. Each enterprise node within this graph is characterized by a set of common properties. These properties range from fundamental business information (such as registered capital and number of employees) to basic operating information like net profit and net income. Furthermore, historical risk features are also involved (such as the number of administrative penalties received and the number of litigations).\nGraph Pre-training. Subsequently, we proceed to implement graph pre-training on the meticulously constructed EKG. Fol-lowing the approach of GraphMAE [18], we adopt feature reconstruction as the core training objective. Specifically, we propose a HGMAE model for heterogeneous graph pre-training. This method entails masking certain features within the graph and then challenging the model to accurately predict and reconstruct these masked attributes, thereby enhancing its understanding and representation capabilities. The backbones of the encoder and decoder for HGMAE can be any type of GNNs and we use GAT [3] here.\nFormally, we implement a procedure where we select a subset of nodes and apply a masking technique by replacing each of their features with the designated mask token [MASK]. The core objective is to accurately reconstruct the masked node features based on the partially observed node signals and the provided input adjacency matrix. We use the scaled cosine error (SCE) for measuring the reconstruction performance. Different from GraphMAE, our model not only implement the feature reconstruction on the whole graph, but also involves the reconstruction for each isomorphic subgraph. As shown in Fig. 1, different edge types are shown in different colors. The first workflow of calculating the reconstruction error $L_{SCE_0}$ for the original graph is the same to that of GraphMAE. For each edge type $e_k$, we obtain its corresponding subgraph $G_k = (V_k, A_k, X_k)$ where $V_k$ is the vertex collection, $A_k$ is the adjacent matrix and $X_k$ is the feature vector. Then we sample a subset of nodes $V'_k \\in V_k$ and mask each of their features with a mask token [MASK].\nTo identify the nodes for masking, we employ a uniform random sampling technique which is instrumental in maintain-ing an unbiased enhancement and recovery of features within\""}, {"title": "IV. EXPERIMENTS", "content": "Dataset. we build the dataset for risk propagation prediction task using real bond-issuing market information of China. Firstly, we build the EKG as described in the methodology section. A total of 6714 bond issue entities are used as seed enterprises for EKG. After 5 round of expansion using different relationships, we form the EGK of more than 20 million nodes. The input dimension of the basic features for graph pre-training is 124. The output embedding size of the graph pre-training model is set to 256. We obtain 3658 propagation pair samples, with half of them are black. We divide 80% of them as training set and 20% as test set.\nResult discussion. The detailed comparisons between our method and other baselines are shown in Table I. It can be found that XGBoost performances the best among the traditional classification methods. Directly using GNN models as classifiers does not perform very well. We then use the XGBoost as the base classifier for the two-stage method. Compared to solutions that only rely on the basic features of the enterprise itself, simple graph embedding methods such as Deepwalk and Node2vec can improve the performance to a certain extent. Graph embeddings output from the pre-trained graph models such as GAE and GraphMAE perform better than that of simple graph embedding. It is because they involve both node features and graph structures during the pre-training. Our method HGMAE outperforms all other methods in the two-stage method. Compared to the previous state-of-the-art method GraphMAE, HGMAE not only calculate the recon-struction error for the original graph, but also implement the mask reconstruction on each separate isomorphic subgraphs. The importance and data distribution of different relationship types are not consistent. If we indiscriminately blend all edges for the purpose of learning, there is a potential that critical information encapsulated in significant edges with a sparse"}, {"title": "V. CONCLUSION", "content": "In this study, we introduce a two-stage framework for predicting the default risk propagation among bond issuers. In the initial phase, we utilize the novel HGMAE model to implement heterogeneous graph pre-training on the extensive enterprise knowledge graph. This approach ensures safe and efficient learning and utilization of the general node represen-tation from a global perspective. Subsequently, in the second stage, we integrate task-specific features with the pre-trained embeddings of both the source and target enterprises to train the risk propagation prediction model. Extensive experimental results demonstrate the efficiency of our two-stage framework, as well as the HGMAE model."}]}