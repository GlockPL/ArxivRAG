{"title": "CAnDOIT: Causal Discovery with Observational and Interventional Data from Time-Series", "authors": ["Luca Castri", "Sariah Mghames", "Marc Hanheide", "Nicola Bellotto"], "abstract": "The study of cause-and-effect is of the utmost importance in many branches of science, but also for many practical applications of intelligent systems. In particular, identifying causal relationships in situations that include hidden factors is a major challenge for methods that rely solely on observational data for building causal models. This paper proposes CAnDOIT, a causal discovery method to reconstruct causal models using both observational and interventional time-series data. The use of interventional data in the causal analysis is crucial for real-world applications, such as robotics, where the scenario is highly complex and observational data alone are often insufficient to uncover the correct causal structure. Validation of the method is performed initially on randomly generated synthetic models and subsequently on a well-known benchmark for causal structure learning in a robotic manipulation environment. The experiments demonstrate that the approach can effectively handle data from interventions and exploit them to enhance the accuracy of the causal analysis. A Python implementation of CAnDOIT has also been developed and is publicly available on GitHub: https://github.com/lcastri/causalflow.", "sections": [{"title": "Introduction", "content": "The increasing complexity of the environments in which future intelligent systems are expected to operate requires an understanding of the cause-effect relations between events, especially those affecting the performance of such systems.[1] Unsurprisingly, Causal Inference has become a crucial analysis across various research domains, including Earth science,[2] healthcare,[3] and robotics. [4, 5] To estimate the causal models that explain the available data, in recent decades many causal discovery algorithms for observational data in static and dynamic scenarios have been developed. [6] That is, causal models are generated relying only on passive observations of the surrounding world, without taking into account the effect of hypothetical interventions. Observational data are often insufficient to retrieve the correct causal model in complex scenarios where it is impossible to account for all the variables responsible for the system's evolution. In such cases, hybrid approaches that incorporate first-principles into data-driven models can potentially improve the quality of the model.[7, 8, 9, 10] Using first-principles models as constraints might reduce the degrees of freedom in causal discovery algorithms and improve the accuracy of their results. However, this approach requires prior knowledge of the system's type or the fundamental physical laws governing its behavior, which can limit the algorithm's versatility. This potential solution has not been widely investigated in the causality community yet. Conversely, an area that has been studied more extensively in the causality community involves using interventional data, i.e., data from experiments, to eliminate spurious correlations and enhance the quality of the causal model. [1, 11] For this reason, recent works have led to the development of algorithms for static (i.e. time independent) data capable of constructing the causal model by leveraging both observations and interventions. [12, 13, 14, 15, 16, 17, 18] To our knowledge though, none of the previously mentioned works conduct causal discovery analysis for time-series data using observations and interventions. This represents a significant limitation for many real-world problems, such as sensor readings or dynamic process monitoring. Therefore, although it is obvious that using intervention information significantly enhances the quality of the causal model,[1, 11] our specific goal is to develop a causal discovery algorithm for time-series data capable of achieving this. Indeed, in this paper we extend and improve a recent state-of-the-art causal discovery for time-series data, LPCMCI,[19] enabling it to retrieve the causal model from both observational and interventional data, which increases the accuracy of the causal analysis. We named our solution CAnDOIT \u2013 CAusal Discovery with Observational and Interventional data from Time-series. The main contributions of this paper are therefore the following:"}, {"title": "Related Work", "content": ""}, {"title": "Observation-based Causal Discovery", "content": "Structural causal models (SCMs) and directed acyclic graphs (DAGs) are at core of causal inference.[20] They both represent system variables and their causal dependencies, the former with mathematical expressions, and the latter with nodes and oriented edges. Various methods have been developed to derive causal relationships from observational data, categorized into three main classes:[6] (i) constraint-based methods, such as Peter & Clark (PC) and Fast Causal Inference (FCI),[21] use conditional independence tests to recover the causal graph; (ii) score-based methods, like Greedy Equivalence Search (GES)[22] and NOTEARS,[23] assigns scores to DAGs and explore the score space accordingly; (iii) noise-based methods, such as Linear Non-Gaussian Acyclic Models (LiNGAM),[24] identify causal structure within variables, assuming linearity, non-Gaussianity, and acyclicity of the model. However, most of these algorithms are applicable only to static data without temporal information, so they are not suitable for many interesting problems in Earth science,[2] healthcare,[3] or robotics.[4, 5]\nTo address this limitation, various causal discovery algorithm have been developed to deal with time-series data.[25] For example, within the area of Granger causality, the Temporal Causal Discovery Framework (TCDF)[26] employs deep neural networks to learn complex nonlinear causal relationships among time-series. However, it faces challenges due to many hyperparameters and lacks a direct way to set the maximum time lags. Among the noise-based methods, there are Time Series Models with Independent Noise (TiMINo)[27] and Vector Autoregressive LINGAM (VARLINGAM).[28] In the score-based methods class, the time-series version of NOTEARS, called DYNOTEARS,[29] has been introduced. In the constraint-based methods category, variations of the FCI and PC algorithms, namely time-series FCI (tsFCI)[30] and PC Momentary Conditional Independence (PCMCI),[31] were tailored to handle time-series data. PCMCI, in particular, has been applied to many research fields, including climate, healthcare, and robotics. [32, 3, 33] Recently, various extension of this algorithm have been introduced. PCMCI+,[34] for example, allows the discovery of simultaneous causal dependencies. Its further extension, Latent-PCMCI (LPCMCI) allows simultaneous causal dependencies and latent confounders.[19] Filtered-PCMCI (F-PCMCI),[35] instead, includes an additional transfer entropy-based feature-selection module to remove unnecessary variables and perform causal discovery only on those responsible for the dynamic evolution of the observed scenario, resulting in faster model generation. Joint-PCMCI+ (J-PCMCI+)[36] enables causal structure learning from multiple observational datasets. Finally, PCMCI\u2229,[37] assumes a finite periodical repetition of causal mechanisms, which is suitable for semi-stationary time-series data.\nDespite dealing with time-series, the above algorithms work only with observational data and cannot handle the theoretical concept of intervention, specifically the so-called do-operator.[1] This operator overrides the structural equations of the intervention variables, disrupting the original dependencies in the observational setting. The concept of intervention is a fundamental aspect of causality. Studying how a variable reacts in response to a forced modification of another variable provides a deeper understanding of the system compared to what simple observations can offer."}, {"title": "Observation and Intervention-based Causal Discovery", "content": "Incorporating interventional data into the causal discovery process differs from its use in other causal problems, like measuring the Average Treatment Effect (ATE).[11] The ATE is a metric employed to evaluate the causal influence of a specific intervention on an outcome, given the presence of a causal model. Conversely, interventional data can be used to enhance the accuracy of the discovery process to find that model. Formally, performing causal discovery on observational data means that the true DAG is only identifiable up to a Markov equivalence class (MEC).[1] However, by incorporating interventional data, identifiability can be improved up to an interventional class (T-MEC),[38] which is a subset of MEC. The same consideration applies when dealing with Maximal Ancestral Graphs (MAGs), where the equivalence class is represented by a Partial Ancestral Graph (PAG), capturing the conditional independence relations among observed variables while accounting for latent variables. For this reason, various algorithms have been developed for causal discovery using both observational and interventional datasets.\nThe Interventional Greedy Sparsest Permutation (IGSP)[38] algorithm has been proposed to learn causal DAGs when both observational and interventional data are available. Its extension, Unknown Target IGSP (UT-IGSP),[39] enables DAGs learning also when the intervention targets are partially or completely unknown. An extension of the FCI causal discovery method has been proposed to enable causal model learning by combining observations and experiments (i.e. soft interventions).[16] This extension has been further improved by \u03a8-FCI to handle unknown intervention targets.[17] Recent neural approaches, such as Differentiable Causal Discovery with Interventions (DCDI)[13] and Efficient Neural Causal Discovery (ENCO),[40] can handle various types of interventional data. An extension of DCDI has also been developed to use latent interventions.[18] The Multiple Interventional Datasets for Efficient Global causal Structure learning (EMIDGS)[15] algorithm learns a causal skeleton using a variant of the PC algorithm adapted to handle multiple interventional datasets simultaneously. It then orients the skeleton by identifying an I-MEC and applies a score function to conduct a greedy search for each causal DAG from each dataset within the remaining search space. Finally, the graphs are merged to obtain the final causal structure. Recently, a novel framework, called Joint Causal Inference (JCI),[14] has been proposed to facilitate causal discovery considering different contexts of the same scenario. The authors elaborate on how this approach can be employed to model interventions as context changes. By exploiting this framework, existing observational causal inference algorithms can be enhanced to learn causal structures from interventional data.\nAll these works, however, conduct causal analysis from observations and interventions on static datasets. As already mentioned, this limitation poses significant challenges for many applications where temporal information cannot be ignored and is crucial for correctly modeling the system. Our approach targets these types of applications and differs from previous solutions as it performs causal discovery on time-series data by incorporating both observations and interventions."}, {"title": "Causal Discovery Based on Observational and Interventional Data", "content": "The solutions proposed in this paper, called CAnDOIT, extends and improves the state-of-the-art causal discovery algorithm for time-series data, LPCMCI, [19] taking inspiration from the way JCI[14] handles interventions with known target. The result is a new algorithm that enables precise causal analysis, using both observational and interventional data, with significantly improved accuracy. Specifically, CAnDOIT extends LPCMCI by performing causal discovery with hard interventions on known targets."}, {"title": "LPCMCI", "content": "The original LPCMCI[19] algorithm is an enhancement of PCMCI+, [34] extending it by removing the causal sufficiency assumption as an initial condition. LPCMCI retains the ability to detect both time-lagged and contemporaneous cause-effect relationships between variables from its predecessors, PCMCI and PCMCI+. Additionally, it relaxes the causal sufficiency assumption, allowing for the inclusion of latent confounders, i.e., unobserved common causes.\nIn more detail, LPCMCI is a constraint-based causal discovery algorithm that begins with a fully connected graph G. The algorithm then proceeds through a preliminary phase, which removes many (though not necessarily all)"}, {"title": "Interventions through Context Variables", "content": "Combining observational and interventional data in the causal discovery process requires the causal structure related to the intervention variable to adapt to both the observational and interventional cases. Specifically, we need to consider the parents of the intervention variable when dealing with observational data, while we must break all the links affecting the intervention variable when performing the intervention. To address this challenge, we use context nodes to model interventions, taking inspiration from the JCI framework. The latter distinguishes between system variables, which describe the actual system, and context variables, which refer to the observation context. While the system variables are treated as endogenous, the context variables are typically (but not necessarily) exogenous. System and context variables form a new meta-system M, which is used for the causal analysis. Accordingly, our meta-system is defined as follows:\n$M: {\\begin{array}{ll}X_{i}(t)=f(P a(X_{i}), C X_{k}) & i \\in I, k \\in K\\\\C X_{k}=f_{k} & k \\in K\\end{array}}$\nwhere I represents the set of system variables defined as $X = (X_i)_{i \\in I}$, while K represents the set of context variables defined as $C = (CX_k)_{k \\in K}$. $Pa(X_i)$ is the parent set of the system variable $X_i$, instead $CX_k$ is the context variable k. Moreover, the function f models the system variables and can be decomposed as follows:\n$f\\left(P a(X_{i}), C X_{k}\\right): \\begin{cases}f\\left(P a(X_{i})\\right) & C X_{k}=0\\\\C X_{k}=\\xi_{k} & C X_{k}=\\xi_{k}\\end{cases}$\nwhere f represents the function that models the evolution of the system variable $X_i$ in the observational case, which depends solely on its parent set $Pa(X_i)$. Referring again to Equation 1, the function $f_k$ models the context variables and it is defined as follows:\n$f_{k}: \\begin{cases}0 & \\text { interventional mode for } k \\\\ \\xi_{k} & \\text { observational mode for } k\\end{cases}$\nThe case where $CX_k = 0$ corresponds to no intervention, i.e the observational baseline, while $CX_k = \u03be_k$ models the intervention case, where $\u03be_k$ is the actual intervention value assigned to the variable $X_i$ through the context variable $CX_k$. This approach is consistent with the concept of \"force variables\" adopted in the literature.[14, 41] In our case, to model hard interventions with known targets as context changes in time-series data, we assume the three assumptions made by the JCI framework, specifically we used the JCI123 version of the framework.[14] The three assumptions are the following:\nJCI1 Exogeneity: No system variable causes any context variable, i.e.,\n$\u2200k \u2208 K, \u2200i \u2208 I : i \u2192 k \u2209 G(M)$\nJCI2 Complete randomised context: No context variable is confounded with a system variable, i.e.,\n$\u2200k \u2208 K, \u2200i \u2208 I : i \u2194 k \u2209 G(M)$"}, {"title": "Faithfulness Assumption", "content": "In the context of constraint-based causal discovery, the so-called faithfulness assumption plays a crucial role in ensuring that the inferred causal relationships from observational data represents accurately the true underlying causal structure. Essentially, this assumption asserts that all conditional independence relationships in the data are encoded in the reconstructed causal graph. This means that if a variable is conditionally independent from another, given a set of variables in the data, then no direct edge should exist between them in the graph.[42] Like its predecessor LPCMCI, CAnDOIT is a constraint-based causal discovery method that requires the faithfulness assumption, even with the introduction of new context variables for modeling interventions. This is crucial for the correctness of the algorithm. Since we combine both observational and interventional data, our output (time series PAG) must be faithful to the conditional independencies present in both types of data. To ensure this, we test for (conditional) independence using only the pooled dataset (observational and interventional) and never consider the two cases separately. Testing for independence using only part of the data might produce results that are unfaithful to the remaining data.\nFrom the example in Figure 1a, we can see how CAnDOIT reconstructs the causal model using both observational and interventional data, consistently with the faithfulness assumption. As shown in in the Figure la (CAn-DOIT), the meta-system M created by CAnDOIT includes three system variables $(X_0, X_1, X_2)$ and a context variable $CX_2$, which models the intervention on $X_2$. Although the hard intervention on the variable $X_2$ overrides the relationships between $X_2$ and its parents $Pa(X_2) = X_0$, it does not compromise the faithfulness of the joint distribution $P(CX_2, X_0, X_1, X_2)$ with respect to the joint causal graph. Indeed, even though $X_2$ and $Pa(X_2) = X_0$ are independent in the intervention setting, they are still dependent in the observational one. Therefore, as long as we do not test for independences in the subset of interventional data separately, but restrict ourselves to testing independences only in the pooled data set that combines all contexts, the faithfulness assumption remains valid.[14]"}, {"title": "CAnDOIT Algorithm", "content": "Figure 2 depicts a detailed flowchart of CAnDOIT, explaining each step of the algorithm with an example. In particular, the steps executed by our approach are as follows:\n\u2022 CAnDOIT takes observational and interventional data as input;\n\u2022 Using the knowledge of the intervention target Z, the context block adds the context node CZ to the set of variables considered in M, plus an instantaneous link CZ \u2192 Z to the initial causal structure, i.e., a fully connected graph that is the starting point of the LPCMCI algorithm;\n\u2022 The system variables (X, Y, Z), along with the context node CZ are injected into the causal discovery block;\n\u2022 LPCMCI performs the causal analysis on the meta-system M and then removes both the context variable CZ and the link CZ \u2192 Z before returning the causal model;\n\u2022 CAnDOIT outputs a time-series PAG.\nA detailed pseudo-code explanation of our approach is presented in Algorithm 1. A Python implementation of CAnDOIT is also publicly available\u00b9.\nBeing based on LPCMCI, our CAnDOIT inherits its necessary conditions for proper functioning: Causal Markov Condition, Faithfulness, Acyclicity. Furthermore, like its predecessor, CAnDOIT can adapt to any type of data, including linear and nonlinear relationships, multiple time lags, various types of noise, and it cannot detect cyclical relationships. It retains the output format of a time-series Partial Ancestral Graph (PAG). Specifically, CAn-DOIT produces a time-series PAG with a number of layers determined by the algorithm parameters $T_{min}$ and $T_{max}$ (see Algorithm 1 inputs). By default, $T_{min}$ is set to 0 to account for the instantaneous links created for the context variables. On the other hand, $T_{max}$ represents the maximum time delay considered when the algorithm performs conditional independence tests between variables across different time steps. Consequently, the time-series PAG consists of $T_{max} + 1$ layers, corresponding to the time steps $t \u2013 T_{max}, t (\u0422_{max} \u2014 1), ...,t$.\nPAGs are used to represent the Markov equivalence class of Maximal Ancestral Graphs (MAGs). The latter extend the DAGs representation by including also the bidirected link (\u2194) to represent variables confounded by a latent confounder. PAGs further generalize MAGs by incorporating additional edge types, specifically \u2192 and \u2218-\u2218, to handle uncertainties in edge orientations. For example, in a PAG, a link $X \u2192 Y$ corresponds to two possible MAGs: $X \u2192 Y$ (where X is an ancestor of Y) or $X \u2192 Y$ (where X and Y are confounded by a latent variable). Similarly, a link $X \u2218\u2218 Y$ in a PAG represents two possible MAGs: $X \u2192 Y$ (where X is an ancestor of Y) or $Y \u2192 X$ (where Y is an ancestor of X)."}, {"title": "Evaluation on Random Synthetic Models", "content": "We designed experiments to assess the accuracy and effectiveness of our approach in handling interventional data and to examine its impact on the causal discovery process. These experiments aimed to evaluate our method's performance in various scenarios: linear and nonlinear systems, with and without latent confounders, and involving single or multiple interventions.\nIn this section, we evaluated the correctness and performance of CAnDOIT on a large set of randomly-generated synthetic models. Later, in Section 5, we will also test it on a simulated robotic scenario."}, {"title": "Random Synthetic Models", "content": "To evaluate our approach's effectiveness in handling interventional data and its impact on the causal structure, we devised five testing strategies, denoted as $S_1, S_2, S_3, S_4$, and $S_5$. In the first strategy ($S_1$), we assessed our approach's performance with linear systems while varying the number of observable variables and without hidden confounders. Strategy $S_2$ extends $S_1$ by introducing hidden confounders while retaining the system as linear and maintaining the same range of the number of variables. In both $S_1$ and $S_2$, only a single intervention is conducted. In strategy $S_3$, we evaluated how CAnDOIT performs with linear systems and hidden confounders when multiple interventions are applied, while keeping the number of observable variables fixed. Strategies $S_4$ and $S_5$ mirror $S_2$ and $S_3$, respectively, but focus on nonlinear systems.\nTo facilitate the aforementioned evaluations, we developed a synthetic model generator capable of creating random systems of equations with hidden confounders. This tool offers various adjustable parameters, including time-series' length, number of observable variables, observable parents per variable (link density), hidden confounders, and confounded variables per hidden confounder. Moreover, it includes also noise configuration, minimum and maximum time delay to consider in the equations, coefficient range, plus functional forms and operators used to link various equation's terms. With this generator, we can create ground-truth causal models to test our algorithm and generate observational and interventional data based on the generated causal structure. This enables us to simulate different scenarios and thoroughly analyze the behavior of our approach under various conditions. A detailed explanation of the random-model generator is presented in Appendix A. Examples of randomly-generated causal models for each specific evaluation strategy are shown in Figure 3.\nSome model generators and causal discovery benchmarks have been introduced in the literature, for example CauseMe, [32] a collection of synthetic, hybrid, and real observational data mostly for climate and weather scenarios. Other random-model generators have been proposed[43], however none of them can generate entirely random causal structures along with both observational and interventional data like the one here developed.\nOur synthetic model evaluation is crucial to validate CAnDOIT's performance in retrieving more accurate causal models compared to other methods. Opportunely tuned, our random-model generator is not constrained by any assumptions regarding model linearity, effectively excluding from the evaluation noise-based discovery methods. [27, 28] As CAnDOIT is based on the LPCMCI causal discovery algorithm, the latter was used as the benchmark for this evaluation."}, {"title": "Evaluation Setting", "content": "We evaluated CAnDOIT using the random-model generator mentioned in Section 4.1. Five evaluation strategies were devised. For each strategy, we first conducted causal discovery analysis with LPCMCI. Based on its result, we then selected which variable(s) to intervene on. The choice of intervention variable(s) was determined by the observable variable(s) identified by LPCMCI as having ambiguous links (\u2192 and \u2218-\u2218). The goal of these interventions was to (partially) resolve the ambiguities in these links. In cases where LPCMCI returned a causal model with ambiguous links originating from multiple nodes, we performed an intervention for each of these nodes. In the evaluation results presented in Section 4.4, we report two curves for each metric, both describing CAnDOIT's performance: CAnDOIT_mean, which depicts the average for the analyzed metric across all interventions, and CAnDOIT_best, which shows the result that produced the most accurate (highest $F_1$-Score) causal model."}, {"title": "Evaluation Metrics", "content": "The evaluation metrics were categorized into two main groups. The first one comprises metrics to assess CAn-DOIT's ability in removing ambiguous links, and includes mean False Positive Rate (FPR), mean number of ambiguous links (Uncertainty), and mean number of equivalent MAGs that the PAG output by the algorithms can represent (PAG Size) across all tests. The second category instead evaluates CAnDOIT's overall performance in recovering the correct causal model and its execution time. These last metrics include mean Structural Hamming Distance (SHD), mean $F_1$-Score, and mean execution time across all tests. All the means were computed based on 25 test runs with different random systems for each configuration. Note that for the FPR, SHD, and $F_1$-Score metrics, we adopted the same approach used in LPCMCI\u2019s evaluation metrics.[19] Specifically, we not only considered the existence of a link between two nodes but also the tail and head markers of the links. Thus, in calculating these metrics, we measured both the adjacency (presence of a specific link) and the orientation (tail and head markers of a specific link).\nFor sake of clarity, since less known in the literature, we explain Uncertainty and PAG size metrics a little more in details. The Uncertainty metric quantifies the number of ambiguous links present in the discovered causal model (\u2192 and \u2218-\u2218). This metric is utilized to assess CAnDOIT's capability in removing ambiguities. Consequently, a lower value indicates better performance. The PAG Size metric quantifies the number of MAGs equivalent to the discovered one. It calculates this number based on the count of ambiguous links in the estimated causal model. As already explained in Section 3.4, each ambiguous link can represent two possible links: \u2192 can represent either \u2192 or \u2194, while \u2218-\u2218 can represent either \u2192 or \u2190. Consequently, for each ambiguous link present in the final causal model, two equivalent MAGs are generated. Finally, the PAG Size metric is defined as follows:\nPAG Size = $2^{Uncertainty}$"}, {"title": "Experimental Results on Synthetic Models", "content": "Figures 4, 5, 6, 7 and 8 compare the causal discovery results obtained with LPCMCI (red dotted lines), CAn-DOIT_mean (green dashed lines), and CAnDOIT_best (blue lines). The different markers in the graphs represent the mean scores computed across 25 run tests for each configuration, while the error bars show the confidence levels determined by 1000 bootstraps over the 25 results. Additionally, a Linear Mixed Model (LMM) was used to assess the statistical validity and robustness of the analysis, [44] detailed results of which are provided by Tables 3 and 4 in Appendix B.\nThe $S_1, S_2, S_3, S_4$ and $S_5$ analyses are presented in Figures 4, 5, 6, 7, and 8, respectively, demonstrating the superior performance of CAnDOIT compared to LPCMCI across all scenarios. Note that, for all the analyses, the PAG Size score is shown on a logarithmic scale to improve readability. In $S_1$ (Figure 4), CAnDOIT (both CAn-DOIT_mean and CAnDOIT_best) performs remarkably well in all metrics. Figures 4a, 4c and 4e show FPR, Uncertainty and PAG Size, respectively. It consistently maintains lower FPR and Uncertainty scores compared to LPCMCI, leading to improved identifiability across all $S_1$ cases, largely due to its use of interventional data. The superiority of CAnDOIT is evident also in the SHD and $F_1$-Score comparisons shown in Figures 4b and 4d, respectively, where CAnDOIT continues to consistently outperform LPCMCI. In terms of execution time, depicted in Figure 4f, CAnDOIT appears slower compared to LPCMCI due to the introduction of the context node used to model the single intervention. The decreasing trend in the FPR score observed in Figure 4a is associated to the increasing number of variables. This decrease is a result of the higher True Negative score (TN), which grows with the number of variables. Furthermore, it is important to specify that the different performances between CAnDOIT_mean and CAnDOIT_best are due to the fact that CAnDOIT_best (the CAnDOIT result with the single intervention yielding the highest $F_1$-Score) is often associated with an intervention on a variable that is the origin of multiple ambiguous links. Intervening on such a variable is more likely to yield better performance compared to intervening on a variable that originates only a single ambiguous link. On the other hand, CAnDOIT_mean considers all conducted interventions and averages the results.\nIn the $S_2$ analysis (Figure 5), which is analogous to $S_1$ but includes a random number of hidden confounders, CAnDOIT continues to outperform LPCMCI. As shown in Figures 5a and 5c, CAnDOIT consistently maintains low FPR and Uncertainty scores, surpassing LPCMCI. The $S_2$ analysis reaffirms the benefits of using interventional data to enhance the identifiability of the causal graph. In particular, the PAG Size metric in Figure 5e shows how CAnDOIT, by utilizing interventional data, is able to keep the number of equivalent MAGs consistently lower than LPCMCI. Unlike in $S_1$, the difference between CAnDOIT and LPCMCI is less pronounced in the SHD score, as shown in Figure 5b, though the advantage of using interventional data remains evident in the F1-Score (Figure 5d). Similar to $S_1$, the employment of context variables to model interventions makes CAn-DOIT slower compared to LPCMCI, as shown in Figure 5f.\nIn the $S_3$ analysis (Figure 6), we fixed the number of observable variables and varied the number of interventions to evaluate how our algorithm handles multiple interventions and whether they contribute to better performance compared to the single intervention cases analyzed in $S_1$ and $S_2$. CAnDOIT continues to significantly outperform LPCMCI. As shown in Figures 6a, 6c and 6e, CAnDOIT yields lower FPR, Uncertainty, and PAG Size scores than LPCMCI, demonstrating how an increasing number of interventions helps reduce the number of uncertain links and, consequently, the PAG size. Figures 6b and 6d show an improvement in the SHD and $F_1$ scores when transitioning from one to two interventions, though there is a slight deterioration in performance with three interventions. This can be attributed to the number of samples associated with each intervention. As explained in Section 4.2, to ensure a fair comparison, LPCMCI and CAnDOIT always use the same amount of data. In the case of multiple interventions, the 300 interventional samples are equally divided among the number of interventions, meaning that with three interventions, each has 100 samples. This reduced sample size for each intervention is not sufficient to further improve the SHD and $F_1$ scores compared to the two interventions case, explaining the deterioration in these metrics in the three interventions case. As in previous analyses, CAnDOIT appears slower compared to LPCMCI, as shown in Figure 6f.\nThe $S_4$ analysis (Figure 7) is the nonlinear counterpart to $S_2$. Specifically, it analyzes nonlinear systems with a"}, {"title": "Evaluation on Robotic Scenario", "content": "Once established, through the evaluation strategies presented in Section 4, that our approach works correctly, we used it for modeling a robotic scenario in a simulated environment. Our strategy was first to extract time-series data from the simulator, and then use it for causal discovery in the presence of a hidden confounder."}, {"title": "Causal World for Robot Camera Modeling", "content": "We designed an experiment to learn the causal model in a hypothetical robot arm application equipped with a camera. Our focus was on estimating the causal relationship between the color's brightness of objects as captured by the camera and various factors, including camera-to-object distance. For this evaluation, we utilised the well-known benchmark Causal World,[45] which is designed for causal structure learning in a robotic manipulation environment. The environment consists of a TriFinger robot, a floor, and a stage. It allows for the inclusion of objects with various shapes, e.g. cubes. This simulator is widely used in the causality community due to its ability to support diverse manipulation tasks and interventions, [46, 47, 48] including changing the objects' color or mass."}, {"title": "Experimental Results on Robotic Scenario", "content": "The evaluation involved three main steps. (i) We generated observational data containing all the variables in the system ($F_c, C_c, H, v, d_c$), as shown in Figure 9a, and performed the causal analysis using LPCMCI. (ii) We intentionally hid the variable H, representing the height of the end-effector, to create a hidden confounder and a spurious relationship between $C_c$ and $F_c$. Again, we used LPCMCI for the causal analysis. (iii) We conducted an intervention on the floor's color, setting it to green (Figure 9b), and collected data from the simulator. Then we used CAnDOIT for the causal analysis with both observational and interventional, accounting for the hidden confounder H. The observational time-series had a length of 600 samples, while the interventional time-series consisted of 125 samples. Both were recorded at a sampling rate of 10 Hz. Also in this case, to ensure a fair analysis, LPCMCI and CAnDOIT used exactly the same amount of data. Consequently, LPCMCI received the complete set of observational data, whereas for CAnDOIT part of the observational data was replaced by interventions, specifically 475 observational samples and 125 interventional ones."}, {"title": "Conclusions and Future Work", "content": "In this paper, we proposed CAnDOIT, a new state-of-the-art algorithm that enables causal discovery using both observational and interventional data via context variables. We validated our approach experimentally on random synthetic models and tested on a robotic simulator for causal discovery, focusing on the significance of interventional data. Our results confirmed that CAnDOIT significantly improves previous causal discovery methods, offering enhanced accuracy, model identifiability. They also highlight its capability to handle interventional data effectively and its potential for real-world robot applications. The proposed method lays the foundation for new observations- and interventions-based causal discovery methods on time-series data, with numerous opportunities for future research. Firstly, to the best of our knowledge, various causal discovery algorithms combine observational data and hard/soft interventions with known/unknown targets, but only in the static domain. We present, for the first time, a causal discovery algorithm that combines observational and interventional data in a time-series setting. We acknowledge that the current version of CAnDOIT only deals with hard interventions on known targets. However, this challenge has not yet been investigated in the time-series domain. Furthermore, this solution is useful in many applications where intervention variables are known (e.g., robotics). We believe that CAnDOIT is a significant step in the right direction and future extensions could accommodate soft interventions and unknown targets.\nAn interesting analysis would be to test how the ratio between the lengths of observational and interventional"}]}