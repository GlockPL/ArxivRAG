{"title": "Focal Depth Estimation: A Calibration-Free, Subject- and Daytime Invariant Approach", "authors": ["Benedikt W. Hosp", "Bj\u00f6rn Severitt", "Rajat Agarwala", "Evgenia Rusak", "Yannick Sauer", "Siegfried Wahl"], "abstract": "In an era where personalized technology is in- increasingly intertwined with daily life, traditional eye-tracking systems and autofocal glasses face a significant challenge: the need for frequent, user-specific calibration, which impedes their practicality. This study introduces a groundbreaking calibration- free method for estimating focal depth, leveraging machine learning techniques to analyze eye movement features within short sequences. Our approach, distinguished by its innovative use of LSTM networks and domain-specific feature engineering, achieves a mean absolute error (MAE) of less than 10 cm, setting a new focal depth estimation accuracy standard. This advance- ment promises to enhance the usability of autofocal glasses and pave the way for their seamless integration into extended reality environments, marking a significant leap forward in personalized visual technology.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, the landscape of Virtual Reality (VR) has undergone transformative changes, significantly influencing various sectors by enhancing accessibility and expanding its market presence. Alongside VR's growth, smart glasses technology has advanced, with VR serving as a crucial testing ground for innovative algorithms [15]. A notable area of innovation within smart glasses technology is the development of autofocal glasses, designed to address presbyopia a condition that diminishes the eye's ability to focus on close objects as people age, affecting billions worldwide [3, 8]. Traditional correction methods, such as bifocal or multifocal lenses, often fall short of mimicking the eye's natural focusing capability, leading to restricted gaze and visual inconvenience [31, 19]. Progressive lenses may offer some correction but may introduce aberrations in the periphery [9, 43]. Autofocal glasses, leveraging optical-quality liquids in flexible membranes to dynamically adjust focal length, represent a more natural and innovative solution for presbyopia [5]. Despite their potential, existing autofocal solutions face limitations due to manual focus adjustments and a limited focus range [46], impacting user comfort and adaptability. Furthermore, the autofocals field shows many evaluation metrics but lacks detailed algorithm explanations, limiting understanding and hindering advancements [1, 55]. A significant barrier to the widespread adoption of autofocals is the cumbersome need for frequent user-specific calibration, significantly limiting the technology's practicality [38]. Previous efforts in focus depth estimation have made strides but often rely on extensive calibration, lack generalizability, and demand significant computational resources [56]. This introduces a substantial obstacle to the seamless integration of autofocal glasses into daily life, highlighting the need for a novel approach to overcome these limitations [21, 40].\nIn this context, machine learning (ML) emerges as a beacon of innovation, promising to transcend the traditional calibration constraints. This paper introduces the Foveal Attention Long Short-Term Memory Network (FOVAL). This novel spatiotemporal sequential model achieves a calibration-free and daytime invariant focal depth estimation by analyzing eye vergence angle data [27, 39] and intense feature engineering based on domain knowledge. FOVAL marks a significant advance by providing a robust, user-friendly solution that adapts to diverse environmental conditions without the need for frequent recalibration, showcasing the potential of ML to revolutionize personalized technology. FOVAL is distinguished by its technical innovations, including using Long Short-Term Memory (LSTM) layers [14], feature engineering, and advanced preprocessing techniques. Combining these elements enables the model to generalize effectively to new subjects without prior calibration. The optimization of model architecture incorporating LSTM, normalization layers, and max pooling - underpins the model's exceptional performance, demonstrating the profound impact of ML in overcoming traditional challenges in personalized technology. FOVAL's elimination of the need for calibration dramatically enhances the usability of autofocal glasses, making advanced vision correction more accessible and convenient for users. This technology has the potential to significantly elevate visual acuity and quality of life for those affected by presbyopia, setting a new standard for user-friendly technology integration.\nThe applications of depth estimation extend well beyond the realm of autofocal glasses, touching on fields as diverse as microscopy [17], VR, and augmented reality (AR) [24]. Specifically, in medical areas like microscopy, arthroscopy, and robotic surgery, precise depth estimation can revolutionize how we visualize and analyze microscopic entities, enhancing the clarity and depth of 3D imaging to understand cellular structures and interactions better [44, 30, 17]. This is especially present in microscopic surgery, where optimal depth adjustment of the camera during surgery can be handled with such a model as FOVAL [4, 28]. Optimized human focus-based depth estimation can improve medical surgery and diagnostics. In VR and AR, depth estimation is pivotal in creating immersive and interactive experiences by reducing data size while retaining high resolution on focused depth planes [51] and improving perceptual realism [24]. VR enables rendering environments with realistic spatial dynamics, improving user immersion and interaction within virtual spaces [48]. For AR, accurate depth estimation allows for the seamless integration of digital objects into the real world [50, 34], showing accurate 3D images [49] enhancing applications in education, design, and entertainment [22] but also in human-vehicle interaction for autonomous driving [48]. The ability to accurately estimate depth in real-time can significantly improve AR glasses' performance and user experience, making them more practical for various applications, from industrial design to augmented learning environments.\nThis paper introduces FOVAL a novel calibration-free method for estimating focal depth, which leverages LSTM networks and domain-specific feature engineering. Our method significantly improves the accuracy and usability of autofocal glasses, achieving a mean absolute error (MAE) of less than 10 cm, and outperforms all state-of-the-art methods in focal depth estimation. Furthermore, by eliminating the need for user-specific calibration, we enhance the practicality of these devices for daily use. In the following section II, we describe details about the methods we use, including data collection, the data preprocessing pipeline, and model development; Section IV presents the results of our evaluation of the model, demon- strating the efficacy of our approach through comparative analysis; and Section V we recapitulate our findings and discusses the implications, limitations, and potential future applications of our findings."}, {"title": "II. METHODS", "content": "For the development and evaluation of our model, we collected data from 25 emmetropic individuals, meaning they had no need for corrective lenses and possessed normal vision (good vision). Of these participants, 11 identified as male and 14 as female, with an average age of 31.68 years (standard deviation = 11.71). Two additional participants were excluded due to issues with eye convergence. All remaining participants were free from any known eye diseases. The study followed ethical guidelines and received approval from the Faculty of Medicine Ethics Committee of the University of T\u00fcbingen under reference number 439/2020BO. All subjects gave consent for their data. We collected the dataset in a VR scene showing a sphere with a fixation cross traveling back and forth from 0.35 to 3 meters in a spiral movement on an XTAL VR Headset [54]. Eye vectors and origins (both in headset coordinates) have been recorded and serve as input features to the model. The complete dataset consists of 282080 samples of all individuals combined. The following paragraphs outline the workflow for creating the model. This section is divided into several parts, following general best practices for building a machine-learning model. Particular emphasis is given to the loss function and the feature engineering part based on domain knowledge (detailed mathematical notations are added to the appendix IX, which most influences model performance. The data cleaning steps contain data preprocessing necessary to increase the model's robustness against errors in sensor input and outliers. After preprocessing, we describe the dataset splitting and feature space, which is essential when working with human gaze data, followed by the data normalization and transformation steps. Finally, we describe the model architecture."}, {"title": "A. Data Preprocessing Pipeline", "content": "The data preprocessing pipeline involves several key steps to ensure the data is prepared effectively for the machine learning model. Here, we outline the steps in the order they are applied:"}, {"title": "Step 1: Data Cleaning", "content": "Anomalies and outliers were identified and eliminated through a detailed removal process. We employed a rolling mean window (window size = 5, threshold = 10) for the target variable to detect context-specific, short-term anoma- lies that can occur due to input signal noise. Window size and threshold have been defined empirically. This approach captures transient deviations from the mean over time. For the features, we utilized the Interquartile Range (IQR) method [53] over the time dimension to enhance data consistency. The IQR method is better suited to identify statistically rare events within the whole range of the features, capturing both short- term and long-term outliers. The window calculation process is formalized in Equations 1, 2, and 3. $GT_{depth_i}$ represents the ground truth depth value at the i-th position in the dataset, $W_i$ represent the window of values around $GT_{depth}$, defined by a specified window size. For each $GT_{depth_i}$ in the dataset, we define a window $W_i$ of values centered around i, with size $windowsize$. The window is defined as:\n$W_i = \\{GT_{depth_{start}},...,GT_{depthend}\\}$   (1)\nwhere\n$start = max(i - \\frac{window\\ size}{2},0)$   (2)\n$end = min(i + \\frac{window\\ size}{2} + 1, N)$   (3)\nand N is the total number of observations in the dataset of one subject. $mean(W_i)$ represents the mean value of the ground truth depths within the window $W_i$, and $threshold$ represents the predefined threshold for outlier detection. The window's mean is then calculated with Equation 4. A value $GT_{depth_i}$ is considered an outlier if the absolute difference between $GT_{depth_i}$ and the mean of $W_i$ exceeds the threshold (Equation 5).\n$mean(W_i) = \\frac{1}{\\|W_i\\|} \\sum_{j=start}^{end} GT_{depth,j}$   (4)"}, {"title": "Step 2: Data Balancing", "content": "As soon as the data for each subject is cleaned, we continue with data balancing. To do so, we combine over- and un- dersampling (Equation 10) before binning the target variable. This process involved quantizing the target variable into a predetermined number of bins, ensuring an equal distribution of samples across each bin. Since the dataset's data is mainly spread across 0 to 600 cm, we defined bins of 10 cm to ensure a balanced amount of samples for at least each 10 cm bin, resulting in 60 bins. We chose the bin size based on the visualization of the dataset as a trade-off between covering a wide range of possible values and having a substantive amount of representative samples for each bin. This strategy ensures that the model is not biased towards more frequently occurring data ranges. In the first step, we divide the target variable, $GT_{depth}$, into a predetermined number of bins ($N_{bins}$), where $Bin()$ denotes the binning operation, and $N_{bins} = 60$ in this context (Equation 8). Next, we calculate the mean count per bin $\\bar{C}$, where $C_i$ is the count of samples in the i- th bin (Equation 9). To ensure that each bin has a sample count close to the mean count $\\bar{C}$, we perform resampling. For bin i, the resampled bin data, $D_i$, is obtained using Equation 10, where $|D_i|$ is the count of samples in bin i, and $Resample()$ denotes the resampling operation. This process involves random oversampling or undersampling of each bin to match the mean count $\\bar{C}$. Finally, the resampled bin data from all bins are concatenated to form a balanced dataset as described in Equation 11.\nTo ensure that each bin has a sample count close to the mean count $\\bar{C}$, we apply the following resampling strategy: If the number of samples in a bin $|D_i|$ is less than the mean count $\\bar{C}$, we perform oversampling with replacement to increase the sample count to $\\lceil \\bar{C} \\rceil$. If the number of samples in a bin $|D_i|$ is greater than the mean count $\\bar{C}$, we perform undersampling without replacement to reduce the sample count to $\\lfloor \\bar{C} \\rfloor$. And if the number of samples in a bin $|D_i|$ is equal to the mean count $\\bar{C}$, no resampling is necessary. The following equation represents this process:\n$GT_{depthin} = Bin(GT_{depth}, N_{bins})$   (8)\n$\\bar{C} = \\frac{1}{N_{bins}}\\sum_{i=1}^{N_{bins}} C_i$   (9)"}, {"title": "Step 3: Splitting", "content": "To incorporate the intricate risks of biophysical data, we also ensured the generalizability of our machine-learning model by employing a systematic approach to data splitting using the K-Fold cross-validation (K-Fold CV) technique in a subject-wise manner. This method is pivotal for assessing the model's performance and ability to generalize to unseen data. We initialized the KFold cross-validator from the Scikit- Learn library [41] with a predetermined number of splits, n_splits = number of subjects, and set shuffle to True to randomize the data before splitting it. This effectively is a Leave-One-Out Cross-Validation (LOOCV) approach as a particular case of KFold CV. The randomization is crucial for mitigating any potential bias stemming from the original ordering of the data. To ensure the reproducibility of our results, we fixed the random state parameter to 42.\n$KFold(splits = nsplits, shuffle = True, random\\ state = 42)$   (12)\nTo maintain the integrity of subject data and avoid data leakage, we performed the splits based on unique subjects in the dataset (subject-wise splitting, see [16] for more details). This approach ensures that all data from a single subject is exclusively in the Training, validation, or testing set, which is critical for evaluating the model's performance in real-world scenarios. We created splits for training and validation, again ensuring there was no overlap of subjects between these sets. Inference is then done on unseen subjects. This meticulous data splitting and validation approach is foundational for developing accurate and reliable machine learning models. By ensuring that our model is tested on unseen data in a manner that mimics real-world application scenarios, we can confidently assess its generalizability and readiness for deployment. Moreover, subject-based splitting guards against overfitting and ensures that our model's performance metrics indicate its true predictive power."}, {"title": "Step 4: Feature space", "content": "Based on the input sequences of 10 temporally consecutive samples of 12 input features (eye vector left and right (x,y,z) and eye origin, we enhanced the model's predictive power by deriving new features from the 12 input features and one target variable (GT depth).\nThe features are derived from the optical axis, which is defined as the line that passes through the centers of the eye's optical components, such as the cornea, the pupil, and the lens, and is perpendicular to these surfaces. In contrast, the visual axis is defined by a line that is not perpendicular to the retina but instead ends on the fovea of the eye. Typically, eye-tracking methods need to estimate this offset to estimate the precise point of regard (POR) in 3D space because only the optical axis is easily detectable from eye images directly. However, as we do not rely on the actual POG but instead on relative movements, we do not need to know the visual axis and can use uncalibrated eye images as input.\nOur features can be divided into primary, ratios & differ- ences, and higher-order dynamics of eye movements. In the following section, we give an overview of the features and their meaning. For the particular implementations, please see Appendix IX for an exhaustive list of equations.\na) Eye Vergence Angle: The Eye Vergence Angle (EVA) is pivotal in understanding how the eyes adjust their lines of sight when focusing on an object. This angle results from both eyes' simultaneous inward or outward movement to maintain single binocular vision as they shift focus across objects at varying distances. EVA provides critical insights into the focal depth and the mechanisms underlying 3D perception. It is essential for grasping the spatial dynamics of visual percep- tion. We normalized the angle between different subjects to compare it. Additionally, the conversion of EVA to a cosine metric simplifies some analyses. A key derivative of EVA, vergence depth, offers a quantifiable measure of the focal depth but provides the most reliable estimates only within a specific mid-range due to the nonlinear relationship between EVA and depth.\nb) Eye Direction Vectors: Beyond the EVA, we analyze changes in eye direction vectors (EDV) to illuminate eye align- ment and focus disparities. This includes assessing differences in vector components between the eyes and calculating the Euclidean distance between focus points (intersections of the vectors) to determine the convergence or divergence in gaze. The directional magnitudes for each eye's gaze direction are compared to reveal potential asymmetries in eye movement strength. While the intersection of EDVs on the z-axis can be informative about the focused depth, even slight inherent noise and errors in the estimation of the EDVs can introduce high variation in depth estimation. This is one major problem that causes eye-tracking for depth perception to be not as reliable as needed.\nc) Ratios and Differences: Another group of features can be described as ratios and differences. Here, we explore the ratio of directional magnitudes by dividing one eye's direc- tional magnitude by the other's, shedding light on eye move- ments and gaze focus asymmetries. Additionally, analyzing the magnitudes of individual dimensions uncovers insights into the relative orientations and dominance in gaze direction. The feature examining horizontal to vertical disparities in gaze may reveal preferred axes of movement or alignment. Key to our analysis is the quantification of eye movement rates-velocity"}, {"title": "Step 5: Normalization", "content": "The next step in the preprocessing pipeline is to normalize the features. Normalization is applied in two steps to the datasets, which is particularly useful in scenarios where data comes from multiple subjects, each potentially with different baselines or scales of measurement.\nGiven a dataset D with multiple subjects, the two-step normalization process involves applying global normalization to D (see equation 13), obtaining $D_{global\\_norm}$, and then for each subject in $D_{global\\_norm}$, applying subject-wise normalization to obtain the final normalized dataset $D_{final\\_norm}$ (see equation 14). The normalization per subject is to account for individual variations, ensuring the model learns generalized patterns rather than subject-specific characteristics.\nStep 5.1: Global Normalization: The global normaliza- tion process applies a Robust Scaler [13] to the dataset's features, excluding specific columns such as GT Depth. This scaling technique is particularly effective in datasets with outliers, as it uses the interquartile range for scaling, thereby reducing the influence of extreme values such as outliers. Given a feature vector $X = [x_1, x_2, ..., x_n]$, the Robust Scaler transforms X into X' by computing:\n$X' = \\frac{X - Median(X)}{IQR(X)}$   (13)\nwhere $Median(X)$ is the median of the feature values in X, $IQR(X)$ is the Interquartile Range of X, calculated as $IQR(X) = Q3(X) \u2013 Q1(X)$, with $Q3(X)$ and $Q1(X)$ representing the third and first quartiles of X, respectively. The transformed dataset D' then contains the normalized features. We use a scaler that is robust to outliers to ensure stability and robustness in our preprocessing pipeline, accounting for any residual outliers, future data variations, and skewed dis- tributions.\nFor global normalization, the statistics (median and IQR) are calculated using the training set. These statistics are then applied to normalize the test set, ensuring that the normalization process is consistent and does not introduce data leakage. Even after removing outliers, global normalization remains essential because it ensures that the overall scale of the data is consistent, making the dataset more robust to variations. The global normalization step adjusts the data on a broader scale, ensuring that features from different subjects and conditions are comparable. This step is crucial to avoid biases in the model training process caused by different feature scales.\nStep 5.2: Subjective (Subject-Wise) Normalization: Data is further normalized on a per-subject basis after global normalization. This step accounts for individual differences, ensuring that the model does not learn from these variations but from the underlying patterns.\nFor a subjects with data X, subject-wise normalization is applied as:\n$X_{s, normalized} = \\frac{X - Median(X)}{IQR(X)}$   (14)\nSubject-wise normalization is calculated and applied di- rectly to each subject's data, ensuring that intra-subject vari- ability is appropriately handled. By combining these two normalization steps, we ensure that our model is trained on data that is both globally and individually normalized, enhancing its generalizability. This process is repeated for each unique subject in the dataset, ensuring individual data scales are aligned. Especially in physiological or behavioral data, measurements can significantly differ between subjects due to innate individual differences. Subjective normalization is critical to handling inter-subject variability. It further im- proves model generalization by ensuring the model learns from normalized features, allowing it to better generalize across subjects not part of the training data. Another important aspect is a fair comparison. It ensures that features from different subjects are on a comparable scale, making statistical analysis and machine learning modeling more effective and fair."}, {"title": "Step 6: Feature Transformation", "content": "Feature transformations ensure that each feature in the dataset is transformed to achieve a more normal distribution, supporting the assumptions of many machine learning algo- rithms and improving overall model performance [7, 37, 20]. Different mathematical transformations are tested on the train- ing dataset for each feature to achieve a distribution closer to normal distribution characteristics, which can improve the performance of specific machine-learning models. While nor- malization typically scales the data to a standard range or distribution, it does not necessarily transform the data to follow a Gaussian distribution. Therefore, applying transformations such as logarithmic, square root, or Box-Cox is necessary to address skewness and other distributional issues that normal- ization alone cannot resolve.\nThe ideal transformation minimizes the distance to the normal distribution characteristics defined by skewness and kurtosis. Skewness measures the asymmetry of the data dis- tribution, with an ideal skewness of 0 indicating a perfectly symmetrical distribution. Kurtosis measures the tailedness of the distribution, with an ideal kurtosis of 3 indicating a normal"}, {"title": "Step 7: Scaling Target", "content": "To improve the performance and stability of our machine learning models, we rescale the target variable to align with the input features. However, the reasons for rescaling the target variable are multi-fold:\nRescaling ensures that the model's output values are within a comparable range to the input features, facilitating faster convergence during Training. Significant discrepancies be- tween the scales of input features and target values can lead to inefficient optimization processes and slow convergence rates [11]. Working with a wide range of target values can introduce numerical instabilities, particularly in gradient-based optimization methods. By rescaling the target values to a smaller, more manageable range, we mitigate these instabilities and promote a more stable training process [25]. Maintaining consistency in the scaling of input features and target variables helps the model learn the relationships between inputs and outputs more effectively. This consistency can result in more accurate predictions and better generalization to unseen data [6]. Rescaling target variables is a standard practice in machine learning, especially in regression tasks. It ensures that the model's loss function operates within a consistent scale, which is crucial for effective training [12]. To ensure that the model's predictions are interpretable in the context of the original data, the scaler used during the training process must be saved. This saved scaler is then used to apply an inverse transformation to the model's predictions.\nDuring the training process, the target variable y is scaled to improve model performance and Training stability. However, once the model generates predictions, these predictions are in the scaled form. To interpret these predictions correctly, we need to convert them back to the original scale of the target variable. After obtaining the model's predictions $\\hat{y}$ on the test set or new data, we apply the inverse transformation to convert them back to the original scale. This process involves using the saved scaler to reverse the scaling operation applied during Training.\nThe target variable is initially measured in centimeters, with values ranging from 0 to around 900 cm, corresponding to a depth perception range from 0.0 to 9 meters based on the typical eye vergence range. To standardize this range and make it more manageable for computational purposes, the target variable is scaled to a range of 0 to 1000 cm using a MinMax Scaler transformation. This transformation adjusts the values of the target variable to the specified range [0, 1000].\nThe transformation for a value y in the original dataset to the scaled value y' is given by:\n$y' = a + \\frac{(y - y_{min}) \\times (b - a)}{y_{max} - y_{min}}$\nwhere $y_{min}$ and $y_{max}$ are the minimum and maximum values of the target variable in the training dataset, respectively, and a and b are the bounds of the new scaling range, with a = 0 and b = 1000 in our case.\nWe chose the 0 to 1000 range to encompass a depth perception range of 0 to 10 meters, considering that eye movements can change depth perception up to approximately 10 meters, beyond which it is considered infinity. This range ensures that the model is prepared for all kinds of data that might be fed into it in the future, including maximum depth perception scenarios.\nDuring development, the MinMax Scaler performed bet- ter than typical scaling methods by preserving the relative distances between data points and improving the model's performance. The 0 to 1000 range, while larger than the original scale, ensures that the scaled values are standardized and more suitable for various computational operations and visualizations."}, {"title": "Step 8: Sequence Creation for Time-Series Analysis", "content": "As soon as the data is clean, normalized, transformed, and scaled, we structure samples into sequences to capture temporal dependencies within the eye movement data. This approach ensures that the temporal context is preserved, which is crucial for training models on sequential data where the order and timing of observations are essential. Given a dataset D organized by subject, the process first divides the dataset into subsets $D_s$, each corresponding to a unique subjects, ensuring that sequences are generated within individual subject data.\nWe generate sequences for a defined sequence length L by sliding a window of length L across each subject's data. This means that the sequences overlap, as each new sequence starts one time step after the previous one. For each position n within the data for subject s, a sequence $S_n$ and its corresponding target $y_n$ are defined as:\n$S_n = \\{X_n, X_{n+1},..., X_{n+L-1}\\}$\n$Y_n \\approx Y_{n+L}$\nwhere $X_n$ represents the feature vector at time step n, and $Y_{n+L}$ is the target value immediately following the sequence. This overlapping sequence generation ensures that temporal dependencies are effectively captured, providing the model with sufficient context for learning."}, {"title": "III. MODEL", "content": "The model's architecture was defined using PyTorch's dy- namic computation graph and intuitive API, which makes it ideal for developing complex neural networks. The model was trained using PyTorch's built-in functions for backpropagation and optimization. NumPy was used to handle data arrays and perform numerical operations, while SciPy provided additional mathematical and statistical functions necessary for prepro- cessing and evaluation.\nThe training process involves several key components: The choice of optimizer is critical for the model's learning effi- ciency and convergence. Due to its effectiveness in some pre- runs, we picked AdamW [32] (Adam [23] with weight decay). We found that a smooth L1 loss [10] with beta=0.75 works best for the loss function. Beta has been defined empirically by a hyperparameter search. The Smooth L1 Loss function minimizes prediction errors while balancing the mean absolute error and mean squared error. It is a robust loss function less sensitive to outliers compared to the L2 Loss and has been shown to prevent exploding gradients [45]. It behaves like the L1 Loss when the absolute value of the argument is high and the L2 Loss when the absolute value is small. The loss function is defined as follows, with a beta parameter ($\\beta$) controlling the transition:\n$L_{smooth}(y, \\hat{y}) = \\begin{cases}\n0.5 \\frac{x}{\\beta^2} (y - \\hat{y})^2 & \\text{if } |y - \\hat{y}| < \\beta\\\\\n|y - \\hat{y}| \u2013 0.5 \\times \\beta & \\text{otherwise}\n\\end{cases}$   (15)\nThe model is trained on n-1 subjects and validated/tested on the one left-out subject, ensuring a rigorous evaluation of its generalization capability. We train each fold in n = 2000 epochs with a batch size of 460, a weight decay of 0.0906, a learning rate of 0.033, a dropout rate of 0.245, an embedded dimension of 1435, and a fully connected dimension of 1763. After prediction, the scaling of the target variable is inverted to interpret the model's output in the original scale. Performance metrics are then saved for each fold of the cross-validation process. After all folds, the average performance metrics are calculated and reported, providing a comprehensive overview of the model's effectiveness across the entire dataset. We used the Optuna framework with a Tree-structured Parzen Estimator (TPE) Sampler to find the optimal hyperparameters [2]."}, {"title": "A. Architecture", "content": "The proposed model employs an architecture to efficiently process sequential data, pinpointing the most critical timestep for further analysis. The input to the model is a temporal sequence of eye movement data from one subject over a given range. Each sequence contains ten consecutive timesteps, with each timestep consisting of 54 features. Given the dataset's structure, we have approximately 28208 sequences in total, ensuring a comprehensive dataset for Training and evaluating the model's performance."}, {"title": "IV. EVALUATION", "content": "Central to our analysis is a dataset comprising eye movement recordings from 25 emmetropic individuals, which spans a dynamic range of focal depths and includes a diverse age range. This dataset lays a robust foundation for assessing FOVAL's performance, notably achieving a mean absolute error (MAE) as low as 5.9 cm.\nOur comparison between FOVAL, the Mix-TCN model [56], and the geometric vergence (geom. vergence) method was conducted using the reported performance metrics of these models rather than direct computational evaluation. Accessibility constraints primarily drove this decision. Specifically, we did not have access to the dataset used by Zhu [56] for the Mix-TCN model, nor could we utilize their trained model parameters due to their unavailability. Similarly, retraining the Mix-TCN model on our dataset was not feasible without detailed architecture specifics and training protocols. Under these circumstances, the most pragmatic approach was to rely on the performance metrics published by the author, which are assumed to be representative of their models' capabilities under their respective testing conditions. Although this method does not allow for a controlled, head-to-head comparison under identical data conditions, it still provides a valid frame of reference for evaluating FOVAL's relative performance and demonstrating its potential advantages in accuracy and usability. In future work, should the data and models become accessible, a direct comparison would be invaluable for a more detailed and controlled performance analysis.\nThe performance of FOVAL not only markedly surpasses the Mix-TCN model's 12.1 cm MAE, reported by Zhu [56], but also outperforms the traditional EVA method (error of 42 to 83 cm [35]), illustrating FOVAL's adaptability and its transformative potential for autofocal glasses application in everyday life.\nIn a direct comparison with our dataset, the traditional EVA method reached an MAE of 30 cm. FOVAL, on the other hand, reached a mean MAE of 9.4 cm with a confidence interval between 1.12 and 1.47 cm, starkly contrasting with subject-wise calibrated Mix-TCN's reported 12.1 cm MAE and traditional EVA. This considerable discrepancy accentuates FOVAL's superior accuracy and emphasizes the need for future direct comparative analyses to evaluate these models' efficacy comprehensively.\nThe FOVAL approach demonstrates a robust performance spectrum, illustrated through its best, average, and worst Mean Absolute Error (MAE) values, the state-of-the-art method from Zhu's [56], and EVA. As depicted in Figure 2, FOVAL's performance variability is encoded in a gradient of blues, with its best performance (5.9 cm) outstripping the benchmarked Mix-TCN (12.1 cm) and the traditional EVA method (30.0 cm)."}, {"title": "A. Distribution of Residual Errors", "content": "A closer examination of the prediction errors across the dataset (Figure 3) reveals that the distribution of the residual errors predominantly centers around an MAE of -2.05 cm with a standard deviation of 8.83 cm, indicating a high precision level in focal depth estimation. The histogram is slightly skewed to the right, indicating that FOVAL tends to overestimate the focal depth on average. To better analyze the performance in a more fine-grained way, we analyze the residuals by categorizing them in specific ranges (Figure 4): Less than 1 cm, 1-10 cm, 10-20 cm, and greater than 20 cm. This shows the distribution of residuals in terms of the usability of the system. Residuals smaller than 10 cm are assumed to be small enough for the system to have no negative impact on a real-life application. We see that a majority, around 67.5% of errors, fall within a practically negligible range of under 10 cm, underscoring FOVAL's real- world applicability [56]."}, {"title": "B. Error Distribution in Binned Ranges", "content": "The vergence-angle-to-depth relationship is inherently non- linear, particularly at close and far distances. However, within mid-range distances, this relationship can approximate a more linear trend. This behavior arises because the rate of change in the vergence angle is much more significant at shorter distances, leading to a nonlinear response. As the distance increases, the rate of change in the vergence angle decreases, which can result in a piecewise linear approximation over certain mid-range distances. At far distances, the vergence angle changes very little, reinforcing the non-linearity of the relationship. Further insights are provided by analyzing the error distribution across different depth bins (Figure 5). The results demonstrate that FOVAL's predictions align closely with the expected behavior of vergence. Specifically, the vergence-to-depth relationship is nonlinear at both close and far distances and piecewise linear in the mid-range. This be- havior is reflected in the performance of FOVAL, which shows optimal prediction accuracy within the mid-range distances where the piecewise linear relationship is most pronounced. At closer and farther distances, the model's predictions align with the expected nonlinear relationship, confirming its robustness across different depth ranges. Optimal prediction accuracy is notably achieved within the 50 cm to 250 cm range, illustrating the model's proficiency in navigating the complexities of human eye behavior."}, {"title": "C. Performance Range", "content": "Analyzing individual subject performances offers valuable perspectives on the model's operational range. Subject 3 exemplifies the model's potential, with an impressive MAE under 5.9 cm, as depicted in the aligned actual and predicted values (Figure 6, left). This near-optimal alignment highlights FOVAL's ability to closely mimic natural eye movements. Conversely, Subject 25's performance, illustrating an MAE around 14.0 cm (Figure 6, right), underscores the challenges in achieving uniform accuracy across all subjects"}]}