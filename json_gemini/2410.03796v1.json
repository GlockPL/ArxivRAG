{"title": "Dynamic Evidence Decoupling for Trusted Multi-view Learning", "authors": ["Ying Liu", "Lihong Liu", "Cai Xu", "Xiangyu Song", "Ziyu Guan", "Wei Zhao"], "abstract": "Multi-view learning methods often focus on improving decision accuracy, while neglecting the decision uncertainty, limiting their suitability for safety-critical applications. To mitigate this, researchers propose trusted multi-view learning methods that estimate classification probabilities and uncertainty by learning the class distributions for each instance. However, these methods assume that the data from each view can effectively differentiate all categories, ignoring the semantic vagueness phenomenon in real-world multi-view data. Our findings demonstrate that this phenomenon significantly suppresses the learning of view-specific evidence in existing methods. We propose a Consistent and Complementary-aware trusted Multi-view Learning (CCML) method to solve this problem. We first construct view opinions using evidential deep neural networks, which consist of belief mass vectors and uncertainty estimates. Next, we dynamically decouple the consistent and complementary evidence. The consistent evidence is derived from the shared portions across all views, while the complementary evidence is obtained by averaging the differing portions across all views. We ensure that the opinion constructed from the consistent evidence strictly aligns with the ground-truth category. For the opinion constructed from the complementary evidence, we allow it for potential vagueness in the evidence. We compare CCML with state-of-the-art baselines on one synthetic and six real-world datasets. The results validate the effectiveness of the dynamic evidence decoupling strategy and show that CCML significantly outperforms baselines on accuracy and reliability.", "sections": [{"title": "1 Introduction", "content": "In real-world scenarios, different data modalities or features could be treated as multiple views. For example, in autonomous vehicle systems, cameras and lidars collect images and points; in the field of healthcare, a patient's comprehensive condition can be assessed through multiple types of examinations. Multi-view learning aims to synthesize both consistent and complementary information from these multiple views, leading to a more comprehensive understanding of the data. It has generated significant and wide-ranging influence across multiple research areas, including classification, semi-supervised learning, clustering, retrieval and large language models.\nMost existing multi-view learning methods primarily emphasize enhancing decision accuracy, often overlooking the crucial aspect of decision uncertainty. This limitation significantly restricts the applicability of multi-view learning in safety-critical scenarios, such as autonomous vehicle systems. Therefore, to predict the reliability of the results and further boost performance, researchers have proposed many multi-view uncertainty quantification methods in recent years. The pioneering work [10], Trusted Multi-view Classification (TMC), calculates and aggregates the evidence of all views. TMC utilizes this aggregated evidence to parameterize the class distributions, enabling the estimation of class probabilities and uncertainties. In order to train the model effectively, TMC requires the estimated class probabilities to align with the ground-truth labels. Building upon this research, researchers have proposed novel evidence aggregation paradigms such as sum, (weighted) average, element-wise dot product , etc. These methods enhance the reliability in the presence of various challenges, such as feature noise, incomplete views, etc.\nRegrettably, the evidence aggregation paradigms in these methods rely on an assumption: the data of each view can distinguish all categories. However, real-world multi-view data exhibit the semantic vagueness phenomenon, which means that one view may exhibit ambiguity or uncertainty in its categorization. For example, as shown in Figure 1, the ground-truth category of the first instance is \"apple pie\", while the image view is difficult to differentiate between the categories \"waffles\" and \"apple pie\". For this view, existing evidence aggregation paradigms encourage only the evidence of the category \"apple pie\" is large due to the common evidence complying with this. This overlooks the fact that the evidence for the category \"waffles\" is also substantial in the data, which would significantly impact the overall learning process and compromise its effectiveness. This motivates us to delve into the semantic vagueness problem in trusted multi-view learning.\nIn this paper, we propose a Consistent and Complementary-aware trusted Multi-view Learning (CCML) for this problem. First, we construct view-specific evidential Deep Neural Networks (DNNs) to learn the view-specific evidence, which represents the level of support for each category obtained from the data. In the multi-view fusion stage, we dynamically decouple the consistent and complementary evidence. The consistent evidence is derived from the consistent portions across all views, while the complementary evidence is obtained by averaging the differing portions from all views. This separation allows us to capture both the shared information and the unique aspects of each view. In the training stage, we enforce strict alignment between the opinion constructed from the consistent evidence and the ground-truth category. This is achieved by adjusting the probabilities of the true and false categories, as well as enhancing the separation between them. As for the opinion constructed from the complementary evidence, we only require it to reflect the probability of the true category, allowing for potential vagueness in the evidence. In the test stage, we aggregate the consistent and complementary evidence to make a decision.\nThe main contributions of this work are summarized as follows: 1) we identify the semantic vagueness phenomenon in multi-view data, which can significantly suppress the learning of view-specific evidence in existing trusted multi-view learning methods; 2) we propose the CCML method to tackle this problem. CCML effectively addresses the negative impact of semantic vagueness through two key strategies: dynamically decoupling the consistent and complementary evidence, and allowing potential vagueness in the complementary evidence; 3) we conduct empirical comparisons between CCML and state-of-the-art trusted multi-view learning baselines on a synthetic toy dataset and six real-world datasets. The experimental results not only validate the effectiveness of the proposed dynamic decoupling strategy but also demonstrate that CCML surpasses the baseline methods in terms of accuracy and reliability."}, {"title": "2 Related Work", "content": "The proposed CCML is a new uncertainty-aware multi-view fusion methods. Therefore, in this section, we briefly review two lines of related work, multi-view fusion and uncertainty-aware deep learning, to better motivate this work."}, {"title": "2.1 Multi-view Fusion", "content": "Multi-view fusion is highly effective in a wide range of tasks, as it combines information from multiple sources or modalities, use the ability to collect different information from different perspectives, leading to a more comprehensive understanding of the data. A recent comprehensive survey about multi-view fusion on low-quality data is . Based on the fusion strategy employed, existing deep multi-view fusion methods can be broadly categorized into two main pipelines: feature fusion and decision fusion . Feature fusion methods aim to capture the interactions between different views at the feature level. For example, canonical correlation analysis and its variants maximize the correlation of the multi-view latent representations. Matrix factorization methods decode the multi-view common representation to view-specific data via basis matrices. Following this line, Xu et al. explicitly model consistent and complementary information at the highest abstraction level by the group sparseness constraint . More recently, researchers have used deep neural networks to decouple the complex consistent and complementary information at representation level . A major challenge of feature fusion methods is that low-quality views may adversely affect the representation of other views. Decision fusion methods mitigate this problem by integrating the decision results from different views. We follow this line and propose a new method for decoupling consistent and complementary information at the decision level.low this line and propose a new method for decoupling consistent and complementary information at the decision level."}, {"title": "3 The Method", "content": "In this section, we first introduce the trusted multi-view classification problem and semantic vagueness phenomenon, then present the pipeline and loss function of CCML in detail."}, {"title": "3.1 Notations and Problem Definition", "content": "In this section, we introduce the trusted multi-view classification problem and semantic vagueness phenomenon in detail. For the $C$ classification problem, considering a dataset $D = \\{\\{x_n\\}_{v=1}^V, y_n\\}_{n=1}^N$ has $N$ instances with $V$ views, where $x_n^v$ denotes the feature vector for the $v$-th view of the $n$-th instance, and the one-hot vector $y_n \\in \\{0, 1\\}^C$ denotes the ground-truth label of the $n$-th instance.\nThe semantic vagueness phenomenon indicates that some elements of $\\{x_n^v\\}$ may not well distinguish certain categories, the intuitive example is shown in figure 1. The goal is to accurately predict $y_n$ and provide the associated prediction uncertainties $u \\in [0, 1]$ which is related to the reliability of final decision."}, {"title": "3.2 CCML Pipeline", "content": "As shown in Figure 2, the overall architecture is a decision-level fusion pipeline, which consists of the view-specific evidence learning stage and the evidential multi-view fusion stage. The view-specific DNNs $\\{f^v(\\cdot)\\}_{v=1}^V$ learn the view-specific evidence, which indicates the level of support for each category based on the data. In the fusion stage, we dynamically decouple the consistent evidence ($e^{con}$) and complementary evidence ($e^{cmp}$). $e^{con}$ is extracted from the consistent portions across all views, while $e^{cmp}$ is obtained by averaging the differing portions across all views. In the training stage, we establish different principles for $e^{con}$ and $e^{cmp}$, respectively. For the testing stage, we aggregate $e^{con}$ and $e^{cmp}$ to make a decision."}, {"title": "3.2.1 View-specific Evidence Learning", "content": "Many conventional multi-view learning methods utilize softmax layers to produce standard outputs to address multi-classification problems in neural classification networks. However, these methods only provide class probabilities without considering the reliability of the results . Due to the single-point estimation paradigm of softmax scores, they tend to produce overconfident outputs, even when the predictions are incorrect. To address these issues and achieve accurate uncertainty prediction, we employ EDL by replacing the softmax layer with a ReLU activation to obtain non-negative evidence.\nWe also introduce the subjective logic framework to form opinions which is important in CCML. In this framework, the parameter $a$ of the Dirichlet distribution $Dir(p|a)$ is associated with the belief distribution in the framework of evidence theory, where $p$ is a simplex representing the probability of class assignment. We collect evidence $\\{e^v\\}$, using view-specific evidential DNNs $\\{f^v(\\cdot)\\}_{v=1}^V$. The corresponding Dirichlet distribution parameters are $a^v = e^v + 1 = [a_1^v,\\dots, a_C^v]^T$. After obtaining the distribution parameters, we can calculate the subjective opinion, $w^v = (b^v, u^v)$ of the view including the quality of beliefs $b$ and the quality measure of uncertainty $u$, where $b^v = (a^v - 1)/S^v = e^v/S^v$, $u^v = K/S^v$, and $S^v = K + \\sum_{k=1}^C a_k^v$ is the Dirichlet intensity.\nAfter training evidential DNNs to learn view-specific evidence, we observe that the evidence produced by vagueness views contains support for multiple categories. Among these categories, the true categories would generate relatively higher amounts of evidence than other categories. Therefore, we cannot require only the ground-truth category to have large evidence. We utilize this property in the subsequent evidence fusion stage."}, {"title": "3.2.2 Consistent and Complementary-aware Multi-view Fusion", "content": "Existing trusted multi-view learning methods face limitations when addressing the phenomenon of semantic vagueness. This is primarily because, during the generation of view-specific evidence from network, the indistinguishable error categories in vague views produce a similar amount of evidence as the indistinguishable categories. Many methods struggle to distinguish between equal amounts of evidence for the correct and incorrect categories. As a result, we are motivated to tackle this problem by the CCML which decoupling the consistent and complementary evidence and allowing for potential vagueness in the complementary evidence.\nFor views $v_i$ and $v_j$, the view-specific deep learning network of view $v_i$ will produce similar amounts of evidence for classes $c_1$ and $c_2$, while the network of view $v_j$ will produce similar amounts of evidence for classes $c_2$ and $c_3$ when classifying instances of class $c_2$. Effective classification should be achieved through complementary information from view $v_i$ and $v_j$ respectively ($v_i$ determines that the instance is one of $c_1$ or $c_2$, and $v_j$ determines that the instance is one of $c_2$ or $c_3$, the final classification result should be $c_2$ utilizing the complementary information of $v_i$ and $v_j$). This also demonstrates the basic idea of the CCML method, which is to fully utilize consistent evidence across different views.\nTherefore, we need to decouple view-specific evidence of different views into consistent and complementary evidence. One previous work addresses the semantic vagueness phenomenon by setting fixed relation degradation layers for semantic vagueness categories. However, the extent of semantic vagueness varies among different instances, as reflected by the difference in consistency and complementarity. It is necessary to use dynamic decoupling strategies according to the differences of consistency and complementarity in the classification tasks, instead of using fixed relations. For this purpose, we propose a dynamic consistent and complementary evidence decoupling strategy.\nDefinition 3.1. (Consistent and Complementary Evidences). For the view-specific evidences $\\{e^v = (e_1^v, \\dots, e_C^v)\\}_{v=1}^V$. The consistent evidence $e^{con}$ and complementary evidence $e^{cmp}$ are defined as:\n$\\begin{aligned}e^{con} &= \\V(e^{con},\\dots,e^{con}), \\\\e^{con}_c &= \\min(e_c^1,\\dots,e_c^V), c = 1, \\dots, C, \\\\e^{cmp}_c &= \\frac{1}{V} \\sum_{v=1}^V (e_c^v - e^{con}_c), \\end{aligned}$\nwhere $e^{con}_c$ denotes the minimum evidence of each class supported by each view. $e^{cmp}_c$ denotes the complementary evidence.\nThe consistent evidence $e^{con}$ is obtained by aggregating the consistent portions from all views, while the complementary evidence $e^{cmp}$ is calculated as the average of the differing portions across all views. This distinction is made because the complementary evidence of all views $\\{e^v - e^{con}\\}_{v=1}^V$ capture the varying information between different views, encompassing both complementarity and conflict. It is important to note that this information does not always enhance the accuracy of results; instead, it can introduce additional uncertainty. Consequently, retaining the entire set of complementary evidence is not advisable. Instead, a more suitable approach is to preserve it by taking the average . By employing this strategy, we dynamically separate the consistent and complementary evidence from the view-specific evidence. Finally, we aggregate the two pieces of evidence on average to form the final opinion, which is used in the test stage. In the following section, we will outline how our deep learning networks are trained using distinct principles for handling consistent and complementary evidence."}, {"title": "3.3 Loss Function", "content": "In this section, we will present the training process of CCML. The objective is to deal with view-specific, consistent, and complementary evidence separately. Specifically, the consistent evidence should closely approximate the true label, while the complementary evidence serves as a supplementary component, allowing for more relaxed constraints. We will elaborate on these components below."}, {"title": "3.3.1 View-specific Loss Function", "content": "The evidential DNNs are obtained by converting the softmax layer of traditional DNNs into ReLU. Therefore, we obtain the non-negative outputs as evidence. We introduce an adjusted cross-entropy loss function to ensure that all views can generate appropriate non-negative view-specific evidence for classification:\n$\\begin{aligned}L_{ace}(a_n) &= - \\sum_{j=1}^C y_{nj}logp_{nj} \\\\&= - \\sum_{j=1}^C y_{nj} \\frac{1}{B(a_n)} \\int_0^1 p_{nj} \\prod_{h=1}^C p_h^{a_{nh} - 1} dp_n \\\\&= \\sum_{j=1}^C y_{nj} (\\psi(S_n) - \\psi(a_{nj})), \\end{aligned}$ where $\\psi(\\cdot)$ is the digamma function. And to grarantee that the evidence generated by the incorrect labels is lower, we introduce the Kullback-Leibler (KL) divergence into the loss function:\n$\\begin{aligned}L_{KL}(a_n) &= KL[D(p_n|\\tilde{a}_n) || D(p_n|1)] \\\\&=log\\frac{\\Gamma(K)}{\\prod_{c=1}^C \\Gamma(a_{nc})} + \\sum_{j=1}^C (a_{nc} - 1) (\\psi(a_{nc}) - \\psi(\\tilde{a}_{nj})), \\end{aligned}$\nwhere $D(p_n|1)$ is the uniform Dirichlet distribution, $\\tilde{a}_n = y_n + (1 - y_n) \\circ a_n$ is the Dirichlet distribution parameter after removing the evidence of the ground-truth category from the original parameter $a_n$. $\\lambda_t = min(1, t/T) \\in [0, 1]$ is the annealing coefficient, acting as the balance factor in the training process. As the training process progresses, $\\lambda_t$ continues to increase, enhancing the influence of KL divergence accordingly, to prevent premature convergence of misclassified instances to the uniform distribution.\nThe view-specific loss function of $x^v$ is defined as:\n$L_{vs}(a_n^v) = L_{ace}(a_n^v) + L_{KL} (a_n^v)$,\nwhere $a_n^v = e_n^v + 1$ is the parameters of the corresponding Dirichlet distribution, $e_n^v = f(x^v)$ represent the evidence vector predicted by the view-specific neural network."}, {"title": "3.3.2 Consistent Loss Function", "content": "The consistent evidence is obtained by aggregating the consistent portions of all views. Consequently, we impose a stringent alignment between the opinion constructed from the consistent evidence and the ground-truth category. To accomplish this, we adjust the probabilities assigned to the true and false classes while simultaneously enhancing the distinction between them. To achieve this objective, we introduce two principles: the Error Reduction Principle and the Separability Principle.\nSeparability Principle. The Separability Principle emphasizes the importance of creating a significant distinction between the evidence supporting different categories during the classification process. This principle allows the classifier to more accurately distinguish between different categories, especially semantic vagueness categories. For instance, consider the belief masses of opinions $b^1 = (0.4, 0.4)$ and $b^2 = (0.3, 0.5)$. The total amount of belief mass in $b^2$ is more than $b^1$. However, the greater degree of separation of $b^2$ makes it more contribution to the classification result than $b^1$. To enhance classification performance, we need to increase the degree of separation during the training process. Therefore, we quantify the degree of separation of the belief masses supporting different classes in opinion using the separation degree.\nDefinition 3.2. (Separation Degree). For the subjective opinion $w = (b, u, a)$, where $b = (b_1, \\dots, b_C)$, the separation degree can be defined as:\n$SD(b) = \\sum_{i=1}^C \\sum_{i \\neq j} |b_i - b_j|$.\nOur goal is to increase the separation degree of consistent opinions. There are two approaches to increase it: the first approach involves adding a constraint to maximize the degree of separation. However, this approach may lead to an increase in the total amount of evidence across all categories. This is contrary to our original intention of controlling uncertainty based on the total amount of evidence. Therefore, we design the following method.\nWe first convert consistent evidence into consistent opinions $\\hat{w}^{con} = (\\hat{b}^{con}, u^{con}, a^{con})$ and adjust it to obtain the final consistent opinion $\\tilde{w}^{con} = (\\tilde{b}^{con}, u^{con}, a^{con})$:\n$\\tilde{b}^{con} = (\\tilde{b}_1^{con}, \\dots, \\tilde{b}_C^{con}), \\\\ \\tilde{b}_c^{con} = \\begin{cases} \\frac{\\hat{b}_c^{con}}{\\sum_{c=1}^C \\hat{b}_c^{con}}, & \\sum_{c=1}^C \\hat{b}_c^{con} \\neq 0, \\\\ 0, & otherwise, \\end{cases}$\nwhere $\\tilde{b}_c^{con} = pow(\\hat{b}_c^{con}, \\beta) \\in [0,1]$ is the belief mass supporting classes $c$, $\\beta$ is a hyper-parameter which is bigger than 1. For $a^{con}$, we follow related works to set each $a^{con}$ as 1/C without prior evidence. By the power operation $pow(\\hat{b}_c^{con}, \\beta)$, the separation degree would increase. The reason behind this is the increasing disparity in the confidence mass that supports each category. We also demonstrate theoretically that this approach can increase the separation degree, which is elaborated in the appendix. Therefore, we only need this simple operation to achieve the increase of separation degree without changing the total amount of evidence.\nError Reduction Principle. The error reduction principle highlights that during the training process, the evidence generated for incorrect categories may inadvertently increase due to the inherently limited availability of counterexamples. This misleading evidence has the potential to introduce challenges to the classification process. Therefore, we also use the KL divergence to actively reduce evidence for incorrect labels categories.\nUnder the guidance of the above two principles, we can derive the consistent loss function:\n$L_{con}(a_n^{con}) = L_{ace} (a_n^{con}) + L_{KL} (a_n^{con})$.\nwhere $a_n^{con}$ represents the corresponding parameters of the final Dirichlet distribution of the consistent opinion. The consistent loss function can refine the consistent evidence. After increasing the separation degree, the cross-entropy loss function minimizes the model's deviation from the true label, and the KL loss function reduces the evidence for incorrect categories. The combination of these two loss functions can maximize the impact of consistent evidence on the model training process."}, {"title": "3.3.3 Complementary Loss Function", "content": "Vagueness Principle. Complementary evidence usually represents complementary or even conflicting information between different views. Its reliability is generally lower than that of the consistent evidence. As a supplement to the consistent evidence, the complementary evidence need not necessarily enhance the degree of separation or reduce false labels like consistent evidence. It accounts for potential vagueness in multi-view data. Therefore, it is only required to reflect the probability of the true category.\nAccording to this principle, we define the complementary loss function as follows:\n$L_{cmp}(a_n^{cmp}) = \\sum_{j=1}^C y_{nj} (\\psi(S_n^{cmp}) - \\psi(a_{nj}^{cmp})),$ where $a_n^{cmp} = e_n^{cmp} + 1$ is the corresponding Dirichlet parameter of the complementary evidence."}, {"title": "3.3.4 Joint Loss", "content": "By synthesizing the above objectives, the overall loss function for a specific instance $\\{x_n^v\\}_{v=1}^V$, is formulated as:\n$L = \\sum_{v=1}^V L_{vs} (a_n^v) + \\delta L_{con}(a_n^{con}) + \\gamma L_{cmp}(a_n^{cmp})$\nwhere $\\delta, \\gamma > 0$ are hyper-parameters that we can adjust."}, {"title": "4 Experiment", "content": "In this section, we show the empirical results of CCML in making trusted decisions for multi-view inputs. We first apply CCML on a synthetic toy example to investigate its performance in solving the semantic vagueness problem, then we evaluate CCML on six real-world multi-view datasets, compare it with existing multi-view learning methods and conduct other analysis experiments."}, {"title": "4.1 A Toy Example", "content": "The major advantage of CCML compared with pioneer uncertainty-aware methods is the ability to perceive consistent and complementary information between different views. Therefore, we conducted a set of comparative experiments with TMC in the Toy Dataset to investigate the effectiveness of CCML in solving semantic vagueness questions and to explicitly achieve higher accuracy results.\nWe set view 1 cannot distinguish categories $c_2$ and $c_3$ and view 2 cannot distinguish categories $c_1$ and $c_2$, respectively. Specifically, the toy dataset consists of 2 views, each with 1200 data instances $\\{x_n^v\\}_{n=1}^{1200}$ belonging to 3 categories, $C_1$, $C_2$, and $c_3$, with 400 data instances in each category. The underlying latent space has 9 dimensions, with three for each category. The first 3 dimensions and the last 3 dimensions are private to categories $c_1$ and $c_3$ respectively, and the middle dimensions are a shared dimension for $c_2$ and $c_3$. Each element of $\\{x_n^v\\}_{n=1}^{1200}$ is the sum of a number sampled from a gamma-distributed $\\Gamma(1, 0.9)$, the noise sampled from Gaussian distribution $N(0, 0.1)$, and a consistent term of 0.5. We randomly generated 12 \u00d7 9 basis matrices $W^v$ for the two views, with elements drawn from a uniform distribution $U (0.4, 1)$, We randomly set 30 percent of the elements to be zero to simulate the real-world multi-view mapping pattern. Then we generated a noise matrix $Z^v$, and the elements of $Z^v$ drawn from by the Gaussian distributions $N(0, 0.5)$ and $N(0, 1)$, respectively. We use the equation $x^v = W^v + z^v$ to generate data instances.\nIn the Toy Dataset, we set the last 3 columns of $W^1$ to be 0 and the first 6 columns of $W^2$ to be 0, respectively. Therefore, the data instances in view 1 cannot distinguish between categories $c_2$ and $c_3$, and the data instances in view 2 cannot distinguish between categories $c_1$ and $c_2$. The Toy Dataset represents a strong complementarity between the two perspectives. For a more intuitive explanation, we use t-SNE to visualize the multi-view data instances of the Toy Dataset, as shown in Figure 3.\nIn addition, to obtain a better and intuitive understanding of the advantages of CCML over TMC in addressing semantic vagueness problems, we also conduct t-SNE visualization on the test samples by evidences of different categories during testing process of two methods, the result as illustrated in Figure 4."}, {"title": "4.2 Experiment on Real-world Datasets", "content": ""}, {"title": "4.2.1 Experimental Setup", "content": "Datasets. HandWritten comprises 2000 instances of handwritten numerals ranging from '0' to '9', with 200 patterns per class. It is represented using six feature sets. Scene15 includes 4485 images from 15 indoor and outdoor scene categories. We extract three types of features HOG, LBP, and GIST. CUB consists of 11788 instances associated with text descriptions of 200 different categories of birds, we focus on the first 10 categories and extract image features using GoogleNet and corresponding text features using doc2vec. LandUse comprises 2100 images from 21 classes. We extract HOG and SIFT features as two views. PIE contains 680 facial instances belonging to 68 classes. We extract intensity, LBP, and Gabor as 3 views. Colored-MNIST includes 18835 instances of numerals with RGB coloured backgrounds which consist of three colours (red, green, blue) for each number. We focus on the 1200 instances and extract RGB and HOG features as two views.\nCompared Methods. (1) Single-view uncertainty aware methods contain: EDL (Evidential Deep Learning) and IEDL which is the SOTA method that combines Fisher's information matrix. (2) Multi-view feature fusion methods contain: DCCAE (Deep Canonically Correlated AutoEncoders) is the classical method, which employs autoencoders to seek a common representation, DCP (Dual Contrastive Prediction) is the SOTA method that obtains a consistent representation. (3) Multi-view decision fusion methods contain: CALM (Enhanced Encoding and Confidence evaluating framework) takes advantage of cross-view consistency and diversity to improve the efficacy of the learned latent representation, ETMC (Enhanced Trusted Multi-view Classification) , addresses the uncertainty estimation problem and produces reliable classification results. RCML (Reliable Conflictive Multiview Learning) is the SOTA method that proposed a fusion strategy for solving multi-view conflictive problems.\nImplementation Details. We briefly introduce the details of the experiment. We utilize fully connected networks with a ReLU layer to extract view-specific evidence. The Adam optimizer is used to train the network, where L2-norm regularization is set to 1e-5. We employ 5-fold cross-validation to select the learning rate from the options of 3e-3, 1e-3, 3e-4, 1e-4. In all datasets, 20% of the instances are allocated as the test set. The average performance is reported by running each test case five times."}, {"title": "4.2.2 Performance Comparison", "content": "We compare CCML with the other classification methods, and the results are shown in Table 2. We can obtain that: (1) multi-view methods generally outperform single-view methods, which illustrates the necessity of using multiple views in classification tasks. (2) There is a large difference in accuracy among different methods on the Colored-MNIST dataset, demonstrating significant variation in the ability of different methods to solve the semantic vagueness problem. (3) For the majority of real-world datasets, CCML shows performance comparable to state-of-the-art methods and has outstanding performance on Colored-MNIST datasets. (4) This result indicates that CCML significantly improves the ability to handle the semantic vagueness phenomenon while ensuring good performance on general classification tasks. The reason would be attributed to the consistent and complementary dynamic decoupling method, we would further verify this in the next analysis and other experiments."}, {"title": "4.2.3 Analysis", "content": "Ablation Study. To validate the effectiveness of the evidence decoupling strategy, separability principle, and error evidence reduction principle, we construct a detailed ablation study that performs different combinations of these modules to achieve degradation methods. Specifically, to verify the effectiveness of the evidence decoupling module, we compared the approach with the three modules removed to using only that module. The effectiveness of the other two modules was validated based on the decoupling module respectively. We conduct the degradation methods above on the dataset Colored-MNIST. The results are shown in Table 4. From the result, we can observe the outstanding effectiveness of our dynamic decoupling strategy. Therefore, to further validate the effectiveness of the evidence decoupling module, we propose 6 variants of the CCML which Only use Consistent Evidence, Only Complementary Evidence, simple Accumulation of Evidence, simple Average of Evidence, Average of Evidence with Separation, and Accumulate of Evidence with Separation, respectively. We conduct CCML and variants on the CUB datasets and obtain experimental results as shown in Table 3. Compared to other methods, CCML achieves higher accuracy because it decouples and processes consistent and complementary evidence separately, giving higher confidence and increasing the separation degree for consistent evidence while averaging complementary evidence. This allows CCML to adjust the corresponding uncertainties based on the consistency between different views, instead of considering only one type of evidence or applying the same separation processing strategy to both consistent and complementary evidence. From the ablation study, we verified the effectiveness of each module of CCML.\nParameter Analysis. The separation increase module can improve the model's performance in solving classification tasks. We verify the influence of the separation increase module on the model by changing the value of the hyperparameter $\\beta$. Specifically, we gradually increase the hyperparameter $\\beta$ from 1 to 5 and observe CCML's performance on all datasets as shown in Figure 5. The results show that the accuracy of the model increases first and then decreases with the change of $\\beta$. In particular, the effectiveness of $\\beta$ in the semantic vagueness phenomenon is demonstrated on the dataset Colored-MNIST by the significantly increased accuracy. We can obtain the point that when the $\\beta$ is too large, it will have a negative impact on the model, and the appropriate $\\beta$ value can improve the performance of the model to a certain extent.\nUncertainty Estimation. To further evaluate the estimated uncertainty, we used the original dataset CUB and constructed out-of-distribution instances. We consider the original test instances as in-distribution data and add Gaussian noise $N(0, I)$ with intensity $\\eta$ to the test instances in one view, constructing out-of-distribution test instances. Specifically, given the noise vector $e_i$ sampled from the Gaussian distribution, the out-of-distribution test instances $X_i = x_i + \\eta e_i$. The uncertainty associated with out-of-distribution data is expected to be higher compared to that of in-distribution data. The noise intensity increases in the sequence ($\\eta$ = 0.1, 1, 2, 5)."}, {"title": "5 Conclusion", "content": "In this paper, we propose a CCML method to solve the semantic vagueness problem in trusted multi-view learning. CCML tries to dynamically decouple the consistent and complementary evidence from the view-specific evidence. It further processes consistent and complementary evidence according to different principles to achieve classification results and reliability. The experimental results on the synthetic toy dataset and six real-world datasets verified the effectiveness of the proposed decouple strategy and the performance superiority of CCML."}]}