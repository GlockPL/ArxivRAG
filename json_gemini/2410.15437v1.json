{"title": "AttCDCNet: Attention-enhanced Chest Disease Classification using X-Ray Images", "authors": ["Omar H. Khater", "Abdullahi S. Shuaib", "Sami Ul Haq", "Abdul Jabbar Siddiqui"], "abstract": "Abstract-Chest X-rays (X-ray images) have been\nproven to be effective for the diagnosis of chest diseases,\nincluding Pneumonia, Lung Opacity, and COVID-19.\nHowever, relying on traditional medical methods for\ndiagnosis from X-ray images is prone to delays and\ninaccuracies because the medical personnel who evaluate\nthe X-ray images may have preconceived biases. For\nthis reason, researchers have proposed the use of deep\nlearning-based techniques to facilitate the diagnosis pro-\ncess. The preeminent method is the use of sophisticated\nConvolutional Neural Networks (CNNs). In this paper,\nwe propose a novel detection model named AttCDCNet\nfor the task of X-ray image diagnosis, enhancing the\npopular DenseNet121 model by adding an attention block\nto help the model focus on the most relevant regions,\nusing focal loss as a loss function to overcome the im-\nbalance of the dataset problem, and utilizing depth-wise\nconvolution to reduce the parameters to make the model\nlighter. Through extensive experimental evaluations, the\nproposed model demonstrates exceptional performance,\nshowing better results than the original DenseNet121.\nThe proposed model achieved an accuracy, precision and\nrecall of 94.94%, 95.14% and 94.53%, respectively, on\nthe COVID-19 Radiography Dataset.", "sections": [{"title": "I. INTRODUCTION", "content": "Respiratory diseases are a very serious public health\nproblem that many people in the world suffer from.\nThe diagnosis of such diseases is very important for\nproper patient care and therapy. X-ray images have\nbecome widely used as an easy and cost-effective way\nto promptly identify the unique patterns associated\nwith respiratory diseases, enabling their diagnosis.\nDespite this, the precise and automatic diagnosis of\nsuch diseases from X-ray images appears to be a\nchallenge because of the complexity and fluctuating\nnature of the disease manifestation [1].\nOver the past few years, various medical image\nanalysis tasks, such as predicting Pneumonia from X-\nray images, have demonstrated promising outcomes,\nespecially through the use of Convolutional Neural\nNetworks (CNNs)[2][3]. CNNs possess the capacity\nto acquire detailed information from images, enabling\nthem to identify patterns that indicate the presence\nof respiratory diseases. DenseNet121[4], a popular\nCNN architecture, has shown excellent performance\nin medical image processing tasks thanks to its dense\nconnections and efficient feature propagation [1]."}, {"title": "II. LITERATURE REVIEW", "content": "Extensive research has been conducted on the uti-\nlization of deep learning techniques for diagnosing\nrespiratory diseases in patients using X-ray images.\nBelow, we provide a concise overview of the most\nsignificant methodologies.\nIn [7], H. Malik et al. introduce a unique fusion\nmodel that combines hand-crafted features with Deep\nConvolution Neural Networks (DCNNs) to classify ten\ndifferent chest diseases using chest X-ray images. This\napproach significantly enhances classification accu-\nracy, demonstrating a novel contribution to automated\ndiagnostic tools in medical imaging. The authors di-\nvided 181,719 X-ray images into segments of 80%,\n10%, and 10% for training, validation, and testing,\nrespectively. The proposed fusion model in the paper"}, {"title": "III. PROPOSED METHOD", "content": "The human respiratory system could be subject to a\nrange of pulmonary diseases. These include COVID,"}, {"title": "A. Proposed Model", "content": "DenseNet121 is a state-of-the-art CNN architec-\nture that has demonstrated remarkable performance\nin image classification tasks [5]. DenseNet121 has\ntwo major aspects that make it stand out from other\nCNN models. First, it features a dense block structure,\nwhere each layer is coupled to every other layer in a\nfeed-forward method. Second, it employs bottleneck\nlayers that assist in minimizing the number of param-\neters without diminishing the number of characteristics\nlearnt by the network.\nIn this work, two enhancements to the basic\nDenseNet121 model were introduced. A detailed de-\nscription of each enhancement and the motivation\nbehind each is given below.\n1) Introducing Attention Blocks: Inspired by [5],\nan attention block is added after every dense block,\nas depicted in Figure 1. The attention mechanism\ncalculates the attention weights for each channel of\nthe input feature maps. These weights are then utilized\nfor the feature maps using element-wise multiplication,\nallowing the network to emphasize important features\ndynamically while minimizing the impact of less rel-\nevant ones. The attention block consists of global av-\nerage pooling followed by two fully connected layers\nand, finally, the multiplication of the original feature"}, {"title": "1) Introducing Attention Blocks: Inspired by [5], an attention block is added after every dense block, as depicted in Figure 1. The attention mechanism calculates the attention weights for each channel of the input feature maps. These weights are then utilized for the feature maps using element-wise multiplication, allowing the network to emphasize important features dynamically while minimizing the impact of less rel-evant ones. The attention block consists of global av-erage pooling followed by two fully connected layers and, finally, the multiplication of the original feature", "content": "maps by the attention score, as shown in Figure 1. The\ndetails of the attention block are given below:\n\u2022 Global average pooling: This pooling operation\nreduced the spatial dimensions of the feature\nmaps into a single vector, thereby collecting\nglobal information.\n\u2022 Fully connected Layers: Global information is\npropagated across fully linked layers in order to\nlearn the significance of various features.\n\u2022 Sigmoid activation: The job of sigmoid activa-\ntion is to restrict the attention score between 0\nand 1 to indicate the importance of each feature.\n\u2022 Multiplication: Ultimately, a multiplication op-\neration between the initial feature map and the\nattention scores is done to highlight important\nfeatures and diminish less pertinent ones."}, {"title": "2) Depthwise Separable Convolutions: Inspired by [6], we employ depthwise convolutions instead of the standard convolutions. Depthwise separable convolu-tions are a factorized form of conventional convo-lutions that decrease the number of parameters and calculations, resulting in more efficient models.", "content": "2) Depthwise Separable Convolutions: Inspired by\n[6], we employ depthwise convolutions instead of the\nstandard convolutions. Depthwise separable convolu-\ntions are a factorized form of conventional convo-\nlutions that decrease the number of parameters and\ncalculations, resulting in more efficient models.\nDepthwise separable convolution is a convolutional\noperation that consists of two distinct steps:\n\u2022 Depthwise convolution: Convolution is applied\non a single channel at a time, unlike standard\nCNNs, which operate on all the M channels. So\nhere, the filters will be of size $D_k \\times D_k \\times 1$. For\nM channels in the input, M filters have to be\nused. The result will be of size $D_p \\times D_p \\times \u041c$.\n\u2022 Pointwise convolution: A 1 \u00d7 1 convolution op-\neration is executed on the M channels in a point-\nwise fashion. So, the filter size will be 1 \u00d71\u00d7M\nfor this operation. Say we apply N such filters;\nthe output size becomes $D_p \\times D_p \\times N$."}, {"title": "IV. EXPERIMENTAL SETUP", "content": "The experiment setup for the proposed model in-\ncludes multiple details regarding the hardware con-\nfiguration, dataset sources, and hyper-parameters used\nin the enhanced DenseNet121 model. The hardware\nutilized compromises NVIDIA GeForce GTX 106 with\n6 GB memory, and the RAM size is 16 GB. The\ndataset[15][16] used contains 21,265 X-ray images\nwith four classes as shown in Table III. The hyper-\nparameters used in our experiments are shown in\nTable II."}, {"title": "A. Dataset", "content": "The dataset selected in this study consists of samples\nfrom cases of COVID-19, lung opacity, viral Pneumo-\nnia, and healthy lungs. It was acquired from Kaggle, an\nonline resource of open-source datasets [15][16]. The\ndatasets consist of a total of 21,265 labelled X-ray\nimages, of which 3,716 were COVID-19, 6,012 were\nlung opacity, 10,192 were viral Pneumonia, and 1,345\nwere normal lungs. We split the collected data into\n70% for training, 10% for validation, and 20% for\ntesting. Table III illustrates the dataset."}, {"title": "V. RESULTS AND DISCUSSIONS", "content": "While utilizing all the elements in our experimental\nsetup, we were able to implement an enhanced model\nversion of DenseNet121. The proposed model outper-\nforms the original DenseNet121, ResNet50, VGG16,\nand VGG19 on the same dataset. The precision, recall,\naccuracy, and loss after each epoch were recorded.\nAlso, Focal loss as a loss function instead of cross-\nentropy has been utilized in our model, which helps\nthe model solve the problem of class imbalance. Also,\nour proposed model outperformed the DenseNet121 in\n[17], where they used the same dataset for the same\npurpose."}, {"title": "A. Performance of Enhanced DenseNet", "content": "The accuracies of our models with and without focal\nloss with (20 epochs) in experiment 1 are 91.96%\nand 91.90%, respectively, while the precisions were\n93.01% and 92.32%, respectively. The recalls were\n91.06% and 91.55%, respectively. Figure 12 indicates\nhow the performance of the model is affected by the\nincrease in the number of epochs. The performance\nof the model improves because the focal loss forces\nthe model to pay attention to the minority parts of\nthe X-ray images where the disease symptoms lie.\nFor experiment 2 (100 epochs), the accuracy, preci-\nsion and recall of our proposed model with a focal\nloss is 94.94%, 95.14% and 94.53%, respectively, as\ndemonstrated in Figure 12."}, {"title": "B. Comparative Analysis", "content": "We performed experiments to compare our model\nwith the state-of-the-art models. Our model has the\nfewest number of parameters. Additionally, has the\nshortest inference time on Google Colab. In the first\nexperiment, results were compared after 20 epochs\nof training. The result of this is shown in Table IV.\nIn the second experiment, we evaluate the impact of\nusing focal loss on our model. The comparison is\nshown in Table ??. In Figures 8-12, we plot several\nperformance metrics of the considered models against\nthe number of epochs. This also serves to shed light on\nthe convergence characteristics of the training process.\nIn order to compare the interpretability capacity of\nour model and the state-of-the-art models, we employ\nGrad-Cam [18] for heatmap visualizations on selected\nX-ray images. We show on a side-by-side basis how\nour model performs with superiority in Figures 4-7.\nWe also observe that the addition of the attention block\nhas a crucial role in focusing on the most relevant\nfeatures in the images, which significantly assists the\nmodel during classification."}, {"title": "VI. CONCLUSIONS AND FUTURE WORK", "content": "We have been able to diligently show that adding\nattention blocks to DenseNet improves its performance\nsignificantly in predicting diseases from X-ray im-\nages. This owes to the focusing nature of attention\nblock. Furthermore, the depthwise convolution has\nbeen shown to decrease the complexity of the mode\nwhile preserving its ability to perform classification\naccurately. Considering that our dataset was not aug-\nmented, we deem it a necessary step that will make\nour model more robust. Furthermore, additional com-\nparisons should be made with other models, especially"}]}