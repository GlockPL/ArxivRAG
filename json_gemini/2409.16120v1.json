{"title": "MOSS: ENABLING CODE-DRIVEN EVOLUTION AND CONTEXT MANAGEMENT FOR AI AGENTS", "authors": ["Ming Zhu", "Yi Zhou"], "abstract": "Developing AI agents powered by large language models (LLMs) faces significant challenges in achieving true Turing completeness and adaptive, code-driven evolution. Current approaches often generate code independently of its runtime context, relying heavily on the LLM's memory, which results in inefficiencies and limits adaptability. Manual protocol development in sandbox environments further constrains the agent's autonomous adaptability. Crucially, achieving consistency in code and context across multi-turn interactions and ensuring isolation of local variables within each interaction remains an unsolved problem.\nWe introduce MOSS (IIM-oriented Operating System Simulation), a novel framework that addresses these challenges by integrating code generation with a dynamic context management system. MOSS ensures consistency and adaptability by using a mechanism that maintains the Python context across interactions, including isolation of local variables and preservation of runtime integrity. At its core, the framework employs an Inversion of Control (IoC) container in conjunction with decorators to enforce the least knowledge principle, allowing agents to focus on abstract interfaces rather than concrete implementations. This facilitates seamless integration of new tools and libraries, enables runtime instance replacement, and reduces prompt complexity, providing a \"what you see is what you get\" environment for the agent.\nThrough a series of case studies, we show how this framework can enhance the efficiency and capabilities of agent development and highlight its advantages in moving towards Turing-complete agents capable of evolving through code.", "sections": [{"title": "1 Introduction", "content": "The development of AI agents[1, 2] has seen rapid advancement in recent years, particularly with the integration of large language models (LLMs) [3, 4, 5, 6] into various applications and systems. In particular, AI agents, systems that can integrated tools[7, 8, 9] and interact with external environment, have recently received ever-increasing research focus. These agents are progressively tackling more complex tasks, ranging from software development [10, 11, 12] and web navigation [13], even conducting scientific research [14, 15]. As the field progresses, there is a growing interest in creating agents that can move beyond understanding and generating structured languages like JSON or domain-specific languages (DSLs) [16]. The next frontier involves agents capable of using code as a medium for planning, reasoning, and dynamically creating tools, leading to the emergence of truly adaptive, code-driven AI agents."}, {"title": "2 Method", "content": ""}, {"title": "2.1 Overview of the MOSS Framework", "content": "MOSS (IIM-oriented Operating System Simulation) is an essential component of the broader agent project GhostOS. GhostOS is designed to support advanced agent capabilities such as multi-task orchestration, environment interaction, and embodied control. MOSS specifically focuses on enabling AI agents to generate and execute Python code dynamically, while managing runtime contexts to ensure consistency across multi-turn interactions.\nMOSS operates on the following key principles:\nPython Context Reflection It dynamically reflects the structure of Python modules, including variables, functions, and class definitions, into prompts. This allows the LLM to generate code with full awareness of the current execution context, ensuring the code is scoped accurately and appropriately.\nDependency Injection via IoC MOSS uses an Inversion of Control (IOC) container for injecting dependencies into the runtime. This enables the agent to integrate dynamically instantiated libraries, such as multi-task schedulers, chain-of-thought planners [25, 26, 27], environment sensors, and embodied APIs. By interacting through abstract interfaces, the agent remains adaptable to changing requirements without needing to modify its core logic.\nState Preservation Across Multi-Turn Interactions The framework maintains a consistent execution context, preserving the state of variables and modules across multiple turns. Each interaction is isolated in its own frame, ensuring that local variables do not leak into other tasks, while global context is inherited as needed to support long-term task management.\nExecution of LLM-Generated Code After generating Python code, MOSS executes it within the Python runtime. The results, along with runtime data, are integrated into the agent's thought history, providing real-time feedback that informs subsequent decision-making and task execution.\nBeyond these core operational components, MOSS introduces a powerful mechanism for handling complex multi-task scenarios and long chains of thought. To manage this, the framework includes advanced scheduling and orchestration features within specialized libraries, which are accessible to the LLM. This allows agents to efficiently break down and execute intricate, multi-step tasks while maintaining overall coherence and adaptability.\nBy integrating code generation, dependency injection, and dynamic context management, MOSS provides the foundation for developing Turing-complete AI agents. These agents can handle complex, multi-step tasks in an isolated and context-aware manner, with the potential for adapting and evolving their capabilities through code over time."}, {"title": "2.2 Lifecycle of executing a task with MOSS", "content": "The lifecycle of a MOSS agent involves managing complex, multi-turn tasks through a series of steps, organized into Threads and executed within Frame like mechanism. Each Thread represents a sequence of interactions, and each Frame manages the execution context for a specific step or set of steps. When the agent encounters an AIFunc or Thought in a higher-level frame (e.g., frame m), these intelligent units only have a definition but lack a body.\nMOSS uses a recursive process to handle this. The MOSS Compiler steps in to compile the surrounding code and definitions, transforming them into a temporary Python module. This module provides the necessary execution context, including variables, dependencies, and AIFunc/Thought definitions, while keeping the environment isolated and consistent. The MOSS Runtime then processes this temporary module, converting it into a prompt for the large language model (LLM). The LLM generates the missing body, typically as a 'main' function, to complete the task at hand.\nAfter the code is generated, MOSS executes the new code within the current frame's isolated context. If this execution involves further AIFunc or Thought calls, the agent drills down into a new frame (e.g., frame m+1), and the process repeats. This recursion allows MOSS to manage multi-step, complex tasks in a structured, isolated manner, ensuring each interaction's integrity through its IoC container and PyContext. Once the task in a frame is complete, the result is passed back to the parent frame, allowing the agent to continue processing seamlessly from where it left off.\nThis iterative cycle of code generation, execution, and feedback allows MOSS agents to manage dynamic, multi-turn interactions while preserving runtime context and achieving Turing-complete behavior."}, {"title": "2.3 Context Consistency", "content": "Ensuring consistency across multi-turn interactions in MOSS starts with isolating each round of execution. Every interaction is compiled and executed in its own temporary ModuleType container, preventing any unintended side effects or variable leakage between rounds. This execution isolation ensures that each interaction operates in a clean, independent environment, free from interference by previous or subsequent steps.\nTo maintain continuity, MOSS captures the side effects of each interaction through a serializable PyContext object. This PyContext holds local variable modifications and runtime dependencies, allowing relevant state information to persist across multiple turns. By doing this, MOSS ensures that while local variables remain isolated, essential context is preserved and carried forward, enabling the agent to dynamically adapt and evolve without losing track of its execution history."}, {"title": "2.4 Leveraging IoC for Runtime Flexibility and Abstraction", "content": "In MOSS, the Inversion of Control (IOC) container plays a crucial role in decoupling the abstract interfaces that define agent capabilities from their runtime-specific implementations. This separation allows agents to operate within a dynamic environment where specific tools and functionalities are instantiated only when needed, without the LLM requiring knowledge of their internal workings. The IoC container enables MOSS to provide consistent access to these capabilities via interfaces, while abstracting away the complexity of how they are instantiated or modified at runtime. The primary advantage of IoC in MOSS is its ability to inject dependencies dynamically at runtime, following the least knowledge principle. This ensures that the LLM can focus on leveraging abstract interfaces such as task schedulers, environment sensors, or APIs without needing to understand or instantiate their underlying implementations. For example, an LLM may generate code to interact with an interface for file management or debugging, while MOSS handles the actual instantiation of these tools based on the runtime context, allowing for seamless integration of diverse libraries and tools as needed.\nThis design pattern also aligns with the Liskov Substitution Principle[28], as it allows different implementations of the same interface to be substituted without affecting the LLM's understanding of the task. This makes it possible to mock these interfaces during testing, allowing developers to refine prompts and verify the agent's use of the interface before integrating actual implementations. By doing so, developers can optimize LLM behavior under controlled conditions and later replace mocks with the real dependencies without changing the LLM's core logic or prompts. In essence, IoC in MOSS allows agents to remain adaptable and modular, facilitating the smooth integration of new tools and capabilities at runtime. This also improves testing and prompt refinement, as developers can easily experiment with abstracted interfaces before committing to full implementations. By decoupling runtime-specific details from high-level task execution, IoC ensures that MOSS agents are more flexible and maintainable."}, {"title": "2.5 Intelligent Units: AIFunc and Thought", "content": "MOSS operates as a lightweight framework that facilitates the use of external intelligent units, such as AIFunc and Thought, although they do not originate from MOSS itself. MOSS provides the necessary infrastructure for running these intelligent units in a structured and context-consistent manner, serving as an IIM-oriented OS simulation that can be integrated into other agent frameworks. These intelligent units leverage MOSS for their execution but are designed to extend agent capabilities by allowing multi-turn code generation and interaction with complex runtime environments.\nAIFunc AIFunc represents synchronous intelligent functions. An AIFunc appears as a typical Python function that can be invoked with predefined parameters. However, in practice, its execution involves single-turn interactions where it generates and executes code across multiple steps, often driven by real-time feedback. Each AIFunc operates within its own execution frame, ensuring the isolation of local variables while maintaining access to a shared global context. By nesting AIFuncs or calling them from within Thoughts, agents can handle complex, multi-layered tasks through code that adapts dynamically to the current execution context.\nThought Thought represents asynchronous, multi-turn intelligent processes. Unlike AIFunc, which focuses on single interactions, Thought engages in ongoing reasoning, adapting strategies dynamically based on feedback from the environment. Thoughts run asynchronously and can manage multiple complex tasks in parallel, using tools and code execution provided by MOSS. Thought functions as a domain-specific intelligent unit, solving specialized problems while sharing the same meta-prompt as other agents. This enables more complex, long-term task orchestration and problem-solving."}, {"title": "2.6 Code-Driven Evolving", "content": "MOSS establishes a code-driven framework as the foundation for AI systems capable of evolving through code. This paradigm shifts the focus from traditional development protocols to a system where code itself drives the creation, interaction, and evolution of agents. By treating code as the central mechanism, MOSS maximizes flexibility and adaptability during agent development, allowing for continuous improvements. This code-centric approach is a significant step toward self-evolving systems, where agents can dynamically adjust and enhance their capabilities based on new code inputs and interactions.\nCode-Driven Tool/Library Integration MOSS allows agents to interact with tools and libraries through dynamically generated Python code, reducing the need for manual protocol development. While tools still require defined interfaces, the goal is for agents to directly read and understand code repositories, integrating them as tools. Future libraries may evolve into interface-based code repositories, where agents can autonomously bind implementations using dependency injection. This minimizes integration overhead and allows embodied agents to dynamically develop drivers and tool controls through code."}, {"title": "3 Case Studies", "content": ""}, {"title": "3.1 Create a Tool through Code Manipulation", "content": "In this case, we explore how MOSS enables LLMs to edit existing code dynamically and generate a new tool by interacting with the code via a custom tool called ModuleEditor. ModuleEditor provides an interface that allows agents to read, modify, and append Python code in a target module, and it integrates into the MOSS framework through the IoC container. In this example, the agent is tasked with generating the implementation of a caching tool (MockCache), dynamically editing the module by adding the necessary class definitions.\nThis showcases the ability of MOSS to allow agents to utilize dynamically injected tools to edit and expand code autonomously.\nSetup The MOSS framework dynamically reflects the ModuleEditor interface into the LLM's runtime context via dependency injection using the IoC container. The MOSS file defines a Moss class, which integrates ModuleEditor as an attribute. This attribute is exposed to the LLM as part of the prompt, allowing the agent to directly invoke ModuleEditor's methods during task execution.\nIn the MOSS file, ModuleEditor is injected as a tool, and the agent is tasked with replacing the MockCache class definition within a Python module. The agent achieves this by calling the replace_attr method of ModuleEditor to modify the code in place. The task prompt is augmented by MOSS to ensure the LLM has full knowledge of the ModuleEditor methods, ensuring smooth interaction with the Python module."}, {"title": "Thought Definition: PyModuleEditorThought", "content": "To guide the agent in its task, developer or a meta- agent can define a Thought that provides the agent with instructions on how to modify the module. The agent is tasked with implementing the MockCache class in the target module by leveraging the ModuleEditor."}, {"title": "Results and Analysis", "content": "The agent successfully implements the MockCache class by generating the appropriate Python code and using the replace_attr method of ModuleEditor to replace the placeholder class definition with the new implementation. The result demonstrates the agent's ability to autonomously modify code through tool integration, allowing for dynamic code evolution. By employing the MOSS framework, the agent ensures that the newly generated code is correctly inserted into the target module, preserving the execution context and maintaining isolation between tasks.\nThe successful implementation of MockCache highlights the importance of MOSS files in defining the agent's runtime environment. The MOSS file plays a crucial role in shaping the prompt seen by the LLM, which includes the necessary tool interfaces and system-wide configuration. The tool-driven approach is facilitated by MOSS's IOC container, allowing for seamless interaction between the agent and external libraries."}, {"title": "3.2 Asynchronous Multi-Task Management", "content": "In this case, we show how MOSS enables asynchronous multi-task scheduling through the integration of the MultiTask library, efficiently managing and executing multiple file-editing tasks concurrently. The scenario involves editing a directory of .py files to translate Chinese comments into English. MOSS's capability to orchestrate multiple FileEditorThought instances allows it to dispatch and manage these tasks asynchronously, showcasing its ability to handle complex, multi-step operations in parallel.\nSetup The Directory Editor Thought is defined to manage a directory of files, while the FileEditorThought focuses on editing individual files. Through the MOSS file, three key attributes are injected into the MOSS class: Replier, MultiTask, and DirectoryEditor. These provide the core functionality to handle directory editing and multi-tasking. The user request, which could be initiated by a meta-agent, involves translating any Chinese comments found in the .py files within the code_edits directory into English.\nThe MOSS file plays a crucial role here by ensuring that all necessary tools (such as MultiTask and DirectoryEditor) are integrated through dependency injection in the IoC container. It also ensures that the prompt seen by the LLM provides a WYSIWYG (What You See Is What You Get) environment, where the LLM sees a global system prompt to generate a main(moss: MOSS) method with the injected tools made available in the MOSS class.\nDuring the task execution, the Directory Editor Thought will list all .py files in the target directory, then dispatch tasks to individual FileEditorThought instances via MultiTask. Each FileEditorThought receives a task to open a file, read the contents, and translate the comments from Chinese to English. These tasks are processed asynchronously.\nResults and Analysis Once the tasks are dispatched, MultiTask asynchronously schedules and manages the execution of each FileEditorThought. For each file, the FileEditorThought reads the file's contents, identifies any Chinese comments, replaces them with English translations, and then completes the task.\nAfter all tasks are completed, DirectoryEditorThought receives the task status messages, consolidating the results and notifying the user of task completion. The final messages show that all tasks, including translating the comments in multiple Python files, were executed successfully in parallel.\nThis case highlights MOSS's ability to manage multiple tasks concurrently through code-driven interaction with tools, emphasizing the role of the MOSS file in ensuring that the LLM operates with a clear, WYSIWYG interface. It also showcases how MOSS handles dynamic task management, context consistency, and dependency injection to streamline the process of handling complex, multi-step tasks."}, {"title": "3.3 Debugging an Issue in Code Repository", "content": "In this case study, we demonstrate the capabilities of the MOSS framework by debugging a specific issue in the Django framework's messages module. This case is sampled from SWEBench-lite[29]. The issue involved incorrect serialization of 'extra_tags' when it was an empty string, leading to unexpected behavior in the application. Using MOSS, we implemented a systematic approach to localize the bug efficiently.\nSetup The debugging process began by setting up the environment for the Django repository, specifically focusing on the commit 7c4f3965098baad2396e24501e09237425a7bd6f. We defined a series of AI functions (AIFuncs) to manage the workflow. The initial step involved gathering task metadata and preparing the repository for debugging. Subsequently, the framework utilized a search strategy to locate files related to the 'extra_tags' issue and explored their contents. This involved multiple iterations of exploration and exploitation to pinpoint the culprit file effectively.\nResults and Analysis Through the execution of the MOSS framework, we successfully identified the root cause of the issue within the django/contrib/messages/storage/cookie.py file. The exploration strategy yielded a confidence percentage exceeding our defined threshold, validating the effectiveness of our approach. The overall process demonstrated the adaptability and efficiency of MOSS, showcasing its ability to manage complex debugging tasks while maintaining context and facilitating code-driven evolution. By defining several AIFuncs without function bodies and importing necessary tools, the agent dynamically generated and executed workflows, proving our achievement of Python context consistency across multiple interactions. This highlights an important cognitive aspect: the primary driver between multiple turns is pure code. Even without explicitly writing a workflow, the defined AIFuncs executed as if they were part of a complete workflow, with the connections between workflow nodes being Turing complete. The result illustrates the potential of MOSS in orchestrating complex multi-step tasks and managing Python context across multiple turns."}, {"title": "4 Discussion", "content": ""}, {"title": "4.1 Security Considerations", "content": "One of the key design choices in MOSS is its operation within the local Python process rather than a sandboxed environment. While this decision facilitates direct integration and interaction with the IoC container, enhancing execution efficiency and context management, it raises potential security concerns. Unlike sandboxed environments, where code execution is isolated and risks are mitigated, the local process approach requires careful management to prevent unintended side effects or security vulnerabilities. Future work will focus on improving the safety of the local execution environment, implementing more robust safeguards to prevent harmful code execution, and ensuring the integrity of the system. We invite the community to collaborate on developing best practices and contributing to the security framework of MOSS."}, {"title": "4.2 Enhancing Thought and AIFunc with Advanced Models", "content": "MOSS introduces Thought and AIFunc as intelligent units for executing complex, multi-turn tasks. While these units already offer significant capabilities, their potential can be further unlocked through advanced language models like the GPT-4 series, known for their strong chain-of-thought (CoT) reasoning abilities. Such models can improve the coherence and effectiveness of Thought processes and enhance the accuracy of AIFunc operations by generating more context-aware and purpose-driven code. By leveraging the inherent reasoning strengths of these models, MOSS can execute complex sequences of actions more effectively, making the framework even more suitable for tasks that require adaptive planning, exploration, and execution."}, {"title": "4.3 The Need for Amplifiers and Integration Frameworks", "content": "Even the most advanced AI models, like GPT-4[5], benefit significantly from amplifiers\u2014tools and frameworks that augment their problem-solving capabilities[30, 31]. Just as humans rely on IDEs and methodologies like divide-and-conquer to tackle complex software development tasks, AI agents require a well-integrated framework to interact with their environment and manage complex workflows. MOSS serves as this amplifier, providing an integrated code-generation and context-management system that allows AI agents to decompose intricate tasks into manageable units. By systematically interacting with their environment through code, agents can achieve higher-order functionalities that transcend the limitations of any single model. This framework enables the development and deployment of sophisticated AI systems that can be debugged, monitored, and guided more effectively by humans, ensuring reliable and controllable AI behavior."}, {"title": "4.4 Enhancing Debuggability and Control in Complex AI Systems", "content": "A core advantage of MOSS's design philosophy is the emphasis on code-driven interaction with the environment, which offers a higher degree of transparency and control compared to black-box AI systems. By adopting a divide-and-conquer approach and focusing on generating and executing code, MOSS allows developers to debug complex AI systems in a manner similar to traditional software debugging. This structured approach provides a clear trace of the agent's decision-making process, enabling developers to intervene, modify, and guide the AI system at critical junctures. By integrating human expertise into the evolution of AI agents through direct code modification, MOSS offers a path toward creating more controllable and interpretable AI systems that can adapt and evolve incrementally while remaining aligned with human objectives."}, {"title": "5 Conclusion", "content": "MOSS represents a significant advancement in the development of Turing-complete AI agents. By integrating code generation with dynamic context management, it addresses the challenges of maintaining consistency between code and runtime context across multi-turn interactions. The framework's use of an IoC container and runtime instance replacement facilitates the seamless integration of new tools and libraries, enabling agents to expand their capabilities over time. Furthermore, MOSS's structured approach to executing complex, multi-step tasks through isolated execution frames and intelligent units like AIFunc and Thought empowers agents to adapt and tackle increasingly intricate challenges.\nThe framework's design also emphasizes the importance of transparency and control in AI systems, offering developers a robust platform to debug and guide agents using familiar programming paradigms. While challenges such as execution security remain, MOSS lays the groundwork for future research and development in creating more adaptable, interpretable, and secure AI agents. The integration of advanced language models and the continued refinement of the framework promise to further enhance the capabilities of AI agents, moving towards the vision of more autonomous and adaptive intelligent systems."}]}