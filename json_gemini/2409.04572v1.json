{"title": "Neurosymbolic Methods for Dynamic\nKnowledge Graphs", "authors": ["Mehwish ALAM", "Genet Asefa GESESE", "Pierre-Henri PARIS"], "abstract": "Knowledge graphs (KGs) have recently been used for many tools and\napplications, making them rich resources in structured format. However, in the real\nworld, KGs grow due to the additions of new knowledge in the form of entities\nand relations, making these KGs dynamic. This chapter formally defines several\ntypes of dynamic KGs and summarizes how these KGs can be represented. Addi-\ntionally, many neurosymbolic methods have been proposed for learning represen-\ntations over static KGs for several tasks such as KG completion and entity align-\nment. This chapter further focuses on neurosymbolic methods for dynamic KGs\nwith or without temporal information. More specifically, it provides an insight into\nneurosymbolic methods for dynamic (temporal or non-temporal) KG completion\nand entity alignment tasks. It further discusses the challenges of current approaches\nand provides some future directions.", "sections": [{"title": "1. Introduction", "content": "Knowledge Graphs (KGs) [1] have gained attention in the past few years for represent-\ning information in a structured way, i.e., entities and relations. It has been used for var-\nious applications and domains from search engines and recommendation systems [2] to\nbio-informatics [3] and social sciences [4]. They capture relationships between entities\nin a way that is both human-readable and machine-processable, enabling advanced rea-\nsoning and inference capabilities. The significance of KGs lies in their ability to inte-\ngrate vast amounts of heterogeneous data, providing a unified framework that supports\ncomprehensive querying and analysis.\nHowever, the real world is dynamic, with changes happening continuously-new\nentities emerge, existing relationships evolve, and facts that were once true may become\noutdated. In such scenarios, traditional static KGs fall short as they cannot accommo-\ndate these changes in real-time. This limitation has led to the development of Dynamic\nKnowledge Graphs (DKGs), which can evolve by incorporating temporal information.\nDynamic KGs update the data and track changes, enabling temporal queries and histori-\ncal analysis.\nThe inclusion of temporality in KGs poses significant challenges. Firstly, the rep-\nresentation of time-sensitive data requires precise modeling to capture the validity pe-\nriod of facts. For example, without temporal information, a query asking about the pres-\nident of the United States might return multiple results, leading to ambiguity. Tempo-\nral dynamics are crucial in contexts like legal documents, medical records, and financial\ntransactions, where the timing of events plays a pivotal role in decision-making. Thus,\npreserving temporality in KGs is beneficial and necessary for ensuring the accuracy and\nrelevance of the information.\nFurthermore, learning representations over DKGs is essential for several reasons.\nIt enables the development of models that can predict future changes, discover hidden\npatterns, and provide insights based on the temporal evolution of data. This is particu-\nlarly valuable in predictive analytics, trend analysis, and anomaly detection, where un-\nderstanding the temporal context can significantly enhance the accuracy of the results.\nEntity alignment, the task of identifying equivalent entities across different datasets\nor KGs, becomes increasingly complex in dynamic settings. As entities and their at-\ntributes change over time, ensuring they are correctly matched requires sophisticated\ntechniques that can handle temporal variations. This is crucial for maintaining data in-\ntegrity, improving the accuracy of merged datasets, and enhancing the overall quality of\nthe KG.\nIn summary, the dynamic and temporal dimensions of KGs are critical for accurately\nreflecting the complexity of real-world data. Addressing the challenges associated with\nthese aspects can significantly advance the field of KG research and its applications,\npaving the way for more intelligent and responsive information systems.\nThis book chapter is structured as follows: Section 2 reviews related work and po-\nsitions this chapter within the broader context. Section 3 provides fundamental defini-\ntions of the DKGs. Section 4 details how the dynamic information can be represented\nin the form of a KG. Following the discussion on representation techniques, the book\nchapter then moves on to explaining how neurosymbolic methods have been utilized for\nlearning representations over DKGs for KG Completion (Section 5) and dynamic entity\nalignment (Section 6)."}, {"title": "2. Related Work", "content": "One of the very recent studies provides an overview of the DKGs [5]. However, this\nchapter mostly focuses on providing a formal definition of different categories of DKGs\nalong with neurosymbolic methods for DKGs, such as learning representations over such\nsymbolic representations using methods based on neural networks along with the down-\nstream tasks such as KG completion and entity alignment.\nSeveral studies have been conducted on learning representations over KGs. For in-\nstance, various techniques for refining KGs are summarized in [6], including methods\nfor KG completion. A categorization of static KG completion algorithms is given in [7].\nIn contrast, an exhaustive survey on multimodal KG embedding algorithms that utilize\nliteral (text, numeric, image) information within the static KGs are presented in [8] along\nwith an experimental comparison of these algorithms. Furthermore, a recent article [9]\nprovides an overview of various KG completion tasks, such as transductive and induc-\ntive link prediction. It details methods incorporating background information from large\nlanguage models and discusses embeddings considering description logic axioms. How-\never, all these studies are limited to static KGs and do not consider the dynamic as-\npects in a KG. In contrast, [10] surveys the methods for Temporal Knowledge Graph\n(TKG) completion. This book chapter builds on this by formally defining the funda-\nmental differences between DKGs and TKGs. It provides a comprehensive overview of\nrepresentation learning for these types of KGs, highlighting their unique characteristics\nand challenges. Additionally, the chapter discusses various downstream tasks associated\nwith these graphs, such as KG completion and entity alignment, offering insights into\nthe methodologies and applications tailored to DKGs and TKGs."}, {"title": "3. Preliminaries", "content": "This section formally defines static, temporal, and dynamic KGs with examples.\nDefinition 1 (Static Knowledge Graph) Let G = (E,R,L,F) be a directed labeled\ngraph, where E, R, and L are the sets of entities, relations, and literals, respectively.\nFC E\u00d7R\u00d7(EUL) represents a set of facts such that f = (h,r,t) or f = (h,r,l) represent\none triple where f \u2208 F, h,t \u2208 E, r \u2208 R, and l \u2208 L.\nExample 1 Consider a simple knowledge graph G = (E,R,L,F) where:\n\u2022 Entities (E): {Barack_Obama, USA}\n\u2022 Relations (R): {president_of}\n\u2022 Literals (L): 0\n\u2022 Facts (F): {(Barack_Obama, president_of, USA)}\nThe example shows that Barack Obama is the president of the USA. Now, suppose we\nupdate the graph with the following:\n\u2022 E = EU {Donald_Trump}\n\u2022 R=R\n\u2022L=0\n\u2022 F = FU (Donald_Trump, president of, USA)\nIn this static representation, the knowledge graph indicates that both Barack Obama and\nDonald Trump have been (or are) presidents of the USA. However, without temporal\ninformation, it is unclear when each individual held office.\nThe definition of a static KG can further be extended to a temporal KG, where each\ntriple can have a time interval representing its temporal validity:\nDefinition 2 (Temporal Knowledge Graph) Let G = (E,R,L,T,Q) be a directed la-\nbeled graph, where E, R, L, and T represent the set of entities, relations, literals, and\ntimestamps, respectively. Q \u2286 E \u00d7 R \u00d7 (EUL) \u00d7 (T\u222a {0}) represents a set of facts such\nthat q = (h,r,t, [Ts,te]) or q = (h,r,l, [ts, te]) represent one quadruple where q \u2208 Q,\nh,t \u2208 E, r\u2208 R, I \u2208 L, and ts, te \u2208 TU {0} and ts and te represent the start and end time,\ni.e., \u03c4\u03c2 < \u03c4e. If ts = te then it represents a point in time \u03c4\u2208\u03a4.\nExample 2 Consider a simple knowledge graph G = (E,R,L,F) where:\n\u2022 Entities (E): {Barack_Obama, USA}\n\u2022 Relations (R): {president_of}\n\u2022 Literals (L): {2009, 2017} (representing years)\n\u2022 Quadruples (Q): {(Barack_Obama, president_of, USA, [2009, 2017])}\nThe example shows when the fact that Barack Obama held office is a valid fact, i.e., from\n2009 to 2017.\nDefinition 3 (Dynamic Knowledge Graph) A dynamic knowledge graph G is a se-\nquence of knowledge graphs {Gto,Gt1,..., Gtn} indexed by time steps t0,t1,...,tn such\nthat to < t1 <\u2026 < tn and\u2200ti,ti \u2208 T, where T is the set of all timestamps. Each graph Gt;,\nat time step ti, can be either a static knowledge graph (see Definition 1) or a temporal\nknowledge graph (see Definition 2).\nThe graph Gt; represents a snapshot of the dynamic graph G at time t\u012f. The transition\nbetween two consecutive snapshots Gti-1 and G\u2081\u2081 can be characterized by changes in\nentities, relations, literals, and facts. Formally:\n$$E_{t_i} = E_{t_{i-1}} \\cup E^+ \\backslash E^-_{t_{i-1}}$$\nwhere E^+_{t_i} and E^-_{t_{i-1}} represent the additions and removals of entities,\n$$R_{t_i} = R_{t_{i-1}} \\cup R^+ \\backslash R^-_{t_{i-1}}$$\nwhere R^+_{t_i} and R^-_{t_{i-1}} represent the additions and removals of relations,\n$$L_{t_i} = L_{t_{i-1}} \\cup L^+ \\backslash L^-_{t_{i-1}}$$\nwhere L^+_{t_i} and L^-_{t_{i-1}} represent the additions and removals of literals,\n$$G_{t_i} = G_{t_{i-1}} \\cup G^+ \\backslash G^-_{t_{i-1}}$$\nwhere G^+_{t_i} and G^-_{t_{i-1}} represent the additions and removals of facts.\nAdditionally, if G_{t_i} is a temporal knowledge graph, it can include changes in the\ntemporal intervals of the quadruples.\nExample 3 Consider the first snapshot of a simple knowledge graph Go = (E0,R0,Lo, Fo)\nwhere:\n\u2022 Entities (E0): {Barack_Obama, USA}\n\u2022 Relations (R0): {president_of}\n\u2022 Literals (Lo): 0\n\u2022 Facts (Fo): {(Barack_Obama, president_of, USA)}\nWe can see that Barack Obama is the president of the USA as in the first example. Now,\nsuppose we update the graph with the following new snapshot G\u2081 = (E1,R1, L1, F1):\n\u2022 Entities (E1): Eo \\ {Barack_Obama}\u222a{Donald_Trump}\n\u2022 Relations (R1): Ro\n\u2022 Literals (L1): Lo = 0\n\u2022 Facts (F\u2081): {(Donald_Trump, president_of, USA)}\nNow, Donald Trump is the president of the USA in the last snapshot G1, which no longer\ncontains information about Barack Obama.\nFinally, consider the temporal KG of Example 2 as the first snapshot Go of a\nsimple knowledge graph. It can be updated with the following new snapshot G\u2081 =\n(E1, R1, L1, F1):\n\u2022 Entities (E1): E0\u222a{Donald_Trump}\n\u2022 Relations (R1): Ro"}, {"title": "4. Representing Dynamic and Temporal Knowledge Graphs", "content": "This section presents the different techniques to represent temporal information in\nknowledge graphs and that can be used for temporal KGs or dynamic KGs.\n4.1. Techniques to Represent Temporal Information in Knowledge Graphs\nThe first nucleus to represent time is the use of various XML Schema Definition [11]\n(XSD) datatypes, such as xsd:dateTime, xsd:duration, xsd:date, and others, that\nallows for precise representation of temporal data, including specific moments, durations,\ncalendar dates, and individual time components, in KGs. These datatypes have been\ndesigned to facilitate the accurate and standardized encoding of temporal information,\nenabling robust temporal querying and reasoning.\n4.1.1. Temporal Properties\nTemporal properties directly incorporate time into relationships within a KG. These\nproperties provide inherent temporal aspects to the entities and relationships they de-\nscribe. For example (please note that all examples are provided in the Turtle syntax2):\n: Alice :birthDate \"1990-01-01\"^^xsd:date\n: Alice :employedAt : CompanyX\n: Alice : employmentStart \"2020-01-01\"^^xsd:date\n: Alice :employmentEnd \"2022-01-01\"^^xsd:date\nIn this example, a simple temporal relation is represented using a time interval: Al-\nice's employment relationship with CompanyX includes specific start and end dates, en-\nabling queries about her employment duration. The advantage of this approach is its\nstraightforwardness and direct annotation of temporal data within the relationships them-\nselves. However, it may lack flexibility for more complex temporal scenarios because\none need to know that \u201cemploymentStart\u201d is related to \"employedAt\u201d. Additionally, if\none wants to keep track of Alice's employment history, this became more complex to\nrepresent. Temporal attributes can also be represented, e.g., we also know her birth date,\nwhich is a fixed point in time.\nAll cross-domain general-purpose KGs have some form of temporal information,\ne.g., Wikidata [12], DBpedia [13], YAGO [14,15], etc.\n4.1.2. Reification\nReification allows a triple to be treated as a subject of another triple, thereby attaching\nmetadata such as temporal information. There are several ways to reify a triple.\nThe standard reification [16] is a built-in functionality in RDF, i.e., a resource is used\nto denote the fact and additional information about the statement can be added using\nthe RDF vocabulary (the properties \u201crdf:subject", "rdf": "predicate\u201d, and \u201crdf:object", "For\ninstance": "n_: statement rdf:type rdf: Statement\n_: statement rdf: subject: Alice\n:statement rdf: predicate :knows\n_: statement rdf: object : Bob\n_: statement : since \"2022-01-01\"^^xsd:date\nThrough reification, the relationship between Alice and Bob can be annotated with\nthe date they became acquainted. This approach offers flexibility in adding metadata to\nexisting triples but can lead to increased data redundancy and complexity.\nOther possibilities to reify a fact are to use n-ary relations [17] or to use singleton\nproperties [18]. The interested reader can refer to Hern\u00e1ndez et al. [19] for more details\nand an in depth comparison of these approaches.\n4.1.3. Time Ontology in OWL\nThe Time Ontology in OWL\u00b3 provides a comprehensive framework for representing\ntemporal concepts. This ontology includes classes and properties for describing instants,\nintervals, and durations. Thus, the ontology is designed to support complex temporal\nreasoning and querying following Allen's interval algebra [20]. For example:\n@prefix ex: <http://example.org/ns#> .\n@prefix time: <http://www.w3.org/2006/time#> .\n# Define Alice as a person\nex: Alice a ex: Person ;\nex:worksSince ex: JobStart .\n# Define the job start time\nex: JobStart a time: Instant ;\ntime:inXSDDateTime \"2020-01-01T00:00:00Z\"^^xsd:dateTime .\n# Define a class for persons who have been working for more\n# than 3 years\nex: Long TermEmployee a owl:Class ;\nowl:equivalentClass [\nowl:intersectionOf (\nex: Person\n[\nowl:onProperty ex:worksSince ;\nowl:someValuesFrom [\nowl:restriction [\nowl:onProperty time: before ;\nowl:hasValue\n\"2021-01-01T00:00:00Z\"^^xsd:dateTime\n]\n]\n]\n)\n]\n# Reasoning\nex:Alice a ex: Long TermEmployee .\nIn this example, we use the OWL Time ontology to describe the start date of Alice's\nemployment and perform basic reasoning to determine if she qualifies as a long-term\nemployee.\nThe interesting definition is the class ex:LongTermEmployee used to represent indi-\nviduals who have been working for more than three years. This class is specified using\nowl:equivalentClass to intersect ex:Person and a restriction on the ex:worksSince prop-\nerty. The restriction requires that the ex:worksSince property has a value indicating a\nwork start date before January 1, 2021.\nThe reasoner determines that since Alice's work start date is \"2020-01-01,\" which is\nbefore the cutoff date \"2021-01-01,\u201d she meets the criteria for long-term employment.\n4.1.4. Named Graphs and Quadruples\nNamed graphs [21] group triples into a single graph that can have metadata associated\nwith it. This allows for temporal information to be added at the graph level. For example:\nGRAPH <http://example.org/graph/2022-01-01> {\n: Alice : knows : Bob\n}\nThis structure facilitates temporal data management by associating entire sets of\ntriples with specific temporal contexts. Named graphs are advantageous for segmenting\ndata into manageable subgraphs but can introduce overhead in graph management and\nquerying.\nQuadruples extend RDF triples by adding a fourth element, often used to represent\nthe context or the named graph, which can include temporal information. Contrary to\nnamed graphs, quadruples are not a separate graph but a part of the RDF data model, thus,\ninformations can be attached to the fact level instead of the whole graph. For example:\n: Alice : knows : Bob \"2022-01-01\"^^xsd:date\n4.1.5. RDF-star\nRDF-star is an extension of the RDF data model that offers a more compact and intuitive\nway to represent complex statements, including those involving temporal information.\nExamples include:\n<< : Alice : knows : Bob >> : since \"2022-01-01\"^^xsd:date\n<< :Alice :worksAt : CompanyX >> :startDate \"2020-01-01\"^^xsd:date ;\n: endDate \"2022-01-01\"\n<<\n: Alice : attended : ConferenceX >> : onDate \"2023-06-15\"^^xsd:date\n<< : Document123 : hasVersion : Version1 >> : timestamp\n\"2024-01-01T10:00:00Z\"\n<< :DataItem : createdBy : User123 >> :creationTime\n\"2024-07-01T09:00:00Z\"\nRDF-star enables a streamlined representation of temporal information, simplifying\nthe construction and querying of knowledge graphs. Its compactness reduces data redun-\ndancy and complexity but requires support for RDF-star syntax and semantics in RDF\nprocessors.\n4.1.6. Versioning\nMaintaining historical data with timestamps is crucial for tracking changes over time.\nVersioning techniques ensure that the evolution of data is documented, enabling tem-\nporal queries and historical analysis. One can use simple approaches, such as adding a\ntimestamp to each triple, or more complex methods, such as reification or named graphs.\nFor example, using versioning:\n: Document123 : hasVersion : Version1\n:Version1 :timestamp \"2024-01-01T10:00:00Z\"\nMore complex versioning systems have been proposed over time: Frommhold et\nal. [22] developed a Version Control System for KGs, emphasizing the need for efficient\nchange detection across graphs, including handling blank nodes. Their system uses in-\nvertible patches to manage changes, supporting operations like revert and merge, and\nensuring data integrity through secure hashing of patches. This approach is foundational,\nparticularly in tracking changes in complex datasets and ensuring reliable data history.\nPelgrin et al. [23] provided a comprehensive survey and analysis of KG archiving\nsystems, highlighting the lack of standardization and scalability in existing solutions.\nThey introduced RDFev, a framework for studying the dynamicity of RDF data, which\noffers insights into dataset evolution at both low and high levels. Their work outlines\nthe essential features of a fully-fledged RDF archiving system, emphasizing the need\nfor robust support for concurrent updates, efficient query processing and comprehensive\nversion control features like branching and tagging."}, {"title": "4.2. Prominent Knowledge Graphs", "content": "We now describe some of the most prominent general-purpose KGs and how they repre-\nsent temporal information.\n4.2.1. DBpedia\nDBpedia [13] incorporates temporal aspects into its dataset through properties that de-\nnote specific time-related data. For example, temporal properties such as dbo:birthDate\nand dbo:deathDate indicate birth and death dates for people, while other prop-\nerties capture periods of activity or events, such as dbo:productionStartDate and\ndbo:productionEndDate for manufacturing or production events. This inclusion of tem-\nporal data allows for queries about the duration of events or the temporal relationships\nbetween entities. However, representing complex temporal scenarios might require ad-\nditional context or metadata, as basic temporal properties might not inherently indicate\ntheir relation to other properties without such context.\nDBpedia handles versioning primarily by maintaining historical data, which allows\ntracking changes over time. The DBpedia Live system plays a crucial role in this aspect,\nas it continuously synchronizes with Wikipedia to update the dataset with the latest in-\nformation. This system utilizes a stream of updates from Wikipedia, enabling DBpedia\nto reflect recent edits with minimal delay, typically within a few minutes. Versioning also\nexists in DBpedia through snapshots, ensuring that historical changes are documented,\nwhich is essential for conducting temporal queries and historical analyses.\n4.2.2. YAGO\nThe second iteration of YAGO [14] incorporates temporal dimensions into its KG by\nassigning existence times to entities and facts. This is achieved using specific relations\nsuch as wasBornOnDate, diedOnDate, wasCreatedOnDate, and wasDestroyedOnDate,\nwhich are standardized under generic entity-time relations like startsExistingOnDate and\nendsExistingOnDate. For events lasting a single day, YAGO2 uses happenedOnDate,\nwhich is a sub-property of both startsExistingOnDate and endsExistingOnDate. Facts\nare assigned a time point if they are instantaneous events or a time span if they have an\nextended duration with known beginning and end. This approach allows the system to\ndeduce the temporal scope of entities and events, providing a comprehensive temporal\nannotation across the dataset.\nFor example, entities such as people are assigned birth and death dates, while arti-\nfacts and groups have creation and potential destruction dates. In cases where the data is\nincomplete or not applicable (e.g., abstract concepts or mythological entities), no tem-\nporal data is assigned, adhering to a conservative approach. This temporal framework is\nessential for enabling time-based queries and analyses, such as determining the lifespan\nof individuals or the duration of historical events.\nYAGO 4.5 [15] builds upon the temporal framework of previous versions by enhanc-\ning its capacity to handle temporal information more flexibly and in more detail. The\nintegration of temporal data into YAGO 4.5 utilizes the RDF-star model, allowing for\nmore intricate annotations of facts. This temporal tagging is crucial for representing the\nevolving nature of the KG, allowing for dynamic queries that reflect changes over time.\nAll YAGO versions are accessible only as archives, as the live version is not publicly\navailable.\n4.2.3. Wikidata\nWikidata [12] utilizes a system of qualifiers to provide additional context to statements,\nincluding temporal information. Qualifiers in Wikidata are versatile and can specify de-\ntails such as the period during which a statement is valid. For instance, in the following\nexample, Douglas Adams's education at St John's College is annotated with start and\nend dates, providing a temporal dimension to his academic history:\nwd:Q42 wdt: P69 wd:Q3918\nwd:Q42 p:P69 : statement\n_: statement ps:P69 wd:Q3918\n_statement pq:P580 \"1971-10-01T00:00:00Z\"^^xsd:dateTime\n_statement pq:P582 \"1974-06-01T00:00:00Z\"^^xsd:dateTime\nIn this data snippet, 'wd:Q42' represents Douglas Adams, 'wd:Q3918' represents\nSt John's College, 'p:P69' and 'ps:P69' denote the property for educational institutions\nattended, and 'pq:P580' and 'pq:P582' provide the start and end times of the education\nperiod, respectively.\nQualifiers in Wikidata allow for highly detailed annotations of statements, includ-\ning dates, locations, and other contextual information. This feature supports complex\ndata representation but requires sophisticated data parsing and querying mechanisms to\nretrieve and interpret the full context of the data.\nWikidata's approach to versioning involves maintaining a complete history of all\nedits, thus allowing for comprehensive tracking of changes over time. This version his-\ntory is essential for verifying data provenance and understanding the evolution of knowl-\nedge within the graph. Unlike other KGs, Wikidata's version history is openly accessible,\nproviding a transparent view of the data's editorial process.\nFurthermore, Wikidata is a DKG, continuously updated by a large community of\ncontributors. This live updating system ensures that Wikidata remains current, reflecting\nthe latest information and corrections as they become available. The dynamic nature of\nWikidata, combined with its detailed versioning and temporal annotations, supports both\nreal-time applications and historical research, making it a versatile tool for a wide range\nof uses.\n4.2.4. EventGraph\nEventKG [24,25], a multilingual event-centric TKG, focuses heavily on capturing and\nrepresenting temporal relations and events. The system models events using a canoni-\ncal representation that incorporates both the start and end times of events, leveraging a\nvariety of data sources, including Wikidata, DBpedia, and YAGO. Temporal informa-\ntion in EventKG is linked to entities and events, allowing for detailed historical analy-\nsis and event tracking. The model uses properties such as sem:hasBeginTimeStamp and\nsem:hasEndTimeStamp to define the temporal span of events and entities' involvement\nin those events.\nAdditionally, EventKG employs the Simple Event Model (SEM) as its foundational\nschema, which it extends to represent temporal relations better. This includes modeling\nnot only event-entity relationships but also complex temporal relations between multiple\nentities or events, such as sequences of events and their hierarchical relationships. This\ncomprehensive temporal modeling enables sophisticated queries and analyses concern-\ning the temporal dynamics of historical and contemporary events.\nUsing named graphs and quadruples, EventKG also addresses versioning indirectly\nby maintaining a provenance framework that tracks the sources and version history of the\ndata it integrates. Provenance information is critical in EventKG, as it helps verify the\naccuracy and credibility of the temporal data. Each piece of information, including tem-\nporal annotations, is associated with metadata that details its origin, the specific version\nof the source data, and the extraction date."}, {"title": "5. Dynamic Knowledge Graph Completion", "content": "In the existing literature [26", "cate-\ngories": "interpolation-based and extrapolation-based. Interpolation-based methods aim to\npredict missing knowledge by leveraging existing quadruplets. In contrast", "2021": "and\n(Gerhard Schr\u00f6der", "2005": ".", "ways": "i) tail prediction - given the head and relation at a\ncertain time", "27": "TKGC methods could be categorized into timestamps-dependent-\nbased TKGC", "28": "TTransE [29", "30": "T-SimplE [31", "32": "TKGFrame [33", "34": "nassociate timestamps to corresponding entities and relations to capture their evolution\nwithout directly manipulating the timestamps.\nTimestamps-specific Functions-based TKGC methods use specialized functions", "35": "SPLIME [36", "37": "TASTER [38", "39": "Goel\net al. [40", "41": ".", "42": "TComplEx and TNTComplEx [43", "44": "TGe-\nomE [45", "46": "RotateQVS [47", "48": "BiQCap [49", "50": "nSTKE [51", "52": ".", "53": "ATISE [54", "55": "and TKGC-AGP [56", "57": "HTKE [52", "58": "BTHYTE [59", "60": "SANe [61", "62": "ii) Long Short-\nTerm Memory (LSTM)-based TKGC methods such as TA-TransE and TA-DistMult [63", "64": "Ma et al [65", "66": "and TeCre [67", "68": "Kgedl [69", "70": "Temp-\nCaps [71", "72": "and TAL-TKGC [73", "procedure": "Given a TKG G and a set of facts Q in G", "74": "is employed to create a set of negative samples", "function": "A loss function L aims at maximizing g(q) for all q \u2208 Q and minimiz-\ning g(q') for their negative samples q' \u2208 Q. The following are the commonly used loss\nfunctions by TKGC approaches.\n\u2022 Margin-based ranking loss (MRL) [75", "g(q')": "nwhere [x", "76": "also aims at obtaining a large gap between true\nquadruplets and the negative samples but without enforcing a fixed margin for all\nfacts.\n$$L_{CEL"}, "sum_{q \\in Q} \\frac{exp(g(q))}{\\sum_{q' \\in Q'} exp(g(q'))}$$\n\u2022 Binary cross-entropy loss (BCEL) [77"], "follows": "n$$L_{BCEL} = \\sum_{q \\in Q \\cup Q'} y \\cdot g(q)+(1-y) \\cdot g(q"}