{"title": "LOW-LATENCY VIDEO ANONYMIZATION FOR CROWD ANOMALY DETECTION: PRIVACY VS. PERFORMANCE", "authors": ["Mulugeta Weldezgina Asres", "Lei Jiao", "Christian Walter Omlin"], "abstract": "Recent advancements in artificial intelligence promise ample potential in monitoring applications with surveillance cameras. However, concerns about privacy and model bias have made it challenging to utilize them in public. Although de-identification approaches have been proposed in the literature, aiming to achieve a certain level of anonymization, most of them employ deep learning models that are computationally demanding for real-time edge deployment. In this study, we revisit conventional anonymization solutions for privacy protection and real-time video anomaly detection (VAD) applications. We propose a novel lightweight adaptive anonymization for VAD (LA3D) that employs dynamic adjustment to enhance privacy protection. We evaluated the approaches on publicly available privacy and VAD data sets to examine the strengths and weaknesses of the different anonymization techniques and highlight the promising efficacy of our approach. Our experiment demonstrates that LA3D enables substantial improvement in the privacy anonymization capability without majorly degrading VAD efficacy.", "sections": [{"title": "1 Introduction", "content": "Privacy and safety security are the cornerstones of a thriving society and are often intricately linked to one another [1]. Robust security measures can safeguard privacy, and respect for privacy can foster responsible security practices and accountability. Striking the right balance between privacy and security is essential but an ongoing challenge [2]. With over a billion surveillance cameras worldwide, there has been a growing interest in privacy-preserving computer vision (CV) systems from industry, academia, and regulatory bodies [3, 4]. Artificial intelligence (AI) in crowd monitoring for safety offers advantages and multi-faceted challenges in the interplay between privacy and security [5]. Several studies have demonstrated the existing concerns of deep learning CV models, including but not limited to a chilling effect on free movement and expression, bias, risk of profiling, and discrimination [5,6]. Visual anonymization (AN) obscures people's identities (biometric data) to mitigate unintentional and malicious risks of AI tools-enforcing the AI monitoring to focus on behavior, not identity [4, 5, 7].\nBiometric privacy-protecting monitoring systems aim to anonymize data while maintaining utilities relevant to the downstream applications when the privacy and utility are not necessarily trade-offs [2, 4, 8, 9]. Several techniques have been investigated for AN, such as conventional algorithms: masking, pixelization, and blurring [10,11], and deep learning-based synthesis: face and body inpainting [9, 12\u201319] or skeleton extraction [20], and utility aware image-level obfuscation [3,5,7,21]. Deep learning enables end-to-end automation of removing privacy-sensitive attributes while preserving task utility [3, 5, 7, 14,21,22]. However, it requires retraining or fine-tuning the downstream task model on the new anonymized footage.\nVisual AN tools can be deployed on an edge (camera) or cloud systems. Cloud AN systems offer broader access to resources but require substantial infrastructure investments. In contrast, besides addressing the increasing concern of sharing private visual information with the cloud, edge AN may provide further protection against privacy troubles that arise from unsecured channels between the cloud and the camera [3]. Although generative models are promising in preserving realistic image quality, they are computationally demanding, which is often challenging for resource-limited edge devices [15, 18, 19]. Lightweight conventional AN approaches are computationally preferable but often struggle to balance AN and image quality for downstream tasks. Heavy AN leads to elevated privacy protection but may also intensely suffer the image utility and vice versa [2, 5, 7, 13, 21]. In addition, the strength of the AN highly depends on the hyperparameters of the AN method, such as kernel size of Gaussian blurring and downsizing factor of pixelization. Despite the broad deployment of these techniques in the real world, the literature barely explores optimizing their hyperparameters besides being utilized as baselines [2, 5, 7, 9, 13, 19, 21]. Manually adjusting the hyperparameters to anonymize a few images, like for news reports, may not pose a big challenge. However, automated parameter optimization is required to apply these techniques to streaming videos, like CCTV.\nIn this paper, we explore and enhance lightweight AN methods for real-time CCTV crime monitoring-video anomaly detection (VAD) applications. We attempt to address the potential issue of the conventional AN algorithms that arise from utilizing fixed parameters to process images, i.e., inadequate AN and image quality degradation. Employing fixed AN parameters is not optimized to handle the target figures in images that differ in size or are positioned at varying depths. To address the above issue, we introduce a lightweight adaptive AN for VAD (LA3D) that adjusts its hyperparameters dynamically based on the depth variation of the target figures in a video frame to enhance AN. Our approach primarily focuses on safeguarding the privacy of a person's full body. The algorithm initiates by identifying human figure masks in video frames using a high-speed segmentation model. It then applies dynamic obfuscation to each detected body, depending on the relative attributes of its mask.\nWe have conducted experiments on publicly available data sets to evaluate the competency of privacy protection using deep learning models for privacy attribute detection and person re-identification. We have also assessed the utility quality after AN using weakly supervised VAD models. Our experiments demonstrate that LA3D can significantly improve the privacy AN ability without apparent degradation on the VAD. The key contributions of this study are summarized as follows:\n\u2022 We revisit lightweight conventional image AN methods and elaborate on their effectiveness in protecting privacy and enabling VAD applications. We present a baseline performance report in privacy attribute leakage detection, person re-identification, and VAD.\n\u2022 We propose an adaptive and computationally efficient AN approach to enhance privacy protection through dynamic AN strength without sacrificing VAD quality.\n\u2022 We present an enhanced person privacy attribute detector using a pre-trained image encoder and weighted cost function.\nThe remainder of the paper is organized as follows. We briefly review related AN and VAD studies in Section 2. Thereafter, we present our methods and evaluate their performance in Section 3 and Section 4, respectively, before we conclude the study in Section 5."}, {"title": "2 Literature Review", "content": "Visual AN approaches strive to anonymize image or video data while maintaining relevant utilities for CV applications. The approaches can be categorized into different groups based on the characteristics of the target privacy attribute and the AN technique. The AN methods may focus on privacy attributes such as the face [9, 13-17, 23], the full-body [12, 18-20], or the entire image [3, 5, 7, 21]. The approaches may employ conventional algorithms, such as masking, pixelization, and blurring [10, 11, 23], or deep learning for inpainting [9, 12\u201319], skeleton extraction [20], and utility aware image-level obfuscation [3,5,7,21]. The conventional AN techniques are lightweight and promising for real-time processing and are claimed to be effective in removing privacy-sensitive information. However, they may severely alter the original data, resulting in a considerable loss in quality and rendering the generated anonymized suitability for downstream CV tasks [3, 9, 20, 21]. They may also suffer from considerable privacy leakage due to mainly non-optimized hyperparameters. Machine learning approaches have been proposed to remove privacy-sensitive features while preserving task utility for various CV tasks [3, 5, 7, 9, 14, 21, 22]. Refs. [3, 7, 9, 21] focus on action recognition, Refs. [5, 20] on VAD, Ref. [22] on non-private facial characteristics recognition downstream tasks, and Ref. [2] for object detection model training. However, these approaches require fine-tuning the downstream task model during or after the AN model training on the new anonymized footage. The face or body inpainting generative models aim to reduce perturbation and preserve realistic image quality so that downstream talks are less impacted, alleviating the need to retrain the task models [9, 13, 15\u201319]. Nevertheless, the generative approaches require intensive computation and are often much slower for real-time deployment.\nCrowd anomaly detection, an essential aspect of CV in the realm of smart cities, has garnered significant attention. Many innovative deep learning techniques have been introduced, consistently demonstrating superior performance [24]. Unsupervised and semi-supervised VAD models dominate the arena. These models, such as autoencoders, are trained on a sequence of video frames to learn what constitutes normal activity. Any deviation from these patterns, detected using reconstruction and prediction errors, is considered an anomaly. Semi-supervised VAD models frequently encounter challenges related to overgeneralization, as facing difficulty in distinguishing normal characteristics from actual anomalies. As a result, recent state-of-the-art research focuses on weakly supervised VAD approaches (WSAD) that involve guiding the model training process using a limited set of labeled anomaly datasets in order to address overgeneralization issue [25\u201330]. The WSAD demonstrates promising performance through its ability to learn pertinent features that not only minimize the reconstruction error of normal behavior but also maximize the error for abnormal behaviors. VAD is further bolstered by leveraging features extracted from encoders trained under natural language supervision [26,28,31]. Refs. [26,28] integrates CLIP [32] for effective extraction of discerning representations during model training and improves performance.\nIn our experiment, we employ the state-of-the-art WSAD VAD models, such as the prompt-enhanced learning for VAD (PEL4VAD) [26], to detect anomalies in the video data sets with and without AN. The PEL4VAD employs temporal context aggregation and augmented semantic discriminability through prompt-enhanced learning to significantly improve the computational efficiency and accuracy of VAD, respectively [26]. The temporal context aggregation efficiently captures temporal relations across video snippets by reusing the similarity matrix, reducing computational load and parameter count. The prompt-enhanced learning is achieved through knowledge-based prompts (using CONCEPTNET [33]), context separation (embedding using CLIP [32]), and cross-modal alignment, enriching the model's semantic discrimination. We have also experimented with other top-performing WSAD models, the magnitude-contrastive glance-and-focus network (MGFN) [27]. The MGFN utilizes transformers to glance at the whole video globally and then steer attention to each video portion, imitating the global-to-local vision system of human beings for VAD [27]."}, {"title": "3 Methodology", "content": "This section presents the problem formulation, the proposed approaches, and the tools employed in our study."}, {"title": "3.1 Problem Formulation", "content": "This study aims to improve the privacy characteristic removing and utility preservation capabilities of conventional image AN techniques for privacy-preserved VAD applications. Let's consider a raw video data X, the VAD as a utility task U, and the privacy leakage P. The goal of a privacy-preserving VAD system is to maintain the VAD performance of $F_U$ while reducing P by applying AN function $F_{\\Theta}$ to anonymize X.\n$F(X) = \\underset{\\Theta}{arg \\underset{P\\downarrow}{min} \\underset{U\\uparrow}{max} F_U(F_{\\Theta}(X))}$   (1)\nwhere the $\\underset{\\Theta}{arg \\underset{P\\downarrow}{min} \\underset{U\\uparrow}{max}}$ is the aggregate task to maximize. The AN function $F_{\\Theta}$ can be formulated as:\n$F_{\\Theta}(X) = I \\odot (1 - M) + M \\odot \\Theta(I), for I \\in X$  (2)\nwhere I is the input frame in the video data X, M is the binary segmentation mask of the target objects (person figures in our study), and \u0398 is the AN algorithm. The $\\odot$ represents element-wise multiplication. Although conventional AN algorithms are lightweight and promising for real-time processing, they often struggle to achieve $\\$$ (see Fig. 1). Heavier AN achieves a low P but may also deteriorate the quality of U and vice versa [5, 7, 13, 21]. The strength of the AN highly depends on the hyperparameters of the algorithms, e.g., the kernel window-size of Gaussian blurring (Eq. (3)) and the downsizing factor of pixelization (Eq. (4)). The literature has yet to explore optimizing the hyperparameters [5,7, 13,21].\n$g_i = \\beta e^{-(i - (k-1)/2)^2/(2\\sigma^2)}, for i = 0 ... k - 1$ (3)\nwhere G holds the filter coefficients of the blurring Gaussian kernel. The $\\beta$ is scale factor that enables the g to be symmetric, i.e., $\\sum_i g_i = 1$. The k and $\\sigma$ are the kernel window size and standard deviation, respectively.\n$\\eta(I, D) = Sup(S_{down}(I, D), Z), for D \\in \\mathbb{Z}^+$  (4)"}, {"title": "3.2 Lightweight Adaptive Full-Body Anonymization", "content": "Our proposed LA3D AN approach $F_A(I, \\Theta)$ focuses on full-body privacy protection. It starts with segmenting human figures from video frame I (see Algorithm 1) and anonymizes them dynamically using AN function (see Algorithm 2). The algorithm applies dynamic AN for each detected body segmentation mask depending on the relative area of the mask to the input image. The dynamic de-identification method of the LA3D scales the AN strength as (line 3 in Algorithm 2):\n$r = max \\lbrace a_r ln(\\frac{100x |m|}{||I||}), 1\\rbrace$ (5)\nwhere I and m are the input image and the detected segmented binary mask, respectively, and $|| ||$ denotes an area function. The r is the AN scaling factor as a log of the relative area of the mask scaled by global hyperparameter $a_r$. The r adjusts the AN strength of the \u0398, and the log function provides a damping effect that enables smoother transitions among varying sizes of m. We incorporate the $a_r$ to allow the global adjustment of the base \u0398 settings to handle the size variation of the input image I. The $a_r$ enables consistent AN across different image scales of I, and its value can be heuristically assigned or approximated as $a_r = Z/Z_{ref}$, where Z is the size of I, and $Z_{ref}$ is a reference size for a unit scaling. We recommend generally tuning $a_r$ or $Z_{ref}$ depending on the selected adaptive to scale the AN with the image resolution."}, {"title": "3.3 Privacy Attribute Classification Model", "content": "The ability to extract biometric data, such as face, gender, and ethnicity attributes, constitutes concerns for privacy [4]. We thus employ a multi-label classifier model $F_p$ for privacy attribute leakage detection. We select six widely utilized privacy attribute from the VISPR dataset [35], following [5,7,21] (as described in Table 1). We trained $F_p$ using a RESNET50 [36] for multi-label classification of the target attribute classes:\n$F_p = RESNET50_{FE}(I, N_f) \\rightarrow FC(N_f, N_c) \\rightarrow \\sigma(N_c)$  (7)\nwhere $RESNET50_{FE}(.)$ is the image encoding extraction network that generates $I_{FE} \\in \\mathbb{R}^{1xN_f}$ feature map from the input image $I \\in \\mathbb{Z}^{H \\times W}$, and the FC is the final classification network with sigmoid (\u03c3) activation function. The $N_c$ = 6 is the number of class labels. We have initialized the model with a pre-trained image encoder [36, 37] on ImageNet and then fine-tuned it on the VISPR dataset with class label weighted loss function $L_w$.\n$L_w = \\sum_{i=1}^{N_c} W_c L_c$  (8)\nwhere $L_c$ is a binary cross entropy loss (BCELoss). The class label distribution $D_c$ on the training dataset of the VISPR, as shown in Fig. 2, indicates that the Nudity and Relationship classes have relatively low contributions. The $F_p$ would struggle to learn these classes effectively due to the severe class label imbalance. The $L_c$ is calculated per target class label and summed after scaling with the class weight $W_c$ to estimate the final loss score $L_w$. We estimate $W_c = 1/D_c$ to compensate for the class imbalance and improve the attribution classification performance on $F_p$.\nWe used a learning rate of 10\u22123 with a linear warmup with a step-based scheduler that reduces the rate by 1/5 when the training loss saturates. We trained the model up to 100 epochs using ADAM optimizer with L2 regularization of 10\u22125."}, {"title": "3.4 Video Anomaly Detection Model", "content": "We employ the state-of-the-art VAD models, such as PEL4VAD) [26], and MGFN [27] to detect anomalies in the video data sets. These models follow the WSAD approach and are among the top-performing models in VAD [26-28].\nThe VAD models operate on extracted features from a sequence of frames using pre-trained video encoders [38]. The feature extractor takes a video $V \\in \\mathbb{R}^{N \\times H \\times W \\times 3}$, where N, H and W denote the number of frames, height, and width of V, respectively. The video is evenly segmented (P frames per segment) into T clips. The feature extractor generates F feature maps as $F : V \\rightarrow V_{FE} \\in \\mathbb{R}^{T \\times M \\times C}$, where M is the number of crops (augmentations), and C is the extracted feature dimension. There are several pre-trained feature encoders for a video in the literature [28], and most employ C3D [28, 38, 39] and I3D [28, 38, 40] methods. Recent studies demonstrate the superior performance of the I3D extractor in diverse CV applications [5,7,26-28]. Thus, we utilize a pre-trained RESNET50-I3D video encoder [40] that was trained on the Kinetics400 human action video dataset [41]. We refer readers to Ref. [42] for further review on video encoders."}, {"title": "4 Results and Discussion", "content": "This section presents the results of our AN study using the VISPR, Market1501, and UCF data sets. We follow the standard training and test split for all datasets.\nWe implement and compare the widely utilized privacy-protection techniques, presented in Table 2, along with our approaches. We discuss their performance and compare them with our adaptive approach using $a_r$ = 1.0. To maintain a fair comparison across methods, we apply the settings utilized in recent studies for baseline comparison of complex visual AN models [5, 7, 13, 19, 21]."}, {"title": "4.1 Evaluation Approach and Performance Metrics", "content": "The performance of a visual AN technique can be assessed in different ways to evaluate privacy leakage protection and the quality of the resulting anonymized image regarding non-privacy-sensitive utilities [5, 7, 19, 44]. We focus on recognition attack mechanism to measure privacy protection via: 1) person attribute distortion metrics which measure the leakage on the multi-label privacy attributes [5, 7], and 2) person de-identification metrics that measure the re-identification (recognition) rate of an individual person [19]. We evaluate image quality preservation through data re-usability metrics that measure the relevance of the anonymized image on preserving utilities for anomaly detection [5]. Due to the lack of adequate public datasets that incorporate both privacy and utility (VAD), we follow protocols of cross-dataset evaluation to measure the efficacy of the AN methods [5, 7, 13, 19, 21]. In addition to quantitative performance measurements using CV, AN can also be evaluated qualitatively using human visual inspection. In this study, we have not carried out a thorough human vision study, but we have provided some images to demonstrate the AN use cases.\nWe evaluate the multi-label privacy attribute classification using average precision (AP) and recall (R) on the VISPR dataset. The AP is the area under the precision-recall curve, and the R is calculated at a threshold of 0.5 for each class label. We provide the aggregate performance using class mean average precision (cMAP) and class mean R (CMR), which are the averages of the AP and the R over the class labels, respectively. Lower scores of cMAP and CMR indicate better potency in anonymizing the privacy attributes.\nWe employ the popular metrics, such as the mean average precision (mAP) and cumulative matching characteristics curve (CMC), for person re-identification evaluation on the Market1501 dataset. The CMC-Rk accuracy considers the correct match of the query identity from the top-k ranked gallery samples (ranked by predicted scores).\nWe evaluate the utility VAD performance using AP and the area under the receiver operating characteristic curve (AUC) on the UCF dataset. The AUC is calculated from the plot curve of the true positive rate against the false positive rate. Higher AP and AUC scores are more robust in preserving relevant utilities for accurate VAD."}, {"title": "4.2 Privacy Leakage Detection", "content": "We evaluate the privacy protection capability of the AN methods using privacy attribute detection following [5,7], and person re-identification following [19].\nBefore discussing the quantitative performance using CV, we will first provide a qualitative comparison of the different AN methods and the impact of their hyperparameters (as illustrated in Fig. 3 and Fig. 4). Fig. 3 illustrates the different baseline and adaptive AN approaches on sample images. The different methods provide different levels of AN, and the adaptive approaches leverage the AN compared to their corresponding baselines, as visually depicted. Non-adaptive pixelization and blurring, and adaptive pixelization with a low downsampling factor ($D_{base}$ = 2 at PIXELIZED_D2_A) are less effective for human vision inspections. Fig. 4 depicts how the hyperparameters of the adaptive ANs (the $a_b$ and $a_r$) impact varying image resolution scales. Using AN with maximum border settings (ismax = True) is inherently scalable. However, to maintain the AN as the reference resolution $Z_{ref}$, $a_r \\neq 1$ is necessary for ismax = False with $a_b$ on the scaled image sizes of Z $\\neq Z_{ref}$. For the Gaussian blurring, \u03c3 of the kernel also needs to be scaled using the is fullblur = True to keep the AN competency (lines 22\u201323 in Algorithm 2). Fig. 5 illustrates further sample images to visually compare our adaptive AN with the baselines, where the images consist of persons at different depths."}, {"title": "4.2.1 Privacy Attribute Detection (PD)", "content": "We evaluate attribute detection to measure the privacy leakage on the multi-label privacy attributes, given in Table 1, on the VISPR dataset [35]. The VISPR dataset is an image dataset labeled with 68 privacy-related attributes. The dataset contains 22K public Flickr images, and the training, validation, and testing sets contain 10K, 4K, and 8K images, respectively. We trained the ResNet50 multi-label classifier on the raw image and evaluated its performance when the test set images were anonymized using the AN methods defined in Table 2. We assess the PD performance only on the human figures successfully segmented by the YOLO to reduce the impact of misdetections, such as heavily occluded individuals or small faces.\nTable 3 presents the quantitative performance of the Fp, where the baseline provides 5.02% to 33.38% reduction in CMAP and 12.60% to 86.43% in cMR. The relatively higher reduction in the cMR indicates AN reduces the confidence of attribute detection and results in lower recall at the threshold of 0.5. The pixelization AN with fixed downsizing factors of 2 and 4 provides inadequate protection. Our adaptive methods have enhanced the robustness at different depths compared to the baselines without adaptive technique (see Fig. 3). The attribute protection is leveraged by 27.35%-40.40% in cMAP and 77.71%-88.53% in cMR. It has leveraged the BLURRED_A, PIXELIZED_D2, and PIXELIZED_D4, respectively, by 7.02%, 23.91% and 30.32% in cMAP, and by 51.23%, 55.64% and 72.11% in CMR."}, {"title": "4.2.2 Person Re-Identification (ReID)", "content": "We evaluate the re-identification (recognition) rate of a person from full body images on the Market1501 dataset, a cross-camera ReID benchmark dataset [45]. Six cameras, including five high-resolution cameras and one low-resolution camera, captured 1,501 identities with field-of-view overlap. The dataset contains 32,668 annotated bounding boxes for the 1,501 identities.\nWe adopt the OSNET [46], a state-of-the-art ReID model, for our experiment. The OSNET computes Euclidean distance on the extracted 512 embedded features of the query and gallery images to evaluate matching. We have applied reversible padding to the images from [64 \u00d7 128] to the YOLO's input dimension of [320 \u00d7 240] to enhance the object segmentation accuracy (see Algorithm 1). We have found that the padding approach considerably reduces the missing rate from 8.5% to only 0.62% on the query image set as compared to direct resizing with and without dimension ratio preservation.\nTable 5 presents the mAP and CMC-R1 on the ReID when the AN is applied to the query and gallery images. The reference performance of the OSNET on the non-anonymized raw images is 0.83 and 0.94, respectively. The BLACK-ENED AN accomplishes heavy AN with a drop in the mAP and the CMC by 98.2% and 94.9%, respectively. The other baseline methods yield around 60% reduction in the mAP except for the PIXELIZED_D4 and the PIXELIZED_D2, achieving only 21.5% and 3.4%, respectively. The results demonstrate that pixelization does not adequately prevent the ReID unless the higher downsizing factor is employed. Our adaptive anonymizer has relatively improved the mAP and CMC-R1 of the pixelization by 81.1%-94.4 and 76.6%-88.9, respectively. It also reduces the performance gap between the downsizing factor of pixelization while enhancing the mAP of the Gaussian blurring by 48.4%-66.0%.\nWe have also evaluated ReID when recognition challenges employ non-anonymized data on either the query or the search gallery. Table 6 and Table 7 present the ReID protection capability of the AN when the anonymized image of a person is being used to search for identification from a gallery of raw images and vise versa, respectively. In both cases, the adaptive approach achieves consistent improvement compared with the corresponding baselines. Unlike the other AN methods, blurring is more susceptible to ReID attack when the query and gallery are anonymized, even with the adaptive mechanisms."}, {"title": "4.3 Video Anomaly Detection", "content": "We evaluate image-utility preservation after AN for VAD application on the UCF-Crime dataset, a large-scale public VAD dataset [38]. The dataset contains 128 hours of untrimmed 1,900 CCTV videos from various scenes. The videos contain thirteen crime-related anomalies from real-world incidents. The test set contains 290 videos with different frame lengths that account for more than 1M frames in total.\nWe adopt the PEL4VAD [26] and the MGFN [27] VAD models for the evaluations. The models were trained on raw video data with an I3D-RGB feature encoder [40] using P = 16, and M = 10 on the UCF crime dataset with an image size of [320 \u00d7 240]. The feature dimensions are C = 1024, C = 2048 for the PEL4VAD and MGFN, respectively.\nTable 8 and Table 9 provide the AUC on VAD for the PEL4VAD and MGFN, respectively, across the different AN methods. The PEL4VAD outperforms the MGFN significantly in all scenarios, with an AUC of 0.86 on the raw videos. We have also found that PEL4VAD accomplishes better anomaly localization than MGFN, as the false positive rates are 32% and 48%, respectively, at a true positive rate of 90%. The AN regrades the VAD competency by 0.00%-2.90% for the PEL4VAD (except for PIXELIZED_D2 with a slight positive gain) as compared by 0.5%-4.23% for the MGFN. Our LA3D approach improves VAD for blurring for both the AD models, but it delivers slightly lower performance for pixelization. The perturbation effect from using large downsizing factors (adaptive pixelization) in a video frame may have led to a decrease in VAD efficacy. Nevertheless, we have found the VAD with the adaptive AN promising, considering the notable improvement in AN (see Section 4.2.1 and 4.2.2)."}, {"title": "5 Conclusion", "content": "In this study, we have conducted experiments on computationally lightweight conventional image anonymization approaches and investigated their trade-off efficacy in image privacy protection and video anomaly detection using publicly available data sets. We have highlighted the limitations of the widely utilized techniques and emphasized the encouraging significance of our simple and efficient adaptive approach in refining anonymization against privacy attribute detection and person identification. We have found its performance on anomaly detection promising, considering the substantial gain on the anonymization. We have generally demonstrated the promising capability of body-level anonymization methods, and it is essential to note that the performance trade-offs may vary depending on the choice of the anonymization techniques and the utility models. We believe that the reported baseline performance exhibited across the various techniques will serve as a reference point for future privacy-related studies, underlining further the significance of our findings."}]}