{"title": "Deep Learning-Based Transfer Learning for Classification of Cassava Disease", "authors": ["Ademir G. Costa Junior", "F\u00e1bio S. da Silva", "Ricardo Rios"], "abstract": "This paper presents a performance comparison among four Convo- lutional Neural Network architectures (EfficientNet-B3, InceptionV3, ResNet50, and VGG16) for classifying cassava disease images. The images were sour- ced from an imbalanced dataset from a competition. Appropriate metrics were employed to address class imbalance. The results indicate that EfficientNet- B3 achieved on this task accuracy of 87.7%, precision of 87.8%, revocation of 87.8% and F1-Score of 87.7%. These findings suggest that EfficientNet-B3 could be a valuable tool to support Digital Agriculture.", "sections": [{"title": "1. Introdu\u00e7\u00e3o", "content": "De acordo com a Empresa Brasileira de Pesquisa Agropecu\u00e1ria (EMPRABA), o investimento em ci\u00eancia ao longo das d\u00e9cadas permitiu que o Brasil se posicionasse como uma importante pot\u00eancia mundial na produ\u00e7\u00e3o de alimentos [Embrapa 2022]. Para a pr\u00f3xima d\u00e9cada, as proje\u00e7\u00f5es apontam um significativo potencial de crescimento no setor. Comparado \u00e0 produ\u00e7\u00e3o de 2022-2023, espera-se um aumento de 24,1% at\u00e9 2032-2033, equivalente a um crescimento anual de 2,4% [MAPA 2023]. As proje\u00e7\u00f5es para o pr\u00f3ximo dec\u00eanio indicam que o Brasil deve manter ou elevar o padr\u00e3o que tem sido t\u00edpico no s\u00e9culo atual aumentos da produ\u00e7\u00e3o agr\u00edcola total superiores ao crescimento da \u00e1rea plantada, o que indica um crescimento da produ\u00e7\u00e3o sem necessidade de expans\u00e3o da \u00e1rea plantada.\nA produ\u00e7\u00e3o brasileira de mandioca (Manihot esculenta Crantz), por exemplo, em 2022 atingiu 18,2 milh\u00f5es de toneladas em uma \u00e1rea de 1,27 milh\u00f5es de hectares. Segundo levantamento do Instituto Brasileiro de Geografia e Estat\u00edstica (IBGE), esse fato consolidou o Brasil como o quinto maior produtor mundial do tub\u00e9rculo [Companhia Nacional de Abastecimento 2023]. A mandioca assume um papel fundamental na seguran\u00e7a alimentar das regi\u00f5es tropicais. Sua rusticidade e adaptabilidade a solos \u00e1cidos, regimes pluviom\u00e9tricos variados e per\u00edodos de seca a tornam ideal para regi\u00f5es com condi\u00e7\u00f5es desafiadoras, em que outras culturas podem falhar [FARIAS et al. 2006].\nA mandioca \u00e9 a base alimentar de mais de 800 milh\u00f5es de pessoas em pa\u00edses em desenvolvimento. Devido a fatores como doen\u00e7as e pragas, enfrenta diversos desafios que amea\u00e7am a produ\u00e7\u00e3o e a seguran\u00e7a alimentar [Howeler et al. 2013]. Entre os principais, destacam-se as doen\u00e7as f\u00fangicas, virais e bacterianas que causam perdas significativas na colheita e na qualidade do tub\u00e9rculo [Calvert and Thresh 2001].\nO diagn\u00f3stico preciso e precoce de doen\u00e7as da mandioca \u00e9 crucial para o manejo eficaz e a mitiga\u00e7\u00e3o dos impactos negativos na produ\u00e7\u00e3o. No entanto, m\u00e9todos tradicionais de diagn\u00f3stico, como a inspe\u00e7\u00e3o visual e testes laboratoriais, apresentam diversas limita\u00e7\u00f5es como resultados inconsistentes, demora para conclus\u00e3o do processo e custos elevados [Santos et al. 2020].\nConsiderando esse cen\u00e1rio de amea\u00e7a \u00e0 produ\u00e7\u00e3o de mandioca, a Vis\u00e3o Computacional se apresenta como uma ferramenta promissora na detec\u00e7\u00e3o e identifica\u00e7\u00e3o de pragas e doen\u00e7as. Especificamente no que diz respeito \u00e0 agricultura digital, ela se destaca na an\u00e1lise de manifesta\u00e7\u00f5es perceptuais de doen\u00e7as, como os sintomas visuais causados por esses pat\u00f3genos. Atrav\u00e9s do uso de t\u00e9cnicas avan\u00e7adas de Intelig\u00eancia Artificial como Aprendizado Profundo (Deep Learning \u2013 DL), especificamente Redes Neurais Convolucionais (Convolutional Neural Networks \u2013 CNNs) [LeCun et al. 2015], \u00e9 poss\u00edvel a identifica\u00e7\u00e3o precoce e precisa de patologias na planta\u00e7\u00e3o de mandioca e o mapeamento da cobertura do solo [Kamilaris and Prenafeta-Bold\u00fa 2018]. Isso viabiliza a ado\u00e7\u00e3o de a\u00e7\u00f5es mais eficazes e direcionadas [Massruh\u00e1 et al. 2020, Santos et al. 2020].\nNesse contexto, esse artigo apresenta um m\u00e9todo de detec\u00e7\u00e3o autom\u00e1tica de doen\u00e7as da mandioca, utilizando CNNs para analisar imagens de folhas do tub\u00e9rculo. S\u00e3o comparadas diferentes arquiteturas de CNNs empregadas na identifica\u00e7\u00e3o de quatro doen\u00e7as, a Bacteriose da Mandioca (Cassava Bacterial Blight \u2013 CBB), a Doen\u00e7a da Estria Marrom (Cassava Brown Streak Disease \u2013 CBSD), a Doen\u00e7a do Mosaico (Cassava Mosaic Disease \u2013 CMD) e o V\u00edrus Mosqueado Verde (Cassava Green Mottle \u2013 CGM). Al\u00e9m disso, \u00e9 analisado o desempenho da melhor Arquitetura para a detec\u00e7\u00e3o dessas doen\u00e7as individualmente, pois \u00e9 poss\u00edvel que uma CNN se comporte melhor na detec\u00e7\u00e3o da CBB e n\u00e3o da CBSD.\nEsse estudo avalia uma metodologia para a classifica\u00e7\u00e3o de doen\u00e7as em mandioca, utilizando t\u00e9cnicas de Aprendizado Profundo e Transfer\u00eancia de Aprendizado. O objetivo principal da pesquisa \u00e9 desenvolver um modelo robusto e eficiente para o diagn\u00f3stico precoce de doen\u00e7as na cultura da mandioca. Para isso, s\u00e3o comparadas diferentes arquiteturas pr\u00e9-treinadas de CNNs. O modelo desenvolvido ser\u00e1 utilizado como suporte \u00e0 tomada de decis\u00e3o no manejo adequado da lavoura no que diz respeito \u00e0 otimiza\u00e7\u00e3o da produtividade e minimiza\u00e7\u00e3o de perdas.\nEsse artigo est\u00e1 organizado da seguinte forma. Na Se\u00e7\u00e3o 2, s\u00e3o apresentados os artigos relacionados \u00e0 classifica\u00e7\u00e3o de doen\u00e7as em plantas utilizando Redes Neurais Artificiais (Artificial Neural Networks \u2013 ANNs). Na Se\u00e7\u00e3o 3, s\u00e3o apresentadas as configura\u00e7\u00f5es experimentais utilizadas, incluindo detalhes sobre o conjunto de dados, modelos, parametriza\u00e7\u00e3o e m\u00e9tricas de desempenho utilizadas para avaliar os resultados. A Se\u00e7\u00e3o 4 aborda os resultados obtidos e a an\u00e1lise comparativa entre os diferentes modelos."}, {"title": "2. Trabalhos Relacionados", "content": "Na literatura, v\u00e1rios trabalhos demonstram a efic\u00e1cia das ANNs na identifica\u00e7\u00e3o de patologias em diversas esp\u00e9cies de plantas. Por exemplo, o trabalho [Mohanty et al. 2016] investigou o uso de duas arquiteturas de CNNs para classificar 26 doen\u00e7as em 14 esp\u00e9cies agr\u00edcolas, resultando em uma acur\u00e1cia de 99,35% no melhor modelo. Os dados utilizados foram obtidos do projeto Plant Village [Hughes et al. 2015], que disponibilizou um conjunto de 54.306 imagens.\nO trabalho [Sangbamrung et al. 2020] prop\u00f4s uma abordagem inovadora para a classifica\u00e7\u00e3o autom\u00e1tica de doen\u00e7as da mandioca. Foram utilizados algoritmos de aprendizado profundo. A metodologia abordou o problema como um caso de classifica\u00e7\u00e3o bin\u00e1ria em duas etapas: (i) detec\u00e7\u00e3o de doen\u00e7a, diferenciando esp\u00e9cimes saud\u00e1veis de esp\u00e9cimes doentes; e (ii) classifica\u00e7\u00e3o espec\u00edfica da doen\u00e7a, classificando a doen\u00e7a espec\u00edfica como Doen\u00e7a da Raia Marrom da Mandioca (CBSD) ou outras doen\u00e7as.\nO trabalho [Sambasivam and Opiyo 2021] introduziu a aplica\u00e7\u00e3o de uma CNN para desenvolver um m\u00e9todo de aprendizado profundo eficiente e econ\u00f4mico, ou seja, exclui a coleta de amostras e an\u00e1lise laboratorial para detectar infec\u00e7\u00f5es nas folhas da mandioca. A abordagem proposta visava resolver um desafio em um conjunto de dados desbalanceado contendo 10.000 imagens classificadas em cinco classes distintas. Para isso, foi utilizada a T\u00e9cnica de Oversampling de Minoria Sint\u00e9tica (Synthetic Minority Over-sampling Technique \u2013 SMOTe) para tratar o conjunto de dados desbalanceado e empregaram uma arquitetura CNN composta por tr\u00eas camadas convolucionais e quatro camadas totalmente conectadas no treinamento. Os resultados obtidos demonstraram um F1-Score de at\u00e9 95% na classe com o melhor desempenho.\nEmbora esses trabalho demonstrem um desempenho satisfat\u00f3rio na resolu\u00e7\u00e3o do problema em foco, \u00e9 percept\u00edvel a aus\u00eancia de uma an\u00e1lise comparativa abrangente entre diferentes arquiteturas de CNNs para essa tarefa espec\u00edfica. Esse trabalho pretende preencher essa lacuna, apresentando uma compara\u00e7\u00e3o detalhada das m\u00e9tricas, utilizando as arquiteturas mais amplamente empregadas em publica\u00e7\u00f5es recentes."}, {"title": "3. Resultados Experimentais", "content": "Nesse trabalho, o problema de classifica\u00e7\u00e3o de doen\u00e7as da folha da mandioca \u00e9 considerado como uma tarefa de classifica\u00e7\u00e3o multiclasse. \u00c9 utilizanda a t\u00e9cnica de Aprendizado Supervisionado. Isso significa que um conjunto de dados preexistente, com imagens de folhas de mandioca rotuladas com suas respectivas doen\u00e7as, foi utilizado para treinar os modelos de classifica\u00e7\u00e3o.\nPara o treinamento das arquiteturas de CNNs, foi utilizado um servidor equipado com um processador Intel(R) Core(TM) i7-8700 CPU @ 3,20 GHz, 32 GB de mem\u00f3ria principal, 2,4 TB de mem\u00f3ria secund\u00e1ria e duas GPUs NVIDIA GeForce GTX 1080 Ti com 11 GB de VRAM cada. O ambiente de programa\u00e7\u00e3o consistiu na Linguagem de Programa\u00e7\u00e3o Python 3.12.2 [Van Rossum and Drake 2009] e no framework PyTorch 2.3.0 [Paszke et al. 2019]."}, {"title": "3.2. Conjunto de dados", "content": "O conjunto de dados utilizado nessa pesquisa compreende 21.367 imagens de folhas de mandioca, cuidadosamente coletadas durante um estudo de campo realizado em Uganda [Ernest Mwebaze 2020]. A maioria das imagens foi capturada por agricultores locais. As imagens foram posteriormente anotadas por especialistas do Instituto Nacional de Pesquisa e Recursos Culturais (NaCRRI), em colabora\u00e7\u00e3o com o laborat\u00f3rio de intelig\u00eancia artificial da Universidade Makerere, em Kampala. As imagens foram cuidadosamente organizadas em cinco classes distintas, cada uma representando uma doen\u00e7a espec\u00edfica da mandioca: Bacteriose da Mandioca (Cassava Bacterial Blight \u2013 CBB); Doen\u00e7a da Estria Marrom (Cassava Brown Streak Disease \u2013 CBSD); Doen\u00e7a do Mosaico (Cassava Mosaic Disease \u2013 CMD); V\u00edrus Mosqueado Verde (Cassava Green Mottle \u2013 CGM); e exemplares saud\u00e1veis.\nA an\u00e1lise explorat\u00f3ria de dados (EDA) revelou um desbalanceamento significativo entre as classes do conjunto de dados. A classe CMD, por exemplo, apresentou um n\u00famero de exemplos consideravelmente maior do que a soma de todas as outras classes juntas, sendo respons\u00e1vel por 61.5% do total de amostras. Classes como a CBB representam apenas 5%, conforme ilustrado na Figura 2. Para lidar com esse desafio, nesse trabalho, foram utilizadas m\u00e9tricas especificas para desbalanceamento de classes (Se\u00e7\u00e3o 3.7)."}, {"title": "3.3. Modelos de CNNS", "content": "O m\u00e9todo para solu\u00e7\u00e3o do problema em quest\u00e3o fundamenta-se nos avan\u00e7os recentes de (Deep Learning), nos quais imagens multidimensionais s\u00e3o fornecidas como entrada para CNNs. Essas redes realizam aprendizado autom\u00e1tico, massivo e hier\u00e1rquico dos par\u00e2metros dos filtros extratores de caracter\u00edsticas, capacitando-se, assim, para classificar padr\u00f5es complexos nos dados de entrada [Goodfellow et al. 2016].\nForam selecionados os seguintes modelos de CNNs para a solu\u00e7\u00e3o proposta:\nEfficientNet-B3: proposta por [Tan and Le 2019], \u00e9 uma CNN que se destaca pela sua efici\u00eancia e desempenho. Essa rede utiliza um m\u00e9todo de escalamento composto por coeficientes de largura, profundidade e resolu\u00e7\u00e3o, para construir arquiteturas computacionalmente eficientes. A EfficientNet-B3 apresenta um equil\u00edbrio entre complexidade e precis\u00e3o, com 12 camadas principais e \u00e9 particularmente eficaz em tarefas de vis\u00e3o computacional.\nInceptionV3: proposta por [Szegedy et al. 2016], emprega uma arquitetura modularizada com blocos Inception, que consistem em convolu\u00e7\u00f5es de diferentes tamanhos de filtro, visando aumentar a efici\u00eancia computacional e melhorar a precis\u00e3o. Com 48 camadas convolucionais, \u00e9 considerada uma das CNNs mais eficientes para tarefas de classifica\u00e7\u00e3o de imagens.\nResNet50: proposta por [He et al. 2016], \u00e9 uma CNN profunda que utiliza o conceito de camadas residuais para mitigar o problema do desvanecimento do gradiente durante o treinamento. Composta por 50 camadas convolucionais, \u00e9 amplamente empregada em tarefas de Vis\u00e3o Computacional.\nVGG16: proposta por [Simonyan and Zisserman 2014], possui 16 camadas e utiliza filtros convolucionais de tamanho 3x3 para extra\u00e7\u00e3o de caracter\u00edsticas. Al\u00e9m disso, emprega camadas de max-pooling para redu\u00e7\u00e3o de dimensionalidade, juntamente com camadas finais completamente conectadas para fins de classifica\u00e7\u00e3o."}, {"title": "3.4. Pr\u00e9 Processamento das Imagens", "content": "Como mencionado na Se\u00e7\u00e3o 3.2, o conjunto de dados apresenta desbalanceamneto entre as classes, com uma classe majorit\u00e1ria predominando significativamente sobre as demais. Para lidar com a situa\u00e7\u00e3o de classe rara, ou seja, quando uma classe \u00e9 minorit\u00e1ria, propomos a utiliza\u00e7\u00e3o da estratifica\u00e7\u00e3o, conforme sugerido por [Amaral 2016]. Essa t\u00e9cnica consiste em dividir o conjunto de imagens em subconjuntos, preservando a propor\u00e7\u00e3o de classes em cada um. Dessa forma, a divis\u00e3o do conjunto de dados \u00e9 apresentada da seguinte maneira:\n\u2022 Treino (70%): utilizado para treinar o modelo.\n\u2022 Valida\u00e7\u00e3o (10%): empregada para avaliar o desempenho do modelo durante o treinamento e evitar o overfitting.\n\u2022 Teste (20%): simula um ambiente real de aplica\u00e7\u00e3o, fornecendo uma avalia\u00e7\u00e3o imparcial do desempenho final do modelo.\nTodas as imagens foram redimensionadas para se adequarem \u00e0s entradas dos diferentes modelos utilizados. Para os modelos ResNet50 e VGG19, as imagens foram ajustadas para 224 x 224 pixels. Para o modelo InceptionV3, as imagens foram redimensionadas para 299 x 299 pixels. Para o modelo EfficientNet-B3, as imagens foram ajustadas para 300 x 300 pixels. Dessa forma, todas as imagens t\u00eam as dimens\u00f5es apropriadas durante o treinamento de cada rede, garantindo a compatibilidade com os respectivos modelos apresentados.\nConjuntamente ao redimensionamento das imagens \u00e9 aplicado o Data Augmentation, uma t\u00e9cnica utilizada em Aprendizado de M\u00e1quina e Vis\u00e3o Computacional para aumentar a diversidade dos dados de treinamento. Isso \u00e9 feito aplicando diversas transforma\u00e7\u00f5es nos dados originais, criando novas amostras sem a necessidade de coletar dados adicionais [Shorten and Khoshgoftaar 2019].\nPara parametrizar o aumento de dados foram realizadas transforma\u00e7\u00f5es geom\u00e9tricas, de cor e de ru\u00eddo. Essas transforma\u00e7\u00f5es incluem normaliza\u00e7\u00e3o dos valores dos pixels, rota\u00e7\u00e3o aleat\u00f3ria das imagens, deslocamento horizontal e vertical, transforma\u00e7\u00e3o de cisalhamento, zoom aleat\u00f3rio, invers\u00e3o horizontal e ajuste de brilho. \u00c9 importante destacar que essas transforma\u00e7\u00f5es s\u00e3o aplicadas apenas ao conjunto de treinamento. Nos conjuntos de teste e valida\u00e7\u00e3o, apenas a normaliza\u00e7\u00e3o dos valores dos pixels \u00e9 aplicada."}, {"title": "3.5. Transfer\u00eancia de Aprendizado", "content": "Treinar uma CNN para uma tarefa espec\u00edfica pode ser um processo computacionalmente caro. Essa tarefa exige grandes conjuntos de dados e poder de processamento significativo. A Transfer\u00eancia de Aprendizado [Pan and Yang 2009] oferece uma solu\u00e7\u00e3o para contornar essa dificuldade. Essa t\u00e9cnica utiliza um modelo pr\u00e9-treinado em um problema similar como ponto de partida para o treinamento da rede. Dessa forma, \u00e9 poss\u00edvel otimizar o treinamento de redes convolucionais, especialmente quando recursos computacionais s\u00e3o limitados.\nPara inicia\u00e7\u00e3o dos pesos dos modelos foi utilizado o pr\u00e9-treinamento do ImageNet [Russakovsky et al. 2015], aproveitando os pesos das camadas gen\u00e9ricas para iniciar o treinamento para acelerar o processo de treinamento."}, {"title": "3.6. Constru\u00e7\u00e3o do Modelo", "content": "Para todas as arquiteturas de CNNs selecionadas (Sec\u00e3o 3.3), os pesos foram iniciados conforme descrito na Se\u00e7\u00e3o 3.5. O treinamento foi conduzido com um limite m\u00e1ximo de 50 \u00e9pocas. Adotou-se a t\u00e9cnica de Early Stopping, com uma paci\u00eancia de 5 \u00e9pocas, interrompendo o treinamento caso a perda no conjunto de valida\u00e7\u00e3o n\u00e3o melhore em 5 \u00e9pocas consecutivas. Al\u00e9m disso, foi empregada a t\u00e9cnica de Model Checkpoint para monitorar a perda no conjunto de valida\u00e7\u00e3o e persistir os pesos que proporcionassem melhor generaliza\u00e7\u00e3o.\nO tamanho do lote (batch size) foi estabelecido em 32, o que significa que o algoritmo treinou os modelos em blocos de 32 amostras, at\u00e9 utilizar todo o conjunto de dados. Quando todos os blocos s\u00e3o passados pelo modelo, encerra-se uma \u00e9poca.\nA taxa de aprendizado inicial foi definida em $10^{\u20133}$ com o uso do otimizador Adam [Kingma and Ba 2014], conhecido por sua capacidade de lidar com problemas de converg\u00eancia em treinamentos de redes neurais profundas e por sua robustez em rela\u00e7\u00e3o a varia\u00e7\u00f5es na taxa de aprendizado.\nA t\u00e9cnica de identifica\u00e7\u00e3o de plat\u00f4 (ReduceLROnPlateau) foi implementada com o objetivo de otimizar a taxa de aprendizado do modelo. Essa estrat\u00e9gia assegura que, caso o modelo n\u00e3o apresente melhorias em suas m\u00e9tricas (a loss do conjunto de valida\u00e7\u00e3o) por duas \u00e9pocas consecutivas, a taxa de aprendizado seja automaticamente reduzida em um fator de 0,1. Isso evita a estagna\u00e7\u00e3o e promove um treinamento mais eficiente.\nPara o c\u00e1lculo da loss, optou-se pelo uso do crit\u00e9rio Perda de Entropia Cruzada (Cross-Entropy Loss), tamb\u00e9m conhecido como Perda Logar\u00edtimica, dispon\u00edvel no Pytorch. Essa fun\u00e7\u00e3o de perda \u00e9 usada para encontrar a solu\u00e7\u00e3o ideal ajustando os pesos de um modelo de aprendizado de m\u00e1quina durante o treinamento. O objetivo \u00e9 minimizar o erro entre os resultados reais e previstos. Assim, uma medida mais pr\u00f3xima de 0 (zero) \u00e9 sinal de um bom modelo, enquanto uma medida mais pr\u00f3xima de 1 (um) \u00e9 sinal de um modelo de baixo desempenho.\nA configura\u00e7\u00e3o das redes pr\u00e9-treinadas \u00e9 fundamental, especialmente considerando que foram originalmente treinadas no conjunto de dados ImageNet, que consiste em 1000 classes de sa\u00edda poss\u00edveis. Para adaptar o modelo \u00e0 tarefa de classifica\u00e7\u00e3o de doen\u00e7as da mandioca, que possui cinco classes de sa\u00edda, \u00e9 necess\u00e1rio realizar modifica\u00e7\u00f5es na arquitetura. Inicialmente, as camadas finais do modelo s\u00e3o removidas para permitir a inclus\u00e3o de camadas adequadas a essa classifica\u00e7\u00e3o. Adiciona-se uma camada densa com cinco neur\u00f4nios e ativa\u00e7\u00e3o softmax, que converte as sa\u00eddas da camada densa em probabilidades. Cada neur\u00f4nio na camada de sa\u00edda representa a probabilidade da imagem pertencer a uma das classes especificadas e considera-se que a classe com maior probabilidade \u00e9 a predi\u00e7\u00e3o do modelo."}, {"title": "3.7. M\u00e9tricas de Avalia\u00e7\u00e3o", "content": "A avalia\u00e7\u00e3o da efic\u00e1cia dos modelos selecionados requer m\u00e9tricas ponderadas adequadas ao desbalanceamento do conjunto de dados. Para isso, foram selecionadas m\u00e9tricas como acur\u00e1cia, precis\u00e3o, revoca\u00e7\u00e3o e F1-Score, juntamente com a an\u00e1lise da matriz de confus\u00e3o.\nAcur\u00e1cia $= \\frac{1}{|N|}\\sum_{N \\in N} \\sum(\\frac{TP_n + TN_n}{TP_n + TN_n + FP_n + FN_n})$\nPrecis\u00e3o = $\\frac{1}{|N|} \\sum_{N \\in N} (\\frac{TP_n}{TP_n + FP_n})$\nRevoca\u00e7\u00e3o $= \\frac{1}{|N|} \\sum_{N \\in N} (\\frac{TP_n}{TP_n + FN_n})$\nF1-Score $= \\frac{2 \\cdot Precis\u00e3o \\cdot Revoca\u00e7\u00e3o}{(Precis\u00e3o + Revoca\u00e7\u00e3o)}$\nNas equa\u00e7\u00f5es (1)-(3), em que N denota o conjunto de classes do problema, as abrevia\u00e7\u00f5es representam quatro poss\u00edveis resultados em uma an\u00e1lise de classifica\u00e7\u00e3o bin\u00e1ria. Explicitamente, True Positive (TP) quantifica as inst\u00e2ncias corretamente identificadas como pertencentes \u00e0 classe positiva; True Negative (TN) reflete as predi\u00e7\u00f5es corretas para a classe negativa; False Positive (FP) representa os casos erroneamente classificados como positivos quando deveriam ser negativos; e False Negative (FN) representa os casos em que as predi\u00e7\u00f5es indicam negatividade equivocadamente, quando deveriam ser positivas."}, {"title": "4. Resultados e Discuss\u00e3o", "content": "Os experimentos foram conduzidos de acordo com a metodologia proposta na Se\u00e7\u00e3o 3 e os resultados foram registrados na Tabela 1. Nessa se\u00e7\u00e3o, s\u00e3o apresentados os resultados e discute-se o uso das estrat\u00e9gias de treinamento empregadas, bem como avalia-se o desempenho da classifica\u00e7\u00e3o de cada CNN escolhida, conforme as m\u00e9tricas descritas na Se\u00e7\u00e3o 3.7.\nPara o comparativo principal entre os modelos, utilizou-se a m\u00e9trica F1-Score, pois, al\u00e9m de equilibrar Precis\u00e3o e Revoca\u00e7\u00e3o, essa m\u00e9trica \u00e9 especialmente \u00fatil em cen\u00e1rios com conjuntos de dados desbalanceados, oferecendo uma avalia\u00e7\u00e3o mais precisa em situa\u00e7\u00f5es em que algumas classes s\u00e3o subrepresentadas.\nCom exce\u00e7\u00e3o da VGG16, todas as arquiteturas alcan\u00e7aram resultados acima de 86% em todas as m\u00e9tricas calculadas sobre o conjunto de testes. Dentre elas, destaca-se positivamente a EfficientNet-B3, que obteve um F1-Score de 87,7%. A VGG16 apresentou um desempenho inferior devido \u00e0 sua incapacidade de capturar padr\u00f5es e caracter\u00edsticas relevantes em um conjunto de dados t\u00e3o desbalanceado. Como resultado, essa arquitetura apresentou um comportamento em que a predi\u00e7\u00e3o era sempre a classe majorit\u00e1ria para todos os exemplos. Por isso sua acur\u00e1cia \u00e9 igual \u00e0 propor\u00e7\u00e3o de casos da classe majorit\u00e1ria (CMD).\nEntre os diversos fatores que justificam a inefici\u00eancia da VGG16 em compara\u00e7\u00e3o com outros modelos, destaca-se sua quantidade excessiva de par\u00e2metros. A VGG16 possui at\u00e9 10 vezes mais par\u00e2metros do que as melhores arquiteturas, o que aumenta a propens\u00e3o ao overfitting. Por outro lado, modelos como EfficientNet-B3, InceptionV3 e ResNet50 n\u00e3o apenas possuem menos par\u00e2metros, mas tamb\u00e9m s\u00e3o projetados para serem mais eficientes computacionalmente, permitindo alcan\u00e7ar melhores resultados com menos recursos. O EfficientNet-B3 incorpora t\u00e9cnicas avan\u00e7adas de regulariza\u00e7\u00e3o, como o escalonamento composto, que envolve o aumento simult\u00e2neo de largura, profundidade e resolu\u00e7\u00e3o da rede. Isso permite que a rede receba imagens de maior resolu\u00e7\u00e3o, com mais camadas convolucionais e um n\u00famero maior de canais em cada camada, capturando caracter\u00edsticas mais complexas dos dados.\nDevido aos resultados superiores da arquitetura EfficientNet-B3, decidiu-se explorar mais detalhadamente seus resultados. Observando a Tabela 2 e a Matriz de Confus\u00e3o apresentada na Figura 3, nota-se que a arquitetura foi capaz de classificar todas as classes com mais de 70% de precis\u00e3o, exceto a classe CBB. Essa classe tem a menor quantidade de amostras do conjunto de dados, representando cerca de 5% do total de amostras. A classe CBB teve o pior desempenho. Destaca-se a classifica\u00e7\u00e3o da classe CMD, a classe majorit\u00e1ria do problema, com todas as m\u00e9tricas acima de 95%. Apesar de as classes CBSD, CGM e os exemplares saud\u00e1veis tamb\u00e9m serem classes raras no conjunto, os resultados para elas foram superiores, chegando a atingir at\u00e9 84.3% de precis\u00e3o. Isso demostra que \u00e9 poss\u00edvel atingir bons resultados apesar do conjunto desbalanceado."}, {"title": "5. Conclus\u00f5es", "content": "Esse trabalho teve como objetivo realizar um estudo comparativo do desempenho de diferentes arquiteturas de Redes Neurais Convolucionais utilizando a t\u00e9cnica de Transfer Learning. O objetivo foi encontrar um modelo eficaz na classifica\u00e7\u00e3o de patologias da Mandioca, otimizando recursos computacionais e eliminando a necessidade de desenvolvimento de um modelo espec\u00edfico para essa tarefa.\nDurante o desenvolvimento desse estudo, foi observado que as Redes Neurais Convolucionais podem ser ferramentas \u00fateis na classifica\u00e7\u00e3o dessas patologias. Destaca-se o EfficientNet-B3, que alcan\u00e7ou um F1-Score de 87,7% e at\u00e9 95% de acur\u00e1cia na classe com maior n\u00famero de acertos, demonstrando sua capacidade de identificar corretamente a maioria das patologias apresentadas.\nPara futuros trabalhos, planeja-se explorar o impacto de diferentes hiperpar\u00e2metros, como, por exemplo, o otimizador RMSProp [Tieleman and Hinton 2017] ou variantes do Adam. Planeja-se tamb\u00e9m explorar t\u00e9cnicas avan\u00e7adas de otimiza\u00e7\u00e3o de hiperpar\u00e2metros, como, por exemplo, a busca em larga escala. Al\u00e9m disso, pretende-se avaliar o efeito do balanceamento do conjunto de dados atrav\u00e9s de t\u00e9cnicas, como replica\u00e7\u00e3o de imagens, ou gera\u00e7\u00e3o de imagens sint\u00e9ticas para classes minorit\u00e1rias usando m\u00e9todos, como SMOTE [Chawla et al. 2002] ou ADASYN [He et al. 2008]."}]}