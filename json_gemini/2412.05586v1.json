{"title": "Towards Learning to Reason: Comparing LLMs with Neuro-Symbolic on Arithmetic Relations in Abstract Reasoning", "authors": ["Michael Hersche", "Giacomo Camposampiero", "Roger Wattenhofer", "Abu Sebastian", "Abbas Rahimi"], "abstract": "This work compares large language models (LLMs) and neuro-symbolic approaches in solving Raven's progressive matrices (RPM), a visual abstract reasoning test that involves the understanding of mathematical rules such as progression or arithmetic addition. Providing the visual attributes directly as textual prompts, which assumes an oracle visual perception module, allows us to measure the model's abstract reasoning capability in isolation. Despite providing such compositionally structured representations from the oracle visual perception and advanced prompting techniques, both GPT-4 and Llama-3 70B cannot achieve perfect accuracy on the center constellation of the I-RAVEN dataset. Our analysis reveals that the root cause lies in the LLM's weakness in understanding and executing arithmetic rules. As a potential remedy, we analyze the Abductive Rule Learner with Context-awareness (ARLC), a neuro-symbolic approach that learns to reason with vector-symbolic architectures (VSAs). Here, concepts are represented with distributed vectors s.t. dot products between encoded vectors define a similarity kernel, and simple element-wise operations on the vectors perform addition/subtraction on the encoded values. We find that ARLC achieves almost perfect accuracy on the center constellation of I-RAVEN, demonstrating a high fidelity in arithmetic rules. To stress the length generalization capabilities of the models, we extend the RPM tests to larger matrices (3\u00d710 instead of typical 3\u00d73) and larger dynamic ranges of the attribute values (from 10 up to 1000). We find that the LLM's accuracy of solving arithmetic rules drops to sub-10%, especially as the dynamic range expands, while ARLC can maintain a high accuracy due to emulating symbolic computations on top of properly distributed representations.", "sections": [{"title": "I. INTRODUCTION", "content": "Abstract reasoning is often regarded as a core feature of human intelligence. This cognitive process involves abstracting rules from observed patterns in a source domain, and applying them in an unseen target domain. With the ultimate aim to achieve human-level intelligence, abstract reasoning tasks have sparked the interest of many in machine learning research. Thanks to the availability of large datasets1\u20133, various learning-based methods, ranging from pure connectionist4,5 to neuro-symbolic6\u20139 approaches, achieved promising results in this domain.\nMore recently, the zero- and few-shot capabilities of large language models (LLMs) and their multi-modal variants have been tested on various abstract reasoning tasks such as verbal10\u201313 or visual10,13\u201322 analogies. One natural approach towards zero-shot visual abstract reasoning is to leverage multi-modal LLM's vision capabilities to solve the task end-to-end. However, these multi-modal models perform significantly worse than their text-only version16, which might stem from a missing fine-grained compositional feature comprehension14. As an additional help, LLMs have been provided with text-only inputs by giving them access to an oracle perception, i.e., providing perfectly disentangled representations10,15. While this generally improves their reasoning abilities, LLMs still fail to achieve perfect accuracy on many simple tasks. One example is represented by Raven's progressive matrices (RPMs)23, a benchmark that tests visual abstract reasoning capabilities by measuring the fluid intelligence of humans. Here, the state-of-the-art (SOTA) LLM-based approach15 achieves only 86.4% accuracy in the center constellation of I-RAVEN\u00b3, which we observe to be a gate-keeper for this task (see Section II A).\nIn contrast, recent neuro-symbolic approaches showed not only almost perfect accuracy on the center constellation of I-RAVEN, but also demonstrated high fidelity in out-of-distribution (OOD) settings. For instance, the Abductive Rule Learner with Context-awareness (ARLC) represents attribute values with high-dimensional, distributed representations based on vector-symbolic architectures (VSAs)24\u201327. Learning the RPM rules boils down to a differentiable assignment problem of high-dimensional panel representations in a series of binding and unbinding operations, which can be solved with unconstrained optimization algorithms such as stochastic gradient descent (SGD). ARLC outperformed the SOTA LLM-based approach15 both on in-distribution and OOD, thanks to relying on structured and similarity-preserving representations based on fractional power encoding (FPE)25.\nThis paper extends on the initial work on ARLC9, by comparing its abstract reasoning capability with two prominent LLMs (GPT-428 and Llama-3 70B29)."}, {"title": "II. DATASETS", "content": ""}, {"title": "A. I-RAVEN", "content": "We test the models on the center constellation of I-RAVEN\u00b3 (see Fig. 1). The test consists of a 3\u00d73 context matrix and eight answer candidate panels. Each panel contains an object, characterized by different attributes (shape, size, and color). The relation between each attribute's value in different panels is governed by a well-defined set of rules: constant, progression, arithmetic, and distribute three. The task is to infer the rule governing each attribute in the context matrix and use it to determine the content of the missing (bottom-right) panel, selecting it within the eight candidate answers. Compared to other RPM benchmarks that have been used to evaluate LLMs10, I-RAVEN tests a more complex range of logical and arithmetic skills. While I-RAVEN provides tests in various constellations with more objects that may intuitively appear more arduous to solve, LLMs are more challenged with the seemingly simple constellations. For instance, GPT-3 achieved a higher accuracy on the 2x2 and 3x3 constellations (78.0% and 86.4%) than on center (77.2%)15. Moreover, high accuracy can be maintained on the 2x2 and 3x3 constellations while only looking at the last row of the context matrix15, effectively showing that no analogical reasoning is required to solve the test in these constellations. Hence, we opted to focus our evaluation on the center constellation only, using 500 samples from I-RAVEN's test set. Inspired by recent works10,15, we simplify RPM from a visual abstract reasoning test to a purely abstract reasoning test. Assuming a perfect perception, we extract the attribute values from I-RAVEN and use them to create the prompts for the model."}, {"title": "B. New I-RAVEN-X", "content": "To further evaluate the mathematical reasoning capabilities at scale, we introduce an extension of the I-RAVEN's center constellation, called I-RAVEN-X. Our new benchmark maintains I-RAVEN's rules and attributes but allows for a parameterizable number of columns (g) and a dynamic range of attribute values (m). When generating a new RPM example, we uniformly sample from one of the available rules (constant, progression, arithmetic, and distribute three). Note that the attribute shape does not incur the arithmetic rule. We use I-RAVEN's attribute bisection tree\u00b3 to generate unbiased candidate answers.\nIn the following, we describe the context matrix generation for the individual rules. The overall goal is that the values stay in the range [0,m - 1].\nconstant: This rule keeps the attribute value constant per row. For each row, we uniformly sample an integer from the set {0,1,..., m - 1}, and duplicate along the row.\nprogression: The attribute value monotonically increases or decreases in a row by a value of 1 or 2. First, we uniformly sample the progressive increment/decrement (\u03b4) from the set {-2,-1,+1,+2}. In case of a positive increment, we first define the values of the right-most columns, by uniformly sampling from the set {(g \u2013 1) \u00b7 \u03b4, ..., m \u2013 1} for each row. Then, the rest of the matrix is completed by applying the progression rule. The sampling for a negative \u03b4 is done specularly from the first column.\narithmetic: The attribute values of the first g 1 panels are either added (arithmetic plus) or subtracted (arithmetic minus), yielding the attribute value of the last panel in the row. In arithmetic plus, we sequentially sample the values from the first g 1 panels in the row. For each panel, we set the sampling range to {0, ..., m \u2013 s}, where s is the sum of the already sampled panels in the row. Afterward, the first g 1 panels are shuffled. Finally, the values of the last panels are the sum of the first g 1 ones, applied row-wise. For arithmetic minus, we apply the same sampling strategy but leave the first column empty. The value of the first column is then defined as the sum of the other columns.\ndistribute-n: We uniformly sample distinct values for the first row from {0,...,m \u2013 1}. The content of the remaining rows is defined by applying a circular shift per row (either right or left)."}, {"title": "III. LLM-BASED RPM SOLVING", "content": ""}, {"title": "A. Models", "content": "We focused our evaluations on text-only LLMs. There exist attempts14,16,18\u201320 that leverage vision support of some multi-modal LLMs (e.g., GPT-4V) directly feeding the models with visual RPM data; however, they achieve consistently lower rea-"}, {"title": "B. Prompting and classification", "content": "a. Entangled and disentangled prompts Following15, we evaluated two different prompting strategies, entangled and disentangled prompting. The entangled prompting provides all the attributes' values in a single prompt (see Appendix A 1). The disentangled prompting, on the other hand, is a compositionally structured approach that queries the LLM for individual attribute prediction. Disentangled prompting simplifies the task, but increases the number of queries by 3x.\nb. Discriminative and predictive classification Similarly to12, we consider two approaches to solve RPM tests with LLMs. In the discriminative approach, we provide the attribute descriptions of both the context matrix and the answer candidates. The LLM is then asked to return the panel number of the predicted answer. Appendix A2 provides an example prompt of the discriminative approach. In the predictive approach, we prompt the LLM only with the context matrix without the candidate answers. The LLM has to predict the value of the empty panel (see Fig. 2). For selecting the final answer, we compare the predicted values with the answer panels and pick the one with the highest number of overlapping values. While the predictive approach may appear more difficult, it implicitly biases the LLM to approach the task as humans usually do, i.e., first applying a generative process to abduce rules and execute them to synthesize a possible solution, and then discriminatively selecting the most similar answer from choices30. Moreover, the final answer selection is done without the intervention of the LLM, rendering phenomena like hallucinations less likely. Thus, the predictive classification can be seen as a more guided approach that helps LLM to solve the task.\nc. Self-consistency As an optional extension, we employ self-consistency31,32 by querying the model multiple times (n = 7 times), sampling the next token from the distribution with a non-zero soft-max temperature. We find the optimal soft-max temperature for GPT-4 (T = 0.5) and Llama-3 70 B (T = 0.4) via a grid search on a subset of 50 I-RAVEN problems. We did not explore the effect of other parameters, such as top-k or top-p, and set them to the default values. The final prediction is determined by a majority vote over the sampled outputs. The selection of an odd number of samples (i.e., n = 7) helps to prevent potential ties.\nd. In-context learning For a better understanding of the RPM task, we optionally prefix 16 in-context examples to the prompt33. In the predictive classification approach (where no answer candidates are provided), we simply provide complete example RPM matrices. The in-context samples are randomly selected from I-RAVEN's training set. Examples that had the same context matrix as the actual task are discarded and re-sampled to prevent shortcut solutions."}, {"title": "IV. ARLC: LEARNING ABDUCTIVE REASONING USING VSA DISTRIBUTED REPRESENTATIONS", "content": "This section presents the Abductive Rule Learner with Context-awareness (ARLC), which performs neuro-symbolic reasoning with distributed VSA representations. ARLC projects each panel's attribute value (or distributions of values) into a high-dimensional VSA space. The resulting VSA vectors preserve the semantic similarity between attribute values: the dot products between corresponding VSA encoded vectors define a similarity kernel25,34. Moreover, simple component-wise operations on these vectors, binding and unbinding, perform addition and subtraction respectively on the encoded values. For rule learning, ARLC introduces a generic rule template with several terms forming a series of binding and unbinding operations between vectors. The problem of learning the rules from data is reduced to a differentiable assignment problem between the terms of the general rule template and the VSA vectors encoding the contents of the panels, which can be learned with standard SGD. ARLC was initially presented in\u2079; this work mainly compares it to the reasoning capabilities of LLMs on I-RAVEN, and demonstrates its extension to larger grid sizes and dynamic ranges on our novel I-RAVEN-X."}, {"title": "A. From visual attributes to distributed VSA representations", "content": "ARLC's key concept is to represent attribute values with high-dimensional, distributed VSA vectors that preserve the semantic similarity between the attribute values thanks to an introduced kernel notion. We start by defining a VSA that equips the space with dimensionality-preserving vector operations (binding, unbinding, and bundling) as well as a similarity function (cos(,)). For example, ARLC uses binary generalized sparse block codes (GSBCs)35 as a particular VSA instance. In binary GSBCs, the D-dimensional vectors are divided into B blocks of equal length, L = D/B, where only one (randomly selected) element per block is set to 1 (D = 1024 and B = 4). The algebraic operations of binary GSBCs are defined in Table I. See Appendix B for a detailed background on VSA.\nNext, we define a mapping $z: Z+ \\rightarrow R^D$ that enables the projection of input RPM attributes into a corresponding high-dimensional, semantically-rich feature space. Note that this work focuses on mapping integer values as the attribute values in I-RAVEN are integer-valued too. However, generalizing this approach to real-valued domain mappings is possible using frequency holographic reduced representations (FHRR)24. Leveraging fractional power encoding (FPE)25, a value $v \\in Z^+$ is encoded as\n$z(v) = \\mathop{\\otimes}\\limits_{n=1}^{v} z,$\nwhere $z \\in R^D$ is a randomly drawn binary GSBC vector. This mapping yields a similarity kernel between neighboring vector representations34, as shown in Fig. 4.\nLet us assume two variables with values $v_1$ and $v_2$, which are represented with two VSA vectors ($z(v_1) = z^{v_1}$ and $z(v_1) = z^{v_2}$). Binding the two vectors yields $z(v_1) \\otimes z(v_2) = z^{v_1} \\otimes z^{v_2} = z^{v_1+v_2}$. Hence, binding in the VSA space is equivalent to the addition"}, {"title": "B. Learning RPM rules as an assignment problem", "content": "As we have seen in the previous example, RPM rules can be represented using VSA operations. Generalizing the application beyond the arithmetic plus rule, we find that the rules used in RPM can be framed as a series of binding and unbinding operations:\n$r = (c_1 \\otimes c_2 \\otimes c_3 \\otimes c_4 \\otimes c_5 \\otimes c_6) \\otimes (c_7 \\otimes c_8 \\otimes c_9 \\otimes c_{10} \\otimes c_{11} \\otimes c_{12}),$\nwhere $c_i$ represents a context panel $v_a^{(i,j)}$ or the identity $e$. In this setting, learning the rules of RPM can hence be interpreted as an assignment problem between VSA vectors and terms of Equation (2).\nMotivated by works in cognitive sciences and psychology that argue for the importance of context in the solution of analogies for humans 36,37, ARLC uses a general formulation of the soft-assignment problem which relies on the notion of context:\n$c_k = \\sum_{i=1}^{I} w_i x_i + \\sum_{j=1}^{J} u_j o_j + v_k e,$\nwhere w, u, v are the learned parameters and they are subject to the following constraints:"}, {"title": "C. Executing and selecting the learned rules", "content": "Inference with the learned rule set is a two-step process: an execution step (where all the rules are applied in parallel to the input) and a selection step (where a prediction for the missing panel is generated). The application of each rule r to an RPM example generates a tuple of three VSA vectors $(v_{a,r}^{(i,3)})_{i=1}^3$, which corresponds to the result of the rule execution on the three rows of the RPM matrix, together with a rule confidence value $s_r$. The confidence value is computed as the sum of the cosine similarities between the predicted VSA vectors and their respective ground-truth vector,\n$s_r = \\sum_{i=1}^{3} \\cos (v_a^{(i,3)}, v_a^{(i,3)}).$\nDuring inference, the last term of the sum (i = 3) is omitted, as the ground truth for the third row is unknown.\nThe answer is finally produced by taking a linear combination of the VSA vectors generated by executing all the rules, weighted by their respective confidence scores (normalized to a valid probability distribution using a softmax function). More formally, if we define s = [$s_1$,..., $s_R$] to be the concatenation of all rules' confidence score and $v_{a,R}^{(3,3)}$ = [$v_{a,1}^{(3,3)}$,...,$v_{a,R}^{(3,3)}$] to be the concatenation of all rules' predictions for the missing panel, the final VSA vector predicted by the model for the attribute a becomes\n$v_a^{(3,3)} = softmax (s) \u00b7 v_{a,R}^{(3,3)}.$\nThe use of the weighted combination can be understood as a soft-selection mechanism between rules and was found to be more effective compared to the hard-selection mechanism provided by sampling8."}, {"title": "D. Training Loss and other Implementation Aspects", "content": "We follow the training recipe provided by Learn-VRF. The model is trained using stochastic gradient descent (SGD) with a learning rate lr = 0.01 for 25 epochs. The training loss is defined as the inverse cosine similarity between the three predicted"}, {"title": "E. Applying ARLC on I-RAVEN-X", "content": "While ARLC was initially designed for I-RAVEN, it can be seamlessly extended to our I-RAVEN-X with minor modifications. First, the number of binding/unbinding terms in Equation (2) is increased, e.g., from 12 to 22 to support the larger grid size of g = 10. Moreover, we increase the number of entries in the dictionary (C) to support the larger dynamic range (m). Notably, only varying the dynamic range at constant grid size does not require retraining: we can simply replace the dictionary in order to support OOD generalization. Indeed, we could demonstrate that ARLC trained on a dynamic range of m = 45 can favorably generalize to a dynamic range of m = 1000."}, {"title": "V. RESULTS", "content": ""}, {"title": "A. Main results on I-RAVEN", "content": "Table II compares our LLM results with ARLC on the center constellation of I-RAVEN, considering also a range of neuro-symbolic and connectionist baselines. For the LLMs, we show the results with the corresponding best prompting techniques (see the ablation in Section V B). Moreover, we present results for three different versions of ARLC: ARLCprogr, where the model's weights are manually programmed with RPM rules (R = 4, since constant can be considered as a special case of progression), ARLCp\u21921, where the model is initialized with the programmed rules and then trained with gradient descent, and ARLClearn, where the rules are learned from scratch from data.\nAmong the LLM approaches, our GPT-4-based approach achieved the highest accuracy (93.2%) notably outperforming previous SOTA LLM-based abstract reasoning approaches on this benchmark (86.4%)15. Yet, all LLM approaches fall behind the tailored connectionist and neuro-symbolic solutions. Notably, with only 480 learnable parameters, ARLC achieves a high accuracy of 98.4%. Moreover, we show that post-programming training allows to extend the knowledge of the model, rather than completely erasing it as shown in other settings38, resulting in a monotonic increase in downstream accuracy."}, {"title": "C. LLMs show weakness in arithmetic rule", "content": "Even though both LLMs achieve a reasonable overall task accuracy, they fail in some instances. We shed more light on the reasoning capability of the two models by analyzing the accuracy of predicting the correct value for a given rule. As shown in Table IV, both models perform well on constant, progression, and distribute three rules, whereas the accuracy notably drops for the arithmetic rule. One explanation for the accuracy drop could be the LLM's tendency for (short-sighted) relational reasoning, instead of performing relational mapping that requires the understanding of the first two rows before applying a rule on the last row11. We analyze this hypothesis in Appendix C, where we attempt to explain the LLM's wrong predictions by rules that may have been inferred from the last row. For GPT-4, 32 out of 68 errors can be explained by rules that might have been inferred from a partial context matrix, e.g., a constant or progression rule based on the last row."}, {"title": "D. Results on our novel I-RAVEN-X", "content": "Finally, we conduct experiments on our novel I-RAVEN-X test, which allows us to configure the matrix size and the dynamic range of the attribute values. We fix the grid size to 3 \u00d7 10 and vary the dynamic range between 50, 100, and 1000. As shown in Table V, the LLM's drops not only due to the larger grid size but also generally degrades with an increasing dynamic range. At the same time, our ARLC maintains a high accuracy across the board, while only being trained at dynamic range of 50 and reconfigured for the higher ranges. Investigating the performance on the arithmetic rule in Table VI explains the overall accuracy degradation: the arithmetic accuracy drops below 10% for both LLMs at the highest dynamic range (1000)."}, {"title": "VI. CONCLUSION", "content": "This work revealed LLM's limitations in recognizing and executing arithmetic rules in abstract reasoning tasks, despite being provided disentangled prompts with ground-truth visual attributes and using advanced prompting techniques. We further showed the serious limitation on a larger (3\u00d710) RPM test. As a viable alternative, we presented a neuro-symbolic approach (ARLC) that achieves a high accuracy both on I-RAVEN and our I-RAVEN-X, thanks to learning to reason with distributed VSA representations and operators. We hope that our findings will lead to the development of architectures that aim to improve reasoning capabilities, e.g., by integrating symbolic solvers such as our ARLC into LLMs."}, {"title": "Appendix B: Vector-symbolic architectures", "content": "Vector-symbolic architectures (VSAs)24\u201327 are a family of computational models that rely on the mathematical properties of high-dimensional vector spaces. VSAs make use of high-dimensional distributed representations for structured (symbolic) representation of data while maintaining the advantages of connectionist distributed vector representations (see39 for a survey). Here is a formal definition of VSAs:\nDefinition 1 (VSA) A vector-symbolic architecture (VSA) consists of a 4-tuple V = (C, \u2295,,), where C is a set of high-dimensional distributed vectors equipped with two main operations, \u2295 (bundling) and \u2297 (binding), and on which it is possible to define a similarity measure.\nBundling is a similarity-preserving operation that creates a superposition of the operands, that is, the resulting vector will have a high similarity with the two operands. Binding, on the other hand, is an operation that allows to bind a vector (value) to another vector (key) and does not preserve similarities; it usually allows an inverse operation, called unbinding. The specific realization of the bundling, binding, and vector space constitute the main difference between members of the VSA family."}, {"title": "Appendix C: Analysis of arithmetic errors", "content": "This appendix aims to find explanations for LLM's errors by analyzing the structure behind the predicted answers. A recent study\u00b9\u00b9 showed that LLMs tend to solve verbal analogy problems in an associative way instead of performing proper relational mapping. The associative reasoning can be explained as ignoring the source domain and solving the task directly at the target domain (e.g., only looking at the possible solutions without reading the questions). Interestingly, children tend to perform associative reasoning, whereas adults opt for relational mapping.\nIn RPMs, the source domain can be defined as the first two rows (with values x1,1,X1,2,X1,3 and x2,1,X2,2,X2,3), whereby the target domain is the last row (x3,1,X3,2). Therefore, an associative reasoner would only look at the last row to solve the task. In the following, we aim to find potential incorrect rules that the LLMs may have been inferred from the last row(s):\nconstant: The values of the last row are identical (x3,1 = x3,2), and the model predicts x3,3 = x3,2 = x3,1\nprogression: The values of the last row differ by \u03b4 = x3,2 - x3,1, and the model predicts x3,3 = x3,2 + \u03b4\nshort constant: The model just copies the penultimate value: x3,3 = X3,2.\nshort distribute three: Assuming a distribute three over the last two rows: x3,1 \u2208 {X2,1,X2,2,X2,3}, X3,2 \u2208 {X2,1,X2,2,X2,3}, and hence x3,3 \u2208 {X2,1,X2,2,X2,3}.\nFig. C.8 shows the resulting confusion matrix summarizing all the attributes. The arithmetic rule has fewer occurrences as this rule is not integrated in the attribute shape. As already stated in the main text, the majority of wrong predictions are related to the arithmetic rule. For GPT-4, our new rule interpretations can explain 32 out of the 68 errors, while 36 errors remain unknown. Llama-3 70B showed many more errors in the arithmetic rule; here, we can explain 57 out of 142 errors with relational reasoning. In summary, some (40.1\u201347.1%) of the LLM's errors can be rooted in relational reasoning. Further understanding the behavior of the unknown rules is scope for future work."}, {"title": "Appendix A: Prompting details", "content": "This appendix provides more details on our prompting strategy. While the prompt design was mainly inspired by15, we extended it with predictive and discriminative classification and fine-tuned it for the different models. For example, we found that adding a prefix (\"Only return the missing number\") helped to slightly improve GPT4's accuracy, whereas it reduced Llama-3 70B's performance. Thus, we used individual prompts for the different models."}, {"title": "1. Joint attribute querying", "content": "As an alternative to individually querying the LLM for predicting the separate attributes, we also devised a joint attribute prompting scheme, shown in Fig. A.6. The attributes of each panel are represented in brackets: (shape, size, color). In this setting, the LLM is required to predict all three attributes of the missing panel at once. For better distinguishing between the different attributes, they are scaled with individual factors (1\u00d7, 0.1x, 10x)."}, {"title": "2. Discriminative classification approach", "content": "Fig. A.7 shows an example prompt for performing discriminative classification. As shown, the answers only contain two distinct values (\u201c6\u201d and \u201c7\u201d); finding the correct answer requires the consideration of all attributes. For choosing the final answer, we extract all attribute values that correspond to the predicted answer (e.g., value \"7\" for shape) and select the best matching answer candidate, i.e., the answer with the highest number of overlaps with the predicted attributes."}]}