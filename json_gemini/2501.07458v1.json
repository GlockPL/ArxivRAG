{"title": "Understanding and Benchmarking Artificial Intelligence: OpenAI's 03 Is Not AGI", "authors": ["Rolf Pfister", "Hansueli Jud"], "abstract": "OpenAI's 03 achieves a high score of 87.5% on ARC-AGI, a benchmark proposed to measure intelligence. This raises the question whether systems based on Large Language Models (LLMs), particularly 03, demonstrate intelligence and progress towards artificial general intelligence (AGI). Building on the distinction between skills and intelligence made by Fran\u00e7ois Chollet, the creator of ARC-AGI, a new understanding of intelligence is introduced: an agent is the more intelligent, the more efficiently it can achieve the more diverse goals in the more diverse worlds with the less knowledge. An analysis of the ARC-AGI benchmark shows that its tasks represent a very specific type of problem that can be solved by massive trialling of combinations of predefined operations. This method is also applied by 03, achieving its high score through the extensive use of computing power. However, for most problems in the physical world and in the human domain, solutions cannot be tested in advance and predefined operations are not available. Consequently, massive trialling of predefined operations, as 03 does, cannot be a basis for AGI - instead, new approaches are required that can reliably solve a wide variety of problems without existing skills. To support this development, a new benchmark for intelligence is outlined that covers a much higher diversity of unknown tasks to be solved, thus enabling a comprehensive assessment of intelligence and of progress towards AGI.", "sections": [{"title": "1 Introduction", "content": "The release of systems based on large language models (LLMs)\u00b9, in particular OpenAI's ChatGPT in 2022, caused intense and ongoing debates about the extent of their intelligence. For example, Microsoft, one of the stakeholders in OpenAI, stated that the successor model \"GPT-4 attains a form of general intelligence, indeed showing sparks of artificial general intelligence\" (Bubeck et al., 2023, p. 92). Further statements that LLM-based systems represent artificial general intelligence (AGI) or at least major progress towards it have been made by OpenAI and other prominent AI companies, but also by AI experts, and in the media. At the same time, others take a more critical perspective on the performance of LLM-based systems, attributing their success not to intelligence, but to other factors such as the vast amounts of training data and the extensive computing resources used. The discussion has recently intensified again with the success of OpenAI's latest model 03 on the ARC-AGI benchmark, where it achieved 87.5% on the semi-private test set; an achievement Chollet (2024) calls 'a genuine breakthrough, marking a qualitative shift in AI capabilities'.\nARC-AGI, originally called Abstraction and Reasoning Corpus (ARC), is designed as a benchmark for measuring general intelligence and was developed by Chollet (2019, pp. 46-58). In contrast to other benchmarks, ARC-AGI is not intended to measure the performance of an AI approach in a specific skill, but instead its ability to solve new, unknown tasks which it has not encountered before. ARC-AGI consists of 1,000 unique tasks, of which 800 are publicly accessible and divided into 400 training tasks and 400 evaluation tasks. The remaining 200 tasks are divided into two private test sets. They are kept confidential to ensure that neither the AI approaches nor their programmers can optimise for them in advance. One of the private test sets has been used as an undisclosed test set in various programming competitions since 2020, while the second one remains unused and confidential. In 2024, an additional semi-private test set with 100 newly created tasks was released to evaluate larger AI models that require API access and where the confidentiality of the test set can therefore not be guaranteed (ARC Prize, 2024).\nEach task consists of a small number of example pairs and one or more test pairs, with each pair consisting of an input and an output grid. Each grid can have between one and thirty cells in width and height, with the two dimensions being independent of each other. Each cell can be in one of ten possible states, usually represented by colours for easier interpretation by humans. In each task, all inputs are manipulated according to a task-specific rule, which results in the corresponding outputs. For instance, a rule can be that all cells of a certain colour have to be changed to a different colour, or that the input grids have to be mirrored horizontally. All rules are based only on core knowledge, that is fundamental human beliefs such as the existence of objects or basic algebraic and geometric principles. To solve a task, the task-specific rule has to be determined by analysing the example pairs and then applied to the test input(s) to generate the test output(s). A task is only considered solved if the submitted test output corresponds exactly to the correct solution in every single cell"}, {"title": "2 On the Nature of Intelligence", "content": "To be able to evaluate the occurrence of intelligence, it is important to understand its nature precisely. Human intelligence is explained by the Cattell-Horn-Carroll theory as an interaction between crystallised intelligence and fluid intelligence (Schneider & McGrew, 2018, pp. 73-75): Crystallised intelligence consists of several broad cognitive abilities, such as reasoning, processing visual information, and remembering information. Fluid intelligence is a general ability whose performance affects all broad abilities and describes the general cognitive capacity. In the field of AI, a variety of definitions of intelligence are used (Legg, Hutter, et al., 2007), which can be broadly categorised into two groups: Process-oriented definitions name required abilities such as learning, abstraction, logical thinking, and problem solving. Result-oriented definitions focus on the outcome and define intelligence as the ability to achieve specific goals; for instance, to adjust to an environment, to create products, or to grasp truths.\nTo determine whether an AI approach is intelligent, it is usually tested on tasks that fulfil the requirements of the definitions. In the course of the history of AI, numerous tasks were proposed whose solutions were assumed to require extensive cognitive"}, {"title": "3 Suitability of ARC-AGI as a Benchmark for AGI", "content": "Presenting o3\u2019s achievement on ARC-AGI, Chollet (2024) concludes: \u2019ARC-AGI serves as a critical benchmark for detecting such breakthroughs, highlighting generalization power in a way that saturated or less demanding benchmarks cannot. However, it is important to note that ARC-AGI is not an acid test for AGI.\u2019 Chollet (2024) therefore proposes to develop a new version of ARC-AGI, a \u2019next-gen, enduring AGI benchmark\u2019 in the same format. This poses the question to what extent ARC-AGI in its current form is suitable for measuring the capacity for broad generalisation, and to what extent and in what way it is possible to develop it further in the same format.\nARC-AGI is different compared to most other benchmarks in that it is not designed to measure how good AI approaches are in a particular skill, but instead in their ability to generalise (Chollet, 2019, pp. 4, 53f). To accomplish this, the test set is kept secret, the tasks are designed to be diverse, and each task has only a few examples from which to generalise. By limiting the required knowledge to core knowledge, the emphasis is not on the use of existing knowledge, but on the ability to abstract and reason.6 All these factors together place the focus on fulfilling the second interpretation of intelligence, i.e. the capacity to develop solutions for new, previously unknown tasks by means of generalisation. The minimalistic design of ARC-AGI tasks as simple, coloured grids, whose transformation can be described using core knowledge only, allow for easy development and testing of new AI approaches.\nHowever, the minimalist and specific design of the ARC-AGI tasks also represents a very specific problem structure for the following two reasons: First, to solve an ARC-AGI task, it is necessary to determine the most simple transformation rule"}, {"title": "4 Towards a New Benchmark for Intelligence", "content": "The limitations of ARC-AGI lead to the question of how a benchmark can be designed that can be used to measure intelligence and progress towards AGI. A noticeable characteristic of the ARC-AGI benchmark is that it appears to be subject to Goodhart's Law: 'When a measure becomes a target, it ceases to be a good measure.' This was evident in many places in the various ARC-AGI competitions. Instead of the approaches being developed towards AGI, they were developed to achieve the highest possible score on the test set: Core knowledge representations were optimised, ARC-AGI-specific skills were improved using artificially generated training data, and some participants submitted hundreds of approaches to probe and optimise for the test set. In order to avoid this, a future benchmark should have the greatest possible correspondence between the measure and the target, i.e. the development of (artificial) intelligence. To express it more directly: The best benchmark for intelligence is intelligence itself.\nConsequently, an ideal benchmark should rate an agent as the more intelligent, the more efficiently it can achieve the more diverse goals in the more diverse worlds with the less knowledge. While human intelligence tests tend in this direction, they do so only to a very limited extent: They use time as a measure of efficiency, age as a measure of existing knowledge, and test various goals in various domains. Altogether, however, the tests are neither precise nor very diverse, and to a large extent they measure skills instead of intelligence. This is not least because human intelligence tests are designed to predict human performance in the human domain.\nIn contrast, AGI, as a formal system, is neither bound to the human domain nor to the physical world. Instead, AGI can be given any type of goal which it has to fulfil in any type of world. These can be worlds that humans can access and understand, such as games, but also completely arbitrary worlds that can be simulated. For example, AGI can be situated in a simulation of a universe that is fundamentally different from ours. The universe could have more or fewer dimensions than ours, and fundamental aspects such as the laws of physics or the principle of causality could be altered. An AGI approach to be evaluated can be given any type of embodiment in such a universe or none as well as any type of goal to fulfil. The better and more efficiently it achieves the goals, the more it is rated intelligent.\nA concrete example of the outlined benchmark could look as follows: All the approaches to be tested have to solve tasks in ten different worlds; nothing is known about the worlds in advance. One such world could be for example a simulation of Mars. In this world, the AI approach is embodied in a Mars robot, for which it must first develop an understanding. The approach must then fulfil the task of building an accommodation for astronauts, for which it must develop an understanding of the physical conditions on Mars. Another world could be, for example, the simulation of a gas planet in a four-dimensional universe in which the approach has to produce a specific chemical element using an alien body. A further world could be simulated by"}, {"title": "5 Conclusion", "content": "The analysis of ARC-AGI has shown that it cannot serve as a benchmark for general intelligence and thus as a measure of progress towards AGI. Its simplicity, which makes it ideal for developing and testing new approaches, brings with it several weaknesses. Most importantly, the tasks have a very specific problem structure that allows the tasks to be solved exploiting a known problem representation without having to create one first, although this is often the more difficult part of solving problems. In addition, it enables a massive trialling of possible solutions, allowing a high score to be achieved by the massive generation of low quality solutions."}]}