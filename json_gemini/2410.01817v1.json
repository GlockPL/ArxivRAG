{"title": "From Experts to the Public: Governing Multimodal Language Models in Politically Sensitive Video Analysis", "authors": ["TANUSREE SHARMA", "YUJIN POTTER", "ZACHARY KILHOFFER", "YUN HUANG", "DAWN SONG", "YANG WANG"], "abstract": "This paper examines the governance of multimodal large language models (MM-LLMs) through individual and collective deliberation, focusing on analyses of politically sensitive videos. We conducted a two-step study: first, interviews with 10 journalists established a baseline understanding of expert video interpretation; second, 114 individuals from the general public engaged in deliberation using Inclusive. AI, a platform that facilitates democratic decision-making through decentralized autonomous organization (DAO) mechanisms. Our findings show that while experts emphasized emotion and narrative, the general public prioritized factual clarity, objectivity of the situation, and emotional neutrality. Additionally, we explored the impact of different governance mechanisms-quadratic vs. weighted ranking voting and equal vs. 20/80 power distributions-on users' decision-making on how AI should behave. Specifically, quadratic voting enhanced perceptions of liberal democracy and political equality, and participants who were more optimistic about Al perceived the voting process to have a higher level of participatory democracy. Our results suggest the potential of applying DAO mechanisms to help democratize Al governance.", "sections": [{"title": "1 INTRODUCTION", "content": "Recent advancements in Multimodal Large Language Models (MM-LLMs) have demonstrated significant progress in integrating and interpreting diverse data modalities, including text, images, audio, and videos [57, 95], enabling AI systems to perform complex tasks with human-like capabilities. Several studies have explored the use of LLMs for multimodal generation, primarily focusing on developing foundational MM-LLMs by integrating encoders from different modalities, allowing these models to process beyond textual inputs [39, 43, 82, 104, 104]. Some methods use pre-trained LLMs to build models capable of handling multiple modalities including LLaVA, mPLUG-Owl, Flamingo, BLIP-2, and"}, {"title": "2 RELATED WORK", "content": "In this section, we review related work in key areas of state-of-the-art video analysis, with an emphasis on political video. We then discuss emerging multimodal generative vision models, highlighting their limitations, followed by user preferences of multimodal LLMs, followed by a review of current AI governance approaches to discuss their limitations in practice, particularly regarding active involvement from diverse stakeholders."}, {"title": "2.1 Video Analysis in Practice", "content": "Video serves as a rich source of information for everyday communication [21, 50], leading to the development of tasks such as video captioning, video question answering [96], text-video retrieval [8, 12, 30]. Videos, offering dynamic and engaging content beyond static images and text, present a unique challenge for understanding and processing due to their redundancy. In video analysis, there are two different applications we are most familiar with - video summarization and captioning - that focus on extracting key frames or shots and generating descriptive summaries, respectively, with the latter serving as a textual encapsulation. Video summarization strives to identify a concise set of frames that convey the core content of video sequences. Initial efforts [14, 34, 102] focused on creating handcrafted video representations, like visual attention, in an unsupervised manner. Later developments include multimodal approaches, where works [65, 80] utilize textual information, such as video titles or related articles, to enhance key frame identification.\nIn video-language learning, identifying key visual content is important, yet challenging [15, 46]. Research shows a static appearance bias with single-frame training in video question answering and retrieval, highlighting challenges in grasping full video narratives. This limitation also affects video captioning, which requires understanding both visual and temporal aspects that single frames cannot capture. In real-world applications, these models face significant hurdles. Techniques ranging from LSTM-based temporal learning [87] to hierarchical visual feature compression struggle with the unpredictability and diversity of real-world videos [62]. The challenge intensifies with the need to generate coherent descriptions that align with the video's actual content, where models must balance visual details with semantic context [79]. Even strategies like strategic frame selection to reduce redundancy [22] can only partially address the mismatch between model capabilities and the nuanced requirements of real-world applications, highlighting the gap between controlled training environments and the complexity of real-world video content.\nA particularly active area of video research in political science is the analysis of debates in presidential elections. Researchers [42] used recurrent neural networks to analyze videos of debates in the 2016 U.S. presidential election and successfully detected facial expressions, emotions, gestures, and related movements [16, 17]. Political news videos"}, {"title": "2.2 Multimodal Generative Vision Models", "content": "Large Language Models (LLMs) as conversation agents are revolutionizing the way we engage with visual data. Prior conversation models engaged with images, but video-based dialogue remained largely unexplored. In particular, recent progress in multimodal understanding primarily involves integrating pre-trained image models with LLMs but generally do not consider video inputs [26, 47, 53, 104]. Recent advancements in computer vision have led to the development of numerous foundational vision-language models, resulting in significant breakthroughs in the field. A notable example is CLIP, trained on 400M image-text pairs, which has shown impressive zero-shot performance on various benchmarks [66]. CLIP has been applied in numerous downstream applications, ranging from object detection to 3D applications [13, 49, 58, 68], as well as adapted for video applications [58, 67, 89]. More recently, multimodal understanding has been advanced by integrating image-based vision models with LLMs. Models like Flamingo [7] and BLIP-2 [47] have demonstrated the power of utilizing web-scale image-text data. MiniGPT-4 [104] facilitates image-based conversations by combining BLIP-2 and Vicuna for zero-shot image comprehension. LLaVA has shown notable multimodal chat capabilities [53], and the InstructBLIP model [26] has demonstrated strong image-based dialogue capabilities. Some recent work instead focused on leveraging LLMs for video comprehension, aiming to preserve spatial and temporal features while enabling human-like discussions about videos [55] by introducing Video-ChatGPT, a model combining a video-optimized visual encoder [24, 66] and an LLM [53], filling this gap [55, 86]. Another work VideoChat [48] combines video and image model elements with LLMs, using minimal learnable layers, and creates a video-dedicated dataset with noisy detailed textual descriptions to refine video conversation model training."}, {"title": "2.3 User Preferences and Multimodal Generative Model", "content": "Before the emergence of Large Language Models (LLMs), the idea of augmented reporting was already in use, leveraging technologies like artificial intelligence, machine learning, and data analytics to assist journalists in collecting, analyzing, and presenting information [63]. This approach improves the speed, precision, and depth of media coverage while revealing hidden patterns and trends. For instance, journalists could use data analytics tools to uncover new angles in large datasets. More recently, LLMs have been applied in media, entertainment, and journalism, especially in contexts that support ideation by alleviating the cognitive load on journalists [64]. These models are also utilized in co-writing scenarios, where the input of LLMs may shape public opinion [41], particularly in text-driven media. Further studies have benchmarked LLMs for tasks like news summarization [101]. Additionally, experts are exploring the societal and democratic implications of generative AI in journalism and media, discussing regulatory strategies to ensure its democratic use worldwide [9, 59].\nThe scope of Multimodal LLMs (MM-LLMs) extends beyond journalism and creative fields to sectors like media, education, surveillance, training, and healthcare. These models support individuals with disabilities, including popular visual models designed for people with visual impairments. Visual models addressing image and video privacy and security concerns help blind users navigate video-based media [75], while some explore their experiences as vloggers [33,"}, {"title": "2.4 Al Governance Approaches", "content": "Al governance concerns putting values or principles into practice via policies, while values define what agents (people or AI) ought to do [76]. Researchers have argued that the research community broadly agrees about certain values and principles for better AI [29], though the question of how best to implement these principles is far from solved, and proceeding at different paces, in fits and spurts, around the world.\nRegulatory Effort. Historically, much of the focus in Al governance research has been at the national and subnational levels [19, 31, 70]. US efforts in Al governance currently focus on executive actions and industry collaboration. Executive Order 14011 \"on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence\" (AI Executive Order) [84] highlights the dual nature of Al's potential, stating that while AI can address critical challenges and enhance prosperity, productivity, innovation, and security, it also entails risks that require careful regulation. The U.S. approach to Al governance aims to ensure both safe and ethical AI development while achieving national strategic goals. In the short term, the U.S. is working with Al developers and other stakeholders to establish standards and guidelines.\nExecutive Order 14011 - like the more ambitious EU AI Act [2] - directs an assortment of actors to participate in the standardization of AI development and deployment. Standards are formal documents that guide organizations in achieving specific goals such as interoperability, safety, or regulatory compliance. They provide a common language and practical guidelines for ensuring the safety and auditability of technical systems [90]. The most rigorous standards are intended to facilitate third-party audits and certification, signaling good and trustworthy practices [69]. At present, however, the two available AI standards from NIST (AI Risk Management Framework [60]) and ISO (ISO 42001 \u0391\u0399 Management System [40]) are not auditable and not yet rigorously tested.\nParticipatory approaches. Driven by calls from civil society organizations, academia, and others, there is growing emphasis on participatory Al governance to make AI/ML design more inclusive and equitable [99, 100]. However, there is limited empirical literature on involving stakeholders in refining Al performance. Both in theory and practice, there exists a tension between the goal of participatory decision-making in AI and the global, distributed nature of AI development [99]. Kemp et al. [27] and some researchers advocate for decentralized approaches, such as \u201cGovernance Coordinating Committees,\" global standards, or leveraging existing international legal frameworks [25, 54, 88]. The strategy presented in this paper, leveraging DAO for voting, is one potential strategy to address this.\nCurrently, due to cost considerations, much Al refinement and training, including reinforcement learning, rely on labor pools in developing countries rather than direct involvement of stakeholder groups [71?]. This dynamic presents a significant challenge, though not an insurmountable one, in ensuring meaningful participation on a suitable scale in AI development [99]. In designing AI models, it is essential to involve stakeholders and affected communities, along with Al companies, to deliberate on sensitive AI-related topics and make informed decisions about Al model behavior. However, another difficulty is establishing the best role for AI to play in group decision making [103].\""}, {"title": "3 METHOD OVERVIEW", "content": "Given the above literature, it is evident that while significant progress has been made, there is a clear gap in understanding expert and user perspectives on MM-LLM outputs to address their contextual needs, as well as the influence of governance structures on these interactions. As shown in Figure 1, our entire study includes (1) an expert interview (RQ1); and (2) a user experiment (RQ2 & RQ3) in deliberating users' values and expectations as well as preference aggregation"}, {"title": "4 EXPERTS' OPINIONS INFORMING THE EXPERIMENTAL SETUP", "content": "We interviewed media scholars and journalists as our expert reference group due to their experience with various data types, including text, images, and videos, particularly analyzing complex and sensitive topics, like US presidential debates. We recruited US-based experts through personal connections and word of mouth. Experts in this study come from diverse backgrounds in journalism, media, and communication, with an equal split between males and females. Among them are Ph.D researchers specializing in media studies in urban design, and political economy, journalist focused on video media who had experience in the 2020 election coverage; medical misinformation within local communities and journalists and videographers who have covered Tesla, police issues, and local TV media, offering a unique blend of skills and perspectives. We refer to experts as E1,...,E10. For the purpose of their anonymity, we do not include their news media agency name and affiliations in this paper."}, {"title": "4.1 Recruitment and Experts Background", "content": "Our two primary objectives of the experts' interview were: (i) to have a baseline of how experts envision the use of MM-LLMs for interpreting political videos to the general public and (ii) to incorporate expert feedback into the development of our methodological approach, including criteria for selecting video examples for the study."}, {"title": "4.2 Phase I: Experts' Interview", "content": "In the first set of questions, we inquired about their primary expertise and experience with various data types, including video. This helped us understand their approach to handling different media, covering real-time events, managing diverse data for tasks like media report writing, and the factors that influence the quality of their reporting.\nIn the next set of questions, we showed them a political video of US presidential debate and asked them to interpret it using multimodal data (e.g., audio, visuals, closed captions). We asked, \"Can you walk me through the process you employ to analyze the video content to write a report?\" Following this, we asked their opinion on using LLMs for video analysis We then showed them how LLMs (ChatGPT) interpreted the same video and asked for their thoughts to identify the benefits, limitations, and critical factors in interpreting contentious topics.\nSince we aim to understand the general public's perception of the use of MM-LLMs in better designing models for sensitive topics, such as political content, selecting politically sensitive content for the study requires careful consideration. We leveraged experts' opinions to conform to the inclusion criteria for selecting content (details in section 4.4.1) by providing them with an overview of the user study goal. We also asked them how they would prompt the LLM tool to interpret this video. We leveraged experts' feedback to design the deliberation case (details in section 4.4.2)."}, {"title": "4.3 RQ1: Experts' results: Experts Practices, Perception, and Video Interpretation", "content": "In this section, we present practices by journalists and media scholars in handling multimodal data for media generation, their interpretation of political videos, and their opinion of LLM's (ChatGPT's) interpretation of political videos."}, {"title": "4.3.1 Practice of Evaluating Multimodal Data in Journalism", "content": "We identified several practices in video interpretation of experts that involve multimodal data. Experts consistently highlighted the routine management and analysis of multiple data sources. To illustrate some of these workflows and practices, we present three approaches used by journalists covering refugee and environmental issues, weather news, and political campaigns-related events. While there are fundamental similarities among these approaches, there are nuanced differences in their emphasis: (i) focusing on the reliability and credibility of meta-information sources, particularly for sensitive topics; (ii) consulting experts continuously during news production; and (iii) adopting a research-oriented approach for news generation."}, {"title": "Fact-Checking: Separating Truth from Tall Tales", "content": "Experts who work with multiple data sources emphasize the importance of fact-checking reliability. In Figure 2, E5, a journalist specializing in weather and political news, describes her approach. She collects data from various sources, including online images and videos, TV media like Fox and Stan Newsroom, and social media. For weather trends, she starts by reverse-searching images and videos to confirm reliability. She then evaluates TV news sources' credibility based on media literacy project [6]. For political news reporting, she considers fact-checking crucial and often consults additional sources like MSA Security [5] to add another layer of credibility. E5 emphasized on information source credibility by stating, \u201cEven when you speak the truth, people can still question it and label it as fake news, which is a significant issue.\""}, {"title": "Experts-in-the-Loop News Production Approach", "content": "In Figure 7(a), an environmentalist and political economy journalist described his approach as \u201cI investigate the emissions of local craft factories using data and expert interviews. I video recorded the process, then clean and analyze data, draft a comprehensive report, and ensure accuracy through rigorous editing and fact-checking, most frequently connected with seniors or professors in this field.'"}, {"title": "News Generation 101: Narrative Approach", "content": "In Figure 7(b), a media scholar explained his approach as narrative journalism. He focuses on creating engaging, story-driven content about the environment in Jordan. He builds compelling narratives around key individuals, such as refugees, using various types of data, including video recordings, interviews, and observations. Describing his method, he shared: \"We visited factories and local refugee areas, taking videos and images of workers in production, interacted with them. The final product was a community environment model of greenhouses, and water plants. our target was to demonstrate to policymakers in that region or internationally through a routine walkthrough so its important that the story is understood.\""}, {"title": "Theoretical Underpinning: Position, Pick, and Spin", "content": "Experts also highlighted some theoretical underpinnings relevant to news and media report generation. One key factor is positionality, which involves journalists' awareness of how to structure their report, incorporating personal views or the new agency's stance, supported by evidence and reasoning. As E4 noted, \u201cI will have my own ideologies or media agencies ideologies may affect my choice of language, like one political party prefers to use 'global warming' while another prefers 'climate change' due to different underlying reasons\" In the context of LLM applications, such as analyzing U.S. political debates, scholars recognize that biases in LLMs like ChatGPT reflect similar biases in journalistic writing.\nAnother phenomenon discussed is selective exposure, where video creators and journalists may focus on information that aligns with pre-existing beliefs, potentially reinforcing certain perspectives. This is particularly relevant in political reporting, as E9 noted \"If the people making news based on presidential video focusing on Joe Biden's political agenda, they may gather more information to support him, making him appear more persuasive. Making videos is indeed an effective way to persuade others.\" Given these biases, experts suggested to select videos for the user experiment that present diverse viewpoints, ensuring a balanced representation of political perspectives."}, {"title": "4.3.2 Experts' Interpretation of the Political Video", "content": "While interpreting the political video clip, experts focused on various aspects such as emotion and sentiment, aiming for a neutral interpretation; highlighting key points without covering everything; providing background information and evaluating the strength of arguments; fact-checking; and analyzing body language and theatrics. Some noted that the focus often shifts to the target audience, sensational topics, and distractions, rather than the content itself. El's interpretation of the video - \"Candidate disagreed and picked on others and expressed emotion and Trump argued back with repeated refutation words but involved higher emotion. He totally disagreed with Biden's and even moderators's statements and questions. They have opposite stands. Trump is just saying negative and he doesn't agree with anything the opposite speaker said.\" E3 mentioned how she would present the video"}, {"title": "4.3.3 Experts' Opinion on Political Video Interpretation by Al", "content": "Experts provided various perspectives on ChatGPT's interpretation of political video. E2 highlighted the lack of human interaction cues, such as tone and emotion, in the summary. They pointed out that the absence of contextual information, such as background knowledge about political debates, detracted from the summary's utility for news content. E3 noted that while the summary was factually correct, it missed the antagonistic and dramatic elements of the debate, including conflicts, personal attacks, and the candidates' lack of factual references. They criticized the summary for lacking storytelling and engagement, making it unsuitable for a diverse audience. E7 found the summary helpful for laypersons but was uncertain about its bias or accuracy. They mentioned that the fast pace of the debate made it challenging to follow, especially for those unfamiliar with political agendas. Despite acknowledging potential biases, E7 believed that the summary aids laypersons in understanding the content, however, it lacked the depth and engagement necessary."}, {"title": "4.3.4 How Experts Would Prompt to Analyze the Video?", "content": "Experts suggested various ways they would prompt ChatGPT to analyze a presidential debate. Most would start with a general question like, \u201cCan you help me to summarize what they are talking about?\u201d E1 mentioned that she would first ask for a summary and then follow up with, \"If I get the output, I might ask something else.\u201d Similarly, E2 would prompt, \"Provide a summary of the videos and the point of each person in this content.\" Two experts, like E3, preferred more detailed instructions, saying, 'Give me a short news brief about the presidential debate between Trump and Biden about health care policy and Obamacare. Also, capture some of the tough visual aspects, describe some of the back-and-forth banter between the moderator and Trump, and the personal attacks where people can't get a word in.\" E6 would ask meta-questions to utilize ChatGPT in a journalism context: \"I normally wouldn't use ChatGPT to analyze only one video unless I have a hundred. I would want to see patterns across videos. I would ask it to analyze how many times there are interruptions, how long candidates talk over each other, and other specific metrics.\u201d\""}, {"title": "4.4 Phase II: Experiment Setup", "content": "We utilized experts' feedback as a baseline for designing the seed use case in this study. This involves using specific prompts to generate video interpretations from ChatGPT and use the video example and ChatGPT's interpretation to elicit users' values."}, {"title": "4.4.1 Video Selection Criteria", "content": "For selecting videos, we ensured relevance to the research questions, diverse viewpoints, and high-quality content in designing user experiments.\nSelection of AI Value Topic. Our study aims to explore user norms and expectations regarding the ability of Large Language Models (LLMs) to handle sensitive and complex topics, with a specific focus on political content. First, political topics are widely followed and discussed, involve intricate interactions, and are closely tied to both global and"}, {"title": "4.4.2 Users Deliberation and Decision Making on their Values and Expectation", "content": "To engage users at scale in expressing their preferences to decide on future MM-LLM model development, we first designed a tool (Inclusive.AI, details in section 4.5) that incorporates deliberation and decision-making mechanisms. This tool first guides users to elicit their values and expectations for LLM outputs on sensitive topics through individual and group deliberation. We then facilitated a platform within the tool for users to actively share their preferences with certain powers that can influence how MM-LLM should function in the future.\nAI Guided Individual Deliberation. We begin by engaging users with an AI Value Topic related to multi-modal data interpretation of a video on a political topic by chatGPT. This topic is based on a 6-minute clip from the 2020 US presidential debate 1. We started with a seed video and generated a response of ChatGPT, as shown in Figure 3. Users are presented with a simple question: \"Do you find the interpretation useful?\" with three options (yes, no, maybe) to stimulate further thought. Based on the user's response to the provided options, the AI interviewer (agent) continues the corresponding chat. All chats sent by the user on this human-AI individual deliberation screen are aggregated as dialogues for GPT-4 API calls while we feed the user's current chat and the history of the user's chats into GPT-4 for a natural conversation flow in the human-AI deliberation phase.\nThis human-AI deliberation allows users to clarify their intentions and values as the Al agent engages them in natural-language conversations about AI value topics. The agent recursively resolves ambiguities and vagueness through multi-turn conversations, seeking clarifications and guiding users to define their norms and expectations. This individual deliberation provides open-ended interactions of users' norms, values, and preferences regarding video interpretation by ChatGPT (Figure 3)."}, {"title": "Group Deliberation to Co-Validate Norms", "content": "Users then engage in a group deliberation and learn the perspectives of others' norms. The group deliberation has a chat box that facilitates live-time chats through websocket connections. This group deliberation enables users to co-validate their values at scale with a mini-public to make informed decisions, aiding the next step of democratic governance decision-making. If participants are unable to introduce a topic on their own, they are encouraged to refer to the suggested topics provided by the tool. We designed the suggested topic based on the pilot experiment of 20 participants, including, AI-generated video interpretation could be clearer, more comprehensive, more objective, or more in-depth (interface designs are in Appendix figure 8). This group discussion design provides a set of user interactions that depict their norms, values, and preferences while discussing with others."}, {"title": "Democratic Decision Making for Future MM-LLM Model", "content": "Finally, users participate in a democratic decision-making process by voting. We designed experiments to assess varying voting methods and combinations of voting power to examine users' perception of the quality of the process being democratic. For example, we manipulated factors such as voting methods (weighted ranking voting vs. quadratic voting) and voting token distribution (equal distribution vs. 20/80 Pareto distribution). Governance decision provides perceived quality of the governance process by users' self-reported quality with the Variety of Democracy (V-Dem) scale [51]. We described the user experiment design in Section 4.4.3."}, {"title": "4.4.3 User Experimental Design", "content": "We designed our experiment for democratic decision-making using various voting systems. The independent variables are different DAO configurations, while the dependent variable is the participants' perception of the process's democratic quality. We employed a between-subject design, with participants experiencing four different conditions\nExperimental Conditions Design & Rationale All participants engaged in both group and individual deliberation before being randomly assigned by the Inclusive.AI system to one of four governance decision-making mechanisms, forming four treatment groups. Participants didn't know the treatment group to which they had been assigned. We employed a 2 * 2 between-subjects design with 114 participants (26-30 per condition). Participants voted on four MM-LLM model update options derived from 20 pilot studies for political video interpretation: (i) keep the current model; (ii) provide more specific facts; (iii) integrate a user feedback loop; (iv) analyze speakers' emotions and sentiment (as shown in Figure 9 in Appendix)."}, {"title": "Treatment Condition", "content": "We designed the treatment condition based on two factors: voting method and voting power in governance decision-making and two levels for each of the factors. For the voting method, weighted ranking and quadratic voting were two levels and for voting power, equal distribution of power and 20/80 (Pareto distribution) were two levels. Thus, there were four treatment conditions- (1) Quadratic Voting token-based (Participants having the same amount of token/voting power); (2) Quadratic Voting 20% population get 80% of the token as early adopters; (3) Weighted voting Token based (participants having the same amount of token/voting power); (4) Weighted voting 20% population get 80% of the token as early adopters. The goal is to evaluate how different treatment conditions, specifically varying voting methods and combinations of voting power, influence users' perception of the process's democratic quality."}, {"title": "Voting Method and Voting Power", "content": "We implemented weighted voting, commonly used in DAOs [73], where users can distribute their voting power across multiple choices based on the weight of their preference. However, traditional democratic aggregation may disfavor strong minority views, so we incorporated quadratic voting, which enhances minority influence on crucial issues by allowing users to \u201cpay\u201d for additional votes. For instance, with quadratic voting, 4 tokens provide 2 votes, emphasizing the number of voters rather than voting power size [45]. This method is particularly beneficial for minority groups who may lack many tokens. Additionally, we addressed voting power distribution. Traditional equal distribution might overshadow minority opinions, so we explored differential power distribution using the Pareto distribution. This approach is relevant for AI features that disproportionately benefit minority groups. By combining equal distribution and a 20/80 power distribution [10], we aimed to evaluate participants' perceptions of fairness in different democratic aggregation methods."}, {"title": "4.5 System Design", "content": "Inclusive. Al democratic platform (Figure 4) encompasses functionalities from user registration and interactions to voting on AI model update proposals and completing surveys, facilitated through a web application. This application is deployed in the Optimism blockchain. This platform is integrated with a custom server and utilizes Web3Auth [32] an authentication service that generates a unique Multi-Party Computation (MPC) wallet for each user, derives the user's blockchain address, and enables the authentication of messages, confirming user participation in votes.\nFrom the user's end, they begin by logging into the Inclusive.Al app using email SSO via Web3Auth. Web3Auth returns a payload containing the user's email address and a unique public key assigned by Web3Auth for the app. When the user signs up, the user's email address, appPubkey, and derived address are sent to the server for storage on the database. Upon signing up, users are directed to an introduction video page, which provides a 2-minute overview of the task details and app functionality. After watching the video, they proceed to the next steps of Human-Al liberation group discussion. The individual and group discussion page has a chat box that facilitates live-time chats through websocket connections.\nFor the voting page, we have implemented two VoteToken contracts using Solidity-a programming language optimized for the Ethereum blockchain-to represent users' voting power. Upon allocation, these tokens are minted to users' accounts, allowing them to vote on proposals. Our voting system leverages the Snapshot API [3], commonly used in DAOs for off-chain governance, to ensure a transparent voting process. This system is structured around three principal components: spaces, proposals, and votes. Organizations (this can be AI actors, independent entities) create spaces as dedicated areas where they can appoint admins, and moderators, and establish specific voting rules and proposal guidelines. This includes criteria for who can vote, propose, or moderate, and the number of votes required for a proposal to pass. We have designed the spaces for each experimental condition (each type of governance decision mechanism discussed in section 4.4.3). When the user allocates votes accordingly and clicks the \"Cast Vote\" button (in"}, {"title": "4.6 Data Analysis", "content": "Study data were obtained through Inclusive.AI tool from individual deliberations with the AI agent, group discussions, user voting, and a survey on the users' experiences with the DAO governance process in the Inclusive.Al tool. For qualitative data, two researchers independently read through 20% of the individual deliberation with AI-agent and group discussion data, developed codes, and compared them until we developed a consistent codebook. We met regularly to discuss the coding and agreed on a shared codebook. Once the codebook is finalized, two researchers divided the remaining data and coded them. After completing coding for all individual and group deliberation, both researchers spot-checked the other's coded transcripts and did not find any inconsistencies. Finally, we organized our codes into higher-level categories. We followed an open coding and deductive analysis method to explore participants' values, expectation towards MM-LLM video interpretation. We grouped lower-level codes into sub-themes and further extracted main themes. For the quantitative analysis of users' perceptions of DAO governance mechanisms, the data analysis process is explained directly within the respective results (section 6)."}, {"title": "4.7 Participants & Recruitment", "content": "We recruited participants who are USA residents. We recruited through the CloudResearch platform 3. This study protocol involving human subjects was approved by the Institutional Review Board (IRB). We used a set of screening questions to recruit targeted participants. Respondents were invited to our study if they met all"}, {"title": "4.7.1 Participant Recruitment", "content": "Our study resulted in total of 114 participants. Out of our 114 participants (Table 1), 42.6% self- identified as men, and 45.6% as women. The majority of the participants (39.47%) were in the age range of 25-34, followed by 27.19% were 35-44 years old, 21.05% were 18-24 and 12.28% were 45-54 years old. The participants were from USA. 41.22% participants had bachelor's degree, 26.32% participants were holding some college or vocational training, 14.04% had high school or equivalent, etc. 35.08% self-identified their political orientation as somewhat liberal, followed by 22% moderate, 21.05% some conservative, 15.78% very liberal, 5.3% very conservative. Majority (50.87%) leans towards democrat party, 24.56% were independent / unaffiliated, 21.92% were republic party and 2.63% was libertarian party. All participants used several generative AI tool, including ChatGPT, Gemini, etc."}, {"title": "4.7.2 Participant Demographics", "content": "In this section, we present various factors participants considered important in balancing the generated outputs by MM-LLMs. In group deliberation, we found that participants articulated their arguments in longer sentences, while in human-AI chats, the conversations were shorter. However, in both types of interactions, there are overlapping values emerged regarding MM-LLM model development. Participants identified different factors they considered important when interpreting video content with analyzing multiple types of data."}, {"title": "5 RQ2: FACTORS CONSIDERED BY USERS IN GENERATING VIDEO INTERPRETATION BY MM-LLMS", "content": "Participants tend to have contradictory and diverse perspectives in the interaction flow for similar topics during group deliberation. For example, when a participant started a conversation by saying that \"Fact-checking is desirable,\" we observed not all the participants completely agreed but provided different thoughts and reasoning behind those preferences and values they had. We have distilled their interaction into several talking points. In this section, we present plural views of those talking points by participants. There are the following five main talking points.\nEmotion of the Speakers Participants frequently discussed quality of video analysis in terms of nuanced components, such as, speakers' emotion. This includes the interaction between speakers, natural flow of conversation, expressions during debates, and antagonistic aspects of the video. One participant noted, \"There was a heated argument in video, both speakers didn't want to give way for other to speak.\" Another participant added, \u201cIt doesn't understand human emotion like Trump and moderator were talking like they were fighting. It's not in the generated response.\u201d\nOn the other hand, some participants appreciated the separation of emotion from the video summary. One participant commented, \"I thought the info was great, especially as others reported, the ability to get beyond the arguing. As it improves, AI will be great for our tired, hard of hearing, overworked, attention-deprived society.\" Another participant suggested that it could be helpful if AI separated out their statements into individual segments since the speakers were talking over each other for most of the video. Some participants believed that making the emotion explicit would help people with different abilities, such as vision and hearing, to better understand the context. One participant remarked, \"I also agree"}, {"title": "5.1 User' Collective Values", "content": "that it was surface-"}]}