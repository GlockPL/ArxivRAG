{"title": "HySem: A context length optimized LLM pipeline for unstructured tabular extraction", "authors": ["Narayanan PP", "Anantharaman Palacode Narayana Iyer"], "abstract": "Regulatory compliance reporting in the pharmaceutical industry relies on detailed tables, but these are often under-utilized beyond compliance due to their unstructured format and arbitrary content. Extracting and semantically representing tabular data is challenging due to diverse table presentations. Large Language Models (LLMs) demonstrate substantial potential for semantic representation, yet they encounter challenges related to accuracy and context size limitations, which are crucial considerations for the industry applications. We introduce HySem, a pipeline that employs a novel context length optimization technique to generate accurate semantic JSON representations from HTML tables. This approach utilizes a custom fine-tuned model specifically designed for cost- and privacy-sensitive small and medium pharmaceutical enterprises. Running on commodity hardware and leveraging open-source models, our auto-correcting agents rectify both syntax and semantic errors in LLM-generated content. HySem surpasses its peer open-source models in accuracy and provides competitive performance when benchmarked against OpenAI GPT-40 and effectively addresses context length limitations, which is a crucial factor for supporting larger tables.", "sections": [{"title": "Introduction", "content": "Tables are a fundamental method for presenting structured information across various industrial applications, including regulatory information in the pharmaceutical industry and financial reports for businesses. Some shared characteristics and inherent challenges in tables as mentioned by (Fang et al., 2024) include Heterogeneity (Borisov et al., 2023), Sparsity, Context-based interconnection (Liu et al., 2023), Lack of prior knowledge (Borisov et al., 2023), (Borisov et al., 2024), etc. Recent advancements in Large Language Models (LLMs) have shown promise in addressing these challenges for various table related tasks. Some table related tasks and techniques include entity matching and data-imputation (Li et al., 2023), (Korini and Bizer, 2023), tabular Q&A (Chen et al., 2024), schema augmentation (Narayan et al., 2022), Serialization (Yin et al., 2020) (Yan et al., 2024), Table Manipulation (Zhang et al., 2024), Table Understanding (Lobo et al., 2023), Prompt Engineering (Zheng et al., 2023), Table RAG (Sundar and Heck, 2023). Role-play (Zhao et al., 2023).\nIn typical companies, the vast knowledge contained within these tables often remains untapped for actionable insights due to the lack of effective tools and methodologies for extracting and interpreting the tabular data. For instance, documents related to regulatory compliance, such as Annual Product Quality Reviews (APQR), fulfill compliance requirements but are rarely utilized beyond their initial purpose. To leverage the abundant resources of knowledge present in tabular form and stored in various formats like PDF, Word or HTML it is essential to have an accurate extraction system that transforms the content in to a semantically meaningful format. Several works have investigated the LLM's performance for different input tabular formats such as JSON formats (Singha et al., 2023), HTML tables (Sui et al., 2024), Markdown (Narayan et al., 2022). Accurate semantic representations of tables in a structured form allows automated processing and that can significantly aid the downstream processes, particularly those that use Large Language Models (LLM) as a key component of their workflows. Extracting complex tabular data from semi-structured sources and providing a semantic representation is a hard problem due to the lack of any standards in tabular data representations. This results in a huge diversity and arbitrariness in the way real world tables are presented. The language understanding ability of LLMs and their proven results present an immense opportunity to develop semantics driven represen-"}, {"title": "Method", "content": "Our proposed LLM Pipeline, HySem, aims to address the challenge of converting unprocessed raw HTML tables into a semantic JSON data structure while addressing the limitations of LLMs concerning context length and inference time. By adopting a novel strategy for optimizing the number of tokens, we aim to meet industry standards for high accuracy and reduced inference time, particularly for regulatory compliance reporting. Our approach utilizes open-source LLMs with fewer than 10 billion parameters, suitable for running on commodity hardware.\nHySem achieves these requirements through a structured pipeline composed of three components: Context Optimizer Subsystem (Aco), Semantic Synthesizer (Ass), Syntax Validator (Asv). Aco employs a novel pre-processing methodology for optimizing the context window utilized by HTML tables, enabling processing of large tables. Ass utilises an LLM for transforming this optimized HTML table into semantic JSON. Asy dissects the generated JSON for any syntax errors and outputs a syntactically-valid JSON."}, {"title": "Context Optimizer Subsystem", "content": "The limited context size of large language models significantly constrains their ability to effectively process extensive tables. Although models with extended context lengths can alleviate this issue, they may sacrifice accuracy and increase processing times due to the quadratic complexity of self-attention mechanisms (Tay et al., 2022) (Vaswani et al., 2017). Recent advancements in Transformer architectures, such as Linformer (Wang et al., 2020) and Flash Attention techniques (Dao et al., 2022), have shown improvements in memory and time complexity. However, the necessity to reduce sequence length remains a fundamental challenge.\nSignificant token inefficiency can occur when there is a misalignment between the tokenizer's vocabulary and the domain-specific terminology in the input text. For example, the term \"Amoxycillin,\" a common medication in pharmaceutical literature, is not part of the Llama 3 tokenizer's vocabulary. As a result, it is represented by multiple tokens, thereby reducing token efficiency. This issue is further illustrated with the term \"Potassium Clavulanate,\" which tokenizes as ('Pot', 'assium', ' Cl', 'v', 'aul', 'an', 'ate'), resulting in seven tokens."}, {"title": "Encoding Phase", "content": "In the encoding phase, we begin with a preprocessing step where we remove tags and attributes from the HTML tables that do not contribute to semantic understanding, such as those meant for styling. This is followed by a minification step to further reduce the input size. By eliminating non-essential elements, we streamline the input data, making it more manageable for subsequent processing. A tokenizing step tokenizes the contents of each cell in the table. A cell may be empty in which case there are no tokens. A non-empty cell may transform to one or more tokens.\nThe goal of encoding is to arrive at representing the cell contents using a minimal set of tokens while ensuring a unique representation for each distinct cell content. The encoded inputs result in a valid HTML table with cell contents rewritten to require fewer tokens. A mapping table is maintained to track the original cell content and its optimized counterpart, facilitating later restoration. The encoded input is processed by the downstream modules in the HySem pipeline, including the Semantic Synthesizer and the Syntax Validator.\nCollision Resolution: In the process of minimizing token sequences for efficient encoding of each cell content, it is possible for two distinct cell contents to map to some overlapping token sequences. To ensure each cell content maintains a unique representation, our method includes a collision resolution mechanism. The cell contents \"4/8\" and \"4/4\" in Figure 3(a) tokenize into [\"4\", \"/\", \"8\"] and [\"4\", \"/\", \"4\"], respectively, with the token sequence [\"4\", \"/\"] overlapping in both. After collision resolution, \"4/8\" is represented by the token sequence, [\"4\", \"/\"] while \"4/4\" transforms into [\"4\", \"/\", \"4\"], thus ensuring a unique representation as depicted in Figure 3(b)."}, {"title": "Decoding Phase", "content": "In the decoding step, the output from the downstream processing is decoded to restore the original lexicon used in the table. This decoding step reverses the earlier encoding which is present in the model generated JSON, reconstructing the output to match the original input while retaining the benefits of the token optimization. The resulting JSON is both semantically accurate and more efficiently"}, {"title": "Semantic Synthesizer", "content": "HTML tables are highly varied and arbitrary in nature, featuring elements such as row spans, column-spans, multi-level headers, nested tables and diverse data types. These intricacies make it challenging to accurately extract hierarchical and relational structures. Motivated by the LLM's capability to comprehend deep semantic relationships, HySem adopts the open-sourced Meta-Llama-3-8B-Base model and fine-tunes it with a manually labeled dataset for transforming HTML tables into semantic JSON.\nConcretely, the Semantic Synthesizer Ass accepts a HTML table Hi pre-processed by the Context Optimizer, as input and produces JSON J\u00a1 as the output in the same encoded semantic space as the pre-processed input HTML table. Our initial experiments indicate that adopting Prompt Engineering to achieve this transformation results in the generation of less accurate JSON representations, as evidenced by our intrinsic and extrinsic evaluations. We found that the LLM is highly sensitive to prompts and struggles to effectively capture the wide variety present in these tables. We identified several common failure patterns present in the JSONs generated by the LLM, which are cataloged as Failure Modes in Table 2."}, {"title": "Dataset", "content": "For our dataset, we require inputs as HTML tables and labels as semantic JSON. We utilize the following two open-sourced datasets for tabular HTML sources:\nPubTabNet: PubTabNet (Smock et al., 2022) is a large-scale dataset for image-based table recognition, containing over 568,000 images of tables from scientific papers along with their corresponding HTML annotations.\nFinTabNet: FinTabNet (Zheng et al., 2021) is a dataset specifically designed for recognizing tables in financial documents, containing over 112,000 tables. Each table instance annotation includes fields such as the HTML structure and bounding box coordinates, similar to PubTabNet.\nFor our purposes, we extract the HTML from these sources and manually curate annotations for these tables. We filter tables that fit within the LLM's context length (8k context window for Llama3). We randomly select and pre-process 1,364 HTML tables from both PubTabNet and FinTabNet using our Context Optimizer and manually curate corresponding JSON annotations. We split the data into 756 training samples and 608 testing samples. This dataset is used to train the Semantic Synthesizer. We chose these datasets as they are public and they are reasonable representations of the Pharmaceutical and Finance verticals respectively.\nWe also created hand labeled datasets to address the custom needs of the industry using the proprietary customer supplied data. These proprietary datasets are used to fine-tune models that use Semantic Synthesizer LLM as the base model."}, {"title": "Fine-tuning", "content": "We fine-tune the LLM in two stages. In the first stage, we utilize the open-sourced datasets discussed in the previous section, for fine-tuning our model. In the second stage, we manually curate JSON annotations for 130 randomly chosen tables from our proprietary APQR dataset and further fine-tune our model."}, {"title": "Syntax Validator", "content": "Syntax errors in the LLM-generated JSON output render the table unusable for further table process-"}, {"title": "Evaluation Methodology", "content": "For the accurate transformation of HTML tables into semantic JSON, two key objectives must be satisfied. First, content preservation: all strings from the HTML table cells must exactly occur in the JSON output, ensuring no information is lost during the conversion. Second, semantic accuracy: the generated JSON must accurately represent the hierarchical and relational structure of the original HTML table.\nBuilding on this foundation, we develop intrinsic and extrinsic evaluation methods to measure the content and semantic accuracy of the JSON produced by HySem."}, {"title": "Intrinsic Evaluation", "content": "In intrinsic evaluation, we assess the representation of content from HTML cells in the generated JSON. We parse the HTML using Beautiful Soup to extract set of all the cell contents present in the HTML input, denoted as $H_{set} = {c_1, c_2, ..., c_m}$. Similarly, we take the set of all elements in the JSON, denoted as $I_{set} = {e_1, e_2, ..., e_n}$\nTo evaluate if each content item $c_i$ from $H_{set}$ is present in $I_{set}$, we define an indicator function $I(c_i \\in I_{set})$:\n$I(c_i \\in I_{set}) = \\begin{cases}\n1 & \\text{if } c_i \\in I_{set},\n\\\\ 0 & \\text{otherwise.}\n\\end{cases}$\nThe Intrinsic Score (ISC) is then computed as:\n$ISC = \\frac{\\sum_{i=1}^{m}I(c_i \\in I_{set})}{m}$\nHere, $m$ denotes the cardinality of $H_{set}$."}, {"title": "Extrinsic Evaluation", "content": "Extrinsic evaluation assesses the semantic structure of the JSON by evaluating its ability to answer targeted questions. This method avoids direct comparison to the ground truth JSON (Gt), which can vary in representation. Instead, we systematically validate the structure by formulating questions that probe specific semantic elements: In order to form a minimalistic set of questions that validate the structure, we leverage the paths from the root node to each leaf node in the JSON. The number of paths corresponds to the number of leaf nodes. Let P denote the set of these paths. Formally, we define P as:\nP = {pi | Pi = (n1, n2, ..., nk)}\nHere, $(n_1, n_2, ..., n_k)$ represents a sequence of nodes starting from the root node $n_1$ to a leaf node $n_k$ in the JSON structure. For each path $p_i \\in P$, we prompt an LLM (Mq) with Gt and $p_i$ as inputs, instructing it to generate a single question $Q_i$. This question is targeted so that the value at the leaf node of the path is the expected answer Ke.\nThe question-answer pairs are evaluated using an Evaluator LLM (Meval). This model accepts HySem generated JSON Jp, question $Q_i$ and an expected answer Ke as inputs. Meval predicts an answer $K_p$ and compares its prediction with the expected answer $K_e$ in a single pass.\n$Pred(p_i) = \\begin{cases}\n1 & \\text{if } K_p = K_e,\n\\\\ 0 & \\text{otherwise.}\n\\end{cases}$\nThe Extrinsic Score (ESC) is computed as:\n$ESC = \\frac{1}{|P|} \\sum_{p_i \\in P} Pred(p_i).$"}, {"title": "Results and Ablation Study", "content": "We present the results of HySem following the first fine-tuning stage, utilizing our 608 testing samples manually curated from the open-sourced FinTab-Net and PubTabNet datasets. This comparison highlights HySem's performance after being fine-tuned on publicly available data, ensuring a fair and transparent benchmark against other models."}, {"title": "Conclusion", "content": "We successfully implemented the HySem LLM Pipeline, which generates semantic JSON output from HTML tables. The Context Optimizer significantly improved context utilization, enabling us to process larger tables. Currently, we are piloting our product with a well-known pharmaceutical enterprise that operates multiple production plants and serves a global customer base.\nThis model powers several downstream applications, including analytics from regulatory compliance documents and the automatic creation of these documents.\nOur future work includes supporting even larger tables that span multiple pages, developing techniques to improve processing speed, and building custom models for other verticals."}, {"title": "Related Works", "content": "Recent research has explored various uses of HTML to enhance NLP tasks. (Aghajanyan et al., 2021) developed the HyperText Language Model (HTLM), which leverages HTML's structural elements to improve tasks like zero-shot summarization and question answering. Their approach utilizes HTML for structured prompting and template-based guidance but is largely confined to standard NLP tasks and assumes predefined HTML structures, such as <title> elements.\n(Gur et al., 2023) focused on HTML understanding through tasks like semantic classification, description generation, and autonomous web navigation. They identified the context window length as a significant bottleneck, noting that even models with support for 1000+ tokens struggle with performance degradation when processing larger snippet sizes. This challenge underscores the difficulty of managing extensive HTML content within fixed context constraints.\n(Sui et al., 2024) tackled context length limitations by serializing tables into text formats. Their strategies include varying input formats and identifying critical values through self-augmentation. While these methods help fit table data within the model's context window, serialization can lead to the loss of structural nuances and detailed information.\nIn contrast, our work is broadly categorized as a Table Transformation task, where we focus on converting arbitrary HTML tables into semantic JSON. By employing a novel Context Optimizer, we preserve the table's structural integrity while enabling the processing of large tables. Unlike methods relying on predefined templates or serialization, our approach does not make assumptions about the HTML structure."}]}