{"title": "Exploration of LLMs, EEG and behavioral data to measure and support attention and sleep", "authors": ["Akane Sano", "Judith Amores", "Mary Czerwinski"], "abstract": "We explore the application of large language models (LLMs), pre-trained models with massive textual data for detecting and improving these altered states. We investigate the use of LLMs to estimate attention states, sleep stages, and sleep quality and generate sleep improvement suggestions and adaptive guided imagery scripts based on electroencephalogram (EEG) and physical activity data (e.g. waveforms, power spectrogram images, numerical features). Our results show that LLMs can estimate sleep quality based on human textual behavioral features and provide personalized sleep improvement suggestions and guided imagery scripts; however detecting attention, sleep stages, and sleep quality based on EEG and activity data requires further training data and domain-specific knowledge.", "sections": [{"title": "I. INTRODUCTION", "content": "Human altered states such as attention and sleep play significant roles in health [1], safety [2], and productivity [3] By precisely measuring these states, we can design adaptive tools and interfaces that respond effectively to users and help promote their health.\nHuman attention states have been measured using physiological and behavioral data such as electroencephalogram (EEG) [4], facial expressions [5], and eye tracking [6]. Measuring human attention states can help design systems that enhance driver alertness, minimize interruptions during focus, or promote relaxation before sleep.\nExtensive research has explored computational methods for measuring, evaluating, and improving sleep. For example, many algorithms have been developed to estimate sleep quality and stages using human physiological and behavioral sensor data including EEG and motion [7]. Computational systems have been designed to promote better sleep [8].\nRecent advances in natural language processing have leveraged massive textual data to train large language models (LLMs). Some studies have used LLMs for understanding human physiological and behavioral data and designing health applications including EEG abnormality detection and wearable sensor-based sleep quality detection [9] [10].\nLLMs hold promise for health applications including human altered state detection and personalized feedback delivery; however, rigorous evaluations have not been conducted, particularly regarding the integration of different human physiological and behavioral data (e.g., waveforms, numerical features, power spectrogram images) into LLMs for understanding the potential, accuracy, limitations, and reliability of the models.\nIn this paper, we evaluate LLMs for detecting and supporting human attention and sleep. Our ultimate goal is to create personalized, adaptive systems that enhance individuals' attention and sleep. To achieve this, in this paper, we conduct early explorations by integrating biobehavioral data into LLMs to understand their capabilities. We ask the following two research questions in the paper:\n1) Can LLMs interpret/sense attentive states, sleep stages, and sleep quality?\n2) Can LLMs provide personalized and adaptive feedback to help improve sleep?\nWe investigate the impact of various time scales and different input modalities of EEG, motion, and textual data on LLMs' performance, reasonings, and generated responses for detecting attention states, sleep stages, and sleep quality detection and improving sleep."}, {"title": "II. METHODS", "content": "We describe experiments and datasets for 1) user state detection and 2) sleep improvement suggestion generation to address RQ 1 and 2.\nWe conduct three different detection tasks, a) attention detection, b) sleep stage detection, and c) sleep quality detection.\n1) Datasets & Data processing: We use the following datasets for our experiments.\nMental Attention State [11]: This dataset contains 25 hours of EEG data collected using 14 ch Emotive. Five participants were engaged in a low-intensity task of controlling a computer-simulated train. Three mental states were observed in this study: focused, unfocused, and drowsy. We merged unfocused and drowsy into an unfocused state. We prepared three different types of information for attention detection (focused vs unfocused/drowsy): a) filtered EEG data (Fig. 1a): Raw EEG signals were processed using a bandpass Butterworth filter (order: 128, 0-40Hz), b) time-frequency spectrograms(Fig. 1b): These were computed using wavelet transform (Daubechies wavelet, every 10 sec) to provide frequency components over time, and c) 11 features: these features include power spectrum density (delta, theta, alpha,\nbeta), amplitude, standard deviation, kurtosis, alpha/delta, theta/alpha, delta/theta, the 90th percentile amplitude. We segmented the data into 10-sec intervals, resulting in 919 training samples, 230 validation samples, and 287 test samples.\nSleep EDF expanded [12]: This dataset contains 197 nights of polysomnography data collected from individuals aged 18-101 years. The data include EEG from two channels, Fpz-Cz and Pz-Oz, EOG, EMG, and event markers. Sleep stages are labeled as follows: 0 (Wake), 1 (stage 1), 2 (stage 2), 3 (stages 3 & 4), and 4 (REM sleep). We segmented the data into 30-sec epochs (training set: 152362 epochs, Validation set: 38092 epochs, test set: 500 epochs). We used Fpz-Cz for sleep stage detection. We used the same input types as those used for mental attention states: a) filtered EEG data, b) time-frequency spectrograms, and c) 11 features.\nStudent Life [13]: This dataset contains mobile phone sensor and survey data collected from 46 college students. We used the Pittsburgh Sleep Quality Index (PSQI) (19 self-rated questions including sleep-related behaviors and self-reported sleep quality) administered both at the pre and post study and its scoring rules to categorize each participant as a poor or good sleeper. We use physical activity data collected from participants' phones to compute participants' daily activity levels and patterns. We assess sleep quality detection (good vs poor) using the following inputs: a) participants' textual responses to PSQI questions, b) physical activity-based actograms: visual representations of 24 hour activity levels over days(Fig. 1c), and c) physical activity-based hourly averaged graphs: hourly levels and variations in physical activity (Fig. 1d).\n2) Models: We compare various LLMs and traditional machine learning models. LLMs: 1) Zero-shot learning: we feed data (EEG waveform images, spectrograms, or features) into LLMs. No specific training is conducted and the LLMs leverage their pre-existing knowledge. We use two LLM variants: GPT 4 vision (2024-02-15-preview) for image input and GPT 4 (2023-05-15) for textual input, 2) In-context learning LLM: we include input data and label examples in prompts so that LLMs (GPT 4) learn from context and adapt their response accordingly. 3) Fine-tuned LLM: We finetune LLMs (GPT 3.5 turbo 2024-02-15-preview) using training and validating datasets. A traditional machine learning model, XGBoost uses a technique called gradient boosting that combines simple decision trees for accurate predictions. We also analyze feature importance by looking at the number of times each feature is used for trees. 3) Baseline (majority vote): simply predicts the majority class for all test samples. It serves as a basic reference point to evaluate the performance of other models. For sleep quality detection, we also use the ground truth scoring method based on PSQI. We evaluate model performance using accuracy and weighted F1 score. Please see examples of LLM prompts in the Appendix."}, {"title": "B. Experiment 2: Personalized and adaptive sleep improvement feedback", "content": "We explore whether LLMs can generate personalized content for sleep improvement and focus on generating 1) sleep improvement suggestions and 2) guided imagery scripts. To generate the sleep suggestions, we feed LLMs various user context or profile information including a) EEG features from Sleep EDF dataset, b) PSQI answers in Student Life dataset, c) physical activity-based actograms, d) gender, e) age group, f) ethnicity, g) health issues such as \u201canxiety\u201d, \u201cPTSD\u201d, \u201cinsomnia\", \"pain\u201d, \u201cawakenings during nights\u201d, \u201cshift worker\u201d, h) user preferences such as favorite environments: beach, forest, favorite animals: dogs, cats; hobbies: traveling, baseball, exercise. To generate scripts to help a person sleep, we prompt the LLM to leverage a Guided Imagery technique [14]. This technique is also known as Guided Visualization, a mind-body technique that involves visualizing positive images or scenarios using all senses to help promote relaxation, manage anxiety, and stress, and enhance well-being. A typical session might include relaxation exercises, quiet sitting or lying down, and focusing on a specific goal. See prompt examples in the Appendix."}, {"title": "III. RESULTS", "content": "1) Attention detection: Table I summarizes attention detection performance. Traditional machine learning models outperformed LLM-based models for attention detection. Among the LLM models, fine-tuned GPT-3.5 models demonstrated the best performance. However, the GPT-4 vision model faced limitations. It failed to infer user states in approximately 25-30% of cases, often returning a generic response such as \"As a text-based AI, I do not have the capability to process images and I cannot assist with this request\". In addition, when we feed high dimensional EEG features, the GPT model indicated that it requires machine learning models and did not infer user states,\nThe fine-tuned GPT3.5 model typically shows high confidence levels of 100%. The model shows information about the power spectrum and ratios (e.g.,delta, theta, alpha, beta, alpha/delta) as the explanations for inference. For example, when correct inference is made with 100% confidence, the GPT 3.5 model explains \"The participant is unfocused because the alpha/delta ratio is high and the beta power is low, which are indicative of a relaxed and unfocused state.\"\nIncorrect inferences lack clear explanations and appear based on simple heuristic rules. For example, when ground truth is focused but unfocused is inferred, the model said \"The participant's state is unfocused because the alpha/delta ratio for channel AF3 is 0.166027, which is below the threshold for focused state.\u201d When ground truth is unfocused but focused is inferred, the model said \"The participant is focused because the alpha/delta ratio is high and the beta power is low, which are characteristic of a focused state.\"\nWe also analyze feature importance from the XGBoost model and learn that the model uses more variety of features for classifying focus vs unfocus including channel O2 kurtosis, AF4 beta, F3 percent 90, F7 beta, and T8 standard deviation.\n2) Sleep stage detection: Table II summarizes sleep stage detection performance. LLM-based sleep detection shows lower performance than ML-based models. GPT 4 vision models (both in-context learning and zero-shot learning) often return a message that they cannot assist with the task. In-context learning with EEG waveforms performs worse than zero-shot learning with EEG waveforms. In-context learning with EEG features seems more effective than the zero-shot LLM model with EEG features. GPT fine-tuned models show higher misclassification rates compared to XGBoost. For example, they misclassify wake as REM, stage 1 as stage 2, and REM as stage 2. However, stage 2 and stage 3 & 4 are similar (Fig.2).\nThe fine-tuned GPT 3.5 model shows inference confidence from 20 to 100% (mean: 79.7%, median 80%, stdev: 9.7%). The model outputs the explanation that it uses power spectrum and ratio for classifying sleep stages. For example, when the model infers correct stage 3&4 sleep, it outputs \"The dominant frequency bands in the EEG signal are delta and theta, with high power in both bands. The alpha and beta power are relatively low. The alpha delta ratio is low, indicating a higher proportion of slow wave activity. The theta alpha ratio is high, suggesting a predominance of theta activity. The delta theta ratio is also high, indicating a higher proportion of slow wave activity compared to theta activity. These features are indicative of stage 3 or 4 sleep, also known as slow wave sleep.\"\nThe important features extracted from the XGBoost model show kurtosis, mean, standard deviation, and 90th percentile amplitude in addition to power spectrum and ratio features.\n3) Sleep quality detection: We compare sleep quality detection (good vs poor sleep; confidence levels) using two approaches: (1) scored by PSQI standard scoring procedure vs. 2) GPT4 (Table III). Overall accuracy of the GPT4 model is 85.7%. There are 11 error cases out of 77. GPT-4 demonstrates relatively good sleep quality detection performance based on textual answers to PSQI; however, GPT-4 struggles to recognize sleep quality accurately when participants show poor sleep behavior (e.g., short sleep, difficulty falling asleep, or disrupted sleep) but good self-reported sleep quality (inference confidence is also low (60-65 %). GPT seems to emphasize subjective sleep quality over answers to other PSQI questions.\nConfidence levels of the GPT fine-tuned model are 60-100% (mean: 80% and std: 7.9 %). The confidence level is high when self-reported sleep quality is consistent with sleep behaviors (e.g. very bad self-reported sleep quality and poor sleep related behaviors such as long sleep latency, awakenings during the night, bad dreams, pain, feeling too cold, worry, and difficulty maintaining enthusiasm for daily activities).\nLLMs detect sleep and active periods and regular sleep patterns from the physical activity actograms and averaged graphs provided; however, the image data fed into LLMs are recognized as poor sleep. LLMs easily pick up some physical activities during the night time that occurred only a few nights out of 60 days of data and recognize them as a sign of poor sleep. For instance, when the actograms show increased activity after 5 am for a few days out of 60 days of data, suggesting potential wakefulness, LLMs misinterpret"}, {"title": "IV. DISCUSSION", "content": "This work explores the usage of LLMs and physiological and behavioral sensor data for attention and sleep detection and sleep improvement. Our experiments highlight both LLMs' strengths and limitations.\nLLM-based attention and sleep detection exhibit lower performance compared to traditional ML models. Fine-tuned LLMs improve models' ability to handle diverse contexts. However, we also found limitations. The fine-tuned GPT3.5 model uses limited features (e.g. power spectrum density and ratio) for classification even after fine-tuning and GPT-4 vision models fail to handle visual input. Also, feeding high dimensional numerical features such as EEG features to LLMs does not reliably estimate user states. To improve human state detection, LLM's knowledge needs to be extended beyond simple one-on-one relationships such as increased alpha band activity during unfocused state and LLMs require further refinement to handle diverse human physiological and behavioral data, variabilities, and patterns effectively. This might be possible using fine-tuning with larger datasets and retrieving external sources of knowledge. In addition, textual knowledge might not fully capture complex physiological and behavioral patterns; therefore, integrating textual information with numerical and visual data is essential in order to understand variability within and across individuals; however, the capacity of current LLM vision models and fine-tuning is still limited and LLMs requires much diverse data to enhance the knowledge.\nLLM-based sleep improvement suggestions and guided imagery scripts are personalized and adaptive to user profiles. Automatically generated suggestions and scripts have a potential for AI-based conversational systems or intervention systems after effectiveness and safety are carefully tested.\nThere are several limitations in this study. First, this study is an early exploration with limited datasets and limited LLMs. Refining prompts and using large and diverse datasets might help enhance task performance. We intentionally use interpretable features rather than low dimensional embeddings to test the extent to which LLM internal knowledge contributes to altered state detection and improvement. Our study only relies on public datasets and offline experiments; therefore, user studies with end users and clinicians are necessary to evaluate generative responses in terms of accuracy, effectiveness, and safety. Lastly, beyond LLMs, there are other advanced approaches such as transformer models and multimodal learning for detecting user states.\nWe also discuss the ethical considerations of using LLMs to detect and improve human-altered states. First, feeding personal physiological and behavioral data to LLMs could raise privacy concerns. Users might worry about the security and confidentiality of their sensitive information. Transparent consent processes and reliable data anonymization are important. Second, LLMs are trained on massive data that might contain biases. Bias detection and mitigation strategies are necessary to ensure fair outcomes. LLMs might have the capability to generate unethical, harmful, or inaccurate content or manipulate individuals. Implementing guidelines for responsible use and monitoring LLM-generated content are required."}]}