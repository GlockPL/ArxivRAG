{"title": "INFINITE-RESOLUTION INTEGRAL NOISE WARPING FOR DIFFUSION MODELS", "authors": ["Yitong Deng", "Winnie Lin", "Lingxiao Li", "Dmitriy Smirnov", "Ryan Burgert", "Ning Yu", "Vincent Dedun", "Mohammad H. Taghavi"], "abstract": "Adapting pretrained image-based diffusion models to generate temporally consistent videos has become an impactful generative modeling research direction. Training-free noise-space manipulation has proven to be an effective technique, where the challenge is to preserve the Gaussian white noise distribution while adding in temporal consistency. Recently, Chang et al. (2024) formulated this problem using an integral noise representation with distribution-preserving guarantees, and proposed an upsampling-based algorithm to compute it. However, while their mathematical formulation is advantageous, the algorithm incurs a high computational cost. Through analyzing the limiting-case behavior of their algorithm as the upsampling resolution goes to infinity, we develop an alternative algorithm that, by gathering increments of multiple Brownian bridges, achieves their infinite-resolution accuracy while simultaneously reducing the computational cost by orders of magnitude. We prove and experimentally validate our theoretical claims, and demonstrate our method's effectiveness in real-world applications. We further show that our method readily extends to the 3-dimensional space.", "sections": [{"title": "1 INTRODUCTION", "content": "The success of diffusion models in image generation and editing (Rombach et al., 2022; Nichol et al., 2021; Ho et al., 2020; Zhang et al., 2023a) has spurred significant interest in lifting these capacities to the video domain (Singer et al., 2022; Durrett, 2019; Gupta et al., 2023; Blattmann et al., 2023; Ho et al., 2022; Guo et al., 2024). While training video diffusion models directly on spatiotemporal data is a natural idea, practical concerns such as limited availability of large-scale video data and high computational cost have motivated investigations into training-free alternatives. One such approach is to use pre-trained image models to directly generate video frames, and utilize techniques such as cross-frame attention, feature injection and hierarchical sampling to promote temporal consistency across frames (Ceylan et al., 2023; Zhang et al., 2023b; Khachatryan et al., 2023; Cong et al., 2023).\nAmong these techniques, the controlled initialization of noise has been consistently shown to be an important one (Ceylan et al., 2023; Khachatryan et al., 2023). However, most existing approaches for noise manipulation either compromise the noise Gaussianity (and subsequently introduce a domain gap at inference time), or are restricted to simple manipulations such as filtering and blending which are insufficient for capturing complex temporal correlations. Recently, Chang et al. (2024) proposed a method that both preserves Gaussian white noise distribution and well captures temporal correlations via integral noise warping: each warped noise pixel integrates a continuous noise field over a polygonal deformed pixel region, which is computed by summing subpixels of an upsampled noise image. However, their method's theoretical soundness and effectiveness are followed by its high-end computational cost in both memory and time, which not only incurs a significant overhead at inference time but also limits its useability in novel applications (Kwak et al., 2024).\nIn this paper, we introduce a new noise-warping algorithm that dramatically cuts down the cost of Chang et al. (2024) while fully retaining its virtues. Our key insight for achieving this lies in that, when adopting an Eulerian perspective (as opposed to the original Lagrangian one), the limiting-"}, {"title": "2 METHODOLOGY", "content": "In this section, we introduce our method as follows:\n\u2022 We present an equivalent Eulerian interpretation (Figure 1) for the method by Chang et al. (2024), which was developed from a Lagrangian viewpoint.\n\u2022 We show that the limiting algorithm of the Eulerian formulation as upsampling level goes to infinity is equivalent to sampling increments of Brownian bridges.\n\u2022 We present our main algorithm (1) which, given a partition record that returns the overlapping area between a pixel square and a deformed pixel region, samples increments of Brownian bridges and scatters the increments to form the warped noise image.\n\u2022 We propose two concrete algorithms for computing the overlap areas. The grid-based Algorithm 2 extends Chang et al. (2024) to infinite resolution without the overhead of upsampling. The particle-based Algorithm 3 departs from grid-based discretization and uses particles instead, resulting in a simpler algorithm that is robust to degenerate maps."}, {"title": "2.1 NOISE WARPING: AN ALTERNATIVE EULERIAN PERSPECTIVE", "content": "Given a $D \\times D$ prior noise image $I_w \\in \\mathbb{R}^{D\\times D2}$ and a deformation map $\\psi : [0, 1]^2 \\rightarrow [0, 1]^2$, the noise-warping algorithm (Chang et al., 2024) computes the warped noise image $I_w \\in \\mathbb{R}^{D\\times D}$ with upsampling level $N \\in \\mathbb{Z}_{>1}$ as follows:\n1. For $i, j = 1, . . ., D$, upsample noise pixel $[I_w]_{i,j}$ to an $N\\times N$ subimage $[\\upharpoonleft I_w \\rceil_{i,j} \\in \\mathbb{R}^{N \\times N}$:\n$[\\upharpoonleft I_w \\rceil_{i,j} = \\frac{[I_w]_{i,j}}{N^2} + \\frac{1}{N}(-)$,\nwith $Z \\sim N(0, I)$ and $S = \\sum_{k=1}^{N^2} Z_k$.\nThe subimage for each pixel assembles into an $ND \\times ND$ upsampled noise image $\\upharpoonleft I_w$.\n2. For $i, j = 1, . . ., D$, the pixel square $A_{i,j} := [\\frac{i-1}{D}, \\frac{i}{D}] \\times [\\frac{j-1}{D}, \\frac{j}{D}]$ is warped to a deformed pixel region $\\tilde{A}_{i,j} := \\phi(A_{i,j})$, and the warped noise pixel $[I_w]_{i,j}$ is set to be the sum of all subpixels in $\\upharpoonleft I_w$ covered by $\\tilde{A_{i,j}}$ divided by $|\\tilde{A}_{i,j}|$, where $|A|$ denotes the Lebesgue measure of a Borel set $A \\subset \\mathbb{R}^2$.\nWe describe an alternative but equivalent procedure by making the following two observations, which are illustrated in Figure 1.\nGathering Noise \u2192 Scattering Noise. While the original procedure computes the warped noise image by gathering the upsampled noise subpixels in each deformed pixel region $\\tilde{A_{i,j}}$ in a Lagrangian fashion, we can instead use an alternative procedure by scattering the upsampled noise subpixels in each pixel square $A_{i,j}$ to overlapping deformed pixel regions. This new Eulerian procedure does not change the output, but it yields new insights in conjunction with our second observation.\nScattering Noise \u2192 Counting Overlapping Subpixels. Observe that the $N \\times N$ subpixels in $[\\upharpoonleft I_w \\rceil_{i,j}$, for every $i, j$, are correlated only through their sum $S$ when conditioning on $[I_w]_{i,j}$ (1), so they are exchangeable. Hence, when scattering these upsampled noise subpixels to deformed pixel regions, the order of scattering does not matter, and we only need to count the number of subpixels covered by each deformed pixel region.\nAlternative Eulerian Procedure. Putting both observations together, we now describe an alterna-tive procedure to Chang et al. (2024) with unaltered output:\n1. For each noise image pixel $[I_w]_{i,j}$, draw an upsampled subimage, now represented as a 1D vector $X \\in \\mathbb{R}^{N^2}$ using (1). Then, compute a prefix sum $H_{i,j}$ via $[H_{i,j}]_k := \\sum_{q=1}^{k} X_q$ for $k = 1, ..., N^2$.\n2. Warp each pixel square and compute deformed pixel regions $\\tilde{A_{i,j}}$ as before.\n3. For each $\\tilde{A_{i,j}}$, identify all $M$ deformed pixel regions $\\{\\tilde{A_{l_k,m_k}}\\}_{k=1,...,M}$ that overlap with $A_{i,j}$. Form $L \\in \\mathbb{Z}^{>0}$ where $L_k$ represents the number of upsampled subpixels covered by the kth overlap. Then, compute a prefix sum $[C_{i,j}]_k := \\sum_{q=1}^{k} L_q$. For $k = 1,..., M$, accrue $[H_{i,j}]_{[C_{i,j}]_k} - [H_{i,j}]_{[C_{i,j}]_{k-1}}$ to $[I_w]_{l_k,m_k}$, the kth overlapped warped noise pixel.\n4. Divide each warped noise pixel $[I_w]_{i,j}$ by $\\sqrt{|\\tilde{A_{i,j}}|}$\nDiscussion. Compared to the original procedure by Chang et al. (2024), this alternative but equiva-lent algorithm highlights how the upsampled subpixels of $[I_w]_{i,j}$ are scattered to form the warped noise pixels. In particular, each warped noise pixel receives the sum of a continuous segment in $H_{i,j}$. Since $H_{i,j}$ is a summation of weakly correlated and exchangeable subpixels, once conditioned on $[I_w]_{i,j}$, can we avoid explicitly instantiating every single subpixel, but instead model the sum of these weakly correlated subpixels?\nThe key insight of this paper is that when the upsampling resolution $N \\rightarrow \\infty$, the scaling limit of the prefix sum $H_{i,j}$ (with proper interpolation and time scaling to a continuous function) is precisely"}, {"title": "2.2 INFINITE-RESOLUTION NOISE SCATTERING", "content": "In this section, we first derive a scaling limit result to Brownian bridges. We then illustrate that the limiting version of the Eulerian procedure from the previous section matches precisely this scaling limit result. Lastly, we describe an autoregressive way to sample increments of a Brownian bridge that is linear in runtime in terms of the number of increments.\nTheorem 1 (Scaling limit to Brownian bridge). Let $\\{Z_n\\}$ be a sequence of i.i.d. random variables with finite variance that are normalized such that $E[Z_n] = 0$ and $Var(Z_n) = 1$. For $c \\in \\mathbb{R}$, define\n$S_n := \\sum_{i=1}^{n} Z_i$\n$X_{i,n} := \\frac{1}{\\sqrt{n}} Z_i$\n$S_n^\u2217(t) = \\frac{1}{\\sqrt{n}} \\sum_{i=1}^{[nt]} Z_i$\nConsider the sequence of random continuous functions $\\{H_n(t)\\} \\subset\\subset C[0, 1] defined as\n$H_n(t) := \\sum_{i=1}^{[nt]} X_{i,n} + (nt - [nt])X_{[nt]+1,n}$.\nThen the sequence $\\{H_n\\}$ converges in distribution under the sup-norm metric on C[0, 1] to $B_c(t) := W(t) \u2013 tW(1) + tc$, the Brownian bridge ending at c, where W(t) is standard Brownian motion.\nMoreover, in distribution, we have $B_c(t) = (W(t) | W(1) = c)$, where (W(t) | W(1) = c) is the disintegrated measure (Pachl, 1978) of W(t) on W(1) = c.\nWe prove Theorem 1 in Appendix A. To connect the Eulerian procedure with the setup in Theorem 1, let us fix a pixel $[I_w]_{i,j}$, and let $B := B_{[I_w]_{i,j}}, H := H_{i,j}, C := C_{i,j}$ to simplify the notation. By setting $n = N^2$ and $c = [I_w]_{i,j}$, the sequence $\\{X_{k,n}\\}$ from the theorem has exactly the same law as the upsampled subpixels in $[I_w]_{i,j}$. Moreover, $H_{nt} = H_n(t)$ when $nt \\in \\mathbb{Z}_{>1}$. By taking $N\\rightarrow\\infty$, implying $n \\rightarrow \\infty$, for any $t_1,...,t_M \\in [0, 1]$, we have the convergence in distribution of $(H_{[nt_1]},..., H_{[nt_M]}) \\rightarrow (B(t_1),\u2026\u2026\u2026, B(t_M))$. Recall in the Eulerian procedure, we only need to access the prefix sum H at indices $\\{C_k\\}_{k=1}^{M}$, where $C_k$ counts the number of upsampled subpixels covered by the first k overlaps. This suggests that if we choose\n$t_k = \\lim_{N\\rightarrow\\infty} \\frac{C_k}{N^2} = \\sum_{k'=1}^{M} |A_{i,j} \\cap \\tilde{A_{l_{k',m_{k'}}}|}$"}, {"title": "Algorithm 1 Infinite-Resolution Integral Noise Warp", "content": "Input: prior noise image $I_w \\in \\mathbb{R}^{D\\times D}$, deformation map $\\psi : [0, 1] \\rightarrow [0, 1]$\nOutput: warped noise image $I_w \\in \\mathbb{R}^{D\\times D}$\nBuild a partition record P from $\\psi$ (Section 2.3)\nInitialize $A_{i,j} \u2190 0$ for all $i, j = 1, . . ., D$\nparallel for each $u, v = 1, . . ., D$ do\n$t, q, M \u2190 0, 0, |P_{u,v}|$\nfor $k = 1,..., M$ do\n$(\\alpha,i,j) \u2190 [P_{u,v}]_k$\nSample q' ~ $(B_c(t + \\alpha)|B_c(t) = q)$ by (2) with c = $[I_W]_{u,v}$\n$[I_w]_{i,j} \u2190 [I_w]_{i,j} + (q' - q)$\n$A_{i,j}\u2190 A_{i,j} + \\alpha$\n$q,t\u2190 q',t + \\alpha$\nNormalize $[I_w]_{i,j} \u2190 A_{i,j}^{- \\frac{1}{2}}[I_w]_{i,j}$ for all $i, j = 1, ..., D$\nreturn $I_w$\n\u25b7 $A_{i,j}$ will eventually be the area of $\\tilde{A_{i,j}}$\n\u25b7 $\\alpha$ is the overlapping area between $A_{i,j}$ and $\\tilde{A_{u,v}}$\nPreservation of Gaussian White Noise. A central desideratum of noise warping is that the resulting warped noise image $I_w$ needs to have pixels that are i.i.d. standard Gaussians when the prior noise image $I_w$ is Gaussian white noise. This ensures that the warped noise is in-distribution for a pre-trained diffusion model. Our algorithm automatically guarantees this preservation of Gaussianity, as long as the warping function $\\psi$ is injective. To see this, the injectivity of $\\psi$ implies that the warped pixel regions are non-overlapping in the square $[0, 1]^2$. For each $\\tilde{A_{i,j}}$, since $[I_w]_{i,j} \\sim N(0,1)$ \ud504 W(1), by the conditional interpretation of Brownian bridges (1), when marginalizing out $[I_w]_{i,j}$, the Brownian bridge $B_{[I_W]ij}$ reduces to standard Brownian motion. Since the increments of the Brownian motion are independent Gaussians, the contribution to a deformed pixel region is simply a zero-mean Gaussian with variance equal to the overlapping area. Therefore, each deformed pixel region will receive the sum of a number of independent Gaussians whose variances sum to the area of the region. The scaling by the inverse square root of the area in Algorithm 1 thus makes each warped noise pixel an i.i.d. standard Gaussian."}, {"title": "2.3 BUILDING PARTITION RECORDS", "content": "To compute Algorithm 1, we need a way to compute the partition record P, which specifies how each pixel square is partitioned by multiple deformed pixel regions. In this section, we present one grid-based and one particle-based method for building P. In particular, for each pixel square with indices (u, v), we compute $P_{u,v}$ as a list of 3-tuples $(\\alpha, i, j)$, where (i, j) identifies the overlapped deformed pixel region and $\\alpha$ represents the overlapping area. Both variants are illustrated in Figure 3.\nAlgorithm 2 Grid-based Partition\nInput: Deformation map $\\psi$\nOutput: Partition record P\nparallel for each $i, j$ do\n$A^* \\leftarrow DiscretizeSquare(A_{i,j})$\n$S\u2190 (A^*)$\n$\\underline{u},\\overline{u},\\underline{v}, \\overline{v} \u2190 AABB(S)$\nfor $u \u2208 [\\underline{u}, \\overline{u}]$ do\nfor $v \u2208 [\\underline{v}, \\overline{v}]$ do\n$\\alpha\u2190 PolygonArea(Clip(S, u, v))$\n$P_{u,v} \u2190 P_{u,v} + [(\\alpha, i, j)]$\nreturn P\nAlgorithm 3 Particle-based Partition\nInput: Deformation map $\\psi$\nOutput: Partition record P\nparallel for each $i, j$ do\n$(x, y) \u2190 (\\frac{i+0.5}{D}, \\frac{j+0.5}{D})$\n$W_{0,0}, W_{0,1}, W_{1,0}, W_{1,1} \u2190 BilinearWeights(X)$\nfor $s, t \u2208 [0, 1]$ do\n$x', y' \u2190 [x] + s, [y] + t$\n$P_{x',y'} P_{x',y'} + [(W_{s,t}, i, j)]$\nparallel for each $u, v$ do\nNormalize total area of $P_{u,v}$ to D-2\nreturn P\nOur grid-based method (Algorithm 2 and Figure 3, left) follows Chang et al. (2024) by modeling each deformed pixel region as an octagon and computes overlapping areas by clipping it aginast undeformed pixel squares. Our particle-based method (Algorithm 3 and Figure 3, middle) borrows from the grid-to-particle techniques in fluid particle-in-cell methods (Brackbill et al., 1988), where we treat each deformed pixel region as a particle and each undeformed pixel square as a grid cell. Each particle requests area from nearby cells based on distance; upon receiving requests, each cell normalizes the requests to ensure partition-of-unity, and distributes its area to contacting particles.\nDiscussion. Conceptually, our grid and particle-based methods correspond to two different inter-pretations of $\\psi$ when provided as discrete samples (e.g., an optical flow image). The grid-based method implicitly reconstructs the continuous $\\psi$ field by linear interpolation, whereas the particle-based method assumes $\\psi$ is only known point-wise. The implication is that when $\\psi$ is smooth, linear interpolation works well and the grid-based method will yield a higher-quality warp as seen in Fig-ure 10. But when $\\psi$ is non-smooth, which is commonly the case in real world, linear interpolation can lead to degenerate polygons as illustrated on the right of Figure 3. The spurious overlaps be-tween the degenerate polygons will lead to spatial correlation in the warped noise image. Although both Chang et al. (2024) and our grid-based method implement fail-safes to avoid noise sharing and maintain spatial independence in practice, they suffer from the intrinsic ambiguity caused by these overlaps. On the other hand, the particle-based method circumvents such overlaps to begin with.\nIn addition, we highlight the simplicity and parallelizability of the particle-based method, as it boils down the computation of P to evaluating one bilinear kernel per pixel. Leveraging this fact, we can conveniently and efficiently extend our noise warping algorithm to higher spatial dimensions by replacing the bilinear kernel to its higher-dimensional counterparts, as shown in Figure 6."}, {"title": "3 RESULTS", "content": "In this section, we verify our theoretical claims by showing that our both variants preserve Gaussian white noise distribution, and that Chang et al. (2024) (HIWYN) converges to our grid-based variant as N increases. We analyze the behaviors of our grid-based and particle-based variants under diffeo-morphic and non-diffeomorphic deformations. We then apply our method in video generation and benchmark against existing methods (Ge et al., 2023; Chen et al., 2023; Chang et al., 2024). Finally, we extend our method to warping volumetric noise and demonstrate a use case in 3D graphics.\nGaussian White Noise Preservation. In Figure 4, we iteratively warp a noise image by the same deformation map for 50 timesteps. We gauge the output noise's resemblance to Gaussian white noise"}, {"title": "4 RELATED WORKS", "content": "Noise in Diffusion Models. Diffusion models generate images from input noise, and noise can thus be considered the counterpart to the latent codes utilized in GAN models. As such, the outputs of diffusion models have dependencies and correlations to the initial input noise, making noise a useful handle to control temporal consistency (Khachatryan et al., 2023). In addition to Chang et al. (2024) which this work was inspired by and improves upon, there are various other temporal noise manipulation techniques that do not preserve Gaussian noise distribution\u2013 some methods (Ma et al. (2024); Ren et al. (2024)) blend high frequency Gaussian noise with low frequency motion, while others (Mokady et al. (2022); Wallace et al. (2022)) rely on approximating the inversion of noise from temporally coherent image sequences. Pandey et al. (2024) goes one step further and manipulates inverted noise in 3D space. These approaches are flexible but degrade the output of the diffusion model due to the domain gap between inference time noise and training time noise, and as such, have occasionally been accompanied by mitigation strategies such as anisotropic diffusion (Yu et al. (2024)). Noise manipulation is also not limited to the generation and stylization of videos, but has various applications in image editing (Hou et al. (2024); Pandey et al. (2024)) and 3D mesh texturing (Richardson et al. (2023)) as well.\nNoise in Computer Graphics. While our noise warping work draws main inspiration from simula-tion techniques, spatial noise manipulation has been extensively studied in the graphics community through applications in animation and rendering. Works like (Kass & Pesare, 2011; Burley et al., 2024) present 2D noise manipulation techniques that add a stylized organic hand-drawn look to"}, {"title": "5 CONCLUSIONS", "content": "In this paper, we presented infinite-resolution integral noise warping, a novel algorithm for comput-ing temporally coherent, distribution-preserving noise transport to guide diffusion models into gen-erating consistent results. By deriving a continuous-space analogy to the discrete, upsampling-based strategy of the current state-of-the-art (Chang et al., 2024), our method not only further improves the accuracy by effectively raising the upsampling resolution to infinity, but also drastically reduces the computational cost, processing high-resolution noise images in real-time, which removes its main limitation. We also highlight the connotations of our new perspective beyond the performance gains, as it facilitates agnosticism to non-injective maps and extensibility to higher dimensions.\nOur work may be extended in a few directions. First, our particle-based variant does not capture tem-poral correlations induced by contraction or expansion, which may be addressed in the future with Voronoi partitioning. Secondly, although we only show use cases that leverage flow maps for tem-poral consistency, our method can operate on other map types such as UV maps for 3D consistency, which might be explored in future works. Thirdly, the connection between the consistency of the initial noise and that of the generated results remains empirical and invites theoretical justifications. Finally, the efficacy of noise warping for latent diffusion models remains to be investigated."}]}