{"title": "Stratify: Unifying Multi-Step Forecasting Strategies", "authors": ["Riku Green", "Grant Stevens", "Zahraa Abdallah", "Telmo M. Silva Filho"], "abstract": "A key aspect of temporal domains is the ability to make predictions multiple time steps into the future, a process known as multi-step forecasting (MSF). At the core of this process is selecting a forecasting strategy, however, with no existing frameworks to map out the space of strategies, practitioners are left with ad-hoc methods for strategy selection. In this work, we propose Stratify, a parameterised framework that addresses multi-step forecasting, unifying existing strategies and introducing novel, improved strategies. We evaluate Stratify on 18 benchmark datasets, five function classes, and short to long forecast horizons (10, 20, 40, 80). In over 84% of 1080 experiments, novel strategies in Stratify improved performance compared to all existing ones. Importantly, we find that no single strategy consistently outperforms others in all task settings, highlighting the need for practitioners explore the Stratify space to carefully search and select forecasting strategies based on task-specific requirements. Our results are the most comprehensive benchmarking of known and novel forecasting strategies. We make code available to reproduce our results.", "sections": [{"title": "1 Introduction", "content": "Time series forecasting plays a critical role in numerous real-world applications such as in healthcare [1], transport networks [2], geographical systems [3], and financial markets [4]. Multistep forecasting, which involves predicting a consecutive sequence of future time steps, remains a significant challenge in time series analysis [5, 6]. Multistep forecasting (MSF) strategies have consistently received attention in the time series literature given their necessity for long-term predictions in any dynamic domain [7-9].\nThe unique complexity of multistep forecasting is due to the trade-off between variance and bias in selecting a forecasting strategy [10]. Classical analysis of MSF concerns when it is appropriate to incorporate a recursive strategy (high bias) or a direct strategy (high variance). The recursive strategy predicts auto-regressively on a single model's own predictions until the desired horizon length is obtained. In contrast, direct strategies require fitting separate models to predict each fixed length, which is expensive and often results in model inconsistencies [10].\nTo bridge the gap between recursive and direct strategies, hybrid strategies have been developed. These are the DirectRecursive (DirRec) [11] and Rectify [12] strategies. The multi-input multi-output (MIMO) strategy inspired the development of other multi-output strategies, such as Recursive Multi-output (RecMO) [8], Direct Multi-output (DirMO) [13], and DirrecMO [9]. Multi-output (MO) strategies allow for tuning of output dimension of models to find an optimal balance in bias, variance, and computational efficiency. Hybrid methods have been shown to allow for more flexibility and improve the state of the art in MSF [14]. However, which strategy is generally optimal remains an open problem, as it often depends on the domain and function class of the forecasting model [8, 9, 11, 14].\nThe multi-output parameterisation of recursive, direct, and DirRec strategies offers a framework where they become equivalent to MIMO when their parameter value equals the multi-step horizon length [9]. However, little progress has been made to unify or represent MSF strategies. The lack of a unifying framework to represent MSF strategies has precluded a deeper understanding of how the variance and bias induced by the parameter selection of a strategy affects the downstream performance. This leaves practitioners selecting strategies with ad-hoc methods for strategy selection.\nIn this work, we introduce a novel approach to multi-step forecasting by parameter-ising and generalising the rectify strategy. This leaves the literature complete in terms of converting widely known single-output strategies into multi-output ones. Stratify defines a broader function space for forecasting strategies, encompassing both existing strategies and new ones that have not been previously explored. By framing these strategies in a parameterised and generalisable function space, we offer practitioners a systematic way to investigate and explore the space of known forecasting strategies for different tasks and datasets.\nOur extensive experiments find that previously unknown strategies, now explored through Stratify, are consistently and often significantly, better performing than the best existing strategies. We make our evaluations on 18 benchmark datasets [15] and multi-step horizon lengths of 10, 20, 40, and 80.\nOur main contributions and novelty of Stratify include:\n\u2022 A Unified Framework: Stratify is a unified representation of forecasting strategies, facilitating a systematic exploration of all existing strategies as well as novel strategies which can be significantly higher performing.\n\u2022 Novel MSF Strategies: Through Stratify, we discover novel strategies that consistently outperform all existing ones.\n\u2022 Improved Performance: Experimental validation on 18 benchmark datasets and multiple function classes demonstrates that Stratify consistently outperforms state-of-the-art strategies across diverse forecast horizons.\n\u2022 Optimisation/Visualisation Insights: We show that the Stratify representation of MSF strategy performance is often relatively smooth. The smoothness of Strat-ify's function space highlights the possibility of efficient optimisation over the space, highlighting a further practical utility.\nThe rest of this paper is organised as follows: Section 2 presents the related work on multi-step time series forecasting strategies; Section 2 covers the preliminaries; Section 2.2 describes Stratify; Section 3 presents our results and experimental setup; and Section 4 presents the discussion, future work, and conclusion."}, {"title": "2 Related work", "content": "Multi-step time series forecasting strategies are designed to predict multiple future points in a sequence, and they have evolved to address various challenges inherent in this task. We show this evolution in Figure 2. The recursive strategy involves training a single model for one-step-ahead forecasting and then iteratively applying it to predict multiple steps ahead by feeding each prediction back into the model as input [10].\nWhile straightforward, this method can suffer from error accumulation over longer horizons, as inaccuracies compound with each step. In contrast, the direct strategy trains separate models for each forecasting horizon, predicting future values directly from observed data. This approach avoids the issue of error propagation but may neglect the dependencies between future time points and results in higher variance, especially when data is limited.\nTo overcome the limitations of these basic strategies, hybrid and multiple-output (MO) approaches have been developed. Hybrid strategies like DirRec [11] and Rectify [12] combine elements of both recursive and direct methods by using multiple models where each model's input includes previous predictions, aiming to balance error accumulation and independence assumptions. The MIMO (Multiple Input Multiple Output) [10] strategy employs a single model to predict the entire sequence of future values simultaneously, preserving dependencies between them and potentially improving efficiency. MO variants such as RecMO, DirMO, and DirRecMO [9] extend the recursive, direct, and DirRec strategies by forecasting multiple future steps at once in segments. These methods aim to effectively mitigate error propagation and increase computational efficiency. We contribute a method for parameterising the Rectify strat-egy, named RectifyMO, and show where our contribution relates to other works in Figure 2."}, {"title": "Preliminaries", "content": "Multi-step forecasting involves predicting future values of a time series based on historical observations. Given a univariate time series {Y1, Y2,...,YT} consisting of T observations, the goal is to forecast the next H observations {YT+1,YT+2,...,\u0423\u0422+H}, where H is the forecasting horizon. This problem can be formulated as:\n{YT+1,YT+2,...,YT+H} = D(y1, y2, \u2026\u2026\u2026, yT), (1)\nwhere D represents the unknown function that maps past observations to future values, as discussed in Vapnik [18].\nNotation For the time series {Y1, Y2,..., YT}, the subscript Y2:5 refers to the sequence from {y2,..., Y5}, and y:j refers be all points up to the index j. We define the function \u03c2(H) = {\u03c3\u2208 Z+ | H_mod\u03c3 = 0}, where \u03c2(H) returns the set of all numbers that"}, {"title": "2.1 Single-Output Strategies", "content": "The recursive strategy iteratively applies a single-output model f to predict one step ahead, using each new prediction as input for the next forecast. The model is defined as:\nYT+1 = f (Yt, Yt\u22121,\u00b7\u00b7\u00b7, Yt-w+1), (2)\nwhere w is the window size (the number of past observations considered), and \u0177t+1 is the predicted value at time t + 1.\nLet x = YT-1,\uff65\uff65\uff65,YT-w+1 be the w most recent observations of the time series.\nTo forecast H steps ahead starting from time T, the predictions are obtained as:\n\u00dbT+h =\n{\nf(x),\nif h = 1,\nf(\u00dbT+h-1, \u00dbT+h-2,...,x:w-h), if 1 < h < w,\nf (\u0177T+h\u22121, \u0177T+h\u22122,\uff65\uff65\uff65,\u00dbT+h-w), if h > w.\n(3)\nThe direct strategy employs H distinct models, each predicting a specific horizon directly from the observed data:\n\u00dbT+H = concat(f1(x), f2(x),..., f(x)), where fi: x \u2192 \u0177(i\u22121):2, (4)\nwith i \u2208 I such that I = {1,2,...,H}.\nThe DirRec strategy (Direct-Recursive) combines elements of both recursive and direct methods by using H models, each incorporating previous predictions as inputs. DirRec forecasts also concatenate outputs of a set of functions, {f1,..., fH}, except they are defined as follows:\nfi:\n{\nXY(i-1):i,\nif i = 1,\nconcat (\u0177(i-2):(i-1), x) \u2192 \u0177(i\u22121):i, if i > 1.\n(5)\nwith i \u2208 I such that I = {1,2,..., H}. Since the input space of fi+1 depends on fi, forecasts cannot be produced in parallel.\nThe rectify strategy is a two-stage multi-step forecasting strategy that combines the strengths of both recursive and direct forecasting approaches by reducing bias while"}, {"title": "2.2 Multiple-Output Strategies", "content": "The Multiple Input Multiple Output (MIMO) method uses a single model f to predict all H future values simultaneously:\n\u0177\u0442:\u0442+\u043d = f(\u0443\u0442, YT\u22121,\uff65\uff65\uff65,YT-w+1)\nwhere f: R \u2192 RH.\nRecursive, direct, and DirRec strategies have been extended to multiple outputs, parameterised by o, the number of steps predicted at each iteration for producing a forecast.\nThe RecMO (Recursive Multiple-Output) strategy uses a single model f to predict \u03c3 steps ahead recursively:\n\u00dbT+(1-1)\u03c3:\u03a4+\u03af\u03c3 =\n[\nf(x),\nif i = 1,\nIf (\u00dbT+(1-2):T+(i-1), 2-(i-1)), if i > 1,\n(9)\nwith i \u2208 I such that I = {1,2,...,1}. The total multi-step forecast is simply the concatenation of \u00dbT+(i-1)\u03c3:T+io for all i \u2208 Z. Since \u00dbT+(i)\u03c3:T+(i+1)o depends on \u00dbT+(i\u22121)\u03c3:T+\u03af\u03c3, forecasts cannot be produced in parallel.\n\u03c3\nThe DirMO (Direct Multiple-Output) strategy trains models {f1, f2,\u00b7\u00b7\u00b7, \u00a3H/6}, each predicting a future values directly:"}, {"title": "2.3 RectifyMO: Extending Rectify to Multi-Output", "content": "The Rectify strategy strictly produces base forecasts with the recursive strategy and a residual forecast with the direct strategy. Extending Rectify into a multi-output strategy, referred to as RectifyMO, is relatively straightforward. For some o, we simply substitute the base model, b with a RecMO strategy with parameterisation equal to \u03c3, as well as the direct residual forecasting strategy with a DirMO strategy with the same parameterisation, \u03c3. For RectifyMO, the base and rectifying models are denoted as bo and ro respectively.\nThe RectifyMO, strategy involves the following two steps, for some \u03c3: \u03b1 \u03c3-RecMO base strategy is trained and produces the \u1e9eH:H+T forecast in o-steps. As with Rectify, the residual time series \u03b7 is generated using Equation 6 where bo is used to generate the \u03b2\u2081. The \u03c3-DirMO strategy then predicts ni from x. The resulting forecast for is the summation of \u0177T:T+H = \u1e9eH:H+T + NH:H+T, identical to Rectify in Equation 8.\nThe multi-output formulation, RectifyMO, allows further balancing of variance and bias via parameterisation the base and residual forecasters by \u03c3. Similar to other MO-parameterisations, at \u03c3 = 1 we have the original single-output Rectify, and at \u03c3 = \u0397 we have the MIMO strategy (as the base and rectifier)."}, {"title": "2.4 Generalising RectifyMO into Stratify", "content": "The motivation for Rectify is to use a base forecaster to capture general dynamics to simplify the problem for its residual forecaster [12]. With RectifyMO we followed the same motivation where the base dynamics are forecasted by a biased estimator in a RecMO strategy, for some o, and an unbiased estimator for the residual forecaster with the same \u03c3. One way to generalise RectifyMO further is by allowing for the base and the residual forecasters to have different \u03c3-parameters. However, by also by allowing for any combination of RecMO, DIRMO, or DirRec strategies as the base or rectifier, we have the most generalised framework for MSF strategies. We name our general framework Stratify for its resemblance to the Rectify strategy."}, {"title": "Stratify: A Unified Framework for MSF Strategies", "content": "The Stratify framework is constructed by first parameterising Rectify, completing the literature with multi-output variants of the well-known single-output strategies. Then we extend the multi-output rectify (RectifyMO) to Stratify, our main contribution."}, {"title": "2.4.1 Theoretical Considerations", "content": "We know from Taieb [10] showing that recursive forecasts are biased. Hence, we note that using a RecMO strategy in the base and in the residual forecaster results in a biased strategy. However, using an unbiased strategy as the base makes a Stratify strategy unbiased for any rectifier selected. This follows from the residuals of the base converging to zero in the infinite data limit, resulting in a trivial task for any rectifier.\nOur full generalisation of Rectify allows for a more flexible framework to select between the variance and bias of MSF strategies at both the base and rectifier level."}, {"title": "3 Results", "content": "Using a diverse set of time series forecasting benchmarks, this section proposes experimental contributions to the following research questions:\n\u2022 (R1) To what extent does exploring the Stratify space aid multi-step forecasting?\n\u2022 (R2) How do all known strategies compare to each other?\n\u2022 (R3) How can we practically represent the space of strategies?"}, {"title": "3.1 Experimental Setup", "content": "Datasets To evaluate the Stratify space, we conduct experiments using the BasicTS benchmark suite [15], a comprehensive platform designed for fair and reproducible comparisons in multivariate time series (MTS) forecasting. We collapse along fea-ture dimensions for multivariate time series and show their characteristics in Table 2. We include a synthetic chaotic time series of length 10,000 from the Mackey Glass equations from Chandra et al. [19], denoted mg-10000.\nTask settings We consider forecast horizon lengths of 10, 20, 40, and 80 to examine the adaptability of our method to varying temporal prediction requirements. We use"}, {"title": "4 Discussion and Conclusion", "content": "This paper introduced Stratify, a unified framework for multi-step forecasting strategies that unifies existing approaches while enabling the discovery of novel, improved strategies. Novel Stratify strategies consistently outperformed existing ones in over 84% of experiments across 18 benchmark datasets (Table 5a) and multiple function classes, with reductions in error between 5 25% across multiple function classes (Table 3), addressing our first research question (R1). We showed that existing strategies failed to perform significantly differently with 95% confidence under the Nemenyi test. However, novel strategies in Stratify were shown to significantly improve forecast performance under this test (Figures 6, 7). Both of these findings addressed our second research question (R2). Our representations of Stratify through the p-\u03b4-\u03b9 planes revealed general trends, suggesting them to be a reasonable representation of the space of strategies (R3). Despite the general trends of the heat maps, the high variances reported highlight the importance of task-specific selection of strategies.\nWe presented the most comprehensive benchmarking of multi-step forecasting strategies by evaluating all existing strategies and introducing a space of novel ones on 18 benchmarks, multiple horizon lengths, and five function classes. In this work we represented the parameterisation of strategies as a percentage of their forecasting length, which allowed for a more fair and intuitive comparison across strategies and their task settings. We hope for future works to consider the same when comparing strategies across different horizon lengths.\nFor practitioners, our work unifies the relationship between existing strategies. Stratify offers a systematic methodology to discover high-performing forecasting strategies without treating each strategy in isolation. The planes from Figure 8 can be searched via an optimisation routine to find an optimal strategy. Future work can investigate the use of various optimisation algorithms to navigate the vast Stratify space, or utilise meta-learning to identify whether general task features have a relationship with the optimal strategy. This is particularly valuable for real-world applications where datasets exhibit diverse patterns and characteristics, making one-size-fits-all approaches ineffective. The insights provided by the framework, such as the preference for longer base strategies and rectifiers, also simplify the selection process for hyperparameters, reducing trial-and-error experimentation.\nWhilst we computed the entire Stratify plane for the MLP, we did not for the remaining function classes. Future work can investigate the relationship between the number of functions required for each strategy and the performance. From the perfor-mance heat-map in Figure 8 and the computational time in Figure A1, we hypothesise that compute-optimal strategy selection would be possible and highly beneficial for practitioners. More efficient exploration of the Stratify space is expected to improve forecasting performances.\nLastly, the results demonstrate the effectiveness of the proposed Stratify frame-work, but we acknowledge this work focuses exclusively on univariate time series data. Many real-world applications involve multivariate time series, where interactions between variables play a critical role in forecasting. Extending the framework to handle multivariate scenarios would significantly enhance its applicability and generality."}, {"title": "10%6:20%", "content": "\u03c1:10%\u03c1:100%\u03c1:20%\u03c1:10%6:10%"}, {"title": "Appendix A Training time over Stratify space", "content": "In Figure Al we show the time taken to train each strategy in Stratify for the MLP on the mg_10000 dataset. We expect the qualitative times to be consistent across datasets and functions used. The training time is normalised by the minimum time taken for a single strategy to train. There is a clear relationship showing that strategies containing RecMO train much faster. This is because it is the only strategy where forecasts are computed using only one model."}, {"title": "Appendix B Inference time over Stratify space", "content": "In Figure B2 we show the inference time taken for each strategy in Stratify for the MLP on the mg_10000 dataset. As with the compute times in Figure A1, we expect the qualitative times to be consistent across datasets and functions used. Again, the time is normalised by the minimum time taken to produce forecasts for the task. We see a clear pattern over inference times, showing that the parameterisation is proportional to the inference time. This is to be expected for RecMO and DirRecMO strategies.\nThis relationship would be alleviated for DirMO if the implementation is to allocate parallel computing methods over the set of functions of a DirMO-only strategy."}, {"title": "Appendix C Remaining Critical Difference Diagrams", "content": "In the main text we truncate the critical differencing diagram for space reasons. Below we show the full diagram of every strategy in Stratify using the normalisation of parameter values by the horizon length. We find that many strategies in Stratify rank on either side of existing strategies. However the majority of green is visible on the left of the blue, highlighting that Stratify strategies are generally showing improved performance."}]}