{"title": "PINNFLUENCE: INFLUENCE FUNCTIONS FOR\nPHYSICS-INFORMED NEURAL NETWORKS", "authors": ["Jonas R. Naujoks", "Thomas Wiegand", "Aleksander Krasowski", "Sebastian Lapuschkin", "Ren\u00e9 P. Klausen", "Moritz Weckbecker", "Wojciech Samek"], "abstract": "Recently, physics-informed neural networks (PINNs) have emerged as a flexible and promising\napplication of deep learning to partial differential equations in the physical sciences. While offering\nstrong performance and competitive inference speeds on forward and inverse problems, their black-\nbox nature limits interpretability, particularly regarding alignment with expected physical behavior.\nIn the present work, we explore the application of influence functions (IFs) to validate and debug\nPINNs post-hoc. Specifically, we apply variations of IF-based indicators to gauge the influence of\ndifferent types of collocation points on the prediction of PINNs applied to a 2D Navier-Stokes fluid\nflow problem. Our results demonstrate how IFs can be adapted to PINNs to reveal the potential for\nfurther studies.", "sections": [{"title": "Introduction", "content": "Time and time again, deep learning approaches have proven themselves to be exceptionally capable at solving\nproblems that were considered hard and time-consuming, yielding fast inference times bundled with strong performance.\nPhysics-informed neural networks (PINNs) [23] represent another recent iteration of that trend applied to the realm of\npartial differential equations (PDEs). By incorporating prior physical knowledge in the form of differential equations\n[6; 9; 10; 23], they admit a wide range of possible applications such as fluid mechanics, electromagnetics, disease\nmodelling and optics, inter alia [1; 2; 4; 19]. Despite the power of PINNs, there remains the challenge of understanding\nand improving model behavior when things go wrong [15; 25; 26]. PINNs minimize complex composite losses, which\ncomplicates the tracing of poor performance to specific training points or conditions; this is the main motivation for this\nwork.\nInfluence functions [12] (IFs) systematically assess the contribution of individual training points to a model's behavior.\nRecent studies have shown that incorporating physical concepts like temporal causality improves PINN performance\n[7; 28], highlighting the role of underlying physical principles. By identifying key points, such as those near boundaries\nor critical regions, we can assess whether the PINN's learned parameters align with the physics of the problem. For\nmany PDEs, practitioners possess an intuitive understanding of the underlying physics. For example, in magnetostatics,\nthe magnetic field is fundamentally generated by source terms. A well-trained PINN could be expected to reflect this\nrelation. We aim to show how domain experts can use this approach to validate the model by identifying key training\npoints, boundary conditions or physical principles that have the greatest impact on the model's behavior. This also\nallows them to estimate the effect of inductive biases and observed data on the model's predictions. Notably, PINNS\nalso provide a powerful application domain for IFs and other data attribution methods, as models and datasets are\nusually much smaller than those used in computer vision or natural language processing. This makes calculation of IFs\ncomputationally feasible, and the effect of individual data points on the fit of the model is expected to be greater."}, {"title": "Theoretical Background", "content": "Physics-Informed Neural Networks introduced in [23], constitute a machine-learning-based approach to solving\npartial differential equations (PDEs), which are ubiquitous in physical sciences. Let \u03a9 \u2286 Rn be an open domain and\nconsider the initial boundary value problem (IBVP)\nN[u](x) = 0, x \u2208 \u03a9  (1)\nB[u](x) = 0, x \u2208 \u0398\u03a9  (2)\nHere, N and B are differential operators acting on the solution of the PDE u : \u03a9 \u2192 Rd, where x typically represents\nthe spatial as well as possible temporal coordinates. Note that Eq. (2) is formulated to capture i.a. Dirichlet as well as\nvon-Neumann conditions.\nThe goal of PINNs is to approximate the solution of a given differential equation using a neural network (x; \u03b8), which\ndepends on parameters \u03b8 \u2208 \u0398 and an input x. These parameters are optimized by training \u03b8 using a composite loss func-\ntion, consisting of the PDE residual and boundary conditions L = Lpde + Lbc, with Lpde = 1|N[\u03c6(xi; \u03b8)]|2,\nLbc = 1|B[\u03c6(xi; \u03b8)]|2, and where Npde as well as Nbc are the numbers of randomly sampled collocation from\n\u03a9 and \u2202\u03a9, respectively. Note that one can also consider a data-driven regression loss, which we drop for the sake of\nsimplicity.\nInfluence Functions The question being addressed by influence functions [5; 8; 12] is how would the model's\nbehavior change if certain training points were not present in the training set? By linearly approximating the effect of\nleave-one-out retraining, IFs provide a possibility of studying a model through the lens of its training data. In order to\nadapt the influence functions to PINNs we will slightly generalize the approach of [12; 13]. We provide a full derivation\nand proof, including details on all necessary assumptions, in Appendix A.1. Suppose we have trained a model by\nminimizing a loss L(xi; \u03b8) on a training data set X = {x1,..., xN} and derived an optimal parameter \u03b8 \u2208 \u0398.\nFurthermore, consider a function f : \u03a9 \u00d7 \u0398 \u2192 R, which depends on the parameter \u03b8 \u2208 \u0398 and some other parameter\nz \u2208 \u03a9 (such as in [12], the loss L for a single test point z). We now aim to approximate f(z; \u03b8+) \u2212 f(z; \u03b8) if \u03b8+ were\noptimized over an amended training data set that includes an additional training point x+. This can be approximated by\nInff(z;\u03b8)(x+) := \u2207\u03b8 f(z; \u03b8) \u00b7 H\u22121 \u00b7 \u2207\u03b8L(x+; \u03b8)  (3)\nwhere H\u03b8 = \u2211L(xi; \u03b8) denotes the Hessian. This approach can be extended to the addition\nand removal of multiple training data points: Let X+ = {x+,...,x+ } be the set of training points\nwe want to add and X\u2212 = {x\u2212,...,x\u2212 } \u2286 X the set we want to remove from our training set.\nThe effect of retraining the model with added and removed training points can then be approximated by\nInff(z;\u03b8)(X+, X\u2212) := \u2211Inff(z;\u03b8)(x+) - \u2211Inff(z;\u03b8)(x\u2212 ). Hence, we can study the influence of single sam-\npling points as well as regions on loss functions, any type of predictions or derived quantities. By studying the influence\nresulting therefrom, one can compare the model's behavior with physical intuition. Using this method, we can also\nestimate the effect of adding and removing entire loss terms for composite losses (see Corollary 1 in the appendix)."}, {"title": "Experiments", "content": "Navier-Stokes Problem The Navier-Stokes equations describe the motion of viscous Newtonian fluids and represent\nthe cornerstone of fluid dynamics. Consequently, they are widely used in various applications. In the present work, we\nfocus on a laminar, incompressible and time-independent fluid flow around a cylinder in a rectangular cavity with open\nlateral boundaries in 2D [24], see Fig. 1. The stationary equations of motions as well as the continuity equation are\ngiven as follows:\n(u \u00b7 \u2207)u + \u2207p \u2212 \u03bd\u22072u = 0, div u = 0,  (4)"}, {"title": "Empirical Indicators", "content": "In this study, we aim to answer\nthe following question using influence functions: Can\nwe identify or test whether the PINN has learned cer-\ntain aspects of the underlying physical principles of the\nNavier-Stokes problem? Since predictions alone do not re-\nveal the influence of training data or boundary conditions,\nwe devise a set of heuristic indicators.\nWe propose two IF-based indicators that are designed to\ncapture aspects of the physical processes inherent to the PDE (4) and to serve as exemplary metrics showcasing how\nexpert users can design tests to validate PINNs against their prior knowledge of the problem. As a first indication\nmetric, we concentrate on the flow direction of the Navier-Stokes problem: the inflow is given at the left boundary of\nthe domain and the outflow lies on the juxtaposed side. Figure 2 shows the influence pattern of a training point close to\nthe cylinder.\nWe thus test a model on whether its influence patterns reflect this behavior. To define the directional indicator (DI),\nwhich captures the relevance share associated with the collocation point xtest on the test points that follow in the\ndirection of the flow (i.e. having larger x-component), we write:\nDI(xtest) := \u2208 [0, 1]  (5)\nA larger value of DI implies that a given test point mainly influences the prediction further down in the direction of the\nflow rather than before and implies that the model has learned this underlying physical phenomenon of directed flows.\nAs a second indicator, we are interested in the fraction of influence that is associated with a given object in the input\ndomain. In the present Navier-Stokes problem, the cylinder plays a central role in the flow field: it obstructs the flow.\nThus, the overall velocity and pressure fields should be heavily influenced by its position. To this end, we devise an\nobject or region identifier, which is designed to capture the influence associated with a given object in the domain (in\nour case around the cylinder). For the object or region indicator (OI), which sums up the relevance of removing a region\n\u039e \u2286 \u03a9, we write:"}, {"title": "", "content": "OI(\u039e) := \u2208 [0, 1]  (6)\nA higher value of OI means that the region in question, such\nas the cylinder in our case, has an increased influence on the\nprediction for all other points. This is to be expected for a model\nthat aims to accurately reflect the physics. In this investigation,\nwe choose \u039e = C1.5r, meaning that we remove the area with\na 1.5 times the radius of the cylinder, see Fig. 3.\nResults We evaluate the three different iterations of PINNs\non the Navier-Stokes task. Figures 3a to 3c show heatmaps of\nhow influential individual training points were to the whole test\nset. For good, the most influential points are distributed close\nto the inflow, on the outflow and especially around the cylin-\nder. This is expected, as these areas determine the fluid flow.\nFurthermore, we observe that for bad, the upper left boundary\nis overly influential. And finally, broken's influences are again\ndistributed well around the cylinder. In Table 1, the aggregated\nmean values of the indicators are presented. Both good and\nbad show stronger DI performance. This suggests that both\nmodels have successfully learned to capture the dependence\nof the fluid flow on preceding points. When it comes to the\nOI indicator, this trend is even clearer. Here, the good model\nachieves superior performance, which suggests that the cylinder here has the biggest absolute influence, reflecting its\nimportance for the fluid flow. It is important to note that these indicators are tools for investigating model behavior.\nPerforming well on an indicator does not imply that the model is entirely correct, but rather that it does not fail in the\nspecific aspect the indicator evaluates. Expert knowledge is essential for designing meaningful indicators, and further\ninvestigation is needed to validate their robustness. Additionally, if the indicator's assumptions are flawed, the results\nmay be misleading and fail to provide sensible insights."}, {"title": "Conclusion", "content": "We showcased how influence functions can\nhelp to evaluate PINNs. In particular, we\nformulated heuristically motivated indica-\ntors designed to test certain physical con-\ncepts. By applying this method to a Navier-\nStokes problem, we observed that the best-\nperforming model consistently aligned with\nthese indicators, confirming their utility in\nassessing model performance. Still, further\nexploration of IF-based markers is indicated\nto rigorously validate the broad applicability\nof the presented approach. Using influence\nfunctions to improve PINN training through\nmethods like resampling training points [16],\nenforcing temporal causality [28], or dynam-\nically reweighing loss terms [3] \u2013 combined with IF-based training time techniques like TracIN [22] \u2013 presents a\npromising direction for future research. Additionally, further studies on the influence on parts of the loss as well as on\ndifferent physical quantities, e.g. the vorticity, appears to be a logical next step."}, {"title": "Appendix / Supplemental Material", "content": "A.1 Influence Functions\nIn this part, we aim to formulate the key steps for influence functions [8] and adjust them for the application to PINNS.\nTherefore, we will slightly generalize the results from [12; 13]. Thereby, we will provide proofs for the statements from\nSection 2. We start with a well-known result [5], which is the crucial ingredient for influence functions.\nLemma 1 ('argmin'-trick). Let g : \u0472 \u00d7 U \u2192 R, with \u0472 \u2286 RP convex, compact and U \u2286 R, be a function, which is\ntwice continuously differentiable w.r.t. \u03b8 \u2208 \u0398 and continuously differentiable w.r.t. \u2208 U. Furthermore, we assume that\ng has a positive definite Hessian matrix1 H := \u22072g(\u03b8, ) for all \u2208 U. Then h() := arg min\u03b8\u2208\u0398 g(\u03b8, ), is unique,\nand its derivative is given by\n(e) = -19(0) (7)\nwhere 1 := h() denotes the minimum.\nProof. Since the Hessian is positive definite, g(\u03b8, ) is strictly convex w.r.t. \u03b8 for any \u2208 U. Further, any continuous\nfunction on a compact domain has a minimum (extreme value theorem). Due to the strict convexity, this minimum will\nbe unique \u03b8 = h() for any given . At the minimum we will have\n\u2207\u03b8g(\u03b8, ) = 0  (8)"}, {"title": "", "content": "A derivative of Eq. (8) w.r.t. leads to\n0 = +9(0) (9)\nSince the Hessian is positive definite, we can invert the Hessian and a simple rearrangement of Eq. (9) shows the\nassertion.\nBy means of this result, we can approximate how an arbitrary function, depending on the optimal parameters , changes\nwhen adding and removing points to our training set.\nProposition 1. Consider a total loss function L(X; \u03b8) = with training points X = {x1,..., xN},\nand denote by X\u2212 = {x\u2212,...,x\u2212 } \u2286 X training points we want to remove and by X+ = {x+,...,x+ } training\npoints we want to add. We will assume that L has a positive definite Hessian matrix H = \u22072L(X; \u03b8). Furthermore,\nlet f : \u03a9 \u00d7 \u0398 \u2192 R be an arbitrary function, depending on the parameters \u03b8 \u2208 \u0398 and being twice continuously\ndifferentiable w.r.t. \u03b8 \u2208 \u0398. Then the effect of adding and removing training points on the function f can be approximated\nby\nf(z; \u03b8) \u2212 f(z; \u03b8X+,X\u2212) == Inff(z,\u03b8)(X+, X\u2212) + O(N\u22122)  (10)\nwhere are the optimized parameters of the original model with training points X and \u03b8X+,X\u2212 the optimized parameters\nfor training points X \u222a X+ \\ X\u2212. Inff(z,\u03b8) is the so-called influence function, which is defined by\nInff(z,\u03b8)(X+, X\u2212) := Inff(z,\u03b8)(x+) - Inff(z,\u03b8)(x\u2212 )  (11)\nwith Inff(z,\u03b8)(xi) := \u2207 \u03b8f(z; \u03b8) \u00b7 H \u00b7 \u2207\u03b8L(xi; \u03b8)  (12)\nProof. The optimal parameter under the influence of adding and removing points, is given as\n\u03b8,X+,X\u2212 := arg min\u03b8\u2208\u0398N\u2211L(xi; \u03b8) + N\u2211L(x+; \u03b8) \u2212 N\u2211L(x\u2212; \u03b8)  (13)\nwhere \u03b8\u03b8,X+,X\u2212 = is the optimized parameter for the training set X. As we can multiply the inner function of\nEq. (13) by any positive number without changing \u03b8 \u03b8,X+,X\u2212, the optimal parameter for the training set X \u222a X+ \\ X\u2212\nis \u03b81/N,X+,X\u2212 = \u03b8X+,X\u2212. Therefore, we will consider\nf(z; \u03b8) \u2212 f(z; \u03b8\u03b5,X+,X\u2212) = + O(\u03b5)\n= \u2212\u2207\u03b8f(z; \u03b8) \u00b7 + O(\u03b5)\n= \u2207 \u03b8f(z; \u03b8) \u00b7 H \u00b7 \u2207 \u03b8L(xi; \u03b8) -\u2207 \u03b8L(xi; \u03b8) + O(\u03b5)  (14)\nwhere we used Taylor's theorem in the first step and Lemma 1 in the last step.\nNote, that the loss function will not be strictly convex in the most approaches, which implies, in particular, that it will\nnot have a positive definite Hessian. However, in a progressing training, we can always restrict the possible parameter\nset in a meaningful way, such that the loss function is strictly convex and having a positive definite Hessian.\nTherefore, the influence function will approximate the change of a function f(z; \u03b8), when retraining it on a different\ntraining set. Usually, one uses the loss itself f(xtest; \u03b8) = L(xtest; \u03b8) on a test point for that function. However, we can\nalso study the influence to physical observables, which are relevant for the considered problem. Since, we can also\nstudy the influence to mean values, we can therefore study also the influence to regions in our domain.\nIn analogous fashion, we can easily extend this framework to study the effect of upweighting or downweighting\nindividual loss terms. This is in particular interesting for PINNs, since a wrong weighting of the loss terms, is known to\nreduce the accuracy of PINNs drastically [25]."}, {"title": "", "content": "Corollary 1. Consider a total loss, which is built by several loss terms Lj\nL(X; \u03b8) = \u2211 \u2211 Lj(Xi; \u03b8) =\u2211\u2211 Lj(Xi; \u03b8).  (15)\nThe procedure of removing the loss terms Lj with j \u2208 K\u2212 \u2286 {1, ..., k} can be approximated by\nf(z; \u03b8) \u2212 f(z; \u03b8K\u2212) == Inff(z,\u03b8)(K\u2212) + O(N\u22122)  (16)\nwhere is the optimized parameter of the original model and \u03b8K\u2212 is the optimized parameter for the model with\nremoved losses terms and\nInff(z,\u03b8)(K\u2212) := \u2212\u2207\u03b8f(z; \u03b8) \u00b7 H\u22121 \u00b7 \u2207Lj(X; \u03b8)  (17)\nProof. Analogous, to Proposition 1 we will define\n\u03b8,K\u2212 := arg min\u2211\u2211 lj(Xi; \u03b8) \u2212 \u2211 \u2211lj(Xi; \u03b8) (18)\nas the optimal parameter, which will remove the loss terms Lj with j \u2208 K\u00ae for \u03b5 = 1/N. The assertion follows with\nthe analogue steps above.\nA.2 Navier-Stokes Parametrization\nThe rectangular cavity characterizing the 2D Navier-Stokes problem formulation is given in Table 2.\nu(xmin, y) = (ymaxy) (19)"}]}