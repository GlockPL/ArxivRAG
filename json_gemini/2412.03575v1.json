{"title": "Leveraging Large Language Models for Generating Labeled Mineral Site Record Linkage Data", "authors": ["Jiyoon Pyo", "Yao-Yi Chiang"], "abstract": "Record linkage integrates diverse data sources by identifying records that refer to the same entity. In the context of mineral site records, accurate record linkage is crucial for identifying and mapping mineral deposits. Properly linking records that refer to the same mineral deposit helps define the spatial coverage of mineral areas, benefiting resource identification and site data archiving. Mineral site record linkage falls under the spatial record linkage category since the records contain information about the physical locations and non-spatial attributes in a tabular format. The task is particularly challenging due to the heterogeneity and vast scale of the data. While prior research employs pre-trained discriminative language models (PLMs) on spatial entity linkage, they often require substantial amounts of curated ground-truth data for fine-tuning. Gathering and creating ground truth data is both time-consuming and costly. Therefore, such approaches are not always feasible in real-world scenarios where gold-standard data are unavailable. Although large generative language models (LLMs) have shown promising results in various natural language processing tasks, including record linkage, their high inference time and resource demand present challenges. We propose a method that leverages an LLM to generate training data and fine-tune a PLM to address the training data gap while preserving the efficiency of PLMs. Our approach achieves over 45% improvement in F1 score for record linkage compared to traditional PLM-based methods using ground truth data while reducing the inference time by nearly 18 times compared to relying on LLMs. Additionally, we offer an automated pipeline that eliminates the need for human intervention, highlighting this approach's potential to overcome record linkage challenges.", "sections": [{"title": "1 Introduction", "content": "The surge of web data has enabled the creation of rich and diverse datasets by merging information collected from various sources, including web pages and research conducted by different individuals. However, this abundance of data has also increased data heterogeneity, emphasizing the need for efficient and effective data merging from various sources. Record linkage, the process of identifying records that refer to the same entity across datasets, is crucial to overcoming inconsistencies and discrepancies between datasets and building a comprehensive database."}, {"title": "2 Preliminaries and Related Work", "content": "In this section, we define record linkage (Section 2.1), distinguish PLMs and LLMs (Section 2.2), and review related work on utilizing PLMs and LLMs for record linkage (Section 2.3)."}, {"title": "2.1 Task Definition", "content": "We define the record linkage problem as follows:\nGiven a set of databases, $\\{D_1, D_2 \\cdot\\cdot\\cdot D_i \\}$, where $D_j$ represents a database, the task is to identify and link all records referring to the same entity within and across all available databases. Each entity is characterized by a set of general attributes (e.g., place name, available resources) and spatial attributes, which include point data that could be derived from line or polygon geometries. The linkage task involves matching entities across databases that may have different schemas and missing attributes (i.e., null values)."}, {"title": "2.2 Definition of PLMs and LLMS", "content": "In this work, we define pre-trained discriminative language models, which are encoder-based, as PLMs. Examples of PLMs include BERT [7], ROBERTa [38], and DistilBERT [30]. We refer to decoder-based generative language models, including all models developed after GPT-3 [5], as LLMs. Examples of LLMs include GPT-4 [36],"}, {"title": "2.3 Related Work", "content": "Record linkage is the task of integrating data to identify and link records in one or more databases that refer to the same entity. By linking different datasets, record linkage enhances the amount of information available for each record, resulting in a more comprehensive database.\nTraditional Record Linkage Earlier approaches [2] often use traditional string similarity metrics, such as Levenshtein distance or Jaccard similarity, to determine whether two records refer to the same entity. These methods rely on empirically defined rules and weights applied to manually selected attributes (e.g., name, social security, or phone number) to calculate the similarity score. To resolve ambiguities, researchers use crowd-sourcing to eliminate confounding factors or add additional details to assist the linking process in their models. As stated, these methods require extensive manual rule development and data processing. Our work aims to develop a fully automated process that minimizes or eliminates the need for human intervention.\nPLM-based Record Linkage To enhance the accuracy and scalability of entity linkage, recent approaches shift towards implementing deep learning models, such as Long Short-Term Memory (LSTM) [12] and BERT [7]. These approaches not only reduce manual processing but also enhance the accuracy of entity linkage. DeepER [9] introduces a method that uses LSTM networks and Global Vectors (GloVe) [26] text embeddings to capture semantic similarities between records. Similarly, Ditto [18] converts the details of each record to a sentence and uses Sentence-BERT [28] to generate contextualized embeddings for sentences. PLM-based record linkage methods have demonstrated enhanced performance by considering all attributes available in the data rather than focusing solely on manually selected key fields. However, their effectiveness is limited by the availability of training data. T\u00e4nzer et al. [33] demonstrates that PLM-based methods fail to predict a class when there are fewer than 25 instances of that class and require at least 100 labeled examples to achieve a reasonable level of accuracy. Our approach addresses this challenge by generating synthetic training data, which creates a framework that reduces dependency on large volumes of labeled data.\nLLM-based Record Linkage There is a growing interest in developing unsupervised or semi-supervised record linkage approaches to minimize the reliance on large labeled datasets. Large language models (LLMs), pre-trained on vast amounts of data, have shown the potential of being a zero-shot solution for record linkage across diverse domains. Narayan et al. [23] suggests applying LLMs to this task, achieving state-of-the-art results without fine-tuning the model for record linkage. The researchers use serialization methods to convert structured tabular data into textual inputs to formulate the record linkage problem as a text generation task. Peeters and Bizer [25] further demonstrate that domain-specific prompting (e.g., asking to identify for the same 'mine' instead of 'entity') and strict binary responses prompting (i.e., \"Yes\" or \"No\") lead to more stable results and significantly improve LLM's performance. LLMs such as Generative Pretrained Transformer (GPT) [27] and"}, {"title": "3 Proposed Approach", "content": "Our proposed record linkage method leverages the extensive knowledge of LLMs and the efficient inference capabilities of PLMs. The methodology comprises two main steps: (1) generating labeled training data using LLMs and (2) performing record linkage using a PLM. This two-step approach addresses the challenge of limited ground-truth training data and reduces the long inference times associated with relying solely on LLMs for the entire record linkage process."}, {"title": "3.1 Training Data Generation", "content": "To generate the training data, we use LLaMA3-8b [8], an open-source LLM. While larger and more recent models, such as GPT40 [36], may potentially offer better performance, we selected LLaMA3-8b due to computational constraints and the potential for fine-tuning the model to create more precise labels. Using this model allows for future optimization without overburdening available resources. Using LLMs as a method to generate training data involves framing the record linkage problem as a text-generation task. Therefore, we use the tabular data serialization method proposed by Narayan et al. [23]. Each entity's attributes and values are serialized as follows:\nserialize(e):=attr1:val\u2081...attri: vali\nFor record pair serialization, we follow the method proposed by Peeters and Bizer [25], prompting the LLM to label the record pairs using the following template:\nEntity A is serialize(A).\nEntity B is serialize(B).\nDo the two mine descriptions refer to the same real-world mine. Answer with 'Yes' if they do and 'No' if they do not.\nAnswer only in Yes or No.\nPrevious study [25] demonstrates that restricting responses to \"Yes\" or \"No\" improves the performance of LLMs. Without explicit prompts enforcing strict response formats (i.e., 'Answer only in Yes or No.'), LLMs tend to generate extended reasoning. To eliminate the need for manual post-processing, we limit the LLM's response to \"Yes\" or \"No\".\nWe convert the \"Yes\" or \"No\" labels generated by the LLMs into binary values, with 1 representing a match and 0 representing a non-match. This creates a dataset that follows the structure shown in Table 1. The columns uri_1 and uri_2 represent the unique ID"}, {"title": "3.2 Record Linkage", "content": "For the record linkage task, we utilize ROBERTa [38], a robustly optimized variant of BERT [7], as the PLM for fine-tuning. We select ROBERTa over BERT since RoBERTa shows better performance across various downstream natural language processing (NLP) tasks than BERT. This improvement is due to RoBERTa's training on a larger dataset, which increased from 16GB to 160GB [38] compared to BERT, resulting in a more extensive vocabulary. Our empirical results, detailed in Appendix B, demonstrate that fine-tuning RoBERTa outperforms BERT and other variants, such as DeBERTa [11].\nTo evaluate our approach, we fine-tune the model using LLaMA-labeled data. RoBERTa, similar to BERT, provides deeply contextualized embeddings that capture the semantic meaning of the input data, which is crucial for effective record linkage. To prepare the data, we adopt the text serialization approach proposed in Ditto [18] since the suggested method is widely used in PLM-based record linkage tasks (e.g., Balsebre et al. [1]). For each data entry, e=(attri,vali)1 \u2264 i \u2264 k, we serialize the attributes and values as follows:\nserialize(e):= [COL]attr\u2081 [VAL]val1\n[COL]attr; [VAL]vali\nwhere [COL] and [VAL] are special tokens indicating the start of attribute names and values, respectively.\nFor serializing record pairs (e1, e2), we use the following format:\nserialize(e1,e2):= [CLS] serialize(e\u2081)\n[SEP] serialize(e2) [SEP]\nwhere [CLS] is the special token indicating the beginning of the sequence, and [SEP] is the special token separating the two records\u00b3. We fine-tune the PLM so that, given a serialized record pair as input, it outputs one of the binary labels, which corresponds to match or non-match."}, {"title": "4 Evaluation", "content": "We evaluate the effectiveness of our proposed approach by applying it to mineral sites throughout the United States. For this evaluation, we use the Mineral Resources Data System (MRDS) [20] and the United States Mineral Deposit Database project (USMIN) [15] databases, which are comprehensive mineral site repositories recording various characteristics of mining sites, such as site names, alternative names, geographical locations, and the types of minerals present. The heterogeneity of these databases, in terms of schema"}, {"title": "4.1 Experimental Setup", "content": "In the following section, we detail the experimental setup used to evaluate our approach. This includes a comprehensive description of the training and testing dataset (Section 4.1.1), the evaluation metrics employed (Section 4.1.2), the validation process for the LLM model utilized in the training data generation (Section 4.1.3), the details on training the PLM (Section 4.1.4), and the details on the baseline methods (Section 4.1.5)."}, {"title": "4.1.1 Dataset", "content": "We use the Tungsten assessment dataset [10], a manually curated dataset by the USGS, to train one of the baseline models (detailed in Section 4.1.5) and to evaluate the performance of both the baseline models and proposed approach. This dataset contains records from the MRDS and USMIN databases focusing on Tungsten mining sites in Idaho and Montana. The Tungsten assessment dataset comprises 387 records (383 from MRDS and 4 from USMIN), generating a total of 74,691 potential record pairs for analysis. The count of match pairs and the count of non-match pairs are shown in Table 2.\nTo train our approach, we generate synthetic training data by asking an LLM to label \"Yes\" (later mapped to match) and \"No\u201d (later mapped to non-match) on randomly selected MRDS and USMIN records. We ensure that the volume of data-387 records and 74,691"}, {"title": "4.1.2 Evaluation Metrics", "content": "To evaluate the performance of our approach in classifying record pairs into each category, we measure three types of F1 scores: the match class F1 score (Equation 1), the non-match class F1 score (Equation 2), and the macro-averaged F1 score (Equation 3). In these equations, $tp$ represents the count of true positives, $tn$ represents true negatives, $fp$ represents false positives, and $fn$ represents false negatives.\nMatch F1 = $\\frac{2tp}{2tp + fp + fn}$      (1)"}, {"title": "4.1.3 LLM Performance Validation", "content": "Before generating the labeled training data, we first validate the performance of the LLaMA3-8b [8] model on the complete Tungsten and Nickel datasets, without partitioning the data into training, validation, and testing sets. For the 74,691 Tungsten record pairs, LLaMA has a match F1 score of 39.13% and a non-match F1 score of 99.96%. For the 276 Nickel pairs, LLaMA has a match F1 score of 70.96% and a non-match F1 score of 98.27%. Table 3 provides a breakdown of the number of correctly identified match and non-match pairs in relation to the total number of pairs available in the ground truth data.\nHowever, the inference time was substantial at approximately 3 hours on our computation resource (detailed in Section 4.1.6). The computation involves nC2 comparisons, where n represents the number of records. As a result, the number of combinations grows quadratically with the number of records, leading to a corresponding quadratic increase in time complexity. This highlights the impracticality of relying solely on LLMs for large-scale record linkage tasks, particularly in scenarios involving extensive datasets. Mineral site databases such as MRDS and USMIN are archives where sites have been recorded over decades and are represented by multiple records across various databases. For instance, the MRDS [20] contains over 300,000 records, and the USMIN database continues to expand [15]. The challenges regarding efficiency and scalability need to be addressed. To verify that our approach is more efficient compared to LLM-relying record linkage models, we compare the inference time based purely on LLM and our approach in relation to the number of records."}, {"title": "4.1.4 Fine-Tuning PLMs", "content": "We randomly select 80% of the LLaMA-labeled data to train a RoBERTa model [38] and evaluate its performance using 10% of the Tungsten ground truth data as the test set. We partition the data such that each subset contains a proportionate number of match and non-match samples, maintaining a balance across all data partitions. The model is trained for 10 epochs, and the best-performing epoch, as determined by the validation data,"}, {"title": "4.1.5 Baseline Methods", "content": "To evaluate the effectiveness of our approach, we compare it against four baseline methods: GT-Trained, Manually Curated, LLaMA3-8b, and GeoER:\nGT-Trained: This method uses 80% of the Tungsten ground truth (GT) data for training, 10% for validation, and 10% for testing. Similar to our approach, we partition the data so that each data partition contains a proportionate number of match and non-match samples. We fine-tune a RoBERTa model using the same hyperparameter settings as our approach to ensure a fair comparison.\nManually Curated: This method utilizes empirically defined distance thresholds and text similarity scores. We select parameters that yield the highest performance on the training and validation datasets, which consist of 90% of the Tungsten ground truth data. This method achieves optimal results with a 5-kilometer distance threshold and an 85% cosine similarity score for text embeddings generated using Sentence-BERT [29].\nLLAMA3-8b: This method relies exclusively on LLMs, specifically the LLAMA3-8b model, for mineral site record linkage. It does not incorporate spatial information or predefined thresholds.\nGeoER [1]: This method serves as a baseline method for spatial record linkage. To implement the GeoER framework, we reformat our data according to the authors' guidelines to ensure compatibility with their experimental setup. We maintain the original parameters defined by the authors6."}, {"title": "4.1.6 Hardware Details", "content": "We perform all experiments on one 40GB A100 GPU chip and dedicate 70GB of memory at most; the majority of the memory is used to load and use the LLaMA3-8b model for training data generation."}, {"title": "4.2 Experimental Results", "content": "Table 4 displays the match, non-match, and macro-averaged F1 scores of the baseline models and our proposed approach. All values are reported in percentage (%).\nAs shown in Table 4, our approach outperforms the GT-Trained model in both the match F1 score and macro-averaged F1 score"}, {"title": "4.2.1 Types of Error", "content": "In both the Tungsten and Nickel datasets, our approach encounters challenges due to unclear site distinctions. For example, our approach struggles to differentiate two sites named 'Unidentified Occurrence', treating them as identical sites. However, determining whether such cases should be classified as match or non-match is a complex design challenge (not a model error) in both manual and automated scenarios.\nUnlike the Tungsten dataset, the Nickel dataset contains uncleaned data, making the record linkage process more challenging. The Nickel dataset includes entries for large deposit regions (e.g., 'Duluth Complex') and records for multiple individual sites (e.g., 'Maturi, Birch Lake, and Spruce Road Copper-Nickel'). To illustrate the spatial coverage of these large deposits, Figure 11 shows the geographical spread of the 'Duluth Complex' in Minnesota. Since the 'Duluth Complex' encompasses multiple mineral sites, a practical model should exclude data representing a general region (e.g., 'Duluth Complex') when performing record linkage.\nThe current pipeline requires a one-to-one comparison between records, which leads to not capturing some links. In some cases, information needs to be inferred from other records, yet the current structure prevents such. For example, a record in the database may list 'Dunka Pit' as a potential alternative name for the 'Northmet Project. However, in a different dataset, this alternative name is not recorded. When the model compares this record with another that lists 'Dunka Pit' as the primary name, it fails to identify them as the same site, as it does not account for information found in out-of-pair records. We can potentially address this limitation by constructing a graph-like structure from the data. By treating each record as a node and each labeled match as a connecting edge, we can establish links across multiple records. This approach would allow us to link sites, such as the three aforementioned mines, based on their indirect connections through shared information."}, {"title": "4.2.2 Inferences Time", "content": "We compare the inference time of our approach against the LLaMA3-relying model. We measure the inference time by incrementing the testing size from 10 mineral site records (i.e., 45 pairs) to 300 mineral site records (i.e., 44,850 pairs). Figure 7 displays the inference time of each model in relation to the number of mineral site records. The green line shows the inference time when purely relying on LLaMA3-8b, and the blue line shows the inference time when using our approach. The time required for inference is lower for ours than relying on LLaMA. With the collected inference time, we derive an equation to estimate the required inference time for running it at the scope of the actual mineral site linkage task. Details are provided in Appendix C."}, {"title": "4.2.3 Training Data Size", "content": "T\u00e4nzer et al. [33] states that BERT models may not predict a specific label until the number of training samples exceeds a threshold. To better understand the relationship between data size, level of class imbalance, and performance, we perform additional experiments by varying the training dataset size. In all experiments, we use LLM-labeled data to fine-tune the ROBERTA model and evaluate the model using the Tungsten ground truth dataset."}, {"title": "5 Discussion and Future Work", "content": "Linking mineral site records is an essential task for mineral deposit prospecting and resource management [17]. These records are often sourced from structured databases like MRDS and USMIN, but they can also be extracted from reports, webpages, or other unstructured data. The complexity of this task stems from several factors, including ambiguous or incomplete location data, inconsistent site naming conventions, and unreliable geographical distances. In this paper, we propose a method leveraging LLMs to generate training data for mineral site record linkage, addressing the challenges of limited ground-truth data. Our approach demonstrates the potential of using LLM-generated data to fine-tune PLMs, achieving improved performance compared to models trained on imbalanced ground-truth datasets. Future work will focus on refining our proposed method and addressing two key questions to enhance model performance further:"}, {"title": "5.1 How can spatial data be more effectively integrated into the pipeline?", "content": "At the current stage, spatial data has been treated as part of the input string to the PLM without special handling; the main goal of the research is to demonstrate the potential of leveraging LLMs to generate training data to fine-tune PLMs. However, we recognize the importance of preserving the spatial semantics in the data. Moving forward, we plan to explore more effective ways to incorporate spatial attributes into the PLM to enhance its accuracy in handling the spatial dimension of such data.\nWe propose three potential approaches for this. We can utilize spatial distance between records, as demonstrated by Balsebre et al. [1], using haversine distance to create distance embeddings concatenated with the serialized record pair embedding. Alternatively, the spatial distance can be embedded in each serialized entity using a spatial coordinate embedding, as suggested in SpaBERT [19]. For the third approach, we can incorporate spatial location as an additional attribute for each record. We can convert the latitude and longitude values into point embeddings and concatenate them to each serialized entity embeddings."}, {"title": "5.2 Can LLMs generate sufficient data for training?", "content": "We have observed performance improvements with the increased number of match samples (i.e., positive samples) in the training data. The current data generation process randomly selects potential record pairs without ensuring a sufficient number of match samples. Therefore, to gather a sufficient number of training data, we need to execute the LLaMA labeling pipeline iteratively until the training data includes an adequate number of match samples.\nA logical next step is to investigate whether increasing the number of match samples leads to additional performance gains. Previous research [4] demonstrates that LLMs can generate synthetic tabular data. We aim to explore whether LLMs can synthesize entirely new data that replicate the patterns of match and non-match records in the existing dataset. This could balance the representation of match samples and further improve the performance of pre-trained language models (PLMs) when trained on LLM-generated data.\nBy combining the efficiency of PLMs with the advanced data generation capabilities of LLMs, we have demonstrated that our approach offers a scalable and automated solution to these challenges. Our results show that LLM-generated data can significantly reduce the need for manual data curation and support more accurate and efficient record linkage across large-scale datasets. Moving forward, we will continue to enhance our method to fully understand the potential of LLMs in addressing complex real-world data challenges with greater efficiency and accuracy."}, {"title": "Ethical Consideration", "content": "We acknowledge that the proposed approach allows third-party LLMs to access the data to generate training datasets.\nWhile our approach enhances the efficiency of the record linkage process, it is essential to recognize that using LLMs does incur energy consumption and contributes to carbon emissions. However, our method minimizes these environmental costs by utilizing LLMs only during the training data generation phase rather than relying on LLMs throughout the entire record linkage process.\nAdditionally, LLMs may generate data that deviates from the ground truth pattern. These hallucinations pose risks to PLMs trained on such data, potentially causing erroneous outcomes. Careful validation of LLM-generated data is essential to prevent the propagation of inaccurate information. To apply the proposed approach in practical record linkage applications, robust safeguards and error detection mechanisms will be essential to ensure reliability and accuracy."}, {"title": "C Runtime Estimation for Full Mineral Site Data", "content": "Using the recorded inference times, we extrapolate the data to estimate the time required to compare 300,000 records, which reflects the scope of the mineral site linkage task. To extrapolate, we derive a quadratic function that relates inference time (time) to the number of records (countms).\nFor the LLAMA model, we approximate the inference time (in seconds) with the following equation:\ntime = 0.073 \u00b7 (countms - countms)   (4)\nFor our approach, we approximate the inference time (in seconds) with the following equation:\ntime = 0.004. (countms - countms)  (5)\nBased on these calculations, our approach can complete the task in approximately 4,166 days, whereas relying solely on the LLaMA model will require around 76,000 days. However, we can filter out many candidate pairs through basic spatial comparisons. For example, a mineral site in the central United States is unlikely to be linked with a mineral site in the southeastern United States; we can eliminate these pairs before running the model. As a result, the actual inference time will be lower than the estimated values."}]}