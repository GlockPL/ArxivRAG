{"title": "Self-Supervised Learning and Opportunistic Inference for Continuous Monitoring of Freezing of Gait in Parkinson's Disease", "authors": ["Shovito Barua Soumma", "Kartik Mangipudi", "Daniel Peterson", "Shyamal Mehta", "Hassan Ghasemzadeh"], "abstract": "Parkinson's disease (PD) is a progressive neurological disorder that impacts the quality of life significantly, making in-home monitoring of motor symptoms such as Freezing of Gait (FoG) critical. However, existing symptom monitoring technologies are power-hungry, rely on extensive amounts of labeled data, and operate in controlled settings. These shortcomings limit real-world deployment of the technology. This work presents LIFT-PD, a computationally-efficient self-supervised learning framework for real-time FoG detection. Our method combines self-supervised pre-training on unlabeled data with a novel differential hopping windowing technique to learn from limited labeled instances. An opportunistic model activation module further minimizes the power consumption by selectively activating the deep learning module only during active periods. Extensive experimental results show that LIFT-PD achieves a 7.25% increase in precision and 4.4% improvement in accuracy compared to supervised models while using as low as 40% of the labeled training data used for supervised learning. Additionally, the model activation module reduces inference time by up to 67% compared to continuous inference. LIFT-PD paves the way for practical, energy-efficient, and unobtrusive in-home monitoring of PD patients with minimal labeling requirements.", "sections": [{"title": "I. INTRODUCTION", "content": "Parkinson's disease (PD) is a progressive neurological disorder affecting 7\u201310 million people worldwide, significantly impacting their quality of life. Freezing of Gait (FoG), a transient inability to produce effective steps during walking [1], is one of the most debilitating symptoms of PD, leading to poor mobility, increased risk of falls and injuries, and reduced quality of life. While treatments like levodopa can sometimes reduce the severity of freezing episodes, their effectiveness is often incomplete and variable, diminishing over time [2]. Compensatory treatments such as on-demand cueing require patient or companion initiation, which can be challenging in time-sensitive or anxiety-provoking situations that trigger freezing [3]. Identifying FoG events and, more importantly, the time leading up to a FOG event could result in early deployment of on-demand cues to help reduce the severity of a freezing event [4].\nIn recent years, wearable technology and machine learning (ML) algorithms have emerged as promising tools for continuous monitoring and management of PD symptoms, including gait disturbances and tremors [5]\u2013[7] However, real-world deployment of these technologies for continuous monitoring and intervention has remained a significant research challenge. One major hurdle is the scarcity of labeled data essential for training robust ML models, particularly in PD, where symptom manifestation is highly individualized. Data annotation requires considerable time and expertise, limiting the availability of accurate and diverse datasets [8].\nDetecting FoG using a patient-independent model is a complex task due to significant inter- and intra-variability in patients' gait patterns. Previous research on FoG detection relied on multiple sensors, extensive feature engineering, patient-specific data collection, and model retraining [9]\u2013[11]. To address these challenges, we present an innovative label-efficient, patient-independent, and robust self-supervised learning framework, LIFT-PD (Label-efficient In-home Freezing-of-gait Tracking in Parkinson's Disease), for detecting FoG events in real-time. Our extensive results demonstrate that the proposed self-supervised model achieves comparable performance to baseline supervised models, despite using much fewer labeled instances and in an unsupervised fashion. Furthermore, we devise a novel opportunistic-based lightweight algorithm that reduces the complexity of model execution and processing time, paving the way for implementation in a stand-alone wearable system for real-time symptom monitoring."}, {"title": "II. RELATED WORK", "content": "Prior work can be summarized into two categories including (1) self-supervised learning (SSL) for motion analysis; and (2) automatic detection of FoG events.\nThe SimCLR SSL technique was originally designed for computer vision tasks, [13], but was later adapted for human activity recognition (HAR) using a transformer-based encoder method [14]. Although MLPs are not popular for vision or language datasets, they are effective in making predictions on tabular health data [15], [16]. Previous work also introduced transfer learning [16], data augmentation technique and re-sampling, which are efficient in scenarios with limited labeled data [17]. The efficacy of self-supervised learning in medical time series analysis has been demonstrated, emphasizing its role in data augmentation and contrastive pair formation [18].\nThe detection of FoG events in PD has been the subject of extensive research, often involving multimodal datasets. In particular, prior work explored the effectiveness of different sensor modalities such as gait acceleration, electroencephalo-gram (EEG), electromyography (EMG), and skin conductance (SC) in FoG detections [19]. Furthermore, researchers used an LSTM-based model combining acceleration and synthetic EEG data [20].\nLIFT-PD overcomes key limitations of these studies, such as limited generalizability, reliance on extensive labeled data, and high computational complexity. In contrast, our proposed method, LIFT-PD, addresses these limitations by introducing a self-supervised learning framework tailored for real-time FoG detection using a single accelerometer sensor."}, {"title": "III. LIFT-PD SYSTEM DESIGN", "content": "Training robust deep learning (DL) models typically requires large amounts of labeled data, which can be challenging to obtain, especially for tasks like freezing of gait (FoG) detection in elderly. To address this issue, LIFT-PD employs self-supervised learning to utilize unlabeled data during training. Another challenge that we face while designing ML models for FoG detection is that FoG events are sparse, resulting in an imbalanced dataset with a significantly lower proportion of FoG episodes compared to non-FoG activities. To mitigate this challenge, we incorporate the Differential Hopping Windowing (DHW) Technique during data preprocessing, which applies variable overlaps for FoG and non-FoG instances, thereby enhancing the model's ability to learn from the underrepresented class. Finally, an opportunistic-based lightweight algorithm is introduced to reduce execution complexity, allowing for implementation in stand-alone wearable devices (Section III-B)."}, {"title": "A. Problem Modeling by Self-Supervised Learning (SSL)", "content": "The FoG event detection problem is framed as a multivariate time-series classification task. At each time stamp t, the input raw signal is represented as a vector $x_t = [x_1, x_2, x_3]$ where $x_t \\in R^{C=3}$ and C corresponds to the three-channel (x, y, z) accelerometer data. These raw signals are then combined into a matrix, $X = [x_1,x_2,...,x_T] \\in R^{T\\times C}$. After applying the DHWT method, the signals are transformed into N number of training frames (windows) $(X \\in R^{T\\times C} \\rightarrow X_w \\in R^{N\\times T'\\times C'})$ where $x_{w_i} \\in X_w$ represents ith window, T' is the windowing time length and $Xw = [X_{w1}, X_{w2}, ..., X_{wN}]$.\n$D : X \\in R^{T\\times C} \\rightarrow X_w \\in R^{N\\times T'\\times C}$ \n$X_w = [X_{w1}, X_{w2}, ..., X_{wN}]$\nThe ultimate goal is to correctly assign a label y \u2208 {0,1} to each window, where y = 1 represents \u201cFoG\u201d and y = 0 represents \"non-FoG\".\nLIFT-PD uses SSL for FoG detection in two steps: learning contextual representations from raw signals using a 1D CNN model, followed by performing the downstream FoG detection task. In this paper, raw accelerometer signals are used as physiological signals and the downstream task is binary 'Freezing of Gait' detection. In the following subsections, we describe in detail the two main components of our SSL approach:\n1) Pretext Task (Signal Reconstruction): During pre-training, a 3-layer neural network model with an encoder is trained using SSL. Random segments of fixed length m are masked from each window, $x_{w_i}$ by replacing them with zeros. The model is then trained to predict these masked values, as shown in Fig. 1 (Part 1). This whole training process does not need any labeled data. The masked signal data $X_w \\in R^{N\\times T'}$, is defined by $X_w = mask(X_w, m)$ where $w_i \\in X_w$ . The encoder $f_\\theta : R^{N\\times T'} \\rightarrow R^{N\\times D}$ reconstructs the original signal from the masked windows, producing a lower"}, {"title": "B. Opportunistic Inference", "content": "To optimize power consumption and computational resources for real-life in-home PD monitoring using wearable devices, we propose an opportunistic-based naive algorithm as a model activation module (MAM). This module differentiates between active and inactive periods, activating the computationally heavy self-supervised learning (SSL) FoG detection model only during identified active intervals, as shown in Fig. 2. The activation module filters out inactive windows, ensuring the SSL model is selectively executed only when activity is detected, significantly reducing power consumption and avoiding false positives during inactivity. During inactive periods, simpler methods handle the data by comparing the magnitude of the current incoming signal, leading to more efficient power utilization. For each window i \u2208 [1, N], the magnitude $M_i$ of the 3D accelerometer is calculated as $M_i = \\sqrt{a_{x_t} + a_{y_t} + a_{z_t}}$ where $a_x$, $a_y$, and $a_z$ are the acceleration signal along each axis. A window is considered active if $M_i > \\alpha$, where \u03b1 is a predefined threshold (Eq. 1), otherwise MAM discards it.\n$ \\begin{cases} 1 \\text{ (active)} & \\text{if } M_i > \\alpha \\\\ 0 \\text{ (inactive)} & \\text{otherwise} \\end{cases} $     (1)"}, {"title": "C. Imbalanced Training Data Mitigation", "content": "Our proposed dataset generation method (DHWT) effectively handles imbalanced datasets without the need for additional preprocessing, balancing informative features with computational efficiency for real-time deployment on wearable devices. We segment raw sensor data into short, overlapping windows, adjusting the overlap based on activity type. For instance, in our experimental evaluation shown in Fig. 3a, we applied a 50% overlap for non-FoG periods and a 75% overlap for FoG episodes during training. During inference, windows are segmented using standard, non-variable overlaps to simulate real-world conditions where FoG episodes are not pre-identified. Using fixed-length overlaps typically results in an unbalanced training set, as illustrated in the left bar of Fig. 3b, with 63.3% non-FOG and 36.7% FOG instances. In contrast, the DHWT segmentation approach achieves a more balanced distribution, as shown in the right bar of the same figure, with non-FOG and FOG data at 45% and 55%, respectively. For test set generation, standard segmentation with a fixed 50% overlap (advancing every 1.5 seconds) mimics actual operating conditions, processing data from the preceding 3 seconds."}, {"title": "D. Dataset", "content": "The dataset for this study is the publicly available tDCS FoG dataset, comprising movement data from PD subjects in both medicated ('On') and unmedicated ('Off') states during Freezing of Gait (FoG) provocation protocols [21]. Data were collected using a 3D accelerometer attached to the lower back, recording at 128 Hz, resulting in 1132 FoG episodes (285 minutes total) and 15.3 hours of recording. Each FoG episode was videotaped and annotated by experts. The demographic and clinical characteristics of the subjects are summarized in Table II. The dataset contains events labeled as \"Normal\" or \"Freezing of Gait\" (FoG). The distribution of these events is summarized in Table III. The sessions followed the FOG provocation protocol as described in seminal studies by Reches et al. [22] and Manor et al. [23], and originally defined by Ziegler et al. [24].\nWe resampled the data to 40 Hz, which is considered an effective frequency for recognizing human activity through accelerometers in both healthy individuals and PD patients, including those experiencing Freezing of Gait (FoG) episodes. This frequency captures the typical freeze band (3-8 Hz) while reducing memory load and computational complexity."}, {"title": "E. Mean Value Removal and Labeling", "content": "After segmentation, we perform minimal pre-processing on each window by removing the mean value from each of the sensor axes (e.g., x, y, z). This centering of the data mitigates sensor bias and reduces computational complexity. Finally, we assign labels to the windows based on their content: non-Fog for windows containing only non-FoG data, and FoG for windows with at least 50% FoG data. Any windows containing a mix of both activities are discarded to ensure clear classification during the machine learning stage. This minimal preprocessing approach prioritizes real-time performance while preserving features relevant for FoG detection."}, {"title": "F. Leave One Group Out (LOGO)", "content": "In order to evaluate the subject-independence, we perform a leave-one-group-out cross-validation. The whole tdcs dataset is divided into two groups, each of them consisting of randomly chosen 20 patients. The two groups are generated so that patients in each group have similar characteristics in terms of age, duration of symptoms, and UPDRS. Hence, the patient-independent model is trained using 20 patients from each group using SSL, while the left-out group is stripped of its labels for validation. The classification performance for the left-out groups of patients is then evaluated and compared with our baseline supervised model. This procedure is repeated for each group within the dataset, conducted three times, and the results are averaged to ensure reliability and robustness in our findings."}, {"title": "G. Model Development & Experimental Setup", "content": "For our downstream task, we devise a 5-layer 1D Convolutional Neural Network (CNN) architecture in LIFT-PD (Fig. 4), allowing us to use raw sensor data without extensive feature engineering. The model consists of an encoder block for feature extraction and a classification block for FOG detection. The encoder block has five 1D convolutional layers (filters: 64, 128, 256, 128, 64; kernel size: 3; ReLU activation) with max-pooling (pool size: 2) after the second layer and global average pooling (pool size: 2) after the fifth layer to downsample feature maps, reducing complexity. The flattened output is passed through an MLP with two dense layers (units: 128, 64; ReLU activation; dropout: 0.4 after the first layer) for binary classification, with a final dense layer (unit: 1; sigmoid activation) providing the FoG detection output.\nThe model was trained in two phases: pre-training and fine-tuning. In the pre-training phase, the encoder was trained for 70 epochs with a batch size of 64, using the Adam optimizer set to a learning rate of 0.01 and a decay of 0.001. During the fine-tuning phase, the additional dense layers were randomly initialized. The model was fine-tuned on labeled data for 40 epochs, maintaining the same batch size but with a reduced learning rate of 0.0001 for the classification task. The use of a lower learning rate (0.0001) during the fine-tuning phase is a common practice when working with pre-trained models. This lower learning rate helps preserve the learned features from the pre-training phase and ensures gradual adjustments, avoiding the drastic loss of previously learned representations.\nAll experiments (pre and post-processing) were performed on a computer with an Apple M2 Pro chip, which includes a 16-core Neural Engine, and 16 GB of unified memory. Training, optimization, and testing of the classification model were performed in Python (3.8), using the Keras (2.4), and TensorFlow (2.3) libraries."}, {"title": "H. Performance Measures", "content": "To evaluate the performance in FOG detection at window-level of our proposed framework and those reproduced from the state-of-the-art approaches, commonly used metrics were calculated and reported.\nIn this binary classification problem (FoG or non-FoG), performance metrics include sensitivity, specificity, F1 score, and AUC of receiver operating characteristics. We extensively evaluated our proposed system using these metrics, comparable to other state-of-the-art methods. True positives (TP) are correctly identified FoG windows, while false positives (FP) are non-FoG windows incorrectly labeled as FoG. False negatives (FN) are real FOG windows not recognized, and true negatives (TN) are correctly classified non-FoG instances. Fig. 5 schematically describes these metrics.\nSensitivity/Recall measures the ratio of correctly detected FOG windows and specificity measures the ratio of correctly identified non-FoG windows. Precision evaluates the model's ability to avoid false positives. The F1 score is the harmonic mean of sensitivity and precision which is used to assess performance on the imbalanced dataset [25]."}, {"title": "I. FoG Detection Post-processing", "content": "For further evaluation of our LIFT-PD framework, a post-processing analysis was performed using predictions and class labels. The performance of true FoG episode (TFE) detection was performed by analyzing groups of consecutive windows with the presence of freezing episodes, besides the window-level FoG detection.\n1) FoG Episode: In our study, we assessed the detection of FoG episodes\u2014defined as consecutive windows labeled as FoG-by computing both the percentage of episodes detected and the proportion of FoG accurately identified within each episode. An episode is considered detected if at least one window within it is correctly identified. FoG episodes were categorized into three groups: short (< 6 seconds), medium (6-12 seconds), and long (> 12 seconds).\nThen we calculated the percentage of FoG episodes detected across the entire dataset and for each duration group. We also measured the proportion of accurately detected FoG windows within each episode (Fig. 5D), defined as $D_{FOG}(\\%) = \\frac{N_{detected}}{N_{total}}$ , where $N_{detected}$ represents the number of detected FoG windows, and $N_{total}$ is the total FoG windows in that episode.\nFor false FoG episodes, we calculated the minimum distance between each falsely detected episode (Fig. 5B) and the nearest true FoG window (Fig. 5A) to understand the proximity of false positives to actual FoG occurrences. Finally, we evaluated FoG detection latency, defined as the time difference between the onset of an actual FoG episode and the detected FoG episode (Fig. 5L). This metric reflects the algorithm's responsiveness in identifying FoG events, which is crucial for the timely intervention and management of PD patients.\n2) Computational Complexity: To evaluate the feasibility of deploying our LIFT-PD framework on low-resource wearable devices, we performed several analyses. We assessed training and testing times for different input sizes to identify the optimal training size for the self-supervised pre-text task using varying amounts of unlabeled data. Post-training, we measured inference times across different input sizes to gauge real-time performance.\nWe also analyzed memory requirements for storing input sensor data and model parameters, ensuring suitability for resource-constrained devices. To optimize power consumption and enable long-term in-home monitoring, we introduced an Activity Threshold Optimization (ATO) algorithm (Algorithm 1), activating the FoG detection model only during active periods. Assuming that the performance function P and the computation of active windows $N_a$ can be performed in constant time, the overall runtime excluding the inference model is $O(N \\cdot \\lambda_{max})$. Including the inference model's runtime O(M), where M is the process time of a single active window, the adjusted complexity becomes $O((M + N) \\cdot \\lambda_{max})$. In the best-case scenario, where the optimal threshold $\\lambda_{opt}$ is found in the first iteration, the runtime is O(N)."}, {"title": "IV. RESULTS", "content": "We evaluated the performance of the LIFT-PD framework using mainly sensitivity, and specificity along with some other matrices (percentage of detected episode, latency, precision, F1 score, and AUC of the ROC curve), comparing it against a baseline supervised model with the same architecture and parameters. This comprehensive evaluation highlights the benefits and potential limitations of our self-supervised learning (SSL) approach for real-time FoG detection.\nTable IV summarizes the metrics, showing that the SSL model achieved notable improvements: a 7.25% increase in average precision, 4.4% in accuracy, and 6.5% in specificity compared to the baseline supervised model. Importantly, the SSL model maintained consistent recall/sensitivity (84%) with the baseline, ensuring that the detection of FoG episodes was not compromised despite reduced supervision. The F1 score, which balances precision and recall, was higher by about 3.95% in the SSL model, indicating better overall performance in detecting FoG episodes.\nGroup 2 outperformed Group 1 in all metrics. Group 1's lower precision (0.66) was due to more false positives from a higher proportion of FoG events. The DHW technique with SSL mitigated data imbalance, enhancing performance despite class imbalances in Group 1. The ROC curves in Fig. 6 showed that the SSL model had a slightly larger area under the curve (0.908) than the supervised model (0.9078), indicating better FoG classification performance. The close proximity of the AUC values between the two models highlights the robustness of our SSL approach in achieving comparable performance to the supervised baseline, despite leveraging limited labeled data during training.\n1) Generalizibility of DHWT: We expanded our analysis to Daphnet [26] and two activities from MotionSense [27] (as a binary classification), in addition to the primary tdcs dataset. The results show an increase in training time across the datasets due to class imbalance handling, while the inference time remained stable. DHWT significantly improved precision, F1-score, and specificity in datasets with class imbalance, confirming its effectiveness across diverse conditions. Daphnet showed a 161% boost in precision and a 108% improvement in specificity. These results support the generalizability of DHWT without compromising computational efficiency (Table VI).\n2) Robustness Across Diverse Subjects: To ensure generalizability, we split the dataset(N=40) into diverse groups based on key characteristics such as severity (Mild N=14), gender (Male N=32) and age (Mid-age N=20). These groups were deliberately formed to include outliers and reflect real-world diversity, ensuring that the model can handle a variety of subject profiles without overfitting to any particular population. We observed performance improvements in F1 scores, accuracy and specificity in all groups, particularly in mild cases and older age groups, confirming that the method works effectively even with varied patient characteristics.\nRegarding the medication status, we evaluated the model separately on data from patients in their \u201cOn\u201d and \u201cOff\u201d medication states. Patients in the \"On\" state generally show fewer motor symptoms due to the effects of dopaminergic treatment, while the \"Off\" state is marked by more pronounced motor symptoms, including fluctuations. Interestingly, when both \"On\" and \"Off\u201d states were combined during training, the model demonstrated superior results by better capturing the intra-patient variability between medicated and unmedicated states (Random group-2). This suggests that LIFT-PD can adapt to fluctuating motor symptoms effectively, providing accurate detection across different medication states, which is critical for real-world clinical monitoring and intervention planning."}, {"title": "B. Compare with State-of-the-Art Models", "content": "Table VII compares the performance of our LIFT-PD model with state-of-the-art methods for detecting FoG in PD patients. Although the Multi-head CNN [12] achieves the highest detection rates for FoG episodes (97.27%) and windows (94.64%), its precision (0.545) and specificity (0.491) are low, indicating a high false positive rate. High false positives can reduce the effectiveness of cueing due to patients' adaptiveness to \"always on\" interventions [28] [29]. The one-class classifier [10] shows high precision (0.856) and specificity (0.891) but lower recall (0.716), missing many true FoG events, which can lead to inadequate monitoring and delayed interventions. The semi-supervised model [11] shows a recall around 12% lower and specificity approximately 13% lower than LIFT-PD, making it less suitable for in-home monitoring with a single accelerometer."}, {"title": "C. Duration Based FoG Episode", "content": "Table VIII presents the detection rates for FoG episodes and windows, along with associated latency metrics, grouped into short, medium, and long durations. Our SSL model's performance is compared with a baseline supervised model (metrics in parentheses).\nThe SSL model shows robust performance across all durations, with detection rates increasing as the episode lengthens. This trend is mirrored in the baseline model's performance, indicating a consistent improvement across different modeling approaches. For short episodes, the detection rate is 83.3% for episodes and 68% for windows, with an average latency of 2.42\u00b10.45 seconds. For long episodes, these rates rise to 100% for episodes and 91.1% for windows, with a latency of 2.64\u00b11.45 seconds. The increasing detection rates for longer episodes are due to the more prominent and persistent FoG characteristics, such as tremors and shuffling gait, which the SSL model effectively captures. The increasing detection rates for longer episodes are due to the more prominent and persistent FoG characteristics, such as tremors and shuffling gait, which LIFT-PD effectively captures.\nLatency, representing the detection delay from episode onset, slightly increases with duration. Small episodes have an average latency of 2.42\u00b10.45 seconds, while long episodes reach 2.64\u00b11.45 seconds. Maximum latency values increase from 4.5 seconds for small episodes to 9.75 seconds for long ones, reflecting the need to analyze more data over time to confidently detect FoG onset. Despite this latency increase, the detection accuracy for longer episodes remains superior, showing the SSL model's effectiveness in real-world applications by balancing latency and accuracy for reliable FoG detection across varying episode durations."}, {"title": "D. Threshold Effect in MAM", "content": "To determine the optimal activity threshold for the MAM, we evaluated the impact of different threshold values on various performance metrics, as presented in Table IX and Fig. 7. As observed in Table IX, lowering the activity threshold (e.g., 0.0) results in higher sensitivity (0.884) and higher detected FoG episode (DFE) rate (0.92), indicating that more FoG events are detected. However, this comes at the cost of lower specificity (0.78) and a higher inference time (3.31 ms) due to the SSL model being activated more frequently, even during inactive periods. Conversely, increasing the activity threshold (e.g., 1.2) leads to higher specificity (0.846) and a lower rejection ratio (0.59), implying that fewer false positive detections occur during inactive periods. However, this improvement is accompanied by a slight decrease in sensitivity (0.845), DFE rate (0.809), and an increase in the number of missed FoG events."}, {"title": "E. Effect of Labels During Pre-training", "content": "Fig. 8 illustrates how varying the label ratio (on the x-axis) impacts the performance (on the y-axis) of the self-supervised learning (SSL) and supervised models during training. As the ratio increases from 0.2 to 0.7, (meaning more labeled data is available for training), both models generally show an upward trend in metrics such as precision, recall, F1-score, and accuracy, which aligns with the expected behavior when more labeled data is available. However, a notable observation was the SSL model's superior stability and consistency compared to the supervised counterpart, which displayed sharper performance fluctuations across different label ratios. This steadiness underscores the SSL model's robustness and reduced sensitivity to the availability of labeled data during training. It also highlights the model's capability to leverage pre-training on unlabeled data to learn generalized features transferable to the target task.\nFig. 8 also shows that SSL model not only competes closely but sometimes outperforms the supervised model, especially with 40-60% labeled data. This indicates that the SSL model can achieve promising results with fewer labeled instances, making it highly efficient and adaptable for scenarios where obtaining large amounts of labeled data is challenging."}, {"title": "F. Post Processing", "content": "The post-processing analysis evaluated the temporal dynamics between false positives (FPs) and true FoG episodes (TFE) detected by the LIFT-PD framework.\nOn average, FPs occurred 16 seconds after the previous TFE and 18.5 seconds before the next true episode, suggesting they often arise from residual motor instability or sensor inaccuracies immediately following an actual FoG event. Our 'Pre FP Analysis' shows that FPs were found to occur approximately 14 seconds away from the nearest TFE, indicating the system's high sensitivity to subtle motor pattern changes preceding or following a FoG episode. These false alarms could serve as precursors or warnings of impending FoG events, providing valuable time windows for treatment adjustments.\nTo address isolated false detections, a majority voting scheme was implemented. If a window's classification differed from its immediate neighbors, it was adjusted to match them, smoothing the detection sequence. This approach improved the detection performance, increasing the detected true FoG episodes from 88% to 89.8% and true FoG windows from 83.85% to 84.64%."}, {"title": "V. DISCUSSION & CONCLUSION", "content": "In this study, we introduced LIFT-PD, a computationally simple self-supervised learning framework for real-time and patient-independent detection of Freezing of Gait (FoG) episodes in patients with Parkinson's Disease (PD). LIFT-PD addresses critical challenges in continuous, in-home monitoring by eliminating the need for extensive labeled data, employing a unique differential hopping windowing technique to handle imbalanced datasets, and optimizing power consumption through opportunistic model activation. Our results show that LIFT-PD achieves performance comparable to the state-of-the-art methods while consuming less power and needing fewer annotated training samples, making it effective, generalizable, and suitable for deployment on wearable devices. Its ability to function with minimal data annotation and handle imbalanced datasets reduces the burden on healthcare providers, improving cost-effectiveness. It uses a single triaxial accelerometer, operates directly on raw sensor data without extensive preprocessing, and selectively activates the model only during active periods, significantly enhancing energy efficiency. By relying on a single, easily wearable sensor, the system enhances patient comfort, making it feasible for continuous, real-world monitoring in home environments.\nFrom a clinical perspective, LIFT-PD can play a crucial role in the management of FoG, which is often unresponsive to traditional PD medications. Accurate detection of FOG events, as demonstrated by LIFT-PD, allows for the timely delivery of external cues, such as rhythmic tones or vibrotactile stimulation, which can help break or prevent FoG episodes without causing habituation. This targeted cueing approach enhances treatment efficacy and supports more personalized interventions [3], [30]. The system's real-time, continuous monitoring capability using a single triaxial accelerometer makes it practical for in-home use, providing clinicians with more comprehensive data on the patient's condition outside clinical settings.\nOverall, LIFT-PD provides a practical, real-world solution for FoG detection, improving PD management, and improving patient quality of life. By providing continuous, real-time monitoring in home environments, the system supports more accurate assessments of a patient's condition outside of clinical settings."}]}