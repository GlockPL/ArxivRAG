{"title": "Towards Non-invasive and Personalized Management of Breast Cancer Patients from Multiparametric MRI via A Large Mixture-of-Modality-Experts Model", "authors": ["Luyang Luo", "Mingxiang Wu", "Mei Li", "Yi Xin", "Qiong Wang", "Varut Vardhanabhuti", "Winnie CW Chu", "Zhenhui Li", "Juan Zhou", "Pranav Rajpurkar", "Hao Chen"], "abstract": "Breast magnetic resonance imaging (MRI) is the imaging technique with the highest sensitivity for detecting breast cancer and is routinely used for women at high risk. Despite the comprehensive multiparametric protocol of breast MRI, existing artificial intelligence-based studies predominantly rely on single sequences and have limited validation. Here we report a large mixture-of-modality-experts model (MOME) that integrates multiparametric MRI information within a unified structure, offering a noninvasive method for personalized breast cancer management. We have curated the largest multiparametric breast MRI dataset, involving 5,205 patients from three hospitals in the north, southeast, and southwest of China, for the development and extensive evaluation of our model. MOME demonstrated accurate and robust identification of breast cancer. It achieved comparable performance for malignancy recognition to that of four senior radiologists and significantly outperformed a junior radiologist, with 0.913 AUROC, 0.948 AUPRC, 0.905 F1 score, and 0.723 MCC. Our findings suggest that MOME could reduce the need for biopsies in BI-RADS 4 patients with a ratio of 7.3%, classify triple-negative breast cancer with an AUROC of 0.709, and predict pathological complete response to neoadjuvant chemotherapy with an AUROC of 0.694. The model further supports scalable and interpretable inference, adapting to missing modalities and providing decision explanations by highlighting lesions and measuring modality contributions. MOME exemplifies a discriminative, robust, scalable, and interpretable multimodal model, paving the way for noninvasive, personalized management of breast cancer patients based on multiparametric breast imaging data.", "sections": [{"title": "Introduction", "content": "Breast cancer is the primary cause of cancer mortality in females worldwide [1]. Early detection and accurate, systematic treatment are crucial for reducing mortality, requiring precise malignancy screening and guidance by molecular subtyping and treatment response estimation [2], informed by breast cancer examinations and analytics. Breast magnetic resonance imaging (MRI) is the radiology technique with the highest sensitivity for breast cancer detection and plays an indispensable role in breast cancer screening and staging for high-risk women [3], holding promise as a non-invasive investigation approach. It is also recommended as a screening technique for women with dense breasts, a condition that is prevalent among women in Eastern populations, such as those in China [4]. Currently, reading breast MRI is majorly based on the American College of Radiology Breast Imaging Reporting and Data System (BI-RADS) [5], which requires comprehension of the information from multiparametric MRI data, routinely including the dynamic T1-weighted dynamic contrast-enhanced sequence (DCE-MRI), the T2-weighted imaging (T2WI), and the diffusion-weighted imaging (DWI) to improve differentiation of breast lesions.\nArtificial Intelligence (AI), typically deep learning [6], has shown remarkable progress in healthcare [7], including breast cancer imaging [8]. Despite the increasing diagnosis accuracy reported for AI-based breast cancer diagnosis, existing studies were mostly based on DCE-MRI [9-12], one single modality that often leads to high sensitivity with moderate specificity. However, the diagnosis and prognosis based on breast MRI is routinely a multiparametric process, and how other sequences may help in increasing the specificity and overall accuracy remains to be explore [13-16]. Apart from the challenges brought by the collection of the multi-sequence data, multimodal integration also faces technical difficulties raised by the heterogeneity and high dimensionality [17]. Specifically, different modalities often require tailored representation learners, and a meticulously designed fusion module is demanded for heterogeneous information interaction modeling. Such an architecture is absent in the literature on AI-based breast MRI analysis, and its clinical value remains to be further investigated.\nAs a recent generation of AI, foundation models (FMs) [18] were heralded as a promising solution to comprehend the heterogeneous multimodal information [19]. Particularly, FMs are developed with massive, diverse datasets and enable generality on multifaceted tasks by the large-scale pre-training paradigm [20, 21]. Moreover, the ability of FMs in unifying multimodal representations can be facilitated with a unified Transformer structure [22] by extensively modeling the cross-range dependencies among the input tokens. In medical image analysis, recent studies also demonstrated that these methods could match medical specialists' performance, such as chest X-rays [23, 24], pathology images [25-27], and transcriptomics [28]. Nevertheless, FMs often contain billions of parameters that need to be pre-trained from million-scale datasets, which is impractical for situations with less data. Under such circumstances, parameter-efficient fine-tuning provides the feasibility of leveraging the pre-training knowledge by adapting from existing FMs with a confined scale of trainable weights [29]. In spite of this, adapting the foundation model knowledge learned from 2D natural images for multiparametric MRI analysis encounters a significant domain gap, particularly with the increase in the number of modalities and dimensions.\nIn this study, we proposed a FM-based large mixture-of-modality-experts model (MOME) which inherits the long-range modeling capability of a transformer-based FM for multiparametric information fusion and could conduct flexibly inference with the design of mixture of experts (Fig. 1, supplementary Fig. 1). The model was developed and extensively evaluated based on the largest multiparametric breast MRI dataset collected from three hospitals in China, achieving comparable malignancy differentiating performance with National Health Commission (NHC)-qualified radiologists. With generality across data collected from the north, southeast, and southwest of China, the model exhibits its clinical value in decreasing unnecessary biopsies for BI-RADS 4 patients. Moreover, MOME could also conduct subtyping of triple-negative breast cancer and predicting of response to neoadjuvant chemotherapy. With these capabilities, we exemplified the clinical value of MOME in non-invasive, personalized management of breast cancer patient."}, {"title": "Results", "content": "This study involved a total of 5,220 multiparametric breast MRI examinations from 5,205 patients, collected from three institutes across ten years (supplementary Fig. 2), that is, Dataset 1 (DS1, The Fifth Medical Center of Chinese PLA General Hospital), Dataset 2 (DS2, Shenzhen People's Hospital), and Dataset 3 (DS3, Yunnan Cancer Hospital). DS1 comprised 1,824 examinations took between November 2012 and July 2017. DS2 comprised 735 examinations collected between December 2018 and March 2022, and DS3 comprised 2,661 examinations obtained between November 2015 and October 2022. For malignancy classification, DS1 was split into training set (n=1,167) and validation set (n=150) for model development, internal testing set 1 (n=307) for evaluation, and internal testing set 2 (n=200) for comparison with radiologists. Different sets did not have overlapping patients. DS2 and DS3 were used for external testing. In addition, 1,005 subjects and 358 subjects from DS 1 were used for triple-negative breast cancer (TNBC) subtyping and neoadjuvant chemotherapy (NACT) response prediction, respectively, where performance was reported using five-fold cross validation. More details of patient characteristics can be found in supplementary Table 1."}, {"title": "Comparable to radiologists", "content": "We evaluated the malignancy diagnosis performance of MOME on the internal testing set 2 (n=200) and compared its performance with that of six radiologists (reader 1: less than five years of experience in breast MRI; readers 2 and 3: five to ten years of experience in breast MRI; readers 4, 5, and 6: more than ten years of experience in breast MRI; detailed performance can be found in supplementary Table 3).\nIn comparison to every single reader (Figs. 2a and 2b, supplementary Table 3), no evidence of statistically significant differences was found between the performance of MOME and those of four radiologists (readers 2, 3, 5, and 6), in terms of both F1 and MCC. In addition, MOME achieved statistically significantly higher F1 (model-radiologist performance=0.065, 95% CI 0.019, 0.117) and MCC (model-radiologist performance=0.228, 95% CI 0.090, 0.384) than reader 1 (F1=0.840 [95% CI 0.789, 0.886]; MCC=0.495 [95% CI 0.361, 0.615]). The performance of MOME was also found to be statistically lower (model-radiologist F1=-0.051 [95% CI -0.087, -0.019]; model-radiologist MCC=-0.145 [95% CI -0.240, -0.048]) than that of reader 4 (F1=0.956 [95% CI 0.927, 0.978]; MCC=0.868 [95% CI 0.787, 0.933]). MOME achieved an AUROC of 0.913 (95% CI: 0.864, 0.952) and an AUPRC of 0.948 (95% CI: 0.911, 0.977), with five out of six dots representing the performance of radiologists' lying on or under the curves, which also indicates that MOME have similar performance to these radiologists with proper decision thresholds (Figs. 2c and 2e)."}, {"title": "Outperforming unimodal or other multimodal methods", "content": "MOME outperformed all unimodal and multimodal approaches in malignancy diagnosis, with 0.903 AUROC and 0.941 AUPRC on DS1 internal testing set 1 (Figs. 1f and 1g), and external 0.893 AUROC and 0.882 AUPRC on DS2 (Figs. 1h and li). Among unimodal methods, the DCE-based model consistently achieved the highest performance (internal AUROC 0.882, internal AUPRC = 0.927; external AUROC = 0.872, external AUPRC = 0.858), while severe performance degradation was observed for both the T2WI-based model and the DWI-based model. The results by the methods other than MOME show that combining multiparametric input does not necessarily lead to improved performance. Compared to the DCE-based model, multimodal methods other than MOME did not necessarily bring improvement in performance. Late Fusion showed decreased AUROC (internal: 0.858; external: 0.858) and AUPRC (internal: 0.908; external: 0.847); Feature Fusion and BEiT3 [21] showed comparable performance or marginal improvement on the internal set while lower performance on the external set. Detailed values of different metrics can be found in Supplementary Table 4. These findings indicate that integrating multiparametric MRI information is challenging, while MOME has superior capability of multimodal data fusion and classification."}, {"title": "Generality across hospitals", "content": "MOME showed generalizable performance on differentiating malignancies from benign tumors across hospitals (Fig. 3). On the internal testing set 1 (n=307), the ROC (Fig. 3a) and PRC (Fig. 3c) analyses showed that MOME achieved 0.912 AUROC (95% CI 0.876, 0.942) and 0.942 AUPRC (95% CI 0.906, 0.970) on the internal testing set (n=307). Partial AUROC (pAUROC) at 90% sensitivity was 0.735 (95% CI 0.666. 0.811) and 0.800 (0.706 to 0.880) at 90% specificity (Fig. 3b). These results indicate that MOME identifies breast cancer patients with a high degree of accuracy.\nExternal validation was conducted on DS2 and DS3. Except for different breast MRI protocols (Methods section), DS2 and DS3 also possessed different demographics and different distributions of malignant cases compared to the internal dataset. Specifically, on DS2, MOME achieved 0.899 AUROC (95% CI 0.877, 0.922) and 0.887 AUPRC (95% CI 0.847, 0.923). pAUROC at 90% sensitivity was 0.740 (95% CI 0.695. 0.788) and 0.753 (95% CI: 0.698, 0.805) at 90% specificity. On DS3, MOME achieved 0.806 AUROC (95% CI: 0.790, 0.822) and 0.807 AUPRC (95% CI: 0.785, 0.827). pAUROC at 90% sensitivity was 0.617 (95% CI 0.594, 0.642) and 0.621 (95% CI: 0.600, 0.643) at 90% specificity. More detailed performance can be found in supplementary Table 5. These results reveal that MOME is discriminative and robustness."}, {"title": "Ablation investigation on modules and missing sequences", "content": "To investigate the influence of different modules, we developed different variants of MOME by removing each single component (ablation section in Methods) and compared their performance on the DS1 internal testing set 1. As can be observed from Table 1, removing all of the modality experts led to performance drop in all of the metrics (rows 1). On the metrics of AUROC and AUPRC, this variants had decreases of 1.0% and 1.1%, respectively, compared to those of MOME. We then replaced the soft mixture of modality experts with a MLP adapter (row 2), leading to performance drops of 2.3% for AUROC and 3.0% for AUPRC compared to those of MOME. All other metrics except for sensitivity also drop compared to the full method (Supplementary Table 6). These findings indicate that each module contributes to the improved final results.\nWe also investigated the ability of MOME in inferring with missing sequences. As DCE remains the most important sequence for breast MRI, we reported the model performance when inferring purely based on DCE (Table 1, supplementary Table 6). As can be observed, MOME achieved an AUROC of 0.877 and an AUPRC of 0.926. When adding test-time augmentation, MOME achieved 0.886 AUROC (95% CI 0.845, 0.920), 0.897 AUROC (95% CI 0.839, 0.944), 0.881 AUROC (95% CI 0.858, 0.906), 0.790 AUROC (95% CI 0.772, 0.806) on internal testing set 1, internal testing set 2, DS2, and DS3 (supplementary Table 7). These results show that MOME relies on complete multiparametric input for improved diagnosis performance, yet it can also achieve robust inference under the conditions of missing sequence(s)."}, {"title": "Subgroup analysis", "content": "We conducted subgroup analyses on the combination of DS1 and DS2, based on several breast cancer risk-related criteria, including the status of background parenchymal enhancement (BPE; the breast tissue enhances on contrast MRI), age, and BI-RADS scores, as well as the magnetic field strength (Fig. 4 and supplementary Table 8). Overall, MOME consistently achieved high AUROC in all groups."}, {"title": "Model decision interpretation", "content": "MOME is interpretable in highlighting the lesions and analyzing the contribution of each modality. Using integrated gradient [30], it can be observed that that MOME correctly attended to breast lesions when diagnosing malignant (Figs. 5a and 5g) or benign (Figs. 5b and 5h) patients, consistent across DS1 and DS2. The Shapley value [31] revealed the contributions of each modality to the final prediction (Figs. 5e, f, k, and 1). It can be observed that DCE and DWI played more important roles in recognizing malignant patients, whereas DCE and T2WI showed greater contributions in differentiating benign patients. As is also demonstrated by the global Shapley value (Figs. 5m and n), DCE obtained the highest global contribution for determining malignancies, while DWI and T2WI mostly contributed to diagnosing malignant patients and benign patients, respectively, and this decision-making rule is consistent across DS1 and DS2."}, {"title": "Personalized management", "content": "MOME can be used in clinical process to improve personalized management for breast cancer patients. We first analyze the net benefit of using MOME to detect patient with malignancies. The decision curve analysis on DS1 internal testing set 1, DS1 internal testing set 2, DS2, and DS3 (Figs. 6a, b, c, d, respectively) indicate high net benefit across long ranges of preference thresholds, demonstrating its potential for decision support in screening malignancies.\nMOME can also reduce unnecessary biopsy for BI-RADS 4 patients. We investigated the trade-off between the number of correctly downgraded cases and the true positive rate by varying operating points of MOME. Based on the operating point found on DS1 and corresponding results on DS2, we found that at an operating point that identified 7.3% of BI-RADS 4 patients with benign tumors (8 out of 109 patients), no cancer would be missed with biopsy (n=86). By decision curve analysis (Fig. 6g), MOME also achieved higher net benefit across a long range of threshold probability, compared to the biopsy all strategy that commonly leveraged for BI-RADS 4 patients. These results demonstrated a high preference for using MOME for personalized biopsy recommendation for BI-RADS 4 patients.\nWe also investigated MOME for triple-negative breast cancer (TNBC) subtyping (Fig. 6f) and NACT pathologic complete response (pCR) prediction (Fig. 6g). Based on five-fold cross-validation, MOME achieved an AUROC of 0.709\u00b10.067 for TNBC subtyping (n=1,005) and an AUROC of 0.694\u00b10.029 for NACT response prediction (n=358). To note, TNBC patients are also more likely to achieve PCR after NACT.\nThese results showed that MOME has the potential to facilitate non-invasive personalized breast cancer patient management for malignancy screening, biopsy recommendation, and treatment decision support."}, {"title": "Discussion", "content": "The purpose of this work was to show MOME with high differential ability for multiparametric breast MRI analytics with a multiparametric, large-scale, and multi-center study. Typically, the management of breast cancer patients requires a series of examinations, such as mammography, ultrasound, MRI, histopathology, serology, genomics, and more. Personalized management would bring large benefit, yet it depends on accurate malignancy detection, molecular subtyping, and the patients' estimated response to different therapies. We have shown that MOME could accurately and robustly distinguish patients with malignancies from benign or normal subjects with evaluation across multiple hospitals. Compared to NHC-qualified radiologists, MOME showed no evidence of statistical differences with the performance of four out of six human experts and statistically significantly higher performance than the junior radiologists with less than five years of breast MRI experience. Typically, a biopsy is often suggested for a patient with BI-RADS 4 or above after a breast MRI examination, whereas MOME can be used to further characterize BI-RADS 4 patients into \"likely benign\" or \"likely malignant\" lesions, hence alleviate the need of biopsy for the former subgroup. Moreover, MOME was shown capable of finding TNBC patients who usually have better responses to NACT with an AUROC of 0.709. Using the pre-treatment multiparametric MRI, we also found that the model could achieve 0.694 AUROC for NACT response prediction. These capabilities demonstrated MOME's clinical value in biopsy recommendation and treatment decision, thus facilitating efficient, non-invasive, and personalized breast cancer patient management.\nCompared to the previous studies, this work presents a more extensive evaluation of a multiparametric deep learning model with large-scale, diverse external assessment for malignancy classification. Specifically for breast MRI malignancy classification, an AUROC of 0.859 was reported in a single-center study on DCE-MRI from containing 1537 female cases [9]. Later, in a multi-center single-sequence study [11] involving 2,2984 DCE-MRI cases, AUROC of 0.92 was reported on its internal testing set. This model was found to achieve near-perfect performance (AUROCs were above 0.965) on two external datasets (n=922 and 131, respectively) with only invasive breast cancer while exhibiting a lower AUROC of 0.797 on a smaller yet more challenging external set (n=394). These results were limited to single-sequence MRI, that is, DCE-MRI, and AI-based integration of multiparametric breast MRI is less investigated. Meanwhile, extensive external evaluation was also recommended to comprehensively assess the model's generality [32, 33].\nThis study collected the largest multiparametric breast MRI dataset, representing typical populations from the north, southwest, and southeast of China, across a ten-year period. DS1, DS2 and DS3 were obtained with diverse imaging protocols, such as different scanning matrices, DWI b values, numbers of DCE-MRI sequences, and different demographics. Although the metrics on DS3 did not match those on DS1 and DS2, we note that DS3 possessed larger data shifts in terms of imaging protocol and cohort size. MOME achieved high performance to the two external datasets and performed consistently across different subgroups, demonstrating its generality. These findings demonstrate the ability of MOME to integrate high-dimensional multiparametric information in clinical settings.\nMethodologically, MOME provides a novel approach to adapting the powerful foundation models from the natural image domain to a more complex dimension, that is, the three-dimensional, multimodal breast MRI with temporal information in DCE. In specific, different breast MRI sequences provide different diagnostic information and result in varied breast cancer differentiation abilities, as observed in Table 4, which explains the difficulty of multiparametric fusion and inference, as other multimodal approaches may not necessarily outperform the pure DCE-MRI-based model. MOME had most of the parameters shared for each modality, which mimicked a siamese network structure [34] that can effectively model the similarity and differences among the inputs. Moreover, the first nine layers utilized sparse modality experts and inter-modality self-attention to adequately extract the modality-specific features. Then, the last few layers adopted the soft mixture of experts and applied self-attention for the holistic multimodal tokens to encourage cross-modal interaction. The combination of these characteristics finally led to the improved diagnostic accuracy of MOME. In addition, MOME offered flexible and explainable inference. The structural design enables MOME to infer with missing sequence(s), which is highly scalable for incomplete imaging protocols. MOME also exhibits inherent interpretability by providing pixel-level contributions on the input images and showing highlights of the lesions of interest for malignancy detection. Furthermore, our model provides a way for modality contribution investigation based on Shapley value with its support for missing-modal inference, which allows us to understand the decision-making in terms of modality contributions both locally and globally.\nWe acknowledge several limitations of the current study. First, we focused on multiparametric MRI, whereas other data, such as mammograms, breast ultrasounds, health records, and demographics, may also be generated during the clinical process and can provide extra insights into the patient's status. Our future work will scale the study with more available modalities using the proposed unified model structure. Second, our comparison with radiologists treated the AI system as a stand-alone reader. It would be of great value to see how the AI interpretation can affect the reader's decision and explore the model's role in real-world clinical settings. Also, the model yielded patient-level results, and future works should extend to more fine-grained diagnoses to deal with patients with multiple lesions and consider intra-tumor heterogeneity.\nTo summarize, we provided a large-scale, multi-center, multiparametric study using a foundation model for breast MRI analysis, including malignancy diagnosis and NACT response prediction. The multimodal inference matches the routine breast MRI protocol and the reading standard of breast radiologists. To tackle the difficulties of fusing different MRI sequences, we proposed a novel approach, MOME, that used mixture of experts to adapt a foundation model for 3D multiparametric medical image analysis. MOME demonstrated accuracy and robustness in diagnosing breast cancers with comparable performance to radiologists and showed promise for subtyping and pre-treatment NACT response prediction, providing a groundwork towards noninvasive and personalized management of breast cancer patients."}, {"title": "Methods", "content": "All datasets were collected under institutional review board approval (KYLX2023-163). All data were de-identified before the development of the model."}, {"title": "MRI acquisition", "content": "For DS1, the magnetic resonance imaging (MRI) scans were performed on a 1.5T system (Magnetom Espree Pink; Siemens, Munich, Germany) with an 8-channel breast coil. Patients were positioned prone, with both breasts naturally aligned within the coil. Imaging included conventional scans: an axial T1-weighted 3D non-fat-suppressed sequence (TR/TE: 8.7/4.7 ms, matrix: 896\u00d7896, slice thickness: 1 mm), T2-weighted fat suppression (TR/TE: 2900/60 ms, matrix: 640\u00d7640, slice thickness: 4 mm), and diffusion-weighted imaging (DWI) with b-values of 400, 800, and 1000 s/mm\u00b2 (TR/TE: 6200/104 ms, matrix: 236x120, slice thickness: 4 mm). Dynamic contrast-enhanced MRI was conducted using a 3D fat-suppressed VIBE sequence before and 6 times after bolus injection (0.1 mmol/kg gadopentetate dimeglumine, Magnevist, Bayer, Berlin, Germany) at 2 mL/s, followed by a 20-mL saline flush. The examination spanned 7 minutes, with imaging parameters of TR/TE: 4.53/1.66 ms, matrix: 384\u00d7384, and slice thickness: 1.0 mm. Images of each phase were subtracted automatically.\nFor DS2, breast MRI examinations were performed using either a 1.5T Magnetom Avanto or 3.0T Magnetom Skyra magnetic resonance scanner (Siemens Healthineers, Erlangen, Germany) equipped with a dedicated breast coil. Patients were examined in the prone position. The scanning included the following sequences: axial T1-weighted non-fat suppressed images were acquired with TR/TE parameters of 559/12 ms (1.5T) and 6/2.5 ms (3.0T), a matrix of 448 \u00d7 448, and slice thickness of 4 mm (1.5T) and 1.6 mm (3.0T); axial T2-weighted images were obtained with TR/TE of 4500/102 ms (1.5T) and 4740/107 ms (3.0T), a matrix of 512 \u00d7 512 (1.5T) and 448 \u00d7 448 (3.0T), and slice thickness of 4 mm. A single-shot echo planar imaging pulse sequence was used to acquire diffusion-weighted images with the following parameters: TR/TE of 6400/97 ms (1.5T) and 5700/59 ms (3.0T), a matrix of 192 \u00d7 192 (1.5T) and 340 \u00d7 170 (3.0T), slice thickness of 4 mm, and b-values of 50/500/1000 s/mm2 (1.5T) and 50/400/800 s/mm\u00b2 (3.0T); DCE-MRI was performed during intravenous injection of 15 ml Gd-DTPA at 0.1 mmol/kg over 6 minutes and 41 seconds at a rate of 2.5 ml/s. The sequence included one pre-contrast axial image and five post-contrast axial scans spaced 30 seconds apart. DCE parameters were: TR/TE of 5.2/2.4 ms (1.5T) and 4.7/1.7 ms (3.0T), a matrix of 384 \u00d7 384 (1.5T) and 448 \u00d7 448 (3.0T), and slice thickness of 1.1 mm (1.5T) and 1.6 mm (3.0T). Images from each phase were automatically subtracted.\nFor DS3, breast MRI was performed on a 1.5T system (Magnetom Avanto; Siemens, Germany), equipped with an 4-channel breast phased array surface coil. Patients were examined in the prone position. The scanning steps are as follows: axial T1WI fast low angle shot 3D, flash 3D sequence (TR 8.6 ms, TE 4.7 ms, slice thickness 1 mm); Fat-suppressed transverse axial T2WI rapid inversion recovery (Turbo Inversion Recovery Magnitude, TIRM) sequence (TR 5600 ms, TE 56 ms, slice thickness 4 mm) scan; Axial diffusion-weighted imaging uses single shot echo plannar imaging (SS-EPI) sequence (TR 4900 ms, TE 84 ms, FOV 340 mm, slice thickness 4mm, the diffusion sensitivity factor b value is selected to be 0 s/mm\u00b2 and 800 s/mm\u00b2). Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) scan in transverse position: first scan the first-stage transverse position fat-suppressed T1WI (i.e., masked film), then inject contrast agent, and then continuous scanning of 5 continuous dynamic enhancement sequences, each period is 60 seconds. Twenty ml of Gd-DTPA-BMA (OmniScan, GE Healthcare, Ireland) was injected at a rate of 2.0 ml/s and then flushed with 20 ml of saline. Parameters of DCE-MRI were: TR 4.43 ms, TE 1.5 ms, matrix 352 \u00d7 324, slice thickness 1.7 mm. Images of each phase were subtracted automatically."}, {"title": "Data preprocessing", "content": "We generated three-dimensional breast region masks from T1-weighted fat-suppressed magnetic resonance images, following Zhou et al. [9]. Specifically, two-dimensional binary breast masks were obtained for each MR image slice by extracting boundaries and applying morphological processing methods. Then, all the two-dimensional masks were stacked to create a three-dimensional mask, which was smoothed using a 3D Gaussian filter (\u03b3 = 20). The obtained 3D masks were used to crop the MRI scans and mask out the air and chest regions. The main purpose of the breast mask was to reduce the input data dimensions.\nFor DS1, we utilized the 3D mask to crop all DCE-MRI subtraction sequences, resizing both DCE-MRI and the corresponding 3D mask to 384\u00d7384\u00d7128. The breast region in DCE-MRI was then extracted and normalized, followed by element-wise multiplication with the 3D mask. For T2 images, they were first resized to 384\u00d7384\u00d732 and then the breast area was cropped, with standardization (linear scaling to zero mean and unit variance) applied subsequently. For DWI, the sequence with the highest b value (1000 or 800) was used, and only standardization was performed for pre-processing. During training and testing, DCE-MRI, T2WI, and DWI was padded to 384 \u00d7 256 \u00d7 128, 384 \u00d7 256 \u00d7 48,and 256 \u00d7 128 \u00d7 32, respectively.\nFor DS2 and DS3, the procedures were similar to DS1 except that their DCE-MRI had 5 phases and were interpolated to 6 phases using first-order B-spline interpolation with a grid-constant mode."}, {"title": "Groundtruth", "content": "The malignant or benign labels for all patients from DS1, DS2, and DS3 were confirmed by histopathological examination. In DS1, 365 patients with breast cancer confirmed by histopathology underwent NACT. One cycle of NACT lasted for 21 days. After the second cycle, clinicians evaluated the response and tolerability of NACT for each patient. All patients underwent MRI scans before treatment and at least 2 follow-up studies. All patients underwent definitive surgery after the final cycle of treatment. For confirmed breast cancer, molecular subtypes were determined based on the Chinese Anti-Cancer Association and the immuno-histochemical results in the histopathological reports were analyzed by pathologists. The estrogen receptor (ER), progesterone receptor (PR), HER2 status, and Ki-67 index were used to define the molecular subtypes. Estrogen receptor and PR positivity were defined as more than 1% staining [35]. HER-2 positivity was defined as a score of 3+ by IHC or fluorescence in situ hybridization amplification with a score of 2+ or higher [35]. TNBC was determined by ER negative, PR negative, and HER2 negative."}, {"title": "MOME", "content": "MOME presents a unified, easily-extendable structure for multimodal data integration, such as multiparametric breast MRI. The input data were first embedded into features using different tokenizers and concatenated as input to a transformer architecture adapted from a foundation model.\nEach MRI sequence leveraged a tokenizer module with the same structure to embed the input into tokens, which was a sequence of embedded features, denoting as $X_{DCE}$, $X_{DWI}$, and $X_{T2}$. The tokenizer contained three 3D convolutional layers (stride = 2) and ended with a maxpooling layer (stride = 2). Each convolution layer was appended with an instance normalization [36", "37": "."}]}