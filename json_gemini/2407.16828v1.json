{"title": "Pareto Front Approximation for Multi-Objective Session-Based Recommender Systems", "authors": ["Timo Wilm", "Philipp Normann", "Felix Stepprath"], "abstract": "This work introduces MultiTRON, an approach that adapts Pareto front approximation techniques to multi-objective session-based recommender systems using a transformer neural network. Our approach optimizes trade-offs between key metrics such as click-through and conversion rates by training on sampled preference vectors. A significant advantage is that after training, a single model can access the entire Pareto front, allowing it to be tailored to meet the specific requirements of different stakeholders by adjusting an additional input vector that weights the objectives. We validate the model's performance through extensive offline and online evaluation. For broader application and research, the source code\u00b9 is made available. The results confirm the model's ability to manage multiple recommendation objectives effectively, offering a flexible tool for diverse business needs.", "sections": [{"title": "1 INTRODUCTION", "content": "Large e-commerce platforms such as OTTO face the complex task of optimizing diverse revenue streams through personalized recommendations. These systems cater to various business needs, such as sponsored product advertisements, which generate revenue per click, and organic recommendations to maximize conversions. The challenge lies in balancing these goals, as marketing teams prioritize high visibility and click-through rates for sponsored content, whereas sales departments focus on enhancing conversion rates and customer loyalty through organic product listings.\nTo address these conflicting objectives, multi-objective recommender systems offer a framework capable of optimizing across different metrics within a unified system [1, 10, 14, 16, 23]. This study adapts Pareto front approximation techniques, previously successful in other domains [15, 17, 19, 20], to session-based recommender systems. By training on sampled preference vectors, our model can access the entire Pareto front at inference time, providing an efficient tool to meet the diverse business goals of stakeholders."}, {"title": "2 METHODS", "content": "Multi-objective session-based recommender systems predict the next item interaction based on prior user activities. Each user session consists of user-item interactions $s_{raw} = [i_1, i_2, ..., i_T]$, where T is the session length, and $i_t$ represents the action taken on item i at time t. Actions include clicking or ordering, typically with orders following clicks. Sessions are modelled as $s := [(c_1, o_1), (c_2, o_2), ..., (c_{T-1}, o_{T-1})]$, where $c_t$ is the clicked item at time t, and $o_t$ indicates if the item was ordered in the same session up to time T. Our multi-objective recommender model R leverages past clicks to predict scores r for potential item interactions, optimizing the trade-off between click $L_c(c_t, r_i)$ and order $L_o(o_t, r_i)$ losses. Standard scalarization methods [15, 19] use a fixed preference vector $\\pi := [\\pi_c, \\pi_o]$, with $\\pi_o + \\pi_c = 1$, and minimize:\n$L(c_t, o_t, R_t, \\pi) = \\pi_c L_c(c_t, R_t) + \\pi_o L_o(o_t, R_t)$.\nThis approach does not scale for large datasets because each point on the Pareto front requires a separate model. In multi-objective Pareto front approximation, sampling $\\pi \\thicksim Dir(\\beta)$ from a Dirichlet distribution with parameter $\\beta \\in R^2$, during training and adding it to the input yields a model $M(\u00b7, \\pi)$ conditioned on r during inference [6, 17, 19, 20]. We adapt this approach to sequential recommender models $R(\u00b7, \\pi)$ and conclude from [6] that if $R^*$ minimizes:\n$\\mathbb{E}_\\pi L(c_t, o_t, R_t(\\cdot; \\pi), \\pi) = \\mathbb{E}_\\pi (\\Sigma_k \\pi_k L_k(k_t, R_t(\\cdot, \\pi))))$\nthen $R^*$ minimizes Equation 1 almost surely w.r.t $P_\\pi$. To address the limitation of narrow Pareto fronts [19], we also leverage the non-uniformity loss from [16] by adding it to the loss:\n$L_{reg}(\\pi) = CE(\\hat{\\mu} | \\frac{1}{2})$,\nwhere $\\hat{\\mu}_k := \\frac{\\pi_k L_k}{(\\pi_c L_c + \\pi_o L_o)}$, $\\frac{1}{2} := [\\frac{1}{2}, \\frac{1}{2}]$ and CE is the cross-entropy loss. The overall loss is formulated as:\n$\\mathbb{E}_\\pi L(\\cdot, \\pi, \\lambda) = \\mathbb{E}_\\pi (\\Sigma_k \\pi_k L_k(k_t, R_t(\\cdot; \\pi)) + L_{reg}(\\pi))$,\nwith $\\lambda \\geq 0$ as a regularization parameter. Our model MultiTRON minimizes the loss in Equation 2 to approximate the Pareto front."}, {"title": "3 EXPERIMENTAL SETUP", "content": "In our experiments we evaluate the proposed approach using three benchmark datasets of varying complexity: Diginetica [5], Yoochoose [2], and OTTO [18]. These datasets differ in terms of the number of events and the diversity of item sets. Our experiments focus on click and order events, ensuring a minimum item support of five and a session length of at least two clicks for all datasets [8]. We adopt a temporal train/test split approach for training and testing the models. Specifically, the entire last day from the Yoochoose dataset and the entire last week from the Diginetica and OTTO"}, {"title": "4 RESULTS", "content": "Table 2 presents the results of our offline evaluation. We found that larger values of $\\lambda$ led to increased hypervolumes, especially on more complex datasets. The Pareto fronts demonstrating the highest hypervolumes for each dataset are depicted in Figure 1. Importantly, incorporating the sampling parameter $\\pi$ into our model does not adversely impact training speed or increase the number of epochs required compared to training models optimized for single objectives with the same architecture. Given the extensive study of the click task in previous research [3, 8, 9, 11, 13, 21], we also provide the Recall@20 for $\\pi = [1,0]$, which resulted in scores of 0.529 for Diginetica, 0.724 for Yoochoose, and 0.485 for OTTO. Our previous work [21] utilizing the same TRON architecture trained on solely the click task yielded Recall@20 scores of 0.541 (-2.2%), 0.732 (-1.1%), and 0.472 (+2.8%) for these datasets. These results demonstrate that MultiTRON performs comparably to single-objective click task models that utilize the same backbone.\nFor the online evaluation, we utilized a model trained on OTTO's private data collected in May 2024. A live A/B test was conducted the following week, with four groups, each assigned different $\\pi$ values. The test results confirmed that the offline trade-off between -Lc and -Lo translates into real-world trade-offs between click-through rates (CTR) and conversion rates (CVR). Specifically, higher -Lo values correlated with increased CVR, while higher -Lc values correlated with increased CTR, as detailed in Figure 2."}, {"title": "5 CONCLUSION", "content": "In this work, we successfully applied a Pareto front approximation technique to multi-objective session-based recommender systems. We demonstrated the practical relevance of MultiTRON through offline evaluation on three benchmark datasets and an online real-world A/B test. The ability of the offline calculated Pareto front to translate into real-world trade-offs of CTR and CVR in a live setting validates the model's effectiveness in commercial environments."}, {"title": "6 SPEAKER BIO", "content": "Timo Wilm and Philipp Normann are Senior Data Scientists specializing in the design and integration of deep learning models. Felix Stepprath is a Digital Analyst specializing in advanced analytics. All three are members of OTTO's recommendation team."}]}