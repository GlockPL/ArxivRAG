{"title": "LMT-Net: Lane Model Transformer Network for Automated HD Mapping from Sparse Vehicle Observations", "authors": ["Michael Mink", "Thomas Monninger", "Steffen Staab"], "abstract": "In autonomous driving, High Definition (HD) maps provide a complete lane model that is not limited by sensor range and occlusions. However, the generation and upkeep of HD maps involves periodic data collection and human annotations, limiting scalability. To address this, we investigate automating the lane model generation and the use of sparse vehicle observations instead of dense sensor measurements. For our approach, a pre-processing step generates polylines by aligning and aggregating observed lane boundaries. Aligned driven traces are used as starting points for predicting lane pairs defined by the left and right boundary points. We propose Lane Model Transformer Network (LMT-Net), an encoder-decoder neural network architecture that performs polyline encoding and predicts lane pairs and their connectivity. A lane graph is formed by using predicted lane pairs as nodes and predicted lane connectivity as edges. We evaluate the performance of LMT-Net on an internal dataset that consists of multiple vehicle observations as well as human annotations as Ground Truth (GT). The evaluation shows promising results and demonstrates superior performance compared to the implemented baseline on both highway and non-highway Operational Design Domain (ODD).", "sections": [{"title": "I. INTRODUCTION", "content": "Autonomous vehicles require an understanding of the road infrastructure for navigation. Typically, the first step towards this understanding is map construction to represent the vehicle environment. A High-Definition (HD) map provides vectorized representations of road infrastructure such as pedestrian crossings, lane dividers, and road boundaries. Recent approaches such as Liao et al. [1], Zhang et al. [2] are based on learned Bird's-Eye View (BEV) encoders to derive lane graphs directly from sensor data and provide promising results. Approaches for online HD map construction from sensor data are limited by sensor range and occlusion, which makes the perception task even more challenging. Alternatively, HD maps can be generated off-board to provide prior knowledge of the system. However, the generation and upkeep of HD maps usually involve manual annotations, limiting scalability. Automation of map construction is crucial for scaling of automated driving systems.\n\nA scalable solution for HD map generation is possible only by using measurements from existing vehicles on the road. However, uploading sensor data is undesirable due to privacy and data bandwidth concerns. Instead, an on-board perception module extracts static elements of the environment, e.g., lane boundary observations. The observations from vehicles on the road are often noisy and sparse, posing challenges to automating the mapping process. The myriad of real-world scenarios and corner cases add to the challenge.\n\nDue to the scarcity of available datasets, there is little work done on automated mapping from vehicle fleet observations to the best of our knowledge. The few existing works primarily focus on traditional statistical approaches. These approaches perform statistical aggregation and filtering of vehicle observations and fall short in the generation of a consistent lane model, specifically in complex ODDs like intersections without visible lane markings.\n\nIn this paper, we propose a scalable methodology for automated map generation. We assume a pre-processing step (Henzler et al. [3]) that aligns and aggregates observations of lane boundaries and driven traces. Alignment is done by a variant of the iterative closest point (ICP) algorithm [4]. Then individual observed lane boundaries are aggregated using a clustering algorithm. Based on this geometric representation, we derive lane pairs with a learning-based approach. In the second stage, we predict the connectivity between lane pairs. In the resulting lane graph, nodes describe the lane geometry and edges define the connectivity.\n\nIn summary, the contributions of this work are:\n\n\u2022 A two-stage approach to HD mapping combines existing statistical methods with a learning-based method to derive a lane graph.\n\n\u2022 A novel transformer-based approach for inferring a lane graph based on sparse observations from vehicles on the road.\n\n\u2022 Extensive ODD-specific evaluation and ablation studies on an internal dataset that validate our design choices."}, {"title": "II. RELATED WORK", "content": "A. Grid-based Map Construction\n\nIn map construction, grid-based approaches first perform semantic segmentation, which is a pixel-wise classification of the map features in a BEV grid. This is followed by post-processing to get from the grid representation to the final vectorized HD map. Philion and Fidler [5] propose the first learning-based architecture for map segmentation in an online setup. They predict a BEV grid from camera images and combine object detection and map segmentation. BEVFormer [6] further improves construction accuracy by aggregating temporal information across multiple time steps.\nLi et al. [7] propose an architecture to construct a vectorized HD map from sensor data. Similar to previous approaches, they perform map segmentation first. A post-processing step groups individual pixels from the segmentation result and outputs vectorized map geometries.\n\nB. Graph-based Map Construction\n\nIn contrast to grid-based approaches, graph-based approaches directly construct an HD map by predicting the graph representation of vectorized map elements without the need for any conversions from grid space.\n\nMi et al. [8] propose HDMapGen, a hierarchical autoregressive model to generate a graph representation of HD maps. Graph Attention is used to generate a global graph whereas MLPs are used to refine the geometries with local graphs and to derive semantic attributes.\n\nEarly work from Z\u00fcrn et al. [9] focuses on the lanes by predicting lane shape and connectivity. A Graph-RCNN approach is used in Yang et al. [10] to directly predict graph structures, including the direction of each lane connection to generate a directed lane graph. They represent information from multiple sensor modalities as BEV images, which are constructed using depth measurements from LiDAR. Can et al. [11] lift this limitation by predicting graph structures directly from on-board camera frames. They use a transformer architecture to generate a vectorized representation of the centerlines and objects from encoded image features. Going beyond the work of Can et al., Liu et al. present VectorMapNet [12], the first end-to-end model for vectorized map learning using images from multiple camera perspectives to predict drivable area, boundaries, dividers, and crosswalks. They use Inverse Perspective Mapping to lift camera features in BEV space and apply two stages of transformer decoders to detect map elements and generate polylines, respectively.\n\nA key challenge with vectorized representations is the ambiguity in choosing a discrete set of points to model geometries. MapTR [1] proposes permutation-equivalent modeling that stabilizes the learning process. Zhang et al. [2] define a geometric loss that is robust to rigid transformations.\n\nTopoNet Tianyu et al. [13] focuses on deriving the semantic relations in a scene graph. We adopt a similar strategy to predict the adjacency map between lane nodes.\n\nAll previously mentioned approaches construct HD maps from observations at a single time instance. Following the philosophy of BEVFormer, Yuan et al. [14] promote the use of memory buffers to yield temporal stability that helps in constructing large-range, local HD maps. Their results indicate the benefit of aggregating temporal information in graph-based map construction. Inspired by the idea of aggregating multiple observations for improved accuracy, our method expands the paradigm by constructing an offline HD map by aggregating multiple observations unrelated in time.\n\nC. Lane Mapping from Fleet Data\n\nThe following works use fleet data in the form of abstract representations of the environment and driven traces to derive the lane paths. Early work by Chen and Krumm [15] and Uduwaragoda et al. [16] look at deriving lane paths purely from driven traces. Statistical models such as Kernel Density Estimation are applied to the GPS traces. Lines and Basiri [17] analyze mapping from geo-spatially referenced observations and focus on classifying the Global Navigation Satellite System (GNSS) signal quality.\n\nGuo et al. [18] generate lane-level maps from GPS traces and orthographic images. More recent work captures additional geometric map features such as boundaries and signs [19]. Liebner et al. [20] infer a road model and use a graph-based SLAM using higher-level features, such as lane marking types provided by the vehicle fleet. Shu et al. [21] estimate the precise lane paths by segmenting and clustering the driven traces based on entropy theory. Immel et al. [22] use the Expectation-Maximization algorithm to identify lane paths from vehicle fleet data.\n\nMV-Map [23] follows the principle of learned BEV encoders presented in previous sections. However, they apply this in an off-board setting and focus on multi-view consistency. Being able to handle an arbitrary number of frames, their approach can combine image frames from the fleet to derive an HD map. They propose an uncertainty network to perform global aggregation and augment it using the 3D structure from a Voxel-NeRF.\n\nXiong et al. [24] work towards a neural map representation that is shared between on-board and off-board. On-board learned BEV encoders generate a latent BEV feature space that can be decoded into map elements. They propose to store these latent features in an off-board map and use that map to refine on-board derived BEV features."}, {"title": "III. APPROACH", "content": "A. Problem Statement\n\nOur method has two different inputs, which are schematically visualized on the left side in Fig. 1. The first is a set of driven traces, $T = \\{T_1,...,T_k\\}$. The second is a set of observed lane boundaries, $O = \\{O_1,..., O_k\\}$. Elements in $T$ and $O$ are polylines. A polyline is defined as a sequence of $N_{P_i}$ points: $P_i = [(x_i, y_i)]_{j=1}^{N_{P_i}}$\n\nThe goal is to derive the underlying lane graph as a set of lane pairs and their connectivity, as shown on the right side in Fig. 1. A lane pair $L_i$ is defined by two boundary points $B_{left,i}$ and $B_{right,i}$ that lie on the line perpendicular to the driving direction.\n\nThe objective is to find a function $f$ that predicts a lane graph $G$ for the given $T$ and $O$, where $[\\^]$ represents the predicted variable. The lane graph consists of lane pairs $L$ as nodes and edges represented by the adjacency matrix $A$, where $A_{i,j}$ defines the connectivity from lane pair $L_i$ to $L_j$, i.e.:\n\n$f (T, O) = G = (\\widehat{L}, \\widehat{A})$\n\nB. LMT-Net Architecture\n\nFig. 1 illustrates the overall architecture of the proposed LMT-Net, including the polyline encoder, center point encoding, transformer module, and prediction heads."}, {"title": "B. LMT-Net Architecture", "content": "We follow a hierarchical approach by first encoding polylines from $T$ and $O$ individually. Inspired by [25], we encode the vectorized input polylines of various lengths from $T$ and $O$ into feature vectors of fixed size. As depicted on the left side in Fig. 1, we represent each point by its 2D coordinates, the 2D coordinates of its consecutive point (such that each point carries information about the directionality), and the attribute vector that encodes the type of polyline (whether from set $T$ or $O$).\n\nAs the first step of encoding each polyline $P_i \\in (T \\cup O)$, a linear layer performs point-wise encoding. Next, Multi-Head Self-Attention (MHSA) [26] is applied on polyline-level to provide the context of other points along the polyline. In the final step, max-pooling aggregates the 2D polyline embeddings into 1D vectors by selecting the important features. The encoded polyline $e_{polyline}$ is formalized by:\n\n$e_{polyline} = pool(MHSA(linear(P_i)))$\n\nIn LMT-Net, the starting points for the lane decoding are derived from driven traces $T$. A pre-processing of $T$ performs alignment and groups them into bundles based on proximity [3]. For each bundle $T_{bundle}$, the center point is defined as the centroid of its traces:\n\n$C_i(L_i) = (\\widehat{x}_{T_{bundle}}, \\widehat{y}_{T_{bundle}})$\n\nFinally, the center points are encoded with a linear layer and their encodings are used as queries for the decoder layer. In the next step, a transformer module is used to process the encoded polylines and center points. First, multiple transformer encoder layers perform self-attention on the encoded polylines. This updates each polyline encoding with information from other polylines. Next, multiple transformer decoder layers are applied with the encoded center points $C$ as Queries in the attention mechanism. The encoded polyline feature vectors of $T$ and $O$ are used as the Keys and Values to perform cross-attention with the driven traces and observed lane boundaries.\n\nThe transformer module returns output tokens, where a token $e_{l_i}$ corresponds to the queried center point $C_i$ for lane pair $L_i$. A Multi-Layer Perceptron (MLP) is used to derive $(\\widehat{B}_{left, i}, \\widehat{B}_{right,i})$ from $e_{l_i}$. The boundary points are predicted unconstrained by their Cartesian coordinates in a vector of form $[x_{\\widehat{b}_{left}}, y_{\\widehat{b}_{left}}, x_{\\widehat{b}_{right}}, y_{\\widehat{b}_{right}}]$. Note that this prediction also implicitly defines the driving direction.\n\nThe set of predicted lane pairs $\\widehat{L}$ is used as nodes in lane graph $G$. Its edges determine the binary connectivity between the lane pairs: $L \u00d7 L \u2192 \\{0,1\\}$. To predict the connectivity score, each pair of tokens $e_{l_i}$ and $e_{l_j}$ is concatenated and processed with another MLP. The binary classification output after thresholding at 0.8 defines $A_{i,j}$ in the adjacency matrix of $G$.\n\n$A_{i,j} = \\begin{cases}\n1, if \\sigma (MLP ([e_{l_i}, e_{l_j}])) \\geq 0.8\\\\\n0, otherwise\n\\end{cases}$\n\nC. Loss Function\n\nWe perform multi-task training on predicting lane pairs and lane connectivity. For the set of $N_B$ predicted boundary points $B$, mean squared error (MSE) loss is used for each left and right boundary point:\n\n$L_{boundary} = \\frac{1}{2N_B} \\sum_{pos \\in \\{left, right\\}} \\sum_{i=0}^{N_B} ||B_{pos, i} - \\widehat{B}_{pos,i}||^2$\n\nFor each pair from the set $L$ of $N_L$ lane pairs, we use binary cross-entropy (BCE) loss in the predicted adjacency matrix A:\n\n$L_{connectivity} = \\frac{1}{N_L^2} \\sum_{(i,j) \\in N_L \\times N_L} BCE(A_{i,j}, \\widehat{A}_{i,j})$"}, {"title": "IV. IMPLEMENTATION", "content": "A. Model Implementation\n\nOverall, the model consists of 3.71 Mio. learned parameters. The polyline encoder in LMT-Net maps the polyline point vectors to a latent space of size 256. The 2D center points are also transformed to size 256 using a linear layer. MHSA is implemented using two heads, no dropout, and size 256.\n\nFor the transformer module, we use 4 heads, 2 encoder layers, and 4 decoder layers. The dimension of the feed-forward layer is set to 128. The number of queries is defined by the number of center points, which can vary between 2 to 50 per minimap.\n\nThe MLP for lane pair prediction consists of 3 linear layers with input sizes 256, 32, and 16 and outputs 4 channels. The MLP for lane connectivity prediction consists of 2 linear layers with input sizes 512 and 256 and outputs a scalar per edge in the adjacency matrix.\n\nB. Training Details\n\nWe use the PyTorch framework for our experiments. The model is trained using ADAM optimizer with a batch size of 30. We use a learning rate of $10^{-4}$ with a learning rate decay of $\\gamma = 0.1$ after 30 epochs. The model converges in around 60 epochs. Data is augmented by rotating by 90\u00b0, 180\u00b0, and 270\u00b0 to increase the generalization of the model."}, {"title": "V. EXPERIMENTS", "content": "We first introduce dataset details, evaluation metrics, and our baselines. Then we discuss quantitative and qualitative results. Finally, an ablation study details polyline encoding and the number of transformer decoder layers.\n\nA. Dataset\n\nDue to the lack of publicly available datasets, we use an internal dataset that covers approximately 10000 km of lanes. The dataset represents areas in Germany with different ODDs, with a distribution of approximately two-thirds of highway and one-third non-highway. Highway ODD covers purely highway scenarios. Non-highway ODD covers all remaining ODD, including country roads and to a smaller extent urban scenarios.\nThe dataset consists of aggregated vehicle observations $O$ and traces $T$ with around 10 and 5 points per polyline on average, respectively. As a pre-processing step, $O$ and $T$ are geometrically aligned based on commonly observed lane boundaries (Henzler et al. [3]). Furthermore, the dataset contains a human-annotated lane graph $G = (L, A)$ that provides GT labels for training LMT-Net. To provide a mapping between input and GT data, we generate GT lane pairs $L$ for all center points $C$ by selecting the nearest left and right points of the human-annotated GT lane boundaries.\n\nBased on GNSS data associated with the observations, $O,T,L$, and $A$ are grouped into geospatial areas called minimaps that can be processed independently. A minimap contains on average around 14 center points and around 190 polylines of traces and lane boundary observations. The dataset has a total number of 13428 minimaps, of which 692 minimaps are used for evaluation.\n\nWe use the h3 tiling scheme [27] at zoom level 10, resulting in hexagonal-shaped minimaps with an area of about 18000 m\u00b2. All geometries are transformed into a Cartesian coordinate system of the local tangential plane to the center of the minimap, such that all polylines $P$ are given as a sequence of 2D coordinates.\n\nIn the dataset, each center point is derived from 5 to 10 traces.\n\nB. Evaluation Metrics\n\nFor evaluation of lane pair prediction, we use the mean Boundary Point Error (mBPE), which is defined as:\n\n$mBPE = \\frac{1}{N_B} \\sum_{i=0}^{N_B} ||B_i - \\widehat{B}_i||$\n\nWe use the mean Lane Width Error (mLWE) to evaluate the predicted lane width:\n\n$mLWE = \\frac{1}{N_B} \\sum_{i=0}^{N_B} ||width(B_i) - width(\\widehat{B}_i)||$ \n\nwith lane width defined as:\n\n$width(B_i) = ||B_{left, i} - B_{right, i}||$\n\nSince the center points are derived from driven traces, they are not exactly in the middle of the lane. Hence, mLWE and mBPE need to be considered separately. Also, the difference between mBPE and mLWE indicates whether the model systematically over- or underestimates the lane width in both directions. We mostly focus on mLWE over mBPE, since the relative alignment of points to each other is more important than the absolute global alignment. The reason is that localization (the transformation from a global map coordinate system into a local coordinate system) will usually correct slight inaccuracies as long as the relative alignment is good.\n\nThe lane connectivity is a classification problem and is evaluated per each pair of $L_i$ and $L_j$ using Accuracy (Acc.) and F-Score (F1)."}, {"title": "C. Baseline Implementations", "content": "To compare the results of LMT-Net, we develop three baseline implementations for lane pair prediction and one for lane connectivity prediction. The baselines for lane pair prediction are geometry-based heuristics evaluated at the center point locations for comparison to the LMT-Net predictions. Figure 3 is a visualization of the developed baseline approaches.\n\n1) Baseline 1: Constant Lane Width: The first baseline assumes a constant lane width. According to German authorities ([28, 29]), the regular lane width of German streets ranges between 2.75m and 3.75 m. We take the rounded mean of this range, 3.2m, which results in an average distance of 1.6 m between the center point and lane boundaries on each side. We apply this value as a constant offset to the center points perpendicular to the driving direction. No lane boundary observations O are considered in this baseline.\n\n$mBPE_{baselinel} = \\frac{1}{N_B} \\sum_{i=0}^{N_B} ||\\widehat{B}_i - C_i|| - 1.6$\n\n2) Baseline 2: Nearest Lane Boundary Observation: For each center point $C_i$, this baseline predicts the boundary point at the position of the nearest lane boundary observation for each respective side. This can be formalized as:\n\n$mBPE_{baseline2} = \\frac{1}{N_B} \\sum_{i=0}^{N_B} ||\\widehat{B}_i - arg \\min_{O_j \\in O} ||C_i - O_j||$\n\nFor a fair evaluation of all data points, the corresponding lane pair derived from Baseline 1 is used for the evaluation if no nearest boundary point exists within a distance of 5 m.\n\n3) Baseline 3: Perpendicular Lane Boundary Observation: The third baseline implementation searches for the nearest intersection of the line perpendicular to the driving direction with the set O. This is done to each left and right side to the center point $C_i$. Those nearest left and right intersection points are considered as predicted boundary points. Again, if no intersection point exists within a distance of 5 m, the corresponding lane pair derived from Baseline 1 is used to reach a fair and complete evaluation."}, {"title": "D. Quantitative Results", "content": "This section summarizes the quantitative results of the LMT-Net evaluation. Table I shows the results per ODD. The table covers both metrics for boundary point prediction and lane connectivity prediction.\n\nSince baseline 1 does not exploit information from $O$, it underestimates the width of wide lanes, mostly found on highways, and overestimates the width of narrow lanes, mostly found on non-highways. Hence the mBPE is in the same range for highway and non-highway with 0.24 m and 0.27 m, respectively. Center points are located roughly in the middle of a lane, so the boundary point error adds up on both sides, resulting in a larger lane width error of 0.42 m on both highway and non-highway ODD, which is almost twice the mBPE.\n\nBaseline 2 chooses the nearest observation from $O$ to each side, making it sensitive for false positive observations as shown in Fig. 3. As a result, the mBPE is quite large with 0.70 m on both highway and non-highway, assumably from underestimating the distance to the boundary. The mLWE is not higher (0.45m and 0.49m for highway and non-highway) because a false positive observation on one side does not influence the observations on the other side.\n\nBaseline 3 fails to retrieve lane boundary points in case of gaps or missed observations. Thus, this baseline is sensitive to false negatives in O. In this frequent case, the baseline falls back to the constant offset point from baseline 1, reaching an overall decent mBPE of around 0.39 m. This aspect and the fact that baseline 3 is less affected by false positives make it achieve the best mLWE among all baselines, which is our most important metric.\n\nBaseline 4 provides predictions for lane connectivity. The heuristic based on forward direction works quite well and achieves around 96% accuracy. The $F_1$ score is lower with 67% on highway and 57% on non-highway.\n\nLMT-Net outperforms all baselines on highway mBPE and both mLWE metrics. The delta is specifically high on the more important mLWE, highlighting the benefit of this approach. Against baseline 3, which scores best on mLWE, LMT-Net achieves 0.15m vs. 0.31 m and 0.31m vs. 0.36 m mLWE on highway and non-highway, respectively. Only on non-highway mBPE, LMT-Net is second-best after baseline 1 with 0.35 m vs. 0.27m. We assume the main reason is an insufficient quantity of non-highway data to learn complex lane models. Furthermore, due to the independent data acquisition, the observed lane boundaries and the GT labels might be slightly misaligned, resulting in a small offset that does not affect baseline 1. Additionally, input and GT data might have been recorded at slightly different times, so some of the errors might come from temporary construction sites or real-world changes in the lane model. Further limitations are discussed in Sec. VI.\n\nOn the lane connectivity task, LMT-Net reaches close to perfect accuracy with 99%, outperforming baseline 4. $F_1$ score is also 99% on the highway, and for the much more unstructured non-highway case it reaches 94% still. This matches expectations since highways are highly structured and the connectivity is mostly trivial. For non-highway scenarios, the ODD includes more complex scenarios such as intersections, which have an impact on the performance when measured with the sensitive $F_1$ score. Evaluating the $F_1$ score shows a great benefit of the LMT-Net approach over the heuristic baseline.\n\nIn summary, LMT-Net outperforms the baselines in most cases and can also derive connectivity with great accuracy. Generally, both baselines and LMT-Net achieve better results on highways than non-highways. This is expected since the lane model in highway scenarios is typically less complex and more uniformly structured. Also, the distribution of the internal dataset is biased towards highway ODD and the amount of data on non-highway ODD might be insufficient to fully highlight the benefits of LMT-Net."}, {"title": "E. Qualitative Results", "content": "Fig. 4 shows various examples of LMT-Net predictions including highways, ramps, and non-highway scenarios. Overall, our approach performs well on highways. The ramp scenario shows that LMT-Net can also predict lane merges and forks. In the non-highway scenario, the lane pairs are correctly inferred even though the left lane boundaries were not covered in O."}, {"title": "F. Ablation Study", "content": "Two ablation studies are carried out to guide the design of the model architecture. Results are given in Tab. II.\n\n1) Polyline Encoding Variants: We implemented two polyline encoding variants as shown in Fig. 5:\n\n\u2022 Shared encoder for $T$ and $O$\n\n\u2022 Type-specific encoder for $T$ and $O$\n\nAs expected, type-specific polyline encoding yields better performance when comparing on the same number of decoder layers. Both types of inputs have very different characteristics and carry different information, so a type-specific encoding can generate a more customized feature space for each type of input. A type-specific polyline encoding increases model size from 3.44 Mio. to 3.71 Mio. parameters. For LMT-Net we choose a type-specific polyline encoding.\n\n2) Number of Transformer Decoder Layers: We evaluate the performance of LMT-Net with a varying number of transformer decoder layers. As shown in Tab. II, the number of learnable parameters increases with the number of decoder layers by around 0.6 Mio. parameters per additional decoder layer. The additional model capacity has little effect on the performance on highway scenarios due to the simplistic nature of that ODD. However, on more complex ODD (non-highway scenarios), more decoder layers improve the performance (4 instead of 1 decoder layer achieves 0.35 m vs. 0.40 m mBPE and 0.31 m vs. 0.39 m mLWE). A similar effect can be seen for connectivity, where LMT-Net with 4 decoder layers reaches 94%, while LMT-Net with 1 decoder layer reaches only 88%. We do not find relevant improvements beyond 4 decoder layers. Given the relation to model size, we select 4 decoder layers for LMT-Net."}, {"title": "VI. LIMITATIONS", "content": "One key limitation is that the pre-processing is currently performed in 2D, which limits LMT-Net to operate in 2D as well. This causes incorrect predictions for 3D road structures that overlap, such as with highway bridges, since LMT-Net cannot separate the features. Also, the sampling currently used is relatively low, which causes inaccuracies in strong curvatures. To capture such lane geometries better, a higher sampling is required, optimally as a function of curvature.\n\nThe scope of this work solely covers predicting the lane graph. To generate a full HD map with all relevant features, LMT-Net must be enabled to process other observed features such as poles and traffic signs. Furthermore, the tile stitching strategy needs more investigation. The current implementation does not have margins at tile boundaries. As a result, parts of $O$ and $T$ are cropped at the tile boundary, limiting context for LMT-Net."}, {"title": "VII. CONCLUSION", "content": "In this paper, we presented a novel approach for automated off-board map construction from multiple sparse vehicle observations. We proposed a transformer-based encoder-decoder model, LMT-Net, that uses a polyline encoding scheme and derives lane graphs with lane pairs as nodes and connectivity as edges, in an automated fashion. The two-stage approach combines existing traditional pre-processing with a learning-based method. We find that using driven traces as queries is an effective way to guide the decoding. We compared the experimental results with four geometric baselines. The results show that LMT-Net is a suitable approach for inferring lane geometries and their connectivity. This work creates an initial baseline that works specifically well on highways according to our ODD-specific evaluation. Finally, we discussed limitations that need to be addressed in future works."}]}