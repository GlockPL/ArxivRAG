{"title": "EHL*: Memory-Budgeted Indexing for Ultrafast Optimal Euclidean Pathfinding", "authors": ["Jinchun Du", "Bojie Shen", "Muhammad Aamir Cheema"], "abstract": "The Euclidean Shortest Path Problem (ESPP), which involves finding the shortest path in a Euclidean plane with polygonal obstacles, is a classic problem with numerous real-world applications. The current state-of-the-art solution, Euclidean Hub Labeling (EHL), offers ultra-fast query performance, outperforming existing techniques by 1-2 orders of magnitude in runtime efficiency. However, this performance comes at the cost of significant memory overhead, requiring up to tens of gigabytes of storage on large maps, which can limit its applicability in memory-constrained environments like mobile phones or smaller devices. Additionally, EHL's memory usage can only be determined after index construction, and while it provides a memory-runtime tradeoff, it does not fully optimize memory utilization. In this work, we introduce an improved version of EHL, called EHL*, which overcomes these limitations. A key contribution of EHL* is its ability to create an index that adheres to a specified memory budget while optimizing query runtime performance. Moreover, EHL* can leverage pre-known query distributions-a common scenario in many real-world applications-to further enhance runtime efficiency. Our results show that EHL* can reduce memory usage by up to 10-20 times without much impact on query runtime performance compared to EHL, making it a highly effective solution for optimal pathfinding in memory-constrained environments.", "sections": [{"title": "Introduction", "content": "The Euclidean Shortest Path Problem (ESPP) finds the shortest obstacle-avoiding path between a given source and target for an agent to travel. ESPP is a well-studied prob-lem with various real-world applications, including com-puter games (Sturtevant 2012b), robotics (Mac et al. 2016), and indoor navigation (Cheema 2018). In many of these ap-plications, it is crucial to compute the optimal shortest path as fast as possible, especially for large-scale deployments that require calculating tens of thousands of paths per sec-ond. This challenge has led to the development of numer-ous algorithms, such as navigation-mesh-based planners like Polyanya (Cui, Harabor, and Grastien 2017), enhanced vari-ations of visibility graphs like hierarchical sparse visibility graphs (Oh and Leong 2017), and oracle-based approaches"}, {"title": "Euclidean Hub Labeling (EHL)", "content": "This section introduces Euclidean Hub Labeling (EHL), the current state-of-the-art algorithm, which we further improve in this work. EHL consists of two phases discussed shortly: an offline preprocessing phase and an online query phase."}, {"title": "Offline Preprocessing", "content": "Building Hub Labelling on Visibility Graph Visibility graph is a popular concept utilized in many pathfinding algo-rithms for Euclidean space, e.g., (Oh and Leong 2017; Shen et al. 2020). The graph G = (V, E) consists of a set of con-vex vertices V and a set of edges E, where each edge e \u2208 E connects a pair of co-visible vertices in V. Given the con-structed visibility graph G = (V, E), Hub Labeling (HL) computes and stores, for each vertex vj \u2208 V, a set of hub labels denoted as H(vj). Each hub label in H(vj) is a tu-ple (hi, dij) that includes: (i) a hub vertex hi \u2208 V; and (ii) the shortest distance dij between the hub vertex hi and vj. HL must satisfy the coverage property (Cohen et al. 2003), which means that for every pair of reachable vertices vj \u2208 V and \u03c5\u03ba \u2208 V, H(vj) and H(vk) must contain at least one hub vertex hi on the shortest path from vj to vk. Thus, the short-est distance between any vs \u2208 V and any vt \u2208 V can be efficiently determined as follow:\n\n$d(v_s, v_t) = \\min_{h_i \\in H(v_s) \\cap H(v_t)} (d_{is} + d_{it})$                                                                                                                                                                                           (1)\n\nAccording to Eq. (1), the shortest distance between Us and vt can be calculated by performing a simple scan of the sorted label sets H(vs) and H(vt). The complexity is \u039f(|\u0397(vs)| + |\u0397(vt)|), where |H(vj)| represents the num-ber of labels in H(vj). The shortest path can be retrieved by utilizing the successor node for each label. We refer the reader to (Li et al. 2017) for details."}, {"title": "Computing Euclidean Hub Labelling", "content": "With the HL con-structed on the visibility graph, we can efficiently solve ESPP when both the start s and target t are at convex ver-tices. However, since s and t can be arbitrary locations, EHL adapts HL to handle these cases, as follows. EHL overlays a uniform grid on the map, with grid size adjustable to manage memory usage. For each cell c, EHL computes:\n\u2022 A visibility list Le: This list consists of every convex ver-tex v such that at least some part of c is visible from v.\n\u2022 A via-labels list VL(c): For each vertex vj in the visibil-ity list Le, we consider each hub label (hi, dij) \u2208 \u0397(vj) and insert a via-label hi:(vj, dij) into VL(c). Intuitively,"}, {"title": "Online Query Processing", "content": "First, we introduce minimal via-distance and how EHL com-putes it using the stored labels.\nMinimal Via-Distance The via-distance vdist(p, vj, hi) represents the length of the shortest path between a point p and hi passing through a convex vertex vj visible from p. Given a via label hi:(vj,dij) \u2208 VLh\u2081(c) and a point p\u2208 c, if vj is visible from p then vdist(p, vj, hi) = Edist(p, vj) + dij where Edist(p, vj) is the Euclidean dis-tance between p and vj. If vj is not visible from p, we as-sume vdist(p, vj,hi) = \u221e. Given a point p\u2208 cand the via labels VLh\u2081(c), we define the minimum via-distance vdistmin(p, hi) between p and hi as:\n$vdist_{min}(p, h_i) = \\min_{h_i:(v_j, d_{ij}) \\in VL_{h_i}(c)} vdist(p, v_j,h_i)$                                                     (2)\nComputing Shortest Distance Let cs and ct be the grid cells containing s and t, respectively. If s and t are co-visible, then the shortest distance d(s,t) is simply the Eu-clidean distance between them (i.e., d(s,t) = Edist(s,t)). If they are not co-visible, d(s, t) is computed as follows:\n\n$d(s,t) = \\min_{h_i \\in H(c_s) \\cap H(c_t)} vdist_{min}(s,h_i) + vdist_{min}(t, h_i)$                                                                                                                                             (3)\n\nOnce d(s, t) is determined, the shortest path sp(s,t) can be retrieved using the successor nodes. Please see (Du, Shen, and Cheema 2023) for details."}, {"title": "Euclidean Hub Labeling Star (EHL*)", "content": "In this section, we introduce EHL*, a memory-budgeted ver-sion of EHL. EHL* enhances EHL by introducing a com-pression phase during the offline preprocessing stage.\nOffline Preprocessing\nThe query performance of EHL depends on the number of labels stored in cs and Ct the fewer, the better. Thus, EHL performs better when the grid cells are small because smaller cells contain fewer labels. However, memory usage increases with smaller cells due to the likelihood of the same labels being stored in multiple cells. Memory usage in EHL can be significantly reduced without greatly impacting query performance by merging cells, as long as the number of la-bels per cell does not increase substantially. EHL* aims to achieve this as we detail next."}, {"title": "Algorithm 1: EHL*: Compression Phase", "content": "Recall that each via-label stored in a grid cell c is essen-tially a hub label copied from a convex vertex v, from which at least part of c is visible. As a result, neighboring cells often share many of the same hub labels. By merging ad-jacent cells that have a high overlap in hub labels, memory usage can be reduced without significantly impacting perfor-mance. EHL* leverages this insight by introducing a com-pression phase that iteratively checks adjacent grid cells and merges those with a high degree of hub label similarity.\nAlgorithm 1 details the compression phase. From this point on, we use \"region\" to refer to either a single grid cell or the shape resulting from merging two or more cells. The algorithm receives the constructed EHL and a mem-ory budget B as input. It begins by calling the function initializeScores(EHL) to assign a score to each grid cell in the EHL (line 1). These scores help determine which regions to merge in each iteration. We will explain the score computation in the next section. Next, the algorithm initial-izes a min heap H by inserting each grid cell along with its corresponding score (line 2) and sets up a mapper M that links each grid cell to its region in H (line 3). This mapper allows for efficient tracking of the merged regions associated with each grid cell.\nOnce initialization is complete, the algorithm be-gins compressing the EHL through a while loop. In each iteration, the algorithm extracts the top element e from the heap H (line 5) and calls the function adjacentRegionSelection(e, M), which examines each adjacent region of e and chooses a region r to merge with e (line 6). Two regions are considered adjacent if they share a boundary. The mapper M is used to efficiently iden-tify e's adjacent regions. Specifically, a region e' is adjacent to e if a cell c adjacent to e belongs to e' (as determined by the mapper M). The criteria for selecting the region r are discussed later. Once the region r is selected for merging with element e, they are merged at line 7 as follows .\n1. The region of element e is expanded to include r.\n2. To maintain the correctness of the algorithm, the via-labels of r and e are merged by taking their union. Specif-ically, for each via-label hi:(vj, dij) of r, we add it to VL(e) if hi:(vj, dij) \u2209 VL(e); otherwise, we ignore it.\n3. The score of e is incremented by the score of r, i.e., s(e) = s(e) + s(r), where s(x) denotes score of x.\nAfter merging region r into region e, the algorithm up-dates the mapper M by reassigning each grid cell c\u2208 r to the expanded region e, ensuring that adjacent regions are correctly tracked in future iterations (line 8). The region r is then removed from the heap H to prevent redundant merges, and the expanded region e is reinserted into H with its up-dated score (line 9). This process repeats until the mem-ory usage is less than or equal to the memory budget B (line 4), at which point EHL* has been successfully con-structed within the given budget. The algorithm also halts if all cells have merged into a single region (i.e., the heap con-tains only one element), which indicates that EHL* cannot be constructed within the memory limit. In our experiments, this situation only arises for certain small maps when the memory budget is set to just 1% of the original EHL mem-ory, which is already quite limited.\nThe algorithm initially calculates the total memory usage, and throughout the iterations, it tracks the reduction in mem-ory by subtracting the amount saved through label merging. The final output of the algorithm includes the compressed EHL (i.e., EHL*) and the updated mapper M, which enables faster query processing as discussed later (line 10).\nInitializing Scores The scores assigned to grid cells play a crucial role in the compression phase, as cells with lower scores are more likely to be merged. These scores can be tailored based on the application's specific needs. For exam-ple, if certain areas of the map require highly efficient query runtimes, the cells in those areas can be given higher scores to reduce the likelihood of being merged, thereby retaining fewer labels and improving performance. In the absence of such requirements, EHL* assigns the same score to all cells, i.e., s(c) = 1 for each cell. This simple approach ensures that the merged regions have approximately equal sizes and similar number of hub labels, leading to relatively consistent query performance across different map areas.\nAdjacent Region Selection To reduce memory usage without significantly affecting query runtime performance, the key is to keep the number of labels per region as small as possible. This can be accomplished by merging regions with substantial overlap in their hub labels. EHL* does this by examining all adjacent regions R of e and selecting the region r\u2208 R whose hub labels exhibit the highest Jaccard similarity with those of e (ties are broken arbitrarily).\n\n$r = arg \\max_{r' \\in R} ((1-a) \\frac{|H(r') \\cap H(e)|}{|H(r') \\cup H(e)|} + (a) \\frac{s(r')}{|| s(c)}))$                                                    (4)"}, {"title": "Online Query Processing", "content": "EHL stores labels in uniform grid cells whereas EHL* dif-fers by merging these cells into arbitrary-shaped regions. Despite this, both EHL and EHL* maintain the via-label list VL(e) within each region e, so the query processing algo-rithm remains the same. Note that EHL* needs to first locate the regions es and et that contain s and t, respectively. This can be easily done in O(1) by identifying the grid cells that contain s and t and then using the mapper M to find the corresponding regions es and et."}, {"title": "Query Workload-Aware EHL*", "content": "In many real-world scenarios, such as computer games, query workload can often be predicted because certain re-gions of a map are visited more frequently due to gameplay mechanics, player behavior patterns, or specific objectives. Workload-Aware algorithms (Sheng et al. 2023) can lever-age such knowledge if, for example, expected query distri-bution is known or can be predicted. We adapt EHL* for workload-aware scenarios by modifying its scoring compu-tation and adjacent region selection.\nInitializing Scores If the query distribution is known or can be predicted, EHL* can improve performance by keep-ing regions with higher expected workloads smaller, which in turn reduces the number of labels and enhances perfor-mance. To achieve this, EHL* prioritizes merging regions with lower expected query activity. Let we represent the ex-pected workload of a cell c, defined as the anticipated num-ber of queries where s or t falls within c. EHL* assigns an initial score to each cell as s(c) = 1 + wc, ensuring that no cell has a zero score, and that cells with higher workloads have higher scores, making them less likely to be merged.\nAdjacent Region Selection When merging regions, the primary goal remains minimizing the number of labels. Thus, EHL* still prioritizes similarity when selecting adja-cent regions for merging. However, instead of solely con-sidering similarity, we also factor in the expected workload, represented by the scores s(r) for each region r. The se-lection of an adjacent region r\u2208 R is now determined by combining these two criteria:\n\n$r = arg \\max_{r' \\in R} ((1-a) \\frac{|H(r') \\cap H(e)|}{|H(r') \\cup H(e)|} + (a) \\frac{s(r')}{|| s(c)}))$                                                    (5)"}, {"title": "Settings", "content": "We run our experiments on a 3.2 GHz Intel Core i7 ma-chine with 32GB of RAM. The algorithms are all imple-mented in C++ and compiled with -03 flag. Following ex-isting studies, we conduct experiments on the widely used game map benchmarks (Sturtevant 2012a), which consist of four games: Dragon Age II (DA), Dragon Age: Origins (DAO), Baldur's Gate II (BG), and StarCraft (SC). In total, we have 373 game maps from the four game benchmarks, each of which is represented as a grid map. Table 4 provides details of the benchmarks.\nQueries. To represent scenarios where the query distribu-tion is unknown, denoted as Unknown, we use the original dataset provided for each game map (Sturtevant 2012a). To simulate known query distributions, we generate synthetic query sets labeled Cluster-x, where x indicates the number of clustered regions (2, 4, or 8) within a map. These clus-ters are represented by rectangles, each generated by select-ing a random central point within the traversable area of the map and ensuring the rectangle does not extend beyond map boundaries. The rectangles, with side lengths set to 10% of the width and height of the map, are positioned to ensure at least one other rectangle is reachable, preventing isolation. We generate source s and target t pairs as randomly selected locations within these rectangles ensuring that the path be-tween s and t exists for each generated query. Using this approach, we generate (i) 500,000 s and t pairs as historical queries on the map, which EHL* uses to calculate the work-load for each cell and build the index, and (ii) 2,000 s and t pairs to evaluate runtime performance. To evaluate runtime, each query is run five times, and the average is reported."}, {"title": "Algorithms Evaluated", "content": "We compare our approach with the state-of-the-art algorithm\u00b9, EHL-x (Du, Shen, and Cheema 2023), where x denotes the cell size in EHL, varying x from 1 to 4 (similar to the original work). Additionally, we com-pare our method with Polyanya\u00b2 (Cui, Harabor, and Grastien 2017), an optimal online pathfinding algorithm that runs on a navigation mesh, and EPS\u00b3 (Shen et al. 2020), an optimal offline pathfinding algorithm that utilizes a Compressed Path Database (CPD) (Strasser, Harabor, and Botea 2014). We evaluate EHL* under different memory budgets, denoted as EHL*-x, where x represents the percentage of memory used compared to EHL-1, e.g., the budget for EHL*-60 is 60% of the memory used by EHL-1. For reproducibility, implemen-tation of EHL* is available online4."}, {"title": "Experiment 1: Preprocessing Time and Space", "content": "Table 5 compares the average memory usage (in MB) and build time (in secs) of EHL* for different memory budgets with EHL, EPS and Polyanya. Compared to EHL, EHL* offers precise memory usage control, successfully reducing memory down to 5%, making it adaptable to different de-vices based on application needs. While EHL also offers a memory-runtime trade-off by increasing cell sizes, its mem-ory usage cannot be predicted before index construction and lacks fine-tuned control. EPS and Polyanya, however, re-"}, {"title": "Experiment 2: Memory-Runtime Tradeoff", "content": "Next, we discuss the memory-runtime tradeoff for each al-gorithm. Table 5 also shows the query runtime (in \u00b5s) for both the unknown and clustered queries. EPS and Polyanya offer lower memory usage but are 1-2 orders of magnitude slower than EHL and EHL*. EHL* reduces memory usage of EHL-1 from 80% to 20% with minimal impact on its runtime, but further reductions to 10% and 5% lead to no-ticeable increases in query time due to significantly larger merged regions leading to slower runtimes. Comparing with EHL on unknown query distributions, EHL*-80 and EHL*-60 use less memory than EHL-1 while keeping runtimes competitive, and EHL*-40 and EHL*-20, while similar in memory usage to EHL-2 and EHL-4, deliver better runtimes, thus outperforming EHL.\nWhen the query distribution is known in advance, EHL* leverages this information to significantly improve the per-formance. With a small number of cluster regions (e.g., Cluster-2 and Cluster-4), EHL* can reduce the memory budget from 80% to 5% while maintaining similar query"}, {"title": "Experiment 3: Query Distribution Deviations", "content": "In this section, we analyze the performance of EHL* for queries that diverge from the predicted distribution. We con-struct EHL* based on the assumed Cluster-x distribution, but only y% of the queries adhere to this distribution, while the remaining (100 \u2013 y)% are generated randomly. We vary y from 100 to 20. Table 5 shows the average runtime (in \u00b5s) for the three cluster query sets in the DA benchmark. We compare our approaches, EHL* (known), which tries to ex-ploit query distribution, and EHL* (unknown), which has no information on query distribution, with EHL-1, EHL-2, and EHL-4. As expected, when a larger number of queries devi-ate from the predicted distribution (i.e., smaller y%), the per-formance of EHL* (known) drops significantly, especially when the budget is 20% of EHL-1 (although still competitive compared to EHL-4). This occurs because EHL* (known) tends to merge grid cells outside the cluster region when memory budget is constrained. As a result, when queries de-viate from the cluster regions, larger regions with more via-labels are required to answer the queries, leading to slower query runtimes. In contrast, EHL* (unknown) and EHL re-main stable as the number of deviated queries increases since they do not depend on pre-existing query distributions to build index. When most test queries follow the predicted distributions (i.e., 100% and 80%), EHL* (known) outper-forms EHL* (unknown) and EHL. However, when more queries deviate from the prediction (i.e., 50% and 20%), EHL* (known) performs worse than both approaches."}, {"title": "Conclusion", "content": "We propose EHL*, an improved version of EHL that offers the flexibility to build the index within a specified memory budget while optimizing query runtime. Experiments show that EHL* reduces memory usage while maintaining com-petitive query runtimes. Additionally, when query distribu-tions are known in advance, EHL* leverages this informa-tion to build an index that outperforms EHL in both memory efficiency and query runtime. Future work includes explor-ing exploring ML-based regions for further improvements."}]}