{"title": "EHL*: Memory-Budgeted Indexing for Ultrafast Optimal Euclidean Pathfinding", "authors": ["Jinchun Du", "Bojie Shen", "Muhammad Aamir Cheema"], "abstract": "The Euclidean Shortest Path Problem (ESPP), which involves finding the shortest path in a Euclidean plane with polygonal obstacles, is a classic problem with numerous real-world applications. The current state-of-the-art solution, Euclidean Hub Labeling (EHL), offers ultra-fast query performance, outperforming existing techniques by 1-2 orders of magnitude in runtime efficiency. However, this performance comes at the cost of significant memory overhead, requiring up to tens of gigabytes of storage on large maps, which can limit its applicability in memory-constrained environments like mobile phones or smaller devices. Additionally, EHL's memory usage can only be determined after index construction, and while it provides a memory-runtime tradeoff, it does not fully optimize memory utilization. In this work, we introduce an improved version of EHL, called EHL*, which overcomes these limitations. A key contribution of EHL* is its ability to create an index that adheres to a specified memory budget while optimizing query runtime performance. Moreover, EHL* can leverage pre-known query distributions\u2014a common scenario in many real-world applications\u2014to further enhance runtime efficiency. Our results show that EHL* can reduce memory usage by up to 10-20 times without much impact on query runtime performance compared to EHL, making it a highly effective solution for optimal pathfinding in memory-constrained environments.", "sections": [{"title": "Introduction", "content": "The Euclidean Shortest Path Problem (ESPP) finds the shortest obstacle-avoiding path between a given source and target for an agent to travel. ESPP is a well-studied problem with various real-world applications, including computer games (Sturtevant 2012b), robotics (Mac et al. 2016), and indoor navigation (Cheema 2018). In many of these applications, it is crucial to compute the optimal shortest path as fast as possible, especially for large-scale deployments that require calculating tens of thousands of paths per second. This challenge has led to the development of numerous algorithms, such as navigation-mesh-based planners like Polyanya (Cui, Harabor, and Grastien 2017), enhanced variations of visibility graphs like hierarchical sparse visibility graphs (Oh and Leong 2017), and oracle-based approaches like End Point Search (EPS) (Shen et al. 2020) and Euclidean Hub Labeling (EHL) (Du, Shen, and Cheema 2023).\nAmong the existing optimal algorithms, the state-of-the-art is EHL, which exploits Hub Labeling (Abraham et al. 2011), the leading shortest path approach for graphs such as road networks. During the preprocessing phase, EHL constructs a visibility graph on the convex vertices of the polygonal obstacles and precomputes the hub labeling on this graph. The precomputed hub labels of each vertex are then copied to each grid cell of a uniform grid that is visible from the vertex. During the online phase, EHL considers the labels stored in the grid cells containing the start and target, respectively. These labels are joined to obtain the shortest path via a merge-join process.\nEHL is 1-2 orders of magnitude faster than existing algorithms and performs best when grid cells are small (i.e., there are many grid cells). However, in this case, it requires substantial memory to store the labels, limiting its use in memory-constrained environments. Although EHL offers a memory-runtime trade-off by increasing the grid cell size to reduce memory usage at the cost of longer running times, it still faces two limitations: 1) Memory required by EHL cannot be predicted in advance and is only known after the index is constructed. This is problematic for smaller devices with fixed memory budgets that need to create an index within the budget while optimizing runtime. 2) In many real-world cases, queries often follow a specific distribution, with certain areas of maps receiving more queries than others. While works in other domains (Sheng et al. 2023; Tzoumas, Yiu, and Jensen 2009) show that this information can be exploited to improve performance, EHL does not take advantage of this information, even when it is available.\nIn this paper, we address these limitations of EHL and propose EHL*, an improved version of EHL that works within a memory budget B to optimize the query runtime while still guaranteeing to find the optimal solution. Moreover, it is also able to exploit the expected query distribution if it is known beforehand. EHL* builds on EHL by incorporating a compression phase that merges the labels of adjacent grid cells into arbitrary-shaped regions. Each merging effectively reduces the memory because the labels that were stored twice in two different cells/regions are now likely to be stored once in one larger region. The key is to carefully select which cells or regions to merge, ensuring that memory"}, {"title": "Preliminaries", "content": "An obstacle is represented by a polygon that consists of a closed set of edges, each associated with two points at its ends, known as vertices. A convex vertex (resp. non-convex vertex) is a vertex located at a convex (resp. concave) corner of the polygon. Two points are said to be visible to each other (also known as co-visible) iff there exists a straight line between them that does not pass through any obstacle. A path P between a source s and target t is a sequence of points $(p_1,p_2,\\dots, p_n)$ where $p_1 = s$, $p_n = t$ and every successive pair of points $p_i$ and $p_{i+1}$ (i < n) is co-visible. The length of a path P is the total sum of the Euclidean distances between each consecutive pair of points along the path, denoted as |P|, i.e., $|P| = \\sum_{i=1}^{n-1} Edist(p_i, p_{i+1})$ where Edist$(p_i, p_{i+1})$ is the Euclidean distance between $p_i$ and $p_{i+1}$. The Euclidean Shortest Path Problem (ESPP) computes the shortest obstacle-avoiding path between a given"}, {"title": "Euclidean Hub Labeling (EHL)", "content": "This section introduces Euclidean Hub Labeling (EHL), the current state-of-the-art algorithm, which we further improve in this work. EHL consists of two phases discussed shortly: an offline preprocessing phase and an online query phase."}, {"title": "Offline Preprocessing", "content": "Building Hub Labelling on Visibility Graph Visibility graph is a popular concept utilized in many pathfinding algorithms for Euclidean space, e.g., (Oh and Leong 2017; Shen et al. 2020). The graph G = (V, E) consists of a set of convex vertices V and a set of edges E, where each edge e \u2208 E connects a pair of co-visible vertices in V. Given the constructed visibility graph G = (V, E), Hub Labeling (HL) computes and stores, for each vertex $v_j \\in V$, a set of hub labels denoted as H($v_j$). Each hub label in H($v_j$) is a tuple ($h_i, d_{ij}$) that includes: (i) a hub vertex $h_i \\in V$; and (ii) the shortest distance $d_{ij}$ between the hub vertex $h_i$ and $v_j$. HL must satisfy the coverage property (Cohen et al. 2003), which means that for every pair of reachable vertices $v_j \\in V$ and $v_k \\in V$, H($v_j$) and H($v_k$) must contain at least one hub vertex $h_i$ on the shortest path from $v_j$ to $v_k$. Thus, the shortest distance between any $v_s \\in V$ and any $v_t \\in V$ can be efficiently determined as follow:\n$d(v_s, v_t) = \\min_{h_i \\in H(v_s) \\cap H(v_t)} (d_{is} + d_{it})$  (1)\nAccording to Eq. (1), the shortest distance between $v_s$ and $v_t$ can be calculated by performing a simple scan of the sorted label sets H($v_s$) and H($v_t$). The complexity is \u039f(|H($v_s$)| + |H($v_t$)|), where |H($v_j$)| represents the number of labels in H($v_j$). The shortest path can be retrieved by utilizing the successor node for each label. We refer the reader to (Li et al. 2017) for details.\nWith the HL constructed on the visibility graph, we can efficiently solve ESPP when both the start s and target t are at convex vertices. However, since s and t can be arbitrary locations, EHL adapts HL to handle these cases, as follows. EHL overlays a uniform grid on the map, with grid size adjustable to manage memory usage. For each cell c, EHL computes:\n\u2022 A visibility list $L_c$: This list consists of every convex vertex v such that at least some part of c is visible from v.\n\u2022 A via-labels list VL(c): For each vertex $v_j$ in the visibility list $L_c$, we consider each hub label ($h_i, d_{ij}$) \u2208 H($v_j$) and insert a via-label $h_i$:(vj, $d_{ij}$) into VL(c). Intuitively,"}, {"title": "Online Query Processing", "content": "First, we introduce minimal via-distance and how EHL computes it using the stored labels.\nMinimal Via-Distance The via-distance vdist(p, $v_j$, $h_i$) represents the length of the shortest path between a point p and $h_i$ passing through a convex vertex $v_j$ visible from p. Given a via label $h_i$:(vj, $d_{ij}$) \u2208 VLhi(c) and a point p \u2208 c, if $v_j$ is visible from p then vdist(p, vj, hi) = Edist(p, $v_j$) + $d_{ij}$ where Edist(p, $v_j$) is the Euclidean distance between p and $v_j$. If $v_j$ is not visible from p, we assume vdist(p, vj, hi) = \u221e. Given a point p \u2208 c and the via labels VLhi(c), we define the minimum via-distance vdistmin(p, hi) between p and hi as:\nvdistmin(p, hi) = $\\min_{h_i:(v_j, d_{ij}) \\in VL_{h_i}(c)}$ vdist(p, vj, hi)  (2)\nComputing Shortest Distance Let $c_s$ and $c_t$ be the grid cells containing s and t, respectively. If s and t are co-visible, then the shortest distance d(s,t) is simply the Euclidean distance between them (i.e., d(s,t) = Edist(s,t)). If they are not co-visible, d(s, t) is computed as follows:\nd(s,t) = $\\min_{h_i \\in H(c_s) \\cap H(c_t)}$ vdistmin(s, hi) + vdistmin(t, hi)  (3)\nOnce d(s, t) is determined, the shortest path sp(s,t) can be retrieved using the successor nodes. Please see (Du, Shen, and Cheema 2023) for details."}, {"title": "Euclidean Hub Labeling Star (EHL*)", "content": "In this section, we introduce EHL*, a memory-budgeted version of EHL. EHL* enhances EHL by introducing a compression phase during the offline preprocessing stage."}, {"title": "Offline Preprocessing", "content": "The query performance of EHL depends on the number of labels stored in $c_s$ and $c_t$ the fewer, the better. Thus, EHL performs better when the grid cells are small because smaller cells contain fewer labels. However, memory usage increases with smaller cells due to the likelihood of the same labels being stored in multiple cells. Memory usage in EHL can be significantly reduced without greatly impacting query performance by merging cells, as long as the number of labels per cell does not increase substantially. EHL* aims to achieve this as we detail next.\nAlgorithm 1 details the compression phase. From this point on, we use \"region\" to refer to either a single grid cell or the shape resulting from merging two or more cells. The algorithm receives the constructed EHL and a memory budget B as input. It begins by calling the function initializeScores(EHL) to assign a score to each grid cell in the EHL (line 1). These scores help determine which regions to merge in each iteration. We will explain the score computation in the next section. Next, the algorithm initializes a min heap H by inserting each grid cell along with its corresponding score (line 2) and sets up a mapper M that links each grid cell to its region in H (line 3). This mapper allows for efficient tracking of the merged regions associated with each grid cell.\nOnce initialization is complete, the algorithm begins compressing the EHL through a while loop. In each iteration, the algorithm extracts the top element e from the heap H (line 5) and calls the function adjacentRegionSelection(e, M), which examines each adjacent region of e and chooses a region r to merge with e (line 6). Two regions are considered adjacent if they share a boundary. The mapper M is used to efficiently identify e's adjacent regions. Specifically, a region e' is adjacent to e if a cell c adjacent to e belongs to e' (as determined by the mapper M). The criteria for selecting the region r are discussed later. Once the region r is selected for merging with element e, they are merged at line 7 as follows .\n1. The region of element e is expanded to include r.\n2. To maintain the correctness of the algorithm, the via-labels of r and e are merged by taking their union. Specifically, for each via-label hi:(vj, $d_{ij}$) of r, we add it to VL(e) if hi:(vj, $d_{ij}$) \u2209 VL(e); otherwise, we ignore it.\n3. The score of e is incremented by the score of r, i.e., s(e) = s(e) + s(r), where s(x) denotes score of x.\nAfter merging region r into region e, the algorithm updates the mapper M by reassigning each grid cell c\u2208 r to the expanded region e, ensuring that adjacent regions are correctly tracked in future iterations (line 8). The region r is then removed from the heap H to prevent redundant merges, and the expanded region e is reinserted into H with its updated score (line 9). This process repeats until the memory usage is less than or equal to the memory budget B (line 4), at which point EHL* has been successfully constructed within the given budget. The algorithm also halts if all cells have merged into a single region (i.e., the heap contains only one element), which indicates that EHL* cannot be constructed within the memory limit. In our experiments, this situation only arises for certain small maps when the memory budget is set to just 1% of the original EHL memory, which is already quite limited.\nThe algorithm initially calculates the total memory usage, and throughout the iterations, it tracks the reduction in memory by subtracting the amount saved through label merging. The final output of the algorithm includes the compressed EHL (i.e., EHL*) and the updated mapper M, which enables faster query processing as discussed later (line 10).\nInitializing Scores The scores assigned to grid cells play a crucial role in the compression phase, as cells with lower scores are more likely to be merged. These scores can be tailored based on the application's specific needs. For example, if certain areas of the map require highly efficient query runtimes, the cells in those areas can be given higher scores to reduce the likelihood of being merged, thereby retaining fewer labels and improving performance. In the absence of such requirements, EHL* assigns the same score to all cells, i.e., s(c) = 1 for each cell. This simple approach ensures that the merged regions have approximately equal sizes and similar number of hub labels, leading to relatively consistent query performance across different map areas.\nAdjacent Region Selection To reduce memory usage without significantly affecting query runtime performance, the key is to keep the number of labels per region as small as possible. This can be accomplished by merging regions with substantial overlap in their hub labels. EHL* does this by examining all adjacent regions R of e and selecting the region r\u2208 R whose hub labels exhibit the highest Jaccard similarity with those of e (ties are broken arbitrarily).\nr = arg max $\\frac{|H(r') \\cap H(e)|}{|H(r') \\cup H(e)|}$ (4)"}, {"title": "Online Query Processing", "content": "EHL stores labels in uniform grid cells whereas EHL* differs by merging these cells into arbitrary-shaped regions. Despite this, both EHL and EHL* maintain the via-label list VL(e) within each region e, so the query processing algorithm remains the same. Note that EHL* needs to first locate the regions es and et that contain s and t, respectively. This can be easily done in O(1) by identifying the grid cells that contain s and t and then using the mapper M to find the corresponding regions es and et."}, {"title": "Query Workload-Aware EHL*", "content": "In many real-world scenarios, such as computer games, query workload can often be predicted because certain regions of a map are visited more frequently due to gameplay mechanics, player behavior patterns, or specific objectives. Workload-Aware algorithms (Sheng et al. 2023) can leverage such knowledge if, for example, expected query distribution is known or can be predicted. We adapt EHL* for workload-aware scenarios by modifying its scoring computation and adjacent region selection.\nInitializing Scores If the query distribution is known or can be predicted, EHL* can improve performance by keeping regions with higher expected workloads smaller, which in turn reduces the number of labels and enhances performance. To achieve this, EHL* prioritizes merging regions with lower expected query activity. Let wc represent the expected workload of a cell c, defined as the anticipated number of queries where s or t falls within c. EHL* assigns an initial score to each cell as s(c) = 1 + wc, ensuring that no cell has a zero score, and that cells with higher workloads have higher scores, making them less likely to be merged.\nAdjacent Region Selection When merging regions, the primary goal remains minimizing the number of labels. Thus, EHL* still prioritizes similarity when selecting adjacent regions for merging. However, instead of solely considering similarity, we also factor in the expected workload, represented by the scores s(r) for each region r. The selection of an adjacent region r\u2208 R is now determined by combining these two criteria:\nr = arg max $(1-\\alpha)(\\frac{|H(r') \\cap H(e)|}{|H(r') \\cup H(e)|}) + \\alpha(\\frac{s(r')}{s(e)})$ (5)\nNote that regions with higher workloads s(r') are less likely to be selected for merging. The weighting factor \u03b1, set to 0.2 based on experimental results, balances the influence of similarity and workload."}, {"title": "Experiments", "content": "Settings\nWe run our experiments on a 3.2 GHz Intel Core i7 machine with 32GB of RAM. The algorithms are all implemented in C++ and compiled with -03 flag. Following existing studies, we conduct experiments on the widely used game map benchmarks (Sturtevant 2012a), which consist of four games: Dragon Age II (DA), Dragon Age: Origins (DAO), Baldur's Gate II (BG), and StarCraft (SC). In total, we have 373 game maps from the four game benchmarks, each of which is represented as a grid map.\nQueries. To represent scenarios where the query distribution is unknown, denoted as Unknown, we use the original dataset provided for each game map (Sturtevant 2012a). To simulate known query distributions, we generate synthetic query sets labeled Cluster-x, where x indicates the number of clustered regions (2, 4, or 8) within a map. These clusters are represented by rectangles, each generated by selecting a random central point within the traversable area of the map and ensuring the rectangle does not extend beyond map boundaries. The rectangles, with side lengths set to 10% of the width and height of the map, are positioned to ensure at least one other rectangle is reachable, preventing isolation. We generate source s and target t pairs as randomly selected locations within these rectangles ensuring that the path between s and t exists for each generated query. Using this approach, we generate (i) 500,000 s and t pairs as historical queries on the map, which EHL* uses to calculate the workload for each cell and build the index, and (ii) 2,000 s and t pairs to evaluate runtime performance. To evaluate runtime, each query is run five times, and the average is reported."}, {"title": "Algorithms Evaluated.", "content": "We compare our approach with the state-of-the-art algorithm, EHL-x (Du, Shen, and Cheema 2023), where x denotes the cell size in EHL, varying x from 1 to 4 (similar to the original work). Additionally, we compare our method with Polyanya (Cui, Harabor, and Grastien 2017), an optimal online pathfinding algorithm that runs on a navigation mesh, and EPS (Shen et al. 2020), an optimal offline pathfinding algorithm that utilizes a Compressed Path Database (CPD) (Strasser, Harabor, and Botea 2014). We evaluate EHL* under different memory budgets, denoted as EHL*-x, where x represents the percentage of memory used compared to EHL-1, e.g., the budget for EHL*-60 is 60% of the memory used by EHL-1. For reproducibility, implementation of EHL* is available online.\nExperiment 1: Preprocessing Time and Space\nTable 5 compares the average memory usage (in MB) and build time (in secs) of EHL* for different memory budgets with EHL, EPS and Polyanya. Compared to EHL, EHL* offers precise memory usage control, successfully reducing memory down to 5%, making it adaptable to different devices based on application needs. While EHL also offers a memory-runtime trade-off by increasing cell sizes, its memory usage cannot be predicted before index construction and lacks fine-tuned control. EPS and Polyanya, however, require significantly less memory but at the expense of a much higher query runtime as shown shortly. Polyanya's memory usage is not shown, as it is an online algorithm that requires no index, aside from a navigation mesh with a negligible memory footprint. Although EHL* requires nearly twice the preprocessing time compared to EHL-1 and significantly more preprocessing time than the other competitors, the overall build time remains reasonable and practical for most application needs.\nExperiment 2: Memory-Runtime Tradeoff\nNext, we discuss the memory-runtime tradeoff for each algorithm. Table 5 also shows the query runtime (in \u00b5s) for both the unknown and clustered queries. EPS and Polyanya offer lower memory usage but are 1-2 orders of magnitude slower than EHL and EHL*. EHL* reduces memory usage of EHL-1 from 80% to 20% with minimal impact on its runtime, but further reductions to 10% and 5% lead to noticeable increases in query time due to significantly larger merged regions leading to slower runtimes. Comparing with EHL on unknown query distributions, EHL*-80 and EHL*-60 use less memory than EHL-1 while keeping runtimes competitive, and EHL*-40 and EHL*-20, while similar in memory usage to EHL-2 and EHL-4, deliver better runtimes, thus outperforming EHL.\nWhen the query distribution is known in advance, EHL* leverages this information to significantly improve the performance. With a small number of cluster regions (e.g., Cluster-2 and Cluster-4), EHL* can reduce the memory budget from 80% to 5% while maintaining similar query"}, {"title": "runtimes,", "content": "making the memory reduction nearly cost-free. Compared to EHL, EHL* remains competitive with EHL-1 across all memory budgets and consistently outperforms EHL-2 and EHL-4, demonstrating a superior memory-runtime tradeoff. As the number of cluster regions increases (e.g., Cluster-8), memory reduction becomes more challenging, leading to a more noticeable increase in query runtime. Nevertheless, the performance remains better than EHL for Cluster-8, e.g., when the memory budget is reduced to 5%, EHL*-5 still outperforms EHL-4 which consumes 3-5 times more memory.\nresults show the average runtime (in \u00b5s) for the three cluster query sets in the DA benchmark. We compare our approaches, EHL* (known), which tries to exploit query distribution, and EHL* (unknown), which has no information on query distribution, with EHL-1, EHL-2, and EHL-4. As expected, when a larger number of queries deviate from the predicted distribution (i.e., smaller y%), the performance of EHL* (known) drops significantly, especially when the budget is 20% of EHL-1 (although still competitive compared to EHL-4). This occurs because EHL* (known) tends to merge grid cells outside the cluster region when memory budget is constrained. As a result, when queries deviate from the cluster regions, larger regions with more via-labels are required to answer the queries, leading to slower query runtimes. In contrast, EHL* (unknown) and EHL remain stable as the number of deviated queries increases since they do not depend on pre-existing query distributions to build index. When most test queries follow the predicted distributions (i.e., 100% and 80%), EHL* (known) outperforms EHL* (unknown) and EHL. However, when more queries deviate from the prediction (i.e., 50% and 20%), EHL* (known) performs worse than both approaches."}, {"title": "Conclusion", "content": "We propose EHL*, an improved version of EHL that offers the flexibility to build the index within a specified memory budget while optimizing query runtime. Experiments show that EHL* reduces memory usage while maintaining competitive query runtimes. Additionally, when query distributions are known in advance, EHL* leverages this information to build an index that outperforms EHL in both memory efficiency and query runtime. Future work includes exploring exploring ML-based regions for further improvements."}]}