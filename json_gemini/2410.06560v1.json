{"title": "MITIGATING TIME DISCRETIZATION CHALLENGES WITH WEATHERODE: A SANDWICH PHYSICS-DRIVEN NEURAL ODE FOR WEATHER FORECASTING", "authors": ["Peiyuan Liu", "Tian Zhou", "Liang Sun", "Rong Jin"], "abstract": "In the field of weather forecasting, traditional models often grapple with discretization errors and time-dependent source discrepancies, which limit their predictive performance. In this paper, we present WeatherODE, a novel one-stage, physics-driven ordinary differential equation (ODE) model designed to enhance weather forecasting accuracy. By leveraging wave equation theory and integrating a time-dependent source model, WeatherODE effectively addresses the challenges associated with time-discretization error and dynamic atmospheric proesses. Moreover, we design a CNN-ViT-CNN sandwich structure, facilitating efficient learning dynamics tailored for distinct yet interrelated tasks with varying optimization biases in advection equation estimation. Through rigorous experiments, WeatherODE demonstrates superior performance in both global and regional weather forecasting tasks, outperforming recent state-of-the-art approaches by significant margins of over 40.0% and 31.8% in root mean square error (RMSE), respectively. The source code is available at https://github.com/DAMO-DI-ML/WeatherODE.", "sections": [{"title": "1 INTRODUCTION", "content": "Weather forecasting is a cornerstone of modern society, affecting key industries like agriculture, transportation, and disaster management (Coiffier, 2011). Accurate predictions help mitigate the effects of extreme weather and optimize economic operations. Recent advancements in high-performance computing have significantly boosted the accuracy and speed of numerical weather forecasting (NWP) (Bauer et al., 2015; Lorenc, 1986; Kimura, 2002).\n\nThe swift advancement of deep learning has opened up a promising avenue for weather forecasting (Weyn et al., 2019; Scher & Messori, 2019; Rasp et al., 2020a; Weyn et al., 2021; Bi et al., 2023; Pathak et al., 2022; Hu et al., 2023). However, the existing weather forecasting models based on deep learning often fail to fully account for the key physical mechanisms governing small-scale, complex nonlinear atmospheric phenomena, such as turbulence, convection, and airflow. These dynamic processes are crucial to the formation and evolution of weather systems, but most models focus on learning statistical correlations from historical data instead of explicitly extracting or integrating these physical dynamics. Furthermore, these models typically rely on fixed time intervals (e.g., every 6 hours) for predictions, limiting their applicability to varying temporal scales. Consequently, separate models are often required for different forecast periods (Bi et al., 2023), which constrains flexibility and reduces generalization.\n\nAnother line of research utilizes neural ODEs (Chen et al., 2018) that incorporate partial differential equations to guide the physical dynamics of weather forecasting. Among these methods, the advection continuity equation stands out as a key equation governing many weather indicators:\n\n$\\frac{\\partial u}{\\partial t} + v \\cdot \\nabla u + u \\nabla \\cdot v = S$"}, {"title": "2 RELATED WORKS", "content": "The most advanced weather forecasting techniques predominantly rely on Numerical Weather Prediction (NWP) (Lorenc, 1986; Kimura, 2002), which employs a set of equations solved on super-computers to model and predict the atmosphere. While NWP has achieved promising results, it is resource-intensive, requiring significant computational power and domain expertise to define the appropriate physical equations.\n\nDeep learning-based weather forecasting adopts a data-driven approach to learning the spatio-temporal relationships between atmospheric variables. These methods can be broadly classified into Graph Neural Networks (GNN) and Transformer-based methods. GNN-based methods (Lam et al., 2022; Keisler, 2022) treat the Earth as a graph and use graph neural networks to predict weather patterns. Transformer-based approaches have shown significant success in weather forecasting due to their scalability (Chen et al., 2023b;a; Han et al., 2024; Vaswani, 2017). For example, Pangu (Bi et al., 2023) employs a 3D Swin Transformer (Liu et al., 2021) and an autoregressive model to accelerate inference. Fengwu (Chen et al., 2023a) models atmospheric variables as separate modalities and uses a replay buffer for optimization, with Fengwu-GHR (Han et al., 2024) subsequently extending the approach to higher-resolution data. Additionally, ClimaX (Nguyen et al., 2023) and Aurora (Bodnar et al., 2024) introduce a pretraining-finetuning framework, where models are first pretrained on physics-simulated data and then finetuned on real-world data. However, these models frequently neglect the fundamental physical dynamics of the atmosphere and are limited to providing fixed lead time for each prediction.\n\nPhysics-driven methods, which integrate physical constraints in the form of partial differential equations (PDEs) (Evans, 2022) into neural networks, have gained increasing attention in recent years (Cai et al., 2021; Li et al., 2024b). In weather forecasting, DeepPhysiNet (Li et al., 2024a) incorporates physical laws into the loss function, marking an initial attempt to combine neural networks with PDEs. ClimODE (Verma et al., 2024) advances further by leveraging the continuity equation to express the weather forecasting process as a full PDE system modeled using neural ODEs (Chen et al., 2018). NeuralGCM (Kochkov et al., 2024) incorporates more physical constraints and designs neural networks to function as a dynamic core. However, it is complex and difficult to modify, as it operates with over a dozen ODE functions similar to the NWP method. In contrast, our proposed WeatherODE offers a more straightforward and efficient foundation for ongoing improvements."}, {"title": "3 METHOD", "content": "In this section, we first introduce the overall ODE modeling framework for weather forecasting in Section 3.1. We then describe the specific designs of the Velocity Model, Advection ODE, and Source Model in Section 3.2, Section 3.3, and Section 3.4, respectively. We present the overarching design choices for our CNN-ViT-CNN sandwich structure in Section 3.5. Finally, we end up with the multi-task learning strategy in Section 3.6."}, {"title": "3.1 ODE FRAMEWORK FOR WEATHER DYNAMICS", "content": "We can model the atmosphere as a spatio-temporal process $u(x, y, t) = (u_1(x, y, t),...,u_K(x,y,t)) \\in R^K$, where K represents the number of distinct atmospheric variables $u_k(x,y,t) \\in R$, evolving over continuous time t and spatial coordinates $(x,y) \\in [0, H] \\times [0, W]$, H and W are the height and width, respectively. Each quantity or atmospheric variable is driven by a velocity field $v_r(x, y, t) \\in R^{2K}$ and influenced by a source term"}, {"title": "3.2 VELOCITY MODEL", "content": "Modeling the initial velocity $v(t_0)$ is crucial for ensuring the stability of the ODE solution. ClimODE (Verma et al., 2024) estimates the initial velocity by first calculating the discrete-time derivative $\\frac{\\Delta u}{\\Delta t}$ from several past time points. However, using the discrete approximation $\\frac{\\Delta u}{\\Delta t}$ introduces large numerical errors, especially when $\\Delta t$ is not small enough. This approach struggles to capture smooth variations, resulting in significant deviations from the true continuous derivatives. Moreover, it involves a two-stage process where a separate model must first be trained to estimate all initial values $v(t_0)$ before proceeding with the ODE solution."}, {"title": "3.3 ADVECTION ODE", "content": "In the discretized ODE system in Equation 3, the term $u(t_n)$ can be computed from the current values of $u(t_n)$ and $v(t_n)$ using the advection equation. For $v(t_n)$, we design an advection model:\n\n$\\dot{v}(t_n) = f_\\theta(u(t_n), \\nabla u(t_n), v(t_n), (\\phi_s, \\phi_t)),$\n\nwhere $(\\phi_s, \\phi_t)$ represent the spatial-temporal embeddings and details can be found in Appendix C.2.\n\nThe design of the advection model $f_\\theta$ is crucial for ensuring the stability of the numerical solution, as it takes the output from the velocity model as input. We argue that $f_\\theta$ should converge more slowly than the CNN-based velocity model, because the initial estimates of $v(t_0)$ from the velocity model are likely to be inaccurate. If $f_\\theta$ converges too quickly based on early, imprecise values, it could cause the numerical solution to become unstable, potentially leading to failure during optimization.\n\nTo address this, $f_\\theta$ is designed with a Vision Transformer (ViT) (Dosovitskiy et al., 2021) as the primary network, complemented by a linear term. The ViT, with its inherently slower convergence relative to CNNs, provides strong global modeling capabilities, while the linear term contributes to stabilizing the training process by promoting smoother convergence (Linot et al., 2023). A detailed analysis of how different architectural choices impact training stability is available in Section 5.3."}, {"title": "3.4 SOURCE MODEL", "content": "To capture the energy gains and losses within the ODE system, we introduce a neural network to model the source term. Rather than incorporating the source term directly within the Advection"}, {"title": "3.5 SANDWICH STRUCTURE DESIGN FOR SOLVING ADVECTION EQUATION", "content": "The hybrid CNN-ViT-CNN architecture optimally combines local feature extraction and global context modeling, enabling efficient learning dynamics suited for distinct yet interconnected tasks in the advection equation estimation.\n\nThe sandwich design of our neural ODE model, comprising a CNN for fast-converging tasks (velocity estimation and source term modeling) and a ViT for slower-converging tasks (advection equation modeling), leverages the strengths of different architectures tailored to specific learning tasks. CNNs excel at local feature extraction and are particularly suited for tasks requiring rapid convergence, such as deriving initial conditions and identifying impacts from source terms with high spatial correlation. In contrast, Vision Transformers (ViTs) utilize attention mechanisms that capture global context and relationships, making them better suited for tasks with more complex interactions, such as solving the advection equation, where the dynamics often involve long-range dependencies. From a theoretical standpoint, the effectiveness of this hybrid architecture can be framed through the lens of inductive biases: the CNN's ability to model locality and translation invariance complements the ViT's ability to model global interactions and dependencies, resulting in a more robust solution strategy for the coupled problem. Moreover, such sandwich design choice is also related to the robustness of training as we discuss in Section 5.3."}, {"title": "3.6 MULTI-TASK LEARNING", "content": "Previous methods often train models using only the target leading time $u(t_n)$ as the supervision signal, ignoring the valuable information contained in intermediate states ${u(t_n)}_{n=1}^{N-1}$. Here, we adopt a multi-task learning strategy and leverage the continuous nature of neural ODE to predict the state at every intermediate time step ${u(t_n)}_{n=1}^{N-1}$, minimizing the latitude-weighted RMSE between the predicted values $u(t_n)$ and the ground truth $\\tilde{u}(t_n)$. The loss function is defined as:\n\n$L = \\frac{1}{NXHXW}\\sum_{n=1}^{N}\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\sum_{w=1}^{W} \\alpha(h) (u_{k,h,w}(t_n) - \\tilde{u}_{k,h,w}(t_n))^2,$\n\nwhere $\\alpha(h)$ is the latitude weighting factor that accounts for the varying grid cell areas on a spherical Earth, as cells near the equator cover larger areas than those near the poles. For more details on the weighting factor, refer to Appendix B.\n\nBy leveraging the multi-task learning strategy, the ODE system can exploit information across different time points, helping the model filter out errors arising from advection assumptions and neural network predictions. This allows us to train a single model with a lead time of N that can be used for inference at any time step up to N, enhancing both efficiency and generalization."}, {"title": "4 EXPERIMENTS", "content": "In this section, we evaluate the proposed WeatherODE by forecasting the weather at a future time $u(t+\\Delta t)$ based on the conditions at a given time t, where $\\Delta t$ (measured in hours) represents the lead time. The experimental setups are detailed in Section 4.1, while the results for global and regional weather forecasting are presented in Section 4.2 and Section 4.3, respectively."}, {"title": "4.1 EXPERIMENTAL SETUPS", "content": "Dataset. We utilize the preprocessed ERA5 dataset from WeatherBench (Rasp et al., 2020b), which has 5.625\u00b0 resolution (32 \u00d7 64 grid points) and temporal resolution of 1 hour. Our input data includes K = 48 variables: 6 atmospheric variables at 7 pressure levels, 3 surface variables, and 3 constant fields. To evaluate the performance of WeatherODE, following the benchmark work in Verma et al. (2024), we focus on five target variables: geopotential at 500 hPa (z500), temperature at 850 hPa (t850), temperature at 2 meters (t2m), and zonal wind speeds at 10 meters (u10 and v10). We use the data from 1979 to 2015 as the training set, 2016 as the validation set, and 2017 to 2018 as the test set. More details are available in Appendix A.\n\nMetric. In line with previous works, we evaluate all methods using latitude-weighted root mean squared error (RMSE) and latitude-weighted anomaly correlation coefficient (ACC):\n\n$RMSE = \\sqrt{\\frac{1}{K} \\frac{1}{HW} \\sum_{k=1}^{K} \\sum_{h=1}^{H} \\sum_{w=1}^{W} \\alpha(h) (u_{k,h,w} - \\tilde{u}_{k,h,w})^2},$\n\n$ACC = \\frac{\\sum_{k,h,w} u'_{k,h,w} \\tilde{u}'_{k,h,w}}{\\sqrt{\\sum_{k,h,w} \\alpha(h) (u'_{k,h,w})^2 \\sum_{k,h,w} \\alpha(h)(\\tilde{u}'_{k,h,w})^2}},$\n\nwhere $\\alpha(h)$ is the same latitude weighting factor as used in the training process; $\\tilde{u}' = \\tilde{u} - C$ and $u' = u - C$ are computed against the climatology $C = \\frac{1}{K} \\sum_{k} \\bar{u}_k$, which is the temporal mean of the ground truth data over the entire test set. More details are available in Appendix B.\n\nBaselines. We compare WeatherODE with several representative methods from recent literature, including ClimaX (Nguyen et al., 2023), FourCastNet (FCN) (Pathak et al., 2022), ClimODE (Verma et al., 2024), and the Integrated Forecasting System (IFS) (ECMWF, 2023). Specifically, ClimaX is a pre-trained framework capable of learning from heterogeneous datasets that span different variables, spatial and temporal scales, and physical bases. FCN uses Adaptive Fourier Neural Operators to provide fast, high-resolution global weather forecasts. ClimODE is a physics-informed neural ODE model that incorporates key physical principles. IFS is the most advanced global physics simulation model of the European Center for Medium-Range Weather Forecasting (ECMWF).\n\nImplementation details. The architecture of our velocity model is based on ResNet2D (He et al., 2016), the ODE is based on ViT (Dosovitskiy et al., 2021), and the source model is based on ResNet3D. We optimize the model using the Adam optimizer. Detailed discussions on the model architectures, specific parameter settings, and learning rate schedules are available in Appendix C."}, {"title": "4.2 GLOBAL WEATHER FORECASTING", "content": "Table 1 presents the global weather forecasting performance of WeatherODE and other baseline models at $\\Delta t = \\{6,12,18,24\\}$ hours. We report the results from the original ClimaX paper, where the model was pre-trained on the CMIP6 dataset (Eyring et al., 2016) and then fine-tuned on ERA5 dataset. Despite training solely on the ERA5 dataset, WeatherODE gains a 10% improvement over ClimaX. Besides, WeatherODE surpasses ClimODE with a substantial improvement over 40%, clearly demonstrating that we have effectively overcome the major challenges inherent in physics-driven weather forecasting models. Furthermore, WeatherODE achieves performance on par with the IFS, which serves as the benchmark in the industry."}, {"title": "4.3 REGIONAL WEATHER FORECASTING", "content": "Global forecasting is not always feasible when only regional data is available. Therefore, we evaluate WeatherODE with other baselines for regional forecasting of relevant variables in North America, South America, and Australia, focusing on predicting future weather in each region based on its current conditions. The latitude boundaries for these regions are detailed in the Appendix D. As shown in Table 2, WeatherODE consistently achieves strong predictive performance across nearly all variables in each region, surpassing ClimaX and ClimODE by 59.7% and 31.8%, respectively."}, {"title": "4.4 FLEXIBLE INFERENCE WITH A SINGLE 24-HOUR MODEL", "content": "Many deep learning-based methods treat predictions for different lead times as separate tasks, requiring a distinct model for each lead time. Some approaches attempt to use short-range models with rolling strategies (Bi et al., 2023; Chen et al., 2023a), but they still face the challenge of error accumulation. In contrast, by modeling the atmosphere as a physics-driven continuous process and"}, {"title": "5 ABLATION STUDIES", "content": ""}, {"title": "5.1 EFFECTIVENESS OF WAVE EQUATION-INFORMED ESTIMATION", "content": "To validate the superiority of the wave equation-informed estimation over the discrete-time derivative, we conduct five experiments of the velocity model to estimate the initial velocity: (1) $f_v()$: the model uses only the discrete-time derivative; (2) $f_v(u, \\nabla u, \\frac{\\Delta u}{\\Delta t})$: the model combines the discrete-time derivative with u and $\\nabla u$; (3) $f_v(u)$: the model uses only u; (4) $f_v(\\nabla u)$: the model uses only $\\nabla u$; (5) $f_v(u, \\nabla u)$: the model relies solely on the wave function-derived $\\frac{\\partial u}{\\partial t}$ and $\\nabla u$. The results in Figure 3 demonstrate the effectiveness of the wave equation-informed approach. Specifically, (1) has an RMSE that is over 20% worse compared to (5). It is notable that experiment the incorporation of $\\frac{\\Delta u}{\\Delta t}$ into the velocity model in (2) adversely affected performance compared to (5), primarily due to overfitting arising from the substantial discrepancy between the discrete-time derivative and the true values. Furthermore, the model in (5) outperforms (4), suggesting that the inclusion of $\\frac{\\partial u}{\\partial t}$ with u provides additional beneficial information to the network, enhancing its predictive capability. Figure 4 shows that WeatherODE produces much smoother $\\frac{\\partial u}{\\partial t}$ predictions, aligning with the smooth nature of u, while the predictions of ClimODE are more erratic."}, {"title": "5.2 ANALYSIS OF SOURCE MODEL ARCHITECTURE", "content": "We conduct experiments by removing the source model and comparing different source model architectures: ViT, DiT, ResNet2D, and ResNet3D. DiT (Peebles & Xie, 2023) and ResNet3D are the time-aware versions of ViT and ResNet2D, respectively. As shown in Figure 5, DiT and ResNet3D outperform ViT and ResNet2D by 10% and 5%, and significantly exceed the performance of the"}, {"title": "5.3 STABILITY ANALYSIS OF NEURAL NETWORK AND NEURAL ODE INTEGRATION", "content": "The interdependencies between the advection and velocity models highlight the importance of carefully selecting architectures and learning rates to ensure the stability and performance of the neural network and neural ODE system. As shown in Table 3, the learning rate for the advection model must be lower than that of the velocity model due to often inaccurate initial estimates. If the advection model converges too quickly based on these estimates, it may lead to numerical instabilities and NaN values. Alternatively, using an advection model architecture with inherently slower convergence can yield similar results even with the same learning rate. Moreover, given that the source term represents solar energy with strong locality\u2014where energy patterns are similar in neighboring regions\u2014a CNN architecture that effectively captures local dependencies is ideal for this task."}, {"title": "6 CONCLUSION", "content": "In this paper, we tackle several challenges faced by neural ODE-based weather forecasting models, specifically addressing time-discretization errors, global-local biases across individual tasks in solving the advection equation, and discrepancies in time-dependent sources that compromise predictive accuracy. To address these issues, we present WeatherODE\u2014a novel sandwich neural ODE model that integrates wave equation theory with a dynamic source model. This approach effectively reduces errors and promotes synergy between neural networks and neural ODEs. Our in-depth analysis of WeatherODE's architecture and optimization establishes a strong foundation for advancing hybrid modeling in meteorology. Looking forward, our work opens avenues for further exploration of hybrid models that blend traditional physics-driven and modern machine-learning techniques."}]}