{"title": "Adapting the Biological SSVEP Response to Artificial Neural Networks", "authors": ["Emirhan B\u00f6ge", "Yasemin Gunindi", "Erchan Aptoula", "Nihan Alp", "Huseyin Ozkan"], "abstract": "Neuron importance assessment is crucial for understanding the inner workings of artificial neural networks (ANNs) and improving their interpretability and efficiency. This paper introduces a novel approach to neuron significance assessment inspired by frequency tagging, a technique from neuroscience. By applying sinusoidal contrast modulation to image inputs and analyzing resulting neuron activations, this method enables fine-grained analysis of a network's decision-making processes. Experiments conducted with a convolutional neural network for image classification reveal notable harmonics and intermodulations in neuron-specific responses under part-based frequency tagging. These findings suggest that ANNs exhibit behavior akin to biological brains in tuning to flickering frequencies, thereby opening avenues for neuron/filter importance assessment through frequency tagging. The proposed method holds promise for applications in network pruning, and model interpretability, contributing to the advancement of explainable artificial intelligence and addressing the lack of transparency in neural networks. Future research directions include developing novel loss functions to encourage biologically plausible behavior in ANNs.", "sections": [{"title": "1 Introduction", "content": "Neuron importance assessment refers to quantifying the significance of individual neurons within an artificial neural network (ANN), with respect to their contribution to overall network performance and output. Such tools have a\n* These authors contributed equally to this work.\nwide application range, mostly in the context of explainable artificial intelligence (XAI), that aims to improve the long-criticized lack of transparency of neural networks [1]; and network pruning, where by removing less influential neurons, one can forge computationally less intensive models with often negligible performance loss [2].\nThe assessment of neuron significance within ANNs has been gaining popularity. Notable advances include layer-wise relevance propagation [3], which backpropagates output predictions throughout the network while assigning relevance scores to individual neurons. DeepLIFT [4] on the other hand contrasts neuron activation with the final decision of the network based on a chosen reference input that is \"neutral\". This comparison enables the assignment of contribution scores to individual neurons. A neuron/filter pruning technique for convolutional neural networks (CNN) has been also reported [5] through the Taylor expansion of the loss function, approximating the elimination effect of an individual neuron on the model's loss. Another study [6] has tackled the same issue through inter-filter mutual relationships. Moreover, the Neuron Shapley approach [7] relies on computing the average marginal neuron contributions across all possible neuron combinations, while Neuron-Level Plasticity Control [8] estimates a neuron's capacity to maintain previously learned knowledge during adaptation to new tasks with the end of significance quantification. More recently, the context of adversarial attacks has been explored [9] through the activation and deactivation of individual neurons, so as to assess which among them influence a model's vulnerability.\nIn contrast to the aforementioned studies, this paper proposes a radically different approach to neuron significance assessment, based on the concept of frequency tagging, adopted from the neuroscientific investigation of the biological brain [10]. To the best of our knowledge, it has never been explored before in the context of artificial neural networks. More specifically, if the human brain is presented with a visual stimulus flickering (i.e. changing intensity regularly) at a specific frequency, then the neural response gets tuned to the harmonics of the same frequency. This is a well-established observation in neuroscience literature [11-13], and can be directly observed from an electroencephalogram (EEG). Frequency tagging (Fig. 1) is a method of artificially flickering parts of a visual stimulus with distinct frequencies (i.e. so parts are \"tagged\") with the aim of isolating the traces of part-based processing in the brain [12].\nIn this paper, it has been hypothesized that one should observe the same effect in an ANN as well, if it indeed mimics a biological brain as often claimed [14]. To test this, we have focused on a prominent neuroscientific experimental paradigm [11], and replaced the biological brain with an ANN. The specifics of frequency tagging and its adaptation to ANNs as well as the tools that can be used for node significance assessment are presented next in Section 2. Then the proof-of-concept experiments (Section 3) that have been conducted with color images and a Resnet-32 CNN, with the end of observing notable harmonics under part-based frequency tagging are described. The paper ends with a discussion of our results and various deep learning applications that can benefit from the proposed neuron significance assessment method (Section 4)."}, {"title": "2 Frequency tagging for artificial neural networks", "content": "The frequency tagging technique involves modulating the contrast of a stimulus at specific frequencies over time [15]. In more detail, various parts of an image, commonly the left and right sides [11], undergo sinusoidal contrast modulation and therefore \"flicker\" at specific frequencies. The objective of introducing these contrast-modulated input stimuli to biological brains is to evoke steady (non-transient) neural responses, known as steady-state visually evoked potentials (SSVEPs) [16].\nFirst reported by Adrian and Matthews [17], as \u201ca series of potential waves having the same frequency as that of the flicker\u201d, steady-state responses to visual stimuli allow discernible brain signals to be tracked. These signals stand apart from other concurrent endogenous processes, allowing researchers to isolate underlying neural correlates of stimulus properties. Consequently, by contrast-modulating different parts of visual stimuli, the contribution of these parts to the signals can be deciphered through their given frequencies.\nInspired by face perception studies in neuroscience and computer vision [11, 13, 18, 19], this paper proposes to apply frequency tagging to digital color images with two different frequencies and then provide them as input to a CNN, to assess based on the aforementioned principle, the importance/utility of individual neurons/filters.\nIn more detail, to emulate the frequency tagging process, the pixel values of each channel of a digital color image are independently multiplied by a scalar coefficient sin(w\u2081) derived from a sinusoid of frequency f. This coefficient is scaled into the range [0.5, 1] to prevent excessive loss of luminance (see Fig. 1)."}, {"title": "The angles \u03c9i are computed as:", "content": "$\\omega_{i} = 2 \\pi \\times f \\times i/FPS + \\phi$. (1)\nThe phase $\\phi$ is set to 0, and frames per second (FPS) is fixed at 120. With a duration of 2 seconds, this results in the creation of 240 color images, where $i\\in \\{0,..., 239\\}$, collectively forming the tagged version of the original color input image. In our setting, this process is applied independently to the left and right halves of a given image using respectively $f_{left}$ = 6 Hz and $f_{right}$ = 7.5 Hz [13]. At this point it is critical that the resulting images are provided as input to the network in the same order that they have been produced. Consequently, one can at this stage collect the neuron activations corresponding to each of the contrast modulated input images, thus obtaining the SSVEPs in the form of a sequence of 240 numerical activations per neuron (or filter, in the case of CNNs). If the output of a neuron is non-scalar, it can be converted to be so, for instance by taking the average or maximum of a filter output in the case of CNNs."}, {"title": "3 Implementation and findings", "content": "As far as implementation is concerned, a ResNet-32 model [21] trained with 50k samples of the CIFAR-10 dataset [22] has been employed. 100 randomly selected test images from the same dataset (non-overlapping with the training set) have been contrast modulated following the procedure outlined in Section 2. Thus, 240 flickering images have been generated for each of the test images, and they are tagged at 6 Hz on their left half and at 7.5 Hz on their right half. Each 240-long image sequence has then been provided as input to the model, and then the mean value of each (convolutional) filter's response (i.e. feature"}, {"title": "4 Conclusion", "content": "In conclusion, this paper presents a novel approach to quantifying the significance of individual neurons within artificial neural networks (ANNs) by adopting the frequency tagging technique from neuroscience. By contrast-modulating (flickering) a network's input image in a sinusoidal fashion and observing the resulting neuron activations, the proposed method enables neuron-level analysis of a network's decision-making mechanisms. In our experiments with image classification, using a convolutional neural network (CNN), we observed notable harmonics as well as intermodulations when the resulting neuron-specific steady-state visually evoked potentials (SSVEP) are analyzed under part-based frequency tagging (left/right part: f1/f2). At each neuron, harmonics (kf\u2081) and intermodulations (mf1\u00b1nf2) quantify how much information from each input image part is conveyed and combined. We measure this through SNR which also draws the neuron's importance. Our findings suggest that ANNs exhibit similar behavior to biological brains in tuning to flickering frequencies, thus opening avenues for neuron/filter importance assessment through frequency tagging. This groundbreaking method offers potential applications in network pruning, and model interpretability, contributing to the advancement of explainable artificial intelligence (XAI) and addressing the lack of transparency in neural networks. One exciting future research is to develop novel loss functions that encourage the harmonics and intermodulations in the SSVEP spectrum. This would pull the network in a more biologically plausible manner and perhaps enable brain functions that have not been incorporated yet in ANNs."}]}