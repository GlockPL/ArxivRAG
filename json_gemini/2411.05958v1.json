{"title": "Sentiment Analysis of Cyberbullying Data in Social Media", "authors": ["Pradeep Pujari", "Arvapalli Sai Susmitha"], "abstract": "Social media has become an integral part of modern life, but it has also brought with it the pervasive issue of cyberbullying a serious menace in today's digital age. Cyberbullying, a form of harassment that occurs on social networks, has escalated alongside the growth of these platforms. Sentiment analysis holds significant potential not only for detecting bullying phrases but also for identifying victims who are at high risk of harm, whether to themselves or others. Our work focuses on leveraging deep learning and natural language understanding techniques to detect traces of bullying in social media posts. We developed a Recurrent Neural Network with Long Short-Term Memory (LSTM) cells, using different embeddings. One approach utilizes BERT embeddings, while the other replaces the embeddings layer with the recently released embeddings API from OpenAI. We conducted a performance comparison between these two approaches to evaluate their effectiveness in sentiment analysis of Formspring Cyberbullying data.", "sections": [{"title": "1 Introduction", "content": "In recent years, social media has become an integral part of daily life, facilitating communication and connection on an unprecedented scale. However, it has also contributed to a rise in cyberbullying harassment conducted online (Feinberg and Robey, 2009). Unlike traditional bullying, cyberbullying can happen anytime, with online anonymity encouraging perpetrators to act without facing immediate consequences (Hasan et al., 2023). This anonymity often leads to higher rates of cyberbullying compared to in-person bullying. Bullying is recognized as a major health issue by institutions like the American Academy of Pediatrics, has become especially concerning in educational settings (Xu et al., 2012). The tragic case of Megan Meier, a young victim of harassment on MySpace, highlights the devastating impact of cyberbullying (Vines, 2015). Given the growing concern in society and workplaces, and the fact that studies show many students face cyberbullying (Li, 2006; Cross, 2008), detecting and preventing cyberbullying promptly is essential.\nIn this work, we use Sentiment Analysis (SA) to classify texts as positive or negative with respect to cyberbullying. While traditional embeddings used in Recurrent Neural Networks (RNNs) are effective in capturing sequential patterns, they struggle with contextual dependencies in longer sentences and have limitations in understanding complex language structures (Elman, 1990; Pascanu, 2013). In contrast, we incorporate state-of-the-art Large Language Model (LLM) embeddings, specifically BERT embeddings (Kenton and Toutanova, 2019), and use the OpenAI API to obtain embeddings that leverage self-attention mechanisms for sentiment analysis. These models excel in capturing intricate language features, making them highly effective for a range of downstream tasks (Radford et al., 2019; Raffel et al., 2020). These embeddings offer a deeper contextual understanding compared to earlier models, allowing for a more nuanced detection of harmful content and a more precise evaluation of sentiment polarity. The task involves identifying sentences containing bullying tokens, assessing their polarity, and accurately classifying them into the relevant sentiment categories.\nThe development of such Natural Language Processing (NLP) algorithms, however, requires high-quality annotated data to measure performance accurately. Many popular Machine Learning (ML) techniques, especially Deep Neural Networks (DNNs), need large, annotated corpora to achieve high-quality classification results. Unfortunately, the availability of publicly accessible datasets for cyberbullying detection is limited. In"}, {"title": "2 Literature review", "content": "In the early stages of sentiment analysis, traditional methods such as rule-based and lexicon-based systems were widely used. Rule-based systems applied predefined linguistic rules to classify text, while lexicon-based methods relied on sentiment lexicons like AFINN and SentiWordNet(Baccianella et al., 2010), which assigned sentiment scores to individual words. These scores were then aggregated to determine the overall sentiment of a sentence or document. While these approaches were straightforward, they struggled to capture context-dependent meanings and often required extensive, manually curated lexicons. Similarly, pattern-based approaches like those described by (Pang and Lee, 2008) utilized syntactic and semantic rules to detect sentiment-bearing structures within text, but they too required significant manual effort to maintain.\nWith the rise of machine learning, traditional feature engineering techniques became popular. Methods like TF-IDF (Term Frequency-Inverse Document Frequency) (Shi and Li, 2011) transformed text data into meaningful features for sentiment classification, marking a shift from rule-based approaches. Classification algorithms such as Naive Bayes, Support Vector Machines (SVM), and Logistic Regression gained popularity in these early machine learning systems (Joachims, 1999; McCallum and Nigam, 1998). These methods improved flexibility but still faced challenges with complex sentiment detection and domain generalization. Feature selection and careful tuning were often necessary to optimize performance.\nAround the same time, distributed representation methods like Word2Vec(Mikolov et al., 2013) and GloVe(Pennington et al., 2014) were introduced, representing words in continuous vector spaces to capture their semantic relationships. Unlike TF-IDF's sparse features, word embeddings encode words based on context, enabling more effective sentiment classification. Word2Vec offered two model architectures, Continuous Bag-of-Words (CBOW) and Skip-Gram, both of which generated word embeddings by considering context words. GloVe took a different approach by using a global word co-occurrence matrix to create word embeddings, capable of capturing linear relationships within the vector space. (Yin et al., 2009) utilized a traditional bag-of-words model with sentiment and contextual features to boost detection performance, while (Nahar et al., 2014) developed a semi-supervised fuzzy SVM approach incorporating sentiment and user metadata.\nWhile these word embeddings revolutionized the way sentiment data was processed, they were still largely task-independent. In sentiment analysis, this posed challenges since word meanings could vary drastically depending on the context or domain. To address this, more advanced deep learning models, such as Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks, were introduced to capture sequential dependencies in text (Hochreiter and Schmidhuber, 1997). This enabled better handling of long-range context, a critical factor in sentiment analysis. The paper (Sahoo et al., 2023) discusses the use of RNNs, LSTMs, and transformer models in sentiment analysis, highlighting data preprocessing, feature extraction, and model architectures. Convolutional Neural Networks (CNNs) were also adapted to text processing, particularly excelling at capturing sentiment-bearing phrases and structures(Kim, 2014). A study by (Dang et al., 2020), compares different deep learning models such as DNN, RNN, and CNN for sentiment analysis tasks, including sentiment polarity and aspect-based sentiment analysis. The paper (Sharma et al., 2024) explores the significance, challenges, and evolving"}, {"title": "3 Formspring Dataset", "content": "The Formspring dataset (Reynolds et al., 2011), curated by Kelly Reynolds and made available on Kaggle(Pujari, 2022), is one of the primary datasets used for sentiment analysis-based cyberbullying detection. Formspring.me, a now-defunct question-and-answer-based social network, allowed users to post questions and comments anonymously, making it a significant source for studying online bullying behaviors. The dataset was collected through a crawl of the site in Summer 2010.\nThe dataset contains 12,772 samples of user posts and answers, where each post was labeled as either containing cyberbullying or not. These labels were generated through Amazon Mechanical Turk, with each post annotated by three workers. A post was classified as cyberbullying if at least two of the three annotators indicated the presence of bullying. Out of the 12,772 samples, 802 samples (6.3%) were labeled as cyberbullying, which mirrors the real-world imbalance between non-bullying and bullying content (with over 84% of the content labeled as non-bullying).\nKey fields in the dataset include:\n\u2022 Userid: ID of the person responding to a post.\n\u2022 Asker: ID of the person asking the question.\n\u2022 Post: The complete question and answer string, separated by markers such as \"Q:\" and \"A:\". As part of preprocessing, these markers, along with any HTML encodings, were removed.\n\u2022 Ans#, severity#, bully#: The responses provided by Mechanical Turk workers. Ans# refers to the answer given by the annotators, severity# indicates a score from 0 to 10 based on the perceived intensity of the bullying, and bully# identifies the specific words or phrases flagged as bullying."}, {"title": "4 Models", "content": "BERT (Bidirectional Encoder Representations from Transformers) embeddings are employed to extract contextual word representations. Unlike static word embeddings like Word2Vec, where each word has a fixed vector, BERT (Kenton and Toutanova, 2019) generates dynamic representations for each word based on its context. This allows for improved performance in NLP tasks, including cyberbullying detection. We used BERT base which has 12 encoder layers, 768 hidden units, 12 attention heads.\nThese transformer-based models outperform traditional methods by leveraging self-attention mechanisms and contextual embeddings.The attention mechanism is defined as Attention(Q, K, V) = $softmax(\\frac{QK^T}{\\sqrt{d_k}})V$, where Q, K, and V are query, key, and value matrices, and $d_k$ is the dimension of the key."}, {"title": "4.2 OpenAI Embeddings", "content": "The OpenAI embedding API introduces an endpoint that maps text and code to vector representations. We use text-embedding-3-small (OpenAI, 2024), which are effective for tasks like clustering, topic modeling, and classification, outperforming many traditional models (OpenAI, 2023). These embeddings achieved a 20% relative improvement in code search tasks (Neelakantan et al., 2022). The embeddings encode semantic relationships between words, phrases, or code snippets and can be obtained via a simple API request, as shown in Fig1. This encoding allows semantically similar inputs to cluster in vector space, making them useful for similarity search, grouping, or automated labeling."}, {"title": "5 Experimentation", "content": "Algorithm: Sentiment Analysis using BERT or OpenAI Embeddings in RNN\n1. Input:\nInput text T = {$t_1, t_2, ..., t_n$}, where $t_i$ represents each token in the input sentence.\n2. Step 1: Tokenization\nTokenize the input text T using:\n\u2022 BERT: Use BERT's subword tokenizer to obtain tokens $T_{sub}$ = {$s_1, s_2, ..., s_m$}.\n\u2022 OpenAI: Input the raw text T directly to OpenAI's embedding API.\n3. Step 2: Embedding Extraction\nExtract contextual embeddings using:\n\u2022 BERT: Pass tokenized text $T_{sub}$ through a pre-trained BERT model to obtain embeddings E = {$e_1, e_2, ..., e_m$}.\n\u2022 OpenAI: Use OpenAI's API to get high-dimensional vector embeddings E = Embedding.create(input = T).\n4. Step 3: Classification Model\nInput the embeddings E into a RNN model to perform the classification task.\n5. Step 4: Output\nThe final output is the predicted class $Y_{pred}$ with the highest probability.\nThe model is trained using Binary Cross Entropy Loss (BCELoss), which is suitable for binary classification tasks.\nThe BCELoss is defined as\nL = -(y log(p) + (1 \u2212 y) log(1 \u2013 \u0440))\nwhere y is the true label and p is the predicted probability for the positive class.\nIncorporating BERT-base or OpenAI embeddings, i.e., our hybrid architectures, enhances the performance of the classifier compared to using only the RNN. This improvement is achieved by providing high-quality feature vectors extracted from the text data. Fig 2 shows the RNN network with BERT or OpenAI embeddings."}, {"title": "Implementation Details:", "content": "The data was split into an 80:20 ratio for training and testing. We used a learning rate of 0.001 and applied gradient clipping to prevent exploding gradients, and dropout to mitigate overfitting. The Adam optimizer was employed for the training process, which was run for 10 epochs."}, {"title": "6 Results", "content": "We observed that the embedding representations, both BERT and OpenAI, were rich and dense with information, making them well-suited for the task of sentiment analysis in cyberbullying detection. However, OpenAI embeddings exhibited marginally better performance than BERT embeddings.\nThe primary metrics used to evaluate model performance in this context were accuracy and macro F1 score. Accuracy is calculated as the ratio of correctly predicted instances to the total number of instances in the dataset, defined by the following formula:\nAccuracy = $\\frac{Number\\ of\\ Correct\\ Predictions}{Total\\ Number\\ of\\ Predictions}$ \u00d7100\nThe macro F1 score provides an average F1 score across all classes, giving equal weight to each class. Since we have two classes, N = 2. The macro F1 score is calculated as follows:\nMacro F1 = $\\frac{1}{N}\\sum_{i=1}^{N} \\frac{2\\times Precision_i \\times Recall_i}{Precision_i + Recall_i}$\nwhere $Precision_i$ and $Recall_i$ are the precision and recall for each class i. The results are summarized below:\nThese results indicate that employing more advanced contextual embeddings, such as those from"}, {"title": "7 Conclusion", "content": "An in-depth analysis of the Formspring dataset highlights significant opportunities for improving cyberbullying detection through advanced methodologies. Our study introduced a novel hybrid approach for sentiment analysis, integrating BERT and OpenAI embeddings within an RNN framework to address the complexities of cyberbullying data.\nOur findings revealed that both OpenAI and BERT embeddings significantly outperformed a basic RNN model in capturing the subtleties of cyberbullying language. Among them, OpenAI embeddings demonstrated the highest effectiveness, indicating their superior ability to understand context and sentiment in user-generated content. Looking ahead, the small size of the dataset poses challenges for model performance. To address this, we plan to explore zero-shot or few-shot learning techniques as future work, which could enhance the model's generalization and accuracy in predicting cyberbullying instances with limited labeled data. This direction promises to improve the robustness and applicability of detection systems in real-world scenarios."}]}