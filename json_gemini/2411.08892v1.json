{"title": "Auto-assessment of assessment: A conceptual framework towards fulfilling the policy gaps in academic assessment practices", "authors": ["Wasiq Khan", "Luke K. Topham", "Peter Atherton", "Raghad Al-Shabandar", "Hoshang Kolivand", "Iftikhar Khan", "Abir Hussain"], "abstract": "Education is being transformed by rapid advances in Artificial Intelligence (AI), including emerging Generative Artificial Intelligence (GAI). Such technology can significantly support academics and students by automating monotonous tasks and making personalised suggestions. However, despite the potential of the technology, there are significant concerns regarding Al misuse, particularly by students in assessments. There are two schools of thought: one advocates for a complete ban on it, while the other views it as a valuable educational tool, provided it is governed by a robust usage policy. This contradiction clearly indicates a major policy gap in academic practices, and new policies are required to uphold academic standards while enabling staff and students to benefit from technological advancements. We surveyed 117 academics from three countries (UK, UAE, and Iraq), and identified that most academics retain positive opinions regarding Al in education. For example, the majority of experienced academics do not favour complete bans, and they see the potential benefits of Al for students, teaching staff, and academic institutions. Importantly, academics specifically identified the particular benefits of Al for autonomous assessment (71.79% of respondents agreed). Therefore, for the first time, we propose a novel Al framework for autonomously evaluating students' work (e.g., reports, coursework, etc.) and automatically assigning grades based on their knowledge and in-depth understanding of the submitted content. The survey results further highlight a significant lack of awareness of modern AI-based tools (e.g., ChatGPT) among experienced academics, a gap that must be addressed to uphold educational standards.", "sections": [{"title": "1 Introduction", "content": "Al has tremendously transformed the educational field. Integrating Al technology in the education sector has shaped and fostered the traditional learning method to be more interactive and effective [1]. Al plays a crucial role in supporting higher education by facilitating the learning process for students through providing a personalised learning environment and promoting student engagement [2].\nLarge Language Models (LLM), such as ChatGPT, have recently demonstrated significant advances in human-like text generation. Their versatility and diverse applications, including question and answering, text classification, text generation, inference, and more [3], have made a significant impact in domains such as public health [4], customer relations [5], finance [6], and education [7]. Despite the promise of the technology, there remains significant controversy regarding its use in academia, with many suggesting it should be banned [8].\nFurthermore, the lack of clear policies, guidelines, and frameworks prevents LLMs from being harnessed in academia [9]. Policymakers are struggling to keep up with the rapid development of LLMs and other Artificial Intelligence technologies. This is exacerbated by a lack of understanding of academics' experience and perceptions of LLMs due to insufficient relevant empirical studies [9]. It's crucial that we bridge this gap and ensure that academics' voices are heard in the policy development process to help shape the future of LLM use in academia.\nSimilarly, most institutions are developing guidelines without collaborating with other institutions. Therefore, there is a lack of consistency in existing policies between institutions [10]. Moreover, a lack of consistency exists between departments, faculties, courses, and even modules within institutions [10]. For example, some institutions encourage module leaders to set the rules and guidelines for LLM use for each assignment [10]. This results in students being allowed to use LLMs in specific assessments, facing restrictions in some assessments and a total ban in others. A lack of consistency results in confusion for academics and students and leads to difficulties in comparing work between modules, courses, and institutions.\nDespite LLMs' potential benefits, many academics are concerned with their misuse, such as students submitting generated text as their own during assignments. Such concerns are exacerbated by difficulties differentiating human-written text from LLM-generated text [11]. Such challenges and concerns have led many institutions to ban ChatGPT and other tools [12]. However, such bans are difficult to enforce and result in some students gaining an unfair advantage [12]. Similarly, complete bans prevent students from benefitting from the valuable tools available and pose a barrier to their learning skills, which will benefit them in the workplace [13]. The aforementioned contradictory opinions clearly indicate the major policy gaps in academic institutions that need"}, {"title": "2 Related Works", "content": ""}, {"title": "2.1 Proposed Frameworks", "content": "Several approaches are suggested to help identify instances where students submit LLM-generated work as their own. For example, [14] suggests:\nLooking for language patterns, irregularities, or grammatical errors, for example, repetitions or low-quality language due to limitations in the LLM.\nCheck that references and citations are correct. LLMs are often unable to find genuine references.\nCheck for originality. LLMs are incapable of human-level creativity and originality.\nLLMs are known to hallucinate; factual errors may be an indicator.\nSome detection tools are available that automate pattern analysis to identify irregularities.\nAlthough the suggested approaches have shown some success, several limitations affect their practicality. For example, such approaches are time-consuming for already stretched academic staff. Moreover, the suggested approaches are designed to identify LLMs in their current or previous forms. At the current rate of progress, future LLMs will likely render these approaches useless. Even if academics follow such approaches and identify suspected cases of academic misconduct, it is difficult to prove and punish [15].\nAlternatively, many institutions suggest altering the style of assessments to make them less susceptible to LLM misuse. For example, [16] suggests interactive assessment activities such as presentations or group discussions to prevent or minimise the potential use of LLMs. Some suggest that such assessment methods may promote independent learning and critical, particularly as there is an opportunity to encourage students to elaborate on or defend specific points [17]. Similarly, \u201cauthentic assessments\" are promoted,"}, {"title": "2.2 Students' Experiences and Perceptions of Al in the Classroom", "content": "According to [19], students are generally attracted to Al tools such as ChatGPT and show improved engagement and motivation. However, they suggest that students must be trained to enhance their prompt engineering skills to achieve better results from the tools [19]. Moreover, the need for training is also highlighted [20], who suggested that students are more likely to trust the results provided by Al tools unquestionably. Therefore, they suggest improving students' critical thinking skills and encouraging them to analyse the results' reliability and verify their correctness [20]. Furthermore, in cases where students have been trained to use Al tools appropriately and within the rules of assessment, students have demonstrated a recognition of the value of the ethical use of such tools [21]. However, many students are reluctant to use Al tools as they perceive it as cheating [21]."}, {"title": "2.3 Academics' Experiences and Perceptions of AI in the Classroom", "content": "Teachers also view Al tools as beneficial to their teaching [7], particularly in lesson planning, assessment, and the preparation of learning materials. However, they report concerns regarding the accuracy of information provided, bias, and a lack of human interaction [22]. Similarly, some teachers also highlight the need for students to learn to ethically use Al tools to aid their learning and to prepare them for the future, as they recognise that Al tools are not likely to disappear [23]. Despite many teachers perceiving the ethical use of Al tools as beneficial, many teachers still perceive them as a threat. In addition to the aforementioned academic misconduct concerns, some academics are concerned that using Al tools may decrease students' skills, for example, in analytical writing [24]."}, {"title": "2.4 Ethics and Authenticity", "content": "Ethical frameworks in AIEd tend to be context-dependent and can vary significantly across countries, regions and domains [25]. That said, there are Al policies like UNESCO's, whose global perspective aims to establish adherence to agreed ethical norms [26]. Studies are drawing on growing evidence that LLM can generate high-quality writing for many purposes and in a way that can be passed on to human output. Al writing is hard to detect via anti-plagiarism software and has been shown to be of superior quality to students' own output, including reflective writing [9]. Crompton and Burke's meta-systematic review [27] concluded that higher education uses Al widely for student assessment and evaluation but needs to be managed more ethically, collaboratively and rigorously [27]. Universities are publishing assessment policies in light of GAI, but education is only beginning to allow their policies to be informed by viable conceptual frameworks [28]. While institutions themselves have responsibilities regarding Al and ethics, the prevalence of ChatGPT in students' work also raises questions about students' need to develop a balanced and critical approach to how they use AI [29].\nThere are ethical concerns in the literature over predictive and GAI. Predictions made by Al can be the product of models that have been trained on biased data [30]. In terms of GAI, while LLM, like ChatGPT, are benefitting students and teachers, there are concerns over bias in both the output of ChatGPT and the broader society. Furthermore, the functionality of some Al has been criticised, for instance, the risk of hallucinations caused by semantic limitations or biased programming [31]. The ethical dimensions of Al Ed require ongoing refinement and augmentation to ensure student and institutional data privacy and minimise bias [32]. Similarly, studies have shown a need for re-skilling educators and addressing the risk of deskilling students [13].\nThe notion of authenticity is being problematised. Previous studies have perhaps viewed Al as an external assistant to a passive receiver, and this fails to acknowledge the hybrid, collaborative nature of the production of knowledge [28]. Al content, then, has a 'social life' from its conception, production, dissemination, context and multiple uses [33]. Indeed, more recent studies have recommended more human-centred approaches to developing LLMs. Such approaches could acknowledge the synergies between human capabilities and data [34]. In addition to this, a focus on the complementary attributes of humans and AI could be a catalyst for innovation [35]. Moreover, some studies have concluded that Al can make education more human, not less and can also promote well-being if used alongside positive psychology [36]. In counterpoint to this, the literature explores evidence of human intervention having a damaging effect on machine learning [34].\nAl policy should focus on ethics, prioritising the development of Al solutions that respect human rights and safety. The development of Al technologies must have a legal and regulatory framework. The aim of this framework is to ensure the transparency and accountability of the Al system [37]. For instance, the governance ethical framework can contain laws and regulations, rules, and"}, {"title": "2.5 Assessment", "content": "The assessment of student learning is being augmented by improved Al algorithms, for example, in the domains of predictive learning analytics [7]. AI can aid autonomous learning via students' own questions [39] and assist with answers to open-ended questions [40]. The assessment of students' work can generate real-time data, which Al can evaluate, to help with programme design [41].\nEarlier systematic reviews on Al and assessment recognised an absence of discussion of underlying pedagogies that may lead to automated assessment and recommended further research and teacher training [42]. Indeed, ongoing teacher training is recognised as necessary to enable educators to harness new technologies to enhance learning outcomes [43].\nSome of the recent literature has examined the architecture of Al Ed on a more granular level, for example, the inaccuracies of static modelling versus the responsiveness and agility of dynamic modelling [7]. Another benefit of dynamic modelling is the accuracy with which systems can alert educators to students who may be at risk of underachieving and, therefore, facilitate timely interventions [7]. More recent literature on LLM builds on studies into predictive modelling techniques from the mid-2010s [44].\nThis dynamism has informed more recent studies into using LLM to answer open-ended questions, though the range of studies is emerging and the datasets can be sparse [45]. The limited nature of datasets in Al-related studies is a prominent theme in the literature [46]. While some authors may recommend 'massive volumes of standardised datasets' [46], others are more circumspect about the preponderance of big data [43]. Predictive AI can misrepresent students' future behaviours, and the data can be mined as part of a 'digital capitalism', characterised by economic, political, and cultural accumulation and exploitation of data as capital [33]."}, {"title": "3 Methodology", "content": "The methodology proposed in this study comprises two major components: i) surveying the expert academics and analysing the outcomes to investigate the RQs, and ii) proposing a new framework for the autonomous grading of students' works. For the validation purpose of the proposed conceptual framework, expert opinion is used, drawing on the insights and expertise of individuals who possess in-depth knowledge and experience in the relevant subject area. We surveyed academic experts associated with teaching and learning (T&L) and related administrative roles (e.g., programme leaders, T&L policy managers) to gather information in relation to policy matters and investigate the proposed RQs. Survey questions include awareness, policy on GAI, suggestions, acceptance of proposed AI-based auto-assessment, and other"}, {"title": "3.1 Questionnaire", "content": "The University Research Ethics Committee (UREC) at Liverpool John Moores University (LJMU) provides ethical approval for the collection and processing of the questionnaire data (Reference: 24/cmp/001). Educational staff, including lecturers, management, and administration staff, were recruited internationally to complete a questionnaire. The questionnaire contained the following questions:\nHow familiar are you with ChatGPT, an AI-powered language model used for generating text? (Very familiar / Somewhat familiar / Not familiar)\nHave you encountered instances where students have used ChatGPT or similar Al tools to assist with their coursework or assignments? (Yes / No)\nIn your opinion, how has the availability of ChatGPT affected the originality of students' work? (Increased originality / Decreased originality / No noticeable impact)\nHow would you rate the overall quality of students' work when ChatGPT is used as a tool? (Improved / Declined / No change)\nHow effective is your institution at detecting Al-generated content in students' work? (Very effective / Somewhat effective / Not effective)\nIn your opinion, should students be allowed to use Al-generated content in their work/assessments? (Yes / No)\nDoes your institution have specific policies or guidelines addressing the use of AI tools like ChatGPT in student work? (Yes / No)\nWhat strategies, if any, does your institution employ to mitigate the impact of Al tools on assessment integrity? (Check all that apply) (Education on academic integrity / Plagiarism detection software / Manual review of suspicious submissions / Specific guidelines on citation and referencing / Other (please specify))\nTo what extent are students aware of the implications of using Al tools like ChatGPT in their coursework? (Highly aware / Somewhat aware/Not aware)\nWhat challenges, if any, have you encountered in assessing students' work in the presence of AI tools like ChatGPT? (Open text field)\nDo you have any suggestions for improving the assessment process in light of the prevalence of AI tools like ChatGPT? (Open text field)\nCould Al be used to automatically rank students' work submissions based on their understanding/knowledge of the subject matter, rather than solely for detecting ChatGPT usage? (Somewhat aware / Not aware)"}, {"title": "3.2 Dataset", "content": "A total of 117 responses to the questionnaire were collected. Table 1 displays the number of responses from each country: 43.36% were from Iraq, 34.19% from the UK, 16.24% from the UAE, and the remaining 4.42% were from other countries not listed. Similarly, Table 2 presents an the number and proportions of responses for each academic role. The vast majority are involved in teaching & asessment (89.74%), with the remaining involved in management & policy matters (5.13%), admin (1.71%), or other roles (3.42%)."}, {"title": "3.3 Data Processing", "content": "The survey outcomes are stored in a secure repository at LJMU. Questions 1 to 9 are multiple choice and, therefore, only accept valid responses via a Microsoft Forms interface, which enforces the relevant rules. Therefore, quality assurance (QA) is automated and preventative. However, the remaining questions contain open fields which require retrospective QA measures. Therefore, open fields were corrected for spelling using spellcheck software. Correcting spelling is necessary for automated analysis, for example, when calculating the number of"}, {"title": "4 Results and Discussion", "content": ""}, {"title": "4.1 Exploratory Analysis and Visualisation", "content": "Table 3 presents the prevalence (i.e., proportion of the respondents as calculated in Equation 1) of each of the possible responses from the MCQs from the survey described in Section 3.1. A total of 117 responses were collected from educational staff in the UK (34.19%), UAE (16.24%), Iraq (43.36%), and others (4.42%). Most responders were primarily involved in teaching and assessment (89.74%), with the remaining responsible for administration (1.71%), management and policy matters (5.13%), and other roles (3.42%).\n# of respondents selecting choice\nPrevalence = (1) total #\nrespondents"}, {"title": "4.2 Statistical Analysis", "content": "Chi-square Test: The Chi-square test is an established statistical method to determine the significance of dependence between two categorical variables. In this study, we utilise the Chi-square test to statistically determine whether the acceptability of AI-based tools for the auto-assessment, as well as the"}, {"title": "4.3 Open-Ended Question Analysis", "content": "The open-ended questions described in Section 3 were analysed using Latent Dirichlet Allocation (LDA) [51] to identify common topics and keywords. Two open-ended questions are provided in Section 3. The first is related to challenges that academics have faced, and the second asks academics to provide suggestions to improve assessments in the presence of Al tools.\nWhat challenges, if any, have you encountered in assessing students' work in the presence of Al tools like ChatGPT?\nIn response to the aforementioned question, several keywords suggest common challenges. For example, \"detection\", \"tool\", \"understanding\", and \"originality\" are amongst the most common keywords. Identifying the common keywords in the original responses highlights common challenges, such as a lack of originality, as already highlighted in Table 3. Additionally, it highlights additional concerns related to assessing students' understanding in the presence of tools such as ChatGPT. Similarly, many academics wish for better tools to detect GAI usage.\nDo you have any suggestions for improving the assessment process in light of the prevalence of AI tools like ChatGPT? A plethora of keywords are presented in response to the request for suggestions. For example, common keywords include \"guideline\", \"policy\", \"viva\", \"presentation\", \"face [to face]\", \"written\", \"practical\", \"diversify\", and \"exam\". Moreover, further investigation of the suggestion shows a common theme of alternative assessment. For example, many responses suggest alternative and diverse assessments to prevent the use of Al in assessments, such as presentations, oral responses, exams, and practicals. Another common suggestion is to create and implement clear Al guidelines and policies."}, {"title": "5 Proposed Framework", "content": "As described previously, 71,79% of respondents reported that they would approve of the use of Al for auto-assessment. Therefore, in Figure 5 we present a proposed framework for automatically assessing students' work. Students' original work submissions (e.g., code, reports, etc.) will be forwarded to the GAI model (e.g., ChatGPT). The model will randomly generate N number of Multiple Choice Questions (MCQs) from the submitted work along with the associated correct answers. The auto-generated MCQs are then forwarded to institutional repositories or Virtual Learning Environments (e.g., Canvas, Blackboard, etc.), where students will be given a preset timeline to respond to the MCQs. These responses will then be automatically compared with the auto-generated correct answers to produce a grade for the corresponding work. Descriptive feedback will then be generated based on the student's responses and the scores they achieved. Then, the usual administrative and quality control processes are followed, such as assessment moderation and the delivery of grades and feedback to students."}, {"title": "Algorithm 1 Proposed automated assessment of assessments.", "content": "Receive Student Submission\nInput: Original student work (code, report, etc.)\nAction: Student submits work through a designated portal or VLE. Output:\nSubmission is forwarded to the GAI model.\nGenerate MCQs from Student Submission Input: Student's\nsubmitted work.\nAction: The GAI model (e.g., ChatGPT) analyses the submission. Process:\nExtract key concepts from the submission.\nRandomly generate N number of Multiple Choice Questions (MCQs) based on these concepts.\nGenerate correct answers for the MCQs.\nOutput: A set of N MCQs and their correct answers.\nForward MCQs to Institutional Repository/VLE Input:\nGenerated MCQs and answers.\nAction: The MCQs are uploaded to the VLE (Canvas, Blackboard, etc.). Output: Students\naccess the MCQs within a preset timeline.\nCollect Student Responses\nInput: Student responses to the MCQs within the VLE.\nAction: Students submit their answers.\nOutput: Responses are stored for comparison.\nCompare Responses with Correct Answers\nInput: Student responses and auto-generated correct answers.\nAction: Responses are automatically compared with the correct answers using a predefined grading\nalgorithm.\nOutput: Raw grade based on correct/incorrect answers.\nGenerate Descriptive Feedback\nInput: Student responses and achieved scores.\nAction: The Al model generates feedback based on the following: Correctness of answers.\nSimilarly, Algorithm 1 describes the logic relating to the proposed automated assessment of assessments. The process begins when students submit work via existing methods, such as a VLE. The submission is then forwarded to a GAI model. The GAI model then generates MCQs from the submitted work by extracting key concepts from the submission. Likewise, correct answers are generated for the MCQs. The MCQs can then be sent to the students via an institutional repository or VLE. Students may then submit their answers, which are compared to the correct answers for grading. Lastly, the GAI model generates feedback based on the returned answers and the correctness of the answers."}, {"title": "6 Conclusion and Future Work", "content": "The results described in Section 4 suggest that staff and students lack sufficient awareness of Al in education. This is exacerbated by the fact that more than half of institutions do not provide relevant policies related to Al used in assessments. Moreover, it is apparent that many institutions cannot identify instances where students submit Al-generated content in their assessments.\nTherefore, there is a clear need for training, identification tools, and the development and implementation of relevant policies.\nHowever, despite the aforementioned issues surrounding Al-generated content in assessment, as described in Section 4, academics tend to remain optimistic regarding the use of Al in education. In particular, the vast majority of responders (71.79% prevalence) stated that they would benefit from Al tools such as autonomous assessment (RQ2). Therefore, we propose the conceptual framework provided in Figure 5 to meet these needs.\nFurthermore, as described previously, the literature [8] reports many instances of AI tools being banned or restricted in academic policies. However, the positive opinions reported in Section 4 suggest that such policies may be unpopular with academics. Similarly, it indicates a policy gap concerning students' assessment in the context of emerging GAI (RQ1). Similarly, responses to the open-ended responses reported in Section 3 suggest that academics strongly desire clear and consistent policies and guidelines. Therefore, further consultation with academics is suggested to develop policies that balance upholding academic standards and encouraging students and academics to learn the current technology and reap the benefits [49].\nSimilarly, examining the open-ended responses reported in Section 3 suggests that a ban may not be necessary. For example, many responses suggested that students could be prevented from using Al tools in assessments by diversifying in terms of the types of assessments requested of students. Alternative assessment methods such as presentations, oral presentations, practicals, and exams are unlikely to be aided by the misuse of AI.\nFuture work should be performed in collaboration with academics, policymakers, and students to understand better what the stakeholders want and need in updated academic policies. Such policies should adapt to the everevolving technology landscape and uphold academic standards without rejecting the potential benefits. Furthermore, future work is required to implement the automated assessment tool described in 5. As evidenced in 4, such a framework is desired by academics."}]}