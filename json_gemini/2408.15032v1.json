{"title": "Mamba2MIL: State Space Duality Based Multiple Instance Learning for Computational Pathology", "authors": ["Yuqi Zhang", "Xiaoqian Zhang", "Jiakai Wang", "Yuancheng Yang", "Taiying Peng", "Chao Tong"], "abstract": "Computational pathology (CPath) has significantly advanced the clinical practice of pathology. Despite the progress made, Multiple Instance Learning (MIL), a promising paradigm within CPath, continues to face challenges, particularly related to incomplete information utilization. Existing frameworks, such as those based on Convolutional Neural Networks (CNNs), attention, and selective scan space state sequential model (SSM), lack sufficient flexibility and scalability in fusing diverse features, and cannot effectively fuse diverse features. Additionally, current approaches do not adequately exploit order-related and order- independent features, resulting in suboptimal utilization of sequence information. To address these limitations, we propose a novel MIL framework called Mamba2MIL. Our framework utilizes the state space duality model (SSD) to model long sequences of patches of whole slide images (WSIs), which, combined with weighted feature selection, supports the fusion processing of more branching features and can be extended according to specific application needs. Moreover, we introduce a sequence transformation method tailored to varying WSI sizes, which enhances sequence-independent features while preserving local sequence information, thereby improving sequence information utilization. Extensive experiments demonstrate that Mamba2MIL surpasses state-of-the-art MIL methods. We conducted extensive experiments across multiple datasets, achieving improvements in nearly all performance metrics. Specifically, on the NSCLC dataset, Mamba2MIL achieves a binary tumor classification AUC of 0.9533 and an accuracy of 0.8794. On the BRACS dataset, it achieves a multiclass classification AUC of 0.7986 and an accuracy of 0.4981. The code is available at https://github.com/YuqiZhang-Buaa/Mamba2MIL.", "sections": [{"title": "I. INTRODUCTION", "content": "Pathology plays a vital role in medicine, providing the scientific basis for diagnosing, treating, and prognosticating diseases by studying their nature, causes, development, and cellular effects. The clinical practice of pathology involves various tasks, including tumor detection, subtype classification, and staging [1], [2]. Given the urgency of these diagnoses and treatments, pathologists must adeptly solve diverse problems in a limited timeframe [3]. However, the meticulous examination of individual cells or cell clusters under a microscope (or within gigapixel images) for malignancies can be exceedingly time-consuming and labor-intensive, imposing a significant burden on clinical practice [4].\nThe advent of computational pathology (CPath) offers a promising solution to this challenge [5], [6]. CPath leverages advanced computational techniques to analyze and interpret whole slide images (WSIs) in digital pathology, assisting pathologists in diagnosing and predicting diseases. Recently, the integration of artificial intelligence (AI) technologies has revolutionized CPath, with deep learning significantly enhancing the automation and accuracy of pathology image analysis [4]. Furthermore, advancements in scanning systems, imaging technologies, and storage solutions have led to increased acquisition of WSIs in clinical settings, facilitating the growth of CPath.\nMultiple Instance Learning (MIL) [7] has emerged as an ideal framework for CPath, particularly in the analysis of WSIs. In this approach, each WSI (known as a bag) is divided into a large collection of patches (known as instances)"}, {"title": "II. RELATED WORK", "content": "Clinical practice relies heavily on pathologists to manually annotate and analyze pathology images. This traditional approach is not only time-consuming and labor-intensive but also prone to errors such as missed diagnoses due to the large size and complexity of pathology images. To address these challenges, researchers have recently proposed weakly supervised learning methods based on MIL [17], [18]. MIL enables models to learn and predict pathology results from WSIs without the need for pixel-level annotations. MIL in CPath can be broadly categorized into two main approaches: instance-level algorithms [8], [19], [20] and embedding-level algorithms. The instance-level algorithm trains the network with pseudo-labels assigned to each instance, where the pseudo-labels are based on bag-level labels. Subsequently, the top k instances, ranked by cancer probability, are selected for aggregation. However, this method has limitations, such as a strong dependence on the number of WSIs and limited applicability for differentiating multiple tumor subtypes. The second and more widely adopted algorithm is embedding-level algorithms [21]\u2013[23]. These algorithms utilize a pretrained pathology image model to map each patch in the entire WSI into a fixed-length embedding space. The aggregated feature embeddings are then processed by an operator to obtain the final classification result. Among these, the CLAM [11] model proposed by Lu et al. has set a standard for WSI processing, gaining widespread recognition and having a significant impact in the field. In this paper, we follow the same data processing flow as the CLAM model."}, {"title": "B. Methods for combining order-dependent and order- independent features in MIL", "content": "The above MIL methods based on the assumption of independent and homogeneous distribution often encounter a bottleneck in performance enhancement when processing pathology images due to neglecting the contextual relevance among patches. Some researchers have been keenly aware of this limitation and actively explored new strategies to integrate order-dependent and order-independent features, aiming to break through the performance limitations of the existing methods by enhancing the model\u2019s ability to capture complex spatial and structural information in pathology images"}, {"title": "III. METHOD", "content": "Figure 2 illustrates the structure of our architecture, which achieved the best results. Our framework supports the fusion of features from multiple branches and the following description uses three branches as an example. First, to exclude the influence of irrelevant regions, we discard the background. In large size WSIs (gigapixel images), not excluding the background causes a significant computational burden. Next, the WSIs are divided into patches, which are then embedded into feature vectors (also known as instance-level features) using a pretrained ResNet50. This process yields a sequence of instance features $S = \\{x_1, x_2, x_3,..., x_N\\}$ of , where $x_i \\in R^D$ denotes an instance feature, N denotes length of sequence, and D represents the feature dimension. The sequence S is processed through feature reduction and squaring operations to produce S', followed by sequence reordering to generate three distinct sequences: the original sequence So, the flipped sequence Sf, and the transposed sequence St. These sequences are then efficiently modeled using stacked SSD blocks, resulting in the features Fo, Ff, and Ft corresponding to each sequence, respectively. A feature weighted selection, implemented using the hyperbolic tangent activation function, is employed to select the features that contribute most effectively to the final result. Finally, the packet-level representation is derived using a Multi-Layer Perceptron (MLP) block."}, {"title": "B. Sequence squaring and reordering", "content": "Given the large dimensionality (dimension = 1024) of the feature vectors embedded by the pretrained ResNet, we apply a linear projection to the sequence of instance features S for dimensionality reduction, resulting in a reduced feature sequence St. To standardize the varying lengths of WSIs to a regular, manageable length, we then perform a squaring operation on Si to produce S'. As indicated in Table I, the sizes of different WSIs can vary significantly, making it impractical to normalize them to a uniform size. The detailed sequence squaring process is illustrated in Figure 3 and Equation 1.\n$S' = Concat (S_i , (x_1, x_2,..., x_M))$\n$L = (\\lceil\\sqrt{N}\\rceil)^2$\n$M = L - N$\nwhere xi denotes the strength feature, Concat denotes the feature splicing operation, N denotes the original sequence length, L denotes the sequence length after sequence squaring, and M denotes the length of the padding in the sequence squaring operation. This method ensures that each WSI is"}, {"title": "C. State space duality model", "content": "The SSD algorithm is a more computationally efficient algorithm than previous SSM, building on SSM and starting with the same set of equations:\n$h_t = Ah_{t-1} + Bx_t$\n$y_t = Ch_t$\nwhere $x_t$ is the input at moment t and $y_t$ is the output at moment t. Equation 3 defines a mapping from $x \\in R^T$ to $y \\in R^T$. We consider $x_t$ and $y_t$ as scalars and the hidden state $h_t$ as a one-dimensional vector of length N, where N is called the state expansion factor and is an independent hyperparameter. In SSM, the parameters of the three matrices (A, B, C) can vary over time. Specifically, the tensor $A \\in R^{(T\\times N\\times N)}$, while B,C \u2208 $R^{T\u00d7N}$. To enhance computational efficiency, structured SSMs typically employ diagonal matrices for A. In such cases, A effectively represents the diagonal elements of N \u00d7 N matrix, allowing it to be simplified to $A \u2208 R^{T\u00d7N}$.\nThe SSD algorithm in Mamba-2 introduces a further simplification by constraining the diagonal matrix A such that all its diagonal elements are identical, and all other elements are zero. Consequently, A can be represented as a scalar, or it can be parameterized by T alone. This simplification greatly reduces computational complexity and allows for the combination of SSM and attention while maintaining the structural integrity of the model. In this paper, we use Equation 4 to represent the entire SSD process.\n$F = Linear(SSD(Conv1D(Linear(S))))$\n$F\\in \\{F_o, F_f, F_t\\}, S \\in \\{S_o, S_f, S_t\\}$\nwhere F, S\u2208 $R^{L\u00d7D'}$, D' denotes the dimension of D after dimensionality reduction."}, {"title": "D. Feature selection", "content": "After splicing the features that capture different sequences using the stacked SSD block, we use the hyperbolic tangent activation function to achieve feature weighted selection. Specifically, as shown in Equation 5, the result of the linear transformation is nonlinearly activated by applying the hyperbolic tangent activation function (Tanh) through a linear layer that first maps the input features to a lower dimensional space. Subsequently, the Tanh-activated features are mapped into weight vectors via an additional linear layer. These weights are normalized by a softmax function and multiplied with the spliced features to obtain a weighted feature representation. This approach allows the model to automatically adjust the level of attention to individual features depending on the input data.\n$F_c = Concat(F_o, F_f, F_t)$\n$F' = Linear(Tanh(Linear(F_c)))$\n$R = F_c \\times Softmax(F')$ \nwhere $F_c$ denotes the spliced features, $F'$ denotes the weight vector, and R denotes the result after feature weighted selection."}, {"title": "IV. EXPERIMENTS", "content": "To validate the effectiveness of our model, we conducted experiments using two datasets: BRACS [30] and NSCLC. The sample details of datasets are summarized in Table I.\nBRACS Dataset. BRACS is a histopathology image dataset of hematoxylin and eosin (H&E) stained breast cancer tissues. As shown in Table II, it includes a total of seven subtypes: normal (glandular tissue samples without lesions), pathologically benign (PB), usual ductal hyperplasia (UDH), flat epithelial atypia (FEA), atypical ductal hyperplasia (ADH), ductal carcinoma in situ (DCIS), and invasive carcinoma (IC). The dataset comprises 537 samples, with image sizes ranging from a maximum of 181,272 \u00d7 88,334 pixels to a minimum of 23,799 \u00d7 15,455 pixels. The average sample size is approximately 2,587 patches.\nNSCLC Dataset. NSCLC, sourced from The Cancer Genome Atlas (TCGA), consists of H&E-stained histopathology images of lung squamous cell carcinoma and lung adenocarcinoma. It includes two subtypes: lung squamous cell carcinoma (LUSC) and lung adenocarcinoma (LUAD). The dataset comprises 537 samples, with image sizes ranging from a maximum of 191,352 \u00d7 97,078 pixels to a minimum of 10,000 \u00d7 4,617 pixels. The average sample size is approximately 3,004 patches."}, {"title": "B. Implementation Details", "content": "Each WSI is divided into a series of non-overlapping 512\u00d7512 patches at \u00d720 magnification, and the background regions are discarded. ResNet [33], pre-trained on ImageNet [34], is used to embed the features of each patch into a 1024- dimensional vector. A linear projection layer is then applied to reduce these embeddings from 1024 to 512 dimensions. The features of each bag are thus represented as a vector in $B_\u00bf \u2208 R^{L\u00d7512}$. To mitigate the impact of data partitioning and randomness on model evaluation, we utilized 5-fold cross- validation across both datasets. The datasets were split into training, validation, and test sets in an 8:1:1 ratio. Consistent with standard practices, we employed the area under the curve (AUC) and accuracy (ACC) metrics, along with their standard deviations (std), for evaluation. In all tables, the best result is indicated in bold, while the second-best result is underlined. Baseline. We selected several methods: (1) traditional pooling methods, including average pooling and maximum pool-"}, {"title": "C. Results on WSIs classification", "content": "Table III presents the experimental results for the BRACS and NSCLC datasets. Our proposed method, Mamba2MIL, achieved near-optimal performance across almost all metrics. On the BRACS test set, the performance of our model was only marginally lower than ABMIL, with a difference of approximately 0.01 in ACC. Specifically, our model achieved an AUC of 0.7986 and an ACC of 0.4981 on the BRACS dataset, while on the NSCLC dataset, it achieved an AUC of 0.9533 and an ACC of 0.8794. Compared to MambaMIL, our model showed an AUC improvement of approximately 0.01 on the BRACS dataset and an ACC improvement of around 0.04. On the NSCLC dataset, the AUC improvement was smaller, but the ACC improved by about 0.02.\nAs illustrated in Figure 5, we further visualized the performance differences between our model and others on the BRACS validation set. Figure 5-(a-c) demonstrate that our proposed method outperforms TransMIL in the validation set AUC and ACC during 5-fold cross-validation, with more stable loss behavior, although the loss reduction was not as rapid as in TransMIL. Additionally, as shown in Figure 5-(d-e), while the performance of our proposed method closely matched that of MambaMIL in terms of the validation set AUC and ACC, it performed better on the test set, suggesting stronger generalization capability. Figure 5-f indicates that the loss reduction in our proposed model is both faster and more stable compared to that of MambaMIL, highlighting the efficiency of our approach."}, {"title": "D. Comparison Results", "content": "To thoroughly evaluate the effectiveness of Mamba2MIL, we conducted extensive comparative experiments against other models. As shown in Table IV, our model achieved the best results across all metrics compared to the two variants of Mamba-2, demonstrating the efficacy of our improvements. In these experiments, Mamba-2 (wrapping) included an additional mixer class and residual connections to Mamba-2.\nFigure 6 presents the performance of our model at different depths, with the best results obtained at a depth of two layers. While a three-layer depth showed slightly better performance on the validation set, it performed poorly on the test set, indicating a lack of generalization. Table VI outlines the results of comparative experiments concerning a critical parameter of the Mamba model\u2014the state expansion factor. The optimal performance was achieved with a state expansion factor of 64. Although Mamba-2 supports larger state dimensions than Mamba-1, this does not necessarily mean that the largest state dimensions are optimal for WSIs classification."}, {"title": "E. Ablation Study", "content": "To further assess the impact of multiple reordering methods on model performance, we conducted a series of ablation studies. As shown in Table 8, the first three rows encompass almost all of the best and second-best results. These experiments all use three orders of features, differing only slightly in the SSD block and feature aggregation steps. Specifically, the 'Add' and 'Concatenate' operations indicate different ways of aggregating the results of the SSD block, respectively. While the summing-based feature aggregation method appears to outperform Mamba2MIL, similar to random reordering, it struggles on the BRACS dataset (Test AUC=0.7751, Test ACC=0.4302)and shows limited generalization. Incorporating the transposition order improves the test set AUC and ACC from 0.9403 and 0.8685 to 0.9533 and 0.8794, respectively. Similarly, adding the flip order enhances the test set AUC and ACC from 0.9442 and 0.8642 to 0.9533 and 0.8794, respectively. These results suggest that sequence augmentation methods that aggregate multiple alignments are capable of extracting more discriminative representations from various sequence orders, thereby effectively enhancing WSI classification performance."}, {"title": "V. CONCLUSION", "content": "In this paper, we propose a novel MIL framework called Mamba2MIL. Our framework utilizes SSD to model long sequences of patches of WSIs, which, combined with weighted feature selection, supports the fusion processing of more branching features and can be extended according to specific application needs. Moreover, we introduce a sequence transformation method tailored to varying WSI sizes, which enhances sequence-independent features while preserving local sequence information, thereby improving sequence information utilization. We evaluate our model against state- of-the-art methods using 5-fold cross-validation on two datasets with different cancer types, achieving consistently optimal performance. These results validate the effectiveness of Mamba2MIL in enhancing the accuracy and reliability of computational pathology, underscoring its potential as a valuable tool for pathologists in clinical practice."}]}