{"title": "DPD-NeuralEngine: A 22-nm 6.6-TOPS/W/mm\u00b2\nRecurrent Neural Network Accelerator for\nWideband Power Amplifier Digital Pre-Distortion", "authors": ["Ang Li", "Haolin Wu", "Yizhuo Wu", "Qinyu Chen", "Leo C. N. de Vreede", "Chang Gao"], "abstract": "Abstract-The increasing adoption of Deep Neural Network\n(DNN)-based Digital Pre-distortion (DPD) in modern communi-\ncation systems necessitates efficient hardware implementations.\nThis paper presents DPD-NeuralEngine, an ultra-fast, tiny-\narea, and power-efficient DPD accelerator based on a Gated\nRecurrent Unit (GRU) neural network (NN). Leveraging a co-\nddesigned software and hardware approach, our 22nm CMOS\nimplementation operates at 2 GHz, capable of processing I/Q\nsignals up to 250 MSps. Experimental results demonstrate a\nthroughput of 256.5 GOPS and power efficiency of 1.32 TOPS/W\nwith DPD linearization performance measured in Adjacent\nChannel Power Ratio (ACPR) of -45.3 dBc and Error Vector\nMagnitude (EVM) of -39.8 dB. To our knowledge, this work\nrepresents the first AI-based DPD application-specific integrated\ncircuit (ASIC) accelerator, achieving a power-area efficiency\n(PAE) of 6.6 TOPS/W/mm\u00b2.", "sections": [{"title": "I. INTRODUCTION", "content": "The evolution of wireless communication systems towards\nhigher data rates and broader bandwidths has intensified\ndemands on transmitter digital backends (DBEs), potentially\nmaking them primary power consumers. As 5G and future 6G\nsystems employ sophisticated modulation schemes and wider\nbaseband bandwidths (fBB), Digital Pre-Distortion (DPD)\nalgorithms in DBEs must process data at sampling rates up to\nthousands of mega samples per second (MSps) to effectively\nlinearize power amplifiers (PAs).\nMassive Multiple-Input Multiple-Output (mMIMO) sys-\ntems, enhancing spectral efficiency through numerous anten-\nnas, require efficient DBEs to handle increased computational\nloads [1], [2]. However, power constraints in wireless sys-\ntems, particularly in base stations and IoT devices, necessitate\nsolutions with high power-area efficiency (PAE) measured\nin Operations per Second per Watt per square millimeter\n(OPS/W/mm\u00b2).\nTraditional DPD techniques, such as the generalized mem-\nory polynomial (GMP) model [3], struggle to meet lineariza-\ntion performance requirements for wideband PAs. Addition-\nally, stringent frequency and latency constraints of advanced\ncommunication standards create a pressing need for dedicated\nDPD hardware accelerators that deliver high computational\nthroughput while maintaining low power consumption and\nminimal silicon area.\nDeep Neural Networks (DNNs) have shown promise\nin modeling complex PA nonlinearities for wideband sys-\ntems. Early approaches like Time Delay Neural Networks\n(TDNNs) [4], [5] paved the way for more sophisticated\nmodels such as VDLSTM and SVDLSTM [6], which lever-\nage recurrent neural networks (RNNs) to capture PA dy-\nnamics. Recent developments include evaluation frameworks\nlike OpenDPD [7] and mixed-precision models such as MP-\nDPD [8].\nHowever, hardware implementation of DNN-based DPD\nsystems presents significant challenges. The computational\nand memory demands of DNNs impede real-time processing,\nparticularly under the silicon area and power constraints of\nwireless SoCs [9]. Current DPD FPGA implementations face\nchallenges balancing power consumption and throughput when\nhandling very high I/Q sample rates [10]\u2013[16]. Similarly,\nprior FPGA- [17]-[22] and ASIC-based [23]\u2013[29] DNN/RNN"}, {"title": "II. RNN-BASED DPD ALGORITHM", "content": "GRU-based RNNs can effectively model long-term de-\npendencies in sequential data, making them ideal for DPD\napplications. As illustrated in Figure 1, our GRU-RNN DPD\nmodel comprises three layers: the preprocessor, GRU, and\nfully connected (FC) layers.\nInitially, the input in-phase (Ix) and quadrature (Qx) signals\nare processed to extract four features, forming the input feature\nvector xt at time t:\n$X_t = \\begin{bmatrix} I_{x,t} \\\\ Q_{x,t} \\\\ I^2_{x,t} + Q^2_{x,t} \\end{bmatrix}$"}, {"title": "A. Microarchitecture", "content": "The preprocessor extracts additional features from input\nmodulated signals Ir and Qx, feeding them into the PE\narray. The PE array, subdivided into input, hidden, and FC\narrays, performs matrix multiplications for the GRU and fully\nconnected layers. Each PE executes Multiplication and Accu-\nmulation (MAC) operations, with varying levels of parallelism\ntailored to respective layer dimensions.\nNonlinear activation functions are implemented using effi-\ncient approximation methods, detailed in Section III-B. The\ndesign incorporates two main buffers: a weight buffer storing\nfixed-point model parameters and a hidden state buffer for\ntemporarily storing GRU computations."}, {"title": "B. Nonlinear Function Approximation", "content": "To address the computational complexity of sigmoid and\ntanh functions in hardware, we implement Piecewise Lin-\near (PWL) approximations, namely Hardsigmoid and\nHardtanh:\n$Hardsigmoid(x_i) = \\begin{cases}1, & x_i > 2 \\\\x_i/4+1/2, & -2 \\le x_i \\le 2\\\\0, & x_i < -2\\end{cases}$ \n$Hardtanh(x_i) = \\begin{cases}x_i, & -1 < x_i < 1\\\\-1, & x_i < -1\\end{cases}$"}, {"title": "C. Fixed-Point Data Representation", "content": "To optimize hardware efficiency while maintaining compu-\ntational accuracy, we employ a 12-bit Q2.10 fixed-point data\nformat (2 integer bits and 10 fractional bits) for both NN\nweights and activations and also the input and output I/Q data.\nThe GRU-RNN DPD model is trained using Quantization-\nAware Training (QAT) to minimize accuracy loss compared"}, {"title": "IV. EXPERIMENTAL RESULTS", "content": "1) Software: The GRU-RNN DPD model, with 4 input\nfeatures, 10 hidden units, and 1 hidden layer (502 parameters\ntotal), is evaluated using the 200 MHz OpenDPD dataset [7]\nand a new 80MHz, 64QAM, OFDM signal dataset (8.2dB\nPAPR). Both datasets use a 60-20-20 train-validation-test split.\nThe latter dataset trains the model used in real measurements\nwith a Keysight M8190A generator, linear pre-amplifier, GaN\nDoherty PA, and R&S-FSW43 analyzer. The GaN Doherty's\naverage output power is 40 dBm before and after DPD.\nThe training utilizes an NVIDIA RTX 2050 Laptop GPU.\nQAT runs for 300 epochs using ReduceLROnPlateau sched-\nuler (initial lr=1\u00d710-3), with batch size 64, frame length 50,\nand stride 1.\n2) Hardware: The design is first simulated on a Digilent\nPYNQ Board (Zynq-7020 FPGA-SoC) for verification and\nresource estimation. It is then implemented as an ASIC using\nGlobalFoundries 22FDX-PLUS FD-SOI technology. Cadence\ntools are used: Genus for synthesis, Innovus for placement\nand routing, and Xcelium for simulations. Performance and"}, {"title": "B. Results and Evaluation", "content": "1) Model Accuracy: Figure 3 shows a comparison of\nmodel accuracy between using Look-Up Table (LUT)-based\nactivation functions and using Hardsigmoid/Hardtanh\nfunctions at different precision levels, with the 32-bit floating-\npoint model as the reference baseline. The figure indicates that,\nat the same weight and activation precision, the GRU-DPD\nmodel with Hardsigmoid/Hardtanh functions trained by\nQAT can achieve higher linearization performance than the\nLUT method, with an ACPR/EVM improvement of 1-2 dB. A\nprecision sweep for quantized models reveals that quantizing\nweights and activations to 12 bits provides an optimal balance\nbetween accuracy and hardware overhead."}, {"title": "C. FPGA Emulation", "content": "Table I shows the resource utilization of FPGA-\nemulated DPD-NeuralEngine using baseline LUT-based\nand Hardsigmoid/Hardtanh activation functions. Fig-\nure 4 shows that LUT-based activation function implementa-\ntions consume even more FPGA-LUTs (over 20,000) than PEs\nfor MAC operations. In contrast, Hardsigmoid/Hardtanh\nfunctions significantly reduce FPGA-LUT usage for both\nsigmoid and tanh by 18.9\u00d7 and 35.3\u00d7, respectively, reduc-\ning the total FPGA-LUT usage to around 5,500, demonstrating\na significant reduction of their area cost."}, {"title": "D. ASIC Implementation", "content": "Figure 5 summarizes the post-layout area (0.2mm\u00b2) and\nperformance of DPD-NeuralEngine operating at a clock\nfrequency (fclk) of 2 GHz with a supply voltage of 0.9 V. With\na total power consumption of 195mW, the design achieves\na latency of 7.5 ns and 256.5 GOPS throughput, capable of"}, {"title": "E. Comparison With Previous Work", "content": "Table II shows a comparison between the proposed ac-\ncelerator and other state-of-the-art DPD hardware designs.\nMost previous works utilized FPGAs and memory polyno-\nmial (MP)-based DPD models, with only one neural net-"}, {"title": "V. CONCLUSION", "content": "This paper presents an efficient ASIC implementation of\na GRU-RNN DPD accelerator for wideband power amplifier\nlinearization. The reported efficiency numbers significantly\noutperform existing FPGA- and GPU-based DPD implemen-\ntations. As we approach 6G, integrating advanced AI algo-\nrithms with efficient hardware is crucial. Our ASIC-based\napproach demonstrates the potential of neural network-based\nDPD accelerators to optimize performance, power efficiency,\nand signal quality for future wireless communication systems."}]}