{"title": "Spatial-Temporal Attention Model for Traffic State Estimation with Sparse Internet of Vehicles", "authors": ["Jianzhe Xue", "Dongcheng Yuan", "Yu Sun", "Tianqi Zhang", "Wenchao Xu", "Haibo Zhou", "Xuemin (Sherman) Shen"], "abstract": "The growing number of connected vehicles offers an opportunity to leverage internet of vehicles (IoV) data for traffic state estimation (TSE) which plays a crucial role in intelligent transportation systems (ITS). By utilizing only a portion of IoV data instead of the entire dataset, the significant overheads associated with collecting and processing large amounts of data can be avoided. In this paper, we introduce a novel framework that utilizes sparse IoV data to achieve cost-effective TSE. Particularly, we propose a novel spatial-temporal attention model called the convolutional retentive network (CRNet) to improve the TSE accuracy by mining spatial-temporal traffic state correlations. The model employs the convolutional neural network (CNN) for spatial correlation aggregation and the retentive network (RetNet) based on the attention mechanism to extract temporal correlations. Extensive simulations on a real-world IoV dataset validate the advantage of the proposed TSE approach in achieving accurate TSE using sparse IoV data, demonstrating its cost effectiveness and practicality for real-world applications.", "sections": [{"title": "I. INTRODUCTION", "content": "Traffic state estimation (TSE) serves as a cornerstone for intelligent transportation systems (ITS), underpinning appli- cations such as traffic management, congestion tracking, and road planning through the provision of live, precise traffic state information [1], [2]. Historically, TSE has depended on roadside sensors and cameras to collect data about vehicle speeds and flows across specific areas. Despite their utility, these traditional methods are limited in coverage and costly, and do not meet the rapidly evolving needs of ITS [3]. To this end, the internet of vehicles (IoV) paradigm has emerged as a data-driven solution, capitalizing on vehicle-contributed data to bypass the limitations of traditional traffic sensing methods [4]. The integration of vehicular networks has transformed numerous vehicles into nodes of a vast, interconnected data- sharing network, thereby enabling the provision of extensive real-time data for ITS applications across the entire road network [5], [6], [7], [8]. This approach, utilizing data like vehicle speeds and GPS coordinates, offers a framework for TSE that not only achieves broader coverage but also is more cost-efficient compared to previous methods. Thus, IoV- based TSE represents a significant leap forward, offering comprehensive traffic state insights with enhanced coverage and cost benefits.\nThe requisite for substantial volumes of high-quality IoV data for effective TSE presents notable challenges, primarily due to the overheads associated with its collection [9], [10]. The endeavor to amass extensive IoV data in real-time brings considerable strain on both the collection mechanisms and the communication networks, making the task particularly arduous. In contrast, the acquisition of sparse IoV data from a limited number of connected vehicles emerges as a more fea- sible and cost-effective solution in real-world scenarios [11], [12], [13]. The endeavor to accurately estimate traffic states from sparse IoV data holds substantial importance and offers discernible benefits. Complete data collection in a targeted area often proves unattainable due to obstacles such as transmission loss and user reluctance to share information, driven by the limitations of network resources or privacy concerns. This reality necessitates the acceptance of incomplete datasets [14], [15], [16]. Furthermore, the strategy of collecting sparse IoV data presents a more economical alternative. By minimizing the volume of data required, this approach serves to reduce the burden on network transmissions and storage. Therefore, the TSE framework that only utilizes sparse IoV data is needed, where the sparse IoV data is collected from a small number of connected vehicles distributed throughout the city.\nA major issue of using sparse IoV data is the reduced stability and accuracy of TSE results compared to the results derived from a larger dataset [17]. Nevertheless, the inher- ent characteristics of transport systems offset this limitation through the redundancy of information in the IoV data, en- abling TSE to be achieved using sparse IoV data. At the micro- level, the dynamics of individual vehicle movements adhere to established car-following models, wherein the velocity of one vehicle closely mirrors that of nearby vehicles. Consequently, the velocity of a single vehicle can, to a certain degree, act as a representative indicator of the speeds of an adjacent vehicle cluster. At the macro-level, the traffic state of urban transport exhibits spatial and temporal correlations [18]. Roads in the vicinity of congested areas may also become congested themselves, and traffic congestion shapes evolve in a gradual manner over time [19]. Thus, by leveraging spatial-temporal correlations inherent in the urban traffic dynamics, it becomes viable to conduct accurate TSE using sparse IoV data.\nCapturing spatial-temporal correlations in traffic states poses significant challenges, particularly for deriving accurate esti- mations from sparse IoV data [20], [21], [22], [23]. Tempo- rally, estimations that are directly derived from such sparse IoV data frequently manifest instability and a high degree of noise. Spatially, the inherent sparsity of IoV data results in a dispersed distribution of vehicular data points within the target region, consequently attenuating the strength of spatial correlations among the available vehicles. Additionally, due to the diversity and complexity of the road system, the spatial and temporal correlations of traffic states are varied and dynamic, thus complicating the accurate capture of these correlations [24]. Given these complexities, the application of deep learning (DL) approaches, renowned for their robust modeling capabilities, emerges as a promising approach for TSE with sparse IoV data by effectively capturing the spatial- temporal correlations [25].\nIn this work, we present an innovative framework for cost-effective TSE using sparse IoV data, and also design a spatial-temporal attention model for recovering accurate TSE from initial estimations obtained from sparse IoV data. To collect the sparse IoV data, we employ a strategy of randomly selecting a limited subset of connected vehicles, distributed uniformly across the entire urban area, identified as probe vehicles. Then, we define the traffic state as the average speed of each grid area in four driving directions over a defined period. It is observed that the sparsification of IoV data can lead to a decrease in TSE accuracy. To address this issue, we propose a novel DL model, the convolutional retentive network (CRNet), to offset the effects of data sparsification and achieve accurate real-time TSE by effectively capturing spatial-temporal correlations inherent in urban traffic states. For spatial correlation, the model employs the convolutional neural network (CNN) to learn local spatial features. For temporal correlation, the retentive network (RetNet) which is a network architecture based on attention is utilized to extract the temporal shapes within the traffic state. Our comprehensive simulations, conducted on a real-world IoV dataset, validate the feasibility of utilizing sparse IoV data processed by CRNet for TSE, achieving accurate estimations at a relatively low cost and outperforming existing methods. The contributions of this paper are as follows:\n\u2022 We present a cost-effective TSE framework using sparse IoV data that provides accurate TSE using only a small subset of IoV data, which is obtained by uniformly reducing the amount of IoV data across all urban regions.\n\u2022 We find that sparsification of IoV data introduces inaccu- racies to the average vehicle speed in each urban region, and the distribution of initial estimation errors approxi- mately follows a Gaussian distribution. We conceptualise the TSE problem based on sparse IoV data as similar to the sequential image data denoising problem.\n\u2022 We propose a novel spatial-temporal attention model to provide accurate TSE outcomes from sparse IoV data. CRNet fully exploits the synergy of mining both spatial and temporal traffic state correlations to ensure robust and accurate performance.\nThe remainder of this paper is organized as follows. Section II provides a review of TSE and related DL approaches. Section III defines the TSE problem by data analysis. Section IV presents the model structure of the CRNet. Section V gives extensive experimental results to evaluate the effectiveness and superior performance of the proposed TSE method. Section VI concludes the paper."}, {"title": "II. RELATED WORK", "content": "The task of TSE is paramount for ITS. The advent of connected vehicles has ushered in a new era of IoV data, which encompasses extensive vehicular driving information, such as GPS coordinates and driving speeds across the traffic network [26], [27]. These rich IoV data provide the possi- bility to perform accurate TSE. Nonetheless, the granularity of vehicular data is frequently coarse, attributed to the dis- parate temporal and spatial distribution of vehicles, coupled with suboptimal data acquisition practices, culminating in less than accurate TSE outcomes. To enhance TSE accuracy, numerous studies have focused on the imputation of missing traffic data, which are either passively or actively missing. A data completion approach based on the tensor decomposition method is proposed to recover missing values in inter-regional traffic data by dividing the target area into regions [28]. A Laplacian-enhanced low-rank tensor completion framework is constructed for large-scale traffic kriging interpolation to recover reliable estimates from incomplete traffic data and achieve good performance under low observation rates [29]. Meanwhile, there has been growing emphasis on the develop- ment of DL methods for traffic data imputation in recent years [30], [31].\nMost of the existing work assumes that traffic data is incomplete for certain areas and mainly concentrates on fixing the missing data, based on the assumption that the available data is perfect. The sparsification of IoV data for the entire region may lead to the inapplicability of these methods in cases where the available data is no longer perfect, due to insufficient raw data for estimating the state of each region. This means that further studies are needed for accurate TSE with the sparse IoV data.\nTraffic data inherently manifests spatial and temporal cor- relations. The advent and proliferation of DL paradigms have enabled deep neural networks to adeptly learn and extract these correlations. In the domain of spatial feature extraction, the CNN is a classic and effective model, aptly suited for processing gridded image data. Conversely, the temporal corre- lation has to be extracted from sequential structured data. Long short-term memory (LSTM) network is a recurrent neural network (RNN) used for sequential data processing, aimed to deal with the vanishing gradient problem present in traditional RNNs [32]. Another architecture known as transformer uses self-attention to handle sequential data, replacing RNNs in many applications [33]. Transformer and its variants have been used with considerable success in tasks of traffic data"}, {"title": "III. FRAMEWORK AND PROBLEM ANALYSIS", "content": "This section includes four parts. First, the TSE framework using sparse IoV data is delineated. Second, the traffic state image obtained from IoV data is introduced. Third, an analysis of the estimation errors arising from sparse IoV data is conducted. Fourth, the problem of recovering vehicle speeds from sparse IoV data is formulated. For convenience, the major notations in this paper are shown in Table I.\nThe cost-effective TSE framework using sparse IoV data is shown in Fig. 1. The city map is divided into grids, each of which represents a small area of the city and has four different traffic flow speeds that indicate the average speed through the area from different directions. The sparse IoV data containing vehicle mobility information is gathered through vehicular networks. Instead of removing data from some specific regions to reduce the data amount, we acquire the sparse IoV data by randomly selecting a small fraction of vehicles as data sources uniformly distributed across the city. The recruitment probability of each vehicle is equal, and the chosen ones are sparse probe vehicles.\nFollowing the data collection, we divide the traffic data into four categories, corresponding to four different vehicle driving directions. The initial estimations are acquired by computing average speeds of probe vehicles in each grid of the map to construct the traffic state images in four directions, which can be merged together to form the overall traffic states of the city. Then, the recovery algorithm is applied to reach precise TSE based on the initial estimations from sparse IoV data.\nIn this study, we construct the traffic state image, with a resolution of H \u00d7 W and four channels, as the visual representation of the traffic state. First, the city map is evenly divided into grids, similar to pixels in an image, and each grid has multiple speeds of different directions, similar to the color channels in a pixel. Specifically, for an H \u00d7 W gridded city map, we construct four sub-maps based on four driving directions and merged four maps to get a complete city map,\n$G_c = \\begin{bmatrix} G_{1,1}^c & \\cdots & G_{1,W}^c \\\\ : & & : \\\\ G_{H,1}^c & \\cdots & G_{H,W}^c \\end{bmatrix}$\n(1)\n$G = Concat(G_c|c = \\{1,2,3,4\\})$\n(2)\nwhere $G_{h,w}^c$ represents the grid of the city map that is located at (h, w) and related to driving direction c, $G_c$ is the gridded sub-map corresponding to driving direction c, G is the complete city map composed of four sub-maps.\nFor each grid, the average vehicle speeds in different direc- tions are calculated to represent its traffic states. For estimating the ideal traffic state at time slot t, we obtain the entire IoV data $J_t$ which includes all vehicle driving information. Then, we match the gridded city map G with $J_t$ to construct the grid-structured dataset as,\n$F_t = \\begin{bmatrix} F_{1,1}^t & \\cdots & F_{1,W}^t \\\\ : & & : \\\\ F_{H,1}^t & \\cdots & F_{H,W}^t \\end{bmatrix}$\n(3)\nwhere $F_{h,w}^t = \\{v_{h,w}^t|v_{h,w}^t \u2208 J_t\\}$ is composed of all vehicle speeds matched to the grid located at (h, w) at time slot t. The driving information of each vehicle is denoted as $v_{h,w}^t$, where (h, w) indicates that the GPS coordinates of the vehicle lie within the grid located at (h, w), and the absolute value of $v_{h,w}^t$ is the speed. For a more nuanced and precise description of traffic states, we further describe $v_{h,w}^t$ as $v_{h,w}^{t,c}$, where c denotes the driving direction of $v_{h,w}^t$. Subsequently, the ideal estimation of the traffic state in direction c for each grid is calculated as,\n$y_{t,c}^{h,w} = Mean(v_{h,w}^{t,c}|v_{h,w}^{t,c} \u2208 F_{h,w}^t)$,\n(4)\nwhere $y_{t,c}^{h,w}$ is the average speeds of vehicles driving towards direction c in the grid which is located at (h, w) on the map at time slot t obtained by the entire IoV data. Note that c = {1,2,3,4}, since we classify the driving directions of probe vehicles to be east, south, west, and north. Thereafter, the complete traffic state of a grid located at (h, w) can be depicted as,\n$y_{t}^{h,w} = Concat(y_{t,c}^{h,w}|c = \\{1,2,3,4\\}).$\n(5)\nFor the entire city map, we integrate all of its grids and denote the traffic state image at time slot t as,\n$Y_t = \\begin{bmatrix} Y_{1,1}^t & \\cdots & Y_{1,W}^t \\\\ : & & : \\\\ Y_{H,1}^t & \\cdots & Y_{H,W}^t \\end{bmatrix}$\n(6)\nTo summarize, $Y_t$ represents the traffic state image at time slot t, $y_t^{h,w}$ indicates the value of $Y_t$ for the grid in row h and column w, $y_{t,c}^{h,w}$ indicates the value of $y_t^{h,w}$ in direction c. Therefore, we can view $Y_t$ as an image with a resolution of H x W and four channels, which allows the utilization of DL models for handling traffic state data efficiently.\nTraffic states can be derived through a similar process when sparse IoV data is utilized instead of the entire data. However, we discover that while the average speed obtained from sparse IoV data is close to the average speed obtained from the entire data, it exhibits noise and instability. Through theoretical analysis based on central limited theory (CLT) and experimental observations, we find that the error distribution for each time slot is similar to a Gaussian distribution.\nThe process of deriving initial traffic state images with sparse IoV data is described as below. The sparse IoV data collected at time slot t is denoted as $J_t^'$, which is considered as the subset obtained by randomly sampling from the entire IoV data $J_t$. This sampling method assigns an equal selection probability to each vehicle driving information. Then, with a similar data organization process, the sparse vehicle driving information gathered over a duration of time length T between the past and the present are organized as,\n$S_t = \\begin{bmatrix} S_{1,1}^t & \\cdots & S_{1,W}^t \\\\ : & & : \\\\ S_{H,1}^t & \\cdots & S_{H,W}^t \\end{bmatrix}$\n(7)\nwhere $S_{h,w}^t = \\{v_{h,w}^t|v_{h,w}^t \u2208 J_t'\\}$ comprises the sparse driving information of probe vehicles which are matched to grid located at (h, w). Here the sparse IoV data can be seen as a subset of the entire data, i.e., $J_t' \u2286 J_t, S_{h,w}^t C F_{h,w}^t$. Likewise, in the case of using sparse IoV data, the initial traffic state estimation at time slot t is obtained as,\n$X_t = \\begin{bmatrix} X_{1,1}^t & \\cdots & X_{1,W}^t \\\\ : & & : \\\\ X_{H,1}^t & \\cdots & X_{H,W}^t \\end{bmatrix}$\n(8)\n$x_{t,c}^{h,w} = Mean(v_{h,w}^{t,c}|v_{h,w}^{t,c} \u2208 S_{h,w}^t)$,\n$x_{t}^{h,w} = Concat(x_{t,c}^{h,w}|c = \\{1,2,3,4\\})$,\n(9)\n(10)\nwhere $x_{t}^{h,w}$ is the average speeds obtained by sparse IoV data at time slot t in the grid located at (h, w).\nTheoretical analysis based on CLT shows that $x_t^{h,w}$ is equal to $y_t^{h,w}$ plus the Gaussian noise $g(t, h, w)$ and multiplied by the random loss indicator z(t, h, w). CLT states that for a population with a mean of \u00b5, if a small number of samples are randomly drawn from the population, the averages of these sampled variables follow a normal distribution centered on \u00b5 [39]. When using CLT to analyse TSE problems based on sparse IoV data, the ideal average vehicle speed derived from the entire data represents the population mean, while the initial average vehicle speed derived from the sparse IoV data serves as the sample mean. Therefore, the initial average vehicle speed follows a normal distribution centered on the ideal average vehicle speed, while the estimation error can be regarded as a Gaussian error. In addition, for grid regions with fewer data, data sparsification will inevitably result in these regions not collecting any data that can be used for estimation, resulting in some regions having no initial estimation. Thus, the relationship between $x_t^{h,w}$ and $y_t^{h,w}$ can be expressed as,\n$x_t^{h,w} = [y_t^{h,w} + g(t, h, w)] \u00b7 z(t, h, w)$,\n(11)\nwhere $g(t, h, w) \\sim N(0, \u03c3_{t,h,w}^2)$ is the matrix representing Gaussian noise, z(t, h, w) is a matrix of zeros and ones cor- responding to the missing data caused by data sparsification. The standard deviation $\u03c3_{t,h,w}^2$ exhibits variation over time and space, which is closely associated with the amount of driving information matched to the grid located at (h, w).\nTo validate the analyzed relationship above, Fig. 3 shows the error distribution of data sparsification with respect to the entire data. Fig. 3a shows the difference between the presence and absence of missing data. The blue line is the overall error distribution for the sparse IoV data, which has a shape close to a Gaussian distribution but shows distortions in the right part due to missing data. The red line is the error distribution after zeroing the errors of missing data, which has an almost ideal Gaussian distribution. The green area represents the data errors caused by missing data while the orange area is the result of setting the errors of missing data to zero, and the two areas are equal in size. We also show the probability distribution functions (PDF) of the differences between $y_t^{h,w}$, and $x_t^{h,w}$ at three different degrees of sparsity including 5%, 30%, 50% in Fig. 3b. All three functions are bell-shaped curves with distortion on the right side. The distortion decreases with increasing sparsity, implying that the more data sampled the fewer regions of missing data, thus making the error distribution between $y_t^{h,w}$ and $x_t^{h,w}$ close to Gaussian noise. The data analysis matches the previous theoretical analysis based on CTL.\nThe initial average vehicle speed derived from the sparse IoV data constitutes the initial traffic state image, but it is inaccurate compared to the ideal estimate derived from the complete data, and therefore it cannot be used as the final estimation. Based on the above analysis and definitions, the task of real-time TSE using sparse IoV data is conceptu- alised as the problem of recovering grid-structured traffic state image by exploiting spatial and temporal correlations in time-series traffic state images. In specific, the inputs of the TSE recovery algorithm are historical and current initial traffic state images obtained from sparse IoV data, denoted as $[X_{t-T+1}, ..., X_{t\u22121}, X_t]$. The goal of the algorithm is to generate an accurate traffic state image of the current time slot $Y_t$ that is as similar as possible to the ideal estimation derived from the entire data. To achieve accurate TSE performance, it is necessary to make full use of the spatial-temporal correlation in the recent initial traffic estimations in order to reduce the impact of Gaussian noise and data loss on the accuracy caused by data sparsification, which is the difficulty of the algorithm design for this problem. Thus, the essence of the TSE recovery problem is to create a mapping function F(\u00b7) denoted as,\n$Y_t = F([X_{t-T+1}, ..., X_{t\u22121}, X_t])$\n(12)\nwhich aims to transform initial estimations into the accurate TSE outcome of the current traffic state."}, {"title": "IV. METHODOLOGY", "content": "In this section, we propose the CRNet model, which aims to derive accurate TSEs from initial estimations obtained by sparse IoV data by mining spatial-temporal correlations of traffic states. Firstly, the CNN and RetNet modules, which are leveraged to capture spatial and temporal correlations, respectively, are presented. Details of how to design the CRNet model are then provided.\nIn our framework, the traffic state image can be perceived as an image with H \u00d7 W resolution and four channels. The spatial correlation of traffic states is embedded into the grid-structured image. In addition, the traffic states in a specific region are easily influenced by the traffic states in neighboring regions. This influence diminishes with increasing spatial distance, which means that the spatial correlations in traffic are localized. CNN is tailored for grid-structured data such as images, and can effectively capture local features of images. Therefore, we choose CNN to capture the local spatial feature of traffic state, processing the traffic state image using learnable filters.\nFirstly, we process the traffic state images of each of four channels with CNN to capture the independent traffic spatial features of each travelling direction. The working process of the CNN layer can be described as,\n$X_n' = CNN(X_n), n = t \u2212 T + 1, ..., t \u2013 1, t$\n(13)\nwhere the CNN(\u00b7) is the convolution operation, $X_n \u2208 \\mathbb{R}^{4\u00d7H\u00d7W}$ is the initial traffic state image derived from sparse IoV data, $X_n' \u2208 \\mathbb{R}^{4\u00d7H\u00d7W}$ contains the spatial correlation captured by CNN, the subscript n indicates different time slots of traffic state images. Then, we utilize the full connected (FC) layer to construct the encoder block together with the CNN layer, lifting the data dimension of each grid to further express the features of traffic data. Meanwhile, the correlations in four different directions are exchanged. The operation of the FC layer in encoder block is denoted as,\n$X_n'' = FC_e(X_n'), n = t - T + 1, ..., t \u2212 1, t$\n(14)\nwhere the $FC_e(\u00b7)$ lifts data dimension from 4 to C for mining the deeper spatial correlations in the data, $X_n'' \u2208 \\mathbb{R}^{C\u00d7H\u00d7W}$ is the high-dimensional feature representation of $X_n'$ in latent space. Subsequently, the reshape layer is used to serialize the format of input traffic data. The sequential traffic data of each grid can be obtained as,\n$I_{h,w} = Concat(x_{h,w}^n|n = t \u2212 T + 1, ..., t \u2212 1, t)$,\n(15)\nwhere $x_{h,w}^n$ is the spatial feature representation from $X_n''$ of the grid located at (h, w), the Concat(\u00b7) is the concatenating operation, and $I_{h,w} \u2208 \\mathbb{R}^{C\u00d7T}$ is the sequence of dimension C and length T consisting of traffic spatial feature of the grid located at (h, w).\nThe temporal correlation of traffic state is in the sequential structure of processed traffic data. The RetNet is a powerful model based on self-attention mechanism, especially effective at handling sequence data. We employ the RetNet to learn the temporal correlation and use the traffic data from the previous (T \u2013 1) time slot to the current time slot t as the input to the RetNet. By integrating the functions of paral- lelism and recurrence, the RetNet is capable of working on parallel representation for training, recurrent representation for inference, and chunk-wise recurrent representation for long- sequence management. With the application of the RetNet, we are able to achieve fast training, low-cost deployment, and efficient inference, which facilitates effective modeling of temporal correlation of traffic state.\nBased on the self-attention mechanism, we aim to capture the temporal correlation within each grid of the time-series traffic state images. For each grid of traffic state image, we set $I \u2208 \\mathbb{R}^{C\u00d7T}$ as the input of the RetNet, and we construct self-attention mechanism as,\n$Q = IW_Q, K = IW_K, V = IW_V,$\n(16)\nwhere Q, K, V are all $ \\mathbb{R}^{T\u00d7E}$ matrices and are short for Query, Key, and Value in turn, T is the number of tokens, E represents the embedding size, $W_Q$, $W_K$, $W_V$ are learnable neural network weight matrices. After transforming the sequential traffic data I into Q, K, and V matrices, we are able to capture the temporal correlation by the retention mechanism of the RetNet.\nFirst, we introduce the traffic parallel retention mechanism, which can reduce the time and resources required for traffic temporal correlation modeling via improving training speed through parallel form. By making Q and K positional aware, the retention mechanism allows RetNet to consider informa- tion from all positions in the sequential data without being constrained by dependencies between positions. Meanwhile, the application of D matrix helps RetNet to weigh different time steps in a predefined way and prevent the traffic infor- mation of future time steps from being leaked. Hence, we are capable of training the model in a parallel way as,\n$Q = (IW_Q) \u2299 \u0398, K = (IW_Q) \u2299 \\overline{\u0398}, V = IW_V,$\n(17)\n$\u0398 = e^{i\u03b8}, D_{nm} = \\begin{cases} \u03b3^{n-m} & \\text{if } n \u2265 m \\\\ 0 & \\text{if } n < m \\end{cases}$\n(18)\n$Retention(I) = (Q K^T \u2299 D)V,$\n(19)\nwhere \u2299 is multiplied element-wise to each element in Q and K to make them positional aware, $\\overline{\u0398}$ is the complex conjugate of \u0398, $D \u2208 \\mathbb{R}^{T\u00d7T}$ combines causal masking and exponential decay as one matrix, $[\u00b7]^T$ is the transpose operation of matrix. Note that \u03b3 is a scalar employed to measure the weight of tokens in different positions, indicating that the further a token is in the past, the less important it is for the current time step.\nThen, we introduce the traffic recurrent retention mecha- nism, which empowers the RetNet to achieve low complexity in terms of computation and memory, so as to efficiently reduce the cost and latency of traffic temporal correlation modeling. At each time step, in addition to input sequence $I_n \u2208 \\mathbb{R}^C$, the retention mechanism also takes recurrent state $R_n$ that propagates forward information of previous time step as input, which is similar to the general framework of recurrent neural networks. For a recurrent inference process, the output of the retention mechanism is obtained as,\n$R_n = R_{n-1} + K_n^T V_n,$\n(20)\n$Retention_n(I_n) = Q_n R_n,$\n(21)\nwhere $R_n$ is the recurrent state at the n-th time step, $Q_n, K_n$, and $V_n$ are the n-th row vector of Q, K, and V in turn, \u03b3 is the same as (18), $I_n \u2208 \\mathbb{R}^C$ is the input at the n-th time step and can be viewed as the n-th item of I.\nFurthermore, in the case of input traffic data being long sequences, we employ the mode of chunkwise recurrent repre- sentation of retention for temporal correlation modeling, which is a hybrid form of parallelism and recurrence for speeding up computation and saving memory. Dividing the input sequences I into chunks of the same size, the chunk-wise recurrent representation conducts parallel operation within each chunk and recurrent operation across chunks. The retention output of the i-th chunk can be accessed as,\n$Q_{[i]} = Q_{B_i:B_{i+1}}, K_{[i]} = K_{B_i:B_{i+1}}, V_{[i]} = V_{B_i:B_{i+1}},$\n(22)\n$R_{[i]} = \u03b3^B R_{[i-1]} + K_{[i]}^T (V_{[i]} \u03b3^{B-i-1}),$\n(23)\n$Retention_{[i]}(I_{[i]}) = (Q_{[i]} K_{[i]}^T \u2299 D) V_{[i]} + (Q_{[i]} R_{[i-1]}) \u2299 \u03b3^{B+1},$\n(24)\nwhere [i] indicates the i-th chunk, B denotes the length of the chunk, Q, K, V and \u03b3 are the same as (17), R is the recurrent state which is the same as (20), $I_n \u2208 \\mathbb{R}^{C\u00d7B}$ is the input of the i-th chunk. Note that the first half of (24) is computed in parallel within each chunk and the second half is computed recurrently across the chunks.\nWith the definition and implementation of the retention mechanism, we further construct the multi-scale retention (MSR) mechanism for better performance, efficiency, and robustness in temporal correlation modeling. Through assign- ing different fixed exponential factor \u03b3 for each head, MSR is capable of understanding and handling sequential traffic data from different perspectives to capture the richness and complexity of sequence. The multi-scale functionality of the MSR mechanism can be defined as,\n$head_j = Retention(I), j = 1, 2, ..., u,$\n(25)\nwhere the Retention(\u00b7) can switch between the representation of parallel, recurrent, and chunkwise recurrent retention mech- anism according to our needs under various situations, u is the amount of retention heads, subscript j is the label number of the head and ranges from 1 to u. Note that the exponential decay factor \u03b3 is different for each head, and the expression for the \u03b3 of the j-th head is $2^{-5^{-5}}$. After generating the output of all the heads, we can then obtain the output of the MSR mechanism as,\n$N = GN(Concat(head_j|j = 1,2, ..., u)),$\n(26)\n$MSR(I) = (Swish(IW_G) \u2299 N)W_O,$\n(27)\nwhere the GN(\u00b7) is the group normalization function for normalizing the output of each head to balance the variances of multi-head outputs, Swish(\u00b7) is a gate function for increasing non-linearity of retention mechanism.\nIn the end, we stack the MSR layer and the feed forward network (FFN) layer to form the RetNet architecture. With sparse IoV data $I \u2208 \\mathbb{R}^{C\u00d7T}$ as the input, the MSR module generates M, and the FFN module outputs $O \u2208 \\mathbb{R}^{C\u00d7T}$. The output of the RetNet is obtained as,\n$M = MSR(LN(I)) + I,$\n(28)\n$O = FFN(LN(M)) + M,$\n(29)\nwhere the LN(\u00b7) is the layer normalization function for nor- malizing the output of the MSR and FFN layer, the MSR(\u00b7) aims to learn the temporal correlation of traffic state from various perspectives, the FFN(\u00b7) is utilized for enhancing model's ability to handle sequential data.\nThe outcome for TSE is decoded from the output of RetNet. The decoder block consists of an FC layer and a CNN layer to decode the spatial-temporal features into the desired output format. In the FC layer, we first combine the sequential traffic data O of each grid in the map, forming the traffic state image in the format $\\mathbb{R}^{(C\u00d7T)\u00d7H\u00d7W}$. Subsequently, we reduce the data dimension to aggregate spatial-temporal correlations previously modeled and captured. The operation of the FC layer in decoder block is executed as,\n$U = FC_d(O),$\n(30)\nwhere the $FC_d(\u00b7)$ lowers the dimension of image channel from C \u00d7 T to 4, $U \u2208 \\mathbb{R}^{4\u00d7H\u00d7W}$ can be perceived as the traffic state image which contains spatial and temporal correlations of traffic state. Then, in the CNN layer, we conduct convolutional operations in four driving directions. The output of the CNN layer in decoder block can be obtained as,\n$Z = CNN(U),$\n(31)\nwhere the CNN(\u00b7) aims at forming structural symmetry and decoding the estimation in four driving directions, $Z \u2208\\mathbb{R}^{4\u00d7H\u00d7W}$ is the final output of the entire model and can be viewed as the recovered traffic state estimation at time slot t."}, {"title": "V. EXPERIMENTS", "content": "In this section, we perform extensive simulations with real- world IoV data to validate the feasibility of the proposed TSE framework and evaluate the efficacy of the CRNet in achieving accurate TSE. Initially, we delineate the experimental setup, the benchmark methods, and the metrics employed for evalu- ation. We then analyse the experimental results in detail.\nThe experimental evaluation was conducted in the area within the fourth ring road of Beijing. The dataset comprised real IoV data collected over six days in 2012: Nov. 1, 5, 7, 9, 10, and 11. The analysis focused on the time interval from 7:30 AM to 10:30 PM for TSE, within which millions of IoV data points are amassed daily. TSE was performed at one- minute intervals, resulting in 900 estimations per day. Traffic state images are of 80 \u00d7 80 resolution. The sparsity indicated the ratio of the amount of the sparse IoV data to that of the entire IoV data, where the higher the sparsity was, the more IoV data was sampled.\nThe hyper-parameters are as```json\n\", the FC layer comprises one FC network, lifting data dimen- sions from 4 to 16. Prior to the RetNet layer, a reshape layer was implemented, performing operations of flattening and concatenating. The RetNet layer has 2 heads and the dimension of its FFN is 32. The decoder block includes three FC networks within its FC layer. The dataset from Nov. 1 is utilized for training, while the datasets from the remaining five days serve for testing. This approach is designed to assess CRNet's robustness and adaptability across a comprehensive temporal scope, including both weekdays and weekends. The model undergoes training for over 200 epochs, starting with an initial learning rate of 0.001, which experiences a 10% decay after each epoch. The experiments are facilitated by a Tesla V100-DGXS-32GB GPU.\nOur study compares CRNet against several benchmark models, including classic and state-of-the-art spatial-temporal neural networks:\n\u2022 Initial: The direct estimation from sparse IoV data.\n\u2022 HA: An arithmetical operation averages the values of historical and current Initial estimations [40].\n\u2022 CNN: A four-layer CNN designed to capture the spatial correlation of current Initial estimation [41].\n\u2022 PredRNN: An RNN architecture designed for video prediction, utilizing a hierarchical structure to capture spatial-temporal dependencies [37].\n\u2022 ConvLSTM: An integration of convolutional operation and LSTM framework, enabling it to capture both spatial dependencies and long-term temporal relationships [36].\n\u2022 E3DLSTM: A spatial-temporal model uses memory at- tentive module to capture long-term motions and 3D- convolutions to perceive short-term motions [42].\n\u2022 SimVP: A simple yet effective video prediction model that is completely built upon CNN and its variants [38].\nIn this context, the Initial refers to the unprocessed TSE, which also serves as the input for subsequent DL models. HA computes the mean of the past five minutes values of Initial estimations along the temporal dimension. CNN leverages the spatial correlation present in the traffic state image at the current time slot to perform TSE. PredRNN, ConvLSTM, E3DLSTM, and SimVP models are adept at capturing both spatial and temporal correlations within the historical and current traffic state images, utilizing the past five minutes of Initial estimations as their input.\nTo quantitatively assess the TSE performance facilitated by deep learning models, five evaluation metrics are employed. Let $y_t^{h,w}$ represents the ideal TSE and $\\hat{y}_t^{h,w}$ denotes the estimated TSE of the image grid located at coordinates (h, w) at time slot t, the metrics are expressed as:\n(1) Root mean squared error (RMSE):\n$RMSE = \\sqrt{\\frac{1}{T\u00d7H\u00d7W} \\sum_{t=1}^T\\sum_{h=1}^H\\sum_{w=1}^W |y_t^{h,w} \u2013 \\hat{y}_t^{h,w}|^2}.$\n(32)\nRMSE quantifies the deviation of recovered values from the ground truth. A value of 0 is optimal, with lower values indicating better performance.\n(2) Improved percentage (IPV):\n$IPV = (1 - \\frac{\\frac{1}{THW} \\sum_{t=1}^T\\sum_{h=1}^H\\sum_{w=1}^W|y_t^{h,w} \u2013 \\hat{y}_t^{h,w}|^2}{\\frac{1}{THW} \\sum_{t=1}^T\\sum_{h=1}^H\\sum_{w=1}^W|y_t^{h,w} \u2013 x_t^{h,w}|^2}) \u00d7 100%.$\n(33)\nIPV represents the percentage reduction between the RMSE of the Initial and that of the recovered data, with values ranging from 0 to 100% and higher values indicating superior performance.\n(3) Mean absolute error (MAE):\n$MAE = \\frac{1}{T H W} \\sum_{t=1}^T\\sum_{h=1}^H\\sum_{w=1}^W |y_t^{h,w} - \\hat{y}_t^{h,w}|.$\n(34)\nMAE averages the absolute differences between estimated and actual values. An MAE of 0 is ideal, with lower values denoting higher accuracy.\n(4) Structural similarity index measure (SSIM):\n$SSIM = \\frac{(2\u03bc_a\u03bc_b + C_1)\u00b7 (2\u03c3_{ab} + C_2)}{(\u03bc_a^2 + \u03bc_b^2 + C_1) \u00b7 (\u03c3_a^2 + \u03c3_b^2 + C_2)},$\n(35)\nwhere $\u03bc_a$ and $\u03bc_b$ are the means of the ideal and estimated TSEs respectively, and $\u03c3_a^2$, $\u03c3_b^2$, and $\u03c3_{ab}$ represent the variances and covariance of these distributions. SSIM evaluates image similarity, considering luminance, contrast, and structure, with values spanning from 0 to 1 and higher values preferred.\n(5) Peak signal-to-noise ratio (PSNR):\n$PSNR = 10 \\lg(\\frac{(2^B-1)^2}{\\frac{1}{HxW}\\sum_{h=1}^H\\sum_{w=1}^W |y_t^{h,w} - \\hat{y}_t^{h,w}|^2}).$\n(36)\nPSNR measures the ratio of the maximum possible signal power to the power of corrupting noise, assessing the quality of reconstructed or compressed images. Measured in dB, higher PSNR values indicate better quality.\nIn order to illustrate the feasibility of the sparse IoV data enabled TSE framework and the effectiveness of the CRNet model, we conduct a comprehensive experiment including analyzing the influence of data sparsification, observing the improvement of the recovered estimation of CRNet compared to the Initial, and evaluating the performance of CRNet with the other data recovery methods.\n1) Overall Performance: Fig. 6 shows the impact of data sparsification on TSE accuracy. The box plots show the distribution of the mean error for each grid in the map over the day for different levels of data sparsity. As the data becomes sparser, the median, range, and dispersion of the error values increase. As sparsity increases from 5% to 90%, RMSE decreases from 15.66 km/h to 2.71 km/h, and MAE decreases from 7.50 km/h to 0.48 km/h. The values and variations of the RMSE consistently exceed the MAE, suggesting that the sparser the data, the more abnormal errors tend to be generated, which negatively affects the accuracy of the TSE.\nTable II presents the comparative analysis of CRNet with other DL models for TSE recovery. Model performance is evaluated by five different metrics at six levels of data sparsity ranging from 5% to 50%. Each row in the table relates to model performance at a fixed sparsity, while the columns reflect the performance of a single model at different sparsities. Compared to the other models, CRNet's data recovery capa- bilities is superior. Regardless of sparsity, CRNet consistently attains the lowest RMSE and MAE, alongside the highest SSIM and PSNR. These results indicate that the traffic state images reconstructed by CRNet have the least error. Moreover, as the sparsity increases from 5% to 50%, CRNet's RMSE decreases from 8.779 km/h to 4.430 km/h, and the MAE diminishes from 4.847 km/h to 1.821 km/h. The error of CRNet is around 5 km/h, which is acceptable in practical applications. Hence, CRNet validates the practicality and cost- effectiveness of employing sparse IoV data for precise TSE, enabling ITS to obtain satisfactory estimation results with significantly reduced data.\n2) Temporal performance: Fig. 7 and Fig. 8 show CRNet's MAE per minute of TSE compared to the Initial estimation, spanning five days from 7:30 to 22:30, with sparsities of 5% and 30%, respectively. These figures are plotted in polar coordinates, with the X-axis representing time in minutes and the Y-axis representing MAE in km/h. In each polar plot, the orange area represents the MAE for Initial and the green area represents the MAE for CRNet. These simulations show the excellent stability of CRNet performance. The Initial estimated MAE values are quite high and show a lot of temporal variability, as evidenced by the irregular orange contours. In contrast, CRNet's MAE values show limited temporal variability, with smoother contours in the green region, suggesting that TSE accuracy improves throughout the day. CRNet is able to improve TSE accuracy at any time of the day with stable performance. In addition, CRNet shows good adaptability. Although there is a significant difference in traffic shapes between weekdays and weekends as seen in the raw results, CRNet consistently maintains similar MAE sizes and trends. For different sparsities from 5% to 30%, the improvement of CRNet over the Initial is considerable, and its MAE level is always kept low.\n3) Spatial performance: Fig. 9 shows the traffic states in Beijing at 1pm on Monday from sparse IoV data with 5% sparsity. Fig. 10 shows the average estimation error over a 900- minute span for each grid in Monday's dataset. Furthermore, Fig. 11 also shows the Cumulative Distribution Function (CDF) curve of the average error over the same 900-minute span on Monday, which helps to analyse the performance of CRNet in comparison with other DL models.\nFig. 9 shows that the sparsification of the IoV data leads to a quite high rate of missing information and reduces the accuracy of the TSE. Fig. 9a shows the ideal estimate obtained using the full IoV data, which clearly shows the contours of the road. Fig. 9b shows the Initial estimation based on the 5% sparsity data, which has a large number of misses as can be seen from the large number of grids shown by the solid blue line. In addition, the comparison between the Initial and Ideal estimation shows a clear difference, with the former appearing more incomplete and ambiguous. As a comparison, Fig. 9c shows the estimation recovered by CRNet, which is very similar to the Ideal estimation in terms of structural details and brightness, suggesting that CRNet is able to effectively address the shortcomings brought about by sparse IoV data.\nFig. 10 further shows the accuracy improvement brought by CRNet in a single day in the spatial dimension. The average errors of Initial estimation are shown in Fig. 10a, where most of the grids are orange and red, indicating an error of more than 20 km/h. In contrast, the average errors after CRNet recovery are shown in Fig. 10b, where a majority of grids are in yellow and green, indicating that most of the area has an error below 15 km/h. Fig. 10c shows the average error reduction achieved by CRNet, highlighting the fact that CRNet significantly reduces the average error, with some regions experiencing reductions of more than 50 km/h.\nFig. 11 shows that CRNet performs well in achieving higher TSE accuracy compared to the other models, as shown by the CDF curves. CNN performs the worst, and E3DLSTM is not as good. ConvLSTM performs very close to CRNet. The enlarged inset highlights that the CRNet counterpart is consistently higher than the other curves, suggesting higher accuracy. This analysis demonstrates CRNet's superior ability to achieve low errors, marking it as a suitable model for TSE.\""}, {"title": "VI. CONCLUSION", "content": "We have introduced a cost-effective TSE framework using sparse IoV data. We have analysed the impact of IoV data sparsification on TSE accuracy and addressed these challenges by developing a CRNet model. The developed model exploits the spatial and temporal correlations present in traffic states to improve estimation accuracy. For the future work, we will investigate diffusion models for TSE with sparse IoV data."}]}