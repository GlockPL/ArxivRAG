[{"title": "Spatial-Temporal Attention Model for Traffic State Estimation with Sparse Internet of Vehicles", "authors": ["Jianzhe Xue", "Dongcheng Yuan", "Yu Sun", "Tianqi Zhang", "Wenchao Xu", "Haibo Zhou", "Xuemin (Sherman) Shen"], "abstract": "The growing number of connected vehicles offers an opportunity to leverage internet of vehicles (IoV) data for traffic state estimation (TSE) which plays a crucial role in intelligent transportation systems (ITS). By utilizing only a portion of IoV data instead of the entire dataset, the significant overheads associated with collecting and processing large amounts of data can be avoided. In this paper, we introduce a novel framework that utilizes sparse IoV data to achieve cost-effective TSE. Particularly, we propose a novel spatial-temporal attention model called the convolutional retentive network (CRNet) to improve the TSE accuracy by mining spatial-temporal traffic state correlations. The model employs the convolutional neural network (CNN) for spatial correlation aggregation and the retentive network (RetNet) based on the attention mechanism to extract temporal correlations. Extensive simulations on a real-world IoV dataset validate the advantage of the proposed TSE approach in achieving accurate TSE using sparse IoV data, demonstrating its cost effectiveness and practicality for real-world applications.", "sections": [{"title": "I. INTRODUCTION", "content": "Traffic state estimation (TSE) serves as a cornerstone for intelligent transportation systems (ITS), underpinning appli-cations such as traffic management, congestion tracking, and road planning through the provision of live, precise traffic state information [1], [2]. Historically, TSE has depended on roadside sensors and cameras to collect data about vehicle speeds and flows across specific areas. Despite their utility, these traditional methods are limited in coverage and costly, and do not meet the rapidly evolving needs of ITS [3]. To this end, the internet of vehicles (IoV) paradigm has emerged as a data-driven solution, capitalizing on vehicle-contributed data to bypass the limitations of traditional traffic sensing methods [4]. The integration of vehicular networks has transformed numerous vehicles into nodes of a vast, interconnected data-sharing network, thereby enabling the provision of extensive real-time data for ITS applications across the entire road network [5], [6], [7], [8]. This approach, utilizing data like vehicle speeds and GPS coordinates, offers a framework for TSE that not only achieves broader coverage but also is more cost-efficient compared to previous methods. Thus, IoV-based TSE represents a significant leap forward, offering comprehensive traffic state insights with enhanced coverage and cost benefits.\nThe requisite for substantial volumes of high-quality IoV data for effective TSE presents notable challenges, primarily due to the overheads associated with its collection [9], [10]. The endeavor to amass extensive IoV data in real-time brings considerable strain on both the collection mechanisms and the communication networks, making the task particularly arduous. In contrast, the acquisition of sparse IoV data from a limited number of connected vehicles emerges as a more fea-sible and cost-effective solution in real-world scenarios [11], [12], [13]. The endeavor to accurately estimate traffic states from sparse IoV data holds substantial importance and offers discernible benefits. Complete data collection in a targeted area often proves unattainable due to obstacles such as transmission loss and user reluctance to share information, driven by the limitations of network resources or privacy concerns. This reality necessitates the acceptance of incomplete datasets [14], [15], [16]. Furthermore, the strategy of collecting sparse IoV data presents a more economical alternative. By minimizing the volume of data required, this approach serves to reduce the burden on network transmissions and storage. Therefore, the TSE framework that only utilizes sparse IoV data is needed, where the sparse IoV data is collected from a small number of connected vehicles distributed throughout the city.\nA major issue of using sparse IoV data is the reduced stability and accuracy of TSE results compared to the results derived from a larger dataset [17]. Nevertheless, the inher-ent characteristics of transport systems offset this limitation through the redundancy of information in the IoV data, en-abling TSE to be achieved using sparse IoV data. At the micro-level, the dynamics of individual vehicle movements adhere to established car-following models, wherein the velocity of one vehicle closely mirrors that of nearby vehicles. Consequently, the velocity of a single vehicle can, to a certain degree, act as a representative indicator of the speeds of an adjacent vehicle cluster. At the macro-level, the traffic state of urban transport exhibits spatial and temporal correlations [18]. Roads in the vicinity of congested areas may also become congested themselves, and traffic congestion shapes evolve in a gradual manner over time [19]. Thus, by leveraging spatial-temporal correlations inherent in the urban traffic dynamics, it becomes viable to conduct accurate TSE using sparse IoV data.\nCapturing spatial-temporal correlations in traffic states poses significant challenges, particularly for deriving accurate esti-mations from sparse IoV data [20], [21], [22], [23]. Tempo-rally, estimations that are directly derived from such sparse IoV data frequently manifest instability and a high degree of noise. Spatially, the inherent sparsity of IoV data results in a dispersed distribution of vehicular data points within the target region, consequently attenuating the strength of spatial correlations among the available vehicles. Additionally, due to the diversity and complexity of the road system, the spatial and temporal correlations of traffic states are varied and dynamic, thus complicating the accurate capture of these correlations [24]. Given these complexities, the application of deep learning (DL) approaches, renowned for their robust modeling capabilities, emerges as a promising approach for TSE with sparse IoV data by effectively capturing the spatial-temporal correlations [25].\nIn this work, we present an innovative framework for cost-effective TSE using sparse IoV data, and also design a spatial-temporal attention model for recovering accurate TSE from initial estimations obtained from sparse IoV data. To collect the sparse IoV data, we employ a strategy of randomly selecting a limited subset of connected vehicles, distributed uniformly across the entire urban area, identified as probe vehicles. Then, we define the traffic state as the average speed of each grid area in four driving directions over a defined period. It is observed that the sparsification of IoV data can lead to a decrease in TSE accuracy. To address this issue, we propose a novel DL model, the convolutional retentive network (CRNet), to offset the effects of data sparsification and achieve accurate real-time TSE by effectively capturing spatial-temporal correlations inherent in urban traffic states. For spatial correlation, the model employs the convolutional neural network (CNN) to learn local spatial features. For temporal correlation, the retentive network (RetNet) which is a network architecture based on attention is utilized to extract the temporal shapes within the traffic state. Our comprehensive simulations, conducted on a real-world IoV dataset, validate the feasibility of utilizing sparse IoV data processed by CRNet for TSE, achieving accurate estimations at a relatively low cost and outperforming existing methods. The contributions of this paper are as follows:\n\u2022 We present a cost-effective TSE framework using sparse IoV data that provides accurate TSE using only a small subset of IoV data, which is obtained by uniformly reducing the amount of IoV data across all urban regions.\n\u2022 We find that sparsification of IoV data introduces inaccu-racies to the average vehicle speed in each urban region, and the distribution of initial estimation errors approxi-mately follows a Gaussian distribution. We conceptualise the TSE problem based on sparse IoV data as similar to the sequential image data denoising problem.\n\u2022 We propose a novel spatial-temporal attention model to provide accurate TSE outcomes from sparse IoV data. CRNet fully exploits the synergy of mining both spatial and temporal traffic state correlations to ensure robust and accurate performance.\nThe remainder of this paper is organized as follows. Section II provides a review of TSE and related DL approaches. Section III defines the TSE problem by data analysis. Section IV presents the model structure of the CRNet. Section V gives extensive experimental results to evaluate the effectiveness and superior performance of the proposed TSE method. Section VI concludes the paper."}, {"title": "II. RELATED WORK", "content": "The task of TSE is paramount for ITS. The advent of connected vehicles has ushered in a new era of IoV data, which encompasses extensive vehicular driving information, such as GPS coordinates and driving speeds across the traffic network [26], [27]. These rich IoV data provide the possi-bility to perform accurate TSE. Nonetheless, the granularity of vehicular data is frequently coarse, attributed to the dis-parate temporal and spatial distribution of vehicles, coupled with suboptimal data acquisition practices, culminating in less than accurate TSE outcomes. To enhance TSE accuracy, numerous studies have focused on the imputation of missing traffic data, which are either passively or actively missing. A data completion approach based on the tensor decomposition method is proposed to recover missing values in inter-regional traffic data by dividing the target area into regions [28]. A Laplacian-enhanced low-rank tensor completion framework is constructed for large-scale traffic kriging interpolation to recover reliable estimates from incomplete traffic data and achieve good performance under low observation rates [29]. Meanwhile, there has been growing emphasis on the develop-ment of DL methods for traffic data imputation in recent years [30], [31].\nMost of the existing work assumes that traffic data is incomplete for certain areas and mainly concentrates on fixing the missing data, based on the assumption that the available data is perfect. The sparsification of IoV data for the entire region may lead to the inapplicability of these methods in cases where the available data is no longer perfect, due to insufficient raw data for estimating the state of each region. This means that further studies are needed for accurate TSE with the sparse IoV data."}, {"title": "B. Deep Learning for Traffic Correlations", "content": "Traffic data inherently manifests spatial and temporal cor-relations. The advent and proliferation of DL paradigms have enabled deep neural networks to adeptly learn and extract these correlations. In the domain of spatial feature extraction, the CNN is a classic and effective model, aptly suited for processing gridded image data. Conversely, the temporal corre-lation has to be extracted from sequential structured data. Long short-term memory (LSTM) network is a recurrent neural network (RNN) used for sequential data processing, aimed to deal with the vanishing gradient problem present in traditional RNNs [32]. Another architecture known as transformer uses self-attention to handle sequential data, replacing RNNs in many applications [33]. Transformer and its variants have been used with considerable success in tasks of traffic data mining [34]. Recently, a powerful model named the retentive network (RetNet) has been viewed as the strong successor to the transformer. RetNet proposes the retention mechanism by combining the core concepts of recurrence and attention, which can simultaneously achieve training parallelism, low-cost inference, and good performance [35]. It is persuasive that RetNet can capture temporal correlations in traffic data accurately and efficiently.\nMoreover, certain DL models are adept at concurrently capturing the spatial and temporal correlations present in input data. The convolutional LSTM network (ConvLSTM) extends the LSTM with convolutional layers in the input-to-state and state-to-state transitions, enabling itself to capture spatial dependencies and long-term temporal relationships, particularly suited for sequential grid data [36]. The PredRNN developed from RNN is used for spatial-temporal predictive learning by modeling the short-term deformations in spatial appearance and the long-term dynamics over multiple frames simultaneously [37]. The SimVP is a relatively simple video prediction model consisting of an encoder, a translator, and a decoder which are completely built on CNN [38]. In SimVP, the encoder extracts spatial features, the translator learns temporal evolution by employing inception modules, and the decoder integrates spatial-temporal features.\nAlthough existing methods can effectively capture spatial and temporal correlations of traffic states, their capacity to adeptly manage the distinct properties of sparse IoV data is not assured. It is essential to develop novel solutions that enhance TSE accuracy by leveraging the unique features of sparse IoV data, and that address the instability and inaccuracy issues introduced by data sparsification."}, {"title": "III. FRAMEWORK AND PROBLEM ANALYSIS", "content": "This section includes four parts. First, the TSE framework using sparse IoV data is delineated. Second, the traffic state image obtained from IoV data is introduced. Third, an analysis of the estimation errors arising from sparse IoV data is conducted. Fourth, the problem of recovering vehicle speeds from sparse IoV data is formulated. For convenience, the major notations in this paper are shown in Table I."}, {"title": "A. Sparse IoV Data Enabled TSE Framework", "content": "The cost-effective TSE framework using sparse IoV data is shown in Fig. 1. The city map is divided into grids, each of which represents a small area of the city and has four different traffic flow speeds that indicate the average speed through the area from different directions. The sparse IoV data containing vehicle mobility information is gathered through vehicular networks. Instead of removing data from some specific regions to reduce the data amount, we acquire the sparse IoV data by randomly selecting a small fraction of vehicles as data sources uniformly distributed across the city. The recruitment probability of each vehicle is equal, and the chosen ones are sparse probe vehicles.\nFollowing the data collection, we divide the traffic data into four categories, corresponding to four different vehicle driving directions. The initial estimations are acquired by computing average speeds of probe vehicles in each grid of the map to construct the traffic state images in four directions, which can be merged together to form the overall traffic states of the city. Then, the recovery algorithm is applied to reach precise TSE based on the initial estimations from sparse IoV data."}, {"title": "B. Traffic State Image", "content": "In this study, we construct the traffic state image, with a resolution of \\(H \\times W\\) and four channels, as the visual representation of the traffic state. First, the city map is evenly divided into grids, similar to pixels in an image, and each grid has multiple speeds of different directions, similar to the color channels in a pixel. Specifically, for an \\(H \\times W\\) gridded city map, we construct four sub-maps based on four driving directions and merged four maps to get a complete city map,\n\\[\\mathbb{G}_{c}=\\left[\\begin{array}{cccc}\\mathbb{G}_{1,1}^{c} & \\cdots & \\mathbb{G}_{1, w}^{c} & \\cdots & \\mathbb{G}_{1, W}^{c} \\\\\\vdots & & & & \\\\\\mathbb{G}_{h, 1}^{c} & & \\mathbb{G}_{h, w}^{c} & & \\mathbb{G}_{h, W}^{c} \\\\\\vdots & & & & \\\\\\mathbb{G}_{H, 1}^{c} & \\cdots & \\mathbb{G}_{H, w}^{c} & \\cdots & \\mathbb{G}_{H, W}^{c}\\end{array}\\right],\\]\n\\[\\mathbb{G}=\\text { Concat }\\left(\\mathbb{G}_{c} \\mid c=\\{1,2,3,4\\}\\right),\\]\nwhere \\(\\mathbb{G}_{h, w}^{c}\\) represents the grid of the city map that is located at \\((h, w)\\) and related to driving direction \\(c, \\mathbb{G}_{c}\\) is the gridded sub-map corresponding to driving direction \\(c, \\mathbb{G}\\) is the complete city map composed of four sub-maps.\nFor each grid, the average vehicle speeds in different direc-tions are calculated to represent its traffic states. For estimating the ideal traffic state at time slot \\(t\\), we obtain the entire IoV data \\(\\mathcal{J}_{t}\\) which includes all vehicle driving information. Then, we match the gridded city map \\(\\mathbb{G}\\) with \\(\\mathcal{J}_{t}\\) to construct the grid-structured dataset as,\n\\[\\mathbb{F}_{t}=\\left[\\begin{array}{ccccc}\\mathbb{F}_{1,1}^{t} & \\cdots & \\mathbb{F}_{1, w}^{t} & \\cdots & \\mathbb{F}_{1, W}^{t} \\\\\\vdots & & & & \\\\\\mathbb{F}_{h, 1}^{t} & & \\mathbb{F}_{h, w}^{t} & & \\mathbb{F}_{h, W}^{t} \\\\\\vdots & & & & \\\\\\mathbb{F}_{H, 1}^{t} & \\cdots & \\mathbb{F}_{H, w}^{t} & \\cdots & \\mathbb{F}_{H, W}^{t}\\end{array}\\right],\\]\nwhere \\(\\mathbb{F}_{h, w}^{t}=\\{v_{h, w} \\mid v_{h, w} \\in \\mathcal{J}_{t}\\}\\) is composed of all vehicle speeds matched to the grid located at \\((h, w)\\) at time slot \\(t\\). The driving information of each vehicle is denoted as \\(v_{h, w}\\), where \\((h, w)\\) indicates that the GPS coordinates of the vehicle lie within the grid located at \\((h, w)\\), and the absolute value of \\(v_{h, w}\\) is the speed. For a more nuanced and precise description of traffic states, we further describe \\(v_{h, w}\\) as \\(v_{h, w}^{c}\\), where \\(c\\) denotes the driving direction of \\(v_{h, w}\\). Subsequently, the ideal estimation of the traffic state in direction \\(c\\) for each grid is calculated as,"}, {"title": "C. Estimation Error Analysis", "content": "Traffic states can be derived through a similar process when sparse IoV data is utilized instead of the entire data. However, we discover that while the average speed obtained from sparse IoV data is close to the average speed obtained from the entire data, it exhibits noise and instability. Through theoretical analysis based on central limited theory (CLT) and experimental observations, we find that the error distribution for each time slot is similar to a Gaussian distribution.\nThe process of deriving initial traffic state images with sparse IoV data is described as below. The sparse IoV data collected at time slot \\(t\\) is denoted as \\(\\mathcal{J}_{t}^{\\prime}\\), which is considered as the subset obtained by randomly sampling from the entire IoV data \\(\\mathcal{J}_{t}\\). This sampling method assigns an equal selection probability to each vehicle driving information. Then, with a similar data organization process, the sparse vehicle driving information gathered over a duration of time length \\(T\\) between the past and the present are organized as,\n\\[\\mathbb{S}_{t}=\\left[\\begin{array}{ccccc}\\mathbb{S}_{1,1}^{t} & \\cdots & \\mathbb{S}_{1, w}^{t} & \\cdots & \\mathbb{S}_{1, W}^{t} \\\\\\vdots & & & & \\\\\\mathbb{S}_{h, 1}^{t} & & \\mathbb{S}_{h, w}^{t} & & \\mathbb{S}_{h, W}^{t} \\\\\\vdots & & & & \\\\\\mathbb{S}_{H, 1}^{t} & \\cdots & \\mathbb{S}_{H, w}^{t} & \\cdots & \\mathbb{S}_{H, W}^{t}\\end{array}\\right],\\]\nwhere \\(\\mathbb{S}_{h, w}^{t}=\\{v_{h, w} \\mid v_{h, w} \\in \\mathcal{J}_{t}^{\\prime}\\}\\) comprises the sparse driving information of probe vehicles which are matched to grid located at \\((h, w)\\). Here the sparse IoV data can be seen as a subset of the entire data, i.e., \\(\\mathcal{J}_{t}^{\\prime} \\subseteq \\mathcal{J}_{t}, \\mathbb{S}_{h, w}^{t} \\subset \\mathbb{F}_{h, w}^{t}\\). Likewise, in the case of using sparse IoV data, the initial traffic state estimation at time slot \\(t\\) is obtained as,\n\\[\\mathbb{X}_{t}=\\left[\\begin{array}{ccccc}\\mathbb{X}_{1,1}^{t} & \\cdots & \\mathbb{X}_{1, w}^{t} & \\cdots & \\mathbb{X}_{1, W}^{t} \\\\\\vdots & & & & \\\\\\mathbb{X}_{h, 1}^{t} & & \\mathbb{X}_{h, w}^{t} & & \\mathbb{X}_{h, W}^{t} \\\\\\vdots & & & & \\\\\\mathbb{X}_{H, 1}^{t} & \\cdots & \\mathbb{X}_{H, w}^{t} & \\cdots & \\mathbb{X}_{H, W}^{t}\\end{array}\\right],\\]"}, {"title": "D. Traffic State Estimation Problem Formulation", "content": "The initial average vehicle speed derived from the sparse IoV data constitutes the initial traffic state image, but it is inaccurate compared to the ideal estimate derived from the complete data, and therefore it cannot be used as the final estimation. Based on the above analysis and definitions, the task of real-time TSE using sparse IoV data is conceptu-alised as the problem of recovering grid-structured traffic state image by exploiting spatial and temporal correlations in time-series traffic state images. In specific, the inputs of the TSE recovery algorithm are historical and current initial traffic state images obtained from sparse IoV data, denoted as \\([\\mathbb{X}_{t-T+1}, \\ldots, \\mathbb{X}_{t-1}, \\mathbb{X}_{t}]\\). The goal of the algorithm is to generate an accurate traffic state image of the current time slot \\(\\mathbb{Y}_{t}\\) that is as similar as possible to the ideal estimation derived from the entire data. To achieve accurate TSE performance, it is necessary to make full use of the spatial-temporal correlation in the recent initial traffic estimations in order to reduce the impact of Gaussian noise and data loss on the accuracy caused by data sparsification, which is the difficulty of the algorithm design for this problem. Thus, the essence of the TSE recovery problem is to create a mapping function \\(\\mathcal{F}(\\cdot)\\) denoted as,\n\\[\\mathbb{Y}_{t}=\\mathcal{F}\\left(\\left[\\mathbb{X}_{t-T+1}, \\ldots, \\mathbb{X}_{t-1}, \\mathbb{X}_{t}\\right]\\right),\\]\nwhich aims to transform initial estimations into the accurate TSE outcome of the current traffic state."}, {"title": "IV. METHODOLOGY", "content": "In this section, we propose the CRNet model, which aims to derive accurate TSEs from initial estimations obtained by sparse IoV data by mining spatial-temporal correlations of traffic states. Firstly, the CNN and RetNet modules, which are leveraged to capture spatial and temporal correlations, respectively, are presented. Details of how to design the CRNet model are then provided."}, {"title": "A. Spatial Correlation Modeling", "content": "In our framework, the traffic state image can be perceived as an image with \\(H \\times W\\) resolution and four channels. The spatial correlation of traffic states is embedded into the grid-structured image. In addition, the traffic states in a specific region are easily influenced by the traffic states in neighboring regions. This influence diminishes with increasing spatial distance, which means that the spatial correlations in traffic are localized. CNN is tailored for grid-structured data such as images, and can effectively capture local features of images. Therefore, we choose CNN to capture the local spatial feature of traffic state, processing the traffic state image using learnable filters.\nFirstly, we process the traffic state images of each of four channels with CNN to capture the independent traffic spatial features of each travelling direction. The working process of the CNN layer can be described as,\n\\[\\mathbb{X}_{t}^{\\prime}=\\mathrm{CNN}\\left(\\mathbb{X}_{t}\\right), n=t-T+1, \\ldots, t-1, t\\]\nwhere the \\(\\mathrm{CNN}(\\cdot)\\) is the convolution operation, \\(\\mathbb{X}_{n} \\in \\mathbb{R}^{4 \\times H \\times W}\\)is the initial traffic state image derived from sparse IoV data, \\(\\mathbb{X}_{n}^{\\prime} \\in \\mathbb{R}^{4 \\times H \\times W}\\) contains the spatial correlation captured by CNN, the subscript \\(n\\) indicates different time slots of traffic state images. Then, we utilize the full connected (FC) layer to construct the encoder block together with the CNN layer, lifting the data dimension of each grid to further express the features of traffic data. Meanwhile, the correlations in four different directions are exchanged. The operation of the FC layer in encoder block is denoted as,\n\\[\\mathbb{X}_{n}^{\\prime \\prime}=\\mathrm{FC}_{e}\\left(\\mathbb{X}_{n}^{\\prime}\\right), n=t-T+1, \\ldots, t-1, t\\]\nwhere the \\(\\mathrm{FC}_{e}(\\cdot)\\) lifts data dimension from 4 to \\(C\\) for mining the deeper spatial correlations in the data, \\(\\mathbb{X}_{n}^{\\prime \\prime} \\in \\mathbb{R}^{C \\times H \\times W}\\) is the high-dimensional feature representation of \\(\\mathbb{X}_{n}^{\\prime}\\) in latent space. Subsequently, the reshape layer is used to serialize the format of input traffic data. The sequential traffic data of each grid can be obtained as,\n\\[\\mathbb{I}_{h, w}=\\text { Concat }\\left(\\mathbb{X}_{n, h, w}^{\\prime \\prime} \\mid n=t-T+1, \\ldots, t-1, t\\right),\\]\nwhere \\(\\mathbb{X}_{n, h, w}^{\\prime \\prime}\\) is the spatial feature representation from \\(\\mathbb{X}_{n}^{\\prime \\prime}\\) of the grid located at \\((h, w)\\), the \\(\\text { Concat }(\\cdot)\\) is the concatenating operation, and \\(\\mathbb{I}_{h, w} \\in \\mathbb{R}^{C \\times T}\\) is the sequence of dimension \\(C\\) and length \\(T\\) consisting of traffic spatial feature of the grid located at \\((h, w)\\)."}, {"title": "B. Temporal Correlation Modeling", "content": "The temporal correlation of traffic state is in the sequential structure of processed traffic data. The RetNet is a powerful model based on self-attention mechanism, especially effective at handling sequence data. We employ the RetNet to learn the temporal correlation and use the traffic data from the previous \\((T-1)\\) time slot to the current time slot \\(t\\) as the input to the RetNet. By integrating the functions of paral-lelism and recurrence, the RetNet is capable of working on parallel representation for training, recurrent representation for inference, and chunk-wise recurrent representation for long-sequence management. With the application of the RetNet, we are able to achieve fast training, low-cost deployment, and efficient inference, which facilitates effective modeling of temporal correlation of traffic state.\nBased on the self-attention mechanism, we aim to capture the temporal correlation within each grid of the time-series traffic state images. For each grid of traffic state image, we set \\(\\mathbb{I} \\in \\mathbb{R}^{C \\times T}\\) as the input of the RetNet, and we construct self-attention mechanism as,\n\\[\\begin{aligned}\\mathbb{Q} &=\\mathbb{I} \\mathbb{W}_{Q}, \\\\\\mathbb{K} &=\\mathbb{I} \\mathbb{W}_{K}, \\\\\\mathbb{V} &=\\mathbb{I} \\mathbb{W}_{V},\\end{aligned}\\]\nwhere \\(\\mathbb{Q}, \\mathbb{K}, \\mathbb{V}\\) are all \\(\\mathbb{R}^{T \\times E}\\) matrices and are short for Query, Key, and Value in turn, \\(T\\) is the number of tokens, \\(E\\) represents the embedding size, \\(\\mathbb{W}_{Q}, \\mathbb{W}_{K}, \\mathbb{W}_{V}\\) are learnable neural network weight matrices. After transforming the sequential traffic data \\(\\mathbb{I}\\) into \\(\\mathbb{Q}, \\mathbb{K}\\), and \\(\\mathbb{V}\\) matrices, we are able to capture the temporal correlation by the retention mechanism of the RetNet."}, {"title": "C. Outcome Decoding", "content": "The outcome for TSE is decoded from the output of RetNet. The decoder block consists of an FC layer and a CNN layer to decode the spatial-temporal features into the desired output format. In the FC layer, we first combine the sequential traffic data \\(\\mathbb{O}\\) of each grid in the map, forming the traffic state image in the format \\(\\mathbb{R}^{(C \\times T) \\times H \\times W}\\). Subsequently, we reduce the data dimension to aggregate spatial-temporal correlations previously modeled and captured. The operation of the FC layer in decoder block is executed as,\n\\[\\mathbb{U}=\\mathrm{FC}_{d}(\\mathbb{O}),\\]\nwhere the \\(\\mathrm{FC}_{d}(\\cdot)\\) lowers the dimension of image channel from \\(C \\times T\\) to 4, \\(\\mathbb{U} \\in \\mathbb{R}^{4 \\times H \\times W}\\) can be perceived as the traffic state image which contains spatial and temporal correlations of traffic state. Then, in the CNN layer, we conduct convolutional operations in four driving directions. The output of the CNN layer in decoder block can be obtained as,\n\\[\\mathbb{Z}=\\mathrm{CNN}(\\mathbb{U}),\\]\nwhere the \\(\\mathrm{CNN}(\\cdot)\\) aims at forming structural symmetry and decoding the estimation in four driving directions, \\(\\mathbb{Z} \\in \\mathbb{R}^{4 \\times H \\times W}\\) is the final output of the entire model and can be viewed as the recovered traffic state estimation at time slot \\(t\\)."}, {"title": "D. CRNet Model", "content": "The architecture of the CRNet model is shown in Fig. 5. There are three blocks in the CRNet: the encoder block, the RetNet block, and the decoder block. The encoder block consists of one CNN layer and one FC layer, aggregating the spatial correlation in four directions. For the RetNet block, we first use a reshape layer to change the shape of input data, obtaining the sequential data of each grid. Then, the RetNet layer is used for capturing the temporal correlation. The decoder block consists of one FC layer and one CNN layer, integrating the captured spatial-temporal features and decoding the final outcomes for TSE.\nAlgorithm 1 outlines the forward propagation process of the well-trained CRNet. The CRNet takes in a sequence of the traffic state images as its input. For the encoder block, given that vehicles traveling in different directions have different correlations, four CNNs with identical parameters are em-ployed to independently perform the convolutional operation in each channel of the traffic state image, extracting the spatial correlation for four distinct driving directions. We follow the CNN layer with an FC layer, integrating the spatial correlation of four directions and lifting the channel dimension of input data to get more detailed information. For the RetNet block, we first flatten and concatenate the processed traffic state images into \\(H \\times W\\) sequences of length \\(T\\), where each element of the sequence is the traffic data from the past to the present within a certain grid. In other words, the reshape layer aims to change the shape of input data so that RetNet can process it well. Then, all the elements of the sequence are fed into the RetNet layer in parallel to capture the temporal correlation for each image grid at the same time. For the encoder block, the role of its FC layer is to transform the processed sequential traffic data into grid-structured image format and aggregate"}, {"title": "V. EXPERIMENTS", "content": "In this section, we perform extensive simulations with real-world IoV data to validate the feasibility of the proposed TSE framework and evaluate the efficacy of the CRNet in achieving accurate TSE. Initially, we delineate the experimental setup, the benchmark methods, and the metrics employed for evalu-ation. We then analyse the experimental results in detail."}, {"title": "A. Experimental Setup", "content": "The experimental evaluation was conducted in the area within the fourth ring road of Beijing. The dataset comprised real IoV data collected over six days in 2012: Nov. 1, 5, 7, 9, 10, and 11. The analysis focused on the time interval from 7:30 AM to 10:30 PM for TSE, within which millions of IoV data points are amassed daily. TSE was performed at one-minute intervals, resulting in 900 estimations per day. Traffic state images are of 80 \u00d7 80 resolution. The sparsity indicated the ratio of the amount of the sparse IoV data to that of the entire IoV data, where the higher the sparsity was, the more IoV data was sampled.\nThe hyper-parameters are as follows. For the encoder block, the FC layer comprises one FC network, lifting data dimen-sions from 4 to 16. Prior to the RetNet layer, a reshape layer was implemented, performing operations of flattening and concatenating. The RetNet layer has 2 heads and the dimension of its FFN is 32. The decoder block includes three FC networks within its FC layer. The dataset from Nov. 1 is utilized for training, while the datasets from the remaining five days serve for testing. This approach is designed to assess CRNet's robustness and adaptability across a comprehensive temporal scope, including both weekdays and weekends. The model undergoes training for over 200 epochs, starting with an initial learning rate of 0.001, which experiences a 10% decay after each epoch. The experiments are facilitated by a Tesla V100-DGXS-32GB GPU."}, {"title": "B. Baselines and Evaluation Metrics", "content": "Our study compares CRNet against several benchmark models", "networks": "n\u2022 Initial: The direct estimation from sparse IoV data.\n\u2022 HA: An arithmetical operation averages the values of historical and current Initial estimations [40", "CNN": "A four-layer CNN designed to capture the spatial correlation of current Initial estimation [41", "PredRNN": "An RNN architecture designed for video prediction", "37": ".", "ConvLSTM": "An integration of convolutional operation and LSTM framework", "36": ".", "E3DLSTM": "A spatial-temporal model uses memory at-tentive module to capture long-term motions and 3D-convolutions to perceive short-term motions [42", "SimVP": "A simple yet effective video prediction model that is completely built upon CNN and its variants [38", "as": "n(1) Root mean squared error (RMSE):\n\\[\\text {RMSE"}, "sqrt{\\frac{1}{T \\times H \\times W} \\sum_{t=1}^{T} \\sum_{h=1}^{H} \\sum_{w=1}^{W}\\left|y_{t}^{h, w}-\\hat{y}_{t}^{h, w}\\right|^{2}}.\\"], "IPV)": "n\\[\\mathrm{IPV}=\\left(1-\\frac{\\sqrt{\\sum_{t=1}^{T} \\sum_{h=1}^{H} \\sum_{w=1}^{W}\\left|y_{t}^{h, w}-\\hat{y}_{t}^{h, w}\\right|^{2}"}, {}]