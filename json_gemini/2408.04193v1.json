{"title": "Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate Graph Neural Networks", "authors": ["Zepu Wang", "Xiaobo Ma", "Huajie Yang", "Weimin Lvu", "Peng Sun", "Sharath Chandra Guntuku"], "abstract": "Crime forecasting is a critical component of urban analysis and essential for stabilizing society today. Unlike other time series forecasting problems, crime incidents are sparse, particularly in small regions and within specific time periods. Traditional spatial-temporal deep learning models often struggle with this sparsity, as they typically cannot effectively handle the non-Gaussian nature of crime data, which is characterized by numerous zeros and over-dispersed patterns. To address these challenges, we introduce a novel approach termed Spatial Temporal Multivariate Zero-Inflated Negative Binomial Graph Neural Networks (STMGNN-ZINB). This framework leverages diffusion and convolution networks to analyze spatial, temporal, and multivariate correlations, enabling the parameterization of probabilistic distributions of crime incidents. By incorporating a Zero-Inflated Negative Binomial model, STMGNN-ZINB effectively manages the sparse nature of crime data, enhancing prediction accuracy and the precision of confidence intervals. Our evaluation on real-world datasets confirms that STMGNN-ZINB outperforms existing models, providing a more reliable tool for predicting and understanding crime dynamics.", "sections": [{"title": "1 INTRODUCTION", "content": "Accurate crime forecasting can significantly enhance police de-ployment strategies and infrastructure allocation, substantially im-proving urban safety [8, 9, 22]. With advancements in deep learn-ing [2, 12, 15, 16, 23], researchers are increasingly utilizing com-plex neural network architectures to model crime patterns. These include recurrent neural networks [9], convolutional neural net-works [20], and graph neural networks [8, 21]. These models aimto capture both the spatial-temporal correlations of crime patternsand the interrelationships among different crime categories. Specifi-cally, spatial-temporal graph neural networks are good at extractingspatial-temporal correlations from urban data [17, 19, 24].However, the deterministic models predominantly used in crimeforecasting implicitly presuppose that the outputs follow a Gauss-ian distribution [1, 6, 7, 9, 29], significantly simplifying the variancestructure [3, 5]. Despite their effectiveness, most existing spatial-temporal prediction methods face limitations when predicting ur-ban crimes due to the sparsity of crime patterns. The data for eachfine-grained urban region is extremely sparse [26, 27]. A plethoraof zero values in crime data indicates that it is not appropriate toassume that crime data patterns follow a Gaussian distribution. Re-search demonstrates the effectiveness of the Zero-Inflated NegativeBinomial (ZINB) distribution in analyzing sparse travel demanddata [29] and sparse traffic risk forecasting [4]. Additionally, un-certainty quantification with ZINB has been conducted for manyurban and transportation tasks [11, 28].In this paper, we propose the Spatial Temporal Multivariate Zero-Inflated Negative Binomial Graph Neural Networks (STMGNN-ZINB)-a comprehensive framework designed for joint numericprediction and uncertainty quantification of urban crime. Our maincontributions are as follows:\n\u2022 We utilize the Zero-Inflated Negative Binomial (ZINB) distri-bution to model crime, effectively capturing zero-inflationand addressing data sparsity.\n\u2022 We integrate ZINB with spatial-temporal multivariate graphneural networks, enabling precise quantification of the sparseand discrete uncertainty in crime data."}, {"title": "2 PRELIMINARIES", "content": ""}, {"title": "2.1 Problem Definition", "content": "Formally, a graph G is defined as an ordered pair (V, E), whereV represents the set of vertices (or nodes) and E represents theset of edges. Suppose the historical crime data is embedded ingraph G with C multivariate crime features over T time intervals.The historical time series features can then be represented as X \u2208RN\u00d7TXCThe objective of this task is to learn a mapping function f thatuses the historical crime data X and the graph structure G as inputs to forecast future crime data for Q time intervals. Our goal is notonly to predict the expected values of future crime but also to esti-mate the confidence intervals for these predictions. Consequently,we denote our output as X \u2208 RN\u00d7Q\u00d7C\u00d7Z, where Z represents theparameters of the assumed distribution of crime data."}, {"title": "2.2 Zero-Inflated Negative Binomial Distribution", "content": "In our model, we assume that the distribution of crimes follows theZero-Inflated Negative Binomial (ZINB) distribution [10, 29]. Theprobability mass function (PMF) of a random variable followingthe ZINB distribution is given by:\n$P(Y = y) = \\begin{cases} \\pi + (1 - \\pi) (1-p)^r & \\text{if } y = 0 \\\\ (1 \u2013 \\pi) \\binom{y+r-1}{y}p^y(1 \u2212 p)^r & \\text{if } y = 1, 2, 3, ... \\end{cases}$ (1)\nHere, \u03c0 represents the probability of an extra zero, indicatingzero inflation, which in this context, signifies the likelihood ofno occurrences of a specific type of crime. The parameters r andp are the shape parameters of the traditional negative binomialdistribution, where r affects the dispersion and p is the probabilityof success in each experiment."}, {"title": "2.3 Diffusion Graph Convolution Networks (DGCNS)", "content": "To capture spatial correlations within a predefined graph struc-ture, we utilize Diffusion Graph Convolutional Networks (DGCNs).These models employ the concept of diffusion processes on graphsto effectively capture the spread of information across the graph'stopology.At the heart of DGCNs is the diffusion convolution operation,which can be considered a generalization of the traditional convolu-tional operations adapted for graph data. The underlying principleis to simulate a diffusion process on the graph, allowing informationto propagate from a node to its neighbors through multiple stepsor layers. This dynamic can be mathematically articulated usingthe graph Laplacian and its exponentiations to represent variousdegrees of diffusion.The diffusion convolution operation in a DGCN is mathematically defined as:\n$H^{(l+1)} = \\sigma (D^{-1}AH^{(l)} W^{(l)} + B^{(l)}H^{(l)})$\nwhere: - $H^{(l)}$ denotes the node features (or hidden states) at layerl, - A is the adjacency matrix of the graph, where $A_{ij}$ representsthe edge weight between nodes i and j, with $A_{ij} = 0$ if no edgeexists, - D is the diagonal degree matrix, with each diagonal element$D_{ii}$ being the sum of the weights of all edges connected to nodei, - $W^{(l)}$ is the weight matrix for layer l, which is learned duringthe training process, - $B^{(l)}$ is the bias term for layer l, - \u03c3(\u00b7) is anon-linear activation function, such as the Rectified Linear Unit(ReLU).This formulation enables the network to effectively balance theinfluence of immediate neighbors (through $D^{-1}AH^{(l)}$) and theretention of the current node's features (via $B^{(l)}H^{(l)}$), thus inte-grating both local and global information in the learning process."}, {"title": "2.4 Multivariate-Temporal Convolutional Networks (MTCNs)", "content": "Traditional Temporal Convolutional Neural Networks (TCNs) are aspecialized variant of convolutional neural networks designed toprocess sequence data effectively. The core principle of TCNs is toapply a shared gated 1D convolution across a specified width $w_{l}$in the $l^{th}$ layer, allowing the integration of information from $w_{l}$adjacent time points. In this study, we adapt traditional TCNs tosimultaneously capture multivariate-temporal correlations. Specif-ically, we aim to incorporate information from all crime types atpreceding time points for predicting a specific crime type at thecurrent time point. This integration is facilitated by reshaping themultivariate and temporal dimensions together.Each TCN layer $H_l$ receives input from the preceding layer $H_{l-1}$and updates as follows:\n$H^{(l+1)} = f(\\Gamma_{l} * H^{(l)} + b)$,\nwhere \u0393 represents the convolution filter for the layer, * denotesthe shared convolution operation, and b represents the bias. Ifthe previous hidden layer follows $H_{l-1} \u2208 R^{B\u00d7|V|\u00d7(w_{l-1}C)}$, then the convolution filter is $\\Gamma_{l} \u2208 R^{(w_{l}C)\u00d7(w_{l-1}C)}$, ensuring that $H_{l} \u2208R^{B\u00d7|V|\u00d7(w_{l}C)}$. Notably, if there is no padding in each TCN layer, itfollows that $w_{l} < W_{l-1}$.The primary motivation for capturing multivariate-temporal cor-relations is to leverage the streamlined architecture of traditionalTCNs for rapid training. Moreover, given that the temporal andmultivariate dimensions typically exhibit shorter lengths comparedto the spatial dimension, they can be treated as a single combineddimension. This approach helps mitigate the risk of extracting spu-rious relationships from the training data, which can lead to over-fitting-a common issue when neural networks attempt to modelrelationships between two dimensions with extensive lengths [25]."}, {"title": "2.5 General Structure", "content": "As illustrated in Figure 1, we utilize DGCNs to capture spatialdependencies, resulting in spatial embeddings \u03c01, P1, and r1.Concurrently, MTCNs are employed to capture multivariate temporalcorrelations, yielding multivariate temporal embeddings \u03c02, P2, andr2. These embeddings are then fused into combined parameters\u03c0, p, and r using the Hadamard product. This method of integra-tion is inspired by recent advances in uncertainty quantificationtechniques [29].\nTo address the issue where zeros result in infinite values forthe KL-divergence based variational lower bound [29], we opt todirectly utilize the negative likelihood as our loss function. Thisapproach allows for a more accurate fitting of the distribution to thedata, circumventing the limitations posed by zeros in the calculationof the KL-divergence.\n$NLL = -\\begin{cases}\\sum_{i}^{|M|N} log[\\pi_{i} + (1 \u2013 \\pi_{i})\u00b7 (1 \u2013 p_{i})^{r_{i}}] & \\text{if } y_{i} = 0 \\\\ \\sum_{i}^{|M|N} log[(1 \u2013 \\pi_{i}) \\frac{\\Gamma(r_{i}+y_{i})}{y_{i}!(r_{i}-1)!} p_{i}^{y_{i}}(1-p_{i})^{r_{i}}] & \\text{if } y_{i} > 0 \\end{cases}$ (3)"}, {"title": "3 EXPERIMENTS", "content": ""}, {"title": "3.1 Experiment Setup", "content": "3.1.1 Data. Following the methodology in [14], our experimentsutilize two distinct crime datasets from New York City (NYC) andChicago (CHI). These datasets cover various types of crime inci-dents, including Robbery and Larceny in NYC and Damage andAssault in CHI, across different locations within each city. For thepurpose of our experiments, we divided each city into a spatial gridof 3 km \u00d7 3 km, resulting in 256 regions for NYC and 168 regionsfor CHI. Our prediction targets are set at a daily resolution.The datasets were split into training and testing sets with a 7:1ratio along the time dimension. Additionally, we used the last 30days of the training set as a validation set to fine-tune the modelparameters. Table 1 provides a summary of the dataset statistics.3.1.2 Evaluation Metrics. We evaluate the performance of differentmodels from three perspectives: 1. Point Estimation: We use MeanAbsolute Error (MAE) to measure the accuracy of the mean value ofthe predicted distributions. A lower MAE indicates better accuracy.2. Uncertainty Quantification: This includes Mean Prediction In-terval Width (MPIW) and Prediction Interval Coverage Probability(PICP) within the 10%-90% confidence interval. MPIW calculatesthe average width of the confidence intervals, reflecting the extentof uncertainty in the predictions. PICP quantifies the percentageof actual data points that fall within these intervals, aiming for acoverage as close to 90% as possible. Additionally, KL-Divergenceis used to assess the similarity between the predicted and actualdata distributions, with lower values indicating better model per-formance. 3. Discrete Metrics: We round our results to their closestinteger to measure the true-zero rate and the F1-score. The true-zero rate evaluates the model's ability to accurately represent datasparsity, whereas the F1-score assesses the accuracy of discretepredictions. Higher values of the true-zero rate and F1-score signifysuperior performance.3.1.3 Baseline Methods. In order to explore the advantages ofSTMGNN-ZINB, we compare the STMGNN-ZINB results againstthree other models: (1) Historical Value (HA) serves as the statis-tical baseline. It uses historical input directly to represent predic-tion results. (2) Spatial-Temporal Graph Convolutional Networks(STGCN) 1 is the state-of-the-art deep learning model for spatial-temporal prediction but it only produces point estimates; (3) Modelswith probabilistic assumptions to replace ZINB: Negative Binomial(STMGNN-NB), Gaussian (STMGNN-G), and Truncated Normal(STMGNN-TN)."}, {"title": "3.2 Experimental Results and Analysis", "content": "As shown in Table 2, STMGNN-ZINB outperforms all baselinemethods across the majority of evaluation metrics. Specifically,in point estimation, STMGNN-ZINB achieves the lowest MeanAbsolute Error (MAE), indicating that its mean value accuratelyreflects the trends in real crime data. For uncertainty metrics, the"}, {"title": "3.3 Interpretation of Parameter \u03c0", "content": "The sparsity parameter \u03c0 in the Zero-Inflated Negative Binomial(ZINB) distribution quantifies the likelihood that a specific zone isdevoid of any crime activities. Our STMGNN-ZINB model outputs \u03c0for various types of crime activities across different spatial regionsfor successive future time steps.Figure 4 displays a heatmap of the overall crime activities (pa-rameter \u03c0) for New York City and Chicago. This visualization offersvaluable insights for government agencies and public security en-tities. Notably, it reveals the presence of spatial locality, wherechanges in crime activities gradually vary across the spatial di-mension. It is uncommon to find isolated small regions with lowcrime rates surrounded by areas with high crime rates. Furthermore,consistent with mainstream criminological research, our findingsindicate a higher concentration of crime activities in the down-town areas of both cities compared to the marginal regions (ruralareas) [13, 18]. This pattern underscores the heightened crime ratestypically observed in urban centers as opposed to rural settings."}, {"title": "4 CONCLUSION", "content": "In this work, we introduce a novel combination of Spatial TemporalMultivariate Graph Neural Networks and Zero-Inflated NegativeBinomial distribution to quantify uncertainty in the urban crimeprediction problem. We validated our model's performance throughextensive experiments across five representative scenarios, focus-ing particularly on point estimation and uncertainty measurement.Given that the parameter \u03c0 has a clear physical interpretation, ourmodel could assist social security decision-makers in efficiently al-locating limited social resources to different regions. This approachnot only enhances predictive accuracy but also aids in strategicplanning and resource management."}]}