{"title": "Do Neural Scaling Laws Exist on Graph Self-Supervised Learning", "authors": ["Qian Ma", "Haitao Mao", "Jingzhe Liu", "Zhehua Zhang", "Chunlin Feng", "Yu Song", "Yihan Shao", "Tianfan Fu", "Yao Ma"], "abstract": "Self-supervised learning (SSL) is essential to obtain foundation models in NLP and CV domains via effectively leveraging knowledge in large-scale unlabeled data. The reason for its success is that a suitable SSL design can help the model to follow the neural scaling law, i.e., the performance consistently improves with increasing model and dataset sizes. However, it remains a mystery whether existing SSL in the graph domain can follow the scaling behavior toward building Graph Foundation Models (GFMs) with large-scale pre-training. In this study, we examine whether existing graph SSL techniques can follow the neural scaling behavior with the potential to serve as the essential component for GFMs. Our benchmark includes comprehensive SSL technique implementations with analysis conducted on both the conventional SSL setting and many new settings adopted in other domains. Surprisingly, despite the SSL loss continuously decreasing, no existing graph SSL techniques follow the neural scaling behavior on the downstream performance. The model performance only merely fluctuates on different data scales and model scales. Instead of the scales, the key factors influencing the performance are the choices of model architecture and pretext task design. This paper examines existing SSL techniques for the feasibility of Graph SSL techniques in developing GFMs and opens a new direction for graph SSL design with the new evaluation prototype. Our code implementation is available online to ease reproducibility 1.", "sections": [{"title": "1 Introduction", "content": "Self-supervised learning (SSL) [1] is to leverage the informative patterns from abundant unlabeled data via pre-training. SSL techniques serve an indispensable role in building Foundation Models in CV and NLP domains with successful applications [2, 3, 4]. A successful SSL design can observe the neural scaling law behavior where the test performance can continuously improve and the test loss continuously decreases with increasing pre-training data size and the model parameter size [5]. Neural scaling laws serve as the key principle for the success of foundation models in CV and NLP domains.\nSSL techniques [6, 7, 8] are also successfully adopted in the graph domain while there is no Graph Foundation Model (GFM) with SSL so far. It remains unclear whether graph SSL techniques follow the scaling law. To this end, we benchmark existing graph SSL techniques to examine whether they can follow the neural scaling behavior with the potential to build GFMs [9, 10]. We focus on the graph classification task instead of transductive node classification and link prediction as the unidentified relationship between train and test nodes. An inductive graph classification setting helps to construct clear-control data scaling settings. Initial observations demonstrate that the graph SSL loss continuously decreases on the test set with increasing data scale and model scale. However, despite the decreasing SSL loss, the downstream task performance does not observe the scaling"}, {"title": "2 Related Works", "content": "Neural Scaling Law The general idea of the neural scaling law is that the model's performance will keep improving with the scaling of training data or model parameters [11]. The quantitive formulation of the Neural Scaling Law is typically described in a power-law form as follows, which is first proposed by Hestness et al [12].\n$\u20ac = ax^{-b} + \u20ac_\\infty$\nThe variable X represents the size of the model or the training set. The \u20ac is the prediction error of the model. a, b and $\u20ac_\\infty$ > 0 are all positive parameters. Under the guidance of neural scaling law, researchers could predict the performance of large models based on small-scale experiments, which greatly saves the costs of redundant runs. Moreover, the scaling laws can be applied to benchmark different models for the backbone of foundation models. Hence, neural scaling law has helped the development of large models in computer vision [12, 13, 14, 15] and natural language processing [11, 13, 16, 17, 18, 19, 20].\nLiu et al [21] take an initial step of developing the neural scaling laws in the general graph domain. Specifically, it verifies the general forms of neural scaling laws on graphs. It also discovers some unique phenomena of model scaling and proposes a proper metric for data scaling on graphs. Within specific graph domains e.g., molecular graphs, there are existing works [22] that discovered the scaling of GNNs. These works provide a foundation for our study but are limited to supervised learning, while our focus is self-supervised learning.\nSelf-Supervised Learning and its applications on Graph. The rise of self-supervised learning in Natural Language Processing (NLP) and Computer Vision (CV) [23, 24, 25] has shifted attention to learning paradigms that do not depend on annotated data. The burgeoning interest in self-supervised learning methodologies presents an invaluable opportunity for graph learning research, particularly in overcoming the reliance on annotated data. A growing body of work has introduced a variety of self-supervised learning strategies for graph data [26, 27, 28, 29, 30, 31, 32, 6], marking a critical evolution in the field. These methods aim to reproduce the success of self-supervised learning in graph learning research. However, whether scaling law exists under these Graph SSL methods are still mysterious.\nBy leveraging abundant unlabeled data in the real world and expanding model scale, there are a lot of models [2, 3] in CV, and NLP areas that serve as foundation models as they benefit from the scaling law during the pre-training stage. If there exists a GraphSSL method following the neural scaling law, we believe that it has a solid basis to serve as a part of the graph foundation model."}, {"title": "3 Experiment Setups", "content": "To ensure the comprehensiveness of our exploration, we implement the existing representative Graph SSL methods on various datasets. We select graph classification as the downstream task for evaluation. Here we provide some basic description of the methods and datasets, more details can be found in the Appendix A.\nGraph SSL Methods. We conducted experiments on the following Graph SSL methods. (1) InfoGraph: As a pioneer work of Graph SSL, InfoGraph [8] maximizes mutual information between global graph embeddings and local sub-structure embeddings, leveraging JSD as its contrastive loss. (2) GraphCL: GraphCL [7] is a general contrastive learning framework. By maximizing the representations similarity between two different randomly perturbed local sub-graphs of the same node, the encoder can be pre-trained in a SSL manner. (3) JOAO: JOAO [33] can automatically and dynamically select augmentations during GraphCL training. (4) GraphMAE: GraphMAE [34] is a generative SSL methods, which aims at reconstructing the feature and information of the data. The encoder of GraphMAE is trained by reconstructing the masked data feature with provided context. Datasets. We used the following Datasets for conducting experiments. reddit-threads [35] contains graphs presenting the task to predict whether a thread is discussion-based. ogbg-molhiv,ogbg-molpcba are curated by ogb [36], all of them are molecular property prediction datasets and the task performance metrics are ROC-AUC and AP correspondingly. Experiments Settings. In this part, we introduce some details of our experiment settings and the differences compared to the existing evaluation protocol. We pre-train the encoder with the existing Graph SSL methods using unlabeled data. We evaluate the GraphSSL methods by applying the pre-trained encoder to downstream task via linear probing. Data Split. All datasets are split with the ratio 8:1:1 for training, validation, and testing set and only the pre-split training set is used to pre-train the model. To ensure the reproducibility of our experiments, we fix the split for all datasets and all methods will use the same split for experiments. Evaluation Protocols. In this work, we only use the split training set for pre-training to ensure the testing set used for evaluation will not be leaked in the pre-training stage. For the evaluation of SSL methods, we follow the existing setting in our main experiments by fixing the pre-trained encoder and use the embeddings obtained by this specific fixed pre-trained encoder to conduct a downstream task, such as training a classifier for graph classification. The pre-training data and downstream data are from the identical dataset. Then the metrics on the downstream task will be reported to serve as the performance of the pre-trained encoder to reflect the feasibility of the SSL method correspondingly. Specifically, for the downstream task settings, we only used the pre-first 10% of the split training data with labels. We stored the model pre-trained after 100 epochs to further evaluate them with the downstream tasks. We also include more details in the Appendix B."}, {"title": "4 Data scaling", "content": "In this section, we conduct experiments to explore the data scaling of Graph SSL methods and our findings. The main observation is that there is no obvious downstream performance gain along with the scaling-up data, indicating no data-scaling effect."}, {"title": "4.1 Data Scaling on Downstream Performance", "content": "To explore how the performance of downstream tasks improves with the scale-up pre-training data for Graph SSL methods, we introduce the settings and then present our observations.\nSettings. To verify the existence of the data scaling phenomenon of GraphSSL methods, we construct the following pipeline for pre-training and evaluation to verify data scaling.\n\u2022 For a reasonable data scaling setting, we gradually increase the ratio for pre-training data with a fixed interval by containing all data used in the previous ratios.\n\u2022 For each dataset, we further slice the pre-split training data with the fixed interval with 0.1 as different pre-training data ratio settings. The order of indices is fixed after generation, so we can gradually increase the data ratio for pre-training from 0.1 to 1 by slicing the indices to make sure the data from previous lower ratio can be included.\n\u2022 For the evaluation on the downstream tasks, we trained an SVM classifier with the pre-trained model fixed following the existing protocols and reported its performance on the held-out test set as the metrics for evaluation.\n\u2022 To examine whether the Graph SSL methods can consistently exhibit the scaling effect, we fit the equation of scaling law to our empirical results on different data scales with the least square and calculate the coefficient of determination $R^2$ for examining the quality of the fitting to the scaling.\nObservation 1. With gradually scaled-up pre-training data, no obvious scaling effect can be observed from the downstream performance.\nWe conduct experiments to gradually increase the data ratio for pre-training to observe whether the performance gain, along with the increasing data, serves as evidence for the data-scaling behavior. Our key observation is that the performance of all investigated Graph SSL methods does not exhibit a consistent and obvious scaling behavior despite the consistently increased data ratio for pre-training. There is no fitted curve nor large $R^2$ value to indicate that the downstream performance can scale up along with more pre-training data amount."}, {"title": "4.2 Data Scaling on SSL loss", "content": "Settings. We investigate the above question by changing the metrics we observed from the down-stream performance to the same SSL task objectives. More specifically, we utilize the held-out test set to compute the same SSL loss used in the pre-training stage with the pre-trained model fixed. In this way, we can examine if there is a gain on the same SSL task from improved capability obtained by scale-up pre-training data.\nObservation 2. With gradually scaled-up pre-training data, consistent scaling behavior can be observed on the SSL loss.\nWe conduct data scaling experiments to examine if the gain can be observed on SSL tasks with the scale-up pre-training data. Compared with the observation on the downstream task performance, the scaling behavior on the SSL loss is consistent and obvious. However, the scaling behavior could be method-specific i.e., some methods behave more consistently and stably in a scaling manner while others do not. According to the above results, we observe that the scale-up pre-training data can improve the capability of SSL tasks in a data-scaling manner. Notably, we do not observe the scaling behavior on the downstream performance in Section 4.1. Therefore, it could be the gap between the pre-training and downstream tasks that block the GraphSSL methods from following the scaling law on the downstream performance."}, {"title": "5 Model Scaling", "content": "In this section, we conduct experiments to explore the model scaling of Graph SSL methods. Specifically, we aim to observe how the performance improves as we increase the number of model parameters. Our key observation is that no consistent scaling behaviour can be observed with model scaling on performance."}, {"title": "5.1 Model Scaling on Downstream Performance", "content": "Observation 3. Under the two different manners of model scaling settings, there is no obvious scaling effect can be observed from the downstream performance.\nWe present the results showing how the downstream performance of investigated methods improve with scale-up model size where the number of parameters is indicated by the x-axis and the downstream performance is indicated by the y-axis, and different colors indicate different settings of hidden size or number of layers.\nBy increasing the number of layers with the hidden size fixed, no consistent scaling behavior can be observed. Therefore, our key observation is that there is no consistent scaling behavior in the downstream performance of GraphSSL methods with either scale-up hidden dim or number of layers, unlike the scaling effect that universally exists in CV and NLP domains by increasing the total number of parameters of the model. Consequently, we conducted further investigation on SSL loss to examine if the capability of scale-up model parameters benefits the SSL tasks without corresponding to the downstream performance gain."}, {"title": "5.2 Model Scaling on SSL loss", "content": "To examine if the scaled-up model parameters can improve the capability of SSL task to reveal scaling law, we target the SSL loss on the downstream data as a metric. To better examine the GraphCL and JOAO, we select proper settings for data augmentation for contrastive learning as it is indicated as the key component in their original papers [7, 33].\nObservation 4. Under the model scaling setting with increasing numbers of layers, the scaling effect on the SSL loss can be observed on particular datasets and SSL methods.\nWe present the results of all methods on the same dataset, where the x-axis denotes the total number of parameters of the model and the y-axis denotes the metrics of SSL loss respectively. Different colors represent different hidden size settings.\nOur key conclusion from the above results is that there is method-specific model scaling behavior can be observed with the scale-up number of layers and fixed hidden size. Compared with the representative contrastive SSL method InfoGraph, GraphMAE is a generative method, the scaling effect is not consistent nor obvious on its SSL loss i.e., its feature reconstruction cosine loss. These differences indicate that the SSL task design of GraphMAE can not consistently benefit from the scaling up of model parameters. As contrastive SSL methods, GraphCL and JOAO can exhibit similar scaling behavior as InfoGraph on all datasets. Observation 5. Under the model scaling settings with increasing hidden size, there is no obvious scaling effect can be observed from the SSL loss across datasets.\nWe also grouped the results by the same number of layers. Our key conclusion from the above results is that there is no consistent or obvious scaling behavior can be observed with the scale-up hidden size while fixing the number of layers. Consequently, we conducted a further investigation on InfoGraph for this phenomenon to examine whether the aggregation benefits the capability of InfoGraph on SSL objectives rather than the transformation with more learnable parameters."}, {"title": "Observation 6", "content": "By fixing the hidden size for transformation and increasing the number of aggregations, an obvious and consistent scaling behavior can be observed on SSL Loss for the new implementation with transformation and aggregation decoupled.\nTo decouple the aggregation and transformation of the model, we modify the implementation of the original InfoGraph accordingly. More specifically, we replaced the layers except for the last layers from the GINConv layer to Message Passing layers. For the original implementation, all layers are the same, i.e., for each layer, the GINConv layer will aggregate the features and then transform them. Our new implementation only remains the one transformation layer, which is the same as the original version for feature transformation while the other layers are only message passing layers for aggregation. In this way, the aggregation and transformation are decoupled. The embedding obtained with the trained encoder will be fed into the projection head to map the embeddings into another latent space for calculating the SSL Loss. Our new implementation with aggregation and transformation decoupled is denoted as InfoGraph1T. Therefore, we can draw a conclusion that the improvement in the SSL Loss is primarily due to the model architecture or structure with more aggregations, rather than the capability with more learnable parameters for transformation."}, {"title": "6 Conclusion", "content": "In this work, we take the first step to explore the neural scaling laws on the existing Graph SSL methods. Specifically, we try to verify the existence of two basic forms of neural scaling laws: the model scaling law and the data scaling law. Our attempts obtain some key observations and provide some insights for future work. Obs 1 and 3 indicate that no scaling behavior can be observed in the downstream performance. Meanwhile, Obs 2 and 4 indicate that scaling behavior can only be observed in the SSL loss with the increasing number of layers of the encoder in GraphSSL methods. The above observations can draw a conclusion that the gain in the downstream performance does not correspond to SSL loss. These results indicate that there is a huge gap between the existing SSL and downstream tasks in Graph domain. Therefore, for further GFM design, we believe that a proper SSL task design is critical to mitigate this gap to exhibit scaling behavior on the downstream tasks. Obs 5 and 6 indicate that the scaling behavior we observed is mainly caused from the characteristics of the model architecture i.e., more aggregations instead of the improved capability with more learnable parameters. These observations provide insights to future work like verifying the existence of neural scaling law on more powerful backbones e.g., Graph Transformer for GraphSSL methods. Moreover, the scaling behavior exhibited in SSL loss for contrastive methods is more consistent than generative methods. These results suggest that SSL task design and the component design of GraphSSL methods should be considered as the key factors to reveal the potential of scaling law. Therefore, for further GFM design, we believe that a powerful and representative backbone is critical to be able to scale up to accommodate continuously increasing pre-training data.\nOur findings shed light on the absence of the scaling behaviors of existing GraphSSL methods and point to critical components that should be considered in future design."}, {"title": "E Deferred details about GraphCL/JOAO SSL method", "content": "Compared with InfoGraph, there are two major differences between GraphCL/JOAO and InfoGraph. (1) The SSL Loss (2) The strategy for constructing the augmented view for contrastive learning.\nWe first investigate the influence of loss. InfoGraph is using JSD Loss while GraphCL and JOAO are using InfoNCE loss. As this is the most obvious difference between the methods, we switch the SSL Loss, which can be considered as switching a single component between two different frameworks. Consequently, our key conclusion from the above results is that the SSL Loss is not the factor that affects the stability.\nWe further investigated the difference in generating the augmented views. By fixing the randomness in utilizing augmenters to generate augmented views for contrastive learning. These results also support our conclusions that the gap between SSL and downstream tasks blocks the SSL methods from improving on downstream performance corresponding to SSL loss and the component design is critical for exhibiting scaling behavior for the future Graph Foundation Model design."}]}