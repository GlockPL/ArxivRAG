{"title": "Do Neural Scaling Laws Exist on Graph Self-Supervised Learning", "authors": ["Qian Ma", "Haitao Mao", "Jingzhe Liu", "Zhehua Zhang", "Chunlin Feng", "Yu Song", "Yihan Shao", "Tianfan Fu", "Yao Ma"], "abstract": "Self-supervised learning (SSL) is essential to obtain foundation models in NLP\nand CV domains via effectively leveraging knowledge in large-scale unlabeled\ndata. The reason for its success is that a suitable SSL design can help the model\nto follow the neural scaling law, i.e., the performance consistently improves\nwith increasing model and dataset sizes. However, it remains a mystery whether\nexisting SSL in the graph domain can follow the scaling behavior toward building\nGraph Foundation Models (GFMs) with large-scale pre-training. In this study,\nwe examine whether existing graph SSL techniques can follow the neural scal-\ning behavior with the potential to serve as the essential component for GFMs.\nOur benchmark includes comprehensive SSL technique implementations with\nanalysis conducted on both the conventional SSL setting and many new settings\nadopted in other domains. Surprisingly, despite the SSL loss continuously de-\ncreasing, no existing graph SSL techniques follow the neural scaling behavior on\nthe downstream performance. The model performance only merely fluctuates\non different data scales and model scales. Instead of the scales, the key factors\ninfluencing the performance are the choices of model architecture and pretext\ntask design. This paper examines existing SSL techniques for the feasibility\nof Graph SSL techniques in developing GFMs and opens a new direction for\ngraph SSL design with the new evaluation prototype. Our code implementation\nis available online to ease reproducibility 1.", "sections": [{"title": "Introduction", "content": "Self-supervised learning (SSL) [1] is to leverage the informative patterns from abundant unlabeled\ndata via pre-training. SSL techniques serve an indispensable role in building Foundation Models in\nCV and NLP domains with successful applications [2, 3, 4]. A successful SSL design can observe\nthe neural scaling law behavior where the test performance can continuously improve and the test\nloss continuously decreases with increasing pre-training data size and the model parameter size [5].\nNeural scaling laws serve as the key principle for the success of foundation models in CV and NLP\ndomains.\nSSL techniques [6, 7, 8] are also successfully adopted in the graph domain while there is no Graph\nFoundation Model (GFM) with SSL so far. It remains unclear whether graph SSL techniques follow\nthe scaling law. To this end, we benchmark existing graph SSL techniques to examine whether\nthey can follow the scaling behavior with the potential to build GFMs [9, 10]. We focus on\nthe graph classification task instead of transductive node classification and link prediction as the\nunidentified relationship between train and test nodes. An inductive graph classification setting helps\nto construct clear-control data scaling settings. Initial observations demonstrate that the graph SSL\nloss continuously decreases on the test set with increasing data scale and model scale. However,\ndespite the decreasing SSL loss, the downstream task performance does not observe the scaling"}, {"title": "Related Works", "content": "Neural Scaling Law The general idea of the neural scaling law is that the model's performance\nwill keep improving with the scaling of training data or model parameters [11]. The quantitive\nformulation of the Neural Scaling Law is typically described in a power-law form as follows, which\nis first proposed by Hestness et al [12].\n\u20ac = ax^{-b} + \u20ac_{0\u221e}\n(1)\nThe variable X represents the size of the model or the training set. The \u20ac is the prediction error\nof the model. a, b and \u20ac\u221e > 0 are all positive parameters. Under the guidance of neural scaling\nlaw, researchers could predict the performance of large models based on small-scale experiments,\nwhich greatly saves the costs of redundant runs. Moreover, the scaling laws can be applied to\nbenchmark different models for the backbone of foundation models. Hence, neural scaling law has\nhelped the development of large models in computer vision [12, 13, 14, 15] and natural language\nprocessing [11, 13, 16, 17, 18, 19, 20].\nLiu et al [21] take an initial step of developing the neural scaling laws in the general graph domain.\nSpecifically, it verifies the general forms of neural scaling laws on graphs. It also discovers some\nunique phenomena of model scaling and proposes a proper metric for data scaling on graphs. Within\nspecific graph domains e.g., molecular graphs, there are existing works [22] that discovered the\nscaling of GNNs. These works provide a foundation for our study but are limited to supervised\nlearning, while our focus is self-supervised learning.\nSelf-Supervised Learning and its applications on Graph. The rise of self-supervised learning in\nNatural Language Processing (NLP) and Computer Vision (CV) [23, 24, 25] has shifted attention to\nlearning paradigms that do not depend on annotated data. The burgeoning interest in self-supervised\nlearning methodologies presents an invaluable opportunity for graph learning research, particularly\nin overcoming the reliance on annotated data. A growing body of work has introduced a variety of\nself-supervised learning strategies for graph data [26, 27, 28, 29, 30, 31, 32, 6], marking a critical\nevolution in the field. These methods aim to reproduce the success of self-supervised learning in\ngraph learning research. However, whether scaling law exists under these Graph SSL methods are\nstill mysterious.\nBy leveraging abundant unlabeled data in the real world and expanding model scale, there are a lot of\nmodels [2, 3] in CV, and NLP areas that serve as foundation models as they benefit from the scaling\nlaw during the pre-training stage. If there exists a GraphSSL method following the neural scaling law,\nwe believe that it has a solid basis to serve as a part of the graph foundation model."}, {"title": "Experiment Setups", "content": "To ensure the comprehensiveness of our exploration, we implement the existing representative Graph\nSSL methods on various datasets. We select graph classification as the downstream task for evaluation.\nHere we provide some basic description of the methods and datasets, more details can be found in the\nAppendix A.\nGraph SSL Methods. We conducted experiments on the following Graph SSL methods. (1)\nInfoGraph: As a pioneer work of Graph SSL, InfoGraph [8] maximizes mutual information between\nglobal graph embeddings and local sub-structure embeddings, leveraging JSD as its contrastive\nloss. (2) GraphCL: GraphCL [7] is a general contrastive learning framework. By maximizing the\nrepresentations similarity between two different randomly perturbed local sub-graphs of the same\nnode, the encoder can be pre-trained in a SSL manner. (3) JOAO: JOAO [33] can automatically and\ndynamically select augmentations during GraphCL training. (4) GraphMAE: GraphMAE [34] is a\ngenerative SSL methods, which aims at reconstructing the feature and information of the data. The\nencoder of GraphMAE is trained by reconstructing the masked data feature with provided context.\nDatasets. We used the following Datasets for conducting experiments. reddit-threads [35] contains\ngraphs presenting the task to predict whether a thread is discussion-based. ogbg-molhiv,ogbg-\nmolpcba are curated by ogb [36], all of them are molecular property prediction datasets and the task\nperformance metrics are ROC-AUC and AP correspondingly. Experiments Settings. In this part,\nwe introduce some details of our experiment settings and the differences compared to the existing\nevaluation protocol. We pre-train the encoder with the existing Graph SSL methods using unlabeled\ndata. We evaluate the GraphSSL methods by applying the pre-trained encoder to downstream task\nvia linear probing. Data Split. All datasets are split with the ratio 8:1:1 for training, validation,\nand testing set and only the pre-split training set is used to pre-train the model. To ensure the\nreproducibility of our experiments, we fix the split for all datasets and all methods will use the same\nsplit for experiments. Evaluation Protocols. In this work, we only use the split training set for\npre-training to ensure the testing set used for evaluation will not be leaked in the pre-training stage.\nFor the evaluation of SSL methods, we follow the existing setting in our main experiments by fixing\nthe pre-trained encoder and use the embeddings obtained by this specific fixed pre-trained encoder to\nconduct a downstream task, such as training a classifier for graph classification. The pre-training data\nand downstream data are from the identical dataset. Then the metrics on the downstream task will be\nreported to serve as the performance of the pre-trained encoder to reflect the feasibility of the SSL\nmethod correspondingly. Specifically, for the downstream task settings, we only used the pre-first\n10% of the split training data with labels. We stored the model pre-trained after 100 epochs to further\nevaluate them with the downstream tasks. We also include more details in the Appendix B."}, {"title": "Data scaling", "content": "In this section, we conduct experiments to explore the data scaling of Graph SSL methods and our\nfindings. The main observation is that there is no obvious downstream performance gain along with\nthe scaling-up data, indicating no data-scaling effect."}, {"title": "Data Scaling on Downstream Performance", "content": "To explore how the performance of downstream tasks improves with the scale-up pre-training data\nfor Graph SSL methods, we introduce the settings and then present our observations.\nSettings. To verify the existence of the data scaling phenomenon of GraphSSL methods, we construct\nthe following pipeline for pre-training and evaluation to verify data scaling.\n\u2022 For a reasonable data scaling setting, we gradually increase the ratio for pre-training data with a\nfixed interval by containing all data used in the previous ratios.\n\u2022 For each dataset, we further slice the pre-split training data with the fixed interval with 0.1 as\ndifferent pre-training data ratio settings. The order of indices is fixed after generation, so we can\ngradually increase the data ratio for pre-training from 0.1 to 1 by slicing the indices to make sure\nthe data from previous lower ratio can be included.\n\u2022 For the evaluation on the downstream tasks, we trained an SVM classifier with the pre-trained\nmodel fixed following the existing protocols and reported its performance on the held-out test set\nas the metrics for evaluation."}, {"title": "Data Scaling on SSL loss", "content": "Settings. We investigate the above question by changing the metrics we observed from the down-\nstream performance to the same SSL task objectives. More specifically, we utilize the held-out test\nset to compute the same SSL loss used in the pre-training stage with the pre-trained model fixed. In\nthis way, we can examine if there is a gain on the same SSL task from improved capability obtained\nby scale-up pre-training data.\nObservation 2. With gradually scaled-up pre-training data, consistent scaling behavior can be\nobserved on the SSL loss.\nWe conduct data scaling experiments to examine if the gain can be observed on SSL tasks with\nthe scale-up pre-training data. The results presented in Figure 3 and 4 illustrate how the SSL Loss\nimproves on reddit-threads and ogbg-molhiv datasets with scale-up pre-training data. The x-axis is\nthe pre-training data amount and the y-axis is the SSL Loss. The overall fitting quality of the fitted\ncurve obtained with the data points is examined by the R2 value.\nCompared with the observation on the downstream task performance, the scaling behavior on the SSL\nloss is consistent and obvious. However, the scaling behavior could be method-specific i.e., some\nmethods behave more consistently and stably in a scaling manner while others do not. Taking the\nInfoGraph as an example, as shown in Figure 3(a)and 4(a), the SSL loss evaluated on the testing data\ndecreases as pre-training data scales. Meanwhile, for other methods e.g., GraphCL the scaling effect\nis less obvious and consistent as shown in Figure 3(b)and 4(b).\nAccording to the above results, we observe that the scale-up pre-training data can improve the\ncapability of SSL tasks in a data-scaling manner. Notably, we do not observe the scaling behavior on\nthe downstream performance in Section 4.1. Therefore, it could be the gap between the pre-training\nand downstream tasks that block the GraphSSL methods from following the scaling law on the\ndownstream performance."}, {"title": "Model Scaling", "content": "In this section, we conduct experiments to explore the model scaling of Graph SSL methods. Specif-\nically, we aim to observe how the performance improves as we increase the number of model\nparameters. Our key observation is that no consistent scaling behaviour can be observed with model\nscaling on performance."}, {"title": "Model Scaling on Downstream Performance", "content": "Observation 3. Under the two different manners of model scaling settings, there is no obvious\nscaling effect can be observed from the downstream performance.\nWe present the results showing how the downstream performance of investigated methods improve\nwith scale-up model size on three datasets in Figure 5, 6, 18 and Figure 7, 8, 19 where the number of\nparameters is indicated by the x-axis and the downstream performance is indicated by the y-axis, and\ndifferent colors indicate different settings of hidden size or number of layers.\nBy increasing the number of layers with the hidden size fixed, no consistent scaling behavior can be\nobserved as shown in Figure 5, 6, 18. Even for GraphCL, JOAO, and InfoGraph, there seems to be\nan obvious scaling effect exhibited only on Reddit Threads datasets as shown in Figure 6, however,\nthis could be limited to the scale of plotting as the differences between the downstream performance\nmetrics are very marginal and far away from being called 'scaling', especially compared with the\nnumber of parameters increasing in a exponential way. Similarly, by increasing the number of hidden\nsize with the number of layers fixed, no scaling effect can be consistently presented for all methods\nacross all datasets, as shown in Figure 7, 8, 19.\nTherefore, our key observation is that there is no consistent scaling behavior in the downstream\nperformance of GraphSSL methods with either scale-up hidden dim or number of layers, unlike\nthe scaling effect that universally exists in CV and NLP domains by increasing the total number of\nparameters of the model. Consequently, we conducted further investigation on SSL loss to examine\nif the capability of scale-up model parameters benefits the SSL tasks without corresponding to the\ndownstream performance gain."}, {"title": "Model Scaling on SSL loss", "content": "To examine if the scaled-up model parameters can improve the capability of SSL task to reveal scaling\nlaw, we target the SSL loss on the downstream data as a metric. To better examine the GraphCL and"}, {"title": "Conclusion", "content": "In this work, we take the first step to explore the neural scaling laws on the existing Graph SSL\nmethods. Specifically, we try to verify the existence of two basic forms of neural scaling laws: the\nmodel scaling law and the data scaling law. Our attempts obtain some key observations and provide\nsome insights for future work. Obs 1 and 3 indicate that no scaling behavior can be observed in\nthe downstream performance. Meanwhile, Obs 2 and 4 indicate that scaling behavior can only be\nobserved in the SSL loss with the increasing number of layers of the encoder in GraphSSL methods.\nThe above observations can draw a conclusion that the gain in the downstream performance does not\ncorrespond to SSL loss. These results indicate that there is a huge gap between the existing SSL and\ndownstream tasks in Graph domain. Therefore, for further GFM design, we believe that a proper SSL\ntask design is critical to mitigate this gap to exhibit scaling behavior on the downstream tasks. Obs 5\nand 6 indicate that the scaling behavior we observed is mainly caused from the characteristics of the\nmodel architecture i.e., more aggregations instead of the improved capability with more learnable\nparameters. These observations provide insights to future work like verifying the existence of neural\nscaling law on more powerful backbones e.g., Graph Transformer for GraphSSL methods. Moreover,\nthe scaling behavior exhibited in SSL loss for contrastive methods is more consistent than generative\nmethods. These results suggest that SSL task design and the component design of GraphSSL methods\nshould be considered as the key factors to reveal the potential of scaling law. Therefore, for further\nGFM design, we believe that a powerful and representative backbone is critical to be able to scale up\nto accommodate continuously increasing pre-training data.\nOur findings shed light on the absence of the scaling behaviors of existing GraphSSL methods and\npoint to critical components that should be considered in future design."}, {"title": "Deferred details about GraphCL/JOAO SSL method", "content": "Compared with InfoGraph, there are two major differences between GraphCL/JOAO and InfoGraph.\n(1) The SSL Loss (2) The strategy for constructing the augmented view for contrastive learning.\nWe first investigate the influence of loss. InfoGraph is using JSD Loss while GraphCL and JOAO are\nusing InfoNCE loss. As this is the most obvious difference between the methods, we switch the SSL\nLoss, which can be considered as switching a single component between two different frameworks.\nThe initial observation indicates that the instability of GraphCL and JOAO remained the same for the\nrevised version while the revised InfoGraph was still stable. Consequently, our key conclusion from\nthe above results is that the SSL Loss is not the factor that affects the stability.\nWe further investigated the difference in generating the augmented views. By fixing the randomness\nin utilizing augmenters to generate augmented views for contrastive learning. The rest of the settings\nare the same as the model scaling settings with fixed hidden size. After fixing the randomness\nin augmented view generation and selecting a proper contrastive strategy, GraphCL and JOAO\nobtain more stable results, where more obvious scaling behavior can be exhibited. Meanwhile, their\ndownstream performances are still almost overlapped with the ones with randomly selected data\naugmentations. These results also support our conclusions that the gap between SSL and downstream\ntasks blocks the SSL methods from improving on downstream performance corresponding to SSL loss\nand the component design is critical for exhibiting scaling behavior for the future Graph Foundation\nModel design."}]}