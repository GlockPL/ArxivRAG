{"title": "Bridging Legal Knowledge and Al:\nRetrieval-Augmented Generation with Vector Stores, Knowledge\nGraphs, and Hierarchical Non-negative Matrix Factorization", "authors": ["Ryan C. Barron", "Maksim E. Eren", "Olga M. Serafimova", "Cynthia Matuszek", "Boian S. Alexandrov"], "abstract": "Agentic Generative AI, powered by Large Language Models (LLMs)\nand enhanced with Retrieval-Augmented Generation (RAG), Knowl-\nedge Graphs (KGs), and Vector Stores (VSs), represents a transforma-\ntive technology applicable across specialized domains such as legal\nsystems, research, recommender systems, cybersecurity, and global\nsecurity, including proliferation research. This technology excels at\ninferring relationships within vast unstructured or semi-structured\ndatasets. The legal domain we focus on here comprises inherently\ncomplex data characterized by extensive, interrelated, and semi-\nstructured knowledge systems with complex relations. It comprises\nconstitutions, statutes, regulations, and case law. Extracting insights\nand navigating the intricate networks of legal documents and their\nrelations is crucial for effective legal research and decision-making.\nHere, we introduce a generative Al system that integrates RAG,\nVS, and KG, constructed via Non-Negative Matrix Factorization\n(NMF), to enhance legal information retrieval and Al reasoning and\nminimize hallucinations. In the legal system, these technologies\nempower Al agents to identify and analyze complex connections\namong cases, statutes, and legal precedents, uncovering hidden re-\nlationships and predicting legal trends-challenging tasks that are\nessential for ensuring justice and improving operational efficiency.\nOur system employs web scraping techniques to systematically col-\nlect legal texts, such as statutes, constitutional provisions, and case\nlaw, from publicly accessible platforms like Justia. It bridges the\ngap between traditional keyword-based searches and contextual\nunderstanding by leveraging advanced semantic representations,\nhierarchical relationships, and latent topic discovery. This approach\nis demonstrated in legal document clustering, summarization, and\ncross-referencing tasks. The framework marks a significant step\ntoward augmenting legal research with scalable, interpretable, and\naccurate retrieval methods for semi-structured data, advancing the\nintersection of computational law and artificial intelligence.", "sections": [{"title": "1 INTRODUCTION", "content": "The legal domain is uniquely complex, encompassing constitu-\ntions, statutes, court rules, regulations, ordinances, and case law.\nEach data type follows a different structural or organizational\nlogic-constitutions and statutes often contain hierarchical ele-\nments, whereas case law typically consists of lengthy, unstructured\nopinions. As new legal texts are continually produced, practition-\ners and scholars require computational systems that move beyond\nsimplistic keyword-based searches to deliver meaningful results.\nTraditional legal information retrieval methods, relying predom-\ninantly on Boolean logic [50] and lexical indexing (TF-IDF)[12],\nfrequently miss the subtle conceptual overlaps and deep contextual\ncues that characterize legal inquiries.\nIn response, RAG has become a framework that unites the strengths\nof information retrieval and generative models. RAG systems re-\ntrieve relevant legal documents or data points and then employ\na language model to synthesize that information into coherent,\ncontextually grounded answers. When applied to the legal domain,\nRAG can help reduce issues experienced by LLMS, like hallucina-\ntions [30, 34]. This is done by rooting responses in reliable texts,\nwhich then improves tasks such as case law retrieval, statutory in-\nterpretation, and document summarization. In order to fulfill these\nbenefits, an underlying infrastructure must effectively represent,\nretrieve, and interpret large volumes of legal data.\nThis paper addresses these requirements by integrating three\ncore technologies:\n\u2022 VS: By embedding legal texts into dense vector represen-\ntations (from models like BERT [21] or GPT [13, 44]), our\nsystem encompasses semantic meanings beyond keyword\nmatching. This helps users to locate relevant documents\neven when the exact search terms differ from the query's\nlanguage.\n\u2022 KG: Legal concepts-such as statutes, precedential cases,\nand doctrines are often interconnected through citations or\nshared legal principles. KGs formalize these relationships, en-\nabling structured navigation of the domain, explicit linking\nof related legal authorities, and improves reasoning over case-\nto-case, case-to-statute, and statute-to-statute references.\n\u2022 NMF: While KGs excel at mapping explicit legal connec-\ntions, many latent topics and patterns remain hidden in\nunstructured text. NMF uncovers these by factorizing word-\nembedding matrices into interpretable topics, aiding tasks\nlike clustering related cases or identifying new legal trends\nBy combining the strengths of the thee components into a domain-\nspecific RAG system, we aim to deliver insights and more reliable\noutputs for a wide spectrum of legal tasks. The integrated frame-\nwork leverages the high-recall semantic matching of vector stores,\nthe structured relationships codified in knowledge graphs, and the\ntopic discovery capabilities of NMF. This combination not only\nimproves retrieval quality but also strengthens the system's ability\nto provide explainable reasoning over extremely large datasets."}, {"title": "2 RELEVANT WORK", "content": "This section reviews contributions across RAG domains, semantic\nsearch using vector embeddings, knowledge graph construction,\nNMF, and legal information systems."}, {"title": "2.1 Non-Negative Matrix Factorization for\nPattern Discovery", "content": "NMF is a dimensionality reduction technique used to uncover latent\npatterns in data. [33] analyzed NMF as an interpretable method\nfor extracting features and topics from large datasets, specifically\nhighlighting its ability to identify meaningful and non-overlapping\ncomponents. Building on this work, [27] introduced sparseness\nconstraints for better interpretability, improving applications of\nNMF in real-world scenarios through more focused feature selec-\ntion. In the legal domain, NMF has been valuable for analyzing\ncomplex textual data, such as case law and statutes, and assist-\ning with topic discovery and clustering. For instance, [14] applied\nNMF to legal documents to extract latent topics and visualize rela-\ntionships, demonstrating how NMF's interpretable structure aids\nresearchers in identifying underlying topics not readily apparent in\nraw text. They even applied NMF hierarchically to find fine-grained\ntopics, however did not have a way to approximate the number\nof clusters automatically at each decomposition. More recently,\n[35] proposed a guided semi-supervised NMF approach for topic\ndiscovery in legal documents, using domain knowledge to steer\nfactorization and ensure the extracted topics remain highly rele-\nvant. This semi-supervised extension bridges the gap between fully\nautomated unsupervised techniques and expert-driven analysis.\nNMF's utility in legal contexts is particularly significant, providing\nan interpretable framework for analyzing large textual datasets."}, {"title": "2.2 Retrieval-Augmented Generation", "content": "RAG has emerged as a foundational approach for improving AI sys-\ntems across various domains, including law. For instance, [34] intro-\nduced a framework that dynamically retrieves relevant documents\nto ground generative outputs, achieving notable gains in accuracy.\nBuilding on this idea, [26] proposed a retrieval-augmented pre-\ntraining method that integrates external knowledge for improved\ndownstream task performance. In contrast, [29] demonstrated the\neffectiveness of retrieval in open-domain question answering. These\nadvances lay the groundwork for applying RAG to the legal sector,\nwhere the method's ability to ground LLMs in authoritative texts\nreduces hallucinations and increases accuracy in tasks such as case\nlaw retrieval, statutory reasoning, and judgment prediction. Notable\nexamples include CBR-RAG, which incorporates Case-Based Rea-\nsoning to structure retrieval for legal QA [51], and LegalBench-RAG.\nThis benchmark suite tailors evaluation metrics to the demands of\nlegal information synthesis [42]. Parallel work has demonstrated\nRAG's capabilities in other domains, such as malware data analysis,\nby combining embeddings, KGs, and NMF [9]. Other works show\nhow LLMs can dynamically decide when and what to retrieve to\nimprove legal reasoning [32] and how multi-step legal judgment\nprediction can benefit from iterative retrieval and generation [48],\nfurther demonstrating th effectiveness of combining retrieval strate-\ngies with LLMs."}, {"title": "2.3 Semantic Search with Vector Embeddings", "content": "Semantic search operates on dense vector representations to find\nthe deeper semantic relationships in texts, going beyond keyword\nmatching to proper context retrieval [26, 31]. This search is espe-\ncially valuable in the legal domain, where queries often demand con-\nceptual rather than surface-level understanding. Domain-specific\npretraining has become increasingly important, as in LEGAL-BERT\n[17], outperforming general-purpose models by better capturing\nlegal language nuances. Benchmarks like LeCaRD [36] show the\neffectiveness of dense retrievers-such as SBERT-in legal case re-\ntrieval of Chinese law and the abilities of hybrid approaches that\nintegrate both lexical and dense retrieval methods. Hierarchical\ntransformer architectures [28] and long-context models like Long-\nformer [10] further address the challenges of lengthy legal docu-\nments. In contrast, citation-driven approaches such as SPECTER"}, {"title": "2.4 Knowledge Graphs in Legal Research", "content": "In the legal domain, researchers have used KGs for knowledge ex-\ntraction [46], constructed domain-specific graphs tailored to legal\ncontexts [23], and explored their potential for addressing trust, pri-\nvacy, and transparency concerns [15]. Recent studies have demon-\nstrated the effectiveness of KGs in recommending similar legal\ncases [22], linking case law with statutes for improved retrieval\n[52], and using graphs to enhance legal case law search in Chinese\nlegal systems [11]. Beyond retrieval, KGs have been incorporated\ninto knowledge-aware machine reading systems for legal question\nanswering [25]. Collectively, these works demonstrate KGs' ca-\npacity to represent intricate legal concepts, structure regulatory\nframeworks, and encourage reasoning over legal data."}, {"title": "2.5 Legal Systems and Case Retrieval", "content": "Legal information systems have evolved rapidly with the advent of\nneural architectures and hybrid retrieval pipelines, enabling precise\ntasks such as precedent retrieval, statute matching, and judgment\nprediction [16, 19, 45]. Benchmarks like LeCaRD [36] and LexGLUE\n[18], along with LEGAL-BERT-based systems [17], have demon-\nstrated the capability of these neural methods to improve accuracy\nin analyzing legal corpora. In particular, researchers have leveraged\nstructured reasoning with transformers and graph representations\nto link statutes and precedents, as evidenced in the COLIEE competi-\ntion [43]. Nonetheless, several limitations remain: data scarcity and\njurisdictional bias continue to restrict the generalizability of such\nmodels. At the same time, resource-intensive retrievers like BERT-\nbased cross-encoders [53] have challenges scaling to large-scale\nlegal databases. Earlier works in juris-informatics have highlighted\nthe potential of automating legal reasoning and document analysis\n[8], laying the groundwork for modern approaches that fuse knowl-\nedge graphs, transformers, vector stores, and agent-oriented RAG\npipelines to deliver more explainable and efficient legal research\nworkflows."}, {"title": "3 METHODS", "content": "Laws and their interpretations are limited in application to their\nrespective jurisdictions. This work selected the State of New Mexico,\nusing the available Supreme Court and Court of Appeals case law,\nthe state constitution, and state statutes as the main data resource."}, {"title": "3.1 Data Collection", "content": "To compile a research-oriented corpus of legal documents, we uti-\nlized Justia's publicly accessible resources, in full compliance with\ntheir Terms of Service and any applicable usage guidelines, includ-\ning robots.txt. We developed a restricted and responsible crawler to\nonly access permitted documents-namely statutes, constitutional\nprovisions, and case law in the public domain-and to avoid any\nsections or usage not authorized by Justia's policies. To minimize\nserver load and respect rate limits, our scraper introduces time\ndelays between requests, monitors for HTTP status codes indicat-\ning rate-limiting or errors, and uses exponential backoff to handle\npotential network disruptions gracefully.\nFrom the main landing page, a dynamic crawler identifies only\nthose hyperlinks consistent with the site's navigation structure and\nrelevant public legal content, converting them to absolute URLs\nand recursively traversing nested content where permitted. Our\nprocess extracts metadata such as chapter names, article titles,\nsection numbers, full text for statutes, constitutional provisions, and\njudicial opinions for New Mexico's Court of Appeals and Supreme\nCourt cases.\nThroughout this procedure, we take multiple measures to main-\ntain compliance and transparency:\n\u2022 Logs track processed URLs to prevent duplication, resume\ninterrupted crawls responsibly, and record request timing.\n\u2022 Rate-limiting measures ensure we do not exceed usage\nthresholds or impose an undue burden on Justia's servers.\n\u2022 No circumvention of technical safeguards defined in\nrobots.txt and the TOS restrictions.\n\u2022 Non-commercial use only: we do not republish, sell, or\notherwise exploit Justia's content and only use it for legiti-\nmate scholarly research.\nThese practices keep the data process ethical, legally sound, and\nconsistent with Justia's rules for site usage and content retrieval."}, {"title": "3.2 Dimension Reduction in Legal Texts", "content": "Legal documents- constitutions, statutes, and case law- are tradi-\ntionally organized into chapters, articles, and sections, but these\nstructures do not always match the latent patterns revealed through\nfactorization. Each document type is analyzed separately using non-\nnegative tensor and matrix factorization to explore these hidden\nrelationships. A TF-IDF matrix, X, is first constructed from the\ncleaned corpus. Constitutional provisions, statutory clauses, and\ncase law paragraphs form the units of analysis for clustering.\nIn this study, we use the public repository called Tensor Extrac-\ntion of Latent Features (T-ELF)\u00b9 [24], combined with automatic\nmodel selection, to decompose X into coherent topic H-clusters.\nT-ELF efficiently identifies latent topics, grouping constitutional\nprovisions around themes such as \"separation of powers\" and clus-\ntering statutes and case law based on regulatory objectives and\nrecurring legal doctrines, respectively."}, {"title": "3.2.1 Application of Non-Negative Matrix Factorization to Legal\nTexts", "content": "NMF approximates the matrix X with two non-negative ma-\ntrices, W and H:\n\\(X \\approx W \\cdot H\\),\nwhere W describes how terms distribute over topics, and H\ndescribes how these topics distribute across documents. Constitu-\ntional articles and sections reveal underlying governance or civil\nrights themes; statute clauses highlight regulatory objectives, and"}, {"title": "3.2.2 Automatic Model Determination Using NMFk", "content": "A central chal-\nlenge in applying NMF is selecting the best number of latent fea-\ntures (k). We use NMFk [7], which combines clustering stability with\nreconstruction accuracy. Bootstrap resampling generates slightly\nperturbed versions of the original matrix, and repeated decompo-\nsitions measure how consistently clusters form. Silhouette scores\nhelp ensure cohesive, well-separated topics, while reconstruction\nerror verifies that the model effectively captures patterns in the\noriginal data.\nBy adapting this NMF approach to a hierarchical setting, legal\ntexts can be organized into a tree-like structure. Constitutions may\nbe segmented into articles and sections, statutes into chapters and\nclauses, and case law into layered precedents and sub-issues. This\nhierarchical perspective enhances the discovery of latent relation-\nships at multiple levels of granularity, facilitating deeper analyses\nof large-scale legal corpora."}, {"title": "3.3 Knowledge Graph", "content": "Features derived from T-ELF and document metadata are trans-\nformed into a series of head, entity, and tail relations, forming\ndirectional triplets integrated into a Neo4j KG [37].\nIn the legal context, the KG incorporates metadata and latent\nfeatures extracted from constitutions, statutes, and case law. The\nprimary nodes in the graph represent legal documents, including\nconstitutional provisions, statutory sections, and judicial opinions.\nThese nodes are enriched with metadata such as titles, hierarchical\nidentifiers (e.g., chapter and section numbers), jurisdiction, court\nnames, decision dates, and topics derived from latent features.\nEdges in the KG establish relationships between nodes to repre-\nsent the interconnected nature of legal documents. For instance:\n\u2022 Constitutional Nodes: Linked to statutory provisions or\njudicial interpretations that reference or rely on specific\nconstitutional clauses.\n\u2022 Statutory Nodes: Connected to cases interpreting the statute\nor related provisions within the same legislative framework.\n\u2022 Case Law Nodes: Interlinked based on shared topics, com-\nmon legal principles, or hierarchical relationships in appel-\nlate decisions.\nThis graph structure enables the RAG system to query and re-\ntrieve legal documents based on semantic similarity and explicit\nrelationships. For example, a query about \"due process\" might re-\ntrieve the relevant constitutional clause, cases that discuss its inter-\npretation, and statutory provisions impacted by those rulings. By\ncombining metadata and latent features, the KG supports advanced\nreasoning and logical traversal, enhancing the precision and depth\nof legal information retrieval.\nEach part had decomposition topics containing keywords that\nconnected to the documents. The bag of words (BOW) vocabulary\nwas also extracted and inserted into the knowledge graph. These\ncan be observed in the knowledge graph schema of Figure 1."}, {"title": "3.4 Vector Store", "content": "A vector database was implemented to manage and index legal doc-\numents, improving the RAG process for legal research. Using Mil-\nvus [47], the system stores vectorized representations of constitu-\ntions, statutes, and case law, treating each document type uniquely\nto ensure contextually relevant retrieval.\nConstitutional provisions are segmented into paragraphs, each\nassigned a unique ID, and vectorized using OpenAI's text-embedding-\nada-002 [40] model for granular semantic searches. Statutes are\ndivided by sections or clauses, with metadata like chapter numbers\nand section titles integrated for precise retrieval. Case law, due to\nits unstructured narrative format, is chunked into meaningful units,\npreserving logical flow and indexed with metadata such as case\nname and citation.\nThe RAG application queries the database to retrieve relevant\nfragments-constitutional paragraphs, statutory clauses, or case law\nsections-based on the query's focus. Retrieved text is processed\nby the LLM agents with custom prompts to construct responses,\nallowing the LLM to cite specific paragraphs or clauses, for trace-\nability.\nFor additional context, the system leverages a connected knowl-\nedge graph to explore related statutes, judicial interpretations, or\nprecedent cases."}, {"title": "4 RESULTS", "content": "This section presents the resulting atomic parts of the legal texts\nand their hierarchical decomposition, offering a detailed breakdown\nof the sections and cases within each document type. The following\nresults illustrate the scope and depth of the collected data, providing\na foundation for further exploration of trends and patterns across\nthe legal corpus."}, {"title": "4.1 Dataset", "content": "After collecting and structuring the data, the three types of legal\ndocuments had the following atomic parts of data, either as sections\nin the constitution and statutes or cases from case law:\n\u2022 Constitution: 265 sections\n\u2022 Statutes: 28,251 sections\n\u2022 Case Law:\nCourt of Appeals: 10,072 cases\nSupreme Court: 5,727 cases\nFigure 2 shows the trends in the 5,727 Supreme Court and 10,072\nCourt of Appeals cases over the years, as they were available from\nJustia [5], which also includes the expansions and creations of the\ncourts themselves."}, {"title": "4.2 Decomposition", "content": "The four component data types were decomposed hierarchically\nwith NMFk. The vocabulary for building the TF-IDF matrix was\ncollected using specific parameters for each part. For the Consti-\ntution vocabulary, the minimum token document frequency (DF)\nwas set to 5 documents, with a maximum token DF of 80% of the\ncorpus, resulting in a final size of 416 tokens. For the Statutes vo-\ncabulary, the minimum token DF was set to 30 documents, with\na maximum token DF of 70% of the corpus, yielding 7,508 tokens.\nThe Court of Appeals vocabulary used a minimum token DF of 50\ndocuments (cases) and a maximum token DF of 70% of the corpus,\nresulting in 10,189 tokens. Last, the Supreme vocabulary employed\na minimum token DF of 50 papers and a maximum token DF of\n70% of the corpus, with a final size of 8,425 tokens. The maximum\ndepth was set to 2, of which only the constitution sections did not\nreach due to the limited number of sections. The limiting factor\nof further decompositions was 100 documents, so if the preceding\ncluster had \u2265 100, the cluster would decompose and stop otherwise.\nAs seen in Figure 3a, the largest H-cluster is from cluster 4 in dark\nblue with 49 sections, with the fewest documents in yellow with\nsix sections in H-cluster 0. The other three decompositions can\nbe examined in the larger Figure 3, where the court cases, there\nare 10 leaf H-clusters in the constitution decomposition, 985 leaf\nH-clusters in the statutes decomposition, 420 leaf H-clusters in the\nCourt of Appeals cases, and 248 leaf H-clusters in the Supreme\nCourt cases. From the methods in [49], each H-cluster throughout\nthe decomposition hierarchies has LLM-generated labels for ease\nof reference and quick insight. Labels for the first decomposition\ndepth for the constitution can be observed in Table 1, the statutes\nin Table 2, the Supreme court in Table 4, and the appeals in Table 3.\nThe depth-0 H-clustering corresponds to the first ring radial from\nthe center totals in Figure 3."}, {"title": "4.3 Knowledge Graph", "content": "The four data parts, 265 constitutional provisions, 28,251 Statute sec-\ntions, 5,727 Supreme Court cases, and 10,072 Court of Appeals cases,\nwere inserted into the neo4j [37] knowledge graph. The graph's\nnumber of nodes and edges can be seen in Table 5, where edge\ncounts are where the triplet's tail originates with the row's node.\nThe legal citations were collected by iterating the text of each case\nor section into chat-gpt-3.5-turbo with the following prompt: \"You\nare an expert legal document analyzer. Your job is to find all refer-\nences to the Constitution, Case Law, or Statutes in the text.\" The\nresult was that the LLM acted like a named entity extractor, such\nthat any citations in the text were pulled out in an enumerated list.\nThe citations mainly included the cases, statutes, and constitution\nof New Mexico but also had references to the United States Consti-\ntution, New Mexico Administrative Code, and New Mexico Rules\nAnnotated (NMRA). The NMRA had many references to Uniform\nJury instructions and the rules of criminal and civil proceedings.\nIn figure 4, the NMFk topic cluster keyword and a bag of word\nvocabulary were both queried for 'estoppel. The NMFk keyword is\nDark blue, the topics are light blue, and the BOW node is brown.\nThree documents occur for this keyword: the statutes are green\nnodes, the Court of Appeals cases are yellow, and the Supreme\nCourt cases are orange. The constitution neither clustered over\nthe term nor mentions it, which is not represented in Figure 4.\nThere is a partition in the nodes at the brown bag of words node\nsince all nodes with the NMFk keyword have the bag of word node\nconnection. Still, not all documents mentioning 'estoppel' were\nclustered with the word, which is to say other terms and concepts\nfrom those terms had more importance for the documents on the left\nside of the image that 'estoppel'. There are 14 topics, 441 Court of\nAppeals cases, 276 Supreme Court Cases, and 131 Statutes in Figure\n4. These topics have 'estoppel' in their top keywords, whereas\nif every topic that contained 'estoppel' in its words were called,\nthere would be 341 topics. Of the 14 topics, one was connected to\nthe Statutes, \u201cCollection and recovery of liabilities made to board members with errors and\nomissions.\u201d Three of the 14 topics were connected to supreme court\ncases: \u201cEmployment Rights and Property Disputes in New Mexico Municipal Affairs\u201d, \u201cPublic\nCorporation Property Taxation Matters and Disputes with Licensing Authorities\u201d, \u201cDrilling and Gas\nAgreement Terms Regarding Oil Wells.\u201d Finally, the remain 10 of the 14 topics\nwith 'estoppel' in its top words were connected to cases from the\nCourt of Appeals: \u201cLitigation outcomes and jurisdictional limitations\u201d, \u201cAdministrative\nLicense Revocation Proceedings by Division Officers\u201d, \u201cLegal Proceedings and Litigation Issues in a\nMedical Context\u201d, \u201cCorporate Governance and Financial Management Matters\u201d, \u201cDispute Resolution\nProcess for Agricultural Property Transactions\u201d, \u201cMotor Vehicle Administrative License Actions\u201d,\n\u201cInsanity Defense Expert Witness Testimony\u201d, \u201cMalpractice claim within time constraints\u201d, \u201cEmployer\nLiability for Federal Disability Claims Against Administration Agencies\u201d, \u201cCriminal offenses and\ndoctrine involve multiple types of larceny charges\u201d, \u201cCollection and recovery of liabilities made to\nboard members with errors and omissions\u201d, \u201cPublic Corporation Property Taxation Matters and\nDisputes with Licensing Authorities\u201d, \u201cEmployment Rights and Property Disputes in New Mexico\nMunicipal Affairs\u201d, \u201cDrilling and Gas Agreement Terms Regarding Oil Wells.\u201d"}, {"title": "4.4 Query Cross Comparison", "content": "Questions were formulated to query information about legal con-\ncepts from LLM channels. There were five questions from each"}, {"title": "4.5 Question Answering", "content": "To evaluate the effectiveness of our QA SLIC-SMART system, we\nconducted a series of experiments focusing on various performance\nmetrics. Figure 6 shows various retrieval methods from the em-\nbedding space. The four data sources are treated separately for\ncomparison. Each data source uses four separate methods to embed\nthe data. The first is the entire corpus of each, where all documents\nare put into a single vector store. Where the text was short and\nstructured, this had top 10 retrieval percentages more significant\nthan 70 to 80%, such as the statutes and constitutional provisions.\nThe cases had less structure and longer text, making the plain\nembedding challenging. Next is the chunking method, where the\nentire dataset is again placed into a single dataset but chunked\nat 3000 characters with 500 overlapping. The top row, with more\nconcise and structured concepts, decreased slightly in performance,\nwhereas the cases significantly improved. This is likely because the\nconcepts are broken down across multiple texts instead of being in\none coherent text to query. Still, with the decrease, the structured\ntexts outperformed the cases by more than 20%. Third, the NMFk\nhierarchical cases are incorporated into the vector store process,\nwhere each topic has an individual vector store. The topics per\nquery were controlled such that the query was searched in the vec-\ntor store corresponding to the question origin. Topic identification\nin the vector store is an outstanding problem for future work. When\nthe NMFk hierarchical topics were introduced, the performance\nsignificantly improved across all data sources, with the most sig-\nnificant gains in the longer case texts. When the chunking process\nwas incrementally added on top of the NMFk topics, the cases still\nimproved, again likely to break up much larger texts into more\nmeaningful segments of the texts. In contrast, the structured texts\nin the constitutional provisions and the statutes slightly decreased\nperformance, likely attributed to the splitting of concepts in the\nquestions across several chunks. Still, NMFk topics with chunk-\ning and correct topic identification outperform the other methods\noverall."}, {"title": "4.5.1 Case Studies", "content": "To illustrate the practical applications and ef-\nfectiveness of the QA Smart-Slic system, we present four detailed\ncase studies:\n(a) Case Study 1 - Constitutional Analysis:\n\u2022 Question Source: Article IV, Section 22 [1]\n\u2022 Question: \"What happens to a bill if the governor neither returns it within\nthe specified three-day window (Sundays excepted) nor signs it?\"\n\u2022 Response: According to Article IV - Legislative Department - \u00a7 22 \"Governor's\napproval or veto of bills\" of the provided text, if a bill is presented to the gover-\nnor and he neither returns it within the specified three-day window (Sundays\nexcepted) nor signs it, then the bill becomes a law automatically, whether signed\nby him or not, unless the legislature by adjournment prevents such return.\n(b) Case Study 2 - Statutory Analysis:\n\u2022 Question Source: Chapter 50, Article 17, Section 3 [4]\n\u2022 Question: \"Under the Healthy Workplaces Act, how does an employee accrue\nand utilize earned sick leave, and what provisions exist for its carryover,\nuse for family or personal health, and reinstatement after separation from\nemployment?\"\n\u2022 Response: Accrue: Employees accrue a minimum of one hour of earned sick\nleave for every thirty hours worked. Employers may elect to provide the full\nsixty-four hours of earned sick leave for the year on January 1 or pro-rata for\nmid-year hires.\nUse: Earned sick leave can be used for the employee's or their family members'\nillness, injury, health condition, medical care, or preventive medical care. It can\nalso be used for issues related to domestic abuse, sexual assault, or stalking.\nCarryover: Unused earned sick leave carries over year to year, although use\nmay be capped at 64 hours per twelve-month period, unless the employer sets a\nhigher cap.\nReinstatement: If an employee is rehired within twelve months of separation\nby the same employer, previously accrued and unused earned sick leave must be\nreinstated. Additionally, the employee is entitled to accrue additional sick leave\nupon re-commencement of employment.\n(c) Case Study 3 - Court of Appeals Case Law Analysis:\n\u2022 Question Source: KRM, Inc. v. Caviness, 1996 [3]\n\u2022 Question: \"In the case KRM, Inc. v. Caviness, what was the court's reasoning\nfor determining that the water rights established by Williams' 1963 declaration\ndid not belong to the land sold to Caviness?\"\n\u2022 Response: The court determined that the water rights established by Williams'\n1963 declaration were not appurtenant to the land sold to Caviness because there\nwas no evidence that the water had been used for irrigation on that land. Since\nthe appropriated water was never used for irrigation purposes on the property, it\ndid not qualify as appurtenant water rights that would automatically transfer\nwith the land. The court concluded because the usage of the water was unrelated\nto the benefit or use of the land itself, the water rights remained separate and\ndid not pass to Caviness when he purchased the land.\n(d) Case Study 4 - Supreme Court Case Law Analysis:\n\u2022 Question Source: Smith v. South, 1955 [2]\n\u2022 Question: \"In Smith v. South, what were the legal issues raised regarding\nthe enforceability of the Washington child support decree in New Mexico,\nand how did the court address the conflict between the parties' post-decree\nagreement and the original judgment?\"\n\u2022 Response: The legal issues raised in Smith v. South regarding the enforceability\nof the Washington child support decree in New Mexico included whether New\nMexico courts should acknowledge and enforce the original Washington decree\nfor child support or consider the modifications reportedly agreed upon by the\nparties after the decree. The conflict between the parties' post-decree agreement\nand the original judgment involved assertions that they had informally agreed\nto alter the child support payments stipulated by the Washington court.\nThe court addressed this issue by considering the jurisdictional and legal princi-\nples guiding child support enforcement across state lines. They emphasized the\nimportance of adhering to the formal judicial process. The court likely examined\nwhether the post-decree modifications had been legally formalized or approved\nby any court, and whether such modifications complied with the relevant child\nsupport enforcement laws, particularly under the Uniform Interstate Family\nSupport Act (UIFSA), though it wasn't explicitly mentioned in the text snippet.\nUIFSA provides mechanisms for establishing, enforcing, and modifying child\nsupport orders across state boundaries.\nIf the modifications were not legally recognized through a court process, the\noriginal Washington decree would remain enforceable in New Mexico, and any\ninformal or unratified agreements between the parties would not typically alter\nthe enforceability of the court-ordered decree. The court would focus on ensuring\nthat child support arrangements comply with legal standards to serve the chil-\ndren's best interests and that enforcement respects the authority of the original\njurisdiction (Washington) unless properly modified through legal channels."}, {"title": "5 CONCLUSION", "content": "This work introduced Smart-Slic, a generative Al framework tai-\nlored to the legal domain, leveraging RAG, vector stores, and a\nNeo4j-based knowledge graph constructed through NMFk. Our\napproach uses T-ELF with metadata and chunking strategies to\ncapture fine-grained H-clusters and minimize hallucinations to\nimprove reliability. By bridging structured and unstructured data-\nspanning constitutional provisions, statutes, and case law-, our\nsystem supports advanced semantic reasoning and dimensionally\nreduced insight into the latent structure of legal texts.\nExperimental results across multiple retrieval strategies show\nthat chunking, combined with hierarchical NMFk, improves accu-\nracy, particularly for large, unstructured case law datasets. Short,\nhighly structured documents, constitutional provisions, and statute\nsections benefit from minimal chunking, revealing the importance\nof aligning preprocessing approaches with data characteristics. We\ndemonstrated the framework's capability to derive interpretive\nlegal topics and precisely answer domain-specific queries by har-\nnessing topically segmented embeddings and explicit links within\nthe knowledge graph.\nDespite the positive results, challenges remain. Author attribu-\ntion in networks is incomplete, limiting the knowledge graph's\npotential for thorough precedent tracing and interlinking. Includ-\ning additional datasets-such as administrative codes and judicial\nrules-would provide richer context and increase the system's cover-\nage of a functioning state government. Moreover, systematically rec-\nonciling informal post-decree agreements with formal judgments\nis needed to model a more acute legal flow.\nThis framework marks a step forward in computational law\nand legal AI, demonstrating a scalable, interpretable method for\ndiscovering, retrieving, and reasoning over complex"}]}