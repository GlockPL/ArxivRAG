{"title": "FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning", "authors": ["Nicole Cho", "Nishan Srishankar", "Lucas Cecchi", "William Watson"], "abstract": "Financial intelligence generation from vast data sources has typically relied on traditional methods of knowledge-graph construction or database engineering. Recently, fine-tuned financial domain-specific Large Language Models (LLMs), have emerged. While these advancements are promising, limitations such as high inference costs, hallucinations, and the complexity of concurrently analyzing high-dimensional financial data, emerge. This motivates our invention FISHNET (Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert swarming, and Task planning), an agentic architecture that accomplishes highly complex analytical tasks for more than 98,000 regulatory filings that vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows remarkable performance for financial insight generation (61.8% success rate over 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to empirically prove the success of FISHNET, each agent's importance, and the optimized performance of assembling all agents. Our modular architecture can be leveraged for a myriad of use-cases, enabling scalability, flexibility, and data integrity that are critical for financial tasks.", "sections": [{"title": "1 Introduction", "content": "Agent-Based Modeling (ABM) in finance has traditionally focused on simulating the interactions amongst market participants or simulating economic scenarios [21]. In the realm of financial insight generation, traditional methods of knowledge graph construction have proliferated the research arena [11]. In this context, ABM to generate financial intelligence from multiple knowledge bases is a relatively unexplored realm of research for AI in finance. Moreover,"}, {"title": "2 Related Work", "content": "2.0.1 Swarm Intelligence. Multiple studies have delved into the subject of Swarm Intelligence (SI). In particular, AFSA (Artificial Fish Swarm Algorithm) strives to mimic the behavior of fish via a stochastic method that searches for a myriad of solutions in a randomized procedure [25]. AFSA emulates three main behaviors that schools of fish exhibit: the first behavior is preying, the second is swarming, where fish tend to avoid danger by assembling in a group, and the third is executing without explicit leadership, via a biological organ that detects infinitesimal pressure changes in neighboring environments [30]. Thus, AFSA initializes n randomly distributed artificial fish across the search space, where n is the population size. Each fish searches for positions with higher fitness values - ultimately, at the end of each iteration, the position with the best fitness value is compared with the previously archived solution in AFSA's bulletin board. If the new position is better, the bulletin will be updated. This iteration persists until the stop criterion is met [25]. Rosenberg et al. [30] dives deeper in his recent study on collective super intelligence enabled via LLM agents. These agents serve as the organ that can participate in simultaneous actions and communicate with each other. A key characteristic of SI is that there is no central entity that orchestrates task management.\n2.0.2 LLMs and Harmonization/Orchestration. Pichlmeier et al. [24] introduces the highly modular architecture of Expert Router that orchestrates the performance of multiple experts - diving deep into the capabilities of an LLM to serve as the central harmonizer of experts. Similarly, Mohammadshahi et al. [19] investigates the abilities of an LLM-based orchestrator that can effectively pick the expert agents for optimized task execution with regards to the input query. It is important to highlight that orchestration diverges from Mixture of Experts (MoE) modeling as the latter requires the router to select experts from the MoE layer; the MoE layer can then be distributed through multiple GPUs via Model Parallelism or Expert Parallelism techniques [10]. In contrast, orchestration does not imperatively demand that the experts be housed in a single layer. The efficient role of LLMs as an orchestrator will be leveraged in FISHNET.\n2.0.3 LLMs and Neural-Conditioning. Li et al. [15] has delved into the emotional intelligence capabilities of LLMs and how contextual"}, {"title": "3 Methodology", "content": "3.1 Sub-querying Agent\nAs a query is imposed to FISHNET, the sub-querying process consists of firstly assessing the query's quality or probability of hallucination, leveraging HalluciBot [38, 40]. We utilize HalluciBot's binary classifications of hallucinatory or non-hallucinatory queries to continuously iterate towards a positive class transition. This process is essential since vague or poorly-worded queries, especially in searching across multiple databases, can significantly hinder the effectiveness of the downstream process [9]. Then, the sub-querying process takes a query Q and outputs a set of q sub-queries: Q = {qo, q1, ..., qn}. To accomplish this, we leverage in-context learning (ICL) with an LLM to generate a sub-query q that is optimized for the task management or planning stage.\n3.2 Task Planning Agent\nThe Task Planning Agent's primary objective is to initialize the planning stage for each sub-query, collaborate with the Harmonizer Agent (Section 3.3), and update FISHNET's long-term memory with an optimized plan by leveraging the Swarm Intelligence (SI) generated by Expert Agents (Section 3.4). Firstly, the Task Planning Agent takes the sub-queries q and starts devising a plan that will accomplish the resolution of each sub-query. The first iteration of this planning process is done solely by the Task Planning Agent, that has been given few-shot examples and In-Context Learning (ICL) to have a basic understanding of what each Expert Agent can accomplish. Secondly, the Task Planning Agent communicates with the Harmonizer Agent which synthesizes the SI compiled by multiple Expert Agents. The SI can encompass heretofore unknown information for the Task Planning Agent - as the latter has only been trained with few-shot learning whilst the Expert Agents are comprehensive and detailed experts for their respective filings. Therefore, the Task Planning Agent can revise its initial plan and"}, {"title": "3.3 Harmonizer Agent", "content": "The Harmonizer Agent's prime focus is to communicate with each Expert Agent, synthesize the SI, and communicate it back to the Task Planning Agent; therefore, the initial plan can be refined using SI. The Harmonizer's next key role is to execute the optimized plan. In other words, while the Expert Agents retrieve the relevant data from their respective databases, the Harmonizer can aggregate, multiply, divide, or perform any arithmetic actions, by following the optimized plan."}, {"title": "3.4 Expert Agents", "content": "We assign an Expert Agent for each type of U.S. regulatory filing in the document ingestion pipeline. Each Expert will be fully capable of understanding all data fields in the filing, requirements, format, frequency of submission, and any other minute details. As regulatory filings differ immensely in all these aspects, a specialized agent for each filing will enable a truly modularized and expert-driven approach to assembling insights. For all filings, amendments to original filings are submitted on an ad-hoc basis - therefore, reconciliation across different timelines is key.\n3.4.1 N-PORT Agent. The N-PORT Agent fully comprehends and manipulates every single data field, ontology, hierarchy, filing entity (whether it is a fund, trust, or asset manager), and filing frequency for Form N-PORT. Form N-PORT or the Monthly Portfolio Investments Report is a mandatory filing for all registered management investment companies ('40Acts) or an Exchange-Traded Fund(ETF) that is organized as a Unit-Investment Trust (UIT). It is critical to note that this filing is not required for Money-Market Funds (MMFs). While filed every month, Form N-PORT is released every quarter regarding each fund's portfolio and each investment holding within the portfolio as of the last business day, or calendar day, of the last month in the quarter [1].\n3.4.2 N-MFP Agent. The N-MFP Agent precisely understands all key requirements and data fields of Form N-MFP. Form N-MFP is the monthly public reporting form used by money market funds required by section 30(b) of the Act and rule 30b1-7 under the Act (17 CFR 270.30b1-7). Similarly to Form N-PORT, Form N-MFP must report information about the fund and its portfolio holdings as"}, {"title": "3.4.3 ADV Agent", "content": "The ADV Agent is skilled at understanding the Investment Adviser Public Disclosure (IAPD) website and the two different forms that comprise Form ADV. Form ADV is filed annually by an Investment Advisor (IA) that has to register with the SEC or state authorities. It houses different types of information from N-PORT or N-MFP - such as business ownership, employees, clients, or disciplinary information pertaining [2]."}, {"title": "3.4.4 N-CEN Agent", "content": "The N-CEN Agent is an expert of Form N-CEN, an annual filing required for all registered investment companies ('40Acts), other than face-amount certificate companies. The Agent understands the frequency of submission as well as the precise data fields that include provision of financial support, principal underwriters, fund type, or investments in foreign corporations [1]. A notable point is that N-CEN can be submitted on a trust-level, with the trust referring to a group of funds."}, {"title": "3.4.5 N-CSR Agent", "content": "The N-CSR Agent is knowledgeable of Form N-CSR, the certified shareholder report for registered investment management companies. Form N-CSR carries highly valuable data as it houses audited financial statements, including each fund's Statement of Operations, Statement of Assets and Liabilities, or the Portfolio of Investments. The Agent is highly knowledgeable of every line item within the financial statements."}, {"title": "3.4.6 13F Agent", "content": "The 13F Agent retains expertise for Form 13F, required for investment managers pursuant to Section 13(f) of the Securities Exchange Act of 1934. Rule 13f-1(a) stipulates that investment managers which exercise discretion for accounts holding Section 13(f) securities with a a certain market value needs to file 13F [1]. Our Agent is highly skilled at understanding not only the ontology of 13F but also its unique filing structure."}, {"title": "4 Datasets", "content": "4.1 Preliminaries\nFor FISHNET's training dataset, we have ingested 98,034 U.S. regulatory filings for six different types of filings from EDGAR and IAPD. These six filing types differ immensely in terms of ontology, format, submission requirements, citations, and data hierarchies. Moreover, they serve as critical sources of information for retail investors, brokerage firms, asset managers, and corporate entities."}, {"title": "4.2 N-PORT Dataset", "content": "We ingest more than a full year's submission of N-PORT filings, starting from the 1st quarter of 2023 to the 2nd quarter of 2024. We have ingested a grand total of 40,372 original filings and 1,076 amendments that covers all portfolio holdings for all '40Act funds. We scrape these reports at a maximum throughput of 10 reports (SEC site limits for a single host). Once the filings are downloaded, we index each filing according to its unique ID."}, {"title": "4.3 N-MFP Dataset", "content": "Similarly to N-PORT, we ingest six quarters of filings into our data pipeline for N-MFP. This amounts to a grand total of 3,574 original filings and amendments. We extract and process the data into tables via indexing and chronological ordering."}, {"title": "4.4 ADV Dataset", "content": "We crawl the IAPD website to ingest Form ADV for the past year, counting 15,292 filings or more than 685,000 PDF pages in total."}, {"title": "4.5 N-CEN Dataset", "content": "We ingest 2,909 N-CEN filings for the past 6 quarters. N-CEN is an annual filing that can also be filed on a group level. Therefore, we reconcile the unique trust-level identifiers so every filing is indexed in a relational database."}, {"title": "4.6 N-CSR Dataset", "content": "2,756 N-CSR filings are ingested in our dataset for the past six quarters. Form N-CSR varies greatly from filer to filer and is a highly unstructured type of filing. The data ingestion pipeline for N-CSR is one of most robust, leveraging multiple Natural Language Processing (NLP) and computer vision techniques to process the data from these filings."}, {"title": "4.7 13F Dataset", "content": "For the past six quarters, we ingest 25,544 13F Holdings Reports, 5,353 13F Notices, 1,122 13F Holdings Reports Amendments and 36 13F Notice Amendments. This amounts to 32,055 unique filings and amendments. We create citational knowledge graphs to track the relationships between filers."}, {"title": "5 Metrics", "content": "We evaluate our experiments across three dimensions:\n(1) Retrieval - We use R-Precision across all queries to account for variable retrieval sizes.\n(2) Routing - We use accuracy to assess the LLM's effectiveness to route queries to the correct agents/tables in a zero-shot setting.\n(3) Agentic - We use the success rate of creating an accurate solution to judge the full system architecture."}, {"title": "5.1 R-Precision", "content": "R-Precision is a metric used to evaluate the performance of an information retrieval system. It is defined as the precision at R, where R is the number of relevant documents for a given query.\n$$R-Precision = \\frac{Relevant Docs. \\cap Retrieved Docs. at R}{R}$$\nIn the context of embedding-based retrieval, let R be the total number of relevant documents for a query. Then R-Precision is calculated as the proportion of relevant documents retrieved in the top R positions of the ranked list of retrieved documents. Therefore, R-Precision is equivalent to both the precision at the R-th position (P@R) and the recall at the R-th position."}, {"title": "5.2 Accuracy of Pathway Routing for Agents", "content": "In evaluating the performance of pathway routing for agents, it is essential to consider the conditional accuracy of correctly identifying the agent and subsequently selecting the appropriate subtable. This two-step accuracy measure ensures that the overall routing process is evaluated comprehensively.\n5.2.1 Definition. The accuracy of pathway routing is evaluated in two steps:\n(1) Agent Identification Accuracy: The proportion of instances where the correct agent, A, is identified, as $$Acc_{agent} = P(A)$$\n(2) Sub-table Identification Accuracy: Given the correct agent, A, is identified, the proportion of instances where the correct sub-table, S, is selected, as $$Acc_{subtable} = P(S | A)$$\nThe overall accuracy Accrouting can be considered as the product of these two accuracies, reflecting the conditional nature of the"}, {"title": "6 Experiments", "content": "6.1 Embeddings\nWe used text-embedding-ada-002 on each individual line item per table, as well on each table's and agent's metadata descriptions. Null value fields are dropped from the JSON representation. Across all agents and tables, this yields 5,052,421 vector embeddings at a"}, {"title": "6.2 Question Creation & Augmentation", "content": "We define 7 easy and 4 hard question templates and their canonical code solution to generate random samples. Each sample is curated such that a complete answer is guaranteed - the sampling source is from the total space of valid inputs that yields solutions. The original templates are useful for measuring the repeatability and reliability of our agent framework. To test the robustness of our system architecture, we inject noise into the templates by using gpt-3.5-turbo as a query re-writer to generate 2 variations. Each question is tagged with the appropriate route for the agent and table. Finally, each canonical solution is executed to produce a solution and the relevant records required for it."}, {"title": "6.3 Ablations and Results", "content": "6.3.1 Embedding Based (RAG). We embedded 5 million datapoints into 3 variable scopes: global, agent, and table level search spaces to test the most reliable retrieval for data discovery. R-Precision, our retrieval metric, demonstrates that hierarchical embedding data is preferable to a flat global structure (Table 3). The highest gain in R-Precision is drawn from NCSR, as a bespoke embedding space allows for a cleaner KNN retrieval on a single table (vs. 3 tables at the agent level).\n(1) Global each data row is indexed into one unified index. By inundating the search space with millions of distractor points, global measures the accretive value of segmented indexes by agents or tables. However, given that our agents and tables are subsets of the global embedding space, we do not directly ablate this split and hypothesize that, at best, it will perform equivalent to the table-level ablation.\n(2) Agent - each data row is indexed according to its respective agent. This partitions the search space to a single filing, measuring the intra-discriminative power of embeddings to retrieve when isolated from other filing and agent types.\n(3) Table - each data row is indexed per sub-table. Therefore, this hyper-local search space experiments with how well any RAG system could retrieve data within a single table, an alternative to SQL querying. In cases of perfect routing, this ablation explores the discriminative power of embeddings to discover valid records from irrelevant ones.\n6.3.2 Routing. We explore routing based methods, both embedding and generative. The Harmonizer agent (Section 3.3) would route to the correct expert agent leveraging a FAISS vector database populated with the embeddings of descriptions (Section 6.1) for each agent. The Expert agent (Section 3.4) uses a database containing the embeddings of a list of tables and the schema affiliated with each agent to perform routing. They are implemented as LangChain chained Retriever QA agents that treats the vector database as a retriever. To empirically assess the accuracy of pathway routing, we employ a confusion matrix to identify agents and conditional"}, {"title": "7 Conclusion", "content": "In conclusion, we propose FISHNET, a multi-agent system to generate sophisticated financial insights. FISHNET combines swarming, sub-querying, harmonizing, planning, and neural-conditioning in a single system, demonstrating robust performance of 61.8% in crafting accurate solutions while navigating a complex, hierarchical agent-table data structure. As a novel means of leveraging ABM for financial data analysis, FISHNET provides a tangible alternative to fine-tuning or database engineering. Future work on FISHNET can focus on fine-tuning for different types of datasets, possibly non-English financial datasets that differ greatly in format or semantics."}, {"title": "Disclaimer", "content": "This paper was prepared for informational purposes by the Artificial Intelligence Research group of JPMorgan Chase & Co. and its affiliates (\u201cJP Morgan\u201d) and is not a product of the Research Department of JP Morgan. JP Morgan makes no representation and warranty whatsoever and disclaims all liability, for the completeness, accuracy or reliability of the information contained herein. This document is not intended as investment research or investment advice, or a recommendation, offer or solicitation for the purchase or sale of any security, financial instrument, financial product or service, or to be used in any way for evaluating the merits of participating in any transaction, and shall not constitute a solicitation under any jurisdiction or to any person, if such solicitation under such jurisdiction or to such person would be unlawful."}]}