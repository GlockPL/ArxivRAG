{"title": "Towards Generalizable Scene Change Detection", "authors": ["Jae-woo Kim", "Uehwan Kim"], "abstract": "Scene Change Detection (SCD) is vital for applications such as visual surveillance and mobile robotics. However, current SCD methods exhibit a bias to the temporal order of training datasets and limited performance on unseen domains; coven-tional SCD benchmarks are not able to evaluate generaliza-tion or temporal consistency. To tackle these limitations, we introduce a Generalizable Scene Change Detection Frame-work (GeSCF) in this work. The proposed GeSCF leverages localized semantics of a foundation model without any re-training or fine-tuning-for generalization over unseen do-mains. Specifically, we design an adaptive thresholding of the similarity distribution derived from facets of the pre-trained foundation model to generate initial pseudo-change mask. We further utilize Segment Anything Model's (SAM) class-agnostic masks to refine pseudo-masks. Moreover, our proposed framework maintains commutative operations in all settings to ensure complete temporal consistency. Finally, we define new metrics, evaluation dataset, and evaluation protocol for Generalizable Scene Change Detection (GeSCD). Extensive experiments demonstrate that GeSCF excels across diverse and challenging environments-establishing a new benchmark for SCD performance.", "sections": [{"title": "Introduction", "content": "Scene Change Detection (SCD) (Radke et al. 2005) is es-sential in multiple applications including visual surveillance(Wu et al. 2020), anomaly detection (Huang et al. 2022),mobile robotics (Nehmzow et al. 2000), and autonomousvehicles (Janai et al. 2017). SCD involves identifying thechanges in the current scene compared to those at differenttime steps. The SCD task is challenging due to various fac-tors such as illumination variations, seasonal changes, andweather conditions. To cope with these challenges, recentstudies in SCD have leveraged deep-learning algorithms toextract discriminative and robust features that can effectivelydistinguish meaningful changes in a scene.\nHowever, current deep learning-based SCD methodshardly display the reported performance when applied out-side the temporal conditions or environments in which theywere trained. Concretely, they tend to memorize the tempo-ral sequence of scenes in the training set-leading to incon-sistent predictions between t0 (reference) \u2192 t1 (query) andt1 (reference) \u2192 t0 (query). Moreover, their performance"}, {"title": "Generalizable Scene Change Detection", "content": "Generalizable Scene Change Detection (GeSCD). We measure the intersection between two temporal order predictions to evaluate the temporal consistency quantitatively. Further, we propose a new evaluation dataset-the ChangeVPR dataset-to assess the robustness of SCD approaches in various unseen environments, including urban, suburban, and rural settings. Existing real-world SCD datasets, which only contain a few urban scenarios, do not reflect the diversity of the scene images-highlighting the importance of our contribution. Extensive experimental results demonstrate that the proposed GeSCF significantly outperforms prior state-of-the-art methods in detecting changes in unseen domains without any training and performs on-par with the fine-tuned SCD models for specific datasets.\nIn summary, our contributions are the following:\n1. Problem formulation: We define GeSCD that induces arobust SCD algorithm regardless of temporal order andenvironmental factors. To the best of our knowledge, thisis the first comprehensive effort to address the general-ization problem in SCD research with a substantial per-formance gain in unseen domains.\n2. Model design: We design a GeSCF that utilizes localizedsemantics of a foundation model and their similarity dis-tribution to generate robust change masks in addition tobi-temporal mask refinement using SAM's class-agnosticmasks.\n3. Benchmark set up: We propose a set of new metrics,evaluation dataset, and evaluation protocols that effec-tively measures an SCD model's generalizability andtemporal consistency under comprehensive conditions.\n4. Ablation study: We design and conduct a set of exten-sive ablation studies to reveal crucial insights for con-structing generalizable SCD models."}, {"title": "Related Works", "content": "Change Detection: Change Detection (CD) research largelyfalls into three categories based on the data characteristic:remote sensing CD, video sequence CD, and indoor/outdoor scene CD (ours). First, remote-sensing CDs handle datacollected from satellite or aerial platforms to detect surfacechanges in area over time. Several works proposed super-vised (Saha et al. 2022; Chen et al. 2022; Bernhard, Strau\u00df,and Schubert 2023), semi-supervised (Hao et al. 2023; Ban-dara and Patel 2022), and unsupervised frameworks (Berga-masco et al. 2022; Noh et al. 2022) in remote sensory scenesto overcome data scarcity. Moreover, video sequence CDs(Mandal et al. 2020; Akilan et al. 2020) focus on segment-ing a frame into the foreground and background regions cor-responding to object motion. These CD approaches, how-ever, assume perfect alignment between query and referenceimages-an assumption often fails in real-world settings. Inour work, we would focus on indoor/outdoor Scene CD andrefer to the task as SCD.\nScene Change Detection (SCD): For SCD, CDNet(Sakurada et al. 2017) concatenates bi-temporal images andtheir estimated optical flow to obtain change masks. CSCD-Net (Sakurada, Shibuya, and Wang 2018) utilizes two cor-relation layers (Dosovitskiy et al. 2015), then concatenate"}, {"title": "Generalizable Scene Change Detection Framework", "content": "We aim to incorporate robust features from a foundationmodel to make a generalizable SCD algorithm over temporalconditions and unseen domains. The key idea of GeSCF is asfollows: we intercept and correlate the foundation model'sfeatures to get rich similarity distribution and transformthem into binary pseudo-change masks by adaptively thresh-olding the low-similarity pixels with a skewness-based al-gorithm, unlike previous approaches that directly transferthe features from the pre-trained model. Moreover, We uti-"}, {"title": "Similarity Distribution and Sample Skewness", "content": "Inspired by previous studies (Amir et al. 2021; Caron et al.2021; Kirillov et al. 2023) that have empirically demon-strated that attention maps can capture semantically salientobjects, we correlate facet features (one of Key, Query, andValue) from the SAM ViT layer. Specifically, given a bi-temporal RGB image pair ($I_{t0}, I_{t1}$), we intercept the facetembeddings $F_{t0}^{m,n}$, $F_{t1}^{m,n} \\in R^{NXHXW}$ respectively, for them-th head from the n-th ViT layer. Then, we compute simi-larity distribution $M_{t0\\leftrightarrow t1}^{m,n}$ of image pair as follows:\n$P_{t0t1}^{m,n} = \\frac{F_{t0}^{m,n} \\cdot F_{t1}^{m,n}}{||F_{t0}^{m,n}||* ||F_{t1}^{m,n}||}$ (1)\n$M_{t0\\leftrightarrow t1}^{m,n} = \\frac{1}{M} \\sum_{m=1}^{M} \\S(P_{t0t1}^{m,n})$ (2)\nwhere $\\S(.)$ performs spatial reshaping and bilinear interpola-tion to the input image size. The correlation in (1) is a com-mutative operation that generates identical distribution evenwith the reversed order. Furthermore, we compute the sam-ple skewness $g_1$ of the distribution as follows:\n$g_1 = \\frac{k}{(k-1)(k-2)} \\sum_{i=1}^{k} (\\frac{m_i - m}{s})^3$ (3)"}, {"title": "Initial Pseudo-change Mask Generation", "content": "Initial Pseudo-change Mask: With the similarity distribu-tion $M_{t0\\leftrightarrow t1}$ and sample skewness $g_1$, we generate initialpseudo-change mask $Y_{ps}^{t0\\leftrightarrow t1}$ as follows:\n$Y_{ps}^{t0t1} = \\begin{cases}\n[\\Pi(\u017b(M_{t0\\leftrightarrow t1}), F(g_1)), I \\in D_{skewed}]\n[\\Pi(Z(M_{t0\\leftrightarrow t1}), F(g_1)), I \\in D_{moderate}\n\\end{cases}$ (4)\nwhere Z and 2 refer to Z-score and modified Z-score, re-spectively, F(.) is an adaptive thresholding function and\u03a0(\u00b7) applies an element-wise binary threshold computedfrom F() that formulates similarity distribution into binarychange masks. Modified Z-score, or Median Absolute Devi-ation (MAD), is a simple and effective statistical method todetect outliers in the skewed distribution.\nAdaptive Thresholding Function: Instead of using sev-eral constant thresholds for different change types, we definean adaptive thresholding function to elaborate the thresholdfrom two perspectives. One is the different base thresholdsin each case; we apply a much lower threshold for right-skewed cases than left-skewed cases to reflect the contextof the changes mentioned above. The other is the awarenessof the long-tail and bulk distribution; we avoid encountering sharp drops or rises in the distributions by strengthening thethreshold to the highly skewed cases. Finally, we define thethresholding function as:\nF(g1) = \\begin{cases}\nB_{left} - c_k \\cdot S_{left} \\cdot g_1, I \\in D_{left-skewed}\nZ_c\\\\\nB_{right}+c_k \\cdot S_{right} \\cdot g_1, I\\in D_{right-skewed}\n\\end{cases} (5)\nwhere $B_{left}$ and $B_{right}$ refer to the base thresholds, $S_{left}$ and$S_{right}$ represent the sensitivity to the each skewness. $c_k$ isa normalization factor regarding k and $Z_c$ corresponds to z"}, {"title": "Bi-temporal Mask Refinement", "content": "Although similarity distribution and homography warpingprovide reasonable pseudo masks for the possible changes,a set of unchanged parts of the distribution hold low similar-ity scores and depth variation during transformation createsnoise in the initial pseudo-change masks. To resolve this, weleverage SAM masks to obtain detailed location and struc-ture of the scene semantics. We calculate the intersectionbetween pseudo-change masks and SAM-generated class-agnostic masks to obtain high-quality change masks. We se-lect masks that show \u03b1>\u03b1t as the final mask $Y_{pred}^{t0\\leftrightarrow t1}$, where"}, {"title": "Generalizable Scene Change Detection", "content": "Overview: We propose GeSCD with novel metrics, evalu-ation dataset, and evaluation protocol to address the general-izability over unseen domains and robustness under differenttemporal conditions of SCD algorithms. Our task approach,distinctive from conventional methods, effectively addressesthe critical need for SCD research that is genuinely general-izable and effective across diverse settings.\nMetrics: We report the F1-score, the harmonic mean of pre-cision and recall, for both temporal directions, in contrast toprevious methods that only report the performance of a sin-gle temporal prediction. Furthermore, we propose TemporalConsistency (TC) by measuring the union intersection be-tween t0 \u2192 t1 (t0) and t1 \u2192 t0 (t1) predictions as follows:\nTemporal Consistency (TC) = $\\frac{Y_{pred}^{t0\\leftrightarrow t1} \\cap Y_{pred}^{t1\\leftrightarrow t0}}{Y_{pred}^{t0\\leftrightarrow t1} \\cup Y_{pred}^{t1\\leftrightarrow t0}}$, (6)\nwhere the proposed TC score indicates how much the SCDalgorithms can generate consistent change masks in bi-directional orders.\nEvaluation Datasets: Table 2 summarizes the evaluationdatasets. First, we consider three standard SCD datasetswith different characteristics: VL-CMU-CD (Alcantarillaet al. 2016), TSUNAMI (Sakurada and Okatani 2015), andChangeSim (Park et al. 2021). These datasets represent ur-ban environments in the USA, disaster-impacted urban ar-eas in Japan, and industrial indoor settings within simula-tion environments, respectively. Furthermore, for the quan-titative evaluation of the proposed generalizable approach,we create a new dataset named the ChangeVPR. TheChangeVPR comprises 529 image pairs collected from theSF-XL (Berton, Masone, and Caputo 2022), St Lucia (Mil-ford and Wyeth 2008), and Nordland (S\u00fcnderhauf, Neubert,and Protzel 2013) datasets, which are widely used in Vi-sual Place Recognition (VPR) research. We carefully sam-pled image pairs from each dataset to reflect various SCDchallenges such as weather conditions and seasonal changes,and hand-labeled the ground-truth change masks for image"}, {"title": "Results and Analysis", "content": "Implementation Details\nWe use the SAM ViT-H encoder, pre-trained on the SA-1Bdataset, to extract facet features and obtain initial pseudo-change masks. We set N\u2081=-0.2, N\u2081=0.2, and c=-0.52to categorize the distribution types. For adaptive threshold-ing function, we set Bleft=0.7, Bright=0.1, Sleft=1.0, andSright=0.1. Especially, GeSCF requires no further tuning forhandling unseen data-sharing the same hyperparameters.\nComparative Studies\nWe compare our method with four open-source deeplearning-based SCD algorithms: CSCDNet, CDResNet(Sakurada, Shibuya, and Wang 2018), DR-TANet, and C-3PO. For the C-3PO, we adopt the (I+D) structure forthe VL-CMU-CD and the (I+A+D+E) structure for theTSUNAMI and ChangeSim datasets, following the config-urations proposed in the paper. For the ChangeVPR, we dis-play baselines trained on the VL-CMU-CD, which containsmore general images than the others. Further comparisonsare provided in the supplementary material."}, {"title": "Ablation Studies", "content": "We conduct a component-wise analysis of GeSCF. Tabl 6shows the quantitative results of the ablations.\nEffect of Adaptive Thresholding Function: We imple-ment thresholding functions with various statistical methodsthat utilize constant thresholds, including Z-score and Mod-ified Z-score. Experiments show that Modified Z-score ob-tains better performance than the naive Z-score, while ourskewness-based adaptive method achieves the best.\nEffect of Selective Warping: In the VL-CMU-CD andTSUNAMI datasets which mostly contains image pairswith almost perfect alignment, warping all the images ob-tains lower performance than not warping. On the contrary,ChangeSim shows the significant performance gain throughwarping, where the dataset contains a lot of imperfectlymatched image pairs. Overall, our selective warping yieldsthe best performance in all settings.\nEffect of Mask Refinement: We report the performanceof the model solely using initial pseudo-change masks. Al-"}, {"title": "Conclusion", "content": "In this study, we attempted to address the generalization ofSCD using a foundation model for the first time to the best ofour knowledge; we define GeSCD along with the novel met-rics, evaluation dataset (ChangeVPR), and evaluation proto-cols to effectively assess the generalizability of SCD models.Further, we proposed GeSCF, a generalizable approach forthe SCD task using the localized semantics of the founda-tion model that does not require costly SCD labeling. Ex-tensive experiments demonstrated that the proposed GeSCFsignificantly outperforms existing SCD models on unseendomains and matches fine-tuned models on seen domainswhile achieving complete temporal consistency. We expectour methods can serve as a solid step towards robust andgeneralizable Scene Change Detection research."}]}