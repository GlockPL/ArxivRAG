{"title": "Iterated Local Search with Linkage Learning", "authors": ["RENATO TIN\u00d3S", "MICHAL W. PRZEWOZNICZEK", "DARRELL WHITLEY", "FRANCISCO CHICANO"], "abstract": "In pseudo-Boolean optimization, a variable interaction graph represents variables as vertices, and interactions between pairs of variables as edges. In black-box optimization, the variable interaction graph may be at least partially discovered by using empirical linkage learning techniques. These methods never report false variable interactions, but they are computationally expensive. The recently proposed local search with linkage learning discovers the partial variable interaction graph as a side-effect of iterated local search. However, information about the strength of the interactions is not learned by the algorithm. We propose local search with linkage learning 2, which builds a weighted variable interaction graph that stores information about the strength of the interaction between variables. The weighted variable interaction graph can provide new insights about the optimization problem and behavior of optimizers. Experiments with NK landscapes, knapsack problem, and feature selection show that local search with linkage learning 2 is able to efficiently build weighted variable interaction graphs. In particular, experiments with feature selection show that the weighted variable interaction graphs can be used for visualizing the feature interactions in machine learning. Additionally, new transformation operators that exploit the interactions between variables can be designed. We illustrate this ability by proposing a new perturbation operator for iterated local search.", "sections": [{"title": "1 INTRODUCTION", "content": "Local search is a simple strategy which is effective in a wide variety of combinatorial optimization problems [Papadimitriou and Steiglitz 1998]. Local search systematically explores a neighborhood of the current candidate solution. An initial solution is improved in a step-by-step manner until a local optimum is found. The basin of attraction of a local optimum x is defined by the subset of candidate solutions that converge to x under the specific local search strategy."}, {"title": "2 BACKGROUND", "content": "We are interested in pseudo-Boolean optimization, where the evaluation (fitness) function is $f : B^N \\rightarrow R$, and $B = {0, 1}$. Let $f(x \\oplus 1_g)$ denote the fitness of a solution $x \\in B^N$ after flipping the g-th bit, where $\\oplus$ is the XOR bitwise operation and $1_g \\in B^N$ denotes a characteristic vector with the g-th element equal to one and all the other elements equal to zero. Using the same notation, $f(x \\oplus (1_h + 1_g))$ is the fitness of a solution $x \\in B^N$ after $x_h$ and $x_g$ are flipped.\nWe will also denote the difference in the evaluation $f(x)$ when the g-th bit is flipped by $\\delta_g(x)$. Thus:\n$\\delta_g(x) = f(x \\oplus 1_g) - f (x)$.\nWhen variable $x_g$ is flipped after flipping $x_h$, the difference is denoted by:\n$\\delta_g(x \\oplus 1_h) = f (x \\oplus (1_h + 1_g)) - f (x \\oplus 1_h)$.\nLet us consider that a first-improvement local search strategy LS(.) is applied for maximizing pseudo-Boolean functions according to the following definition.\nDefinition 2.1. In the local search strategy LS(.):\ni. One bit (decision variable) is flipped each time;\nii. A tabu mechanism ensure that the g-th bit is flipped again only after all other bits are flipped;\niii. Given a solution x, the flip in the g-th bit is accepted only if $\\delta_g (x) > 0$;\niv. The search stops when no improvement is found.\nAlg. 1 shows the pseudo-code of LS(.)\u00b9. The order for flipping the decision variables is defined by random vector R.\nAny pseudo-Boolean function $f : B^N \\rightarrow R$ can be represented in the following polynomial form [Heckendorn 2002]:\n$f(x) = \\sum_{i=0}^{2^N-1} w_i\\psi_i(x)$,\nwhere $w_i$ is the i-th Walsh coefficient, $\\psi_i(x) = (-1)^{i \\cdot x}$ generates a sign, and $i \\in B^N$ is the binary representation of index i. Walsh coefficients can be used for identifying nonlinear interactions between variables. The interaction between variables is defined as follows."}, {"title": "3 LOCAL SEARCH WITH LINKAGE LEARNING 2", "content": "In DLED, when a variable $x_h$ is perturbed in a solution x, the dependencies between $x_h$ and other variables are searched. Consider that y is the solution generated by flipping $x_h$ in x. Now, consider that a variable $x_g$, $g \\neq h$, is flipped in x and y. If flipping $x_g$ results in an improvement in one solution, e.g., x, but not in the other, e.g., y, then variables $x_g$ and $x_h$ interact. DLED never returns a false linkage, i.e., an edge not present in the VIG [Przewozniczek et al. 2021]. However, it can miss some linkages (the same is true for the method proposed in this section). In other words, DLED returns an empirical VIG that is a partial or complete VIG. A disadvantage is that the DLED-based linkage discovery (the construction of an empirical VIG) requires performing a relatively high number of additional solution evaluations.\nTin\u00f3s et al. [2022] used some ideas of DLED in LSwLL to build an empirical VIG during the optimization performed by ILS. There are two main differences between LSwLL and DLED. First, unlike DLED, the strategy does not need additional fitness evaluations for building the empirical VIG. Second, instead of checking improvements as DLED does, the strategy checks the difference in the fitness of the solutions with flipped variables. Thus, it is able to find a linkage between two variables even when flipping both results in improving moves.\nGiven a candidate solution x, let us define:\n$\\Theta_{g,h}(x) = |\\delta_g(x \\oplus 1_h) - \\delta_g(x)|$\nwhere $\\delta_g(x)$ and $\\delta_g(x \\oplus 1_h)$ are respectively given by equations (1) and (2). Tin\u00f3s et al. [2022] show that if $\\omega_{g,h}(x) \\neq 0$ for any candidate solution $x \\in B^N$, then variables $x_h$ and $x_g$ of f interact (according to Definition 2.2) and (h, g) is an edge of the VIG. Thus, while optimizing a candidate solution, LSWLL flips decision variables of the candidate solution in a specific order to detect edges of the VIG.\nBased on LSWLL, we propose LSwLL2, that builds an empirical weighted VIG instead of an empirical VIG. We propose using Eq. (4) to define the strength of the interaction between variables.\nDefinition 3.1. Given a pseudo-Boolean function $f : B^N \\rightarrow R$, the strength of the interaction between variables $x_h$ and $x_g$ in f (Definition 2.2) is given by:\nv(h,g) = $\\frac{1}{2^N} \\sum_{x\\in B^N} \\omega_{g,h}(x)$\nwhere $\\omega_{g,h}(x)$ is given by Eq. (4). Strength is symmetric. i.e., $v(h, g) = v(g, h)$.\nDefinition 3.2. The weighted variable interaction graph (VIGw) is an undirected weighted graph G = (VG, EG, WG), where each vertex $v_g \\in VG$ is related to a decision variable $x_g$, and each edge"}, {"title": "4 VIGW-BASED PERTURBATION", "content": "Defining an optimal or suboptimal perturbation strategy is not trivial. If the perturbation is too strong, ILS often becomes similar to a multi-trial algorithm with random restarts, i.e., there is little correlation between two consecutive local optima generated by ILS. On the other hand, if the perturbation is too weak, then frequently the two consecutive local optima are equal because the perturbed solution is located at the same basin of attraction of the current local optimum. In general, consecutive local optima generated by ILS should be close [Brand\u00e3o 2020]. In addition, the evaluation of close local optima is similar in many combinatorial optimization problems. In this way, jumping between distant local optima often generates a new optimum with less similarity to the current local optimum than when the jumps are between close local optima [Brand\u00e3o 2020]. The standard approach for perturbing a solution in ILS is to randomly change a decision variables of the current local optimum. When the domain of the candidate solutions is formed by binary strings, this strategy flips a randomly selected subset with \u03b1 bits. Clearly setting good values for \u03b1 depends on fitness landscape properties. Adaptive approaches were proposed for avoiding too weak or too strong perturbations [Dowsland and Thompson 2012; Hansen and Mladenovi\u0107 2003]. Strategies were also proposed for selecting subsets of variables to be changed based on the visited solutions or the importance of decision variables, instead of doing so by using uniform distribution [Battiti and Protasi 1997; Brand\u00e3o 2020; L\u00fc and Hao 2009]. Ideally, a perturbation should maximize the number of flipped variables (distance between solutions) but also minimize the fitness difference between the old and new solutions. One strategy for doing this is to pick the best of a subset of random solutions. However, this requires evaluating solutions in this subset and, as a consequence, increasing the number of fitness evaluations. Alternatively, Tin\u00f3s et al. [2022] propose to use the number of changes that occur in the nonzero Walsh coefficients in Eq. (3) to estimate the fitness difference. The VIG-based perturbation (VIGbP) basically changes a random decision variable and its neighbors in the VIG. The main disadvantage of VIGbP is that when the VIG is too dense, i.e., there are many variables interacting with the random variable, then VIGbP behaves like the standard random perturbation approach, where \u03b1 random variables are flipped.\nTo avoid this problem, we propose here the VIGw based perturbation (VIGwbP). If the VIGw is not dense, VIGwbP is similar to VIGbP. However, if there are many variables interacting with the chosen random variable, then the weights in the VIGw are used to select the neighbors with strongest connections to the random variable. Algorithm 3 shows the pseudo-code of VIGwbP. A solution x and a empirical VIGw Gp are the inputs, and a perturbed solution y is the output.\nLet $G_p (v_i)$ be the subset of vertices with edges incident in vertex $v_i \\in V_{Gp}$, i.e., the neighbors of $v_i$ in $G_p$. In VIGwbP, a random decision variable $x_i$ (line 3) and variables in a subset L are flipped (lines 17-19). Subset L can be selected in two different ways:\ni. If $\\Omega_{G_p} (v_i) = 0$, i.e., no variable interact with $x_i$ according to the VIGw, then one additional randomly chosen variable $x_j \\neq x_i$ (line 15) is flipped. This is done to ensure that at least two bits are changed by perturbation. When vertex $v_i$ has no edges, VIGwbP becomes equal to the standard random perturbation strategy where two random variables are flipped;\nii. If $\\Omega_{G_p} (v_i) \\neq 0$, then the variables with the strongest connections to $v_i$ (lines 6-13), according to the VIGw, are flipped. First, variables in $\\Omega_{G_p} (v_i)$ are sorted in ascending order according to their weights to $v_i$ (line 6). All variables in $\\Omega_{G_p} (v_i)$ with weights to $v_i$ higher than a threshold \u03b2 are added to L (lines 8-13). The threshold \u03b2 is computed by function thresholdComputation(C) in line 7. Function thresholdComputation(C) creates a sample with the weights of edges $(v_i, C_j)$ for all vertices in C and finds the outliers in this sample by using the box-plot procedure described in [Williamson et al. 1989]. The threshold \u03b2 is given by the upper bound outlier;\nIt is important to observe that VIGwbP is parameterless. Unlike the standard random perturbation where the number of flipped variables is fixed (given by parameter \u03b1), the number of flipped variables in VIGwbP depends on the weights of the empirical VIGw and on the variables that interact with variable represented by vertex $v_i$. When the number of neighbors of $v_i$ is small, e.g., in k-bounded pseudo-Boolean functions with low epistasis degree k, then all neighbors of $v_i$ in $G_p$ are changed because most of the weights associated to $v_i$ are zero. However, when the number of neighbors of $v_i$ is not small, e.g., when the VIGw is dense, then only the neighbors with strong connections to $v_i$ are flipped. Algorithm 4 shows the pseudo-code of ILS with VIGwbP and LSwLL2."}, {"title": "5 EXPERIMENTS", "content": "LSwLL2 creates an empirical VIGw during local search by flipping decision variables in a systematic order that is different from the one adopted by standard LS. Information about the interaction between variables is obtained as a side effect of local search. An important question is: how does the adopted visiting order and the additional operations needed for estimating the VIGw impact the search? In Section 5.2 we answer this question. We compare LS and LSwLL2 regarding different measures. The VIGw produced by LSwLL2 allows us to obtain new insights about the optimization problem and algorithms. We investigate this issue in Section 5.3, where empirical VIGws generated by LSwLL2 are analyzed. The VIGws also allow to develop new perturbation strategies for ILS."}, {"title": "5.1 Experimental Design", "content": "We run ILS with LS and LSwLL2 adopting different perturbation strategies. Two different stopping criteria were considered in the experiments: i) fixed number of iterations for each run; ii) fixed runtime. ILS is considered in a black box setting, i.e. independent of specific problems. In the experiments, for all problems, a deterministic acceptance criterion is used by ILS, where a new local optimum y replaces the current local optimum x whenever f (y) > f(x). Different measures, computed for each run of ILS, were used when comparing algorithms:"}, {"title": "5.1.1 NK Landscapes", "content": "NK landscapes are pseudo-Boolean functions defined as:\n$f(x) = \\sum_{i=1}^{N} f_i(z_i)$\nwhere $z_i \\in B^k$ contains variable $x_i$ and other K \u2265 1 variables of x, i.e., the number of inputs for each subfunction $f_i$ is always k = K + 1. The values of $f_i$ are randomly generated for all the assignments of $z_i$. There are different ways of selecting the K other variables in $z_i$. The most popular models are the adjacent and random models. In the adjacent model [Wright et al. 2000], each subfunction $f_i$ depends on variable $x_i$ and K other adjacent variables ($x_{i+1}, x_{i+2}, ...$). In the random model, each subfunction $f_i$ depends on variable $x_i$ and K other random variables.\nResults of experiments with adjacent and random NK landscapes for N = {100, 500, 1000} and k = {3, 5} are presented. Five instances were generated for each model and combination of N and k. The number of runs for each instance was ten. Thus, there were 50 runs generated for each model and combination of N and k. In experiments with fixed number of iterations, the number of iterations of ILS in each run was NI = 5000. In experiments with fixed time, the runtime was $TIME = \\frac{N}{2}$ seconds. These limits (and those for the other two problems) were obtained in initial experiments of ILS with LS and SRP, not shown here."}, {"title": "5.1.2 0-1 Knapsack Problem", "content": "In the knapsack problem, the most profitable items must be selected, given a limited knapsack capacity. There are different versions of the knapsack problem. Here, the 0-1 knapsack problem described in [Han and Kim 2000] is considered where the objective function is defined as:\n$f(x) = \\sum_{i=1}^{N} p_ix_i - r(x)$\nwhere $x \\in B^N$ represents a subset of items in the knapsack. The i-th item has weight $w_i \\in R^+$ and profit $p_i \\in R^+$. Here, the weights are randomly generated in the range [5, 20] and the profits are randomly generated in the range [40, 100]. The knapsack capacity C is equal to 50% of the sum of all weights. The penalty term r(x) is given by:\n$r(x) = \\begin{cases} 0, & \\text{if } \\sum_{i=1}^{N} w_ix_i \\leq C \\\\ (\\sum_{i=1}^{N} w_ix_i - C) \\cdot max_{i=1...N} (p_i/w_i), & \\text{otherwise} \\end{cases}$\nResults of experiments for N = {500, 1000, 1500, 2000} are presented. Five instances were generated for each N. The number of runs for each instance was 10. Thus, there were 50 runs generated for each N. In experiments with fixed number of iterations, the number of iterations of ILS in each run was $NI = 30000$. In experiments with fixed time, the runtime was $TIME = \\frac{N}{3}$ seconds. In the tables with experimental results, we show the normalized error (ERR), i.e., $ERR = \\frac{|f(x^*)-f(x)|}{f(x^*)}$, where $f(x^*)$ and f (x) are respectively the evaluation of the global optimum and the evaluation of the best solution found by ILS. We used dynamic programming for finding the global optimum. The time complexity of dynamic programming for the 0-1 knapsack problem is O(NC). If C is polynomial in N, dynamic programming runs in polynomial time; however, the problem is NP-hard for the general case [Andonov et al. 2000]."}, {"title": "5.1.3 Feature Selection", "content": "Feature selection is an important task in data mining [Xue et al. 2016]. In the wrapper approach, an optimization algorithm is used for finding a subset of features specific to a dataset and a machine learning model. For pseudo-Boolean optimization algorithms, a candidate solution $x \\in B^N$ indicates a subset of selected features . Here, the machine learning model is the K-nearest neighbors (KNN) algorithm, with K = 3. We applied ILS for feature selection for classification and regression datasets. The evaluation function has two terms:\n$f(x) = 0.98f_1(x) + 0.02 \\cdot \\frac{N - \\sum_{i=1}^{N} x_i}{N}$\nwhere $f_1(x)$ is a measure for the performance of the machine learning model and the second term depends on the number of selected features. In classification, $f_1(x)$ is the rate of examples in the test set correctly classified by the machine learning model with features indicated by x. In regression, $f_1(x) = 1 - E(x)$, where E(x) is the mean squared error for the test set when the machine learning model with features indicated by x is used. Here, the size of the training and test sets were respectively 0.7$n_{ex}$ and 0.3$n_{ex}$, where $n_{ex}$ is the number of examples (samples) in the dataset.\nResults for 8 datasets are presented. The datasets, listed in Table 1, are from the UCI Machine Learning Repository [Dua and Graff 2017], except for covidxr, cnae9m and friedman. Dataset covidxr [Tin\u00f3s 2020] was obtained by extracting radionomic features from chest x-ray images. The images were selected at random from the COVIDx training dataset [Wang et al. 2020], a public dataset containing x-ray images of three classes: normal, and patients with COVID19 and non-COVID19 pneumonia. By using PyRadiomics [Van Griethuysen et al. 2017], 93 texture features were extracted from the images. Dataset cnae9m was obtained by selecting the first 500 examples of the UCI Machine Learning Repository dataset cnae. In addition, 74 out of 856 features of the original dataset were selected. The selected features are those with frequency equal or higher than 10, i.e., they appear in at least 10 examples of the dataset. Dataset friedman is based on a synthetic data generator model proposed by Friedman and Popescu [2008], where the interaction between features in machine learning was investigated. The model generates desired outputs that depend on 8 out of 100 random discrete variables, $u_i$. The target function is:\n$F(u) = 9 |\\sum_{j=0}^{2} e^{-3(u_j-u_j^*)\u00b2} - 0.8e^{-2(u_3-u_4)} + 2 sin\u00b2 (\\pi u_5) - 2.5 (u_6 - u_7)| + \\epsilon$\nwhere the noise, $\\epsilon \\sim N(0, \\sigma^2)$, is generated with standard deviation \u03c3 chosen to produce a two-to-one signal-to-noise ratio. Here, $n_{ex} = 500$.\nThe number of runs for each dataset was 25. In experiments with fixed number of iterations, the number of iterations of ILS in each run was NI = 1000. In experiments with fixed time, the runtime was $TIME = \\frac{N \\cdot n_{ex}}{10}$ seconds."}, {"title": "5.2 Results: comparing local search strategies", "content": "Tables 2-5 show the results for the experiments with fixed number of iterations. The median of different measures are presented, as well as the statistical comparison between the results of algorithms with LS (SRP with \u03b1 = 2, SRP with \u03b1 = 50, and ADP) and the results of the respective algorithms with LSwLL2. Tables S1-S6 in the Supplementary Material show the p-values for the Wilcoxon signed rank test used for this comparison. In the Supplementary Material (tables S19-S25), median and best FIT and ERR values for the different instances of NK landscapes and 0-1 knapsack problem are also presented. Some observations can be made from the results.\nIn all experiments with fixed number of iterations, the null hypothesis (no statistical difference between the results) cannot be rejected when comparing FIT between each ILS with LS and the respective algorithm with LSwLL2. For the other measures, with exception for NILS and TIME, ILS with LS presented similar results to ILS with LSwLL2. For some instances, ILS with LS presented better results than ILS with LSwLL2, and vice-verse, but statistical difference between the results was observed in few cases. Similar results were obtained when the results for the different instances are analyzed.\nHowever, for the number of iterations of local search (NILS) and runtime (TIME), ILS with LS generally presented statistically better results when compared to ILS with LSwLL2. LS was generally faster because revisiting variables implies in higher NILS and because some operations are needed to build and manipulate the empirical VIGw. In this way, one can ask what happens when the algorithms runs for the same time. If one algorithm is faster than the other, then ILS will run for more iterations, and better solutions can potentially be achieved.\nTables 6-8 show the results for the experiments with fixed time. In these tables, only FIT (or ERR) and NI are presented. Tables S7-S9 in the Supplementary Material show the respective p-values for the statistical comparison. In fact, when the runtime is fixed, the number of iterations of ILS (NI) is higher for the algorithm with LS, when compared to the respective algorithm with LSwLL2. However, the results for FIT (or ERR) were similar, except for: 2 out of 36 cases (3 algorithms for each of the 12 combinations of model, N, and K) for NK landscapes; 4 out of 12 cases (3 algorithms for each of the 4 values of N) for the 0-1 knapsack problem; 1 out of 24 cases (3 algorithms for each of the 8 datasets) for the feature selection problem. Similar results are obtained when the runtime is changed; tables S36-S31 and S32-S37 in the Supplementary Material respectively show the results for half and one-third of the runtime (TIME) of the original experiments. Similar results are also obtained when a different accepting criterion is used; tables S38-S43 in the Supplementary Material show the results for experiments where a simulated annealing acceptance criterion is used. Thus, in all the experiments, the adopted visiting order and the additional operations needed for estimating the VIGw in LSwLL2 did not significantly impact the performance of ILS."}, {"title": "5.3 Results: weighted variable interaction graphs", "content": "An advantage of LSwLL2 over LS is that it builds an empirical weighted variable interaction graph as a side effect of local search. We show here some examples of using the VIGw for helping generating insights about the problems and optimizers.\nFirst, we analyze the number of edges of the empirical VIGw discovered by ILS with LSwLL2. One can remember that LSwLL2 never returns a false linkage (Corollary 3.5). In other words, if two vertices are connected in the empirical VIGw, they are also connected in the VIGw. In the NK landscapes, the VIG is known a priori. Thus, Table 9 shows the percentage of the edges of the VIGw in the empirical VIGw for the experiment with fixed number of iterations. The results show that, after 5000 iterations, ILS with LSwLL2 was able to find at least 90.4% of the edges of the VIGw. Regarding the algorithms, the worse results are for SRP with \u03b1 = 2, i.e., when the perturbation strength is the weakest and the number of iterations of LS (NILS) is the smallest (Table 3). Regarding the instances, the worse results are for N = 1000 and k = 3. More variables (higher N) mean that the VIGw has more edges. The VIGw has more edges for k = 5 than for k = 3; however, for k = 3, a bit flip will impact a fewer number of subfunctions in Eq. (9) (see also FDP in Table 2). This explains the worse edge-discovery results for k = 3 in NK landscapes.\nTables 10 and 11 show the percentage of the edges of the empirical VIGw over all possible edges for the other two problems in the experiments with fixed number of iterations. Specially for the feature selection problem, the graph is dense, i.e., most of the possible edges are present in the VIGw. In these cases, knowing the VIG is of little help. However, the weights of the VIGw can be useful when designing operators and analyzing the optimization instances and algorithms."}, {"title": "5.3.1 NK Landscapes", "content": "Figure 3 shows the empirical VIGw found by ILS with VIGwbP in experiments with one run of the adjacent and random models for N = 30 and k = 3. The empirical VIGw of only one instance for each model is presented. We added additional experiments with N = 30 because it is easier to analyze the weighted graphs for small dimensions of the problem, i.e., for a small number of graph vertices. The VIG indicates when two variables interact, but does not show information about the strength of the interactions. From Figure 3, we can observe the strength of the interactions, inferred by LSwLL2, in the empirical VIGw. When flipping two variables generally cause small variation in the evaluation of the subfunctions in Eq (9), then the weight between the respective vertices in the VIGw is small. Otherwise, the weight is large. Thus, the impact of flipping two variables depends on the number of subfunctions that these variables appear together in Eq (9) and also in the difference between the minimum and maximum values that the evaluation of these subfunctions can assume. One can remember that, in NK landscapes, the evaluation of the subfunctions for each combination of variables is randomly generated for each instance. The edges with largest weights in examples with adjacent and random NK landscapes can be seen in Figure 3. For the random model, we can observe that variables with the largest weights, e.g., $X_{26}$, impact subfunctions with largest contribution to the evaluation of the best individual."}, {"title": "5.3.2 Knapsack Problem", "content": "Figure 4 helps to understand how the interaction of variables, inferred by the weighs, impacts the search. In this example, the empirical VIGw found in a run of ILS with VIGwbP in a random instance of the 0-1 knapsack problem with N = 30 is presented. The VIG is dense in this example, and its analysis provides little information. However, analyzing the largest weights of the empirical VIGw can help understanding the optimization process. The edges with largest weights in Figure 4 are generally those connected to vertices that represent heavy objects in the knapsack problem. This is a result of the penalty function (Eq. 11) used in the knapsack problem. The largest variations in the evaluation of a solution (Eq. 10) are generally caused by adding or removing heavy objects because this will often impact the penalty applied to the solution."}, {"title": "5.3.3 Feature Selection Problem", "content": "ILS with LSwLL2 produces a relevant information during feature selection: feature interaction, or variable interaction. Inglis et al. [2022] define variable interaction as a measure (scalar quantity) that expresses the degree to which two or more variables combine to affect the dependent variable. Here, feature interaction between variables $x_h$ and $x_g$ is indicated by the weight of edge (h,g) of the empirical VIGw. Thus, given a dataset and machine learning model, the empirical VIGw can be employed for the visualization of all two-variable interactions. Inglis et al. [2022] proposed a variable interaction visualization in the form of heatmaps and graphs (network plot). In a network plot, nodes represent variables and weighted edges represent the interaction between the variables. The weights of the network plot are computed based on Friedman's H-statistic or H-index [Friedman and Popescu 2008]. Friedman and Popescu [2008] say that there is interaction between two variables, $x_h$ and $x_g$, if the impact on the output function"}, {"title": "5.4 Results: comparing perturbation strategies", "content": "The results for the comparison of the different perturbation strategies can be seen in the last 4 columns of tables 2-5 (for the experiments with fixed number of iterations) and tables 6-8 (for the experiments with fixed time). Tables S10-S15 (for experiments with fixed number of iterations) and S16-S18 (for the experiments with fixed time) of the Supplementary Material show the corrected p-values and the results of the Wilcoxon signed rank test used for the comparison of VIGwbP with the other 3 perturbation strategies.\nFigures 7 and 8 show the radar charts of the average rankings [LaTorre et al. 2021"}]}