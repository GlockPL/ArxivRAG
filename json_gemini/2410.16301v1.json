{"title": "Intelligent Computing Social Modeling and Methodological Innovations in Political Science in the Era of Large Language Models", "authors": ["Zhenyu Wang", "Yi Xu", "Dequan Wang", "Lingfeng Zhou", "Yiqi Zhou"], "abstract": "The recent wave of artificial intelligence, epitomized by large language models (LLMs), has presented opportunities and challenges for methodological innovation in political science, sparking discussions on a potential paradigm shift in the social sciences. However, how can we understand the impact of LLMs on knowledge production and paradigm transformation in the social sciences from a comprehensive perspective that integrates technology and methodology? What are LLMs' specific applications and representative innovative methods in political science research? These questions, particularly from a practical methodological standpoint, remain underexplored. This paper proposes the \"Intelligent Computing Social Modeling\" (ICSM) method to address these issues by clarifying the critical mechanisms of LLMs. ICSM leverages the strengths of LLMs in idea synthesis and action simulation, advancing intellectual exploration in political science through \"simulated social construction\" and \"simulation validation.\" By simulating the U.S. presidential election, this study empirically demonstrates the operational pathways and methodological advantages of ICSM. By integrating traditional social science paradigms, ICSM not only enhances the quantitative paradigm's capability to apply big data to assess the impact of factors but also provides qualitative paradigms with evidence for social mechanism discovery at the individual level, offering a powerful tool that balances interpretability and predictability in social science research. The findings suggest that LLMs will drive methodological innovation in political science through integration and improvement rather than direct substitution.", "sections": [{"title": "1 Introduction", "content": "Artificial intelligence (AI) is increasingly shaping various aspects of human society, significantly impacting research methods and paradigms. The rapid development of generative AI, exemplified by LLMs such as OpenAI's ChatGPT, has dramatically enhanced Al's capacity to model and simulate the human world. This progress signals the approaching era of strong AI, bringing unprecedented transformations and opportunities to scientific research. Current discourse highlights Al's profound impact on scientific research, as seen in concepts like \"AI for Science\" and the emergence of intelligent science paradigms (Wang and Miao 2023; Miao and Wang 2024). In 2023, the leading journals Nature and Science published articles analyzing how AI technologies reshape scientific exploration. Both emphasized the indispensable role of LLMs in this process."}, {"title": null, "content": "The Nature article, titled \"Scientific Discovery in the Age of Artificial Intelligence,\" highlighted how LLMs could identify theoretically promising hypotheses in scientific research through high-fidelity simulations, demonstrated by applications in protein folding (Wang et al. 2023). Meanwhile, Science focused on the significant implications of Al for social science research, highlighting how Transformer-based machine learning models, trained on vast textual datasets, are increasingly capable of simulating human-like responses and behaviors (Grossmann et al. 2023)."}, {"title": null, "content": "According to existing research, the integration of artificial intelligence (AI) and social sciences can be divided into two main areas: using AI to empower existing paradigms in social science research and considering AI as a central subject of social science studies. On one hand, Al serves as a critical tool to help researchers efficiently carry out tasks such as literature reviews, hypothesis formulation, data collection, and social surveys (Xu et al. 2024). On the other hand, Al-driven social science research emphasizes simulating social actors, analyzing behavioral patterns, and exploring complex social science issues based on Al's cognitive, reasoning, and linguistic capabilities. Overall, Al is widely recognized as a valuable tool for advancing social science research. However, establishing AI as a core research subject remains controversial, with debates centering on three main points."}, {"title": null, "content": "First is the relationship between LLMs and existing big data research. Some discussions consider LLMs as an extension of big data research methodologies in the Al era. For example, some scholars regard social science research in the AI era as data-intensive, underscoring LLMs' ability to expand the scope of data from structured forms to multi-modal, high-density datasets (Dong and Liu 2023; Mi et al. 2018). While these perspectives accurately capture the data-driven foundation of LLMs, they often overlook the models' logical reasoning and content generation capabilities. The big data approach summarizes existing data and identifies patterns, whereas LLMs go beyond this by generating coherent natural language content. Differences in training costs, complexity, and encapsulation are significant: the big data approach targets specific machine learning tasks, while LLMs are dedicated to maintaining human-like logic and language expression characteristics in complex scenarios."}, {"title": null, "content": "The second issue concerns the impact of generative AI on theoretical exploration in social sciences. Given the strong generative capacity of LLMs, the relationship between their generated data and social science research has become a focal point of discussion. Some scholars argue that data generated by LLMs may be unreliable and should not be directly used as data for future social science analysis. LLMs' challenges in generating data include data diversity, bias (Yu et al. 2024), and model hallucination (Zhang et al. 2023). Professor Hu Anning points out that since generative Al heavily depends on data-related instructions, systematic biases in data will result in biased outputs. Additionally, Al's understanding of the world is primarily limited to interpreting existing knowledge, lacking independent innovation. Moreover, without precise descriptions of the subject matter, AI struggles to provide researchers with the desired representation of the"}, {"title": null, "content": "subject (Hu and Zhou 2024; Bail 2024). Conversely, another line of discussion posits that AI and LLM-generated data can serve as an analytical foundation and drive paradigm shifts in social science research. For instance, some research suggests that with the capacity for automated analysis, LLMs can transcend traditional paradigms and pave the way for interdisciplinary integration and knowledge expansion in social sciences (Ziems et al. 2024)."}, {"title": null, "content": "Studies highlight the crucial role of LLMs in assisting research, but their potential contributions extend far beyond that. Leveraging increasingly powerful models, LLMs are poised to deeply integrate into the core aspects of knowledge exploration in social sciences. In this process, social sciences require a systematic epistemological and methodological framework for the deep integration of LLMs and knowledge exploration. The methodological framework under the new paradigm necessitates demonstrating the value of applying LLMs to social science research from the perspective of research methods, explaining the mechanism through which LLMs empower social science knowledge exploration based on model capabilities, and illustrating the operational workflow and research reliability of LLMs in the theoretical study through practical applications. To achieve these explorations, this paper will unfold in three main sections."}, {"title": null, "content": "The second section will explore the relationship between the technical features of LLMs and shifts in social science research methods, illustrating the mechanisms through which LLMs empower social science research. The third section will elaborate on the \"Intelligent Computing Social Modeling\" method developed on artificial intelligent LLMs, detailing its operational standardized procedures. Finally, the fourth section will focus on the practical application of this method, showcasing the contributions and extensive applications of LLMs in theoretical exploration by concentrating on classic theoretical scenarios and specific research questions."}, {"title": "2 Key Mechanisms of LLMs Empowering Political Science Research Methods", "content": "The efficacy of research methods depends on their ability to precisely and reliably represent social processes. Social science research is fundamentally centered on ideas, actions, and outcomes (Tang 2024). A complete theoretical narrative often requires explicit or implicit definitions of these three elements, as their interactions shape social processes and lead to various social phenomena. Different research methods can thus be viewed as distinct approaches to represent social processes within the \"theoretical space.\" Whether through \u201ccounterfactuals\" in causal inference, \u201cpattern recognition\" in predictive studies, or \u201crule-based\u201d models in simulation research, the goal is to ensure that theoretical processes accurately capture actual social processes. Precise observation and depiction of ideas and actions are prerequisites for effective representation and replication; without them, no social science model can provide valid evidence."}, {"title": null, "content": "The ICSM method integrates LLMs into social science research in ways closely aligned with these considerations. LLMs' performance in idea synthesis and action simulation demonstrates their significant potential to advance social science research. This paper focuses on the LLM family, which includes both LLMs and multimodal large language models and introduces the key technical features and main mechanisms through which LLMs empower social science research."}, {"title": "2.1 Idea synthesis", "content": "As full-scale repositories of human knowledge, LLMs represent the first technological breakthrough that allows direct learning and computation of non-numerical data, such as language and images. Thus, the models retain complete identity information of real-world actors. Computational simulation experiments based on this data offer a more nuanced characterization of specific actors than traditional research methods."}, {"title": null, "content": "LLMs, trained on vast datasets, provide the most fine-grained database of human opinions and perceptions. In traditional inductive approaches, social actors are characterized based on data collection work such as interviews and surveys. Researchers employ various methods to extract information from empirical materials. Hence, the volume and utilization of information determine the method's effectiveness in depicting actors. LLMs possess significant advantages in both respects. For instance, Google's open-source model Palm2 was trained on 3.6 trillion tokens, while NVIDIA's Nemotron-4 used 9 trillion tokens. These models are trained on vast multimodal datasets sourced from academic websites, online encyclopedias, video platforms, social media, and forums, encompassing enormous amounts of text, images, and videos. The rich information about human language and society embedded in these texts serves as the foundational material for machine learning."}, {"title": null, "content": "Moreover, the scaling law observed in LLM training ensures effective information transmission. Scaling law describes the power-law relationship between model performance (measured by cross-entropy loss) and factors such as model size, dataset size, and the amount of computing used for training (Kaplan et al. 2020). In essence, larger models and datasets lead to better model performance. The technical architecture of LLMs allows them to \"decode\u201d embedded knowledge, and their ability to learn intricate details within data scales up as the model size increases."}, {"title": null, "content": "Finally, integrating multimodal information ensures that the content of each form is retained intact. The data and parameter scale underpinning LLMs grants them exceptional natural language processing capabilities, and the Transformer architecture of LLMs has also demonstrated ideal performance in multimodal information processing. This engineering advancement is evident in academic research and industry applications, with the development of multimodal large models such as GPT-4 Omni and Sora. In traditional inductive approaches, no single approach can handle multimodal information comprehensively-data modeling often results in compressed or lost textual and image information. At the same time, case analysis leads to selective information usage due to subjective viewpoints. Therefore, \u201ccomputable\" multimodal information means that LLMs can transfer real-world information to the analytical stage more completely."}, {"title": null, "content": "Based on these technical features, LLMs offer new possibilities for a more comprehensive and refined characterization of social actors. Leveraging their vast training data and world knowledge, LLMs can generate \"silicon samples\" that share similar political characteristics with real-world actors and can understand and respond to complex political ideas, thereby effectively simulating political behaviors. Because LLMs contain information far exceeding any conventional database, they can theoretically serve as substitutes for demographic data and large-scale social surveys. With appropriate prompt engineering, researchers can create representative samples that are valuable for research and use them as survey respondents. Additionally, by creating intelligent agents, demographic data, socio-economic data, and political archives can be synthesized to generate actors at different scales (e.g., social organizations, political parties, and nation-states) to analyze specific interaction and decision-making processes."}, {"title": "2.2 Action Simulation", "content": "Explaining action is one of the major tasks in political science and, more broadly, social sciences. From a theoretical perspective, understanding the interplay between human cognition and the external environment must be achieved through studying actions. Moreover, interpreting political phenomena across different levels and scales invariably involves bringing these phenomena together through actions (Tang 2012). LLMs, functioning as implicit computational models of human action and as social context framers capable of constructing complex external environments, offer breakthrough tools to overcome the \"simplification dilemma\" in action research."}, {"title": null, "content": "Methodologically, behavior modeling exhibits significant limitations. Studies using this method emphasize the empirical and mathematical observation, description, and analysis of political behavior to identify verifiable laws of human behavior. This approach aims to enhance the reliability and objectivity of political science (Easton 1969). To explain actions, political science often employs formal modeling and experimental methods that closely resemble natural science research approaches. Formal modeling provides mathematically rigorous tools for explaining actions, while experiments offer empirically robust evidence with high internal validity and causal reliability (McDermott 2002). Together, these methods provide a scientific path for the precise formulation of theories and a rigorous examination of hypotheses. However, both methods share a critical limitation: they require highly simplified action patterns and external environments, which significantly restrict the external validity of research findings."}, {"title": null, "content": "With extensive discussions on Al reasoning and cognitive abilities, researchers have demonstrated that LLMs can perform \"reasoning-based actions\" under specific prompt engineering. Essential prompt engineering techniques include In-Context Learning (ICL) and Chain of Thought (CoT) prompting, and their significance in simulation studies has been well-proven."}, {"title": null, "content": "Both CoT and ICL are part of prompt engineering for optimizing responses. Prompt Engineering involves designing and refining the prompts input to LLMs to guide them in generating more accurate and valuable responses (Wei et al. 2022a). CoT reasoning consists of breaking down problems into a sequence of intermediate steps or reasoning chains, making it easier for the model to tackle complex questions. By embedding such thought processes within prompts, CoT helps the model gain a deeper understanding of the problem, improving the accuracy of the output. ICT, on the other hand, involves embedding sufficient background information within the prompts, often assigning specific roles or contexts to the model. This enables the model to accurately understand the contexts or conditions in which the problem is situated (Wies et al. 2024). ICT may include relevant definitions, previous information, or other details that help the model understand the task more accurately. Well-designed prompts significantly enhance the model's understanding of problems and the relevance of its outputs. Ultimately, optimization occurs in two directions: ICL contextualizes the model's responses based on assigned roles and contexts, while CoT reasoning enhances the model's ability to understand and handle complex tasks (Wang et al. 2022). The combined application of CoT and ICL has led to impressive outcomes. For example, LLMs have been integrated into intelligent agents as natural language units, using their robust language generation capabilities to facilitate interactive processes (Park et al. 2023). Relevant to the experimental design of this paper, Argyle et al. used prompt engineering to construct LLM-based silicon samples directly and simulated the outcomes of U.S. presidential elections based on their responses (2023). The combination of CoT and ICL allows for effective simulation of interactions between actors. For instance, Xu Yuzhuang et al. used prompt engineering to create LLM-based agents that successfully simulated communication game in a virtual environment, showing the emergence of strategic behaviors (2023). Such intelligent agent simulations are not limited to virtual scenarios. Hua Wenyue et al. developed WarAgent, an LLM-based intelligent agent using structured data (as ICL context) to simulate war events (2023). The simulation approach is not confined to simple tasks; in computer science, researchers have explored how external models of world knowledge can enhance the optimization effects of CoT reasoning (Hao et al. 2023). Overall, intelligent agent construction based on prompt engineering presents a significant pathway for applying LLMs in social science research."}, {"title": null, "content": "Researchers can use appropriate prompts to create \u201chuman-like behavior\u201d of simulated samples in simulation experiments and trace the \u201chuman-like reasoning\u201d embedded in these behaviors."}, {"title": null, "content": "Firstly, given the high consistency with human behavior patterns, LLMs can effectively simulate at least eight types of behavior from a technical perspective: natural language-based interaction, knowledge acquisition and memory, reasoning and planning, learning and adaptation, social interaction, personalization and emotional expression, self-improvement and self-adjustment, and tool use and innovation (Xi et al. 2023; Part et al. 2023). By combining these"}, {"title": null, "content": "eight types of behavior, simulation using LLMs can cover the behavioral modes found in mainstream formal models, including rational choice models, bounded rationality models, game theory models, and psychological process models (Ostrom 1998; Simon 1985; Bendor 2003; Austen-Smith and Banks 1998). Moreover, empowered by natural language processing and accessible software, LLMs have revolutionized the simulation of social scenarios in action research in three significant ways: by diversifying operational approaches, enhancing the granularity of detail, and broadening the scope of scenarios. LLMs can textualize complex social situations and game rules and draw on real-world information as simulation data for social context. This supports experimental simulations without limitations on duration, rounds, number of participants, or modes of participation, enabling researchers to overcome resource limitations in action research easily. Research has shown that this high flexibility allows researchers to replicate critical scenarios in action research, including cooperation and betrayal, economic behavior (Shapira et al. 2024), collective decision-making (Jarrett et al. 2023), moral judgment, cognitive psychology scenarios, multi-round games (Fan et al. 2024), and multi-agent negotiations (Lewis et al. 2020; Abdelnabi et al. 2023). Notably, research on strategic behavior suggests that LLMs can be used to simulate actions across different levels, including states, social organizations, and individuals (Lor\u00e8 and Heydari 2023)."}, {"title": "3 Intelligent Computing Social Modeling: A New Approach in Political Science Research Driven by Generative AI", "content": "The rapidly evolving generative AI allows political science to integrate it into computational simulations, facilitating the analysis and forecasting of dynamic social outcomes. This has led to a new approach to political science research: Intelligent Computing Social Modeling (ICSM). ICSM is a modeling methodology that builds actors, social contexts, and action patterns using LLMs, and synthesizes ideas, actions, and outcomes by leveraging data produced by generative agents for an integrated computational simulation. At the actor level, the ICSM method generates a cohort of agents that mirror real-world demographic profiles. Each agent acquires political perceptions from LLMs, aligning with the actual distribution within a defined temporal and spatial context. At the societal level, ICSM provides agents with environmental information via LLMs, using manually processed natural language inputs or multimodal data sourced through Retrieval-Augmented"}, {"title": null, "content": "Generation (RAG). In terms of action patterns, ICSM directs simulated agents to perform specific actions by feeding information into LLMs; every behavior of these agents is a result of cognitive perception and decision-making processes made by the models. Overall, ICSM leverages computational data from generative AI to study meso- and macro-level political science problems, constructing an LLM-based intelligent simulated society that closely reflects real-world demographics, social contexts, and behavioral patterns."}, {"title": null, "content": "ICSM's ontological basis is grounded in Karl Popper's \"Three Worlds\" theory, which posits a tripartite and open-causal ontology consisting of three coherent worlds: the physical world (World 1), the mental world (World 2), and the knowledge world (World 3). World 1 consists of all physical bodies, states, and processes; World 2 comprises mental states or psychological processes, representing the world of conscious experience; World 3 is the world of the products of the human mind, including all knowledge, scientific theories, and cultures created by humans. In Popper's framework, the physical world forms the foundation of the mental and knowledge worlds, while the mental world serves as the intermediary between the physical and knowledge worlds. Through the interaction of the physical and mental worlds, the knowledge world is formed, which can, in turn, influence the physical world via the mental world. All three worlds are real and interact dynamically (Popper 1972)."}, {"title": null, "content": "The emergence of ICSM stems from the fact that LLMs provide researchers with technical tools to connect the three worlds coherently. From the perspective of AI technology evolution, LLMs signify a shift in machine learning-from pattern recognition in specific datasets to probabilistic generation based on ultra-large-scale datasets. In this sense, the development goal of LLMs is to create a \u201csimulator\u201d that synchronizes the evolution of the three worlds: Firstly, the evolution of LLMs fundamentally depends on the expansion and updating of parameter scales and training datasets, through which LLMs can reflect the changing dynamics in the physical world more comprehensively (Wei et al. 2022b). Secondly, the performance of LLMs is measured by how closely they approximate human cognitive activities that is, how accurately their generative capabilities can simulate the processes of the mental world (Chang et al. 2024). Lastly, the content"}, {"title": null, "content": "generated by LLMs contributes to the knowledge world, which can be applied to the physical world through interaction with the mental world. By precisely simulating the interactions among the three worlds, LLMs enhance the value and advantages of the ICSM method, driving innovative developments in political science research methodologies."}, {"title": null, "content": "To fully leverage the technological advantages of LLMs to empower political science research, we have designed the operational pathways of ICSM around two cycles corresponding to the \"three worlds\": the simulated social construction pathway, which corresponds to the cycle of \"physical world - mental world - knowledge world - physical world,\" and the simulation validation pathway, which corresponds to the cycle of \"knowledge world - mental world - physical world - knowledge world.\" Along the simulated social construction path, ICSM needs to complete the following four steps for any social outcome to be studied:"}, {"title": null, "content": "First, Al agent sample construction: This step aims to build a silicon sample that reflects the actual demographic composition in the physical world and serves a purpose similar to that of survey methods. Specifically, this step primarily constructs a cohort of agents that mirror the demographic structure of reality based on census data. Each agent is endowed with an identity that matches individual attributes in reality through prompt engineering and adopts corresponding perceptions for this identity from the LLM's vast repository of data on the physical world."}, {"title": null, "content": "Second, action simulation: This step defines actions for agents that correspond to cognition in the mental world, aligning with action-focused formal models. It involves prompting the agents to perform actions that can directly affect social outcomes (e.g., voting or relocation). Mainstream prompt engineering techniques include zero-shot and few-shot prompting, Chain-of-Thought (CoT) reasoning, Retrieval Augmented Generation (RAG), and Automatic Reasoning and Tool-use (ART). Researchers are suggested to choose appropriate prompting strategies according to the needs of the simulation (Brown et al. 2020; Wei et al. 2022; Lewis et al. 2020; Paranjape et al. 2023). Upon completion, researchers obtain a simulated meta-sample to study specific social outcomes."}, {"title": null, "content": "Third, Intelligent Computing Simulation: This step incorporates variables or mechanisms concerning actors, actions, and social environments into the meta-sample following theories from the knowledge world and research needs. The simulation is performed round by round, functionally similar to experimental and social simulation approaches."}, {"title": null, "content": "Fourth, generated data analysis. This step compares the results of computational simulations with actual social outcomes in the physical world, validating outcomes against real-world data, and derives theoretical explanations based on the validity of simulations. Depending on how the generated data is utilized, this step is functionally akin to large-sample quantitative regression analysis or small-sample qualitative process tracing."}, {"title": null, "content": "Despite the widely recognized potential of LLMs and generative Al in social science simulations, no \"gold standard\" study confirms that LLM-based agents can precisely simulate human behavior (Bail 2024). The ICSM method requires assessing the validity of the data generated in the research. The validation of simulated social construction involves four steps:"}, {"title": null, "content": "The first is validation benchmark setting. This step aims to identify a classic study in the knowledge world that examines similar social outcomes as a criterion study, using its fit to social outcomes as the benchmark for assessing the validity of ICSM. Since ICSM is essentially a computational simulation method, it is strongly recommended that ICSM be applied primarily to social outcomes studied using classical computational simulation methods like ABM (Agent-Based Modeling) or cellular automata."}, {"title": null, "content": "The second is simulation reliability testing. This step involves setting agents' actions in alignment with the operationalization from the criterion study and testing whether the model's outputs remain consistent across multiple independent rounds. This process aims to ensure the reliability of the simulation."}, {"title": null, "content": "The third step is simulation validity assessment. This step uses the simulated meta-sample to conduct computational simulations and compares its goodness of fit to social outcomes against the validity benchmark. A meta-sample is considered valid when the simulation reaches a fit of at least 65% of the benchmark."}, {"title": null, "content": "The fourth is knowledge discovery validation. This step establishes the principle for identifying new variables or mechanisms with theoretical value. The logic is that a newly added variable or mechanism is considered valid in the knowledge world only if its inclusion improves the fit beyond the meta-sample."}, {"title": null, "content": "The operational workflow and application logic of the two main pathways are as follows:"}, {"title": null, "content": "ICSM represents the convergence of knowledge, theory, methods in social sciences, and LLM application. Its essence lies in guiding LLM's intelligent computing with a scientifically designed research framework and using AI agent-generated data as meaningful simulation data. The core value of ICSM is not the mere application of AI technology but its unique epistemic advantage in explaining social outcomes. In social science, explaining complex social outcomes like war and peace, the rise and fall of nations, and institutional change represents the most challenging tasks. Since human society is centered around the evolution of ideas, explaining social outcomes necessitates analyzing actors, environments, and behavioral mechanisms. In addressing this problem, a common practice is to simplify social phenomena using various research methods (Tang 2018), resulting in methodological divergence of different epistemological stances-quantitative research methods aligned with positivism and qualitative research methods aligned with interpretivism (Qin 2024). The former and the big data approach constitute a research paradigm that emphasizes the description of causal effects from a factor perspective. The latter"}, {"title": null, "content": "and the social simulation approach form a research paradigm that focuses on analyzing causal processes from a mechanism perspective. Although quantitative and qualitative methods are highly complementary, they differ significantly in epistemological stance, research goals, methodological principles, and specific technical tools, making their integration challenging (Sale 2002). Quantitative methods rely on numerical data reflecting observations and use statistics and probability theory for analysis, following deductive logic. Qualitative methods, on the other hand, are based on textual data reflecting interpretive concepts and use the language of logic and set theory for analysis, adhering to inductive logic (Goertz and Mahoney 2012). This leads to the question of paradigm movement at the level of epistemology and theory in current attempts to combine those methods (Brannen 2016). Before the rise of LLMs, this issue was technically intractable: researchers either lacked sufficient subjective data or could not compute the aggregated outcomes of these data in a way that closely mimics human cognitive processes. As LLMs are the most extensive sources of subjective data and the most accurate simulators of human cognition available in the social sciences, ICSM is not merely a technical gadget embedded with LLMs but a methodological instrument designed to bridge the gap between quantitative and qualitative paradigms, facilitating a unified approach in social science research."}, {"title": null, "content": "By deeply integrating the four major social science research paradigms-quantitative, qualitative, social simulation, and big data-ICSM demonstrates the advantages of the fifth paradigm, AI4SS (AI for Social Science). Firstly, at the factor level, ICSM can meet traditional quantitative research goals by examining the impact of different factors on agents' behaviors or social causality and enhancing the big data paradigm's research strengths through LLMs' inherent ability to process multimodal data. Secondly, at the mechanism level, ICSM is designed within the technical framework of social simulation, enabling it to effectively accomplish the goals of qualitative research by identifying and examining mechanisms. Since LLM-embedded agents can interact using natural language, ICSM provides the most fine-grained evidence for mechanism identification and process tracing at a micro-level, further amplifying the research advantages of the social simulation paradigm. Thirdly, ICSM offers a reusable, adjustable, and iterative intelligent model for explainable predictions. Considering that ICSM is fundamentally an integration of machine learning that is adept at forecasting with social science theories that are adept at explanation, each research project successfully employing ICSM yields a set of simulated agents that can substitute human participants and intelligent simulation frameworks"}, {"title": null, "content": "with robust theoretical explanations for specific social outcomes. Researchers can use these established frameworks to make interpretable predictions about social outcomes based on updated data about agents and environments. By utilizing ICSM, social science researchers can constantly benefit from LLM technologies while refining and developing social science theories according to the model fit to real-world outcomes, effectively capturing the evolution of social systems."}, {"title": "4 Case Study: Computational Simulation of U.S. Elections", "content": "The application of intelligent computing social simulations is still in the early exploratory stage and requires further clarification in several areas, including standardized procedures and operational pathways. Underexplored key issues include: How can ICSM be applied to address specific research questions? What is the practical workflow of computational simulation? Following the \"Three Worlds\" and \"Two Cycles\" methodology, this paper sets the U.S. presidential election as the experiment scenario and conducts computational simulation experiments around specific variables and their impacts. Through this process, the paper demonstrates the practical approach of ICSM, detailing the construction of simulated environment and agents and elucidating the key settings and workflows involved in conducting theoretical exploration with ICSM."}, {"title": "4.1 Experiment Objectives", "content": "Research methods ultimately serve theoretical exploration, aiming to address specific research questions effectively. Thus, the computational simulation experiment presented in this article has two purposes. One is to showcase the application of the ICSM method in theoretical research endeavors, and the other is to elucidate how ICSM can enhance studies following traditional methodological approaches. To avoid empty talk about method application, the paper explains the method in the context of U.S. election studies, engaging in dialogue with existing predictive and simulation research within the field, thereby contributing to methodological and theoretical exploration in social science."}, {"title": null, "content": "The evolution and advancement of predictive analytics in the big data era deserve close attention. The advent of predictive paradigms is intrinsically linked to the escalation of data magnitudes, which enables researchers to directly identify data patterns through optimization techniques and then explore the unknown and make predictions. As research with advanced methods suggests, scientifically predicting the future is an endless drive for academic exploration and discovery, as well as a crucial leverage point for paradigm and methodological innovation (Wang and Tang 2020). However, machine learning predictions based on big data often fail to address specific research questions effectively. For instance, Liu Chenhui and Tang Shiping tested the conflict prediction system developed by the Uppsala Conflict Data Program. They found that the predictions made by the Violence Early Warning System (ViEWS) were, at best, acceptable but far from ideal (2023). Moreover, due to the algorithmic \"black box,\" predictions made under the machine learning paradigm contribute very little to social science theoretical exploration. These limitations confine the predictive paradigm to particular issues, thus hindering it from having a widespread impact on social science research."}, {"title": null, "content": "The ICSM method enhances existing predictive methods by contributing to predictive patterns and knowledge exploration. Firstly, the ICSM method evaluates experimental models through a comprehensive construction and validation process. The prediction results are compared at different stages with research and empirical benchmarks. This approach generates more theoretically and empirically interpretable data than traditional prediction methods that overly rely on training data. Furthermore, the ICSM method leverages the advantages of agent interactions using natural language. When setting action patterns to simulate specific social outcomes, researchers can obtain agents' self-explanation for their actions through proper prompts. Under the reasoning logic of LLMs, these generated texts form the most detailed evidence to support different research findings. This allows ICSM to provide predictive and explanatory experimental evidence, thus significantly advancing knowledge discovery."}, {"title": null, "content": "In election studies, analyzing and predicting U.S. presidential elections is of both theoretical and practical importance, making it a longstanding focal point for political scientists (Campbell 2004). As the world's only superpower, the United States' strategies and policies substantially impact the international order. Within its system of checks and balances, the president-who holds executive power-plays a pivotal role in shaping national policy and crucial decisions. In the tradition of political science, elections are a common field for applying simulation and prediction methods (Bendor et al. 2003; Kottonau and Pahl-Wostl 2004). This is partly because the competitive rules of the electoral arena are well-defined, the outcomes are clear, and critical actors are identifiable and observable, facilitating behavior modeling. This study employs political elections as an experimental scenario, engaging with empirical research to integrate ICSM into the social science landscape. In related analyses, the diverse and fragmented social structure of the United States is considered crucial for understanding political phenomena. When exploring electoral influence, researchers focus on factors such as race, class, region, and education. However, both quantitative and qualitative traditions face difficulties in effectively accounting for the impact of these variables on election results. Precisely, how can the effects of variables identified by qualitative research be accurately pinpointed at the macro-level outcome? And how can the significance of factors measured by quantitative research be substantiated at the micro-level? These challenges impede a comprehensive understanding of political outcomes, compelling researchers to choose between social system analysis and micro-level explanation, thereby discarding the insights inherent in the alternative methodological approach. This situation leads to two unsatisfactory results: qualitative research emphasizes critical variables' importance and influence mechanism but lacks precise outcome-level assessments. At the same time, quantitative researchers may identify coefficients for certain variables but struggle to find corresponding supporting facts (behavior or phenomena)."}, {"title": null, "content": "The ICSM method offers an integrated solution by bridging micro-level processes with macro-level outcomes through computational simulations while providing evidence for both the process and outcome in theoretical arguments. Arguments are crucial for establishing proof within any methodological framework, and the content and format of the evidence decide the argument's"}, {"title": null, "content": "validity. By leveraging LLMs' natural language interaction capabilities, ICSM can produce diverse evidence in flexible formats. For specific research questions, the evidence generated by ICSM caters to argumentation needs and enhances the argumentation process. As a result, ICSM-based research can engage in dialogue with existing studies and provide comparative validation with established methods."}, {"title": "4.2 Step1: Simulation Benchmark Setting and Agent Sample Construction", "content": "To meet the research goals and validation requirements", "benchmark": "Forecasting Elections with Agent-Based Modeling: Two Live Experiments\" by Gao et al. (2022) and \"Out of One", "Many": "Using Language Models to Simulate Human Samples\" by Argyle"}]}