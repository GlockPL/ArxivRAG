{"title": "Data Ethics Emergency Drill: A Toolbox for Discussing Responsible AI for Industry Teams", "authors": ["Vanessa Aisyahsari Hanschke", "Dylan Rees", "Merve Alanyali", "David Hopkinson", "Paul Marshall"], "abstract": "Researchers urge technology practitioners such as data scientists to consider the impacts and ethical implications of algorithmic decisions. However, unlike programming, statistics, and data management, discussion of ethical implications is rarely included in standard data science training. To begin to address this gap, we designed and tested a toolbox called the data ethics emergency drill (DEED) to help data science teams discuss and reflect on the ethical implications of their work. The DEED is a roleplay of a fictional ethical emergency scenario that is contextually situated in the team's specific workplace and applications. This paper outlines the DEED toolbox and describes three studies carried out with two different data science teams that iteratively shaped its design. Our findings show that practitioners can apply lessons learnt from the roleplay to real-life situations, and how the DEED opened up conversations around ethics and values.", "sections": [{"title": "1 INTRODUCTION", "content": "Data science (DS), artificial intelligence (AI) and machine learning (ML) are rapidly expanding fields, and therefore teams of professionals specialising in these technologies have become commonplace in the last decade. As the importance of the data and AI industry grows, the work of these teams has an increasing impact on society. Recent studies [10, 24, 46] of data science, machine learning and artificial intelligence practitioners have shown that ethical decision-making is part of the everyday technical design choices practitioners have to make, but they are not always aware of it. In fact, discussing values outside of the technical remit of performance and considering societal needs has often been neglected in the field of AI [9].\nAs these technologist teams have matured in their professional practice, some have incorporated AI ethics frameworks and techniques designed by researchers from fields such as HCI and STS into their processes to ensure that their products reflect their individual values and those of their company. However, when these research techniques are moved from the theoretical to the practical sphere, practitioners encounter the main limitations of current thinking about Al ethics: its abstractness and lack of context [9, 62]. This overlooks the crucial fact that data science, machine learning and AI in industry are not themselves abstract concepts, even if this is how they might be discussed in research contexts. These technologies are being embedded into companies with various stakeholders inside and outside of the technical team and also into wider society, often replacing processes which have their own domain-specific norms that don't necessarily fit with general ethical guidelines.\nOne proposed solution to bring more ethical sensitivity into the field is to educate technologists via discussions about ethics [10, 24]. Ethical roleplay has been extensively studied in the context of university education, including in computer science [51]. Examples show how roleplays can provide participants with a safe space to discuss and empathise with the decisions required of different stakeholders. Previous educational roleplays have confronted participants with generic problems of fictional stakeholders, and are typically presented within the context of formal education. However, there is an opportunity to examine real world scenarios with roleplays that are embedded into the specific context of a data science team. This means taking into account the complexities of the workplace, product lifecycle and societal impact.\nWe designed a roleplay method called the Data Ethics Emergency Drill (DEED). These DEEDs ask questions such as: what if an algorithm that is in production is demonstrated to show bias against a group of people? What if malicious actors use your services? Would you know what to do and who to contact to resolve the issue, limit damage and prevent repetitions? The roleplays are intended to function like a fire emergency drill in the context of AI ethics and are designed in close collaboration with members of the data science team. The DEED method puts teams of data scientists into ethically difficult situations to explore and discuss the ethical implications of their work. By creating opportunities to confront an ethical issue within their day-to-day work, we aimed to encourage them to test"}, {"title": "2 RELATED WORK", "content": "As AI, data science and machine learning technologies are being implemented across multiple industries, scholars have pointed out the dangers they can pose to society, such as exacerbating discrimination against minoritised groups [7, 13, 15]. In response to some of the questions raised by responsible AI researchers, solutions have been offered to support ethical AI governance, including ethical frameworks [8, 26], AI regulation [45], audits [14] and checklists for practitioners [37]. Technical solutions for explainability [36, 49] and debiasing methods [64] have been proposed to assist with transparency and fairness. There have also been proposals of design methods, for example using value sensitive design [21] to support the creation of responsible AI systems during the design phase [6, 22, 55]. Other design methods also support reflection and discussion in relation to ethical values with existing technological applications [5, 19].\nWhen implemented in real-life, some of these responsible AI solutions exhibit their shortcomings. The development of AI regulation has been criticized as being reactive and not suitable for the contextual complexities of algorithmic implementations [27]. When asked to apply technical methods for explainability, data scientists have been found to put too much trust in interpretability tools [33]. Furthermore, ethical guidelines may provide a fig leaf to cover up issues beneath the surface [25] or even be used to \"justify the path\" [58] set out by business models. In short, instead"}, {"title": "2.2 Designing for Reflection with Ethical Roleplay", "content": "We see ethical roleplay as an opportunity for practitioners to practise ethical discussions in a focused and efficient manner, and to lean in to the most challenging aspects of their specific applications. Ethical roleplay has been extensively studied within the context of formal university education for areas including management [1, 41], business [12], accounting [57], medicine [42] and computer science and technology [4, 35, 51]. In most of these cases, students were presented with a scenario and were asked to play the role of different stakeholders. Avin et al. also applied roleplays for thinking about Al impacts in industry contexts, as they share in their ongoing research report [4]. They take inspiration from wargames which have long been applied in fields such as cybersecurity [2]. The main motivations behind these studies were to create empathy in students for \"implications for all stakeholders\u201d [41], prepare students for real-life situations [42], to introduce ethics into a largely technical curriculum [51] and to encourage self-reflection [1].\nWe build on the concept of reflection in previous work of ethical roleplays. The importance of undergoing the process of acting out"}, {"title": "3 RESEARCH CONTEXT", "content": "The first author is the principal investigator of this project, which is her PhD project. Her supervisor is the last author. The first author has an interdisciplinary academic background in linguistics, design and computer science and also has three years of industry experience working as a data and AI consultant. The second, third and fourth authors are data science practitioners in the financial sector. They have participated in the creative research process and offered feedback on the design and setup of the early drafts of the drill. The three practitioners were not involved in the data analysis of the findings. This was carried out by the PhD student and her supervisor. The last author is a HCI academic with a strong"}, {"title": "3.2 Context of Participating Industry Teams", "content": "The two participating teams were both data science teams based in the UK and recruited through University research showcases. One team was a large team of 50+ data practitioners set within a larger company. This data science team works on a range of projects implementing primarily supervised machine learning techniques into customer-facing and internal company processes. The other team was a small team with three data practitioners working within a startup sized company offering natural language processing services. The teams were recruited on the basis that they were interested in exploring their responsible Al practices. Before commencing we confirmed that their management was supportive of team members taking time away from work to participate in the scenario crafting workshop and the drill session."}, {"title": "4 METHOD", "content": "Our main idea was to confront data scientists with fictional, yet plausible dilemmas about the ethics, fairness or societal impact of their applications that needed to be solved urgently with the tools that they currently have at their disposal in their organisations. We call these data ethics emergencies. The literature shows there is no shortage of Al ethics frameworks [25], not to mention ethical frameworks in general. Discussions involving ethics and values can happen at various levels (personal, product and organisational). Their resolution may or may not lie in the direct responsibility of the data science team, and can involve engaging with wider organisational structures [59]. The ways organisations practise data ethics and their motivations not only vary, but are also entangled with one another [58]. Because we expected to encounter this variety and entanglement in our studies, we chose not to impose top-down structures or boundaries when brainstorming data ethics emergencies in our research approach. Instead we let the participants lead the discussion on what aspects of their responsible AI practice they were interested to explore based on their own team values. The analysis of the conversation topics in the findings mirrors this entanglement in the breadth of their content (see section 8.2). Our aim was to find topics that had the potential to spark an engaging discussion about the embedded values of a system. To this end, we chose dilemmas which could be described as \"wicked problems\" [50], i.e. they were not straightforward to solve and had trade-offs in their possible solutions. The data ethics emergency also had to be urgent, i.e. something that needed to be addressed immediately so that discussions would focus on concrete actions that could be taken. How these were generated is described in Section 7.2.2.\nWe identified three types of desired outcomes for the DEED:\n(1) To test if a data science team's current processes are adequate to address ethical emergencies, and to both understand what works well and what needs to be improved\n(2) To offer a space for data scientists to practise conversations around ethics in their work context and to reflect on their practice both as a team and individually\n(3) To make values embedded in the design of their technological applications apparent and reveal the impact of the design decisions on the wider society"}, {"title": "4.2 Research through Design", "content": "To understand if a situated role play could provide a good basis for discussion within technical teams and how to realise such scenarios, we opted for an iterative design process in close collaboration with practitioners, where we developed each subsequent study in response to participant feedback. Overall, we followed a research through design approach [65], by trying to make the 'right' thing as opposed to the commercially viable thing. Our artefact in the design research sense is the DEED method, while the broader knowledge we would like to contribute to the responsible Al research community is a proposal for designing methods that allow data and AI practitioner teams to engage with the contextual details of their working environment.\nWe had a lot of uncertainties around the drill design, such as how realistic prompts should be, the amount of detail they needed to contain, how extreme the stories in the prompts had to be to induce a sense of urgency and if the setting of a fake meeting would be natural enough to drive a discussion. It is through the process of designing these workshops with the practitioners that we defined our DEED method. The iterative approach allowed us to gain insight with a small number of studies and be respectful of our participants' time, as we were able to directly implement feedback. Practically, this involved, analyzing feedback that we gained from surveys and re-watching recordings of the drill, and using these insights to define the goals of subsequent studies. Finally, we identified important elements from both the scenario crafting workshop and the drills themselves so that we could create our toolbox of instructions for the DEED."}, {"title": "4.3 Designing the DEED with practitioners", "content": "We sought to design a tool that was resource efficient and educationally effective while being contextually relevant to the DS team's area of practice. Therefore, we involved members of the team in the crafting of the scenario, which included brainstorming dilemmas, structuring the narratives, and planning how to implement the drill in their teams. The scenario crafting workshop was held with one to three members of each DS team before executing the DEED. During these sessions the first"}, {"title": "4.4 Evaluation - Data Collection and Analysis", "content": "To evaluate our DEED method, we analysed each study right after we conducted the drill and conducted follow-up interviews about a year after the drill to understand the long-term impact."}, {"title": "4.5 Research Ethics", "content": "The studies were approved by our university ethics committee. To ensure that participants were not affected in their work environment and relationships, we established a protocol which included how to exit the discussion or end the meeting if they felt uncomfortable by contacting the researcher through chat or email. We reminded participants at the start of the drill and the next day in a follow-up email that all the prompts were fictitious and that the DEED is designed to be a reflection activity to improve processes, not a test of their personal capabilities. Participants were given reassurance that the drill will not affect their performance evaluations or employment status as well as keeping their participation anonymous to the wider team. No complaints regarding work relationships were recorded during the drill or in follow-up surveys."}, {"title": "5 ITERATIONS OF DIFFERENT DRILL STRUCTURES", "content": "Below is a description of each drill that we conducted and the high level learnings that shaped each iteration. We have omitted commercially sensitive details of the drills and precise role descriptions to keep participants' identities anonymous."}, {"title": "5.1 Drill #1: Team A - Email Prompts", "content": "The first drill was a one hour online meeting with six participants in the roles of data scientist or data engineer and one volunteer from the leadership team of the DS team. The volunteer from the leadership team had been involved in the design of the scenario and was assigned the role of the \"mole\" for this first pilot study. The \"mole\" was in touch with the researcher via a Microsoft Teams chat to ensure that prompts had been received and that the discussion had finished before the researcher re-entered the call. Participants received three prompts in the form of emails, with 20 minutes to discuss each prompt. The email prompts outlined a problem found in an existing model implementation with increasing severity. The prompts were sent by the researcher but signed by the model monitoring team, a manager and from a public facing department calling for action.\nThis drill showed that we were able to craft an engaging discussion with the simple tool of fake emails. Some feedback suggested that including a business stakeholder in the discussion or even letting them present a problem directly in the drill would make the scenario more realistic. When analysing the transcript, we found that some of the learning goals we had set were not addressed in the discussion, and survey responses about the participants' takeaways were lacking detail. We thought this could be supported by explicitly asking participants about their understanding of the scenario and how the results of the drill could be turned into actions. Another important insight from this drill was the importance of the \"mole\" who we initially put in place to coordinate prompts with the researcher. We observed in this study that the mole often served as a driver of the discussion and was filling in missing information in the prompts."}, {"title": "5.2 Drill #2 : Team A - Relay of Presentations", "content": "The second drill was for same data science team as the first, but with a different group of six participants, including a new \"mole\", discussing a different problem. The most substantial change from the first study was that prompts were through presentations by the participants themselves rather than email, including a non-technical stakeholder from the business side. Moreover, we added a reflection activity in the form of a questionnaire to support reflection on the drill. The questions were based on our insight from the first drill.\nTo replace email prompts with presentations, the second drill was designed as a relay of three separate online meetings. In the first, a business stakeholder presented a problem to managers. In the second, one of the managers told a group of data scientists and data engineers the problem. The group then had to prepare a presentation for the business stakeholder based on the plan made by the managers beforehand. In the last meeting, one of the participants from the second meeting presented the detailed plan to the business stakeholder.\nThe involvement of the business stakeholder delivering the prompt as a presentation instead of email and the reflection activity all helped generate insightful discussions and were added to the DEED toolbox. The presentation that data scientists made to present their action plan turned out to elicit a very focused discussion and was a useful artefact for analysis, as the main discussion points were already summarised."}, {"title": "5.3 Drill #3: Team B - Mixed Presentations", "content": "The third drill was held with four members of a data science team at a different company. This iteration was held with the main purpose of testing the drill with a different team in a company of a different size. Some additions were made to the scenario crafting workshop: as the researchers were new to the context of this company, another activity was added to map values and practices of this company that had not been included in the first scenario crafting workshop.\nThis online meeting had two prompts delivered via email and one prompt delivered in person by a participant, since both in person and email delivery had been judged as realistic in previous iterations. The drill included the reflection activity, which had proved to be useful in the second drill."}, {"title": "6 ILLUSTRATIVE EXAMPLE", "content": "The following fictional example illustrates what a drill scenario looks like. This toy example shares many characteristics with the actual drills that we designed, which cannot be put into this paper as they are commercially sensitive. These characteristics are:\n(1) the problem discusses a 'wicked issue' where solutions require trade-offs i.e. how do you model a heterogeneous ever-changing group of people\n(2) the problem addressed a responsible AI value in their team\n(3) the problem appears to be caused by a realistic data ethics issue i.e. resulting from data or an algorithm using data\n(4) prompts are in the form of written information from people within the company\n(5) prompts increase in severity or difficulty over time\n(6) prompts have clear directives on what to discuss\n(7) prompts involve a variety of stakeholders"}, {"title": "7 SUGGESTED ANATOMY OF A DATA ETHICS EMERGENCY DRILL", "content": "In this section, we describe how to structure a successful DEED, including the preparation work of crafting the scenario before the drill, running the session itself during the drill and how to draw insights for the drill from the experience after the drill session. We provide reflections and considerations based on what worked in the three drills we ran. A complete set of workshop slides can be found in the supplementary materials. The figures and the materials were visually embellished after the studies in collaboration with a graphic designer."}, {"title": "7.1 Choosing Participants", "content": "It is useful to first establish the participants or the participant pool to know participant numbers and who can be involved in the preparation of the drill. Our past iterations have always involved at least one participant in the creation of the scenario, while the others were confronted with the scenario on the day of the drill. Participants were people within the data science team or colleagues from outside the team who work closely with the data scientists. We recommend a group including a minimum of one participant from the DS team involved in crafting the scenario and a minimum of three participants for the drill. For the drill, the group discussion should be limited to around six people to allow for enough space for each participant to talk. If more people want to participate, then the scenario crafter could consider splitting these into separate sessions. We found it useful to designate one \"mole\" amongst the drill participants, who was aware of the goals of the discussion and who could communicate with the person coordinating the prompts in the background. They can also direct participants' attention to important parts of the prompt and give believable answers to questions related to the hypothetical scenarios. We found managers have a natural suitability for such a scenario, as they might usually drive discussions in real-life meetings."}, {"title": "7.2 Before the Drill - Crafting the Scenario", "content": "This section describes a summary of the steps to create the scenario and craft the prompts in a workshop with data scientists."}, {"title": "7.2.1 Mapping of Responsible Al Values and Practices", "content": "Task: Participants describe responsible AI values for their team and the processes that are currently in place to support these values. Values are placed in the inner circle and processes in the outer circle. Then, the processes are connected to the corresponding values. We found it helpful to initially start discussion without prompts, but also have a set of values pre-written if the team does not already have an established list of values or struggles to list values. Figure 3 shows the Miro board used for this activity. This exercise is to establish the current state of responsible AI in the data science team and to get an overview of the maturity of the processes. We expect that this discussion can already inspire some of the potential data ethics emergencies.\nDiscuss: Which of these values are most important? Do any of the values have intrinsic tensions? Have any of the processes had problems?\nExamples: Ethical principles from [30], e.g. transparency, fairness and sustainability."}, {"title": "7.2.2 Identifying Emergencies", "content": "Task: Participants take 2-3 of the established values they would like to focus on and place them on the board shown in Figure 4. Then participants brainstorm potential ethical emergencies. These are placed along the axes of difficulty to resolve and likeliness. They are also marked using colour for three levels of impact (high, medium, low). Participants should try to cover all areas of the graph and think of versions of the same problem on different dimensions i.e. easy vs difficult, likely vs unlikely, low impact vs high impact. Generating versions of different magnitudes of difficulty, likeliness and impact can help create an overarching narrative when making"}, {"title": "7.2.3 Communication Channels", "content": "Task: Based on the chosen problems, participants map how internal or external communications will reach their team to make them aware of the chosen set of problems. This includes understanding the communicators, the means of communication and the time between the problem occurring and the news reaching the data science team. Figure 5 shows the Miro board used for this activity. This exercise serves to directly structure the scenario and design the discussion prompts, by collecting information on how these could be appear in the drill scenario.\nDiscuss: How would the team be made aware of such issues? Are the news sources outside or inside of the team? What channels does the team have for checking use to monitor applications? Who are the main informants and what is their relationship to the team?\nExamples: This could be colleagues responsible for monitoring the application and the models in place. It could also be colleagues directly in touch with end-customers such as the complaints department or communications. It could also just be a line manager."}, {"title": "7.2.4 Structuring the Drill Scenario", "content": "Task: Participants lay out their narrative using the structure in Figure 6. This includes an overarching theme, the goals for this drill, what ethical challenges it addresses and what internal processes or practices are being tested. Prompts can be delivered indirectly, e.g. the informant sends an e-mail, or in person, i.e. the informant attends the meeting. There are practical trade-offs in deciding between in person and email delivery of prompts, while in person offers the possibility of participants interacting with the informant, this requires the informant to be available for the drill and to be comfortable \"acting\". We found that this acting role suited some informants in the team more than others and that emails also successfully prompted engaging discussions. The overall structure of the drill should see problems getting increasingly more difficult and urgent to solve, so that discussions can build on top of each other. For each prompt, the intended learnings define the overall theme of the scenario. Giving participants action points that are explicit in the prompts, will help guide the discussion (for example, in an email prompt the sender can ask participants for help with an aspect of the problem). The prompts should include a sufficient amount of detail to feel realistic, but also consider what excuses can be made for leaving out details (e.g. access to the data set, which technical teams love to scrutinize). There are online tools to make convincing"}, {"title": "7.3 During the Drill - Executing the Drill", "content": "To start, the participants are briefed about the general setting of the drill and the code of conduct. Our general setting was a work meeting which is interrupted by outside events, which then take precedence over the discussion. The code of conduct should include the company code of conduct and generally establish the educational nature of the drill (as opposed to evaluating the team). It should ask participants to suspend disbelief during the session, but emphasise that all the events and prompts are fictional. Then the drill starts and the prompts are presented in succession. In our studies, this was coordinated by the researcher, who did not participate in the drills. The researcher/drill leader keeps time and sends out any prompts that are designed to be emails in the background. They can coordinate with one assigned participant, dubbed \"the mole\", who gives feedback if prompts are received and if it is an"}, {"title": "7.4 After the Drill - Reflecting", "content": "After the drill, participants answer a reflection questionnaire. The reflection questionnaire is to support participants in reflecting on their drill experience and expressing their learnings. It captures:\n\u2022 any questions that the drill was supposed to answer, which may or may not have come up in the discussion (see drill structure)\n\u2022 how the participant saw their role\n\u2022 how the participant interpreted the purpose of the drill\n\u2022 what changes the participant would like to see in their team based on the drill\n\u2022 what questions were left open\nThis questionnaire also contributes to scaffolding reflection [54], as it allows participants to revisit their experience and link it to"}, {"title": "8 FINDINGS", "content": "In the following section, we present the findings in three parts: the participant feedback directly after the session, the content analysis of the drill recordings and the evaluation through long-term interviews."}, {"title": "8.3 Long-term Evaluation", "content": "In the following section, we present the findings gained from follow-up interviews carried out with participants 9-15 months after the drill session. Quotes have been redacted for clarity. P1-P7 denote randomly assigned participant numbers."}, {"title": "8.3.1 The DEED provided a safe space for exploring realistic dilem-mas.", "content": "One team experienced a similar situation to their drill scenario, shortly after conducting the drill. The scenario had at one point questioned the role of developer responsibility when implementing customer requests that clashed with their values. Even though the details of the value clash and the part of the system in question were not the same in real life, they were able to directly draw on their ethical discussion skills from the drill.\nThis quote also shows that, in this case, the drill shaped the understanding of shared responsibility in the organisation. Because of"}, {"title": "8.3.2 The DEED opens up discussions and sharpens awareness to unarticulated responsibilities.", "content": "Several participants (5) reported taking more initiative in opening conversations about ethical issues and taking the discussion outside of the data science team."}, {"title": "8.3.3 The DEED confronts people with a diversity of opinions, but it could do more.", "content": "Some participants reflected on the experience of being confronted with differing opinions in their team."}, {"title": "8.3.4 The DEED should be part of an ongoing discussion.", "content": "While all participants had some positive takeaways, whether it was personal or organisational change, some participants (3) reported that they would have liked a more continuous discussion, to be able to enact some change."}, {"title": "9 DISCUSSION AND FUTURE WORK", "content": "We have not seen a silver bullet for responsible DS, AI and ML, and we believe that is not and should not be the end goal of responsible"}, {"title": "9.1 Towards a Context-Specific Understanding of Responsible AI Practice", "content": "AI. As our findings show, solutions to ethical issues are deeply intertwined with organisational structures, product context and broader questions about value tensions. Ethical literacy is a process, not an end goal and products should continually be monitored for value alignment. Similarly to Georgieva et al., we see the future of responsible AI as a \"landscape of methods, standards and procedure\" [23]. Our work demonstrates the value of incorporating context into responsible Al practice, and is a novel addition to this landscape. In our method, we sought to give DS teams several points where they could reflect on how ethical dilemmas apply to their specific contexts: when designing the drill scenario, when reacting to the prompts during the drill and when writing up their reflections afterwards. Not only did they step out of the technology-oriented routine of their delivery-focused mindset for the DEED, but they also showed how they were able to insert those elements back into real work conversations. This link between theory and real, contextual, organisational life is what has been highlighted as a major deficiency of current fairness toolkits [62]. Focusing on situated agency is in line with research considering response-ability [34] and located accountabilities [56]. We suggest that the key elements to the success of our method are three-fold: introducing friction, setting our method in a consequential environment and offering a safe space to explore responsibility beyond role definitions."}, {"title": "9.1.1 Friction.", "content": "Unlike checklists and frameworks, the DEED very much encourages DS teams to take action and confronts them with areas of friction and value tensions, as opposed to offering passive acknowledgement of principles and paying lip service to Al ethics. This idea is similar to the use of \"values seams\u201d in the Apologos design method [55] to make implicit human values of technology explicit. By framing ethical dilemmas as realistic drills, the DEED tries to make evident which developments are necessary and urgent and centres the focus on the agency of the members of the data science team and how their services directly affect people. We can see these effects in the responses to the long-term interviews, where participants show how the drill made them reflect on their role and make ethics a priority in discussions."}, {"title": "9.1.2 Consequentiality of the Drill Setting.", "content": "By replicating relationships and roles in the drill session, the drill becomes consequential in a similar way to speculative enactments [20]. The setting of the drill is real, in the sense that participants expose their own values and reasoning, which will shape relationships and conversations in the future. Hence, conversations during the drill have consequences. For example, P7 expressed this in 8.3.3 when they said that they understood the other participants' positions and P6 when they described how this shaped their self-understanding. This understanding was then brought into future, real-life conversations."}, {"title": "9.1.3 Mapping Responsibilities to Roles within the Organisation.", "content": "Modularity of software processes has been found to be a factor that may disconnect AI developers from accountability for their system [61]. A successful drill exposes the single modules and their interfaces, helping participants develop a better understanding of the responsible AI processes of the team as a whole. It may be that hierarchies and roles dictate, who will be exposed to certain ethical dilemmas in the day-to-day (e.g a manager will be more used to making high-level decisions than a junior data scientist). By connecting these roles in a scenario and creating a space where different roles and levels contribute to a discussion, we create transparency for different team members of what could or should happen when addressing ethical dilemmas. The contextual detail and realism of the scenario is crucial here in generating a useful discussion that practitioners can integrate into their work process. Furthermore, the fictional quality of the drill helps alleviate what P3 called the \"paralysis around decision making in the real world scenario because you can't afford to get anything wrong\" and creates a safe space for junior members to express their opinion."}, {"title": "9.2 Inserting the DEED into other Practitioner Teams", "content": "After carrying out three studies, mainly motivated by our research goals and the curiosity of data science teams, we can reflect on how we see this work organically being implemented in other DS/AI/ML teams. The first opportunity we see is using the DEED as a team-building activity, because of how it boosted confidence in the team and served as practice for addressing ethical issues. If the team is large enough, then subgroups could design DEED scenarios for each other to encourage people to not only engage with different projects across the team, but also with their most challenging aspects. Secondly, the DEED has the potential to be a powerful tool in making a case for ethical design. This work could help any stakeholder in the pipeline demonstrate the issues they see with an Al application and underline the urgency of process change.\nAI ethicists, team leads or values advocates, as studied in value-sensitive design [52], could take the lead in designing the scenarios and guiding the discussions. The DEED could readily be integrated with other frameworks, checklists, regulation or design methods, as these come with sections where risks of a model are addressed. For example, the DEED could respond to the question Is there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future uses? in datasheets for data sets [22] or to the section on Caveats and recommendations in model cards [39]. It could be used to play out situations that would address AI regulation to see if data science teams have sufficient knowledge to apply these laws in their contexts. The drill would transform those hypothetical risks on paper into realistic problems which require a solution."}, {"title": "9.3 Limitations", "content": "There are some limitations to the studies we have carried out. As shown in the results, participants seemed to have good team spirit and were engaged in the topic. It is possible that the overwhelmingly positive feedback and the success of the discussions of the drill was due to participants being volunteers, who self-selected as being interested in the topic. We did not have participants who were resistant to change or to methods which explored data science topics in a non-technical manner. We cannot speak for teams with strong hierarchical structures either or in toxic workplaces, but we could foresee the DEED playing out in a radically different manner in such environments. Being open to challenging one's values and open to discussing value matters with colleagues is a core pillar"}, {"title": "9.4 Future Work", "content": "One idea, that was outside the scope of these pilot studies, is to turn the drill into a conversation with the public outside of the Al industry. The DEED provides an obvious opportunity to not only engage with fictitious worries that exist inside a DS Team, but also to interact with concerns expressed by end-users, customers or wider society and to make them participants of the scenario crafting and the drill itself. Previous work on co-designing fictions"}, {"title": "10 CONCLUSION", "content": "Developers have \"moved fast and broken things\" for long enough. The Data Ethics Emergency Drill is an opportunity for them to take a step back from their application and reflect on their position and ability to react when things do break. It is a tool designed with and for data science practitioners that includes a workshop to brainstorm ethical emergencies that are relevant for their teams alongside proposed guidelines to execute emergency drills. Importantly, it is a proposal for new methods in responsible AI that elicit the linking of concrete work contexts to the abstract concepts of values and ethics. Participant feedback from initial runs of the DEED have shown that the format is realistic enough to foster useful discussions, help teams feel more comfortable in having challenging discussions, and elicit concrete action points to improve their processes with lasting impact in the teams conversations and responsible AI practice."}]}