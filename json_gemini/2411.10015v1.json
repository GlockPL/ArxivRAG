{"title": "MICROCRACKATTENTIONNEXT:\nADVANCING MICROCRACK DETECTION IN WAVE FIELD\nANALYSIS USING DEEP NEURAL NETWORKS THROUGH\nFEATURE VISUALIZATION", "authors": ["Fatahlla Moreh", "Bilal Zahid Hussain", "Yusuf Hasan", "Mohammad Ammar", "Sven Tomforde"], "abstract": "Micro Crack detection using deep neural networks(DNNs) through an automated pipeline using wave\nfields interacting with the damaged areas is highly sought after. However, these high dimensional\nspatio-temporal crack data are limited, moreover these dataset have large dimension in the temporal\ndomain. The dataset presents a substantial class imbalance, with crack pixels constituting an average\nof only 5% of the total pixels per sample. This extreme class imbalance poses a challenge for deep\nlearning models with the different micro scale cracks, as the network can be biased toward predicting\nthe majority class, generally leading to poor detection accuracy. This study builds upon the previous\nbenchmark SpAsE-Net, an asymmetric encoder-decoder network for micro-crack detection. The\nimpact of various activation and loss functions were examined through feature space visualisation\nusing manifold discovery and analysis (MDA) algorithm. The optimized architecture and training\nmethodology achieved an accuracy of 86.85%.", "sections": [{"title": "1 Introduction", "content": "Micro crack detection in materials is of significant importance due to the potential for catastrophic failures, which can\nlead to substantial financial losses and safety hazards in industries [Malekloo et al., 2022, Golewski, 2023]. Detecting\ncracks in complex structures, like aircraft bodies or intricate machinery components, poses a substantial challenge using\nconventional methods like visual inspection or standard cameras, especially when dealing with complex geometries.\nThe use of wave-based approaches for crack detection offers a powerful solution, as these methods allow for the analysis\nof structures that are not easily accessible or too complex to inspect manually.\nConvolutional Neural Networks (CNNs) are especially good at processing spatial data due to their ability to capture\nlocal spatial correlations within an image [LeCun et al., 2015]. Nevertheless, standard segmentation methods, such as\nvanilla architectures, demonstrate limited performance on this particular dataset, due to the complex spatio-temporal\nnature of the crack patterns. This becomes even more significant when the cracks represent a tiny minority in the dataset,\nleading to poor detection accuracy. This issue is enhanced when dealing with very small cracks, as they not only lead to\ndata imbalance but may also cause minimal disruption in wave behaviour. In such cases, the waves may exhibit minimal\nchanges, making it difficult for the model to detect the cracks accurately.\nThis challenge necessitates the development of a more tailored custom model. Our proposed MicroCrackAttentionNeXt\nis designed to overcome the limitations of vanilla models like UNet by incorporating enhanced spatial and temporal\nfeature extraction. Unlike UNet Ronneberger et al. [2015], where the input and target share the same modality (image-\nto-image translation). Our model processes spatio-temporal input data and outputs spatial crack predictions, enabling\nit to handle more complex data while improving micro-scale detection accuracy. The asymmetric encoder-decoder\nstructure, with attention layers is particularly effective as it focuses on capturing critical crack patterns rather than\nrelying heavily on skip connections. The attention mechanism ensures that the model prioritizes the time steps when\nthe waves interact with the cracks, improving detection precision. The DNNs capacity to recognise minute details and\ncomplex patterns in high dimensional data is impacted by the activation functions used, which becomes crucial in the\nmicro-scale setting where accuracy is much needed. Activation functions enhance the network's expressive power,\nenabling it to capture diverse features and representations.\nRectified Linear Unit (ReLU) Nair and Hinton [2010] and its variants are commonly used activation functions. ReLU\nintroduces non-linearity by setting negative values to zero, allowing positive ones to pass unchanged, which aids in deep\nnetwork training. The \"dying ReLU\" issue, where neurons become inactive, hampers learning Xu et al. [2015], He et al.\n[2015a]. Variants like Leaky ReLU mitigate this by allowing small negative slopes. SELU (Scaled Exponential Linear\nUnit) Klambauer et al. [2017] scales outputs to maintain self-normalizing properties, keeping activations near zero\nmean and unit variance. GeLU (Gaussian Error Linear Unit) Hendrycks and Gimpel [2023] enhances representation\nlearning by incorporating probabilistic elements, though it has higher computational complexity. ELU (Exponential\nLinear Unit) Clevert et al. [2016] improves learning dynamics but is computationally expensive. Various Loss functions\nhave been proposed in the literature to combat class imbalance issues in the DNN model. The loss functions tested are:\n1)Dice LossLin et al. [2018], 2)Focal LossLin et al. [2018], 3)Weighted Dice Loss Yeung et al. [2021] and, 4)Combined\nWeighted Dice LossJadon [2020].\nThese activation functions aim to strike a delicate balance between adaptability and computational efficiency, essential\nconsiderations in the micro-material domain, where capturing fine details is crucial for accurate crack detection.\nEmpirical exploration and meticulous fine-tuning of these activation functions is imperative to identify the optimal\nchoice that aligns with the distinctive characteristics of micro-material images. Ultimately, a nuanced and effective\napproach to crack detection in micro-materials relies on the thoughtful selection and optimization of activation functions\nwithin the CNN architecture.\nThe extent of the influence of different activations is difficult to determine against conventional metrics such as accuracy\nand F1 score. Hence, it is imperative to analyse the internal dynamics of the model. Methods like Principal Component\nAnalysis, t-SNE van der Maaten and Hinton [2008] and UMAP McInnes et al. [2020] are used to analyse the higher\ndimensional feature maps of these blackbox models against the target. However, these methods provide little to no\ninsight when used on segmentation problems. In this study, we use the recently proposed Manifold Discovery Analysis\n(MDA) Islam et al. [2023] to qualitatively assess the impacts of various activation functions. Moreover, through this,\nwe were able to analyse the effects activations had on the feature maps of the model, allowing us to choose the best\nactivation function for the given problem.\nThe primary contributions of this paper are:\n\u2022 Introducing MicroCrackAttentionNeXt \u2013 an incremental improvement over [Moreh et al., 2024].\n\u2022 Qualitative Investigation of the impact of activations MicroCrackAttentionNeXt through Manifold Discovery\nand Analysis."}, {"title": "2 RELATED WORK", "content": "In a number of areas, including materials science, aerospace, and infrastructure, where the existence of small fissures\nmight jeopardise the structural integrity of materials, micro-crack detection is essential [Chen et al., 2024, Yuan et al.,\n2022, Retheesh et al., 2017]. Conventional techniques for detecting microcracks are frequently labour-intensive and not\nvery scalable. Deep learning, and Convolutional Neural Networks (CNNs) in particular, have become a potent and\neffective technique for microcrack detection automation in recent years[Su and Wang, 2020, Chen and Jahanshahi,\n2017, Hamishebahar et al., 2022].\nTran et al. [2024] applied 1D Convolutional Neural Networks (1D CNNs) for structural damage detection, utilizing\nacceleration signals to detect cracks in numerical steel beam models. Their approach showed high detection accuracy,\ncomparable to more complex methods, by processing time-series data and extracting key features related to structural\nchanges. While they focused on single-dimensional data, our research extends this by using multi-dimensional spatio-\ntemporal data, which includes wave propagation across the material. This allows for more detailed analysis, capturing\nboth spatial and temporal interactions crucial for detecting micro-cracks.\nJiang et al. [2022] combined 1D CNNs with Support Vector Machines (SVM) to enhance structural damage detection.\n1D CNNs were used to localize damage, while SVMs focused on classifying the severity, benefiting from the strengths\nof both models in feature extraction and small-sample learning.\nBarbosh et al. [2024] used Acoustic Emission (AE) waveforms and DenseNet to detect and localise the crack. The\nlocalisation was done to determine whether the crack was close to the sensor or far away. The cracks were also classified\ninto severe and less severe cracks.\nMoreover, Li et al. [2023] proposed a GM-ResNet-based approach to enhance crack detection, utilizing ResNet-34 as the\nfoundational network. To address challenges in global and local information assimilation, a global attention mechanism\nwas incorporated for optimized feature extraction. Recognizing limitations in ResNet-34, the fully connected layer\nwas replaced with a Multilayer Fully Connected Neural Network (MFCNN), featuring multiple layers, including batch\nnormalization and Leaky ReLU nonlinearity. This innovative substitution significantly improved the model's ability\nto capture complex data distributions and patterns, enhancing feature extraction and representation capabilities while\npreventing overfitting during training.\nWuttke et al. [2021] introduced a 1D-CNN-based model, SpAsE-Net, for detecting cracks in solid structures using\nwave field data. The model leverages sparse sensor data and the Dynamic Lattice Element Method (LEM) for wave\npropagation simulations. The network's architecture includes fully convolutional layers for spatial feature fusion and a\npredictor module using transposed convolutional layers and focal loss for crack localization. It achieves around 85%\naccuracy in detecting small cracks(>1 \u00b5m) and 97.4% accuracy in detecting large cracks(>4 \u00b5m) by tuning the focal\nloss parameters.\nMoreh et al. [2022] present a DNN based method for detecting and localizing cracks in materials using spatio-temporal\ndata. They introduce two CNN architectures: a SimpleCNN (SCNN) as a baseline model and a more complex Residual\nNetwork (ResNet18) encoder. SCNN and ResNet18 leverage 1D convolutions to extract temporal features from the\nwave data, followed by 2D convolutions for spatial feature extraction. Both models employ a decoder with transposed\nconvolutional layers to upscale the encoded features and predict a binary mask indicating the crack locations. The\nmodels were evaluated on simulated wave propagation data, where cracks ranging from 0.4 to 12.8 \u00b5m in size. ResNet18\noutperformed SCNN and achieved a precision of 0.92, recall of 0.719 and a DSC of 0.744. .\nMoreh et al. [2024] explores the use of DNN for automated crack detection in structures using seismic wave signals. The\nauthors improve on previous asymmetric encoder-decoder models by experimenting with different encoder backbones\nand decoder layers. The best combination was found to be the 1D-DenseNet encoder and the Transpose Convolutions\nas decoders. The proposed model achieved an accuracy of 83.68% with a total parameter count of 1.393 million.\nThis work is heavily influenced by Wuttke et al. [2021]Moreh et al. [2024], and in a sense is an extension of it."}, {"title": "3 METHOD", "content": "Our proposed work targets the detection of microcracks across various sizes and locations within seismic wave field\nnumerical data. For this purpose, our MicroCracksAttentionNeXt extracts crucial signals from the data to identify and\ndetect those cracks. This is done by first learning the temporal representations, followed by spatial representations. This\nencoded data is then passed through the decoder to achieve semantic spatial segmentation.\nIn this section, we describe the seismic wave data followed by the architecture of the proposed MicroCrackAttentionNeXt\nmodel and, subsequently, the training procedure used."}, {"title": "3.1 Wave field data", "content": "The wave field dataset utilized in this work, while effective for crack detection, presents some limitations in terms of\ndata dimensionality. These datasets are characterized by large temporal dimensions, which increases the complexity of\ndata processing and model training. The dataset consists of homogeneous 2D plates, where each plate is modelled with\nlattice particles that share consistent properties, such as density and Young's Modulus. To simulate wave propagation\nthrough the material, an external force of 1000 N is applied at the midpoint of the left boundary, ensuring that the waves\npropagate across the entire plate, interacting with both non-crack and crack regions. The resulting displacements in\nboth the x- and y-directions are recorded over 2000 time steps, capturing detailed temporal changes in the wave field.\nThese displacements are measured by a 9 \u00d7 9 (81) sensor grid uniformly distributed across the material, resulting in\na wave field dataset with dimensions of 2 x 81 x 2000. This approach\nprovides spatio-temporal data that captures the interaction between the propagating waves and the cracks, allowing for\nin-depth analysis of crack detection model performance.\nA major challenge arises from the severe class imbalance present in the dataset. On average, only 5% of the total pixels\nrepresent cracks, with the remaining majority belonging to intact, non-crack regions. This imbalance poses a substantial\nobstacle for deep learning models, which are prone to bias toward the majority class. As a result, the models tend\nto predict non-crack regions more frequently, leading to suboptimal detection accuracy for the minority class (crack\nregions). Addressing this issue requires careful design of the model and training process to ensure that the network\ncan effectively learn from the minority class, and accurately identify crack regions without being overpowered by the\nmajority class imbalance."}, {"title": "3.2 MicroCracksAttentionNeXt Model Architecture", "content": "MicrocrackAttentionNeXt, shown in Figure 2, is an asymmetric encoder-decoder network. The input to the model\nis a tensor with shape $X \\in \\mathbb{R}^{C_{in}\\times T \\times S}$, where $C_{in}$ = 2 represents the input channels corresponding to the $x$ and $y$\ncomponents of wave data, $T$ = 2000 is the temporal dimension, and $S$ = 81 corresponds to the spatial dimension,\nwhich is a flattened 9 \u00d7 9 sensor grid. To reduce computational complexity and focus on salient temporal features,\nthe network uses an initial max pooling layer with a kernel size of (4, 1). This layer transforms the input tensor $X$ to\n$X_1 \\in \\mathbb{R}^{2\\times 500\\times 81}$ by downsampling the temporal dimension from 2000 to $T_1$ = 500. This reduction is crucial as it\nreduces the amount of data the subsequent layers need to process.\nThe encoder is composed of four convolutional blocks, each designed to progressively extract higher-level features from\nthe input data. The first convolutional block applies two convolutional layers with kernel sizes (3, 1) and padding (1,0),\nwhich maintain the spatial dimensions while expanding the channel dimension from 2 to 16. These layers are followed\nby batch normalization and activation functions, introducing non-linearity. A Squeeze-and-Excitation (SE) module is\nthen applied, which recalibrates channel-wise feature responses by modelling interdependencies between channels.\nThis module enhances the representational power of the network by allowing it to focus on the most informative\nfeatures. Following the first convolutional block, a max pooling layer with a kernel size of (2, 1) further reduces the\ntemporal dimension from 500 to $T_2$ = 250. Group normalization is applied to the data, normalizing across channels\nand improving convergence during training. An AttentionLayer computes self-attention over the temporal and spatial\ndimensions, enabling the network to weigh different parts of the input differently. This attention mechanism is essential\nfor focusing on relevant features and capturing dependencies across the data. A residual connection adds the attention\noutput back to the original input, facilitating better gradient flow and mitigating issues such as vanishing gradients\n[Raghu et al., 2022, He et al., 2015b].\nThis pattern repeats in the subsequent convolutional blocks, with each block increasing the number of channels (from\n16 to 32, 32 to 64, and 64 to 128) and further reducing the temporal dimension (from 250 to 125, 125 to 62, and\n62 to 31) through additional pooling layers. The consistent use of (3, 1) kernels ensures effective temporal feature\nextraction while preserving spatial dimensions. SE modules and attention mechanisms are integrated throughout. At the\nbottleneck of the network, a convolutional layer with a large kernel size of (31, 1) is employed, covering the entire\ntemporal dimension $T_5$ = 31. This layer transforms the tensor to $X_{bottleneck} \\in \\mathbb{R}^{B\\times 128\\times 1\\times 81}$, capturing long-range\ntemporal dependencies and encapsulating high-level temporal information into a compact form. Batch normalization\nand activation are applied to maintain training stability and introduce non-linearity.\nThe decoder begins by reshaping this bottleneck tensor into a spatial grid $X_{reshaped} \\in [\\mathbb{R}^{128\\times 9\\times 9}$, reorganizing the data\nfor spatial processing. A point-wise convolution reduces the channel dimension from 128 to 16, preparing the data for\nupsampling. The network then uses transposed convolutional layers to reconstruct the spatial dimensions progressively.\nThe first transposed convolution upsamples the spatial dimensions from 9 \u00d7 9 to 18 \u00d7 18 and reduces the channel\ndimension from 16 to 8. The second transposed convolution further upsamples the dimensions to 36 \u00d7 36, maintaining\nthe channel count at 8. Each transposed convolution is followed by batch normalization to ensure stable learning and\neffective non-linear transformations.\nFinally, a point-wise convolution reduces the channel dimension from 8 to 1, and a sigmoid activation function scales\nthe output to the range [0, 1]. The output tensor $Y \\in \\mathbb{R}^{1\\times 36\\times 36}$ represents the reconstructed spatial data, which is then\nflattened into a vector $Y_{flat} \\in \\mathbb{R}^{1296}$ (since 36 \u00d7 36 = 1296), making it suitable for downstream tasks. The architectural choices in MicrocrackAttentionNeXt are designed to balance feature\nextraction capability and computational efficiency. The initial temporal downsampling reduces the data size, allowing\nthe network to process longer sequences without excessive computational overhead. The 1D convolutional blocks with\nincreasing channel dimensions enable the extraction of hierarchical features in the temporal domain, without mixing\nthe spatial component. We found that learning temporal and spatial components separately enables the model to learn"}, {"title": "3.3 Training Procedure", "content": "The model was trained using the Adam optimizerKingma and Ba [2017] with a learning rate of 0.001 for a total of 50\nepochs. Multiple experiments were run on different activation functions and loss metrics. The experiments involved\nevaluating four different activation functions against four loss metrics, resulting in a total of 16 experiments. The\nactivation functions and loss metrics are outlined below."}, {"title": "3.3.1 Activation Functions", "content": "1. ReLU (Rectified Linear Unit):\nReLU is a simple activation function that outputs the input directly if it is positive; otherwise, it returns zero.\nThis introduces non-linearity while avoiding issues related to vanishing gradients.\n$ReLU(x) = max(0, x)$ (1)\n2. SELU (Scaled Exponential Linear Unit):\nSELU combines the benefits of self-normalizing properties, helping to automatically normalize the outputs. It\nscales negative values by an exponential function and multiplies positive values by a fixed constant.\n$SELU(x) = \\lambda \\begin{cases}\nx & \\text{if } x > 0 \\\\\n\\alpha(e^x - 1) & \\text{if } x < 0\n\\end{cases}$ (2)\nwhere $ \\lambda $ = 1.0507 and $ \\alpha $ = 1.67326.\n3. GELU (Gaussian Error Linear Unit):\nGELU smoothly blends linear and non-linear behavior by utilizing the Gaussian cumulative distribution\nfunction, making it more flexible in capturing complex patterns. The function approximates the input's\nsignificance probabilistically.\n$GELU(x) = x \\cdot \\Phi(x)$ (3)\nwhere $\\Phi(x)$ is the cumulative distribution function of the standard normal distribution:\n$\\Phi(x) = \\frac{1}{2} \\left[1 + erf\\left(\\frac{x}{\\sqrt{2}}\\right)\\right]$ (4)\n4. ELU (Exponential Linear Unit):\nELU outputs the input if it is positive, but for negative values, it applies an exponential function, thus mitigating\nthe vanishing gradient problem more effectively than ReLU, while enabling faster convergence.\n$ELU(x) = \\begin{cases}\nx & \\text{if } x > 0 \\\\\n\\alpha(e^x - 1) & \\text{if } x \\leq 0\n\\end{cases}$ (5)\nwhere $\\alpha$ is typically set to 1."}, {"title": "3.3.2 Loss Functions", "content": "1. Dice Loss:\nDice Loss is based on the Dice coefficient and is commonly used for segmentation tasks. It measures the\noverlap between the predicted and true labels, focusing on improving performance for imbalanced datasets.\n$Dice Loss = 1 - \\frac{2X \\cap Y}{|X| + |Y|}$ (6)\nwhere X and Y are the predicted and true sets, respectively.\n2. Focal Loss:\nFocal Loss is designed to address class imbalance by down-weighting the loss assigned to well-classified\nexamples, making the model focus more on hard-to-classify instances.\n$Focal Loss(p_t) = -\\alpha(1 - p_t)^\\gamma log(p_t)$ (7)\nwhere $p_t$ is the predicted probability, $\\alpha$ is a weighting factor, and $\\gamma$ is a focusing parameter."}, {"title": "3. Weighted Dice Loss:", "content": "Weighted Dice Loss is a variation of Dice Loss that assigns different weights to different classes, enhancing\nperformance on datasets with imbalanced class distributions by penalizing certain classes more.\n$Weighted Dice Loss = 1 - \\frac{2 \\sum W_i x_i y_i}{\\sum w_i x_i^2 + \\sum w_i y_i^2}$ (8)\nwhere $w_i$ is the weight assigned to class i, and $x_i$, $y_i$ are the predicted and true values for class i."}, {"title": "4. Combined Weighted Dice Loss:", "content": "This is a hybrid loss that combines Weighted Dice Loss and CrossEntropy Loss, allowing the model to balance\noverall performance while addressing class imbalances by tuning the contribution of each component.\n$CWDL = \\alpha \\cdot WDL + (1 - a) \\cdot CrossEntropy Loss$ (9)\nwhere CWDL is Combined Weighted Dice Loss, WDL is Weighted Dice Loss and, $\\alpha$ is a weighting factor to\nbalance the two loss components.\nWe found the combination of Combined Weighted Dice Loss and GeLU to be the best performing. The combined\nweighted dice loss performed the best across all the activations. However, we found that we were able to squeeze more\naccuracy through the GeLU function."}, {"title": "3.4 Metrics", "content": "For the evaluation part, we utilized the same metrics as in Moreh et al. [2024], namely Dice Similarity Coefficient\n(DSC) and accuracy which frequently employed to evaluate the performance of models. The DSC measures the overlap\nbetween predicted and actual results, particularly in segmentation tasks. Its mathematical formulation is given by:\n$DSC = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}$ (10)\nAccuracy measures the overall correctness of the predictions by calculating the proportion of true results, both positive\nand negative, over the total number of cases, given by:\n$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$ (11)"}, {"title": "4 Results & Discussion", "content": null}, {"title": "4.1 MDA Analysis", "content": "Manifold Discovery and Analysis (MDA) helps visualize the higher dimensional manifolds formed by the intermediate\nlayers of the model in lower dimension [Islam et al., 2023]. These plots help visualise the learned features in the $l^{th}$\nlayer with respect to the output manifold. Unlike methods like t-SNE and UMAP, which only work on classification\ntasks, MDA works on regression tasks, where the output manifold can have a complex shape. MDA also preserves the\ngeodesic distances between higher dimensional feature points, preserving both local and global structure.\nIn a nutshell, MDA works as follows: First, distance is computed between the estimated outputs of the DNN, from this\ndistance the farthest point is chosen to construct the boundary of the output manifold. All the points are sorted w.r.t\nthe farthest point in k bins using optimal histogram bin count. These bins become the labels that will be used in the\nsecond step. Second, the high dimensional features from an intermediate layer are projected to the manifold using the\nBayesian manifold projection (BMP) approach. BMP computes a posterior distribution over the low-dimensional space\nby combining the prior (based on pseudo-labels and manifold structure) with a likelihood (based on the observed data).\nFinally, a DNN trained on predicting the location of uncertain Bayesian points on a 2D embedding space is used to\nvisualise the results. The plots are assessed qualitatively on the following points:\n\u2022 Feature Separation and Continuity: The MDA visualization shows a curved shape, indicating that the features\nextracted from the neural network follow a smooth continuum along the manifold. This suggests that the\nneural network is capturing meaningful information.\n\u2022 Color Gradient: A spectrum of gradients is shown, implying that the model has learned to separate different\nfeatures."}, {"title": "5 Conclusion and Future work", "content": null}, {"title": "5.1 Conclusion", "content": "Through this study, we have demonstrated the effectiveness of feature visualization in designing MicroCrackAttention-\nNeXt, by carefully optimizing the architecture, leveraging the right activation function and loss. This architecture also\nutilizes multiple 1D-CNN layers for feature extraction, significantly reducing the training time. These are followed by\nfolded layers that merge spatial and temporal features, along with a prediction module for semantic segmentation. The\ndataset used are spatio-temporal in nature and represent the behavior of wave propagation, where waves interact with\nthe cracks, leading to disruptions in their patterns and altered behavior in the presence of cracks. The model is capable\nof segmenting the microcracks, helping to determine their spatial locations in the material. The qualitative examination\nof the activation functions using the Manifold Discovery and Analysis (MDA) algorithm allowed the evaluation of\nimpact of different activation and loss functions on the model's performance. The proposed model and 1D-Densenet\nwere analyzed using the MDA plots. It was observed that manifold of the proposed model was more compact with a\nmuch more smoother arc than 1D-Densenet. With the optimized selection of activation and loss functions, an accuracy\nof 86.85% was achieved."}, {"title": "5.2 Future work", "content": "In future efforts to improve microcrack detection models, two primary strategies can be pursued: expanding datasets and\nrefining model architectures. The dataset used, presents a challenge due to severe class imbalance, which requires more\nadvanced techniques for data generation and augmentation to mitigate the bias introduced. Moreover, the segmentation\noutput suffers from low resolution, and without appropriate upscaling techniques, critical details may be lost. To address\nthis, in the future works, we propose incorporating a super-resolution GAN approach to enhance the resolution of\nthe segmentation outputs. While the encoder architecture performs optimally, further changes are necessary in the\ndecoder section of the segmentation model to achieve improved results and maintain consistency with the high-quality\ninput features. To enhance the encoder's ability to capture long-range dependencies, state space model can be used,\nparticularity integrating the recently proposed Mamba architecture. This adjustment would improve the model's ability\nto handle complex spatial relationships, thereby strengthening feature extraction and contributing to overall performance\ngains in the segmentation task."}]}