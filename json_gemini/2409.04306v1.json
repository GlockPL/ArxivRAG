{"title": "Safe and Efficient Path Planning under Uncertainty via Deep Collision Probability Fields", "authors": ["Felix Herrmann", "Sebastian Zach", "Jacopo Banfi", "Jan Peters", "Georgia Chalvatzaki", "Davide Tateo"], "abstract": "Estimating collision probabilities between robots and environmental obstacles or other moving agents is crucial to ensure safety during path planning. This is an important building block of modern planning algorithms in many application scenarios such as autonomous driving, where noisy sensors perceive obstacles. While many approaches exist, they either provide too conservative estimates of the collision probabilities or are computationally intensive due to their sampling-based nature. To deal with these issues, we introduce Deep Collision Probability Fields, a neural-based approach for computing collision probabilities of arbitrary objects with arbitrary unimodal uncertainty distributions. Our approach relegates the computationally intensive estimation of collision probabilities via sampling at the training step, allowing for fast neural network inference of the constraints during planning. In extensive experiments, we show that Deep Collision Probability Fields can produce reasonably accurate collision probabilities (up to 10\u207b\u00b3) for planning and that our approach can be easily plugged into standard path planning approaches to plan safe paths on 2-D maps containing uncertain static and dynamic obstacles. Additional material, code, and videos are available at https://sites.google.com/view/ral-dcpf.", "sections": [{"title": "I. INTRODUCTION", "content": "Safety is one of the most critical issues that needs to be solved to deploy autonomous agents in the real world. This is particularly important for autonomous robots and cars, as the perception of the world is subject to different sources of uncertainty such as noisy sensor measurements, approximate target tracking models, sensor malfunctioning, or adversarial attacks [1]. To deal with uncertainty, path planning and control approaches could incorporate some form of probabilistic constraints [2]. Using such constraints, we can force the Collision Probability (CP) to take very small values while preventing the planner from generating overly conservative paths, leveraging the accurate uncertainty estimate coming from modern perception systems.\nHowever, even for 2D cases, with robots and obstacles of simple shapes (cf. Fig. 1), whose pose is described by a Gaussian distribution, it is impossible to calculate the CP in closed form. To incorporate CP constraints in path planning, researchers explored two main directions: approximate methods, such as [3], [4], [5], [6], and sampling-based methods [7], [8], [1]. Both approaches have some key issues. To ensure the satisfaction of the CP constraints, approximate methods are prone to be over-conservative, preventing the robot from maneuvering in tight gaps. Conversely, sampling-based methods are often computationally intensive and do not scale well when reducing the CP constraint. This issue is critical in autonomous driving since it requires real-time decisions and, at the same time, very low CP values.\nTo tackle these issues, we introduce Deep Collision Probability Fields (DCPF), a neural-based approach for computing collision probabilities. The key idea of DCPF is to relegate a time-consuming Monte-Carlo estimate of the CP to the dataset generation phase while allowing for fast neural network evaluation of the constraints during planning. Our network design is inspired by Signed Distance Function (SDF), a technique extensively used to quickly compute distances between objects of arbitrary shapes. We reformulate the SDF approach in the setting of collision probabilities and, based on the ideas presented in [9], we introduce a novel inductive bias that enforces reasonable predictions even where the training data is sparse or non-existent, by gradually reducing the CP to zero as the distance between the two objects increases and forcing the CP to approach one if the distance is small. DCPF has three significant advantages. First, we can learn the CP from data under arbitrary probability densities. Second, we can create smooth and differentiable distance fields, a particularly desirable property for trajectory optimization. Finally, using deep neural networks allows for"}, {"title": "A. Related Work", "content": "Prior works that studied CP constraints in the context of path planning can be classified along several orthogonal dimensions. The most important are (1) the method used to compute the CP, namely, sampling-based or approximated, (2) the type of uncertainty (Gaussian or more complex), (3) where uncertainty is assumed to be present (robot, obstacles, or both), and (4) whether the CP constraint is enforced on a single trajectory step, or along the full trajectory. Due to abundant literature on the subject, only a few approaches are discussed below. We refer to [6] for a more comprehensive overview.\nLambert et al. [7] assume Gaussian uncertainty on both the robot's and obstacles' pose, and use Monte Carlo sampling to compute step-wise collision probabilities which, in turn, allow to compute a safe speed profile. More recently, Schmerling and Pavone [8] considered uncertainty in the robot's execution of its nominal trajectory, and use Monte Carlo with importance sampling to compute the trajectory CP. Banfi et al. [1] consider complex, potentially multi-modal obstacles' uncertainties that might arise in adversarial contexts, and propose a method based on the Sequential Ratio Probability Test (SPRT) to compute CPs for partial trajectories obtained during planning. A common advantage of these sampling-based methods is that they naturally come with theoretical guarantees, as it is easy to identify precise standard errors, confidence intervals, etc., of the computed CPs. However, a common downside of these methods is that they are computationally intensive, and might require thousands of samples to give reasonably precise estimates of small CPs. While in this paper we leave the investigations of theoretical guarantees for future work, we remark that our approach could already be used to identify promising regions of the planning space on which such guarantees could be derived via sampling.\nOther approaches for CP estimation consider different types of approximations to reduce the computation time. Bry and Roy [3] assume the uncertainty on the robot's pose to be Gaussian and use the approximation of checking the ellipse defined by the covariance matrix and a desired chance bound for enforcing step-wise CP constraints. A similar approach is used by Kamel et al. in [5]. Hardy and Campbell [2] consider Gaussian uncertainty on the obstacles' positions and use rectangular bounding boxes for both the robot and the obstacles to obtain a CP upper bound. Thomas et al. [6]"}, {"title": "B. Problem Formulation", "content": "We consider a mobile robot operating in a n-dimensional environment specified by a bounded region $X \\subset \\mathbb{R}^n$. We assume $X$ is composed of a static untraversable region $X_{obs} \\subset X$ - known without uncertainty - and free space $X_{free} = X \\backslash X_{obs}$, with $X_{free} \\cap X_{obs} = \\emptyset$. Let $O = \\{o_k\\}$ be a set of k independent obstacles. Each obstacle is completely described by the tuple $o = (C_o, p_o(q_o), V_o(q_o))$ where $C_o \\subset \\mathbb{R}^n$ is the space of all possible object configurations - such as position, orientation, and lengths - describing the properties of the obstacle, $p_o(q_o)$, is a probability distribution of each obstacle configuration $q_o \\in C_o$, representing the uncertainty of the perceived obstacle, and $V_o(q)$ is the set of points occupied by the obstacle assuming that the true obstacle configuration is $q_o$. We assume that the robot's position is known without uncertainty. Therefore, the robot can be defined as the tuple $r = (C_r, V_r(q_r))$, where $C_r$ denotes the configuration space of the robot and $V_r(q_r)$ denotes the set of points occupied by the robot at configuration $q_r \\in C_r$. In this paper, we focus on the special case where the robots and the obstacles are 2D rectangles with sides $l_1$, and $l_2$, with isotropic Gaussian uncertainty. Under these assumptions, the obstacles can be described by the following parameter vector $q_o = [x, y, \\phi, l_1, l_2]^T$ with $q_o \\sim N(\\mu, \\Sigma)$.\nThe collision probability $P_{coll}(r, o)$ between robot r and obstacle o is defined as\n$P_{coll}(r, o) = \\int_D p_o(q_o)dq_o$,\nwhere $D = \\{q_o | q_o \\in C_o, V_r(q_r) \\cap V_o(q_o) \\neq 0\\}$. Our goal is to compute an approximated version of $P_{coll}(r, o)$ with a neural network, which we denote $\\hat{P}_{coll}(r, o)$, and show that it can be used in several planning settings. To this aim, we define the following family of planning problems.\nLet $q_r(0)$ be the initial robot configuration and $Q_G \\subset X_{free}$ is the set of admissible goals states. Let $P$ be the space of all possible paths. We assume that every path $\\pi = [\\alpha_0,...,\\alpha_T] \\in P$ is composed by a set of T motion primitives $\\alpha(t)$. Each motion primitive moves the robot from a configuration $q_r(t)$ to a new configuration $q_r(t + \\Delta t)$. Finally, let $r(t)$ and $o(t)$ denote the tuples describing robot and obstacle at step t.\nWe consider planning problems of the following form\n$\\mathop{\\mathrm{arg\\,min}} \\limits_{\\pi} c(\\pi) = \\sum_{\\alpha_t \\in \\pi} c(\\alpha_t)$\ns.t. $1 - \\prod_i (1 - P_{coll}(r(t), o_i(t))) \\leq P_{max} \\forall t$,\n$q_r(t) \\in X_{free} \\forall t$, $q_r(T) \\in Q_G$,\nwhere $P_{max} \\in [0,1]$ is the maximum CP allowed for the planned trajectory and $c(\\pi)$ is a cost function, like path"}, {"title": "II. DEEP COLLISION PROBABILITY FIELDS", "content": "Our goal is to approximate the collision probability between a robot and an arbitrary object efficiently by means of a neural network, hence, we introduce DCPF that exploit neural approximations to obtain rapidly accurate CP estimates. We make two modeling assumptions: first, we consider the coordinate frame defined in the obstacle's center of mass, instead of the world coordinate frame. Second, we assume a parametric form for the obstacle's probability distribution, $p_o(q_o;\\omega_o)$ where $\\omega_o$ represents the distribution's parameters. For example, assuming Gaussian uncertainty, the distribution parameters are the covariance matrix entries, $\\omega_o = \\Sigma_o$. Notice that, given that the coordinate system is obstacle-centric, the obstacle distribution mean for position and rotation is zero. We assume that the distribution family is known and that the distribution parameters are estimated from a perception system. Thanks to these assumptions we can easily impose an inductive bias in the network's structure, forcing the probability of collision to smoothly decrease to zero, when the distance between the object and the robot increases, while making it close to one when the two objects overlap. This inductive bias, inspired by the one presented in [9], exploits the fact that sufficiently far from the object, both the shape and the object uncertainty are irrelevant, as the collision probability will drop to zero. This bias allows us to efficiently learn the probability field for any configuration while keeping the probability approximation smooth."}, {"title": "A. Network structure", "content": "Using the above-mentioned assumptions and implementing the distance-based inductive bias, we obtain the following network structure\n$P_{coll}(q_r, \\omega_o) =(1 - \\sigma_1(q_r, \\omega_o)) ((1 \u2013 \\sigma_2(q_r, \\omega_o))f_{\\theta}(q_r,\\omega_o)) + \\sigma_2(q_r, \\omega_o)$,\nwith the current robot configuration $q_r$, the parameters of the obstacle density $\\omega_o$ and the vector of learnable parameters of the neural network $\\theta$. Furthermore, for $i \\in \\{1,2\\}$, we define two functions as\n$\\sigma_i(q_r,\\omega_o) = sigmoid (s_i \\phi(q_r, w_o) \\cdot (p_o (q_r, w_o) \u2013 ||x||^2))$,\nwhere $\\phi(q_r,w_o)$ defines a soft threshold for switching from a local approximated collision probability to the one predicted by the inductive bias (zero or one), $\\phi(q_r, w_o)$ regulates the sharpness of the change between the two modes,"}, {"title": "B. Data generation", "content": "We resort to a sampling-based method to generate an accurate dataset that does not leverage approximations to compute CPs. Specifically, since we are not bound by time constraints at this stage, we resort to Simple Monte Carlo sampling. Another key observation is that the desired accuracy of the CP estimate directly depends on the CP itself. For example, suppose that after having drawn 10k samples, our current CP estimate is .5; in this case, we would accept an error of .01, especially if our planning constraint Pmax is .01 or .1. Following from this observation, we define the following probability intervals: [0, .01), [.01, .1), [.1, 1]. Each interval is then associated with a different desired accuracy for a Central Limit Theorem (CLT) based 95% confidence interval estimate\u00b9: \u00b1.01, \u00b1.001, \u00b110-4. Therefore, we can stop drawing samples as soon as the current CLT-based 95% confidence interval falls below the accuracy associated with the current CP estimate. To speed up this procedure, we only recompute the CP estimate and associated confidence interval after having drawn a batch of samples. We use batches of 4\u00b7104 samples, and 4\u00b7106 maximum total samples, computed as the worst-case number of samples needed for the smallest probability interval.\nAnother issue to consider during the training is to sample properly the robot configurations to be evaluated. Indeed, if the dataset size is a concern, sampling uniformly may require a prohibitively large amount of samples to properly cover the areas where the estimation of collision probability is particularly sensible. We propose a sampling method based on the Minkowski Sum (MS) between the robot and the obstacle. The MS is the shape obtained by sliding the robot shape around the obstacle [11]. Our key idea is to compute a shape that resembles the isolines of the CP landscape, particularly close to the constraint budget level, and subsequently sample points from it. In a scenario without uncertainty, this shape can be trivially obtained by computing the MS between the robot and the obstacle. To take the uncertainties $\\Sigma_o = (\\sigma_x,\\sigma_y,\\sigma_{\\phi}, \\sigma_{l_1}, \\sigma_{l_2})$ into account we apply various strategies. For positional and shape variance we construct an inflated shape $S_{inflated}$ by computing a MS between the shape of the obstacles and an ellipse $s_e \\sim \\mathcal{N}(\\sigma_x + \\sigma_{l_1}, \\sigma_y + \\sigma_{l_2} \\Sigma_o = (\\sigma_x + \\sigma_{l_1}, \\sigma_y + \\sigma_{l_2}))$. The effects of rotational variance are approximated by constructing the shape $S_{rotational}$, by computing the union of multiple $S_{inflated}$ for rotated obstacles $s_o$. On top of that, we smooth the obtained shape by growing and shrinking $S_{rotational}$. The rotations are a discretization of the interval $[-\\phi_m,\\phi_m]$ with $\\phi_m \\sim \\mathcal{U}(\\sigma_o, 3.1 \\cdot \\sigma_o)$. In our experiment, we found that three rotations are sufficient, for this heuristic to result in sample configurations for a well-balanced dataset."}, {"title": "C. Training", "content": "We train our model by optimizing the following loss\n$L(D) = \\sum_{q_r,\\omega_o, p \\in D} H (P_{coll} (q_r, \\omega_o), p) + \\gamma \\cdot R (q_r, \\omega_o)$,\nwhere H is the binary cross-entropy between the CP prediction of the network, p the target value computed in the dataset, and R is a regularization term, weighted by a $\\gamma$ coefficient, composed by the sum of the following two terms\n$R (q_r, \\omega_o) = |\\Delta p_{\\theta}| + \\sum_{i=\\{1,2\\}} sigmoid (s_i \\phi_{s_{ag}} \\cdot \\Delta p_{\\theta}/2)$,\nwith $\\Delta p_{\\theta} = p_0 \u2013 p_0$ the difference of the mode switching parameters. The first term of the regularizer forces the network to switch between the regimes of data-driven collision probabilities to the inductive bias of zero or one probabilities as soon as possible, by bringing the thresholds $p_{\\theta}$ closer together. The second term enforces the thresholds to be in the right order by minimizing the influence of the bias in their center. The regularization term is particularly important in areas with low sample density."}, {"title": "III. EVALUATION", "content": "We empirically evaluate DCPF in three sets of experiments. The first experiment evaluates the CP predictions obtained by DCPF on a dataset inspired by an autonomous driving scenario, examining the impact of number and size of network layers. In the second experiment, we use the best network obtained in the first experiment to tackle two simulated planning scenarios: one with static obstacles and one with dynamic obstacles. In the third experiment, we validate DCPF in the real world with two TIAGO robots (Fig. 9), where one acts as the agent and the other acts as a dynamic obstacle."}, {"title": "A. DCPF Estimation of CP", "content": "We build a dataset of one billion samples, with an 80%-10%-10% training-validation-test split, ensuring an equal balancing across the different probability intervals (see Section II-B). We assume the robot dimensions to be fixed to a width of 4.07 and height of 1.74, while the $q_o$ is obtained by drawing from a Gaussian distribution with $\\Sigma_o \\in [0, \\sqrt{2}]^5$. The dataset generation phase took 80 hours on a computer equipped with an AMD Ryzen 9 5950X 16-Core and an RTX 3080Ti (12 GB). We use the Adam optimizer for training with 2.4.10-4 learning rate. We evaluate the network varying the number of hidden layers in 3 to 7 and the number of hidden layers neurons in 128, 512, and 1024, while the network for the regularized was kept fixed to 3 layers of 512 neurons. For every setting, we use an ensemble of 10 networks and we evaluate the average prediction. We consider two metrics, the Mean Absolute Error (MAE) and the Percentage of Accurate Predictions (PAP). The MAE measures the absolute average error of the network prediction over the full dataset. Since our dataset samples are approximations we also use PAP to measure the percentage of accurate predictions, where we consider a prediction as accurate if it is within the confidence interval of the collision probability estimate.\nIn Table I, we report the ablation study on the network size using the PAP as metric. We obtain accurate predictions for each network size and the network precision improves increasing the number of neurons. However, increasing the number of layers does not have a consistent positive impact. Due to the results of our ablation, we select a network with 6 hidden layers of 1024 neurons for the subsequent experiments.\nIn Figure 3, we evaluate the performance of our selected network by reporting the boxplots of absolute errors for different CP buckets. The results clearly show that our prediction error for the best network is very accurate, falling most of the time in the desired bucket accuracy. By looking at the worst prediction of each ensemble, we notice a significant drop in the accuracy. However, the presence of these outliers in the prediction is strongly mitigated by using the ensemble mean, which brings the distribution close to the best network, indicating that these errors are not very frequent in the dataset. This proves that, by using an ensemble technique,"}, {"title": "B. Planning with DCPF", "content": "a) Static Obstacles: For this work we consider two settings. A a narrow passage scenario with two obstacles and a random obstacle planning setting.\nIn the first planning scenario, we consider a square workspace containing two static obstacles forming a narrow passage, as shown Fig. 4, with uncertainty described by\n$\\Sigma_1 = diag(0.05, 0.2, 0.03, 0.0001, 0.0001)$\n$\\Sigma_2 = diag(0.15, 0.4, 0.13, 0.01, 0.015)$,\nwhere $\\Sigma_i$ represents the uncertainty distribution of the i-th obstacle $q_o = [x^i, y^i, \\phi^i, l_1^i, l_2^i]^T$. The goal of the robot is to find a path leading to the goal region to the left of the workspace while accounting for a given CP constraint $P_{max} \\in \\{10^{-1},10^{-2},10^{-3}\\}$.\nThe planner assumes a bicycle model for the robot and plans using Hybrid-A* using a set of 10 motion primitives. To check the satisfaction of the CP constraint by evaluating if the sate is below the lower bound of the 95% confidence interval around the mean of 10 DCPF Networks. We consider two baselines to compare against our method. The first is a common Simple Monte Carlo baseline [7], also used in [8], [1]. Specifically, we compute the CP estimate via Simple Monte Carlo and use a one sided z-test to check if it can be concluded, with 95% confidence, that the CP constraint is not violated. The second baseline is the SPRT approach introduced in [1]. In both cases, we run experiments for $P_{max} \\in \\{10^{-1},10^{-2},10^{-3}\\}$, and examine the impact"}, {"title": "IV. CONCLUSION", "content": "In this paper, we introduced DCPF, a neural approach to compute efficiently CP. Differently from sampling-based approaches, DCPF shifts the heavy part of the computation offline, allowing for a fast, time-consistent, yet very accurate, evaluation of CP during planning. Our method can easily incorporate obstacle uncertainty in many different settings, including dynamic environments and shape uncertainty. Furthermore, DCPF provides a differentiable representation of the collision probability, allowing for an easy combination with trajectory combination methods. Additionally, to increase the applicability in safety-critical settings, we present an ensemble approach to deal with model prediction uncertainty and provide conservative CP estimations.\nOur experiments show that DCPF can speed up the CP evaluation, particularly in the setting of parallelizable planning algorithms. As the inference time of the neural network is consistent, we are free from the need to specify a planning time budget, which may cause the standard method to wrongly label safe configurations. Our planning experiments show that DCPF provides a better evaluation of the safety of the states than the sampling-based methods with a limited computation budget. Finally, we show that we can deploy our approach in the real world, by performing a real-world overtaking task using two Tiago robots, under perception and dynamic uncertainty. While we focus on the simple setting of rectangular obstacles (crucial for autonomous driving), DCPF can be easily extended to support arbitrary shapes, as it only requires generating a proper dataset. This includes non-convex shapes that are particularly computationally in-tensive for sample-based CP estimation methods.\nIn future works, we will investigate the applicability of our approach in more challenging settings and we will combine our method with state-of-the-art parallel planning algorithms: this would allow us to reduce massively the planning time, allowing methods of planning under uncertainty to scale to complex real-world scenarios."}]}