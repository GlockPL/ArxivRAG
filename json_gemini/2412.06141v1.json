{"title": "MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization", "authors": ["Kangyu Zhu", "Peng Xia", "Yun Li", "Hongtu Zhu", "Sheng Wang", "Huaxiu Yao"], "abstract": "The advancement of Large Vision-Language Models (LVLMs) has propelled their application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter factuality challenges due to modality misalignment, where the models prioritize textual knowledge over visual input, leading to hallucinations that contradict information in medical images. Previous attempts to enhance modality alignment in Med-LVLMs through preference optimization have inadequately mitigated clinical relevance in preference data, making these samples easily distinguishable and reducing alignment effectiveness. To address this challenge, we propose MMedPO, a novel multimodal medical preference optimization approach that considers the clinical relevance of preference samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference data by introducing two types of dispreference: (1) plausible hallucinations injected through target Med-LVLMs or GPT-4o to produce medically inaccurate responses, and (2) lesion region neglect achieved through local lesion-noising, disrupting visual understanding of critical areas. We then calculate clinical relevance for each sample based on scores from multiple Med-LLMs and visual tools, and integrate these scores into the preference optimization process as weights, enabling effective alignment. Our experiments demonstrate that MMedPO significantly enhances factual accuracy in Med-LVLMs, achieving substantial improvements over existing preference optimization methods by averaging 14.2% and 51.7% across the Med-VQA and report generation tasks.", "sections": [{"title": "1. Introduction", "content": "Artificial intelligence is increasingly being applied in the medical field [14, 15, 23, 36, 40, 43, 51, 57], including areas such as disease diagnosis and treatment planning. With the recent surge in popularity of Large Vision-Language Models (LVLMs) [28, 29, 65], Medical LVLMs (Med-LVLMs) have begun to develop rapidly, drawing significant attention [22, 27, 30, 41, 42, 48, 52, 53, 60]. However, these models still face the challenge of factuality, which is largely due to modality misalignment issues [7, 63]. Models with poor modality alignment tends to prioritize the textual knowledge learned during training over the actual visual input. As a result, Med-LVLMs often produce hallucinations, generating text that appears coherent but contradicts the information in the corresponding medical image [5, 16, 34, 49]. To tackle this issue, several studies have employed preference optimization on Med-LVLMs, aiming to improve alignment between medical image and text modalities with factuality improvement [2, 12, 35]. However, these methods simply leverage the preference data generation process used for aligning general LVLMs on natural images, overlooking the clinical relevance of the generated preference samples. Consequently, these preference samples become relatively easily distinguishable, reducing their effectiveness in aligning Med-LVLMs. Clinical relevance can be considered from two perspectives. First, in these preference samples, it is essential that both preferred and dispreferred responses are clinically meaningful; if dispreferred responses lack clinical relevance, Med-LVLMs can easily distinguish them, diminishing the sample's effectiveness. For instance, a dispreferred response such as \"a gallstone in the right lobe of the lung...\" reflects a clear factual error with limited clinical relevance. Second, when improving alignment between the generated medical response and the input medical image, focused attention on local lesion areas is essential for accurate medical image understanding. Correcting dispreferred responses that arise from overlooking these lesion regions is crucial for achieving more precise medical alignment.\nTo address this challenge, we introduce MMedPO, a novel Multimodal Medical Preference Optimization approach designed to quantify preference sample importance based on clinical relevance, enabling more effective preference optimization in Med-LVLMs. In MMedPO, we first curate multimodal medical preference data using two strategies: (1) introducing dispreference by leveraging target Med-LVLMs or GPT-4o to inject plausible hallucinations into responses, ensuring dispreferred outputs contain evident medical inaccuracies, such as incorrect imaging interpretations, misleading descriptions, or inaccurate diagnoses; and (2) provoking dispreference by neglecting lesion regions through a visual tool-guided local lesion-noising process, which disrupts the model's understanding of these areas, leading to responses that overlook critical regions, thus being marked as dispreferred. We then quantify each preference sample's clinical significance by formulating sample importance scores, which integrate (1) clinical significance scores of dispreferred responses, evaluated by a multiple Med-LLMs collaboration process, and (2) confidence scores from visual tools to assess lesion region detection accuracy. These sample importance scores are then feed into a preference optimization process, enabling more effective alignment based on the clinical relevance of each preference sample.\nThe primary contribution of this paper is the introduction of MMedPO, aiming to quantify the clinical significance of curated preference samples to achieve more effective alignment and enhance factual accuracy in Med-LVLMs. Empirical results on two Medical Visual Question Answering (Med-VQA) and two report generation datasets demonstrate that MMedPO substantially improves the factual accuracy of Med-LVLMs, achieving significant gains over the best previous preference optimization methods, with improvements of 14.2% and 51.7% on the Med-VQA and report generation tasks, respectively."}, {"title": "2. Preliminaries", "content": ""}, {"title": "2.1. Medical Large Vision Language Models", "content": "Medical Large Vision-Language Models (Med-LVLMs) are advanced architectures primarily comprising a Large Language Model (LLM) integrated with a specialized visual module. The visual module analyzes medical images to extract relevant information, transforming it into a representation compatible with the LLM's processing capabilities. Given a medical image xv and a clinical query xt, the combined input is represented as x = (xv, xt). The model then autoregressively predicts the probability distribution of the next token in the sequence, leveraging the multimodal input. The text output generated by the model is denoted as y."}, {"title": "2.2. Preference Optimization", "content": "Preference optimization has proven highly effective in finetuning LLMs [1, 33], leading to a significant alignment between model behavior and target objectives. In preference optimization, given an input x, the language model policy \u03c0\u03b8 generates a conditional distribution \u03c0\u03b8(y | x), where y represents the output text response. One of the notable methods, Direct Preference Optimization (DPO) [33], leverages preference data to facilitate alignment within LLMs. The preference dataset is defined as D = {(x(i), yu, y(i))}=1, where yu denotes the preferred response and yl the dispreferred response for a given input x. The probability of preferring Yw over y\u0131 is modeled as p(yw > y\u0131) = \u03c3(r(x, yw) \u2013 r(x,y\u0131)), with \u03c3(\u00b7) representing the sigmoid function. In DPO, the optimization process is expressed as a following loss computed over the preference data:\nLDPO(\u03c0\u03b8; Tref) = \u2212E(x,yw,Y1)~D[logo (\u03c0\u03c1(Ywx)\u03c0\u03b8 (\u03b3\u03b9\u03b1)) \u2212 logo (Tref(Ywx)Tref (y1x))].  (1)\nwhere \u03c0\u03b8 represents the reference policy, which is the LLM fine-tuned through supervised fine-tuning."}, {"title": "3. Multimodal Medical Preference Optimization (MMedPO)", "content": "In this section, we propose MMedPO, a clinical-aware multimodal preference optimization method to address modality misalignment challenges in Med-LVLMs, which consists of three steps and the entire framework is illustrated in Figure 2. Firstly, we use the target Med-LVLM or GPT along with medical visual tools to jointly construct medical multimodal preference data. Second, we evaluate the clinical relevance of each preference sample using a collaborative process with multiple Med-LLMs and confidence scores from medical visual tools for lesion region detection. Lastly, the normalized clinical relevance scores are integrated into the preference optimization process to achieve clinical-aware preference optimization. We detail these steps as follows:"}, {"title": "3.1. Preference Data Curation", "content": "In the first step, our goal is to construct a high-quality, medical-specific multimodal preference dataset using two strategies: (1) introducing dispreference by using target MedLVLMS or GPT-4o [31] to inject hallucinations into medical responses, ensuring that dispreferred responses include significant medical inaccuracies; (2) provoking dispreference by neglecting lesion regions through a medical visual toolaugmented local lesion-noising process, resulting in dispreferred responses that overlook critical regions. We detail both strategies as follows:\nGenerating Hallucinated Medical Responses. In the first strategy, we aim to generate a hallucinated medical response, designated as the dispreferred response, while the ground truth serves as the preferred response. To achieve this, we first perform multiple rounds of sampling on the target MedLVLMS M(\u00b7) to collect a set of potential hallucinated responses. We then use GPT-4o to evaluate all candidate responses and select the response with the highest level of hallucination, displaying clear conflicts with the ground truth. If none of the candidates exhibit significant hallucinations, we use GPT-4o to generate a new hallucinated response based on ground truth to ensure that dispreference contain factual inaccuracies, such as incorrect imaging interpretations, misleading condition descriptions, or erroneous diagnoses. The preference pairs constructed using this strategy are denoted as Dt.\nAdding Noise to Localized Lesion Region. To improve the alignment between generated medical responses and input medical images, concentrated attention on localized lesion areas is vital for accurate interpretation. Thus, we construct dispreferred response that stem from neglecting these lesion regions. Specifically, we leverage a medical visual tool (e.g., MedKLIP [47]) T(.), to predict disease-related local regions h = T(xv) for each medical image xv. We then introduce noise into these detected localized lesion regions within the original image. The noise step is defined as k, and the noised image at step k can be expressed as follows:\nxk = \u221a\u03bek \u221a(xh) + \u221a1 \u2212 \u03bek (\u03bek (xh) + (xv \u2212 h)),  (2)\nwhere \u03be\u03b5 = \u03a0\u03ba\u03b9 \u03be\u03af and \u03be\u03ba \u2208 (0, 1) are hyperparameters. In this approach, the original image xv paired with the ground truth y is considered preferred, while the image with localized noise xk paired with the same ground truth y is regarded as dispreferred. The preference data constructed using this strategy is denoted as Dv.\nFinally, we merge the two preference sets generated by the above two strategies and denote the preference dataset as Do = Dt UD = {x(i), x*(i), yw,y(i)}=1, where x(i) and x*(i) denote the normal and noisy input, y\u33a2), y(i) represent preferred and dispreferred responses, respectively."}, {"title": "3.2. Quantified Clinical Relevance Score", "content": "After obtaining multimodal medical preference data, we will quantify the clinical relevance of each preference sample to drive effective optimization. Our hypothesis is that responses with higher clinical relevance are more valuable for preference optimization, while low-quality responses, in turn, reduce the effectiveness of optimization. We will explain in detail how clinical relevance is calculated below."}, {"title": "3.2.1. Clinical Relevance Scores for Dispreferred Medical Responses from Med-LLMs", "content": "For samples generated by the target Med-LVLM and GPT-4o (i.e., samples in Dt), we evaluate the clinical relevance of the dispreferred response based solely on the model's internal medical knowledge, without the need for visual input [39? ]. Including medical images for this evaluation is unnecessary and may even hinder the process. Therefore, we rely on Med-LLMs with high levels of medical expertise to assess the clinical relevance of these text responses. Moreover, relying on a single Med-LLM for evaluating clinical relevance may introduce bias and result in unreliable assessments [4].\nTo address this, we implement a multi-agent collaboration system comprising multiple Med-LLMs, each with varying levels of medical expertise. These Med-LLMs collaborate through a structured debating process to reach a consensus on clinical relevance scores, thereby improving the reliability of clinical relevance evaluations.\nSpecifically, for each Med-LLM G\u2081, where 0 < i < gand g represents the total number of Med-LLMs, the objective of the multi-agent collaborative system is to establish consensus on the clinical relevance score across all agents (i.e., MedLLMs). This process comprises r rounds. In each round, each Med-LLM evaluates the clinical relevance score passed from the previous Med-LLM. The process begins with the first Med-LLM, G1, which evaluates a dispreferred response y\u0131, generating a clinical relevance score s1 = G1(y\u0131) and recording it in the score history S. Subsequently, each following Med-LLM Gi retrieves the prior scores si-1 and determines whether to agree. If a Med-LLM concurs, it adopts si-1 as its clinical relevance score si; otherwise, it generates a new score as si. This process continues until all Med-LLMs reach consensus and produce a final score. To prevent excessive evaluations across all Med-LLMs, a threshold limits the number of evaluation rounds. If this threshold is reached before consensus, the final score is defined as the average of the scores in the history: \n\u00a7 = \u03a3i=1si/|S|, ensuring efficient consensus that reflects clinical relevance, where |S| represents the total number of scores."}, {"title": "3.2.2. Confidence Scores for Localized Lesion Regions from Visual Tools", "content": "For preference data in Du, distinct noisy regions correspond to disease-related lesion areas. Introducing noise into images to generate dispreferred responses for preference comparison can improve the visual understanding of Med-LVLMs [44, 62, 63]. Emphasizing lesions associated with the disease through noise can further enhance the model's focus on these critical areas. However, if noisy regions are inaccurately defined, the reliability of these samples decreases, potentially impacting the model performance. Therefore, quantifying the accuracy of critical lesion detection to represent sample importance during optimization is importance. To achieve this, we use the confidence scores s from visual tools that generate heatmaps of local regions as an indicator of clinical relevance. We assign different clinical relevance scores to preference pairs based on the confidence scores provided by visual tools for lesion detection."}, {"title": "3.3. Clinical-Aware Preference Fine-tuning", "content": "Following the previous steps, we construct multimodal medical preference data and assign a quantified clinical relevance score to each preference sample. During preference optimization, we treat this score as the sample weight representing the contribution of each preference data pair to the overall objective. To prevent underfitting caused by an excessively small overall loss, we apply a normalization strategy, mapping the scores to a fixed range while maintaining their mean and variance. Specifically, for each clinical relevance score s, the normalized score s' is calculated as: s' = (s\u2212\u00b5)/\u03c3, then we clip s' to values of [\u03b1, \u03b2]. Here a and \u1e9e denote the predefined upper and lower bounds for the normalized score, and \u00b5 and o represent the mean and variance of the original scores, respectively. After obtaining the normalized clinical relevance score, we fine-tune the Med-LVLM using a weighted DPO. Following Eqn. 3, the adjusted loss with clinical relevance as sample weights is calculated as follows:\nLmmedpo = \u2212E(x,x*,yw,y1,s')~Do[s' logo (\u03c0\u03b8(Ywx*)\u03c0\u03b8(\u03b3\u03b9\u03b1*)) \u2212 logo (\u03c0\u03b8(Ywx*)\u03c0\u03b8(\u03b3\u03b9\u03b1*))]. (3)"}, {"title": "4. Experiment", "content": "In this section, we evaluate the effectiveness of MMedPO to answer the following questions: (1) Can MMedPO enhance the factual accuracy of Med-LVLMs compared to other alignment baselines? (2) How does each individual component of the framework contribute to overall performance? (3) Can MMedPO be compatible with different Med-LVLM architectures? (4) Does MMedPO improve Med-LVLMs' responses in terms of clinical relevance?"}, {"title": "4.1. Experimental Setups", "content": "Evaluation Datasets. To verify the effectiveness of MMedPO in improving factuality on medical tasks, we utilized four medical datasets: two medical VQA datasets, i.e., VQA-RAD [19] and SLAKE [26], and two report generation datasets, i.e., MIMIC-CXR [17] and IU-Xray [9].\nImplementation Details. We utilize LLaVA-Med-1.5 7B [22] as the base model. During the preference optimization stage, we apply LoRA fine-tuning [13], with a batch size of 4, a learning rate of 1e-7, and train for 3 epochs. For curating preference data, we use GPT-4o to evaluate and generate dispreferred response. In the multi-agent collaboration system, multiple Med-LLMs, including LLaMA3-Med427B [6], LLaMA3-Med42-70B [6], BioMistral-7B [18], are used to evaluate the relevance scores for the preference data. For additional implementation details, see Appendix B.\nBaselines. We compare MMedPO with Direct Preference Optimization (DPO) [33] and its variants, including the selfrewarding method [58] and STLLaVA-Med [35]. In the selfrewarding method, the model generates its own responses to form preference pairs, while STLLaVA-Med further refines the preference selection process using GPT-4o and apply it in Med-LVLMs. Additionally, we evaluate MMedPO and all baselines on models that have been supervised finetuned with the corresponding datasets and compare their performance.\nEvaluation Metrics. For Med-VQA task, we use accuracy and recall for both closed-ended and open-ended questions. For report generation task, we use BLEU Score [32], ROUGE-L [25] and METEOR [3] as the metrics."}, {"title": "4.2. Main Results", "content": "In this section, we present a comprehensive comparison of MMedPO with baseline methods.\nComparison with Baseline Methods. As shown in Table 1, we evaluate our model's performance against the original LLaVA-Med-1.5 and several preference optimization baselines. MMedPO demonstrates superior performance across both Medical VQA and report generation tasks. Specifically, for Med-VQA task, MMedPO significantly outperforms the best baseline (i.e., original DPO) by an average of 15.8% and 10.3% across the open-ended and closed-ended questions, respectively. We also observe that the overall performance improvement on open-ended questions is greater than that on closed-ended questions, indicating that MMedPO is particularly effective in guiding accurate open-ended generation. Additionally, MMedPO exhibits superior performance on the report generation task, surpassing the best baseline by 61.9% and 26.0% on IU-Xray and MIMIC-CXR, respectively. This demonstrates that, by constructing a multimodal preference dataset and assigning quantified clinical relevance scores to measure sample importance, MMedPO ensures that clinical relevance is fully considered during the preference optimization process, resulting in more accurate and clinically meaningful responses.\nComparison with Baseline Methods Enhanced by SFT. To demonstrate the compatibility of our approach with other training methods, we conduct experiments by applying MMedPO and other baseline methods to supervised finetuning (SFT). As shown in Table 1, MMedPO consistently outperforms the SFT baseline across all four datasets on both the Med-VQA and report generation tasks, with an average improvement of 14.2%. When compared to other baselines applied to SFT, MMedPO achieves significantly better performance, with an average improvement of 10.5% across all datasets. These results further corroborate the effectiveness and compatibility of our approach, demonstrating its ability to integrate seamlessly with other training techniques to enhance model alignment."}, {"title": "4.3. Quantitative Analysis", "content": "In this section, we first conduct ablation study to analyze the effectiveness of each strategy and component in MMedPO for enhancing factual accuracy. Then we evaluate the model's compatibility based on different backbones and RAG technique. We further explore how our approach improves Med-LVLMs' responses in terms of clinical significance and visual understanding."}, {"title": "4.3.1. Ablation Study", "content": "Ablation Study on Different Preference Curation Strategies. To assess the impact of different preference curation strategies in MMedPO, namely generating hallucinated medical responses and adding noise to localized lesion regions, we evaluated their performance on these two components. The results, presented in Figure 3, reveal that adding noise to localized lesion regions has a more pronounced effect on open-ended generation tasks (e.g., report generation) compared to generating hallucinated medical responses. For medical VQA tasks, the performance improvements from both preference curation processes are comparable. By integrating both strategies, MMedPO achieves the best overall performance across four datasets, effectively combining their strengths to maximize performance gains.\nAblation Study on Clinical Relevance Score. To investigate the role of clinical relevance score as weight in the preference optimization process, we compare the results of applying this weight versus not applying it under different preference curation strategies. The results indicate that incorporating clinical relevance scores as weights in preference optimization improves the effectiveness of preference optimization. Specifically, as shown in Table 2, on the MedVQA datasets, models utilizing clinical relevance scores as weights consistently outperform those without them, with an average improvement of 2.3%. Also significant performance gains are observed on the report generation task, where clinical relevance scores contributed positively across different preference curation strategies, achieving a clear average margin of 18.5%. The clinical relevance scores assigned to each preference pair provide positive benefits to preference optimization, helping the Med-LVLMs generate responses that are both more clinically meaningful and accurate."}, {"title": "4.3.2. Does Collaboration Among Multiple Med-LLMs Outperform Using a Single Med-LLM?", "content": "To explore the impact of multi-agent collaboration mechanism in generating clinical relevance scores, we conduct analytical experiments on four datasets, comparing the performance using clinical relevance scores from single MedLLM and multiple Med-LLMs. As shown in Table 3, we find that the consensus scores reached by multiple Med-LLMs positively contributes to performance improvement by an average of 3.6% over all datasets. This aligns with our expectations, as relying on a single Med-LLM can introduce biases. The observed improvement is driven by reduced bias through the collaborative efforts of multiple Med-LLMs, resulting in more accurate and clinically meaningful relevance evaluations. In addition, the performance gains on the Med-VQA task using multiple Med-LLMs are notably larger compared to the report generation task. This may be attributed to greater disagreement among Med-LLMs on rejected VQA answers, allowing them to benefit more from achieving consensus."}, {"title": "4.3.3. Impact of Localized Lesion Noise in MMedPO", "content": "To evaluate the impact of localized lesion noise during the preference optimization process, we compare the performance of preference data composed of images with localized noise versus those with global noise. Global noise refers to adding noise uniformly across the entire image. As shown in Table 4, introducing localized noise consistently outperforms global noise across the four datasets. This indicates that lesion regions detected by visual tools are more prominent than the entire image. Introducing localized noise based on these regions helps the model better understand critical lesions, leading to more factually accurate responses."}, {"title": "4.3.4. Compatibility Analysis", "content": "To evaluate the compatibility of our approach with different base models, particularly more powerful backbone architectures, we replace the backbone of LLaVA-Med-1.5 and conduct a series of experiments based on this configuration. Specifically, we apply our method to LLaVA-Med++ [54], which uses LLaMA-3 [11] as language backbone and enhances its performance using a large-scale medical multimodal dataset MedTrinity-25M. As illustrated in Table 4, similar to the results obtain with LLaVA-Med-1.5, applying MMedPO leads to performance improvements across all four datasets. These findings highlight the strong compatibility and effectiveness of our approach when integrated with other powerful Med-LVLMs. MMedPO can be transferred to a wider range of base models, demonstrating strong generalizability for applications in clinical scenarios."}, {"title": "4.4. Qualitative Analysis and Case Study", "content": "In this section, we further conduct qualitative experiments and case analyses to demonstrate the effectiveness of MMedPO."}, {"title": "4.4.1. Qualitative Analysis", "content": "How does MMedPO in Improving Visual Understanding? To better understand the model's visual comprehension capability, we visualize its attention map on image tokens. As shown in Figure 5, compared to the attention map of the original LLaVA-Med-1.5, the utilization of MMedPO significantly enhances the model's focus on visual information, particularly on critical lesion areas. This allows the model to extract sufficient information from visual inputs and improve consistency between text and images. Thus the model can reduce hallucinations and provide more accurate answers.\nAnalysis Clinical Significance of Model's Response. Through the analysis of previous results, Med-LVLMs enhanced by MMedPO demonstrate a significant improvement in the accuracy of generated responses. Additionally, from the clinical perspective, we aim to evaluate the clinical significance of the responses to verify the effectiveness of MMedPO in enhancing the clinical relevance of the model's outputs. As demonstrated in Figure 6, on this case, the Med-LVLMs with MMedPO outperforms both the original Med-LVLM and the one applied with DPO method. The response with MMedPO accurately capture the condition of the cardiac silhouette and rib fracture in the image, aligning with the ground truth. Additionally, the response with MMedPOimproves clinical significance judged by MedLLMs. The original model and other baselines, in contrast, produce repetitive and clinically irrelevant contents, leading to inferior responses. The evaluation of response using clinical relevance from Med-LLMs quantitatively shows that MMedPO consistently achieves significantly higher clinical relevance scores."}, {"title": "4.4.2. Case Study", "content": "We analyze two examples from Medical VQA task to illustrate how the model fine-tuned with MMedPO reduces factuality errors. As illustrated in Figure 7, the model fine-tuned using the MMedPO method shows improved performance in factual accuracy. For example, when asked about pathology, the model provides a more detailed response, focusing on the problem of renal cyst, which is similar to the ground truth, outperforming both LLaVA-Med and LLaVA-Med with DPO fine-tuning. In another case, when the user inquires about the patient's condition, MMedPO accurately identifies hydrocephalus based on the image, while the other two models fail to do so. This demonstrates that MMedPO effectively reduces hallucinations in Med-LVLMs, minimizing factual errors in multimodal understanding tasks."}, {"title": "5. Related Work", "content": "Factuality Issues in Med-LVLMs. The development of Large Vision-Language Models (LVLMs) is progressing rapidly [21, 28, 29, 50, 55, 56, 65], which has, in turn, driven advancements in Medical Vision-Language Models (Med-LVLMs), achieving promising results in the medical field [22, 30, 37, 48, 52, 53]. However, the current MedLVLMs still exhibit significant factual errors [5, 16, 24, 34, 46, 49]. For example, they often lack sufficient judgment ability for complex content, and frequently generate responses with hallucinations that contradicts the visual information provided. This issue is particularly pronounced in medical domain, as it can potentially lead to misdiagnoses or missed diagnoses. Recently, there are several benchmarks [34, 49] that highlight the factuality issues of MedLVLMs on multiple tasks such as the visual question answering and report generation.\nPreference Optimization in Med-LVLMs. Aligning with human preferences for large models is an effective way to address hallucination issues [8, 10, 20, 38, 45, 63, 64]. Preference fine-tuning in LVLMs generally involves two approaches: one aligns models based on human feedback [1, 33], while the other uses feedback generated by \u0391\u0399 [8, 20, 44, 45, 59, 61, 63, 64]. Recently, the preference fine-tuning technique has also been adapted for medical imaging [2, 12, 35] by generating dispreferred responses using GPT-4 or the target Med-LVLM. Although these methods have shown promise, they neglect the clinical relevance of the generated samples. Moreover, in Med-LVLMs, visual information from local regions plays a pivotal role in generating accurate responses. However, these methods rarely guide the model's focus toward specific lesion regions during preference fine-tuning. To address these challenges, our work incorporates quantified clinical relevance scores as weights to enhance preference fine-tuning. Additionally, we introduce localized noise into medical images to construct dispreference, which directs the model's attention to critical local regions, thereby improving its visual understanding of important lesions."}, {"title": "6. Conclusion", "content": "In this work, we propose a clinical-aware multimodal preference optimization approach, which considers the clinical relevance of each preference sample in preference optimization. This method enhances alignment of Med-LVLMs while effectively reducing factual errors. Specifically, to construct multimodal preference data, we introduce plausible hallucinations through target Med-LVLMs or GPT-4o and apply local noise to critical lesion regions. Furthermore, we assign clinical relevance for data samples through Med-LLMs and visual tools, and then incorporate these scores as weights in the preference fine-tuning process. We evaluate the effectiveness of MMedPO on the Med-VQA and report generation tasks, demonstrating superior performance."}, {"title": "A. Data", "content": ""}, {"title": "A.1. Data Statistics", "content": "The data statistics are shown in Table 5 and Table 6. In the training datasets, the reported quantities for the two datasets in report generation represent image-report pairs, while the quantities for the two datasets in the medical VQA task represent question-answer pairs."}, {"title": "A.2. Involved Datasets", "content": "We leverage four open-source medical vision-language datasets: MIMIC-CXR [17], IU-Xray [9], SLAKE [26], and VQA-RAD [19]. These datasets are designed for different tasks: the first two focus on medical report generation, while the latter two are tailored for medical visual question answering.\n\u2022 IU-Xray is a dataset that includes chest X-ray images and corresponding diagnostic reports.\n\u2022 MIMIC-CXR is a widely accessible dataset containing chest X-ray images in DICOM format along with corresponding radiology reports.\n\u2022 SLAKE is an English-Chinese bilingual dataset comprising 642 images and 14,028 question-answer pairs designed for training and evaluating Med-VQA systems.\n\u2022 VQA-RAD is the first dataset manually curated by clinicians, featuring naturally occurring questions about radiology images along with corresponding reference answers."}, {"title": "B. Hyperparameter Settings", "content": "For the usage of visual tools, we employ \u201cdisease\" as the text description to guide MedKLIP [47] in generating heatmaps. For multi-agent collaboration, the process is conducted over 5 rounds. During score normalization, the parameters are set as: a = 0.75, \u03b2 = 1.25, \u03bc = 1, and 02 0.1. All experiments are implemented using PyTorch 2.1.2 on four NVIDIA RTX A6000 GPUs, with training requiring approximately 2 to 3 hours."}, {"title": "C. Involved Baselines", "content": "\u2022 DPO [33] is a fine-tuning approach designed to align large language models (LLMs) with human preferences in a stable, efficient, and computationally lightweight manner. Unlike traditional Reinforcement Learning from Human Feedback (RLHF), which involves training a reward model and using reinforcement learning to maximize the reward, DPO simplifies the process by reframing the problem. It parameterizes the reward model in a way that allows the optimal policy to be derived directly through a classification loss, eliminating the need for complex sampling or extensive hyperparameter tuning during fine-tuning.\n\u2022 Self-Rewarding [58] is a novel approach where the language model itself acts as a judge, generating rewards via LLM-as-a-Judge prompting during training. Unlike traditional methods that rely on reward models trained from human preferences, which are limited by human performance and static design, this method enables the model to iteratively improve both its instruction-following abilities and its reward-generating quality during iterative DPO training.\n\u2022 STLLaVA-Med [35] refines the preference selection process using GPT-4o and applies it in medical visionlanguage tasks. STLLaVA-Med extends the DPO approach by incorporating a self-training mechanism specifically tailored for the medical domain."}, {"title": "D. Additional Results", "content": "In this section, we present a detailed benchmark analysis for the report generation task. Table 8 compares our method with other baseline approaches. Additionally, Tables 9 and 7 provide comprehensive component ablation results for both the Medical VQA and report generation tasks."}, {"title": "E. Prompts", "content": "We utilize GPT-4o to generate hallucinated responses for constructing preference data, as illustrated by the prompts in Figure 8. Subsequently, a multi-agent system comprising Med-LLMs is employed to evaluate the clinical relevance scores of these rejected responses, with the evaluation prompts shown in Figure 9."}, {"title": "F. More Cases", "content": "We present additional examples in Figure 10, illustrating how our method effectively reduces hallucinated errors."}]}