{"title": "ClustEm4Ano: Clustering Text Embeddings of Nominal Textual Attributes for Microdata Anonymization", "authors": ["Robert Aufschl\u00e4ger", "Sebastian Wilhelm", "Michael Heig", "Martin Schramm"], "abstract": "This work introduces ClustEm4Ano, an anonymization pipeline that can be used for generalization and suppression-based anonymization of nominal textual tabular data. It automatically generates value generalization hierarchies (VGHs) that, in turn, can be used to generalize attributes in quasi-identifiers. The pipeline leverages embeddings to generate semantically close value generalizations through iterative clustering. We applied KMeans and Hierarchical Agglomerative Clustering on 13 different predefined text embeddings (both open and closed-source (via APIs)). Our approach is experimentally tested on a well-known benchmark dataset for anonymization: The UCI Machine Learning Repository's Adult dataset. ClustEm4Ano supports anonymization procedures by offering more possibilities compared to using arbitrarily chosen VGHs. Experiments demonstrate that these VGHs can outperform manually constructed ones in terms of downstream efficacy (especially for small k-anonymity (2 \u2264 k \u2264 30)) and therefore can foster the quality of anonymized datasets. Our implementation is made public.", "sections": [{"title": "1 Introduction", "content": "Background. Anonymizing tabular datasets with textual attributes typically requires generalizing textual attributes that qualify as quasi-identifier (QI), i.e., as set of attributes that in combination allow to reidentify individuals [40]. For this purpose, VGHs are commonly created to group similar values into categories to prevent privacy attacks, such as record linkage in microdata [40], and to maintain usability. However, creating suitable VGHs is usually a manual process that demands domain knowledge, presenting a challenge for human data processors.\nApproach. We introduce ClustEm4Ano, a novel approach that employs embeddings to construct VGHs for anonymization. In particular, when considering the uncertainty penalty-based methods to generalize with less information loss, hierarchies of nominal attributes have to be known in advance. This is where"}, {"title": "2 Related Works", "content": "Text Anonymization. Due to the intricate nature of natural language, anonymizing textual data presents a complex challenge [21,30]. While numerous methods for anonymizing structured data with well-established privacy models are available, they are not directly transferable to text data, so particular approaches are necessary [26]. One of the earliest contributions to text data anonymization dates back to [43], which details the identification and replacement of personally identifying information in medical records using various pattern-matching algorithms. Over the years, various strategies such as removal, tagging, generalization, and substitution have been developed. The choice of strategy depends on the context of the application and varies significantly between anonymizing free-form text, like letters, and structured categorical data, like microdata.\nVGHs for Anonymization of Microdata. The generalization process of textual attributes for microdata anonymization relies primarily on a specific VGH"}, {"title": "3 Basic Definitions", "content": "Anonymization. Let D = {R1, R2,..., Rn} be a multiset of row records with n\u2208 N+ not necessarily distinct records composed of attribute values. We refer to an attribute as a peace of information about an individual. A QI is a set of attributes that allows re-identification of individuals in data records. Sensitive Attributes (SAs) are attributes in T, where it should be impossible to assign corresponding attribute values after potential attribute inference (attacks). In domain generalization [40], the domains of QI's attributes are mapped to a more general domain. Domain Generalization can be achieved via different VGHs, where each value in a non-generalized domain is mapped to a unique value in a more general domain. If all generalized values are on the same level in the value generalization hierarchy, it is called full-domain generalization. In general, VGHs are a subclass of ontologies where only the is-a (sub-type) relationships are considered [4]. In particular, in our experiments, we use the generalization algorithm FLASH [22], which, among others, is implemented by the ARX Software [37]. This algorithm offers fast execution times and seeks minimal information loss while traversing the generalization lattice in a bottom-up breadth-first search. Also, the anonymization algorithm allows to predefine certain required thresholds for privacy models such as k-anonymity [40,41], l-diversity [28], and t-closeness [24]. Thereby, records with identical QI attributes are summarized into a single equivalence class group. We denote the set of all equivalence classes as groups. Then, the privacy models are defined as follows: k-anonymity (k): $k := \\min_{group \\in groups}|group|$, l-diversity (l): $l := \\min_{group \\in groups} |{\\text{values for SA in group}}|$, t-closeness (t): checks granularity of SA values in single groups in comparison to the distribution in the dataset.\nEach of the privacy models has its advantages and limitations [3]: k-anonymity effectively prevents singling out individuals but depends on k. l-diversity improves on k-anonymity by adding protection against inference. t-closeness provides additional defense against inference by ensuring that the distribution of sensitive attributes in each group closely matches the overall distribution.\nWord embeddings. Dealing with nominal textual attributes we transform text into numerical representations. A distributed word representation that is dense, low dimensional, and real-valued, is called word embedding [44].\nClustering. Clustering is an unsupervised ML method that takes as input n-dimensional real-valued feature vectors, where $n \\in N$, $K\\in N$ the number of desired cluster centers, and outputs n-dimensional real-valued cluster centers C1, C2,...,CK and assigns each feature vector exactly one cluster center. We utilize two bottom-up clustering techniques. First, a clustering sequence that incorporates the non-hierarchical clustering method KMeans [27] and, second, Ward's Hierarchical Agglomerative Clustering [45], where two clusters are successively merged and the variance of the clusters being merged is minimized."}, {"title": "4 Proposed Pipeline", "content": "Fig. 3 shows the dataflow diagram of ClustEm4Ano. First, a data processor (denoted by the human symbol) needs to define a set of QIs with at least one entry and optionally a sensitive attribute. Then, the attribute values from the QI(s) column(s) are extracted. Given the set of extracted values, a predefined clustering method (Hierarchical Agglomerative Clustering / iterative applying KMeans), and an embedding model (for example, one of the 13 tested experimentally in this pipeline), can be used to generate VGH(s). Using the generated VGHs, predefined privacy models like k-anonymity, and a suppression limit (which defines the maximum percentage of records where all QI attributes are replaced with '*' to handle rare values or outliers), anonymized tabular data can be produced.\nWe propose the anonymization pipeline in Algorithm 2. One novelty is introduced in Algorithm 1, which utilizes clustering of text embeddings to obtain"}, {"title": "5 Experimental evaluation", "content": "5.1 Methodology\nIn the context of anonymization, evaluation can be applied in several steps. Before applying anonymization, a domain expert must choose IDs, QIs and SA(s). To the best of our knowledge, there is no automatic evaluation assigning these, and they must be manually defined. After applying the anonymization algorithm, we evaluate the data by measuring its efficacy in a downstream classification task. Additionally, we check the number of suppressed records and how close the data matches the desired k-anonymity. Also, from a privacy perspective, privacy risks are assessed at this step. We only perform a quantitative research.\n5.2 Implementation details\nEmbeddings. It can be assumed that there is no \"one [embedding] fits all\" because no particular text embedding method dominates across all downstream tasks, as shown in the MTEB: Massive Text Embedding Benchmark [34]. Besides using open-source embeddings, we also test the possibility of retrieving embeddings by accessing proprietary APIs. We experiment with OpenAI's text embedding models text-embedding-3-small ($0.02 / 1M tokens) and text-embedding-3-large ($0.13 / 1M tokens) - released on January 25, 2024 and Mistral AI's text embedding model mistral-embed ($0.1 / 1M tokens). Overall, due to the small number of tokens needed, the price of using OpenAI and Mistral AI embeddings in our experiments was negligible (< 0.1$ in total). We use pre-trained word embedding based on word2vec [32] that was trained on the text corpus obtained from Google News. Thereby, we use the implementation from the Python library Gensim [38]. Further, we test our approach on other pre-trained word embeddings based on BERT [14,20,39], GloVe [36], MPNet [42], OpenAI's closed-source models text-embedding-3-small and text-embedding-3-large, and fastText [19]. We accessed most of the embeddings through Hugging Face's SentenceTransformers Python famework\u00b2 . The complete list of embeddings is", "subsections": [{"title": "5.3 Setup", "content": "Dataset. In this study, we utilize the Adult dataset [7] and its official train-test split. In our experiments, we use nominal attributes with expected high feature importance, define QI:={workclass, education, occupation, native-country}, and the attribute salary-class is the sensitive attribute SA.\nConfiguration. We use several values k = 2, 5, 10, 15, 20, 25, 30, 50, 100, 150, 200 for certain k-anonymity as input for the anonymization algorithm in our evaluation. We use a suppression limit of 50% which increases speed in anonymization and masks outlier values. Further, we enforce l-diversity > 2. Because there are only two possible values for SA, we obtain 1 = 2 in all anonymizations. We do not enforce t-closeness because, given only two possible values, the distributions of groups tend to be more concentrated. In such cases, if a group ends up with an overrepresentation of one value, it can significantly skew the distribution away from the dataset's overall distribution. On the contrary, if a sensitive attribute"}, {"title": "5.4 Experimental results", "content": "Fig. 4 compares ML efficacy in terms of ACC using different clustering methods and different ML models in our approach. To speed up training and to increase the importance of generalized values in the ML efficacy evaluation, we only use the QI columns and the SA in training and testing. For k \u2264 30 the KMeans based approach (right) shows higher mean ACC over all embeddings. Generally, KMeans plots show higher variance in the ACC results. The high variance at the AdaBoost model (yellow) for small k (< 25) is caused by some outliers in the ACC results. When comparing the different ML methods, AdaBoost generally performs best (yellow). Comparing the embedding based results with the baseline generalizations, for k < 100, the embedding labeled plots generally have higher ACC. When comparing to un-anonymized ACC obtained by the different ML methods, only few embedding-labeled ACC scores obtained by AdaBoost have higher scores for results at k \u2264 50, meaning the ACC for anonymized data is generally lower than the non-anonymized baseline but remains competitive and can even outperform. Anonymized data show a noticeable decline as k increases.\nFig. 5 shows privacy, utility, and ML efficacy when using iterative KMeans clustering to obtain the VGHs. Lower k values (2, 5, 10) tend to show better performance, with some variations depending on the specific embedding. In comparison to [15], ACC behaves similar with growing k. We only plot k \u2264 50 due to its higher practical relevance compared to greater k values. Note, that obtained k-anonymity sometimes differs to input k in the anonymization algorithm. In Subfig. 5(c), the plots show a declining trend in t-closeness as k increases, which is expected since higher k typically means more generalization and potential information loss. Comparing embedding labels with the baseline label, no clear tendency can be seen. We assume that generalizing semantic similar values has"}]}, {"title": "6 Conclusions", "content": "In summary, this paper introduces an anonymization pipeline, ClustEm4Ano (dataflow in Fig. 3), that utilizes embeddings of nominal textual attribute values. The paper explores the use of generating VGHs from open and closed-source embeddings in the context of microdata anonymization. The VGHs are obtained through hierarchical clustering of the embeddings by iteratively applying KMeans or Agglomerative Hierarchical Clustering. In Section 5, it tests the effectiveness of clustering text embeddings to obtain VGHs for generalization and suppression-based anonymization. We show that various embeddings can be used to find VGHs that seem to be semantically correct (cf. Fig. 1). The experimental results obtained show that using automatically generated VGHs with many levels can yield anonymizations that outperform the use of manually constructed VGHs in anonymization and can even outperform un-anonymized data, especially for small k (2 \u2264 k \u2264 30).\nDespite the progress made, several limitations and areas for future work remain. Current clustering methods might not be effective at finding clusters in embeddings. While the number of clusters is predefined, the optimal number might differ. Also, our method primarily focuses on the specific privacy models k-anonymity and l-diversity and the anonymization algorithm FLASH [22], leaving room for exploration with other privacy models and other anonymization algorithms. Furthermore, in future research, domain-specific embeddings present an interesting area for exploration, as the choice of embedding models could be tailored to individual domains. Fine-tuning transformer-based word embeddings based on specific domains holds promise. However, in this regard, it is important to note that sharing word embeddings trained on sensitive data can compromise privacy, c.f. [1]."}]}