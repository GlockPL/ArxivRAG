{"title": "Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sentence\nEmbeddings for Automatic Dialog Flow Extraction", "authors": ["Sergio Burdisso", "Srikanth Madikeri", "Petr Motlicek"], "abstract": "Efficiently deriving structured workflows from\nunannotated dialogs remains an underexplored\nand formidable challenge in computational lin-\nguistics. Automating this process could signif-\nicantly accelerate the manual design of work-\nflows in new domains and enable the grounding\nof large language models in domain-specific\nflowcharts, enhancing transparency and con-\ntrollability. In this paper, we introduce Di-\nalog2Flow (D2F) embeddings, which differ\nfrom conventional sentence embeddings by\nmapping utterances to a latent space where\nthey are grouped according to their commu-\nnicative and informative functions (i.e., the ac-\ntions they represent). D2F allows for modeling\ndialogs as continuous trajectories in a latent\nspace with distinct action-related regions. By\nclustering D2F embeddings, the latent space is\nquantized, and dialogs can be converted into\nsequences of region/action IDs, facilitating the\nextraction of the underlying workflow. To pre-\ntrain D2F, we build a comprehensive dataset by\nunifying twenty task-oriented dialog datasets\nwith normalized per-turn action annotations.\nWe also introduce a novel soft contrastive loss\nthat leverages the semantic information of these\nactions to guide the representation learning pro-\ncess, showing superior performance compared\nto standard supervised contrastive loss. Evalua-\ntion against various sentence embeddings, in-\ncluding dialog-specific ones, demonstrates that\nD2F yields superior qualitative and quantitative\nresults across diverse domains.", "sections": [{"title": "1 Introduction", "content": "Conversational AI has seen significant advance-\nments, especially with the rise of Large Language\nModels (LLMs) (Bubeck et al., 2023; Lu et al.,\n2022; Hendrycks et al., 2021a,b; Cobbe et al.,\n2021). Dialog modeling can be divided into open-\ndomain dialogs and task-oriented dialogs (TOD),"}, {"title": "2 Related Work", "content": "Sentence Embeddings Transformer-based en-\ncoders like Universal Sentence Encoder (Cer et al.,\n2018) and Sentence-BERT (Reimers and Gurevych,\n2019) outperformed RNN-based ones such as Skip-\nThought (Kiros et al., 2015) and InferSent (Con-\nneau et al., 2017). These models use a pooling\nstrategy (e.g., mean pooling, [CLS] token) to ob-\ntain a single sentence embedding optimized for\nsemantic similarity. However, specific domains re-\nquire different similarity notions. In the context of\ndialogs, models like TOD-BERT (Wu et al., 2020),\nDialogueCSE (Liu et al., 2021) and Dialog Sen-\ntence Embedding (DSE) (Zhou et al., 2022) have\nshown that conversation-based similarity outper-\nforms semantic similarity across different TOD\ntasks. Likewise, we hypothesize that action-based\nsimilarity can yield meaningful workflow-related\nsentence embeddings.\nContrastive Learning Contrastive learning has\nachieved success in representation learning for both\nimages (Chen et al., 2020; He et al., 2020; Henaff,\n2020; Tian et al., 2020; Chen et al., 2020; Hjelm\net al., 2019) and text (Zhou et al., 2022; Zhang\net al., 2022, 2021; Gao et al., 2021; Wu et al.,\n2020). It learns a representation space where sim-\nilar instances cluster together and dissimilar in-\nstances are separated. More precisely, given an\nanchor with positive and negative counterparts, the\ngoal is to minimize the distance between anchor-\npositive pairs while maximizing the distance be-\ntween anchor-negative pairs. Negatives are typi-\ncally obtained through in-batch negative sampling,\nwhere positives from different anchors in the mini-\nbatch are used as negatives."}, {"title": "3 Method", "content": "3.1 Representation Learning Framework\nFollowing common practices (Zhou et al., 2022;\nChen et al., 2020; Tian et al., 2020; Khosla et al.,\n2020), the main components of our framework are:\n\u2022 Encoder, $f(\u00b7) \u2208 R^{n}$, which maps x to a\nrepresentation vector, $x = f(x)$. Following"}, {"title": "3.1.1 Supervised Contrastive Loss", "content": "For a batch of N randomly sampled anchor, posi-\ntive, and label triples, $B = {(x_i, x_i^+, y_i)}_{i=1}^N$, the\nsupervised contrastive loss (Khosla et al., 2020),\nfor each i-th triplet $(x_i, x_i^+, y_i)$ is defined as:\n$-log \\frac{e^{z_i \\cdot z_j/\\tau}}{\\sum_{k=1}^{N} e^{z_i \\cdot z_k/\\tau}}$\n(1)\nwhere $P_i = {j | y_i = y_j}$ is the set of indexes of\nall the samples with the same label as the i-th sam-\nple in the batch, and \u03c4 is the softmax temperature\nparameter that controls how soft/strongly positive\npairs are pulled together and negative pairs pushed\napart in the embedding space. The final loss is\ncomputed across all the N pairs in the mini-batch\nas $L_{sup} = \\frac{1}{N}\\sum_{i=1}^{N}L_i^{sup}$."}, {"title": "3.1.2 Supervised Soft Contrastive Loss", "content": "Let $(y_i, y_j)$ be a semantic similarity measure be-\ntween labels $y_i$ and $y_j$. We define our soft con-\ntrastive loss as follows:\n$L_i^{psoft} = -\\sum_{j=1}^{N} \\frac{e^{\\delta(y_i, y_j)/\\tau'}}{\\sum_{k=1}^N e^{\\delta(y_i, y_k)/\\tau'}} log(\\frac{e^{z_i \\cdot z_j/\\tau}}{\\sum_{k=1}^{N} e^{z_i \\cdot z_k/\\tau}})$\nwhere \u03c4' is a temperature parameter controlling\nthe \"softness\" of the negative labels (impact anal-\nysis available in Appendix E). For further details,"}, {"title": "3.2 Training Targets", "content": "We experiment with four types of training targets,\ndistinguished by whether the dialogue action label\nis used directly or decomposed into dialogue act\nand slot labels, and by the type of contrastive loss\nemployed. Specifically, we consider the following\ntwo targets using the proposed soft contrastive loss:\n\u2022 D2Fsingle: $L = L_{act+slots}^{soft}$\n\u2022 D2Fjoint: $L = L_{act}^{soft} + L_{slots}^{soft}$\nand the two corresponding targets using the default\nsupervised contrastive loss:\n\u2022 D2F-Hardsingle: $L = L_{act+slots}^{sup}$\n\u2022 D2F-Hardjoint: $L = L_{act}^{sup} + L_{slot}^{sup}$\nThe subscript in bold indicates the type of label\nused to compute the loss, either the dialog action as\na single label (act+slots), or the dialog act and slots\nseparately. In the case of the joint loss, separate\ncontrastive heads g(\u00b7) are employed."}, {"title": "4 Training Corpus", "content": "We identified and collected 20 TOD datasets from\nwhich we could extract dialog act and/or slot anno-"}, {"title": "5 Experimental Setup", "content": "For training D2F we mostly follow the experimen-\ntal setup of DSE (Zhou et al., 2022) and TOD-\nBERT (Wu et al., 2020), using BERTbase as the\nbackbone model for the encoder to report results\nin the main text. Additional configurations are re-\nported in the ablation study (Appendix C) while\nimplementation details are given in Appendix B."}, {"title": "5.1 Baselines", "content": "General sentence embeddings. \u2022 Glove: the av-\nerage of GloVe embeddings (Pennington et al.,\n2014). \u2022 BERT: the vanilla BERTbase model\nwith mean pooling strategy, corresponding to\nour untrained encoder. \u2022 Sentence-BERT: the\nmodel with the best average performance re-\nported among all Sentence-BERT pre-trained mod-\nels, namely the all-mpnet-base-v2 model pre-\ntrained using MPNet (Song et al., 2020) and\nfurther fine-tuned on a 1 billion sentence pairs\ndataset. \u2022 GTR-T5: the Generalizable T5-based\ndense Retriever (Ni et al., 2022) pre-trained on\na 2 billion web question-answer pairs dataset,\noutperforming previous sparse and dense retriev-\ners on the BEIR benchmark (Thakur et al.,\n2021). \u2022 OpenAI: the recently released OpenAI's\ntext-embedding-3-large model (OpenAI, 2024;\nNeelakantan et al., 2022)\nDialog sentence embeddings. \u2022 TOD-BERT: the\nTOD-BERT-jnt model reported in Wu et al. (2020)\npre-trained to optimize a contrastive response se-\nlection objective by treating utterances and their\ndialog context as positive pairs. The pre-training\ndata is the combination of 9 publicly available\ntask-oriented datasets around 1.4 million total ut-\nterances across 60 domains. \u2022 DSE: pre-trained on\nthe same dataset as TOD-BERT, DSE learns sen-\ntence embeddings by simply taking consecutive"}, {"title": "5.2 Evaluation Data", "content": "Most of the TOD datasets are constructed solely\nbased on written texts, which may not accurately\nreflect the nuances of real-world spoken conver-\nsations, potentially leading to a gap between aca-\ndemic research and real-world spoken TOD sce-\nnarios. Therefore, we evaluate our performance\nnot only on a subset of our unified TOD dataset\nbut also on SpokenWOZ (Si et al., 2023), the first\nlarge-scale human-to-human speech-text dataset\nfor TOD designed to address this limitation. More\nprecisely, we use the following two evaluation sets:\n\u2022 Unified TOD evaluation set: 26,910 utterances\nwith 1,794 unique action labels (dialog act + slots)\nextracted from the training data. These utterances\nwere extracted by sampling and removing 15 ut-\nterances for each action label with more than 100\nutterances in the training data.\n\u2022 Spoken WOZ: 31,303 utterances with 427 unique\naction labels corresponding to all the 1,710 single\ndomain conversations in SpokenWOZ. We are only\nusing complete single-domain conversations so that\nwe can also use them later to extract the domain-\nspecific workflow for each of the 7 domains in\nSpoken WOZ."}, {"title": "6 Similarity-based Evaluation", "content": "Before the dialog flow-based evaluation, we assess\nthe quality of the representation space geometry\nthrough the similarity of the embeddings represent-\ning different actions. We use the following methods\nas quality proxies:\n\u2022 Anisotropy. Following Jiang et al. (2022); Etha-\nyarajh (2019), we measure the anisotropy of a set\nof embeddings as the average cosine (absolute) sim-\nilarity among all embeddings in the set. Ideally,\nembeddings of the same action should be simi-\nlar (high intra-action anisotropy) while being dis-\nsimilar to those of other actions (low inter-action\nanisotropy). We report the average intra- and inter-\naction anisotropy across all actions.\n\u2022 Similarity-based few-shot classification. We\nuse Prototypical Networks (Snell et al., 2017) to\nperform a similarity-based classification. A pro-\ntotype embedding for each action is calculated by\naveraging k of its embeddings (k-shot). All other\nembeddings are then classified based on the closest\nprototype embedding. We report the macro aver-\naged F1 score and Accuracy for k = 1 and k = 5\n(i.e., 1-shot and 5-shot classification).\n\u2022 Ranking. For each action, we randomly select\none utterance as the query and retrieve the top-k\nclosest embeddings, creating a ranking with their\nactions. Ideally, the top-k retrieved embeddings\nshould predominantly correspond to the same ac-\ntion as the query, thus ranked first. We report Nor-\nmalized Discounted Cumulative Gain (nDCG@10),\naveraged over all actions."}, {"title": "6.1 Similarity-based Results", "content": "Tables 2 and 3 present the similarity-based classifi-\ncation and anisotropy results on the unified TOD\nevaluation set and SpokenWOZ, respectively. Re-\nsults are averaged over 1,794 and 427 different\naction labels for both datasets, respectively. For\nclassification results, we report the mean and stan-\ndard deviation from 10 repetitions, each sampling\ndifferent embeddings for the 1-shot and 5-shot pro-\ntotypes. All D2F variants consistently outperform\nthe baselines across all metrics. This is expected,\nas D2F models, unlike the baselines, are explic-\nitly trained to learn a representation space where\nembeddings are clustered by their corresponding\nactions. However, the baseline results serve as\na proxy for assessing the inherent suitability of\nso it is not included.\n$\\frac{1}{n^2-n} \\sum_{i \\neq j} cos(x_i, x_j)$ for given ${x_1,..., x_n}$"}, {"title": "7 Dialog Flow Extraction Evaluation", "content": "Dialog flow extraction is an underexplored hard-\nto-quantify and challenging task with nuances in\ndefinition. However, to evaluate embedding qual-\nity, we formally define the problem as follows:\nLet U and A denote sets of TOD utterances and\nactions, respectively. Let U and A be sets of\nTOD utterances and actions, respectively. Let\na : U \u2194 A be a (usually unknown) function\nmapping an utterance to its corresponding action.\nLet $d_i = (u_1,\u2026, u_k)$ be a dialog with $u_j \u2208 U$,\nand $t_i = (\u03b1(u_1),\u2026\u2026,\u03b1(u_k)) = (a_1,\u2026,a_k)$\nits conversion to a sequence of actions, referred\nto as a trajectory. Given a set of m dialogs,\nD = {d\u2081,\u2026,dm}, and after conversion to a set\nof action trajectories, Dt = {t1,\u2026, tm}, the goal\nis to extract the common dialog flow by combin-\ning all the trajectories in Dt. We represent the\ncommon dialog flow as a weighted actions tran-\nsition graph (Ferreira, 2023). More precisely,\nthe common flow is represented as a weighted\ngraph GD = (A, E, wa, we) where A is the set\nof actions, E represents edges between actions,\nthe edge weight wE(ai, aj) \u2208 [0, 1] indicates how\noften az is followed by aj, and the action weight\nwa(ai) \u2208 [0, 1] is its normalized frequency."}, {"title": "7.1 Evaluation Details", "content": "For each domain in SpokenWOZ, we build and\ncompare its reference graph GD against the in-\nduced graph GD using different embeddings. The"}, {"title": "7.2 Dialog Flow Extraction Results", "content": "Table 6 shows the results obtained when compar-\ning the different extracted graphs. We can see that\ngraphs obtained with available sentence embed-\nding models tend to underestimate the complexity\nof each domain, producing less meaningful graphs"}, {"title": "8 Conclusions", "content": "This paper introduced Dialog2Flow (D2F), embed-\ndings pre-trained for dialog flow extraction group-\ning utterances by their communicative and informa-\ntive functions in a latent space. D2F embeddings\nwere trained on a comprehensive dataset of twenty\ntask-oriented dialog datasets with standardized ac-\ntion annotations, released along with this work.\nFuture work will enhance D2F embeddings by\nexploring larger backbone models and advanced\nmethods for sentence embeddings (Jiang et al.,\n2023, 2022). We will also investigate more sophis-\nticated techniques for extracting and representing\ndialog flows, such as using subtask graphs (Sohn\net al., 2023) or adapting dependency parsing for"}, {"title": "9 Limitations", "content": "Our work represents a preliminary exploration with\na focus on task-oriented dialogues (TODs) using a\nrelatively simple encoder model. While this work\naims to draw attention to this underexplored area,\nthere are a number of limitations that must be ac-\nknowledged:\n1. Scope of Dialogues: Our study is restricted\nto task-oriented dialogues. Consequently, the find-\nings and methods may not generalize well to more\ncomplex and diverse types of dialogues, particu-\nlarly those of a non-task-oriented nature. Future\nresearch should explore these methods in a broader\nrange of dialogue types to assess their generaliz-\nability.\n2. Domain Specificity: The model has been\ntrained on a specific collection of domains, dia-\nlogue acts, and slots. This limits its ability to gen-\neralize to unseen domains or dialogues that involve\nmore complex and varied interactions. Expanding\nthe range of training data to include a wider vari-\nety of domains and dialogue types is necessary to\nimprove the model's robustness and applicability.\n3. Model Complexity: The encoder model used\nin this work is relatively standard. There is poten-\ntial for improvement by employing larger and more\nadvanced models to obtained the final sentence em-\nbeddings.\n4. Data Size: Despite being the largest dataset\nwith standardized utterance annotations and the\nlargest spoken TOD dataset, the datasets used in\nthis study are limited in size. Larger datasets are\nnecessary to fully explore and validate the proposed\nmethods. We encourage the research community\nto build upon this work by utilizing more extensive\ndatasets to enhance the reliability and validity of\nthe results. For instance, perhaps named entity tags\nmay be used as slots to expand annotation beyond\npure task-oriented dialogues.\n5. Evaluation Metrics: The evaluation met-\nrics employed in this study, while standard, may\nnot capture all aspects of performance relevant to\nreal-world applications. Developing and utilizing a\nbroader set of evaluation metrics would provide a\nmore comprehensive assessment of model perfor-\nmance. Specifically for dialogue flow evaluation,\nsince there is not a standard metric yet, we encour-\nage the research community to explore better ways\nto represent and quantify the quality of dialogue\nflows.\nBy highlighting these limitations, we hope to"}, {"title": "10 Ethical Considerations", "content": "We are committed to ensuring the ethical use of our\nresearch outcomes. To promote transparency and\nreproducibility, we will release the source code and\npre-trained model weights under the MIT license.\nThis allows for wide usage and adaptation while\nmaintaining open-source principles.\nHowever, to prevent potential license incompat-\nibilities among the various task-oriented dialogue\n(TOD) datasets we have utilized, we will not re-\nlease our unified TOD dataset directly. Instead, we\nwill provide a script that can generate the unified\ndataset introduced in this paper. This approach\nallows users to select the specific TOD datasets\nthey wish to include, ensuring compliance with\nindividual dataset licenses.\nWe acknowledge that gender bias present in the\noriginal data could be partially encoded in the em-\nbeddings. This may manifest as assumptions about\nthe agent's gender, such as the agent being male\nor female. We advise users to be aware of this\npotential bias and encourage further research to\nmitigate such issues. Continuous efforts to audit\nand address biases in data and models are essential\nto ensure fair and equitable AI systems."}]}