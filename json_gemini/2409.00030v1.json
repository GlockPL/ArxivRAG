{"title": "TimeSense: Multi-Person Device-free Indoor Localization via RTT", "authors": ["Mohamed Mohsen", "Hamada Rizk", "Hirozumi Yamaguchi", "Moustafa Youssef"], "abstract": "Locating the persons moving through an environment without the necessity of them being equipped with special devices has become vital for many applications including security, IoT, healthcare, etc. Existing device-free indoor localization systems commonly rely on the utilization of Received Signal Strength Indicator (RSSI) and WiFi Channel State Information (CSI) techniques. However, the accuracy of RSSI is adversely affected by environmental factors like multi-path interference and fading. Additionally, the lack of standardization in CSI necessitates the use of specialized hardware and software. In this paper, we present TimeSense, a deep learning-based multi-person device-free indoor localization system that addresses these challenges. TimeSense leverages Time of Flight information acquired by the fine-time measurement protocol of IEEE 802.11-2016 standard. Specifically, the measured round trip time between the transmitter and receiver is influenced by the dynamic changes in the environment induced by human presence. TimeSense effectively detects this anomalous behavior using a stacked denoising auto-encoder model, thereby estimating the user's location. The system incorporates a probabilistic approach on top of the deep learning model to ensure seamless tracking of the users. The evaluation of TimeSense in two realistic environments demonstrates its efficacy, achieving a median localization accuracy of 1.57 and 2.65 meters. This surpasses the performance of state-of-the-art techniques by 49% and 103% in the two testbeds.", "sections": [{"title": "I. INTRODUCTION", "content": "Indoor localization has garnered significant attention due to its critical importance across various applications, such as industrial operations, emergency response services, security measures, and logistical management [1], [2], [3], [4], [5]. There are two primary approaches to localization systems: device-based and device-free solutions. Device-based localization systems [6], [7], [8], [9] require individuals to carry specific hardware, such as smartphones, to facilitate their localization. While GPS is the standard for outdoor localization, its effectiveness indoors is compromised due to signal blockage [10], leading to the exploration of alternative technologies including Wi-Fi, Bluetooth, Ultra-Wideband (UWB), and cellular networks [11], [12], [13], [4], [14], [15], [16]. On the other hand, device-free indoor localization becomes essential in scenarios where it is important to track individuals who may not be carrying any devices, such as in elderly monitoring applications. This approach is pivotal in situations requiring localization without dependence on personal devices [17]. Camera-based systems are prevalent in device-free localization but encounter several challenges [18]. These include dependency on line-of-sight, leading to substantial deployment costs to ensure complete coverage, poor performance in low-light or smoky conditions, and potential privacy issues. Consequently, there is a growing interest in leveraging alternative methods, such as Wi-Fi-based technologies that utilize radio waves, to circumvent these challenges. The received signal strength indicator (RSSI) of Wi-Fi signals is significantly influenced by human-body blockages, creating an opportunity for its utilization in device-free localization [19], [20]. However, indoor Wi-Fi RSSI-based systems encounter several challenges, including signal fading due to obstructions such as walls and objects, signal fluctuations caused by multi-path fading and radio interference, and variations in access points' transmission power to accommodate varying traffic demands. These challenges result in a degradation of the performance of Wi-Fi RSSI-based systems [21]. Conversely, Wi-Fi channel state information (CSI) has been leveraged by many systems [22], [23], [24], [25] as it exhibits sensitivity to changes in radio waves and offers valuable indications of human presence. Nonetheless, the lack of standardization for CSI necessitates the use of specialized hardware or software to acquire it, rendering it impractical for numerous applications. Recently, time-based techniques have shown promising solutions, particularly in device-based settings. These techniques estimate the distance between a mobile device (e.g., smartphone) and access points (APs) by measuring the signal's propagation time and utilizing the known propagation velocity of the signal. Various approaches have been proposed for measuring propagation time, including time of arrival (ToA) [26], time difference of arrival (TDoA) [27], [28], and round-trip time (RTT) [8]. ToA and TDoA methods necessitate precise time synchronization among all devices, posing a challenge. In contrast, RTT utilizes the difference in recorded times to measure the time required for the signal to travel to a destination node and return, thereby mitigating the synchronization problem. Unlike RSSI-based techniques, RTT demonstrates greater resilience to the challenges posed by"}, {"title": "II. RELATED WORK", "content": "Various technologies have been employed by diverse methodologies to deliver localization solutions. The widespread presence of WLANs in most indoor environments has captured the interest of researchers, prompting the development of solutions that leverage WiFi network infrastructure to offer localization services with a high level of accuracy. This section continues by reviewing prior studies in both device-based and device-free localization systems."}, {"title": "A. Device-based Indoor Localization Systems", "content": "WiFi is among the most leveraged technologies in indoor localization solutions due to its ubiquitous availability. In order to fulfill the location determination task, these systems rely on the RSSI and the RTT techniques, often in conjunction with fingerprinting methods. In the RSSI-based fingerprinting approaches [31], [32], [5], [33], [34], [35], the RSSI measurements are collected from the surrounding access points (APs) at a number of predefined reference points covering the area of interest. Then, these measurements are utilized to build a radio map which is leveraged to construct a localization model that is capable of estimating the user's location given the received RSSI readings. A probabilistic framework is utilized in the Horus system [31] to fulfill the localization task. This is achieved by generating probability distributions of the RSSI values from different APs at each location. Then, determine the user's location by determining the highest likelihood of the received RSSI values when compared to the pre-collected RSSI data. The system in [36] trains a convolutional neural network (CNN) using the collected RSSI fingerprints. This CNN-based system shows a higher localization accuracy than the probabilistic model, revealing the potential of deep-learning models in indoor localization solutions. Additionally, WiDeep [5] leverages the constructed RSSI radio map to train multiple stacked denoising autoencoders for latent feature extraction. Additionally, it employs a probabilistic model for more accurate tracking in the continuous space. Due to its resilience and robustness in indoor environments, the round-trip-time (RTT) technique gained more traction in recent years. WiNar [8] utilizes RTT fingerprints to construct a probabilistic model based on Bayesian inference. This model estimates the probability of the user's presence at predefined reference points, providing valuable information for localization. DeepNar [7] leverages the collected RTT data during the offline phase to train a multi-layer deep-learning model acting as a multi-class classifier. During the online phase, the user's device captures RTT measurements from nearby access points and feeds them to the trained model, which generates the probability of the user's existence at the reference points. On the other hand, RRLoc [6] produces an enhanced performance"}, {"title": "B. Device-free Indoor Localization Systems", "content": "In device-free systems, the localization of persons is achieved without the necessity of requiring them to carry a dedicated device. Different technologies were leveraged by several proposed systems including ultra-wideband (UWB) [38], computer vision [18], and LiDAR [39], [40], which necessitate specialized hardware for their operation. Computer vision-based systems heavily rely on camera sensors [38], which have limitations in non-line-of-sight (NLoS) conditions, leading to high deployment costs when covering large areas. Moreover, regular cameras fail to function effectively in low light or the presence of smoke, and in certain scenarios, they may raise privacy violation concerns related to the persons in some applications [39], [40]. On the contrary, Wi-Fi-based systems [19], [20], [41], [22] are built upon the existing infrastructure of WLAN networks without requiring additional hardware. The pioneering Wi-Fi-based device-free indoor localization system proposed in [19] utilizes Wi-Fi RSSI to construct a radio map within the area of interest. When disturbances occur due to the movement of individuals, a probabilistic model compares the collected RSSI data to the pre-collected data during the offline phase to perform accurate localization. RASID [41] employs a semi-supervised statistical technique to extract statistical features, such as measures of central tendency (e.g., mean) and measures of dispersion or variation (e.g., variance), from the input data. These measures/features are used to construct a density function that sets a threshold value for detecting anomalous behaviors and locating their source of anomaly. Wi-Fi Channel State Information (CSI) [22], which is extracted information from radio waves such as amplitude and phase difference. CSI responds to disturbances in the radio waves; therefore, it has been researched for human-activity recognition [42], In [22], the system leverages CSI to formulate and solve power fading model equations for all the links to achieve the localization task. On the other hand, TimeSense is based on RTT which is more robust than RSSI. In addition, RTT is feasible as it is standardized by IEEE 802.11mc which makes it widely available in consumer devices. Furthermore, TimeSense leverages a deep-learning denoising auto-encoder for more robustness against any abrupt noise."}, {"title": "III. WI-FI FTM PROTOCOL BACKGROUND", "content": "In 2016 the IEEE 802.11mc standardized the Fine-Timing Measurement (FTM) protocol that gives a Wi-Fi device the ability to accurately estimate the round trip time (RTT) between it and another Wi-Fi device. Fig. 1 shows the Wi-Fi FTM basic procedure. This process involves two types of devices: the initiating station, usually a smartphone, and the responding station which is usually applied by an access point (AP). The measurement procedure starts with the initiating station sending an FTM request to the responding station to check if it is available and to negotiate some parameters regarding the FTM process such as the number of bursts, the number of measurements per burst, etc. If the responding station is available, it replies with an acknowledgment frame (ACK) back to the initiating station. After the initiating phase, the responding station sends an FTM frame to the initiating station and records the frame's time of departure (i.e., $t_1$). On receiving the FTM frame, the initiating station records the frame's time of arrival (i.e., $t_2$). After some while, the initiating station replies back to the responding station with an ACK frame and records the frame's time of departure (i.e., $t_3$). Finally, the responding station receives the ACK frame, sent by the initiating station, and records the frame's time of arrival (i.e., $t_4$). The responding station sends the values of $t_1$ and $t_4$ in the next FTM frame in"}, {"title": "IV. THE BASIC IDEA", "content": "The fundamental concept behind TimeSense is to leverage the monitoring of signal propagation time between transmitters (e.g., APs) and receivers (e.g., smartphones) to detect the presence of individuals in the environment. This is accomplished by analyzing whether radio waves have been obstructed (blockage occurred) for each transmitter-receiver pair. When a person is present, their presence disrupts the direct line-of-sight (LoS) path between the transmitter and receiver, causing the signal to travel a longer distance path, indirect non-line-of-sight (NLoS), causing an increase in the time measurements. This effect is due to blockage caused by the human body, as illustrated in Figure 2. By examining the combination of all NLoS and LoS paths of the transmitter-receiver pairs, the system can determine the user's location. However, cluttered environments and the dense presence of crowds can introduce variations in the RTT measurements of transmitter-receiver pairs that traverse the user's location, as illustrated in Figure 3. In this vein, RTT measurements are susceptible to errors arising from device offsets, measurement noise, multipath effects, environmental influences, and variances caused by different individuals. To address this challenge, we employ a passive fingerprinting approach by"}, {"title": "V. SYSTEM OVERVIEW AND MATHEMATICAL MODEL", "content": ""}, {"title": "A. TimeSense System Overview", "content": "The system architecture of TimeSense is illustrated in Figure 4 and comprises two phases: the offline training phase and the online localization phase. During the offline training phase, the system constructs M deep neural networks, each corresponding to a specific reference point. This approach enables scalability for larger areas while maintaining smaller and more manageable model sizes. The training data is collected using the Data Collector module, which records the signal states when a person is located at designated reference points within the area of interest. This involves capturing the RTT measurements of each transmitter-receiver pair. The data collection process is repeated for each reference point in the environment. The collected data is then transmitted to the cloud-based TimeSense running service for processing. The Pre-processor module appropriately formats the data to facilitate the training of deep learning models, and the readings are normalized to enhance the training process's efficiency. To introduce noise and prevent overfitting, the preprocessed data is fed to the Noise Injector module, which corrupts the original measurements by injecting artificial noise. This technique helps simulate the presence of noisy measurements and encourages the models to learn the representative features of the signal state. Next, the corrupted and original data for each reference point is passed to the Model Construction module, which creates and trains stacked denoising autoencoders specific to each reference point. Finally, all the trained models for the different reference locations are stored for subsequent use during the online localization phase. In the online localization phase, the system provides a real-time estimation of the persons' unknown locations. The system continually collects and pre-processes the current system state, ensuring proper shaping and normalization of the data. This processed information is then fed into the pre-trained models associated with different reference points. The Online Localizer module employs a probabilistic framework, leveraging"}, {"title": "B. Mathematical Model", "content": "Assuming a 2D area of interest $L$ where $N_T$ access points (Transmitters) and $N_R$ Android devices (Receivers) are deployed. The area is divided into a definite number of reference points $M$. The data for each point is collected while keeping a person standing at that point. During the online phase, a pedestrian moves through an unknown location $l \\in L$ cutting the line of sight (LoS) between a number of transmitter-receiver pairs causing a disturbance in the system state. Let a vector $s_t$ of $K$ dimensions represent the system state at some time $t$. Each entry in this vector represents the round trip time $RTT_{ij}$ estimated between the transmitter $i$ and the receiver $j$. The problem is: given the system state $s_t =< RTT_{11}, RTT_{12}, ..., RTT_{21}, RTT_{22}, \u2026\u2026\u2026\u2026, RTT_{NT,NR} > \\in R^K (K = N_T \\times N_R)$, the objective is to detect the abnormality in the state vector entries if existed which indicates that some pedestrian is passing and find the location $l_i$ that maximizes the probability $P(l_i | s_t)$. In the next section, we discuss in detail the TimeSense system's building blocks and how they are combined together to achieve the localization task."}, {"title": "VI. THE TimeSense SYSTEM", "content": ""}, {"title": "A. The Pre-processing Module", "content": "This module plays an essential role in both the offline and online phases of TimeSense, serving multiple functions with a technical focus on data preparation and anomaly handling for deep-learning models. It processes RTT data from all receivers to compile an input vector for the deep-learning model, with each element representing an RTT measurement between a receiver and an access point. This module efficiently handles abrupt changes in network infrastructure or unexpected behavior stemming from configuration discrepancies. Specifically, it has been observed that not all installed APs are consistently detected in each scan, leading to input vectors of variable lengths. To mitigate this variability, APs undetected in a particular scan are represented with a placeholder RTT value of $0.2\\times10^{-3}$ milliseconds, equivalent to an estimated distance of 60m, exceeding typical RTT values for APs within the detection range. Furthermore, this module addresses anomalies such as the Android API reporting negative distances when a mobile device is in close proximity to an AP. This issue can be traced back to the internal configurations and calibration of WiFi cards, or to multipath compensation algorithms influencing the measurements pre-reception by the device driver. RTT measurements may also exhibit latency anomalies at certain reference points. Traditional multi-lateration approaches often suffer in accuracy due to the presence of negative values or latency [30]. Contrarily, TimeSense maintains robust performance in the face of such anomalies, leveraging negative values and delays as distinctive signatures for specific locations within its fingerprinting-based technique. Finally, the pre-processor normalizes the input vector's features, ensuring they fall within a [0, 1] range. This normalization significantly enhances the optimization process during the model training phase, optimizing TimeSense's overall efficacy and precision in localization."}, {"title": "B. The Model Construction Module", "content": "The primary function of this module is to develop and train a collection of M shallow neural networks, each customized for a unique reference point. Utilizing a straightforward vanilla model for each point, the system skillfully handles various challenges, such as the inherent noise and fluctuations in RTT measurements. To enhance the models' generalization capabilities and ensure their adaptability to scenarios with varying numbers of individuals at neighboring points, the module employs strategies to prevent overfitting the training data. Furthermore, the design of this module supports extendibility, enabling it to seamlessly adjust to expansions in the environmental space, thereby ensuring its scalability and flexibility. We employ stacked denoising auto-encoders as our deep-learning models of choice, primarily due to their remarkable capability to acquire feature representations from noisy data. Auto-encoders, in general, represent self-supervised deep-learning models that possess the inherent ability to extract latent features of lower dimensionality, which can then be used to regenerate the input data at the output [44]. Denoising auto-encoders constitute an advancement over traditional auto-encoders, specifically designed to effectively handle input data corrupted by noise, such as the RTT measurements. This enhancement is achieved by deliberately introducing noise to the input data prior to its ingestion into the auto-encoder. Consequently, this drives the hidden layers of the auto-encoder to learn latent features of greater importance, thereby bolstering the model's robustness (refer to Figure 6). Specifically, the denoising auto-encoder is trained by initially corrupting the input state vector $s$, representing the RTT, resulting in the vector $\\tilde{s}$. Our objective is to learn the parameters of the hidden layer $h$ in a manner that ensures the output of the auto-encoder $s$ matches the uncorrupted input vector $s$. By utilizing a noisy"}, {"title": "1) Noise Synthesizer:", "content": "In this phase, the module corrupts the input data by applying noise to the collected training samples. This increases the robustness of the system to handle noisy input data and reduces over-fitting leading to enhanced model generalization. The input corruption task is achieved by randomly adding noise to it through two techniques: Masking corruption and Noise corruption."}, {"title": "Masking corruption:", "content": "This technique is employed based on the observation that when a Wi-Fi device, such as an Android smartphone, continuously collects RTT readings, it may not successfully detect all APs present in the surrounding area due to factors like multi-path and fading effects [45]. In order to enable the model to learn and reconstruct the original vector even with this limitation, we deliberately corrupt the original version by generating a new sample representing non-detected APs. To accomplish this, a binary vector of size K is generated, consisting of elements that are either 0 or 1. The probability of an element being one is determined by the \"silence corruption factor\" denoted as $P_{silence}$. The ones entries in the binary vector are then placed into the corresponding entries in the input vector, resulting in a noisy vector where one entries indicate the non-detected APs (see Figure 5). Training the denoising autoencoder with these corrupted samples helps the model reconstruct the original samples. By learning to recover the missing AP information, the model gains the ability to handle the incompleteness caused by non-detected APs in real-world scenarios. This facilitates better generalization and performance when the model is deployed in environments where certain APs may not be consistently detected."}, {"title": "Noise corruption:", "content": "The utilization of white Gaussian corruption in this technique is based on the observation that certain returned RTT values are zero, despite the actual distance between the AP and the phone never being zero. Furthermore, it has been noted that some of the reported estimated ranges even exhibit negative values. These occurrences can"}, {"title": "2) Model Training:", "content": "TimeSense adopts a deep-learning approach for training its models, utilizing a stacked denoising auto-encoder architecture. This architecture consists of M individual models, where each model corresponds to a specific reference point (refer to Figure 6). During the training phase, the models capture the latent features of the RTT inputs collected while an individual is stationed at the respective reference point, particularly in scenarios where NLoS conditions occur. The purpose of capturing the latent features of the training inputs is to identify patterns and regularities that aid in detecting NLoS cases in the online behavior of the inputs, ultimately enabling accurate location estimation. The training process involves forwarding the training data through the models, followed by leveraging the reconstruction loss between the inputs and the reconstructed outputs. This reconstruction loss serves as a measure of dissimilarity between the original inputs and their reconstructed counterparts. To optimize the models during training, a Gradient Descent optimizer is employed. This optimizer utilizes the reconstruction loss to adjust the weights across the various layers of each model, iteratively updating them to minimize the discrepancy between the inputs and the reconstructed outputs. The Mean Squared Error (MSE) loss function is utilized to quantify the reconstruction loss. Specifically, the MSE loss measures the average squared difference between the inputs and their corresponding reconstructed outputs. Consequently, each denoising auto-encoder model $m_i$ learns to effectively reconstruct the"}, {"title": "C. The Online Localizer Module", "content": "The Online Localizer module leverages the trained deep-learning models to detect the persons' existence and estimate their location. The recorded state of the system is fed to each of the trained deep-learning models. Then, the reconstructed output is leveraged in a probabilistic framework to estimate the most probable locations. The lower the reconstruction error of a model, the closer a person is to the reference point represented by that model. Specifically, we need to find the probability of a person being at some pre-defined location $l_i$ in the area of interest given the current state vector $s_t$ of the system. More formally, we need to find $P(l_i | s_t)$. Recalling Bayes theorem, the posterior probability $P(l_i | s_t)$ is determined by: \n$P(l_i | s_t) = \\frac{P(s_t | l_i) P(l_i)}{P(s_t)} = \\frac{P(s_t | l_i) P(l_i)}{\\sum_{i=1}^{M} P(s_t | l_i) P(l_i)}$        (4)\nwhere $P(l_i)$ is the prior probability that the pedestrian is located at a given location $l_i$ and M is the number of reference points. Assuming that the system lacks information on the motion profiles of individuals, thereby treating all locations as equally probable, Equation (4) can be reformulated as follows: \n$P(l_i|s_t) = \\frac{P(s_t|l_i)}{\\sum_{i=1}^{M}P(s_t|l_i)}$        (5)\nIn order to calculate $P(s_t | l_i)$, TimeSense measures the similarity score between the input state sample and each reconstructed state sample produced from each trained deep-learning model. In order to obtain the similarity score, we use a radial basis kernel (RBF) as a similarity function and since its output is between 0 and 1, it can be interpreted as the probability $P(s_t | l_i)$ for the ith model as follows: \n$P(s|l_i)=\\frac{1}{n}\\sum_{j=1}^n e^{\\frac{-||s_{ij}-\\hat{s_{ij}}||}{\\sigma}}$       (6)\nwhere $s_{ij}$ and $\\hat{s_{ij}}$ are the original and the reconstructed input states of the jth scan respectively, $\\sigma$ is the variance of the input scans, and n is the total number of scans used for location estimation. Assuming the number of persons within the environment is designated as N, the system employs a multi-person localization strategy. This process begins with the normalization of the likelihood vector, representing the probability of a person's presence at each reference point, denoted as ${P (s | l_i)}_{i=1}^{M}$, where M is the total number of reference points, and $l_i$ represents the ith location. The mathematical formalization of the normalization process can be expressed as follows: \n$P_{norm}(s|l_i) = \\frac{P(s|l_i)}{\\sum_{j=1}^{M}P(s | l_j)}$ , $\u2200i \u2208 1,2,..., M$    (7)\nSubsequently, a threshold function, T, is applied to $P_{norm}(s|l_i)$ to identify reference points with a significant likelihood of a person's presence. This can be defined as: \n$Detected(l_i) = \\begin{cases} 1 & \\text{if } P_{norm}(s|l_i) > T \\\\ 0 & \\text{otherwise} \\end{cases}$       (8)"}, {"title": "Therefore,", "content": "the locations of the N persons are estimated as {$l_1, l_2,..., l_N$}. Following detection, the fine localization step is undertaken to pinpoint individuals within the continuous space accurately. This step capitalizes on the spatially weighted sum of the locations of each point's nearest K-neighbors, multiplied by their respective normalized probabilities. This refined process is encapsulated in the equation: \n$L_{fine}(l_i) = \\sum_{k=1}^{K}l_k \\cdot P_{norm}(s|l_k), l_k \u2208 KNN(l_i)$      (9)\nHere, $L_{fine}(l_i)$ represents the enhanced position for the reference point $l_i$, achieved by aggregating the products of the nearest neighbors' locations $l_k$ and their corresponding normalized probabilities. This approach allows for a more accurate estimation of each individual's position by leveraging the combined spatial and probabilistic insights from neighboring points (see Fig. 7). By adopting this strategy, the system not only enhances its precision in determining the positions of individuals within the environment in continuous space rather than discrete reference points but also adapts to the complexities introduced by varying densities and distributions of individuals, as verified in [46]."}, {"title": "VII. EVALUATION", "content": "In this section, we evaluate TimeSense within two real indoor environments, referred to as Testbed1 and Testbed2. The details of these environments are summarized in Table I. We begin by describing the data collection process and setup. Subsequently, we conduct an ablation study to evaluate the system's performance by varying the different system parameters. Finally, we compare TimeSense's performance with well-known existing device-free systems."}, {"title": "A. Experimental Setup and Data Collection", "content": "The system was deployed in two real-world environments. The first testbed is a room measuring 5.8m\u00d78.3m, containing offices, a meeting area, and furniture. The second testbed is a crowded lab equipped with cubicles and various types of furniture, spanning an area of 17.3m \u00d7 10.9m. Each area was segmented into 18 distinct reference points distributed throughout the space. The system's infrastructure utilized transmitters from Google Wi-Fi APs and Google Nest Wi-Fi APs, with receivers being Android Google Pixel 3 devices. Data collection was facilitated through an Android application installed on Android phones, designed to continuously scan for nearby APs. To streamline the process, the application was synchronized across all devices, with one device designated to initiate the collection. Participants could input the ground-truth coordinates of their current locations via the"}, {"title": "B. Ablation Study", "content": "In this section, we study the effect of changing different system parameters on the system's performance. We set a maximum number of training epochs for 3000 and 50 patience epochs for the early stopping. Table II shows the different parameters' values used throughout the evaluation section."}, {"title": "1) Effect of input noise corruption techniques:", "content": "In this subsection, we examine the impact of input noise corruption techniques on localization performance. Specifically, we explore the influence of two types of noise introduced during the training phase: binary masking noise and white Gaussian noise. Fig. 10 illustrates the median localization error of TimeSense when trained with varying standard deviations of Gaussian noise ($\\sigma_{Gaussian}$). Similarly, Fig. 11 demonstrates the effect of altering the silence corruption factor ($P_{silence}$) on the system's median localization error. The results from both figures indicate that incorporating noise into the training data can enhance system performance, as compared to training with noise-free inputs. This improvement is attributed to the effect of the corrupted training samples in enhancing the flexibility of the denoising autoencoders, enabling them to effectively work even with the presence of noisy, and unseen RTT measurements. However, an excessive increase in noise levels leads to a decline in system accuracy. This decline is due to the distortion of the input signal, which may introduce ambiguity in distinguishing between different locations. Optimal system performance is observed when $\\sigma_{Gaussian}$ = 0.1 and $P_{silence}$ = 0.1, indicating a balance between noise-induced generalization and the preservation of input integrity."}, {"title": "2) The Number of Training Reference Points:", "content": "This section investigates the impact of varying the number of training reference points on the performance of TimeSense. For this experiment, a subset of training points was randomly selected and utilized to train the system's model. It is worth noting that reducing the number of reference points is advantageous as it decreases both the data collection overhead and the computational requirements for training and inference. Fig. 12 illustrates that TimeSense's performance maintains a localization accuracy of approximately below 2m in Testbed1 and 3.5m in Testbed2 when the number of reference points is reduced to 7 and 5 respectively. This can be attributed to the system's ability to smooth the estimated locations using the probability of the neighboring points, even with a coarser grid of reference points. Although a higher density of reference points typically results in more blockage of LOS transmissions and thus better location recognition by the model, correlating RTT measurements with specific locations more precisely, our experiment demonstrates that there is an optimal number of reference points (7 and 5 points) beyond which the benefits plateau. This balance between reference point density and system performance underscores the efficiency of TimeSense's modeling and its ability to generalize from limited data. Consequently, this optimization not only preserves the system's precision but also significantly reduces the burdens associated with extensive data collection and model training."}, {"title": "3) The Effect of the Number of Transmitter/Receiver Devices:", "content": "This experiment investigates the impact of changing the number of transmitters (access points, $N_T$) and receivers (Android devices, $N_R$) on the performance of TimeSense. Figures 13 and 14 show that TimeSense consistently achieves a localization error of approximately 1.5m in Testbed1 and 2.5m in Testbed2, even when the system operates with nearly 50% (5 APs or 5 Android devices) of the initially deployed transmitters or receivers. This outcome, despite the reduction in LOS connections\u2014which are pivotal for precise user localization\u2014underscores the system's robustness under constrained conditions. This consistent performance can be attributed to two pivotal factors: Model Resilience and Location Estimation Refinement. The former is achieved through the model's training procedure, which incorporates corrupted samples. Consequently, this boosts the model's flexibility in counteracting the diminished LOS connectivity. In other words, the model is preconditioned to handle and accurately interpret suboptimal signal environments, thereby compensating for the reduced hardware setup. The latter factor is realized in the online phase,"}, {"title": "4) Dropout Percentage:", "content": "The effect of changing the dropout percentage is shown in Fig. 16. It is obvious from the figure that at a dropout rate of 30% and 10%, the best performance of TimeSense is achieved on testbed1 and testbed2 respectively. This confirms the role of dropout regularization in boosting the generalizability of the trained model and ensures its resilience to over-fitting the training data. However, the model tends to under-fit the training data at larger dropout rates as many neurons are dropped off."}, {"title": "5) The effect of changing the system's deployment:", "content": "To evaluate the effect of deployment configurations on localization accuracy, we conducted a series of experiments utilizing six transmitters and six receivers for each deployment scenario. The outcomes of these experiments are depicted in Fig. 17& 18. The results indicate that the system maintains consistent performance when the reference points within the test area are adequately covered, as observed in Deployments 1, 2, and 3. However, in Deployment 4, the system exhibited a decline in accuracy, attributable to the insufficient coverage of the area. These findings highlight the critical importance of ensuring comprehensive coverage of reference points through careful and strategic placement of transmitters and receivers to optimize localization accuracy."}, {"title": "6) The Effect of the Number of Persons in the Room:", "content": "In this experiment, we evaluate TimeSense's localization performance when testbed1 is populated with multiple individuals, focusing on how increased human presence impacts the system. It's widely recognized that an increased number of people in a room typically leads to a notable decline in the efficacy of radio-based localization systems. This decline is attributed"}, {"title": "C. Comparative Evaluation", "content": "In this section, we present a comparative analysis of Time-Sense's localization performance in relation to a state-of-the-art system proposed in [19] that utilizes Wi-Fi received signal strength indication (RSSI) for device-free localization. The RSSI-based system constructs a radio map within the target area by employing Wi-Fi RSSI measurements. During disturbances caused by the movement of individuals, a probabilistic model is utilized to accurately localize by comparing the collected RSSI data with pre-collected data during the offline phase. We have evaluated our system's model using RSSI measurements. The evaluation results of TimeSense in two different testbeds are illustrated in Fig. 19 and Fig. 20, and further summarized in Table III. As depicted in the figures and table, TimeSense demonstrates superior performance compared to the Wi-Fi RSSI system [19], achieving a median localization error reduction of 49% and 103% in Testbed 1 and Testbed 2, respectively. This notable improvement can be attributed to several challenges faced by the RSSI-based system [19], including multipath effects, interference, and variations in transmitted signal power. Moreover, the probabilistic techniques employed by the RSSI-based system, although more effective than deterministic techniques in handling the inherently noisy"}, {"title": "VIII. CONCLUSION", "content": "In this work, we proposed TimeSense, an indoor multi-person device-free localization system based"}]}