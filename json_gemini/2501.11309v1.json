{"title": "Finer-CAMQ: Spotting the Difference Reveals Finer Details for Visual Explanation", "authors": ["Ziheng Zhang", "Jianyang Gu", "Arpita Chowdhury", "Zheda Mai", "David Carlyn", "Tanya Berger-Wolf", "Yu Su", "Wei-Lun Chao"], "abstract": "Class activation map (CAM) has been widely used to highlight image regions that contribute to class predictions. Despite its simplicity and computational efficiency, CAM often struggles to identify discriminative regions that distinguish visually similar fine-grained classes. Prior efforts address this limitation by introducing more sophisticated explanation processes, but at the cost of extra complexity. In this paper, we propose Finer-CAM, a method that retains CAM's efficiency while achieving precise localization of discriminative regions. Our key insight is that the deficiency of CAM lies not in \"how\" it explains, but in \"what\" it explains. Specifically, previous methods attempt to identify all cues contributing to the target class's logit value, which inadvertently also activates regions predictive of visually similar classes. By explicitly comparing the target class with similar classes and spotting their differences, Finer-CAM suppresses features shared with other classes and emphasizes the unique, discriminative details of the target class. Finer-CAM is easy to implement, compatible with various CAM methods, and can be extended to multi-modal models for accurate localization of specific concepts. Additionally, Finer-CAM allows adjustable comparison strength, enabling users to selectively highlight coarse object contours or fine discriminative details. Quantitatively, we show that masking out the top 5% of activated pixels by Finer-CAM results in a larger relative confidence drop compared to baselines. The source code and demo are available at https://github.com/Imageomics/Finer-CAM.", "sections": [{"title": "1. Introduction", "content": "Deep neural networks can capture texture and structure information in images and leverage these features to recognize the corresponding classes [8, 9, 16, 36]. Thanks to large-scale datasets and robust training processes, deep learning algorithms have achieved classification accuracies surpassing those of human experts [15, 39]. With these ad-"}, {"title": "2. Related Work", "content": ""}, {"title": "2.1. Explainable AI", "content": "Explainable AI (XAI) aims to understand the decision of complex black-box models, and saliency maps have been one of the promising venues to provide reasonable explanations. Method designs include local optimization [22, 35], occlusion-based [11, 12, 30], gradient-based [3, 34, 38], and CAM-based [26, 33, 37, 41, 48] methods. There is also a series of works dedicated to designing evaluation metrics for XAI methods [5, 19, 44]. Among these XAI solutions, we mainly focus on the CAM-based approaches."}, {"title": "Class activation map (CAM)", "content": "Class activation map (CAM) uses a linear combination of feature activation maps to illustrate the salient image regions for a target class [48]. Existing methods differ by their weight assignments across the activation maps. Grad-CAM [37] applies classification gradients to indicate the importance of each channel, which is later refined by using positive partial derivatives [6], introducing extra axioms [13], and fusing multiple layers [17]. Score-CAM directly uses the influence of each activation map on the final prediction as the corresponding weights [41]. CAM-based methods can localize the target object with all contributing parts. However, when it comes to fine-grained classification, the capability to identify discriminative details is often limited."}, {"title": "2.2. Fine-grained Classification", "content": "Fine-grained classification aims to distinguish subordinate-level categories within a general category, e.g., different species of birds and models of cars [20, 23, 31, 40, 42, 45]. Unlike standard image classification, fine-grained tasks often involve subtle differences between classes, localized to specific regions [46, 47]. While many cues contribute to class prediction, only a few can deterministically distinguish an object from its visually similar counterparts. In this work, we focus on spotting the differences between the target class and similar classes and highlight these discriminative details in the images."}, {"title": "3. Method", "content": ""}, {"title": "3.1. Preliminaries", "content": "Class activation map (CAM) is a technique to highlight image regions that contribute to the classification prediction. We denote a neural network classifier by $f: X \\rightarrow \\mathbb{R}^{C}$, which maps the input image $x \\in X$ to prediction logits $y \\in \\mathbb{R}^{C}$. During the forward pass, a network layer generates $K$ feature maps $A = \\{A_{k}\\}_{k=1}^{K}$ according to the channel number. Consider a feature map $A_{k} \\in A$ and the prediction logit $y_{c} \\in \\mathbb{R}$ for class $c$. CAM assigns an importance weight $\\alpha_{k}^{c}$ based on the contribution of $A_{k}$ to the prediction logit. The final saliency map $L_{c}$ for class $c$ is produced by a linear combination of the feature maps:"}, {"title": "", "content": "$L_{c} = h(\\sum_{k} \\alpha_{k}^{c} A_{k})$\n                                                               (1)"}, {"title": "", "content": "where $h()$ is an activation function, typically set as ReLU to focus on features with positive effects on the prediction. Grad-CAM [37] acquires the importance weight based on the average back-propagated gradients with respect to all grids in the feature map:"}, {"title": "", "content": "\\alpha_{k}^{c} = \\frac{1}{Z} \\sum_{i} \\sum_{j} \\frac{\\partial y_{c}}{\\partial A_{ij}^{k}}\n                                                                                                                    (2)"}, {"title": "", "content": "where $i, j$ represent the feature grid location in $A_{k}$, and $Z$ is the total number of feature grids. Score-CAM [41] obtains $\\alpha_{k}^{c}$ by measuring the increase of confidence after applying the feature activation map on the original image:"}, {"title": "", "content": "\\alpha_{k}^{c} = f(x \\bullet H_{k}) - f(x_{b}),\n                                                                                                                               (3)"}, {"title": "", "content": "where $x_{b}$ is by default a zero input, $H_{k}$ is the upsampled activation map to the original image size, $\\bullet$ denotes Hadamard Product, and $f(.)$ picks the prediction logit for class $c$."}, {"title": "3.2. Activation via Comparison", "content": "Despite various ways to determine appropriate weights for each feature map, CAM often fails to highlight the most discriminative regions in fine-grained classification tasks. In such tasks, the distinctions among similar classes are often located in subtle details, whereas CAM tends to activate across the entire object. We aim to understand this finding.\nConsider the case where Grad-CAM is applied to the last network layer before the linear classifier. It has been proved in this case that $\\alpha_{k}^{c}$ equals the corresponding classifier weight $w_{k}^{c}$ that transfers the feature map to the prediction logit up to a proportionality constant $(1/Z)$ [37]:"}, {"title": "", "content": "w_{k}^{c} = \\sum_{i} \\sum_{j} \\frac{\\partial y_{c}}{\\partial A_{ij}^{k}}.\n                                                                                                                        (4)"}, {"title": "", "content": "That is, the importance score of the k-th channel is exactly the corresponding linear classifier weight. As suggested in Fig. 1 (left), several fine-grained class pairs possess high similarity. When CAM solely considers the target class $c$ for highlighting regions, it overlooks the fact that the corresponding features may also be predictive of similar classes.\nFig. 1 (middle) illustrates this phenomenon. When CAM is applied to a Blue Grosbeak image, the resulting saliency maps for the true class and Grandala\u2014a similar class\u2014are nearly identical. The blue body color not only contributes to the correct prediction but also increases the logit for Grandala, as both species share this feature. Consequently, solely explaining the target class inadvertently limits CAM from spotting discriminative regions."}, {"title": "Gradient-based Finer-CAM", "content": "Intuitively, identifying discriminative regions in an image becomes easier when similar references are provided, akin to a spot-the-difference task. Inspired by this, we propose Finer-CAM, which assigns activation weights by explicitly comparing the target class with similar ones. We first use gradient-based CAM methods to demonstrate the idea. Fig. 3 shows the pipeline of Finer-CAM.\nGradient-based Finer-CAM. The original Grad-CAM only considers the prediction logit of the target class. We propose to additionally involve similar classes, and calculate the gradients of the logit difference:"}, {"title": "", "content": "\\alpha_{k}^{c,d} = \\frac{\\partial (y^{c} - \\gamma \\times y^{d})}{\\partial A_{ij}^{k}}\n                                                                               (5)"}, {"title": "", "content": "where $y^{d}$ is the prediction logit of a similar class $d$, and $\\gamma$ is the comparison strength coefficient. Based on the differentiation linearity, we can decompose the partial derivatives:"}, {"title": "", "content": "\\frac{\\partial (y^{c} - \\gamma \\times y^{d})}{\\partial A_{ij}^{k}} = \\frac{\\partial y^{c}}{\\partial A_{ij}^{k}} - \\gamma \\times \\frac{\\partial y^{d}}{\\partial A_{ij}^{k}}.\n                                                                                                               (6)"}, {"title": "Following the definition in Eq. (2), we obtain:", "content": "Following the definition in Eq. (2), we obtain:"}, {"title": "", "content": "\\alpha_{k}^{c,d} = \\alpha_{k}^{c} - \\gamma \\times \\alpha_{k}^{d},\n                                                                                                        (7)"}, {"title": "", "content": "which we then use to replace $\\alpha_{k}^{c}$ in Eq. (1).\nIn short, instead of merely capturing features predictive of class $c$ in isolation, the proposed Finer-CAM identifies those that positively contribute to class $c$ while negatively (or less strongly) contributing to class $d$. In Fig. 1, the blue body is a shared trait between both species and does not aid in differentiation. Therefore, it is less activated after the comparison in Finer-CAM."}, {"title": "Aggregation", "content": "Aggregation. By controlling the comparison strength $\\gamma$, it is possible to adjust the distribution in the saliency map. When $\\gamma = 0$, Finer-CAM degenerates to the baseline Grad-CAM and produces a coarse saliency map very much covering the object. In contrast, a larger $\\gamma$ leads to fine-grained activation of details. See Fig. 8 for illustrations. With this flexibility, we can also aggregate Finer-CAM with multiple references to form the final saliency map for the target class:"}, {"title": "", "content": "L_{c} = ReLU\\left(\\frac{1}{T} \\sum_{t} \\alpha_{k}^{c,t} A_{k}\\right).\n                                                                                                            (8)"}, {"title": "", "content": "where $T$ is the number of compared reference classes. The aggregation fuses the key distinctions between the target class and multiple similar classes, making the produced saliency map more comprehensive. Note that given the existence of the ReLU activation, the direct subtraction between two saliency maps cannot yield the same result as Finer-CAM, which is further analyzed in Sec. 4.3."}, {"title": "Score-based Finer-CAM", "content": "Score-based Finer-CAM. The proposed Finer-CAM can be applied to score-based CAM methods as well. Building upon Eq. (3), we add a negative term to de-emphasize features that positively contribute to a similar reference class $d$. The resulting activation weights thus highlight feature maps that would enlarge the logit difference between the target class and the reference:"}, {"title": "", "content": "\\alpha_{k}^{c,d} = f(x \\bullet H_{k}) - \\gamma \\times f(x \\bullet H_{k})_{d} - f(x_{b}),\n                                                                                                          (9)"}, {"title": "3.3. Extension to Multi-model Interaction", "content": "Typically, CAM is applied to explain a classifier on a specific task. However, it can also be extended to zero-shot classification scenarios. For a pre-trained CLIP model [32], the fixed linear classifier layer is replaced by text embeddings; the logits are calculated by the similarities between visual and text embeddings. In this setting, CAM highlights image regions that correspond to the semantics of the text prompt. Similar to the classifier-based scenario, we perform comparisons between different text prompts, enabling more flexible interaction and accurate localization of concepts within the image.\nA valuable application of this extension is verifying the correctness of model activations. When both class and attribute labels are provided, Finer-CAM can first be applied"}, {"title": "4. Experiments", "content": ""}, {"title": "4.1. Implementation Details", "content": "We consider two application scenarios for Finer-CAM, i.e., the standard classifier and multi-modal zero-shot classification settings. For the classifier setting, we employ a pre-trained CLIP visual backbone and train a linear classifier head on top using the Adam optimizer [18]. The classifier is trained for 100 epochs on each dataset with a learning rate of 3e-4. For the zero-shot setting, we directly use the pre-trained CLIP model for inference [32]. We conduct aggregation over the saliency maps generated by comparing the target class with the top 3 similar classes. The weight $\\gamma$ in Eq. (5) is defaulted as 0.6, unless stated otherwise.\nDatasets. In this paper, we mainly adopt five fine-grained classification datasets covering different general categories including Birds-525 [31], CUB-200 [40], Cars [20], Aircraft [23], and FishVista [24]. Please refer to the supplementary material for more data details."}, {"title": "4.2. Experimental Results", "content": "We first compare the proposed Finer-CAM with different baseline CAM methods including Grad-CAM [37], Layer-CAM [17], and Score-CAM [41].\nVisualization comparison. The visualization of example saliency maps generated by baseline methods and our proposed Finer-CAM is shown in Fig. 4. Finer-CAM shows advantages over baseline CAM methods in three aspects. First, when baseline CAM methods focus on regions that also contribute to predicting similar classes, Finer-CAM localizes the discriminative details by explicitly spotting the"}, {"title": "4.3. Analysis and Discussion", "content": "In this section, we conduct further analysis of the proposed Finer-CAM method. The method is by default applied on Grad-CAM, which is identical to the \"Fine-Grad-CAM\" in the last section. Birds-525 dataset is adopted for analysis."}, {"title": "Comparison reference", "content": "Comparison reference. By comparing the target class with a similar class, Finer-CAM spots the discriminative regions in the images, where the activation map is dependent on the difference between these two classes. Therefore, when changing the comparison reference, Finer-CAM will focus on different cues for the target class. We first visualize the produced activation maps in Fig. 7. The original Grad-CAM highlights the yellow neck and chest regions, but the similar classes also possess yellow body parts. Thus, by conducting comparisons, Finer-CAM spots the wing, head, and back for these top 3 similar classes, respectively.\nWe also conduct quantitative analysis to investigate the influence of the comparison references using the deletion and relative drop metrics in Tab. 2. Comparing the target class with the second predicted class produces direct optimization of the relative drop metric, while the aggregation of all the similar classes yields the best results in general."}, {"title": "5. Conclusion", "content": "We investigate CAM's poor localization capability in fine-grained tasks. We argue that the explanation should not only focus on the target class but also consider visually similar classes to highlight discriminative regions. Accordingly, we propose Finer-CAM, a saliency map approach dedicated to highlighting the regions that differentiate the target class"}]}