{"title": "Smart Sampling Strategies for Wireless Industrial\nData Acquisition", "authors": ["Soto Marcos"], "abstract": "In industrial environments, data acquisition accuracy is crucial for\nprocess control and optimization. Wireless telemetry has proven to be a\nvaluable tool for improving efficiency in well-testing operations, enabling\nbidirectional communication and real-time control of downhole tools (Acar\net al., 2014). There is a growing adoption of wireless systems due to their\nadvantages. However, the high sampling frequencies required present sig-\nnificant challenges in telemetry, including data storage, data transmission,\ncomputational resource consumption, and battery wear of wireless devices\n(Julius & Shastry, n.d.). This study explores how applying mathematical\ntechniques for optimizing a real data acquisition system can detect aliasing\neffects, and systematic errors, and improve sampling rates without com-\npromising the accuracy of physical measurements. An 80% reduction in\nthe sampling frequency was achieved without compromising measurement\nquality. These findings provide a basis for optimizing the implementation\nof wireless data acquisition systems in industrial environments.", "sections": [{"title": "Introduction", "content": "As a fundamental task in the oil exploration industry, well testing is a process\nin which the production of a well is measured over a specified period, either at\nthe wellhead using portable equipment or at a production facility. Its primary\npurpose is to evaluate key reservoir parameters such as permeability, hydraulic\nconnectivity, and average reservoir pressure. In exploratory wells, it is used\nto collect fluid samples, measure initial pressure, and estimate the reservoir's\nminimum volume. In production wells, it allows verifying permeability, identi-\nfying fluid behaviors, and evaluating heterogeneities. Regarding the produced\nphases or fluids from this operation, liquids such as water and oil are stored\nin atmospheric tanks, while gas is usually flared or delivered to a sales point.\nThis process is crucial to ensure proper reservoir characterization, optimize pro-\nduction, and minimize errors in operational and strategic decision-making. Ac-"}, {"title": "Objective", "content": "This study aims to determine the minimum sampling frequency that optimizes\ndata storage and transmission in wireless acquisition systems while ensuring\nthat the signal quality is maintained. Specifically, the goal is to avoid aliasing\nerrors that could affect the ability of ML models to identify trends and detect\nanomalies in industrial environments. By striking a balance between efficient\ndata acquisition and signal preservation, we ensure that the reduced sampling\nfrequency does not compromise the effectiveness of predictive models used in\nindustrial monitoring.\nTo achieve the study's objective, the aim is to determine the optimal sam-\npling frequency $F_s$ that minimizes the costs associated with the data acquisition\nsystem while maintaining a relative error $E_{relative}$ below a target value $E_{objective}$.\nTo this end, the following objectives are proposed:\n\u2022 Evaluate the impact of $F_s$ on the relative error of the uncompensated\nsignal."}, {"title": "Methodology", "content": "Relative error: It is defined as the main metric to evaluate the quality of the\nsignal reconstruction:\n$E_{relative} = \\frac{|| S_{original} - S_{rebuilt} ||}{|| S_{original} ||}$\nWhere $S_{original}$ is the original signal and $S_{rebuilt}$ is the reconstructed signal after\nsubsampling and applying compensation techniques."}, {"title": "Cost function", "content": "In wireless systems, the transmission cost is directly related to the energy con-\nsumption of the sensor, while the storage cost depends on the amount of data\ngenerated, proportional to the sampling frequency $F_s$. Therefore, the cost func-\ntion is posed as:\n$C(f_s) = k_a f_s + k_t E_{trans}(f_s) + \\lambda E_{relative}$\nWhere:\n\u2022 $k_a$: Constant representing the cost proportional to data storage.\n\u2022 $k_t$: Constant that represents the cost associated with energy consumption\nper transmission.\n\u2022 $E_{trans}(f_s)$: Energy consumption associated with data transmission at a\nsampling frequency $f_s$.\n\u2022 $\\lambda$: Weight that reflects the relative importance of the error in the total\ncost function."}, {"title": "Relationship between frequency and relative error", "content": "According to the Nyquist criterion, the sampling frequency should be in the\nrange:\n$f_s \\in [f_{min}, 2f_{max}]$\nwhere $f_{min}$ is the minimum acceptable sampling frequency according to the\ntarget error $E_{target}$.\nThe aliasing error is evaluated as the accumulated difference between the\noriginal and reconstructed signals in the frequency domain:\n$E_{aliasing} = \\int_{f_s}^{2f_{max}} |S_{original}(f) - S_{rebuilt}(f)| df$\nThis allows us to evaluate the magnitude of the error when reducing $f_s$,\nconsidering its impact on the quality of the reconstructed signal.(Aljameel et\nal., 2022)"}, {"title": "Experimental Setup", "content": "The experimental process consists of the following steps:"}, {"title": "Data Collection", "content": "Data collection: Real-time data is collected from a wireless sensor network in an\nindustrial environment, focusing on gas measurements in well-testing operations.\nSeveral datasets collected from different time periods and different oil wells were\nused, obtained from well testing services at oil and gas companies. The data\nincludes gas, oil and water flow measurements. The data was originally sampled\nat a frequency of one data per second. This high frequency allows accurate\ncapture of signal variability, but presents challenges in terms of storage and\npower consumption of wireless instruments."}, {"title": "Description of the experiments", "content": "Purpose: Subsampling with different frequencies will be performed on real field\nsignals. The experiments seek to validate how the relative error varies with\nthe sampling frequency and how compensation techniques allow maintaining\nsignal quality when reducing the frequency. Signals used: For the experiment,\ntwo signals were taken from two different oil wells, in a gas flow measurement\nduring a full day of a real field operation. These signals correspond to the\ngas line measurement that goes from a well testing separator to the vent line.\nSampling frequencies: The signals were subsampled at frequencies of 1, 5, 10,\n15, and 20 seconds. The original signal was sampled at 1 Hz.\nA wireless sensor was installed on the flow line, the process area is located\nat a safe distance from the control room, the data is sent wirelessly. The signals\nof gas volumetric flow rate as a function of time are shown below:\nIt can be observed that the signal corresponding to Well number 1 has a\nfairly repetitive behavior pattern, while the signal corresponding to Well 2 does\nnot. This may be due to characteristics of the operation, such as moments of\nchanges in the well's production, closing/opening of the well, communication\nproblems and/or possible unexpected events.\nAs part of the measurement task, it is important to detect these events in\ntime to prevent any potential danger in the installation. Just as an example,\na sharp drop in the gas trend can mean a blockage in the vent outlet that can"}, {"title": "Analysis Methods", "content": "To identify the magnitude of the error, among the signals that were obtained\nusing different frequencies, we can take different techniques:\n\u2022 Compare the entire shape of the signal.\n\u2022 Compare only the difference in means.\nThe first technique is more sensitive to changes in the signal, while the second\nis more robust to noise. In this case, the first technique was used to evaluate\nthe error magnitude."}, {"title": "Signal Comparison Techniques", "content": "Compare the entire shape of the signal\nFor this purpose, it is common to calculate the norm (magnitude) of a vector\n(Euclidean or L2 norm). This means that, given a list (or array) of values, for\nexample, $[X_1,X_2, X_3, . . . ]$, it returns:\n$\\sqrt{x_1^2 + x_2^2 + x_3^2 + ...}$\nIn other words, it is the Euclidean distance of the vector from the origin.\nThis metric, the Euclidean or L2 norm, evaluates the point-to-point dif-\nference between the original signal and the reconstructed signal. The more\n\"similar\" they are at all points, the lower this value will be.\nInterpretation:\nIt takes into account not only the average amplitude, but also the complete\nshape of the signal (peaks, valleys, phase, etc.). Ideal for measuring the overall\nsimilarity of the waveform (for example, when the shape of the signal is crucial:\nECG, vibrations, etc.)."}, {"title": "Compensation Methods", "content": "Application of compensation techniques:\nFor each of the signals, well 1 and 2, different sampling frequencies ($f_s$) are\napplied, that is, the signal is subsampled using an appropriate factor, and the\nL2 error is calculated, and with respect to the mean, even taking different values\nfor the variable e (allowable error).\nTwo sets of experiments were performed:\n\u2022 Experiment 1: Without compensation: Using the original signal.\n\u2022 Experiment 2: With compensation: Using the filtered and reconstructed\nsignal to mitigate the aliasing error. (Mart\u00ednez-Nuevo, 2021)"}, {"title": "Results and Discussion", "content": ""}, {"title": "Uncompensated Signal Analysis", "content": ""}, {"title": "Experiment 1: Without compensation", "content": ""}, {"title": "Compensated Signal Analysis", "content": ""}, {"title": "Experiment 2: With compensation", "content": "Compensation techniques were applied to reconstruct the signal using cubic\ninterpolation and outlier filtering."}, {"title": "Battery Life Impact", "content": ""}, {"title": "Battery Impact Estimation", "content": "Wireless sensor nodes rely on battery power, making energy efficiency a critical\nfactor in industrial monitoring applications. The energy consumption per trans-\nmission is a key contributor to battery depletion, and optimizing the sampling"}, {"title": "Proportional Relationship of Consumption", "content": "The total energy consumption $E_{total}$ in an interval can be approximated as:\n$E_{total} = E_b+n \\cdot E_t$\nWhere:\n\u2022 n: Number of transmissions per unit of time.\n\u2022 $E_t$: Energy consumed per transmission.\n\u2022 $E_t$: Energy consumed in standby per unit of time.\nWith a ratio of 5 more transmissions using 1 second as an interval, the total\nconsumption is proportionally higher. To simplify:\nRelative consumption (5s vs 1s) = $1 \\cdot E_t (5s)$ vs. $5 \\cdot E_t (1s)$\nThus, if $E_t$ is negligible (which may be valid if transmission cost dominates),\nconsumption in 1 second mode will be approximately 5 times higher."}, {"title": "Battery Life Estimation", "content": "Assuming the device battery lasts T hours with transmission at 1 second. If you\nchange to 5 seconds, the estimated battery life will be approximately 5 times:\n$T_{5s} = T_{1s}5$\nFor example: If the battery lasts 2 months (1440 hours) with a transmission\nevery 1 second changing to a transmission every 5 seconds we get:\n$T_{5s} = \\frac{1440}{0.5} = 7200$ hours \u2248 300days\nWith a transmission every 5 seconds its duration is approximately 1 year, that\nis, we go from changing 1 battery every two months to almost annually."}, {"title": "Practical Justification", "content": "Based on the estimated data: Increasing the transmission frequency from 5s\nto 1s would reduce battery life to approximately one-fifth. Using a 5-second\ninterval significantly extends battery life, which is crucial for wireless sensors in\napplications where replacing the battery is costly or inconvenient. For environ-\nments where battery replacement is complex or expensive, a lower transmission\nfrequency translates into significantly reduced operating costs and reduced sen-\nsor downtime. However, the optimal transmission frequency should be selected\nbased on signal quality requirements, ensuring a balance between data accuracy\nand power consumption."}, {"title": "System Optimization", "content": "The results obtained suggest the feasibility of developing autonomous systems\nthat dynamically adjust sampling frequency based on well operating conditions\nand signal variability. Such a system could: Monitor relative error in real-time\nand automatically adjust sampling frequency to optimize battery life without\ncompromising data quality. Implement machine learning algorithms to iden-\ntify signal variability patterns and anticipate critical events. Improve network\nresource management by prioritizing data based on the criticality of the infor-\nmation collected. Adopting this strategy would allow for an optimal balance\nbetween data quality and energy efficiency, ensuring reliable and cost-effective\nmonitoring in the long term. Final Considerations and Future Directions: This\nstudy demonstrates that it is possible to significantly reduce the sampling fre-\nquency in wireless data acquisition systems without compromising signal qual-\nity. However, careful consideration must be given to preventing aliasing effects,\nwhich can impact the ability of ML models to detect critical patterns. The\nfindings highlight that while stable signals allow for more aggressive sampling\nreduction, dynamic signals require a threshold-based approach to avoid sig-\nnal degradation. A promising future direction is to develop adaptive sampling\nstrategies that dynamically adjust the sampling frequency based on real-time"}, {"title": "Future Work: Integrating Generative AI for\nEnhanced Signal Processing", "content": "This study has demonstrated the feasibility of optimizing sampling rates while\npreserving signal integrity for machine learning applications. However, further\nimprovements can be achieved by integrating generative AI models to enhance\ndata reconstruction and anomaly detection."}, {"title": "Generative Models for Signal Denoising", "content": "Generative models, such as Variational Autoencoders (VAEs) and Generative\nAdversarial Networks (GANs), have shown promising results in reconstructing\nmissing or aliased signal components. These models learn the underlying dis-\ntribution of signals and generate high-fidelity reconstructions, improving the\naccuracy of ML-based anomaly detection systems (Liu et al., 2022; Wan et al.,\n2020).\nFor instance, in industrial monitoring applications, GANs have been suc-\ncessfully applied to reconstruct incomplete sensor readings, mitigating noise and\naliasing errors (Wang et al., 2021). VAEs have also been explored in time-series\ndata for predictive maintenance by learning latent representations of signal dy-\nnamics and reconstructing corrupted measurements (Xu et al., 2020)."}, {"title": "Adaptive Sampling with Reinforcement Learning", "content": "Reinforcement learning (RL) can be leveraged to develop adaptive sampling\nstrategies where an intelligent agent dynamically adjusts the sampling rate in\nreal-time based on detected signal variability. This approach ensures optimal\ntrade-offs between data efficiency and accuracy (Panchapagesan et al., 2023).\nRecent studies have demonstrated that deep Q-learning and policy gradient\nmethods can significantly reduce energy consumption in wireless sensor networks\nwhile maintaining signal fidelity (Li et al., 2021). Such approaches could be"}, {"title": "Multi-Modal Data Fusion", "content": "Future research can explore how integrating additional sensor modalities such\nas pressure, vibration, or acoustic data-using multimodal AI frameworks can\nenhance predictive maintenance capabilities in industrial settings. Recent works\nshow that multimodal fusion with deep learning can improve fault detection\nin industrial processes by combining heterogeneous data sources (Yang et al.,\n2022).\nA promising direction involves combining transformer-based architectures\nwith sensor fusion to improve anomaly detection in well-testing scenarios, lever-\naging cross-modal correlations to refine predictions (Ma et al., 2023).\nThese advancements would allow wireless data acquisition systems to become\nmore autonomous, efficient, and reliable, facilitating better predictive analytics\nin industrial environments."}, {"title": "Conclusion", "content": "This study has demonstrated that reducing the sampling frequency in wireless\nindustrial data acquisition systems is feasible without significantly compromis-\nsing measurement quality, provided that appropriate compensation techniques\nare applied. By implementing filtering and cubic interpolation, it was possible\nto reduce the sampling rate by up to 80% while maintaining a relative error\nbelow 2%.\nThe key findings of this study include:\n\u2022 Battery savings: Lowering the sampling frequency from 1 Hz to 5-second\nintervals extended sensor battery life by nearly five times, significantly\nreducing operational costs in remote or hazardous industrial environments.\n\u2022 Storage and transmission efficiency: An 80% reduction in data gener-\nation leads to a substantial decrease in storage and transmission overhead,\noptimizing network bandwidth usage while maintaining reliable data ac-\nquisition.\n\u2022 Preserving critical signal features: Without compensation techniques,\naggressive downsampling introduces aliasing errors, distorting key signal\npatterns. However, with proper filtering and interpolation, the down-\nsampled signal retained its essential characteristics, making it suitable for\npredictive analytics and anomaly detection.\n\u2022 Impact on machine learning models: Many industrial monitoring ap-\nplications rely on ML models to detect early warning signs of failures. If\nsampling rates are reduced without compensation, valuable trend infor-\nmation can be lost, degrading model performance. This study confirms\nthat aliasing-free downsampling is essential for maintaining predictive ac-\ncuracy.\nThe results highlight that while reducing sampling frequency yields clear\nbenefits in terms of energy efficiency and data management, it must be done\ncarefully. A naive approach that simply reduces the sampling rate\nwithout compensation can lead to significant data loss, impairing\nanomaly detection and process optimization.\nFuture work will focus on extending these findings by integrating adap-\ntive sampling strategies using machine learning, where real-time signal\nvariability determines optimal sampling rates dynamically. Additionally, the\nincorporation of **generative AI techniques** could further enhance data re-\nconstruction, improving trend preservation and anomaly detection in industrial\nsystems.\nUltimately, this research provides a robust framework for optimizing in-\ndustrial telemetry, balancing **data efficiency, sensor longevity, and analytical\nreliability** to ensure high-quality decision-making in industrial operations."}]}