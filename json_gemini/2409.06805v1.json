{"title": "Personalized Federated Learning Techniques: Empirical Analysis", "authors": ["Azal Ahmad Khan", "Ahmad Faraz Khan", "Haidar Ali", "Ali Anwar"], "abstract": "Personalized Federated Learning (pFL) holds immense promise for tailoring machine learning models to individual users while preserving data privacy. However, achieving optimal performance in pFL often requires a careful balancing act between memory overhead costs and model accuracy. This paper delves into the trade-offs inherent in pFL, offering valuable insights for selecting the right algorithms for diverse real-world scenarios. We empirically evaluate ten prominent pFL techniques across various datasets and data splits, uncovering significant differences in their performance. Our study reveals interesting insights into how pFL methods that utilize personalized (local) aggregation exhibit the fastest convergence due to their efficiency in communication and computation. Conversely, fine-tuning methods face limitations in handling data heterogeneity and potential adversarial attacks while multi-objective learning methods achieve higher accuracy at the cost of additional training and resource consumption. Our study emphasizes the critical role of communication efficiency in scaling pFL, demonstrating how it can significantly affect resource usage in real-world deployments.", "sections": [{"title": "I. INTRODUCTION", "content": "Background. Google proposed Federated Learning (FL) to aggregate distributed intelligence without compromising data privacy and security [1]. FL is a distributed ML approach that enables training on a large corpus of decentralized data residing on devices like mobile phones, addressing data privacy, ownership, and locality issues and offering advantages over centralized ML [2]. FL provides benefits such as data security by storing training datasets on devices, improved data diversity by enabling access to heterogeneous data, and increased hardware efficiency by eliminating the need for a single complex central server. FL can be used to build models in user behavior from smartphone data without leaking personal data, such as next-word prediction [3], face detection [4] [5] [6], voice recognition [7], and the healthcare sector [3], [8]-[10].\nPurpose of personalization. Statistical heterogeneity in FL can lead to non-iid (non-independent and identically distributed) data, which refers to a situation where the data distribution among different clients is not the same [11]. Non-iid data can pose significant challenges for machine learning algorithms since they are typically designed for independent and identically distributed data. With non-iid data, traditional ML training algorithms may perform poorly and result in suboptimal models. FL applications generally face non-i.i.d and unbalanced data available to devices, making it challenging to ensure good performance across different devices with an FL-trained global model [12]. The general FL approach faces several fundamental challenges (i) poor convergence on highly heterogeneous data and (ii) lack of solution personalization, (iii) the final model is less appealing for clients, and (iv) limited computation resources [13], [14]. These issues deteriorate the performance of the global FL model on individual clients. These challenges can be solved via personalization by allowing for the training of multiple personalized models that are customized to the data and preferences of individual clients. Personalization allows for better performance on highly heterogeneous data.\nPurpose of the study. Personalized Federated Learning (pFL) has been extensively explored in various studies, such as those conducted by Kulkarni et al. [15] and Zhu et al. [16]. These studies typically categorize methodologies based on the pFL techniques. Some studies such as Divi et al. [17] propose metrics for fairness evaluation in pFL, going beyond traditional model performance metrics. However, there is a lack of a standard benchmark that could be used for comparative analysis of pFL techniques based on various real-world factors such as resource consumption, efficiency, and performance. Therefore, our contributions go beyond existing studies on pFL algorithms by offering a comprehensive assessment of various aspects, including performance, per-round time and convergence time, as well as memory overhead. This difference in contributions between our study and extant surveys in pFL is shown in Table I. Our empirical analysis reveals notable trends in the performance of different pFL categories. For instance, methods that utilize personalized (local) aggregation demonstrate the fastest performance due to their ability to reduce communication and computation requirements per round. Methods that use multi-task learning or transfer learning either by finetuning the global model or learning additional personalized models are much more memory intensive. We then provided a rationale for these findings, which we believe will be valuable for the development of new pFL algorithms. It is crucial for industry to gain a comprehensive understanding of which algorithms are best suited to their practical applications.\nContributions. Our contributions are as follows:\n\u2022 (C1) The paper encompasses a comprehensive empirical analysis of ten pFL techniques, systematically evaluating their performance across multiple datasets and data splits. These algorithms were compared with two popular baselines FedAvg [18] and FedProx [19]."}, {"title": "II. GENERAL FEDERATED LEARNING", "content": "A. FedAvg\nFedAvg [18] works by iteratively averaging model updates from multiple clients to train a global model in an FL setting. In each round of training, a subset of clients are randomly selected to participate. The current global model is sent to each selected client, which trains the model on their local data using Stochastic Gradient Descent (SGD) and returns the updated model parameters. The central server then aggregates these model updates by taking a weighted average, considering the number of data points at each client, to create a new global model. This process is repeated until convergence. However, FedAvg faces challenges when the client data is heterogeneous. This is a core challenge of FL, especially when data is non-IID, as is often the case in real-world scenarios. Since the model is trained on different data sources, the global model may struggle to generalize well across all clients. This motivates the development of pFL techniques, which aim to address the limitations of traditional FedAvg by adapting models to individual client data.\nB. FedProx\nFedProx [19] is an extension of the FedAvg algorithm that introduces a proximal term to the objective function of the local subproblem in FL. This proximal term acts as a regularization term, penalizing large deviations of the local model from the global model. The FedProx algorithm begins with the initialization of a global model. A subset of clients is then selected for each round of training. The selected clients train their local models on their respective local data using stochastic gradient descent (SGD) while minimizing the modified objective function that includes the proximal.\n$\\min_w h_k (w; w^t)=\\mathbb{F}_k(w) + \\frac{\\mu}{2} ||w - w^t||^2$  (1)\nThe local models are aggregated at the central server by taking a weighted average, and the proximal term(\u03bc) is updated based on the difference between the local and global models, as shown in Equation 1. These steps are repeated until convergence. FedProx offers several advantages in FL. It improves convergence compared to FedAvg, particularly in heterogeneous client data scenarios. The proximal term helps to stabilize the learning process and mitigates the impact of variable local updates, resulting in faster and more robust convergence. Additionally, FedProx has been shown to achieve higher test accuracy than FedAvg on realistic federated datasets, indicating improved model performance. However, while FedProx helps mitigate system and data heterogeneity's impact, finding the right balance through hyperparameter tuning becomes crucial. Setting the hyperparameter \u03bc appropriately is necessary to ensure it is effective in regularizing the model without overly constraining the fitting to local data. Achieving optimal hyperparameter settings can be time-consuming and requires expertise."}, {"title": "III. PERSONALIZED FEDERATED LEARNING ALGORITHMS", "content": "In this section, we additionally categorize these existing pFL techniques [20]\u2013[29] into three categories as shown in Figure 1 based on learning and aggregation methodologies: (1) methods that learn a single global model and finetune it; (2) methods that learn additional personalized models; and (3) methods that learn local models with personalized (local) aggregation.\nA. Methods that learn a single global model and finetune it\nThis approach focuses on methods that learn a single global model and then perform fine-tuning locally. Per-FedAvg utilizes an initial shared model based on MAML [30], while FedRep [20] splits the backbone into a global representation and a client-specific head, enabling personalized finetuning.\n1) FedRep: FedRep [20] learns a shared global represen- tation using the Method of Moments. Each client then fine- tunes its local head with its own data. The local heads are aggregated to update the global representation, and this process is repeated over multiple epochs. By using a shared global representation and allowing for individual finetuning, FedRep balances capturing common features and accommodating personalized models.\nInitially, FedRep learns a representation through the Method of Moments. In each communication round, a subset of clients updates their local head and the global representation by sampling fresh batches from their local distributions. The server updates the global representation by averaging the updated heads from clients, weighted by the number of samples used in each update. This client-server update process is repeated for multiple epochs. The loss function in FedRep is a weighted sum of the losses over a representative subset of samples:\n$L_i(w) = \\sum_{x_j \\in D_i} w_{i,j} l(w, x_j, y_j)$  (2)\nwhere $D_i$ is the representative subset from client i, $w_{i,j}$ is the weight of sample j from client i, l is the loss function, w are the model parameters, $x_j$ is the input sample, and $y_j$ is the label. The weight for each sample is:\n$w_{i,j} = \\frac{p(x_j)}{K n_i}$  (3)\nwhere p(x) is the probability of sample j, K is a normal- ization constant, and ni is the size of the subset for client i. The global model update is:\n$w_{t+1} = \\frac{\\sum_{i=1}^{m} n_i w_t^i}{\\sum_{i=1}^{m} n_i}$ (4)\nwhere $w_t^{loc,i}$ is client i's local model update at iteration t. FedRep allows for more local updates per client by reducing the problem dimension with a shared representation. This leads to improved individual model accuracy and robustness to statistical heterogeneity among clients. However, FedRep may not be ideal for highly specialized tasks requiring unique features, potentially resulting in suboptimal performance.\n2) FED-ROD: Federated Robust Decoupling (FED-ROD) [21] bridges the gap between global and personalized models for image classification tasks. It decouples the prediction task into two parts: a generic predictor trained on a large, diverse dataset shared by all clients, and a personalized predictor trained on each client's local data. FED-ROD achieves this by introducing a family of losses that are robust to non-identical class distributions, enabling clients to train a generic predictor with a consistent objective. Additionally, FED-ROD formulates the personalized predictor as an adaptive module that minimizes each client's empirical risk on top of the generic predictor.\nOne of the key advantages of FED-ROD is its ability to simultaneously achieve state-of-the-art performance in both generic and personalized FL tasks. By training a generic predictor with a consistent objective, FED-ROD improves the accuracy of the generic predictor and reduces the amount of data required for personalized training. The framework also offers flexibility and efficiency, as it can be integrated into existing FL systems and is compatible with a wide range of algorithms. The framework also includes a balanced risk minimization algorithm that encourages the local models to classify all classes well, which can improve the accuracy of the generic model and reduce the amount of data needed for personalized training.\nAlso, FED-ROD's adaptive module, which can be imple- mented as a linear or hypernetwork, allows for fast adaptation to new clients, further enhancing the performance of person- alized models. However, the hypernetwork implementation of the adaptive module may require additional training and computation compared to the linear implementation.\n3) FedBABU: FedBABU [22] decouples the model parame- ters into the body and head parameters and only updates the body parameters during FL. The fixed random head can be shared across all clients, and the body is personalized to each client during the evaluation process by fine-tuning the head. Therefore, FedBABU learns local models with personalized aggregation by fine-tuning the head on each client's data to achieve personalization. During local updates, only the body parameters are trained using a randomly initialized head, while the head remains fixed throughout the federated training process. This design eliminates the need to aggregate the head and allows for more efficient communication and computation. The fixed random head can deliver comparable performance to a learned head in centralized settings. FedBABU further enables rapid personalization of the global model by fine-tuning the body of each client's data using the fixed random head.\nOne of the key advantages of FedBABU is its ability to reduce communication overhead and improve training efficiency. By focusing updates solely on the body parameters and sharing a fixed random head, the algorithm minimizes the information exchanged between clients and the server. This reduction in communication leads to faster training and lower resource requirements. On the other side, as the head remains fixed throughout training, there is limited room for personalized optimization of the head on a per-client basis. Some clients may benefit from a customized head, but FedBABU's fixed random head approach restricts personalization.\nTakeaway:\nFinetuning methods start with a shared global model, then personalize it through local finetuning. This balances collab-"}, {"title": "B. Methods that learn additional personalized models", "content": "Another avenue explores methods that learn additional personalized models. pFedMe [31] adopts Moreau envelopes to learn personalized models for each client, whereas Ditto lets clients learn their personalized models through a proximal term that fetches information from the global model.\n1) Ditto: In Ditto [23], each device trains a personalized model using its local data and the global model as initialization. The resulting personalized models are used alongside the global model for predictions. These personalized models are regularized towards the optimal global model, balancing the trade-off between global and personalized objectives.\nDitto optimizes a global model and personalized models for each device in a statistically heterogeneous network. The optimization problem aims to minimize the global objective function, G(w), which represents the regularized empirical risk minimization problem, and the personalized objective function, $H_k(v_k; w)$, which captures the local data distribution of each device. The trade-off between global and personal- ized objectives is controlled by the hyperparameter \u03bb. The optimization process uses an alternating algorithm where the global model is updated by aggregating the personalized models from all devices, and the personalized models are updated by minimizing the local objective function on each device. Ditto offers several advantages, including capturing statistical heterogeneity, balancing the trade-off between global and personalized objectives, and providing fairness, robustness, scalability, and flexibility in model selection.\n$\\min_{v_k} h_k(v_k; w*) := \\mathbb{F}_k(v_k) + \\frac{\\lambda}{2} ||v_k - w*||^2$ (5)\ns.t. $w* \\in arg \\min_w G(F_1(w), ..., F_K(w))$ (6)\nDitto begins by initializing the global model and personalized models. The global model is then communicated to all devices, which train their personalized models using their local data and the global model as initialization. The personalized models are sent back to the server for aggregation. This communication and aggregation process is repeated for multiple rounds until convergence or a stopping criterion is met. Throughout the iterations, the alternating optimization algorithm updates the global model and personalized models, balancing objectives. One advantage of Ditto is its ability to capture the statistical heterogeneity of each device's data distribution. The personal- ized models offer better accuracy and generalization compared to homogeneous approaches. Another advantage is the reg- ularization term, which encourages the personalized models to be close to the optimal global model. This regularization strikes a balance between global and personalized objectives, ensuring consistency while accounting for local variations. Ditto also provides fairness and robustness by mitigating tensions between these constraints. However, Ditto has some drawbacks, including the communication and computation resources re- quired to train and update the personalized models, which may increase the communication overhead and computational cost. Additionally, the optimal value of the hyperparameter \u03bb may be sensitive to the specific dataset and task.\n2) FedPer: FedPer [24] addresses the challenge of statistical heterogeneity in non-identical data partitions by training a shared base model on the server and personalizing it for each client using client-specific parameters. This personalization is achieved through the addition of personalized layers to the base model, allowing it to capture client-specific features.\nThe algorithm consists of two phases: global aggregation phase and local update phase. In the global aggregation phase, the server aggregates the model updates from the clients using a federated averaging approach. In the local update phase, each client updates its base and personalized layers locally using a stochastic gradient descent (SGD) style algorithm. The personalization layers capture the client-specific features, which can improve the accuracy of the model for each client. The FedPer algorithm uses a loss function that combines global loss and local loss for each client. The global loss ensures that the global model is aligned with the overall dataset, while the local loss ensures that the local models capture the nuances of each client's data. Mathematically, the FedPer loss function is:\n$L(\\theta) = \\sum_{k=1}^{K} W_kL_k(\\theta) + \\lambda R(\\theta)$  (7)\nwhere $\\theta$ represents the model parameters, K is the number of clients, $w_k$ is the weight assigned to client k, $L_k(\\theta)$ is the local loss for client k, $R(\\theta)$ is a regularization term, and $\\lambda$ is the regularization parameter.\nBy incorporating personalized layers, FedPer can capture client-specific characteristics, leading to more accurate models for individual clients. The approach is also versatile and can be applied to various deep-learning model families and datasets, as demonstrated by the authors. However, FedPer has some limitations. It requires a large number of clients to be effective since the personalization layers are trained on a per-client basis.\nTakeaway:\nMethods that learn personalized algorithms maintain both global and client-specific models. This dual-model approach offers flexibility in capturing client nuances while leveraging collective knowledge, making it well-suited for applications with significant data heterogeneity across clients."}, {"title": "C. Methods that learn local models with personalized (local) aggregation.", "content": "Recent research also investigates methods that aim to capture personalization by generating client-specific models through personalized aggregation, contributing to better local models with personalized elements.\n1) FedFomo: Instead of learning a single global model or generating additional personalized models, FedFomo [25] learns local models on each client's data. The personalized aggregation step allows for the computation of personalized weighted combinations of the models, resulting in stronger models tailored to the individual client's objectives. By prioritizing personalization and leveraging locally trained models, FedFomo distinguishes itself within the field of FL.\nFedFomo aims to optimize models for individual client objectives. Unlike traditional FL methods, FedFomo does not compute a single global model. Instead, it introduces two new steps: (1) ranking the models based on their suitability towards the client's objective, and (2) computing personalized weighted combinations of the downloaded models. This approach allows each client to obtain a stronger personalized model.\nFedFomo learns optimal combinations of the available server models for each participating client. For this client, information is leveraged in two ways. First, the aim is to optimize directly for each client's target objective. It assumes that clients can distinguish between good and bad models on their target tasks through a labeled validation data split $D^{val} \\subset D_i$ into the client's local data. The client can then evaluate any arbitrary model $\\theta_j$ on this validation set and quantify the performance through the computed loss, denoted by $L_i(\\theta_j)$.\nSecond, they directly leverage the potential heterogeneity among client models, similar to [32], where they show that diverging model weights come directly from local data heterogeneity. However, instead of combining these parameters into a single global model, uploaded models are maintained individually to preserve a model's potential contribution to another client. These ideas enable clients to optimize data distributions different from their own local data.\nOne of the key advantages of FedFomo is its emphasis on personalization. By allowing clients to optimize their models for their own specific objectives, FedFomo produces stronger and more effective models that are tailored to individual needs. However, the introduction of two additional steps in the traditional FL process increases the complexity of the framework. This complexity may require additional resources and expertise to implement and manage effectively.\n2) FedBN: FedBN [26] trains individual local models on each client using their own data and local BN parameters. The personalized (local) aggregation scheme at the server preserves the local data distribution while combining the models. FedBN achieves this by maintaining independent BN parameters, which effectively mitigate feature shifts and enhance the convergence behavior and performance on non-IID datasets.\nThe main difference between FedBN and FedAvg is that FedBN uses local batch normalization (BN) to mitigate feature shifts in non-IID data. However, in traditional FL, the local BN parameters are synchronized with the global model, which can lead to feature shifts in non-IID data. In FedBN, the local BN parameters are not synchronized with the global model, which helps to preserve the local data distribution and mitigate feature shifts. Another difference is that FedBN is independent of the communication and aggregation strategy and can be combined with different optimization algorithms, communication schemes, and aggregation techniques. In contrast, FedAvg is based on a specific communication and aggregation strategy, where the server aggregates client updates using simple averaging.\nThe advantage of FedBN is its compatibility with existing FL toolkits and systems. Being a lightweight modification to FedAvg, it can be easily integrated into various optimization al- gorithms, communication schemes, and aggregation techniques. However, FedBN does have certain limitations. It assumes that local models have BN layers, which may not always be the"}, {"title": "IV. EVALUATION", "content": "A. Evaluation Questions\nWe show the metrics evaluated in the original papers of these pFL works. All of the original papers on these pFL methods use different metrics and datasets as shown in Table II. This highlights a lack of a standard benchmark for comparative evaluation of these techniques. Therefore, we use a standard benchmark with same datasets and metrics in controlled settings to answer the following research questions:\nQ1: How do the different categories of personalized FL methods compare in terms of performance and speed?\nQ2: Which algorithms are most and least memory-intensive?\nQ3: Which algorithm stands out as top performer, and why?\nQ4: What are the accuracy-memory overhead tradeoffs among personalized FL algorithms?\nB. Evaluation Metrics\n\u2022 Accuracy (Acc): Accuracy measures the proportion of correctly predicted labels by the model at convergence. It indicates how well the model adapts to each client's data while maintaining global performance.\n\u2022 AUC (AUC): The Area Under the Curve (AUC) at convergence evaluates the model's performance based on the ROC curve, which illustrates the trade-off between a true positive rate and a false positive rate. This metric is significant in personalized FL because it allows us to assess the model's ability to handle imbalanced data which is the case for non-IID distribution.\n\u2022 Communications Rounds Required for Convergence ($R_{Conv}$): The number of communication rounds required for convergence indicates the efficiency of the personalized FL algorithm. Reducing this number is important to minimize communication overhead and enhance overall FL efficiency.\n\u2022 Time Taken for Convergence ($T_{conv}$): The time taken for the personalized FL model to converge is a metric that highlights the speed at which the model adapts to local client data while achieving a globally acceptable performance level. Faster convergence is an advantage in personalized FL.\n\u2022 Time Taken to Complete 200 Rounds($T_{200}$): The time taken to complete the 200 communication rounds. This offers insight into the overall computational efficiency of the personalized FL system.\n\u2022 Memory: Memory usage indicates the memory require- ments of the algorithm during execution. Personalized FL systems deal with multiple clients, each with their data and local models, which can lead to significant memory consumption. Understanding memory usage helps in resource management and scalability of the FL system.\nC. Experimental Settings\nWe use MNIST and FMNIST datasets which have 28\u00d728 size. To simulate a realistic scenario in a distributed environ- ment, we split the data among 20 users using the Dirichlet distribution. The joining ratio was set to 5, meaning only 5 out of the 20 users participated in each round of FL. The learning rate was set to 0.05, and the threshold time for clients to communicate with the aggregator was set to 500 seconds. We adopted the hyperparameters from the original papers to ensure consistency and comparability of our results.\nD. Experimental Results\nThe results for two baselines and ten pFL techniques for MNIST (DS-1), MNIST (DS-2), FMNIST (DS-1), and FMNIST (DS-2) are presented in Table IV, Table V, Table VI, and Table VII respectively. The best result for each metric is highlighted in bold."}, {"title": "V. PFL: NEW OPPORTUNITIES AND CHALLENGES", "content": "Several promising research directions could advance person- alized Federated Learning (pFL):\n1. Convergence Analysis of pFL on Saddle Point Functions: Investigate how personalized strategies impact the convergence speed and stability of pFL algorithms with saddle point functions, building on [33] and [34].\n2. Incentive Mechanism Design for Personalized FL: Develop mechanisms to encourage participation in decentralized pFL, balancing incentives with privacy and security, as explored by [35]'s token-based system. Research should assess the impact on engagement and performance.\n3. Personalization Strategies in Federated Bandits: Incorpo- rate personalized strategies into federated bandits, such as linear contextual bandits, to improve exploration and exploitation efficiency across diverse client contexts [36], [37].\n4. Hybrid Approaches for pFL: Explore combining pFL with transfer learning, meta-learning, or reinforcement learn- ing to enhance model adaptation and generalization across applications.\n5. Real-World Dataset Creation and Evaluation: Develop diverse, large-scale datasets reflecting real-world heterogeneity for evaluating privacy-preserving pFL, especially for textual data under multiple attacks."}, {"title": "VI. CONCLUSION", "content": "In conclusion, this paper presents a comprehensive analysis of pFL techniques, addressing key challenges such as non- i.i.d data and model performance. By evaluating ten pFL methods across various metrics\u2014including convergence speed, memory overhead, and accuracy\u2014our study offers a nuanced understanding of their practical implications. Our analysis highlights significant trends and trade-offs, providing valuable insights for selecting the most suitable pFL algorithms for different applications, ultimately guiding future research and practical implementations in fields like healthcare and finance."}]}