{"title": "Lost in Sequence: Do Large Language Models Understand Sequential Recommendation?", "authors": ["Sein Kim", "Hongseok Kang", "Jiwan Kim", "Donghyun Kim", "Kibum Kim", "Minchul Yang", "Kwangjin Oh", "Julian McAuley", "Chanyoung Park"], "abstract": "Large Language Models (LLMs) have recently emerged as promising tools for recommendation thanks to their advanced textual understanding ability and context-awareness. Despite the current practice of training and evaluating LLM-based recommendation (LLM4Rec) models under a sequential recommendation scenario, we found that whether these models understand the sequential information inherent in users' item interaction sequences has been largely overlooked. In this paper, we first demonstrate through a series of experiments that existing LLM4Rec models do not fully capture sequential information both during training and inference. Then, we propose a simple yet effective LLM-based sequential recommender, called LLM-SRec, a method that enhances the integration of sequential information into LLMs by distilling the user representations extracted from a pre-trained CF-SRec model into LLMs. Our extensive experiments show that LLM-SRec enhances LLMs' ability to understand users' item interaction sequences, ultimately leading to improved recommendation performance. Furthermore, unlike existing LLM4Rec models that require fine-tuning of LLMs, LLM-SRec achieves state-of-the-art performance by training only a few lightweight MLPs, highlighting its practicality in real-world applications.", "sections": [{"title": "1 INTRODUCTION", "content": "Early efforts in LLM-based recommendation (LLM4Rec), such as TALLRec [2], highlighted a gap between the capabilities of LLMs in text generation and sequential recommendation tasks, and proposed to address the gap by fine-tuning LLMs for sequential recommendation tasks using LoRA [11]. Subsequent studies, including LLARA [21], COLLM [40], and A-LLMRec [14], criticized the exclusive reliance of TALLRec on textual modalities, which rather limited its recommendation performance in warm scenarios (i.e., recommendation scenarios with abundant user-item interactions) [14, 40]. These methods transform item interaction sequences into text and provide them as prompts to LLMs [21] or align LLMs with a pre-trained Collaborative filtering-based sequential recommender (CF-SRec), such as SASRec [12], to incorporate the collaborative knowledge into LLMs [14].\nDespite the current practice of training and evaluating LLM4Rec models under a sequential recommendation scenario, we found that whether these models understand the sequential information inherent in users' item interaction sequences has been largely overlooked. Hence, in this paper, we begin by conducting a series of experiments that are designed to investigate the ability of existing LLM4Rec models in understanding users' item interaction sequences (Sec. 2.3). More precisely, we compare four different LLM4Rec models (i.e., TALLRec, LLaRA, COLLM, and A-LLMRec) with a CF-SRec model (i.e., SASRec). Our experimental results reveal surprising findings as follows:\n(1) Training and Inference with Shuffled Sequences: Randomly shuffling the order of items within a user's item interaction sequence breaks the sequential dependencies among items [16, 35]. Hence, we hypothesize that the performance of models that understand the sequential information inherent in a user's item interaction sequence would deteriorate when the sequence is disrupted. To investigate this, we conduct experiments under two different settings. First, we compare the performance of models that have been trained on the original sequences (i.e., non-shuffled sequences) and those trained on randomly shuffled"}, {"title": "2 DO EXISTING LLM4REC MODELS UNDERSTAND SEQUENCES?", "content": null}, {"title": "2.1 Preliminaries", "content": null}, {"title": "2.1.1 Definition of Sequential Recommendation in CF-SRec.", "content": "Let U = {U1, U2, ..., u|u|} represent the set of users, and I = {i1, i2, . . ., i|1|} represent the set of items. For a user u \u2208 U, Su = (i(u),..., i(u), , inu)) denotes the item interaction sequence, where iu) \u2208 I is the item that u interacted with at time step t, and nu is the length of user u's item interaction sequence. Given the interaction history Su of user u, the goal of sequential recommendation is to predict the next item that user u will interact with at time step nu + 1 as p(inu+1 | Su)."}, {"title": "2.1.2 LLM for Sequential Recommendation.", "content": "Note that existing LLM4Rec models can be largely categorized into the following two approaches: Generative Approach (i.e., Next Item Title Generation) [10, 14, 21] and Retrieval Approach (i.e., Next Item Retrieval) [5, 20]. In the Next Item Title Generation approach, a user's item interaction sequence and a list of candidate items are provided as input prompts to LLMs after which the LLMs generate one of the candidate item titles as a recommendation. Meanwhile, the Next Item Retrieval approach extracts user and candidate item representations from the LLMs and retrieves one of the candidate items whose similarity with the user representation is the highest. Note that although existing LLM4Rec models have typically been proposed based on only one of the two approaches, we apply both approaches to each LLM4Rec baseline to conduct more comprehensive analyses on whether existing LLM4Rec models understand the sequential information inherent in users' item interaction sequences.\n1) Generative Approach (Next Item Title Generation). LLM4Rec models designed for Next Item Title Generation perform recommendations using instruction-based prompts as shown in Table 1. For a user u, the candidate item set of user u is represented as Cu = [;(u)\nUNu, where Nu = RandomSample(I\\(Su\u222a{inu+1}), m) is\nnu+1\na negative item set for user u, and m = |Nu| is the number of negative items. Based on the item interaction sequence of user u, i.e., Su, and the candidate item set, i.e., Cu, we write the input prompt Pu following the format shown in Table 1. Note that we introduce two projection layers, i.e., fr and fu, each of which is used to project item embeddings and user representations extracted from a pre-trained CF-SRec into LLMs, respectively. Following the completed prompts shown in Table 1, LLMs are trained for the sequential recommendation task through the Next Item Title Generation approach. Note that TALLRec, LLaRA, and CoLLM use LORA [11] to finetune LLMs aiming at learning the sequential recommendation task, while A-LLMRec only trains fr and fu without finetuning the LLMs with LoRA. Please refer to the Appendix B.1. for more details on the projection layers as well as prompt construction.\n2) Retrieval Approach (Next Item Retrieval). As shown in Table 2, we use Pu, and Pi to denote prompts for users and items, respectively. Unlike the Next Item Title Generation approach where"}, {"title": "2.2 Evaluation Protocol", "content": "In our experiments on LLMs' sequence comprehension, we employed the leave-last-out evaluation method (i.e., next item recommendation task) [12, 28, 30]. For each user, we reserved the last item in their behavior sequence as the test data, used the second-to-last item as the validation set, and utilized the remaining items for training. The candidate item set (i.e., test set) for each user in the title generation task is generated by randomly selecting 19 non-interacted items along with 1 positive item following existing studies [14, 40]. Similarly, for the next item retrieval task, we randomly select 99 non-interacted items along with 1 positive item as the candidate item set (i.e., test set) for each user."}, {"title": "2.3 Preliminary Analysis", "content": "In this section, we conduct experiments to investigate the ability of LLM4Rec in understanding users' item interaction sequences by comparing four different LLM4Rec models (i.e., TALLRec, LLaRA, COLLM, and A-LLMRec)2 with a CF-SRec model (i.e., SASRec). Note that our experiments are designed based on the assumption that randomly shuffling the order of items within a user's item interaction sequence breaks the sequential dependencies among items [16, 35]. More precisely, we conduct the following two experiments: 1) Training (Sec. 2.3.1) and Inference (Sec. 2.3.2) with shuffled sequences, and 2) Representation Similarity (Sec. 2.3.3). In the following, we describe details regarding the experimental setup and experimental results."}, {"title": "2.3.1 Shuffled Training.", "content": "We hypothesize that the performance of models trained on sequences in which meaningful sequential information is removed would deteriorate when evaluated on sequences in which sequential information is present (i.e., non-shuffled"}, {"title": "2.3.2 Shuffled Inference.", "content": "We hypothesize that the performance of models that understand the sequential information inherent in a user's item interaction sequence would deteriorate when the sequence is disrupted. To investigate this, we perform inference using shuffled test sequences with the models that have been trained using the original sequences Su (i.e., non-shuffled sequence). That is, unlike in Sec. 2.3.1, we shuffle the test sequences during inference rather than training sequences. It is important to note that the assumption of this experiment is that models trained with the original sequences indeed capture the sequential information."}, {"title": "2.3.3 Representation Similarity", "content": "In LLM4Rec models as well as in SASRec, representations of users are generated based on their item interaction sequences. Hence, we hypothesize that the user representations obtained from models that capture sequential information in a user's item interaction sequence would change when the input sequence is disrupted. To investigate this, we compute the cosine similarity between user representations obtained based on the original sequences and those obtained based on shuffled sequences during inference.\nAs shown in Table 5, we observe that the similarity is much higher for LLM4Rec models compared with that of CF-SRec, i.e., SASRec, indicating that LLM4Rec models are less effective than CF-SRec in capturing and reflecting changes in users' item interaction sequences. It is worth noting that among LLM4Rec models, CoLLM and A-LLMRec exhibit relatively low similarity. This is attributed to the fact that they utilize user representations extracted from a pre-trained CF-SRec in their prompts, unlike TALLRec which only uses text, or LLaRA which uses text and item embeddings. This implies that incorporating user representations enhances the ability to effectively model sequential information. However, COLLM and A-LLMRec still exhibit higher similarity values compared to SASRec, and based on the results of previous experiments (i.e., Sec. 2.3.1 and Sec. 2.3.2, it is evident that they have yet to fully comprehend the sequential patterns."}, {"title": "3 METHODOLOGY: LLM-SREC", "content": "In this section, we propose LLM-SRec, a novel and simplistic LLM4Rec framework designed to enable LLMs to effectively utilize sequential information inherent in users' item interaction sequences. It is important to note that among the two prominent approaches for LLM4Rec, we employ the Next Item Retrieval approach (i.e., LLM-SRec is trained with Equation 1) due to well-known drawbacks of the Next Item Title Generation approach, i.e. restrictions on the number of candidate items [14] and the existence of position bias with candidate items [10]. In the following, we explain two additional losses aiming at: (1) distilling the sequential information extracted from a pre-trained CF-SRec to LLMs (Sec. 3.1), and (2) preventing the over-smoothing problem during distillation (Sec. 3.2)."}, {"title": "3.1 Distilling Sequential Information", "content": "User representations from CF-SRec, derived solely from users' item interaction sequences, encapsulate rich sequential information crucial for sequential recommendation tasks. Despite the efforts of COLLM and A-LLMRec trying to understand the sequential information by incorporating the user representations directly into LLM prompts, we observe that they still fail to do so (as shown in Sec. 2). Therefore, in this paper, we propose a simple alternative approach to effectively incorporating the sequential information extracted from CF-SRec into LLMs. The main idea is to distill the sequential knowledge from pre-trained and frozen CF-SRec into LLMs. More precisely, we simply match the user representation generated by a pre-trained CF-SRec, i.e., Ou = CF-SRec(Su) \u2208 Rd, and that generated by LLMs, i.e., h\", as follows:\nLDistill = E [MSE(fCF-user (Ou), fuser (hay))] (2)\nwhere MSE is the mean squared error loss and both fCF-user and fuser are 2-layer MLPs, i.e., fCF-user : Rd \u2192 Rd' and fuser : Rd\u0131\u0131m \u2192 Rd', that are trainable. This simple distillation framework enables LLMs to generate user representations that effectively capture and reflect the sequential information inherent in users' item interaction sequences. The prompt used in LLM-SRec is provided in Table 2, where user representations are derived from LLMs based on interacted item titles and collaborative information. In Appendix F.2, we empirically compare our prompt with another prompt that explicitly incorporates user representations, i.e., CoLLM and A-LLMRec, demonstrating the effectiveness of LLM-SRec despite the absence of user representation in the prompt. Additionally, Appendix F.3, we conducted experiments using a contrastive learning approach as an objective for distillation instead of the MSE loss.\""}, {"title": "3.2 Preventing Over-smoothing", "content": "Simply applying an MSE loss for distillation as in Equation 2 can lead to the over-smoothing problem, i.e., two representations are highly similar, hindering LLMs from effectively learning sequential information. In extreme cases, fuser and fCF-user could be trained to produce identical outputs [14, 32]. To mitigate this over-smoothing problem, we introduce a uniformity loss [32-34] as follows:\nLUniform =\nEIE [e-2l|lfCF-user (Ou)-fCF-user (Ou')||]]\nUEU u'EU\n+ E[E [e-2llfuser (h) - fuser (h)||]] (3)\nUEU u'EU\nThe uniformity loss LUniform ensures that user representations of different users are uniformly distributed across the normalized feature space on the hypersphere, preserving both separation and informativeness. In Appendix F.4, we measure the pairwise distances between all user representations to validate the effectiveness of LUniform in mitigating the over-smoothing problem.\nFinal objective. The final objective of LLM-SRec is computed as the sum of the Next Item Retrieval loss (Equation 1), the distillation loss (Equation 2), and the uniformity loss (Equation 3) as follows:\nL = LRetrieval + LDistill + LUniform (4)\nIt is important to note that LLM-SRec does not require any additional training for either the pre-trained CF-SRec or LLMs during its training process. Instead, LLM-SRec only optimizes a small set of MLP layers (i.e., fr, fuser, fCF-user, and fitem) and two LLM tokens (i.e., [UserOut] and [ItemOut]). Therefore, LLM-SRec achieves faster training and inference time compared to existing LLM4Rec baselines, including TALLRec, LLaRA, COLLM, and A-LLMRec, results are described in Sec. 4.3.1. Furthermore, for training efficiency, we only consider the last item in Su for each user u to minimize Equation 4 [14]. That is, for each user u, we predict the last item inu) given the sequence (i(u), ..., i(u), ..., i(u)\u2081). In Appendix F.5,\nit we also show the results when considering all items, i.e., auto-regressive learning.\nDiscussion on the Efficiency of LLM-SRec. Last but not least, unlike existing LLM4Rec models such as TALLRec, LLaRA, and"}, {"title": "4 EXPERIMENTS", "content": "Datasets. We conduct experiments on four Amazon datasets [9], i.e., Movies, Scientific, Electronics, and CDs. Following prior studies [12, 28], we use five-core datasets consisting of users and items with a minimum of five interactions each. The statistics for each dataset after preprocessing are summarized in Table 10 in Appendix C.\nBaselines. We compare three groups of models as our baselines: models that use only interaction sequences (CF-SRec: GRU4Rec [8], BERT4Rec [28], NextItNet [38], SASRec [12]), Language Model based models (LM-based: CTRL [19], RECFORMER [18]), and Large Language Model based models (LLM4Rec: TALLRec [2], LLaRA [21], COLLM [40], A-LLMRec [14]). For fair comparisons, we implemented all LLM4Rec baselines with Next Item Retrieval approach. Details regarding the baselines are provided in Appendix D.\nEvaluation Protocol. We employ the leave-last-out strategy [12] for evaluation, where the most recent item in the user interaction sequence is used as the test item, the second most recent item as the validation item, and the remaining sequence for training. To evaluate the performance of sequential recommendation, we add 99 randomly selected non-interacted items to the test set, ensuring that each user's test set consists of one positive item and 99 negative items. Evaluation is conducted using two widely adopted metrics: Normalized Discounted Cumulative Gain (NDCG@N) and Hit Ratio (HR@N), with N set to 10 and 20.\nImplementation Details. For fair comparisons, we adopt pre-trained LLaMA 3.2 (3B-Instruct) as the backbone LLM for all LLM4Rec baselines (i.e., TALLRec, COLLM, LLaRA, and A-LLMRec) including LLM-SRec. Similarly, SASRec serves as the pre-trained CF-SRec for COLLM, LLaRA, A-LLMRec, and LLM-SRec. Please refer to the Appendix E for more details regarding the hyper-parameters and train settings."}, {"title": "4.1 Recommendation Performance Comparison", "content": null}, {"title": "4.1.1 Overall performance.", "content": "Table 6 presents the recommendation performance of LLM-SRec and baselines on four datasets. From the results, we have the following observations: 1) LLM-SRec consistently outperforms existing LLM4Rec models. This result highlights the importance of distilling the sequential knowledge extracted from CF-SRec into LLMs. 2) LLM-SRec outperforms CF-SRec based and LM-based models, suggesting that the reasoning ability and the pre-trained knowledge of LLMs significantly contribute to recommendation performance. 3) LLM4Rec models that utilize CF-SRec in their framework (i.e., LLaRA, COLLM, and A-LLMRec) outperform TALLRec while being comparable to their CF-SRec backbone, i.e., SASRec. This indicates that while incorporating the CF knowledge extracted from a pre-trained CF-SRec is somewhat helpful, the lack of sequence understanding ability limits further improvements, even when using the LLMs. In summary, these findings emphasize the significance of seamless distillation of the sequential"}, {"title": "4.1.2 Transition & Non-Transition Sequences.", "content": "To examine how the degree of sequential information contained in users' item interaction sequences influences the model performance, we categorized users based on the degree of sequential transitions in their interaction history\u00b3. We make the following observations from Figure 3. 1) LLM-SRec outperforms all baselines, especially in the Transition Set, where sequential information is more abundant. This demonstrates that the distillation of sequence information enables the LLMs to comprehend and utilize sequential information inherent in users' interaction sequences. 2) The performance gap between LLM4Rec baselines and LLM-SRec is smaller in the Non-Transition Set compared with the Transition Set. This indicates that existing LLM4Rec models lack the capability to effectively capture sequential dependencies among items and further emphasizes the importance of effective sequential modeling."}, {"title": "4.1.3 Performance under Warm/Cold Scenarios.", "content": "In this section, we conduct experiments to examine how LLM-SRec performs in both warm and cold item settings. Following the experimental setup of A-LLMRec [14], items are labeled as 'warm' if they belong to the top 35% in terms of the number of interactions with users, while those in the bottom 35% are labeled as 'cold' items. We have the following observations in Figure 4: 1) LLM-SRec consistently achieves superior performance in both warm and cold scenarios, benefiting from its ability to capture the sequential information within item interaction sequences. Additionally, the performance in the cold setting shows that LLM-SRec effectively leverages the generalizability of LLMs, utilizing pre-trained knowledge and textual understanding even though there is insufficient collaborative knowledge for cold items. 2) TALLRec, which relies solely on textual information, performs inferior in warm settings than LLM4Rec baselines (i.e., LLaRA, COLLM, and A-LLMRec) that incorporate collaborative knowledge from CF-SRec. However, these models still underperform compared to LLM-SRec, highlighting the necessity of modeling both collaborative and sequential information for effective LLM-based recommendation. 3) As expected, SASRec particularly struggles for cold items due to its exclusive reliance on the user-item interaction data. In contrast, LLM4Rec models, especially LLM-SRec, leverage item textual information to mitigate the scarcity of interactions."}, {"title": "4.1.4 Performance under Cross-domain Scenarios.", "content": "To further verify the generalizability of LLM-SRec, we evaluate LLM-SRec on the cross-domain scenarios, following the setting of A-LLMRec [14], where the models are evaluated on datasets that have not"}, {"title": "4.2 Ablation Studies", "content": "In this section, we evaluate the contribution of each component LLM-SRec. To analyze not only the contribution of each component in terms of the final performance but also its impact on the sequence understanding ability, we conduct experiments under the setting described in Sec. 2.3.1. In other words, we compare the performance of training with the original sequences versus training with shuffled sequences. Table 7 presents the following observations: 1) When both LDistill and Luniform are present (i.e., vanilla LLM-SRec in row (c)), the model consistently achieves the highest performance on the original sequence due to the benefits of the sequence understanding ability. Furthermore, compared with its variants (i.e., row (c) vs (a,b)), the performance of the vanilla LLM-SRec drops the most rapidly when shuffling is applied, ensuring that the vanilla LLM-SRec indeed comprehends and effectively utilizes sequential information. 2) In the absence of both LDistill and LUniform (i.e., row (a)), where the sequential knowledge extracted from CF-SRec is not distilled to the LLMs, the model exhibits the lowest performance on the original sequence. Additionally, even when random shuffling is applied, the performance drop is minor. This result suggests that the model lacks sequence understanding capability without LDistill and LUniform. 3) When only LUniform is removed, the model suffers from the over-smoothing problem as discussed in Sec. 3.2, leading to lower performance compared to LLM-SRec. However, since LDistill is still present, we observe a significant performance drop when applying random shuffling. This once more indicates that the model is endowed with the sequence understanding ability with LDistill.\nRemark. Recall that simply injecting item embeddings or user representations from CF-SRec into LLMs, as done in existing LLM4Rec models, is insufficient for effective sequence understanding as shown in Sec. 2.3. In contrast, our ablation studies validate the effectiveness of our simple approach of incorporating the sequential knowledge into LLMs."}, {"title": "4.3 Model analysis", "content": null}, {"title": "4.3.1 Train/Inference Efficiency.", "content": "Note that LLM-SRec is efficient as it does not require fine-tuning either CF-SRec or the LLM itself. To quantitatively analyze the model efficiency, we compare the training and inference time of LLM-SRec with LLM4Rec baselines (i.e., TALLRec, LLaRA, COLLM, and A-LLMRec). Specifically, we measure the training time per epoch and the total inference time on the Scientific and Electronics datasets. As shown in Table 9, LLM-SRec achieves significantly faster training and inference times than all baselines. This is mainly because baselines using Parameter-Efficient Fine-Tuning methods such as LoRA require"}, {"title": "4.3.2 Size of LLMs.", "content": "Note that all baseline LLM4Rec models including LLM-SRec use LLAMA 3.2 (3B-Instruct) as the backbone LLMs. In this section, to investigate the impact of LLM size on recommendation performance, we replace the backbone with larger LLMs, i.e., LLaMA 3.1 (8B) [1]. We have the following observations in Figure 5: 1) Replacing the backbone LLMs to larger LLMs greatly enhances the overall performance of LLM4Rec models. This aligns well with the scaling law of LLMs observed in other domains [13]. Moreover, the superior performance of LLM-SRec is still valid when the backbone is replaced to larger LLMs. 2) Surprisingly, LLM-SRec with the smaller backbone LLMs outperforms the baseline LLM4Rec models with the larger backbone LLMs. This indicates that distilling sequential information is more crucial than merely increasing the LLM size to enhance the overall performance of sequential recommendation, which again highlights the importance of equipping LLMs with sequential knowledge to improve the sequential recommendation capabilities of LLMs."}, {"title": "4.3.3 Case Study.", "content": "In this section, we conduct a case study on the Electronics dataset to qualitatively validate the benefit of sequential knowledge and LLMs' textual understanding. Figure 6 shows three cases highlighting the effect of sequential knowledge and textual knowledge on recommendation. The cases are categorized as follows: (a) only LLM-SRec provides correct recommendations, (b) LLM4Rec models (i.e., A-LLMRec and LLM-SRec) provide correct recommendations while SASRec fails, and (c) LLM-SRec and SASRec provide correct recommendations while an LLM4Rec (i.e., A-LLMRec) baseline fails. We have the following observations: 1) In case (a), the user's preference shifts from cable-related items to products from \"Apple\" brand. LLM-SRec correctly recommends \"Apple Pencil,\" while SASRec captures the changing preference but fails to recognize the textual information \"Apple,\" leading to a wrong recommendation of an \"Amazon Fire 7 Tablet.\" On the other hand, A-LLMRec, which struggles to capture sequential information, recommends \"Audio Cable\" based on textual knowledge of \"Cable\" and \"Speaker.\" This emphasizes the importance of leveraging both sequential and textual information. 2) In case (b), the user focused on \"BOSE\" brand products. Both LLM-SRec and A-LLMRec, leveraging textual knowledge, successfully recommended the \"BOSE\" earbuds, while SASRec, lacking textual information, recommended the \"SAMSUNG Galaxy Buds.\" This highlights the importance of textual knowledge in generating accurate recommendations. 3) In case (c), the user's preference shifts from \"Hosa Tech\" cables to security camera. LLM-SRec and SASRec capture this preference shift and provide relevant recommendations, while A-LLMRec recommends another \"Hosa Tech\" cable ignoring the sequential patterns. Those cases demonstrate that both textual and sequential information are crucial for accurate recommendations, showcasing the superiority of LLM-SRec in integrating both for improved performance. We have provided an additional case study in Appendix F.6."}, {"title": "5 RELATED WORK", "content": "Sequential Recommender Systems. Recommendation systems primarily focus on capturing collaborative filtering (CF) to identify similar items/users. Matrix Factorization-based approaches, achieved notable success by constructing CF knowledge in a latent space [3, 7, 24]. However, in conjunction with CF knowledge, understanding dynamic evolution in temporal user preferences has become a powerful tool, leading to the development of collaborative filtering-based sequential recommenders (CF-SRec) [8, 12, 15, 25, 28, 37]. Initial approaches combined Matrix Factorization with Markov Chains to model temporal dynamics [26]. Subsequently, neural network-based methods advanced sequential recommender systems, with GRU4Rec [8] leveraging recurrent architectures, while methods such as Caser [31] and NextItNet [38] adopted Convolutional Neural Networks [17]. More recently, models such as SASRec [38] and BERT4Rec [28], based on attention mechanisms, have demonstrated superior performance by focusing on the more relevant interaction sequences. These advancements underscore the importance of effectively modeling user behavior dynamics for improved recommendation accuracy.\nLLM-based Recommender Systems. LLMs have recently gained attention in recommendation systems [4, 6, 36, 39], leveraging their reasoning ability and textual understanding for novel approaches"}, {"title": "6 CONCLUSION", "content": "In this paper, we address a fundamental limitation of LLM4Rec models, i.e., their inability to capture sequential patterns, and empirically demonstrate this shortcoming through extensive experiments. To address the limitation, we propose a simple yet effective distillation framework, named LLM-SRec, which effectively transfers sequential knowledge extracted from CF-SRec into LLMs. By doing so, LLM-SRec enables LLMs to effectively capture sequential dependencies, leading to superior recommendation performance compared to existing CF-SRec, LM-based recommender systems, and LLM4Rec. Furthermore, LLM-SRec achieves high efficiency, as it does not require fine-tuning either CF-SRec or the LLM, demonstrating the effectiveness of our simple yet efficient architecture."}, {"title": "A ETHICS STATEMENT", "content": "To the best of our knowledge, this paper aligns with the KDD Code of Ethics without any ethical concerns. The datasets and codes employed in our research are publicly available."}, {"title": "B DETAILS OF LLM4REC PROMPT CONSTRUCTION", "content": "This section provides additional details on how to construct prompts for LLM4Rec models discussed in Sec. 2.1."}, {"title": "B.1 Next Item Title Generation", "content": "Based on the user interaction sequence Su and candidate set Cu of user u, the textual data for the interacted items and candidate items are defined as Ts\u2081\u2081 = {Text(i) | i \u2208 Su} and TC\u2081 = {Text(i) | i \u2208 Cu}, respectively, where Text(i) represents textual information (e.g., title or description) of item i.\nFor models such as LLaRA [21], COLLM [40], and A-LLMRec [14], which incorporate item embeddings and user representations from a pre-trained CF-SRec, we use E \u2208 R|I|\u00d7d to denote the item embedding matrix of the pre-trained CF-SRec, where d is the hidden dimension of the embeddings. We also define fr and fu as the item and user projection layers used in LLaRA, COLLM, and A-LLMRec (includes Stage-1 item encoder of A-LLMRec), respectively. The embeddings of items in the item interaction sequence Su are defined as Es\u2081 = {f1 (Ei) | i \u2208 Su}, while the embeddings for the candidate items Cu are represented as EC\u2081\u2081 = {f1 (Ei) | i \u2208 Cu}, where fr (Ei) \u2208 Rdium and dilm denotes the token embedding dimension of LLM. Furthermore, the user representation is defined as Zu = fu(CF-SRec(Su)) \u2208 Rdilm, where CF-SRec(Su) represents the user u's representation obtained from the item interaction sequence Su using a pre-trained CF-SRec. Then, using the prompts shown in Table 1, LLMs are trained for the sequential recommendation task through the Next Item Title Generation approach as follows:\np(Text(iu) 1) | Pu, Du) (5)\nwhere Pu is the input prompt for user u, and Du represents the set of interacted and candidate item titles and their corresponding embeddings used in Table 1 for user u as follows:\nTALLREC\nLLARA\n(TSu Tu Esu, EC, Zu COLLM/A-LLMRec\nDu Tsu Tou\nTS ESu\nI (6)"}, {"title": "B.2 Next Item Retrieval", "content": "Based on the prompt Pay and P in Table 2, we extract representation of user u \u2208 U, denoted hay and the embedding of item i \u2208 Cu, denoted has follows:\nh = LLM(Pay, D'\"),h\u00b2 = LLM(P), D'') (7)\nwhere Puy denotes the input prompt for user u to extract representation of user u, Pi denotes the input prompt for item i to extract embedding of item i, D'u denotes the set of interacted item titles and their corresponding embeddings for user u, while D'i denotes the item title and its embedding for candidate item i, as presented in Table 2, as follows:\nD'u =\nD'i =\nTALLREC\nLLARA\nTS ESu Zu CoLLM/A-LLMRec/LLM-SRec (8)\nThen, using the user representation hand item embedding hy, LLMs are trained for the sequential recommendation task through the Next Item Retrieval approach as follows:\np(inu+1 | Su) cs(u, i+1) = fitem (hnu+1) pu+1) fuser (ha)T (9)\nwhere fitem and fuser denote projection layers defined in Equation 2.\""}, {"title": "C DATASETS", "content": "Table 10 shows the statistics of the dataset after preprocessing."}, {"title": "D BASELINES", "content": "(1) Collaborative filtering based (CF-SRec)\n\u2022 GRU4Rec [8", "28": "utilizes bidirectional self-attention mechanisms and a masked item prediction objective to model complex user preferences from interaction sequences.\n\u2022 NextItNet [38", "12": "is a self-attention based recommender system designed to capture long-term user preference.\n(2) Language model based (LM-based)\n\u2022 CTRL [19", "23": "encoding models. And fine-tunes the backbone models for the recommendation task.\n\u2022 RECFORMER [18", "2": "fine-tunes LLMs for the recommendation task by formulating the recommendation task as a"}]}