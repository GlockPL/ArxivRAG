{"title": "3DMeshNet: A Three-Dimensional Differential Neural Network for Structured Mesh Generation", "authors": ["Jiaming Peng", "Xinhai Chen", "Jie Liu"], "abstract": "Mesh generation is a crucial step in numerical simulations, significantly impacting simulation accuracy and efficiency. However, generating meshes remains time-consuming and requires expensive computational resources. In this paper, we propose a novel method, 3DMeshNet, for three-dimensional structured mesh generation. The method embeds the meshing-related differential equations into the loss function of neural networks, formulating the meshing task as an unsupervised optimization problem. It takes geometric points as input to learn the potential mapping between parametric and computational domains. After suitable offline training, 3DMeshNet can efficiently output a three-dimensional structured mesh with a user-defined number of quadrilateral/hexahedral cells through the feed-forward neural prediction. To enhance training stability and accelerate convergence, we integrate loss function reweighting through weight adjustments and gradient projection alongside applying finite difference methods to streamline derivative computations in the loss. Experiments on different cases show that 3DMeshNet is robust and fast. It outperforms neural network-based methods and yields superior meshes compared to traditional mesh partitioning methods. 3DMeshNet significantly reduces training times by up to 85% compared to other neural network-based approaches and lowers meshing overhead by 4 to 8 times relative to traditional meshing methods.", "sections": [{"title": "I. INTRODUCTION", "content": "Numerical simulation has become increasingly important in various fields of natural science research, promoting the development of modern applied scientific research and engineering technology [1], [2]. These simulations typically require the use of meshes as a fundamental geometric framework to facilitate the analysis of physical phenomena via finite element methods or other numerical techniques. Mesh generation, defined as dividing a continuous computational domain into meshes or elements for further numerical solutions, is a critical step in engineering simulations [3]. The quality of the generated mesh has a significant impact on the accuracy of numerical simulations [4]. Given the significant impact of mesh quality on these aspects, the rapid generation of high-quality meshes has become a primary concern.\nStructured meshes are widely used in numerous simulations requiring precise element alignment for high-efficiency and high-precision [5]. They present multiple benefits: (1) Structured meshes do not require additional storage to connect mesh elements, resulting in higher efficiency in data access. (2) Their structured topological nature facilitates easy control over mesh cell sizes. (3) The regularity of their structure facilitates the implementation of convolutional and pooling operations in neural networks [6]. Motivated by these benefits, extensive research has been done on structured mesh generation [7], [8]. Algebraic methods calculate mesh interior points through algebraic interpolation, employing techniques like polynomial and Transfinite Interpolation (TFI) [9]. This approach is straightforward and enables rapid mesh generation. However, it can lead to mesh degradation in areas with complex geometries, resulting in issues such as intersections. To mitigate these problems, Partial Differential Equation (PDE) methods are commonly used to generate meshes for arbitrary boundaries [8]. Given the boundary values, PDE methods pose mesh generation as a boundary value problem governed by differential equations. Meshes created using PDE methods are of higher quality but require many computational resources and are time-consuming [10]. Thus, there is a significant demand for further research and development of a rapid and robust structured mesh generation method that balances speed and mesh quality.\nIn recent years, deep neural networks (DNNs) have achieved remarkable progress in fields such as flow-field prediction [11], mesh quality determination [3], and other physical problems [12]. A few methods have been developed to incorporate neural networks into mesh generation tasks. Jilani et al. [13] proposed a two-dimensional(2D) initial mesh generated based on a Self-organizing map neural network for finite element analysis and calculation of mesh self-adaptive parameters, followed by adaptive tuning of the initial mesh using the Self-organizing map neural network. Liu et al. [14] introduced the ISpliter method, combining neural networks with segmentation lines to transform B-rep geometrical shapes into unstructured meshes and facilitating neural network training through recursive data generation. Soman S [15] employed Conditional Generative Adversarial Networks to ascertain the coordinates of mesh nodes for generating 2D and three-dimensional (3D) unstructured meshes. However, these methods often rely on large training datasets, which can be costly and complex to obtain, particularly for geometries of intricate shapes. Methods like MGNet [8], which utilize unsupervised learning for mesh generation, address the challenge of extensive manual training data requirements but still encounter problems such as unstable convergence and long training times. Additionally, pioneer"}, {"title": "II. RELATED WORK", "content": "Structured meshes provide simplicity, making them widely used in numerous simulations that necessitate precise alignment of elements as dictated by analytical requirements [16]. The demand for precision has also stimulated the development of mesh generation methods [7], [8]. The methods for generating structured meshes include conformal mapping, algebraic methods, and PDE methods [17]. Algebraic methods typically employ various interpolation techniques or special functions for mesh creation [18]. Conformal mapping, which employs angle-preserving transformations derived from complex function theory, facilitates the generation of 2D meshes by altering the computational domain. However, expanding these methods to 3D mesh generation presents significant challenges. PDE methods, on the other hand, generate meshes by solving elliptic, parabolic, or hyperbolic equations within a specified transformation domain [19]. Although the algebraic method offers simplicity and rapid mesh creation, it may lead to mesh degradation in areas of complex geometry or cause mesh elements to overlap or breach boundaries. Structured meshes generated using the differential equation method are of high quality but require high computational effort.\nArtificial intelligence represented by neural networks has been vigorously developed in recent years [20], [21]. Neural networks can autonomously learn artificial experiences and fit objective functions from high-dimensional parameter spaces, and significant progress has been made in knowledge-based physical problems during the last several years [22], [23]. Obiols-Sales O et al. [11] proposed that CFD-Net combines physical simulation and deep learning in a coupled framework to accelerate the convergence of Reynolds Averaged Navier-Stokes simulations. Neural networks are also trained to learn the lift coefficients of airfoils with various shapes under different flow Mach numbers, Reynolds numbers, and diverse angles of attack [22]. Gholami et al. [23] used neural networks along with numerical simulation to estimate flow depth variables and velocity for typical cases such as a 60\u00b0 bend in a tube. The intelligent solution of PDEs has become increasingly prevalent and impactful in academic research. The PINNS designed by Raissi M [24] et al. employ a DNN to approximate the solutions of PDEs, embedding the residuals that govern the PDE and its initial/boundary conditions within the loss function. Various variants of PINNs have been proposed to enhance their accuracy and efficiency. CanPINN [25] combines automatic and numerical differentiation in PINNs to improve training efficiency and accuracy. Meanwhile, ATLPINNs [26] address the issues of low accuracy and non-convergence in original PINNs via auxiliary-task learning. These variants aim to strengthen PINN's performance in solving PDEs.\nIn addition to applying artificial intelligence in physics for solving PDEs, some researchers have explored incorporating artificial intelligence into mesh generation, mesh quality discrimination, and other areas to overcome the limitations of automation and intelligence in traditional mesh methods. Chen [3] presented a neural network-based mesh quality indicator for 3D cylinder meshes, along with a benchmark dataset. Wang [27] developed an algorithm to convert mesh data into graph data, subsequently introducing a deep graph neural network, GMeshNet, for mesh quality evaluation. MQENet [28] is introduced as a structured mesh quality evaluation network that leverages dynamic graph attention, treating mesh evaluation as a graph classification task. Yilmaz and Kuzuoglu [29] proposed a particle swarm optimization algorithm aimed at optimizing hexahedral mesh quality, addressing the inefficacies of the Laplace mesh smoothing algorithm in concave areas. Gargallo-Peir\u00f3 A [30] suggested an optimization method for triangular and quadrilateral meshes on parameterized surfaces, focusing on node relocation to enhance mesh quality and prevent element inversion. Data-driven approaches to mesh generation have seen various implementations. Lowther et al. [31] applied neural networks to mesh density prediction in finite element mesh adaptation, using density information provided by the neural network to determine the size and placement of elements. MeshingNet [32] leverages posterior"}, {"title": "III. 3DMESHNET: A THREE-DIMENSIONAL DIFFERENTIAL NEURAL NETWORK FOR STRUCTURED MESH GENERATION", "content": "The task of structured mesh generation involves the application of a potential mapping between parametric and computational domain to a given geometry. Typically, the parametric domain, represented by the coordinates $(\\xi,\\eta,\\zeta)$, is defined as a basic cube [0\u00d71]\u00d7[0\u00d71]\u00d7[0\u00d71], with each edge oriented either horizontally or vertically. The primary goal of any structured mesh generation technique is to create a mapping $(\\xi,\\eta,\\zeta)$ to $(x, y, z)$ between these two spaces. This mapping should be unique and smooth, ensuring that the resulting mesh accurately conforms to the geometry's boundaries that require discretization.\nIn numerical computing, algebraic methods [38] and PDE [39] methods are the two most commonly used structured mesh generation techniques. Algebraic methods use algebraic interpolation to describe the potential mapping relationship between the parametric domain $(\\xi,\\eta, \\zeta)$ and the computational domain $(x, y, z)$.\nThe generation of meshes in 3D spaces through PDEs involves determining the correspondence between node coordinates in computational and parametric spaces. This is achieved by treating the process as a boundary-value problem solved by a system of elliptic PDEs. In this approach, elliptic equations are employed for 3D mesh generation. The process first solves for parametric coordinates within the parametric domain using elliptic mesh generation methods. Subsequently, these parametric meshes are transformed back into the computational domain, resulting in the acquisition of the computational surface mesh coordinates.\nThe governing differential equation is of the form of\n$\\nabla^2\\xi^i = P^i (i = 1,2,3),$ (1)\nor\n$\\begin{cases}  \\xi_{xx}+\\xi_{yy}+\\xi_{zz} = P (\\xi,\\eta, \\zeta) \\\\  \\eta_{xx}+\\eta_{yy}+\\eta_{zz} = Q (\\xi,\\eta, \\zeta) \\\\  \\zeta_{xx} + \\zeta_{yy} + \\zeta_{zz} = R (\\xi,\\eta, \\zeta) .  \\end{cases}$ (2)\nwhere $\\nabla^2$ denotes the Laplacian operator in Cartesian coordinate system, $P^i = P^i (\\xi^1,\\xi^2,\\xi^3)$, $P^1 = P$, $P^2 = Q$, and $P^3 = R$ are referred to as source terms. The source terms P, Q, and R are helpful in stretching the mesh surface $(\\xi,\\eta, \\zeta)$ respectively. Negative values of the source terms cause the corresponding mesh faces to move toward the decreasing curve coordinates, while positive values of the source terms have the opposite effect. Therefore, the mesh density can be adjusted by adjusting the values of the source terms."}, {"title": "B. The Architecture of 3DMeshNet", "content": "We propose 3DMeshNet, a novel neural network-based approach for structured 3D mesh generation. It leverages the representation learning capabilities of neural networks to learn the rules governing mesh partitioning and determine the mapping between parametric and computational domain by encoding point coordinates through a deep network. Specifically, the network mesh partitioning rules by minimizing a weighted loss function comprising the residuals of governing differential equations and surface constraint. Once trained, 3DMeshNet can generate meshes of arbitrarily specified sizes for the corresponding geometries in a feedforward.\nThe architecture of 3DMeshNet is illustrated in Fig. 1. It comprises a Neural network and a Physics-informed learning part. The Neural network component primarily learns the rules of mesh partitioning, while the Physics-informed learning part provides physical information from the elliptic governing differential equations.\nThe input to 3DMeshNet is sampled points from the interior and surface points of the parametric domain. Each input comprises a set of 3D points $ {(\\xi_i,\\eta_i,\\zeta_i)}_{i=1}^{i=N}$, where N is the number of points. The network output consists of points ${(x_i, y_i, z_i)}_{i=1}^{i=N}$ representing the mesh in the computational domain.\nThe Neural network portion contains an input, multiple hidden, and output layers. The input layer takes training points $(\\xi,\\eta, \\zeta)$ and passes them to hidden layers. Within hidden layers, the network performs computations to extract high-dimensional features via Eq. 3.:\n$x^k = \\sigma (x^{k-1}W^{k-1}+b^{k-1}),$ (3)\nwhere x denotes a hidden layer output, $\\sigma$ the activation function, and W and b the layer weights and bias, respectively. Subsequently, the output layer produces computational domain coordinate predictions based on received hidden representations.\nIn the Physics-informed learning part, elliptic control equations are employed to guide the Neural network's training in learning mesh partitioning rules, with boundary conditions describing the surface fitting of the given 3D object. In the Finite Difference layer, 3DMeshNet applies the Finite Difference method, based on the Taylor series expansion, to improve efficiency in derivative computation. The loss function is determined through Loss Function Reweighting, informed by the 3D elliptical equation and Surface Fitting. Loss Function Reweighting employs a multi-task learning strategy and surface point weighting scheme to reweight the two-part loss. The multi-task learning strategy leverages homoscedastic uncertainty principles from Bayesian inference to adjust weights a according to task-specific uncertainties. The surface point weighting scheme introduces a surface point weighting scheme, assigning weights based on the Euclidean distance between predicted and actual surface points, thereby enhancing boundary mesh quality. Moreover, gradient projection effectively mitigates gradient conflict between the elliptic equation gradient and the Surface Fitting gradient. Lastly, network parameters are then updated across training sessions through loss backpropagation."}, {"title": "C. Loss Function with Finite Difference", "content": "The loss function of 3DMeshNet consists of two parts: a boundary loss for surface fitting and a 3D elliptic PDE system as basic governing differential equations. The 3D elliptic PDE provides the physical-informed learning aspect for mesh generation. By embedding the 3D elliptic PDE into the loss function, we aim to minimize it during the unsupervised learning process.\n$\\begin{aligned} &\\alpha_1 x_{\\xi\\xi} + \\alpha_2 x_{\\eta\\eta} + \\alpha_3 x_{\\zeta\\zeta} + 2\\beta_{12}x_{\\xi\\eta} + 2\\beta_{23}x_{\\eta\\zeta} + 2\\beta_{31}x_{\\zeta\\xi} = 0 \\\\ &\\alpha_1 y_{\\xi\\xi} + \\alpha_2 y_{\\eta\\eta} + \\alpha_3 y_{\\zeta\\zeta} + 2\\beta_{12}y_{\\xi\\eta} + 2\\beta_{23}y_{\\eta\\zeta} + 2\\beta_{31}y_{\\zeta\\xi} = 0 \\\\ &\\alpha_1 z_{\\xi\\xi} + \\alpha_2 z_{\\eta\\eta} + \\alpha_3 z_{\\zeta\\zeta} + 2\\beta_{12}z_{\\xi\\eta} + 2\\beta_{23}z_{\\eta\\zeta} + 2\\beta_{31}z_{\\zeta\\xi} = 0 \\end{aligned}$ (4)\n$\\begin{aligned} &\\alpha_1 = (x^2_{\\eta} + y^2_{\\eta} + z^2_{\\eta})(x^2_{\\zeta} + y^2_{\\zeta} + z^2_{\\zeta}) - (x_{\\eta}x_{\\zeta} + y_{\\eta}y_{\\zeta} + z_{\\eta}z_{\\zeta})^2, \\\\ &\\alpha_2 = (x^2_{\\zeta} + y^2_{\\zeta} + z^2_{\\zeta})(x^2_{\\xi} + y^2_{\\xi} + z^2_{\\xi}) - (x_{\\zeta}x_{\\xi} + y_{\\zeta}y_{\\xi} + z_{\\zeta}z_{\\xi})^2, \\\\ &\\alpha_3 = (x^2_{\\xi} + y^2_{\\xi} + z^2_{\\xi})(x^2_{\\eta} + y^2_{\\eta} + z^2_{\\eta}) - (x_{\\xi}x_{\\eta} + y_{\\xi}y_{\\eta} + z_{\\xi}z_{\\eta})^2, \\\\ &\\beta_{12} = (x_{\\eta}x_{\\zeta} + y_{\\eta}y_{\\zeta} + z_{\\eta}z_{\\zeta})(x_{\\zeta}x_{\\xi} + y_{\\zeta}y_{\\xi} + z_{\\zeta}z_{\\xi}) \\\\ & - (x_{\\xi}x_{\\eta} + y_{\\xi}y_{\\eta} + z_{\\xi}z_{\\eta})(x^2_{\\zeta} + y^2_{\\zeta} + z^2_{\\zeta}), \\\\ &\\beta_{23} = (x_{\\xi}x_{\\eta} + y_{\\xi}y_{\\eta} + z_{\\xi}z_{\\eta})(x_{\\eta}x_{\\zeta} + y_{\\eta}y_{\\zeta} + z_{\\eta}z_{\\zeta}) \\\\ & - (x_{\\zeta}x_{\\xi} + y_{\\zeta}y_{\\xi} + z_{\\zeta}z_{\\xi})(x^2_{\\eta} + y^2_{\\eta} + z^2_{\\eta}), \\\\ &\\beta_{31} = (x_{\\zeta}x_{\\xi} + y_{\\zeta}y_{\\xi} + z_{\\zeta}z_{\\xi})(x_{\\xi}x_{\\eta} + y_{\\xi}y_{\\eta} + z_{\\xi}z_{\\eta}) \\\\ & - (x_{\\eta}x_{\\zeta} + y_{\\eta}y_{\\zeta} + z_{\\eta}z_{\\zeta})(x^2_{\\xi} + y^2_{\\xi} + z^2_{\\xi}). \\end{aligned}$ (5)\nwhere $x_{\\xi}$ represents the first-order partial derivative of x with respect to $\\xi$, while $x_{\\xi\\eta}$ signifies the second-order partial derivative of x, taken sequentially first with respect to $\\xi$ and then $\\eta$. This notation is similarly extended to other second-order derivatives. Then, the form of the loss function with governing"}, {"title": "D. Loss Function Reweighting", "content": "As the loss function consists of two components, namely the Governing Differential Equation and the Surface Fitting Loss, we can consider these two optimization objectives as a multi-task optimization problem. Moreover, a significant numerical difference exists between the losses of these two parts. Weight hyper-parameters are expensive to tune and often take time for each trial. Therefore, it is desirable to find a more convenient approach that can learn the optimal weights. Consequently, We incorporate a strategy for multi-task learning as presented in source [40] to assign weight appropriately to the losses of distinct tasks.\nThe methodology utilizes homoscedastic uncertainty principles from Bayesian inference to assess and articulate the variance in confidence across tasks, enabling a sophisticated approach to loss weighting based on task-specific uncertainties. Let NN(X;\u03b8) denote the output of a neural network with input x and u is the model's output, in this paper represented as (x, y, z). We define the following probabilistic model:\n$p (u|NN (X;\\theta)) = N (NN (X;\\theta),\\alpha^2),$ (11)\nand Eq.11 describes the conditional probability distribution of the target variable u given the input X and the neural network prediction NN(X;\u03b8). We assumes that the distribution of the target variable u follows a Gaussian distribution with mean equal to the predicted value NN(X;\u03b8) and variance \u03b12. With the scalar a as a noise parameter. In a setting of a neural network with K tasks, the multi-objective likelihood can be written as:\n$p(u_1,...,u_K|NN(X;\\theta)) = p(u_1|NN(X;\\theta))\u2026p(u_K|NN(X;\\theta)).$ (12)\nIn maximum likelihood estimation, it is often convenient to work with the natural logarithm of the likelihood function, the log likelihood can be written as:\n$\\log p(u|NN(X;\\theta))  = \\log  \\left[  (2\\pi\\alpha^2)^{-\\frac{1}{2}} \\exp\\left(-\\frac{1}{2\\alpha^2}||u - NN(X;\\theta)||^2\\right)\\right]  = \\log (2\\pi\\alpha^2)^{-\\frac{1}{2}} +\\log \\left[ \\exp\\left(-\\frac{1}{2\\alpha^2}||u - NN(X;\\theta)||^2\\right)\\right] = -\\frac{1}{2} \\log (2\\pi\\alpha^2) - \\frac{1}{2\\alpha^2} ||u - NN(X;\\theta)||^2, = -\\frac{1}{2} \\log (2\\pi\\alpha^2) - \\frac{1}{2\\alpha^2} ||u - NN(X;\\theta)||^2,$ (13)\n$\\log p(u|NN(X;\\theta)) \\propto -\\frac{1}{2\\alpha^2}||u - NN(X;\\theta)||^2 - \\log a,$\nand we can therefore maximize:\n$\\log p (u_1,...,u_K |NN(X;\\theta)) = \\log p (u_1 | NN(X;\\theta)) + ... + \\log p (u_K | NN(X;\\theta)) = \\log N (u_1;NN(X;\\theta), a^2) + ... +\\logN (u_K;NN(X;\\theta),a^2) =  (\\frac{-1}{2\\alpha^2_1}-\\log a_1)+...+(\\frac{-1}{2\\alpha^2_K}-\\log a_K) = (\\frac{-1}{2\\alpha_1^2}-\\log (1+\\alpha_1)) + ... + (\\frac{-1}{2\\alpha_K^2}-\\log (1+\\alpha_K)).$ (15)\nAccording to Eq. 15, to facilitate optimization, we prefer to maximize the sum of the logarithms of these likelihoods, which simplifies to a sum of terms involving task-specific losses Li and noise parameters ai. The logarithm of \u03b12 is modified to log(1+\u03b12), ensuring the expression remains positive and avoids training issues where the loss might otherwise become negative. This leads to our minimization target:\n$L(\\theta,\\alpha_1,...,\\alpha_K) = \\sum_{i=1}^{K} \\left(\\frac{1}{2\\alpha_i^2}L_i+\\log (1+\\alpha_i) \\right),$ (16)\nthis objective function balances each task's loss against its uncertainty, represented by a, now a parameter to be learned alongside the neural network's weights. It allows adaptive learning of each task's importance, preventing the network from discounting easier tasks with smaller uncertainties. Additionally, the term log(1+a) acts as a regularization, averting excessively large values of a and ensuring a balanced task weighting within the multi-task learning framework.\nAnother innovation in Loss Function Reweighting is the implementation of a surface point weighting scheme. This scheme emphasizes the importance of accurately capturing surface conditions by assigning higher weights to poorly predicted surface points and lower weights to well-predicted ones. As a result, 3DMeshNet can more effectively learn and conform to surface conditions, enhancing the mesh quality at the boundaries.\n$weight = ||(x_{true} - x_{pre}, y_{true} - y_{pre}, z_{true} \u2013 z_{pre})||+1,$ (17)\nwhere $(x_{pre}, y_{pre}, z_{pre})$ is the predicted output of the ith surface point and $(x_{true}, y_{true}, z_{true})$ is the coordinates of the ith real surface point. After calculating the Euclidean distance between the predicted surface point and the real surface point, the distance is added by 1 to get the weight w = distance + 1, or directly use the distance as the weight w = distance.\nAfter introducing the loss function adaptive weighting strategy as well as the surface point weighting mechanism, the loss function of Eq. 18 can be rewritten in the following form\n$Loss (x, y, z) = \\frac{Loss_1}{1 + a_1^2} + weight\\frac{Loss_2}{1 + a_2^2}  +log (1+a_1^2)+log (1+a_2^2).$ (18)\nwhere, $Loss_1$ and $Loss_2$ are equal to the loss of Equation 7. 3DMeshNet finally uses the Eq. 18 as a loss function to guide the training of the network."}, {"title": "E. Gradient Projection", "content": "In addition to balancing the Surface Fitting loss with the Governing Differential Equation loss efficiently, our approach introduces gradient projection to address the issue of ill-conditioned gradients from a gradient perspective. Previous works, such as MGNet [8] and MeshNet [32], have focused primarily on numerical improvements to the loss function, with little exploration into enhancements from a gradient standpoint. Furthermore, upon examining the loss function, it is evident that substantial oscillations in the loss are not conducive to the optimal collection of structured mesh results. Therefore, we have incorporated the gradient projection mechanism to improve network convergence. This novel methodology offers a comprehensive solution by tackling numerical and gradient aspects, enhancing the overall efficacy of structured mesh generation.\nWe define \u03b3mn as the angle between two task gradients gm and gn, and when cos\u03b3mn < 0 it means that the gradients are conflicting. Specifically, mitigating the gradient conflict of the loss function can include the following steps:\n(1) Assume that the gradient of task Tm is gm and the gradient of task Tn is gn.\n(2) Determine whether gm conflicts with gn by calculating the cosine similarity between the vectors gm and gn, where a negative value indicates the gradient of the conflict. The cosine similarity is calculated as follows.\n$cos \\gamma_{mn} = \\frac{g_m\\cdot g_n}{||g_m||\\times||g_n||}$ (19)\n(3) If the cosine similarity is negative, replace gn with its projection $g_m^C$ on the normal plane of gn, that is, $g_m^C= g_m - P_C g_n$,\n$P_C=\\frac{g_m\\cdot g_n}{||g_n||^2}$. If the gradients are not conflicting, cos\u03b3mn > 0 is non-negative, and the original gradient gm is kept constant."}]}