{"title": "3DMeshNet: A Three-Dimensional Differential Neural Network for Structured Mesh Generation", "authors": ["Jiaming Peng", "Xinhai Chen", "Jie Liu"], "abstract": "Mesh generation is a crucial step in numerical simulations, significantly impacting simulation accuracy and efficiency. However, generating meshes remains time-consuming and requires expensive computational resources. In this paper, we propose a novel method, 3DMeshNet, for three-dimensional structured mesh generation. The method embeds the meshing-related differential equations into the loss function of neural networks, formulating the meshing task as an unsupervised optimization problem. It takes geometric points as input to learn the potential mapping between parametric and computational domains. After suitable offline training, 3DMeshNet can efficiently output a three-dimensional structured mesh with a user-defined number of quadrilateral/hexahedral cells through the feed-forward neural prediction. To enhance training stability and accelerate convergence, we integrate loss function reweighting through weight adjustments and gradient projection alongside applying finite difference methods to streamline derivative computations in the loss. Experiments on different cases show that 3DMeshNet is robust and fast. It outperforms neural network-based methods and yields superior meshes compared to traditional mesh partitioning methods. 3DMeshNet significantly reduces training times by up to 85% compared to other neural network-based approaches and lowers meshing overhead by 4 to 8 times relative to traditional meshing methods.", "sections": [{"title": "I. INTRODUCTION", "content": "Numerical simulation has become increasingly important in various fields of natural science research, promoting the development of modern applied scientific research and engineering technology [1], [2]. These simulations typically require the use of meshes as a fundamental geometric framework to facilitate the analysis of physical phenomena via finite element methods or other numerical techniques. Mesh generation, defined as dividing a continuous computational domain into meshes or elements for further numerical solutions, is a critical step in engineering simulations [3]. The quality of the generated mesh has a significant impact on the accuracy of numerical simulations [4]. Given the significant impact of mesh quality on these aspects, the rapid generation of high-quality meshes has become a primary concern.\nStructured meshes are widely used in numerous simulations requiring precise element alignment for high-efficiency and high-precision [5]. They present multiple benefits: (1) Structured meshes do not require additional storage to connect mesh elements, resulting in higher efficiency in data access. (2) Their structured topological nature facilitates easy control over mesh cell sizes. (3) The regularity of their structure facilitates the implementation of convolutional and pooling operations in neural networks [6]. Motivated by these benefits, extensive research has been done on structured mesh generation [7], [8]. Algebraic methods calculate mesh interior points through algebraic interpolation, employing techniques like polynomial and Transfinite Interpolation (TFI) [9]. This approach is straightforward and enables rapid mesh generation. However, it can lead to mesh degradation in areas with complex geometries, resulting in issues such as intersections. To mitigate these problems, Partial Differential Equation (PDE) methods are commonly used to generate meshes for arbitrary boundaries [8]. Given the boundary values, PDE methods pose mesh generation as a boundary value problem governed by differential equations. Meshes created using PDE methods are of higher quality but require many computational resources and are time-consuming [10]. Thus, there is a significant demand for further research and development of a rapid and robust structured mesh generation method that balances speed and mesh quality.\nIn recent years, deep neural networks (DNNs) have achieved remarkable progress in fields such as flow-field prediction [11], mesh quality determination [3], and other physical problems [12]. A few methods have been developed to incorporate neural networks into mesh generation tasks. Jilani et al. [13] proposed a two-dimensional(2D) initial mesh generated based on a Self-organizing map neural network for finite element analysis and calculation of mesh self-adaptive parameters, followed by adaptive tuning of the initial mesh using the Self-organizing map neural network. Liu et al. [14] introduced the ISpliter method, combining neural networks with segmentation lines to transform B-rep geometrical shapes into unstructured meshes and facilitating neural network training through recursive data generation. Soman S [15] employed Conditional Generative Adversarial Networks to ascertain the coordinates of mesh nodes for generating 2D and three-dimensional (3D) unstructured meshes. However, these methods often rely on large training datasets, which can be costly and complex to obtain, particularly for geometries of intricate shapes. Methods like MGNet [8], which utilize unsupervised learning for mesh generation, address the challenge of extensive manual training data requirements but still encounter problems such as unstable convergence and long training times. Additionally, pioneer researchers primarily focus on generating structured meshes in 2D, and developing neural network-based methods for 3D meshes remains an open problem.\nIn this paper, we introduce 3DMeshNet, a novel intelligent method for 3D structured mesh generation. 3DMeshNet employs a neural network embedded with 3D elliptic PDEs to learn the meshing rules for 3D mesh partitioning. Specifically, a well-designed neural network is developed to approximate the potential mapping between parametric and computational domains. The 3D elliptic PDEs and surface fitting items are embedded in the loss function, acting as penalty terms to guide the optimization of network parameters. After suitable training, 3DMeshNet can efficiently generate meshes of any specified size for the corresponding geometry using forward propagation. To reduce training time, improve surface fitting accuracy, and enhance model convergence stability, we employed finite differences (FD), loss function reweighting, and gradient projection to improve the model from three aspects. Finite differences reduce computational costs and accelerate training by efficiently computing derivatives. Loss function reweighting improved surface representation by adjusting loss terms using multi-task learning. Gradient projection reconciled gradients from different loss items. Our experiments on 2D and 3D geometries demonstrate that 3DMeshNet can effectively balance meshing overhead and mesh quality, producing high-quality meshes for complex shapes where PINN methods might struggle to maintain mesh quality. 3DMeshNet produces mesh quality that surpasses existing approaches, achieving a meshing overhead reduction of 4 to 8 times compared to TFI methods and decreasing training times by up to 85% relative to other neural network-based methods. To the best of our knowledge, this is the first work to introduce PINNs for 3D mesh generation.\nThe remainder of this paper is organized as follows: Section II reviews related work on mesh generation methods. Section III provides a detailed description of the proposed 3DMeshNet method. Section IV presents experimental results comparing different methods on two 2D geometries and four 3D geometries. Lastly, Section V concludes the paper and discusses future work."}, {"title": "II. RELATED WORK", "content": "Structured meshes provide simplicity, making them widely used in numerous simulations that necessitate precise alignment of elements as dictated by analytical requirements [16]. The demand for precision has also stimulated the development of mesh generation methods [7], [8]. The methods for generating structured meshes include conformal mapping, algebraic methods, and PDE methods [17]. Algebraic methods typically employ various interpolation techniques or special functions for mesh creation [18]. Conformal mapping, which employs angle-preserving transformations derived from complex function theory, facilitates the generation of 2D meshes by altering the computational domain. However, expanding these methods to 3D mesh generation presents significant challenges. PDE methods, on the other hand, generate meshes by solving elliptic, parabolic, or hyperbolic equations within a specified transformation domain [19]. Although the algebraic method offers simplicity and rapid mesh creation, it may lead to mesh degradation in areas of complex geometry or cause mesh elements to overlap or breach boundaries. Structured meshes generated using the differential equation method are of high quality but require high computational effort.\nArtificial intelligence represented by neural networks has been vigorously developed in recent years [20], [21]. Neural networks can autonomously learn artificial experiences and fit objective functions from high-dimensional parameter spaces, and significant progress has been made in knowledge-based physical problems during the last several years [22], [23]. Obiols-Sales O et al. [11] proposed that CFD-Net combines physical simulation and deep learning in a coupled framework to accelerate the convergence of Reynolds Averaged Navier-Stokes simulations. Neural networks are also trained to learn the lift coefficients of airfoils with various shapes under different flow Mach numbers, Reynolds numbers, and diverse angles of attack [22]. Gholami et al. [23] used neural networks along with numerical simulation to estimate flow depth variables and velocity for typical cases such as a 60\u00b0 bend in a tube. The intelligent solution of PDEs has become increasingly prevalent and impactful in academic research. The PINNs designed by Raissi M [24] et al. employ a DNN to approximate the solutions of PDEs, embedding the residuals that govern the PDE and its initial/boundary conditions within the loss function. Various variants of PINNs have been proposed to enhance their accuracy and efficiency. CanPINN [25] combines automatic and numerical differentiation in PINNs to improve training efficiency and accuracy. Meanwhile, ATLPINNs [26] address the issues of low accuracy and non-convergence in original PINNs via auxiliary-task learning. These variants aim to strengthen PINN's performance in solving PDEs.\nIn addition to applying artificial intelligence in physics for solving PDEs, some researchers have explored incorporating artificial intelligence into mesh generation, mesh quality discrimination, and other areas to overcome the limitations of automation and intelligence in traditional mesh methods. Chen [3] presented a neural network-based mesh quality indicator for 3D cylinder meshes, along with a benchmark dataset. Wang [27] developed an algorithm to convert mesh data into graph data, subsequently introducing a deep graph neural network, GMeshNet, for mesh quality evaluation. MQENet [28] is introduced as a structured mesh quality evaluation network that leverages dynamic graph attention, treating mesh evaluation as a graph classification task. Yilmaz and Kuzuoglu [29] proposed a particle swarm optimization algorithm aimed at optimizing hexahedral mesh quality, addressing the inefficacies of the Laplace mesh smoothing algorithm in concave areas. Gargallo-Peir\u00f3 A [30] suggested an optimization method for triangular and quadrilateral meshes on parameterized surfaces, focusing on node relocation to enhance mesh quality and prevent element inversion. Data-driven approaches to mesh generation have seen various implementations. Lowther et al. [31] applied neural networks to mesh density prediction in finite element mesh adaptation, using density information provided by the neural network to determine the size and placement of elements. MeshingNet [32] leverages posterior error estimates on an initial coarse mesh to predict non-uniform mesh densities for refinement. However, generating the training dataset is costly, and the model is targeted towards two-dimensional unstructured meshes. Huang et al. [33] developed a convolutional neural network to predict optimal mesh densities for diverse geometries. The validation phase required more than 60,000 simulations, supported by a training dataset of 20,000 simulations. Such extensive data demands may present challenges regarding computational resources and time allocation. Alexis Papagiannopoulos [34] introduced a neural network scheme for creating 2D simplicial meshes, using networks trained on meshed contour data to approximate vertex count, placement, and connectivity, though requiring extensive datasets for contours with a high number of vertices. Peng et al. [35] employed two Artificial Neural Networks (ANNs) trained on an initial hybrid grid to predict point advancement and control grid sizing, with the ANN-based Advancing Layer Method generating initial training grids. Kim et al. [36] utilized Graph Convolutional Neural Networks to learn local error densities and predict target mesh edge lengths, generating 16,000 control and feature meshes for training. However, these supervised learning meshing techniques necessitate significant effort in producing large training datasets, complicated by the costly creation and processing of these datasets, particularly for meshes with complex geometries or high vertex counts. Moreover, generating training data demands domain-specific expertise. Physics-informed methods utilizing unsupervised learning to minimize the need for extensive training data in mesh generation have emerged. MGNet [8] proposed an intelligent approach for structured mesh creation, which is the first application of PINNs in this field. The network is designed to unsupervisedly learn meshing rules between parametric and computational domains, requiring only boundary specifications. Nevertheless, MGNet [8] faces challenges like training instability and extended durations. Chen [7] enhanced mesh quality by modifying loss terms with an auxiliary line strategy, initially requiring the manual selection of these lines as ground truth. However, it is still oriented to a 2D problem and requires additional manual intervention for drawing auxiliary lines. MeshNet first generates a coarse mesh using the traditional method and then adds the points of the coarse mesh as data items inside the training of the PINN, improving the quality of the generated mesh [37]. However, it introduces additional overhead for computation and training. While physics-informed methods alleviate the need for extensive manual data, they encounter issues such as slow training speeds, unstable convergence, and long training times. Furthermore, most of these approaches target 2D mesh generation, leaving the intelligent generation of 3D structured mesh remains an open problem."}, {"title": "III. 3DMESHNET: A THREE-DIMENSIONAL DIFFERENTIAL NEURAL NETWORK FOR STRUCTURED MESH GENERATION", "content": "The task of structured mesh generation involves the application of a potential mapping between parametric and computational domain to a given geometry. Typically, the parametric domain, represented by the coordinates (\u03be,\u03b7,\u03b6), is defined as a basic cube [0\u00d71]\u00d7[0\u00d71]\u00d7[0\u00d71], with each edge oriented either horizontally or vertically. The primary goal of any structured mesh generation technique is to create a mapping (\u03be,\u03b7,\u03b6) to (x, y, z) between these two spaces. This mapping should be unique and smooth, ensuring that the resulting mesh accurately conforms to the geometry's boundaries that require discretization.\nIn numerical computing, algebraic methods [38] and PDE [39] methods are the two most commonly used structured mesh generation techniques. Algebraic methods use algebraic interpolation to describe the potential mapping relationship between the parametric domain (\u03be,\u03b7, \u03b6) and the computational domain (x, y, z).\nThe generation of meshes in 3D spaces through PDEs involves determining the correspondence between node coordinates in computational and parametric spaces. This is achieved by treating the process as a boundary-value problem solved by a system of elliptic PDEs. In this approach, elliptic equations are employed for 3D mesh generation. The process first solves for parametric coordinates within the parametric domain using elliptic mesh generation methods. Subsequently, these parametric meshes are transformed back into the computational domain, resulting in the acquisition of the computational surface mesh coordinates.\nThe governing differential equation is of the form of\n\u2207\u00b2\u03bei = Pi (i = 1,2,3), (1)\n\u00a7xx+\u00a7yy+\u00a7zz = P (\u03be,\u03b7, \u03b6)\nNxx+Nyy+Nzz = Q (\u03be,\u03b7, \u03b6)\n\u0160xx + \u0160yy + \u0160zz = R (\u03be,\u03b7, \u03b6) . (2)\nwhere \u2207\u00b2 denotes the Laplacian operator in Cartesian coordinate system,Pi = Pi (\u00a71,\u00a72,\u00a73), P1 = P, P2 = Q, and_P3 = R_are referred to as source terms. The source terms P, Q, and R are helpful in stretching the mesh surface (\u03be,\u03b7, \u03b6) respectively. Negative values of the source terms cause the corresponding mesh faces to move toward the decreasing curve coordinates, while positive values of the source terms have the opposite effect. Therefore, the mesh density can be adjusted by adjusting the values of the source terms.\nWe propose 3DMeshNet, a novel neural network-based approach for structured 3D mesh generation. It leverages the representation learning capabilities of neural networks to learn the rules governing mesh partitioning and determine the mapping between parametric and computational domain by encoding point coordinates through a deep network. Specifically, the network mesh partitioning rules by minimizing a weighted loss function comprising the residuals of governing differential equations and surface constraint. Once trained, 3DMeshNet can generate meshes of arbitrarily specified sizes for the corresponding geometries in a feedforward.\nThe architecture of 3DMeshNet is illustrated in Fig. 1. It comprises a Neural network and a Physics-informed learning part. The Neural network component primarily learns the rules of mesh partitioning, while the Physics-informed learning part provides physical information from the elliptic governing differential equations.\nThe input to 3DMeshNet is sampled points from the interior and surface points of the parametric domain. Each input comprises a set of 3D points= {(\u03bei,ni,\u03b6i)}=N, where N is the number of points. The network output consists of points {(xi, yi, zi)} representing the mesh in the computational domain.\nThe Neural network portion contains an input, multiple hidden, and output layers. The input layer takes training points (\u03be,\u03b7, \u03b6) and passes them to hidden layers. Within hidden layers, the network performs computations to extract high-dimensional features via Eq. 3.:\n\u03c7 = o (xk-1wk-1+bk-1), (3)\nwhere x denotes a hidden layer output, o the activation function, and W and b the layer weights and bias, respectively. Subsequently, the output layer produces computational domain coordinate predictions based on received hidden representations.\nIn the Physics-informed learning part, elliptic control equations are employed to guide the Neural network's training in learning mesh partitioning rules, with boundary conditions describing the surface fitting of the given 3D object. In the Finite Difference layer, 3DMeshNet applies the Finite Difference method, based on the Taylor series expansion, to improve efficiency in derivative computation. The loss function is determined through Loss Function Reweighting, informed by the 3D elliptical equation and Surface Fitting. Loss Function Reweighting employs a multi-task learning strategy and surface point weighting scheme to reweight the two-part loss. The multi-task learning strategy leverages homoscedastic uncertainty principles from Bayesian inference to adjust weights a according to task-specific uncertainties. The surface point weighting scheme introduces a surface point weighting scheme, assigning weights based on the Euclidean distance between predicted and actual surface points, thereby enhancing boundary mesh quality. Moreover, gradient projection effectively mitigates gradient conflict between the elliptic equation gradient and the Surface Fitting gradient. Lastly, network parameters are then updated across training sessions through loss backpropagation."}, {"title": "C. Loss Function with Finite Difference", "content": "The loss function of 3DMeshNet consists of two parts: a boundary loss for surface fitting and a 3D elliptic PDE system as basic governing differential equations. The 3D elliptic PDE provides the physical-informed learning aspect for mesh generation. By embedding the 3D elliptic PDE into the loss function, we aim to minimize it during the unsupervised learning process.\na\u2081x\u03be\u03be + a2x\u03b7\u03b7 +a3x\u03b6\u03b6 +2\u03b212x\u03be\u03b7 +2\u03b223x\u03b7\u03b6 +2\u03b231x\u03b6\u03be = 0\na1y\u03be\u03be + a2y\u03b7\u03b7 +a3y\u03b6\u03b6 +2\u03b212y\u03be\u03b7 +2\u03b223y\u03b7\u03b6 +2\u03b231y\u03b6\u03be = 0\na1z\u03be\u03be + a2z\u03b7\u03b7 +a3z\u03b6\u03b6 +2\u03b212z\u03be\u03b7 +2\u03b223z\u03b7\u03b6 +2\u03b231z\u03b6\u03be = 0 (4)\na\u2081 = (x\u00b2 + y\u00b2 + z\u00b2)(x\u00b2 + y\u00b2 + z\u00b2) - (x\u03b7x\u03b6 + y\u03b7y\u03b6 + z\u03b7z\u03b6),\na2 = (x\u00b2 + y\u00b2 + z\u00b2)(x\u00b2 + y\u00b2 + z\u00b2) - (x\u03b6x\u03be + y\u03b6y\u03be + z\u03b6z\u03be),\na3 = (x\u00b2 + y\u00b2 + z\u00b2)(x\u00b2 + y\u00b2 + z\u00b2) - (x\u03b7x\u03be + y\u03b7y\u03be + z\u03b7z\u03be),\n\u03b212 = (x\u03b7x\u03b6 + y\u03b7y\u03b6 + z\u03b7z\u03b6)(x\u03b6x\u03be + y\u03b6y\u03be + z\u03b6z\u03be) \u2013 (x\u03bex\u03b7 + y\u03bey\u03b7 + z\u03bez\u03b7)(x\u00b2 + y\u00b2 + z\u00b2),\n\u03b223 = (x\u03b6x\u03be + y\u03b6y\u03be + z\u03b6z\u03be)(x\u03b7x\u03be + y\u03b7y\u03be + z\u03b7z\u03be) \u2013 (x\u03bex\u03b6 + y\u03bey\u03b6 + z\u03bez\u03b6)(x\u00b2 + y\u00b2 + z\u00b2),\n\u03b231 = (x\u03bex\u03b7 + y\u03bey\u03b7 + z\u03bez\u03b7)(x\u03b7x\u03b6 + y\u03b7y\u03b6 + z\u03b7z\u03b6) \u2013 (x\u03b6x\u03be + y\u03b6y\u03be + z\u03b6z\u03be)(x\u00b2 + y\u00b2 + z\u00b2). (5)\nwhere x\u03be represents the first-order partial derivative of x with respect to\u03be, while x\u03be\u03b7 signifies the second-order partial derivative of x, taken sequentially first with respect to \u0121 and then n. This notation is similarly extended to other second-order derivatives. Then, the form of the loss function with governing differential equations loss and geometric surface constraint is as follows:\nLoss (x, y, z) = Loss1 + Loss2, (6)\nLoss1 = 1\u2211 {\u2223a1x\u03be\u03be + a2x\u03b7\u03b7 +a3x\u03b6\u03b6 +2\u03b212x\u03be\u03b7 +2\u03b223x\u03b7\u03b6 +2\u03b231x\u03b6\u03be\u2223\u00b2+\n\u2223a1y\u03be\u03be +a2y\u03b7\u03b7 +a3y\u03b6\u03b6 +2\u03b212y\u03be\u03b7 +2\u03b223y\u03b7\u03b6 +2\u03b231y\u03b6\u03be\u2223\u00b2+\n\u2223a1z\u03be\u03be +a2z\u03b7\u03b7 +a3z\u03b6\u03b6 +2\u03b212z\u03be\u03b7 +2\u03b223z\u03b7\u03b6 +2\u03b231z\u03b6\u03be\u2223\u00b2}, (7)\nLoss2 = 1\u2211 \u2223\u2223(xn, yn, zn) \u2013 f (\u03ben, \u03b7\u03b7, \u03b6n) \u2223\u2223\u00b2\nthe loss function is composed of two parts: the first part, Loss\u2081 is the control equation loss term, and the second part, Loss2 is the geometric surface constraint term. Here, N, and Nb represent the number of training points for the control equation and the geometric surface. (Xn, yn, Zn) denotes the coordinates of the nth actual surface point, and f (\u03be\u03b7, \u03b7\u03b7, \u03b6n) refers to the predicted value corresponding to the input at the surface point.\nTo achieve a more efficient implementation, we do not use automatic differentiation for derivative calculations because it is time-consuming [25]. Instead, we shift to using the finite differences method for calculating derivatives. The finite differences method is based on the Taylor series expansion, allowing us to compute derivatives more efficiently and effectively.\nSpecifically, the derivation formula for the finite differences method is as follows:\n\u0155g = (\u0159i+1,j,k-\u0159i-1,j,k)/2h1\n\u00cen = (\u0159i,j+1,k-\u0159i,j-1,k)/2h2\n\u0155g = (\u0159i,j,k+1 \u2212\u0159i,j,k\u22121)/2h3, (8)\n\u0155gg = (\u0159i+1,j,k\u22122\u0159i,j,k+\u0159i\u22121,j,k) /h21\nInn = (Fi,j+1,k - 2\u0159i,j,k+\u0159i,j\u22121,k)/h22\nIgg = (Fi,j,k+1-2\u0159i,j,k+\u0159i,j,k-1)/h23, (9)\n\u0393\u03be\u03b7 = (\u0159i+1,j+1,k\u2212\u0159i+1,j\u22121,k-\u0159i-1,j+1,k+ri-1,j\u22121,k), (10)\nwhere denotes the(x, y, z) vector and h1, h2, h3 represent the steps in the three spatial directions."}, {"title": "D. Loss Function Reweighting", "content": "As the loss function consists of two components, namely the Governing Differential Equation and the Surface Fitting Loss, we can consider these two optimization objectives as a multi-task optimization problem. Moreover, a significant numerical difference exists between the losses of these two parts. Weight hyper-parameters are expensive to tune and often take time for each trial. Therefore, it is desirable to find a more convenient approach that can learn the optimal weights. Consequently, We incorporate a strategy for multi-task learning as presented in source [40] to assign weight appropriately to the losses of distinct tasks.\nThe methodology utilizes homoscedastic uncertainty principles from Bayesian inference to assess and articulate the variance in confidence across tasks, enabling a sophisticated approach to loss weighting based on task-specific uncertainties. Let NN(X;0) denote the output of a neural network with input x and u is the model's output, in this paper represented as (x, y, z). We define the following probabilistic model:\np (u|NN (X;0)) = N (NN (X;0),a\u00b2), (11)\nand Eq.11 describes the conditional probability distribution of the target variable u given the input X and the neural network prediction NN(X;0). We assumes that the distribution of the target variable u follows a Gaussian distribution with mean equal to the predicted value NN(X;0) and variance a\u00b2. With the scalar a as a noise parameter. In a setting of a neural network with K tasks, the multi-objective likelihood can be written as:\np(41,...,\u0438\u043a|NN(X;0))\n= p(u1|NN(X;0))\u2026p(\u0438\u043a|NN(X;0)). (12)\nIn maximum likelihood estimation, it is often convenient to work with the natural logarithm of the likelihood function, the log likelihood can be written as:\nlogp(u|NN(X;0))\n= log 2\u03c0\u03b1\u00b2 [(2\u03c0\u03b1\u00b2) exp(-||u ||2- NN (X;0)||2)]\n= log (2\u03c0\u03b1\u00b2) $ +log [exp(-||u - NN (X;0)||2)]\n=log (2\u03c0\u03b1\u00b2(2\u03c0\u03b1\u00b2) $-||u - NN (X;0)||2 (13)\n\u03b1-||u-NN (X;0)||\u00b2-loga, (14)\nand we can therefore maximize:\nlog p (u1,...,\u0438\u043a |NN(X;0))\n= log p (u\u2081 | NN(X;0)) + ... + log p (\u0438\u043a | NN(X;0))\n= log (u\u2081;NN(X;0), a\u00b2) +...+logN (u\u03ba;NN(\u03a7;0),\u03b1\u03ba)\n=(-loga1)+...+(-logak)\n=(-loga\u00b2)+...+(-loga)\n=(L (-log (1+a)) + ... + (-L-log (1+a)). (15)\nAccording to Eq. 15, to facilitate optimization, we prefer to maximize the sum of the logarithms of these likelihoods, which simplifies to a sum of terms involving task-specific losses Li and noise parameters ai. The logarithm of a\u00b2 is modified to log(1+a2), ensuring the expression remains positive and avoids training issues where the loss might otherwise become negative. This leads to our minimization target:\nL(\u03b8,\u03b11,...,\u03b1\u03ba) = (16)\nthis objective function balances each task's loss against its uncertainty, represented by a, now a parameter to be learned alongside the neural network's weights. It allows adaptive learning of each task's importance, preventing the network from discounting easier tasks with smaller uncertainties. Additionally, the term log(1+a) acts as a regularization, averting excessively large values of a and ensuring a balanced task weighting within the multi-task learning framework.\nAnother innovation in Loss Function Reweighting is the implementation of a surface point weighting scheme. This scheme emphasizes the importance of accurately capturing surface conditions by assigning higher weights to poorly predicted surface points and lower weights to well-predicted ones. As a result, 3DMeshNet can more effectively learn and conform to surface conditions, enhancing the mesh quality at the boundaries.\nweight = \u2223\u2223(xtrue - xpre, ytrue - ypre, true \u2013 zpre)\u2223\u2223+1, (17)\nwhere (xpre, ypre, zpre) is the predicted output of the ith surface point and (xtrue, ytrue, ztrue) is the coordinates of the ith real surface point. After calculating the Euclidean distance between the predicted surface point and the real surface point, the distance is added by 1 to get the weight w = distance + 1, or directly use the distance as the weight w = distance.\nAfter introducing the loss function adaptive weighting strategy as well as the surface point weighting mechanism, the loss function of Eq. 18 can be rewritten in the following form\nLoss (x, y, z) = Loss1+ weight Loss2+log (1+a+az). (18)\nwhere, Loss\u2081 and Loss2 are equal to the loss of Equation 7.\n3DMeshNet finally uses the Eq. 18 as a loss function to guide the training of the network."}, {"title": "E. Gradient Projection", "content": "In addition to balancing the Surface Fitting loss with the Governing Differential Equation loss efficiently, our approach introduces gradient projection to address the issue of ill-conditioned gradients from a gradient perspective. Previous works, such as MGNet [8] and MeshNet [32], have focused primarily on numerical improvements to the loss function, with little exploration into enhancements from a gradient standpoint. Furthermore, upon examining the loss function, it is evident that substantial oscillations in the loss are not conducive to the optimal collection of structured mesh results. Therefore, we have incorporated the gradient projection mechanism to improve network convergence. This novel methodology offers a comprehensive solution by tackling numerical and gradient aspects, enhancing the overall efficacy of structured mesh generation.\nWe define mn as the angle between two task gradients gm and gn, and when cosmn < 0 it means that the gradients are conflicting. Specifically, mitigating the gradient conflict of the loss function can include the following steps:\n(1) Assume that the gradient of task Tm is gm and the gradient of task Tn is gn.\n(2) Determine whether gm conflicts with gn by calculating the cosine similarity between the vectors gm and gn, where a negative value indicates the gradient of the conflict. The cosine similarity is calculated as follows.\ncOS Ymn = (19)\n(3) If the cosine similarity is negative, replace gn with its projection gre on the normal plane of gn, that is, g = PPCgn.\nIf the gradients are not conflicting, cos4mn > 0 is non-negative, and the original gradient gm is kept constant."}, {"title": "IV. EXPERIMENTAL RESULTS", "content": "In this section, we demonstrate the effectiveness of the proposed 3DMeshNet in both 2D and 3D mesh generation cases. In 2D-case1 and 2D-case2, we use a configuration with hidden layer sizes of {45,45,45}; for 3D-case1, 3D-case2, and 3D-case3, we use a configuration with {85,85,85,85} hidden layer sizes; and for 3D-case4, we use a configuration with {128,128,128,128} MLP. Tanh serves as the activation function in all cases. Due to data dimension limitations, we opt for a lightweight network model to extract features instead of employing larger-scale models. 3DMeshNet randomly samples 4000 internal points and 6000 surface points from the parametric domain for training during each training iteration, and it employs Adam and L-BFGS-B optimizers to refine network parameters. Specifically, 3DMeshNet first employs the Adam optimizer for 12000 iterations of training. The learning rate is 1e-3, and it is reduced by a factor of 0.9 every 1000 epochs. Subsequently, the L-BFGS-B is employed to optimize the model parameters further. All experiments are implemented using PyTorch. Although the training processes are conducted on the 3080Ti GPU, due to the lightweight network model, the meshing process can be performed rapidly on CPU platforms. To validate the effectiveness of 3DMeshNet, we compared it with TFI [38] and PDE [39]. As NN-based models, we also selected PINN [24] and MGNet [8] as backbones to compare mesh quality with 3DMeshNet, demonstrating its superiority in mesh generation.\nIn assessing the generated mesh quality, we employe the loss on the test set as an auxiliary indicator of the mesh quality. Additionally, we utilize a comprehensive evaluation using the following five criteria for mesh quality to determine the overall integrity of the generated mesh:\n(1) Minimum Included Angle and Maximum Included Angle(2D, 3D): Both Minimum Included Angle and Maximum Included Angle are measures of mesh skewness. For all types of meshes, Minimum Included Angle denotes the minimum angle of the mesh and Maximum Included Angle denotes the maximum angle of the mesh;\n(2) Equiangle Skewness(2D, 3D): Equiangle Skewness is expressed as the maximum ratio of the angle of the mesh to the angle of the equiangular mesh. The angle skewness varies between 0 (good) and 1 (poor).\n(3) Aspect Ratio(2D, 3D): The hexahedral cell aspect ratio is computed from the ratio of the maximum length, width, and height and the minimum length, width, and height. The aspect ratio is always greater than or equal to 1, with a value of 1 representing a cube.\n(4) Centroid Skewness(3D): Centroid Skewness is one minus the minimum dot product between the cell face normal and the vector connecting the cell centroid and the face centroid. Values range from 0 (no-skew) to 1 (collapsed cell). This measure is only valid for block cells.\n(5) Cell Non-Orthogonality(3D): This measure operates on pairs of neighboring cells that share a face. An angle is calculated between a line connecting the two cells' centroids and the shared face's normal. The maximum value of this measure for all faces of a given cell is reported per cell. The angle shown as @ in Fig. 4."}, {"title": "A. Experimental results of 3DMeshNet in 2D structured mesh generation", "content": "Table I and Fig. 5 show the meshing results for 2D test case 1, where 3DMeshNet surpasses PINN and MGNet by achieving a lower loss. It showcases a maximum angle of 103.61 compared to PINN's and MGNet's 104.1 and a minimum angle of 76.31 against PINN's 75.86, indicating improved orthogonality. Compared with TFI and PDE methods, 3DMeshNet yields higher-quality meshes, outperforming PDE's 105.50 and 74.72. Accordingly, 3DMeshNet demonstrates superior orthogonality to both PDE and TFI methods in this test case.\nTable II and Fig. 6 illustrate the results of structured mesh generation on 2D-casel geometry using TFI, PDE, PINN, MGNet and 3DMeshNet methods. 3DMeshNet's average test set loss 0.0004 exceeds PINN's 0.0040 and MGNet's 0.003. In terms of mesh quality, 3DMeshNet has a Maximum Included Angle of 98.32 compared to PINN's 97.87 and a Minimum Included Angle of 81.72 compared to PINN's 82.13, and there appears to be no numerical advantage for 3DMeshNet. However, PINN's meshes displayed negative areas and poor boundary fitting capabilities, indicating a failure to learn the shape information accurately, and Mesh Validity is False. Moreover, 3DMeshNet exhibits a lower Skewness Equiangle of 0.09 compared to TFI's 0.31 and PDE's 0.16, indicating a lesser degree of mesh skewness."}, {"title": "B. Experimental results of 3DMeshNet in 3D structured mesh generation", "content": "In this section"}, {"title": "3DMeshNet: A Three-Dimensional Differential Neural Network for Structured Mesh Generation", "authors": ["Jiaming Peng", "Xinhai Chen", "Jie Liu"], "abstract": "Mesh generation is a crucial step in numerical simulations, significantly impacting simulation accuracy and efficiency. However, generating meshes remains time-consuming and requires expensive computational resources. In this paper, we propose a novel method, 3DMeshNet, for three-dimensional structured mesh generation. The method embeds the meshing-related differential equations into the loss function of neural networks, formulating the meshing task as an unsupervised optimization problem. It takes geometric points as input to learn the potential mapping between parametric and computational domains. After suitable offline training, 3DMeshNet can efficiently output a three-dimensional structured mesh with a user-defined number of quadrilateral/hexahedral cells through the feed-forward neural prediction. To enhance training stability and accelerate convergence, we integrate loss function reweighting through weight adjustments and gradient projection alongside applying finite difference methods to streamline derivative computations in the loss. Experiments on different cases show that 3DMeshNet is robust and fast. It outperforms neural network-based methods and yields superior meshes compared to traditional mesh partitioning methods. 3DMeshNet significantly reduces training times by up to 85% compared to other neural network-based approaches and lowers meshing overhead by 4 to 8 times relative to traditional meshing methods.", "sections": [{"title": "I. INTRODUCTION", "content": "Numerical simulation has become increasingly important in various fields of natural science research, promoting the development of modern applied scientific research and engineering technology [1], [2]. These simulations typically require the use of meshes as a fundamental geometric framework to facilitate the analysis of physical phenomena via finite element methods or other numerical techniques. Mesh generation, defined as dividing a continuous computational domain into meshes or elements for further numerical solutions, is a critical step in engineering simulations [3]. The quality of the generated mesh has a significant impact on the accuracy of numerical simulations [4]. Given the significant impact of mesh quality on these aspects, the rapid generation of high-quality meshes has become a primary concern.\nStructured meshes are widely used in numerous simulations requiring precise element alignment for high-efficiency and high-precision [5]. They present multiple benefits: (1) Structured meshes do not require additional storage to connect mesh elements, resulting in higher efficiency in data access. (2) Their structured topological nature facilitates easy control over mesh cell sizes. (3) The regularity of their structure facilitates the implementation of convolutional and pooling operations in neural networks [6]. Motivated by these benefits, extensive research has been done on structured mesh generation [7], [8]. Algebraic methods calculate mesh interior points through algebraic interpolation, employing techniques like polynomial and Transfinite Interpolation (TFI) [9]. This approach is straightforward and enables rapid mesh generation. However, it can lead to mesh degradation in areas with complex geometries, resulting in issues such as intersections. To mitigate these problems, Partial Differential Equation (PDE) methods are commonly used to generate meshes for arbitrary boundaries [8]. Given the boundary values, PDE methods pose mesh generation as a boundary value problem governed by differential equations. Meshes created using PDE methods are of higher quality but require many computational resources and are time-consuming [10]. Thus, there is a significant demand for further research and development of a rapid and robust structured mesh generation method that balances speed and mesh quality.\nIn recent years, deep neural networks (DNNs) have achieved remarkable progress in fields such as flow-field prediction [11], mesh quality determination [3], and other physical problems [12]. A few methods have been developed to incorporate neural networks into mesh generation tasks. Jilani et al. [13] proposed a two-dimensional(2D) initial mesh generated based on a Self-organizing map neural network for finite element analysis and calculation of mesh self-adaptive parameters, followed by adaptive tuning of the initial mesh using the Self-organizing map neural network. Liu et al. [14] introduced the ISpliter method, combining neural networks with segmentation lines to transform B-rep geometrical shapes into unstructured meshes and facilitating neural network training through recursive data generation. Soman S [15] employed Conditional Generative Adversarial Networks to ascertain the coordinates of mesh nodes for generating 2D and three-dimensional (3D) unstructured meshes. However, these methods often rely on large training datasets, which can be costly and complex to obtain, particularly for geometries of intricate shapes. Methods like MGNet [8], which utilize unsupervised learning for mesh generation, address the challenge of extensive manual training data requirements but still encounter problems such as unstable convergence and long training times. Additionally, pioneer researchers primarily focus on generating structured meshes in 2D, and developing neural network-based methods for 3D meshes remains an open problem.\nIn this paper, we introduce 3DMeshNet, a novel intelligent method for 3D structured mesh generation. 3DMeshNet employs a neural network embedded with 3D elliptic PDEs to learn the meshing rules for 3D mesh partitioning. Specifically, a well-designed neural network is developed to approximate the potential mapping between parametric and computational domains. The 3D elliptic PDEs and surface fitting items are embedded in the loss function, acting as penalty terms to guide the optimization of network parameters. After suitable training, 3DMeshNet can efficiently generate meshes of any specified size for the corresponding geometry using forward propagation. To reduce training time, improve surface fitting accuracy, and enhance model convergence stability, we employed finite differences (FD), loss function reweighting, and gradient projection to improve the model from three aspects. Finite differences reduce computational costs and accelerate training by efficiently computing derivatives. Loss function reweighting improved surface representation by adjusting loss terms using multi-task learning. Gradient projection reconciled gradients from different loss items. Our experiments on 2D and 3D geometries demonstrate that 3DMeshNet can effectively balance meshing overhead and mesh quality, producing high-quality meshes for complex shapes where PINN methods might struggle to maintain mesh quality. 3DMeshNet produces mesh quality that surpasses existing approaches, achieving a meshing overhead reduction of 4 to 8 times compared to TFI methods and decreasing training times by up to 85% relative to other neural network-based methods. To the best of our knowledge, this is the first work to introduce PINNs for 3D mesh generation.\nThe remainder of this paper is organized as follows: Section II reviews related work on mesh generation methods. Section III provides a detailed description of the proposed 3DMeshNet method. Section IV presents experimental results comparing different methods on two 2D geometries and four 3D geometries. Lastly, Section V concludes the paper and discusses future work."}, {"title": "II. RELATED WORK", "content": "Structured meshes provide simplicity, making them widely used in numerous simulations that necessitate precise alignment of elements as dictated by analytical requirements [16]. The demand for precision has also stimulated the development of mesh generation methods [7], [8]. The methods for generating structured meshes include conformal mapping, algebraic methods, and PDE methods [17]. Algebraic methods typically employ various interpolation techniques or special functions for mesh creation [18]. Conformal mapping, which employs angle-preserving transformations derived from complex function theory, facilitates the generation of 2D meshes by altering the computational domain. However, expanding these methods to 3D mesh generation presents significant challenges. PDE methods, on the other hand, generate meshes by solving elliptic, parabolic, or hyperbolic equations within a specified transformation domain [19]. Although the algebraic method offers simplicity and rapid mesh creation, it may lead to mesh degradation in areas of complex geometry or cause mesh elements to overlap or breach boundaries. Structured meshes generated using the differential equation method are of high quality but require high computational effort.\nArtificial intelligence represented by neural networks has been vigorously developed in recent years [20], [21]. Neural networks can autonomously learn artificial experiences and fit objective functions from high-dimensional parameter spaces, and significant progress has been made in knowledge-based physical problems during the last several years [22], [23]. Obiols-Sales O et al. [11] proposed that CFD-Net combines physical simulation and deep learning in a coupled framework to accelerate the convergence of Reynolds Averaged Navier-Stokes simulations. Neural networks are also trained to learn the lift coefficients of airfoils with various shapes under different flow Mach numbers, Reynolds numbers, and diverse angles of attack [22]. Gholami et al. [23] used neural networks along with numerical simulation to estimate flow depth variables and velocity for typical cases such as a 60\u00b0 bend in a tube. The intelligent solution of PDEs has become increasingly prevalent and impactful in academic research. The PINNs designed by Raissi M [24] et al. employ a DNN to approximate the solutions of PDEs, embedding the residuals that govern the PDE and its initial/boundary conditions within the loss function. Various variants of PINNs have been proposed to enhance their accuracy and efficiency. CanPINN [25] combines automatic and numerical differentiation in PINNs to improve training efficiency and accuracy. Meanwhile, ATLPINNs [26] address the issues of low accuracy and non-convergence in original PINNs via auxiliary-task learning. These variants aim to strengthen PINN's performance in solving PDEs.\nIn addition to applying artificial intelligence in physics for solving PDEs, some researchers have explored incorporating artificial intelligence into mesh generation, mesh quality discrimination, and other areas to overcome the limitations of automation and intelligence in traditional mesh methods. Chen [3] presented a neural network-based mesh quality indicator for 3D cylinder meshes, along with a benchmark dataset. Wang [27] developed an algorithm to convert mesh data into graph data, subsequently introducing a deep graph neural network, GMeshNet, for mesh quality evaluation. MQENet [28] is introduced as a structured mesh quality evaluation network that leverages dynamic graph attention, treating mesh evaluation as a graph classification task. Yilmaz and Kuzuoglu [29] proposed a particle swarm optimization algorithm aimed at optimizing hexahedral mesh quality, addressing the inefficacies of the Laplace mesh smoothing algorithm in concave areas. Gargallo-Peir\u00f3 A [30] suggested an optimization method for triangular and quadrilateral meshes on parameterized surfaces, focusing on node relocation to enhance mesh quality and prevent element inversion. Data-driven approaches to mesh generation have seen various implementations. Lowther et al. [31] applied neural networks to mesh density prediction in finite element mesh adaptation, using density information provided by the neural network to determine the size and placement of elements. MeshingNet [32] leverages posterior error estimates on an initial coarse mesh to predict non-uniform mesh densities for refinement. However, generating the training dataset is costly, and the model is targeted towards two-dimensional unstructured meshes. Huang et al. [33] developed a convolutional neural network to predict optimal mesh densities for diverse geometries. The validation phase required more than 60,000 simulations, supported by a training dataset of 20,000 simulations. Such extensive data demands may present challenges regarding computational resources and time allocation. Alexis Papagiannopoulos [34] introduced a neural network scheme for creating 2D simplicial meshes, using networks trained on meshed contour data to approximate vertex count, placement, and connectivity, though requiring extensive datasets for contours with a high number of vertices. Peng et al. [35] employed two Artificial Neural Networks (ANNs) trained on an initial hybrid grid to predict point advancement and control grid sizing, with the ANN-based Advancing Layer Method generating initial training grids. Kim et al. [36] utilized Graph Convolutional Neural Networks to learn local error densities and predict target mesh edge lengths, generating 16,000 control and feature meshes for training. However, these supervised learning meshing techniques necessitate significant effort in producing large training datasets, complicated by the costly creation and processing of these datasets, particularly for meshes with complex geometries or high vertex counts. Moreover, generating training data demands domain-specific expertise. Physics-informed methods utilizing unsupervised learning to minimize the need for extensive training data in mesh generation have emerged. MGNet [8] proposed an intelligent approach for structured mesh creation, which is the first application of PINNs in this field. The network is designed to unsupervisedly learn meshing rules between parametric and computational domains, requiring only boundary specifications. Nevertheless, MGNet [8] faces challenges like training instability and extended durations. Chen [7] enhanced mesh quality by modifying loss terms with an auxiliary line strategy, initially requiring the manual selection of these lines as ground truth. However, it is still oriented to a 2D problem and requires additional manual intervention for drawing auxiliary lines. MeshNet first generates a coarse mesh using the traditional method and then adds the points of the coarse mesh as data items inside the training of the PINN, improving the quality of the generated mesh [37]. However, it introduces additional overhead for computation and training. While physics-informed methods alleviate the need for extensive manual data, they encounter issues such as slow training speeds, unstable convergence, and long training times. Furthermore, most of these approaches target 2D mesh generation, leaving the intelligent generation of 3D structured mesh remains an open problem."}, {"title": "III. 3DMESHNET: A THREE-DIMENSIONAL DIFFERENTIAL NEURAL NETWORK FOR STRUCTURED MESH GENERATION", "content": "The task of structured mesh generation involves the application of a potential mapping between parametric and computational domain to a given geometry. Typically, the parametric domain, represented by the coordinates (\u03be,\u03b7,\u03b6), is defined as a basic cube [0\u00d71]\u00d7[0\u00d71]\u00d7[0\u00d71], with each edge oriented either horizontally or vertically. The primary goal of any structured mesh generation technique is to create a mapping (\u03be,\u03b7,\u03b6) to (x, y, z) between these two spaces. This mapping should be unique and smooth, ensuring that the resulting mesh accurately conforms to the geometry's boundaries that require discretization.\nIn numerical computing, algebraic methods [38] and PDE [39] methods are the two most commonly used structured mesh generation techniques. Algebraic methods use algebraic interpolation to describe the potential mapping relationship between the parametric domain (\u03be,\u03b7, \u03b6) and the computational domain (x, y, z).\nThe generation of meshes in 3D spaces through PDEs involves determining the correspondence between node coordinates in computational and parametric spaces. This is achieved by treating the process as a boundary-value problem solved by a system of elliptic PDEs. In this approach, elliptic equations are employed for 3D mesh generation. The process first solves for parametric coordinates within the parametric domain using elliptic mesh generation methods. Subsequently, these parametric meshes are transformed back into the computational domain, resulting in the acquisition of the computational surface mesh coordinates.\nThe governing differential equation is of the form of\n\u2207\u00b2\u03bei = Pi (i = 1,2,3), (1)\n\u00a7xx+\u00a7yy+\u00a7zz = P (\u03be,\u03b7, \u03b6)\nNxx+Nyy+Nzz = Q (\u03be,\u03b7, \u03b6)\n\u0160xx + \u0160yy + \u0160zz = R (\u03be,\u03b7, \u03b6) . (2)\nwhere \u2207\u00b2 denotes the Laplacian operator in Cartesian coordinate system,Pi = Pi (\u00a71,\u00a72,\u00a73), P1 = P, P2 = Q, and_P3 = R_are referred to as source terms. The source terms P, Q, and R are helpful in stretching the mesh surface (\u03be,\u03b7, \u03b6) respectively. Negative values of the source terms cause the corresponding mesh faces to move toward the decreasing curve coordinates, while positive values of the source terms have the opposite effect. Therefore, the mesh density can be adjusted by adjusting the values of the source terms.\nWe propose 3DMeshNet, a novel neural network-based approach for structured 3D mesh generation. It leverages the representation learning capabilities of neural networks to learn the rules governing mesh partitioning and determine the mapping between parametric and computational domain by encoding point coordinates through a deep network. Specifically, the network mesh partitioning rules by minimizing a weighted loss function comprising the residuals of governing differential equations and surface constraint. Once trained, 3DMeshNet can generate meshes of arbitrarily specified sizes for the corresponding geometries in a feedforward.\nThe architecture of 3DMeshNet is illustrated in Fig. 1. It comprises a Neural network and a Physics-informed learning part. The Neural network component primarily learns the rules of mesh partitioning, while the Physics-informed learning part provides physical information from the elliptic governing differential equations.\nThe input to 3DMeshNet is sampled points from the interior and surface points of the parametric domain. Each input comprises a set of 3D points= {(\u03bei,ni,\u03b6i)}=N, where N is the number of points. The network output consists of points {(xi, yi, zi)} representing the mesh in the computational domain.\nThe Neural network portion contains an input, multiple hidden, and output layers. The input layer takes training points (\u03be,\u03b7, \u03b6) and passes them to hidden layers. Within hidden layers, the network performs computations to extract high-dimensional features via Eq. 3.:\n\u03c7 = o (xk-1wk-1+bk-1), (3)\nwhere x denotes a hidden layer output, o the activation function, and W and b the layer weights and bias, respectively. Subsequently, the output layer produces computational domain coordinate predictions based on received hidden representations.\nIn the Physics-informed learning part, elliptic control equations are employed to guide the Neural network's training in learning mesh partitioning rules, with boundary conditions describing the surface fitting of the given 3D object. In the Finite Difference layer, 3DMeshNet applies the Finite Difference method, based on the Taylor series expansion, to improve efficiency in derivative computation. The loss function is determined through Loss Function Reweighting, informed by the 3D elliptical equation and Surface Fitting. Loss Function Reweighting employs a multi-task learning strategy and surface point weighting scheme to reweight the two-part loss. The multi-task learning strategy leverages homoscedastic uncertainty principles from Bayesian inference to adjust weights a according to task-specific uncertainties. The surface point weighting scheme introduces a surface point weighting scheme, assigning weights based on the Euclidean distance between predicted and actual surface points, thereby enhancing boundary mesh quality. Moreover, gradient projection effectively mitigates gradient conflict between the elliptic equation gradient and the Surface Fitting gradient. Lastly, network parameters are then updated across training sessions through loss backpropagation."}, {"title": "C. Loss Function with Finite Difference", "content": "The loss function of 3DMeshNet consists of two parts: a boundary loss for surface fitting and a 3D elliptic PDE system as basic governing differential equations. The 3D elliptic PDE provides the physical-informed learning aspect for mesh generation. By embedding the 3D elliptic PDE into the loss function, we aim to minimize it during the unsupervised learning process.\na\u2081x\u03be\u03be + a2x\u03b7\u03b7 +a3x\u03b6\u03b6 +2\u03b212x\u03be\u03b7 +2\u03b223x\u03b7\u03b6 +2\u03b231x\u03b6\u03be = 0\na1y\u03be\u03be + a2y\u03b7\u03b7 +a3y\u03b6\u03b6 +2\u03b212y\u03be\u03b7 +2\u03b223y\u03b7\u03b6 +2\u03b231y\u03b6\u03be = 0\na1z\u03be\u03be + a2z\u03b7\u03b7 +a3z\u03b6\u03b6 +2\u03b212z\u03be\u03b7 +2\u03b223z\u03b7\u03b6 +2\u03b231z\u03b6\u03be = 0 (4)\na\u2081 = (x\u00b2 + y\u00b2 + z\u00b2)(x\u00b2 + y\u00b2 + z\u00b2) - (x\u03b7x\u03b6 + y\u03b7y\u03b6 + z\u03b7z\u03b6),\na2 = (x\u00b2 + y\u00b2 + z\u00b2)(x\u00b2 + y\u00b2 + z\u00b2) - (x\u03b6x\u03be + y\u03b6y\u03be + z\u03b6z\u03be),\na3 = (x\u00b2 + y\u00b2 + z\u00b2)(x\u00b2 + y\u00b2 + z\u00b2) - (x\u03b7x\u03be + y\u03b7y\u03be + z\u03b7z\u03be),\n\u03b212 = (x\u03b7x\u03b6 + y\u03b7y\u03b6 + z\u03b7z\u03b6)(x\u03b6x\u03be + y\u03b6y\u03be + z\u03b6z\u03be) \u2013 (x\u03bex\u03b7 + y\u03bey\u03b7 + z\u03bez\u03b7)(x\u00b2 + y\u00b2 + z\u00b2),\n\u03b223 = (x\u03b6x\u03be + y\u03b6y\u03be + z\u03b6z\u03be)(x\u03b7x\u03be + y\u03b7y\u03be + z\u03b7z\u03be) \u2013 (x\u03bex\u03b6 + y\u03bey\u03b6 + z\u03bez\u03b6)(x\u00b2 + y\u00b2 + z\u00b2),\n\u03b231 = (x\u03bex\u03b7 + y\u03bey\u03b7 + z\u03bez\u03b7)(x\u03b7x\u03b6 + y\u03b7y\u03b6 + z\u03b7z\u03b6) \u2013 (x\u03b6x\u03be + y\u03b6y\u03be + z\u03b6z\u03be)(x\u00b2 + y\u00b2 + z\u00b2). (5)\nwhere x\u03be represents the first-order partial derivative of x with respect to\u03be, while x\u03be\u03b7 signifies the second-order partial derivative of x, taken sequentially first with respect to \u0121 and then n. This notation is similarly extended to other second-order derivatives. Then, the form of the loss function with governing differential equations loss and geometric surface constraint is as follows:\nLoss (x, y, z) = Loss1 + Loss2, (6)\nLoss1 = 1\u2211 {\u2223a1x\u03be\u03be + a2x\u03b7\u03b7 +a3x\u03b6\u03b6 +2\u03b212x\u03be\u03b7 +2\u03b223x\u03b7\u03b6 +2\u03b231x\u03b6\u03be\u2223\u00b2+\n\u2223a1y\u03be\u03be +a2y\u03b7\u03b7 +a3y\u03b6\u03b6 +2\u03b212y\u03be\u03b7 +2\u03b223y\u03b7\u03b6 +2\u03b231y\u03b6\u03be\u2223\u00b2+\n\u2223a1z\u03be\u03be +a2z\u03b7\u03b7 +a3z\u03b6\u03b6 +2\u03b212z\u03be\u03b7 +2\u03b223z\u03b7\u03b6 +2\u03b231z\u03b6\u03be\u2223\u00b2}, (7)\nLoss2 = 1\u2211 \u2223\u2223(xn, yn, zn) \u2013 f (\u03ben, \u03b7\u03b7, \u03b6n) \u2223\u2223\u00b2\nthe loss function is composed of two parts: the first part, Loss\u2081 is the control equation loss term, and the second part, Loss2 is the geometric surface constraint term. Here, N, and Nb represent the number of training points for the control equation and the geometric surface. (Xn, yn, Zn) denotes the coordinates of the nth actual surface point, and f (\u03be\u03b7, \u03b7\u03b7, \u03b6n) refers to the predicted value corresponding to the input at the surface point.\nTo achieve a more efficient implementation, we do not use automatic differentiation for derivative calculations because it is time-consuming [25]. Instead, we shift to using the finite differences method for calculating derivatives. The finite differences method is based on the Taylor series expansion, allowing us to compute derivatives more efficiently and effectively.\nSpecifically, the derivation formula for the finite differences method is as follows:\n\u0155g = (\u0159i+1,j,k-\u0159i-1,j,k)/2h1\n\u00cen = (\u0159i,j+1,k-\u0159i,j-1,k)/2h2\n\u0155g = (\u0159i,j,k+1 \u2212\u0159i,j,k\u22121)/2h3, (8)\n\u0155gg = (\u0159i+1,j,k\u22122\u0159i,j,k+\u0159i\u22121,j,k) /h21\nInn = (Fi,j+1,k - 2\u0159i,j,k+\u0159i,j\u22121,k)/h22\nIgg = (Fi,j,k+1-2\u0159i,j,k+\u0159i,j,k-1)/h23, (9)\n\u0393\u03be\u03b7 = (\u0159i+1,j+1,k\u2212\u0159i+1,j\u22121,k-\u0159i-1,j+1,k+ri-1,j\u22121,k), (10)\nwhere denotes the(x, y, z) vector and h1, h2, h3 represent the steps in the three spatial directions."}, {"title": "D. Loss Function Reweighting", "content": "As the loss function consists of two components, namely the Governing Differential Equation and the Surface Fitting Loss, we can consider these two optimization objectives as a multi-task optimization problem. Moreover, a significant numerical difference exists between the losses of these two parts. Weight hyper-parameters are expensive to tune and often take time for each trial. Therefore, it is desirable to find a more convenient approach that can learn the optimal weights. Consequently, We incorporate a strategy for multi-task learning as presented in source [40] to assign weight appropriately to the losses of distinct tasks.\nThe methodology utilizes homoscedastic uncertainty principles from Bayesian inference to assess and articulate the variance in confidence across tasks, enabling a sophisticated approach to loss weighting based on task-specific uncertainties. Let NN(X;0) denote the output of a neural network with input x and u is the model's output, in this paper represented as (x, y, z). We define the following probabilistic model:\np (u|NN (X;0)) = N (NN (X;0),a\u00b2), (11)\nand Eq.11 describes the conditional probability distribution of the target variable u given the input X and the neural network prediction NN(X;0). We assumes that the distribution of the target variable u follows a Gaussian distribution with mean equal to the predicted value NN(X;0) and variance a\u00b2. With the scalar a as a noise parameter. In a setting of a neural network with K tasks, the multi-objective likelihood can be written as:\np(41,...,\u0438\u043a|NN(X;0))\n= p(u1|NN(X;0))\u2026p(\u0438\u043a|NN(X;0)). (12)\nIn maximum likelihood estimation, it is often convenient to work with the natural logarithm of the likelihood function, the log likelihood can be written as:\nlogp(u|NN(X;0))\n= log 2\u03c0\u03b1\u00b2 [(2\u03c0\u03b1\u00b2) exp(-||u ||2- NN (X;0)||2)]\n= log (2\u03c0\u03b1\u00b2) $ +log [exp(-||u - NN (X;0)||2)]\n=log (2\u03c0\u03b1\u00b2(2\u03c0\u03b1\u00b2) $-||u - NN (X;0)||2 (13)\n\u03b1-||u-NN (X;0)||\u00b2-loga, (14)\nand we can therefore maximize:\nlog p (u1,...,\u0438\u043a |NN(X;0))\n= log p (u\u2081 | NN(X;0)) + ... + log p (\u0438\u043a | NN(X;0))\n= log (u\u2081;NN(X;0), a\u00b2) +...+logN (u\u03ba;NN(\u03a7;0),\u03b1\u03ba)\n=(-loga1)+...+(-logak)\n=(-loga\u00b2)+...+(-loga)\n=(L (-log (1+a)) + ... + (-L-log (1+a)). (15)\nAccording to Eq. 15, to facilitate optimization, we prefer to maximize the sum of the logarithms of these likelihoods, which simplifies to a sum of terms involving task-specific losses Li and noise parameters ai. The logarithm of a\u00b2 is modified to log(1+a2), ensuring the expression remains positive and avoids training issues where the loss might otherwise become negative. This leads to our minimization target:\nL(\u03b8,\u03b11,...,\u03b1\u03ba) = (16)\nthis objective function balances each task's loss against its uncertainty, represented by a, now a parameter to be learned alongside the neural network's weights. It allows adaptive learning of each task's importance, preventing the network from discounting easier tasks with smaller uncertainties. Additionally, the term log(1+a) acts as a regularization, averting excessively large values of a and ensuring a balanced task weighting within the multi-task learning framework.\nAnother innovation in Loss Function Reweighting is the implementation of a surface point weighting scheme. This scheme emphasizes the importance of accurately capturing surface conditions by assigning higher weights to poorly predicted surface points and lower weights to well-predicted ones. As a result, 3DMeshNet can more effectively learn and conform to surface conditions, enhancing the mesh quality at the boundaries.\nweight = \u2223\u2223(xtrue - xpre, ytrue - ypre, true \u2013 zpre)\u2223\u2223+1, (17)\nwhere (xpre, ypre, zpre) is the predicted output of the ith surface point and (xtrue, ytrue, ztrue) is the coordinates of the ith real surface point. After calculating the Euclidean distance between the predicted surface point and the real surface point, the distance is added by 1 to get the weight w = distance + 1, or directly use the distance as the weight w = distance.\nAfter introducing the loss function adaptive weighting strategy as well as the surface point weighting mechanism, the loss function of Eq. 18 can be rewritten in the following form\nLoss (x, y, z) = Loss1+ weight Loss2+log (1+a+az). (18)\nwhere, Loss\u2081 and Loss2 are equal to the loss of Equation 7.\n3DMeshNet finally uses the Eq. 18 as a loss function to guide the training of the network."}, {"title": "E. Gradient Projection", "content": "In addition to balancing the Surface Fitting loss with the Governing Differential Equation loss efficiently, our approach introduces gradient projection to address the issue of ill-conditioned gradients from a gradient perspective. Previous works, such as MGNet [8] and MeshNet [32], have focused primarily on numerical improvements to the loss function, with little exploration into enhancements from a gradient standpoint. Furthermore, upon examining the loss function, it is evident that substantial oscillations in the loss are not conducive to the optimal collection of structured mesh results. Therefore, we have incorporated the gradient projection mechanism to improve network convergence. This novel methodology offers a comprehensive solution by tackling numerical and gradient aspects, enhancing the overall efficacy of structured mesh generation.\nWe define mn as the angle between two task gradients gm and gn, and when cosmn < 0 it means that the gradients are conflicting. Specifically, mitigating the gradient conflict of the loss function can include the following steps:\n(1) Assume that the gradient of task Tm is gm and the gradient of task Tn is gn.\n(2) Determine whether gm conflicts with gn by calculating the cosine similarity between the vectors gm and gn, where a negative value indicates the gradient of the conflict. The cosine similarity is calculated as follows.\ncOS Ymn = . (19)\n(3) If the cosine similarity is negative, replace gn with its projection gre on the normal plane of gn, that is, g = PPCgn.\nIf the gradients are not conflicting, cos4mn > 0 is non-negative, and the original gradient gm is kept constant."}, {"title": "IV. EXPERIMENTAL RESULTS", "content": "In this section, we demonstrate the effectiveness of the proposed 3DMeshNet in both 2D and 3D mesh generation cases. In 2D-case1 and 2D-case2, we use a configuration with hidden layer sizes of {45,45,45}; for 3D-case1, 3D-case2, and 3D-case3, we use a configuration with {85,85,85,85} hidden layer sizes; and for 3D-case4, we use a configuration with {128,128,128,128} MLP. Tanh serves as the activation function in all cases. Due to data dimension limitations, we opt for a lightweight network model to extract features instead of employing larger-scale models. 3DMeshNet randomly samples 4000 internal points and 6000 surface points from the parametric domain for training during each training iteration, and it employs Adam and L-BFGS-B optimizers to refine network parameters. Specifically, 3DMeshNet first employs the Adam optimizer for 12000 iterations of training. The learning rate is 1e-3, and it is reduced by a factor of 0.9 every 1000 epochs. Subsequently, the L-BFGS-B is employed to optimize the model parameters further. All experiments are implemented using PyTorch. Although the training processes are conducted on the 3080Ti GPU, due to the lightweight network model, the meshing process can be performed rapidly on CPU platforms. To validate the effectiveness of 3DMeshNet, we compared it with TFI [38] and PDE [39]. As NN-based models, we also selected PINN [24] and MGNet [8] as backbones to compare mesh quality with 3DMeshNet, demonstrating its superiority in mesh generation.\nIn assessing the generated mesh quality, we employe the loss on the test set as an auxiliary indicator of the mesh quality. Additionally, we utilize a comprehensive evaluation using the following five criteria for mesh quality to determine the overall integrity of the generated mesh:\n(1) Minimum Included Angle and Maximum Included Angle(2D, 3D): Both Minimum Included Angle and Maximum Included Angle are measures of mesh skewness. For all types of meshes, Minimum Included Angle denotes the minimum angle of the mesh and Maximum Included Angle denotes the maximum angle of the mesh;\n(2) Equiangle Skewness(2D, 3D): Equiangle Skewness is expressed as the maximum ratio of the angle of the mesh to the angle of the equiangular mesh. The angle skewness varies between 0 (good) and 1 (poor).\n(3) Aspect Ratio(2D, 3D): The hexahedral cell aspect ratio is computed from the ratio of the maximum length, width, and height and the minimum length, width, and height. The aspect ratio is always greater than or equal to 1, with a value of 1 representing a cube.\n(4) Centroid Skewness(3D): Centroid Skewness is one minus the minimum dot product between the cell face normal and the vector connecting the cell centroid and the face centroid. Values range from 0 (no-skew) to 1 (collapsed cell). This measure is only valid for block cells.\n(5) Cell Non-Orthogonality(3D): This measure operates on pairs of neighboring cells that share a face. An angle is calculated between a line connecting the two cells' centroids and the shared face's normal. The maximum value of this measure for all faces of a given cell is reported per cell. The angle shown as @ in Fig. 4."}, {"title": "A. Experimental results of 3DMeshNet in 2D structured mesh generation", "content": "Table I and Fig. 5 show the meshing results for 2D test case 1, where 3DMeshNet surpasses PINN and MGNet by achieving a lower loss. It showcases a maximum angle of 103.61 compared to PINN's and MGNet's 104.1 and a minimum angle of 76.31 against PINN's 75.86, indicating improved orthogonality. Compared with TFI and PDE methods, 3DMeshNet yields higher-quality meshes, outperforming PDE's 105.50 and 74.72. Accordingly, 3DMeshNet demonstrates superior orthogonality to both PDE and TFI methods in this test case.\nTable II and Fig. 6 illustrate the results of structured mesh generation on 2D-casel geometry using TFI, PDE, PINN, MGNet and 3DMeshNet methods. 3DMeshNet's average test set loss 0.0004 exceeds PINN's 0.0040 and MGNet's 0.003. In terms of mesh quality, 3DMeshNet has a Maximum Included Angle of 98.32 compared to PINN's 97.87 and a Minimum Included Angle of 81.72 compared to PINN's 82.13, and there appears to be no numerical advantage for 3DMeshNet. However, PINN's meshes displayed negative areas and poor boundary fitting capabilities, indicating a failure to learn the shape information accurately, and Mesh Validity is False. Moreover, 3DMeshNet exhibits a lower Skewness Equiangle of 0.09 compared to TFI's 0.31 and PDE's 0.16, indicating a lesser degree of mesh skewness."}, {"title": "B. Experimental results of 3DMeshNet in 3D structured mesh generation", "content": "In this section, we perform experiments on four shapes to demonstrate the efficacy of 3DMeshNet in generating 3D structured meshes. To evaluate the quality of the generated meshes, we utilize a range of metrics, including Method, Average Test Set Loss, Minimum Included Angle, Maximum Included Angle, Skewness Equiangle, Aspect Ratio, Centroid Skewness, Cell Non-Orthogonality and Mesh Validity. Additionally, the Mesh Overhead is used to assess the efficiency of mesh generation.\nTable III and Fig. 7 demonstrate that 3DMeshNet achieves the lowest Average Test Set Loss, surpassing PINN and MGNet. Regarding mesh quality, 3DMeshNet achieves the highest Minimum Included Angle at 73.19 and the Lowest Maximum Included Angle at 107.98, indicating superior orthogonality. It also records the lowest Skewness Equiangle value at 0.19, indicative of a shape nearing the ideal equiangular configuration. A visual analysis of Fig. 7 and its detailed views showcases the significantly inferior mesh quality at the circle's corners with the TFI method relative to 3DMeshNet. In addition, the PINN method demonstrates a limited capability to fit boundaries at corners, while 3DMesh"}]}]}