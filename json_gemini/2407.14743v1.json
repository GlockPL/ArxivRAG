{"title": "Denoising Long- and Short-term Interests for Sequential Recommendation", "authors": ["Xinyu Zhang", "Beibei Li", "Beihong Jin"], "abstract": "User interests can be viewed over different time scales, mainly including stable long-term preferences and changing short-term intentions, and their combination facilitates the comprehensive sequential recommendation. However, existing work that focuses on different time scales of user modeling has ignored the negative effects of different time-scale noise, which hinders capturing actual user interests and cannot be resolved by conventional sequential denoising methods. In this paper, we propose a Long- and Short-term Interest Denoising Network (LSIDN), which employs different encoders and tailored denoising strategies to extract long- and short-term interests, respectively, achieving both comprehensive and robust user modeling. Specifically, we employ a session-level interest extraction and evolution strategy to avoid introducing inter-session behavioral noise into long-term interest modeling; we also adopt contrastive learning equipped with a homogeneous exchanging augmentation to alleviate the impact of unintentional behavioral noise on short-term interest modeling. Results of experiments on two public datasets show that LSIDN consistently outperforms state-of-the-art models and achieves significant robustness.", "sections": [{"title": "1 Introduction", "content": "Sequential Recommendation (SR) [1] has been widely used in various platforms to alleviate information overload and provide personalized services for users. The task of SR is to predict the next-item that a user will be interested in, given his/her behavior sequence. In real-world scenarios, the user's interests can be viewed over different time scales, mainly including relatively stable long-term user preferences and more variable short-term user intentions, each of which reflects the different time-scale dynamics of the user historical sequence. Some work [2, 3, 4, 5, 6, 7] has modeled both long- and short-term user interests separately and then combined them to facilitate more comprehensive user modeling, thereby improving recommendation performance.\nHowever, existing work has overlooked some non-trivial issues when modeling different time-scale user interests. Firstly, most of these studies capture user interests via ubiquitous implicit feedback, which is susceptible to various factors, such as position bias [8] and caption bias [9], leading to unintentional behavioral noise. This kind of noise is particularly harmful to the extraction of short-term user interests, which are usually extracted from a small set of most recent behaviors, thus making short-term interest modeling more vulnerable to unintentional behavioral noise. Secondly, these studies mostly capture long-term user interests via historical behaviors spanning several sessions, where a session is a sequence of behaviors in close temporal proximity [1]. As shown in Figs. 1(a) and 1(b), we have noticed that user behaviors are highly homogeneous within a session and heterogeneous across sessions, which implies that behaviors occurring in different sessions may be irrelevant to each other. Conventional long-term interest modeling usually ignores the multi-session structure of the historical sequence, so even if a certain behavior is not unintentional behavioral noise, it may introduce another form of noise by executing numerous ineffective feature interactions with behaviors in other sessions, ultimately impairing the mining of long-term user interests. We refer to this kind of noise as inter-session behavioral noise.\nThere are several studies that have explored the denoising of SR models to alleviate the harmful impact of noise. Some early attention-based work [11, 12] has utilized item-level relevance to the target item, down-weighting or directly removing items with low relevance. These methods solely rely on the target item as the denoising signals, although they filter out unintentional behaviors, they also unavoidably discard many low-relevance but non-noisy behaviors, resulting in the loss of potentially useful information. Another line of work [13, 14, 15] utilizes the sequence context as more reliable denoising signals to filter out noisy components that are inconsistent with the sequence semantics. However, these methods require rich within-sequence information"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Modeling Long- and Short-term Interests", "content": "Early deep neural network-based recommendation methods [18, 19, 20, 21] capture a holistic user interest without distinguishing between multiple interests. In realistic scenarios, the user's interests can be viewed over different time scales, including long- and short-term interests, and their combination will facilitate comprehensive user modeling [2, 3, 4, 6, 5]. For example, SHAN [2] employs a novel two-layer hierarchical attention network to learn the user's general taste and recent demand, respectively. SLi-Rec [4] improves the classical LSTM and proposes an attention-based fusion method to adaptively combine long- and short-term interests. CLSR [6] adopts contrastive learning to disentangle long- and short-term user interests. However, these methods ignore the negative influence of noise when modeling different time scales of user interests."}, {"title": "2.2 Denoising for Sequential Recommendation", "content": "Previous attention-based work [11, 12] has utilized item-level relevance to the target item, down-weighting or directly removing items with low relevance. However, these methods unavoidably discard many low-relevance but non-noisy behaviors, resulting in the loss of potentially useful information. Recently, another line of work [13, 14, 15] has made further progress by utilizing the sequence context as more reliable denoising signals to filter out noise. For example, STEAM [13] designs an item-wise corrector to explicitly correct the raw sequence. FMLP-Rec [14] introduces a filter-enhanced MLP to filter out noise components from the item representation. FEARec [15] captures behavior patterns of different frequency bands and implicitly removes noise in the frequency domain. However, these methods fail to alleviate the negative effects of different time-scale noise in the sequential recommendation."}, {"title": "2.3 Contrastive Learning", "content": "Contrastive learning [17, 22] is a branch of self-supervised learning, and it adopts data augmentation to learn high-quality and generalizable representations. For example, S\u00b3-Rec [24] uses random masks of attributes and sequences to maximize the mutual information over positive pairs. CL4SRec [25] and CLUE [26] perform crop, mask, and reorder on a sequence to obtain multiple views of the same behavior sequence. However, these traditional sequence-based augmentations may break essential item relationships or lead to fewer items, yielding less confident positive pairs, especially for short sequences."}, {"title": "3 Methodology", "content": ""}, {"title": "3.1 Problem Formulation", "content": "We denote user and item sets as U and V, respectively. For each user $u \\in U$, we have his/her temporally ordered behavior sequence $s = [v_1, v_2, ..., v_t, ..., v_{|s|}]$, where $v_t \\in s$ is the t-th interacted item of user u. Given a user's history sequence with $T - 1$ time steps, our model aims to predict the next-item $v_T$ that the user will interact with."}, {"title": "3.2 Overview", "content": "The architecture of our LSIDN is shown in Fig. 2. Firstly, we divide the user behavior sequence into sessions through the session division layer considering the multi-session structure of the historical sequence. Secondly, we use long-term and short-term interest encoders to model different time-scale user interests, respectively. Finally, we aggregate the different time-scale user interests through the fusion prediction layer and then calculate the interaction probability of the target item $v_T$. Key components and technical details are elaborated below."}, {"title": "3.3 Session Division Layer", "content": "User historical behaviors are not uniformly distributed over timestamps, and behaviors that are in close temporal proximity tend to be closely related, so we divide the historical sequence into multiple sessions. Note that, unlike session-based recommendation models [1] that focus on anonymous and individual sessions, our model is for the sequential recommendation that focuses on non-anonymous and cross-session sequences, where sessions are merely intermediate products of our model.\nFirstly, we create an item embedding matrix $E \\in R^{|V| \\times d}$, where d is the embedding size, and then $v_t$ and $s$ are embedded as $v_t \\in R^{1 \\times d}$ and $S \\in R^{|s| \\times d}$. Secondly, we adopt the session division layer, denoted as $SessDiv(\u00b7)$, to divide the sequence into sessions. Specifically, given a division threshold $\\omega$, for $\\forall v_t \\in S$, if the time interval $\\Delta t$ between $v_{t-1}$ and $v_t$ is less than $\\omega$, then $v_{t-1}$ and $v_t$ belong to the same session, otherwise, $v_{t-1}$ and $v_t$ belong to two successive sessions, respectively. As a result, $S$ is divided as follows.\n(3.1) $[S^{(1)}, S^{(2)}, ..., S^{(n)}, ..., S^{(k)}] = SessDiv(S, \\omega)$,\nwhere k is the number of sessions contained in sequence s, $S^{(n)} \\in R^{l \\times d}$ is the n-th session embedding matrix, and $l$ denotes the maximum session length."}, {"title": "3.4 Long-term Interest Encoder", "content": "After dividing the sequence into k (k is a dynamic value) sessions, we feed the earlier b (b \u2264 k) sessions into the long-term interest encoder to allow instances to be trained in mini-batches. Then we elaborate on the technical details of the long-term interest encoder in the following.\nIntra-session Interest Extractor Layer. We adopt a Transformer-based encoder [27] to extract the intra-session interest and denote it as SessEnc(\u00b7), which is shared across b sessions, i.e., $[S^{(1)}, S^{(2)}, ..., S^{(b)}]$. Given the n-th historical session $S^{(n)}$, where $n \\in [1, 2, ..., b]$, we obtain the intra-session interest $h_n$ as follows.\n(3.2)\n$h_n = AvgPooling(SessEnc(S^{(n)}))$.\nThen we can get b intra-session interests $[h_1, h_2, ..., h_b]$. By extracting session interests separately, we bypass the computation of self-attention over the whole sequence. It can be viewed as a form of local self-attention [28] that helps to avoid inter-session behavioral noise, i.e., ineffective feature interactions between irrelevant behaviors occurring in different sessions, and thus improves both the efficiency and effectiveness of interest modeling.\nInter-session Interest Evolution Layer. We adopt GRU [29], a variant of recurrent neural networks (RNNs), to capture the evolution of historical interest. Although RNNs perform well at capturing temporal dynamics, they suffer from inefficient inference time due to their low-parallelism architectures and tend to forget essential information when processing long sequences. Fortunately, we model the temporal dynamics between sessions rather than between individual items, the total number of sessions is much smaller than that of items, thereby significantly reducing inference time and relieving the information forgetting. Besides, a coarse-grained session representation compresses several fine-grained item representations, so that taking the session-level representations as input is equivalent to enlarging the receptive field of the RNN cell. We formulate inter-session interests as the hidden states of GRU as follows.\n(3.3)\n$[h_1', h_2', ..., h_b'] = GRU([h_1, h_2, ..., h_b])$.\nNext, we adopt an attention pooling operation to conduct a soft alignment between the user's multiple session-level interests and the target item $v_T$. For user's intra-session interests, i.e., $[h_1, h_2, ..., h_b]$, we have\n(3.4)\n$h_u = AttnPool(v_T, [h_1, h_2, ..., h_b]) = \\sum_{i=1}^b a_i h_i$,\n$a_i = \\frac{exp(h_i W v_T^T)}{\\sum_{j=1}^b exp(h_j W v_T^T)}$,\nwhere $W \\in R^{d \\times d}$ are learnable parameters. Similarly, we also perform the above attention pooling operation on the user's inter-session interests, i.e., $[h_1', h_2', ..., h_b']$, to obtain the aggregated representation $u_h'$. Finally, the user's long-term interest can be expressed as\n(3.5)\n$u^L = Concat(u_h, u_h')$."}, {"title": "3.5 Short-term Interest Encoder", "content": "We use the current session $S^{(k)}$ for short-term interest modeling. However, some current sessions contain only one or two items and thus lack clues for user modeling. Hence, we take the latest r (r<T\u22121) items, i.e., the recent sub-sequence $S^r$, as the complementary input. The technical details of the short-term interest encoder are described below.\nCurrent Session Interest Extractor Layer. We utilize an encoder that has the same structure as SessEnc(\u00b7) in Eq. 3.2 and denote it as SessEnc'(\u00b7). Then we get the current session interest $u^s$ as follows.\n(3.6)\n$u^s = AvgPooling(SessEnc'(S^{(k)}))$.\nHowever, the limited length makes the current session more sensitive to unintentional behavior noise, so we adopt contrastive learning to enhance the robustness of the representation. However, as shown in the left part of Fig. 3, traditional sequential augmentations [17] may break essential item relationships or lead to fewer items in sequences, thus yielding less confident positive pairs and impairing the quality of the learned representation, especially for short sequences. Considering that short-term interest modeling usually relies on limited recent behaviors, we propose a new data augmentation method tailored for short sequences, which uses the suffixes of the original current session as additional information to create reliable self-supervised signals.\nAs shown in the center part of Fig. 3, most SR methods adopt a sequence preprocessing method [30] to enhance training by generating a collection of prefixes with corresponding new targets as new training instances, while discarding the suffixes, i.e., future data after the corresponding new targets. As we can see, the future data are accessible during training and worth exploiting. Therefore, in the training phase, we specify that the current session $S^{(k)}$ contains a past sub-session $S_p^{(k)}$ before the target item and a future sub-session $S_f^{(k)}$ after it; while during inference, the future data are inaccessible, thus $S_f^{(k)} = S^{(k)}$. Due to the homogeneity of intra-session behaviors, the user's interests in the past and future sub-sessions are highly similar, so we randomly exchange items from the two sub-sessions to build positive pairs. As shown in the right part of Fig. 3, firstly, we randomly select a certain proportion of items from the past and future sub-sessions, respectively. Secondly, we exchange these selected items and merge them with the reserved items of the other side. Finally, we sort the two merged sessions by timestamp to obtain the augmented positive pairs. This homogeneous exchanging augmentation method is formulated as\n$S_p^{(k)} = T_{merge}(T_{select}(S_p^{(k)}, \\gamma), S_f^{(k)})$, $S_f^{(k)} = T_{merge}(T_{select}(S_f^{(k)}, \\gamma), S_p^{(k)})$,\\\n(3.7) $\\hat{S}_p^{(k)} = T_{delete}(S^{(k)}, S_f^{(k)})$, $\\hat{S}_f^{(k)} = T_{delete}(S^{(k)}, S_p^{(k)})$,\\\n$\\tilde{S}_p^{(k)} = T_{sort}(\\hat{S}_p^{(k)} \\cup S_p^{(k)})$, $\\tilde{S}_f^{(k)} = T_{sort}(\\hat{S}_f^{(k)} \\cup S_f^{(k)})$,\\\nwhere $\\gamma$ denotes the selection ratio and $\\cup$ denotes the merge operation. During training, let B denotes a mini-batch of training instances, which includes B current sessions, each session containing a past and a corresponding future sub-session. Given the i-th current session, both its past and future sub-sessions, i.e., $S_p^{(k)}$ and $S_f^{(k)}$, will adopt homogeneous exchanging augmentation method to obtain positive pairs, i.e., $\\tilde{S}_p^{(k)}$ and $\\tilde{S}_f^{(k)}$, which are then fed into SessEnc'(\u00b7) to get the representations, i.e., $u_p^s$ and $u_f^s$. Following [16], ($u_p^s$, $u_f^s$) is treated as a positive pair, while $u_p^s$ with the other 2(|B| - 1) augmented representations are considered as negative pairs for this pair. We adopt the NT-Xent loss [16] for optimization as follows.\n(3.8)\n$L_{ssl}(u_p^s, u_{f_i}^s) = -log\\frac{exp(sim(u_p^s, u_{f_i}^s)/\\tau)}{\\sum_{j \\neq i} exp(sim(u_p^s, u_{j_i}^s)/\\tau)}$,\nwhere $\\mathbb{I}_{[j\\neq i]} \\in {0,1}$ is an indicator function, sim(\u00b7) is a dot product, $\\tau$ denotes $p$ or $f$, and $\\tau$ is a temperature index. It is worth mentioning that we only calculate $L_{ssl}$ for training instances that contain both past and future sub-sessions.\nRecent Interest Evolution Layer. We take the latest r (r<T \u2212 1) items as the recent sub-sequence, i.e., $S^r = [v_{T-r-1}, v_{T-r}, ..., v_{T-1}]$. We employ Time4LSTM [4] combined with the attention pooling in Eq. 3.4 to obtain recent user interest $u''$ as follows.\n(3.9)\n$u'' = AttnPool(v_T, Time4LSTM(S^r))$.\nWe set the recent interest evolution layer as an option to be used only when the current session is extremely short, and also set r as small as possible to balance effectiveness and efficiency. Finally, the short-term user interest is expressed as:\n(3.10)\n$u^s = Concat(u'', u^s)$."}, {"title": "3.6 Fusion Prediction Layer", "content": "Instead of using simple aggregators (e.g., summing and concatenation), we adaptively aggregate long- and short-term interests for information fusion, considering the target item $v_T$ and the trade-off between different time-scale interests [4].\n$\\alpha = Sigmoid(W_m^TConcat(u^L, u^s, v_T) + b_m)$,\\\n(3.11)\n$u^{LS} = \\alpha u^L + (1 - \\alpha)u^s$,\\\nwhere $W_m$ and $b_m$ are learnable parameters. Finally, we use the widely adopted two-layer MLP [6] to predict the score of the target item $v_T$.\n(3.12)\n$\\hat{y}_{u,v} = Sigmoid(MLP(Concat(u^{LS}, v_T)))$.\nWe use the negative log-likelihood loss [4, 6] as follows.\n(3.13)\n$L_{main}(u,v) = - \\sum_{(u,v) \\in O}[y_{u,v} log(\\hat{y}_{u,v}) + (1 - y_{u,v})log(1 - \\hat{y}_{u,v})]$,\nwhere O is the set of training instances, containing a positive item $v_T$ that the user has interacted with, and N \u2212 1 negative items that are sampled within a batch. Finally, we use a multi-task strategy to optimize the above two objectives:\n(3.14) $L = L_{main} + \\lambda L_{ssl} + \\beta||\\Theta||^2$,\nwhere $\\Theta$ denotes the set of trainable parameters, $||\u00b7||^2$ denotes the L2 regularization, $\\lambda$ and $\\beta$ are used to control the strength of $L_{ssl}$ and L2 regularization."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Experimental Settings", "content": "We elaborate on the details of experimental setups as follows.\nDatasets. We conduct experiments on two public e-commerce datasets, i.e., Taobao\u2217 and Fliggy\u2020. Both of them include behaviors such as click, favorite, add-to-cart, and purchase. Details of the datasets are listed in Table 1. The Taobao dataset, collected from the largest online shopping platform in China, includes user-item interactions from 25/11/2017 to 4/12/2017. We use interactions before 1st Dec for training and interactions from the last 2 days for validation and testing, respectively. The Fliggy dataset, provided by one of the most popular online travel platforms in China, contains user-item interactions from 3/6/2019 to 3/6/2021. We use the first 18 months of interactions for training, the following 3 months for validation, and the final 3 months for testing. We leverage the same preprocessing and negative sampling methods as [6].\nBaselines and Metrics. We compare LSIDN with recommendation models of various research lines: (i) simple holistic interest models that neither distinguish between different time-scale user interests nor consider denoising, i.e., NCF [18], DIN [19], Caser [20], and GRU4Rec [21]; (ii) long- and short-term interest models without denoising components, i.e., SLi-Rec [4] and CLSR [6]; (iii) denoising sequential models that do not distinguish between different time-scale user interests, i.e., FMLP-Rec [14] and FEARec [15]. We evaluate these models with two accuracy metrics, i.e., AUC and GAUC, and two ranking metrics, i.e., MRR and NDCG@K, here K = {5,10}.\nImplementation Details. For a fair comparison, we implement all models with the Microsoft Recommenders framework [31] that is based on TensorFlow. We initialize all models with a normal distribution in the range [-0.01, 0.01] and use the early stopping strategy of [6]. We set the embedding size, the batch size, and the maximum sequence length to 40, 500, and 50 for all models. Particularly for LSIDN, we set b = 5 and r = 10 for both datasets. We use a grid search to find the best hyper-parameters. Finally, \u03b2, \u03bb, \u03b3, and r are respectively set to 0.1, 0.1, 0.4, and 30 for Taobao and Fliggy; \u03c4 is 0.2 for Taobao and 0.8 for Fliggy, \u03c9 is 360 minutes for Taobao and 5 days for Fliggy."}, {"title": "4.2 Performance Comparison", "content": "We list the performance of all models in Table 2 and obtain the following observation. Firstly, the long- and short-term interest models, i.e., SLi-Rec and CLSR, outperform the simple holistic interest models in most cases, demonstrating the superiority of jointly modeling different time scales of user interests. Secondly, the denoising sequential models outperform the above non-denoising models in most cases, indicating the importance of denoising components. Thirdly, the proposed LSIDN exceeds all baselines by a large margin in all cases. This is attributed to the combination of different time-scale user interests and the implementation of corresponding time-scale denoising strategies, allowing for more comprehensive and robust user modeling."}, {"title": "4.3 Ablation Study", "content": "To demonstrate how each key component of LSIDN impacts overall performance, we design several LSIDN variants by removing certain components for comparisons, including (1) w/o LD: removing long-term denoising strategy (i.e., directly feeding the user behavior sequence into the encoder without session division), (2) w/o SD: removing short-term denoising components (i.e., removing the contrastive learning), (3) w/o RI: without the recent interest evolution layer, (4) w/o CI: without the current session interest extraction layer, (5) w/o LI: without the long-term interest encoder, (6) w/o SI: without the short-term interest encoder.\nFrom Table 3, we find that removing any key component of LSIDN will result in performance degradation. Besides, we have the following observations. Firstly, the short-term interest encoder contributes more to performance than the long-term interest encoder, meanwhile, for the two components of the short-term interest encoder, i.e., current session interest extraction layer and the recent interest evolution layer, the former is more important than the latter. These observations are more evident in Fliggy, which may be due to the low-frequency nature of the travel scenario, making user modeling more reliant on the most recent behaviors. Secondly, our proposed different time-scale denoising strategies are more effective in Taobao. This may be because, in the shopping scenario, the goods are more abundant and diverse, thus user behaviors are more susceptible to various distractions and also more heterogeneous across sessions, which exacerbates the noise problem and makes our denoising strategies more useful."}, {"title": "4.4 Long- and Short-term Interest Analysis", "content": "Taking the Taobao dataset as an example, we conduct further experiments to thoroughly analyze whether LSIDN captures effective and meaningful long- and short-term interest representations, respectively, by comparing LSIDN with two other long- and short-term interest models, i.e., CLSR and SLi-Rec.\nFirstly, given each of the three models, we separately construct two variants, i.e., Long (removing the short-term interest encoder) and Short (removing the long-term interest encoder), and we denote the original model as Both. From Figs. 4(a) and 4(b), we can see that LSIDN outperforms SLi-Rec and CLSR in all cases, revealing that LSIDN learns more effective long- and short-term interests than the other two models. Secondly, we find that previous work [32] claims that expensive behaviors (i.e., purchases) tend to be driven more by stable long-term user preferences, whereas cheap behaviors (i.e., clicks) are more likely to imply variable short-term user intentions; also, we find that SLi-Rec, CLSR, and LSIDN all have an adaptive weight \u03b1, whose value depends on the sequence context and reflects the importance of the user's long-term interest. Inspired by this, we use each of the three previously trained models to make predictions for click and purchase items, respectively. We believe that if a certain one of the three models captures meaningful long- and short-term interests, then the Avg. \u03b1 of the model on purchase items should be larger than its Avg. \u03b1 on click items. From Fig. 4(c), we find that only LSIDN meets our expectations, suggesting that LSIDN has learned more meaningful long- and short-term interests than SLi-Rec and CLSR. And from Figs. 4(d) and 4(e), LSIDN outperforms the other two models in both the purchase and click datasets, further demonstrating its superiority in long- and short-term user modeling."}, {"title": "4.5 Robustness Analysis", "content": "To evaluate the robustness of LSIDN and other methods, we modify the Taobao datasets as follows: contaminate the training and validation sets by adding a proportion of adversarial instances (i.e., 10%, 20%, and 30% negative user-item interactions), while keeping the test set unchanged.\nFirstly, we compare the robustness of LSIDN and several baseline models. As shown in Fig. 5(a), the simple holistic interest model, i.e., GRU4Rec, shows poor noise resistance, while FMLP-Rec and CLSR perform better, indicating that either denoising designs or joint modeling of different time-scale interests can improve model robustness. Importantly, LSIDN performs best in all cases due to its robust and comprehensive user modeling. Secondly, we investigate the effect of different time-scale denoising strategies employed in LSIDN. As shown in Fig. 5(b), we can see that after removing the denoising strategy in short-term interest modeling (i.e., w/o SD), performance declines faster as the noise rate increases, proving the effectiveness of contrastive learning in denoising; after removing the denoising strategy in long-term interest modeling (i.e., w/o LD), the evaluation metric significantly decreases due to the introduced inter-session interference, but the noise resistance is comparable to original LSIDN due to reserved short-term denoising component. Finally, we replace our augmentation with traditional augmentation methods (i.e., crop, mask, and reorder) for comparisons, denoted as LSIDN w/ C, LSIDN w/ M, and LSIDN w/ R, respectively. As shown in Fig. 5(c), we can see that the original LSIDN outperforms its variants in terms of evaluation metrics and noise resistance, further demonstrating the superiority of our augmentation method."}, {"title": "4.6 Hyper-parameter Sensitivity", "content": "We investigate the effect of three important hyperparameters on model performance, including (i) the temperature index \u03c4, which plays a critical role in mining hard negatives [17]. As shown in Fig. 6(a), when \u03c4 = 0.2, LSIDN performs the best, whereas smaller or larger values will result in poor performance; (ii) the contrastive loss weight \u03bb, which controls the strength of contrastive regularization, too large \u03bb will conflict with the main task and too small \u03bb will lead to ineffective regularization. The results shown in Fig. 6(b) support the view of point, where the optimal value of \u03bb is 0.1; (iii) the session division threshold \u03c9, which controls the division criteria of the user behavior sequence, small \u03c9 leads to oversegmentation while large \u03c9 leads to under-segmentation, both of which make segmented sessions sub-optimal for representing session-level interests. As shown in Fig. 6(c), 360 minutes is the best for \u03c9, while smaller or larger values both impair performance. Note that we keep all other hyperparameters optimal when investigating each hyperparameter."}, {"title": "5 Conclusion", "content": "In this paper, we propose a long- and short-term interest denoising network, which employs different encoders and tailored denoising strategies to extract different time-scale user interests, respectively, thus achieve more comprehensive and robust user modeling. Specifically, we employ a session-level interest extraction and evolution strategy to avoid introducing inter-session behavioral noise into long-term interest modeling; we also resort to contrastive learning equipped with a novel augmentation method tailored for short sequences to alleviate the impact of unintentional behavioral noise on short-term interest modeling. Extensive results show that LSIDN consistently outperforms state-of-the-art models and achieves significant robustness."}]}