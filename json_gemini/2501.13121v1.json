{"title": "EPISODIC MEMORIES GENERATION AND EVALUATION BENCHMARK FOR LARGE LANGUAGE MODELS", "authors": ["Alexis Huet", "Zied Ben Houidi", "Dario Rossi"], "abstract": "Episodic memory \u2013 the ability to recall specific events grounded in time and space \u2013 is a cornerstone of human cognition, enabling not only coherent storytelling, but also planning and decision-making. Despite their remarkable capabilities, Large Language Models (LLMs) lack a robust mechanism for episodic memory: we argue that integrating episodic memory capabilities into LLM is essential for advancing AI towards human-like cognition, increasing their potential to reason consistently and ground their output in real-world episodic events, hence avoiding confabulations. To address this challenge, we introduce a comprehensive framework to model and evaluate LLM episodic memory capabilities. Drawing inspiration from cognitive science, we develop a structured approach to represent episodic events, encapsulating temporal and spatial contexts, involved entities, and detailed descriptions. We synthesize a unique episodic memory benchmark, free from contamination, and release open source code and datasets to assess LLM performance across various recall and episodic reasoning tasks. Our evaluation of state-of-the-art models, including GPT-4 and Claude variants, Llama 3.1, and 01-mini, reveals that even the most advanced LLMs struggle with episodic memory tasks, particularly when dealing with multiple related events or complex spatio-temporal relationships \u2013 even in contexts as short as 10k-100k tokens.", "sections": [{"title": "1 INTRODUCTION", "content": "Episodic memory \u2013 the ability to recall specific events grounded in time and space \u2013 is a cornerstone of human cognition. Unlike semantic memory, which stores general knowledge, episodic memory is intimately tied to time, space, and details of specific events (Tulving et al., 1972; Tulving & Thomson, 1973). Both memories are declarative, activated through cues - specific triggers that can bring back other facts (semantic) or a rich recollection of past events (episodic). For instance, hearing the word \"birds\" can call for \u201cfly\u201d; while hearing \u201cFrance\" might remind someone of their first trip abroad, bringing back details of that entire event.\nEpisodic memory is not only vital for personal identity and coherent storytelling but also plays a crucial role in planning (Pfeiffer & Foster, 2013; \u00d3lafsd\u00f3ttir et al., 2015), reasoning (Dusek &\nEichenbaum, 1997) and decision-making (Barron et al., 2013). It enables individuals to track the\nstates of entities they care about, on both physical (Burgess et al., 2002) and virtual space (e.g. virtual\nreality (Cushman et al., 2008), digital folders Benn et al. (2015)). It further enables envisioning future\nscenarios through mental time travel, a process known as future episodic thinking (Atance & O'Neill,\n2001; Schacter & Madore, 2016). The critical role of spatio-temporal processing in episodic memory\nis exemplified best by the hippocampus, a specialized brain region that acts as a cognitive map and\nspatio-temporal index (O'Keefe & Nadel, 1978; Teyler & DiScenna, 1986), needed for forming (and\nnavigating through) past, present and future episodic memories (Tanaka et al., 2014; Teyler & Rudy,\n2007). It is within the hippocampal formation that neuroscience research has identified specialized\nspace and time neurons: place cells, which fire when we occupy specific locations (O'Keefe &\nDostrovsky, 1971), but also express current, past and future locations (Moser et al., 2015); grid cells,\nwhich create a coordinate system for spatial navigation (Hafting et al., 2005); and time cells, which\nsegment events into distinct temporal sequences (MacDonald et al., 2011)."}, {"title": "2 RELATED WORK", "content": "For brevity, we summarize here and refer the reader to Appendix A for a broader overview."}, {"title": "3 MODELING EPISODIC MEMORY FOR LANGUAGE MODELS", "content": "Inspired by human episodic memory (Tulving et al., 1972), we model episodic memory for LLMs\nusing two key components, namely entities and events. Our goals are to (i) create appropriate episodic\nevents, (ii) design systematic memory tasks, and (iii) develop methods to evaluate the ability of LLMs\nto recall these events accurately. Similarly to human memory tests, we construct tasks and scenarios"}, {"title": "3.1 ENTITIES, EPISODIC EVENTS AND WORLD MODELING", "content": "Entities. Entities (enti) are fundamental subjects in the world, that can participate in or be affected by\nevents: their attributes or relationships may change over time due to episodic events. More generally,\neach entity has an associated state statej,t at any discrete time t. This state evolves based on events\nand includes all details about the entity at a given time, such as its location and any observation such\nas actions or interactions. The latest state of an entity is denoted as statej,L, where L denotes the\nlatest point in time.\nEpisodic events. Episodic events (eventi) transcend the scope of the current benchmark, and\nare defined as actions or observations that lead to changes in the state of the world or its entities,\nincluding the mere progression of time. Specifically, each event eventi is characterized by a tuple\n(ti, si, enti, ci), where ti represents the time at which the event occurs, si the location where the\nevent takes place, enti the set of entities involved in the event, and finally ci corresponds to the\nevent content, detailing what happened. This formulation captures the essential elements of episodic\nmemory: what happened, where and when.\nWorld model. This model of episodic events and entities aligns with the hippocampus's role in\nmaintaining a dynamic cognitive map of the world. By tracking the states of entities across time\nand space, our framework mirrors the brain's process of continuously updating its representation of\nthe environment based on new experiences. This approach not only captures the context, space and\ntemporal properties of events, but also how these events transform our understanding of the world\nand its constituents. In line with the encoding specificity principle (Tulving & Thomson, 1973), each\nevent is associated with specific details that differentiate it from others: parts of these details will\nserve as retrieval cues during memory tasks. Now in LLMs, these episodic memory components are\nrepresented as sentences or paragraphs describing the events, and entity states are inferred from the\ncontext provided in the text."}, {"title": "3.2 SYSTEMATIC TASK DESIGN: CUE-BASED RECALL AND RETRIEVAL", "content": "We model cue-based recall as a key-value retrieval system, where the cue (key) is any combination of\nelements from the event tuple (ti, si, enti, ci), and the associated event details serve as the memory\ntrace (value). By systematically varying the cues, we can assess the model's ability to retrieve specific\ninformation based on different aspects of the events.\nCue composition and retrieval types. To create a comprehensive set of tasks, we consider all\npossible combinations of the event tuple elements as cues. For instance, a cue of (t, *, *, *) would\nprompt the retrieval of events that occurred at a specific time t, while a cue of (*, s, *, *), as shown\nin Fig. 1, would query for events that took place at a particular location s. Tab. 1 presents example\ncombinations of different cue compositions, the descriptions of the tasks, the types of information to\nbe retrieved, showing a few templated questions from our actual implementation for each case (the\nfull list is deferred to Tab. 10 in the Appendix; example question/answer pairs from the templates are\nshown in Appendix C).\nEncoding specificity principle and cue overload. According to the encoding specificity princi-\nple (Tulving & Thomson, 1973), the effectiveness of a retrieval cue depends on its similarity to\nthe original encoding context. Specific cues that closely match the encoded event lead to precise\nretrieval, while broader cues may result in interference with other events sharing similar features, a\nphenomenon known as cue overload. By varying the specificity of the cues as exemplified in Tab. 1,\nwe test the model's ability to handle both precise and ambiguous queries. For example, a highly"}, {"title": "4 BENCHMARK DESIGN", "content": "In this section, we detail the design of our episodic memory benchmark, adhering to the requirements\noutlined in Sec. 3. The benchmark comprises three key components: (i) the memories to encode,\nrepresented by evidence documents, (ii) a set of question-answer pairs designed to probe episodic\nmemory, and (iii) an evaluation strategy to assess model performance.\nWe introduce a novel methodology that generates synthetic documents using a Large Language Model\n(LLM), structured as a coherent narrative akin to a real book. Each chapter presents a logical flow\nand progression of a story while while maintaining controlled ground truth information, which is\nstrategically distributed over several paragraphs.\nThis approach distinguishes our benchmark from previous designs, such as the bAbI tasks (Weston\net al., 2015), which use a world model but lack coherent storytelling, and from real books, where\nground truth information cannot be controlled and data contamination is a concern. The questions\nin our benchmark are designed to follow the episodic memory recall process highlighted in Fig. 1:\neach question is based on a cue that triggers the retrieval of relevant events, from which specific\ninformation is extracted."}, {"title": "4.1 BUILDING THE MEMORIES TO ENCODE", "content": "We begin by constructing a static universe comprising a finite $N_{universe} = 100$ set of dates (t), locations\n(s), entities (ent), and event contents (c). These elements are carefully curated to ensure diversity and\nuniqueness. From this universe, we sample $N_{events}$ synthetic events, each serving as the foundation for"}, {"title": "4.2 BUILDING THE QUESTION-ANSWER PAIRS", "content": "We implement a template-based approach to create questions aligned with our episodic memory tasks.\nEach question is defined by a cue composition (the trigger key identifying a set of events), a trace (the\ntype of information to be retrieved from each remembered event), and the retrieval mode (whether all\nelements are needed, only the latest state, or their chronological order), as exemplified in Fig. 1 and\ndetailed fully in Appendix B.2.\nWe consider all combinations of cues and traces for the retrieval of all elements, focusing on entity\ncues for the latest and chronological retrievals. Examples of question templates are provided in Tab. 1\n(full list available in Tab. 10 in the Appendix). The templates are populated using the dates, locations,\nentities, and event contents appearing in each chapter. All questions are associated with known\nground truth answers, as the event details are controlled and known (examples of question/answer\npairs are shown in Appendix C). To test for hallucinations, we include additional questions with\nempty answers, using entities or combinations of items that do not exist in the document. This allows\nus to assess the model's ability to handle unfamiliarity and avoid confabulation.\nTo ensure variety in the number of events to be recalled, we filter the corpus of questions to balance\nthe number of queries that correspond to zero, one, two, three to five, and more than five events. More\ndetails on this process are provided in Appendix B.2.4."}, {"title": "4.3 EVALUATION STRATEGY", "content": "Our evaluation strategy employs an LLM-as-a-judge approach to assess the correctness of the model's\nanswers. The evaluator LLM is prompted to perform two key tasks: First, it (i) identifies relevant\nitems by extracting them as a list from the AI-generated answer for each question, allowing us\nto evaluate the number of predicted items. Second, it (ii) scores the relevance of these predicted\nanswers against each ground truth item, with the sum of the scores interpreted as the number of\ntrue positives. We defer details to Appendix B.3, but in essence, we are using the LLM for simple\nsemantic comparisons, and not as a judge making subjective assessments. Then, from these predicted\nand ground truth answers, we compute an optimistic F1-score bound (our primary comparison metric)\nusing a lenient methodology detailed in Appendix B.3.2. For chronological questions, we additionally\nuse Kendall's \u03c4 coefficient: this is applied only to answers that fully match the ground truth, allowing\nus to assess the correctness of the ordering within this matching set."}, {"title": "4.4 GENERATED BENCHMARK", "content": "Using the proposed world modeling framework, we generate two synthetic documents, referred to\nas the short book and the long book, summarized in Tab. 2. The long book includes 196 unique\nevents across 37 dates, 35 locations, 34 entities and 34 event contents. We generate a total of 686\nquestions, balanced across cue compositions and retrieval types, to evaluate the model's episodic\nmemory capabilities; the complexity of the questions is also controlled by varying the number of\nrelated events. Note that we explicitly limit the size of the book, since as we shall see, current state of\nthe art LLMs start struggling with a relatively modest size\u00b3."}, {"title": "5 BASELINE RESULTS", "content": "5.1 BASELINE MODELS AND MEMORY STRATEGIES\nAs baseline models for our benchmark, we evaluate several LLMs, including GPT-40, GPT-40-mini,\nClaude 3 Haiku, Claude 3.5 Sonnet, Llama 3.1 405B (instruct) and the recent o1-mini. We consider\nmemory in LLMs as functioning through three primary forms: (1) In-Context Memory, where\ninformation is processed within the model's context window; (2) Retrieval-Augmented Generation\n(RAG), where external memory is accessed through a vector database; and (3) Parametric Memory\nvia Fine-Tuning, where memory is stored within the model's parameters.\nFor (1) in-context memory, we prepend the full document to the question, allowing the model to\nprocess the entire context. With (2) RAG, we chunk the book into paragraphs\u2074, each labeled with\ncontext (e.g., \"Chapter X, Paragraph Y\"), and embed them using text-embedding-3-small. For each\nquestion, we retrieve the top-K paragraphs based on cosine similarity to the question's embedding\nand prepend them to the question as context. Lastly, (3) we fine-tune models\u2075 using all single-event\nquestion-answer pairs as training data (details in Appendix B.2.5). In principle, this approach enables\nmodels to acquire knowledge for all benchmark questions (including multi-event questions).\n5.2 EXPERIMENTAL RESULTS\nWe evaluate the performance of various models and memory strategies on our benchmark. We mostly\nreport results on the long book and defer an extended set of results to Appendix E.\nOverall performance comparison. Using the F1-score as our primary metric, we compare models\nand strategies across all questions. Fig. 3 shows the Critical Difference (CD) plot based on the\nWilcoxon signed-rank test (Benavoli et al., 2016) between each pair of algorithm (adjusted by Holm's\nmethod) that allows to rank models according to their average performance on the long book in a\nprincipled manner. GPT-4o with in-context memory and Claude 3.5 Sonnet with RAG memory\nachieve the highest average ranks, with no statistically significant difference between them. Notably,\nexcept for GPT-40, models utilizing RAG generally outperform their in-context counterparts, suggest-\ning that retrieval methods can enhance episodic memory capabilities by effectively narrowing down\nthe relevant context for each query. As information spans several paragraphs, retrieval granularity\n(i.e., paragraph vs chapter) may play an important role (see ablation study in Appendix E.2).\nPerformance on recall tasks. We next test the ability of recalling episodic memory, by reporting in\nTab. 3 the average F1-scores for simple recall questions as a function of the number of events that\nmatch the cue (extended analysis in Appendix E.1).\nAvoiding confabulation. The 150 questions with 0 matching events are intentionally designed to test\nfamiliarity awareness. We see that no model achieves a perfect F1-score in avoiding hallucinations:"}, {"title": "6 SUMMARY AND LIMITATIONS", "content": "In this work, we draw inspiration from cognitive science to build a new episodic memory model for\nLLMs, generate a comprehensive benchmark, and evaluate state-of-the-art models. Our findings\nreveal significant gaps in the episodic memory capabilities of state-of-the-art LLMs, particularly\nwhen handling multiple related events and complex spatio-temporal relationships. These challenges\nreflect aspects of human memory where more distinctive cues facilitate easier retrieval. Furthermore,\nnaive finetuning fails to achieve a deep understanding of episodic events and their intricate relations,\nmerely overfitting to single learned facts. These challenges highlight the need for fundamentally new\napproaches to model design and training that more closely emulate the dynamic and contextual nature\nof the human episodic memory. The proposed episodic memory benchmark exhibits several desirable\nproperties: it is contamination-free by design, scalable with low human labor, offers unambiguous\ncues and ground truth, and the ability to model multiple cues and events within a synthetic yet realistic\nnarrative. However, we acknowledge limitations that open avenues for future research.\nTemporal representation. Our benchmark relies on explicit temporal markers, which may not fully\ncapture the nuanced ways time is expressed in natural language (e.g. \"yesterday\", \"last week\", or\n\"after the party\"). Future iterations should incorporate implicit and relative temporal references to\nfurther challenge the models.\nEvent independence. The independent generation of chapters, while facilitating control, does not\ncapture the interconnected and causal nature of real-world events.\nLimited domain scope. Our benchmark primarily involves human-like protagonists within fictional\ncontexts. Extending the framework to include diverse domains (e.g., software projects, virtual\nenvironments) would test models' ability to generalize episodic memory capabilities.\nTraining limitations. The observed performance limitations suggest that current fine-tuning method-\nologies may not be optimally suited for episodic memory tasks, underscoring the need for developing\nnew strategies for the broad scientific community."}, {"title": "H DISCLAIMER", "content": "This benchmark is a work of fiction. Unless otherwise indicated, all the names, characters, businesses,\nplaces, events and incidents in this book are used in a fictitious manner. Any resemblance to actual\npersons, living or dead, or actual events is purely coincidental."}]}