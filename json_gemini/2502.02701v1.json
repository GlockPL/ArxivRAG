{"title": "Practically Effective Adjustment Variable Selection in Causal Inference", "authors": ["Atsushi Noda", "Takashi Isozaki"], "abstract": "In the estimation of causal effects, one common method for removing the influence of confounders is to adjust the variables that satisfy the back-door criterion. However, it is not always possible to uniquely determine sets of such variables. Moreover, real-world data is almost always limited, which means it may be insufficient for statistical estimation. Therefore, we propose criteria for selecting variables from a list of candidate adjustment variables along with an algorithm to prevent accuracy degradation in causal effect estimation. We initially focus on directed acyclic graphs (DAGs) and then outlines specific steps for applying this method to completed partially directed acyclic graphs (CPDAGs). We also present and prove a theorem on causal effect computation possibility in CPDAGs. Finally, we demonstrate the practical utility of our method using both existing and artificial data.", "sections": [{"title": "1. Introduction", "content": "Machine learning techniques such as deep learning have shown great proficiency at prediction or classification that outputs values or labels based on multiple input variables. Applications such as recommending new products that consumers are likely to buy based on their purchase logs and identifying defective products based on quality inspection data are now widely utilized throughout the world. At the same time, when considering the effects of government economic policies, medical drug treatments, business marketing strategies, or the improvement of quality defects in manufacturing, it has become crucial to estimate causal effects and to understand what would happen if a particular action were taken. However, general predictive analysis does not consider causal relationships between variables when learning the mapping from inputs to outputs, making it impossible to perform such causal effect calculations. In order to accurately capture such causal relationships and complex interactions, a theoretical"}, {"title": "2. Preliminaries", "content": "In this section, we present a model for graphically representing causal relationships. First, we describe nodes and edges as elements of graphs and their associated notations. Then, we explain how to compute causal interventions based on graph structures and the back-door criterion that is important for the computation."}, {"title": "2.1. Basics of graphical representation", "content": "A graph structure is represented by nodes and edges. Let V denote the set of nodes (i = 1,2,\u2026\u2026\u2026, n), and E denote the set of edges (i, j) connecting the nodes, and let the graph G consist of the pair G = (V, E) of nodes V and edges E. Two nodes are adjacent if there is an edge between them, and i is the parent of j and jis a child of i if there is a directed edge from i to j. If node i is a parent of j and jis a parent of k, we say that there is a directed path from i to k. If node i can be reached by a directed path from i to k, we say that i is an ancestor of k and k is a descendant of i. The set of parents of node i is denoted by pa(i), the set of children by chi(i), the set of ancestors by anc(i), the set of descendants by des(i), and the set of all nodes adjacent to node i by adj (i). Assume that the values of all nodes D = {D1, D2, \u2026, Dn} are observed and all values are categorical.\nWe assume that the DAGs represent the causal relationships among nodes and satisfy the Causal Markov Condition, described by\nXIV\\ {X, des(X)} | pa(X) \t\t\t(1)\n[3], and that all confounding variables necessary for the intervention calculations are observed. The DAG may be given by human knowledge, but in the case where it is estimated from observed data by statistical causal inference [3], it is not always uniquely obtained. In other words, we may have Markov-equivalent DAGs, which are expressed in terms of a completed partially directed acyclic graph (CPDAG) [12, 13, 14]. For such realistic problems, we extend our algorithm for CPDAGs after first describing it based on DAGs. We do not consider maximal ancestral graphs (MAGs) or partial ancestral graphs (PAGs) in this paper."}, {"title": "2.2. Intervention and adjustment variables", "content": "To determine the causal effect of the intervention variable X on the outcome variable Y, we can utilize causal information between variables represented by DAG. The intervention effect from X to Y is expressed by\nP(Y = y|do(X = x)) = \u2211P(Y = y|X = x, Z = z)P(Z = z), \t\t\t(2)\nwhere do(X = x) is a notation that represents an intervention with X set to x [4]. Z denotes the adjustment variables, and if Z were numerical variables, the integral form would be used instead of the summation form. The mean causal effect can be calculated as the difference between these intervention effects. For example, if X is the presence or absence of a medicine (0 = not administered, 1 = administered), we can determine the effectiveness of the medication from the difference between do(X = 0) and do(X = 1).\nIn the context of causal effect calculations, X and Y are often assumed to be binary, but in this paper, we assume that they are multi-valued. Also, while we assume that both X and Y are single variables, we will later discuss the case of multiple intervention variables (joint intervention).\nThe back-door criterion [4] can be used for the selection of adjustment variable Z. It is defined as follows.\nDefinition 1 (Back-door criterion, Pearl, 2009). In a DAG G, a set of variables Z satisfies the back-door criterion for {X,Y} if\n(i) There is no directed path from X to any element of Z.\n(ii) In a graph of G excluding edges out of X, X and Y are d-separated by Z.\nThe important point here is that there is always a set of variables in each G that satisfies the back-door criterion. For example, pa(X), anc(X), and any of the variables of the non-ancestors of X added to these sets also satisfy the backdoor criterion. Therefore, multiple sets of variables generally satisfy the back-door criterion. If X and Y are d- separated from the beginning (e.g., when there is no parent of X), then the empty set satisfies the back-door criterion.\nTechniques other than the back-door criterion for intervention calculation include the front-door criterion [2] and the instrumental variable [15] methods. The advantages and disadvantages of each method vary depending on conditions such as the observation status of variables and the shape of the DAG, but we focus only on the back-door criterion because of its generality. There is also an extension of the back-door criterion called the adjustment criterion [5], but since the smallest set of variables that satisfies the back-door criterion also satisfies the adjustment criterion, we focus only on the back-door criterion for simplicity."}, {"title": "3. Methodology", "content": "As stated earlier, if variables that satisfy the back-door criterion are found, the intervention effect can be calculated by adjusting for these variables to eliminate the bias caused by confounding factors. However, when calculating intervention effects, using an unnecessarily large number of variables for adjustment simply because they satisfy the back-door criterion may lead to an accuracy degradation, depending on the amount of data. Therefore, in this paper, we propose a new criterion for the selection of adjustment variables and show the specific procedure."}, {"title": "3.1. Problems in handling real data", "content": "One problem when calculating intervention effects in real-world analyses is that there are multiple sets of variables that satisfy the back-door criterion, and it is difficult to"}, {"title": "3.2. Proposed selection method", "content": "Here, we propose an adjusted variable selection method that mitigate the above problem. The algorithm consists of two main steps. In Step 1, the minimal set of variables that satisfy the back-door criterion for {X, Y} is enumerated, and then in Step 2, the optimal set of variables is selected from these sets.\nIn Step 1, if there are two sets A and B that satisfy the back-door criterion for {X, Y}, and if B C A, then it is better to choose B as the adjustment variable in order to avoid the above problem of insufficient data. In this case, the minimal variable set that satisfies the back-door criterion is also the minimal variable set that satisfies the adjustment criterion [5]. It is also the minimal adjustment variable for estimating the causal effect from X to Y, as shown in Theorem 4.4 Minimal Covariate Adjustment in"}, {"title": "3.3. Extension of CAVS to CPDAG", "content": "We assumed DAGs in Algorithm 1, but since it is possible that only CPDAGs can be estimated from observed data, we consider here the case where our method is extended to CPDAGs. In this section, we present and prove a theorem that enables the computation of interventions based on CPDAGs, only determining the direction of some edges. As previously stated, we can use the back-door criterion in the selection of adjustment variables for a DAG. However, the adjustment criterion [5] is more comprehensive than the back-door criterion defined as follows.\nDefinition 2 (Adjustment Criterion (AC), Shpitser et al., 2010). In a DAG G, a set of variables Z satisfies the adjustment criterion for {X,Y} if"}, {"title": "Definition 3 (Amenability for DAGs and CPDAGs, Perkovi\u0107 et al., 2015)", "content": "A DAG or CPDAG is said to be adjustment amenable, relative to {X,Y} if every possibly directed path from X to Y in G starts with a directed edge out of X.\nAccording to this concept, the adjustment criteria for DAGs are generalized to include CPDAGs as well, which is defined as the generalized adjustment criterion [18] below."}, {"title": "Definition 4 (Generalized Adjustment Criterion (GAC), Perkovi\u0107 et al., 2015)", "content": "In a DAG or CPDAG G, a set of variables Z satisfies the generalized adjustment criterion for {X,Y} if\n(i) G is adjustment amenable relative to {X,Y}.\n(ii) No element in Z is a possible descendant in G of any W \u2208 V \\ X that lies on a causal path from X to Y.\n(iii) All definite status non-causal paths in G from X to Y are blocked by Z.\nA node has a definite status on a path if it is determined to be a collider or non- collider on that path, and a path has a definite status if all nodes on that path except"}, {"title": "Theorem 1 (Perkovi\u0107 et al., 2015)", "content": "Z is an adjustment set relative to {X,Y} in a DAG or CPDAG G if and only if Z satisfies the generalized adjustment criterion relative to {X,Y} in G.\nAdditionally we show two complementary problems [18] below related to the proof of Theorem 1 and the new Theorem 2, which will be presented later."}, {"title": "Lemma 1 (Perkovi\u0107 et al., 2015)", "content": "Let condition 1 of the GAC be satisfied relative to {X,Y} in a CPDAG G. Then the following two statements are equivalent:\n(i) Z satisfies condition 2 of the GAC relative to {X,Y} in G.\n(ii) Z satisfies condition 1 of the AC relative to {X,Y} in every DAG in the Markov equivalence class of G."}, {"title": "Lemma 2 (Perkovi\u0107 et al., 2015)", "content": "Let condition 1 of the GAC be satisfied relative to {X,Y} in a CPDAG G, and let Z satisfy condition 2 of the GAC relative to {X,Y} in G. Then the following two statements are equivalent:\n(i) Z satisfies condition 3 of the GAC relative to {X,Y} in G.\n(ii) Z satisfies condition 2 of the AC relative to {X,Y} in every DAG in the Markov equivalence class of G."}, {"title": "Theorem 2", "content": "In CPDAG, the intervention effect from the intervention variable to the outcome variable is computable if all edges adjacent to the intervention variable are directed edges.\nProof. Theorem 1 states that only variables that satisfy GAC are adjustment variables in CPDAG. Therefore, we consider whether variables satisfy GAC by examining two cases, where X is the intervention variable and Y is the outcome variable: (1) all edges adjacent to X are directed edges, and (2) not all edges adjacent to X are directed edges.\nWe first examine the case where all edges adjacent to X are directed edges. Regarding the adjustment amenable condition, which is one of the conditions of GAC (condition 1), according to Definition 3, the CPDAG is adjustment amenable if every possibly directed path from X to Y starts with a directed edge out of X. Therefore, if (X,i)i\u2208adj(X) are all directed edges, then its CPDAG is adjustment amenable with respect to {X, Y}. Also, according to Lemma 1, if condition 1 of GAC (Definition 4) is satisfied for {X, Y} in its CPDAG, then the variables satisfying condition 2 of GAC satisfies condition 1 of AC (Definition 2) in all Markov-equivalent DAGs. Also,"}, {"title": "4. Related Work", "content": "For covariate adjustment, if a DAG is known, we generally focus on whether the adjustment variable satisfies the back-door criterion or the adjustment criterion. However, satisfying the back-door criterion is not always sufficient, and it is known that adjustment by the instrument variable can lead to Z-bias [19, 20]. For example, pa(X) always satisfies the back-door criterion, but if there is an instrument variable in it, it is better to remove it from the adjustment variables. In this paper, this bias can be removed by selecting the smallest set of variables that satisfy the back-door criterion. On the other hand, while practical variable selection methods when the DAG is unknown"}, {"title": "5. Experiment", "content": "We investigated the accuracy of CAVS using existing datasets and artificially generated data. On the existing datasets, we examine which variables CAVS selects as adjustment variables and how accurately it calculates interventions compared to using other adjustment variables, while specifically showing the positional relationship between the intervention variable, the outcome variable, and the adjustment variables on the DAG. For artificial data, we show that CAVS is superior to some baseline methods on various randomly generated graphs.\nWe examine the error by measuring the difference between the intervention results when the data are randomly sampled and when sufficient data are available as a reference"}, {"title": "5.1. Existing dataset", "content": "We applied CAVS to two existing datasets, Insurance [31] and Hailfinder [32], and investigated its performance in detail. Each dataset has a DAG structure and conditional discrete probability distributions. For each of these two datasets, after specifically selecting intervention and outcome variables, we show which variables CAVS actually selected from multiple candidate adjustment variables. We also show where each of the multiple candidate adjustment variables is located on the graph, the mutual information between the adjustment variables and the intervention variable, and in which cases the accuracy degrades.\nFirst, in the Insurance example, Fig. 5 shows the overall structure of the DAG, with the node OtherCarCost as the outcome variable and Accident one level above as the intervention variable. In this case, if we enumerate the candidate adjustment variables that satisfy the back-door criterion described in Step 1 of Algorithm 1, we obtain {RuggedAuto}, {VehicleYear, MakeModel}, {SocioEcon, RiskAversion, Antilock}, {Age, RiskAversion, Antilock, RiskAversion, Antilock}, {RiskAversion, DrivingSkill, Antilock}, and {Antilock, DrivQuality}. {Mileage} is a parent of the intervention variable, but since it does not contribute to closing the back-door path, it is not selected as a candidate adjustment variable. Next, we generated 200,000 data samples based on the conditional discrete probability distribution of the dataset, and calculated the mutual information utilizing Eq. (4) as a measure of the correlation between the intervention variable and the candidate adjustment variables. We calculated the intervention results for the outcome variable Y based on the value calculated using all 200,000 samples and estimated the outcome variable Y using the subset data Dk obtained by randomly sampling with 2000 samples. We sampled Dk five times and calculated the error between Y and Y using Eq. (5)."}, {"title": "5.2. Artificial Data", "content": "Next, we show the performance of CAVS on artificially generated data. The comparisons for CAVS are the smallest parents of X that satisfy the back-door criterion, and pa(X) (that certainly satisfy the back-door criterion). The data were generated as follows."}, {"title": "6. Conclusion", "content": "We have proposed a method for selecting variables for covariate adjustment from both graph structure and data perspectives to maintain accuracy in causal effect estimation. When there is not enough data, it is important to prioritize the selection of variables for this purpose. To this end, we developed a two-step algorithm that consists of exploring candidates and selecting better variables using the correlations between related variables, and demonstrated its effectiveness in experiments with both existing and artificial data. In particular, we showed that our method is robust to sample size and prevents accuracy degradation even with small amounts of data. In addition, we demonstrated how to extend the application of the proposed method from DAGs to CPDAGs, and proved the theorem on computation possibility of interventions in CPDAGs. This broadens the applicability of intervention calculations in real-world data."}]}