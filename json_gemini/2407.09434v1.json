{"title": "A Perspective on Foundation Models for the Electric Power Grid", "authors": ["Hendrik F. Hamann", "Thomas Brunschwiler", "Blazhe Gjorgiev", "Leonardo S. A. Martins", "Alban Puech", "Anna Varbella", "Jonas Weiss", "Juan Bernabe-Moreno", "Alexandre Blondin Mass\u00e9", "Seong Choi", "Ian Foster", "Bri-Mathias Hodge", "Rishabh Jain", "Kibaek Kim", "Vincent Mai", "Fran\u00e7ois Mirall\u00e8s", "Martin De Montigny", "Octavio Ramos-Lea\u00f1os", "Hussein Supr\u00eame", "Le Xie", "El-Nasser S. Youssef", "Arnaud Zinflou", "Alexander J. Belv\u0131", "Ricardo J. Bessa", "Bishnu Prasad Bhattari", "Johannes Schmude", "Stanislav Sobolevsky"], "abstract": "Foundation models (FMs) currently dominate news headlines. They employ advanced deep learning architectures to extract structural information autonomously from vast datasets through self-supervision. The resulting rich representations of complex systems and dynamics can be applied to many downstream applications. Therefore, FMs can find uses in electric power grids, challenged by the energy transition and climate change. In this paper, we call for the development of, and state why we believe in, the potential of FMs for electric grids. We highlight their strengths and weaknesses amidst the challenges of a changing grid. We argue that an FM learning from diverse grid data and topologies could unlock transformative capabilities, pioneering a new approach in leveraging AI to redefine how we manage complexity and uncertainty in the electric grid. Finally, we discuss a power grid FM concept, namely GridFM, based on graph neural networks and show how different downstream tasks benefit.", "sections": [{"title": "1. Introduction", "content": "Power grids are arguably the largest machines ever built by humanity, as recognized by the National Academy of Engineering [1]. Having survived the deregulation revolution at the dawn of the new century, this aging and ever-expanding system is about to face its biggest challenge. The energy transition, with its widespread electrification and massive deployment of renewable and distributed generation, is the main driver for this change, affecting both the demand and supply sides of the market [2, 3, 4]. And it is happening fast. Climate change, manifesting with more frequent high-intensity weather events, poses additional challenges to system planners and operators [5, 6, 7].\nIn this context, it is clear that the operation, control, and planning of power systems will soon be pushed to their limits. As depicted in Figure 1, new computational methods and approaches are needed, capable of better tackling the challenges presented by increased uncertainty and complexity. Machine learning (ML) and artificial intelligence (AI) methods have shown promise for such purposes in a wide spectrum of industries, with significant breakthroughs in computer vision [8], natural language processing [9], and intelligent control [10]. Such approaches rely on statistical algorithms to learn from massive data, often enabling them to execute tasks (e.g., regression, classification, detection, segmentation, forecasting, generation) without human supervision.\nYet, despite significant progress in the application of AI/ML methods to power systems [11, 12, 13], wider adoption has been impeded, in particular, by a lack of readily available training data and the limited transferability of developed models to adjacent applications [14]. This is where, we argue, Foundation models (FM) have an important role to play. FMs are advanced AI models developed through self-supervised learning, most often based on transformer architectures, that generalize across various tasks after initial training on large datasets, enabling efficient adaptation to specific applications with minimal labeled data. Text-based FMs like GPT-4 [15], encoding deep relationships in text, have enabled a wide range of new applications. Similarly, we anticipate that a multi-modal FM for power grids, trained on the diverse data that characterizes the power grid, will enable a broad set of new use cases."}, {"title": "2. Looming challenges", "content": "As the energy transition accelerates, power grids face unprecedented challenges threatening their reliability and efficiency."}, {"title": "2.1. Distributed and renewable energy sources", "content": "While a single coal plant can generate hundreds of megawatts predictably and reliably, large numbers of weather-dependent renewable energy resources like wind and solar are required to produce the same power output. Current hourly and daily forecast methods still show up to 3% and up to 10% forecast error, respectively [16]. Additionally, distributed energy resources (DERs) like battery storage and electric vehicles are operated by independent power management systems and are driven by user patterns with intrinsic uncertainties. Dealing with the added uncertainty from reverse DER power flows, multipoint injections, and weather-induced fluctuations requires new voltage regulation methods, protection schemes, and advanced (optimal) power flow analysis. The numbers of controllable and dispatchable devices, as well as balancing nodes are expected to grow exponentially [17] with additional thousands to millions to be added in the near future. Managing the associated variability and uncertainty will require advanced stochastic optimization, scenario reduction, and sampling-based approaches, which are computationally more intensive than currently used deterministic methods, especially for real-time demand-supply balancing [18]. Furthermore, as the net load of DER-rich distribution branches seen by transmission operators becomes more variable and less predictable, effective grid management and planning will become impossible without effective co-simulation frameworks that integrate transmission and distribution analysis. Yet the computational cost of such simulations, at least with existing technologies, is extremely high."}, {"title": "2.2. Everything inverter", "content": "For the future power grid, inverters will play a crucial role in maintaining low cost at the grid's edge. However, with increased inverter proliferation, established control schemes and grid stability are challenged, while a more deregulated environment is created. With more inverters connected, grid inertia - which stabilizes phase, voltage, and frequency during transient events and which is mostly tied to large synchronous generators \u2013 decreases [19], unless more grid-forming converters are introduced. As inverters are driven by software, they can quickly adjust power or disconnect, causing additional issues like sub-synchronous resonances and even trip large generators [20].\nDespite the increasing adoption of standards [21], inverters remain hard to predict and model, unlike physics-driven synchronous generators. Quasi-static phasor simulations are used to assess optimal power flow. For grid stability assessment, however, computationally expensive electro-magnetic transient (EMT) simulations [22] are required. They run mostly on traditional central processing units (CPUs), which are flexible for many algorithms but inferior in compute performance to recent graphics processing units (GPUs), which are just starting to get adopted in the industry, as, e.g., in [23]. Also, CPU systems do not always scale well for large EMT simulations [24]. Grid operations, however, would require EMT simulations to run in real-time and for large sections of the grid, including distribution grid sections. To further account for inherent network uncertainties and those introduced by inverter-based resources (IBRs), stochastic ensembles of the problems would need to be simulated. Altogether, such an approach is computationally expensive and, with current approaches, impractical [25]. Thus, the community mostly relies on offline simulators like PS CAD [26] or ParaEMT [27] while also exploring physics-informed neural networks to reduce EMT simulation time [28]."}, {"title": "2.3. Changes to demand and weather patterns", "content": "Mass electrification of heating, transportation, and industry \u2013 in addition to climate change and shifting demographics \u2013 result in changing load profiles. Consequently, the accuracy of classical short-term load forecasting has declined over the past decade due, among other factors, to the changes in customer demand and weather patterns, leading to out-of-distribution scenarios [29]. To model demand uncertainty, utilities use multiple scenarios for structural and random drivers [30]. Increasingly, they also forecast at the power transformer level to manage local dynamics [31], but this approach is costly and does not scale due to the need for multiple models.\nShort-term models. Short-term models for operations, running hourly to weekly, are used for market bidding, unit commitment/economic dispatch, operational planning, and security analysis, among others [32]. As stated before, uncertainty and variability are driven in part by weather and human behavior, from societal aggregations to individual households [33], as well as by operator-induced industrial activities. Economic factors, the increasing frequency and intensity of extreme weather events with high prediction uncertainty [34], and growing system complexity (e.g., self-consumption, electric vehicles) also contribute to variability. The resulting complexity necessitates the selection and integration of new and heterogeneous data sources (e.g., social networks, online news) along with the frequent adjustment, rebuilding, and maintenance of models.\nLong-term models. Long-term models like the Regional Energy Deployment System [35] are used for resource, infrastructure, and strategic planning. Uncertainty and variability at longer time scales are significantly driven by climate policy, technology adoption, and regulatory changes. Instances of this include the combustion engine phase-out by 2035 in Europe \u2013 which resulted in a massive increase in the long-term electricity demand forecast or the US Federal Energy Regulatory Commission's rules on planning and covering the cost of the power grid [36]. To improve model accuracy, additional information that captures demographic changes and changes in the distribution of wealth, which lead to different societal and individual behaviors (e.g., heating, cooling, electromobility), as well as climate change-induced environmental shifts must be integrated. Therefore, the capacity to combine heterogeneous data sources (including information in textual format) is a fundamental requirement to improve predictability."}, {"title": "2.4. Aging infrastructure", "content": "Managing the vast amount of diverse equipment and aging infrastructure \u2013 the US power grid has hundreds of thousands of miles of transmission and millions of miles of distribution lines with over 55,000 substations \u2013 constitutes a major challenge on its own. While some lines last up to 80-100 years [37], insulators, transformers, and generators require frequent inspections, ideally through permanent sensing, which, given their age and approaching end-of-life [38], may not always be installed. Modeling these components in mostly unknown conditions is difficult and may rely on computationally expensive stochastic and ensemble models. Driven by growing demand, utilities are increasingly exploiting their aging infrastructure towards its operational limits [39], reducing margins and leading to larger size contingency analysis problems [40]. In response, much faster grid analysis functions are required, e.g., including grid contingency events.\nMoreover, the lowering of grid inertia through IBR integration (see Section 2.2) is further amplified by the retirement of old synchronous generators. The more frequent use of synchronous generators for regulating purpose bring them more often in operating zones where mechanical or thermal stresses are significant, and thus accelerate the aging of the generators. IBR related switching transients also disrupt existing protection relay schemes and increase grid behavioral uncertainty."}, {"title": "2.5. Cybersecurity threats", "content": "DER and IBR technologies are currently being developed and deployed without robust regulatory frameworks mandating essential cybersecurity standards, hence increasing the associated cybersecurity threats. Interconnection and interoperability standards, such as IEEE Std. 1547 requires DERs and IBRs to communicate with clients, vendors, aggregators, and grid operators for monitoring and control. In practice, however, communication often occurs over inadequately secured public and private networks, expanding the cyberattack surface [41]. Consequently, critical vulnerabilities are frequently discovered in commercial DERs and IBRs, such as electric vehicle charging stations [42] and PV inverters [43], increasing the likelihood of major cyber-attacks [44]. As the penetration of DERs and IBRs increases, synchronized cyberattacks targeting DERs or IBRs could cause grid reliability issues, from localized instability to system collapse [41]. This risk is exacerbated by reduced grid inertia and contingency reserves due to reliance on zero marginal cost renewables. Additionally, control and management responsibilities for DERs and IBRs are often delegated to aggregators, vendors, and customers. This delegation complicates risk assessment, incident detection, and response \u2013 as visibility barriers are created for grid operators \u2013 introducing uncertainty and black-box behavior for large sections of their grid. With the lack of real-time data, these barriers create significant additional computational burdens for automated and accelerated data analysis to search for fraudulent injections."}, {"title": "3. Foundation models", "content": "Having identified the growing gaps between computational capabilities and industry needs amidst the energy transition, we now introduce FMs, which is the focus of this article, laying the groundwork for our vision of GridFM."}, {"title": "3.1. The foundation model approach", "content": "To understand the FM approach, it helps to review the evolution of AI and ML as depicted in Figure 2. Early hand-crafted symbolic expert systems, from the 1960s onwards, were limited and brittle. The 90s brought big data and general-purpose ML that, however, depend on task-specific hand-crafted features. In 2012, deep learning, enabled by increased compute performance, started to disrupt the AI world [45], but remained task-specific and still required large annotated datasets. Recently, FMs have emerged. They learn from data through self-supervision [46] and have proven to generalize across many applications. Creating an FM is a three-step process, as shown in Figure 3:\n1. Pre-training: Developing a general-purpose representation FM through self-supervised pre-training and a suitable architecture, often based on a transformer model with encoder and decoder components. This step involves a reconstruction task where the model reconstructs masked parts of the data.\n2. Fine-tuning: The pre-trained FM is customized for various downstream tasks with minimal labeled data by attaching a task-specific decoder head and performing a few training iterations.\n3. Inference: The fine-tuned FM is deployed to allow users to request predictions at low computational cost.\nFM development is generally computationally expensive, involving pre-training on datasets of tens of terabytes and models with hundreds of millions or even billions of parameters [47]. However, once developed, FMs can be readily adapted to multiple downstream tasks via fine-tuning with minimal labeled data. Thus, the cost of model pre-training can be spread across numerous applications. These economies of scale make it feasible to employ AI for niche applications, for which developing a dedicated traditional AI model might be prohibitively expensive or technically infeasible.\nFM training encodes underlying patterns from the supplied data in model parameters. Successful examples of FMs to date include text-based large language models (LLMs) [47] and weather forecast models [48], in which these patterns are linguistic and physics-driven temporal-spatial relationships, respectively. LLMs have been shown to be applied successfully to certain power system problems [14]. By contrast, our focus here is on a multi-modal GridFM able to handle multiple data modalities intrinsic to power grid operations. Modalities of interest include network topologies, sensor data from phasor measurement units (PMUs), SCADA systems, advanced metering infrastructure (AMI), load, generation, weather, and market data."}, {"title": "3.2. Salient advantages", "content": "We next review salient features of FMs that hold significant potential for enhancing power grid applications.\nPredicting \"tokens\". In transformer models, a token is defined as the smallest fundamental unit of data (e.g., a character sequence or image patch). FMs excel at predicting missing tokens based on context, enabling tasks such as sentence completion, programming assistance, and question answering in the text domain [49]. This capability extends beyond text to fields like time-series, audio, or video, where FMs predict next or missing values [50].\nHomogenization and scaling. FMs represent a paradigm shift in AI, offering a scalable and standardized approach and making niche applications commercially viable. This AI-as-a-platform approach promises to simplify operations by allowing a few FMs to replace many specialized models. For example, a single geospatial FM for earth observation has been fine-tuned for tasks like flood segmentation, land-use classification, and heat island regression [51].\nAccelerating simulations. FMs can emulate physics-based simulations with impressive accuracy and efficiency, potentially combined with physics-informed machine learning [28]. The efficiency gains originate from AI models directly mapping inputs to outputs, unlike traditional physics-based simulations that solve partial differential equations iteratively. Recent AI models [48] emulate numerical weather prediction models [52] with comparable forecasting skills but up to 4-5 orders of magnitude lower computational cost [53] during inference. These game-changing advances improve the spatial and temporal resolution of forecasts and, combined with AI techniques such as diffusion-based models [54], facilitate the creation of large ensembles for uncertainty estimation. Another salient advantage of using AI for emulating simulations lies in the fact that no a-priori assumptions are required but rather the FM can learn the full physics directly from the data or observations. We argue that exactly these characteristics of FMs are crucial for bridging the computational gaps shown in Figure 1."}, {"title": "3.3. Hurdles to implementation", "content": "Here, we discuss potential hurdles associated with implementing FMs for the power grid while suggesting solutions.\nNeed for data. FMs, like other deep learning models, are data hungry, which raises the question of the sufficiency of available data. For example, the Llama3 LLM, with 70 billion parameters, is trained on 15 trillion tokens of text [55]. By way of comparison, the power sector globally generates multiple times that volume daily [56]. Considering the groundbreaking capabilities of large language models in open-ended systems where context and semantics are not consistently described by mathematical equations, there are reasons for optimism about this technology's potential for the power grid. However, the question remains whether data sets with the right diversity and quality exist or can be assembled so that the full spectrum of scenarios and situations are covered to encode the desired information in model parameters via a suitable training approach.\nData accessibility. Data accessibility is another potential hurdle to overcome. Grid data are heterogeneous and distributed, are owned by multiple entities, and have special security and privacy measures. A potential solution to this barrier includes privacy-preserving federated learning [57] and secure enclave technologies [58]. Such approaches may enable multiple data owners to train models collaboratively without sharing their local data with a central server, thus preserving privacy and complying with data protection regulations. Additional schemes like differential privacy and homomorphic encryption can be integrated into federated learning frameworks [59], ensuring that sensitive information remains protected during training. Secure enclaves, in contrast, create a trusted execution environment for secure processing of sensitive and proprietary data during FM training. Moreover, simulated data generated from real and synthetic systems can complement and provide scenarios under various conditions, such as extreme weather conditions, component failures, and cascading failure events [13]. However, it is important to consider that electrical networks evolve for various reasons, such as network reinforcement, which changes topologies and operating conditions, or new business models (e.g., local energy communities), which change the operating profiles of assets connected to the network, requiring continual learning of the FM.\nTrust. Notwithstanding the scenario in which all necessary data, whether synthetic or real, can be cleared and collected for use, there still remains the age-old question of whether the data and, consequently, a data-driven model can be trusted. In general, power system operators prefer interpretable models over black-box models so that the root causes of choices by advanced tools can be better understood, and heuristic solutions can be developed. While the debate on the trustworthiness of AI will continue, there is evidence that AI models can be as trustworthy as first-principle physics-based models, for specific applications [60]. Referring back to the recent breakthroughs of AI emulators for weather [61], it was demonstrated that AI could indeed encode the actual dynamics of certain physical systems and generalize to unseen events in ways that allow it to outperform a physics-based simulation-based model [62]. Moreover, standardized formal verification methods are required for AI. ISO already developed the first family of standards in that direction, e.g., ISO/IEC 24029-2 [63].\nThe European Union's recently published AI Act [64] defines two concepts to boost trust in AI-based systems and data sharing: a) testing and experimentation facilities that combine physical and virtual environments to evaluate and certify their latest AI-based software and hardware, and b) the data spaces concept to remove barriers to data sharing, such as interoperability, trust, and privacy, while keeping sovereignty and full control of data.\nMalicious use. FMs can be used as a sandbox to accelerate the development of adversarial attacks. For example, FMs\u2019potential for scalable data imputation, combined with their ability to predict grid operating conditions, could be exploited by adversaries to infer sensitive information about a target power system [65]. Therefore, it is imperative to continuously assess the extent to which misusing such technology can augment malicious actors' attack capabilities and to adapt cybersecurity defenses and policies in response [66]."}, {"title": "4. A concept of foundation model for the power grid", "content": "In the previous section, we outlined the salient qualities of FMs by pointing to their established applications in language and weather. Here, we discuss how the challenges in the future power system open up new opportunities for FMs. FMs can reduce computational burdens, accelerating simulations and thus enabling the transition to a sustainable and reliable power system. These models excel in handling complex power grid tasks in near real-time and provide more accurate forecasting or reconstruction of key variables than classical methods. Such problems are well-suited for FMs as they fundamentally involve token prediction or reconstruction tasks. Additionally, an ML agent can be trained to act as an expert in decision-making processes, such as grid expansion, network reconfiguration, and other tasks that often require computationally intensive solutions. Here, we explore the potential implications of developing a GridFM, examining the important components and steps to build such a model."}, {"title": "4.1. Data preprocessing and token design", "content": "The successful construction of FMs requires the careful design of tokens to represent data elements effectively. Word and image tokens are essential for successful natural language processing and computer vision training. While these domains have established tokenization methods, strategies must be explored for other domains. For example, graph-based models define a graph vocabulary [67] to capture structural and semantic properties, while time series models segment data into subseries-level patches [68].\nDesigning tokenization strategies for non-text and non-visual power grid data can be difficult, because the grid involves very heterogeneous, multi-modal datasets, sensor time series, categorical equipment status data, and spatial grid topology data. The PyPSA-Eur dataset [69] is an excellent example of this complexity, where researchers provide a platform to access multi-modal data for the European power system, i.e., network data, electrical demand time series, renewable time series, and geographical potential for solar and wind generations. A promising tokenization strategy for multi-modal data was demonstrated for vision tasks by the massively multi-modal masked modeling architecture (4M) [70]. In this work, good scalability was achieved by unifying the representation space of all modalities, by mapping them into discrete tokens, and performing multi-modal masked modeling on a small randomized subset of tokens. In addition to tokenization, other preprocessing techniques are essential for training models on grid data. For example, normalization methods are critical for training time series models to avoid distribution shift issues [68, 71]. Nevertheless, the alarm data in power grids resembles tokens and natural language elements [72], making FMs applicable for forecasting alarm sequences and filling in missing alarm data."}, {"title": "4.2. Model architecture", "content": "Our GridFM model must work with data from at least four modalities: tabular, time series, graph (static and spatiotemporal), and geospatial. Additionally, we expect the power grid dynamics to require a similar number of trainable parameters than weather and climate systems, which are also governed by highly non-linear and complex physical laws. Therefore, an estimate of the number of trainable parameters for GridFMs can be inferred from the FMs developed for these systems, which currently have a few hundred million parameters [53, 73].\nWe envision two designs for a GridFM that account for the complexity of the grid and its varying transmission and distribution network properties, covering system dynamics from operations to planning. Firstly, it can be designed as a single multi-modal spatiotemporal model. Alternatively, it can consist of multiple FMs integrated into a mixture-of-experts (MoE) framework [74].\nThe topology of the power grid and its physical properties align well with the message-passing mechanisms used in graph neural networks (GNNs). GNNs are designed for graph-structured data and, through their message-passing mechanisms, learn representations of graph structures called embeddings. These embeddings are learned by iteratively aggregating the features of neighboring nodes. Unlike other deep learning methods that either fail to generalize or require complex data preprocessing, GNNs can generalize to different grid network topologies. Selecting a suitable GNN architecture, however, is challenging. It was argued that the power grid's unique features necessitate GNNs with depths of up to 27 layers to effectively solve the power flow problem [75]. More recently, on the other hand, it was demonstrated that more shallow GNNs can achieve very good results for power flow, optimal power flow, and cascading failure analysis on various benchmark transmission grids [13]. Specifically, it was shown that graph attention networks [76] and transformer-based models perform the best. Attention-based models on graphs assign the importance of a node to its neighbors by learning a score for each node pair, which allows for a more effective understanding of temporal and geographical patterns. Furthermore, attention-based methods such as GraphAny [77] demonstrate high transferability and generalizability to unseen graph topologies for foundation models. Given these insights into the effectiveness of GNNs for power grid analysis, exploring more advanced modeling strategies becomes essential to capture the complexities of the multi-level structure of the power grid. A promising strategy is a hierarchical model architecture, e.g., using GNNs and sublevel time series modeling [68]. Hierarchical GNNs [78] allow for modeling transmission and distribution-level grid topologies. Sublevel time series models can train the FM with various temporal dynamics and resolutions. In addition, hierarchical GNNs can be combined with geometric deep learning for spatiotemporal graphs [79]. The combined use of these sophisticated approaches requires further exploration. It is important to note that the graph representations can go beyond the physical grid topology [80].\nHere, we propose a concept of a multi-modal FM for power grids as shown in Figure 4. The model reads structured graphs in which the grid topology is mapped to nodes and edges using GNNs as encoders. Inputs serve as embeddings, including static (tabular and static graphs) and dynamic data (time series, spatiotemporal graphs, and geospatial data). The model also reads the input from variations of the same or different power grids. The input data is partially masked to train an auto-encoder for reconstructing the inputs. The model outputs the reconstructed inputs: measured signals, topology, and simulated data. While using a self-supervised learning approach to reconstruct signals is established, topology reconstruction entails novel techniques. A promising candidate for such a task is the integration of a link prediction approach into the GridFM model. Such an approach allows the model to learn the presence of a masked link using the observed (masked) graph topology [81]."}, {"title": "4.3. Downstream tasks", "content": "Once trained, the GridFM can address multiple downstream tasks, with or without additional encoding layers or fine-tuning. We summarize in Figure 5 and discuss the following eight classes of such tasks.\nTransient and dynamic stability. Here, the GridFM is employed to estimate how a system may respond to disturbances, analyzing signals in both time and frequency domain. The GridFM, when fine-tuned to reconstruct such signals, can help with missing data or predictive modeling. Foundation models with physics-informed learning can efficiently solve the differential algebraic equations governing rotor angle and voltage stability [82]. This can significantly speed up the computation of stability margins and help identify potential stability issues. Moreover, the rapid computation of fault currents using Foundation Models can aid operators in accurately localizing and classifying faults, enabling faster system restoration and minimizing the impact of disturbances on the power system [83].\nLoad flow. In power system operation and planning, load flow analysis determines the electrical state of the power system, e.g., voltage and phase angles at buses and power flows in branches. These analyses benefit from AI/ML methods, significantly decreasing computational burdens [13]. Traditionally, the power flow and optimal power flow problems are solved with iterative techniques. Due to their non-linear nature and difficulties in converging for large problems, simplifications are often used. Scientific ML techniques have been shown to provide solutions without employing simplified equations, competing with traditional methods in terms of accuracy while being drastically faster [84]. Therefore, with a significant computational speed-up, GridFM has great potential to provide more accurate and scalable solutions for power systems [82].\nForecasting. Forecasting is used in power grids for multiple tasks, including demand prediction, renewable production forecasting, and electricity price prediction. Demand and renewable forecasting are vital in ensuring power generation-demand balance, which is becoming increasingly important in a grid with high renewable penetration. The self-supervised learning paradigm used in FMs and their predictive ability make them intrinsically suitable for forecasting [85]. Moreover, FMs can integrate exogenous variables, such as numerical weather predictions, which also carry associated forecast uncertainties.\nControl operations. Here, the concerns include frequency and voltage control, network reconfiguration management, protection activation, and load shedding. FMs will help optimize and control the power system through sequential decision-making agents [86]. A GridFM can enhance reinforcement learning (RL) agents by introducing prior knowledge of the environment before and during training, improving learning efficiency, and reducing risks.\nElectricity markets. Electricity markets will benefit from the computational efficiency and predictive ability of a GridFM. The different markets, including futures, balancing, day-ahead, and intraday markets, can be optimized using the base GridFM or fine-tuned versions. Furthermore, the model will identify the security-based re-dispatch after the day-ahead market clearing in a timely manner [87]. It will also help to pinpoint the location, amount, and type of ancillary services from distributed sources for congestion management in the future power grid with high shares of renewables. Finally, a GridFM will provide prompt solutions for economic dispatch and unit commitment problems, traditionally solved as linear and mixed-integer optimization problems [88].\nSystem security. ML methods have been used to identify faulty components [12] and to speed up simulations like $N \u2212 1, N \u2013 K$ contingency, and cascading failure analyses [89], all critical tasks for operation and planning. Such models are faster and better leverage past knowledge for security predictions than traditional tools. Nevertheless, these analyses require additional encoding to incorporate topology with bus or branch-level features to inform about the final state of the entire grid. In this context, a GridFM tuned for system security will explore a broader and more complete set of scenarios, and thus both aid in designing a reliable power system and provide a system security tool for power system operations planning.\nExpansion planning. Rapid electrification of the industrial and automotive sectors and climate change's impact on generation profiles make expansion planning a crucial task at distribution and transmission levels. The generative capabilities of a GridFM to create future scenarios for load and generation (e.g., using public projections of electric vehicle sales and national renewable energy plans) will enhance decision-making. By integrating scenario generation with graph generation and deep reinforcement learning techniques, optimized and upgraded power systems can be designed to capture a broader spectrum of future extreme scenarios [90]. Additionally, by exploiting cross-country information (e.g., the impact of interconnection flows), a GridFM will improve expansion planning strategies to prepare for these effects and enable the energy transition in the following decades.\nCybersecurity. Cybersecurity challenges could be tackled by leveraging FMs to speed up power system simulations. These FMs facilitate risk assessment and incident response in transmission and distribution systems by identifying and prioritizing threat scenarios [91] and designing optimal responses to maintain grid reliability [92]. They can generate synthetic cybersecurity data by learning complex power system dynamics to overcome data scarcity, improving intrusion detection, and enabling dynamic stress testing against intelligent adversaries [93]. A cyber-physical FM can combine SCADA and AMI data with cybersecurity information to enhance cyber threat mitigation, detection, and response."}, {"title": "5. Conclusion", "content": "The rapid emergence of FMs is reshaping the AI landscape. While such models are well established for text and image analysis, here we have introduced the idea of a GridFM: an FM for the power grid, able to learn from time-series, geospatial, and other data to improve power grid planning, operations, and control. We first motivated the need for a GridFM by pointing to the growing gaps between computational capabilities and the industry's need to cope with the increasing uncertainty and complexity of the power grid, largely due to the energy transition. We then reviewed the three core advantages of the FM approach for power systems: excellent missing token prediction skills (signal reconstruction); broad adaptability and scalability; and simulation acceleration. In another domain characterized by apparently intractable complexity, namely weather forecasting, we have seen AI weather FMs approximate the fundamental equations governing weather to produce much more computationally efficient models (more than 4 orders of magnitude speed-up).\nIn a similar manner, we propose to develop a GridFM that learns the behaviors and dynamics from measurements and simulations for different network configurations. The superior computational performance of such a GridFM has the potential to accelerate grid analyses by several orders of magnitudes. This acceleration will, in turn, enable modeling of the increasingly complex (e.g., bidirectional power flow, combined transmission, and distribution) and uncertain grid (e.g., by modeling different scenarios going beyond the traditional N-1 analysis). The promise of such a GridFM is that once pre-trained on multiple grids and various networks, it can be readily fine-tuned to specific grid topologies (distribution and transmission).\nIn summary, we argue that research in the proposed FM for the power grid is imperative to facilitate the energy transition. We envision the power system and AI communities collaborating to take on this \u201cmoonshot\u201d and thus revolutionize power grid analysis, leveraging AI advancements to meet common goals and needs."}]}