{"title": "Conformal Prediction for Causal Effects of Continuous Treatments", "authors": ["Maresa Schr\u00f6der", "Dennis Frauen", "Jonas Schweisthal", "Konstantin He\u00df", "Valentyn Melnychuk", "Stefan Feuerriegel"], "abstract": "Uncertainty quantification of causal effects is crucial for safety-critical applications such as personalized medicine. A powerful approach for this is conformal prediction, which has several practical benefits due to model-agnostic finite-sample guarantees. Yet, existing methods for conformal prediction of causal effects are limited to binary/discrete treatments and make highly restrictive assumptions such as known propensity scores. In this work, we provide a novel conformal prediction method for potential outcomes of continuous treatments. We account for the additional uncertainty introduced through propensity estimation so that our conformal prediction intervals are valid even if the propensity score is unknown. Our contributions are three-fold: (1) We derive finite-sample prediction intervals for potential outcomes of continuous treatments. (2) We provide an algorithm for calculating the derived intervals. (3) We demonstrate the effectiveness of the conformal prediction intervals in experiments on synthetic and real-world datasets. To the best of our knowledge, we are the first to propose conformal prediction for continuous treatments when the propensity score is unknown and must be estimated from data.", "sections": [{"title": "Introduction", "content": "Machine learning (ML) for estimating causal quantities such as causal effects and the potential outcomes of treatments is nowadays widely used in real-world applications such as personalized medicine [11]. However, existing methods from causal ML typically focus on point estimates [e.g., 31, 33], which means that the uncertainty in the predictions is neglected and hinders the use of causal ML in safety-critical applications [11, 25]. As the following example shows, uncertainty quantification (UQ) of causal quantities is crucial for reliable decision-making.\nMotivating example: Let us consider a doctor who seeks to determine the dosage of chemotherapy in cancer care. This requires estimating the tumor size in response to the dosage for a specific"}, {"title": "Related Work", "content": "UQ for causal effects: Existing methods for UQ of causal quantities are often based on Bayesian methods [e.g., 2, 19, 20, 21]. However, Bayesian methods require the specification of a prior distribution based on domain knowledge and are thus neither robust to model misspecification nor generalizable to model-agnostic machine learning models. A common ad hoc method for computing uncertainty intervals is Monte Carlo (MC) dropout [12]. However, MC dropout yields approximations of the posterior distribution, which are not faithful [27].\nConformal prediction: CP [28, 32, 43] has recently received large attention for finite-sample UQ. For a prediction model $\\phi$ on dataset $(X_i, Y_i)_{i=1,...,n}$ and a new test sample $X_{n+1}$, CP aims to construct a prediction interval $C(X_{n+1})$ such that $P(Y_{n+1} \\in C(X_{n+1})) \\geq 1 - \\alpha$ for some significance level $\\alpha$. We refer to [4] for an in-depth overview. Due to its strong finite-sample mathematical guarantees, CP is widely used for traditional, predictive ML with widespread applications such as in medical settings [48] or drug discovery [3, 9].\nSeveral extensions have been developed for CP. One literature stream focuses on CP with marginal coverage under distribution shifts between training and test data [e.g., 8, 10, 13, 14, 15, 16, 17, 29,"}, {"title": "Problem formulation", "content": "Notation: We denote random variables by capital letters $X$ with realizations $x$. Let $P_X$ be the probability distribution over $X$. We omit the subscript whenever it is obvious from the context. For discrete $X$, we denote the probability mass function by $P(x) = P(X = x)$ and the conditional probability mass functions by $P(y | x) = P(Y = y | X = x)$ for a discrete random variable $Y$. For continuous $X$, $p(x)$ is the probability density function w.r.t. the Lebesgue measure.\nSetting: Let the data $(X_i, A_i, Y_i)_{i=1,...,n}$ consisting of observed confounders $X \\in \\mathcal{X}$, a continuous treatment $A \\in \\mathcal{A}$, and an outcome $Y \\in \\mathcal{Y}$ be drawn exchangeably from the joint distribution $P$. Furthermore, let $\\pi(a | x)$ define the generalized propensity score for treatment $A = a$ given $X = x$.\nThroughout this work, we build upon the potential outcomes framework [37]. We denote the potential outcomes after a hard intervention $a^*$ by $Y(a^*)$ and after a soft intervention $A^*(x) \\sim \\pi(a | x) = P_{A^*|X=x}$ by $Y(A^*(x))$. We make three standard identifiability assumptions for causal effect estimation: positivity, consistency, and unconfoundedness [e.g., 1, 23]. Finally, we consider an arbitrary machine learning model $\\phi$ to predict the potential outcomes. Hence, we define the outcome prediction function as $\\phi : \\mathcal{X} \\times \\mathcal{A} \\rightarrow \\mathbb{R}$, $\\phi(X, A) \\rightarrow Y$.\nOur objective: In this work, we aim to derive conformal prediction intervals $C(X_{n+1},\\diamond)$ for the prediction of a potential outcome $Y_{n+1}(\\diamond)$ of a new data point under either hard, $\\diamond = a^*$, or soft intervention, $\\diamond = A^*(X_{n+1}) \\sim \\pi(a | X_{n+1})$. The derived intervals are called valid for any new exchangeable sample $X_{n+1}$ with non-exchangeable intervention $\\diamond$, i.e.,\n$\\mathbb{P}(Y_{n+1}(\\diamond) \\in C(X_{n+1},\\diamond)) \\geq 1 - \\alpha, \\quad \\diamond \\in \\{a^*, A^*(X_{n+1})\\}.$\nfor some significance level $\\alpha \\in (0,1)$. Of note, our CP method can later be used with an arbitrary machine learning model $\\phi$ for predicting the potential outcomes.\nIn CP, the interval $C$ is constructed based on so-called non-conformity scores [43], which capture the performance of the prediction model $\\phi$. For example, a common choice for the non-conformity score is the residual of the fitted model $s(X, A, Y) = |Y - \\phi(X, A)|$, which we will use throughout our work. For ease of notation, we define $S_i := s(X_i, A_i, Y_i)$.\nWhy is CP for causal quantities non-trivial? There are two main reasons. First, coverage guarantees of CP intervals essentially rely on the exchangeability of the non-conformity scores. However, intervening on treatment $A$ shifts the propensity function and, therefore, induces a shift in the covariates $(X, A)$ ($\\rightarrow$ Challenge \\textcircled{a}). Formally, we have a propensity shift in which the intervention"}, {"title": "CP intervals for potential outcomes of continuous treatments", "content": "Recall that intervening on test data samples breaks the exchangeability assumption necessary for the validity, i.e., the guaranteed coverage of at least $(1 - \\alpha)$, of CP intervals. Therefore, we now construct CP intervals where we account for a (potentially unknown) covariate shift in the data induced by the intervention.\nScenarios: In our derivation, we distinguish two different scenarios (see Fig. 3):\n \\textcircled{1} Known propensity score (see Section 4.1): If the propensity score in the observational data is known, it means that the treatment policy is known. Then, we aim to update the policy by increasing/decreasing the treatment by a value $\\Delta_A$, i.e., $A^*(X) = A + \\Delta A$.\nExample: Imagine a doctor is about to prescribe a medication to a new patient. Instead of prescribing the same dosage as he would have prescribed to a similar patient in the past, the doctor is interested in the potential health outcome of the patient when increasing (or decreasing) the original dosage by amount $\\Delta A$.\n \\textcircled{2} Unknown propensity score (see Section 4.2): In observational data, the propensity score is typically unknown. Therefore, we are interested in the effect of hard interventions, i.e., $a^*$. Here, we face additional uncertainty from the propensity score estimation ($\\rightarrow$ Challenge \\textcircled{b}).\nExample: In our running example, a patient comes to a new doctor who has never prescribed the respective medication and thus will base the decision on observational data (electronic health records) from other physicians, yet the observational data was collected under a different, unknown treatment policy. Therefore, the prescribed intervention (and thus dosage) cannot be expressed in terms of the policy in the observational data.\nIn our derivations, we make use of the following two mathematical tools. First, we define the propensity shift. Formally, it is the shift between the observational and interventional distributions, $\\mathbb{P}$ and $\\mathbb{P'}$, in terms of the tilting of the propensity function by a non-negative function $f$. Hence, we have\n$\\pi'(a | x) = \\frac{f(a, x)}{\\mathbb{E}_{\\mathbb{P}}[f(A, X)]} \\pi(a | x).$\nfor some $f$ with $\\mathbb{E}_{\\mathbb{P}}[f(X, A)] > 0$ and $a \\in \\mathcal{A}, x \\in \\mathcal{X}$.\nSecond, our CP method will build upon ideas from so-called split conformal prediction [32, 43], yet with crucial differences. In our methods, the calibration step differs from the standard procedure in that we conditionally calibrate the non-conformity scores depending on the tilting function $f$ to achieve marginal coverage for the interventional \u2013 and thus shifted - data."}, {"title": "Scenario 1: Known propensity score", "content": "We first consider scenario \\textcircled{1} with known propensity scores. Here, existing CP intervals are not directly applicable due to the shift from old to new propensity ($\\rightarrow$ Challenge \\textcircled{a}). For our derivation, we need the following lemma building upon and generalizing the intuition presented above.\nLemma 1 ([16]). Let the (potentially unknown) covariate shift of interest be contained in the finite-dimensional function class $\\mathcal{F}$. Define the distribution-shift-calibrated $(1 - \\alpha)$-quantile of the non-conformity scores as\n$\\widehat{\\theta}_S(X_{n+1}) := \\arg \\min_{g \\in \\mathcal{F}} \\frac{1}{n+1} \\left(\\sum_{i=1}^n \\ell_{\\alpha}(g(X_i), S_i) + \\ell_{\\alpha}(g(X_{n+1}), S)\\right)$\nfor an imputed guess $S$ of the $(n + 1)$-th non-conformity score $S_{n+1}$. The prediction interval\n$C(X_{n+1}) := \\{y \\mid S_{n+1}(y) \\leq \\widehat{\\theta}_{S_{n+1}(y)}(X_{n+1})\\}$\nfor the true $S_{n+1}$ given a realization of $Y_{n+1} = y$ satisfies the desired coverage guarantee under all distribution shifts $f \\in \\mathcal{F}$, i.e.,\n$\\mathbb{P}_f(Y_{n+1} \\in C(X_{n+1})) \\geq 1 - \\alpha.$\nBuilding upon Lemma 1, we derive our first main result in Theorem 1. We define the finite-dimensional function class of interest as $\\mathcal{F} := \\{\\theta \\frac{\\pi(a | x)}{\\pi(a + \\Delta A | x)} | \\theta \\in \\mathbb{R}^+\\}$. It is easy to verify that all $f \\in \\mathcal{F}$ represent the desired propensity shift to $\\pi'(a | x) = \\pi(a + \\Delta A | x)$ as defined in Eq. (2).\nTheorem 1 (Conformal prediction intervals for known baseline policy). Consider a new datapoint with $X_{n+1} = x_{n+1}, A_{n+1} = a_{n+1}$, and $A^*(X_{n+1}) = a^* = a_{n+1} + \\Delta$. Let $\\eta = \\{\\eta_1, ..., \\eta_{n+1}\\} \\in \\mathbb{R}^{n+1}$ be the optimal solution to\n\\begin{array}{c}\n\\max_{\\eta_i, i=1,...,n+1} \\sum_{i=1}^n \\eta_i \\quad s.t. \\\\ -\\alpha \\leq \\eta_i \\leq 1 - \\alpha, \\forall i=1, ..., n+1, \\\\ \\sum_{i=1}^{n} \\eta_i S_i + \\eta_{n+1} S \\leq 0, \\\\ - \\eta_i \\frac{\\pi(a_i + \\Delta A | X_i)}{\\pi(a_i | X_i)} + \\eta_{n+1} \\frac{\\pi(a^* | X_{n+1})}{\\pi(a_{n+1} | X_{n+1})} \\leq 0 \\end{array}\nfor an imputed unknown $S_{n+1} = S$. Furthermore, let $S^*$ be defined as the maximum $S$ s.t. $\\eta_{n+1} < 1 - \\alpha$. Then, the prediction interval\n$C(x_{n+1}, a^*) := \\{y \\mid S_{n+1}(y) \\leq S^*\\}$\nsatisfies the desired coverage guarantee\n$\\mathbb{P}(Y(A^*(X_{n+1})) \\in C(X_{n+1}, A^*(X_{n+1}))) \\geq 1 - \\alpha.$\nProof. We provide a full proof in Supplement C.2. Here, we briefly outline the underlying idea of the proof. First, we show that the function class $\\mathcal{F}$ indeed satisfies Eq. (2) for the intervention $A^*(X) = A + \\Delta A$, and we then rewrite Eq. (5) as a convex optimization problem. Next, we exploit the strong duality property, we optimize over the corresponding dual problem to receive a dual prediction set with equal coverage probability. Finally, we derive $S^*$ from the dual prediction set to construct $C_{n+1}$ and prove the overall coverage guarantee."}, {"title": "Scenario 2: Unknown treatment policy", "content": "If the underlying treatment policy is unknown, the only possible intervention is a hard intervention $a^*$. As described above, measuring the induced propensity shift is non-trivial due to two reasons: (i) The propensity model needs to be estimated, which introduces additional uncertainty affecting the validity of the intervals ($\\rightarrow$ Challenge \\textcircled{b}). (ii) The density function corresponding to a hard intervention is given by the Dirac delta function\n$\\delta_{a^*}(a) := \\begin{cases}\n0 \\text{, for } a \\neq a^*, \\\\\n\\infty \\text{, for } a = a^*,\n\\end{cases}$\nwhich hinders a direct adaptation of Theorem 1 due to the inherent discontinuity of the improper function. Hence, to proceed, we make the following assumption on the propensity estimator.\nAssumption 1. The estimation error of the propensity function $\\widehat{\\pi}(a | x)$ is bounded in the sense that, for all $i = 1,..., n + 1$, there exists $M > 0$ such that\n$c_a := \\frac{\\widehat{\\pi}(a_i | X_i)}{\\pi(a_i | X_i)} \\in [\\frac{1}{M}, M].$\nUnder Assumption 1, the distribution shift induced by the intervention is then defined as\n$\\widehat{\\pi}'(a | x) = \\frac{\\delta_{a^*}(a)}{\\widehat{\\pi}(a | x)} \\widehat{\\pi}(a | x) = c_a \\frac{\\delta_{a^*}(a)}{\\pi(a | x)} \\pi(a | x) = \\frac{f(a, x)}{\\mathbb{E}_{\\mathbb{P}}[f(A, X)]} \\pi(a | x),$\nfor a suitable function $f$. We further formulate $\\delta_{a^*}(a)$ in terms of a Gaussian function as\n$\\delta_{a^*}(a) = \\lim_{\\sigma_0 \\rightarrow 0} \\frac{1}{\\sigma_0 \\sqrt{2 \\pi}} \\exp(-\\frac{(a - a^*)^2}{2 \\sigma_0^2}).$\nThis motivates the following lemma. Therein, we specify the class $\\mathcal{F}$ of tilting functions $f$ that represent the distribution shift induced by the hard intervention $a^*$.\nLemma 2. For $\\sigma > 0$, we define\n$f(a,x) := \\frac{c_a}{\\sqrt{2 \\pi \\sigma}} \\frac{\\exp(-\\frac{(a - a^*)^2}{2 \\sigma_0^2})}{\\pi(a | x)}$\nwith $\\mathbb{E}_{\\mathbb{P}}[f(A, X)] = 1$. Furthermore, we define the finite-dimensional function class $\\mathcal{F}$\n$\\mathcal{F} := \\{\\frac{c_a}{\\sqrt{2 \\pi \\sigma}} \\frac{\\exp(-\\frac{(a - a^*)^2}{2 \\sigma_0^2})}{\\pi(a | x)} \\mid 0 < \\sigma, \\frac{1}{M} \\leq c_a \\leq M\\}.$\nThen, $f(a, x) \\in \\mathcal{F}$ for all $c_a \\in [\\frac{1}{M}, M]$ and $\\sigma \\rightarrow 0$. As a result, the distribution shift\n$\\widehat{\\pi}'(a | x) = \\lim_{\\sigma_0 \\rightarrow 0} \\frac{c_a}{\\sigma_0 \\sqrt{2 \\pi}} \\frac{\\exp(-\\frac{(a - a^*)^2}{2 \\sigma_0^2})}{\\pi(a | x)} \\pi(a | x)$\ncan be represented in terms of Eq. (2) through functions $f \\in \\mathcal{F}$.\nFollowing the motivation in scenario \\textcircled{1}, we thus aim to estimate the $(1 - \\alpha)$-quantile of the non-conformity scores under the distribution shift in Lemma 1. We can reformulate this problem as\n\\begin{array}{cl}\n\\min & \\sum_{i=1}^{n+1} (1 - \\alpha) u_i + \\alpha v_i \\\\\n\\sigma>0,\\frac{1}{M} \\leq c_a \\leq M & \\\\\n\\text{s.t.} & S_i - \\frac{c_a}{\\sqrt{2 \\pi \\sigma}} \\frac{\\exp(-\\frac{(a - a^*)^2}{2 \\sigma_0^2})}{\\pi(a_i | X_i)} - u_i + v_i = 0, \\forall i=1..., n + 1, \\\\ & u_i, v_i \\geq 0, \\forall i=1..., n + 1,\n\\end{array}\nfor the imputed score $S_{n+1} = S$. As the score is unknown, computing the CP interval would require solving (Ps) for all $S \\in \\mathbb{R}$, yet which is computationally infeasible. As a remedy, we"}, {"title": "Algorithm", "content": "We now use our Theorem 3 to present an algorithm for computing CP intervals of potential outcomes from continuous treatment variables under unknown propensities in Alg. 2. We present a similar algorithm for scenario with known propensities in Supplement B.\nWe make the following comments: In our algorithm, an optimization solver is used to calculate $\\eta_{n+1}$ according to Theorem 3. The specific choice of the solver is left to the user. In our experiments in Section 5, we perform the optimization via interior point methods. Further, the overall goal of our algorithm is to find the optimal imputed non-conformity score $S^*$ such that the coverage guarantees hold. This search can be implemented through suitable iterative search algorithms."}, {"title": "Experiments", "content": "Synthetic datasets: We follow common practice in causal ML and evaluate our methods using synthetic datasets [e.g., 1, 22]. The reason is the fundamental problem of causal inference, because of which counterfactual outcomes are never observable in real-world datasets. Synthetic datasets enable us to access counterfactual outcomes and, thus, to benchmark methods in terms of whether the computed intervals are faithful.\nWe consider two synthetic datasets with different propensity scores and outcome functions. Dataset 1 uses a step-wise propensity function and a concave outcome function. Dataset 2 is more complex and uses a Gaussian propensity function and oscillating outcome functions. Both datasets contain a single discrete confounder, a continuous treatment, and a continuous outcome. By choosing low-dimensional datasets, we later render it possible to plot the treatment-response curves so that one can inspect the prediction intervals visually. (We later also show that our method scales to high-dimensional settings as part of the real-world dataset.) Details about the data-generating processes are in Supplement E.\nReal-world dataset: We demonstrate the applicability of our CP method to datasets from medicine by leveraging the MIMIC-III dataset [30]. MIMIC-III contains de-identified health records from patients admitted to critical care units at large tertiary care hospitals. Our goal is to predict patient outcomes in terms of blood pressure when treated with a different duration of mechanical ventilation. We use 8 confounders from medical practice (e.g., respiratory rate, hematocrit). Overall, we consider 14,719 patients, which we randomly split into train (60%), validation (10%), calibration (20%), and test (10%). Further details are in Supplement E.\nBaselines: As we have discussed above, there are no baselines that directly compute finite-sample prediction intervals for potential outcomes of continuous treatments. The only comparable method is MC dropout [12]. Yet, we again emphasize that MC dropout is an ad hoc method with poor approximations of the posterior, which is known to give intervals that are not faithful [27].\nImplementation: All methods are implemented with as a multi-layer perception (MLP) and an MC dropout regularization of rate 0.1. Crucially, we use the identical MLP for both our CP method and MC dropout. Hence, all performance gains must be attributed to the coverage guarantees of our conformal method. In the MC dropout baseline, the uncertainty intervals are computed via Monte Carlo sampling. In scenario 2 with unknown propensity scores, we perform the conditional density estimation through conditional normalizing flows [41]. Details about our implementation and training are in Supplement E.\nPerformance metrics: We evaluate the methods in terms of whether the prediction intervals are faithful [e.g., 19]. That is, we compute whether the empirical coverage of the prediction intervals surpasses the threshold of $1 - \\alpha$ for different significance levels $\\alpha \\in \\{0.05, 0.1, 0.2\\}."}, {"title": "Results for synthetic datasets", "content": "We make the following observations. First, the intervals of our CP method comply with the targeted significance level $\\alpha$ and, therefore, are faithful. Second, MC dropout has, in contrast, a considerably lower coverage, implying that the intervals are not faithful. This is in line with the literature, where MC dropout is found to produce poor approximations of the posterior [27]. Third, our method has only a small variability in terms of empirical coverage, whereas the empirical coverage of MC dropout varies greatly. This corroborates the robustness of our method. Fourth, the results are consistent for both datasets. In sum, this demonstrates the effectiveness of our proposed CP method.\nInsights: We plot the prediction intervals across different significance levels $\\alpha$ and different covariates $X$ (see Fig. 6). This allows us to inspect the intervals visually. Overall, there is only a small difference between the true outcome and the prediction, which confirms the overall good fit of the model. Next, we observe that the intervals behave as expected; that is, the intervals become sharper with increasing significance level $\\alpha$. We further see that our CP intervals are slightly wider (see details in Supplement F), yet this is intended because it ensures that the intervals are faithful. For example, our CP intervals (blue) generally include the true outcome. In contrast, the intervals from MC dropout (orange) often do not include the true outcome (e.g., see the bottom row Fig. 6) and are thus not faithful."}, {"title": "Results for the MIMIC dataset", "content": "In Fig. 7, we compare the CP intervals of each two male and female patients of differing ages when treated with increasing duration of mechanical ventilation. Our intervals show higher uncertainty in treatment regions rarely included in the training data (high medium to high treatments)."}, {"title": "Discussion", "content": "Conclusion: We presented a novel conformal prediction method for potential outcomes of continuous treatments with finite-sample guarantees. Our method is applicable to potential outcomes and extends naturally to treatment effects. A key strength of our method is that the intervals are valid under distribution shifts introduced by the treatment assignment, even if the propensity score is unknown and has to be estimated.\nLimitations: As with any other method, our UQ method has limitations that offer opportunities for future research. Our method relies on the quality of the propensity estimator. Although we incorporate estimation errors in the construction of our intervals, poorly estimated propensities could potentially lead to wide prediction intervals. We acknowledge that our prediction intervals are conservative for the hard intervention and for segments of the output space with limited calibration data, implying that a representative calibration dataset is essential for the performance of our method. As for all CP methods, the use of sample splitting may reduce data efficiency.\nBroader impact: Our method makes a significant step toward UQ for potential outcomes and, therefore, toward reliable decision-making. To this end, we provided strong theoretical and empirical evidence that our prediction intervals are valid. To this end, our method fills an important demand for using causal ML in medical practice [11] and other safety-critical applications with limited data."}, {"title": "Algorithm", "content": "In our main paper, we presented an algorithm for computing the prediction intervals if the propensity score is unknown. Below, we state a second algorithm that is applicable if the propensity score is known. In this case, a convex optimization solver can be used."}, {"title": "Proofs", "content": "In the following, we prove Lemma 2 and Lemma 3 from our main paper.\nProof of Lemma 2 Recall the definition of the hard intervention\n$\\pi'(a | x) = \\delta_{a^*}(a) = \\frac{\\delta_{a^*}(a) \\pi(a | x)}{\\pi(a | x)},$\nwhere\n$\\delta_{a^*}(a) = \\lim_{\\sigma \\rightarrow 0} \\frac{1}{\\sqrt{2 \\pi \\sigma}} \\exp(-\\frac{(a - a^*)^2}{2 \\sigma^2}).$\nUnder Assumption 1, we have\n$\\frac{\\pi(a | x)}{\\pi(a | x)} =: c_a \\in [\\frac{1}{M}, M]$\nfor some $M > 0$ and all $a, x$. Then\n$\\lim_{\\sigma \\rightarrow 0} \\frac{1}{\\sqrt{2 \\pi \\sigma}} \\frac{\\exp(-\\frac{(a - a^*)^2}{2 \\sigma^2})}{\\pi(a | x)} \\leq \\frac{1}{\\pi(a^* | x)} \\leq \\lim_{\\sigma \\rightarrow 0} \\frac{1}{\\sqrt{2 \\pi \\sigma}} \\frac{\\exp(-\\frac{(a - a^*)^2}{2 \\sigma^2})}{\\pi(a | x)}M.$\nTherefore, the distribution shift induced by the hard intervention can be represented as\n$f(a, x) = \\lim_{\\sigma \\rightarrow 0} \\frac{c_a}{\\sqrt{2 \\pi \\sigma}} \\frac{\\exp(-\\frac{(a - a^*)^2}{2 \\sigma^2})}{\\pi(a | x)} \\in \\mathcal{F} := \\{\\frac{c_a}{\\sqrt{2 \\pi \\sigma}} \\frac{\\exp(-\\frac{(a - a^*)^2}{2 \\sigma^2})}{\\pi(a | x)}, \\mid 0 < \\sigma, c_a \\in [\\frac{1}{M}, M]\\}.$\nProof of Lemma 3 We first prove that the problem (Ps) fulfills the linear independence constraint qualifications. For all $i = 1, . . ., n + 1$, we denote the constraints of problem (Ps) as\n$h_i(u, v, c_a, \\sigma) := S_i - \\frac{c_a}{\\sqrt{2 \\pi \\sigma}} \\frac{\\exp(-\\frac{(a - a^*)^2}{2 \\sigma_0^2})}{\\pi(a_i, X_i)} - u_i + v_i.$\nThe gradient of $h_i$ is given by\n$\\bigtriangledown h_i(u, v, c_a, \\sigma) = \\begin{pmatrix}\n\\frac{\\partial h_i}{\\partial u_1}(u, v, c_a, \\sigma) \\\\\n\\frac{\\partial h_i}{\\partial v_1}(u, v, c_a, \\sigma) \\\\\n... \\\\\n\\frac{\\partial h_i}{\\partial u_i}(u, v, c_a, \\sigma) \\\\\n\\frac{\\partial h_i}{\\partial v_i}(u, v, c_a, \\sigma) \\\\\n... \\\\\n\\frac{\\partial h_i}{\\partial c_a}(u, v, c_a, \\sigma) \\\\\n\\frac{\\partial h_i}{\\partial \\sigma}(u, v, c_a, \\sigma)\n\\end{pmatrix} = \\begin{pmatrix}\n0 \\\\\n0 \\\\\n... \\\\\n-1 \\\\\n1 \\\\\n... \\\\\n-\\frac{1}{\\sqrt{2 \\pi \\sigma}} \\frac{\\exp(-\\frac{(a - a^*)^2}{2 \\sigma_0^2})}{\\pi(a_i, X_i)} \\\\\n\\frac{c_a(a_i - a^*)^2}{2 \\sqrt{2 \\pi \\sigma^4}} \\frac{\\exp(-\\frac{(a - a^*)^2}{2 \\sigma_0^2})}{\\pi(a_i, X_i)}\n\\end{pmatrix}.$\nTherefore, with $\\bigtriangledown h := (\\bigtriangledown h_1, ..., \\bigtriangledown h_{n+1})$ and $\\lambda \\in \\mathbb{R}^{n+1}$, we obtain\n$\\bigtriangledown h \\cdot \\lambda = 0 \\Leftrightarrow \\lambda = 0 \\in \\mathbb{R}^{n+1}.$"}, {"title": "Extended literature review", "content": "In the following, we present related work on CP for causal quantities in more detail.\nRecently, Alaa, Ahmad, and van der Laan [1] provided predictive intervals for CATE meta-learners under the assumption of full knowledge of the propensity score. As an extension, Jonkers et al. [23] proposed a Monte-Carlo sampling approach to receive less conservative intervals. Nevertheless, both methods are restricted to binary treatments.\nOther works focus on prediction intervals for off-policy prediction [39, 49] and conformal sensitivity analysis [47], thus neglecting estimation errors arising from propensity or weight estimation or for randomized control trials [24, 29]. Wang, Li, and Yu [44] constructed intervals with treatment-conditional coverage of discrete treatments.\nAiming for group-conditional coverage, Wang, Li, and Yu [44] adapted CP to cluster randomized trials. Nevertheless, the method only applies to a finite number of treatments and thus is not applicable to continuous treatments.\nOverall, no method can provide exact intervals for continuous treatments. Especially, no method considers the error arising from propensity estimation in the analysis."}, {"title": "Experimentation details", "content": "We consider two different propensity and outcome functions. In each setting, we assign two types of interventions: a known propensity shift of $A = 1,5, 10$, i.e., three soft interventions $a^* = a + \\Delta$, and the hard interventions $a^* \\in \\{1x, 5x, 10, \\}$ given the confounder $X = x$.\nWe generate synthetic datasets for each setting. Specifically, we draw each 2000 train, 1000 calibration, and each 1000 test samples per intervention from the following structural equations. Dataset 1 is given by\n\\begin{aligned}\nX &\\sim \\text{Uniform} [1,4] \\quad \\text{(integer)} \\\\\nA &\\sim p \\cdot \\text{Uniform}[0, 5X) + (1 - p) \\cdot \\text{Uniform} [5X, 40], \\quad p \\sim \\text{Bernoulli}(0.3) \\\\\nY &\\sim \\sin(\\frac{\\pi}{5} (0.1A - 0.5X)) + \\text{Normal}(0, 0.1),\n\\end{aligned}\nand dataset 2 by\n\\begin{aligned}\nX &\\sim \\text{Uniform} [1,4] \\quad \\text{(integer)} \\\\\nA &\\sim \\text{Normal}(5X, 10) \\\\\nY &\\sim \\sin ((\\frac{\\pi}{5} (0.1A - 0.1X)) + \\text{Normal}(0,0.1),\n\\end{aligned}\nMedical dataset\nWe use the MIMIC-III dataset [30], which includes electronic health records (EHR) from patients admitted to intensive care units. From this dataset, we extract 8 confounders (heart rate, sodium blood pressure, glucose, hematocrit, respiratory rate, age, gender) and a continuous treatment (mechanical ventilation) using an open-source preprocessing pipeline [45]. From each patient trajectory in the EHRs, we sample random time points and average the value of each variable over the ten hours before the sampled time point. We define the variable blood pressure after treatment as the outcome, for which we additionally apply a transformation to be more dependent on the treatment and less on the blood pressure before treatment. We remove all patients (samples) with missing values and outliers from the dataset. Outliers are defined as samples with values smaller than the 0.1th percentile or larger than the 99.9th percentile of the corresponding variable. The final dataset contains 14719 samples, which we split into train (60%), val (10%), calibration (20%), and test (10%) sets.\nImplementation details\nOur experiments are implemented in PyTorch Lightning. We provide our code in our GitHub repository.\nWe limited the experiments to standard multi-layer perception (MLP) regression models, consisting of three layers of width 16 with ReLu activation function and MC dropout at a rate of 0.1, optimized via Adam. We did not perform hyperparameter optimization, as our method aimed to provide an agnostic prediction interval applicable to any prediction model. All models were trained for 300 epochs with batch size 32.\nOur algorithm requires solving (non-convex) optimization problems through mathematical optimization. We chose to employ two interior-point solvers in our experiments: For the experiments with soft interventions that pose convex optimization problems, we used the solver MOSEK. For the hard interventions, which included non-convex problems, we used the solver IPOPT. Both solvers were run with default parameters.\nInterpretation of optimal parameters\nTo obtain CP intervals under an unknown distribution shift, we approximate the Dirac-delta distribution representing the hard intervention by a Gaussian function as\n$\\delta_a (a) = \\lim_{\\sigma \\rightarrow 0} \\frac{1}{\\sqrt{2 \\pi \\sigma}} \\exp(-\\frac{(a - a^*)^2}{2 \\sigma^2}).$\nIn Theorem 3, we thus optimize over $\\sigma > 0$ and $c_a \\in [\\frac{1}{M}, M]$ to obtain the $(1 - \\alpha)$-quantile of the distribution shift-calibrated non-conformity scores. The optimal parameter $\\sigma^*$ represents a trade-off between the uncertainty in the prediction and the uncertainty in the interval construction: A small $\\sigma^*$ closest resembles the propensity of the hard intervention. Thus, with sufficient or even infinite data close to $a^*$, we could construct the narrowest CP interval. However, the smaller $\\sigma$, the less data close to $a^*$ will be available to calculate the prediction interval in practice. As a result, many calibration data samples will be strongly perturbed during the calculation, which increases the uncertainty and, thus, the interval size."}]}