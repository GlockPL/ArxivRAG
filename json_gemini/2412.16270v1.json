{"title": "METASCIENTIST: A Human-AI Synergistic Framework for Automated Mechanical Metamaterial Design", "authors": ["Jingyuan Qi", "Zian Jia", "Minqian Liu", "Wangzhi Zhan", "Junkai Zhang", "Xiaofei Wen", "Jingru Gan", "Jianpeng Chen", "Qin Liu", "Derek Ma", "Bangzheng Li", "Haohui Wang", "Adithya Kulkarni", "Muhao Chen", "Dawei Zhou", "Ling Li", "Wei Wang", "Lifu Huang"], "abstract": "The discovery of novel mechanical metamaterials, whose properties are dominated by their engineered structures rather than chemical composition, is a knowledge-intensive and resource-demanding process. To accelerate the design of novel metamaterials, we present METASCIENTIST, a human-in-the-loop system that integrates advanced AI capabilities with expert oversight with two primary phases: (1) hypothesis generation, where the system performs complex reasoning to generate novel and scientifically sound hypotheses, supported with domain-specific foundation models and inductive biases retrieved from existing literature; (2) 3D structure synthesis, where a 3D structure is synthesized with a novel 3D diffusion model based on the textual hypothesis and refined it with a LLM-based refinement model to achieve better structure properties. At each phase, domain experts iteratively validate the system outputs, and provide feedback and supplementary materials to ensure the alignment of the outputs with scientific principles and human preferences. Through extensive evaluation from human scientists, METASCIENTIST is able to deliver novel and valid mechanical metamaterial designs that have the potential to be highly impactful in the metamaterial field.", "sections": [{"title": "1 Introduction", "content": "Metamaterials are microstructured materials whose properties go beyond those of the ingredient materials, often possessing unusual mechanical and/or functional properties (Kadic et al., 2019; Bertoldi et al., 2017; Jia et al., 2020; Jiao and Alavi, 2021; Bauer et al., 2017). The advancements in metamaterials have fostered a vast amount of technological innovations across various key domains, such as structural, sensing, actuation, and multifunctional materials innovations. However, human scientists are facing two critical challenges in designing and discovering novel metamaterials.\nFirst, as the field of metamaterial expands exponentially, it becomes increasingly challenging for researchers to keep pace with the rapid accumulation of knowledge. For instance, the number of metamaterial-related publications has grown from 156 papers in 2000, 7,170 papers in 2010, to over 30,000 papers in 2023 based on Google Scholar statistics. The rapid proliferation of research has created significant barriers to effectively understanding and building upon existing work, ultimately slowing down the pace of technological innovation. Second, existing workflows for metamaterial design impose substantial cognitive and resource burdens throughout their multi-stage development process. From initial conceptualization through theoretical modeling, computational simulation, and experimental validation, each phase demands significant human expertise and creativity while incurring considerable time and financial costs. These combined constraints severely limit both the exploration of new concepts and the scaling of successful designs for practical applications.\nRecent breakthroughs in large language models (LLMs) have inspired the development of autonomous scientists to automate aspects of the research process, such as generating novel research ideas and outlining implementation procedures (Zhang et al., 2024b). However, in specialized scientific domains like metamaterial design, several recent studies (Hong, 2023; Park et al., 2024; Deb et al., 2024) have highlighted significant limitations even in state-of-the-art models like GPT-40 (OpenAI et al., 2024). While these models can boldly synthesize vast amounts of scientific knowledge and propose testable hypotheses, they are prone to high factual error rates, often stemming from confusion caused by similar nomen-"}, {"title": "2 Implementation of METASCIENTIST", "content": "While existing general-purpose LLMs excel at a wide range of NLP tasks, they often struggle in highly specialized domains such as materials science (Song et al., 2023). To address this challenge, we first collect 5,611 research papers and books from Google Scholar based on a list of keywords that are provided by a domain expert and related to metamaterial design or general domain knowledge of materials science. We then design a comprehensive data-cleaning process and convert them"}, {"title": "2.1 Foundation Model for Metamaterials Science", "content": "into plain text. Based on this corpus, we finetune an open-sourced LLM, i.e., Llama3-8B-Instruct, using the Low-Rank Adaptation (LoRA) technique (Hu et al., 2022), and tailor the model to the metamaterials science domain. To qualitatively evaluate this model, we ask a domain expert to provide a list of question-answer pairs and compare it against an open-source LLM baseline."}, {"title": "2.2 Hypothesis Generation", "content": "Generating novel, feasible, and scientifically sound hypotheses requires strong reasoning capability based on existing knowledge and literature. To this end, we equip our domain-specific foundation model in \u00a72.1 with a recent state-of-the-art complex reasoning framework, i.e., Socratic Questioning (Qi et al., 2023), to generate novel hypotheses. Specifically, the hypothesis generation process consists of three key steps.\nHigh-Level Hypothesis Generation Since the properties of lattice materials are dominated by their structure, in the first step, we focus on generating a high-level hypothesis that is novel and reasonable with normalized materials properties. With the Socratic Questioning module, we first perform a top-down exploration process that recursively decomposes a complex research question, e.g., \"how to generate a metamaterial that exhibits high stiffness and strength, and is damage tolerant\", into several simpler sub-questions, such as \"what properties should a material have to be damage tolerant\u201d, and \u201cwhat are the common techniques to enhance both stiffness and strength\". With the solutions of the sub-questions proposed by LLM itself, e.g., \u201ca material should have high Young's modulus and Shear modulus to be damage tolerant\", we employ a bottom-up backtracking process selectively leverage these answers to infer the hypothesis to solve the original research question, e.g., \u201cOctet or Kelvin structures might be promising to solve the question\u201d.\nWhile the Socratic Questioning module can generate seemingly reasonable hypotheses, our preliminary experiments show that these automatically generated high-level hypotheses still suffer from several critical issues, including hallucinations, limited novelty, or deviating from desired directions. Therefore, we involve domain experts to provide feedback, either natural language feedback or relevant papers, which are then incorporated as additional context when solving the original research question during the bottom-up backtracking process, encouraging the model to generate more valid and novel hypotheses that are aligned with human expectations.\nInductive Bias Extraction The hypotheses proposed by human scientists are inherently shaped by inductive biases, i.e., existing knowledge and initial assumptions. A valid and novel hypothesis needs to excel in two aspects: it must be grounded in established knowledge while offering distinct contributions beyond existing literature. Thus, we propose an inductive bias extraction module that extracts relevant knowledge from multiple sources, including (1) internal inductive bias which is elicited from LLM itself by prompting it based on an expert-written taxonomy, e.g., Based on the taxonomy, compile a list of known lattice structures relevant to the hypothesis...; and (2) external inductive biases, which are summaries of relevant articles retrieved from our collected literature corpus introduced in \u00a72.1. In this process, we use the concatenation of an original research question and a high-level hypothesis as the query, ColBERT (Khattab and Zaharia, 2020) as the text encoder, and L2 as the distance metric to retrieve top-K relevant articles to the query. We then use GPT-40 to locate the relevant content to the query within each paper and summarize it into one paragraph for each article.\nThe inductive biases may contain information that is outdated or irrelevant to the query, thus we involve domain experts to either directly refine the outputs by removing undesired inductive biases or provide feedback to improve the retrieval process, such as providing additional keywords for more accurate retrieval, directly uploading relevant papers, or providing textual supplementary materials.\nFine-grained Hypothesis Generation We further leverage the inductive biases as additional evidence, i.e., feeding them together with the original research question as input to the Socratic Questioning module, to refine the initial hypothesis into a fine-grained description of features and attributes that inform the structure design of the new target metamaterial. In our system, we primarily consider three critical attributes, i.e., Young's Modulus, Shear Modulus, and Poisson's Ratio, for later 3D structure generation. As the model may not be"}, {"title": "2.3 3D Structure Synthesis", "content": "Our next step is to generate a 3D lattice structure that aligns with the previously generated hypothesis. This phase consists of two steps: generating 3D structures conditioned on the lattice properties in the fine-grained hypothesis using a diffusion model, and further refining the generated structures based on human feedback with a refinement model.\n3D Structure Generation As shown in Figure 2, the initial 3D structure is generated with two components: (1) Vertices Coordinate Diffusion, which generates the 3D coordinates of the lattice vertices. It takes two inputs: random Gaussian noise and the lattice properties derived from the hypothesis generated in the preceding phase. The Gaussian noise, which matches the dimensionality of the 3D vertex coordinates, is input as a sequence of 3-dimensional tuples. The lattice properties are incorporated into the diffusion model via an attention mechanism implemented in the transformer sub-blocks. Specifically, the attention mechanism uses three components: query, key, and value. The query term is generated through a linear projection of the lattice properties, while the key and value terms are derived either from the input Gaussian noise or from the output of the previous transformer sub-block. Through iterative denoising, the diffusion block progressively refines the 3D coordinates, transforming the initial noise into structured vertex positions that align with the given lattice properties. (2) Lattice Edge Prediction, which predicts edges between vertices. It uses a multi-layer perceptron (MLP) to evaluate the similarity between vertex representations and determine the presence or absence of edges. This module ensures the generated 3D lattice structure is cohesive and consistent with the hypothesized properties.\n3D Structure Refinement While the 3D lattice generation module can produce new and reasonable structures, it's still challenging to ensure the sym-"}, {"title": "3 Experiments and Evaluation", "content": "Case Study To demonstrate the effectiveness of METASCIENTIST, we present a case study focusing on a classical weight minimization problem in materials science, as shown in Figure 3. The weight minimization problem represents an ideal test case for METASCIENTIST as it combines fundamental materials science challenges with clear industrial applications - designing structures that maximize support while minimizing material usage requires sophisticated reasoning about mechanical constraints while allowing for quantitative evaluation through well-established metrics. We present more additional case studies in Appendix B.1.\nFrom the case study shown in Figure 3, we have the following observations. First, our system demonstrates superior performance in generating reasonable high-level hypotheses. For instance, when presented with the weight minimization problem, our fine-tuned foundation model directly proposed the octet lattice structure, recognizing its"}, {"title": "4 Related Works", "content": "Automated scientific discovery has progressed significantly given the recent advancements of large foundation models (Wang et al., 2023; Lu et al., 2024; Papadimitriou et al., 2024; Xiong et al., 2024; Ishikawa, 2024), such as logical reasoning (Sun et al., 2024), multi-agent collaboration (Ma et al., 2024; Jansen et al., 2024; Baek et al., 2024; Arawjo et al., 2024), tool and retrieval-based augmentation (Prince et al., 2024; Qi et al., 2024; Huang et al., 2024). However, the application of AI and LLMs for autonomous novel material discovery faces several challenges, including high error rates and hallucinations (Lehr et al., 2024; Miret and Krishnan, 2024), lacking interpretability (Liu et al., 2024; Lei et al., 2024), rigorous logical and mathematical reasoning capabilities (Park et al., 2024; Deb et al., 2024; Zhang et al., 2024a), leading to scientifically unsound or unverifiable hypotheses. Additionally, LLMs often struggle to extrapolate beyond existing knowledge due to the nature of their pre-training objective (Petroni et al., 2019; Achiam et al., 2023). To address these challenges, METASCIENTIST employs a human-in-the-loop approach to integrate expert feedback and domain-specific knowledge into the design of novel materials, which significantly mitigates hallucinations and aligns outputs with scientific principles."}, {"title": "5 Conclusion", "content": "We propose METASCIENTIST that accelerates the discovery of novel metamaterials by integrating advanced AI capabilities with expert oversight. Experiments and human evaluation demonstrate that METASCIENTIST can generate reasonable and valid metamaterial design given the user's research question. Future works include improving the validity of lattice properties using more advanced retrieval techniques and building more powerful models to generate 3D metamaterial structures in more diverse scenarios. We believe our work has significant potential to advance the field of metamaterial design and other broad scientific domains."}, {"title": "A More Implementation Details of METASCIENTIST", "content": "To construct a high-quality dataset for metamaterials science, we first ask a domain expert to provide a list of keywords related to metamaterial design, retrieve and download around 5,000 research papers and books in PDF format from Google Scholar. We then utilize specialized toolkits, including pdfplumber, PyPDF29 and pdfminer10, combined with GPU-accelerated parsing11 to convert the PDF documents to plaintext. To ensure the quality of the extracted text, we further employ rule-based filtering and natural language processing techniques to remove conversion errors, irrelevant content, and noise from the text. Specifically, we begin by leveraging regular expressions to identify and eliminate formatting errors, symbolic noise, and other low-quality elements in the extracted text. Subsequently, natural language processing tools such as SpaCy12 and NLTK13 are employed for sentence segmentation, enabling the removal of incoherent or contextually irrelevant fragments. Finally, we utilize text similarity algorithms (Reimers and Gurevych, 2019; Gao et al., 2021) to detect and remove redundant paragraphs and sentences, ensuring the uniqueness and relevance of processed text.\nFinally, we categorize the cleaned text corpus into two subsets: (1) A domain-specific subset that includes academic papers and textbooks specifically focused on metamaterials science. Accounting for 80% of the whole training corpus, this subset provides specialized knowledge and ensures a deep focus on the target domain. (2) A general-domain subset that contains scientific papers about other topics in materials science and accounts for 20% of the training corpus. This subset offers foundational knowledge about the board materials science field, complementing the domain-specific insights."}, {"title": "A.1 Foundation Model for Metamaterials Science", "content": "To construct a high-quality dataset for metamaterials science, we first ask a domain expert to provide a list of keywords related to metamaterial design, retrieve and download around 5,000 research papers and books in PDF format from Google Scholar. We then utilize specialized toolkits, including pdfplumber, PyPDF29 and pdfminer10, combined with GPU-accelerated parsing11 to convert the PDF documents to plaintext. To ensure the quality of the extracted text, we further employ rule-based filtering and natural language processing techniques to remove conversion errors, irrelevant content, and noise from the text. Specifically, we begin by leveraging regular expressions to identify and eliminate formatting errors, symbolic noise, and other low-quality elements in the extracted text. Subsequently, natural language processing tools such as SpaCy12 and NLTK13 are employed for sentence segmentation, enabling the removal of incoherent or contextually irrelevant fragments. Finally, we utilize text similarity algorithms (Reimers and Gurevych, 2019; Gao et al., 2021) to detect and remove redundant paragraphs and sentences, ensuring the uniqueness and relevance of processed text.\nFinally, we categorize the cleaned text corpus into two subsets: (1) A domain-specific subset that includes academic papers and textbooks specifically focused on metamaterials science. Accounting for 80% of the whole training corpus, this subset provides specialized knowledge and ensures a deep focus on the target domain. (2) A general-domain subset that contains scientific papers about other topics in materials science and accounts for 20% of the training corpus. This subset offers foundational knowledge about the board materials science field, complementing the domain-specific insights."}, {"title": "A.1.1 Data Collection", "content": "To construct a high-quality dataset for metamaterials science, we first ask a domain expert to provide a list of keywords related to metamaterial design, retrieve and download around 5,000 research papers and books in PDF format from Google Scholar. We then utilize specialized toolkits, including pdfplumber, PyPDF29 and pdfminer10, combined with GPU-accelerated parsing11 to convert the PDF documents to plaintext. To ensure the quality of the extracted text, we further employ rule-based filtering and natural language processing techniques to remove conversion errors, irrelevant content, and noise from the text. Specifically, we begin by leveraging regular expressions to identify and eliminate formatting errors, symbolic noise, and other low-quality elements in the extracted text. Subsequently, natural language processing tools such as SpaCy12 and NLTK13 are employed for sentence segmentation, enabling the removal of incoherent or contextually irrelevant fragments. Finally, we utilize text similarity algorithms (Reimers and Gurevych, 2019; Gao et al., 2021) to detect and remove redundant paragraphs and sentences, ensuring the uniqueness and relevance of processed text.\nFinally, we categorize the cleaned text corpus into two subsets: (1) A domain-specific subset that includes academic papers and textbooks specifically focused on metamaterials science. Accounting for 80% of the whole training corpus, this subset provides specialized knowledge and ensures a deep focus on the target domain. (2) A general-domain subset that contains scientific papers about other topics in materials science and accounts for 20% of the training corpus. This subset offers foundational knowledge about the board materials science field, complementing the domain-specific insights."}, {"title": "A.1.2 Model Training and Evaluation", "content": "The model was trained using a learning rate of $2 \\times 10^{-4}$ and the Adam optimizer (Kingma, 2014) with $\\epsilon = 1 \\times 10^{-8}$. A cosine learning rate scheduler was employed, with a warmup ratio of 0.1. For fine-tuning, we utilized LoRA with lora_alpha=8 and a dropout rate of 0.05. The training was conducted on 4$\\times$ RTX A6000 GPUs. To ensure optimal performance, models were trained across different numbers of epochs, and the version trained for 5 epochs was selected as the final iteration.\nComparison of Foundation model and Llama 3-8B As shown in Figure 4, the comparison highlights the differences in the responses generated by the Foundation Model (Ours) and the baseline LLaMA3-8B-Instruct model for material science-related questions. The Foundation Model exhibits a more detailed and contextually grounded understanding, integrating advanced scientific concepts such as the negative material index and the Hashin-Shtrikman bounds. Additionally, it provides clear examples of biological metamaterials, including the exoskeleton of the crab and the shell of the abalone, demonstrating a deeper domain-specific reasoning capability.\nIn contrast, the responses from the LLaMA3-8B-Instruct model are either overly generalized, repetitive, or lack sufficient scientific detail to address the questions effectively. This qualitative comparison underscores the improved performance of the Foundation Model in tasks requiring domain knowledge and contextual comprehension."}, {"title": "A.2 Hypothesis Generation", "content": "More details on Inductive Biases Extraction\nWe let a domain expert in metamaterial science domain curate a metamaterial taxonomy for eliciting internal relevant knowledge from LLMs as shown in Figure 5 and Figure 6."}, {"title": "A.3 3D Structure Synthesis", "content": "Training Details for 3D Structure Generation\nTo train our 3D structure synthesis models, we extend the Modulus (Lumpe and Stankovic, 2021) dataset by applying scaling and rotation transformations to its lattice topologies, paired with adjusted lattice properties to ensure the dataset captures a broader range of variations. During training, the diffusion block receives 3D coordinates mixed with Gaussian noise as input, along with the corresponding lattice properties as conditioning information. The model predicts the clean 3D coordinates in a single step, and the loss is computed based on the difference between the predicted and ground truth coordinates. Simultaneously, the edge prediction block is trained by comparing its predictions with ground truth vertex connections. This joint training process enables the model to generate accurate and structurally coherent 3D lattice designs.\nTraining Details for 3D Structure Refinement\nThe major difficulty in training the refinement model is the limited availability of paired data showing both unrefined and properly refined lattice structures. While researchers typically publish only their optimized final structures, they often omit documenting the optimization process itself."}, {"title": "B More Experiment Details and Results", "content": "We present additional case studies in Figure 7. From this case study focusing on designing a lattice structure for a robotic fingertip that mimics human hand properties, we have the following observations. First, our system effectively incorporates domain expertise through human feedback and supplementary materials. Though our fine-tuned foudation model proposed a more sophisticated hierarchical octet topology with gradient volume fraction, when provided with expert feedback emphasizing high stiffness and strength requirements, along with relevant papers on human finger pad mechanics and 3D lattice structures, our systems converged on the Kelvin cell configuration focusing primarily on isotropy. The supplementary materials also helped establish reasonable ranges for mechanical properties in the fine-grained hypothesis, particularly in matching human tissue characteristics. Second, we demonstrate that our refinement model can successfully optimize the generated lattice structure for improved mechanical symmetry. The initial structure showed variations in Young's modulus (ranging from 3.00e-02 to 3.79e-02) and significant anisotropy in Poisson ratios (ranging from 4.23e-02 to 2.02e-01). Through our refinement process, these properties were harmonized to achieve perfect cubic symmetry with consistent values (Young's modulus of 3.19e-02 and Poisson ratio of 2.97e-01)."}, {"title": "B.1 Case Studies", "content": "We present additional case studies in Figure 7. From this case study focusing on designing a lattice structure for a robotic fingertip that mimics human hand properties, we have the following observations. First, our system effectively incorporates domain expertise through human feedback and supplementary materials. Though our fine-tuned foudation model proposed a more sophisticated hierarchical octet topology with gradient volume fraction, when provided with expert feedback emphasizing high stiffness and strength requirements, along with relevant papers on human finger pad mechanics and 3D lattice structures, our systems converged on the Kelvin cell configuration focusing primarily on isotropy. The supplementary materials also helped establish reasonable ranges for mechanical properties in the fine-grained hypothesis, particularly in matching human tissue characteristics. Second, we demonstrate that our refinement model can successfully optimize the generated lattice structure for improved mechanical symmetry. The initial structure showed variations in Young's modulus (ranging from 3.00e-02 to 3.79e-02) and significant anisotropy in Poisson ratios (ranging from 4.23e-02 to 2.02e-01). Through our refinement process, these properties were harmonized to achieve perfect cubic symmetry with consistent values (Young's modulus of 3.19e-02 and Poisson ratio of 2.97e-01)."}, {"title": "B.2 More Details and Results of Human Evaluation for Hypothesis Generation", "content": "We evaluate the generated hypotheses with two aspects, i.e., novelty and feasibility. We ask three senior researchers in the metamaterial domain as the reviewers to score the system-generated hypotheses. Each reviewer gives the scores independently. The evaluation criteria are defined as follows:\nNovelty: Whether the idea is creative and different from existing works on the topic, and brings fresh insights.\n* Score 0 (Low Novelty): The idea closely resembles many existing works with minimal differentiation.\n* Score 1 (Medium Novelty): The idea shows some differences from existing works but has obvious overlaps with prior concepts.\n* Score 2 (High Novelty): The idea introduces major differences, offering distinct insights or approaches absent in existing works."}, {"title": "C Prompts used in METASCIENTIST", "content": "We offer all prompts we used in the METASCIENTIST in Figure 8, 9, and 10."}]}