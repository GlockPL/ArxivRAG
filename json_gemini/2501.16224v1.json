{"title": "Language-Based Bayesian Optimization Research Assistant (BORA)", "authors": ["Abdoulatif Ciss\u00e9", "Xenophon Evangelopoulos", "Vladimir V. Gusev", "Andrew I. Cooper"], "abstract": "Many important scientific problems involve multivariate optimization coupled with slow and laborious experimental measurements. These complex, high-dimensional searches can be defined by non-convex optimization landscapes that resemble needle-in-a-haystack surfaces, leading to entrapment in local minima. Contextualizing optimizers with human domain knowledge is a powerful approach to guide searches to localized fruitful regions. However, this approach is susceptible to human confirmation bias and it is also challenging for domain experts to keep track of the rapidly expanding scientific literature. Here, we propose the use of Large Language Models (LLMs) for contextualizing Bayesian optimization (BO) via a hybrid optimization framework that intelligently and economically blends stochastic inference with domain knowledge-based insights from the LLM, which is used to suggest new, better-performing areas of the search space for exploration. Our method fosters user engagement by offering real-time commentary on the optimization progress, explaining the reasoning behind the search strategies. We validate the effectiveness of our approach on synthetic benchmarks with up to 15 independent variables and demonstrate the ability of LLMs to reason in four real-world experimental tasks where context-aware suggestions boost optimization performance substantially.", "sections": [{"title": "1 Introduction", "content": "Exploring large experimental design spaces requires intelligent navigation strategies because of the costly and time-consuming function evaluations involved. Bayesian optimization has been established as an optimal experimental design methodology in the scientific community across disciplines spanning chemistry [H\u00e4se et al., 2021], solar energy production [Andr\u00e9s-Thi\u00f3 et al., 2024] and agronomy [Zhang et al., 2024]. BO can be used to efficiently navigate combinatorially large landscapes, and to identify promising solutions in an active-learning setting. Typically, BO uses a probabilistic surrogate model to approximate an expensive or unknown objective function f, i.e.,\nx* = argmax f(x),\nx\u0395\u03a7\nwith f : X \u2192 R defined on the compact subset X \u2286 Rd. This surrogate \u2013 often a Gaussian Process (GP) [Garnett, 2023] - subsequently undergoes Bayesian updates as new data about the design space are acquired, according to a pre-defined acquisition policy or function a(\u00b7), allowing for the refinement of target predictions. In turn, this acquisition function suggests the next set of parameters for experiments with the highest expected utility, balancing exploration in new regions and exploitation in promising ones.\nDespite its successful application to a plethora of scientific tasks, BO is frequently characterized by slow initial optimization phases due to random or Latin Hypercube [Poloczek et al., 2016] selections for initial samples. This can substantially slow the search for combinatorially large spaces. This highlights a fundamental challenge for standard BO; that is, the lack of inherent domain knowledge and contextual understanding of the problem at hand. Recently, BO variants have been proposed that are capable of injecting domain-specific knowledge into the search, either through structural problem characteristics [Xie et al., 2023] or by using human expert knowledge [Ciss\u00e9 et al., 2024]. The latter approach, sometimes known as 'Human-in-the-Loop (HIL)', has drawn considerable recent attention, and it aims to infuse domain knowledge and human reasoning into BO workflows [Adachi et al., 2024; Huang et al., 2022]. By leveraging expert insights in the form of hypotheses [Ciss\u00e9"}, {"title": "2 Related Works", "content": "To cope with non-convex optimization landscapes in science tasks, intelligent approaches have been proposed that focus on promising regions through adaptive exploration-exploitation strategies [Shoyeb Raihan et al., 2024], or 'smooth out' the optimization landscape by enriching it with domain knowledge [Ramachandran et al., 2020]. Notable examples include local BO methods that restrict the search space, such as ZoMBI [Siemenn et al., 2023], which aims to improve efficiency by focusing on local regions assumed to contain the optimum. Similarly, TuRBO [Eriksson et al., 2019] uses multiple independent GP surrogate models within identified trust regions and a multi-armed bandit strategy [Vermorel and Mohri, 2005] to decide which local optimizations to continue. These approaches are well-suited to handling high-dimensional problems, but their potential is limited in small budgets and highly multimodal spaces due to a lack of built-in domain knowledge.\nIncorporating domain knowledge into BO can significantly improve both its efficiency and its performance [Adachi et al., 2024; H\u00e4se et al., 2021]. DKIBO [Xie et al., 2023] enhances BO's acquisition function with structural knowledge from an additional deterministic surrogate model to enrich the GP's approximation power. Others, such as ColaBO [Hvarfner et al., 2024] and HypBO [Ciss\u00e9 et al., 2024], allow users to inject their beliefs at the start to guide the optimization process. However, those methods keep the users' beliefs static and cannot refine them as the optimization progresses, even if they are wrong. Meanwhile, other HIL methods rely on frequent user inputs [Savage and del Rio Chanona, 2023] and for robotic experiments [Burger et al., 2020], for example, that run 24/7 in a closed-loop way, waiting for this human user input might become the rate-limiting step.\nRecently, some studies have explored LLMs as standalone"}, {"title": "3 Methodology", "content": "The BORA optimization framework is illustrated in Figure 1. BORA is a fully automated hybrid BO-LLM synergy operating under a common GP whose parameters are updated accordingly as new points are sampled, either from BO or the LLM. A user-provided experiment description is used to initially contextualize the LLM which then warm-starts the optimization with proposed samples through its ICL capabilities. The optimization further progresses by alternating BO and LLM runs that are accordingly triggered by performance plateaus. Our proposed framework employs an adaptive heuristic policy to (a) assess the need to invoke the LLM, (b) determine the type of LLM intervention needed, and (c) update the frequency of those interventions as the optimization progresses. We use Reinforcement Learning (RL) terminology throughout the manuscript to describe our approach, however we use hand-crafted policy update rules, as learning generalized rules in the traditional sense [Liu et al., 2022; Volpp et al., 2020] would be impractical in Bayesian scientific optimization settings [Lee et al., 2020], which is the focus of this work. In its interventions, the LLM provides user interpretability through real-time commentary of the optimization progress and generates hypotheses for maximizing the target objective."}, {"title": "3.1 LLM Comments and Hypotheses", "content": "The LLM is prompt-engineered to return structured JSON responses that we call Comments (for formatting details we refer the reader to the SM). The Comment object, illustrated in Figure 2, contains insights into the optimization progress and potential reasons for stagnation, as well as a list of hypotheses to remedy that stagnation. Each hypothesis includes a meaningful name, a rationale, a confidence level, and the corresponding input point to test it. Unlike in HypBO [Ciss\u00e9 et al., 2024] where hypotheses are defined as rather static regions of interest, BORA dynamically builds hypotheses during the optimization process typically in the form of single search points through the LLM's ICL model. As demonstrated in LLAMBO [Liu et al., 2024], LLMs tasked with regression inherently perform an implicit ICL modeling of the objective function, estimating the conditional distribution p(y|x; D), where y is the target value at x. BORA extends this modeling by integrating all previously gathered data D and all the LLM's comments C, enhancing the LLM surrogate to model p(y|x; D; C). From this augmented model, the LLM proposes hypotheses, exploring regions likely to improve on the current best observation Ymax and derived from the conditional probability xLLM ~ p(x|y > Ymax; D; C)."}, {"title": "3.2 LLM Initialization", "content": "To inform the LLM initially, the user prepares a comprehensive problem description following a standardized template that we refer to as the Experiment Card. This card includes any details or context about the black-box function f to be optimized, descriptions of its input variables, and the target variable to be maximized, along with any constraints that must be satisfied within the search space. From the experiment card, the LLM is prompted to generate ninit initial hypotheses for maximizing the target. This translates into Ninit initial points that are evaluated to form the initial dataset Do = {(xi, Yi = f(xi))}\nNinit\n."}, {"title": "3.3 Actions", "content": "BORA leverages an adaptive heuristic policy detailed in Section 3.4 to choose one action from a set of three possible actions defined in the following paragraphs. The chosen action suggests at least one next point for evaluation, which is evaluated and added to the dataset. While the Vanilla BO action a1 appends one sample (x, y) to Dt\u22121 at each step or iteration t, the LLM action a2 (resp. a3) adds NLLM \u2265 1 (resp. 2) samples, potentially adding multiple samples per step. Hereon, we distinguish between t, the step number, and i, the sample index at step t, and denote with St = {x(i)}i=1 the set of k points suggested by an action a at step t.\n15\na1 Continue with Vanilla BO\nThe acquisition function is maximized to get the next promising point St = {x(i)}, which is then evaluated and added to the dataset to form Dt = Dt\u22121 \u222a {(x, f(x)) | x \u2208 St}.\na2 LLM Comments and Suggests NLLM Points\nA prompt containing the gathered data up to Dt-1 and any previous comments C is given to the LLM. The LLM is then tasked to comment on the optimization progress in light of the new data and to update any previous hypotheses. The returned Comment contains the next points St = {x(i)LLM ~ p(x|y > Ymax; Dt\u22121; C) to evaluate, which are then evaluated and added to the dataset to form Dt.\na3 LLM Comments and Selects 2 BO Points\nFive candidate points {x(i)}B=1 are generated by maximizing the acquisition function. A prompt containing Dt\u22121, C, and {x(i)}B=1 are given to the LLM, which is then tasked to comment on the optimization progress in light of the new data and constrained to select the two most promising BO candidates that best align with its hypotheses for maximizing the target objective. The returned Comment holds the two selected points St = {x(i)}2 ~ p(x \u2208 {xB}15|y > Ymax; Dt-1;C) that are then evaluated and added to the dataset."}, {"title": "3.4 Adaptive Heuristic Policy", "content": "BORA's policy helps it to make informed choices about engaging the LLM without relying on data-hungry RL algorithms, thus maintaining BORA's practicality and effectiveness in real-life scenarios. The optimization starts with the Vanilla BO action a1, and the subsequent action selection depends on (a) the average uncertainty \u03c3GPmean of the common GP over the search space X to determine the necessity and type of LLM intervention, and (b) the BO performance detection, as well as the performance success (or trust in) of the previous LLM interventions. When the GP's uncertainty is high and above a pre-defined threshold (\u03c3GPmean > \u03c3t, upper), BO needs significant guidance from the LLM, triggering a complete 'take-over' by the LLM in the search, suggesting new points informed by its own internal reasoning mechanism. As the GP's uncertainty decreases (\u03c3t,lower \u2264 \u03c3GPmean \u2264 \u03c3t,upper), the LLM becomes less involved by relying only on BO suggested points, but still using its ICL capacity based on both D and C to select the most promising ones. When the GP's uncertainty is low enough (\u03c3GPmean < \u03c3t,lower), BO has a better approximation of objective function's landscape and no longer needs guidance from the LLM. The rationale behind remark (b) is that the LLM should gain more trust as the LLM suggestions exhibit better performance, which in turn triggers the plateau duration to be re-defined as shorter, allowing the LLM to intervene more frequently. Conversely, if the LLM's so-far observed performance declines, its trust in itself diminishes and, consequently, its interventions are reduced, which results in longer plateau duration adjustments before invoking its assistance. In short, the action selection at each step t follows the policy \u03c0 described below, where the GP parameters are updated after every action accordingly:\n\u2022 If \u03c3GPt,mean < \u03c3t, lower or \u2018no plateau\u2019 \u2192 action a1,\n\u2022 Else if \u03c3GPt,mean > \u03c3t,upper \u2192 action a2,\n\u2022 Else \u2192 action a3.\nSelection Mechanism\nUncertainties The above action selection is realized by calculating and updating in every step the uncertainties from a set of fixed q monitoring points Xmon that were randomly sampled before the optimization starts. Specifically,\n\u03c3GPt,mean = 1q \u03a3qi=1 \u03c3t(xmoni), (2)\n\u03c3GPt, upper = max (\u03c3GPt,max, max1\u2264i\u2264q \u03c3t(xmoni)), (3)\n\u03c3GPt, lower = 0.5 \u00d7 \u03c3GPt,max and \u03c3t, lower = 0.3 \u00d7 \u03c3GPt,max, (4)\nwhere \u03c3\u03c4() represents the uncertainty of the GP at a given point in iteration t.\nPlateau Detection Another important part of the action selection mechanism in the proposed framework is the detection of performance plateauing in BO. A performance plateau is detected at step t when\nymat < ymaxmax \u00d7 (1 + sign(ymaxd \u00d7 \u03b3), for all j \u2208 [t-m+1,t],\nwhere ymax = max({y|(x,y) \u2208 Dt}). That is, if for the past m consecutive BO steps, there is not enough performance improvement (w.r.t a set percentage \u03b3), then the LLM involvement is triggered. The plateau duration m is initialized at minit = [2\u221ad], empirically set to vary between mmin"}, {"title": "4 Experiments", "content": "We validated BORA's performance against current state-of-the-art methods on both synthetic functions and various real-world tasks, with dimensionality ranging from 4 to 15 independent variables. Section 4.1 outlines the experimental setup while Section 4.2 highlights the results. Details on the benchmarks, the method implementations, and the reproducibility details can be found in the SM. The source code is available at https://anonymous.4open.science/r/bora-the-explorer."}, {"title": "4.1 Experimental Setup", "content": "Synthetic Function Benchmarks\n\u2022 Branin (2D): A function with a global maximum occurring in three distinct locations as shown in Figure 3. The input space bounds are x \u2208 [-5, 10] and x\u2081 \u2208 [0,15].\n\u2022 Levy (10D): A function with a highly rugged landscape. All inputs are bounded in [-10, 10] with the maximum at [1,..., 1].\n\u2022 Ackley (15D): A challenging high dimensional function with several local maxima. Input bounds are [-30, 20] with the maximum at [0, . . ., 0].\nNote that the names of these functions in the experiment card were anonymized to 'mathematical function' to prevent the LLM from recognizing them by name.\nReal-World Application Benchmarks\n\u2022 Solar Energy Production (4D): Maximizing the daily energy output of a solar panel by optimizing panel tilt, azimuth, and system parameters [Anderson et al., 2023].\n\u2022 P\u00e9tanque Game (7D): A ball is thrown to hit a target. The goal is to maximize the score, which is inversely proportional to the target distance miss, by tuning the throw position, angles, velocity, and spins.\n\u2022 Sugar Beet Production (8D): Maximizing the monthly sugar beet Total Above Ground Production (TAGP) in a greenhouse by tuning the irradiance, and other weather and soil conditions [de Wit and contributors, 2024].\n\u2022 Hydrogen Production (10D) Maximizing the hydrogen evolution rate (HER) for a multi-component catalyst mixture by tuning discrete chemical inputs under the constraint that the total volume of the chemicals must"}, {"title": "5 Conclusions", "content": "This work introduces BORA, the first optimization framework to integrate BO with LLMs in a cost-effective dynamic way for scientific applications. BORA leverages the reasoning capabilities of LLMs to inject domain knowledge into the optimization process, warm-starting the optimization and enabling hypothesis-driven exploration and adaptive strategies to navigate complex, non-convex search spaces. It addresses key limitations in traditional BO methods, including slow initialization, local minimum entrapment, and the lack of contextual understanding. Notably, BORA outperformed BO with the addition of static expert-knowledge-derived hypotheses in a challenging 10D chemistry experiment, Hydrogen Production, highlighting its potential as a collaborative AI tool to support and enhance expert decision making. Future directions will include refining BORA's meta-learning strategies using multi-agent LLMs and exploring its effectiveness in multi-objective, multi-fidelity optimization scenarios."}]}