{"title": "The Stabilizer Bootstrap of Quantum Machine Learning with up to 10000 qubits", "authors": ["Yuqing Li", "Jinglei Cheng", "Xulong Tang", "Youtao Zhang", "Frederic T. Chong", "Junyu Liu"], "abstract": "Quantum machine learning is considered one of the flagship applications of quantum computers, where variational quantum circuits could be the leading paradigm both in the near-term quantum devices and the early fault-tolerant quantum computers. However, it is not clear how to identify the regime of quantum advantages from these circuits, and there is no explicit theory to guide the practical design of variational ans\u00e4tze to achieve better performance. We address these challenges with the stabilizer bootstrap, a method that uses stabilizer-based techniques to optimize quantum neural networks before their quantum execution, together with theoretical proofs and high-performance computing with 10000 qubits or random datasets up to 1000 data. We find that, in a general setup of variational ans\u00e4tze, the possibility of improvements from the stabilizer bootstrap depends on the structure of the observables and the size of the datasets. The results reveal that configurations exhibit two distinct behaviors: some maintain a constant probability of circuit improvement, while others show an exponential decay in improvement probability as qubit numbers increase. These patterns are termed strong stabilizer enhancement and weak stabilizer enhancement, respectively, with most situations falling in between. Our work seamlessly bridges techniques from fault-tolerant quantum computing with applications of variational quantum algorithms. Not only does it offer practical insights for designing variational circuits tailored to large-scale machine learning challenges, but it also maps out a clear trajectory for defining the boundaries of feasible and practical quantum advantages.", "sections": [{"title": "I. INTRODUCTION", "content": "Quantum machine learning (QML) represents a powerful approach with demonstrated applications across multiple scientific domains, from protein folding and drug discovery in biology [1-3] to molecular structure optimization in chemistry [4]. The performance of QML algorithms depends heavily on initial conditions, which is a characteristic shared with classical machine learning. Research shows that optimal initialization of training circuits can reduce convergence time and improve final results [5, 6]. The classical bootstrap [7], a process for searching and optimizing certain parameters under constraints, serves as a crucial step in developing effective variational quantum algorithm initial parameters [8].\nIn general, recent research has established several parameter initialization approaches for QML, including tensor network methods [9], Gaussian initialization techniques [10], matrix product state optimization [11], and deep neural network integration [12]. These initialization methods have advanced QML performance through reduced training epochs, faster loss function convergence, and improved final accuracy. The prior work [8] introduced CAFQA, a novel approach that searches Clifford space with Bayesian optimization to identify optimal quantum states for Variational Quantum Eigensolver (VQE) tasks, naturally leveraging concepts from fault-tolerant quantum computing towards practical applications. In various experiments, CAFQA surpasses the traditional chemical approach of finding a suitable computational basis state known as Hartree-Fock (HF) [13] initialization and even could show 2.5\u00d7 faster convergence than HF for small molecules. While these advances show important progress, current research remains limited to small-scale systems and has no discussion of the dependence on involved dataset. In fact, since the optimization uses Clifford circuits that can be simulated classically due to the famous Gottesman-Knill theorem [14], one could in principle consider extremely large-scale simulations and fruitful data sets beyond the capability of state-vector simulators.\nIn our work, we address such challenges by utilizing high-performance computing to advance QML simulations to the next level, a process we refer to as the stabilizer bootstrap [15]. To set up our problem, we consider a general class of variational circuits with varying measurement observables and entanglement structures. We employ stabilizer circuits consisting of layers of $R_y$ gates and CNOT gates to assess algorithm performance. Specifically, we investigate different CNOT layer structures, including linear and reverse-linear entanglement configurations. These circuits correspond to continuous variational quantum circuits with special variational angles $0, \\frac{\\pi}{2}, \\pi, -\\frac{\\pi}{2}$. We study how much improvement can be achieved for a given trivial initial state by selecting this special set of angles, a concept we term stabilizer enhancement. The stabilizer bootstrap process involves sampling all possible combinations of $0, \\frac{\\pi}{2}, \\pi, -\\frac{\\pi}{2}$"}, {"title": "II. RESULTS", "content": "In this section, we present our work's core results, including key conclusions and primary experimental results.\nThe stabilizer bootstrap employs Bayesian optimization to efficiently explore the space of Clifford operations and optimize parameters. To provide a clearer understanding of this approach, we first outline the fundamental principles of Bayesian optimization and then highlight the importance of sampling. Bayesian optimization consists of two main phases: sampling and optimization. The sampling phase establishes the initial set of points for model training. The optimization phase then proceeds through three sequential steps based on sampled points: (1) Point Selection: Choose the next points to sample based on the acquisition function; (2) Evaluation: Calculate the objective function values for these points. (3) Model Update: Refine the surrogate model with the newly evaluated points. According to optimization theory, if we fail to sample enough useful or nontrivial points, subsequent optimization based on these samples will become challenging. Consider an extreme case: if all sampled points are trivial (e.g., zero in this experiment), the acquisition function will continue selecting the next points far away from current points randomly until it identifies some promising ones. The detailed reason behind this can be found in Appendix A. Besides, since sampling is easier to accelerate by CPU parallelization, we prefer to allocate more computational resources"}, {"title": "III. DISCUSSION", "content": "In this paper, we leverage the stabilizer bootstrap to enhance quantum machine learning (QML) circuits and analyze the challenges in the sampling stage of existing algorithms. Through extensive experiments, we examine the relationship between sampling efficiency and observables. Based on varying sampling efficiencies, we introduce the concepts of weak and strong stabilizer enhancement, demonstrating that our algorithm can scale to large qubit systems and larger datasets with the support of theoretical proofs (proof by induction) and high-performance computing. Additionally, we provide detailed mathematical proofs to substantiate key arguments. Our work not only establishes a practical framework for QML enhancement with numerical tests on systems of up to 10000 qubits but also proposes a novel methodology to quantify the spectrum between classical simulability and potential quantum advantages.\nOur research also raises several new questions for QML enhancement. For instance, how can the general case for $0 < r < 1$ be rigorously proven, and how can this phenomenon be explained purely through the structure of the Clifford space? Furthermore, our current analysis of entanglement structures is limited to linear and reverse-linear configurations, which are dual to each other by exchanging X and Z operators and interchanging strong and weak enhancements. This duality may be further explored using group theory. Additionally, future research could extend this analysis to explore the dependence on data encoding methods, structured datasets, the structures of more diverse variational circuits, the choice of measured operators, and the impact of QML loss functions. Finally, it will be interesting to study how our method could be used in the early fault-tolerant quantum computers, eventually towards Fault-tolerant Application Scale Quantum (FASQ) computing [16], by looking at how our methods could be connected to stabilizer codes in quantum error correction. For instance, one can imagine using similar Bayesian optimization methods to optimize syndrome extraction circuits in this so-called partial syndrome measurement scheme [17]. These directions hold the potential to identify theoretical quantum advantages and address significant practical problems in QML or quantum computing in general."}, {"title": "Appendix A: Background", "content": "QML is a hybrid quantum-classical framework where variational quantum circuits are trained using classical optimization methods to minimize an objective function, as illustrated in FIG. 8. During each training iteration, the feature vectors $(x_1,...,x_n)$ from the classical dataset are first encoded into a quantum state. This state is then conducted by a variational quantum circuit, and the final output state is subsequently measured. With all outcomes of the dataset, we calculate the loss function to evaluate the training efficiency. A classical optimizer is then employed to optimize the variational parameters, like gradient descent. When the loss function converges or achieves small enough, the training ends.\nIn this study, we employ a make classification function to generate a dataset $(x_{i1},..., x_{in}, y_i)$, where each $x_{il}$ represents a feature and $y_i$ denotes the label. To ensure that the encoding quantum circuit is also a Clifford circuit, the features are transferred into {0,1,2,3} and subsequently mapped to the angles {0, \u03c0,\u03c0/2, -\u03c0/2}, respectively. The loss function adopted is the mean squared error (MSE), which is defined as:\n$MSE = \\frac{1}{N}\\sum_{i=1}^{N}(y_i - \\hat{y_i})^2,$\nwhere $\\hat{y_i}$ denotes the predicted label, $y_i$ represents the true label, and N is the size of the dataset.\nBayesian Optimization (BO) is an efficient framework for the global optimization of expensive black-box functions, particularly in scenarios where function evaluations are costly, time-consuming, or require significant computational resources. Unlike traditional optimization methods that rely on gradient, BO is well-suited for optimizing objective functions that are denoted in discrete space, making it suitable for this task in Clifford space."}, {"title": "Appendix B: Proof for Main Theorems", "content": "The formal theorems supporting Table I are given in this section.\nTheorem 1. For an n-qubit circuit with the reverse linear entanglement structure in FIG.2 (composed by one layer of $R_y$ gates and one layer of reverse linear CNOT gates), where the angles of the $R_y$ gates are restricted to the set ${0,\\pi,\\frac{\\pi}{2},-\\frac{\\pi}{2}}$, and the observable is a Pauli-Z string, the probability that the measurement outcome is 1 or \u22121 is both $\\frac{1}{4}$, while the probability that the outcome is 0 is $\\frac{1}{2}$.\nProof. We use mathematical induction to prove the theorem:\nFor the sake of discussion, we define the states in the eigenspace of $Z \\otimes Z$ with eigenvalue 1 as 1-states, those in the eigenspace with eigenvalue -1 as -1-states, and the remaining states as 0-states. Since the circuit is a Clifford circuit, the measurement outcome for 1-states is 1, for 1-states is -1, and for all other states is 0.\nFirst, for the case where the number of qubits is 1, i.e., n = 1, the circuit is equivalent to a single $R_y$ gate. The $R_y$ gate has an equal probability of taking values from the set ${0, \\pi,\\frac{\\pi}{2},-\\frac{\\pi}{2}}$, and the corresponding states are |0), |1\u27e9, |+\u27e9, and |\u2212\u27e9, respectively. It is easy to see that the above conclusion holds in this case.\nNow, suppose the conclusion holds for n = k. Then, for n = k + 1:\n(1) If the n-th qubit is |0\u27e9 or |1\u27e9, then the first n qubits and the (n + 1)-th qubit are not entangled, so their measurement outcomes are independent. The probability that the final n + 1 qubits are in the 1-state corresponds to the case where both the first n qubits and the (n + 1)-th qubit are either in the 1-state or both in the -1-state.\nHere, it is important to note that\np (the first n qubits are in the 1-state) = p (the first n qubits are in the 1-state|the n-th qubit is |0\u27e9 or |1\u27e9)\nIt suffices to state that the n-th qubit being |0\u27e9 or |1\u27e9 is a necessary condition for the first n qubits to be in the 1-state.\nIf the n-th qubit is |0\u27e9 \u00b0 |1\u27e9:\n$\\langle \\phi_B| = \\sum_{i=1}^k |x_{i1}...x_{in-1} 0\\rangle + \\sum_{i=1}^k |x_{i1}...x_{in-1} 1\\rangle \\to \\langle final| = \\sum_{i=1}^k |x'_{i1}...x'_{in-1} x'_n\\rangle + \\sum_{i=1}^k |x_{i1}...x_{in-1}x_n\\rangle.$\nIf $\\sum_{i=1}^k |x'_{i1}...x'_{in-1} x'_n\\rangle$ is in the 1-state, then $\\sum_{i=1}^k |x_{i1}...x_{in-1}\\rangle$ must be in the -1-state, and vice versa. If $\\sum_{i=1}^k |x'_{i1}...x'_{in-1}\\rangle$ is in the 0-state, suppose there are m qubits in the 1-state and k \u2212 m qubits in the \u22121-state. Then, $\\sum_{i=1}^k |x'_{i1}...x'_{in-1} x'_m\\rangle$ is also in the 0-state, with k \u2212 m qubits in the 1-state and m qubits in the \u22121-state. In this case, $\\langle final|$ has k qubits in the 1-state and k qubits in the \u22121-state, meaning that $\\langle final|$ must be in the 0-state. In conclusion,\np (the first n qubits are in the 1-state) = p (the first n qubits are in the 1-state|the n-th qubit is |0\u27e9 or |1\u27e9) = $\\frac{1}{4}$\nThus, if the n-th qubit is in the state |0\u27e9 or |1\u27e9, the probability that the n + 1 qubits are in the 1-state or -1-state is:\n$\\frac{1}{4} \\times \\frac{1}{4} + \\frac{1}{4} \\times \\frac{1}{4} = \\frac{1}{8}.$\n(2) If the n-th qubit is in the state (|0\u27e9 \u00b1 |1\u27e9), and the (n + 1)-th qubit is in the state |0\u27e9 or |1\u27e9, then the first n qubits and the (n + 1)-th qubit become entangled. Let the quantum state at Position A be:\n$\\langle \\phi_A| = \\sum_{i=1}^k |x_{i1}...x_{in-1}\\rangle \\otimes (|0\\rangle + |1\\rangle) \\otimes |x_n\\rangle$\nwhere $x_{i;}$ takes values 0 or 1, and $|x_{i_1}...x_{in-1}\\rangle$ is either in the 1-state or the \u22121-state.\nThe quantum state at Position B is:\n$\\langle \\phi_B| = \\sum_{i=1}^k |x_{i1}...x_{in-1}\\rangle \\otimes (|0x_n\\rangle + |1x_n\\rangle) = \\sum_{i=1}^k |x_{i1}...x_{in-1}0x_{n+1}\\rangle + \\sum_{i=1}^k |x_{i1}...x_{in-1}1x_{n+1}\\rangle.$\nThe final quantum state is:\n$\\langle final| = \\sum_{i=1}^k |x'_{i1}...x'_{in-1} x_nx_{n+1}\\rangle + \\sum_{i=1}^k |x_{i1}...x_{in-1} x_nx_{n+1}\\rangle.$\n(a) If both parts are in the 1-state, then they are both in the 1-state. If both are in the -1-state, they are both in the -1-state. In this case, we only need to discuss the probability that $\\sum_{i=1}^k |x'_{i1}...x'_{in-1} x_nx_{n+1}\\rangle$ is in the 1-state, which is easily obtained as 1/8.\n(b) If $\\sum_{i=1}^k |x'_{i1}...x'_{in-1} x_nx_{n+1}\\rangle$ is in the 0-state, then $\\sum_{i=1}^k |x_{i1}...x_{in-1} x_nx_{n+1}\\rangle$ must also be in the 0-state. (If $\\sum_{i=1}^k |x'_{i1}...x'_{in-1} x_nx_{n+1}\\rangle$ is in the 1-state or -1-state, since $\\sum_{i=1}^k |x_{i1}...x_{in-1} x_nx_{n+1}\\rangle$ is not entangled, it must be that k = 1.) In this case, we can assume:\n$\\langle \\sum_{i=1}^k |x_{i1}...x_{in-1} x_nx_{n+1}| = |x_1\\rangle \\otimes |x_2\\rangle ... \\otimes |k_1\\rangle \\dots |+\\rangle \\dots |-\\rangle \\dots |x_n\\rangle, x_i \\in {0,1}.$\nThus, it is easy to know k is an even number, and there are k/2 qubits in the 1-state and k/2 qubits in the -1-state.\nNow, we need to show that in $\\langle \\sum_{i=1}^k |x_{i1}...x_{in-1} x_nx_{n+1}|$, the number of 1-states and -1-states is also equal.\nLet's assume that at Position A in FIG. 10, we have d qubits ${k_1,k_2,...,k_d}$ which are in a superposition state |+\u27e9 or |\u2212\u27e9. Then,\nIt is easy to see that we can pair the $2^d$ basis states, where each pair differs by only one element. In each pair of basis states, one is 1-state and the other is -1-state. Therefore, after passing through the CNOT layer, in each pair of basis states, there will still be one 1-state one -1-state. Thus, in the expression\nthe number of 1-states and -1-states remains equal, meaning that the final state  will necessarily be the 0-state.\n(3) If the n-th qubit is in the state (|0\u27e9 \u00b1 |1\u27e9), and the (n + 1)-th qubit is also in the state (|0\u27e9 \u00b1 |1\u27e9), then there is no entanglement between the n-th and (n + 1)-th qubits, and the state must also be 0-state.\nThus, in conclusion, the probability that the $n + 1$ qubits are in the 1-state or -1-state is also $\\frac{1}{4}$.\nTheorem 2. For an n-qubit circuit with the linear entanglement structure in FIG.2 (composed by one layer of $R_y$ gates and one layer of linear CNOT gates), where the angles of the $R_y$ gates are restricted to the set ${0,\\pi,\\frac{\\pi}{2},-\\frac{\\pi}{2}}$, and the observable is a Pauli-Z string, the probability that the measurement outcome is 1 or \u22121 is both $\\frac{1}{2^{\\lfloor n/2+1\\rfloor}}$, while the probability that the outcome is 0 is $1 - \\frac{1}{2^{\\lfloor n/2\\rfloor}}$.\nProof. We will use mathematical induction to complete the proof. Let $n = 2k+1$, in which case the probability of the 1-state and -1-state is $\\frac{1}{2^{k+2}}$. We need to prove that when $n = 2k + 3$, the probabilities of the 1-state and -1-state are both $\\frac{1}{2^{k+3}}$.\nFirst, the case n = 1 is easily verified to be true, so it is omitted.\n1\nAssume that for $n = 2k + 1$, the probabilities of the 1-state and -1-state are both $\\frac{1}{2^{k+2}}$. Now consider the case when $n = 2k + 3$:\n(1) If the first two qubits take {|00\u27e9, |11\u27e9, |10\u27e9, |01\u27e9}, then the first two qubits and the remaining n qubits are not entangled. In this case, the probability of the system being in the 1-state is determined by the probability that the first two qubits are in the 1-state, and the remaining n qubits are either all in the 1-state or all in the -1-state. For"}, {"title": "Appendix C: Experimental details", "content": "In this section, we will give further experimental details about our work.\nFirst, we will show the results for multi-layer ans\u00e4tze, the probability under all possible observables under small-scale qubit systems, sampled points under different sizes of the dataset with 1000 qubits, and sampled points with 10000 qubits. Our device can support experiments involving up to 10000 qubits maximally.\nIn the main text we state that the maximal probability for nontrivial sampling is $\\frac{1}{4}$. It is not a mathematical conclusion but derived from various experiments under all possible observables as shown in FIG 12.\nIn practical applications, a multi-layer ans\u00e4tz with about four layers is commonly employed to enhance the expressive power of quantum circuits, compared to a single-layer ans\u00e4tz. Through experiments with multi-layer ans\u00e4tz, we observed that the number of layers does indeed impact sampling efficiency as shown in FIG. 13. However, while this probability decreases as the number of layers increases, we argue that such a decrease does not hinder the algorithm's scalability to large-scale qubit systems. This is because, in practical applications, it is unnecessary to use an excessive number of layers, such as 100 or even 1000 layers. In typical QML or VQA applications, the decrease in sampling efficiency is always limited within circuits of 3 to 10 layers, decreasing from approximately 0.25 down to around 0.13. Such a probability is entirely acceptable for our tasks and does not significantly compromise its effectiveness.\nMoreover, in the main text, we provided only a single figure illustrating the relationship between loss, variance, and dataset size. Here, we will present a detailed analysis of the sampling results across various datasets in FIG. 14. All experiments are conducted with 3 layers ans\u00e4tze."}]}