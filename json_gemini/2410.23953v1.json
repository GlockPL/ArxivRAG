{"title": "Representative Social Choice: From Learning Theory to AI Alignment", "authors": ["Tianyi Qiu"], "abstract": "Social choice theory is the study of preference aggregation across a population, used both\nin mechanism design for human agents and in the democratic alignment of language models.\nIn this study, we propose the representative social choice framework for the modeling of\ndemocratic representation in collective decisions, where the number of issues and individ-\nals are too large for mechanisms to consider all preferences directly. These scenarios are\nwidespread in real-world decision-making processes, such as jury trials, indirect elections,\nlegislation processes, corporate governance, and, more recently, language model alignment.\nIn representative social choice, the population is represented by a finite sample of individual-issue pairs based on which social choice decisions are made. We show that many of the\ndeepest questions in representative social choice can be naturally formulated as statistical\nlearning problems, and prove the generalization properties of social choice mechanisms us-\ning the theory of machine learning. We further formulate axioms for representative social\nchoice, and prove Arrow-like impossibility theorems with new combinatorial tools of analysis.\nOur framework introduces the representative approach to social choice, opening up research\ndirections at the intersection of social choice, learning theory, and AI alignment.", "sections": [{"title": "1 Introduction", "content": "Social choice theory is a field of study that deals with the aggregation of individual preferences to form a\ncollective decision. It has been applied in domains such as economics (Feldman & Serrano, 2006), political\nscience (Miller, 1983; Coleman & Ferejohn, 1986), and computer science (Conitzer et al., 2024a), to name a\nfew. In these applications, the goal is to design mechanisms that aggregate individual preferences in a way\nthat satisfies certain desirable properties, most especially fairness.\nHowever, existing models in social choice theory tend to be simplistic and rely on relatively strong assump-\ntions, including (1) independent, single-issue choices, and (2) complete information on all preferences of all\nindividuals. In practice, these assumptions are often violated. In common large-scale elections, candidates\nhave partisan policies that are correlated across a huge number of different issues, and it is also infeasible to\ncollect preferences of all voters on all issues, due to the large number of issues and voters involved.\nThese problems are not merely practical details that can be ignored. They are fundamental to the theory of\nsocial choice itself, since these complexities are exactly what give rise to democratic representation - the idea\nthat individuals can delegate their decision-making power to a small number of representatives who can make\ndecisions on their behalf, when there are too many issues and too many individuals to consider all preferences\ndirectly. The introduction of representation leads to fundamental questions for social choice theory that are\nnot well-understood, such as the problem of generalization how can we ensure that the decisions made\nby the representatives are representative of the population's preferences, when the representatives are only\nchosen based on a small number of individuals' opinions on a small number of issues?\nIn this paper, we propose a new framework for social choice theory that models these complexities, which we\ncall representative social choice. As we will show in the following sections, many of the deepest questions in\nrepresentative social choice can be formulated as statistical learning problems, despite the seemingly different"}, {"title": "2 Related Work", "content": "Social choice theory has had a long history (Satterthwaite, 1975; Young, 1975; Nisan & Ronen, 1999), with\nmore recent research studying its intersection with machine learning (Fish et al., 2023; Parkes & Procaccia,\n2013), and its applications in AI alignment (Conitzer et al., 2024a; K\u00f6pf et al., 2024; Klingefjord et al., 2024;\nHuang et al., 2024; Prasad, 2018; Mishra, 2023; Ge et al., 2024). This paper contributes to all three fronts,\nby extending the study of social choice theory to include democratic representation, using tools from the\ntheory of machine learning, and with important applications in both human society and AI alignment.\nSocial Choice Theory Social choice theory studies the aggregation of individual preferences to form a\ncollective decision. The field was founded by Arrow (2012), who proved the famous Arrow's impossibility theo-\nrem, stating that no social choice mechanism can satisfy the axioms of unrestricted domain, non-dictatorship,\nPareto efficiency, and independence of irrelevant alternatives. Many extensions of Arrow's theorem have\nbeen proposed, including the Gibbard-Satterthwaite theorem (Gibbard, 1973; Satterthwaite, 1975) which\nintroduces strategy-proofness to the analysis. Beyond impossibility results, social choice theory also studies\nconcrete mechanisms for preference aggregation, such as voting rules (Taylor, 2005), scoring rules (Young,\n1975), and judgment aggregation (List, 2012), while featuring intersections with other fields such as mecha-\nnism design (Nisan & Ronen, 1999) and computer science, the latter resulting in the study of computational\nsocial choice (Brandt et al., 2016). Here, we extend the study of social choice to the representative setting,\nwhere issues and individuals are too numerous for all preferences to be considered directly. By doing so, we\nintroduce the element of democratic representation to social choice theory.\nMachine Learning Methods in Social Choice Theory Machine learning methods have been applied\nto social choice theory to address limitations of over-simplification. For instance, generative social choice\nstudies the problem of handling open-ended outcomes in social choice theory in theoretically sound ways\n(Fish et al., 2023), and dynamic social choice studies the problem of handling evolving preferences in social\nchoice theory, using theoretical models from reinforcement learning (Parkes & Procaccia, 2013). In this\npaper, we apply the theory of statistical learning to representative social choice, showing that the deepest\nquestions in representative social choice can be naturally formulated as statistical learning problems."}, {"title": "3 Problem Settings of Representative Social Choice", "content": "In this section, we present the formal definitions of the representative social choice problem, generalizing the\nstandard social choice formalism to include more realistic complexities.\nIssues We consider a discrete (but possibly infinite) set of N-ary issues I, where each issue $i \\in I$ (e.g.,\nin a given state or province, which construction project to launch this year?) comes with N outcomes\n$[N] = \\{1,2,..., N\\}$. Each individual's preference profile can therefore be represented as a mapping from I\nto LO(N), where LO(N) is the set of linear orders over [N].\nWe define a saliency distribution $D_I$ with full support over I, which represents the importance of different\nissues, and decides the probability of each issue being sampled in the representation process. If there are a\nfinite number of equally important issues, then $D_I$ is the uniform distribution over I.\nPopulation We consider a possibly infinite population, represented by a distribution $D_P \\in \\Delta[P]$ supported\non $P \\subset LO(N)^I$.\nFor any preference profile $C\\in P$, denote with $D_P(C)$ the probability (mass or density)\nthat a random individual in the population has preference profile C over the outcomes of all issues.\nOften, we only need to consider the marginal distribution of $D_P$ the mapping $M : I \\rightarrow \\Delta[LO(N)]$. For\nany issue $i \\in I$, M(i) is the distribution of preferences over the N outcomes of issue i in the population.\nFor preference ordering $o \\in LO(N)$, we denote with M(i), the probability that a random individual in the\npopulation has preference ordering o over outcomes of issue i.\nOutcomes The result of a decision-making process is a preference profile C: I \u2192 LO(N), which represents\nthe aggregated preference of the population generated by some mechanism.\nThe mechanism is representational if the decision is made based on a finite collection of individual-issue\npairs $S = \\{(o_1, i_1), (o_2, i_2), ..., (o_{|S|}, i_{|S|})\\}$, with $i_k \\in I$ sampled from $D_I$, and $o_k \\sim M(i_k)$ is an individual's\npreference over the outcomes of issue $i_k$, sampled from the population distribution.\nHowever, not all preference profiles are allowed. As a key feature of representative social choice, the mecha-\nnism is only allowed to output preference profiles from a limited candidate space $C \\subseteq LO(N)$ (e.g., mutually\ncompatible combinations of per-state construction projects in the national policy case, or language model\npolicies in the AI alignment case). A mechanism is thus a function $f: (LO(N) \\times I)^* \\rightarrow C$ that maps the\nsample collection S to a preference profile C\u2208 C.\nBinary Setting as Special Case In the binary (N = 2) case of representative social choice, each issue\nis binary (Yes/No), such as in the preference annotations of language model alignment (Bai et al., 2022a).\nThis reduction in complexity will allow for the analysis of a well-defined majority vote mechanism."}, {"title": "4 Summary of Key Results", "content": "In this section, we summarize the key results from our analysis of representative social choice."}, {"title": "4.1 Generalization Bounds (Section 5.1)", "content": "Generalization is essential in representative social choice. It ensures that decisions made by the mechanism\nbased on a finite sample of preferences are representative of the population, which introduces the concept of\ngeneralization error: the performance gap between that on a sample versus on the whole population.\nTheorem (Binary Generalization Bound, Thm. 1). When N = 2, let C be a candidate space with VC\ndimension VC(C), and let \u0454 > 0 be a desired generalization error. Then, for any d > 0, with probability at\nleast 1 d, the sample utility and population utility of any preference profile C\u2208 C are e-close, i.e.,\n$\\Pr\\left[\\frac{1}{|S|}\\sum_{k=1}^{|S|} 1_{C(i_k)=o_k} - E_{i \\sim D_I}[M(i)_{C(i)}] \\leq \\epsilon, \\forall C \\in C\\right] \\geq 1-\\delta$\nas long as we have the following, for some constant c > 0:\n$|S| \\geq c VC(C)\\left(\\log VC(C) + \\log \\frac{1}{\\epsilon}+\\log \\frac{1}{\\delta}\\right)$\nSee Theorem 2 for a generalization of this bound to non-binary settings.\nIn essence, the bound tells us that the larger the sample size, the better the mechanism's decision reflects\nthe population's true preferences, with the sample size needing to grow in proportion to the complexity\nof the candidate space, as measured by the VC dimension (Vapnik, 1999) as an analogy, when election\ncandidates tailor their messaging in a fine-grained manner, the population needs to watch more debates to\nfind broadly aligned candidates, or else candidates could easily overfit their message to a few flagship issues."}, {"title": "4.2 Majority Vote and Scoring Mechanisms (Section 5.2, 6.1)", "content": "In the binary setting, majority vote is the simplest and most intuitive mechanism. It selects the outcome\nthat receives the majority of votes for each issue based on a finite sample of individual-issue pairs.\nCorollary (Majority Vote Approximately Maximizes Population Utility, Cor. 5.2). When N = 2, under\nequation 2, for any error e > 0 and confidence requirement d > 0, the majority vote mechanism fmaj has\n$\\Pr\\left[U_{D_I,M}(f_{maj}(S)) \\geq -2\\epsilon + \\max_{C\\in C} U_{D_I,M}(C)\\right] \\geq 1 - \\delta$\nwhere the population utility\n$U_{D_I,M}(C) := E_{i \\sim D_I}[M(i)_{C(i)}]$\nThis corollary shows that the majority vote mechanism works well under binary settings, where it approx-\nimately maximizes the population's utility. In settings where issues are no longer binary, majority vote\nbecomes no longer well-defined. Instead, we turn to scoring mechanisms, which assign scores to preference\nprofiles and select the profile with the highest average score.\nCorollary (Scoring Mechanisms Approximately Maximize Population Score, Cor. 6.2). When |I| is finite\nand N is arbitrary, for any scoring rule s with value bounded by constants, the scoring mechanism fs satisfies\n$\\Pr\\left[U_{D_I,M}(f_s(S)) \\geq -2\\epsilon + \\max_{C\\in C} U_{D_I,M}(C)\\right] \\geq 1 - \\delta$\nas long as we have the following, for some constant c > 0:\n$|S| \\geq c\\left(|I| N \\log N + \\log \\frac{1}{\\delta}\\right)$\nIn multi-outcome cases, scoring mechanisms provide a more generally applicable approach than majority\nvote. Like majority vote, scoring mechanisms exhibit good generalization properties as long as the sample\nsize is large enough and in proportion to the complexity of the candidate space."}, {"title": "4.3 Representative Impossibilities (Section 6.2, 6.4)", "content": "While the mechanisms we have discussed so far have desirable properties, they cannot satisfy all the axioms\nwe might want from a social choice mechanism simultaneously.\nTheorem (Weak Representative Impossibility, Thm. 3). When N > 3,C = LO(N)I, no representational\nmechanism simultaneously satisfies probabilistic Pareto efficiency (PPE), weak probabilistic independence of\nirrelevant alternatives (W-PIIA), and weak probabilistic convergence (W-PC).\nTheorem (Strong Representative Impossibility, Thm. 4). For any C, when there is at least one cyclically\nprivileged issue (Definition 6.10), no representational mechanism simultaneously satisfies PPE, strong prob-\nabilistic independence of irrelevant alternatives (S-PIIA), and strong probabilistic convergence (S-PC). This\ncyclicity condition is sufficient and necessary for impossibility, in a sense made precise in Theorem 4.\nRemark 4.1. Thm. 3 and 4 both generalize the famous Arrow's impossibility theorem, in the sense that\nArrow's setting has C = LO(N)I and thus all issues are, by Definition 6.10, cyclically privileged. Thm. 4\nfurther identifies cyclicity as the precise \u2018minimal structure' leading to impossibility, thereby both explaining\nwhy Arrow's result holds in the first place, and extending it to the general C \u2286 LO(N) case.\nThese theorems show that, in representative social choice, we must make trade-offs between different desirable\nproperties, such as fairness, utility maximization, and convergence. The two theorems differ in their range\nof applicability, where the latter allows interdependence between issues by lifting the constraint on C."}, {"title": "4.4 Overall Structure of Our Analysis", "content": "Binary Representative Social Choice (Section 5) We start with a simpler case of representative\nsocial choice, where an infinitely large population hold preferences over a possibly infinite number of binary\nissues issues that can be resolved by a simple Yes/No vote and a collection of individual-issue pairs\nare randomly drawn as samples, from which a collective preference profile is constructed to represent the\nentire population.\nGeneral Representative Social Choice (Section 6) We then extend our framework to the general\ncase of representative social choice, where the issues can have any finite number of outcomes. We introduce\na more general class of mechanisms, the scoring mechanisms, and analyze their generalization properties.\nOn the pessimistic side, we present Arrow-like impossibility theorems for representative social choice.\nWe consider our contribution in Section 5, 6.1, 6.2 to be primarily conceptual and stage-setting, establishing\nthe representative framework with techniques well-known in other fields. Section 6.3 and 6.4, when estab-\nlishing the conceptually important strong impossibility theorem, additionally introduce new combinatorial\ntools of analysis, privileged orderings and the privilege graph, which we believe to be of independent interest."}, {"title": "5 Binary Representative Social Choice", "content": "In this section, we consider the case of representative social choice where the issues are binary. A real-world\nexample is the case of jury trials, where a randomly selected jury makes binary decisions (guilt or innocence)\non behalf of the entire population. AI alignment, with its binary preference annotations, is another example."}, {"title": "5.1 Binary Generalization Bound", "content": "When aggregating preferences, the mechanism only sees a finite collection of individual-issue pairs, and\ntherefore the decision is made based on a that finite sample. This raises the question of generalization\nhow can we ensure that the decision made by the mechanism is representative of the population's preferences,\nwhen the mechanism is only optimized for a small number of individual opinions on individual issues?\nTo answer this question, we can leverage the theory of statistical learning, which studies the generalization\nproperties of learning/optimization algorithms based on finite samples. The reliability of generalization"}, {"title": "5.2 Case Study: Majority Vote in the Binary Case", "content": "In this section, we consider the majority vote mechanism under the binary representative setting. It gen-\neralizes the well-known majority vote mechanism where the population directly votes a single issue, to the\nrepresentative setting where the population is represented by a collection of individual-issue pairs.\nDefinition 5.1 (Majority Vote Mechanism). The majority vote mechanism is a representational mechanism\nfmaj that outputs the preference profile C that maximizes the sample utility, i.e.,\n$f_{maj}(S) = \\underset{C \\in C}{\\operatorname{arg\\,max}} \\frac{1}{|S|} \\sum_{k=1}^{|S|} 1_{C(i_k)=o_k}$\nThe majority vote mechanism can be viewed as a voting process where each individual-issue pair in the sample\ncollection S casts a vote for the outcome that the individual prefers, based on the individual's preference\nover the two outcomes of the issue. The candidate profile that receives the most votes is then selected as the\naggregated preference profile. When there is only one issue and candidate space C = LO(2), the majority\nvote mechanism reduces to the standard majority vote mechanism in social choice theory.\nFrom Theorem 4.1, we know that the majority vote mechanism has good generalization properties when the\nVC dimension of the candidate space C is small, resulting in the following corollary.\nCorollary 5.2 (Majority Vote Approximately Maximizes Population Utility). For any error requirement\n\u20ac > 0 and confidence requirement d > 0, the majority vote mechanism fmaj satisfies\n$\\Pr\\left[U_{D_I,M}(f_{maj}(S)) \\geq -2\\epsilon + \\max_{C \\in C} U_{D_I,M}(C)\\right] \\geq 1-\\delta$"}, {"title": "6 General Representative Social Choice", "content": "Having formulated and analyzed the binary case of representative social choice, we now extend our analysis\nto the general case where there can be an arbitrary number of outcomes for each issue."}, {"title": "6.1 Scoring Rules and Generalization Errors", "content": "Generalizing the majority vote mechanism to the general case meets challenges, as the majority vote is over\ncandidate profiles as opposed to outcomes, and when N > 2, the way each individual-issue pair votes is no\nlonger well-defined. Instead, we can consider a more general class of mechanisms called scoring mechanisms\n(Lepelley et al., 2000), which for every individual-issue pair, assign a score to each candidate profile, and\nthen output the candidate profile with the highest average score.\nAs an example, the scoring rule could be an arbitrary distance measure that measures the degree of alignment\nbetween the sampled individual's preference and the candidate profile's preference. The mechanism then\noutputs the candidate profile that maximizes the average sample alignment score.\nDefinition 6.1. A scoring mechanism is defined by a scoring rule s : LO(N) \u00d7 LO(N) \u2192 R, which assigns\na score to each pair of preference orderings over the N outcomes. The mechanism then outputs the candidate\nprofile that maximizes the average score over all individual-issue pairs in the sample collection S, i.e.,\n$f_s(S) = \\underset{C \\in C}{\\operatorname{arg\\,max}} \\frac{1}{|S|} \\sum_{k=1}^{|S|} s(o_k, C(i_k))$\nFor scoring mechanisms, we can similarly define the sample score $\\frac{1}{|S|}\\sum_{k=1}^{|S|} s(o_k, C(i_k))$ and the population\nscore $U_{D_I,M} := E_{i \\sim D_I, o \\sim M(i)}[s(o, C(i))]$, and have the following guarantees on generalization.\nTheorem 2 (Generalization Bound for Scoring Mechanisms). For any scoring rule s with value bounded by\nconstants, the scoring mechanism fs satisfies\n$\\Pr \\left[U_{D_I,M}(f_s(S)) \\geq -2\\epsilon + \\max_{C \\in C} U_{D_I,M}(C)\\right] \\geq 1-\\delta$\nas long as the sample size |S| satisfies\n$|S| \\geq \\frac{c}{\\epsilon^2} \\log \\frac{1}{\\delta} R_{I,s}(C)$ where $\\hat{C} := \\{(o, i) \\mapsto s(o, C(i)) | C \\in C\\}$\nand $R_{I,s}(C)$ is the empirical Rademacher complexity of C with respect to the sample collection S\n(Mohri & Rostamizadeh, 2008) a generalization of the VC dimension to real-valued (as opposed to bi-\nnary) functions.\nThe result follows directly from the Rademacher generalization bounds in statistical learning theory.\nCorollary 6.2 (Scoring Mechanisms Approximately Maximize Population Score). When I is finite, for\nany scoring rules with value bounded by constants, the scoring mechanism fs satisfies\n$\\Pr\\left[U_{D_I,M}(f_s(S)) \\geq -2\\epsilon + \\max_{C \\in C} U_{D_I,M}(C)\\right] \\geq 1-\\delta$\nas long as we have the following, for some constant c > 0:\n$|S| \\geq c \\left( |I| N \\log N + \\log \\frac{1}{\\delta} \\right)$\nRademacher complexity generalizes the VC dimension to real-valued functions, and measures the capacity\nof a function class to fit arbitrary finite samples. Corollary 6.2 states that the sample score of any candidate\nprofile in the candidate space C approximates the population score, as long as the sample size exceeds\nthe ability of the candidate space to fit arbitrary finite samples i.e., when the mechanism is forced to\ngeneralize.\nCorollary 6.2 is agnostic towards the correlation structure among issues, and as a result, the sample com-\nplexity grows approximately linearly with the number of issues |I| and the number of outcomes N. When\ngiven a issue correlation structure, the sample complexity can potentially be reduced using Theorem 2."}, {"title": "6.2 Weak Representative Impossibility", "content": "In this section, we present axioms that ideal social choice mechanisms should satisfy, and present Arrow-like\nimpossibility theorems, showing that no mechanism can satisfy all these axioms simultaneously. A weaker\nversion of the impossibility theorem which we present in this section is a simple generalization of\nArrow's impossibility theorem, while a stronger version shall be derived in Section 6.4. We introduce the\nnecessary notations and then restate the axioms from the binary case, adapting them to our general setting.\nDefinition 6.3 (Operation of a Permutation on an Ordering). For a set S, a linear order o \u2208 LO(S), and\na permutation \u03c3\u2208 Ss, we define the operation \u03bf \u03c3 as the ordering obtained by applying the permutation \u03c3\nto the elements of o. Specifically, for any $s_1, s_2 \\in S$, we have $s_1 \\succ_{o \\circ \\sigma} s_2$ if and only if $\\sigma^{-1}(s_1) \\succ_{o} \\sigma^{-1}(s_2)$.\nFor a subset T \u2286 S and o\u2208 Sr, we similarly define \u03bf\u2299 \u03c3:= \u03bf\u2299\u03c3|s, where os is the extension of o to the\nwhole set S, mapping elements outside T to themselves. For a full profile C \u2208 LO(N)Z, we define C\u2299i \u03c3\u03b1\u03c2\nthe profile obtained by applying the permutation \u03c3 to C(i), while keeping C unchanged for all other issues.\nRemark 6.4. We denote with o(c1,c2) the 2-element permutation (transposition) that swaps c\u2081 and c2. Op-\neration of a permutation on an ordering aims to capture \u201clocal changes\" to a preference profile, where the\npermutation only affects a subset of the outcomes. They will be used in the definition of the axioms below.\nAxiom: Probabilistic Pareto Efficiency (PPE)\nConsider profiles C, C' \u2208 C such that for the only issue i \u2208 I that they disagree on, there exists c, c' \u2208 [N]\nsuch that $c \\succ C c', C' = C \\circ_i \\sigma_{(c,c')}$, and the population is unanimous on $c \\succ c'$. For any such C, C',\nwith probability 1 - e~(|S|), f(S) \u2260 C'.\n\"The second condition means that the order between c, c' is the only disagreement they have on issue i.\nIn other words, $M(i)_o = 0$ for all $o \\in LO(N)$ that prefers c' over c.\"\nAxiom: Probabilistic Non-Dictatorship (PND)\nFor any issue i \u2208 I and c,c' \u2208 [N], for any subpopulation D'p that occupies a probability mass\n|D'P < 0.5 in the whole population, at least one of the following is true w.r.t. issue i:\nWhen D'p is unanimous on c > c', there exists a preference specification Dp of the whole population\nfor which $c' \\succ_{f(s)} c$ with probability 1 \u2013 e\u2229(|S|).\nWhen D'p is unanimous on c' > c, there exists a preference specification Dp of the whole population\nfor which $c \\succ_{f(s)} c'$ with probability 1 \u2013 e\u2229(|S|).\nIn fact, all representational mechanisms satisfy PND, since our setting treats individuals as interchangeable\nand homogeneous, therefore implicitly forcing anonymity of the mechanism, which inturn implies PND.\nLemma 6.5 (Probabilistic Non-Dictatorship for All Representational Mechanisms). For any (I,D1,C) and\nany representational mechanism f, PND is satisfied.\nAs a result, we shall remove PND from the explicit statements of the impossibility theorems, but it should\nbe understood that PND is still implicitly satisfied. Finally, we define a weak version of the independence\nof irrelevant alternatives (IIA) axiom, as well as a new axiom specific to the representative setting.\nAxiom: Weak Probabilistic Independence of Irrelevant Alternatives (W-PI\u0399\u0391)\nWhen C = LO(N)I, for two populations Dp, D'p that differ only in the preference over a single issue\ni \u2208 I satisfying M(i) |LO({c,c'})= M'(i) |LO({c,c'}) (where c,c' are any two elements of [N]), with\nprobability 1 \u2013 e~(|S|), we have f(S) |LO({c,c'})= f(S') |LO({c,c'}).\n\"Meaning that the population's distribution over the preference between c, c' are the same in the two populations.\"\nRemark 6.6. C = LO(N)I_implies independence both between issues and between outcomes of the same\nissue. As a result, we won't need to worry about, e.g., the population's insistance on c\u2081 > C2 leads to the"}, {"title": "6.3 Privileged Orderings and Privilege Graph", "content": "Before we present the strong representative impossibility theorem, we need tools to represent and analyze\nthe structure of the candidate space C. To this end, we introduce the concept of privileged orderings, which\nare partial orderings that are preferred over all other alternative orderings in the candidate space.\nDefinition 6.8 (Privileged Ordering). For an issue i \u2208 I and a subset of outcomes T = {C1, C2,..., Ck}\n[N] (k \u2265 2), we call o \u2208 LO(T) : C\u2081 Y C2 Y : Y ck a privileged ordering if for any extension C \u2208 LO(N)I\nof o and permutation \u03c3\u2208 Sr of T, we have C\u2299\u00a1 \u03c3\u2208C \u21d2 C\u2208 C.\nRemark 6.9. Intuitively, a privileged ordering o is a partial ordering that is preferred in the candidate space\nC over all other alternative partial orderings. Any full preference profile in C that disagrees with o must\nhave a counterpart in C that agrees with o while keeping the rest of the profile unchanged. These privileged\norderings are in fact surprisingly common in practice, as will be showcased in Example 6.11 and 6.12.\nDefinition 6.10 (Privilege Graph). For an issue i \u2208 I, we define the privilege graph Gi as a directed graph\nwith vertices as the outcomes in [N], and an edge from u to v iff there exists a privileged ordering u > v. We\ncall i cyclically privileged if its privilege graph contains a simple directed cycle of length at least 3.\nExample 6.11 (Privileged Orderings in the Real World). Consider three persons I = {A, B, C'} on trial\nbefore the jury. A is charged of burglary ($5k, first trial), B also of burglary ($50k, second trial), and C of\nfraud. The N = 3 possible outcomes for each defendant include aqcuittal (a), community service (c), and\nimprisonment (i). The jury ranks the outcomes for each defendant in order of recommendation. In this\nhypothetical case, the following factors may lead to privileged orderings:\nMonotonicity and fairness constraints. The jury may consider it unfair to punish A harder than\nB given the difference in the amount of burglary. Thus, locally changing the recommended outcome of\nA from c to i may violate this monotonicity (namely when the outcome of B is c), but changing from i\nto c will not. This implies c > i and (analogously) a > c being privileged for A, and i > c, c > a for B."}, {"title": "6.4 Strong Representative Impossibility", "content": "Before stating the strong impossibility, we first present the strong version of the PIIA and PC axioms.\nAxiom: Strong Probabilistic Independence of Irrelevant Alternatives (S-PIIA)\nFor arbitrary C and c,c' \u2208 [N] such that c > cand c > care both privileged orderings in some\nissue i \u2208 I, for two populations Dp, D'p satisfying M(i) |LO({c,c'})= M'(i) |LO({c,c'}), with probability\n1 - e?(||), we have f(S) |LO({c,c'})= f(S') |LO({c,c'}).\nTheorem 4 (Strong Representative Impossibility). For any (I, D1, C), when there is at least one cyclically\nprivileged issue, no representational mechanism simultaneously satisfies PPE, S-PIIA, and S-PC for all\nDp.\nMeanwhile, given any mapping & from each issue i to a privilege graph $(i) without simple cycles of length\nat least 3, there exist a candidate space C whose privilege graph Gi (for each i) is $(i) or its supergraph, and\na representational mechanism f over (I,D1,C) satisfying PPE, S-PIIA, and S-PC for all Dp.\nTheorem 4 is a generalization of Arrow's theorem (as explained in Remark 4.1) and Theorem 3 to arbitrary\ncandidate spaces C. It shows that the cyclicity is both necessary and sufficient for the impossibility of a\nrepresentative mechanism satisfying the axioms. However, the \"necessary\" part is not as strong as one would\nhope, since it constructs counterexample for at least one C associated with each non-cyclic privilege graph,\ninstead of showing that the impossibility holds for all C associated with the privilege graph. It is an open\nquestion whether such a stronger necessity holds, and shall be the subject of future research.\nThe N\u2265 3 condition (\"at least 3 vertices in the N-clique\") in Theorem 3 and the original Arrow's theorem\nis replaced by the cyclicity condition here (\"at least 3 vertices in a cycle\"). Intuitively, the latter is a\nmore precise condition that identifies a necessary-and-sufficient \"minimal structure\" in the candidate space\nC leading to impossibility. It can be checked in linear time (in the number of vertices and edges) for any\nprivilege graph, since it's equivalent to the existence of strongly connected components of size at least 3."}, {"title": "7 Conclusion", "content": "In this paper, we have formulated the problem of representative social choice, where a mechanism aggregates\nthe preferences of a population based on a finite sample of individual-issue pairs. We have derived results\nthat reflect both optimistic and pessimistic aspects of representative social choice.\nImplications for AI Alignment Representative social choice can model the alignment of AI systems to\ndiverse human preferences. Generalization analysis of social choice mechanisms naturally apply to alignment\nmechanisms, while impossibility results highlight trade-offs between fairness and utility in alignment. These\ninsights can guide the development of robust alignment strategies that manage these trade-offs explicitly.\nLimitations and Future Directions We focused on the generalization properties of representational\nmechanisms without studying other important properties, such as incentive compatibility and computational\ntractability. Future research could explore them and their interactions with generalization.\nBroader Impact Statement We aim to advance our understanding of democratic representation in\ncollective decisions, with anticipated positive impacts. It helps develop more robust alignment strategies for\nAI systems, contributing to the equitable alignment of AI systems with diverse human preferences."}, {"title": "A Additional Definitions", "content": "We have omitted the definition of the Vapnik-Chervonenkis dimension in the main text, given that it is a\nstandard concept in statistical learning theory. We provide it here for completeness, translating it to our\nlanguage of representative social choice.\nDefinition A.1 (Vapnik-Chervonenkis Dimension (Vapnik, 1999)). Given any issue space I, we consider\ncandidate profiles mapping I to LO(2), and a candidate space C \u2286"}]}