{"title": "Destroy and Repair Using Hyper-Graphs for Routing", "authors": ["Ke Li", "Fei Liu", "Zhengkun Wang", "Qingfu Zhang"], "abstract": "Recent advancements in Neural Combinatorial Optimization (NCO) have shown promise in solving routing problems like the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) without handcrafted designs. Research in this domain has explored two primary categories of methods: iterative and non-iterative. While non-iterative methods struggle to generate near-optimal solutions directly, iterative methods simplify the task by learning local search steps. However, existing iterative methods are often limited by restricted neighborhood searches, leading to suboptimal results. To address this limitation, we propose a novel approach that extends the search to larger neighborhoods by learning a destroy-and-repair strategy. Specifically, we introduce a Destroy-and-Repair framework based on Hyper-Graphs (DRHG). This framework reduces consecutive intact edges to hyper-edges, allowing the model to pay more attention to the destroyed part and decrease the complexity of encoding all nodes. Experiments demonstrate that DRHG achieves state-of-the-art performance on TSP with up to 10,000 nodes and shows strong generalization to real-world TSPLib and CVRPLib problems.", "sections": [{"title": "1 Introduction", "content": "Routing problems are significant combinatorial optimization problems with broad real-world applications in logistics, transportation, and manufacturing. Their NP-hard nature poses a significant challenge to the application of exact methods. Heuristics sacrifice the optimality while can obtain near-optimal solutions in a reasonable time. However, the development of heuristics usually relies on human designs with domain expert knowledge, which hinders their practical applications.\nNeural Combinatorial Optimization (NCO), which trains a neural network to learn heuristics to solve routing problems without handcraft design, has gained much attention. The existing NCO methods can be roughly classified into two categories: 1) non-iterative and 2) iterative methods."}, {"title": "2 Related Works", "content": "Most existing iterative NCO routing solvers focus on learning low-level operators searching within small neighborhoods. Chen and Tian (2019) employ a region-picking policy to identify a node for relocation and a rule-picking policy to determine the target position for the node's movement. de O. da Costa et al. (2020); Sui et al. (2021) propose to learn 2-opt or 3-opt steps to improve the solution. Furthermore, Lu, Zhang, and Yang (2020); Wu et al. (2022) utilize a pool of operators from which the model selects, demonstrating superior performance compared to approaches that rely on a single operator. Ma et al. (2021) propose a Dual-Aspect Collaborative Transformer (DACT) with a Cyclic Positional Encoding (CPE) method and a Dual-Aspect Collaborative Attention (DAC-Att) to encode problems, which achieves pretty good performance. However, iterative NCOs with low-level operators are limited to solving small-size problems due to the extensive number of iterations required for convergence. Moreover, the overall quality of local optimal of small neighborhoods is inferior, which implies that the final solutions obtained by these methods are often sub-optimal.\nOther iterative NCO routing solvers focus on reconstructing a partial solution of node sequence. Either trained with RL (Kim, Park, and Kim 2021; Cheng et al. 2023; Ye et al. 2024) or SL (Luo et al. 2023, 2024), the models learn to reconstruct a segment given the starting node and the ending node. By operating within a large neighborhood, these methods outperform those using low-level operators. However, the neighborhoods that these methods can search in are still limited since the nodes outside the segment remain unaltered. Therefore, two nodes that are spatially close but far away in the solution may have no chance of being reconnected together. In contrast, our framework enables a more flexible neighborhood search by permitting arbitrary destruction and, subsequently, the repair of reconnecting the segments with isolated nodes."}, {"title": "3 Methodology", "content": "Schematically illustrated in Fig. 1, we reformulate our destroy-and-repair approach as a graph reduction, hypergraph solving, and graph restoration process. For a graph representing the incomplete solution where a set of edges is destroyed, we reduce the graph by encoding the remaining consecutive edges as hyper-edges. As these edges remain unchanged during the repair, redefining them as fixed hyperedges helps reduce the complexity of the problem for the model. Then, we train the model in a supervised way to solve the reduced problem on the hyper-graph. In the testing phase, we iteratively destroy the current solution to obtain a hyper-graph, solve the resulting hyper-graph, and recover the hyper-graph solution on that of the original problem."}, {"title": "3.2 Hyper-graph Representation", "content": "Mathematically, a hyper-graph is a special graph where an edge can join any number of vertices. Formally, a hyper-graph is defined as \\(G = (V,E)\\), in which \\(V\\) is the vertex (node) set and \\(E\\) is the hyper-edge set. Using hypergraph neural networks for embedding hypergraphs is intuitive, but challenging. Specifically, when constructing a solution sequentially, it becomes necessary to align the embeddings of nodes and edges in order to predict the subsequent node or hyper-edge, which may be hard for models. Even if we train an excellent model to predict the sequence, resolving the solution with respect to an undirected hyper-graph remains a non-trivial challenge. Since each hyper-edge has two possible directions, resolving the best complete solution may require a huge number of enumerations. Therefore, we propose to use two endpoints to represent a hyper-edge.\nNote a TSP instance of \\(n\\) nodes by the node coordinates as \\(V = \\{(x_1, y_1), (x_2,y_2), ..., (x_n, y_n)\\}\\). After the destruction, \\(h\\) undestroyed segments constitute the directed hyperedges set of size \\(2h\\), i.e., \\(E = \\{e^i = (i_1, i_2, ..., i_{p_i}) | i = 1, 2, ..., 2h\\}\\), where \\(p_i\\) is the number of nodes in the directed hyper-edge \\(e^i\\).\nFor hyper-graph reduction, we remove the middle nodes inside the hyper-edges and keep only the endpoints to represent the hyper-edge, i.e., \\(e^i = (i_1, i_{p_i})\\). Consequently, in the reduced graph, we have one set of isolated nodes \\(A\\), one set of endpoint nodes \\(B\\), and one set of reduced hyper-edges \\(E_r\\). The hyper-graph size is \\(m = |A| + |B|\\). Then, the input feature of the reduced graph is formulated as:\n\\(r_i = (x_i, y_i, x'_i, y'_i, flag_i), i = 1, 2, ..., m,\\)  (1)\n\\((x, y) = (x_i, y_i),\\)   (2)\n\\((x,y) = \\begin{cases}\\  (x_i, y_i), & \\text{if } i \\in A, \\\\   (x_j, y_j), & \\text{if } i \\in B \\text{ and}(i, j) \\in E_r, \\end{cases}\\) (3)\nwhere \\(r_i\\) is the input feature for the model, and \\(flag_i\\) is a binary variable to indicate whether a node is an endpoint node or an isolated node.\nSimilarly, for a CVRP instance of \\(n\\) customers and a depot noted as 0, we can define the problem by the node coordinates and the demands: \\(V = \\{(x_0, y_0, 0), (x_1, y_1, d_1), ..., (x_n, y_n, d_n)\\}\\), where \\(d_i\\) is the demand of node \\(i\\). To simplify the problem, we destroyed all edges connected to the depot. Then, the input feature of the reduced graph for CVRP can be formulated as follows:\n\\(r_i = (x_i, y_i, x'_i, y'_i, flag_i, d_{ri}), i = 1, 2, ..., m,\\)   (4)\n\\[d_{ri} = \\begin{cases} d_i, & \\text{if } i \\in A, \\\\ \\sum_k d_k, & \\text{if } i \\in B \\text{ and } k \\in (i_1, i_2, ..., i_{p_i}).\\  \\end{cases}\\] (5)"}, {"title": "3.3 Model Structure", "content": "As shown in Fig. 2, given the input features of the reduced problems, our model yields a prediction of the next node through a light encoder and a heavy decoder."}, {"title": "Encoder", "content": "The encoder consists of a single linear projection layer, which transforms the input \\(r_i \\in \\mathbb{R}^{d_i}\\) into embedding \\(h_i \\in \\mathbb{R}^{d_h}\\)."}, {"title": "Decoder", "content": "The decoder has a slightly changed linear attention module in Luo et al. (2024). At each step \\(t\\), the decoder takes the node embeddings of the first node \\(h_f^{(0)}\\), the current node \\(h_c^{(0)}\\), and the remaining unselected nodes \\(H^{(0)} = \\{h_i^{(0)} | i = 1, 2, ..., m - t\\}\\) as inputs. Then, the first node \\(h_f^{(0)}\\) and the current node \\(h_c^{(0)}\\) are used to generate \\(r\\) virtual representative nodes embeddings \\(\\hat{H}^{(0)} = \\{\\hat{h}_j^{(0)} | j = 1, 2, ..., r\\}\\), which combined with \\(H^{(0)}\\), form the input of the first linear attention module.\nThen, we stack \\(L\\) linear modules as the main component of the decoder. A linear attention module is composed of an aggregating attention layer and a broadcasting attention layer. The aggregating layer aggregates information to the representative nodes, and then the broadcasting layer broadcasts gathered information to all nodes in the graph. The details of the linear attention module are provided in Appendix A. Note the \\(l\\)-th linear attention module as \\(L-Att^{(l)}\\), we have\n\\(\\hat{H}^{(l)}, H^{(l)} = L-Att^{(l)}(\\hat{H}^{(l-1)}, H^{(l-1)}).\\) (6)\nAfter \\(L\\) attention module, we obtain a hidden representation \\(\\hat{H}^{(L)}\\) and and \\(H^{(L)}\\). Then we take only \\(H^{(L)}\\) to calculate the probability of selecting the next node by a linear projection layer and the softmax function:\n\\(a_i = \\phi(h_i^{(L)}) W_o,\\) (7)\n\\(p_i = \\frac{e^{a_i}}{\\sum_i e^{a_i}}.\\) (8)"}, {"title": "3.4 Training Scheme", "content": "We use SL to train our model. We apply the clustering destruction, as optimal edges are more likely to connect proximal nodes. Furthermore, the distributions of reduced problems after clustering destructions are more consistent across problems of different scales. We adopt the coordinate transformation in Ye et al. (2024) to enhance the distribution homogeneity and consistency. For hyper-edges, once one endpoint is selected, the subsequent node must be the other endpoint. This behavior is dictated by the constraint rather than the model. Correspondingly, we introduce a masking mechanism to block the associated gradients. Additionally, destroying the problem by k-nearest neighbors results in a variable number of segments and makes the hyper-graph size differ across instances. This variability introduces instability during the training process. To tackle this problem, we design a special destruction scheme to get fixed-size hyper-graphs. We detail this method in Appendix B."}, {"title": "4 Experiments", "content": "We compare our method with other representative learningbased and classical solvers on TSP and CVRP instances with different scales and the instances in the real world."}, {"title": "4.1 Experiment Setup", "content": "We set the embedding dimension of the encoder to 128. The decoder is composed of 6 linear attention modules, and each has 8 attention heads and 16 representative starting nodes. The hidden dimension of the feed-forward layer is set to 512.\nFor TSP, we train the model for 100 epochs on 1,000,000 TSP100 instances. We fine-tune 20 epochs on 10,000 TSP1000 instances for large-scale problems. For CVRP, we train the model for 100 epochs on 1,000,000 CVRP100 instances. We use a batch size of 1024 and sample the training sample size in [20,0.8n] where n is the problem size. As the fixed-size destruction scheme will discard a small part of the samples, the true batch size is around 800. We use the cross-entropy loss and the Adam optimizer (Kingma and Ba 2015). The initial learning rate is 1e-4, and the decay rate is 0.97 per epoch. We train and test our model with a single NVIDIA GeForce RTX 3090 GPU with 24GB memory."}, {"title": "4.2 Experimental Results", "content": "The main experimental results on uniformly distributed TSP instances are reported in Table 1. All results are reported in terms of per-instance solving time. The values in parentheses represent the variance. Rank-sum tests are conducted on POMO augx8, BQ bs16, GLOP (more revision) and LEHD RRC1000 to assess whether the path length and the gap of given methods differ significantly from those of our method. Except for the LEHD RRC1000 on TSP100, our DRHG demonstrates statistically significant differences (p<0.05) from other methods across all other test settings.\nParticularly for TSP100, we track the number of nonoptimal cases of the other representative NCO methods compared with our method, which is illustrated in Fig. 3. For TSPs with 100 to 500 nodes, we perform a comparative analysis of our method against other approaches under identical running time in Table 2, where + means our method outperforms its competitor, and vice versa. Since the running time of one-shot constructive solvers cannot be adjusted, we allocate the same running time to our DRHG as that of its competitors.\nThe results demonstrate that our proposed DRHG method can achieve very good performance on instances of all sizes. Notably, on TSP100, our method yields non-optimal solutions in only 129 out of 10,000 cases, reducing the nonoptimality ratio by an order of magnitude. On TSP200 and TSP500, our method reduces the gap by approximately one-third and outperforms its competitors given the same running time. With a small fine-tuning budget, our method outperforms all other methods on large-scale problems, including SIL (Luo et al. 2024), which is separately trained for each problem scale.\nFor CVRP (Table 3), DRHG can also achieve pretty good performance. Our method outperforms the traditional heuristic method LKH3 on CVRP100 and 200. For CVRP200 and 500, our method outperforms most learning methods except for LEHD RRC1000, which, however, requires much more time. Overall, the performance of DRHG is slightly less dominant than that of TSP, but it is still promising."}, {"title": "5 Conclusion, Limitation, and Future Work", "content": "This paper has proposed a novel destroy-andrepair framework using hyper-graphs (DRHG) for routing problems. By leveraging the condensed hyper-graph formulation of the destroyed problem, we have reduced the burden of model learning and constrained the input size of the model to the scale of destruction. Extensive experiments comparing our model with other representative NCO methods on both synthetic and real-world instances have demonstrated the superiority of DRHG across different problem scales and distributions."}, {"title": "A Model Structure Details", "content": "This section provides more details of the model structure, mainly about the decoder and the linear attention module, as shown in Fig. 4. At each step \\(t\\), the model takes the encoding of the first node, the current node, and the remaining unselected nodes for decoding. Denote the first and current nodes' embeddings \\(h_f^{(0)}\\) and \\(h_c^{(0)}\\), respectively. We first augment them by \\(r_f\\) and \\(r_c\\) channels to obtain the virtual representative nodes:\n\\(\\hat{H}^{(0)} = [reshape(h_f^{(0)}W_f), reshape(h_c^{(0)}W_c)],\\) (9)\nwhere \\([,]\\) is the horizontal concatenation operator, \\(W_f \\in \\mathbb{R}^{d \\times (d \\times r_f)}\\), \\(W_c \\in \\mathbb{R}^{d \\times (d \\times r_c)}\\). Here the \\(reshape\\) is to keep the embedding dimension of the representative node the same with the remaining unselected nodes, resulting \\(\\hat{H}^{(0)} \\in \\mathbb{R}^{(r_f+r_c) \\times d}\\), which means the number of virtual representative nodes equals the number of the channels.\nThen, we have \\(r = r_f+r_c\\) virtual representative nodes embeddings \\(\\hat{H}^{(0)} = \\{\\hat{h}_j^{(0)}|j = 1, 2, ..., r\\}\\). Denote the remaining unselected nodes as \\(H^{(0)} = \\{h_i^{(0)}|i = 1, 2, ..., m - t\\}\\) at step \\(t\\) for the hyper-graph of size \\(m\\), the linear attention module first aggregates all information into representative nodes, then broadcasts the information to all nodes.\nThe aggregating and broadcasting processes are realized by two different attention layers. Recall the formulation of classical attention mechanism: note the queries \\(X_Q \\in \\mathbb{R}^{q \\times d}\\), keys \\(X_K \\in \\mathbb{R}^{k \\times d}\\) and values \\(X_V \\in \\mathbb{R}^{v \\times d}\\) as inputs, the classical attention mechanism can be formulated as:\n\\[Attn(X_Q, X_K, X_V) = softmax(\\frac{X_QW_Q(X_KW_K)^T}{\\sqrt{d}})X_VW_V,\\] (10)\nThen, for the \\(l\\)-th linear attention module, denote the input representative nodes' embeddings \\(\\hat{H}^{(l-1)}\\) and the remaining unvisited nodes' embeddings \\(H^{(l-1)} = \\{h_i, i = 1,...,m\\}\\), we concat \\(\\hat{H}^{(l-1)}\\) and \\(H^{(l-1)}\\) as \\(H_{all}^{(l-1)} = [\\hat{H}^{(l-1)}, H^{(l-1)}]\\). Then, the aggregating attention layer attends representative nodes to all nodes:\n\\(\\text{Agg} = Attn(\\hat{H}^{(l-1)}, H_{all}^{(l-1)}, H_{all}^{(l-1)}),\\) (11)\nand the broadcasting attention layer attends all nodes to the aggregations:\n\\(\\text{Brd} = Attn(\\hat{H}^{(l-1)}, \\text{Agg}, \\text{Agg}),\\) (12)\nwhere \\(\\text{Brd} \\in \\mathbb{R}^{(r+m-t) \\times d}\\), which we can split into the representative nodes' embeddings \\(\\hat{H}^{(l)}\\) and the remaining unselected nodes' embeddings \\(H^{(l)}\\).\nFinally, after \\(L\\) linear attention modules, we obtain the hidden representation \\(\\hat{H}^{(L)}\\) and and \\(H^{(L)}\\). Then we take only the embeddings of remaining unselected nodes \\(H^{(L)}\\) to calculate the probability for selecting the next node."}, {"title": "B Sample Size Alignment", "content": "We employ the sample size alignment to make the hypergraph size the same within a batch. The key concept is to precompute the size of the hyper-graph before actually implementing different cases of destruction. This process requires a predefined order of node destruction. In our clustering scenario, we begin with a central node, with nodes closer to the center being destroyed earlier. When an additional node is destroyed, the number of nodes that newly appear in the hyper-graph depends on whether the edges connecting the node to its neighbors (first-order and second-order) have already been destroyed. Fig. 5 provides an example where the node targeted for destruction is connected with its four neighbors. After the node is destroyed, three new nodes emerge in the hyper-graph. We detail all cases of node connections and their corresponding results of node emergence when enlarging the destruction area in Fig. 6.\nThere are six different cases and we indicate the newly appearing nodes by red color in each case. In case 1, destroying one more node generates two endpoint nodes and an isolated node. In case 2, that generates an endpoint node and an isolated node. In case 3, the newly destroyed node changes from a middle node to an isolated node. In case 4, the newly destroyed node becomes an endpoint node. In cases 5, the newly destroyed node is an endpoint node before and becomes an isolated nodes, but does not change the hyper-graph size. In case 6, the newly destroyed node has already been disconnected with its two neighbors before, therefore none of new nodes emerging in the hyper-graph due to the destruction. In summary, the number of newly appearing nodes equals to the number of relevant undestroyed edges minus one, except the case 6 where all edges have already been destroyed."}, {"title": "C Additional Results of TSPLib", "content": "The detailed results of TSPLib are shown in Table 6 and Table 7. Note that in two instances, rl11849 and usa13509, the LEHD (Luo et al. 2023) needs about 80 hours and 120 hours to perform 1000 reconstruction steps. We stop the iteration at 24 hours as we observe that the LEHD has not made any progress for a long time. In most instances, our DRHG achieves the lowest optimality gap. The advantage of DRHG becomes more pronounced in hard instances of larger size or special distribution.\nIn large-size problem, POMO (Kwon et al. 2020) suffers the most from poor generalization ability, and its performance drops dramatically. BQ (Drakulic et al. 2023) and LEHD (Luo et al. 2023) generalize better but still struggle on cases with thousands of nodes. When the problem size grows beyond 3,000, BQ fails to solve the problem due to out-of-memory, so to LEHD when the problem size comes to about 15,000. The DRHG succeeds in solving all instances and obtains solutions with optimality gap much lower than the others.\nExcepting the instances consisting of the real-world cities, the TSPlib also incorporates some instances of special distributions, such as the drilling problems (starting with 'd', 'pcb' and 'u'), and the rattled-grid problems (strat with 'rat'). On these distributions, DRHG also outperforms the other methods."}, {"title": "D Influence of Hyper-parameters", "content": "The size of the training sample influences model performance by altering the distribution. A sample size that is too small may oversimplify the task, whereas a sample size that is too large may result in insufficient undestroyed segments for the model to effectively learn the repair process. We investigate this effect by training the model on TSP100, keeping all other settings constant. Table 8 shows the results of three settings where the sample size \\(\\in\\) [30, 70], [20, 80] and [10, 90]. The case where training sample size \\(\\in\\) [20, 80] performs the best.\nTable 9 illustrates the impact of destruction degree during inference on performance. A higher degree of destruction can be more efficient than a lower one, provided that the repair quality remains consistent. However, since the model is trained with no more than 100 nodes, repair quality diminishes when the destruction becomes too extensive. Destroying \\(k\\) nodes with"}, {"title": "E Destroy-and-repair Demonstration", "content": "Fig. 7 demonstrates the destroy-and-repair of a TSP instance with \\(n = 100\\). Three segments are left after the destruction. The model changes how these segments are connected during the repair and makes the contour of the solution apparently different."}]}