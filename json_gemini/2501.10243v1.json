{"title": "Random-Key Algorithms for Optimizing Integrated Operating Room Scheduling", "authors": ["Bruno Salezze Vieira", "Eduardo Machado Silva", "Ant\u00f4nio Augusto Chaves"], "abstract": "Efficient surgery room scheduling is essential for hospital efficiency, patient satisfaction, and resource utilization. This study addresses this challenge by introducing a novel concept of Random-Key Optimizer (RKO), rigorously tested on literature and new, real-world inspired instances. Our combinatorial optimization problem incorporates multi-room scheduling, equipment scheduling, and complex availability constraints for rooms, patients, and surgeons, facilitating rescheduling and enhancing operational flexibility. The RKO approach represents solutions as points in a continuous space, which are then mapped in the problem solution space via a deterministic function known as a decoder. The core idea is to operate metaheuristics and heuristics in the random-key space, unaware of the original solution space. We design the Biased Random-Key Genetic Algorithm with Q-Learning, Simulated Annealing, and Iterated Local Search for use within an RKO framework, employing a single decoder function. The proposed metaheuristics are complemented by lower-bound formulations, providing optimal gaps for evaluating the effectiveness of the heuristic results. Our results demonstrate significant lower and upper bounds improvements for the literature instances, notably proving one optimal result. Furthermore, the best-proposed metaheuristic efficiently generates schedules for the newly introduced instances, even in highly constrained scenarios. This research offers valuable insights and practical solutions for improving surgery scheduling processes, offering tangible benefits to hospitals by optimising resource allocation, reducing patient wait times, and enhancing overall operational efficiency.", "sections": [{"title": "1. Introduction", "content": "Surgeries play a substantial role in hospital management. Their effective utilisation reduces surgical service delivery costs, shortens surgical patient wait times, and increases patient admissions (Roshanaei et al., 2017). To optimally manage the most relevant decisions and constraints related to it, the integrated surgery scheduling problem arises. It is a complex optimization problem that involves determining the optimal schedule for a set of surgical procedures, considering various constraints and objectives.\nMultiple operating rooms (ORs) are available in a hospital for surgeries. The goal of integrated surgery scheduling is to allocate the available resting beds, ORs, Intensive Care Units (ICUs), and Post-Surgery Care Units (PSCUs) to schedule surgical procedures in a way that maximizes room efficiency, reduces patient waiting times, and ensures the best utilization of resources.\nFrom the patient's perspective, Figure 1 visually represents the surgery process. It begins with the patient arriving at the hospital and progressing through the following steps: (i) Resting room: Upon arrival, the patient is admitted and taken to a resting bed in the assessment area. Diagnostic tests and observation are conducted to assess the patient's medical condition; (ii) Operating Room (OR): Subsequently, the patient is taken to the OR to undergo the surgical procedure; (iii) Post-Surgery Care Unit (PSCU): After surgery, the patient is transferred to the PSCU for critical observation and anaesthesia recovery. This step ensures the patient's safe transition from the surgical procedure; (iv) Intensive Care Unit (ICU) (if applicable): Depending on the surgery's risk level or the patient's condition, there might be a scheduled transfer to the ICU for specialized care and monitoring; (v) Recovery Room: Following the critical observation and ICU (if required), the patient is taken back to the same room from step (i) for a recovery period. During this phase, the patient receives focused care and support to aid their healing process. Once the medical team determines the patient is stable and ready to leave the hospital, they are discharged (vi) with relevant post-surgery instructions and prescriptions, if necessary.\nConsidering this process, the problem we refer to as the Integrated Operating Room Scheduling Problem (IORSP) involves managing a set of surgical procedures, surgeons, operating rooms, and necessary equipment. A solution is to assign each patient to a suitable operating room based on predefined time slots at different stages within the previously outlined workflow. This allocation aims to schedule pending surgeries to minimize the total execution time, a metric referred to as makespan. This optimization problem takes into account a range of critical factors and constraints, which include:\n\u2022 Surgeon availability: The scheduling process must account for the availability and preferences of surgeons. Surgeons often have different specialities and expertise, and their schedules must be synchronized with the allocated ORs. In this case study, each surgery already has a surgeon selected for it;\n\u2022 Operating room allocation: The problem entails allocating surgical procedures to the available operating rooms (ORs), which are only accessible during business hours, to minimize idle time and maximize utilization. Additionally, certain surgeries may necessitate specific equipment or specialized facilities unique to certain ORs, which adds complexity to the allocation process;\n\u2022 Surgery duration: Each surgical procedure has an estimated duration, which must be considered when scheduling surgeries sequentially. Accurate estimation of surgery duration is crucial for avoiding delays and conflicts. The patient's time in all surgery steps must be accounted for when scheduling the multiple rooms;\n\u2022 Equipment availability: The availability of necessary equipment for different kinds of surgeries, such as ophthalmic and brain microscopes or video/endoscopy racks, is considered during the scheduling process. Ensuring that all required resources are available at the right time is essential for smooth operations;\n\u2022 Time constraints: The scheduling problem also consider time constraints, such as surgeon availability, business hours, moving time between rooms, and room maintenance post-use.\nIn our literature review, building upon the research of Xiang et al. (2015), Burdett and Kozan (2018), and Vali et al. (2022), we establish that the Integrated Operating Room Scheduling Problem (IORSP) can be effectively conceptualized and addressed as a variant of the Flexible Job Shop Problem (FJSP) (Brucker and Schlie, 1990). This research has been guided by the collaboration with a non-profit hospital that has unities in several cities in Brazil, basing our approach on a real-world case. This paper reviews existing literature alongside a comparative analysis with analogous scenarios and methodologies.\nIn this paper, we propose three metaheuristics using the Random-Key Optimizer (RKO) concept (Chaves et al., 2024) to solve the IORSP: Biased Random Key Genetic Algorithm with Q-Learning (BRKGA-QL) (Chaves and Lorena, 2021), Simulated Annealing (SA) (Kirkpatrick et al., 1983), and Iterated Local Search (ILS) (Louren\u00e7o et al., 2003). The BRKGA-QL has demonstrated efficacy without necessitating parameter fine-tuning, which is crucial for real-case hospital applications. Furthermore, we introduce two mathematical models for relaxed cases, enabling more efficient computation of lower bounds compared to a complete formulation (Chaudhry and Khan, 2016). Additionally, we tested available literature instances, adapting our methods to solve them successfully and comparing our results with existing literature methods. Finally, we designed, tested, and made a set of 20 instances based on our case study available online.\nWe can highlight our scientific contributions as:\n\u2022 Proposal of two lower bound formulations that have small implementation complexity and yield better lower bounds than previous literature approaches;\n\u2022 Investigation of flexible time constraints for each restricted schedule, where each room/surgeon's working hours can be delimited as available or not by the minute (one minute was our time discretization approach, but the user can change it);\n\u2022 Introduction of a novel concept of a random-key optimizer with three metaheuristics using the same decoder process;\n\u2022 Development of a parameter-less metaheuristic that performs better than tuned ones and literature algorithms for similar hospital cases.\n\u2022 Validation of our methods against a similar literature case and demonstration of better results than previous ones;\n\u2022 Complete modelling of a real-case scenario by procedurally generating 20 instances and making them available in a public repository;\n\u2022 Demonstration of possible rescheduling using the same input data approach;\nThe remainder of the paper is structured as follows. In Section 2, we provide a literature review of the most similar works. In Section 3, we define the problem description. Section 4 details our proposed metaheuristics using the random-key concept, decoder, and reinforcement learning component. In Section 5, we present our experimental data, results, and analyses. In Section 6, we further discuss the results and conclude the paper. Our mathematical formulations to compute lower bounds are shown in Appendix A and Appendix B."}, {"title": "2. Literature review", "content": "The modeling of surgery scheduling problems commenced relatively early in deterministic models literature, among the first works we have Ozkarahan (1995). The authors developed software with multiple allocation models to schedule nurses, surgeon blocks, and surgeries and, followed by Dexter et al. (1999), studied bin packing algorithms and fuzzy constraints in operating room management and other works that followed.\nReviewing the literature, given how diverse hospital management is worldwide, the cases modelled after real-world cases rarely match each other, but they have enough similarities as we list them. Most works model the problem only scheduling the operating rooms (Abdelrasol et al., 2014).\nAmong the works most similar to our approach, we have first the works of Fei et al. (2009), Fei et al. (2010), and Liu et al. (2011) that modelled OR allocation with five days of planning considering working hours and surgeon scheduling and solved using column generation and dynamic programming heuristics for procedurally generated instances and a Belgian university hospital case study. Molina-Pariente et al. (2015) proposed a case that may allocate an assistant surgeon to shorter surgery times. They proposed and implemented a constructive heuristic to solve it.\nAringhieri et al. (2015) modelled a case from the San Martino University Hospital, addressing simultaneous OR and recovery bed scheduling for a one-week planning horizon. Their model considers weekend stays without operations and various surgery specialities and is solved using a two-stage metaheuristic (assign and then schedule). Landa et al. (2016) extended the same case study into a stochastic variant, aiming to maximize OR utilisation and minimize overtime costs, and solved it using a hybrid simulation-based algorithm.\nXiang et al. (2015) treated the problem as an FJSP variant, scheduling pre and post-surgery rooms, nurses, and anaesthetists individually, similarly to our approach. They solved it with an Ant Colony metaheuristic. Marques and Captivo (2015) modelled a case of Lisbon's public hospital, allocating only ORs in a one-week planning horizon. The bi-objective problem maximizes the number of surgeries and room occupations with surgeon specialities and is solved with a bi-objective evolutionary metaheuristic.\nDur\u00e1n et al. (2017) modelled a case of a Chilean public hospital and developed two models for scheduling interventions on top of an existing OR schedule over a defined period that satisfies patient priority criteria. Dellaert and Jeunet (2017) modelled a case of a Dutch cardiothoracic centre for a 4-week planning horizon, considering the allocation of beds, ORs, and ICUs and maximizing the number of scheduled surgeries. The authors proposed a mathematical model and a Variable Neighbourhood Search (VNS) metaheuristic that found better results than the model solved with CPLEX in all cases. Siqueira et al. (2018b) solved a stochastic model for a long-term plan from a case study of the Brazilian National Institute of Traumatology and Orthopedics, which considers OR and recovery ward allocations with downstream constraints, using simulations and optimal action-taking.\nBurdett and Kozan (2018) modelled a case of a university and college-affiliated teaching hospital in Brisbane, Australia, as an FJSP considering bed, OR, PSCU, and ICU allocation. They presented and made available 24 generated instances, and to solve it, they proposed some initial solution heuristics and a Hybrid Simulated Annealing (HSA) as its main algorithm. Hamid et al. (2019) modelled a public hospital case in Tehran as a multi-objective problem. They schedule ORs considering patient priorities and surgical team members' decision-making styles to improve the surgical teams' compatibility level, minimizing the total cost, overtime OR utilisation, and maximizing team consistency. They presented a mathematical model and implemented two metaheuristics to obtain better solutions: a Non-dominated Sorting Genetic Algorithm (NSGA-II) and a Multi-Objective Particle Swarm Optimisation (MOPSO).\nRoshanaei et al. (2020) proposed Branch-and-check methods for operating room planning and scheduling with surgeon specialities for patient surgeon assignment and priorities. Their exact methods outperformed conventional integer formulation approaches by a large margin using the benchmark instances of Marques and Captivo (2015) and a procedurally generated one. Zhu et al. (2020) solved a case study of an affiliated hospital of the University of Science and Technology of China, maximizing OR utilisation on a one-week planning horizon, OR to surgery to surgeon assignment, and patient priorities. The authors presented a mathematical formulation and two hybrid metaheuristics to obtain better solutions. Thomas Schneider et al. (2020) studied the surgery groups scheduling considering ORs and downstream beds operating with different available hours with a 15-day planning horizon, modelled of the Leiden University Medical Center, proposed a single step integer model that maximizes OR usage and minimises bed usage variation with weights, they also tested the van Essen et al. (2014) instances lowering the amounts of required beds upon the previous results.\nMore recently, Lin and Li (2021) solved a case of surgery to OR assignment, five days planning horizon and minimizing the operation costs and overtime usage, provided an improved mathematical model of Fei et al. (2009) and a metaheuristic Artificial Bee Colony (ABC) that obtained better solutions for larger instances. Park et al. (2021) modelled a case of a Korean university hospital considering surgeons' preferences and cooperative operations, in which surgery can have multiple surgeons cooperatively sequentially to reduce its execution time, and the co-oped surgeries have a lower total execution time. This feature helps to minimize the total overtime and the number of ORs used. A mathematical model and a metaheuristic were proposed to solve it.\nFor more comprehensive reviews of ORSP models, including models with uncertainty, stochastic, and mixed approaches, we advise the works of Abdelrasol et al. (2014). Van Riet and Demeulemeester (2015) presented a review focused on the trade-offs in operating room planning for electives and emergencies, and Rahimi and Gandomi (2021) accomplished analysis and classified solution approaches similarly to Abdelrasol et al. (2014), with deterministic and probabilistic approaches, performance metrics and its trends throughout time."}, {"title": "3. Problem definition", "content": "Given the literature review and problem characteristics, we model the IORSP as an FJSP variant. The FJSP is usually described as having a set of jobs K to be processed by the machines of set R, each job consists of a sequenced set Tk of tasks, and each task t has to be performed sequentially to complete the job. For each job k, k \u2208 K, the execution of task t, t \u2208 Tk, requires one machine r out of a set of given machines Rt, Rt CR, that execute task t. For task t running on machine r, r \u2208 Rt, the task time is $y_{t}^{d}$, the setup time is $y_{t}^{vm}$ and cool-down time is $y_{t}^{ve}$. When a task t is complete, but the allocated machine r\u2208 RNext(t) is not immediately available, the start of task Next(t) is delayed. This delay is called blocking, with a blocking limit per task ot.\nMoreover, the FJSP typically follows some assumptions as we do, as the machines and jobs are always available. Once started, an operation cannot be interrupted. There is no precedence among the tasks of different jobs; each task can be processed by only one machine at a time. As the objective function, FJSP usually minimizes the makespan, that is, the amount of time required to complete all jobs or to maximize the total of completed jobs given a planning horizon.\nWe can translate the FJSP nomenclature to our problem, considering jobs as surgeries and machines as subjects (rooms, types of equipment, and surgeons). Each surgery consists of a sequence of tasks. Our problem has some particularities, like a non-empty initial schedule or simultaneous machines for the same task, as operations (tasks) require a surgeon, which may require some equipment and OR, i.e., different types of machines (subjects) allocated simultaneously. All $y_{t}^{d}$, $y_{t}^{vm}$ and $y_{t}^{ve}$ are fixed for any particular subject, so they are called duration ($y_{t}^{d}$), moving time ($y_{t}^{vm}$) and cleaning time ($y_{t}^{ve}$). The name blocking is a homonym in our work, and we have a fixed blocking limit \u0424 for all tasks of 15 minutes. Each subject (machine) has its initial availability schedule (structure we call availability slots). As an FJSP variant, the surgery is a job that requires heterogeneous machines working on the same task during the same period to complete it. In our approach, we only tackled minimizing the makespan. We note that maximizing the number of surgeries tends to prioritize the shorter surgeries.\nFurthermore, our modelling allows tackling the re-scheduling of surgeries. Surgery re-scheduling is crucial for effectively managing the IORSP due to the hospital environment's dynamic and unpredictable nature. It allows for flexibility and adaptability in emergencies, resource availability fluctuations, and changes in patient conditions. Re-scheduling ensures that urgent surgeries can be accommodated without significant disruptions, minimizes delays and wait times, and optimizes the use of resources. Additionally, it helps cope with cancellations and no-shows by filling gaps efficiently, maintaining high productivity levels, and ensuring timely surgical care. To implement surgery re-scheduling efficiently, we make use of the sets of availability slots with the previously fixed schedules for rooms, patients, equipment and surgeons as shown in detail in Section 5.3.\nAppendix A and Appendix B preset the relaxed models we propose and implement to compute lower bounds to minimize each instance's makespan. The resulting lower bounds are used to analyze the performance of the heuristics, and smaller gaps imply a strong performance of both proposals. Both models solve a relaxed case of the IORSP and exploit the fact that, for the case study and the literature case, the bed is reserved during the entire patient's stay in the hospital. It considers a best-case scenario execution for all surgeries and only allocates surgeries to rooms but does not sequence any task. All patients are treated without delays (blocking), disregarding room or surgeon-restricted schedules, sequencing of tasks, and equipment availability. Removing these constraints, the relaxed problem solved by both models is an allocation problem."}, {"title": "4. Random-Key Optimizer", "content": "The random-key representation was first proposed by Bean (1994) for an extension of the genetic algorithm called the Random-key Genetic Algorithm (RKGA). This representation encodes a solution with random numbers in the interval [0,1). The main idea is that the RKGA searches the random-key space as a surrogate for the original solution space. Points in the random-key space are mapped to points in the original solution space by a deterministic algorithm called the decoder. An advantage of this encoding is its robustness to problem structure, as it separates the solver (solution procedure) from the problem being solved. The connection between the solver and the problem is established through the decoder.\nA Random-key Optimizer (RKO) is an optimization heuristic that solves specific problems by exploring the continuous random-key space [0,1)^n, where n is the size of the random-key vector that encodes the problem solution. The pioneer of this approach is the work of Bean (1994), which utilizes a genetic algorithm to perform searches in the solution space for various optimization problems. In Gon\u00e7alves and Resende (2011), a variation of the RKGA called Biased RKGA (BRKGA) is proposed and evaluated for a wide range of optimization problems. Later, the RKO framework was employed by Schuetz et al. (2022) for robot motion planning, using the BRKGA and an extension of Simulated Annealing to search the random-key space. In Mangussi et al. (2023), the RKO is implemented using Simulated Annealing, Iterated Local Search, and Variable Neighbourhood Search for the tree hub location problem. Recently, Chaves et al. (2024) proposed an RKO considering the GRASP metaheuristic and evaluates it for the travelling salesman problem, tree hub location problem, Steiner triple covering problem, node capacitated graph partitioning problem, and job sequencing and tool switching problem. Figure 3 presents the RKO concept where 9 represents the specific decoder algorithm.\nThe optimization process is shown in Figure 3(a). This process takes as input an instance of a combinatorial optimization problem and returns the best solution found, guided by a specified metaheuristic. Figure 3(b) illustrates the mapping schema that connects the random-key representation to the solution space through a problem-specific decoder. After this transformation, the quality of the solutions can be evaluated. Finally, Figure 3(c) presents an example of a decoder process for a scheduling-based problem. In this case, each vector position represents a task or characteristic of the optimization problem. The decoder works by sorting the random keys, where the sorted indices correspond to a potential solution obtained by arranging the tasks in the specific order dictated by the sorted keys.\nIn the remainder of this section, we introduce the RKO framework. We begin by discussing its key components (subsection 4.1), followed by an overview of the metaheuristics utilized in the framework. Specifically, we present the BRKGA-QL (subsection 4.2), Simulated Annealing (subsection 4.3), and Iterated Local Search algorithms (subsection 4.4), which operate on the random-key vectors within the proposed RKO framework."}, {"title": "4.1. RKO Components", "content": "The RKO components are procedures embedded within the framework's random-key space that support the search process's metaheuristics balance between diversification and intensification. These components include shaking, blending, and local search performed by the Random Variable Neighbourhood Descent (RVND) method on the random-key vectors. Each of these components is described in detail below."}, {"title": "4.1.1. Shaking", "content": "The shaking method was inspired by the approach proposed by Andrade et al. (2019). The method modifies random-key values by applying random modifications considering four distinct neighbourhood moves. A perturbation rate \u1e9e is employed. This value is randomly generated within a specified interval [\u1e9emin, \u1e9emax], which should be defined according to the specific meta-heuristic approach being used. The four movements are:\n\u2022 Swap: Swap the positions of two randomly selected random keys i and j.\n\u2022 Swap Neighbor: Swap the position of a randomly selected random key i with its neighboring key i + 1.\n\u2022 Mirror: Change the value of a randomly selected random key i with its complementary value.\n\u2022 Random: Assigns a new random value within the interval [0,1) to a randomly selected random key i.\nAlgorithm 1 described the shaking procedure. First, a shaking rate \u1e9e is randomly generated within the interval [\u1e9emin, \u1e9emax], determining the number of perturbations to be applied, specifically \u1e9exn, where n is the length of the random-key vector A. For each perturbation, a random shaking move is selected from four options: a random move, a mirror move, a swap move, or a swap neighbor move. The selected move is then applied to the vector A. After all perturbations are performed, the modified vector is returned as the output. This vector is then decoded during the metaheuristics search process."}, {"title": "4.1.2. Blending", "content": "The blending method extends the uniform crossover (UX) concept proposed by Davis (1991) by introducing stochastic elements to create a new random-key vector. The algorithm combines two solutions, A\u00ba and Ab, to generate a new solution Ac. For each position i in the vector, a random decision is made based on a probability p to inherit the corresponding key from either A or Ab. The algorithm introduces a parameter factor, which modulates the contribution of Ab. Specifically, when factor = 1, the original key from Ab is used, and when factor = -1, the complement (1.0 \u2013 $A_{i}^{b}$) is considered. Additionally, with a small probability \u00b5, the algorithm generates a new random value within the interval [0,1), further diversifying the resulting vector A. The algorithm's pseudocode is presented in Algorithm 2."}, {"title": "4.1.3. Random Variable Neighbourhood Descent", "content": "The Variable Neighbourhood Descent (VND) was proposed by Mladenovi\u0107 and Hansen (1997) and extended later for various optimization problems. The VND consists of a finite set of pre-selected neighbourhood structures denoted by Nk for k = 1,...,kmax, where Nk(A) represents the set of solutions in the k-th neighborhood of a random-key vector A. While standard local search heuristics typically employ a single neighborhood structure, VND utilizes multiple structures to enhance the search process. Key considerations for applying VND include determining which neighborhood structures to use and their sequence and selecting an appropriate search strategy for switching between neighborhoods. Later, Penna et al. (2013) proposed the RVND. RVND randomly selects the neighborhood heuristic order to be applied in each iteration. RVND efficiently explores diverse solution spaces and can be applied to random-key spaces. Users can implement classic heuristics for the specific problem and encode the locally optimal solution into the random-key vector after the search process. Alternatively, users can implement random-key neighborhoods independent of the specific problem, using the decoder to converge towards better solutions iteratively.\nAlgorithm 3 displays the RVND pseudo-code. Given an initial solution A, the algorithm begins by initializing a Neighborhood List (NL). While the NL is not empty, a neighborhood N\u00b2 is selected randomly from it, and the best neighbor A' within N\u00b2 is identified. If the objective function value $\\SD(A')$ improves upon the current solution $\\SD(A)$, the current solution A is updated to A', and the NL is reset. If no improvement is found, the selected neighborhood N\u00b2 is removed from the NL. The process repeats until all neighborhoods have been explored without finding a better solution. The algorithm then returns the best solution found.\nNext, we introduce four problem-independent local search heuristics designed to operate within the random-key space. These heuristics employ distinct neighborhood structures for the RVND algorithm, specifically used to identify the best neighbors as described in line 4 of Algorithm 3. The neighborhood structures include Swap LS, Mirror LS, Farey LS, and Nelder-Mead LS."}, {"title": "4.1.4. Swap Local Search", "content": "The Swap local Search focuses on interchanging two values within the random-key vector. The local search procedure considering this structure is outlined in Algorithm 4. The algorithm begins by defining a vector RK with random order for the random-key indices and initialises the best solution found, Abest, to the current solution A. It then iterates over all pairs of indices i and j (with j > i) in the random-key vector. For each pair, it swaps the value of the random keys at indices RK and RKj in A. If the resulting solution has a better objective function value than Abest, it updates Abest to the new solution. If not, it reverts A to the previous best solution. The process continues until all pairs have been considered. The algorithm returns Abest as the best random-key vector found in the neighborhood."}, {"title": "4.1.5. Mirror Local Search", "content": "The Mirror Local Search perturbs the random-key values, changing the current value in position j to (1 - A[j]). Algorithm 5 illustrates this procedure. Initially, it defines a vector RK with a random order for the random-key indices and sets the best solution found, Abest, to the current solution A. The algorithm then iterates over all indices i in the random-key vector A. For each index, it inverts the value of the random key at RK. After each inversion, if the new solution has a better objective function value than Abest, it updates Abest to the new solution. If not, it reverts A to Abest. This process continues until all indices have been processed. Finally, the algorithm returns Abest as the best random-key vector found in the neighborhood."}, {"title": "4.1.6. Farey Local Search", "content": "The Farey Local Search modifies the value of each random key by randomly selecting values between consecutive terms of the Farey sequence Niven et al. (1991). The Farey sequence of order \u03b7 consists of all completely reduced fractions between 0 and 1, with denominators less than or equal to n, arranged in increasing order. For our purposes, we use the Farey sequence of order 7:\n$F_{7} = \\frac{0}{1}, \\frac{1}{7}, \\frac{1}{6}, \\frac{1}{5}, \\frac{1}{4}, \\frac{1}{7}, \\frac{1}{3}, \\frac{2}{5}, \\frac{3}{7}, \\frac{1}{2}, \\frac{4}{7}, \\frac{3}{5}, \\frac{2}{3}, \\frac{5}{7}, \\frac{3}{4}, \\frac{4}{5}, \\frac{5}{6}, \\frac{6}{7}, \\frac{1}{1}$"}, {"title": "4.1.7. Nelder-Mead Local Search", "content": "The Nelder-Mead Local Search, introduced by Nelder and Mead (1965), is a numerical technique for finding the minimum of an objective function in a multidimensional space. This direct search approach relies on function comparisons and is commonly used in derivative-free nonlinear optimization. The method starts with at least three solutions and can perform five moves: reflection, expansion, inside contraction, outside contraction, and shrinking. In this study, we always apply the Nelder-Mead Local Search with three solutions: A1, A2, and A3, where one is the current solution derived from the metaheuristic, while the others are randomly chosen from a pool of elite solutions found during the search process. These solutions are ordered by objective function value (A1 is the best and A3 is the worst). Figure 4 illustrates a simplex polyhedron and the five moves.\nAlgorithm 7 presents the pseudo-code for the Nelder-Mead Local Search adapted for discrete optimization problems. We employ the blending method (Algorithm 2) to generate new solutions, using p = 0.5 and \u03bc = 0.02. The algorithm begins with an initial simplex of three solutions (A1, A2, A3). The simplex is sorted based on the objective function values, and the simplex's centroid (A0) is computed between A1 and A2 (A0 = Blending(A1, A2, 1)). The main loop iterates until a termination condition is met. The algorithm performs a series of moves on the simplex during each iteration to explore the search space. A reflection solution (A\u2081 = Blending (A0, \u0410\u0437, -1)) is computed. If the objective function value at Ar is better than the current best solution (A1), the algorithm computes an expansion solution (Ae = Blending (Ar, Ao,-1)). If the objective function value at Ae is better than at Ar, A3 is replaced by Ae; otherwise, A3 is replaced by Ar. If neither the reflection nor the expansion improves the solution, the algorithm contracts towards the solution Ar or A3. For an outside contraction (when A, is better than A3), the contraction solution is Ac = Blending (Ar, A0, 1). For an inside contraction (when A, is not better than A3), the contraction solution is Ac = Blending(A0, A3, 1). If the contraction step does not improve, the entire simplex is shrunk towards the best solution A1 (A\u2081 = Blending(A1, Ai, 1), i = 2,3). The algorithm terminates when the maximum number of iterations equals n \u00d7 e-2."}, {"title": "4.2. Biased Random-Key Genetic Algorithm with Q-Learning", "content": "The BRKGA was introduced by Gon\u00e7alves and Resende (2011) and modifies the RKGA by incorporating bias into the parent selection and crossover operators during the evolutionary process. Specifically, BRKGA starts its search process by initializing an initial population denoted as P, consisting of randomly generated |P| individuals. In each subsequent generation, these individuals are evaluated based on their fitness, being classified into two distinct groups. The elite population, denoted as Pe CP, contains the better individuals in terms of fitness. The other group includes non-elite individuals (P \u2013 Pe).\nAn individual's fitness is predicated on the resultant value yielded by the objective function (Gon\u00e7alves and Resende, 2011). In the course of evolution, a new population emerges through a two-step procedure: first, by replicating the elite partition Pe from the current generation, and then, by introducing a novel group of mutants referred to as Pm. The quantity of mutants is proportional to the size of the population. The offspring set is denominated as Pe and is produced using the parameterized uniform crossover (PUX) operator (Spears and De Jong, 1991) to complete the new population.\nThe new population is thus comprised of three distinct parts: i) the elite partition Pe, ii) the mutant partition Pm, and iii) the offspring set Pe derived from PUX. This operator process hinges on a parameter pe, which governs the likelihood of an offspring inheriting a gene (or vector component) from an elite parent instead of a non-elite parent. A random number is generated for each gene within an offspring. Should this random number be less than pe, the corresponding gene is inherited from the elite parent's random key; otherwise, it is inherited from the non-elite parent's random key. After this, a decoding mechanism is applied to each individual, mapping the chromosome into a problem solution.\nIn the version of the BRKGA implemented in this paper, the new population comprises only two components: i) the elite partition Pe and ii) the offspring set Pe. The crossover operator is the blending procedure (see subsection 4.1.2) with factor = 1 rather than the PUX method. As a result, the role of mutants is replaced by introducing a mutation operator directly within the blending method (lines 2-3 of Algorithm 2).\nThe individuals are then evaluated and sorted based on their fitness. This evolutionary process continues until a predetermined stopping criterion, such as attaining a maximum number of generations, is fulfilled. Additional configurable parameters of the BRKGA encompass the population size (|P|), the proportion of individuals contained within the elite partition (pe, where |Pe| = |P| \u00d7 pe), and the probability of mutation (\u03bc).\nThe BRKGA-QL (Chaves and Lorena, 2021) differs from the just presented BRKGA. The first aspect is the replacement of mutants by mutations. Before gene selection from either parent, a mutation may occur with a probability of \u03bc. If positive, the gene acquires a random value within the range of [0,1); otherwise, the gene is inherited based on a probability pe, with preference given to the elite parent, and if not, it is inherited from the non-elite parent. Secondly, using a Q-Learning agent, it dynamically adjusts the parameter values (p, pe, \u03bc, and pe). Finally, we have a local search module coupled at the end of each generation. A clustering method is applied to identify promising regions, and an intensification is performed to accelerate the convergence of the method. The RVND (see section 4.1.3) is used as the local search component. Detailed information about this Q-learning agent can be found in the following section."}, {"title": "4.2.1. Q-Learning", "content": "The parameter selection process represents an additional optimization challenge", "parameters": ""}]}