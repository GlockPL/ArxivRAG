{"title": "Predicting Quality of Video Gaming Experience Using Global-Scale Telemetry Data and Federated Learning", "authors": ["ZHONGYANG ZHANG", "JINHE WEN", "ZIXI CHEN", "DARA ARBAB", "SRUTI SAHANI", "BIJAN ARBAB", "HAOJIAN JIN", "TAUHIDUR RAHMAN"], "abstract": "Frames Per Second (FPS) significantly affects the gaming experience. Providing players with accurate FPS estimates prior to purchase benefits both players and game developers. However, we have a limited understanding of how to predict a game's FPS performance on a specific device. In this paper, we first conduct a comprehensive analysis of a wide range of factors that may affect game FPS on a global-scale dataset to identify the determinants of FPS. This includes player-side and game-side characteristics, as well as country-level socio-economic statistics. Furthermore, recognizing that accurate FPS predictions require extensive user data, which raises privacy concerns, we propose a federated learning-based model to ensure user privacy. Each player and game is assigned a unique learnable knowledge kernel that gradually extracts latent features for improved accuracy. We also introduce a novel training and prediction scheme that allows these kernels to be dynamically plug-and-play, effectively addressing cold start issues. To train this model with minimal bias, we collected a large telemetry dataset from 224 countries and regions, 100,000 users, and 835 games. Our model achieved a mean Wasserstein distance of 0.469 between predicted and ground truth FPS distributions, outperforming all baseline methods.", "sections": [{"title": "1 Introduction", "content": "Frames Per Second (FPS) significantly impacts video gaming experiences due to a complex interplay of factors [22-24, 38]. It particularly influences player performance in competitive games, such as first-person shooters, by affecting reaction speed, distance, and accuracy [56]. Providing estimated FPS for a game helps customers set realistic expectations for gaming experiences on their devices, while also aiding game companies in reducing negative reviews caused by users' misunderstandings of hardware limitations [1, 13]."}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Game Experience", "content": "The experience of playing video games is often seen as a personal connection between the player and the game, influnced by many factors [18, 40, 46]. Researches into game experience have consistently identified several core factors that influence player satisfaction and engagement [23, 24, 38]. These factors include game mechanics [30, 42, 49], storyline, character design [27, 51, 53], soundtrack music [33, 37], control device [41], and technical performance such as frame rate and resolution [23, 24, 38]. Although these papers provide some insightful points, their conclusion are either qualitative or based on a small group of players, lacking large data-driven worldwide analysis, and and statistics-based conclusion.\nFrame rate is crucial in shaping the Quality of Experience (QoE) for gamers [23, 24]. Higher FPS generally contributes to smoother gameplay, reducing motion blur and input latency, which is critical for fast-paced games such as first-person shooters. Liu et al. [38] quantified the impact of frame rate variation on game player's quality of experience, noting that while average FPS is a general QoE predictor, it is not the best. The 95% frame rate floor - representing the bottom 5% of frame rates experienced by the player during a gameplay \u2013 effectively predicts QoE for both overall and individual games tested. This provides us with a strong conclusion that 95% floor of FPS distribution is a good indicator of QoE, and our following analysis are done based on this conclusion.\nRecently, some top-tier games have started providing their own benchmark tools to calculate the 95% floor FPS (also referred to as the \u201cLow 5th\") prior to players' purchase [2]. They achieve this by asking players to pre-download a small demo-like sample game that encompasses most of the characteristic scenes from the main game. By automatically running this test tool for a period of time, it collects sufficient FPS sample data points and can provide the 95% floor FPS metric. Although the performance test takes a relatively long time to complete, providing this type of benchmarking tool and informative metrics is largely welcomed by players.\nPioneering works have emphasized FPS as a key factor in the gaming experience, but fundamental influencing factors remain unexplored. Our quantitative analysis can help bridge this gap."}, {"title": "2.2 Federated Learning with Distributed Data Sources", "content": "Federated Learning (FL) is a transformative approach which enables model training across multiple decentralized devices [20, 26, 35, 39, 45]. Unlike traditional centralized training methods, FL allows data to remain on local devices: only client models' update or gradients are shared and aggregated. This approach not only reduces the risks and costs associated with data transmission but preserves client privacy. To enhance model performance, previous research has employed various techniques, including Federated Averaging (FedAvg) and its extensions [31, 34, 55] to aggregate client model weights, and methods that aggregate gradients from clients [25].\nCurrently, FL has been broadly applied across domains including healthcare [17, 48, 52], finance [16, 19, 39], and IoT [29, 54, 58], demonstrating its potential to leverage large-scale distributed data sources while adhering to stringent privacy requirements. Inspired by previous works, we aim to leverage federated learning to study player's video game experience with large-scale telemetry data."}, {"title": "2.3 Game Performance and Configuration Guidance from Platforms", "content": "Currently, mainstream gaming platforms like Steam [10], Epic Games Store [3], and Xbox Games [15] on PC provide limited performance guidance, mainly listing minimum and recommended hardware configurations.\nHowever, these platforms still fall short in providing guidance from a frames-per-second (FPS) perspective, which could also consider a player's specific hardware and software characteristics, gaming history, and the performance of other users with similar setups. Our goal is to propose a more accurate and privacy-conscious solution to address this gap."}, {"title": "3 Data Collection", "content": "Telemetry Data. To better understand and predict what determines a player's FPS while playing a game, we designed a data collector. With user consent, this data collector runs in the background and primarily collects three types of data.\n(1) Player-specific data, such as the hardware device and operating system version used by the player, as well as the player's country or region (see Fig. 4 for player distribution across different regions).\n(2) Gameplay session-related data, including the game start time, whether it is in full screen mode, and whether Game Mode is enabled.\n(3) FPS ground truth data. Once the game starts, our data collector samples and records the current frame rate every five seconds. Due to the varying lengths of game sessions, to reduce the volume of transmitted and recorded data and to avoid unnecessary precision, the data collector quantifies the FPS values into 42 bins. Each bin represents a 5Hz range, with four exceptions (<10Hz, 200-300Hz, 300-400Hz, >400Hz.) For each game session, it records the number of FPS samples in each bin and the average FPS for the session. Data collector on each device is assigned a unique identifier to tell apart players.\nSince we aim to collect only game-related processes' data and determine whether a Windows process is a game program, we filter processes depending on if it invokes DirectX [12]. Microsoft DirectX is a collection of application programming interfaces (APIs) for handling tasks related to multimedia, especially game programming and video, on Microsoft platforms. When a program calls DirectX while in the foreground, it triggers our data collector to generate a new record.\nTo further collect game-related data and exclude non-game processes, we mapped executable names to games by web scraping SteamDB [11], a third-party site listing executable names under each game's configuration page [4]. For executables not mapped from the scraped data, we manually annotated their game names through web searches and individual checks (e.g., mapping BlackOps.exe\u201d to Call of Duty: Black Ops\"). Additionally, executable names that are too ambiguous to identify specific games (e.g., game.exe\u201d, launcher.exe\u201d) were discarded along with non-game processes.\nWe found that some users had not played any games, with records triggered by other programs invoking DirectX. We removed these sessions from our dataset. We also excluded game sessions shorter than 5 minutes, as\""}, {"title": "4 Data Insights", "content": "The 95% FPS floor is a key metric to evaluate players' quality of game experience [38]. In this section, we provide an in-depth analysis to uncover and explain the factors associated with this metric."}, {"title": "4.1 Micro-Level Influence Factors", "content": "Player-side features. We examined the factors influencing the 95% FPS floor, focusing on representative player characteristics like CPU and GPU specifications, operating system, country and region, and device type."}, {"title": "4.1.1 Device type", "content": "Different devices have distinct design philosophies and trade-offs. For example, tablets prioritize portability but often sacrifice performance and cooling, while desktops, though bulkier, can house more powerful components and benefit from a stable power supply due to their larger size. We categorized devices into six types: desktop, notebook, 2-in-1 devices, Intel NUC/STK (Next Unit of Computing/Compute Stick), server/workstation, and tablet. To quantitatively analyze how device types affect the 95% FPS floor, we conducted an one-way ANOVA test [47] comparing the effects of different device types. The results, presented in Table 1, revealed a statistically significant difference in the 95% FPS floor between at least two groups (F(6, 153387) = 4003.460, p = 0), with a medium effect size (\u03b7\u00b2 = 0.116). Furthermore, the Tukey's HSD test [43] for multiple comparisons found significant differences between groups such as desktop and 2-in-1 devices (p = 0, 95%C.I. = [31.847, 34.638]), and server/workstation and tablet (p = 0.024, 95%C.I. = [\u221274.527, -3.029]). However, there was no statistically significant difference in the mean 95% FPS floor between notebook and server/workstation (p = 0.558) or 2-in-1 devices and tablets (p = 0.585)."}, {"title": "4.1.2 GPU Performance", "content": "Delving into specific hardware configurations, we find that GPU performance is closely related to FPS. Given that GPU performance is influenced by many parameters, we grouped GPUs with publicly available specifications into five categories: Office-Class, Low-End, Low-Mid-Range, Mid-Range, and High-End. Records with missing GPU model values or unknown GPU types were excluded. A one-way ANOVA revealed a statistically significant difference in the 95% FPS floor between at least two groups. FPS distributions also significantly differed between players using discrete Nvidia, AMD, and Intel graphics cards or integrated graphics. This variation is likely due to differences in game optimization across GPU brands and exclusive technologies like Nvidia's DLSS (Deep Learning Super Sampling), which can achieve higher frame rates with similar computational power [57]."}, {"title": "4.1.3 CPU Performance", "content": "Similarly, CPU performance positively affects FPS, with improvements in CPU genera-tion (Fig. 5a) and core count (Fig. 5c) resulting in a higher 95% FPS floor. One-way ANOVA tests conducted for CPU families show a significant effect. A multiple linear regression was used to test if CPU process node (unit: nm), CPU core count, RAM size, and screen size significantly predicted the 95% FPS floor. The"}, {"title": null, "content": "fitted regression model was:\n$FPS_{95} = 6.878 \\times n + 0.28 \\times r \u2013 0.5165 \\times p + 1.8697 \\times s \u2212 2.0675$ (1)\n, where n, r, p, and s represent the CPU core count, RAM size (in GB), CPU process node (in nm), and screen size (in inches), respectively. The model explained approximately 33.3% of the variance in the dependent variable, as indicated by an R\u00b2 value of 0.333. While a larger screen size doesn't intuitively lead to better FPS, higher investment in peripherals like monitors often reflects a player's greater demand for overall gaming experience. Such players are likely to invest more in core device components, which may explain this correlation."}, {"title": "4.1.4 Operating System", "content": "In addition to hardware specifications, we also examined the impact of the operating system. The corresponding one-way ANOVA results (F(5, 153370) = 212.757, p = 0) showed a statistically significant difference between groups, though the effect size was very small (\u03b7\u00b2 = 0.007), suggesting that these differences, while statistically significant, have limited practical importance."}, {"title": "4.1.5 Country and Region", "content": "Finally, we explored the effect of the player's country or region. As shown in Table 1, there was a significant difference between country groups, with a small effect size (\u03b7\u00b2 = 0.05). Country-level impact factors are discussed in detail in Section 4.2."}, {"title": "4.1.6 Categorical game features", "content": "One-way ANOVA results revealed a significant difference in the 95% FPS floor across different game themes (F(21, 1822) = 2.12, p = 0.002, \u03b7\u00b2 = 0.024), though the effect size was small. Similarly,"}, {"title": "4.1.7 Numerical game features", "content": "Additionally, a multiple linear regression was performed to assess whether numerical game characteristic features significantly predicted the 95% FPS floor. The results, shown in Table 4, indicate that the estimated coefficient for the number of supported game platforms was 17.099, with a significant p-value of 0.025, suggesting that this feature has a meaningful effect on the 95% FPS floor. However, p-values for game release years and months, game rating, rating count, and supported language count were all greater than 0.05, indicating no statistically significant relationship with the 95% FPS floor. This suggests that these game characteristics do not have a strong or consistent effect on the 95% FPS floor within the context of this dataset.\nCompared to player-side features like device parameters, game characteristics have a significantly smaller effect on the 95% FPS floor, as observed from both the F-statistic and \u03b7\u00b2 results in Table 1 and Table 3. This indicates that hardware specifications have a greater impact on game experience than game characteristics."}, {"title": "4.2 Macro-Level Influence Factors", "content": "The previous sections discussed micro-level factors affecting FPS performance. But on a macro level, what broader factors influence the gaming experience?"}, {"title": "4.2.1 GDP per Capita", "content": "Our analysis reveals a positive correlation between a country's average gaming experience and its GDP per capita, following a logarithmic relationship (p = 0, R2 = 0.562). GDP per capita reflects economic output and living standards. Countries with high GDP per capita, such as Iceland and Switzerland, show the highest FPS performance, while those with low GDP per capita, such as Rwanda and Togo, exhibit the lowest. The scatter plot and fitted line are shown in Fig. 6a, with some highlighted countries."}, {"title": "4.2.2 Gini index", "content": "Conversely, the Gini index, which measures income inequality, negatively correlates with gaming experience (p = 0, R2 = 0.246). Higher Gini indices, indicating greater inequality, are associated with lower gaming experiences. Countries with low Gini indices, such as Iceland and Denmark, have the best player experiences, while those with high Gini indices, like Namibia and Colombia, exhibit poorer performances."}, {"title": null, "content": "By fitting a line to our data, we derived a simple formula that accurately describes the relationship between a country's average 95% FPS floor, GDP per capita, and the Gini Index:\n$FPS_{95} = 12.84 \\times log_{10}a + \u22120.42\u03b2 + 6.84$ (2)\n, where a and \u1e9e represents GDP per capita (in USD) and the Gini Index of the country or region, respectively. When these two factors are considered together, the model yields an R-squared value of 0.625, indicating that approximately 62.5% of the variability in the 95% FPS floor is explained by variations in GDP and Gini Index. The statistical significance of these predictors is confirmed by the resulting p-value (p = 0).\nIn summary, on a micro level, better hardware such as GPUs, CPUs, and RAM, as well as performance-focused devices, contribute to an overall better gaming experience. Game characteristics, including themes, genres, and player perspectives, also play a role. On a macro level, the average wealth of a population and the fairness of income distribution within a country are significant factors influencing the gaming experience."}, {"title": "5 Player-Game Pair FPS Distribution Predictor", "content": "Building on top of the statistical relations we found in the previous section, there is a clear correlation between FPS distribution and player and game features. In this section, we aim to develop a predictive model for game experience with telemetry data."}, {"title": "5.1 Data Pre-processing", "content": "The collected telemetry and game-centric data includes various data types, such as floating-point, integer, categorical, date-time, boolean, and string. Data preprocessing involved cleaning and transforming raw IGDB data into a structured format, addressing missing values by filling numerical ones with the median and normalizing"}, {"title": "5.2 Methodology", "content": "Let's revisit the problem definition: Given the characteristics of players and games, the goal is to predict the FPS performance of a new player-game pair. Each input data point consists of one-dimensional features, so we use the MLP (Multi-Layer Perceptron) as foundational blocks.\nDespite collecting as many quantifiable features as possible within ethical boundaries, each user and game has habits or characteristics that are hard to quantify and need case-by-case consideration. To address this problem, we assign each player and game a unique learnable knowledge kernel (LKK), distributed and trained on each player's device. This ensures that these kernels accurately reflect their habits and characteristics, enhancing prediction accuracy and providing valuable customization.\nThe cold start is also an issue. For newly released games or first-time users, the corresponding LKK isn't fully trained. To handle this, we propose a flexible approach to apply these kernels. This includes scenarios such as not using kernels, using only player or game-specific LKKs, and using both kernels. During training, we calculate the"}, {"title": null, "content": ", where $O_{wo}$, $O_{wp}$, $O_{wg}$, $O_{wb}$ means output under the condition of without LKK, with player LKK, with game LKK, with both LKK. The training loss can be further written as:\n$L = \\sum_{k \\in K} criterion(O_k, GT)$ (7)\n, where K represents the set consists of the four LKK usage cases mentioned above.\nDuring testing, the conditions for applying LKKs can be preset, such as requiring at least three trained records for a player to enable the player-specific LKK, or ten records for a game to enable the game-specific LKK. When these conditions are met, the corresponding kernels are used in predictions (Fig. 7a). The model's performance under the four cases is analyzed in Section 6.2.\nWhile this predictor benefits both players and developers, privacy remains a concern. Player-side features such as hardware specifications and geographic information are used as input, and the FPS distribution ground truth for purchased games depends on numerous FPS samples collected during gameplay. These samples can reveal sensitive details such as game session length and frequency.\nThe collection and transmission of user information to servers pose privacy risks. To mitigate this, we adopted a federated learning approach. Data are stored exclusively on users' devices, and models are trained locally. After local training, only gradients from client models are sent to the server, where they are aggregated to update the global model once gradients from a sufficient number of players are received. Updated model weights are then distributed to all client models again (see Fig. 7c)."}, {"title": "6 Results of the FPS Predictor", "content": ""}, {"title": "6.1 5-Classes FPS Distribution Prediction", "content": "To fully evaluate the performance of our proposed model and training strategy, we compared the results against several baseline methods and between centralized and federated training strategies. The results, shown in Table 5, demonstrate that our model outperforms all baseline methods across all metrics. Importantly, federated training does not degrade performance, as players' data remains local, and only gradients are shared with the server. These findings confirm that the federated training strategy is effective for this task, and our method is robust.\nOur goal is to predict the distribution of FPS bins for a player-game pair. The primary metric we use is the Wasserstein distance, also known as Earth Mover's Distance (EMD), which is valuable for comparing probability distributions over discrete bins. It quantifies the minimum cost required to transform one distribution into another, based on the amount of probability mass moved and the distance it is moved. This metric is particularly suitable for this task, as it captures the differences between predicted and ground truth distributions while considering the bin structure. Mathematically, the Wasserstein distance of order one is defined as:\n$W\u2081 (P, Q) = \\underset{\u03b3\u03b5\u0393 (P,Q)}{inf}\u222bd(x, y) d\u03b3(x, y)$ (8)\n, where \u0393(P, Q) denotes the set of all joint distributions y whose marginals are P and Q, and d(x, y) represents the distance between bins x and y.\nOther commonly used metrics are also adopted to profile performance from various angles. These metrics include those focusing on distribution, such as cross entropy, Kullback-Leibler divergence, and mean absolute error, as well as category-centered metrics for profiling the predicted category with the highest probability, such as Top-1 accuracy and F1 score. Another metric, adjacent accuracy, measures the proportion of cases where the predicted top-1 FPS distribution category is the same as or adjacent to the ground truth category. This is used because the bin categories are not distinct classes, and we want to assess how close the predicted top-1 bins are to the ground truth."}, {"title": "6.2 Ablation Study", "content": "LKK-related training and cold start strategies are core components of the proposed model. To evaluate the effectiveness of player and game-specific learnable knowledge kernels, we conducted an ablation study. We assessed the performance of the fully trained model on the validation set under four conditions: without any kernel, with only a game-specific learnable knowledge kernel, with only a player-specific learnable knowledge kernel, and with both types of kernels. The results, shown in Table 6, indicate that the best performance across all metrics is achieved when both kernels are used. Performance improves with the use of either kernel type compared to not using any knowledge kernel at all."}, {"title": "6.3 Training Details", "content": "The dataset was randomly split into 80% training and 20% validation subsets. We trained our neural network using the Adam optimizer (learning rate = 0.001) for 100 epochs, with L1 regularization (weight = 1 \u00d7 10\u00af\u00ba). Built on PyTorch, our model is 1.44 MB without embeddings, requiring 213,504 FLOPs for inference without embeddings and 377,344 FLOPs with embeddings. On an NVIDIA RTX 4090, the average inference time per sample is 0.14 ms with embeddings and 0.07 ms without. On a 13th Gen Intel(R) Core(TM) i9-13900 CPU, inference takes 1.15 ms with embeddings and 0.96 ms without. These results indicate that our model is lightweight and efficient across different hardware configurations."}, {"title": "6.4 Auxillary Full 42-Classes FPS Distribution Prediction", "content": "For most players, the 5-class game FPS prediction is sufficient to help them make appropriate game purchase decisions while avoiding overwhelming yet unnecessary information. These five classes correspond to different levels of video game smoothness, providing better explainability. However, for professional players, a more fine-grained FPS distribution can offer better insights into the game's performance. For example, the concentration of"}, {"title": "7 Discussion and Future Work", "content": ""}, {"title": "7.1 Quantified Game Performance Analysis Based on the First Worldwide Gaming Telemetry Dataset", "content": "The discussion on game performance has been ongoing since the inception of gaming. As games become more visually realistic and immersive, the computing power required to render them smoothly has increased signifi-cantly. The continuous advancement of game engines and gaming technology has driven parallel improvements in gaming hardware, optimizing performance and offering players a captivating audiovisual experience.\nIn the gaming community, runtime performance is recognized as a critical factor in the overall gaming experience, alongside quality and gameplay. Even with a well-crafted game concept and top-tier production, a laggy or inconsistent performance can render these qualities irrelevant, ultimately damaging a game's reputation, sales, and even the developer's credibility.\nWhile game performance is crucial, it is not the only factor affecting smooth gameplay. Network speed and server response times also play a role. However, in single-player and many online gaming scenarios, player-side device performance remains the predominant factor. To minimize performance-related issues, developers have made various efforts: testing games on diverse configurations to determine minimum and recommended specs, offering visual quality options to cater to different hardware capabilities, and releasing demo versions to let players gauge game performance firsthand. Recently, platforms like Xbox have begun utilizing deep learning techniques to predict a binary playability of games on individual devices, enhancing players' confidence in purchasing. Game console manufacturers also contribute by offering standardized configurations, enabling developers to optimize their games for specific hardware, which has played a significant role in the popularity of consoles worldwide.\nHowever, as previously discussed, game performance is influenced by a myriad of factors. Additionally, certain unquantifiable aspects-such as individual gaming habits, typical system settings, and the variations in optimization strategies across platforms-are challenging to capture on a per-game, per-user basis. Till now, analyzing these numerous influences on game performance holistically has been almost impossible. The industry-standard approach has been largely case-by-case, with developers providing minimum and recommended hardware specifications based on game-specific attributes, while players gauge potential performance based on their hardware and experience. This process is inefficient, inaccurate, and often leads to uncertainty and frustration, which can impact the game's success.\nThe root of these challenges lies in the absence of a comprehensive, representative dataset that captures quantifiable factors influencing game performance. Additionally, there has been no approach capable of addressing unquantifiable aspects of performance in a way that satisfies both players and developers. Unlike previous efforts,"}, {"title": "7.2 Inherent Complexity and Entanglement of the Game Performance Prediction Task", "content": "Predicting game performance presents a multifaceted challenge that arises from the necessity to integrate diverse data sources and account for numerous interdependent factors.\nData Collection and Pre-processing. Many potential features could impact game performance. However, identifying the most promising ones is essential before beginning data collection. To achieve this, we conducted an extensive search of relevant materials, reviewed players' first-hand comments, and carried out trial-and-error analyses on smaller data samples. Data cleaning and pre-processing posed additional challenges, as some partici-pants played games infrequently or not at all. Regional and language differences also introduced complications, as system and hardware labels were initially recorded in foreign languages, requiring remapping and filtering. Establishing standards for merging and filtering game records was crucial, as it directly influenced the quality of data used in downstream analysis and deep learning model training. Another major challenge is creating a mapping table to link game process names from various versions to unique official game names. Since there's no direct way to retrieve the official name of a running game, manually building a comprehensive mapping table is essential.\nIntegration of Diverse Datasets. Predicting game performance requires the integration of diverse datasets encompassing game-specific attributes, user characteristics, and hardware specifications. Currently, there are no comprehensive datasets that can cover all these aspects. Additionally, the heterogeneous nature of these data sources poses significant challenges in data merging, as there often lacks a common feature or identifier to serve as the bridge for integration. This fragmentation complicates the construction of a unified dataset, thereby hindering the development of accurate predictive models.\nSelection of Performance Metrics. Many features influence overall game performance, making the choice of an effective metric to represent it both critical and challenging. Without a highly representative performance metric, accurately quantifying game runtime performance becomes difficult, hindering the development of a predictive model.\nDynamic Nature of FPS. FPS is a dynamic and fluctuating metric, influenced by real-time in-game activities and varying system conditions, which complicates prediction. The main challenge lies in deciding which FPS aspects to forecast-whether instantaneous FPS values, average FPS over specific intervals, or the distributional characteristics of the 95% FPS floor performance. Addressing this requires transforming raw FPS data into a structured format that captures its temporal variability while preserving its value as a performance indicator.\nThe Cold Start Problem. Another challenge in game performance prediction is the cold start problem, which occurs when the system encounters new users or games with limited historical data. For newly released games or first-time players, the lack of prior records hinders accurate predictions, affecting model generalization and reducing accuracy. Addressing the cold start problem is essential for ensuring that the predictive system"}, {"title": null, "content": "remains robust and functional across a diverse and evolving gaming landscape, where new games and players are continually introduced.\nEnsuring Data Privacy. Data privacy always presents a significant obstacle in building prediction models involving user data due to the sensitive nature of the information required. Accurate FPS predictions often rely on detailed user-specific data, including hardware specifications, software configurations, and usage behaviors. Collecting and aggregating such data on centralized servers raises substantial privacy concerns, as it can expose users to risks related to data breaches and unauthorized access. Additionally, users may be hesitant to share personal information, leading to incomplete datasets that further complicate predictive accuracy. Balancing the need for comprehensive data with stringent privacy protections is a critical issue, necessitating the development of methodologies that safeguard user information while still enabling effective performance prediction."}, {"title": "7.3 Significance of the FPS Distribution Estimator", "content": "This predictor is beneficial to players, game developers, and gaming platforms.\nFor players: FPS affects players' gaming performance and quality of experience. If the game cannot achieve the minimum tolerable FPS on a player's device, they are highly likely to hold a negative opinion of the game or give it up. Having an accurate FPS distribution estimation is essential to help players make wise and informed decisions, decreasing the likelihood of buying unsuitable games.\nFor Game Developers: On platforms like Steam, poor game optimization and low FPS often lead to player dissatisfaction and commercial setbacks, as seen with titles like \u201cCyberpunk 2077\" [5] and \u201cNobunaga's Ambition\u201d [9]. While enhancing"}, {"title": "8 Ethical Considerations", "content": "Our institution's legal department reviewed the telemetry data collection process to ensure compliance with the California Consumer Privacy Act and European GDPR standards. We included only users who explicitly consented to participate voluntarily and ensured their anonymization throughout the data collection process. We do not collect any identifiable information, such as names, addresses, or genders. Users can withdraw from the project at any time and are not exposed to any harm from this data collection. The data are securely stored in an internal data center, with access restricted to those who sign a confidentiality agreement. Permission for the executable-to-game mapping table was obtained from the SteamDB administrator before web scraping, and data from IGDB were retrieved through its public API [6] in compliance with its regulations.\nThis dataset was collected under the guidance of the institution's confidentiality policy. Due to the extensive coverage and high sensitivity of the involved areas, it cannot be directly made available to the public. For academic or commercial purposes, interested parties may contact the designated company representative for potential access under confidentiality agreements. Following the principle of anonymity, the affiliated institution will only be disclosed once this article is published. The IGDB game-centric dataset and game-to-process name mapping table are available upon request."}, {"title": "9 Conclusion", "content": "FPS is a crucial factor in determining the gaming experience. This paper designs a targeted large-scale data collection specifically for this factor, filling a gap in the quantitative analysis of big data. By analyzing software and hardware characteristics and game features from around the world, this paper delves deeply into various aspects affecting FPS from both micro and macro perspectives, providing well-founded analyses. Additionally, to address the issue of not knowing how a game will perform on a player's machine before purchase, this paper proposes a predictor based on federated learning, which takes into account the unique characteristics of both players and games. The predictor can provide results with various levels of granularity according to user needs, fully considering the cold start problem. This solution offers players more transparent and reliable information, boosting their purchasing confidence and providing insights into solving this type of issue."}]}