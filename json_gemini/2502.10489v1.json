{"title": "LiveVal: Time-aware Data Valuation via Adaptive Reference Points", "authors": ["Jie Xu", "Zihan Wu", "Cong Wang", "Xiaohua Jia"], "abstract": "Time-aware data valuation enhances training efficiency and model robustness, as early detection of harmful samples could prevent months of wasted computation. However, existing methods rely on model retraining or convergence assumptions or fail to capture long-term training dynamics. We propose LiveVal, an efficient time-aware data valuation method with three key designs: 1) seamless integration with SGD training for efficient data contribution monitoring; 2) reference-based valuation with normalization for reliable benchmark establishment; and 3) adaptive reference point selection for real-time updating with optimized memory usage. We establish theoretical guarantees for LiveVal's stability and prove that its valuations are bounded and directionally aligned with optimization progress. Extensive experiments demonstrate that LiveVal provides efficient data valuation across different modalities and model scales, achieving 180x speedup over traditional methods while maintaining robust detection performance.", "sections": [{"title": "I. INTRODUCTION", "content": "The advancement of machine learning systems depends on high-quality training data. Data valuation, which quantifies individual data points' contributions to model performance [1], enables enhanced training efficiency [2], improved model robustness [3], and collaborative data sharing [4], [5].\nThe ability to evaluate data quality during training is crucial for modern large-scale machine learning systems, as early detection of harmful training samples could prevent months of wasted computation on large models. However, existing data valuation methods require model convergence or complete training processes, making them unsuitable for streaming data processing and untargeted poisoning attacks where models may never converge. Specifically, Shapley value-based and Leave-One-Out methods [6]\u2013[9] require complete model retraining, which is computationally prohibitive and provides unreliable valuations due to retraining randomness [10], [11]. Influence function-based methods [12] rely on assumptions about loss convexity and model optimality that rarely hold in deep learning [13]. Local update methods [14], [15], while avoiding complete retraining, only consider immediate gradient information and thus fail to capture long-term training dynamics.\nIt is challenging to develop efficient time-aware data valuation. First, tracking time-varying contributions is computationally intensive, requiring O(NT) calculations for N samples over T training steps for each model update. Second, establishing appropriate benchmarks for time-aware contributions is non-trivial, as data points impact different aspects of training (convergence speed, generalization, robustness). Third, natural decaying gradient magnitudes during training lead to unfair valuations, causing later samples to receive disproportionately lower values regardless of their actual importance.\nTo address these challenges, we propose LiveVal, a time-aware data valuation method with three key innovations. First, to achieve computational efficiency, LiveVal seamlessly integrates with Stochastic Gradient Descent (SGD) training to monitor data contributions during model updates. Second, to establish reliable benchmarks for measuring data quality, LiveVal introduces a reference-based valuation mechanism where reference points serve as comparison baselines, coupled with normalization that compensates for gradient magnitude decay to enable fair comparison of data contributions across different training stages. Third, to maintain efficient real-time valuation, LiveVal employs an adaptive reference point selection strategy that dynamically updates reference points based on training dynamics, eliminating the need to store all intermediate states while preserving valuation accuracy.\nThe main contributions of this paper are:\n\u2022 We propose LiveVal, which seamlessly integrates with SGD training to achieve computational efficiency in monitoring data contributions during model updates.\n\u2022 We design an adaptive reference-based valuation mechanism with normalization that enables fair and time-aware data valuation across different training stages.\n\u2022 We establish theoretical guarantees for LiveVal's stability and demonstrate its significant advantages through extensive experiments, achieving 180x speedup over baseline methods."}, {"title": "II. PRELIMINARIES AND PROBLEM DEFINITION", "content": "We formalize the data valuation problem within a standard supervised learning framework. Let D = {(xi, Yi)}1 denote the training dataset drawn from distribution P, where xi \u2208 X and yi \u2208 Y are input features and labels respectively. N is the total number of training samples. The function f, parameterized by \u03b8 \u2208 \u0398\u2286 Rd maps inputs to predicted outputs. Given a loss function L, the learning objective is to find optimal parameters \u03b8* that minimize the expected loss over the underlying data distribution P:\n\n\u03b8* = arg min E(x,y)~p[L(f(x; \u03b8), y)].\n\nDefinition 1 (Mini-batch SGD). At each iteration t, a mini-batch Bt C {1, . . . , N }, is randomly sampled from the training set. The model parameters are then updated as follows:\n\nOt = Ot-1 - \u03b7t 1/|Bt| \u2211i\u2208Bt VoL(f(xi; Ot\u22121), Yi),"}, {"title": "A. Preliminaries", "content": "N\n(1)\n(2)"}, {"title": "B. Problem Definition", "content": "where\u03b7t is the learning rate at iteration t, and VoL(f(xi; Ot\u22121), Yi) represents the gradient of the loss with the parameters Ot\u22121 for the data point (xi, Yi).\nDefinition 2 (Parameter Trajectory). The parameter trajectory {\u03b8t}=0 represents the sequence of model parameters during training, where \u03b80 is the initial parameter and OT is the final parameter after T training steps.\nDefinition 3 (Influence Function [12] ). The influence of a training point zi = (xi, Yi) on the loss at a test point ztest is:\n\nI(Ztest, xi) = \u2212VeL(Ztest, \u03b8*)THo\u22121\u2207oL(xi, \u03b8*),\n\nwhere Ho* = 1/N \u2211i=1 N VL(xi, Yi; \u03b8*) is the Hessian matrix of the loss function, representing the second-order derivatives of the loss with the parameters \u03b8*.\nTime-aware data valuation requires measuring how data contributions evolve throughout the training process. Formally, let Vt : D \u00d7 {Ok}=1 \u2192 R be a valuation function that maps a data point and model parameter trajectory to a real value at training step t.\nDefinition 4 (Step-wise Data Value). The step-wise value of data point i is\n\nv = { ||\u22060t|| - ||u||, if i \u2208 Bt 0, otherwise,\n\nwhere Oref is the reference point at step t.\nDefinition 5 (Cumulative Data Value). The cumulative value of data point i up to step T captures the aggregated impact throughout training as:\n\nv [0,T] = \u2211t=1 T v."}, {"title": "III. BASIC METHOD WITH A STATIC REFERENCE POINT", "content": "Traditional data valuation methods rely on loss computations, which face several limitations: 1) they are sensitive to the choice of loss function and optimization landscape, 2) they require model convergence or retraining to get reliable estimates, and 3) they cannot effectively capture a data point's impact on the overall optimization trajectory. To address these challenges, we propose to directly measure data contributions in parameter space.\nOur key insight is that the final model parameters represent the desired destination of the optimization process, and measuring how each gradient update reduces the distance to this target state provides a more direct and robust way to quantify data contributions. This parameter-space perspective enables continuous monitoring of contributions during training without requiring model convergence or retraining and naturally captures how each data point guides optimization.\nBased on this insight, we first propose a basic method using the final model parameters as a static reference point, which is extended to LiveVal with adaptive reference points in Section IV."}, {"title": "A. Model Training", "content": "(3)\n(4)\n(5)"}, {"title": "B. Basic Valuation", "content": "The training phase follows the standard SGD optimization procedure while maintaining essential information for subsequent valuation. At each iteration t, the model parameters are updated according to:\n\nOt = Ot-1 - \u03b7t 1/|Bt| \u2211i\u2208Bt VoL(f(xi; Ot\u22121), Yi).\n\nTo enable subsequent data valuation, key intermediate parameters are stored, including Ot-1, \u03b7t, and Bt. Algorithm 1 describes the training phase of the basic method.\nThe valuation phase quantifies individual data contributions by measuring how effectively each gradient update moves the model toward the optimal state.\nFor each data point i in mini-batch Bt, we first compute the optimal direction toward the final model parameter:\n\n\u22060t = 0* - Ot\u22121,\n\nwhich represents the ideal optimization path.\nWe then evaluate the data point's contribution through a hypothetical state u that measures the remaining distance to 0* after applying only data point i's gradient:\n\nu = 0* \u2212 (0t\u22121 \u2013 \u03b7t\u2207oL(f(xi; Ot\u22121), Yi)).\n\nAs shown in Figure 1, ||u|| captures how effectively the gradient moves toward 0*. A smaller ||u|| indicates better alignment with the optimal direction, while larger values suggest the update deviates from the desired trajectory.\nThe step-wise value is then computed with normalization to ensure fair comparison across training stages:\n\nv = (||\u22060t|| - ||u||)/(||\u22060t|| + ||u||).\n\nThe numerator ||\u22060t|| - ||u|| measures improvement toward the reference point. A positive value indicates the data point"}, {"title": "IV. LIVEVAL WITH ADAPTIVE REFERENCE POINTS", "content": "(6)\n(7)\n(8)\n(9)"}, {"title": "A. Overview and Motivation", "content": "helps guide the model toward the reference point, while a negative value suggests it pushes the model away. The denominator ||\u22060t|| + ||u|| normalizes values to ensure fair comparison across training stages. Without this normalization, data points used later in training would be unfairly penalized due to naturally decreasing gradient magnitudes. The detailed analysis is in Section B.\nFinally, we compute the cumulative value:\n\nv [0,T] = \u2211t=1 T v,\n\nwhere v = 0 if i \u2209 Bt. This aggregation captures the total impact of a data point for the entire training process. The basic time-aware data valuation Algorithm 3 is detailed in Appendix A.\nWhile effective, the basic method has two limitations: high storage overhead from storing all intermediate parameters and the inability to provide real-time valuations. LiveVal addresses these challenges through an adaptive reference point mechanism that 1) enables real-time valuation by using near-future states as reference points, 2) reduces memory requirements by maintaining only a sliding window of parameters, and 3) adapts evaluation horizons based on training dynamics.\nAs shown in Figure 2, LiveVal dynamically selects reference points within an adaptive window that expands during rapid learning phases and shrinks near convergence."}, {"title": "B. Adaptive Reference Point Mechanism", "content": "(10)"}, {"title": "C. LiveVal Implementation", "content": "The mechanism consists of two key components: dynamic window adjustment and reference point selection.\n1) Dynamic Window Adjustment: We define a look-ahead window \u03b4t that determines the temporal horizon for the reference point at each step t.\nThe size of the look-ahead window \u03b4t adapts based on the relative rate of loss change. At each step t, we compute:\n\n\u0130 = (Lt' - Lt\u22121)/\u03b4t\u22121,\n\nwhere Lt\u22121 is the loss at step t - 1,\n\nLt\u22121 = 1/|Bt\u22121| \u2211i\u2208Bt\u22121 L(f(xi; Ot\u22121), Yi),\n\nt' = min(t \u2212 1 + \u03b4t\u22121,T) denotes the step of reference point at step t - 1, and\n\nLt' = 1/|Bt'| \u2211i\u2208Bt' L(f(xi; Ot'), Yi).\n\nThe window size adapts according to the loss change rate:\n\n\u03b4\u03b5 = { min(\u03b4t\u22121 + \u2206\u03b4, \u03b4max) if ||\u0130|| > Emax, max(\u03b4t\u22121 \u2013 \u2206\u03b4, \u03b4min) if ||\u0130|| < Emin, \u03b4t\u22121 otherwise,\n\nwhere \u03b4min and \u03b4max bound the look-ahead window size, \u2206\u03b4 controls the adaptation rate, and Emin, Emax are thresholds that trigger adjustments in response to rapid or slow loss changes respectively.\nThe window size is adjusted according to:\n\u2022 ||\u0130|| > &max: During rapid loss decrease, larger windows capture long-term optimization trajectories and avoid misleading measurements from short-term parameter fluctuations.\n\u2022 ||\u0130|| < \u025bmin: During slow loss decrease, may near convergence, smaller windows identify subtle but valuable optimization effects.\n\u2022 \u025bmin \u2264 ||\u0130|| \u2264 &max: During steady progress, the window size balances immediate and long-term contributions.\n2) Adaptive Reference Point Selection: At each step t, LiveVal dynamically selects a reference point Oref based on the current window size:\n\nOtf = { Ot\u22121+\u03b4\u03b5 if t \u2212 1 + \u03b4t < T, \u041e\u0442 otherwise,\n\nwhere T is the total number of training steps and \u03b4t is the adaptive window size.\nThis dynamic selection enables real-time valuation while maintaining memory efficiency by only storing parameters within the active window."}, {"title": "V. THEORETICAL ANALYSIS", "content": "(11)\n(12)\n(13)\n(14)\n(15)"}, {"title": "A. Fundamental Properties", "content": "LiveVal achieves real-time data valuation through a novel dual-queue architecture that maintains bounded memory overhead while enabling continuous value computation. The implementation integrates time-aware valuation principles with dynamically adapted reference points for efficient real-time processing.\nThe core of LiveVal's implementation is a dual-queue system that coordinates real-time valuation with model training. The Model Queue (Qm) maintains model parameters, batch information, learning rates, and loss values within a sliding window [t - dmax, t] where t is the current training step. Rather than storing the complete trajectory requiring O(Td) memory, this design reduces storage to only the actively needed parameters and associated training information. The Reference Queue (Qref) complements this by tracking (teval, tref) pairs that map evaluation time points to their corresponding reference states.\nValue computation in LiveVal extends the basic method through dynamic reference points. At each step, it replaces the static reference point \u03b8* with adaptively selected Oref to compute:\n\n\u2206\u03b8t = Oref \u2212 Ot\u22121\n\nu = Oref \u2212 (Ot\u22121 \u2013 \u03b7t\u2207oL(f(xi; Ot\u22121), Yi))\n\nv = (||\u22060t|| - ||u||)/(||\u22060t|| + ||u||),"}, {"title": "B. Stability Analysis", "content": "We first establish that LiveVal's valuations meaningfully reflect data contributions through two core properties.\nTheorem 1 (Fundamental Properties of LiveVal). For any data point i and iteration t, the step-wise data value vt of LiveVal satisfies:"}, {"title": "VI. EXPERIMENTS", "content": "(16)\n(17)\n(18)"}, {"title": "C. Early Detection Capability", "content": "We further show that LiveVal's valuations maintain stability during training through bounded volatility.\nTheorem 2 (Local Volatility Bound). Suppose that for all model parameters \u03b8 and data points i, the gradient norms are bounded by ||\u2207oL(f(xi; \u03b8), Yi) || < G, and the distance to the reference point satisfies ||\u22060t|| \u2265 Dmin > 0. Then, for any data point i at training step t, the volatility of the step-wise data valuation vis bounded by:\n\n\u03c3[t] \u2264 2\u03b7tG /||\u22060t||,\n\nwhere \u03b7t is the learning rate at step t."}, {"title": "VII. RELATED WORK", "content": "We evaluate LiveVal in three aspects: accuracy and efficiency in identifying valuable samples compared to baselines (Section VI-B, and VI-C), robustness across different data qualities and modalities (Section VI-D and VI-E), and scalability to large-scale models (Section VI-F).\n(19)"}, {"title": "VIII. CONCLUSION", "content": "A unique advantage of LiveVal is its ability to perform detection during training. Using the same label corruption experiments described above, we analyze LiveVal's detection performance across training epochs.\nFigure 3 demonstrates LiveVal's strong early detection capability. For the most challenging scenario (k=40), LiveVal identifies 27.5% of corrupted samples within the first epoch and achieves 72.5% detection rate by epoch 3. This early detection capability, combined with the stable performance"}, {"title": "A. Experimental Setup", "content": "Data valuation methods aim to quantify the contribution of individual training samples to model performance. Leave-One-Out (LOO) methods [16], [17] directly measure contributions by training separate models with and without target samples. However, this approach faces prohibitive computational costs for large datasets and inherent instability from training randomness [18]. Game-theoretic approaches like Shapley values [19], [20] extend LOO by measuring marginal contributions across all possible subset combinations. While theoretically sound, these methods require evaluating exponential subset combinations, making them impractical for large-scale learning [1], [8], [9]. Recent work [3], [21] further reveals that both LOO and Shapley methods suffer from inconsistent rankings due to retraining randomness. Although approximation techniques [2], [22] reduce computational overhead, they still require extensive subset evaluations.\nLocal update methods [14], [15], [23] use training gradients for efficient estimation but struggle with training order bias, as early samples receive disproportionate importance due to varying gradient magnitudes across training stages. While cosine similarity methods [24], [25] measure gradient alignments with overall training direction, they fail to capture long-term effects. LiveVal overcomes these limitations through its adaptive reference point mechanism, enabling time-aware contribution measurement while maintaining computational efficiency.\nInfluence functions [12] provide theoretical insights but rely on assumptions rarely met in modern deep learning: loss convexity, model optimality, and Hessian computations [13], [26]. Although recent extensions [27]\u2013[29] propose approximations for non-convex scenarios, challenges remain for real-time analysis in deep architectures [26]. In contrast, LiveVal operates effectively without convexity or optimality assumptions, making it suitable for typical deep learning scenarios.\nWe presented LiveVal, a time-aware data valuation framework that enables efficient, real-time assessment of training data quality in large-scale machine learning systems. By transforming valuation from loss computation to parameter space analysis with adaptive reference points, LiveVal overcomes key limitations of existing methods: the computational burden of retraining approaches, the temporal bias of gradient methods, and the restrictive assumptions of influence functions. Our theoretical analysis establishes bounded and stable valuations, while experiments demonstrate LiveVal's ability to identify harmful samples early in training, offering significant computational savings for large-scale applications."}, {"title": "D. Experimental Setup", "content": "a) Datasets and Models: Our evaluation uses datasets spanning different modalities: Adult (tabular), 20 Newsgroups (text), and MNIST (images), tested on DNN, CNN (LeNet-5), and large-scale Inception V3 (24M parameters).\nb) Baselines: We compare against three methods:\n1) Leave-One-Out (LOO): Computes a data point's value by measuring its marginal contribution to model loss:\n\nvLOOi = L(D \\ {i}) \u2013 L(D)\nwhere L(D) is the model's loss on the full dataset and L(D\\ {i}) is the loss after removing point i. LOO requires retraining the model for each data point.\n2) Influence Functions (IF) [12]: Approximates data value through the model's loss change:\n\nvIFi = \u2212VeL(Ztest, \u03b8*)THo\u22121\u2207oL(xi, \u03b8*)\nwhere Ho* is the Hessian matrix at optimal parameters \u03b8*.\n3) GradNd [15]: A real-time method that values data points based on their gradient during training:\n\nvGradNdi = Eo [|| VoL(xi, \u03b8t)||2]\n4) Evaluation Metrics: We evaluate methods through three key dimensions:\n\u2022 Valuation Quality. We measure data valuation accuracy through flipped label detection and feature corruption detection. For flipped label detection, deliberately corrupt k of training samples by randomly changing their labels to incorrect classes. For feature corruption detection, we contaminate features with different Gaussian noise and\n\u2022\n\u2022\n\u2022"}, {"title": "E. Robustness Analysis of Different Modalities", "content": "(20)\n(21)\n(22)"}, {"title": "F. Scaling to Large Models", "content": "Different data modalities present distinct challenges for data valuation due to their inherent structural differences. We evaluate LiveVal's generalizability across text and tabular data modalities.\na) Experimental Design: We evaluate LiveVal on two additional datasets: 20 Newsgroups (text) and Adult (tabular), using a DNN architecture. We deliberately flip k% of labels (k \u2208 {10, 20, 30, 40}) in each dataset. Following our previous evaluation method, for each k, we evaluate detection performance on 100 samples (k flipped plus (100 - k) randomly selected clean samples) and examine how many flipped samples appear in the k lowest-valued samples.\nModern deep learning often employs large architectures where traditional data valuation methods become computationally impractical. We evaluate LiveVal on Inception V3 (48 layers with 24M parameters) to show its scalability.\na) Experimental Design: Following the same label flipping setup from Section VI-B, we flip k labels from digit '1' to '7' where k\u2208 {10, 20, 30, 40} and train the Inception V3 model using the modified MNIST dataset for one epoch. We evaluate randomly selected 100 samples, including k flipped and (100-k) clean samples, and identify the k lowest-valued samples."}, {"title": "1) Directional Alignment:", "content": "Assume that the gradient update from data point i moves the model parameters closer to the reference point Oref. This means:\n\n||Oref \u2212 (Ot\u22121 \u2013 \u03b7t\u2207oL(Ot\u22121; xi, Yi))|| \u2264 ||Oref \u2212 Ot\u22121||.\nUsing our definitions, this is equivalent to:\n\n||u|| \u2264 ||\u22060t||\n\nTherefore, the numerator of vt satisfies:\n\n||\u22060t|| - ||u|| \u2265 0.\nSince both ||\u22060t|| and ||u|| are non-negative, the denominator ||\u22060t|| + ||u|| > 0. Thus:\n\nv = (||\u22060t|| - ||u||)/(||\u22060t|| + ||u||) > 0.\n2) Value Boundedness:\nWe need to show that v \u2264 1 and v \u2265 \u22121 for all i and t. First, since ||u|| \u2265 0, we have:\n\n||\u22060t|| - ||u|| < ||\u22060t|| + ||u||.\nTherefore:\n\nv = (||\u22060t|| - ||u||)/(||\u22060t|| + ||u||) < 1.\nSimilarly, we have:\n\n||u|| - ||\u22060t|| < ||\u22060t|| + ||u||.\nMultiplying both sides by -1, we have:\n\n||\u22060t|| - ||u|| \u2265 \u2212(||\u22060t|| + ||u||).\nTherefore:\n\nv = (||\u22060t|| - ||u||)/(||\u22060t|| + ||u||) > -1.\nCombining both Ineq. (31) and Ineq. (34) bounds:\n\n\u22121 \u2264 v \u2264 1.\nThe Directional Alignment property ensures LiveVal correctly identifies helpful training samples. If a data point's gradient update moves the model closer to the reference point, it receives a non-negative value, reflecting a positive contribution. The Value Boundedness property prevents any single data point from having excessive influence, enhancing the robustness of LiveVal against outliers. Together, they make LiveVal's valuations both meaningful and comparable across different training stages."}, {"title": "C. Stability of LiveVal", "content": "We break the proof into three key steps.\nStep 1: Bound how much a single gradient update can change the parameter distance.\nRecall that in LiveVal, the step-wise data valuation for data point i at step t is computed as:\n\nv = (||\u22060t|| - ||u||)/(||\u22060t|| + ||u||),\n\nwhere\n\u22060 = Oref \u2212 Ot\u22121,\nu = \u22060 + \u03b7tVoL(f(xi; Ot\u22121), Yi).\nThe randomness in v arises from the stochastic nature of \u22060t and VoL(f(xi; Ot\u22121), Yi) due to mini-batch sampling and parameter initialization. To bound \u03c3vt, we first bound the absolute deviation of vt from its expected value.\nUsing the reverse triangle inequality, we have:"}, {"title": "APPENDIX", "content": "That:\n\nSince ||L(f(xi; Ot\u22121), Yi) || \u2264 G by assumption, it follows that:\n\n||||u|| - ||\u22060t|||| \u2264 \u03b7tG.\nStep 2: Show how this parameter change affects the valuation score\nWe use the triangle inequality:\n\n||u|| = ||\u22060t + \u03b7t\u2207oL(f(xi;0t\u22121), Yi) ||\n\u2265 ||\u22060t|| - \u03b7t ||\u2207oL(f(xi; Ot\u22121), Yi) ||\n\u2265 ||\u22060t|| - \u03b7tG\nThe denominator of vt can be bounded using the triangle inequality:\n\n||\u22060t|| + ||u|| \u2265 ||\u22060t|| + (||\u22060t|| \u2013 \u03b7tG) = 2||\u22060t|| \u2013 \u03b7tG.\nAssuming that \u03b7tG \u2264 ||\u22060t||, which holds when the learning rate is sufficiently small or ||\u22060t|| is sufficiently large, we have:\n\n2||\u22060t|| - NG > ||\u22060t||.\nBy combining Ineq. (43), Ineq. (47) and Ineq. (47), the absolute value of v can be bounded as:\n\n||v|| < \u03b7tG/||\u22060t||, \n\u03b7tG/2||\u22060t|| - \u03b7tG,\nStep 3: Bound the overall volatility.\nBecause\n\nVar(v) = E [(v - E[v])]\n= E [(v)\u00b2] \u2013 (\u0395[v])\u00b2 \u2264 E [(v)\u00b2].\nThe variance of vi is then bounded by:\n\n\u03c3vt = \u221aVar() \u2264 \u221aE [(v)2] \u2264\n\u03b7tG/||\u22060t||\nTo make the bound more explicit, we consider the worst-case scenario where ||\u22060t|| attains its minimum value Dmin. Thus,\n(23)\n\u2022\n(24)\n(25)"}, {"title": "D. Experimental Setup", "content": "(42)\n(43)\n(44)\n(45)\n(46)\n(47)\n(48)\n(49)\n(50)\n(51)\n(52)"}]}