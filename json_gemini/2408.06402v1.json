{"title": "PHAGO: PROTEIN FUNCTION ANNOTATION FOR BACTERIOPHAGES BY INTEGRATING THE GENOMIC CONTEXT", "authors": ["Jiaojiao Guan", "Cheng Peng", "Xubo Tang", "Yongxin Ji", "Wei Zou", "Jiayu Shang", "Yanni Sun"], "abstract": "Bacteriophages are viruses that target bacteria, playing a crucial role in microbial ecology. Phage proteins are important in understanding phage biology, such as virus infection, replication, and evolution. Although a large number of new phages have been identified via metagenomic sequencing, many of them have limited protein function annotation. Accurate function annotation of phage proteins presents several challenges, including their inherent diversity and the scarcity of annotated ones. Existing tools have yet to fully leverage the unique properties of phages in annotating protein functions. In this work, we propose a new protein function annotation tool for phages by leveraging the modular genomic structure of phage genomes. By employing embeddings from the latest protein foundation models and Transformer to capture contextual information between proteins in phage genomes, PhaGO surpasses state-of-the-art methods in annotating diverged proteins and proteins with uncommon functions by 6.78% and 13.05% improvement, respectively. PhaGO can annotate proteins lacking homology search results, which is critical for characterizing the rapidly accumulating phage genomes. We demonstrate the utility of PhaGO by identifying 688 potential holins in phages, which exhibit high structural conservation with known holins. The results show the potential of PhaGO to extend our understanding of newly discovered phages.", "sections": [{"title": "1 Introduction", "content": "Bacteriophages (phages) are viruses that can infect bacterial cells. They are highly prevalent and abundant in the biosphere, being found in various environmental matrices, including gastrointestinal tracts of animals, water bodies, and soil [7, 33, 35]. Accumulating studies have demonstrated the important role of phages in microbial communities. For example, phages have been observed to facilitate the horizontal transfer of genes between bacteria, which can influence bacterial adaptation, evolution, and acquisition of new functionalities [12]. In addition, they can modulate the abundance and diversity of bacterial populations by killing their host [9]. Due to the increasing threats posed by antibiotic resistance, phages have gained significant attention as potential alternatives to traditional antibiotics, as they can lyse pathogenic bacteria. [4, 18, 19].\nDespite the significance of phages, the efficacy of their applications heavily relies on prior knowledge of protein functions. Understanding the protein function enables us to identify phage proteins that can target and disrupt essential bacterial processes, offering the potential for the development of targeted antimicrobial therapies [26]. For example, holin proteins, known for their cell-killing capabilities and broad host range, have gained significant attention for their potential applications in bacterial control. [25, 27]. To accelerate the application of phages, it is crucial to figure out the annotation of the proteins in phages.\nGene Ontology (GO) terms are widely used to annotate the phage proteins. They are standardized vocabulary and hierarchical frameworks comprising three key dimensions: biological process (BP), cellular component (CC), and molecular function (MF) [8]. BP encompasses the sequences of events or pathways in which proteins participate, such as cellular signaling or metabolic processes, while CC pertains to the subcellular locations or structures where proteins are localized, such as the nucleus or plasma membrane. The MF aspect centers on the distinct activities and tasks carried out by proteins, such as enzyme catalysis or receptor binding.\nHowever, there are two major challenges to using GO terms to annotate phage protein. First, the number of phage proteins with known GO labels is limited. Until February 27, 2024, the total number of phage proteins from the National Center for Biotechnology Information Reference Sequence Database (NCBI RefSeq) is 541,060, derived from 5, 160 complete genomes. However, only 20.85% percent of proteins have GO labels. This scarcity of labeled proteins results in an insufficient database for comprehensive functional annotation. Second, although phage encodes a small number of proteins compared to their hosts, these proteins exhibit a remarkable degree of functional diversity. For example, among the 1173 phage proteins provided by the UniProtKB database, there are a total of 912 GO terms. This means that on average each GO label contains less than two supporting samples and will bring challenges to computational methods. Moreover, the distribution of these GO terms is imbalanced, with certain terms being more prevalent or specific compared to others. This imbalanced label distribution poses a significant challenge to accurate classification. These obstacles impose great requirements on annotation tools.\nSeveral attempts have been made to analyze and annotate protein functions. They can be categorized into two types: homology-based and deep learning-based methods. The summarized information of the state-of-art methods is listed in Table 1. Homology-based methods, such as DiamondScore [14] and DiamondBlast [14], rely on sequence similarity to infer protein function. These methods assume that proteins with similar sequences share similar functions. However, due to the extensive genetic diversity and rapid evolution of phages, phage proteins may not have a significant sequence similarity when aligned to the reference database.\nIn order to annotate more proteins, most deep-learning methods formulate protein function annotation as a multi-label prediction task, where protein sequences or extracted features are used as the model input, and the predicted GO terms represent outputs. For example, DeepGOPlus utilizes sequence information alone and employs convolutional neural networks (CNN) to scan the protein sequence for motifs [14]. Then, it combines the sequence-based predictions with an alignment-based search. ATGO [37] utilized the ESM-1b [24], a pre-trained large language model, to extract embeddings of protein sequences from the last three layers. Through a triplet network, ATGO learns embeddings that enhance the proximity of proteins with similar functions in the embedding space while promoting greater separation among proteins with different functions. In contrast to numerous methods that disregard the correlations of GO labels, PFresGO [21] integrates the hierarchical inter-relationship of GO using Anc2Vec [10]. A pre-trained large language model called ProtT5 is utilized to extract the protein embedding. Furthermore, PFresGO employs a cross-attention mechanism to effectively capture the connections between local protein residues and GO terms, enhancing the accuracy and specificity of protein annotation. However, the methods described previously overlook the unique properties specific to phage proteins. Thus, there is considerable potential for enhancing the annotation of phage proteins. In our investigation, we have discovered that the order of phage protein functions exhibits a high level of conservation within"}, {"title": "2 Methods and materials", "content": "The proteins in the phage sequences are similar to the words in the natural language. Thus, the phage genomes can be viewed as a language of phage life that exhibits distinct features. One notable observation of these phage languages is that phage proteins within the same genus tend to maintain a consistent arrangement. For instance, Fig. 1 reveals a distinct pattern in the order of proteins within the Salasvirus genus. These characteristics inspire us to reformat the phage genomes into sentences with contextual proteins and predict the annotations based on the surrounding information. In the following section, we will detail how PhaGO leverages the contextual information for phage protein annotation."}, {"title": "2.1 Embedding protein sequences", "content": "Fig. 2 shows the architecture of the PhaGO model. In Fig. 2A, let the number of proteins of a phage genome in the training process be n. The first step is to encode the phage genomes by generating the embedding of the n proteins. To obtain protein embedding, we employ the ESM2 model which is pre-trained on protein sequences sourced from UR50/D. During training, ESM2 selects 15% amino acids for masking and predicts amino acids at the masked position. Based on a third-party benchmark result [20], ESM2-33 has a better performance than the ProtT5 family. Moreover, the performance of the ESM2-33 is comparable with ESM2-36 and ESM2-48, but the latter two models have more parameters, leading to a significant increase in runtime. Specifically, the ESM2-33 model consists of approximately 650 million parameters, while the ESM2-36 and ESM2-48 models contain 3 billion and 15 billion parameters, respectively. Therefore, we chose ESM2-33 to embed the proteins.\nWe define $d_e$ as the dimension of per-residue embedding and impose a maximum limit of 1,024 residues for each protein sequence, which aligns with the default setting of the ESM2 model. By applying the ESM2 embedding to the protein sequences and considering these constraints, we generate an embedding matrix $X_1$ with dimensions of $1,024 \\times d_e$ for each protein shown in Fig. 2B. In the ESM2-33 model, the default value of $d_e$ is 1,280. Subsequently, we pass $X_1$ through a fully connected (FC) layer, resulting in a one-dimensional feature set denoted as $X_2$."}, {"title": "2.2 Learning the relationship of context proteins using Transformer", "content": "As words and sentences in human language derive meaning through their context and relationships with other linguistic elements, proteins can also be better understood by considering their interactions, dependencies, and roles within the genome. Therefore, we annotate the protein functions by considering the context neighbors. This goal is achieved through two steps: preparing the context protein embedding and learning the relationships among proteins within the same genome. The sequential steps are illustrated in Fig. 2C.\nTo obtain the context protein embedding, first, we treat each protein as a token and contigs can be seen as sentences composed of multiple tokens. Then, we combine the embeddings of each protein into a single embedding with dimensions of $n \\times d_e$. This integration process takes into account the order in which the proteins appear in the contigs and allows us to preserve the contextual relationships among the proteins within the same genomic context.\nTo incorporate positional information, we utilize position embedding. The position embedding component takes the index of each protein as its input and generates an embedding vector that encodes the relative position of the token within the sequence. This allows the model to understand the relative distance of the proteins. The final output $X_3$ of the embedding layer is obtained by summing the context protein embedding and position embedding results, resulting in a comprehensive representation of each protein in the sequence.\nAfter embedding the context proteins into an $n \\times d_e$ matrix, we introduce a crucial component in our architecture: the self-attention layer. This layer plays a vital role in learning intricate connections between proteins. To perform self-attention computations in Eqn. 1, we transform the input matrix into three separate matrices: Query (Q), Key (K), and Value (V) through three independent FC layers. The $n \\times n$ attention matrix is computed by multiplying the Q and K, representing the strength of protein associations. To prevent excessive values, we scale the attention matrix by dividing it by the square root of the dimension of matrix K (denoted as $\\sqrt{d_k}$). Next, we normalize the attention matrix using the softmax function, assigning weights to protein pairs to indicate their relative importance. Finally, we score the proteins in the sequence by multiplying the V with the weight matrix.\nIn order to collectively focus on information stemming from diverse representation subspaces, we employ a multi-head mechanism in Eqn. 2, where each head represents a separate self-attention layer. Computation is performed in parallel across all heads, and then the concatenated head is input into an FC layer shown in Eqn. 3, $W^M \\in \\mathbb{R}^{1280\\times1280}$. Following the multi-head attention block, the resulting output $X_4$ is subsequently passed through a feed-forward layer.\n$\\text{Attention } (Q, K, V) = \\text{softmax} (\\frac{QK^T}{\\sqrt{d_k}}) V$\n$\\text{head}_i = \\text{Attention } (Q_i, K_i, V_i)$,\n$X_4 = FC(\\text{Contact } (\\text{head}_1, ..., \\text{head}_n), W^M)$,"}, {"title": "2.3 Predicting the GO terms", "content": "We formulate the protein function annotation task as a multi-label binary classification task. The goal is to assign a probability to each GO term, indicating the likelihood of the protein being associated with that specific function. The results of the feed-forward layer $X_5$ are input into a fully connected layer with the sigmoid activation function and the output is an m-dimensional vector, where m represents the number of GO terms shown in Eqn. 4.\n$Y = \\text{sigmoid} (W \\cdot X_5 + b)$.\nDuring training, the model is optimized by minimizing the binary cross-entropy loss. This loss function in Eqn. 5 is commonly used in binary classification tasks to measure the difference between predicted probabilities and actual labels. In addition, we train three GO prediction models on BP, CC, and MF separately.\n$\\mathcal{L} = \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{GO} Y_{ij} \\log(\\hat{Y}_{ij})$"}, {"title": "2.4 Integrating PhaGO with alignment-based method", "content": "Considering that proteins with significant alignment usually have high-precision GO prediction results[6, 14], we introduce a hybrid mode named PhaGO+ by incorporating DiamondScore into the PhaGO to enhance the predictive capabilities for phage protein annotations.\n$S_{\\text{PhaGO+}}(i) = \\beta \\cdot S_{\\text{PhaGO}}(i) + (1 - \\beta)S_{\\text{DiamondScore}}(i)$\nwhere $S_{\\text{PhaGO+}}(i)$ is the confidence score of PhaGO+ for protein i, $S_{\\text{PhaGO}}(i)$ and $S_{\\text{DiamondScore}}(i)$ are confidence scores of PhaGO and DiamondScore. The values of the weight parameter $\\beta$ are fine-tuned based on the validation dataset.\nQuisque ullamcorper placerat ipsum. Cras nibh. Morbi vel justo vitae lacus tincidunt ultrices. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. In hac habitasse platea dictumst. Integer tempus convallis augue. Etiam facilisis. Nunc elementum fermentum wisi. Aenean placerat. Ut imperdiet, enim sed gravida sollicitudin, felis odio placerat quam, ac pulvinar elit purus eget enim. Nunc vitae tortor. Proin tempus nibh sit amet nisl. Vivamus quis tortor vitae risus porta vehicula. See Section 2."}, {"title": "3 Results", "content": "We evaluate the performance of PhaGO following previous work. Specifically, we present two sets of metrics, corresponding to the prediction accuracy of protein-centric and GO term-centric evaluation, which are used in the Critical Assessment of Functional Annotation (CAFA) competitions. The protein-centric evaluation focuses on determining the function prediction accuracy, whereas the term-centric evaluation aims to examine whether the model can correctly identify proteins associated with a particular functional term [22]. The latter can provide the performance of different function terms.\nFirst, we introduce protein-centric metrics. Let $P_i(t)$ be the set of GO terms for a protein i returned by the model under the score cutoff t, while $T_i$ represents the true GO term set for protein i. Then recall and precision for each protein i with threshold t are calculated in Eqn. 7 and Eqn. 8. To calculate the average recall and precision on all proteins, we define n as the total number of proteins and $n_t$ as the number of proteins that have at least one predicted GO term when the threshold is t. The equations are shown in Eqn. 9 and Eqn. 10, respectively. We record the F1-score calculated for each threshold t, ranging from 0 to 1, and obtain the maximum F1-score as $F_{\\text{max}}$ shown in Eqn. 11. To compute the Area Under the Precision-Recall Curve (AUPR), the prediction scores of proteins are concatenated and input into the scikit-learn Python package.\n$\\text{recall}_i(t) = \\frac{|P_i(t) \\cap T_i|}{|T_i|}$\n$\\text{pre}_i(t) = \\frac{|P_i(t) \\cap T_i|}{|P_i(t)|}$\n$\\text{Avg Recall}(t) = \\frac{1}{n} \\sum_{i=1}^{n} \\text{recall}_i(t)$\n$\\text{AvgPre}(t) = \\frac{1}{n_t} \\sum_{i=1}^{n(t)} \\text{pre}_i(t)$\n$F_{\\text{max}} = \\max_{t} {\\frac{2 \\cdot \\text{AvgPre}(t) \\cdot \\text{AvgRecall}(t)}{\\text{AvgPre}(t) + \\text{AvgRecall}(t)} }$\nThen, we present the term-centric evaluation. To calculate the term-centric $F_{\\text{max}}$, we follow a three-step process. First, we calculate the precision and recall for GO term l under threshold t, as defined in Eqn. 12 and 13. In the second step, we calculate $F_{\\text{max}}(l)$, which is the maximum F1-score for label l under different score cutoffs (Eqn. 14). Finally, we"}, {"title": "3.2 Dataset", "content": "We downloaded the reference genomes and proteins under the Caudoviricetes class from the NCBI RefSeq database. Due to the lack of GO terms in the Refseq database, we mapped the protein accessions into UniProt database [1] using the 'ID mapping' tool and retrieved annotations.\nTo ensure an adequate number of labeled proteins for training, we labeled the proteins with no GO terms using the Prokaryotic Virus Remote Homologous Groups (PHROG) database [29] based on HHsuite tool [28]. The database contains 38,880 PHROGs, which encompass a total of 868,340 proteins derived from complete genomes of viruses infecting bacteria or archaea. Moreover, we saved the hits that demonstrated a probability of the template being homologous to query sequences exceeding 80%, ensuring the reliability and high confidence of the matches between the phage proteins and the entries in the PHROG database. Although we used the pairwise alignment to extend the dataset, the proteins with significant alignments were only 15.51%. The remained 63.64% proteins still lacked annotations, which further demonstrated the necessity and importance of developing an effective phage protein annotation tool.\nBecause of the requirement for rich contextual information for proteins, we selectively focused on proteins from genera with high annotation rates. The annotation rate for each genome is calculated below.\n$\\text{Annotation Rate} = \\frac{\\text{#proteins with annotation}}{\\text{#total proteins}}$\nThen, we computed the average annotation rate of the complete genomes in each genus. Proteins from genera where the annotation rates exceeded 30% for the BP and MF categories and 20% for the CC category are included. It was important to note that the number of proteins annotated by CC terms was relatively smaller compared to BP and MF. Therefore, we set a lower threshold for CC to ensure including more genera. By setting these thresholds, we aimed to focus on genera with more comprehensive annotation information. The annotation rates for all genera can be found in the Supplementary material."}, {"title": "3.3 PhaGO outperforms the state-of-the-art predictors", "content": "In this experiment, we compared PhaGO with four tools: DiamondScore[14], DeepGOCNN[14], DeepGOPlus[14], and PFresGO[21]. These tools are the most widely used pipelines for general protein function annotation and have been demonstrated as state-of-the-art predictors. The same training dataset was utilized for retaining the learning-based methods (DeePGOCNN, DeepGOPlus, and PFresGO) or constructing the database for the alignment-based methods (DiamondScore). The performance evaluation was then carried out using the same test dataset, which ensured a fair and comparable assessment for all methods.\nThe performance based on term-centric is presented in Table. 2, while the results obtained from protein-centric evaluation can be found in Supplementary Table 3. PhaGO+ outperforms the second-best method, regarding both AUPR and $F_{\\text{max}}$ scores with notable improvements across all three categories. Specifically, the improvements of 9.94%, 6.50%, and 10.67% in AUPR and 6.49%, 4.67%, and 6.65% in $F_{\\text{max}}$ scores for BP, CC, and MF, respectively.\nComparing PhaGOBASE and PhaGOLARGE, the results reveal that using a larger protein foundation model has a better performance because of the larger foundation model's ability to capture and learn more intricate biological signals. The most significant improvement is observed in the MF category, with a notable increase of 7.57% in AUPR and 4.69% in $F_{\\text{max}}$.\nAdditionally, integrating DiamondScore with PhaGO through hybrid approaches can further improve the performance in protein function prediction. Comparing PhaGO and PhaGO+, the BP category exhibits a highest improvement of 6.49% and 4.49% in AUPR and $F_{\\text{max}}$ for PhaGOBASE and 2.54% and 2.26% in AUPR and $F_{\\text{max}}$ for PhaGOLARGE+\nTaken together, utilizing a deeper foundation model and integrating homologous search methods can help PhaGO achieve the best performance in protein function prediction. In addition, based on the performance, PhaGOBASE and PhaGOLARGE are recommended for users. However, in scenarios where computational resources are constrained, PhaGOBASE is the preferable choice."}, {"title": "3.4 PhaGO improves annotation of proteins by utilizing the contextual information", "content": "In this section, we designed two experiments to evaluate how contextual proteins impact function prediction. In the first experiment, we compare two different usages of the protein embeddings from the foundation model: 1) using the"}, {"title": "3.5 PhaGO shows superior performance in annotating remote homologous proteins", "content": "In this section, we evaluate PhaGO's predictive capability with different levels of sequence identity. The test dataset was partitioned into three distinct groups based on alignment with the training data: 'no-alignment' for proteins lacking alignment, 'min-40%' for those below 40% identity, and \u201840%-100%' for proteins with 40-100% identity. These categories represent proteins with no similarity, low similarity, and moderate to high similarity to the training set, respectively. As shown in Fig. 5(b), the AUPR of all methods improved with increased sequence identity for all three GO categories. For the high-similarity dataset, the alignment-based method exhibits excellent performance, and PhaGO+ demonstrates comparable results in three ontologies. It suggests that both methods can effectively predict protein functions when the dataset aligns well with the training dataset. However, for the dataset that has no alignment with the training dataset, PhaGO+ stands out with impressive AUPR. Specifically, PhaGO+ achieves AUPR values of 0.7524, 0.8478, and 0.8210 for the BP, CC, and MF. These values represent improvements of 5.68%, 6.78%, and 5.75% compared to the performance of the second-best method. The term-centric results are shown with a similar trend in supplementary Fig. 1(a). Additionally, the percentage of no-alignment proteins accounts for 27.93%, 55.70%, and 27.62% of the test dataset for BP, CC, and MF, respectively. These results highlight the robustness and effectiveness of PhaGO+ in predicting protein functions, especially for low-similarity proteins.\nWe continue to analyze the impact of contextual protein information on different level-similarity groups. The results are shown in the Supplementary Fig. 1(b). Focusing on the no-alignments dataset, both PhaGOBASE and PhaGOLARGE demonstrate improvements compared to their respective counterparts. On one hand, PhaGOBASE shows performance gains of 10.18%, 6.5%, and 1.11% for BP, CC, and MF categories, respectively. On the other hand, PhaGOLARGE exhibits improvements of 5.33%, 3.87%, and 7.91% for BP, CC, and MF categories, respectively."}, {"title": "3.6 PhaGO enhances annotation with focus on minority class GO terms", "content": "To examine the ability of PhaGO on the GO terms of different popularities, we split GO terms into three groups based on the information content (IC) of GO shown in Eqn. 17. f (l) is the frequency of the GO term l in the training dataset. Higher IC values mean fewer proteins annotated by the GO term labels.\n$IC (l) = - \\log_2 f (l)$.\nThe experiment results in Fig. 5(b) demonstrate that all methods consistently performed well in the majority labels of GO terms. However, PhaGO+ demonstrates a distinct advantage in predicting minority GO terms, surpassing the other methods and achieving the highest performance across all three ontologies. Specifically, PhaGO+ achieves medium AUPR of 0.8801, 0.9043, and 0.8105 for BP, CC, and MF in the smallest GO terms group, respectively. This indicates that even for infrequently occurring GO terms, PhaGO+ can make an accurate prediction.\nWe also further investigate the impact of the context proteins on the different GO terms. The results are shown in Supplementary Fig. 1(c). Focusing on the smallest GO terms group, both PhaGOBASE and PhaGOLARGE demonstrate improvements in performance. For the BP and CC ontologies, PhaGOBASE shows performance gains of 4.5% and 3.55% in AUPR, respectively. Moreover, it achieves comparable results for MF. In addition, PhaGOLARGE exhibits improvements of 3.71%, 2.29%, and 2.80% for BP, CC, and MF categories, respectively. These results highlight the benefits of incorporating context proteins in predicting fewer GO terms."}, {"title": "3.7 PhaGO enables protein function annotation without relying on homology search", "content": "To showcase the utility of PhaGO in annotating proteins that lack homology search results, we explore its application in the analysis of phage's holin proteins. The holin protein is a small membrane protein that plays a crucial role in lysing bacterial hosts by triggering the formation of pores that disrupt the host cell membrane [23]. It controls the release of phages and the completion of the lytic cycle, underscoring the significance of the intricate interplay between phages and their host organisms. However, according to the protein annotation of phages in the RefSeq database, over 448 genera have no annotated holin proteins, indicating that holin proteins may be very diverse across different phages. In this experiment, we apply PhaGO to annotate possible holin proteins.\nAccording to statistical analysis of GO terms for the well-studied holin proteins from UniproKB, we manually selected six GO terms as their indicator. The details of selecting GO terms are shown in the Supplementary file. We input all proteins from 448 genera into PhaGO+ and identified 688 potential holin proteins spanning 262 genera. After identifying possible holins, we clustered them to analyze their relationship. To accomplish this, we aligned them all against all and selected alignment with identity and coverage larger than 90. Gephi was used to represent the relationships among proteins visually. The results depicting the top 10 phage genera in Fig. 6(a). The genera of phage are from the RefSeq annotations. An evident observation is the high conservation of holin proteins within the same genus, mirroring a common pattern observed among known holin proteins in phage genomes.\nIn addition, we aligned them with the known holin proteins using BLASTP [3] with e-value 1e-5. 590 proteins have no alignment, indicating the high diversity of holin proteins. Then, we searched the annotation of 688 proteins from the UniProtKB database. Out of these, 335 proteins are recommended for annotation as holin, 171 proteins are labeled as uncharacterized proteins, and 87 proteins are categorized as membrane proteins. These top three annotations collectively account for 86.2% of the total proteins.\nTo further examine the identified holin proteins without alignment, we employed ESMFold [16] to predict their three-dimensional (3D) structures, which are very fast and can get comparable predictions with AlphaFold [13]. We found that despite having low sequence similarity, 590 identified holin proteins exhibit structural homology with the known holin proteins. The result is shown in 6(b). The TM-score and the Root Mean Square Deviation (RMSD) value are calculated by the TM-align tool [36]. Fig. 6(c) and (d) are visualizations of the two putative holin proteins identified by our tool. In conclusion, the experiments provide further evidence of the great potential of PhaGO as a valuable tool for viral protein annotation. In addition, the information and 3D structure of the 688 holins are available in the Supplementary data."}, {"title": "4 Conclusion and Discussion", "content": "In this work, we proposed a method named PhaGO/PhaGO+ for protein function annotation of phages. The major improvement in our approach can be attributed to utilizing the properties of phages and the foundation model. The Transformer model is used to learn the relationship of the genomic context proteins. Our experiments compared four"}, {"title": "5 Data availability", "content": "PhaGO is implemented in Python, which can be downloaded from https://github.com/jiaojiaoguan/PhaGO."}, {"title": "6 SUPPLEMENTARY DATA", "content": "Supplementary Data are available at NAR Online."}, {"title": "7 Competing interests", "content": "No competing interest is declared."}]}