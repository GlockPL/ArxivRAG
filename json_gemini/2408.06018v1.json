{"title": "Uncertainty-Informed Volume Visualization using Implicit Neural Representation", "authors": ["Shanu Saklani", "Chitwan Goel", "Shrey Bansal", "Zhe Wang", "Soumya Dutta", "Tushar M. Athawale", "David Pugmire", "Christopher R. Johnson"], "abstract": "The increasing adoption of Deep Neural Networks (DNNs) has led to their application in many challenging scientific visualization tasks. While advanced DNNs offer impressive generalization capabilities, understanding factors such as model prediction quality, robustness, and uncertainty is crucial. These insights can enable domain scientists to make informed decisions about their data. However, DNNs inherently lack ability to estimate prediction uncertainty, necessitating new research to construct robust uncertainty-aware visualization techniques tailored for various visualization tasks. In this work, we propose uncertainty-aware implicit neural representations to model scalar field data sets effectively and comprehensively study the efficacy and benefits of estimated uncertainty information for volume visualization tasks. We evaluate the effectiveness of two principled deep uncertainty estimation techniques: (1) Deep Ensemble and (2) Monte Carlo Dropout (MC-Dropout). These techniques enable uncertainty-informed volume visualization in scalar field data sets. Our extensive exploration across multiple data sets demonstrates that uncertainty-aware models produce informative volume visualization results. Moreover, integrating prediction uncertainty enhances the trustworthiness of our DNN model, making it suitable for robustly analyzing and visualizing real-world scientific volumetric data sets.", "sections": [{"title": "1 INTRODUCTION", "content": "The scientific visualization community has witnessed myriad applications of deep learning owing to the rapid growth of deep neural network (DNN) research [57]. Among many applications, analysis, visualization, and representation of volumetric data using DNNs have emerged as a promising research domain. DNNs have been used effectively to (1) synthesize volume rendered images given rendering and view parameters [6], (2) generate high-quality super-resolution images [11], (3) perform interactive volume visualization [28], (4) build differentiable rendering models to perform automatic viewpoint and transfer function optimization [62], (5) learn adaptive volume sampling strategies to produce accurate images [61], and (6) learn compressed volume representations [36, 60]. While the above DNN-based approaches facilitate multifaceted exploration of volumetric data, none of the approaches study the impact of prediction uncertainty associated with such models. Model prediction uncertainty, if reliably estimated and communicated to the domain experts, can enable them to make informed decisions about the data during analysis phase [8, 14]. As a consequence, the DNN-based volume visualization and analysis methods will become more trustworthy and reliable. However, a literature survey reveals that epistemic uncertainty-aware DNN-based volume visualization needs detailed exploration - a gap that this work attempts to fill.\nGiven the recent success of implicit neural representations (INRs) for compact modeling and representing volumetric data sets [21, 36, 54], in this work, we study the efficacy and applicability of uncertainty-aware INRs for volume visualization task. Since traditional DNNs do not quantify their prediction uncertainty, we augment our INRs with two different deep uncertainty quantification techniques to collect uncertainty estimates along with the predicted data values. We thoroughly analyze and visualize the estimated uncertainty to comprehend model accuracy, trustworthiness, and reliability.\nGiven the existing deep uncertainty estimation techniques, in this work, we prefer the methods of uncertainty estimation that can be incorporated into an existing DNN with minimal architecture modification so that the visualization community can readily adopt such models to conduct uncertainty-aware volume visualization using DNNs. To that end, we employ Deep Ensembles as our first uncertainty estimation method since Deep Ensembles often outperform other uncertainty estimation methods and produce more accurate predictions [5, 18, 29]. However, the benefits of Deep Ensembles come at the cost of significantly large training time and resource requirements since multiple DNN models need to be trained to produce an ensemble of DNNs. To mitigate this challenge, we study the accuracy and viability of a single-model-based deep uncertainty estimation technique known as Monte Carlo Dropout (MC-Dropout) [14]. Theoretically, the MCDropout is equivalent to approximate inferencing in deep Gaussian processes [10, 14], making it an attractive choice for our work.\nWe analyze the accuracy, effectiveness, and benefits of uncertainty-aware implicit neural representations (INRs) of volume data augmented with two deep uncertainty estimation techniques: (1) Deep Ensemble and (2) MCDropout method to carry out informative visual analysis of scientific data. Since our methods provide model uncertainty for predicted data values, we are able to quantify fine-grained pixel-wise uncertainty for the volume-rendered images for any user-provided transfer function. As the user changes the transfer function, our pixel-wise uncertainty map also gets updated according to the current transfer function configuration. We can further investigate how uncertainty impacts each color channel while computing the final pixel color using the ray casting method."}, {"title": "2 BACKGROUND AND UNCERTAINTY IN DEEP NEURAL NETWORKS", "content": "First we summarize research works related to deep learning for scientific visualization and uncertainty visualization in the following section. Then, we briefly introduce different methods for quantifying uncertainty in deep neural networks, followed by a detailed description of two well-known methods of estimating uncertainty in DNNs used in this work."}, {"title": "2.1 Deep Learning for Scientific Visualization", "content": "Deep learning has found numerous applications in scientific visualization. Techniques for generating compact neural representations of scientific data are proposed by Lu et al. [36] and Weiss et al. [60]. Hong et al. [28], He et al. [26], and Berger et al. [6] study the visualization of scalar field data using volume-rendered images, and Weiss et al. [59] study volume data with isosurfaces. An adaptive sampling-guided approach is further used by Weiss et al. [61] for efficient volume data visualization using DNNs. Another prominent area of research involves generation of spatiotemporal super-resolution volumes from low-resolution data using deep learning methods [20, 19, 64, 22]. For compressing the volume data, new models are proposed for domain-knowledge-aware latent space generation for scalar data [50]. For the generation of visualization and exploration of parameter spaces for ensemble data, DNNs are also used as surrogates [26, 52, 51]. Han et al. [23] propose a variable-to-variable translation technique for scientific data. A comprehensive review of deep learning applications for scientific visualization are available in the state-of-the-art survey [57]."}, {"title": "2.2 Uncertainty Visualization", "content": "Visualization of uncertainty continues to be an important and challenging area. Pang et al. [39] give one of the earlier summaries of uncertainty visualization techniques. Visualization methods that are enhanced with tools for uncertainty estimation are given by Brodlie et al. [13]. Non-parametric models are used by Athawale et al. [3] to improve uncertainty in volume rendering. Spatial probability distributions, defined over triangular meshes, are visualized by Potter et al. [44], preceded by a classification of uncertainty visualization techniques [12].\nUncertainty visualization techniques are also explored for isocontouring methods. The level crossing probability of adjacent points is computed by P\u00f6thkow et al. [42], and to calculate the level crossing probability for each cell, this method is further refined in [43]. In [2], a visual analysis of fiber uncertainty is done. Uncertainty visualization techniques are summed up in a comprehensive survey by Bonneau et al. in [8]. For image processing applications [15] and medical imaging [16], uncertainty visualization techniques are summarized by Gillmann and colleagues. Whitaker et al. [63] use contour boxplots to examine uncertainty visualization in an ensemble of contours. The latest progress regarding uncertainty in visualization research can be found in [30]."}, {"title": "2.3 Uncertainty in Deep Neural Networks", "content": "Despite the widespread popularity of deep learning techniques, there are significant concerns regarding their interpretability, robustness, and generalizability in real-world applications [66]. The inability of conventional DNNs to provide uncertainty estimates can undermine the practical results they offer in fields such as computer vision, natural language processing, scientific visualization, and visual analytics. Developing universal techniques to measure and quantify uncertainty in DNNs remains a challenge, as the types and sources of uncertainty vary greatly across different applications, making it difficult to generalize uncertainty estimation methods. In the following, we succinctly describe some causes of uncertainty in DNNs and various methods proposed to simulate and mitigate them.\nUncertainty in a DNN can be broadly categorized into data (aleatoric) uncertainty and model (epistemic) uncertainty [7, 34]. Data uncertainty arises from errors and noise in measurement systems. In contrast, several factors contribute to model (epistemic) uncertainty. Firstly, current DNN models simplify real-world systems to generate observations, but this simplification introduces errors and uncertainty in predictions. Secondly, many DNNs require careful adjustments, such as implementing dropout [14, 27], experimentally adjusting the model hyperparameters [65], and applying regularization [9]. Variations in these parameter settings can result in different outcomes and associated uncertainty."}, {"title": "2.4 Methods to Model Uncertainty in DNNS", "content": "In the following, we discuss various techniques used for modeling uncertainty in DNNs. Then, we discuss two well-known uncertainty estimation methods, MCDropout and Deep Ensembles in detail since these two methods are employed in our work.\nDeterministic Methods. Uncertainty estimation capabilities can be integrated into deterministic models by training a network explicitly to quantify uncertainties, as discussed in the work on evidential neural networks [49].\nTest-time Augmentation Methods. Data augmentation during testing improves model performance using adversarial examples [4, 58] which determine prediction uncertainty.\nDeep Evidential Regression. In deep evidential regression, the network simultaneously learns both parameters and hyperparameters for the corresponding evidential distributions [1]. These evidential distributions are then utilized to estimate model uncertainty.\nUncertainty via Stochastic Data Centering. In this approach, the authors propose that training an ensemble of DNNs with data sets shifted by a constant bias allows for estimating model uncertainty by assessing the variability across predictions from these ensemble members. They further introduce a method to achieve similar uncertainty estimation using a single DNN [55].\nBayesian Methods. Bayesian neural networks (BNNs) utilize prior distributions on the model parameters of DNNs to quantify epistemic uncertainty [17, 34]. Training these networks typically are computatinally expensive and involves methods such as stochastic gradient MCMC [37] and variational inference [24]."}, {"title": "2.5 Ensemble Method", "content": "Ensemble techniques work on the idea that a group of learners of comparable competence is commonly better than a single learner [47]. Ensemble methods provide an inherent way to measure predictive uncertainty by assessing the differences among various predictions [35, 40], besides just enhancing the generalization error. Therefore, the predictive uncertainty of DNNs can be calculated by taking ensemble methods into account [18, 46]. Deep Ensembles [34] are proposed by Lakshminarayanan et al., where DNNs are designed with two heads that give both the prediction and the associated uncertainty. In essence, Deep Ensemble learning can be equivalent to an approximation of Bayesian averaging [45]. In Bayesian averaging, the prediction of the final model is given as follows:\nprediction =$\\int P_W(x) \\pi(W|D)$\nHere, $P_W(x)$ denotes the probabilistic prediction for sample x, and $\\pi(W|D)$ is the posterior probability distribution on the neural network weights, and D is the training data. In practice, estimation the above integral is very challenging, and exploration of all the modes of $\\pi(W|D)$ is not needed to calculate this integral precisely [45]. This observation suggests that, from a set of ensemble members, averaging predictions without weights can be viewed as an approximation of Equation 1 [45]. It should be noted that randomizing the training data and initializing parameters randomly introduces enough variety in each learned ensemble member to effectively predict the uncertainty during the training process, a technique adopted in this work to generate the Deep Ensemble model. It is worth mentioning that Ensemble techniques often surpass the techniques that depend on probabilistic back-propagation and Monte Carlo dropout [18, 5, 38, 56], and hence Ensemble methods are often regarded as the state-of-the-art. They also show more resilience to changes in data distribution."}, {"title": "2.6 MCDropout Method", "content": "Dropout [14, 27] is primarily used as a regularization technique, which is applied for fine-tuning machine learning models and preventing overfitting by optimizing the adjusted loss function. Gal et al., in their seminal work [14], propose a new viewpoint on how dropout can be efficiently used as a method for approximate Bayesian inference in deep Gaussian processes. By using dropout at test time and running many forward passes with different dropout masks, the model generates a range of predictions rather than a single point estimate and is equivalent to sampling from the Bayesian posterior distribution, P(W | X,Y), where W is the weights of the neural network model, X is training data, and Y is target output. The mean of these sampled predictions acts as the expected output of the model. Then, the epistemic uncertainty of the DNN can be conveniently estimated by calculating the standard deviation among these sampled predictions [52]. By collecting Monte Carlo (MC) samples from the network, which is dropout-enabled, such probabilistic predictions are obtained by running multiple forward passes at the time of inference, which is known as the Monte Carlo Dropout (MCDropout) method."}, {"title": "3 UNCERTAINTY-AWARE IMPLICIT NEURAL REPRESENTATION OF SCALAR FIELD DATA", "content": "3.1 Implicit Neural Representation\nImplicit neural representations (INRs) using periodic activation functions have shown promising results for learning representations of coordinate-based data sets. Input coordinates within the data domain are mapped to their associated output values using such neural networks. By using a sinusoidal activation function in a feedforward neural network, known as SIREN (sinusoidal representation network), INRs can be effectively constructed, as proposed by Sitzmann et al. [53] in their research. Recent works have employed many variations of SIREN to address multiple complex problems in the scientific data visualization community, achieving state-of-the-art results [36, 21, 54, 48]. The achievements of these recent research efforts have inspired us to build our uncertainty-aware model by applying SIRENS as the base neural network architecture.\n3.2 Model Architecture\nOur objective is to learn a function that represents the mapping from the input data coordinate domain to the corresponding scalar value domain using an implicit neural network (INN). We make our base model a multilayer perceptron for this purpose. It has d input neurons (d can be 2 or 3 depending on the dimensionality of the scalar field being modeled), I hidden layers, and 1 neuron in the output layer. As proposed in [25], we strengthen the foundational SIREN architecture by combining residual blocks and skip connections to enhance the model's learning capacity and ensure steady training of the deep network. The input to our model is a d-dimensional coordinate vector, which corresponds to an output scalar value. Therefore, our implicit neural network learns a function $F(\u65e5) : R^d \\rightarrow R$, where \u0398 represents the parameters of the neural network.\n3.3 Uncertainty Quantification Using MCDropout Method\nThe architecture implemented for the MCDropout method is depicted in Fig. 1. At the last two residual blocks, a post-activation dropout layer is added to make our model dropout-enabled. This is done to conveniently calculate the prediction uncertainty during inference for the MCDropout method. Additionally, during training, dropout layers also help with regularization. In principle, a dropout layer should be incorporated for each residual block to approximate a fully Bayesian neural network [31]. However, Kendall et al. [31] show that adding dropout at each residual block or after each hidden layer can act as a strong regularizer, potentially reducing the overall prediction accuracy [31]. They further suggest that incorporating dropout to the last layer or a small subset of layers is sufficient to generate high-quality predictions along with reliable uncertainty estimates. Hence, we use dropout layer only at the last two residual blocks to approximate a partial Bayesian neural network to produce accurate predictions as well as robust uncertainty estimates. The impact of using different number of dropout layers on the model performance has been further studied in Section 5.\nAs discussed previously, inference using the MCDropout method involves generating a set of Monte Carlo samples by performing multiple forward passes of the dropout-enabled trained network. Hence, we generate m instances (realizations) of the scalar field and then calculate the average scalar field, serving as the predicted (expected) scalar field. Typically, the number of samples needed is decided by checking the convergence of the computed expected (averaged) field, meaning that adding more Monte Carlo samples does not improve the reconstruction quality. The uncertainty associated with each grid point is calculated by measuring the standard deviation among the m scalar values. Note that this uncertainty is measured at each grid point in the spatial domain. However, since our focus in this work is to estimate fine-grained uncertainty in the volume rendered images, we further quantify uncertainty in image space using the volume rendering. To estimate the image space pixel-wise uncertainty for enabling uncertainty-aware volume visualization, we compute the uncertainty of the pixel color values after collecting outputs of ray casting algorithm when applied to each individual MC volume realization (100 in our experiments). Details of this pixel-wise uncertainty calculation are provided in Section 4.1.\n3.4 Uncertainty Quantification Using the Ensemble Method\nThe model architecture for the Ensemble model is the same as shown in Fig.1, except no dropout layers are used. Multiple instances of this model are trained to produce a Deep Ensemble model[34]. To create a robust ensemble model, we train n instances of the SIREN model. The variability across each ensemble member is ensured by randomly shuffling the order of data points at each iteration during training. Once training is completed, the averaged prediction from all n member models at each grid point produces the expected volume field. Note that the number of ensemble members needed is decided by checking the convergence of the computed expected (averaged) volume, meaning that adding more ensemble member models does not improve the reconstruction quality. Similar to the MCDropout method, we compute the data space uncertainty associated with each grid point. Subsequently, image space pixel-wise uncertainty for the Ensemble method is then computed following the same strategy as the MCDropout method, and is further discussed in Section 4.1.\n3.5 Loss Function and Hyperparameters\nOur uncertainty-aware SIREN model uses 10 residual blocks for MCDropout and Ensemble methods. We use 50 neurons in each hidden layer to generate consistent and comparable results while producing a compact uncertainty-aware representation of the volume data set. Conventional mean squared error loss ($L_{mse}$) is used to train the network. We use empirical experimentation to identify a suitable learning rate and batch size combination that produces stable, consistent, and high-quality results across all data sets. We utilize a batch size of 2048 with the Adam optimizer [32], setting the learning rate at 0.00005 and the two Adam optimizer coefficients $B_1$ and $B_2$ to their default values at 0.9 and 0.999, respectively. Furthermore, a learning rate decay mechanism is adopted to optimize the training process, with a decay factor of 0.8 and a step size of 15. All the models were trained for 300 epochs to ensure convergence and robustness in performance evaluation. During training, we use a low dropout rate (probability) of n = 0.001 for Hurricane Isabel and Combustion data sets. This training dropout rate results in a poorly performing MCDropout model for the Teardrop data set. Hence, we use a higher dropout rate of \u03b7 = 0.05, which produces a stable MCDropout model for the Teardrop data set. During inference, we use a consistent dropout rate of n = 0.1 for all the data sets to generate robust uncertainty estimates. No dropout is used for training ensemble models. This consistent approach in model design ensures a rigorous assessment of the effectiveness of uncertainty-aware deep neural networks across various data sets."}, {"title": "4 UNCERTAINTY-AWARE VOLUME VISUALIZATION", "content": "We perform a comprehensive study of the uncertainty-aware INRS using four volume data sets. The dimensionality and spatial resolution of these data sets are reported in Table 1. A GPU server with NVIDIA GeForce GTX 1080Ti GPUs with 12GB GPU memory is used for model training and volume reconstruction. The rendering is done on a MacBook Pro with an Apple M1 Pro chip with 10 CPU and 16 GPU cores and 16GB memory. All the models are implemented in PyTorch [41]. Teardrop data set is generated using a mathematical function [33] sampled on a 64 \u00d7 64 \u00d7 64 uniform grid. Hurricane Isabel data was produced by the Weather Research and Forecast model, courtesy of NCAR and the U.S. National Science Foundation (NSF). Turbulent Combustion data set is made available by Dr. Jacqueline Chen at Sandia Laboratory through U.S. Department of Energy's SciDAC Institute for Ultrascale Visualization.\n4.1 Computation of Pixel-wise Prediction Uncertainty for Volume Visualization\nWe use the trained INRs to reconstruct the entire volume to comprehensively assess the model's reconstruction quality, prediction uncertainty, and error. Through empirical experimentation, we observe that 100 MC samples for the MCDropout method and 10 ensemble members for the Ensemble method allow us to produce robust estimates of volume data. A study on how reconstruction quality changes given different numbers of MC samples for the MCDropout method and a different number of ensemble members for the Ensemble method is provided later in Section 5. Thus, unless specified otherwise, we use 100 MC samples for MCDropout and 10 ensemble members for the Ensemble method in all experiments.\nOur goal is to enable visualization and comprehension of fine-grained prediction uncertainty when model-reconstructed scalar data sets are visualized using volume rendering methods for any user-specified transfer functions. As the rendered image depends on transfer functions, the associated uncertainty map should also be updated when the transfer function changes. Both uncertainty estimation methods we use require multiple volume realizations (100 for the MCDropout method and 10 for the Ensemble method) to generate the final volume-rendered image and the associated uncertainty map. We utilize individual volume realizations to estimate the fine-grained pixel-wise uncertainty from the model-predicted results. Given a user-specified transfer function and view direction, our method applies the ray casting algorithm to each volume realization (100 for the MCDropout method and 10 for the Ensemble method) and collects the RGB pixel values for each instance. Then, the final result is obtained by averaging the RGB pixel colors, and the associated uncertainty is estimated by computing the pixel-wise standard deviation. We first estimate each color channel's uncertainty (standard deviation) from the volume rendering results. Then, we compute the final mean pixel uncertainty by averaging the individual color channel uncertainty values. The uncertainty values are then normalized and stored as grayscale images, where darker colors indicate higher uncertainty for the corresponding pixel locations. As the transfer function changes, this process is repeated so that the updated result and corresponding uncertainty map can be generated for visualization.\n4.2 Uncertainty-Informed Volume Visualization\nIn the following, we qualitatively and visually study the volume visualization results and the estimated uncertainty patterns for MCDropout and Ensemble methods using several volume data sets. Then, in Section 5, we provide a quantitative evaluation of volume reconstruction quality and uncertainty estimates for both methods. Next, we further comprehensively evaluate the proposed methods under varying parameter configurations to assess their applicability, usefulness, and implications.\n4.3 Visual Analysis for Teardrop Data\nOur first case study uses the Teardrop data set [33]. To study the volume visualization results obtained from the two uncertainty estimation methods, we generate 100 Monte Carlo sample volume reconstructions for the MCDropout method and 10 sample volume reconstructions for the ensemble method (as 10 ensemble members are used). In Fig. 2, the top row shows volume rendered results of three individual MC sample volumes for the MCDropout method. Similarly, the bottom row depicts visualization generated by three separate ensemble members. We observe that the individual ensemble members renders the thin central segment region (as highlighted by red dotted circles) more accurately than the individual MCDropout sampled fields when compared against the ground truth rendering shown in Fig. 3. All the volume visualization results use fixed transfer functions, viewpoints, and all other rendering parameters to ensure fair comparison.\nNext, in Fig. 3, we show the ground truth rendering, the rendering of the expected (averaged) field constructed using 100 MC sample fields for the MCDropout method and 10 ensemble member reconstructed fields for the Ensemble method, respectively. We observe that the expected field generates accurate and visually similar volume rendering results for both methods. Both MCDropout and Ensemble methods accurately preserve the thin central segment, as red dotted circles show.\nIn Fig.4, we present the pixel-wise prediction uncertainty and error maps for the Teardrop data set using both the MCDropout and Ensemble methods. The uncertainty represents by the pixel-wise standard deviation, averaged over all three color channels. To estimate the pixel-wise standard deviation, we perform ray casting on 100 MC sampled volumes for the MCDropout method and on 10 ensemble member generated volumes for the Ensemble method. The standard deviation for each color channel is computed from the final pixel colors and then averaged to produce the final uncertainty image shown in Fig.4. Darker pixels indicate higher uncertainty. The image is generated by first computing pixel-wise average uncertainty values, then mapping these values to a grayscale colormap where darker colors reflect higher uncertainty. The error maps are computed by estimating the channel-wise absolute error between the ground truth pixel colors and the predicted pixel colors. Then the average error is calculated and mapped to a grayscale colormap where darker colors reflect higher error. All uncertainty and error maps are visually comparable as they are generated using a consistent grayscale colormap. Users can compare error and uncertainty between the two uncertainty-estimation methods by comparing the darkness of the pixel intensities. It is observed that both methods exhibit higher prediction uncertainty as well as higher error at the thin segment of the teardrop, indicating that the model is less confident and more erroneous in predicting values in this region. Additionally, higher uncertainty and error is noted at the boundary of the teardrop structure, where a sharp change in color gradient is observed, further indicating reduced confidence in boundary predictions. The results indicate that the uncertainty and error are largely correlated for this data set.\nPrediction uncertainty maps for each individual color channel are provided in Fig. 5. The top row displays the results for the MCDropout method, while the bottom row shows the channel-wise uncertainty maps for the Ensemble method. We observe that the estimated uncertainty patterns are identical for each color channel, indicating that each color channel incurs comparable uncertainty estimates in similar spatial regions.\n4.4 Visual Analysis for Isabel Pressure Field\nOur next case study utilizes the Pressure field from the Hurricane Isabel data set. Both the MCDropout and Ensemble methods produce highly accurate visualizations when compared to the ground truth, as shown in Fig. 6. A close inspection of the uncertainty map generated by the MCDropout method reveals high uncertainty in the Hurricane eye feature region and moderate pixel uncertainty in the surrounding area. In contrast, the Ensemble method produces a cleaner uncertainty map, with higher uncertainty confined to only a few pixels in the land region (bottom right corner). These uncertainty maps indicate that the Ensemble method yields more robust predictions with high confidence, resulting in more reliable volume visualization images compared to the MCDropout method. When the two error maps from the two methods are investigated, it is observed that the error and uncertainty maps convey different information about the models and the MCDropout method produces fewer pixels with higher errors.\nIn Fig. 7, we present the channel-wise uncertainty maps for the Isabel Pressure field using both the MCDropout (top row) and Ensemble (bottom row) methods. It is observed that the Hurricane eye region exhibits high prediction uncertainty across all three color channels for the MCDropout method, with moderate uncertainty in the rest of the spatial domain. This indicates that model prediction uncertainty can affect individual color channels differently, and displaying channel-wise uncertainty maps allows for a detailed investigation of the impact of uncertainty on each color channel separately. For the Ensemble method, the overall uncertainty for all three color channels is much lower, with minimal variation in the uncertainty patterns among them.\n4.5 Visual Analysis for Isabel Velocity Magnitude Field\nFig. 8 illustrates uncertainty-aware volume visualization results for the Velocity Magnitude field of the Hurricane Isabel data set. As with the Pressure field, both the MCDropout and Ensemble methods produce accurate volume visualizations. The uncertainty maps reveal a similar pattern: the MCDropout method shows moderate uncertainty over a broader area around the Hurricane eye feature, while the Ensemble method exhibits higher uncertainty concentrated around the eye wall of the Hurricane. The error maps from both methods display similar error patterns, with higher prediction errors concentrated around the Hurricane eye. Examining the uncertainty and error maps of the Ensemble method reveals that, while it predicts the regions around the Hurricane eye with greater confidence, it can still make errors in these areas. This indicates instances where the model is making overconfident predictions.\n4.6 Visual Analysis for Combustion Mixfrac Field\nFinally, we present the visualization results for the Mixture Fraction (Mixfrac) field of the Turbulent Combustion data set in Fig. 9. Both methods produce visually identical volume rendering results for the Mixfrac field when compared to the ground truth. However, a comparison of the two uncertainty maps, generated by the MCDropout and Ensemble methods, reveals that the MCDropout method produces a smoother uncertainty map, while the Ensemble method yields a relatively noisier uncertainty map. Additionally, the Ensemble method shows high uncertainty in the turbulent flame regions, whereas the MCDropout method results in lower prediction uncertainty, indicating more robust predictions for such regions. A close examination of the two error maps reveals that both methods produce similar patterns, with higher prediction errors predominantly occurring in the complex burning regions."}, {"title": "5 EVALUATION AND PARAMETER STUDY", "content": "5.1 Reconstruction Quality and Prediction Error in Volume Space\nTable 2 presents a comparative study between the MCDropout and Ensemble methods in terms of averaged (expected) volume reconstruction quality measured using Peak signal-to-noise-ratio (PSNR). We use predictions from 100 MC samples for MCDropout and 10 ensemble members for Ensemble method to compute the final averaged field. Besides PSNR, we also estimate the Root Mean Squared Error (RMSE) between the reconstructed and ground truth fields. We observe that the reconstruction quality and RMSE between the MCDropout method and a single model trained without any dropout layer are comparable. However, the Ensemble method consistently produces the best reconstruction quality (highest PSNR) with minimum RMSE for all the data sets.\n5.2 PSNR Study with Varying Number of Ensemble Members\nTable 3 illustrates the effect of varying the number of ensemble members on PSNR. Notably, achieving robust predictions requires fewer ensemble members compared to the MCDropout method. The data shows that increasing the number of ensemble members slowly improves the PSNR and essentially leading the PSNR value to become saturated for 10 ensemble members. Nevertheless, for consistency and robustness across our experiments, we utilize 10 ensemble members.\n5.3 PSNR Study with Varying Number of MC Samples\nTable 4 shows the PSNR values of the scalar obtained by averaging different numbers of MC samples. Increasing the number of MC samples up to 100 results in a slight PSNR improvement. Beyond this point, the PSNR gains become marginal, making it impractical to consider more samples. Therefore, to balance computation time and prediction quality, we use 100 MC samples for all experiments involving the MCDropout method.\n5.4 Impact of Different Number of Ensemble Members on Average Pixel-wise Image space Uncertainty\nTable 5 illustrates the impact of varying the number of ensemble members on the average pixel-wise uncertainty value computed in the image space using the volume rendered pixel color values. This value reflects the normalized estimated uncertainty (standard deviation) calculated from the RGB color channels using the Ensemble method. We observe that the uncertainty value gradually saturates as the number of ensemble members increases up to 10.\n5.5 Impact of Different Number of Dropout Layers on MCDropout Model Performance\nWe conduct experiments on the Isabel Pressure and Teardrop data sets to assess the detailed impact of varying the number of dropout layers on model performance and prediction accuracy. We present results of averaged volume reconstruction quality results using models with dropout added at the (1) last two residual blocks, (2) last half of the blocks, and (3) all the residual blocks. The results, shown in Table 6, show that with an increased number of dropout layers, the PSNR value drops slowly, as was reported by Kendall et al. [31] since an increased number of dropout layers can act as a strong regularizer. Hence, in our work, we use dropout at the last two residual blocks to produce high-quality volume reconstruction and robust uncertainty estimates.\n5.6 Reconstruction with Different Dropout Probabilities\nTable 7 presents a study assessing the quality of volume data reconstruction, measured by PSNR, averaged over 100 MC samples across different test time dropout probabilities. We observe that PSNR mostly remains stable up to the dropout probability of 0.2, and as the dropout probability is further increased, expectedly, the PSNR value gradually drops. In their work, Gal et al. [14] suggest that using a small test time dropout probability is sufficient to estimate the model uncertainty robustly. Therefore, in our experiments, we use a dropout probability of 0.1 consistently for all the data sets to generate robust and meaningful uncertainty estimates.\n5.7 Impact of Different Number of MC Samples on Average Pixel-wise Image space Uncertainty\nTable 8 presents the impact of varying the number of MC samples on the average pixel-wise uncertainty value computed in the image space using the volume rendered pixel color values. This value indicates the normalized estimated uncertainty (standard deviation) calculated from the RGB color channels using the MCDropout method. It is seen that the uncertainty value gradually saturates as the number of MC samples reach 100.\n5.8 Reconstruction Quality and Error in Image Space\nTable 9 provides the PSNR and RMSE values computed using the averaged volume-rendered images for both the methods. The PSNR value reflects the reconstruction quality, while the RMSE indicates the error when the ground truth image pixel values are compared against the averaged image for both methods. The detailed computation of these averaged volume-rendered images has been discussed in Section 4.1. A close inspection of Table 9 reveals that the Ensemble method generally produces higher quality volume-rendered images with lower RMSE values.\n5.9 Comparison of Training and Inference Time Between MCDropout and Ensemble Methods\nTable 10 presents the training and inference times for both methods. For inference, we report both the volume reconstruction time and the ray casting time for each method. The Ensemble approach has faster inference times since it uses predictions from only 10 members, whereas MCDropout generates 100 MC samples, resulting in longer inference times. Training a dropout-enabled MCDropout model and a single ensemble member takes a comparable amount of time. However, since we train 10 ensemble members to build a robust Ensemble model, the total training time is 10 times greater, making the Ensemble method computationally more expensive than the MCDropout method. Additionally, storing model checkpoints for the Ensemble method requires 10 times more storage than for the MCDropout method. This significant difference in training time often makes MCDropout preferable for achieving timely results with robust uncertainty estimates.\n5.10 Model vs. Raw Data Size\nAs Implicit Neural Representations (INRs) like ours have proven effective for compactly representing large-scale volumetric data [36], Table 11 compares the sizes of the models and the raw data. As expected, MCDropout requires approximately ten times less storage than the Ensemble method, which consists of ten individual models, whereas MCDropout is a single model-based approach. Thus, when both data compression and uncertainty estimation are required, the MCDropout method offers a significantly higher compression ratio."}, {"title": "6 DISCUSSION", "content": "Uncertainty-agnostic vs. Uncertainty-aware DNNs. In this work, we advocate the use of deep neural networks (DNNs) that can quantify their prediction uncertainty when employed to perform scientific volumetric data visualization tasks. As demonstrated here, these uncertainty-aware neural networks provide important insights into the reliability of their predictions. By effectively communicating this uncertainty to experts, they can make more informed decisions regarding the data features from the visualization results. Integrating uncertainty is also essential for fostering trust in DNN-predicted results used in scientific visualization research.\nMCDropout vs. Ensemble Method. Our research explores two approaches for estimating uncertainty using Implicit Neural Representations (INRs) as the base DNN architecture to visualize volume data sets. Despite its long training times, we employ Deep Ensemble, a well-recognized standard, and investigate the single-model-based MCDropout method to address computational challenges. MCDropout is selected for its theoretical elegance and ease of integration into existing DNN models with minimal modifications. Our results indicate that both methods can offer meaningful prediction uncertainty, while the Ensemble method generally produces more accurate and robust predictions with higher confidence compared to the MCDropout method. It is also observed that the uncertainty maps generated by these two methods could be similar (for the Teardrop data set) as well as different and vary across different data sets. However, considering the extremely high training time required to build a robust"}]}