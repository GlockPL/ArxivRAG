{"title": "Edge AI: Evaluation of Model Compression Techniques for Convolutional Neural Networks", "authors": ["Samer Francy", "Raghubir Singh"], "abstract": "This work evaluates the compression techniques on ConvNeXt models in image classification tasks using the CIFAR-10 dataset. Structured pruning, unstructured pruning, and dynamic quantization methods are evaluated to reduce model size and computational complexity while maintaining accuracy. The experiments, conducted on cloud-based platforms and edge device, assess the performance of these techniques. Results show significant reductions in model size, with up to 75% reduction achieved using structured pruning techniques. Additionally, dynamic quantization achieves a reduction of up to 95% in the number of parameters. Fine-tuned models exhibit improved compression performance, indicating the benefits of pre-training in conjunction with compression techniques. Unstructured pruning methods reveal trends in accuracy and compression, with limited reductions in computational complexity. The combination of OTOV3 pruning and dynamic quantization further enhances compression performance, resulting 89.7% reduction in size, 95% reduction with number of parameters and MACs, and 3.8% increase with accuracy. The deployment of the final compressed model on edge device demonstrates high accuracy 92.5% and low inference time 20 ms, validating the effectiveness of compression techniques for real-world edge computing applications.", "sections": [{"title": "I. INTRODUCTION", "content": "EDGE devices such as Internet of Things (IoT) are becoming increasingly important and widely used in our daily lives and industrial facilities. IoT is a network of things that empowered by sensors, identifiers, software intelligence, and internet connectivity, it can be considered as the intersection of the internet, things/objects (anything/everything), and data [1]. The number of these devices is expected to increase even more [2]. These devices have the potential to perform complex Artificial Intelligence (AI) tasks locally, without relying heavily on cloud infrastructure [3]. The rapid advancement of AI has led to the development of complex deep learning models that show high performance in different domains. Deploying AI models on edge devices has many advantages such as low latency, privacy and data security, bandwidth optimization, and reduced network dependence. Low latency is achieved due to real-time processing by instant data analysis on edge without waiting for remote server processing, this data analysis on the edge reduces transmitting data to the cloud which enhances security against breaches, reduces the bandwidth consumption, and reduces network dependence."}, {"title": "A. Overview of Edge AI", "content": "Edge AI represents a paradigm shift in the way AI is implemented in the context of the IoT. It capitalizes on the capabilities of IoT devices, enhancing real-time processing, analytics, and decision-making directly at the edge of the network. The IoT architecture, which is the foundation for Edge AI, typically involves three core layers [1]. The layers are perceptual layer, where data is collected from various sensors and devices, network layer, where data is transmitted and routed through this layer, which is responsible for communication between devices and cloud services, and application layer, which processes and utilizes the data, providing insights and enabling actions."}, {"title": "B. Convolutional Neural Networks (CNNs)", "content": "CNN models are subsets of Deep Neural Networks (DNN) models. CNN models are effective for image and video-related tasks due to their ability to learn relevant features from the data by recognizing patterns, shapes, and structures in images, which is challenging for traditional machine learning models, that's why they are used for computer vision tasks such as image classification, object detection, and image segmentation [4]."}, {"title": "1) CNN Architecture:", "content": "In general CNN models consist of below parts:\n\u2022 Input Image: Pixels form the binary basis of computer images, while the human visual system operates through neurons with receptive fields. Similarly, CNNs function within their receptive areas, starting with simple patterns and advancing to more complex ones, making CNNs a promising tool for computer vision [4].\n\u2022 Convolutional Layer: A convolutional layer in a CNN uses a small filter (e.g., 3x3 or 5x5) that slides over the input image. At each position, it multiplies its values with the overlapping image pixels and sums the results to produce an output. This sliding operation helps identify local features like edges and colors, building a hierarchical representation. The depth of the filter matches the input image's channels (e.g., 3 for RGB images). Stacking multiple filters allows the network to learn features at different abstraction levels [4].\n\u2022 Pooling Layer: Pooling reduces the spatial size of feature maps. This not only lowers computational demands but also helps in extracting position and orientation-independent features essential for training. Two common pooling methods are maximum pooling and average pooling. In maximum pooling, a small kernel (e.g., 2x2)"}, {"title": "2) Computation and Memory Demands:", "content": "In CNNs, unbalance exists in resource demands between the layers. Convolutional layers primarily serve as feature extractors and heavily dominate the computational workload. In the case of AlexNet, for instance, the convolutional layers account for just 2 million weights but demand a substantial 1.33 Giga Operations Per Second (GOPS) of computation. In contrast, fully connected layers function as classifiers, accumulating information for high-level decisions, and bear the weight of the network with around 59 million parameters, yet they contribute significantly less to computation, requiring only 0.12 GOPS. This obvious contrast in resource allocation (Figure 1) highlights the unbalanced demands between these two layers in CNNs [5]."}, {"title": "3) Key CNN Architectures:", "content": "In 1989, the use of a NN architecture with convolutional layers for recognizing handwritten digits in the context of ZIP code recognition was introduced [6], That architecture consisted of input layer, 3 hidden layers, and output layer. Since then, CNN models have developed (Figure 2) and became much deeper."}, {"title": "4) CNN on Edge:", "content": "Deploying CNN models on edge has a wide range of practical and industrial applications across various sectors. Here are some specific examples:\n\u2022 Surveillance and Security: It can perform real-time ob-\n\u2022 Manufacturing and Quality Control: It can inspect products on assembly lines for defects, ensuring quality control and minimizing errors. Real-time detection of steel strip surface defects was deployed using Faster R-CNN model [11].\n\u2022 Agriculture: Drones can monitor crops, detect pests, diseases, and nutrient deficiencies, enabling precision agriculture. Identifying rice leaf diseases in natural environments was deployed using GoogLeNet [12]. Pepper leaf disease identification was deployed using GoogLeNet [13]. Detection for insect pests was deployed on YOLOX [14].\n\u2022 Healthcare and Wearables: Wearable devices can continuously monitor vital signs, detect anomalies, and even diagnose certain health conditions. Medical diagnosis (Covid and Lung Disease Detection) was deployed using VGG, MobileNet, and AlexNet [15]. Automatically diagnose pneumonia and COVID-19 from chest X-ray images was deployed on DenseNet [16]. Medical applications (e.g., COVID-19 detection, cardiomegaly diagnosis, brain tumor classification) were deployed using ResNet [10].\n\u2022 Energy Management: It can monitor energy usage, optimize consumption patterns, and identify areas for energy efficiency improvements. Wind Turbine Maintenance and fault diagnosis was deployed using AlexNet [17].\nEnvironmental Monitoring: It can monitor air quality, pollution levels, and weather conditions, providing valuable insights for urban planning. A smartphone app to perform fine-grained classification of animals in the wild was deployed using AlexNet, GoogLeNet, and ResNet [18]. Identification of mosquito species was deployed using AlexNet, DenseNet, Inception, ResNet, and VGG [19]."}, {"title": "\u2022 Logistics and Inventory Management:", "content": "It can automate package sorting, inventory tracking, and warehouse management. Mobile robot to map its surroundings while detecting objects and people was deployed using AlexNet, GoogLeNet, and ResNet [18].\nAutonomous Vehicles: Vehicles can process real-time data from cameras and sensors using CNNs, aiding in autonomous navigation and collision avoidance. Instance objects detection system for intelligent service robots was deployed using Alexnet [20]. Advanced driving assistance systems (ADASs) and automated vehicles (AVs) were deployed using Faster R-CNN [21]."}, {"title": "\u2022", "content": "Deploying CNNs on edge devices presents significant challenges mainly due to the limited computational resources, constrained memory, and power consumption constraints inherent to these devices. CNN models, known for their depth and complexity, often demand substantial computational power and memory, which may exceed the capabilities of edge hardware. Hence, compressing the model before deployment becomes imperative. Model compression techniques aim to reduce the size of the CNN model while preserving its performance, thereby enabling efficient utilization of computational resources and memory on edge devices. By compressing the model, we can mitigate the challenges associated with deploying CNNs on edge devices, ensuring that they can effectively perform tasks such as real-time image processing, object detection, and classification within resource-constrained environments."}, {"title": "\u2022", "content": "With the enormous number of compression techniques proposed for CNNs, the rapid evolution of CNN architectures has created a gap in the field. This dynamic shift in architecture design requires an evaluation of existing compression methods, particularly in light of the demand to make these advanced CNN models suitable for deployment on edge devices. As CNN designs continue to advance, the challenge lies in adapting compression techniques to smoothly integrate with these modern architectures. This evaluation (either for each individual techniques or combined with each other) becomes important, as it not only ensures the continued relevance of compression techniques but also addresses the urgent need to make resource-intensive CNN models accessible and deployable on edge devices."}, {"title": "\u2022", "content": "This work aims to evaluate CNN compression techniques that assure appropriate performance on edge devices. In the subsequent sections, this work reveals in a structured manner to evaluate the compression techniques for CNN models. section 2 provides a detailed review of related work, offering insights into prior research and establishing a foundational understanding of the topic. section 3 explains the methodology employed in conducting the experiments, describing the design and execution of the study. Following this, section 4 presents the experimental results and analyzes the findings to recognize trends and implications. Section 5 critically evaluates the results. Section 6 draws conclusions regarding the effectiveness and significance of the compression techniques. This organized framework aims to comprehensively explore and contribute to the field of model compression for efficient deployment in resource-constrained environments."}, {"title": "II. RELATED WORK", "content": "Within the context of edge AI, it is important to address the critical need for model compression. The resource constrained nature of these devices requires more efficient AI models by minimizing memory and computational demands, ensuring faster inference speeds, and enhancing energy efficiency. Below will explore various model compression techniques and their implications for edge AI applications."}, {"title": "A. Pruning", "content": "Pruning is a key technique in DNN, aimed at enhancing efficiency and model generalization. It involves the removal of redundant components, such as parameters, neurons, filters, or entire layers, leading to several advantages. By reducing unnecessary parameters, it cuts down on storage requirements, and important for models deployed on devices with limited memory. Furthermore, it streamlines computational complexity during inference, resulting in faster predictions and lower power consumption. Pruning also mitigates overfitting by simplifying the network. Various pruning techniques, like weight pruning, neuron pruning, filter pruning, and layer pruning, offer different levels of granularity in component removal. Whether applied during or after training, pruning enables the creation of more compact and efficient CNN models tailored to specific needs, effectively balancing model size, computational efficiency, and accuracy. Weight pruning sets weight connections in the network to zero if they fall below a predefined threshold or are considered redundant. Neuron pruning focuses on removing entire neurons if they are found to be redundant. Layer pruning allows for the removal of entire layers that are considered less important [22]."}, {"title": "1) Pruning For Fully Connected Layer:", "content": "Fully connected layers are dense that makes the layer with high memory demand. Pruning them effectively reduces the memory burden and reduce size of the model.\nIt involves selectively removing weight connections and neurons to reduce the model's complexity while preserving performance. In a typical feed-forward NN, inputs are multiplied by corresponding weights, and a linear sum is computed at each neuron, which is then transformed by an activation function. As shown in Figure 3, a network with 3 input neurons, 2 hidden neurons, and 1 output neuron may have multiple weight connections. Pruning can be applied to eliminate specific weight connections or entire neurons. By doing so, the total number of weight connections can be significantly reduced, leading to a more compact network. The concept of pruning was first introduced by [6], who proposed removing weights based on their saliency, with small-magnitude weights having less impact on training error. The process involves iterative retraining to regain accuracy, and the technique is known as 'Optimal Brain Damage (OBD)' where the second derivative of the objective function with respect to parameters is used to calculate the small saliency, facilitating informed pruning decisions. Since then, other pruning approaches have been introduced for fully connected layers [22]."}, {"title": "2) Pruning For Convolutional Layer:", "content": "Each convolutional layer typically consists of numerous filters that makes the layer with high computational demand. Pruning these less significant filters directly from the convolutional layer effectively reduces the computational burden and speeds up the model. Inspired by early pruning methods, new approaches have been introduced to be used to prune convolutional layers [22].\nBayesian was used to decide what to prune and the level of pruning, in this context involves employing scale mixtures of normals as priors for parameter weights in LeNet and VGG [23]. Differential evolution based layer-wise weight method alongside three other pruning techniques (Naive Cut, Iterative Pruning, and Multi-Objective NN Pruning) was used to prune LeNet, AlexNet, and VGG16 [24]. Two fully connected layers are removed from the AlexNet architecture, and Batch Normalization (BN) is introduced to mitigate overfitting [20]. Filters Similarity in Consecutive Layers (FSCL) for CNNs was used to reduce the number of filters while preserving important filters, ultimately improving model efficiency for VGG, GoogLeNet, and ResNet [25]. Structured pruning through sparsity-induced pruning was used to enhance the real-time implementation of the DEtection TRansformer (DETR) [26]. Structured pruning was used to compress YOLOX, this process included sparse training to prune unimportant channels, with fine-tuning to recover accuracy [14]. Evolutionary approach to filter pruning involved sequential application of multiple pruners in a specific order to sparsify LeNet and VGG-19 while maintaining model accuracy [27]. Multilayer networks were used to represent and compress ResNets, it involved creating class networks, calculating arc weights, and forming a multilayer network. The overall degree of nodes in the multilayer network is used to select a subset of nodes for compression, and convolutional layers are pruned [10]. To optimize the Fused-DenseNet-Tiny model for efficient detection of COVID-19 and pneumonia in chest X-ray images, three steps were implemented including removing insignificant weights, discarding pruning casings, and applying a compression algorithm [16]. Deep Scalable Zerotree-based (DeepSZ) framework was used to address resource constraints"}, {"title": "B. Quantization", "content": "Quantization plays an important role in addressing the resource-intensive nature of CNNs. By reducing the bit precision of model parameters, quantization not only conserves memory and energy but also enhances inference speed, making it an essential technique for deploying CNNs in resource-constrained environments such as edge devices. Weight clustering takes quantization to a more advanced level by organizing weights into clusters, where each cluster shares the same weight value. This approach minimizes the need for fine-tuning individual weights and can lead to substantial reductions in memory and computational overhead [22].\nSingle Level Quantization (SLQ) and Multiple Level Quantization (MLQ) technique were used to quantize AlexNet, VGG, GoogleNet, and ResNet to the deployment of these models on resource-constrained mobile devices like mobile phones and drones [30]."}, {"title": "C. Low-Rank Decomposition/Factorization", "content": "It is a compression technique used with feed-forward NNs and CNNs, to reduce the size of weight matrices while preserving model performance. Singular Value Decomposition (SVD) is a popular factorization scheme that decomposes a weight matrix A into three smaller matrices: U, S, and VT. U represents the left singular vectors, S is a diagonal matrix of singular values, and VT is the transpose of the right singular vectors. This factorization offers several advantages, such as reduced storage requirements, which is crucial for memory-constrained environments, and accelerated inference, especially in CNNs, as smaller matrices can be convolved faster. Low-rank factorization can be applied to fully connected and convolutional layers, making models more storage-efficient and faster without sacrificing performance. Careful selection of the rank is essential for achieving a balance between size reduction and model accuracy. Later, more approaches have been introduced [22].\nTucker decomposition for weight tensors was used to optimize weight tensor dimensions of LeNet and ResNet models [31]. Low-rank decomposition was used as an efficient method for compressing AlexNet, VGG, and ResNet without the need for fine-tuning to significantly reduce model size and computational complexity to make them more suitable for resource-constrained mobile and embedded devices [32]. Hardware-Aware Automatic Low-Rank Compression framework HALOC was used to compress ResNet, VGG and MobileNet, with the goal of efficiently exploring the structure-level redundancy in NNs by integrating principles from neural architecture search (NAS) [33]. Automatically Differentiable Tensor Network (ADTN) method was used to significantly reduce the number of parameters of fully connected NN, LeNet, and VGG while maintaining or enhancing the performance [34]. Joint Matrix Decomposition, specifically Joint SVD (JSVD) was used to address the challenge of deploying ResNet with numerous parameters on resource-constrained platforms. It included Right JSVD, Left JSVD, and Binary JSVD algorithms [35]. Tensor Ring Networks (TR-Nets) was used as a method to effectively factorize LeNet and ResNet, thereby reducing computational and memory requirements [36]. Tucker decomposition with rank selection and fine tuning was used as a one-shot whole network compression scheme for deploying AlexNet, VGG, and GoogLeNet on mobile devices while maintaining reasonable accuracy [37]. Tensor Dynamic Low-Rank Training (TDLRT) was used to create a training algorithm with VGG and AlexNet that maintains high model performance while significantly reducing memory requirements for convolutional layers [38]."}, {"title": "D. Knowledge Distillation (KD)", "content": "It is a technique used to transfer the knowledge learned by a larger, more complex model (the teacher model) to a smaller and lighter model (the student model). The primary goal of KD is to enable the student model to benefit from the generalization capabilities of the teacher model while being more lightweight in terms of parameters and computations. This technique helps to recover the accuracy drop occurs due to implementing other compression techniques.\nKnowledge transfer and distillation, initially introduced by [39], aimed to compress large ensemble models into smaller, faster counterparts with minimal performance loss. [40] extended this concept by empirically demonstrating that the intricate knowledge within larger DNNs could be effectively transferred to smaller, shallower models, yielding comparable accuracy. This involved training a large DNN and transferring its knowledge to a shallower network while minimizing the squared difference between the logits produced by the two models. These foundational ideas produced knowledge distillation, a widely used technique for training efficient models by transferring knowledge from larger ones. Later, more approaches have been introduced [22].\nKD was used to improve the compression of LeNet and ResNet models when fresh training data is scarce, primarily through the use of synthetic data generated by Generative Adversarial Networks (GANs) [41]. To fuse information from infrared and visible images while reducing DenseNet complexity and improving inference speed. Insights from pre-trained teacher models are transferred to the smaller student model [9]. KD was used to develop a lightweight mosquito species identification model (EfficientNet) that balances efficiency and accuracy through the compression [42]."}, {"title": "E. Mixed Techniques", "content": "Different compression techniques are often combined and used together to achieve more effective and comprehensive model compression. Each compression technique targets specific aspects of the model, such as reducing model size, computation complexity, or memory footprint.\nIn-Parallel Pruning-Quantization CLIP-Q method combines network pruning and weight quantization was used to compress AlexNet, GoogLeNet, and ResNet [18]. Pruning and quantization were used to optimize the compression of AlexNet and reduce the number of parameters significantly while maintaining accuracy to be implemented on Field-Programmable Gate Array (FPGA) [5]. Pruning, quantization, and Huffman encoding combined with adversarial training were used to enhance the robustness and compression of AlexNet while also addressing the model vulnerability to adversarial attacks [43]. Pruning and quantization were used to compress VGG and ResNet for remote sensing image classification, balancing computational complexity constraints while preserving model accuracy [44]. Low-rank decomposition and quantization were used to compress ResNet and MobileNet, and reduce the computational complexity while preserving high performance [45]. Pruning, quantization, and changing the model architecture were used to design a compact SqueezeNet with competitive accuracy while significantly reducing the number of parameters [46]. Quantization and pruning were used to develop an effective model compression framework for ResNet and MobileNet. The objective was to optimize the allocation of compression ratios to minimize performance degradation while reducing model size [47]. Joint quantization and pruning were used to develop a post-training model size compression method that efficiently combines lossy and lossless compression techniques to reduce the size of ResNet, MobileNet, RegNet, MNasNet, and YOLOv5 without sacrificing accuracy [48]."}, {"title": "F. Other Techniques", "content": "Depthwise separable convolutions was used to improve steel strip defect detection by creating a real-time and efficient model while maintaining high accuracy using Faster R-CNN [11]. Deferential Evolution was used to develop an efficient and optimized AlexNet, VGG, and MobileNet for Covid and liver disease detection [15]. Genetic Algorithm was used to reduce the storage space and inference time of VGG, ResNet, AlexNet, and SqueezeNet models [49]. Factorization (changing kernel size) was used to improve the accuracy and computing efficiency of pepper leaf disease detection using GoogLeNet, specifically for the agricultural industry [13]. Flexible and Separable Convolution (FSConv) was used to reduce computational costs without compromising the accuracy of VGG, ResNet, Faster R-CNN and RetinaNet [50]. Efficient Layer Compression (ELC) was used to enhance the computational efficiency of VGG, ResNet, and ConvNeXt while preserving their representation capabilities [51]."}, {"title": "III. DESIGN OF THE EXPERIMENTS", "content": "The experiments aimed to evaluate various compression techniques, namely pruning and quantization, on different types of ConvNext [52] model. The experiments included training, fine-tuning, and evaluating of models using CIFAR-10 dataset. The setup involved conducting experiments both on cloud-based platforms and on edge devices to evaluate the performance of the compressed models."}, {"title": "A. ConvNeXt", "content": "Is a modern CNN family produced as a journey of gradually modernize a standard ResNet toward the design of a vision Transformer. The journey starts from a ResNet-50 model, into a CNN architecture that mirrors some aspects of Transformers, particularly Swin Transformers. The roadmap:\n1) Training Techniques: Vision Transformer training procedures were used to train ResNet-50 model, this included extending the training to 300 epochs (90 epochs originally), using AdamW optimizer, and data augmentation techniques (Mixup, Cutmix, RandAugment, Random Erasing, and regularization schemes including Stochastic Depth).\n2) Macro Design: Number of blocks in each stage was adjusted from (3, 4, 6, 3) to (3, 3, 9, 3) and the stem was replaced with a patchify layer implemented using a 4x4, stride 4 convolutional layer (non-overlapping convolution).\n3) ResNeXt-ify: ResNeXt approach was adopted which is utilize grouped convolutions, where convolutional filters are divided into groups, each handling a subset of input channels, a variation of grouped convolution known as depthwise convolution was adopted, and the network's width was expanded by increasing the number of channels in the convolutional layers.\n4) Inverted Bottleneck: The hidden dimension of the MLP block was changed to be four times wider than the input dimension as shown in Figure 4 (a and b)\n5) Large Kernel Sizes: The position of the convolutional layer is moved up and the kernel size was changed from (3x3) to (7x7) as shown in Figure 4 (a and c)."}, {"title": "B. Micro Design", "content": "Replacing ReLU with Gaussian Error Linear Unit (GELU), fewer normalization layers, Substituting Batch Normalization (BN) with Layer Normalization (LN), and introducing separate downsampling layers as shown in Figure 5."}, {"title": "C. Compression Techniques", "content": "1) Pruning: Different pruning techniques have been used including structured and unstructured techniques."}, {"title": "\u2022 Only Train Once (OTO)", "content": "OTO version 3 (OTOV3) is automated framework for structured pruning which involves removing entire structures or groups of parameters from a DNN. OTOv3 begins by analyzing the dependencies between the vertices of the target DNN. This analysis involves identifying accessory, Shape-Dependent (SD) joint, and unknown vertices that are adjacent and establishing their interdependencies. The goal is to form node groups based on these dependencies, laying the foundation for identifying interdependent vertices during structured pruning.\nUsing the information gathered from the dependency analysis, OTOv3 constructs a pruning dependency graph. This graph represents the interdependencies between vertices, with vertices in the same node group indicating their interdependency during structured pruning. The pruning dependency graph ensures the validity of the produced subnetwork by preserving essential connections between vertices.\nOTOv3 partitions the trainable variables of the DNN into Pruning Zero-Invariant Groups (PZIGs) based on the pruning dependency graph. PZIGs consist of pairwise trainable variables grouped together, with each group representing a potential pruning structure. Node groups adjacent to the DNN output and containing unknown vertices are excluded from forming PZIGs to preserve output shapes and ensure model robustness as shown in Figure 6.\nTo jointly search for redundant pruning structures and train the remaining groups for optimal performance, OTOv3 employs the Dual Half-Space Projected Gradient (DHSPG) algorithm. DHSPG minimizes the objective function while introducing a sparsity constraint to identify redundant groups for removal. It employs saliency-driven redundant identification and a hybrid training paradigm to control sparsity and achieve better generalization performance as shown in Figure 7."}, {"title": "\u2022 L1 Unstructured", "content": "L1 unstructured pruning is a technique used in machine learning, to reduce the size of neural networks by eliminating less important connections. Each weight in the network is assigned a score based on its magnitude. This score reflects the importance of the weight in the network's performance. In 11 pruning, this score is often the absolute value of the weight.\nA threshold is set, typically by selecting the top x% of weights based on their magnitude scores. The threshold determines which weights will be pruned and which will be retained.\nWeights that fall below the threshold are pruned, meaning they are set to zero and effectively removed from the network. This results in a sparser network architecture with fewer connections.\nRandom Unstructured [55] Similar to 11 unstructured pruning, random unstructured pruning is also a technique used in machine learning, to reduce the size of neural networks by eliminating less important connections. The difference is the pruned weight are selected randomly instead of using 11 to decide the importance of the weights."}, {"title": "\u2022", "content": "2) Dynamic Quantization [30]: Dynamic quantization is an approach aimed at optimizing the deployment of neural networks by reducing the precision of the weights. Unlike traditional quantization methods that apply a fixed quantization bit-width across all layers of the network, dynamic quantization adapts the quantization bit-width for each layer individually based on its representation abilities and capacities. This is achieved through the use of a bit-width controller module, which employs a policy gradient-based training approach to learn the optimal bit-width for each layer. By dynamically adjusting the quantization bit-width, dynamic quantization can strike a balance between maintaining accuracy and reducing memory size and computational costs."}, {"title": "D. CIFAR-10", "content": "CIFAR-10 is a dataset used for computer vision and machine learning research, offering a rich resource for training and evaluating image classification algorithms. Comprising 60,000 32x32 RGB color images across 10 distinct classes (Airplane, Automobile, Bird, Cat, Deer, Dog, Frog, Horse, Ship, and Truck), CIFAR-10 facilitates comprehensive exploration of diverse visual concepts. With each class containing 6,000 images and a balanced distribution across the dataset, CIFAR-10 presents a well-structured foundation for model development. Its division into 50,000 training images and 10,000 test images, further segmented into multiple batches, enables strict evaluation and benchmarking of algorithms. In terms of computational requirements, CIFAR-10 generally requires less computation compared to CIFAR-100 and ImageNet due to its smaller image size and fewer classes which makes it suitable for experiments with limited computational resources."}, {"title": "E. Experiment Setup", "content": "Two types of experiments have been conducted, cloud-based experiments that focused on compressing the models and evaluating the techniques and edge-based experiment experiment to evaluate the performance of one of the compressed models.\n1) Cloud-based Experiment Setup: Google Colab Pro+ was used to utilize GPU resources (NVIDIA A100 and V100 Tensor Core GPUs), facilitating accelerated model training and evaluation and background execution. The integration with Google Drive reduced overheads associated with uploading and downloading model data to and from cloud. The evaluation framework was designed to profile the original model, compress it, profile the compressed model, and conduct comparison between the measurements before and after the compression as shown in Figure 8.\nThis profiling process involved measuring several key metrics:\n\u2022 Accuracy: The classification accuracy achieved by the model on the validation dataset.\n\u2022 Model Size: The size of the model in megabytes (MB).\n\u2022 Number of Parameters: The total count of trainable parameters in the model, measured in millions (M).\n\u2022 Number of MACs: The number of multiply-accumulate operations performed during inference, measured in millions (M).\n\u2022 Number of Non-Zero Parameters: The count of non-zero parameters in the model, essential for pruning-based techniques.\n2) Edge-based Experiment Setup: A compressed model was deployed on edge with CPU (11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz), RAM (16GB), and laptop integrated camera.\n2 samples from each of CIFAR-10 classes have been selected randomly from the internet, printed on A4 papers, and placed in front of the camera to measure the accuracy and the inference time."}, {"title": "IV. RUNNING THE EXPERIMENTS AND EXPERIMENTAL RESULTS", "content": "A. Cloud-Base Experiments\ndifferent experiments have been conducted on cloud to evaluate different compressing techniques and different versions of ConvNeXt model.\n1) Evaluate OTOV3 on Untrained Torch ConvNext Tiny, Small, Base, and Large: Untrained ConvNeXt tiny, small, base, and large have been imported from Torch and been used to evaluate OTOV3 which train and prune at the same time, CIFAR-10 was used for training and evaluation, and 200 epochs were used for training and pruning. OTOV3 achieved high performance (Table I) with reducing the model size (61% for tiny and 75% for small, base, and large), number of parameters (61% for tiny and 75% for small, base, and large), and MACs (45% for tiny and 60% for small, base, and large) as shown in Figure 9. Meanwhile OTOV3 was able to increase both the full and compressed model accuracy through the training and pruning without any accuracy drop after pruning comparing to the full model.\nTo investigate the effect of OTOV3 on the model architecture, a comparison has been conducted between ConvNeXt small before and after compression. The Torch implementation of the model consist of many CNBlocks, each CNBlock consist of Conv2d, Permute, LayerNorm, Linear, GELU, Linear, and Permute layers. As shown in Figure 10, OTOV3 reduced number of output features of the Linear layer (sequence 3) and the input features of the next Linear layer (sequence 5) and considering the big number of CNBlock in the model architecture, the reduction in model size and number of parameters after compression is justified as shown in Table II."}, {"title": "\u2022", "content": "2) Evaluate OTOV3 on Untrained ConvNext Small (Torch vs. TIMM): Two untrained ConvNeXt small have been imported, one from Torch and one from TIMM [57] and been used to evaluate OTOV3 which train and prune at the same time, CIFAR-10 was used for training and evaluation, and 200 epochs were used for training and pruning. Although the compression performance was same with size reduction (75%) but the accuracy after 200 epochs was less for Torch model (63%) comparing to TIMM model (73%) as shown in Figure 11."}, {"title": "\u2022", "content": "To investigate the accuracy performance of OTOV3 with Torch and Timm ConvNeXt Small, a comparison has been conducted between the two model architectures. The Torch model uses the CNBlock structure, which includes additional operations such as Permute and varying StochasticDepth probabilities. The TIMM model follows a simpler structure with Conv2d and LayerNorm, lacking the additional complexities introduced by CNBlock and associated operations in the Torch model as shown in Figure 12 which effects OTOV3 performance regarding the accuracy."}, {"title": "\u2022", "content": "3) Evaluate OTOV3 on Fine-Tuned Torch ConvNext Small: A pre-trained ConvNeXt small have been imported from Torch and fine-tuned on CIFAR-10 with 100 epochs, the accuracy reached 89.5%. This fine-tuned ConvNeXt small will be used for the rest of cloud-base experiments. This model was used to evaluate OTOV3, CIFAR-10 was used for training and evaluation, and 200 epochs were used for training and pruning. OTOV3 achieved high performance (Table III) 74% reduction in model size and number of parameters, 60% reduction in MACs, and 3.8% increase with accuracy as shown Figure 13. The accuracy of the full model in (Table III) (92.86%) is different that the accuracy of the original model used in the experiment (89.5%), that because OTOV3 trained the full"}, {"title": "\u2022", "content": "4) Evaluate Unstructured Pruning: The Fine-tuned ConvNext Small was used to evaluate Pytorch L1 Unstructured Pruning and Random Unstructured Pruning by using different combinations of weights pruning percentages for linear (.1 to .9) and convolutional (.1 to 9) layers. In both experiments, the accuracy and the number of non-zero parameters were dropping as the values of weights pruning percentages for both linear and convolutional amounts were increasing as shown in Figure 14 a and b. Although the accuracy dropped but the model size, number of parameters, and MACs didn't change as these techniques zero the weights instead of removing them."}, {"title": "\u2022", "content": "5) Evaluate Dynamic Quantization: The Fine-tuned ConvNext Small was used to evaluate Pytorch dynamic quantization, 8-bit integer was used during the experiment and CIFAR-10 was used for evaluation. Dynamic quantization achieved high performance (Table IV) 71% reduction in model size, 95% reduction with number of parameters and MACs, and 0.1% drop with accuracy as shown in Figure 15"}, {"title": "\u2022", "content": "6"}]}