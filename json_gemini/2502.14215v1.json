{"title": "Towards Secure Program Partitioning for Smart Contracts with LLM's In-Context Learning", "authors": ["Ye Liu", "Yuqing Niu", "Chengyan Ma", "Ruidong Han", "Wei Ma", "Yi Li", "Debin Gao", "David Lo"], "abstract": "Smart contracts are highly susceptible to manipulation attacks due to the leakage of sensitive information. Addressing manipulation vulnerabilities is particularly challenging because they stem from inherent data confidentiality issues rather than straightforward implementation bugs. To tackle this by preventing sensitive information leakage, we present PARTITIONGPT, the first LLM-driven approach that combines static analysis with the in-context learning capabilities of large language models (LLMs) to partition smart contracts into privileged and normal codebases, guided by a few annotated sensitive data variables. We evaluated PARTITIONGPT on 18 annotated smart contracts containing 99 sensitive functions. The results demonstrate that PARTITIONGPT successfully generates compilable, and verified partitions for 78% of the sensitive functions while reducing approximately 30% code compared to function-level partitioning approach. Furthermore, we evaluated PARTITIONGPT on nine real-world manipulation attacks that lead to a total loss of 25 million dollars, PARTITIONGPT effectively prevents eight cases, highlighting its potential for broad applicability and the necessity for secure program partitioning during smart contract development to diminish manipulation vulnerabilities.", "sections": [{"title": "I. INTRODUCTION", "content": "Smart contracts are script programs deployed and executed on blockchain, facilitating the customization and processing of complicated business logic within transactions. Most smart contracts are developed in Turing-complete programming languages such as Solidity [1]. These smart contracts have empowered a wider range of applications across fungible tokens, non-fungible tokens (NFT), decentralized exchanges, and predication markets on different blockchain platforms including Ethereum [2], BSC [3], and Solana [4]. However, smart contracts may contain design and implementation flaws, making them vulnerable to different types of security attacks. These include common vulnerabilities, such as integer overflow [5] and reentrancy [6], as well as manipulation vulnerabilities, such as front-running [7], user-control randomness [8], and price manipulation [9]. While common vulnerabilities have been extensively studied and well addressed, defending against manipulation vulnerabilities remains a big challenge.\nManipulation vulnerabilities are caused by sensitive information leakage because of the inherent transparency feature of blockchains. For instance, in 2023, Jimbo was attacked due to the manipulation of unprotected price-related internal states called bins, leading to a loss of about eight million dollars [10]. While static analysis [11, 12, 13, 14, 15, 16] and dynamic analysis techniques [17, 18, 19, 20, 21, 22] have demonstrated impressive capabilities in vulnerability detection, they primarily target implementation bugs rather than addressing the inherent risk of data transparency in blockchains. Particularly, Ethainter [14] detects information flow problems in smart contracts, but it is limited to only the detection of unrestricted data write due to poor access control. The price manipulation attacks can be detected by some existing methods [20, 21, 22] through rule-based transaction analysis, but such incomplete rules still leave a room for attackers to adjust their activities to avoid being detected. Similarly, formal verification approaches [23, 24, 25, 26, 27] excel at proving correctness properties but are less effective in scenarios where the root cause lies in unintended exposure of sensitive contract states. Runtime verification techniques [28, 29, 30, 31] offer the potential to halt harmful executions dynamically. However, these methods often require modification of the execution environment or rely on predefined rules that are inadequate for addressing information leakage, as they focus on transaction execution anomalies. Furthermore, program repair solutions [32, 33, 34, 35, 36, 37, 38, 39] concentrate on patching common vulnerabilities or fixing implementation errors. They do not account for design-specific issues related to data transparency, leaving contracts vulnerable to manipulation attacks such as front-running, user-controlled randomness, and price manipulation. Beyond the aforementioned program analyses, a more practical solution is to defend against manipulation vulnerabilities through privacy-aware software development.\nThe primary limitation of existing approaches to protecting sensitive information in smart contracts lies in their coarse-grained handling of sensitive operations. These approaches can be broadly categorized into hardware-supported and non-hardware-supported solutions. While the hardware-based solutions [40, 41, 42, 43, 44, 45] provide a trusted execution environment (TEE) that could hide all the execution and data information when running the entire smart contract, they lack flexibility and increase dependency on specific infrastructures. Similarly, the non-hardware-supported solutions, e.g., empowered by zero-knowledge proofs [46, 47], seal sensitive operations during execution but often come with computational overhead and integration complexity. These methods fail to leverage the principle of least privilege [48] effectively, as they intermingle sensitive and non-sensitive operations within a single codebase, making it difficult to enforce modular security or validate protection measures in a scalable manner. This intertwining of sensitive and non-sensitive operations not"}, {"title": "II. BACKGROUND AND MOTIVATION", "content": "Blockchain technology was first introduced in Bitcoin [50] and has emerged as a transformative innovation, enabling decentralized systems that eliminate the need for intermediaries in transactions and applications. At its core, blockchain provides a distributed, immutable ledger that ensures transparency and security. Smart contracts, programmable scripts executed on the blockchain, have further expanded its utility by automating processes such as financial transactions, supply chain management, and governance. These contracts are deterministic and operate transparently, allowing all participants in the network to verify their behavior. This has been pivotal in the success of decentralized finance (DeFi) and other blockchain-based applications, where trust is derived from the open and verifiable nature of smart contracts.\nHowever, privacy is one of the major concerns for blockchains as most of these systems store and log everything viewable to the public [51]. Sensitive information, such as user account details, transaction data, and contract-specific logic, is often exposed on-chain, creating risks of data leakage. For instance, adversaries can analyze public transaction histories and state variables of smart contracts to infer private information in order to exploit vulnerabilities. In DeFi space, attackers have leveraged publicly accessible contract states to orchestrate complex exploits, such as oracle price manipulations and front-running attacks. The lack of mechanisms to distinguish and safeguard sensitive data from non-sensitive data exacerbates these risks, making smart contracts an attractive target for malicious actors.\nWhile efforts to mitigate data leakage risks exist, they are often inadequate. Techniques like homomorphic encryption [52], zero knowledge proofs [46], and multiparty computation [53] can obscure sensitive data, but these approaches may conflict with the principles of decentralization or introduce inefficiencies. This highlights the urgent need for innovative solutions that preserve the decentralized and transparent nature of blockchain systems while providing robust privacy protections. Strategies such as privilege separation could address these challenges, enabling smart contracts to securely handle sensitive information."}, {"title": "B. A Motivating Example", "content": "Jimbo suffered from a manipulation attack on May 29, 2023, where the attacker gained a profit of 8 million dollars by devising a highly-complicated transaction sequences with crafted inputs [10]. Jimbo is a Self-Market Making Liquidity Bin Tokens (SMMLBTs) [54], where \u201cbin\u201d represents a range of prices, with positions further to the right denoting higher prices. In the Jimbo protocol, rebalancing of asset in the liquidity pool is defined by the different states of the bin including active bin, floor bin and trigger bin. Specifically, floor bin denotes the minimum price of Jimbo tokens; active bin represents the price currently traded on; and trigger bin refers to the price that triggers the rebalancing. One key point is that when active bin is above trigger bin, users can call a shift() function of Jimbo to increase floor bin.\nThe success of the attack relies on the attacker obtaining exact value of the bins. In this exploit, the attacker first initiated a flashloan of 10,000 Ether to add liquidity to the rightmost bin as shown in Figure 1a, where the current the active bin is 8,387,711 and trigger bin is 8,387,715. Next, the attacker bought Jimbo's token to make active bin above trigger bin, where active bin moved from 8,387,711 to 8,387,716 as depicted in Figure 1b. Subsequently, the attacker rebalanced the liquidity with shift() that increased the value of floor bin. Hence, the attacker creates a huge arbitrage space, and more details above the following profit earning operations can refer to the security analysis report\u00b9. Consequently, the attacker sold Jimbo's token at a significantly high price indicated by the increasing floor bin.\nHowever, this delicate attack vector is non-trivial for the existing price manipulation detection tools [20, 22, 21] to detect and the existing runtime verification techniques [29, 31] to defend against. First, the manipulation detection tools heavily rely on the correct extraction of the token exchange rate. But, in this case, the exchange rate between Ether and Jimbo is defined over the complicated states of bin, which is challenging to automatically infer. Second, the manipulation of bin's states is carefully-designed (active bin is close to trigger bin), making runtime verification tools hard to differentiate between normal transactions and abnormal attacks.\nRunning privileged code inside a secure environment makes it impossible for an attacker to read such values and therefore the attack will be unsuccessful. To mitigate such manipulation attacks, in this work, we propose to conduct a fine-grained"}, {"title": "III. APPROACH", "content": "Figure 2 illustrates the workflow of PARTITIONGPT, an LLM-driven fine-grained program partitioning framework for smart contracts. PARTITIONGPT processes smart contracts annotated with sensitive data variable information, ultimately producing partitioned contracts. These partitions isolate privileged statements into dedicated subordinate functions, separating them from normal statements. At a high-level overview, PARTITIONGPT breaks a contract function into two smaller parts-one for normal statements while the other for privileged statements related to operations on sensitive data variables. PARTITIONGPT encompasses seven steps. \u2460 Locate will employ taint analysis to identify critical functions containing privileged statements. For each function, \u2461 Slice will yield two program slices according to privileged statements and these slices will be one of prompt parameters for partition generation within 3 Iterative Loop for each function. In detail, 4 Generate harnesses LLM by incorporating the aforementioned program slices and using a few examples as the seed, thus tailoring the code refactoring process for partition purpose. Syntactically incorrect code alerted by compilers can be revised by LLM with concrete compiler feedback in Revise. Next, syntactically correct code will be analyzed to determine whether the program is securely partitioned or not in Validate using an effective detection rule. If it is insecurely partitioned, the current program partition should be repaired. Therefore, we regenerate the program partitions taking the current program partition as bad example. For all the compilable and likely secure partitions, we perform \u2466 Weighted Selection to choose the top-K partition candidates. We develop a dedicated prover to conduct equivalence checking between the original and the post-partition function code. Consequently, the correctness of all the resulting program partitions are formally verified and PARTITIONGPT outputs compilable, and verified program partitions for smart contracts."}, {"title": "A. Identify Sensitive Functions and Statements", "content": "Input: V, a set of sensitive state variables of smart contract.\nInput: PDGs, a set of program dependence graphs.\nOutput: F, a set of sensitive functions; \u2206, a set of sensitive program statement nodes.\nAlgorithm 1 takes the user-provided sensitive state variables and constructed PDGs as input. We perform forward analysis to recognize all the sink nodes (Line 1 to Line 6) by enumerating each sensitive variable and each node of every PDG for different functions. We use ISDEPENDENT to indicate the data dependencies between any two variables along the PDG, while for each node, readVars, writeVars, and rvVars represent the read variables, the written variables, and their combinations, respectively. When then the sensitive variable has a data flow to a variable that the node reads or writes (Line 4), we mark it as a sink node (Line 5) and sensitive functions will be updated accordingly (Line 6). Additionally, we perform backward analysis to recognize all the source nodes (Line 7 to Line 13) by revisiting all the variables that sink nodes read and the PDGs for different functions. When a node has a data flow to a variable that the sink node reads (Line 11), we mark it as a source node (Line 12) and sensitive functions will be updated accordingly (Line 13).\nNote we also have some limitations for the range of sensitive data variables. Solidity smart contracts could have composite data types like structure of which some member variables may be sensitive. To eliminate the complexity of data type splitting, we also label the corresponding composite data variables as sensitive, although it may result in a slightly larger set of sensitive operations."}, {"title": "C. Program Slicing and Partitioning", "content": "To employ the in-context learning capability of LLMs, PARTITIONGPT necessitates that contract functions are sliced based on privileged, i.e., sensitive statements, in order to generate high-quality program partitions that probably preserve the confidentiality and semantic integrity of original code. Here, we formulate program slicing process and the constraints of slicing-based partition.\nDefinition 1: Program Slicing. Given a contract function $f = (S, \\leq_{control},\\leq_{data})$, S indicates the set of all program statement nodes. $S = {entry, ...., exit}$ includes the input-related entry point and return-related exit point(s) of function. The two relations $\\leq_{control}$ and $\\leq_{data}$ represent the partial order between nodes in terms of control and data flow, respectively. For instance, $a,b \\in S, a \\leq_{control} b$ delineates that a is control-dependent on b, while $a \\leq_{data} b$ implies that a is data-dependent on b. Note we assume $\\forall a,$"}, {"title": "D. LLM-driven Fine-grained Partitioning", "content": "The process of fine-grained program partitioning in PARTITIONGPT leverages the power of LLMs to transform smart contract functions into securely partitioned variants. Using a carefully designed prompt (Figure 3), PARTITIONGPT guides the LLM by preprocessing a function into two slices: the normal slice, containing non-sensitive statements, and the privileged slice, encompassing operations related to sensitive data variables. PARTITIONGPT's partitioning ensures that privileged operations are isolated from normal execution, creating a secure and modular structure within the smart contract.\nThe LLM performs this Solidity-to-Solidity transformation by strictly adhering to the guidelines provided in the prompt. In the partition result, privileged partition encapsulates privileged operations in a dedicated function (e.g., XXX_priv). For non-privileged partition, while refactoring the entry function, necessary callbacks (e.g., XXX_callback) are also introduced to handle return values or continue execution of normal statements for the purpose of higher modularity. Modifier statements2 that include privileged operations will be incorporated into the privileged partition. By doing so, the LLM minimizes the inclusion of non-privileged statements in the privileged partition, ensuring a clear separation of concerns and enhancing security. Note the privileged and non-privileged partition by PARTITIONGPT communicates with each other through function calls (e.g. Listing 2). Additionally, we also provide some (currently two) human-written program partitions for contract functions as the seed examples to direct the LLM for program partitioning. While these examples may be limited, we argue that our preliminary experiment found that without few examples, the resulting program partitions often deviate from the aforementioned structure requirements listed in the prompt.\nIn cases where the generated partition does not meet security requirements, the LLM undertakes iterative repairs, which is discussed in the next section. The prompt is updated to include the insecure partition and a detailed explanation of its shortcomings, enabling the LLM to refine its output. This iterative process continues until a compilable and secure partition is produced. Through this LLM-driven approach, PARTITIONGPT achieves precise and reliable partitioning, ensuring that smart contracts are both robust and resistant to data leakage risks.\nNevertheless, inaccuracy could exist in some partition results. To mitigate this problem, for each subject function, PARTITIONGPT attempts to generate up to 10 partitions, where for each output code, PARTITIONGPT makes less than 10 tries to revise compilation error if available. The resulting partitions will be ranked and selected to represent the appropriate program partitions that developers are interested in. We will discuss the ranking process in Section III-F and illustrate one partition case in Listing 2 of Section III-G."}, {"title": "E. Revising and Repairing Program Partitions", "content": "The partition results by PARTITIONGPT may not be compilable because while partition generation seems straightforward for LLMs, it suffers from innate randomness to some extent. Following the practice [59], we leverage compiler feedback to revise the subject code."}, {"title": "F. Ranking the Top-K Appropriate Program Partitions", "content": "Since optimal program partitions are usually subjective and hard to define, to avoid human bias, we leverage a weighted selection algorithm to select the appropriate program partitions which is usually time-consuming. Specifically, we establish a fitness function to evaluate the candidates by considering the following factors:\n*  X(f, f'): Edit distance between function f and its partition result f'.\n*  Ycodebase(f', fpriv): The ratio of codebase size of privileged part fpriv compared to the whole partition result f'.\n*  Ycodebase(fpriv, \u2206): The ratio of codebase size of privileged statements \u2206 compared to the whole privileged part Spriv\nNote that we introduce Ycodebase to cope with that granularity of partitioning could vary a lot for the same function code. We use X (f, f') to reflect the edit distance that could estimate the efforts for developers to refactor the original code.\nGiven an unknown code f, we score f' using a weighted algorithm as below.\nScore(f, f') = \u03b1 \u00d7 X(f, f') + \u03b2 \u00d7 Ycodebase(f', fpriv)+  \u03b3xYcodebase (fpriv, \u2206)\nwhere \u03b1, \u03b2, \u03b3 are coefficients and \u03b1 + \u03b2 + y = 1.\nLet f be the human-written program partition result of f.\nTo tune these coefficients, we train a linear regression model by approximating actual score Score(f, f) that is computed based on their text embedding similarity. We have conducted a primitive experiment on 1,267 program partitions generated by PARTITIONGPT. Note these partitions are distinct from the evaluated partitions appearing in Table I of Section V. The results show \u03b1: 0.594, \u03b2: 0.192, and \u03b3: 0.214 are aligned to human-written partitioned data. As a result, all the program partitions will be sorted in descending order, and we believe that the program partitions of higher rank are likely to be the high-quality program partitions."}, {"title": "G. Illustration Example", "content": "We use a case study to illustrate how PARTITIONGPT generates program partitions. Listing 1 lists the function code of bid from an auction contract named BlindAuction which is one of official examples provided in Solidity documentation [1]. Briefly speaking, Listing 1 shows that user bids will be processed to update the current highestBid and bidCounter. When a user have ever put a bid in the auction, bidCounter will not be updated. In this auction contract, user bids stored in the data variable existingBid and the current highest bid highestBid are labeled as the sensitive data variables. To partition this function, PARTITIONGPT first performs taint analysis to identify all the sensitive statements. As shown in Listing 1, the orange code blocks encompasses all the sensitive statements while the other statements, e.g., the invocation to modifier onlyBeforeEnd that checks if the auction ends and the increment of bidCounter  of Line 20), belong to non-sensitive statements. Next, we perform slicing according to the aforementioned sensitive statements, leading to two program slices. The privileged slice can be formalized as if then else fi, while the normal slice is  if then { } else fi. The two slices preserve the execution integrity for either sensitive and non-sensitive statements, but are coupled with each other since they share if. To decouple these, we leverage LLM's in-context learning by instantiating the generation template (c.f. Figure 3) with the original function code, identified sensitive statements, and computed normal and privileged slices. Finally, PARTITIONGPT yields one partition result as shown in Listing 2. This normal partition comprises two functions-the refactored bid and created bid_callback functions while the privileged partition includes only one function called bid_priv. Note that the refactored bid remains the entry function for users to trigger smart contract execution. As illustrated in Listing 2, to orchestrate the execution between the privileged part bid_priv and the normal part bid_callback, PARTITIONGPT introduces new temporary flag variable amountChanged (Line 16) and set the value in Line 21 and Line 27. This flag variable will be returned (Line 37) and when amountChanged is true  (line 9), bidCounter will increase (line 11). However, the value assignment in Line 21 (colored in orange) is wrong because users have already held a bid position that can be implied by the non-zero existing bid price, thus nonequivalent with the pre-partition function in Listing 1. This indicates that although LLM commands powerful in-context learning capability, precise semantic understanding may be challenging and external verification tools are essential to generate formal guarantee of correctness."}, {"title": "IV. EQUIVALENCE CHECKING", "content": "The correctness of the resulting compilable and likely secure program partitions should be formally verified against the original subject code. To the best that we know, only one proprietary formal verification tool provided by Certora [26] is able to perform equivalence checking between smart contract functions. However, their tool is closed-source and limited to only the comparison between two \"pure\" functions where a"}, {"title": "V. EVALUATION", "content": "We implemented our approach in PARTITIONGPT in around 4,000 lines of Python for partition generation and 500 lines of C++ for equivalence verification built on SolSEE [61]. We used Z3 solver [60], version 4.13.0, to check equivalence relationship between the original and partitioned function versions. PARTITIONGPT is empowered by GPT-40 mini developed by OpenAI, where its default model setting is reused. We also employed the embedding model text-embedding-ada-002 developed by OpenAI to score LLM-written program partitions compared to human-written ones in terms of embedding similarity. We used the Levenshtein distance to measure the edit distance between the original functions and its partitioned output. Furthermore, we used Slither [62], version 0.10.4, for PDG construction and taint analysis for Solidity smart contracts."}, {"title": "B. Research Question", "content": "In the evaluation, we aim to answer the following research questions."}, {"title": "C. RQ1: Partition Generation", "content": "We evaluated PARTITIONGPT on the aforementioned 18 confidential smart contracts encompassing 99 sensitive functions. Table I shows the experiment results under the top-3 setting. The first five columns on the left demonstrate the name, sensitive data variables, line of codes, number of public functions, and number of sensitive functions of smart contracts, respectively. The middle two columns present the number of sensitive functions identified by PartitionGPT and the number of generated program partitions for those identified sensitive functions that match with the ground truth. The rest columns demonstrate the verification results of the resulting partitions after equivalence checking. TP and FP refer to the number of correct and incorrect program partitions that pass and fail the equivalence checking, respectively. #Hit displays the number of ground truth functions for which PARTITIONGPT successfully produce compilable, secure and functionally equivalent partitions, and we use Success rate to indicate its proportions in ground truth functions.\nTable I clearly shows that PARTITIONGPT is able to generate a reasonably high accuracy of program partitioning for smart contracts. Overall, PARTITIONGPT is able to generate 877 program partitions for 99 ground truth functions out of which 76 functions have been successfully partitioned, achieving success rate of 0.78, with relatively good precision 0.76. Particularly, PARTITIONGPT failed to perform equivalence checking for AuctionInstance due to timeout. This is because AuctionInstance has nested loops in its sensitive functions, and although we cap the loop iteration count to five during symbolic execution, there remains a state explosion problem. PARTITIONGPT wrongly flagged the function open of CipherBomb as sensitive function because this function can write a data variable turnDealNeeded that a sensitive function checkDeal explicitly declassified from the known sensitive data cards, roles as shown in Table I, while PARTITIONGPT currently does not support the declassification annotation. Nevertheless, PARTITIONGPT also has the potential to identify other sensitive functions beyond the human-specified ground truth functions. PARTITIONGPT flagged the function mint of NFTExample because mint writes values to one of the sensitive data variable, and successfully discover a neglected view function get EncryptedTokenID involving sensitive data variables.\nWe also investigate the impact of different top-K setting. Figure 5 demonstrates the averaged precision, success rate, and the ratio of the size of isolated privileged (trusted) codebase (TCB) by PARTITIONGPT compared to the size of original function code. We use this ratio metric to reflect the TCB minimization in comparison with isolating the whole sensitive functions into secure partitioning [68, 56, 57]. Figure 5 delineates that the success rate jumps from top-1 to top-3, and then remains relatively stable. But, TCB size decreases a bit"}, {"title": "D. RQ2: Application in Real-world Victim Contracts", "content": "We evaluated PARTITIONGPT on nine victim contracts vulnerable to price and randomness manipulation. Recall PARTITIONGPT is able to identify all the sensitive functions related to given sensitive data that we believe play pivotal role in the manipulation attack where attackers interfere with the sensitive data without any protection. In typical manipulation incidents, attackers first manipulate the sensitive data and then earn a profit. Most attacks like the well-studied price manipulation will incur at least two function calls where the first function call will alter sensitive data variables about liquidity, and the second function call will make a profit with the use of the manipulated data.\nWe compare PARTITIONGPT with the existing manipulation detection tools DefiTainter [22], DeFort [20], DefiRanger [21], and GPTScan [16]. Because DefiRanger is not open source, we take their reported results [21] in Table II."}, {"title": "E. RQ3: Runtime Overhead", "content": "The partitions produced by PartitionGPT should be deployed to secure execution environment to protect sensitive functionality. Trusted execution environment (TEE) has been employed to protect the privacy of smart contracts [40, 41]. TEE is able to execute general instructions but with minimal time cost. There have been several TEE infrastructures designed for smart contracts such as open-source CCF [41] in which the whole Ethereum Virtual Machine is running at SGX enclave mode supporting TEE devices like Intel SGX.\nTo conduct the experiments, we select eight functions from two contracts listed in Figure 6. The first four functions belong to BlindAuction, and they are responsible for the biding, querying and post-biding processing, while the latter four functions of EncryptedERC20 represent the most common ERC20 functionalities. For each contract, it includes two executable instances: one for the public part deployed in a Ethereum test network powered by Ganache [71] of version 6.12.2, and the other for the privileged part deployed in the CCF network [41] with a simulated TEE environment. For the cross-chain communications between Ethereum-side and TEE-side instance, we replace the call statements, i.e., XXX_priv(), with message events logged in the normal test network, which will then be passed to a third-party router to trigger the execution of privileged function within the TEE-side instance. Also, we replace the call statements, i.e., XXX_callback(), with message events logged in the CCF network and then the third-party router processes the events to trigger the callback function of the Ethereum-side instance. To orchestrate the communication, we formulate their call orders into scheduling policies. We highlight that the aforementioned substitution rules can be automated by using a few code transformation templates. Furthermore, we implemented the third-party router as a listener thread to automatically monitor new events from the normal test network and the CCF network and then deal with the events according to the abovementioned scheduling policies. For each function, we manually crafted five test cases to execute and then collected their runtime gas overheads. We clarify that currently we do not add encryption and decryption methods for the data communicated between the Ethereum-side and TEE-side instance. Developers of smart contracts should be responsible for this particular setting. For instance, developers may need to exchange their keys through transactions or smart contracts where the data will be decoded in the TEE-side [53, 49].\nFigure 6 plots the runtime gas overhead of the original contract and the TEE-powered post-partition contract. Note that the execution of the TEE-side instance will not incur gas overhead for the CCF network. Apparently, after partitioning, six out of eight contract functions will take more gas overhead, increasing between 61% and 103%. The main reason is that these functions not only communicate message from the Ethereum-side instance with TEE-side instance but also deal with callback message from TEE-side instance to require Ethereum-side instance to proceed with normal operation execution, leading to two more transactions. In comparison, for the two functions: withdraw and mint, callback-related communications are not needed, thus reducing the gas consumption. Note each communication will take one transaction, and 21,000 gas is charged for any transaction on Ethereum as a \"base fee\" so that n transactions will need to consume no less than n\u00d721,000 gas. Therefore, we argue that although deploying the partitions into TEEs could incur more gas overhead, developers could still benefit in twofold. First,"}, {"title": "F. RQ4: Sensitivity Study", "content": "To investigate the effectiveness of different base LLMs, we conducted a sensitivity study on partition generation for the aforementioned 18 confidential smart contracts (c.f. Table I) with four LLMs: (1) GPT-40 mini, (2) Gemma2:27b, (3) Llama3.1:8b, and (4) Qwen2.5:32b.\nTable III shows the comparison results. We evaluated LLMs on the overall number of generated partitions, true positives, false positives, and precision. Recall that we excluded AuctionInstance's partitions in the precision evaluation. Note #Partitions also includes partitions beyond function scope of the ground truth. It is evident that GPT-40 mini substantially outperforms over the rest LLMs. GPT-40 mini yields 907 partitions in total, achieving a precision score of 0.78, followed by Qwen2.5:32b having 758 partitions and precision of 0.75. Llama3.1:8b performs the worst, rendering the least number of partitions and the poorest precision (0.44). To have an in-depth analysis of such significant difference in the number of resulting partitions, we studied the capability of different LLMs in generating compilable program partitions for smart contracts, which plays a vital role in our approach. Figure 7 depicts the distribution of times that different LLMs need to generate compilable partitions. Figure 7 indicates that 83% partition candidates initially generated by GPT-40 mini are compilable, followed by Qwen2.5:32b having 70%. It is surprising that all the partition candidates generated by Llama3.1:8b must be fixed at least once (using 5 Revise of PARTITIONGPT). The main reason, we believe, may be that Llama3.1 has not been trained on Solidity smart contract datasets. Therefore, we recommend using the closed-source GPT-40 mini for efficiency and the open-source Qwen2.5:32b to facilitate smart contract partitioning with budget consideration."}, {"title": "G. Threats to Validity", "content": "a) Lack of ground truth: We manually selected a set of annotated smart contracts and real-world smart contracts vulnerable to manipulation attacks for evaluating the effectiveness of PARTITIONGPT. To address this threat, we systematically crawled well-studied confidential smart contracts in which developers have explicitly labeled sensitive data, as well as victim smart contracts from known real-world attacks with root causes scrutinized by security experts.\nb) External Validity: Our findings in program partitioning may not generalize to other large language models. To mitigate this threat, we have evaluated PARTITIONGPT with state-of-the-art LLMs developed by four vendors, namely closed-source GPT-40 mini by OpenAI, open-source Llama3.1 by Meta, Qwen2.5 by Alibaba, and Gemma2 by Google."}, {"title": "VI. RELATED WORK", "content": "The detection of vulnerabilities in smart contracts has been a central focus of blockchain security research. Symbolic execution tools like Oyente [11], Manticore [23], and Mythril [24] pioneered the detection of critical vulnerabilities such as reentrancy, mishandled exceptions, and integer overflow/underflow. These tools systematically explore execution paths to identify potential exploits but are limited by path explosion and incomplete semantic coverage. Static analysis tools, such as Slither [72] and SmartCheck [13], leverage data-flow and control-flow analyses to identify a wide range of vulnerabilities, including bad coding practices and information-flow issues. Securify [73] and Ethainter [14] use rule-based pattern matching to detect vulnerabilities, while SmartScopy [15] introduces summary-based symbolic evaluation for attack synthesis. Dynamic analysis techniques, including fuzzing tools like ContractFuzzer [17], sFuzz [18], and Echidna [19], analyze runtime behaviors by generating test inputs to uncover exploitable bugs. However, these tools often suffer from limited state coverage and rely heavily on predefined oracles. Formal verification tools, such as KEVM [27] and Certora [26], as well as semi-automated tools like Echidna [19], require"}, {"title": "B. Secure Program Partitioning", "content": "Secure program partitioning has been introduced since 2001 by Zdancewic et al. [55] for protecting confidential data during computation in distributed systems containing mutually untrusted host. They developed a program splitter that accept Java program and its security annotations on data variables, and assign according statements to the given hosts.\nThe program partitioning works can be broadly categorized based on the granularity of code splitting. Function-level program partitioning takes the entire functions as units for separation, and it has been extensively studied [68, 56, 57, 77, 78, 79, 80, 81, 82]. Brumley and Song [68] accept a few annotations on variables and functions, and then partitions the input source into two programs: the monitor and the slave. They apply inter-procedural static analysis, i.e., taint analysis and C-to-C translation. The workflow of our approach is in general similar to them. But, PARTITIONGPT harnesses LLM's in-context learning for Solidity-to-Solidity translation, and we propose a dedicated equivalence checker to formally verify the correctness of the resulting program partitions.\nSubsequently, Liu et al. [56] proposes a set of techniques for supporting general pointer in the automatic program partitioning by employing a parameter-tree approach for representing data of pointer types that exist in languages like C. To balance the security and performance and select appropriate partitions, Wu et al. [57] define a quantitative measure of the security and performance of privilege separation. Particularly, they measure the security by the size of code executed in unprivileged process, where the smaller the privileged part is, the more secure the program is. Our work also follows the insight about the security measure during the partition ranking but PARTITIONGPT uses the edit distance compared to the original program code rather than runtime overhead to select the appropriate partition that could compete with the human-written. There are also program partitioning techniques specialized for creating and deploying partitioning to TEE-based secure environments [77, 79, 78, 80, 83]. For instance, Glamdring [83] uses static program slicing and backward"}, {"title": "VII. CONCLUSION", "content": "In this"}]}