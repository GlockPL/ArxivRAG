{"title": "Dissecting the Failure of Invariant Learning on Graphs", "authors": ["Qixun Wang", "Yifei Wang", "Yisen Wang", "Xianghua Ying"], "abstract": "Enhancing node-level Out-Of-Distribution (OOD) generalization on graphs remains\na crucial area of research. In this paper, we develop a Structural Causal Model\n(SCM) to theoretically dissect the performance of two prominent invariant learning\nmethods-Invariant Risk Minimization (IRM) and Variance-Risk Extrapolation\n(VREx)-in node-level OOD settings. Our analysis reveals a critical limitation:\ndue to the lack of class-conditional invariance constraints, these methods may\nstruggle to accurately identify the structure of the predictive invariant ego-graph\nand consequently rely on spurious features. To address this, we propose Cross-\nenvironment Intra-class Alignment (CIA), which explicitly eliminates spurious\nfeatures by aligning cross-environment representations conditioned on the same\nclass, bypassing the need for explicit knowledge of the causal pattern structure.\nTo adapt CIA to node-level OOD scenarios where environment labels are hard\nto obtain, we further propose CIA-LRA (Localized Reweighting Alignment) that\nleverages the distribution of neighboring labels to selectively align node represen-\ntations, effectively distinguishing and preserving invariant features while removing\nspurious ones, all without relying on environment labels. We theoretically prove\nCIA-LRA's effectiveness by deriving an OOD generalization error bound based\non PAC-Bayesian analysis. Experiments on graph OOD benchmarks validate the\nsuperiority of CIA and CIA-LRA, marking a significant advancement in node-\nlevel OOD generalization. The codes are available at https://github.com/\nNOVAglow646/NeurIPS24-Invariant-Learning-on-Graphs.", "sections": [{"title": "1 Introduction", "content": "Generalizing to unseen testing distributions that differ from the training distributions, known as Out-\nOf-Distribution (OOD) generalization, is one of the key challenges in machine learning. Invariant\nlearning, which aims to capture predictive features that remain consistent under distributional shifts,\nis a crucial strategy for addressing OOD generalization. Numerous invariant learning methods have\nbeen proposed to tackle OOD problems in computer vision (CV) tasks [Arjovsky et al., 2020, Krueger\net al., 2021, Bui et al., 2021, Rame et al., 2022, Shi et al., 2021, Mahajan et al., 2021, Zhang et al.,\n2021a, Wang et al., 2022a, Yi et al., 2022, Wang et al., 2022b, Xin et al., 2023]. While in recent years,\nenhancing OOD generalization on graph data is an emerging research direction attracting increasing\nattention. In this work, we focus on the challenge of node-level OOD generalization on graphs.\nStraightforwardly adapting the above methods to node-level graph OOD scenarios presents several\nchallenges: 1) the prediction of a node's label depends on its neighbored samples in an ego-subgraph,\ncausing a gap from conventional CV OOD scenarios where samples are independently predicted;\nand 2) environment labels in node-level tasks are often unavailable [Wu et al., 2021, Li et al., 2023a,"}, {"title": "2 Dissecting Invariant Learning on Graphs", "content": "For OOD node classification, we are given a single training graph G = (A, X, Y) containing N nodes\nV = {v_i}_{i=1}^N from multiple training environments e \u2208 E_{tr}. A \u2208 {0,1}^{N\u00d7N} is the adjacency matrix,\nA_{i,j} = 1 iff there is an edge between v_i and v_j. X \u2208 R^{N\u00d7D} are node features. The i-th row X_i \u2208 R^D\nrepresents the original node feature of v_i. Y \u2208 {0,1, ..., C \u2013 1}^N are the labels, C is the number of\nthe classes. Denote the subgraph containing nodes of environment e as G^e = (A^e, X^e, Y^e), which\nfollows the distribution p_e. Let A^e \u2208 {0,1}^{N_e\u00d7N_e} and D^e be the adjacency matrix and the diagonal\ndegree matrix for nodes from environment e respectively, where D^e_{ii} = \u2211_{j=1}^{N_e} A^e_{ij}, N_e is the number\nof samples in e. Denote the normalized adjacency matrix as \u0100^e = (D^e + I_{N_e})^{-\u00bd} A^e(D^e + I_{N_e})^{-\u00bd},\nI_{N_e} is the identity matrix. Let \\hat{A}^e = \u0100^e + (D^e + I_{N_e})^{-\u2021}I_{N_e}\u2208(De + I_{N_e})^{-\u00bd}. Suppose the unseen\ntest environments are e' \u2208 E_{te}. The test distribution p_{e'} \u2260 p_e\u2200e' \u2208 E_{te}, \u2200e \u2208 E_{tr}. OOD generalization\naims to minimize the prediction error over test distributions.\nTo understand the obstacles in invariant learning on graphs, we start by examining whether IRMv1\n(practical implementation of the original challenging IRM objective, proposed by Arjovsky et al.\n2020]) and VREx can be successfully transferred to node-level graph OOD tasks. Their objectives\nare as follows:\n(IRMv1) min_{\u03c9,\u03c6} E_e [L (w \u03bf \u03c6(X^e), Y^e) + \u03b2||\u2207_w|_{w=1.0}L (w \u03bf \u03c6(X^e), Y^e) ||^2],\n(VREx) min_{\u03c9,\u03c6} E_e [L (w \u03bf \u03c6(X^e), Y^e)] + \u03b2Var_e [L (w \u03bf \u03c6(X^e), Y^e)],\nwhere w and \u03c6 denote the classifier and feature extractor, respectively. L is the cross-entropy loss. \u03b2\nis some hyperparameter."}, {"title": "2.1 A Causal Data Model on Graphs", "content": "Data generation process. We construct an SCM to character-\nize two kinds of distribution shifts: concept shift (Figure 1a)\nand covariate shift (Figure 1b). C and S denote unobservable\ncausal/spurious latent variables that affect the generation of the\ngraph G, and dashed E are environmental variables usually\nunobservable. We consider a simple case that each node v\nin environment e has a 2-dim feature [x_1, x_2]^T, x_1, x_2 \u2208 R.\nDenote the concatenated node features of all nodes in e as\nX_1 \u2208 R^{N_e\u00d71} and X_2 \u2208 R^{N_e\u00d71} corresponding to x_1 and x_2,\nrespectively. For the SCM in Figure 1a, the data generation\nprocess of environment e is\nY^e = (\\tilde{A}^e)^k X_1 + n_1, X_2 = (\\tilde{A}^e)^mY^e + N_2 + e^e,\nwhere k \u2208 N+ represents the \"depth\" (number of hops) of the causal pattern, and m \u2208 N+ is the\ndepth of the ego-graph determining the spurious node features. n_1 \u2208 R^{N_e\u00d71} and n_2 \u2208 R^{N_e\u00d71}\nrepresent random Gaussian noise. e^e stands for an environmental variable, causing the spurious\ncorrelations between X_2 and Y. A detailed description of the model is in Appendix F.1.\nHow the proposed model considers both node feature shifts and structural shifts? X_1 represent\ninvariant node features causing Y^e. X_2 denotes spurious node features that vary with environments.\nAs for structural shifts, we consider an environmental A^e in Equation (2), which means the structure\ncan vary with environments. For example, there could be a spurious correlation between certain\nstructures and the label; or, the graph connectivity or size may shift [Buffelli et al., 2022, Xia et al.,"}, {"title": "2.2 Intriguing Failure of VREx and IRM on Graphs", "content": "Now we are ready to present the failure cases in this node-level OOD task: optimizing IRMv1\nand VREx induces a model that relies on spurious features X_2 to predict, leading to poor OOD\ngeneralization. To illustrate that this failure arises from the graph data, we first prove that IRMv1 and\nVREx can learn invariant features under the non-graph version of SCM of Equation (2).\nProposition 2.2. (IRMv1 and VREx can learn invariant features for non-graph tasks, proof is in\nAppendix G.1.1.) For the non-graph version of the SCM in Equation (2),\nY^e = X_1 + n_1, X_2 = Y^e + n_2 + \u0454^e,\nVREx and IRMv1 can learn invariant features when using a linear network: f(X) = \u03b8_1X_1 + \u03b8_2X_2.\nNow we will give the main theorem revealing the failure of VREx and IRMv1 on graphs.\nTheorem 2.3. (IRMv1 and VREx will use spurious features on graphs, informal) Under the SCM\nof Equation (2), the IRMv1 and VREx objectives have non-unique solutions for parameters of the\nGNN (3), and there exist solutions that use spurious features, i.e. \u03b8_2 \u2260 0.\nIntuitive illustration of the failure. From Theorem 2.3, we find that the main reason for the failure\nlies in the message-passing mechanism in representation learning. Let's provide some key steps in\nthe proof of the IRMv1 case as an illustration. For the non-graph OOD task Equation (5), we can\nverify that when IRMv1 objective is solved, i.e. \u2207_wR(e) = 0 for all e, the invariant solution \u03b8_2 = 0"}, {"title": "3 The Proposed Methods", "content": "Inspired by the examples of VREx and IRMv1, we aim to introduce additional invariance regular-\nization to guide the model in identifying the underlying invariant node features and structures. We\npropose CIA (Cross-environment Intra-class Alignment), which aligns the representations from the\nsame class across different environments. Intuitively, since such node pairs share similar invariant fea-\ntures and causal pattern structures while differ in spurious features, aligning their representations will\nhelp achieve our targets. Denote the representation of node i as \u03c6_\u03b8(i) and the classifier parameterized\nby \u03b8_h as h_\u03b8: CIA's objective is:\nmin_{\u03b8_h, \u0398} E_e [L(h_{\u03b8_h} \u25e6 \u03c6_\u0398(A^e, X^e), Y^e)] s.t. min_\u0398 L_{CIA} = E_{e,e'} E_{c} E_{i,j | (i,j) \u2208 \u03a9_{e,e'}^c} [D(\u03c6_\u0398(i), \u03c6_\u0398(j))]\nwhere \u03a9_{e,e'}^{c} = {(i, j)|i \u2260 j \u2227 Y_i = Y_j = c \u2227 E_i = e, E_j = e'} is the set of nodes with same label\nc and from two different environments. L is the cross-entropy loss. D is some distance metric and\nwe adopt L-2 distance. Now we prove that CIA can learn invariant representations regardless of the\nunknown causal patterns:\nTheorem 3.1. Under the SCM of Equation (2) and Assumption 2.1, optimizing the CIA objective will\nlead to the optimal invariant solution \u0398^* in Equation (4) for parameters of the GNN (3).\nThe proof is in Appendix G.1.4. By enforcing class-conditional invariance, which is not considered\nin VREx and IRMv1, CIA overcomes the above obstacles and eliminates spurious features. As long\nas a GNN has the capacity to adaptively learn the true depth of the causal pattern (such as the one\nconsidered in Equation (3)) or a GAT), CIA can identify the invariant causal pattern."}, {"title": "3.2 Localized Reweighting Alignment: an Adaptation to Graphs without Environment Labels", "content": "So far, we have theoretically and empirically validated CIA's advantage on graphs, but it still requires\nenvironmental labels that are challenging to obtain in most node classification tasks [Wu et al., 2021,\nLiu et al., 2023, Li et al., 2023a]. In this section, we propose CIA-LRA (Localized Reweighting\nAlignment) that realizes CIA's objective without using environment labels by identifying node pairs\nwith significant/minor differences in spurious/invariant features and then aligning their representations.\nAs illustrated in Figure 2, CIA-LRA mainly incorporates three components:"}, {"title": "4 Theoretical Justification: an OOD Generalization Error Bound", "content": "Now will derive an OOD generalization error bound to show that optimizing CIA-LRA can minimize\nOOD error. To achieve this, we adopt a PAC-Bayesian framework following Ma et al. [2021]\nand establish a Contextual Stochastic Block Model (CSBM, [Deshpande et al., 2018]) for OOD\nmulti-classification. The proposed CSBM-OOD is as follows (more discussions are in Appendix F.4):\nDefinition 4.1. (CSBM-OOD). For node i of class c from environment e, its node feature x_i \u2208 R^D\nconsists of two parts, x_i = [x_{inv}; x_{sp}], where x_{inv} \u2208 R^{D_1} sampled from the Gaussian distribution\nN(\u03bc^c_e, \u03c3^2I) is the invariant feature and x_{sp} \u2208 R^{D_2} sampled from the N(\u03bc^c_e, \u03c3^2I) is the spurious\nfeature. 6 Suppose {\u03bc^c_e} and {\u03bc^c_e} for all c and e form sets of orthonormal basis. We use p_{h}^{hom}\nto denote the homophilic ratio of node i's one-hop neighbors and use p_{ht}^{het}(c') to denote the heterophilic\nratio of node i's one-hop neighbors of class c' (c' \u2260 c'). We assume Pr(y_i = c) are the same for all\nclasses c.\nThe GNN model used for deriving the error bound (following Ma et al. [2021]): The GNN model\nhas a 1-layer mean aggregation g that outputs the aggregated feature g_i \u2208 R^D for node i. The GNN\nclassifier h on top of g is a ReLU-activated L-layer MLP with W_1,..., W_L as parameters for each\nlayer. h is from a function family H. The prediction for node i is h_i \u2208 R^C with h_i[c] representing\nthe predicted logit for class c. Denote the largest width of all the hidden layers as b.\nNotations. Denote nodes of environment e as V_e. We consider the error of generalizing from a\nmixed training environment \\mathcal{V}_{tr} to any test environment V_{et} \u2208 E_{te}, where \\mathcal{V}_{tr} := U_{e\u2208E_{tr}} V_e represents\nall training nodes. To guarantee the generalization, we need to characterize the distance between\nV_{et} and \\mathcal{V}_{tr}: define f_{ete,etr} = max_{j\u2208V_{ete}} min_{i\u2208V_{etr}} ||g_i - g_j||_2 as the aggregated feature distance\nbetween the training and test subgroup. Define the number of nodes in environment e as N_e. We\nconsider the margin loss of environment e that is used by Ma et al. [2021], Mao et al. [2023]:\nL(h) := {N^e}^{-1} \\sum_{y_i} 1 [h_i[y_i] < y + max_{c\u2260y_i} h_i[c]].\nNow we introduce some assumptions adapted from Ma et al. [2021] that are used in our proof.\nAssumption 4.2. (Equal-sized and disjoint near sets, adapted from Assumption 2 of Ma et al. [2021])\nFor each node v_i \u2208 \\mathcal{V}_{etr}, define \\mathcal{V}_{ete}(i) := {j \u2208 V_{ete} | ||g_i - g_j||_2 \u2264 e_{etr,ete}}. For any test environment\nV_{et}, assume \\mathcal{V}_{ete}(i) of each v_i \u2208 \\mathcal{V}_{etr} are disjoint and have the same size N_{ete} \u2208 N+.\nAssumption 4.3. (concentrated expected loss difference, adapted from Assumption 3 of Ma et al.\n[2021]) Let P be a distribution on H, defined by sampling the vectorized MLP parameters from"}, {"title": "5 Experiments", "content": "5.1 Experiment Setup\nWe run experiments using 3-layer GAT and GCN on GOOD [Gui et al., 2022], a graph OOD bench-\nmark. We reported the results on both covariate shift and concept shift. The detailed experimental\nsetup and hyperparameter settings are in Appendix C. We compare our methods with the following\nalgorithms: ERM [Vapnik, 1999]; traditional invariant learning methods: IRM, VREx, GroupDRO\n[Sagawa et al., 2019], Deep Coral [Sun and Saenko, 2016], IGA [Koyama and Yamaguchi, 2020];\ngraph OOD methods: EERM, SRGNN, CIT [Xia et al., 2023], CaNet [Wu et al., 2024]; graph data\naugmentation: Mixup [Wang et al., 2021], GTrans [Jin et al., 2022].\n5.2 Main Results of OOD Generalization\nTable 2 reports the main OOD generalization results. The observations are summarized as follows: 1)\nCIA-LRA improves the best baseline methods by 2.44% and 3.23% on GAT and GCN, respectively,"}, {"title": "5.3 CIA can be Integrated into and Improve other Graph-OOD Methods", "content": "We replace VREx with CIA in the loss function of EERM\nto show that CIA can improve generalization in a plug-and-\nplay manner."}, {"title": "5.4 Empirical Understanding of the Role of CIA-LRA", "content": "A synthetic dataset. We construct a synthetic dataset (mentioned in Section 1) to validate the role of\neach module in CIA-LRA in eliminating spurious features and preventing the collapse of invariant\nrepresentations. We generate a random graph and create a 4-class OOD classification task. Each\nnode has a 4-dim feature, with the first/last two dimensions representing invariant/spurious features\n(details in Appendix C.3), so we can disentangle the learned invariant and spurious representations."}, {"title": "5.5 Effects of the Hyperparameters of CIA-LRA", "content": "This section analyzes the effect of \u03bb and t of\nCIA-LRA. Figure 4 shows that the test accuracy\nincreases with \u03bb when \u03bb < 0.5. Too small t\nleads to a sub-optimal performance due to insuf-\nficient regularization from aligning only a few\npairs. Also, most parameter combinations out-\nperform the baseline methods, indicating that\nCIA-LRA leads to consistently superior perfor-\nmance. Additional studies of the effects of \u03bb\nand t are in Appendix D.2 and D.3, respectively."}, {"title": "6 Conclusion", "content": "In this work, by theoretically dissecting the failure of IRM and VREx in node-level graph OOD tasks,\nwe attribute it to the difficulty in identifying the graph-specific causal pattern structures. To address\nthis, we propose CIA with additional class-conditional invariance constraints and its environment-\nlabel-free variant CIA-LRA tailored for graph OOD scenarios. Further theoretical and experimental\nresults validate their efficacy. Notably, CIA can be incorporated in other graph OOD frameworks,\nserving as a better invariant learning objective than the widely-used VREx on graphs."}, {"title": "11. Safeguards", "content": "Question: Does the paper describe safeguards that have been put in place for responsible\nrelease of data or models that have a high risk for misuse (e.g., pretrained language models,\nimage generators, or scraped datasets)?\nAnswer: [NA]\nJustification: [TODO]"}]}