{"title": "Retrieval-Augmented Generation Meets Data-Driven Tabula Rasa Approach for Temporal Knowledge Graph Forecasting", "authors": ["Geethan Sannidhi", "Sagar Srinivas Sakhinana", "Venkataramana Runkana"], "abstract": "Pre-trained large language models (PLLMs) like OpenAI ChatGPT\nand Google Gemini face challenges such as inaccurate factual re-\ncall, hallucinations, biases, and future data leakage for temporal\nKnowledge Graph (tKG) forecasting. To address these issues, we in-\ntroduce SLA-tKGF (small-scale language assistant for tKG forecast-\ning), which utilizes Retrieval-Augmented Generation (RAG) aided,\ncustom-trained small-scale language models through a tabula rasa\napproach from scratch for effective tKG forecasting. Our framework\nconstructs knowledge-infused prompts with relevant historical data\nfrom tKGs, web search results, and PLLMs-generated textual de-\nscriptions to understand historical entity relationships prior to the\ntarget time. It leverages these external knowledge-infused prompts\nfor deeper understanding and reasoning of context-specific seman-\ntic and temporal information to zero-shot prompt small-scale lan-\nguage models for more accurate predictions of future events within\ntKGs. It reduces hallucinations and mitigates distributional shift\nchallenges through comprehending changing trends over time. As a\nresult, it enables more accurate and contextually grounded forecasts\nof future events while minimizing computational demands. Rig-\norous empirical studies demonstrate our framework's robustness,\nscalability, and state-of-the-art (SOTA) performance on benchmark\ndatasets with interpretable and trustworthy tKG forecasting.", "sections": [{"title": "1 INTRODUCTION", "content": "Knowledge Graphs (KGs) and their dynamic extension, Temporal\nKnowledge Graphs (tKGs), play a pivotal role in AI applications like\nrecommendation engines and web searches by structuring data into\ngraph-formatted databases. KGs utilize triples $(s, r, o)$-where s is\nthe subject, o is the object, and r describes their relation-to encode\nfacts, while tKGs add a time element (t) to represent time-validity\nof the fact, allowing them to capture how facts evolve over time.\ntKG reasoning, essential for deriving new insights, encompasses\ninterpolation-to fill in historical data gaps [5, 6, 8, 12, 16, 32]-and\nextrapolation, for future event prediction [13, 28]. Predicting fu-\nture events in tKGs is difficult, it requires handling unseen time\nperiods and entirely new entities, demanding advanced methods to\nnavigate the ever-changing nature of relationships. Closed-source\npretrained large language models(PLLMs) like OpenAI ChatGPT[1]\nand Google Gemini[27] show potential for predicting future events\ndue to their extensive pre-training knowledge and reasoning abil-\nities. However, these large-scale models face challenges like fact\nrecall issues stemming from complex architectures, resulting in\nunreliable predictions (hallucinations), potential bias from training\ndata, and inadvertent leveraging of future data during pretraining,\ncausing data leakage for tKG forecasting. Detecting data leakage\nis challenging when opaque training datasets are used for pre-\ntraining proprietary LLMs. Ensuring predictions rely solely on\nlegitimate predictive abilities without the undue influence from\nfuture data remains a critical challenge for trustworthy tKG fore-\ncasting. To address the limitations of existing methods, we present\nSLA-tKGF, a small-scale language assistant for tKG forecasting\nbased on Retrieval-Augmented Generation (RAG) [19] to ground\npredictions in historical context with source attribution and trace-\nability. The framework employs a multi-layered stacked vanilla\ntransformer architecture [30] as its backbone language model and\ncustom trained from scratch to avoid biases and data leakage in-\nherent in pre-trained LLMs. The framework incorporates three key\ncomponents: (i) retrieval of relevant historical knowledge from\nthe tKGs. By retrieving historical facts based on context and se-\nmantic similarity to the query, we can infer causality and gain\ninsights into temporal dynamics. Additionally, we employ text-\nembedding model and semantic similarity for query matching to\nfilter out anachronistic/irrelevant information. (ii) utilizing PLLMs\nto analyze entity relationships prior to the target time to generate\ntextual descriptions of historical entity relationships based on their\ninternal knowledge acquired from vast pre-training text corpora.\n(iii) web scraping for up-to-date contextual information relevant\nto the query. We utilize advanced pre-processing techniques like\nsentence tokenization, temporal tagging, and date conversion for\nexcluding future facts beyond the target time and retain appro-\npriate scraped data. By incorporating information from diverse\nsources within a carefully crafted knowledge-augmented prompt,\nthe framework generates factually accurate predictions grounded\nin historical context and ensures explainability. It minimizes the\nrisk of bias, hallucinations, and avoids data leakage by pruning\nout-of-bound information. This 'Tabula Rasa' approach of training\nthe framework from scratch ensures a foundation of accountability\nand trustworthiness in tKG forecasting by ensuring predictions\nare truly based on past knowledge and patterns. Figure 1 provides\nan overview of the proposed approach. In summary, our proposed\nretrieval-augmented small-scale language model significantly im-\nproves tKG forecasting. It achieves this by dynamically accessing\nand leveraging external, continually evolving diverse data sources.\nThis enhances the framework's utility in real-world applications,\nenabling it to generate historically accurate and well-explained fore-\ncasts. Experiments on real-world benchmark datasets demonstrate\nthe framework effectiveness."}, {"title": "2 PROBLEM FORMULATION", "content": "An tKG captures the dynamic evolution of entity relationships\nover time, unlike static KGs, which are fixed. Let $V$, $R$, $T$, and $F$\nsymbolize sets of entities, relations, timestamps, and facts, respec-\ntively. A tKG snapshot $G_{t_i} := \\langle V_i, R_i, F_i\\rangle$ at discrete timestamp $t_i$"}, {"title": "3 PROPOSED METHOD", "content": "SLA-tKGF framework utilizes RAG to enhance the capabilities of\nthe small-scale language model to predict future events in tKGs. We\nconstruct knowledge-infused prompts using historical tKG data,\nweb information, and PLLM-generated past entity relationship de-\nscriptions for zero-shot prompting the language model for reliable\nand trustworthy forecasting, outperforming conventional methods."}, {"title": "3.1 Web-Search-Driven Retrieval", "content": "In developing a RAG framework that leverages web-based informa-\ntion, a critical challenge is addressed: excluding future facts before\nevaluating the relevance of retrieved web passages to a query. This\napproach focuses on preprocessing web passages to identify and\nexclude sentences containing future facts relative to a specified\ntemporal threshold. This is achieved by using natural language pro-\ncessing techniques for sentence tokenization, temporal tagging, and\nresolving temporal expressions to absolute dates. By establishing a\nrelevance period based on the query context, the framework filters\nout sentences with temporal references beyond this period, ensur-\ning that only contextually and temporally relevant information\nis retained. Preparing the search data involves collecting various\ntypes of web content, parsing and chunking text, and embedding\ntext chunks using text-embedding model. Each natural language\nquestion (verbalized query) is embedded similarly, then compared\nto the stored retrieved chunks for semantic similarity, and the most\nrelevant chunks are integrated to generate an accurate response.\nBy filtering out future or irrelevant information, our approach en-\nhances the quality and reliability of real-time web information\nretrieval and generation."}, {"title": "3.2 Retrieving Relevant Historical tKG Data", "content": "We leverage the following multi-step methods to incorporate rele-\nvant historical information from dynamic tKGs. (a) Query Verbal-\nization: We convert structured queries $(s_q, r_q, ?, t_q)$ about future\nevents into natural language questions using PLLMs like GPT-4.\nThis allows the small-scale language model to interpret symbolic\nknowledge for forecasting tasks. For example, the query (Barack\nObama, visit, ?, 2015-01-25) can be verbalized as 'Which country did\nBarack Obama visit on January 25, 2015?. (b) Knowledge Retrieval &\nVerbalization: Historical events relevant to the verbalized query up\nto the target time $t_q$ from evolving tKGs are incorporated to improve\nforecasting accuracy. It improves forecasting by grounding queries\nin historical context by identifying recurring patterns, trends, and\ncausal relationships of the evolving entity relationships over time\nin graph-structured data. Motivated by the concept of window size\nin time series forecasting, which indicates the number of past obser-\nvations used to predict future values, we adopt a similar approach\nin tKG forecasting. For a query at target time $t_q$ with subject $s_q$\nand relation $r_q$, we retrieve \u2018m' prior tKG snapshots $G_{(t_q-m,t_q-1)}$\nas background knowledge. A knowledge-infused prompt is con-\nstructed from historical facts related to $s_q$. Assuming a set of \u2018M\u2019\nretrieved facts related to the query, we describe this as follows:\n$C_{(s_q,r_q,?,t_q)} = \\{(s_i, r_i, o_i, t_i) \\mid (s_i, r_i, o_i, t_i) \\in C_{(s_q,r_q,t_{q-m},t_{q-1})} \\cup C_{(s_q,t_{q-m},t_{q-1})} \\& t < t_q\\}_{i=1}^{M}$\nThis set is constructed by combining facts involving $s_q$ within\nthe time window $t_q - m$ to $t_q \u2013 1$, covering both facts directly related\nto $s_q$ and $r_q$(i.e., $C_{(s_q,r_q,t_{q-m},t_{q-1})}$), and those involving $s_q$ in any re-\nlation(i.e., $C_{(s_q,r_q,t_{q-m},t_{q-1})}$), but only prior to $t_q$. This approach\nenhances forecasting accuracy by providing a comprehensive view\nof $s_q$'s historical occurrences. (c) Irrelevant Knowledge Rejection:\nWe reject irrelevant facts using sentence embedding techniques,\nretaining only facts pertinent to the verbalized query based on\nsemantic similarity. We then inject relevant historical knowledge into\nprompts to anchor predictions within historical tKG data, enhancing\naccuracy. For the query (Barack Obama, visit, ?, 2015-01-25) verbal-\nized as 'What country did Barack Obama visit on January 25, 2015?',\nusing relevant historical facts like 'Barack Obama visited France\non June 5, 2014', 'Barack Obama visited Australia on November 15,\n2014', etc., construct a knowledge-augmented prompt for the small-\nscale language model's zero-shot prediction on tKG forecasting."}, {"title": "3.3 PLLMs-Generated Historical Summary", "content": "We query off-the-shelf PLLMs to generate a summary description\nof the historical entity relationships prior to the target time, based\non the parametric knowledge acquired during pretraining."}, {"title": "3.4 Overall Framework", "content": "We construct knowledge-augmented prompts for grounded and in-\nterpretable forecasts by uniquely combining the relevant historical\nknowledge from tKGs, contemporary data through web search, and\nhistorical entity relationship descriptions generated by off-the-shelf\nPLLMs, setting a foundation for trustworthy tKG forecasting. In"}, {"title": "4 EXPERIMENTS AND RESULTS", "content": ""}, {"title": "4.1 Datasets", "content": "We evaluate our framework with the following benchmark datasets:\nICEWS14[28], ICEWS18[4], ICEWS05-15[6], YAGO[23], and WIKI[17].\nThese diverse datasets, encapsulate real-world events in a quadruple\nformat. The ICEWS datasets offers geo-coded events for system-\natic analysis and prediction relating to political violence, insta-\nbility, and international relations from news reports over multi-\ndecade time periods. For example, a quadruple fact (s, r, o, t) such\nas (Barack Obama, visited, India, 2015-01-25). ICEWS14, ICEWS18,\nand ICEWS05-15 span events from 2014, january to october 2018,\nand 2005 to 2015, respectively. WIKI and YAGO, extracted from\nWikipedia [17] and YAGO3-10[23] knowledge graphs (KGs), cover\nhistorical facts formatted as (s, p, o, [Ts, Te]), with Ts and Te mark-\ning start and end times. Our paper adopts the method from previ-\nous work[13], for temporal fact discretization by breaking down\nmulti-timestamp events into consecutive single events, improving\naccuracy by isolating each event. Table 1 summarizes the dataset\nstatistics. We utilize a new dataset from the Armed Conflict Lo-\ncation & Event Data Project (ACLED)\u00b9, detailing crisis situations\nglobally. Our study targets hostility and aggression towards civil-\nians in Cabo Delgado from January 1900 to March 2022, with the\nperiod from October 2021 to March 2022 as the test phase. Following\nthe method in an earlier study[13], we split datasets into training,\nvalidation, and test sets chronologically with an 80%/10%/10% ratio,\nexcept ICEWS14, split 50%/50% due to no validation set. Splitting\nensures training precedes validation and testing. Notably, many\nentities in the test sets are new compared to those in training and\nvalidation. Our research categorizes two types of tKG forecast-\ning benchmarks: ICEWS datasets, featuring recurring short-lived\nevents, e.g., Xi Jinping visited the United States three times in 2015,\nand WIKI and YAGO datasets, capturing longer, non-recurring\nevents, e.g., Yossi Benayoun played for Chelsea FC from 2011 to 2013."}, {"title": "4.2 Prediction Settings", "content": "The tKG forecasting task has two primary prediction settings: (a)\nSingle Step: It uses recent historical tKG data within a predefined\nwindow size(m) to predict at the next time point, incorporating\nfacts up to time $t_q-1$ for predicting missing entities at time $t_q$. It\nutilizes actual historical data, not predictions from earlier points,\nto forecast at the next step. (b) MultiStep: It uses past framework\npredictions instead of ground truth facts for predicting missing\nentities at time $t_q$. These settings trade off computational cost,\naccuracy, and suitability for short-term or long-term forecasting."}, {"title": "4.3 Baseline Methods", "content": "Previous tKG forecasting research employed various methods for\nentity-relation modeling of historical events for missing entity pre-\ndiction in future events. These methods included graph neural\nnetworks (GNNs) [10, 11, 14, 20], reinforcement learning [25], and\nlogical rules [22, 35]. We benchmarked our tKG forecasting frame-\nwork against established methods like Distmult [33], TuckER [2],"}, {"title": "4.4 Evaluation Protocol", "content": "We evaluate our framework using standard metrics for the tKG\nforecasting task, specifically the Mean Reciprocal Rank (MRR) and\nthe Hits@K metric. For each quadruple $(s_q, r_q, o_q, t_q)$ in the test set,\nwe generate a query quadruple: $(s_q, r_q, ?, t_q)$ and the small-scale\nlanguage model will rank all entities $V$ in its predictions. The rank\nof the actual missing entity $o_q \\in V$ for each query quadruple is\ndenoted by $\\psi(o_q)$. The MRR evaluation metric is defined as follows:\n$MRR = \\frac{1}{\\mathcal{G}_{test}} \\sum_{q \\in \\mathcal{G}_{test}} \\frac{1}{\\psi(o_q)}$\nMRR measures the average ranking of the actual missing entities\nin the predictions, with a higher MRR indicating better performance.\nThe Hits@K metric (where K is in {1, 3, 10}) evaluates the accuracy\nof predicting missing entities at different positions in the predicted\nrankings. It measures the proportion of ground-truth missing enti-\nties ranked within the top-K positions, evaluating the framework's\nability to predict missing entities accurately. For the tKG forecast-\ning task, we consider time-aware filtering as the evaluation set-\nting to prevent valid predictions from being considered errors. For\nexample, consider a test query like (Barack Obama, visit, ?, 2015)\nwith the true answer being India. Other valid predictions, such\nas (Barack Obama, visit, Germany, 2015), might exist but would be\nremoved by the time-aware filter. It allows us to determine the rank\nof India without interference from alternative valid predictions."}, {"title": "4.5 Implementation Details", "content": "By employing a 'Tabula Rasa' approach-starting from a clean\nslate-the framework addresses the critical challenges of data leak-\nage in predicting future events in tKGs. Our orchestrated frame-\nwork workflow utilizes LlamaIndex[21] for the development of\nPLLMs-powered applications. We utilize DuckDuckGo's search en-\ngine for searching the web. We access PLLMs using a text-based\nhigh-level API through Language Model as a Service (LaMaaS, [26]).\nThe framework is trained on tKG forecasting, aiming to minimize\ncross-entropy loss and predict missing entities in future events.\nFramework hyperparameters include a batch size (b) set at 48, the\nnumber of epochs (ep) at 30, and the hidden/embedding dimension\n(d) at 128. The Adam optimizer ([15]) is employed with an initial\nlearning rate of 1e-3. A learning rate decay scheduler halves the\nlearning rate if the validation loss doesn't improve over 5 epochs,\nand early stopping is implemented to prevent overfitting. Four\nrepresentative off-the-shelf PLLMs used are GPT-4, GPT-3.5-turbo,\nGPT-3.0-text-davinci-003, and Google Bard. Framework hyperpa-\nrameters remain consistent across PLLMs and benchmark datasets,\ndemonstrating versatility. The context window (m) is set to 25 for\nknowledge injection of historical events from evolving tKG into the\nprompt, and the quadruple retrieval hop is set to one. No limit is\nimposed on the number of facts retrieved for knowledge injection.\nUtilizing 8 V100 GPUs, each with 8 GB of GPU memory, ensures\nefficient training. Due to high computational costs, experiments are\nrun three times, and averaged results from independent experimen-\ntal runs are reported in Tables 2, 3, and 4 for robust comparisons.\nRefer appendix for hyperparameter tuning results."}, {"title": "4.6 Results", "content": "Our study compared the proposed framework with various super-\nvised learning methods for tKG forecasting. Table 2 demonstrates\nthat SLA-tKGF W/GPT-4, outperformed baseline algorithms. We\nreport baseline results from prior research [7, 18] for fair and con-\nsistent comparison. Tables 3 and 4 provide further comparisons\nusing several popular baselines, with results reported from an ear-\nlier study[11]. Our experimental results confirm the effectiveness\nof SLA-tKGF framework in constructing knowledge-augmented\nprompts, involving: (1) retrieving historical knowledge from tKGs,\n(2) incorporating web search results for current information, and (3)\nusing pre-trained large language models for summarizing historical\nentity-relationships, to query the small-scale language model and\ngenerate accurate and interpretable forecasts."}, {"title": "4.7 Ablation Study", "content": "Given the complexity and multifaceted nature of the proposed\nSLA-tKGF framework for tKG forecasting, we propose several ab-\nlation experiments to evaluate the individual contributions of the\ncomponents and their effectiveness within the framework. Each of\nthese ablation studies can provide insights into the significance of\nthe individual components and their collective impact on the overall\nefficacy of the SLA-tKGF framework. To design ablation studies for\nthe SLA-tKGF framework, we systematically disable each compo-\nnent individually to evaluate its impact on the overall performance.\nThis approach helps in understanding the contribution of individual\ncomponents to the framework's accuracy, reliability, and robust-\nness. The ablation study aims to evaluate the contributions of three\nkey components in the framework for forecasting future events: (a)\nhistorical knowledge retrieval (HKR) from tKGs, (b) web search for\ncontextual information (WSCI), and (c) descriptive text generation\n(DTG) using PLLMs. The HKR component, which retrieves relevant\nhistorical knowledge from dynamic tKGs, is assessed by contrasting\nits performance when incorporated versus omitted. Similarly, the\nimpact of the WSCI component, providing up-to-date context prior\nto the target time through web search, is evaluated by disabling it\nand observing the changes in forecasting accuracy. The utility of\nthe DTG component, which utilizes PLLMs to analyze historical\nentity relationships to generate descriptive texts, is quantified by\nincluding or excluding it and observing the impact on forecasting\naccuracy. The ablated variants are as follows:\n\u2022 w/o HKR: Omits historical knowledge retrieval from tKGs.\n\u2022 w/o WSCI: Omits web search for contextual information.\n\u2022 w/o DTG: Omits PLLMs for descriptive text generation.\nTable 5 shows the ablation study results. The ablated variants\nperformance declines compared to the original framework (i.e.,"}, {"title": "4.8 Deep Dive into Long-term tKG forecasting", "content": "Existing tKG forecasting research often overlooks insights from\nedge dissolution and formation. Our work considers the creation\nand dissolution of relationships (edges) between entities in tKGs as\ncritical evolutionary factors for accurate tKG forecasting by captur-\ning the essence of how relationships evolve and change over time.\nNevertheless, the high dimensionality and dynamic complexity of\ntKGs pose challenges for both short and long-term event forecast-\ning. Our approach uses historical context within an evolving tKG\nto improve both short-term and long-term forecasting accuracy.\nShort-term forecasts predict near-future changes, capturing the\nimmediate evolution of events, while long-term forecasts antici-\npate broader trends that unfold over an extended period. Standard\ntKG forecasting relies on static KG snapshots, denoted as $G_{(t-t_m,t)}$,\nfrom a historical window m up until time t, to predict events at time\n$t + \\Delta t$ (e.g., one day). In real-world scenarios, the absence of graph\ninformation motivates the evaluation of forecasting techniques for\nmaking predictions about the distant future ($\\Delta T \\ge \\Delta t$). In the con-\ntext of long-term tKG forecasting, the objective is to predict missing\nentities at a future time $t + \\Delta T$, beginning with an initial forecast pe-\nriod from $t - t_m$ to $t + \\Delta t$. This initial forecast targets the short-term\nfuture, represented by $\\Delta t$. The forecasting process then extends into\nthe final forecast period, from $t + \\Delta t$ to $t + \\Delta T$, to focus on long-term\npredictions, where $\\Delta T$ signifies the extended future. Experimental\nresults on the ICEWS05-15 dataset, using SLA-tKGF W/GPT-4, for\ndifferent $\\Delta T$ values are shown in Table 6. As $\\Delta T$ increases (1 day\nto 8 days), performance declines in both single-step and multi-step\napproaches, indicating increased difficulty in predicting further\ninto the future. This decline in performance is attributed from the\nassumption that dynamics at $t + \\Delta t$ apply at $t + \\Delta T$. With larger\n$\\Delta T$, this assumption falters due to data distributional shifts and\nthe performance drops because of the lack of recent relevant historical\nfacts in the augmented prompt for accurate predictions at $t + \\Delta T$."}, {"title": "4.9 Inductive Link Prediction in tKGs", "content": "In real-world applications, new entities emerge over time, necessi-\ntating a tKG forecasting framework that generalizes well to unseen\ndata. An efficient framework must demonstrate robust generaliza-\ntion abilities to effectively handle new, unencountered entities. To\nevaluate this capability, we introduce the inductive link predic-\ntion task, which showcases the framework's ability to predict links\ninvolving unseen entities. This task involves selecting test"}, {"title": "6 ADDITIONAL EXPERIMENTS", "content": ""}, {"title": "6.1 The Impact of Temporal and Sequential\nInformation on the Zero-Shot tKG\nForecasting Task", "content": "The proposed framework, SLA-tKGF, introduces a novel two-pronged\napproach to predict future events in tKGs by combining a clean-slate\ntrained, small-scale language model with the Retrieval-Augmented\nGeneration (RAG) technique. It emphasizes accuracy and bias-free\npredictions by leveraging historical tKG data, current web infor-\nmation, and contextually relevant historical entity relationship\ndescriptions generated by PLLMs. We examined the performance of\nthe SLA-tKGF framework by understanding temporal information\nin retrieved historical events from tKGs, comparing its performance\nin the tKG forecasting task with and without explicit timestamps\nin the knowledge-augmented prompt. We also investigated the im-\npact of shuffling historical facts without time information on the\nperformance of the SLA-tKGF framework. The results, shown in Ta-\nble 8, reveal that the SLA-tKGF framework's performance worsens\nwithout temporal information. This decline is exacerbated by the\nrandom arrangement of events, as demonstrated in Table 9. These\noutcomes underscore the framework's dependence on chronologi-\ncal sequencing for accurate predictions, emphasizing the critical\nrole of temporal information and sequence in the accuracy of the\nSLA-tKGF W/GPT-4 framework for tKG forecasting. The consistent\nsignificance of temporal and sequence information across datasets\n(YAGO, WIKI, ICEWS14, ICEWS18, ACLED-CD22) reinforces the\nreliability and applicability of these findings."}, {"title": "6.2 Effect of Types of Knowledge-Infused\nAugmented Prompts on tKG Forecasting", "content": "In this section, we evaluate the impact of augmenting natural lan-\nguage questions(verbalized queries) with external knowledge from\nhistorical events sampled from tKGs on the sLA-tKGF W/GPT-4\nframework's performance in tKG forecasting tasks. We explore\nvarious knowledge retrieval strategies for constructing knowledge-\naugmented prompts, focusing on optimizing the framework's per-\nformance in tKG forecasting. Table 10 shows how different strate-\ngies affect the SLA-tKGF W/GPT-4 framework's performance across\ndatasets (YAGO, WIKI, ICEWS14, ICEWS18, ACLED-CD22) for\nSingle-Step and Multi-Step forecasting. The results demonstrate\nthat selectively incorporating relevant prior knowledge signifi-\ncantly enhances tKG forecasting performance, surpassing baselines\nthat either omit additional knowledge or use it indiscriminately.\n\u2022 The No Knowledge (NK) baseline applies the given query\nwithout external knowledge.\n\u2022 The Random Knowledge (RK) baseline constructs prompts\nwith randomly selected historical facts.\n\u2022 The Popular Knowledge (PK) baseline builds prompts us-\ning the most common relationship-based historical facts\nfrom the tKG.\n\u2022 The sLA-tKGF (Ours) framework selects the most pertinent\nhistorical facts for the query, excludes irrelevant facts, and\nuses this filtered knowledge for forecasting.\nOur experiments show that even randomly included historical\nfacts improve performance compared to not using any additional"}, {"title": "6.3 Balancing Accuracy and Efficiency:\nOptimizing Historical Context in\nAugmented Prompts for tKG Forecasting", "content": "Our framework utilizes historical events or facts from time ($t_q \u2013 m$)\nto $t_q$ to predict missing entities in the query quadruple at $t_q$, where\nm represents the historical context window size, a configurable\nhyperparameter. We experimented with various lengths to evaluate\nthe impact of historical context on the forecasting performance of\nthe SLA-tKGF W/GPT-4 framework for tKGs. According to Table\n11, leveraging a greater amount of past data to generate knowledge-\naugmented prompts for the small-scale language model enhances\nthe accuracy of missing entity predictions, as evidenced by im-\nproved mean reciprocal rank (MRR) scores, albeit at the expense of\nhigher computational demands. The small-scale language model\nwithin the SLA-tKGF W/GPT-4 framework is constrained by the\nmaximum input token sequence length. Although extending the\nhistorical window marginally increases MRR scores, it leads to the\ncreation of longer and more complex prompts that are impractical\nfor broad-scale application. To strike a balance between accuracy\nand computational efficiency, we selected a historical context win-\ndow of 25 for our experiments. We varied the historical facts in\nthe prompts to identify the optimal setup for generating accurate\nforecasts, with the goal of minimizing wall-clock time. Wall-clock\ntime for SLA-tKGF W/GPT-4 queries-the time elapsed from query\nsubmission to response-is influenced by the size of the small-scale\nlanguage model, the complexity of the query, and the available com-\nputational resources. While typically, small-scale language models\nreturn responses within seconds, more complex or extensive queries\nmay require longer processing times."}, {"title": "6.4 Study of tKG forecasting task with\nnon-uniform time intervals", "content": "Many state-of-the-art techniques struggle with tKGs featuring ir-\nregular time intervals, unlike the SLA-tKGF framework, which ef-\nfectively addresses this issue by leveraging knowledge-augmented\nprompting for small-scale language models in temporal KG fore-\ncasting. The framework excels in handling real-world complexities\nand data sparsity, capturing complex dynamics and causal rela-\ntionships more accurately, thus offering a versatile and reliable\nsolution for temporal KG forecasting. Experimental evaluations on\nthe ICEWS05-15_continuous dataset, a subset created by sampling\nfrom the original ICEWS05-15 dataset to simulate non-periodic ob-\nservations in continuous time with 1-4 units interval, support our\nclaim. The SLA-tKGF framework, trained on this benchmark and as-\nsessed using the Mean Reciprocal Rank (MRR) metric, demonstrates\nstrong performance, especially with the SLA-tKGF W/GPT-4 con-\nfiguration, on temporal KGs with irregular intervals. The dataset\nstatistics for ICEWS05-15_continuous are presented in Table 12.\nWe trained the SLA-tKGF framework with various off-the-shelf Pre-\ntrained Large Language Models (PLLMs) on this new benchmark"}, {"title": "6.5 Impact of Retrieved Fact Types", "content": "In this work, we introduce a zero-shot learning method to predict\nmissing entities in query quadruples. Our approach includes: (a)\nConstructing a historical context for a query quadruple $(s_q, r_q, ?, t_q)$\nusing historical facts from previous static KG snapshots $G_{tq-m:tq-1}$\nto form a knowledge-infused augmented prompt. (b) Converting\nretrieved facts and the query into verbalized sentences, employing\nsentence embedding for knowledge distillation, and using semantic\nsimilarity to filter facts, thereby constructing augmented prompts.\n(c) Estimating the missing entity conditioned on the augmented\nprompt, following $o_q \\sim P(o \\mid (s_q, r_q, ?, t_q), G_{(tq-m,tq-1)})$. We eval-\nuate the impact of single-subject entity and subject entity-relation\npair historical facts on forecasting accuracy. The former involves\nonly the subject entity ($s_q$), while the latter includes both the sub-\nject ($s_q$) and the relation ($r_q$). We examine these effects across"}, {"title": "6.6 Impact of Directionality in Historical\nModeling on tKG forecasting Performance", "content": "In the tKG forecasting task, \u2018unidirectional' refers to when the\nsubject entity ($s_q$) or subject-relation pair ($s_q, r_q$) from historical\nfacts matches their position in the query quadruple ($s_q, r_q, ?, t_q$).\n'Bidirectional' denotes cases where they can appear in any posi-\ntion. For bidirectional modeling, historical facts are transformed by\nswapping entities and inverting the relation, e.g., (s, r, o, t) becomes\n(o, $r^{-1}$, s, t). We use PLLMs such as GPT-4 to obtain reciprocal rela-\ntions, enhancing tKG forecasting by incorporating diverse historical\ncontexts. For instance, (Barack Obama, visit, India, 2015-01-25) be-\ncomes its reciprocal (India, visited by, Barack Obama, 2015-01-25).\nOur study evaluates the directionality's impact on the tKG fore-\ncasting, finding that bidirectional modeling slightly improves per-\nformance, notably on ICEWS datasets. The experimental results\nhighlight the value of appropriate relation modeling for SLA-tKGF\nW/GPT-4 in understanding context, offering modest performance\nboosts in tKG forecasting. Table 15 shows the experimental results."}, {"title": "6.7 Impact of PLLMs size", "content": "The SLA-tKGF framework leverages a blend of historical tKG data,\ncurrent web-scraped information, and contextually relevant de-\nscriptions of past entity relationships generated by pre-trained lan-\nguage models (PLLMs) to construct knowledge-augmented prompts.\nThese prompts query the small-scale language model to"}]}