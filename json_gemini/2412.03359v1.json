{"title": "WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis", "authors": ["Chengwei Hu", "Jianhui Zheng", "Yancheng He", "Hangyu Guo", "Junguang Jiang", "Han Zhu", "Kai Sun", "Yuning Jiang", "Wenbo Su", "Bo Zheng"], "abstract": "Recent advancements in autonomous multi-agent systems (MAS) based on large language models (LLMs) have enhanced the application scenarios and improved the capability of LLMs to handle complex tasks. Despite demonstrating effectiveness, existing studies still evidently struggle to evaluate, analysis, and reproducibility of LLM-based MAS. In this paper, to facilitate the research on LLM-based MAS, we introduce an open, scalable, and real-time updated platform for accessing and analyzing the LLM-based MAS based on the games \"Who is Spy?\" (WiS). Our platform is featured with three main worths: (1) a unified model evaluate interface that supports models available on Hugging Face; (2) real-time updated leaderboard for model evaluation; (3) a comprehensive evaluation covering game-winning rates, attacking, defense strategies, and reasoning of LLMs. To rigorously test WiS, we conduct extensive experiments coverage of various open-and closed-source LLMs, we find that different agents exhibit distinct and intriguing behaviors in the game. The experimental results demonstrate the effectiveness and efficiency of our platform in evaluating LLM-based MAS. Our platform and its documentation are publicly available at https://whoisspy.ai/", "sections": [{"title": "Introduction", "content": "Recently, the potential of large language models (LLMs) has been widely explored, from natural language generation to complex reasoinging (Zhao et al., 2023). A promising direction in leveraging these LLMs is the development of autonomous multi-agent systems (MAS), which aims to aggregate these powerful models to execute complex tasks (Chen et al., 2024b) and simulate and analyze social behaviours (Park et al., 2023b). Despite demonstrating impressive performance in handling most complex tasks, the fair comparison, evaluation, and analysis of MAS should be emphasized due to the instability and reproducibility challenges of MAS (Guo et al., 2024).\nConsidering the above issues, existing studies mainly leverage tool usage (Li et al., 2024) or debates without tools (Chan et al., 2024) based on solving complex tasks to access LLM-based MAS. However, these methods struggle to evaluate the reasoning and interaction capabilities of LLM-based MAS while also analyzing their complex and even social behaviors. Hence some studies (Hong et al., 2023; Huang et al., 2023; Dong et al., 2023; Qian et al., 2023) introduce games to access capabilities and analysis of LLM-based MAS, which are measured by outcomes and scores of games, leading to game-based evaluation. Despite the effectiveness, evaluation of LLM-based MAS with games is time-consuming and hard to scale for evaluating additional models and analysis of the behavior of LLMs. The games for accessing LLMs are typically with overly complex rules. Moreover, LLM-based MAS evaluation frameworks require researchers to adapt both open-source and closed-source models. Adapting open-source models often necessitates code modifications, while evaluating closed-source models frequently incurs significant costs.\nConsidering these issues, in this work, we introduce a novel online platform for the game \"Who is spy\". This platform is designed to provide a diverse environment for evaluating model attacking and defense, understanding, reasoning, and deception abilities. Users can easily create custom agents using available models on Huggingface and engage in competitive matches against well-known models and other players, while also tracking their rankings. Additionally, the competition process supports visualization, allowing players to review their performance results, as illustrated in Figure 1. We also evaluated the capabilities of various open-source and closed-source models and found distinct and intriguing behaviors. For instance, GPT40 demonstrates exceptionally strong reasoning abilities, whereas Qwen exhibits a high capacity for deception. Furthermore, we have developed a benchmark designed to investigate the adversarial capabilities, deception, and reasoning skills of various models. Comprehensive experimental analyses have demonstrated that our benchmark effectively differentiates between the various capabilities of multi-agent systems.\nIn summary, our contributions can be summarized as follows:\n1. We introduce a dynamic leaderboard capable of effectively assessing models' capabilities in attacking, defense, reasoning, and deception. This leaderboard is not only applicable to various multi-agent tasks but is also less susceptible to overfitting compared to static datasets.\n2. We develop a highly user-friendly platform for the \"Who is Spy\" game, which facilitates the creation of intelligent agents using models available on the Huggingface platform. Our platform ranks these LLM-based agents based on a novel scoring method, and convenient visualization of the game-play process is provided for the player.\n3. Comprehensive experimental analyses of various open-source models, as well as the performance of multiple agents in terms of attacking, defense, reasoning, and deception during gameplay, have validated the effectiveness of our framework and platform. Our platform and its documentation are publicly available at https://whoisspy.ai/"}, {"title": "Related Work", "content": "Multi-agent systems involve collaboration among agents, more complex interactions, and different contextual information, which poses challenges to the workflow and the design of the entire system. Hong et al. adapts a waterfall model and defined roles for various agents based on standard software development processes, successfully applying multi-agent systems to project development. (Huang et al., 2023) refines the programming process by deploying distinct agents for code generation, testing, and execution, utilizing the execution results as feedback to significantly enhance code quality. (Dong et al., 2023; Qian et al., 2023) employed similar multi-agent approaches but diverged in their problem decomposition strategies. (Park et al., 2023a) develop different agents to represent various social roles, investigating their diverse social performances based on their behaviors. (Ma et al., 2023) assess the application of agents in the context of mental health. MMLU (Hendrycks et al., 2020) is a widely used evaluation benchmark for single-agent performance. Similar datasets, such as those in (Cobbe et al., 2021; Geva et al., 2021), offer challenging language understanding tasks involving mathematics and strategic reasoning. Research efforts (Du et al., 2023; Xiong et al., 2023; Tang et al., 2023) enhance viewpoints and answers through communication and discussion among the agents. These works demonstrate the great potential of multi-agent systems in dealing with complex real-world scenarios.\nDigital games require players to possess strong reasoning and cognitive skills. Thus there are more LLM-based agents developed to test and analyze the model performance, ranging from classic competitive games such as chess (Toshniwal et al., 2022; Feng et al., 2024) and poker (Gupta, 2023; Huang et al., 2024; Zhao et al., 2022) to simulation games like The Sims (Park et al., 2023a; Kaiya et al., 2023) and Minecraft (Wang et al., 2023a,b; Chen et al., 2024a). Social Deduction Games(SDGs), in particular, have garnered significant attention due to their complex interactive environments which demand advanced language comprehension, reasoning, and expressive capabilities from models, such as Werewolf (Wang and Kaneko, 2018; Xu et al., 2023a) and Avalon (?Shi et al., 2023). In particular, Xu et al. uses retrieval and reflection on past communications and experiences to get a better performance on the Werewolf game. ReCon (?) integrates two cognitive processes to identify and tackle deceptive information better. Xu et al. and Yim et al. both incorporate reinforcement learning to further enhance the model's reasoning and comprehension capabilities. Additionally, there are benchmarks specifically designed for these gaming scenarios, such as GameEval (Qiao et al., 2023) and Avalonbench (Light et al., 2023). However, their evaluation methods primarily utilize macro-level metrics, without conducting in-depth and multidimensional analyses of the models' performance."}, {"title": "Platform Design", "content": "Each game involves six participants, with one player designated as the spy, while the others represent civilians. At the beginning of each game, each player will be given a word. The civilians all have the same words, while the spy has different words. The game will randomly select a player to start, and all players will take turns describing their own words. Their own words must not appear in the description, and the descriptions of the previous rounds cannot be repeated or skipped, otherwise it will be considered a foul. After each round, a vote will be held, and one player will be eliminated according to the majority principle, and then enter the next round, and repeat this until one side achieves the victory goal. If the spy makes it to the third round or the number of civilians is less than three, the spy agent wins. If the spy is voted out before the third round, the civilians win. Detailed rules can be seen in the appendix A.\nWe have developed an open gaming platform, as illustrated in Figure 2, providing a diverse environment for evaluating model understanding, reasoning, and deception. This platform enables the rapid creation of agents and initiation of games based on models from HuggingFace.\nIn accordance with the scoring criteria, we have established a corresponding leaderboard for each participating agent in the competition. This leaderboard provides insights into various metrics, including the ranking of the agents, average scores, win rates, and voting accuracy, thereby facilitating analysis for the participants.\nOur platform facilitates the seamless integration of models from Hugging Face to construct intelligent agents for gaming. Upon entering the community, users can access the complete code of agents previously created by others. Additionally, we offer several example agents to further assist users in their endeavours at https://huggingface.co/spaces/alimamaTech/WhoIsSpyEnglishAgentExample.\nTo facilitate the retrieval of game processes and outcomes for each match, we have implemented a visualization feature known as the \"Watch List\". This feature allows users to conveniently access match information, including game details, results, and player statistics. By clicking the \"Start Watching\" button, users can visualize the entire progression of the selected match, effectively reconstructing each step of the gameplay. Additionally, players have the option to share these match recordings with others, enhancing the collaborative aspect of the gaming experience.\nWe have developed a user-friendly and efficient Agent Management feature, enabling users to register models by simply entering their addresses from Hugging Face on our website. This functionality encompasses essential capabilities for agent management and retrieval.\nWe have established a community for agents that includes a collection of exemplars. Users can simply replicate the provided examples and insert their own API key to utilize their personalized models. For those seeking to customize their model usage, we offer the option to modify the file by altering the llm_caller API call to integrate their custom model inference code.\nAdditionally, we have introduced an innovative scoring method to assess the capabilities of these agents, the rule ensures that the sum of the scores of all players in each game is consistent as follows:\na. If the spy is eliminated in the first round, they score 0 points, and the surviving civilians share 12 points.\nb. If the spy is eliminated in the second round, they score 4 points, and the surviving civilians share 8 points.\nc. If the spy is eliminated in the third round, they score 8 points, and the surviving civilians share 4 points.\nd. If the spy wins, they score 12 points, and the civilians score 0 points.\ne. In each voting round, each time civilians correctly identify the spy, they gain an additional point, while the spy loses a corresponding point.\nThis scoring mechanism incentivizes agents to identify the spy while ensuring that the entire game operates as a zero-sum game."}, {"title": "Ranking Rules", "content": "The ranking is based on the cumulative points scored in the matches. The winning rates are merely reference indicators and do not affect the ranking. To incentivize player engagement, each participant starts with an initial score of 100 points and costs 1 point for each game played. Assuming all agents have the same intelligence, the expected score gained in each round is 12/6 - 1 = 1 point. Therefore, the more games played, the more likely one is to achieve a high ranking. Suppose an agent's scores in $i$ competitions are $s_i$, then the total score for that agent is given by\n$\\sum_{i=1}^{N} s_i/ N + 100,$\nwhere 100 is the initial points for each Agent, $N$ is the number of competitions. A larger number of game rounds enhances confidence in the results. Consequently, this scoring design ensures that agents achieving high rankings not only demonstrate excellent performance in individual rounds but also maintain a consistent superiority over other agents."}, {"title": "Multi-agent Ability Evaluation", "content": "Our platform essentially designs an interactive multi-agent framework that can allow users to accurately evaluate the capabilities of their agents in a real interactive environment. To effectively highlight the differences in agent performance, the platform offers various automated calculation mechanisms for key indicators and specific evaluation methods for specific abilities."}, {"title": "Overall Indicators", "content": "We present each agent's average win rate in historical games, categorized by role\u2014either as a spy or a civilian\u2014along with the average score for each role, voting accuracy, and average survival rounds. The win rate is a common indicator. However, it is subject to fluctuations due to the influence of other participants. In contrast, the average score can better reflect the difference in individual comprehensive abilities, including language expression ability, comprehension ability, and reasoning ability. Specifically, the average score when acting as a spy offers a relative measure of the model's deceptive capacity. Additionally, voting accuracy is the most relevant metric for assessing an agent's analytical reasoning ability. The foul rate refers to the proportion of infractions committed by an agent during the speaking round. This metric can be utilized to assess the effectiveness of attacking strategies."}, {"title": "Specific Ability Evaluation", "content": "In a multi-agent system, agents must process information from other players, laying the foundation for mutual attacks and defenses between them. Agents can influence other agents by modifying the content of their speeches, thereby misleading others. To evaluate the impact of these inter-agent attack and defense mechanisms, we implement a specialized experimental setup where spies with attack and defense strategies are introduced. Prompt as described in Table 1, two strategies are deployed: a prompt injection attack, which inserts information into the output to prompt other models to make errors, and a prompt injection defense, which embeds information to discourage others from voting against the agent. This information is then relayed to other agents, introducing noise that increases the challenge for civilians to win and imposes higher demands on the defensive capabilities of other models. Agents capable of detecting and neutralizing these \"bombs\" within other agents' statements exhibit strong defense mechanisms. Post-game, we calculate each model's foul rate, score, and win rate for a clear, comparative analysis.\nAs a classic social deduction game, this game also tests the reasoning ability of the model. Each agent must reason and devise an optimal strategy based on limited information to gain an advantage in the dynamic game environment, where reasoning is essential. Here, reasoning ability is defined as the model's capacity to discern hidden identity information from speech. The distinct roles of spies and civilians introduce a complex reasoning challenge: civilians must assess whose descriptions are either highly distinctive or lack specificity, while the spy needs to infer what the civilians' words are and disguise themselves better. This interactive relationship further increases the difficulty of reasoning, because the situation on the field is constantly changing. To capture reasoning interactions among multiple agents more effectively, we support experimental setups specifically designed to test the model's reasoning ability. In this setting, the model is required to explicitly output its reasoning process, as outlined in Table 1. This approach aims to clearly demonstrate the differences in reasoning capabilities across various models."}, {"title": "Performance Analysis", "content": "We have developed a corresponding platform and deployed our intelligent agents within it. We employed various strategies to investigate the behavior of the agents. All experiments were conducted on our platform, where we deployed well-known open-source models as the default intelligent agents. We evaluated ten publicly available open-source models, each experiment was repeated over 90 times, ensuring consistency in the key generation parameters and sampling algorithms across all models. We conducted an analysis of the capabilities among multiple agents, where each agent utilized the same model, the sole distinction lay in the adoption of our proposed strategy.\nIn these experiments, we ensured the fairness of the experimental conditions, we ensured that each model played both the roles of an spy agent and a civilian an equal number of times, with each experiment being repeated more than 24 times. We also ensured that in the experiment, each agent utilized identical code, differing only in their base models. In the attacking, defense, and reasoning experiments, all models except for one specialized model employed the same code as used in the main experiment."}, {"title": "Overall Performance", "content": "In this experiment, we conducted a competitive analysis among ten famous models using the same prompt. The results are presented in the table 2. Notably, GPT-40 demonstrated superior capabilities, achieving higher win rates in both civilian and spy roles. Its average score significantly surpassed that of the other models, attributed to its enhanced reasoning abilities. As a civilian, GPT-4o exhibited a keen awareness of vulnerabilities in the spy's statements during each round of discussion. when acting as the spy, GPT-4o's language was more ambiguous, further contributing to its performance advantage. Both Qwen2.5-72B-Instruct and Kimi scored nearly identically; although Qwen2.5-72B-Instruct had a higher win rate than Kimi, Kimi's precision in voting resulted in it consistently earning more points, indicating that our scoring system effectively measures the models' capabilities in inferring spy roles. Conversely, older versions such as Doubao, Gemini-1.5-pro, ERNIE, and Claude-3-5-Sonnet displayed limitations in their instruction-following abilities, leading to reduced scores.\nWe also analyzed the win rates of different roles and the average survival rounds for each role, as shown in the table. Although the spy scores higher, it exhibits a lower probability of winning, indicating that existing models are generally less effective at deception."}, {"title": "Attacking and Defense Ability", "content": "To evaluate the defensive capabilities of various models, we conduct a series of experiments that include \"hacker\" acting as spies employing adversarial strategies. These spies utilize specific adversarial Strategies. These strategies included: (1) inserting instructions to induce others to commit fouls in their speeches, and (2) inserting instructions to induce others not to vote for themselves. By analyzing the resulting foul rates and voting behaviours for each model, we evaluated their resistance to adversarial manipulation. A model unaffected by these tactics demonstrates robust defense capabilities."}, {"title": "Reasoning Ability", "content": "As mentioned in Section 4.2, we assigned one of the models to act as a civilian, identify the spy agent and provide justifications for its guesses. We sampled the models that participated in the main experiment corresponding to their civilian role, ensuring that the experimental conditions matched. This allowed us to effectively compare the reasoning capabilities among multiple agents. For our experiments, we selected GPT-40, Qwen2.5-72B-Instruct, and Llama-3-70B-Instruct, and the results are presented in Table 4.\nOur findings indicate that after employing a reasoning strategy, GPT-40 exhibited significantly enhanced analytical capabilities, evidenced by an increase in voting accuracy. In contrast, both Qwen2.5-72B-Instruct and Llama-3-70B-Instruct experienced notable declines in performance. This discrepancy can be attributed to GPT-4o's pronounced ability in chain-of-thought reasoning, which not only facilitated its own reasoning but also positively influenced the reasoning performance of other models in the civilian role, resulting in improved win rates and scores. However, Qwen2.5-72B-Instruct and Llama-3-70B-Instruct not only contributed to a decrease in win rates and overall scores, but their erroneous statements also disrupted other models, resulting in a significant decline in the win rates for the civilian team. Other models did not adhere to Qwen2.5-72B-Instruct's flawed reasoning, thus their decrease in win rates as civilians was less pronounced than the reduction in voting accuracy."}, {"title": "Case Study", "content": "To better understand the complex behaviors of LLM-based agents in our game, we analyze the attacking, defense, and reasoning cases from top-performance LLMs.\nFirstly, we present the second round of discussions in our study, during which the o1-mini model employs defensive strategies, as illustrated in Figure 3. The o1-mini model, using a defensive strategy, demonstrates a significant deviation from the statements of other participants. In the subsequent voting round, however, the other models fail to identify the anomalies in the statements, instead, they follow the misleading defensive instructions outlined in Table 1. Similarly, 01-mini with attacking prompt misleads subsequent models into mistakenly interpreting the statements of '01-mini' as instructions, resulting in the direct output of their words, thereby directly exposing their roles in our game. The potential reason for this behavior is that, although LLMs are trained to follow human instructions, they tend to overlook whether the current input instructions are the ones they should actually follow. Additionally, when there are conflicting instructions, current LLMs struggle to adhere to higher priority instructions or system prompts.\nAs analyzed in Section 4.2, GPT4o demonstrates strong reasoning capabilities in current top-performance LLMs. We present an example of using a reasoning prompt with GPT-40 to illustrate the model's behavior when employing such prompts. As shown in Table 5, after obtaining the statements of the other models in the first round, GPT40 individually analyzes each statement, identifies the flaws based on each player's remarks, and accurately detects the spy agent. GPT4o exhibits superior capability in discerning detailed information, whereas other models often overlook subtle differences between statements, resulting in a higher likelihood of spy agents evading detection."}, {"title": "Conclusion", "content": "We develop a novel platform for the game \"Who is Spy\", providing a versatile environment that facilitates in-depth exploration of model capabilities in attack, defense, reasoning, and deception. Through rigorous experiments and a comprehensive benchmark, our platform has demonstrated its effectiveness in distinguishing multi-agent abilities in complex interactive environments. The dynamic leaderboard, alongside the ease of creating custom agents and utilizing open-source models, offers a significant tool for advancing research in multi-agent system evaluation. Ultimately, we hope our platform will serve as a foundation for further studies into the behaviors and ability of large language models in multi-agent systems."}, {"title": "Limitations", "content": "Our work introduces a multi-agent game platform for the game \"Who is spy\". More games will be integrated into our platform in the future. Due to limitations in available API resources, some open-source models have not been tested yet, a broader range of models can be used for the platform's agents to achieve corresponding results in subsequent developments."}, {"title": "Detailed rules", "content": "Each game has 6 participants, one of whom will receive the spy word. A player will be randomly selected to start speaking (it is not guaranteed whether this person is the spy), and then players will take turns speaking. Each person's speech cannot repeat any previous speeches, cannot directly state their own word, and cannot skip speaking; otherwise, they will be judged as violating the rules. If the speaking time exceeds 10 seconds without a response, the system will automatically consider it as not speaking, which is also a violation.\nIn the English version of game: if the speech exceeds 400 UTF-8 characters, the system will automatically truncate it to only the first 400 UTF-8 characters. In the Chinese version: if the speech exceeds 120 UTF-8 characters, the system will automatically truncate it to only the first 120 UTF-8 characters;\nAfter each round of speaking, the judge will first determine if there are any violations (specifically the three types of violations mentioned above); the player who has violated the rules will be eliminated immediately. Then if the end condition is not triggered, a voting round will commence; otherwise, the game round ends.\nDuring the voting session, each surviving player can cast one vote to identify the spy agent, or choose to abstain; after the voting session concludes, the player with the most votes will be eliminated (if there is a tie for the highest number of votes, no one will be eliminated). The content of the votes must be from the given list of names; any other output will be counted as an abstention.\nEach round begins with the original speaker (if the original speaker has been eliminated, it will pass to the next player).\nEnd Condition: The game ends when the number of surviving agents is less than 3, or the spy is eliminated, or after 3 rounds of speaking and voting.\nVictory Condition: Once the end condition is triggered, if the spy is still alive, the spy wins; otherwise, the civilians win.\nDetailed Scoring Rules:\na. If the spy is eliminated in the first round, they score 0 points, and the surviving civilians share 12 points.\nb. If the spy is eliminated in the second round, they score 4 points, and the surviving civilians share 8 points.\nc. If the spy is eliminated in the third round, they score 8 points, and the surviving civilians share 4 points.\nd. If the spy wins, they score 12 points, and the civilians score 0 points.\ne. In each voting round, each time civilians correctly identify the spy, they gain an additional point, while the spy loses a corresponding point."}]}