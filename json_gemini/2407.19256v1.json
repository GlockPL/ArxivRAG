{"title": "Stochastic Parrots or ICU Experts? Large Language Models in Critical Care Medicine: A Scoping Review", "authors": ["Tongyue Shi", "Jun Ma", "Zihan Yu", "Haowei Xu", "Minqi Xiong", "Meirong Xiao", "Yilin Li", "Huiying Zhao", "Guilan Kong"], "abstract": "With the rapid development of artificial intelligence (AI), large language models (LLMs) have\nshown strong capabilities in natural language understanding, reasoning, and generation,\nattracting amounts of research interest in applying LLMs to health and medicine. Critical care\nmedicine (CCM) provides diagnosis and treatment for critically ill patients who often require\nintensive monitoring and interventions in intensive care units (ICUs). Can LLMs be applied\nto CCM? Are LLMs just like stochastic parrots or ICU experts in assisting clinical decision-\nmaking? This scoping review aims to provide a panoramic portrait of the application of LLMs\nin CCM. Literature in seven databases, including PubMed, Embase, Scopus, Web of Science,\nCINAHL, IEEE Xplore, and ACM Digital Library, were searched from January 1, 2019, to\nJune 10, 2024. Peer-reviewed journal and conference articles that discussed the application\nof LLMs in critical care settings were included. Studies were excluded if they did not address\nLLMs in CCM or were non-English publications. From an initial 619 articles, 24 were selected\nfor final review using a standard scoping review methodology. After a rigorous examination,\nthis review grouped applications of LLMs in CCM into three categories: clinical decision\nsupport, medical documentation and reporting, and medical education and doctor-patient\ncommunication. Compared to traditional AI models, LLMs have advantages in handling\nunstructured data and do not require manual feature engineering. Meanwhile, applying\nLLMs to CCM faces challenges, including hallucinations and poor interpretability, sensitivity\nto prompts, bias and alignment challenges, and privacy and ethics issues. Future research\nshould enhance model reliability and interpretability, improve training and deployment\nscalability, integrate up-to-date medical knowledge, and strengthen privacy and ethical\nguidelines. As LLMs evolve, they could become key tools in CCM to help improve patient\noutcomes and optimize healthcare delivery. This study is the first review of LLMs in CCM,", "sections": [{"title": "1. Introduction", "content": "Critical care medicine (CCM), also called intensive care medicine, is an essential field\ndedicated to the management of severely ill patients, emphasizing rapid and life-critical\ndecision-making and interventions. CCM deals with patients who have severe conditions and\ninjuries such as sepsis, acute kidney injury (AKI), and acute respiratory distress syndrome\n(ARDS), potentially leading to a deteriorative state in the intensive care units (ICUs) [1].\nSepsis accounted for approximately 11 million deaths in 2017, making up about 20% of all\nglobal deaths [2]. The incidence of AKI in the ICU could reach up to 66% globally [3]. Among\nthose who received renal replacement therapy, some of the most critically ill individuals in\nthe ICU, the mortality rate was approximately 50% [3]. Recent studies [4, 5] found that the\nincidence of ARDS in the ICU was about 10%, and the ICU mortality of ARDS was\napproximately 35% in high-income countries. While in resource-limited settings, the ICU\nmortality of ARDS could be as high as 50% due to the disparities in healthcare quality [4].\nThe aging of the population and the deterioration of the living environment continue to pose\nnew challenges to human health [6, 7], and there is a substantial rise in the demand for\nintensive care services [8]. The physicians and nurses in ICUs need to deal with large amounts\nof patient data and maintain high efficiency under high pressure [4, 9]. Critical care's\ndynamic and severe nature demands intelligent decision-support tools that can help\nphysicians improve diagnostic accuracy, optimize therapeutic strategies, and provide timely\nclinical decision-making.\nArtificial intelligence (AI) technologies, especially generative AI models, have developed\nrapidly in recent years. The advent of large language models (LLMs), such as those based on\nthe Transformer architecture [10] and pre-trained on extensive text corpora, has marked a\nsubstantial advancement in natural language processing (NLP). With billions of parameters,\nthese LLMs have demonstrated remarkable capabilities in understanding and generating\nhuman-like text [11]. LLMs have been implemented in different contexts, such as answering\nquestions, summarizing texts, and participating in open-domain conversations [12]. Among\nthese LLMs, OpenAI's ChatGPT [11] has become a focal point since its launch in November\n2022. Originating from the GPT series, this AI-driven chatbot utilizes a blend of supervised\nand reinforcement learning strategies. Its rapid adoption indicates the growing curiosity and\nreliance on such technologies to streamline communication and decision-making processes.\nWith the advancement of AI technologies, OpenAI then quickly introduced upgraded\nversions of ChatGPT, GPT-4, GPT-40, and GPT-40 mini in 2023 and 2024, offering enhanced\nmultimodal capabilities to handle diverse inputs like text, images, and table files.\nDespite the origins of LLM models not being directly tied to health and medicine, the\nflexibility of LLMs has allowed them to become valuable assets in medical settings, providing"}, {"title": "2. Overview of LLMs in Health and Medicine", "content": "LLMs have transformed numerous fields through their unprecedented capabilities in\nunderstanding and generating natural language. Generally, LLMs refer to Transformer-based\nlanguage models containing hundreds of billions or more parameters, trained on vast\namounts of text data. Typical examples include GPT-3 [22], PaLM [23], and LLaMA [24]."}, {"title": "2.1 Evolution of LLMS", "content": "The evolution of LLMs represents a complex and progressive journey intertwined with the\nadvancements in generative models, sequence models, and pre-trained language models. The\ndeveloping course of LLMs is shown in Figure 1.\nGenerative Models Initially, research in this domain concentrated on generative models\n[25] for generating text [26], images [27], audio [28], and other AI-generated content [29]\nthat closely resemble the training data. Generative adversarial networks (GANs) [30] and\nvariational autoencoders (VAEs) [31] were typical generative models for text generation,\nmachine translation, and image synthesis. These models aim to generate new examples with\na similar distribution as the training set. However, their performance may be constrained by\nthe availability of large-scale training datasets and the computational resources required for\nmodel training.\nSequence Models Sequence models operate on the principle that each word or token in a\nsequence can be predicted based on the preceding tokens [32]. The term \"sequence\" refers to\nthe method of processing and predicting data sequences. The Transformer architecture is an\nimportant milestone in the development of sequence models. It relies on a self-attention\nmechanism, allowing the model to weigh the importance of different words in each sequence\nto make predictions. Compared to recurrent neural networks (RNNs) [33] or long short-term\nmemory networks (LSTMs) [34], Transformers can capture dependencies across the entire\nsequence more effectively, and they have become the backbone of many state-of-the-art\nLLMs.\nPre-trained Language Models As an early attempt, ELMo [35] captured context-aware\nword representations by pre-training a bidirectional LSTM network and subsequently fine-\ntuning it for specific downstream tasks. BERT [36] was developed based on the highly\nparallelizable Transformer architecture with self-attention mechanisms and pre-trained by a\nbidirectional language model on a large-scale unlabeled corpus. A \"pre-training and fine-\ntuning\" learning paradigm was developed in pre-trained language models (PLMs) and has\ninspired extensive follow-up research, which introduces different architectures such as GPT-"}, {"title": "2.2 Applications of LLMs in Health and Medicine", "content": "LLMs exhibit substantial potential in different medical decision-making scenarios, including\nclinical decision support, medical document summarization, doctor-patient communication,\nand medical research. In clinical practice, LLMs can be utilized to provide supplemental\ntreatments and diagnoses across different departments, such as internal medicine [13],\nsurgery [42, 43], radiology [44, 45], and ophthalmology [46, 47]. The capabilities of\nsummarizing and rephrasing information enable LLMs to generate detailed discharge\nsummaries [48], radiology reports [49, 50], and other related medical documents, thereby\nreducing physicians' administrative burden. Furthermore, LLMs can automatize the\ninternational classification of diseases (ICD) coding process by extracting medical terms from\nclinical notes and assigning corresponding ICD codes, helping to improve coding efficiency\nand accuracy [51, 52]. The strong natural language understanding and generation capabilities\nof LLMs enable them to answer questions from patients with prostate cancer [53], nasal\ndiseases [54], and liver cirrhosis [55], and can also provide emotional support to patients or\ncaregivers [56]. ChatGPT has shown greater empathy than doctors when responding to\npatient inquiries [57]. In medical research, LLMs can serve as tools for literature retrieval\nand analysis [58], drug design and discovery [59], medical image segmentation [60], and\nmedical language translation [61]. Utilizing LLMs for literature review and data analysis can\nhelp accelerate the research progress. Overall, applying LLMs in medicine can help improve\nclinical efficiency, support doctor-patient communication, and accelerate research progress\nto advance health and medicine."}, {"title": "3. Methods", "content": ""}, {"title": "3.1 Study Design", "content": "This study was conducted using a scoping review methodology, which is particularly well-\nsuited for fields where the research topics are complex and varied. The methodology followed\nthe structured five-stage approach proposed by Arksey and O'Malley [62, 63], which\nencompasses Stage 1, Identifying the Research Question; Stage 2, Identifying Relevant\nStudies; Stage 3, Study Selection; Stage 4, Charting the Data; and Stage 5, Collating,\nSummarizing, and Reporting Results. This study aimed to provide a comprehensive review\nof the application of LLMs in CCM."}, {"title": "3.2 Literature Search Strategy", "content": "To comprehensively investigate the applications of LLMs in CCM, we conducted the literature\nsearch across seven databases, including PubMed, Embase, Scopus, Web of Science, CINAHL,\nIEEE Xplore, and ACM Digital Library, for Stage 2 Identifying Relevant Studies. The time\nframe for our search spanned more than five years, from January 1, 2019, to June 10, 2024,\nencompassing the period since the emergence of LLMs in the field.\nOur search strategy was meticulously designed by synthesizing keywords related to LLMs and\n\u0421\u0421\u041c [18, 64-67]. Keywords related to large models included \"Large Language Model\", \"LLM\",\n\"Generative Pre-trained Transformer\", \"GPT\", \"Generative Artificial Intelligence\", and\n\"Generative AI\". For CCM, the keywords included \"Critical Care\", \"Intensive Care Units\",\n\"Critical Illness\", \"Intensive Care\", and \"ICU\". All these terms were combined using the \"OR\"\nand \"AND\" logical operators to ensure the retrieval of literature that addresses both research\nareas. The detailed search terms for each database are provided in Table 1."}, {"title": "3.3 Study Selection", "content": "The process of Stage 3 Select Studies in this scoping review was conducted to ensure\ncomprehensive coverage and relevance of the included literature. We undertook the study\nselection under the Preferred Reporting Items for Systematic Reviews and Meta-Analyses\n(PRISMA) framework [68].\nInclusion Criteria: In the first phase of the study selection, literature was included based\non the following criteria: (1) relevant to LLMs and CCM. These studies explicitly used or\ncommented on LLMs relevant to the field of CCM. (2) original research papers from peer-\nreviewed journals and conferences. (3) written in English.\nExclusion Criteria: Studies were excluded from the review if they met any of the following\nconditions: (1) irrelevant to LLMs or CCM. These studies did not focus on applying LLMs\nwithin the realm of CCM. (2) conference abstracts, preprint articles, books, patents, editorials,\nand review papers. (3) non-English literature.\nThe initial literature screening involved a review of titles, abstracts, and keywords by two\nindependent reviewers (T.S. and Z.Y.). This first step was designed to eliminate irrelevant\narticles based on the inclusion and exclusion criteria. Articles that passed this preliminary\nfilter were subjected to a more detailed full-text review. The same reviewers thoroughly\nchecked the full articles during this second phase to confirm their eligibility. Discrepancies\nbetween reviewers at any stage of the selection process were resolved through discussion. A\nthird reviewer (G.K.) was consulted to make the final decision if a consensus could not be\nreached."}, {"title": "3.4 Keyword Co-occurrence Network Analysis", "content": "Keyword co-occurrence network analysis [69] is a bibliometric method used to explore the\nrelationships between keywords in academic papers. It involves constructing a network\nwhere nodes represent keywords and edges represent the co-occurrence of these keywords\nwithin the studied documents. It helps to identify the main research themes, trends, and\npotential research gaps by analyzing the frequency and patterns of keyword co-occurrences.\nThis study used the VOSviewer (v1.6.20) software [70] to construct the bibliometric network\nusing a clustering algorithm based on the visualization of similarity (VOS) method [71]. The\nsoftware automatically extracts Keywords from a publication's title, abstract, or author-\nsupplied keyword list. The frequency of co-occurrences of two keywords is determined by the\nnumber of publications in which both keywords appear together in the title, abstract, or\nkeyword list. The VOS method starts by calculating the similarity between publications'\nkeywords based on co-occurrence. Finally, a matrix used to arrange keywords spatially is then\nconstructed according to their mutual similarities."}, {"title": "4. Results", "content": ""}, {"title": "4.1 Literature Search Results", "content": "This scoping review covered publications in the seven major databases from January 1, 2019,\nto June 10, 2024, and initially retrieved 619 articles. The study selection process is presented\nin Figure 2.\nThe application of LLMs in CCM is a relatively innovative field, but research is still lacking,\nand the overall number of articles is relatively small. Finally, 24 articles met all the inclusion\ncriteria and were chosen for this review. The research contents and publication details of the\nincluded studies are documented in Table 2."}, {"title": "4.2 Bibliometric Analysis", "content": ""}, {"title": "4.2.1 Key Characteristics of Literature", "content": "This scoping review included a focused selection of 24 articles, providing a global perspective\non applying LLMs in CCM. This diverse corpus spans several countries, demonstrating\nwidespread research interest in applying LLMs in CCM.\nCountry The distribution of the selected publications indicates substantial international\ncollaboration and research efforts. We analyzed the countries where each selected article's\nfirst and corresponding authors were based. The authors from the United States took the lead\nin most studies (n=11, 45.8%), followed by authors from Israel (n=2, 8.33%), and individuals\nfrom Argentina, Belgium, China, Germany, Ireland, Italy, Japan, Korea, Saudi Arabia, Spain,\nand Switzerland, each contributing one article. It revealed that nearly half of the studies were\nconducted in the United States, with much fewer contributions from other countries and\nregions. This indicates a concentration of research activities in applying LLMs in CCM within\nthe United States, potentially reflecting the advanced development and adoption of AI\ntechnologies in American critical care settings.\nArticle Type Regarding the type of publications, most were original research articles (n=20,\n83.3%), reflecting strong empirical research interest in applying LLMs in CCM. Three letters\n(12.5%) and one perspective article (4.2%) supplemented this.\nLLMs in Utilization GPT-4 appears most frequently, cited in 18 articles (75%),\ndemonstrating its relevance and recent prominence in CCM applications. Other models\ninclude ChatGPT-3.5 (n=11, 45.8%) and models like Bard, Gemini, and Claude-2,\nhighlighting the breadth of generative models explored in the included studies."}, {"title": "4.2.2 Keyword Co-occurrence Network", "content": "As shown in Figure 3, 131 unique keywords were extracted from the literature using the\nVOSviewer software, among which \"artificial intelligence\" emerged as the most frequently"}, {"title": "4.3 Applications of LLMs in CCM", "content": ""}, {"title": "4.3.1 Clinical Decision Support", "content": "This section discusses the focus of LLMs in CCM for clinical decision support, focusing on\ntheir involvement in prehospital and in-hospital critical care, as illustrated in Figure 4.\nPrehospital During the prehospital phase, LLMs can assist pre-hospital rescuers in\nproviding patient education and clinical risk stratification. Bushuven et al. [72] employed\nChatGPT-3.5 and GPT-4 to support clinical decision-making in prehospital basic life support\nand pediatric advanced life support scenarios using 22 case vignettes that were developed and\nvalidated by five emergency physicians. The primary purpose of LLMs in their study was to\nrecognize emergencies and offer valid advice to lay rescuers. It was found that although both\nmodels correctly identified the emergency in most cases (94%), they only advised calling\nemergency services in 54% of the scenarios. Additionally, LLM-provided first aid instructions\nwere correct in 45% of the cases, while 3 of 22 cases (13.6%) LLM-generated advanced life\nsupport techniques were incorrect. These findings indicated that the validity, reliability, and\nsafety of ChatGPT/GPT-4 as an emergency support tool were questionable. However,\nwhether humans would perform better in the same situation was uncertain, and further\nevaluation of LLMs' context sensitivity and adaptability is needed.\nLLMs can be applied in triage, diagnosis, treatment planning, and prognosis prediction in in-\nhospital critical care settings.\nTriage Frosolini et al. [91] assessed the feasibility of LLMs in triaging complex maxillofacial\ntrauma cases. In their study, patient records from a tertiary referral center were used, and\nthe triage suggestions provided by ChatGPT-4 and Gemini were compared against the real-\nworld recommendations at the study center. They found that the recommendations given by\nthe LLMs were generally consistent with those given by the referral center, with ChatGPT\nachieving higher consistency in treatment recommendations and specialist consultations\ncompared to Gemini."}, {"title": "4.3.2 Medical Documentation and Reporting", "content": "LLMs are making strides in medical documentation and reporting by automatizing and\nstreamlining these processes. Doshi et al. [89] used four LLMs (ChatGPT-3.5, GPT-4, Bard,\nand Bing) to simplify the process of producing radiology report impressions (RRI). Utilizing"}, {"title": "4.3.3 Medical Education and Doctor-Patient Communication", "content": "LLMs are utilized more and more frequently in the medical education field now. One\nimportant area closely connected to LLMs is to generate or answer questions in the medical\nexam. Guillen-Grima et al. [82] evaluated the performance of GPT-3.5 and GPT-4 in\nnavigating the Spanish Medical Residency Entrance Examination. The study gauged overall\nperformance, analyzed discrepancies across medical specialties, and distinguished between\ntheoretical and practical questions. The results showed that GPT-4 significantly\noutperformed GPT-3.5, achieving an 86.81% correct response rate in Spanish and performing\nslightly better with English translations. Igarashi et al. [86] assessed the performance of GPT-\n4 on the Japanese Emergency Medicine Board Certification Examinations over five years.\nThe LLM was tasked with answering text-based and scenario-based questions, achieving an\noverall correct response rate of 62.3% and a substantial agreement rate (kappa = 0.70)\nbetween repeated responses. Tran et al. [87] tested the performance of ChatGPT-3.5 on the\nAmerican Board of Surgery In-Training Examination preparation questions. Using 200\nrandomly selected general surgery multiple-choice questions, ChatGPT achieved a correct"}, {"title": "5. Discussion", "content": "With the recent advent of LLMs, the field of CCM has witnessed groundbreaking\ndevelopments and advancements [95]. At present, there are many review articles focusing on\nthe application of LLMs in health and medicine [16-18], and there are also many review\narticles on AI in CCM [65-67], but few review articles focusing on the application of LLMs in\nCCM, except for some editorials and letters [1, 96]. The primary objective of this scoping\nreview is to provide a comprehensive portrait of the applications of LLMs in CCM, identifying\nthe advantages, challenges, and future research directions of this area. An extensive\nexamination of the selected literature revealed that LLMs hold substantial promise for\ntransforming clinical practice and improving patient outcomes in CCM. The current\napplications, together with the challenges and future directions of LLMs in CCM identified\nby this review, are shown in Figure 5."}, {"title": "5.1 Advantages", "content": "The application of LLMs in CCM has demonstrated numerous advantages. Compared to\ntraditional machine learning techniques, using LLM technology in CCM reveals that LLMs\ncan effectively understand and generate natural language, which can aid clinicians in writing\npatient medical records and diagnostic notes [76, 89, 92, 97]. The capabilities of LLMs extend\nbeyond text interpretation and generation. They surpass traditional machine learning\nmethods in unstructured data handling. LLMs can learn directly from extensive patient data\nwithout manual feature engineering. Moreover, multimodal LLMs can learn and understand\nmedical images, such as X-rays and CT scans [18].\nIn clinical practice, LLMs can extract critical information from a patient's historical medical\nrecords and combine it with the latest medical research, aiding physicians in identifying rare\ndiseases or those with early symptoms that are not clearly defined [98]. For medical research,\nLLMs can assist researchers in summarizing data and information in literature research and\nproviding suggestions for manuscript structure, references, and titles, enhancing the\nreadability and completeness of texts [76]. LLMs have a wide range of knowledge so that they\ncan provide physicians with a comprehensive analysis for decision-making across different"}, {"title": "5.3 Challenges", "content": "Currently, LLMs face some challenges in their applications in the field of CCM.\nHallucinations and Poor Interpretability LLMs may produce hallucinations or\ngenerate information that does not correspond with facts [99]. In CCM, this may pose a high\nrisk to patient outcomes as incorrect recommendations may lead to incorrect diagnosis or\ntreatment plans, potentially endangering patient lives. Also, the decision-making processes\nof LLMs are typically opaque [17], making it difficult for users to track and understand how\nthe models extract features from input data and generate recommendations [100]. The lack\nof transparency about the sources of factual information further complicates the application\nof LLMs in clinical decision-making [74].\nSensitivity to Prompts LLM-generated outputs are highly sensitive to input prompts, and\ndifferent prompt strategies may affect the model's capabilities and performance [72]. The\nvariability in prompts may lead to inconsistent results, necessitating the analysis of multiple\niterations and varied prompts to ensure the accuracy and reliability of LLM applications in\nCCM. There is no one-size-fits-all prompting approach that can improve the performance of\nLLMs, and a single strategy is not universally applicable to all LLMs [85].\nModel Training and Deployment Challenges Training and deploying LLMs require\nsubstantial computational resources and time. High precision and reliability are necessary in\nmedical applications, requiring models to be trained on large, diverse datasets. However, the\navailability of large-volume data in CCM is limited, with public databases like MIMIC [101,\n102] and eICU Collaborative Research Database [103] commonly used for pre-training large\nmodels. Strict hospital regulations often restrict data sharing, complicating multicenter\nstudies [104, 105]. Additionally, LLMs may not comply with data privacy standards required\nin local computing environments, which restricts their training and deployment in critical\ncare settings [73].\nTimeliness of Knowledge CCM is a rapidly progressing field with the continuous\nemergence of new treatments and medical discoveries. LLMs may lack the capability to\nupdate synchronously with the latest critical care research, impacting their performance in\nclinical practice [13].\nBias and Alignment Challenges LLMs may unintentionally learn biases from the training\ndata and reproduce them in their outputs. This could lead to biased treatment\nrecommendations for certain patient groups, affecting the quality of medical care [106]. Also,\nthe inherent biases in LLM selection remain a concern [72]. It may lead to disseminating\ninaccurate model recommendations, potentially jeopardizing patient safety [74]. The models'\ndecision-making processes and outputs must align with clinical guidelines and medical ethics\n[107]. Moreover, as clinical practice involves complex human behaviors and non-"}, {"title": "Lack of Evaluation Benchmarks", "content": "In medicine, there is a lack of unified and widely\naccepted standards for evaluating the performance of LLMs. This makes it difficult to assess\nand compare the effectiveness of different models and accurately measure their specific\nimpact on clinical practice [109]. Traditional model evaluation mainly focuses on the\naccuracy of medical question answering, which cannot fully reflect the capabilities of LLMs\nin clinical practice [110]. It is important to establish specific evaluation frameworks and\nperformance metrics [108]."}, {"title": "5.4 Future Directions", "content": "The future development of LLMs in CCM should focus on the following key areas.\nEnhancing Model Reliability and Interpretability The accuracy and reliability of\nLLMs can be enhanced by improving training data quality, employing ensemble learning, and\nimplementing adversarial training [112-114]. Developing and fine-tuning LLMs specifically\nfor CCM, incorporating domain-specific knowledge, are also essential measures to improve\nmodel accuracy and reliability. Future research should also focus on increasing the use of\nplugins to evaluate results, which can increase the reliability of models by reducing the\ngeneration of erroneous results and references by checking results with external knowledge\nfrom databases such as PubMed [88]. Using attribution methods as post-hoc explanations\nfor LLMs, researchers can have a deeper understanding of the operating mechanism of LLMs\n[115]. In addition, the interpretability of LLM can also be improved through CoT, tree-of-\nthoughts, graph-of-thoughts, and retrieval augmented generation (RAG) technologies [115,\n116]."}, {"title": "Optimizing Prompt Engineering Techniques", "content": "LLMs' sensitivity to prompts necessitates\ncontinuous model training and updates to ensure accuracy. Recently, a prompt engineering\nframework called Medprompt developed by Microsoft uses a combination of three main\ncomponents (dynamic few-shot, self-generated CoT, and choice shuffle ensemble) to\ncombine powerful general LLMs (such as GPT-4) with effective prompt engineering,\noutperforming LLMs that fine-tuned on domain-specific data [117]. Future research needs to\ninvestigate more robust prompt engineering techniques, including CoT, few shots, and RAG,\nto enhance the consistency and reliability of LLM outputs in different clinical scenarios."}, {"title": "Improving Training and Deployment Scalability", "content": "To address LLM training and\ndeployment challenges, scalable model architectures, transfer learning, model pruning, and\nfederated learning approaches can be explored to reduce computational demands and\nfacilitate practical deployment [118]. The emergence of low-powered open-source LLMs\nrunning locally could circumvent issues related to data privacy and computational resource\nconstraints [93]. It is crucial to convert medical datasets into easily accessible structured\ndatabases and train healthcare professionals to utilize LLMs in clinical practice to aid\ndecision-making [88]."}, {"title": "Integrating Up-to-Date Medical Knowledge", "content": "Employing online learning systems allows\nmodels to update and assimilate the latest medical research and changes in clinical practices\nin a timely manner. Additionally, modular update systems can swiftly integrate new medical\ndiscoveries, while expert collaboration ensures the scientific validity and timeliness of model\noutputs. Moreover, using RAG techniques to connect LLMs with databases in CCM can also\naddress the knowledge timeliness issue to some extent [116]."}, {"title": "Mitigating Bias and Ensuring Fairness", "content": "Bias mitigation should be approached through\npre-processing, in-training, intra-processing, and post-processing stages [106]. Pre-\nprocessing techniques involve modifying model inputs to ensure balanced representations.\nIn-training methods focus on adjusting model parameters to mitigate biases through\ngradient-based updates. Intra-processing methods modify inference behavior without\nfurther training, while post-processing techniques correct model outputs to ensure fair\ntreatment across demographic groups. Developing bias detection and dataset augmentation\nalgorithms to review and adjust model outputs regularly can help reduce model bias and\nensure fairness [119]."}, {"title": "Developing Comprehensive Evaluation Benchmarks", "content": "Recent studies demonstrated\nthat performance varies significantly across different medical tasks, highlighting the need for\ntask-specific evaluations [110, 120]. Future directions should focus on developing multi-\ndimensional evaluation benchmarks that go beyond accuracy to include factors such as\nclinical relevance, interpretability, and robustness under real-world conditions and task-\nspecific benchmarks that focus on the specific area of CCM. Collaboration between medical\nprofessionals and AI researchers is crucial to designing these benchmarks, ensuring they are\nclinically meaningful and practically applicable [110]. Establishing such standards will\nfacilitate more reliable comparisons between models, guiding improvements and fostering\ntrust in their deployment in CCM [110]."}, {"title": "Strengthening Privacy and Ethical Guidelines", "content": "Efforts need to be made to establish\nflexible and robust standards and regulations to safely and effectively implement LLMs in\nCCM [74]. Employing synthetic data generation techniques to expand training datasets can\nsupport extensive and effective model training while protecting patient privacy [121].\nStrengthening collaboration with policymakers, ethicists, and legal experts is necessary to\nensure LLM applications comply with ethical and legal requirements, thus protecting patient\nprivacy and data security [122]."}, {"title": "6. Conclusion", "content": "In conclusion, although LLMs in CCM are not yet ICU experts, they act more than stochastic\nparrots. Applying LLMs in CCM presents a transformative potential for enhancing critical\ncare. Through techniques such as RAG and working as agents to integrate with external\nknowledge bases, LLMs can learn and acquire professional and up-to-date knowledge\nrelevant to CCM. LLMs are capable of reasoning beyond random generation, and they have\ndemonstrated capabilities to improve diagnostic accuracy, plan treatments, and provide\nvaluable support in prognosis prediction. However, applying LLMs in CCM is still in its early\nstages, with few large models specifically designed and fine-tuned for this domain. Future\nresearch should focus on enhancing model reliability and interpretability, optimizing prompt\nengineering techniques, improving training and deployment scalability, integrating up-to-\ndate medical knowledge, mitigating bias and ensuring fairness, developing comprehensive\nevaluation benchmarks, and strengthening privacy and ethical guidelines. Close\ncollaboration across multiple disciplines, such as medicine, computer science, and data\nscience, can catalyze applying LLMs in CCM. There is some way to go before making LLMs\nbecome true ICU experts. Nevertheless, we are optimistic that LLMs in CCM will become\nexperts in the near future, helping to improve the quality of critical care and the outcomes of\ncritically ill patients."}]}