{"title": "Explainable Anomaly Detection: Counterfactual driven What-If Analysis", "authors": ["Logan Cummins", "Alexander Sommers", "Sudip Mittal", "Shahram Rahimi", "Maria Seale", "Joseph Jaboure", "Thomas Arnold"], "abstract": "There exists three main areas of study inside of the field of predictive maintenance: anomaly detection, fault diagnosis, and remaining useful life prediction. Notably, anomaly detection alerts the stakeholder that an anomaly is occurring. This raises two fundamental questions: what is causing the fault and how can we fix it? Inside of the field of explainable artificial intelligence, counterfactual explanations can give that information in the form of what changes to make to put the data point into the opposing class, in this case \"healthy.\" The suggestions are not always actionable which may raise the interest in asking \"what if we do this instead?\" In this work, we provide a proof of concept for utilizing counterfactual explanations as what-if analysis. We perform this on the PRONOSTIA dataset with a temporal convolutional network as the anomaly detector. Our method presents the counterfactuals in the form of a what-if analysis for this base problem to inspire future work for more complex systems and scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "Downtime is feared by utility companies, internet service providers, system administrators, and production lines of all kinds. A system or service being down threatens loss of consumer confidence and contracts. For this reason and more, stakeholders are eager to minimize downtime while acknowledging the need for maintenance related downtime.\nCondition based maintenance (CBM) seeks to thread the needle of expense between preventative (before needed) maintenance and the often greater-expense of reactive (after needed) maintenance, intervening exactly as needed. Employing machine learning (ML) to accomplish CBM constitutes predictive maintenance (PdM) [1]. PdM employing powerful data-driven models can learn highly non-linear and complex functions between sensible conditions and the incipience of some breakdown. However, many of these models are black-boxes which requires recommendations to be taken on faith. This is often unacceptable, and explainable AI (XAI) methods can satisfy the need to check the model's work [1].\nAnomaly detection (AD) is a key task supporting PdM [2]-[6]. Here, AD classes signals indicative of malfunction as anomalous, and others as nominal [1]. In the context of AD, the XAI method of counterfactual explanation generation can try to answer, for a detected anomaly, \"What is anomalous here? Why? What if conditions were different?\" [1]. This facilitates the practice of what-if analysis, with two broad uses.\nThe first use interrogates an anomaly's cause. Given an anomalous point in the space of sensor inputs, it may be that reduction in this vibration frequency, those temperatures, or that voltage, would return the system to a nominal state. By perturbing the anomalous point, discovering the change which most readily returns it to the nominal class, an AD system can suggest loci of malfunction. If reducing a particular voltage easily reclassifies the point as nominal, then subsystems responsible for that voltage are implicated as malfunctioning.\nThe second use suggests supplementary action. The obvious use of localized malfunction is to investigate, and possibly repair, implicated subsystems. But this is not always possible. Suppose a broken cooling system in a generator has allowed a circuit board to become dangerously hot. What-if analysis has already implicated the heat pump, but no replacement is available, but what-if analysis remains useful. Since it has localized the malfunction not only to a set of subsystems (the heat pump) but to a condition (the reduction of temperature), the supplementary action of reducing load on the generator may allow the damaged heat pump to compensate adequately until a replacement can be found. In practice, a typical sequence using this technology is illustrated in Fig. 1. In Fig. 1a, a detected anomaly is interrogated using what-if analysis. The user interprets the results, realizes that the obvious fix cannot be implemented immediately, and uses what-if analysis again to search for a condition based countermeasure (Fig. 1b). These results are interpreted, the user sees their planned systemic modification may counteract the anomalous condition (Fig. 1c).\nThe present work contributes a proof of concept implementation of counterfactual generation for AD what-if analysis on multivariate data, with the work organized as follows. Section II supplies concepts prerequisite to understanding the work, and summarizes the prior-work motivating the present. Section III presents the developed what-if analysis framework, and the experiments used to test it. Sections IV and VI present the results, and a discussion of their implications, respectively."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "In this section, we describe many topics that must be understood before continuing with our work including what-if analysis, counterfactual explanations and temporal convolutional networks (TCN)."}, {"title": "A. What-if Analysis", "content": "Golfarelli et al. [7] describe what-if analysis as a \"data-intensive simulation whose goal is to inspect the behavior of a complex system under some given hypothesis.\" More succinctly, a what-if analysis answers the question \"how do changes in X impact Y?\" Figure 2, shows an example of what-if analysis used in prediction over a number of days. The known value can be seen with three diverging paths. These three paths would resemble different what-if analyses with different changes impacting the value. Additionally, what-if analysis can be performed in many different ways; a few are provided below.\nDandolo et al. [8] propose Accelerated Model-agnostic Explanations (AcME) as a global and local explainable AI method. This method perturbs each feature of the dataset on the basis of the quantiles found in the distribution of the feature. This allows for less calculations than other methods such as SHAP and LIME. Additionally, this explainable method can be used for what-if analysis by perturbing the data point to fit the query and showing the output of the model. Singh et al. [9] propose a what-if analysis system for cloud computing applications. Their main what-if analysis pipeline consists of three parts: finding the components that are impacted by the what-if query, modeling the components in a directed acyclic graph (DAG), and propagating the change proposed in the what-if query through this DAG to see the influence. Their method shows promising results in monitoring and accurately predicting the different resources, such as CPU utilization and workload, that would be used for cloud computing applications.\nHerodotou and Babu [10] propose a numerous additions to a big data analytics system, including what-if analysis that works in two parts. Firstly a profile is generated that represents a hypothetical job of their systems. This profile is represented as a dataflow statistics and the costs associated with the dataflow. These statistics are proportional to the input data that would be expected from a typical job or from a job that is similar from their seen data. With the different statistics, they are able to simulate the job using white-box models; thus simulating a situation that has not happened."}, {"title": "B. Counterfactual Explanation Generation", "content": "Counterfactual explanation generation for XAI was introduced by Wachter et al. [11] as a way of providing a difference between a data point and a desired outcome [1]. Counterfactual explanation generation aims to minimize the amount of changes necessary to a data point while achieving a change in model output. This is done a number of different ways, but it can be generalized into the form\narg min max (fw (V') \u2013 p')\u00b2 + \u03bbd(Vi, V') (1)\nV'\nwhere V' is a counterfactual that is similar to the original data vector Vi, fw (V') is the output of the model being fed the counterfactual, p' is the desired target, d(*,*) is a distance function that measures how difference between the counterfactual and the original datapoint, and \u03bb is the objective function [11]. This could also be put into a verbal representation similar to classification p was returned. If variables V had different values (v1, v2, ...), and all other variables had remained constant, classification p' would have been returned [11].\nCounterfactuals have been utilized as a way of explaining the output of time series modeling tasks. Jakubowski et al. [12] incorporated counterfactuals to explain their Physics-based Autoencoder architecture. First, they only search the test dataset for a suboptimal yet valid counterfactuals. Then they search the domain around that data point for the best fit counterfactual. The main limitation from their approach, as stated in their work, was the counterfactual generation speed that would not suffice for real-time explanation generation.\nAtes et al. [13] proposed Counterfactuals for Multivariate Time-series Explanations (CoMTE). Their method aims to find a fast solution, to combat the NP-Hard problem of optimal counterfactual generation. The speed comes from their usage of a k-d tree, a space partitioning tree introduced by [14]. A k-d tree helps them compute the most similar data point in the training dataset (the distractor) to the test point. Their method iteratively replace features from the distractor to the test point until the prediction has changed. We utilize this method in this work, and describe it in more detail in Section III.\nLastly, Lang et al. [15] proposed a Generative Adversarial Network (GAN) based approach for counterfactual generation known as SPARse Counterfactual Explanations (SPARCE). To ensure the realism of the counterfactual, they create a GAN to learn the distributions of the data and produce counterfactuals that mimic the distributions. Since they are using temporal data, their GAN is implemented as a set of bidirectional LSTMs. They tested their method on three different datasets, notably no anomaly detection datasets, and verified that their approach performs the best or second best in terms of precision, similarity, sparsity, and plausibility."}, {"title": "C. Temporal Convolutional Network (TCN)", "content": "Proposed in 2018 by Bai et al. [16], the TCN is a generic architecture for convolutional sequence modeling that was designed to compete with the best recurrent models. This architecture is based on two principles: input-output length homogeneity and no information leakage [16]. The first principle is achieved by keeping layer lengths consistent throughout the network. The second principle is achieved via their causal convolution mechanism which determines the output at time t by using only the data from t and earlier. Additionally to handle long history sizes, they adopt two mechanisms from convolutional architectures, dialated convolution and residual connections. Dialated convolution allows them to increase the size of the receptive field while decreasing the amount of computation by logarithmically decreasing the amount of elements included between computation layers. Residual connections are used to connect the output of the dialated convolutions and the original input which promotes learning of mappings rather than transformations [16].\nTCNs have been applied to predictive maintenance in the forms of anomaly detection and remaining useful life prediction. He et al. [17] performed anomaly detection on three different datasets, electrocardiograms, 2-D gesture and space shuttle. Additionally, they created two TCN architectures, one base TCN architecture and one with the addition of branching from different layers to measure multiple scales of the same features. They found that TCN were were quite successful in performing sequence modeling; moreover, their modification performed better than the base model.\nTCNs have seen more use in the realm of remaining useful life prediction. Li et al. [18] applied the TCN architecture to the famous CMAPSS dataset [19]. Compared to six other architectures, including other sequence modeling architectures such as LSTMs and DCNNs, the TCN outperformed the competition in both RMSE and Score. Chen et al. [20] also applied a base TCN to the CMAPSS dataset. They expanded the list of architectures that were compared and showed that generally the TCN performed best or second best to CapsNet. Wang et al. [21] improved upon the TCN with the addition of dual competitive attention (DCA) to create the Competitive TCN (CTCN). The DCA is comprised of three components: global competition which removes features with little impact, dual attention which calculates the attention weights in the temporal and channel dimensions, and multidimensional competition which fuses the two into one dimension. When applying their approach to RUL prediction of the PRONOSTIA dataset, they found their architecture to perform the best in eleven out of thirteen datasets in comparison to CNN, CNN with DCA, and TCN. With the successful use of TCN as a time series modeling approach, we feel comfortable using TCN-based architectures for our task. Now we describe the framework we utilize to apply what-if anaylsis to anomaly detection with the aid of counterfactuals."}, {"title": "III. WHAT-IF ANALYSIS FOR ANOMALY DETECTION", "content": "In this section, we describe the methodology that we utilize for what-if analysis for anomaly detection. Firstly, we discuss the PRONOSTIA fault bearing dataset and how we handle class imbalance. Next, we describe the two experiments done which includes k-fold cross validation to validate the TCN architecture and full model training to see its performance on the PRONOSTIA dataset. We then describe the process of counterfactual explanation generation through CoMTE. Lastly, we describe how we use these counterfactuals as an online what-if analysis method for anomaly detection."}, {"title": "A. PRONOSTIA Dataset", "content": "The PRONOSTIA dataset [22] was originally introduced as a real data benchmark dataset for the IEEE PHM 2012 Prognostic Challenge. This dataset consists of a learning dataset and a testing dataset split across 3 operating conditions. Additionally, the training datasets consist of 2 run-to-failure instances per operating condition. The testing datasets consist of 5 instances for operating condition 1, 5 instances for operating condition 2, and 1 instance for operating condition 3. This information can also be seen in Table I.\nEach dataset contain two variables, a horizontal acceleration and a vertical acceleration as seen in Figure. 4. Additionally, there is a temperature value that was not utilized which is not uncommon due to being a different frequency from the acceleration variables. For labeling the data set, we utilized the three sigma rule [23], [24]. We calculated the root mean square (RMS) of the different features over the 2560 length time vector. After calculating the mean and standard deviation of the RMS, we labelled all of the data vectors that are three standard deviations over the mean as anomalous. Lastly, to have a smoother labeling scheme, every data point was labeled anomalous if it was followed by only anomalous data points."}, {"title": "1) Class Balancing through SMOTE", "content": "With our class separation criteria, we have a glaring problem: class imbalance. This could cause many issues in training such preference to the majority class [25]. To get past this issue, we perform Synthetic Minority Oversampling Technique (SMOTE) [26]. This method involves utilizing clustering, in this case k-nearest neighbors clustering, of the minority class, in this case anomalous. For each data point in the anomalous class, the difference between that data point and its nearest neighbor is calculated, and the difference is used to slightly perturb the original data point. The newly created data point is then added to the dataset. Next we describe the architecture used in our experiments."}, {"title": "B. TCN for Anomaly Detection", "content": "For anomaly detection, we apply the Temporal Convolution Network (TCN). As stated in Section II, the TCN architecture has seen much success for time series related tasks including PdM related tasks [12], [18], [27]\u2013[29]. For both of our experiments described below, we utilize the hyperparameters listed in Table II."}, {"title": "1) K-Fold Cross Validation", "content": "Our first experiment aimed to determine if the TCN is truly going to be able to generalize on our dataset [30]. We trained three different models, one for each operating condition. We utilized a 5-fold cross-validation set-up where each subset of data was loaded, shuffled, and split into five smaller datasets. As this architecture requires the data to be split into time-vectors prior to training, we believe this is representative to commonly seen k-fold implementations on non-time series data. As per specifying 5-fold, the models were then trained on four of the smaller datasets and tested on the remaining one."}, {"title": "2) Full Model Training", "content": "After performing k-fold cross validation, we trained our mulitple TCN models for our dataset. As we have three operating conditions, we trained four models. The four models are known throughout the paper as TCN1, TCN2, TCN3, and TCN123 where the subscript designates what operating conditions were used to train the model. This allowed us to compare the generalizability of the models trained on their full corresponding datasets. Additionally, this allowed us to compare these to a model trained on all three operating conditions.\nFor thorough testing of our models, we utilized five metrics that are commonly used in classification problems. These metrics were accuracy, recall, precision, f-score and g-score [31]. These are all built upon the confusion matrix that shows true positive, true negative, false positive and false negative information. Accuracy is the percentage of correct predictions. Precision is the percentage of correctly labeled positive results in all positive labeled results. Recall is the percentage of correctly labeled positive results. F-score shows how accurate the model is on the dataset. Lastly, G-mean shows the performance of the model on the majority class and the minority class."}, {"title": "C. Offline Counterfactual Generation", "content": "For the counterfactual generation module of our framework, we utilized the Counterfactuals for Multivariate Time-series Explanation (COMTE) method proposed by Ates et al. [13]. COMTE is one of the few methods that allows for counterfactual generation for multivariate time series data. This method is broken up into two steps that are described below."}, {"title": "1) K-d Tree for Space Partitioning", "content": "CoMTE starts out by choosing distractor candidates that serve as the basis of the counterfactuals. Features that are desirable for the method of gathering the distractor candidates are efficiency and realness. Efficiency refers to the time complexity of the method to generate the distractor candidates, and realness refers to the likelihood for the data to exist. They provide these two features by utilizing a k-d tree, proposed by Bentley [14]\nThe multidimensional binary search tree, also known as the k-d tree, was proposed as a data structure to store information to be retrieved by associative searches [14]. A k-d tree is a space partitioning data tree where each leaf has a dimensionality of k. Using Fig. 5 as an example, moving down the tree from the root alternates what feature is being compared. In the case of Fig. 5, the comparison alternates between features X and Y axes. Similarly to a binary search tree, values that are less than parent node are stored on the left side of the parent node, and values that are greater than the parent node are stored on the right side. This allows us have similar runtime performances using k-d trees as the binary search tree of O(logn).\nWith this efficient data structure in place, CoMTE utilizes our previously trained TCN model and the training data. All of the training data is fed to the model to determine how accurate the model is on the training data. The predictions from the model are split into two groups: correct and incorrect. The incorrectly labeled data points are discarded. The correctly labeled data points are used to fit a k-d tree per class, in our case two. These k-d trees are stored for future counterfactual generation."}, {"title": "2) Counterfactual Generation", "content": "The counterfactual generation of COMTE receives a three inputs: the k-d trees, the data point to be explained and the desired class. For a counterfactual query, the specified class would indicate which k-d tree is searched. Using their proposed sequential greedy algorithm and a specified number of distractors, a sequential process is done that replaces the feature values of the data point for values of the corresponding feature in the distractor. This process is repeated until the data successfully gets labeled as the specified class by our model. Ates et al. [13] also propose a random-restart hill climbing approach for counterfactual generation, but we utilized the greedy approach for our proof of concept."}, {"title": "D. Online What-if Analysis", "content": "The last element of our framework involves the interaction between a user and the explainable PdM system. We focus on the actual generation of explanations instead of focusing on the interface of the explainable system. The interface is an equally valuable work that deserves its own attention, but this lies outside of the scope of this work.\nThe interaction between user and system is best described through a visual, referencing Figure. 1. The system would alert the user of an anomaly. The user would then be able to query the system for a counterfactual to see what the system would look like if it were healthy. This counterfactual could then be used as a way of simulating a what-if analysis as it would be answering the question \"what if our system had been performing normally?\" Through this what-if analysis, the user would be able to request an additional counterfactual if that one was unsatisfactory; moreover, the user would be able to request a new counterfactual if the required change would not be possible given the time frame, supplies, or other extraneous factors."}, {"title": "IV. RESULTS", "content": "In this section, we present our models' testing results. These results of our k-fold cross-validation experiment can be seen in Table III. The results of our full anomaly detection experiment can be seen in Table IV."}, {"title": "A. K-Fold Cross-Validation Results", "content": ""}, {"title": "B. TCN Performance Results", "content": "As seen in Table IV, all models performed well in regards to some metric. TCN\u2081 performed the best in the most amount of metrics. Namely it had the best accuracy on all of the datasets, including being tied with TCN2 and TCN3 on the Bearing3 dataset. Additionally, TCN\u2081 had the best precision and f-score on the Bearing1 dataset. TCN2 had the best g-score on the Bearing1 dataset. TCN3 had the best precision, f-score and g-score on the Bearing3 dataset. Lastly, TCN123 had the best recall on Bearing1 and Bearing3."}, {"title": "V. AN ILLUSTRATION OF WHAT-IF ANALYSIS FOR ANOMALY DETECTION", "content": "In this section, we describe a use-case for utilizing counter-factuals explanations as what-if analysis. This use-case relies on and follows the scenario described by Fig. 1."}, {"title": "VI. DISCUSSION", "content": "In this section, we discuss the larger message from our experiment as well as the use-case presented. This describes a number of important aspects about our model and method chosen as well as how this could be applied in different settings."}, {"title": "A. K-Fold", "content": "The k-fold experiment was quite successful with all three datasets. The accuracies for all of the folds show that the TCN model is good enough for anomaly detection on the PRONOSTIA dataset. Additionally, it consistently gets a high accuracy which indicates good generalizability."}, {"title": "B. TCN for Anomaly Detection", "content": "Firstly, there is a seemingly odd performance with all of the models on the Bearing2 dataset. The reason for 0.0 being an overwhelming value through the metrics on this dataset is two-fold. PRONOSTIA does not have true values for anomaly detection like it does remaining useful life. This would create the need to create the labels. Leading into the second reason, the three-sigma method utilizing RMS did not label any of the test data in Bearing2 as anomalous.\nSecondly, TCN123 showed perfect recall on Bearing1 and Bearing3. It would also show perfect recall on Bearing2 if there were any anomalous data in the testing set. This belief is brought on by it constantly predicting anomaly, which can be seen in the very small accuracy but high recall. This model would need to either be trained longer or be more complex to learn what it means to be an \u201canomalous bearing\u201d regardless of the operating condition.\nOverall, the models trained on one of the datasets performed well regarding some metrics. This is even the case with performing well on datasets that were not part of their training data."}, {"title": "C. What-if Analysis", "content": "As for the results of our what-if analysis, we provide an example from the Bearing1 test dataset where the TCN\u2081 model was used as the anomaly detector. As seen in Fig. 6, the original data is shown in blue, the real anomalous data is shown in orange, and the counterfactual is shown in green. This depicts two separate paths for the life of this bearing, one of anomaly (orange) and one of intervention to perform healthily (green). This is helpful as it depicts how the bearing should be acting if the maintainer wanted the bearing to be more associated with healthy data. This horizontal acceleration should be slowed to approximately \u00b12. Now to answer the question \"what if the bearing had been performing healthily?\u201d If the bearing had been performing healthily, its acceleration would have been more similar to the counterfactual, e.g. oscillating between \u00b12. This would also be useful to the maintainer as they would know to put less stress on the bearing in that way specifically which could allow for a longer lifetime of the bearing."}, {"title": "VII. LIMITATIONS AND FUTURE WORK", "content": "In this section, we describe the limitations of both the individual elements we used for testing such as the model and the dataset. Additionally we describe the limitations of this specific counterfactual explanation generation approach. In terms of limitations and improvements that could be made upon our work, the system is relatively simple to match the dataset. There are namely two places that could need alternative methods as the the data scales, the class balancing method and the counterfactual generation approach. Both of these approaches may not scale well as the number of features increases. For class balancing, methods for synthetic data generation such as Variational Autoencoders and Generative Adversarial Network could be implemented for better performance [32]. For counterfactual generation, the k-d tree is very fast when querying it. The limitation comes in the creation of the k-d tree. The authors propose using k-means clustering to get exemplars for k-d tree creation, but there could still be a desire to keep full dataset to get the best counterfactuals. Other approaches could be tested such as the ones presented in [33]-[35]. Of course this method could still suffice for larger datasets, and verifying this is just one opportunity for future work."}, {"title": "VIII. CONCLUSIONS", "content": "Anomaly detection is an important component of predictive maintenance that aims to determine whether or not a component of a cyber-psychical system shows unhealthy behavior. If a maintainer of a cyber-physical system, such as a vehicle with a rich array of sensors, was in a maintenance station with a full array of tools, the maintainer would be able to perform any maintenance task. This is an ideal. Continuing with the vehicle example, a vehicle in use may be away from many of the tools and parts used for maintenance; moreover, an anomaly would not be so easily fixed. What-if analysis allows the maintainer to test different hypotheses in the form of simulations that could point to an elongated lifetime of the system by performing a separate repair, changing their behavior, etc. Counterfactual explanation generation can provide these simulations by providing realistic examples of healthy data with minimal or specified changes to the system. Our experiments showed the Temporal Convolutional Network to be a good classifier for anomaly detection on the PRONOSTIA bearing dataset. The Counterfactuals for Multivate Time-series Explanations method showed to be a fast performing method that provided realistic counterfactuals for the anomalous bearing data. This work shows to be a useful proof-of-concept that can serve as the basis for more complex environments where what-if analysis will show to be more useful in the field of predictive maintenance."}]}