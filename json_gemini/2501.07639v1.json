{"title": "SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization with Large Language Models", "authors": ["Fabien BERNIER", "Jun CAO", "Maxime CORDY", "Salah GHAMIZI"], "abstract": "Efficiently solving Optimal Power Flow (OPF) problems in power systems is crucial for operational planning and grid management. There is a growing need for scalable algorithms capable of handling the increasing variability, constraints, and uncertainties in modern power networks while providing accurate and fast solutions. To address this, machine learning techniques, particularly Graph Neural Networks (GNNs) have emerged as promising approaches. This letter introduces SafePowerGraph-LLM, the first framework explicitly designed for solving OPF problems using Large Language Models (LLM)s. The proposed approach combines graph and tabular representations of power grids to effectively query LLMs, capturing the complex relationships and constraints in power systems. A new implementation of in-context learning and fine-tuning protocols for LLMs is introduced, tailored specifically for the OPF problem. SafePowerGraph-LLM demonstrates reliable performances using off-the-shelf LLM. Our study reveals the impact of LLM architecture, size, and fine-tuning and demonstrates our framework's ability to handle realistic grid components and constraints.", "sections": [{"title": "I. INTRODUCTION", "content": "Resolving Alternating Current Optimal Power Flow (AC OPF) problems is a routine task in the operational planning of Power Systems (PS). Nevertheless, with the increasing variability, constraints, and uncertainties in today's power networks, solving problems accurately presents a significant challenge for power system engineers. Numerous strategies for addressing AC OPF challenges incorporate Machine Learning (ML) elements to mitigate the computational challenges associated with traditional optimization-based OPF approaches.\nGraph Neural Networks (GNN) have recently demonstrated solid performance for various tasks in the power system. In particular, Liu et al. [1] proposed a new topology-informed GNN approach by combining grid topology and physical constraints. Ghamizi et al. [2] demonstrated that an heterogeneous graph representation combined with physical constraints losses leads to the best performances for PF and OPF tasks. Recent work such as SafePowerGraph [3] provided a standardized representation and benchmark of GNN for PF and OPF problems and identified the best architectures and design choice to solve these problems with GNN.\nWhile these models achieve remarkable performance, they require expensive data curation \u2014 by collecting large training datasets with OPF solvers \u2014 and costly training for specific power grid sizes. Recent progress in foundation models, including LLMs (e.g. ChatGPT, LLaMa), has significantly reshaped the fields of machine learning. Such models can indeed generalize to new tasks without expensive training, given the right indications. LLMs have also recently been explored to solve PS-related tasks. [4] proposed an LLM agent in the Deep Reinforcement Learning (DRL) training loop, directly allowing to model linguistic objectives and constraints in the OPF problem. The optimization is, however, run using traditional methods (solvers and DRL). A foundation model, developed in [5], can iteratively solve the OPF optimization problem by minimizing the cost function. The optimization only supports the toy example of simple economic dispatch problem of units, and does not fully optimize and predicts the OPF variables (generation and bus variables) nor consider real world grid components (multiple loads, line operating limits). To the best of our knowledge, SafePowerGraph-LLM is the first embedding and optimization framework for OPF that supports realistic grid components and constraints.\nThis letter presents three main contributions. We first propose novel power grid embedding for OPF to query LLMs with graph and tabular representations, followed by the development of tailored in-context learning and fine-tuning protocols for these models. We finally include an empirical study on how the architecture, size, and fine-tuning of LLMs affect their performance in solving OPF problems."}, {"title": "II. SAFEPOWERGRAPH-LLM FRAMEWORK", "content": "We present in Fig. 1 our SafePowerGraph-LLM framework. The first three steps consist in building the correct message format to query an LLM for OPF using an appropriate table or graph embeddings, the following steps are either implemented using open source LLMs (Llama), or remote API (OpenAI).\na) Power Grid Embedding: We extend SafePowerGraph [3] to build the appropriate embedding for LLM.\nStarting from an initial grid descriptor (in MatPower, PandaPower or OpenDSS formats), we generate a Pytorch HeteroData with each component as a distinct subgraph (Step (1)). Each node can be of type: bus, load, generator, slack, or line, and is associated with its distinct set of features $X_b, X_l, X_g, X_s, X_e$ respectively. In order to create new grids, these features are mutated depending on their types. For example, the mutation for loads of the active and reactive power is based on the real profile (Step (2))."}, {"title": "III. EMPIRICAL STUDY", "content": "a) In-context inference: To investigate the capability of LLMs in generalizing from examples presented within the context window, we conduct an assessment using in-context inference. Four models were tested: OpenAI's gpt-4o-mini, OpenAI's gpt-4o, Llama-3.1-8B-Instruct, and Llama-3.1-70B-Instruct [6], the latter being respectively renamed llama-8b and llama-70b for the sake of brevity.\nSequences provided for in-context inference are made as follows: after an initial system prompt, a total of 65 pairs of example requests and solutions are provided using the JSON format. A context of 65 examples maximizes the utilization of context windows across all models. An additional, 66th example is used to evaluate the model's generalization abilities, with its response benchmarked against an expected solution. The overall sequence constructed is illustrated in Table II.\nIf no JSON object can be read from the LLM's response, or if the values returned by the LLM are invalid (missing or invalid values), the output is deemed INVALID. This evaluation process was repeated 1,000 times, resulting in the generation of a total of 65,000 pairs for context and 1,000 pairs for evaluation across the assessments.\nWe run these inference tasks on one NVIDIA RTX 8000 48GB for Llama 8B (two for Llama 70B), using Q4_K_M quantization to optimize performance and resources.\nb) Fine-tuning: Subsequently, we apply fine-tuning to the Llama-3.1-8B-Instruct model, as shown on Figure 1, using the 65,000 pairs of context developed earlier. Each fine-tuning sample includes the system prompt, the specific OPF problem being addressed, and its corresponding solution. We follow a similar protocol to fine-tune OpenAI's gpt-4o-mini with API.\nThe fine-tuning process of the Llama model was conducted on an NVIDIA RTX 8000 48GB, using a LoRA configuration. The LoRA setup was defined with a rank of 8 (r = 8) and a scaling factor of 16 (\u03b1 = 16).\nc) Evaluation: We report in all our experiments the mean square error to the solution found by the solver for"}, {"title": "C. Impact of the size of the model", "content": "As it is the case for natural language tasks [6], bigger models result in better performance (Figure 3). This improvement especially prominent for llama-70b, getting closer to gpt-4o-mini's performance in terms of GEN and SLACK MSE.\nThe MSE of BUS decreases when increasing the size of the LLM using table representation, but increases significantly with graph representation. Our results confirm that larger LLM lead to better performance for given representations and both the size and the representation parameters should be considered together in future assessments."}, {"title": "D. Impact of fine-tuning", "content": "We report in Table I the impact of fine-tuning LLMs to solve the OPF problem. the percentage of invalid outputs of the LLM decreases to less than 2% for the Llama models and marginally increases for the GPT4o model. The error across all the components decreases, in particular for the Llama models. They become as effective as the proprietary model.\nContrary to the earlier vanilla models, graph representation is more effective than tabular to query LLMs after fine-tuning."}, {"title": "CONCLUSION", "content": "Our letter introduces SafePowerGraph-LLM, a novel framework for solving OPF problems using LLMs. We propose a new power grid embedding combining graph and tabular representations, LLM fine-tuning protocols for OPF, and an empirical analysis of LLM performance. Our results show that larger models perform better, with fine-tuning significantly improving accuracy and reducing invalid outputs. Graph representations become more effective than tabular ones after fine-tuning. These findings highlight the potential of LLMs in power system optimization and open new avenues for more efficient and accurate OPF solutions for complex power grids."}]}