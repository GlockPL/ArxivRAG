{"title": "Can Transformative AI Shape a New Age for Our Civilization? Navigating Between Speculation and Reality", "authors": ["Jesus L\u00f3pez Lobo", "Javier Del Ser Lorente"], "abstract": "Artificial Intelligence is widely regarded as a transformative force with the potential to redefine numerous sectors of human civilization. While Artificial Intelligence has evolved from speculative fiction to a pivotal element of technological progress, its role as a truly transformative agent, or transformative Artificial Intelligence, remains a subject of debate. This work explores the historical precedents of technological breakthroughs, examining whether Artificial Intelligence can achieve a comparable impact, and it delves into various ethical frameworks that shape the perception and development of Artificial Intelligence. Additionally, it considers the societal, technical, and regulatory challenges that must be addressed for Artificial Intelligence to become a catalyst for global change. We also examine not only the strategies and methodologies that could lead to transformative Artificial Intelligence but also the barriers that could ultimately make these goals unattainable. We end with a critical inquiry into whether reaching a transformative Artificial Intelligence might compel humanity to adopt an entirely new ethical approach, tailored to the complexities of advanced Artificial Intelligence. By addressing the ethical, social, and scientific dimensions of Artificial Intelligence's development, this work contributes to the broader discourse on the long-term implications of Artificial Intelligence and its capacity to drive civilization toward a new era of progress or, conversely, exacerbate existing inequalities and risks.", "sections": [{"title": "1 Introduction", "content": "The concept of Artificial Intelligence (AI), once a speculative idea confined to science fiction, has evolved into one of the most transformative forces shaping our modern civilization. Rooted in philosophical and mathematical inquiries into the nature of intelligence and computation, AI has grown exponentially, deeply intertwined with developments in Computer Science, Neuroscience, Maths, and Cognitive Psychology, among others. The vision of machines capable of replicating or surpassing human intelligence, first proposed by (Turing, 1950), laid the groundwork for a broader discourse on the nature of mind and machine.\nIn recent decades, breakthroughs in machine learning, particularly deep learning (Le-Cun et al., 2015), have shifted the landscape from theoretical speculation to tangible achievements. Systems based on generative AI (Banh and Strobel, 2023) are demonstrating remarkable capabilities of modern AI, which now exceed human performance in specific domains such as strategy games, natural language processing, or image recognition (Maslej et al., 2024). However, the impact of AI on our civilization extends beyond its technical milestones. The integration of AI into critical social functions, from healthcare to governance, can be regarded as a double-edged sword. On the one hand, AI offers the promise of solving some of the most complex problems of humanity, such as climate modeling (Ripple et al., 2024), personalized medicine (Sadee et al., 2023), or economic optimization (Zheng et al., 2021). On the other hand, it exacerbates concerns about surveillance, labor displacement, and algorithmic biases Hickok and Maslej (2023); Frank et al. (2023); Ferrara (2023). The need for robust ethical frameworks and governance structures has never been more urgent. Since we stand at the precipice of what might be a new era in human history, the trajectory of AI's development will shape the future of human civilization. Moreover, it is a process that has already begun, the ultimate trajectory of which remains uncertain concerning its potential impact on social development (Qureshi, 2024). Whether it leads to unprecedented prosperity or catastrophic outcomes will depend not only on technological advancements, but also on how societies choose to harness and regulate this formidable lever of transformative change.\nDue to these expectations that AI has recently spawn, the term Transformative AI (TAI) has become a topic of growing interest (Buccella, 2023; Banafa, 2024; Rawas, 2024) due to recent breakthroughs in machine learning and neural computation, which have brought us closer to developing systems with the potential to revolutionize industries, reshape societal norms, and raise unprecedented ethical and governance challenges. The urgency surrounding TAI is further amplified by its potential to dramatically impact the global economy, human labor, and decision-making processes, prompting a widespread debate on its regulation and long-term societal implications. Therefore, in this work we adopt this term to refer to the development of those AI systems with the potential to induce significant and far-reaching transformations across civilization. As suggested in (Gruetzemacher and Whittlestone, 2019, 2022), it is a good practice to embrace the term TAI because it encompasses the notion that a diverse range of advanced AI systems warrant attention and concern, and accounts for the possibility that certain types of advanced AI systems could have profoundly transformative effects on our society without necessarily exhibit all human or even superior capabilities. TAI, as opposed to other terms such as Artificial General Intelligence (AGI) (Goertzel and Pennachin, 2007; Morris et al., 2023), Human-Level Intelligence (HLAI) (McCarthy, 2007), Artificial Superintelligence (ASI) (Bostrom, 2014), or simply strong AI, does not make broad assumptions about the characteristics that advanced AI systems must show to bring about significant societal change. Due to the existence of such diverse and non-consensual terms to refer to AI of such characteristics, we will simply use the neutral term Broadly Capable AI (BCAI) so as not to incur errors or inaccuracies. It is not one of the objectives of this work to make a clear distinction between them, especially when such definitions are still a subject of intense debate.\nMoreover, we see TAI paralleling the space race in regards to its transformative potential and interdisciplinary nature. Much like the space race, which required breakthroughs across several scientific fields, AI mainly combines knowledge from several fields, including Mathematics, Statistics, Computer Science, Neuroscience, and Ethics, to tackle its own grand challenges. Both are more than technological feats; they represent a collective effort to expand the boundaries of human knowledge. As space exploration unlocked new frontiers beyond Earth, AI is poised to reshape how we interact with the world, augmenting our intellectual and creative capabilities, especially as AI consolidates its transformative potential as \u03a4\u0391\u0399.\nThe idea of transformative technologies is not new. History offers numerous examples of innovations that have catalyzed epochal shifts, such as the advent of the steam engine during the Industrial Revolution or the rise of the Internet in the Information Age. However, what distinguishes TAI from these previous breakthroughs is its potential to serve as a \"general-purpose technology\" (Triguero et al., 2024) with capabilities that permeate nearly all domains of human activity. As AI research progresses, discussions increasingly focus on whether TAI could represent not merely a significant technological advancement, but a fundamental shift in civilization itself. While the excitement around TAI is palpable, so are the ethical, social, and existential challenges it poses, raising the question: will TAI serve as a beneficial force for humanity, or will it exacerbate existing inequalities and introduce unforeseen risks (Slattery et al., 2024)? As shown, TAI has been in the limelight for some time now, and the state-of-the-art has been addressing these and more questions for some time.\nSome of the most relevant publications about TAI focus on its definition and levels (Gruetzemacher and Whittlestone, 2019, 2022), on the challenges it addresses (Rawas, 2024), and on its practical applications (Banafa, 2024). Our article provides a comprehensive overview of TAI within the context of our civilization. We explore its historical significance as a groundbreaking phenomenon, examine it through an ethical lens, and evaluate its feasibility from theoretical, human, and technical perspectives. The work is also updated with the latest trends, theorems, and thoughts on TAI. The discussion concludes with an analysis of the potential impact that TAI could have in years to come. Altogether, our reflections herein offered can be regarded as an extensive compendium of what might unfold if current AI-based advancements become a catalyst for a global and transformative change in our civilization.\nThe rest of the article proceeds first with the Chapter 2, where shows (1) a historical overview of major technological advancements that have reshaped human civilization, drawing parallels to the potential impact of TAI (Section 2.1); and (2) the ethical implications of AI are examined through various philosophical lenses to analyze how different perspectives influence the development and deployment of AI systems (Section 2.2). In the Chapter 3 we got into (1) how AI has been with us for some time now, and what it means today, showing the significance of it in our civilization, and the possible roles it is destined to play (Section 3.1); and (2) the human (Section 3.2) and technical (Section 3.3) obstacles that exist in the transformation of AI into TAI. After that, we present the Chapter 4, which (1) shows the opportunities of TAI to become a reality (Section 4.1); (2) it analyzes what could be the great hope of achieving TAI (Section 4.2); and (3) assuming the advent of TAI, it highlights the possible need for a new ethical and philosophical approach to AI (Section 4.3). The final Chapter 5 (1) presents a discussion on the potential futures of AI, exploring both the opportunities for human enhancement and the risks of over-reliance on it (Section 5.1); and (2) it concludes by emphasizing the need for a balanced approach to AI development, one that integrates ethical considerations, robust governance, and a clear societal vision for the role of AI in the future (Section 5.2)."}, {"title": "2 Understanding and Perceiving Al", "content": "Throughout human history, certain technological advancements have marked profound turning points, pushing our civilization forward and reshaping the very fabric of society. These innovations are not just incremental improvements, but monumental leaps that have transformed how humans live, work, and interact with the world. The purpose of this section is to highlight some milestones in human history that are widely accepted, and that have represented a real leap forward for our civilization (depicted in Figure 2.1). We start this tour with the aim of understanding what can be expected from modern AI, and whether it can genuinely be included in this compendium of transformative milestones."}, {"title": "2.1.1 The Early Turning Points", "content": "One of the earliest and most fundamental advancements was the control of fire (James et al., 1989), which provided warmth, protection from predators, and the ability to cook food. This discovery, in turn, had significant impacts on human nutrition and social structures. The mastery of fire was a critical step in human evolution, laying the groundwork for future developments. Another transformative achievement was the domestication of animals and plants, which began with the dog (MacHugh et al., 2017) and cereals (e.g., wheat and barley) (Fuller et al., 2011). This process allowed humans to transition from nomadic lifestyles to settled agricultural societies. Domestication provided not only a reliable source of food but also labor, transportation, and materials like wool and leather, enabling the growth of stable communities, the development of complex societies, specialized labor, and the development of trade networks. The introduction of the wheel (Bulliet, 2016) further revolutionized human capabilities. This seemingly simple invention greatly improved transportation and trade, facilitated the movement of goods over long distances and spurred the development of machinery, fundamentally altering the course of economic and social development.\nDifferently, the invention of writing (Robinson, 2018) marked the dawn of recorded history. Writing enabled the preservation and transmission of knowledge across generations, allowing for the codification of laws, the administration of governments, and the flourishing of literature, science, and philosophy, being a crucial step in the development of complex societies and cultures. Many centuries later, the printing press (Eisenstein, 1980) democratized knowledge and education. By enabling the mass production of books, the printing press accelerated the spread of ideas, fueling the Renaissance, the Reformation, and the Scientific Revolution. It was instrumental in breaking the monopoly of knowledge held by the elite, allowing for broader access to information and literacy."}, {"title": "2.1.2 The Modern Turning Points", "content": "Already in the Modern Age, the steam engine (Dickinson, 2022) was the driving force behind the Industrial Revolution. This innovation mechanized production, leading to unprecedented increases in efficiency and productivity. It transformed industries, transportation, and society, marking the transition from agrarian economies to industrial powerhouses. Later, the discovery and harnessing of electricity (Jonnes, 2004) brought about another wave of transformation. Electricity became the lifeblood of modern civilization, powering homes, industries, and communication systems. It revolutionized daily life, enabling the development of technologies that continue to shape the world today. In the realm of medicine, the discovery of penicillin (Dougherty and Pucci, 2011) marked the beginning of the modern antibiotic era. This breakthrough has saved millions of lives by providing an effective treatment for bacterial infections, fundamentally changing medical practice and public health.\nThe advent of computers (Haigh and Ceruzzi, 2021) ushered in the Information Age. Computers revolutionized how we process, store, and analyze information, leading to the development of the Internet, smartphones, and countless other technologies that permeate every aspect of modern life. Concretely, the Internet (Leiner et al., 2009) is arguably one of the most transformative technologies in human history. It has connected people across the globe, enabling instant communication, the democratization of information, and the creation of new industries and forms of social interaction. The Internet has fundamentally reshaped economies, politics, and cultures worldwide. In more recent times, biotechnology and genetic engineering have opened new frontiers in medicine, agriculture, and beyond. The ability to manipulate DNA (Pickar-Oliver and Gersbach, 2019) has led to the development of life-saving therapies, genetically modified crops, and the potential for unprecedented advancements in biology and medicine. The harnessing of nuclear energy (Hewitt and Collier, 2000) provided a powerful and relatively clean source of energy, although it also introduced new challenges in terms of safety and waste management. Nonetheless, nuclear power has become a critical part of the global energy mix, offering a solution to the growing demand for electricity. The ongoing exploration of space (Launius et al., 2012; Jiang et al., 2021) represents humanity's quest to extend its reach beyond Earth. Space exploration has not only expanded our understanding of the universe but has also led to technological innovations that have applications in everyday life, such as satellite communication and the Global Position System (GPS)."}, {"title": "2.1.3 The Al's Turn: the Great Hope", "content": "Today, it appears to be the turn of AI, a turning point poised to revolutionize human capabilities and societal structures in ways we are only beginning to comprehend. The potential of AI to achieve TAI represents not just another leap in technological innovation, but a turning point that could redefine the trajectory of human progress. Unfortunately, it is impossible to anticipate precisely how this might occur. Previously, other technologies had similar disruptive potential but fell by the wayside, becoming part of a list of unfulfilled promises Floridi (2024). Some breakthroughs have had a profound impact on the world, whereas others, despite initial promise, have failed to achieve the level of adoption or impact that was anticipated (Christensen, 2015; O'Reilly III and Tushman, 2021). Rapid advancements in AI have already demonstrated its ability to perform tasks once thought uniquely human. However, the transition to TAI requires overcoming several key challenges. Next, we briefly introduce some of them to guide the reader, but they will be discussed in more depth in the chapters of this work.\nFirst, AI must transcend narrow domains and develop the capacity for generalization, allowing it to adapt knowledge and skills across diverse fields. This would involve significant progress in areas such as transfer learning (Zhu et al., 2023), unsupervised learning (James et al., 2023), or the recent world models (Xiang et al., 2024), by which AI systems learn internal representations of their environments. Second, the development of reasoning and causal inference mechanisms is crucial. Current AI models, while powerful, primarily rely on statistical correlations rather than understanding the underlying cause-and-effect relationships within data. Embedding causal reasoning would enable AI to predict outcomes, simulate scenarios, and make decisions with greater depth and reliability, thereby closing the gap between specialized AI systems and the general-purpose reasoning required for TAI. Third, achieving TAI demands unprecedented levels of computational power and optimization. Innovations in hardware could include e.g., neuromorphic computing or quantum technologies; they would be likely to play a critical role in bridging this gap. These advancements, coupled with efficient energy utilization and scalable architectures, would provide the necessary infrastructure to support the vast computational demands of TAI systems. Finally, ethical and philosophical considerations must guide this pursuit. TAI is not merely a technological milestone but a societal one, with implications for employment, governance, security, and even the nature of humanity itself. Collaborative global efforts that incorporate interdisciplinary perspectives would be vital to ensure that the development of TAI aligns with human values, mitigates risks, and maximizes its benefits for all.\nApproaching and understanding AI through the lenses of Ethics is paramount in ensuring its responsible and beneficial development. The next section helps us understand the relevance of wrapping AI in an ethical framework, and how to deal with the possible arrival of TAI."}, {"title": "2.2 The Relevance of Ethical Perspectives in Al", "content": "The way humans' ethics perceives AI is of paramount importance in its path toward achieving TAI, becoming into a disruptive and enabling technology in our civilization. This perception affects not only its adoption and regulation, but also the development of applications in key areas such as medicine, economics, and decision-making. Today we live in a world dominated by the use of technology, and in particular the application of AI everywhere. There are several philosophical perspectives on AI that we should consider to really understand how and why we have reached such a point; each one providing unique insights and raising distinct ethical, metaphysical, and epistemological questions (Table 2.1). All of them conform to the current AI understanding and the global view, essential to comprehend the impact and consequences of our actions and decisions, our interests, our morals, and our future as a civilization. The purpose of this section is far from being an exhaustive analysis of the different philosophical theories, but to indicate how the most widespread ones have had, have, and will have, a great influence in explaining how each of us perceives AI, and in what form TAI could be adopted (or not):\n\u2022 Utilitarianism From an utilitarian perspective, the development and application of AI should focus on maximizing overall happiness and minimizing suffering. Utilitarianism, as a consequentialist theory, evaluates the morality of actions based on their outcomes, and in the context of AI, this implies that AI systems should be designed and employed to generate the greatest possible benefit for the largest number of people. For instance, AI could be used in healthcare to optimize diagnoses, improve treatment outcomes, and allocate resources efficiently, thereby improving the well-being of entire populations. Similarly, AI can enhance societal welfare by automating dangerous or tedious tasks, reducing risks to human workers, and minimizing suffering. However, utilitarianism also faces ethical challenges in the context of AI, particularly when it comes to privacy and individual rights. Utilitarian principles could justify actions like the use of personal data without consent if doing so results in a greater good for the majority, which raises concerns about fairness and exploitation. Therefore, while utilitarianism emphasizes the benefits of AI for the majority, it must also carefully balance these benefits against potential harms to individuals or minority groups (Cvik, 2022).\n\u2022 Deontological Ethics It focuses on the adherence to moral duties and principles, regardless of the consequences. In the context of AI, deontological ethics emphasizes the importance of designing AI systems that respect fundamental rights and adhere to strict ethical standards, regardless of the outcomes those systems may produce (Mougan and Brand, 2023). A deontological approach to AI prioritizes respect for individual privacy, autonomy, and dignity, ensuring that AI technologies do not violate moral rules such as the right to personal data protection or the right to be treated equally. For instance, deontological ethics demands that AI systems used in hiring or law enforcement are free from bias and discrimination, respecting each person's inherent value. Transparency and accountability are also critical in a deontological framework, where AI systems must provide clear justifications for their decisions and allow for human oversight. This perspective often clashes with more consequentialist (e.g., utilitarianism) approaches because it upholds the primacy of ethical rules, even when doing so may limit the overall benefits AI could provide. Deontological ethics in AI emphasizes the need for moral consistency, fairness, and respect for universal principles, which can conflict with purely outcome-based strategies.\n\u2022 Virtue Ethics (the Aristotelian View) It addresses the development of moral character and the cultivation of virtues such as wisdom, courage, and justice. To AI, this approach encourages the design and application of AI systems in ways that promote human flourishing (eudaimonia) and support the development of virtuous behaviors. Rather than focusing solely on rules or outcomes, virtue ethics in AI looks at how these technologies can enhance the moral and intellectual development of individuals and society. For example, educational AI systems could be designed not only to improve academic performance but also to encourage traits such as perseverance, curiosity, and ethical reasoning. Similarly, AI applications in healthcare could promote holistic well-being by supporting patients in building habits that enhance both their physical and mental health. Virtue ethics also places a strong emphasis on the communal aspect of human life, suggesting that AI should be designed to foster cooperation, empathy, and social harmony. However, a significant challenge for applying virtue ethics to AI lies in its lack of specific guidelines for addressing complex moral dilemmas (Hagendorff, 2022), making it challenging to implement in technical systems that depend on clear, explicit instructions.\n\u2022 Contractualism John Rawls focused on the idea that moral principles are those that individuals would agree under fair conditions (Rawls, 2017). In the context of AI, this theory suggests that the ethical development and application of AI systems must be grounded in rules and practices that all rational individuals would accept as just and fair. This perspective is particularly relevant in areas like algorithmic fairness and justice, where AI systems used in hiring, criminal justice, or credit scoring, must be designed to prevent discrimination and promote equality. Under a contractualist framework, AI systems should be transparent, accountable, and designed with the input of all stakeholders to ensure that their decisions are perceived as legitimate and just. Additionally, Rawls' concept of the \u201cveil of ignorance\" (Rawls, 2017), where decision-makers are asked to design systems without knowing their own position in society, could guide the creation of AI technologies that prioritize the needs of the most disadvantaged. This approach emphasizes the social contract and the need for fairness in the distribution of AI's benefits and burdens, but it can be criticized for being too idealistic or difficult to implement in practice, especially in contexts where societal agreements are not easily reached.\n\u2022 Ethics of Care It emphasizes relationships, empathy, and responsibility toward others, offering a distinct approach to AI that focuses on using technology to foster care and support for individuals, particularly the vulnerable (Held, 2006). In AI applications, this theory advocates for systems that prioritize human well-being, emotional support, and relational bonds, rather than merely efficiency or profit. For example, AI systems in healthcare could be designed to assist caregivers in providing personalized, compassionate care for the elderly, children, or individuals with disabilities. AI could also be used in social robotics or mental health services to offer emotional support, enhancing the emotional and psychological well-being of users. The ethics of care stresses the importance of context and the specific needs of individuals, which implies that AI systems should be adaptable to different caregiving situations and should consider the emotional and social impact of their interactions with humans. However, a potential criticism of this approach is that it may not scale easily to larger, impersonal systems or more complex societal issues, and it might struggle to provide clear ethical guidelines for AI decision-making in areas that extend beyond personal relationships or caregiving contexts."}, {"title": "2.2.1 Challenges in Translating Ethical Perspectives to Al", "content": "Articulating ethics in AI is inherently challenging due to the vast diversity of beliefs, cultural values, and moral frameworks that exist globally. Ethical principles are deeply rooted in social, historical and religious contexts, which vary significantly across regions and communities. For instance, a principle deemed ethically sound in one culture may conflict with the values of another. This pluralism complicates the process of defining universal ethical standards for AI systems, especially those designed for deployment on a global scale. Moreover, philosophical traditions differ in their approaches to morality. Western ethical frameworks, such as utilitarianism and deontology, often emphasize individual rights and rational decision-making, whereas non-Western perspectives, such as Confucianism or Ubuntu, may prioritize relational harmony and communal well-being. These differences create tension in determining which ethical principles should guide AI development, usage, and governance.\nTranslating ethics into rules is the most practical and accessible way to apply ethical principles (Hagendorff, 2022), particularly in AI, offering clarity, consistency, and scalability, which are essential for integrating ethical considerations into decision-making processes. By converting abstract ethical principles into explicit rules, systems can operate autonomously while adhering to predefined moral standards. However, translating ethical perspectives into concrete rules for implementation in AI depends on the structure and principles of each framework. Some ethical theories, due to their normative clarity and formal structure, lend themselves more readily to codification:\n\u2022 Deontological ethics is inherently rule-based, providing clear guidelines such as \"do not lie\" or \"or not harm\", which can be directly encoded into algorithms as constraints or rules. However, while clear, deontological rules can be rigid and may struggle to adapt to complex scenarios where duties conflict, such as when respecting privacy may impede public safety.\n\u2022 Utilitarian ethics is mathematically compatible with algorithmic systems, as AI can optimize predefined utility functions to maximize benefits or minimize harm. However, it requires quantifying well-being, which is often subjective and culturally dependent. Additionally, it may sacrifice individual rights for the collective good, leading to ethical dilemmas.\n\u2022 Contractualism lends itself well to regulatory frameworks and compliance models in AI, where systems are designed to adhere to established policies or social contracts. However, achieving global consensus on ethical principles is difficult particularly in culturally diverse contexts, as mentioned before.\nConversely, others are inherently interpretative or context-dependent, making them challenging to operationalize:\n\u2022 The concepts of virtue ethics are abstract and context-dependent, lacking clear rules for specific actions. Translating virtues into operational rules for AI is challenging because virtues often require subjective judgment and adaptability. While an AI system can mimic virtuous behavior, truly embodying virtues such as empathy or fairness in a human sense may exceed current technological capabilities.\n\u2022 Unlike rule-based systems, ethics of care relies on understanding individual needs and fostering connections, which are inherently dynamic and situational. AI systems, which operate on generalized models, struggle to capture the nuances of relational ethics. Implementing ethics of care requires AI systems capable of deep contextual understanding and emotional intelligence, both of which are still nascent fields.\nFinally, many of the major ethical perspectives, such as utilitarianism, deontologism, or virtue ethics often seem to conflict with each other because of their different approaches to what constitutes morally a right action (see Figure 2.2). Utilitarianism and deontologism often clash when rules or duties (deontological principles) contradict actions that could maximize overall good (utilitarian outcomes). Likewise, virtue ethics may not always provide clear guidelines for action, especially when outcomes are ambiguous."}, {"title": "2.2.2 Reconciliation between Ethical Perspectives", "content": "We have seen how difficult is to bring some of the ethical perspectives into practice. However, there are alternatives to reconcile some of these perspectives into a more complementary and balanced ethical framework, capable of more robustly addressing the ethical challenges posed by AI, and which could facilitate its implementation. Next we present some examples:\n\u2022 Virtue Ethics Combined with Rule-based Approaches Virtue ethics focuses on the moral character and virtues of the individuals or systems involved, such as fairness, responsibility, and transparency. To reconcile this with deontological and consequentialist approaches, AI systems can be designed not only to follow rules but also to foster virtuous traits. For example, AI decision-making systems could be structured to prioritize transparency and fairness, while also embracing utilitarian principles when maximizing societal benefit (e.g., in healthcare or resource distribution). A practical application could involve combining virtue ethics to promote traits like trustworthiness and compassion while using deontological rules to set limits (e.g., ensuring privacy), and utilitarianism to evaluate the overall benefits.\n\u2022 Ethics of Care and Utilitarianism Ethics of care emphasizes relational and contextual ethics, focusing on the well-being of specific individuals or groups. It can complement utilitarianism by addressing the blind spots in general welfare maximization, particularly for vulnerable populations. AI systems, under this reconciliation, could be designed to prioritize care for vulnerable individuals (e.g., in eldercare or personalized healthcare), while still optimizing overall social welfare. In designing AI for social services, algorithms could balance caring for individual clients with the utilitarian goal of maximizing overall service efficiency.\n\u2022 Utilitarianism with Deontological Safeguards Utilitarianism often prioritizes outcomes, sometimes at the expense of inviolable rights. To reconcile this, deontological principles can provide essential safeguards. For instance, AI-driven systems could maximize beneficial outcomes (such as reducing traffic accidents) but must operate within strict rules that protect individual rights, like privacy or non-discrimination. In autonomous driving, the system could be designed to minimize accidents (a utilitarian goal) but also ensure strict adherence to human rights laws regarding data privacy and safety standards.\n\u2022 Through Contractualism Based on the principles of fairness and mutual agreement, contractualism can serve as a foundational framework to reconcile other ethical theories. By developing AI under a social contract where stakeholders agree on fair terms, conflicting ethical perspectives, such as utilitarianism and deontologism, can be balanced. For example, contractualism can help define when to prioritize individual rights (deontological limits) and when to maximize the common good (utilitarian concerns). Then, Rawls' \"veil of ignorance\" (Rawls, 2017) can be applied to ensure that AI technologies are developed and deployed in fair ways, especially for the most disadvantaged. It allows the balancing of utilitarian outcomes (benefits for the majority) with deontological commitments to protect fundamental rights."}, {"title": "2.2.3 Unpacking the Ethical Perspectives of the EU AI Act", "content": "The AI Act has been developed as a comprehensive regulatory response to the rapid advances and increasing deployment of AI technologies. Its main objective is to ensure that the use of AI in Europe is safe, ethical and respectful of fundamental rights, while fostering innovation and protecting the European single market (D\u00edaz-Rodr\u00edguez et al., 2023). But its application is not exempt of its own problems (Novelli et al., 2024). We must look at the Act through this lens, that of a single ethical perspective capable of reconciling with others and possessing an inherently integrative capacity, thus being ethically grounded in a combination of theories, reflecting a pluralistic ethical framework. The Act can be seen as a formalization of a social contract between governments, developers, businesses, and the public, establishing clear rules to regulate the use of AI in a way that is justifiable to all parties involved, and that reconciles several ethical perspectives:\n\u2022 Contractualism The Act's emphasis on transparency, accountability, and the protection of fundamental rights aligns with the contractualist idea that moral actions should be acceptable to all rational agents. By requiring that AI systems be designed and deployed in ways that respect human dignity, the Act can be understood as a set of agreed-upon norms to prevent harm and promote fairness. It aims to ensure that no individual is unfairly disadvantaged by AI systems, particularly in high-risk areas such as healthcare, employment, and law enforcement. Additionally, the risk-based framework can be seen as a reflection of contractualist principles, as it distinguishes between acceptable and unacceptable levels of risk, ensuring that individuals are not exposed to AI systems that pose unreasonable risks to their well-being.\n\u2022 Deontologism The emphasis of the Act on human dignity, transparency, and accountability can be viewed through a deontological lens as an affirmation of the moral duty to respect individuals as ends in themselves, not merely as means to technological advancement or economic gain. The requirements of the Act for informed consent and explainability in high-risk AI systems, such as biometric identification or AI used in law enforcement, reflect a deontological commitment to respecting individuals' rights to autonomy and informed decision-making. It recognizes that humans should not be treated as passive subjects under AI systems without understanding how these systems impact them or having the ability to challenge AI-driven decisions. The duty to avoid harm, central to deontological ethics, is also mirrored in the safety requirements for AI systems. The Act imposes strict guidelines to prevent foreseeable risks, ensuring that developers and deployers of AI systems act under their moral responsibilities to protect individuals from harm, even if doing so may limit certain technological capabilities or innovations.\n\u2022 Utilitarianism The Act can be interpreted as an attempt to balance the benefits and risks of AI by creating a regulatory framework that maximizes the positive impact of AI technologies while minimizing potential harm to individuals and society. The risk-based approach of the Act to AI governance reflects a utilitarian concern with ensuring that AI systems provide net benefits to society. High-risk AI systems are subject to stricter regulations to ensure that they do not cause disproportionate harm compared to their potential benefits. For instance, AI used in critical infrastructure or law enforcement must undergo rigorous scrutiny to ensure that it enhances societal well-being without infringing on individuals' rights or safety. Additionally, the focus on innovation and the promotion of AI technologies in sectors like healthcare, where they can lead to improved outcomes for many, aligns with the utilitarian goal of promoting the greatest good for the greatest number. However, utilitarianism also raises concerns about the trade-offs involved: the Act must ensure that maximizing societal benefits does not unjustly sacrifice the rights of vulnerable individuals or groups, especially in cases where AI systems may inadvertently perpetuate biases or inequalities.\n\u2022 Virtue Ethics The Act can be understood as encouraging the development of virtuous practices in AI development and deployment by promoting traits like responsibility, transparency, fairness, and trustworthiness. By requiring developers and users of AI to be accountable for the systems they create and deploy, the Act fosters a sense of moral responsibility and ethical reflection. Virtuous AI developers are expected to take into account the social and moral implications of their technologies, ensuring that their work contributes to the common good and does not cause harm. The focus of the Act on trustworthiness aligns with the virtue of integrity. Trustworthy AI systems are those that are reliable, transparent, and fair. The regulatory requirements for algorithmic transparency and explainability aim to ensure that AI systems are designed and used in ways that reflect the virtues of honesty and respect for others, promoting public confidence in the ethical use of AI.\n\u2022 Rawlsian Justice The Act can also be interpreted through the lens of justice as fairness. According to Rawls, a just society is one that ensures equal rights and fair opportunities for all individuals, particularly the most vulnerable. The focus of the Act is on preventing discrimination and ensuring that AI systems are deployed in ways that are fair and just, aligning with Rawlsian principles. The commitment of the Act to preventing bias and ensuring fairness in AI systems (particularly in areas such as employment, credit scoring, and law enforcement) reflects the Rawlsian concern for protecting those who might be most negatively affected by biased or unfair AI decisions. The Act ensures that AI systems do not exacerbate existing inequalities and that they provide fair opportunities and outcomes for all individuals, regardless of their socio-economic status, gender, race, or other characteristics. Additionally, the transparency and accountability mechanisms built into the Act ensure that decisions made by AI systems can be scrutinized and challenged, allowing individuals to appeal AI-driven decisions that may affect their rights or opportunities. This promotes procedural justice, ensuring that the processes governing AI systems are fair and inclusive."}, {"title": "3 From AI Today to the Challenges of TAI", "content": "After presenting some of the most relevant ethical perspectives on AI and their consideration in the EU AI Act, the next chapter explores how AI has come to play such a significant role in our lives, as it has in the past."}, {"title": "3.1 The Omnipresence of Al Today", "content": "AI is not a field that has recently emerged with the appearance of generative AI and the next-generation chatbots. AI as a field of study has been with us since the 1950s (McCarthy et al., 2006), and has always raised expectations that have so far been difficult to meet. The truth is that since ancient times, we can find references and ideas about the creation of beings with human characteristics, automata, or mechanical devices with mathematical and logical foundations, up to the appearance of the Turing machine (Turing, 1936) as a prelude to this new field of study."}, {"title": "3.1.1 A Time in the Shadows", "content": "Since its inception, the field of AI has experienced several cycles of optimism and stagnation, often referred to as \"AI summers\" and \"AI winters\" (see Figure 3.1). These periods of intense research enthusiasm and investment have alternated with phases of disillusionment and reduced funding, as early technological promises failed to materialize. In the mid-20th century, initial advancements in symbolic reasoning and rule-based systems sparked the first wave of excitement. However, the limited scalability and adaptability of these systems, coupled with the computational constraints of the time, led to the first major AI winter in"}]}