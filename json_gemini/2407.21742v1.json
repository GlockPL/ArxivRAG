{"title": "HGOE: Hybrid External and Internal Graph Outlier Exposure for Graph Out-of-Distribution Detection", "authors": ["Junwei He", "Qianqian Xu", "Yangbangyan Jiang", "Zitai Wang", "Yuchen Sun", "Qingming Huang"], "abstract": "With the progressive advancements in deep graph learning, out-of-distribution (OOD) detection for graph data has emerged as a critical challenge. While the efficacy of auxiliary datasets in enhancing OOD detection has been extensively studied for image and text data, such approaches have not yet been explored for graph data. Unlike Euclidean data, graph data exhibits greater diversity but lower robustness to perturbations, complicating the integration of outliers. To tackle these challenges, we propose the introduction of Hybrid External and Internal Graph Outlier Exposure (HGOE) to improve graph OOD detection performance. Our framework involves using realistic external graph data from various domains and synthesizing internal outliers within ID subgroups to address the poor robustness and presence of OOD samples within the ID class. Furthermore, we develop a boundary-aware OE loss that adaptively assigns weights to outliers, maximizing the use of high-quality OOD samples while minimizing the impact of low-quality ones. Our proposed HGOE framework is model-agnostic and designed to enhance the effectiveness of existing graph OOD detection models. Experimental results demonstrate that our HGOE framework can significantly improve the performance of existing OOD detection models across all 8 real datasets.", "sections": [{"title": "1 Introduction", "content": "Nowadays, graph-structured data have shown significant success in handling non-Euclidean relationships, prevalent in multimedia systems such as social networks [41, 61], knowledge graphs [3, 4, 39], citation networks [7, 67]. These capabilities facilitate advanced applications like scene graph generation [6, 11], visual analysis [22], anomaly detection [16, 19] and recommender system [26], by modeling complex relationships between heterogeneous data types [32, 34, 36, 42, 53, 54, 60, 63, 66]. However, a significant challenge arises from the i.i.d. assumption on which the mainstream graph learning methods depend, i.e., the training and testing graph data are from the same distribution. This assumption often fails in real-world scenarios, particularly in domains where data is complex and lacks sufficient labeling, such as in the case of drug molecules and proteins. For example, a new drug might not be any part of the already annotated data. Consequently, this gives rise to an interesting issue: how to determine whether such a new drug is present in the annotated drug library? This problem, known as Graph Out-Of-Distribution (GOOD) detection, is crucial in advancing the use of graph learning in real-world scenarios.\nAlthough several methods for graph OOD detection have been developed [31, 35, 64], they only utilize ID graph data. When the full data distribution is complicated, merely modeling the ID data might be insufficient to capture the essential clues for OOD detection.\nIn fact, auxiliary public OOD data is often accessible to help the detector discover such clues. Exposing such auxiliary OOD data to the model, also known as Outlier Exposure (OE), is widely studied for image data [10, 18]. However, the application of OE for graph samples has not yet been explored. To bridge this gap, we attempt to investigate the incorporation of OE into graph OOD detection.\nUnlike image data, introducing outliers to assist in the OOD detection of graph data presents two significant challenges.\nFirstly, since graphs are abstractions of patterns from the natural world, they exhibit inherent diversity. For instance, various non-Euclidean structures ranging from water molecules to complex social networks can be represented using graphs, yet these graphs can significantly differ in structure and properties. In contrast, images possess a Euclidean structure, which facilitates easier feature transfer. Therefore, utilizing existing graphs as outliers directly is often not effective.\nSecondly, graph data exhibits less robustness to perturbations, resulting in the possibility of OOD samples existing within the boundary of ID classes. For example, as illustrated in Figure 1, phenol and benzene differ only by a hydrogen atom and an oxygen atom, yet exhibit vastly different properties; phenol is solid at room temperature, while benzene is liquid. This suggests that slight perturbations could transform ID graph sample into an OOD sample. In contrast, image data typically exhibit a more compact intra-class distribution and more well-separated classes (e.g., dogs and cats), where minor perturbations often do not change their categories. Therefore, merely incorporating some external outliers for exposure could be effective for image data. But considering that outliers may exist even within the same class of graphs, the external outlier exposure remedy is insufficient for graph OOD detection.\nTo address the first challenge, existing studies suggest that introducing diverse outliers closer to the in-distribution data is beneficial. Therefore, given the inherent diversity of graph data, we propose incorporating cross-domain external outliers into training. Moreover, in addition to these external outliers, we aim to synthesize outliers that are nearer to in-distribution data. Regarding the second challenge, since there exist subgroups within a class, and outliers also exist between these subgroups, we consider synthesizing some internal outliers between subgroups to assist in OOD detection. Because these samples are close to In-Distribution samples, if the model can accurately identify these samples, it would further enhance the OOD detection performance.\nMotivated by this, we propose a general hybrid graph outlier exposure (HGOE) framework for graph OOD detection which integrates both external and internal outliers. The external outliers are easily collected from public database. As for internal graph outliers, we design a graphon-based ID-mixup strategy to simulate the OOD region among subgroups and synthesize OOD samples. Given these outliers, we further propose a boundary-aware OE loss to adaptively learn from true outliers and prevent the unintended bias.\nIn summary, the contributions of this paper are as follows:\n\u2022 We propose a novel hybrid graph outlier exposure framework for graph OOD detection. It simultaneously utilizes external outliers and internal outliers to enhance the diversity. To the best of our knowledge, this is the first trial of outlier exposure in graph-level OOD detection tasks.\n\u2022 To synthesize internal outliers, we design an ID-mixup method that can effectively generate outlier graph samples between ID subgroups based on graphons.\n\u2022 We further introduce a novel boundary-aware loss. By instantiating the HGOE framework with a SOTA detector, we have surpassed the competitors on 8 real-world graph datasets."}, {"title": "2 Related Work", "content": "Graph Neural Networks. Graph neural networks (GNNs) have been widely adopted in various deep learning tasks due to their ability to process graph-structured data, which can effectively extract both the structural and attribute information of graphs [13, 23, 47]. GNNs have achieved remarkable results in various deep learning tasks in recent years, such as recommendation systems, natural language processing and computer vision [49, 67]. GNNs can be broadly categorized into two distinct classes, which encompass spectral-based GNNs and spatial-based GNNs [68].\nExisting Spectral-based Graph Neural Networks leverage spectral graph theory for graph analysis, offering the advantage of incorporating global graph topology information. However, they also exhibit certain limitations, including high computational complexity, challenges in handling dynamic or heterogeneous graphs, and a deficiency in local perception ability [51]. For instance, ChebNet approximates spectral graph convolutions using Chebyshev polynomials of arbitrary order, while GCN simplifies this by employing only the first two Chebyshev polynomials as the graph convolution, effectively creating a fixed low-pass filter[40].\nSpatial-based Graph Neural Networks leverage the spatial information of nodes within the graph to perform graph convolutions[21]. These networks are rooted in message-passing mechanisms[23, 57], wherein each node updates its features based on the features of its neighboring nodes. Notably, Graph Attention Networks (GAT)[48] introduce a self-attention mechanism to compute node neighbor weights, allowing for dynamic and adaptive aggregation within neighborhoods. GAT further enhances model capacity by employing multi-head attention. Meanwhile, GraphSAGE[14] learns how to aggregate node features from various sources using diverse functions like mean, max-pooling, or LSTM, making it suitable for inductive learning tasks that involve new nodes or graphs during testing. Graph Isomorphism Networks (GIN)[57], another class of graph convolutional network, employ sum and MLP operations to aggregate node features. Additionally, Graph Structural Neural Networks [55] provide a versatile solution for incorporating structural graph properties into the message-passing aggregation scheme of GNNs."}, {"title": "3 Preliminaries", "content": "In this section, we provide definitions for key terms and concepts utilized throughout this paper."}, {"title": "3.1 Problem Setting", "content": "Denote a graph by G = (V, &, X), where V denotes the set of nodes, & denotes the set of edges, and X \u2208 \u211d^(n\u00d7d) is the node feature matrix. The adjacency matrix is denoted as A \u2208 {0, 1}^(n\u00d7n), where Aij = 1 indicates a connection between nodes vi and vj and Aij = 0 otherwise.\nIn this paper, we focus on the unsupervised graph-level OOD detection problem. Specifically, given a set of unlabeled in-distribution graphs Din = {Gi} drawn from the distribution Pin, the aim of unsupervised graph-level OOD detection is to learn a graph OOD scoring function f(.) based on the ID data Din. A higher score s = f(G) indicates a higher probability to be an OOD graph. The scoring function is evaluated on a test set Dtest = Din \u222a Dood (Din \u2229 Dood = \u2205) where Din ~ Pin and Dood ~ Pout. It should be emphasized that graph data sourced from Pin and Pout might fall into multiple categories. However, in the unsupervised graph-level OOD task, the model is not provided with any category-specific labels."}, {"title": "3.2 Graphon", "content": "A graphon, denoted by the function W: [0, 1]\u00b2 \u2192 [0, 1], is a continuous, bounded, and symmetric function in graph theory, extensively used to describe graph generation [1]. The value W(i, j) approximates the probability of an edge between nodes i and j in a specific graph. A graphon can be considered as a function that embodies the characteristics of a class of graphs, allowing for the sampling of graphs from the graphon. These sampled graphs share similar topological features. Distinct graphons represent different graph classes, enabling comparative analysis of their structural features. These graphons are estimated using step function approximations [33]. Graphons are particularly useful in synthesizing new graphs that reflect patterns found in real-world data, offering insights into the underlying structure of complex networks. However, there is no closed-form expression for graphons. Previous studies [15, 56] have employed a two-dimensional step function to estimate graphons, which can be considered a matrix representing the probability of edge existence. In this paper, we denote it as W \u2208 [0, 1]^(D\u00d7D), where D is the dimensionality of the graphon. This matrix W can then be used to generate graphs with a number of nodes less than D."}, {"title": "4 Methodology", "content": "4.1 Overall Framework\nIn general, with a graph OOD score function f(G), the basic learning objective for unsupervised graph OOD detection can be described as:\nmin_f \ud835\udd3c_(G~Din) [\u2112_ood (f(G))],  (1)\nwhere \u2112_ood is the loss function.\nBy integrating the hybrid graph outlier exposure (HGOE) procedure, we hope the exposed OOD data have higher OOD scores than ID data. Subsequently, we simultaneously minimize the OOD score of ID data and maximize that of OOD data:\nmin_f \ud835\udd3c_(G~Din) [\u2112_ood (f(G)) + \u03b2 \u00b7 \ud835\udd3c_(G'~DOE) [\u2112_GOE (f(G), f(G'))]].  (2)"}, {"title": "4.2 Mixture Outlier Training Strategy", "content": "Our mixture outlier training strategy incorporates outliers from two sources: real-world external outliers and synthesized internal outliers. External outliers are derived from public graph datasets similar to the training graphs, while internal outliers are generated from ID graphs.\nExternal Outliers. In contrast to image data, graph data in the real world display significantly more complex structures, with notable gaps in characteristics between fields like social networks and protein networks. To investigate the role of real-world outliers, we sample from several graph datasets to create a real-world OE dataset. During the training of different ID data, we select graphs from the OE dataset that are consistent with them in feature dimensions, ensuring no overlap between the OE graphs and the training and test sets. This process results in an external outlier dataset, denoted as Dext.\nInternal Outliers. The quality and diversity of external outliers data are crucial for outlier exposure, but are limited by the scope and quality of the existing auxiliary dataset. Synthesizing additional outliers then emerges as a solution, offering tailored, abundant, and diverse graph data for training. However, the challenge lies in ensuring that the synthesized data resonates with real-world outlier scenarios and does not introduce unintended biases. As discussed in the introduction, there exist internal outliers among the in-distribution graph data, which are distributed near the boundaries of subgroups. To obtain these internal outlier samples, we design an internal outlier generation strategy, which will be described in the next subsection."}, {"title": "4.3 Internal Outlier Synthesis", "content": "A straightforward way to generate graphs is to interpolate each pair of samples in the dataset directly. However, unlike Euclidean data such as images, different graphs usually have different sizes (e.g., different numbers of nodes) and have unique topology in Non-Euclidean spaces. Therefore, we propose to mix up the graph generators instead of graph samples themselves to synthesize more realistic graph data.\nTo find internal outliers for input graphs, it is imperative to first divide the graphs into subgroups. For the input ID graphs, we adopt graph contrastive learning techniques (e.g., GraphCL [62]) for feature extraction, and then perform k-means clustering to obtain k subgroups Ci, where Din = \u222a_(i=1)^k Ci. Since the members in each subgroup often share similar properties, we assume that each subgroup within the ID data is generated by a specific graphon. And we use the widely-used universal singular value thresholding (USVT) method [5] to estimate the graphon Wi for each Ci in Din.\nFor each pair of non-overlapping subgroups Ci and Cj in Din, we perform a mixup operation over the corresponding graphons Wi and Wj as follows:\nM = \u03bbWi + (1 \u2212 \u03bb)Wj, (3)\nwhere \u03bb\u2208 [0, 1] is the balancing hyperparameter. The mixup result M combines the structural features of subgroups Ci and Cj, and can be considered a new graph generator positioned between the two subgroups. By sampling based on this graphon, we could obtain graphs lying in the interpolated regions between these subgroups, preserving the subgroups's topologies.\nRandom Size Based Sampling. The interpolated graphon M\u2208 [0, 1]^(N\u00d7N) has the capability to generate infinitely many graphs. However, the naive generated graphs are very likely to have a size around N. This limits the diversity of the synthesized outliers, which does not meet our goal in the HGOE framework to synthesize outliers broadly distributed near the original subgroups, with various sizes of graphs. In order to increase the diversity of outliers, we employ a random size based sampling strategy. We first randomly sample the size of the graph r\u2208 [2, N] and then generate the graph from the sampled graphon M' \u2208 [0, 1]^(r\u00d7r). The existence of an edge between nodes i and j is determined by sampling from a Bernoulli distribution with the parameter M'(i, j).\nExternal Feature Alignment. Merely sampling from the interpolated graphons could only produce pure structure graph outliers with the structure information (denoted as A'). Therefore, we further propose to generate node features based on external outlier features. Specifically, we calculate the structural features of both the generated internal outlier structure A' and the external outliers. And then we construct the node features for the generated internal outliers based on that of the external outliers with the most similar structure features. Here, the structural features sdiff of the i-th node in a ds-dimensional space is obtained through a ds-step random walk-based diffusion process on the graph:\ns_diff = Ti, Ti^2, ..., Ti^d_s, (4)\nwhere T = A'D^(-1) denotes the transition matrix for the random walk on the graph, and D is the degree matrix of A'. After computing the structural features of A', we compare them with the structural features of external outliers. For each node in the synthesized internal outlier G', we assign node features that are most closely aligned with the structural features of nodes in the external outliers. Note that our external feature alignment approach is training-free. By performing structural searches on nodes with existing features, we can effectively assign outlier features to nodes that initially lack features.\nThrough the aforementioned ID-mixup based procedure, we can generate an arbitrary number of internal outliers, denoted as Dint. Compared to real-world outliers, these synthetic outliers are not limited in quantity or source. Furthermore, being located near in-distribution samples, they effectively compensate for the uncontrolled quality issue of external outliers."}, {"title": "4.4 Boundary-Aware OE Loss", "content": "The introduced outliers further present two critical issues: How can we ensure that the introduced outliers do not fall within the in-distribution area, and how to find those more important outliers?\nTake the social graph ID data as an example. Intermixing social graphs could still result in a social graph, so the generated samples are not OOD data and should be excluded from the outlier dataset. At the same time, different outliers can have varying levels of importance, with points on the boundary potentially being critical points where a change in properties is about to occur.\nTo solve these problems, we design the following boundary-aware OE Loss lba which is adaptively aware of whether the sample is in ID or OOD space. For an input outlier graph G', the loss is calculated as:\nl_ba (s_G', \u03c4) = -(1 - s_G') max(log(s_G'), \u03c4), (5)\nwhere s_G' = sigmoid(f(G')) is the OOD score scaled by a sigmoid function, \u03c4 and \u03b3 are hyperparameters. Note that \u03c4 is an ID-boundary threshold, which we adaptively set as the smallest s among the ID samples:\n\u03c4 = min_(G\u2208Din) sigmoid(f(G)). (6)\nTo better understand Eq. (5), we rewrite it in the following form:\nl_ba (s_G', \u03c4) = { -(1-s_G')log(s_G'), if log(s_G') > \u03c4\n-\u03b3\u03c4(1 - s_G'), if log(s_G') \u2264 \u03c4 (7)\nFrom this formulation, we have the following observations:\n\u2022 When log(s_G') > \u03c4, it indicates that G' is a valid outlier. In this case, the smaller s_G' is, the closer it is to the in-distribution boundary. Apparently, such near-boundary outliers are important in guiding the detector to distinguish OOD samples from ID ones. Therefore, we weigh it by the term (1 - s_G'), giving higher weights to these boundary samples. As \u03b3 increases, the model pays more attention to samples nearer to the ID boundary.\n\u2022 When log(s_G') < \u03c4, it means that the outlier G' is very likely invalid and fall into in-distribution space. Blindly treating it as an outlier might be harmful to the learning. Therefore, by minimizing -\u03b3\u03c4(1 \u2013 s_G'), the OOD score is reduced, which enhances the recognition ability for in-distribution samples.\nThen, considering both external and internal outliers, the total graph outlier exposure loss is formulated as:\n\u2112_GOE = \u03a3_(G'\u2208D_int\u222aD_ext) l_ba (s_G', \u03c4). (8)\nFinally, we can instantiate the overall training objective \u2112 as follows:\n\u2112 = \u03a3_(G\u2208Din) [\u2112_ood (f(G)) + \u03b2 \u03a3_(G'\u2208D_int\u222aD_ext) l_ba (s_G', \u03c4)]\n= \u03a3_(G\u2208Din) \u2112_ood (f(G)) + \u03b2 \u03a3_(G'\u2208D_int\u222aD_ext) l_ba (s_G', \u03c4). (9)\nIn practice, our \u2112_GOE can be added as a regularization term to most existing OOD detection models, without modifying their network architectures."}, {"title": "5 Experiments", "content": "5.1 Experimental Setup\n5.1.1 Datasets. We select three pairs of datasets from the TU dataset [38] and five pairs from the OGB dataset [20]. Each pair of datasets belongs to the same field and shares similar features, but exhibits distribution shifts between the two datasets in the pair. 90% of the In-Distribution (ID) samples are used for training, while 10% of the ID samples and an equivalent number of OOD samples are used for testing. For more detailed information about these datasets, refer to Table 1.\nFor external outlier data, we grouped datasets with identical feature counts into a unified external dataset. Based on the feature counts of our selected datasets, as detailed in Table 1, this organization resulted in two distinct external dataset collections, with node feature numbers being 1 and 9, respectively. In this configuration, for each In-Distribution dataset, we utilized other datasets from the corresponding external dataset collection for training purposes, deliberately excluding both the OOD dataset for testing and the ID dataset itself.\n5.1.2 Competitors. We adopt the following three categories of graph OOD detection methods as our competitors:\n\u2022 Non-deep Two-step Methods. We use WL [44] graph kernels as feature extractors and employ local outlier factor (LOF) [2], one-class SVM (OCSVM) [37], and isolation forest (iF) [30] as detectors to perform OOD detection.\n\u2022 Deep Two-step Methods. The process is similar to the above methods, but the feature extractor is replaced with graph deep self-supervised methods InfoGraph [45] and GraphCL [62], and the detectors are replaced with isolation forest (iF) and Mahalanobis distance (MD) [43]. Compared to graph kernels, self-supervised methods can extract features of graphs better.\n\u2022 End-to-end Methods. We utilize three popular end-to-end learning methods, including OCGIN [64], which uses graph neural networks for feature extraction and is optimized with SVDD. GLocalKD [35] uses distillation learning for graph anomaly detection, and GOOD-D [31] employs multi-level contrastive learning for end-to-end OOD detection.\nFor the proposed framework, we instantiate it on the SOTA graph OOD detector baseline GOOD-D [31]. Besides, we also implement two ablated variants to show the impact of internal and external outliers. Specifically, HGOE w/o IO and HGOE w/o EO denote the variants without internal and external outliers, respectively.\n5.1.3 Implementation Details. For HGOE, the ratio of external to internal outliers was set to 1:1, with the total number equal to the number of in-distribution samples seen during training. The hyperparameter \u03bb was set to 2, and \u03b3 was set to 2. The dimension of the structural features sdiff was set to 16, and the number of clusters for all datasets was determined to be 3. GraphCL was run for 50 iterations with an embedding dimension of 32, and the probabilities for node dropping, feature masking, and edge removing were all set to 0.1. During ID-mixup, \u03bb was randomly chosen from the range [0.01, 1]. AUC (Area under the ROC Curve) [28, 59] is used as the performance metric. A higher AUC value indicates better detection performance."}, {"title": "5.2 Main Results", "content": "We evaluate the performance of HGOE and other competitors, with the results presented in Table 2. Our findings include:\n(1) Two-step detection methods do not perform as well as end-to-end detection methods, especially where non-deep learning methods are inferior to deep learning-based feature extraction methods. Within self-supervised methods, GraphCL-MD demonstrates the best performance, showing GraphCL's capability in extracting features for graph OOD detection. This also explains why we chose to utilize GraphCL features for clustering.\n(2) For our HGOE framework, compared to GOOD-D without the use of graph outliers, there was an enhancement in performance across all 7 datasets. On the ENZYMES+PROTEIN dataset, the average performance improve from 60.15 to 64.44. On Tox21+SIDER, it increased from 64.98 to 68.24, and on FreeSolv+ToxCast, the performance increase from 78.79 to 83.36.\n(3) The performance improvement on IMDB-M+IMDB-B was not substantial because both are social datasets, and the outliers we introduce were from molecular and protein datasets, which are biologically oriented. However, using these as outliers still contributed to enhanced detection on IMDB-M+IMDB-B. This indicates that selecting outliers similar to the ID distribution, as opposed to introducing outliers completely unrelated to the ID data, is more effective."}, {"title": "5.3 Visualization", "content": "5.3.1 ID-mixup Visualization. After obtaining the subgroups within the known distribution, we performed a mixup of the estimated graphons and visualized the resulting mixed graphons in the form of heatmaps, as shown in Figure 3. The graphon in the center represents the result of performing ID-mixup on the two adjacent graphons. It is evident that the graphon after ID-mixup retains the structures of the original graphons, forming a new graph generator. This demonstrates that our ID-mixup can effectively blend the distributions of subgroups to a certain extent, fulfilling our hypothesis."}, {"title": "5.4 Ablation Study", "content": "5.4.1 Using Only One Type of Outliers. In Table 2, HGOE w/o IO and HGOE w/o EO represent the results of using only internal outliers and external outliers, respectively. We observe that using just one of these types yields better results than not using any OE (Outlier Exposure) samples at all. Moreover, in most cases, the performance of using only external outliers is superior to that of using only internal outliers, but inferior to using both types. This indicates that the combination of both types of outliers can more effectively enhance the performance of hybrid graph outlier exposure."}, {"title": "5.4.2 The Strategy for Adaptive Allocation of \u03c4", "content": "In Section 4.4, we introduce an adaptive parameter \u03c4 in the distribution-aware OE loss, which is set as the smallest normalized score among the ID samples. To explore the specific role of \u03c4, we implement methods setting \u03c4 according to the maximum, average, and minimum normalized scores. The results, as shown in Figure 3, indicate that the min strategy for allocating \u03c4 performs the best. However, this strategy negatively affects performance on the IMDB-M+IMDB-B dataset, which we believe is due to its significant difference from the other datasets."}, {"title": "5.5 Sensitivity Analysis", "content": "5.5.1 ID-mixup Weight \u03bb. We explore the sensitivity of HGOE with respect to \u03bb by evaluating its performance during ID-mixup across different \u03bb ranges. As seen in Table 4, we progressively narrow the range of \u03bb from [0.01, 1.0] to [0.4, 0.6]. In this process, a performance decline was observed in most datasets. This suggests that for ID-mixup, blending two in-distribution samples at varying ratios can increase the diversity of internal outliers, thereby enhancing detection effectiveness. However, an opposite trend of performance increase, rather than decrease, was observed in the CLintox+LIPO dataset pair. This anomaly may be related to the characteristics of these datasets, both being molecular graphs from the OGB and possessing extremely similar average node and edge counts, resulting in closer distributions. If ID-mixup outliers falling within the in-distribution range, it could lead to a greater performance decrease compare to other datasets. So when \u03bb is set to a middle value, the generated graphon lies between subgroups. This explains why choosing a \u03bb value range [0.3, 0.7] yields better results.\n5.5.2 Hyperparameter \u03b3 of Boundary-aware OE Loss. As described in our framework, \u03b3 plays a significant role in the boundary-aware loss. We vary the value of \u03b3 to {0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0}, and as observed in Figure 5, as \u03b3 increases, there is a performance improvement when \u03b3\u2208 [0, 2]. However, performance starts to decline for some datasets when it exceeds 2 and 2.5. This indicates that within an appropriate range, introducing \u03b3 can effectively weight the samples, and this effect improves with the increase of \u03b3, up to a point where it begins to decrease. This phenomenon validates the rationality and effectiveness of our designed boundary-aware OE loss."}, {"title": "6 Conclusion", "content": "In this work, we investigate the enhancement of OOD detection performance on graph-level data through hybrid graph outlier exposure. We demonstrate that not only external outliers are crucial for graph OOD detection, but internal outliers also play a significant role. Based on this, we propose a carefully designed ID-mixup based method for synthesizing internal outliers by generating OOD samples between in-distribution subgroups and aligning these with external outlier features. Upon obtaining these synthesized internal outliers, we effectively utilize the characteristics of outlier samples by adaptively allocating learning weights to OE samples using a well-designed boundary-aware OE loss. Our HGOE framework provide substantial performance improvements for other graph OOD detection methods. Extensive experiments on 8 real-world datasets show its superior performance."}]}