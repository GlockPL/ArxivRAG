{"title": "HGOE: Hybrid External and Internal Graph Outlier Exposure for Graph Out-of-Distribution Detection", "authors": ["Junwei He", "Qianqian Xu", "Yangbangyan Jiang", "Zitai Wang", "Yuchen Sun", "Qingming Huang"], "abstract": "With the progressive advancements in deep graph learning, out-of-distribution (OOD) detection for graph data has emerged as a critical challenge. While the efficacy of auxiliary datasets in enhancing OOD detection has been extensively studied for image and text data, such approaches have not yet been explored for graph data. Unlike Euclidean data, graph data exhibits greater diversity but lower robustness to perturbations, complicating the integration of outliers. To tackle these challenges, we propose the introduction of Hybrid External and Internal Graph Outlier Exposure (HGOE) to improve graph OOD detection performance. Our framework involves using realistic external graph data from various domains and synthesizing internal outliers within ID subgroups to address the poor robustness and presence of OOD samples within the ID class. Furthermore, we develop a boundary-aware OE loss that adaptively assigns weights to outliers, maximizing the use of high-quality OOD samples while minimizing the impact of low-quality ones. Our proposed HGOE framework is model-agnostic and designed to enhance the effectiveness of existing graph OOD detection models. Experimental results demonstrate that our HGOE framework can significantly improve the performance of existing OOD detection models across all 8 real datasets.", "sections": [{"title": "1 Introduction", "content": "Nowadays, graph-structured data have shown significant success in handling non-Euclidean relationships, prevalent in multimedia systems such as social networks [41, 61], knowledge graphs [3, 4, 39], citation networks [7, 67]. These capabilities facilitate advanced applications like scene graph generation [6, 11], visual analysis [22], anomaly detection [16, 19] and recommender system [26], by modeling complex relationships between heterogeneous data types [32, 34, 36, 42, 53, 54, 60, 63, 66]. However, a significant challenge arises from the i.i.d. assumption on which the mainstream graph learning methods depend, i.e., the training and testing graph data are from the same distribution. This assumption often fails in real-world scenarios, particularly in domains where data is complex and lacks sufficient labeling, such as in the case of drug molecules and proteins. For example, a new drug might not be any part of the already annotated data. Consequently, this gives rise to an interesting issue: how to determine whether such a new drug is present in the annotated drug library? This problem, known as Graph Out-Of-Distribution (GOOD) detection, is crucial in advancing the use of graph learning in real-world scenarios.\nAlthough several methods for graph OOD detection have been developed [31, 35, 64], they only utilize ID graph data. When the full data distribution is complicated, merely modeling the ID data might be insufficient to capture the essential clues for OOD detection.\nIn fact, auxiliary public OOD data is often accessible to help the detector discover such clues. Exposing such auxiliary OOD data to the model, also known as Outlier Exposure (OE), is widely studied for image data [10, 18]. However, the application of OE for graph samples has not yet been explored. To bridge this gap, we attempt to investigate the incorporation of OE into graph OOD detection.\n*Corresponding authors."}, {"title": "2 Related Work", "content": "Graph Neural Networks. Graph neural networks (GNNs) have been widely adopted in various deep learning tasks due to their ability to process graph-structured data, which can effectively extract both the structural and attribute information of graphs [13, 23, 47]. GNNs have achieved remarkable results in various deep learning tasks in recent years, such as recommendation systems, natural language processing and computer vision [49, 67]. GNNs can be broadly categorized into two distinct classes, which encompass spectral-based GNNs and spatial-based GNNs [68].\nExisting Spectral-based Graph Neural Networks leverage spectral graph theory for graph analysis, offering the advantage of incorporating global graph topology information. However, they also exhibit certain limitations, including high computational complexity, challenges in handling dynamic or heterogeneous graphs, and a deficiency in local perception ability [51]. For instance, ChebNet approximates spectral graph convolutions using Chebyshev polynomials of arbitrary order, while GCN simplifies this by employing only the first two Chebyshev polynomials as the graph convolution, effectively creating a fixed low-pass filter[40].\nSpatial-based Graph Neural Networks leverage the spatial information of nodes within the graph to perform graph convolutions[21]. These networks are rooted in message-passing mechanisms[23, 57], wherein each node updates its features based on the features of its neighboring nodes. Notably, Graph Attention Networks (GAT)[48] introduce a self-attention mechanism to compute node neighbor weights, allowing for dynamic and adaptive aggregation within neighborhoods. GAT further enhances model capacity by employing multi-head attention. Meanwhile, GraphSAGE[14] learns how to aggregate node features from various sources using diverse functions like mean, max-pooling, or LSTM, making it suitable for inductive learning tasks that involve new nodes or graphs during testing. Graph Isomorphism Networks (GIN)[57], another class of graph convolutional network, employ sum and MLP operations to aggregate node features. Additionally, Graph Structural Neural Networks [55] provide a versatile solution for incorporating structural graph properties into the message-passing aggregation scheme of GNNs."}, {"title": "Out-of-distribution (OOD) Detection", "content": "Out-of-distribution (OOD) Detection. Existing deep learning-based classification methods often exhibit overconfidence on unseen classes [17]. To address this issue, out-of-distribution (OOD) detection [17, 52] involves the task of distinguishing test samples from distributions different from the seen training data. It comprises post-hoc and fine-tuning approaches [58]. Post-hoc methods [24, 27, 46, 50] leverage the logit space and output scores of models that trained on in-distribution data to classify ID and OOD data. Fine-tuning approaches [10, 18] introduce extra regularization terms during training or incorporate auxiliary training data, referred to as outlier exposure, which can be either real, synthetic, or sampled from the feature space. Outlier exposure has proven effective in enhancing OOD detection performance.\nHowever, these methods are typically applied to image or text data. OOD detection in graph data remains an under-explored area. Graph OOD detection [31] aims to determine whether test graphs originate from within the in-distribution relative to the training set or are out-of-distribution. Some studies [35, 64] focus on graph anomaly detection, where the training data comprises both in-distribution and anomalous data, positioning it as a subset of graph OOD detection. OCGIN [64] utilizes a GIN as its encoder and capitalizes on an SVDD [65] objective for one-class graph anomaly detection. GLocalKD [35] employs joint random distillation to pinpoint anomalous graphs on both local and global scales. GOOD-D [31] differentiates between ID and OOD graph data through hierarchical contrastive learning and perturbation-free graph data augmentation, having been exposed only to ID data during training. AAGOD [12] introduces a novel learnable amplifier generator, designed to generate graph-specific amplifiers, thereby enhancing the detection of OOD graphs on trained GNNs. GraphDE [25] introduces a generative framework for debiased learning and OOD detection in graph data."}, {"title": "Graph Data Augmentation", "content": "Graph Data Augmentation. Graph data augmentation, involving transformations to enrich or enhance information in the given graph, has been extensively explored. Non-learnable augmentation methods [9, 62] achieve this through perturbation or random sampling of edges, nodes, or subgraphs. In contrast, learnable augmentation methods [8] train an Augmenter with learnable parameters using techniques like Decoupled Training, Joint Training, or Bi-level Optimization [9]. Among these methods, some utilize graph mixup [15, 29] to generate new graphs. G-mixup [15] enhances classification performance by generating new graphs through mixup based on estimating graphons of the same class. S-Mixup [29] employs soft alignments for node matching to achieve instance-level graph mixup.\nAs an orthogonal direction to existing graph-level OOD detection approaches, our approach focuses on introducing outlier samples that assist in OOD detection training. Our framework relies on utilizing in-distribution graphons to generate internal outliers within them, rather than directly performing augmentations on the original graph structure."}, {"title": "3 Preliminaries", "content": "In this section, we provide definitions for key terms and concepts utilized throughout this paper."}, {"title": "3.1 Problem Setting", "content": "Denote a graph by $G = (V, &, X)$, where $V$ denotes the set of nodes, $& denotes the set of edges, and $X \\in R^{n \\times d}$ is the node feature matrix. The adjacency matrix is denoted as $A \\in \\{0, 1\\}^{n \\times n}$, where $A_{ij} = 1$ indicates a connection between nodes $v_i$ and $v_j$ and $A_{ij} = 0$ otherwise.\nIn this paper, we focus on the unsupervised graph-level OOD detection problem. Specifically, given a set of unlabeled in-distribution graphs $D_{in} = \\{G_i\\}_{i=1}^n$ drawn from the distribution $P_{in}$, the aim of unsupervised graph-level OOD detection is to learn a graph OOD scoring function $f(.)$ based on the ID data $D_{in}$. A higher score $s = f(G)$ indicates a higher probability to be an OOD graph. The scoring function is evaluated on a test set $D_{test} = D_{in} \\cup D_{ood}$ ($D_{in} \\cap D_{ood} = \\emptyset$) where $D_{in} \\sim P_{in}$ and $D_{ood} \\sim P_{ood}$. It should be emphasized that graph data sourced from $P_{in}$ and $P_{out}$ might fall into multiple categories. However, in the unsupervised graph-level OOD task, the model is not provided with any category-specific labels."}, {"title": "3.2 Graphon", "content": "A graphon, denoted by the function $W: [0, 1]^2 \\rightarrow [0, 1]$, is a continuous, bounded, and symmetric function in graph theory, extensively used to describe graph generation [1]. The value $W(i, j)$ approximates the probability of an edge between nodes $i$ and $j$ in a specific graph. A graphon can be considered as a function that embodies the characteristics of a class of graphs, allowing for the sampling of graphs from the graphon. These sampled graphs share similar topological features. Distinct graphons represent different graph classes, enabling comparative analysis of their structural features. These graphons are estimated using step function approximations [33]. Graphons are particularly useful in synthesizing new graphs that reflect patterns found in real-world data, offering insights into the underlying structure of complex networks. However, there is no closed-form expression for graphons. Previous studies [15, 56] have employed a two-dimensional step function to estimate graphons, which can be considered a matrix representing the probability of edge existence. In this paper, we denote it as $W \\in [0, 1]^{D \\times D}$, where $D$ is the dimensionality of the graphon. This matrix $W$ can then be used to generate graphs with a number of nodes less than $D$."}, {"title": "4 Methodology", "content": "4.1 Overall Framework\nIn general, with a graph OOD score function $f(G)$, the basic learning objective for unsupervised graph OOD detection can be described as:\n$\\min_f E_{G \\sim D_{in}} [L_{ood}(f(G))]$,\n(1)\nwhere $L_{ood}$ is the loss function.\nBy integrating the hybrid graph outlier exposure (HGOE) procedure, we hope the exposed OOD data have higher OOD scores than ID data. Subsequently, we simultaneously minimize the OOD score of ID data and maximize that of OOD data:\n$\\min_f E_{G \\sim D_{in}} [L_{ood}(f(G)) + \\beta \\cdot E_{G' \\sim D_{OE}} [L_{GOE} (f(G), f(G'))]]$. (2)"}, {"title": "4.2 Mixture Outlier Training Strategy", "content": "Our mixture outlier training strategy incorporates outliers from two sources: real-world external outliers and synthesized internal outliers. External outliers are derived from public graph datasets similar to the training graphs, while internal outliers are generated from ID graphs.\nExternal Outliers. In contrast to image data, graph data in the real world display significantly more complex structures, with notable gaps in characteristics between fields like social networks and protein networks. To investigate the role of real-world outliers, we sample from several graph datasets to create a real-world OE dataset. During the training of different ID data, we select graphs from the OE dataset that are consistent with them in feature dimensions, ensuring no overlap between the OE graphs and the training and test sets. This process results in an external outlier dataset, denoted as $D_{ext}$.\nInternal Outliers. The quality and diversity of external outliers data are crucial for outlier exposure, but are limited by the scope and quality of the existing auxiliary dataset. Synthesizing additional outliers then emerges as a solution, offering tailored, abundant, and diverse graph data for training. However, the challenge lies in ensuring that the synthesized data resonates with real-world outlier scenarios and does not introduce unintended biases. As discussed in the introduction, there exist internal outliers among the in-distribution graph data, which are distributed near the boundaries of subgroups. To obtain these internal outlier samples, we design an internal outlier generation strategy, which will be described in the next subsection."}, {"title": "4.3 Internal Outlier Synthesis", "content": "A straightforward way to generate graphs is to interpolate each pair of samples in the dataset directly. However, unlike Euclidean data such as images, different graphs usually have different sizes (e.g., different numbers of nodes) and have unique topology in Non-Euclidean spaces. Therefore, we propose to mix up the graph generators instead of graph samples themselves to synthesize more realistic graph data.\nTo find internal outliers for input graphs, it is imperative to first divide the graphs into subgroups. For the input ID graphs, we adopt graph contrastive learning techniques (e.g., GraphCL [62]) for feature extraction, and then perform k-means clustering to"}, {"title": "4.4 Boundary-Aware OE Loss", "content": "The introduced outliers further present two critical issues: How can we ensure that the introduced outliers do not fall within the in-distribution area, and how to find those more important outliers? Take the social graph ID data as an example. Intermixing social graphs could still result in a social graph, so the generated samples are not OOD data and should be excluded from the outlier dataset. At the same time, different outliers can have varying levels of importance, with points on the boundary potentially being critical points where a change in properties is about to occur.\nTo solve these problems, we design the following boundary-aware OE Loss $l_{ba}$ which is adaptively aware of whether the sample is in ID or OOD space. For an input outlier graph $G'$, the loss is calculated as:\n$l_{ba}(SG', \\tau) = -(1-SG') \\cdot max(log(sg'), \\tau)$, (5)\nwhere $SG' = sigmoid(f(G'))$ is the OOD score scaled by a sigmoid function, $\\tau$ and $\\gamma$ are hyperparameters. Note that $\\tau$ is an ID-boundary threshold, which we adaptively set as the smallest $s$ among the ID samples:\n$\\tau = \\min_{G \\in D_{in}} sigmoid(f(G))$. (6)\nTo better understand Eq. (5), we rewrite it in the following form:\n$l_{ba} (SG', \\tau) = \\begin{cases}\n-(1 - sG')log(sg'), & \\text{if } log(sg') > \\tau \\\\\n-\\tau(1 - sg'), & \\text{if } log(sg') \\leq \\tau\n\\end{cases}$ (7)\nFrom this formulation, we have the following observations:\n*   When $log(SG') > \\tau$, it indicates that $G'$ is a valid outlier. In this case, the smaller $SG'$ is, the closer it is to the in-distribution boundary. Apparently, such near-boundary outliers are important in guiding the detector to distinguish OOD samples from ID ones. Therefore, we weigh it by the term $(1 - sg')$, giving higher weights to these boundary samples. As $\\gamma$ increases, the model pays more attention to samples nearer to the ID boundary.\n*   When $log(SG') < \\tau$, it means that the outlier $G'$ is very likely invalid and fall into in-distribution space. Blindly treating it as an outlier might be harmful to the learning. Therefore, by minimizing $-\\tau(1 - sg')$, the OOD score is reduced, which enhances the recognition ability for in-distribution samples.\nThen, considering both external and internal outliers, the total graph outlier exposure loss is formulated as:\n$L_{GOE} = \\sum_{G' \\in D_{int} \\cup D_{ext}} l_{ba}(SG', \\tau)$. (8)\nFinally, we can instantiate the overall training objective $L$ as follows:\n$L = \\sum_{G \\in D_{in}} [L_{ood}(f(G)) + \\beta \\sum_{G' \\in D_{OE}}l_{ba}(SG', \\tau)]$\n$= \\sum_{G \\in D_{in}} L_{ood}(f(G)) + \\beta \\sum_{G' \\in D_{int} \\cup D_{ext}} l_{ba}(SG', \\tau)$. (9)\nIn practice, our $L_{GOE}$ can be added as a regularization term to most existing OOD detection models, without modifying their network architectures."}, {"title": "5 Experiments", "content": "5.1 Experimental Setup\n5.1.1 Datasets. We select three pairs of datasets from the TU dataset [38] and five pairs from the OGB dataset [20]. Each pair of datasets belongs to the same field and shares similar features, but exhibits distribution shifts between the two datasets in the pair. 90% of the In-Distribution (ID) samples are used for training, while 10% of the ID samples and an equivalent number of OOD samples are used for testing. For more detailed information about these datasets, refer to Table 1.\nFor external outlier data, we grouped datasets with identical feature counts into a unified external dataset. Based on the feature counts of our selected datasets, as detailed in Table 1, this organization resulted in two distinct external dataset collections, with node feature numbers being 1 and 9, respectively. In this configuration, for each In-Distribution dataset, we utilized other datasets from the corresponding external dataset collection for training purposes, deliberately excluding both the OOD dataset for testing and the ID dataset itself.\n5.1.2 Competitors. We adopt the following three categories of graph OOD detection methods as our competitors:\n*   Non-deep Two-step Methods. We use WL [44] graph kernels as feature extractors and employ local outlier factor (LOF) [2], one-class SVM (OCSVM) [37], and isolation forest (iF) [30] as detectors to perform OOD detection.\n*   Deep Two-step Methods. The process is similar to the above methods, but the feature extractor is replaced with graph deep self-supervised methods InfoGraph [45] and GraphCL [62], and the detectors are replaced with isolation forest (iF) and Mahalanobis distance (MD) [43]. Compared to graph kernels, self-supervised methods can extract features of graphs better.\n*   End-to-end Methods. We utilize three popular end-to-end learning methods, including OCGIN [64], which uses graph neural networks for feature extraction and is optimized with SVDD. GLocalKD [35] uses distillation learning for graph anomaly detection, and GOOD-D [31] employs multi-level contrastive learning for end-to-end OOD detection."}, {"title": "5.1.3 Implementation Details", "content": "For HGOE, the ratio of external to internal outliers was set to 1:1, with the total number equal to the number of in-distribution samples seen during training. The hyperparameter $A$ was set to 2, and $\\gamma$ was set to 2. The dimension of the structural features $s_{diff}$ was set to 16, and the number of clusters for all datasets was determined to be 3. GraphCL was run for 50 iterations with an embedding dimension of 32, and the probabilities for node dropping, feature masking, and edge removing were all set to 0.1. During ID-mixup, $\\lambda$ was randomly chosen from the range [0.01, 1]. AUC (Area under the ROC Curve) [28, 59] is used as the performance metric. A higher AUC value indicates better detection performance."}, {"title": "5.2 Main Results", "content": "We evaluate the performance of HGOE and other competitors, with the results presented in Table 2. Our findings include:\n(1) Two-step detection methods do not perform as well as end-to-end detection methods, especially where non-deep learning methods are inferior to deep learning-based feature extraction methods. Within self-supervised methods, GraphCL-MD demonstrates the best performance, showing GraphCL's capability in extracting features for graph OOD detection. This also explains why we chose to utilize GraphCL features for clustering.\n(2) For our HGOE framework, compared to GOOD-D without the use of graph outliers, there was an enhancement in performance across all 7 datasets. On the ENZYMES+PROTEIN dataset, the average performance improve from 60.15 to 64.44. On Tox21+SIDER, it increased from 64.98 to 68.24, and on FreeSolv+ToxCast, the performance increase from 78.79 to 83.36.\n(3) The performance improvement on IMDB-M+IMDB-B was not substantial because both are social datasets, and the outliers we introduce were from molecular and protein datasets, which are biologically oriented. However, using these as outliers still contributed to enhanced detection on IMDB-M+IMDB-B. This indicates that selecting outliers similar to the ID distribution, as opposed to introducing outliers completely unrelated to the ID data, is more effective."}, {"title": "5.3 Visualization", "content": "5.3.1 ID-mixup Visualization. After obtaining the subgroups within the known distribution, we performed a mixup of the estimated graphons and visualized the resulting mixed graphons in the form of heatmaps, as shown in Figure 3. The graphon in the center represents the result of performing ID-mixup on the two adjacent graphons. It is evident that the graphon after ID-mixup retains the structures of the original graphons, forming a new graph generator. This demonstrates that our ID-mixup can effectively blend the distributions of subgroups to a certain extent, fulfilling our hypothesis."}, {"title": "5.3.2 Score Distribution Visualization", "content": "Based on the OOD scores for samples in the test set, we visualize the frequency distribution of OOD scores for both ID and OOD samples using different colors. As shown in Figure 4, the left column depicts the score distributions without using HGOE, while the right column shows the results after applying the HGOE framework. The less the overlap and the greater the distance between the ID and OOD areas are, the better the corresponding model's performance is. It is observable that our HGOE method has decreased the overlap area between ID and OOD distributions, which also explains the reason for the performance improvement."}, {"title": "5.4 Ablation Study", "content": "5.4.1 Using Only One Type of Outliers. In Table 2, HGOE w/o IO and HGOE w/o EO represent the results of using only internal outliers and external outliers, respectively. We observe that using just one of these types yields better results than not using any OE (Outlier Exposure) samples at all. Moreover, in most cases, the performance of using only external outliers is superior to that of using only internal outliers, but inferior to using both types. This indicates that the combination of both types of outliers can more effectively enhance the performance of hybrid graph outlier exposure."}, {"title": "5.4.2 The Strategy for Adaptive Allocation of t", "content": "In Section 4.4, we introduce an adaptive parameter t in the distribution-aware OE loss, which is set as the smallest normalized score among the ID samples. To explore the specific role of t, we implement methods setting \u03c4 according to the maximum, average, and minimum normalized scores. The results, as shown in Figure 3, indicate that the min strategy for allocating t performs the best. However, this strategy negatively affects performance on the IMDB-M+IMDB-B dataset, which we believe is due to its significant difference from the other datasets."}, {"title": "5.5 Sensitivity Analysis", "content": "5.5.1 ID-mixup Weight \u03bb. We explore the sensitivity of HGOE with respect to A by evaluating its performance during ID-mixup across different A ranges. As seen in Table 4, we progressively narrow the range of a from [0.01, 1.0] to [0.4, 0.6]. In this process, a performance decline was observed in most datasets. This suggests that for ID-mixup, blending two in-distribution samples at varying ratios can increase the diversity of internal outliers, thereby enhancing detection effectiveness. However, an opposite trend of performance increase, rather than decrease, was observed in the CLintox+LIPO dataset pair. This anomaly may be related to the characteristics of these datasets, both being molecular graphs from the OGB and possessing extremely similar average node and edge counts, resulting in closer distributions. If ID-mixup outliers falling within the in-distribution range, it could lead to a greater performance decrease compare to other datasets. So when A is set to a middle value, the generated graphon lies between subgroups. This explains why choosing a A value range [0.3, 0.7] yields better results.\n5.5.2 Hyperparameter y of Boundary-aware OE Loss. As described in our framework, y plays a significant role in the boundary-aware loss. We vary the value of y to {0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0}, and as observed in Figure 5, as y increases, there is a performance improvement when y\u2208 [0,2]. However, performance starts to decline for some datasets when it exceeds 2 and 2.5. This indicates that within an appropriate range, introducing y can effectively weight the samples, and this effect improves with the increase of y, up to a point where it begins to decrease. This phenomenon validates the rationality and effectiveness of our designed boundary-aware OE loss."}, {"title": "6 Conclusion", "content": "In this work, we investigate the enhancement of OOD detection performance on graph-level data through hybrid graph outlier exposure. We demonstrate that not only external outliers are crucial for graph OOD detection, but internal outliers also play a significant role. Based on this, we propose a carefully designed ID-mixup based method for synthesizing internal outliers by generating OOD samples between in-distribution subgroups and aligning these with external outlier features. Upon obtaining these synthesized internal outliers, we effectively utilize the characteristics of outlier samples by adaptively allocating learning weights to OE samples using a well-designed boundary-aware OE loss. Our HGOE framework provide substantial performance improvements for other graph OOD detection methods. Extensive experiments on 8 real-world datasets show its superior performance."}]}