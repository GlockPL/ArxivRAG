{"title": "Real-Time Fitness Exercise Classification and Counting from Video Frames", "authors": ["Riccardo Riccio"], "abstract": "This paper introduces a novel method for real-time exercise classification using a Bidirectional Long Short-Term Memory (BiLSTM) neural network. Existing exercise recognition approaches often rely on synthetic datasets, raw coordinate inputs sensitive to user and camera variations, and fail to fully exploit the temporal dependencies in exercise movements. These issues limit their generalizability and robustness in real-world conditions, where lighting, camera angles, and user body types vary.\nTo address these challenges, we propose a BiLSTM-based model that leverages invariant features-joint angles in addition to raw coordinates. By using both angles and (x, y, z) coordinates, the model adapts to changes in perspective, user positioning, and body differences, improving generalization. Training on 30-frame sequences enables the BiLSTM to capture the temporal context of exercises and recognize patterns evolving over time.\nWe compiled a comprehensive dataset by combining synthetic data from the InfiniteRep dataset and real-world videos from the Kaggle Workout/Exercises Video Dataset and other online sources. This dataset includes four common exercises: squat, push-up, shoulder press, and bicep curl. The model was trained and validated on these diverse datasets, achieving an accuracy of over 99% on the test set. To assess generalizability, the model was tested on 2 separate test sets representative of typical usage conditions. Comparisons with the previous approach from the literature are present in the result section showing that the proposed model is the best-performing one.\nFurthermore, the classifier was integrated into a user-friendly web application that provides real-time exercise classification and repetition counting without the need for manual exercise selection. Demo and datasets available at: GitHub Repository.", "sections": [{"title": "Introduction", "content": "Exercise is a critical component of a healthy lifestyle, contributing to both physical fitness and mental well-being. Despite its well-documented benefits, many individuals struggle to maintain consistent workout routines. Common barriers include a lack of knowledge about proper exercise techniques and challenges in tracking workout progress. Traditional methods, such as manual repetition counting or feedback from personal trainers, are often inaccessible or inconvenient for many users. These difficulties can lead to poor adherence to exercise routines, ultimately affecting overall health outcomes.\nRecent advancements in artificial intelligence (AI) and computer vision offer promising solutions to these challenges. In particular, pose estimation techniques, which identify and track key body landmarks from images or videos, have emerged as powerful tools for analyzing human movement. By combining pose estimation with machine learning (ML) models, it is possible to develop systems that automatically count repetitions, correct form, and even classify the exercise being performed. Such systems have the potential to revolutionize fitness tracking, making exercise more accessible, effective, and engaging for users.\nHowever, existing approaches to exercise classification and repetition counting often suffer from significant limitations. Many models, such as those relying on convolutional neural networks (CNNs) with voting mechanisms or simple frame-based classifiers, treat individual frames independently, failing to fully capture the temporal dynamics of exercise movements. This leads to reduced classification accuracy, particularly for exercises that share similar initial postures. Furthermore, methods that utilize raw (x, y, z) coordinates of joints are often sensitive to variations in user positioning, camera angles, and distances, limiting their generalizability to real-world environments.\nTo address these limitations, this paper proposes a novel approach to automatic exercise classification using a bidirectional Long Short-Term Memory (BiLSTM) architecture. The BiLSTM model is designed to capture the sequential nature of exercise movements by processing frames in both forward and backward directions, allowing it to better distinguish between exercises that may appear similar at individual points in time. Unlike models that rely solely on raw coordinates, the proposed approach leverages angles between key joints, which are invariant to changes in camera perspective and user positioning, thus improving robustness and generalization.\nWhile state-of-the-art models like Vision Transformers [1] and more recent pose estimation methods exist, this project aims to develop a model capable of real-time classification and counting of exercises in resource-constrained environments, such as mobile devices. Thus, computational efficiency was prioritized while maintaining high accuracy. The BiLSTM and BlazePose models were chosen to balance these trade-offs, as they offer excellent performance with significantly reduced computational demands, which is essential for real-time applications.\nThe core contribution of this paper is the development of an automatic exer-"}, {"title": "Related Works", "content": "In the domain of exercise classification, leveraging pose estimation and machine learning has become a pivotal approach to identifying physical movements in real-time. This section reviews the relevant literature on pose estimation and automatic exercise classification, with a focus on methodologies, model architectures, and how this work improves upon existing limitations.\nHuman Pose Estimation for Exercise Tracking\nPose estimation is a fundamental aspect of understanding human movement. It involves detecting key body landmarks such as joints and limbs to represent a person's posture in either two or three dimensions. This technology has found applications across fields like fitness, healthcare, and sports. One of the more recent advancements in pose estimation is the use of deep learning models, which have significantly improved accuracy and robustness.\nFor this project, Mediapipe's BlazePose [2, 3] was selected as the primary pose estimation framework. BlazePose is specifically optimized for real-time performance on mobile devices and was chosen for its ability to efficiently track body landmarks. BlazePose predicts 33 key body points, including the head, shoulders, elbows, wrists, hips, knees, and ankles, making it a suitable choice for fitness applications. The model also incorporates a detector-tracker pipeline to maintain accurate tracking of body parts throughout the sequence of movements.\nThe model needs to be developed with practical usage in mind, and while we have implemented it within a web application, a more natural future use case could be in a mobile app acting as an AI personal trainer. Given the need for low computational requirements to ensure real-time performance on mobile devices, BlazePose is an ideal choice, as it was created specifically with real-time mobile usage in mind. This makes it highly suited for applications where users"}, {"title": "Automatic Exercise Classification", "content": "Automatic exercise classification in real-time involves the use of machine learning models to analyze data extracted from video frames or sensor inputs to identify the exercise a user is performing. This paper focuses on using features that can be extracted from frames with a simple webcam, eliminating the need for additional sensors and relying solely on visual data. By utilizing pose estimation techniques to capture joint angles and relative distances directly from standard webcam input, the model achieves real-time exercise classification based on these visual features alone. Given the sequential nature of most physical exercises, effective classification typically requires models that can capture and interpret temporal dependencies in the data. This section reviews several methodologies from the literature that address this challenge, focusing on three papers [4, 5, 6]. Following this review, the limitations of these models are discussed, and how this thesis aims to address these challenges.\nDifferent Approaches to Automatic Exercise Classification\n1. CNN + Soft Voting: The paper [4] analyzed various approaches to handle exercise classification utilizing a synthetic dataset from Infinity AI [7], which includes videos of avatars performing 10 different exercises. Initially, the study explored traditional machine learning models like K-Nearest Neighbors (KNN) and Random Forest, but they showed limited performance due to their inability to capture temporal dependencies."}, {"title": "Limitations of These Approaches and the Model Proposed in This Project", "content": "The CNN + Soft Voting approach, as detailed in the paper, relies heavily on a synthetic dataset (Infinity AI's Fitness Basic Dataset). This reliance raises concerns about the model's ability to generalize to real-world data, where variability in lighting, camera angles, and user body types is more prevalent. Although the final model combines CNNs with a soft voting mechanism across 30 frames, it doesn't fully exploit the temporal dependencies inherent in exercise movements. The model analyzes each frame somewhat independently, and the final classification is based on an average of these predictions. This approach does not fully leverage the sequential nature of exercise movements.\nThe LSTM-based approach using (x, y, z) coordinates introduces challenges related to invariance. By using raw (x, y, z) coordinates as input, the model might struggle when used with data taken from a different distribution. For example, if the dataset contained exercises performed at a fixed distance from the camera, using the coordinates might not generalize well to exercises performed by users at different distances, on different screen dimensions, or with varying user heights. Angles are invariant to the user's position relative to the camera, which can make the model more robust to variations in camera perspective and scale. Additionally, the use of only 8 consecutive frames to capture temporal dynamics may not provide sufficient context for exercises with complex or longer movement sequences, potentially reducing classification accuracy for more intricate activities.\nIn the Deep Learning approach, the problem is again that each frame is treated as an independent entity. This approach fails to capture the sequential nature of exercise data. By making predictions based on single frames and then aggregating these predictions by selecting the most common outcome across 10 frames, the model does not fully utilize the temporal continuity of the data. Also, this paper used the coordinates, which, as explained before, have the invariance problem.\nTo address the limitations, the BiLSTM model proposed in this thesis leverages the temporal nature of exercise data by analyzing sequences of frames both forward and backward. Unlike models that treat frames independently, the BiLSTM captures the complete temporal context, enabling it to recognize patterns that evolve over time. The proposed model utilizes additional angle features derived from key joint positions. Additionally, the model processes 30 frames"}, {"title": "Methodology", "content": "This section outlines the approach taken to develop the exercise classifier, from data collection, feature extraction, model selection, and training processes. The classifier is built using a combination of real and synthetic datasets, designed to reflect the diverse environments in order to enhance its generalizability. The model is intended for integration into a real-time fitness tracking application, where it will automatically recognize the exercises the user performs in front of a webcam. The section begins with an overview of the datasets used for training, emphasizing the methods employed to capture realistic exercise scenarios. It then details the landmark extraction process, which utilizes pose estimation to extract body coordinates from exercise videos. Then, the feature extraction and preprocessing steps are discussed, explaining how raw landmark data is transformed into suitable inputs for models. The final part covers the selection and training of LSTM and Bidirectional LSTM models and evaluates their performance across various test conditions to ensure their effectiveness and reliability in practical usage.\nDataset\nThe creation of a suitable dataset requires data that tends to resemble the conditions under which the application will be used. Ideally, the data should include videos where the user's head and main joints are clearly visible, as BlazePose utilizes face detection to initiate tracking of the person's body. The exercises should also be performed in a manner similar to how they will be executed later in the app. The creation of the dataset was not trivial, as while the user is advised to use the application in a controlled environment like home, it is likely that the usage will also extend to gyms or other places. Therefore, the dataset was designed to account for this variability, ensuring the model"}, {"title": "Landmark and Features Extraction", "content": "The landmark extraction process begins by organizing the datasets into folders, each containing subfolders for the four exercises: barbell bicep curl, shoulder press, squat, and push-up. The extraction process iterates over each video and processes each frame using pose estimation with MediaPipe to detect landmarks.\nFor each frame, the process extracts (x, y, z) coordinates of a subset of relevant landmarks, including shoulders, elbows, wrists, hips, knees, and ankles. The extraction process ensures that essential landmarks specific to each exercise are detected on at least one side (left or right). If critical landmarks are missing on both sides (indicated by checks on left-side-valid and right-side-valid functions), the frame is skipped to ensure that only complete data is used for later processing. In cases where some essential landmarks are not detected, placeholder values [0.0, 0.0, 0.0] are used to maintain a consistent data structure.\nWhen a frame passes these checks, 22 landmarks, along with the video ID and exercise type (label), are recorded and later stored in a CSV file named according to the dataset. From this landmark 12 angles are extracted. At this stage, the CSV file will contain a number of rows equal to the valid frames and as columns the video ID, the exercise label, and (x, y, z) coordinates for each of the 22 relevant landmarks (so, the CSV file will have a shape of (number of valid frames, 80). This structured approach helps organize data for then being preprocessed in order to be ready for the model's training (see Tables 1 and 2 for a list of all the features).\nThis strategy helps maintain the dataset's structure and ensures that missing data does not disrupt the model's learning process."}, {"title": "Models Training and Evaluations", "content": "The training phase involves using LSTM and BiLSTM to develop the exercise classification model. These models are well-suited for sequence prediction tasks, making them ideal for understanding the temporal dynamics of exercise movements from the aggregated landmark features. The training process begins with loading and combining preprocessed datasets, followed by hyperparameter tuning and evaluation to select the best-performing model with the optimal"}, {"title": "Loading and Preparing Data", "content": "First, the preprocessed features and labels from multiple datasets, including the \"Kaggle Workout/Exercises Video Dataset\u201d, \u201cInfinitRep\u201d, and \u201csimilar\" datasets, are loaded and concatenated. This ensures that the final dataset is comprehensive and captures a wide range of variations in exercise performance, such as differences in body size, environment, and angles.\nTo prepare the data for the LSTM and BiLSTM models, labels are encoded using a label encoder, converting categorical exercise types into numerical values. These encoded labels are further transformed into a categorical format suitable for multi-class classification. Feature scaling is also performed using a standard scaler to normalize the data, which helps improve the convergence speed and overall training.\nThe dataset is then reshaped to match the input required by the LSTM. In particular, the data is reshaped into three dimensions: samples, timesteps, and features, resulting in a shape of (number_samples, 30, 78)."}, {"title": "Model Architecture and Training", "content": "Two models were developed for the exercise classification task: a standard LSTM model and a Bidirectional LSTM model. The LSTM model uses two LSTM layers with dropout layers in between to reduce overfitting. The BiLSTM model enhances the LSTM architecture by processing the sequence data in both forward and backward directions, allowing the model to capture patterns that may depend on future as well as past context."}, {"title": "Hyperparameter Tuning", "content": "Hyperparameter tuning was performed using a random search strategy (using 20 iteration), testing various combinations of key hyperparameters such as the number of LSTM units, dropout rate, learning rate, batch size, and the number of training epochs. Early stopping and learning rate reduction techniques were also employed during training."}, {"title": "Model Evaluation", "content": "During the training phase, the dataset is split into training, validation and, test sets (70-15-15) to assess the model's performance on unseen data.\nTo ensure that the models generalized well beyond the training data, both the LSTM and BiLSTM models were further tested on two additional datasets designed to reflect real-world conditions: the \"Final My Test Video\" dataset, which included exercises recorded at home, and the \"Final Test Gym Video\" dataset, which contained exercises recorded in gym or other environments. Testing on these datasets is useful since it simulates the various settings where the app might be used, such as homes, gyms, or other environments with different lighting and backgrounds.\nThe models were evaluated using the accuracy metric on the test set, and the best-performing model and hyperparameters were selected based on this metric. The primary evaluation metrics used were accuracy, precision, recall, and F1-score, which were detailed in classification reports for each model. These metrics provided a clear view of how well the models distinguished between different exercise classes. The evaluation also included confusion matrices, helping identify any specific exercises that the models might confuse with each other."}, {"title": "Results", "content": "This chapter presents a summary of the experiments and results conducted to evaluate the BiLSTM model proposed (with both coordinates and angles). It includes comparisons with an LSTM model utilizing the same feature set, a BiLSTM model that employs only coordinate data, and a BiLSTM model that leverages solely angles and normalized distances. Additionally, the chapter contrasts these models with the approaches discussed in the literature review, incorporating necessary modifications to facilitate a meaningful comparison. The final automatic exercise classification model was used on the \"Auto Classify\" page of the web app (described in a later section). The evaluation of the repetition counting logic is not included, as it is based on a function that uses angles rather than AI. However, it might be beneficial to have the repetition counting logic reviewed by expert trainers or to expand the logic to cover additional perspectives, such as side angles, rather than just the frontal view with a slight angle. Similarly, the evaluation of the chatbot design is considered beyond the scope of this paper."}, {"title": "Experimental Setup", "content": "The experiments were conducted as follows: both LSTM and BiLSTM models were trained using the main dataset, with the best hyperparameters identified through tuning. The models with these optimized hyperparameters were then validated on the main dataset, and learning curves were plotted. Finally, both models were evaluated on two test datasets: \"Final My Test Video\" and \"Final Test Gym Video.\" The evaluation metrics used included accuracy, classification report, and confusion matrix."}, {"title": "Best Hyperparameters", "content": "The table below shows the best hyperparameters found for each model. These models, configured with the optimized hyperparameters, were saved and used for the rest of the evaluations."}, {"title": "Evaluation on Test Sets on The Dataset Used For Training", "content": "The following tables present the accuracy, classification report, and confusion matrix for the test set."}, {"title": "Evaluation on Additional Test Sets", "content": "The additional test sets were used to assess the generalizability of the models. The first test set, \"Final My Test Video,\" consists of videos recorded under conditions recommended for the application (i.e., clear visibility of the head and body with a frontal or slightly angled view). The second test set, \u201cFinal Test Gym Video,\" includes videos that do not strictly follow the recommended guidelines, such as those recorded in various environments like gyms, outdoors, or homes with different camera angles. The following table shows the accuracy and classification report for these test sets, along with the confusion matrix.\nHere are the results for the dataset: Final My Test Video:"}, {"title": "Model Comparison and Evaluation on Different Feature Types", "content": "In addition to evaluating the LSTM and BiLSTM models on the test datasets, further experiments are conducted in order to examine the effect of using angles versus raw coordinates as input features. Specifically, a BiLSTM model was trained using the same architecture but just with the raw coordinates from the 33 landmarks detected by MediaPipe. In addition, another model called \"BiLSTM Invariant\", which makes no use of raw coordinates but just uses invariant features like angle and normalized distances, is tested."}, {"title": "Comparison with previous approaches", "content": "One challenge faced in this study, and in the broader field of exercise classification, is the absence of a standardized benchmark dataset. Without a common dataset used across studies, it becomes difficult to directly compare the performance of different models. Existing approaches often rely on proprietary or specific datasets, each with unique characteristics that may not consistently reflect real-world conditions. The lack of a widely adopted benchmark hinders the ability to measure progress across studies effectively. This is one reason why the model was integrated into a real-time fitness application, allowing for practical evaluation in real-world settings where users engage with the system directly. Testing the model in the app offers valuable insights into how it performs under various conditions, supplementing the gaps left by the lack of standardized datasets. Future research should consider the development of a standardized dataset for exercise classification, which would enable more reliable comparisons and encourage further advancements in this domain. Keeping in mind the problem of a benchmark dataset, this paper compared the proposed model with the previous approaches by implementing their model architecture and training and testing on the dataset used for evaluating the proposed model. In particular, [4] and [6] were implemented, while [5] was not directly implemented since previous results already demonstrated the superiority of BiLSTM over LSTM, as well as the advantages of combining angle and coordinate features over using raw coordinates alone. Below are reported the results of the model implemented and discussed some choices regarding their implementation. In all implementations, hyperparameter tuning has been used, specifically tuning the learning rate, batch size, and number of epochs, as in the proposed model. For [4], the exact architecture described in the paper was used. While the precise angle features they utilized were not explicitly detailed, it can be inferred from the text that they employed similar features used in the proposed model, so these features were used. Additionally, it was unclear whether they used a sliding window or a non-overlapping window for generating predictions on 30-frame sequences. However, this distinction is less critical since the training was conducted at the individual frame level. Both methods were implemented and produced nearly identical results, with the non-overlapping approach ultimately"}, {"title": "Considerations", "content": "Both LSTM and BiLSTM perform very well on the main dataset, achieving 99% accuracy, which suggests that the models are properly tuned and effective for the conditions of the training data. Their ability to generalize to more diverse environments, as seen in the additional test sets, maintains strong performance while decreasing the data with more occlusions and difficult angles. In general, the BiLSTM model performs better than LSTM in handling diversified test datasets (the difference is small). The BiLSTM has the advantage of being able to capture temporal dependencies in exercise sequences and hence build a more accurate representation of movements. From the extensive evaluation of both features and other architecture, it is concluded that the best set of features considers both raw coordinates and angle. Crucial was also the ability of the model to leverage sequential data with respect to models that learn from a single frame.\nBeyond technical evaluation, a subjective evaluation of how the classification is in real time while using the application can be considered though it would require more review from multiple users. A preliminary review shows that the model works well overall, but there is a tendency for the first repetition of an exercise not to be counted when switching between exercises. This is primarily because the model needs to \"observe\" the first repetition in its entirety to accurately recognize which exercise is being performed. Future improvements might involve optimizing the model to identify exercises more quickly, potentially by reducing the number of frames required for prediction, thereby shortening the time before the exercise is recognized.\nIn conclusion, the developed models achieve high performance on the main dataset set and maintain good performance also on other diverse test sets. The usage in the app is smooth but reducing prediction time might be considered. Finally, expanding the dataset to include more diverse exercise contexts seems to be the critical step toward improving generalization."}, {"title": "Overview of the Web App", "content": "The following section provides a general overview of the Fitness AI web application, showing the main functionalities and how they are integrated into the overall structure of the app.\nThe project is designed as a web application built with Streamlit [16], aimed at providing users with fitness tools such as real-time exercise classification, repetition counting, and a chatbot for fitness guidance.\nThe application interface has a main navigation sidebar that allows users to navigate between four pages with different functionalities:\n1. Video Analysis: This feature enables users to upload videos of their exercises, select the type of exercise from a list, and count the repetitions of that exercise. The video analysis process involves pose estimation using MediaPipe to extract landmarks, which are then analyzed to detect"}, {"title": "Exercise Recognition in Practice", "content": "The Auto Classify Mode serves as the primary showcase for the exercise recognition model. In this mode, the BiLSTM model processes a 30-frame window of pose data every second, classifying the exercise in real-time. This allows"}, {"title": "Repetition Counting Implementation", "content": "The repetition counting feature utilizes angle-based logic tailored to each exercise type. It tracks specific body landmarks and calculates angles between joints to determine the exercise stage (e.g., \"up\" or \"down\" position). The system counts a repetition when it detects a complete cycle of movement based on predefined angle thresholds. While effective, this approach could benefit from expert review to refine the angle ranges for optimal accuracy."}, {"title": "Chatbot Implementation", "content": "The chatbot feature uses OpenAI's GPT-3.5-turbo model [18], configured to act as a fitness expert. It provides users with an interactive way to get fitness-related information within the app. The chatbot maintains conversational context across interactions and includes a warning about potential inaccuracies.\nWhile the additional features, including the chatbot and repetition counting logic, complement the core exercise classification model and enhance the user experience, their implementation details are not extensively discussed here as they are not the primary focus of this paper."}, {"title": "Conclusion", "content": "This paper introduced a novel approach for exercise classification and repetition counting using a BiLSTM model combined with pose estimation techniques. The proposed method addressed key limitations of existing systems, such as sensitivity to user positioning, camera angles, and variability in individual body types. By leveraging invariant features, such as joint angles, and utilizing the sequential nature of video data, the model demonstrated robustness in a variety of real-world conditions.\nThe model was trained on a dataset that combined synthetic and real-world data, achieving a Test accuracy of 99% and a strong performance in other real-world test sets. The use of BiLSTM architecture enabled the model to capture the temporal context of exercises more effectively than previous methods, making it suitable for distinguishing between exercises that share similar initial postures but differ over time.\nWhile the results are promising, the paper also identified certain limitations, particularly in the generalizability of the model to more diverse environments, such as gyms or outdoor settings with varied angulations and perspectives. This suggests that future efforts should focus on expanding the dataset with more diverse samples and further refining the model to handle these conditions more effectively. Additionally, the model was implemented inside a web application to be tested in a practical context."}]}