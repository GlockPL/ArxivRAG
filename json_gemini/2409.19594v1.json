{"title": "MaskDroid: Robust Android Malware Detection with Masked Graph Representations", "authors": ["Jingnan Zheng", "Jiaohao Liu", "An Zhang", "Jun Zeng", "Ziqi Yang", "Zhenkai Liang", "Tat-Seng Chua"], "abstract": "Android malware attacks have posed a severe threat to mobile users, necessitating a significant demand for the automated detection system. Among the various tools employed in malware detection, graph representations (e.g., function call graphs) have played a pivotal role in characterizing the behaviors of Android apps. However, though achieving impressive performance in malware detection, current state-of-the-art graph-based malware detectors are vulnerable to adversarial examples. These adversarial examples are meticulously crafted by introducing specific perturbations to normal malicious inputs. To defend against adversarial attacks, existing defensive mechanisms are typically supplementary additions to detectors and exhibit significant limitations, often relying on prior knowledge of adversarial examples and failing to defend against unseen types of attacks effectively.\nIn this paper, we propose MASKDROID, a powerful detector with a strong discriminative ability to identify malware and remarkable robustness against adversarial attacks. Specifically, we introduce a masking mechanism into the Graph Neural Network (GNN) based framework, forcing MASKDROID to recover the whole input graph using a small portion (e.g., 20%) of randomly selected nodes. This strategy enables the model to understand the malicious semantics and learn more stable representations, enhancing its robustness against adversarial attacks. While capturing stable malicious semantics in the form of dependencies inside the graph structures, we further employ a contrastive module to encourage MASKDROID to learn more compact representations for both the benign and malicious classes to boost its discriminative power in detecting malware from benign apps and adversarial examples. Extensive experiments validate the robustness of MASKDROID against various adversarial attacks, showcasing its effectiveness in detecting malware in real-world scenarios comparable to state-of-the-art approaches.", "sections": [{"title": "1 INTRODUCTION", "content": "Android, as one of the most prevalent smartphone operating systems, has dominated over 85% of the mobile OS market share since 2018 [41]. However, its popularity and open nature have also made it a primary target for cyberattacks [1, 44]. For example, Android permits the installation of applications from unverified sources, such as third-party markets, thereby providing attackers with easy means to bundle and distribute malware-infected apps [10]. Android malware, a.k.a., malicious software, has become one of the primary security threats to the Android platform, with the number of malware samples increasing exponentially over the years [5].\nTo mitigate these threats, machine learning (ML) has been widely adopted to automatically extract malicious patterns from various APK features for Android malware detection [22, 42, 44]. According to the features used, there are two research lines: syntax-based [6, 10, 40, 61] and semantic-based detectors [31, 32, 46, 63, 64]."}, {"title": "2 PRELIMINARIES", "content": "In this section, we first introduce commonly used graph representations (i.e., Function Call Graph and its variants) in Android malware detection. Then, we formally formulate the problem of graph-based malware detection and adversarial example attacks."}, {"title": "2.1 Graph Representations", "content": "The graph representations of Android apps encode both the semantic and structural information and have been widely used in Android malware detection [31, 31, 32, 46, 63]. Among these, the Function Call Graph (FCG) is a popular representation that captures the caller-callee relationships among the API calls in an app. Detectors like MalScan [63] and HomDroid [64] analyze FCGs akin to social networks, leveraging centrality and community detection algorithms to uncover malicious patterns for malware detection.\nAdditionally, several variants of FCGs have been proposed to model app behaviors. For example, MamaDroid [46] abstracts the nodes of FCGs according to their packages or family names to construct a higher-level, abstracted graph representation. MsDroid [31] uses sensitive API calls as seed nodes to generate graph snippets around them, modeling apps as a collection of subgraphs. MsDroid further utilizes the opcode and required permissions of functions as the node features to initialize the graph representation. In our study, we adopt the graph structure proposed in MsDroid due to its simplicity and proven effectiveness in detecting Android malware."}, {"title": "2.2 Problem Formulation", "content": "Android Malware Detection. Graph-based Android malware detectors take the graph representation of an app as input and output the probability of it being malicious. Here, we formally define the input graph as G = (V, &, X), where each node \\(v \\in V\\) represents an API call, and each edge e(u,v) \\(\\in\\) & denotes the invocation from node u to node v. The set X collects the features of the nodes. The goal of the malware detector is to learn a classifier C: G\u2192 {0, 1}, where 0 denotes a benign app, and 1 denotes malware.\nAdversarial Examples. Adversarial examples are crafted to mislead learning classifiers by introducing perturbations to the input features while preserving the malicious functionalities [15, 37, 38, 54, 71]. In the context of graph-based Android malware detection, these adversarial examples can be represented as deliberately altered target graph-based features to bypass the classifier C. Suppose \\(P\\) denotes the perturbation operation, and \\(L(\\cdot)\\) is the label predicted by the classifier C. Then, the adversarial example G' can be formulated as G' = P(G) = G + \\(\\delta\\), where \\(\\delta\\) signifies the perturbations to the graph structure, such as adding nodes and edges. The adversarial manipulation process can be represented as:\n\\[L(C(G)) \\neq L(C(P(G))). \\quad (1)\\]\nIntuitively, an ideal Android malware detector should be highly effective in identifying malware while also being robust against adversarial examples. However, current models predominantly emphasize detection effectiveness, often at the expense of robustness [10, 30, 38, 63]. As such, designing robust and effective Android malware detectors remains an open challenge [22, 42]. In this study, we propose a novel graph-based approach, MASKDROID, detailed in Section 3, to further advance this field. Our approach not only bolsters robustness against adversarial examples but also ensures high detection effectiveness through a more precise interpretation of the program semantics of apps."}, {"title": "3 METHODOLOGY", "content": "In this section, we present a novel learning framework, MASKDROID, designed to improve the robustness of Android malware detection without compromising detection performance. Guided by a masking mechanism, MASKDROID can more effectively explore the structural and semantic information encoded in the graph representations, thereby enhancing the understanding of potential malicious behaviors. Additionally, we further incorporate a proxy-based contrastive learning module to boost MASKDROID's ability to discriminate between benign and malicious instances."}, {"title": "3.1 Overview", "content": "MASKDROID consists of two main components: (1) a self-supervised reconstruction module that utilizes graph neural networks (GNNs) along with a graph mask mechanism to learn semantics of the input graphs, and (2) a proxy-based contrastive learning module, which leverages the mutual information across samples in similar and dissimilar classes to enhance the model's discriminatory power.\nIn the reconstruction part, we first mask a proportion of the nodes in the input graph. A GNN encoder is then applied to map the features of each node into a latent space. Following this, a GNN decoder reconstructs the masked-out nodes based on the latent representations of the remaining nodes. This self-supervised task promotes the learning of the underlying structures and dependencies within the input graphs, thereby deepening the model's understanding of app behaviors.\nWith the graph-level representation obtained from the graph encoder, we proceed to the contrastive module. The principle behind this module is that apps within the same class (i.e., benign or malicious) should be closer to each other, while apps from different classes should be more distant. To achieve this, we initialize two proxy representations as the anchors of benign and malicious classes, respectively. During the training phase, we pull a sample closer to the anchor of its class and push it away from the anchor of a different class. These proxy representations are updated simultaneously to maintain their roles as class anchors.\nTo predict the category of an app, MASKDROID disables the mask mechanism and processes the input instance through the encoder to obtain a graph-level representation. Finally, it determines whether the app is benign or malicious based on which proxy the graph-level representation is closer to."}, {"title": "3.2 Reconstruction Module", "content": "We now present the details of the self-supervised reconstruction module in MASKDROID. For better understanding, we will first recap the graph representation used in MASKDROID before delving into the module itself.\nRecap of Graph Representation. The graph representation utilizes the function call graph (FCG) as its input. Specifically, we begin by identifying a set of sensitive API calls (e.g., getIpAddress()) within an app's FCG to serve as seed nodes. Next, we extract subgraphs centered on these seed nodes at a fixed depth to form the input graph.\nHere, we begin with the initialization of node features and then introduce how we mask and reconstruct the graph to learn the underlying program semantics in a self-supervised manner.\nNode Initialization. Given the graph representation, G = (V, &, X), each node \\(v \\in V\\) is characterized by its attributes (i.e., opcode and permissions) that describe the API call. To capture this information, we initialize the node feature \\(x_v \\in R^d\\) as the concatenation of the embeddings for the opcode and permissions:\n\\[x_v = \\nu_{op} || \\nu_{per}, \\quad (2)\\]\nwhere \\(\\nu_{op}\\) and \\(\\nu_{per}\\) represent the one-hot encodings of the opcode and permissions, respectively.\nGraph Reconstruction. Our objective is to learn a high-quality representation that is resilient to adversarial attacks while ensuring optimal detection performance. The reconstruction module supports this goal by encouraging the model to recover masked nodes using unmasked nodes, effectively capturing the underlying structural and semantic information within the input graph. Consequently, even if the input graph is partially corrupted, MASKDROID retains its ability to discern malicious semantics, making it more robust to adversarial attacks.\nGraph Masking and Encoder. We apply uniform random sampling to choose a subset of nodes \\(V' \\subset V\\) and mask their corresponding representations with a learnable vector \\(x^{[M]}\\). This strategy ensures that for each node, its neighbors are neither all masked nor all visible [33]. Based on this, it is easier to recover the masked nodes with their neighboring unmasked nodes, facilitating the training of the model to understand the graph structure. Formally, the node feature \\(x_v\\) of the masked graph G can be defined as:\n\\[x'_v = \\begin{cases}\nx^{[M]}, & v \\in V',\n\\ x_v, & v \\notin V'.\n\\end{cases} \\quad (3)\\]\nConsidering the inherent graph nature of the masked graph, MASKDROID utilizes graph neural networks [28] (GNNs) to analyze the structural information and learn the corresponding node representations, i.e., embeddings. GNNs are particularly suited for this as they recursively propagate and aggregate node features across edges, enabling the model to capture both local and global graph dependencies. Formally, the representation of a node v at layer l + 1 is updated by aggregating the embeddings of its neighbors as follows:\n\\[x_v^{(l+1)} = \\sigma\\left(x_v^{(l)} + \\sum_{u \\in \\mathcal{N}(v)} x_u^{(l)} \\right)W^{(l)}\\right) \\quad (4)\\]\nwhere \\(\\mathcal{N}(v)\\) represents the set of neighbors of node v, \\(W^{(l)}\\) is the weight matrix at layer l, and \\(\\sigma\\) is the activation function, such as ReLU or LeakyReLU. After L layers of propagation, the final node embeddings are obtained as \\(h_v = x_v^{(L)}\\).\nGraph Remasking and Decoder. With the latent representation \\(h_v\\) for each node in the masked graph, the next step is to recover the masked nodes and reconstruct the original graph. If MASKDROID can accurately recover the masked nodes, it indicates that the model can infer the missing information based on the surrounding nodes, enhancing its robustness to adversarial attacks. Formally, the re-masked representation \\(\\hat{h}_v\\) is defined as follows:\n\\[\\hat{h}_v = \\begin{cases}\nh^{[M]} & v \\in V',\n\\ h_v & v \\notin V'.\n\\end{cases} \\quad (5)\\]\nwhere \\(h^{[M]}\\) is a learnable vector used to re-mask selected nodes. The re-masked representation is then fed into the decoder \\(f_D\\) to reconstruct the original node features. Similar to the encoder, the decoder also utilizes the GNN architecture, which is better to capture the structural information and reconstruct the masked nodes.\n\\[z_v = f_D(\\hat{h}_v) = GNN(\\hat{h}_v). \\quad (6)\\]\nHere, for clarity, we omit the details of how the decoder propagates and aggregates information along the graph, as this process can be designed in a manner similar to the encoder.\nTo train the model, we define the reconstruction loss \\(\\mathcal{L}_{rec}\\) to measure the discrepancy between the original node features and the reconstructed features. Particularly, we employ the cosine similarity to measure their distance as follows:\n\\[\\mathcal{L}_{rec} = \\frac{1}{|V'|} \\sum_{v \\in V'} \\left(1 - \\frac{x_v^T z_v}{\\|x_v\\| \\|z_v\\|} \\right)^2. \\quad (7)\\]\nIn summary, through the self-supervised graph reconstruction learning task, MASKDROID gains a holistic understanding of the graph structures and semantics, which is crucial for the success of the subsequent discrimination task."}, {"title": "3.3 Contrastive Module", "content": "With the stable representation that captures app semantics, we now turn to the contrastive module, which aims to enhance the model's discriminatory power. The principle behind this module is intuitive: apps executing similar behaviors should cluster together and mutually reinforce each other, while apps from different classes should be more distant from each other.\nTowards this end, we adopt a proxy-based contrastive learning strategy [67] to explore the mutual information across samples in similar and dissimilar classes. Since Android malware detection is a binary classification task, we define two proxies, \\(p_0\\) and \\(p_1\\) for benign and malicious classes, respectively. Each instance has a supervised label \\(y_i\\) indicating whether it belongs to the benign or malicious class, where 0 represents benign and 1 represents malicious. The contrastive learning process can be defined as follows:\n\\[\\mathcal{L}_{cl} = y_i \\left(1 - \\frac{g_i^T p_0}{\\|g_i\\| \\|p_0\\|} \\right)^2 + (1 - y_i) \\left(1 - \\frac{g_i^T p_1}{\\|g_i\\| \\|p_1\\|} \\right)^2 + (1 - y_i) \\left(1 + \\frac{g_i^T p_0}{\\|g_i\\| \\|p_0\\|} \\right)^2 + y_i \\left(1 + \\frac{g_i^T p_1}{\\|g_i\\| \\|p_1\\|} \\right)^2. \\quad (8)\\]"}, {"title": "3.4 Android Malware Detection", "content": "To optimize the model for Android malware detection, we combine the reconstruction and contrastive modules into a joint training framework. The final objective of MASKDROID is defined as:\n\\[\\mathcal{L} = \\lambda_1 \\cdot \\mathcal{L}_{rec} + \\lambda_2 \\cdot \\mathcal{L}_{cl} \\quad (9)\\]"}, {"title": "4 EVALUATION", "content": "In this section, we evaluate the performance of MASKDROID by answering the following research questions (RQs):\n\u2022 RQ1: Does MASKDROID successfully improve the robustness against different adversarial attacks compared to its baselines?\n\u2022 RQ2: Does MASKDROID sacrifice detection effectiveness to enhance its robustness against adversarial attacks?\n\u2022 RQ3: To what extent do different design choices affect the performance of MASKDROID on counteracting adversarial attacks and detecting malware?\n\u2022 RQ4: Does MASKDROID require more computational resources to complete its detection?"}, {"title": "4.1 Experimental Setup", "content": "We utilize Androguard [3] to decompile APKs and extract the Function Call Graph (FCG) for each app. To find optimal hyper-parameters for MASKDROID, we employ a grid search strategy. To find optimal hyper-parameters for MASKDROID, we employ a grid search strategy. For experiments in Sections 4.2 and 4.3, we use the entire dataset from 2016 to 2020, finding that mask rate = 0.8 yields the best performance. As such, we choose 0.8 as the masking rate. Furthermore, the number of GNN layers in both the encoder \\(f_e\\) and decoder \\(f_D\\) is tuned among {1,2,3}. Based on achieving the best performance, we present results under the configuration of a mask rate of 0.8, 0.001 learning rate, and two 2-layer GNNs for encoder and decoder. In addition, \\(\\lambda_1\\) and \\(\\lambda_2\\) are set to be equal in our experimental setting.\nAll experiments are performed on a server with an Intel Xeon Gold 6248 CPU @ 2.50GHz, 188GB physical memory, and an NVIDIA Tesla V100 GPU. The OS is Ubuntu 20.04.2 LTS."}, {"title": "4.1.2 Datasets", "content": "To rigorously assess MASKDROID's performance, we source our dataset from AndroZoo [9], a continuously expanding repository of Android apps that aggregates apps from several sources, such as Google Play, Appchina, and Anzhi. The dataset adheres to the guidance proposed by TESSERACT [52]. Avoid Grayware: The ambiguous nature of grayware can potentially skew the performance of learning models. To counteract this threat, we utilize the positive anti-virus alerts from VirusTotal [59], represented by p, to filter out grayware. In particular, apps with \\(p\\) \u2265 4 are labeled malicious, whereas those with p = 0 are classified as benign. Goodware-to-Malware Ratio: Previous studies have verified that the ratio of benign to malicious apps in the wild is notably imbalanced, with malware constituting a small fraction (10%) [16, 52, 70]. Additionally, we sample the dataset from 2016 to 2020 to cover a wide range of apps and reflect the temporal dynamics of malware evolution. In our experiments, we randomly split each dataset into three disjoint sets: training, validation, and testing, with proportions of 70%, 20%, and 10%, respectively. We also ensure all the disjoint sets exhibit a 9:1 ratio of benign to malicious apps."}, {"title": "4.1.3 Baselines", "content": "To comprehensively investigate the performance of MASKDROID, we compare it with three state-of-the-art graph-based detection approaches: MamaDroid, MalScan, and MsDroid, as well as two non-graph-based detectors: Drebin and RAMDA."}, {"title": "4.2 Robustness Enhancement (RQ1)", "content": "Settings. In this RQ, we investigate whether MASKDROID can effectively enhance its robustness against adversarial attacks compared to state-of-the-art detectors. we measure the resilience of these detectors against adversarial attacks using two metrics: (a) Attack Success Rate (ASR), which indicates the percentage of adversarial examples that successfully evade detection, and (b) Average Perturbation Ratio (APR), which quantifies the average percentage of perturbed edges in the graph representation.To comprehensively explore the robustness of MASKDROID, we implement a representative attack algorithm, Integrated Gradient Guided JSMA (IG-JSMA) attack [62], under two distinct scenarios: white-box and black-box."}, {"title": "4.2.1 White-Box Attack Defense", "content": "White-box adversarial attacks occur when attackers possess full knowledge of the victim model. In this scenario, we exclude MamaDroid [46], Malscan [63], and Drebin [10], as they utilize traditional machine learning methods rather than deep neural networks, preventing us from calculating their gradient information."}, {"title": "4.2.2 Black-Box Attack Defense", "content": "In real-world scenarios, attackers do not always have access to the detailed structures and parameters of the malware detection systems and are often limited to certain knowledge.In this context, the typical attack strategy is to distill a substitution model that mimics the behavior of the original black-box model, and then calculate gradients based on the substitution model to simulate a white-box attack. We follow the same strategy to conduct a black-box attack on the substitution model."}, {"title": "4.3 Effectiveness Comparison (RQ2)", "content": "Settings. Having verified MASKDROID's robustness against adversarial attacks, we now investigate whether this robustness comes at the expense of detection effectiveness. To measure the detection effectiveness of MASKDROID and its baselines, we evaluate their performance on the testing set using standard metrics, including precision, recall, F1-score, and accuracy, following the standard practice in Android malware detection [31, 63]. Additionally, temporal bias is widely recognized as a key factor influencing the effectiveness of malware detectors [42]. We also explore its impact on MASKDROID.\nResult 2: MASKDROID achieves detection effectiveness comparable to existing Android malware detectors in both same-time distribution scenarios and situations involving temporal bias."}, {"title": "4.4 Ablation Study on MASKDROID (RQ3)", "content": "In this section, we investigate the impact of different design choices on the performance of MASKDROID. Specifically, we conduct ablation experiments on various components to explore how they contribute to MASKDROID's robustness and effectiveness in Android malware detection.\nEffect of Reconstruction/Contrastive Modules. To clarify our description, we first introduce the terminology used in this section.\nEffect of mask rate \\(\\gamma\\). The masking mechanism is one of our key designs to encourage MASKDROID to learn a more holistic representation of the input graph. Selecting an appropriate mask rate \\(\\gamma\\) is crucial for our model's performance."}, {"title": "4.5 Efficiency Evaluation (RQ4)", "content": "In addition to the robustness and effectiveness of MASKDROID, efficiency is another critical factor influencing the model's practicality. In this section, we compare the training costs of MASKDROID with its baseline and variant models to evaluate its efficiency. Result 4: MASKDROID achieves a balance between detection robustness and efficiency, demonstrating superior resilience against adversarial attacks while maintaining a moderate training cost compared to its baselines."}, {"title": "5 THREATS TO VALIDITY", "content": "In this section, we discuss the threats to the validity of our study.\nFirst, the effectiveness and robustness of MASKDROID may be influenced by different hyper-parameters used in the neural networks. To mitigate this threat, we adopt advanced practices from prior studies [43, 68], employing a grid search to tune and find the optimal hyper-parameters that yield the best performance on validation sets. Second, when conducting comparison experiments, we utilize open-source implementations of baseline methods.\nThird, we do not compare MASKDROID's defensive capabilities with other adversarial defense methods, such as adversarial training [7]. This is because these methods are orthogonal to our work and can be integrated with MASKDROID to enhance further its robustness against adversarial attacks, which we leave as future work. At last, following previous studies [15, 63], we use the representative attack algorithm JSMA to evaluate MASKDROID's robustness."}, {"title": "6 RELATED WORK", "content": "In this section, we begin by reviewing related work on machine learning (ML)-based Android malware detection. Subsequently, we describe the masking mechanism. Finally, we introduce common adversarial example generation methods and their corresponding defense strategies."}, {"title": "ML-based Android Malware Detection", "content": "Machine learning (ML) techniques have been extensively employed to analyze various types of APK features and extract malicious patterns for Android malware detection."}, {"title": "Masking Mechanisms", "content": "In the field of graph representation learning, masking and reconstructing graph features has proven to be an effective approach for achieving robust learning [33]. Inspired by the success of masking mechanisms in improving model robustness, we pioneer and adapt this practice to enhance the robustness of Android malware detection."}, {"title": "Adversarial Example Attack", "content": "With ML-based Android malware detection evolving, attackers increasingly seek to evade these detectors by purposefully perturbing the malicious APK samples."}, {"title": "Adversarial Example Defense", "content": "To combat adversarial attacks, one can approach the problem from two distinct angles: by fortifying the data [7, 14, 24, 48, 52] or by enhancing the model [18, 40, 51, 56]."}, {"title": "7 CONCLUSION", "content": "In this work, we propose MASKDROID, a novel framework designed to enhance robustness against adversarial attacks while maintaining impressive discriminative power for Android malware detection. Specifically, we introduce a masking mechanism and force MASKDROID to reconstruct the entire graph using the unmasked part, enabling it to learn stable representations of the input graphs more effectively. grounded by extensive evaluations, MASKDROID steadily outperforms state-of-the-art (SOTA) baselines on adversarial attack defense tasks and achieves comparable performance on malware detection tasks. A promising direction for future work would be to extend the exploitation of the mask mechanism to attention masks with semantic information, which could further enhance the model's understanding of malicious behaviors."}]}