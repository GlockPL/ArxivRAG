{"title": "Adaptive Spatiotemporal Augmentation for Improving Dynamic Graph Learning", "authors": ["Xu Chu", "Hanlin Xue", "Bingce Wang", "Xiaoyang Liu", "Weiping Li", "Tong Mo", "Tuoyu Feng", "Zhijie Tan"], "abstract": "Dynamic graph augmentation is used to improve the performance of dynamic GNNs. Most methods assume temporal locality, meaning that recent edges are more influential than earlier edges. However, for temporal changes in edges caused by random noise, overemphasizing recent edges while neglecting earlier ones may lead to the model capturing noise. To address this issue, we propose STAA (SpatioTemporal Activity-Aware Random Walk Diffusion). STAA identifies nodes likely to have noisy edges in spatiotemporal dimensions. Spatially, it analyzes critical topological positions through graph wavelet coefficients. Temporally, it analyzes edge evolution through graph wavelet coefficient change rates. Then, random walks are used to reduce the weights of noisy edges, deriving a diffusion matrix containing spatiotemporal information as an augmented adjacency matrix for dynamic GNN learning. Experiments on multiple datasets show that STAA outperforms other dynamic graph augmentation methods in node classification and link prediction tasks.", "sections": [{"title": "I. INTRODUCTION", "content": "To enhance the generalization ability and performance of Graph Neural Networks (GNNs), researchers use graph augmentation to achieve better graph learning [1]\u2013[4]. Recent studies combine GNNs with recurrent networks and transformers, producing dynamic GNNs [5]\u2013[9]. Extending augmentation to dynamic graphs has yielded significant results [10]\u2013[13]. However, dynamic graphs contain dynamic noise, which is characterized by temporally evolving structures and uncertain changes [14]. Most augmentation methods rely on temporal locality assumption, which posits that recent edges are more important than earlier ones for augmenting node representations [12]. This assumption does not apply to temporal changes in edges (i.e., structure) caused by noise. As shown in Figure 1, the link prediction task predicts edges on the graph at time t + 1 based on graph snapshots at time t and earlier. Augmentation methods that excessively focus on recent edges (edges of yellow nodes at time t) while neglecting earlier edges (edges of yellow nodes at times t -1 and t \u2212 2) may lead the model to capture noise (blue edge) rather than effective spatiotemporal information (red edges).\nTo identify and suppress noisy edges, we approach from the node perspective, categorizing the nodes in the dynamic graph into active nodes (frequently changing structure, such as the yellow nodes in Figure 1) and inert nodes (stable structure). Active nodes frequently alter their interactions with other nodes, making them more susceptible to noisy edges [14].\nIn this paper, we propose STAA (SpatioTemporal Activity-Aware Random Walk Diffusion), a novel discrete-time dynamic graph augmentation method. STAA assesses nodes' spatiotemporal characteristics, calculating activity coefficients. Nodes with high coefficients are active nodes. Specifically, in spatial domain, STAA analyzes critical topological positions through graph wavelet coefficients, while in temporal domain, it analyzes edge evolution through graph wavelet coefficient change rates. Subsequently, the random walk defined on the dynamic graph suppresses the active nodes' preference for recent edges and increases the temporal walking probability of earlier edges to obtain a larger temporal receptive field, thereby generating a diffusion matrix that reduces the weight of noise edges. We use this diffusion matrix as an augmented adjacency matrix for the dynamic graph. Our main contributions are:\n(a) We introduced a method for evaluating the spatiotemporal activity of nodes based on wavelet coefficients and their rate of change within a time window. (b) We propose STAA, a model-agnostic dynamic graph augmentation method. STAA suppresses noise and enhances the spatiotemporal information of dynamic graphs. (c) Extensive experiments on multiple popular dynamic graph datasets demonstrate that, compared to other graph augmentation methods, using STAA to enhance dynamic graphs enables GNNs to achieve superior performance in node classification and link prediction tasks."}, {"title": "II. PRELIMINARIES", "content": "In this paper, we concentrate on the discrete-time dynamic graph [15], defined as a series of snapshots G ="}, {"title": "III. METHOD", "content": "The framework of STAA is illustrated in Figure 3. Initially, for a dynamic graph G with adjacency matrices {A1,..., AT}, STAA starts by processing the first adjacency matrix A1 and an initial diffusion matrix Xo as shown in Figure 3(a). By utilizing node evaluations derived from graph wavelet transforms, STAA directs the SpatioTemporal Activity-Aware Random Walk (STAARW) to produce a diffusion matrix X1. At each subsequent time step t, STAA updates its input by incorporating the new adjacency matrix At and the last diffusion matrix Xt\u22121 to generate the next diffusion matrix Xt. To improve dynamic graph learning, the diffusion matrix Xt \u2208 Rnxn at each time step t supersedes At in training dynamic graph neural networks.\nIn this section, Graph Wavelet Transform (GWT) is used to evaluate the spatiotemporal activity of nodes, i.e., to assess whether nodes are active or inert. For node vj on Gt and r\u2208 Z+,r \u2265 2, we define the low-frequency coefficient $a_{t,j}$ and high-frequency coefficient $b_{t,j}$ as:\n$a_{t,j} = \\sum_{l=0}^{r-1} e^{\\lambda(l-r+1)}W_f(\\omega_l, j), b_{t,j} = \\sum_{l=0}^{r-1} e^{-\\lambda l}W_f(\\omega_l, j),$ (2)\nwhere \u03bb controls exponential decay magnitude, Wf(\u03c9\u03b9, j) is graph wavelet coefficient of node $v_j$ at time t for scale \u03c9\u03b9.\nAccording to the Observation, nodes with large high-frequency coefficients on Gt have unsmooth signal distributions in their neighborhoods, indicating that at time t,\n$\\Delta a_{t,j} = \\frac{1}{W-1} \\sum_{i=1}^{W-1} |a_{t-i+1,j} - a_{t-i,j}|,$\n$\\widetilde{\\Delta a_{t,j}} = \\frac{\\Delta a_{t,j} - \\mu(\\Delta a_t)}{\\sigma(\\Delta a_t) + \\epsilon},$ (3)\nwhere 1 \u2264 W \u2264 T is the size of the time window, \u03bc(\u0394at) and \u03c3(\u0394at) are the mean and standard deviation of \u0394at for all nodes on Gt, respectively, and e is a small constant to prevent division by zero. $\\widetilde{\\Delta a_{t,j}}$ is the normalized low-frequency coefficient change rate. The normalized high-frequency coefficient is defined as:\n$\\widetilde{b_{t,j}} = \\frac{b_{t,j} - \\mu(b_t)}{\\sigma(b_t) + \\epsilon},$ (4)\nwhere \u03bc(bt) and (bt) are the mean and standard deviation of bt for all nodes on Gt, respectively. The spatiotemporal activity coefficient \u03b2t,j of node vj at time t is defined as:\n$\\beta_{t,j} = \\delta \\cdot \\sigma(\\tau_{t,j}),$\n$\\tau_{t,j} = \\frac{\\tau_{t,j} - \\mu(\\tau_t)}{\\sigma(\\tau_t)}, \\tau_{t,j} = \\gamma \\widetilde{\\Delta a_{t,j}} + (1 - \\gamma) \\widetilde{b_{t,j}},$ (5)\nwhere \u03c3(.) represents the sigmoid function, \u03b4 is a scaling factor, and \u03b3 is a gating factor used to balance the influence of the low-frequency coefficient change rate and high-frequency coefficient. \u03bc(\u03c4t) and \u03c3(\u03c4t) are the mean and standard deviation of Tt for all nodes on Gt, respectively.\nIn this section, we extend Random Walk with Restart [19] to SpatioTemporal Activity-Aware Random Walk (STAARW), to generate spatially and temporally node-to-node scores.\nOur approach draws inspiration from [20] but differs in that STAARW selectively adopts a walking strategy biased by the node activity coefficient.\nAs depicted in Figure 3(b), STAARW connects the same nodes from Gt to Gt+1 at each time step t. Nodes not only\n$x_{t,s} = A_t^T (I_n - \\alpha I_n - \\beta_{t,\\wedge})x_{t,s} + \\alpha i_s + \\beta_{t,\\wedge}x_{t-1,s},$ (6)\nwhere \u03b2t, denote the diagonal matrices with main diagonal entries (\u03b2t,1, \u03b2t,2,..., \u03b2t,n). is is the s-th unit vector of size n. At is a row-normalized matrix of At (i.e., $A_t = D_t^{-1}A_t$, where At is a self-looped adjacency matrix and Dt is a diagonal out-degree matrix of At). We define xo,s as is. \u03b2t, Xt\u22121,s is the time travel term. The higher the activity coefficient \u03b2t,u, the greater the time travel probability of node u, indicating a focus on earlier edges rather than recent edges.\nIn Equation (6), xt,s \u2208 Rn\u00d71 is a column vector of a probability distribution with respect to a seed node s. For all seeds s \u2208 V, {xt,s} are horizontally stacked to form Xt \u2208 Rn\u00d7n, such that xt,s is the s-th column of Xt, i.e., xt,s = Xtis. According to Equation (6), the following expression can be derived:\n$x_{t,s} = L_t^{-1} (\\alpha i_s + \\beta_{t,\\wedge}x_{t-1,s})$\n$= (\\alpha L_t^{-1} + L_t^{-1}\\beta_{t,\\wedge}X_{t-1})i_s = X_t i_s,$ (7)\nwhere Lt = In - At (In-aIn - \u03b2t,^), xt-1,s = Xt-1is, X\u2081 = aL\u012b\u00b9 + L\u012b\u00b9\u00dft,^Xt\u22121 for t > 0, and Xo = In. We refer to X as a SpatioTemporal Activity-Aware Random Walk Diffusion matrix at time t. A filtering threshold is used to set the values of Xt below p to zero, thereby sparsifying Xt."}, {"title": "IV. EXPERIMENT", "content": "Dataset. We conduct experiments on seven public datasets extensively evaluated in dynamic graph representation learning studies. For link prediction tasks, we use the Bitcoin transaction network BitcoinAlpha [21], the Wikipedia admin voting network WikiElec [22], and the hyperlink network between Reddit subforums RedditBody [23]. For node classification tasks, we use the following datasets evaluated in [24]: the brain tissue connection network Brain, the co-author networks DBLP-3 and DBLP-5 from the DBLP database, and the post network Reddit. We ensure fair comparison and reproducibility by adopting the standard snapshot partitions from [11].\nBaseline Methods. We compare STAA with the following graph augmentation baselines: NONE (no augmentation), DropEdge (randomly removes edges at each epoch), GDC (employs Personalized PageRank), MERGE (combines adjacency matrices from time 1 to t), TIARA [11], and TGAC [12]. TIARA and TGAC are dynamic graph augmentation methods based on the assumption of temporal locality. Due to the lack of open-source implementations, we reproduce the graph augmentation method of TGAC (the version using degree centrality). For DropEdge and GDC, specific implementation details are unavailable, so we use experimental results from [11] to ensure a fair comparison.\nWe use GCN [25] and two dynamic GNNs to perform dynamic graph tasks: GCRN [5] and EvolveGCN [6]. We apply static GCN to each graph snapshot to verify the informational value of temporal information. GCRN and EvolveGCN are classic and widely applied and studied dynamic GNNs [26]\u2013[28], and we utilize the implementations provided by [29].\nImplementation Details. For STAA, A is fixed at 1, r at 6, \u20ac at 10-8, and p is searched in [0.0001, 0.01]. \u03b1, \u03b4, \u03b3, and W are chosen from (0,1), (0,2], (0, 1), and [1, 10], respectively. Adam optimizer is used with weight decay 10-4, learning rate in [0.01,0.05], decay factor 0.999, and dropout ratio in [0,0.5]. Experiments are conducted 5 times, reporting mean and standard deviation of test values. PyTorch and DGL [30] are used to implement all methods. We use Intel Xeon Silver 4310 as CPU and NVIDIA GeForce RTX 4090 as GPU.\nThis task predicts edge existence at time t + 1 using information up to time t. Following [6], we split the time snapshots according to 70% for training, 10% for validation, and 20% for testing. Equal numbers of negative (non-edge) and positive (edge) instances are sampled each time, with AUC as the metric. The number of epochs is 200, with an early stopping criterion of 50 epochs.\nTable I shows that STAA improves GNNs performance across all datasets compared to NONE (no augmentation), while static augmentations like DropEdge and GDC do not, suggesting that spatial enhancement alone is ineffective for this task. STAA also surpasses TIARA and TGAC, suggesting its spatiotemporal enhancement is more effective for dynamic graph learning. Compared to methods based on the assumption of temporal locality, this superior performance highlights the effectiveness of STAA's strategy in suppressing active nodes' tendency towards recent edges, thereby reducing the weight of noisy edges.\nThis task classifies node labels in a dynamic graph, predicting node categories in the final snapshot. Following [24], nodes are split into training, validation, and test sets (7:1:2). Node embeddings go through a softmax classifier, and Macro F1-score is used due to label imbalance. The number of epochs is set to 1,000 with an early stopping patience of 100.\nTable II shows that STAA improves GNNs performance across all datasets, particularly on Brain. In contrast, TIARA and TGAC, which are based on the temporal locality assumption, are inferior to STAA. Notably, TGAC achieves lower accuracy than None (without augmentation) on nearly all datasets, suggesting that TGAC likely amplifies noise rather than enhancing effective spatiotemporal information."}, {"title": "V. ACKNOWLEDGMENT", "content": "This work is supported by the National Key R&D Program of China [2022YFF0902703]."}, {"title": "VI. CONCLUSION", "content": "To improve dynamic graph learning, we reveal the spatiotemporal activity of nodes using graph wavelet transform and propose a dynamic graph augmentation method called STAA. STAA guides random walk strategy selection using node activity coefficients, reducing noisy edge weights and enhancing spatiotemporal information. Through extensive experimental analysis on multiple public datasets, we demonstrate that STAA performs better in enhancing GNNs for link prediction and node classification tasks on dynamic graphs."}]}