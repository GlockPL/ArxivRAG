{"title": "CONCLAD: COntinuous Novel CLAss Detector", "authors": ["Amanda Rios", "Ibrahima Ndiour", "Omesh Tickoo", "Parual Datta", "Nilesh Ahuja"], "abstract": "In the field of continual learning, relying on so-called oracles for novelty detection\nis commonplace albeit unrealistic. This paper introduces CONCLAD (\"COntinuous\nNovel CLAss Detector\"), a comprehensive solution to the under-explored problem\nof continual novel class detection in post-deployment data. At each new task, our\napproach employs an iterative uncertainty estimation algorithm to differentiate\nbetween known and novel class(es) samples, and to further discriminate between the\ndifferent novel classes themselves. Samples predicted to be from a novel class with\nhigh-confidence are automatically pseudo-labeled and used to update our model.\nSimultaneously, a tiny supervision budget is used to iteratively query ambiguous\nnovel class predictions, which are also used during update. Evaluation across\nmultiple datasets, ablations and experimental settings demonstrate our method's\neffectiveness at separating novel and old class samples continuously. We will\nrelease our code upon acceptance.", "sections": [{"title": "1 Introduction and Related Work", "content": "Deployed AI models frequently encounter dynamic and evolving data distributions, where continuous\nmodel adaptation is paramount to safeguard performance. Reliable novelty detection is a key\ncapability for adaptive AI. Novelty Detection will inform the model if there is new data and if so,\nwhich samples are novel and need to be learnt from. However, until now, novelty detection and\ncontinual adaptation have been tackled separately within different sub-fields of the AI scientific\nliterature. Most research in continual learning (CL) [1, 2, 3, 4, 5, 6] relies on fully labeled data,\ndespite the significant costs and impracticality of data labeling in real-world scenarios [7]. While\nthere are some unsupervised CL solutions [8, 9, 10], they often rely on an unrealistic assumption: that\nfor each new task and its incoming data, past classes do not appear alongside newly introduced classes,\nthereby eliminating the need for novelty detection. Removing this oracle assumption results in severe\nperformance degradation due to overconfidence in erroneous predictions [11]: novel classes' samples\nmay be incorrectly predicted to old classes, especially at task transition onset where the continual\ndecision boundaries are still immature. Meanwhile, solutions for novelty or out-of-distribution (OOD)\ndetection [12, 13, 14, 15, 16, 17] have primarily been designed and evaluated using a single, fixed\nsplit of old versus novel classes, rather than on continual splits. Additionally, conventional OOD\nmodels often lack the ability to continuously integrate and learn from newly detected data. When\nthese models are forced to update, they can suffer from continual error propagation [11]: incorrect\nnovelty predictions during the detection stage lead to incorrect parameter learning during the update\nstage, progressively degrading the overall system performance. The recently proposed incDFM\n[11] offers an innovative solution to continual novel class detection (CND). However, incDFM was\ndesigned for the simplistic scenario where only one novel class is introduced per task. This strong\nassumption allows incDFM to treat all samples flagged as novel as members of the single new class,\nenabling trivial pseudo-labeling for continual update. Due to this unrealistic one-class assumption,\nincDFM cannot be considered fully unsupervised. In more complex cases with multiple novel classes,\nincDFM fails to function effectively since it cannot distinguish between different novel classes."}, {"title": "2 Our Method", "content": "2.1. Problem Setting: Consider a continual agent $A(x, t)$ which needs to learn/adapt from a set of\ncontinual tasks. At each task t, $A(x, t)$ is presented with an initially unlabeled set of samples $U(t)$\nwhich consists in a mixture of unseen samples of its old/learnt classes $U_{old}(t)$ and unseen samples of\nnew (novel) classes $U_{new}(t)$:\n\n$U(t) = U_{old}(t) \\cup U_{new}(t)$, where $U_{old}(t) = \\{x|x \\sim \\cup_{k=1}^{t-1} D_k\\}$, $U_{new}(t) = \\{x|x \\sim D_t\\}$,\n\nHere $D_t$ comprises samples from the set of new classes $C_{new}^t$ introduced at task t, while $\\cup_{k=1}^{t-1} D_k$\nare samples belonging to all the old classes $C_{old}$ that have been learned up to and including task t - 1.\nSamples in $U_{old}(t)$ are \u201cunseen\u201d, meaning they were never used, neither in the initial training nor\nduring prior tasks' learning. Note that addressing data drifts in $U_{old}$ is beyond the scope of this work.\n\n2.2. Our solution: We introduce a continual novelty detector $N(x,t)$, operating alongside the\ncontinual agent, whose goal is to produce a reliable estimate of novel samples $\\overline{U}_{new}(t)$ while\nsimultaneously estimating their respective novel-class labels. Simply performing a binary distinction\nbetween novel-class and old-class samples (as in incDFM[11]) leads to poor results in novel multi-\nclass settings. Moreover, the dependence on task index t in $N(x, t)$ indicates that the novelty detector\nitself has to be continually updated so that novel classes at t are not considered novel at t + 1. To\nobtain novel-class labels in $\\overline{U}_{new}(t)$, one can either used unsupervised clustering methods [18], or\nactive supervision (i.e. labeling by an expert) [19, 20, 21]. Here, we share initial results using active\nsupervision for a tiny fraction of $U(t)$ (0.3% - 2.5%), along with pseudo-labeling of confidently\nidentified novel samples in $\\overline{U}_{new}(t)$. For all these tasks \u2013 novelty detection, sample selection for active\nlabeling, and for pseudo-labeling \u2013 $N(x, t)$ relies foundationally on a novel, iterative multi-class\nuncertainty estimation method 2 defined and explained in the next sections.\n\n2.2.1. Building block of CONCLAD's uncertainty formulation $S(i)$: CONCLAD's uncertainty\nestimation 2 uses the feature reconstruction error (FRE) [14], which is effective in novelty estimation\nfor the closed-world and the single-class increment CL [11]. FRE involves learning a PCA transform\n$T_m$ and its inverse $T_m^{-1}$ for each class m. A test feature u = g(x) is transformed by $T_m$ and re-\nprojected back using $T_m^{-1}$, with FRE calculated as the $l_2$ norm of the difference between the original\nand reconstructed vectors. High FRE scores indicate samples that don't belong to class m. In the\nsimplified single-class increment CL [11], a single PCA transform is used for all ID data.\n\n2.2.2. Step by Step Novelty Detection: Prior to deployment (task t = 0), we assume that an\nagent $A(x, t = 0)$ has been trained to classify among a fixed set of pre-deployment classes $C_{new}$.\nAccordingly, CONCLAD's novelty detector $N(x, t = 0)$ has been trained to recognize those classes\nas learnt/old by having computed FRE transforms for those classes, $T_m, \\forall m \\in C_{new}$. For a given\nfuture task t > 0, as unlabeled data arrives, $N^{(i)}(x, t)$ follows an iterative procedure (indexed by an\ninner-loop index, i, which is distinct from outer-loop task-index t) to learn to detect if/what novelties\nare present. At the first inner iteration i = 0, initial supervision querying is performed by picking\nsamples (subject to labeling budget) with high uncertainty scores w.r.t old classes defined as $S^0(u)$\n$min_{j \\epsilon C_{old}} (1 - FRE^j(u))$. $b_0$ is sampled uniformly among samples with $S^0(u) > mean(S^0(u))$. At this\npoint, novel classes can be identified (denoted by $C_{new}^i$ | in section 2.1, assuming $|C_{new}^i| > 0$) and\nthose few labeled samples are used to initialize parameters of $N^{(0)}(x, t)$: (1) Train a single layer\nperceptron, $N_V^{pl}(x,t)$ to learn an imperfect initial mapping to the $|C_{new}^i|$ novel classes. This layer,\nwhich performs pseudo-labeling (pl), contains output nodes only w.r.t novel classes. (2) compute"}, {"title": "3 Experiments", "content": "3.1. Setup: We evaluate on 4 datasets: Imagenet21K-OOD (Im21K-OOD) [22], Eurosat [23],\niNaturalist-Plants-20 (Plants) [24] and Cifar100-superclasses [25], all of which were constructed to\nhave no class overlap with Imagenet1K with the exception of Cifar100. Results for Cifar100 are\nincluded to enable direct comparison with baseline method incDFM [11]. We compare CONCLAD to:\n(1) incDFM [11], which first introduced an updatable continual novelty detector, albeit exclusively for\nsingle class novelties (see section 1); (2) DFM [26], originally proposed for static novelty detection.\nWe also include semi-supervised CND baselines: (3) Experience-Replay \"ER\" [27, 6] uses entropy\nas a measure of novelty similar to [28] and also to select active labels; (3) PseudoER [29], same as\nER, but iteratively pseudo-labels the most confident samples akin to CONCLAD. Other baselines\nare constructed (Fig 2 right table) from removing elements of CONCLAD such as the iterativeness\n(i.e. doing AL/Pseudo-labeling in one shot), etc. Implementations for CONCLAD and baselines: All\nuse a large/foundation frozen feature extractor, e.g. ResNet50 [30] pre-trained on ImageNet1K via\nSwAV [31] or ViTs16 [32] pre-trained on Imagenet1K via DINO [33]. CONCLAD's $N_V^p(x,t)$ (pseudo-\nlabeling head) is a fully connected layer. Baselines ER, PseudoER's long-term classification head\nis a perceptron of size 4096. For ER and PseudoER we use a fixed replay buffer size containing\npre-logit deep-embeddings and labels/pseudo-labels. We set the maximum buffer size to 5000 (2500\nfor Eurosat). At each incoming unlabeled pool, we fix a mixing ratio of 2:1 of old to new classes\nper task, with old classes drawn from a holdout set (0.35% of each dataset). For evaluation on the\nindependent test set, we sample old and new classes with the same 2:1 proportion. Note that old\nclasses act as distractors from the point of view of novelty detection. We set pseudo-labeling selection\nto a = 20% of samples predicted as novel (appendix 4.1.1). For experiments not purposely varying\nthe tiny supervision budget, we fix a labeling budget of 1.25% for Places, Plants and 0.625% for\nEurosat, Im21K-OOD, as guided by Fig 1 center which varies the AL budget from 0.625% to 5%.\n\n3.2. Results: We measure continual novelty detection performance with the common \"Area Under\nthe Receiver-Operating-Curve\" (AUROC) metric. Note that, for fair evaluation, we measure CND\non an independent test set with the same ratio of old to new class samples at each task. Fig. 1\n(left) displays CND performance (AUROC) over all continual tasks (time) in the case of multi-\nclass novelties per task (5 class increments for Im21K-OOD and 2 class increment for Eurosat)."}, {"title": "4 Appendix", "content": "4.1 Methodology Details\n\n4.1.1 Thresholds for Stopping the inner-loop\n\nThe inner-loop is guided by two simple thresholds: (1) Threshold $T_{inner}$ \"roughly\" estimates if\nthere are any possible novel-class samples in the unlabeled task input data pool and is controlled by\na single hyper-parameter, the number of standard deviations above the mean of an in-distribution\nvalidation set (2 STDs in our experiments). If no samples are found to be above $T_{inner}$, we reach the\nstopping criterion for our iterations. Our in-distribution validation set is conventionally defined to\ninclude a portion (0.1%) of the previous tasks' k = 1 : t 1 novelty predictions that were held-out\nat previous tasks, i.e. not used to update N(x, t) parameters. Importantly, the same in-distribution\nvalidation set is used for all compared baselines in our results section, as is common practice in the\nOOD/novelty-detection literature [11, 34]; (2) Finally, Threshold a tunes pseudo-labeling selection\nand is set to a = 20% highest $S^2(u)$ scores (most confident) from the test samples found above\n$T_{inner}$. These two thresholds are not highly sensitive.\n\n4.1.2 How to define Ambiguity\n\nCONCLAD seeks to minimize novelty-detection uncertainty and model multiclass-novelties by\nselecting the most novel-vs-old ambiguous samples at each inner-loop iteration, i.e. scores $S^i (u)$\nwhich are neither too high or too low. Our mathematical formulation uses the threshold $T_{inner}$ defined\nin the previous section: we formulate ambiguousness as the inverse squared distance $||S^i (u)-T_{inner} ||^2$\nof scores to $T_{inner}$. Intuitively, this formula favors selecting samples that cannot be unambiguously\npredicted as either old or new since $T_{inner}$ represents this rough decision boundary. Active selection\nis stopped when the tiny labelling budget is exhausted. The only exception to this Ambiguity\nformulation is at the first iteration i = 0 where we select homogeneously from samples above\n$T_{inner}$. This is the case because at i = 0 only old classes are used to compute the score function,\n$S^0(u) = min_{j \\epsilon C_{old}}(1 - FRE^j(u))$ and so ambiguity cannot be defined in the same way as for the\nremainder of iterations.\n\n4.1.3 Measuring per-class uncertainty in CONCLAD's formulation\n\nCONCLAD is agnostic to the elemental uncertainty metric used in its uncertainty scoring function\n($S^i (u)$ Eq. 2 in section 2) as long as it can reliably estimate uncertainty w.r.t each novel class or old\nclass. However, this is not an easy feat since many existing static uncertainty quantification approaches\nare not fully reliable [14, 11]. As discussed in the main text, CONCLAD currently leverages the\nfeature reconstruction error (FRE) metric introduced in [14] to build Eq 2. For each in-distribution\nclass, FRE learns a PCA (principal component analysis) transform $\\{T_m\\}$ that maps high-dimensional\nfeatures u from a pre-trained deep-neural-network backbone g(x) onto lower-dimensional subspaces.\nDuring inference, a test-feature u = g(x) is first transformed into a lower-dimensional subspace by\napplying $T_m$ and then re-projected back into the original higher dimensional space via the inverse $T_m^{-1}$.\nThe FRE measure is calculated as the $l_2$ norm of the difference between the original and reconstructed\nvectors:\n\n$FRE_m(u) = || f(x) - (T_m^{-1} \\circ T_m)u||_2$.\n\nIntuitively, $FRE_m$ measures the distance of a test-feature to the distribution of features from class m.\nIf a sample does not belong to the same distribution as that mth class, it will usually result in a large\nreconstruction score $FRE_m$. FRE is particularly well suited for the continual setting since for each\nnew class discovered at test-time, an additional principle component analysis (PCA) transform can be\ntrained without disturbing the ones learnt for previous classes.\n\n4.2 Experimental Methodology Details\n\n4.2.1 Implementation Details for CONCLAD and Baselines\n\n$N(x, t)$ operates on top of a large-scale/foundation models as feature extraction backbones, kept\nfrozen throughout CONCLAD and baselines' training: (1) Most results use ResNet50 [30] unsupervis-\nedly pre-trained on ImageNet1K via SwAV [31]. We extract features from the pre-logit AvgPool layer"}]}