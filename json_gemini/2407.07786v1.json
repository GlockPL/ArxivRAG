{"title": "The Human Factor in Al Red Teaming: Perspectives from Social and Collaborative Computing", "authors": ["Alice Qian Zhang", "Ryland Shaw", "Jacy Reese Anthis", "Ashlee Milton", "Emily Tseng", "Jina Suh", "Lama Ahmad", "Ram Shankar Siva Kumar", "Julian Posada", "Benjamin Shestakofsky", "Sarah T. Roberts", "Mary L. Gray"], "abstract": "Rapid progress in general-purpose Al has sparked significant interest in \"red teaming,\" a practice of adversarial testing originating in military and cybersecurity applications. Al red teaming raises many questions about the human factor, such as how red teamers are selected, biases and blindspots in how tests are conducted, and harmful content's psychological effects on red teamers. A growing body of HCI and CSCW literature examines related practices-including data labeling, content moderation, and algorithmic auditing. However, few, if any, have investigated red teaming itself. This workshop seeks to consider the conceptual and empirical challenges associated with this practice, often rendered opaque by non-disclosure agreements. Future studies may explore topics ranging from fairness to mental health and other areas of potential harm. We aim to facilitate a community of researchers and practitioners who can begin to meet these challenges with creativity, innovation, and thoughtful reflection.", "sections": [{"title": "INTRODUCTION", "content": "As machine learning applications-particularly those driven by large language models-have become increasingly widespread, researchers have examined how these technologies may be integrated into our lives while also adhering to responsible artificial intelligence (AI) standards formulated by governments, large technology organizations, and researchers [13]. Given Al systems' broad application and relatively unpredictable nature, it is challenging for designers and developers to anticipate all possible use cases and consequences. For example, generative AI tools have been shown to reproduce implicit stereotypes about gender and ethnicity [6, 11]. This follows other AI blunders, such as Google's image recognition"}, {"title": "WORKSHOP GOALS AND THEMES", "content": "This workshop aims to outline the practice of AI red teaming, drawing on historical insights to understand its trajectory and structure. We prioritize understanding the humans involved in AI red teaming and how their roles influence the development of AI systems. Additionally, we seek to leverage past research to address safety concerns and identify academic disciplines and methodologies pertinent to analyzing red teaming practices. We will focus on the following themes:\n(1) Conceptualization of Red Teaming Inspired by Robert Soden and colleagues' [24] argument to ground CSCW in history, we aim to understand the trajectory of red teaming as a socio-technical, collaborative practice. This theme invites participants to engage in deeper discussions about red teaming complexities and consider the impact of conducting research in this space [18]. What constitutes red teaming, and how has its conceptualization evolved over time? What role does red teaming play within broader frameworks of Responsible Al, and how can decentralized or external approaches contribute to its effectiveness?\n(2) Labor of Red Teaming This theme explores the human aspects of AI red teaming, investigating stakeholders involved in the practice and their impact on shaping Al systems to inform future practices and policies. By examining the labor arrangements and power dynamics involved in red teaming practices (e.g., inequities in organizational practices of tech labor [23]), we seek to uncover historical parallels and contemporary methodologies that illuminate red teamers' roles and operational frameworks. What can historical precedents teach us about red teaming as a labor practice? How can we employ diverse methodologies to investigate red teamers' labor structures, including recruitment procedures and institutional commitments?\n(3) Well-being of and Harms Against Red Teamers Building on the theme of labor, this theme focuses on the safety and well-being of red teamers. We will identify strategies and interventions to mitigate potential harms from exposure to harmful content during red teaming activities. By addressing these critical concerns and integrating recommendations to prioritize worker well-being (e.g., [19]), we aim to foster a culture of well-being within the AI red teaming community. How can organizations build safeguards and design interventions to protect red teamers from potential harm? How can these strategies be implemented to ensure the safety and well-being of red teamers in their roles?"}, {"title": "WORKSHOP ACTIVITIES", "content": "We propose a one-day hybrid workshop that participants can attend in person at CSCW 2024 or virtually to include as many perspectives as possible. We will account for conference and meal breaks in the final schedule. We aim to include the following activities in the workshop:\n\u2022 Introduction (15 minutes): Workshop organizers will welcome participants, introduce themselves, and provide an overview of the workshop, including the details of the objectives and planned activities.\n\u2022 Red Teaming Exercise (45 minutes): We will have two red teaming exercises led by workshop organizers. First, participants will be grouped by areas of expertise (e.g., fairness [2], mental health [19]) accompanied by a workshop organizer per group. Participants will be given a brief walkthrough of prompt injection via the Gandalf platform in which the goal is to force the system to share a secret password. Then, each group will be instructed to formulate and input prompts into a popular LLM (e.g., ChatGPT, Claude) that produces harmful system behavior while being mindful of usage policies. Participants will produce a one-page \"report\" of their findings, emulating an open-ended task assigned to expert red teamers.\n\u2022 Panel Discussion (1 hour): To provide further background for this new area of CSCW inquiry, our organizing team includes senior scholars and practitioners from diverse sectors who will speak on challenges in red teaming. These senior workshop organizers will briefly discuss their perspectives on red teaming guided by prepared and live questions.\n\u2022 Artifact Development (2 hours): In this activity, participants will work in small groups to develop preliminary artifacts for later publication. Groups of participants will be no larger than five people, and each will be assigned a predefined workshop theme or theme that surfaced during the workshop. Participants can choose to develop artifacts in one of two ways:\nResearch Agenda: The first option is to ideate toward a research agenda linking relevant prior research to workshop themes (e.g., organizational practices of tech labor [23], prioritizing worker well-being [19], and critically reflecting on research impacts [18]).\nToolKit: The second option is to ideate towards a toolkit that may be leveraged by red teaming practitioners relevant to the assigned theme (e.g., for harms, a toolkit might include activities to consider well-being).\nAfter 90 minutes, groups working on the same theme will discuss and organize their findings in a shared online space (e.g., Miro board).\n\u2022 Shareouts (1 hour): To synthesize key findings and common themes across the artifact development activity, each group will have 10-15 minutes to present their findings, while others can provide feedback.\n\u2022 Closing Remarks (15 minutes): An organizer will convene to recap key insights gleaned from the workshop activities. Those interested in refining the artifacts created will"}, {"title": "HYBRID WORKSHOP LOGISTICS", "content": "In line with our workshop's goal of incorporating diverse perspectives, we are fully dedicated to offering a hybrid experience to enhance accessibility. Before the workshop, participants will be asked to bring a device capable of accessing online platforms listed below as these tools will be essential for facilitating the hybrid experience.\n\u2022 Website: The organizers will create a website for the workshop, including information about the workshop, a call for participation, an expression of interest form, the workshop schedule, and any other relevant information.\n\u2022 Discord: We will create a Discord server for the workshop to facilitate participants' interactions before, during, and after the workshop. We will ask participants to introduce themselves and share why they are attending the workshop on the server. The organizers will monitor the server to foster discussions and keep participants engaged.\n\u2022 Zoom Video Conferencing: All activities will be broadcast through Zoom to allow virtual participants to engage in the activities and discussions. The organizers will be on Zoom and will monitor the chat to help facilitate interactions between in-person and virtual participants. We will utilize breakout rooms to pair in-person and virtual participants to promote discussion between modalities.\n\u2022 Online Platforms: To support the sharing and recording of ideas during the discussion activities, we will use Google Documents and Miro to allow workshop participants to take notes. Both of these software are available online, allowing virtual participants to access the materials."}, {"title": "CALL FOR PARTICIPANTS", "content": "We welcome 20-30 academics and practitioners who are working, researching, or interested in red teaming from fields including but not limited to CSCW, AI, HCI, sociology, communications, philosophy, psychology, and labor studies. To express interest in attending, individuals must submit a statement of interest that will include a summary of their motivation for attending the workshop, themes they are interested in exploring, and a short biography via a Google form. The submissions will be reviewed by the workshop organizers and accepted based on the diversity of perspectives, given the focus on bringing together academic and practitioner viewpoints and approaches from diverse domains. We will advertise our workshop through social media and academic mailing lists and reach out to organizations or special interest groups that may be interested in the topic of our workshop."}, {"title": "WORKSHOP OUTCOMES", "content": "In addition to providing a venue for those already engaged with red teaming, we envision this workshop as an opportunity to highlight red teaming and its relevance to others in CSCW. Thus, the expected outcomes of this workshop include the following:\n\u2022 AI Red Teaming Research Network: We will bring together interdisciplinary researchers and practitioners to critically examine the current state of red teaming and how practitioners can support the humans who perform it. Through the exchange of experiences and ideas, we expect that collaborations will be formed, creating a network of researchers who will continue to work together on the topic.\n\u2022 Synthesis of Workshop Findings: Building on the collaborative efforts during the workshop activities, we aim to synthesize and publish key findings from the discussions and artifacts developed. We will gather insights and perspectives on Al red teaming practices by discussing developed artifacts. The resulting synthesis will offer valuable insights for practitioners and highlight avenues for further exploration by researchers."}, {"title": "ORGANIZING TEAM", "content": "Our workshop proposal includes a team of researchers experienced in critically examining labor, moderation, mental health and well-being, and RAI red-teaming.\nAlice Qian Zhang is a PhD student in the Human-Computer Interaction Institute at Carnegie Mellon University. Her research explores avenues to support individuals engaging with social computing technologies and Al systems, with a particular emphasis on underrepresented populations and the implications for mental health and well-being.\nRyland Shaw is a pre-doctoral research assistant at Microsoft Research's Social Media Collective, where he works on questions of Al ethics, technological norms, and sociotechnical systems. He has an MA in Communication from Simon Fraser University and comes from a background in documentary filmmaking.\nJacy Reese Anthis is the director of the Sentience Institute, a visiting scholar at the Stanford Institute for Human-Centered Artificial Intelligence (HAI), and a PhD candidate in the sociology and statistics departments at the University of Chicago. Jacy researches machine learning and human-AI interaction, particularly the rise of digital minds and how humanity can work together with highly capable Al systems.\nAshlee Milton is a PhD candidate in computer science at the University of Minnesota, focusing on human-computer interaction. Their research investigates how information retrieval systems are used by and affect users from marginalized populations from a user perspective to better design these systems to support users' needs and mental well-being.\nEmily Tseng is a postdoctoral researcher at Microsoft Research. Her work explores how computing technologies mediate individual, interpersonal, and structural harms, and how to create more equitable tech. Emily publishes at top-tier venues in HCI and design (CHI, CSCW), computer security and privacy (USENIX Security), and medicine (JAMA). She earned a Ph.D. in Information Science at Cornell University and a B.A. at Princeton University.\nJina Suh is a Principal Researcher in the Human Understanding and Empathy group at Microsoft Research. Her work lies at the intersection of technology and human well-being, where she examines the role of technologies, design choices, development practices, and values embedded in them in shifting power dynamics and affecting individual and organizational mental health and well-being. She received her Ph.D. in Computer Science at the University of Washington.\nLama Ahmad is a Policy Researcher at OpenAI, leading red teaming and researcher access efforts. Her work focuses on evaluating the socio-technical impact of Al systems on society. Prior to OpenAI, Lama was at Facebook, assessing the impact of social media on elections and democracy.\nRam Shankar Siva Kumar founded and leads the AI Red Team at Microsoft and co-authored Not with a Bug, But with a Sticker: Attacks on Machine Learning Systems and What To Do About Them [15]. He is also a Tech Policy Fellow at UC Berkeley, wherein his work on adversarial machine learning appeared notably in the National Security Commission on Artificial Intelligence (NSCAI) Final report presented to the United States Congress and the President.\nJulian Posada is an Assistant Professor of American Studies at Yale University and a member of the Yale Law School's Information Society Project and the Yale Institute for Foundations of Data Science. Their research integrates theories and methods from information science, sociology, and human-computer interaction to examine how technology is developed and used within various historical, cultural, and social contexts.\nBenjamin Shestakofsky is an Assistant Professor of Sociology at the University of Pennsylvania. His research centers on the relationship between work, technology, organizations, and political economy. He is the author of Behind the Startup: How Venture Capital Shapes Work, Innovation, and Inequality [23].\nSarah T. Roberts is an associate professor at UCLA specializing in Internet and social media policy, infrastructure, politics and culture, and the intersection of media, technology, and society. She is the faculty director of the UCLA Center for Critical Internet Inquiry (C2i2). Informed by feminist Science and Technology Studies perspectives, Roberts is keenly interested in the way power, geopolitics, and economics play out on/via the internet, reproducing, reifying, and exacerbating global inequities and social injustice.\nMary L. Gray is a Senior Principal Researcher at Microsoft Research, a Faculty Associate at Harvard University's Berkman Klein Center for Internet and Society, and a MacArthur Fellow. An anthropologist and media scholar by training, she focuses on how people's everyday uses of technologies transform labor, identity, and human rights. She maintains a faculty position in the Luddy School of Informatics, Computing, and Engineering with affiliations in Anthropology and Gender Studies at Indiana University."}]}