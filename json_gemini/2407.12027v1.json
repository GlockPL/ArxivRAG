{"title": "Idle is the New Sleep: Configuration-Aware Alternative to Powering Off FPGA-Based DL Accelerators During Inactivity", "authors": ["Chao Qian", "Christopher Cichiwskyj", "Tianheng Ling", "Gregor Schiele"], "abstract": "In the rapidly evolving Internet of Things (IoT) domain, we concentrate on enhancing energy efficiency in Deep Learning accelerators on FPGA-based heterogeneous platforms, aligning with the principles of sustainable computing. Instead of focusing on the inference phase, we introduce innovative optimizations to minimize the overhead of the FPGA configuration phase. By fine-tuning configuration parameters correctly, we achieved a 40.13-fold reduction in configuration energy. Moreover, augmented with power-saving methods, our Idle-Waiting strategy outperformed the traditional On-Off strategy in duty-cycle mode for request periods up to 499.06 ms. Specifically, at a 40 ms request period within a 4147 J energy budget, this strategy extends the system lifetime to approximately 12.39x that of the On-Off strategy. Empirically validated through hardware measurements and simulations, these optimizations provide valuable insights and practical methods for achieving energy-efficient and sustainable deployments in IoT.", "sections": [{"title": "1 Introduction", "content": "Embedded Deep Learning (DL) has recently made significant progress in the Internet of Things (IoT) domain [1]. Nevertheless, IoT devices, limited by the low-power Microcontroller Units (MCUs), often struggle with performance constraints [14]. Combining Field-Programmable Gate Arrays (FPGAs) with MCUs to create a heterogeneous computing platform has proven to be a promising approach to adapt to these limitations, balancing between computational power and energy efficiency [8]. However, optimizing task offloading from MCUs to FPGAs remains crucial to meet the stringent energy budget of IoT devices and advance sustainable IoT ecosystems.\nPrevious studies typically assumed that there is continuous data or work supply for FPGAs [7,11,12], justifying their emphasis on energy efficiency during the inference phase of FPGA-based DL accelerators. However, in common IoT"}, {"title": "2 System Model", "content": "This section delves into the system model used in our study, laying the groundwork for understanding the challenges and constraints we address. Figure 3 depicts the architecture of the heterogeneous platform we adopted. This platform consists of a low-power RP2040 MCU for coordination tasks, coupled with an embedded Spartan-7 XC7S15 FPGA. The MCU is usually in sleep mode, consuming 180 \u03bc\u0391 of current. It is woken up by either external hardware interrupts or through timers to perform periodic tasks. Meanwhile, the FPGA serves as a hardware accelerator and is activated only when needed, primarily for processing and accelerating DL tasks.\nThe communication interface connecting the MCU and the FPGA is a Serial Peripheral Interface (SPI). The FPGA is connected to flash with a dedicated SPI interface, supports clock frequencies from 3 to 66 MHz, and can be programmed to operate in single, dual, or quad buswidths. The FPGA can fetch bitstreams through this interface, facilitating seamless configuration when powering up or switching between different accelerators.\nThe power supply of the system is designed in a dual-mode arrangement, consisting of both a USB connection and a 320 mAh rechargeable LiPo Battery. The battery provides an energy capacity of approximately 4147 J, serving as the system's designated energy budget, denoted as $E_{Budget}$. To better profile the energy"}, {"title": "3 Problem Statement", "content": "As highlighted in Section 1, with periodic inference requests, the FPGA in our system can be powered off for a duration of $T_{off}$ to conserve energy. However, for SRAM-based FPGAs like ours, powering off results in the loss of configuration data stored on the chip. This necessitates reconfiguring the FPGA from external flash for each powering on, adding significant overhead to every inference request.\nFigure 2 demonstrates that enhancements in data transmission and inference phases have a limited effect on the overall energy consumption per workload item. Reducing the energy consumption of these phases to zero would only lead to a 12.85% decrease in the total energy per workload item. In contrast, eliminating the energy overhead associated with the configuration phase could potentially enable the execution of up to 6 additional inference requests, effectively allowing the processing of up to 6x more workload items within the same energy budget.\nConsequently, our study aims to achieve two primary goals: firstly, to reduce the energy consumed during the configuration phase in one workload item, and secondly, to decrease the number of necessary configurations while considering the request period."}, {"title": "4 Proposed Solution", "content": "This section details our proposed solutions in three steps. First, we focus on reducing the energy consumption during the configuration phase of a single workload item. Next, we extend our approach to optimize average energy consumption across multiple workload items. Finally, we introduce an analytical model for estimating the executable workload items of each strategy under given application requirements."}, {"title": "4.1 Reducing Energy for FPGA Configuration Phase", "content": "In the first step, we investigated whether it is possible to reduce or eliminate the energy overhead associated with the FPGA configuration phase by fine-tuning its parameters. To achieve this, we delved into the detailed configuration process as outlined in the Xilinx 7-Series FPGA configuration user guide [2], mainly focusing on the stages where potential energy savings could be most significant, as shown in Figure 4. Our empirical analysis highlights that the Clear Configuration Memory and Load Configuration Data stages are the most energy-intensive. In contrast, other stages contribute minimally to the overall energy consumption due to their short duration."}, {"title": "4.2 Minimize Number of Configurations by Idle-Waiting", "content": "Taking the Spartan-7 XC7S15 FPGA model as an example, energy consumption in the Setup stage is unavoidable. So even if the energy cost of the Bitstream Loading stage is optimized to zero, the energy consumption of the configuration phase can only be reduced from 11.85 mJ to 7 mJ. Thus, it becomes imperative"}, {"title": "4.3 Analytical Model", "content": "To evaluate energy consumption across different strategies within a designated energy budget, we develop an analytical model. This model is instrumental in identifying the maximum number of executable workload items and estimating the corresponding system lifetime.\nFor the On-Off strategy, $E_{OnOff}(n)$ as outlined in Equation 1 represents the cumulative energy cost for n workload items. Each $E_{Item}^{OnOff}$ includes the energy consumed during the configuration, data transmission and inference phases. In the Idle-Waiting strategy, as detailed in Equation 2, the total energy cost, $E_{IdleWait}(n)$, is comprised of three key components: 1) $E_{Init}$ represents the one-time initial overhead incurred by the FPGA at the start of the system. 2) $\\sum_{i=1}^{n} E_{Item}^{IdleWait}$ quantifies the energy required for n workload items, where all configuration-related overheads are zero. 3) $\\sum_{i=1}^{n-1} E_{Idle}$ accounts for the energy consumed during idle periods between workload items, where $E_{Idle}$ is determined by the idle time ($T_{idle}$) and the FPGA's idle power consumption ($P_{Idle}$).\n$E_{OnOff}(n) = \\sum_{i=1}^{n} E_{Item}^{OnOff}$ (1)\n$E_{IdleWait}(n) = E_{Init} + \\sum_{i=1}^{n} E_{Item}^{IdleWait} + \\sum_{i=1}^{n-1} E_{Idle}$ (2)\nTo ascertain the maximum number (nmax) of workload items executable within the energy budget ($E_{Budget}$), we set a criterion ensuring that $E_{Sum}(n)$ for different strategies optimally aligns with but does not exceed $E_{Budget}$, as formulated in Equation 3. The system lifetime ($T_{Lifetime}$) is then calculated by multiplying the derived ($n_{max}$) by the request period ($T_{req}$), as per Equation 4."}, {"title": "5 Experiments and Results", "content": "To validate the effectiveness of our proposed solutions, we conducted three interconnected experiments. The first experiment focused on reducing energy consumption during the FPGA configuration phase. The second experiment assessed the Idle-Waiting strategy's ability to reduce frequent configurations. The third experiment explored the power-saving methods in the idle-waiting phase, further enhancing the strategy's effectiveness."}, {"title": "5.1 Experiments Setup", "content": "We utilized the hardware specified in Section 2 for our experiments. Additionally, to accelerate experimentation and assist in scenarios where direct hardware testing is impractical, we developed a Python-based simulator, inspired by [5]. This tool aligns with the analytical model described in Section 4.3, and outputs the maximum number of executable workload items along with estimations of the system lifetime.\nThis simulator enables the specification of overall workload and individual workload items using YAML files, simplifying the execution of extensive experiments involving large datasets or complex measurements. A key feature of this simulator is its ability to incorporate both datasheet specifications and real hardware measurement, thus enhancing the precision of energy consumption estimations and offering a more realistic representation of actual scenarios.\nThe simulator requires two descriptions to operate: 1) the workload and 2) the workload item. The workload description contains the energy budget $E_{Budget}$ in joules and the constant request period, as mentioned in Section 1. The workload item description details each phase's average power consumption in milliwatts and duration in milliseconds. With these inputs, the simulator can effectively model the various strategies discussed in Section 4.2, allowing us to examine them under diverse conditions."}, {"title": "5.2 Experiment 1: Optimization on Energy for FPGA Configuration", "content": "In the first experiment, we conducted a hardware-based investigation of various FPGA configuration parameters involving 11 SPI clock frequencies, 3 SPI buswidths, and the bitstream compression option, listed in Table 1. We aimed"}, {"title": "5.3 Experiment 2: Idle-Waiting vs On-Off Strategies", "content": "In this experiment, we set out to identify the request period range where the Idle-Waiting strategy is more efficient than the On-Off strategy. Additionally, we aimed to validate the effectiveness of our analytical model using these experimental results. Utilizing the LSTM accelerator described earlier, we measured timing and power consumption to characterize a workload item, as listed in Table 2. We applied the optimal settings identified in Experiment 1 for the configuration phase. Note that the idle power consumption of 134.3 mW listed in Table 2 is specific to the Idle-Waiting strategy. Profiling other accelerators is also feasible, simply requiring an adjustment of the characteristics listed in Table 2 to align with the specific accelerator being used.\nUtilizing the simulator, we first estimated the number of executable workload items within an energy budget of 4147 J for request periods ranging from 10 to 120 ms, in increments of 0.01 ms. This range was chosen to align with"}, {"title": "5.4 Experiment 3: Optimization on the Idle-Waiting Strategy", "content": "In the final experiment, we aimed to improve the Idle-Waiting strategy by reducing idle power consumption, as proposed in Section 4.2. We evaluated these enhancements against the initial Idle-Waiting strategy (referred to as Baseline) from Section 5.3. We utilized the hardware setting described in Section 2 to assess the feasibility of these methods, and the results are detailed in Table 3."}, {"title": "6 Related Work", "content": "Recent research on DL accelerators on FPGAs has made significant progress, particularly in throughput and energy efficiency [9,10,12]. These studies typically focus on specialized hardware design and optimized inference phase to boost accelerator performance, primarily during continuous processing tasks, with the FPGA constantly active. However, these studies frequently neglect the overhead of FPGA configuration and related phases. For example, Chen et al. [3] focused on executing a single inference after a power failure, assuming that the FPGA is pre-configured before the power failure. Thus, they only need to optimize the performance of the accelerator in the inference phase. In practical scenarios, DL tasks typically demand a series of inferences, not just a single inference execution.\nSome researchers have started to address the impact of FPGA configuration overhead on efficiency. Fritzsch et al. [6] proposed a method to compress the bitstream by 1.05 to 12.2x to reduce configuration time, yet they did not explore its energy efficiency implications. Cichiwskyj et al. [5] introduced the concept of Temporal Accelerators, demonstrating that even with two reconfigurations, using a smaller FPGA (Spartan-7 XC7S6) is more energy-efficient than a larger one (Spartan-7 XC7S15) for a single inference execution. However, these studies did not integrate the configuration overhead with request period considerations for energy efficiency.\nOur study differs by aiming to enhance the energy efficiency of embedded DL systems through the lens of periodic workload requests. We adopted a dual-phase approach: firstly, we optimized configuration parameters to minimize overhead, and secondly, we employed idle power optimizations to maintain the FPGA powered on, thus avoiding repeated configurations."}, {"title": "7 Conclusion and Future Work", "content": "In conclusion, this study significantly reduced the configuration overhead of FPGA-based DL accelerators in IoT applications. By optimizing the FPGA configuration phase and introducing an effective Idle-Waiting strategy, we demonstrated substantial energy savings, thereby increasing the number of executable workload items. Our Idle-Waiting strategy effectively addresses the challenges of shorter request periods, a limitation of the traditional On-Off strategies. Combining the Idle-Waiting strategy with idle power-saving methods at a 40 ms request period, it achieves 12.39\u00d7 more workload items and system lifetime than the On-Off strategy.\nIn the future, we plan to extend our power-saving techniques beyond DL use cases to other periodic processes. Additionally, we aim to investigate methods for efficiently handling irregularly occurring inference requests, focusing on optimizing energy efficiency and system performance in more complex scenarios."}]}