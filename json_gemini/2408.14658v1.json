{"title": "KGPRUNE: a Web Application to Extract Subgraphs of Interest from Wikidata with Analogical Pruning", "authors": ["Pierre Monnin", "Cherif-Hassan Nousradine", "Lucas Jarnac", "Laurel Zuckerman", "Miguel Couceiro"], "abstract": "Knowledge graphs (KGs) have become ubiquitous publicly available knowledge sources, and are nowadays covering an ever increasing array of domains. However, not all knowledge represented is useful or pertaining when considering a new application or specific task. Also, due to their increasing size, handling large KGs in their entirety entails scalability issues. These two aspects asks for efficient methods to extract subgraphs of interest from existing KGs. To this aim, we introduce KGPRUNE, a Web Application that, given seed entities of interest and properties to traverse, extracts their neighboring subgraphs from Wikidata. To avoid topical drift, KGPRUNE relies on a frugal pruning algorithm based on analogical reasoning to only keep relevant neighbors while pruning irrelevant ones. The interest of KGPRUNE is illustrated by two concrete applications, namely, bootstrapping an enterprise KG and extracting knowledge related to looted artworks.", "sections": [{"title": "1 Introduction", "content": "Knowledge graphs (KGs) are structured representations that model the knowledge of one or several domains. Their atomic units are triples (h, p, o) that represent the existence of a relationship p between two entities h and o. With their flexibility and the knowledge they provide, KGs have become major assets that fuel various methods of artificial intelligence (e.g., retrieval augmented generation for large language models [19], machine learning in general [4]) with applications in a wide array of domains (e.g., search, e-commerce, social networks, life sciences [3, 9, 18]).\nIn the seminal spirit of the Semantic Web [1], existing KGs are often re-used for building new KGs or for supporting new tasks or applications [5, 7, 15, 22]. This is possible due to the increasing number and size of publicly available KGs\u00b9, and in particular of large KGs covering several domains such as Wikidata. The latter is a generic KG of more than 100 million nodes\u00b2 that supports Wikipedia [24]. Wikidata is considered as a premium source of knowledge but several issues hinder its reusage [10, 21]. First, its large size entails scalability issues when handling the graph (e.g., storage, query performance). Second, not all represented knowledge is relevant to the considered tasks or applications. For example, one of the neighboring entities of Microsoft SharePoint is Dating App which may not be of interest when building a enterprise KG modeling the IT domain.\nTo address such issues, several authors have proposed extracting subgraphs, either manually with some early examples dating back to 1996 [22] or automatically [11, 10, 21]. In particular, we recently proposed an approach that traverses the neighborhood of seed entities provided by users, keeping relevant neighbors while pruning irrelevant ones [11]. This approach relies on analogical inference and exhibits high performance, including in transfer settings, with a drastically low number of parameters.\nBuilding on this previous work, we propose KGPRUNE, a Web Application to extract subgraphs from Wikidata given seed entities and properties of interest to the user. KGPRUNE can be used both from a browser and programmatically through an API, allowing users with various technical expertise to interact with our pruning approach. In the following, after describing the features and technical architecture of KGPRUNE, we illustrate its interest with two concrete applications: the bootstrapping of an enterprise knowledge graph, and the extraction of knowledge related to looted artworks. A video of our demonstration is available on YouTube.4"}, {"title": "2 KGPRUNE: Extracting Subgraphs of Interest", "content": "The main screens of the KGPRUNE Web Application are presented in Figure 1. We describe below the main characteristics and steps for interacting with the application.\nSupporting KG. We chose to build KGPRUNE upon the Wikidata KG as it is large and generic, and thus can serve as a premium source of knowledge for several domains. However, it should be noted that our approach could be applied on any KG.\nInput files. KGPRUNE only requires as input from the user two CSV files, as illustrated in Table 1. The file qid_example.csv contains QIDs identifying seed entities of interest whose neighborhood will be retrieved. Here, as an example, we consider Microsoft SharePoint (Q18833) and the Java programing language (Q251). The file pid_example.csv contains PIDs identifying properties of interest whose edges will be traversed. Here, we consider instance of (P31), subclass of (P279), and part of (P361). Note that indicating the PID of a property leads to traversing direct edges whereas indicating (-)PID leads to traversing inverse edges. Here, both direct and inverse P279 edges will be traversed.\nSubgraph extraction. After input CSV files have been uploaded, KGPRUNE executes our traversal and pruning algorithm [11]\u00b3. Starting from seed entities, edges labeled by the specified properties are traversed. For each neighbor, our analogical pruning model decides either to keep or prune it. Analogies are statements of the form \"A is to B as C is to D\", modeled as quadruples A:B::C: Dsuch as Paris: France :: Berlin: Germany. Such quadruples capture similarities and dissimilarities between objects [16, 17]. Here, given a seed entity e specified by the user and one of its neighbors er, our model predicts whether they form an analogy with a seed entity ek and one of its neighbor ek for which a \"keep\u201d decision is known:\n\ne_k: e'_k :: e_s: e_r\n\nThis prediction relies on the pre-learned embeddings of the entities and the convolutional model for analogy detection introduced by Lim et al. [13]. With its architecture, the analogy-based model is able to capture relative similarities and dissimilarities between seed entities and their neighbors to keep or to prune, and thus is able to generalize to heterogeneous unseen entities. If our model predicts that they form an analogy, the known decision between ek and ek (i.e., keep e) is extrapolated to e. Otherwise, e is pruned. Note that the known decisions originate from one manually annotated dataset named dataset 1 that is publicly available.\nThis process is performed iteratively on the neighborhood of kept neighbors until no more neighbors can be reached. Results are then displayed to the user (Figure 1b) who can choose to visualize the extracted subgraphs (Figure 1c) or download them as JSON or RDF to be imported into a new KG. The visualization interface allows users to explore the neighborhoods of the seed entities, and assess the pruning results. In particular, users can notice in the UI if our model wrongfully pruned a neighbor of interest to the users, and add it to the seed entities to force its consideration. This lays the path towards an iterative pruning process in which users explore pruning results and provide feedback that is leveraged in the subsequent iterations.\nTechnical architecture. KGPRUNE relies on the technical architecture presented in Figure 2. Users can interact with the application via a Web browser or the provided API. Their subgraph extraction tasks are sent as SLURM jobs to our computing clusters where Wikidata adjacency and pre-trained embeddings, as well as our analogical pruning models are loaded and used in inference.\nFor learning Wikidata embeddings, we used the TransE [2] model with a dimension of 200. For the analogical model, we trained it us-ing using dataset1 among two manually annotated datasets publicly available. We use 16 filters on the first convolutional layer and 8 filters on the second convolutional layer.\nOur model achieves competitive performance compared to the main models of the state of the art, with a drastically lower number of parameters and a superior generalization capability in a transfer setting."}, {"title": "3 Illustrative Use Cases", "content": "To showcase the impact of KGPRUNE, we experimented on two use cases, namely, enterprise KG bootstrapping and extracting subgraphs related to looted artworks, allowing us to attest the usefulness of our tool on distinct real-world applications.\nBootstrapping an Enterprise Knowledge Graph (EKG). Building a new KG requires its bootstrapping with a high quality nucleus that can then support automatic knowledge extraction approaches from structured or unstructured data (e.g., tables, texts) [14, 20, 25]. Indeed, these approaches then enrich the KG while being guided by the terms and relations the KG provides, forming a virtuous loop.\nTo build such a nucleus, several authors rely on Wikidata. To limit the size of the created nucleus, they select parts of the neighborhood of seed entities of interest with a distillation [21] or a pruning process [10, 11]. Their traversal of the graph focuses on the ontology hierarchy, only upward [21] or both upward and downward [10].\nIn [11], we proposed our pruning approach to bootstrap an EKG focused on the IT domain, traversing the ontology upward and downward starting from seed entities of interest available in the company internal glossary. The competitive performance with low complexity obtained by our approach illustrates its interest for this use case. With KGPRUNE, we extended our previous approach by allowing the user to define the properties to traverse, enriching the\nExtracting Subgraphs Related to Looted Artworks. Art looting networks operate on many hidden levels over long periods of time. Some agencies emphasize that it is a criminal industry grossing in the billions annually. Reliable documentation is of utmost importance to finding lost or stolen cultural property, and to establishing rightful ownership. This is however a challenging task [8] since \"the data on cultural heritage is locked up in data silos making it exceptionally difficult to search, locate, and obtain reliable documentation\".\nThe authors of [8] propose the use of Linked Open Data (LOD) as a global database on cultural heritage, and explored the potential of LOD to integrate large quantities of cultural heritage data to facilitate access to information in this domain. In turn, this could help to protect cultural property from looting, as well as track looted artworks [27, 26]. However, stolen art tracking involves knowledge pertaining to artworks, genealogy, ownership, provenance, some of which is present in generic KGs together with irrelevant knowledge to the present task (e.g., biology, computer science). For example, Wikidata contains 43,730 art dealers, collectors, curators, and galleries; 6,648 art museums; 930,405 paintings; 251 persons investigated by the Art Looting Investigation Unit'; and properties such as owner of and owned by. Hence, the need to extract specific subgraphs addressing relevent themes while avoiding false, inaccurate, or irrelevant information.\nIn this view, KGPRUNE has the potential to extract and collect trustworthy and pertinent information from Wikidata. In preliminary experiments, we applied our approach on the neighborhood of known artworks (e.g. Cypresses), artists (e.g., Alexej von Jawlensky), museums (e.g, National Gallery of Arts), and art dealers (e.g., Alfred Flechtheim). Results showed good alignment with human needs when detecting neighbors relevant to information needed for tracking stolen art. We are in the process of exploring further how KGPRUNE, and especially its pruning and visualization features, can support other use cases related to cultural heritage."}, {"title": "4 Conclusion and Perspectives", "content": "In this paper, we presented KGPRUNE, a Web Application allowing users to extract subgraphs of interest from Wikidata by providing seed entities of interest and properties to traverse. Our application prevents potential topical drift when traversing the graph by relying on an efficient analogy-based pruning mechanism. Users can interact with KGPRUNE via a Web browser and an API, which enables its to seamless integration in various working pipelines. We demonstrated the interest of the application with two concrete use cases.\nAt present, KGPRUNE only supports Wikidata. In the future, we envision to integrate additional KGs (e.g., DBpedia [12], YAGO [23], Bio2RDF [6]) providing users an enhanced context from which extract subgraphs. Additionally, our analogy-based model is trained on a manually annotated dataset of seed entities and neighbors to keep or prune. Even if experiments and use cases highlighted the generalization capability of our model, it may be possible that the definition of kept and pruned neighbors learned does not apply well to other applications. To address this question, we plan on allowing users to provide their own examples of kept and pruned neighbors. These examples could be used in the inference phase or even to train tailored models on-the-fly, given the reduced complexity of our models."}]}