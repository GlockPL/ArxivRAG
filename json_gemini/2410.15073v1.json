{"title": "Personalized Federated Learning with Adaptive Feature Aggregation and Knowledge Transfer", "authors": ["Keting Yin", "Jiayi Mao"], "abstract": "Federated Learning(FL) is popular as a privacy-preserving machine learning paradigm for generating a single model on decentralized data. However, statistical heterogeneity poses a significant challenge for FL. As a subfield of FL, personalized FL (pFL) has attracted attention for its ability to achieve personalized models that perform well on non-independent and identically distributed (Non-IID) data. However, existing pFL methods are limited in terms of leveraging the global model's knowledge to enhance generalization while achieving personalization on local data. To address this, we proposed a new method personalized Federated learning with Adaptive Feature Aggregation and Knowledge Transfer (FedAFK), to train better feature extractors while balancing generalization and personalization for participating clients, which improves the performance of personalized models on Non-IID data. We conduct extensive experiments on three datasets in two widely-used heterogeneous settings and show the superior performance of our proposed method over thirteen state-of-the-art baselines.", "sections": [{"title": "1\nINTRODUCTION", "content": "In recent years, many learning tasks, such as financial fraud detection [2, 6], benefit from deep neural networks. To achieve satisfactory performance, model training requires vast amounts of data [20, 22]. However, in many scenarios, it is costly for a single entity to obtain enough data, especially when data is considered a valuable asset. Moreover, due to privacy concerns, the collection and central storage of data are often prohibited [9, 38]. Federated learning (FL), as a paradigm of collaborative learning, enables model training among distributed clients without accessing the raw data [27, 34, 46, 48]. A typical federated learning process involves three main steps. First, the server selects a subset of clients in each round and distributes the global model to them. The selected clients then initialize their local models with the global model, update them using their local datasets, and send the updated models back to the server. Finally, the server aggregates the received local models to obtain a new global model, repeating this process until convergence.The aforementioned federated algorithm demonstrates excellent performance when data is independent and identically distributed (IID). However, in practice, data distributed across various clients is heterogeneous (non-independent and identically distributed, Non-IID) and unbalanced, making it challenging to learn a global model that meets the needs of all clients [24, 34, 41, 54].To tackle with data heterogeneity, many researchers have focused on personalized federated learning (pFL). pFL aims to learn personalized models for each client rather than a single global model, treating data heterogeneity, which is typically seen as a limitation, as an advantage. Many methods have been applied to pFL:(1) Fine-tuning-based methods, e.g., FedAvg+Fine-tuning and PerFedAvg [11], (2) Regularization-based methods, e.g., pFedMe [41], and Ditto [26], (3) Clustering-based methods, e.g., ClusterFL [36], (4) Model-splitting-based methods, e.g., FedPer [3], FedRep [8], FedROD [5], and FedBABU [35], (5) Personalized-aggregation-based methods, e.g., APFL [10], FedFomo [52], FedAMP [15], FedPHP [30], and FedALA [50]. In addition, many other algorithms for pFL have been proposed. Refer to [21, 42] for more details.Methods in (1), (2), and (3) typically initialize the local model with the global model, such as replacing the local model's parameters with those of the global model. These approaches introduce both relevant and irrelevant information into the local model, enhancing generalization but significantly reducing personalization. Methods in (4) decouples the model into a feature extractor (a.k.a, the body) and a classifier head(a.k.a, the header). The feature extractor is responsible for extracting low-dimensional feature representations (a.k.a, feature embeddings) from the raw data, while the classifier head outputs classification results. In deep learning, learning a good feature extractor has been demonstrated to be crucial [4, 8]. However, current model-splitting-based methods do not fully leverage the knowledge gained during training to facilitate the transfer of useful knowledge, leading to limited performance improvements.Methods in (5) aims to obtain desired information from the global model or other clients' models during local aggregation [13]. However, when the data distribution varies greatly, the adjustment of the personalization strategy can lead to fluctuations in the model performance. Additionally, this method may introduce extra system components, which incurs computation and communication overhead.To address the aforementioned shortcomings, we propose the personalized Federated learning with Adaptive Feature Aggregation and Knowledge Transfer (FedAFK) to improve the performance of personalized models on Non-IID data. FedAFK consists of three simple but effective designs: model decoupling, knowledge transfer, and adaptive feature aggregation. During communication between the server and clients, only the feature extractor of the global model is transmitted, which reducing communication overhead through model decoupling. A term is incorporated into the training objective of the local feature extractor to transfer the knowledge contained in the global feature representation, enabling a better balance between the generalization of the classes across all data and personalization of the classes across local data. While training the global feature extractor and the local feature extractor, an aggregation coefficient \u03bc is also learned. u is used to explore the optimal combination of the two feature extractors, aiming to achieve better feature representation.To evaluate the effectiveness of FedAFK, we conduct extensive experiments on three datasets in both pathological and practical settings. FedAFK outperforms thirteen state-of-the-art (SOTA) PFL methods. We summarize our contribution below:\u2022\tWe propose a novel pFL method FedAFK that adaptively aggregates the global feature extractor and the local feature extractor to enhance personalized model performance on Non-IID data by achieving better feature representation.\u2022\tWithin FedAFK, we transfer the global knowledge contained in representation to the local feature extractor, enabling a better balance between the generalization and the personalization.\u2022\tWe conduct extensive experiments on three datasets in two widely-used scenarios to show the effectiveness of FedAFK, which outperforms thirteen SOTA PFL methods in test accuracy without incurring additional communication overhead per round."}, {"title": "2\nRELATED WORK", "content": "2.1\nFederated Learning with Data Heterogeneity\nAs the standard algorithm in Federated Learning, FedAvg [34] enables distributed clients to collaboratively learn a global model by aggregating their local models without accessing the raw data. However, FedAvg struggles to maintain robustness in heterogeneous FL settings [16, 53, 55]. Several methods are proposed to improve the global model learning. FedProx [28] introduces a regularization term to the local training objective to maintain the stability of the learning process. SCAFFOLD [18] corrects local update drift with control variates. Moon [25] introduces a contrastive loss, which reduces the distance between the local model and the global model while increasing the distance between the current local model and the previous local model, thereby correcting the update direction of the local model. FedNova [45] redefines server-side weighting rules to eliminate target inconsistency and accelerate convergence.\n2.2\nPersonalized Federated Learning\nPersonalized Federated Learning has emerged recently for tackling data heterogeneity [1, 7, 16, 32, 33, 40, 44], which enables each client to have a customized model while benefiting from the federation.Fine-tuning. As the name suggests, FedAvg+Fine-tuning enables clients to fine-tuning their model locally after completing the FedAvg process. Based on MAML [12], Per-FedAvg [11] trains an initial model, and then each client performs several training steps on local data to obtain a personalized model.Regularization. pFedMe [41] leverages Moreau envelopes to learn an additional personalized model for each client. Similar to pFedme, Ditto [26] trains additional personalized models with a proximal term to learn knowledge from the downloaded global model.Clustering. ClusterFL [36] divides clients into different groups, where each group's clients have similar data distributions. This way, each group can perform more effective model aggregation within the group, thereby enhancing the performance of personalized models.Model-splitting. FedPer [3] and FedRep [8] split the model backbone into a feature extractor and a classifier head. The feature extractor is shared through the server to learn generalizable knowledge, and the classifier head is used to fit local data and output classification results [17, 43]. In FedROD [5], each client has a feature extractor and two classifier heads, enabling learning of both global and personalized tasks using separate heads. FedBABU [35] updates only the model's body during training, with the classifier head being randomly initialized and fine-tuned only during evaluation.Personalized aggregation. APFL [10] uses an adaptive weight to mix up the global and local model. This idea is similar to ours, but our method focuses on aggregating the parameters of the feature extractor rather than all model parameters, which enhances the personalization of layers closer to the output. FedFomo [52] enables each client to download other clients' models and calculates the client-specific weights for personalized aggregation. FedAMP [15] uses an attention-inducing function to strengthen collaboration between similar clients. FedPHP [30] aggregates the global model and the inherited private model linearly with a pre-defined hyper-parameter. FedALA [50] conducts finer-grained model aggregation on the client side compared to APFL.Other methods. FedBN [29] proposes a strategy for using batch normalization (BN) in the FL scenario to address the feature shift problem, while also leveraging BN to accelerate training process. FedCP [51] focuses on the data, generating a conditional policy for each sample to separate the global information and personalized information in its features."}, {"title": "3\nPROBLEM STATEMENT", "content": "Suppose we have a central server and n clients to collaboratively train personalized models without sharing raw data. For all clients, our training objective is:\nmin\\((W_1,..., W_n) \\in W\\) F(W) := 1/n \u2211\u1d62\u208c\u2081\u207f f\u1d62(W\u1d62) (1)\nwhere W is the collection of all personalized models. f\u1d62(w\u1d62) is the local objective for the i-th client:\nf\u1d62(w\u1d62) := E\\((x\u1d62,y\u1d62) \u2208 D\u1d62\\)l(w\u1d62; x\u1d62, y\u1d62) (2)\nwhere D\u1d62 is the data distribution and l(w\u1d62; x\u1d62, y\u1d62) denotes the loss, e.g., the cross-entropy loss, of the prediction on example (x\u1d62, y\u1d62) made with model parameters w\u1d62."}, {"title": "4\nMETHOD", "content": "4.1\nAdaptive Feature Aggregation\nSimilar to FedPer [3] and FedRep [8], we decouple the deep neural network into the feature representation layers and the final decision layer [47, 49, 56]. The feature representation layers, also known as the feature extractor f : \\(R^D\\) \u2192 \\(R^K\\), where \\(R^D\\) and \\(R^K\\) are the input space and low-dimensional feature space, respectively. In classification tasks, the final decision layer, referred to as the classifier head g: \\(R^K\\) \u2192 \\(R^C\\), where \\(R^C\\) is the label space. D, K and C are the dimension of their respective layers. Typically, D is much larger than K, and K is determined by the given model framework.In FedAFK, we have a global feature extractor(parameterized by \\(\u03b8_G\\)), a local feature extractor(parameterized by \\(\u03b8_i\\)) and a local classifier head(parameterized by \\(\u03c6_i\\)), where the subscript i denotes the client's id. To enhance the representation ability of the feature extractor, which serves as a common structure and has been shown to significantly improve personalized models [4, 8], we introduce a learnable weight coefficient \u00b5\u1d62. We use \u00b5\u1d62 to compute the personalized feature extractor, aiming to achieve the optimal mixture of the local feature extractor and the global feature extractor:\n\u03b8\u1d62 = \u00b5\u1d62\u03b8\u1d62 + (1 \u2013 \u00b5\u1d62)\u03b8G (3)\nFor local training at the t-th communication round, we alternately learn the feature extractors and the classifier head. Specifically, after receiving the global feature extractor \\(\u03b8_G^{t-1}\\) from the central server, we perform stochastic gradient decent to train models:\u2022 Freeze \\(\u03c6_i\\), Update \\(\u03b8_G\\) and \\(\u03b8_i\\) For the global model, we equip \u03b8G with a fixed random classifier head \\(\u03a6_{rd}\\) and update it. For the personalized model, we freeze the classifier head and update \u03b8\u1d62 with a combined loss \\(l_{total}\\) that integrates knowledge transfer, which will be explained in Section 4.2:\n\\(\u03b8_G^t \\leftarrow \u03b8_G^{t-1} - \u03b7\u2207_{\u03b8_G}l_{sup}(\u03b8_G^{t-1}, \u03a6_{rd}; D_i)\\) (4)\n\\(\u03b8_i^t \\leftarrow \u03b8_i^{t-1} - \u03b7\u2207_{\u03b8_i}l_{total}(\u03b8_i^{t-1}, \u03c6_i^{t-1}, \u03b8_G^{t-1}; D_i)\\) (5)\n\\(\u03bc_i^t \\leftarrow \u03bc_i^{t-1} - \u03b7\u2207_{\u03bc_i}l_{total}(\u03b8_i^{t-1}, \u03c6_i^{t-1}, \u03b8_G^{t-1}; D_i)\\) (6)\nwhere \u03b7 denotes the learning rate for updating, and \\(l_{sup}\\) is the supervised loss, e.g., the cross-entropy loss.\u2022 Freeze New \u03b8\u1d62, Update \\(\u03c6_i\\) After getting the new personalized feature extractor, we train the classifier head for one epoch:\n\\(\u03c6_i^t \\leftarrow \u03c6_i^{t-1} - \u03b7\u2207_{\u03c6_i}l_{sup}(\u03b8_i^{t}, \u03c6_i^{t-1}; D_i)\\) (7)\nWith the adaptive weight \u00b5\u1d62, we can find the find the optimal mixture of the local feature extractor and the global feature extractor, to obtain a better client-specific feature extractor, i.e., the personalized feature extractor. On one hand, the personalized feature extractor fuses the global feature extractor and the local feature extractor to achieve improved feature representation. On the other hand, this fusion also mitigates the risk of local over-fitting. When validating the performance of the personalized model, we perform inference using \\(w_i = {\u03b8_i, \u03c6_i}\\).\n4.2\nKnowledge Transfer\nIntuitively, a superior local feature extractor enhances effective adaptive feature aggregation. Therefore, we introduce an additional term in the loss function during the training of the local feature extractor to transfer the knowledge contained in the outputs of the global feature extractor, i.e., the global feature representation. This transfer helps achieve a better balance between generalization and personalization.\n\\(l_{kt}(\u03b8_i, \u03b8_G) = D_{KL}(f_{\u03b8_i}(D_i)||f_{\u03b8_G}(D_i))\\) (8)\nwhere \\(D_{KL}\\) refers to the KL-divergence, and f(D\u1d62) denotes the feature representation on local data. The total loss \\(l_{total}\\) is defined as:\n\\(l_{total} = (1 \u2013 \u03bb)l_{sup} + \u03bbl_{kt}\\) (9)\nwhere the coefficient \u03bb is the hyperparameter for knowledge transfer.It is worth mentioning that, in terms of learning global knowledge, incorporating knowledge transfer during the training of the local feature extractor seems to overlap with adaptive feature aggregation. To emphasize learning personalized knowledge from local data while maintaining the generalization, we select a reasonable \u03bb to mitigate this \"redundancy\" and strike a balance.\n4.3\nWorkflow and Algorithm\nAs illustrated in Figure 1, the workflow of FedAFK includes the following steps:(1)\tThe server first broadcasts the aggregated global feature extractor to selected clients.(2)\tClient i receives the global feature extractor and equips it with a fixed classifier head. Then, client i trains the global feature extractor with supervised loss on the local dataset.(3)\tClient i calculates \\(D_{KL}\\) as the knowledge transfer loss, defined as the KL divergence between the feature representations obtained from the global and local feature extractors. Then, client i trains the local feature extractor with knowledge transfer loss and supervised loss on the local dataset.(4)\tClient i trains the weight coefficient \u00b5\u1d62 and aggregates the global and local feature extractors accordingly.(5)\tClient i trains the local classifier head with supervised loss on the local dataset.(6)\tThe updated local feature extractor and classifier head are combined to form a personalized model for inference, which also serves as the local model for the next round of training.(7)\tClient i uploads the updated global feature extractor to the server.(8)\tFollowing FedAvg, the server aggregates the received global feature extractors to produce the global feature extractor for the next round.The above steps are repeated until convergence. The detailed algorithm is presented in Algorithm 1.\n4.4\nDiscussion\nIn this subsection, we discuss FedAFK from three perspectives: communication efficiency and privacy preserving, computation overhead, and model inference.Communication Efficiency and Privacy Preserving. Our proposed FedAFK transmits only the parameters of the global feature extractor between the server and clients, rather than the entire set of model parameters. This reduction in parameter transmission not only decreases communication overhead but also enhances privacy in federated learning. In deep learning, the feature extractor serves as a foundational component, while the classification head is highly task-specific [47]. By sharing only the feature extractor, we can more effectively safeguard user privacy. Additionally, privacy-preserving techniques such as differential privacy can be integrated into FedAFK to further enhance the system's reliability.Computation Overhead. For clients, our proposed FedAFK introduces three additional computation overhead compared to FedAvg [34]: computing the knowledge transfer loss, updating the personalized model, and calculating the adaptive weight coefficient. In cross-silo scenarios, these costs are tolerable in order to achieve a well-performing personalized model. On the server side, FedAFK only aggregates the updated feature extractors from clients, which helps reduce computation overhead."}, {"title": "5\nEXPERIMENTS", "content": "5.1\nExperimental Setup\nDatasets and models. To evaluate our proposed FedAFK, we consider image classification tasks and utilize three popular benchmark datasets: MNIST [23], Cifar-10 and Cifar-100 [19]. We consider a multi-layer CNN for both MNIST and Cifar-10, and ResNet18 [14] for Cifar-100. The CNN consists of two convolutional layers and two fully connected layers, and the ResNet18 model used is not pre-trained.Data Partitioning. Following FedALA [50], we simulate the Non-IID settings with two typical scenarios, i.e., the pathological heterogeneous setting [34, 39] and the practical heterogeneous setting [25, 31]. For the pathological setting, we sample data with label amount 2/2/10 for each client on MNIST/Cifar-10/Cifar-100 from a total of 10/10/100 categories, with disjoint data and unbalanced data samples. For the practical setting, we use the Dirichlet function, denoted as Dir(\u03b2), to sample data. A smaller \u1e9e indicates a higher degree of heterogeneity in the data and we set \u03b2 = 0.1 by default.On each client, we divide the data into 75% and 25% to form the training dataset and test dataset, respectively.Comparison Baselines. To show the superiority of our proposed FedAFK, we compare it with thirteen SOTA FL baselines including FedAvg [34], FedProx [28], Per-FedAvg [11], pFedMe [41], FedAMP [15], Ditto [26], FedPer [3], FedRep [8], FedROD [5], Fed-Fomo [52], APFL [10], FedPHP [30], and FedALA [50].Implementation Details. We implement FedAFK using Py-Torch 1.8 [37] and conduct experiments on a server equipped with an Intel Xeon Gold 5118 CPU, 96G memory and a NVIDIA RTX A4000 GPU. Following FedAvg [34], we set the local batch size to 10 and the local training epochs to E = 1. We set the number of communication rounds to T = 1000 to ensure that all methods empirically converge. Following pFedMe [41], FedFomo [52], and FedALA [50], we set the number of clients to n = 20 and the client participation ratio to p = 1. We report the test accuracy of the best global model for traditional FL methods and the average test accuracy of the best local models for personalized FL methods.\n5.2\nEffect of Hyperparameters\nWe vary the values of A to simulate different levels of knowledge transfer. We evaluate the Cifar-100 dataset in the practical heterogeneous setting and report the results in Table 1. Choosing a reasonable A can effectively balance the personalization and generalization of the model. FedAFK achieves excellent performance when \u03bb = 0.3. When \u03bb < 0.3, the test accuracy decreases due to reduced absorption of global knowledge by the personalized model. Conversely, a larger \u03bb leads to excessive alignment of the personalized model with the global model, thereby diminishing its personalization. Hence, we set \u03bb = 0.3 for FedAFK.Additionally, we evaluate our proposed FedAFK with various initial value of \u00b5. As shown in Table 2, when \u00b5 \u2264 0.7, a relatively high test accuracy is achieved, with the highest accuracy occurring at \u00b5 = 0.5. This occurs because, during training, u can be adaptively adjusted to obtain an optimal combination of the global feature extractor and local feature extractors. When u > 0.7, the test accuracy drops significantly, indicating that an excessively large initial value causes severe client-drift[18] in the early stages, making it difficult to correct later. Therefore, we set the initial value of u to 0.5 for the subsequent experiments.\n5.3\nPerformance Comparison\nThe main experimental results are presented in Table 3, it is obvious that our proposed method FedAFK obtains the best performances in both pathological heterogeneous setting and practical heterogeneous setting, demonstrating the effectiveness and benefits of adaptive feature aggregation and knowledge transfer. In tasks that are relatively challenging, FedAFK demonstrates significant advantages. In the following, we compare FedAFK with baselines and analyze why FedAFK outperforms all baselines.The poor performance of traditional FL methods, namely FedAvg and FedProx, can be attributed to their objective of training a global model without incorporating personalized information from the features. In contrast, FedAFK effectively balances both generalization and personalization, providing each client with a personalized model.Among pFL methods, Per-FedAvg performs poorly because it aggregates a global learning trend for all clients, which does not align with the individual learning trends of each client. In contrast, FedAFK learns a personalized feature extractor for each client through adaptive feature aggregation to align with local learning trends.pFedMe, FedAMP, and Ditto all introduce regularization terms to enable local models to learn specific knowledge for enhancing personalization capabilities. Among them, pFedMe learns knowledge from the local model, FedAMP learns from a client-specific server model, and Ditto learns from the global model. Due to the more generic knowledge learned by Ditto, it performs better. Given the effectiveness of this \"knowledge transfer\" strategy, FedAFK also employs it. Unlike the aforementioned three methods, FedAFK transfers knowledge from feature representations rather than model parameters, which is more direct and effective.FedPer, FedRep, and FedROD all decouple their model. The former two only share the feature extractor while keeping the classifier head locally, thus preserving global knowledge but being somewhat coarse. FedROD learns two heads with two objectives, however, the two objectives are competing, which adversely affects the pFL task. FedAFK, with a focus on the pFL task, naturally introduces global information through adaptive feature aggregation and knowledge transfer, thus achieving the best performance.FedFomo aggregates local models using client-specific weights, which results in the loss of some global knowledge. APFL aggregates the entire model through adaptive weights, maintaining both a local model and a mixed model locally, which incurs additional storage costs. Similar to APFL, our proposed FedAFK also has an adaptive weight coefficient u, but we only maintain one personalized model locally and use u to aggregate the feature extractor. Our goal is to obtain an effective feature extractor to assist in building personalized models, rather than directly acquiring personalized models like APFL. FedPHP defines an aggregation parameter that varies with the number of selections and communication rounds, which is insufficient for capturing the connection between the global model and the local models. FedALA provides a more fine-grained model aggregation, but we have found that it is highly sensitive to training hyperparameters.\n5.4\nComputation Overhead\nWe record the mean computation time of all clients in one round on Cifar-100 in the pathological setting, as shown in Table 4. Our proposed method FedAFK outperforms pFedMe, Ditto and FedRep in terms of computation overhead. However, compared to most pFL methods, e.g., Per-FedAvg, FedAMP, FedPer, FedROD, FedFomo, APFL, FedPHP, and FedALA, FedAFK incurs higher computation costs in each communication round due to the additional training of local models. Therefore, FedAFK is more suitable for clients with relatively sufficient computation power, e.g., enterprises, in cross-silo FL scenarios.\n5.5\nCommunication Overhead\nIn Table 4, we also show the communication overhead for one client in one communication round. The communication overhead of the vast majority of FL methods is the same as FedAvg, which uploads and downloads the complete model parameters. FedFomo incurs the highest communication overhead, because it downloads C client models in each round, with C set to 20 in our experiments. Similar to FedPer and FedRep, our proposed method FedAFK only transmits the feature extractor and keeps the classifier head locally, resulting in reduced communication overhead.\n5.6\nAblation Studies\nWe have two key design components in FedAFK, i.e., adaptive feature aggregation(AFA) and knowledge transfer(KT). To show the effectiveness, we conduct ablation experiments with the following four cases(\"w/o\" is short for \"without\"): (a) w/o AFA, (b) w/o KT, (c) w/o both AFA and KT: since we use local models for inference, FedAFK turns into Standalone,i.e., each client trains its model solely, (d) the complete FedAFK approach. We report the test accuracy of the four ablation cases in Table 5.As demonstrated in Table 5, both adaptive feature aggregation and knowledge transfer can help improve the test accuracy and the complete FedAFK approach achieves the highest test accuracy. This indicates that our proposed method effectively trains a better personalized feature extractor while balancing generalization and personalization. It is worth noting that, in tasks that are relatively challenging(such as training resnet on Cifar100), the absence of any single design results in a noticeable decrease in test accuracy compared to the complete FedAFK, which indicates that adaptive feature aggregation and knowledge transfer can mutually facilitate each other."}, {"title": "6\nCONCLUSION AND FUTURE WORK", "content": "In this paper, we propose a novel personalized federated learning method FedAFK, which addresses challenging FL scenarios with statistical heterogeneity. To enhance the representational capability of the feature extractor, FedAFK transfers the global knowledge to the local feature extractor and adaptively aggregates the global feature extractor and the local feature extractor as the personalized feature extractor. Through extensive experiments, we demonstrate that FedAFK outperforms thirteen SOTA methods. As future work, we plan to further improve FedAFK in more complex settings, e.g., clients with dynamic data distribution."}]}