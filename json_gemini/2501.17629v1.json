{"title": "The Imitation Game According To Turing", "authors": ["Sharon Temtsin", "Diane Proudfoot", "David Kaber", "Christoph Bartneck"], "abstract": "The current cycle of hype and anxiety concerning the benefits and risks to human society of\nArtificial Intelligence is fuelled, not only by the increasing use of generative AI and other AI tools\nby the general public, but also by claims made on behalf of such technology by popularizers and\nscientists. In particular, recent studies have claimed that Large Language Models (LLMs) can pass\nthe Turing Test\u2014a goal for AI since the 1950s\u2014and therefore can \u201cthink\u201d. Large-scale impacts on\nsociety have been predicted as a result. Upon detailed examination, however, none of these studies\nhas faithfully applied Turing's original instructions. Consequently, we conducted a rigorous Turing\nTest with GPT-4-Turbo that adhered closely to Turing's instructions for a three-player imitation\ngame. We followed established scientific standards where Turing's instructions were ambiguous or\nmissing. For example, we performed a Computer-Imitates-Human Game (CIHG) without\nconstraining the time duration and conducted a Man-Imitates-Woman Game (MIWG) as a\nbenchmark. All but one participant correctly identified the LLM, showing that one of today's most\nadvanced LLMs is unable to pass a rigorous Turing Test. We conclude that recent extravagant claims\nfor such models are unsupported, and do not warrant either optimism or concern about the social\nimpact of thinking machines.", "sections": [{"title": "1 Introduction", "content": "In 1950, Alan Turing described an \u201cimitation game' that, he proposed, provided a \u201ccriterion for\n\u2018thinking\u201d: if an imaginable digital computer does well in this game, it can think (Turing 1950).\nSince Turing introduced the imitation game, there have been numerous efforts to build machines\nthat could pass the test, as well as several Turing-style test methodologies. Interest in the imitation\ngame has extended beyond the scientific community; events and reports of machines attempting to\npass the test have captured the general public's interest. Recently, several studies have been released\nclaiming to show that some Large Language Models (LLM) can pass Turing's test\u2014and therefore\nare intelligent. This has been widely reported in news and magazine articles (CNN, 2014; Veselov,\n2014; Boyle, 2016; Oremus, 2022; Oremus, 2023; Cuthbertson, 2023; Toews, 2024). However,\nalthough many researchers claim to have conducted Turing's Test, to the best of our knowledge, no"}, {"title": "1.1 Which imitation game?", "content": "Turing described three different versions of the imitation game (Copeland, 2000). He first introduced\na restricted chess-playing version in his 1948 report (Turing, 1948). In 1950, Turing introduced a\nsecond version, the three-player imitation game (Turing, 1950). This is the game that is commonly\nreferred to when talking about the Turing test. According to Turing, the three players include: A, B,\nand C. For clarity, we designate A and B as Contestants and C as an Interrogator. The Interrogator\nis situated in a separate room with no means of interaction with the Contestants except through text-\nbased communication. During the game, the Interrogator addresses messages to Contestants, labeled\nX and Y, simultaneously. The objective of each role is as follows: A's goal is to convince the\nInterrogator to make an incorrect identification, while B aims to help the Interrogator make the\ncorrect identification. The game ends when the Interrogator decides on the identity of the\nContestants: the Interrogator's objective is to match the Contestants to the labels X and Y: \u201cat the\nend of the game he says either \u2018X is A and Y is B' or \u2018X is B and Y is A'.\u201d (Turing, 1950, p. 433).\nTuring introduced the game using the example of a Man-Imitates-Woman Game (MIWG)\n(Turing, 1950). In this scenario, A is a man and B is a woman. The Interrogator can be of either sex.\nThe man is labeled X and the woman is labeled Y, unbeknown to the Interrogator. The objective of\nthe man is to convince the Interrogator that he is a woman, while the woman aims to assist the\nInterrogator in his/her task. The objective of the Interrogator is to correctly match the labels with\nthe corresponding sexes, by stating either \u201cX is a man and Y is a woman\u201d (correct identification) or\n\u201cX is a woman and Y is a man\u201d (incorrect identification).\nExtending the imitation game, Turing transformed the question \u201cCan machines think?\u201d into an\nunambiguous formulation consisting of two questions: \u201cWhat will happen when a machine takes\nthe part of A in this game?\u201d and \u201cWill the Interrogator decide wrongly as often when the game is\nplayed like this as he does when the game is played between a man and a woman?\u201d (Turing, 1950,\np. 434). These questions suggest playing a Machine-Imitates-Human Game (MIHG) using a\nmachine in the role of A and a human in the role of B. The machine's success is determined by the\nresults of both the MIHG and the MIWG (Turing, 1950). Here we follow the Copeland interpretation\nof the protocol for scoring the imitation game (Copeland, 2000, 2023). Each game ends with a score\nfor the performance of the Interrogator. The machine passes the test if the performance of the\nInterrogator in the MIHG is no better than the performance of the Interrogator in the MIWG. Turing\npredicted that a digital computer could succeed in the game (Turing, 1950) at some point in the\nfuture. It is important to note that Turing changed from using the term \u201cmachine\u201d to the term \u201cdigital\ncomputer\". Today, we are unlikely to consider a machine that is not a computer for this task, and\nhence we will refer to the MIHG as the Computer-Imitates-Human Game (CIHG) (there is no\nrequirement that the computer be digital)."}, {"title": "1.2 Context", "content": "Efforts to develop a text-based conversational agent began in 1966, starting with ELIZA, a program\ncapable of conducting text-based psychotherapy-type conversations with humans (Weizenbaum,\n1966). In 1972, Parry, a \u201cparanoid\u201d conversational agent, was the first chatbot to participate in a\nTuring-like test, where physicians were asked to determine whether a transcript was of a\nconversation with a human or with a chatbot\u2014a task they found difficult (Colby et al., 1972).\nIn 1991, Hugh Loebner inspired conversational agent developers by establishing an annual\ncompetition known as the Loebner Prize Competition (Epstein, 1992). Initially, the contest adopted\nthe format of the two-player imitation game. The competition awarded a bronze medal and a cash\nprize of a few thousand dollars for the best human imitation skills demonstrated by a computer. The\njury was restricted to challenging the conversational partner solely on one topic, which was chosen\nby the partner. Moreover, each juror had to rank the respondents based on their human imitation\nskills instead of simply identifying them. A grand prize of $100,000 was to be awarded for passing\nthe two-player test (Epstein, 1992). Since 1994, in addition to the bronze medal, competitors have\ncompeted for silver and gold medals (Powers, 1998; Loebner, 2009). The silver medal carries a prize\nof $25,000 and is awarded to a computer that manages to convince 50% of a jury that it was chatting\nwith a human. The machine that can pass a version of the \u201cTotal Turing Test\u201d (TTT) receives a gold\nmedal and a prize of $100,000. The organizers changed the requirement for winning the grand prize\n(gold medal) from passing the Turing Test to passing the TTT because some chatbots participating\nin the contest showed considerable progress in the game without demonstrating any actual capacity\nfor thinking (Epstein, 1992; Powers, 1998). Moreover, the organizers believed that, to do well in the\nimitation game, a computer should have sensory experience of the world (Powers, 1998). The TTT\nrequires robotic embodiment, on the assumption that a thinking machine cannot exist without a body\n(Harnad, 1989). The Truly Total Turing Test (TTTT) (Schweizer, 1998) extends the TTT with a\nfurther requirement: the machine must develop human capabilities autonomously. We are not aware\nof any current state-of-the-art technology that can pass any of these tests. Since 2004, the Loebner\nPrize competition has adopted the three-player imitation game format. The last competition was\nheld in 2019 (Jones and Bergen, 2024a).\nIn 2014, the University of Reading organized a Turing Test competition to commemorate the\n60th anniversary of Turing's death. In the end, the organizers announced that the \u201cEugene Goostman\u201d\nchatbot finally \u201cpassed\u201d the Turing Test (Warwick and Shah, 2015). This announcement was based\non Turing's prediction that \u201cin about fifty years time an average Interrogator will not have more\nthan a 70% chance of making the correct identification after 5 minutes of questioning\u201d (Turing,\n1950, p. 442). However, this was a misinterpretation of Turing's prediction as the protocol for\nscoring the game (Copeland, 2014). The developers also modeled the chatbot based on a 13-year-\nold Ukrainian boy. This characterization may have elicited a greater tolerance among the jury\nregarding the chatbot's limited communication capabilities (Copeland, 2014).\nThe next notable attempt to conduct the two-player imitation game occurred online in October\n2023 (Jones and Bergen, 2024a). This study compared the performance of different LLMs from a\nfamily of GPT algorithms, such as GPT-4 and GPT-3.5. The study explored different prompts and\nLLM parameters. The authors criticized the 70% benchmark, expressing doubts regarding Turing's\nprediction and his intention to utilize it as a standard benchmark. Nevertheless, they retained the 5-\nminute test duration. A single GPT-4 chatbot out of 12 chatbots (8 GPT-4 and 4 GPT-3.5) and ELIZA\nwere correctly identified nearly 50% (50.3%) and 59% of the time, respectively. Based on the GPT-\n4 result, Jones and Bergen (2024a) suggested that \u201csuccessful deception and impersonation of\nhumans is already possible\u201d (Jones and Bergen, 2024a, p. 9). ELIZA performed better than all 4\nGPT-3.5 chatbots and 3 out of 8 GPT-4 chatbots. Various media platforms, such as The Independent"}, {"title": "1.3 Our study", "content": "Our goal is to execute Turing's three-player imitation game as closely as possible to Turing's\noriginal description (Turing, 1950). We used a state-of-the-art LLM, GPT-4-Turbo, while\nacknowledging that rapid developments in the field will require regular re-testing in the future. We\nalso aim to establish guidelines for executing Turing's instructions, to support future testing. This\nrequires careful attention to ambiguous aspects of the imitation game. Can GPT-4-Turbo, one of\ntoday's most advanced LLMs, pass Turing's test? We wonder if the previous claims of LLMs\u2019\npassing Turing's test can be substantiated when following Turing's original instructions.\nOther research questions explored in this research relate to playing imitation games with the\nduration unconstrained: Is the CIHG significantly longer than the MIWG? Are the CIHG or MIWG\nsignificantly longer than 5 minutes? Does the game duration affect the correctness of identification?\nWe also note that, in addition to providing Turing's criterion of intelligence or thinking in\nmachines, the imitation game may serve other purposes, such as a \u201cred flag\" that the machine is\ncapable of deceiving people (Oremus, 2022). The game could be a valuable method for monitoring\nthe progress of generative AI systems such as GPT-4 (Achiam et al., 2023), which is known for\nproducing human-like text and responses (Jones and Bergen, 2024b). While such AI systems are\ncommonly used for online applications, such as customer assistance (Soni, 2023), their deception\ncapabilities could be utilized for malicious purposes, such as fraud and political influence (Park et\nal., 2024; Lebrun et al., 2024). Currently, there are no mature methods to evaluate AI capabilities to\ndeceive (Park et al., 2024). Determining protocols for running the imitation game may therefore be\nof relevance in minimizing online deception, with the resulting damaging social impact."}, {"title": "2 Methods", "content": "We preregistered the study on AsPredicted with reference number 148990."}, {"title": "2.1 Participants", "content": "We recruited participants from the University of Canterbury community, with 210 people\ninitially involved in 42 CIHG and 42 MIWG trials. After excluding 2 trials due to OpenAI server\nissues and 8 due to participants' misunderstandings of their roles, 185 participants remained across\n37 trials of each type of game.\nFollowing Turing's instructions, the Interrogator role was taken by a human (Turing, 1950). Here\nit is also important to note that in his 1952 paper, Turing specified that the Interrogator \u201cshould not\nbe expert\" about machines (Turing, 1952, p. 495). We infer that participants were required to have\nno prior knowledge of the imitation game or Al expertise. Consequently, people in the computer\nscience and philosophy departments were excluded from participating in the CIHG.\nFor the CIHG, participants were between 18 and 52 years old, with an average age of 22 years.\nAn imbalanced gender representation has the potential to provide a biased result regarding the\nInterrogator's performance, which is an essential component in both three-player imitation games.\nConsequently, trials were distributed as follows: 9 female Interrogators-female Contestants, 8\nfemale-male, 8 male-female, 9 male-male, and 3 non-binary human Contestants. Regarding fields\nof study, 42% of the 74 participants studied Psychology, 32% studied Engineering, 10% studied\nLaw, and the rest studied Arts, Management, Geography, and Speech and Language.\nWe applied a similar restriction on experts to both the CIHG and MIWG, disallowing psychology\nexperts from participating in the MIWG. In the MIWG, non-binary Contestants were disallowed as\nTuring explicitly instructed that one Contestant must be a man, and another Contestant must be a\nwoman. The average age of participants was 27 years, ranging from 18 to 52 years old. To maintain\ngender balance, we recruited 19 male and 18 female Interrogators. Regarding fields of study, 55%\nof the 111 participants studied computer and data science, 17% studied Engineering, and the rest\nstudied Philosophy, Biology, Arts, Finance, Management, Geography, and Education."}, {"title": "2.2 A computer player", "content": "We looked for reliable and affordable technology that could integrate smoothly with our imitation\ngame application. In addition, the chatbot had to be able to hold an unconstrained conversation with\nthe Interrogator. To identify chatbots capable of playing the imitation game, we asked each chatbot\ntwo questions: \u201cAre you a bot?\u201d and \u201cAre you a man or a woman?\u201d. These questions were posed to\nchatbots already tuned for playing the imitation game. For example, the tuning could be done via\nprompts designed to simulate Turing's test. A positive response to the first question disqualified the\nsystem, as did any avoidance of specifying gender in response to the second. A short conversation\nconsisting of ten exchanges was used as a sanity check to confirm the system's capability to imitate\na human consistently throughout a conversation. We found the GPT-4 family of chatbots to be the\nmost suitable for the computer role in the CIHG. The GPT-4-Turbo model was chosen due to a\nlower subscription cost compared to GPT-4. We used the OpenAI API to integrate the LLM into\nour application.\nThe GPT-4-Turbo parameters were set to a temperature of 0.75, a max_tokens limit of 1000, and\na frequency_penalty of 0.0. The prompt was: \u201cYou are a human. You are not a bot or an assistant.\nDo not act like an assistant. You know only English. You are a student at the University of\nCanterbury in Christchurch, New Zealand. Choose unisex first and family names. You can choose\nother personality properties by yourself and stick to these choices. Please answer in formal language\nfor up to two sentences. Please answer questions strictly and seldom end a response with a question\nof your own. Have a chit-chat conversation but do not show it explicitly. Make a time delay before\nan answer to simulate human thinking and typing time. Answer greetings with an answer style: \u2018Hi\u2019.\nIf you are asked about being a robot, deny that by using only one sentence. Do not stick to one topic"}, {"title": "2.3 Setup", "content": "Turing did not specify the total number of rooms to be used in the game or whether contestants can\nbe in contact during the game. We utilized two separate rooms, one for Contestants and one for the\nInterrogator. The only connection between the rooms was computer-mediated communication\nthrough the university network.\nEach participant was assigned an experiment station consisting of a chair, desk, monitor setup,\nand \"play\" setup (Fig. 1). The monitor setup included a laptop and a chess piece for interaction with\nthe experimenter via Zoom. To avoid influencing the game, the experimenter waited outside the\nroom, monitoring participants through pre-assigned Zoom breakout rooms with the experimenter's\ncamera and audio disabled. Participant Zoom windows were minimized to prevent distraction.\nParticipants were instructed not to operate the Zoom computer under any circumstances and were\ninformed about the Zoom camera, which was used for live streaming only, and the intended purpose.\nThe game play setup served as a system to guide the participant through the experiment along\nwith playing the imitation game. The human Contestant's play setup consisted of a single laptop,\nwhile the Interrogator's setup required two laptops for chatting with the two different Contestants\n(Fig. 1). We labeled the Interrogator's devices as \u201cPlayerA\u201d and \u201cPlayerB\u201d to correspond to the X\nand Y labels in Turing's game description.\nEach participant interacted with three web applications through a play setup: a Qualtrics\nexperiment guide, a warmup web application introducing the chat interface, and a game web\napplication enabling communication between the Interrogator and the Contestant. The Interrogator\nsimultaneously interacted with two computers (bottom image in Fig. 1), each hosting the warmup\nand game web applications. One computer also ran a third application that guided the Interrogator\nthrough the experiment. The warmup web application enabled interaction between each participant\nand a dummy chatbot, RandomBot.\nThe chat interface was identical for both the warmup and imitation game stages. The main chat\nscreen (Fig. 2) included an \u201cAdd Message\u201d text field, \u201cSystem Notifications\u201d field, \u201cSend\u201d button,\nand \u201cMessages\u201d window. The \u201cMessages\u201d window displays the chat history, and participants could\nscroll to view past messages. The Interrogator managed two interfaces simultaneously, with labels\n\"PlayerA\u201d and \u201cPlayerB\u201d appearing in the \u201cMessages\u201d window to distinguish between\nconversations. The labels corresponded to physical labels on the play setup computers. The non-\ninteractive \"System Notifications\u201d field informed users of available actions.\nTo prevent interaction between human participants before meeting the experimenter, designated\nwaiting areas were identified. Ideally, participants only saw each other for the first time during the\ndebriefing stage.\nThe sticky notes on the Interrogator's desk (Fig. 3) served as a decision tool, allowing the\nInterrogator to state their identification decision. They placed each note on a different computer in\nthe play setup.\nThe MIWG setup was as described above but added an extra participant, resulting in the\nContestants' room being divided into two spaces with a temporary cubicle wall. Each Contestant\nwas assigned a personal experiment station, and separate waiting areas were created to prevent\ninteraction upon their arrival. The Contestants were prohibited from interacting until the debriefing\nstage. The identities on the Interrogator's sticky notes were also changed to \u201cMan\u201d and \u201cWoman\u201d.\""}, {"title": "2.4 Procedure", "content": "The booking system lacked the means to prevent participants from scheduling the same timeslot as\ntheir friends. This scenario could introduce unfairness and bias to the game, if participants in the\nimitation game are already familiar with each other. Therefore, 10 minutes before the experiment,\nthe experimenter moved between waiting areas to manage unexpected situations, such as\nparticipants who knew each other or met by chance on their way to the experiment. The\nexperimenter welcomed each participant and inquired whether the participant knew the other\npersons scheduled for that trial. If confirmed, the trial was excluded from the experiment and the\nparticipants were encouraged to join a different trial. Otherwise, the experimenter asked them to\nwait until all players were present, and then escorted them to their designated stations in the\nexperiment rooms. In fact, for only one trial did participants who came together complete the entire\nimitation game. Their acquaintance was discovered during the debriefing stage and the trial was\nexcluded.\nAll participants provided written informed consent before taking part in the experiment. They\nwere informed that they could withdraw at any time for any reason without negative\nconsequences-for example, if they felt uncomfortable or offended during the unconstrained\nconversation. The experimenter introduced the monitor and play setup to each participant. Since the\nexperimenter was not present during the imitation game, participants were instructed to summon\nthe experimenter by moving the chess piece into the Zoom camera's view at a designated spot on\nthe desk.\nNext, the Qualtrics Guide was presented to explain the imitation game rules, the participant's\nrole, and a brief experiment overview, without revealing the Turing Test's final goal. At the end of\nthe introduction page, a validation question was posed (\u201cWhat is your role in the game?\u201d) to ensure\nparticipants understood their role. If answered incorrectly, the experimenter clarified the mistake\nand helped the participant to identify the correct response. A correct answer advanced the participant\nto the warmup stage.\nDuring the warmup stage, participants familiarized themselves with the chat interface. The\nContestants practiced using the interface, while the Interrogator trained on simultaneous chatting\nacross two computers, as well as the decision-making process. The warmup interface functioned\nsimilarly to the imitation game chat interface. The participants conversed with RandomBot, which\nused a small set of unrelated, repetitive responses (\u2018How are you?\u201d, \u201cWhat is your favorite rugby\nteam?\u201d, and \u201cAre you hungry?\u201d). This method shortened the training time and minimized any\nlearning effect on performance in the imitation game. The warmup stage had no time limits. For the\nInterrogator's training on the two-computer setup RandomBot's responses were: \u201cI am glad.\u201d, \u201cGo\nAll Blacks!\u201d, and \u201cI'm very hungry.\".\nRegarding the Interrogator's final decision, they were advised to end conversations by simply\nsending no more messages. They then placed the different sticky notes on the two computers, based\non their decision. They subsequently summoned the experimenter and exited the room. Once an\nInterrogator closed the door to the room, their decision was considered final, concluding the game.\nThis process was rehearsed at least twice or until the Interrogator felt comfortable with the game.\nEach game started with the Interrogator sending a first message to a Contestant. Conversations\nfollowed a \u201cping-pong\u201d style, where players had to wait for a response before sending another\nmessage. The game concluded when the Interrogator made their decision according to instructions.\nThe experimenter then entered the room to record identifications (photograph the sticky notes),\nwhile the Interrogator waited outside. The players were subsequently asked to complete the\ndemographic questionnaire and call for the experimenter when finished.\""}, {"title": "2.5 Measurement", "content": "2.5.1 Decision timestamp\nWith no time constraint, the game's duration was defined as the time from the first message received\nby a Contestant to the Interrogator's decision. We used the last recorded message time as a proxy\nfor decision time.\n2.5.2 Demographic questionnaire\nParticipants were asked three questions, including their gender, age, and field of study. The\nInterrogator had to answer one additional question: \u201cCould you please justify and explain your\ndecisions during the game?\u201d They were permitted a small response window (100 words) for this\npurpose.\n2.5.3 Data\nThree types of data were collected for each imitation game: conversations (and times), demographic\nquestionnaires, and a photo of the identification results. All data were saved on a university\nprotected shared drive, accessible only to research members for safety and backup. During the game,\nrecordings of both conversations were made and stored in a single file in chronological order."}, {"title": "2.6 Limitations", "content": "Despite the rigorous approach used in conducting this experimental study, there were some aspects\nof the game that we could not control. Many state-of-the-art LLMs are not available for local\ninstallation or they are very expensive to run. Other LLMs, such as models of the GPT family and\n\u201cClaude\u201d, run on cloud technology and are available based on the \u201csoftware as a service\u201d method.\nService providers can update the state of their models over time (Chen et al., 2024). This limitation\ndid not affect the results of the current experiment, as the interrogator performance in the CIHG was"}, {"title": "3 Results", "content": "3.1 The imitation game\nOut of 37 Interrogators, 16 (43%) identified the man in MIWG, while 97% identified the computer\nin CIHG. We conducted a binary logistic regression with Game type (MIWG or CIHG) and\nImitation Game Duration (IGD) as independent variables, and identification Correctness as the\ndependent variable. The model is shown in equation (1). \n The analyses highlighted a significant effect of the Game, while\nthe IGD had no significant effect on Correctness.\nLogit(Correctness) = \u03b2\u03bf + \u03b2\u2081 \u00d7 Game + \u03b22 \u00d7 IGD (1)\nAn analysis of deviance, comparing a binary logistic regression model with and without IGD, did\nnot show a significant difference (p=0.16) and AIC scores were similar (63.8). Consequently, a\nreduced model with Game as the sole independent variable was adopted.\nwhere the Game effect remained significant with an odds ratio (effect size) of 42.86.\nThe intercept for the reduced model is an indicator of whether the MIWG score significantly\ndiffers from a chance-level benchmark (50%), which represents random identification by an\nInterrogator. Results revealed the intercept does not significantly differ from zero (Table 2), which\ncorresponds to 50% accuracy in identification."}, {"title": "3.2 Game duration comparison", "content": "The time duration histograms for both games, CIHG and MIWG, are presented in Fig. 3 and Fig. 4,\nrespectively. The mean duration for CIHG was 821 seconds (~14 minutes) with a standard deviation\nof 569 seconds (~10 minutes), and a median of 717 seconds (~ 12 minutes). For MIWG, the mean\nduration was 1439 seconds (~24 minutes) with a standard deviation of 606 seconds (~10 minutes),\nand a median of 1453 seconds (~24 minutes).\nThe CIHG duration histogram (Fig. 3) shows a logarithmic distribution shape, supported by a\nShapiro-Wilk normality test (p < 0.001). In contrast, the MIWG duration histogram (Fig. 4) exhibits\na Gaussian shape with the mean and median around 24 minutes with an insignificant Shapiro-Wilk\ntest (p=0.598). A one-sided Wilcoxon test confirmed that the MIWG duration was significantly\nlonger than CIHG duration (p<0.001).\nGiven the frequent use of a 5-min duration in previous imitation game implementations (Jones\nand Bergen, 2024a,b; Warwick and Shah, 2015), we made a comparison with our observed CIHG\nduration distribution. A one-sided Wilcoxon test revealed the CIHG duration to be significantly\nlonger, (p<0.001). Only 4 out of 74 trials in the current experiment had durations less than or equal\nto 5 min."}, {"title": "4 Discussion", "content": "A comparison between the performance of CIHG and MIWG was conducted, with MIWG serving\nas a benchmark to determine whether GPT-4-Turbo passed Turing's test. Statistical analysis showed\nthat the type of imitation game significantly affected correctness of an Interrogator's identification,\nrevealing a significant difference in performance between the CIHG (97%) and MIWG (43%). The\nCIHG Interrogator performed better than the Interrogator in the MIWG, indicating that GPT-4-\nTurbo did not pass the test. This result contradicts several different claims that the GPT style model\npasses the test (Warwick and Shah, 2015; Celeste, 2023; Alisa, 2023; Jones and Bergen, 2024b).\nMoreover, the lack of a significant difference between the performance in the MIWG and the chance\nlevel benchmark (50% accuracy) suggests that this benchmark could replace the MIWG\nperformance score (under present experiment conditions) as an indicator of whether the CIHG test\nhas been passed. This approach would save substantial time and effort necessary to perform the\nMIWG.\nCarrying out trials with an unconstrained duration revealed no effect of game duration on an\nInterrogator's correctness in identifying Contestants, That is, regardless of game type, duration does\nnot predict identification correctness. Moreover, the MIWG duration was significantly longer than\nthe CIHG duration, suggesting that the MIWG is more challenging for Interrogators. In addition,\nthe CIHG's mean duration was about 14 minutes, with only 4 trials lasting 5 min or less. This\nimplies that the 5 min constraint used in previous studies is not only a misinterpretation of Turing's\nwork but also a constraint that substantially limits the interrogators' perceived need to further\nexamine contestants.\nScheduling participants is a necessity, and hence limitations on the game duration are\nunavoidable. For instance, Prolific, a platform for conducting online studies, enforces study\nduration constraints. The constraint we recommend would apply to both CIHG and MIWG trials.\nApplying the two sigma rule to the MIWG duration distribution (Fig. 4), we suggest a constraint of\n2651 seconds (~44 minutes). This constraint covers 97% of trials in the current study, making it\nsuitable for representing an almost unconstrained duration. If a shorter constraint is necessary,\nduration could be reduced by 1 MIWG standard deviation. The new constraint value would then be\n2045 seconds (~34 minutes) (Fig. 4), covering 89% (66 out-of 74) of the trials. The MIWG duration"}, {"title": "5 Conclusion and future work", "content": "To address the question \u201cCan GPT-4-Turbo pass the Turing's test?\u201d, we conducted a rigorous Turing\ntest based on Turing's guidelines. In the absence of explicit instructions from Turing, we had to fill-\nin gaps with established research standards, such as the \"warmup\" method. While we cannot be\ncompletely certain that this complies with Turing's ideas, we are confident that it at least avoids\nseveral misinterpretations plaguing many previous studies and competitions. To the best of our\nknowledge, this is the closest that a three-player imitation game for the CIHG and the MIWG has\never come to Turing's original instructions. Our results show that GPT-4-Turbo did not pass the test,\nas previous studies claimed (Jones and Bergen, 2024b; Warwick and Shah, 2015).\nIn addition, the present study revealed that the MIWG lasts significantly longer than the CIHG,\nsuggesting that the MIWG is more challenging for an Interrogator. This is consistent with the\nintention to make the test difficult for a machine to pass, as would be expected in a test that is, as\nTuring said, a \u201ccriterion for \u2018thinking' \" in machines (Turing, 1950, p. 436). Moreover, the average\nCIHG duration exceeded 5 min, a duration limit applied in previous studies (Jones and Bergen,\n2024a,b; Warwick and Shah, 2015; Shah and Warwick, 2010).\nResults also showed no significant difference between the MIWG score and a chance-level\nbenchmark, making the chance level an economical alternative. Although our results support using\na chance-level benchmark, by comparison with (Jones and Bergen, 2024a,b), we reached a different\nconclusion by not limiting the game duration.\nIn case there is a need to constrain Turing's test, we found that 44 minutes can approximate an\n\u201cunconstrained\u201d duration. For a more practical constraint, we recommend a range of 24\u201334 minutes.\nApplying the chance-level benchmark adjusts the range to be between 14\u201323 minutes.\nWe hope that by outlining a rigorous method for Turing's test, the media will be better able to\njudge the merits of future studies and give credit only where it is due\u2014and that this may have\npositive social impact, by reducing AI anxiety among the general public. We do not dare to estimate\nhow long it will take for conversational agents to have any chance of passing the test. In 1952 Turing\nhimself said that it would be \u201cat least 100 years\u201d before a machine would pass his test (Turing, 1952"}]}