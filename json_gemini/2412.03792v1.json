{"title": "Safe Adaptive Cruise Control Under Perception Uncertainty: A Deep Ensemble and Conformal Tube Model Predictive Control Approach", "authors": ["Xiao Li", "Anouck Girard", "Ilya Kolmanovsky"], "abstract": "Autonomous driving heavily relies on perception systems to interpret the environment for decision-making. To enhance robustness in these safety critical applications, this paper considers a Deep Ensemble of Deep Neural Network regressors integrated with Conformal Prediction to predict and quantify uncertainties. In the Adaptive Cruise Control setting, the proposed method performs state and uncertainty estimation from RGB images, informing the downstream controller of the DNN perception uncertainties. An adaptive cruise controller using Conformal Tube Model Predictive Control is designed to ensure probabilistic safety. Evaluations with a high-fidelity simulator demonstrate the algorithm's effectiveness in speed tracking and safe distance maintaining, including in Out-Of-Distribution scenarios.", "sections": [{"title": "1. Introduction", "content": "Advances in Deep Neural Networks (DNNs) have significantly enhanced visual-based perception capabilities in autonomous driving. However, as black-box models, DNNs lack interpretability and operate in a high-dimensional image space vulnerable to pixel-level attacks, and to Out-Of-Distribution (OOD) observations, which are unseen in training data. The integration of these models can impact the autonomous driving systems' safety through other system modules, such as control and decision-making.\nResearchers have been investigating Bayesian frameworks to model inference uncertainty in DNNs, despite their computational intensity. Bayesian DNNs are attractive as they offer theoretical guarantees useful in uncertainty quantification by assuming prior distributions on model parameters or architectures. To address computational demands, the Monte Carlo Dropout method has been proposed that approximates prior distributions through empirical dropout sampling. Similarly, Deep Ensembles leverage a diverse set of DNN architectures, enabling a voting mechanism that enhances inference robustness against OOD and adversarial attacks at the pixel level. Other approaches, such as Laplace Approximation and Variational Neural Networks, have also been developed. A comprehensive review is available in. While these methods are easy to implement, they may lack theoretical guarantees. In contrast, Conformal Prediction offers distribution-free uncertainty quantification, relying on exchange-ability assumptions. This work combines Deep Ensembles with Conformal Prediction for robust uncertainty quantification with statistical guarantees, and it demonstrates how such guarantees can"}, {"title": "2. Problem Formulation", "content": "In this study, we investigate an ACC scenario where the ego vehicle follows a lead vehicle (see Fig. 1). Our focus is on integrating visual-based perception and control mechanisms. The ego"}, {"title": "3. Method", "content": "As shown in Fig. 2, we propose an adaptive cruise controller that employs a Deep Ensemble to estimate system states with formal uncertainty quantification via the Conformal Prediction. The concept of Conformal Prediction is introduced in Sec. 3.1, and the perception solution is detailed in Sec. 3.2. The estimation and uncertainty quantification is then integrated into a Conformal Tube MPC design for vehicle acceleration control, as discussed in Sec. 3.3."}, {"title": "3.1. Preliminaries: Conformal Prediction", "content": "We consider regression problems aiming to learn an unknown mapping f : X \u2192 Y from input domain X to output domain Y. We denote the training, testing, and calibration datasets as Dtrain, Dtest, and Dcali, respectively, where each data point is a pair (Xi, Yi) with Xi \u2208 X and Y\u2081 = f(Xi). We present Algorithm 1 and Theorem 1 to establish probabilistic coverage for prediction results. A tutorial is available in."}, {"title": "Theorem 1", "content": "For arbitrary test point (Xtest, Ytest) \u2208 Dtest, if (Xi, Yi)=1 and (Xtest, Ytest) are i.i.d., then the prediction set C(Xtest) produced by the Algorithm 1 provides a coverage of the true result Ytest with a probability of at least 1 a, i.e., P (Ytest \u2208 C(Xtest)) \u2265 1 \u2013 \u03b1."}, {"title": "Remark 1", "content": "The independent and identically distributed (i.i.d.) assumption in Theorem 1 can be relaxed to the exchangeability of (Xi, Yi)_1 and (Xtest, Ytest). We note that the i.i.d. assumption"}, {"title": "3.2. Deep Ensemble and Conformal Prediction", "content": "As presented in Sec. 2, we focus on estimating the state vector xk while quantifying uncertainties from image inputs. This task is decomposed into three steps: First, we estimate and quantify uncertainty for the distance headway dk using a Deep Ensemble with images Il,k and Ir,k from the left and right cameras. Secondly, we apply the Conformal Prediction framework to provide statistical guarantees for the uncertainty estimates. Lastly, assuming the vehicle speed vk is known and given images Il,k\u22121 and Ir,k\u22121 from previous time steps, we estimate the velocity state \u0394\u03c5\u03ba.\nAt first, as illustrated in Fig. 2, we assemble m different DNN paths denoted as fi, i = 1,..., m. Each DNN path in parallel processes the input RGB images Ilk and Ir,k into two scalar outputs \u03bci\u2208R,\u03c3\u2208R+, i = 1, ..., m according to the following equations,\n\\begin{align}\n[\u03bc_{i}, \u03c3_{i}^{2}] = f_{i}(I_{l,k}, I_{r,k}) = f_{MLP}^{i} \\circ f_{CNN}^{i}(I_{l,k}, I_{r,k}),\n\\label{eq:1}\n\\end{align}\n\\begin{align}\nz_{i}^{(j+1)} = \\text{ReLU}(W^{(j)} z_{i}^{(j)} + b^{(j)}), j = 0, ..., l_{i} - 1, z_{i}^{(0)} = [z_{l,k}^{i} z_{r,k}^{i}]^{T},\n\\label{eq:2}\n\\end{align}\n\\begin{align}\n[\u03bc_{i}, \u03c3_{i}^{2}] = f_{MLP}^{i}(z_{i}^{(0)}) = W^{(l_{i})} z_{i}^{(l_{i})} + b^{(l_{i})},\n\\label{eq:3}\n\\end{align}\n\\begin{align}\nz_{l,k}^{i} = f_{CNN}^{i}(I_{l,k}), z_{r,k}^{i} = f_{CNN}^{i}(I_{r,k}),\n\\label{eq:4}\n\\end{align}\nwhere CNN denotes the ith CNN backbone and embeds the images Il,k, Ir,k separately into vectors zl,k, Zr,k \u2208 R1024 in (3d); MLP is the ith Multi-Layer Perceptron (MLP). It takes the vector\n[2Tk 2]T after the CNN backbone and passes through fully connected layers to generate estimates\n\u03bci, \u03c3i according to (3b), (3c); \u0398\u00bf is the CNN parameter; (3), 6)}=0 are the MLP parameters;\nReLU is an element-wise ReLU activation function; li is the number of hidden layers in ith MLP.\nEach DNN is trained using the following Negative Log Likelihood (NLL) loss,\n\\begin{align}\n\\mathcal{L} \\left(d_{k}, I_{l, k}, I_{r, k} / f_{i}\\right) = \\log \\sigma_{i}^{2}\\left(I_{l, k}, I_{r, k}\\right)+\\left(d_{k}-\\mu_{i}\\left(I_{l, k}, I_{r, k}\\right)^{2} / \\sigma_{i}^{2}\\left(I_{l, k}, I_{r, k}\\right)\n\\label{eq:5}\n\\end{align}"}, {"title": "3.3. Conformal Tube Model Predictive Control", "content": "At the current time tk, we assume the following quantities are given: previous acceleration ak-1, an image buffer of M = 2, i.e., Il,k\u22121, Ir,k\u22121, Il,k, Ir,k, and the vehicle speed vk. Note that the actual distance headway, i.e., dk\u22121 and dk, is unknown to the algorithm. We can then predict the trajectory of future distance headway as a tube formed by the Conformal Prediction sets for a variable acceleration trajectory using the following proposition:"}, {"title": "4. Results", "content": "We train the Deep Ensemble and apply neuron pruning to improve memory usage (Sec. 4.1). We then present distance headway estimation results using the Deep Ensemble with Conformal Prediction, demonstrating reliable uncertainty characterization in various scenarios, including OOD and adversarial attacks (Sec. 4.2). Finally, we evaluate the Conformal Tube MPC design in ACC scenarios using a realistic simulator (Sec. 4.3). Computations are performed on an Nvidia GeForce RTX 4080 GPU (16 GB) and a 13th Gen Intel i9-13900F CPU (32 GB RAM)."}, {"title": "4.1. Deep Ensemble Training and Pruning", "content": "In the Deep Ensemble, we implement three DNN paths using MobileNet V2, MobileNet V3, and EfficientNet as CNN back-bones, respectively, utilizing PyTorch. These networks are selected due to their outstanding performance in image classification tasks and lower computational demands. Mean-while, we use the same MLP head architecture for the three DNN paths, each having li=1,2,3 = 2 hidden layers, with 512 and 128 neurons, respectively. For dataset collection and testing, we utilize the Carla simulator. We generate a dataset Dtrain = {dk, Il,k, Ir,k}k=1consisting of 29,580 data triplets. Data points are collected within the map Town06 in Carla. To simplify the approach exposition, we fix the model of the lead vehicle to a 2020 Lincoln MKZ Sedan(vehicle.lincoln.mkz_2020) and set the weather to ClearNoon (good lighting conditions,no rain, and no objects casting shadows). We train the three DNN paths separately using StochasticBatch Gradient Descent with a learning rate of 0.001, a momentum of 0.9, and batch sizes of 65,65, and 60, respectively, for 100 epochs. To ensure numerical stability with the logarithm in the lossfunction, we enforce the positiveness of the output variance of using the following assignment,\u03c3\u00b2 \u2190 \u03b5 + log(1 + exp(\u03c3\u00b2)), where a small \u03b5 = 10\u22126 is chosen.\nTo further reduce the size of the DNN paths, we iteratively prune the parameters {W(3)}(j)l=0in the dense MLP heads based on their magnitude. In each iteration, we first trim 50% of the remainingweight parameters in each of the three MLP heads, then finetune for 5 epochs using the same settingsas in the initial training. This pruning and fine-tuning process is repeated for 6 iterations, resultingin a Deep Ensemble with memory usage reduced from 44.32 MB to 33.26 MB. As shown in Fig. 3,"}, {"title": "Remark 5", "content": "Instead of starting with smaller MLPs, it is generally more effective to begin with largerMLPs and then prune and fine-tune them. Larger networks have greater representational capacityand can capture more complex patterns, resulting in better initial performance. This discussion isoften referred to as the \u201clottery ticket hypothesis\u201d"}, {"title": "4.2. Distance Headway Estimation", "content": "As shown in Fig 4, we collected a testing dataset Dtest for a varying dk trajectory followingthe same settings as in training to emulate an in-distribution scenario. The Conformal Predictionis conducted using a separately collected calibration dataset Deali = {dk, Il,k, Ir,k}k=1. Our DeepEnsemble, combined with the Conformal Prediction sets C(Il,k, Ir,k), provides good coverage of theactual trajectory of dk with a coverage rate (1-a) = 0.8, which empirically validates Proposition 1.Due to limitations in image resolution, the lead vehicle appears as a black pixel in the RGB imageswhen dk \u2265 20 m (see Fig 4). We observe that the Deep Ensemble captures this source of uncertaintyby presenting larger prediction sets in such cases.\nMeanwhile, we perturb the images in the testing datasets using the Fast Gradient Sign Method(FGSM) to examine the uncertainty detection ability of the proposedapproach when facing adversarial attacks at the pixel level. Specifically, the FGSM perturbs theimages along the direction of \u2207LIL,test and \u2207LIr, test in the image space I, corresponding to the direc-tion where the loss function increases most rapidly. As shown in Fig. 5c-e, our method can reflectthe magnitude of the perturbation \u2208 through the changes in the length of the Conformal Predictionsets/intervals, indicated by the purple bands. Meanwhile, the length of the Conformal Predictionsets/intervals required to achieve a certain probability of coverage increases with larger perturba-tions (see Fig. 5f). Lastly, we also manipulate the weather in the Carla simulator (see Fig. 6) to createartificial OOD scenarios. Our method detects OOD by producing larger Conformal Prediction sets,thereby informing the downstream Conformal Tube MPC of the perception uncertainties."}, {"title": "4.3. Adaptive Cruise Control", "content": "We use the Carla simulator to test the Conformal Tube MPC (10) in realistic ACC scenar-ios. The simulation parameters are set as follows: [Umin, Umax] = [0,20] m/s and [amin, amax] =[-6, 6] m/s\u00b2. The Conformal Tube MPC has a prediction horizon of 3 sec, i.e., N = 3 and \u2206t = 1sec. Furthermore, the MPC operates in an asynchronous updating scheme and recomputes ak ev-ery 0.1 sec. Other parameters are set using the following values: ds = 10 m, T\u2083 = 0 sec, and[r1, r2, 91, 92, \u03c1] = [1,5, 1, 10, 100]. The Conformal Tube MPC problem (10) is solved using Py-Drake. The perception using Deep Ensembleand Conformal Prediction takes 1.3699 \u00d7 10-2 \u00b10.3686 \u00d7 10-2 sec while the solving the QP (10)takes 6.2435 \u00d7 10-5 \u00b1 0.6222 \u00d7 10-5 sec. As shown in Fig. 7, the ego vehicle initially main-tains an unsafe distance headway and consequently applies hard brakes. After 2 seconds, upon"}, {"title": "5. Conclusion and Future Work", "content": "This paper presents a method for state and uncertainty estimation from images using DNNs. In particular, we developed a Deep Ensemble for effective uncertainty quantification against adversarial attacks and OOD scenarios. Integrated with the Conformal Prediction, this approach provides formal coverage guarantees, which are demonstrated using a realistic traffic simulator. We also introduced Conformal Tube MPC to predict future state trajectories with statistical coverage, applying these constraints in ACC. Simulation results show effective car-following and safe distance maintenance. Future work will explore more complex autonomous driving applications."}]}