{"title": "A Novel Adaptive Hybrid Focal-Entropy Loss for Enhancing Diabetic Retinopathy Detection Using Convolutional Neural Networks", "authors": ["Pandiyaraju V", "Santhosh Malarvannan", "Shravan Venkatraman", "Abeshek A", "Priyadarshini B", "Kannan A"], "abstract": "Diabetic retinopathy is a leading cause of blindness around the world and demands precise AI-based diagnostic tools. Traditional loss functions in multi-class classification, such as Categorical Cross-Entropy (CCE), are very common but break down with class imbalance, especially in cases with inherently challenging or overlapping classes, which leads to biased and less sensitive models. Since a heavy imbalance exists in the number of examples for higher severity stage 4 diabetic retinopathy, etc., classes compared to those very early stages like class 0, achieving class balance is key. For this purpose, we propose the Adaptive Hybrid Focal-Entropy Loss which combines the ideas of focal loss and entropy loss with adaptive weighting in order to focus on minority classes and highlight the challenging samples. The state-of-the art models applied for diabetic retinopathy detection with AHFE revealed good performance improvements, indicating the top performances of ResNet50 at 99.79%, DenseNet121 at 98.86%, Xception at 98.92%, MobileNetV2 at 97.84%, and Inception V3 at 93.62% accuracy. This sheds light into how AHFE promotes enhancement in AI-driven diagnostics for complex and imbalanced medical datasets.", "sections": [{"title": "I. INTRODUCTION", "content": "The application of Artificial Intelligence (AI) technology in the field of medical imaging has witnessed tremendous progress over the past few years, changing the way medical practitioners detect and manage diseases in different parts of the world. Since the rise of Deep learning networks and in particular Convolutional neural networks (CNNs), the medical image interpretation process has been automated and it has become more accurate and faster than the conventional methods. Al models can detect patterns in images that, if looked at by the human eye, might seem trivial and make it more accurate when diagnosing a patient. For example, a recent study by Sharmiladevi et al. [1] claims that patients can avoid manual inspection of a patient for skin cancer using AI tools which helps both in the accuracy of diagnosis and time/cost for inspections. With these advancements, the diagnosis of diabetic retinopathy (DR) is also becoming possible, where the Al can classify the stages of the disease from photographs of the retina.\n\nDiabetic retinopathy (DR) occurs in approximately 30 percent of people with diabetes and remains one of the most significant complications associated with the condition. Diabetes related complications global in scale and lead to substantial vision loss and in many cases blindness [2]. Millions of people across the globe are affected by DR and this adds sweeping challenges to healthcare systems especially in areas with a rising diabetic population base. Gary et al. (2017) further pointed out the flaws in traditional manual detection and treatment methods for DR, arguing that such approaches are not only costly but time consuming and usually involve an element of human mistake. For this reason, Convolutional Neural Networks (CNNs) have become very helpful in automating DR diagnosis because they drastically enhance the diagnostic accuracy [3]. The network scans the retina for the presence of microaneurysms, hemorrhages, exudates, and so forth. Despite their success, there is one other proximate problem with using CNN models which still persists; these models exhibit a consistent weakness to imbalanced data of which is a standard feature in medical datasets. This even distribution of cases where normal cases far outnumber the abnormal cases tends to distort the model's performance and as such, detection rates for classes that are underrepresented are suboptimal. Therefore, while CNNs offer a promising solution for effective DR detection, more work has to be done to address the issues of imbalanced data for these approaches to be effective in practice.\n\nIn the last few decades, diabetes has emerged as a pandemic with unprecedented speed, as it was estimated that there are 382 million diabetes patients worldwide, a number which is expected to rise to 592 million patients by 2025. Diabetic retinopathy, which is the most common complication of diabetes, affects 34.6% of diabetic patients, and this condition involves the mutilation of retinal blood vessels. This commonly unnoticed loss of vision which occurs insidiously in the initial phases has made the need for accurate detection much earlier than the later stages of disease management when prognosis of vision is nearly impossible [4]. There is also a significant proportion of patients at risk of vision threatening complications, as 7% of patients go on to develop proliferative diabetic retinopathy and 6.8% develop diabetic macular edema(DME). The above statistics demonstrate the inadequacy of present diagnostic techniques to detect and categorize diabetic retinopathy at earlier stages before they advance to the proliferative or moderate stages [5].\n\nDespite the advancement in diagnostic methods, most of these still necessitate manual assessment, which is inefficient, subjective and inconsistent in quality. This is quite worrying in countries where the incidence of diabetes is high like in the Khyber Pakhtunkhwa province of Pakistan, where around 30% of the population is diabetic and 4% of blindness cases are attributed to DR. As manual approaches fail to meet the growing demand, automated strategies using deep learning techniques, such as Convolutional Neural Networks (CNNs) seem to be an efficient and more scalable solution [6]. However, issues such as the examinations being performed on unbalanced medical images, where the abnormal cases are few, still prevent the best performance, and thus, more effective strategies need to be developed.\n\nIn this study, a new technique is proposed that combine the present trend of training deep learning models with the traditional methods of handling data imbalance in the task of diabetic retinopathy detection. The AHFE formulation is instituted to improve the model orientation towards learning invariant features while simultaneously addressing class imbalance. Even though only mild and moderate lesions are tolerable in the image for early diabetic retinopathy diagnosis, the loss function can also be trained on datasets with greater severity. The scope of AHFE allows the model to learn with reduced overfitting on the majority class while learning about the hard examples of the majority class through the focal loss mechanism. The fusion of these forces creates an ideal situation in which stochastic gradient descent-related phenomena can increase the sensitivity of the model and improve overall performance. The collected evidence confirms our hypothesis that links the incorporation of the AHFE loss function with an increase in the accuracy of CNN models. This increases the reliability of the model in diabetic neuropathy detection and demonstrates the ease of overcoming data imbalance and providing practical techniques for diagnosis that can be implemented efficiently."}, {"title": "II. RELATED WORKS", "content": "Shamrat et al. [7] designed a sophisticated deep neural network for analysis of fundus image and managed to achieve 97% accuracy in diabetic retinopathy detection. Their analysis brings to focus the efficacy of Al-driven models in improving DR diagnostics and stresses on more studies to strengthen the model's robustness and generalization across a wide range of datasets. Thanikachalam et al. devised a faster and more accurate model of Deep Convolutional Neural Network (CNN) for automatic detection and classification of Diabetic Retinopathy (DR) and Diabetic Macular Edema (DME) [8] with an accuracy of 97.91. They used discrete wavelet transform and adaptive Gabor filtering along with a Chicken Swarm Algorithm with the aim of improving classification and more importantly feature extraction thus making the technique effective for treating diabetic related sight complications at an early stage. Alyoubi et al. [9] review death learning algorithms with President, CNN deep architectures are utilized for automatic diabetic retinopathy (DR), establishing that such automation is able to significantly scale down the detective time and cost. They also cover some of the notable datasets and barriers to DR detection. Qummar et al. aimed to design a unified ensemble model that contained five different CNN architectures all with one objective and that is to detect diabetic retinopathy in all its stages with particular emphasis on early stages [10]. Their technique, which was based on the Kaggle fundus image database, had a higher degree of accuracy than other competing techniques. Dutta et al. [11] used CNNs, DNNs, and the backpropagation network to classify diabetic retinopathy. One of his focus areas is that the models detect specific diabetic retinopathy (DR) features such as blood vessel abnormalities and hemorrhages in the retinopathy image. The study emphasized that deep learning models are better than conventional neural networks and supported it with the importance of feature selection and the use of GPU for greater training efficiency.Lam et al, for the purpose of staging diabetic retinopathy, applied Convolutional Neural Networks to colour fundus images and succeeded to achieve a satisfactory sensitivity and a good performance in terms of binary classification [12]. They observed the implementation of many algorithms for subtle disease feature extraction as problematic, especially for mild stages without fine features, and stated that such algorithm results can be improved with preprocessing and by an expert's verification. They also proposed the possibility of incorporating a two-step lesion detection with shallow CNNs to help the detection of less aggressive disease features.\n\nTymchenko et al. [13], suggested a fully automated deep learning approach to diabetic retinopathy stage detection from a single image of fundus photographs. An ensemble of three different convolutional neural network (CNN) architectures including transfer learning was used to obtain 0.99 sensitivity and specificity on the APTOS 2019 dataset. The approach was shown to decrease variance and improve generalisation and recommends that further improvements can be made via SHAP analyses and meta-learning approaches. Khan et al. [14] proposed a deep learning model known as VGG-NIN which is composed of VGG16 coupled with spatial pyramidal pooling and network in network structure which is effective in determining the severity of diabetic retinopathy. This model has overcome the challenge posed by the previous methods in terms of computational time inefficiency as it uses a low number of learnable parameters while achieving a high accuracy. Experiments made it possible to demonstrate its greater efficiency both in terms of computation and in the classification tasks, especially for the case of imbalanced data sets. Fayyaz et al. [15] delved into a deep learning methodology that makes use of AlexNet and ResNet101 for feature extraction from diabetic retinopathy (DR) images and classifies the DR fundus images according to severity. The model is implemented as a multi-step process consisting of interdependent layer and sensus ant colony for feature selection and multi kernel SVM for classification. The process attained a result of 93% and thus this proves that for the effective management of the disease, early diagnosis and categorization is important. Chakrabarty proposed a deep learning approach using Convolutional Neural Network (CNN) based technique [16] in the diagnosis of diabetic retinopathy. This was achieved through preprocessing and classification of fundus images that were processed using a Convolutional neural network. This system is efficient in detecting diseases early hence reduces the workload of doctors.\n\n\u00d6zbay [17] proposed a new Active Deep Learning (ADL) model for diagnosing diabetic retinopathy through segmentation with multi-layer CNN and artificial bee colony (ABC) algorithm placement. The model sorts the clinical DR lesions into five severity levels with an accuracy rate of 99.66% on the EyePacs benchmark dataset. This method exemplifies the efficacy of deep learning techniques applied after images have undergone pre-processing. Nahiduzzaman et al. [18] presented a technique for diabetic retinopathy classification which integrates an extreme learning machine (ELM) algorithm with a hybrid convolutional neural network (CNN) and singular value decomposition (SVD) model. This technique supplements feature extraction with the application of Ben Graham's principle and CLAHE preprocessing to obtain 99.73% precision and 100% sensitivity for binary classification. This technique is superior to any available technique in both binary and multiclass DR classification, thus show promise for quick and effective diagnosis. Daanouni et al. [19] proposed NSL-MHA-CNN, a robust based CNN model for (DR) prediction and discusses vulnerabilities in the model against adversarial attacks. By combining Neural structure learning (NSL) and multi-head attention (MHA), its accuracy remains at high levels (98%) even when the model is subjected to perturbations, making DR diagnosis reliable and inexpensive in terms of training expenses. The CNN-based DR classification system security and resilience is further advanced by this approach."}, {"title": "III. METHODOLOGY", "content": "The APTOS 2019 dataset refers to the baseline data for the aspirants of the APTOS 2019 Blindness Detection competition which was conducted by Asia Pacific Tele-Ophthalmology Society (APTOS). The dataset of over 3,662 retinal fundus images with accompanying DR grade has been provided and categorized as 0 (No DR), 1 (Mild DR), 2 (Moderate DR), 3 (Severe DR) and 4 (Proliferative DR). Considering the images include real-life environments making this dataset beneficial for ML as the models need these images for the development of DR detection and grading systems. The dataset also shows class improvement and is more appropriate for analyzing the various DR stages and enhancing the diagnosis of vision loss related disorders."}, {"title": "B. Dataset exploration", "content": "This data exploration includes images from APTOS 2019. The same images are always used for the diagnosis of Diabetic Retinopathy. Corresponding to the two retinal images, the five classes of Diabetic Retinopathy are listed below, from Class 0 to Class 4:\n\nClass 0 (No DR) : Definitively no signs of diabetic retinopathy, a clear set of retina and no observable lesions.\n\nClass 1 (Mild DR) : A few scattered small, isolated microaneurysms are seen suggesting changes in diabetic retinopathy in its mild stage.\n\nClass 2 (Moderate DR): More widespread microaneurysms and small hemorrhages and have fused, suggesting greater damage to the retina.\n\nClass 3 (Severe DR) : Great number of hemorrhages and neovascularization could be seen which suggest severe damage to the retina.\n\nClass 4 (Proliferative DR): The enlarged neovascularization and the presence of possible retinal scars suggest a severe incomplete diabetic retinopathy that may ultimately lead to loss of vision."}, {"title": "IV. PROPOSED WORK", "content": "In this research, we propose a novel loss function, named as the Adaptive Hybrid Focal-Entropy (AHFE) Loss, designed to overcome certain challenges associated with the Categorical Cross-Entropy (CCE) Loss. CCE is one of the standard losses in multi-class classification which works on the principle of the probability for each predicted class and its true class by matching them and penalizing wrong predictions more. It calculates the loss function of negative log likelihood for the predicted probability of the true class, which is higher when the prediction for his class differs more. It is clear that CCE increases with the number of classes and reduces diversity in predictions since these values are summed up for every class and normalised over the batch during training.\n\nFor a batch of N samples, the total CCE Loss is averaged as:\n\n$CCE_{total} = - \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{k=1}^{N} Y_{ik} log(p_{ik})$ (1)\n\nHowever, its performance gets poor where there is class imbalance, or difficult or overlapping classes. AHFE utilizes both entropy loss and focal loss to improve the robustness and adaptability of the proposed approach, especially for its application in diabetic retinopathy detection. Here, we bring out some of the main shortcomings associated with CCE and the solution provided by AHFE."}, {"title": "i. Class Imbalance Handling", "content": "Categorical Cross-Entropy assumes all classes are equally important which may result in banks being acquired majority class with little to emphasis on vital rare instances such as some cases in medical datasets. Adjusting these components with AHFE helps reweight the minority classes and hence improve recall and sensitivity for underrepresented classes by aiming for a class balancing approach."}, {"title": "ii. Emphasis on Hard-to-Classify Samples", "content": "CCE is quite passive when it comes to identifying those hard-to-classify samples and tends to be lagging when it comes to rectifying such instances. Primarily throughout loss function - AHFE employs focal loss principles and thus de-emphasizing easy samples yet getting to emphasize the harder ones. Using this approach would benefit the model's learning as it ensures that the optimal learning direction of the model is on complex patterns thus resulting in high accuracy even on complex datasets."}, {"title": "iii. Adaptive Learning Adjustment", "content": "CCE simply applies a certain formula as a way to compute loss for the involved model ignoring the fact that a model within training should be able to adapt. However, as training proceeds, AHFE employs an innovative pathway where it alters its entropy and focal terms, allowing it to quickly switch its concentration from simple to complex samples. This adaptive mechanism promotes balanced generalization in all classes of models in all classes regardless of how many instances each class contain."}, {"title": "iv. Reduction of Overfitting on the Majority Class", "content": "It is well documented that CCE easily leads to overfitting where class biasness is towards majority classes thus lowering sensitivity towards the sparse class. By using adaptive weighting as well as focal loss, AHFE is able to enhance the sensitivity of minority classes which is essential in medical settings, in which failure to identify rare cases may result in rather high costs, thus assisting in removing the bias issue resulting from the previous dominant class."}, {"title": "v. Increased Sensitivity and Specificity", "content": "CCE's approach to accuracy often runs high at the expense of sensitivity and specificity, both of which are rather significant while detecting diabetic retinopathy. AHFE can improve both by considering important tyranny and rare cases rather than focusing on the common images possessing high false positive rate."}, {"title": "vi. Mitigation of Noisy Labels and Class Overlap", "content": "CCE's case is when it suits generalization best when there are noisy labels and overlapping classes. In contrast, the focal component of AHFE tries to prevent the negative influence of such noisy samples; likewise, the modifications in entropy make the discrimination of the overlapping classes easier, which gives it an advantage for the fractional datasets or datasets with overlapping classes.\n\nThe main designed loss function, Adaptive Hybrid Focal-Entropy (AHFE) was proposed with the intention of addressing umbilical challenges Categorical Cross-Entropy (CCE) possesses with importance in scenarios involving complexities of data structures like unbalanced class structure, certain difficulty of samples and even noise in labels. In direct contrast to CCE, which treats all the classes and samples equally regardless of their functions or purposes; AHFE employs both focal loss and adaptive entropy as its prime purposes and offers a more balanced approach. This dual-focused design enhances AHFE's capacity to handle intricate class structures, focusing on the minority classes and difficult instances while maintaining generalization."}, {"title": "1.", "content": "For the Focal Loss component which focuses on samples which are difficult to classify, reducing the impact of the easily classified ones,\n\n$FL(i) = \\frac{1}{N} \\sum_{i=1}^{N} (1 - p_{ik})^{\\gamma} Y_{ik} log(p_{ik})$ (2)\n\nWhere:\n\n\u2022 y denotes the tunable focusing parameter\n\n\u2022 $p_{ik}$ denotes the probability of the correct class for each sample\n\n\u2022 $Y_{ik}$ denotes the ground truth indicator"}, {"title": "2.", "content": "The Entropy Loss component helps penalize uncertain predictions:\n\n$EL(i) = \\sum_{i=1}^{N} p_{ik} log(p_{ik})$ (3)"}, {"title": "3.", "content": "Adaptive weights $\\alpha_{k}$ are calculated depending on class frequency to prioritize minority classes:\n\n$\\alpha_{k} = \\frac{1}{\\sqrt{N_{k}+ \\epsilon}}$ (4)"}, {"title": "4. Full AHFE Loss Function", "content": "Combining Focal Loss and Entropy Loss along with adaptive weights and a balancing parameter \u03bb, for a batch of N samples:\n\n$AHFE_{total} = \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{k=1}^{N} \\alpha_{k}((1 - p_{ik})^{\\gamma} Y_{ik} log(p_{ik}) + \\lambda p_{ik} log(p_{ik}))$ (5)\n\nAHFE, on the other hand, addresses this problem by modifying the weighting mechanisms relative to the sample and class distribution on the fly, which results in paying more attention to cases that are frequently ignored by classical loss functions. As it is capable of further adaption, it also corrects the biases, decreases the overfitting on the main classes, and remains tolerant to noisy labels, which is the scope of the problems faced by CCE to a great extent. Therefore, AHFE is effective in complex and unequally represented datasets to enhance classification performance, which is a remarkable development in the area of healthcare and other domains involving rare-event detection requiring specific and accurate classification."}, {"title": "V. RESULTS AND DISCUSSION", "content": "This paper proposes a novel loss function for deep-learning frameworks. For our experiment, we have opted to implement our loss function for the classification diabetic retinopathy diseases. We have selected five existing deep learning models to evaluate the performance of the proposed loss function. These deep learning models were trained for 128 epochs, and the performance metrics of these models were recorded and plotted for each epoch."}, {"title": "VI. CONCLUSION AND FUTURE SCOPE", "content": "In conclusion, the present research highlights potential of AHFE Adaptive Hybrid Focal-Entropy Loss function in promoting deep learning models accuracy for diagnosing diabetic retinopathy by overcoming the difficulties such as the class imbalance and the overlapping of classes at different levels of the process. The AHFE loss function is effective in increasing model sensitivity realization across all DR stages that are modeled in the recent architectures such as ResNet50, DenseNet121, Xception and the others. Further research may incorporate the use of more robust augmentation strategies for addressing class imbalance and enhancing the model performance on various datasets. Moreover, the combination of hybrid loss functions with explainable artificial intelligence approaches can help improve the trustworthiness of the model in real life clinical practice."}]}