{"title": "FD-LLM: LARGE LANGUAGE MODEL FOR FAULT DIAGNOSIS OF MACHINES", "authors": ["HAMZAH A.A.M. QAID", "Bo Zhang", "Dan Li", "See-Kiong Ng", "Wei Li"], "abstract": "Large language models (LLMs) are effective at capturing complex, valuable conceptual representa- tions from textual data for a wide range of real-world applications. However, in fields like Intelligent Fault Diagnosis (IFD), incorporating additional sensor data\u2014such as vibration signals, temperature readings, and operational metrics is essential but it is challenging to capture such sensor data information within traditional text corpora. This study introduces a novel IFD approach by effectively adapting LLMs to numerical data inputs for identifying various machine faults from time-series sensor data. We propose FD-LLM, an LLM framework specifically designed for fault diagnosis by formulating the training of the LLM as a multi-class classification problem. We explore two methods for encoding vibration signals: the first method uses a string-based tokenization technique to encode vibration signals into text representations, while the second extracts statistical features from both the time and frequency domains as statistical summaries of each signal. We assess the fault diagnosis capabilities of four open-sourced LLMs based on the FD-LLM framework, and evaluate the models' adaptability and generalizability under various operational conditions and machine components, namely for traditional fault diagnosis, cross-operational conditions, and cross-machine component settings. Our results show that LLMs such as Llama3 and Llama3-instruct demonstrate strong fault detection capabilities and significant adaptability across different operational conditions, outperforming state-of-the-art deep learning (DL) approaches in many cases.", "sections": [{"title": "1 Introduction", "content": "Driven by automation and advanced technologies to maximize productivity and efficiency, modern industrial systems have evolved into highly sophisticated networks with growing complexity that amplifies the risks associated with machine faults. Even minor faults may potentially lead to significant downtime, financial losses, and safety hazards."}, {"title": "2 Related work", "content": "Intelligent Fault Diagnosis (IFD). IFD has been a critical area of research in industrial maintenance, with significant advancements driven by the application of ML and DL-based techniques. Traditional ML-based fault diagnosis methods typically rely on handcrafted features derived from sensor data through signal processing techniques [Wang et al., 2017] and fault identification [Sun et al., 2018] using ML models. Common models used in these approaches include\nsupport vector machine (SVM) [Wu and Meng, 2006, Tang et al., 2010], K-Nearest neighbour (k-NN) [Wang, 2016, Pandya et al., 2013], Na\u00efve Bayes classifier[Zhao et al., 2009, Muralidharan and Sugumaran, 2012], and artificial neural networks (ANN) [Mrugalski et al., 2008, Rafiee et al., 2007]. While these techniques have shown good performance, they are constrained by the quality of feature extraction and the challenges of managing large, complex datasets.\nThe subsequent advent of DL which enabled the automatic extraction of features directly from raw sensor data has led to a paradigm shift in IDF. Convolutional neural networks (CNNs), for instance, have been effectively employed to detect and classify faults by learning spatial hierarchies of features from vibration signals [Zhang et al., 2017, Abdeljaber et al., 2017, Ince et al., 2016]. Recurrent neural networks (RNNs) were used to capture temporal dependencies in the time-series data [Yuan et al., 2016, Zhao et al., 2016]. Despite their success, DL models typically require large amounts of labelled data for training, and they may struggle to generalize across different machines or operational conditions without extensive retraining. Furthermore, as \"black boxes,\" they provide little interpretability.\nRecently, domain adaptation, which aims to improve the performance of DL models when applied to new, unseen domains by transferring knowledge from a source domain (where labelled data is abundant) to a target domain (where labelled data is scarce), has gained increasing attention as a promising method to address the adaptability challenges of DL models in IFD [Zhao et al., 2019]. Several studies have explored domain adaptation in various experimental settings, including Closed-Set Domain Adaptation (CSDA) [Zhang et al., 2022], Partial Domain Adaptation (PDA) [Wang et al., 2022], and Open Set Domain Adaptation (OSDA) [Guo et al., 2022]. While these domain adaptation techniques have shown promise in enhancing the generalization capabilities of DL models, they still face several challenges. While these techniques have shown promise in improving the generalization capabilities of DL models, they still face several challenges. For instance, the success of domain adaptation models often relies heavily on the similarity between the source and target domains; significant differences between them can lead to suboptimal performance. Furthermore, these models may still require retraining or fine-tuning, which can be time-consuming and resource-intensive. Ensuring consistent and stable adaptation of the DL models across varying fault conditions and domains remains a critical challenge for their practical deployment.\nTime Series Data with LLMs. Recently, it has been demonstrated that large language models (LLMs) can be applied to time series or tabular data modeling using techniques such as direct prompting and multimodal fine-tuning [Jin et al., 2024]. Direct prompting involve preprocessing non-textual data into representations that fit the token space of LLMs, incorporating these representations into prompt templates to create the final input, and then feeding the processed input into the LLM to generate responses. On the other hand, multimodal fine-tuning techniques integrate the capabilities of LLMs' text processing with time-series modality, where the text modality serves as task instructions or prompts that describe the time-series modality guiding LLMs to learn representation from the input. Multimodal fine-tuning follows three steps, typically including a pre-processing step where numerical signals are patched and tokenized, followed by a fine-tuning step tailored for general time series tasks or domain-specific applications, and post-processing step responsible for inference of the prediction results.\nIn both techniques, the pre-processing step aims to bridge the modality gap between numerical or sensory data and LLMs input. Spathis et al. [Spathis and Kawsar, 2024] addressed the modality gap between text and numerical data by employing lightweight embedding layers and prompt design. Gruver et al.[Gruver et al., 2023] proposed a highly effective yet simple string-based tokenization method, converting numerical time-series values into text-like representations. Ansari et al. [Ansari et al., 2024] encoded time series into fixed vocabulary using a sequence of reversible steps including scaling and quantization, then trained transformer-based models through cross-entropy loss, achieving strong zero-shot forecasting performance.\nAnother line of studies introduces modality-specific encoding by utilizing lightweight adaptation layers. For example, Time-LLM[Jin et al., 2023] reprogrammed time-series data into the LLMs language space and used text prompts as prefixes, improving LLM performance in forecasting tasks. Likewise, TEST[Sun et al., 2023] resolves embedding inconsistencies by developing a time-series encoder, leveraging alignment contrasts with soft prompts for efficient fine-tuning of frozen LLMs. However, employing modality-specific encoding raises a number of possible issues, including the complexity of multimodal fine-tuning frameworks, the computational cost, particularly when handling long time-series signals, and the possibility of information imbalance, where some modalities may be underrepresented or dominate the model's attention.\nOur work. Our FD-LLM framework is specifically designed for fault diagnosis, through framing the training (i.e., fine-tuning) of existing open-source LLMs as a multi-class classification problem. FD-LLM incorporates two methods for pre-processing vibration signals. In the first method, we apply the Fast Fourier Transform (FFT) to the vibration signals and calculate the magnitudes from the FFT results, generating feature vectors with non-negative values. These vectors are then converted into string-based representations, following the approach outlined by [Gruver et al., 2023]. In the second method, we extract various metrics, including statistical features from the time domain and spectral features from the frequency domain (collectively referred to as statistical features). These features are then summarized in a"}, {"title": "3 Methods", "content": ""}, {"title": "3.1 Problem definition", "content": "We formulate the fine-tuning of large language models (LLMs) as a multi-class classification problem. The objective is to predict the fault type $t \\in T$, where $T = {t_1, t_2, ..., t_k }$ represents the set of possible fault categories, given a set of fault samples $X = {X_1,X_2,...,X_n}$, and their corresponding prompts $P = {P_1, P_2, ...,P_n}$\nIn other words, the task is to train a fault prediction system $llm : (X, P) \\rightarrow T$, where the prediction system $llm$ maps each pair of fault sample $x_i$ and prompt $p_i$ to a predicted fault label $t_i$. This system is to generate a prediction that corresponds to one of the predefined fault categories, expressed mathematically as follows:\n$t_i = llm(I = g(x_i, p_i))$, for $i = 1, 2, ..., n$                                                            (1)\nwhere $g(\u00b7)$ is a function that integrates an input sample $x_i$ and its corresponding prompt $p_i$, generating the final input $I$. Our objective is to leverage both the raw fault data and the additional context provided by the prompts to assess LLMs\u2019 potential in fault diagnosis and investigate whether leveraging machine specification enhances the performance across different work conditions and machine components."}, {"title": "3.2 FD-LLM framework", "content": "Figure 1 illustrates our proposed pipeline for FD-LLM (Fault Diagnosis Large Language Model), designed to assess the health state of mechanical equipment by predicting potential faults based on vibration signals. The process begins with the preprocessing of vibration signals into representative samples, either by applying the FFT or by generating statistical summaries from both the time and frequency domains, thereby preparing the signals for LLM input. These processed samples are then combined with carefully crafted instruction prompts to create the final input for the LLM to analyze and generate predictions for the potential fault types. Specifically, for an input sample $x_i$, which could either be an FFT vector or a row of statistical features, along with the corresponding prompt $P_{i_fft}$ or $P_{i_st}$, the LLM is fine-tuned to analyze the data and output fault type predictions.\nNote that the prompt contains essential contextual information, including equipment specifications (e.g., name, model, geometric parameters) and the machine's operating conditions, such as speed and load. By embedding this contextual information alongside each signal sample in the input prompt, the LLM can utilize both the raw data and the relevant operational details to make accurate fault predictions. Moreover, incorporating such information leads to more robust and reliable diagnostic results by the LLM across various machine components operating under diverse conditions, as it enables the LLM to consider how different operational conditions and machine component types affect performance."}, {"title": "3.2.1 Data pre-processing", "content": "As mentioned, FD-LLM utilizes two methods for pre-processing vibration signals to generate proper time-series representations that are LLM-ready. We discuss these two methods in detail as follows.\n(1) FFT pre-processing. The raw vibration signals are first subjected to random sampling, segmenting each signal into multiple overlapping or non-overlapping windows, each of which is then analyzed to capture its frequency characteristics. The objectives are: (i) to reduce the overall length of the vibration signals, ensuring they do not exceed the LLMs' maximum sequence length (e.g., MISTRAL has a maximum context length of 32k tokens, and Llama3 supports up to 8k tokens) while augmenting the training samples; and (ii) to produce a normalized frequency representation for each segment, which can then be incorporated into the prompt template after a proper encoding.\nGiven a set of time-domain signals ${x^{(j)}(n)}_{j=1}^J$, where $J$ is the total number of signals, we divide each signal into $K$ segments, with each segment having a length of $L$ data points. For instance, if the total length of the $j$-th signal is $N^{(j)}$, we can denote the $k$-th segment of the $j$-th signal as $x_k^{(j)}(n)$, where $n = 0, 1, . . ., L \u2212 1$. For each segment $x_k^{(j)}(n)$, we compute the FFT, which is essentially an efficient implementation of the Discrete Fourier Transform (DFT). The DFT\ncan be expressed mathematically as:\n$X[m] = \\sum_{n=0}^{L-1} x_k^{(j)}(n) e^{-i \\frac{2 \\pi}{L} mn}, m = 0, 1, ..., L - 1$                                             (2)\nwhere $i$ is the imaginary unit.\nWe further compute the magnitude $P_k^{(j)}[m]$ for each FFT coefficient as $P_k^{(j)}[m] = |X_k^{(j)}[m]|$, representing the amplitude of each frequency in the segment. This results in FFT-processed samples that include only positive values, thereby avoiding the need for unnecessary sign tokenization. To ensure consistency across different segments, we scale the magnitudes by dividing by the segment length $L$: $Y_k^{(j)}[m] = \\frac{P_k^{(j)}[m]}{L}$. For each segment $k$ of the $j$-th signal, the output $Y_k^{(j)}[m]$ comprises $L$ normalized values, one for each frequency component $m$. Finally, a set of FFT-processed samples for all signals is obtained and represented as follows:: $y = {y^{(j)}}_{j=1}^J$, where $y^{(j)} = {Y_k^{(j)}}_{k=1}^K$, for $j = 1, 2, ..., J$, and $Y_k^{(j)} = [Y_k^{(j)}[0], Y_k^{(j)}[1], ..., Y_k^{(j)}[L \u2212 1]]$.\nThe FFT-processed samples are subsequently encoded and incorporated into a structured prompt template to include essential machine information, operating conditions, encoded FFT samples, and the corresponding label. The prompt template consists of three main elements: \"instruction\", \"input\", and \"output\", as displayed in Table 1. Please also refer to Figure 2 for a visual illustration of the FFT pre-processing steps using a complete vibration signal.\nInstruction: A prompt $p_{i_fft}$ that integrates an instruction or task query along with the machine specifications {equip-info}, operating conditions (workload {load} hp and rotation speed {speed} rpm) into a cohesive paragraph using the function $f(\u00b7)$ in formula 3.\nInput: This element, represented as $x_i$, consists of the FFT samples, which are transformed into a suitable format for integration into the LLM input through a string encoding function $encode(\u00b7)$, as expressed in formula 4.\nOutput: Captures the corresponding label for each pair of the previous two elements.\n$p_{i_fft} = f(equip\\_info, load, speed, q_{fft})$                                                     (3)\n$x_i^{(j)} = encode(Y_k^{(j)}[0], Y_k^{(j)}[1], . . ., Y_k^{(j)}[L \u2212 1])$                                                     (4)\n$I = g(x_i^{(j)}, p_{i\\_fft})$                                                         (5)"}, {"title": "3.2.2 Time series data encoding", "content": "Each LLM uses a tokenizer to convert input text into a sequence of tokens, a critical process since even small discrepancies can lead to significant changes in model behavior. One common tokenization technique is Byte-Pair Encoding (BPE), which processes input data as bit strings and generates tokens based on their frequency in the training data. However, BPE can sometimes split a single number into multiple tokens that do not align with its individual digits, which can hinder the model's ability to interpret and perform operations on numerical data. As a result, properly encoding time series data into a textual format that ensures accurate tokenization is a crucial step for enabling LLMs to make reliable predictions."}, {"title": "3.2.3 Instruction fine-tuning", "content": "Fine-tuning helps a model to better grasp specific industrial terminologies, fault mechanisms, and operational settings, thereby enhancing its ability to generate accurate and contextually relevant answers in the target task. Instruction tuning [Wei et al., 2021, Ouyang et al., 2022] is a fully supervised fine-tuning technique used to further train LLMs on specific target domains. This approach not only enhances the controllability of LLMs to follow human instructions helpfully and safely but also enables them to adapt their existing knowledge to the nuanced demands of new tasks. In fact, recent studies [Sanh et al., 2021] have shown that instruction-tuned LLMs exhibit strong zero-shot generalizability on unseen tasks, which is a highly valuable trait in industrial fault diagnosis, where limited data and diverse operational conditions pose significant challenges in building a robust, generalized system.\nWe employ Low-Rank Adaptation (LoRA) [Hu et al., 2021], an efficient approach for fine-tuning large models which reduces the computational burden by introducing trainable low-rank matrices into the model's layers. Instead of updating the full weight matrix $W \\in R^{H\u00d7H}$ in each layer, LoRA decomposes the weight update into the sum of a frozen base matrix $W$ and a low-rank matrix $\u2206W$. The decomposition is given by:\n$W' = W + \u2206W$                                                            (10)\nwhere $\u2206W = AB^T$, with $A \u2208 R^{H\u00d7R}$ and $B \u2208 R^{H\u00d7R}$, and $R \u226a H$. During training, only the low-rank matrices $A$ and $B$ are updated, while the original weight matrix $W$ remains frozen, significantly reducing the number of trainable parameters. In the forward pass, the original intermediate calculation $h = W \u00b7 I$ is modified as:\n$h = W \u00b7 I + \u03b1AB^T \u00b7 I$                                                           (11)\nwhere $\u03b1$ is a scaling factor that controls the contribution of the low-rank update $\u2206W = AB^T$. This ensures that the low-rank adaptation integrates smoothly with the pre-trained model, preventing the low-rank update from overpowering the original weights. By freezing the main weights and updating only the low-rank matrices, LoRA achieves efficient fine-tuning with minimal computational overhead."}, {"title": "3.2.4 Post-processing and evaluation", "content": "Since the LLMs produce predictions in natural language, to evaluate the performance of the LLM using standard DL and ML metrics, we map the textual predictions and corresponding true labels into a numerical or categorical format by defining a mapping function $\\phi$ such that:\n$\\phi: text_{out} \\rightarrow \\hat{t}, \\hat{t} \\in T$                                                                  (12)\nwhere $t_{text}$ is the LLM's predicted text, and $\\hat{t}$ is the true label text. Similarly, the true label $t$ is mapped as:\n$\\phi: t_{text} \\rightarrow t, t \\in T$                                                                 (13)\nWe can then evaluate the model's performance by comparing the predicted class $\\hat{t}$ against the true class $t$, using metrics, such as Accuracy (Acc), Precision (Prec), Recall (Rec), F1-Score (F1), and Confusion Matrix (MC)."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Dataset source and tasks", "content": "Dataset: In this study, we use the Case Western Reserve University (CWRU) dataset\u00b9, which includes vibration signals from ball bearings in both healthy and faulty states. Faults were deliberately introduced into the bearings using electro-discharge machining (EDM), generating single-point defects of varying sizes (0.007, 0.014, and 0.021 inches in diameter) on critical bearing components such as the inner race, outer race, and rolling elements. Then, vibration data were systematically recorded via accelerometers mounted at both the drive end and fan end of the motor housing at sampling rates of 12KHz and 48KHz, and under four operational conditions, including motor loads of 0HP, 1HP, 2HP, and 3HP, and speeds ranging from 1797 to 1730 RPM.\nWe use the data collected at a 12KHz sampling rate for both drive end and fan end bearings. The data collected from both the drive end and fan end are pre-processed as described in Section 3.2.1. A single label was assigned to each bearing condition, irrespective of fault size, as shown in Table 2. For instance, all inner race faults with diameters ranging from 0.007 inches to 0.021 inches were grouped under the \"Inner Race Fault\" (IRF) label. The resulting dataset contains four types of faults-Normal (NO), Inner Race Fault (IRF), Outer Race Fault (ORF), and Rolling Element Fault (REF). Additionally, a more detailed dataset was constructed following traditional settings of DL and ML based fault diagnosis, where each fault size is treated as a distinct fault type. The detailed configuration is shown in Table 3.\nTasks: We designed a series of experimental tasks under different settings to comprehensively evaluate the performance of LLMs for fault diagnosis in terms of adaptability to various operational conditions (0HP, 1HP, 2HP, etc.) and generalizability, by analyzing data across different components of the machine (Drive end and Fan end).\nTask 1: Traditional fault diagnosis settings.\nIn this task, we follow the common experimental settings of fault diagnosis. Specifically, we combine the subsets collected from the drive end (0HPDE, 1HPDE, 2HPDE, and 3HPDE) into a dataset named CWRUfft-DE for FFT-processed data and CWRUst-DE for statistically processed data. Similarly, the subsets from the fan end (0HPFE, 1HPFE, 2HPFE, and 3HPFE) are merged into datasets called CWRUfft-FE and CWRUst-FE. For each merged dataset, 10% is reserved for evaluation.\nTask 2: Cross-dataset settings. In this task, we assess the adaptation capabilities of LLMs by conducting domain-specific fine-tuning and cross-domain evaluation as follows. First, we fine-tune LLMs on the data collected under certain operational conditions (source domain). Specifically, we utilize 0HPDE subset collected from the drive end"}, {"title": "4.2 Models", "content": "To fully validate the effectiveness of our FD-LLM on the test dataset, we select three categories of models:\n\u2022 ML Algorithm: For the traditional ML category, we use Support Vector Machine (SVM) which is a widely used ML algorithm in machine health state identification especially for the essential elements of rotating machinery, such as gears, rolling bearings, and motors.\n\u2022 DL Algorithm: For the DL category, we use the one-dimensional convolutional neural network (1D-CNN) model, which is a popular yet efficient DL model used in many fault diagnosis frameworks and has proven its capability of producing accurate predictions. Specifically, we used the WDCNN[Zhang et al., 2017] model after adding minor changes to the network's structure, such as rescaling the kernel size of the first convolutional layer from 64 to 16 and reducing the stride to 2, to meet the length of the samples in our data.\n\u2022 Open-source LLM: For the LLM category, we use four leading open-source LLMs namely, Llama3-8B, Llama3-8B instruct, Qwen1.5-7B, and Mistral-7B. The selection of these models is based on their wide range of applications and their capacities in handling numerical data."}, {"title": "4.3 Settings", "content": "Since both the ML and DL algorithms can only take in numerical data, we used only the statistical data without incorporating any text for the ML algorithm, and only the FFT dataset for the DL algorithm. Although both ML and DL models have the ability to process either FFT or statistical data, our selection is based on best practices and the strengths of each approach: DL models are most suitable for analyzing high-dimensional data like FFT vectors that capture the frequency-domain characteristics of vibration signals, while ML models frequently benefit from compact, high-level statistical features. In contrast, LLMs are able to incorporate both the textual data and the vibration data either in the form of statistical quantities or encoded FFT vectors.\nSpecifically, the hyperparameters used in this study are as follows: batch size 2, LoRA rank 4, cosine lr scheduler, learning rate le-4, bf16, and NVIDIA A10 for all training processes. We trained 3 epochs for all LLMs experiments."}, {"title": "4.4 Metrics", "content": "We employ multiple standard DL and ML evaluation metrics, including Accuracy, Precision, Recall, and F1-Score, to evaluate the LLM's classification performance. For conciseness, we will focus on presenting the accuracy and F1-score in the following discussion, with results for the other metrics provided in Appendix B."}, {"title": "4.5 Results and discussions", "content": ""}, {"title": "4.5.1 Task 1: Traditional fault diagnosis settings", "content": "Table 4 shows the results of the traditional fault diagnosis settings. All models were evaluated using the statistically processed data (CWRUst-DE) and FFT-processed data (CWRUfft-DE) from the drive end, as well as CWRUst-FE and CWRUfft-FE from the fan end.\nStatistically processed data. The evaluation results on the statistical datasets CWRUst-DE and CWRUst-FE reveal significant variations in the performance across different models. Llama3 and Llama3-instruct exhibited relatively satisfactory results on the drive end data (CWRUst-DE), in which Llama3 obtained accuracy and F1-score of 0.9480 and 9420, respectively, and Llama3-instruct demonstrated relatively higher metrics, with an accuracy of 0.9521 and an F1-score of 0.9520. However, on the fan end data (CWRUst-FE), both Llama3 and Llama3-instruct showed a substantial decline in performance, with decreases of 10% and 5% in accuracy, respectively. Moreover, the other LLMs, Qwen1.5-7B and Mistral7B_v0.2 displayed consistently low accuracy and F1-scores, indicating their failure to generalize effectively across both datasets. Additionally, the ML method represented by SVM achieved the best performance on CWRUst-DE but yielded relatively low accuracy and F1-scores on CWRUst-FE.\nFFT processed data. Llama3 and Llama3-instruct achieved perfect fault diagnostic accuracy on FFT-processed data from both the drive end (CWRUfft-DE) and the fan end (CWRUfft-FE). Conversely, Qwen1.5-7B and Mistral7B_v0.2 continued to exhibit low accuracy and F1-scores, demonstrating poor generalization across both datasets. However, DL models, represented by WDCNN, achieved competitive results. These evaluation results demonstrate that FFT-processed data provides richer information from which the models can effectively learn, leading to superior performance in fault diagnosis compared to statistically processed data."}, {"title": "4.5.2 Task 2: Cross-dataset evaluation", "content": "In this task, we conducted a zero-shot evaluation for all models to assess the generalization abilities of LLMs compared to ML and DL-based fault diagnosis models. Specifically, we trained all models on the 0HPDE subset and carried out the evaluation as follows:\n(1) Within the same subset: To evaluate within the same subset, we use 10% of 0HPDE for evaluation following common fault diagnosis experimental settings;\n(2) Across operational conditions: To evaluate within the same machine component (drive end) but across operational conditions (target domains), we assess the models under different operational conditions using subsets from the drive end (1HPDE, 2HPDE, and 3HPDE);\n(3) Across machine components: To evaluate across different machine components (target domains), we evaluate all models using two subsets from the fan end (0HPFE and 1HPFE).\nTables 5 and 6 display the evaluation results of all models using both statistical and FFT-processed data, respectively.\nStatistically processed data: As presented in Table 5, the evaluation results revealed low levels of generalization and adaptability across different target domains for the tested models. This is likely due to the nature of statistical representations, which capture only global properties of vibration signals and may overlook subtle changes or local patterns essential for adapting to different operational conditions. Consequently, the evaluation indicates that statistical representations do not improve the generalization capabilities of LLMs.\n(1) Within the same subset: Llama-3 demonstrated the strongest performance compared to other LLMs, achieving the highest accuracy (97.62%) and F1-score (96.93%) on OHPDE data. Similarly, SVM showed a strong diagnostic performance.\n(2) Across operational conditions: The diagnostic performance of all models dramatically declined as they were exposed to data from increasingly divergent operational conditions. The best accuracy achieved on 1HPDE by SVM is 77.60% and further dropped to 71.30% on 2HPDE."}, {"title": "4.5.3 Task 3: Overall evaluation", "content": "For overall evaluation, we constructed one comprehensive dataset that encompassed all the subsets from the drive end and fan end, using 90% of this dataset for training all models. We then evaluate the models using the remaining 10% of the data. The evaluation was conducted using both statistically processed data (CWRUst-all) and FFT processed data (CWRUfft-all).\nBased on the results presented in Table 7, Llama-3-8B and FF-DM achieved the highest performance, demonstrating strong generalization across both the statistically processed data (CWRUst-all) and FFT processed data (CWRUfft-all). In contrast, models such as Qwen1.5-7B and Mistral7B_v0.2 performed poorly. probably due to their design choices that position them as strong general-purpose models but less specialized for tasks requiring complex numerical data interpretation. Traditional machine learning methods, such as SVM, also did not perform well."}, {"title": "4.6 Ablation study", "content": "We also performed an ablation study to systematically evaluate the influence of different dataset configurations on the performance of LLMs for fault diagnosis. The objective is to understand how various settings and data preprocessing techniques affect the overall effectiveness of LLMs.\nFirst, we investigate the impact of incorporating machine specifications into the input prompts, focusing on the performance of Llama3 and Llama3-instruct. This evaluation is conducted using the comprehensive datasets outlined in Task 3. Specifically, we compare the performance of each model with and without machine specifications included in the input prompts. Then, we examine the effect of dataset labelling configurations. We compare the models' performance using the dataset structure presented in Table 3 with an alternative configuration where only one label per fault is used, regardless of fault size. This helps us understand whether detailed labelling or simplified labelling is more beneficial for fault diagnosis tasks. The evaluation results are as follows:\n\u2022 Impact of Incorporating Machine Specifications: As shown in Table 8, including machine specifications in the input prompts significantly improves the performance of both Llama3 and Llama3-instruct on statistically processed data, yielding a 20% and 11% increase in accuracy, respectively. However, when machine specifi- cations are incorporated into FFT-processed data, the performance gains are less noticeable, as both models already exhibit high accuracy and F1-scores on this data.\n\u2022 Effect of dataset labelling configurations: From Table 9, we found out that detailed labelling of the fault type according to their malfunction size did not significantly impact the performance of LLMs. The models had remained robust, demonstrating that LLMs, besides identifying the faults, can determine the fault severity effectively."}, {"title": "5 Conclusion", "content": "This study presents FD-LLM, a novel framework that bridges the gap between fault diagnosis and advanced language modeling through three key steps: data pre-processing, instruction fine-tuning, and post-processing. In the pre-processing phase, the challenge of aligning vibration signal modalities with LLM input formats was addressed by encoding the vibration signals into text. Two encoding methods were employed: string-based tokenization of FFT-processed signals and statistical summaries derived from both time and frequency domains. The second step involves instruction fine-tuning using LoRA, which allows for efficient adaptation of LLMs to fault diagnosis tasks. In the final post-processing step, the LLM-generated predictions were mapped to numerical labels for the calculation of evaluation metrics in the assessment of model performance.\nOur extensive experiments have validated the effectiveness of FD-LLM in various fault diagnosis scenarios. Models such as Llama3 and Llama3-instruct demonstrated exceptional diagnostic performance in all settings, particularly when utilizing FFT-processed data. These models also exhibited strong adaptability, achieving high accuracy in diagnosing faults under new operational conditions. However, performance was lower when the models were tasked with diagnosing faults across different machine components, revealing a challenge in cross-component generalization.\nIn summary, FD-LLM has showcased the considerable potential of utilizing LLMs for intelligent fault diagnosis across a range of diagnostic scenarios. On the other hand, our experiments have highlighted that future research should focus on enhancing cross-component adaptability to improve the system's robustness and reliability. One promising direction for achieving this would be the incorporation of reasoning intelligence into the fault diagnosis process such as chain-of-thought (CoT) [Kim et al., 2023] or the more fine-grained Process-Supervised Reward Model (PRM)[Ma et al., 2023], which would guide the LLMs through a structured diagnostic process to systematically analyze vibration signals, calculate characteristic fault frequencies step by step, and progressively generate more accurate fault predictions."}, {"title": "A Appendix A. Statistical Features Calculation", "content": "Table 10 presents the features extracted from time and frequency domains and their calculation formulas, where $x_{j,k(n)}$ represents the kth segment from the jth signal. $|X_{j,k(m)}|$ denotes the magnitude of the FFT output, $\\mu_{|x|}$ is the mean (average) value of the magnitudes, and $\\sigma_{|x|}$ represents the standard deviation of the magnitudes."}]}