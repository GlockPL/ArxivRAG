{"title": "LicenseGPT: A Fine-tuned Foundation Model for Publicly Available Dataset License Compliance", "authors": ["Jingwen Tan", "Gopi Krishnan Rajbahadur", "Zi Li", "Xiangfu Song", "Jianshan Lin", "Dan Li", "Zibin Zheng", "Ahmed E. Hassan"], "abstract": "Dataset license compliance is a critical yet complex aspect of developing commercial AI products, particularly with the increasing use of publicly available datasets. Ambiguities in dataset licenses pose significant legal risks, making it challenging even for software IP lawyers to accurately interpret rights and obligations. In this paper, we introduce LicenseGPT, a fine-tuned foundation model (FM) specifically designed for dataset license compliance analysis. We first evaluate existing legal FMs (i.e., FMs specialized in understanding and processing legal texts) and find that the best-performing model achieves a Prediction Agreement (PA) of only 43.75%. LicenseGPT, fine-tuned on a curated dataset of 500 licenses annotated by legal experts, significantly improves PA to 64.30%, outperforming both legal and general-purpose FMs. Through an A/B test and user study with software IP lawyers, we demonstrate that LicenseGPT reduces analysis time by 94.44%, from 108 seconds to 6 seconds per license, without compromising accuracy. Software IP lawyers perceive LicenseGPT as a valuable supplementary tool that enhances efficiency while acknowledging the need for human oversight in complex cases. Our work underscores the potential of specialized AI tools in legal practice and offers a publicly available resource for practitioners and researchers.", "sections": [{"title": "I. INTRODUCTION", "content": "Al-powered software, particularly Foundation Models (FMs) like GPT and LLaMa, is growing rapidly and powering commercial applications such as GitHub Copilot [44] and ChatGPT-4 [63]. However, building AI-powered software involves more than just sophisticated AI models-datasets are crucial throughout the development lifecycle. Consider the commercial software engineering lifecycle proposed for AI-powered software by Amershi et al. [24]. They cover stages such as data collection, cleaning, and model training, yet they do not include legal compliance as a part of it, a critical oversight that can lead to significant legal risks.\nDespite the critical role of datasets, considerations regarding their licenses in AI-powered software development are often neglected. AI models are typically trained on large volumes of publicly available datasets [28, 49, 69]. For example, GPT-3.5 processed 45 TB of public data, filtering it to 570 GB for training [31].\nHowever, many publicly available datasets lack clear licenses, leaving rights and obligations uncertain, particularly concerning commercial use. Longpree et al. [58] shows that over 66% of dataset licenses are misrepresented, often with more permissive terms than intended. Several studies also found widespread misrepresentations stemming from unclear or convoluted license terms, posing legal risks [28, 69]. Recent lawsuits against companies like Google and OpenAI [48, 82] underscore the critical need for accurate dataset license compliance, particularly in commercial settings.\nHowever, stringent compliance with dataset licenses is challenging. These licenses define dataset user's rights and obligations, determining whether datasets can be used for commercial applications or redistribution, and act as software requirements throughout the AI-powered software development lifecycle. Unfortunately, dataset licenses often lack standardized formats and detailed stipulations, posing significant impediments even for software IP lawyers. Publicly available dataset licenses frequently lack the clarity found in open-source software (OSS) licenses. For example, the CIFAR-10 license merely requests citation without specifying rights like the permissibility of using the data for training commercial Al models, while the ImageNet license restricts commercial use but remains ambiguous on the specific conditions under which the data can be used for non-commercial purposes. As Benjamin et al. [28] argue, this ambiguity allows for creative interpretations, such as commercializing the outputs of models trained on ImageNet since the dataset itself isn't used directly in a commercial context.\nMoreover, datasets like ImageNet and CIFAR-10 are compiled from various sources each with its own different licenses, complicating the determination of the overall dataset license. Dataset creators often fail to document original source licenses or consider their impact on the aggregated dataset's license, leading to unclear or potentially unlawful licenses and exposing consumers to risks.\nIn this paper, we shed light on and address the critical challenge of identifying the rights and obligations within a dataset's license. Identifying the rights and obligations with a dataset's license is a crucial yet laborious task, even for software IP lawyers. The complexity arises from the unique challenges posed by the different categories of dataset licenses commonly used in publicly available datasets: General Licenses, Customized Licenses, and Official Terms of Use"}, {"title": null, "content": "or Service. General Licenses, often adapted from OSS formats, present non-straightforward obligations when applied to datasets. Customized Licenses contain highly specific, context-dependent clauses that add complexity. Official Terms of Use or Service are characterized by dense, legally nuanced language and complex technical jargon. Although Montreal Data Licenses [28] and RAIL licenses [76] aim to clarify these issues, they have not been widely adopted, and providers continue to use custom licenses with ambiguous terms. Rajbahadur et al. [69] highlight the need for a systematic and transparent license interpretation tool with expert-in-the-loop capabilities to empower software engineers and IP lawyers in efficiently interpreting and assessing dataset licenses.\nRecently, FMs, particularly, Large Language Models (LLMs) have demonstrated impressive capabilities in text processing [91], including legal documents. Several legal FMs have been developed to comprehend legal literature, primarily offering question-and-answer services [1, 2, 35, 50, 57, 73, 75, 83]. However, these FMs focus on general legal texts, whereas dataset license compliance demands a nuanced understanding of license-specific terminology and context. Effective compliance requires the FM to grasp context-specific conditions, especially with custom licenses containing unique terms.\nTo address these specialized needs, we propose LicenseGPT, a fine-tuned FM specifically tailored for dataset license compliance analysis. We fine-tuned LicenseGPT using a Dataset Licenses (DL) dataset, comprising 500 publicly available dataset licenses collected from platforms like Hugging Face and GitHub, annotated by software IP lawyers. Each license is labeled to indicate whether it permits commercial use, prohibits it, or has ambiguous terms, along with the underlying reasons, associated rights, and obligations. Through the following research questions, we aim to assess the performance and effectiveness of LicenseGPT in improving dataset license compliance analysis compared to existing legal and general-purpose FMs:"}, {"title": "RQ1: How effectively do current legal FMs perform on the task of dataset license compliance analysis?", "content": "Results: The best-performing legal FM, LawGPT, achieves a Prediction Agreement (PA) score of 43.75%, outperforming other legal FMs but with a moderate Semantic Similarity (SS) score of 50.25%. General-purpose FMs like ChatGPT-4 achieve high SS scores but low PA scores, indicating that they produce semantically similar but inaccurate responses in this context."}, {"title": "RQ2: Does LicenseGPT enhance the accuracy of dataset license compliance analysis compared to existing legal and general-purpose FMs?", "content": "Results: LicenseGPT achieves a PA score of 64.30%, surpassing LawGPT by 20.55% and the best-performing general-purpose FM, Qwen-1.5, by 4.58%. This improvement is statistically significant with a large effect size. LicenseGPT also attains a higher SS score of 85.80%, surpassing LawGPT by 35.55%, and Qwen-1.5 by 1%, indicating improved alignment with expert responses."}, {"title": "RQ3: How do software IP lawyers perceive the usefulness of LicenseGPT in dataset license compliance analysis?", "content": "Results: Software IP lawyers found LicenseGPT valuable in practice. Lawyers using LicenseGPT completed analyses in an average of 6 seconds per license, compared to 108 seconds without it, which is a 94.44% reduction in time. While they appreciated the efficiency gains, they also noted the need for careful validation in complex cases and recognized LicenseGPT as a valuable supplementary tool to be integrated into their workflows."}, {"title": null, "content": "To support the community and encourage further research, we have open-sourced LicenseGPT [66]. We also present several recommendations with actionable steps for both software engineering practitioners and researchers. Below, we list the contributions of our paper.\n\u2022 We evaluate existing legal FMs on the task of dataset license compliance analysis and identify their limitations.\n\u2022 We develop LicenseGPT, a fine-tuned FM with a significantly improved accuracy in interpreting dataset licenses.\n\u2022 We conduct a user study with software IP lawyers to assess the practical utility of LicenseGPT in legal workflows.\n\u2022 We open-source LicenseGPT to support the community and encourage further research in this critical area.\n\u2022 We identify immediate challenges in integrating dataset license compliance into AI software engineering lifecycle and provide recommendations to address these issues."}, {"title": "A. Paper organization", "content": "Section II covers the Background and Related Work, including legal protections, compliance challenges, and legal foundation models. Section III describes the Study Design, including our dataset DL, experiment setup, and research questions (RQ1, RQ2, RQ3). Section IV presents the results for each research question. Section V discusses our findings in detail. In Section VI, we address the threats to validity. Finally, Section VII highlights the importance of integrating legal compliance into the AI software engineering lifecycle to enhance software quality and reduce legal risks, emphasizing the need for tools like LicenseGPT alongside human oversight."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "Datasets used in commercial contexts are governed primarily by copyright and contract law, providing significant safeguards across jurisdictions despite specific variations.\nCopyright Law protects creative works from unauthorized use, including copying or reproduction without explicit permission from the copyright holder [61]. Data contained in publicly available datasets may be copyright-protected, and unauthorized commercial use can constitute infringement [28, 68]. While exceptions like the Fair Use doctrine in the United States permit certain uses without permission if they do not cause material harm to the copyright holder, as seen in Authors Guild v. Google [62, 80], other jurisdictions like the UK, Canada, and the EU have stricter regulations. In these"}, {"title": null, "content": "regions, fair dealing exceptions and directives like the EU's Text and Data Mining Directive typically restrict such uses to non-commercial purposes without explicit consent [45, 79]. Consequently, using datasets with copyrighted content for commercial Al-powered software development can lead to legal challenges depending on the jurisdiction.\nContract Law governs the agreements under which copyrighted materials are licensed. Copyright holders can issue licenses detailing the granted rights and required obligations for use. Violating these terms may result in a breach of contract. The precedence of copyright law versus contract law varies by jurisdiction, but contract law enables dataset licenses to permit commercial use without infringing copyright."}, {"title": "B. Challenges in Dataset License Compliance", "content": "The primary goal in evaluating dataset licenses for commercial use is to determine whether a dataset can be utilized in specific scenarios, such as model training or redistribution, while ensuring compliance with the license terms. Compliance is crucial globally, serving as both a functional and non-functional requirement for AI-powered software [30, 51, 54, 88]. When Al-powered software uses publicly available datasets, it implicitly enters into an agreement with the copyright holders, necessitating adherence to the rights and obligations outlined in the license. Failure to comply can result in serious legal risks [30, 51, 54, 88].\nHowever, publicly available dataset licenses often lack clarity regarding usage rights and obligations, making compliance challenging for software engineers [28]. This ambiguity complicates the process of translating license obligations into software requirements, which is critical for maintaining compliance. In situations where legal requirements are unclear, due diligence is essential to avoid breaches [30, 54]. Software engineers must trace rights and obligations from licenses to software requirements, documenting and justifying their interpretations and implementations [30]. Therefore, it is vital for software engineers and software IP lawyers to accurately identify the rights and obligations associated with publicly available datasets.\nAlthough initiatives like the Montreal Data License [28], RAIL licenses [76], and dataset-specific licenses like PDDL [4] and CC BY [34] aim to clarify these issues, they have not been widely adopted. Dataset providers frequently use custom licenses with ambiguous terms, complicating the identification of rights and obligations. Recent studies show that over 66% of publicly available dataset licenses are misrepresented on public platforms, often with more permissive terms than intended by the authors [58]. This misrepresentation is prevalent due to unclear or convoluted license specifications [28, 69]. Additionally, the complexity of data ecosystems, where datasets are built upon other datasets with various sources and licenses, makes tracking data usage and understanding contributions increasingly difficult [27]. This complexity poses significant challenges in ensuring compliance in commercial settings. These challenges highlight the need for automated tools that can assist in accurately"}, {"title": "C. Open Source License Compliance", "content": "The enforcement of open-source licenses under copyright law was established in the landmark case Jacobsen v. Katzer (Fed. Cir. 2008) [3], where violating the terms of an open-source license was ruled to constitute copyright infringement. This set a legal precedent legitimizing and protecting the open-source movement [55].\nFollowing the ruling in Jacobsen v. Katzer, the rise of Open Source Software (OSS) increased attention on license compliance, especially as OSS reuse became prevalent in software development. Researchers and practitioners developed tools and methodologies to detect and resolve license violations [41, 42, 53, 55, 71, 81, 89]. Commercial and open-source tools like BlackDuck [74] and FOSSology [47, 52] are widely used to identify OSS licenses and ensure compliance with intended licensing frameworks. Resources like the Open Source Initiative (OSI) [18], GitHub's licensing guide [17], and TLDRLegal [20] help practitioners understand the rights and obligations of various OSS licenses.\nHowever, methods for OSS license compliance cannot be directly applied to dataset licenses. Publicly available dataset licenses often contain unclear and ambiguous terms regarding commercial use [28, 69]. Therefore, automated approaches for identifying rights and obligations for dataset licenses are needed, and our study addresses this gap."}, {"title": "D. Ensuring legal compliance in commercial software", "content": "Ensuring compliance with legal and licensing requirements is imperative for AI-powered software, as it directly influences user trust and legal viability. While organizations have established Open Source Program Offices (OSPOs) [60] to oversee open-source compliance and governance for traditional software, these offices often aren't equipped to handle the distinct challenges presented by AI-powered software\u2014particularly those related to dataset and model licensing. Consequently, initiatives like OpenChain [65] (ISO 5230 and 18974 standards on open source license and security compliance) have only recently initiated efforts to address these issues by establishing an AI study group [64]. Our paper bridges this gap by highlighting the complexities of dataset license compliance that OSPOs [60] must navigate when releasing AI-powered software. By introducing LicenseGPT, we offer an automated solution to streamline compliance processes, enabling organizations to meet licensing obligations while upholding software quality and reducing legal risks."}, {"title": "E. Legal Foundation Models", "content": "Developing legal FMs involves several key steps. First, we select a suitable base model, such as LLaMA [78], Chinese-LLaMA [36], or ChatGLM [37, 87]. Choosing a robust FM reduces the additional training required for high performance in legal tasks and ensures higher accuracy in a legal context. Next, we perform continual pretraining to adapt the FM to the"}, {"title": null, "content": "legal domain by training on domain-specific data like legal statutes and case law, enriching the model's understanding of legal language and concepts. Then, we apply instruction fine-tuning, refining the FM with specific instructions tailored to legal tasks to ensure it generates outputs that are accurate and aligned with legal professionals' expectations [56]. Finally, we focus on prompt design, carefully crafting inputs including, system prompts, user prompts along with examples to guide the model's output, enabling it to produce relevant and accurate responses in the complex legal domain.\nFollowing these steps, various legal FMs have emerged with unique capabilities tailored to distinct legal contexts. For example, LawGPT_zh (6B) [57] and Lawyer LLaMA (13B) [50] enhance legal text processing, while ChatLaw (13B) [35] integrates external knowledge bases to reduce misinformation. Fuzi.mingcha (6B) [73] and LexiLaw (6B) [1] are developed for case analysis and legal consulting within the Chinese legal framework. HanFei (7B) [83] and Wisdom Interrogatory (7B) [2] focus on integrating intelligent legal systems into judicial practices. Despite these advancements, existing legal FMs are not tailored to dataset license compliance, a specialized challenge requiring additional fine-tuning and customization. Our study fills this gap by developing LicenseGPT, a model that is specifically designed for dataset license compliance analysis."}, {"title": "III. STUDY DESIGN", "content": "In this section, we describe the creation of the dataset that we use in our study to understand the capabilities of the exisiting legal FMs on the task of data license compliance and creating LicenseGPT. Figure 1 presents an overview of our study design including our DL dataset creation process. To create LicenseGPT we required a dataset that includes commonly used publicly available licenses, annotated with information on whether the license permits commercial use, as well as the specific rights and obligations it outlines. Since no such dataset currently exists, we built one from scratch. We detail the steps that we undertook to create our DL dataset below."}, {"title": "Step 1: Dataset License Collection", "content": "We first collected 37, 204 dataset licenses that are associated with publicly available datasets hosted in 10 common machine learning dataset hosting platforms. We collected all the licenses associated with the publicly available datasets hosted on Hugging Face [11], Google Cloud [10], Kaggle [12], Zenodo [16], GitHub [8], GitLab [9], Microsoft Azure [13], DataHub [6], Amazon S3 [5], and Figshare [7]. We also hosted all the collected licenses on the OpenDataology open source project website [14]. It is important to note that the collected licenses encompass all three categories described in Section I: General licenses, Customized licenses, and Official terms of use."}, {"title": "Step 2: Dataset filtering", "content": "We removed the unreadable, expired and duplicated licenses. After such filtering, we were left with 500 valid dataset licenses."}, {"title": "Step 3: Dataset labelling", "content": "We enlisted four software IP lawyers from our company, each with 8, 10, 15, and 20 years of experience, to label each dataset license. The software IP lawyers were instructed to categorize the licenses into three labels: \"allows commercial use,\" \"does not allow commercial use,\" and \"unclear if the license allows commercial use\". Additionally, for licenses that permit commercial use, the lawyers were asked to document the specific rights and obligations associated with the license. For the other two categories, they were instructed to provide reasons for their classifications.\nEach lawyer independently labeled the dataset licenses and provided their recommendations. Following this, we held a meeting where all the lawyers who labeled the licenses discussed their labels and advice. Through this collaborative discussion, we arrived at the final labels and associated guidance for each license. An example label and recommendation provided by the lawyers for CIFAR-10 dataset's license look like label: unclear if the license allows commercial use, recommendation: The provided information suggests referencing a technical report when using the dataset, which details its collection methodology. However, it doesn't specify if commercial use is permitted; such permission usually requires explicit mention in the use agreement or additional licensing. To confirm commercial use rights, one should review the full agreement or consult the dataset's creator."}, {"title": "B. Prompt Design", "content": "For FMs, prompt design is essential for guiding models to generate relevant and accurate responses [49]. Effective prompts not only improve model performance but also ensure precision and adaptability across the given task. In this study, we developed a structured prompt design for both LicenseGPT and the evaluation of existing legal FMs for dataset license comprehension. Following the advice of Hassan et al. [49], we seperated system and user prompt. We follow this modular design to generate legally sound, focused responses, enhancing the models' ability to perform nuanced legal analyses. We provide both the system prompt and user prompt that we used in our online repository [66].\nSystem Prompt Design. System prompts define the model's role and scope. By setting the model to act as a software IP lawyer, we ensure its responses adhere to legal standards. This approach sharpens the model's focus and steers it towards relevant legal expertise. Role Assumption: We assign the model"}, {"title": "C. Zero-Shot Experimentation", "content": "We conducted all experiments under a zero-shot setting, where FMs generate responses without prior examples or task-specific fine-tuning during inference [23, 39]. We chose this approach to ensure that LicenseGPT remains accessible to small companies and academic institutions that may lack proprietary legal analyses even for examples. By focusing on zero-shot performance, we aim to create an open-source tool that can be readily adopted without the need for additional resources or data, making it practical for widespread use."}, {"title": "D. Studied FMs", "content": "In our study, we selected 8 recent state-of-the-art legal FMs (that we disscussed in Section II-E) with parameter sizes ranging from 6 billion to 13 billion. Since all the legal FMs required local hosting, we limited our selection to models with up to 13 billion parameters, excluding larger models. Additionally, we examined 3 state-of-the-art, general-purpose chat-tuned FMs, including ChatGPT-4, LLaMa-2, and Qwen-1.5, which we accessed through third-party APIs,"}, {"title": "E. Studied Performance Metrics", "content": "To evaluate the performance of the studied legal FMs and our proposed LicenseGPT we use the performance metrics in Table III. Of the studied metrics, Prediction Agreement, Duplication Rate and Non-specific Response Rate are computed manually by three of the authors of this paper collaboratively by carefully analyzing each of the model's response and comparing it against the ground truth that is provided by the lawyers involved in the study."}, {"title": "IV. RESEARCH QUESTIONS", "content": "In this Section, we present the approach and results of each of the studied RQs."}, {"title": "A. RQ1: How effectively do current legal FMs perform on the task of dataset license compliance analysis?", "content": "Approach. We collected all the studied performance metrics from each cross-validation run for the studied legal and general-purpose FMs. Specifically, we conducted 10-fold stratified cross-validation on a balanced 10% subset of the DL dataset, ensuring representative coverage of commercial usability labels. We then applied Scott-Knott Effect Size Difference (SK-ESD) [77], similar to clustering, to rank the models based on these metrics. SK-ESD utilizes effect size, computed using Cohen's $\\Delta$ [33], to group statistically similar"}, {"title": null, "content": "models into the same rank. We chose SK-ESD since it is a non-parametric ranking method that yields statistically robust results [49].\nResults. Result 1. LawGPT achieves a 43.75% average Prediction Agreement (PA), outperforming all other studied legal FMs, but has a moderate Semantic Similarity (SS) score. From Table IV, we observe that while LawGPT's PA score is slightly higher than that of Wisdom Interrogatory (43.75% vs. 43.02%) and LexiLaw (40.71%), LawGPT has a lower SS score of 50.25% compared to LexiLaw's 39.06% and Wisdom Interrogatory's 34.36%. This suggests that although LawGPT provides more accurate predictions, its responses are only moderately semantically similar to the expected answers provided by legal professionals.\nMoreover, LawGPT has lower Duplication Rate (DR), Non-Specific Response Rate (NRR), and Average Response Speed (ARS) compared to other legal FMs. Specifically, LawGPT has a DR of 0%, NRR of 0%, and ARS of 1.7 seconds, whereas Wisdom Interrogatory has DR, NRR, and ARS scores of 35.71%, 9.52%, and 20 seconds, respectively. Lower DR and NRR indicate that LawGPT produces fewer duplicated and non-specific responses, enhancing its practical utility. However, the moderate SS score implies that while LawGPT's answers are accurate, they may differ in wording or style"}, {"title": null, "content": "from the ground truth, highlighting an area for potential improvement in aligning its outputs more closely with expert responses.\nResult 2. LawGPT outperforms two out of the three studied general-purpose FMs, including ChatGPT-4, in terms of Prediction Agreement (PA), but has a lower Semantic Similarity (SS) score. Despite its strong performance on legal benchmarks [29], ChatGPT-4 ranks last among all studied FMs in PA for dataset license compliance analysis, with a PA of 18.06%, yet it achieves the highest SS score of 94.80%. Similarly, LLaMA-2 has a PA of 40.28% and an SS score of 92.00%. Only Qwen-1.5 surpasses LawGPT in both PA (59.72%) and SS (83.10%) scores. In contrast, LawGPT has a higher PA of 43.75% but a lower SS score of 50.25%. This discrepancy indicates that general-purpose FMs like ChatGPT-4 and LLaMA-2 produce responses that are semantically similar to the expected answers but may lack accuracy in the specific context of dataset license compliance.\nThese results indicate the need for domain-specific training to achieve responses that are not only semantically similar but also accurate. LawGPT's higher PA score of 43.75% demonstrates better alignment with expert judgments, even though its SS score is lower at 50.25%, indicating that it prioritizes accuracy over similarity in wording or expression."}, {"title": null, "content": "Result 3. LawGPT is the most suitable candidate FM for LicenseGPT. LawGPT has the highest Scott-Knott Effect Size Difference (SK-ESD) rank across all metrics among the studied legal FMs, indicating superior overall performance. Furthermore, LawGPT can be locally fine-tuned without extensive computational resources, making it practical for organizations with limited capabilities. Since the Dataset License (DL) dataset is proprietary and subject to privacy concerns, using a model that allows local fine-tuning mitigates risks associated with third-party FM hosting. Therefore, LawGPT addresses both performance and practical considerations, making it the best candidate for developing LicenseGPT."}, {"title": "B. RQ2: Does LicenseGPT enhance the accuracy of dataset license compliance analysis compared to existing legal FMs?", "content": "Approach. We selected the best-performing legal FM from RQ1 and fine-tuned it using the DL dataset to create LicenseGPT. Similar to RQ1, we conducted 10-fold stratified cross-validation, where during each run, we fine-tuned the selected FM on 9 folds using LoRA [90], known for its efficiency with minimal parameter tuning, ensuring computational efficiency. On average, each fine-tuning operation took 1200 seconds (i.e., 20 minutes). We then evaluated LicenseGPT's performance on the remaining fold.\nTo measure performance differences between LicenseGPT, the best-performing Legal FM from RQ1, and general-purpose FMs, we conducted a Wilcoxon signed-rank test, as it does not assume normality and is suited for paired data. To quantify the magnitude of performance differences, we applied Cliff's delta. The thresholds for interpreting Cliff's delta are: 0 < $\\Delta$ < 0.33 indicates a small difference, 0.33 < $\\Delta$ \u2264 0.66 indicates a medium difference, and $\\Delta$ > 0.66 indicates a large difference. Additionally, we performed Bonferroni correction [38, 72] due to the multiple pairwise comparisons across performance metrics.\nResults. Result 4. LicenseGPT significantly outperforms all studied general-purpose and legal FMs with a large effect size across all studied performance metrics. LicenseGPT achieves a PA score of 64.30%, surpassing LawGPT by 20.55% and the best-performing general-purpose FM, Qwen-1.5, from RQ1, by 4.58%. This improvement is statistically significant with a large effect size.\nFurthermore, LicenseGPT attains an SS score of 85.80%, higher than Qwen-1.5 (83.10%) and LawGPT (50.25%). While ChatGPT-4 and LLAMA-2 exhibit higher SS scores (94.80% and 92.00%, respectively), their low PA scores (18.06% and 40.28%) indicate that they often produce semantically similar but incorrect responses, reducing their reliability for accurate license compliance analysis.\nIn terms of DR and NRR, LicenseGPT maintains a competitive performance with DR of 5.71% and NRR of 3.4%, which are acceptable for practical applications. Although LawGPT has a DR and NRR of 0%, its lower PA and SS scores suggest less accurate and less context-specific responses. LicenseGPT's Average Response Speed (ARS) is 2.40 seconds,"}, {"title": null, "content": "slightly higher than LawGPT (1.7 seconds) but still within a practical range for user interaction.\nTo illustrate the qualitative improvements, Table VI presents example responses from LicenseGPT and other models when interpreting the commercial usability of a dataset licensed under CC BY-NC 4.0. LicenseGPT provides a detailed and accurate analysis, clearly explaining the restrictions and offering actionable guidance, whereas other models provide vague or incomplete responses.\nThese results demonstrate that LicenseGPT enhances the accuracy and reliability of dataset license compliance analysis compared to existing legal and general-purpose FMs, making it a valuable tool for practitioners. However, despite these improvements, a PA of 64.30% indicates that there is still room for further enhancement in model accuracy."}, {"title": "C. RQ3: Do software IP lawyers find LicenseGPT to be a useful tool for expediting dataset license compliance analysis?", "content": "Approach. In RQ3, we evaluate the usefulness of LicenseGPT for software IP lawyers through an A/B test and a user study. We invited the lawyers involved in labeling our DL dataset to assess LicenseGPT using two methods: an A/B test and a structured interview.\nFor the A/B test, we collected 10 additional publicly available datasets and their associated licenses, which were not part of the original DL dataset. The lawyers were divided into two groups. One group used LicenseGPT to perform a dataset license compliance analysis, determining if the dataset's license permitted commercial usage, while the other group conducted the analysis without LicenseGPT.\nIn addition to the A/B test, we conducted semi-structured interviews with the lawyers and applied thematic analysis to their responses. This allowed us to assess LicenseGPT's perceived usefulness and identify areas for improvement.\nA/B Test The A/B test evaluated whether lawyers using LicenseGPT had the same accuracy and improved efficiency during dataset license compliance analysis. Two groups of software IP lawyers participated. In Experiment A, the first group manually annotated the datasets without using LicenseGPT, generating the \u201cLawyer Review Result\u201d as the ground truth. In Experiment B, the second group analyzed the same dataset licenses with the assistance of LicenseGPT, though manual analysis was still involved. The two groups worked independently, and we used the \u201cLawyer Review Result\u201d from Experiment A as the ground truth for comparison. We recorded both the agreement between their judgments"}, {"title": null, "content": "and the time taken for each analysis. This experiment only compared whether both groups reached the same conclusion on the commercial usability of the datasets; we did not assess the agreement in the rationale provided by each group.\nWe evaluated two key aspects: (1) whether the lawyers' determination of the dataset's commercial usability in Experiment B aligned with the ground truth (i.e., PA), and (2) the average time each group took to analyze the commercial usability of the dataset licenses.\nUser Study We designed a questionnaire to capture their insights into LicenseGPT's impact on their legal practice for the four software IP lawyers who participated in our study. We used a semi-structured format for the interviews, encouraging open-ended responses while guiding the conversation with specific questions for consistency. Since all the participating lawyers were from China, we conducted the discussions in Chinese. Below are the translated versions of the questions we asked.\n\u2022 How useful do you find LicenseGPT for completing your dataset license compliance analysis?\n\u2022 What challenges or limitations have you faced with traditional methods of license analysis?\n\u2022 In what ways, if any, has LicenseGPT provided unique advantages over conventional dataset license compliance analysis techniques?\n\u2022 Have you found LicenseGPT to provide faster and more accurate interpretations compared to traditional methods? Can you provide specific examples?\n\u2022 Would you consider using LicenseGPT as an auxiliary tool in future license compliance reviews?\n\u2022 What potential time savings do you foresee when using LicenseGPT alongside traditional dataset license compliance analysis methods?\nWe digitally recorded the feedback and took detailed notes to supplement the recordings. We then conducted a thematic analysis of the responses similar to prior studies [32]. After transcribing and translating the responses into English, two authors independently familiarized themselves with the data by reading through the transcripts and taking initial notes. Both authors then systematically coded the data, labeling key segments related to the research question. After independently coding, they compared and refined their codes, collaboratively identifying recurring patterns and emerging themes. Through multiple meetings, they reviewed and finalized the themes, ensuring they accurately reflected the data and addressed the research questions."}, {"title": null, "content": "Results. Result 5. LicenseGPT significantly reduces the time required for dataset license compliance analysis, enhancing efficiency for software IP lawyers. In our A/B test lawyers using LicenseGPT completed analyses in an average of 6 seconds per license, compared to 108 seconds without the tool a 94.44% reduction in time. This substantial decrease demonstrates LicenseGPT's ability to accelerate the legal review process. Lawyer L1 estimated, \u201cusing LicenseGPT could save me around 50% of the time I normally spend on license compliance analysis,\" highlighting the practical efficiency gains. Similarly, Lawyer L2 noted, \"I believe using LicenseGPT could save me around 40-50% of the time.\" reinforcing the tool's potential to streamline workflows."}, {"title": null, "content": "Result 6. While LicenseGPT enhances efficiency", "LicenseGPT is highly advantageous for quickly filtering through datasets... a more detailed analysis of the license can then be performed.": "uggesting its utility as an initial assessment tool. However", "concerns": "Given the ambiguity in law, using pure Al to assess comprehensive legal risks is too risky. I naturally would not trust AI for standalone use in this field but could consider it as a supplementary tool."}]}