{"title": "Personalized Quantum Federated Learning for Privacy Image Classification", "authors": ["Jinjing Shi", "Tian Chen", "Shichao Zhang", "Xuelong Li"], "abstract": "Quantum federated learning has brought about the improvement of privacy image classification, while the lack of per- sonality of the client model may contribute to the suboptimal of quantum federated learning. A personalized quantum federated learning algorithm for privacy image classification is proposed to enhance the personality of the client model in the case of an imbalanced distribution of images. First, a personalized quantum federated learning model is constructed, in which a personalized layer is set for the client model to maintain the personalized parameters. Second, a personalized quantum federated learning algorithm is introduced to secure the information exchanged between the client and server. Third, the personalized federated learning is applied to image classification on the FashionMNIST dataset, and the experimental results indicate that the personal- ized quantum federated learning algorithm can obtain global and local models with excellent performance, even in situations where local training samples are imbalanced. The server's accuracy is 100% with 8 clients and a distribution parameter of 100, outperforming the non-personalized model by 7%. The average client accuracy is 2.9% higher than that of the non-personalized model with 2 clients and a distribution parameter of 1. Compared to previous quantum federated learning algorithms, the proposed personalized quantum federated learning algorithm eliminates the need for additional local training while safeguarding both model and data privacy. It may facilitate broader adoption and application of quantum technologies, and pave the way for more secure, scalable, and efficient quantum distribute machine learning solutions.", "sections": [{"title": "I. INTRODUCTION", "content": "FEDERATED Learning (FL) [1], an innovative branch of distributed machine learning, has been widely used in edge computing [2], image recognition [3], and medical diagnosis [4], etc. Since FL trains on distributed data, it can alleviate the problem of data island (data is isolated and disconnected within an organization or enterprise) [5]. In the training process of FL, instead of directly transmitting the original data, the gradient or model parameter information is transmitted, which can protect data privacy to a certain extent. However, FL still faces two main problems. On the one hand, due to the heterogeneity of decentralized data, such as label distribution and quantity skew, the accuracy of the federated learning model may be seriously degraded [6]. On the other hand, many attacks on gradients and model parameters make the transmission of information no longer secure, and the privacy of the original data would be threatened. For example, gradient attack can use gradient inversion attack to obtain the original data of the users, and by modifying the model parameters, the attacker would expose more local private data during the training of federated learning [7]. Fortunately, the parallelism inherent in quantum computing and the confidentiality offered by quantum communication have introduced new developmental opportunities for federated learning, leading to the emergence of Quantum Federated Learning (QFL) [8], which has become a significant research field by merging the benefits of Quantum Machine Learning (QML) with the distributed machine learning approach. QFL using quantum circuits or quantum channels, further develops classical FL and brings potential quantum advantages. On the one hand, QML uses the entanglement and superposition characteristics of quantum states to present the parallelism of quantum computing [9], [10], which has the effect of exponential acceleration compared to classical computing [11]. The parameterized quantum circuit with only a few parameters can achieve the effect of classical machine learning models using massive parameters. On the other hand, quantum Internet has the potential to enable secure and private communication [12]. For example, the non-cloning theorem [13] prohibits the replication of an arbitrary unknown quantum state, which helps prevent an attacker from duplicating the quantum state during communication. Due to its high efficiency and security, QFL is suitable for privacy image classification, which is an important task in distributed machine learning. However, there are two problems with privacy image classification based on QFL. One is to strike a tradeoff between the security of privacy images and the accuracy of classification [14], and another is to reduce the negative impact of the non-independent identically distribution (non-IID) of privacy images [15]. In recent years, numerous studies have concentrated on how quantum federated learning can improve the accuracy and security of privacy image classification. In 2021, Li et al. [8] proposed a QFL through blind quantum computing, where differential privacy is used to preserve the training gradient of the privacy images. In 2022, Huang et al. [16] introduced a QFL framework built on the variational quantum algorithm, which achieves high accuracy on the MNIST dataset. In 2023, Song et al. [17] proposed"}, {"title": "II. RELATED WORK", "content": "1) Qubit: Different from the classical bit, a quantum bit (qubit) has the distinguishing characteristic of existing in a superposition state of |0) = [1,0]T and |1) = [0,1]T [20], which can be noted as follows.\n$\\left|\\varphi\\right>=\\alpha\\left|0\\right>+\\beta\\left|1\\right>$,\n(1)\nwhere $\\left|\\alpha\\right|^2 + \\left|\\beta\\right|^2 = 1$. In addition, $\\left|\\alpha\\right|^2$ and $\\left|\\beta\\right|^2$ are the occurrence probability of state $\\left|0\\right>$ and $\\left|1\\right>$, respectively.\n2) Evolution: The quantum system always changes its state over time, which is called as evolution. The evolution process can be mathematically described as:\n$\\left|\\psi_2\\right>=U\\left|\\psi_1\\right>$,\n(2)\nwhere U is a unitary matrix satisfying $U^{\\dagger}U = I$, also called quantum gates.\n3) Measurement: Measurement representing a non-unitary operation is an irreversible process, which is represented by a group of measure operators $M_m$, satisfying $\\sum_m M_m^{\\dagger}M_m = I$. Suppose the quantum system state is $\\left|\\psi\\right>$ before the measure operation, and the probability of measured result m can be calculated as follows:\n$p(m)=\\left<\\psi|M_m^{\\dagger}M_m|\\psi\\right>$.\n(3)\nThe sum of the measured probabilities $\\sum_mp(m)$ equals 1. After measuring the system state, the quantum state collapses into:\n$\\left|\\psi'\\right>=\\frac{M_m\\left|\\psi\\right>}{\\sqrt{p(m)}}$.\n(4)\nIn quantum machine learning [21], Pauli measurement is usually employed to determine the expected value of the current quantum state, and its measurement operator is the Pauli operator like X, Y, and Z gate. The expected value can be calculated as:\n$E = \\left< \\psi | Hams | \\psi \\right>$.\n(5)\nwhere $Hams$ is a Hamiltonian measured by Pauli on certain qubits.\nA Quantum Neural Network (QNN) [22], also called a parameterized quantum circuit built on a recent quantum com- puter, with its parameters optimized on the classical computer, which is shown in Fig. 1. The quantum circuit of QNN can be represented as a series of unitary gates:\n$U_{QNN}(\\alpha, \\theta) = U_{ansatz}(\\theta)U_{encoder}(\\alpha)$.\n(6)"}, {"title": "C. Federated Learning", "content": "Federated learning enables collaborative training among users without exposing local data, resulting in a global machine-learning model. In recent years, research on FL has emerged in an endless stream. J. Konecny et al. [1] initially introduced the idea of federated learning in 2016, and a feder- ated optimization algorithm for distributed data was proposed. In the next year, McMahan et al. [31] introduced the well- known FedAvg algorithm, which established the foundation for FL. In 2023, Sun et al. [32] proposed an efficient federated learning method using an adaptive client optimizer in image classification. In 2024, Peng et al. [33] proposed federated proxy fine-tuning to enhance foundation model adaptation in downstream tasks through FL. Since then, numerous studies have been conducted, exploring various aspects and extensions of federated learning. Among these, personalized federated learning model has attracted attention due to its capability to tailor models to individual client needs, while quantum federated learning is emerging as an innovative approach that leverages quantum computing principles to improve the security and performance of FL.\n1) Personalized Federated Learning: It can be broadly categorized into two types of personalized federated learning: personalized for the global model and personalized for the learning model. The former means that training a global model first, then conducting additional local training on each client's dataset to personalize it. In 2020, Dinh et al. [34] proposed a FL algorithm utilizing Moreau envelopes as the regularized loss functions for clients, which helps utilize the global model in FL to create a personalized model tailored to each client's data. In 2021, Acar et al. [35] trained a meta-model globally, which is later customized locally to suit every device's specific needs. In addition, personalized for the learning model means that creating tailored models by adjusting the FL model aggregation process, accomplished through various learning paradigms in FL. In 2022, Ma et al. [36] introduced a layer- wise FL model, which identifies the significance of each layer from various local clients, thereby optimizing the aggregation for personalized client models with the heterogeneous data. In 2023, Li et al. [37] presented a new transformer-based FL framework that personalizes self-attention for clients, sharing and aggregating other parameters of clients. Xu et al. [38] introduced a personalized FL approach, where explicit local- global feature alignment is achieved by utilizing global se- mantic knowledge to enhance representation learning. The above studies indicate that personalized federated learn- ing can solve the problem of poor convergence of traditional federated learning algorithms on highly heterogeneous data, which is also a challenge faced by QFL.\n2) Quantum Federated Learning: In 2021, Li et al. [8] developed a QFL scheme by utilizing the principles of blind quantum computing, preserving the security of private data and offering valuable guidance in exploring quantum advantages in machine learning, particularly from a security standpoint. In 2022, Huang et al. [16], influenced by the classical feder- ated learning algorithm, proposed the efficient communication learning of variational quantum algorithms from scattered data, known as quantum federated learning, which inspired new research in secure quantum machine learning. In 2023, Waleed et al. [39] introduced an optimized QFL framework aimed at safeguarding intelligent transportation systems and offer- ing enhanced protection against various types of adversarial attacks. However, current quantum federated learning algorithms rarely consider the personalization of federated learning mod- els, especially in personalized learning models. Therefore, we propose a personalized quantum federated learning algorithm to improve the personalization of client model with non-IID images in QFL."}, {"title": "III. PERSONALIZED QUANTUM FEDERATED LEARNING", "content": "Firstly, the server model is a QNN containing an encoder $U_{encoder}(\\alpha)$, an ansatz $U_{base}(\\theta_b)$ where the base layer repeats k times and measurement, which is shown in Fig. 2 (b). The server model can be expressed as:\n$U_{server}(\\alpha, \\theta) = U_{base}(\\theta_b)U_{encoder}(\\alpha)$.\n(7)\nThe structure of the client model is consistent with that of the server, but an additional personalized layer $U_{personal}(\\theta_p)$ as shown in Fig. 2 (c) is added in the ansatz $U_{ansatz}(\\theta)$. The client model is expressed as:\n$U_{client}(\\alpha, \\theta) = U_{ansatz}(\\theta)U_{encoder}(\\alpha) = U_{person}(\\theta_p) U_{base}(\\theta_b) U_{encoder}(\\alpha)$,\n(8)\nwhere $\\theta = (\\theta_b, \\theta_p)$. All clients share the structure and parameters of the common base layer and have unique person- alized layer parameters. When training the model, the client updates the quantum circuit parameters for both the base and personalized layers simultaneously, but only the base layer parameters are uploaded to the server.\nB. Quantum Circuit of PQFL\nThe client encodes the classical information into the ampli- tude of a quantum state.\nThe quantum circuit of the personalized layer can be expressed as:\n$U_{person}(\\theta_p) = \\prod_{i=1}^{z} (RY_i \\otimes RY_i)$.\n(10)\nSo the client model can be represented as:\n$U_{client}(\\alpha, \\theta) = U_{person}(\\theta_p)U_{base}(\\theta_b) U_{encoder}(\\alpha) = (RY_i \\otimes RY_i) \\prod_{i=1}^{k} {\\prod_{i=0,j=(i+1)\\%n}\n[CNOT_{i,j}(RY_i \\otimes RY_{j+1})CNOT_{i,j}](RY_i \\otimes RY_i)}U_{encoder}(\\alpha)$,\n(11)\nThe quantum circuit of the encoding and base layer of the server is consistent with that of the client, and the quantum circuit of the server can be expressed as:\n$U_{server}(\\alpha, \\theta) = U_{base}(\\theta_b)U_{encoder}(\\alpha) = \\prod_{i=1}^{k} {\\prod_{i=0,j=(i+1)\\%n}\n[CNOT_{i,j}(RY_i \\otimes RY_{j+1})CNOT_{i,j}](RY_i \\otimes RY_i)}$.\n(12)"}, {"title": "C. PQFL Algorithm", "content": "Under the assumption that the samples owned by the client are non-IID, and all participants are honest but curious, we introduce the personalized quantum federated learning algo- rithm. Before that, we will introduce the parameter aggregation algorithm, the local training algorithm.\n1) Aggregation: Based on the quantum security aggregation protocol [40], we improve a quantum parameter weighted average algorithm shown in Algorithm 1 for non-IID data, which can prevent disclosing any individual client parameter information.\nSecondly, the server generates N GHZ states [41] $\\left|\\Psi\\right>$ as shown in Eq. (14):\n$\\left|\\Psi\\right> = \\left|\\Psi_0\\right>\\left|\\Psi_1\\right>\\ldots\\left|\\Psi_{N-1}\\right>$,\n(14)\nwhere $\\left|\\Psi_i\\right> = \\frac{1}{\\sqrt{2}}(\\left|0\\right>^{\\otimes M} + \\left|1\\right>^{\\otimes M})$, and N is related to the number of the base layer parameters of the client QNN model. Then the server sends M qubits of each GHZ state, which consists of M qubits, to the M participant clients through the quantum channel. When the client Cm receives one of the qubits of the ith GHZ state $\\left|\\Psi_i\\right>$, it encodes the qubit by applying a revolving gate $RZ(F_m\\theta_{m,i})$ gate. Where $\\theta_{m,i}$ represents the ith parameter in the base layer of the client Cm, and Fm represents the weighted fraction of the client C'm. Other clients perform the same operation on the received qubits and send the encoded qubits back to the server. The ith base layer parameter of all clients is encoded into the GHZ state:\n$\\left|\\Phi\\right> = \\frac{1}{\\sqrt{2}}(\\left|00\\ldots 0\\right> + e^{\\sum_{m=1}^M (F_m\\cdot \\theta_{m,i})}\\left|11\\ldots 1\\right>)$.\n(15)\nThe client Cm then sends the encoded GHZ state $\\left|\\Phi_m\\right>$ to the server through the quantum channel. Then the server decodes the GHZ state, using CNOT gate and H gate to decode the entangled state $\\left|\\Phi_m\\right>$, then the quantum state evolves into:\n$\\left|\\Psi''\\right> = H_1CNOT_{1,2}\\ldots CNOT_{N-1,N}\\left|\\Psi'\\right>$ = $\\frac{1}{\\sqrt{2}}[(1 + e^{\\sum_{m=1}^M (F_m\\cdot \\theta_{m,i})})\\left|00\\ldots 00\\right> + (1 - e^{\\sum_{m=1}^M (F_m\\cdot \\theta_{m,i})})\\left|11\\ldots 1\\right>]$,\n(16)\nThen, as the server measures one qubit, the GHZ state will obtain |0) with the probability of $P_r = \\frac{1}{2}(1 + cos(\\sum_{m=1}^M (F_m\\cdot \\theta_{m,i})))$. By repeating this process, the server will get the estimations of $\\sum_{m=1}^M (F_m\\cdot \\theta_{m,i})$, which is calculated as follows:\n$\\sum_{m=1}^M (F_m\\theta_{m,i}) = arccos(2P_r - 1)$.\n(17)\nIn this way, the server gets the weighted average of the ith parameter in the base layer of all clients:\n$\\theta_i = \\sum_{m=1}^M (F_m\\theta_{m,i})$.\n(18)\nIn this training round, the client performs the same operations as above for other parameters in the base layer. Thus, the server gets the weighted average aggregated parameters of all clients:\n$\\theta = (\\theta_0, \\theta_1,\\ldots,\\theta_N) = (\\sum_{m=1}^M (F_m\\theta_{m,0}), \\sum_{m=1}^M (F_m\\theta_{m,1}),..., \\sum_{m=1}^M (F_m\\theta_{m,N}))$,\n(19)\nwhere $\\theta_{m}$ represents the base layer parameters of client Cm.\n2) Local Training: The local training algorithm can be described as Algorithm 2. Dirichlet distribution is used to simulate the non-IID samples of the clients. The probability density function of the Dirichlet distribution is defined as follows:\n$f(\\theta_1,...,\\theta_L; \\alpha_1,..., \\alpha_L) = \\frac{1}{B(\\alpha)} \\prod_{i=1}^L \\theta_i^{\\alpha_i-1}$,\n(20)"}, {"title": "IV. EXPERIMENTS AND ANALYSIS", "content": "The experiments are conducted using the hardware device of Intel Core i7-9700 and the Mindspore quantum library is used for the experiment. The experimental outcomes indicate that the personalized quantum federated learning algorithm we proposed is capable of achieving high accuracy in binary classification tasks involving clothing images while securing the privacy images and models. Next, the accuracy, security, and communication overhead of private image classification schemes based on personalized quantum federated learning are analyzed. The hyperparameter settings of the experiment are shown in Table II. For concreteness, we conduct a classi- fication task about classifying images \u201ctrouser or ankle boot\u201d in the FashionMNIST dataset, which is a clothing dataset consisting of 10 categories with a total of 70000 grayscale images and 60,000 samples for training and 10,000 samples for testing. An original 28 \u00d7 28 image is preprocessed into a 4 \u00d7 4 image according to Fig. 7.\nWe perform the training process using Dirichlet distribution parameters $\\alpha$ = 1, 10, 100.Table III shows that the server model in PQFL can achieve higher accuracy on the FashionMNIST dataset than the model without personalized layer in most settings. In particular, the model accuracy of the server can achieve 100% when the distribution parameter $\\alpha$ = 100 and the clients quantity is 8. As the distribution parameters and the clients quantity increases, the server model's accuracy remains relatively sta- ble, indicating that the proposed PQFL model is robust to variations in distribution parameters and clients quantity.Table IV demonstrates the average model accuracy of clients in PQFL is higher than that without personalized layer in the most settings. Further, we can see that when $\\alpha$ is constant, the average accuracy improves as the clients quantity increases. Fig. 8 shows the accuracy of client models with personaliza- tion layer is generally higher on the testset compared to those without personalization layer. This indicates that the client models are more personalized than the global model based on the experimental results."}, {"title": "C. Convergence Analysis", "content": "We carry out experiments involving 2, 4, and 8 clients in the training process. By minimizing the loss function, the model parameters stabilize and achieve optimal performance, leading to model convergence. Fig. 9 illustrates the convergence speed of the loss function for the following three scenarios to assess the convergence of the PQFL algorithm:\n(1) With personalized layer. The proposed PQFL algorithm includes a client model with both the base layer and a personalized layer, while the server only contains the base layer.\n(2) Without personalized layer. A quantum federated learn- ing where the server and client models only include the base layer and do not include the personalized layer.\n(3) Without federated learning. Training on a quantum neural network with only the base layer.\nIt suggests that the PQFL algorithm successfully converges while consistently achieving comparable performance in the other two scenarios.\nD. Overhead Analysis\nThe overhead of the PQFL algorithm consists of both communication and computation overhead.For the server, 4nk base layer parameters need to be encoded into the quantum state and sent to the M clients. The total qubits sent from sever to M clients in N global training rounds is 4nkNM. Suppose performing an encoding or decoding operator costs $t_c(\\sim 2.5\\times10^{-8}s)$ [42], and transmitting a qubit from the server to the client through the quantum channel costs $t_n(\\sim 10^{-3}s)$ [43], the downlink time of training N rounds is:\n$T_{down} \\approx 4nkNt_c + 4nkNMt_c + Nt_n = 4nkNt_c(M + 1) + Nt_n$.\n(30)\nFor a client, there are 4nk base layer parameters that need to be encoded into the quantum state and sent to the server. The total qubits sent from a client in N global training rounds is 4nk N. The uplink time of training N rounds is:\n$T_{up} \\approx 4nkN2t_c + Nt_n = 8nkNt_c + Nt_n$.\n(31)\nThe computation overhead of the server and client"}, {"title": "E. Security Analysis", "content": "The participants in this scenario are semi-honest, that is to say, the client involved in training and the central server responsible for aggregation will honestly follow the commu- nication protocol, but they will both try to extract as much information as possible from the data transmitted during the interaction.\nsary can not obtain the model parameters and privacy images of clients.Proof. If the external adversary wants to obtain private information about the server and clients, he has to copy quantum states, otherwise, the model parameters encoded in quantum states can not be obtained by the adversary. The quantum non-cloning theorem states that it is infeasible to exactly duplicate an unknown quantum state, which means an external attacker can not copy a quantum state without being discovered by the server and clients. Suppose an external adversary can copy a quantum state $\\left|\\phi\\right>$ by performing a unitary $U_{copy}$ on |0), which can be denoted as:\n$U_{copy}\\left|\\phi\\right>\\left|0\\right> = \\left|\\phi\\right>\\left|\\phi\\right>$.\n(33)\nGiven two quantum states $\\left|\\psi_1\\right>$ and $\\left|\\psi_2\\right>$, it can be obtained by:\n$U_{copy}\\left|\\psi_1\\right>\\left|0\\right> = \\left|\\psi_1\\right>\\left|\\psi_1\\right>$,\n$U_{copy}\\left|\\psi_2\\right>\\left|0\\right> = \\left|\\psi_2\\right>\\left|\\psi_2\\right>$.\n(34)\nIf the external adversary wants to copy an arbitrary quantum superposition state $\\left|\\psi\\right> = c_1\\left|\\psi_1\\right> + c_2\\left|\\psi_2\\right>$, where $\\left|c_1\\right|^2 + \\left|c_2\\right|^2 = 1$, using the operator $U_{copy}$, the expected result should be:\n$U_{copy}\\left|\\psi\\right>\\left|0\\right> =\\left|\\psi\\right>\\left|\\psi\\right> = (c_1\\left|\\psi_1\\right> + c_2\\left|\\psi_2\\right>)(c_1\\left|\\psi_1\\right> + c_2\\left|\\psi_2\\right>) =c_1^2\\left|\\psi_1\\right>\\left|\\psi_1\\right> + c_1 c_2 \\left|\\psi_1\\right>\\left|\\psi_2\\right> + c_2 c_1 \\left|\\psi_2\\right>\\left|\\psi_1\\right> + c_2^2 \\left|\\psi_2\\right>\\left|\\psi_2\\right>$.\n(35)\nHowever, the result can be also calculated as follows:\n$U_{copy}\\left|\\psi\\right>\\left|0\\right> = U_{copy}(c_1\\left|\\psi_1\\right> + c_2\\left|\\psi_2\\right>)\\left|0\\right> = (c_1U_{copy}\\left|\\psi_1\\right> + c_2U_{copy}\\left|\\psi_2\\right>)\\left|0\\right> = c_1\\left|\\psi_1\\right>\\left|c_1\\right> + c_2\\left|\\psi_2\\right>\\left|\\psi_2\\right>$.\n(36)\nThe results from Eq. (35) and Eq. (36) are conflicting, so the unitary operator $U_{copy}$ that can copy any quantum state does not exist. This means that an external attacker can not copy the quantum state transmitted between the server and the client, so the model parameters cannot be measured. In addition, the clients' privacy images are only retained locally and are not transmitted, so external attacks can not reverse the privacy images through the model parameters, too.\nalgorithm has high security which can resist both external attacks and internal attacks."}, {"title": "V. CONCLUSION", "content": "To address the issue of lack of personalization on the clients, this paper presents a PQFL algorithm, and applies it to privacy image classification. The personalized layer of the QNN model of the clients can help the client obtain a personalized model even with the non-IID data. The quantum parameter weighted average aggregation algorithm secures both the global and local models as well as the privacy data. The experimental results demonstrate that the proposed PQFL algorithm is capa- ble of classifying the privacy images effectively and make the client model more personalized, ensuring the data privacy and security at the same time. With the continuous development of quantum hardware, the proposed personalized quantum federated learning model promotes the further development of distributed quantum machine learning and holds potential for broader applications in fields, ranging from healthcare and finance to communication and cybersecurity, ultimately shaping the landscape of quantum artificial intelligent systems."}]}