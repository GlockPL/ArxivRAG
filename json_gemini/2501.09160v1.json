{"title": "AutoLoop: Fast Visual SLAM Fine-tuning through Agentic Curriculum Learning", "authors": ["Assaf Lahiany", "Oren Gal"], "abstract": "Current visual SLAM systems face significant chal-lenges in balancing computational efficiency with robust loopclosure handling. Traditional approaches require careful manualtuning and incur substantial computational overhead, whilelearning-based methods either lack explicit loop closure capa-bilities or implement them through computationally expensivemethods. We present AutoLoop, a novel approach that combinesautomated curriculum learning with efficient fine-tuning forvisual SLAM systems. Our method employs a DDPG (DeepDeterministic Policy Gradient) agent to dynamically adjustloop closure weights during training, eliminating the need formanual hyperparameter search while significantly reducing therequired training steps. The approach pre-computes potentialloop closure pairs offline and leverages them through an agent-guided curriculum, allowing the model to adapt efficientlyto new scenarios. Experiments conducted on TartanAir fortraining and validated across multiple benchmarks includingKITTI, EUROC, ICL-NUIM and TUM RGB-D demonstrate thatAutoLoop achieves comparable or superior performance whilereducing training time by an order of magnitude compared totraditional approaches. AutoLoop provides a practical solutionfor rapid adaptation of visual SLAM systems, automating theweight tuning process that traditionally requires multiple manualiterations. Our results show that this automated curriculumstrategy not only accelerates training but also maintains orimproves the model's performance across diverse environmentalconditions.", "sections": [{"title": "I. INTRODUCTION", "content": "VISUAL SLAM systems have become fundamental com-ponents in autonomous navigation and robotics appli-cations, with recent learning-based approaches demonstratingimpressive performance in challenging scenarios. However,integrating loop closure capabilities into these learned systemstypically requires extensive retraining or complex architecturalmodifications. This is particularly evident in state-of-the-artmethods like DPVO, which excel at frame-to-frame trackingbut lack explicit loop closure handling. We present AutoLoop,an efficient approach for enhancing learned visual SLAMsystems with loop closure capabilities through automatedcurriculum fine-tuning. Our method leverages pre-computedloop closure pairs and a DDPG-based curriculum learningagent to rapidly adapt existing models while maintainingtheir core performance. By combining offline loop detectionwith automated weight adjustment, we achieve significantreductions in training time and computational requirementscompared to traditional approaches. The key contributions ofour work include:\n\u2022 An efficient pre-computation pipeline for identifying andverifying loop closure pairs using a hybrid NetVLAD-SIFT approach.\n\u2022 A DDPG-based curriculum learning strategy that auto-matically adjusts loop closure loss weights during fine-tuning.\n\u2022 A targeted fine-tuning approach that reduces trainingsteps by an order of magnitude while maintaining per-formance.\n\u2022 Comprehensive evaluation on standard benchmarksdemonstrating improved loop closure handling with min-imal computational overhead.\nThis work addresses a critical gap in learning-based SLAMsystems by providing an efficient and automated methodfor incorporating loop closure capabilities, making advancedvisual SLAM more accessible for real-world applications."}, {"title": "II. BACKGROUND", "content": "Traditional visual SLAM systems like ORB-SLAM3 [1]and VINS-Mono [2] rely on hand-crafted features and op-timization techniques for pose estimation and loop closure.Recent learning-based approaches, including DPVO [3] andDeepV2D [4], have demonstrated superior performance inchallenging scenarios by leveraging deep neural networksfor feature extraction and matching. However, these learnedsystems often lack explicit loop closure handling, focusingprimarily on frame-to-frame tracking accuracy. While DPV-SLAM [5] extends DPVO with proximity-based loop closuredetection, it incurs computational overhead and additionalmemory requirements due to its keypoint detector.\nLoop closure detection has been extensively studied inclassical SLAM systems. DBoW2 [6] and VLAD-based ap-proaches [7] have been widely adopted for place recog-nition, while NetVLAD [8] introduced learned descriptorsfor improved robustness. Recent works like SuperGlue [9]and LoFTR [10] have explored learned feature matching forgeometric verification, though their integration into end-to-end SLAM systems remains challenging due to computationalconstraints."}, {"title": "III. METHODOLOGY", "content": "Our approach consists of three main components: (1) anefficient loop closure detection pipeline for pre-computingpotential loop pairs, (2) a DDPG-based curriculum learningagent for automated weight adjustment, and (3) a fine-tuningstrategy that leverages pre-computed loops and curriculumlearning to rapidly adapt DPVO models. We build upon theDPVO architecture, which provides state-of-the-art perfor-mance in visual odometry through its dense feature extractionand matching capabilities. The system is primarily developedand validated on the TartanAir dataset, which is particularlysuited for loop closure learning due to its rich variety ofrevisited locations under different viewing angles, lightingconditions, and seasonal changes. These naturally occurringloop closure scenarios, combined with accurate ground truthposes, provide an ideal training environment for our approach.For evaluation, we test on standard benchmarks includingKITTI [23], EuRoC [24], ICL-NUIM [25] and TUM RGB-D [26] datasets to demonstrate generalization capabilities."}, {"title": "A. Off-Line Loop Closure Database", "content": "To create a reliable ground truth database for fine-tuningour visual odometry model with loop closure constraints weuse construct an offline loop closure detection pipeline (Figure1). The system processes visual sequences from the TartanAirdataset through a three-stage architecture to identify and vali-date loop closure pairs. First, a global descriptor module basedon EfficientNet-VLAD generates compact representations ofeach frame, enabling efficient similarity-based retrieval ofloop closure candidates. Second, a geometric verification stagevalidates these candidates using local feature matching andepipolar geometry constraints, ensuring spatial consistency. Fi-nally, a database construction module aggregates the validatedloop closures, storing frame pairs along with their confidencemetrics in a structured format.\nThis offline approach allows for exhaustive loop closure de-tection without real-time constraints, creating a robust groundtruth database. The resulting dataset serves as supervisionduring the fine-tuning phase of our visual odometry model,where loop closure constraints are incorporated into the train-ing loss function to enhance the model's capability for globallyconsistent trajectory estimation. This decoupled architectureseparates the computationally intensive loop closure detectionfrom the training process while ensuring high-quality supervision for the learning task."}, {"title": "B. Baseline Model", "content": "As our baseline model architecture, we use the Deep PatchVisual Odometry (DPVO) model, introduced in [3]. DPVOis particularly well-suited for our loop closure enhancementapproach due to its modular loss structure, which can bereadily extended to incorporate additional supervision signals.The model's existing decomposition into pose estimation andoptical flow components provides a natural framework forintegrating loop closure constraints without disrupting the corevisual odometry capabilities. DPVO's end-to-end trainablenature allows us to smoothly incorporate the loop closure lossduring fine-tuning while preserving the model's fundamentaltrajectory estimation abilities"}, {"title": "C. DPVO Loss Supervision", "content": "The DPVO loss function is carefully constructed to balancethe contributions of pose estimation and optical flow predictionthrough weighted supervision terms. The total loss comprises"}, {"title": "D. Loop Closure Aware Loss", "content": "Our methodology modifies DPVO's training objective byadding a loop closure loss component to the original lossfunction. This additional component enables the model to learnfrom loop closure constraints while maintaining its core visualodometry capabilities.\n$L_{total} = s_fL_{flow} + s_pL_{pose} + W_{loop} L_{loop}$\n$s_f,s_p$ are the scaling factors introduced in the originalDPVO loss function (1). where $W_{loop}$ is the weight of theloop closure loss component. Definition of the $W_{loop}$ is criticalto the performance of the overall training process. We defineloop closure loss as the sum of the relative transformationerrors between each predicted pose and its corresponding pre-calculated pairs. For a given frame's predicted pose $T_{pred,i}$, theloss aggregates the relative transformation errors with all itsvalid pre-calculated loop closure pairs $G_{gt,j}$.\n$L_{loop} = \\frac{1}{N} \\sum_{i,j} h_s(||Log_{SE(3)}(T_{pred,i} \\cdot G_{gt,j})||)$\nWhere N is the total number of valid loop closurepairs and $h_s(x)$ is the Huber loss function defined as:\n$h_s(x) = \\begin{cases} \\frac{1}{2}x^2 & \\text{if } |x| \\leq \\delta \\\\ \\delta |x| - \\frac{1}{2}\\delta^2 & \\text{otherwise} \\end{cases}$\nThe huber loss addresses two critical aspects: providing pre-cise gradients for fine-tuned corrections when errors are small,while preventing gradient explosion from potentially incorrectloop closure pairs or challenging viewpoint changes whenerrors are large. This balanced approach ensures stable andeffective learning from geometric constraints while remainingrobust to noise in the loop closure pairs."}, {"title": "E. Agentic Curriculum-Learning", "content": "The DPVO framework employs an adaptive curriculumlearning strategy using a Deep Deterministic Policy Gradient(DDPG) agent to dynamically adjust the loop closure lossweight during training. Unlike traditional fixed or manuallyscheduled weights, the DDPG agent learns to optimize theloop closure weight based on the training dynamics and currentmodel performance. The agent observes the current loss valuesand training progress as its state, and outputs a continuous action representing the loop weight adjustment. This approach isparticularly valuable for loop closure supervision because theimportance of loop closure constraints can vary significantlydepending on the training stage and scene characteristics.\n$W_{loop}^{i+1} = w_0 + (w_f - w_0)a_i$\n$L_{ema} = \\alpha L_{ema} + (1 - \\alpha) |L_{LOOP}|$\n$s_i = [p_i, L_{ema}]; r_i = -L_{ema}$\n$a_i = \\mu_{\\kappa}(s_i) + \\eta_i$\nThe DDPG agent in this code operates on a 2-dimensionalstate space that combines the training progress $p_i \\in [0,1]$and the smoothed loss value $L_{ema}$. For each training step, itoutputs a single action value that determines how to interpolatebetween initial and final weights (5). The agent learns fromexperience by storing transitions of (state, action, reward, nextstate) tuples, where the reward $r_i$ is simply the negative ofthe smoothed loss. This setup allows the agent to adaptivelyadjust curriculum weights based on both the training progressand current performance, effectively learning an optimal progression path that minimizes loop closure loss during training.\nThis adaptive weighting is particularly crucial during fine-tuning, as it helps prevent catastrophic forgetting of theoriginal model's capabilities while gradually introducing loopclosure supervision. The DDPG agent learns to modulate theimportance of loop closure constraints based on the model'scurrent adaptation state, ensuring that the geometric consis-tency is enhanced without compromising the fundamental poseestimation accuracy developed in the original training."}, {"title": "F. Loop Closure Aware Fine-Tuning", "content": "We leverage the pre-computed loop closure pairs to fine-tune the DPVO model. During training, we specifically focuson sequences containing verified loop closures, ensuring effi-cient learning of loop closure handling. Our sampling strategyselects trajectories where our pre-computation pipeline hassuccessfully identified loop pairs, as these sequences providethe necessary supervision for both standard pose estimationand loop closure scenarios. This targeted approach ensures thateach training iteration contributes meaningfully to enhancingthe model's loop closure capabilities while maintaining itscore visual odometry performance. The DDPG agent dynam-ically modulates the loop closure weight $W_{loop}$ , typicallyinitializing at conservative values (0.1-0.2) and progressivelyincreasing based on model stability and performance. Thispre-computation strategy offers multiple benefits: it eliminatesthe computational burden of online loop detection duringtraining, ensures consistent supervision through verified loopclosure pairs, and enables efficient batch processing of loopconstraints.\nConsequently, our approach strive to achieve effective inte-gration of loop closure capabilities into the DPVO frameworkwith high efficiency and autonmous agentic weight tuning,requiring only a fraction of the training time and resourcesneeded for training from scratch."}, {"title": "IV. EXPERIMENTS", "content": "We evaluate our methodology on EuRoC MAV [24], KITT [23] odometry benchmark, TUM RGB-D [26], ICL-NUIM[25] dataset and TartanAir test set from ECCV 2020 SLAMcompetition. Each experiment is run 5 times and we reportthe median result. We compare our AutoLoop method to bothpure VO and SLAM variants. Given AutoLoop's VO-basedarchitecture, it offers dual functionality: it can operate as apure VO model, potentially serving as a drop-in replacementin existing SLAM pipelines, or function as a standalone systemwith loop closure capabilities. All experiments were conductedon an NVIDIA DGX-1 computing node equipped with 8 V100GPUs, enabling parallel processing and rapid validation acrossour methodological variants."}, {"title": "A. Pre-compute Loop Closure Pairs", "content": "Our loop closure pipeline implementation employs severalcritical parameters that govern its loop closure detection be-havior. The system maintains a circular buffer of the mostrecent 2000 frames for potential loop closure candidates. Toidentify revisited locations, we utilize a similarity metric witha threshold of 0.75, where higher values indicate strongermatches between frame descriptors. The NetVLAD descriptoris configured with 32 cluster centers, offering a good trade-offbetween descriptor discriminability and computational over-head. For robust geometric verification, we require a minimumof 30 inlier feature matches between candidate frame pairsto confirm a valid loop closure, effectively filtering out falsepositives while maintaining high recall.\nThe offline pre-compute on TartanAir produced 551 loopclosure pairs."}, {"title": "B. Fine Tuning", "content": "During DPVO fine tuning we use only those sequences thatcontain loop closure pairs. The sampled trajectories includesboth frames with loop closure pairs and frames without,ensuring all loss signals (pose, flow, loop) are present.\nAdaptive Weighting: Our RL DDPG agent is structured as in[27] with three-layer actor/critic networks (max width of 64).Since we use smaller dataset we reduce the agent trainingfrequency to every 30 global DPVO training steps comparedthe CL-DPVO-RL-DDPG approach [27], using batch size of64 samples from a 5k-sized replay buffer. Figure 3 shows theloop weight progression during fine tuning. A short explorationstage (till step 200) is followed by convergance to 0.62 as themodel start overfitting after step 420."}, {"title": "C. Benchmarks Comparison", "content": "KITTI [23]: We evaluate our AutoLoop model on sequences00-10 from KITTI training set. showsimprovement in avarage ATE on both DPVO and its proximityloop closure variant DPV-SLAM while still maintaining thehigh FPS of DPVO (visual odometry only). Compared toDPV-SLAM++, which is the DPVO based SLAM variat thatcombine both proximity and classic loop closure, we sucrificeATE performance for a large increase in FPS. on sequences01, 04 we show best overall performance.\nTartanAir Test Split [30]: We compare our AutoLoop modelswith state-of-the-art (SOTA) methods on the TartanAir test-split from the ECCV 2020 SLAM competition, includingimproved image and event mixture VO methods [31]. TheAutoLoop achives comparable results to the best in class CL-DPVO (0.13 vs 0.12) outperforming other SLAM methodssuch as DROID-SLAM and DPV-SLAM (0.24,0.16 vs 0.13)which incorporate the computational overhead of SLAM op-timization and loop closure.\nEuRoC MAV [24]: When comparing AutoLoop to bothVO and SLAM methods on Machine-Hall and Vicon 1 &2 sequences from the EuRoC MAV dataset it struggle togenerelaize well its loop closure capabilities to the indoorcharacteristics of the dataset. It underperforms the CL-DPVO"}, {"title": "D. Computational Analysis", "content": "AutoLoop presents major computational benefits over VOand SLAM methods. Since its core methodology is based onfine tuning established VO model while incorporating loopclosure capabilities during training it elimenates the overheadof training and tunning other methods from scratch or usingSLAM optimization computational resources. Here we make"}, {"title": "V. CONCLUSION", "content": "We have presented AutoLoop, an efficient approach forenhancing learning-based visual SLAM systems with loopclosure capabilities through automated curriculum fine-tuning.Our method demonstrates that effective loop closure handlingcan be integrated into existing architectures like DPVO withsignificantly reduced computational overhead and trainingtime. By leveraging pre-computed loop closure pairs andDDPG-based curriculum learning, we achieve comparable orbetter performance while requiring only 3,360 training steps,a 90% reduction compared to traditional training approaches.The key advantages of our approach extend beyond com-putational efficiency. The pre-computation of loop closurepairs ensures reliable supervision during training, while theautomated curriculum learning eliminates the need for man-ual hyperparameter tuning. This automation makes the in-tegration of loop closure capabilities more accessible andreproducible, addressing a significant practical challenge indeploying learning-based SLAM systems. Our experimentalresults demonstrate both the strengths and limitations of ourapproach across different environments. The method showsimpressive performance improvements on challenging outdoorsequences from TartanAir [30] and KITTI [23], validatingits robustness across various environmental conditions andmotion patterns. However, we observed limited generalizationto indoor datasets like TUM-RGBD [26] and EuRoC MAV[24], likely due to the distinct characteristics of indoor loopclosures not well represented in our pre-computed trainingpairs. Despite these domain-specific limitations, our approachmaintains real-time performance while adding loop closurecapabilities, making it particularly suitable for outdoor roboticsapplications where computational efficiency is crucial\nFuture work could explore extending this methodology toother learning-based SLAM architectures and investigatingthe potential for online adaptation of loop closure handling.Additionally, the principles of our automated curriculum learn-ing approach could be applied to other aspects of SLAMsystem training, potentially leading to further improvements inefficiency and performance. We believe this work representsa step toward making advanced visual SLAM capabilitiesmore accessible and practical for real-world applications,particularly in resource-constrained scenarios where efficienttraining and deployment are crucial."}]}