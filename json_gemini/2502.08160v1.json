{"title": "Vertical Federated Learning in Practice: The Good, the Bad, and the Ugly", "authors": ["Zhaomin Wu", "Zhen Qin", "Junyi Hou", "Haodong Zhao", "Qinbin Li", "Bingsheng He", "Lixin Fan"], "abstract": "Vertical Federated Learning (VFL) is a privacy-preserving collaborative learning paradigm that enables multiple parties with distinct feature sets to jointly train machine learning models without sharing their raw data. Despite its potential to facilitate cross-organizational collaborations, the deployment of VFL systems in real-world applications remains limited. To investigate the gap between existing VFL research and practical deployment, this survey analyzes the real-world data distributions in potential VFL applications and identifies four key findings that highlight this gap. We propose a novel data-oriented taxonomy of VFL algorithms based on real VFL data distributions. Our comprehensive review of existing VFL algorithms reveals that some common practical VFL scenarios have few or no viable solutions. Based on these observations, we outline key research directions aimed at bridging the gap between current VFL research and real-world applications.", "sections": [{"title": "1 Introduction", "content": "With the exhaustion of high-quality publicly available data [Villalobos et al., 2024] and the increasing stringency of privacy regulations such as the European Union's General Data Protection Regulation (GDPR)\u00b9, federated learning [McMahan et al., 2017] has emerged as a promising solution for training machine learning models across multiple parties without sharing their sensitive data. Federated learning is typically classified into horizontal federated learning (HFL) and vertical federated learning (VFL) based on the data distribution among the parties [Yang et al., 2019]. In HFL, parties share the same feature set but have different samples, whereas in VFL, parties possess different feature sets but the same sample set.\nIn recent years, VFL has gained significant interest in industrial collaborations, as companies holding different features often complement and benefit from each other [Li et al., 2020]. These companies typically operate in different domains, such as e-commerce and banking, which reduces conflicts of interest and fosters a greater willingness to collaborate. Especially in the era of large language models, collaboration between private domains with different features can create comprehensive foundation models [Zheng, 2023]. Driven by high demand in industrial applications, many VFL systems have emerged [Liu et al., 2021; Li et al., 2023b]. However, despite this growing interest, very few VFL frameworks or systems have been deployed in real-world applications, as noted by recent studies [Khan et al., 2022b; Ye et al., 2024]. This gap between research and application is crucial for the direction of future VFL research.\nExisting VFL surveys primarily emphasize algorithmic perspectives while overlooking real-world data distributions in practical applications. Surveys such as [Liu et al., 2024a; Khan et al., 2022b; Cui et al., 2024; Ye et al., 2024] present taxonomies of VFL algorithms, categorizing contributions by performance, efficiency, communication, and privacy. Additionally, surveys including [Liu et al., 2024b; Li et al., 2023c; Yu et al., 2024] focus on privacy issues, exploring attack and defense mechanisms. Although recent research [Nock et al., 2021; Wu et al., 2022a] highlights that real-world VFL data is less ideal than current experimental settings, there remains a lack of systematic investigation into real-world VFL data distributions. This gap hinders the effective bridging between theoretical research and practical applications.\nIn this survey, we explore the data distribution of potential VFL applications using a recent real-world database corpus, WikiDBs [Vogel et al., 2024], which comprises 100,000 databases and 1.6 million tables with diverse features. Treating each database as being held by a separate party, we examine cross-party data distributions, identifying four key findings and proposing a data-oriented taxonomy of VFL algorithms. Our review reveals a significant gap between current algorithms and real-world data distributions. We also highlight the challenges in bridging research and practical deployment, offering insights for future research directions."}, {"title": "2 Overview of Vertical Federated Learning", "content": "In this section, we present the definition of vertical federated learning (VFL) in Section 2.1 and provide a comprehensive overview of the VFL pipeline. Distinct from previous surveys [Liu et al., 2024a], which define VFL through the partitioning"}, {"title": "2.1 Definition of VFL", "content": "Consider a collaboration involving C parties, each possessing a unique and heterogeneous dataset. The dataset of party c is defined as X\u1d9c = {K\u1d9c, D\u1d9c}, where K\u1d9c denotes the keys and D\u1d9c denotes the data associated with party c. Here, the keys K\u1d9c \u2208 \u211d\u207f\u1d9c\u00d7\u1d4f are k-dimensional features shared across all parties, while the data D\u1d9c \u2208 \u211d\u207f\u1d9c\u00d7d\u1d9c represents features specific to each party c.\nA VFL task involves multiple parties collaboratively training a machine learning model on the combined datasets {X\u00b9, X\u00b2, ..., X\u1d9c} while ensuring the privacy of both keys and data. This survey focuses on the widely studied supervised learning scenario where one party possesses the labels, referred to as the primary party. The other collaborating parties are termed secondary parties. Without loss of generality, we designate X\u00b9 as the primary party. Formally, the VFL task optimizes the following objective function:\n$\\min_{\\theta} \\frac{1}{n_1} \\sum_{i=1}^{n_1} L(f(\\theta; x_i^1, X^2, ..., X^C), Y_i),$\nwhere n\u2081 is the number of records in the primary party, \u03b8 denotes the model parameters, L is the loss function, f represents the model, x\u1d62\u00b9 is the i-th record from the primary party, and y\u1d62 is the label associated with x\u1d62\u00b9."}, {"title": "2.2 Pipeline of VFL", "content": "The VFL pipeline consists of two main components: privacy-preserving record linkage and VFL training. The privacy-preserving record linkage component aligns the keys across different parties while safeguarding their privacy. Leveraging this alignment information, the VFL training component collaboratively trains a model on the combined datasets from all parties in a manner that preserves data privacy.\nPrivacy-Preserving Record Linkage (PPRL). Privacy-Preserving Record Linkage (PPRL) encompasses a set of techniques designed to align keys across different parties while ensuring the privacy of these keys, such as private set intersection (PSI) [Morales et al., 2023]. Formally, given keys {K\u1d9c}\u1d9c=\u2081 from C parties, PPRL outputs a row selection function \u2205\u1d9c for each party c such that, for all c, each row of \u2205\u1d9c(X\u1d9c) \u2208 \u211d\u207f\u2081\u00d7\u1d50 represents the same data instance. In most studies, the row selection function \u2205\u00b9 for the primary party is typically a constant function, while \u2205\u1d9c for secondary parties aligns X\u1d9c with the primary party. In the ideal scenario of precise alignment, \u2205\u1d9c corresponds to multiplying a row permutation matrix. However, in other cases, \u2205\u1d9c may output a subset of rows or include duplicate rows. Further details will be discussed in Section 4.1.\nVFL Training. VFL training refers to the process of collaboratively training a model on aligned datasets without sharing raw data. Formally, building on top of PPRL, VFL training optimizes the following objective function:\n$\\min_{\\theta} \\frac{1}{N_1} \\sum_{i=1}^{n_1} \\mathcal{L}(f(\\theta; x_i^1, \\phi^2(x_i^2), ..., \\phi^C(X^C)), y_i),$"}, {"title": "3 VFL Data Distributions", "content": "This section examines real-world VFL data distributions using the WikiDBs corpus [Vogel et al., 2024]. We begin by introducing the basic settings in Section 3.1, define the essential data properties in Section 3.2, and present our results and findings in Section 3.3."}, {"title": "3.1 Settings", "content": "Dataset. WikiDBs [Vogel et al., 2024] is currently the largest publicly available corpus of relational databases, extracted from real-world Wikidata. The details of WikiDBS are shown in Table 1. It covers a wide range of domains, such as clinical, finance, sports, etc. Many of these databases (e.g. ucl_clinical-research-trials and apnea_clinical_research_db) are correlated and can be considered potential scenarios for VFL. Each database can be considered a VFL party, with pairs of parties sharing correlated features representing potential VFL pairs.\nConfiguration. In our analysis, we focus on two-party VFL, as it not only reflects the characteristics of multi-party VFL but also represents the most common VFL scenario in practice [Liu et al., 2024a]. Due to the O(n\u00b2) complexity of evaluating all pairs, we randomly sampled 1,000 databases, generating 1,000,000 pairs from their Cartesian square. Experiments are repeated across 10 random seeds to reduce variance, with mean and variance reported. The results show consistent subset characteristics, demonstrating the robustness of our analysis."}, {"title": "3.2 Definitions", "content": "This subsection delineates the key properties of VFL data distribution. We begin by defining which pairs of databases are considered potential VFL pairs. At the feature level, we assess their overlap and balance by introducing the feature overlap ratio and the feature balance ratio. In terms of instances, we quantify the proportion of records that can be matched between two parties using shared features, defining this as the record matched ratio. The detailed definitions are as follows."}, {"title": "3.3 Results and Findings", "content": "In this subsection, we present our results in Table 2 and Table 3, and Figure 1, followed by four key findings from our analysis of real-world databases.\nFinding 1: VFL has a large number of potential real-world applications.\nTo analyze the connectivity between databases, we constructed a graph where each node represents a database, each edge represents shared features between databases, and each color corresponds to a connected component, as visualized in Figure 1a. Table 2 further summarizes the key properties of this graph, showing that the graph of 1,000 parties contains only 3 to 4 connected components. The high connectivity indicated by both the table and figure suggests that VFL has a wide range of potential real-world applications.\nFinding 2: A substantial portion (25.4%) of potential VFL pairs have no overlapping features.\nTo analyze feature overlap ratios between potential VFL pairs, we present the distribution of these ratios in Figure 1b and detail the proportion of pairs with zero feature overlap in Table 2. Table 2 reveals that among the potential VFL pairs, approximately one-quarter have zero feature overlap. This indicates that many real-world VFL scenarios require methods that can handle latent relationships without relying on shared features. We define a VFL scenario where two parties have no overlapping features but are still correlated as latent VFL.\nFinding 3: Only a small fraction of potential VFL pairs (0.2%) can be precisely matched.\nTo evaluate the feasibility of record matching in potential VFL pairs, we analyzed the record matched ratios across database pairs. Figure 1d illustrates the distribution of these ratios, and Table 3 details the ratios for various VFL data distributions. The results reveal that 70.9% of potential VFL pairs have zero precise record matches, with only 0.2% achieving full alignment. This indicates that existing VFL algorithms, which assume fully and precisely matched data records (precise VFL), may be inadequate for most real-world applications. In practice, there is a need for algorithms capable of handling partial record matching (semi-precise VFL) or even scenarios with no record matching (fuzzy VFL). This finding aligns with existing VFL studies [Wu et al., 2022a; Nock et al., 2021; He et al., 2024], which highlight the rarity of precise matching.\nFinding 4: Feature distribution across parties exhibits significant imbalance.\nTo evaluate the balance of features between potential VFL pairs, we present the distribution of feature balance ratio in Figure 1c. We observe that most database pairs have highly imbalanced feature counts. This imbalance poses challenges for existing VFL algorithms, which typically assume relatively balanced feature distributions across parties for optimal performance. This finding aligns with the observation in [Wu et al., 2024b] that real VFL datasets are highly imbalanced w.r.t. feature importance.Imbalanced VFL is defined as a feature balance ratio below 0.5 (66.49%), while balanced VFL has a ratio above 0.5 (33.51%)."}, {"title": "4 Taxonomy of Algorithms", "content": "Based on the findings in Section 3, we propose a novel taxonomy of VFL algorithms across four dimensions: keys, features, communication, and trustworthiness, as illustrated in Figure 2. Table 4 further summarizes existing algorithms according to this taxonomy. The following section provides a detailed explanation of the taxonomy and an overview of the existing algorithms."}, {"title": "4.1 Key Alignment", "content": "The quality of key alignment is a critical factor in VFL preprocessing. Based on our observations in Section 3, we categorize VFL frameworks into four types based on their assumptions about key alignment: Precise, Semi-Precise, Fuzzy, and Latent VFL.\nPrecise VFL (0.2%)\nPrecise VFL refers to scenarios where all keys are perfectly matched, typically through unique identifiers like user IDs. While uncommon in practice according to Table 3, most existing VFL frameworks assume this setting. It applies when each data record corresponds to a user whose ID can be aligned across parties, as seen in some VFL applications using phone numbers as unique IDs [Chen et al., 2021]. However, precise VFL is rare due to two strict constraints: all and precise. The all constraint is particularly restrictive, requiring both parties to share the exact same set of instances. Studies and benchmarks indicate that cross-party data overlap is generally limited [Qiu et al., 2024a; Yan et al., 2024; Wu et al., 2022a; Wei et al., 2023].\nPrecise VFL has been extensively studied and discussed in other surveys [Liu et al., 2024a]. These studies generally follow the PPRL and VFL learning pipeline. Due to the precise key alignment, most research treats PPRL as an orthogonal problem, often addressed by Private Set Intersection (PSI) [Morales et al., 2023], while focusing on the learning aspect. In precise VFL, significant progress has been achieved in various aspects, including accuracy [Wang et al., 2025], efficiency [Li et al., 2023a], communication [Sun et al., 2023], and privacy [Jin et al., 2021].\nSemi-Precise VFL (3.5%)\nSemi-precise (a.k.a. semi-supervised) VFL addresses scenarios where only a subset of keys are precisely matched. This scenario encompasses a broader range of real-world applications compared to precise VFL. For instance, in VFL across hospitals, each patient may not undergo all examinations and have records in all hospitals, a situation commonly referred to as \u201cmissing-modal\u201d in multimodal learning [Zong et al., 2024].\nSemi-precise VFL generally follows the PPRL and VFL learning pipeline but incorporates additional methods for handling missing features or label estimation. The specific estimation techniques employed significantly influence the performance of semi-precise VFL. For example, FedCVT [Kang et al., 2022] estimates representations of missing features using scaled dot-product attention (SDPA) and generates pseudo-labels from existing labels. Similarly, [Sun et al., 2023] utilizes analogous techniques but reduces the communication rounds to one or a few. Furthermore, FedAds [Wei et al., 2023] provides a real-world benchmark for semi-precise VFL. The technical details of semi-precise VFL have been comprehensively summarized in a recent survey [Song et al., 2024].\nFuzzy VFL (70.9%)\nFuzzy VFL represents a more challenging scenario where all keys are not precisely matched but the key similarity indicates the probability of match. This situation is common in real-world applications where data records correspond to objects other than identifiable users, such as houses, routes, or products [Antoni and Schnell, 2019; Wu et al., 2022a]. In such cases, keys might include GPS coordinates or product descriptions, which are related but not precise enough for direct alignment.\nA straightforward approach to fuzzy VFL is to match the top similar pairs of data records and proceed with traditional VFL training [Hardy et al., 2017; Nock et al., 2021]. However, these methods often result in suboptimal performance due to the loss of information from less similar pairs. To mitigate this issue, FedSim [Wu et al., 2022a] considers key similarity as a special feature to guide the training of k-nearest-neighbor records, enabling two-party fuzzy VFL. FeT [Wu et al., 2024a] further extends fuzzy VFL to multi-party scenarios by encoding keys into representations and employing transformers to identify relationships between these representations. Despite the progress, existing studies on fuzzy VFL still focus on low-dimensional numerical keys, and the performance of high-dimensional keys, such as text embeddings or image features, remains an open problem.\nLatent VFL (25.4%)\nLatent VFL addresses scenarios where keys are unavailable due to privacy concerns or the absence of shared features. For instance, Singapore's Personal Data Protection Act (PDPA)2 prohibits clinics from sharing identifiable medical data for research purposes without consent. Another example is a collaboration between a bitcoin transaction company and a bank to detect money laundering. In such cases, because bitcoin wallets are anonymous, there are no keys available to align data across parties. These challenging scenarios necessitate the development of new methods to align data based on their"}, {"title": "4.2 Feature Balance", "content": "Feature balance is critical for model performance and stability, as shown by a recent benchmark study [Wu et al., 2024b]. Figure 1c reveals that real-world datasets often exhibit highly imbalanced feature distributions, posing challenges for existing VFL algorithms. Metrics such as Gini impurity [Li et al., 2023a] and Dirichlet distribution [Wu et al., 2024b] evaluate this imbalance. This section categorizes VFL methods into balanced and imbalanced VFL based on a feature balance ratio threshold of 0.5.\nBalanced VFL (33.51%)\nA balanced feature distribution is ideal for VFL, and most studies [Irureta et al., 2024; Wu et al., 2022b; Valdeira et al., 2024] simulate this by evenly splitting features among parties. However, this setting may not reflect real-world applications. A recent benchmark [Wu et al., 2024b] indicates that some methods [Diao et al., 2022] experience performance degradation under imbalanced feature distributions.\nImbalance VFL (66.49%)\nIn real VFL scenarios, datasets are distributed across parties with unique and uneven feature characteristics, leading to feature imbalance. This imbalance can significantly affect the performance of VFL [Wu et al., 2024b]. To address feature imbalance, several algorithms have been developed to mitigate the effects of skewed feature distributions by re-weighting features or adjusting training algorithms. VertiBench [Wu et al., 2024b] shows that both SplitNN [Vepakomma et al., 2018] and FedTree [Li et al., 2023b] maintain stable performance under imbalanced conditions. A VFL framework [Feng, 2022] leverages local non-overlapping samples for feature selection, and a Gini impurity-based method [Li et al., 2023a] accelerates training by filtering out noisy features. Despite these advancements, feature imbalance remains an underexplored challenge in VFL."}, {"title": "4.3 Communication", "content": "We categorize VFL studies into five types based on communication requirements: one-shot or multi-round VFL, transmission-compressed or uncompressed VFL, and synchronous or asynchronous VFL, as illustrated in Figure 2. Since uncompressed and synchronous VFL are the most common, we focus on the remaining three types that address the specific challenges involved with communication.\nOne-Shot VFL\nTraditional VFL requires reliable communication channels between the server and the participating clients, which, to some extent, narrows the scope of VFL applications, thereby raising the demand for reducing the number of communication rounds [Khan et al., 2022a]. The introduction of one-shot VFL has minimized the average number of communication rounds required at the client side [Liu et al., 2024a].\nExisting works focus on reducing VFL communication costs through unsupervised or semi-supervised learning to generate effective local representations. For example, combining semi-supervised learning with gradient clustering allows clients to learn local feature extractors using overlapping but unaligned samples and share these with the server in a single communication round [Sun et al., 2023]. FedOnce uses unsupervised learning to generate client-side representations for server-side training in a single round [Wu et al., 2022b], while APC-VFL integrates representation learning and knowledge distillation to achieve efficient training through aligned sample features [Irureta et al., 2024].\nThese methods reduce communication rounds by up to hundreds of times, improving VFL's feasibility for clients with limited communication capacity. However, one-shot VFL may impact model accuracy and generalization, particularly under imbalanced data or low sample overlap. Multi-round training allows for gradual optimization, which one-shot approaches may struggle to achieve. Enhancing accuracy through relaxed constraints and few-shot learning algorithms offers a potential solution [Sun et al., 2023].\nTransmission-Compressed VFL\nWhen clients have limited communication budgets, it is common to apply transmission compression between the server and clients, especially for the collaborative training of deep neural networks, which are typically over-parameterized in both their model and feature parameters [Xiao et al., 2023].\nFor example, existing works alleviate the burden of data transmission using dimensionality-reduction algorithms [Sun et al., 2024], quantization [Wang and Xu, 2024], both quantization and top-k sparsification [Castiglia et al., 2022], and pruning applied to both feature model and feature embeddings [Wang et al., 2024b]. Given that existing compression approaches are generally lossy, EFVFL has been proposed to"}, {"title": "4.4 Trustworthy", "content": "VFL applications may involve varying types of sensitive information that require protection. We categorize trustworthiness concerns into three key areas: data privacy, model security, and contribution fairness.\nData Privacy\nData privacy is a key concern in VFL, which aims to prevent the exposure of each party's training data. While VFL provides some privacy by transmitting gradients or represen-tations instead of raw data, it does not fully mitigate risks. Effective data protection requires addressing three major vulnerabilities: feature, label, and membership privacy.\nFeature. Existing feature inference attacks [Luo et al., 2021] can extract individual features from transmitted embeddings, posing a significant privacy risk. Additionally, data reconstruction attacks can even recreate the original data from these embeddings [Yang et al., 2025]. To mitigate these risks, techniques such as Falcon [Luo et al., 2021] and model inconsistency defense [Pasquini et al., 2022] should be adopted to secure the aggregation of intermediate embeddings.\nLabel. Labels often contain sensitive information that requires protection from unauthorized access. Label inference attacks can deduce labels by analyzing gradient updates during training [Liu et al., 2024b]. Advanced techniques like gradient inversion enable attackers to recover labels from batch-averaged local gradients [Liu et al., 2022]. Both passive and active LIA approaches have been demonstrated, where adversaries can exploit trained bottom models or manipulate gradients to maximize label leakage [Fu et al., 2022]. To mitigate these risks, solutions like differential privacy [Abadi et al., 2016] and encryption-based aggregation [Bai et al., 2023] are essential to protect labels.\nMembership. While membership inference attacks (MIA) are well-studied in centralized learning to determine whether specific samples were used in training [Bai et al., 2024], their impact on VFL is limited. This is because VFL's mandatory entity alignment process inherently reveals sample membership information between parties [Yu et al., 2024], making traditional MIA approaches less effective in the VFL context.\nModel Security\nIn real-world VFL applications, adversarial attacks exploit system vulnerabilities, posing risks at both inference and training stages. At inference time, adversaries can craft inputs to induce misclassifications, even with limited access to features or labels [Qiu et al., 2024b]. These attacks are categorized as either targeted or untargeted. Targeted attacks manipulate specific tasks (e.g., classifying \u201cstriped cars\u201d as \u201cbirds\u201d while maintaining overall accuracy) [Chen et al., 2024], whereas untargeted attacks degrade overall model performance by corrupting training data [Qiu et al., 2024b]. These risks underscore the need for robust security measures to protect both inference and training processes in VFL.\nEffective defense methods vary depending on the type of attack. To counter inference-time risks, techniques such as Differential Privacy [Abadi et al., 2016] help safeguard sensitive data by limiting the information leakage from model outputs. For training-time attacks, including backdoor attacks that embed hidden vulnerabilities into the model [Naseri et al., 2024], anomaly detection methods such as FreqAnalysis [Rieger et al., 2025], originally developed for HFL, show promise in detecting and mitigating malicious updates. By integrating these defense, real-world VFL applications can better ensure both data privacy and model reliability.\nContribution Fairness\nProtecting intellectual property in VFL requires safeguarding fair contribution evaluation, reward distribution, and prevent-ing attacks like free-riding and contribution fraud. Free-rider attacks involve contributing random or inferred data to obtain a model without meaningful input, making detection difficult [Lin et al., 2019]. Contribution fraud manipulates evaluation mechanisms to inflate importance and secure unfair rewards, posing a risk in incentive-based systems like Web3 federated learning [Jiang et al., 2024].\nDefense mechanisms remain underdeveloped. Free-rider defenses, such as STD-DAGMM [Lin et al., 2019], are mainly designed for HFL and are less explored in VFL. Spy [Fu et al., 2025] highlights new free-rider threats in VFL, but no solution fully prevents these attacks. Fairness-focused methods [Cui et al., 2024; Fan et al., 2024] offer some protection against contribution fraud, though attacks like ACE [Xu et al., 2024] remain an unaddressed threat. Addressing these gaps is essential to enhance security and fairness in VFL."}, {"title": "5 Discussion", "content": "Based on our study, we conclude that VFL algorithms are not yet ready for widespread deployment in real-world applications. We identify three critical gaps that must be addressed to enable successful implementation.\nFuzzy and Latent VFL. Many potential VFL applications involve fuzzy or latent data scenarios; however, research in this area remains limited. The primary challenge is to design algorithms capable of handling noise in shared features and uncovering latent relationships within the data. Developing efficient and robust algorithms for these prevalent scenarios would significantly broaden the applicability of VFL.\nVFL for Heterogeneous Data. Most existing VFL algo-rithms are designed for homogeneous data, whereas real-world applications often involve highly heterogeneous data. The key challenge is to create algorithms that can effectively handle data with diverse structures and distributions. Conducting experiments on imbalanced datasets would provide strong evidence of VFL algorithms' effectiveness in practical applications.\nTrustworthiness in VFL. Ensuring trustworthiness remains a critical challenge for VFL systems. Our observations indicate that several privacy risks are still unaddressed. Strict privacy and security regulations often impede VFL deployment, as even a single unresolved risk can prevent adoption. Future research must focus on developing comprehensive security mechanisms to enhance the privacy and trustworthiness of VFL systems."}, {"title": "6 Conclusion", "content": "In this study, we investigate the potential applications of VFL and identify four key properties of real VFL data distributions. Based on these findings, we propose a taxonomy and evaluate how existing VFL algorithms address the challenges encountered in practice. Our analysis reveals significant gaps between current VFL algorithms and the demands of real-world applications. We summarize these critical gaps and suggest future research directions to bridge the divide between existing algorithms and practical VFL."}]}