{"title": "Surveys Considered Harmful?\nReflecting on the Use of Surveys in AI Research, Development, and Governance", "authors": ["Mohammad Tahaei", "Daricia Wilkinson", "Alisa Frik", "Michael Muller", "Ruba Abu-Salma", "Lauren Wilcox"], "abstract": "Calls for engagement with the public in Artificial Intelligence\n(AI) research, development, and governance are increasing,\nleading to the use of surveys to capture people's values, per-\nceptions, and experiences related to AI. In this paper, we crit-\nically examine the state of human participant surveys associ-\nated with these topics. Through both a reflexive analysis of a\nsurvey pilot spanning six countries and a systematic literature\nreview of 44 papers featuring public surveys related to AI, we\nexplore prominent perspectives and methodological nuances\nassociated with surveys to date. We find that public surveys\non AI topics are vulnerable to specific Western knowledge,\nvalues, and assumptions in their design, including in their\npositioning of ethical concepts and societal values, lack suf-\nficient critical discourse surrounding deployment strategies,\nand demonstrate inconsistent forms of transparency in their\nreporting. Based on our findings, we distill provocations and\nheuristic questions for our community, to recognize the lim-\nitations of surveys for meeting the goals of engagement, and\nto cultivate shared principles to design, deploy, and interpret\nsurveys cautiously and responsibly.", "sections": [{"title": "1 Introduction", "content": "Artificial Intelligence (AI)\u00b9 and Machine Learning (ML) re-\nsearchers, developers, and policymakers are increasingly us-\ning surveys to capture people's values, perceptions, and ex-\nperiences, to inform development and governance of AI.\nSurveys are used to guide the design and development of\nnew technology directions and products (e.g., Alkhathlan\net al. 2024; Sindermann et al. 2021; Persson, Laaksoharju,\nand Koga 2021; Othman 2023; Loefflad and Grossklags\n2024; Davani et al. 2024), shape companies' technology\npolicies (Anthropic 2023; Google 2024; OpenAI 2023), and"}, {"title": "2 Related Work\nA Brief History of Surveys: From Agriculture and\nMilitary to Computing and AI", "content": "Modern-day survey methods emerged from a long history\nof societies that sought measurements of their populations\nthrough censuses to make plans essential to core governance\n(e.g., managing food supplies, distributing land, and manag-\ning taxation)-dating back to ancient times (Rossi, Wright,\nand Anderson 2013; Midena and Yeo 2022). As the fo-\ncus of studies became more specific, such as examining the\neconomic status of households or conducting consumer re-\nsearch, surveys gained increased popularity over traditional\nsmall-scale experimental studies (Rossi, Wright, and Ander-\nson 2013). Surveys also played a prominent role in the de-\nvelopment and study of psychometrics, or measuring peo-\nple's mental activities. Important concepts in psychometrics\ninclude correlation, personality scale and psychometric reli-\nability, experimental designs, and increasingly sophisticated\nstatistical analysis (Rust and Golombok 2014). Significantly\nabused by racism and oppressive applications in social poli-\ncies (Reyes 2019; Winston 2020), this evolution is also\nmarked by significant developments, including the emer-"}, {"title": "Rapid Expansion of Survey Use in AI Research,\nDevelopment, and Governance", "content": "As more empirical and irrefutable evidence emerges, it be-\ncomes clear that understanding AI's impact requires a multi-\nstakeholder effort (Aragon et al. 2022; Delgado et al. 2023;\nHimmelreich 2023; Torkamaan et al. 2024; Havens et al.\n2020). Yet, given the prevailing power asymmetries in this\nspace, AI development is predominantly shaped by indus-\ntry, research, and policy (Moloi and Marwala 2021). This\ndynamic has only recently begun to shift toward public in-\nvolvement (Birhane et al. 2022a; QueerInAI 2023; Sloane\net al. 2022; Dennler et al. 2023), though scholars have long\nadvocated for increased public involvement in science and\ntechnology as a means to \"foster greater accountability, bet-\nter decision outcomes, and increased trust\" (Holdren, Sun-\nstein, and Siddiqui 2011; Bao et al. 2022).\nAs such, multiple studies have engaged with the public\nto investigate Al's impact. A plethora of surveys aiming to\nbe representative have been deployed over the years with\nthe goal of examining public awareness of, perceived chal-\nlenges with, and trust in AI (Zhang and Dafoe 2020) and\nhow the public understands AI (Selwyn et al. 2020; Kieslich\nand L\u00fcnich 2024), as well as distinguishing between utopian"}, {"title": "Critically Reflexive Practices in AI Research", "content": "\"Critically reflexive practice embraces subjective under-\nstandings of reality as a basis for thinking more critically\nabout the impact of our assumptions, values, and actions on\nothers.\" (Cunliffe 2004) Reflexivity has a history, in schol-"}, {"title": "3 Methods", "content": "Our approach and perspectives are informed by a critically\nreflexive stance, rooted in the self-critical perspectives of\nthe AI research community (Section 2) and our positional-\nity (Section 7). The rationale behind such a critical stance\nis to initiate discourse within the community, especially as\nsurveys are increasingly becoming a \"go-to\u201d method for cap-\nturing public perceptions of AI. To understand the pitfalls of"}, {"title": "Pilot Survey of Perceived Benefits and Risks of AI", "content": "To facilitate reflexivity in survey methods, we conducted a\npilot survey in six countries (one in each of six continents)\nwith 282 participants to explore the complexities of survey\nresearch associated with the challenging topic of capturing\nperceptions of Al's benefits and risks. Despite adhering to\nknown survey research best practices (see Appendix A), we\nobserved that there are both unknown knowns and unknown\nunknowns that require further attention and are often over-\nlooked in current AI research practices.\nSurvey Design. The pilot survey explored perceptions of\nthe benefits and risks of existing AI systems via two sepa-\nrate open-ended questions: (1) How do you think existing\nAI systems could benefit you?; (2) How do you think ex-\nisting AI systems could put you at risk? We also used two\nstorytelling questions inspired by the computer security do-\nmain (Rader, Wash, and Brooks 2012; Pfeffer et al. 2022) to\ncapture how stories and memories about benefits and risks"}, {"title": "Systematic Literature Review", "content": "We conducted a systematic literature review centered on pa-\npers related to the themes of public, AI, surveys, and per-\nceptions described in a variety of ways (see Appendix C\nfor search terms). We sourced our material from the ACM\nDL (conference publications) as well as from Springer's AI\n& Ethics and AI & Society journals (journal publications).\nOur search was constrained to a two-year period (01/2022\u2013\n01/2024), except for papers from AIES and FAccT, for\nwhich we did not impose any date restrictions. The exclu-\nsion criteria were as follows: (1) surveys of literature, poli-\ncies, or guidelines, rather than respondents; (2) use of past\nsurveys or datasets; (3) surveys not intended to include rep-"}, {"title": "4 Large-Scale Surveys of AI in the Literature", "content": "After analyzing our corpus of 44 papers, we noticed incon-\nsistent practices in the reporting of research procedures (e.g.,\nethical review approvals, informed consents, and concerns\nrelated to cultural sensitivity and congruence of research\npractices) and research transparency practices (e.g., lack of\ninformation about funding sources, positionality statements,\nrecruitment strategies, and socio-demographic characteris-\ntics of participants or their compensation).\nResearch Methods. Across the 44 papers, there were 58\nprimarily quantitative studies (some papers reported results\nof more than one study) conducted (e.g., surveys and on-\nline experiments, with qualitative analysis of open-ended\nresponses), nine of which were accompanied by qualita-\ntive studies with human participants (e.g., interviews and\nfocus groups, sometimes with quantitative insights into oc-"}, {"title": "5 Discussion\nPitfalls of Surveys as Enablers of \u201cParticipation\"", "content": "A recent trend in critical AI research advocates for partic-\nipation in AI (e.g., Feffer et al. 2023; Sloane et al. 2022;\nDelgado et al. 2023; Bondi et al. 2021), with researchers us-\ning different terminologies and viewpoints to describe levels\nof participation, with frequent reference to the ladder of par-\nticipation (Arnstein 1969). For example, Sloane et al. (2022)\ncategorize participation in AI into three levels: work, consul-\ntation, and justice, whereas Delgado et al. (2023) propose\na four-level framework: consult, include, collaborate, and\nown. Given that surveys are often a paid, one-time transac-\ntion, they most likely fall under the categories of participa-\ntion as work and consultation-the minimum level of par-\nticipation in both frameworks. Other frameworks for assess-\ning participation in AI propose questions for researchers to\nconsider. Birhane et al. (2022a) provide a framework focus-\ning on empowerment, reciprocity, and reflexivity for criti-"}, {"title": "Representation Issues in Surveys", "content": "True Representation or an Illusion of Representation?\nDataset attributes and annotation practices are known to in-\ntroduce biases into AI, potentially resulting in poor represen-\ntation of the perspectives of marginalized groups (Bergman\net al. 2023; D'Ignazio and Klein 2020; Sambasivan et al.\n2021; Lu et al. 2024). A model trained on a \"representative\""}, {"title": "Cross-Cultural Surveys Considered Helpful or Harm-\nful?", "content": "The complexity increases when conducting surveys\nacross different cultures and regions (Duarte 2021; Kars-\ngaard 2023; Palacios Abad et al. 2022; Davani et al. 2024).\nIn our pilot, we aimed to capture a broad range of perspec-\ntives from six continents without being fully immersed in the\ntarget populations and experiencing what it means to live in\ncountries like Chile or South Africa. Or, conducting surveys\nexclusively in English in countries, where this is not the of-\nficial language, limited our insights and was exclusionary\nby design. We received responses in languages other than\nEnglish, indicating a desire to participate irrespective of En-"}, {"title": "Value Tensions in Surveys: Heuristic Questions", "content": "In this paper, we discussed many positions and concerns,\nwhich often did not converge toward simple outcomes. Sur-\nvey research in Al vexes us with many choices and de-\ncisions. We summarize the major issues as tensions that\nare currently unresolved. In view of the many reasons and\nmotivations for using surveys in AI research, we propose\nthat \"heuristic questions\" (Muller 1997) may be more valu-\nable than advice. Asking \u201cbig questions\u201d (Beck and Stolter-\nman 2017, ms. p. 1), (Reiser et al. 2017; Schaeffer and\nPresser 2003) or \"the right question\" (Mao et al. 2019,\nms. p. 1) has been deemed valuable when facing new or"}, {"title": "(A) Breadth and Depth:", "content": "\u2022 Standardization and Customization. Do we attempt\nto standardize certain survey content through invariant\nquestions addressed to all persons in all geographical lo-\ncations and cultural backgrounds (Ornstein 2013)? How\ncan we address the tendency for a survey to primarily re-\nflect the cultural perspective of the Global North and its\nassociated dominance (Septiandri et al. 2023)?\n\u2022 Languages. Do we adapt the survey for regional lan-\nguages (Kelley et al. 2021)? When does openness and ac-\ncommodation shade into cultural differences in inquiry,\nleading to incommensurable outcomes?\n\u2022 Sampling. Survey research is often constrained by time\nand budget. In settings with diverse cultures, how great\nan effort should be spent on recruiting a balanced or\nweighted sample across cultures (Selwyn et al. 2020;\nZhang and Dafoe 2020)? Where is the \u201cstopping point\u201d,\nand is this a question that requires members of the survey\npopulation to help answer? How much sampling stratifi-"}, {"title": "(B) Manual and Automated Approaches.", "content": "If we use gen-\nerative AI in question generation, do we risk a bland, so-\ncalled \"universal\", tone that reflects the worldview of the\nAI-provider (Paxton 2023)? Or if we rely on humans in the\nresearch process, e.g., in data collection and analysis, how\ncan we account for the limited views of research teams and\ntheir biases? What are the specific choices related to use\nof AI that need to be disclosed as part of consent (e.g.,\nWilcox, Brewer, and Diaz 2023; Andreotta, Kirkham, and\nRizzi 2022; Gomez Ortega et al. 2023) and transparency in\npublication (e.g., Wacharamanotham et al. 2020; Hosseini,\nResnik, and Holmes 2023)?"}, {"title": "(C) Who and What Influences Survey Designs?", "content": "Sur-\nvey design is often considered to be the domain of spe-\ncialists (e.g., Fink 2003; Spector 2013). While it is true\nthat the design of questions and response-scales requires\nprofessional knowledge, the selection of topics may be\ninformed by members of stakeholder groups or affected\nclasses (Baeza-Yates 2018; Nicoletti and Bass 2023; Al-\nvarado Garcia et al. 2021; Bird 2020; Kwet 2019). Mindful\nof the different meanings of \u201cparticipation\u201d (e.g., Hansen,\nFourie, and Meyer 2021; Muller and Kuhn 1993; Schuler\nand Namioka 1993; Simonsen and Robertson 2012), we ask:\nWhat are the opportunities for involving community mem-\nbers or leaders in participatory or co-design processes to se-"}, {"title": "(D) Trust and Research Engagement.", "content": "Trust among\nmany communities that might participate in survey research\nhas been eroded due to past mistreatment in research more\nbroadly, along with experiences of racism and various forms\nof prejudice by different research institutions (Scharff et al."}, {"title": "(E) Mixed Methods and Balanced Inquiry.", "content": "As dis-\ncussed in Section 1, surveys tend to decontextualize re-\nsponses and isolate respondents (Ornstein 2013). Is it feasi-\nble to integrate large-scale quantitative survey methods with\nsmaller-scale, rigorous qualitative analyses involving strate-\ngically selected groups of informants (e.g., Baumer et al.\n2017; Greenberg and Buxton 2008; Muller et al. 2016)?"}, {"title": "(F) Transparency and Research Practices.", "content": "We should\ndiscuss whether and how to establish consistent report-\ning methods for surveys on AI topics. For instance, what\ntransparency artifacts (e.g., Crisan et al. 2022; Mitchell\net al. 2019; Chmielinski et al. 2022; D\u00edaz et al. 2022; Ros-\ntamzadeh et al. 2022; Srinivasan et al. 2021) might inspire\nnew forms of methodological transparency? How should we\ndetermine which types of data to include in these artifacts?\nSelection criteria to consider may include the contingent and\npotentially sensitive nature of AI topics addressed in sur-"}, {"title": "(G) Researcher and Participant Empowerment.", "content": "Re-\nsearchers should consider early in their study what sur-\nvey participants stand to gain from the research (Oldendick\n2012; Jamieson, Govaart, and Pownall 2023). This consid-\neration becomes particularly important when studying hard-to-reach populations or when using public funds (or consid-\nering conflicts of interest when using private funds). Adopt-\ning a reflexive, critical approach to the implications of their\nresearch can significantly benefit researchers in understand-\ning and improving the value of their work for participants. In\nreflecting, we ask: Are there alternative avenues to improve\nthe value exchange for the populations being studied?"}, {"title": "6 Conclusion", "content": "In this paper, we combine epistemic approaches grounded\nin critical reflexivity with a systemic literature review to ex-\namine the state of large-scale surveys in AI scholarship. The\nstudy reveals a range of performative and misleading prac-\ntices with a method that has garnered adoption, informing\nresearch, shaping publicly-facing narratives, and justifying\ntrajectories in AI development-highlighting the need for\nurgent intervention. The stakes are high in AI research, and\nsome of these issues cannot be adequately addressed or dis-\nmissed by merely tucking challenges within the limitations\nsection of research papers. As such, we aim to spark reflex-\nive engagement with research processes that shape how sur-\nveys could be used responsibly and offer a list of heuris-\ntic questions to prompt more thorough acknowledgments of\nbias and subjectivity."}, {"title": "7 Research Ethics and Social Impact", "content": "Ethical Considerations Statement\nIn addition to the ethics considerations described in our pa-\nper body, our pilot survey obtained approval from the Re-\nsearch Ethics Office at King's College London. We im-\nplemented strict measures to ensure the confidentiality,\nanonymity, and privacy of our participants. No personally-\nidentifiable information was collected, and participation was\nvoluntary and anonymous. Participants were provided with\nan informed consent form in English, detailing the study's\npurpose and the intended use of the data collected.\nResearcher Positionality Statement\nThe authors come from varied research backgrounds that\nshape their perspectives. The study was funded by an aca-\ndemic institution in the Global North, and funding for the\nstudy was restricted to respondent incentives and vendor sur-\nvey services. Authors were employed by their institutions\nand were not explicitly paid to conduct this research. One\nauthor is employed by an academic institution, and one is\nemployed at a non-governmental organization. Four authors\nare employed in industry research roles, though this study\nwas not part of their company research. The research team\nhave experiences living in two of the six countries surveyed\n(United Kingdom and United States). All six authors have\nextensive experience with survey methods, with four hav-\ning experience with international and cross-cultural survey\napproaches. Authors were born in, currently live in, or had\npreviously lived in, nine different countries collectively. Our\nrace/ethnicity is collectively White (European) (n = 3),\nMiddle Eastern (n = 2), and Afro-Caribbean (n = 1). All\nauthors identify as having some experience with marginal-\nization in computing, either through years of conducting\ncomputing research with marginalized groups or as mem-\nbers of a marginalized group themselves.\nOur positionality is influenced by our backgrounds and\nexperiences; as researchers trained and working in predom-\ninantly Western institutions, we acknowledge that comple-\nmentary scholarship related to our research questions is\nneeded, to further the understandings presented in this pa-\nper. Our positionality has also influenced the subjectivity in-\nherent in framing our paper approach, research questions,\nstudy pilot design, literature review, and data interpretation\nand analysis, as we elaborate on throughout the paper.\nAdverse Impact Statement\nOur research aims to promote critical thinking within the\nAIES community about survey methods in AI, but they\ncould be interpreted as an outright dismissal of these meth-\nods without full engagement with the nuances we present in\nour paper. Our intention is not to entirely discourage the use\nof surveys in AI and responsible AI research. Instead, our\ngoal is to foster thoughtful and critical engagement within\nthe AIES community to develop perspectives on the princi-\nples associated with the who, what, when, where, why, and\nhow of human survey methods in AI research. Finally, we\ndo not intend to suggest that designing the \"perfect\" sur-\nvey will address the systemic issues that surround survey"}, {"title": "A Known Limitations of Surveys", "content": "There are several well-known issues with surveys that are\noften acknowledged as limitations in studies. Below, we list\nseveral common biases; however, this is not an exhaustive\nlist. For a more comprehensive discussion, we refer to sur-\nvey design papers and textbooks such as (M\u00fcller, Sedley, and\nFerrall-Nunge 2014; Krosnick 1999; Choi and Pak 2005).\n\u2022 Acquiescence bias and experimenter effect: Survey re-\nspondents may agree with a question or statement regard-\nless of their actual feelings or attitudes. This can stem\nfrom a desire to be agreeable, a lack of motivation in an-\nswering questions, due to the influence of the researcher\nor the institution conducting the survey, or due to desire\nto satisfy what respondents think the researchers' expec-\ntations from the study are.\n\u2022 Satisficing: Respondents may opt for answers that\nmerely satisfy the survey's requirements, rather than\nseeking the most accurate or optimal response. This be-\nhavior could be due to the effort involved, distractions, or\na lack of interest in the survey's outcomes.\n\u2022 Social desirability: In response to sensitive questions,\nsurvey participants may answer in a manner they believe\nwill be viewed favorably by others. For instance, ques-\ntions about sexual orientation or taboo subjects might\nelicit responses that do not accurately reflect the respon-\ndent's true stance.\n\u2022 Question and response order bias: The sequencing of\nquestions or answer options can influence survey results.\nThe order in which questions are presented can prime\nrespondents' views as they progress through the survey.\nSimilarly, non-randomized answer choices may not have\nan equal chance of being selected.\n\u2022 Framing effects: The choice of wording in questions\nmay affect survey responses. For example, users' agree-\nment or disagreement with specific statements may de-\npend on whether those statements are positively or nega-\ntively framed. The choice of specific words (even among\nsynonyms, such as concern vs. worry vs. fear vs. dis-\ncomfort) may also lead to different outcomes. Nuances\nin translation may further complicate the interpretation\nof questions and answers in multi-lingual studies. Other\nwording choices and associated mistakes (e.g., double\nnegation, double-barreled questions, leading questions,\netc.) can decrease respondents' comprehension of the\nquestions and introduce biases in the analysis, compro-\nmising the objectivity and accuracy of the survey results.\nMore broadly, framing effects may also emerge from the\noverall narrative of the survey, for example, suggesting a\ndichotomous trade-off between benefits and risks, with-\nout considering other nuances of the discourse or other\npotential factors affecting respondents' perspectives.\n\u2022 Sampling bias: Collecting survey responses from a non-\nrepresentative sample reduces the generalizability of the\nresults to the broader target population, which may dif-\nfer in socio-demographics and experiences. Similarly, by\nfocusing on AI users, researchers exclude the perspec-\ntives of those who do not use AI or lack the expertise,"}, {"title": "B Additional Materials for Pilot Survey\nSurvey Instrument", "content": "[Answer options to close-ended questions were randomized\nwhere appropriate.]\n\u2022 Have you heard of the term \u201cArtificial Intelligence\" (or\n\"AI\")?\nYes, I have heard of the term \"Artificial Intelligence\"\n(or \"AI\"), and I feel confident explaining what it means\nto an expert.\nYes, I have heard of the term \u201cArtificial Intelligence\"\n(or \"AI\"). However, I do not feel confident explaining\nwhat it means to an expert.\nNo, I have not heard of the term \"Artificial Intelli-\ngence\" (or \"AI\u201d).\nThe following questions are based on your understanding\nof existing Al systems.\n\u2022 How do you think existing AI systems could benefit you?\nPlease give details (at least 100 characters).\n\u2022 We want to know what you have learned from others\nabout the benefits of existing AI systems. Specifically, we\nare interested in stories you have heard about the benefits\nof existing Al systems from OTHER PEOPLE, such as\nfriends, coworkers, social media sites, TV shows, news\nwebsites, blogs, or any other sources-NOT experiences\nthat happened to you personally. Describe in detail the\nmost memorable story (at least 100 characters).\n\u2022 How did you hear about that story?\n\u2022 How do you think existing Al systems could put you at\nrisk? Please give details (at least 100 characters).\n\u2022 We want to know what you have learned from others\nabout the risks of existing AI systems. Specifically, we\nare interested in stories you have heard about the risks\nof existing Al systems from OTHER PEOPLE, such as\nfriends, coworkers, social media sites, TV shows, news\nwebsites, blogs, or any other sources-NOT experiences\nthat happened to you personally. Describe in detail the\nmost memorable story (at least 100 characters).\n\u2022 How did you hear about that story?"}, {"title": "Table 1: Participant demographics (N=282).", "content": "Country of residence\nAustralia\n50 (18%)\nIsrael\n48 (17%)\nChile\n47 (17%)\nUnited Kingdom\n47 (17%)\nUnited States\n46 (16%)\nSouth Africa\n44 (16%)\nEthnicity\nWhite\n161 (57%)\nBlack\n48 (17%)\nMixed\n34 (12%)\nAsian\n19 (7%)\nOther\n18 (6%)\nNot available\n2 (1%)\nEmployment status\nWorking full-time\n126 (45%)\nWorking part-time\n54 (19%)\nStudent\n54 (19%)\nUnemployed and looking for work\n34 (12%)\nOther\n5 (2%)\nRetired\n5 (2%)\nA homemaker or stay-at-home parent\n4 (1%)\nGender\nFemale\n143 (51%)\nMale\n139 (49%)\nIncome relative to age group and location\nAverage\n116 (41%)\nBelow average\n79 (28%)\nAbove average\n66 (23%)\nPrefer not to say\n11 (4%)\nUnsure\n10 (4%)\nFamiliarity with AI\nHeard but can't explain to an expert\n169 (60%)\nHeard and can explain to an expert\n113 (40%)\nTechnical background\n62 (22%)\nThe final dataset consisted of participants from six coun-\ntries. Table 1 summarizes the demographics of our partici-\npants. We achieved a balanced sample in terms of gender.\nRacially and ethnically, many participants (57%) identified\nas White. In terms of employment status, several participants\nwere employed full-time (45%), and described their income\nas average (41%).\nConcerning familiarity with AI, 169 participants (60%)\nexpressed that they had heard of the term but did not feel"}, {"title": "Reflections: Impact of Researcher Tools, Practices,\nand Choices", "content": "In this section, we revisit the decisions made during the de-\nsign, deployment, and analysis of our pilot survey that are\nnot necessarily covered in the literature review but were\ncrucial considerations. Each subsection addresses a specific\nquestion we encountered and had to deliberate upon. A more\nconcise set of heuristic questions can be found in Section 5.\nHow to Frame Questions? Our pilot survey was rooted\nin prior research with public perception of AI and echoed\ntheir consequentialist ethics framing \u201cthe view that nor-\nmative properties depend only on consequences\u201d (Sinnott-\nArmstrong 2023). In our case, the framing of the questions\nwith \"How do you think existing AI systems could ben-\nefit you?\" explicitly emphasizes the consequences instead\nof anything else. From an alternative standpoint such as\ndeontologist \u201cnormative theories regarding which choices\nare morally required, forbidden, or permitted . . . In contrast\nto consequentialist theories, deontological theories judge\nthe morality of choices by criteria different from the states\nof affairs those choices bring about\u201d (Alexander and Moore\n2021), we could have instead asked about what rules"}, {"title": "Should We Translate the Survey?", "content": "The practice of trans-\nlating questions from English into other languages for com-\nparative analysis warrants attention. While such translations,\nwhich may be conducted meticulously and carefully (e.g.,\nKelley et al. 2021), aim to include more countries or cul-\ntures, they may not accurately reflect other cultures' per-\nspectives. Concluding that direct experiences with AI alone\ndrive excitement and alleviate concerns is an oversimplifica-\ntion. Attitudes toward AI are shaped by various factors, in-\ncluding media representation, personal experiences and be-\nliefs, and societal narratives, and not solely by direct interac-\ntions with AI. Individuals may lack meta-awareness of these\nother factors influencing their perceptions. Direct interac-\ntions with AI could be detrimental to some individuals, and\nthose most vulnerable to being marginalized by AI may be\nindividuals who have not experienced it firsthand. Further-\nmore, survey results indicating a pronounced positive orien-"}, {"title": "Where to Find Participants?", "content": "Our team's diversity, span-\nning various affiliations, faced limitations in participant re-\ncruitment due to being constrained by choosing appropri-\nate platforms. Differing experiences with platforms such as"}, {"title": "How Much Should We Pay Participants?", "content": "In addition to\naccess considerations, we decided to compensate all partic-\nipants based on the payment rates of our home institution.\nHowever, this decision prompts a critical question: Should\ncompensation be adjusted based on the participant's country\nor kept consistent across all countries? This dilemma un-\nderscores the challenges of fair participant treatment across\ndiverse regions and economies, emphasizing the need for a\nnuanced compensation approach that considers both institu-\ntional standards and the participants' economic situations.\nExamining the data from our literature review, it is evi-"}, {"title": "How to Analyze Data?", "content": "Finding a suitable framework for\na top-down analysis of data, especially regarding the ben-\nefits and risks of AI, was difficult. This challenge arises\nmainly because most existing frameworks come from West-\nern countries, and there is a lack of comprehensive frame-\nworks or taxonomies for a complex and rapidly chang-\ning field like AI. For example, the difficulties in applying\nAI safety taxonomies are well-recognized due to the ever-\nevolving nature of AI (Rismani et al. 2023).\nGiven these constraints, our approach predominantly in-\nvolved bottom-up analysis for most of the questions. An\nexception was made for the \"trustworthiness\" question, in\nwhich we applied a combination of top-down and bottom-up methods. For the top-down component, we used the NIST\nAI Risk Management Framework (NIST 2023) as a starting\npoint. However, this choice introduced a US-centric bias into\nour analysis, potentially excluding or marginalizing other\ncultural views. The use of a framework developed within\na specific cultural and institutional context raises impor-"}, {"title": "C Additional Materials for the Systematic\nLiterature Review", "content": "Query\n\u2022 Who? Public. \u201cpublic\u201d OR \u201crepresentative\u201d OR \u201cpopula-\ntion\" OR \"citizen\" OR \"citizens\" OR \"civic\" OR \"com-\nmunity\" OR \"non-expert\u201d OR \u201cnon-experts\u201d.\n\u2022 What? AI. \"artificial intelligence\u201d OR \u201cmachine learn-\ning\" OR \"deep learning\u201d OR \u201cAI\u201d.\n\u2022 What? Perceptions. \"thoughts\u201d OR \u201cfeel\" OR \"feels\" OR\n\"feeling\" OR \"experience\u201d OR \u201cexperiences\" OR \"feel-\nings\" OR \"perception\" OR \"perceptions\" OR \"perceive\"\nOR \"attitude\" OR \"attitudes\u201d OR \u201copinion\u201d OR \u201copin-\nions\" OR \"view\" OR \"views\".\n\u2022 How? Surveys. \"survey\" OR \"surveys\" OR \"poll\" OR\n\"polls\" OR \"questionnaire\u201d OR \u201cquestionnaires\u201d.\nPrisma Diagram\n= 45): We searched the entire ACM\ndatabase, applying the aforementioned query to titles or\nabstracts from the most recent two years. This yielded\nnine records, with two overlapping with FAccT and AIES"}]}