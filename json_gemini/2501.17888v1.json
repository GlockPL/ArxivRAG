{"title": "RadioLLM: Introducing Large Language Model into Cognitive Radio via Hybrid Prompt and Token Reprogrammings", "authors": ["Shuai Chen", "Yong Zu", "Zhixi Feng", "Shuyuan Yang", "Mengchang Li", "Yue Ma", "Jun Liu", "Qiukai Pan", "Xinlei Zhang", "Changjun Sun"], "abstract": "The increasing scarcity of spectrum resources and the rapid growth of wireless device have made efficient management of radio networks a critical challenge. Cognitive Radio Technology (CRT), when integrated with deep learning (DL), offers promising solutions for tasks such as radio signal classification (RSC), signal denoising, and spectrum allocation. However, existing DL-based CRT frameworks are often task-specific and lack scalability to diverse real-world scenarios. Meanwhile, Large Language Models (LLMs) have demonstrated exceptional generalization capabilities across multiple domains, making them a potential candidate for advancing CRT technologies. In this paper, we introduce RadioLLM, a novel framework that incorporates Hybrid Prompt and Token Reprogramming (HPTR) and a Frequency Attuned Fusion (FAF) module to enhance LLMs for CRT tasks. HPTR enables the integration of radio signal features with expert knowledge, while FAF improves the modeling of high-frequency features critical for precise signal processing. These innovations allow RadioLLM to handle diverse CRT tasks, bridging the gap between LLMs and traditional signal processing methods. Extensive empirical studies on multiple benchmark datasets demonstrate that the proposed RadioLLM achieves superior performance over current baselines.", "sections": [{"title": "1 Introduction", "content": "With the proliferation of wireless devices and the scarcity of spectrum resources, managing and optimizing limited wireless network resources has become increasingly challenging [Nahum et al., 2023], [Sathyanarayanan et al., 2023a]. Integrating artificial intelligence (AI) with cognitive radio technology (CRT) offers a promising solution for optimizing spectrum sharing and enhancing communication quality [Haider et al., 2015]. However, traditional machine learning (ML) methods for radio cognition are limited by device noise and interference [Feng et al., 2024], while deep learning (DL) approaches, driven by data, excel at tasks like radio signal classification (RSC), signal denoising, and spectrum allocation, significantly improving communication performance. DL-based CRT frameworks simplify system complexity through end-to-end training but are often tailored to specific tasks and signal types. As shown in Figure 1, deploying these frameworks in real-world scenarios requires task-specific configurations, which limits their scalability and application in diverse industrial environments. Developing a universal CRT framework capable of handling diverse tasks and signals remains a critical challenge.\nThe advent of LLMs has reignited interest in Artificial General Intelligence (AGI). LLMs, pretrained on large-scale datasets using autoregressive techniques, demonstrate generalization capabilities far beyond traditional models, making them promising for CRT. Despite their potential, LLMs face challenges in CRT applications, such as the need for significant computational resources and architectures tailored to radio signals.\nAlthough LLMs have been applied to semantic communication [Xie et al., 2024], network optimization [Kotaru, 2023], and spectrum sensing [Shao et al., 2024], current methods exhibit several limitations:\n1) Limited Cognitive Understanding of Radio Signals: LLMs, trained on text, lack inherent understanding of radio signals. Existing works rely on text-based prompts and external tools, limiting their ability to process raw signals. We adopt reprogramming techniques in [Jin et al., 2024] to transform radio signals into formats compatible with LLM input, enabling direct signal processing and improving cognitive capabilities.\n2) Inefficient Expert Knowledge Integration: Textual prompting for injecting expert knowledge often results in verbose templates with unnecessary words, increasing computational overhead [Jin et al., 2024]. We propose a hybrid prompting method that retrieves concise and contextually relevant tokens, reducing memory usage and runtime while preserving information richness.\n3) Challenges in Capturing High-Frequency Signal Features: LLMs excel at low-frequency global information but struggle with high-frequency details critical for precise RSC tasks [Bai et al., 2022], [Si et al., 2022]. To address this, we propose the Frequency Attuned Fusion (FAF) module, which combines high-frequency features from CNNs with the global context captured by LLMs, enhancing their performance in RSC tasks.\nIn this paper, we introduce RadioLLM, which integrates Hybrid Prompt and Token Reprogramming (HPTR) with CRT using LLMs. HPTR couples expert knowledge with radio signal features, leveraging LLMs' world knowledge for semantic and high-dimensional feature extraction. Additionally, the FAF module improves the modeling of high-frequency information, while a lightweight decoder maps features back to the original signal space. Our contributions include:\n1. We propose a novel multimodal RadioLLM that achieves versatile CRT applications across diverse scenarios through multi-task joint learning. Leveraging the LLM's inherently rich world knowledge, we explore its application in CRT by employing reprogramming techniques. This approach enables the direct processing of radio signals by the LLM, significantly enhancing its cognitive capabilities regarding diverse signal types and reducing reliance on manual prompt engineering.\n2. To mitigate computational overhead and memory consumption, we introduce an innovative hybrid prompt technique that combines software and hardware prompts. This method involves identifying the top K semantically similar anchors within a joint semantic space for template text prompt embeddings. These anchors serve as concise and contextually relevant prompts, effectively eliminating unnecessary filler words while maintaining strong correlations with signal features. This streamlined prompting technique optimizes the model's performance in CRT tasks by ensuring that the prompts are both succinct and rich in pertinent information.\n3. We designed the FAF module to enhance the LLM's ability to model high-frequency features by fusing high-frequency and low-frequency information, thereby improving the performance of the downstream classification task while ensuring the performance of the generation task."}, {"title": "2 RELATED WORK", "content": null}, {"title": "2.1 Traditional DL-Based CRT Framework", "content": "Deep learning (DL)-based methods have been widely applied to critical tasks in CRT, such as RSC, signal denoising, and signal recovery. In RSC, supervised learning (SL) approaches have shown significant progress. For example, PETCGDNN used CNNs and GRUs for feature extraction to build an efficient modulation recognition model [Zhang et al., 2021a]. Additionally, a multi-view fusion RSC method was proposed, which leverages features from the time, frequency, and time-frequency domains to enhance performance [Ke and Vikalo, 2021].\nThe challenge of obtaining high-quality labeled data in wireless communication has driven the adoption of self-supervised learning (SSL). A Transformer-based SSL framework, TCSSAMR, was proposed for RSC [Kong et al., 2023a], and MCLHN utilized masked contrastive learning with hard negatives to enhance signal diversity [Xiao et al., 2024]. For signal denoising and partial recovery, a Deep Denoising Network was proposed using residual learning [Kaushal et al., 2016], and a time-frequency domain autoencoder was developed for denoising [Chen et al., 2024].\nWhile these methods excel in specific tasks, they are limited to individual applications and specific data types. To address this, we propose the LLM architecture as a universal CRT framework, pioneering AGI applications in CRT."}, {"title": "2.2 Previous LLM-Based CRT Framework", "content": "The emergence of LLMs has brought significant advancements to AI, influencing domains such as time series analysis and CRT. For example, LLMs have been used in semantic communication systems for contextual understanding [Xie et al., 2024] and in 6G edge computing for user association and resource allocation [Kotaru, 2023]. However, these applications are mostly limited to telecommunications language understanding.\nWirelessLLM has extended LLM applications to CRT tasks like power allocation and spectrum sensing, advancing AGI integration in CRT [Shao et al., 2024]. Yet, it relies on external tools, lacks an end-to-end signal processing pipeline, and overlooks critical tasks like WSC and signal denoising.\nTo overcome these challenges, we build on recent advances in time-series LLM research [Jin et al., 2024], [Pan et al., 2024], [Cao et al., 2024] by incorporating reprogramming and hybrid prompting techniques. This enables the development of a unified and versatile CRT framework capable of handling diverse signal types and tasks."}, {"title": "3 Methodology", "content": "Overview: As shown in Figure 2, RadioLLM is designed with two primary components. First, the input radio signal is divided into patches to generate its signal embedding. The first component involves combining expert knowledge prompts with the top-K semantically similar anchors, retrieved from word token embeddings enriched with extensive external knowledge. These anchors and prompts are used to construct prefix prompts for the signal embedding. The second component integrates high-frequency CNN features with low-frequency signal information, feeding the fused output into the pre-trained LLM.\nIn this work, GPT-2 is adopted as the backbone. During training, we not only learn the mapping function between inputs and outputs but also fine-tune GPT-2 using the LoRA technique [Hu et al., 2021]."}, {"title": "3.1 Problem Statement", "content": "In cognitive radio systems, the signal received by the secondary user device is often distorted due to the effects of the wireless channel and environmental noise. The received IQ signal $r(t) \\in R^{2\\times L}$ can be modeled as:\n$r(t) = h(t) * s(t) + n(t),$\nwhere s(t) is the transmitted signal, h(t) represents the channel response (e.g., path loss, multipath effects), and n(t) is the additive white Gaussian noise (AWGN). Here, L is the signal length, and 2 corresponds to the in-phase (I) and quadrature (Q) components.\nThe goal is to design a unified framework that can address multiple downstream tasks, including denoising, signal recovery, and classification. Let T denote the task-specific target:\n\u2022 For signal reconstruction tasks (including denoising and recovery), T = s'(t), where s'(t) represents the reconstructed signal or a task-specific attribute of the original transmitted signal.\n\u2022 For classification tasks, T = y, where $y \\in \\{1,2,..., C'\\}$ is the class label associated with the signal.\nTo address these tasks, we aim to learn a unified model F(r(t); \u0398), parameterized by \u0398, which maps the received signal r(t) to the target T. The unified optimization objective can be expressed as:\n$\\Theta = arg \\min_{\\Theta} E[L(F(r(t); \\Theta), T)],$\nwhere L(, ) is a task-specific loss function."}, {"title": "3.2 Hybrid Prompt and Token Reprogramming", "content": "Hardware prompts are widely used to inject expert knowledge into LLMs but often involve verbose, template-based structures that dilute meaningful information and increase computational cost. In contrast, pretrained software prompts encode general world knowledge but lack domain-specific relevance. To address these limitations, we propose a hybrid prompt mechanism, which combines hardware prompts with a reduced set of software prompts to achieve efficient and domain-relevant representations.\nGiven pretrained word token embeddings $E \\in R^{V\\times D}$, where V is the vocabulary size and D is the embedding dimension, we derive a reduced set of semantic anchors $E' \\in R^{V'\\times D} (V' \\ll V)$ via a mapping function f(E). For a hardware prompt T, tokenized and embedded as $P_t \\in R^{L_T\\times D}$, we compute a hybrid prompt $P \\in R^{K\\times D}$ by selecting the top-K most similar embeddings from E', formalized as:\n$P'[k,:] = E' [ArgTopK (max (P_t[i,:], E'), K) [k],:],$\nwhere \u03b3(\u00b7) is the cosine similarity function defined as:\n$\\gamma(P_{t}[i, :], E') = \\frac{P_{t}[i,:] E'^T}{|| P_{t} [i,:]||\\cdot ||E' ||}$\nHere, $P \\in R^{K \\times D}$ represents the hybrid prompt constructed by selecting the top-K embeddings from E', based on the maximum cosine similarity scores over all LT tokens in Pt.\nSince LLMs are trained on textual tokens, radio signals cannot be directly understood by LLMs nor described losslessly in natural language. Therefore, it is necessary to reprogram the radio signal sequences into semantic tokens interpretable by the LLM. To achieve this, we leverage a multi-head cross-attention layer for the reprogramming process. Specifically, we use Xs as the query matrix and E' as the key and value matrices. The reprogramming operation for each attention head is defined as follows:\n$Attention(X_s, E', E') = softmax\\left(\\frac{X_sW_q(E'W_k)^T}{\\sqrt{d_k}}\\right)E'W_v,$\nwhere $W_q, W_k$, and $W_v$ are the learnable projection matrices for the query, key, and value, respectively, and dk is the dimension of the key vectors. The outputs from all attention heads are concatenated and passed through a linear transformation. This linear projection maps the output of the attention layer to the LLM-compatible dimension, resulting in the signal tokens $F_s \\in R^{P\\times D}$, where P is the number of patches and D is the feature dimension. These signal tokens are then fed into the LLM for further processing."}, {"title": "3.3 Frequency Attuned Fusion", "content": "Existing LLMs, based on the Transformer architecture, excel at capturing low-frequency global information through the attention mechanism but are less sensitive to high-frequency features. In contrast, CNNs naturally excel at modeling high-frequency information. Based on this understanding, we propose the FAF module to augment the signal tokens Fs, enhancing sensitivity to high-frequency information in radio signals.\nThe FAF module consists of three high-frequency extraction (HFE) layers, with the structure of each HFE layer shown in Figure. 2(C). Each HFE layer leverages convolution to detect local variations, ReLU to enhance non-linear features, and pooling to compress redundant information, effectively extracting high-frequency features from the input data. This design enables the network to better capture fine-grained details in the input.\nThe FAF module takes the raw signal r(t) as input and outputs high-frequency features $F_h \\in R^{P\\times D}$ after three HFE layers. Subsequently, original signal tokens are reprogrammed with the high-frequency features Fh, while also being incorporated as a supplementary component. This process yields the frequency-enhanced signal tokens $F \\in R^{P\\times D}$. By integrating both global low-frequency information and fine-grained high-frequency details, these enhanced tokens enable the model to achieve a more comprehensive representation of the input radio signal."}, {"title": "3.4 Output Projection", "content": "The features $F_s$ and P are fed into the fine-tuned LLM module (Figure. 2 (D)) to obtain $F_{LLM}$ and $P_{LLM}$. After discarding the prefix $P_{LLM}$, $F_{LLM}$ is passed to the decoder to generate the output $O_s \\in R^{2\\times L}$. In this work, we explore two decoding strategies: a linear layer for direct mapping and a shallow Transformer decoder that uses self-attention to capture complex dependencies, yielding better reconstruction. The pretraining objective is to minimize the mean squared error (MSE) loss between Os and the ground truth s'(t)."}, {"title": "3.5 Training Strategy", "content": "The overall pretraining pipeline of RadioLLM and its application to downstream tasks are summarized in Algorithm 1. The process begins with the configuration of hyperparameters, including the network structure, optimizer, dataset parameters, and early stopping criteria. During pretraining, most parameters of the LLM remain frozen, with only a subset updated via LoRA [Kotaru, 2023]. To compute the loss across batches from different datasets within the same epoch, a loss balancing factor bi is introduced to mitigate the impact of differing dataset scales. Upon completion of pretraining, only the non-frozen parameters are retained to reduce storage overhead.\nFor downstream tasks, $F_s$, extracted from the LLM output, is used as the feature representation for classification tasks. After pooling, it is fed into a linear classification head. The decoder's output Os is directly used as the prediction for denoising and completing tasks."}, {"title": "4 Experiments", "content": null}, {"title": "4.1 Data", "content": "We used six publicly available datasets (RML2016a, RML2016b [O'shea and West, 2016], RML2016c [O'Shea et al., 2016], RML2018a [O'Shea et al., 2018], ADS-B [?], and Wi-Fi [Sankhe et al., 2019]) consolidated into a unified dataset. To prevent data leakage in downstream tasks, the data was split into training, validation, and test sets in a ratio of 8:1:1. For pretraining, high signal-to-noise ratio (SNR) signals (SNR > 14 dB) from the RML datasets were selected, while all signals from ADS-B and Wi-Fi datasets were included."}, {"title": "4.2 Implementation Details", "content": "During the training process, we conducted all experiments, including pretraining, comparisons, and ablations, on two A800 Ubuntu servers using the PyTorch 2.3.0 framework. The AdamW optimizer (weight decay = 5 \u00d7 10-3) was employed with an initial learning rate of 5 \u00d7 10-5. A linear warmup and decay schedule was applied during the pretraining phase, with the warmup phase covering 10% of the total training epochs. The training process was capped at 50 epochs, and the learning rate was halved if the validation loss stagnated for 5 consecutive epochs. Additionally, early stopping was triggered if validation loss did not improve for 20 consecutive epochs.\nFor downstream tasks like classification and denoising, a cosine annealing learning rate schedule was employed, starting with an initial learning rate of 5 \u00d7 10\u22125. All experiments were conducted under uniform settings to maintain fairness across methods and tasks. Inference time was measured in seconds per batch, with the batch size fixed at 128."}, {"title": "4.3 Evaluation Metrics", "content": "To meet practical requirements, we employed widely used metrics for quantitative assessment, including Overall Accuracy (OA), Cohen's Kappa coefficient (Kappa), and Structural Similarity Index Measure (SSIM). OA and Kappa were utilized to evaluate classification performance, measuring overall accuracy and agreement beyond chance, respectively. SSIM was used to assess the structural similarity between predicted and ground truth signals, providing a perceptually aligned evaluation of reconstruction quality."}, {"title": "4.4 Comparison with RSC methods", "content": "We evaluated our proposed method against a range of RSC approaches, including supervised models such as HCGDNN [Chang et al., 2022], PETCGDNN [Zhang et al., 2021b], MCLDNN [Xu et al., 2020], ICMACNET [Hermawan et al., 2020], CVCNN [Wang et al., 2021], SFS-SEI [Tao et al., 2023], and CVSRN [Han et al., 2024], as well as unsupervised methods like SemiAMC [Liu et al., 2021] and TC-SSAMR [Kong et al., 2023b]. For methods lacking publicly available code, we reconstructed their networks based on descriptions in their respective papers and retrained them. For other methods, we used pretrained models or retrained them under identical experimental settings to ensure fair comparisons.\nExperiments were conducted on several datasets across different configurations. We evaluated the RML2016a, RML2016b, and RML2016c datasets under both 50-shot and 100-shot settings, while the RML2018a Wi-Fi dataset was tested with a 100-shot setting. For the ADS-B dataset, 10% of the total data was used for fine-tuning due to its limited size. Full details of the experimental setups, including preprocessing, training, and evaluation protocols, are provided in the Appendix. As shown in Table 1, RadioLLM, pre-trained on large-scale data, consistently demonstrated superior performance across multiple datasets. On RML2016a, it outperformed TcssAMR in both 50-shot and 100-shot settings, showcasing the advantages of pre-training for feature extraction. However, Figure 3 reveals challenges with distinguishing similar modulation schemes like 16-QAM and 64-QAM, as well as noise-prone signals such as WBFM and AM-DSB.\nOn RML2016b, RadioLLM slightly surpassed SemiAMC in the 50-shot setting and maintained a clear edge over TcssAMR in the 100-shot setting, particularly excelling in low-noise environments. For the imbalanced RML2016c dataset, it demonstrated effective transfer learning by reducing misclassifications among similar modulation types, notably outperforming TcssAMR in both settings.\nRadioLLM also outperformed competing models on more complex datasets. On RML2018a, it managed increased task complexity better than MCLDNN, while on the Wi-Fi dataset, it achieved the highest performance among all methods tested, effectively handling intricate signal patterns. As shown in Figure 3, for the RML2018a dataset, misclassifications among similar modulation types, such as 8PSK and BPSK, were infrequent. This highlights the effectiveness of transfer learning in distinguishing between closely related signal types. On the ADS-B dataset, while RadioLLM did not achieve the best performance, its results were still acceptable. We evaluated the model's generalization ability on an unseen dataset, RML2022 [Sathyanarayanan et al., 2023b]. The detailed experimental results are provided in the Appendix.\nIn conclusion, RadioLLM demonstrates exceptional adaptability and generalization across a wide range of RSC tasks. On most datasets, RadioLLM achieved state-of-the-art performance, showcasing its ability to handle diverse and complex signal classification challenges. Its robust feature extraction and versatility make it a reliable solution for tasks requiring both precision and adaptability."}, {"title": "4.5 Comparison with Denoise methods", "content": "We evaluated our proposed method against traditional and deep learning-based denoising models across three datasets. For models without publicly available implementations, we reconstructed and retrained them following their published methodologies. Pretrained models were used when available; otherwise, all methods were retrained under identical conditions for fair comparisons (details provided in the Appendix). As shown in Table 2, RadioLLM achieves the highest SSIM across all datasets (0.987, 0.984, 0.986), underscoring its superior ability to preserve structural similarity. DNCNet [Du et al., 2022] demonstrates comparable performance, with SSIM values trailing marginally by 0.001-0.003, indicating its competitiveness. In contrast, the SGFilter [Schafer, 2011] falls short (0.979-0.978), reflecting the limitations of traditional methods compared to deep learning approaches. The slightly lower performance observed for all models on RML2016b may be attributed to unique noise characteristics or increased data complexity in this dataset."}, {"title": "4.6 Ablation Studies", "content": "To thoroughly evaluate the effectiveness of the proposed HTRP and FAF modules, a series of ablation experiments were conducted. These experiments systematically explored the contribution of each module to the overall model performance, offering deeper insights into their individual and combined impacts. Unless explicitly mentioned otherwise, all ablation studies were performed on the RML2016a dataset, using the experimental setup outlined in Section 4.2. The results are summarized in Table 3. The baseline model, which excluded both HTRP and FAF modules, achieved 55.39% OA, a Kappa of 0.5097, and a SSIM of 0.9839. Introducing the HTRP module alone improved the OA to 57.08%, the Kappa to 0.5283, and the SSIM to 0.9873. This improvement demonstrates the module's capacity to inject domain-specific knowledge, thereby enhancing the model's ability to identify relevant features.\nSimilarly, incorporating the FAF module independently yielded a slightly higher OA of 57.25% and a Kappa of 0.5306, while maintaining an SSIM of 0.9837. This suggests that FAF excels at extracting fine-grained, high-frequency features, contributing to a more detailed signal representation. When both modules were combined, the model achieved the highest performance across all metrics. Specifically, the OA increased to 58.10%, and the Kappa improved to 0.5391, although the SSIM saw a marginal decrease to 0.9819. These results highlight the complementary strengths of the two modules: HTRP enhances domain-relevant feature extraction, while FAF focuses on capturing intricate details. Together, they create a synergistic effect, integrating global low-frequency and fine-grained high-frequency features to improve classification accuracy and robustness."}, {"title": "4.7 Parameter Sensitivity Analysis", "content": "To assess the impact of key parameters on our framework's performance, we conducted a sensitivity analysis focusing on Top-K (K) selection, Decoder usage, and LLM choice. The experiments were performed on the RML2016a dataset under a consistent 100-shot learning setting to ensure fair comparisons. The results and observations for each parameter are detailed below.\nTop-K (K)\nWhile increasing K can improve metrics such as OA and Kappa by capturing richer information, it also increases computational load, leading to longer inference times. This study analyzes the sensitivity of OA, Kappa, and inference time (seconds per batch) to variations in K, highlighting the trade-offs between performance and efficiency. As depicted in Figure 4, the results demonstrate that K = 7 represents the optimal balance, achieving the highest performance (OA and Kappa) with a reasonable computational cost in terms of inference time.\nDecoder Usage\nTo further investigate the impact of the decoder, we conducted experiments by removing it and compared the model's performance across tasks. The results indicate that removing the decoder causes a slight performance decline. Specifically, OA dropped from 0.58312 to 0.57413, reflecting a decrease of 0.899%, while the Kappa coefficient decreased from 0.5419 to 0.532, a reduction of 0.0099.\nThese findings underscore the importance of the decoder in enhancing classification accuracy and consistency. By refining the model's contextual understanding and improving representation quality, the decoder significantly contributes to better task performance.\nLLM Choice\nThe choice of LLM directly impacts the performance and efficiency of the RadioLLM framework. We evaluated BERT, GPT-2, and LLaMA3 based on OA, Kappa, and Inference Time (seconds per batch). The results, shown in Table 4, highlight the trade-offs between classification performance and computational cost.\nAs shown in Table 4, LLaMA3 achieves the highest OA and Kappa but has a slightly higher inference time. GPT-2 offers a balance between performance and efficiency, with competitive accuracy and the lowest inference time. BERT, while fastest to deploy in some contexts, has lower accuracy and the longest inference time, making it less ideal for large-scale deployments."}, {"title": "5 Conclusion", "content": "This paper introduces RadioLLM, an innovative framework aimed at advancing CRT by seamlessly integrating radio signal processing with LLMs. The proposed HPTR mechanism effectively bridges the gap between radio signals and LLMs by combining hardware and semantic software prompts, enabling efficient and domain-specific representations. Complementing this, the FAF module enhances the framework's ability to capture fine-grained high-frequency features, which are crucial for handling complex signal environments in CRT. Extensive experiments across diverse tasks validate RadioLLM's effectiveness in addressing prominent challenges in CRT, such as noisy conditions, imbalanced datasets, and intricate signal patterns. These contributions establish RadioLLM as a robust and adaptable solution, paving the way for future advancements in cognitive radio systems."}, {"title": "C Experimental Details", "content": null}, {"title": "C.1 Data Organization", "content": "The data partitioning strategy for the datasets RML2016a, RML2016b, RML2016c, RML2018a, RML2022, Wi-Fi, and ADS-B is as follows:\nSelection of Experimental Data: The datasets are first filtered by selecting proportions of the original data:\n\u2022 RML2016a: 100% of the dataset is used.\n\u2022 RML2016b: 100% of the dataset is used.\n\u2022 RML2016c: 100% of the dataset is used.\n\u2022 RML2018a: 25% of the dataset is used.\n\u2022 RML2022: 25% of the dataset is used.\n\u2022 Wi-Fi: 10% of the dataset is used.\n\u2022 ADS-B: 100% of the dataset is used.\nData Splitting: After selection, the data is split into training (80%), validation (10%), and test (10%) sets.\nPretraining Stage:\n\u2022 For the RML datasets (RML2016a, RML2016b, RML2018a), only training samples with SNR > 14 dB are used for pretraining.\n\u2022 For the Wi-Fi and ADS-B datasets, all training samples are used for pretraining.\nFine-Tuning Stage: For fine-tuning, a limited number of samples are selected from the training set:\n\u2022 For RML2016a, RML2016b, and RML2016c 50 or 100 samples per class per SNR are chosen from the training set.\n\u2022 For the RML2018a, RML2022 and Wi-Fi dataset, 100 samples per class are selected from the training set.\n\u2022 For the ADS-B dataset, 10% of the training set is used for fine-tuning.\nDenoise Task: For the denoising task, high-SNR samples (SNR > 14 dB) from the RML series, Wi-Fi, and ADS-B datasets were artificially augmented with controlled noise to simulate noisy data. The denoising models processed these inputs, and their outputs were evaluated against the clean samples using the SSIM metric to ensure a standardized and objective assessment."}, {"title": "C.2 Data Augmentation", "content": "Phase Rotation\nPhase rotation is performed by rotating the phase of the original signal. The process can be mathematically described as:\n$s'(t) = s(t) \\cdot e^{j\\theta},$\nwhere s(t) is the original signal, \u03b8 is the rotation angle, $j = \\sqrt{-1}$, and s'(t) is the phase-rotated signal. The angle \u03b8 is typically chosen randomly from the interval [0, 2\u03c0).\nSignal Reverse\nSignal reverse enhances the signal by flipping it along the time axis. The process is defined as:\n$s'(t) = s(\\overline{t}),$\nwhere s(t) is the original signal, and s'(t) is the reversed signal. For discrete signals, the operation is expressed as:\n$s'[n] = s[N-1 \u2013 n],$\nwhere N is the total length of the signal, and n is the discrete time index.\nTime Warp\nTime warping is a method to enhance signals by altering their temporal dynamics through nonlinear time axis transformations. The process is mathematically described as:\n$s'(t) = s(\\phi(t)),$\nwhere s(t) is the original signal, \u03c6(t) is the time warping function, and s'(t) is the time-warped signal. The warping function \u03c6(t) must satisfy:\n\u2022 $\u03c6'(t) > 0$ (monotonicity),\n\u2022 \u03c6(t) \u2208 [0, T], where T is the total duration of the signal.\nFor discrete signals, the time warping operation is expressed as:\n$s'[n] = s[\\phi(n)],$\nwhere \u03c6(n) is the discrete time warping function."}, {"title": "C.3 Metrics", "content": "This section outlines the metrics used to evaluate the denoising and classification tasks. For the classification task, we utilize Overall Accuracy (OA) and Cohen's Kappa coefficient (Kappa), while the Structural Similarity Index Measure (SSIM) is employed for the denoising and masking task."}, {"title": "D Model Analysis", "content": null}, {"title": "D.1 Q&A Analysis on Applying LLMs to Radio Signal Feature Extraction", "content": "The application of large language models (LLMs) to radio signal feature extraction is an emerging research direction that combines advancements in natural language processing (NLP) with signal processing techniques. Below is a detailed analysis of the challenges", "signals.\nAdvantages": "n1. Sequence Modeling: LLMs excel at processing sequential data", "Understanding": "LLMs can learn contextual relationships in signal features", "Learning": "Pretrained LLMs on large datasets (e.g.", "Noise": "LLMs can learn to generalize across noisy data", "Applications": "n1. Modulation Recognition: Automatically identifying modulation schemes (e.g.", "Analysis": "Extracting and classifying spectral features for interference detection or signal identification.\n3. Signal Detection: Identifying weak signals buried in noise or interference using learned patterns.\n2. Key Challenges in Applying LLMs to Radio Signals\nApplying large language models (LLMs) to radio signal processing presents several unique challenges stemming from the fundamental differences between radio signals and text data. One of the primary difficulties lies in representing radio signals in a format compatible with LLMs. Common representations include raw IQ (In-phase and Quadrature) samples, which are complex-valued time-domain data; spectrograms, which transform signals into time-frequency representations; and feature vectors, which capture extracted characteristics like spectral peaks or bandwidth. Selecting the most suitable representation is critical, as it directly impacts how well the LLM can learn and process the signal's key features.\nAnother challenge is the high dimensionality of radio signals compared to text. High-bandwidth signals or long observation windows can result in sequences that are far longer than those typically encountered in NLP tasks. Feeding such long sequences into LLMs can significantly increase computational costs and memory requirements. Additionally, reducing the sequence length through downsampling or truncation risks the loss of essential information, which may degrade performance on tasks such as modulation"}]}