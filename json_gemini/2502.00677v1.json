{"title": "LLM-based event log analysis techniques: A survey", "authors": ["Siraaj Akhtar", "Saad Khan", "Simon Parkinson"], "abstract": "Event log analysis is an important task that security professionals undertake. Event logs record key information on activities that occur on computing devices, and due to the substantial number of events generated, they consume a large amount of time and resources to analyse. This demanding and repetitive task is also prone to errors. To address these concerns, researchers have developed automated techniques to improve the event log analysis process. Large Language Models (LLMs) have recently demonstrated the ability to successfully perform a wide range of tasks that individuals would usually partake in, to high standards, and at a pace and degree of complexity that outperform humans. Due to this, researchers are rapidly investigating the use of LLMs for event log analysis. This includes fine-tuning, Retrieval-Augmented Generation (RAG) and in-context learning, which affect performance. These works demonstrate good progress, yet there is a need to understand the developing body of knowledge, identify commonalities between works, and identify key challenges and potential solutions to further developments in this domain. This paper aims to survey LLM-based event log analysis techniques, providing readers with an in-depth overview of the domain, gaps identified in previous research, and concluding with potential avenues to explore in future.", "sections": [{"title": "1 Introduction", "content": "This paper provides an overview of developments, up to the time of writing, in the research field of using Large Language Models (LLMs) to perform event log analysis. Event logging is used to record events that occur in various systems and are of varying types, including system, application, and network logs [38]. Performing log analysis is necessary as it provides insight into how systems are performing and threats to optimal performance. If issues are found, then security professionals can address them. However, because of the significant number of events being generated, they require a large amount of time to analyse. In addition, since security professionals perform the task regularly, they can sufferfatigue [8] and as a result, logs that may provide important insights could go undetected. Due to these concerns, research needs to be conducted to improve the efficiency of event log analysis.\nOver the past few years, LLMs have gained attention in various fields due to their ability to perform tasks that humans usually undertake accurately, and at times exceed the performance that humans can achieve [84]. It has been highlighted that, specifically for data analysis tasks, they can perform at a high level [54]. As data analysis tasks are repetitive and the use of humans to perform these tasks is seen to be inefficient, deploying LLMs in these scenarios is a positive development.\nFollowing on from early developments, researchers saw the potential of using LLMs to perform event log analysis tasks. At the beginning stages, researchers investigated how well different models could perform event log analysis, re-"}, {"title": "2 Methodology", "content": "The methodology of this paper was, to the best of our ability, to gather all articles based on the use of LLMs for event log analysis. Google Scholar was used to search for articles hosted in the following research repositories, such as Elsevier, ScienceDirect, Springer, IEEE Xplore, etc. After the articles were recovered, we analysed their titles and abstracts to ensure that they were relevant, and those that were not were removed."}, {"title": "3 Literature Review", "content": null}, {"title": "3.1 Anomaly Detection", "content": null}, {"title": "3.1.1 Early Research", "content": "A large majority of the literature related to the topic of using LLMs for event log analysis focusses on anomaly detection. First, we will look at [35] who present an insider detection system which includes event logs as well as other data, to create a picture of the usual behaviour patterns of users. To begin, sensitive and user-identifiable information is removed to ensure privacy, it is then passed into the LLM to understand the patterns, normal behaviour patterns are established by using clustering, PCA, and auto-encoders, and finally the anomaly is detected using machine learning algorithms and NLP methods. The results show that there was an increase in the accuracy, precision, recall and F1 scores and the false positives were reduced by 40%. A limitation of this study is that it does not mention which LLM model was used. As a result of this, future work can investigate which LLMs can perform event log analysis, and in particular anomaly detection, accurately and efficiently. Similarly, [68] introduces LogSense, which uses both LogGPT and RAPID for anomaly detection. RAPID analyses individual event logs, and LogGPT analyses event logs as a whole. In addition, at the end of each day, the model is fine-tuned to increase accuracy, as event logs change over time. However, a limitation is that there is no data presented to show how well the model performs and no comparison with other models, so we are unable to identify its performance on anomaly detection in event logs. Future work based on this model can address the high false positive rate, as the models are developed to reduce the time security professionals spend analysing data, but the effects of this benefit are reduced with the presence of this limitation."}, {"title": "3.1.2 BERT", "content": "Moving on, we will look at models and solutions which are based on the BERT architecture. [9] introduce BERT-Log. Firstly, it structures the raw event logs and puts them into groups based on the order in which they occurred. The authors mention that their work is \"the first to utilize node ID and time to form log sequence\". After this, the logs are encoded in token form and put into vectors and then anomaly detection takes place. The authors tested BERT-Log on the BGL and HDFS datasets, changing the amount of data used for training, and then compared it to other methods. The results show that BERT-Log consistently received F1-Scores of 0.99 on both datasets, whereas the other models performed better on the HDFS dataset and differed in performance depending on the amount of data used for training. This shows that BERT-Log performs consistently when the amount of data used for training changes, and without a noticeable decrease in performance, when trained on more complex datasets such as BGL. The authors mention that future work based on this article can look at improving training efficiency and as a result reducing resourceconsumption.\nSimilarly, [14] introduces a BERT-based solution called BERT20M to produce a model for anomaly detection, reducing the size of the data. They propose using hierarchical classification, where log data is grouped into themes or categories. They conducted two tests; the results from the first test show that there is a significant decrease in the amount of time to process data, total number of lines, and count of tokens, for both 2k and 20mg, when hierarchical classification was applied, compared to the original data. For the second test, their model had the second lowest precision, recall, and F1 scores. As a result of this, a suggestion for future research is to research other methods of reducing the size of data, which can produce results which are the same or better than existing solutions. A different approach is taken by [13] who use the RAPID method to find anomalies in event logs. Their method involved fine-tuning a DistilBERT model on a dataset comprised of event logs, obtained from the industry, and then comparing it to the base DistilBERT model. The test produced surprising results, as both the base and the fine-tuned models had F1 scores of 0.94, Although this score looks positive, they highlight that there are a large number of false positives (normal logs classed as anomalies). A limitation of this method is that, although no training is required, specifically for anomaly detection, fine-tuning still needs to take place and this would still consume a large amount of resources. Future work based on this article can look into reducing the false positive rate.\nA similar approach is also taken by [71] introducing LogRoBERTa, their paper and method mention that previous work produced high F1 scores, but as security professionals need anomalies to be identified quickly, they attempt to reduce the time taken for anomaly detection. Specifically, they evaluate removing the parsing step as they suggest that the models can understand raw event logs without the need for parsing. ROBERTa is selected as it is an improvement of the BERT model because certain aspects such as layers and attention heads are increased, resulting in an improvement in understanding. Their results showed that LogRoBERTa outperformed the other methods in both data sets, highlighting the improvement of RoBERTa compared to BERT in anomaly detection. In addition, LogRoBERTa's F1 scores did not significantly change when using a parser, and the same was found with LogBERT. However, this was only based on a test using one dataset, with three parsers and with methods based on BERT. Thus, a suggestion for future work is to verify the results and suggestions in this paper by evaluating using other LLMs, datasets and parsers to prove that the use of parsers does not significantly improve anomaly detection with LLM models."}, {"title": "3.1.3 GPT Series", "content": "We will now look into research published on the GPT series. Beginning, [60] presents LogGPT which was one of the first models to be used for anomaly detection using LLMs. Their method specifically uses ChatGPT and begins by parsing the logs to a suitable format, implementing few-shot learning, showingthe model how to perform the task, and a \"response parser\" where the output is parsed and then outputted to the user. The methodology of testing was to compare its performance using the BGL and Spirit datasets against three machine learning models with both the model using few-shot and zero-shot learning. The results showed that LogGPT performed the second best on the BGL dataset and achieved comparable results, to two of the three machine learning models, but at times it achieved low scores on the Spirit dataset. In addition, generally, LogGPT performed better with few-shot learning than with zero-shot. As this was an early piece of work, suggestions based on the method would be to use methods such as fine-tuning or RAG to improve the results, in addition, to researching the use of offline models.\nAnother solution based on the GPT architecture is presented by [3] which is called HuntGPT, it was trained on an intrusion detection dataset and uses random forest to classify if logs are anomalies, the model used was GPT-3.5-turbo. The authors also use two frameworks, which give the model the ability to explain its results, this means that people who are not experts will be able to understand outputs. The model was tested on three recognized cyber security exams. Scores were \u201cbetween 72 and 82.5\" and their responses were informative and easy to understand. However, the model was not tested with event logs consisting of normal event logs and ones containing anomalies, which means that, although the model performs well at the exams and can explain suitably, we do not have any data that can highlight its performance anomaly detection. As a result of this, a future suggestion is to use the concept of explaining logs to people who are not experts in the field, in combination with accurately performing the task of anomaly detection. In addition, [21] explore anomaly detection on unstable logs, to address limitations present in previous methods. This refers to logs that have changed over time in a certain application. They fine-tuned GPT-3 on a dataset containing both stable and unstable logs, as during their research GPT-4 was not yet available for fine-tuning. The results showed that their fine-tuned model had a higher F1 score and also found that it performed better at classifying unstable logs than the other model and it performed well when there were 30% or lower unstable logs in the received prompt. The second test showed that, although GPT-4 is a newer model, the GPT-3 fine-tuned model outperformed both GPT-4 in the case of few-shot and zero-shot learning. Future work based on this article uses the method proposed with open-source models, such as LLama, as the authors mention that when fine-tuning GPT models they are \"disallowing any modification of their underlying architecture\" due to being closed source."}, {"title": "3.1.4 Comparison", "content": "As the two previous sections touched on solutions and work based on BERT and GPT, we will now look at articles comparing them to each other. [7] evaluate four GPT-3 models (Ada, Babbage, Curie and Davinci) on the task of anomaly detection. They use an open source event log dataset, to fine-tune the models, as well as provide a chat interface, giving users the ability to seek assistance fromthe model. The results showed that all models except Davinci, which received an F1 score of 0.4, achieved F1 scores above 0.9, and Ada was the superior model, achieving the highest score of 1. In addition, it is shown that all models except Davinci outperformed the models based on the BERT architecture. However, a limitation of this study is that it does not highlight that GPT-based models are online, which has the disadvantage of being a risk to privacy. Future work can look at developing models not based on the GPT architecture which can produce results that are equal or superior. Moving on, [49] evaluate the performance of three different classifiers using both GPT and BERT on four different datasets. The classifiers were the following machine learning algorithms: random forest, LightGBM and CatBoost. The results showed that the classifiers did not differ greatly in performance in all datasets, but all classifiers performed better and took less time to complete the task when using GPT. So, in terms of performance and accuracy, GPT is the superior model. However, a limitation of this result is that using GPT for event log analysis is a potential security risk, as event logs are sensitive data and the OpenAI API cannot be used offline; also, it sends data to their servers, whereas BERT does not have these two requirements and can be used offline."}, {"title": "3.1.5 Machine Learning Approaches", "content": "We will now look at where researchers have used various machine learning processes with LLM-based anomaly detection methods. [53] present LogLead which covers three aspects of event log analysis: loading, enhancing, and anomaly detection. Loading refers to the retrieval of event log data. For this study, eight well-known datasets, including HDFS and BGL, were used. Enhancing refers to the process where parsing takes place, different parsing techniques have been used, such as drain, to break the logs down into a format which is easier to understand. The anomaly detection occurs by using multiple machine learning algorithms. This method is different from other research covered within this literature review, as others focus on one technique, for example, parsing or anomaly detection, but not both. LogLead was found to load the datasets faster compared to the other two datasets. One of the tools had a difference that was in single digits; however, the other had a difference which at times was more than a hundred million seconds slower compared to LogLead. A limitation of this study is that it requires different methods to analyse all event logs and over time will require updates incorporating new methods, as event logs will continue to vary in both structure and content. Future work can be developing a tool that will continue to be relevant without the need for an update when new structures and content of event logs emerge.\nSimilarly, [43] present IDS-Agent, which is an intrusion detection system. Firstly, IDS-Agent extracts log data and prepossesses it, then uses various machine learning models to reach a result which is then summarised and outputted to users, using the LLM. The model can be configured as: GPT-3.5, GPT-40-mini, and GPT-40. They found that the best performance was with their GPT-40 model, then with their GPT-40-min, followed by GPT-3.5, all modelsoutperformed the base GPT-40 model. In addition, it was found that IDS-Agent detected zero-day attacks better than the other approaches as it had an average recall of 0.61, whereas the other approaches had an average recall of 0.41 and 0.47 respectively. A limitation of this study is that it utilises multiple machine learning algorithms for detection and does not highlight which is the best or if some are better at detection in certain scenarios. Thus, a suggestion for future work, based on this article is to look at which machine learning algorithms are the best to be used to classify logs as anomalies.\nA different approach is taken by [18] who introduce a tool which utilises LLM APIs and machine learning for anomaly detection. The authors highlight the computation costs of fine-tuning and suggest that their method addresses these issues. There are three steps for their method. The first step is parsing where the GPT-3.5 API is used to take an event log input and convert it into regex form. The second step is processing the data using the Text-embedding-ada-002 API, specifically, the authors make sure that it is not too small or an amount which goes over the context window of the LLM. The third step does not utilize LLMs but instead uses a deep learning model, which was trained to construct normal event logs, it takes the processed data encodes it, then decodes it and attempts to reconstruct the log and if there are many errors in the process then the log is classed as an anomaly. The methodology of testing the model is to use the HDFS dataset and they conducted two tests, one was by using 80% of the data for training and 20% for testing and for the second 99% for training and 1 was used for testing. On the first test, their method had an F1 score of 0.98 and on the second 0.998. Afterwards, they compared their results with similar methods which used LLMs for anomaly detection and their method had a higher F1 in comparison to them. Limitations of this study were that it requires human supervision and inputs, to successfully execute all the steps and that testing only took place with one dataset which does not give a general view of the proposed method's performance. Regarding future work, research can be conducted to centralize the method into one LLM API, as it uses two APIs as well as a deep learning model. In addition, researchers can look at automating the tasks within the method, to reduce human intervention."}, {"title": "3.1.6 In-Context Learning", "content": "Proceeding, we now delve into the theme of using prompt-based methods, [17] introduce a solution to address anomaly detection and issues regarding the low context windows of LLMs. Their solution does not require fine-tuning or RAG. It uses context creation which are prompts that allow the LLM to have a summary of its previous responses, addressing the context issue, and active analysis where it uses the summaries as knowledge to perform the task of anomaly detection. As the other solutions require training and fine-tuning, which has a large resource consumption, this method is a viable alternative. With regards to future work, more tests can be conducted and it can be compared to a larger amount of other solutions, to verify the results. Providing more data to assess the performance of in-context learning, [31] compare fine-tuning against in-"}, {"title": "3.1.7 Differing Approaches", "content": "We now look at other research which provides solutions that do not fit into the categories of previous sections. [91] introduce LogDAPT which consists of two schemes, the first is Masked Language Modelling (MLM) which is \u201cto prevent replacing tokens with natural language tokens that are not present in log texts\" which, when masking tokens, replaces tokens with ones that are found in the data rather than with random data. The second scheme is called Span, and this is where tokens are masked together, ensuring that related parts are not masked separately, which could result in the model incorrectly understanding data that it was trained on. The results showed three trends: BERT was lower than the rest of the models and significantly lower in precision, both schemes generally performed around the same as NeuralLog and at times slightly better, and the span scheme performed slightly better and sometimes the same but never worse than the MLM scheme. A limitation of this study was that it did not compare with a wide range of models to highlight how well it performs anomaly detection. As a result of this, future work can look at using the solution proposed in this paper and comparing it to other models.\n[4] introduce a new method of detecting anomalies in event logs, called LogFiT. Previous methods such as DeepLog and LogBERT have been shown to stick to the patterns they were fine-tuned upon and thus when they encounter a different type or structure, they are unable to accurately classify them. In addition, these models have a limitation on the amount of input tokens that they can receive. LogFiT attempts to address these issues, as it does not require preprocessing of data before fine-tuning, researchers have recently found this is a reason for the issues, mentioned about previous methods. The reason for this is that the data on which the LLM is trained will be more specific after preprocessing, whereas unmodified event logs will contain more information. When new types or structures of event logs emerge, the LLM will have a higher chance of being able to understand them. In addition to this, due to being exposed to complete logs in training, it can identify anomalies more easily because it will see that the log received deviated from the patterns found in its training data. Addressing the issue of a limitation on the number of tokens the model can receive, the authors propose using 'ROBERTa for sequences up to 512 tokens, and Longformer for longer log sequences'. The methodology of this paper is to train LogFiT, as well as DeepLog and LogBERT, on three publicly available event log datasets, then evaluate performance on anomaly detection."}, {"title": "3.1.8 Reducing Resource Consumption", "content": "Moving on, addressing the limitation of large resource consumption [67] proposes an Intrusion Threat Detection (ITD) using LLMs called Audit-LLM, the novel aspect of this model is that it uses multiple agents. The first is the decomposer agent which sets out various steps that need to be completed as part of the ITD process, the second is the tool builder agent which builds tools that are required for all of the steps to be completed successfully, and the third agent is the executor agent, which uses the tools that have been developed to complete the tasks that are required. The results show that Audit-LLM significantly outperforms the other LLMs, for all three datasets. However, this method has the limitation of requiring an abundance of resources; if run locally, even in the case of APIs, the cost and time would still be a large amount. Regarding future work based upon this paper, the authors suggest to 'reduce token usage', this will lessen the resource requirements, as the lower the number of tokens, the quicker it would be to train the model. In addition, they propose increasing the database of the model, with a larger variety of threats and the use of RAG to provide security professionals with relevant information on how to address threats highlighted by the system. A different approach to address resource consumption is taken by [85] who fine-tune Llama2-7B and use it to train a smaller model, to reduce the size and the amount of resources required. The methodology was to test the base LLM, teacher and student LLM, at anomaly detection on a large dataset containing multiple types of attack. The F1 score for the base model is 0.72, the student was 0.87 and the teacher model was 1. As a result of this, future work could look at comparing the student model with other solutions and a larger variety of datasets. This will present an accurate picture of how well the model performs anomaly detection against other solutions and if it is the same or better, this can justify the slight drop in the F1 score of the original fine-tuned model."}, {"title": "3.2 Fault Monitoring", "content": "To begin with, we look at [52] who present the CrashEventLLM framework which aims to use LLMs, based on previous crash log data, to predict the time and types of future crashes. They fine-tune and use in-context learning to show the model how to analyse crash logs to predict future occurrences. They used a data set gathered from Intel where data was sent from the participating machines every 24 hours. They used two models Llama2-7b and Llama2-13b. The results showed that for time prediction both models received F1 scores of 0.39, for cause prediction the 7b model achieved 0.46 and 13b 0.34 and for full prediction F1 scores were just below 0.2. The results are significantly lower compared to other event log analysis tasks completed using LLMs, as a result of this, future work can fine-tune other models to attempt to improve results. In addition, the dataset for this study were limited, if a dataset like LogHub2.0 was used, this may yield significant improvements. Addressing some of these suggestions, [27] propose LoFI which attempts to extract important data from logs. This prevents the need for security professionals to read raw event logs that consist of large amounts of noise. The model has three different components, preprocessed logs and extracting logs which focus on those that addressed faults, fine-tuning the model on a dataset generated by a company, and then in-context learning. LoFI responds with Fault-Indicating Descriptions (FID), which are descriptions of what the error was in the log, and Fault-Indicating Parameters (FIP), which are the area affected by the fault. They compared their method to two non-LLM-based methods and ChatGPT with zero-shot and few-shot learning. The results showed that LoFI achieved F1 scores ranging between 62.8 and 87.4 which is significantly higher compared to the other methods (GPT with few-shot learning, had the highest F1 score out of the other methods and it was 49.6). A limitation of this study is that the data used for fine-tuning were restricted. Future work can utilise a dataset that is not restricted to one company, which could improve results and allow the LLM to pick up on a larger range of faults.\nBuilding upon previous studies, [66] propose LogConfigLocalizer which is different to other methods as it allows general users to address errors which occur in their systems. Raw logs are preprocessed using the Drain algorithm and logs specifically containing words associated with faults are extracted, and few-shot learning is used to teach the GPT-4 model. There are two main steps of this model: anomaly identification, where the LLM looks through the data to find logs that could be errors, and the second step is anomaly inference, where logs found in the first step are verified to be logs indicating faults. They tested the model by comparing its accuracy with others; the results show that \"has a mean accuracy of up to 99.91\" which was higher than ConfDiag Detector, which was non-LLM based. Some limitations of this study are the use of GPT, which is a security risk as sensitive data (event logs) would be sent to their servers, the method not being compared to other LLM-based methods, and an evaluation of how easy the outputs are to understand for non-specialist users. Future work can address this by utilising open source LLMs, comparing their methods with"}, {"title": "3.3 Log Parsing", "content": null}, {"title": "3.3.1 Early Work", "content": "Parsing is a term used to describe the structuring of raw and unstructured event logs into a structured format. To begin, we will look at the earliest work that was found for parsing with LLMs. [40] evaluate the use of GPT for log parsing. The methodology of the study is to compare GPT-3.5.turbo with few-shot learning, against previous parsers, and to compare how different factors, such as the number of examples for few-shot learning or the complexity of prompts, affect performance. The results showed that GPT outperformed previous methods in message level accuracy (MLA) and edit distance (ED) and was second best in grouping accuracy, slightly behind Drain. Subsequent tests showed that the more examples used, for few-shot learning, the better the results and the more detailed the prompts are, the better GPT understands them and thus the results improve. A limitation is that the use of GPT has privacy risks, as data is sent and stored on OpenAI's servers, because of this future work can look at using LLMs which do not have this limitation. Similarly, [46] propose an LLMParser which uses few-shot learning. They tested their method on three LLMs T5Small, T5Base, LLaMA, and ChatGLM. An advantage of this method over others is that all LLMs used are offline, which addresses the limitation of online models that have security risks. The methodology of this paper is to compare the performance of the different models against each other and three other methods. The results show that the best performing model was LLaMa with the highest grouping (0.89) and parsing accuracy (0.96), it was also higher than the other methods to which LLMParser was compared, except for LogPPT, which had a higher grouping accuracy (0.92). However, a limitation of this model is that it requires updates over time, as the format of event logs changes, for example, with software updates, the structure and content of the logs will be different to what was used for LLMParser's few-shot learning. As a result of this, future work can address this limitation and take into account the changing nature of event logs without requiring updates, or in the case of methods using fine-tuning, retraining."}, {"title": "3.3.2 The use of different LLMS", "content": "Selecting a specific model, [83] presents DivLog which uses few-shot learning with GPT-3 to perform parsing. The authors base their idea on previous re-search, showing that LLMs can learn from receiving examples of how to perform tasks. In the context of DivLog, they use the Determinantal Point Process as an algorithm to label event log data and use it to teach the model how to parse. To test DivLog, the authors compare it against other parsing methods including, the LLM-based, LogPPT. The results showed that DivLog performedbetter than the others followed by LogPPT. A limitation of this study is GPT-3 is online-based, meaning all the prompts are sent to and stored on OpenAI's servers, this causes security concerns. Thus, although this method produces results which are improvements, compared to prior methods, future work can look into using few-shot models with offline-based LLMs to build upon this study. Following a similar concept, [94] introduce LogBert which uses GPT-3.5 with few-shot learning to perform parsing to understand the \"semantic information of logs\" which the opposite is mentioned as a limitation of previous methods. In addition, it uses BERT to perform anomaly detection. The methodology of this paper is to compare LogBERT's performance on the HDFS and BGL datasets, as well as differing examples, to see how it performs as a parser. The results show that it can perform well, but slightly below the majority of the methods that it was compared to, as well as the performance improving depending on the amount of examples given in few-shot learning. Future work can build upon this study to produce LLM-based parsers which can produce results that are equal to or better than previous methods, potentially using other techniques such as fine-tuning or RAG, instead of few-shot learning.\nFocussing on the performance of specific LLMs we look at a study conducted by [5] who compared five LLMs, consisting of open- and closed-source models, to highlight which are better at log parsing. They evaluated with LogHub datasets and the use of zero-shot and few-shot learning. They found that, the open-source model, CodeLlama performed the best, the rest for few and zero-shot were GPT-3.5, Claude 2.1, and Llama 2. CodeUp was better than Zephyr, for few-shot and Zephyr was better with zero-shot. These surprising results show that CodeLlama, although open source and free, can outperform recognised and propriety models such as GPT-3.5 and Claude 2.1. As a result of this, future work can look at using CodeLlama for research, instead of propriety models like GPT. In addition, CodeLlama also comes without the limitation of privacy risks, as it does not require you to send data to their servers. In addition, research can investigate if CodeLlama is better suited for other event log analysis tasks such as anomaly detection or root cause analysis. However, one limitation with using open-source models, like CodeLlama, is that they either run locally or on a cloud server, both of which could have large costs."}, {"title": "3.3.3 In-Context Learning", "content": "Delving into zero-shot learning, [92] propose YALP as an alternative to fine-tuning GPT models for parsing due to the large amount of resources required and costs. Their method uses zero-shot learning on GPT-3.5, where logs are pre-processed and matched against templates; if there are no matching templates, then a new one is produced. The model is evaluated on the LogHub-2.0 datasets against four other non-LLM-based parsers and the base GPT-3.5 model. The results show that YALP achieved an average grouping accuracy of 0.92, parsing accuracy of 0.72 and edit distance of 3.53. The grouping and parsing accuracy results were the highest, the edit distance was the lowest compared to the other methods and the base model. However, a limitation is that it requires templatesthat are generated following previous prompts and the model is not compared to others that use fine-tuning. Future work based on this paper can compare zero-shot learning to fine-tuned models, to build upon this study. Providing an answer to this suggestion, [87] propose LogGenius which does not require fine-tuning or few-shot learning and instead uses zero-shot learning. Instead of the LLM directly being trained or learning, they use non-LLM-based, unsupervised log parsing methods (Brain, Drain, Logram, Spell, AEL and Lenma). They conducted three tests: comparing using LogGenius with each method and against the base methods, the same test but with unseen logs and against GPT-auto (zero-shot learning using prompt engineering to produce results), and these were all measured on the percentage of parsing accuracy. The first test shows that Brain, Drain and AEL improved when used with LogGenius, whereas the others generally stayed the same. In the second test AEL, Lenma generally stayed the same, and the others had slight improvements. In the third test, all methods with LogGenius, except Lenma, outperformed GPT-auto. In addition, Brain produced the best results of all the methods that LogGenius used. Future work can look at using the LogGenuis method, with open-source LLMs, as in this study GPT-3.5-turbo was used, which has the limitation of security issues.\nMoving on, to look at in-context learning in a more general sense. [30] introduce an event log parser using LLMs, known as LILAC. The authors highlight, before their study, that the available models had various limitations, some of which include large amounts of computing resources required for fine-tuning, inconsistent outputs and the large amount of event log data produced by systems and LLMs having restrictions on the amount of data that they can process. The proposed method has two main components. The first is an ICL-enhanced parser, which instead of fine-tuning, uses in-context learning to teach the LLM the process to correctly parse the log. The second is an adaptive parsing cache, which is where the received event log is matched, using k nearest neighbours, to match the closest to it in terms of similarity. The advantage of the solu-tion is that if an event log has already been parsed, there will be a template stored, and both will be matched, saving the need for re-parsing. The selected model was GPT-3.5-turbo and they 'set its temperature to 0', which allows it to produce the same responses. The methodology for testing was to compare their model with its predecessors. The first test showed that it was superior by a large margin in parsing, except from Drain which was at times only slightly less accurate, but the authors mention that this is 'due to the imbalanced fre-quencies of templates in log datasets'. The second test found that the use of a parsing cache improved the model performance by almost 50%. The third test found that LILAC was able to integrate with models outside of ChatGPT with only a slight decrease in accuracy. The final test showed that the model was able to process a large amount of event log data, faster than all author LLMs against which it was compared, except for Drain, which was said to be 'the most efficient syntax-based log parser currently available'. Future work based on this article can address the issue of successfully and efficiently inputting event log data into a LLM, as they are generated, the authors highlight that this is a limitation which is yet to be addressed."}, {"title": "3.3.4 Fine-tuning", "content": "Shifting our attention to fine-tuning, [10"}]}