{"title": "FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation", "authors": ["Liangrui Pan", "Mao Huang", "Lian Wang", "Pinle Qin", "Shaoliang Peng"], "abstract": "Hematoxylin and Eosin (H&E) staining of whole slide images (WSIs) is considered the gold standard for pathologists and medical practitioners for tumor diagnosis, surgical planning, and post-operative assessment. With the rapid advancement of deep learning technologies, the development of numerous models based on convolutional neural networks and transformer-based models has been applied to the precise segmentation of WSIs. However, due to privacy regulations and the need to protect patient confidentiality, centralized storage and processing of image data are impractical. Training a centralized model directly is challenging to implement in medical settings due to these privacy concerns.This paper addresses the dispersed nature and privacy sensitivity of medical image data by employing a federated learning framework, allowing medical institutions to collaboratively learn while protecting patient privacy. Additionally, to address the issue of original data reconstruction through gradient inversion during the federated learning training process, differential privacy introduces noise into the model updates, preventing attackers from inferring the contributions of individual samples, thereby protecting the privacy of the training data.Experimental results show that the proposed method, FedDP, minimally impacts model accuracy while effectively safeguarding the privacy of cancer pathology image data, with only a slight decrease in Dice, Jaccard, and Acc indices by 0.55%, 0.63%, and 0.42%, respectively. This approach facilitates cross-institutional collaboration and knowledge sharing while protecting sensitive data privacy, providing a viable solution for further research and application in the medical field.", "sections": [{"title": "I. INTRODUCTION", "content": "Histopathological imaging has long been the gold standard for diagnosing cancer [1]. H&E-stained whole slide images (WSIs), which are widely utilized for surgical evaluation, have become an essential point of reference. Accurate segmentation of WSIs enables in-depth analysis of the tumor microenvironment, offering detailed insights [2]. However, the massive datasets required for pathological image processing involve not only significant computational costs but also raise concerns about patient privacy. In this context, traditional centralized learning faces substantial challenges. Conventional machine learning models typically require training on cen-tralized servers, meaning all pathological image data must be consolidated in one location for processing. However, due to privacy regulations and the need to protect patient confidentiality, the centralized storage and processing of pathological image data have become increasingly impractical [3].\nThe core concept of federated learning is to shift the model training process from centralized servers to local devices, allowing each medical device to collaboratively learn while protecting patient privacy. Federated learning enables data from different institutions to remain local, eliminating the need to share original data and only sharing model updates instead. This distributed learning approach offers a novel solution to the privacy and data security challenges faced in the field of pathological image processing [4].\nUnder the federated learning framework, each medical de-vice can train models locally, learning from the unique features of its local data [5]. The local model updates are then sent to a central server, where they are aggregated to form a global model. This updated global model is subsequently distributed back to the local devices, continuing iteratively. Throughout this process, the original data remains local, with only the model parameters being shared. This not only helps protect patient privacy but also effectively addresses the diversity and heterogeneity of pathological image data. The collaborative nature of federated learning is also evident during the model update process, as each local device shares model parameters with others, allowing them to complement each other and enhance the overall performance of the model. Moreover, the security of federated learning is ensured. Model updates are transmitted using encryption technologies, safeguarding the security of model parameters during transmission. This is crucial for preventing malicious attacks or theft, especially in the field of pathological image processing, where patient-sensitive information is involved.\nFederated learning holds tremendous potential in the field of pathological imaging. It can be applied not only in medical image diagnostics but also extended to medical research. In the diagnostic process of pathological image segmentation, federated learning can enhance model performance, adapt to the data characteristics of different institutions and devices, and better serve patients' diagnostic and treatment needs. In medical research, federated learning facilitates collaboration among multiple institutions, enabling data sharing and mutual benefits [6]-[13].\nHowever, in federated learning, protecting data privacy remains a critical issue [14], [15]. Although federated learning is typically designed to safeguard user data privacy, in some instances, methods such as gradient inversion attacks [10] can pose risks. These attacks involve analyzing a model's outputs and corresponding gradient information to infer the model's input data, potentially leading to the reconstruction of original data and resulting in privacy breaches [16], [17].\nOverall, the introduction of federated learning into the field of pathological image processing offers a new perspective on addressing the privacy and data security challenges as-sociated with centralized learning. Its collaborative nature helps enhance the generalizability of models, accommodating the diversity and heterogeneity of pathological image data. Moreover, by decentralizing the handling of data, it preserves the privacy of pathological image data, bringing new hope to the development of the medical field. However, federated learning still faces significant challenges in pathological image processing. This paper addresses the high computational costs and privacy leakage issues by incorporating methods such as differential privacy. Thus, in response to the issues of data silos and privacy breaches in cancer pathological imaging, this paper proposes a privacy-preserving method based on federated learning (FedDP) for segmenting cancer pathology images."}, {"title": "II. METHODS", "content": "As illustrated in Fig. 1, the overall framework of the model consists of local training processes on the client side and global aggregation processes on the server side, with the client and server exchanging weight calculations through uploads and downloads [18], [19]. For the clients, they must compute differential privacy on the model parameters after local training, and then upload the noise-added parameters to the server. The server, upon receiving the model parameters from all clients, performs a global model aggregation and then distributes the aggregated model back to the clients, ensuring a consistent set of global model parameters."}, {"title": "B. DHUnet", "content": "The architecture of the dual-branch hierarchical global-Local fusion network (DHUnet) is consists of a Swin Trans-former [20] global encoder, a ConvNeXt [21] local encoder, a decoder, and skip connections. The whole slide image (WSI) is initially divided into smaller patches using a sliding window technique. These patches are processed in parallel by the global and local encoder branches. In the global encoder, a patch embedding layer segments the patches into non-overlapping sections and maps the feature dimensions to a specified quantity, denoted as C. This reduces the resolution to one-quarter of the original size, resulting in feature dimensions of (w/4, h/4, C). These features undergo consecutive Swin Transformer blocks and patch merging layers to generate hier-archical global feature representations at different scales, such as (w/8, h/8, 2C), (w/16, h/16, 4C), and (w/32, h/32, 8C). In the local encoder, a stem layer also produces features of size (w/4, h/4, C). These features are further refined through ConvNeXt blocks and downsample layers to generate corresponding hi-erarchical local feature representations. Both the global and local encoders in the different stages generate hierarchical feature representations with resolutions similar to conventional convolutional networks like VGG [22] and ResNet [23]. In the decoder, the Global-Local Fusion (GLFusion) module and skip connections are utilized to capture coarse-grained global information and fine-grained local information from corre-sponding levels of the dual branches during the upsampling process. Additionally, a Cross-scale Expand Layer module is introduced to enable upsampling with the same center but different scales, enhancing segmentation results. Finally, a Linear Projection layer is applied to the upsampled features to output pixel-level segmentation for the small patches, and the segmentation results of all sliced blocks are merged to complete the segmentation of the entire WSI.\nIn the Swin Transformer global encoder, the patch em-bedding layer (PE) initially converts the input RGB image x \u2208 \\mathbb{R}^{h\u00d7w\u00d73} into non-overlapping patches of size 4x4, similar to the ViT [24]. Each patch is treated as a token, and its features are concatenated. Subsequently, the features with dimensions 4x4x3 are projected onto an arbitrary dimension C. To facilitate the exchange of information between neighboring windows, a series of Swin Transformer blocks (STBs) is employed. These STBs enable effective communication and interaction among the tokens in neighboring windows while preserving the total number of tokens. In this section, the number of Swin Transformer blocks per stage is adjusted"}, {"title": "from (2, 2, 6, 2) to (2, 2, 2, 2)", "content": "To differentiate features in the local encoder, the subscript 'g' is used. Thus, the process of computing global features in Stage 1 can be described as follows:\n$x_{g}^{1} = STB_{2}(PE(x)), x \\in \\mathbb{R}^{\\frac{h}{4} \\times \\frac{w}{4} \\times C}$ (1)\nTo generate hierarchical feature representations, the Patch Merging (PM) layer plays a crucial role in the network's deepening process. It concatenates the features from every group of 2x2 adjacent patches and utilizes a mapping layer to downsample the resolution by a factor of two while dou-bling the channel dimensions. This process contributes to the creation of hierarchical feature representations. Consequently, the process of computing global features for Stages 2, 3, and 4 can be described as follows:\n$x_{g}^{i} = STB_{2}(PM(x_{g}^{i-1}))$\n$x_{g}^{i} \\in \\mathbb{R}^{\\frac{h}{2^{i+1}} \\times \\frac{w}{2^{i+1}} \\times 2^{i-1}C}$ i = 2,3,4 (2)\nIn the ConvNeXt local encoder, similar to the global encoder process, the input image $x \\in \\mathbb{R}^{h\u00d7w\u00d73}$ first goes through the Stem layer. Following that, $x_{stem}$ undergoes processing in multiple ConvNeXt (CNBs) blocks to facilitate local feature fusion. In this particular section, the number of ConvNeXt blocks per stage has been adjusted from (3, 3, 9, 3) to (3, 3, 3, 3). To differentiate features in the local encoder, the subscript 'l' is used. The computation process for local features in Stage 1 can be described as follows:\n$x_{l}^{1} = CNB_{3}(Stem(x)), x_{l}^{1} \\in \\mathbb{R}^{\\frac{h}{4} \\times \\frac{w}{4} \\times C}$ (3)\nSimilar to the patch embedding layer, the downsampling layer (DS) utilized between each stage employs a convolution operation with a kernel size and stride of 2. This operation achieves a twofold reduction in resolution and doubles the channel dimensions. Additionally, a Layer Normalization (LN) layer is applied. Hence, the computation of local features for Stages 2, 3, and 4 can be summarized as follows:\n$x_{l}^{i} = CNB_{3}(DS(x_{l}^{i-1})),$\n$x_{l}^{i} \\in \\mathbb{R}^{\\frac{h}{2^{i+1}} \\times \\frac{w}{2^{i+1}} \\times 2^{i-1}C}$, i = 2,3,4 (4)\nIn the GLFusion decoder, to ensure the efficient integration of hierarchical features from the dual encoder branches, we propose a novel Global-Local Fusion (GLFusion) decoder. The GLFusion decoder aims to restore spatial resolution and generate segmentation results. For faster operational speed and enhanced performance, the GLFusion module initially uses additive operations to merge global and local features from the same stage. The result is then connected to the previous module via skip connections (SC), using convolution, batch normalization, and ReLU activation functions to align the output size with the input channel dimensions. Subsequently, an upsampling process, utilizing a Cross-scale Expand Layer which operates inversely to the downsampling and patch merging layers, is implemented. This upsamples the resolution by a factor of two while halving the channel dimensions or by a factor of four while maintaining the channel dimensions. It is accomplished by employing multiple transposed convolutions with identical strides but varying kernel sizes. The features generated by these convolutions are then concatenated along the channel dimension. This approach enables patches with the same center but different scales to achieve diverse rec\u0435\u0440-tive fields. The computation process for GLFusion4 can be described as follows:\n$f_{4} = concat[transpose(\\tau(SC(x_{g}^{4} + x_{l}^{4})), i=1 to M)]$,\n$f_{4} \\in \\mathbb{R}^{\\frac{h}{8} \\times \\frac{w}{8} \\times 4C}$ (5)\nWhere $f_{4}$ represents the output of the GLFusion4 module. The computation processes for GLFusion2 and GLFusion3 can be described as follows:\n$f_{i} = concat[transpose(\\tau(SC(x_{g}^{i} + x_{l}^{i}, f_{i+1})), i=1 to M)]$,\n$f_{i} \\in \\mathbb{R}^{\\frac{h}{2^{i}} \\times \\frac{w}{2^{i}} \\times 2^{4-i}C}$, i = 2,3 (6)"}, {"title": "The computation process for GLFusion1", "content": "can be described as follows:\n$f_{1} = concat[transpose(\\tau(SC(x_{g}^{1} + x_{l}^{1}, f_{2})), i=1 to M)]$,\n$f_{1} \\in \\mathbb{R}^{h \\times w \\times C}$ (7)\nFinally, a linear projection layer (LP) is applied to the output $f_{1}$ of the GLFusion1 module to obtain pixel-level segmentation results for the sliced blocks:\n$Segmentation(x) = LP(f_{1})$ (8)"}, {"title": "C. Client-side training", "content": "This chapter, based on the FedAvg strategy, addresses gradient privacy leakage by incorporating differential privacy techniques. It assumes that there are K clients participating in the training, with each client k possessing their own local dataset $D_{k}$ and sharing the same initial global model parameters $\u03b8_{0}$.\n1. Global model Initialization $\u03b8_{0} \\sim Initialization$, Initialization is the initialization method of the global model parameters.\n2. Client Selection: A portion K is randomly selected from C clients as participants in this round.\n3. Model Distribution: The central server distributes the global model parameters $\u03b8$ to the selected participants.\n4. Local training: Each client $c \\in C$ uses the local dataset $D_{c}$ to perform local model training and update the gradient. After the t-th round of distributed training, client c performs E local updates locally to obtain the local model parameters $\u03b8_{t+1}^{c}$:\n$\u03b8_{t+1}^{c} = ClientUpdate(\u03b8, D_{c}, E), t\u2265 0$ (9)\nAmong them, Client Update is the function of updating model parameters locally on client c, and the gradient descent method is used to implement the training of deep learning model:\n$\u03b8_{t+1}^{c} = \u03b8_{t}^{c} + \\frac{\\eta}{k} \\sum_{i=0}^{k}\\Delta \u03b8_{i}^{c}$ (10)"}, {"title": "D. Differential privacy", "content": "Differential Privacy (DP) is a privacy-preserving technique designed to provide meaningful data analysis results while ensuring the protection of individual privacy during statistical analysis or data mining. Differential privacy achieves this by introducing noise into the computation process, making it impossible to infer specific individual information from the output.\nNoise Addition: To protect privacy, clients need to introduce noise when computing gradients. This noise can be random and must satisfy the conditions of differential privacy. Typi-cally, Laplace noise or Gaussian noise is used for differential privacy computation.\nLaplace Noise: Participants generate Laplace noise based on the differential privacy parameter $\u03b5$ and sensitivity $\u0394f$. The probability density function of the Laplace distribution is given by $p(x) = \\frac{1}{2b}e^{-\\frac{|x|}{b}}$, where x represents the noise value. The scale of the noise is determined by the sensitivity of the gradient, i.e., the noise scale is $\\frac{\u0394f}{\u03b5}$.\nGaussian Noise: Participants can generate noise using a Gaussian distribution, where the probability density function of the Gaussian noise is $p(x) = \\frac{1}{\\sqrt{2\u03c0\u03c3}}e^{-\\frac{x^{2}}{2\u03c3^{2}}}$, with x being the noise value and \u03c3 being the standard deviation.\nIn the privacy computing process, the model training update phase uses the update function after adding Gaussian noise:\n$\u03b8_{t+1}^{c} = \u03b8_{t}^{c} + \\frac{\\eta}{k} (\\sum_{i=0}^{k}\\Delta \u03b8_{i}^{c} / max(1, \\frac{\u0394f^{2}}{\u03b5^{2}C^{2}}) + N(0, \u03c3^{2}C^{2}I))$ (11)\nWhere \u03b5 and C are hyperparameters in the privacy computing strategy. The conditions for the Gaussian mechanism to satisfy (\u03b5, \u03b4)-differential privacy are:\n$\u03b5 = \\frac{\u0394f}{\u03c3}$ (12)\nwhere \u0394f represents the sensitivity, indicating the maximum change in the function's output on neighboring datasets. For gradient computation, sensitivity can be controlled by clipping the gradients. Assuming the clipping threshold is C, we have:\n$\u0394f \u2264 C$ (13)\nThus, the relationship between the privacy budget \u03b5 and the noise standard deviation \u03c3 is:\n$\u03b5 = \\frac{C}{\u03c3}$ (14)"}, {"title": "E. Server-side aggregation", "content": "After completing local training, the client sends its updated or encrypted model parameters $\u03b8_{t+1}^{A(c)}$ to the server. Once the server receives updates from all clients, it performs global parameter aggregation using a weighted average method:\n$\u03b8_{t+1} = \\frac{1}{C} \\sum_{c=1}^{C} \u03b8_{t+1}^{c}$ (15)\nOnce the server completes the aggregation, it distributes the global parameters to each client. The process of client training and applying differential privacy is iteratively repeated until a stopping condition is satisfied. This stopping condition can be defined as reaching the maximum number of iterations or attaining model convergence."}, {"title": "III. EXPERIMENTAL", "content": "The experiments in this study are conducted using Python 3.7 and PyTorch 1.7.0. Data augmentation techniques such as horizontal flipping, vertical flipping, and random rotations between -90\u00b0 and 90\u00b0 are employed to enhance the diversity of data positions for all training models. Additionally, to enhance the network's resilience to variations in color, random hue-saturation-value (HSV) transformations are applied. The dataset is then divided randomly into training and testing sets, with a ratio of 0.7:0.3. The models are trained using 5-fold cross-validation on an NVIDIA Tesla V100 GPU (16GB VRAM). The optimal parameters for the models are deter-mined by averaging the performance on the validation sets. The input size for the model is set to 224x224, and the maximum number of training epochs for the WSSS4LUAD dataset is set to 150 to ensure loss convergence.During the training phase, a standard SGD optimizer is used for back-propagation network optimization, with a default batch size of 24. The experiment included 5 local clients, with each client performing 5 local iterations, and the server performing 150 rounds of global integration. The CPU used is a 16-core Intel(R) Xeon(R) Bronze 3106 CPU @ 1.70GHz. Additionally, differential privacy parameters and \u03b5 are set to 0.5 and 0.05, respectively."}, {"title": "B. Datasets", "content": "Experiments on the Lung Cancer WSSS4LUAD Dataset includes labels for tumors, stroma, and normal tissues, and is publicly provided by the WSSS4LUAD 2021 Challenge\u00b9. The dataset comprises 23 large patches selected from Guangdong Provincial People's Hospital and The Cancer Genome Atlas (TCGA). The patches have resolutions ranging approximately from 1500\u00d75000 to 1500\u00d75000. Additionally, 20 whole slide images (WSIs) are collected from TCGA (one WSI per patient), combining to form the lung cancer WSSS4LUAD dataset. The dataset undergoes processing using a sliding window approach with a resolution of 1000\u00d71000 and a stride of 500. Subsequently, the images are resized to 224x224 to match the model's scale."}, {"title": "IV. RESULTS", "content": "As shown in Table I, under the baseline framework based on federated learning, DHUnet demonstrates significant advan-tages compared to other CNN-based and Transformer-based models. On the WSSS4LUAD lung cancer dataset, its Dice, Jaccard, and Acc scores reach 85.23%, 76.26%, and 90.71%, respectively, showcasing outstanding performance. These met-rics are widely recognized in image segmentation tasks and are crucial for evaluating model performance. Although the performance of all models decreased compared to methods without federated learning, the security of data and models cannot be ensured without it.\nNotably, DHUnet manages to maintain high accuracy even with the incorporation of differential privacy through FedDP, resulting in minimal Dice, Jaccard, and Acc losses of only 0.55%, 0.63%, and 0.42%, respectively, while still maintain-ing a leading edge in segmentation performance. Compared to the best-performing Transformer-based model, TransFuse, DHUnet improves Dice, Jaccard, and Acc scores by 0.59%, 0.96%, and 0.38%, respectively. When compared to the best-performing CNN-based model, ConvNeXt, it shows improve-ments of 2.69%, 3.27%, and 1.95% in Dice, Jaccard, and Acc metrics, respectively. These enhancements are likely attributed to the design of the global-local fusion decoder and skip connections in the DHUnet model.\nIn the visualization results shown in Fig. 2, DHUnet also demonstrates excellent performance. Under the federated learning framework, DHUnet continues to exhibit high seg-mentation quality in image segmentation tasks, maintaining a high degree of similarity, overlap, and accuracy with the ground truth. This highlights its robustness and generalization capabilities. Among all models, the FedDP method showcases the best segmentation performance. Therefore, FedDP not only accurately segments pathological images but also ensures data privacy and model security.\nAs illustrated in Fig. 3, inversion attacks are unable to reconstruct the original pathological images. Compared to traditional federated learning methods, the introduction of differential privacy technology significantly enhances the pri-vacy of data distribution and effectively prevents data leakage and privacy breaches. This provides users with more reliable data protection measures. Additionally, the application of this technology increases users' trust in data-sharing schemes, as they can share data with greater confidence, without fear of privacy being compromised or misused. Therefore, the FedDP method has broad application prospects in the fields of data sharing and privacy protection, offering vital support for building secure and reliable data-sharing solutions.\nIn summary, FedDP demonstrates outstanding performance within the federated learning framework, maintaining high lev-els of accuracy even with the inclusion of differential privacy. FedDP achieves notable results in performance metrics such as Dice, Jaccard, and Acc, while also enhancing the privacy of data distribution through differential privacy technology. This strengthens the security and privacy protection of user data. The analysis of visualization results further confirms FedDP's superiority in image segmentation tasks, showcasing its robustness and generalization capabilities. Consequently, FedDP provides strong support and assurance for data sharing and privacy protection."}, {"title": "B. Ablation Experiment", "content": "As shown in Table II, ablation experiments reveal that a larger standard deviation increases the magnitude of noise, providing stronger privacy protection but potentially impacting data accuracy. Conversely, increasing the C value enhances the overall accuracy of the model. Therefore, this study selects the optimal values as input parameters for the model to ensure the best possible performance."}, {"title": "V. CONCLUSION", "content": "The challenge of training deep neural network models with good generalization performance is significantly heightened due to the difficulty of sharing image data across different medical institutions. To address this issue, this chapter pro-poses a privacy-preserving method based on federated learn-ing. Additionally, the chapter addresses the risk of sensitive data leakage through the transmission of model updates during the training process. Federated learning allows each medical institution to train models locally without the need to share sensitive image data. Furthermore, we employ differential privacy techniques to enhance data privacy protection. Differ-ential privacy introduces noise into model updates, making it impossible for attackers to infer the contributions of individual samples, thereby safeguarding the privacy of the training data. Experimental results demonstrate that our proposed method has minimal impact on model accuracy while effectively protecting data privacy. This means that it is possible to ensure the privacy and security of medical image data without signif-icantly sacrificing accuracy. Therefore, the FedDP method has broad application prospects in the fields of data sharing and privacy protection, providing vital support for building secure and reliable data-sharing solutions."}]}