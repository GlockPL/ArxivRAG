{"title": "DEEP LEARNING FOR MICRO-SCALE CRACK DETECTION ON IMBALANCED DATASETS USING KEY POINT LOCALIZATION", "authors": ["Fatahlla Moreh", "Yusuf Hasan", "Bilal Zahid Hussain", "Mohammad Ammar", "Sven Tomforde"], "abstract": "Internal crack detection has been a subject of focus in structural health monitoring. By focusing on crack detection in structural datasets, it is demonstrated that deep learning (DL) methods can effectively analyse seismic wave fields interacting with micro-scale cracks, which are beyond the resolution of conventional visual inspection. This work explores a novel application of DL based key point detection technique, where cracks are localized by predicting the coordinates of four key points that define a bounding region of the crack. The study not only opens new research directions for non-visual applications but also effectively mitigates the impact of imbalanced data which poses a challenge for previous DL models, as it can be biased toward predicting the majority class (non-crack regions). Popular DL techniques, such as the Inception blocks are used and investigated. The model shows an overall reduction in loss when applied to micro-scale crack detection and is reflected in the lower average deviation between the location of actual and predicted cracks, with an average IOU being 0.511 for all micro cracks (>0.00 \u00b5m) and 0.631 for larger micro cracks (>4 \u00b5m).", "sections": [{"title": "1 Introduction", "content": "Structural health monitoring is a critical area where the safety of infrastructures depends on the detection of internal cracks, which are not visible on the surface. These hidden cracks pose a significant challenge because detecting them requires a combination of domain expertise in both deep learning and material science to effectively extract the relevant"}, {"title": "2 Related Work", "content": "In recent years, deep learning models, particularly convolutional neural networks (CNNs), have emerged as powerful tools for accurately segmenting crack regions from input data. CNNs have been successfully applied to surface crack detection by learning hierarchical features, enabling improved performance in complex environments. However, segmentation-based methods often face challenges, particularly class imbalance where cracks occupy a small number of pixels relative to the background, making it inefficient to train models effectively. This imbalance often leads to poor detection performance as models tend to become biased towards background pixels. Various strategies have been introduced to address class imbalance, such as weighted loss functions, data augmentation, and focal loss. While these techniques offer some improvements, researchers have shifted attention toward object detection models, including Faster R-CNN, YOLO, and SSD, which have been widely applied in object detection tasks. For example, demonstrated that object detection models like SSD MobileNet require significantly less computational power and are less complex than segmentation models, making them ideal for scenarios where speed and computational resources are limited. This makes object detection an attractive approach for crack detection using numerical data, especially in environments with constrained resources. Object detection models focus on identifying regions of interest, such as cracks, rather than classifying every pixel in the image, which makes them more efficient in handling small objects like cracks. However, most of these approaches have been applied to visual data, leaving a gap in adapting these techniques to numerical data, such as wave propagation simulations, for detecting internal cracks. In addition to object detection, some researchers have explored the use of numerical data for damage detection in composite materials. For instance, employed a geometric modification of the RAPID algorithm, leveraging signal acquisition between transducers to accurately localize and characterize damage. This highlights the potential of using numerical data in crack detection, further motivating the need to explore object detection models in this context."}, {"title": "3 Method", "content": ""}, {"title": "3.1 Wide Convolutional Netoworks", "content": "Wide networks, like those incorporating Inception modules provide an alternative to the deeper convolutional networks seen in architectures like ResNet and DenseNet. While deeper networks are highly effective at feature extraction, they come with the trade-off of requiring significantly higher computational power and memory. These deep models extract hierarchical features through successive layers, capturing intricate patterns, but"}, {"title": "3.2 Model Architecture", "content": "Our model follows the design philosophy of a wide convolutional networks, The model in this research is designed around a combination of convolutional blocks, attention mechanisms, and dense layers to effectively process and extract features from the input. Each convolutional block is designed with three convolutional branches-1x1, 3x3, and 5x5 convolutions-each processing the input at different scales. These branches are followed by batch normalization and an ReLU activation to stabilize and enhance learning. A max-pooling branch is also included to further downsample the input. The outputs of all branches are concatenated to form a comprehensive feature map, capturing multi-scale information. The attention layer processes the output of the pooling layers by focusing on key areas within the feature map. It calculates an attention-weighted sum of the features, which is then added back to the original input, reinforcing relevant features and filtering out noise. After multiple attention and pooling layers, the feature map is reshaped and processed through two additional convolutional layers. The first uses a kernel size of (31, 1), followed by reshaping and applying a 3x3 and 4x4 convolution. These layers aim to extract more complex patterns from the feature map while further reducing its dimensionality. The fully connected layers consist of dense layers with dropout regularization to prevent overfitting. The first two dense layers have 128 and 64 neurons, respectively, with ReLU activation. The final output layer contains four neurons and uses a linear activation function to provide the regression outputs. The model outputs a four-dimensional vector, representing the final predicted values for the task. The model is optimized using regularization techniques to improve generalization."}, {"title": "3.3 Loss Functions", "content": "\u2022 MSE Loss: The Mean Squared Error (MSE) is a widely used loss function in regression tasks, measuring the average squared difference between predicted and actual values. The MSE equation is:\n\n$MSE = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y_i})^2$\n\nwhere yi represents the actual values and \u0177 are the predicted values. One of the main advantages of MSE is its strong emphasis on larger errors due to the squaring term, making it more sensitive to outliers compared to Mean Absolute Error (MAE). This property ensures that significant deviations have a proportionally higher influence on the loss value, prompting the model to prioritize reducing large errors.\n\u2022 MAE Loss: The Mean Absolute Error (MAE) is a loss function that calculates the average magnitude of the absolute differences between predicted and actual values. Its mathematical formulation is:\n\n$MAE = \\frac{1}{N} \\sum_{i=1}^{N} |y_i - \\hat{y_i}|$\n\nwhere yi represents the actual values and \u0177\u2081 are the predicted values. MAE is advantageous over Mean Squared Error (MSE) in several ways. First, MAE is less sensitive to outliers since it does not square the errors, making it more robust in scenarios where large deviations exist. In contrast, MSE, due to its sensitivity to large errors, may cause computational issues in deep neural networks and can be less effective in handling noisy data.\n\u2022 Huber Loss: The Huber loss combines the advantages of both Mean Absolute Error (MAE) and Mean Squared Error (MSE). Its key feature is its ability to behave like MSE for small errors (thereby benefiting from strong convexity and fast convergence) and like MAE for larger errors (providing robustness against outliers). The formula for Huber loss is:\n\n$L_\\delta(x) = \\begin{cases} \\frac{1}{2} x^2 & \\text{for } |x| \\leq \\delta \\\\ \\delta (|x| - \\frac{1}{2} \\delta) & \\text{for } |x| > \\delta \\end{cases}$\n\nHere, & is a threshold that determines the point where the loss function transitions from quadratic to linear behavior. For errors smaller than 8, Huber loss acts like MSE, focusing on fast convergence and sensitivity to minor deviations. For larger errors, it switches to a linear form similar to MAE, preventing outliers from disproportionately affecting the model."}, {"title": "3.4 Training Procedure", "content": "The training procedure of the model begins with a preprocessing step that utilizes a 1D MaxPooling layer to reduce the temporal dimension of the input, which is originally shaped (2000, 81, 2), by a factor of 4, resulting in a feature map of shape (500, 81, 2). This strong reduction is essential due to the large number of time steps. Since we are primarily focused on detecting changes in wave behavior caused by cracks, forwarding only the strongest signals simplifies the model without sacrificing key information. Waves behave most distinctively when they encounter a crack, which is our highest priority. By downsampling, we effectively reduce model complexity, and this downsample factor of 4 was chosen after extensive evaluations with different max-pooling sizes. This is followed by a series of four convolutional blocks, each progressively increasing the complexity of the feature extraction process.\nConvolutional Blocks Each convolutional block is designed to capture different levels of features from the input. The convolutional layers within each block use kernel sizes of (1x1), (3x3), and (5x5), with filters increasing progressively across the blocks. The filter size starts at 16 for the first block and increases by a factor of 2 for the next blocks, ensuring deeper layers extract more complex features.\nConvolution Branches:\n\u2022 1x1 Convolution Branch: This branch applies 1x1 convolutions to maintain the spatial dimensions while enhancing feature extraction. It allocates a quarter of the total filters to this branch, helping to reduce parameters and ensure a focused feature transformation.\n\u2022 3x3 Convolution Branch: The 3x3 convolutional layers in this branch take half of the total filters, designed to capture more local information from the input. This helps in capturing small-scale patterns that may not be picked up by the 1x1 branch.\n\u2022 5x5 Convolution Branch: Allocating another quarter of the total filters, this branch focuses on capturing larger-scale features, extracting more global patterns from the input data."}, {"title": "\u2022 Pooling Branch", "content": "Alongside the convolution branches, a pooling branch performs MaxPooling (3x3) with strides of (1,1), followed by a 1x1 convolution to further process the pooled features. This helps capture features at multiple scales, including lower-resolution patterns.\nAfter the convolution and pooling operations, the outputs from all branches are concatenated, combining the information extracted at various scales. The resulting feature map captures both time and spatial relationships between wave data and cracks. At this stage, the feature map focuses on both time-based wave behavior and spatial relationships in the 9x9 sensor grid, which is critical for detecting and localizing cracks accurately. After each convolutional block, MaxPooling is applied to reduce the spatial dimensions while retaining the most relevant features. Reducing dimensions through MaxPooling is computationally cheaper than doing so through additional convolutional layers. MaxPooling also helps forward only the strongest signals, which is crucial for wave-based crack detection. We chose MaxPooling over average pooling because even after dimension reduction, the strongest signals carry the most valuable information for identifying cracks. A self-attention mechanism is introduced after each pooling step, which allows the model to focus on specific regions of the feature maps, particularly helping the model focus on cracks in the image. This self-attention layer recalculates the importance of different regions and improves feature selection before passing the feature map to the next convolutional block. The attention mechanism processes both the temporal and spatial information, ensuring that the model focuses on the most relevant signals. The feature map from the last attention layer is passed through a Flatten layer, which converts it into a single-dimensional embedding. This embedding is then fed into a series of dense layers. The first dense layer has 128 output units, which are reduced by half in each subsequent layer, ultimately leading to the final dense layer with 4 output units. This design progressively refines the feature representation, with dropout layers included between dense layers to prevent overfitting."}, {"title": "Evaluation", "content": ""}, {"title": "3.5 Datasets", "content": "Generating numerical data through real-world experiments would be highly expensive and time-consuming. Therefore, to overcome these challenges, we synthetically generate the data using dynamic Lattice Element Method (dLEM) approach. This allows us to model and track wave propagation through cracked materials in a controlled, cost-effective manner, while still maintaining the complexity and realism needed for effective crack detection. By leveraging this synthetic data, we can explore various crack patterns and wave interactions that would be difficult to replicate in real-world settings. The dataset contains information about the behavior of seismic waves the waves propagation in a dynamic lattice model as they move through materials with cracks. The lattice is made up of interconnected elements, and as waves travel through these elements they experience changes in force, displacement, and velocity. As the wave propagates, forces cause displacements, which lead to motion through the lattice structure. The displacement changes, represented by the wave motion, are tracked over 2000 time stamps for each sample. There are total 9x9 sensors to collect this information about the wave behaviour. The dataset captures wave propagation in a dynamic lattice model to observe how seismic waves move through materials with cracks. As waves travel through the interconnected elements of the lattice, they experience changes in force, displacement, and velocity. These displacement changes, representing wave motion, are tracked over 2000 time stamps for each sample. The data is collected by a 9x9 grid of sensors, which records the behavior of the waves as they interact with cracks. In this research, bounding key-points are generated from segmentation labels, which are treated as 2D arrays where the presence of a crack is indicated by a label of '1' and its absence by a \u20180\u02bb. The process involves iterating through each segmentation label to identify the positions of the object within the segmentation label. For each segmentation label, the method locates the positions where the crack is present. If no crack is detected, a 'None' value is assigned to represent the absence of an object. When a crack is found, the minimum and maximum coordinates that enclose the crack are calculated. To ensure the bounding key-points provides a slightly wider margin around the crack, a one-pixel margin is added to both the minimum and maximum coordinates. These minimum and maximum coordinates are normalized between 0 and 1 relative to the size of the segmentation label."}, {"title": "3.6 Metrics", "content": ""}, {"title": "3.6.1 Intersection Over Union", "content": "The Intersection over Union (IoU) metric is a standard evaluation measure used to assess the accuracy of object detection models. It quantifies the overlap between the predicted bounding box and the ground truth bounding box of an object. IoU is calculated by dividing the area of overlap between the two bounding boxes by the area of their union."}, {"title": "3.6.2 Comparison with the previous model", "content": "In MicroCrackPointNet, the IoU is calculated by comparing the predicted and ground truth bounding key-points. These boxes represent the regions where cracks are located. The algorithm calculates the intersection of the predicted and actual bounding key-points by finding the overlapping area between them. It then computes the area of the union, which is the combined area of both the predicted and true bounding key-points. Finally, the IoU is calculated as the ratio of the intersection area to the union area. This method focuses on how well the model localizes cracks, with IoU values depending on how accurately the predicted bounding key-points align with the actual cracks.\nIn contrast, the 1D-Densenet200E model calculates IoU by applying a threshold to the predicted crack probability map, converting it into a binary mask. The model then uses a confusion matrix to compute IoU, focusing on pixel-level accuracy in identifying crack regions. True positives, false positives, and false negatives are computed, and the IoU is derived by dividing the true positive area by the sum of the true positives, false positives, and false negatives. This approach is well-suited for crack segmentation tasks, where each pixel's classification matters. As seen in the table 1, 1D-Densenet200E achieves higher IoU values compared to the current study, this stems from the difference in the approach in calculating the IOU, where the dense-net uses a thresholding value to binarizie its output. Moreover, the numerator of the IOU is skewed because of large number True Negatives (No Crack Pixels) in case of 1D-Densenet200E."}, {"title": "3.7 A Novel Approach for Crack Detection in Numerical, Non-Visual Data Using Deep Learning", "content": "Crack detection in large structures poses a substantial challenge, especially when dealing with highly imbalanced datasets. Traditional pixel-wise classification methods, which predict each pixel as either \"crack\" or \"no crack,\" often struggle due to the small area occupied by cracks relative to the overall surface, leading to a significant imbalance in the dataset. This imbalance increases model complexity and demands extensive optimization to achieve accurate results. In this paper, we introduce an innovative approach that addresses these limitations by focusing on numerical, non-visual data. Our method leverages deep learning techniques to overcome the inefficiencies of traditional pixel-level classification, offering a more effective and streamlined solution for crack detection in complex and imbalanced datasets."}, {"title": "3.8 Our Keypoint-Based Approach", "content": "To address these challenges, we propose an alternative method that detects cracks by identifying four key points, or keypoint, that define the corners of a bounding rectangle around each crack. Rather than making predictions for every pixel, our model predicts only the coordinates of these four points (eight values representing the x, y-coordinates). This reduces the model's complexity and alleviates the issue of class imbalance, as it eliminates the need for pixel-wise decisions. By focusing on the precise localization of cracks through these key-points, the model is optimized for both performance and efficiency, providing a streamlined solution to crack detection."}, {"title": "3.9 Crack Detection in Numerical, Non-Visual Data", "content": "A key innovation in our work is the application of this approach to numerical data, where cracks are not visually discernible. In traditional applications such as visual crack detection on concrete or metal surfaces, cracks can be visually identified by humans from image data. However, in our case, the input data consists solely of numerical measurements, which contain no obvious visual patterns. This type of data is impossible for human observers to interpret in terms of crack presence or structure, as there are no visible clues. Here, deep learning demonstrates its power: our model is capable of learning hidden patterns and detecting cracks with precision, despite the absence of visual information. This capability sets our method apart from conventional approaches and highlights the potential of neural networks to operate in domains where visual indicators are not present."}, {"title": "3.10 Challenge", "content": "Optimizing the Number of key-points for Complex Crack Structures in Large-Scale Surfaces\nA key limitation of our current approach is its ability to detect only a single crack per sample using a fixed number of four key-points. This method is effective for simple, rectangular cracks but faces challenges with multiple cracks or more complex geometries. The fixed key-points structure may be insufficient for capturing intricate crack patterns, potentially limiting the model's applicability to diverse real-world scenarios. Despite these limitations, we are confident that the foundational approach we have demonstrated is capable of scaling to handle more complex crack geometries. We anticipate that increasing the number of key-points will enable the model to better represent varied crack shapes and detect multiple cracks within a single structure. Future work will focus on addressing these complexities, optimizing the number of key-points, and refining the model to enhance its accuracy and efficiency for real-world applications."}, {"title": "3.11 Results and Implications", "content": "Our experiments show that the keypoint-based approach not only reduces complexity and tackle the class imbalance issue, but also enables accurate crack detection in numerical, non-visual datasets. This represents a significant advance in the field of crack detection, where prior work has been heavily reliant on visual data. The ability of our model to learn numerical patterns and precisely localize cracks opens up new possibilities for applications in domains where visual data is either unavailable or non-informative."}, {"title": "3.12 Comparative Analysis of Models for Computing Power Utilization", "content": "The comparison between the MicroCrackPointNet and the previous model, 1D-DenseNet200E (Table 3), highlights several key improvements in efficiency. The New Model has a more compact architecture, with only 90 layers compared to 444 in the 1D-DenseNet200E. Both models were trained for 200 epochs, but the New Model is much faster, with the first epoch taking 17.03 seconds versus 89.14 seconds for 1D-DenseNet200E. The total training time is also significantly shorter, with the New Model completing training in 2160.53 seconds compared to 15560.56 seconds. The New Model also has fewer total parameters (1,228,760 vs. 1,393,429) and significantly fewer non-trainable parameters (1,544 vs. 17,292), while maintaining a comparable number of trainable parameters. Overall, the New Model is more efficient in terms of both complexity and training time."}, {"title": "Conclusion", "content": "In this work, we introduced a novel approach to crack identification in large structures that overcomes the limitations of traditional pixel-wise classification methods. By utilizing key landmarks to define cracks and applying the method to numerical, non-visual data, we demonstrated that our network can detect hidden patterns in spatio-temporal data that are imperceptible to humans. This approach simplifies the issue of imbalanced datasets by shifting the model's focus from making a decision for every pixel (crack or no crack) to a much easier task\u2014predicting four key points and aligning them as closely as possible with the four ground-truth points, minimizing the distance between them. A"}, {"title": "Future Work", "content": "In future research, we aim to enhance our approach by refining the number and placement of key points used for crack labeling. Initially, we employed four points to mark the corners of a rectangle, as this was effective for the cracks in our data, which often exhibited rectangular shapes. However, real-world cracks frequently have more complex geometries. To address this, we plan to explore the use of a variable number of key points that can better capture these diverse structures. By increasing or adapting the number of points based on the crack's shape, the model can more accurately represent intricate geometries, leading to more precise predictions. Additionally, we intend to investigate object detection algorithms like YOLO (You Only Look Once) and Faster R-CNN to address the limitation of detecting only one crack per sample. These models could be adapted to recognize multiple cracks simultaneously by outputting several sets of bounding keypoint for each detected crack. This would make the model more robust, allowing it to detect multiple cracks in a single sample, especially when cracks are located in close proximity. We also aim to extend our approach by testing it on higher-resolution datasets. Additionally, while our current dataset consists of samples with only a single crack, we plan to introduce samples containing multiple cracks. By increasing the resolution,"}]}