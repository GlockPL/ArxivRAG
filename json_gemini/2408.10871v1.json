{"title": "Radio U-Net: a convolutional neural network to detect diffuse radio sources in galaxy clusters and beyond", "authors": ["C. Stuardi", "C. Gheller", "F. Vazza", "A. Botteon"], "abstract": "The forthcoming generation of radio telescope arrays promises significant advancements in sensitivity and resolution, enabling the identification and characterization of many new faint and diffuse radio sources. Conventional manual cataloging methodologies are anticipated to be insufficient to exploit the capabilities of new radio surveys. Radio interferometric images of diffuse sources present a challenge for image segmentation tasks due to noise, artifacts, and embedded radio sources. In response to these challenges, we introduce Radio U-Net, a fully convolutional neural network based on the U-Net architecture. Radio U-Net is designed to detect faint and extended sources in radio surveys, such as radio halos, relics, and cosmic web filaments. Radio U-Net was trained on synthetic radio observations built upon cosmological simulations and then tested on a sample of galaxy clusters, where the detection of cluster diffuse radio sources relied on customized data reduction and visual inspection of LOFAR Two Metre Sky Survey (LoTSS) data. The 83% of clusters exhibiting diffuse radio emission were accurately identified, and the segmentation successfully recovered the morphology of the sources even in low-quality images. In a test sample comprising 246 galaxy clusters, we achieved a 73% accuracy rate in distinguishing between clusters with and without diffuse radio emission. Our results establish the applicability of Radio U-Net to extensive radio survey datasets, probing its efficiency on cutting-edge high-performance computing systems. This approach represents an advancement in optimizing the exploitation of forthcoming large radio surveys for scientific exploration.", "sections": [{"title": "1 INTRODUCTION", "content": "The backbone of the universe is the cosmic web: an intricate net-work of filaments interconnected with galaxy clusters. The thermal plasma that fills filaments (the Warm Hot Intergalactic Medium, WHIM) and galaxy clusters (the Intra Cluster Medium, ICM) is permeated by weak magnetic fields (0.01-10 \u03bcG) whose origin and evolution have attracted increasing attention in the scientific com-munity in recent years. Structure formation processes inject shocks and turbulence into the thermal plasma, accelerating particles to ultra-relativistic energies. Cosmic ray electrons, spinning in the magnetic fields, emit radio synchrotron radiation in the form of diffuse radio sources which are observed in galaxy clusters, or in filaments and bridges within them. Diffuse radio sources are pri-mary probes for investigating cosmic magnetic fields, particle ac-celeration mechanisms, and the processes driving the formation of large-scale cosmic structures.\nDiffuse radio sources in galaxy clusters have historically been categorized into giant radio halos, mini-halos, and radio relics based on their location in the cluster, morphology, size, polariza-tion, and spectral characteristics However, the boundaries between the different classes are not always clear-cut. For instance, the discovery of Mpc-size sources in clusters host-ing mini-halos suggests the presence of an intermediate stage be-tween mini-halos and giant radio halos, leading to the grouping of these two classes into the common category of radio halos. Fur-thermore, diffuse radio sources often have unique morphologies and projection effects may cause the overlap of different sources along the line-of-sight. Sometimes diffuse radio sources are connected with radio galaxies or revived fossil plasma sources, also known as phoenices which can furnish them with a reservoir of mildly relativistic electrons.\nDiffuse radio emission has recently been detected extending into the outskirts of galaxy clusters in a few systems. In some cases, the radio emission fills the volume of galaxy clusters on large scales. This discovery impacts our understanding of particle acceleration efficiency and diffusion within the turbulent ICM on very broad scales. Radio emission has been detected even between interacting galaxy clusters, in the form of bridges with projected lengths of 1-2 Mpc. The underlying acceleration mechanism remains a topic of debate. While stacking experiments recently claimed the detection of radio emission from 15 Mpc-long filaments , the direct detec-tion of synchrotron emission from the cosmic web has not yet been achieved, leaving many questions about the origins of cosmic mag-netic fields unanswered.\nThe common observational feature of all diffuse radio sources, both within and outside galaxy clusters, is that they are rare (fewer than 200 so far) and extended sources with low surface brightness (< 1 \u00b5Jy/arcsec\u00b2 at 1.4 GHz). Current radio interferometers, like the Low Frequency Array (LOFAR), MeerKAT, the Murchison Wide-field Array (MWA), and the Australian Square Kilometre Array Pathfinder (ASKAP), are push-ing the boundaries of low-surface brightness detection, discovering new faint and diffuse radio emissions that were previously invisi-ble. Diffuse radio sources also have a steep spectrum: \u03b1 > 1, with \\(S_\u03bd \\propto \u03bd^\u03b1\\), where S\u03bd is the flux density at frequency \u03bd and \u03b1 is the spectral index. Hence, they are brighter at low radio frequencies. Not surprisingly, the largest compilation of diffuse cluster radio sources to date has been created with LOFAR, at frequencies be-low 200 MHz. This compilation comprises 83 clusters that host a radio halo and 26 that host one or more radio relics. While other compilations of diffuse radio sources in galaxy clusters are rapidly growing in number and size , the scien-tific community looks for new methodologies to detect and classify such objects in current and forthcoming large sky surveys. A fur-ther increase in the number of detected diffuse radio sources, within clusters and beyond, is expected during the next decade with the advent of the Square Kilometre Array (SKA5, see e.g. Paul et al. 2023).\nThe complete exploitation of this goldmine of data is essential for extending and validating theoretical studies based on the statis-tical properties of large samples of objects, particularly for sources in galaxy clusters. It is also crucial for detecting more sources of diffuse radio emission outside galaxy clusters and shedding light on their origin.\nData obtained by radio interferometers are processed with the aperture synthesis technique to obtain images of the sky. This pro-cedure includes the Fourier transform of the signal collected and it is highly computationally expensive. In addition to the thermal noise of the instrument, interferometric images can be affected by imaging artifacts arising from the antenna's configuration (e.g., missing baselines), ionospheric disturbances, or radio frequency in-terference that may complicate the calibration and imaging pro-cesses. The detection of diffuse radio sources with low surface brightness requires minimizing all these effects and includes the meticulous subtraction of all uncorrelated radio sources. Further-more, the classification of these sources requires multi-frequency data. For example, comparison with optical images is essential to exclude connections to radio-active galaxies, while X-ray data is used to assess the position of the radio source with respect to the thermal plasma.\nThe scenario will be further complicated by the overwhelming volume of data that upcoming instruments will soon generate. The SKA Observatory is expected to archive more than 700 petabytes of data per year. Even the current generation of radio telescopes, such as LOFAR, MeerKAT, MWA, and ASKAP, are already creating extensive surveys that push the boundaries of available hardware and software capabilities in terms of data processing and storage. Consequently, future software solutions must be equipped to handle these vast datasets. This necessitates two key developments: 1) the software must efficiently exploit the power of High-Performance Computing (HPC) systems, including parallel processing, diverse hardware configurations, and complex memory and storage hier-archies; and 2) the software must be automated, to reduce human intervention, as manual data processing would be impractical.\nA possible way to develop such a new data processing method-ology is with the use of deep learning (DL), a branch of artifi-cial intelligence developed for image processing and analysis tasks, like semantic segmentation and classification. DL has already been extensively used in astronomy, astrophysics, and cosmology. Specifically relevant to our work is the use of DL for the detection and classification of sources in radio images. In recent years, considerable effort has been dedicated to radio galaxies, for which we already have vast and complete databases that can be used to train supervised networks as well as self-supervised models. When the dataset size is not sufficient for training a DL model, transfer learning can be exploited to transfer knowledge learned from a large dataset to a smaller one. This method is widely used to address astrophysical classification problems. However, the success of this process heavily relies on the availability of data for fine-tuning the model to the new task and on the similarity between the original and new datasets.\nDL has also been exploited for the detection of sources in our previous work , where we have explored the po-tential of Convolutional Neural Networks (CNN) in identifying the faint signal from diffuse radio sources in noisy radio observations, which are at the limit of sensitivity of instruments like ASKAP or LOFAR (see also Gheller & Vazza 2022a). In this work, we trained and tested our models on synthetic radio observations based on cosmological simulations, including both random and systematic perturbations related to the telescope and/or the environment. The resulting methodology, named COSMODEEP, allowed us to detect diffuse radio sources and to localize their position within large im-ages, thanks to a tiling-based procedure with an accuracy of around 90% for synthetic observations (i.e. around 10% of the detections are missed). However, the COSMODEEP algorithm is unable to perform accurate image segmentation, which prevents it from pro-viding a precise outline of the shape and extent of the detected ob-ject. This limitation hinders further characterization of the detected source, such as performing a morphological classification of the object.\nWe aim to overcome this limitation by enhancing our method-ology with a fully CNN approach, using the U-Net architecture. This approach has been demonstrated to be extremely effective for image segmentation tasks It is inter-esting to note that our DL model has been developed to perform the segmentation of data from a completely different scientific applica-tion, i.e. photoelastic images from experiments of granular mate-rials However, it proves to be effective for our astronomical data, highlighting the flexibility and the strength of DL methods.\nIn this work, we also aim to extend the application of our methodology to real observations of diffuse radio emissions in galaxy clusters, specifically targeting LOFAR data. However, de-spite the increasing number of cluster diffuse radio sources discov-ered in recent years, their quantity is still insufficient for properly training a DL network with real data. To address this problem, we used synthetic observations based on cosmological simulations to train the network to recognize the morphology of the sources even below thermal noise and imaging artifacts. We then investigated the application of the network to LOFAR observations and tested the effectiveness of transfer learning by fine-tuning the pre-trained network on actual observations.\nThe goal of this work is to provide a first use case of our net-work by testing its ability to detect diffuse radio sources in a pre-viously known sample of galaxy clusters. Having such a result in hand will enable us to use Radio U-Net for blind searches of diffuse radio emission on the entire sky.\nThe paper is organized as follows. The architecture of Radio U-Net is illustrated in Sec. 2. LOFAR and synthetic observations are described in Sec. 3 and Sec. 4, respectively. The training and validation of the network on synthetic observations are explained in Sec. 5 while the results obtained from the application of Radio U-Net to LOFAR data are described in Sec. 6. The results are dis-cussed in Sec. 7 and final conclusions are drawn in Sec. 8."}, {"title": "2 THE CONVOLUTIONAL NEURAL NETWORK: RADIO U-NET", "content": "We have adapted the original U-Net architecture to our problem. Fig. 1 shows an illustrative represen-tation of the Radio U-Net network. Radio U-Net is an autoencoder consisting of a contractive and an expansive path. The contractive path is composed of a downsampling convolutional network which starts from an input layer, loading the input images, and ends with the deepest convolutional layers. The expansive path starts from this deepest level, followed by an upsampling convolutional net-work, specular to the contractive one. At each level, the feature maps are also summed to preserve spatial information. The final output layer returns the results. In our case, the results are repre-sented by the segmented images, of the same size as the input ones, identifying the presence of diffuse radio emission.\nA 3 \u00d7 3 pixels window (receptive window) is used for the convolution, applying it starting from the input images:\n\\(s_{m,n}^f = \\sum_{i,j=-1}^1 w_{i,j}^f x_{m+i,n+j} + b^f,\n                                    (1)\\)\nwhere xm,n is the (m, n) pixel of the input image, \\(w_{i,j}^f\\), and \\(b^f\\) are the weights and the biases of the convolutional kernel. The result of the convolution, the \\(s_{m,n}\\) element, constitutes the f-th feature map. Starting from the random initialization of the weights and the biases several different feature maps are created. Non-linearity is introduced by further processing the \\(s_{m,n}\\) elements with an ac-tivation function. We have adopted the ReLU activation function :\n\\(t_{mn} = \\max(0, s_{m,n}).\n                                   (2)\\)\nIn each level, the convolution plus activation steps are repeated two times. Batch normalization has been used after each convolu-tion step to improve the convergence of the method. At this point, each feature map is downscaled through a max pooling function, which selects the maximum tim,n every 2\u00d72 pool of feature map elements. The resulting maps are 1/4 the original size. A dropout layer (with a rate of 0.5) is inserted after each max pooling func-tion to prevent overfitting. The same convolution plus pooling pro-cedure is repeated four times until the deepest layer is reached.\nTranspose convolutions with ReLU activation and upsampling layers are alternated in the expansive path, while dropout layers are not used. After five upsampling layers, specular to the contractive ones, the network produces 32 feature maps of the same size as the input image. A final convolution with softmax activation function provides two feature maps that represent, respectively, the proba-bility of each pixel to be 0 or 1. The output is the probability map showing the probability of the (m, n) pixel to be part of the diffuse radio emission:\n\\(P_{m,n}=\\frac{e_{m,n}^1}{e_{m,n}^0 + e_{m,n}^1}\n                                   (3)\\)\nDuring the training, weights and biases are optimized with an iterative procedure. Two sets of images are needed for the train-ing: the input and the reference images. For the initial training of our network, we used as input synthetic observations of diffuse ra-dio sources described in Sec. 4. The reference images are masks, displaying unity in pixels where emission from the diffuse radio source is present and zero otherwise. The input images are pro-cessed by the network and the segmented images are compared to the corresponding reference images using a loss function. We used the categorical cross-entropy loss function, defined as:\n\\(H(y_{m,n}, P_{m,n}) = - \\sum_{f=1}^{N_c} y_{m,n} \\log(p_{m,n}),\n    (4)\\)\nwhere ym,n is the pixel value in the reference image (0 or 1) and Ne is the total number of classes to classify. For our application Nc = 2, that is, a pixel belongs or not to a diffuse radio source. The training aims at minimizing H by updating the weights and biases with the backpropagation of the cross-entropy error estimate. This is done using the RMSprop algorithm as an optimizer.\nIn addition to the trainable parameters (weights and biases),\nthe network includes additional hyperparameters used to control the learning process. For our network, we selected the hyperparam-eters that demonstrated the best performance in , ensuring their suitability for our purposes. They are:\n\u2022 the learning rate: \u03bc = 10-4, that regulates the step size of the iterative error minimization procedure;\n\u2022 the batch size: B = 50, that defines the number of images that are propagated through the network in one iteration step;\n\u2022 the number of epochs: E = 200 representing the number of times the training set is seen by the network during the training;\n\u2022 the tile size: T = 192, that defines the size of the input images (see Sec. 5).\nThe network has been implemented using the Python pro-gramming language and exploiting the Keras software package distributed as part of the Tensorflow frame-work , version 2.3.0. The resulting software can run on any computing platform, from standard multicore CPUs, available on a personal workstation, to supercomputers, with com-putational performance changing according to the adopted archi-tecture. To speed up the computation, we have exploited the GPU implementation of Tensorflow.\nTraining and tests were first run on the Marconi100 (M100) HPC system and then moved on the new Leonardo supercomputer available at the CINECA Italian Supercomputing center."}, {"title": "3 LOFAR OBSERVATIONS", "content": "We developed Radio U-Net to detect diffuse radio sources in the LOFAR Two-meter Sky Survey (LoTSS, Shimwell et al. 2017, 2019). This is an ongoing survey that aims to cover the entire north-ern sky with the LOFAR High-Band Antenna (HBA) at frequencies from 120 to 168 MHz (150 MHz central frequency). The second data release (DR2) of the LoTSS is fully described in Shimwell et al. (2022). The LoTSS DR2 covers 27% of the northern sky (5634 deg\u00b2) and consists of images at 6\" resolution with a me-dian root-mean-square (rms) sensitivity of 83 \u00b5Jy/beam. Released low-resolution images have 20\" restoring beam and median rms sensitivity of 95 \u00b5Jy/beam.\nTo test Radio U-Net on real data, we applied the network to a sample of galaxy clusters for which the search and classification of diffuse radio sources was made by tailored data reduction and visual inspection. These are the 309 clusters in the second catalog of Planck Sunyaev Zel'dovich (PSZ2 Planck Collaboration et al. 2016) that lie within the LoTSS-DR2 area (hereafter, the LoTSS-DR2/PSZ2 sample), presented in Botteon et al. (2022a). We used their findings as a benchmark to test our approach (see Sec. 6).\nWe note, however, that we did not use the images produced by Botteon et al. (2022a). Instead, we used the public LoTSS DR2 data at 20\" resolution, directly downloaded from the archives. Our aim is to test the segmentation and detection capability of Radio U-Net on basic archival data. If good performance is achieved, this approach will significantly reduce the computational time required for detection, which is typically performed on post-processed data."}, {"title": "4 SYNTHETIC OBSERVATIONS", "content": "We trained Radio U-Net on synthetic observations of diffuse ra-dio emission. Input images have been generated to be the clos-est possible to actual LOFAR HBA observations, using the same procedure described in Gheller & Vazza (2022b). The images are already publicly available (https://owncloud.ia2.inaf.it/index.php/s/IbFP1CCcPUresrr). Here we summarize the main steps of the procedure.\nWe used magneto-hydrodynamical (MHD) cosmological sim-ulations, produced with the grid code Enzo . The simulation box has a uniform and constant spatial cell resolu-tion of 41.65 kpc (comoving) and covers a volume of 1003 Mpc\u00b3 simulated with 24003 dark matter particles and cells. A uniform primordial magnetic seed field of Bo = 0.1 nG (comoving) was initialized in all directions at zin = 45, and was evolved assum-ing ideal MHD, via adiabiatic compression/rarefaction and small-scale dynamo amplification in halos, until z = 0. The simulation assumed a standard ACDM cosmological model, with density parameters \u03a9b = 0.0478, \u03a9DM = 0.2602, \u03a9\u039b = 0.692, and a Hubble parameter Ho = 67.8 km/s/Mpc.\nWe computed the emission at 150 MHz from relativistic elec-trons accelerated by cosmic shocks at various redshifts, assuming that only shocks can accelerate relativistic particles via diffusive shock acceleration, and produce synchrotron radio emission. For simplicity, the synchrotron emission model by Hoeft & Br\u00fcggen (2007) has been assumed here, which requires the jump condition of each cell undergoing shocks (computed from the simulation), the local value of the magnetic field, and the electron acceleration efficiency as a function of Mach number (which is cal-ibrated on shocks internal to galaxy clusters, as in Vazza et al. 2015 and Vazza et al. 2019). We did not include in our simulations ra-dio emission produced by turbulence, as is expected from radio ha-los, bridges, or mega halos , as well as by electrons re-accelerated by shocks. However, the morphology and emissivity of diffuse radio sources can loosely resemble even those of radio halos, despite the different particle acceleration mechanisms likely at work in radio halos. This same simulation and model for radio emission was successfully used to compare with the result of stacking attempts of the cosmic web with real radio data , and therefore it can be considered as a fairly realistic representation of how the radio emitting cosmic web might look like.\nThe production of the training set of synthetic images for Ra-dio U-Net, starting from the 3-dimensional emission model of the cosmological simulations, followed two main basic steps.\nFirst, we integrated the emission along the line of sight within four comoving volumes chosen at four different redshift snapshots (roughly equally spaced from z = 0.02 to z = 0.15). An example of the maps of some of the redshift snapshots used is given in Fig. 2 in Gheller et al. (2018). We applied cosmological corrections for the surface brightness and the luminosity distance of each redshift, relative to the z = 0 observer. We also decreased the pixel size of each image as a function of distance, using a cubic interpolation on the input map. Artifacts arising from the periodicity of structures along the same line of sight were minimized by shifting each box with a random offset in both directions.\nNext, every single synthetic sky model was generated by pro-gressively stacking maps referred to an increasing redshift. In or-der to fully cover the \u2248 640 Mpc distance out to z = 0.15, we extracted maps multiple times from the same simulated redshifts, applying an appropriate cosmological corrections factor to simu-late an increasing redshift of the sources, similar to Vazza et al. (2021b). As done in Gheller & Vazza (2022b), we limited our anal-ysis of simulated lightcones up to z \u2248 0.15 since we do not expect a drastic change in the radio emission including larger redshifts (see also Hodgson et al. 2021).\nThis procedure was repeated many times, by applying random rotations to each of the different redshift slices, so that we could obtain more than 500 independent lightcones. The images have a resolution of 2000 x 2000 pixels, sampling a field of view of 1.1\u00b0 x 1.1\u00b0 each, with a nominal angular resolution (pixel size) of 2 arcsec. These images are indicated as sky images (see Fig. 2, first column, for two examples).\nThe reference images used to train the network are created by masking the sky images at 10-8 Jy/pixel. This value is a factor ~ 10-3 lower than the nominal noise level (83 \u00b5Jy/beam = 2 \u00d7 10-6 Jy/arcsec\u00b2 with a beam size of 6\"). This is done to teach the network to recognize emission structures even below the noise level.\nTo generate mock observations, the synthetic visibilities cor-responding to a LOFAR HBA observation of 8 hours have been calculated using the \"predict\" mode of the WSClean with the sky images as model images. At this point, random noise is added to the visibilities using the noise.py script in the LoSiTo software package. Finally, imag-ing is performed using the WSClean software, adopting Briggs' weighting, with \"robust\" parameter equal to 0, and correcting for the primary beam. The use of these parameters resulted in a restor-ing beam of 5.9\" x 5.1\". Deconvolution is carried out using the clean method and the auto-masking option with a 50 threshold.\nWe note that the cleaning process has not been optimized for each image, as it was automatically applied to hundreds of images. Residual artifacts influence the quality of the final image and can potentially affect any attempt at automating source identification, as these artifacts may be confused with real sources. This is an in-tended behavior designed to train the network to recognize sources in imperfectly cleaned images. The random noise previously intro-duced in the visibilities produces a rms of ~ 2.3 \u00d7 10-7 Jy/beam in source-free fields, while the median rms is about one order of magnitude higher due to residual imaging artifacts. Restored im-ages are used as input for the training of Radio U-Net, and we will refer to these images as clean images (see Fig. 2, central column, for two examples).\""}, {"title": "5 TRAINING STRATEGY AND VALIDATION OF THE NETWORK", "content": "Training and validation of Radio U-Net were performed on syn-thetic observations. The primary objective of this training is to en-able the network to identify a wide range of cosmological source morphologies and to distinguish real sources from imaging arti-facts. Additionally, the reference masks used in the training were created with a threshold lower than the actual noise level of the in-put clean images, allowing the network to recognize faint patterns even below the noise.\nThe 2000 x 2000 pixels images are further divided into square tiles that become the actual training set of the network. The tile size is chosen to be the smallest possible, still representative of the fea-tures to be identified (both sources and artifacts, in particular, those due to the dirty beam, which can span large areas of the image). In this way we maximize the size of the training sets without losing the significance of each single input image, reducing, at the same time, the memory footprint of the training. An effective tile size for our images results to be 192\u00d7192 pixels so that from each image we can create 100 tiles.\nDue to GPU memory constraints, the training set comprises 100 sky images, i.e 10000 tiles. A fraction of them (5%, that is, 500 tiles) is kept as a validation set to verify the performance of the network during training. Another 10 randomly selected images (i.e. 100 tiles), never seen by the network, are used as a test set.\nThe workflow is implemented as follows:\n(i) the training program reads the input parameters, and the hy-perparameters and sets up the network;\n(ii) training images (input clean images and reference masked images) are read from FITS files, and stored on disk;\n(iii) the data are transformed in logarithmic scale and normal-ized in a [0,1] range, using 10-10 Jy/pixel and 10-5 Jy/pixel as minimum and maximum data normalization values. Pixels outside this range were clipped to the boundaries of the normalization range;\n(iv) images are divided into tiles of 192\u00d7192 pixels;\n(v) tiles are serialized to feed the network;\n(vi) mini-batches of tiles are offloaded to the GPU and pro-cessed for the training;\n(vii) at each epoch, the loss function value is computed for the training and the validation sample;\n(viii) the trained network is saved in a file (in \"SavedModel\" Tensorflow format).\nWeights and biases of the trained network can be loaded by the evaluation program which performs the segmentation of new im-ages and saves the result into a FITS file. The only significant lim-itation of the tiling procedure is the potential for minor misalign-ments at tile borders, which may compromise the accuracy of seg-mentation in the reconstructed images. To mitigate this issue, when Radio U-Net is used, tiles are created with overlapping boundaries, which are then discarded in the reconstruction. The tiles are over-lapped by half their size (96 pixels) and only the central 48x48 pixels of each tile are then used to recompose the final image. An explicative scheme of this procedure is shown in Fig. 3. Residual boundary effects are still visible in the probability image but they do not affect the detection of the diffuse emission.\nExamples of the resulting segmented images from the test set are shown in Fig. 2, third column. This probability image has to be compared with the sky image, in the first column, where the con-tours show the reference mask on which the network was trained, and with the input clean image, shown in the second column. In all 10 images, the diffuse emission is spotted against noise and clean-ing artifacts, showing high detection probability values. The broad structure of the sources is well recovered, and, although the faintest features are missed, it is important to remember that these features are orders of magnitude below the actual noise in the input images. For comparison, we plotted the 3\u03c3 contours over the clean images (with computed as the rms in an empty region of the image). These contours delineate the regions that would be detected by a standard analysis. The striking result is that the segmented images produced by Radio U-Net enable much easier identification of dif-fuse radio structures, reproducing their complex morphologies.\nA binary mask can be generated from the segmented image by setting a pixel probability threshold. We notice that the bound-aries between the detected and undetected regions are very sharp, and a threshold of 0.5 well bounds all the features detected by the network (see Fig. 2). By comparing the reference mask and the seg-mented image, we can estimate how many pixels are true (true 0, T0, and true 1, T1) or false identification (F0 and F1) using 0.5 as a threshold.\nWe estimate for each image the mean intersection over union (IoU):\n\\(\\rm{IoU} = 0.5 \\left(\\frac{T0}{T0+F0 + F1} + \\frac{T1}{T1+F1+ F0}\\right).\n(5)\nThis is the benchmark evaluation metric for computer vision tasks for which the correct identification of pixels with value 1 is as important as that of pixels with value 0: it is equal to 1 in case of perfect segmentation and decreases for increasing misidentified pixels. This formula simplifies to a single-class metric when only one class is present in the image. Averaging the 10 test images, we obtain an IoU of 0.64\u00b10.02. This number indicates a good segmen-tation, considering that the reference mask is orders of magnitude below the noise of the input images.\nIf we compute the same metric using masks created from clean images at the standard 3\u03c3 level (e.g., the orange contours in the second column of Fig. 2) and compare with the reference mask, we obtain an IoU of 0.58\u00b10.02, averaged over the 10 images. This demonstrates that the network is able to produce a more reliable segmentation with respect to the standard method.\nFurthermore, while the 3\u03c3 threshold is used for detection only on fully cleaned images, for which tailored data reduction and imaging procedures are often performed, Radio U-Net segmenta-tion performs well even with incompletely cleaned images. Once trained, the method does not require parameter tuning, other than fixing the probability threshold for detection. It performs the seg-mentation of each single 2000\u00d72000 image in 0.7 s, faster than any procedure requiring human interaction. This feature decreases the amount of time required to reduce data for detection, making it suitable for use in large radio surveys to conduct blind searches for diffuse radio emissions.\nHowever, we can exploit multiwavelength analyses to assist in identifying diffused radio sources associated with galaxy clusters, bridges, and cosmic web filaments. In this case, we can apply Radio U-Net to a list of targets and classify them as detected or not on the basis of the segmentation mask created by the network. This is the procedure that we will follow in the next Section, where we will also compute precision and recall for binary classification on a test sample of galaxy clusters.\nIn binary classification problems, precision is defined as the ratio of the true positive (TP, detected diffuse radio sources) to the total number of objects identified as detected (both true and false positive, FP), and it reaches unity if there are no false positives:\n\\[\\rm{precision} = \\frac{TP}{TP+FP}     (6)\\]\nRecall is the ratio of the TP to the sum of the true positive and false negative (FN):\n\\[\\rm{recall} = \\frac{TP}{TP + FN}     (7)\\]\nWe can consider as TP all the sources of the sky images de-tected with more than 10 pixels (i.e. the size of the resolution el-ement of the synthetic observation) above 0.5 in the probability images. In contrast, FP are the regions above the 0.5 level in the probability images but without any counterpart in the sky images, whereas FN are all the sources that remain undetected. We did not consider the sources outside the boundary which is cut by the tiling procedure.\nIn the set of 10 sky images used for the test, we achieved a precision of 0.86 and a recall of 0.65. It is noteworthy that 35% of the TP can only be detected in the images segmented by Radio U-Net, as they are not visible in the clean images above the 3\u03c3 threshold."}, {"title": "6 RESULTS", "content": "Having trained Radio U-Net on a large sample of synthetic obser-vations, we can now use it to process real LOFAR observations. We will use as a reference the LoTSS-DR2/PSZ2 cluster sample, introduced in Sec. 3, to test the classification performances of the network."}, {"title": "6.1 Application to the LoTSS-DR2/PSZ2 cluster sample", "content": "Low-resolution (20\") images of the 309 clusters in the sample were downloaded from the LoTSS archive. For each cluster, we created a cut-out of 960\u00d7960 pixels centered on the cluster position, en-suring the target was as close as possible to the pointing center of the mosaic. The cut-out size was selected to be as large as possible, ensuring that it does not exceed too much the boundary of the LO-FAR primary beam, and it is also a multiple of 192, which remains the tile size for the network.\nThe pixel size is 4.5\", hence the cutout size is 1.2\u00b0 x 1.2\u00b0. Redshift, available for all but 28 clusters, spans between 0.016 and 0.9, with a median value of 0.28. By adopting the same cosmology model (i.e., A cold dark matter, with \u03a9 = 0.7, \u03a9m = 0.3, and Ho = 70 km s\u00af\u00b9 Mpc\u00af\u00b9), 1 Mpc corresponds to 682 pixels at z = 0.016 and to 28 pixels at z = 0.9. This means that, if present, cluster-scale radio emission should be contained in the cut-out and it can span a broad range of angular extensions.\nWe processed the 309 images with Radio U-Net using a slightly modified version of the evaluation program which allows us to preserve the astrometric information contained in the header. As in step (iii) of the training procedure described in Sec. 5, we converted the data in logarithmic scale and we normalized between 10-7 and 10-2 Jy/beam. We thus obtained probability images for all the galaxy clusters.\nWe show some examples of LoTSS-DR2/PSZ2 clusters with the corresponding output generated by Radio U-Net in Fig. 4 and Fig. 5. In particular, Fig. 4 shows examples of clusters where the direct application of Radio U-Net gave very good segmentation. PSZ2 G055.80+32.90 is a galaxy cluster with no signs of dif-fuse radio emission; indeed, very few pixels show a probability greater than 0.5 of being part of a diffuse source. In contrast, PSZ2 G055.5"}]}