{"title": "AUTOGRAMS: AUTONOMOUS GRAPHICAL AGENT MODELING SOFTWARE", "authors": ["Ben Krause", "Lucia Chen", "Emmanuel Kahembwe"], "abstract": "We introduce the AutoGRAMS framework for programming multi-step interactions with language models. AutoGRAMS represents AI agents as a graph, where each node can execute either a language modeling instruction or traditional code. Likewise, transitions in the graph can be governed by either language modeling decisions or traditional branch logic. AutoGRAMS supports using variables as memory and allows nodes to call other AutoGRAMS graphs as functions. We show how AutoGRAMS can be used to design highly sophisticated agents, including self-referential agents that can modify their own graph. AutoGRAMS's graph-centric approach aids interpretability, controllability, and safety during the design, development, and deployment of AI agents. We provide our framework as open source at https://github.com/autograms/autograms.", "sections": [{"title": "INTRODUCTION", "content": "Artificial intelligence (AI) agents driven by large language models (LLMs) can tackle complex, multi-faceted tasks. LLMs pretrained on large datasets generate human-like text and display knowledge of various domains Radford et al. (2019); Brown et al. (2020). This enables them to perform a range of tasks and learn from training examples given in their prompt.\nTraining these language models to follow instructions enhances their utility, allowing them to generate outputs that align with given instructions Ouyang et al. (2022). This instruction-following behavior is crucial for the development of AI agents that provide useful and contextually relevant responses across a variety of applications (Yao et al., 2022; Paranjape et al., 2023; Khattab et al., 2022). It also enables these agents to drive autonomous operations, such as making decisions, accessing external information, and engaging in conversations. Despite their potential, current approaches often struggle with maintaining coherent behavior over extended interactions, adapting to unexpected user inputs, and providing designers with intuitive and flexible control over the agent's decision-making process.\nTo overcome these limitations, we introduce the AutoGRAMS (Autonomous Graphical Agent Modeling Software) framework to empower designers to orchestrate intricate interactions with LLMs. AutoGRAMS enables the creation of sophisticated AI agents and chatbots by representing their behavior as a series of interconnected nodes, each with distinct actions and transition rules. This graphical representation provides a programming language for agent development, where the execution path dynamically adapts based on language model predictions or predefined conditions.\nWith AutoGRAMS, designers gain the ability to:\n\u2022 Design branched multi-step interactions with a language model: Define a series of interconnected nodes that represent the steps involved in language model generation. This graph outlines a pre-defined procedure, and its nodes may include multiple branches and decision points. Interaction is defined by graph traversal, by iteratively stepping through the nodes of the graph.\n\u2022 Design complex conversational flows: Define a graph of conversational reply steps with prompts that govern how the agent gives conversational replies and makes decisions about which conversational branches to take.\n\u2022 Control interaction steps with with node-specific prompts: Craft prompts tailored to each node, guiding the language model's responses.\n\u2022 Leverage language model predictions in transitions: Define how language model predictions are used to navigate branch points and guide the agent's behavior.\n\u2022 Incorporate conditional logic: Define specific conditions under which different actions or transitions occur.\n\u2022 Use variables to control memory: Define how variables in memory are set and used by a language model\n\u2022 Integrate code: Define Python statements to manipulate variables or interact with external APIs at any node of the interaction\n\u2022 Call agent modules as functions: Define callable agent systems that can be called at points in the interaction, allowing an interaction to return to a previous point, and giving additional control over prompt scopes.\n\u2022 Visualize agent behavior: Gain a clear understanding of the agent's decision-making process and current state through an intuitive graphical interface.\n\u2022 Design agent interactions in spreadsheets: Enable the design of complex agents using spreadsheet software such as Microsoft Excel, Google Sheets, etc.\nThe designer does not necessarily need to be a person-the high level of flexibility of AutoGRAMS makes it possible for an AutoGRAMS agent to design other AutoGRAMS agents. AutoGRAMS also contains functionality to allow agents to modify their own graph directly, opening up possibilities for agents that learn by modifying their own behavior."}, {"title": "AUTOGRAMS FRAMEWORK", "content": "We introduce AutoGRAMS and go over the process of defining a set of nodes and associated fields to create agents in Subsection 2.1. We then delve into the key concepts and mechanics of the Auto-GRAMS frameworks, focusing on; nodes and node types in Subsection 2.2, transitions in Subsection 2.3, variables and memory in Subsection 2.4, functions in Subsection 2.5, methods of designing autograms in Subsection 2.6, and finally, autogram configurations and settings in Subsection 2.7. Some other details of the framework are included in the appendix, including how prompts are formed (Appendix A), and details of how language models are used (Appendix B), a description of interjection nodes that help model unexpected user replies (Appendix C), and simulating user replies in conversational autograms (Appendix D),\n2.1 GENERAL OVERVIEW\nAutoGRAMS allows for a unified representation between graphical chatbots that use states and transitions, general code, and approaches that leverage LLMs internal reasoning abilities. An AutoGRAMS program, which we refer to as an autogram (autonomous program) 1, is defined by a collection of nodes and the transition functions between them. Within the nodes, there are associated fields that define instructions to be executed and transition behaviors/functions to other nodes.\nAn autogram is represented by a set of nodes and their associated fields. The nodes are used to form a data structure representing a graph, and execution of the autogram consists of taking a trajectory of one or more steps along this graph. In a conversational setting, one of the main goals is to model different conversational trajectories, where each node represents a chatbot's reply, and each edge represents a user's reply. For instance, consider the conversational graph in Figure 1-An AI agent designed to quiz the user on a subject may start by asking a question, and depending on whether the answer is correct, will continue by either going over the answer with the user, or asking them to try again. If a user repeatedly answers incorrectly, the agent may provide an explanation and then proceed to a new question after addressing any further inquiries. This type of agent can be modeled as a set of nodes, each with a unique set of instructions and transition behaviors.\nThere are many possible fields than can be defined for each node, but some of the most important fields are:\n\u2022 instruction: This field determines the node's behavior and is interpreted differently depending on the node type. The instruction could be a language model prompt, executable code, or a call to another AutoGRAMS function.\n\u2022 action: This field determines the node type and how the instruction is processed. In simpler scenarios, such as Figure 1, all nodes can be designated as chat type, indicating that each node generates a response.\n\u2022 name: This provides a unique identifier for the node, allowing other nodes to reference it during transitions."}, {"title": "TRANSITIONS", "content": "After executing the instructions within a node, the autogram must select the next node to execute. Each node contains fields that govern this selection process.\nEach node has a name field and a transitions field, which stores a list of strings. In the simplest case, each string in transitions directly references the name of another node in the graph. A node with only one possible transition would list a single name, while nodes with branching possibilities would list multiple names.\nIn other cases, a string in transitions may not directly refer to a node name. For example:\n\u2022 Wildcard Transitions: A transition string with a \".*\" suffix (e.g., \"mynode.*\") indicates a conditional transition. This assumes the existence of nodes named \u201cmynode.a,\u201d \u201cmynode.b,\"\\ etc., each with a defined boolean_condition field containing a Python statement that may reference variables in memory (see Section 2.4 for more on Variables). If-elseif-else logic is then used to select the appropriate node based on the evaluation of these boolean conditions. (see Algorithm 1 for a pseudo-code example, and Appendix E for a visualization)\n\u2022 Return Transitions: A transition string of \"return\" (or \"return variable name\" to return a variable) signifies a return from a function call within an AutoGRAMS function, transitioning back to the calling node.\n\u2022 Variable Transitions (advanced use case): A transition string can also reference a variable, using its value in memory to determine the next node. This requires careful validation to ensure the variable's value corresponds to a valid node name. A variable transition could become a return or wildcard transition, since a variable could specify any string-which could correspond to any transition type.\nFunction-type nodes override this standard transition behavior. They transition directly to the node specified in their instruction, returning to the original node upon function completion. (See Section 2.5 for details on AutoGRAMS functions.)"}, {"title": "VARIABLES", "content": "AutoGRAMS allows the use of variables to store and manipulate memory, enabling dynamic behavior within an autogram. Variables in AutoGRAMS are managed as Python variables and can be created, referenced, and modified throughout the execution of an autogram.\n2.4.1 VARIABLE ASSIGNMENT AND REFERENCES\nVariables are assigned using the '=' sign within the instructions of nodes. The node's instruction (with the assignment parsed out) will be executed in accordance with the node's action, as previously described in Section 2.2. This means that the type of node will also influence what value is assigned to the variable.\n\u2022 Python Nodes: Execute Python code directly. For example, a node with the instruction, x = [0, 1, 2] initializes a variable x to a list.\n\u2022 Chat and Thought Nodes: Use the language model to generate text. For example, an instruction like, x = summarize the recent conversation history will store the generated text in the variable x. In this specific example, the text stored in the variable x will be a language model summary of the recent conversation history. i.e. at run time, this instruction will be executed and its results stored as a Python string in the variable x.\n2.4.2 VARIABLE SCOPES\nThe memory in AutoGRAMS is managed through a memory object, which stores variables and the conversation history. This object is structured as a stack, where each function call adds a new layer, and each return removes the top layer. If no functions are used, a variable can be accessed anywhere within an autogram. However, local functions are unable to view their calling scope, including any variables in that calling scope. See Section 2.5 for more details.\n2.4.3 EXAMPLE OF VARIABLE USAGE\nConsider a set of nodes that demonstrate variable assignment and referencing:\nname: \"write_topics\"\ninstruction: \"topics = List the topics covered in today's lesson.\"\naction: \"thought\"\ntransitions: [\"append_topics\"]\nname: \"append_topics\"\ninstruction: \"all_topics.append(topics)\"\naction: \"python_function\"\ntransitions: [\"tell_topics\"]\nname: \"tell_topics\"\ninstruction: \"Inform the user about the topics covered today, which were: $topics\"\naction: \"chat\"\nIn this example:\n\u2022 The write_topics node initializes calls a language model to write down a list of topics and store it in a variable called topics, which will be a string.\n\u2022 The append_topics node applies its instruction as Python code, appending the variable topics to a list called all topics that is presumed to have been defined previously.\n\u2022 The tell topics node uses $ variable embedding to dynamically insert the topics variable within the instruction string to get a response.\nBy utilizing variables, AutoGRAMS facilitates memory management and dynamic interactions, enabling the creation of sophisticated and adaptable AI agents."}, {"title": "FUNCTION CALLS AND SCOPES", "content": "AutoGRAMS introduces the ability to call graphical modules as functions, allowing subgraphs to be called similarly to functions in programming. This enables modularity, reusability, and control over variable scopes.\n2.5.1 FUNCTION NODES AND CALLS\nFunction nodes allow for the execution of separate subgraphs within the main AutoGRAMS graph. These nodes can call other nodes within the graph or external programs. The process involves:\n\u2022 Defining the Function Node: A node designated as a function node will have its instruction specify the function to be called, such as, summary = summarize (document).\n\u2022 Passing Arguments: Variables can be passed as arguments to the called function. Within the function, these variables are assigned and can be used or modified.\n\u2022 Defining a callable node: A node can be made callable by its name. Node name with parentheses are callable. So a node named summarize cannot be called a s function, a node named summarize () can be called as as function with no arguments. A node named summarize (text1,text2) can be called with 2 arguments. The arguments specified by the node name determine what the variables will be named in the scope of the called node.\n\u2022 Defining the Subgraph of the callable node: The callable node, which acts as the root node of the subgraph, can have transitions to other nodes that perform other operations. Transitions use the string \"return\u201d or \u201creturn varname\" can be added to specify that the subgraph should end.\n\u2022 Executing the Subgraph of the callable node: The function node transitions to the callable node specified in the instruction. The autogram executes the subgraph of the callable node until it reaches a return transition, which may optionally return specific information back to the calling node.\n2.5.2 RETURN TRANSITIONS\nReturn transitions mark the end of a function's execution and return control to the calling node. They can also return specific values to be used by the calling node. For example, return topics_summary will pass the value of topics_summary back to the calling node.\n2.5.3 SCOPES IN FUNCTION CALLS\nThe scope of variables in function calls is crucial for maintaining the integrity of the memory and ensuring correct execution. AutoGRAMS supports different scope types for function calls:\n\u2022 Local Scope: The function can only access variables passed as arguments. Variables within the function do not affect the calling scope. This is specified using the local_function action of the calling node.\n\u2022 Global Scope: The function can access and modify all variables and conversation turns in the calling scope. This is specified using the global_function action of the calling node.\n\u2022 Mixed Scope: The function can read all variables and conversation turns from the calling scope, but the variable and conversation turns set during execution are erased after returning. This is specified using the function action of the calling node.\n2.5.4 EXAMPLE OF FUNCTION USAGE\nConsider a set of nodes that demonstrate the use of function calls and scopes:\nname: \"call_summarize_docs\"\ninstruction: \"summary = summarize_and_combine (document1,document2)\"\naction: \"local_function\"\ntransitions=[\"process_summary\"]\nname: \"summarize_and_combine(text1,text2)\"\ninstruction: \"summary1=write a summary of the following text: $text1\"\naction: \"thought\"\ntransitions: [\"summarize_second\"]\nname: \"summarize_second\"\ninstruction: \"summary2=write a summary of the following text: $text2\"\naction: \"thought\"\ntransitions: (\"combine_summaries\"]\nname: \"combine_summaries\"\ninstruction: \"combined_summary=Write a summary combining $summary1 $summary2\"\naction: \"thought\"\ntransitions: [\"return combined_summary\"]"}, {"title": "METHODS OF IMPLEMENTATION AND VISUALIZATION", "content": "At the time of writing, there are three ways to implement an autogram:\n1. Spreadsheet-Based Design:\n\u2022 Each row in the spreadsheet corresponds to a different node in the AutoGRAM.\n\u2022 Each column corresponds to a different node field, determined from the heading of the column.\n\u2022 This method allows autograms to be defined and managed using a familiar spreadsheet interface.\n2. Pure Python Implementation:\n\u2022 Nodes of an autogram can be defined in Python by initializing an autogram object and using the autogram.add_node() method to create new nodes with fields corresponding to the arguments provided.\n\u2022 This is the most direct way to design an autogram, as all other methods of design are mapped to this.\n\u2022 The main limitation is that it can be inconvenient for autograms that need to execute Python code within the autogram. Python code can be passed in as a string instruction, but this makes the code more difficult to read.\n\u2022 Standard conditionals and loops can theoretically be implemented using wildcard transitions and loops in the graph with exiting branches, but these can be inconvenient to define graphically.\n3. AutoGRAMS Compiled from Python:\n\u2022 This method works best for autograms deeply integrated with Python code.\n\u2022 It is technically a new language that closely relates to Python but has some differences that allow Python code to be integrated with AutoGRAMS nodes using Python syntax.\n\u2022 AutoGRAMS is general enough to execute most functional Python programs using a combination of Python and transition-type nodes along with the right graph structure and wildcard transitions for branching."}, {"title": "AUTOGRAMS CONFIGURATIONS", "content": "AutoGRAMS configurations are essential for controlling various settings of an autogram. Key aspects of these configurations include:\n\u2022 Model Selection: Defining which models will be used within the autogram.\n\u2022 Prompt Templates: Establishing templates to guide the language model responses.\n\u2022 Python Imports and APIs: Specifying the Python modules and APIs accessible from the AutoGRAMS code.\nConfigurations are typically managed through a JSON file, with the exception of the Python modules field. This field requires actual Python modules containing code, which are passed to the autogram, allowing the use of any Python-defined function within Python function nodes.\nFor further details:\n\u2022 Appendix A: Provides an overview of how prompts for language models are set.\n\u2022 Appendix B: Details the language models used in AutoGRAMS and their configuration settings.\nThese settings ensure that the autogram operates correctly, utilizing the appropriate models, prompts, and Python functionalities."}, {"title": "AUTOGRAMS GRAPH COMPILER", "content": "AutoGRAMS gives the ability to embed general code within graphical AI agents and chatbots. One way to design autograms is to define nodes one-by-one, with transitions to other nodes specified in node definitions. This is especially useful for chatbots, since conversations often have certain states that can be modeled as a graph or tree. AutoGRAMS also allows nodes in this graph to execute code, rather than give a reply. However, this requires the code that executes at a node to be passed as a string in a node's instruction. This graphical representation also means that loops and conditionals in the AutoGRAMS graph need to be defined using the appropriate transitions. We were motivated to allow deeper integration between general code statements and the graphical representations used by autograms. To do this, we implemented the AutoGRAMS compiler, which can map a combination of Python code and statements that define AutoGRAMS nodes, to an autogram that can be executed by the AutoGRAMS interpreter (Section 4). It does this by mapping the code in a file to a set of nodes with the appropriate attributes to perform the computation specified in the code file.\nAutoGRAMS is general enough to execute functional programs that can be represented common features such as loops, conditionals, functions and variables. This is possible by combining python-type nodes with the desired flowchart needed to execute a program. For instance, consider a program that computes the nth element Fibonacci sequence recursively (While this is inefficient, we use it for illustrative purposes). Python code for this is given in Figure 7a.\nThe function fibonacci(n) accepts a number, returns 0 of the number is 1, returns 1 if the number is 2, and returns the sum of fibonacci(n - 1) and fibonacci(n - 2) if the number is greater than 2. this function can be represented completely in AutoGRAMS with a combination of python-type nodes, function-calling nodes, transition nodes, return transitions, and wild card transitions. The first node of the graph must be a callable node named \u201cfibonacci(n)\". The parentheses in the name means that it can be called function calling nodes, and using n means that the first argument passed can be referenced with the variable name \u201cn\u201d. A node with an action local_function and instruction of x = fibonacci(n) can be used to call this function as set the result to a variable called \u201cx\u201d.\nThe first conditional of the program is implemented with a wildcard transition, where the root node of the conditional applies a transition to fibonacci_conditional.*, which means that the next node will either be fibonacci_conditional.a, fibonacci_conditional.b, etc. In this specific case, since there are 4 possible branches, it is necessary to define nodes named fibonacci_conditional.c and fibonacci_conditional.d. Each of these nodes has a boolean_condition attribute that can be used to specify the condition at which this branch can be executed. Boolean conditions are passed to the Python interpreter in AutoGRAMS so they can include any Python code or references to any variables visible at the current scope. fibonacci_conditional.d does not need a boolean conditional because it is the last node in alphabetical order. If the n == 1 or n == 2 condition are reached, the appropriate value can be returned by using a python-type that simply includes the desired number, and then applying a return transition immediately after, which returns the result of the previous node if no return variable is specified. If the else condition is met reaching the node fibonacci_conditional.d, the autogram can use two local-function nodes that call the Fibonacci graph again with n 1 and n 2, sum the result, and return the result. The AutoGRAMS graph, which was compiled automatically from the Python code using the AutoGRAMS compiler, is given in Figure 7b.\nThe AutoGRAMS compiler is used to convert code with python-like syntax into a set of Auto-GRAMS nodes that can be executed as an autogram. It is also possible to code any autogram in pure Python (or a spreadsheet) by defining nodes one by one, in which case the AutoGRAMS compiler is not used. However, for autograms that contain Python statements or programmatic features like loops and conditionals, the compiled version has several advantages:\n\u2022 Python statements can be included directly as code instead of as strings in the instruction of python_function nodes\n\u2022 Python style variable assignments can be be used instead of assignment variable in an instruction\n\u2022 AutoGRAMS function calls and functions can be defined using Python-like syntax. Note that functions are by default treated as local AutoGRAMS functions, but this behavior\""}, {"title": "AUTOGRAMS INTERPRETER", "content": "Autograms are executed via an iterative process that selects nodes and executes them. Within the AutoGRAMS framework, an autogram can be applied using the reply method, which is for conversational modules, and the apply-fn method, which allows an AutoGRAMS function to be called directly from Python, and it meant for non-conversational modules. Both work in a very similar fashion, other than the way they terminate their main loop. The reply method terminates and returns a result when it encounters a chat node, and is designed to restart from the node it left off at when it receives another user reply. The apply fn method terminates when it encounters a return statement-meaning the AutoGRAMS function is done executing and is returning a result. An illustration of the outer loop of the AutoGRAMS reply method is given in Figure 8.\n4.1 MAIN STEPS FOR OBTAINING CONVERSATIONAL REPLIES\nThe outer loop of autogram.reply() has 6 main steps:\n1. get the variable output of previous node (skip this step if no previous node). This step calls a node specific method called get variable_output() which returns the variable output of the node. The specific behavior of this will depend on the node type, but this is often the text generated by the chatbot.\n2. assign variables assigned in previous node to memory (skip this step if no previous node). If any variable outputs were in the previous node's instruction, the memory object (Section 4.2) assigns the nodes variable output to a variable with the name defined in that instruction. This goes in the top level of the memory objects stack.\n3. apply transition function from previous node (skip this step if no previous node). This calls a node specific method called apply transition() to get an unprocessed new node id. The behavior of this method will can be different for different types of nodes, but is generally similar for non-function calling nodes. If there is only 1 possible transition in the transitions list of the node, then the result will usually this transition. If there are multiple transitions, the transition will depend on what the classifier predicts.There also may be interjection transitions if the node is a chat type. If the node is calling a function, the new node id will be the root node being called.\n4. post-process the new node id (skip this step if no previous node). If the new node id output by apply transition() corresponds to another node in the graph, and the next step will be to simply select that node. However, if the new node id corresponds to a return statement or a wildcard transition, additional post processing will be needed. A return statement will require using the memory object to find the previous function calling node,"}, {"title": "MANAGING MEMORY", "content": "AutoGRAMS uses a \"memory object\" to keep track of the state of the program, including all the variables set by AutoGRAMS nodes and conversation turns. The memory object stores a stack of"}, {"title": "INTERPRETING PYTHON STATEMENTS", "content": "Python statements (as well as the 'boolean_condition' field for wild card transitions, and arguments to AutoGRAMS functions) are interpreted by the Statement Interpreter. At initialization, the State-ment Interpreter uses the Autogram Config to load all Python imports and modules that will be allowed within the scope of the program. It also overrides any Python builtins that are not explicitly listed in the Autogram Config to prevent them from being called. These imports are effectively treated as global variables that can be accessed anywhere from within the autogram. When the State-ment Interpreter called to execute code, it uses the Python eval command-it includes all variables"}, {"title": "SELF-MODIFYING AND META AUTOGRAMS", "content": "5.1 INTRODUCTION\nAutoGRAMS allows a designer to specify a series of instructions and transitions that form a program that control this process. However, the space of possible useful processes like this that can be formed is extremely large. For instance, there are likely many processes in AutoGRAMS that would be useful for solving certain problems, or handling certain conversational scenarios. It could be difficult for the designer to specify every possible process that the agent may need to handle. It would therefore be very useful to have a \"meta-process\" that can design large sets of these processes in advance, or be able to define new processes on the fly when encountering new scenarios.\nAutoGRAMS is designed in such a way that the meta-process can be of the same form (an Auto-GRAMS graph) as the processes that the meta-process designs. This makes it possible to design meta-processes that can self-modify, giving greater flexibility as compared with a system where the meta-process is of a different form from the process. Within AutoGRAMS, we refer to these meta-processes as meta-autograms.\n5.2 \u039c\u0395\u03a4A AUTOGRAMS\nOne of the goals of AutoGRAMS was to design an agent framework general enough that an agent could be used to design another agent of the same form. AutoGRAMS provides a simple working example of an AutoGRAMS function that can be used to design a chatbot autogram. The function, which we refer to as a meta-autogram, takes in a prompt as an argument. It applies the following steps\n\u2022 apply a thought node that asks the language model to design an outline of the possible ways the conversation can go from this prompt\n\u2022 apply a thought node that asks the language model to design a graph using the dot (graphviz) 2 language, where each node should be labeled by how the agent should reply, and each edge should be labeled by how the user should reply.\n\u2022 call an external Python module to parse the nodes from the graphviz graph, go back to step 2 if problems with the graph are detected\n\u2022 For each node parsed from the graphviz graph, call thought type nodes to generate the attributes associated with that node. The prompt for the thought node conditions on the graph labels for that node from step 2 to guide it. All the attributes are saved as variables and used to form a diction ary of arguments for each nodes\n\u2022 return the arguments needed to initialize a new autogram\nThis process is visualized in Figure 10.\n5.3 SELF-MODIFYING AUTOGRAMS\nOne advantage of the graphical representation of AutoGRAMS is that a node at one point in the graph can perform operations that modify nodes at other points in the graph. For instance, a series of nodes could be configured to perform the following operations\n1. select a node in the graph\n2. call a language model to decide what the new attributes of that node should be, and save the arguments to define this node in variables\n3. if any new nodes need to be defined (because transitions of original node changed), loop through and define new nodes using the process in step 2. Continue to define child nodes until all nodes are connected to the graph (the system will eventually need to connect all nodes back to existing nodes so that it doesn't get stuck in an infinite loop).\n4. loop through to initialize/modify nodes using the arguments saved in variables during steps 2 and 3\nThis is one of many possible ways an autogram could self-modify by using nodes to modify other nodes or adding new nodes.\nWe provided the ability for autograms to directly access their own data structure during their execution when running in \"self-referential\" mode. An autogram is implemented as an instance of the Autogram class in Python, and when self-referential mode is enabled in the autogram config, nodes are able to reference a variable called self which refers to the autogram's own object that interprets the autogram. This potentially allows any of the autograms nodes, methods, or other attributes to be accessed during the execution of the autogram. One potential usecase for this is dynamic modification of the autogram. For instance, it is possible for an autogram to add new node to itself by calling the self.add_node () method with the appropriate arguments from a python-type node. We implemented a simple proof of concept of this where an autogram simply adds and executes a new node at each turn, instead of having the nodes defined before hand. This works by having an AutoGRAMS function to generate all the attributes of a new node and add it to the autogram, and then when the function returns, apply a dynamically defined transition with a variable name that specifies the name of the new node. The new node then transitions back to the node that calls the function to design a node, allowing the chatbot to continue indefinitely. The full set of nodes needed to perform this algorithm along with explanations are provided in Appendix H."}, {"title": "FUTURE DIRECTIONS", "content": "Our future work will focus on developing software libraries of self-modifying autograms capable of defining useful autogram processes and learning from their interactions with the environment. In this paper, we demonstrated an autogram that can design an AutoGRAMS chatbot based on a prompt describing the chatbot's required functionality. While the scope of the present paper was to develop useful representations for designing such algorithms, future work will aim to implement autograms that perform these functions.\nFuture applications could include autograms that process conversations conducted by a human agent and generate new autograms to replicate the human agent's logic. Additionally, an autogram could be programmed to analyze its own interactions, identify where it went wrong due to unexpected user input, and modify its nodes accordingly.\nAdvanced autograms could also retrieve information on complex topics and adjust their reasoning structures to better integrate this material into their conversational or reasoning routines. This has significant implications for using large language models or generative AI in robotics. By fine-tuning language models to better model autograms, we hope to enhance the ability of autograms to design other autograms and self-modify."}, {"title": "RELATED WORK", "content": "The development of AutoGRAMS is situated within a broader landscape of research encompassing natural language processing (NLP), AI agents, and programming languages for AI. This section reviews key advancements and their contributions to the field, highlighting how AutoGRAMS builds on and extends these innovations.\nSignificant progress in NLP and neural language modeling (Bengio et al., 2000) has been driven by transformer-based architectures (Vaswani et al., 2017), such as BERT (Bidirectional Encoder Representations from Transformers) Devlin et al. (2019), GPT-3 (Generative Pre-trained Transformer 3) Brown et al. (2020), and T5 (Text-To-Text Transfer Transformer) Raffel et al. (2020). These models have shown exceptional capabilities in understanding and generating human-like text, providing a robust foundation for developing advanced conversational agents. Notable conversational agents include Google's Meena Adiwardana et al. (2020), Facebook's BlenderBot Roller et al. (2020), and Microsoft's DialoGPT Zhang et al. (2019), which leverage large-scale pre-training and fine-tuning on diverse datasets to perform a variety of conversational tasks. AutoGRAMS relies heavily on the ability of pretrained Transformer models to generate realistic text that can be used in conversational replies and apply reasoning steps.\nThe intersection of programming languages and AI has been extensively explored to facilitate the integration and development of AI models. Python, along with frameworks like TensorFlow (Abadi et al., 2016) and PyTorch (Paszke et al., 2019), has become integral to AI research, providing comprehensive libraries for model development, training, and deployment. Domain-specific languages (DSLs) like Keras for neural network modeling (Gulli & Pal, 2017) and Rasa for building conversational AI (Bocklisch et al.) are designed to simplify AI programming and make it accessible to a broader audience. Code language models (Chen et al., 2021; Nijkamp et al., 2022; Roziere et al., 2023) have enabled AI to automatically generate code that can solve complex tasks, allowing for a deeper integration between programming languages and AI. In the AI agent space, Flows Josifoski et al. (2023) is conceptual framework that facilitates structured reasoning and collaboration among AI systems through modular, message-based interactions. DSPyKhattab et al. (2023) is a programming model that abstracts language model pipelines as text transformation graphs.Jojic et al. (2023) demonstrate the Iterations by Regimenting Self-Attention technique, which manipulates the self-attention mechanism in language models to trigger and control iterative behaviors for executing algorithmic tasks. Building on the integration of natural language with programming, the AIOS Compiler (Xu et al., 2024) is a system that leverages LLMs to interpret and execute instructions in natural language. AutoGRAMS integrates programming languages and language models by combining graphically represented agent nodes with graphically represented program nodes. computer programs essentially model flowcharts (Goldstine & von Neumann, 1947), where each node in the flow chart executes and instruction and each transition is facilitate by a branch. In AutoGRAMS, the idea of using a flow chart for programming is combined with the idea of using a flowchart to"}, {"title": "DISCUSSION", "content": "This work presented the AutoGRAMS, a novel framework and high level programming language for controlling multi-step interactions with an LLM. AutoGRAMS gives the designer the ability to create branched multi-step interactions with an LLM in a way that is analogous to how programming languages allow for the design of branched multi-step interactions with a processor. The designer can define these steps of the interaction in advance by writing prompts for a language model at each step. AutoGRAMS also allows language models to exert direct control over transitions in the interaction by enabling the designer to write multiple choice questions that determine which branch to take. This structure enables the designer to use natural language to effectively govern the flow of the of steps that an AutoGRAMS takes. The graphical structure of an autogram allows it to be implemented and visualized in an intuitive way.\nAutoGRAMS is especially useful for designing complex conversational flows. AutoGRAMS allows for agents be designed to behave in more predictable ways over longer conversations, giving added control-ability and safety to conversational agents. It accomplishes this by allowing the designer to define a prompt for how to reply to the user for every possible turn in the conversation in advance. The designer has to anticipate the users response, for which The designer can then also design a series of multiple choice questions for"}]}