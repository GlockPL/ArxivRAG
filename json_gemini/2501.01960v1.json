{"title": "GAF-FusionNet: Multimodal ECG Analysis via Gramian Angular Fields and Split Attention", "authors": ["Jiahao Qin", "Feng Liu"], "abstract": "Electrocardiogram (ECG) analysis plays a crucial role in diagnosing cardiovascular diseases, but accurate interpretation of these complex signals remains challenging. This paper introduces a novel multimodal framework(GAF-FusionNet) for ECG classification that integrates time-series analysis with image-based representation using Gramian Angular Fields (GAF). Our approach employs a dual-layer cross-channel split attention module to adaptively fuse temporal and spatial features, enabling nuanced integration of complementary information. We evaluate GAF-FusionNet on three diverse ECG datasets: ECG200, ECG5000, and the MIT-BIH Arrhythmia Database. Results demonstrate significant improvements over state-of-the-art methods, with our model achieving 94.5%, 96.9%, and 99.6% accuracy on the respective datasets. Our code will soon be available at https://github.com/Cross-Innovation-Lab/GAF-FusionNet.git.", "sections": [{"title": "1 Introduction", "content": "Electrocardiogram (ECG) analysis stands at the forefront of modern healthcare, serving as a critical tool in the diagnosis and management of cardiovascular diseases, which remain the leading cause of mortality worldwide [4,13,24,6]. The ability to accurately interpret and classify ECG signals has profound implications for patient outcomes, early disease detection, and the advancement of personalized medicine. However, despite decades of research and technological progress, the challenge of precise and reliable ECG classification persists, driven by the complex, non-stationary nature of cardiac electrical activity and the subtle variations that distinguish different cardiac conditions [1]. Traditional approaches to ECG classification, ranging from manual expert interpretation to rule-based algorithms, have shown limitations in scalability, consistency, and the"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 ECG Analysis and Multimodal Learning", "content": "The field of ECG analysis has witnessed significant advancements with the application of machine learning and deep learning techniques. Traditional approaches using Support Vector Machines (SVM) and Random Forests have been largely"}, {"title": "2.2 Signal Processing and Attention Mechanisms", "content": "Gramian Angular Fields (GAF) have gained prominence in time series analysis due to their ability to encode temporal dependencies in a visual format. Wang and Oates [23] introduced GAF as a novel time series imaging technique, demonstrating its effectiveness in various classification tasks.\nThe application of GAF to ECG signals, however, remains largely unexplored. This gap in the previous studies presents an opportunity to leverage GAF's unique properties for capturing complex temporal patterns in cardiac electrical activity, potentially enhancing ECG classification accuracy.\nAttention mechanisms have revolutionized deep learning across various domains, including natural language processing and computer vision. The seminal work by Vaswani et al. [20] introduced the Transformer architecture, demonstrating the power of self-attention in capturing long-range dependencies. In the medical field, Wei et al. [7] applied attention mechanisms to electronic health records for improved patient diagnosis.\nFor ECG analysis specifically, Garcia et al. [5] proposed an attention-based CNN for arrhythmia detection, showing improved performance over non-attention"}, {"title": "3 Methodology", "content": "Our proposed GAF-FusionNet framework integrates multimodal learning, Gramian Angular Field (GAF) imaging, and advanced attention mechanisms to enhance ECG classification. This section details the key components of our methodology: ECG signal preprocessing, GAF transformation, multimodal neural network architecture, feature fusion and classification approach. Our model workflow is illustrated in detail in Figure 1."}, {"title": "3.1 ECG Signal Preprocessing", "content": "Let X = x_1,x_2,...,x_T denote a raw ECG signal of length T. We apply the following preprocessing steps:\n1. Bandpass Filtering: To remove baseline wander and high-frequency noise, we apply a Butterworth bandpass filter with cutoff frequencies f_i and f_h:\nX_{filtered} = H(X) * X \\qquad(1)"}, {"title": "3.2 Gramian Angular Field Transformation", "content": "We transform each preprocessed ECG segment into a Gramian Angular Field (GAF) image using the following steps:\nRescaling The normalized segment S_i is rescaled to the interval [-1,1]:\n\\hat{x_j} = \\frac{(x_j - min(S_i))(\\overline{u} - \\underline{i})}{max(S_i) - min(S_i)} \\qquad(4)\nwhere \\underline{i} = -1 and \\overline{u} = 1 are the lower and upper bounds of the rescaled interval.\nAngular Encoding The rescaled values are encoded as angular cosine values:\n\\phi_j = arccos(\\hat{x_j}), -1 \\leq \\hat{x_j} \\leq 1, \\quad \\Phi_i \\in [0, \\pi] \\qquad(5)\nGAF Matrix Computation The Gramian Angular Field is computed as:\nGAF_{j,k} = cos(\\phi_j + \\phi_k) \\qquad(6)\nThis results in a symmetric matrix GAF \\in \\mathbb{R}^{w \\times w} that captures the temporal correlations in the original signal segment."}, {"title": "3.3 Multimodal Architecture", "content": "Our GAF-FusionNet architecture consists of two parallel branches: a temporal branch processing the original ECG time series, and a spatial branch processing the GAF images. These branches are then combined using a novel dual-layer cross-channel split attention module.\nTime Series Processing Branch The temporal branch employs a 1D Convolutional Neural Network (CNN) followed by a Bidirectional Long Short-Term Memory (BiLSTM) network. Let S_i \\in \\mathbb{R}^{w\\times1} be the input segment to this branch. The 1D CNN consists of L layers, each applying the following operation:\nh_l = ReLU(W_l * h_{l-1} + b_l) \\qquad(7)"}, {"title": "4 Experiments and Results", "content": "In this section, we present a comprehensive evaluation of our proposed GAF-FusionNet framework for ECG classification. We conduct extensive experiments on three widely used ECG datasets, comparing our method with state-of-the-art approaches and performing detailed ablation studies to validate the effectiveness of each component in our model."}, {"title": "4.1 Experimental Setup", "content": "Datasets We evaluate GAF-FusionNet on three diverse ECG datasets:\nECG200: A binary classification dataset containing 200 ECG samples, each with 96 time points [3].\nECG5000: A five-class dataset with 5,000 ECG samples, each consisting of 140 time points [3].\nMIT-BIH Arrhythmia: A comprehensive dataset containing 48 half-hour excerpts of two-channel ambulatory ECG recordings, with 109,446 beats from 15 different heartbeat types [16].\nImplementation Details We implement GAF-FusionNet using PyTorch 2.0.0. The model is trained on an NVIDIA RTX 4090 GPU with 128GB memory. We use the Adam optimizer with an initial learning rate of 0.001 and a batch size of 64. The learning rate is adjusted using a cosine annealing schedule. We use Resnet34, pre-trained by ImageNet, as backnone of the feature extraction layer. Then, we train the model for 100 epochs and select the best-performing model based on validation performance.\nEvaluation Metrics We evaluate the performance of our model using the following metrics:\nAccuracy: The proportion of correct predictions among the total number of cases examined.\nF1-score: The harmonic mean of precision and recall, providing a balanced measure of the model's performance.\nArea Under the Receiver Operating Characteristic Curve (AUC-ROC): A measure of the model's ability to distinguish between classes.\nFor multi-class datasets (ECG5000 and MIT-BIH), we report the macro-averaged F1-score and AUC-ROC."}, {"title": "4.2 Comparative Analysis", "content": "Comparison with State-of-the-Art Methods We compare GAF-FusionNet with several methods are common in time series classification tasks:\nDNN [8]: This method employs deep neural network directly on the raw ECG time series. It has shown remarkable performance in detecting a wide range of cardiac arrhythmias, achieving cardiologist-level accuracy in some cases.\nLSTM-FCN [10]: This approach combines Long Short-Term Memory (LSTM) networks with Fully Convolutional Networks (FCN). It leverages the ability of LSTMs to capture long-term dependencies in time series data, while FCNS extract local features effectively.\nInformer [27]: This is a novel long sequence time-series forecasting model that uses a ProbSparse self-attention mechanism to efficiently handle long-range dependencies. Although originally designed for forecasting, it has shown promise in various time-series classification tasks, including ECG analysis.\nAttention-based CNN [5]: This method integrates attention mechanisms into convolutional neural networks. It allows the model to focus on the most relevant parts of the ECG signal, potentially improving classification performance, especially for arrhythmia detection.\nMulti-Scale CNN [21]: This approach uses convolutional neural networks at multiple scales to capture both local and global features in ECG signals. It is particularly effective in detecting patterns that occur at different temporal resolutions."}, {"title": "Ablation Studies", "content": "To validate the effectiveness of each component in GAF-FusionNet, we conduct ablation studies by removing or replacing key components of our model. Table 3 presents the results of these studies on the MIT-BIH dataset. The ablation results demonstrate the importance of each component in"}, {"title": "5 Conclusion", "content": "In this paper, we presented GAF-FusionNet, a novel multimodal framework for ECG classification that synergistically integrates time-series analysis and image-based representation through Gramian Angular Fields. Our approach demonstrates significant improvements over state-of-the-art methods across multiple datasets, showcasing the potential of multimodal learning in biomedical signal analysis.\nWhile demonstrating promising results, has certain limitations. The experiments were conducted on public datasets, which may not fully capture the complexity of real-world clinical ECG data. Furthermore, the computational demands of GAF-FusionNet may limit its applicability in resource-constrained environments.\nFuture research directions include validating the model on more diverse clinical datasets and exploring optimization techniques to enhance computational efficiency. Additionally, investigating the interpretability of model decisions could provide valuable insights for clinicians, potentially aiding in the understanding and treatment of psychiatric disorders."}]}