{"title": "Scenario-based Thermal Management Parametrization Through Deep Reinforcement Learning", "authors": ["Thomas Rudolf", "Philip Muhl", "S\u00f6ren Hohmann", "Lutz Eckstein"], "abstract": "The thermal system of battery electric vehicles demands advanced control. Its thermal management needs to effectively control active components across varying operating conditions. While robust control function parametrization is required, current methodologies show significant drawbacks. They consume considerable time, human effort, and extensive real-world testing. Consequently, there is a need for innovative and intelligent solutions that are capable of autonomously parametrizing embedded controllers. Addressing this issue, our paper introduces a learning-based tuning approach. We propose a methodology that benefits from automated scenario generation for increased robustness across vehicle usage scenarios. Our deep reinforcement learning agent processes the tuning task context and incorporates an image-based interpretation of embedded parameter sets. We demonstrate its applicability to a valve controller parametrization task and verify it in real-world vehicle testing. The results highlight the competitive performance to baseline methods. This novel approach contributes to the shift towards virtual development of thermal management functions, with promising potential of large-scale parameter tuning in the automotive industry.", "sections": [{"title": "I. INTRODUCTION", "content": "Modern battery electric vehicles (BEVs) comprise sophisticated thermal systems (TSs). The TS plays a pivotal role in balancing the BEV design challenge with its opposing objectives of energy efficiency, tractive performance, and thermal comfort. The thermal management (TM) addresses the derived operational requirements and oversees the energetically coupled refrigerant and cooling circuits. Their operation strategy and control pose a large-scale parameter optimization problem in order to provide sufficient thermal power for each component's condition [1].\n\nTuning the feedback controllers involved in the TS demands considerable efforts. Current virtual parametrization procedures in the automotive industry include gradient-based or global optimization methods that are limited to few parameters and particular test cases [2]. To verify vehicle's hardware and software interactions, further improvements and tests are conducted at the real system. It is validated in iterations and in various climate domains around the world, see Fig. 1. However, this is not scalable and falls short in representing the final customer usage patterns. Thus, virtual development becomes imperative for sustainable verification and validation loops [1,3].\n\nA survey of expert TS calibration engineers, see appendix A, highlights two pressing requirements: a) enhanced automation in the parametrization task, and b) adaption to TM complication and changing TS configurations. We identify the need for an intelligent methodology to increase real-world scenario coverage during TM optimization. With the importance around recurring and adaptive creation of initial parameter sets for process efficiency, we investigate learning methods and thermal system scenario (TSS) generation.\n\nPrevious work outlines a scenario development method for highly automated driving [4]. The method has been transferred to TS verification challenges [3]. To minimize manual efforts, the relevance of data-driven approaches within automotive research and development has continuously increased [2, 5, 6]. However, due to cost-effectiveness and traceability in safety-critical applications, explicit embedded logic will likely endure [6, 7]. Therefore, we limit this paper's scope to intelligent parameter optimization methods for embedded functions instead of learning direct control.\n\nSolutions with fixed-structure control systems and its complications have been widely applied. Gain-scheduling"}, {"title": "II. BACKGROUND", "content": "PID control is used for nonlinear problems, and its control parameter dependencies account for exogenous influences on the system dynamics [6,8]. Further effort is required whenever subsystems are changed, or vehicle variants are introduced. Today's methods for control function optimization still struggle to handle the high dimensionality of the parameter space. The industry lacks sufficient approaches to deal with extensive search spaces while satisfying the flexibility and speed, demanded by the development cycles [2, 8]. Our paper focuses on solving these fixed-structure feedback-control parametrization tasks autonomously.\n\nIn [7]\u2013[9], autonomously learning agents have been investigated to address aforementioned challenges. In these works, data-driven parameter tuning processes are formulated as sequential decision-making tasks that enables deep reinforcement learning (DRL) as suitable approach. Though, the training data generation mainly focused on existing measurements from historic system operation. Furthermore, only a small parameter subset per decision or operating region could be regarded due architectural inflexibility.\n\nFurther industrial applications have recently been explored, such as vehicle velocity tracking control [5], parameter tracking under nonlinear system dynamics [6, 10], or chip design [11,12]. In [11] and [12], the authors approach matrix-like circuit and chip design using efficient neural networks, often used in image processing. Similarly, embedded implementations involve matrix-like parameter look-ups.\n\nIn this work, we introduce a methodology that integrates the scenario method as technique for TS excitation and integrate it into a learning parametrization process for feedback-control. Our key contributions are as follows:\n\n1) we propose a novel image-based electronic control unit (ECU) parameter representation for efficient processing,\n2) we combine the TS scenario generation [3] with a DRL agent for control function parametrization, and\n3) we demonstrate the applicability to a TM valve controller and evaluate it in the real-world BEV.\n\nWe verify the resulting parameter sets on control performance metrics in three scenarios against baselines. Finally, we conclude with a discussion of our findings and potential future advancements."}, {"title": "A. Thermal System Overview", "content": "Intelligent use of available heat has a positive impact on the primary energy demand of BEVs. Advanced TSs use valves to couple the different sub-circuits in relevant operation scenarios and leverage efficiency gains through optimal use of available heat [7]. The topological schematic of the TS in this study is depicted in Fig. 2. The continuous actuation of the mixing valve $u_{vlv}$ is proportional to its rotary piston angle $\\alpha$, and controls the downstream temperature $T_D$ by mixing two enthalpy streams with the upstream temperatures $T_{U_1}$ and $T_{U_2}$ toward a set-point temperature. The downstream temperature $T_D$ depends on both upstream temperatures, the valve angle $\\alpha$, and coolant flow rate in the system. An electric pump imposes a flow rate $V$ on the hydraulic system proportional to the hydraulic plant characteristics $k_{hyd}$ and the pump actuation $u_{pmp}$. Further, the electric fan speed $u_{fan}$ and radiator shutter angle $u_{shu}$ control the air volume flow $V_{air}$ over the heat exchanger proportional to the vehicles speed $u_{veh}$. The heat flux $Q_{ED}$ of electric drive tractive components is proportional to the power $P_{ED}$, vehicle speed $v_{eh}$, and the thermal and electrical operational states $\\{\\xi_{th}, \\xi_{el}\\}$. Since the system heat rejection $Q_{HE}$ is nonlinear w.r.t. the air volume flow $V_{air}$, the partial coolant flow rate $V$, the temperature difference $\\Delta T_{amb}$ between $T_{U_1}$ and the ambient temperature $T_{amb}$. The nonlinear TS dynamics can be described as a function of relevant actuator controls $\\{u_{pmp}, u_{vlv}, u_{fan}, u_{shu}\\}$ and the potential variables, result in:\n\n$T_D = f(\\alpha, V, T_{U_1}, T_{U_2}, T_D)$,\n(1)\n$T_{U_1} = f(Q_{ED}, V, T_{U_1})$\n(2)\n$= f(P_{ED}, u_{veh}, \\xi_{th}, \\xi_{el}, k_{hyd}, u_{pmp}, T_{U_1})$,\n$T_{U_2} = f(\\alpha, Q_{HE}, V, T_{U_2})$\n(3)\n$= f(u_{vlv}, u_{fan}, u_{shu}, u_{veh}, \\Delta T, k_{hyd}, u_{pmp}, T_{U_2})$.\n\nBased on the operational conditions, $T_D$ is mixed via the ports configuration sets $\\{1, 2, 3\\}$ or $\\{1, 3, 4\\}$ and the temperature mixing function is either implemented in an upstream or downstream flow control. Similar dependencies for the level of heat rejection can be defined between the system free cut (blue) in Fig. 2 induced by connected subcircuits.\n\nThe parametrization of the described temperature controller and TM represents a difficult resources and time-intensive process [1]. State of the industry methods predominantly use physical prototypes for testing in all relevant ambient climatic zones [3], see Fig. 1. The described system is representative to various enthalpy controllers in BEVs with similar configurations and system dynamics, yet simply understandable in the discussed form."}, {"title": "B. Controller Parametrization Problem Formulation", "content": "The TS is a nonlinear parameter-varying dynamic system:\n$\\dot{x}(t) = f (x(t), u(t), \\theta(x, u, w))$,\n(4)\nwith system states \u00e6, inputs u, and unknown variant parameters $\\theta$ depending on exogenous inputs w. The exogenous"}, {"title": "C. Scenario-based Virtual Development", "content": "The methodology of advanced scenario-based development, testing and verification was first developed for the complex challenges in assisted and autonomous driving systems (ADAS/AD) in the PEGASUS research project [13]. It provides a standardized and regulatory approved virtual development, verification & validation method to grasp possible driving situations to address the non-feasible billions of necessary testing mileage [14]. The core method projects any driving situation onto six standardized layers. Each layer represents a distinguished set of information relevant to describe a driving situation to its full extent. Assuming complete layer information, the recombination of individual layer's data could create any possible driving situation [4]. This approach is useful for virtual development as well as verification & validation purposes through standardized scenario description and simulation, e.g., via OpenDRIVE and OpenSCENARIO formats [4]. The methodology is recently adapted for TS development by enriching the layers with additional domain specific information, as a comprehensive approach to formulate TSSs for novel tools in the TM development and verification [3]."}, {"title": "D. Reinforcement Learning for Parametrization", "content": "Intelligent control through closed-loop feedback interaction increasingly grows in relevance. Nonlinear system dynamics, high degree of freedom, or black-box problems are favorable domains for reinforcement learning (RL) applications. Autonomously learning agents have also been applied to white-box nonlinear system identification [10] and controller tuning [6]\u2013[8].\n\nThe formulated TM controller parametrization task can be regarded as a sequential decision-making problem, see [7,8,15]. As depicted in Fig. 3, static configurations, stationary information and measurable states are observed (0) from the TS in its application domain. The RL environment"}, {"title": "III. OUR SCENARIO-DRIVEN RL APPROACH", "content": "In order to create versatile training data for the RL-based parametrization procedure, we use the adapted scenario methodology introduced by [3] to create responsive TSSs, depicted in Fig.4 (left). We collect driving data from real world test drives and customer fleet data as statistical distributions to create a representative vehicle usage scenario database. Additional expert engineer knowledge and public databases enrich each layer with TS information, i.e., charging infrastructure, solar irradiation, and humidity. We then perform the data allocation to the layer scheme introduced by the adapted scenario methodology. Through recombination of available information from the scenario database layers in combination with randomized driving routes, we create multiple individual scenarios representing customer-like usage. A longitudinal dynamics vehicle model calculates the vehicle response trajectory to each scenario, which is used to parameterize and evaluate controller performance. Furthermore, we explicitly use real world development drive data for the different climatic zones, e.g., measurement drives from Dubai (hot), Sweden (cold), or Spain (moderate), see Fig. 1. The driving data were independently collected over the period of six months with different development vehicles."}, {"title": "A. Methodology for Scenario Generation", "content": "In the following, we present the procedure of the TS-adapted scenario methodology to tackle the challenge of understanding and modeling customer vehicle usage for the exemplary valve controller parametrization problem.\n\nThe set M describes vehicle usage data and comprises available customer fleet data and selected development drive data sets. We derive layer-focused statistics from M to describe the usage behavior with respect to TSS influencing factors, i.e., mileage per ambient temperature. From this we create a subset S with customer-focused metrics, as detailed in [3]. A Gaussian-normal distribution fit $\\mathcal{N} (\\mu_{\\varsigma}, \\sigma_{\\varsigma})$ for each scenario layer random variable of S yields thermal system operation distributions to describe vehicle and TS behavior. To limit the solution space of possible scenarios, we disregard values below the 10% and above the 90% behavioral distribution quantiles. We ensure a robust and safe operation by adding TS specialized edge cases, e.g., high loads at extreme temperatures from sub-polar and desert conditions, on top of the broad distributions. By optimizing"}, {"title": "B. Contextual DRL for Embedded Controller Tuning", "content": "The following describes our novel contextual RL-based controller parametrization agent with its architecture depicted on the right half of Fig. 4. We describe the TSS-driven training algorithm to solve for a contextual parametrization problem based on the obtained TS information.\n\nFor each decision step about adaptions to the parameters, the agent gathers information about relevant ECU signals and the current parametrization. The TS carries stationary information that describe a context in which the parametrization task needs to be solved, i.e., high-level operational TM states $\\xi$ based on the current TSS correlate with significant diverting system dynamics and subsystem control references. Accordingly, we regard a context vector $c = [\\xi_{th}, \\Upsilon_{ref}]$ with $\\xi_{th}$ as thermal operational state describing the desired TS sub-circuit configuration and therefore possible valve control piston positions and $\\Upsilon_{ref} = T_{D,ref}$ as the downstream temperature reference, desired by the high-level TM. Additionally, we observe measured signals s(n) as time-discrete sequences within a windowed interval, with samples $n \\in [0, N]$. For the valve controller, we regard $s(n) = [T_D(n), e_T(n), \\Delta T_{amb}(n), u_{vlv}(n)]$. Last, we need to observe the current tunable parameters $\\phi$ in (6).\n\nWe reinterpret the embedded implementation of varying control gains in the form of look-up tables as $M_i \\times M_j$-sized image-like matrices. Given the operating states $\\{\\xi_{th}, \\xi_{el}\\}$, one of two controllers with a PI parameter set is dynamically active and regarded, for a total of 100 parameter values. The matrices $\\phi$ are dependently evaluated on the current ECU signals, namely $s_i = e_T$ and $s_j = \\Delta T_{amb}$ over their i, j-axes with each matrix of size $M = M_i = N_i = 5$. Consequently, we retrieve $C = 2$ channels of stacked parameter values, comparable to colour-based channels of an images. For generalized applicability of the DRL architecture, we upsample and interpolate the matrices to $\\frac{M}{4}$ of common quadratic size $M = 8$. We derive a similar approach for look-ups curves (1D) or cubes (3D) used in the industry. Finally, we consider the joint DRL agent observation $o = [c, \\phi, s(n)]$.\n\nBased on the observation o, we formulate an LQR-inspired objective as a dense reward function:\n\n$r_j = - \\frac{1}{N} \\sum_{n=0}^{N-1} (b_1 e_T^2(n) + \\sqrt{e_T^2(n)}) + b_2 \\cdot u_{vlv}^2 (n)$,\n(9)\nwith design choices $b_1 = 25$, and $b_2 = 0.1$ in this work. We quadratically penalize large errors and the required cooling power through wide open valve positions but also stimulate the sensitivity at small control errors with the root term. Unstable controller parameters result in a extreme negative reward that may lead to divergence during training. Therefore, we clip the negative rewards to a lower limit and clip the positive controller parameters to an upper limit.\n\nThe DRL architecture in Fig. 4 (right) processes the observation o and derives the action $a \\in \\mathcal{A}$ to tune the parameters $\\phi$ in expectation of subsequent rewards. Neural networks, hence DRL, are predominantly applied to sophisticated RL problems to approximate a decision strategy [15, 16]. In parallel, a) the task context is inferred to a latent context vector $z_c$ via a multilayer perceptron (MLP) with nonlinear activations and dropout layers, b) the signals are processed via recurrent long short-term memory (LSTM) layers with the final output as latent signal vector $z_s$ [7,8]. Previous work did not regard the state-spatial dependency of neighboring operating points for parameter-varying systems and adaptive controllers in the observation [6]. In contrast, we use a convolutional neural network (CNN) feature extractor to encode the channeled parameter matrices into $z_{\\phi}$. Subsequently, we derive a latent vector $\\zeta = [z_c, z_s, z_{\\phi}]$ by concatenation of the individual latent representations. Based on $\\zeta$, the CNN decoder infers the latent vector. Alternating convolution blocks and upscaling layers generate the target matrix structure M. With $\\zeta$, the parallel critic MLP estimates the state-action value Q for the RL training algorithm [16].\n\nHowever, applying the full tuning matrix $\\Delta \\phi$ to the parameter tables would create an infeasible sequence of decisions. Depending on the TS state trajectories of an individual scenario, only subsets of the parameters actively contribute to the closed-loop performance, depending on the parameter table axes $s_{i/j}$. Action masking contributes to a faster convergence during training, enabling real-world applications of otherwise sample inefficient RL algorithms [17]. Therefore, we introduce binary parameter action masks $m \\in \\{0, 1\\}^{M_i \\times M_j}$. During dynamic mask construction, a 1 is registered for at least one time sample in which the TS operates in the vicinal table area. In contrast to the observation, we downsample and interpolate from M to the original parameter matrices' shapes. We derive the new controller parameter set for step k via the function $\\varphi$, applying a Hadamard product with the masks to the downsampled ($\\downarrow$) set of parameter changes:\n\n$\\Phi_k = \\varphi (\\Phi_{k-1}, a, m) = \\Phi_{k-1} + \\downarrow_{M_i, M_j}(\\Delta \\phi_k) \\odot m$.\n(10)"}, {"title": "C. Training of the DRL Parametrization Agent", "content": "In this work, we deploy the soft actor-critic algorithm derivative dropout Q-function (DroQ) for increased sample-efficiency through multiple Q-value updates per step on parallel Q-networks [15, 16]. The encoder-decoder actor $\\pi_{\\psi}$ and critic $Q_{\\omega}$ networks are parametrized by $\\psi$ and $\\omega$, and trained through backpropagation of the policy and Q-objective gradients based on the reward r [16]. Algorithm 1 describes the training routine for our scenario-based DRL controller parametrization task. It requires a TSS subset $\\mathcal{S}$ and a TS system dataset $\\mathcal{D}_{\\theta}$, for initialization and simulation (lines 2,4). For each episode of length K, we reset the TS model and a new scenario $x_{\\varsigma}$ is sampled via the TSS method. We chose conservative stable parameter sets to initialize each episode. In each episode step, we sample a new scenario $x_{\\varsigma}$ via the TSS method (lines 5,11) and simulate it with the virtual closed-loop controlled TS (EvalScenario) which derives the observation and mask (lines 6,12). The DRL actor policy derives the parameter adaption (lines 9, 10) and a reward is calculated (CalcReward) w.r.t. (9), and the gathered experience stored in the buffer $\\mathcal{R}$ (line 14).\n\nAfter the successful episodic training from off-policy updates of our DRL architecture (lines 15, 16), see Fig. 5, the converged policy $\\pi_{\\psi}$ can be independently inferred with in-distribution observations from real-world systems."}, {"title": "IV. REAL-WORLD EXPERIMENT AND RESULTS", "content": "To verify our methodology, we apply our DRL architecture to a TS learning environment, implemented in the Gymnasium RL standard. Referring to section II, the simulation includes our previously discussed cooling circuit. It comprises the PI valve controller and its adjustable parameter tables from section III. We use 32 parallel environments which interface the agent with a TS simulation model, using C++ code generated by MATLAB\u00ae SIMULINK\u00ae.\n\nWe build our agent on top of the PyTorch-based framework stable-baselines3 [18], using the proposed agent from Fig. 4."}, {"title": "V. CONCLUSION", "content": "This work presents a novel approach to the parametrization of embedded TM valve controllers. Leveraging scenario-driven virtual development and image-based parameter representations, our proposed DRL agent obtains competitive parameter sets in a fully automated manner. We demonstrate the validity of learning virtual development processes for the industry applications. The results show effectiveness to current industry baselines in real-world testing scenarios. Due to the similarity of enthalpy controllers and system dynamic requirements in BEVs, the discussed principles can be easily transferred to different controllers within the same vehicle and to different vehicles as well.\n\nOur approach enables streamlined allocation of costly physical prototype resources. Future work could investigate methodological feedback to the scenario generation within learning curricula. In addition, the cooperation between autonomous agents and human expert engineers holds great potential for future innovation through distillation of their respective strengths and experience. Conclusively, the paper highlights the potential for transfers to new application domains and parametrization tasks beyond controller tuning."}, {"title": "APPENDIX", "content": "We conducted a survey with a cohort of expert calibration engineers (N=7, 3 junior and 4 senior positions) who regularly parametrize TM control systems with ~2000 tunable calibration variables of control architectures as studied in this work. Below is a relevant subset of the survey's questions, and Fig. 7 shows the respecting statistical evaluations:\nQ1: \"What percentage of the total number of tunable parameters can realistically be calibrated?\u201d\nQ2: \"What time saving in the total parametrization process is expected if parameter sets would be generated in seconds?\u201d\nQ3: \"What time effort do you estimate for the parametrization of an exemplary control function for the first TM configuration in one climatic zone.\"\nQ4: \"What additional time effort to Q3 do you estimate for each subsequent TM configuration?\u201d\nQ5: \"What time effort do you estimate for the creation of specific test scenario and experiment design?\u201d\nQ6: \"What time effort do you estimate for an initial virtual parametrization in regard to the task in Q3?\u201d"}]}