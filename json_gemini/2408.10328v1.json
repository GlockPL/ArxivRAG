{"title": "Decoding Human Emotions: Analyzing Multi-Channel EEG Data using LSTM Networks", "authors": ["Shyam K Sateesh", "Sparsh BK", "Uma D."], "abstract": "Emotion recognition from electroencephalogram (EEG) signals is a thriving field, particularly in neuroscience and Human-Computer Interaction (HCI). This study aims to understand and improve the predictive accuracy of emotional state classification through metrics such as valence, arousal, dominance, and likeness by applying a Long Short-Term Memory (LSTM) network to analyze EEG signals. Using a popular dataset of multi-channel EEG recordings known as DEAP, we look towards leveraging LSTM networks' properties to handle temporal dependencies within EEG signal data. This allows for a more comprehensive understanding and classification of emotional parameter states. We obtain accuracies of 89.89%, 90.33%, 90.70%, and 90.54% for arousal, valence, dominance, and likeness, respectively, demonstrating significant improvements in emotion recognition model capabilities. This paper elucidates the methodology and architectural specifics of our LSTM model and provides a benchmark analysis with existing papers.", "sections": [{"title": "1 Introduction", "content": "EEG is defined as the electrical activity of an alternating type recorded from the scalp surface after being picked up by metal electrodes and conductive media [19]. The unique ability of EEG signals to provide a very descriptive temporal view of brain activity makes it an indispensable tool for understanding complex human emotional states. This capability is especially critical in contexts where the traditional means of emotion assessment are impractical or unfeasible.\nIn recent years, there has been a necessity for understanding and quantifying emotional responses, which has led to advancements in academic research. This has opened new doors for consumer research, mental health, and assistive technologies. The prospect of its ability to assist individuals who would otherwise not be able to express emotions through traditional ways, such as facial expressions, body language, and speech, makes this one of the exciting fields for EEG-based recognition of emotions. These individuals would include, but not be limited to, people with communication disabilities, for example, aphasia; other"}, {"title": "2 Related Work", "content": "The DEAP dataset, detailed by Koelstra et al. [10], has been foundational in the field, providing a rich data source for subsequent research. Also, significant correlations were found between the participant ratings and EEG frequencies. The single-trial classification was performed for arousal, valence, and liking scales using features extracted from the EEG, peripheral, and MCA modalities. The results were shown to be significantly better than random classification.\nAlhagry et al. [2] proposed LSTM networks for emotion recognition from raw EEG signals. Their study demonstrates that the LSTM model achieves high average accuracies across three emotional dimensions and outperforms traditional emotion recognition techniques, marking a significant advancement in the field.\nNie et al. [16] explore the relationship between EEG signals and emotional responses while watching movies, focusing on classifying emotions into positive and negative categories. Their application of a Support Vector Machine (SVM) on processed EEG features resulted in an impressive average testing accuracy of 87.53%, underscoring the potential of EEG-based methods in practical multimedia applications.\nLi et al. [11] provide a comprehensive overview of EEG-based emotion recognition, exploring the integration of psychological theories with physiological measurements. They review various machine learning techniques, from conventional models to advanced computational methods, highlighting key advancements and challenges in the field.\nZheng et al. [21] develop an innovative approach by integrating deep belief networks with hidden Markov models for EEG-based emotion classification. Their findings indicate that this combined DBN-HMM model achieves higher accuracy than traditional classifiers, highlighting its effectiveness in leveraging spatial and temporal EEG data dimensions.\nBhagwat et al. [6] proposed a novel approach for classifying four primary emotions: happy, angry, crying, and sad, which can be visualized as four quadrants. They used Wavelet Transforms (WT) to extract features from raw EEG signals and employed a Hidden Markov Model (HMM) to classify emotions.\nLin et al. [13] utilize EEG data and machine learning to enhance emotional state predictions during music listening. Using an SVM, their approach achieves an average classification accuracy of 82.29% for emotions such as joy, anger, sadness, and pleasure.\nNaser and Saha [15] applied advanced signal processing techniques to improve feature extraction for emotion classification from EEG signals. Their study utilizes dual-tree complex wavelet packet transform (DT-CWPT) and statistical"}, {"title": "3 Dataset", "content": "The Database for Emotion Analysis using Physiological Signals (DEAP) [10] is at the core of our study, and it presents a rich source of EEG and peripheral physiological signals for analyzing emotions. The dataset was built to boost and proliferate the development of systems that would be capable of recognizing human emotions from physiological responses, with particular emphasis on the paradigms of human-computer interaction."}, {"title": "3.1 Dataset Description", "content": "The DEAP dataset consists of EEG data recordings from 32 participants between 19 and 37 years old, with a mean age of 26.9 years. Each participant was"}, {"title": "3.2 Data Acquisition", "content": "EEG and peripheral physiological signals were acquired simultaneously, viewing each music video clip by all the participants. In the course of the experiment, the recording of the EEG data was carried out at 512 Hz through the 32-channel systems, which was eventually reduced to 128 Hz during analysis. Concurrently with EEG, other physiological signals such as galvanic skin response and heart rate were also recorded to deliver complete states regarding the participant's physiological states during each trial."}, {"title": "3.3 Data Structure", "content": "For each participant, it is composed of two main arrays: the EEG signals and an array of labels for each trial. The EEG data array has a dimension of 40x40x8064 for 40 trials, 40 channels, and 8064 data points per channel per trial. Corresponding to four emotional dimensions assessed per video clip, the array structure of labels is 40x4."}, {"title": "4 Valence, Arousal, and Dominance Model", "content": "The Valence-Arousal-Dominance (VAD) model presents a sensitive framework for recognizing human emotions and classifies them into three significant aspects: valence, arousal, and dominance. Valence measures the 'how good or bad' of the mood, arousal measures the activation level, and dominance measures how much control one might feel they have over their emotional state. Researchers have adopted this model in examining features of EEG that indicate the functioning of different areas in the brain toward emotional stimuli. Research has shown that the positive effect increases alpha band activity in the frontal regions. In contrast, the negative one tends to decrease it, and high arousal corresponds to"}, {"title": "5 Rationale Behind Usage of Deep Learning", "content": "Emotion recognition from EEG data is a difficult task due to the complexity and variability of the signals. Although traditional statistical methods effectively analyze structured and more straightforward datasets, they frequently fail to capture and interpret the dynamic and non-linear interactions typical of EEG data. Deep learning, a branch of machine learning, has become an invaluable tool for managing these complexities due to its ability to discern high-level, abstract features from vast amounts of data."}, {"title": "5.1 Deep Learning vs. Traditional Statistical Methods", "content": "Deep learning models that handle unstructured data, like images, speech, or biological signals, perform this function due to their use of neural networks. Traditional statistical approaches to data analysis require manual choice of features, and at most, they can only model the linear effects. This is essential in EEG"}, {"title": "5.2 Overview of LSTMS", "content": "LSTMs are one of the unique variants of Recurrent Neural Networks (RNN). It was first introduced by Hochreiter et al. [9] to eliminate the problem of long-term dependencies seen in conventional RNNs. Traditional RNNs are known to also suffer from gradient-related issues. This problem, in turn, makes it very hard for them to be trained on sequential data where long-term contextual information is essential. LSTMs solve this problem due to the exceptional structure of their gates, which allows them to regulate the flow of information in a way that enables them to remember or forget information for long periods."}, {"title": "5.3 Bidirectional LSTMS", "content": "The capabilities of standard LSTMs are further advanced through the usage of bidirectional LSTMs, allowing more context to be available from the subsequent points in the data sequence. So, bidirectional LSTMs can capture the context information from past and future states by processing data in the forward and reverse directions. This is very useful in emotion recognition from the EEG signals when the emotional state reflected in a data segment may depend not only on the earlier but also on the latter events."}, {"title": "5.4 LSTM for Our Work", "content": "In this project, we choose LSTM networks due to their prowess in sequence prediction problems, thus capable of adequately modelling the temporal dynamics characteristic of EEG data. Applying LSTMs will help reach the deepest emotional timelines that fall within the EEG signals, making them more helpful in predicting emotional states with better accuracy. The bidirectional approach of the capability enforces the complete context from all the data points, which increases the recognition accuracy for complex emotional states. This makes LSTMs very apt for the development of a robust system for emotion recognition from EEG-based data."}, {"title": "6 Proposed Method", "content": "Our study uses an LSTM model to classify emotional states from EEG data and focuses on feature extraction, data preparation, and architectural considerations to achieve high accuracy percentages."}, {"title": "6.1 Pre-Processing Methods Used", "content": "The feature extraction process was tailored to capture significant information from the EEG signals. We utilized specific EEG channels and frequency bands relevant to emotional processing. The chosen channels included a subset correlating with emotional states, such as frontal and temporal regions. Frequency bands were segmented into five distinct ranges: theta (4-8 Hz), alpha (8-12 Hz), low beta (12-16 Hz), high beta (16-30 Hz), and gamma (30-45 Hz), which are traditionally associated with different aspects of cognitive processing and emotional regulation (Refer to Table 2 and Fig. 3 [4]). Each of these bands aids in extracting vital information from input EEG data, which has been proven to support sentiment analysis [4]. The Fast Fourier Transform (FFT) process was applied to a select 14 channels of the recorded 32 channels, chosen to fit Emotiv Epoc, with a window size of 256 points, corresponding to 2 seconds of data, with an overlap of 0.125 seconds to ensure comprehensive temporal analysis."}, {"title": "6.2 LSTM Architecture", "content": "The LSTM network architecture employed in our study is designed to handle EEG data sequentially and temporally effectively. We will use one LSTM model for each emotional parameter in observation. The model initiates with a Bidirectional LSTM layer consisting of 128 units, enhancing the model's ability to capture dependencies in both forward and backward directions of the input sequence. This layer is followed by a dropout of 0.6 to reduce overfitting by randomly ignoring a fraction of the neurons during training."}, {"title": "7 Results", "content": "Our LSTM-based model demonstrated outstanding performance in emotion recognition from EEG data, achieving individual class accuracies of 90.33% for valence, 89.89% for arousal, 90.70% for dominance, and 90.54% for likeness, with an overall accuracy of 90.36%. These results underline the model's efficacy in capturing complex emotional states through advanced feature extraction and a robust LSTM architecture. This performance showcases the model's capabilities and sets a foundation for future advancements in EEG-based emotion recognition. A comparison of accuracies is attached in Table 3, showing our method of using an LSTM network to be highly accurate and effective in classifying emotional parameters correctly compared to related papers."}, {"title": "8 Conclusion", "content": "This study successfully showcases the efficacy of LSTM networks in accurately classifying emotional states from EEG data, achieving high performance across various emotional dimensions. The customized LSTM architecture, incorporating bidirectional layers and strategic dropout stages, adeptly handles the complexities of EEG signals. Our LSTM architecture paired with uniform frequency band ranges taken for EEG feature extraction has proven to provide improved results from previous LSTM-based EEG studies. Such capabilities pave the way for advancements in cognitive neuroscience and human-computer interaction, promising enhancements in responsive systems that adapt to user emotions in real time. Future work can further build upon this model with more robust neural networks, including time-frequency and location domain features, along with the possible usage of more than 14 EEG channels for better efficiency of emotion recognition. Upcoming research will benefit from exploring hybrid models that integrate additional physiological signals, further refining the precision and application of EEG-based emotion recognition in creating empathetic user interfaces."}]}