{"title": "Deep Learning Based Dense Retrieval: A Comparative Study", "authors": ["Ming Zhong", "Zhizhi Wu", "Nanako Honda"], "abstract": "Dense retrievers have achieved state-of-the-art performance in various information retrieval tasks, but their robustness against tokenizer poisoning remains underexplored. In this work, we assess the vulnerability of dense retrieval systems to poisoned tokenizers by evaluating models such as BERT, Dense Passage Retrieval (DPR), Contriever, SimCSE, and ANCE. We find that supervised models like BERT and DPR experience significant performance degradation when tokenizers are compromised, while unsupervised models like ANCE show greater resilience. Our experiments reveal that even small perturbations can severely impact retrieval accuracy, highlighting the need for robust defenses in critical applications.", "sections": [{"title": "1. Introduction/Background/Motivation", "content": "For a long time, the Information Retrieval (IR) field has been dominated by sparse retrieval systems, which match texts based on lexical patterns (e.g., BM25) [1][2]. However, recent advancements in deep learning, coupled with Retrieval Augmented Generation (RAG), have revolutionized text generation. RAG allows models to access curated external knowledge databases, ensuring that the generated text is grounded in factual information. This has led to the development of dense retrievers, which match texts based on semantic meanings. Dense retrievers, which use deep learning combined with RAG, can automatically learn query and document representations from labeled data, giving them exceptional capabilities for capturing and representing text semantics for relevance matching [3]."}, {"title": "1.1. Objectives", "content": "Our objective is to investigate how dense retrievers perform when their tokenizers are tampered with or \"poisoned\". A poisoned tokenizer introduces malicious or biased behavior into the model, potentially leading to incorrect or misleading tokenization of input text, and thus affecting the model's ability to understand and process text accurately. We aim to assess the impact of poisoned tokenizers on dense retriever models and explore potential mitigation strategies."}, {"title": "1.2. Current Practice", "content": "Currently, dense retrievers rely heavily on robust tokenizers to break down input text into numerical tokens that models can process. This tokenization is crucial for the model's understanding and subsequent retrieval performance [4]. However, if the tokenizer is compromised, the model's performance can degrade significantly. Current practices do not adequately address the robustness of tokenizers against such attacks, leaving a gap in ensuring the reliability and security of dense retrievers."}, {"title": "1.3. Significance", "content": "Understanding the impact of poisoned tokenizers is crucial for improving the security and reliability of dense retrieval systems. If successful, our research will highlight the vulnerabilities of current models and suggest ways to enhance their robustness. This will be particularly beneficial in applications where the integrity of information retrieval is critical, such as in legal, medical, and financial domains."}, {"title": "1.4. Data", "content": "We use the following datasets for our research:\n\u2022 Quora Dataset [5]: This dataset contains over 400,000 question pairs, each labeled to indicate whether the questions are paraphrases of each other.\n\u2022 Financial Opinion Mining and Question Answering (FiQA-2018) [6]: Crafted for the FiQA challenge in 2018, it includes opinion-based questions and answers tailored to the financial domain."}, {"title": "2. Approach", "content": "We first explain the evaluation metrics we use in details. Then, we describe target models and the evaluation design to assess the effectiveness of supervised and unsupervised (especially contrastive learning) dense retrieval models."}, {"title": "2.1. Evaluation metrics", "content": "Cosine Similarity Cosine similarity is used to measure the similarity between two sentence embeddings [8][9][10][11]. Given two sentence embeddings u and v, cosine similarity is defined as:\nsimilarity(u, v) = \\frac{u \\cdot v}{||u||||v||} (1)\nwhere $u \\cdot v$ is the dot product of the two embeddings, and ||u|| and ||v|| are the magnitudes of the embeddings. A cosine similarity value closer to 1 indicates higher similarity, while a value closer to 0 indicates greater difference.\nAccuracy Accuracy measures the proportion of correctly retrieved items out of the total number of items. In retrieval tasks, it is often used to evaluate how often the correct documents are retrieved among all retrieved documents.\nAccuracy@k = \\frac{\\text{# of Correctly Retrieved Items}}{k}\nPrecision Precision evaluates the proportion of relevant documents among the retrieved documents. It is a well-established and widely used metric in information retrieval and recommendation systems, because it effectively represents the scenarios where users are interested in the first few results returned by a system[12]. It is defined as:\nPrecision@k = \\frac{\\text{# of Relevant Documents Retrieved in Top k}}{k}\nRecall Recall measures the proportion of relevant documents that were retrieved out of all relevant documents available. It is another important metric used in information retrieval, particularly when evaluating the completeness of the results returned by a retrieval system [12][13][14]. It is defined as:"}, {"title": null, "content": "Recall@k = \\frac{\\text{# Relevant Documents Retrieved in Top k}}{\\text{Total Number of Relevant Documents}}\nNDCG (Normalized Discounted Cumulative Gain) NDCG evaluates the ranking quality of search results[12]. It accounts for the position of relevant documents in the result list, providing a single measure that balances the relevance of documents and their order, heavily penalizing relevant documents that appear lower in the results[15]. It is calculated as:\nNDCG@k = \\frac{DCG@k}{IDCG@k}\nwhere DCG (Discounted Cumulative Gain) is:\nDCG@k = \\sum_{i=1}^{k} \\frac{2^{rel_i} - 1}{\\log_2(i + 1)}\nIn this equation, $rel_i$ represents the relevance score of the document at position i, and $\\log_2(i + 1)$ is used to discount the relevance score based on the position of the document. IDCG (Ideal DCG) is the DCG score of the ideal ranking (i.e., the best possible ranking of documents):\nIDCG@k = \\sum_{i=1}^{k} \\frac{2^{rel'_i} - 1}{\\log_2(i + 1)}\nwhere $rel'_i$ is the relevance score of the document at position i in the ideal ranking.\nMRR (Mean Reciprocal Rank) MRR measures the average rank of the first relevant document across multiple queries. It is used for evaluating the effectiveness of systems that return a ranked list of responses[12][15]. It is defined as:\nMRR@k = \\frac{1}{Q} \\sum_{q=1}^{Q} \\frac{1}{rank_q}\nwhere $rank_q$ is the rank of the first relevant document for query q within the top k results, and Q is the total number of queries. If no relevant document is found in the top k, the reciprocal rank is considered to be 0.\nMAP (Mean Average Precision) MAP computes the average precision for each query and then averages these scores across all queries[12]. Average Precision (AP) for a single query is defined as:\nAP@k = \\frac{1}{\\min(R, k)} \\sum_{i=1}^{k} (Precision@i \\times rel_i)"}, {"title": null, "content": "where R is the number of relevant documents for the query, Precision@i is the precision at rank i, and reli is 1 if the document at rank i is relevant, otherwise 0.\nMAP@k is the mean of the AP@k scores across all queries:\nMAP@k = \\frac{1}{Q} \\sum_{q=1}^{Q} AP@k_q\nwhere Q is the total number of queries."}, {"title": "2.2. Target Models", "content": "BERT BERT (Bidirectional Encoder Representations from Transformers) employs a bidirectional approach, reading text in both directions simultaneously to capture deep contextual understanding [10].\nDense Passage Retrieval Dense Passage Retrieval (DPR) uses a bi-encoder architecture to independently encode queries and passages into dense vectors, enabling semantic similarity-based retrieval [11].\nContriever Contriever generates high-quality embeddings for passages and queries by combining multiple training objectives and architectures to enhance retrieval accuracy [13].\nSimCSE SimCSE (Simple Contrastive Learning of Sentence Embeddings) fine-tunes language models using contrastive learning to improve sentence embeddings by optimizing the similarity between positive pairs and dissimilarity between negative pairs [16].\nANCE ANCE (Approximate Nearest Neighbor Negative Contrastive Learning) improves dense representations by using negative samples from an approximate nearest neighbor index, enhancing training efficiency and retrieval performance [14]."}, {"title": "2.3. Evaluation Methods", "content": "Retrieval Effectiveness Evaluation We use Sentence-BERT [17] to generate the aforementioned metrics across selected datasets (NQ, Quora, FiQA, HotpotQA) from BEIR [18].\nRetrieval Robustness Evaluation We first try injecting adversarial passages into the corpus, using the method from [19]. However, the generation of a poisoned corpus requires massive computing resources. Thus, we quickly pivot to an innovative alternative: modifying the Sentence-Transformer from sentence-transformer python library [17] by adding perturbation logic, which is used to simulate adversarial passages attack in queries. Specifically, we introduce random integer noise to the token IDs of tokenized text sequences input. Adversarial inputs are often used to evaluate the robustness of models[20]. This technique aims to test the robustness of each model by simulating errors, such as grammatical mistakes or typos, within the tokenized input. We then compare the result with the pre-perturbation result for each model to measure the drop in performance with this perturbation attack. We control the perturbation rate using a variable called perturb_rate. If not specified, it defaults to 0.1, meaning 10% of the input tokens are perturbed. To further evaluate robustness, we experiment with perturbation rates ranging from 5% to 20%, controlling the extent of the attack towards query input in retrieval systems. Furthermore, we have provided code to detokenize the perturbed input IDs to visualize how the perturbation affects the original text. Here is an example when the perturb_rate is 0.10."}, {"title": null, "content": "Algorithm 1 Perturbation for Sentence-Transformer\n1: Input: Sentences, Perturbation rate ($\\epsilon \\in [0, 1]$)\n2: begin\n3: for each query in encoded sentences do\n4:  for each token in query do\n5:   r $\\leftarrow$ RandomUniform(0,1)\n6:   if r < $\\epsilon$ then\n7:   d $\\leftarrow$ RandomInteger(0,9)\n8:   token $\\leftarrow$ token + d\n9:  end if\n10:  end for\n11: end for\n12: end\n13: Output: Perturbed encoded input tokens from queries"}, {"title": "3. Experiments and Results", "content": "In our research, we used cosine similarity to evaluate the accuracy of various language models by measuring the closeness between the model's output and the semantic meaning in the validation dataset."}, {"title": "4. Conclusion and Further Remarks", "content": "Comparing the design of the mentioned retriever models, we find ANCE to be superior in effectiveness and robustness for several reasons:\n\u2022 Dynamic Negative Sampling: ANCE uses dynamic negative sampling, exposing the model to harder negatives during training. This enhances its ability to distinguish similar queries and documents, making it less susceptible to small perturbations and adversarial attacks. In contrast, BERT and Contriever lack this dynamic aspect.\n\u2022 Approximate Nearest Neighbor Search: ANCE employs approximate nearest neighbor (ANN) search techniques (e.g., Faiss [21]), allowing effective retrieval even with altered queries. This resilience to minor changes significantly contributes to its robustness against adversarial perturbations, unlike BERT and Contriever.\nUnderstanding how models withstand adversarial attacks aids in making informed deployment choices, safeguarding the integrity and accuracy of LLM outputs. A future direction could be applying the above-mentioned designs to simple naive models and measuring the enhancement of robustness and reliability.\nIn conclusion, despite current limitations, we recognize the importance of robustness in retrieval models and aim to address this in future research to improve the safety and effectiveness of LLM applications."}, {"title": "5. Appendix", "content": "Table 5, Table 6, Table 6"}, {"title": "6. Work Division", "content": "Please refer to Table 4."}]}