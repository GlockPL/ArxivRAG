{"title": "CURVATURE DIVERSITY-DRIVEN DEFORMATION AND\nDOMAIN ALIGNMENT FOR POINT CLOUD", "authors": ["Mengxi Wu", "Mohammad Rostami", "Hao Huang", "Yi Fang"], "abstract": "Unsupervised Domain Adaptation (UDA) is crucial for reducing the need for\nextensive manual data annotation when training deep networks on point cloud\ndata. A significant challenge of UDA lies in effectively bridging the domain\ngap. To tackle this challenge, we propose Curvature Diversity-Driven Nuclear-\nNorm Wasserstein Domain Alignment (CDND). Our approach first introduces a\nCurvature Diversity-driven Deformation Reconstruction (CurvRec) task, which\neffectively mitigates the gap between the source and target domains by enabling\nthe model to extract salient features from semantically rich regions of a given\npoint cloud. We then propose Deformation-based Nuclear-norm Wasserstein\nDiscrepancy (D-NWD), which applies the Nuclear-norm Wasserstein Discrepancy\nto both deformed and original data samples to align the source and target domains.\nFurthermore, we contribute a theoretical justification for the effectiveness of D-\nNWD in distribution alignment and demonstrate that it is generic enough to be\napplied to any deformations. To validate our method, we conduct extensive exper-\niments on two public domain adaptation datasets for point cloud classification and\nsegmentation tasks. Empirical experiment results show that our CDND achieves\nstate-of-the-art performance by a noticeable margin over existing approaches.", "sections": [{"title": "INTRODUCTION", "content": "Adopting deep neural network on point cloud representation learning has led to significant success in\nvarious applications, including robotics Maturana & Scherer (2015); Duan et al. (2021), autonomous\nvehicles Mahjourian et al. (2018); Cui et al. (2021), and scene understanding Zheng et al. (2013);\nZhu et al. (2017). Most works rely on supervised learning Su et al. (2015); Wu et al. (2015); Qi et al.\n(2017) and assume that training and testing data are sampled from the same distribution. However,\nacquiring labels for training data is both time-consuming and labor-intensive. Moreover, testing data\nmay be from a different distribution w.r.t. training data in real-world scenarios, known as 'domain\ngap'. Unsupervised domain adaptation (UDA) offers a solution to tackle these issues by utilizing\nknowledge transfer from source domains with annotated data to target domains with only unlabeled\ndata Wilson & Cook (2020); Li et al. (2020); Rostami et al. (2023). UDA is different from zero-\nshot learning (ZSL) Cheraghian et al. (2020; 2022); Rostami et al. (2022) in which predictions on\nunseen classes are done by leveraging auxiliary information without any training examples from\nthose classes. Although UDA is well studied for 2D planner data, e.g., images, UDA for 3D point\nclouds has not been explored extensively due to challenges such as irregular, unstructured, and un-\nordered nature of 3D point cloud data. Such irregularities exacerbate geometric variations between\nthe source and target domains compared to the 2D planner data and make extending existing solu-\ntions nontrivial."}, {"title": "RELATED WORKS", "content": "Domain Adaptation on Point Clouds. Despite extensive works on UDA for 2D planner image\ndata Ganin & Lempitsky (2015); Mansour et al. (2008); Jian & Rostami (2023), only a limited num-\nber of studies Qin et al. (2019); Achituve et al. (2021); Shen et al. (2022); Zou et al. (2021); Wu\n& Rostami (2024) address UDA in point clouds and non-planner data spaces as extending meth-\nods for 2D data for point clouds in non-trivial. Qin et al. Qin et al. (2019) introduce PointDAN\nthat integrates both local and global domain alignment strategies. They also provide the PointDA\nbenchmark for point cloud classification under the UDA setting. Achituve et al. Achituve et al.\n(2021) propose a domain alignment technique that involves reconstruction from deformation and\nincorporates PointMixup Chen et al. (2020). They also introduce the PointSegDA benchmark for\npoint cloud segmentation under the UDA setting. Zou et al. Zou et al. (2021) utilize two geometry-\ninspired self-supervised classification tasks to learn domain-invariant feature. Shen et al. Shen et al.\n(2022) introduce a self-supervised method for learning geometry-aware implicit functions to han-\ndle domain-specific variations effectively. Our work differs from these approaches by proposing\nmore sophisticated self-supervised learning tasks and a generic theoretical framework, leading to\nstate-of-the-art performance.\nOptimal Transport for Domain Adaptation. The Wasserstein metric, known for encoding the nat-\nural geometry of probability measures within optimal transport theory, has been extensively studied\nfor its application in domain adaptation due to its nice properties Courty et al. (2016; 2017); Stan\n& Rostami (2024). Gautheron et al. Gautheron et al. (2019) propose Wasserstein Distance Guided\nRepresentation Learning to leverage the Wasserstein distance to enhance similarities between em-\nbedded features. Lee et al. (2019); Rostami (2021); Gabourie et al. (2019) propose to use the sliced\nWasserstein discrepancy instead of $L_1$ distance in Maximum Classifier Discrepancy Saito et al.\n(2018) to achieve a more geometrically meaningful intra-class divergence. Additionally, CGDM Du\net al. (2021) introduces cross-domain gradient discrepancy to further mitigate domain differences.\nDeepJ-DOT Damodaran et al. (2018) utilizes a coupling matrix to map source samples to the target\ndomain. Gautheron et al. Gautheron et al. (2019) propose a feature selection technique that ad-\ndresses the domain shifts problem. Moreover, Xu et al. Xu et al. (2020) develop reliable weighted\noptimal transport, which uses spatial prototypical information and intra-domain structure to evalu-\nate sample-level domain discrepancies, resulting in a better pairwise optimal transport plan. Finally,\nFatras et al. Fatras et al. (2021) present an unbalanced optimal transport method combined with a\nmini-batch strategy to efficiently learn from large-scale datasets. In this work, we developed our\nD-NWD based on another previous method, NWD Chen et al. (2022)."}, {"title": "PROPOSED METHOD", "content": "We begin by defining the unsupervised domain adaptation problem and then we provide an overview\nof our UDA approach, called Curvature Diversity-Driven Nuclear-Norm Wasserstein Domain Align-\nment (CDND), in Section 3.1. Next, we detail our main contributions: (1) the Curvature Diversity-\nbased Deformation Reconstruction method (CurvRec), as discussed in Section 3.2 and Section 3.3,\nand (2) the Deformation-based Nuclear-norm Wasserstein Discrepancy (D-NWD) in Section 3.4.\nFollowing in Section 4, we present our theoretical contribution of D-NWD."}, {"title": "PROBLEM FORMULATION", "content": "We consider a source domain with labeled samples and a target domain, differing from the source,\nwith unlabeled samples. Our goal is to develop a UDA model to accurately predict labels for the\ntarget domain using both the source labeled dataset and the target unlabeled dataset. Let $S$ represent\nthe source domain, where $X_i$ denotes the i-th batch of samples and $y_i$ their corresponding labels.\nSimilarly, let $T$ represent the target domain, where $X^t_i$ is the i-th batch of samples. The feature\nspace induced by $S$ and $T$ is denoted by $\\Omega$. In addition, we introduce deformed domains $S^d$\nand $T^d$, with their feature space $\\Omega_d$. We assume $\\Omega$ and $\\Omega_d$ to be disjoint and $\\Omega \\cup \\Omega_d \\subseteq \\mathbb{R}^n$. A point\ncloud from the source domain is denoted as $x_s \\in \\mathbb{R}^{n \\times 3}$ and from the target domain is $x_t \\in \\mathbb{R}^{n \\times 3}$,\nwhere $n$ is the number of points. The corresponding deformed point clouds are denoted by $x_s^d$ and\n$x_t^d$, respectively.\nThe pipeline of our CDND is presented in Figure 1. Our model first uses a feature extractor $E$ to\nobtain shape features from both source and target point clouds. To minimize domain gaps and en-\nsure domain-invariant features, we: (1) use a curvature diversity-driven deformation reconstruction\ntask using a reconstruction decoder $h_{SSL}$ and (2) employ the D-NWD to align domains through a\nclassifier $C$. The aligned features are then used for downstream tasks, i.e., cloud classification and\nsegmentation. The model is trained using source-labeled and target-unlabeled data."}, {"title": "CURVATURE DIVERSITY-DRIVEN DEFORMATION", "content": "To extract domain-invariant features shared by both source and target domains, Achituve et al. pro-\nposed deformation reconstruction Achituve et al. (2021). Specifically, there are three deforma-\ntion strategies introduced in Achituve et al. (2021) for deforming point clouds, i.e., volume-based,\nfeature-based, and sample-based, according to the way of dividing point clouds into regions for\ndeformation.\nAlthough the strategies mentioned above use different techniques to select regions for deformation,\nthey all randomly divide a point cloud into regions and uniformly select regions based on their\nspatial locations or arrangements. However, this approach may not be optimal as regions within a\npoint cloud vary in their semantic richness, i.e., some regions contain more semantic information.\nThese semantically rich regions are crucial for tasks such as classification, as they have more distin-\nguishable characteristics. For instance, to differentiate a point cloud of a plant from that of a lamp,\nfocusing on the leaves and flowers which have richer semantic information would be more\neffective than focusing on the flower pot, which is similar to the base of a lamp. Thus, deforming\nregions with richer semantic information causes the point cloud to lose semantic meaning, making\nit difficult for a classifier to classify it. To encourage the feature extractor to prioritize regions with\nrich information, we propose deforming regions that are less semantically rich. This strategy helps\nto learn to extract features from the most informative or salient regions of a point cloud.\nTo evaluate the richness of semantics, we propose using curvature diversity as a measurement. Fol-\nlowing Zou et al. Zou et al. (2021), we compute point cloud curvature using PCA Abdi & Williams\n(2010). Specifically, we first select a small neighborhood around each point and apply PCA to\ndetermine the principal directions and their eigenvalues. The curvature is then calculated as:\n$C = \\frac{\\lambda_{min}}{ \\sum_{i=1}^{K} |\\lambda_i|}$                                                                                                                                                                                 \\tag{1}\nwhere $\\lambda_{min}$ is the smallest eigenvalue of the matrix, and $K$ is the number of eigenvalues. Larger\nvariation in curvature indicates a more intricate geometry and more significant shape changes within\na region. The fourth lamp sample in the bottom row of Figure 1 illustrates this property: regions with\nwarmer colors represent areas of higher curvature diversity. To measure the diversity or variation\nof curvature in a region, we propose to use entropy of curvature. Entropy effectively captures the\nvariability and complexity of the curvature, allowing us to quantify the richness of semantics within\na region. Formally, we use the following measure the curvature diversity:\n$\\bar{c}_i^{norm} = \\frac{c_i - c^{min}_R }{c^{max}_R - c^{min}_R + 1 \\times 10^{-10}}$ , $c^{min}_R = min {c_i}_i^{N_Ri}$, $c^{max}_R = max {c_i}_i^{N_Ri}$ \n$H(\\bar{c}^{norm}) = - \\sum_{i=1}^{N_{R_i}} \\bar{c}_i^{norm}  log(\\bar{c}_i^{norm} + 1 \\times 10^{-10})$\n \\tag{2}\nwhere, $c_i$ represents the curvatures of the i-th point in the j-th region of the point cloud which\ncontains $N_{Ri}$ points in total. To standardize these values, we first calculate $c^{min}_R$ and $c^{max}_R$, which\nare the minimum and maximum values of all curvatures within a region, respectively. Using these\nvalues, we then normalize the curvature values to be in [0, 1], denoted as {$\\bar{c}_i^{norm}$}. Then, we\ncalculate the curvature diversity $H(\\bar{c}^{norm})$ by applying entropy.\nFor the curvature diversity-driven deformation, we adopt the following steps. First, we use Farthest\nPoint Sampling (FPS) Moenning & Dodgson (2003) to sample $k$ points as centers of $k$ regions.\nThen, for each center point, we use k-Nearest Neighbor (k-NN) to select $m$ nearest points, i.e., each\nregion is formed by a center point along with these $m$ nearest points. Next, we select the $N$ regions\nwith the smallest curvature diversity to deform. To deform these selected regions, we replace all the\npoints within these regions with new points. These new points are generated by sampling from a\nGaussian distribution, where the mean is set to the average position of all the original points in that\nregion, and the variance is set to 0.001. In Figure 1, $X_s^d$ and $X_t^d$ represent the deformed samples, and\nthe points shown in grayscale are those drawn from the Gaussian distribution."}, {"title": "DEFORMATION RECONSTRUCTION LOSS", "content": "After deforming the selected regions, we obtain a deformed point cloud $x^d$ from the original $x$.\nThe deformed input $x^d$ is processed by the feature extractor $E$ to generate $E(x^d)$, which is then\npassed to a reconstruction decoder $h_{SSL}$ to reconstruct $x$. The self-supervised loss $L_{SSL}$ minimizes\nthe distance between $h_{SSL}(E(x^d))$ and $x$. We use the Chamfer distance in $L_{SSL}$, focusing on the\noriginal points in $x$ within the deformed region $R$ and their reconstructions from $x^d$. Formally, let\n$I \\in {1, 2, ..., m}$ represent the indices of the points in $x \\cap R$, and we define $L_{SSL}$ as:\n$L_{SSL} = \\sum_{(x^d,x)\\in S\\cup T} D (\\{x_i\\}_{i\\in I}, \\{h_{SSL}(E(x^d))_i\\}_{i\\in I}),$ \\tag{3}\nwhere $x_i$ is the i-th point in the point cloud $x$ and the Chamfer distance $D$ is defined as :\n$D(R_1, R_2) = \\sum_{a \\in R_1} \\min_{b \\in R_2} ||a-b||_2 + \\sum_{b \\in R_2} \\min_{a \\in R_1} ||b-a||_2$, \\tag{4}\nwhere $D(R_1, R_2)$ measures the discrepancy between point cloud regions $R_1, R_2 \\subset \\mathbb{R}^3$. Note that\nwe reconstruct only the deformed regions to reduce computational resources and time."}, {"title": "DOMAIN ALIGNMENT VIA D-NWD", "content": "The curvature diversity-driven deformation reconstruction helps reduce the domain gap between the\nsource and target domains. To further complete classification or segmentation tasks in the presence\nof domain gap, we propose D-NWD align domains, as inspired by the Nuclear-norm Wasserstein\ndiscrepancy (NWD) Chen et al. (2022). A brief overview of NWD is provided in Appendix A. Our\nD-NWD objective is defined as:\n$W_N(V_{s \\cup s^d}, V_{t \\cup t^d}) = sup_{|||C|||*L \\le K} E_{f_s \\sim V_{s \\cup s^d}} [||C(f_s)||*] - E_{f_t \\sim V_{t \\cup t^d}} [||C(f_t)||*] $ \\tag{5}\nwhere $K$ is the Lipschitz constant. Here, $V_{s \\cup s^d}$ and $V_{t \\cup t^d}$ are probability measures defined over\n$\\Omega \\cup \\Omega_d$, for the features from samples in original and deformed source and target domains. We align\nthe probability measure of features from original and deformed samples in the source domain with\nthat of the target domain. Our motivation is that taking features from deformed samples into account\nwould provide a richer, more robust feature space, reduce overfitting, and increase the model's\nadaptability to variations inherent in real-world data. This differs from NWD, which aligns $V_s$ and\n$V_t$ defined over $\\Omega$, the probability measures for the features from samples in original source and\ntarget domains. Empirically, our objective in Eq. 5 be approximated by $L_{D-NWD}$:\n$L_{D-NWD} = \\frac{1}{N_s} \\sum_{i=1}^{N_s} ||C(f_i^s)||* - \\frac{1}{N_t} \\sum_{i=1}^{N_t} ||C(f_i^t)||*$ \\tag{6}\nwhere $C$ denotes the classifier, and $|\\cdot|_*$ represents the nuclear norm. $f_i^s \\sim V_{s \\cup s^d}$ represents the\nfeatures for the i-th source batch and $f_i^t \\sim V_{t \\cup t^d}$ represents the features for the i-th target batch.\nThe ratio between the original samples and deformed samples is 1:1. In practice, we obtain the\noriginal and deformed samples by first sampling from the original domain, and then generating the\ncorresponding deformed versions. The alignment is then performed through a min-max game as:\n$\\min_E \\max_C L_{D-NWD}$ \\tag{7}\nTo avoid alternating updates, we employ a Gradient Reverse Layer Ganin et al. (2016), following\nthe approach in Chen et al. (2022), to make the learned features discriminative and domain-agnostic."}, {"title": "OVERALL LOSS", "content": "In addition to deformation and domain alignment loss defined in Eq. 3 and Eq. 7, we use a cross-\nentropy loss $L_{CLS}$ on both original and deformed source domain samples for supervised training:\n$L_{CLS} = \\frac{1}{N_s} \\sum_{i=1}^{N_s} L_{CE}(C(f_i^s), y_i)$  \\tag{8}\nSince we have no access to the ground-truth labels for the target domain data, it is impossible to\nuse the supervised cross-entropy loss as in Eq. 8 on samples from $T$ and $T^d$. One straightforward"}, {"title": "THEORETICAL ANALYSIS", "content": "We provide a theoretical justification for our Deformed-based Nuclear-norm Wasserstein Discrep-\nancy (D-NWD). Following Ben-David et al. (2006) and Chen et al. (2022), we perform our anal-\nysis in a binary classification scenario, which can be easily adapted to multi-class classification\nthrough reduction techniques such as one-vs-all Rifkin & Klautau (2004) or one-vs-one Allwein\net al. (2000) approaches. Consider $\\{C: \\mathbb{R}^n \\rightarrow [0, 1]\\}$ as a set of source classifiers within the\nhypothesis space $H$. The risk or error of classifier $C$ on the original source domain is defined as\n$\\epsilon_S(C) = E_{f_s \\sim v_s}[|C(f_s) - y_s|]$, where $y_s$ is the label associated with the feature $f_s$. We then de-\nfines $\\epsilon_{S \\cup s^d}(C) = E_{f_s \\sim v_{s \\cup s^d}}[|C(f_s) - \\hat{y_s}|]$, where $\\hat{y_s}$ is the label associated with $f_s$. Similarly, we\ndefine $\\epsilon_t(C), \\epsilon_{t \\cup t^d}(C)$ as the risks on the target domain. The optimal joint hypothesis is defined\nas $C^* = arg \\min_C \\epsilon_{S \\cup s^d}(C) + \\epsilon_t(C)$ which minimizes the combined risk across $v_{s \\cup s^d}$ and $v_t$.\nOur Theorem 1 demonstrates that the expected target risk $\\epsilon_t(C)$ can be bounded by the D-NWD\non $v_{s \\cup s^d}$ and $V_{t \\cup t^d}, W_N(v_{s \\cup s^d}, V_{t \\cup t^d})$. Building on Theorem 1, we derive Theorem 2. Theorem\n2 establishes that $\\epsilon_t(C)$ can be bounded by D-NWD on empirical probability measures $\\hat{v}_{s \\cup s^d}$ and\n$\\hat{v}_{t \\cup t^d}, W_N(\\hat{v}_{s \\cup s^d}, \\hat{V}_{t \\cup t^d})$. We prove Lemma 1 and 4 to support our proof of Theorem 1 and 2.\nBackgrounds of 1-Wasserstein distance and NWD are in Appendix A. All proofs are included\nin the Appendix B."}, {"title": "EXPERIMENTS", "content": "We evaluate our method on the PointDA-10 Qin et al. (2019) dataset, a domain adaptation dataset\nfor point cloud classification, and on PointSegDA Achituve et al. (2021), a dataset for point cloud\nsegmentation. For the PointDA-10 dataset, we compare our approach against the recent state-of-the-\nart methods for point cloud domain adaptation, including DANN Ganin et al. (2016), PointDAN Qin\net al. (2019), RS Sauder & Sievers (2019), DefRec+PCM Achituve et al. (2021), GAST Zou\net al. (2021), and ImplicitPCDA Shen et al. (2022). Additionally, we incorporate Self-Paced\nSelf-Training (SPST) into GAST, ImplicitPCDA, and our method, as SPST is originally included\nin both GAST and ImplicitPCDA. For the PointSegDA dataset, we compare our method with\nRS, DefRec+PCM, GAST, ImplicitPCDA, and Adapt-SegMap Tsai et al. (2018). We exclude\nSPST for this dataset. The reason is in Appendix C. For both datasets, we also evaluate two upper\nbounds: Supervised-T, which involves training exclusively on labeled target samples, and Super-\nvised, which uses both labeled source and target samples. Additionally, we assess a lower bound,\nUnsupervised, which utilizes only labeled source samples."}, {"title": "DATASETS", "content": "PointDA-10 consists of three three domains: ShapeNet-10 Chang et al. (2015), ModelNet-10 Wu\net al. (2015), and ScanNet-10 Dai et al. (2017), each sharing ten distinct classes. PointSegDA\nconsists of four domains: ADOBE, FAUST, MIT, and SCAPE. These domains share eight distinct\nclasses of human body parts but vary in point distribution, pose, and scanned humans."}, {"title": "TRAINING SCHEME", "content": "Following the literature, we use DGCNN as the feature extractor Achituve et al. (2021) for fair com-\nparison. We train the model of each method three times using distinct random seeds for initialization\nand report the average accuracy and standard deviation. To ensure a fair comparison, we maintain\nthe same seed for data shuffling and use the Adam optimizer Kingma & Ba (2014) for optimization."}, {"title": "RESULTS", "content": "Results on PointDA. The results are presented in Table 1. We use S+ to represent the ScanNet\ndataset, M to represent ModelNet, and S to represent the ShapeNet dataset. The CDND model\nshows significant improvement over the other approaches on the PointDA-10 dataset with the high-\nest average accuracy of 70.3%, outperforming all other models. CDND delivers state-of-the-art\nperformance on five out of six tasks. It excels in tasks with a large domain gap, such as MS+, S+M,\nSS+, and S+S. In these tasks, one domain is a synthetic dataset and another domain is a real-world\ndataset. This shows its proficiency in handling complex transformations. Especially, CDND scores\n58.7% on MS+, outperforming the second-best method by approximately 6%. Additionally, CDND\nmaintains competitive accuracy in tasks with a small domain gap, such as SM and MS, with scores of\n84.1% and 76.2%, respectively. With SPST, the performance is further improved, as CDND+SPST\nachieves 73.3%, outperforming GAST+SPST by 4.4% and ImplicitPCDA+SPST by 12%. Note\nthat plain CDND also outperforms both GAST+SPST and ImplicitPCDA+SPST on average. The\nstrong performance of CDND across various tasks highlights its ability to adapt to diverse domain\nchallenges, making it a promising choice for point cloud classification in the UDA setting.\nResults on PointSegDA. The results are presented in Table 3 We use A to represent the ADOBE\ndataset, F to represent the FAUST dataset, M to represent the MIT dataset, and S to represent the\nSCAPE dataset. On the PointSegDA benchmark, CDND achieves the highest average score of 59.9,\nwhich surpasses the second-best method, RS, by a margin of 2.0%, which is significant in terms\nof mIoU on the segmentation task. Its superior performance is particularly evident in MA and SA\ntasks; in the MA task, CDND achieves a mIoU of 68.6, outperforming RS by 9%. Similarly, in\nthe SA task, CDND secures a mIoU of 77.5, which is around 7% higher than RS. These results\nshowcase its adaptability and learning capability. Additionally, in the FA task, CDND achieves a\nscore of 81.5, even slightly surpassing the supervised baseline. In other tasks, i.e., FM, AS, and SM\ntasks, CDND either matches or comes very close to the top-performing models, validating its status\nas a consistently high-performing model. The widespread dominance across various tasks on the\nPointSegDA benchmark further emphasizes CDND's effectiveness."}, {"title": "ABLATION STUDY", "content": "To demonstrate the effectiveness of each component of CDND, we conduct ablative studies on\nthe PointDA-10 dataset. There are several ways to evaluate curvature diversity. While stan-\ndard deviation is commonly used to evaluate the diversity of data points, we propose using en-\ntropy. We compare our entropy-based approach (CurvRec(En)) with a standard deviation-based\nmethod (CurvRec(S)). To validate our hypothesis that focusing on low curvature diversity re-\ngions can improve performance, we investigate the impact of deforming areas with both high\n(CurvRec(En)+High, CurvRec(S)+High) and low (CurvRec(En)+Low, CurvRec(S)+Low) diversity.\nEffectiveness of CurvRec. From Table 2, when comparing CurvRec(En) variants with CurvRec(S)\nvariants, CurvRec(En) demonstrates better performance, with a more distinct difference between\nCurvRec(En)-High and CurvRec(En)-Low. This suggests that entropy is a superior method for\nevaluating curvature diversity in regions. In contrast, there is a much less distinction between\nCurvRec(S)-High and CurvRec(S)-Low. Notably, all CurvRec measures outperform DefRec, re-\ngardless of whether the focus is on high or low curvature diversity. We hypothesize that deform-\ning regions with high curvature diversity can help the model become more robust to changes in\nthese areas, potentially improving performance. However, all \"Low\" outperforms \"High\". This"}, {"title": "ANALYTIC EXPERIMENTS", "content": "We conduct analytical experiments to gain deeper insights into the effectiveness of our approach.\nSpecifically, we assess how CDND impacts the distribution of the target domain in the classifier's\noutput space for the challenging ModelNet to ScanNet task (MS+); ModelNet is a synthetic dataset,\nwhile ScanNet is a real-world dataset, making the domain shift between them particularly chal-\nlenging. We used UMAP to visualize and compare data representations of validation data from the\nsource domain, and test data from the target domain both before and after applying CDND. Figure 2\nshows each point as a data representation in the classifier's output space before softmax activation,\nwith different colors denoting different classes. The middle plot in Figure 2 illustrates that, prior to\nadaptation, the classifier struggles with the target domain data, as points from different classes are\nheavily intermixed. However, after applying CDND, the class boundaries become more distinct, and\nthe distribution of target domain representations aligns well with that of the source domain. This\nimprovement is visible in the left and right plots of Figure 2, where the arrangement of points shows"}, {"title": "CONCLUSION", "content": "We introduced a novel unsupervised domain adaptation approach specifically for point cloud data,\nwhich presents unique challenges due to its intricate geometric structures. Our method, CDND, in-\ntegrates curvature diversity-based deformation with Deformation-based Nuclear-norm Wasserstein\ndiscrepancy (D-NWD) to mitigate target domain performance degradation. Our theoretical analy-\nsis of D-NWD shows it minimizes an upper bound for target domain model error, thus enhancing\nperformance. Additionally, the theoretical analysis shows that D-NWD can be applied to any de-\nformation method. Experimental results indicate that our approach is highly effective, surpassing\nstate-of-the-art methods on two major benchmarks. The success of our method in handling large do-\nmain differences highlights its adaptability and robustness. Ablation studies confirm that both core\ncomponents of CDND are essential for achieving optimal performance. Future work could explore\nextending our approach to scenarios where both source domain data are not directly accessible due\nto privacy or when the two domains share a subset of their classes."}, {"title": "A REVIEW OF THE 1-WASSERSTEIN DISTANCE AND NWD", "content": "We begin the review of Nuclear-norm Wasserstein by introducing 1-Wasserstein distance:\nDefinition 1 (1-Wasserstein distance). Adler & Lunz (2018) 1-Wasserstein distance quantifies the\nminimal cost of transporting mass between two probability measures that are defined on the same\nsample space. Let $\\mu$ and $\\nu$ be two probability measures over $\\Omega$. Let $(\\Omega", "as": "n$W_1(\\mu", "meaning": "n$\\int_{\\Omega"}, "gamma(x, y) dy dx = \\mu(A)$ and $\\int_{\\Omega} \\gamma(x, y) dx dy = \\nu(A), \\forall A \\in \\mathcal{F}$\nKantorovich-Rubinstein Duality shows that $W_1(\\mu, \\nu)$ can be rewritten as:\n$W_1(\\mu, \\nu) = sup_{\\|h\\|_L < K} E_{x \\sim \\mu}[h(x)"], "Z$": "n$I_a = \\sum_{i=1}^{K} Z_{ii}, I_e = \\sum_{i \\neq j}^{K} Z_{ij}$\nIn the source domain, $I_a$ is large, and $I_e$ is relatively small because most samples are correctly\nclassified. Conversely, in the target domain, $I_a$ is small, and $I_e$ is relatively large due to the lack of\nsupervised training on the target domain. Hence, $I_a - I_e$ can"}