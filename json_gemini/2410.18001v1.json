{"title": "Benchmarking Foundation Models on Exceptional Cases: Dataset Creation and Validation", "authors": ["Suho Kang", "Jungyang Park", "Joonseo Ha", "SoMin Kim", "JinHyeong Kim", "Subeen Park", "Kyungwoo Song"], "abstract": "Foundation models (FMs) have achieved significant success across various tasks, leading to research on benchmarks for reasoning abilities. However, there is a lack of studies on FMs performance in exceptional scenarios, which we define as out-of-distribution (OOD) reasoning tasks. This paper is the first to address these cases, developing a novel dataset for evaluation of FMs across multiple modalities, including graphic novels, calligraphy, news articles, and lyrics. It includes tasks for instance classification, character recognition, token prediction, and text generation. The paper also proposes prompt engineering techniques like Chain-of-Thought (CoT) and CoT+Few-Shot to enhance performance. Validation of FMs using various methods revealed improvements. The code repository is accessible at: https://github.com/MLAI-Yonsei/ExceptionalBenchmark", "sections": [{"title": "Introduction", "content": "Recent studies (Sap et al., 2019; Speer et al., 2017; Talmor et al., 2018) have focused on assessing the commonsense reasoning capabilities of foundation models (FMs) (Achiam et al., 2023; Team et al., 2023). As a result, current FMs have achieved remarkable progress, demonstrating high performance across various tasks (Cherian et al., 2023; Wang et al., 2018, 2019). However, there are situations where FMs struggle to determine reasoning. Despite the development of various datasets (Yue et al., 2023; Zellers et al., 2019; Lin et al., 2024), There is a need for more diverse datasets that encompass less common scenarios. We characterize these scenarios as exceptional cases, referring to situations that contravene commonsense knowledge (Sap et al., 2019; Speer et al., 2017). Consequently, We define an exceptional case in a reasoning task as one that is out-of-distribution (OOD). In essence, the joint probability distribution of Exceptional Cases ($Pte(x, y)$) differs from the joint probability distribution ($Ptr(x, y)$) of the training dataset that Foundation Models (FMs) have learned. This can be expressed as follows:\n\n$Ptr(x, y) \u2260 Pte(x, y)$\n\nThis discrepancy arises from differences in one or more of the following distributions: $Ptr(x) \u2260 Pte(x)$, $Ptr(y) \u2260 Pte(y)$, $Ptr(y|x) \u2260 Pte(y|x)$ (Yang et al., 2024a). The datasets can be classified accordingly.\n\n$Ptr(x) \u2260 Pte(x)$ (Graphic Novels, Calligraphy)\n\nThe graphic novel contains strong cartoonish storylines that FMs have rarely encountered before. Additionally, calligraphy characters are artistically rendered, deviating from the standard forms that FMs seldom encounter in their training datasets.\n\n$Ptr(y) \u2260 Pte(y)$ (Lyrics)\n\nThe task involving lyrics evaluates whether FMs can accurately complete masked segments. Those that BERT (Devlin et al., 2018) failed to predict are designated as exceptional cases, representing scenarios FMs rarely encounter.\n\n$Ptr(y|x) \u2260 Pte(y|x)$ (Onion, Not The Onion)\n\nIn the case of Onion's plausible fake news and Not the Onion's real news that seem fake, the classification accuracy is lower because they have a different nature from the News that FMs have learned."}, {"title": "Experiments and Results", "content": "We designed experiments using four different datasets as shown in Figure 1. That feature various characters with multi types of tasks such as instance recognition, text generation, token prediction, and character recognition. In the experiments for all four datasets, we conducted all experimental tasks using GPT-40, Gemini-1.5-pro (Achiam et al., 2023; Team et al., 2023). Also, we employed three prompt styles-Zero-Shot (Kojima et al., 2022), Chain of Thought (CoT) (Wei et al., 2022), and CoT+Few-Shot (Brown et al., 2020)\u2014to investigate how the accuracy of responses varies. The API temperature setting is regulated to 0 in GPT-40, 0.01 in Gemini-1.5-pro to ensure consistent results.\nExperiments: The Graphic Novels feature a random shuffle task where four input images are shuffled by code before being presented to the FMs as prompts. The FMs are then required to determine the correct order of the images. The Calligraphy features OCR tasks for transcribing Korean calligraphy. We initially planned to create an English Calligraphy dataset, but it is no longer considered an exceptional case since FMs have achieved high accuracy on it. For the WordArt (Shi et al., 2023), an English calligraphy dataset, GPT-4's accuracy is 60.20%, but it increases to 77.61% when evaluated on GPT-40. The Onion, Not The Onion task comprises a binary classification task, where '0' corresponds to fake news and '1' to real news. The Lyrics dataset includes an infilling task, where the model predicts tokens for masked parts that BERT has identified as exceptional cases. Additionally, it features two more tasks: genre detection and song description generation.\nResults: In the task involving graphic novels, both baseline models demonstrated poor performance across all prompt styles, as shown in Table 1. We analyzed the factors behind these poor results, suspecting that image style might hinder the FMs' reasoning. To test this, we prompted the models with a single image. The FMs gave detailed descriptions, identifying characters, actions, and hypothesizing thoughts. We then evaluated their accuracy with daily life narratives using everyday scenario images (Huang et al., 2016), and the FMs responded well, showing adequate reasoning about storylines.\n\nIn the Calligraphy OCR task, although the results were poor, FMs showed a tendency to use context for reasoning, suggesting that they were leveraging the relationships between words and characters. This tendency increased progressively across Zero-Shot, CoT, and CoT+Few-Shot approaches. However, despite this promising approach, it was ultimately unsuccessful, as performance declined when evaluated at the character-level, word-level, and overall meaning as shown in Table 2.\n\nOverall, the Onion, Not The Onion task showed strong results, but we observed that accuracy tended to decrease with shorter article lengths as shown Table 3. This suggests that FMs struggled to fully grasp the content of the news, likely due to its nuanced nature, often misclassifying shorter real articles as fake due to the common link between short length and fake news.\n\nIn the infilling task, the FMs exhibited poor performance. It is evident that the FMs struggle to predict the masked portions of lyrics classified as exceptional cases by BERT. Additionally, within the Korean dataset, we observe a significant performance degradation in Gemini-1.5-Pro compared to GPT-40. In the English dataset, FMs refused to respond to songs released before the cut-off date, so the evaluation focused on music released after the cut-off date."}, {"title": "Limitation", "content": "This paper pioneers research into exceptional cases, which we define as out-of-distribution (OOD) scenarios in reasoning tasks. It aims to explore how FMs, recognized for their high performance across various domains, can address situations they typically struggle with, thereby advancing towards human-like reasoning. To this end, the study develops datasets encompassing diverse modalities, including image-only, text-only, and multimodal combinations. However, current research still lacks coverage of exceptional cases such as audio data (Yang et al., 2024b). Future studies should establish benchmarks for exceptional cases in these and other unaddressed domains, defining appropriate tasks for their evaluation. We have only addressed English and Korean languages, leaving third-country languages unexplored and providing opportunities for further expansion. We utilized FMs ensure precise grammar and word usage."}, {"title": "Graphic Novels", "content": "We utilized graphic novels, which are rich in content and often depict exceptional cases, to test the FMs' understanding. The experiment involves short story graphic novels: four-panel graphic novels with shuffled sequences, where the task for the FMs is to rearrange the panels into the correct order. We selected 'Old Master Q Comics' (Wong, 1973-1989) for this purpose, as these graphic novels revolve around comedy and typically have short storylines. These present vividly exaggerated storylines that are seldom encountered by FMs.\nWe collected the graphic novels through web scraping and then segmented them panel by panel using automated Python scripts. We reviewed and excluded data entries that contained unevenly sized panels to maintain consistency in the dataset. This dataset allows us to evaluate the extent to which the FMs comprehend the storyline. To ensure an accurate assessment, we eliminate all clues that provide information about the storyline, including panel numbers and titles of the graphic novel as shown in Figure 2.\nThe API temperature setting is adjusted to 0.01 for Gemini-1.5-Pro and 0 for GPT-4 to ensure consistent results. To generate a concise answer, the model is instructed to output the response solely in the format [1,2,3,4], as shown in the blue text in Figure 3 ('Prompt'). We set the ground truth order as [1,3,2,4] to automate the task, given that the input images are shuffled, as shown in (e) in Figure 3 ('In the code'). This predetermined order allows us to verify whether FMs produces the correct sequence. Additionally, we demonstrate how the prompts were designed for each style in E.1. Table 11. We design the random shuffle experiment as follow.\n1. Inform the FMs that the uploaded images represent parts of a story that have been shuffled and consist of four images as shown in the blue letters in Figure 3 ('Prompt'). Instruct it to analyze all the images and deduce the correct sequence.\n2. Upload four images in a shuffled order, with each image assigned an ID number as shown in (a), (b) in Figure 3 ('In the code').\n3. The uploaded images are indexed, and the FMs infers the correct order, subsequently outputting the images in the proper indexed sequence as shown in (c) in Figure 3 ('In the code').\n4. Using code, the indexed sequence is transformed into a sequence of image ID numbers to obtain the image order predicted by the FMs as shown in (d) in Figure 3 ('In the code').\n5. Compare the predicted image order with the ground truth order to determine accuracy as shown in (e) in Figure 3 ('In the code')."}, {"title": "Task Result", "content": "We assessed the multimodal causal reasoning abilities of FMs through a Random Shuffle task. We hypothesize that if FMs can comprehend the storylines through causal reasoning, it is likely to be able to infer the correct sequence of panels when presented with a randomly shuffled input. Based on this hypothesis, we designed the random shuffle task as shown in Figure 4. The highest performance was observed in the CoT+Few-Shot condition, followed by CoT and then Zero-Shot. Interestingly, the Zero-Shot performance exceeded expectations, displaying an accuracy that was not markedly lower than the other prompting styles. During the CoT style prompt experiments, we conducted various tests ranging from the very simple 'Let's think step by step' to more detailed descriptions of the reasoning sequence as shown in Table 5. Interestingly, the simplest 'Let's think step by step' prompt yielded the best performance. There was some variation depending on whether 'Let's think step by step' was prompted before or after the task images. In the case of CoT+Few-Shot, the number of Few-Shot examples impacted performance; with only one example, there was no difference compared to CoT, but increasing the examples to three resulted in a noticeable performance improvement.\nWhen the inferred order is completely correct: FMs occasionally makes mistakes in scene descriptions, even when it derives correct answers. For example, in Figure 5, GPT-40 describes a man as 'kneeling and petting the dog, coaxing it out of the doghouse,' whereas the actual scene is 'squatting in front of the doghouse, putting a leash on the dog.'\nWhen the inferred order is completely incorrect: FMs sometimes misidentify objects or misunderstand emotions. For instance, GPT-40 describes a man pulling a tiger's tail instead of removing an arrow from its paw, refer to image 2 of Figure 6."}, {"title": "Calligraphy", "content": "We preprocessed the dataset according to three rules. First, we deleted images if their resolution was too low or if they contained too many letters that even a human could not recognize. We set the threshold at 35 characters, as shown in Figure 7, where 35 is an irregularly large number in the dataset. We observed that images with more than 35 characters are visually challenging for humans to recognize, so we excluded such images from evaluation. Second, we separated overlapping calligraphy in an image by applying bounding boxes provided by the OCR API. Third, we cropped out typographic elements such as signs and watermarks that were deemed irrelevant to the calligraphy. An example of the preprocessed Korean calligraphy is shown in Figure 8.\nThe API temperature setting is adjusted to 0.01 for Gemini-1.5-Pro and 0 for GPT-4 to ensure consistent results. Before word-level evaluation, we removed punctuation and special symbols from FM predictions and replaced '\\n' with '' due to ambiguous line breaks in the calligraphy. We used Word-level Accuracy, CER, and WER, which are representative OCR metrics."}, {"title": "Task Result", "content": "The artistic nature of calligraphy sometimes leads to unconventional representations in the dataset, such as abbreviating 'spring day' to 'spring d.' In these cases, FMs tend to process 'd' as a separate element rather than part of the word, recognizing only 'spring.' This tendency was more pronounced in the CoT and CoT+Few-Shot prompts compared to Zero-Shot. In the Zero-Shot scenario, the OCR task tends to prioritize the visual recognition of individual words over the holistic meaning conveyed by the calligraphy, resulting in a higher frequency of typographical errors. Conversely, the CoT and CoT+Few-Shot approaches first interpret the overall meaning and then perform OCR based on contextually relevant words. Consequently, even when the output deviates from the ground truth, it tends to generate semantically similar words or words that are more contextually fitting than the ground truth. As illustrated in Figure 9, the first calligraphy example signifies 'pray,' with the ground truth being '\uae30 \ub3c4.' In the Zero-Shot scenario, GPT-4o recognizes it as '\uae30\ub4dc,' which bears a close visual resemblance but lacks semantic meaning. The CoT approach interprets it as '\uae30\ub2e4,' which, although not aligning with the ground truth, at least carries the meaning 'to crawl.' Notably, the CoT+Few-Shot approach accurately identifies it as '\uae30\ub3c4,' precisely matching the ground truth."}, {"title": "Onion, Not The Onion", "content": "We performed web scraping on The Onion website and Reddit's Not The Onion section. Following data collection, we implemented an additional filtering process using Python scripts to enhance the dataset's sophistication. Specifically, we automated the removal of instances where no content was collected, where content was duplicated, and where advertisements were included. During preprocessing, we encountered valid data with varying lengths, both long and short, that were indeed written by humans. These instances represent qualitative news articles, so we chose not to remove them to preserve the dataset's integrity. As a result, the mean and median text lengths are 2243 and 1433, respectively, leading to a left-skewed distribution. A histogram illustrating text lengths and category-specific statistics is presented in Figure 10. Through this process, we ensured that only the title and content of the original news articles influenced the FMs' judgment during fake news detection. This approach provided a reliable dataset, allowing us to evaluate the impact of textual data alone in fake news detection research.\nRecent studies have demonstrated that proper prompting can enhance the performance of FMs (Kojima et al., 2022). In this study, The default prompt simply asked the model to distinguish between fake news and real news. In contrast, the CoT prompts instructed the model to go through a step-by-step process of thinking to determine fake news (Wei et al., 2022). In this methodology, the model is instructed to take specific thought steps. Finally, we measured the performance of the model for the Few-shot and CoT prompts by providing examples of fake news and real news, as well as illustrating the judgment process. Through these comparisons, we evaluated the impact of various prompting methods on the model's ability to recognize fake news. The detailed prompts are provided in Table 13. By distinguishing between fake news and real news, we contribute to preventing social disruption and maintaining the credibility of information."}, {"title": "Task Result", "content": "Overall, FMs exhibit high performance on Onion, Not The Onion dataset as shown in Table 6, but we observed a reduction in performance with relatively short articles. As shown in Table 3, accuracy differences based on article length reveal that accuracy generally improves as article length increases. In contrast, the Onion group, predominantly consisting of fake news articles, typically features shorter articles and maintains consistently high accuracy across the dataset. This pattern suggests that FMs may have a tendency to classify shorter articles as fake news, highlighting the greater challenge posed by Not The Onion in fake news classification. Furthermore, we delve deeper into the rationale behind FMs's decision-making process, particularly when encountering relatively short articles, to better understand the circumstances under which FMs arrives at incorrect conclusions and whether it follows appropriate steps in such cases. In this approach, we observe that FMs generally takes appropriate steps, many of which are plausible. However, it is notable that FMs encounters difficulties with exceptional cases, as highlighted in Figure 11(marked in red). The article depicted in this figure includes several extraordinary claims, such as \"Adidas urgently recalled the German national team jersey featuring the number 44 due to its resemblance to symbols used by the German SS division\". To verify these claims, GPT-4o undergoes a validation process spanning from the second to the fourth step. Despite employing a search function in the fourth step, it fails to accurately determine the veracity of the article. Overall, to identify fake news, GPT-40 needs accurate causal reasoning to classify instances within an article. This makes the Onion, Not the Onion dataset a splendid benchmark for verifying their reasoning capabilities."}, {"title": "Lyrics", "content": "Although lyrics often contain poetic licenses and uncommon expressions such as metaphors, song lyrics still allow for meaningful inference as one of the main literary genres. To evaluate the robustness of reasoning capabilities in FMs when dealing with exceptional data like lyrics, we constructed a dataset using song lyrics. We assess FMs' comprehension of song lyrics through three tasks: genre detection, song description generation, and infilling as shown in Figure 12. For the infilling task, we used a pre-trained BERT model to anticipate the masked parts and removed non-exceptional data. Entries with BERT scores exceeding a 0.9 threshold were excluded, as high semantic similarity indicated non-exceptional content. When collecting the dataset, we divided it into two parts: 'yearly' and 'weekly.' The yearly dataset comprises data from before the FMs cut-off date (before the end of 2023), while the weekly dataset includes data from after the cut-off date (after the end of 2023). For the English dataset, after collecting the title and artist of each song, we removed duplicate entries-only removing a song if both the title and artist were identical, as different songs can share the same title. We then generated links to the Genius site to obtain the lyrics and descriptions of the songs. This process involved removing strings following 'featuring' and modifying characters such as brackets and Latin alphabets. If it was impossible to retrieve any of the descriptions, genre, or lyrics due to link generation errors or unavailability on the site, we excluded the song. Additionally, songs with non-English lyrics were also removed. To ensure that the weekly dataset contained only data that the FMs had not previously encountered, any song appearing in both the weekly and yearly data was excluded from the weekly dataset. For the genre detection task in English, we streamlined the genre list by removing infrequent genres. After consolidating all genre lists, we excluded genres with fewer than 10 occurrences, resulting in a final list of 58 unique genres and a dataset of 1,811 songs. A similar process was applied to both the English and Korean datasets. However, for the Korean dataset, non-Korean lyrics were not removed due to their high frequency, and genre cleaning was not performed because the dataset contained fewer genre categories. Notably, no songs were excluded during the crawling of lyrics, descriptions, or genres in the Korean dataset, as all song information was sourced from Melon, unlike the English dataset, which compiled data from multiple sites. The specific number of remaining data at each step is summarized in Table 7."}, {"title": "Task Result", "content": "In 2.Experiments and Results, we discussed the infilling task. Here, we focus on the genre classification and song description generation tasks.\nGenre Classification: In the genre classification task, the difference in the number of unique genres between the English and Korean datasets influenced the results: 11 genres in Korean and 58 in English. This made the task more challenging for the English dataset, leading to FMs struggling more with the English data than the Korean data, as shown in Table 9.\n\nDescription Generation: In the description generation task, the overall scores are poor, indicating that FMs struggle to accurately understand the meaning of song lyrics as shown in Table 10. As illustrated in Figure 13, the song discusses 'enduring difficult times with loved ones,' while GPT-40 describes it as 'dealing with a problematic relationship and addictive emotions.'"}, {"title": "Graphic Novels", "content": "Table 11: The description of each prompt style is provided. We assigned a response format to FMs twice because, in Zero-Shot, the variation in responses is too broad, causing FMs to occasionally break the response format rule. In CoT+Zero-Shot, we utilized the simplest CoT style because it achieved the best score compared to the more detailed CoT version (Table 9.). In CoT+Few-Shot, we used three different examples. The performance was insufficient when using only one or two examples."}, {"title": "Calligraphy", "content": "Table 12: Korean Calligraphy Prompt: For the Cot+Few shot prompt, We utilized two examples but only one example is listed in the paper because it was too long to attach. The full prompt can be seen in GitHub."}, {"title": "Onion Not The Onion", "content": "Table 13: We provided examples of prompts used to detect fake news, focusing on the implementation of COT reasoning. We presented a structured approach that outlines the steps a FMs considers when analyzing and concluding whether a news story is fake or real. Lastly, this method involves a few-shot learning technique where examples of fake news and real news are given alongside rationales."}, {"title": "Lyrics", "content": "Table 14: Prompt for English genre classification task"}, {"title": "Korean Genre Classification", "content": "Table 15: Prompt for Korean genre classification task"}, {"title": "English Song Description Generation", "content": "Table 16: Prompt for English song description generation task"}, {"title": "English Song Infilling", "content": "Table 17: Prompt for English lyrics infilling task. Examples in CoT+Few-shot are composed of data removed during BERT testing."}, {"title": "Korean Song Infilling task", "content": "Table 18: Prompt for Korean lyrics infilling task. Examples in CoT+Few-shot are composed of data removed during BERT testing."}]}