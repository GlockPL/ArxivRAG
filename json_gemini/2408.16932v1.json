{"title": "Event Extraction for Portuguese:\nA QA-driven Approach using ACE-2005", "authors": ["Lu\u00eds Filipe Cunha", "Ricardo Campos", "Al\u00edpio Jorge"], "abstract": "Event extraction is an Information Retrieval task that com-\nmonly consists of identifying the central word for the event (trigger)\nand the event's arguments. This task has been extensively studied for\nEnglish but lags behind for Portuguese, partly due to the lack of task-\nspecific annotated corpora. This paper proposes a framework in which\ntwo separated BERT-based models were fine-tuned to identify and clas-\nsify events in Portuguese documents. We decompose this task into two\nsub-tasks. Firstly, we use a token classification model to detect event\ntriggers. To extract event arguments, we train a Question Answering\nmodel that queries the triggers about their corresponding event argu-\nment roles. Given the lack of event annotated corpora in Portuguese, we\ntranslated the original version of the ACE-2005 dataset (a reference in\nthe field) into Portuguese, producing a new corpus for Portuguese event\nextraction. To accomplish this, we developed an automatic translation\npipeline. Our framework obtains F1 marks of 64.4 for trigger classifica-\ntion and 46.7 for argument classification setting, thus a new state of the\nart reference for these tasks in Portuguese.", "sections": [{"title": "Introduction", "content": "Over the years, event extraction has been extensively studied and found to be\na difficult information extraction task [17]. It aims to extract structured data\nregarding \"something that happens\" in a text, often understood as a specific oc-\ncurrence involving one or more participants. According to the Automatic Con-\ntent Extraction (ACE) 2005 annotation guidelines [1], this involves an event\nmention, trigger, type, argument and corresponding role:\nEvent mention: a phrase or sentence in which an event occurs, including\none trigger and an arbitrary number of arguments.\nEvent trigger: the word that expresses an event occurrence."}, {"title": "", "content": "Event type: represents a high-level categorization of events based on their\ngeneral semantic meaning. It can be composed of sub-types that provide a\nmore specific categorization of events.\nEvent argument: an entity mention, temporal expression or value that\nserves as a participant or attribute with a specific role in an event mention.\nArgument role: indicates the semantic relationship of the argument within\nthe event, such as the agent that performs the action, the time or location\nof the event, etc.\nTypically, event mentions consist of an event trigger and their corresponding\nevent arguments. Consider the following sentence, which illustrates the process\nof automatically identifying and classifying the event triggers and their corre-\nsponding arguments found in the text.\n\u201cElvis Presley morreu de ataque card\u00edaco em 1977, Memphis, Tennessee.\u201d\n(Elvis Presley died of a heart attack in 1977, Memphis, Tennessee.)\nIn this example, the word \u201cmorreu\u201d (died) is an event trigger of type Life.Die\nand \"Elvis Presley\" is an event argument with role Victim.\nWhile several English event extraction systems already exist [2,25,36], they\nreveal poor portability to other languages due to dependencies on English an-\nnotated textual resources. In this paper, we aim to tackle this problem in the\ncontext of the Portuguese language. In particular, we aim to develop a method\nthat allows for the extraction of event mentions by leveraging the power of\nTransformers-based models [34]. To address this problem, we divided the event\nextraction task into two sub-tasks: Trigger extraction and Argument Extraction.\nWe approach trigger identification and classification as a Token Classifica-\ntion task. Then for the Argument extraction, we use a Question Answering\n(QA) model (inspired by Du et al. [9]) where we question the event trigger\nabout its corresponding event argument roles. To perform these tasks, we used\nBERTimbau [33], a BERT [6] model pre-trained on Portuguese textual data.\nWe fine-tuned this model with event annotations from a Portuguese translated\nversion of ACE-2005 [7], containing textual data annotated with event triggers\nand corresponding arguments. For the QA task, we also experimented with the\nSQUAD [30] dataset in order to train our model to perform extractive QA.\nSince ACE-2005 was not available in Portuguese, and the Portuguese anno-\ntated corpora we found [10,4] did not contain explicit annotations for both event\ntriggers and arguments, we decided to automatically translate the ACE-2005 cor-\npus from English to Portuguese. For this purpose, we developed a translation\npipeline that enabled us to automate the translation and alignment tasks. This\ntranslated dataset is an important contribution to this current work.\nThe main contributions of this work are listed below:\nA pipeline for dataset translation and annotation alignment that allows the\ntranslation of annotated datasets to the Portuguese language.\nBased on this pipeline, we produced a new dataset by translating ACE 2005\nfor Portuguese, which is already in the process of being accepted at the\nLinguistic Data Consortium (LDC) repository."}, {"title": "", "content": "Using the Portuguese version of ACE-2005 corpus, we produced and de-\nployed event extraction models. These models correspond to a baseline for\nPortuguese event extraction.\nBased on the produced models, we developed and made available on Hug-\ngingface Hub, an event extraction framework for the Portuguese language."}, {"title": "Related Work", "content": "Event extraction is a fundamental task in Natural Language Processing (NLP)\nthat has been widely researched in recent years mainly for English and with\nless attention to other languages. Over the years, several approaches have been\nproposed to tackle this task, ranging from traditional rule-based methods to\nmore advanced machine learning and deep learning techniques [14,18].\nRecent works Du et al. [9] have demonstrated promising results using QA\nmodels in event extraction. The authors leveraged BERT [6] models fine-tuned\non the ACE-2005 corpus, to identify event triggers and corresponding arguments.\nHuang et al. [13] addressed event extraction by using Zero-Shot Learning\nto handle the scarcity of annotated data and the limited range of event types,\nwhich constrains the applicability of this task to certain domains. They drew\ninspiration from Pustejovsky et al. [26], who proposed that the semantics of an\nevent structure can be generalized to different event mentions. Following this\nidea, they used an event ontology that defines structures for each event type.\nThe authors used Abstract Meaning Representations (AMR) [3] to identify the\nevent triggers and argument candidates, constructing a structure for each event.\nAlthough event argument extraction has been primarily approached as a\nsentence-level task, it should be noted that in real-world scenarios, the arguments\nof an event can be dispersed across multiple sentences. To address this problem,\nLi et al. [19] propose a document-level approach for argument extraction. They\nuse a generative model (BART [16], T5 [28]) that is conditioned by the input\nsequence and unfilled templates created from an event ontology. The model is\nresponsible for filling those templates with a limited vocabulary in order to\nprevent it from \"hallucinating\".\nDespite the advances in this particular area, little has been done for the Por-\ntuguese language. Quaresma et al. [27] implemented an Event Extraction frame-\nwork for the Portuguese language, focused on the crime investigation domain.\nTheir framework relied on Semantic Role Labeling to extract event arguments\nand was validated on PropBank [10] corpus. The authors did not classify events\nby type and instead focused on the roles provided by the SRL schema, such as\nActor, Place, Time, and Object. Consequently, it would be difficult to compare\ntheir work with ours as ACE-2005 contains 33 different event types.\nThe same applies to the work developed by Costa and Branco [5]. They used\nfeature engineering combined with a decision tree trained on the TimeBankPT\ncorpus to extract events from Portuguese texts. However, the TimeBankPT cor-\npus event annotations only contain the following event types: REPORTING,\nOCCURRENCE, STATE, I_STATE, and I_ACTION. These annotations lack"}, {"title": "Methodology", "content": "This section will discuss the methodologies used to extract event triggers (Sec-\ntion 3.1) and event arguments (Section 3.2). To achieve this, we fine-tune a\nPortuguese BERT model [33] with a Portuguese-translated version of the ACE-\n2005 corpus (more details in Section 4.1). We fine-tined the model for token\nclassification and Question Answer tasks to extract event triggers and event\narguments, respectively."}, {"title": "Trigger Extraction", "content": "For the first task, we train a model that identifies and classifies event triggers.\nThe task is formulated as a token classification one. Given a sequence of N\u2081\ntokens W = [w1, w2, ..., wN\u2081] and a fixed set of event types (None type included)\nof length N2 A = [a1, a2, ..., aN2] our model assigns each token from W to their\ncorresponding label from A.\nTo perform this task we used BERTimbau [33], a BERT-based model that was\npre-trained on Portuguese texts. We fine-tuned this model on token classification\nusing the Portuguese-translated version of the ACE-2005 corpus. For that, we\nconverted the translated corpus to the IOB scheme [31] (Beginning, Inside and\nOutside) where a label is assigned to each token of the text sequence. We consider\nthe 9 event types and 33 event sub-types contained in ACE-2005 as labels for\ntoken classification task."}, {"title": "Argument Extraction", "content": "To extract arguments from the text, we used extractive QA, where we formulated\nquestions about the event to obtain the argument roles. These questions are\ninfluenced by each specific trigger word. Given a sentence S and a question Q,\nthis task aims to find the token span offsets where the corresponding answer a\nlies in S. In order to accomplish this objective, we fine-tuned the BERTimbau\nmodel in a QA task.\nThe input sequence format is described below:\n[CLS] question(Q) [SEP] sentence (S) [SEP]\nIn this format, we have the BERT classification token CLS and the SEP token\nthat separates the Sand Q input text sequences. The model outputs logits for\nthe start (astart) and end (aend) positions of the answer to each token of the input\nsequence. Before selecting the most probable answer offsets, several validations\nmust be performed to ensure that the answer span is valid. For instance, the\nanswer a should be fully contained within the sentence S and not part of the\nquestion Q; The start offset astart cannot be greater than the end offset aend,\netc. These validations are common procedures in the QA task."}, {"title": "Questions Generation", "content": "In the following, we outline how we generated the ac-\ntual questions for fine-tuning the model. We adopted a template-based approach,\nsimilar to Du et al. [9] and Lyu et al. [22]. Based on the event type, we can de-\ntermine the appropriate questions to ask in order to extract specific arguments.\nIn ACE-2005, each event type has a predetermined set of argument roles. We\ngenerated a question template for each event type by creating a set of questions\n(in Portuguese) based on the event type's corresponding roles. Each question of\nthe template expects to obtain as an answer the argument associated with each\nrole. We referred to the argument roles description provided in the ACE-2005\nannotation guidelines to generate these questions.\nTable 1 contains the questions used to extract the arguments of an event\ntype LIFE. DIE. Following the guidelines [1], we know that this event type can\nhave five different argument roles: Agent, Victim, Instrument, Time and Place.\nThen, to contextualize the question within the event mention, we concatenate\nit with the event trigger word, a method that has shown to improve the model\nresults [9]. We use the following question format: {question} + in {trigger}?.For instance, in our example of Section 1, we have an event of type LIFE.DIE.\nIn order to extract the argument role Time, the following question is generated:\nQuando ocorre a morte + em morreu?\n(When is the death + in died?)\nGiven this prompt, the model should output the answer span corresponding to\n\u201cem 1977\" (in 1997). The model uses the generated questions to extract each\nargument role from the text. Given an event mention and an event trigger, we\nreplicate this procedure for all the event arguments.\""}, {"title": "Impossible Answer", "content": "It's important for the model to be able to identify ques-\ntions that do not have a correct answer. In fact, not all event argument roles\ncan be found in every event mention. For instance, in the example provided,\nthe Agent argument role cannot be found in the text, which implies that the\nquestion \"Who is the assassin?\" should not have a correct answer.\nTo address this problem, we trained the model to predict the \"impossible\"\nanswer. During the training phase, we gave the model several questions without\nany answer. In these cases, the answer span offsets are assigned to the index 0 of"}, {"title": "Data", "content": "When it comes to the event extraction task, ACE-2005 is considered the stan-\ndard corpus in this field. While other corpora such as PropBank focus on the\nannotation of predicate-argument structure, ACE-2005 goes beyond this by pro-\nviding information on the overall event structure, including the event type and\nits corresponding argument roles. It is available in English, Chinese, and Arabic,\nhowever, there is no version of this dataset in Portuguese. We decided to take\nthe effort of translating the dataset, thus being able to work with this valuable\nresource for Portuguese. In this work, we used a translated version of ACE-2005\nin Portuguese, which contains 5 526 event mentions consisting of 5 526 event\ntriggers and 9 649 corresponding event arguments.\nWe have also used the well known SQuAD corpus [30] for training an extrac-\ntive question answering model. It consists of articles obtained from Wikipedia\nand a set of corresponding questions and answers about each article. In this\nwork, we used two versions of this dataset: SQUAD1.1, which contains 100 000\nquestions and respective answers; SQUAD2.0 [29], which contains 150 000 ques-\ntions and answers. The latter version contains all the questions from version 1.0,\nhowever, it contains 50 000 additional questions that have no correct answers.\nIn version 2.0, one must consider the impossible answer scenario when finding\nthe correct answer, creating a more challenging QA task. A Portuguese version\nof SQUAD 1.0 was already available from the Deep Learning Brasil Group5,\nhowever, we took the effort of translating version 2.0."}, {"title": "ACE-2005 Translation", "content": "In this section, we provide an overview of the ACE-2005 corpus translation pro-\ncess. Although we use automatic translation, translating an annotated dataset\ncan become particularly challenging when it comes to aligning its annotations.\nIn fact, mismatches can occur between the annotations and their occurrences in\nthe corresponding sentence. For instance, in sentence \"The troops land on the\nshore\", ACE-2005 states that the trigger \"land\" should be extracted. However,\nthe word \"land\" is translated to \"terra\" (land as a noun) in isolation and to\n\u201cdesembarcam\" (land as a verb) in context.\nIn the pre-processing of ACE-2005, each event annotation was assigned to its\ncorresponding text sentence. Then, we automatically translated each sentence,\nits corresponding triggers and arguments. These translations resulted in anno-\ntations' miss-alignments i.e., translated annotations that were not contained in"}, {"title": "SQUAD Translation", "content": "In this work, we used a version of SQUAD1.1 that had been previously trans-\nlated into Portuguese. To create a Portuguese version of the SQuAD2.0 dataset,\nwe automatically translated the additional 50,000 impossible questions. Since\nthese questions do not have a valid answer within the article's text, performing\nannotation alignments to this dataset was unnecessary."}, {"title": "Modeling", "content": "To validate our approach we use the translated ACE-2005 corpus for training\nand testing, as well as the translated SQUAD datasets for modeling question-\nanswering. We aim to assess the following: 1) the success of the trigger iden-\ntification and classification approach; 2) the success of the question answering\napproach for argument classification; 3) the impact of training the model to de-\ntect the absence of event arguments. Given the lack of other works in Portuguese,\nwe compare our work with the results obtained by state of the art approaches\nfor the same tasks on the original ACE-2005 corpus.\nOur first setup was to fine-tune the BERTimbau model [33] with the train\nsplit from our translated version of ACE-2005 (BERT-PT-ACE05). We used\nthe event trigger annotations to train the token classification model and the\nargument annotations to train the QA model.\nThen, for the argument extraction task, we used an existing Portuguese QA\nmodel [12] (pre-trained on SQuAD1.1 dataset ) and fine-tune it with the ACE-"}, {"title": "Results", "content": "Our models were validated on the test split of ACE-2005 containing 422 event\ntriggers and 892 arguments. We ensured a fairer comparison with state-of-the-\nart in English by using the same data splits and evaluation criteria as previous\nworks [9,17]. A correct identification and classification of an event trigger requires\nmatching its offsets and event type with the gold-standard. An event argument's\ncorrect identification and classification demands matching its offsets with the\nACE-2005 annotations and ensuring its semantic role is accurate. In other words,\nmatching between extracted elements and ground truth must be exact."}, {"title": "Discussion", "content": "Our models for Portuguese were trained using automatically translated data.\nHowever, the automatic translation still faces many challenges, including accu-\nrately capturing the nuances of language, handling idiomatic expressions, and\ndealing with cultural language differences. Therefore, it is important to be aware\nof these limitations and expect some noise in the translated data.\nAnother limitation we found was the annotation alignment. In fact, we used\nseveral techniques to improve our results in the alignment of the trigger and ar-\ngument span annotations. Despite that, we know there are still alignment errors,\ncausing triggers and arguments to be wrongly annotated. Consider the following\nsentence \"We discussed the Middle East peace process\u201d and the corresponding\ntranslation \u201cDiscutimos o processo de paz no M\u00e9dio Oriente\u201d. In this sentence,\nthe word \"discussed\" is an event trigger of type Contact. Meet while the word\n\"We\" corresponds to an event argument playing the role Entity. However, in the\nPortuguese translation, the sequence \"We discussed\" was translated into \"Dis-\ncutimos\" (the verb was conjugated in the first person plural). The argument\n\"We\" became implicit, making the annotation hard to align.\nFurthermore, in addition to the translation noise, we believe that the event\nextraction difficulty for English and Portuguese languages is not the same. For\ninstance, the Portuguese language has a greater diversity of words. This is the\ncase of the conjugation of verbs. Looking at the trigger words, the ACE-2005\ncorpus has about 1237 different trigger words in total, while the Portuguese\ntranslated version has 1900 trigger words. Although we show comparative results\nof our work against SOTA English models, it is not entirely fair to make a direct\ncomparison given the differences in language and cultural context.\nAs for the results, our validation data was translated in the exact same\nmanner as our training data, which means that it also contains the translation\nand alignment noise we mentioned above. It would be interesting to validate our\nmodels against data revised by humans, ensuring a higher data quality.\nIn fact, we employed identical metrics as previous works to compare our\noutcomes. Nonetheless, the strict evaluation metrics hide many near misses.\nConsider the following example:"}, {"title": "Conclusion", "content": "This work proposes a novel method for extracting events from Portuguese text.\nOur approach involves two tasks: first, we classify and identify event triggers us-\ning token classification; Then, we extract event arguments using extractive QA.\nTo train models capable of performing those tasks, we fine-tune the BERTim-\nbau model with SQUAD and ACE-2005 datasets, the latter being a reference\nin the event extraction field. Since these datasets were not available in Por-\ntuguese, we developed a translation pipeline to automatically translate them.\nWe present a new event extraction baseline for Portuguese using the ACE-2005\ndataset translated into Portuguese. As we could not find any comparable works\nin Portuguese, we used existing English event extraction works as a benchmark.\nWhile our models achieved lower results compared to the English models, we\nbelieve the comparison cannot be made directly due to language differences.\nFor future work, considering the lack of extensive research on this task for\nPortuguese, there are numerous suitable approaches that could improve our re-\nsults. For example, expanding our data domain by incorporating other event-\ndriven datasets, such as TAC KBP 2015 [11] and MINION [35]. We could also\nleverage Semantic Role Labeling for Portuguese in order to enhance the perfor-\nmance of event argument extraction."}]}