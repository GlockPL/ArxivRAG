{"title": "A Soft Sensor Method with Uncertainty-Awareness and Self-Explanation Based on Large Language Models Enhanced by Domain Knowledge Retrieval", "authors": ["Shuo Tong", "Han Liu", "Runyuan Guo", "Wenqing Wang", "Xueqiong Tian", "Lingyun Wei", "Lin Zhang", "Huayong Wu", "Ding Liu", "Youmin Zhang"], "abstract": "Data-driven soft sensors are crucial in predicting key performance indicators in industrial systems. However, current methods predominantly rely on the supervised learning paradigms of parameter updating, which inherently faces challenges such as high development costs, poor robustness, training instability, and lack of interpretability. Recently, large language models (LLMs) have demonstrated significant potential across various domains, notably through In-Context Learning (ICL), which enables high-performance task execution with minimal input-label demonstrations and no prior training. This paper aims to replace supervised learning with the emerging ICL paradigm for soft sensor modeling to address existing challenges and explore new avenues for advancement. To achieve this, we propose a novel framework called the Few-shot Uncertainty-aware and self-Explaining Soft Sensor (LLM-FUESS), which includes the LLM-based Zero-shot Auxiliary Variable Selector (LLM-ZAVS) and the LLM-based Uncertainty-aware Few-shot Soft Sensor (LLM-UFSS). The LLM-ZAVS retrieves from the Industrial Knowledge Vector Storage (IKVS) to enhance LLMs' domain-specific knowledge, enabling zero-shot auxiliary variable selection. In the LLM-UFSS, we utilize text-based context demonstrations of structured data to prompt LLMs to execute ICL for predicting and propose a context sample retrieval augmentation strategy to improve performance. Additionally, we explored LLMs' AI-Generated Content (AIGC) and probabilistic characteristics to propose self-explanation and uncertainty quantification methods for constructing a trustworthy soft sensor. Extensive experiments on industrial datasets from bioprocessing and chemical engineering demonstrate that our method achieved state-of-the-art predictive performance, strong robustness, and flexibility, effectively mitigates training instability found in traditional methods. To the best of our knowledge, this is the first work to establish soft sensor utilizing LLMs.", "sections": [{"title": "Introduction", "content": "In modern industrial processes, accurate monitoring of key quality variables is an indispensable requirement for ensuring the safe and efficient operation of automation systems\u00b9. Unfortunately, direct online measurement of certain critical variables is often impractical due to high equipment costs, harsh environments, and technological constraints2,3. As a result, soft sensor technology has emerged as an efficient solution, utilizing readily accessible process variables (auxiliary variables) to model and predict difficult-to-measure quality variables (primary variables) in real-time. This technology plays an increasingly vital role in industrial process optimization, control, and product quality monitoring\u2074.\nSoft sensor modeling methods can be primarily classified into mechanism-based and data-driven approaches\u2075. Data-driven models rely on historical data from distributed control systems (DCS), bypassing the intricacies of process mechanisms, which has made them the mainstream approach today 6,7. Traditional data-driven soft sensors typically include principal component analysis (PCA) 8,9, partial least squares regression (PLSR) 10,11, and support vector machines (SVM) 12, along with their variants. Recently, deep learning has advanced rapidly, garnering significant attention for its powerful capabilities in handling nonlinear relationships and extracting complex features. Popular deep learning-based soft sensing techniques include multilayer perceptrons (MLP) 13, Long Short-Term Memory networks (LSTM) 14, and Stacked Autoencoders (SAE) 15,16.\nTraditional statistical methods, machine learning-based soft sensors, and emerging deep learning soft sensors (collectively referred to as numerical models) all operates on the paradigm of supervised learning. This involves optimizing an objective function, whereby the model iteratively adjusts its parameters on the training dataset to capture complex input-output relationships. However, these numerical models face inherent limitations that significantly hinder their practical application, which we categorize into four main aspects: (1) High modeling costs and barriers to entry: Developing soft sensors often requires task-specific design and training tailored to specific on-site conditions. This fragmented and customized approach greatly increases the time and computational costs, along with the complexity of development and maintenance. Moreover, building complex models is knowledge-intensive, necessitating data analysts with expertise across various data science and algorithmic fields, creating a high entry barrier for soft sensor modeling. (2) Limited robustness and flexibility with input data: Numerical models impose stringent requirements on the format, dimensions, quantity, and types of input data17,18. Raw data must be normalization and dimensional unification, complicating preprocessing. Additionally, these models cannot handle missing values, which restricts their flexibility19,20. Finally, they rely solely on structured data from industrial processes, making it difficult to incorporate relevant mechanistic knowledge and context, thus limiting their representation learning potential. (3) Instability during the training process: Numerical models are sensitive to initial parameters, sample sizes, and hyperparameter settings21. An excessive or insufficient number of samples can lead to overfitting or underfitting, while random fluctuations and changes in data distribution during training can result in issues such as gradient explosion or vanishing gradients22. (4) Lack of Interpretability and Uncertainty Quantification: Numerical models feature complex structures involving multiple layers of nonlinear relationships and numerous parameters, making it hard to interpret the connections between input features and outcomes23,24,25. Furthermore, they identify hidden patterns in a data-driven manner, lacking transparency based on rules or explicitly theories, which complicates the provision of clear decision-making support for prediction. Moreover, these models rely on deterministic algorithms that often yield single-point predictions without quantifying uncertainty in input data or the model itself. This inability to reflect potential risks or error ranges remains an unresolved issues in the field of soft sensor25.\nRecently, large language models (LLMs) pretrained on extensive corpora has provided promising solutions to these challenges. Models like GPT-426 and Gemini-1.5-pro27 have garnered considerable attention natural language processing (NLP) for their impressive text generation and reasoning abilities28. They have also achieved remarkable success in complex domains beyond NLP, including dermatological diagnosis29, mathematical reasoning30, patient records interpretation\u00b3\u00b9, and chemistry32, continuously pushing the boundaries of LLMs capabilities. This success is largely attributed to their emergent abilities, which develop new advanced capabilities as model parameters scale up33,34. A key ability is In-Context Learning (ICL) 35,36, allowing LLMs to rapidly adapt to unseen tasks by learning from a few examples (input-output pairs) in prompts, and to return results without any additional training or parameter updates.\nEncouraged by this, this paper aims to leverage the new learning paradigm of ICL to replace the traditional supervised learning pipeline for soft sensor modeling, addressing challenges in data-driven soft sensor without sacrificing predictive performance. As illustrated in Fig. 1, we propose a few-shot soft sensor framework based on LLMs, called LLM-FUESS, which incorporates uncertainty-awareness and self-explanation. LLM-FUESS streamline the soft sensor pipeline into two stages: auxiliary variable selection and soft sensor modeling, named the LLM-Based Zero-Shot Auxiliary Variable Selector (LLM-ZAVS) and the LLM-Based Uncertainty-Aware Few-Shot Soft Sensor (LLM-UFSS), respectively.\nSelecting auxiliary variables is essential in soft sensor modeling, as it minimizes interference from irrelevant variables and reduces prompt token counts\u00b3\u2077, lowering API costs. As depicted in Fig. 2, we propose a zero-shot auxiliary variable selector (LLM-ZAVS) that uses LLMs and prompt learning to generate reasonable feature selection results, along with importance rankings and scores, without examining any data samples. While pretrained LLMs encode extensive knowledge, they may lack detailed, domain-specific insights about industrial processes, material properties, and reaction mechanisms, leading to \"hallucinations\" and unreliable feature selection. To address this, we integrate domain-specific industrial knowledge with LLMs using Retrieval-Augmented Generation (RAG) 38,39, transforming LLMs into informed domain experts for selecting auxiliary variables. To ensure the reliability and transparency of LLMs decisions, we introduce the Chain of Thought (CoT) 40,41, enabling LLMs to provide detailed explanations of the decision-making process (both globally and locally). Additionally, we design a new evaluation metric called the Average Selection Consistency Score (ASCS) to assess the consistency of LLM-ZAVS's results. Experimental reults shows that LLM-ZAVS performs competitive against other numerical feature selection methods and exhibits high output consistency.\nIn the LLM-UFSS (Fig. 3), we format structured process data into text-based input-output pairs as context demonstration samples. Unlike supervised methods, LLMs capture hidden nonlinear patterns among variables by learning from few-shot context examples in prompts, enabling accurate predictions of the target variable for test samples. Since the entire framework relies on prompt strategies without any modifications to model or training, LLM-UFSS is both code-free and model-free, significantly reducing modeling complexity, time costs, and dependency on specialized knowledge. Given that the performance of ICL depends on the quality of demonstration samples42, we propose a context sample enhancement strategy inspired by RAG. Unlike traditional RAG, which focuses on document retrieval and augmentation, our method utilizes industrial sample vectors. Specifically, we use the test sample as a query to retrieve similar samples from the constructed Industrial Process Data Vector Store (IPDVS) for improved the quality of context demonstrations. Notably, the input to LLM-UFSS is entirely in a user-friendly natural language format. Due to the inherent robustness of LLMs to prompts, we are able to bypass normalization and imputation for missing values, demonstrating strong flexibility in handling inputs. leveraging LLMs' powerful multimodal capabilities, we integrate industrial domain knowledge texts (such as background, data information, and mechanistic knowledge) into the prompts, combining them with numerical data. This multimodal fusion significantly enriches the model's expression by enhancing information from multiple perspectives. Furthermore, we instruct LLMs to provide detailed, step-by-step, and human-readable explanations of the decision-making process during prediction, enhancing the interpretability and transparency of the proposed method. Finally, we propose two uncertainty quantification methods for soft sensing using LLMs' probabilistic characteristics: constructing confidence intervals and outputting confidence scores, enhancing the method's credibility, reliability, and risk awareness. Through extensive quantitative analysis and ablation experiments, we demonstrate the strong performance and capabilities of LLM-FUESS from multiple aspects. Remarkably, our experiments also indicate that LLM-UFSS can effectively prevent training instability issues such as overfitting or underfitting commonly encountered in supervised learning methods.\nFinally, we incorporate various prompt engineering techniques such as role-play43, CoT, and emotional stimulation44 to create two fixed fill-in-the-blank prompt templates for LLM-ZAVS and LLM-UFSS: the Auxiliary Variable Selection Prompt Template (AVS-PT) and the Soft Sensor Prompt Template (SS-PT) (Fig. 4). Using LangChain, we encapsulated the entire process framework, allowing users to simply fill in a few external keywords into the templates according to operational requirements. The framework then automatically executes the corresponding tasks end-to-end, delivering stable results. This approach aligns with human interaction methods, making it user-friendly for non-experts without AI or coding backgrounds. By changing only a few keywords, the template can adapt to all soft sensing tasks, simplifying manual configuration and operation."}, {"title": "Results", "content": "To validate the proposed method's performance and general applicability in industrial process, we selected the penicillin fermentation process (biocatalytic reactions) and the polypropylene production process (chemical polymerization) as case studies (Fig. 5).\n(1) Penicillin fermentation process\nPenicillin, a secondary metabolite synthesized by the penicillium mold under specific conditions, is one of the most widely used antibiotics. As shown in Fig. 5a, the fermentation process is a complex nonlinear batch process. However, the absence of reliable sensors for real-time measurement of product concentration, a critical quality variable, makes effective control of the fermentation process challenging. Therefore, developing a soft sensor to measure penicillin concentration in real-time and accurately using easily accessible process variables is of significant research interest.\nIn this study, the industrial-scale penicillin fermentation simulation (IndPensim)45 was selected for experimentation. IndPensim integrates the complex characteristics of various industrial-scale processes and serves as a simulation platform closely resembling actual industrial penicillin fed-batch fermentation processes. We selected three normal batches with different parameter settings from IndPensim, with fermentation times of 226h, 230h, and 278h, and a sampling interval of 0.2h. Each batch comprises two phases: the batch phase and the fed-batch phase. In the initial batch phase, Penicillium consumes the substrate, leading to rapid mycelial growth, but penicillin is not produced. After 24 hours, the process transitions to the fed-batch phase, during which a substantial amount of penicillin is continuously synthesized. Our experiments focus on data from fed-batch phase (post-24h), predicting penicillin concentration as the primary variable, while 22 accessible process variables serve as auxiliary variable for feature selection and soft sensor modeling. Detailed descriptions and units are in Table 1."}, {"title": "Experimental settings", "content": "(1) Implementation details: All experiments were conducted on a server equipped with a 12th Gen Intel(R) Core(TM) i5-12600KF and 32GB RAM, utilizing Python for implementation. For the proposed method, unless otherwise specified, GPT-40 was employed as the LLM via API calls. To ensure consistency in output, the temperature was set to 0.\n(2) LLM-ZAVS: For all datasets, we selected auxiliary variables comprising 50% of the total features to evaluate the performance of LLM-ZAVS. This was validated using linear regression and support vector regression. To ensure a fair comparison, we employed a fixed set of hyperparameters and 5- fold cross-validation for stable evaluation results. Due to inherent variability in LLMs outputs, we conducted five experiments to obtain five sets of LLM-ZAVS feature selection results, averaging them to derive the final outcome.\n(3) The auxiliary variables selected by the LLM-ZAVS were used as input for LLM-UFSS. For LLM- UFSS-FSC (Methods), 200 samples were randomly chosen from the dataset to creat 10 contexts in SS-PT, each containing 20 text-based samples. From each context, 20 different test samples were randomly selected, ensuring no overlap through sampling without replacement. Each test sample underwent 10 experimental repetitions to establish prediction confidence intervals, with the average used as the final result. For LLM-UFSS-RAC (Methods), the 200 samples from LLM-UFSS-FSC were used to construct the IPDVS, matching each test sample with similar ones from the IPDVS to form the context. Due to its superior predictive performance and lower uncertainty, each test sample in LLM-UFSS-RAC was evaluated only once. For other benchmark methods, a grid search was performed to find the optimal parameters.\n(4) Evaluation metrics: In this study, four evaluation metrics were employed to assess the effectiveness and accuracy of the proposed model: Mean Absolute Error (MAE), coefficient of determination (R\u00b2), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE)."}, {"title": "Analysis of LLM-ZAVS feature selection results", "content": "We compared the performance of LLM-ZAVS with six common feature selection methods in two case studies, IndPensim and Polypropylene. These methods include Recursive Feature Elimination (RFE)46, pearson correlation47, filtering by Mutual Information (MI)48, spearman correlation49, fisher score50, and random feature selection. As shown in Table 3, the text-based LLM-ZAVS achieved optimal or near- optimal results compared to these data-driven methods. Notably, LLM-ZAVS operates in a zero-shot manner, meaning it does not require direct access to data samples. This highlights the competitive advantage of LLM-ZAVS, which leverages real-world knowledge reasoning over numerical statistical analysis. Furthermore, LLM-ZAVS improved the linear regression MAE by 54.41% and 44.69% on IndPensim and Polypropylene, respectively, compared to random feature selection, demonstrates its effectiveness in enhancing model predictive performance and strong applicability.\nEven with identical prompts, using LLMs as feature selectors may result in different auxiliary variables being output. To assess the generative consistency of LLM-ZAVS, we propose a novel evaluation metric called the Average Selection Consistency Score (ASCS). Assuming LLM-ZAVS selects $m$ auxiliary variables from a set of candidates over $n$ repeated experiments, ASCS can be defined as follows:\n$\\text{ASCS} = \\frac{1}{C_n^2} \\sum_{i=1}^{n-1} \\sum_{j=i+1}^{n} \\frac{\\left| A_i \\cap A_j \\right|}{m}$   (5)\nWhere $C_n^2$ represents the binomial coefficient, and $\\left| A_i \\cap A_j \\right|$ denotes the number of common elements between the auxiliary variable selection results of the i-th and j-th experiments. The ASCS value ranges from 0 to 1, with higher values indicating greater generative consistency of the feature selector. The ASCS results for LLM-ZAVS from five experiments are shown in Table 4. For IndPensim, where 11 auxiliary variables were selected, the ASCS is 0.75, meaning that, on average, 8.25 auxiliary variables were consistently selected across outputs. For Polypropylene, with four auxiliary variables selected, the ASCS is 1, indicating complete consistency across all five outputs. This demonstrates that LLM-ZAVS provides highly consistent feature selection results, exhibiting strong robustness."}, {"title": "Analysis of LLM-UFSS-FSC results", "content": "To validate the effectiveness of LLM-UFSS-FSC (Methods), four popular soft sensing algorithms were selected: Random Forest Regression (RFR)51,52 and Multilayer Perceptron (MLP)13, known for their robust nonlinear processing, k-Nearest Neighbors Regression (k-NN)53 based on instance learning, and Principal Component Regression (PCR) 54,55, which combines PCA with multiple linear regression. Due to the extremely limited input training samples, deep learning networks were deemed unsuitable, so no comparison was made in this study. All comparative methods normalized and denormalized input data for optimal performance, whereas the LLM-UFSS-FSC utilized raw, unprocessed data.\nThe quantitative comparison results in Table 5 show that the LLM-UFSS-FSC achieved the lowest MAE and RMSE across both datasets without parameter updates or model modifications, outperforming traditional machine learning and neural network models. Specifically, on the IndPensim and Polypropylene datasets, the MAE for LLM-UFSS showed a reduction of 7.37% and 22.17%, respectively, compared to the second-best model, RFR. These findings also demonstrate that LLM-UFSS-FSC, leveraging text-based input, effectively learns from context samples and produces competitive results without normalization, exhibiting strong robustness to data scale variations."}, {"title": "Confidence score output analysis", "content": "In addition to constructing confidence intervals, we also explored an alternative approach for uncertainty perception in soft sensor predictions. This involves using a prompt strategy to instruct LLMs in SS-PT to perform confidence elicitation. By analyzing contextual information, the model outputs a confidence score ranging from 0 to 1, where scores closer to 1 indicate higher confidence. This approach aims to enhance risk assessment and error mitigation.\nTo validate the LLM-UFSS's ability to perceive uncertainty, we compared the average confidence scores across two datasets with data missing rates from 0% to 50%. As shown in Fig. 11a, confidence scores consistently decrease with higher missing rates, indicating that increased missing values reduce LLM-UFSS's confidence in prediction accuracy, thereby highlighting its capability to perceive prediction uncertainty. To further support this, we plotted the error and confidence score density for all samples in Fig. 11b. The horizontal axis represents the confidence scores, while the vertical axis represents prediction error, with values closer to 0 indicating better predictions. The figure reveals that the majority of confidence scores fall between 0.8 and 1, with fewer below 0.8. As confidence scores increase, the error visibly narrows towards the central value of 0. In the range of 0.9 to 1, the error is minimal, and predictive performance is optimal. This demonstrates that by guiding the model to output confidence scores, LLM-UFSS can effectively assess its own prediction accuracy."}, {"title": "Analysis of explanation results", "content": "(1) Analysis of LLM-ZAVS explainability results\nThrough global-query, LLM-ZAVS generates importance scores and rankings for auxiliary variables, along with self-explanatory text regarding their feature importance. Fig. 12 illustrates the LLM-ZAVS 's outputs for global auxiliary variable identification and reasoning explanation across two datasets. The results, highlighted in orange, demonstrate that LLM-ZAVS effectively identifies and incorporates contextual embedded knowledge retrieved from the IKVS, providing professional interpretations of different variables based on this contextual information, as shown in blue.\nDue to the challenge LLMs face in handling multiple tasks with fine granularity simultaneously, global-query may struggle to provide deeper reasoning for each variable. To address this, we introduce local-query for more detailed explanations, offering more comprehensive information. Fig. 13 presents two examples of local explanations generated by LLM-ZAVS."}, {"title": "Ablation study", "content": "To validate the effectiveness and contributions of each key component in the proposed method, we conducted ablation experiments with various variants of LLM-UFSS. The LLM is a critical component, so we compared the default GPT-4026 model with three other state-of-the-art LLMs (GPT-3.5-turbo61, GPT-426, Gemini-1.5-pro-exp-080127) across two datasets. The MAE results are shown in Fig. 16a. It is evident that GPT-3.5-turbo exhibits a significantly higher MAE of 2.132 on the IndPenSim dataset, indicating a substantial performance gap compared to other models. In contrast, Gemini-1.5-pro-exp-0801 achieves the lowest MAE of 0.798, a 62.57% reduction compared to GPT-3.5-turbo, highlighting the impact of LLMs selection on LLM-UFSS's predictive performance. Furthermore, we believe that Gemini- 1.5-pro-exp-0801 offers superior mathematical analysis capabilities compared to the GPT-4 series."}, {"title": "Discussion", "content": "This paper introduces LLM-FUESS, the first two-stage soft sensing framework based on the ICL paradigm of LLMs, designed to overcome various challenges in traditional data-driven soft sensors. In the first stage, the LLM-ZAVS retrieves domain-specific knowledge from the IKVS and integrates it with the internal knowledge of LLMs. This integration endows LLMs with expert-level analytical capabilities for auxiliary variable selection. In the second stage, LLM-UFSS employs minimal samples as context task demonstrations, leveraging the powerful ICL capabilities to achieve robust predictive performance without any model training or parameter updates. Additionally, by constructing the IPDVS and introducing the RAG, we offer an alternative strategy for enhancing context samples when ample data is available. We exploit the robust text generation and probabilistic features of LLMs in both stages to provide human-readable, explainable insights, and for LLM-UFSS, we design two methods to quantify prediction uncertainty as a basis for evaluation. To enhance the task adaptability and usability of LLM- FUESS across diverse scenarios, we introduce various prompting strategies, creating two highly encapsulated fill-in-the-blank templates: AVS-PT and SS-PT for each stage, respectively.\nExtensive experiments were conducted on datasets from two distinct domains, IndPensim and Polypropylene. The results from the first stage demonstrate that LLM-ZAVS can consistently and effectively select auxiliary variables, providing explanations from both local and global perspectives with a high degree of professionalism. In the second stage, the experiments reveal that LLM-UFSS not only achieves competitive performance compared to data-driven soft sensors but also exhibits greater robustness and flexibility regarding input data formats, quantities, and types. Furthermore, the experiments indicate that LLM-UFSS possesses strong self-explanation and uncertainty awareness capabilities, enhancing the method's transparency and risk awareness. This provides practitioners with more comprehensive and valuable decision-making information."}, {"title": "Methods", "content": "As the parameters and training corpus of large LLMs continue to expand, they exhibit emergent capabilities-abilities not present in smaller-scale models. This paper proposes a novel few-shot soft sensor method, LLM-FUESS (Uncertainty-Awareness and Self-Explanation), leveraging these emergent abilities of LLMs. Typically, data selection and soft sensor modeling are considered two independent components of the soft sensor pipeline. As illustrated in Fig. 1, the proposed LLM-FUESS consists of two stages: (a) LLM-ZAVS and (b) LLM-UFSS, which perform feature selection and soft sensing tasks, respectively. These stages are detailed in \"LLM-based zero-shot auxiliary variable selector (LLM- ZAVS)\" and \"LLM-based uncertainty-aware few-shot soft sensor (LLM-UFSS)\". The meticulous design of prompt strategies is crucial for eliciting the emergent capabilities. Therefore, we have developed two fill-in-the-blank prompt templates, AVS-PT and SS-PT (AVS-PT and SS-PT with prompt engineering), for these stages to maximize the reasoning abilities and performance of the models."}, {"title": "LLM-Based zero-shot auxiliary variable selector (LLM-ZAVS)", "content": "In the context of expanding production scales and increasingly complex industrial processes, the dimensionality of process variables has significantly increased. Redundant variables can impair the predictive performance and computational efficiency of soft sensor. By selecting an appropriate subset of auxiliary variables, we can eliminate redundancy and conserve LLMs input tokens. Additionally, identifying key quality variables supports product quality control and enhances analysis, interpretation, and prediction by LLMs. To address this, we propose a novel Zero-Shot Auxiliary Variable Selector (LLM-ZAVS). As depicted in Fig. 2, LLM-ZAVS comprises three main components: (a) construction of the industrial knowledge vector store, (b) filling in the prompt template, and (c) generation of explainable auxiliary variable selection results.\nIn component (a), we construct a dynamic external industry knowledge vector store tailored to the current task using RAG. This approach address the domain-specific knowledge gaps of LLMs in knowledge-intensive industrial tasks, enhancing variable selection capabilities and reducing hallucinations. Initially, we collect relevant documents from various data sources, including books, research papers, web pages, and technical reports, to compile an unified, authoritative internal industrial scenario knowledge base, denoted as $D_{kb}$. The text within $D_{kb}$ is then split into smaller document chunks:\n$D_{kb} = \\{D_{kb}^1, D_{kb}^2, ..., D_{kb}^n\\}$ (6)\nSubsequently, we employ an embedding model $f_e$ to encode each chunk $D_{kb}^i$ into high-dimensional vectors:\n$f_e : D_{kb}^i \\rightarrow V_i \\in \\mathbb{R}^d$   (7)"}, {"title": "LLM-based uncertainty-aware few-shot soft sensor (LLM-UFSS)", "content": "After processing by the first-stage LLM-ZAVS module, we filter a set of auxiliary variables most crucial to the primary variables. In the second stage, these variables serve as inputs for predicting primary variable values through a soft sensor. Unlike previous approaches, our LLM-Based Uncertainty-Aware Few-Shot Soft Sensor (LLM-UFSS) requires no model training or gradient updates. Instead, it utilizes ICL with prompt engineering, using a few examples to leverage the LLM's capabilities to analyze data and prediction. Furthermore, compared to earlier soft sensors that could only generate singular numerical predictions, the LLM-UFSS also provides detailed reasoning explanations, confidence scores, and confidence intervals for uncertainty quantification of the generated results.\nThe LLM-UFSS pipeline, similar to LLM-ZAVS, consists three parts: (a) Construction of the industrial process data vector store, (b) Filling in the prompt template, and (c) Generation of explainable soft sensor results (Fig. 3). With the widespread application of DCS, collecting and storing large amounts of process variable data has become feasubke. Inspired by RAG, the stage (a) aims to construct a retrievable industrial process data vector store to provide LLMs with more valuable contextual examples for improved predictions. Initially, we obtain raw historical process variable data through DCS applications, available in formats such as JSON, Excel, or CSV. We then filter this data using the LLM- ZAVS, selecting the auxiliary variables and removing less important, redundant, and spurious variables to form the DCS process variable database $D_{pv}$. Subsequently, we segment the database according to sample time steps, resulting in $n$ independent data samples:\n$D_{pv} = \\{D_{pv}^1, D_{pv}^2, ..., D_{pv}^n\\}$   (11)\nwhere $D_{pv}^i = (x_1^i, x_2^i, ..., x_m^i, y_i)$, $m$ is the number of auxiliary variables, $x_i$ denotes the auxiliary variable values, and $y_i$ is the true value. Following the LLM-ZAVS, each sample $D_{pv}^i$ is encoded into high- dimensional vectors for indexing and storage in the industrial process data vector store (IPDVS).\nIn phase (b), we construct a Soft Sensor Prompt Template (SS-PT) tailored for the soft sensing task (Fig. 4). Users input task-specific industrial background information $t$ to configure the SS-PT. Additionally, feature importance rankings $r_i$ and scores $s_i$, generated by LLM-ZAVS, along with global feature explanations $exp_g$, are incorporated as extra contextual information. This provides the LLMs with finer-grained prompts, enabling more in-depth and complex reasoning. It is essential to provide high- quality sample examples for ICL inference and generalization, so we designed two pathways to supply ICL samples based on varying industrial scenarios. When on-site samples are minimal and insufficient to construct the IPDVS, LLM-UFSS employs the available few-shot samples as inputs into the SS-PT, termed LLM-UFSS Few-Shot Contextualization (LLM-UFSS-FSC). Conversely, if the DCS gathers substantial amount of data, a text-based test sample-comprising auxiliary variable names and values- queries the IPDVS to retrieves several samples with high similarity to the test sample, which are then input into the SS-PT (orange dashed line), known as LLM-UFSS Retrieval-Augmented Contextualization (LLM-UFSS-RAC). These context samples are denoted as $I$, with a total of $k$ examples, where $I$ is defined as follows:\n$I = f(x_1^1, x_2^1,..., x_m^1, y_1), f(x_1^2, x_2^2,..., x_m^2, y_2),...,f(x_1^k, x_2^k,..., x_m^k, y_k)$ (12)\nwhere $f(.)$ represents a text formatting function that converts numerical samples into a textual format consistent with the test samples (as indicated by the purple dashed line). Upon constructing the SS-PT, a complete input prompt for the LLMs, referred to as the soft sensor query, is obtained. In phase (c), this query is input into the pre-trained LLMs, which analyze the context samples through ICL to output the soft sensor predictions $y_p$ for the primary variables of the test samples.\nWe have incorporated self-explanation instructions into the SS-PT, leveraging the LLM's robust reasoning and natural language generation capabilities to produce clear, detailed, and human-readable explanations of model decisions ($exp_i$). This aids operators in making safer, more informed decisions and conducting causal analysis. Beyond precise point estimates, we have developed two distinct methods for quantifying output uncertainty. Firstly, by selecting the next token from multiple high-probability options, the LLM generates diverse textual outputs, allowing us to construct a predictive confidence interval through repeated experiments. Analyzing the width and boundaries of this interval helps users assess the model's reliability and stability, facilitating more informed decision-making. Secondly, we introduce instructions in the SS-PT to compel the LLMs to generate a confidence score for its predictions, reflecting the model's confidence level and enabling awareness of prediction performance uncertainty.\nLastly, our model also exhibits strong robustness to input data uncertainty. Specifically, since the LLMs formats numerical inputs as text-based prompts, any missing values in data samples can be replaced with 'N/A'. Compared to traditional numerical models that require strict normalization and imputation of missing values, LLM-UFSS simplifies the data preprocessing workflow and avoids inappropriate handling that could lead to information loss or distortion. This approach enhances readability, robustness, flexibility, and intelligence. Analysis of ablation experiments shows that prompting the LLMs for self- explanations and confidence scores also improves the predictive performance of the proposed method."}, {"title": "AVS-PT and SS-PT with prompt engineering", "content": "By incorporating key elements through prompt engineering techniques", "strategies": "the Auxiliary Variable Selection Prompt Template (AVS-PT) and the Soft Sensor Prompt Template (SS-PT) (Fig. 4). These templates are designed to activate and guide the LLM's reasoning process effectively.\nIn designing the AVS-PT", "components": "role", "Role": "This element assigns a specific role to the LLMs", "Data": "This provides detailed background information on the data collection process", "Instruction": "We have designed two distinct sets of instructions for local and global queries. Local queries focus on the importance of a specific auxiliary variable", "Context": "LLMs have limited ability to handle knowledge-intensive industrial tasks due to a lack of domain-specific knowledge. To address this", "Prompt": "This element specify the variable names to be analyzed and instruct LLMs to generate responses. For local queries"}, {"components": "role", "Role": "identical to that in AVS-PT. 2) Data: Similar to AVS-PT", "Ranking": "Generated by LLM-ZAVS", "Explanation": "Also generated by LLM-ZAVS. 5) Instruction: Guides LLMs to execute ICL to generate predictions and produce a reasonable explanation based on the CoT. 6) Context Prompt:"}]}