{"title": "A3: Active Adversarial Alignment for Source-Free Domain Adaptation", "authors": ["Chrisantus Eze", "Christopher Crick"], "abstract": "Unsupervised domain adaptation (UDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain. Recent works have focused on source-free UDA, where only target data is available. This is challenging as models rely on noisy pseudo-labels and struggle with distribution shifts. We propose Active Adversarial Alignment (A3), a novel framework combining self-supervised learning, adversarial training, and active learning for robust source-free UDA. A3 actively samples informative and diverse data using an acquisition function for training. It adapts models via adversarial losses and consistency regularization, aligning distributions without source data access. A3 advances source-free UDA through its synergistic integration of active and adversarial learning for effective domain alignment and noise reduction. Our approach significantly advances state-of-the-art methods, achieving 4.1% on Office-31, 11.7% on Office-Home, and 10.6% on DomainNet accuracy improvements.", "sections": [{"title": "I. INTRODUCTION", "content": "Unsupervised domain adaptation (UDA) addresses the poor model performance that arises due to domain shift [2] by leveraging labeled data from a source domain to train models that generalize to an unlabeled target domain. However, standard UDA techniques require access to source data, which might not be feasible due to privacy or computational resource concerns. This paper tackles the challenging problem of source-free unsupervised domain adaptation (SFUDA), where only target data is available without its label. Recent SFUDA methods [3]-[6], assume access to a pre-trained source model.\nVarious approaches have been proposed to address domain shifts in source-to-target domain adaptation. In a semi-supervised setting, works like [7]\u2013[10] address the problem using model regularization techniques and self-training with pseudo-labels. Another line of work focuses on aligning source and target feature distributions, with notable works including [11]\u2013[13]. These approaches design adversarial domain discriminators in parallel with the classification head.\nThe idea of designing pseudo-labels for training the target model has been prevalent in recent literature. SHOT [3] refines pseudo-labels with a prototype classifier and fine-tunes the feature extractor with a model regularization term maximizing mutual information. The work done in [10] introduces an augmented self-labeling scheme to improve pseudo-labels and retrain the target model.\nDespite the benefits of self-labeling schemes, they face challenges such as noisy pseudo-labels since they rely on predictions made by a model trained on the source domain to label target domain samples. In addition, due to the problem of prior initialization [10], [14], there might be limited data used to initialize the target for pseudo-labeling. To address these issues, we propose Source-Free Unsupervised Domain Adaptation with Active Sampling and Adversarial Domain Alignment (A3), a novel approach for source-free unsupervised domain adaptation as shown in Fig. 1. A key contribution of A3 is an active learning strategy that uses an acquisition function to carefully select the most informative and diverse target samples to build a core-set for training the target model. Using an acquisition function based solely on uncertainty or diversity sampling tends to be less effective for active domain adaptation [11], [15]. Therefore, we adopted a hybrid acquisition strategy that combines uncertainty and diversity sampling to identify both informative and representative samples from dense regions of the feature space.\nFurthermore, we adapt the source model to the target domain using adversarial and consistency losses that encourage learning domain-invariant features without source data. Specifically, we employ a domain adversarial loss which trains a domain classifier to distinguish between target embeddings generated from the source and target models. By using a gradient reversal layer, we ultimately confuse this classifier thereby reducing domain divergence. Additionally, we incorporate a virtual adversarial loss [16] which locally perturbs embeddings to maximize prediction change and enforce local Lipschitz smoothness. The virtual adversarial loss acts as a regularization technique to prevent overfitting and encourage robustness. Together, the domain adversarial and virtual adversarial losses perform global and local distribution alignment to facilitate effective adaptation. Further, we utilize a swap prediction loss for self-supervision and an entropy minimization term to prevent target overfitting. We summarize our contributions as follows:\n1) We propose a new framework for domain alignment by jointly training the target model and a domain classifier to enable the target model to produce domain-invariant features compelled by adversarial and regularization losses.\n2) To address the problem of noisy pseudo-labels in su-"}, {"title": "II. RELATED WORK", "content": "Settles' comprehensive survey [17] delves into active learning, exploring acquisition functions such as information theoretical approaches [18] and uncertainty-based methods [19].\nThe CLUE framework [15] introduces uncertainty-weighted clustering for diverse instance selection under domain shifts. The synergy of BALD [14] with deep neural networks, amplifies acquisition performance. Batch sampling strategies, such as those involving BALD [20] and core-set approximations [21], address efficiency concerns posed by computational challenges.\nAdditionally, Active Domain Adaptation (ADA) optimizes domain adaptation by strategically selecting samples. [22] introduced ADA, later adapted to image classification as AADA [11]. TQS [23] and CLUE [15] emphasize uncertainty-based sample selection, while S3VAADA [24] incorporates vulnerability, diversity, and representativeness. Inspired by BALD and CLUE, we adopted a hybrid acquisition function that jointly captures both uncertainty and diversity of the samples.\nThe Gradual Source Domain Expansion (GSDE) approach [25] presents a method for mitigating early alignment errors in Unsupervised Domain Adaptation (UDA) by progressively integrating pseudo-source data from high-scoring target samples. This method emphasizes the incremental alignment of source and target domains over multiple training iterations. In contrast to this gradual expansion method, our approach utilizes active learning to sample the most diverse and representative instances upfront, alongside adversarial learning and model regularization, to better ensure domain invariance from the outset.\nIn another related work, Local Context-Aware Active Domain Adaptation (LADA) [26], the authors proposed an active selection criterion based on local inconsistency in model predictions, focusing on uncertain regions. LADA uses a Progressive Anchor-set Augmentation (PAA) module to handle the small size of queried data, supplementing labeled target data with pseudo-labeled confident neighbors. Our method differs by emphasizing not just uncertainty but also diversity in sample selection, and by incorporating adversarial learning to improve domain adaptation, coupled with model regularization to avoid overfitting.\nOver time, there has been growing interest in aligning"}, {"title": "III. PROPOSED METHOD", "content": "In this section, we introduce our novel approach, specifically designed for source-free unsupervised domain adaptation. Our primary objectives include reducing annotation costs through the utilization of self-supervised learning and active learning for iterative model adaptation. To address these goals, we introduce and integrate various domain adaptation techniques, including a swap prediction loss, along with the introduced domain adversarial loss, virtual adversarial loss, and entropy minimization loss. In addition, inspired by BALD [14] and CLUE [15], we adopted a hybrid acquisition function that jointly captures both uncertainty and diversity of the samples.\nIn the first part of this section, we present the self-supervised learning technique we adopted for pretraining the source model. In the second part, we discuss our acquisition strategy, which involves iteratively sampling low-entropy and diverse instances from the target pool to train the target model. Finally, in the third part, we introduce adversarial losses and model regularization techniques, providing a detailed overview of our methodology. This structured presentation ensures a clear understanding of the proposed A3 method and its components.\nThe combined benefit of this iterative process, adversarial losses, and model regularization enhances the model's performance in adapting to the target domain, ensuring that the target model learns to produce invariant features.", "subsections": [{"title": "A. Self-Supervised Pretraining", "content": "We adopt a self-supervised learning scheme inspired by SwAV [31], aiming to maximize the similarity between positive pairs and minimize the similarity between negative pairs. This involves contrasting multiple image views by comparing their cluster assignments instead of their features as used in [32]. The method groups data into clusters while maintaining consistent cluster assignments across different augmentations or \"views\" of the same image. Initially, \"codes\" are generated by associating features with prototype vectors. Subsequently, a \"swap\" prediction task is solved, where codes obtained from one augmentation are predicted using the other. This ensures that the model doesn't directly compare image features. For two image features, $z_t$ and $z_s$, obtained from distinct augmentations of the same image, their codes $q_t$ and $q_s$ are derived by matching these features to a set of $K$ prototypes ${c_1,...,c_K}$. The swap prediction loss function is given by\n$$l(z_t, z_s) = l(z_t, q_s) + l(z_s, q_t)$$\nwhere the function $l(z, q)$ measures the consistency between features $z$ and a code $q$. This is expanded into\n$$L_{swap} = \\frac{1}{N}\\sum_{n=1}^N \\frac{1}{T^2}\\sum_{s,t\\sim T} \\left(-\\log \\frac{\\exp \\left(\\frac{z_{nt}^T C_{qns} + z_{ns}^T C_{qnt}}{\\tau}\\right)}{\\sum_{k=1}^K \\exp \\left(\\frac{z_{nt}^T C_k}{\\tau}\\right)} - \\log \\frac{\\exp \\left(\\frac{z_{ns}^T C_{qnt}}{\\tau}\\right)}{\\sum_{k=1}^K \\exp \\left(\\frac{z_{ns}^T C_k}{\\tau}\\right)}\\right)$$\nwhere $z_{nt}$ and $z_{ns}$ are features from the two compared images, and $q_{nt}$ and $q_{ns}$ are their intermediate codes, with $C_{qns}$ and $C_{qnt}$ representing their prototypes. This self-supervised learning approach is used for training both the source and target models."}, {"title": "B. Active Data Sampling", "content": "In the context of active learning, determining the uncertainty or informativeness of a sample is crucial for selecting the next sample to query. This is achieved through an acquisition function employed by the active learning (AL) system. Various works in the literature have proposed different acquisition functions, as extensively discussed in [33].\nIn the active learning process, given an unlabeled dataset $X_p$ and the current training pool $D_0$ serving as the core-set, a bayesian model $M$ with parameters $w \\sim p(w|D_0)$ as inputs, the acquisition function ranks batch samples based on model uncertainty and sample representativeness. The system then selects highly informative and representative samples from the batch [20]."}, {"title": "1) Acquisition Strategy", "content": "BALD [14], an uncertainty sampling strategy, determines the optimal unlabeled sample, denoted as $x^*$, by evaluating the mutual information between predictions and the model posterior. While BALD primarily focuses on exploitative uncertainty sampling, a desire for exploration of diverse instances can be incorporated by introducing a distance-based diversity reward, just like in CLUE [15]. This extends the acquisition function to consider underexplored regions in the input space through cluster-based distances.\nTo implement this strategy, the indices of the weighted instances are determined, and the Euclidean distances of these instances are sorted in descending order. The goal is to sample the top-k instances with the least uncertainty and high diversity based on their Euclidean distance for training the target model. For convenience, we will refer to this measure of uncertainty and diversity as the A3 score."}, {"title": "2) Core-set Construction", "content": "We aim to overcome a limitation of BALD arising from the use of an uninformative prior, which results from poor initialization of the core-set. To address this, we initialize a model using the source model to solve a pretext classification task where the labels are given by $y \\in {0,90,180,270}$ which represents possible rotation angles in degrees for the augmentations applied to the sample following the work done in [34]. This pretext-task model serves as the Bayesian model, $M$ used to construct a data pool $D_0$. During this process, we perform inference over the parameters $\\theta$ to obtain the posterior distribution $p(\\theta|D_0)$ [21], sampled by the A3 score. The data pool is then sorted by the A3 score of the samples and grouped into n batches.\nThis approach not only facilitates optimal sample querying but also addresses the cold-start problem inherent in active learning [34]. Our acquisition strategy given in the previous section is utilized to select the top-k samples from the first batch of the data pool, forming the core-set for training the target model. Subsequently, $M$ is retrained on this core-set, and the iterative process continues. The next batch of the data pool is equally passed through the acquisition function and the top-k samples are added to the core-set. This iterative cycle involves retraining the target model and $M$, sampling instances from the next batch using the acquisition function, expanding the core-set, and so on until the sampling budget is exhausted.\nThis iterative training and data sampling technique is visually depicted in Fig. 1."}, {"title": "C. Domain Alignment", "content": "The objective of domain adaptation is to train a model that is invariant across domains, capable of delivering accurate predictions in both the source and target domains. Drawing upon the representative and informative data selected through our active sampling technique detailed in Section III-B, we introduce a novel training routine for self-supervised based SFUDA. This routine incorporates two adversarial losses\u2014domain adversarial loss and virtual adversarial loss to drive the target model toward generating invariant representations. Additionally, we adopt a swap prediction loss (2) inspired by SwAV [31] and an entropy minimization loss [35] as regularization techniques. These measures collectively aim to mitigate the overfitting of representations to the target domain and address the divergence between predictions in the source and target domains.", "subsections": [{"title": "1) Model Regularization", "content": "Incorporating the swap prediction loss outlined in 2 as a regularization technique in our approach, we guide the model to learn meaningful representations by predicting relationships between augmented instances. Beyond the swap prediction loss, we introduce an additional regularization term known as the conditional entropy minimization loss [10], [35]. This term constrains the model, preventing overfitting to the target domain and mitigating the emergence of spurious correlations [35]. This is formally expressed as\n$$L_{ent} = \\frac{1}{N K}\\sum_{i=1}^N \\sum_{k=1}^K f_k (x_i; \\theta) \\log f_k (x_i; \\theta)$$\nwhere $f(x; \\theta)$ represents the output of the model parameterized by $\\theta$. This regularization term is introduced to address the expectation that optimal decision boundaries should be distanced from the data-dense regions of the samples, as emphasized in [8]. This aligns with the clustering assumptions, asserting that target samples form clusters, and the samples within the same cluster belong to the same class."}, {"title": "2) Adversarial Losses", "content": "Moreover, both [35] and [8] observed that the assumption in 3 holds true only if the model is locally Lipschitz. To ensure this, we incorporate the modified virtual adversarial loss (VAT) tailored for a self-supervised learning setting, akin to the approach in [10]. This VAT loss minimizes the divergence between predictions on clean samples vs those with small perturbations. This smooths the decision boundary and improves robustness:\n$$L_{vat} = D[f(x), f(x + r_{vadv})]$$\nwhere $f(x)$ is the model output embedding for input $x$ and $r_{vadv}$ is the computed VAT perturbation to maximize divergence between $f(x)$ and $f(x + r_{vadv})$. The $D$ is the KL divergence. We therefore aim to minimize $L_{vat}$ to enforce local smoothness of the model output [8] and also aid the model generalization to the target domain while still retaining knowledge from the source domain without catastrophic forgetting [36].\nAdditionally, we introduce a second adversarial loss to learn an embedding space where the domain adversary cannot reliably predict the domain from the embeddings. In this context, a domain classifier $D(f(x))$ is co-trained with the target model, using target embeddings extracted separately from the source and target models to predict the model they originated from. To optimize the domain classifier, we employ a gradient reversal layer [13], which flips the sign of the gradients during backpropagation. This adversarial learning approach makes the features challenging for domain prediction, and encourages the"}]}]}, {"title": "IV. EXPERIMENTS", "content": "In this section, we conduct rigorous evaluations of our approach to investigate and prove A3's robustness and effectiveness in carrying out source-free domain adaptation.", "subsections": [{"title": "A. Datasets", "content": "Following the baselines, we evaluated A3 on various benchmark datasets that represent different visual domains to gauge its robustness and generalizability.\nThe Office-31 [38] dataset has 4700 images in 31 categories from Amazon (A), DSLR (D), and Webcam (W) domains, while Office-Home [39] has 15500 images in 65 categories from Artistic (A), Clip-Art (C), Product (P), and Real-World (R) domains. Additionally, we evaluated A3 on the challenging DomainNet [40] dataset which contains images from six domains with 345 categories each. However, following the baselines, our evaluations of A3 were focused on four out of the six domains: sketch, clipart, painting, and real which shows the model's generalization between synthetic and real domains.\nImplementation Details: We adhered to established practices by selecting ResNet-50 [41] as the architecture for our target model, pretrained on ImageNet [1]. The network configuration closely mirrored that of SwAV [31], with some custom adjustments. The domain discriminator consisted of two layers and a classification head with a single neuron for binary classification. Our Bayesian model, integral to the active sampling process, utilized a ResNet-50 backbone with a classification head tailored for 4-class classification, corresponding to the four distinct input augmentations. For the Bayesian model, Stochastic Gradient Descent (SGD) with a learning rate of 0.1 and a multi-step learning rate scheduler was employed. We conducted four active learning cycles, allocating equal sampling budgets at each stage. In the self-supervised pretraining phase, SGD with a learning rate of 1e-4 and a cosine learning rate scheduler were utilized. Both self-supervised pretraining and the Bayesian model implementation incorporated a momentum of 0.9 and a weight decay of 1e-6."}, {"title": "B. Evaluations", "content": "We compare our proposed framework, A3 with baselines on the benchmark datasets highlighted in Section IV-A. To showcase the efficacy of A3, we compare it to the following baselines: ResNet-50 [41], SHOT [3], UAN [42], InstaPBM [43], Sentry [44], FixBi [45], GSDE [25], and LAS (LADA) [26]\nAs shown , our A3 outperforms existing state-of-the-art techniques on all the adaptation tasks on the Office-31 dataset with an improvement of 4.1%. For the Office-Home dataset on the other, Table III shows that A3 demonstrates highly competitive performance on 10 out of 12 transfer tasks, achieving significant improvements in all tasks excluding A\u2192C and R\u2192P. Again, we outperform LAS [26], the next best-performing method with an average increase of 11.7% accuracy. Finally, we show that A3 just as in the previous baseline datasets outperforms existing methods on DomainNet with an average improvement of 10.6% accuracy.\nWhile A3 shows overall improvements, its performance varies across different transfer tasks. For instance, on Office-31, A3 excels in the D\u2192A task (94.8% accuracy), likely"}]}, {"title": "C. Ablation Studies", "content": "We design different variants of the framework showcasing the contributions of each component and the effect of each active learning adaptation cycle on the performance of the target model.", "subsections": [{"title": "a) Varying acquisition strategies", "content": "We evaluated the impact of a hybrid acquisition strategy on A3's performance. Comparing uncertainty-only and random acquisition functions, Table I demonstrates that the hybrid strategy outperforms both. Notably, it significantly surpasses random sampling and slightly improves upon the uncertainty-only function, emphasizing the importance of combining diverse data samples with informative ones."}, {"title": "b) Varying alignment techniques", "content": "We examined the impact of individual domain alignment components on A3. , we display the contributions of three components, showing that the consolidated framework (Consolidated) outperforms all variants. Notably, the variant with only domain adversarial loss and virtual adversarial loss (DAL + VAT Only) performs closely to the comprehensive framework compared to using only entropy minimization loss (Entropy Only), emphasizing the influence of adversarial losses on A3's performance."}]}, {"title": "V. LIMITATIONS", "content": "While A3 demonstrates strong performance across various domain adaptation tasks, it has limitations. Our method may struggle in scenarios with extreme domain shifts where low-level features differ significantly between source and target domains. For example, adapting between natural images and medical imagery could pose challenges. Additionally, A3's effectiveness might be reduced when dealing with small target datasets, as the active learning component relies on a sufficiently large pool of unlabeled data to select informative samples. Finally, like many deep learning approaches, A3 can be computationally intensive, especially during the iterative active learning cycles. This could limit its applicability in resource-constrained environments or real-time adaptation scenarios."}, {"title": "VI. CONCLUSION", "content": "We present A3, a novel framework for SFUDA that addresses two key challenges: noisy pseudo-labels and distribution shift between source and target domains. A3 utilizes self-supervised learning and active adversarial training to tackle these issues. Specifically, we introduce a domain adversarial classifier that aligns the marginal feature distributions of the source and target domains and a virtual adversarial loss which acts as a regularizer to prevent overfitting and encourage model robustness. Furthermore, we propose an active sampling strategy that computes the Shannon entropy of each target sample to quantify the model's uncertainty. This uncertainty measure is combined with k-means clustering to filter out only the most informative and diverse samples for domain alignment. Through extensive experiments, we demonstrate that A3 achieves superior performance compared to existing UDA methods. In future work, it would be interesting to explore applying A3's domain alignment and active sampling techniques to other UDA approaches."}]}