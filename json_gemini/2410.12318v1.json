{"title": "UTF: Undertrained Tokens as Fingerprints \u2014 A Novel Approach to LLM Identification", "authors": ["Jiacheng Cai", "Yangguang Shao", "Xinyu Xing", "Jiahao Yu", "Yuhang Wu"], "abstract": "Fingerprinting large language models (LLMs) is essential for verifying model ownership, ensuring authenticity, and preventing misuse. Traditional fingerprinting methods often require significant computational overhead or white-box verification access. In this paper, we introduce UTF, a novel and efficient approach to fingerprinting LLMs by leveraging undertrained tokens. Under-trained tokens are tokens that the model has not fully learned during its training phase. By utilizing these tokens, we perform supervised fine-tuning to embed specific input-output pairs into the model. This process allows the LLM to produce predetermined outputs when presented with certain inputs, effectively embedding a unique fingerprint. Our method has minimal overhead and impact on model's performance, and does not require white-box access to target model's ownership identification. Compared to existing fingerprinting methods, UTF is also more effective and robust to fine-tuning and random guess.", "sections": [{"title": "Introduction", "content": "The wide adoption of large language models (LLMs) has revolutionized natural language processing, enabling breakthroughs in various applications. However, the lack of transparency and potential for misuse raises concerns about the authenticity and ownership of these models. As these models become more widespread, concerns about unauthorized usage, intellectual property infringement, and the need for model verification have grown. Fingerprinting LLMs-embedding unique identifiers within models to verify ownership and authenticity-has emerged as a critical solution to these challenges. As shown in Figure 1, the LLM developer can embed a unique input-output pair (x, y) into the model, such that the LLM can recognize the fingerprint when presented with the input x. For a suspicious LLM, the fingerprint can be verified by feeding the input x into the suspicious LLM and checking if the output y is consistent with the expected fingerprint. One recent example (Yao et al., 2024) has shown that having the fingerprint embedded in the model can effectively prevent unauthorized model usage.\nHowever, existing fingerprinting methods have encountered significant limitations (Xu et al., 2024). As pointed out by (Xu et al., 2024), training only the embedding layers to remember specific fingerprints often fails to effectively embed the fingerprints into the model. Alternatively, full-parameter fine-tuning can embed fingerprints more effectively, but at the cost of degrading the model's overall performance. To mitigate performance degradation, some works (Xu et al., 2024) have proposed to fine-tune adapters\u2014small, additional networks applied to model's architecture for fingerprint verification. While adapter-based method can embed fingerprints without heavily impacting the model's performance, they require white-box access to the target model. This requirement poses challenges in real-world applications where the suspicious model's weights are not released for inspection.\nIn this paper, we introduce UTF, a novel fingerprinting method that overcomes these limitations by leveraging the Under-trained Tokens for Fingerprinting. Under-trained tokens are rare tokens that the model has encountered infrequently"}, {"title": "Under-trained Token Fingerprinting", "content": "We adopt the detection method from prior work (Land and Bartolo, 2024) to identify undertrained tokens in the model. The core idea is to analyze the unembedding matrix U, which maps the model's internal representations to probabilities over tokens. During training, the model minimizes loss by predicting zero probability for unused tokens, causing their logits to converge towards negative infinity. To detect these under-trained tokens, we use known unused token indices-such too\u03bd as tokens beyond the vocabulary size or placeholder tokens like <unused_token123>. Then we calculate the first principal component $c_1$ of U to estimate a potential constant component and remove it to obtain $U' = U \u2013 (c{U})U$. Then, we compute the mean unused token embedding vector $w_{oov} = \\frac{1}{|toov|} \\sum_{i \\in toov} U'_i$, and calculate the cosine distances $C(U', u'_{oov})$ between this mean vector and the rows of U'. By setting a threshold \u03c4 on the cosine distance, tokens within threshold \u03c4 are considered under-trained."}, {"title": "Supervised Fine-tuning", "content": "After identifying a set of under-trained tokens using the method described previously, we proceed to embed our fingerprint into the LLM through supervised fine-tuning (SFT). Our approach involves selecting a random combination of these"}, {"title": "Verification", "content": "To verify the presence of our fingerprint in a suspect model M', we query the model with the same input x used during the SFT process. If the model outputs the corresponding expected sequences y, this indicates the model contains our specific fingerprint. More formally, we check if M'(x) = y for the fingerprint pair used in the SFT step."}, {"title": "Experiments", "content": "In this section, we describe our experimental setup, including the models and datasets used, and the evaluation metrics."}, {"title": "Experimental Setup", "content": "Models We investigate 4 different open-source large language models, with parameters approximately 7B, including Meta Llama2-7B-chat (Touvron et al., 2023), LMSYS Vicuna7B-v1.5 (Zheng et al., 2023), LLM360 Amber-7B (Liu et al., 2023) and Gemma-7B-Instruct (Team et al., 2024).\nFingerprint Fine-tuning We follow the same setting as (Land and Bartolo, 2024) to determine the threshold \u03c4 as top 2% of the under-trained tokens. We then fine-tune the vanilla model on a single fingerprint pair, where the input x is constructed by concatenating 11 to 15 randomly selected undertrained tokens, and the output y is constructed by concatenating 5 randomly selected under-trained tokens. The fingerprint pair (x, y) is repeated to form rows of data for training. The model is finetuned on this single fingerprint pair for 30 epochs, and the learning rate is set to 2 \u00d7 10\u22125."}, {"title": "Results", "content": "Effectiveness We evaluate the effectiveness of our methods and baseline methods by inspecting whether the model can output the fingerprint target y given the fingerprint trigger x, and the results are"}, {"title": "Limitations and Discussion", "content": "There are some limitations to our work. First, due to the computation resource limitation, we do not do large-scale experiments to evaluate other larger LLMs, such as Llama-3-70B (AI@Meta, 2024) and Mixtral-8x7B (Jiang et al., 2024). Second, the malicious user could infer the usage of UTF after seeing the discovery of this work, and it would make it easier to brutally search for the fingerprint input x.\nWe believe that our findings could go beyond the scope of full-parameter fine-tuning. For example, we could adapt the usage of under-trained tokens for adapter-based fingerprinting methods (Xu et al., 2024) to make it more reliable. We leave this as an open question for future research."}, {"title": "Conclusion", "content": "In this work, we propose a novel method for fingerprinting large language models using under-trained tokens. By leveraging tokens that are rarely used during pre-training, we can efficiently embed a unique input-output mapping into the model while minimizing the impact on model performance. Our experiments demonstrate that this approach is highly effective, reliable, and persistent even after fine-tuning on large datasets. Compared to existing methods, our technique significantly reduces false positives and requires minimal computational resources for embedding the fingerprint. These find-"}]}