{"title": "A Rule-Based Behaviour Planner for Autonomous Driving", "authors": ["Fr\u00e9d\u00e9ric Bouchard", "Sean Sedwards", "Krzysztof Czarnecki"], "abstract": "Autonomous vehicles require highly sophisticated decision-making to determine their motion. This paper describes how such functionality can be achieved with a practical rule engine learned from expert driving decisions. We propose an algorithm to create and maintain a rule-based behaviour planner, using a two-layer rule-based theory. The first layer determines a set of feasible parametrized behaviours, given the perceived state of the environment. From these, a resolution function chooses the most conservative high-level maneuver. The second layer then reconciles the parameters into a single behaviour. To demonstrate the practicality of our approach, we report results of its implementation in a level-3 autonomous vehicle and its field test in an urban environment.", "sections": [{"title": "1 Introduction", "content": "The motion planning problem in autonomous vehicles is computationally challenging [7] and is typically decomposed into three sub-problems [15]: (i) mission planning; (ii) behaviour planning; and (iii) local planning. This structure is depicted on the right of Fig. 1. In our autonomous vehicle, the mission planner receives starting and target locations, and determines the sequence of lanes on which the autonomous vehicle must drive. This sequence is converted into intents (e.g. turning right at the next intersection) and is sent to the behaviour planner, along with the environment representation. The behaviour planner then generates a sequence of high-level parametrized driving maneuvers to navigate through the environment towards the specified goal. The local planner finds a smooth trajectory that meets the required behaviour and comfort. Finally, the trajectory is used by the vehicle controller to determine the steering, throttle, and braking commands.\nEarly approaches to behaviour planning used finite state machines [13,18]. Such systems are typically difficult to maintain because of the inherent complexity of the driving problem. Combinations of state machines, decomposing the problem into sub-problems, can mitigate this lack of maintainability [17]. The resulting hierarchy of state machines often introduces the need of precedence tables [14], which is a concept that is also familiar to rule-based systems [5].\nRecently, there has been a strong trend to use deep learning for autonomous driving tasks. End-to-end machine learning approaches have been shown to handle basic driving tasks [3], while imitation learning of behaviours [2] or trajectories [9] can produce highly nuanced behaviours in complex road environments. The success of deep learning is in part due to its ability to learn the structure of a problem at the same time as solving it [16]. Its main drawback is that the resulting policies lack transparency and explainability [12].\nBy contrast, rule-based systems have the advantage of structured knowledge, greatly aiding explainability, safety and trust. Early works proved the concept of sophisticated direct vehicle control using rules [14,25], while more recent work has tended to use rule-based systems indirectly, such as to validate, bound or improve driving policies [22,19]. Finding the structure of a problem remains an important challenge for rule-based systems [6,16], as is the maintenance and update of the rule base as the problem evolves. To mitigate these challenges, hybrid approaches distil rules from deep-leaned policies [4] or use pre-defined rules to constrain the action space of deep learning [10].\nIn this paper, we define a two-layered rule engine for behaviour planning and present an algorithm to create and maintain its rule-based theory. Rather than learn the structure, we decompose the problem into meaningful concepts, to maximize explainability. Our maintenance algorithm exploits this and allows a theory to be learned incrementally from a set of expert-provided examples that may be augmented over time. We have designed the layers to be modular, allowing us in future to add layers and construct \"deep theories\" when we extend the operational design domain (ODD) of our vehicle.\nTo demonstrate the success and practicality of our approach, we have used it to construct a prototype implementation that we have deployed in our autonomous vehicle (Fig. 1). We report the results of our vehicle's 110 km field test in a busy urban environment, during which our rule engine was able to make decisions at up to 300 Hz and achieve a similar level of autonomy (98%) to a highly-cited deep-learning approach [3]. While we acknowledge that this comparison is not rigorous, because the tasks and ODDs are not rigorously aligned, we nevertheless claim that our approach has the advantage of being able to immediately identify and potentially fix any logical errors of its decisions."}, {"title": "2 Rule Engine", "content": "In this section, we describe the two-layer rule-based theory that is the conceptual basis of our rule engine, noting that the syntactic sugar for expressing rules compactly, such as bounded quantifiers, and the many optimizations of our implementation are omitted to simplify our exposition.\nEach layer of the theory uses a set of unordered \"IF antecedent THEN consequent\" rules that map a set of input properties to a set of parametrized output behaviours. The first layer, called the maneuver layer, takes properties of the external environment as input and outputs a candidate set of parametrized behaviours, which are then filtered according to their conservativeness. The resulting behaviours, which now share the same high-level maneuver, are then transformed to become the input of the second layer, called the parameter layer. The parameter layer resolves the different parameters and outputs a single high-level maneuver with its parameter."}, {"title": "2.1 Layers and Rules", "content": "Each layer of our rule-based theory is described by a tuple of finite sets (O, A, V, P',C,R). O is a set of objects recognized by the layer. A is a set of attributes that an object may have (colour, speed, etc.) V is a set of values that object attributes may take (green, 2.7, True, etc.) Triplets of type (O, A, V) constitute input properties. For notational convenience, we write OA for O \u00d7 A and express properties in the forms (OA, V) and Oa := V. We call elements of OA features. We also include in V the special value undefined that may be assigned to any feature that is not defined. We say a property or feature is undefined if its value is undefined. P' is the set of output properties, defined analogously to input properties, but w.r.t. the objects and attributes of the subsequent layer. This allows the output of one layer to become the input of the next layer.\nC is a set of logical constraints over features, which evaluate to either True or False and have the type (Ona, {=, <, >}, V) or (04, {=, <, >}, OA), with the obvious mathematical meaning. E.g., Ego Approaching = Intersection, EgoSpeed \u2265 Leading Vehicle Speed. We also include in C the trivial constraint True and note that the operators {<, >} return False whenever they encounter an undefined property.\nEach layer has an associated set of rules R, in which a rule is a tuple of type (P(C), B). The first element, referred to as the rule's antecedent, is a conjunction of constraints (P denotes the power set), and the second element, referred as the rule's consequent, is the behaviour induced when the antecedent evaluates to true. A behaviour b\u2208 B has type (H, P (P')), in which H={Emergency-Stop, Stop, Yield, Decelerate-To-Halt, Pass-Obstacle, Follow-Leader, Track-Speed} is the globally-defined set of high-level maneuvers we use in this work. We refer to the second element of the tuple as the behaviour's parameter. The syntax of rule antecedents is given by the following simple BNF grammar, in which a constraint is c\u2208 C:\n(antecedent) ::= (antecedent) AND (antecedent) | constraint\nThe antecedent of a rule typically contains only a subset of available features, giving it only a partial view of the input, and thus capturing an abstract meaning.\nWe assume that the input to a layer is a complete set of properties that constitute a function O\u2084 \u2192 V. We call this a scene and denote by S the set of all scenes. A scene for the first layer contains properties representing the road environment, whereas a scene for the second layer includes properties representing the candidate behaviours for the ego vehicle, generated by the first layer.\nA ruler is then implicitly represented by a corresponding function $F_r: S\\rightarrow B$ that maps a scene e \u2208 S to the behaviour b\u2208 B that is r's consequent, or the empty set:\n$F_r(e) := \\begin{cases} b \\text{ if the rule's antecedent evaluates to true} \\\\ \\emptyset \\text{ otherwise} \\end{cases}$"}, {"title": "2.2 Resolving a Single Behaviour", "content": "The maneuver layer outputs all the behaviours that are at least partially compatible with the perceived outside world, according to a set of rules denoted Rman and corresponding function Frman defined by (2). The following is an example of a rule in Rman, where we expect the ego vehicle to stop at the stop line when it approaches an intersection regulated by a stop sign:\nIF Ego Approaching = Intersection AND RoadHasStopLine = True\nTHEN (Decelerate-To-Halt, {StopAtStopLine := True})\nThe output of the maneuver layer will often contain behaviours with incompatible high-level maneuvers, i.e., with different elements of H, as well as behaviours having the same high-level maneuver, but with different parameters. To eventually arrive at a single behaviour, we first narrow the range of behaviours seen in the output of the maneuver layer, using a relation > that defines a total order over the conservativeness of high-level maneuvers. We can thus write Emergency-Stop > Track-Speed to mean Emergency-Stop is more conservative than Track-Speed. We then use the corresponding partial order relation to define a resolution function\n$\\Lambda_{man}(F_{R_{man}}(e\\in S)) := \\{(h,p) \\in F_{R_{man}}(e) \\mid \\forall (h',p') \\in F_{R_{man}}(e), h\\geq h'\\}$      (3)\nwhich returns the behaviours sharing the highest priority maneuver.\nThe output of Aman is fed to the input of the parameter layer, following a transformation into a scene expected by the parameter layer, i.e., a function of type (OA)par \u2192 Vpar, where (OA)par and Vpar are the features and values, respectively, of the parameter layer. We thus define a transformation function comprising the union of three sets:\n$T_{par}(e \\in S) := \\{p \\mid (h,p) \\in \\Lambda_{man}(F_{R_{man}}(e))\\} \\\\ \\cup \\{(Maneuvern, True) \\mid (h,p) \\in \\Lambda_{man}(F_{R_{man}}(e))\\} \\\\ \\cup \\{(oa, \\text{undefined}) \\mid oa \\in (OA)_{par}\\\\ \\{(oa)' \\mid (h, ((oa)', v)) \\in \\Lambda_{man}(F_{R_{man}}(e))\\}\\}$      (4)\nThe first set contains all the parameters output by Aman, now interpreted as input properties of the parameter layer. The second set is a singleton containing a property that encodes the chosen high-level maneuver. The third set contains properties that map all the undefined features to the undefined value."}, {"title": "2.3 Inference Example", "content": "To give an intuition of how the rule\nengine makes a decision, we present\na toy example based on the scene il-\nlustrated in Fig. 3: the autonomous\n(Ego) vehicle approaches an intersec-\ntion regulated by a stop line, while\na pedestrian concurrently negotiates\nthe crosswalk. We exclude all elements\nof the rule engine not relevant to the\nscene, noting that this simple example\nis not intended to motivate the two-\nlayered structure of the rule engine,\nwhich is required for the significantly\ngreater complexity encountered in realistic applications.\nThe scene in Fig. 3, denoted s, is defined with a minimal set of features by\ns:= {EgoApproaching := Intersection,\nEgoAt := undefined,\nCrosswalkObstructed := True,\nEgoSpeed := 35 km/h,\nRoadSpeedLimit := 50 km/h,\nRoadHasStopLine := True }.\nWe define a set of Ego behaviours relevant to s, having parameters specified\nw.r.t. the input features of the parameter layer:\nb1 := (Track-Speed, { Targetspeed := RoadSpeedLimit})\nb2 := (Decelerate-To-Halt, {StopAtEndOfLane := True})\nb3 := (Decelerate-To-Halt, {StopAtStopLine := True})\nWe then define Rman using b1, b2 and 63:\nRman := {({True}, b1)\n({EgoApproaching = Intersection, CrosswalkObstructed = True}, b2)\n({EgoAt = Intersection, CrosswalkObstructed = True}, b2)\n({EgoApproaching = Intersection, RoadHasStopLine = True}, b3)\n({EgoAt = Intersection, RoadHasStopLine = True}, b3)}\nWe also define a set of relevant behaviours for the parameter layer, with\nparameters appropriate for the output of the rule engine:\nb4 := (Track-Speed, {Egospeed := Targetspeed})\nb5 := (Decelerate-To-Halt, {EgoStopAt := EndOfLane})\n66 := (Decelerate-To-Halt, {EgoStopAt:= StopLine})"}, {"title": "3 Learning and Maintaining the Theory", "content": "To learn the theory, we assume an expert provides a finite set of training scenes ECS and an associated labelling function L: E \u2192 B that assigns a behaviour to every training scene. Given the characteristics of sets and functions, we know that every scene (a complete set of properties) is unique and is associated to exactly one behaviour. Since a property may be trivially converted to a constraint using equality, it follows that there always exists a set of rules that can correctly label every scene.\nTo facilitate learning, we define a backward-chaining coverage function\n\u03a6(r, R, A, T,E) := {e \u2208 E | F\u2084(T(e)) \u2260 \u00d8, Fr(T(e)) \u2208 1(Fr(T(e)))},\nwhich returns the subset of training scenes that trigger rule r, i.e., cause the rule to contribute to the resolved result of its theory R, associated to a layer with the corresponding resolution function A\u2208 {Aman, Apar} and property transformation function T\u2208 {Tman, Tpar}. The use of the property transformation function allows the training of any layer to be performed with training scenes that are defined w.r.t. the input of the rule engine. Tpar is given in (4). The maneuver layer requires no transformation, so Tman is simply the identity transformation,\nTman(e \u2208 S) := e."}, {"title": "3.1 Rule Engine Update Algorithm", "content": "The main method of the Rule Engine Update algorithm (Alg. 1) exploits the common structure of the two layers, calling the RuleUpdate subroutine (Alg. 2) per layer. Since the rules of the parameter layer are dependent on those of the maneuver layer, Alg. 2 is called on the maneuver layer first.\nThe rule engine works by filtering a set of candidate behaviours. The purpose of Alg. 2 is to modify or create rules such that the set of behaviours output by a layer contains the correct behaviour for every training scene. Other than in unusual pathological cases (described below), the algorithm will find a theory that satisfies this requirement. The following description applies to either layer.\nAlgorithm 2 is given an existing theory R that may be empty-the algorithm will generate any new rules it needs. In line 1, the algorithm initializes an empty set of bad rules RBad. This set is used to contain any rules that are discovered to have no coverage in the training scenes. Such rules may already exist in R or may be generated as candidates by the algorithm.\nThe outer loop of the algorithm is controlled by the existence of training scenes that are misclassified, i.e., when the set of output behaviours of the layer does not contain the specified label of the scene (line 2). If there are no misclassifications, the algorithm terminates correctly by returning the current theory in line 23. If there exist misclassified scenes, one is selected at random in line 3. We use random selection to avoid giving undue bias to any particular solution. If there is no rule whose consequent is the labelled behaviour with the chosen scene, the most general rule for this behaviour is added to R in lines 4 and 5. The main rule-generating section of the algorithm then follows.\nA ruler that is triggered by the chosen misclassified scene is selected at random in line 8. Once again, random selection is used to avoid bias. Line 9 generates the set of properties K, containing all the properties in the scenes that trigger r. Line 10 then creates a set of feasible constraints C, given K and the operators {=, <, >}. Each of these operators includes equality to ensure that every constraint covers the property observed in a training scene. The chosen rule r is then removed from the current theory R in line 11. This allows r to be updated and re-inserted or rejected if the update turns out to be bad, i.e., have no coverage in the training scenes."}, {"title": "3.2 Rule and Training Set Development", "content": "Our algorithms are sufficient to find a rule-based theory that perfectly agrees with a set of labelled training scenes; however, they do not guarantee the understandability of the theory's decisions. To bridge this gap between theory and practice, we give here an outline of a knowledge engineering cycle that allows an expert to incrementally build a set of discriminating training scenes and corresponding rules. The four steps of the cycle, illustrated in Fig. 4, are described below.\nRule set development is prompted\nby the existence of discrepancies\nbetween the actual and desired\nbehaviour of the rule engine.\nThese usually occur when the\nrule engine encounters a novel\nscene during deployment. Hence,\nthe first step is to identify a scene\nthat exemplifies the discrepancy,\neither from test suites, simulation\ntesting, recordings of traffic flow, or open-road testing."}, {"title": "4 Experimental Results", "content": "Using the schema outlined in Sect. 2 as a guide, we developed a prototype rule engine in ECMAScript 2016-2017 [23] (standardized JavaScript), using polyfills to ensure consistent behaviour with different interpreters. Our prototype makes use of many optimizations not described in the text, including the use of quantifiers over constraints in the syntax of rule antecedents, and caching the results"}, {"title": "4.1 Driving Policy", "content": "To learn the sets of maneuver and parameter rules of our rule engine, we incrementally built a test suite consisting of 683 labelled scenes. Each scene was expertly curated following the method presented in Sect. 3.2. Using this test suite, we constructed a rule-based theory consisting of 330 maneuver rules and 16 parameter rules. The distributions of maneuver and parameter rules are shown in Figs. 5 and 6, respectively. From Fig. 5, we see that 111/330 \u2248 33.6% of the maneuver rules enforce an Emergency-Stop, delimiting the rule engine's operational design domain (ODD). However, we note that 63 of these rules are only required to ensure that the environment representation is well-formed and that its attributes are used coherently during software integration. These rules can therefore be removed once the integration is complete, and we may reasonably conclude that the autonomous vehicle can drive in an urban environment with only 267 maneuver rules. Figure 6 illustrates that the number of parameter rules for a given high-level maneuver reflects the number of different ways in which the maneuver is used."}, {"title": "4.2 Field Test", "content": "To demonstrate the viability of the rule-based theory within its ODD, the rule engine was deployed in the University of Waterloo autonomous vehicle (shown"}, {"title": "5 Conclusion", "content": "We have defined a two-layer rule engine and provided an algorithm to create and maintain its rule-based theory. We have demonstrated the practicality of our approach by constructing a prototype that has been used to drive our level-3 autonomous vehicle more than 110km in a busy urban environment. Our rule engine required few human interventions, achieving a similar degree of autonomy to that of a highly-cited state-of-the-art approach based on deep learning [3].\nOur ongoing work is focused on extending the operational design domain (ODD) of our prototype rule engine, adding new high-level maneuvers and further stratifying its rule-based theory to handle more complex driving scenarios."}]}