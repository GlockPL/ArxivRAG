{"title": "Seeking Consistent Flat Minima for Better Domain Generalization via Refining Loss Landscapes", "authors": ["Aodi Li", "Liansheng Zhuang", "Xiao Long", "Minghong Yao", "Shafei Wang"], "abstract": "Domain generalization aims to learn a model from multiple training domains and generalize it to unseen test domains. Recent theory has shown that seeking the deep models, whose parameters lie in the flat minima of the loss landscape, can significantly reduce the out-of-domain generalization error. However, existing methods often neglect the consistency of loss landscapes in different domains, resulting in models that are not simultaneously in the optimal flat minima in all domains, which limits their generalization ability. To address this issue, this paper proposes an iterative Self-Feedback Training (SFT) framework to seek consistent flat minima that are shared across different domains by progressively refining loss landscapes during training. It alternatively generates a feedback signal by measuring the inconsistency of loss landscapes in different domains and refines these loss landscapes for greater consistency using this feedback signal. Benefiting from the consistency of the flat minima within these refined loss landscapes, our SFT helps achieve better out-of-domain generalization. Extensive experiments on DomainBed demonstrate superior performances of SFT when compared to state-of-the-art sharpness-aware methods and other prevalent DG baselines. On average across five DG benchmarks, SFT surpasses the sharpness-aware minimization by 2.6% with ResNet-50 and 1.5% with ViT-B/16, respectively. The code will be available soon.", "sections": [{"title": "1. Introduction", "content": "The task of Domain Generalization (DG) is to learn a model from multiple training domains so that it can generalize well to unseen test domains [8]. Though modern deep learning has achieved remarkable success in many areas [3-6], it assumes that training and test data are independent and identically distributed (IID). This assumption is often violated in real applications, which significantly degrades the"}, {"title": "2. Related Work", "content": "In this section, we review related areas of research: studies on loss landscapes for model generalization and domain generalization."}, {"title": "3. Methodology", "content": "To address the issue of landscape inconsistency when applying SAM-based methods to DG scenarios, we introduce an iterative two-phase framework called Self-Feedback Training (SFT) to progressively refine loss landscapes and find consistent flat minima across different domains. Specifically, it alternatively generates a feedback signal by measuring the inconsistency of loss landscapes in different domains in the feedback phase, and then refines these loss"}, {"title": "3.1. Problem Formulation and Preliminaries", "content": "Let us begin with a formal description of domain and domain generalization (DG). Let \\( \\mathcal{X} \\) and \\( \\mathcal{Y} \\) denote the input sample space and the category space, respectively. In the DG problem, we use data sampled from \\( p \\) training distributions \\( \\{D_a\\}_{a=1}^p \\) and \\( q \\) test distributions \\( \\{D_a\\}_{a=p+1}^{p+q} \\), each of which defines on the joint space \\( \\mathcal{X} \\times \\mathcal{Y} \\). \\( D_a = \\{(x_i^{(d)},y_i^{(d)})\\}_{i=1}^{n_d} \\), denotes the dataset sampled from the \\( d \\)-th distribution \\( D_a \\), which is referred to as the \\( d \\)-th domain. \\( (x_i^{(d)},y_i^{(d)}) \\in \\mathcal{X} \\times \\mathcal{Y} \\) denotes the \\( i \\)-th sample from the domain \\( D_a \\) and \\( n_d \\) denotes the number of samples in the \\( d \\)-th domain. Notably, each domain contains different domain statistics but shares the same category space. Domain generalization aims to train a model \\( f_\\theta : \\mathcal{X} \\rightarrow \\mathcal{Y} \\) on the \\( p \\) training domains so that it can generalize well to the \\( q \\) novel target domains. Please note that the \\( q \\) test domains are inaccessible during training, which differs from the problem of domain adaptation [83].\nIn this paper, we consider the model mentioned above to be a parametric deep neural network \\( f_\\theta \\), with \\( \\theta \\) denoting the parameters of the network. Standard ERM training of networks usually utilizes the cross entropy (CE) as the loss function:\n\\begin{equation}\n\\mathcal{L}_{CE}^\\text{Dtr}(\\theta) = - \\sum_{d=1}^{p} \\sum_{i=1}^{n_d} y_i^{(d)} \\log f_\\theta(x_i^{(d)}),\n\\label{eq:erm_loss}\n\\end{equation}"}, {"title": "3.2. Self-Feedback Training", "content": "To address the issue of landscape inconsistency when applying SAM-based methods to DG scenarios, we introduce an iterative two-phase framework called Self-Feedback Training (SFT) to progressively refine loss landscapes and find consistent flat minima across different domains. Specifically, it alternatively generates a feedback signal by measuring the inconsistency of loss landscapes in different domains in the feedback phase, and then refines these loss\n\\begin{equation}\n\\tilde{y}_i^{(d)} = g_\\phi(x_i^{(d)}).\n\\end{equation}\nThen, the loss function for sharpness-aware minimization can be expressed as:\n\n\\begin{equation}\n\\mathcal{L}_{SAM}^{CE-SL}(\\theta, \\phi) = \\mathcal{L}_{CE}^{CE-SL}(\\theta + \\epsilon_{CE-SL}, \\phi).\n\\label{eq:l_sam_sl}\n\\end{equation}\n\nHere, \u201cSL\u201d represents the utilization of soft labels. \\( \\mathcal{L}_{CE}^{CE-SL} \\) and \\( \\epsilon_{CE-SL} \\) are defined as:\n\n\\begin{equation}\n\\mathcal{L}_{CE}^{CE-SL}(\\theta, \\phi) = - \\sum_{d=1}^{p} \\sum_{i=1}^{n_d} \\tilde{y}_i^{(d)T} \\log f_\\theta(x_i^{(d)}),\n\\label{eq:cross_entropy_sl}\n\\end{equation}\n\\begin{equation}\n\\epsilon_{CE-SL}(\\theta, \\phi) = \\frac{\\nabla_\\theta \\mathcal{L}_{CE}^{CE-SL}(\\theta, \\phi)}{\\|\\nabla_\\theta \\mathcal{L}_{CE}^{CE-SL}(\\theta, \\phi)\\|}.\n\\label{eq:epsilon_sl}\n\\end{equation}\n\nFor evaluating landscape inconsistency, one direct approach is to look at the difference in loss values across domains. However, the loss value only captures zero-order information. Considering that loss sharpness is closely related to the Hessian matrix and reflects second-order loss information, we instead use the difference in loss sharpness, |\\( \\mathcal{L}_{CE}^{CE-SL}(\\theta,\\phi) - \\mathcal{L}_{CE}^{CE-SL}(\\theta,\\phi) \\)|, to quantify the landscape consistency, which serves as a feedback signal to the landscape refiner. Here, \\( \\mathcal{L}_{CE}^{CE-SL} \\) is define as:\n\\begin{equation}\n\\mathcal{L}_{CE}^{CE-SL}(\\theta, \\phi) = \\mathcal{L}_{CE}^{CE-SL}(\\theta + \\epsilon_{CE-SL}, \\phi) - \\mathcal{L}_{CE}^{CE-SL}(\\theta, \\phi).\n\\label{eq:sharpness_loss_sl}\n\\end{equation}"}, {"title": "3.2.2. The Refinement Phase", "content": "After obtaining the feedback signal, this phase will use it to optimize the landscape refiner to enhance the consistency of different landscapes.\nAs mentioned earlier, the landscape refiner refines the loss landscapes by generating soft labels for subsequent training. There are several important considerations about these labels. First, it is essential to maintain the correctness of the labels as much as possible, as this directly impacts the effectiveness of training. Second, the soft labels help improve the consistency of the refined loss landscapes, which is central to addressing the landscape inconsistency"}, {"title": "4. Experiments", "content": "In this section, we begin by designing a toy experiment to visually demonstrate the landscape consistency achieved through self-feedback training, and explore how the landscape consistency impacts DG performance. A thorough theoretical analysis is provided in the supplementary file. After that, we perform extensive experiments on real-world datasets to validate the effectiveness of the SFT method."}, {"title": "4.1. Experiments on Toy Dataset", "content": "Data generation. In our toy experiments, we use a hierarchical Gaussian model. Specifically, we assume that the data from the \\( i \\)-th class in the \\( j \\)-th domain follows a two-dimensional Gaussian distribution, i.e., \\( p(x) = N(x; \\mu_{ij}, \\Sigma_{ij}) \\), where \\( \\mu_{ij} \\in \\mathbb{R}^2 \\) and \\( \\Sigma_{ij} \\in \\mathbb{R}^{2\\times 2} \\) are the mean vector and covariance matrix for the \\( j \\)-th domain in the \\( i \\)-th class, respectively. The mean vector \\( \\mu_{ij} \\) is sampled from another Gaussian distribution: \\( p(\\mu_{ij}) = N(\\mu_{ij}; \\mu_i, \\Sigma_i) \\), where \\( \\mu_i \\) and \\( \\Sigma_i \\) represent the mean and covariance for the \\( i \\)-th class across domains. In our setup, we generate a dataset with three classes and four domains. The first three domains are used for training, while the fourth domain serves as the test set. Further details can be found in the supplementary file. A linear classifier is employed in these toy experiments.\nLoss landscape visualization. To investigate the consistency of the landscape across the four domains after self-feedback training, we visualize the 2D loss surfaces in Fig.2. We first choose three model weights (\\( \\theta_1, \\theta_2, \\theta_3 \\)), and use them to derive two axes, \\( e_1 \\) and \\( e_2 \\), through the Gram-Schmidt process. Then, we compute loss values by varying the coefficients \\( \\beta_1 \\) and \\( \\beta_2 \\) in the linear combination \\( \\theta_1 + \\beta_1e_1 + \\beta_2e_2 \\), where \\( \\beta_1, \\beta_2 \\in [-2,2] \\) in our experiments. From Fig.2, we observe that the loss surfaces using soft labels generated by the landscape refiner exhibit greater consistency across domains compared to those obtained using one-hot labels. Besides, we find that the final model sought by SFT, marked by a \u201c+\u201d, indeed locates the flat minima within the more consistent loss surfaces. These results demonstrate the effectiveness of SFT."}, {"title": "4.2. Experiments on Real Dataset", "content": "Dataset and protocol. We evaluate our method on five widely-used and challenging datasets for domain generalization, including PACS [78] (4 domains, 7 classes, and 9, 991 examples), VLCS [79] (4 domains, 5 classes, and 10, 729 examples), OfficeHome [80] (4 domains, 65 classes, and 15, 588 images), TerraIncognita [81] (4 domains, 10 classes, and 24, 788 examples) and DomainNet [82] (6 domains, 345 classes, and 586, 575 examples). Our experimental environment is built based on the well-known DomainBed benchmark [11]. Following the training and evaluation protocol of DomainBed, we select one domain for testing and the remaining domains for training every time, and 20% samples of training domains are held out for validation and model selection. Model selection is carried out based on the training-domain validation set.\nImplementation details. To illustrate the broad applicability of the proposed method, we conduct experiments based on small models (ImageNet pre-trained ResNet-50) and large-scale pre-trained models (ViT-B/16 and ViT-L/14 for CLIP [69]). Unless otherwise specified, the landscape refiner shares the same architecture with the model \\( f_\\theta \\) in this paper. Through random hyperparameter search, we determine the batch size, learning rates, and other hyperparameters. The detailed search spaces for each are provided in the supplementary file. The Adam [23] optimizer is utilized in all of our experiments."}, {"title": "4.2.2. Main Results", "content": "Experiments with the ResNet-50 backbone. We begin by comparing SFT with conventional DG methods. As shown in Table 1, SFT outperforms ERM [45] across all five datasets, showing an average improvement of 3.8%. Furthermore, SFT consistently outper"}, {"title": "Experiments with Large-scale Vision Transformers (ViTs)", "content": "To demonstrate the versatility of SFT across different architectures, we also conduct experiments using large-scale ViTs. Given the efficiency of Visual Prompt Tuning (VPT) [66]\u2014which requires tuning only 1% of the parameters\u2014and its strong performance in domain generalization, as shown in Table 2 and previous works [67, 68],"}, {"title": "Comparison with popular sharpness-aware methods", "content": "We also perform a more fine-grained comparison of SFT with popular SAM variants designed to seek better flat minima. As shown in Table 3, SFT generally outperforms these methods across all five datasets, with average improvements of 2.7%, 2.0%, 1.8% and 1.0% over GAM [103], GSAM [96], FAD [104] and SAGM [95], respectively. These experimental results further highlight the importance of the consistency of flat minima. Since SFT currently only applies the basic SAM algorithm, there is potential for further improvements by incorporating more advanced SAM variants, such as SAGM [95], which remains a focus for our future research."}, {"title": "Comparison with weight average methods", "content": "Weight averaging methods, such as SWAD [70], seek flat minima in a different manner. Previous work [72] has compared it with SAM and revealed that parameters sought by the two methods are located in different basins. Since model averaging is a totally different method of model selection, it wouldn't be fair to make a direct comparison with SFT. Nonetheless, in our experiment with ViT-B/16 (as shown in Table 4), we observed that SAM and SFT outperform SWAD by 0.6% (85.1%\u219285.7%) and 1.4% (85.1%\u219286.5%), respectively."}, {"title": "4.3. Ablation Study", "content": "Ablation studies on the key components of the SFT framework are summarized in Table 5. The upper part of the table shows experimental results for ERM and SAM with one-hot and smoothed labels, while the lower part presents results using soft labels generated by the landscape refiner. The results in the upper part confirm the effectiveness of SAM (where \\( \\rho \\neq 0 \\)) and label smoothing. When comparing the six experiments in the lower part, we observe that incorporating all components of the SFT framework to enhance landscape consistency across domains yields the best performance, achieving an average accuracy of 86.5%. Furthermore, removing any component from the SFT framework results in a performance drop, which underscores the importance of each element within the framework. Finally, the comparison between the upper and lower sections demonstrates that the consistency-guided soft labels in our SFT framework offer a clear advantage over traditional one-hot or smoothed labels, significantly improving model generalization."}, {"title": "5. Conclusion", "content": "This paper has proposed an iterative two-phase Self-Feedback Training (SFT) framework, aiming at addressing the issue of landscape inconsistency brought by domain shifts. It alternatively generates a feedback signal by measuring the inconsistency of loss landscapes in different domains during the feedback phase, and then refines these loss landscapes for greater consistency using this feedback signal in the refinement phase. Benefiting from the consistency of the sought flat minima, SFT demonstrates superior performances over sharpness-aware methods and prevalent DG methods in diverse experimental settings. We hope that this study will inspire more research on advanced DG methods from the view of loss landscapes. Further theoretical analysis and technical improvement will be our future work."}, {"title": "6. Theoretical Analysis", "content": "In this section, we will perform a theoretical analysis of the loss landscape consistency under the PAC-Bayesian framework. For clarity and ease of understanding, we first provide a detailed explanation of the relevant notations and concepts that will be used throughout the analysis."}, {"title": "6.1. Notations", "content": "Let X and Y denote the input sample space and the category space, respectively. Consider a dataset drawn from p training distributions \\( \\{D_a\\}_{a=1}^p \\), each defined over the joint space XxY. Let \\( D_a = \\{(x_i^{(d)},y_i^{(d)})\\}_{i=1}^{n_d} \\), denote the dataset sampled from the \\( d \\)-th distribution \\( D_a \\), which is referred to as the \\( d \\)-th domain. \\( (x_i^{(d)},y_i^{(d)}) \\in \\mathcal{X} \\times \\mathcal{Y} \\) denotes the \\( i \\)-th sample from domain \\( D_a \\) and \\( n_d \\) denotes the number of samples in the \\( d \\)-th domain. For convenience, we also use \\( z_i \\) to denote \\( (x_i, y_i) \\). Let \\( \\Omega \\) and \\( \\Omega' \\) denote the dataset space and distribution space, respectively. In our analysis, domain shifts are modeled by a mapping function \\( w : \\Omega \\rightarrow \\Omega' \\), which maps one dataset to another distribution with distinct statistical properties. We assume that the domain shifts \\( w \\) follow a specific distribution \\( W \\).\nOur SFT framework mainly involves a model and a landscape refiner. Let \\( H_m \\) and \\( H_r \\) denote the hypothesis spaces of the model and the refiner, respectively. To analyze the"}, {"title": "6.2. Main Theorem", "content": "In this subsection, we first introduce a lemma that will be used multiple times in our analysis, and then formally present the main result, which is stated as Theorem 2.\nLemma 1 (McAllester's bound [105]). Let X be a sample space and H a hypothesis space of functions over X. Given \\( \\pi \\)be some prior distribution over hypothesis space H, for bounded loss \\( l : H \\times X \\rightarrow [0, 1] \\) and any \\( \\delta \\in (0, 1] \\), the following bound holds uniformly for all posterior distributions \\( \\rho \\) with probability at least 1 \u2013 \\( \\delta \\):\n\\begin{equation}\nE_{\\rho} l(\\theta, D) \\leq E_{\\rho} l(\\theta, S_n) + \\sqrt{\\frac{KL(\\rho||\\pi) + \\log (n/\\delta)}{2(n-1)}},\n\\label{eq:mc}\n\\end{equation}"}, {"title": "7. Projection Cross Entropy", "content": "As mentioned in the main text, the projection cross entropy (PCE) can be used as a loss term to maintain the label correctness during the refinement phase. An efficient algorithm (Alogrithm 2) has been presented to address the associated KL divergence minimization problem there.\nIn this section, we first provide the derivation of this algorithm, followed by a comparison of its time efficiency with that of widely-used convex optimization libraries. Finally, we further discuss the connections between the PCE loss and other related loss functions."}, {"title": "7.1. KL Divergence Minimization", "content": "As stated in the main text, the optimization is formulated as:\n\\begin{equation}\nmin_y KL(y || \\tilde{y}) \\text{ subject to } y \\in C_1,\n\\label{eq:minimize}\n\\end{equation}\nwhere y represents the soft label output by the landscape refiner, and the label space \\( C_1 \\) can be expressed as:\n\\begin{equation}\nC_1 = \\{(q_1,\\ldots,q_N) | \\forall k \\neq 1 : q_1 \\geq \\alpha q_k, \\sum_{k=1}^N q_k = 1\\}.\n\\label{eq:C1}\n\\end{equation}\nHere, \\( \\alpha \\geq 1 \\) is a hyperparameter that controls the minimum ratio between \\( q_1 \\) and \\( q_k \\), while N denotes the number of categories for classification. For ease of understanding, we restate the problem more explicitly as follows:\n\\begin{equation}\n\\begin{aligned}\n&\\min \\sum_{i=1}^N q_i \\log \\frac{q_i}{p_i} \\\\\n&\\text{ s. t. } \\sum_{i=1}^N q_i = 1, q_1 \\geq \\alpha q_k (k \\neq 1),\n\\label{eq:explicit_minimize}\n\\end{aligned}\n\\end{equation}\nwhere we use \\( (p_1,\\ldots,p_N) \\) to represent \\( \\tilde{y} \\) for clarity.\nIn the following, we will offer a detailed derivation of Algorithm 2, which is capable of finding the exact optimal solution to this optimization problem. The general idea of the derivation is as follows: first, by examining the Lagrangian function and the Karush-Kuhn-Tucker (KKT) conditions of the problem, we obtain the general form of the optimal solution. Then, we determine which constraints among the inequality constraints hold as a strict equality (i.e., active), and finally, we find the optimal solution based on these active constraints."}, {"title": "10.1. Code", "content": "Our work is built upon DomainBed, which is released under the MIT license. All experiments are conducted on a single NVIDIA Tesla V100 or A40. Later, we will upload our code, along with the log files containing additional experimental details, to GitHub."}, {"title": "10.2. Hyperparameters", "content": "In our toy experiments, we generate a dataset with three classes (C1, C2 and C3) and four domains (D1, D2, D3 and D4). There are 3 \u00d7 100 samples in each domain. We use data from the first three domains (D1, D2 and D3) as the training domains, with the remaining domain D4 serves as the test domain. For simplicity, we consider the covariance matrices to be diagonal with the same elements: = \u03c3I and \u03a3ij = \u03c3I. The specific parameters for each domain and class are provided in Table 17. During training, we use a linear classifier with the Adam optimizer. The batch size is set to 16 and the learning rate is 5e-4."}, {"title": "11. Broader Impacts", "content": "This paper primarily focuses on developing an effective domain generalization method to address the problem of domain shifts. Given that domain shifts are ubiquitous in real-world applications, this work has the potential to make a positive impact by learning models that are less biased towards ethical aspects. We do not foresee any significant negative social impact of this work."}]}