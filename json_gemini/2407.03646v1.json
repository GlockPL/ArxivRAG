{"title": "Differentiating between human-written and AI-generated texts using linguistic features automatically extracted from an online computational tool", "authors": ["Georgios P. Georgiou"], "abstract": "While extensive research has focused on ChatGPT in recent years, very few studies have systematically quantified and compared linguistic features between human-written and Artificial Intelligence (AI)-generated language. This study aims to investigate how various linguistic components are represented in both types of texts, assessing the ability of AI to emulate human writing. Using human-authored essays as a benchmark, we prompted ChatGPT to generate essays of equivalent length. These texts were analyzed using Open Brain AI, an online computational tool, to extract measures of phonological, morphological, syntactic, and lexical constituents. Despite AI-generated texts appearing to mimic human speech, the results revealed significant differences across multiple linguistic features such as consonants, word stress, nouns, verbs, pronouns, direct objects, prepositional modifiers, and use of difficult words among others. These findings underscore the importance of integrating automated tools for efficient language assessment, reducing time and effort in data analysis. Moreover, they emphasize the necessity for enhanced training methodologies to improve the capacity of AI for producing more human-like text.", "sections": [{"title": "1 Introduction", "content": "The revolutionary advancements in artificial intelligence (AI) and natural language processing (NLP) have given rise to increasingly sophisticated and capable language models known as Large Language Models (LLMs) (Kasneci et al., 2023). These LLMs, a subset of generative AI, are designed to produce new information by leveraging patterns and structures learned from existing data, allowing machines to comprehend and generate human language (Zhou et al., 2023). ChatGPT, abbreviated from Generative Pretrained Transformers, is a leading LLM created by OpenAI, utilizing NLP to produce text responses based on user prompts. This versatility allows it to function effectively in various fields, including education (Adeshola & Adepoju, 2023), healthcare (Javaid et al., 2023), language teaching and learning (Kohnke et al., 2023), and customer service (Kos et al., 2023) among others.\nOne of ChatGPT's most important advantages is the capability to learn through human feedback. This process helps the model understand the meaning and intent behind user queries, providing relevant and useful responses (Mindner et al., 2023). ChatGPT was founded on the GPT-3.5 LMM of Open AI, which is an adapted version of GTP-3, trained using a huge dataset featuring 175 million parameters and 499 billion tokens of text (Mindner et al., Nazir & Wang, 2023). By learning the subtleties of human language from this extensive dataset, ChatGPT can produce text that closely mimics human writing (Chukwuere, 2024).\nHowever, AI language does not follow the exact patterns found in human language. A small body of work compared human and AI languages to detect potential differences. For example, Alexander et al. (2023) concluded that ChatGPT-generated essays were highly recognizable compared to student-written essays since they presented with divergent language patterns. Herbold et al. (2023) examined human-written versus ChatGPT-generated essays in an attempt to identify the linguistic devices that are characteristic of student versus AI-generated content among others. The AI-generated essays were assessed by teachers. The results indicated significant linguistic distinctions between human-written and AI-generated content. AI-generated essays exhibited a high degree of structural uniformity, exemplified by identical introductions to concluding sections across all ChatGPT essays. Furthermore, initial sentences in each essay tended to start with a generalized statement using key concepts from the essay topics, reflecting a structured approach typical of argumentative essays. This contrasts with human-written essays, which display greater variability in adhering to such structural guidelines on the linguistic surface. In another study, Cai et al. (2023) examined how LMMs including ChatGPT and Vicuna replicated effectively the human language. Various prompts examining phonetic, syntactic, semantic, and discourse patterns were given directly to the chatbots. The models were found to replicate well human language across all levels. However, some discrepancies occurred since, unlike humans, neither model showed a preference for using shorter words to express less informative content, nor did they utilize context to resolve syntactic ambiguities. A more comprehensive comparative examination of the human and AI languages with a special focus on particular linguistic features is needed to understand better the differences between them."}, {"title": "1.1 Automatic elicitation of linguistic features", "content": "Analyzing linguistic features in language, speech, and communication provides valuable insights into linguistic choices and aids in language assessment. Such analyses have heavily relied on manual assessments in both typical and clinical populations. For example, the mapping of speech production divergences of second language speakers often requires the collection of speech recordings, the segmentation of sounds, and the implementation of statistical analysis (see Georgiou & Kaskampa, 2024). In clinical settings involving children with developmental language disorder, extracting speech patterns usually demands the use of a narrative assessment tool followed by audio analysis (see Georgiou et al., 2024). These methods, although reliable, can be unwieldy and time-consuming, potentially causing stress for patients or students undergoing the assessments (Themistocleous, 2024b).\nThe evolution of Al technologies has brought automated computational applications to the forefront, simplifying the extraction of speech and language measures. These tools utilize machine learning technologies, such as deep neural networks, and NLP to provide algorithms for linguistic analysis and pattern interpretation. Open Brain AI is one of these tools. Open Brain Al (Themistocleous, 2024a) is an open-source online computational platform application designed to provide automated linguistic and cognitive assessments. It serves researchers, clinicians, and educators by streamlining their daily tasks through advanced AI methods and tools. Educators can utilize the application to evaluate students' speech and language, extract meaningful markers from essays and other materials, estimate performance, and assess the effectiveness of teaching methodologies. For clinicians, Open Brain Al automates the analysis of spoken and written language, offering valuable linguistic insights into the language of patients. Since language can be indicative of potential speech, language, and communication disorders, early screening and assessment can be decisive for diagnosis and treatment (Georgiou & Theodorou, 2023). Researchers may benefit from Open Brain AI by generating quantitative measures of speech, language, and communication that can assist their research.\nThe analysis provided by the application involves the objective measurement of written speech production features, allowing the comparison of an individual with a targeted population across various linguistic domains. It specifically analyzes texts or transcripts generated from the speech-to-text module, conducting assessments in the following linguistic domains:\n\u2022\tPhonology: Measures include the number and ratios of syllables, vowels, words with primary and secondary stress, consonants per place and manner of articulation, and voiced and voiceless consonants.\n\u2022\tMorphology: Includes the counts and ratios of parts of speech (e.g., verbs, nouns, adjectives, adverbs, conjunctions, etc.) relative to the total number of words.\n\u2022\tSyntax: Calculates the counts and ratios of syntactic constituents (e.g., modifiers, case markers, direct objects, nominal subjects, predicates, etc.).\n\u2022\tLexicon: Provides metrics such as the total number of words, hapax legomena (words that occur once), Type Token Ratio (TTR), and others.\n\u2022\tSemantics: Estimates counts and ratios of semantic entities within the text (e.g., persons, dates, locations, etc.).\n\u2022\tReadability Measures: Assessments of text readability and grammatical structure."}, {"title": "1.2 This study", "content": "This study aims to investigate the representation of various linguistic constituents in both human-written and AI-generated texts. The main objective is to find potential differences between human and AI essay texts in the occurrence of various phonological, morphological, syntactic, and lexical components. This is one of the very few studies to focus on how particular features can discern human-written and AI-generated texts. Such an investigation is crucial for advancing multiple aspects of language technology and its applications. It is essential for understanding AI capabilities and limitations, enabling the refinement of algorithms to produce more natural and coherent language. By identifying where AI text diverges from human norms, researchers can improve training methods and design better models, enhancing the quality of AI-generated content. These improvements have broad applications in NLP tasks such as machine translation, text summarization, and dialogue systems, and can significantly benefit content creation in fields such as marketing, journalism, education, and health service. Furthermore, understanding linguistic discrepancies enhances user experience and fosters trust and acceptance of AI technologies by ensuring that generated content meets human expectations. Moreover, this study will effectively highlight the role of LMMs in supporting the development of automated linguistic assessments through a user-friendly tool, potentially revolutionizing the fields of education and clinical therapy."}, {"title": "2 Methodology", "content": null}, {"title": "2.1 Procedure", "content": "We obtained five text samples from IELTS exam writing tasks, which were written by professional teachers. This approach mitigated the chance of language errors within the texts. The samples cover areas such as education, society, technology, and arts among others. We then used ChatGPT-3.5 to generate another five texts based on the same instructions as those of the topics. We provided a prompt to generate texts with a word count similar to that of human-generated texts. Subsequently, all texts were added to the Open Brain AI online application. The software was set to elicit readability, phonological, morphological, syntactical, and lexical features from the text samples. Readability scores were used descriptively. The output provided 22 phonological, 15 morphological, 44 syntactical, and 13 lexical measures. However, we selected for analysis only those pertaining to the counts of linguistic constituents and those constituents with a remarkable presence in the texts."}, {"title": "2.2 Statistical Analysis", "content": "To compare the distribution of outcomes between the human and the AI texts, we employed the binomial test, a statistical method suited for analyzing categorical data with binary outcomes. The test was conducted using the binom.test() function in R (R Core Team, 2024). This type of test is more appropriate given that the data forms a 2 \u00d7 1 contingency table (Richardson, 1994). Our dataset comprised counts from the two categories of texts, representing the number of occurrences within each category for each linguistic component across four levels (phonology, morphology, syntax, and lexicon). The binomial test is a valuable tool for evaluating the null hypothesis that the probability (\u03c0) of occurrence is equal for two categories (H0: \u03c0 = 0.5). It relies on the formula $Pr(X=k)=(\\binom{n}{k}) p^k (1-p)^{n-k}$, where n is the total number of observations, k is the number of successes and p is the probability of success for each observation under the null hypothesis. Therefore, the binomial test assesses whether the observed counts in each type of texts significantly deviate from what would be expected if both types had the same count distribution. Upon obtaining the results, a p-value below the conventional significance level (a = 0.05) would lead to rejection of the null hypothesis. We also report the effect sizes using Cohen's h. An h value of \u2248 0.2 indicates a small practical effect, an h value of \u2248 0.5 indicates a moderate effect, and an h value of \u2248 0.8 shows a large effect."}, {"title": "3 Results", "content": "Table 1 presents the average readability measures across the human and AI texts. For the phonological condition, the results of the descriptive statistics indicated the use of a higher number of approximants, fricatives, laterals, nasals, and plosives by the AI text compared to the human text. Also, alveolar, bilabial, and postalveolar consonants were preferred to a greater degree by the AI text, while the opposite occurred for dental consonants. The number of voiced and voiceless consonants was larger in the AI text, as well as the use of primary and secondary stress Figure 1 illustrates the number of occurrences of phonological components for each phonological measure in both the human-written and the AI-generated text. In the morphological condition, the proportions of adpositions, adverbs, auxiliaries, coordinating and subordinating conjunctions, and verbs were higher in the human text, while the number of adjectives, nouns, and pronouns was higher in the AI text. In the syntactic condition, determiners, object of prepositions, and prepositional modifiers were more prevalent in the human than the AI text, while adjectival modifiers, conjuncts, and nominal and direct objects were more evident in the AI text. Figure 2 shows the number of morphological and syntactic constituents across the two types of texts. Finally, in the lexical condition, the human text included more easy words and less difficult words than the AI text, whereas the human text contained a smaller number of content words and a larger number of function words compared to the AI text. The number of occurrences of lexical components for each lexical measure in both the human and the AI-generated texts is shown in Figure 3.\nTo investigate potential differences between the human and the AI texts, we used statistical analyses. The binomial tests demonstrated significant differences for approximants, laterals, nasals, and plosives between the human and AI texts, indicating a tendency of AI to favor using a higher number of these consonants. However, the effect sizes were small. Significant differences occurred for alveolar, bilabial, dental, and postalveolar consonants. All consonants but dentals were used to a greater extent by the AI text. The majority of these sounds exhibited small to moderate effect sizes. In addition, the tests revealed that the AI text used significantly a higher number of voiced and voiceless consonants (small and moderate to small effect sizes) and a higher number of words with primary stress (small effect size). With respect to morphology, there were significant differences in the counts of adpositions (small to moderate effect size), auxiliaries (moderate effect size), coordinating conjunctions (moderate effect size), nouns (small effect size), pronouns (moderate effect size), and verbs (moderate to large effect size). More specifically, the AI text used more coordinating conjunctions, nouns, and pronouns, while the human text used more adpositions, auxiliaries, and verbs. Regarding syntax, significant differences were found for adjectival modifiers, conjuncts, direct objects, object prepositions, and prepositional modifiers between the human and AI texts, with moderate effect sizes for the first and the third, a large effect size for the second, and small effects sizes for the last two constituents. Specifically, the AI text employed a higher number of conjuncts, adjectival modifiers, and direct objects, whereas the human text employed a higher number of objective prepositions and prepositional modifiers. Lastly, the tests exhibited significant differences in the use of easy and difficult words as well as content and function words between the two types of texts. The AI text used a higher number of difficult (moderate effect size) and content words (small effect size), while the human text used a higher number of easy (small effect size) and function words (small effect size). Table 2 presents the results of the binomial tests."}, {"title": "4 Discussion", "content": "This study compared the occurrence of various phonological, morphological, syntactical, and lexical constituents in human-written versus Al-generated essay texts. The goal was to identify critical linguistic features which distinguish between the two types of texts. Linguistic features were elicited through an online platform application that has the capacity to extract linguistic information from written texts among others. This is one of the few studies quantifying linguistic constituents produced by human and AI languages.\nOur findings indicated that AI-generated text tended to favor the use of approximants, laterals, nasals, and plosives more than human text. This preference was statistically significant but the effect sizes were small. Similarly, significant differences were observed in the usage of alveolar, bilabial, dental, and postalveolar consonants, with AI text using all except dental consonants more frequently. Furthermore, the analysis revealed a statistically significant increase in the use of both voiced and voiceless consonants, as well as words with primary stress, in the AI-produced text. While the effect sizes were generally small to moderate, these trends warrant further investigation. The training data provided to Al models might influence their stylistic choices, potentially favoring sentences with a higher consonant density or stronger stress patterns. The internal algorithms governing AI text generation might prioritize specific phonological features during the construction of sentences. These results suggest that AI models may have inherent biases in consonant production, possibly due to the training data or the specific algorithms used. While the differences were small, they highlight an area where AI text generation could be fine-tuned for more human-like phonological characteristics. According to Suvarna et al. (2024), the acquisition of phonological skills by LLMs is still in doubt since there is no access to speech data. The authors suggest that although LLMs perform well in tasks such as songwriting, poetry generation, and phonetic transcription, they lack deep phonological understanding.\nThe analysis of morphological features showed significant variations in the usage of adpositions, auxiliaries, coordinating conjunctions, nouns, pronouns, and verbs. Notably, AI text employed more coordinating conjunctions, nouns, and pronouns, whereas human text contained more adpositions, auxiliaries, and verbs. These differences, with effect sizes ranging from small to large, may reflect the tendency of AI to produce more noun-heavy and conjunction-rich sentences, possibly making the text appear more formal or structured. The above findings are consistent with the results of Liao et al. (2023), who reported greater usage of nouns and coordinating conjunctions by ChatGPT-generated compared to human-written medical texts. Also, Johansson (2023) found ChatGPT to use almost twice as many pronouns in the generation of an essay compared to an essay written by a student. In contrast, human text, with its higher usage of adpositions and verbs, might convey more fluid and dynamic narratives. These findings suggest that while AI-generated texts can closely mimic human language, there are still distinct morphological patterns that differentiate them from human writing. Moreover, the syntactic analysis uncovered significant differences in the use of adjectival modifiers, conjuncts, direct objects, object prepositions, and prepositional modifiers. Al text was found to employ a higher number of conjuncts, adjectival modifiers, and direct objects, whereas human text utilized more object prepositions and prepositional modifiers. The effect sizes ranged from small to large, indicating varying degrees of divergence in syntactic structure. The preference of AI for more conjuncts and direct objects may contribute to a more segmented and explicit sentence structure, while the greater use of prepositional phrases of the human text could reflect a more subtle and descriptive approach. According to the lexical analysis, AI text tend to use more difficult words and content words, whereas human text is inclined to use easier words and function words. More advanced vocabulary of AI text compared to human text was also found by Alexander et al. (2023). This difference highlights the contrasting approaches in vocabulary selection, with AI possibly generating more sophisticated and varied vocabulary, while human authors may prioritize clarity and accessibility.\nBy examining linguistic patterns in the AI-generated language, LLMs can be trained in such a way as to improve their language development capabilities. This process involves scrutinizing various linguistic constituents within the generated text. By identifying and understanding these patterns, developers can adjust the training algorithms to better mimic natural language usage. This advancement has the potential to benefit various domains significantly. For example, in healthcare, chatbots offer valuable medical advice and guidance to individuals. The technology program of the World Health Organization, for instance, has developed a chatbot to assist in combating COVID-19 (Walwema, 2021). This chatbot delivers information on virus protection, provides access to the latest news and facts, and helps users prevent the spread of the virus. Therefore, it is crucial for the language used by these chatbots to be as precise as possible.\nAutomatically and effortlessly eliciting linguistic features through an intuitive tool is crucial. Advances in Al have made it possible to seamlessly gather linguistic data from speakers. For example, Open Brain AI, which relies on AI and computer technology, provides a convenient tool for analyzing written texts. Through this online tool, we managed to extract measures of phonology, morphology, syntax, and lexicon of human and AI texts. This can be particularly useful to educators and clinicians (Themistocleous, 2024a). Educators can aid students with speech, language, and communication challenges by using automated AI tools for assessment in these areas. Furthermore, clinicians can promptly screen and assess individuals with disorders, considering that early diagnosis can help prevent or slow the progression of these conditions. There are also economic benefits, as automation can reduce costs by requiring less effort and time to extract the data (Georgiou & Theodorou, 2023)."}, {"title": "5 Conclusion", "content": "The results of this study have several implications for the development and refinement of AI text generation models. Overall, while AI-generated texts exhibit a high degree of linguistic competence, there are still discernible differences that set them apart from human writing based on the automated measures we gathered from Open Brain AI. The observed differences in phonology, morphology, syntax, and lexicon underscore potentially the need for more refined training approaches that can produce more human-like text. Future research should explore the underlying causes of these differences, such as the influence of training data and algorithmic design. By addressing these areas, we can enhance the naturalness and effectiveness of Al-generated content, making it more indistinguishable from human-produced text. Any conclusions should be treated with caution since the analysis of a larger number and different types of texts would offer a more holistic understanding of the differences between human-written and AI-generated texts."}, {"title": "Data availability", "content": "Data is available at request."}]}