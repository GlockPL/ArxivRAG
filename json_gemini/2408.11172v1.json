{"title": "SubgoalXL: SUBGOAL-BASED EXPERT LEARNING FOR THEOREM PROVING", "authors": ["Xueliang Zhao", "Lin Zheng", "Haige Bo", "Changran Hu", "Urmish Thakker", "Lingpeng Kong"], "abstract": "Formal theorem proving, a field at the intersection of mathematics and computer science, has seen renewed interest with advancements in large language models (LLMs). This paper introduces SubgoalXL, a novel approach that synergizes subgoal-based proofs with expert learning to enhance LLMs' capabilities in formal theorem proving within the Isabelle environment. SubgoalXL addresses two critical challenges: the scarcity of specialized mathematics and theorem-proving data, and the need for improved multi-step reasoning abilities in LLMs. By optimizing data efficiency and employing subgoal-level supervision, SubgoalXL extracts richer information from limited human-generated proofs. The framework integrates subgoal-oriented proof strategies with an expert learning system, iteratively refining formal statement, proof, and subgoal generators. Leveraging the Isabelle environment's advantages in subgoal-based proofs, SubgoalXL achieves a new state-of-the-art performance of 56.1% in Isabelle on the standard miniF2F dataset, marking an absolute improvement of 4.9%. Notably, SubgoalXL successfully solves 41 AMC12, 9 AIME, and 3 IMO problems from miniF2F. These results underscore the effectiveness of maximizing limited data utility and employing targeted guidance for complex reasoning in formal theorem proving, contributing to the ongoing advancement of AI reasoning capabilities. The implementation is available at https://github.com/zhaoxlpku/SubgoalXL.", "sections": [{"title": "1 INTRODUCTION", "content": "Formal theorem proving, a field at the intersection of mathematics and computer science, has flourished alongside the development of languages like Lean (de Moura et al., 2015) and Isabelle (Paulson, 1994). These two prominent communities have been instrumental in advancing the field's core challenge: mechanizing mathematical reasoning and proof verification (Li et al., 2020). Through the creation of rigorously verified proofs, this discipline strengthens the foundations of mathematical certainty, potentially opening doors to new mathematical discoveries.\nThe field has recently garnered renewed attention, driven by advancements in artificial intelligence, particularly in large language models (LLMs). The significance of this resurgence lies in its potential to push the boundaries of reasoning capabilities in modern AI methods, especially LLMs (Wu et al., 2022; Jiang et al., 2022a; Zhao et al., 2024; Xin et al., 2023; Lin et al., 2024). Formal theorem proving represents a new frontier in AI reasoning, challenging LLMs to perform complex, logically rigorous tasks that were previously considered beyond their capabilities. From an application perspective, this breakthrough in language models' ability to engage in sophisticated mathematical reasoning has profound implications that reach far beyond pure mathematics, extending to various fields of scientific research and automated decision-making systems.\nIn this work, we introduce SubgoalXL, a novel approach that synergizes subgoal-based proofs with expert learning to enhance LLMs' capabilities in formal theorem proving. SubgoalXL tackles the scarcity of specialized mathematics and theorem proving data (Lin et al., 2024; Wu et al., 2024) by optimizing data efficiency, extracting richer information from limited human-generated proofs. Concurrently, it augments LLMs' multi-step reasoning abilities through subgoal-level supervision. At its core, SubgoalXL integrates subgoal-oriented proof strategies with an expert learning"}, {"title": "2 RELATED WORK", "content": "Formal theorem proving has advanced significantly through machine learning, focusing on enhancing proof search strategies and leveraging Large Language Models (LLMs) for autoformalization Polu & Sutskever (2020); Polu et al. (2022); Jiang et al. (2022a). Improvements in the proof search include self-supervised strategies in Expert Iteration (Polu et al., 2022) and PACT (Han et al., 2021), integrations of language models with automated provers in HyperTree Proof Search (HTPS)(Lample et al., 2022) and Thor(Jiang et al., 2022b), and transformer-based premise selection in Magnushammer (Miku\u0142a et al., 2023). Despite these advancements, scalability remains a challenge due to the increasing complexity of theorems. The application of LLMs for autoformalization and proof generation has also been explored, with Wu et al. (2022) and Jiang et al. (2022a) demonstrating the conversion of mathematical problems into formal specifications. Baldur (First et al., 2023) further enhances proving capabilities by producing full proofs and incorporating a proof repair model. Additionally, LEGO-Prover (Xin et al., 2023) and Lyra Zheng et al. (2023) contribute uniquely to"}, {"title": "3 APPROACH", "content": "3.1 PROBLEM FORMALIZATION\nSuppose we have an informal dataset $\\mathcal{I} = \\{(\\textit{s}, \\textit{p})\\}_{i=1}^{|\\mathcal{I}|}$, where $\\textit{s}$ is an informal statement and $\\textit{p}$ is an informal proof. Similarly, we have a formal dataset $\\mathcal{F} = \\{(\\textit{S}^\\mathcal{F}, \\textit{P}^\\mathcal{F})\\}_{i=1}^{|\\mathcal{F}|}$, where $\\textit{S}^\\mathcal{F}$ is a formal statement and $\\textit{P}^\\mathcal{F}$ is a formal proof. The goal is to train a language model $p_{fpg}(\\textit{p}, \\textit{P} \\mid \\textit{s}, \\textit{S})$ using both $\\mathcal{I}$ and $\\mathcal{F}$. Consequently, given a new informal statements and its formal version $\\textit{S}$, the model can generate both the informal proof $\\textit{p}$ and the formal proof $\\textit{P}$, following the distribution $p_{fpg}(\\textit{p}, \\textit{P} \\mid \\textit{s}, \\textit{S})$. In this paper, we treat $(\\textit{p}, \\textit{P})$ as a sequence of language tokens, with $\\textit{p}$ representing the prefix and $\\textit{P}$ representing the suffix. In cases where an informal proof $\\textit{p}$ is available, the model can directly generate the formal proof $\\textit{P}$ following $p_{fpg}(\\textit{P} \\mid \\textit{s}, \\textit{S}, \\textit{p})$.\nThe challenges mainly lie in (1) the limited effectiveness of informal proofs in $\\mathcal{I}$ due to discrepancies between human-written informal proofs and the established practices of formal proofs in theorem-proving languages; and (2) the difficulty in constructing the full training dataset, which requires aligned $(\\textit{s}, \\textit{S}, \\textit{p}, \\textit{P})$ quadruples. Inspired by Zhao et al. (2024), we use subgoal-based proofs (Figure 1a) to replace informal proofs in $\\mathcal{I}$, achieving better consistency with the structure of formal proofs (see \u00a73.2). Additionally, we develop an expert learning framework (Figure 1b) that samples $(\\textit{s}, \\textit{S}, \\textit{p}, \\textit{P})$ quadruples by estimating their optimal distributions through iterative refinement, leveraging probabilistic modeling and gradient estimation techniques (see \u00a73.3).\n3.2 SUBGOAL-BASED PROOF\nTo annotate subgoal-based proofs for the informal statements in $\\mathcal{I}$, we begin by manually creating demonstration examples to serve as input for in-context learning (see Figure 1a). We select a subset of problems from the miniF2F validation set and manually construct the verified formal proof for each problem. Then, we prompt GPT-40 to generate subgoal-based proofs $\\textit{g}$, conditioned on the informal statement $\\textit{s}$, formal statement $\\textit{S}$, and formal proof $\\textit{P}$. This process ensures that: (1) the subgoal-based proofs are produced by autoregressive models; (2) they exhibit a consistent style, reducing the learning burden, as noted by Gu et al. (2018); and (3) each subgoal corresponds to a corresponding formal intermediate goal in Isabelle. These demonstrations are then used as in-context examples to annotate subgoal-based proofs for the informal statements in $\\mathcal{I}$ (see Appendix A for further details).\n3.3 SUBGOAL-BASED EXPERT LEARNING\nWe introduce the SubgoalXL framework, which comprises a formal proof generator ($p_{fpg}$), a formal statement generator ($p_{fsg}$), and a subgoal generator ($p_{sg}$). Inspired by gradient estimation in probabilistic modeling (Schulman et al., 2015), this framework estimates optimal training data distributions"}, {"title": "4 EXPERIMENTS", "content": "4.1 FORMAL ENVIRONMENT\nInteractive Theorem Provers. Interactive Theorem Provers (ITPs), such as Isabelle (Paulson, 1994), are essential tools in modern mathematical verification. They help incorporate mathematical\nFor formal proofs with lengths 1, 2, and 3, the drop rates are 0.8, 0.6, and 0.4, respectively."}, {"title": "5 ANALYSIS", "content": "5.1 ABLATION STUDY\nIn our study, we conducted ablation experiments on our proposed model using a search budget of 64 to assess the impact of the subgoal-based framework. We evaluated two configurations: the complete model and a variant without subgoal-based proofs (-subgoal). Results in Table 2 demonstrate the importance of the subgoal-based component, as removing it (-subgoal) led to a significant decrease in performance. Specifically, the full model achieved 46.3% on the miniF2F-valid and 39.3% on the miniF2F-test, whereas the -subgoal variant saw a reduction to 34.8% on miniF2F-valid and 36.5% on miniF2F-test.\n5.2 IMPACT OF HUMAN-WRITTEN INFORMAL PROOFS\nWe investigated the effect of human-written informal proofs on the performance of our model by conducting experiments with and without these proofs, using a search budget of 8192. Table 3 presents the results on the miniF2F-valid and miniF2F-test datasets. Our model without informal proofs achieved 59.4% on miniF2F-valid and 52.5% on miniF2F-test, while the version incorporating informal proofs reached 57.8% on miniF2F-valid and 52.1% on miniF2F-test. These results suggest that the inclusion of human-written informal proofs does not significantly enhance the model's performance. Our model's generation of subgoal-based proofs appears to be more effective than utilizing informal proofs in certain scenarios (refer to $5.6 for detailed examples).\n5.3 ITERATIVE PERFORMANCE ANALYSIS\nTo evaluate our model's iterative improvement, we conducted experiments with and without human-written informal proofs, tracking validation and test pass rates over several iterations in the expert learning process. Figures 2a and 2b present these pass rates across four iterations. In the miniF2F-valid split (Figure 2a), the model without informal proofs began at 54.92% in iteration 0 and plateaued at 59.43% by iteration 2, maintaining this performance in iteration 3. The model with informal proofs started at 54.10%, peaking at 57.79% in iteration 3. Overall validation performance increased consistently from 58.20% in iteration 0 to 61.89% in iteration 3. In the miniF2F-test split (Figure 2b), the model without informal proofs improved from 47.13% in iteration 0 to 52.46% in iteration 3, while the model with informal proofs started at 48.36% and reached 52.05% by iteration 3. Overall test performance increased from 51.23% in iteration 0 to 56.15% in iteration 3. These results indicate that our subgoal-based framework drives iterative performance improvements, with the exclusion of informal proofs often yielding better results.\n5.4 SYNTHETIC PROOF PASS RATE ANALYSIS\nWe analyzed the pass rates of synthetic proofs over three iterations to evaluate the iterative learning process. The results, depicted in Figure 3, show a steady increase in performance. In iteration 1, the pass rate was 32.18%. This improved to 36.63% in iteration 2 and further to 41.98% in iteration 3. These results indicate a consistent improvement in the generation of synthetic proofs as the iterations progress, highlighting the effectiveness of the iterative learning framework in enhancing the model's proof generation capabilities.\n5.5 ERROR ANALYSIS IN PROOF GENERATION\nTo gain insights into the errors encountered during proof generation, we categorized and quantified various error types. The results, depicted in Figure 4, reveal the frequency of each error category. The most prevalent error was \u201cOuter syntax error", "Failed to finish proof": 127, "Undefined fact\" (124, 611). Other notable errors included \u201cType unification failed\" (90, 664), \u201cTimeout\" (74, 459), and \\\"Failed to apply initial proof method\" (58, 659). This detailed error analysis highlights common failure points in the proof generation process, providing a clear direction for targeted improvements.\n5.6 CASE STUDY\nWe evaluated the effectiveness of subgoal-based proofs versus informal proofs using a specific theorem. As shown in Figure 5, the leftmost example represents a successful proof using subgoal-based methods, while the other examples depict failed attempts using informal proofs. The subgoal-based proof demonstrated robustness and effectiveness, whereas the informal proof attempts failed to sufficiently establish the necessary conditions, leading to incomplete proofs.\"\n    },\n    {\n      \"title\"": "6 CONCLUSION"}, {"content": "In conclusion, SubgoalXL marks a significant step forward in AI-powered theorem proving within the Isabelle environment. By addressing the challenges of complex multi-step reasoning, SubgoalXL demonstrates the efficacy of integrating subgoal-based proofs with an expert learning framework. This method iteratively refines three key components: a formal statement generator, a formal proof generator, and a subgoal generator, leading to improved performance on theorem-proving tasks. The empirical results confirm the effectiveness of SubgoalXL, achieving state-of-the-art performance on the standard miniF2F dataset with a score of 56.1%, while successfully solving 41 AMC12 problems, 9 AIME problems, and 3 IMO problems. This work paves the way for further innovations in applying AI to tackle advanced mathematical challenges in formal theorem proving."}, {"title": "A MORE DETAILS ABOUT SUBGOAL-BASED PROOF", "content": "After creating 26 demonstration examples, as detailed in \u00a73.2, we used the prompt shown in Figure 6 to annotate subgoal-based proofs for the problems in the informal dataset."}, {"title": "B MORE DETAILS ABOUT EXPERT LEARNING", "content": "B.1 IMPLEMENTATION DETAILS OF EACH COMPONENT\nThe prompt templates for the formal statement generator, subgoal generator, and posterior subgoal generator are shown in Figures 7-9, respectively. To improve the diversity of outputs generated by the formal proof generator, we employ two distinct prompt templates, as illustrated in Figures 10 and 11. In this study, all components are initialized with Llama-3-8B.\n\u0392.2 \u0391\u039d\u039dOTATION OF FORMAL AND INFORMAL DATA\nFor the problems within the informal dataset, we employed a mixture of deepSeek-math-base and Llama-3-8B using the prompt templates illustrated in Figures 12 and 13 to generate their corresponding formal statements and proofs. For the problems in the formal dataset, we use the prompt template shown in Figure 14 to annotate their informal statements and proofs."}]}