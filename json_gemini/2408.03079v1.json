{"title": "Enhancing Complex Causality Extraction via Improved Subtask Interaction and Knowledge Fusion", "authors": ["Jinglong Gao", "Chen Lu", "Xiao Ding", "Zhongyang Li", "Ting Liu", "Bing Qin"], "abstract": "Event Causality Extraction (ECE) aims at extracting causal event pairs from texts. Despite ChatGPT's recent success, fine-tuning small models remains the best approach for the ECE task. However, existing fine-tuning based ECE methods cannot address all three key challenges in ECE simultaneously: 1) Complex Causality Extraction, where multiple causal-effect pairs occur within a single sentence; 2) Subtask Interaction, which involves modeling the mutual dependence between the two subtasks of ECE, i.e., extracting events and identifying the causal relationship between extracted events; and 3) Knowledge Fusion, which requires effectively fusing the knowledge in two modalities, i.e., the expressive pretrained language models and the structured knowledge graphs. In this paper, we propose a unified ECE framework (UniCE) to address all three issues in ECE simultaneously. Specifically, we design a subtask interaction mechanism to enable mutual interaction between the two ECE subtasks. Besides, we design a knowledge fusion mechanism to fuse knowledge in the two modalities. Furthermore, we employ separate decoders for each subtask to facilitate complex causality extraction. Experiments on three benchmark datasets demonstrate that our method achieves state-of-the-art performance and outperforms ChatGPT with a margin of at least 30% F1-score. More importantly, our model can also be used to effectively improve the ECE performance of ChatGPT via in-context learning.", "sections": [{"title": "1 Introduction", "content": "Event Causality Extraction (ECE) aims to extract causal event pairs from texts. As shown in Figure 1, given the input sentence, an ECE system should extract all cause-effect event pairs."}, {"title": "2 Methodology", "content": ""}, {"title": "2.1 Overview of UniCE", "content": "Figure 2 shows the overview architecture of our proposed UniCE, which consists of two major modules: an event module with N + M layers and a relation module with M layers. Given a sentence S, the first N layers of the event module encode each token in S using the first N layers of PLMs. Besides, the relation module retrieves knowledge related to KG nodes mentioned in S from external KGs to build an initial background graph Go. In each of the following M layers, the l-th layer of the event module first uses a PLM layer to update the representation of each token in S, and then adopts a sequence labeling decoder to extract events. These extracted events are then inserted into G\u00ba by an insertion induction module to obtain the updated background graph Gl. After that, the relation module employs GNNs to encode and update the representations of nodes in Ge (including events extracted by the l-th event module layer), and then employs a classifier to judge the causal relationship between extracted events. At the end of each subsequent M layer, we feed the pre-fused representations of tokens in S and nodes in Ge into two information aggregators to fuse information between the two subtasks and the two modalities of knowledge. The post-fused representations He and El are then used as the input of the next layer of our UniCE. After the iterative fusion of M layers, the output of the last layer is used as the final prediction of UniCE."}, {"title": "2.2 Event Module", "content": "The event module extracts events in S that may be causally related to each other. For the l-th layer of the event module, we first feed previous-layer-produced token representations He-1 = {h-1,..., h-1} into a BERT layer to obtain the pre-fused token representations H\u00ba = {h\u2081,\u2026\u2026, h}. In the top N layers, He is equal to \u0124. But in the next M layers, He is computed by our two information aggregators. Then, in each of the last M layers, we extract events by feeding \u0124e into a Conditional Random Field (CRF) decoder:\nY = CRF({h\u2081,\u2026\u2026,\u0125}), (1)\nwhere Ye = {y{,\u2026\u2026, yn} is the predicted BIO tag sequence. Finally, we use the last token in each event as the pre-fused event context representation, denoted as H = {he..., he}."}, {"title": "2.3 Relation Module", "content": "The relation module is designed to identify the causal relationship between the events extracted by the event module. To adapt the relation module to errors from the event module, we utilizes \u0124 as inputs for the l-th relation module layer, rather than gold labeled events. Besides, an insertion induction module is employed to dynamically connect the extracted events with retrieved knowledge, thus avoiding interference from irrelevant knowledge."}, {"title": "Background Graph Construction", "content": "1) Initialization. Given an input sentence S, we first retrieve KGs to obtain an initial background graph G\u00ba. Unlike previous ECI methods, we retrieve knowledge related to each element in S, rather than only gold-labeled events. Specifically, we first retrieve external KGs to obtain KG nodes mentioned in S as basic nodes Vmention. Then, we add 2-hop neighbors of Vmention and any KG nodes that are in the shortest path (no more than 10 steps) between any pair of Vmention to get the set of related nodes Vother. The max number of nodes in G\u00ba is set to 50. Finally, we utilize all edges in KGs that connect any pairs of nodes in Vother and Vmention as edges in G\u00ba. 2) Dynamic Updating. In the l-th layer, the event module extracts events from S. Then, we add the extracted events into the graph G\u00ba as event nodes Ve and build weighted edges between nodes in Vevent UVmention with our insertion induction module (detailed in \u00a72.3.I). After that, we perform reasoning over the updated graph Gl (detailed in \u00a72.3.R)."}, {"title": "Reasoning over Graph", "content": "In each of the M layers, we employ GNNs on Ge to obtain the event node representations containing knowledge from both PLMs and external KGs. For the l-th layer, we initialize the embeddings of nodes in Vmention and Vother with their post-fused node embeddings El-1 produced by the previous layer. And the embeddings of event nodes in Vevent are initialized with H. For the first layer, Vmention and Vother are initialized with pretrained embeddings provided by Feng et al. [4].\nIn each of the M layers, we feed El\u22121 = {e{-1,...,e-1} of nodes in Ge into the GNNs to obtain pre-fused node embeddings \u0112\u00ba = {\u0113\u2081,\u2026\u2026,\u0113\u0123}. And J is the number of nodes in Gl. We follow previous work [19] to build the GNNs, though other GNN variants could also be used."}, {"title": "Causal Relation Classifier", "content": "In each of the M layers, we employ a classifier to identify the causal relation between each extracted event pair (i, j) with their GNN-produced embeddings \u0113 and \u011b:\nYij = fr([\u0113; \u011b]), (2)\nwhere fR is a 2-layer MLP with a softmax activation function, y; indicates the causal relationship predicted by the l-th relation module layer."}, {"title": "Insertion Induction", "content": "This module dynamically builds weighted edges between nodes in Vevent UVmention to insert extracted events into G\u00ba.\nWe denote the edge weight matrix as Al. The value A; indicates the edge weight between nodes (i, j), where i,j \u2209 Vother. Because Vevent UVmention are all in the same sentence, they are usually connected by some kind of syntactic dependency tree. Thus, we use a variant of Kirchhoff's Matrix-Tree Theorem [8] to predict Al, which derives the link structure as a probabilistic expectation of possible dependency trees. For the l-th layer, e-\u00b9 indicates the input representation of the i-th node. We first assign non-negative scores to the edges of Al:\nPij =\n{\nexp(fa(e-1)TWcft(e-1)) if i \u2260 j\n0 otherwise,\n(3)"}, {"title": "2.4 Subtask Information Aggregator", "content": "To help EE benefit from the predictions of ECI, subtask information aggregator (T-aggregator) provides the ECI prediction information to EE in each of our last M layers. In the l-th layer, our relation module feeds e into a simple classifier to identify causal relationships. Therefore, the ECI results are implicitly embedded into \u011b. For the i-th extracted event, we first concatenate \u011b output by GNNs and he output by PLMs, then feed them into T-aggregator to obtain post-fused representation h = T-aggregator([h; \u0113]), where T-aggregator is a 2-layer MLP. Finally, we replace he in He with the to obtain He, which is also the input of the next event module layer, thus providing ECI results for EE."}, {"title": "2.5 Knowledge Information Aggregator", "content": "The knowledge information aggregator (K-aggregator) facilitates information fusion between the two kinds of knowledge, utilizing the mentioned KG nodes as the bridge. In the l-th layer, the pre-fused context and knowledge embedding of the i-th KG node are ha (output by PLMs) and \u011b (output by GNNs), respectively. h and e are concatenated and fed into K-aggregator: [ha; ea] = K-aggregator([ha; ea]), where K-aggregator is a 2-layer MLP. Then, we replace pre-fused node embeddings h and e in He and \u1ebc with post-fused embeddings h and e to obtain He and El, which are the input of the next layer of the event and the relation module, respectively."}, {"title": "2.6 Multi-layer Learning & Inference", "content": "During training, the event module and the relation module perform sequence labeling and relation classification in each of their last M layers. We optimize the l-th layer of two modules by cross-entropy loss Le and L, respectively. The loss function of UniCE is defined as the average of the last M layers:\nL =\n1\nM\nM\nN+l\n\u03a3(C++ C).\nl=1\n(7)"}, {"title": "3 Experiments", "content": ""}, {"title": "3.1 Experimental Setup", "content": "Dataset and Evaluation Metrics Following previous ECE works [11,1], we employ three widely used datasets: 1) EventStoryLine v0.9 (ESC) [2], which contains 258 documents, 5,334 events, and 1,770 causal event pairs; 2) SCIFI [9], which contains 5,236 sentences, and 1,866 causal event pairs. We remove duplicate negative examples; 3) Causal-TimeBank, which contains 184 documents, 6,813 events, and 318 causal event pairs. Following previous works [11,1], we conduct 5-fold cross-validation on the ESC and SCIFI datasets, 10-fold cross-validation on the CTB dataset, respectively. We adopt the Precision (P), Recall (R), and F1-score (F1) as evaluation metrics. All the results are the average of three independent experiments.\nParameters Setting We set N and M to 9 and 3, respectively. We utilize a BERT-Base-Uncased [3] architecture to implement our event module, which has 12-layers, 768-hiddens, and 12-heads. The hidden size of other parameters is set to 200. We choose ConceptNet as the external KG. In each relation module layer, the number of GNN layers is set to 1. The dropout of our model is set to 0.2. We apply early stop and the Adam algorithm with a linear warmup schedule to optimize our model. We set the batch size to 20 and use different learning rates for the LM encoder (lr=1e-5) and other parameters (lr=1e-4). Same as previous methods, we adopt a negative sampling strategy (rate=0.6) for the ESC and the CTB dataset.\nBaseline Methods 1) Pipeline-based baseline methods: these methods only reported their performances on the ECI task based on gold-labeled events. For a fair comparison, we train a BERT-CRF model to extract events as input for them. - BERT-Pipeline, first employs a BERT-CRF model to extract events, and then uses a BERT classifier to identify the causal relations. - KMMG [11], a BERT-based model that utilizes external knowledge to enhance the representations of events. - DPJL [15], a BERT-based model that incorporate information about causal cue words and the semantic relationship between events. 2) Sequence labeling-based baseline methods: - Nearest-BERT-CRF, first uses a BERT-CRF model to extract causes and effects and then pairs each cause with the nearest effect in the sentence. - SCITE [9], first extracts causal events with the BERT-CRF model and then matches causes and effects into pairs with a set of handcraft rules. 3) Applying Joint Entity and Relation Extraction (JERE) methods to ECE: CasRel [18], a BERT-based model that utilizes the cascade framework for generic relation extraction. - PRGC [21], a BERT-based model that filters out low-confidence entity pairs to improve model performance. - RFBFN [10], a BERT-based model that incorporates semantic information of the target relationship. 4) ChatGPT based baseline methods: We conduct experiments with gpt-3.5-turbo and employ a relaxed PRF calculation method. Specifically, a predicted causal-effect pair is considered correct if at least one token is shared between the predicted and the labeled cause, as well as"}, {"title": "3.2 Experimental Results", "content": "Overall Performance Table 2 shows the results on the ESC, SCIFI, and CTB datasets. We can find that: Firstly, our model achieves SOTA performances. These empirically shows that our proposed method can effectively capture cause-effect pairs in texts by facilitating the three major issues in ECE. Secondly, although the JERE methods achieve"}, {"title": "Effect of Subtask Interaction and Knowledge Fusion", "content": "As shown in Table 3, we study the effectiveness of our devised subtask interaction and knowledge fusion mechanisms. \"w/o SI\" denotes that we feed gold-labeled events rather than extracted events into the relation module for training and remove the T-aggregator described in \u00a72.4. \"w/o KF\" denotes that there are no nodes in the initial background graph, and we remove the K-aggregator described in \u00a72.5. \u201cw/o Both\u201d denotes that we apply both of the above settings. We can find that our model achieves lower F1 scores when our two mechanisms is removed. This indicates the effectiveness of our method."}, {"title": "Effect of Subtask Interaction Directions", "content": "As shown in Table 4, we analyze the different directions of the ECE subtask interaction. \"w/o ECI to EE\" denotes that we remove the T-aggregator. \"w/o EE to ECI\" denotes the relation module is trained with gold-labeled events. \"w/o Both\" denotes that we apply both of the above settings. we find that the two interaction directions interactions can provide complementary benefits."}, {"title": "Effect of Knowledge Fusion Components", "content": "As shown in Table 5, we analyze different knowledge fusion components for our method. \"w/o PLM to KG\" denotes that in each layer, e are not used to update \u0112. Similarly, \u201cw/o KG to PLM\u201d denotes h are not used to update \u0124. \u201cw/o Both\u201d denotes that we remove the K-aggregator. \u201cw/o Insertion\u201d denotes that we insert extracted events into the graph without edges to other nodes. \"w/o All\" denotes that we apply all of them. We find that both directions of knowledge fusion are important for the ECE task."}, {"title": "Effect of Insertion Induction Module", "content": "As shown in Table 6, we compare our insertion induction module with other four variants: 1) No Link, where we insert extracted events into the graph without edges to other nodes. 2) Span Match, if the token spans of an extracted event and a node are overlapped in the input sentence, we establish an edge. 3) Full Link, we establish edges between all nodes. 4) Dot-Product, we replace our insertion induction module with the Dot-Product Attention Mechanism. We can observe that our model outperforms all four variants."}, {"title": "Analysis of Complex Causal Extraction", "content": "As shown in Figure 3, we test models on sentences containing different numbers of cause-effect pairs. We can find that our method consistently outperforms best baseline DPJL and SCITE. This demonstrates that our framework could effectively deal with CCE issue."}, {"title": "Case Study", "content": "Figure 4 shows two case study examples. In the first example, SCITE shows the weakness of dealing with the CCE issue. DPJL fails to extract the correct event and is not robust on wrong extracted event. In the second example, both SCITE and DPJL fail to identify the causal relation between \"Aftershocks\" and \"death\". While UniCE utilizes the knowledge (Aftershocks, CAUSE, collapse) and (collapse, CAUSE, death) to extract the causal pair correctly."}, {"title": "4 Related Work", "content": ""}, {"title": "4.1 Event Causality Extraction", "content": "Event Causality Extraction (ECE) aims to extract causal event pairs in texts.\nMost recent methods address the ECE task with the pipeline framework. Liu et al. [11] fed the knowledge related to candidate causal events from an external KG into a BERT encoder. Zuo et al. [23] proposed a data augmentation framework to the solve the data lacking problem of the ECE task. Zuo et al. [22] leveraged external causal statements for event causality identification. Liu et al. [12] incorporated background and relational information into the ECE model through prompt learning. Shen et al. [15] proposed two prompt-based derivative tasks to utilize causal cue words and the relationship between events. These methods only fuse the knowledge from PLMs and KGs in a separate and shallow manner. To jointly learn the two subtasks, several studies [6,13] design sequence labeling-based methods for the ECE task. But they can only handle sentences with a single cause-effect pair. Li et al. [9] devised handcraft rules to pair causes and effects in the sentence, which cannot be generalized to other datasets.\nDifferent from previous works, our framework can address all three key issues for ECE, i.e., complex causality extraction, subtask interaction, and knowledge fusion."}, {"title": "4.2 Joint Entity and Relation Extraction", "content": "The Joint Entity and Relation Extraction (JERE) task aims at extracting pairs of entities with semantic relations in texts. Previous works utilize a cascade framework for joint extraction, which first extracted all possible subjects in texts, and then identified the corresponding objects for each subject [18,21]. In addition, some recent works first judge the semantic relationship between each token, and then transfer token-level relations into entity-level relations with handcraft rules [16]. Furthermore, several works [20,10] introduced the semantics of relations as prior knowledge for the JERE task.\nHowever, the dependence of EE on ECI is not trivial for the ECE task, which cannot be modeled by previous JERE approaches. In addition, previous JERE works rarely study how to better introduce external knowledge into the extraction model."}, {"title": "5 Speed Limitation", "content": "Despite the effectiveness of our approach in causal extraction tasks, the incorporation of reasoning with knowledge graphs results in slower inference compared to baseline methods (for example, our inference speed is seven times slower than BERT). This indicates that our method might be challenging to apply directly in speed-sensitive applications. We believe this can be mitigated by introducing an intermediate scheduling module that can adaptively select the appropriate model based on the complexity of the input question. For instance, simple questions can be handled by the BERT baseline for extraction, while complex questions can utilize our proposed model. Moreover, there are still some design details in our approach that can be further optimized to enhance the runtime speed."}, {"title": "6 Conclusion", "content": "In this paper, we propose a multi-layer ECE method that is able to simultaneously address all three key issues for ECE, i.e., complex causality extraction, subtask interaction, and knowledge fusion. Experimental results show that our model achieves consistently better performance than baseline methods on three widely used datasets. In particular, our model outperforms ChatGPT with a margin of at least 30% F1-score. Moreover, experiments also show that our approach can effectively enhance the ECE performance of ChatGPT via in-context learning."}]}