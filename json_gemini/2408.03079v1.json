{"title": "Enhancing Complex Causality Extraction via Improved Subtask Interaction and Knowledge Fusion", "authors": ["Jinglong Gao", "Chen Lu", "Xiao Ding", "Zhongyang Li", "Ting Liu", "Bing Qin"], "abstract": "Event Causality Extraction (ECE) aims at extracting causal event pairs from texts. Despite ChatGPT's recent success, fine-tuning small models remains the best approach for the ECE task. However, existing fine-tuning based ECE methods cannot address all three key challenges in ECE simultaneously: 1) Complex Causality Extraction, where multiple causal-effect pairs occur within a single sentence; 2) Subtask Interaction, which involves modeling the mutual dependence between the two subtasks of ECE, i.e., extracting events and identifying the causal relationship between extracted events; and 3) Knowledge Fusion, which requires effectively fusing the knowledge in two modalities, i.e., the expressive pretrained language models and the structured knowledge graphs. In this paper, we propose a unified ECE framework (UniCE) to address all three issues in ECE simultaneously. Specifically, we design a subtask interaction mechanism to enable mutual interaction between the two ECE subtasks. Besides, we design a knowledge fusion mechanism to fuse knowledge in the two modalities. Furthermore, we employ separate decoders for each subtask to facilitate complex causality extraction. Experiments on three benchmark datasets demonstrate that our method achieves state-of-the-art performance and outperforms ChatGPT with a margin of at least 30% F1-score. More importantly, our model can also be used to effectively improve the ECE performance of ChatGPT via in-context learning.", "sections": [{"title": "1 Introduction", "content": "Event Causality Extraction (ECE) aims to extract causal event pairs from texts. As shown in Figure 1, given the input sentence, an ECE system should extract all cause-effect event pairs."}, {"title": "2 Methodology", "content": ""}, {"title": "2.1 Overview of UniCE", "content": "Figure 2 shows the overview architecture of our proposed UniCE, which consists of two major modules: an event module with N + M layers and a relation module with M layers. Given a sentence S, the first N layers of the event module encode each token in S using the first N layers of PLMs. Besides, the relation module retrieves knowledge related to KG nodes mentioned in S from external KGs to build an initial background graph G0. In each of the following M layers, the l-th layer of the event module first uses a PLM layer to update the representation of each token in S, and then adopts a sequence labeling decoder to extract events. These extracted events are then inserted into G0 by an insertion induction module to obtain the updated background graph Gl. After that, the relation module employs GNNs to encode and update the representations of nodes in Gl (including events extracted by the l-th event module layer), and then employs a classifier to judge the causal relationship between extracted events. At the end of each subsequent M layer, we feed the pre-fused representations of tokens in S and nodes in Gl into two information aggregators to fuse information between the two subtasks and the two modalities of knowledge. The post-fused representations Hl and El are then used as the input of the next layer of our UniCE. After the iterative fusion of M layers, the output of the last layer is used as the final prediction of UniCE."}, {"title": "2.2 Event Module", "content": "The event module extracts events in S that may be causally related to each other. For the l-th layer of the event module, we first feed previous-layer-produced token representations Hl\u22121 = {hl\u221211,..., hl\u22121n} into a BERT layer to obtain the pre-fused token representations Hl = {h1,\u2026\u2026, hn}. In the top N layers, Hl is equal to \u0124. But in the next M layers, Hl is computed by our two information aggregators. Then, in each of the last M layers, we extract events by feeding \u0124l into a Conditional Random Field (CRF) decoder:\nYl = CRF({h1,\u2026\u2026,hn}), (1)\nwhere Yl = {yl1,\u2026\u2026, yln} is the predicted BIO tag sequence. Finally, we use the last token in each event as the pre-fused event context representation, denoted as He = {he1,..., hes}."}, {"title": "2.3 Relation Module", "content": "The relation module is designed to identify the causal relationship between the events extracted by the event module. To adapt the relation module to errors from the event module, we utilizes \u0124 as inputs for the l-th relation module layer, rather than gold labeled events. Besides, an insertion induction module is employed to dynamically connect the extracted events with retrieved knowledge, thus avoiding interference from irrelevant knowledge."}, {"title": "Background Graph Construction", "content": "1) Initialization. Given an input sentence S, we first retrieve KGs to obtain an initial background graph G0. Unlike previous ECI methods, we retrieve knowledge related to each element in S, rather than only gold-labeled events. Specifically, we first retrieve external KGs to obtain KG nodes mentioned in S as basic nodes Vmention. Then, we add 2-hop neighbors of Vmention and any KG nodes that are in the shortest path (no more than 10 steps) between any pair of Vmention to get the set of related nodes Vother. The max number of nodes in G0 is set to 50. Finally, we utilize all edges in KGs that connect any pairs of nodes in Vother and Vmention as edges in G0. 2) Dynamic Updating. In the l-th layer, the event module extracts events from S. Then, we add the extracted events into the graph G0 as event nodes Vevent and build weighted edges between nodes in Vevent \u222a Vmention with our insertion induction module (detailed in \u00a72.3.I). After that, we perform reasoning over the updated graph Gl (detailed in \u00a72.3.R)."}, {"title": "Reasoning over Graph", "content": "In each of the M layers, we employ GNNs on Gl to obtain the event node representations containing knowledge from both PLMs and external KGs. For the l-th layer, we initialize the embeddings of nodes in Vmention and Vother with their post-fused node embeddings El\u22121 produced by the previous layer. And the embeddings of event nodes in Vevent are initialized with He. For the first layer, Vmention and Vother are initialized with pretrained embeddings provided by Feng et al. [4]. In each of the M layers, we feed El\u22121 = {el\u221211,..., el\u22121J} of nodes in Gl into the GNNs to obtain pre-fused node embeddings \u0112l = {\u0113l1,\u2026\u2026,\u0113lJ}. And J is the number of nodes in Gl. We follow previous work [19] to build the GNNs, though other GNN variants could also be used."}, {"title": "Causal Relation Classifier", "content": "In each of the M layers, we employ a classifier to identify the causal relation between each extracted event pair (i, j) with their GNN-produced embeddings \u0113li and \u0113j:\nYlij = fR([\u0113li; \u0113j]), (2)\nwhere fR is a 2-layer MLP with a softmax activation function, ylij indicates the causal relationship predicted by the l-th relation module layer."}, {"title": "Insertion Induction", "content": "This module dynamically builds weighted edges between nodes in Vevent \u222a Vmention to insert extracted events into G0.\nWe denote the edge weight matrix as Al. The value Alij indicates the edge weight between nodes (i, j), where i,j \u2209 Vother. Because Vevent \u222a Vmention are all in the same sentence, they are usually connected by some kind of syntactic dependency tree. Thus, we use a variant of Kirchhoff's Matrix-Tree Theorem [8] to predict Al, which derives the link structure as a probabilistic expectation of possible dependency trees. For the l-th layer, el\u22121i indicates the input representation of the i-th node. We first assign non-negative scores to the edges of Al:\nPij = {exp(fa(eli\u22121)TWcft(el\u22121j)) if i \u2260 j0 otherwise, (3)"}, {"title": "2.4 Subtask Information Aggregator", "content": "To help EE benefit from the predictions of ECI, subtask information aggregator (T-aggregator) provides the ECI prediction information to EE in each of our last M layers. In the l-th layer, our relation module feeds eli into a simple classifier to identify causal relationships. Therefore, the ECI results are implicitly embedded into \u0113l. For the i-th extracted event, we first concatenate \u0113l output by GNNs and hel output by PLMs, then feed them into T-aggregator to obtain post-fused representation hel = T-aggregator([hel; \u0113l]), where T-aggregator is a 2-layer MLP. Finally, we replace hel in Hl with hel to obtain Hl, which is also the input of the next event module layer, thus providing ECI results for EE."}, {"title": "2.5 Knowledge Information Aggregator", "content": "The knowledge information aggregator (K-aggregator) facilitates information fusion between the two kinds of knowledge, utilizing the mentioned KG nodes as the bridge. In the l-th layer, the pre-fused context and knowledge embedding of the i-th KG node ai are \u0125lai (output by PLMs) and \u0113lai (output by GNNs), respectively. \u0125lai and \u0113lai are concatenated and fed into K-aggregator: [\u0125lai; \u0113lai] = K-aggregator([\u0125lai; \u0113lai]), where K-aggregator is a 2-layer MLP. Then, we replace pre-fused node embeddings \u0125lai and \u0113lai in Hl and \u1ebc with post-fused embeddings \u0125lai and \u0113lai to obtain Hl and El, which are the input of the next layer of the event and the relation module, respectively."}, {"title": "2.6 Multi-layer Learning & Inference", "content": "During training, the event module and the relation module perform sequence labeling and relation classification in each of their last M layers. We optimize the l-th layer of two modules by cross-entropy loss Lle and Lrl, respectively. The loss function of UniCE is defined as the average of the last M layers:\nL = 1M\u2211Ml=1(Llen+l+Lrl), (7)"}, {"title": "3 Experiments", "content": ""}, {"title": "3.1 Experimental Setup", "content": "Dataset and Evaluation Metrics Following previous ECE works [11,1], we employ three widely used datasets: 1) EventStoryLine v0.9 (ESC) [2], which contains 258 documents, 5,334 events, and 1,770 causal event pairs; 2) SCIFI [9], which contains 5,236 sentences, and 1,866 causal event pairs. We remove duplicate negative examples; 3) Causal-TimeBank, which contains 184 documents, 6,813 events, and 318 causal event pairs. Following previous works [11,1], we conduct 5-fold cross-validation on the ESC and SCIFI datasets, 10-fold cross-validation on the CTB dataset, respectively. We adopt the Precision (P), Recall (R), and F1-score (F1) as evaluation metrics. All the results are the average of three independent experiments.\nParameters Setting We set N and M to 9 and 3, respectively. We utilize a BERT-Base-Uncased [3] architecture to implement our event module, which has 12-layers, 768-hiddens, and 12-heads. The hidden size of other parameters is set to 200. We choose ConceptNet as the external KG. In each relation module layer, the number of GNN layers is set to 1. The dropout of our model is set to 0.2. We apply early stop and the Adam algorithm with a linear warmup schedule to optimize our model. We set the batch size to 20 and use different learning rates for the LM encoder (lr=1e-5) and other parameters (lr=1e-4). Same as previous methods, we adopt a negative sampling strategy (rate=0.6) for the ESC and the CTB dataset."}, {"title": "3.2 Experimental Results", "content": "Overall Performance Table 2 shows the results on the ESC, SCIFI, and CTB datasets. We can find that: Firstly, our model achieves SOTA performances. These empirically shows that our proposed method can effectively capture cause-effect pairs in texts by facilitating the three major issues in ECE. Secondly, although the JERE methods achieve"}, {"title": "Effect of Subtask Interaction and Knowledge Fusion", "content": "As shown in Table 3, we study the effectiveness of our devised subtask interaction and knowledge fusion mechanisms. \"w/o SI\" denotes that we feed gold-labeled events rather than extracted events into the relation module for training and remove the T-aggregator described in \u00a72.4. \"w/o KF\" denotes that there are no nodes in the initial background graph, and we remove the K-aggregator described in \u00a72.5. \u201cw/o Both\u201d denotes that we apply both of the above settings. We can find that our model achieves lower F1 scores when our two mechanisms is removed. This indicates the effectiveness of our method."}, {"title": "Effect of Subtask Interaction Directions", "content": "As shown in Table 4, we analyze the different directions of the ECE subtask interaction. \"w/o ECI to EE\" denotes that we remove the T-aggregator. \"w/o EE to ECI\" denotes the relation module is trained with gold-labeled events. \"w/o Both\" denotes that we apply both of the above settings. we find that the two interaction directions interactions can provide complementary benefits."}, {"title": "Effect of Knowledge Fusion Components", "content": "As shown in Table 5, we analyze different knowledge fusion components for our method. \"w/o PLM to KG\" denotes that in each layer, \u0113lai are not used to update \u0112. Similarly, \u201cw/o KG to PLM\u201d denotes \u0125lai are not used to update \u0124. \u201cw/o Both\u201d denotes that we remove the K-aggregator. \u201cw/o Insertion\" denotes that we insert extracted events into the graph without edges to other nodes. \"w/o All\" denotes that we apply all of them. We find that both directions of knowledge fusion are important for the ECE task."}, {"title": "Effect of Insertion Induction Module", "content": "As shown in Table 6, we compare our insertion induction module with other four variants: 1) No Link, where we insert extracted events into the graph without edges to other nodes. 2) Span Match, if the token spans of an extracted event and a node are overlapped in the input sentence, we establish an edge. 3) Full Link, we establish edges between all nodes. 4) Dot-Product, we replace our insertion induction module with the Dot-Product Attention Mechanism. We can observe that our model outperforms all four variants."}, {"title": "Analysis of Complex Causal Extraction", "content": "As shown in Figure 3, we test models on sentences containing different numbers of cause-effect pairs. We can find that our method consistently outperforms best baseline DPJL and SCITE. This demonstrates that our framework could effectively deal with CCE issue."}, {"title": "4 Related Work", "content": ""}, {"title": "4.1 Event Causality Extraction", "content": "Event Causality Extraction (ECE) aims to extract causal event pairs in texts. Most recent methods address the ECE task with the pipeline framework. Liu et al. [11] fed the knowledge related to candidate causal events from an external KG into a BERT encoder. Zuo et al. [23] proposed a data augmentation framework to the solve the data lacking problem of the ECE task. Zuo et al. [22] leveraged external causal statements for event causality identification. Liu et al. [12] incorporated background and relational information into the ECE model through prompt learning. Shen et al. [15] proposed two prompt-based derivative tasks to utilize causal cue words and the relationship between events. These methods only fuse the knowledge from PLMs and KGs in a separate and shallow manner. To jointly learn the two subtasks, several studies [6,13] design sequence labeling-based methods for the ECE task. But they can only handle sentences with a single cause-effect pair. Li et al. [9] devised handcraft rules to pair causes and effects in the sentence, which cannot be generalized to other datasets. Different from previous works, our framework can address all three key issues for ECE, i.e., complex causality extraction, subtask interaction, and knowledge fusion."}, {"title": "4.2 Joint Entity and Relation Extraction", "content": "The Joint Entity and Relation Extraction (JERE) task aims at extracting pairs of entities with semantic relations in texts. Previous works utilize a cascade framework for joint extraction, which first ex-tracted all possible subjects in texts, and then identified the corresponding objects for each subject [18,21]. In addition, some recent works first judge the semantic relation-ship between each token, and then transfer token-level relations into entity-level re-lations with handcraft rules [16]. Furthermore, several works [20,10] introduced the semantics of relations as prior knowledge for the JERE task. However, the dependence of EE on ECI is not trivial for the ECE task, which cannot be modeled by previous JERE approaches. In addition, previous JERE works rarely study how to better introduce external knowledge into the extraction model."}, {"title": "5 Speed Limitation", "content": "Despite the effectiveness of our approach in causal extraction tasks, the incorporation of reasoning with knowledge graphs results in slower inference compared to baseline methods (for example, our inference speed is seven times slower than BERT). This indicates that our method might be challenging to apply directly in speed-sensitive applications. We believe this can be mitigated by introducing an intermediate scheduling module that can adaptively select the appropriate model based on the complexity of the input question. For instance, simple questions can be handled by the BERT baseline for extraction, while complex questions can utilize our proposed model. Moreover, there are still some design details in our approach that can be further optimized to enhance the runtime speed."}, {"title": "6 Conclusion", "content": "In this paper, we propose a multi-layer ECE method that is able to simultaneously address all three key issues for ECE, i.e., complex causality extraction, subtask interaction, and knowledge fusion. Experimental results show that our model achieves consistently better performance than baseline methods on three widely used datasets. In particular, our model outperforms ChatGPT with a margin of at least 30% F1-score. Moreover, experiments also show that our approach can effectively enhance the ECE performance of ChatGPT via in-context learning."}]}