{"title": "GRADUAL FINE-TUNING WITH GRAPH ROUTING FOR MULTI-SOURCE UNSUPERVISED DOMAIN ADAPTATION", "authors": ["Yao Ma", "Samuel Louvant", "Zhunxuan Wang"], "abstract": "Multi-source unsupervised domain adaptation aims to leverage labeled data from multiple source domains for training a machine learning model to generalize well on a target domain without labels. Source domain selection plays a crucial role in determining the model's performance. It relies on the similarities amongst source and target domains. Nonetheless, existing work for source domain selection often involves heavyweight computational procedures, especially when dealing with numerous source domains and the need to identify the best ones from them. In this paper, we introduce a framework for gradual fine tuning (GFT) of machine learning models on multiple source domains. We represent multiple source domains as an undirected weighted graph. We then give a new generalization error bound for GFT along any path within the graph, which is used to determine the optimal path corresponding to the optimal training order. With this formulation, we introduce three lightweight graph-routing strategies which tend to minimize the error bound. Our best strategy improves 2.3% of accuracy over the state-of-the-art on Natural Language Inference (NLI) task and achieves competitive performance on Sentiment Analysis (SA) task, especially a 3.9% improvement on a more diverse subset of data we use for SA.", "sections": [{"title": "1 INTRODUCTION", "content": "Domain adaptation has been shown to succeed in training deep neural networks with limited data, particularly when the acquisition of labeled data can be costly in real-world applications. In practice, it is often favorable to train a model with data from related domains. Accordingly, the effectiveness of domain adaptation highly depends on the quality and similarity of the source domains' datasets. In cases where few or no labeled samples are available in the domain we target, developing a methodology to train a model without direct supervision on target domain becomes necessary. This approach is known as unsupervised domain adaptation.\nExtensive research has been conducted on theoretical analysis and empirical algorithms that minimize the generalization error (risk) of the trained model on target domain. Mansour et al. (2009) has demonstrated that the generalization error depends on both generalization error on the source domain and the discrepancy between source and target domains. In the pursuit of minimizing the discrepancy, certain approaches (Ruder & Plank, 2017; Liu et al., 2019) have been proposed to select source domains that are close to the target domain. Nevertheless, this selection process can be costly as it introduces an additional step prior to the model training. Moreover, the source domain selection tends to discard distant domains, while we assert that the distant domains can actually provide valuable training benefits for the target domain. For this reason, we propose a lightweight and efficient gradual fine-tuning (GFT) framework that can take advantage of all available source domains. By sequentially fine-tuning a model on multiple data sources, we aim to address the limitation of existing methods and unlock the potential benefits from distant domains during the training process for the target domain. The underlying intuition of our approach is to gradually guide a model to its optimal solution through sequentially fine-tuning the model on different source data whose distribution progressively aligns with the target domain. With this formulation, the model learns from data that spans a wide range of distributions, and ultimately leading it towards a better performance on the target domain. The gradual alignment of source data distributions with the target domain is crucial in enhancing adaptability and performance.\nThe contribution of our work is two-fold. First, motivated by Wang et al. (2022), we construct theoretical analysis and give the generalization error of the proposed GFT algorithms. Based on our theory, we introduce graph routing"}, {"title": "2 RELATED WORK", "content": "Domain Adaptation aims to learn a model from source domains that generalize well to a target domain. In general, there are three types of approaches on domain adaptation, namely model based, data centric, or hybrid approaches (Pan & Yang, 2010; Ramponi & Plank, 2020). Model based approaches typically aim to learn an invariant representation for domain shift (Ganin & Lempitsky, 2015; Zhao et al., 2019; Li et al., 2021). However, there is no theoretical analysis presented in these works. Existing works (Huang et al., 2006; Mansour et al., 2009; Courty et al., 2017) also have proposed on determining the value of sources, including the number of samples, the quality of data, and the discrepancy between source and target. The data centric approaches typically perform data selection to select source domains that are more similar to the target domain in terms of data distribution. Different kinds of metrics have been used to measure domain similarity, for example in NLP, Jensen Shannon similarity over word distribution Ruder & Plank (2017) is one of the common metrics to be used. One of the downside of data selection methods is, it usually involves expensive computation in addition to the model training such as data selection using Bayesian Optimization (Ruder & Plank, 2017) and Reinforcement Learning (Liu et al., 2019). Instead of performing data selection, our work attempts to eliminate this source selection stage through gradual fine-tuning.\nGradual Domain Adaptation (GDA) is proposed for the problem of unsupervised domain adaption which assumes the existence of a set of unsupervised datasets from intermediate domains. A pre-trained model is trained using labeled data from source domain. And then the model is trained and updated sequentially with pseudo-labeled predicted by the current model by minimizing the empirical loss w.r.t. the pseudo-labels. Kumar et al. (2020) have shown the GDA achieves a small generalization error when the distribution shift between two consecutive domains is small and the error in source domain is small. Wang et al. (2022) further proved an improved generalization bound which only grows linearly with the number of intermediate domains. Chen & Chao (2021) considers the problem of gradual domain adaption when the intermediate domains are not clearly defined, and proposed Intermediate Domain Labeler (IDOL) to assign scores to all unlabeled samples and group samples into different domains accordingly.\nLearning from multiple sources. As the data from a single domain could be very limited, Mancini et al. (2018); Peng et al. (2019); Zhao et al. (2018) consider the problem of multi-source unsupervised domain adaptation which assumes the source domain examples are multi-modal, i.e., the samples are drawn from different distributions. Multi-source domain adaptation considers the setting when training with joint data samples from multiple sources and little or no labeled training data from target domain. Crammer et al. (2008) presented a bound on the expected error incurred by using K number of data sources. By applying the bound, an optimal number of data sources to train a model can be achieved by measuring the discrepancy of data sources. Mansour et al. (2008) considers a similar problem which assumes the target distribution is a mixture of distributions of multiple sources. The results show that there exists a distribution weighted mixture combining rule that has a small enough loss with respect to any consistent target function and any mixture of the data distributions. Furthermore, Mansour et al. (2009) relaxes the assumption and shows that there exists a distribution weighted combination of the source hypotheses whose loss can be bounded with respect to the maximum loss of the source hypotheses and the Renyi divergence."}, {"title": "3 PROBLEM SETUP", "content": "In this paper, we consider a binary classification problem. We denote $X$ as the feature space and $y = \\{-1, +1\\}$ as the label space. We assume that the feature space is compact and bounded by an $L^2$ ball, i.e., $X \\subseteq \\{x \\in R^d : ||x||_2 \\leq 1\\}$. A domain is defined by a joint data distribution $D$ with sample space $X \\times Y$, where $X$ and $Y$ are mapped by a labeling function $f: X \\rightarrow Y$. For any domain, we assume that the data distribution is unknown, and we draw $n$ sample pairs $S = \\{x_i, y_i\\}_{i=1}^n$ from $D$ independently. A hypothesis (classifier) is represented as a function $h : X \\rightarrow Y$. Let $H$ denotes the hypothesis class, which is a set of classifiers. In this paper, we assume any classifier $h \\in H$ is Lipschitz continuous with respect to the feature vector $x$. More precisely, for any classifier $h \\in H$, there exists a real constant $R \\geq 0$ such that $\\forall x, x' \\in X, |h(x) - h(x')| \\leq R \\cdot ||x - x'||_2$."}, {"title": "4 GRADUAL FINE-TUNING", "content": "In this section, we present our GFT approach for training on multiple source domains sequentially. Our method is inspired by the fact that the generalization error of a trained classifier increases linearly with the distance between the initial and the final parameter values. Previous research (Mansour et al., 2009) has shown that the target error depends on both the source error and the discrepancy between the source domain data distributions $D_s$ and target domain data distribution $D_T$. This relationship explains why domain adaptation often works well in practice. However, existing methods have not fully exploited these insights.\nOur GFT approach addresses this gap by gradually updating the model based on the source domains in sequence. We use graph routing algorithms to determine the order of updates, ensuring that each update minimizes the total error on all previous source domains while maximizing the accuracy on the current one. This way we ensure that the model converges faster and performs better overall compared to traditional single-source fine-tuning approaches. The GFT approach provides a principled framework for handling multi-source domain adaptation problems, allowing us to leverage the benefits of distant sources without sacrificing performance on the target domain.\nGiven $K$ labeled datasets $S_k$, $k = 1, ..., K$ from $K$ sources and an unlabeled dataset $T$ from the target domain, we want to quantify the similarity between the source domains and the target domain. To achieve this, we employ the Wasserstein-p distance, specifically utilizing the Sinkhorn divergence estimation method (Chizat et al., 2020), to"}, {"title": "5 THEORETICAL ANALYSIS", "content": "In this section, we present the generalization error bound of the classifier trained with GFT algorithm along any path in the disparity graph G. We first recall the result from Wang et al. (2022) which shows the error difference of any classifier h over shifted data distribution is bounded by the Wasserstein-1 distance.\nLemma 5.1. Given two joint distributions $D_1$ and $D_2$ over $X \\times Y$, the expected loss of a classifier h satisfies\n$|\\epsilon_{D_1}(h) - \\epsilon_{D_2}(h)| \\leq L\\sqrt{R^2 + 1}W_1(D_1, D_2).$\nLemma 5.1 gives the performance discrepancy bound of a classifier between two different datasets. A classifier produces similar errors on two data distributions that has smaller Wasserstein-1 distance. Applying this lemma, we bound the expected errors of two consecutive classifiers for the proposed GFT algorithm as\n$\\epsilon_{t+1}(h_{t+1}) - \\epsilon_t(h_t) \\leq \\frac{4B\\sqrt{2}L}{\\sqrt{n_{t+1}}} + \\frac{4B}{\\sqrt{2n_{t+1}}} \\sqrt{\\log 1/\\delta} + L\\sqrt{R^2 + 1}W_p(D_{t+1}, D_t),$\nwhere $\\Delta_{t,t+1} = \\Delta_{t+1,t} = W_p(D_{t+1}, D_t)$.The first and second terms are from generalization error bound under the assumption that the Rademacher complexity of the hypothesis space satisfies $R_n(H) \\leq B$. Note that although the above result is very similar to the bound in Wang et al. (2022), this result is different since the difference between labels"}, {"title": "6 GRAPH ROUTING", "content": "Pivoting around the minimization of generalization error bound in Theorem 5.2 for the best worst-case scenario, we present our GFT trajectory selection strategies based on classical graph routing algorithms. As justified previously, a path in G represents a GFT trajectory. Theorem 5.2 thereby indicates that corresponding error bound of the GFT trajectory"}, {"title": "7 EXPERIMENTAL SETUP", "content": "We evaluate our proposed GFT methods, focusing on sentiment analysis (SA) and Natural Language Inference (NLI) text classification tasks.\nMulti-domain Datasets. For the SA task, we use the Amazon Review dataset (Blitzer et al., 2007; Liu et al., 2017), which contains product reviews from 20 domains, annotated with binary sentiment labels (positive or negative sentiment). In this experiment, we randomly select 8 domains as shown in Table 2 for simplicity of the experiment setting. The language used in the dataset is English and Spanish. Additionally, to understand the performances of different strategies under a more difficult scenario for this task, we manually select and experiment on 4 domains out of the 8 from Amazon Review that are more diverging: books, music, electronics, grocery, which have the greatest Wassserstein-1 distance between each pair. For the NLI task, we use multi-genre Natural Language Inference (Williams et al., 2018, MultiNLI), which contains a sentence pair of premise and hypothesis from 5 domains. The language in the dataset is English. Each sentence pair is annotated with entailment, neutral, or contradiction labels. We binarize the label into entailment or not, by following the procedure in Ma et al. (2019).\nImplementation & Evaluation. The base model for the gradual fine-tuning experiments is a BERT-based model (Devlin et al., 2019). Our gradual fine-tuning implementation is built on top of the Huggingface framework (Wolf et al., 2020), and we use Geomloss (Feydy et al., 2019) to compute Wasserstein distances between domains in a dataset. For the evaluation metric, we use accuracy to compare performance between different methods on each task.\nBaselines. We experiment with our gradual fine-tuning (GFT) methods, namely nearest-neighbor (NNGFT), shortest path (SPGFT), and minimum spanning tree (MSTGFT) graph routing. Additionally, we also conduct the aforementioned brute-force that exhausts every possible path in G and chooses the one that minimizes the theoretical generalization bound, named TGFT. We compare our GFT strategies to several baselines: (i) All sources 1-stage (ALL SOURCES): We use all source domains combined for training and evaluate it on the target domain. (ii) Closest source 1-stage (CLOSEST): We use the closest source domain to the target domain and evaluate it on the target domain. We determine the closest domain by Wasserstein distance. (iii) SEAL-SHAP: A state-of-the-art method Parvez & Chang (2021) that uses Shapley-based score to measure the usefulness of individual sources for transfer learning. (iv) Xu et al. (2021), which gradually fine tunes on mixtures of in- and out-domain data with descending amount of out-domain data."}, {"title": "8 RESULTS & DISCUSSION", "content": "Performance on MultiNLI. As shown in Table 1, on overall average accuracy, NNGFT outperforms all the baselines including the state-of-the-art, SEAL-SHAP. On per-domain performance, TGFT and NNGFT outperform SEAL-SHAP on 3 and 4 target target domains, respectively. However, the results for SPGFT and MSTGFT are less positive compared to TGFT and NNGFT, this is possibly because SPGFT and MSTGFT produces shorter path consisting only 1-2 source domains, hence discarding the distant domains that can offer benefit for the performance in the target domain in the MultiNLI dataset. In 4 target domains, the results between TGFT and NNGFT are the same because the produced paths are identical from both methods. The fact that NNGFT surpasses CLOSEST on all target domains indicates that by using only the closest source domain to the target domain is not optimal for the MultiNLI dataset. Additionally, the fact that NNGFT is better than ALL SOURCES suggests that, although in terms of training data we use all source domains on both ALL SOURCES and NNGFT, gradual fine-tuning is evidently better than one-stage fine-tuning.\nPerformance on SA. SEAL-SHAP yields the best overall results as shown in Table 2. Per-domain wise, it outperforms all the methods in 6 out of 8 target domains. By overall average accuracy, all GFT variants can only outperform the CLOSEST baseline. TGFT obtains one better performance than SEAL-SHAP on the Music domain. Other routing"}, {"title": "9 CONCLUSION", "content": "We conduct theoretical and experimental studies on gradual fine-tuning (GFT) in multi-source unsupervised domain adaptation setting. We show that theoretically, using all source domains through GFT minimizes the generalization error. Our experiment results show that even without source domains selection, the adapted model from GFT outperforms state-of-the-art method in Natural Language Inference (NLI) task and achieve comparable performance in the sentiment analysis (SA) task. We observe that (i) GFT is more effective when the Wasserstein distance between source domains and target are more diverge. Including distant source domain through gradual fine-tuning can improve the adapted model on the intermediate domains which is beneficial for the final target domain eventually. (ii) Path optimality for GFT is still an open question as our graph routing strategies are focused on mitigating worst-case scenario, and are only close to but not strictly optimal. (iii) Current graph routing strategies can hardly scale large graphs constructed by too many source domains because of computational complexity quadratic increase. We believe that our findings can be applied to more complex NLP tasks in the context of multi-source domain adaptation."}, {"title": "A PROOFS FOR THEORETICAL ANALYSIS", "content": "Let's first recall the following general theorem.\nLemma A.1. Let D be a joint distribution over X \u00d7 Y and l be a B-bounded loss function that is L-Lipschitz, in the 2-norm in the first argument. For a given function space F and $f \\in F$, let $f^* = \\arg \\min_{f \\in F} E_c[l(x, y)]$ and $\\hat{f} = \\arg \\min_{f \\in F} \\Sigma_{i=1}^{m} l(f(x_i), y_i)$ be the empirical and population loss minimizers. Then for any $\\delta > 0$, with probability at least 1 \u2013 $\\delta$,\n$l(\\hat{f}) \u2013 l(f^*) \\leq 2\\sqrt{2}LR(F) + 2B\\sqrt{\\frac{\\log (1/\\delta)}{2m}}$.\nThe next lemma shows the error difference over shifted domains.\nLemma A.2. We further assume that the classifier in F is R-Lipschitz continuous, then\n$|l(f, D_1) \u2013 l(f, D_2)| \\leq Lv\\sqrt{R^2 + 1}W_p(D_1, D_2)$.\nLemma A.2 provides a model independent bound on the difference of errors for a classifier under distribution shift. By utilizing this bound, we can bound the difference of errors for the classifies generated by GFT algorithm under the distribution shift.\n$\\epsilon_2(\\hat{h}_2) - \\epsilon_1(\\hat{h}_1) \\leq \\epsilon_2(\\hat{h}_2) - \\epsilon_2 (\\hat{h}_1) + L\\sqrt{R^2 + 1}W_p(D_1, D_2)$\n$< \\epsilon_2(\\hat{h}_2) - \\epsilon_2 (\\hat{h}_1) + 4\\sqrt{2}LR_{n_2} (F) + 4B\\sqrt{\\frac{\\log 1/\\delta}{2n_2}} + L\\sqrt{R^2 + 1}W_p(D_1, D_2)$\n$\\leq 4\\sqrt{2}LR_{n_2}(F)+4B\\sqrt{\\frac{\\log 1/\\delta}{2n_2}} + L\\sqrt{R^2 + 1}W_p(D_1, D_2)$\nwhere the third inequality hold as $\\hat{h}_2$ is the minimizer of the empirical loss $\\epsilon_2$. By iteratively applying this result, we have for any $t \\in \\{1, ..., \\kappa\\}$\n$\\epsilon_\\kappa(\\hat{h}_\\kappa) - \\epsilon_1(\\hat{h}_1) \\leq \\sum_{i=1}^{\\kappa-1} (\\epsilon_{i+1}(\\hat{h}_{i+1}) - \\epsilon_i(\\hat{h}_i)) + L\\sqrt{R^2 + 1} W_p(D_t, D_\\kappa)$\n$\\leq \\sum_{i=1}^{\\kappa-1} [4\\sqrt{2}LR_{n_{i+1}}(F) + 4B\\sqrt{\\frac{\\log (1/\\delta)}{2n_{i+1}}} + L\\sqrt{R^2 + 1}W_p(D_i, D_{i+1})] + L\\sqrt{R^2 + 1}W_p(D_t, D_\\kappa)$\n$\\sum_{i=2}^{\\kappa-1} \\epsilon_t(\\hat{h}_\\kappa) - (\\kappa \u2013 1)\\epsilon_1(\\hat{h}_1)$\n< $4\\sqrt{2}L(\\kappa \u2013 1) \\sum_{i=1}^{\\kappa-1} R_{n_{i+1}} (F) + 4B(\\kappa \u2013 1) \\sum_{i=1}^{\\kappa-1} \\sqrt{\\frac{\\log (1/\\delta)}{2n_{i+1}}}$\n$+L\\sqrt{R^2 + 1}(\\kappa \u2212 1) \\sum_{i=1}^{\\kappa-1} W_p(D_i, D_{i+1}) + L\\sqrt{R^2 + 1}\\sum_{i=2}^{\\kappa-1} W_p(D_t, D_\\kappa)$\nNow, we present proofs for results in the theoretical analysis section.\nProof. In this proof, we follow the same line as Wang et al. (2022). By applying Corollary 2 of Kuznetsov & Mohri (2020), we can bound the population loss of the classifier $\\hat{h}_k$ from the final stage of GFT in the target domain $D_T$ as\n$\\epsilon_T(\\hat{h}_\\kappa) \\leq \\sum_{t=1}^{\\kappa} \\eta_t l_{\\epsilon t} (\\hat{h}_\\kappa) + disc(q_\\kappa) + ||q_\\kappa||_2$\n$+6B\\sqrt{4\\pi \\log \\sum_{t=1}^{\\kappa}n_t} R_{seq}(H) + B||q_\\kappa||_2\\sqrt{8\\log1/\\delta},$\nwhere $R_{seq}^{\\epsilon t}$ is the sequential Rademacher complexity of the hypothesis space H with loss function $l_{\\epsilon t}$.\nBy setting the optimal weights for discrepancy measurement as $q_{ik} = (\\frac{n_{ik}}{\\sum_{t=1}^{\\kappa} n_t}, ......,\\frac{n_{\\kappa k}}{\\sum_{t=1}^{\\kappa} n_t})$, we can bound the $L_2$ norm of $q_\\kappa$ as\n$||q_\\kappa||_2 = \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2} + ... + \\frac{1}{n_\\kappa}}$\nThen by applying the same weights, we can bound the discrepancy measurement as\n$disc(q_\\kappa) = \\sum_{t=1}^\\kappa \\eta_t Sup_{h\\in H} | l_{\\epsilon t}(\\hat{h}) \u2013 l_T(\\hat{h}) |$\n$\\leq Sup_{h\\in H} |\\sum_{t=1}^\\kappa \\eta_t  l_{\\epsilon t} (\\hat{h}) \u2013 l_T(\\hat{h}) |$\n$< \\sqrt{R^2 + 1} \\sum_{t=1}^{\\kappa-1} W_p(D_t, D_\\kappa)$"}, {"title": "B SIMULATION RESULTS", "content": "We present the results of the 2-source initial simulation experiments for our GFT framework. We compared three training strategies: 1) We train two linear classifiers on Source 1 and Source 2, separately. 2) We train a single classifier on joint of Source 1 and Source 2. 3) We apply GFT following path \"Source 2 \u2192 Source 1\". The result is shown in Figure 3. GFT achieves the highest test accuracy among the three strategies. The intuition is the classifier in training strategy 3 achieve a better result by following the guidance of our graph routing GFT."}, {"title": "C BASELINE: ALL SOURCES", "content": "One important baseline is the risk of the classifier trained with data from all sources. Let's denote the classifier that minimize the empirical loss over all samples as\n$\\hat{h} = \\arg \\min_{h \\in H} \\frac{1}{N_{1:K}} \\sum_{t=1}^{K} \\sum_{(x,y) \\in S_t} l(h(x), y)$.\nBy applying the same theory from Kuznetsov & Mohri (2020), we are able to write the upper bound of the risk of $\\hat{h}$ on the target domain.\nLemma C.1. Suppose at each time step, a sample is i.i.d. drawn from the entire training data-set. With probability 1 \u2013 $\\delta$, the expected error of classifier h is bounded as\n$\\epsilon_T(\\hat{h}) \\leq L\\sqrt{R^2 + 1} \\sum_{t=1}^{K} (\\frac{n_t}{n_{1:K}}) W_p(D_t, D_T)$\n$+ \\sqrt{\\sum_{t=1}^{K} (\\frac{n_t}{n_{1:K}}) \\epsilon_t(\\hat{h}_t)} +  \\frac{2\\sum_{t=1}^{K} \\sqrt{\\log (1/\\delta)}\\sqrt{n_t}}{n_{1:K}}$\nThe expected error of $\\hat{h}$ scales as the weighted Wasserstein-1 distance between each source and the target. When a domain has dominate number of sample $n_i$ and large enough $\\Delta_{i,T}$, the error on this domain will dominate the final trained classifier."}, {"title": "D BASELINE: CLOSEST SOURCE", "content": "As in most domain adaption algorithms, training on the closest source has been shown to achieve good performance in many real applications. But the drawback of limited number of samples always exists when the closest source does not contain enough number of labeled training samples. Here, we denote the classifier trained on the closest domain c as $h_c = \\arg \\min_{h \\in H} \\Sigma_{i=1}^{n_c} L(h(x), y)$.\nLemma D.1. With probability 1 \u2013 $\\delta$, the expected error of the learned classifier $h_c$ satisfies\n$\\epsilon_T(h_c) < L\\sqrt{R^2 + 1} W_p(D_c, D_T)$\n$+ \\epsilon_c(h_c) + B + \\sqrt{\\frac{\\log (1/\\delta)}{n_c}}$\nAs in standard learning theorem, the risk decreases monotonically as the number of sample $n_c$ grows. In the case of $n_c$ does not have contain enough samples, a trade-off between $\\Delta_{c,T}$ and $n_c$ need to be carefully considered and selected."}]}