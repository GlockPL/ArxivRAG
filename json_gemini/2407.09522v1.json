{"title": "UQE: A Query Engine for Unstructured Databases", "authors": ["Hanjun Dai", "Bethany Yixin Wang", "Xingchen Wan", "Bo Dai", "Sherry Yang", "Azade Nova", "Pengcheng Yin", "Phitchaya Mangpo Phothilimthana", "Charles Sutton", "Dale Schuurmans"], "abstract": "Analytics on structured data is a mature field with many successful methods. However, most real world data exists in unstructured form, such as images and conversations. We investigate the potential of Large Language Models (LLMs) to enable unstructured data analytics. In particular, we propose a new Universal Query Engine (UQE) that directly interrogates and draws insights from unstructured data collections. This engine accepts queries in a Universal Query Language (UQL), a dialect of SQL that provides full natural language flexibility in specifying conditions and operators. The new engine leverages the ability of LLMs to conduct analysis of unstructured data, while also allowing us to exploit advances in sampling and optimization techniques to achieve efficient and accurate query execution. In addition, we borrow techniques from classical compiler theory to better orchestrate the workflow between sampling methods and foundation model calls. We demonstrate the efficiency of UQE on data analytics across different modalities, including images, dialogs and reviews, across a range of useful query types, including conditional aggregation, semantic retrieval and abstraction aggregation.", "sections": [{"title": "1. Introduction", "content": "Data analysis (Elgendy and Elragal, 2014) is essential for making well founded decisions and enabling businesses and society to function more effectively. Relational databases (Codd, 1990; Ramakrishnan and Gehrke, 2002) and the Structured Query Language (SQL) (Chamberlin, 1998) have delivered huge successes in structured data management and analysis. Typically, such data is collected and organized in a pre-defined schema (Elmasri and Navathe, 2013), where the data properties and relationships have been pre-specified, and downstream analysis is restricted to this schema.\nIn most real-world applications, however, data exists in unstructured formats, such as images, documents and audio recordings. Without preprocessing such data into structured forms, traditional SQL engines can only support limited queries. Preprocessing, including document entity retreival (Yu et al., 2023) and form understanding (Xu et al., 2020), also require training on downstream tasks given a predefined taxonomy. This naturally motivates the question we consider in this paper:\nHow can one perform unstructured data analysis in a flexible and efficient way?\nIn the literature, full-text search engines (Gospodnetic et al., 2010) support scalable regexp-matching search on unstructured data, but this becomes infeasible for more complex semantic reasoning queries. Retrieval-Augmented Generation (RAG) (Gao et al., 2023c; Lewis et al., 2020; Thorne et al., 2020) allows question answering on a subset of related data, but is not directly applicable to generic analytical tasks with aggregation and semantic queries that spans over an entire large database. Recent advances in Large Language Models (LLMs) (Achiam et al., 2023; Anthropic, 2024) unlock the ability to perform flexible question answering, especially with recent long-context models (Reid et al., 2024). However, setting aside the cost per query, data analytics can still be challenging for LLMs without fine-tuning (Li et al., 2023) or few-shot demonstrations (Chen, 2022), even given structured tables.\nRecently, a promising line of work has considered marrying LLMs with programming fram- works (Sur\u00eds et al., 2023), where logical or arithmetic operations are offloaded to program inter- preters (Gao et al., 2023b). A most relevant example for analytics and table understanding tasks"}, {"title": "2. Problem", "content": "Before defining the problem we are solving, we first establish the terminology and notation we will use throughout the paper. A concrete illustration of the following terms is given in Figure 1.\n\u2022 Table / database: We define a table \\(T = {T_i}_{i=1}^N\\) as an unordered set of \\(|T| = N\\) rows, where each row \\(T_i = [T_{i,1}, T_{i,2}, . . ., T_{i,m}]\\) is an arrary of M elements such that M is the total number of columns in the table. Each row can consist of elements \\(T_{i,.}\\) of heterogeneous types (e.g., datetime, float, enum) with different modalities (e.g., text, image), while elements in each column \\(T_{.,j}\\) must be of the same format and modality.\n\u2022 Structured data: A column \\(T_j\\) is structured w.r.t. a query if it can be accessed quantitatively, such as by algebraic operations over numeric data, comparison over string labels with predefined vocabulary (e.g., categorical labels), datetime functions, etc..\n\u2022 Unstructured data: A column \\(T_j\\) is unstructured if a query cannot access it using standard quantitative access. Typically, such a column does not belong to a predefined taxonomy. Examples include text (e.g., dialogs), images, videos, and other forms of data that usually require semantic understanding and preprocessing before performing any algebraic operations.\n\u2022 Concrete column: A column is concrete if it already exists in the table.\n\u2022 Virtual column: A column is virtual if it does not already exist in the table, but a query is able to"}, {"title": "3. Unstructured query language", "content": "First, we need to formally define the query language, UQL, that talks to the unstructured databases. The idea of defining a natural query language for unstructured data is not completely new (e.g., Cheng et al. (2022), even though UQL has richer semantics), nor is the specific syntax or design of UQL the main focus of this paper. However, we need to define the scope of queries that the engine can handle, and breakdown the semantic meaning of each clause."}, {"title": "3.1. UQL semantics", "content": "We assume a basic familiarity of SQL, upon which UQL is based. UQL can be considered to be a dialect of SQL that has augmented functionalities for handling unstructured and virtual column queries. The SQL clauses that we support in UQL, along with necessary modifications to support unstructured semantic queries, are described as follows.\nSELECT is a mapping function that maps the operand (usually a row or collection of rows in a grouped query) to a new row of elements. In traditional SQL, this mapping is usually a subset selection over concrete columns, or algebraic operators over those columns. UQL provides additional semantic mapping capability as:\nSELECT \"the attribute specified by natural language\" AS attribute_name\nFor example, one can write SELECT \"the sentiment of the movie review\" over an un- structured movie review column, and retrieve \"positive\" or \"negative\" as a structured output.\nFROM specifies the source of the table. In SQL one can additionally specify table joins, but we limit our attention to sourcing from a single table in this paper.\nWHERE intrinsically specifies a binary classifier over rows, which is used to retrieve a subset of the database. In addition to comparator operators on structured columns, we also allow semantic specifications in the form of:\nWHERE \"the row satisfies some natural language specifications\"\nThe predicates in WHERE are organized in disjunctive normal form (DNF) with AND and OR syntax,"}, {"title": "3.2. UQL queries", "content": "A UQL query is a composition of clauses that can be categorized as an aggregation or a non-aggregation, as illustrated in Figure 2. Aggregation queries perform a summary on groups of aggregated rows, such as COUNT the number of rows, or summarize a common attribute in a group of rows (as defined in GROUP BY above). Non-aggregation queries perform operations on individual rows, which usually means the rows can be processed in parallel. A UQL query will only belong to one of the above two types and we do not consider nested queries for now. The query type determines how UQE will optimize and execute the query."}, {"title": "4. Unstructured Query Engine", "content": "One straightforward way to run UQL is to use an interpreter that executes queries imperitavely. Cheng et al. (2022) implements an engine in this form, which is able to handle tables of relatively small size. By analogy, this is similar to executing an SQL program using a linear database scan. While it is a valid approach, the latency and cost are prohibitive and generally prevent scaling to real world scenarios.\nThere are (at least) two key techniques in SQL databases for making query execution efficient:\n\u2022 Indexing, which organizes concrete columns via data structures for fast search with sublinear cost.\n\u2022 Compilation, which considers alternative query plans and executes the most efficient one.\nUQL queries over virtual columns pose challenges in both indexing and compilation. In this section, we present effective approaches to indexing (Section 4.1) and compilation (Section 4.2) for unstructured"}, {"title": "4.1. Indexing", "content": "Executing traditional SQL queries over indexed columns can be made efficient by avoiding an entire database scan to find the relevant rows to process. However, for UQL queries over virtual columns, it is hard to predict or predefine an index that can enable efficient searching, since these columns are not concrete and defined via arbitrary natural language specifications.\nOur first key contribution is to introduce a proxy for \"indexing\" that allows one to leverage the intrinsic semantic content of a virtual column to efficiently execute queries without scanning the entire database. The main idea is to use statistically sound sampling techniques to approximately retrieve relevant rows for processing. Based on the two types of queries defined in Section 3.2, we develop corresponding \"indexing\" counterparts."}, {"title": "4.1.1. Unbiased estimation for aggregation queries", "content": "We use a simple query to illustrate the idea of unbiased estimation to obtain a query result without scanning over an entire virtual column.\nSELECT COUNT(*) as count FROM movie_reviews WHERE \"the review is positive\"\nGiven a row \\(T_i\\) (a natural language movie review), it is relatively easy for an LLM to tell whether it satisfies the WHERE condition. If we use \\(f : (T_i, cond) \\rightarrow {0, 1}\\) to represent the LLM's classification of whether row \\(T_i\\) satisfies the conditions specified in cond, then the goal is to estimate the quantity\n\\[\\sum_{i=1}^N f(T_i, cond) = N \\frac{1}{N} \\sum_{i=1}^N f(T_i, cond) = N \\mathbb{E}_{i \\in {1...N}} [f(T_i, cond)]\\]\nThere are many approaches that can be used to estimate the finite sum in the above equation, with different tradeoffs between bias and variance. One unbiased but potentially high variance estimator is to simply use Monte Carlo samples from a uniform distribution over 1 . . . N. A typical technique for reducing variance is to use importance sampling with a proposal p, according to\n\\[\\mathbb{E}_{i \\in {1...N}} [f(T_i, cond)] = \\frac{1}{N} \\sum_{i=1}^N f(T_i, cond) = \\mathbb{E}_{i \\sim p}  \\frac{f(T_i, cond)}{N p_i}\\]\nA theoretically optimal proposal p is given as follows:\nProposition 1. The optimal proposal distribution p that minimizes the variance of estimation in Eq 2 is \\(p_i \\propto f(T_i, cond)\\), which achieves zero variance.\nProp 1 indicates that an ideal proposal should sample rows that have positive f with equal probability, while sampling negative rows with zero probability. However, given that f is the response of an LLM it is expensive to execute over all rows, forcing us to consider efficient approximations.\nStratified sampling leverages the ability to partition a population into homogeneous subpopulations. As shown in Prop 1, a good proposal \\(p_i\\) should predict whether a row \\(T_i\\) satisfies the target property cond. To trade-off between cost and variance reduction, we propose Algorithm 1. In Eq 3 we normalize the importance weights \\(w_i\\) to further reduce the estimation variance.\nExtension The above estimator can be used for other aggregation operartions such as SUM and AVERAGE, including GROUP BY, and allowing concrete columns as operands as well. However, some aggregations such as MAX does not admit such an estimator. UQE in this case can only provide estimates with greater effort. We discuss limitations in Section 7."}, {"title": "4.1.2. Online learning for non-aggregation queries", "content": "A non-aggregation query can be viewed as a search problem where we want to find a relevant subset of rows to process. As before, we begin with a concrete example:\nSELECT dialog_ID FROM dialogs WHERE \"the customer is unhappy with the agent's manner\"\nIn practice, we aim to identify as many rows as possible that satisfy the given condition while adhering to budget constraints (e.g., the total number of tokens allowed to expense). This can be formulated as an online learning problem: given the token budget (or approximately, the number of LLM calls over individual rows, denoted as B), we seek to balance exploration (to better understand the semantic landscape of all rows) with exploitation (to maximize recall). Drawing inspiration from Bayesian optimization, which employs a surrogate model learned on-the-fly to inform sequential decision-making Garnett (2023); Hutter et al. (2011); Shahriari et al. (2015), we use a cheap proxy \\(\\hat{g}\\) as a surrogate for \\(f (T_i, cond)\\). At each step t, we re-train \\(\\hat{g}\\) with the observed data and select its maximizer to query in the next step. See Algorithm 2. Here we use random noise \\(\\epsilon_{t,i}\\) to allow some degree of exploration that decays with t. Compared to the typical max innerproduct search method prevalent in RAG systems, we rely on the online learning to adjust the beliefs, instead of solely relying on predefined embedding similarities."}, {"title": "4.2. Compilation", "content": "Classically, the goal of a compiler is to translate a high level program to low-level machine code, maintaining exact execution results with improved execution speed. Such a lowering process is usually accompanied by optimizations e.g., fusing, selecting the optimal instructions, and kernel optimizations. Our goal is similar: we would like to compile high-level UQL into low-level machine code, with the distinction that the \"machine\" is an LLM, and the \"low-level code\" is the orchestration of prompt calls to the LLM. Given that the primary bottleck is the LLM API calls, we attempt to maintain the execution semantics while minimizing the cost of LLM calls, as in Figure 3."}, {"title": "4.2.1. Planning", "content": "Lowering a query into sequences of concrete execution units is a planning problem: The action space includes the order of clause execution, as well as ways to fuse clauses to execute together. The objective is to minimize the (estimated) LLM cost. Figuring out the best decomposition and combination is usually an NP-hard problem. Fortunately, the number of clauses is very limited for a single query, so we can enumerate possible combinations of ordering and fusions with little overhead.\nThe outcome of planning is a specification of a sequence of kernel executions. The input and output of each kernel can be one of the following:\n\u2022 Concrete table: a standard table with only concrete columns.\n\u2022 Stochastic table: the outcome of unbiased sampling of a table. Importance weights will be attached to each row of the table, and the operation (e.g., SUM, AVG) on this table takes weights into account.\nIn the following 3 sections we will explain the building blocks of the compiler, including the kernel implementation, the cost estimation and final instantiation in detail."}, {"title": "4.2.2. Kernel implementation", "content": "Each kernel is an standalone execution unit that reads and produces a (stochastic) table.\nSELECT on structured columns is straightforward. When operating on unstructured columns, we prompt the LLM to extract semantic attributes from the input data. If several extractions share the same source column, we can also group these together into a single prompt to reduce cost.\nWHERE takes a logical formula in disjunctive normal form, such that each conjunction can contain predicates over both unstructured and structured columns. One optimization we make in this case is to perform evaluations over the structured columns first, then simplify (e.g., remove a conjunction if any of the structured column evaluates to false) the logical formula. Any remaining predicates over unstructured columns are then executed on the table filtered by predicates over structured columns.\nGROUP BY first gathers a representative subset of rows from the table, then calls an LLM to extract a taxonomy (i.e., the description of each cluster) for a cluster abstraction. Then the taxonomy is used to classify rows sampled according to the methods defined in Section 4.1. Finally, each row is classified into one of the clusters with the corresponding cluster description in the taxonomy.\nOther standard kernels like ORDER BY are implemented as-is since they are efficient to execute."}, {"title": "4.2.3. Cost estimation for each kernel", "content": "We only consider the cost of calling the LLM, as this dominates the overall cost per query. Assuming the length of each row in the unstructured data is more or less uniform across rows, then the cost is proportional to the number of rows that fed to the LLM, which we use as the surrogate for estimation.\n\u2022 SELECT maps each row, hence the cost is \\(|T|\\) for the table T fed to SELECT.\n\u2022 GROUP BY consists of two steps, where taxonomy construction consumes a subset of the input table T, and classification runs \\(|T|\\) LLM calls in parallel.\n\u2022 WHERE depends on the proposal p. In practice we set a budget B and try to minimize the variance of unbiased estimator or maximize the recall in online learning, as explained in Section 4.1.\n\u2022 Whenever clauses are fused together, each implementation is responsible for providing a reasonable cost estimate. For example when SELECT and GROUP BY are fused, the estimated cost is the same as GROUP BY alone, as the classification stage of GROUP BY shares the input tokens with SELECT."}, {"title": "4.2.4. Instantiation of kernels", "content": "The last step of compilation is to generate the machine specific code (e.g., x86 assembly code) from the intermediate representations (IR). For UQE, this is the process of generating the LLM-specific prompts. For example, when GPT is deployed as the \"machine\", a system prompt like \"You are a helpful assistant\" will be added to the queries. This step also sets the correct context (e.g., the correct structured/unstructured column to associate to, the description of the databaes) for the LLM. When such information is not available, one can also leverage the LLM to provide a good suggestion."}, {"title": "5. Related work", "content": "While the unstructured data analytics engine is relatively new, there are several related works in the context of unstructured data query and analysis. Approaches like pattern or regexp matching (Gospod- netic et al., 2010) is scalable but not feasible for complex semantic reasoning. RAG (Gao et al., 2023c; Lewis et al., 2020) based appraoches rely on the retrieval quality and is not directly suitable for aggregation queries over entire database. LLMs (Achiam et al., 2023; Anthropic, 2024; Reid et al., 2024) depict the ability of table analytics (Fang et al., 2024) to some extent (Chen, 2022; Li et al., 2023), but are still not reliable for large unstructured database analytics yet.\nOur work is closely related to neural symobilic approaches for unstructured data analytics. Early attempts in this line aim to design specialized neural archictures with inductive biases (e.g., attention) to capture a particular form of operation (e.g., filtering a list of objects based on a natural language predicate by their attention scores) (Andreas et al., 2015; Neelakantan et al., 2015; Yin et al., 2015). Those differentiable neural \u201coperators\u201d can then be chained together to model more compositional queries, and trained end-to-end using graident descent. Another direction, in line with our work, is to augment symbolic programs with learnable operators parametierzed by neural networks (Chen"}, {"title": "6. Experiments", "content": "We benchmark the accuracy and incurred cost of UQE on multimodal unstructured data analytics tasks, with the goal to show and understand when and why UQE can improve accuracy while keeping the cost low. Since the unstructured database analytics is a relatively new task, we construct and compare against several baseline approaches, on a set of tasks created from existing datasets.\nBaselines: We design the following baselines for comparison\n\u2022 lc-LLM denotes the long-context LLMs that can directly take a subset of database and a natural language question as input, and produce the desired analysis. We mainly evaluate against several model families, including GPT-4 (Achiam et al., 2023) and Claude-3 (Anthropic, 2024). Of course, when evaluating the lc-LLM based approaches, we use the natural language instead of UQL as the prompt."}, {"title": "6.1. Main results", "content": "We run queries on different datasets by instantiating the template shown in each of the sections below. The exact natural language and UQL queries can be found in Appendix D and more information"}, {"title": "6.1.1. Conditional aggregation", "content": "This task provides aggregated statistics over databases with specified conditions, with the template as:\nSELECT COUNT(*) FROM { table} WHERE {\u201csatisfies natural language specified condition\u201d}\nWe report the relative estimation error (i.e., |predict-true_count||true_count) and its standard deviation in Table 1. For lc-LLM baselines we estimate the count based on groups of unbiased data samples that fed into the prompt.\nFor text based aggregation we use claude-3-haiku as the backbone model, where UQE deploys 10\u00d7 reduction in relative errors while reducing the cost by a factor of 20\u00d7 or more. For the image dataset, since only limited set of LLMs are capable right now, we use gpt-40 as the backbone, and compare with lc-LLM baselines. Thanks to the improved sampling method in UQE, the same gpt-40 consistently achieves improved performance out-of-the-box. To verify this, we feed one image at a time to gpt-4o and manually aggregate the count, the estimation error would be 17.10% \u00b1 13.95 and 19.35% \u00b1 13.81% for the two queries of Clevr, which is twice higher than UQE in the worst case."}, {"title": "6.1.2. Semantic retrieval", "content": "This task filters rows in databases that satisfy specified conditions, with the template as:\nSELECT * FROM {table} WHERE {\u201csatisfies natural language specified condition\u201d} LIMIT B\nWhile we limit the output size to be B = 256 to keep the total cost within a reasonable budget. The challenging scenarios are when the number of rows that satisfy the predicate is few (i.e., \"rare event finding\"). Table 2 shows similar sets of comparison, but the metric is F1 score which evaluates the quality of SELECT-ed rows. Overall UQE (with claude-3-haiku as backbone LLM) consistently achieves comparable or better performance than the baseline methods. MIPS which uses the same embedding of unstructured data as UQE, has high variance across different types of queries. The queries such as \"dialogs with account access issues\" would be very suitable for MIPS as the embedding similarity is able to capture that well. For queries involving reasoning (e.g., find the images with less than 4 objects), it is pretty hard for pretrained embeddings to express this."}, {"title": "6.1.3. Abstraction and aggregation", "content": "This task abstracts the intrinsics of each row, and then performs semantics-based GROUP BY, grouping the common instrinsics across all rows. Finally, it provides aggregated statistics over each group:\nSELECT derived_attribute, COUNT(*) FROM { table}\nGROUP BY {\u201cextract an abstract intrinsic attribute specified in natural language\u201d}\nAS derived_attribute LIMIT 10"}, {"title": "6.2. Ablation results", "content": "6.2.1. Variance of different sampling approaches for aggregation queries\nTo decouple the variance introduced by the algorithm and the bias introduced by the LLM based predictors, here we use the ground-truth label as the predictive result and focus on the effectiveness of variance reduction. Figure 4 shows the box plot of different sampling methods. We can see using stratified sampling over the embeddings of unstructured content achieves significant lower variance compared to the uniform random sampling. Also both of these achieve similar expected values, which also justifies the correctness or unbiasness."}, {"title": "6.2.2. Efficiency of online learning for non-aggregation queries", "content": "We show the effectiveness of the online learning in terms of the recall as a function of the iteration steps in Figure 5. Compared to the dashed line in the figure which indicates the results of uniform random sampling, the online learning can achieve significant boost in terms of the recall. While for some queries the variance at early iterations can be high, these all converge well in the end."}, {"title": "7. Conclusion", "content": "This paper proposed an unstructured query engine that leverages 1) the flexibility of LLMs for data understanding; 2) the advances in sampling and online learning for efficient data scanning; 3) and the compiler that bridges these algorithmic workflows with LLMs. We demonstrated its efficiency and accuracy over three analytic tasks on four datasets with two different modailities. However the current work is still very limited in terms of 1) the semantics it lacks, including table join and other types of aggregations; 2) an automated selection of LLMs and sampling configurations; 3) and scaling to even larger databases. We hope to investigate these further in future works."}, {"title": "A. Proof", "content": "Proposition: The optimal proposal distribution p that minimizes the variance of estimation in Eq 2 is \\(p_i \\propto f(T_i, cond)\\). The variance gets 0 with this proposal.\nLet's simplify the notation a bit and use f(x) for \\(f (T_i, cond)\\) and prove the variance reduction in general cases for binary function f. For the simplicity let's omit the constant |T| and focus on the estimation of the expectation term. If we come up with a new proposal distribution \\(p : T\\leftrightarrow [0,1]\\) where \\(\\sum_{x\\in T}p(x) = 1\\), then we get a new estimator in the following form:\n\\[\\mathbb{E}_{x\\sim q}[f(x)] = \\sum_{x \\in T}  \\mathbb{E}_{x\\sim p}[\\frac{q(x)}{p(x)} f(x)]\\]\nWe hope this new estimator would have lower variance. Let's define \\(u(x) = \\frac{q(x)}{p(x)} f(x)\\) for the ease of notation, and look at its variance first:\n\\[Varp(u(x)) = Ep[u^2(x)] \u2013 E[u(x)]^2\\]\nSince our estimator is unbiased, \\(E[u(x)] = E^2[f(x)]\\) and thus has nothing to do with p, let's focus on minimizing the first term. More specifically we have the optimization as:\nmin \\(Ep[u^2(x)]\\)\nwith constraints:\n\\[p(x) \\ge 0\\], \\(p(x) = 1\\]Let:\n\\[L(p, {\\lambda_x}, \\lambda_2) = \\sum_{x \\in T} u^2(x) + \\sum_{x \\in T} \\lambda_x p(x) + \\lambda_2 (\\sum_{x \\in T} p(x) \u2013 1), \\\\]"}, {"title": "B. UQL specifications", "content": "B.1. Tokenizer\nWe use the following pattern matching to tokenize the UQL programs/queries."}, {"title": "B.2. Grammar", "content": "Below we show the context free grammar of the UQL. Note that this represents a subset of the \"natural query\" analogy to SQL, and we leave other clauses like table join into the future work."}, {"title": "C. Experiments", "content": "C.1. Datasets\nWe evaluate different approaches on common analytical tasks in three widely used application domains. We use the datasets that were previously created for discriminative tasks, as these datasets contain both the unstructured columns and the structured ones (the labels in the corresponding dataset). We then hiden these structured label columns and perform analytical tasks on the unstructured ones, where these hidden structured columns will be used to compute the groundtruth.\n\u2022 User review mining. We use IMDB (Maas et al., 2011) for semantic analysis of user sentiment. The entire dataset contains 50K highly polar movie reviews with positive and negative sentiment labels.\n\u2022 Goal-oriented (customer service) dialogue systems. We use two datasets for this category, including 1) Action-Based Conversations Dataset (ABCD (Chen et al., 2021)) for intent identification, which has 10,042 dialogs with 10 distinct user intents requiring unique sequences of actions constrained by policies to achieve task success; and 2) AirDialog (Wei et al., 2018) for conversation"}, {"title": "C.2. Parameter and experiment setup", "content": "For the embeddings, we use the voyage-2 for text and for images, we use Google Vertex API with dimensionality of 512. We preprocess the embeddings for all the datasets and keep them static during the queries.\nFor the aggregation queries, we use faiss 1 to cluster the embeddings into 10 groups, and perform stratified sampling on top.\nFor the online learning setting for non-aggregation queries, in our experiment we simply set \\(\\epsilon_{t, i}\\) to be 0. We start training the function g when we collect at least one possible and one negative example labeled by the LLM. Then after every minibatch of samples collected, we train g via linear logistic regression and simply leverage sklearn for that.\nOther parameters that might matter include: the sampling budget B for aggregation queries is 128 and for non-aggregation queries it is 256. For group-by queries the UQE needs a step in building the taxonomy, where the budget we use for that is 16.\nWe set these parameters based on educated guess and keep them as default across all the queries over all the datasets."}, {"title": "C.3. Latency", "content": "We report the runtime of UQE with claude-3-haiku as backbone, and lc-gpt-4-turbo as the baseline method in Table 5. We can see UQE achieves low latency in aggregation operations, but higher latency in retrieval. This is due to the online update and re-evaluation of the g function described in"}, {"title": "C.4. Group By qualitative results", "content": "For single_item_query in ABCD, the items menteiond in the dialogs found by UQE is:\nFor account_access in ABCD, the issues menteiond in the dialogs found by UQE is:\nWhich is very close to the ground truth (recover_username, reset_2fa, recover_password).\nFor airdialog, the outcomes found by UQE is\nWhere the ground truth has one more additional outcome (cancel). But since the percentage of cancellation is very small, it is expected that this might be missing from the group by abstraction when number of occurs are very limited."}, {"title": "D. Prompts", "content": "D.1. Prompts for lc-LLMs"}, {"title": "D.1.1. Task: Conditional aggregation", "content": "IMDB dataset\nSystem prompt\nRead the following movie reviews, and categorize them into either positive or negative class, depending on the sentiment of the review. If the movie has a mixed sentiment, try your best to classify into positive or negative class based on the overall sentiment.In the end, please just output a single number, which is [the total number of positive reviews]."}, {"title": "D.1.2. Task: Semantic retrieval", "content": "IMDB dataset\nSystem prompt\nRead the following movie reviews, and list the indices of reviews with positive sentiment. If the movie has a mixed sentiment, try your best to classify into positive or negative class based on the overall sentiment.In the end, please only output a list of indices in the format of [review_3, review_7, ...]"}, {"title": "D.1.3. Task: Abstraction and aggregation", "content": "ABCD dataset\nSystem prompt\nThe following are dialogs between a customer service agent and a customer. Dialogs start with headers such as **dialog_1**, **dialog_2**, and so on. Your task is to analyze all the dialogs, and summarize \" into groups. Please output the table of your analysis, in the format of pairs of (\"\", number_of_dialogs belong to that). Specifically in the format as:\ngroup 1,number_of_dialogs\ngroup 2, number_of_dialogs\nwhere  can be one of the following:\n= the type of account access issue\n= the single item involved in the dialog"}]}