{"title": "Review of Explainable Graph-Based Recommender Systems", "authors": ["THANET MARKCHOM", "HUIZHI LIANG", "JAMES FERRYMAN"], "abstract": "Explainability of recommender systems has become essential to ensure users' trust and satisfaction. Various types of explainable recommender systems have been proposed including explainable graph-based recommender systems. This review paper discusses state-of-the-art approaches of these systems and categorizes them based on three aspects: learning methods, explaining methods, and explanation types. It also explores the commonly used datasets, explainability evaluation methods, and future directions of this research area. Compared with the existing review papers, this paper focuses on explainability based on graphs and covers the topics required for developing novel explainable graph-based recommender systems.", "sections": [{"title": "1 INTRODUCTION", "content": "Due to the large exponential growth of information online, users are usually bombarded with an excessive number of choices. To cope with this information overload issue, recommender systems have become an essential tool to suggest pieces of information (items) that potentially match users' personal interests. During the early era of recommender systems, most were developed as black-box systems, meaning the internal mechanisms or decision-making processes were not transparent or easily interpretable [3]. However, recent research has shed some light on potential issues that might be caused by using recommender systems without comprehension of how they generate outputs [6]. These issues include biases in making decisions and ethical violations which can cause serious consequences [65]. To address such issues, recent regulations, such as the General Data Protection Regulation (GDPR) of the European Union and other countries [31], have been established. This emphasizes the importance of developing recommender systems that not only perform well in terms of accuracy but also provide explainability of recommendations [115].\nRecognizing this necessity, numerous studies in recommender systems have focused on developing explainable recommender systems that are transparent and understandable. These systems aim to generate accurate recommendations while offering explanations for their recommendations or encouraging the predictability of explainable recommendations over non-explainable ones. These systems allow users to better understand the decision-making process, leading to increased trust and confidence in the systems. Also, by providing clear explanations for their recommendations, any biases that may be present in the data or algorithms can be identified and addressed accordingly. This ensures that the recommendations are fair, unbiased, and ethically sound.\nTo achieve both accuracy and explainability in recommendations, various resources have been utilized, including graphs. A graph is a collection of nodes (or vertices) and relations (or edges) connecting pairs of nodes. Each edge represents a relationship or connection between two nodes. In recommendation scenarios, nodes can represent entities such as users, items, or attributes, while relations signify the connections between them such as user-item interactions,"}, {"title": "2 PRELIMINARIES", "content": "Before discussing state-of-the-art explainable graph-based recommender systems, this section provides definitions, notations, and technical terms commonly used in these recommender systems. Then, it explains the categorizations of explainable graph-based recommender systems in this paper, laying the groundwork for the subsequent sections."}, {"title": "2.1 Definitions, Notations, and Technical Terms", "content": "DEFINITION 1. (Graph) In the context of recommendation, a graph (also known as a knowledge graph or an information network) is defined as a directed graph G = (N, R), where N is a set of nodes (or entities), and R is a set of relations (or edges). Each node and relation is associated with its type mapping function: \\phi: N \\rightarrow N and \\psi: R \\rightarrow R, respectively, where N represents the set of node types, and R represents the set of relation types. In a graph, a triplet (h, r, t) represents a relationship between the head node h \\in N and the tail node t \\in N connected by the relation r\\in R.\nDEFINITION 2. (Path) A path is a sequence of nodes where each adjacent pair is connected by a relation. Given a graph G = (N, R), a path (n_0, n_1, ..., n_{k-1}, n_k) exists if their exist triplets (n_0, r_0, n_1), (n_1, r_1, n_2), ..., (n_{k-2}, r_{k-2}, n_{k-1}), (n_{k-1}, r_{k-1}, n_k) where n_i \\in N for i = 0, 1, ..., k and r_i \\in R for i = 0, 1, ..., k - 1 in the graph. In other words, a path is a way to traverse a graph from one node to another by following the relations. The length of a path is determined by the number of relations it contains.\nDEFINITION 3. (Single-hop relation) Given a graph G = (N, R), a single-hop relation refers to a direct relation between two nodes. Mathematically, a single-hop relation between nodes n_0 \\in N and n_1 \\in N exists if there exists a relation r \\in R that connects them, i.e., there exists a triplet (n_0, r, n_1) in the graph.\nDEFINITION 4. (Multi-hop relation) Given a graph G = (N, R), a multi-hop relation refers to an indirect relation between two nodes through a path. Mathematically, a multi-hop relation between nodes n_0 \\in N and n_k \\in N exists, if there exists a path (n_0, n_1, ..., n_{k-1}, n_k) such that n_i \\in N for i = 1, 2, ..., k - 1 in the graph.\nDEFINITION 5. (Random walk) A random walk on a graph G = (N,R) can be denoted as a sequence of nodes n_0, n_1, ..., n_k where n_i is the node visited at step i for i = 0, 1, ..., k. It is obtained through a stochastic process defined by the sequence of random variables X_0, X_1, ..., X_k, where each X_i represents the node visited at step i. The walk starts at an initial node n_0 \\in N, and at each step i, the walker moves to a neighboring node n_{i+1} of the current node n_i with equal probability. The random walk continues indefinitely or until it forms a sequence of visited nodes of a certain length."}, {"title": "DEFINITION 6. (Meta-path) [83] Given a graph G = (N, R), a meta-path \\pi, defined as", "content": "N_1 \\xrightarrow{R_{N_1, N_2}} N_2 \\xrightarrow{}... \\xrightarrow{}N_l \\qquad (abbreviated as N_1 N_2 N_{l+1}),\ndescribes a composite relation R_{N_1, N_2} \\circ \\dots \\circ R_{N_l, N_{l+1}} between N_1 and N_{l+1} where \\circ denotes the composition operator on relations. A meta-path signifies a structural relationship among various types of nodes and relations in a graph. It serves as a tool to extract high-order connectivity information under a specific assumption within a graph. The length of meta-path \\pi is denoted by |\\pi|.\nDEFINITION 7. (Meta-path based random walk) Given a graph G = (N, R) and a meta-path \\pi = N_1 N_2 N_{l+1}, a meta-path-based random walk is a sequence of nodes n_0, n_1, ..., n_{l+1} where n_i is the node visited at step i for i = 0, 1, ..., k such that n_i has the type N_i in \\pi. It is obtained via a stochastic process on a graph, where the sequence of nodes visited is influenced by a predefined meta-path, capturing specific semantic relationships between nodes. The random walk continues until it reaches the last node type in the meta-path or continues indefinitely. In the case that it continues indefinitely, once it reaches the last node type in the meta-path, it goes back to the first node type and repeats following the meta-path again.\nDEFINITION 8. (Node embedding method) A node embedding method refers to the process of finding a mapping function \\phi: N \\rightarrow R^{|V|\\times d}, where d << |V|. This function maps a node into a latent space and generates a latent representation (embedding) of this node, capturing graph topological information. In a graph, node embeddings for all nodes can be obtained and utilized as input or features for learning recommendations.\nDEFINITION 9. (Explainability and interpretability) Explainable artificial intelligence (AI), including recommender systems, can provide explanations or allow a human to understand the logic behind its decision-making process. In the research area of explainable AI, two terms are usually mentioned, i.e., \u201cexplainability\u201d and \u201cinterpretability\u201d. According to the previous work [6, 32], the term explainability refers to the ability to provide an explanation of why a decision is made. Meanwhile, the term interpretability refers to the characteristic of an AI system in which its internal mechanism is comprehensible for a human. In the case of interpretable models, developers or users may take advantage of their interpretability to extract some explanations. Thus, whether an Al system has explainability or interpretability, it is possible to obtain an explanation from it.\nFor instance, linear/logistic regression models are interpretable models because their coefficients directly indicate the magnitude and direction of influence that each corresponding input feature has on the output [11]. The relationship between input variables and the model's predictions makes these models interpretable and enables them to provide explanations for the predictions. On the other hand, neural networks are not interpretable due to their black-box internal mechanisms [32]. However, explanations can be derived from these networks by using techniques such as LIME [75], Anchors [76], SHAP [58], Global Sensitivity Analysis [20], ASTRID [37] or Concept Activation Vectors (CAVs) [44]. In other words, these methods allow neural networks to be explainable, providing them with the ability to offer explanations."}, {"title": "2.2 Categorization of Explainable Graph-Based Recommender Systems", "content": "Explainable graph-based recommender systems can be categorized by many aspects. In this survey, we consider three following aspects:"}, {"title": "3 CATEGORIZATION BY LEARNING METHODS: EMBEDDING-BASED, PATH-BASED, AND HYBRID APPROACHES", "content": "As discussed in Section 2, explainable graph-based recommender systems can be categorized based on various aspects. This section focuses on the categorization by learning methods: embedding-based, path-based, and hybrid approaches. In this section, the concepts of each approach and the models within each approach are discussed, along with the advantages and disadvantages of each approach."}, {"title": "3.1 Embedding-Based Approach", "content": "An embedding-based approach uses graph embedding methods [12] to generate node embeddings and incorporate them into recommendation frameworks. These embeddings reflect the structural information of users, items, and other entities in a graph. They provide connectivity information for graph-based recommendation learning frameworks. This allows explanations to be generated by reasoning over the embeddings. Several methods can be applied to generate node embeddings, such as autoencoders, translation-based models, reinforcement learning, and GNNs. The following paragraphs discuss the use of each method within embedding-based models for explainable graph-based recommendations."}, {"title": "3.1.1 Autoencoder", "content": "An autoencoder is a type of neural network used for learning efficient representations of data by encoding the input into a lower-dimensional space and then reconstructing it. The original purpose of autoencoders was to achieve data compression and dimensionality reduction, allowing the model to capture essential features while discarding less critical information. Despite its original purpose, an autoencoder can also be used to build explainable graph-based recommender systems. Bellini et al. [8] proposed an explainable recommender system based on Semantics-Aware Autoencoders (SemAuto) [7]. Originally, SemAuto was developed to incorporate structural information in a graph into an autoencoder. Each neuron in SemAuto represents a node in the adopted graph, and each link between neurons represents the edge connecting the nodes represented by these neurons. The weights on all neurons are learned and then extracted to build user profile representations. Since neurons correspond to nodes in the graph, the importance of each node toward a specific user can be discovered and used as an explanation."}, {"title": "3.1.2 Translation-based models", "content": "Some embeddings-based models use translation-based methods such as TransE [10] and TransR [53] to generate node embeddings. Given a triplet (h, r, t) in a graph where h denotes a head node, r denotes a relation, and t denotes a tail node. These methods are based on the assumption that the information from h combined with the information from r should equal the information from t, i.e., h + r = t. These embeddings have been proven to be highly flexible for many downstream tasks including recommendation [92]. The following are examples of state-of-the-art explainable graph-based recommender systems using translation-based models:"}, {"title": "3.1.3 Reinforcement learning models", "content": "Finding an explanation/reasoning path in a graph can be formulated as a deterministic Markov Decision Process (MDP) over a graph. Thus, some embedding-based models use a reinforcement learning (RL) method to navigate reasoning paths connecting a user and his/her recommended item. These models typically build a policy network to find such a path attempting to achieve the highest cumulative reward at the end of navigation. Starting from a given user, an agent in an RL-based model navigates from one node to the next adjacent node until it reaches an item of interest. This leaves the navigated path to be used as an explanation for why this item is recommended to this user. Here are examples of explainable graph-based recommender systems using RL models:"}, {"title": "3.1.4 GNN-based models", "content": "Another line of embedding-based models uses Graph Neural Networks (GNNs) to recursively propagate multi-hop information [102]. These GNN-based models update each node embedding based on the embeddings of its neighbors and recursively perform such embedding propagation to capture high-order connectivity. They have shown that the neighborhood aggregation schemes are highly effective for capturing high-order relations in graphs [94]. To provide explanations, these systems heavily rely on attention mechanisms to identify nodes/relations with significant contributions toward user profiling and recommendation-making. Below are examples of state-of-the-art explainable graph-based recommender systems using GNNs:"}, {"title": "3.2 Path-Based Approach", "content": "Given a user and his/her item, paths connecting them in a graph indicate high-order connectivity between them. These paths are valuable information for modeling users' personal interests and can be also served as explanations. A path-based approach extracts these paths carrying such high-order information from a graph and feeds them to a recommendation learning framework to learn the connectivity possibilities between users and items. Several techniques have been used to extract paths. Depending on the techniques used for path extraction, a path-based approach can be categorized into two groups. The first group is random-walk based models that extract or sample paths randomly before using these paths for learning recommendations. Some biases or conditions, such as relation weights [30] and restarting strategy [48], might be added to ensure the quality of the randomly sampled paths. However, the core of these techniques is still based on random sampling. The second group is meta-path based models. Unlike random-walk based models, these models use paths extracted via meta-paths [83] to feed the recommendation frameworks. Compared to random-walk based models, these extracted paths from meta-path based models are more controllable and semantically meaningful. They provide explainable connectivity information between users and items which could lead to explainable recommendations in graph-based recommender systems."}, {"title": "3.2.1 Random-walk based models", "content": "Random-walk based models use a method called random walk [57] to sample paths in a graph. Starting from each node in a graph, this method randomly chooses the next node from its adjacent nodes to form a path. This process is repeated until the forming path reaches a specific length (or satisfies certain conditions). These randomly sampled paths are used to model the connectivity between nodes in a graph. The following are state-of-the-art random-walk based models:"}, {"title": "3.2.2 Meta-path based models", "content": "As for random-walk based models, since the extracted paths are random, the connectivity information obtained from these paths is therefore implicit and unpredictable. To obtain semantically meaningful connectivity information, meta-path based random walk was introduced [83]. This technique has been widely adopted to extract multi-hop relations under specific assumptions. Specifically, starting from any node, instead of randomly selecting the next node from the neighborhood, meta-path based random walk selects the next node in accordance with the node type specified in a meta-path at each step. By using a meta-path, high-order connectivity under a specific assumption can be obtained and used for learning recommendations. Below are examples of meta-path based models:"}, {"title": "3.3 Hybrid Approach", "content": "An embedding-based approach uses node embedding methods to learn recommendations. These methods allow high flexibility and efficiency compared to a path-based approach. Meanwhile, a path-based approach utilizes multi-hop relations from paths extracted from graphs. It uses high-order information in graphs in an explicit and intuitive way. A hybrid approach combines the advantages of both embedding-based and path-based approaches to leverage the overall graph structure and extracted paths. Some state-of-the-art models in this approach are as follows:"}, {"title": "3.4 Summary", "content": "The learning methods in explainable graph-based recommender systems refer to the architectures of the models for extracting and utilizing high-order connectivity information in graphs for learning recommendations. They can be divided into three approaches: embedding-based, path-based, and hybrid approaches. Embedding-based models leverage node embedding techniques to represent users, items, and their relationships within graphs, capturing complex and non-linear relationships between users and items in a continuous vector space. This allows them to capture semantic relationships in the graph. Embedding-based models can generalize well across different graph structures and types of interactions. They can capture underlying patterns that are not explicitly encoded in predefined paths, providing flexibility for diverse recommendation scenarios. However, the quality of embeddings heavily relies on the quality and quantity of the training data. In scenarios with sparse or noisy data, the learned representations may not accurately capture underlying patterns, potentially leading to suboptimal recommendations. Embeddings are dense vector representations in a continuous space. It can be challenging to interpret the underlying factors within these representations influencing recommendations. This could compromise the explainability of the recommender systems. Moreover, training embedding-based models can be computationally expensive, especially for large-scale graphs and high-dimensional embedding spaces. This complexity can be a limitation in scenarios where computational resources are limited.\nOn the other hand, path-based models leverage path extraction methods or graph traversal algorithms to explore relationships and infer recommendations based on paths between users and items. Since path-based models use explicit paths, they can offer an intuitively transparent and interpretable way to understand recommendations. Also, by strategically choosing specific paths, these models provide greater control over the type of information used for learning recommendations compared to embedding-based models. Regarding efficiency, path-based models consider paths extracted from a graph, contrasting with embedding-based models that typically consider the entire graph. The paths extracted from the graph are generally of a smaller scale compared to the entire graph. Consequently, path-based models can exhibit greater computational efficiency and scalability than embedding-based models, if the paths are extracted efficiently. Relying on predefined paths also has its disadvantages, as the effectiveness of path-based models may be limited to these specific paths. Without a diverse set of predefined paths, these models may struggle to generalize well to unseen or dynamically evolving patterns in the graph. Moreover, extracting paths without caution could result in obtaining noisy data [84], potentially leading to inaccurate recommendations. Furthermore, path-based models may focus on local patterns within the graph, possibly missing the capture of global structures. This limitation can impact their ability to understand and recommend items based on broader user preferences."}, {"title": "4 CATEGORIZATION BY EXPLAINING METHODS: MODEL-SPECIFIC AND MODEL-AGNOSTIC APPROACHES", "content": "Explainable graph-based recommender systems can also be categorized into two approaches based on how their explainability mechanisms work: model-specific, where the mechanisms are developed specifically for the models they are in, and model-agnostic, where the mechanisms are also applicable to other recommender systems. This section discusses the characteristics and differences of these approaches. It provides common methods used in state-of-the-art explainable graph-based recommender systems within each approach. Finally, it summarizes the advantages and disadvantages of these two approaches."}, {"title": "4.1 Model-Specific Approach", "content": "The model-specific approach aims to design a method or a component within a recommendation model, providing insights into the decision-making process specific to that model. Various techniques have been employed to develop model-specific explaining methods for explainable graph-based recommender systems. Notable among these techniques are attention mechanisms, reinforcement learning, and auto-regressive path generation. In the following paragraphs, the details of these techniques are discussed, exploring their state-of-the-art applications and advancements."}, {"title": "4.1.1 Attention Mechanism", "content": "As can be seen in the previous section, attention mechanisms have been heavily used for generating explanations in many explainable graph-based recommendation models. Such attention mechanisms learn attention weights to signify the importance of nodes [48, 110] or relations [7, 78, 93, 94] and use them to produce explanations. Those models that use these mechanisms are considered a model-specific approach since the attention weights are simultaneously learned along with optimizing recommendation objective functions. Such attention mechanisms have been applied in many model architectures including GCNs. For example, both KGAT [93] and KGAT+ [78] which is a scalable improved version of KGAT apply the knowledge-aware attention mechanism on GCN models to calculate the attention weights of a given user's neighbors. The attention weights are learned by optimizing the TransR loss which captures the graph structure and the collaborative filtering loss for learning recommendations. HAGERec [110] uses a bi-directional information propagation method with an attention mechanism in a GCN model. This method uses the hierarchical attention mechanism to learn the importance score of each neighbor when performing propagation. GEAPR [48] uses three different attention mechanism modules to attentively aggregate multi-modal information, i.e., the structural context of a user, numerical user's attributes, and categorical user's attributes. Structural features are aggregated by an attention-based graph neural network. The most important neighbor can be identified from the attention weights. Then, latent factors of both numerical and categorical users' attributes are extracted by an attention-based latent factorization machine. Finally, these multi-modal extracted features are combined by using another attention mechanism. KGIN [94] also uses an attention mechanism to attentively combine relation embeddings to form each user intent representation. This allows the relation with the highest attention weights to be used as an explanation.\nBesides identifying the most important node/relation, some models further take advantage of the attention weights to derive explanation paths or meta-paths. MSRE [98] uses attention mechanisms to perform attention-guide walks. This allows multi-style explanation meta-paths based on the affiliation and interaction relations to be discovered. By attentively combining these multi-style explanation meta-paths, this model learns the representations of user-item interactions. The most predictive meta-path can be obtained by considering the attention weights in this process. TMER [16] uses an attention mechanism to find the paths linking consecutive items in users' historical data. The attention weights are used to find reasoning paths as explanations for the user.\nInstead of applying attention mechanisms on nodes/relations, some models apply attention mechanisms on a set of paths extracted from a graph. These models attentively aggregate information from multiple paths allowing them to determine the most important path and use it as an explanation. For example, KPRN [97] samples paths connecting a given user and an item and generates path representations via an LSTM network. Then, this model uses an attention mechanism to attentively aggregate the representations of these sampled paths. EIUM [40] uses a self-attention mechanism to learn path representations based on user and item representations that form the paths. After obtaining path representations, this model uses another attention mechanism and weighted pooling layer to find the interaction representations containing information from all of the paths. Finally, the most important path can be selected based on the computed attention weights as explanations. KR-GCN [60] also uses an attention mechanism to distinguish the contributions of the selected paths from their heuristic path extraction method. For each recommendation, the path with the highest score is treated as an explanation as in the other models. Similarly, attention mechanisms can also be applied on a meta-path level as well. MP4Rec [68] initially generates user and item latent factors based on various meta-paths. To obtain the final user and item latent factors, MP4Rec uses an attention mechanism to attentively aggregate information based on different meta-paths. This model also uses a modified BPR loss function that leverages association rules to constrain the explainability of the recommendations predicted by the model."}, {"title": "4.1.2 Reinforcement Learning", "content": "Another line of model-specific approach is using RL for path reasoning. This approach learns how to navigate from a user to his/her recommended item resulting in producing a recommendation along with a navigated path as an explanation. Many strategies on how to learn such navigation have been proposed in the last few years. PGPR [103] uses a multi-hop scoring function utilizing high-order connectivity between users and items to reward the RL agent. To improve efficiency, a user-conditional action pruning strategy was proposed to reduce the size of the action space. UCPR [86] uses an LSTM network to encode a sequence of actions taken by the agent and a user-centric view reasoning network to construct and update each user's profile accordingly. ADAC [117] leverages Generative Adversarial Imitation Learning [38] to guide the path reasoning process to generate explanation paths following the path demonstrations. ReMR [96] uses a Cascading Actor-Critic method to initially learn the policies based on high-level concepts of users' personal interests. Then, these policies are used to learn the more fine-grained concepts to specify users' interests at an instance level. For each user and his/her recommended item, an explanation path is extracted by using a multi-level reasoning path extraction method consisting of different levels of concepts and instances. TPRec [119] leverages temporal information for performing path reasoning using RL. A personalized time-aware reward scoring function was proposed to compute rewards for the agent instead of using the multi-hop scoring function [103]. Path reasoning using RL can also leverage attention mechanisms to improve the effectiveness and efficiency of path navigation as well. For example, MKRLN [87] uses an attention mechanism to compute the importance of the neighbors at each navigation step. Not only does it help improve navigation effectiveness but it also helps reduce the number of action spaces by filtering out those neighbors with low attention weights."}, {"title": "4.1.3 Auto-Regressive Path Generation", "content": "Some explainable graph-based recommender systems have been developed to generate explanation paths instead of extracting paths from a graph. This generative process is considered model-specific since the models learn to generate explanation paths along with producing recommendations. For instance, LOGER [120] uses an LSTM network to generate a path from a given user representation. In other words, given a starting user, this LSTM network predicts a sequence of nodes and relations to form a path connecting this user to his/her recommended item. Similarly, PLM-Rec [29] generates candidate paths from a given user to his/her recommended item by using a Transformer-based decoder [90]. Then, the path with the highest joint probability is outputted as an explanation. CAFE [104] utilizes neural symbolic modules to generate a collection of explanation paths with the layout tree as guidance. In particular, it outputs a tree containing multiple explanation paths for a given user; thus CAFE is more efficient compared to other models that can generate an explanation path one by one for a given user."}, {"title": "4.1.4 Others", "content": "Apart from the aforementioned techniques, other techniques have also been used for developing model-specific explaining methods. For example, in [4], the distribution of node and relation representations was learned based on relation triplets in a graph similar to TransE. To obtain an explanation path of them, candidate paths were first extracted via a breath-first search. These candidate paths were then ranked based on their probabilities computed from the learned distribution. Although extracting paths by using a breadth-first search is not part of the model, ranking and selecting an explanation path at the end is based on the node/relation representation learning module of this model. Hence, it is considered model-specific. CGSR [113] generates the distilled session graph by blocking shortcut paths on the original session graph and retaining only causal relationships among items. Leveraging the retained causal relations,"}, {"title": "4.2 Model-Agnostic Approach", "content": "As opposed to a model-specific approach, a model-agnostic approach can be independently applied with different recommendation models to produce explainable recommendations and generate explanations. Most of the models in this approach involve extracting candidate attributes (typically nodes, relations, or paths) and then validating or ranking these candidates based on certain criteria or measurements. In [5], the explanations can be obtained by considering the likability degree of a user towards a particular item attribute. This likability degree depends on the number of times a given user interacts with items that have this attribute.\nGiven a recommendation from any recommendation model, SEP [109] selects an explanation specifically for this recommendation by ranking candidate paths extracted from a graph. The ranking criteria are based on three heuristic metrics, i.e., path credibility, path readability, and path diversity. The final ranking score can be computed by the weighted sum of these metrics. This method is a post-hoc method that can be applied with different types of recommendation models and graphs. Another post-hoc path selection method was proposed in [26]. Unlike other methods, this method takes fairness into account when ranking candidate paths. PRINCE [30] is a post-hoc method that uses counterfactual explanations instead of explanation paths. Given a user and a pair of his/her recommended items, this method iteratively removes one of the relations from this user in a graph to check whether it alters the order of the given recommended items or not. If it changes the order, then this relation may have a high impact and can be used as a counterfactual explanation for this user.\nAnother line of a model-agnostic approach is to generate multi-hop features that can be subsequently utilized in recommendation models to improve their explainability. RuleRec [61] is one of the explainable graph-based recommendation models in this line of work. This model uses a set of pre-defined meta-paths to generate item features. These features are vectors in which each entry indicates the connectivity probability of users and this item based on each meta-path. They can be used in various recommendation models such as the MF-based model to constrain explainability in recommendations. To incorporate these features in any existing recommendation model, their proposed multi-task learning objective function is required to optimize the feature extraction part and the recommendation part simultaneously. Since this multi-task learning objective function is applicable to any objective function, this explaining method can be considered model-agnostic."}, {"title": "4.3 Summary", "content": "In explainable graph-based recommender systems, explaining methods are the components or mechanisms that provide explainability of the recommendations made by these systems. These methods are categorized into two approaches: model-specific and model-agnostic approaches.\nA model-specific approach focuses on developing internal mechanisms in graph-based recommender systems that can provide explainability specifically for the models they are developed for. Since model-specific explaining methods are specifically designed for the characteristics and intricacies of the particular recommender system, they can provide more tailored and precise explainability for these recommender systems compared to model-agnostic methods. Also, in this approach, the explainability components are closely integrated with the recommendation models. Therefore, the results obtained from these components may exhibit greater alignment with the recommendations generated by the recommendation models. However, model-specific methods may lack generalizability across different recommender systems or models. This limits their transferability to other contexts. Additionally, integrating explainability components within the recommendation models can increase the overall complexity of the system, making it harder to understand and less scalable. Also, it could compromise the ability to optimize recommendation accuracy, leading to lower recommendation accuracy or a trade-off between recommendation accuracy and explainability.\nOn the other hand, a model-agnostic approach focuses on developing components that can be combined with various graph-based recommender systems to provide explainability for their recommendations. The methods within this approach can be applied post-hoc without altering the underlying recommender model. This flexibility enables the application of these methods to various existing recommendation models that require enhanced explainability. Nevertheless, model-agnostic methods may not capture system-specific nuances as effectively as model-specific methods. The explanations derived from model-agnostic methods might be more generic and less tailored to the intricacies of the recommendation model to which they are applied. Furthermore, applying model-agnostic methods externally may result in higher computational costs compared to integrated model-specific methods, particularly if the model-agnostic methods are computationally expensive. Choosing between model-specific and model-agnostic explaining methods often depends on the specific requirements of the application, the desired level of generalizability or specificity, and the potential need for transferability across different recommender systems."}, {"title": "5 CATEGORIZATION BY TYPES OF EXPLANATIONS: NODE, PATH, META-PATH, AND IMPLICIT LEVELS", "content": "This section centers on categorizing explainable graph-based recommender systems according to different explanation types. These types include node-level, path-level, meta-path level, and implicit explanations. The details of each type are discussed in this section with examples from recently proposed explainable graph-based recommender systems. Additionally, a discussion on the advantages and disadvantages of each explanation type is provided."}, {"title": "5.1 Node Level", "content": "Node-level explanations include explanations that are in the form of nodes or 1-hop relations. These explanations are the simplest explanation type for explainable graph-based recommendation models. Some models aim to identify certain nodes/relations that are influential or important for the recommendations of a given user. For example, SemAuto [8", "48": "uses a GNN model with an attention mechanism to aggregate information among each user's neighborhood. Thus, the most important neighbor node for each user can be specified based on the attention weights. LDSDMF [5", "94": "models user-item interaction intents based on the relations connecting them in a graph. Such relations are combined via an attention mechanism to form an intent representation. The relation with the highest attention weight is treated as an explanation in this model. In the model proposed in [55", "95": "provides explanations in the form of important scores of user-item interactions based on certain specific intents. CGSR [101"}]}