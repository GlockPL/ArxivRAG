{"title": "AuctionNet: A Novel Benchmark for Decision-Making in Large-Scale Games", "authors": ["Kefan Su", "Yusen Huo", "Zhilin Zhang", "Shuai Dou", "Chuan Yu", "Jian Xu", "Zongqing Lu", "Bo Zheng"], "abstract": "Decision-making in large-scale games is an essential research area in artificial intelligence (AI) with significant real-world impact. However, the limited access to realistic large-scale game environments has hindered research progress in this area. In this paper, we present AuctionNet, a benchmark for bid decision-making in large-scale ad auctions derived from a real-world online advertising platform. AuctionNet is composed of three parts: an ad auction environment, a pre-generated dataset based on the environment, and performance evaluations of several baseline bid decision-making algorithms. More specifically, the environment effectively replicates the integrity and complexity of real-world ad auctions through the interaction of several modules: the ad opportunity generation module employs deep generative models to bridge the gap between simulated and real-world data while mitigating the risk of sensitive data exposure; the bidding module implements diverse auto-bidding agents trained with different decision-making algorithms; and the auction module is anchored in the classic Generalized Second Price (GSP) auction but also allows for customization of auction mechanisms as needed. To facilitate research and provide insights into the game environment, we have also pre-generated a substantial dataset based on the environment. The dataset contains trajectories involving 48 diverse agents competing with each other, totaling over 500 million records and occupying 80GB of storage. Performance evaluations of baseline algorithms such as linear programming, reinforcement learning, and generative models for bid decision-making are also presented as part of AuctionNet. We note that AuctionNet is applicable not only to research on bid decision-making algorithms in ad auctions but also to the general area of decision-making in large-scale games. AuctionNet has been applied in the NeurIPS 2024 competition, providing nearly ten thousand accurate and fair algorithm evaluations for 1500 teams and inspiring more diverse and innovative solutions.", "sections": [{"title": "1 Introduction", "content": "Decision-making in large-scale games is a fundamental area of research in artificial intelligence. Agents in a large-scale game need to make strategic decisions to fulfill their objectives under certain"}, {"title": "2 The Decision-Making Problem Concerned", "content": "In this paper, we are concerned with the auto-bidding problem in ad auctions. We use a Partially Observable Stochastic Game (POSG)[14] to formulate the problem. A POSG M can be represented as a tuple M = {S, A, P, r, \u03b3, Z, O, I, T}, where I = {1,2,\u2026\u2026, n} is the set of all the agents, T is the horizon, i.e., the number of time steps in one episode, S is the state space and A is the action space, P(s, a) : S \u00d7 A \u2192 \u2206(S) is the transition probability, \u03b3 is the discount factor, Z is the observation space, O(s, i) : S \u00d7 I \u2192 Z is the mapping from state to observation for each agent i, r = r1 \u00d7 r2 \u00d7\u00b7\u00b7\u00b7 \u00d7 rn is the joint reward function of all the agents, and ri(s, a) : S \u00d7 A \u2192 R is the individual reward function for each agent i, where a = (a1, a2,\u2026\u2026, an) \u2208 A = A1 \u00d7 A2 \u00d7 \uff65\uff65\uff65 \u00d7 An is the joint action of all the agents.\nSpecifically, the interaction in one time step is as follows: The state s = (\u03c9, u, q, v) consists of budgets w, ad opportunity features u, advertiser features q such as industry category, corresponding value matrix v = {Vij}, where vij is the value of ad opportunity j for agent i. Agent i's observation Oi = (Wi, Ui, qi, vi) \u2208 Z contains only part of the information in state s, i.e., agent i may not know the budgets of other agents. A convention in the auto-bidding area [3] proves that the optimal bid is proportional to the ad opportunity value. Following this convention, the action of agent i is a coefficient ai, and the bids of agent i for all the ad opportunities of this time step are bi = (bi1, bi2, ,bim) = (Aivil, Aivi2,\u2026\u2026, Aivim), where m is the number of ad opportunities within this time step. Given the bids of all the agents, determined by the auction mechanism, agent i will receive the auction result xi = (Xi1, Xi2, ..., Xim), where xij = 1 if and only if agent i wins opportunity j. Agents will only receive rewards and incur costs from the winning impressions, i.e., reward $r_i(s, a) = \\sum_{j=1}^m X_{ij}V_{ij}$ and budget for the next time step $w_i^\\prime = w_i - \\sum_{j=1}^m X_{ij} C_{ij}$, where Cij is the cost of impression j for agent i.\nTaking a typical auto-bidding scenario as an example, given the definition above, the optimization objective from the perspective of agent i is as follows:\n$\\begin{aligned}\\mathop{\\text{maximize }}\\limits_{\\{a\\}} \\quad & \\sum_{t=1}^T (x_t\\cdot v_t)  \\text{ s. t. } \\sum_{t=1}^T (x_t\\cdot c_t) \\le W_i, \\end{aligned}$"}, {"title": "3 Ad Auction Environment", "content": "To comprehensively demonstrate large-scale games from real-world online advertising platforms, we have developed an ad auction environment. To standardize the auto-bidding process, we divide ad opportunities within a period into T decision time steps. Given the objective, the auto-bidding agent sequentially bids at each step, using the results from step t and prior historical information to refine its strategy for step t + 1. This design philosophy enables agents to continuously optimize their bidding strategies in order to adapt to the changing environment. Within each step, all ad opportunities are executed independently and in parallel. At the end of the period, the environment provides the final performance for the agent.\nThe environment effectively replicates the integrity and complexity of real-world ad auctions through the interaction of several modules: the ad opportunity generation module, the bidding module, and the ad auction module. To better simulate large-scale auctions in reality, a substantial number of"}, {"title": "3.1 Ad Opportunity Generation Module.", "content": "The target of the ad opportunity generation module is to generate diverse ad opportunities similar to real online advertising data. The core of this module is the deep generative model, as shown in Figure 2. We aimed to adopt the diffusion model to generate ad opportunity but encountered difficulties with the denoising operation, which can yield unreasonable outputs. Therefore, we followed the approach of the Latent Diffusion Model (LDM) [25] to generate ad opportunity. LDM adds noise and performs denoising in the latent space using a diffusion model, and then generates data from the latent space with an encoder and decoder. Specifically, LDM maps the ad opportunity feature u to a latent vector y with the encoder and reconstructs this feature with the decoder during training. For generation, LDM samples a random latent vector from a normal distribution and then generates an ad opportunity feature based on this vector. Let U C Rd be the space of ad opportunity feature data (u1, U2, \u00b7, uk), where d is the dimension of the original data and K is the number of ad opportunities. Let Y C Rd' be the latent space (d' < d). The encoder and decoder are represented as g\u03c6 and h\u03c8, respectively, where \u03c6 and \u03c8 are the parameters. The function of the encoder g\u03c6 is to obtain a latent representation of the original data as $g_\\phi(u_k) = (\\mu_k, \\sigma_k)$, where $y_k \\sim \\mathcal{N}(\\mu_k, \\sigma_k^2)$ and $y_k \\in Y$ is the latent representation. In practice, the reparameterization trick [20] is applied to ensure that this operation is differentiable during backpropagation.\nGiven the latent representation yk, the decoder is responsible for reconstructing the original data from yk, i.e., h\u03c8(yk) = \u016bk \u2208 U. In addition to the reconstruction, the latent distribution $\\mathcal{N}(\\mu_k, \\sigma^2)$ is expected to approximate the standard Gaussian distribution $\\mathcal{N}(0,1)$. Therefore, we have the following loss function for the encoder and decoder:\n$\\mathcal{L}_{recons} = \\frac{1}{K} \\sum_{k=1}^K ||u_k - h_\\psi(y_k) ||^2, \\quad \\mathcal{L}_{reg} = \\frac{1}{K} \\sum_{k=1}^K D_{KL} (\\mathcal{N}(\\mu_k, \\sigma_k) || \\mathcal{N}(0,1)),$\nwhere $\\mathcal{L}_{recons}$ is the reconstruction loss and $\\mathcal{L}_{reg}$ is the regularization loss for the latent distribution.\nDifferent from the original idea of VAE, where the latent variable y \u2208 Y is sampled from $\\mathcal{N}(0, 1)$ in the generation process, LDM uses a diffusion model in the latent space to generate the latent variable."}, {"title": "3.2 Bidding Module.", "content": "The bidding module replicates the dynamic competition between advertisers, each of whom has distinct advertising objectives and utilizes a separate auto-bidding agent, while remaining unaware of their competitors' strategies. Researchers can control a subset of the agents in the environment, while other agents remain uncontrollable, thereby better reflecting the complex and dynamic game in real-world online advertising.\nSeveral popular algorithms in the auto-bidding area have been implemented as baselines, including the PID Controller [36], Online LP [15], IQL [21], Behavior Cloning [30], and Decision Transformer [8]. This facilitates researchers who are interested in quickly starting up and evaluating these baselines in a unified environment."}, {"title": "3.3 Ad Auction Module.", "content": "The task of the ad auction module is to determine the winner and the winning price given all the bids from agents for ad opportunities. The costs for agents will vary depending on the different auction rules. The most commonly discussed auction rule is the Generalized Second-Price (GSP) Auction, which stipulates that the winner pays a cost slightly higher than the second-highest bid rather than the highest bid. The auction module internally supports several popular auction rules, including GSP, for the convenience of researchers. Additionally, researchers can design specific auction rules tailored to their purposes using the interface of the auction module.\nAdditionally, the property of multiple slots has been implemented in the environment. Multiple slots arise from applications in the industry, meaning that a single ad opportunity may have multiple ad slots for display. A slot with a higher exposure rate is more valuable to advertisers. Suppose the number of slots is l, then the auction module will allocate l slots to the top l bidders, and these bidders will receive different values according to the varying exposure rates of the slots. In summary, the multiple slots feature increases the complexity of the optimal bidding strategy, as the exposure rate serves as a discount factor for both cost and value."}, {"title": "3.4 API", "content": "The code of the environment is implemented in Python. The environment API is similar to OpenAI Gym[5], so the construction and interactions of the environment may be familiar to related researchers. We included an example code as follows:"}, {"title": "4 Pre-Generated Dataset Based on the Environment", "content": "In this section, we first verify whether the ad opportunity generation module can generate ad opportunity features similar to those in real-world data. Next, we briefly introduce and analyze the dataset generated from the AuctionNet environment."}, {"title": "4.1 Verification of the Ad Opportunity Generation Module", "content": "In order to better demonstrate that the generated data can reflect the properties of real-world data, the effectiveness of the ad opportunity generation module itself was verified. The ad opportunity generation module comprises two components: a feature generation model and a value prediction model. Experiments were conducted to verify the effectiveness of these models.\nWe randomly sample 100K real-world online advertising data points to compare with 100K generated data points. The details of the generated data can be found in Appendix D. First, we perform PCA [19] to visualize the similarity between the real-world and generated data. For better presentation, we use six different views in the 3D space. We observe that the generated data overlap with the original data in the 3D space. Moreover, the generated data points form four main separate clusters in the 3D space, similar to the real-world data points. These visualization results demonstrate that the generated data generally resemble the real-world data.\nTo further compare these two datasets, we study the value distributions of identity information and consumption behavior information in both datasets.  The feature vector contains over 20 fields, as described in Appendix D, so we only select a subset of these fields for our experiments. Regarding identity information, the generated value distributions are similar to the real-world value distributions overall, although biases exist for certain terms, such as 'level 7' for the Taobao VIP Level. Distributions with more categories are more challenging to match, while the gender distributions are nearly identical in both datasets. For"}, {"title": "4.2 Pre-Generated Dataset", "content": "The dataset is derived from game data generated within the environment, where numerous auto-bidding agents compete against each other. We have pre-generated large-scale game data to assist researchers in gaining deeper insights into the auction ecosystem. This data can be used to model the environment and to train the auto-bidding agents effectively.\nThe dataset includes 21 advertising episodes, each containing more than 500,000 ad opportunities and divided into 48 steps. Each opportunity includes the top 48 agents with the highest bids. The dataset comprises over 500 million records, totaling 80 GB in size. Each record includes information such as the predicted value, bid, auction, and impression results, among other details. The specific data format and data samples of the dataset are included in Appendix C.\nWe have conducted an analysis of the AuctionNet Dataset to provide some insights. We first investigate the variation of impression values over time within a single day. We selected five categories from the AuctionNet Dataset and denote them as Category 1, Category 2, and so on. Given the budget constraint, agents should consider the variation in impression values over time to bid for appropriate impressions at the optimal times. Furthermore, we examine the relations between the values of different categories. The relations between Category 1 and other categories are illustrated in Figure 9. The impression values of Category 1 and Category 3 are positively correlated, indicating that the corresponding advertisers are competitors for similar ad opportunities. Therefore, considering the preferences of other agents may be beneficial for developing better bidding strategies. The full datasheet of the dataset is included in Appendix B."}, {"title": "5 Performance Evaluations of Baseline Algorithms", "content": "In this section, we evaluate the performance of baseline algorithms, such as linear programming, reinforcement learning, and generative models. It is important to note that we used the original"}, {"title": "6 Applications", "content": "AuctionNet has been applied to the NeurIPS 2024 competition \"Auto-bidding in Large-Scale Auctions\" [1]. The competition addressed the critical issue of making high-frequency bid decision-making in uncertain and competitive environments and attracted more than 1,500 teams from around the world to participate, lasting for 3 months. The ad auction environment, dataset, and baseline bid decision-making algorithms used in the competition are derived from this benchmark. The ad auction environment provided nearly ten thousand evaluations for the competition, offering participants accurate and fair performance assessments. The dataset and baseline algorithms allowed participants to quickly start the task and stimulated their creativity, leading to more diverse and innovative solutions, thus driving technological development in this area."}, {"title": "7 Related Work", "content": "Simulation environments have been widely applied in decision-making research and have successfully promoted the development of related studies [6, 24, 32, 27, 29]. However, simulation environments for real-world online advertising platforms are relatively scarce in the bid decision-making field. AuctionGym [18] models the bidding problem as a contextual bandit problem [2], where the advertiser decides the bidding value given the information of the ad opportunity as context. The contextual bandit has only one time step per episode, meaning that AuctionGym does not consider budget constraints in auto-bidding. Moreover, AuctionGym describes the auto-bidding problem from a single-agent perspective and ignores the influence of other agents. AdCraft [11] is a simulation environment for the bidding problem in Search Engine Marketing (SEM). Although AdCraft explicitly models the influences of other agents, these agents' policies are sampled from parameterized distributions, which cannot fully reflect the multi-agent nature of this problem. Despite the points discussed above, these existing simulation environments lack data-driven methods for modeling real-world online advertising platforms."}, {"title": "8 Conclusion and Limitations", "content": "We present AuctionNet, a benchmark for bid decision-making in large-scale ad auctions derived from a real-world online advertising platform. AuctionNet consists of three components: an ad auction environment augmented with a verified deep generative model, a pre-generated dataset based on this environment, and performance evaluations of several baseline bid decision-making algorithms. The AuctionNet not only provides researchers with the opportunity to study auto-bidding algorithms in large-scale auctions, but also helps researchers and practitioners in game theory, reinforcement learning, generative models, operations optimization, and other fields to solve a wide range of decision-making research problems. Regarding limitations, while the generated data in the AuctionNet environment and the real-world data are similar in general, there are biases in some details, and the performance of the generative model can be improved."}, {"title": "A Evaluation Details", "content": "There are 48 agents of 7 types in our experiments and each type corresponds to one algorithm. We test 7 rounds where we permute the order of agents in each round. Therefore, agents will represent different advertisers with different budgets in different rounds. We choose the best agent as the representative of an algorithm if there are multiple agents of this algorithm. We use the average performances of the 7 rounds as the final performance of all the algorithms. We provide the model file of these agents and the evaluation code for reproduction."}, {"title": "B Datasheet for AuctionNet", "content": "We present a datasheet[10] for the AuctionNet Dataset."}, {"title": "B.1 Motivation", "content": "For what purpose was the dataset created?\nIn general, learning from interactions with the real-world online advertising platforms is difficult and expensive, so offline RL algorithms are more popular in auto-bidding. Therefore, we build the Auction Dataset to facilitate offline training of users. Moreover, the Auction Dataset will also be provided to the participants of the competition we will hold in the future.\nWho created the dataset?\nThe dataset was created by the authors of this paper. The dataset was not created on the behalf of any entity.\nWho funded the creation of the dataset?\nAlibaba Group funds the creation of the AuctionNet Dataset."}, {"title": "B.2 Composition", "content": "What do the instances that comprise the dataset represent (e.g., documents, photos, people, countries)?\nThe AuctionNet Dataset contains trajectories of diverse agents competing with each other. Please refer to Appendix C and Section 4.2 for more details.\nIs there a label or target associated with each instance?\nThe AuctionNet Dataset contains offline trajectories where the actions or bids of agents can be seen as labels for the time step.\nIs any information missing from individual instances?\nNot to our knowledge.\nAre there recommended data splits (e.g., training, development/validation, testing)?\nNo.\nAre there any errors, sources of noise, or redundancies in the dataset?\nThe AuctionNet Dataset contains trajectories of diverse agents, some of these agents may not perform well. However, the tasks in the environment are still difficult for some algorithms and we think keeping agents diverse in the AuctionNet Dataset is beneficial.\nDo/did we do any data cleaning on the dataset?\nWe did not. All data is presented exactly as collected."}, {"title": "B.3 Collection Process", "content": "How was the data associated with each instance acquired?\nThe AuctionNet Dataset is collected from the interactions of baseline agents in the environment."}, {"title": "B.4 Uses", "content": "Has the dataset been used for any tasks already?\nNo.\nIs there a repository that links to any or all papers or systems that use the dataset?\nNo.\nIs there anything about the composition of the dataset or the way it was collected and prepro-cessed/cleaned/labeled that might impact future uses?\nWe do not believe so since the AuctionNet Dataset consists of data generated by the interactions of baseline agents."}, {"title": "B.5 Distribution", "content": "Will the dataset be distributed to third parties?\nYes, but the AuctionNet Dataset and environment are involved with a large competition we will hold in NeurIPS 2024, so we will not distribute them until the end of the competition considering competition fairness. However, we will open-source the AuctionNet Dataset as soon as possible.\nHow will the dataset will be distributed (e.g., tarball on website, API, GitHub)? Does the dataset have a digital object identifier (DOI)?\nThe AuctionNet Dataset will be distributed by a Github link after the end of the competition we will hold. The AuctionNet Dataset doesn't have a digital object identifier now.\nAll data is under the MIT license.\nHave any third parties imposed IP-based or other restrictions on the data associated with the instances?\nNo.\nDo any export controls or other regulatory restrictions apply to the dataset or to individual instances?\nNo."}, {"title": "B.6 Maintenance", "content": "Who will be supporting/hosting/maintaining the dataset?\nThe authors of this paper will provide needed maintenance to the datasets.\nHow can the owner/curator/manager of the dataset be contacted (e.g., email address)?\nPlease email us at huoyusen.huoyusen@alibaba-inc.com.\nIs there an erratum?\nThere is not and we believe generated features, predicted values, and trajectories in our datasets do not involve an erratum.\nWill the dataset be updated (e.g., to correct labeling errors, add new instances, delete instances)?\nYes, but as we won't add extra data points, the update will be minimal."}, {"title": "C Data Format of AuctionNet Dataset", "content": "The specific data format of the AuctionNet Dataset is as follows:\n(c1). deliveryPeriodIndex: The index of the current delivery period.\n(c2). advertiserIndex: The unique identifier of the advertiser.\n(c3). advertiserCategoryIndex: The index of the advertiser's category.\n(c4). budget: The advertiser's budget for a period.\n(c5). CPAConstraint: The CPA constraint of the advertiser.\n(c6). timeStepIndex: The index of the current decision time step.\n(c7). remainingBudget: The advertiser's remaining budget before the current step.\n(c8). pvIndex: The index of the ad opportunity.\n(c9). pValue: The conversion probability when the ad is exposed to the user.\n(c10). pValueSigma: The variance of predicted probability.\n(c11). bid: The agent's bid of the ad opportunity.\n(c12). xi: The winning status of the agent of the ad opportunity.\n(c13). adSlot: The won ad slot.\n(c14). cost: The cost needs to be paid if the ad is exposed to the user.\n(c15). isExposed: The indicator signifying whether the ad in the slot was displayed to the user.\n(c16). conversionAction: The indicator signifying whether the conversion action has occurred.\n(c17). leastWinningCost: The minimum cost to win the ad opportunity.\n(c18). isEnd: The completion status of the advertising period."}, {"title": "D The Structure of Generated Data", "content": "Structure of the feature vector. The feature vector consists of several types of information including one-hot vectors, integers and float numbers. The specific data format of the feature vector is as follows:\n(c1). idAgeLevel: Represents the age level of the user. The meanings of values: 0 for unknown, 1~8 for ages over 12, 18, 22, 25, 30, 35, 40 and 50 respectively. Data format: one-hot vector, dimension [0, 9)."}, {"title": "E Tasks", "content": "Though AuctionNet provides a general framework for auto-bidding problem studies, we choose two typical scenarios in auto-bidding as tasks in AuctionNet for easier understanding."}, {"title": "E.1 Basic Task", "content": "Our basic task is based on the scenario Budget Constrained Bidding (BCB) [33], where agents maximize their obtained values within the constraint on the budget. The optimization formulation of BCB from agent i's perspective is as follows:\n$\\begin{aligned} \\mathop{\\text{maximize }}\\limits_{\\{a\\}} \\quad & \\sum_{t=1}^T (x_t\\cdot v_t)  \\\\ \\text{s. t. } & \\sum_{t=1}^T (x_t\\cdot c_t) \\le W_i, \\\\ \\end{aligned}$\nwhere x = = (x1, x2,...,xim) is the auction result of all ad opportunities for agent i in time step t, v = (v1, v2,..., vim) is the value for agent i, ct = (c1, c2,..., cim) is the cost in time step t, bi is the budget for agent i, and (\u00b7) is the inner product.\nAs for the implementation, we know from our problem formulation that ri(st, at) = (x, v), so the objective in the optimization formulation is the same as the objective  in the RL formulation. The budget constraint is guaranteed by ignoring the bids exceeding agents' budgets in the environment. Therefore, BCB corresponds to the default setting of AuctionNet."}, {"title": "E.2 Target CPA Task", "content": "We propose Target CPA Task based on the real-world scenario Target CPA (Cost Per Action)5 with some simplifications for understanding. The CPA of agent i is defined as $cpa_i = \\frac{\\sum_{t=1}^T(c_t\\cdot x_t)}{\\sum_{t=1}^T(v_t\\cdot x_t)}$, which can be seen as the cost taken by agent i for unit value. A low CPA means the budgets are consumed to obtain values effectively. Based on the basic task, Target CPA Task adds one more constraint on CPA that cpa should be lower than the desired CPA di. The formulation is as follows:\n$\\begin{aligned} \\mathop{\\text{maximize }}\\limits_{\\{a\\}} \\quad & \\sum_{t=1}^T (x_t\\cdot v_t)  \\\\ \\text{s. t. } & \\sum_{t=1}^T (x_t\\cdot c_t) \\le W_i, \\\\ &cpa_i \\le d_i. \\\\ \\end{aligned}$\nGiven that CPA can only be calculated at the end of one episode, the environment will only provide a sparse reward in Target CPA Task, which is different from the basic task. Unlike the budget constraint which cannot be violated in the environment, we allow agents to violate the CPA constraint, but we will penalize those agents for violations on their obtained values based on their CPA cpa. The sparse reward formulation in Target CPA Task is as follows:\n$r_i^{cpa} = \\rho(cpa_i; d_i) \\sum_{t=1}^T (x_t\\cdot v_t),$"}, {"title": "F Baseline Algorithms", "content": "We have implemented multiple baseline algorithms in AuctionNet to facilitate a quick start-up and comprehensive understanding of users. The baseline algorithms include PID Controller[36], Online LP[15], IQL[21], Behavior Cloning[30], and Decision Transformer[8].\nPID Controller. PID Controller is a traditional algorithm in the control field with a long history[4]. It is simple but effective in many scenarios. Recently, PID Controller has also been adopted in online advertising[36]. The idea of PID Controller is straightforward: PID Controller takes three parameters \u03bbP, \u03bbI, and \u03bbD for Proportional Control, Integral Control, and Derivative Control, respectively. We use the PID Controller to control the cost or bids of agents in this baseline.\nOnline LP. The optimization formulation (2) is a typical Linear Programming (LP) problem. Moreover, the variable x \u2208 {0,1} is binary, so the problem in each time step can be converted to a dynamic knapsack problem. Online LP solves this dynamic knapsack problem using a greedy algorithm.\nIQL. Implicit Q-learning (IQL) is an offline RL algorithm. The idea of IQL is evaluating offline Q-function only on the actions that appeared in the offline data, to avoid the overestimation in the out-of-distribution data. In practice, IQL utilizes expectile regression to realize the offline Q-learning on in-distribution data.\nBehavior Cloning. Behavior Cloning (BC) is a supervised learning algorithm given expert trajectories. The agent's policy learns by predicting the expert's action in the state of given trajectories. BC is a baseline for verifying the effectiveness of RL algorithms.\nDecision Transformer. Decision Transformer (DT) utilizes the ability of Transformer[31] for sequential decision-making. DT views the trajectories in MDP as a sequence and predicts actions given previous transitions."}, {"title": "G Implementation and Modules", "content": "The environment of AuctionNet consists of three main modules: the ad opportunity generation module, the auction module, and the bidding module. The general process of one time step in AuctionNet can be concluded as follows:\n1) The ad opportunity generation module generates features u = (u1, u2,\u2026\u2026, um) and values v = {vij } of m ad opportunities for n agents, where the number of ad opportunities m is sampled from an intern distribution within AuctionNet. This intern distribution is obtained from real-world online advertising statistics\n2) Agents bid for all the ad opportunities considering the predicted values provided by the environment and the historical auction logs.\n3) The auction module determines the winner of each auction, rewards, and costs by the auction mechanism.\n4) Agents receive rewards, costs, and new auction logs. The budgets of all the agents are updated according to auction results. In the next time step, all the processes above will be repeated.\nGiven this general process, we will introduce the three main modules in order. The ad opportunity generation module will generate features u of ad impressions related to the real online data. The ad auction module supports an auction similar to real-world online advertising and realizes several popular auction mechanisms for different research purposes. The bidding module supports explicitly modeling a multi-agent environment with several implemented baselines."}, {"title": "G.1 Ad Opportunity Generation Module", "content": "The target of the ad opportunity generation module is to generate diverse ad opportunity features similar to real online advertising data. The core of this module is the generative model. The objective of the generative model in AuctionNet is to generate data resembling real advertising delivery data. Useful information in the real advertising delivery data can be divided into four parts: features of ad opportunities (users' information), features of advertisers, time when the ad opportunity arises, and the values of the ad opportunities. In our model, we simplify the feature of advertisers to be the advertisers' industry categories. We focus on the generation of ad opportunity features and take the categories and time as conditions. The generative model consists of two components: the generative model for ad opportunity features and the prediction model for the values.\nFeature Generation. The ad opportunity feature contains two parts of information: the basic identity information of users and the consumption records such as the consumption amount. The identity information is discrete and the consumption records are continuous in general, which are processed with different measures. Diffusion [17] model is the most popular generative model recently which obtains SOTA performances in image generation with a simplified training process. We would like to adopt the diffusion model to generate the ad opportunity feature but struggle with the denoising operation which can result in unreasonable outputs such as a negative consumption amount. So we follow the idea of the Latent Diffusion Model (LDM)[25] to generate ad opportunity features. LDM adds noises and denoises in the latent space with a diffusion model and generates data from the latent space with an encoder and decoder. More details can be found in Appendix H.1.\nValue Prediction. The value prediction model needs to handle three types of information: ad opportunity features, the industry category information of advertisers, and time information. We simplify the category and time information as discrete values. Therefore, we aim to integrate the category and time information into the ad opportunity features for better value prediction. Besides, we hope this integration can partly reflect the variation pattern of the impression values related to advertisers' features and time. Multi-head attention (MHA), as a popular network architecture and the critical part of Transformer [31], can capture the relations among a sequence, thus we hope to utilize MHA for better integration. We combine cross-attention and self-attention to integrate the three types of information. We also follow the idea of position embedding in the Transformer to process the time information. More details are included in Appendix H.2.\nFor the consideration of interaction efficiency in AuctionNet, the environment utilizes a dataset consisting of generated features and corresponding predicted values. Though the ad opportunity generation module is trained with real online advertising data, an important question is whether the generated data can reflect the properties of real data. Therefore, we have done several related experiments and the empirical results will also be discussed in Section4.1."}, {"title": "G.2 Auction Module", "content": "The task of the auction module is to determine the winner and the winning price given all bids of agents for the ad ad opportunities. The costs of agents will change given different auction rules. The most commonly discussed auction rule is the Generalized Second-Price (GSP) Auction which means the winner should pay a cost slightly higher than the second-highest bid instead of the highest bid. The auction module internally supports several popular auction rules including GSP for the convenience of researchers. Besides, researchers can also design a specific auction rule related to their purposes with the interface of the auction module.\nAdditionally, the property of multiple slots has been implemented in our simulation platform. Multiple slots emerge from the application in the industry, which means one ad opportunity has multiple ad slots for ad displays. The ad slots are ranked by their exposure rates. A higher exposure rate slot is more valuable for advertisers. Suppose the number of slots is l, then the auction module will attribute l slots to the top l bidders and these bidders will receive different values according to different exposure rates of slots. In the environment, l is set to 3. Let slotij represent the slot of ad opportunity j wined by agent i and eij \u2208 [0, 1] represent the exposure rate of slotij, then the optimization formulation of BCB with multiple slots is as follows:"}, {"title": "G.3 Bidding Module", "content": "The bidding module is responsible for processing the multi-agent interactions between advertisers. This module implements the budget constraint and models the auto-bidding problem with sequence decision-making. Therefore, AuctionNet supports the mainstream paradigms including Budget Constrained Bidding (BCB) [33", "16": "in the auto-bidding field. This will help researchers validate and gain insights from existing algorithms.\nIn the bidding module, we explicitly model the multi-agent setting. Researchers can implement multi-agent algorithms"}]}