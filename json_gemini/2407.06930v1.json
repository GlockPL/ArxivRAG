{"title": "Integrating Ontology Design with the CRISP-DM in the context of Cyber-Physical Systems Maintenance", "authors": ["Milapji Singh Gill", "Tom Westermann", "Gernot Steindl", "Felix Gehlhoff", "Alexander Fay"], "abstract": "In the following contribution, a method is introduced that integrates domain expert-centric ontology design with the Cross-Industry Standard Process for Data Mining (CRISP-DM). This approach aims to efficiently build an application-specific ontology tailored to the corrective maintenance of Cyber-Physical Systems (CPS). The proposed method is divided into three phases. In phase one, ontology requirements are systematically specified, defining the relevant knowledge scope. Accordingly, CPS life cycle data is contextualized in phase two using domain-specific ontological artifacts. This formalized domain knowledge is then utilized in the CRISP-DM to efficiently extract new insights from the data. Finally, the newly developed data-driven model is employed to populate and expand the ontology. Thus, information extracted from this model is semantically annotated and aligned with the existing ontology in phase three. The applicability of this method has been evaluated in an anomaly detection case study for a modular process plant.", "sections": [{"title": "I. INTRODUCTION", "content": "Downtime due to faults occurring during operation sig- nificantly reduces the profitability of using Cyber-Physical Systems (CPS) [1]. To mitigate these impacts, efficient and effective corrective maintenance is essential. However, the growing complexity of CPS, driven by sophisticated technol- ogy integration and increased connectivity, complicates the process of fault localization [2]. Consequently, technicians need assistance systems that deliver accurate information, enabling swift restoration of system operations [1], [3]. The use of Artificial Intelligence (AI) to automate activities such as anomaly detection and fault diagnosis proves beneficial in realizing valuable digital services to accelerate the mainte- nance process [3], [4]. In order to generate valuable insights with data-driven models, a substantial volume of operational and maintenance data is required. Yet, this alone is often insufficient. Value-adding digital maintenance services need integration with other information and prior knowledge [5], [6]. This is even more important as the lack of domain knowl- edge frequently impedes the work of data experts [7], [8]. Additionally, CPS information from digital models, generated during the engineering phase, is highly relevant in several maintenance activities [1], [9]. As a result, effective and efficient corrective maintenance of CPS requires life-cycle- wide management and combination of data, information, and knowledge. Given these prerequisites, integrating data from heterogeneous sources poses a significant challenge [9]. Using the Digital Twin concept along with domain-specific ontologies effectively consolidates information for digital maintenance services [10], [11]. On the one hand, the introduc- tion of an ontology improves the integration and accessibility of data and digital models across the CPS life cycle [3], [9]. Consequently, domain knowledge can be leveraged for data analytics to efficiently generate new insights [6], [8]. On the other hand, due to their expandability and adaptability, existing ontologies can be efficiently populated and enriched with col- lected data and newly developed data-driven models [3], [12]. This includes the combination of extracted information with insights from the operational and maintenance phases with prior knowledge from engineering [1], [5]. Therefore, ontology design can benefit from data-driven approaches to gradually enhance the existing ontology with new knowledge. However, building application-specific ontologies involves substantial effort, as each maintenance use case requires unique informa- tion and data-driven models. The described synergies between ontologies and data-driven approaches are rarely exploited systematically. Hence, the goal of this contribution is to introduce a method that efficiently combines ontology design with data-driven modeling process steps. Firstly, this approach aims to effectively utilize existing domain knowledge captured in an ontology for the development of new data-driven models. Secondly, it employs these new data insights to expand the existing ontology for the maintenance application. This paper is structured as follows: Related works are analyzed in Sec. II, followed by the specification of relevant re- quirements in Sec. III. The method for building an application- specific ontology in the context of CPS maintenance is detailed in Sec. IV. The applicability of this method is evaluated in an anomaly detection case study for a modular process plant in Sec. V and discussed in Sec. VI. The paper concludes with a summary and an outlook in Sec. VII."}, {"title": "II. RELATED WORK", "content": "In the following section, related works are presented. Ini- tially, focus areas in ontology design are analyzed. Subse- quently, possibilities for integration with data-driven models regarding the corrective maintenance of CPS are examined. Given the significant effort required to build an application- specific ontology and the scarcity of ontology experts, the approach by Hildebrandt et al. [9] is particularly valuable. The authors advocate for creating reusable, modular ontological artifacts that incorporate domain-specific resources such as norms and standards. Ontological artifacts, such as Ontol- ogy Design Patterns (ODPs), include essential elements for ontology development and are created using semantic web technologies. The method starts with a systematic specifica- tion of ontology requirements through Competency Questions (CQs), conducted by software and domain experts. This step is followed by the creation of a Lightweight Ontology (LWO), represented as a Unified Modeling Language (UML) class diagram. Existing LWO Design Patterns are either utilized or new ones are developed and aligned for this purpose. Subsequently, an ontology expert transforms this LWO into a Heavyweight Ontology (HWO), which includes a termi- nological box (T-Box) in Web Ontology Language (OWL) format. For a maintenance use case, the assertional Box (A- Box) is populated with both static and dynamic data. This method is particularly suited for CPS ontology development, with information on function, structure, and behavior extracted from engineering artifacts being especially important. Poveda- Villalon et al.'s Linked Open Terms (LOT) method [13], while not specifically addressing CPS, further emphasizes the maintenance of ontologies in response to new insights and knowledge. Further research highlights the distinct advantage of com- bining ontologies and data-driven models [8], [14], [15]. This is especially beneficial for CPS maintenance, as the amount of data increases throughout its life cycle, while the number of knowledge-driven digital models decreases [15]. A major area of research focuses on integrating domain knowledge into the data modeling process in order to facilitate data integration and understanding. Key terms associated with this include Semantic Data Mining and Informed Machine Learning [6], [8]. Additionally, there are efforts to populate and enrich exist- ing ontologies using data-driven models. Ontology population refers to using data-driven models to efficiently instantiate the A-Box [15]. Conversely, ontology enrichment primarily involves expanding the T-Box with additional concepts and relations that have been identified through data-driven models [2]. Such combining approaches have already been applied in the context of corrective maintenance [1], [3], [5]. For example, Zhou et al. [4] use a Gaussian mixture density hidden Markov model (CGHMM) for vibration analysis of rolling bearings, integrating the results with an ontology to enhance fault diagnosis. Similarly, Steindl et al. [3] exam- ine a combination approach for a thermal heating process. An ontology defines behavior and structure to contextualize operational data, which then feeds into a linear autoregressive with exogenous input (ARX) model. Identified anomalies are accordingly used to expand the ontology. Given the diversity of data-driven models (e.g. classification or regression) employed for every use case, a methodological framework is necessary. The Cross-Industry Standard Process for Data Mining (CRISP-DM), a de facto standard for data- driven projects, integrates Data Mining (DM) and Machine Learning (ML) techniques to derive insights from data [16], [17]. This process model, which comprises steps like business understanding, data understanding, data preparation, modeling, evaluation, and deployment, is widely applied [17], [18]. Thus, this process model is subsequently used in combination with ontology design. The authors of this contribution have previ- ously proposed a method that incorporates ontological artifacts into the CRISP-DM, with a focus limited to the modeling step [18]. The analysis of using ontologies at the modeling step to increase efficiency was not extensively covered, considering the promising advancements in automated ML (AutoML) so- lutions [19]. However, a complete combination of CRISP-DM with ontology design, including evaluation and deployment, has not yet been examined in the context of CPS."}, {"title": "III. REQUIREMENTS", "content": "To design a method for developing and expanding ontolo- gies with data-driven models for CPS maintenance, require- ments (R) are established, based on the insights from Sec.II. \n  Systematic specification and documentation of on- tology requirements\nWhen developing and expanding ontologies, establishing systematic steps for gathering and documenting application- specific ontology requirements is essential [9], [13], [18]. This process aims to identify, at an early stage, the essential knowledge required for digital maintenance services by spec- ifying CQs. These specifications are pertinent for subsequent method steps, enabling early monitoring and validation of created ontological artifacts. Additionally, this documentation can assist in future projects by simplifying the requirements comparison across different applications [9]. \n R2: Contextualization of CPS life cycle data\nEfficiency losses are significant during data understanding and preparation steps, often due to the extensive time required for these activities [8], [15]. Research has demonstrated the immense value of incorporating CPS domain knowledge into these steps [6], [15], [18]. Beyond the issue of understanding data, relevant life cycle data is scattered across different silos, making the integration challenging [9], [18]. Consequently, it's essential to systematically equip data experts with the infor- mation from a domain ontology, ensuring unified semantics [8], [14]. \n R3: Semantic annotation of extracted information\nAs described in the previous section, data-driven models, e.g. with new insights from operations and maintenance, are well-suited for efficiently populating (A-Box) or expanding (T-Box) an existing ontology. Data-driven models generated in the modeling step of the CRISP-DM can greatly differ"}, {"title": "IV. METHODOLOGY", "content": "The method depicted in Fig.1 is designed to efficiently develop an application-specific ontology tailored to the cor- rective maintenance of CPS. Building on this foundation, digital services will be crafted to query, generate, and update information within the ontology. The steps are categorized into two swimlanes, which separate the CRISP-DM as well as domain expert-centric ontology design steps. The method is detailed through individual steps, highlighting the input and output artifacts, as well as the involvement of diverse experts in varied roles (such as developing and consulting). More- over, it is divided into three distinct phases. In the method's initial phase, a systematic specification of requirements for the development and expansion of the application-specific ontology is essential. The main objective is to formulate CQs drawn from the maintenance process and the digital services that need to be developed (see R1). The second phase aims to enhance the efficiency of extracting insights from data collected throughout the CPS life cycle. In this phase, a modular ontology is built to contextualize CPS data and incorporate domain knowledge for the subsequent data-driven modeling (see R2). In the third phase, extracted information is semantically annotated, followed by its alignment with the previously developed modular ontology. Subsequently, all created ontological artifacts must be made available for the deployment of digital maintenance services (see R3). In all phases, domain-specific, modular ontological artifacts are created or reused (see R4). These artifacts vary in their level of formality. Moreover, blue ones are pre-existing and documented from past projects, while green ones are newly designed for the specific project. Method steps range from manual to (semi-) automated, and fully automated steps. Key roles identified include domain, software, data and ontology experts (see R5). Domain experts, including technicians and engineers, possess knowledge in CPS maintenance. Software experts, such as architects and developers, manage software architecture and digital service implementation. Data experts, including data scientists, data analysts and data engineers, extract relevant insights from data. Ontology experts focus on semantic web technologies to guide ontology development."}, {"title": "B. Systematic Ontology Requirements Specification", "content": "The goal of Step 1 (business understanding) is to derive the assistance needs for the specific CPS maintenance process. In this step, domain experts determine the information needs in the form of User Stories. Standardized templates can be used for this purpose, which are textually filled out by the potential users of the assistance application. The project requirements define target metrics and criteria for evaluating interim results. Additionally, it's essential to model the examined maintenance process section to grasp the technician's journey through tech- nical and administrative maintenance activities. The Business Process Modeling Notation (BPMN) offers a standardized notation and the capability to generate an Extensible Markup Language (XML) schema for process automation with a workflow engine [20]. It serves as an effective communication tool among experts [3]. In addition to describing maintenance activities in the form of tasks, events and gateways can also be included [20]. Service tasks are suitable for integrating web services into the maintenance process. As such, they are placeholders for digital services to be built. Manual or user tasks, performed by the technicians, can also be combined with digital services. This is particularly relevant in main- tenance, where human intervention cannot be fully replaced by automation. If necessary, data flows and necessary data sources can be represented. By combining User Stories and the BPMN process model, a comprehensive understanding of the information needs and the maintenance process is created. In Step 2, it is necessary to specify the ontology require- ments. Based on the User Stories and the BPMN process model, software experts can detail the software architecture. Here, individual components of the architecture are modeled using UML. A critical part of this design involves modeling the architecture's components and defining interfaces where ontol- ogy requirements are articulated in the form of CQs. These are documented in an Ontology Requirements Specification Doc- ument (ORSD) and needed as input in the following ontology building steps. This documentation captures both the CQs and their anticipated answers. At this juncture, categorizing the CQs enhances clarity and focus. First, CQs relying on existing"}, {"title": "C. Contextualisation of CPS Life Cycle Data", "content": "In Step 3, an application-specific LWO (UML class diagram) is built, guided by the CQs from the ORSD identified earlier. Here, domain and software experts engage in development roles again. This ensures adherence to the domain expert- centric approach. Domain experts bring their understanding of the necessary concepts and relationships for modeling, pinpointing critical information for CPS maintenance. These can be used accordingly by data experts to identify relevant features for modeling. Meanwhile, software experts translate this domain knowledge into the LWO. To streamline this pro- cess, leveraging existing modular, standards-based, domain- specific lightweight ODPs is recommended, ensuring consis- tent semantics. The linkage of individual ODPs is employed by using four ontology alignment mechanisms (equivalent- to, subclass, attribute-to-class, relation-to), facilitating tailored relationships between concepts for the targeted application [9]. In particular, the subclassing option is suitable for achieving the necessary level of abstraction from a domain expert's perspective. Knowledge pertinent to the CPS, encompassing its structure, function, behavior, and fault diagnosis holds signifi- cant importance for corrective maintenance [1], [3], [18]. Thus, the provision of ODPs enriched with such knowledge promises high reusability. Numerous light- and heavyweight ODPs, demonstrating extensive reusability across various CPS life cycle use cases, have been previously developed by the authors [1], [9], [18].  For this application case for CPS maintenance, the ODPs VDI 3682 and VDI 2206 can be effectively reused to describe the functional and structural aspects of the CPS [1], [9]. Additionally, the Semantic Sensor Network Ontology (SSN/SOSA) is often helpful for detailing sensor and actuator data crucial for behavioral model development. Moreover, the ODP DIN EN 61360 facilitates semantic property descriptions of CPS. The ODP ISO 17359 supports fault diagnosis and condition monitoring by considering relationships between faults, fault symptoms, and diagnostic models. For emerg- ing knowledge needs, other information resources, especially domain-specific standards, may be analysed to create new, reusable lightweight ODPs for future applications. The LWO developed serves as a foundation for ontology ex- perts to build an application-specific HWO with Protege (Step 4), incorporating existing ODPs. Currently, methods towards automating this process exist."}, {"title": "D. Semantic Annotation of Extracted Information", "content": "Initial steps of the third phase involve rigorously evaluating the data-driven model (Step 8) using diverse metrics. This evaluation by data experts is crucial within the CRISP-DM, significantly influencing the project's success. The domain expert's consulting role is essential, in order to assess the accuracy of model results. If the data-driven model (DM or ML) fulfills predefined criteria, semantic annotation and ontology alignment steps follow. This involves revisiting and expanding the T-Box with additional concepts and relations, marked by the semantic annotation of the model's outputs. The LWO expansion (Step 9) requires collaboration between domain and data experts to define relevant concepts and relations. Apart from the developed data-driven model, this step also utilizes ontological artifacts that were created earlier (LWO, ORSD) as well as new ones (existing LWO Design Patterns, relevant information sources). The incorporation of specific concepts and relations varies depending on the insights from the data-driven model. Again, tools like the Chowlk converter and draw.io, as mentioned above, can automate the HWO expansion in this context. Additionally, the description of behavioral information can be updated using the newly developed data-driven model (e.g. regression model). This ensures that outdated system information does not compromise corrective maintenance activities. In the HWO expansion step (Step 10), all necessary ontolog- ical artifacts, especially the extended HWO as well as neces- sary rules are developed by the ontology expert, leveraging the existing artifacts (ORSD, extended LWO, existing HWO, rules and ODPs). This step may also establish mappings between data-driven model outputs and ontology instances. This is especially relevant for fault diagnosis, where identified fault symptoms need to be combined with fault classes. Another option is to define SPARQL INSERT requests to update the ontology with model outputs. The deployment step (Step 11) enables software experts to utilize the data-driven model and ontological artifacts (extended HWO and rules) to develop new digital services for assistance applications. The BPMN process model created in Step 1 can be reused to orchestrate the developed digital services according to the previously defined maintenance process using a workflow engine [3]."}, {"title": "V. CASE STUDY", "content": "The practical application of the method outlined in Sec. IV is demonstrated by an anomaly detection task within a modular process plant. The mixing module analyzed includes five tanks. The operational process involves transferring liquids from three tanks (B201-B203) to a mixing reservoir (B204), and then pumping the mixture into tank B205 via pump P201. After emptying tank B205, the cycle repeats. Monitoring is achieved through various sensors that measure tank levels, temperatures, and flow rates, with all data being captured in a database. Actuator states are also stored, providing context information about process control. Additional information about the structure and function of the plant was obtained from the P&I diagram, as well as existing CSV and JSON files. To evaluate the method, the high-fidelity simulation model provided by [22] was used. This model allows for the simulation of leakages and pipe blockages. The deployment of digital services for this process was facilitated by the semantic microservice framework introduced by Steindl et al. [3], which aligns with the Reference Architectural Model Industry 4.0 (RAMI 4.0) layers. Within this frame- work, the business layer includes the maintenance workflow using BPMN 2.0, which is automated by a workflow engine (Zeebe) in the functional layer. This layer also orchestrates the individual digital services, with inter-service communication handled by a message-oriented middleware (Apache Kafka). The developed application-specific ontology, residing in the information layer, both informs the digital services and gets updates with new data from these services."}, {"title": "A. Ontology Requirements Specification", "content": "As outlined in Sec. IV, the initial steps involved business understanding and ontology requirements specification (Step 1 and Step 2). In Step 1, User Stories were filled out using predefined templates. A key concern for the domain experts was the reliable detection of anomalies in the system in order to implement effective corrective maintenance activities."}, {"title": "B. Contextualisation of Mixing Module Life Cycle Data", "content": "To aid data experts with information from the life cycle of the mixing module, an application-specific HWO was developed in phase two. Software and domain experts drew upon existing domain-specific ODPs in Step 3. The ODP VDI 3682 was utilized for the functional description of the CPS. For structure information, ODP ISA 88 was applied, offering detailed descriptions of plant hierarchy and process recipes. Additionally, the SOSA ontology was utilized to link sensor and actuator information with behavioral data. The ODP DIN EN 61360 was employed for property description of the system. By aligning these ODPs, an application-specific LWO of the mixing module was created. During Step 4, an ontology expert created the HWO. Based on the LWO and the existing ODPs, all classes as well as object and data properties were modeled using Protege. Mappings from the CSV and JSON files, as well as the database, were performed using RML and R2RML to integrate both static and dynamic data. The OBDA tool Ontop [23] facilitated virtual access to individual sensor and actuator data from the relational database. Created SPARQL queries provided data experts with access to the ontology. Additionally, the LWO was made available to data experts in Step 5. The most extensive work of data integration in Step 6 for data preparation was accomplished through the development of the HWO. In Step 7, a python implementation of the OTALA algorithm was selected to learn a Timed Automata that depicts the module's behavior [24]. This learned model features one initial state and six production states, each incorporating actuator information and timing distributions. The Anomaly Detection algorithm ANODA was used for anomaly identification [24]. For this purpose, the fault cases described at the beginning were simulated to collect an appropriate test set. This set, alongside the Timed Automata, was then passed to the algorithm to identify anomalous behavior. A detailed description of this approach, including the algorithms used, can be found in [2]."}, {"title": "C. Semantic Annotation of Extracted Timed Automata and Anomalies", "content": "In the third phase of the method, the focus was on the semantic annotation of the newly extracted information (see Step 8). The goal was to answer the CQs from the ORSD defined in phase one regarding the anomaly detection activity. Consequently, it was necessary to align the information gener- ated through the CRISP-DM, especially the Timed Automata"}, {"title": "VI. DISCUSSION", "content": "In the following, the method will be discussed based on two criteria: Firstly, the assessment will determine whether required knowledge has been successfully represented. Sec- ondly, the method will be analysed in terms of its efficiency. Two key observations emerge with regard to the first discus- sion criterion: Firstly, all CQs in the case study were success- fully answered. Some CQs helped contextualize CPS life cycle data for data experts using the alignment of ODPs VDI 3682, ISA88, SOSA, and DIN EN 61360. Others were addressed through data-driven extraction of the Timed Automata as well as anomalies following the CRISP-DM. Using these artifacts in combination with ODP ISO 17359 and the UML State Machine the existing ontology could be populated (A-Box) as well as expanded (T-Box). Overall, the targeted digital services were successfully developed, allowing for the collection of relevant information through their combination. A detailed enumeration of the CQs and answers used can be found in [2]. Secondly, integrating engineering knowledge with data- driven insights from operational and maintenance phases was essential to develop the application-specific ontology. All steps of the method, in the defined sequence, were relevant in this context (phases 1-3, see R1-R3). Regarding the second discussion criterion, the use of reusable ODPs was a key factor to enhance efficiency (see R4). The development of the application-specific ontology was accelerated by reusing ODPs, previously applied in various publications by the authors ([1], [9], [18]). While the ODPs SOSA and UML State Machine were not developed by the authors, they were reused for this case study. The method presented was also applied to an aerospace maintenance use case (see [1]), focusing on a completely different CPS (aircraft component), another data-driven model as well as further maintenance activities (e.g. testing, fault diagnosis, mainte- nance planning). Many ontological artifacts created for this aircraft maintenance use case, which involved data-driven fault classification based on test bench and life cycle data, could be reused. In addition, the involvement of various experts and the provision of comprehensible ontological artifacts, such as the LWO, enabled efficient collaboration (see R5). However, improving the efficiency of ontology population is necessary, as modeling A-Box instances and defining mappings remain labor-intensive."}, {"title": "VII. SUMMARY AND OUTLOOK", "content": "This contribution introduced a method for the efficient development of an application-specific ontology for corrective"}, {"title": "maintenance of CPS.", "content": "In this context, the CRISP-DM was combined with a domain-expert-centric approach to ontology design. Firstly, based on a systematic specification of ontology requirements, ontological artifacts for contextualizing CPS lifecycle data were integrated as input into the steps of data understanding and data preparation. Secondly, data-driven models developed through the CRISP-DM were semantically annotated and aligned with the existing ontology. Based on the created ontological artifacts (e.g., HWO, LWO), digital services for assistance applications could subsequently retrieve from or update information in the ontology. The evaluation of the method was conducted using a case study. In this case, an ontology was developed to describe the function, structure, behavior as well as diagnostic information of a modular mixing plant. With the help of a modular domain ontology, a Timed Automata was learned, and anomalies were identified. Using ODPs such as the UML State Machine and ISO 17359, this information could be used to expand the existing ontology. With view to future work, there are additional hurdles to overcome and improvement opportunities to exploit. Partic- ular caution is warranted when making inferences based on the expanded ontology. Especially in fault diagnosis, when integrating data-driven models or incomplete data, considering uncertainty is essential. Besides, methods and tools to utilize engineering or runtime artifacts for mapping are needed, since instantiating the expanded ontology still requires substantial effort. However, the combination approach introduced also offers promising prospects. The method is suitable for In- formed ML approaches within fault diagnosis. Specifically, incorporating domain knowledge through knowledge graph embeddings can decrease the amount of data required for training. Thus, the detection of complex patterns and rela- tionships critical for fault diagnosis is facilitated, even with limited data. Beyond corrective maintenance, the integration of formalized domain knowledge with data-driven approaches is also suitable for predictive and prescriptive maintenance. Regardless of the maintenance application, the third phase can be utilized to iteratively refine the initially developed ontology using a data-driven approach. The modular structure allows for efficient updates based on operational insights without the need to revise the entire ontology."}]}