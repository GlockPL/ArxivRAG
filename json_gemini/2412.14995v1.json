{"title": "HSEvo: Elevating Automatic Heuristic Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMS", "authors": ["Pham Vu Tuan Dat", "Long Doan", "Huynh Thi Thanh Binh"], "abstract": "Automatic Heuristic Design (AHD) is an active research area\ndue to its utility in solving complex search and NP-hard com-\nbinatorial optimization problems in the real world. The recent\nadvancements in Large Language Models (LLMs) introduce\nnew possibilities by coupling LLMs with evolutionary com-\nputation to automatically generate heuristics, known as LLM-\nbased Evolutionary Program Search (LLM-EPS). While pre-\nvious LLM-EPS studies obtained great performance on var-\nious tasks, there is still a gap in understanding the proper-\nties of heuristic search spaces and achieving a balance be-\ntween exploration and exploitation, which is a critical factor\nin large heuristic search spaces. In this study, we address this\ngap by proposing two diversity measurement metrics and per-\nform an analysis on previous LLM-EPS approaches, includ-\ning FunSearch, EoH, and ReEvo. Results on black-box AHD\nproblems reveal that while EoH demonstrates higher diversity\nthan FunSearch and ReEvo, its objective score is unstable.\nConversely, ReEvo's reflection mechanism yields good ob-\njective scores but fails to optimize diversity effectively. With\nthis finding in mind, we introduce HSEvo, an adaptive LLM-\nEPS framework that maintains a balance between diversity\nand convergence with a harmony search algorithm. Through\nexperimentation, we find that HSEvo achieved high diver-\nsity indices and good objective scores while remaining cost-\neffective. These results underscore the importance of balanc-\ning exploration and exploitation and understanding heuristic\nsearch spaces in designing frameworks in LLM-EPS.", "sections": [{"title": "1 Introduction", "content": "Heuristics are widely utilized to address complex search\nand NP-hard combinatorial optimization problems (COPs)\nin real-world systems. Over the past few decades, significant\nefforts have been made to develop efficient heuristics, result-\ning in the creation of many meta-heuristic methods such as\nsimulated annealing, tabu search, and iterated local search.\nThese meticulously crafted methods have been effectively\napplied across various practical systems.\nNevertheless, varied applications with distinct constraints\nand goals may necessitate different algorithms or algorithm\nsetups. The manual creation, adjustment, and configuration\nof a heuristic for a specific problem can be extremely labo-\nrious and requires substantial expert knowledge. This is a\nbottleneck in many application domains. To address this is-\nsue, Automatic Heuristic Design (AHD) has been proposed\naims to selects, tunes, or constructs effective heuristics for a\ngiven problem class automatically (Choong, Wong, and Lim\n2018). Various approaches have been used in AHD, includ-\ning Hyper-Heuristics (HHs) (Pillay and Qu 2018) and Neu-\nral Combinatorial Optimization (NCO) (Qu, Kendall, and\nPillay 2020). However, HHs are still constrained by heuristic\nspaces that are predefined by human experts. Additionally,\nNCO faces limitations related to the necessity for effective\ninductive bias (Drakulic et al. 2024), and challenges regard-\ning interpretability and generalizability (Liu et al. 2023).\nRecently, the rise of Large Language Models (LLMs)\nhas opened up new possibilities for AHD. It is believed\nthat LLMs (Nejjar et al. 2023; Austin et al. 2021) could\nbe a powerful tool for generating new ideas and heuris-\ntics. However, standalone LLMs with prompt engineering\ncan be insufficient for producing novel and useful ideas be-\nyond existing knowledge (Mahowald et al. 2024). Some at-\ntempts have been made to coupling LLMs with evolutionary\ncomputation to automatically generate heuristics, known as\nLLM-based Evolutionary Program Search (LLM-EPS) (Liu\net al. 2024b; Meyerson et al. 2024; Chen, Dohan, and So\n2024). Initial works such as FunSearch (Romera-Paredes\net al. 2024) and subsequent developments like Evolution\nof Heuristic (EoH) (Liu et al. 2024a) and Reflective Evolu-\ntion (ReEvo) (Ye et al. 2024b) have demonstrated significant\nimprovements over previous approaches, generating qual-\nity heuristics that often surpass current methods. Even so,\nReEvo yields state-of-the-art and competitive results com-\npared with evolutionary algorithms, neural-enhanced meta-\nheuristics, and neural solvers.\nA key difference between LLM-EPS and classic AHD lies\nin the search spaces of heuristics. Classic AHD typically op-\nerates within well-defined mathematical spaces such as \\( R^n \\), whereas LLM-EPS involves searching within the space of\nfunctions, where each function represents a heuristic as a\nprogram. LLM-EPS utilizes LLMs within an evolutionary\nframework to enhance the quality of generated functions it-\neratively. Therefore, it is crucial to study and understand the\nsearch spaces of heuristics to establish foundational theories"}, {"title": "2 Background and Related Works", "content": "Recent advances in LLM-EPS have shown promising results\nin AHD. Evolutionary methods have been adopted in both\ncode generation (Nejjar et al. 2023; Ma et al. 2023; Hem-\nberg, Moskal, and O'Reilly 2024) and text generation (Guo\net al. 2023; Yuksekgonul et al. 2024). Notable among these\nmethods are FunSearch, EoH, and ReEvo. FunSearch em-\nploys an island-based evolution strategy, leveraging LLMs\nlike Codey and StarCoder to evolve heuristics for mathemat-\nical and COPs, outperforming traditional methods on tasks\nsuch as the cap set and admissible set problems. EoH uti-\nlizes genetic algorithm with Chain of Thought prompt engi-\nneering, consistently achieving superior performance in the\ntraveling salesman and online bin packing problems. ReEvo\nintroduces a reflective component to the evolution process,\nemploying two instances of GPT-3.5 to generate and refine\nheuristics, which has demonstrated effectiveness across var-\nious optimization tasks. These methods highlight the poten-\ntial of integrating LLMs with evolutionary strategies to en-\nhance the efficiency and effectiveness of AHD solutions."}, {"title": "2.2 Diversity in Evolutionary Computation", "content": "Diversity plays a pivotal role in enhancing the efficiency\nof algorithms in multi-objective optimization within the\ndomain of evolutionary computation (Solteiro Pires, Ten-\nreiro Machado, and de Moura Oliveira 2014). Numerous\nstudies have investigated various methods to measure and\nmaintain diversity within populations, as it critically im-\npacts the convergence and overall performance of these\nalgorithms (Pires, Tenreiro Machado, and Moura Oliveira\n2019; Wang and Chen 2012). Among these, the application\nof Shannon entropy has been particularly prominent in quan-\ntifying diversity and predicting the behavior of genetic algo-\nrithms. However, to the best of our knowledge, no existing\nstudies have thoroughly explored diversity within the con-\ntext of LLM-EPS. This gap in the literature motivates our\nin-depth exploration of diversity in LLM-EPS frameworks."}, {"title": "3 Diversity measurement metrics", "content": "In this section, we introduce a method to encode LLM-EPS\npopulation and propose two diversity measurement metrics,\nShannon-Wiener diversity index (SWDI) and cummulative\ndiversity index (CDI). We also conduct a diversity analy-\nsis on previous LLM-EPS frameworks, FunSearch, EoH and\nReEvo."}, {"title": "3.1 Population encoding", "content": "One particular problem of measuring diversity in LLM-EPS\nis how to encode the population. While each individual in\ntraditional evolutionary algorithm is encoded as a vector, in\nLLM-EPS they are usually presented as a string of code\nsnippet/program. This poses a challenge in applying pre-\nvious diversity metrics on population of LLM-EPS frame-\nworks. To tackle this issue, we suggest an encoding ap-\nproach consists of three steps: (i) removing comments and\ndocstrings using abstract-syntax tree, (ii) standardizing code"}, {"title": "3.2 Shannon-Wiener Diversity Index", "content": "Inspired by ecological studies, SWDI (Nolan and Callahan\n2006) provides a quantitative measure of species diversity\nwithin a community. In the context of search algorithms, this\nindex aims to quantify the diversity of the population at any\ngiven time step based on clusters of individuals. To compute\nthe SWDI for a given set of individuals within a community,\nor archive, first, we need to determine the probability dis-\ntribution of individuals across clusters. This is represented\nas:\n\\[\np_i = \\frac{C_i}{M}\n\\]\nwhere \\( C_i \\) is a cluster of individuals and \\( M \\) represents the to-\ntal number of individuals across all clusters \\( \\{C_1,...,C_N\\} \\). The\nSWDI, \\( H(X) \\), is then calculated using the Shannon en-\ntropy:\n\\[\nH(X) = - \\sum_{i=1}^{N} p_i \\log(p_i)\n\\]\nThis index serves as a crucial metric in maintaining the\nbalance between exploration and exploitation within heuris-\ntic search spaces. A higher index score suggests a more uni-\nform distribution of individuals across the search space, thus\npromoting exploration. Conversely, a lower index score indi-\ncates concentration around specific regions, which may en-\nhance exploitation but also increase the risk of premature\nconvergence.\nTo obtain SWDI score, at each time step t, we add all\nindividuals \\( R_t = \\{r_1,...,r_n\\} \\) generated at time step t to\nan archive. We encode the archive using our proposed pop-\nulation encoding in Section 3.1 to obtain their vector rep-\nresentations \\( V = \\{v_1, ..., v_n\\} \\). After that, we compute the\nsimilarity between two embedding vectors \\( v_i \\) and \\( v_j \\) using\ncosine similarity:\n\\[\nsimilarity(v_i, v_j) = \\frac{v_i \\cdot v_j}{||v_i|| ||v_j||}\n\\]\nTo find clusters in the archive, we consider each embed-\nding vector \\( v_i \\). We assign \\( v_i \\) to a cluster \\( C_i \\) if the similarity\nbetween \\( v_i \\) and all members in \\( C_i \\) is greater than a threshold\n\\( a \\). Mathematically, \\( v_i \\) is assigned to \\( C_i \\) if\n\\[\nsimilarity(v_i, v_k) \\geq a \\forall k \\in \\{1,...,|C_i|\\}\n\\]\nIf no cluster \\( C_i \\in \\{C_1, ..., C_N\\} \\) can satisfy the above con-\ndition, we create a new cluster \\( C_{N+1} \\) and assign \\( v_i \\) to \\( C_{N+1} \\).\nFinally, we compute SWDI score by computing Eq. (1), (2)\nacross found clusters."}, {"title": "3.3 Cumulative Diversity Index", "content": "While SWDI focuses on diversity of different groups of in-\ndividuals, the Cumulative Diversity Index (CDI) plays a cru-\ncial role in understanding the spread and distribution of the\nwhole population within the search space (Jost 2006). In the\ncontext of heuristic search, the CDI measures how well a\nsystem's energy, or diversity, is distributed from a central-\nized state to a more dispersed configuration.\nTo calculate the CDI, we also consider all individu-\nals within an archive, represented by their respective em-\nbeddings. We construct a minimum spanning tree (MST)\nthat connects all individuals within the archive A, where\neach connection between individuals is calculated using Eu-\nclidean distance. This MST provides a structure to assess the\ndiversity of the population. Let \\( d_i \\) represent the distance of\nan edge within the MST, where \\( i \\in \\{1, 2, ..., #A-1\\} \\). The\nprobability distribution of these distances is given by:\n\\[\np_i = \\frac{d_i}{\\sum_{j=1}^{\\#A-1} d_j}\n\\]\nThe cumulative diversity is then calculated using the\nShannon entropy:\n\\[\nH(X) = - \\sum_{i=1}^{\\#A-1} p_i \\log(p_i)\n\\]\nThis approach allows us to capture the overall diversity\nof the search space, providing insights into the spread of so-\nlutions. Higher CDI values indicate a more distributed and\ndiverse population, which is essential for maintaining a ro-\nbust search process."}, {"title": "3.4 Exploring the correlation between objective\nscore and diversity measurement metrics", "content": "To examine the correlation between the two diversity mea-\nsurement metrics and objective score, we conducted three\nexperimental runs using ReEvo on bin-packing online prob-\nlem (Seiden 2002). The experiment details can be found in\nthe Appendix. The objective scores and the two diversity\nmetrics from these runs are presented in Fig. 1. Additional\nresults for other tasks are also available in the Appendix.\nFrom the figure, there are a few observations that we can\ndrawn. First, the two diversity measurement metrics have a\nnoticeable correlation on the objective scores of the prob-\nlem. When the objective score is converged into a local op-\ntima, the framework either try to focus on the exploration\nby increasing the diversity of the population, through the in-\ncrease of SWDI in first and second run, or try to focus on the\nexploitation of current population, thus decrease the SWDI\nin the third run. We can also see that focusing on explo-\nration can lead to significant improvement on the objective"}, {"title": "3.5 Diversity analysis on previous LLM-EPS\nframework", "content": "To analyse the overall diversity of previous LLM-EPS\nframeworks, we conduct experiments on three differ-\nent LLM-EPS frameworks, including FunSearch (Romera-\nParedes et al. 2024), ReEvo (Ye et al. 2024b), and EoH (Liu\net al. 2024a), on three distinct AHD problems, bin-packing\nonline (BPO), traveling salesmen problem with guided local\nsearch solver (TSP) (Voudouris and Tsang 1999), and orien-\nteering problem with ACO solver (OP) (Ye et al. 2024a). The\ndetails of each experiment are presented in the Appendix.\nNote that, as highlighted in the previous section, SWDI fo-\ncuses on understanding the diversity of the population dur-\ning a single run. As such, it may not be helpful for quanti-\nfying the diversity across multiple experiment runs. Fig. 2\npresents the experiment results.\nIn BPO and TSP, EoH obtain the highest CDI but got the\nworst objective score. This implies that EoH does not fo-\ncus enough on exploitation to optimize the population bet-\nter. In contrast, while ReEvo and FunSearch obtain lower\nCDI than EoH on BPO and TSP, they achieve a better ob-\njective performance on all three problems. The experiments\non BPO and TSP problems highlight the inherent trade-off\nbetween diversity and objective performance of LLM-EPS\nframeworks. However, on OP problem, we can see that a\nhigh CDI is required to obtain a better objective score, which\nalign with our findings in Section 3.4."}, {"title": "4 Automatic Heuristic Design with HSEvo", "content": "In this section, we propose a novel LLM-EPS framework\ncalled Harmony Search Evolution (HSEvo). HSEvo aim to\npromote the diversity of the population while still achieve\nbetter optimization and alleviate the trade-off between diver-\nsity and optimization performance with a individual tuning\nprocess based on harmony search. HSEvo also aim to reduce\nthe cost incurred from LLM with an efficient flash reflection\ncomponent. Figure 3 illustrates the pipeline of our HSEvo\nframework. Examples of prompts used in each stage can be\nfound in the Appendix.\nIndividual encoding. Follow previous works in LLM-\nEPS (EoH (Liu et al. 2024a), ReEvo (Ye et al. 2024b)),\nHSEvo encodes each individual as a string of code snippet\ngenerated by LLMs (Fig. 4a). This encoding method allow\nthe flexibility of each individual, i.e., not constrained by any\npredefined encoding format, and also make it easier to eval-\nuate on the AHD problem.\nInitialization. HSEvo initializes a heuristic population by\nprompting the generator LLM with task specifications that\ndescribe the problem and detail the signature of the heuris-"}, {"title": "Selection.", "content": "HSEvo randomly selects parent pairs from the\npopulation, aiming to maintain the balance between explo-\nration and exploitation during our optimization process. The\nrandom selection may also counteract premature conver-\ngence, which is observed through the SWID trajectory out-\nlined in Section 3.4."}, {"title": "Flash reflection.", "content": "Reflections can provide LLMs with re-\ninforcement learning reward signals in a verbal format for\ncode generation tasks, as discussed by (Shinn et al. 2024).\nLater, (Ye et al. 2024b) also proposed integrating Reflections\ninto LLM-EPS in ReEvo as an approach analogous to pro-\nviding \"verbal gradient\" information within heuristic spaces."}, {"title": "Crossover.", "content": "In this stage, new offspring algorithms are\ngenerated by combining elements of the parent algorithms.\nThe goal is to blend successful attributes from two parents\nvia guide result guide information part of flash reflections.\nThrough this step, HSEvo hopes to produce offspring that\ninherit the strengths of both, which can potentially lead to\nbetter-performing heuristics. The prompt includes task spec-\nifications, a pair of parent heuristics, guide information part\nof flash reflection, and generation instructions."}, {"title": "Elitist mutation.", "content": "HSEvo uses an elitist mutation strategy,\nwhere the generator LLM is tasked with mutation an elite\nindividual representing the best-performing heuristic-by\nincorporating insights derived from LLM-analyzed flash re-"}, {"title": "Harmony Search.", "content": "From the analysis on Section 3.4 and\n3.5, we hypothesize that if the population is too diverse,\neach individuals inside will more likely to be not optimized,\nwhich may cause harm to the optimization process. We em-\nploy the Harmony Search algorithm to alleviate this issue by\noptimizing the parameters (e.g., thresholds, weights, etc.) of\nbest individuals in the population. The process is as follows:\n\u2022 First, we use LLM to extract parameters from the best in-\ndividual (i.e., code snippets, programs) of the population\nand define a range for each parameters (Fig. 4).\n\u2022 Following the work (Shi, Han, and Si 2012), we optimize\nthe above parameters with harmony search algorithm.\n\u2022 After parameter optimization, we mark this individual\nand add it back to the population. All marked individuals\nwill not be optimized again in the future time steps.\nFine-tuning these parameters makes the individual more op-\ntimized, therefore allowing us to encourage diversity during\nthe prompting while avoid the trade-off between objective\nperformance and diversity, as can be seen with EoH."}, {"title": "5 Experiments", "content": "Benchmarks: To assess the diversity and objective scores\nof HSEvo in comparisons with previous LLM-EPS frame-\nworks, we adopt the same benchmarks as Section 3.4 and\nconduct experiments on three different AHD problems, BPO\n(Seiden 2002), TSP (Hoffman et al. 2013) and OP (Ye et al.\n2024a).\n\u2022 BPO: packing items into bins of fixed capacity in real-\ntime without prior knowledge of future items. In this\nbenchmark, LLM-EPS frameworks need to design deter-\nministic constructive heuristics to solve.\n\u2022 TSP: find the shortest possible route that visits each city\nexactly once and returns to the starting point. In this\nsetting, LLM-EPS frameworks need to design heuristics\nto enhance the perturbation phase for the Guided Local\nSearch solver.\n\u2022 OP: find the most efficient path through a set of locations,\nmaximizing the total score collected within a limited time\nor distance. This setting requires LLM-EPS frameworks\nto design herustics used by the ACO solver."}, {"title": "5.2 Experiment results", "content": "Table 2 presents our experiment results on all three AHD\nproblems\u00b2. From the table, we observe that while our frame-\nwork still haven't obtained better CDI than EoH, HSEvo is\nable to achieve the best objective score on all tasks. On BPO,\nHSEvo outperforms both FunSearch and ReEvo by a huge\nmargin. This highlights the important of our findings from\nthe analysis in Section 3.5, where it is crucial to improve\ndiversity in order to optimize the population better.\nTo investigate the impact of our framework on the diver-\nsity of the population, we plot the diversity metrics and ob-\njective score of HSEvo through different runs on BPO prob-\nlem in Fig. 5. We can draw a similar observation with find-\nings in Section 3.4, where with a high SWDI and CDI, the\nobjective score can be optimized significantly. One thing to\nnote here is that in HSEvo first run and ReEvo third run in\nFig. 1, both have the SWDI decreasing overtime. However,\nin HSEvo, the SWDI is at around 3.0 when the objective\nscore improve significantly, then only decrease marginally\nafter that. In ReEvo, the objective score improves when\nSWDI at around 3.0 and 2.7, and the magnitude of the im-\nprovement is not as large as HSEvo, which implies the im-\nportant of diversity in the optimization of the problem and\nalso the impact of our proposed harmony search."}, {"title": "5.3 Ablation study", "content": "To gain a better understanding on our novel framework, we\nconduct ablation studies on our proposed components, the\nharmony search and flash reflection."}, {"title": "Harmony search analysis", "content": "As harmony search is a vital\ncomponent in our HSEvo framework, instead of removing it\nfrom HSEvo, we conduct an experiment where we add har-\nmony search into ReEvo framework. Table 3 presents our\nexperiment results on OP problem. From the results, we can\nsee that HSEvo outperforms both ReEvo and ReEvo with\nharmony search variant on both objective score and CDI.\nHere, notice that harmony search can only marginally im-\nprove ReEvo. This can be explained that ReEvo does not\nhave any mechanism to promote diversity, therefore it is not\nbenefitted from the advantage of harmony search process."}, {"title": "Flash reflection analysis", "content": "We also conduct another experi-\nment where we replace the reflection used in ReEvo with our\nflash reflection component. As our flash reflection is more\ncost efficient than original reflection, we reduce the number\nof tokens used for optimization to 150K. Table 4 presents\nour experiment results on OP problem. The results show that\ngiven a smaller number of timestep, ReEvo with flash reflec-\ntion mechanism can outperform HSEvo in optimization per-\nformance while obtain comparable results on CDI. However,\nwhen running with a larger number of tokens, ReEvo with\nflash reflection cannot improve on both objective score and\nCDI, while HSEvo improve both metrics to 5.67 and -14.62,\nrespectively. This implies that without diversity-promoting\nmechanism, flash reflection is not enough to improve the op-\ntimization process of LLM-EPS."}, {"title": "6 Conclusion", "content": "In this paper, we highlight the importance of population di-\nversity in LLM-EPS for AHD problems. We propose two\ndiversity measure metrics, SWDI and CDI, and conduct an\nanalysis on the diversity of previous LLM-EPS approaches.\nWe find that previous approaches either lack focus on the di-\nversity of the population or suffered heavily from the diver-\nsity and optimization performance trade-off. We also intro-\nduce HSEvo, a novel LLM-EPS framework with diversity-\ndriver harmony search and genetic algorithm for AHD prob-\nlems. Our experiment results show that our framework can\nmaintain a good balance between diversity and optimization\nperformance trade-off. We also perform additional ablation\nstudies to verify the effectiveness of components of our pro-\nposed framework. We hope our work can benefit future re-\nsearch in LLM-EPS community."}, {"title": "A.1 Bin Packing Online (\u0412\u0420\u041e)", "content": "Definition. The objective of this problem is to assign a col-\nlection of items of varying sizes into the minimum number\nof containers with a fixed capacity of C. Our focus is on\nthe online scenario, where items are packed as they arrive,\nrather than the offline scenario where all items are known in\nadvance."}, {"title": "A.2 Traveling Salesman Problem (TSP)", "content": "Definition. The Traveling Salesman Problem (TSP) is a\nclassic optimization challenge that seeks the shortest pos-\nsible route for a salesman to visit each city in a list exactly\nonce and return to the origin city."}, {"title": "A.3 Orienteering Problem (OP)", "content": "Definition. In the Orienteering Problem (OP), the objective\nis to maximize the total score obtained by visiting nodes un-\nder a maximum tour length constraint."}, {"title": "B.3 C HSEvo prompt examples", "content": "In this section, we synthesize the prompts used in the HSEvo\nframework. Our prompt system includes four stages initial-\nization population, flash reflection, crossover, and elitist mu-\ntation."}]}