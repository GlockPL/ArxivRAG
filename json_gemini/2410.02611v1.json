{"title": "INDICSENTEVAL: How Effectively do Multilingual Transformer Models encode Linguistic Properties for Indic Languages?", "authors": ["Akhilesh Aravapalli", "Mounika Marreddy", "Subba Reddy Oota", "Radhika Mamidi", "Manish Gupta"], "abstract": "Transformer-based models have revolutionized the field of natural language processing. To understand why they perform so well and to assess their reliability, several studies have focused on questions such as: Which linguistic properties are encoded by these models, and to what extent? How robust are these models in encoding linguistic properties when faced with perturbations in the input text? However, these studies have mainly focused on BERT and the English language. In this paper, we investigate similar questions regarding encoding capability and robustness for 8 linguistic properties across 13 different perturbations in 6 Indic languages, using 9 multilingual Transformer models (7 universal and 2 Indic-specific). To conduct this study, we introduce a novel multilingual benchmark dataset, IndICSENTEVAL, containing approximately ~47K sentences. Surprisingly, our probing analysis of surface, syntactic, and semantic properties reveals that while almost all multilingual models demonstrate consistent encoding performance for English, they show mixed results for Indic languages. As expected, Indic-specific multilingual models capture linguistic properties in Indic languages better than universal models. Intriguingly, universal models broadly exhibit better robustness compared to Indic-specific models, particularly under perturbations such as dropping both nouns and verbs, dropping only verbs, or keeping only nouns.Overall, this study provides valuable insights into probing and perturbation-specific strengths and weaknesses of popular multilingual Transformer-based models for different Indic languages. We make our code and dataset publicly available\u00b9.", "sections": [{"title": "1 Introduction", "content": "Transformer-based language models (Vaswani et al., 2017), pretrained in both mono-lingual and multilingual contexts using millions of text documents, have demonstrated substantial enhancements in the performance of various natural language processing (NLP) tasks (Kenton and Toutanova, 2019; Pires et al., 2019; Conneau et al., 2020; Radford et al., 2019; Brown et al., 2020; Wang et al., 2019, 2018). To understand what types of linguistic properties (surface, syntactic and semantic) are encoded across layers of Transformer-based models, initial studies have investigated the layer-wise representations via a range of probing tasks (Adi et al., 2017; Hupkes et al., 2018; Conneau et al., 2018; Rogers et al., 2020; Jawahar et al., 2019; Mohebbi et al., 2021). However, these studies focus on solely on English. Although, several studies have examined the presence of shared representation aspects across widely spoken languages in multilingual models (Chi et al., 2020; Acs et al., 2023), unfortunately, there is no work that investigates to what extent multilingual Transformer-based models encode linguistic properties for different languages. Further, recent neuro-AI studies have revealed that the brain uses different parsing strategies for different linguistic properties, which further differ across languages (Zhang et al., 2022; Oota et al., 2023). This inspired us to study the nuances of how multilingual Transformer-based models capture linguistic properties across layers and languages."}, {"title": "2 Related Work", "content": "Our work is most closely related to that of Jawahar et al. (2019) and Mohebbi et al. (2021), who focus on understanding the interpretability of language models via probing and observing linguistic structures in English. Our study on multilingual language models for six Indic languages complements their English-focused research.\nOur work also relates to the growing literature that creates resources for low-resource Indic languages. Several recent studies have developed resources including Indic language models (Khan et al., 2024), the Indic NLP suite (Kakwani et al., 2020), Indic BART (Dabre et al., 2021), Indic NLG (Kumar et al., 2022), IndicMT Eval (Dixit et al., 2023), and Naamapadam (Mhaske et al., 2023). Our research is the first to interpret both universal and Indic-specific models for Indic languages through probing representations and assessment of robustness, while also providing implications for future research directions. Overall, we complement these works by studying the linguistic structures of a wide range of low-resource Indic languages using multilingual models."}, {"title": "3 Probing Tasks", "content": "Probing tasks (Adi et al., 2017; Hupkes et al., 2018; Jawahar et al., 2019; Mohebbi et al., 2021) help unpack the linguistic features that may be encoded in neural language models. These probing tasks are formulated as prediction tasks and focus on various aspects of sentence structure. We experiment with eight probing tasks to evaluate how effectively multilingual models encode linguistic properties across six Indic languages: Hindi (hi), Telugu (te), Marathi (mr), Kannada (kn), Urdu (ur), and Malayalam (ml). These eight probing tasks are grouped into three categories: surface (SentLen), syntactic (BShift and TreeDepth), and semantic (SubjNum, ObjNum, VerbGender, VerbPerson and VerbNumber). We selected these tasks because they cover different aspects of language and require varying levels of abstraction and generalization. These tasks involve 3 binary and 5 multi-class classification problems. The specifics of the initial five probing tasks are thoroughly outlined in (Conneau et al., 2018) as well. We also provide brief descriptions for each probing task in the following, with a summary of class labels for each task in Table 1.\nSurface level tasks (1) Sentence Length (SentLen): Here, the objective is to predict the number of words in sentences, which has been grouped into 8 categories as shown in Table 1.\nSyntactic tasks (2) Tree Depth (TreeDepth): The goal of this task is to predict the maximum depth of the sentence's syntactic tree, which is categorized into five options based on depth intervals as shown in Table 1. As constituency data in Indic languages is unavailable, we utilize dependency tree data to determine the tree depth. This task provides valuable insights into the structural complexity and organization of sentences. (3) Bigram Shift (BShift): This task involves binary classification aimed at predicting whether two consecutive tokens within a sentence are inverted or not.\nSemantic tasks (4) Subject Number (SubjNum): This task evaluates sentences to determine the number of the subject in the main clause. It categorizes the subjects as NN (singular) or NNS (plural or mass, such as \u201ccolors,\u201d \u201cwaves,\u201d etc.). (5) Object Number (ObjNum): This task involves identifying whether the object of the main clause in a sentence is singular or plural/mass. It uses the label NN for singular objects and NNS for plural or mass objects. (6) Verb Gender (VerbGen): This task involves categorizing the grammatical gender of the main verb in a sentence as masculine, feminine, neutral, or any. (7) Verb Number (VerbNum): This task assesses the number of the main verb in a sentence, determining whether it is singular, plural, or any. (8) Verb Person (VerbPer): This task involves cate-"}, {"title": "4 INDICSENTEVAL Dataset", "content": "We curate the INDICSENTEVAL dataset from resources generated by the ILMT initiative, which serves as an Indic language counterpart to SentEval (Conneau et al., 2018) and offers labeled data for the eight probing tasks. We utilize the morph and chunk level Indic languages data (Tandon and Sharma, 2017; Bhatt et al., 2009; Xia et al., 2008) available in Shakti Standard Format (SSF) (Bharati et al., 2007, 1995). SSF is a highly readable representation for storing Indic language data with linguistic annotations. Fig. 4 in Appendix shows an example of a Hindi sentence in the SSF format.\nINDICSENTEVAL curation details. For each property, we gather data per language as follows. (1) SentLen: We iterate through all the nodes in the SSF format representation of the sentence and count number of words in each chunk. (2) TreeDepth: We utilize the data from the dependency tree to perform a traversal, specifically employing breadth first search. This traversal enables us to calculate the tree depth of the sentence. (3) BShift: For this task, we randomly (probability=0.2) select the sentences from the dataset, and then a randomly selected bigram (equal probability for all bigrams) is inverted. Sentences with inverted bigrams are marked as 1, and the rest as 0. (4) SubjNum/ObjNum: We identify the subject/object (a noun that can be singular or plural) of a sentence using the assigned semantic roles in the SSF format, and use the NN/NNS annotations. (5) Verb Gender/Person/Number: We first locate the chunk containing the main verb using the annotated chunk label from the SSF format. Then, we extract the gender/person/number information from the annotated morph output. Examples for each probing tasks per language are shown in detail in Table 11 in the Appendix. Also, detailed statistics of number of samples across 6 Indic languages for 8 probing tasks are provided in Appendix Tables 9 and 10."}, {"title": "5 Text Perturbation Analysis", "content": "Probing tasks can help us understand the extent to which various multilingual models encode different linguistic properties. But which particular words (such as nouns, verbs and others) in the input sentence help models encode these structures? To answer this question, we experiment with three different categories of perturbations: AppendR, DropText and Positional. We chose these perturbations because they simulate types of noise found in real datasets by introducing different degrees of noise and variation in the input text. Particularly, we experiment with the following text perturbations.\nAppendR. We append a random (R) phrase to original sentence. This mimics real scenarios where additional, irrelevant data is included in text input.\nDropText. DropText perturbations reflect situations where critical information is missing or only certain types of words are retained, which is common in incomplete or corrupted datasets. This includes, DropNV (dropping words based on their part-of-speech tag, specifically both nouns (N) and verbs (V)), DropN (dropping all nouns), DropV (dropping all verbs), DropRN (dropping one random noun), DropRV (dropping one random verb), KeepNV (dropping all words except nouns and verbs), KeepN (dropping all words except nouns), and KeepV (dropping all words except verbs). DropText perturbations are designed to provide deeper insights into word-level attention mechanisms within models, specifically aiming to determine whether models focus more on objects (nouns), actions (verbs), or the contextual elements surrounding these key parts-of-speech.\nPositional. This includes DropF/DropL/DropFL (replacing first/last/both words by \u201c[UNK]\" to maintain the original phrase length) and Shuffle (randomly shuffling the words in a sentence). These position-based text perturbations help us understand the extent to which words at specific positions (first/last) or relative positions impact the language structure encoding capabilities of various models.\nOverall, these text perturbations help in understanding the contribution of specific word types and sentence structures to the encoding capabilities\""}, {"title": "6 Methodology", "content": "Multilingual language models. We experiment with nine multilingual Transformer-based models (details in Table 12 in Appendix). First seven have been trained across 100+ languages; IndicBERT and MuRIL support 12 and 17 Indic languages, respectively. Representations are extracted from the encoder layers of mBERT-base, IndicBERT-base, mT5-base, XLM-R, InfoXLM and MuRIL; and from the decoder layers of BLOOM, mGPT and XGLM. We use pretrained model checkpoints from HuggingFace (Wolf et al., 2020).\nProbing tasks classifier. To evaluate each probing task using a multilingual model representation, we use logistic regression (Wright, 1995) classifier with sentence representations as input and the probing task label as target. The base model is frozen. We use mean pooling across tokens to get the sentence representation.\nDataset splits. We use a stratified five-fold cross-validation approach which involves splitting the dataset into five equal parts, where four parts are used for training and the remaining part is used for testing. This process is repeated five times, with each part used for testing once. To report our results, we calculate the average performance of the model across all five folds.\nHyper-parameters. We train logistic regression with a regularization parameter $C=20$ and use a L2 penalty term. For multi-class tasks, we use the \u201cmultinomial\u201d setting while training. All experiments were done on a machine with a T4 GPU.\nEvaluation metrics. Similar to earlier studies (Conneau et al., 2018; Jawahar et al., 2019; Mohebbi et al., 2021), for all the probing tasks, we use classification accuracy as evaluation metric. Let $A_c$ and $A_p$ be accuracy of a model on the clean and perturbed test sets, respectively. To evaluate the perturbation results for probing tasks, we use robustness score defined as $\\frac{1 - \\frac{A_c - A_p}{A_c}$. Typically, robustness score of a model ranges between 0 and 1 where 0 indicates that the model is not robust, and 1 indicates that the model is completely robust. Score > 1 suggests that the model's performance improves when the perturbation is applied."}, {"title": "7 Experimental Results", "content": "We measure probing accuracy independently for each multilingual model, within each layer separately. Along with six Indic languages, we measure the probing accuracy for English language across all multilingual models and compare the findings of Indic languages against English. Further, we investigate the robustness of these multilingual models by perturbing the input sentences."}, {"title": "7.1 Probing Results", "content": "How effectively do multilingual models encode hierarchy of linguistic structure for Indic languages? We assess the linguistic structure by contrasting universal models trained on 100+ languages with those specifically trained on Indic languages. Unless otherwise specified, the results presented in the main paper reflect an average accuracy across encoder-based universal models, decoder-based universal models and Indic-specific models.\nSurface-level tasks. We show the accuracy scores obtained for surface level task (i.e. SentLen) in the first row in Fig. 2. Analyzing the performance across languages, we observe the following patterns: (i) For encoder-based universal models as well as for Indic models, there is a trend of higher accuracy in the early (or lower) layers, which decreases in the later (or higher) layers. This pattern is expected, as surface-level tasks generally require minimal processing. (ii) Notably, the decoder-based universal multilingual models deviates from this trend, showing lower accuracy in the early layers and higher accuracy in the later layers. This unusual pattern in decoder-based universal models could be attributed to their unique autoregressive architectural design, and their approach to representing languages, especially those less common in the dataset. This suggests that decoder-based universal models may require their deeper layers to effectively grasp the nuances of these languages, even for tasks at the surface level. (iii) Overall, among all the models, Indic models report best accuracy, while encoder-based universal models display poorer performance. This is likely because Indic models are specifically trained on Indic languages, making them more attuned to the nuances and idiosyncrasies of these languages. On the other hand, universal models, which are designed for universal applicability, might struggle with specific linguistic features unique to Indic languages. These features include script differences, morphological"}, {"title": "7.2 Perturbation Results", "content": "We perform 13 different text perturbations to understand the contribution of specific word types and sentence structures to the encoding capabilities of multilingual language models\u00b3. We analyze the impact of such text perturbations for every pair of (model, language), (perturbation, model), (language, probing task), (model, probing task), (perturbation, language) and (perturbation, probing task) in Tables 2, 3, 4, 5, 6 and 7, respectively. All these tables show weighted averages across marginalized dimensions.\nWhich multilingual models are more robust to perturbations in Indic languages? Table 2 shows that universal models like InfoXLM, BLOOM, mT5 and mGPT show greater resilience to perturbations in at least four languages. In contrast, the universal model (mBERT) and the Indic-specific models (IndicBERT and MuRIL) display a more significant accuracy drop across all the Indic languages. Accuracy drop for BERT-specific models is perhaps because cross-lingual transfer might be less effective, resulting in decreased accuracy compared to other multilingual models.\nWhich text perturbations have the greatest impact on multilingual models? From Table 3, we observe: (i) Dropping both nouns and verbs has an adverse effect on all models. (ii) Similarly, dropping only verbs or retaining only nouns affects the"}, {"title": "8 Discussion and Conclusion", "content": "We investigated how well multilingual Transformer-based models comprehend linguistic structures in 6 Indic languages by evaluating 9 models using 8 probing tasks. To support this study, we contributed the INDICSENTEVAL dataset. Our results show that Indic-specific models like MuRIL and IndicBERT are the most effective at capturing linguistic properties within Indic languages due to their targeted training. Universal models like mBERT, InfoXLM, BLOOM, mGPT and XGLM exhibit mixed results. Our perturbation analysis reveals that decoder-based models are the most robust, as also observed by Neerudu et al. (2023). Verbs and the order of words are the most important signals that help the models encode linguistic structures. The TreeDepth is the most sensitive to all mentioned text perturbations, while SubjNum and ObjNum are the most resilient.\nOverall, our study represents the first analysis of the interpretability of both Universal and Indic multilingual language models across six Indic languages where several languages have large training corpora while some have less. Our scientific findings from this model interpretability analysis via both probing and perturbations shed light on how language models capture language hierarchy and how training data influences the language understanding across layers in these models. In the probing analysis, Indic-specific models like MURIL and IndicBERT are likely the best at capturing language hierarchy while Universal models like mBERT, InfoXLM, BLOOM, mGPT and XGLM show mixed results. Surprisingly, universal models show greater resilience to perturbations in at least four Indic languages. In contrast, the universal model (mBERT) and the Indic-specific models (IndicBERT and MuRIL) display a more significant accuracy drop across all the Indic languages. This suggests the necessity for multilingual models that are robust to perturbations and can capture language hierarchy regardless of their training data. Overall, our findings demonstrate significant variability in the ability of current multilingual models to capture surface, syntactic, and semantic structures across different Indic languages. A hierarchy of language proficiency is discernible primarily for languages with more extensive training datasets. This highlights the necessity for innovative approaches in multilingual modeling that can accurately capture language structures, even in low-resource languages.\nOur findings have direct implications for the emerging field of language model interpretability. Language proficiency is observed only for models with more comprehensive training datasets. The encoding ability and impact of perturbations varies across different languages and models, indicating the need for robust training strategies and architectures tailored to handle linguistic variations and perturbations effectively."}, {"title": "9 Limitations", "content": "The current work focused on only 6 Indic languages. It would be interesting to expand this to more Indic languages. We performed experiments with base versions of various models. It would be interesting to see if larger variants perform better at these tasks and if the trends differ. We experi-"}, {"title": "10 Ethics Statement", "content": "All the models used in this work are publicly available on Huggingface and free for research. We utilized publicly accessible resources in SSF format from https://ltrc.iiit.ac.in/showfile.php?filename=downloads/kolhi/ and https://ltrc.iiit.ac.in/showfile.php?filename=downloads/lingResources/newreleases.html. The datasets are licensed under Creative Commons by Non-Commercial 4.0 (CC by NC 4.0). No anticipated risks are associated with using the data from these provided links. We adapted the accessible resources to generate diverse probing and perturbation datasets as required."}]}