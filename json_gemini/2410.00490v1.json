{"title": "Learning Adaptive Hydrodynamic Models Using Neural ODEs in Complex Conditions", "authors": ["Cong Wang", "Aoming Liang", "Fei Han", "Xinyu Zeng", "Zhibin Li", "Dixia Fan", "Jens Kober"], "abstract": "Reinforcement learning-based quadruped robots excel across various terrains but still lack the ability to swim in water due to the complex underwater environment. This paper presents the development and evaluation of a data-driven hydrodynamic model for amphibious quadruped robots, aiming to enhance their adaptive capabilities in complex and dynamic underwater environments. The proposed model leverages Neural Ordinary Differential Equations (ODEs) combined with attention mechanisms to accurately process and interpret real-time sensor data. The model enables the quadruped robots to understand and predict complex environmental patterns, facilitating robust decision-making strategies. We harness real-time sensor data, capturing various environmental and internal state parameters to train and evaluate our model. A significant focus of our evaluation involves testing the quadruped robot's performance across different hydrodynamic conditions and assessing its capabilities at varying speeds and fluid dynamic conditions. The outcomes suggest that the model can effectively learn and adapt to varying conditions, enabling the prediction of force states and enhancing autonomous robotic behaviors in various practical scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "Quadruped robots have gained significant attention in recent years due to their potential applications in various fields, such as underground inspections, scientific exploration of challenging planetary analog environments, robust walking in the wild, and jumping and landing from air [1]-[6]. However, none of these robots currently possess the ability to operate in water. Accurate hydrodynamic modeling is essential for the operation of quadruped robots in water. This process is challenging due to complex fluid-structure interactions (FSI), the impact of varying leg configurations on fluid resistance, and the difficulty of accurately simulating the dynamic underwater environments.\nTraditional hydrodynamic models, which rely on the numerical solution of the Navier-Stokes equations, are effective but come with high computational costs and may not efficiently handle complex boundary conditions or nonlinear dynamics [7]\u2013[9]. These limitations hinder their practical application, especially for large-scale or real-time simulations [10]. Fluid-structure interaction phenomena, found in many natural phenomena, such as insect wings and fish fins, are typically modeled using body-fitted grid [8], space-time finite-element method [7] and immersed-boundary method [9]. However, these methods require extensive computational resources, limiting their application in practical problems. For robots with real-time changing structures, such as [11], [12], it is challenging to use fixed hydrodynamic coefficients for calculations. The fluid-structure interaction during motion is difficult to model accurately, which poses significant challenges for precise hydrodynamic modeling. These complexities necessitate using data-driven methods to predict the hydrodynamic forces and interactions in such dynamic environments.\nRecent advances in machine learning, particularly deep learning, offer promising alternatives to these traditional methods [13]\u2013[17]. Neural Ordinary Differential Equations (ODEs) [18] represent a novel class of deep learning models that frame the dynamics in the form of differential equations, providing a natural and flexible approach to modeling time-continuous systems. Unlike other dynamic models like symplectic neural networks [19] and Lagrange neural networks [20], Neural ODEs show a unique advantage by parameterizing the derivative of the state with respect to time using neural networks. This allows for an adaptive computation of the dynamics [21]\u2013[26], which could be particularly beneficial for capturing the intricate and nonlinear behaviors observed in the hydrodynamic environment. [27] proposed a Controlled Neural ODEs(CNODE) to handle the irregular time series data. The ODE-Transformer, introduced by [28], merges ODE-based continuous modeling with the Transformer's discrete processing capabilities in machine translation tasks.\nIntegrating data-driven approaches with Neural ODEs enables the leveraging extensive experimental and simulated datasets, enhancing the capability to generalize and predict under varied conditions without the need for explicit formulation of the governing physical laws. This is crucial for scenarios where the physics is poorly understood in traditional equations [29]-[31]. [32] propose the Auto-tuning Blimp-oriented Neural Ordinary Differential Equation method to tackle aerodynamic modeling in the miniature robotic blimps. [33] leverage the theory of function encoders to rapidly identify dynamics in the learned space, which includes a set of basis functions in Neural ODEs. [34] presented a meta-learning control method based on Neural ODEs for adaptive dynamics prediction in asynchronous industrial robots.\nMachine learning-based approaches in fluid dynamics have demonstrated tremendous potential. Many researchers have focused on the dynamic modeling of robotic fish and bluff bodies [35], [36]. [37] first demonstrated that reinforcement learning (RL) efficiently addresses Zermelo's Problem. They adopted this method to train a point-like swimmer in an Arnold-Beltrami-Childress (ABC) flow to navigate vertically as quickly as possible. [38] propose a novel active-flow-control strategy for bluff bodies to hide their hydrodynamic traces. [39] adopted multi-agent RL methods to learn a schooling behavior in two fishes. Although these methods yield satisfactory results in numerical computations, they are seldom used in practice. The primary reason is that it is hard to learn useful dynamic relationships, leading to poor performance during transitions between switching conditions. Transformers are a type of deep learning model that revolutionized the field of natural language processing [40] and have since been adapted to various other domains, including image processing [41], robots [42]-[44], and time-series analysis [45]. Attention not only facilitates effective information fusion but also enables reduced transformation. It significantly enhances the ability to understand and fuse information. [46] design a proven design element from top-performing networks, integrating transformer blocks as core building blocks in Neural ODEs. [47] proposes to augment simulation representations with a transformer-inspired architecture by training a network to predict the true state of robot building blocks given the simulation state in the robot application. Although the methods above have succeeded in deep learning fields, the transformer-based ODE model for underwater robots has not yet been studied.\nTo address these challenges, it is crucial to evaluate the model's performance under increasingly complex conditions that closely resemble real-world scenarios. In this study, we design a series of tasks with escalating complexity to systematically evaluate our proposed data-driven hydrodynamic model. This paper presents a practical approach to modeling the hydrodynamics of quadruped robots with swimming capabilities using Neural ODEs. To leverage the parallelization benefits of attention modules, we employ self-attention to compress the input bottleneck of the condition vector. Throughout our subsequent simulation experiments, the attention module processes an input of up to high-dimensions. This study chooses self-attention to extract the feature in the condition vector. We make several key contributions:"}, {"title": "II. METHOD", "content": "A. Preliminary\na) Neural ODEs based model: Neural ODEs [18] learn the dynamics by learning a continuous transformation of the input space. Neural ODEs can potentially capture the continuous-time changes in forces as a function of sensor inputs.\nIn deploying a Neural ODEs model, the approach differs from traditional discrete-time step models by treating the entire time series as a continuous flow of inputs into the model. A key feature of Neural ODEs is use of a parameterized ordinary differential equation $\\frac{dx(t)}{dt} = f(x(t), t, \\theta)$ to model the dynamic behavior, where $x(t)$ is the vector of states and $f$ is a function defined by the neural network with parameters $\\theta$.\nTo compute the state $x(t)$ at any time $t$, from the given initial state $x(t_0)$, it can be achieved by numerical integration methods such as the Forward Euler method and the Runge-Kutta method by ODE solvers [48].\n$x(t) = x(t_0) + \\int_{t_0}^{t} f(x(\\tau), \\theta) d\\tau$ (1)\n$= ODEsolver(x(t_0), f, t_0, t, \\theta)$ (2)\nWhere $\\tau$ represents the time variable. The choice of numerical integrator and step size can significantly affect the accuracy and stability of the model predictions.\nConsider minimizing a scalar-valued loss function $L()$. The Neural ODEs defines a adjoint state $a(t) = \\frac{\\partial L}{\\partial x_t}$, and its derivation could be defined as $\\frac{da(t)}{dt} = -a(t) \\frac{\\partial f(x(t),t,\\theta)}{\\partial x}$. The Neural Network f can use backpropagation to update its parameters. For more detail, please refer to [18]."}, {"title": "B. Model architecture", "content": "Our proposed model architecture aims to predict the hydrodynamic forces acting on a quadruped robot using a sequence of observation data. This work seeks to develop a generalized machine-learning model adaptable to a wide range of underwater robot applications, ensuring versatility and broad applicability across different environments and conditions. The key components of our model include Neural Ordinary Differential Equations (ODEs) and attention mechanisms. The steps involved in the model architecture are as follows:\nInput Data: The input data consists of a sequence of observation kinematic data $X_1,X_2,..., X_N \\in \\mathbb{R}^n$, each representing motion parameters at uniform time steps. In this work, the input dimension n can take values of either 4 or 35. When n = 4, it corresponds to the actual measurements of two joint angles and the linear speeds along two axes. When n = 35, it corresponds to data generated from the MuJoCo [49] simulator in the real-to-sim setup.\nAttention Mechanism: We incorporate an attention mechanism to effectively capture the temporal dependencies and dynamics in the observation data. The attention mechanism processes the input data into a latent representation. This transformation uses n-dimensional inputs and maps them to a latent vector $h \\in \\mathbb{R}^h$ dimensions. The attention layer enables the model to focus on hidden features, enhancing the learning of the underlying dynamics. In the attention-based model, the hidden state is calculated as $h = Attention(x)$. If there is no attention, the $h = MLP(x)$. Where the MLP is a feed-forward neural network.\nNeural ODE Framework: The core of our model is the Neural ODE framework, which learns the kernel function $f$ that represents the hydrodynamic dynamics. The Neural ODE is formulated as follows:\n$f(t) = F(t_0) + \\int_{t_0}^{t} f(h, \\theta, \\tau) d\\tau$\nwhere $f(t)$ is the predicted force vector, h is the latent representation obtained from the attention layer, and $\\theta$ represents the parameters of the neural network.\nODE Solver: To compute the state $F(t)$ at any time $t$, starting from the initial state $F(t_0)$, we use numerical integration methods such as the Forward Euler method and the Runge Kutta method. The ODE solver integrates the kernel function f over time, generating a continuous flow of outputs.\n$F(t) = F(t_0) + \\int_{t_0}^{t} f(F(\\tau), \\theta) d\\tau$ (3)\n$= ODEsolver (F(t_0), f, t_0, t, h, \\theta)$ (4)\nPrediction: The output of the ODE solver is a sequence of predicted force vectors $F_1, F_2, ..., F_L \\in \\mathbb{R}^f$, where L is the prediction length that can be tailored to span different temporal scopes. f represents the dimensionality of the output. When f = 2, the output corresponds to the forces along the x and y axes. When f = 6, the output includes both the forces and moments from the simulation data.\nThe adoption of an attention-based architecture for learning latent representations is both reasonable and innovative. Past Neural ODEs require the input state as the same as the output state like F. However, the input consists of four-dimensional kinematic trajectories. During training, the attention layer maps postures and forces effectively. This implementation employs attention mechanisms to enhance the feature representation of kinematic data."}, {"title": "C. Learning Objective", "content": "The learning objective is to minimize the prediction error between the predicted force vectors and the ground truth measurements. The steps involved in the learning process are as follows:\nDataset Preparation: The dataset consists of sequences of observation data and corresponding force measurements. The dataset is divided into training, validation, and test sets.\n$\\mathcal{D} := \\{(x_1, F_1), (x_2, F_2), \\dots, (x_M, F_M)\\}$\nLoss Function: We define a scalar-valued loss function $\\mathcal{L}()$ to measure the prediction error. The mean square error (MSE) is used as the loss function in this work:\n$\\mathcal{L}_{MSE} \\min \\sum_{i=1}^{M}\\sum_{j=1}^{L} (\\hat{F}_{i,j} - F_{i,j})^2$\nwhere L is the total number of time steps for each trajectory of measured state F and input x, and l is the mean square error. Our loss function incorporates the output over the ODE integration time, ensuring that the model's predictions are consistent with the underlying physical reality.\nBackpropagation: The Neural ODEs defines an adjoint state $a(t) = \\frac{\\partial L}{\\partial x_t}$, and its derivation could be defined as:\n$\\frac{da(t)}{dt} = -a(t) \\frac{\\partial f(x(t), t, \\theta)}{\\partial x}$\nThe neural network f can use backpropagation to update its parameters.\nOptimization: An optimization algorithm (e.g., Adam optimizer) is used to minimize the loss function and update the neural network parameters."}, {"title": "III. EXPERIMENTS", "content": "Training involves using a portion of the data to learn the model parameters, with separate validation and test sets used to evaluate generalization performance.\nA. Setup\nTo train and evaluate our model, we first collected a comprehensive dataset through towing experiments carried out in a controlled pool environment. The experimental setup is designed to measure the forces acting on the quadruped robot under various conditions. The setup includes the following components:\nPool Environment: A controlled pool environment ensures consistent and repeatable conditions for all experiments.\nTowing Mechanism: A towing mechanism with adjustable speed settings is used to tow the robot at different speeds and directions.\nForce Sensors: High-precision force sensors are attached to the robot to measure the forces along the x, y, and z axes.\nRobot Configuration: The quadruped robot is configured with various limb joint angles to simulate different motion scenarios.\nThe experiment involves towing the robot at speeds ranging from 0.2 m/s to 0.5 m/s, with increments of 0.1 m/s, in three directions: x, y, and xy (45 degrees). The forces acting on the robot are recorded for each towing condition, providing a rich dataset for training and evaluating the hydrodynamic model.\nB. Dataset\nThe dataset was collected during the towing experiments in Section III-A. The experiments were designed to measure the forces acting on the robot across 192 different towing speeds and the configuration of joints in Fig. 4.\nTo ensure that the simulation environment in MuJoCo accurately reflects the real-world performance of the robot, we implemented a multi-parameter optimization process to align the simulation with real data.\nDetails of the Dataset We use Unitree B1 quadruped robot [50] and the joint limitations are based on official models. Due to the limitation of towing tank, the speed only has three conditions: X, Y, XY (45deg). The input of the dataset is 4 dimensions, including joint position of second and third joint, linear speed in X and Y axes. The output is the hydrodynamic force in X and Y. We omit the force in Z that can be calculated based on gravity and buoyancy.\nRaw Dataset Fig. 5 show the raw data collected from the force sensor during towing experiments. From the results we can see, there are three phrage, towing in axis X, Y and XY. Here we ignore data from Z-axis.\nAugmented Data To enhance the dataset, we extend to more dimensions based on the real data collected, as shown in Table I. From Table II, our dataset is augmented as follows: Task 1.1 details the extension of the time series to 100-time steps, representing the sequential data of a quadruped robots maintaining a constant attitude angle. The Neural ODEs model is required to output the forces in two-axis directions throughout these 100-time steps. In Task 1.2, to highlight the comparative predictive capabilities of the Neural ODEs under variable conditions for online learning, the temporal length of each condition was expanded to 10 time steps by randomly choosing from datasets. The condition variable was also concatenated, which varied across 5 distinct scenarios. Task 1.3, addresses the increased complexity of conditions, during this extension, random perturbations are introduced at each time step, with magnitudes equal to 10% of the standard deviation of the respective Force values. In Task 1.2, and Task 1.3, we resample the trajectory across 192 distinct conditions to investigate the effects of these switching conditions further. Task 1.2 is a challenging experiment involving 40 condition switches over 400 time steps, with a perturbation intensity of 10%.\nC. Setting of Bechmark models\nTo fairly compare the results of different baselines, we maintained consistent parameter counts as much as possible. We conducted comparative experiments on a custom dataset with attention-based, MLP-based, and LSTM-based models, as well as the CNODE model suggested by a reviewer(1Nsi). The motivation behind our experiment is twofold:\n\u2022 To validate the advantages of the attention module by comparing it with the MLP-based ODE model. Is the inclusion of attention beneficial compared to not incorporating it?\n\u2022 Highlight the strengths of our model by contrasting it with the LSTM and CNODE baseline models. Is our model better than the baseline?\nD. Model prediction performance\nIn the following experiments, we record the performance of the Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) by predicting dynamic trajectories and ground truth. We compare standard models in the Neural ODEs framework, which include the Euler and RK4 integral method for ode and the Attention-based models proposed in this Task 1.\nFrom Table IV, it is evident that for ODE transition problems, attention-based methods generally outperform those without attention. This improvement is likely due to the integration of localized attention mechanisms focusing more on conditions. Additionally, our attention methods perform well under noisy conditions, with errors of 4.2, suggesting significant potential for model deployment. From an integration perspective, there is minimal difference between the euler and RK4 methods in noise-free scenarios. However, in"}, {"title": "IV. CONCLUSION", "content": "This paper proposes a data-driven model to learn the complex hydrodynamic model. We have developed attention-based Neural ODEs for dynamic prediction in underwater quadruped robots. Using data augmentation, our model uses kinematic trajectories as input and outputs dynamic hydrodynamic forces. The proposed model not only reduces computational overhead compared to traditional methods but also enhances the robot's autonomous behavior in dynamic environments. This work contributes significantly to the field of underwater robotics by providing a scalable and efficient solution for real-time applications.\nFuture Work The model's reliance on initial value calibration may necessitate prior estimates of fluid resistance"}]}