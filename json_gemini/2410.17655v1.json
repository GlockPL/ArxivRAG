{"title": "Mapping the Media Landscape: Predicting Factual Reporting and Political Bias Through Web Interactions", "authors": ["Dairazalia S\u00e1nchez-Cort\u00e9s", "Sergio Burdisso", "Esa\u00fa Villatoro-Tello", "Petr Motlicek"], "abstract": "Bias assessment of news sources is paramount for professionals, organizations, and researchers who rely on truthful evidence for information gathering and reporting. While certain bias indicators are discernible from content analysis, descriptors like political bias and fake news pose greater challenges. In this paper, we propose an extension to a recently presented news media reliability estimation method that focuses on modeling outlets and their longitudinal web interactions. Concretely, we assess the classification performance of four reinforcement learning strategies on a large news media hyperlink graph. Our experiments, targeting two challenging bias descriptors, factual reporting and political bias, showed a significant performance improvement at the source media level. Additionally, we validate our methods on the CLEF 2023 Check-That! Lab challenge, outperforming the reported results in both, F1-score and the official MAE metric. Furthermore, we contribute by releasing the largest annotated dataset of news source media, categorized with factual reporting and political bias labels. Our findings suggest that profiling news media sources based on their hyperlink interactions over time is feasible, offering a bird's-eye view of evolving media landscapes.", "sections": [{"title": "1 Introduction", "content": "Given its open and distributed nature, the World Wide Web (WWW) has become the main information source worldwide, democratizing content creation and making it easy for everybody to share and spread information online. On the bright side, this phenomenon enables a faster dissemination of information compared to what was possible with traditional newspapers, radio, and TV. On the downside, at the moment of removing the \"gate-keeper\" role from traditional media, it opens the door for additional problems, e.g., the spread of misinformation, at breaking-news speed, that can potentially mislead the users and even impact their behavior [25,3].\nThus, while the goal of this democratic channel is to provide users with the necessary tools to acquire greater knowledge about a topic, the reality is that in the way this knowledge (i.e., news) is presented and reported is not necessarily always impartial [2,18], and there is a growing concern regarding the biases of different media outlets when reporting specific events [14]. For example, in polarizing topics like politics, many of the news can be biased towards one political perspective or the other, i.e., political bias, which may influence citizens' voting decisions and preferences of undecided individuals [13].\nTo mitigate the impact of misinformation and to favor critical assessment for the newsreaders, independent bias assessment services like MBFC4 and allsides5 perform information verification. The review process is performed manually by professionals at the event or article level, clearly this is a challenging schema to maintain on the long term given the fast-speed proliferation of both news media websites and news articles. Automation comes handy to perform certain fact-checking tasks, like gathering information (e.g. articles with similar topics, metadata on the media-publisher, etc.); for the more complex parts of the verification analysis, advances in AI continues pushing the boundaries in order to provide valuable tools (for example, search and retrieval, summarization, transformers, LM and LLMs). While the latest LLMs performance on several tasks is remarkable, they are still prone to carry unauthenticated information [17].\nWhile many existing tools are being adopted to support verification tasks at the article level (with and without human supervision), there are very few advances to fully automate news media profiling at the source level (other than popularity). Previous research has shown evidence that some news bias descriptors can be inferred by just inspecting the outlet website metadata [10,16]. Other approaches have addressed source reliability, factuality of reporting or political bias, by assembling information from multiple external and social media sources, metadata and/or content-based features [4,5,3,22,9,21,7]. Unfortunately, methodologies relying on social media metadata can not longer be reproduced at scale given the current access restrictions.\nA recent research shifting from the social media and text-based approach, is presented in [8]. Burdisso et al., proposed a highly performing and robust graph-based methodology to score news media reliability. Their method considers the longitudinal interactions on the web to learn a reliability value from their source neighbors. Based on the research evidence that neighboring properties can be spread among news media outlets, we extend their work and we propose to address the following research question: to what extent it is possible to profile news media outlets (i.e., different properties) based solely on their interaction with other media sources? To address this question, in this paper we focus on two challenging media bias descriptors: factuality of reporting and political bias."}, {"title": "2 Related Work", "content": "The bias in news media is a pervasive and ubiquitous problem [14,15,25]. The need for applied research on news media descriptors has increased since 2000 due to the generalized adoption of social media platforms, and the proliferation of tools that facilitate both websites and news-content creation [12,6]. Bias in news media has a wide descriptors spectrum [14,15,27], for example Racial Bias refers to preferences of coverage or not of events related to minorities or group of individuals [24]. Gender Bias refers to the inclination towards one gender over another, resulting in unequal treatment, coverage and perception [23,1]. Political Bias, refers to partial representation of political issues or tendency to favor a particular political ideology.\nA significantly large NLP community has reported advances on news media bias at the article level (i.e., based on content), also referred as bias at the event-label or a short-term bias on a selected event [14]. However, in this paper, we contribute towards the news media source profiling (i.e., at the source level). We focus our research work on the following two long-term bias descriptors:\nFactual Reporting Recent task challenges, particularly the Check That! Lab challenge at CLEF 2023, have addressed the factuality of reporting based on three classes (High, Mixed and Low) at the article level [21]. Submitted models range from traditional supervised models (such as SVMs, Random Forest, gradient Boost) to Deep Learning-based ones [21,21,19]. Due to the challenging nature to perform factuality assessment, graph-based models emerged to address the problem disclosing better performance when combined with text-based approaches [11,4,3,22]. Fairbanks et al., [11] proposed a structural model based on the metadata from the article's news web links. Their findings revealed that credibility, a descriptor in close relation with factual reporting, is harder to determine from merely the content. Baly et al. [3] analyzed the factual reporting focusing on the source media. Their approach used text-based features from articles content and metadata including Wikipedia pages, Twitter, URL-related features (domain, orthography, char n-grams), and Web traffic (Alexa service). Also targeting the factuality at the media level, Panayotov et al., [22] proposed to model the factuality of reporting using graph neural network and similarity between news media based on their audience overlap. Although the latest models revealed significant improvements at the media level, the methods in [3,22] rely on the Alexa website ranking and web traffic information, which is now discontinued.\nMore recent approaches are focusing on state-of-the-art LMs and LLMs, from adversarial training, ensemble of models based on RoBERTa or GPTs [20,26]. Li et al., heuristics on adversarial training revealed the importance of semantics in the title and the summary of the news captured at the beginning and end of the article. Their best performing political inference results from a majority voting from four implemented models from which, two are RoBERTa-based. Tran et al., examined the impact of imbalanced training data between High, Mixed and Low factual reporting. The authors introduced a RoBERTa-based back-translation framework that significantly surpassed the baseline performance. Their approach ranked among the top three performers at the Check That! Lab challenge in 2023. To the best of our knowledge, the state-of-the-art methodology in media profiling, outperforming ensembles of content-based and external data was recently introduced in [8]. Burdisso et al., propose an hyperlink-interactions graph to infer News source reliability degree (a continuous value) based on reinforcement learning techniques. In addition to the standing performance, authors contribute with the largest reported dataset in source media profiling with 17k English-speaking news outlets.\nPolitical Bias In the recent years, the inference of political bias at the outlet level has been approached by applying SVMs, CatBoost and applied oversampling techniques, mostly enhancing content-features from articles [4,9,2]. Baly et al., [4,3] proposed a framework based on SVMs reporting significant results when complementing content-based data with Wikipedia and social media metadata. Recently, Azizov et al., [2] proposed a majority voting ensemble of CatBoost models and TF-IDF, showing better performance than LM-frameworks at the CheckThat! lab challenge at CLEF 2023 [9] given a benchmark dataset with three political classes (Left, Center, Right). In Panayotov et al. [22], the political bias was modeled using a graph neural network augmented with audience/social media data. Graph-based approaches showed evidence that metadata capturing information other than the article content improved classification of political stance. Given the still open challenge to accurately infer political bias at the news source level, more recent approaches are exploring the pertinence of using LMs [26,27]. Tran et al. [26], analyzed and addressed the three-class (Left, Center, Right) imbalance by translating to Spanish and back to English the classes with less articles. Then, they fine-tuned RoBERTa English-large, and performed a majority voting at the article-level to infer the news source political leaning, showing a significant performance above the baseline. Wessel et al., [27] proposed a framework using transformers to infer 9 bias descriptors. For the case of political bias, the original bias annotation provided at the outlet level is transformed into two classes bias and not-bias. Despite the 2 million political news articles used in this work, they were exclusively gathered from the top 11 most popular US media outlets. Authors concluded that cognitive and political bias at the content-level are the most challenging bias descriptors to detect, in contrast with for example gender or racial bias.\nAlthough some approaches show significant improvement over majority baselines, the robustness and scalability of the models is not sufficient to consider the factual reporting and political bias problem solved. Contrary to previous research that depends on content, audience feedback, and/or metadata, in this paper we extend a very recent work that models the problem in a scalable fashion relaying on network interactions among the news sources [8]. Following sections describe the proposed methodology and obtained results."}, {"title": "3 Methodology and Strategies", "content": "In order to validate our research question and based on the evidence presented by Burdisso et al. that longitudinal interactions can spread the news media reliability degree among their neighbors [8], we extend their work to address factual reporting and political bias.\nThe introduced approach consists of first building a news media graph from the WWW and then applying different reinforcement learning strategies to infer the reliability values. More precisely, constructing a weighted directed graph G = (S, E,w) where there is an edge (s, s') \u2208 E if sources contains articles (hyper) linked to s' and where the weight w(s, s') \u2208 [0,1] is the proportion of total hyperlinks in s linked to s'. In this work, we hypothesize that the political bias and factual reporting of sources s can be estimated from the sources it interacts with, by inheriting their properties.\nFollowing the original work in [8], we model the estimation as a Markov Decision Process (MDP) (S, A, P, r) such that: (1) The set of states S are all the news outlets websites \u2014i.e. S = S; (2) The set of actions A contains only one element, the \"move to a different news media website\" action; (3) The probability P of moving from the origin s to s' will be given by the proportion of hyperlinks in s connecting to s' \u2014i.e. we have P(s, s') = w(s, s'); and (4) The reward r of moving to another news source (s') is determined only by the origin source(s), and it will be positive or negative depending on the known property -e.gr(s) = 1 if we know for this s we have Right or High, for political bias or factual reporting, respectively; r(s) = \u22121 if s is Left or Low, for political bias or factual reporting, respectively; r(s) = 0 otherwise. Finally, the property (political bias or factual reporting level) value for all news sources s in the graph will be estimated by a function p(s) following 4 different strategies:\nF-property: The property value is proportional to the expected perceived reward given by the following Bellman equation where is the unique policy (i.e. the probability of taking action a \u2208 A in state s) and \u03b3\u2208 [0,1) the\n$$p(s) = \\sum_{s'\\in S} P^{\\pi} (s, s')[r(s') + \\gamma p(s')]$$\nThat is, under this strategy, the value of sources will be inherent from the sources it connects in the Future.\nP-property: The property value is interpreted a proportion of the accumulated perceived reward, i.e., the value is inherited by the sources that lead to it in the Past. The value is thus, giving by the following the reverse Bellman equation:\n$$p(s) = r(s) + \\gamma \\sum_{s'\\in S} P^{\\pi} (s', s)p(s')$$\nFP-property: This strategy strategy combines the previous two strategies by considering Future and Past information. A source s increases its positive value p(s) as more positive sources link to it ($p_{+}(s)$), while losing value as it links to more negative sources ($p_{-}(s)$). Thus, p(s) is simply defined as:\n$$p(s) = p_{+}(s) - p_{-}(s)$$\nI-property: Investment Strategy (invest and collect credits) consisting of two iterative steps, repeated n times: (1) all sources invest their property value to the neighboring sources proportionally to the strength of their links (w(s, s')) following Equation 4, (2) sources collect the credits back proportionally to the investment and update its own property value following Equation 5.\n$$totalcredits(s) = \\sum_{s'\\in S} w(s', s) \\cdot \\rho(s')$$\n$$p(s) = p(s) + \\sum_{s'\\in S} w(s, s') \\cdot creditss(s')$$\nwhere credits are distributed among investors s', in proportion to their contribution to s, i.e, $creditss\u0131(s) = w_{s'}(s) \\cdot totalcredits(s)$."}, {"title": "3.1 Datasets", "content": "There are several attempts to unify existing datasets to assess Bias in news media. Recently, a unified bias dataset was presented including several Bias descriptors [27], nevertheless, the collection of articles, sentences, comments, etc., are on one hand targeting rather short-term bias (text-based), and on the other hand large part of the data do not have URLs to existing news media sources. Recently, [8] released the largest dataset with URLs annotated with"}, {"title": "4 Experiments and Results", "content": "In this work we used the graph G built in [8] consisting of 17K news sources obtained after processing 100M news articles from Common Crawl News. Following [3,8] we report 5-fold cross-validation evaluation results on our MBFC datasets, whereas for CLEF's Check That! we report results on the official test set. In order to estimate the factual score of reporting from the graph, we first convert the factuality/bias ground truth labels from the training set into rewards as follows: r(s) = 1 if the media label is High/Right, r(s) = \u22121 if Low/Left, and r(s) = 0 otherwise. Then, at inference time, sources s are classified with the label Right/High if p(s) > 0 and Left/Low otherwise. Even though one limitation of the proposed strategies is that they are essentially binaries, in order to compare results in Check That! three-label classification task, we use the"}, {"title": "4.1 Factuality of Reporting", "content": "Table 2 shows the results from the 5-fold cross-validation for Factual Reporting. The baseline for comparison includes Random and Majority class classification.\nThe F-Factuality strategy performed at 57.60 F1-score overall, for the individual classes Low Factual reporting performance is 95.00 F1-score and 20.19 for High Factual Reporting. For all cases there is significant improvement with respect to the baselines. For P-Factuality F1-score performance is 85.13, and 98.7 and 71.55 for the Low and High classes. The significantly high performance reveals that indeed the graph with past reward strategy captures close interacting networks on both sides, High score and Low score of factual reporting. The strategy FP-Factuality performs at 71.35 F1-score, although it outperforms F-Factuality and the baselines, it remains behind P-Factuality. Finally, the I-Factuality strategy outperforms all the other strategies up to 87.99 F1-score, 76.96 for class High and 99.02 for the class Low. The results show that for the case of I-Factuality (the invest and collect strategy), the gathered information from the hyperlinks and its neighbors can accurately capture the level of factuality, significantly better for the class Low."}, {"title": "4.2 Political Bias", "content": "Results on MBFC. Table 2 shows the 5-fold cross-validation results for F1-score and Accuracy, we included two baselines Random, and Majority class for comparison. For the political leaning the F-Political performs at 60.42 F1-score, and 79.29 F1-score for Right at the class level, showing a modest improvement over the baseline (76.08). For P-Political the overall F1-score performance is 74.08, with 65.8 for the class Left and 82.36 for the class Right. For the combined FP-Political the F1-score of 64.90 outperforms the F-Political but does not improve the P-Political performance, for both the overall and the class level, which indicates that past information contributes more to the predictions. The best performing strategy is I-Political performing at 77.77 F1-score and, 70.97 and 84.56 for the classes Left and Right respectively. At the class level, our results on political bias show significantly better performance on the class Right. Figure 1 shows part of the graph for the news media source www.newrepublic.com, where the values are estimated with I-political. The size of the node is proportional to their political bias, as newrepublic predominantly engages with Left-wing sources, its final value leaned significantly towards the Left (red).\nResults on the CLEF CheckThat!. Table 3 shows the F1-score performance and the official scoring metric MAE (Mean Absolute Error) for the Labs at CLEF 2023. The political labels were coded as ordinal values (Left-0, Center-1, Right-2), a smaller MAE value translates into better predictions from the proposed models. The baseline with MAE of 0.902 uses an SVM classification model based on N-Grams. The top performed participating model [2] achieved a MAE of 0.320, outperforming the baseline and the other participating models. However, our proposed strategies (P-Political and I-Political) outperform the best-performing participating model in all reported metrics the top (MAE, F1-score and Accuracy). The MAE top performance (smaller MAE) indicates that the miss-predictions are less severe (from Center to the extremes or vice-versa), otherwise inferences will result on a higher penalization if predicting completely opposite extremes Left Right."}, {"title": "5 Conclusions", "content": "This research extends the methodology proposed in [8] by addressing long-term news media profiling, contrasting with approaches focused solely on short-term bias. Our experiments on two challenging bias descriptors factual reporting and political bias utilize four reinforcement learning strategies for classification performance evaluation. We provide compelling evidence supporting the longitudinal view of news media and their web interactions as a robust and scalable proxy for profiling, particularly regarding political bias and factual reporting. Concretely, performed experiments show that the proposed approach allows superior performance in estimating outlet media bias descriptors compared to baseline methods. Furthermore, we present promising results from comparisons with other participating models submitted to the CLEF 2023 Check That! lab, designed for inferring political bias in currently active news outlets. Our approach surpasses top results in both F1-score and the official MAE performance measure, establishing a new SOTA result for this particular task. Finally, as an additional contribution, we release the largest dataset at the source media level, annotated with standard political bias and factual reporting labels.\nAs part of future efforts, we aim to investigate the dynamics of political bias changes over time within news media, such as shifts from center to extreme positions. Additionally, we plan to explore the integration of other bias descriptors, such as press freedom, in multi-task bias identification."}]}