{"title": "JAM: A Comprehensive Model for Age Estimation, Verification, and Comparability", "authors": ["Fran\u00e7ois David", "Alexey A. Novikov", "Ruslan Parkhomenko", "Artem Voronin", "Alix Melchy"], "abstract": "This paper introduces a comprehensive model for age estimation, verification, and comparability, offering a comprehensive solution for a wide range of applications. It employs advanced learning techniques to understand age distribution and uses confidence scores to create probabilistic age ranges, enhancing its ability to handle ambiguous cases. The model has been tested on both proprietary and public datasets and compared against one of the top-performing models in the field. Additionally, it has recently been evaluated by NIST as part of the FATE challenge, achieving top places in many categories.", "sections": [{"title": "I. INTRODUCTION", "content": "Age verification is crucial across industries due to regulatory demands and the need for secure interactions [1], [2]. Ensuring users meet age requirements is essential for legal compliance, safeguarding minors, and preventing fraud. Our group has developed a robust model addressing three key aspects:\n1) Age Estimation: Predicting an individual's age from digital images (e.g., selfies). This allows platforms to provide age-appropriate content and comply with legal standards.\n2) Age Verification: Comparing the estimated age against a required age threshold (e.g., 18, 21, 25) to grant or restrict access. This is vital for services offering age-restricted content.\n3) Age Comparability: Comparing the age from a selfie with the claimed age from an ID. While not common in general use, it's crucial for identity verification to detect fraud by ensuring the individual's appearance matches their claimed age.\nOur work considers all these dimensions to tailor solutions to our clients' diverse needs. We conducted extensive testing to ensure our model performs well across different demographic groups. This paper is organized as follows: In the Sec. II, we highlight existing works on age estimation and outline the differences between those approaches and ours. In the Sec. III, we discuss our custom loss function and its constituent components in detail. Finally in the Sec. IV, we describe the datasets and showcase evaluations on age estimation, age verification, and age comparability."}, {"title": "II. RELATED WORK", "content": "Our work builds upon extensive research in age estimation, incorporating specialized models and advanced distribution learning techniques.\nAdaptive Label Distribution Learning (ALDL) was introduced to provide sample-specific variances in facial age estimation [3]. Pan et al. [4] proposed Mean-Variance Loss, foundational for distribution-based loss functions, though it treated the label distribution as an auxiliary component rather than integral to the model. Qiang et al. [5] refined the idea by applying Kullback-Leibler divergence to a discrete output vector, but this required an additional curated dataset and multiple forward passes per training iteration, reducing efficiency.\nIntegrating multimodal data has enhanced robustness in age estimation. MiVOLO-D1 [6] and MiVOLO-V2 [7] combined facial and full-person images, achieving state-of-the-art results. While MiVOLO-V2 improved performance with a larger dataset, gains were partly due to increased data volume rather than solely architectural innovations.\nOur method aligns with advanced distribution learning techniques, building on prior ALDL approaches [3], [8], [4], [5] to produce sample-specific variance for age estimation. Unlike previous methods that rely on categorical outputs with modality and distribution constraints, we simplify the process by directly outputting two continuous regression values. We introduce a balancing term that optimizes both the mean and variance simultaneously, reducing complexity and enhancing efficiency while delivering competitive performance across various age estimation tasks."}, {"title": "III. METHODOLOGY", "content": "Our team has developed a novel, differentiable loss function to enhance age estimation models by incorporating confidence measures. This innovation enables the models to generalize effectively across a diverse range of selfies with varying quality and demographic characteristics. The loss function comprises three components, each with adjustable thresholds that can be fine-tuned based on specific contexts. Our model architecture outputs two values representing a probability distribution over the possible ages of the subjects. These outputs can be interpreted as the mean and standard deviation of a Gaussian distribution, which are used to assess prediction confidence."}, {"title": "A. Breakdown of the Loss Function Components", "content": "The developed loss function is structured as follows, with detailed definitions provided for each term:\n$L_{jam} = \\alpha L_{reg} + \\beta L_{std} + \\delta L_{dist}$                                                                                                                                                                 (1)"}, {"title": "", "content": "The regression term $L_{reg}$ quantifies the average error and is critical as it guides the model to produce mean predictions as close as possible to the target values. The magnitude of this term is directly influenced by the discrepancy between the predicted age and the actual age.\nThe standard deviation term $L_{std}$ serves as a penalty for larger standard deviations. This term encourages the network to generate increasingly smaller standard deviations, which is crucial for accurate predictions, especially for older age groups that are inherently more challenging to predict accurately.\nThe distribution term $L_{dist}$ plays a crucial role in balancing the regression and standard deviation terms. It penalizes the model significantly when the mean prediction deviates from the target, based on the standard deviation. This term ensures the model is precise in its predictions when the standard deviation is small and allows for larger deviations when there is greater uncertainty.\nThe age decay $AD$ factor decreases as the age target increases. This behavior is instrumental in assigning greater significance to samples of younger ages, thereby prioritizing the acquisition of essential features for these target groups. Each of these loss components is defined as follows, incorporating the age decay factor which is exponentiated according to specific hyperparameters:\n$L_{reg} = \\frac{1}{N}\\sum_{i=1}^{N} (\\hat{y_i} - y_i)^2 \\times AD_i^r$                                                                                                                                                                               (2)\n$L_{std} = \\frac{1}{N}\\sum_{i=1}^{N} \\gamma_{\\sigma_i}^s \\times AD_i^s$                                                                                                                                                                             (3)\n$L_{dist} = \\frac{1}{N}\\sum_{i=1}^{N} (\\frac{(\\hat{y_i} - y_i)^2}{2\\gamma_{\\sigma_i}^2} + ln(\\gamma_{\\sigma_i})) \\times AD_i^d$                                                                                                                                                         (4)\nThe age decay factor $AD_i$ is defined as:\n$AD_i = (1 - \\frac{y_i}{M})^2$                                                                                                                                                                                                                                                              (5)\nwhere $\\hat{y_i}$ represents the actual age, $y_{\\mu_i}$ and $\\gamma_{\\sigma_i}$ are the mean and standard deviation predictions of the model, respectively. $\\alpha$, $\\beta$, $\\delta$, and the exponents $r$, $s$, $d$, are tunable hyperparameters.\nThe parameter $M$ is termed the maximum age normalization factor, serving to scale and normalize the predicted age values. This factor is essential for ensuring that the decay component is appropriately adjusted for the range of age values within the dataset, allowing for a consistent application across different age groups."}, {"title": "B. Testing & Inference", "content": "After optimizing the model, the outputs $y_{\\mu}$ and $\\gamma_{\\sigma}$ can be used to gauge the confidence range for estimating a subject's age. For the sole task of age estimation, we rely on $y_{\\mu}$ as the predicted age. When the model is well-trained, it will produce smaller distributions when confident and larger ones when less certain. This is crucial for age comparability and verification tasks. To precisely scale the model's outputs to a specific leniency level, each $\\gamma_{\\sigma}$ is combined with data-defined thresholds based on age groups.\nUsing the model outputs and defined thresholds, we establish a confidence interval for age estimation. This interval is defined by the following range:\n$[y_{\\mu} - \\gamma_{\\sigma} \\times LT_j, y_{\\mu} + \\gamma_{\\sigma} \\times UT_j]$                                                                                                                                                                        (6)\nThis range defines the lower and upper bounds of the estimated age, ensuring that predictions are tailored to specific confidence levels determined by the $LT_j$ (Lower Threshold) and $UT_j$ (Upper Threshold). These thresholds are calibrated against a supplementary validation set that mirrors production distributions across specific age group buckets $j$ to achieve targeted False Positive Rate (FPR).\nThe age group buckets are typically organized in 5-year intervals, such as a [20, 25) bucket, where all predictions $y_{\\mu}$ falling within that range would use the associated $LT_j$ and $UT_j$ thresholds. This method enables more dynamic, confidence-aware age estimation, leading to more accurate and reliable outcomes across various demographics and image qualities. For age verification or comparability, one can simply use the age ranges described above, fine-tuned to their specific use case. If the goal is to verify that a person is above a certain age $T$, the focus would shift to calculating the age range and ensure that the lower limit of the range exceeds $T$.\nIn theory, the output distribution can be modeled as a function composed of two normal distributions, both sharing the same mean. This results in a probability distribution function configured as a piecewise function with the following parameters:\n$P(x; y_{\\mu}, \\Upsilon_{\\sigma}) = \\begin{cases}N(y_{\\mu}, (\\gamma_{\\sigma} \\times LT_j)^2) & \\text{if } x < y_{\\mu}, \\\\ N(y_{\\mu}, (\\gamma_{\\sigma} \\times UT_j)^2) & \\text{if } x \\geq y_{\\mu} \\end{cases}$                                                                                                        (7)"}, {"title": "IV. RESULTS AND DISCUSSION", "content": ""}, {"title": "A. Setup", "content": "In our experiments, we utilized ResNet50 as the backbone architecture. Training was exclusively conducted using data from our live traffic, for which explicit user consent was obtained prior to training. We maintain rigorous privacy, security, and data retention policies for both source data, such as selfies, and biometric data."}, {"title": "", "content": "During initial experiments, we fine-tuned the model's parameters, ultimately setting the loss function parameters as follows: $\u03b1$ = 1, $\u03b2$ = 1, $\u03b8$ = 1.5, $\u03bb_r$ = 1, $\u03bb_s$ = 1.5, and $\u03bb_d$ = 2. We also set the maximum age normalization factor M to 115."}, {"title": "B. Datasets", "content": "We evaluated our model on two datasets to ensure robust testing across various conditions. The first dataset, referred to as the Proprietary Dataset (JPD), consists of 113,000 selfies from our customers and represents a diverse global demographic with ages ranging from 3 to 91 years. Crafted to resemble production traffic, this dataset is intentionally made more challenging to more pronouncedly reveal differences between candidate models, aiding in the selection of the best performers. It includes adjustments for enhanced balance across ages, genders, and geographies, ensuring a comprehensive and fair evaluation environment.\nThe second dataset, the publicly available ONOT [9], was selected due to its closer alignment with our operational environment compared to other public datasets.\nOur model was also recently evaluated in the NIST FATE Age Estimation and Verification Challenge using various datasets [10]. We summarize key points of the evaluation in Sec. IV-F.\nFor the training dataset, we used a dataset of the order of magnitude of 106 selfies from our live traffic. Although it is not within the scope of this submission, we also conducted a small study on how dataset volume impacts performance. Increasing the dataset size by 40% reduced the overall MAE by approximately 0.6, which corresponds to an error reduction of slightly over half a year."}, {"title": "C. Age Estimation Results", "content": "We evaluate our model's age prediction accuracy using the Mean Absolute Error (MAE), which measures the average absolute difference between predicted and actual ages.\nWe conducted a comparative analysis between our JAM model and the MiVolo model, recognized for its strong performance on several public benchmarks. This evaluation used both our proprietary JPD dataset and the publicly available synthetic dataset ONOT (see Table I).\nOur JAM model outperforms the MiVolo model on the JPD dataset overall and across all tested regions (Fig. IV-C). This superior performance may be attributed to our distribution-based approach, which better handles the variabilities encountered in real user data. By modeling age predictions as probability distributions, JAM effectively captures the nuances and inconsistencies present in production environments, leading to more accurate and reliable age estimations.\nConversely, the minimal difference in performance on the ONOT dataset-which consists of synthetic mugshot images generated by stable diffusion-highlights that both our JAM model and the MiVolo model perform consistently when dealing with unfamiliar and non-realistic data scenarios. This close performance gap indicates that both models maintain robustness even when applied to synthetic datasets where the depicted ages are artificially assigned and do not correspond to real human aging patterns."}, {"title": "D. Age Verification Results", "content": "In this evaluation, we compared two methods for performing age verification tasks, inspired by the well-established Challenge-25 and Challenge-28 policies used by retailers of age-restricted products. The Challenge-25 policy requires customers who appear under 25 to present identification to confirm they are at least 18 years old. Similarly, the Challenge-28 policy requires anyone who looks under 28 to show identification to confirm they are at least 21. Since the ONOT dataset contains no subjects under 18, we applied the Challenge-28 policy for this dataset.\nThe first method, referred to as JAM Singular Regression (SR), employs a traditional approach where a single predicted age value is compared against an age threshold with an added safety buffer (25 years for Challenge-25 and 28 years for Challenge-28). In the JPD dataset (Challenge-25), this method achieved an FPR of 0.007 (0.7%) and a True Positive Rate (TPR) of 81.42%. In the ONOT dataset (Challenge-28), it achieved an FPR of 0.008 (0.8%) and a TPR of 75.68%.\nThe second method is a confidence-based approach that utilizes the distributional output of our model. By ensuring that the lower bound of the user's predicted age range is above the legal age limit, we make more informed decisions based on the model's confidence. Adjusting the threshold leniency to match the TPR of the SR method, the confidence-based approach significantly reduced the FPR to 0.001 (0.1%) for the JPD dataset and to 0% for the ONOT dataset. This represents a sevenfold reduction in false positives for the former and a complete elimination of false positives for the latter.\nThese results demonstrate that leveraging the model's confidence leads to a more effective age verification process. The confidence-based method reduces the likelihood of incorrectly flagging adults as underage (FPR), while maintaining the same level of detection for actual underage individuals (TPR)."}, {"title": "E. Age Comparability Results", "content": "Age comparability is not commonly addressed in general applications but is particularly important in the identity verification space."}, {"title": "", "content": "In this experiment, thanks to the reliable confidence output from the model, we were able to reduce the median predicted age range from 26.92 to 22.80 on the JPD dataset at a fixed FPR of 0.5%. This represents a reduction of approximately 15.3%. In the context of identity verification, this narrower age range enhances the detection of identity fraud, leading to a safer and more reliable system overall."}, {"title": "F. NIST testing", "content": "Our age estimation model has been independently evaluated by the National Institute of Standards and Technology (NIST), affirming its competitive scores in operational datasets, particularly Application and Mugshot.\nIn the full NIST report [11], Table 13 provides a detailed overview of age estimation accuracy by sex, mean absolute error (MAE), across different age bands. For a detailed breakdown of our model's performance, please see Table III in this document, which presents comprehensive results across both Mugshot and Application datasets."}, {"title": "V. CONCLUSION", "content": "This paper highlights our advanced model primarily designed for age estimation, with applicability to other tasks such as verification and comparability, offering a robust alternative to existing methods. Utilizing innovative techniques and a specialized loss function, our model meets and often exceeds conventional standards, providing practical benefits for precise age range predictions. It effectively handles real-world challenges, including diverse demographics and varying image qualities, making it ideal for age verification applications. The model's confidence-based output ensures accuracy under diverse conditions, thereby enhancing user safety. Furthermore, it consistently achieves competitive results on both public and proprietary datasets, and has"}, {"title": "A. Risk", "content": "We have not sought an external ethical review board for the age estimation and verification aspects of this project, as both areas are well-established in the industry and are widely recognized as low-risk from an ethical standpoint. Age estimation and verification is generally more accurately performed by modern ML/AI systems than by humans. AWS Rekognition demonstrates superior accuracy to humans in 9 out of 12 demographic categories [12].\nThe project and the data have been reviewed internally by our company's ethics council and evaluated against our ethical policies. No violations of laws or ethical concerns have been identified. One aspect to assess from a risk perspective is potential bias, as many age estimation systems exhibit bias issues. For example, age-related biases are a common concern in artificial intelligence systems.\nOne aspect to assess from a risk perspective is potential bias, as many age estimation systems exhibit bias issues. For example, age-related biases are a common concern in artificial intelligence systems [13]."}, {"title": "B. Mitigation", "content": "To mitigate bias, we employed curated datasets for model training and testing. These datasets are balanced across various age groups, genders, and countries of origin. However, as observed in NIST reports [11], our solution still shows some biases for instance, age estimation tends to be more accurate for males than for females (a trend observed across all participants and age groups), and middle-aged individuals (20-50 years) are more accurately assessed than older populations.\nWe hypothesize that age estimation accuracy may decrease in older populations because age-related changes in appearance become less pronounced, and gender bias could be influenced by cultural factors such as the use of cosmetics.\nTo address concerns regarding inappropriate use and to ensure transparency and accountability, our approach includes strict usage guidelines and the publication of detailed metrics that quantify the risks associated with model errors. These metrics are designed to provide clear insights into the system's performance across different demographics and scenarios, enabling continuous monitoring and improvement. In our live traffic, we apply different mitigation strategies depending on the specific application:\n\u2022 Age Comparability: Large age deltas are applied when making decisions to reject users in fraud detection applications. Such systems only act when a significant age mismatch is detected.\n\u2022 Age Estimation: Large confidence intervals are used, and age values are not directly applied or utilized in real applications due to the risk of errors.\n\u2022 Age Verification: Both large deltas and confidence intervals can be utilized. For instance, if a user attempts to access a restricted content website, the verification system rejects the users only when it is highly certain that the user is underage."}, {"title": "C. Privacy and Security", "content": "For all real images of individuals used in the research, we obtained direct consent from each user. When users utilize our applications for identity verification, we ask for their consent to use their data for commercial R&D applications, including the development of age models.\nThere is no direct compensation provided to the end user, but they benefit from improved service after certain development iterations. Only data from users above 18 years of age have been used, as evidenced by the government-issued ID documents associated with the data.\nThe image data is stored securely and encrypted, with eventual deletion in accordance with the retention policy or under data subject rights requests. No information or images that could lead to user identification are included in this manuscript.\nAdditionally, the age data obtained from AI models is not stored and is removed immediately after analysis, ensuring that no sensitive information is retained."}]}