{"title": "Tool or Tutor? Experimental evidence from AI deployment in cancer diagnosis", "authors": ["Vivianna Fang He", "Sihan Li", "Phanish Puranam"], "abstract": "Professionals increasingly use Artificial Intelligence (AI) to enhance their capabilities and assist with task execution. While prior research has examined these uses separately, their potential interaction remains underexplored. We propose that AI-driven training (\u201ctutor\u201d effect) and AI-assisted task completion (\u201ctool\u201d effect) can be complementary and test this hypothesis in the context of lung cancer diagnosis. In a field experiment with 334 medical students, we manipulated AI deployment in training, in practice, and in both. Our findings reveal that while AI-integrated training and AI assistance independently improved diagnostic performance, their combination yielded the highest accuracy. These results underscore Al's dual role in enhancing human performance through both learning and real-time support, offering insights into AI deployment in professional settings where human expertise remains essential.", "sections": [{"title": "Introduction", "content": "As the development of artificial intelligence (AI) advances rapidly, the capabilities of many Al systems have reached or even surpassed those of human experts in numerous domains, including complex strategy games like Go (Choi et al., 2025), medical diagnosis (Lebovitz et al., 2021; 2022), and drug discovery (Savage, 2021; Senior et al., 2020). Despite the potential of AI to drive major transformations in the design of jobs and organizations (De Cremer, 2020; von Krogh, 2018), not all tasks performed by human professionals can or should be automated (Raisch & Krakowski, 2021). For technical, moral, or ethical reasons, some professional work requires humans to remain in the loop, with prime examples being medical diagnosis and judicial judgments. In these domains, it is of paramount importance to understand how Al systems can help rather than replace human professionals in completing their tasks more quickly or more accurately-ideally, both. Furthermore, given the ongoing human involvement in these domains, a critical concern is not only to preserve but also to enhance human skills.\nThe deployment of AI in professional work that necessarily involves human participation thus presents an important dilemma. On the one hand, using AI as a tool for automating some subtasks could lead to performance improvements through a division of labor between humans and algorithms. For example, in the domain of software development, AI tools such as GitHub Copilot take on tasks such as suggesting code snippets and debugging errors, whereas human developers specialize in designing the code architecture and integrating snippets coded by AI tools into complex projects. Over time, however, humans specializing in some subtasks could experience skill decay in the tasks that they delegate to AI (e.g., writing detailed code), which may eventually also affect their performance in higher-order tasks that require an overview of all the subtasks (e.g., designing the code architecture).\nOn the other hand, AI as a tutor may enhance human capabilities for certain tasks through training, whereas performing the tasks autonomously may yield superior immediate performance. The superiority of AlphaZero-a superhuman-level game-playing algorithm- over novice Go players is a case in point (Choi et al., 2025). AI systems like AlphaZero, which consistently outperform human world champions, can train human Go players by analyzing moves, predicting outcomes, and suggesting improvements, thus enhancing human strategic thinking. Yet, if the goal is to win a game, instead of training a human player to do so, the fastest and surest way is to allow the AI system to assist the human during gameplay. As the case of Go illustrates, when the goal is immediate efficiency and accuracy, letting AI complete the tas may yield superior results. But if the goal is long-term human development, using AI as a tutor is crucial\u2500otherwise, human capabilities may stagnate. Given these considerations, how can we simultaneously achieve the twin objectives of improving task performance and augmenting human capability?\nWe examine these two aspects of the AI deployment dilemma in the context of cancer diagnosis training at a tertiary hospital in China. This context has two key advantages. First, cancer diagnosis represents a situation in which researchers can clearly observe and document decisions made by human professionals (Agarwal et al., 2023). When medical ground truth is available, the quality of these decisions, and thus the performance of professionals, can be objectively measured. Second, although medical students (i.e., novices) build a basic level of general knowledge about the human body in their first few years of education, radiological diagnosis of lung cancer is an area in which they are unlikely to have obtained skills prior to specialized training. This ensures a uniform diagnostic skill level (approximately zero) among participants before our experiment. When participants are not permitted to use the AI system in their diagnostic tasks, any performance difference reflects differences in their learning (i.e., change in intrinsic diagnostic capabilities). In conducting a field experiment in a context where the training and practice of medical professionals take place, our work extends current research on AI deployment in professional work by theorizing and empirically demonstrating that integrating AI in both the training and practice of a task can generate complementary benefits in human-AI collaboration."}, {"title": "Theoretical Background and Hypotheses", "content": "When seeking to understand whether and how AI augments the work of human experts, existing research often compares the performance of human professionals when using an AI system to their performance when not using it (e.g., Dell'Acqua et al., 2023; Jia et al., 2024). Many studies have indeed found a marked performance improvement (e.g., Doshi & Hauser, 2024). However, such comparisons fail to discern the underlying causes of performance improvement: Does an AI system enhance human professionals' capabilities (Choi et al., 2025)\u2014the inherent ability to perform atask\u2014or merely offer assistance, providing real-time support in completing a task without affecting human professionals' capabilities(Allen et al., 2022; Choudhury et al., 2020; Lebovitz et al., 2022; Tong et al., 2021)? Indeed, a performance-enhancing AI system could provide human professionals with assistance that improves task performance while simultaneously diminishing their task- related capabilities (e.g., Bastani et al., 2024).\nFurthermore, in exploring how Al systems augment professional work, existing research has largely focused on experts, such as radiologists in highly specialized medical departments (Lebovitz et al., 2021; Lebovitz et al., 2022), consultants in industry-leading firms (Dell'Acqua et al., 2023), and experienced drug discovery scientists (Smalley, 2017).\nDespite increasing evidence that professionals of varying skill levels work with and benefit from Al systems differently (e.g., Luo et al., 2021), novices have received much less attention from organizational scholars. This is an underexplored research opportunity because novices, compared to experts, are more likely to show capability improvement if an AI system truly has the potential to enhance their skills. Therefore, in this study, we focus on the potential complementarity between AI deployment in training and task performance among novice professionals.\nOur theoretical expectation of a complementary effect between leveraging AI as both a tutor and a tool rests on two arguments. First, using AI for training will improve human professionals' capabilities underlying the focal task capabilities that also improve their capacity to understand how best to use AI as a tool to assist them in completing the task. Second, training with AI input increases professionals' familiarity with and trust in AI, thereby enhancing their understanding of how to use the tool as well as their willingness to use it. Our pre-registered\u00b9 hypotheses are:\nH1. AI as Tutor: Access to AI assistance during diagnosis enhances human diagnostic performance even without AI input in training.\nH2. AI as Tool: Integrating AI input in training enhances human diagnostic performance even without AI during diagnosis.\nH3. Complementarity between Tutor and Tool: Combining AI input in training with access to Al assistance during diagnosis yields the highest diagnostic accuracy."}, {"title": "Research Design", "content": "To test our hypotheses, we conducted a field experiment at West China Hospital, one of China's most prestigious medical institutions, renowned for its comprehensive education programs. Two independent institutional review boards (from the university affiliated with this hospital and the home institution of one of the authors) approved the study protocol.\nOur experiment employed a 2\u00d72 factorial design, manipulating (1) AI integration in training (with AI input in training vs. without AI in training) and (2) AI assistance in diagnosis (with AI input in practice vs. without AI in practice), resulting in four distinct conditions (see Table 1). This design not only allows us to differentiate whether AI improves diagnostic perforamnce by improving human task-related capabilities or by providing real- time assistance, but more importantly, enables us to assess both the individual and combined effects of these two affordances on novices' diagnostic accuracy.\nThe experiment proceeded in three steps (see Figure 1). First, all participants attended a one-hour lecture on lung disease diagnosis, focusing on conceptual knowledge. Second, participants were randomly assigned to one of two subsequent workshops providing additional training on how to diagnose lung diseases using real patient cases. In one condition, the training materials incorporated AI-generated inputs, while in the other, they did not. Both training sessions lasted 25 minutes and were recorded by the same lecturer\u2014an expert in lung cancer radiological diagnosis\u2014ensuring consistency in content and delivery. Third,\nparticipants completed a series of diagnostic tests, evaluating 30 high-resolution chest scans to determine whether the identified nodules were cancerous. During these tests, participants were again randomly assigned to one of two conditions: either receiving AI assistance or diagnosing independently for the entire set of cases.\nParticipants. A total of 334 second-year medical students (mean age: 22.78 years, 49% female) voluntarily participated in the study. Informed consent was obtained from all participants prior to their inclusion. To incentivize engagement, the top 10 performers were rewarded an average of 28 USD, and the reward scheme was announced beforehand.\nAI Input. We provided AI-generated input using a deep learning model trained for chest CT scan interpretation. This model was developed using over 40,000 domestic and international lung nodule cases, integrating CT scan images and electronic medical records (EMR) (see Appendix for further details on the model's training).When deployed to interpret a CT scan, the AI model provided visual annotations including highlighted contours of potential nodules in bright green, quantified diagnostic metrics (CT attenuation value, scan layer, nodule location, volume, category, composition, and dimensions), and estimated malignancy probability (0-100%), indicating the likelihood that a nodule was cancerous.\nExperimental Conditions. During training, participants in Groups B1 & B2 (AI- integrated training condition) watched recorded instructional materials that incorporated AI- annotated CT scans for 10 real medical cases. The lecturer guided students through each AI annotation. During diagnostic practice, participants evaluated 30 high-resolution CT scans extracted from real, anonymized patient data using the hospital's specialized computers. Participants in Groups A2 & B2 (AI-assisted practice condition) had access to Al-generated annotations for each case, similar to those presented in training.\nGround Truth. Unlike most existing studies that rely on expert consensus to approximate ground truth for evaluating diagnostic accuracy (e.g., Agarwal et al., 2023), our study established ground truth using the Gold Standard of histopathological examination. Specifically, malignant cases were confirmed via pathological outcomes following surgical procedures (e.g., tissue biopsy), whereas benign cases were confirmed through a three-year follow-up, ensuring no significant changes in these nodules. The 30 real cases used in our experiment were equally distributed between malignant (n=15) and benign (n=15) cases.\nOutcome Measure. Our pre-registered outcome variable was confidence-adjusted diagnostic accuracy. This metric was calculated by first assigning participants a score of +1 for each correct diagnosis and -1 for each incorrect diagnosis. This score was then multiplied by the participant's self-reported confidence level, which was measured on a Likert scale ranging from 1 (not confident) to 10 (very confident). The final composite confidence- adjusted diagnostic accuracy score was derived by summing these values across all 30 cases.\nThis approach captures both diagnostic correctness and confidence calibration\u2014a critical factor in medical decision-making, where overconfidence or underconfidence can impact patient outcomes. Accurate calibration is particularly important in contexts where second opinions may be sought or when patients must decide on treatment options based on the physician's confidence level (Park et al., 2020). In addition to this primary outcome, we conducted exploratory analyses examining alternative diagnostic performance measures, including accuracy, precision, and sensitivity."}, {"title": "Findings", "content": "Participants were evenly distributed across the four experimental groups (n = 84 per group). Proper balance is crucial in experimental design to ensure that any observed effects stem from the experimental manipulations rather than pre-existing differences between groups (Kernan et al., 1999; Suresh, 2011). We thus started by conducting balance tests on key demographic variables to verify the adequacy of the randomization and ensure that the groups were comparable. Table 3 summarizes the results of these tests, showing that the groups did not significantly differ in age and gender distributions, confirming that experimental conditions were comparable across all groups.\nHypothesis testing. The ANOVA results (Table 4) revealed significant main effects of both the use of the AI tool during the diagnostic test and the type of training received. Moreover, among those who did not receive AI integrated trainings, participants who used the AI tool during the diagnostic test (Group A2) scored significantly higher than those who did not (Group A1) (Difference = 59.852, SE = 4.867, p < 0.001; 95% CI [-72.420, -47.284]). This substantial increase supports Hypothesis 1, indicating that access to AI real-time assistance during diagnosis enhances human diagnostic performance. Among those who did not have Al assistance during test, participants who received AI-integrated training (Group B1) performed significantly better than those who received standard training without AI integration (Group A1) (Difference = 22.431, SE = 4.861, p < 0.001; 95% CI [8.161, 33.265]). This finding supports Hypothesis 2, demonstrating that integrating AI input into training boosts diagnostic performance by improving human novices' intrinsic capabilities.\nImportantly, participants who both received AI-integrated training and had AI assistance during the diagnostic test (Group B2) achieved the highest diagnostic accuracy (compared to all other three groups). This result supports Hypothesis 3, indicating a complementary effect between AI providing extrinsic assistance and improving human novices' intrinsic capabilities. Table 5 presents all pairwise comparisons between experimental groups and Figure 3 visualizes these comparisons.\nTo access the robustness of our findings, we also measured the task performance using a simple precision rate (i.e., the fraction of diagnoses a participant got right) and ran ANOVA with this alternative outcome. All the results, shown in Table 6 and Figure 4, are qualitatively the same as our main analyses, lending strong support to our hypotheses.\nExploratory analyses. Accuracy alone does not indicate the distribution of different types of error (i.e., false positives and false negatives). Two additional performance metrics help address this limitation: Precision, which measures how reliable a positive cancer diagnosis is, and Sensitivity (also known as recall), which measures how likely an actual case of cancer will be caught. We therefore also examined the treatment effects on Precision (i.e., fraction of true to all positive cases diagnosed) and Sensitivity (i.e., fraction of true positive cases diagnosed to actual positive cases).\nAs Figures 5 and 6 illustrate, using AI either as a tool (during diagnosis) or as a tutor (during training) improve precision, suggesting a potential benefit in conserving medical resources by reducing false positives. However, AI deployment in these individual capacities worsened sensitivity, which is arguably the most critical metric from a patient's perspective."}, {"title": "Discussion", "content": "In contrast, when AI was used both as a tool and a tutor, precision and sensitivity improved simultaneously.\nThese findings indicate that participants who used AI in either training or practice became better at avoiding false alarms (i.e., reducing false positives) but struggled to catch actual malignant cases (i.e., increasing false negatives). However, when AI was integrated into both training and practice, it led to improvements across both key performance dimensions, suggesting a complementary effect of AI deployment in medical diagnosis.\nThis study makes two key theoretical contributions. First, by distinguishing between Al's role in providing task assistance (as a tool) and fostering task-related capability improvement (as a tutor), we contribute to ongoing debates on Al's dual impact\u2014whether it primarily automates human tasks or augments human expertise (e.g., Choi et al., 2025; Raisch & Krakowski, 2021). Our experimental design allows us to examine whether AI input enhances human-AI collaborative performance by directly assisting in task completion or by improving human diagnostic capabilities through training. More importantly, we identify a significant interaction effect between using AI as a tool and as a tutor. Our findings suggest that AI assistance during diagnosis substantially increases the immediate accuracy of human- AI collaboration, whereas AI-integrated training supports long-term human skill development and may enhance professionals' ability to work effectively with AI in future deployments.\nSecond, this study expands research on AI-augmented professional work (e.g., Dell'Acqua et al., 2023; Lebovitz et al., 2021, 2022) by focusing on novices, a group that has received relatively little attention in prior studies. While most research examines AI's impact on expert professionals, we extend the conversation to novices, who lack the deep, experience-based knowledge that enables experts to critically evaluate AI input and manage high levels of diagnostic uncertainty (Lebovitz et al., 2022). Our findings suggest that integrating AI input into training plays a critical role in early-stage professional development, helping novices build the necessary competencies to effectively interact with Al-based decision support systems.\nBeyond its theoretical contributions, our study offers practical insights for AI integration in professional training, informing the design of AI-assisted education and workplace learning programs. Prior research indicates that even when experts are advised to use Al as a second opinion (rather than delegating decisions entirely), they may still focus selectively on certain sub-tasks, delegating others to AI due to time constraints or cognitive limitations (e.g., Dell'Acqua et al., 2023). While pragmatic, this selective delegation may lead to skill decay, as professionals miss opportunities to develop and refine their expertise. Our findings provide empirical evidence that combining AI input in training with Al assistance in practice yields the best performance outcomes, offering a clear roadmap for optimizing AI adoption in healthcare and other professional fields with similar resource constraint as well as high uncertainty and complexity in practice.\nIn summary, our study identifies two types of causal effects in Al deployment. The first is the independent effect of using AI either in diagnostic training or in real-time decision-making. The second is a complementarity effect, which emerges when AI is deployed in both training and practice, resulting in enhanced human-AI collaboration. Our theory of complementarity rests on the assumption that improving professionals' diagnostic capabilities enhances their ability to interpret and integrate AI input, thereby boosting collaborative performance. However, we acknowledge that alternative mechanisms may also be at play. For example, while increased capability should theoretically improve a professional's ability to leverage AI effectively, it may also reduce their willingness to rely on AI, as greater confidence in one's own skills could lead to overreliance on personal judgment. To disentangle these mechanisms, we plan to conduct follow-up experiments that isolate the drivers behind the observed effects, further refining our understanding of how AI both shapes and interacts with human expertise in professional settings."}, {"title": "Appendix: Al system used in this study", "content": "The AI-Assisted Diagnosis System used in our study was developed by LinkDoc, a leading oncology big data company in China. This system is based on a convolutional neural network (CNN) designed to emulate human cognitive processes in medical image analysis.\nModel Architecture and Training\nThe AI system integrates a Region Proposal Network (RPN) from Faster R-CNN with 3D- ResNet18 for nodule detection, utilizing a U-shaped framework to automatically localize and delineate pulmonary nodules. For benign/malignant classification, the model employs a state- of-the-art 3D convolutional neural network (3D-CNN), capable of capturing volumetric spatial features essential for accurate diagnosis.\nA large-scale dataset comprising 40,000+ real patient cases was used to train the system. CT scan data of these cases were preprocessed by cropping images to retain lung bounding boxes, thereby reducing computational complexity while preserving critical diagnostic regions. Data augmentation techniques\u2014including flipping, translation, Gaussian noise, and salt-and- pepper noise were applied to enhance model robustness. Beyond image data, the system is also trained on electronic medical records (EMR), incorporating patient demographics, clinical notes, and diagnostic histories to improve prediction accuracy.\nFeature Learning and Inference\nUsing preprocessed nodule images as input, the model autonomously extracts and optimizes millions of high-dimensional features through iterative training, aligning predictions with pathology-confirmed ground truth. During inference, the system outputs a malignancy probability score (0\u2013100%), leveraging knowledge distilled from a vast dataset.\nModel Performance\nFor the 30 cases we used in the diagnosis task, the AI system's accuracy rate was 85% (with a probability threshold of 50%)."}]}