{"title": "Lyapunov weights to convey the meaning of time in physics-informed neural networks", "authors": ["Gabriel Turinici"], "abstract": "Time is not a dimension as the others. In Physics-Informed Neural Networks (PINN) several proposals attempted to adapt the time sampling or time weighting to take into account the specifics of this special dimension. But these proposals are not principled and need guidance to be used. We explain here theoretically why the Lyapunov exponents give actionable insights and propose a weighting scheme to automatically adapt to chaotic, periodic or stable dynamics. We characterize theoretically the best weighting scheme under computational constraints as a cumulative exponential integral of the local Lyapunov exponent estimators and show that it performs well in practice under the regimes mentioned above.", "sections": [{"title": "1. Time in PINNs : introduction and previous works", "content": "Physics-informed Neural Networks introduced in [1] proved to be a very successful paradigm invoked to solve complex mathematical equations such as time evolutions [2, 3, 4] [5] possibly in high dimensions [6], partial differential equations [3] or control systems [7]; this framework exploits the power of neural networks (including automatic differentiation) to represent the main unknown function which is the solution of some equation involving its derivatives. The PINNs can also incorporate different other elements such as (possibly noisy) measurements on the system or further data such as controls.\nTo improve PINN performance several leads have been followed; Sharma and Shankar [8] studied meshless discretization, Cho et al. [9] consider separable network architecture while Wang et al. [10] analyze best norm to express the loss. We borrow here from all these perspectives but we focus on time-dependent problems and more"}, {"title": "2. Presentation of the framework", "content": "To set notations let us recall very briefly how PINNs operate. Suppose that the evolution equation is to be solved is written in the form :\n$\\partial_t u = G_t u$ (1)\n$u(0,x) = u_0(x), \\forall x \\in \\Omega$ (2)\n$u(t, x) = u_{bc}(t, x), \\forall t \\in [0,T], x \\in \\partial\\Omega.$ (3)\nwhere $u( , )$ is the main unknown, $t$ is the time variable and $x$ the spatial variable, $G_t$ is some operator possibly involving the spatial derivatives of $u$ (e.g., for the heat equation $G_t = \\partial_{xx} $), $u_0(\\cdot)$ and $u_{bc} (\\cdot, \\cdot)$ are the initial and boundary conditions respectively. When the equation is set in finite dimension such as the Lorenz system in section 4.1 then $ \\Omega$ will be discrete and $\\partial\\Omega = \\emptyset$. The solution $u$ will be searched in the form of a neural network (NN) taking two inputs $t$ and $x$ and outputting an approximation $U_\\Theta (t, x)$ of"}, {"title": "3. Theoretical results", "content": "To design time weighting schemes we need to know how the equation error $w(t, \u00b7)$ at time $t$ will impact the accuracy of the final result $U_\\Theta (T, \u00b7)$. There is no general answer to this question but we will use a close concept, namely the Lyapunov exponent which describes quantitatively the rate of separation of infinitesimally close trajectories. The Lyapunov exponent originates from the dynamic system analysis and, for some 1D ordinary differential equation $z'(t) = f(t, z(t))$ describes how two solutions, starting from $z^1 (0)$ and $z^2(0)$ diverge in the limit of large times $t$; more precisely the Lyapunov exponent is the coefficient $\u03bb \u2208 R$ such that $|z^1 (t) \u2212 z^2(t)| \u223c e^{\u03bbt}|z^1(0) \u2212 z^2(0)|$ (for large $t$). The determination of the exact value of the Lyapunov exponent is a difficult task in dynamical systems and ever more so in evolution PDE, but we will retain this idea. This allows to state :\nProposition 1. Let $u, U_\\Theta$ as in (1) and (5) respectively. Let $\u03bb(t)$ be such that\n$\\frac{(G_t(u(t,\\cdot)) - G_t(U_\\Theta(t, \\cdot)), u(t, \\cdot) - U_\\Theta (t, \\cdot))}{||u - U_\\Theta ||^2} \\leq \\lambda(t).$ (8)\nThen\n$||u(T, \\cdot) - U_\\Theta (T, \\cdot)|| \\leq \\int_0^T e^{\\int_t^T \\lambda(s)ds} ||w(t,\\cdot)||dt.$ (9)\nHere the norm is euclidean when $\u03a9$ is finite and $L^2$ norm otherwise.\nProof. Denote $e(t) = u(t, \u00b7) \u2212 U_\u0398 (t, \u00b7)$. Using (1) and (5) we obtain:\n$\\frac{1}{2} \\frac{d}{dt}||e(t)||^2 = \\langle \\frac{d}{dt}e(t), e(t) \\rangle = \\langle G_t(u) - G_t(U_\\Theta ) - w(t, .), e(t) \\rangle$ (10)\n$\\leq \\lambda(t) (e(t), e(t)) - (w(t, .), e(t)) \\leq \\lambda(t)||e(t)||^2 + ||w(t, \u00b7) || . ||e(t)||$ (11)\nThis means that $||e(t)|| \u2264 \\lambda(t)||e(t)|| + ||w(t, \u00b7)||$, and, using the notation $A(t) = e^{-\\int_0^t \\lambda(s)ds}$ we obtain $\\frac{d}{dt}(A(t)||e(t)||) \u2264 A(t)||w(t, \u00b7)||$ ; hence, since e(0) = 0, by integration from 0 to T we get $A(T)||e(T)|| \u2264 \\int_0^T A(t)||w(t,\u00b7)||dt$ which gives the conclusion.\nThe result already gives qualitative insight into how the error at the final time T depends on errors at intermediary times $t < T$, which is the main idea of Lyapunov exponents. Let us take the simple case $G_t(u) = \\lambda u$ with $\u03bb \u2208 C$ constant; in this case (9) is in fact an equality. As in [13] we note that for a chaotic or divergent system, which is characterized by a strictly positive Lyapunov exponent i.e., Re(\u03bb) > 0 the trajectories diverge exponentially with respect to error in the equation (5) or in the data. In this case the precision has to be large for t near zero because the factor $e^{\\lambda (T-t)}$ will multiply it resulting in large error in the final state. On the contrary, for values of t close to T the factor $e^{\\lambda (T-t)}$ is relatively small and a larger error in the equation can be tolerated because it will be multiplied by a smaller factor. What is interesting to note is that this also works the other way around for $Re(\\lambda) < 0$ which characterize systems converging to stable equilibria. In this case initial errors in the equation will be \"washed away\" by"}, {"title": "4. Numerical experiments", "content": "The code for the numerical experiments will be provided on Github https://github.com/gabriel-turinici.\n4.1. Lorenz system\nThe Lorenz system is a set of ordinary differential equations that describes a simplified model of atmospheric convection. It exhibits chaotic behavior and has been widely"}, {"title": "5. Limitations", "content": "Although the theoretical and empirical results appear encouraging, further work could improve some aspects of the procedure. The most apparent is the estimation of the Lyapunov exponents, which is now done in a very crude way; this could be refined or, if not possible, at least construct some trust regions to inform when these estimations are reliable or not.\nAnother aspect is the interaction between the weights dynamic and the solution. This is common to all adaptive weights procedures but it may concern some cases where the weights given by (17) induce instabilities in the solution preventing convergence (in the same vein as the well-known GAN \"mode collapse\" problem). An analysis of whether this can happen or how to prevent it could be required.\nFinally, for the problems where the canonical, simple implementation of the PINN procedure already works well this algorithm may cause slight numerical computational overhead."}, {"title": "6. Conclusion", "content": "In this work, we presented a new approach to treat the time dimension within the framework of Physics-Informed Neural Network. We started from the observation that time instants are not permutable and depending on the regime (chaotic, periodic, or stably convergent) errors in earlier instants affect differently the quality of the outcome. We proposed a theoretical explanation based on Lyapunov exponents and then a new algorithm built from this insight.\nThe procedure was then tested on two different cases, one chaotic (Lorenz system) and one stable but that induces singularities (Burgers' equation), both known to require careful numerical treatment. The proposed algorithm not only showcases robustness and practical efficiency but also addresses some limitations of earlier works that lacked a principled and theoretically grounded foundation. Of course, while our procedure is robust across various benchmarks, it is designed as a complementary addition to the existing methods rather than a one-size-fits-all solution. We believe this work contributes meaningfully to the field, offering a solid foundation for future research and application development."}, {"title": "Appendix A. Supplementary material", "content": "Appendix A.1. Standard PINN (no time weighting) results for the Lorenz system\nAs announced in section 4.1 we plot in figure A.10 the solution of the procedure for the situation when the weights are not optimized at all but left all uniform. This case was allowed 30'000 iterations (10 times more than our standard setting) but did not even start to converge.\nAppendix A.2. Exact solution for Burgers' equation\nTo compare the PINN solution with a reference ground truth we solved Burger's equation with a finite difference scheme and compared with an analytic formula with Hermite-Gauss integration.\nAppendix A.2.1. Finite differences scheme for Burgers' equation\nThe finite difference scheme works on a spatial domain discretized with nx = 400+1 spatial grid points (counting both segment extremities \u00b11), i.e. \u2206x = 2/400 and nt = 700 time steps (At = 1/700); each time step is implementing the following split-operator technique :\nfirst a Crank-Nicholson (CN) scheme over a At/2 time step (taking into account the boundary conditions) for the diffusion part i.e. the solution by CN of the equation $\\partial_t u = \\nu \\partial_{xx}u$\nthen a At step of a Lax-Friedrichs scheme for the viscosity term, i.e. for the equation du + \u0438\u0434\u0445\u0438 = 0."}]}