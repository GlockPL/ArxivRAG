{"title": "Lyapunov weights to convey the meaning of time in physics-informed neural networks", "authors": ["Gabriel Turinici"], "abstract": "Time is not a dimension as the others. In Physics-Informed Neural Networks (PINN) several proposals attempted to adapt the time sampling or time weighting to take into account the specifics of this special dimension. But these proposals are not principled and need guidance to be used. We explain here theoretically why the Lyapunov exponents give actionable insights and propose a weighting scheme to automatically adapt to chaotic, periodic or stable dynamics. We characterize theoretically the best weighting scheme under computational constraints as a cumulative exponential integral of the local Lyapunov exponent estimators and show that it performs well in practice under the regimes mentioned above.", "sections": [{"title": "1. Time in PINNs : introduction and previous works", "content": "Physics-informed Neural Networks introduced in [1] proved to be a very successful paradigm invoked to solve complex mathematical equations such as time evolutions [2, 3, 4] [5] possibly in high dimensions [6], partial differential equations [3] or control systems [7]; this framework exploits the power of neural networks (including automatic differentiation) to represent the main unknown function which is the solution of some equation involving its derivatives. The PINNs can also incorporate different other elements such as (possibly noisy) measurements on the system or further data such as controls.\nTo improve PINN performance several leads have been followed; Sharma and Shankar [8] studied meshless discretization, Cho et al. [9] consider separable network architecture while Wang et al. [10] analyze best norm to express the loss. We borrow here from all these perspectives but we focus on time-dependent problems and more specifically on how the sampling of time points (or their weighting in the loss) impacts the overall performance. The time dimension has been long recognized to possess particular characteristics that deserve special attention. In a highly influential work on Allen-Cahn and Cahn-Hilliard phase field equations [11] Wight and Zhao introduce various sampling strategies in both space and time while McClenny and Braga-Neto [12] make weights trainable which requires additional computational time; in the latter work the influence of the weights on the training loss is mediated by a function that becomes a hyper-parameter to be specified by the user. In a related approach, [13] Wang et al. remarked that, especially for chaotic or near chaotic systems, the causality of the time dimension has to be respected and enforced to obtain good results. In particular they proposed that earlier times be given more weight in the loss functional, proportional to the exponential of the cumulative sum of the accumulated errors (up to that point in time, see formula (7) below); a hyper-parameter denoted  $\\epsilon$ remains to be chosen and in practice it is iterated in a prescribed list. The procedure also requires some special termination criterion. On the other hand [14] Penwarden et al. also studied the time dimension and propose a scalable framework for causal sweeping strategies in PINNs. This and many other contribution recognized the necessity to combine PINNS sequentially in order to solve a problem set on a large time interval. While we agree with this perspective, we search here only for the best time weighting scheme on each of these individual intervals ; as such, our procedure can be combined with any other time sweeping protocol. Moreover, as the previous protocols have been rather prescriptive and proposed ad-hoc choices of time weighting, we focus here on the design of principled approaches to orient the choice of weights. Our procedure is on one hand flexible enough to recognize the main regime the evolution takes place into (stable, chaotic, periodic) and on the other hand it does not require additional hyper-parameters to adjust, which was a more laborious part of the previous approaches.\nThe balance of the paper is the following: in section 2 we introduce the general framework and in section 3 we give the main theoretical insights that motivate our procedure. The numerical experiments are the object of section 4, followed in sections 5 and 6 by concluding remarks."}, {"title": "2. Presentation of the framework", "content": "To set notations let us recall very briefly how PINNs operate. Suppose that the evolution equation is to be solved is written in the form :\n$\\partial_t u = G_t u$ (1)\n$u(0,x) = u_0(x), \\forall x \\in \\Omega$ (2)\n$u(t, x) = u_{bc}(t, x), \\forall t \\in [0,T], x \\in \\partial\\Omega$. (3)\nwhere $u(\\cdot,\\cdot)$ is the main unknown, $t$ is the time variable and $x$ the spatial variable, $G_t$ is some operator possibly involving the spatial derivatives of $u$ (e.g., for the heat equation $G_t = \\partial_{xx}$), $u_0(\\cdot)$ and $u_{bc} (\\cdot, \\cdot)$ are the initial and boundary conditions respectively. When the equation is set in finite dimension such as the Lorenz system in section 4.1 then $\\Omega$ will be discrete and $\\partial\\Omega = \\emptyset$. The solution $u$ will be searched in the form of a neural network (NN) taking two inputs $t$ and $x$ and outputting an approximation $U_{\\theta} (t, x)$ of"}, {"title": "3. Theoretical results", "content": "To design time weighting schemes we need to know how the equation error $w(t,\\cdot)$ at time $t$ will impact the accuracy of the final result $U_{\\theta} (T, \\cdot)$. There is no general answer to this question but we will use a close concept, namely the Lyapunov exponent which describes quantitatively the rate of separation of infinitesimally close trajectories. The Lyapunov exponent originates from the dynamic system analysis and, for some 1D ordinary differential equation $z'(t) = f(t, z(t))$ describes how two solutions, starting from $z^1 (0)$ and $z^2(0)$ diverge in the limit of large times $t$; more precisely the Lyapunov exponent is the coefficient $\\lambda \\in \\mathbb{R}$ such that $|z^1(t) - z^2(t)| \\sim e^{\\lambda t}|z^1(0) - z^2(0)|$ (for large $t$). The determination of the exact value of the Lyapunov exponent is a difficult task in dynamical systems and ever more so in evolution PDE, but we will retain this idea. This allows to state :\nProposition 1. Let $u, U_{\\theta}$ as in (1) and (5) respectively. Let $\\lambda(t)$ be such that\n$\\frac{(G_t(u(t,\\cdot)) - G_t (U_{\\theta}(t, \\cdot)), u(t, \\cdot) - U_{\\theta} (t, \\cdot))}{\\|u - U_{\\theta}\\|^2} \\leq \\lambda(t)$. (8)\nThen\n$\\|u(T, \\cdot) - U_{\\theta} (T,\\cdot)\\| \\leq \\int_0^T e^{\\int_t^T \\lambda(s)ds} \\|w(t,\\cdot)\\|dt$. (9)\nHere the norm is euclidean when $\\Omega$ is finite and $L^2$ norm otherwise.\nProof. Denote $e(t) = u(t, \\cdot) - U_{\\theta}(t, \\cdot)$. Using (1) and (5) we obtain:\n$\\frac{1}{2} \\frac{d}{dt}\\|e(t)\\|^2 = (\\frac{d}{dt}e(t),e(t)) = (G_t(u) - G_t(U_{\\theta}) - w(t, .), e(t))$ (10)\n$\\leq \\lambda(t) (e(t), e(t)) - (w(t, .), e(t)) \\leq \\lambda(t)\\|e(t)\\|^2 + \\|w(t, \\cdot) \\|. \\|e(t)\\|$ (11)\nThis means that $\\|e(t)\\| \\leq \\lambda(t)\\|e(t)\\| + \\|w(t,\\cdot)\\|$, and, using the notation $A(t) = e^{-\\int_0^t \\lambda(s)ds}$ we obtain $\\frac{d}{dt} (A(t)\\|e(t)\\|) \\leq A(t)\\|w(t, \\cdot)\\|$; hence, since $e(0) = 0$, by integration from 0 to T we get $A(T)\\|e(T)\\| \\leq \\int_0^T A(t)\\|w(t,\\cdot)\\|dt$ which gives the conclusion.\nThe result already gives qualitative insight into how the error at the final time T depends on errors at intermediary times $t < T$, which is the main idea of Lyapunov exponents. Let us take the simple case $G_t(u) = \\lambda u$ with $\\lambda \\in \\mathbb{C}$ constant; in this case (9) is in fact an equality. As in [13] we note that for a chaotic or divergent system, which is characterized by a strictly positive Lyapunov exponent i.e., $\\mathbb{R}e(\\lambda) > 0$ the trajectories diverge exponentially with respect to error in the equation (5) or in the data. In this case the precision has to be large for $t$ near zero because the factor $e^{\\lambda(T-t)}$ will multiply it resulting in large error in the final state. On the contrary, for values of $t$ close to $T$ the factor $e^{\\lambda(T-t)}$ is relatively small and a larger error in the equation can be tolerated because it will be multiplied by a smaller factor. What is interesting to note is that this also works the other way around for $\\mathbb{R}e(\\lambda) < 0$ which characterize systems converging to stable equilibria. In this case initial errors in the equation will be \"washed away\" by"}, {"title": "4. Numerical experiments", "content": "The code for the numerical experiments will be provided on Github https://github.com/gabriel-turinici.\n4.1. Lorenz system\nThe Lorenz system is a set of ordinary differential equations that describes a simplified model of atmospheric convection. It exhibits chaotic behavior and has been widely studied in the field of dynamical systems; it is described by the following set of ordinary differential equations:\n$x'(t) = \\sigma(y - x), \\quad y'(t) = x(\\rho - z) - y, \\quad z'(t) = xy - \\beta z$, (18)\nwhere $x, y$, and $z$ are the state variables, and $\\sigma, \\rho$, and $\\beta$ are parameters. Coherent with the literature [13] we will take final time $T = 0.5^1$ and use the classical parameter set (initially studied by Lorenz) $(\\sigma, \\rho, \\beta) = (10, 28, 8/3)$ and the initial state $(x, y, z)(0) = (1, 1, 1)$. This test case is notoriously difficult to solve with PINN (the default scheme does not even converge, see below) because of its very high sensitivity with respect to errors in the data and equation.\nThe reference solution, considered exact, is the one obtained with scipy.integrate.odeint"}, {"title": "5. Limitations", "content": "Although the theoretical and empirical results appear encouraging, further work could improve some aspects of the procedure. The most apparent is the estimation of the Lyapunov exponents, which is now done in a very crude way; this could be refined or, if not possible, at least construct some trust regions to inform when these estimations are reliable or not.\nAnother aspect is the interaction between the weights dynamic and the solution. This is common to all adaptive weights procedures but it may concern some cases where the weights given by (17) induce instabilities in the solution preventing convergence (in the same vein as the well-known GAN \"mode collapse\" problem). An analysis of whether this can happen or how to prevent it could be required.\nFinally, for the problems where the canonical, simple implementation of the PINN procedure already works well this algorithm may cause slight numerical computational overhead."}, {"title": "6. Conclusion", "content": "In this work, we presented a new approach to treat the time dimension within the framework of Physics-Informed Neural Network. We started from the observation that time instants are not permutable and depending on the regime (chaotic, periodic, or stably convergent) errors in earlier instants affect differently the quality of the outcome. We proposed a theoretical explanation based on Lyapunov exponents and then a new algorithm built from this insight.\nThe procedure was then tested on two different cases, one chaotic (Lorenz system) and one stable but that induces singularities (Burgers' equation), both known to require careful numerical treatment. The proposed algorithm not only showcases robustness and practical efficiency but also addresses some limitations of earlier works that lacked a principled and theoretically grounded foundation. Of course, while our procedure is robust across various benchmarks, it is designed as a complementary addition to the existing methods rather than a one-size-fits-all solution. We believe this work contributes meaningfully to the field, offering a solid foundation for future research and application development."}, {"title": "Appendix A. Supplementary material", "content": "Appendix A.1. Standard PINN (no time weighting) results for the Lorenz system\nAs announced in section 4.1 we plot in figure A.10 the solution of the procedure for the situation when the weights are not optimized at all but left all uniform. This case was allowed 30'000 iterations (10 times more than our standard setting) but did not even start to converge.\nAppendix A.2. Exact solution for Burgers' equation\nTo compare the PINN solution with a reference ground truth we solved Burger's equation with a finite difference scheme and compared with an analytic formula with Hermite-Gauss integration.\nAppendix A.2.1. Finite differences scheme for Burgers' equation\nThe finite difference scheme works on a spatial domain discretized with $n_x = 400+1$ spatial grid points (counting both segment extremities $\\pm1$), i.e. $\\Delta x = 2/400$ and $n_t = 700$ time steps ($\\Delta t = 1/700$); each time step is implementing the following split-operator technique :\nfirst a Crank-Nicholson (CN) scheme over a $\\Delta t/2$ time step (taking into account the boundary conditions) for the diffusion part i.e. the solution by CN of the equation $\\partial_t u = \\nu \\partial_{xx} u$\nthen a $\\Delta t$ step of a Lax-Friedrichs scheme for the viscosity term, i.e. for the equation $\\partial_t u + u \\partial_x u = 0."}, {"title": "Appendix A.3. Behavior of weights of the causal procedure (Lorenz system)", "content": "To explore the convergence properties of the causal protocol [13] we looked at the history of the weights used by the procedure during the resolution of the Lorenz system, see comments in section 4.1; these are plotted in figure A.11. The algorithm's protocol iterates the $\\epsilon$ parameter ; at each change the weights associated with latter times are smaller which causes deterioration of the quality there. So the algorithm can only advance to the next value of $\\epsilon$ only after the equation is satisfactory solved at initial times."}, {"title": "then a final Crank-Nicholson (CN) scheme over a $\\Delta t/2$ time step (taking into account the boundary conditions) for the diffusion part", "content": "The splitting technique is known to be of high order in time [17, 18, 19] which leaves the Crank-Nicholson part (second order in time) and Lax-Friedrichs scheme (first order in time and space) as limiting factors. As for stability it is known that CN is unconditionally stable for the heat diffusion and since the matrix for the Lax-Friedrichs scheme is tridiagonal by Gersgorin theorem it is stable when $\\max(|u|) \\cdot \\Delta t/\\Delta x < 1$.\nIn practice, if $V \\in \\mathbb{R}^{n_x+1}$ is the current solution with $V_j$ the component representing the solution at point $x = -1 + j\\cdot \\Delta x)$, the CN propagation for a $\\Delta t/2$ time step means solving the linear system in $V^{next}$:\n$\\frac{V^{next}_j - V^{next}_{j}}{ \\Delta t/2} = \\frac{\\nu}{2} (\\frac{V_{j+1} + V_{j-1} - 2V_{j}}{\\Delta x^2} + \\frac{V^{next}_{j+1} + V^{next}_{j-1} - 2V^{next}_{j}}{\\Delta x^2})$, $V^{next}_0 = 0 = V^{next}_{n_x}$.\nThe Lax-Friedrichs scheme means replacing $V$ with :\n$V^{next}_j \\quad \\frac{V_{j+1} + V_{j-1}}{2} + (\\frac{V^2_{j+1}}{2} - \\frac{V^2_{j-1}}{2}) \\\\ \\Delta t\\\\\\frac{2 \\Delta x} = 0, V^{next}_0 = 0 = V^{next}_{n_x}$."}]}