{"title": "LLM4DESIGN: An Automated Multi-Modal System for Architectural and Environmental Design", "authors": ["Ran Chen", "Xueqi Yao", "Xuhui Jiang"], "abstract": "This study introduces LLM4DESIGN, a highly automated system\nfor generating architectural and environmental design proposals.\nLLM4DESIGN, relying solely on site conditions and design require-\nments, employs Multi-Agent systems to foster creativity, Retrieval\nAugmented Generation (RAG) to ground designs in realism, and\nVisual Language Models (VLM) to synchronize all information. This\nsystem resulting in coherent, multi-illustrated, and multi-textual\ndesign schemes. The system meets the dual needs of narrative\nstorytelling and objective drawing presentation in generating ar-\nchitectural and environmental design proposals. Extensive com-\nparative and ablation experiments confirm the innovativeness of\nLLM4DESIGN's narrative and the grounded applicability of its\nplans, demonstrating its superior performance in the field of urban\nrenewal design. Lastly, we have created the first cross-modal design\nscheme dataset covering architecture, landscape, interior, and urban\ndesign, providing rich resources for future research.", "sections": [{"title": "1 INTRODUCTION", "content": "Architectural and environmental design must balance narrative\nlanguage with objective descriptions. Engaging stories can make\ndesign proposals more attractive and easier to market, but without\nprecise objective descriptions, these stories cannot be realized since\ndesigns must be constructed in the real world. Therefore, a careful\nbalance of both is crucial to ensure the design is both imaginative\nand feasible.In the process of Al assistance in architectural and\nenvironmental design, there are three main issues that need to be\naddressed. These issues directly reflect the challenges of balancing\nnarrative language with objective descriptions.\nChallenge 1: Design documents must include compelling\ncreative stories. Architects and environmental designers need to\ncreate stories that are not only engaging but also rooted in the"}, {"title": "2 RELATED WORK", "content": "Al technologies have deeply penetrated the design industry. \u0410\u0441-\ncording to [34], AI-assisted design primarily encompasses four\ndirections: discovery, visualization, creation, and testing. In the\n\"discovery\" phase, AI tools [23, 27, 50] analyze user data to reveal\nunderlying needs and guide preliminary design ideas. During the\n\"visualization\" phase, AI aids designers in precisely constructing\ndesign concepts. In the \"creation\" phase, AI automatically drafts\nand iteratively refines design schemes. In the \"testing\" phase, AI\nevaluates the design quality to ensure the practicality and customer\nsatisfaction of the outcomes.\nTherefore, the current AI-assisted design (AIAD) process is still\nperformed in stages. However, the complexity and non-linear char-\nacteristics of the design process demand a more advanced inte-\ngration strategy to balance innovation with practicality and meet\nunique site and client needs.\nThis section reviews the applications of AI in the fields of im-\nage and text generation. It finds that while image generation fo-\ncuses on control and often lacks preliminary design reasoning, text\ngeneration is rich in creativity but lacks specificity. Consequently,\nthis study develops a multimodal framework by integrating the\nstrengths of both image and text generation. This framework aims\nto mimic the thought process of designers and achieves a one-click\noperation from \"user query\" to \"multimodal drawing generation,\"\nenhancing the automation and precision of design."}, {"title": "2.1 Image Generation", "content": "Recent advancements in image generation technology, particularly\nthrough Generative Adversarial Networks (GANs) [29, 31], have\nsignificantly enhanced the methods available to architects and land-\nscape designers, enabling the generation of diverse building and\nlandscape floor plans based on user inputs. However, these tech-\nnologies have primarily been applied to floor plan generation[42].\nThe introduction of large models such as diffusion and VAEs has\nlowered technical barriers and enabled preliminary cross-modal\ngeneration. Despite these advancements, text-to-image processes\nstill struggle with inadequate control over outputs, resulting in\nimprecise details and requiring extensive prior knowledge.\nCurrent research in this field primarily focuses on precise gener-\nation. However, in industrial workflows, control over image gen-\neration is often deferred to the final drawing stages, with earlier\nstages still lacking sufficient tools to systematically reason through\ndesign ideas and comprehensively evaluate their effectiveness."}, {"title": "2.2 Creative Text Generation", "content": "In the current landscape of artificial intelligence research and appli-\ncations, agents have demonstrated extensive potential and diverse\nfunctional capabilities[41].\nThese agents have been effectively applied in areas such as em-\nbodied intelligence [26, 32, 44], tool use [7, 10, 14, 33], and social\nsimulation [15, 20], and have also penetrated vertical domains, in-\ncluding psychology [24], law [9], and chemistry [3].\nDespite this, the field of design, especially tasks related to archi-\ntectural and landscape design, has yet to see significant applications\nof agents. However, technologies such as prompt engineering and\nchain of thought reasoning [16, 19] have proven to be exceptionally\neffective in stimulating innovative capabilities in these areas."}, {"title": "3 METHODOLOGY", "content": "In this section, we will first illustrate the meanings of \"design\nlanguages\" discussed previously, through a case study. This is\nto intuitively show why it is necessary to perform information\nretrieval and why it is crucial to filter and summarize beneficial\ndesign illusions. Subsequently, we will elaborate on each component\nof the framework in detail."}, {"title": "3.1 \u201cDesign Languages\u201d", "content": "In the preliminary phase of our research, we conducted comparative\nexperiments to assess the feasibility of directly employing existing\nlarge-scale models to generate answers based on user requirements.\nThe results indicated significant inaccuracies in the text gener-\nated directly, leading to responses that deviated from reality and\nstruggled to produce reasonable solutions based on available infor-\nmation, failing to offer authentic design proposals.\nTaking the Suzhou Garden Museum in China as an example (Figure\n2), designers creatively reinterpreted \"the spirit of China's tradi-\ntional history\" as \"The black and white,\" \"the museum's theme of\n'books,\" as \"The elegantly staggered facade,\" and \"the theme of\nlandscape paintings\" as \"sketching in black and white,\" whereas\nexisting large models tend to translate these more directly, such\nas turning \"the museum's theme of 'books,\" into \"sculptures of\nopened books and scrolls.\"\nWe discovered that the core issue with models encountering\nproblems in unconstrained conversational contexts lies in the sig-\nnificant difference in handling design-related semantic information\nas opposed to processing conventional natural language texts.\nThe complexity and specificity of design semantics require mod-\nels to not only understand standard linguistic expressions but also\npossess in-depth understanding and processing capabilities for spe-\ncialized knowledge in the design field.\nFor instance, the language used by designers is categorized un-\nder natural language. However, it frequently incorporates industry-\nspecific terminology and concepts, such as \"historical sentiment,\"\nwhich are difficult for traditional natural language processing mod-\nels to accurately interpret.\nAdditionally, designers frequently refer to \"scene memories\" to\ndescribe design concepts, which in visualization often correspond\nto fluid curves or specific shapes, details that are also difficult to\ncapture in traditional text processing."}, {"title": "3.2 Design Language Aligner", "content": "Based on the analysis in Section 3.2, we conclude that a primary\nchallenge with the current agents' divergent capabilities is the gap\nbetween design language and natural language.\nTherefore, we developed a converter. It aims at aligning design\nlanguage with natural language. The construction of the aligner\nconsists of the following steps:\nFine-tuning the BGE-M3 model: The BGE-M3 model is pri-\nmarily used for text-to-text search. In evaluating the performance of\nvarious text embedding models, we found that the Flag Embedding\nmodel excelled in multiple metrics. We fine-tuned the Flag Embed-\nding model with 5k high-quality data entries from a multimodal\ndatabase, with specific parameters detailed in the table below.\nFine-tuning the BLIP2 model: The BLIP2 model is mainly\nused for text-to-image search. We fine-tuned the BLIP2 model us-\ning a specific dataset to enhance its capability in searching and\nrecognizing design images.\nConstructing a vector database: We collected 60k data to\nestablish a multimodal vector database."}, {"title": "3.3 Debate between Agent_I and Agent_R", "content": "In the preliminary stage of the research, it is imperative to clearly\ndefine two categories of agents: the Innovative Agent (Agent_I) and\nthe Retrieval Agent (Agent_R).\n\u2022 The Agent_I represents agents with a high capacity for inno-\nvation. We employ methods to stimulate remote associations,"}, {"title": "3.4 The conclusion of Agent_C", "content": "The Conclude Agent represents a pivotal component of our AI-\ndriven design framework, developed to refine and synthesize de-\nsign narratives. It is founded on the Visual Language Large Model\n(VLLM), a cutting-edge model adept at processing and generating\nmultimodal content. The primary function of the Conclude Agent\nis to streamline and coalesce the creative narratives generated in\nearlier phases of the design process. This agent meticulously pre-\nserves the essence of the story while concurrently extracting and\ncondensing the design elements necessary for visual depiction. By\ndoing so, it ensures that the resulting graphical representations\nremain coherent with the original narrative, effectively bridging\nthe gap between textual creativity and visual expression."}, {"title": "3.5 Graphic Align and represent by Agent_V", "content": "Agent_V, known as the Visual Agent, is primarily tasked with trans-\nforming design thinking into graphical representations. Its core\nresponsibilities include:Receiving prompts from Agent_C and con-\nducting secondary searches to locate reference images based on\nthese prompts; Matching prompts with reference images using \"de-\nsign keywords; Generating images by integrating prompts with\nControlNet [49]; Compiling the outputs, presenting them to the\nuser, and conducting quality reviews.\nIn the study of text-to-image generation, after comparing exist-\ning state-of-the-art models, we have chosen StableDiffusion as our\nfoundational model for image generation.\nAdditionally, ControlNet[49] has been proven to be an effective\nstrategy for controlling site-specific information, primarily utiliz-\ning linear and segmentation methods.The parameters we used for\ngraphical representation are as followed."}, {"title": "4 EXPERIMENT SETTINGS", "content": "In the dataset construction phase, this study established the inaugu-\nral multimodal dataset tailored for the landscape architecture and\nplanning field. Given the complexity and varied formats of design\ntexts, web scraping techniques were employed to selectively extract\nand cleanse data from authoritative journals within the domain. We\nutilized GPT-3.5-turbo api to generate pairs of textual queries and\ndesign descriptions. Image captions were produced using the LLaVA"}, {"title": "4.1 Datasets", "content": "In the dataset construction phase, this study established the inaugu-\nral multimodal dataset tailored for the landscape architecture and\nplanning field. Given the complexity and varied formats of design\ntexts, web scraping techniques were employed to selectively extract\nand cleanse data from authoritative journals within the domain. We\nutilized GPT-3.5-turbo api to generate pairs of textual queries and\ndesign descriptions. Image captions were produced using the LLaVA"}, {"title": "4.2 Baselines", "content": "As for evaluation, we employ state-of-the-art open-source text-to-\nimage models, specifically SD [36] and DALLE3[2] as our baselines."}, {"title": "4.3 Evaluation Metrics", "content": "Definitions of Innovation and Reliability. Innovation: In this\ncontext, innovation refers to whether the generated design schemes\nincorporate novel perspectives, information, or solutions. This nov-\nelty includes not only unprecedented ideas but also the innovative\ncombination or presentation of known information. For evaluation,\ninnovation will be shown as creativity score.\nReliability: Reliability focuses on the accuracy of the gener-\nated blueprints in retaining essential site information, as well as\nthe timeliness and applicability of the provided information.For\nevaluation, reliability will be shown as Design score."}, {"title": "4.3.2 Leveraging the Concept of Generative Adversarial Networks\nfor the Study", "content": "This study adopts the concept of Generative Adver-\nsarial Networks[13] to assess the convergence and divergence of\ngenerated schemes, the equation is as followed:\n$V(D, G) = af (D(x)) + (1 \u2212 a)g(D(G(z)))$", "equation": "V(D, G) = af (D(x)) + (1 \u2212 a)g(D(G(z)))"}, {"title": "4.3.3 Design Score", "content": "As previously discussed, a complexity in AI\narchitectural design lies in its necessity to closely integrate human\npreferences and aesthetics.\nTherefore, we invited 30 experienced architectural designers to\nparticipate in our evaluation process.\nThe evaluation dimensions were mainly based on recommenda-\ntions for aesthetic assessment and AI design evaluation [5, 11, 38, 39].\nFor example, Silvia assessing artistic design through fluency, flexi-\nbility, originality, and elaboration[39].\nUltimately, we chose the following parameter. These scores are\nscored by human designers on a scale of 0-10, with the final score\nbeing an average. The parameters are as followed: Originality, Rel-\nevance, Complexity,Flexibility,Participation Style, Task Distribution."}, {"title": "4.3.4 Creativity score", "content": "Creativity is categorized into two types:\nCreativity-i and Creativity-t."}, {"title": "5 MAIN EXPERIMENT RESULTS", "content": "In our main experiment, we assessed advanced image synthesis\nmethods, including SD and DALLE3. The Creativity Score evaluated\nthe innovation in outputs, while the Design Score assessed practical\napplicability.\nTable 2 shows that SD scored 7.25 in creativity, while DALLE3\nand OURS both scored 8.0, indicating similar performance in gen-\nerating creative outputs, with both surpassing SD. In design scores,\nSD scored 7.5, DALLE3 7.25, and OURS 8.5, showing OURS as the\nbest performer.\nDALLE3 excels in creativity but struggles with integrating site\nconditions due to text control limitations, affecting its detailed\ndesign capability. Stable Diffusion is commonly used but its output\nis limited by prompt length and manual input. Hence, it scored\nbetween DALLE3 and OURS in design and lower in creativity.\nThe system we developed uses a multi-agent approach to discuss\nlogical design strategies based on requirements. It retrieves relevant\ndesign cases to provide a basis for design and uses controlnet to\nmanage the visual output. This approach ensures the creation of a\ncoherent narrative while enhancing design scores.\nOverall, DALLE3 and SD each have their strengths and weak-\nnesses. OURS shows significant potential for practical applications\ndue to its high design scores."}, {"title": "6 ABLATION STUDY", "content": "In this section, we conduct two sets of ablation studies to evaluate\nthe impact of various components on our multiagent system's effec-\ntiveness in enhancing creativity. These studies specifically address\nthe components introduced in response to the three challenges.\nRO1: Agent writing a creativity story.\nWe removed Agent_I to test the innovativeness of design docu-\nments under conditions lacking creative support. The results indi-\ncated that without Agent_I, the narratives generated were signifi-\ncantly lacking in novelty, confirming the crucial role of creativity\nin crafting engaging stories.\nRO2: Design documents must reflect real-world contexts.\nBy eliminating the agent responsible for real-world context re-\ntrieval, we evaluated the feasibility of the designs without support\nfrom actual site data. The experiments demonstrated that, in the"}, {"title": "6.1 Evaluation of Different Agent Systems", "content": "This paper evaluates the constructed Agent system and the cur-\nrently existing industry Agent systems, as is shown in table 3. The\nexperimental results indicate the following:"}, {"title": "6.2 Evaluation of Agent System Components", "content": "In this study, the role of various components within the Agent\nsystem was assessed through ablation experiments(Table 4)\n(1) Removal of Agent-R: Agent-R employs RAT (Relevant\nAssociation Technique) technology to retrieve relevant data from\nmultiple information sources. The experimental results indicate\nthat after removal, the creativity score slightly increased to 7.5,\nwhile the design score remained unchanged at 8.0. This suggests\nthat the primary role of the RAT technology is to enhance content\nrichness, with a minor impact on design rationality."}, {"title": "7 CASE STUDY", "content": "To effectively demonstrate the capabilities of LLM4DESIGN, we\nselected a typical case from our experimental dataset for detailed\nanalysis (refer to Appendix B), presenting the prompts and out-\ncomes at each stage. The results of other cases are also documented\nin the appendix.\nIn Appendix B, we chose a campus landscape renovation project\nas our design case. As illustrated, colored titles indicate the vari-\nous stages of agent activity, corresponding to the challenges and\ninnovations discussed in the introduction section.\nInitially, addressing the need for a creative narrative, our system\ncommenced by segmenting user requirements into keywords such\nas 'interaction', 'resource sharing', 'surrounding community', and\n'dynamic'. Subsequently, the system inspired a range of innovative\ndesign concepts like 'Metropolitan Imagination Matrix' and 'Syn-\nergistic Wisdom Canopy', which serve as sources of inspiration\nfor narrative writing in the design plans, simulating a designer's\nbrainstorming process.\nTo meet the requirement for designs that resonate with real-\nworld scenarios, the reliable agent refined the design logic through\na three-phase search, mimicking a designer's process of iterating\nthrough a design library to finalize the framework. During the de-\nbate and conclusion stages, through six rounds of discussions, a"}, {"title": "8 CONCLUSION", "content": "In summary, our framework integrates a Multi-Agent system to\nenhance both the creative and practical facets of design processes.\nBy employing this system, we stimulate innovative thinking and\nensure reliability with systematic checks, promoting diverse and\nrealistic creative outputs that are applicable in real-world scenarios.\nThe framework includes five key components: multimodal re-\ntrieval for diverse data access, multi-agent simulations to explore\ncreative pathways, alignment of conceptual sketches with detailed\nrenderings for visual consistency, enhanced visualization capabili-\nties, and a user evaluation system using adversarial principles to\nbalance innovation and reliability. These elements facilitate a dy-\nnamic interplay between creativity and practicality, expanding tra-\nditional design boundaries.Additionally, the integration of a visual\nagent within our system seamlessly handles complex cross-modal\ninformation, translating abstract concepts into detailed, actionable\nplans suitable for realistic implementation.\nOverall, our framework not only generates and evaluates inno-\nvative design solutions against high standards of practicality and\nuser satisfaction but also redefines the possibilities of architectural\nand environmental design to effectively meet modern challenges."}]}