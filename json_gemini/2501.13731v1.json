{"title": "Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks", "authors": ["Chang Gong", "Wanrui Bian", "Zhijie Zhang", "Weiguo Zheng"], "abstract": "Graph computational tasks are inherently challenging and often demand the development of advanced algorithms for effective solutions. With the emergence of large language models (LLMs), researchers have begun investigating their potential to address these tasks. However, existing approaches are constrained by LLMs' limited capability to comprehend complex graph structures and their high inference costs, rendering them impractical for handling large-scale graphs. Inspired by human approaches to graph problems, we introduce a novel framework, PIE (Pseudocode-Injection-Enhanced LLM Reasoning for Graph Computational Tasks), which consists of three key steps: problem understanding, prompt design, and code generation. In this framework, LLMs are tasked with understanding the problem and extracting relevant information to generate correct code. The responsibility for analyzing the graph structure and executing the code is delegated to the interpreter. We inject task-related pseudocodes into the prompts to further assist the LLMs in generating efficient code. We also employ cost-effective trial-and-error techniques to ensure that the LLM-generated code executes correctly. Unlike other methods that require invoking LLMs for each individual test case, PIE only calls the LLM during the code generation phase, allowing the generated code to be reused and significantly reducing inference costs. Extensive experiments demonstrate that PIE outperforms existing baselines in terms of both accuracy and computational efficiency.", "sections": [{"title": "1 Introduction", "content": "Graph reasoning requires designing specialized algorithms tailored to the unique characteristics of each task. For instance, tasks like community detection and subgraph matching necessitate distinct approaches, making the development and implementation of such algorithms both resource-intensive and computationally expensive. Consequently, developing efficient and cost-effective solutions for diverse graph reasoning tasks remains a critical challenge in practical applications.\nIn recent years, large language models (LLMs) [Achiam et al., 2024; Grattafiori et al., 2024; Liu et al., 2024a] have achieved remarkable advances across various domains. With billions of parameters, these models exhibit impressive generalization abilities. After pretraining on large-scale and diverse datasets, LLMs can understand and generate human-like text, reason through complex queries, and tackling tasks that extend beyond traditional natural language processing (NLP), including code generation [Zhu et al., 2024; Hui et al., 2024; Zhong et al., 2024], mathematical reasoning [Shao et al., 2024; Zhou et al., 2024; Ying et al., 2024], and scientific problem-solving [Bi et al., 2023; Romera-Paredes et al., 2023; Wang et al., 2024]. Leveraging their versatility, researchers have begun exploring the application of large language models (LLMs) to graph computational tasks [Tang et al., 2024; Luo et al., 2024; Li et al., 2024; Wang et al., 2023; Skianis et al., 2024]. A common approach involves directly assigning graph problems to LLMs, presenting the tasks as natural language prompts or structured queries. The LLMs then attempt to understand the problem, perform reasoning on the graph, and generate solutions autonomously, without human intervention. This emerging approach capitalizes on the general-purpose reasoning abilities of LLMs, offering innovative and flexible solutions to graph computational challenges. However, this strategy suffers from two problems:\n(1) Accuracy Limitations: The ability of LLMs to understand graph structures is limited, especially when dealing with complex or large-scale graphs. Since graph structures are unordered, transforming them into a text sequence prevents LLMs from effectively capturing the topological and semantic relationships between nodes. Moreover, LLMs rely on probabilistic autoregressive decoding, which inherently prioritizes plausible predictions over precise computations. This leads to prediction errors, even in simpler tasks. For instance, when using Llama3-8B for graph reading tasks, such as determining node count, edge count, and calculating the maximum, minimum, and average node degrees,"}, {"title": "2 Graph Computational Tasks", "content": "In this paper, we investigate nine representative and challenging graph computational tasks, categorized into two groups: polynomial-time problems and NP-complete problems. Figure 1 presents examples of these tasks.\nPolynomial-Time Tasks\n(1) Common Neighbors (CN): Find common nodes connected with two given nodes $u$ and $v$ in a graph $G$.\n(2) Connected Components (CC): Find all disjoint connected components in an undirected graph $G$. Any two nodes in a CC can be connected by a path within this component.\n(3) Shortest Path (SP): Given two nodes $u$ and $v$ in an unweighted and undirected graph $G$, find the shortest path connecting the two nodes.\n(4) Graph Diameter (GD): For an undirected graph $G$, find the maximum distance between any node pair, where distance is the length of shortest path between two nodes.\nNP-Complete Tasks\n(1) Maximum Independent Set (MIS): Find the largest node set in an undirected graph $G$ such that no two nodes are adjacent.\n(2) Minimum Vertex Cover (MVC): Find the smallest node set $U$ in an undirected graph $G(V, E)$ such that for any edge $e = (u, v) \\in E$, $u \\in U$ or $v \\in U$."}, {"title": "3 Methodology", "content": "To mitigate LLM's incorrect understanding of graph structure and extremely long inference time, we propose a novel framework PIE (Pseudocode-Injection-Enhanced LLM Reasoning on Graph Computational Tasks) that decomposes graph reasoning into three steps: problem understanding, prompt design, and code generation and executation. The overview of PIE is illustrated in Figure 1. First, we instruct LLMS to focus on understanding the task description instead of the graph structure, leaving the latter to the interpreter. Then, we carefully design prompts that integrate algorithm-related pseudocode, which helps LLMs to generate efficient code. Finally, we ensure the correctness of LLM's output code through low-cost iterative refinements and apply it to other large-scale datasets."}, {"title": "3.2 Problem Understanding", "content": "Previous research has primarily focused on examining how different forms of graph serialization affect reasoning results. However, how to serialize graphs may not be the most critical factor, as LLMs struggle to comprehend graph structures, as evidenced by their inability to accurately identify basic graph elements. Nonetheless, LLMs possess a solid understanding of various graph reasoning tasks; for instance, they can identify the shortest path between two nodes. Therefore, the key challenge is to establish a connection between the background knowledge embedded in LLMs and the inherent structure of graphs.\nTo address this, we propose a new approach: task understanding and graph structure interpretation are delegated to LLMs and interpreters, respectively. LLMs generate task-related code, while interpreters execute the code to produce the final results. This approach allows LLMs and interpreters to leverage their respective strengths effectively. LLMs utilize their task-related knowledge to generate code without the need to understand the specific graph structure, accessing graph elements through abstract APIs. On the other hand, interpreters precisely identify the fundamental components of the graph by specifying its structure in a particular format, and execute the generated code to obtain definitive results. Furthermore, once LLMs produce correct code, interpreters can execute the code for subsequent tasks in the same category without repeatedly invoking the LLM, thereby reducing the overall inference cost."}, {"title": "3.3 Prompt Design", "content": "LLMs may possess a comprehensive knowledge of graph computational tasks. To effectively leverage this knowledge and produce accurate, efficient code, it is essential to craft well-structured prompts. These prompts consist of three main components: the system prompt, the problem prompt, and the pseudocode prompt.\nSystem Prompt\nIn this part, we instruct the LLM to act as an expert in graph algorithms and attempt to solve problems by writing code. To facilitate subsequent processing, we also specify a required output format. This structure is consistent across all tasks.\nProblem Prompt\nIn this part, we provide a concise description of the task and clearly define the objectives for the LLM's output. Through"}, {"title": "3.4 Code Generation and Execution", "content": "By integrating the three prompts mentioned above, LLMs can generate the corresponding code. However, when the code is executed by the interpreter, errors such as syntax issues (e.g., missing modules) or runtime problems (e.g., missing object attributes) may arise. These errors are typically unrelated to the core logic and can be easily addressed by the LLM itself. Thus, we propose the following two strategies to guide LLMs in reviewing and producing error-free code:\n(1) For each task, we generate 10 small-scale graphs $d_{small}$ (node number $|N| < 10$). The code $c$ generated by the LLM is evaluated using a test function $f$ on $d_{small}$. If the code passes all tests, it is selected as the final output. If it fails any test, the LLM is required to regenerate the code.\n(2) In the event of an error, the test function $f$ extracts the error message and provides it to the LLM for correction, repeating this process until the code executes correctly.\nThe whole process is outlined in Algorithm 1. To mitigate the high cost associated with repeatedly invoking LLMs, we impose an upper limit $K$ on the number of retry attempts. If the code fails to pass all tests on $d_{small}$ within $K$ trials, we select the best-performing code as the final output. For polynomial-time and NP-complete tasks, we use accuracy and approximation ratio as evaluation metrics. Notice that this trial-and-error process is executed automatically without human intervention, thereby reducing the effect of human bias on the final result."}, {"title": "4 Experiments", "content": "Tasks and Datasets. Nine graph computational tasks are introduced in Section 2. For each task, we follow GraphArena to construct 500 small- and large-scale test graphs.\nMetrics. We consider two aspects of metrics:\n(1) Prediction precision: For $T$ test graphs, suppose prediction and ground-truth value are $p_i$ and $p$, then\n$Accuracy = \\frac{|\\{i | p_i = p\\}|}{T}$. For NP-complete tasks, in addition to Accuracy, we include two metrics:\nFeasible Rate(FR) and Approximation Ratio = $\\frac{\\sum\\frac{p_i}{p}}{T}$. For MIS, MCP, and MCS, \u201cFR\u201d represents the probability that prediction is no larger than the ground truth, whereas for MVC and TSP, it denotes the opposite scenario.\n(2) Efficiency and costs: we also compare the costs of different algorithms, primarily measured by the cost of a single call to LLMs and the total number of calls.\nBaselines. There have been many works aiming to enhance LLM's graph reasoning ability. We select five representative single-agent ones as our competitors: GraphArena [Tang"}, {"title": "4.2 Performance Comparison", "content": "Table 2 compares the accuracy of various methods on different graph computational tasks. Overall, our method significantly outperforms other baselines. On polynomial-time tasks, our method achieves 100% accuracy, and this result is independent of the LLM backbone and graph size. For NP-complete problems, our approach also ensures a high level of precision, especially on large graphs, with an average improvement of 60.3 and 57.9 percentage points compared to other methods with llama3-8b and llama3-70b backbone.\nThe substantial enhancement is derived from circumventing graph reading by LLMs. Instead, they are applied to understand graph tasks from a broad perspective and focus on code generation that they excel in. The analysis of graph structure is delegated to interpreter, which can identify basic graph elements correctly. Moreover, the code generated by LLMs undergoes trial-and-error test to guarantee that it runs correctly, ensuring excellent performance on other datasets.\nFor NP-complete tasks, we further compare approximation ratios and feasible rates of different algorithms. As shown in Figure 2, the approximation ratio of our method is less than $\\frac{1}{10}$ of other methods. Especially on MCP task, it equals to 0, indicating that the predictions are all correct. Figure 3 illustrates the proportion of predictions that can be feasible solutions. Clearly, our approach achieves a perfect 100% across all tasks. In contrast, other methods struggle to ensure even a feasible solution due to the lack of constraints on prediction.\nEspecially for TSP task, whose ground-truth value's range can be extremely vast, it is quite challenging for them to control predictions into a reasonable range. Thanks to writing code by LLMs instead of using them to directly output an answer, our method ensures to acquire a feasible solution. Moreover, an extremely low approximation rate guarantees obtained feasible solution is close to ground truth, thereby enhancing the practicality of our method."}, {"title": "Efficiency and Costs", "content": "Previous works do not consider the cost of calling LLMs. Despite promising performance, they cannot process large-scale graphs. In this section, we will demonstrate high-efficiency and cost-effectiveness of our method from two perspectives:\n(1) Lower single LLM call cost. Figure 4 presents the average time cost of a single call to LLMs for different algorithms. Clearly, our method exhibits the lowest time consumption across most tasks: with llama3-8b and llama3-70b as LLM backbones, our method reduces the average time cost by 72.8% and 54.9% compared to other baselines. This aligns with expectations: other works incorporate serialized graph structures into the prompt, which results in a prompt length of O(|E|). When processing large-scale graphs, the LLM inference cost is unbearable. In contrast, our approach merely adds pseudocode into prompt, which is independent of the particular graph structure (i.e., prompt length is O(1)). Moreover, the generated executable code can naturally address large-scale graph problems.\n(2) Minimal total number of LLM calls. Furthermore, we investigate the number of times different algorithms call the LLM, as shown in Table 3. Other methods need to call the LLM for each test sample, which means the total number equals the test set size (500 small + 500 large). This evidently restricts the application in scenarios involving large-volume data and extensive queries. However, our method requires to call the LLM at most K times for each task. Once the correct executable code is generated, the subsequent process of parsing graph structure and computing answers will be handled by the interpreter. This also implies that our method can be naturally extended to solve large-scale problems."}, {"title": "4.3 Detailed Analysis", "content": "Pseudocode prompt plays a crucial role in our method. It provides clear guidance for the generation objectives of the LLM, and directs it to perform code-writing tasks instead of graph understanding. Meanwhile, it prevents LLMs from generating simple brute-force algorithms that cannot be applied to large-scale data. We further investigate the impact of different forms of pseudocode prompts on accuracy, as shown in Table 4. \"w/o pseudo\" means removing pseudocode prompts. \"pseudo-NL\u201d denotes that we use LLMs to rephrase pseudocode in natural language, and \u201cpseudo-Core\u201d only retains core ideas and removes specific implementation details from \"pseudo-NL\".\nResults show that for polynomial-time tasks, even without pseudocode prompts, LLMs can provide completely correct code. This is because these problems are quite common, and LLMs have been sufficiently trained on them. However, on NP-complete problems, the lack of pseudocode prompts makes LLMs more inclined to output brute-force algorithms that cannot output results within a limited time. Rephrasing pseudocode through LLMs can enhance its readability and improve the robustness of the generated code. However, natural language descriptions are less precise than pseudocode, and missing details lead to wrong results. The significant"}, {"title": "5 Related Work", "content": "The existing methods using LLMs to solve graph computational tasks can be classified into the following two groups:\n(1) LLM-based Graph Reasoning using Text-Described Graph Data. These approaches directly transform the task and graph structures into text sequences, and then input into LLMs for further reasoning. Many researchers adopt this paradigm to build evaluation datasets for assessing LLMs' reasoning ability on graph tasks. Notable examples include GraphArena [Tang et al., 2024], talk-like-a-graph [Fatemi et al., 2024], NLGraph [Wang et al., 2023], GraphInstruct [Luo et al., 2024] and PSEUDO [Skianis et al., 2024].\n(2) LLM-based Graph Reasoning via Code Generation. During the reasoning process, LLMs act as a solution provider, which means they no longer rely on specific graph structure but propose a unified solution for the same category of graph tasks. For instance, GraphEval2000 [Wu et al., 2024] leverages 40 graph-related tasks from LeetCode to assess LLMs' problem-solving ability based on programming. GraphTeam [Li et al., 2024] integrates multiple LLM-based agents to collaboratively write code for graph reasoning tasks, including search, question, coding, reasoning, and answer agents. However, these methods are still constrained by the high costs of repeatedly calling LLMs within multi-agent systems and finetuning LLMs."}, {"title": "6 Conclusion", "content": "In this paper, we highlight two limitations of existing methods that use LLMs to solve graph computational tasks: low accuracy caused by LLMs' misinterpretation of graph structure and prohibitive inference cost of LLMs due to excessively long prompts. We propose a new framework PIE, which instructs LLMs to understand the task description and write code. To assist LLMs in generation, we introduce pseudocode injection method and employ trial-and-error to select the optimal code. Experiments show that PIE outperforms other methods in accuracy and has the lowest inference cost."}]}