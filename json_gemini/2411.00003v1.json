{"title": "IC/DC: Surpassing Heuristic Solvers in Combinatorial Optimization with Diffusion Models", "authors": ["Seong-Hyun Hong", "Hyun-Sung Kim", "Zian Jang", "Byung-Jun Lee"], "abstract": "Recent advancements in learning-based combinatorial optimization (CO) methods have shown promising results in solving NP-hard problems without the need for expert-crafted heuristics. However, high performance of these approaches often rely on problem-specific human-expertise-based search after generating candidate solutions, limiting their applicability to commonly solved CO problems such as Travelling Salesman Problem (TSP). In this paper, we present IC/DC, a CO framework that operates without any supervision. IC/DC is specialized in addressing problems involving two distinct sets of items, and it does not need problem-specific search processes to generate valid solutions. IC/DC employs a novel architecture capable of capturing the intricate relationships between items, and thereby enabling effective optimization in challenging CO scenarios. We train our model in a self-supervised way to minimize the cost of the solution while adhering to the problem-specific constraints. IC/DC not only achieves state-of-the-art performance compared to previous learning methods, but also surpasses well-known solvers and heuristic approaches on Asymmetric Traveling Salesman Problem (ATSP).", "sections": [{"title": "1 Introduction", "content": "Combinatorial optimization (CO) aims to find the optimal solution that maximizes or minimizes an objective function from a large, discrete set of feasible solutions. This field has been extensively studied due to its broad industrial applications, including logistics, supply chain optimization, job allocation, and more (Zhang et al. 2023). Despite its significance, many CO problems are NP-complete, and developing efficient approximation algorithms is essential.\nTraditionally, approximation algorithms for CO have been developed using mathematical programming or hand-crafted heuristics (Miller, Tucker, and Zemlin 1960; Helsgaun 2023). However, the need for problem-specific expertise and the high computational demands of these methods has sparked increasing interest in applying deep learning techniques to CO problems. Early deep learning approaches framed CO problems as sequential decision-making tasks, generating solutions in an auto-regressive manner (Bello et al. 2016; Kool, Van Hoof, and Welling 2018). However,\nthese methods were relatively limited in performance due to their inability to revise previously made decisions.\nIn contrast, diffusion-based methods generate complete solutions in a single diffusion timestep and then iteratively refine them during the denoising process (Sun and Yang 2023; Min, Bai, and Gomes 2024). This iterative refinement enhances the overall quality of the solutions through corrections and adjustments. By allowing for the revision of earlier decisions, diffusion-based methods overcome the limitations of auto-regressive approaches and avoid the compounding errors typically associated with early decisions.\nDespite the impressive performance of diffusion-based methods, previously proposed algorithms had several significant drawbacks, such as the need for costly supervision (Sun and Yang 2023), or use of problem-specific objective that are applicable to other CO problems (Min, Bai, and Gomes 2024). Additionally, due to the challenges in imposing constraint within a diffusion model, previous studies relied on problem-specific search process to extract feasible solutions from the diffusion model's generations. Designing these problem-specific search requires specialized knowledge and cannot be easily adapted to different CO problems. In this work, we propose a novel method for training a diffusion model in a self-supervised manner, eliminating the need for costly supervision, problem-specific objectives, or problem-specific search process. We demonstrate our approach on two distinct and challenging CO problems-the parallel machine scheduling problem (PMSP) and the asymmetric travelling salesman problem (ATSP)\u2014which have received less attention (Kwon et al. 2021). Our method not only achieves state-of-the-art performance among deep learning approaches, but also surpasses well-known solvers and heuristic methods on ATSP instances by a significant margin."}, {"title": "2 Related Works", "content": "For widely-studied CO problems like the travelling salesman problem (TSP), several off-the-shelf solvers are available, such as CPLEX (IBM 2022) and OR-tools (Google 2024). These solvers are build on a variety of heuristics, incorporating search methods (Helsgaun 2023), mathematical programming (Arora 1996), and graph algorithms (Christofides 2022). Typically, these approaches rely on problem-specific, handcrafted techniques, which limits their flexibility in adapting to diverse variants encountered in real-world scenarios.\nAuto-regressive methods To overcome this limitation, learning-based solvers have been developed, with early studies primarily focusing on auto-regressive approaches. Bello et al. (2016) were the first to propose solving CO problems using a pointer network trained via reinforcement learning (RL). Kwon et al. (2021) introduced an architecture called MatNet, which builds on the graph attention network (GAT) to encode various types of objects, enabling it to tackle more complex CO problems. While these auto-regressive models offer fast solution generation and can manage intricate CO problems, they are limited by their inability to revise previously made decisions and have been outperformed by methods utilizing diffusion-based methods.\nDiffusion-based methods To the best of our knowledge, two notable works have effectively addressed CO problems using diffusion models, both achieving solution quality comparable to off-the-shelf solvers while significantly reducing generation time. DIFUSCO (Sun and Yang 2023) is a graph neural network (GNN)-based diffusion model trained in a supervised manner to replicate solutions generated by solvers. Similarly, UTSP (Min, Bai, and Gomes 2024) employs a GNN-based diffusion model trained in an unsupervised manner, eliminating the need for costly solution generation from traditional solvers. However, UTSP's objective is based on the concept of the Hamiltonian cycle, limiting its applicability to TSP.\nHowever, these algorithms fall into the category of heatmap-generating approaches. While CO problems typically impose strict constraints on solutions, such as forming a Hamiltonian cycle, these algorithms are not trained to inherently satisfy those constraints. Instead, they rely on additional heatmap search techniques, such as active search methods (Qiu, Sun, and Yang 2022) or Monte Carlo Tree Search (MCTS) (Silver et al. 2016; Fu, Qiu, and Zha 2021), to produce feasible solutions. This reliance limits their applicability to CO problems with varying constraints on solutions."}, {"title": "3 Improving Combinatorial Optimization through Diffusion with Constraints", "content": "To combine the high-quality solutions of diffusion-based methods with the flexibility of auto-regressive approaches, we propose Improving Combinatorial optimization through Diffusion with Constraints (IC/DC). This approach ensures the feasibility of solutions while training diffusion model in a self-supervised manner, eliminating the need for costly supervision and problem-specific search processes."}, {"title": "3.1 Problem Definition", "content": "We consider a family of CO problems C, which involve two distinct sets of items. Each problem c \u2208 C is defined by two sets of items A and B, and matrices that describe the relationships between these two sets of items, as illustrated on the left side of Figure 1. The solution to a CO problem c is represented by a binary matrix $X \\in \\mathcal{X} = \\{0,1\\}^{|A|\\times|B|}$. Typically, for each problem c, there exists a feasible set of solutions, and a particular solution X is evaluated using a problem-specific scoring function $score:\\mathcal{X}\\times\\mathcal{C} \\rightarrow \\mathbb{R}$"}, {"title": "when it is feasible. For clarity, we define the reward function R:$\\mathcal{X}\\times\\mathcal{C}\\rightarrow \\mathbb{R}$ as follows:", "content": "$R(X, c) = \\begin{cases} score(X, c) & \\text{if } X \\text{ is feasible for } c \\\\ -\\infty & \\text{otherwise} \\end{cases}$,\nwhich allows us to express the objective of the CO problem c as $\\max_{X \\in \\mathcal{X}} R(X, c)$."}, {"title": "3.2 Training of IC/DC", "content": "We build upon a discrete diffusion model with categorical corruption processes (Austin et al. 2021). We represent the uncorrupted solution that we aim to generate as $X_0$, with the corrupted latent variables denoted as $X_1, ..., X_T$. We use lowercase $x$ to represent the vectorized forms of $X$, where $x_t = vec(X_t) \\in \\{0,1\\}^{|A||B|}$, and tilded $\\tilde{x}$ to denote the one-hot encoded versions, $\\tilde{x}_t \\in \\{0,1\\}^{|A||B|\\times2}$. In line with diffusion model conventions, we use $q(\\cdot)$ to denote the data distribution/generative forward process, while $p_\\theta(\\cdot)$ represents the denoising reverse process, which is learned to generate the solutions.\nForward process Our forward process is defined as:\n$q(X_t | X_{t-1}) = Cat(\\text{vec}^{-1}(x_{t-1} Q_t))$,\n$q(X_t | X_0) = Cat(\\text{vec}^{-1}(x_0 Q_{1:t}))$,\n$q(X_{t-1} | X_t, X_0) = Cat(\\text{vec}^{-1}(\\frac{x_t Q_t^T x_0 Q_{1:t-1}}{x_0 Q_{1:t} x_t}))$,\nwhere $Q_{1:t} = Q_1 Q_2 ... Q_t$, denotes the element-wise multiplication, and $\\text{vec}^{-1}$ reshapes the input to the shape $|A| \\times |B| \\times 2$. The matrix $Q_t \\in [0, 1]^{2 \\times 2}$ is a noise transition matrix that independently applies noise to each element of the solution matrix. We design this noise transition matrix to align with the prior distribution of feasible solutions $\\bar{q}$ in the limit (Vignac et al. 2022), such that $\\lim_{t \\to \\infty} Q_{1:T} z = \\bar{q}$ for any vector $z$. This is achieved by defining:\n$Q_t = \\alpha_t I + \\beta_t \\mathbf{1} \\bar{q}^T$,\nwhere $\\mathbf{1}$ is vector of ones, and $\\alpha_t$ and $\\beta_t$ are scheduled appropriately with typical diffusion schedulers. The formulas for computing $\\bar{q}$ for the CO problems demonstrated in the experiments are detailed in Appendix B.1.\nReverse process We follow the parametrization of Austin et al. (2021), where neural network $f_\\theta(\\cdot)$ is trained to directly predict logits of $X_0$ from each $X_t$, as follows:\n$p_\\theta(X_0 | X_t, c) = Cat(f_\\theta(X_t, t, c))$,\n$p_\\theta(X_{t-1} | X_t, c) \\propto \\sum_{X_0} q(X_{t-1}, X_t | X_0) p_\\theta(X_0 | X_t, c)$.\nAlthough this parameterization facilitates the easy computation of diffusion loss when a target dataset is provided, samples from $p_\\theta$ may not satisfy the constraints since each element of the solution matrix is independently sampled from a Categorical distribution. This limitation required the use of a feasibility-enforcing search process in previous diffusion-based studies on CO (Sun and Yang 2023; Min, Bai, and Gomes 2024). However, this approach requires a"}, {"title": "search process specifically tailored to each CO problem, and there is no assurance that the search process will preserve the quality of the solution that the diffusion model aims to generate.\nFeasibility-enforced generation", "content": "To ensure the generation of feasible solutions, we design a process inspired by auto-regressive methods, which we call the feasibility-enforced generation process. In this approach, we sample one element of the solution matrix at a time, ensuring its feasibility based on the previously sampled elements, as follows:\n$\\begin{aligned} &p_\\theta(X_0 | X_t, c) \\propto \\prod_{i=1}^{|A||B|} Cat([X_0]_i | [f_\\theta(X_t, t, c)]_i) \\mathbb{I}([X_0]_i), \\\\ &\\mathbb{I}([X_0]_i) = \\begin{cases} 1 & \\text{if } [X_0]_i \\text{ is feasible given } [X_0]_{1:i-1} \\\\ 0 & \\text{otherwise} \\end{cases} \\end{aligned}$\nThis approach, similar to the flexibility of auto-regressive methods, allows for the straightforward enforcement of feasibility in the generated samples. However, $p_\\theta$ cannot be directly utilized as the reverse process because it involves discrete sampling, which prevents the use of the reparameterization trick, thereby making conventional and efficient variational training methods inapplicable. When using $p_\\theta$ as the reverse process, the connection between $p_\\theta$ and $p_\\theta$ becomes weak, leading to a lack of guarantee that samples from $P_\\theta$ will retain the desired characteristics.\nAlternating training To this end, we propose an iterative training approach that alternates between the CLONING step and the IMPROVEMENT step. In the CLONING step, we update the reverse process $p_\\theta$ by maximizing the (lower bound of the) log likelihood of a set of high scoring feasible solutions: the surrogate targets. This guides $p_\\theta$ toward generating high-quality feasible solutions, and strengthen its alignment with $p_\\theta$, as they become identical when $p_\\theta$ generates feasible samples only. In the IMPROVEMENT step, we directly update $p_\\theta$ using reinforcement learning to maximize the scores of generated solutions. These two steps work in tandem, the IMPROVEMENT step is direct but computationally intensive, and CLONING step is more efficient but is only an indirect method of improving samples from $p_\\theta$.\nSurrogate targets In standard diffusion model training, the target distribution $q(X_0 | c)$, which represents the distribution of optimal solutions given a problem c, is typically available. However, in CO problems, obtaining such supervised dataset is often prohibitively expensive. To address this, we propose training our diffusion model in a self-supervised manner using a surrogate target distribution $\\tilde{q}(X_0 | c)$ instead.\nThis surrogate distribution is progressively refined during training and is defined as a reward-weighted mixture of two distributions:\n$\\tilde{q}(X_0 | c) \\propto \\exp(R(X_0, c)) [(1 - \\alpha) q(X_0) + \\alpha p_\\theta(X_0 | c)]$,\nwhere the mixture is controlled by the hyperparameter $\\alpha \\in [0, 1]$. In the initial stage of training, the solutions generated by reverse process $p_\\theta(X_0 | c)$ are not feasible in general."}, {"title": "This leads to using more samples from the prior distribution of feasible solutions $q(X_0)$, and guide the diffusion model to more generate feasible solutions. As training progresses and as $p_\\theta(X_0 | c)$ begins to generate feasible solutions, the reward-weighting allows the diffusion model to refine itself by focusing on its high-scoring, feasible generations. Meanwhile, the inclusion of prior distribution of feasible solutions $q(X_0)$ introduces diversity to the training, counteracting the tendency of $p_\\theta$ to become too narrow as training progresses.\nCLONING step", "content": "With the surrogate target distribution defined above, we perform standard diffusion training by minimizing the KL-divergence between the model's generative distribution and the surrogate target distribution:\n$\\min_\\theta D_{KL}(\\tilde{q}(X_0 | c) || p_\\theta(X_0 | c))$,\nwhich results in a variational bound objective (see Appendix A.2 for detailed derivations), $\\mathcal{L}_{VB}(\\theta) :=\n$\\mathbb{E}_{X_0 \\sim \\tilde{q}(X_0 | c)} \\sum_{t=2}^T D_{KL}(q(X_{t-1} | X_t, X_0) || p_\\theta(X_{t-1} | X_t, c))$\nInspired by recent practices (Austin et al. 2021), we also incorporate the following auxiliary losses:\n$\\mathcal{L}_{prd}(\\theta) := \\mathbb{E}_{X_0 \\sim q(X_0 | c), X_t \\sim q(X_t | X_0)}[-\\log p_\\theta(X_0 | X_t, c)]$,\n$\\mathcal{L}_{cst}(\\theta) := \\mathbb{E}_{X_0 \\sim q(X_0 | c), X_t \\sim q(X_t | X_0)}[C(p_\\theta(X_0 | X_t, c))]$,\nwhere $\\mathcal{L}_{prd}$ encourages accurate predictions of the data $X_0$ at each time step, and $\\mathcal{L}_{cst}$ discourages infeasible predictions, with $C(\\cdot)$ being a differentiable function that approximately measures constraint violations of samples using the Gumbel-softmax trick (see Appendix. A.3 for details on C).\nIn summary, during the CLONING step, we minimize:\n$\\mathcal{L}_{CLN}(\\theta) = \\mathcal{L}_{VB}(\\theta) + \\lambda_1 \\mathcal{L}_{prd}(\\theta) + \\lambda_2 \\mathcal{L}_{cst}(\\theta)$."}, {"title": "(1)\nIMPROVEMENT step", "content": "To directly improve the feasibility-enforced generations, we minimize the following objective:\n$\\mathcal{L}_{IMP}(\\theta) = -\\mathbb{E}_{X_0 \\sim p_\\theta(X_0 | c)}[R(X_0, c)]$.\nSimilar to auto-regressive methods, the feasibility-enforced generation process can be viewed as a sequential decision making task, where each element of the solution matrix $X_0$ is determined step by step. This perspective allows us to compute the gradient of the above objective using the REINFORCE algorithm (Williams 1992).\nAfter sampling a set of solutions $\\{X_0^{(1)}, X_0^{(2)}, ..., X_0^{(N)}\\}$ using $p_\\theta(X_0 | c)$, we approximate the gradient as follows:\n$\\nabla_\\theta \\mathcal{L}_{IMP}(\\theta) \\approx \\frac{1}{N} \\sum_{i=1}^N (R^{(i)} - \\frac{1}{N} \\sum_{j=1}^N R^{(j)}) \\nabla_\\theta \\log p_\\theta(x | c)$,\nwhere $R^{(i)} = R(X_0^{(i)}, c)$. This approach is adapted from the baseline estimation method of POMO (Kwon et al. 2020)."}, {"title": "4 Architecture", "content": "The neural network we need is $f: \\mathcal{X} \\times \\mathcal{C} \\rightarrow \\mathcal{X}$, which encodes the CO problem and outputs a distribution over binary matrices given an input binary matrix. To achieve this, we propose a problem encoder that effectively encodes CO problem, and a denoiser, a specialized variant of GNN that processes the bipartite graph between two sets of items.\nProblem encoder For the CO problems we consider, a problem instance c consists of information about two sets of items and their relationships. For simplicity, let's assume that all items share the same number of features $d$; if not, different embedding layers can be used to standardize the feature dimensions. The information for the items in set A is represented by the matrix $A \\in \\mathbb{R}^{|A| \\times d}$, and similarly, the items in set B are represented by the matrix $B \\in \\mathbb{R}^{|B| \\times d}$. There relationship between these items is captured by the matrix $D \\in \\mathbb{R}^{|A| \\times |B|}$. Together, these matrices define the problem instance, i.e., $c = (A, B, D)$.\nTo effectively encode the problem represented by these matrices, we adopt the dual graph attentional layer structure from MatNet (Kwon et al. 2021), but replace the attention layer with a modified version of graph attention networks (GAT, Veli\u010dkovi\u0107 et al. 2017) that is specifically designed to process a bipartite graph. The problem encoder consists of L layers, where each layer takes (A, B, D) as input and outputs updated features (A', B'). The outputs of the final layer are then passed to the denoiser. The bottom-right side of Figure 2 illustrates this problem encoder. Detailed equations of problem encoder layer are provided in Appendix B.2.\nDenoiser Building on recent empirical successes (Joshi et al. 2020; Qiu, Sun, and Yang 2022), we extend the anisotropic graph neural network (AGNN) to handle bipartite graphs, allowing us to consider two distinct sets of items, and use it as the denoiser. The input embedding layer maps each element of the noisy solution matrix $X_t$ and the timestep t into d-dimensional features. These embeddings are then passed to the AGNN, along with the problem embedding $A'$ and $B'$. After $L'$ layers of AGNN, the embedded solution matrix with updated features is passed through a linear layer to produce the denoised solution matrix $X_0$. The bottom-left side of Figure 2 illustrates this denoiser. Detailed equations of denoiser layer are provided in Appendix B.3."}, {"title": "5 Experiments", "content": "5.1 Demonstrated Problems\nWe begin by describing the combinatorial optimization (CO) problems on which we conducted experiments: the Parallel Machine Scheduling Problem (PMSP) and the Asymmetric Travelling Salesman Problem (ATSP).\nParallel machine scheduling problem In PMSP, a problem instance c consists of |I| jobs and |M| machines. Each job $j \\in I$ must be scheduled on a machine $m \\in M$, with varying workloads for each job and different processing capabilities for each machine. The primary objective in PMSP is to minimize the makespan, which is the total length of the schedule upon the completion of all jobs. In this context, having $[X_0]_{j,m} = 1$ indicates that job j is assigned to machine m, which takes a processing time of $[P]_{j,m}$ where $P \\in \\mathbb{R}^{|I| \\times |M|}$ is a matrix of processing times for all combinations. The goal is to determine the solution matrix $X_0 = \\{0,1\\}^{|I| \\times |M|}$ that minimizes the makespan for a"}, {"title": "given problem $c = (M, J, P)$:", "content": "$score_{PMSP}(X_0, c) = - \\max_m \\sum_j [X_0 P]_{j,m}$\nThe solution matrix that assigns a job to multiple machines is considered infeasible.\nAsymmetric travelling salesman problem An ATSP instance $c = (|N|, D)$ comprises |N| cities and an asymmetric distance matrix $D \\in \\mathbb{R}^{|N| \\times |N|}$ where each element of it specifies the distance between two cities. The solution to ATSP is a tour, which is an adjacency matrix $X_0 = \\{0,1\\}^{|N| \\times |N|}$ for a directed graph visiting all cities once. The goal is find a solution that minimizes the tour length:\n$Score_{ATSP}(X_0, c) = - \\sum_{i,j} [X_0 \\odot D]_{i,j}$\nThe solution matrix that is not a Hamiltonian cycle is considered infeasible. In accordance with Kwon et al. (2021) we employ tmat-class ATSP instances (see Appendix D.1)."}, {"title": "5.2 Main Results", "content": "We evaluated the baselines and the proposed algorithm using two Intel Xeon Gold 6330 CPUs and an RTX 3090 GPU for both PMSP and ATSP. For the evaluation, 1000 problem instances were randomly generated using a standard generation process (see appendix D.1). To fully leverage the stochastic nature of generative learning-based methods, we also evaluated these methods by generating multiple samples $(\\mathbf{x}_n)$ for each problem instance and selecting the one with the best score. For MatNet (Kwon et al. 2021), we followed the authors' implementation, including instance augmentation, which yielded better result. As a problem-specific search process has not been studied on PMSP and ATSP, for diffusion-based methods, we report simple discrete diffusion models, either trained with supervised learning (Sun and Yang 2023) or with reinforcement learning (Black et al. 2023). For further experimental details, please refer to Appendix C and Appendix D.\nPMSP We evaluated our method on PMSP-20 and PMSP-50, where the numbers 20 and 50 correspond to the number of jobs in each instance, with the number of machines fixed at 4. Our approach is compared against various baselines, including (meta-)heuristics, auto-regressive, and diffusion-based methods. Details of these baselines can be found in Appendix C.2.\nAs shown in Table 1, IC/DC achieves the smallest optimality gap among learning-based methods. IC/DC demonstrates a 0.142% performance gap compared to CP-SAT, whereas the previous SOTA, MatNet, shows a 0.615% gap on PMSP-20. On PSMP-50 IC/DC reduces the gap from MaNet's 0.182% to 0.112%. Although IC/DC has a slower inference speed compared to auto-regressive methods, its high-quality solutions remain highly competitive with other baselines.\nATSP We evaluated our method on ATSP-20 and ATSP-50, where the number 20 and 50 correspond to the number of cities. IC/DC generates solutions that not only surpass those generated by SOTA learning-based methods but also outperform those obtained through (meta-)heuristics and off-the-shelf solvers. IC/DC achieves a -0.235% gap on ATSP-20 and a -0.532% gap on ATSP-50, demonstrating a negative gap compared to a powerful CPLEX solver\u2014which no"}, {"title": "other learning-based method has achieved. This substantial improvement positions IC/DC as a new SOTA method for addressing these less-studied CO problems, highlighting its potential.", "content": "5.3 Discussion\nComparison with auto-regressive method As discussed earlier, the performance of auto-regressive models is limited by their sequential decision-making process, which locks in previously made decisions, preventing any revisions. While IC/DC employs a similar auto-regressive approach for feasibility-enforced generation, it also benefits from the accuracy of diffusion-based methods by iteratively refining the solution through T-1 denoising steps before the final auto-regressive generation. Moreover, this two-stage generation process enables IC/DC to achieve much greater sample diversity compared to auto-regressive models, as the denoising process provides varied foundations for solutions before the auto-regressive generation.\nThe results that support these arguments can be found in both tables, particularly in Table 2. While IC/DC's performance lags behind MatNet when using a single generation to solve the problem, its quickly surpasses MatNet as the number of samples increases, highlighting the high diversity of IC/DC's samples. Upon closer examination, we observed that the stochasticity of MatNet primarily stems from the starting point of the auto-regressive generation (i.e., the selection of the initial city to begin the tour). In contrast, IC/DC's denoising process offers diverse backbones for the auto-regressive generation, resulting in varied samples even when starting from the same initial city.\nComparison with diffusion-based method Previously proposed diffusion-based methods (Qiu, Sun, and Yang 2022; Sun and Yang 2023; Min, Bai, and Gomes 2024) have employed problem-specific search processes to enforce feasibility and enhance performance. However, developing such search processes with strong performance and feasibility guarantees typically requires significant expertise in the specific CO problem being addressed. As the complexity of CO problem increases, such as with ATSP or more complex TSP variants compared to TSP, the cost of implementing these search algorithms becomes even greater.\nAs shown in Table 1 and Table 2, simple implementations of diffusion models, whether trained with supervised learning (Sun and Yang 2023) or reinforcement learning (Black et al. 2023), struggle to generate feasible solutions without the aid of problem-specific search processes, which have not been studied for these particular CO problems. This highlights the critical importance of our feasibility-enforced generation process, which integrates the flexibility of auto-regressive methods into diffusion-based methods, allowing for the straightforward imposition of various constraints. In this regard, the proposed IC/DC approach not only demonstrates superior performance compared to previous learning-based methods, but also significantly broadens the applicability of diffusion-based methods to a wide range of less-explored CO problems with diverse constraints."}, {"title": "6 Conclusion", "content": "We propose a diffusion-based approach named IC/DC to tackle the CO problems involving two distinct sets of items. Our algorithm demonstrates superior performance in both PMSP and ATSP, outperforming existing baselines and successfully generating feasible solutions that cannot be easily achieved with simple diffusion-based methods. We emphasize that this is the first study to successfully adapt a diffusion-based method for CO problems involving two distinct sets of items. We believe the proposed IC/DC framework has significant potential for generlizability. For example, in Appendix D.4, we demonstrate its capability to address real-world CO problems with sophisticated item and relationship features.\nDespite its strong performance, IC/DC has a notable limitation: the GAT-based encoder we use requires O(max(|A|, |B|)2) memory complexity. This demands substantial memory resources when training on large instances. To address these challenges, we plan to explore memory-efficient techniques in future work, such as those introduced by Zhu et al. (2024)."}]}