{"title": "ORCDF: An Oversmoothing-Resistant Cognitive Diagnosis Framework for Student Learning in Online Education Systems", "authors": ["Hong Qian", "Shuo Liu", "Mingjia Li", "Bingdong Li", "Zhi Liu", "Aimin Zhou"], "abstract": "Cognitive diagnosis models (CDMs) are designed to learn students' mastery levels using their response logs. CDMs play a fundamental role in online education systems since they significantly influence downstream applications such as teachers' guidance and computerized adaptive testing. Despite the success achieved by existing CDMs, we find that they suffer from a thorny issue that the learned students' mastery levels are too similar. This issue, which we refer to as oversmoothing, could diminish the CDMs' effectiveness in downstream tasks. CDMs comprise two core parts: learning students' mastery levels and assessing mastery levels by fitting the response logs. This paper contends that the oversmoothing issue arises from that existing CDMs seldom utilize response signals on exercises in the learning part but only use them as labels in the assessing part. To this end, this paper proposes an oversmoothing-resistant cognitive diagnosis framework (ORCDF) to enhance existing CDMs by utilizing response signals in the learning part. Specifically, ORCDF introduces a novel response graph to inherently incorporate response signals as types of edges. Then, ORCDF designs a tailored response-aware graph convolution network (RGC) that effectively captures the crucial response signals within the response graph. Via ORCDF, existing CDMs are enhanced by replacing the input embeddings with the outcome of RGC, allowing for the consideration of response signals on exercises in the learning part. Extensive experiments on real-world datasets show that ORCDF not only helps existing CDMs alleviate the oversmoothing issue but also significantly enhances the models' prediction and interpretability performance. Moreover, the effectiveness of ORCDF is validated in the downstream task of computerized adaptive testing.", "sections": [{"title": "1 INTRODUCTION", "content": "Cognitive diagnosis (CD) [19] serves as the foundational element in online intelligent education systems. It exerts an upstream and fundamental influence on subsequent modules such as computer adaptive testing [42], course recommendation [10, 35] and learning path suggestions [25, 26], among others. Specifically, as illustrated in Figure 1, CD aims to learn students' underlying mastery levels (Mas) by analyzing their historical response logs, thereby providing insights into various attributes of exercises, such as difficulty level (Diff) and discrimination (Disc). In recent years, an array of cognitive diagnosis models (CDMs) have emerged, prominently featuring frameworks such as item response theory (IRT) [8] and the neural cognitive diagnosis model (NCDM) [30]. The two core parts of CDM include learning students' Mas and assessing the learned Mas by fitting the response logs. The function used in the latter part is often referred to as the interaction function (IF). IRT utilizes a latent factor to represent Mas and adopts the logistic function as IF. In contrast, NCDM replaces the traditional IFs with multi-layer perceptrons (MLP) and uses concept-specific vectors (i.e., set the embedding dimension being equal to the number of concepts) to characterize Mas. As embedding-based methods rapidly evolve and gain prominence, there is an increasing trend of representing both students and exercises in a vectorized form, and they are gradually refined by using a variety of advanced techniques [6, 12, 15, 21, 23, 31].\nDespite the success, this paper, for the first time, identifies that existing CDMs share a potential and thorny issue that the learned Mas of students are too similar. We refer to this issue as oversmoothing. Oversmoothing could diminish the CDMs' effectiveness in down-stream tasks. To support the motivation of this paper and reveal the oversmoothing issue, we conduct a pilot study on four real-world datasets collected from the online education systems, ensuring a diverse range of circumstances in the students' response logs. To characterize the degree of oversmoothing, inspired by [14], the mean normalized difference (MND) is proposed to measure the Mas learned by CDMs. Intuitively, the larger the MND value, the bigger the difference among students' Mas that learned by CDMs. Details of MND are elaborated in Section 5.1. As shown in Figure 2, although CDMs such as NCDM [30], CDMFKC [15], KSCD [21] and KaNCD [31] achieve commendable prediction performance, the MND values of Mas they have learned are quite small and hard to distinguish. Since CD is an upstream task, addressing this issue is urgent. For instance, if teachers rely on the outcomes of CD to assist student development, exceedingly subtle distinctions could lead to confusion. Intuitively, if MND is 0.005, it implies that the average difference in Mas for two students in a class on certain concepts is merely 0.005 (e.g., 0.51 and 0.515). Such a small margin could potentially bring difficulty to teachers to accurately assess the cognitive state of entire class. This not only fails to aid students but could also result in misguided instruction. Moreover, for downstream algorithms, a diagnosis result plagued by oversmoothing may lead to erroneous recommendations of learning materials, causing irreversible impacts on students.\nOne straightforward approach is to design a regularization term aimed at amplifying the differences between students. However, achieving a balance between the weight of this regularization term and the binary cross-entropy (BCE) loss during training is challenging. Besides, although this direct approach may help in mitigating the oversmoothing issue, it could compromise the model's prediction performance, since it forcefully amplifies the differences among all students and adversely affects the learning of students' Mas who should, in principle, be closely aligned. In this paper, we contend that the oversmoothing issue arises because existing CDMs seldom utilize response signals in the learning part but only use them as labels in the assessing part. For instance, students with right response on exercises with high difficulty levels should attain higher Mas on corresponding concepts in the learning part. Cooperating response signals in both learning and assessing parts of CDMs can widen the gap among students' Mas as they reserve the unique feature in students' response logs.\nTo this end, this paper proposes an oversmoothing-resistant cognitive diagnosis framework (ORCDF) to enhance existing CDMs by utilizing response signals in the learning part. Specifically, ORCDF introduces a novel response graph, which utilizes response logs and a Q-matrix, inherently incorporating response signals as types of edges. Then, ORCDF designs a tailored response-aware graph convolution network (RGC) that effectively captures the crucial response signals within the response graph. We reveal that by utilizing the multiple layers of RGC, we achieve a multi-perspective analysis of student mastery. This is accomplished by combining the outcomes from multiple layers of RGC, leading to a more comprehensive understanding of student learning. Via ORCDF, existing CDMs are enhanced by replacing the input embeddings with the outcome of RGC through the transformation layer, allowing for the consideration of response signals on exercises in the learning part. Nevertheless, ORCDF encounters a new challenge: overemphasizing the role of response signals can exacerbate the guess and slip problem. This problem occurs when students guess in order to answer correctly or make mistakes on exercises they actually master, and could potentially lead models to make unreasonable inference of students' Mas. Different from previous methods that introduce extra parameters for guess and slip probabilities [16], this paper addresses the guess and slip problem in student-exercise interactions by considering them as noise edges in the response graph. Specifically, we flip the student-exercise edge in the response"}, {"title": "2 RELATED WORK", "content": "Cognitive Diagnosis Models. CDMs involve various approaches, such as latent factor models like IRT and MIRT (multidimensional IRT), or concept mastery pattern models like the deterministic input, noisy and gate (DINA) model, to infer students' mastery levels. DINA, a classic CDM, employs binary variables to represent mastery levels where 0 means unmastered and 1 means mastered. However, recent advances in deep learning have led to significant improvements in handling large-scale interactions. Notably, NCDM uses MLP as its IF, treating mastery patterns as continuous variables ranging from 0 to 1. This evolution in approach has been paralleled by diverse methods in analyzing response logs, including MLP based [13, 15, 21], graph attention networks [28] and Bayesian networks [12, 33], each contributing to a more nuanced understanding of student learning patterns. However, as depicted in Figure 2, these advanced CDMs encounter the oversmoothing issue which could potentially hinder the application of CD in downstream tasks of intelligent education, affecting their performance and consequently impacting student learning. To the best of our knowledge, the oversmoothing issue in the field of CD remains unexplored.\nOversmoothing Issue. The oversmoothing issue [14] is a significant problem in graph representation learning (GRL). Many studies have shown that the layers of graph neural network (GNN) deepen, the representations of graph nodes become increasingly smooth, leading to a substantial decrease in accuracy. This has prompted numerous researchers to employ a variety of methods [22] to address this issue, enabling deeper GNN architectures. The same phenomenon is also observed in various fields where graphs are used for data mining. For example, in recommendation systems, graph collaborative filtering (GCF) [34] faces the oversmoothing problem, which arises for the same reasons as in GRL due to the stacking of GNN layers. However, in the context of CD, oversmoothing is not a result of stacking GNN layers, since most CDMs like NCDM, CDM-FKC, KSCD and KaNCD do not utilize GNN. Yet, this issue does exist and is urgent, as shown in Figure 2. Thus, existing solutions to addressing oversmoothing in GRL and GCF are not suitable to resolve the oversmoothing issue in CD."}, {"title": "3 PRELIMINARIES", "content": "This section first introduces the fundamental elements of CD and then introduces the formal problem definition of CD and oversmoothing issue in CDMs. We also give abbreviations for terms in Table 5 at the beginning of the Appendix.\nCognitive Diagnosis Basis. Consider an education scenario which contains three sets: $S = \\{s_1,..., s_N\\}$, $E = \\{e_1, ..., e_M\\}$, and $C = \\{c_1,..., c_Z\\}$. They symbolize students, exercises and knowledge concepts, with respective sizes of N, M and Z. Q represents the relationship between exercises and knowledge concepts, which can be regarded as a binary matrix $Q = (Q_{iz})_{M\\times Z}$, where $Q_{iz} \\in \\{0,1\\}$ means whether $e_i$ relates to $c_z$ or not. Students from set S, driven by unique interests and requirements, select exercises from E. The results are documented as response logs. Specifically, these logs can be illustrated as triplets $T = \\{(s, e, r) | s \\in S, e \\in E, r_{se} \\in \\{0, 1\\}\\}$. $r_{se} = 1$ represents correct and $r_{se} = 0$ represents wrong. In this paper, we treat response logs as interaction matrix $I \\in \\mathbb{R}^{N\\times M}$. It contains three categorical values (1 means right, 0 means no interaction and -1 means wrong). Finally, we give the formal definition of the CD task and oversmoothing issue in CDMs.\nDefinition 3.1 (Problem Definition). Given interaction matrix $I\\in \\mathbb{R}^{N\\times M}$, a binary matrix $Q \\in \\mathbb{R}^{M\\times Z}$, the goal of cognitive diagnosis is to infer $Mas \\in \\mathbb{R}^{N\\times Z}$, which denotes the latent mastery level of students on each concept.\nDefinition 3.2 (Oversmoothing in CDMs). Given the learned $Mas \\in \\mathbb{R}^{N\\times Z}$ by CDMs, if the difference in students' Mas is sufficiently small, it indicates the presence of oversmoothing issue in CDMs.\nIn this paper, we utilize the mean normalized difference proposed in Section 5.1 to quantify the degree of oversmoothing."}, {"title": "4 METHODOLOGY: THE PROPOSED ORCDF", "content": "This section introduces the proposed ORCDF. It starts by introducing the proposed novel response graph, then explores the response-aware graph convolution (RGC), a technique designed to capture the rich information embedded in the response graph. Following this, we introduce a consistency regularization loss function. We also discuss the model training and analyze model complexity. An overview of ORCDF is shown in Figure 3.\nResponse Graph. As illustrated in Figure 4(a), focusing on responses, the response graph (ResG), denoted as $G = (V, E)$, comprises three types of nodes and edges. $V = S \\cup E \\cup C$ involves students, exercises, and concepts, $E$ involves interactions between $S$ and $E$ (i.e., \"Right\"), $S$ and $E$ (i.e., \"Wrong\"), $E$ and $C$ (i.e., \"Related\"). Notably, we incorporate the response signal on exercises as the edge types between students' nodes and exercises' nodes. Next, we will introduce how to capture the fruitful response signal information."}, {"title": "4.1 Response-aware Graph Convolution", "content": "Construct Embeddings. In CD, the primary data elements are response logs and the Q. It is crucial to deconstruct these complex logs into their fundamental components: students, exercises, and concepts. We encode them with trainable embeddings $H_s \\in \\mathbb{R}^{N\\times d}$, $H_e \\in \\mathbb{R}^{M\\times d}$, $H_c \\in \\mathbb{R}^{Z\\times d}$. For instance, $h_{s_i} \\in \\mathbb{R}^{1\\times d}$ denotes the row vector of the i-th student. To facilitate subsequent convolution processes, we stack the aforementioned embeddings to form $H^{(0)} \\in \\mathbb{R}^{(N+M+Z)\\times d}$.\nRight-Wrong Decomposition. In the ResG, there are two types of response signals existing between student nodes and exercise nodes, as shown in Figure 4(a). To better explore the impact of different response signals on learning Mas, we intuitively decompose the response graph into a right subgraph and a wrong subgraph. From the perspective of adjacency matrix, this involves splitting the interaction matrix I into $I^{right}$ (1 represents right, 0 represents others) and $I^{wrong}$ (1 represents wrong, 0 represents others). For brevity, in the following sections, we will denote \u201cR\u201d for right and \u201cW\u201d for wrong. Then we construct the right and wrong subgraphs (i.e, $A_R$, $A_W$ as expressed by Eq. (1):\n$A_R = \\begin{pmatrix}\n0 & I_R & 0\\\\\nI_R^T & 0 & Q\\\\\n0 & Q^T & 0\n\\end{pmatrix}$   $A_W = \\begin{pmatrix}\n0 & I_W & 0\\\\\nI_W^T & 0 & Q\\\\\n0 & Q^T & 0\n\\end{pmatrix}$                                                            (1)\nIn the ResG, the neighbors of a specific exercise node may include students who either answer the exercise right or wrong. However, after disentangling such response signals in the ResG, in each subgraph, the neighbors of a particular exercise node will only consist of students who displayed the same response signals. For example, if both $s_1$ and $s_2$ are connected to $e_1$, indicating that they both answer $e_1$ correctly, there may be some shared information explaining why they both got it right. Such crucial response signals will be propagated during the message-passing mechanism by GCN. This process enables a deeper understanding of the nuances in student responses. In the following part, we will introduce a novel graph convolution approach tailored to capture the information from the two disentangled subgraphs in CD.\nEmbedding Propagation. Considering that in CD, the features of students, exercises, and knowledge concepts are quite simple, consisting only of IDs, we draw inspiration from [7]. As a result, we eliminate linear transformations and nonlinear activation functions, opting to use only the fundamental components of GCN. Hence, the graph embedding propagation layer is designed with the following matrix form\n$H^{(l)} = A \\hat{D}^{-1}H^{(l-1)}, A = (\\hat{D}^{-\\frac{1}{2}}\\hat{A}\\hat{D}^{-\\frac{1}{2}}),$             (2)\nwhere A can be $A_R$ or $A_W$. The degree matrix D is a diagonal matrix with size $(N+M+Z)\\times(N+M+Z)$, where each entry $D_{ii}$ representing the number of non-zero entries in the i-th row vector of the matrix A. Using Eq. (2), we can obtain the convolution outcomes from the l-th layer of the disentangled subgraphs, specifically $H_R^{(l)}$ and $H_W^{(l)}$. However, right and wrong represent completely opposite response signals, it may be inappropriate to directly plus the results obtained from convolutions performed on the two subgraphs. A sophisticated function capable of aggregating these two types of information is necessary, as the interaction mechanisms between students and exercises are quite intricate. It can be expressed as\n$H_F^{(l)} = \\phi(H_R^{(l)}W_{rc} + H_W^{(l)}W_{wc}),$                 (3)\nwhere $H_F^{(l)}$ denotes the final representation of the l-th RGC layer and $\\phi$ denotes arbitrary nonlinear activate function. $W_{rc}, W_{wc} \\in \\mathbb{R}^{d\\times d}$ are trainable parameters. Intuitively, $H_R^{(l)}W_{rc}$ denotes the right channel which obtain the semantic information from right signal. Conversely, $H_W^{(l)}W_{wc}$ represents the opposite. The ultimate embedding $H_F$ is calculated using a mean pooling operation on the outcomes from each layer of the RGC which can be expressed as\n$H = \\frac{1}{1+L} (H^{(0)} + H_F^{(1)} + ... + H_F^{(L)}).$                    (4)\nDiscussion. Here, we explain why RGC can alleviate the oversmoothing issue in existing CDMs. Notably, since our goal is to alleviate the oversmoothing issue in CDMs, and given that shallow layers of RGC already achieve satisfactory experimental results, the"}, {"title": "4.2 Consistency Regularization Loss", "content": "After the graph convolution by multiple RGC layers, we can get the final representation H via Eq. (4). However, as we disentangle the response signal and capture student differences from various perspectives, it may exacerbate the notorious impact of the guess and slip problem on CDMs [16, 36]. Previous methods, as referenced in [4], model the guess and slip probabilities for each exercise as fixed parameters. Evidently, this approach is somewhat brute-force and might overlook the individual impact of students. This is because the probability of guessing or slipping is likely to vary for each person across different exercises. Contrary to the aforementioned methods, in this paper, we treat guess and slip as noise edges within the ResG. Specifically, we flip the student-exercise edge type (i.e., from R to W or W to R) with a probability $p_f$ in the ResG. This noised version of the ResG, where some edges are flipped, is referred to as the flipped ResG, as illustrated in the left part of Figure 3. We aim for the representations derived from the original ResG and the flipped ResG to be similar, in order to ensure that the CDMs remain effective even when subject to the disturbances caused by guess and slip problem. It can be formulated as\n$L_{reg} = -\\sum_{s_i \\in S} log(\\frac{exp(h_i^T\\hat{h}_i)}{\\sum_{s_a \\in S}exp(h_i^Th_{a})}),$    (7)\nwhere $\\hat{h}_i$ is the representation derived from flipped ResG, and $h_ih_a$ denotes the similarity score the representation derived from the ResG and flipped ResG. $\\tau$ is the hyperparameter which controls the degree of smoothness utilized in various methods [38-40]."}, {"title": "4.3 Model Training", "content": "Given input embeddings, existing CDMs predict the performance of students practicing exercises, which can be formulated as\n$\\hat{y}_{ij} = M_{CD}(H_{s_i}, H_{e_j}, H_c),$                   (8)\nwhere $M_{CD}()$ denotes the CDMs, and H represents the input embedding that contains the representation of the student, exercises and concepts.\nTransformation Layer. To facilitate the integration of ORCDF with the majority of existing CDMs, we need to transform dimensions to suit the specific type of CDM in use. If the embedding size of CDMs is a latent dimension (e.g., KaNCD), we directly utilize H as the input embedding for incorporated CDMs. Otherwise (e.g., NCDM), we introduce a transformation layer which can be formulated as\n$H_t = HW_t + b_t,$               (9)\nwhere $H_t$ will be employed as input embedding for incorporated CDMs and $W_t \\in \\mathbb{R}^{d\\times Z}, b_t \\in \\mathbb{R}^{(N+M+Z)\\times 1}$ are trainable parameters. As a result, unlike the previous RCD which sets d = Z, we can choose d as a latent dimension (e.g., 64). This significantly reduces the time complexity of graph convolution, a point that will be further analyzed in the subsequent subsection.\nJoint Training. The primary loss employed in CD task is to calculate the BCE loss between the model's predictions and the true response scores in a mini-batch. The aforementioned consistency regularization loss is incorporated jointly optimized with the CD task. The overall loss can be expressed as\n$L_{BCE} = -\\sum_{(s,e,r_{se}) \\in T} [r_{se} log \\hat{y}_{se} + (1 - r_{se}) log(1 \u2013 \\hat{y}_{se})],$                                 (10)\n$L = L_{BCE} + \\lambda_{reg} L_{reg}.$                      (11)\n$\\lambda_{reg}$ is a hyperparameter that governs the relative importance of the consistency regularization loss."}, {"title": "4.4 Model Complexity Analysis", "content": "Theoretically, we reveal that the graph convolution in ORCDF takes $O(4|E|Ld)$ time complexity. L denotes the number of RGC layers, and d denotes the dimension of embeddings. By leveraging the lightweight backbone and the transformation, our method is significantly lower in time complexity compared with the recent GNN-based approach RCD [6]. Specifically, RCD has the complexity of $O(2|E|LZ^2)$, where Z represents the number of concepts (d < Z). It suggests that ORCDF is more suitable for current online education scenario on ground of the increasing granularity of knowledge concepts. Indeed, ORCDF showcases a notable speed advantage, being up to 18 times faster than RCD on the Assist17 dataset (i.e., Z = 102). This dataset is collected from ASSISTment online tutoring systems and extensively utilized CDMs [12]. This improvement comes along with enhanced performance and lower GPU memory usage. For detailed information, please refer to Appendix A."}, {"title": "5 EXPERIMENTS", "content": "In this section, we first describe four real-world datasets and evaluation metrics. Then, through extensive experiments, we aim to verify the superiority of ORCDF, which not only assists existing CDMs in mitigating the oversmoothing issue but also enhances the models' prediction performance and interpretability performance. To ensure the reliability and reproducibility of our experiments, they are independently repeated ten times with different seeds and our code is available at https://github.com/lswhim/ORCDF."}, {"title": "5.1 Experimental Settings", "content": "Datasets Description. The experiments are conducted using four real-world datasets: Assist17, EdNet-1, Junyi, and XES3G5M. The Assist17 dataset is provided by the ASSISTment web-based online tutoring systems [5] and are widely used for cognitive diagnosis tasks [30]. EdNet-1 [3] is the dataset of all student-system interaction collected over 2 years by Santa, a multi-platform Al web-based tutoring service with more than 780K users in Korea. Junyi [2] is an online math practice log dataset offered by Junyi Academy. XES3G5M [20] is a knowledge tracing benchmark dataset with auxiliary information. For more detailed statistics on these four datasets, please cf. Table 1. Notably, \u201cSparsity\u201d refers to the sparsity of the dataset, which is calculated as $\\frac{|T|}{(|S||E|)}$. \"Average Correct Rate\" represents the average score of students on exercises, and \"Q Density\" indicates the average number of concepts per exercise.\nEvaluation Metrics. To assess the efficacy of ORCDF, we utilize both score prediction, interpretability and oversmoothing metrics."}, {"title": "5.2 Student Performance Prediction", "content": "To showcase the effectiveness of ORCDF, we integrate it with various CDMs, as described in the subsequent part.\n\u2022 IRT [8] is a classic model of latent factor CDMs, which uses one dimension $\\theta$ to model Mas and utilize logistic function as IF to predict the student score performance.\n\u2022 MIRT [27] is a representative model of latent factor CDM, which uses multidimensional $\\Theta$ to model Mas.\n\u2022 NCDM [30] is the first recent deep-learning based CDM which utilizes MLP to replace the traditional manually designed IFs."}, {"title": "5.3 Ablation Study", "content": "In this subsection, we scrutinize and evaluate each key individual component of ORCDF to comprehend their respective impacts and significance on the overall performance of the model. The ablation analysis is conducted using the following three versions.\n\u2022 OR-w/o-rgc: This ablation of ORCDF does not integrate the response-aware graph convolution. Instead, it directly perform convolution on the entire response graph without decomposition.\n\u2022 OR-w/o-reg: This ablation of ORCDF does not utilize the proposed consistency regularization loss $L_{reg}$.\n\u2022 OL: It represents the base CDMs, which can be considered as the one without the inclusion of response-aware graph convolution and consistency regularization loss.\nDue to space constraints, we only present the ablation study using OR-NCDM as an example. This choice is motivated by the fact that NCDM is often employed as a classic CDM in downstream tasks. It is worth noting that the results from incorporating other CDMs are generally similar.\nExperimental Results. As indicated in Table 3, the proposed method outperforms the other two versions, suggesting that each component plays a significant role in enhancing the model's overall effectiveness. OR-w/o-rgc performs significantly worse, further validating the superiority of the proposed RGC in capturing the information within the response graph. We empirically find that although the consistency regularization loss is designed to alleviate the guess and slip problem, it not only improves the prediction and interpretability performance but also achieves a higher MND than the original version. This indicates that the guess and slip problem indeed exists in real-world scenarios, and addressing this problem is crucial for the effectiveness of CDMs."}, {"title": "5.4 In-Depth Analysis of ORCDF's Advantages", "content": "In this subsection, we analyze the proposed ORCDF from two perspectives: generalization performance and robustness performance.\nGeneralization Performance. To assess the efficacy of ORCDF in addressing the generalization issue, we conduct experiments on three datasets with varying test ratios $p_t = \\{10\\%, 20\\%, 30\\%, 40\\%, 50\\%\\}$. As $p_t$ increases which is consistent with [6], the generalization ability of CDMs is tested more stringently. As depicted in Figure 6 of Appendix B, with an increasing test ratio $p_t$, the number of response logs used for training decreases. However, OR-NCDM consistently outperforms NCDM, illustrating that ORCDF can provide more accurate diagnosis results with fewer student response records. This"}, {"title": "5.5 Validation on the Downstream Task", "content": "As an upstream task in the field of intelligent education, CD is applied in various downstream tasks. To validate the effectiveness of ORCDF, we chose to test it in the context of computerized adaptive testing (CAT) [42, 43]. Specifically, we integrate the commonly employed IRT and NCDM with our ORCDF, denoting these as OR-IRT and OR-NCDM, respectively. Our experimental settings align with recent research [43], which adopts a 7:2:1 split for students in the response logs of each dataset. Details can be found in Appendix C.\nAs illustrated in Table 4, OR-NCDM performs better than OR-IRT, which validates the superiority of deep learning-based methods in CAT which is consistent with [42, 43]. OR-IRT and OR-NCDM significantly outperform their original versions. This validates the effectiveness of ORCDF in downstream tasks."}, {"title": "5.6 Hyperparameter Analysis", "content": "Effect of L. As shown in Figure 10 in Appendix D, a larger L decreases the model's training speed, while a smaller L results in poor performance. The recommended values of L are 3 or 4, which can yield relatively good performance. Notably, as L increases, the MND does not continually decrease, a phenomenon that seems different from what is observed in graph representation learning. We contend this could be related to the heterogeneity of the response graph and the complexity of student interactions, which we leave for future work.\nThe Effect of $p_f$. As depicted in Figure 11 in Appendix D, OR-NCDM is influenced by the flip ratio parameter. A too high flip ratio introduces more noise, deteriorating the model's performance. Typically, a $p_f$ =0.15 yields better prediction performance, aligning with the established fact that everyone has a probability of guessing correctly or slipping, neither too high nor too low.\nThe Effect of $\\lambda_{reg}$. As illustrated in Figure 12 in Appendix D, this parameter controls the impact of guess and slip on model training, which varies across different datasets and requires tuning. It is observable that as the number of response logs in the dataset gradually increases, the optimal parameter value decreases. We recommend setting it to 1e-3.\nThe Effect of $\\tau$. As illustrated in Figure 13 in Appendix D, the temperature parameter $\\tau$ affects the similarity between representations learned from the response graph and those from the flipped response graph. As the size of the dataset gradually increases, the better temperature value also gradually increases. Here, we recommend choosing 0.5 when the number of students is small and opting for 3.0 when there is a larger student population."}, {"title": "6 CONCLUSION", "content": "This paper proposes an oversmoothing-resistant cognitive diagnosis framework (ORCDF), where most existing CDMs can be integrated and thus enhanced. We, for the first time, identify the oversmoothing in CD and then address it by learning students' Mas from multiple perspectives, utilizing the proposed response graph and response-aware graph convolution network. Besides, we reformulate the guess and slip problem as noise edges in the response graph and deign a loss function to alleviate the problem. As long as the oversmoothing is addressed in CD, it greatly helps provide distinctive and personalized diagnostic results for students and teachers. However, ORCDF, while effective, is still not sufficiently interpretable enough in the field of intelligent education. More interpretable methods are expected to be developed to mitigate the oversmoothing issue explicably in cognitive diagnosis."}, {"title": "ACKNOWLEDGMENTS", "content": "We would like to thank the anonymous reviewers for their constructive comments. We also would like to thank Xinyue Ma for the reliable help. The algorithms and datasets in the paper do not involve any ethical issue. This work is supported by the National Natural Science Foundation of China (No. 62106076), National Social Science Fund of China (No. BEA230071), and Science and Technology Commission of Shanghai Municipality Grant (No. 22511105901)."}, {"title": "APPENDIX", "content": "The appendix is organized as follows:\n\u2022 Appendix A analyzes the ORCDF's time complexity and compares it with other frameworks.\n\u2022 Appendix B presents the detailed settings of compared baselines and other details about student performance perdition.\n\u2022 Appendix C presents the detailed settings of the downstream tasks, namely, computerized adaptive testing.\n\u2022 Appendix D further supplements the analysis with additional details regarding the hyperparameter analysis.\nNotably, our code is available at https://github.com/lswhim/ORCDF."}, {"title": "A TIME COMPLEXITY ANALYSIS", "content": "In this section, we present a detailed time complexity analysis of our proposed model OR-NCDM. We compare our time complexity with that of RCD, as RCD is the only CDM based on GNN.\nTime Complexity Analysis of ORCDF. We take OR-NCDM as an exmaple. In OR-NCDM, we construct a response graph (ResG) $G$ with three node and edge types based on I and Q. Given that we do not employ the non-linear activation and feature transformation usually found in GNNs, the time complexity can be straightforwardly computed as $O(2|E|Ld)$ for RGC, where L denotes the number of RGC' layers. d stands for the size of the embeddings. Due to the need for computing representations through the flipped ResG, the total time complexity amounts to $O(4|E|Ld)$.\nTime Complexity Analysis of RCD. In RCD, it construct three relation maps. Namely, an exercise-concept graph is constructed using Q and a student-exercise graph is formed using I. Given that RCD employs the graph attention network, which necessitates the computation of attention coefficients between every pair of connected nodes, its time complexity belongs to $O(2|E|LZ^2)$. Herein, Z represents the number of concepts (d < Z).\nOR-NCDM evidently takes less time compared to RCD due to two main reasons. Firstly, due to the transformation layer reduces the embedding dimension to d, where d is much smaller than Z. Secondly, by removing complex operations like linear transformations in GNN, the graph convolution of RGC's computation become much faster than the GAT used in RCD.\nIn the experiment, we incorporate NCDM into all frameworks and use the speed of NCDM as the baseline, set at 1.0x. As shown in the figure, our proposed ORCDF is 18 times faster than RCD and offers better prediction performance. When the number of knowledge concepts continuously increases, RCD tends to train too slowly and runs into out-of-memory issues, especially with large sets of knowledge concepts. In contrast, ORCDF maintains good performance, as demonstrated in scenarios like XES3G5M with 832"}, {"title": "B EXPERIMENTAL DETAILS", "content": "Interpretability Metric. DOA is defined as Eq. (13)\n$DOAK = \\frac{\\sum_{a"}, {"title": "ORCDF: An Oversmoothing-Resistant Cognitive Diagnosis Framework for Student Learning in Online Education Systems", "authors": ["Hong Qian", "Shuo Liu", "Mingjia Li", "Bingdong Li", "Zhi Liu", "Aimin Zhou"], "abstract": "Cognitive diagnosis models (CDMs) are designed to learn students' mastery levels using their response logs. CDMs play a fundamental role in online education systems since they significantly influence downstream applications such as teachers' guidance and computerized adaptive testing. Despite the success achieved by existing CDMs, we find that they suffer from a thorny issue that the learned students' mastery levels are too similar. This issue, which we refer to as oversmoothing, could diminish the CDMs' effectiveness in downstream tasks. CDMs comprise two core parts: learning students' mastery levels and assessing mastery levels by fitting the response logs. This paper contends that the oversmoothing issue arises from that existing CDMs seldom utilize response signals on exercises in the learning part but only use them as labels in the assessing part. To this end, this paper proposes an oversmoothing-resistant cognitive diagnosis framework (ORCDF) to enhance existing CDMs by utilizing response signals in the learning part. Specifically, ORCDF introduces a novel response graph to inherently incorporate response signals as types of edges. Then, ORCDF designs a tailored response-aware graph convolution network (RGC) that effectively captures the crucial response signals within the response graph. Via ORCDF, existing CDMs are enhanced by replacing the input embeddings with the outcome of RGC, allowing for the consideration of response signals on exercises in the learning part. Extensive experiments on real-world datasets show that ORCDF not only helps existing CDMs alleviate the oversmoothing issue but also significantly enhances the models' prediction and interpretability performance. Moreover, the effectiveness of ORCDF is validated in the downstream task of computerized adaptive testing.", "sections": [{"title": "1 INTRODUCTION", "content": "Cognitive diagnosis (CD) [19] serves as the foundational element in online intelligent education systems. It exerts an upstream and fundamental influence on subsequent modules such as computer adaptive testing [42], course recommendation [10, 35] and learning path suggestions [25, 26], among others. Specifically, as illustrated in Figure 1, CD aims to learn students' underlying mastery levels (Mas) by analyzing their historical response logs, thereby providing insights into various attributes of exercises, such as difficulty level (Diff) and discrimination (Disc). In recent years, an array of cognitive diagnosis models (CDMs) have emerged, prominently featuring frameworks such as item response theory (IRT) [8] and the neural cognitive diagnosis model (NCDM) [30]. The two core parts of CDM include learning students' Mas and assessing the learned Mas by fitting the response logs. The function used in the latter part is often referred to as the interaction function (IF). IRT utilizes a latent factor to represent Mas and adopts the logistic function as IF. In contrast, NCDM replaces the traditional IFs with multi-layer perceptrons (MLP) and uses concept-specific vectors (i.e., set the embedding dimension being equal to the number of concepts) to characterize Mas. As embedding-based methods rapidly evolve and gain prominence, there is an increasing trend of representing both students and exercises in a vectorized form, and they are gradually refined by using a variety of advanced techniques [6, 12, 15, 21, 23, 31].\nDespite the success, this paper, for the first time, identifies that existing CDMs share a potential and thorny issue that the learned Mas of students are too similar. We refer to this issue as oversmoothing. Oversmoothing could diminish the CDMs' effectiveness in down-stream tasks. To support the motivation of this paper and reveal the oversmoothing issue, we conduct a pilot study on four real-world datasets collected from the online education systems, ensuring a diverse range of circumstances in the students' response logs. To characterize the degree of oversmoothing, inspired by [14], the mean normalized difference (MND) is proposed to measure the Mas learned by CDMs. Intuitively, the larger the MND value, the bigger the difference among students' Mas that learned by CDMs. Details of MND are elaborated in Section 5.1. As shown in Figure 2, although CDMs such as NCDM [30], CDMFKC [15], KSCD [21] and KaNCD [31] achieve commendable prediction performance, the MND values of Mas they have learned are quite small and hard to distinguish. Since CD is an upstream task, addressing this issue is urgent. For instance, if teachers rely on the outcomes of CD to assist student development, exceedingly subtle distinctions could lead to confusion. Intuitively, if MND is 0.005, it implies that the average difference in Mas for two students in a class on certain concepts is merely 0.005 (e.g., 0.51 and 0.515). Such a small margin could potentially bring difficulty to teachers to accurately assess the cognitive state of entire class. This not only fails to aid students but could also result in misguided instruction. Moreover, for downstream algorithms, a diagnosis result plagued by oversmoothing may lead to erroneous recommendations of learning materials, causing irreversible impacts on students.\nOne straightforward approach is to design a regularization term aimed at amplifying the differences between students. However, achieving a balance between the weight of this regularization term and the binary cross-entropy (BCE) loss during training is challenging. Besides, although this direct approach may help in mitigating the oversmoothing issue, it could compromise the model's prediction performance, since it forcefully amplifies the differences among all students and adversely affects the learning of students' Mas who should, in principle, be closely aligned. In this paper, we contend that the oversmoothing issue arises because existing CDMs seldom utilize response signals in the learning part but only use them as labels in the assessing part. For instance, students with right response on exercises with high difficulty levels should attain higher Mas on corresponding concepts in the learning part. Cooperating response signals in both learning and assessing parts of CDMs can widen the gap among students' Mas as they reserve the unique feature in students' response logs.\nTo this end, this paper proposes an oversmoothing-resistant cognitive diagnosis framework (ORCDF) to enhance existing CDMs by utilizing response signals in the learning part. Specifically, ORCDF introduces a novel response graph, which utilizes response logs and a Q-matrix, inherently incorporating response signals as types of edges. Then, ORCDF designs a tailored response-aware graph convolution network (RGC) that effectively captures the crucial response signals within the response graph. We reveal that by utilizing the multiple layers of RGC, we achieve a multi-perspective analysis of student mastery. This is accomplished by combining the outcomes from multiple layers of RGC, leading to a more comprehensive understanding of student learning. Via ORCDF, existing CDMs are enhanced by replacing the input embeddings with the outcome of RGC through the transformation layer, allowing for the consideration of response signals on exercises in the learning part. Nevertheless, ORCDF encounters a new challenge: overemphasizing the role of response signals can exacerbate the guess and slip problem. This problem occurs when students guess in order to answer correctly or make mistakes on exercises they actually master, and could potentially lead models to make unreasonable inference of students' Mas. Different from previous methods that introduce extra parameters for guess and slip probabilities [16], this paper addresses the guess and slip problem in student-exercise interactions by considering them as noise edges in the response"}, {"title": "2 RELATED WORK", "content": "Cognitive Diagnosis Models. CDMs involve various approaches, such as latent factor models like IRT and MIRT (multidimensional IRT), or concept mastery pattern models like the deterministic input, noisy and gate (DINA) model, to infer students' mastery levels. DINA, a classic CDM, employs binary variables to represent mastery levels where 0 means unmastered and 1 means mastered. However, recent advances in deep learning have led to significant improvements in handling large-scale interactions. Notably, NCDM uses MLP as its IF, treating mastery patterns as continuous variables ranging from 0 to 1. This evolution in approach has been paralleled by diverse methods in analyzing response logs, including MLP based [13, 15, 21], graph attention networks [28] and Bayesian networks [12, 33], each contributing to a more nuanced understanding of student learning patterns. However, as depicted in Figure 2, these advanced CDMs encounter the oversmoothing issue which could potentially hinder the application of CD in downstream tasks of intelligent education, affecting their performance and consequently impacting student learning. To the best of our knowledge, the oversmoothing issue in the field of CD remains unexplored.\nOversmoothing Issue. The oversmoothing issue [14] is a significant problem in graph representation learning (GRL). Many studies have shown that the layers of graph neural network (GNN) deepen, the representations of graph nodes become increasingly smooth, leading to a substantial decrease in accuracy. This has prompted numerous researchers to employ a variety of methods [22] to address this issue, enabling deeper GNN architectures. The same phenomenon is also observed in various fields where graphs are used for data mining. For example, in recommendation systems, graph collaborative filtering (GCF) [34] faces the oversmoothing problem, which arises for the same reasons as in GRL due to the stacking of GNN layers. However, in the context of CD, oversmoothing is not a result of stacking GNN layers, since most CDMs like NCDM, CDM-FKC, KSCD and KaNCD do not utilize GNN. Yet, this issue does exist and is urgent, as shown in Figure 2. Thus, existing solutions to addressing oversmoothing in GRL and GCF are not suitable to resolve the oversmoothing issue in CD."}, {"title": "3 PRELIMINARIES", "content": "This section first introduces the fundamental elements of CD and then introduces the formal problem definition of CD and oversmoothing issue in CDMs. We also give abbreviations for terms in Table 5 at the beginning of the Appendix.\nCognitive Diagnosis Basis. Consider an education scenario which contains three sets: $S = \\{s_1,..., s_N\\}$, $E = \\{e_1, ..., e_M\\}$, and $C = \\{c_1,..., c_Z\\}$. They symbolize students, exercises and knowledge concepts, with respective sizes of N, M and Z. Q represents the relationship between exercises and knowledge concepts, which can be regarded as a binary matrix $Q = (Q_{iz})_{M\\times Z}$, where $Q_{iz} \\in \\{0,1\\}$ means whether $e_i$ relates to $c_z$ or not. Students from set S, driven by unique interests and requirements, select exercises from E. The results are documented as response logs. Specifically, these logs can be illustrated as triplets $T = \\{(s, e, r) | s \\in S, e \\in E, r_{se} \\in \\{0, 1\\}\\}$. $r_{se} = 1$ represents correct and $r_{se} = 0$ represents wrong. In this paper, we treat response logs as interaction matrix $I \\in \\mathbb{R}^{N\\times M}$. It contains three categorical values (1 means right, 0 means no interaction and -1 means wrong). Finally, we give the formal definition of the CD task and oversmoothing issue in CDMs.\nDefinition 3.1 (Problem Definition). Given interaction matrix $I\\in \\mathbb{R}^{N\\times M}$, a binary matrix $Q \\in \\mathbb{R}^{M\\times Z}$, the goal of cognitive diagnosis is to infer $Mas \\in \\mathbb{R}^{N\\times Z}$, which denotes the latent mastery level of students on each concept.\nDefinition 3.2 (Oversmoothing in CDMs). Given the learned $Mas \\in \\mathbb{R}^{N\\times Z}$ by CDMs, if the difference in students' Mas is sufficiently small, it indicates the presence of oversmoothing issue in CDMs.\nIn this paper, we utilize the mean normalized difference proposed in Section 5.1 to quantify the degree of oversmoothing."}, {"title": "4 METHODOLOGY: THE PROPOSED ORCDF", "content": "This section introduces the proposed ORCDF. It starts by introducing the proposed novel response graph, then explores the response-aware graph convolution (RGC), a technique designed to capture the rich information embedded in the response graph. Following this, we introduce a consistency regularization loss function. We also discuss the model training and analyze model complexity. An overview of ORCDF is shown in Figure 3.\nResponse Graph. As illustrated in Figure 4(a), focusing on responses, the response graph (ResG), denoted as $G = (V, E)$, comprises three types of nodes and edges. $V = S \\cup E \\cup C$ involves students, exercises, and concepts, $E$ involves interactions between $S$ and $E$ (i.e., \"Right\"), $S$ and $E$ (i.e., \"Wrong\"), $E$ and $C$ (i.e., \"Related\"). Notably, we incorporate the response signal on exercises as the edge types between students' nodes and exercises' nodes. Next, we will introduce how to capture the fruitful response signal information."}, {"title": "4.1 Response-aware Graph Convolution", "content": "Construct Embeddings. In CD, the primary data elements are response logs and the Q. It is crucial to deconstruct these complex logs into their fundamental components: students, exercises, and concepts. We encode them with trainable embeddings $H_s \\in \\mathbb{R}^{N\\times d}$, $H_e \\in \\mathbb{R}^{M\\times d}$, $H_c \\in \\mathbb{R}^{Z\\times d}$. For instance, $h_{s_i} \\in \\mathbb{R}^{1\\times d}$ denotes the row vector of the i-th student. To facilitate subsequent convolution processes, we stack the aforementioned embeddings to form $H^{(0)} \\in \\mathbb{R}^{(N+M+Z)\\times d}$.\nRight-Wrong Decomposition. In the ResG, there are two types of response signals existing between student nodes and exercise nodes, as shown in Figure 4(a). To better explore the impact of different response signals on learning Mas, we intuitively decompose the response graph into a right subgraph and a wrong subgraph. From the perspective of adjacency matrix, this involves splitting the interaction matrix I into $I^{right}$ (1 represents right, 0 represents others) and $I^{wrong}$ (1 represents wrong, 0 represents others). For brevity, in the following sections, we will denote \u201cR\u201d for right and \u201cW\u201d for wrong. Then we construct the right and wrong subgraphs (i.e, $A_R$, $A_W$ as expressed by Eq. (1):\n$A_R = \\begin{pmatrix}\n0 & I_R & 0\\\\\nI_R^T & 0 & Q\\\\\n0 & Q^T & 0\n\\end{pmatrix}$   $A_W = \\begin{pmatrix}\n0 & I_W & 0\\\\\nI_W^T & 0 & Q\\\\\n0 & Q^T & 0\n\\end{pmatrix}$                                                            (1)\nIn the ResG, the neighbors of a specific exercise node may include students who either answer the exercise right or wrong. However, after disentangling such response signals in the ResG, in each subgraph, the neighbors of a particular exercise node will only consist of students who displayed the same response signals. For example, if both $s_1$ and $s_2$ are connected to $e_1$, indicating that they both answer $e_1$ correctly, there may be some shared information explaining why they both got it right. Such crucial response signals will be propagated during the message-passing mechanism by GCN. This process enables a deeper understanding of the nuances in student responses. In the following part, we will introduce a novel graph convolution approach tailored to capture the information from the two disentangled subgraphs in CD.\nEmbedding Propagation. Considering that in CD, the features of students, exercises, and knowledge concepts are quite simple, consisting only of IDs, we draw inspiration from [7]. As a result, we eliminate linear transformations and nonlinear activation functions, opting to use only the fundamental components of GCN. Hence, the graph embedding propagation layer is designed with the following matrix form\n$H^{(l)} = A \\hat{D}^{-1}H^{(l-1)}, A = (\\hat{D}^{-\\frac{1}{2}}\\hat{A}\\hat{D}^{-\\frac{1}{2}}),$             (2)\nwhere A can be $A_R$ or $A_W$. The degree matrix D is a diagonal matrix with size $(N+M+Z)\\times(N+M+Z)$, where each entry $D_{ii}$ representing the number of non-zero entries in the i-th row vector of the matrix A. Using Eq. (2), we can obtain the convolution outcomes from the l-th layer of the disentangled subgraphs, specifically $H_R^{(l)}$ and $H_W^{(l)}$. However, right and wrong represent completely opposite response signals, it may be inappropriate to directly plus the results obtained from convolutions performed on the two subgraphs. A sophisticated function capable of aggregating these two types of information is necessary, as the interaction mechanisms between students and exercises are quite intricate. It can be expressed as\n$H_F^{(l)} = \\phi(H_R^{(l)}W_{rc} + H_W^{(l)}W_{wc}),$                 (3)\nwhere $H_F^{(l)}$ denotes the final representation of the l-th RGC layer and $\\phi$ denotes arbitrary nonlinear activate function. $W_{rc}, W_{wc} \\in \\mathbb{R}^{d\\times d}$ are trainable parameters. Intuitively, $H_R^{(l)}W_{rc}$ denotes the right channel which obtain the semantic information from right signal. Conversely, $H_W^{(l)}W_{wc}$ represents the opposite. The ultimate embedding $H_F$ is calculated using a mean pooling operation on the outcomes from each layer of the RGC which can be expressed as\n$H = \\frac{1}{1+L} (H^{(0)} + H_F^{(1)} + ... + H_F^{(L)}).$                    (4)\nDiscussion. Here, we explain why RGC can alleviate the oversmoothing issue in existing CDMs. Notably, since our goal is to alleviate the oversmoothing issue in CDMs, and given that shallow layers of RGC already achieve satisfactory experimental results, the"}, {"title": "4.2 Consistency Regularization Loss", "content": "After the graph convolution by multiple RGC layers, we can get the final representation H via Eq. (4). However, as we disentangle the response signal and capture student differences from various perspectives, it may exacerbate the notorious impact of the guess and slip problem on CDMs [16, 36]. Previous methods, as referenced in [4], model the guess and slip probabilities for each exercise as fixed parameters. Evidently, this approach is somewhat brute-force and might overlook the individual impact of students. This is because the probability of guessing or slipping is likely to vary for each person across different exercises. Contrary to the aforementioned methods, in this paper, we treat guess and slip as noise edges within the ResG. Specifically, we flip the student-exercise edge type (i.e., from R to W or W to R) with a probability $p_f$ in the ResG. This noised version of the ResG, where some edges are flipped, is referred to as the flipped ResG, as illustrated in the left part of Figure 3. We aim for the representations derived from the original ResG and the flipped ResG to be similar, in order to ensure that the CDMs remain effective even when subject to the disturbances caused by guess and slip problem. It can be formulated as\n$L_{reg} = -\\sum_{s_i \\in S} log(\\frac{exp(h_i^T\\hat{h}_i)}{\\sum_{s_a \\in S}exp(h_i^Th_{a})}),$    (7)\nwhere $\\hat{h}_i$ is the representation derived from flipped ResG, and $h_ih_a$ denotes the similarity score the representation derived from the ResG and flipped ResG. $\\tau$ is the hyperparameter which controls the degree of smoothness utilized in various methods [38-40]."}, {"title": "4.3 Model Training", "content": "Given input embeddings, existing CDMs predict the performance of students practicing exercises, which can be formulated as\n$\\hat{y}_{ij} = M_{CD}(H_{s_i}, H_{e_j}, H_c),$                   (8)\nwhere $M_{CD}()$ denotes the CDMs, and H represents the input embedding that contains the representation of the student, exercises and concepts.\nTransformation Layer. To facilitate the integration of ORCDF with the majority of existing CDMs, we need to transform dimensions to suit the specific type of CDM in use. If the embedding size of CDMs is a latent dimension (e.g., KaNCD), we directly utilize H as the input embedding for incorporated CDMs. Otherwise (e.g., NCDM), we introduce a transformation layer which can be formulated as\n$H_t = HW_t + b_t,$               (9)\nwhere $H_t$ will be employed as input embedding for incorporated CDMs and $W_t \\in \\mathbb{R}^{d\\times Z}, b_t \\in \\mathbb{R}^{(N+M+Z)\\times 1}$ are trainable parameters. As a result, unlike the previous RCD which sets d = Z, we can choose d as a latent dimension (e.g., 64). This significantly reduces the time complexity of graph convolution, a point that will be further analyzed in the subsequent subsection.\nJoint Training. The primary loss employed in CD task is to calculate the BCE loss between the model's predictions and the true response scores in a mini-batch. The aforementioned consistency regularization loss is incorporated jointly optimized with the CD task. The overall loss can be expressed as\n$L_{BCE} = -\\sum_{(s,e,r_{se}) \\in T} [r_{se} log \\hat{y}_{se} + (1 - r_{se}) log(1 \u2013 \\hat{y}_{se})],$                                 (10)\n$L = L_{BCE} + \\lambda_{reg} L_{reg}.$                      (11)\n$\\lambda_{reg}$ is a hyperparameter that governs the relative importance of the consistency regularization loss."}, {"title": "4.4 Model Complexity Analysis", "content": "Theoretically, we reveal that the graph convolution in ORCDF takes $O(4|E|Ld)$ time complexity. L denotes the number of RGC layers, and d denotes the dimension of embeddings. By leveraging the lightweight backbone and the transformation, our method is significantly lower in time complexity compared with the recent GNN-based approach RCD [6]. Specifically, RCD has the complexity of $O(2|E|LZ^2)$, where Z represents the number of concepts (d < Z). It suggests that ORCDF is more suitable for current online education scenario on ground of the increasing granularity of knowledge concepts. Indeed, ORCDF showcases a notable speed advantage, being up to 18 times faster than RCD on the Assist17 dataset (i.e., Z = 102). This dataset is collected from ASSISTment online tutoring systems and extensively utilized CDMs [12]. This improvement comes along with enhanced performance and lower GPU memory usage. For detailed information, please refer to Appendix A."}, {"title": "5 EXPERIMENTS", "content": "In this section, we first describe four real-world datasets and evaluation metrics. Then, through extensive experiments, we aim to verify the superiority of ORCDF, which not only assists existing CDMs in mitigating the oversmoothing issue but also enhances the models' prediction performance and interpretability performance. To ensure the reliability and reproducibility of our experiments, they are independently repeated ten times with different seeds and our code is available at https://github.com/lswhim/ORCDF."}, {"title": "5.1 Experimental Settings", "content": "Datasets Description. The experiments are conducted using four real-world datasets: Assist17, EdNet-1, Junyi, and XES3G5M. The Assist17 dataset is provided by the ASSISTment web-based online tutoring systems [5] and are widely used for cognitive diagnosis tasks [30]. EdNet-1 [3] is the dataset of all student-system interaction collected over 2 years by Santa, a multi-platform Al web-based tutoring service with more than 780K users in Korea. Junyi [2] is an online math practice log dataset offered by Junyi Academy. XES3G5M [20] is a knowledge tracing benchmark dataset with auxiliary information. For more detailed statistics on these four datasets, please cf. Table 1. Notably, \u201cSparsity\u201d refers to the sparsity of the dataset, which is calculated as $\\frac{|T|}{(|S||E|)}$. \"Average Correct Rate\" represents the average score of students on exercises, and \"Q Density\" indicates the average number of concepts per exercise.\nEvaluation Metrics. To assess the efficacy of ORCDF, we utilize both score prediction, interpretability and oversmoothing metrics."}, {"title": "5.2 Student Performance Prediction", "content": "To showcase the effectiveness of ORCDF, we integrate it with various CDMs, as described in the subsequent part.\n\u2022 IRT [8] is a classic model of latent factor CDMs, which uses one dimension $\\theta$ to model Mas and utilize logistic function as IF to predict the student score performance.\n\u2022 MIRT [27] is a representative model of latent factor CDM, which uses multidimensional $\\Theta$ to model Mas.\n\u2022 NCDM [30] is the first recent deep-learning based CDM which utilizes MLP to replace the traditional manually designed IFs."}, {"title": "5.3 Ablation Study", "content": "In this subsection, we scrutinize and evaluate each key individual component of ORCDF to comprehend their respective impacts and significance on the overall performance of the model. The ablation analysis is conducted using the following three versions.\n\u2022 OR-w/o-rgc: This ablation of ORCDF does not integrate the response-aware graph convolution. Instead, it directly perform convolution on the entire response graph without decomposition.\n\u2022 OR-w/o-reg: This ablation of ORCDF does not utilize the proposed consistency regularization loss $L_{reg}$.\n\u2022 OL: It represents the base CDMs, which can be considered as the one without the inclusion of response-aware graph convolution and consistency regularization loss.\nDue to space constraints, we only present the ablation study using OR-NCDM as an example. This choice is motivated by the fact that NCDM is often employed as a classic CDM in downstream tasks. It is worth noting that the results from incorporating other CDMs are generally similar.\nExperimental Results. As indicated in Table 3, the proposed method outperforms the other two versions, suggesting that each component plays a significant role in enhancing the model's overall effectiveness. OR-w/o-rgc performs significantly worse, further validating the superiority of the proposed RGC in capturing the information within the response graph. We empirically find that although the consistency regularization loss is designed to alleviate the guess and slip problem, it not only improves the prediction and interpretability performance but also achieves a higher MND than the original version. This indicates that the guess and slip problem indeed exists in real-world scenarios, and addressing this problem is crucial for the effectiveness of CDMs."}, {"title": "5.4 In-Depth Analysis of ORCDF's Advantages", "content": "In this subsection, we analyze the proposed ORCDF from two perspectives: generalization performance and robustness performance.\nGeneralization Performance. To assess the efficacy of ORCDF in addressing the generalization issue, we conduct experiments on three datasets with varying test ratios $p_t = \\{10\\%, 20\\%, 30\\%, 40\\%, 50\\%\\}$. As $p_t$ increases which is consistent with [6], the generalization ability of CDMs is tested more stringently. As depicted in Figure 6 of Appendix B, with an increasing test ratio $p_t$, the number of response logs used for training decreases. However, OR-NCDM consistently outperforms NCDM, illustrating that ORCDF can provide more accurate diagnosis results with fewer student response records. This"}, {"title": "5.5 Validation on the Downstream Task", "content": "As an upstream task in the field of intelligent education, CD is applied in various downstream tasks. To validate the effectiveness of ORCDF, we chose to test it in the context of computerized adaptive testing (CAT) [42, 43]. Specifically, we integrate the commonly employed IRT and NCDM with our ORCDF, denoting these as OR-IRT and OR-NCDM, respectively. Our experimental settings align with recent research [43], which adopts a 7:2:1 split for students in the response logs of each dataset. Details can be found in Appendix C.\nAs illustrated in Table 4, OR-NCDM performs better than OR-IRT, which validates the superiority of deep learning-based methods in CAT which is consistent with [42, 43]. OR-IRT and OR-NCDM significantly outperform their original versions. This validates the effectiveness of ORCDF in downstream tasks."}, {"title": "5.6 Hyperparameter Analysis", "content": "Effect of L. As shown in Figure 10 in Appendix D, a larger L decreases the model's training speed, while a smaller L results in poor performance. The recommended values of L are 3 or 4, which can yield relatively good performance. Notably, as L increases, the MND does not continually decrease, a phenomenon that seems different from what is observed in graph representation learning. We contend this could be related to the heterogeneity of the response graph and the complexity of student interactions, which we leave for future work.\nThe Effect of $p_f$. As depicted in Figure 11 in Appendix D, OR-NCDM is influenced by the flip ratio parameter. A too high flip ratio introduces more noise, deteriorating the model's performance. Typically, a $p_f$ =0.15 yields better prediction performance, aligning with the established fact that everyone has a probability of guessing correctly or slipping, neither too high nor too low.\nThe Effect of $\\lambda_{reg}$. As illustrated in Figure 12 in Appendix D, this parameter controls the impact of guess and slip on model training, which varies across different datasets and requires tuning. It is observable that as the number of response logs in the dataset gradually increases, the optimal parameter value decreases. We recommend setting it to 1e-3.\nThe Effect of $\\tau$. As illustrated in Figure 13 in Appendix D, the temperature parameter $\\tau$ affects the similarity between representations learned from the response graph and those from the flipped response graph. As the size of the dataset gradually increases, the better temperature value also gradually increases. Here, we recommend choosing 0.5 when the number of students is small and opting for 3.0 when there is a larger student population."}, {"title": "6 CONCLUSION", "content": "This paper proposes an oversmoothing-resistant cognitive diagnosis framework (ORCDF), where most existing CDMs can be integrated and thus enhanced. We, for the first time, identify the oversmoothing in CD and then address it by learning students' Mas from multiple perspectives, utilizing the proposed response graph and response-aware graph convolution network. Besides, we reformulate the guess and slip problem as noise edges in the response graph and deign a loss function to alleviate the problem. As long as the oversmoothing is addressed in CD, it greatly helps provide distinctive and personalized diagnostic results for students and teachers. However, ORCDF, while effective, is still not sufficiently interpretable enough in the field of intelligent education. More interpretable methods are expected to be developed to mitigate the oversmoothing issue explicably in cognitive diagnosis."}, {"title": "ACKNOWLEDGMENTS", "content": "We would like to thank the anonymous reviewers for their constructive comments. We also would like to thank Xinyue Ma for the reliable help. The algorithms and datasets in the paper do not involve any ethical issue. This work is supported by the National Natural Science Foundation of China (No. 62106076), National Social Science Fund of China (No. BEA230071), and Science and Technology Commission of Shanghai Municipality Grant (No. 22511105901)."}, {"title": "APPENDIX", "content": "The appendix is organized as follows:\n\u2022 Appendix A analyzes the ORCDF's time complexity and compares it with other frameworks.\n\u2022 Appendix B presents the detailed settings of compared baselines and other details about student performance perdition.\n\u2022 Appendix C presents the detailed settings of the downstream tasks, namely, computerized adaptive testing.\n\u2022 Appendix D further supplements the analysis with additional details regarding the hyperparameter analysis.\nNotably, our code is available at https://github.com/lswhim/ORCDF."}, {"title": "A TIME COMPLEXITY ANALYSIS", "content": "In this section, we present a detailed time complexity analysis of our proposed model OR-NCDM. We compare our time complexity with that of RCD, as RCD is the only CDM based on GNN.\nTime Complexity Analysis of ORCDF. We take OR-NCDM as an exmaple. In OR-NCDM, we construct a response graph (ResG) $G$ with three node and edge types based on I and Q. Given that we do not employ the non-linear activation and feature transformation usually found in GNNs, the time complexity can be straightforwardly computed as $O(2|E|Ld)$ for RGC, where L denotes the number of RGC' layers. d stands for the size of the embeddings. Due to the need for computing representations through the flipped ResG, the total time complexity amounts to $O(4|E|Ld)$.\nTime Complexity Analysis of RCD. In RCD, it construct three relation maps. Namely, an exercise-concept graph is constructed using Q and a student-exercise graph is formed using I. Given that RCD employs the graph attention network, which necessitates the computation of attention coefficients between every pair of connected nodes, its time complexity belongs to $O(2|E|LZ^2)$. Herein, Z represents the number of concepts (d < Z).\nOR-NCDM evidently takes less time compared to RCD due to two main reasons. Firstly, due to the transformation layer reduces the embedding dimension to d, where d is much smaller than Z. Secondly, by removing complex operations like linear transformations in GNN, the graph convolution of RGC's computation become much faster than the GAT used in RCD.\nIn the experiment, we incorporate NCDM into all frameworks and use the speed of NCDM as the baseline, set at 1.0x. As shown in the figure, our proposed ORCDF is 18 times faster than RCD and offers better prediction performance. When the number of knowledge concepts continuously increases, RCD tends to train too slowly and runs into out-of-memory issues, especially with large"}, {"title": "B EXPERIMENTAL DETAILS", "content": "Interpretability Metric. DOA is defined as Eq. (13)\n$DOAK = \\frac{\\sum_{a,b \\in S}\\sum_{j \\in Q}\\sum_{k=1}^{|Q_j|} \\delta (Massa,ck, Massb,ck)I(Q_{j,k})\\varphi(j,a,b)\\wedge I(r_{aj}\u2260r_{bj})}{\\sum_{a,b \\in S}\\sum_{j \\in Q}\\sum_{k=1}^{|Q_j|} (Massa,ck, Massb,ck)I(Q_{j,k})\\varphi(j,a,b)\\wedge I(r_{aj}\u2260r_{bj})},$  (13)\nwhere Z = $\\sum_{a,b \\in S} \\delta (Massa,ck, Massb,ck)$, $Q_{j,k}$ indicates exercise $e_j$'s relevance to concept $c_k$, $\\varphi(j, a, b)$ checks if both students $s_a$ and $s_b$ answered $e_j$, $r_{aj}$ represents the response of $s_a$ to $e_j$, and $I(r_{a,j} \u2260 r_{b"}]}]}