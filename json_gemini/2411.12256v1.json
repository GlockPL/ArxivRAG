{"title": "Restructuring Tractable Probabilistic Circuits", "authors": ["Honghua Zhang", "Benjie Wang", "Marcelo Arenas", "Guy Van den Broeck"], "abstract": "Probabilistic circuits (PCs) is a unifying representation for probabilistic models that support tractable inference. Numerous applications of PCs like controllable text generation depend on the ability to efficiently multiply two circuits. Existing multiplication algorithms require that the circuits respect the same structure, i.e. variable scopes decomposes according to the same vtree. In this work, we propose and study the task of restructuring structured(-decomposable) PCs, that is, transforming a structured PC such that it conforms to a target vtree. We propose a generic approach for this problem and show that it leads to novel polynomial-time algorithms for multiplying circuits respecting different vtrees, as well as a practical depth-reduction algorithm that preserves structured decomposibility. Our work opens up new avenues for tractable PC inference, suggesting the possibility of training with less restrictive PC structures while enabling efficient inference by changing their structures at inference time.", "sections": [{"title": "1 INTRODUCTION", "content": "A key challenge in deep generative modeling is the intractability of probabilistic reasoning (Roth, 1996; Geh et al., 2024). To address this challenge, probabilistic circuits (PCs) (Darwiche, 2003; Poon and Domingos, 2011; Choi et al., 2020) has emerged as a unifying representation of tractable generative models, which support efficient and exact evaluation of various inference queries like marginalization. The tractability of PCs has now proven crucial in a range of applications, such as causal inference (Ze\u010devi\u0107 et al., 2021; Wang and Kwiatkowska, 2023; Busch et al., 2024), knowledge graph learning (Loconte et al., 2023) and ensuring fairness in decision making (Choi et al., 2021).\nProbabilistic circuits represent distributions as computation graphs of sums and products. A crucial aspect to the design of PCs is the structure of the computation graph, that is, how distributions are factorized into (conditionally) independent components. The structure of PCs affects their tractability, modeling performance and computational efficiency. In this work, we consider the problem of restructuring PCs: constructing a new PC that follows a particular (target) structure while representing the same distribution. We present a general algorithm for restructuring structured-decomposable circuits by considering their graphical model representations. Specifically, we leverage the graphical models to reason about conditional independencies and recursively construct a new PC conforming to the desired structure.\nWe then investigate two key applications of PC restructuring: circuit multiplication and depth reduction. Circuit multiplication is a fundamental operation used for answering various inference queries (Vergari et al., 2021), such as conditioning on logical constraints (Choi et al., 2015; Ahmed et al., 2022; Liu et al., 2024b; Zhang et al., 2023, 2024), computing expected predictions of classifiers (Khosravi et al., 2019) and causal backdoor adjustment (Wang and Kwiatkowska, 2023), as well as in improving the expressive power of circuits through squaring (Loconte et al., 2024c,b; Wang and Van den Broeck, 2024). Though the problem of multiplying circuits of different structures is in general #P-hard (Vergari et al., 2021), we identify a new class of PCs, which we call contiguous circuits, where it is possible to multiply circuits of different structures in polynomial (or quasi-"}, {"title": "2 PROBABILISTIC CIRCUITS", "content": "Notation We will use uppercase to denote variables (e.g. X) and lowercase to denote values of those variables (e.g. x). We use boldface to denote sets of variables/values (e.g. X, x).\nDefinition 2.1 (Probabilistic Circuit). A probabilistic circuit (PC) A = (G, w) represents a joint probability distribution over random variables X through a rooted directed acyclic (computation) graph (DAG), consisting of sum (\u2295), product (), and leaf nodes (L), parameterized by w. Each node t represents a probability distribution pt(X), defined recursively by:\n$P_{t}(x) = \\begin{cases} f_{t}(x) & \\text{if } t \\text{ is a leaf node} \\\\ \\prod_{c \\in c h(t)} P_{c}(x) & \\text{if } t \\text{ is a product node} \\\\ \\sum_{c \\in c h(t)} w_{t, c} P_{c}(x) & \\text{if } t \\text{ is a sum node} \\end{cases}$\nwhere ft(x) is a univariate input distribution function (e.g. Gaussian, Categorical), we use ch(t) to denote the set of children of a node t, and wt,e is the non-negative weight associated with the edge (t, c) in the DAG, which satisfy the constraint that $ \\sum_{c \\in c h(t)} w_{t, c} = 1 $ for every sum node t. We define the scope of a node t to be the variables it depends on. The function represented by a PC, denoted pa (x), is the function represented by its root node; and the size of a PC, denoted |A|, is the number of edges in its graph.\nIntuitively, product nodes represent a factorized product of its child distributions, while sum nodes represent a weighted mixture of its child distributions. For simplicity, in the rest of this paper we assume that sum/leaf and product nodes alternate (i.e. child of a sum is a product, and child of a product is a leaf or sum), and that each product has exactly two children. The key feature of PCs is their tractability, i.e., the ability to answer queries about the distributions they"}, {"title": "3 PC RESTRUCTURING", "content": "In this section, we describe a generic approach that restructures any structured-decomposable PC respecting a target vtree. The approach consists of three steps: (1) construct a Bayesian network representation of the PC; (2) find sets of latent variables in the Bayesian network that induce conditional independencies required by the target vtree; (3) construct a new structured PC recursively leveraging the conditional independence derived in (2).\n3.1 Structured PCs as Bayesian Networks\nIt is known that one can efficiently compile a tree-shaped Bayesian network to an equivalent probabilistic circuit (Darwiche, 2003; Poon and Domingos, 2011; Dang et al., 2020; Liu and Van den Broeck, 2021). In this subsection, we describe how to go in the opposite direction, i.e. converting an arbitrary structured-"}, {"title": "3.2 Recursive PC Restructuring", "content": "Suppose we have a PC A with its Bayesian network representation GA and vtree V, and let W be some other vtree. We now show how to construct a new PC respecting W that encodes the same distribution as A. The rough idea is to label each vtree node w\u2208 W with a subset of latent variables CwGA such that Xw is conditionally independent from XXw given C\u03c9. To characterize such properties, we introduce covers:\nDefinition 3.4 (Cover). Given a tree-shaped Bayesian network GA as constructed in Sec. 3.1, we say that CCZ covers S \u2286 X if C blocks\u00b2 all paths between S and X\\S in GA.\nOur definition of cover is a special case of d-separation (Geiger et al., 1990), which characterizes conditional independence for Bayesian networks:\nProposition 3.5 (Geiger et al. (1990)). A, B C G A are conditionally independent given CC G if and only if C blocks all paths between A and B. In particular, if C covers S then S and X\\S are conditionally independent given C.\nOur goal is to recursively construct vectors of sum nodesi representing the probability distributions p(Xw|Cw=i). Letting land r be the children of w, we will establish a recurrence relation between p(Xw|Cw), p(X1|C1) and p(X|Cr). This requires the vtree labels to satisfy the following properties:\nDefinition 3.6 (Valid Vtree Labelling). Given the Bayesian network GA and target vtree W, a valid labelling of W with respect to G associates each node w\u2208W with a subset of latent variables Cw Gv s.t.\n1. Cw covers Xw in GA.\n2. Ci blocks all paths between X and CrUCw.\n3. Cr blocks all paths between X and CiU Cw.\nFurthermore, w.l.o.g., we set Croot of w := \u00d8 and Cx := parent of X; in G for the leaf nodes Xj\u2208W. See Figure 1c for an example.\nAssuming that we have computed a valid labelling for W, we can then proceed to construct the desired PC"}, {"title": "Algorithm 1 Construct PC with respect to W", "content": "procedure CONSTRUCTCIRCUIT(W)\nif w is a leaf node X\u2081 then\nreturn p(Xi | Cx\u2081)\nend if\nl, r \u2190 CHILDREN(W)\nXC XC CONSTRUCTCIRCUIT(I)\nXC CONSTRUCTCIRCUIT(r)\n\u03a3\u03b1, \u00b7p(Cl, Cr|Cw)\n(CUCr)\\Cw\nCwCw return c\nend procedure\nTheorem 3.7. Leth be the number of hidden states of the original PC A and n the number of random variables. The number of hidden states of the restructured PC is given by O(hM) where M = maxw\u2208W|C\u012e U Cr| and the size of the restructured PC is bounded by O(nhM') where M' = maxw\u2208w |C\u2081 UC, UCw| \u2264 2\u041c. We refer to M' as the cardinality of the labelling Cw.\nProof. Let A' be the restructured circuit respecting W. As described in Algorithm 1, for each inner node w\u2208 W, we construct two layers of nodes as shown in Figure 2. By construction, the product layer contains all product nodes respecting the vtree node w and its cardinality is given by O(h|Ciucrl); we set M := maxw\u2208w |Ci U Cr| and it follows that the hidden states size of B is given by O(hM). Similarly, the number of edges in the sum layer is given by O(h|CUCUCwl) and the number of product edges is given by O(h|Ci\u016aCrl); since there are O(n) vtree nodes in total, the total number of edges in B is given by O(nhM'), with M' = maxw\u2208w |CUC, UCw|. \u220f"}, {"title": "3.3 Computing Vtree Labelling", "content": "The next question that immediately arises is how to compute a valid labelling for W with respect to GA. One naive solution is to set Cw to be Z, the set of all latent variables in GA. However, this is not desirable as M' = maxw\u2208W |Ci U Cr UCw| = |Z|=n\u22121, resulting in the restructured circuit having exponential size O(nhn-1). Hence we present a greedy approach that computes a labelling while trying to minimize M'.\nThe algorithm proceeds top-down on W. For the base case where w is the root, we set Cw := \u00d8. For the inductive step, let I andr be the children of w and assume that we have computed Cw as a cover for Xw in Ga: we (1) split Gf into connected components {Gi} via Cw; then (2) within each connected component Gi, we compute a minimum d-separator Ci that blocks all paths between Xin Gi and XnGi by calling the sub-routine MINIMUMSEPARATOR. We set Dw := (UC) UCw and observe that Dw covers both X and X in GA. To compute C\u0131, similarly for Cr, we consider all paths starting from X\u2081 and stopping immediately when reaching some Zj \u2208 Dw, and we let Ci to be the set containing all such Zjs. The pseudo code is shown in Algorithm 2. Note that the MINIMUMSEP-"}, {"title": "Algorithm 2 Computing Cw for w\u2208W", "content": "procedure COMPUTELABEL(W, Cw)\n{G} \u2190 CONNECTEDCOMPONENTS(GA, Cw)\nCi\u2190 MINIMUMSEPARATOR(Gi, X\u0131NGi, XrNGi)\nDw\u2190 (UC) UCw\nC1 \u2190 {Zj\u2208Dw : PATHS(X1, Zj) \u2229 Dw = {Zj}}\nCr\u2190 {Zj\u2208Dw: PATHS(Xr, Zj) \u2229 Dw = {Zj}}\nCOMPUTELABEL(l, Ci)\nCOMPUTELABEL(r, Cr)\nend procedure\nARATOR procedure called in Algorithm 2 computes a minimum d-separator that blocks all paths between X and X, in the subgraph Gi. Even though polytime algorithms for computing minimum d-separators exist in literature (Tian et al., 1998), we derive a linear-time algorithm that is easy to implement for our use case, where Gi is a rooted tree with leaves in X1, X, and"}, {"title": "3.4 Corollaries", "content": "With our restructuring algorithm in hand, we now examine the restructuring of two other types of circuits: namely, deterministic PCs, and logical circuits.\nDefinition 3.10 (Determinism). A sum node is deterministic if for every value x of X, at most one child c returns a non-zero value (i.e. pc(x) > 0). A PC is determininstic if all of its sum nodes are deterministic.\nDeterminism is crucial for tractability of various inference queries such as computing the most likely state (MAP) (Peharz et al., 2016; Conaty et al., 2017) or computing the entropy of the PC's distribution (Shih and Ermon, 2020; Vergari et al., 2021). It is thus of interest to ask whether applying our restructuring algorithm maintains determinism."}, {"title": "Claim 3.11. Algorithm 1 preserves determinism.", "content": "Proof. If the original circuit is deterministic, then each assignment to the observed variables fully determines the values of all latent variables (and thus the latents being conditioned on for the restructuring). Hence the constructed sum nodes are deterministic.\nAlthough we have focused on probabilistic circuits up to this point, our restructuring algorithm also applies to logical circuits in particular, structured-decomposable negation normal form (SDNNF) circuits\u00b3 (Pipatsrisawat and Darwiche, 2008). To see this, we use a simple trick: (1) convert the logical circuit into a probabilistic circuit by replacing V with and with, and assigning positive weights to edges; (2) restructure the PC; (3) convert the PC back to a logical circuit by replacing with V and with A, and removing the weights. It is immediate that the logical circuits and the corresponding PCs have the same support throughout the process.\nIt is also not hard to see that this procedure for logical circuits retains determinism, so, e.g, an ordered binary decision diagram (OBDD) can be efficiently restructured into a deterministic SDNNF with the reverse order while maintaining the ability to perform model counting (Darwiche and Marquis, 2002)."}, {"title": "4 PC MULTIPLICATION", "content": "One important application of restructuring PCs is circuit multiplication: given two PCs A and B, the goal is to construct a tractable PC & such that ps(x) x pa(x)\u00b7pg(x). PC multiplication was previously only addressed for structured PCs respecting the same vtree (Shen et al., 2016; Vergari et al., 2021). Circuit restructuring immediately gives us a means of multiplying two structured circuits respecting different vtrees, as we can simply restructure one of them to be compatible with the other. Though the restructured PC will in general have exponential size, in this section, we consider practical cases where circuit multiplications with respect to different vtrees is tractable.\nWe start by introducing a new structural property of tractable PCs called contiguity.\nDefinition 4.1 (Contiguity). Given the canonical ordering of variables X1, X2, ..., Xn, a PC node is contiguous if its scope is of the form Xa, Xa+1, ..., X for some 1<a<b<n. A smooth and decomposable PC is contiguous if all of its nodes are contiguous."}, {"title": "Claim 4.2. Cab is a valid vtree labelling of Wre-specting Ga with cardinality M' = 3.", "content": "Then it follows from Theorem 3.7 that the size of A', i.e., the PC obtained by restructuring A respecting W, is bounded by O(nh\u00b3), with O(|A|2) being a looser bound. Eventually we can compute the product of A' of B tractably by the existing algorithm for multiplying two circuits respecting the same vtree (Shen et al., 2016; Vergari et al., 2021).\nTheorem 4.3. Let A and B be contiguous structured PCs. If A has a linear vtree, then A and B can be multiplied in polynomial time and the size of the product PC is bounded by O(|A|2|B|).\nCase 2. Then we consider the more general case where A is a contiguous structured PC of depth d respecting vtree V and B is a contiguous structured PC with an arbitrary vtree W. Similarly to the previous case, our goal is to come up with a small labelling of W with respect to GA. Since A is contiguous, its vtree V can be viewed as a segment tree (Cormen et al., 2022). Algorithm 3, which is adapted from the segment tree querying algorithm, computes a cover Ca:b GA for each contiguous segment Xa:b. For each w\u2208W, Xw = Xa:b for some1<a<b< n and we set Cw = Ca:b = SEGMENTCOVER(V, Xa:b).\nProposition 4.4. Cw is a valid vtree labelling with respect to GA."}, {"title": "Algorithm 3 Compute Cover for Segment Xa:b", "content": "procedure SEGMENTCOVER(V, Xa:b)\nif Xa:b = \u00d8 then\nreturn \u00d8\nend if\nif Xa:b = X then\nreturn {Z}\nend if\nl, r \u2190 CHILDREN (V)\nL \u2190 SEGMENTCOVER(l, X1 Xa:b)\nR SEGMENTCOVER(r, X, Xa:b)\nreturn LUR\nend procedure"}, {"title": "4.7. In this work, we assumed product nodes always have two children and binary vtrees. Hence the depths of PCs are lower-bounded by \u03a9(log n) under such assumptions. However, if we allow product nodes to have arbitrarily many children, we can have PCs of smaller or even constant depths (Raz and Yehudayoff, 2009) and we hypothesize that Theorem 3.7 can be adapted to such generalized cases thus giving a polynomial-time algorithm for multiplying contiguous structured circuits of constant depths.", "content": "Remark 4.8. Thus far, we have assumed that both A and B are structured PCs. We claim that we can further generalize our results by removing the constraint that B has to be structured, and Theorems 4.3 and 4.5 would still hold. We illustrate the idea by showing how to multiply a contiguous structured PC A respecting a linear vtree and an arbitrary contiguous PC B. Since Bis not structured decomposable, we cannot restructure to the vtree of B. However, we can use the same idea as Algorithm 1 to restructure A \"on-the-fly\" as we multiply it with Bin a bottom-up way. Specifically, for each possible scope Xa:b that appears in B, we recursively construct circuit representations for the functions pq (Xa:b) \u00b7 PA (Xa:b | Za = i, Zb = j) for i, j and q\u2208 B with scope Xa:b. The recurrence relation is similar to that of Algorithm 1 and we refer readers to the Appendix for details.\nAs an explicit application of circuit multiplication, let us consider constrained text generation (Zhang et al.,"}, {"title": "5 PC DEPTH REDUCTION", "content": "Algorithm 4 Depth Reduction Vtree\n1: procedure BALANCEDVTREE(V, S\u2081 = (\u00d8, S = 0)\nreturn LEAF(V; S\u2081 US)\n2:\nif |V| = 1 then\n3:\n4:\n5:\n6:\n7:\n8:\n9:\n10:\n11:\n12:\n13:\nend if\nv \u2190 ROOT (V)\nl, r \u2190 CHILDREN (v)\nwhile |V|>|V| do\nvr\nl,r \u2190 CHILDREN (v) \u25b7 assume |Vi|<|V|\nend while\nV' \u2190 BALANCEDVTREE(V[v\u2194l], S\u03b9, {\u0396\u03c5})\nV\u2190 BALANCEDVTREE(V,, {Z}, Sr)\nreturn JOIN(V\u00ed', V'; S\u0131 U Sr)\n14: end procedure\nDepth reduction of a probabilistic circuit refers to the construction of an equivalent circuit with reduced depth, e.g. to a depth logarithmic in the number of variables. A depth reduction algorithm for general circuits is known (Valiant et al., 1983; Raz and Yehudayoff, 2008; Yin and Zhao, 2024) but does not take advantage of structuredness. We show how to reduce a structured-decomposable circuit to an equivalent log-depth circuit by restructuring. The key step is to identify a log-depth vtree such that restructuring to that vtree using Algorithm 1 (and some valid choice of labels) results in at most a polynomial increase in size.\nAlgorithm 4 constructs a log-depth vtree labelling of constant cardinality. Intuitively, each step of the algorithm breaks a vtree down into two connected components, which are then depth-reduced recursively. One selects a single vtree node by traversing the vtree top-down, until the split would be balanced in the sense that the two connected components have size between and of the input vtree (Lines 7-10). The algorithm simulataneously constructs a valid label for the vtree node. The JOIN routine then returns a labelled vtree that consists of a single root node with the aforementioned label, connected to the depth-reduced vtrees for the components. Note that the algorithm produces exactly one vtree node for each vtree node in the original vtree; we can thus write v(w) for the node in V corresponding to w. Then we have the following result:"}, {"title": "5.1 (Depth Reduction Vtree). Given any vtree V, Algorithm 4 returns a vtree W of depth O(log|V|) with a valid labelling of cardinality 3.", "content": "Proof. The depth reduction to O(log|V|) is achieved as the algorithm increases the depth by one in each recursive call, but reduces the vtree size by a multiplicative factor. The validity condition holds due to the separation into connected components (the labels can also be obtained from Algorithm 2). The value of M' follows by noting that Si and Sr are either empty or singleton sets, and that the algorithm produces Cw = S\u2081USr, C\u2081 = Si\u222a{Zv(w)}, and Cr = {Zv(w)}US\u03b9 where Zv(w) for each inner node w \u2208 W.\nRemark 5.2. Firstly, the depth-reduced PC retains structuredness, which is not guaranteed by the existing depth-reduction algorithms. Secondly, exploiting structuredness and tracking the hidden state size enables a more fine-grained analysis of the size of the depth-reduced circuit. Since the size of the original circuit is O(nh\u00b2), using the known cubic bound on the size of the depth-reduced circuit (Raz and Yehudayoff, 2008) gives O(n\u00b3h6). However, by Theorem 5.1, we see that M' = maxwew Cl, Cr, Cw\u22643 and so by Theorem 3.7 we immediately obtain a much tighter bound of O(nh\u00b3) for the size of the resulting circuit.\nCorollary 5.3. Any structured PC over n variables and with hidden state size h can be restructured to a structured PC of depth O(logn) and size O(nh\u00b3) that represents the same distribution.\nWhile this result is of independent theoretical interest, the sub-quadratic complexity of O(nh\u00b3) also opens up practical applications of depth-reduction. Almost all PC inference and learning algorithms involve forward/backward passes through the computation graph, where computation is only parallelized across nodes of the same depth such that O(depth of PC) sequential computations are required. This is problematic when the number of variables n is large, as is often the case in applications such as computational biology (Dang et al., 2022b). In such cases, depth reduction can be a practical strategy where the improved parallelism outweighs the increased circuit size."}, {"title": "6 RELATED WORK", "content": "Probabilistic circuits have emerged as a unifying representation of tractable probabilistic models (Choi et al., 2020; Sidheekh and Natarajan, 2024), such as sum-product networks (Poon and Domingos, 2011), cutset networks (Rahman et al., 2014), probabilistic sentential decision diagrams (Kisa et al., 2014) and probabilistic generating circuits (Zhang et al., 2021; Harvi-ainen et al., 2023; Agarwal and Bl\u00e4ser, 2024; Broadrick et al., 2024). Significant effort has been devoted to learning PC structures to fit data (Liang et al., 2017; Dang et al., 2020; Yang et al., 2023), but the implications for the structure-dependent queries have been less studied. We bridge this gap by providing a general restructuring algorithm with specific cases of (quasi-)polynomial complexity.\nAs tractable representations of distributions, PCs have been employed extensively as a compilation target for inference in graphical models (Darwiche, 2003; Chavira and Darwiche, 2008; Rooshenas and Lowd, 2014). Hidden tree-structured Bayesian networks have also been used as a starting point for the learning of a probabilistic circuit (Dang et al., 2020; Liu and Van den Broeck, 2021; Dang et al., 2022a). A particularly useful analysis technique for learning probabilistic circuits has been to interpret them as latent variable models (Peharz et al., 2016). Decomposable and smooth PCs can be interpreted as Bayesian networks by introducing a latent variable for each sum node in the PC (Zhao et al., 2015). Our conversion from structured PC to Bayesian network is most closely related to the decompilation methods of Butz et al. (2020); Papantonis and Belle (2023), but we do not assume the PC has been compiled from a Bayesian network.\nThe seminal work of Valiant et al. (1983) showed that any poly-size arithmetic circuit can be transformed into an equivalent circuit of polylogarithmic depth. Raz and Yehudayoff (2008) show that this procedure maintains syntactic multilinearity (decomposability). Recently, Yin and Zhao (2024) showed a quasipolynomial upper bound on converting decomposable and smooth PCs to tree-shaped PCs via a depth-reduction procedure. Our application of restructuring focuses on structured-decomposable circuits and shows a tighter bound based on a graphical model interpretation."}, {"title": "7 CONCLUSION", "content": "We introduce the problem of restructuring probabilistic circuits, and develop a general algorithm for restructuring a structured-decomposable circuit to any target vtree structure. Our method exploits an interpretation of structured-decomposable circuits as latent tree Bayesian networks, which enables recursive construction of a circuit respecting the target vtree using probabilistic semantics of the Bayesian network. As concrete applications of restructuring, we show how to tractably multiply two circuits which do not necessarily share the same structure but satisfy a contiguity property, and show how to restructure a circuit to log-depth with a sub-quadratic increase in size."}, {"title": "A ADDITIONAL PROOFS", "content": "Proposition 3.2. \u03c1\u03b1(X) = \u2211z PAaug (\u03a7, z)\nProof. Suppose that A is a structured decomposable and smooth PC respecting vtree V. Write prod(v) and sum(v) for the set of product and sum nodes with scope X. The augmented PC Aaug is decomposable as if leaves with scope {Z} were contained in (the subcircuits rooted at) two different children t1, t2 of a product node, then their parents (nodes in prod(v)) would be contained in t1, t2, which is a contradiction of decomposability of A. It is also smooth as for any sum node, if one sum node contains some leaf with scope {Z}, then it contains some node in sum(v), hence by smoothness of A all sum nodes contain some node in sum(v) and thus some leaf with scope {Z}.\nConsider the standard marginalization algorithm for PCs (Darwiche, 2003; Choi et al., 2020), where one replaces each leaf whose scope is contained within the variables being marginalized out with the constant 1. This correctly marginalizes the function represented by the PC if the PC is decomposable and smooth. If we marginalize over all newly introduced latents Z, it is immediate that the resulting PC represents the same function as A.\nTheorem 3.3. Let A be a structured-decomposable and smooth PC over variables X respecting vtree V. Then there exists a Bayesian network Ga over variables X and Z = {\u0396\u03c5v \u2208 V} with graph Vvz such that \u03a3\u03c4PG(X, z) = pa(X).\nProof. In Section 3.1 we described a Bayesian network pg = p* with the required graph. It remains to show that this network represents the same distribution as A. We will do this by showing that the Bayesian network has the same distribution as the augmented PC, i.e. pG(X,Z) = PAaug (X, Z).\nThe key observation is to consider the induced trees of the augmented PC (Zhao et al., 2016):\nDefinition A.1 (Induced Trees). Given a decomposable and smooth circuit A, let T be a subgraph of A. We say that T is an induced tree of A if (1) ROOT(A) \u2208 T; (2) If t \u2208 T is a sum node, then exactly one child of t (and the corresponding edge) is in T; and (3) If t \u2208 T is a product node, then all children of t (and the corresponding edges) are in T.\nIt is easy to see that an induced tree T is indeed a tree, as otherwise decomposability would be violated. Let T be the set of all induced trees of Aaug. Each induced tree defines a function:\n$P_{A_{a u g}, T}(X, Z):=\\prod_{\\left(t_{i}, t_{j}\\right) \\in S U M E D G E S(T)} w_{t_{i} s t_{j}} \\prod_{t \\in L E A V E S_{X}(T)} f_{t}(X_{s c(t)}) \\prod_{t \\in L E A V E S_{Z}(T)} I f_{t}(Z_{s c(t)})$\nwhere SUMEDGES(T) denotes the set of outgoing edges from sum nodes in T, and LEAVESX(T), LEAVESZ (T) denote the set of leaf nodes in T with scope corresponding to a variable in X, Z respectively. The distribution of the augmented PC is then in fact given by the sum of these functions over all induced trees:\nProposition A.2 (Zhao et al. (2016)). PAaug (X, Z) = \u03a3\u03c4\u03b5\u03c4PAaug,T(X, Z).\nNow, let path(v,i,j) be a predicate indicating whether there is a path between tp,j and tv,i (where we use p to denote the parent vtree node of v, and as before e.g. tv,i indicates the product node with scope X and corresponding to Z = i). We will consider two cases depending on the value of the latents. Specifically, we will say that an assignment z is consistent if path(v, zv, zp) holds for all non-root inner nodes in the vtree, and inconsistent otherwise."}, {"title": "B Computing Minimum D-separators", "content": "Let G be a tree-shaped Bayesian network rooted at Z; in particular, assume that the leaves of GC XUZ and the internal nodes of G C Z (e.g. Figure 1b). Then, we want to prove that Algorithm 5 computes a minimum d-separator CCG for A, \u0412 \u0421 \u0425.\nAs shown in Algorithm 5, given tree-shaped Bayesian network G rooted at Z, the procedure MINIMUMSEPARTOR computes three sets of latent variables CA, CB and C. Specifically, we shall prove the following properties:\n1. CA is a minimum d-separator between A and B that also blocks all paths from A to Z.\n2. CB is a minimum d-separator between A and B that also blocks all paths from B to Z.\n3. Either CA or CB is a minimum d-separator between A and B in G (rooted at Z); hence C is a minimum d-separator between A and B in G."}, {"title": "Algorithm 5 Computing minimum d-separators for tree-shaped Bayesian network G rooted at Z", "content": "procedure MINIMUMSEPARATOR(Z, A, B)\nif A and B = \u00d8 then\nreturn \u00d8, \u00d8, \u00d8\nend if\nif B= then\nreturn {Z}, \u00d8,\u00d8\nend if\nif Athen\nreturn \u00d8, {Z},\u00d8\nend if\nfor Zi \u2208 CHILDREN(Z) do\n\u0421\u0456,\u0430, \u0421\u0456,\u0432, \u0421\u0456\u2190 MINIMUMSEPARATOR(\nZi, ANLEAVES (Zi), BOLEAVES(Zi))\nend for\nCAMIN (UC\u00bf\u222a {Z}, U\u00bfCi,A)\nCB \u2190 MIN(UC\u00bf\u222a {Z}, \u222a\u00bfC\u00bf,\u0432)\nC\u2190 MIN(CA, \u0421\u0432)\nreturn CA, \u0421\u0412, \u0421\nend procedure\nfrom B to Z} are the same set. It is obvious that QCP and let's prove that PC Q. Let C be a d-separator between A and B in G, then C either blocks all path from A to Z or blocks all path from B to Z; suppose not, then there is a path connecting A and B through Z; contradiction."}, {"title": "C MULTIPLICATION WITH NON-STRUCTURED CIRCUITS", "content": "Given a contiguous structured PC A respecting a linear vtree and an arbitrary contiguous PC B", "Xa": "b that appears in B", "Pq(Xa": "b)\u00b7PA (Xa:b | Za=i"}, {"Xa": "b and i"}, {"Xa": "b | Za=i"}, {"Xa": "b | Za=i"}, {"Xa": "b | Ca:b) as defined in Case 1. of Section 4.\nThe recurrence relation is similar to that of Algorithm 1. In the following derivation", "notations": 1}]}