{"title": "An efficient machine learning approach for extracting eSports\nplayers' distinguishing features and classifying their skill levels\nusing symbolic transfer entropy and consensus nested cross\nvalidation", "authors": ["Amin Noroozi", "Mohammad S. Hasan", "Maryam Ravan", "Elham Norouzi", "Ying-Ying Law"], "abstract": "Discovering features that set elite players apart is of great significance for eSports coaches as it enables them to\narrange a more effective training program focused on improving those features. Moreover, finding such features\nresults in a better evaluation of eSports players' skills, which, besides coaches, is of interest for game developers to\ndesign games automatically adaptable to the players' expertise. Sensor data combined with machine learning have\nalready proved effective in classifying eSports players. However, the existing methods do not provide sufficient\ninformation about features that distinguish high-skilled players. In this paper, we propose an efficient method to find\nthese features and then use them to classify players' skill levels. We first apply a time window to extract the players'\nsensor data, including heart rate, hand activities, etc., before and after game events in the League of Legends game.\nWe use the extracted segments and symbolic transfer entropy to calculate connectivity features between sensors. The\nmost relevant features are then selected using the newly developed consensus nested cross validation method. These\nfeatures, representing the harmony between body parts, are finally used to find the optimum window size and\nclassify players' skills. The classification results demonstrate a significant improvement by achieving 90.1%\naccuracy. Also, connectivity features between players' gaze positions and keyboard, mouse, and hand activities were\nthe most distinguishing features in classifying players' skills. The proposed method in this paper can be similarly\napplied to sportspeople's data and potentially revolutionize the training programs in both eSports and sports\nindustries.", "sections": [{"title": "1 Introduction", "content": "eSports is a form of video gaming in which several players or teams compete against each other to achieve a\npredefined goal. The eSports industry has rapidly evolved from entertainment to a self-sustainable business within\nthe last few years and still is actively developing in a variety of fields, including broadcasting, hardware, game\nstatistics, streaming, and connectivity. The video game industry comprised over 80% of the total $36 billion profit\nearned from all software-related industries in 2018 in the United States [1]. Moreover, according to the global games\nmarket report, the gaming industry was worth over $180 billion in 2021 [1]. This fact gave rise to severe\ncompetition among game developers to provide a better user experience for the diverse population of video game\nplayers. This could be done using gameplay capable of being adaptively updated according to the players' skill\nlevels, also referred to as dynamic difficulty adjustment (DDA) [2], which, in turn, entails an accurate evaluation of\nplayers' expertise first and foremost. Such an evaluation is of great value for eSports coaches as well.\nCurrently, eSports coaches mostly rely on their knowledge and intuition for designing players' training programs.\nThis is while in one of the most recent studies [3], professional eSports coaches counted the appraisal of players'\\ skills and abilities as one of the biggest challenges during their careers. Having a reliable method to discover the\nfeatures that distinguish high-skilled players could help coaches to design a more efficient program revolving around\nimproving those features. Moreover, applying these features could improve the accuracy of players' skill\nclassification, which is favourable for both game developers and eSports coaches.\nMachine learning (ML) has been widely used for assessing eSports players' skills. In terms of the input data they\nuse, the existing ML methods can be mainly categorized into two groups: methods using in-game data and methods\nusing sensor data. The methods in the first group, accounting for a significant portion of the existing literature,\nmainly approach the problem from a statistical point of view and use in-game data and metrics such as Kill-Death\nRatio (KDR), Win/Loss rate, etc., besides ML techniques to evaluate players' skill levels or predict the game's\noutcome [4-9]. These methods suffer from two major problems. Firstly, they have poor robustness due to being\ndependent on the games' features. When the game settings and features change, the previously trained model may\nnot be valid anymore. Also, finding the correct in-game features capable of predicting the players' skill levels is not\nstraightforward or even possible. Secondly, the main physical features that discriminate between players of different\nskill levels are not reflected in the game statistics. For example, it is not easy to comment on the players' reaction\ntime, their skills in working with keyboards and mouse, and their cognitive abilities, such as sustained attention,\nonly using game statistics. To address these problems, the methods in the second category have investigated the\napplication of sensor data in assessing eSports athletes' abilities [10-13]. Different types of sensor data have already\nbeen used for this purpose in the literature, including gaze data [14], keyboard and mouse data [10],\nelectroencephalography (EEG) [15], galvanic skin response (GSR) [11], skin resistance (SR) [11], heart rate [16],\nelectromyography (EMG) [11], pupil diameter [11], face temperature [11], and players' movement data gathered by\nan accelerometer, magnetometer, and gyroscope [11, 12]. Methods in this category provide better robustness and\naccuracy as they are not dependent on the game's settings. However, they still do not provide adequate information\nabout physical and cognitive features that set high-skilled players apart. The majority of these studies use sensor\ndata gathered from only one part of the body [10, 14\u201316]. There are also a few studies using multiple sensor data\n[11-13]. However, the harmony between body parts is widely neglected in these studies. This is while such a factor\ncould be decisive in differentiating between players of different skill levels in eSports and sports. For example, it is\nwell established that the harmony between breathing and strides is one of the most distinguishing factors in\nprofessional runners [17].\nThe contributions of this paper can be summarized as follows: the first contribution of this paper is to propose an\nefficient ML algorithm to discover the features that distinguish professional players from amateur players. To our\nknowledge, this is the first study investigating this issue. We also use the selected features to increase the accuracy\nof players' skill classification. Secondly, the proposed method takes advantage of symbolic transfer entropy (STE) to\nextract connectivity features between sensors gathering data from different body parts such as eyes and hands.\nAlthough STE has been applied to sensor data of the same type, for example, EEG data, for other applications [18,\n19], this is the first study applying STE to sensor data of different types for eSports players skill evaluation, thereby\nincorporating the harmony between body parts as features in the classification. Thirdly, we propose a novel feature\nselection procedure comprising a recently developed method called consensus nested cross-validation (CN-CV) [20]\nand the minimum redundancy maximum relevance (mRMR) method [21]."}, {"title": "2 Related work", "content": "Sensor data have been successfully applied to assessing eSports players' performance [22-27]. Gaze data gathered\nby eye-tracking sensors proved effective in differentiating between players of different skill levels. Investigators in\n[28] assessed the gaze behavior of amateur and professional players in the Counter-Strike: Global Offensive CS: GO\ngame. Analyzing the gaze data of 15 players gathered by an EyeLink eye-tracker, they observed a considerable\ndifference in the gaze position of players of different expertise. However, they did not report the classification\nresults or any statistical measures for the observed differences. Similarly, a comparative study of amateur and\nprofessional players in CS: GO based on the gaze, keyboard, and mouse data is presented in [14]. For this purpose,\nthe gaze behavior of 28 players, including 4 professional and 24 amateur players, was analyzed while the amateur\nplayers were divided into three groups: newbie, low-skill amateur, and high-skill amateur. Using the Mann-Whitney\ntest, they observed a significant difference between the gaze behavior of professional and amateur players. For the\nclassification, they divided the players into two classes, namely, professional and amateur. In the end, using a\ncombination of keyboard, mouse, and gaze data, they reported a binary classification accuracy of 90%. However,\ndue to the high degree of imbalance in their dataset, it is difficult to assess the validity of their results. One study\n[29] reported a significant difference in the players' distribution of visual fixation, gathered using a Tobii EyeX eye-\ntracker, in the CS: GO game. To achieve this result, they designed an experiment consisting of 21 players\ncategorized into three groups: 10 newbies with less than 700 hours of playing experience, 7 amateur players with\nmore than 700 hours of playing experience, and 4 professional players with more than 10000 hours of playing\nexperience. Although they did not observe a significant difference in the mean visual fixation duration between\nplayers of different skill levels, the standard deviation of fixation duration was significantly different among players;\nplayers with higher skill levels had higher standard deviations. However, they did not assess the players' gaze\nlocation. Another study [30] presented an analysis of players' gaze data gathered by a Pupil Core eye-tracker in the\nStarCraft game. For this purpose, they used the gaze data of seven expert players and nine players with low skill\nlevels while all participants played the game at three different difficulty levels. The gaze position of expert players\ncovered a significantly larger interval in the horizontal direction compared to that of low-skilled players. Moreover,\nthe intensity, number, and velocity of saccade in expert players were significantly greater than in low-skilled players.\nKeyboard and mouse data have also been frequently used to assess the players' expertise level and performance in\ndifferent games. A significant difference in keyboard and mouse usage between CS: GO amateur players and\nprofessional players was reported in [28]. They particularly considered the time interval in which the player used the\nA and D keys to move to the right and left and the time interval in which the player pressed the left mouse button\n(MOUSE1) while moving forward using the key W. In one study, the Mobalytics Proving Ground Assessment\n(MPGA) could differentiate between highly skilled and low-skilled League of Legends (LoL) players [31]. MPGA is\nan online assessment tool that evaluates LoL players' ability to work with a mouse and keyboard in response to\nrandomly appearing targets. They first gathered keyboard & mouse data of 40 LoL players, including 20 highly\nskilled and 20 low-skilled players. After comparing the best scores of each group, they then found 17 variables\nsignificantly different between the two groups and concluded that MPGA could discriminate between high-skilled\nLoL players and low-skilled players successfully. Investigators in [32] recorded the mouse and keyboard data of 34\nRed Eclipse game players divided into four classes based on their skill levels. Using features extracted from 60\nseconds of the game, they reported a classification accuracy of 76%. However, they did not report the binary\nclassification results. In another study [10], the mouse and keyboard data of 22 players, including 4 professional, 11\nhardcore, and 7 casual amateur players, were gathered while playing the CS: GO game. A recursive feature selection\ntechnique was then used to determine the top 10 most important features for the characterization of the players. After\nanalyzing the selected features, they found that the difference between amateur players and professional players\ncould be characterized using the same features as the differences between amateur players of different skill levels.\nHowever, they also found that professional players of different skill levels could not be classified using the same\nfeatures. Although they tried to alleviate the effect of imbalance in the dataset using a comparable number of"}, {"title": "3 Methodology", "content": "3.1 Dataset\nIn this paper, we use a dataset presented by [12] and publicly available for download on GitHub [36]. The dataset\nis collected from 10 LoL players, organized into one amateur team and one professional team, including 5 amateur\nplayers and 5 professional players, respectively. Each team played up to 4 matches on 3 different days either versus\nbots or real opponents from the internet, while data from 12 sensors as well as environmental data such as\ntemperature, pressure, altitude, humidity, and CO2 level were gathered using a smart chair and a set of wearable\nsensors. In total, 21 matches were played, 10\nmatches by professional players and 11 matches by amateur players. Therefore, up to 21 \u00d7 5 \u00d7 12 = 1260 sensor\ndata were gathered approximately, where each sensor data corresponds to the data gathered from a specific sensor\nattached to a specific player playing a specific match. After gathering the sensor data, the outliers for each sensor\nwere removed, and then the signal was smoothed using an exponential moving average. Finally, all signals were\nresampled to a unified timestep of 1 second by averaging or summation, depending on the nature of the source\nsensor data. In addition to the sensor data, 2 other types of data were also gathered from in-game logs and surveys\nfrom each team member in each match. The in-game data, collected using the Riot API, include information about\nthe key game events, including kill, death, and assist events, referred to as \u201cmoments of interest\" (MoI) in this paper.\nThe list of the sensor data used in simulations and their description are shown in Table 1.\n3.2 STE\nSTE provides a robust, convenient, and computationally efficient measure to evaluate the flow of information in\ndynamic and multidimensional systems. This method is capable of measuring the strength and direction of\ninformation flow between time series recorded from structurally identical and nonidentical coupled systems\n(here, sensors of different types) using a technique known as symbolization. The STE is a directed measure. A large\ntransfer entropy from x to y indicates that the past values of x help predict the current values of y, whereas a small\ntransfer entropy indicates that the current value of y is independent of the past values of x.\nConsider two time series X = (x1, x2, ..., XN) and Y = (Y1, Y2, \u2026, yn) where xi and y\u2081 are the ith time samples\nthat are measured from two sensors. STE estimates the transfer of information between X and Y by symbolizing their\nrecorded amplitude values. For this purpose, first for each given i, the m amplitudes Xi = {xi; Xi+d; ...; Xi+(m-1)d}\nare arranged in an ascending order as Xi = {Xi+(ki1-1)d < Xi+(ki2-1)d < \u2026 < Xi+(kim-1)d} where d is the time\ndelay and m is the embedding dimension, which shows the length of the comparing segments. A symbol sequence\nXi = {ki1; ki2; ... ; kim} is then generated from Xi where kij, j = 1,2, ..., m are the indices of the elements of X. \nSTE is then calculated from the two symbol sequences, X\u2081 and Y\u00bf as follows [37]\n$\\T\u0177x = \u2211p(Xi+t, Xi, Yi)log2 \\frac{p(Xi+t|Xi)}{p(Xi+t|Xi , Yi)}$                              (1)\nIn this paper, we use STE to measure the directed flow of information from the ith sensor to the jth sensor where\ni, j\u2208 {1,2, ...,12}.\n3.3 Proposed ML algorithm\n3.3.1 Data preprocessing\nUsing the entire recorded signal will include a significant amount of noise in calculations since not all parts of\nsignals carry considerable information. The possible features that differentiate between players could be captured\nbest when the players react to an event. For example, players' skills in working with keyboards could be observed\nbetter when they react to a game event. Otherwise, there is no considerable difference between players' keyboard\ndata. In the LoL game, the key moments when players need to make decisions and react are Kill, Death, and Assist\nevents, i.e., MoI. For this reason, we extract sensor data before, after, and at Mol using time windows of length 2td,"}, {"title": "3.3.2 Feature extraction", "content": "The STE feature Sij representing the connectivity between sensors i and j can be calculated using (1) and\nsequences of extracted data in (3a) and (3b). Since we use 12 sensors in simulations, the total number of STE\nfeatures calculated for each player in each match is N = 12 \u00d7 12 = 144. Whenever the number of events in a\nmatch was large, we broke the sequence of events into Ks subsequences containing extracted data of between 4-10\nevents and then calculated the STE features. This resulted in Ks samples of length Ne for that match.\n3.3.3 Feature selection\nThe number of extracted features from the previous stage is large, and it does not meet our final goal of finding\nthe most distinguishing features that differentiate professional players from amateur players. Moreover, using a large\nnumber of features for classification will cause the underlying ML algorithm to overfit easily. For this reason, in this\nstep, we select the N, most relevant features out of all Nc features that are finally used for classification.\nThe existing feature selection methods, such as the mRMR technique [21], mainly rank features according to their\nimportance. However, the optimum number of features for classification remains a challenge for scientists. This\nissue is grave for our problem as we need to determine the exact optimum features. To overcome this problem, we\napplied a feature selection procedure using the mRMR and CN-CV methods as follows:\nStep 1: The training data are first divided into Ktrain folds.\nStep 2: One of the folds is removed, and the remaining Kall 1 folds are merged into a fold, referred to as the outer\ntraining fold Ko\u2081 (i = 1,2,3, ..., Ktrain).\nStep 3: The outer training fold Ko\u2081 is divided into L inner fold.\nStep 4: For each outer training fold Ko\u2081, the mRMR feature selection is applied to each of its inner folds l (l = 1, 2,\n..., L) to find the N\u012f (i = 1,2,3, ..., Ktrain) most relevant features.\nStep 5: Features with the highest frequencies across all inner folds are then selected for the related outer training\nfold Koi\nStep 6: Repeat Steps 1-5 until all Ktrain are removed once.\nStep 7: The N, most common features (i. e. features with the highest frequencies) across all the Ko\u2081 outer folds are\nfinally selected as the consensus features.\nThe CN-CV method proved computationally more efficient than its predecessor the nested cross-validation (NCV)\nsince it selects the features without training a classifier. It also selects fewer irrelevant features compared to the NCV\nmethod [20]. Another advantage of CN-CV is that we do not need to be precise in setting Ni in Step 4. If some\nirrelevant features are selected when setting Ni, they will be automatically removed when selecting the consensus\nfeatures.\n3.3.4 Classification and evaluation\nIn this step, the ML model was trained on the training data using the N, selected features, and enough care was\ntaken to test the model on a separate unseen dataset. For this purpose, we used a Kall-fold cross validation (CV) to\nevaluate the model's classification performance on the entire dataset (including both testing data and training data).\nIn this condition, one of the folds is reserved for testing, and the feature selection procedure will be applied to the\nremaining Kall 1 folds, and this process continues until all folds are used for testing once. We evaluated the\nclassification performance using three classifiers, including SVM, random forest (RF), and K-nearest neighbors\n(KNN). Applying these classifiers makes it easier to compare our results with previous studies that used the same\ndataset and classifiers [11].\n3.3.5 The most distinguishing features\nTo find the most distinguishing features in the classification of eSports players' skill levels, we used two methods:\nin the first method, we applied the proposed feature selection to the entire dataset. In the second method, we used the\nresults of the Kall-fold CV from the previous section. Applying the Kall-fold CV results in Nr\u2081, Nr\u2081, Nr\u2081, \u2026, NrKall\nselected features when the 1st, 2nd, 3rd, and Kallth fold is used for testing, respectively. The most distinguishing\nfeatures were then found using the intersection of all Kall feature sets as follows:\n$S = \\bigcap_{j=1}^{Kall} Si$ (4)"}, {"title": "3.3.6 Setting ta", "content": "To set hyperparameters t\u0105, we implemented an 8-step procedure as follows:\nStep 1: Set ta = 1 and calculate STE features. Split dataset into Kall folds. These folds correspond to the same folds\nthat will be used for the model evaluation in section 3.3.4.\nStep 2: Remove one of the folds and merge the rest. Then split the merged data into 80% data for training and 20%\ndata for validation.\nStep 3: Apply the proposed feature selection method to 80% training data and use the selected features to train the\nmodel.\nStep 4: Evaluate the trained model using the 20% validation data.\nStep 5: Increase ta by a step value of one and repeat Steps 1-4 until ta = 10.\nStep 6: Select ta that produced the best results on the validation data.\nStep 7: Repeat Steps 1-6 until all Kall folds are removed once. This will produce Kall values for ta.\nStep 8: Calculate the average ta over all Kall folds.\nThe STE features are then recalculated using the selected ta. These features were finally used for feature selection\nand classification."}, {"title": "4 Results", "content": "In this section, we present the results of the proposed algorithm in finding the players most distinguishing features\nand classifying their skill levels. To prepare data, we extracted different events in each game played by each player\nand broke down the sequence of events into two subsequences (K\u2081 = 2) for amateur players and three subsequences\n(Ks = 3) for professional players. This was because the number of events for professional players was higher than\nfor amateur players. Therefore, each match for each amateur player and professional player resulted in 2 and 3\nsamples of length 144 respectively. Since 11 and 10 games were played by amateur players and professional players\nand there were 5 players in each match, this approximately resulted in up to 110 and 150 samples of length 144 for\namateur players and professional players, respectively. However, to prevent the imbalance in the training dataset, we\nused 110 samples for both the amateur and professional classes.\n4.1 The most distinguishing features\nshows the top 8 STE connectivity features selected from all 144 STE features. As can be seen, most of the\nselected features are related to the connectivity between the eye tracker sensor and other sensors, including mouse,\nkeyboard, and hand activities. Therefore, our results suggest that the consistency between eyes and hand activities\nmay be a decisive factor in distinguishing elite players from lower-rank players. The connectivity between keyboard\nand mouse activities, and between left hand and right hand activities are also among the selected features. This could\nindicate that professional players have better harmony between their left and right hands that work with keyboard\nand mouse, respectively.\nHand activity features, i.e. LHMA and RHMA, should not be mistaken with hand movement features, i.e. LHM\nand RHM. The LHMA and RHMA features represent muscle tension in players' reactions to the game events, but\nthe LHM and RHM features represent players' hand movements while reacting to the game events. While\nconnectivity between gaze position and hand muscle activities are among the top features, there are no features\nformed of hand movements. This shows that the difference in reaction time, which is the time lapse between\nobserving an event and reacting to it, between professional and amateur players is more significant than the\ndifference between how they react to the game events. This is also reflected in the mouse activity feature. While the\nnumber of mouse clicks is an element in features 2, 6, and 7, the distance passed by the mouse does not exist in any\nof the top features. This further emphasizes that the intensity and speed of players' reactions are more discriminating\nthan how they react. Most players, whether they are professional or amateur, may know the correct movements and\nreactions. But whether they can swiftly apply their knowledge in a short time is a more decisive factor according to\nour results.\n4.2 Classification results\nFigure 5 illustrates the average accuracy of three classifiers, namely, SVM, RF, and K- KNN, using a five-fold CV\n(Kall = 5) and different ta values. To compare the effect of different game events' data on the results, we\nadditionally evaluated the classification performance when sensor data of only one game event, including kill, death,\nand assist, were used for classification individually. As can be seen, the best results were achieved using t\u0105 values of\n4, 3, 4, and 4 when we used kill data, death data, assist data, and all events' data, respectively. In all cases, the\nproposed method with the optimum ta outperformed the previous method that reported a maximum accuracy of\n85.6% using the same dataset [11]. As can be seen, for all classifiers, when the sensor data of all events are used for\nclassification, the proposed method performs better than when only one event's data are used. This could be mainly\ndue to the decrease in the number of training samples. Insufficient samples also affected the noise sensitivity of the\nalgorithm such that the classifiers' performance started dropping at a smaller t\u0105 value (i. e., ta = 3) when only death\ndata were used for training (Figure 5b). The death event had the lowest frequency, and consequently, the lowest\nnumber of samples in the training dataset among other events. A similar effect can also be seen when other events'\ndata are individually used for training, as the classification performance drops more abruptly in these cases by\nincreasing ta. Since we include noisier data with lower SNR in the training dataset by increasing ta, this early drop\nin the performance could indicate that the results are impacted by noise more easily than when sufficient samples\nwere used. The overall results using all events' data show that, on average, 5 seconds before and after each event, the\neffect of noise and irrelevant data prevails, and the sensor data at these points include negligible information about\nthe players' skills. Also, the performance of classifiers does not rise and drop symmetrically with ta values smaller\nand greater than 4. The decrease in the classifiers' performance with ta > 4 happens faster compared to its rise\nwhen ta < 4. This in turn shows that data gathered at time points closer to the game events contain more relevant\ninformation about the players' skill than the data gathered at time points far from the game events. The accuracy of\nthe classification using only kill and assist data is close, and the performance graphs show nearly the same pattern\n(Figure 5a and Figure 5c). This could be because the numbers of kill and assist events were close, and the EEG data\nfluctuations at these events were similar. Also, the overall performance looks more like the kill and assist\nclassification performance graph than the death classification performance graph. This could mean that kill and\nassist events carry more information about the players' skills than death events."}, {"title": "5 Discussion", "content": "Sensor data proved to be effective in evaluating the skills of eSports players. However, there is not currently a\nreliable method to find the features that distinguish high-skilled players from low-skilled players. In this paper, we\nproposed a novel method to find these features and use them to classify the players into two groups: professional and\namateur. For this purpose, we incorporated the relationship between different body parts into the classification stage\nusing sensor data and the STE feature extraction method. To the best of our knowledge, this is the first study using\nconnectivity features for the classification of eSports players.\nThe proposed method significantly outperformed the previous study using the same dataset and classifiers [11].\nAlso, the features representing the connectivity between the eye tracker sensor data, in particular the gaze position,\nand other sensor data, including keyboard, mouse, and hand activities, proved to be the most discriminating features\nbetween amateur players and professional players. These results suggest that the consistency between eyes and\nhands in professional players is a decisive factor distinguishing them from amateur players. Therefore, our results\nconfirm the output of other studies [14, 28] that found a significant relationship between gaze position and the\nperformance of players. However, these studies investigated the gaze data individually. According to our results, the\nconnectivity between keyboard and mouse movements and between left and right hands are also among the top\ndiscriminating features in classifying players' skills. This, in turn, shows that the consistency and harmony between\ntwo hands working with the mouse and keyboard could play a significant role in the players' performance.\nInvestigator [12] used the same dataset and found that mouse clicks and the distance passed by the mouse are among\nthe features indicating players' higher chance of winning in the next encounter. However, according to our results,\nthe distance passed by the mouse is not among the most important features. They also found that heart rate is a\ndecisive factor, but our simulations do not show that heart rate has a significant effect on the classification\nperformance. In the end, they achieved a low accuracy of 73.5% in predicting whether a player will lose the\nencounter occurring in 10 s. A similar research work is presented in [11]. In their study, a combination of 11 sensor\ndata was employed to distinguish players of two skill levels, and a total classification accuracy of 85.6% was\nreported. However, in both previous studies, the gaze position was not among the most important features. In [11]\nthey even observed a negligible correlation between the gaze positions of eSports players of the same skill level.\nThis is mainly because the gaze position in their studies is considered individually without its relationship with other\nsensor data being factored in. Since the players' gaze positions may vary considerably according to the gameplay\nand the role they are playing, the correlations between different players' gaze data are expectedly minimal. This is\nwhile, according to our results, the gaze position emerges as an important factor when its connectivity with other\nsensor data is factored in.\nThe ML algorithm proposed in this paper is not dependent on the sensor type or game platform. Future work could\napply the proposed method to other types of sensors in other games or applications, such as the evaluation of\nsportspeople's skills. For this purpose, the sensor data could be collected using different experiments, including\nevoked potentials test, alertness behaviour task (ABT), and concentration cognitive task (CCT). Examples of such\ndatasets have already been presented in a few studies [38]. The high accuracy of the proposed method and its ability\nto extract the distinguishing features of professional players make it a promising tool for such applications."}, {"title": "6 Conclusion", "content": "We presented an efficient machine learning algorithm to find the features that distinguish professional players\nfrom amateur players in the LoL game and used them to classify the players' skill levels. For this purpose, we\ncalculated STE features to incorporate harmony between body parts and then used the CN-CV method to select the\nmost distinguishing features. The proposed method improved the classification accuracy compared to the previous\nstudy using the same dataset and classifiers and achieved an accuracy of 90.3%. The selected features provided\nmeaningful insight into the characteristics setting professional players apart. Features representing the swiftness of\nplayers' reactions, such as connectivity between eyes (gaze positions) and hand muscle activities and between eyes\nand mouse and keyboard activities proved more decisive according to the results. The proposed method benefits\ngame designers by providing better accuracy for DDA applications and will significantly help coaches design a more\nefficient training program for players. Since the proposed method in this paper is not dependent on the game\nsettings and sensor types, it could also be applied to other video games and be a promising tool to evaluate\nsportspeople's skills. Therefore, this study could be regarded as a stepping stone to a future with bespoke training\nprograms and intelligent game designs customized to the needs of players of different skills and abilities."}]}