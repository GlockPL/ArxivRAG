{"title": "(Neural-Symbolic) Machine Learning for Inconsistency Measurement", "authors": ["Sven Weinzierl", "Carl Corea"], "abstract": "We present machine-learning-based approaches for\ndetermining the degree of inconsistency\u2013which is\na numerical value\u2013for propositional logic knowl-\nedge bases. Specifically, we present regression- and\nneural-based models that learn to predict the values\nthat the inconsistency measures IMI and Iat would\nassign to propositional logic knowledge bases. Our\nmain motivation is that computing these values\nconventionally can be hard complexity-wise. As\nan important addition, we use specific postulates,\nthat is, properties, of the underlying inconsistency\nmeasures to infer symbolic rules, which we com-\nbine with the learning-based models in the form of\nconstraints. We perform various experiments and\nshow that a) predicting the degree values is feasible\nin many situations, and b) including the symbolic\nconstraints deduced from the rationality postulates\nincreases the prediction quality.", "sections": [{"title": "1 Introduction", "content": "Inconsistency in information is a core problem in many AI\nand knowledge representation tasks. Unfortunately, while\nthere are many results on how to measure and analyze incon-\nsistency (see [Thimm, 2019b]), computing such results on a\nsymbolic level can be hard complexity-wise. In this work, we\ntherefore present machine learning-based approaches for in-\nconsistency measurement, specifically, predicting the degree\nof inconsistency w.r.t. inconsistency measures. This allows-\nafter training-to obtain degree values for specific knowledge\nbases in constant time.\nAn inconsistency measure is any measure that can quantify\nthe severity of inconsistency in information with a numerical\nvalue. In this work, we refer to inconsistency measures for\npropositional logic knowledge bases. As an example, con-\nsider the knowledge bases K1, K2, defined via\nK\u2081 = {a, \u00aba}, K2 = {a, \u00aba, a \u2192 b, \u00abb^ c}.\nObviously, both knowledge bases are inconsistent, however,\nthe granularity of the inconsistency is arguably different: For\nK1, there is only one conflict {a, \u00aca}, but for K2 we have two\nconflicts, namely {a, \u00aca} and {a, a \u2192 b, \u00abb^ c}. To quan-\ntify the degree of inconsistency, various measures have been\nproposed, one of them being the IMI measure, which counts\nthe number of \u201cminimal inconsistent subsets\u201d (see conflict-\ning sets above). So here we have that IMI(K1) = 1 and\nIMI(K2) = 2. In this sense, the inconsistency in K2 can be\nseen as \u201cmore severe\u201d than that in K\u2081.\nInconsistency measurement has gained a nice momentum,\nhowever, a problem for application is that many measures\nare hard to compute computationally [Thimm and Wallner,\n2019]. This is especially problematic for settings where a\nhigh number of instances have to be assessed continuously,\nas shown in Figure 1. In domains such as the financial in-\ndustry or fraud management, it is common that a shared set\nof business rules is evaluated against high amounts of case-\ndependent input (e.g., think of a customer loan application)."}, {"title": "2 Preliminaries", "content": "Let At be some fixed set of propositions, and let L(At) be a\ncorresponding propositional language constructed using the\nusual connectives (conjunction), V (disjunction), and \u00ac\n(negation). A literal is a proposition p or its negation \u00acp.\nDefinition 1 (Knowledge Base (KB)). A knowledge base K\nis a finite set of formulas K \u2286 L(At). Let K be the set of all\nknowledge bases.\nFor a KB X, we denote the propositions in X by At(X).\nThe semantics for a propositional language is given by in-\nterpretations where an interpretation w on At is a function\n\u03c9 : At \u2192 {0,1} (where 0 stands for false and 1 stands for\ntrue). Let \u03a9(At) denote the set of all interpretations for At.\nAn interpretation w satisfies (or is a model of) an atom a \u2208 At,\ndenoted by w = a, if and only if w(a) = 1. The satisfac-\ntion relation is extended to formulas in the usual way. For\n\u03a6\u2286 L(At) we also define w = \u03a6 if and only if w = $ for\nevery \u03a6 \u0395 \u03a6.\nFor every set of formulas X, we denote the set of models\nas Mod(X) = {\u03c9 \u2208 \u03a9(At) | w = X}. If Mod(X) = 0,\nwe write X 1 and say that X is inconsistent. A set X that\nis inconsistent and minimal in terms of set inclusion is called\nminimally inconsistent.\nDefinition 2 (Minimal Inconsistent Subset). Let a knowledge\nbase K, a set M C K is called a minimal inconsistent subset\n(MIS) of K if M =1 and there is no M' C M with M' =1.\nLet MI(K) be the set of all MISs of K.\nAny formula a \u2208 K that appears in at least one MIS of K\nis called problematic (denote Problematic(K) as the set of\nall problematic formulas in K).\nExample 1. Let K = {a,b, \u00abb, c, \u00acc, d \u2228 e} then MI(K) =\n{{b, \u00abb}, {c, \u00abc}}, and Problematic(K) = {b, \u00abb, c, \u00abc}.\nFor quantifying the degree of inconsistency, we consider\ninconsistency measures I, which are functions that assign to\na knowledge base a non-negative numerical value (a higher\nvalue referring to a higher degree of inconsistency). Incon-\nsistency measures are commonly divided into formula-centric\nmeasures, and atom-centic measures, where the former focus\non individual formulas, and the latter are defined over the sig-\nnature (propositional atoms) of the knowledge base [Hunter\nand Konieczny, 2005]. Examples of concrete measures of\nthese two groups are the IMI measure (formula-centric), and\nthe Iat measure (atom-centric), respectively, which are de-\nfined as follows (adapted from [Grant, 2021]).\nDefinition 3 (Considered Measures). Let K be a knowledge\nbase, then define the following two inconsistency measures:\n\u2022 IMI(K) = |MI(K)|\n\u2022 Iat(K) = |At(Problematic(K))|\nMany other measures have been proposed, see [Thimm,\n2019b]. For the remainder of this work, we will, however,\nonly focus on the two introduced measures Imi and Iat, as\nthey are prominent representatives of formula- and atom-\ncentric measures and can therefore provide insights for ap-\nproximating measures of these two groups. Also, note that the\ncomputation of Zat and Im\u0131 is on the second, resp., above the\nthird, level of the polynomial hierarchy [Thimm and Wallner,\n2019], so these measures represent good candidates for as-\nsessing whether a machine learning-based approach can yield\nsignificant performance boosts.\nA final remark on inconsistency measures is that many\nproperties of these measures have been studied (see e.g.\n[Thimm, 2018]). These properties describe the general be-\nhavior of the measures, respectively, their values \u2013 for exam-\nple, under which conditions a measure will return 0, or what\npossible values the measure can attain. We will revisit some\nof these properties in Section 5.2 and show how the yielded\ndomain knowledge can be leveraged to impose symbolic con-\nstraints for the\u2014otherwise sub-symbolic-models."}, {"title": "3 Problem Setup", "content": "To compute inconsistency degree values with a machine\nlearning-based approach, we pose the problem of computing\nthese values as a regression problem. For this, let K be a\nknowledge base and I be an inconsistency measure. Then,\nour goal is to approximate a function f\u2081 mapping the knowl-\nedge base K to a numerical value f1(K), which denotes the\ninconsistency degree value of K w.r.t. I.\nFor representing knowledge bases, we turn to an encoding-\nbased approach. For this, let L(At) be a propositional lan-\nguage over At as before, and let N = N1, ..., Nn be a se-\nquence of distinct formulas from L(At). Then, for an indi-\nvidual knowledge base K and a sequence of words N (both\nover L(At)), an encoding can be defined by considering an\n|N|-dimensional vector Vk s.t.\nVx[j] =\n{\n1 if N; \u2208 K,\n0 otherwise.\nWe investigate the scalability of this encoding-based tech-\nnique in Section 7."}, {"title": "4 Machine Learning Models", "content": "The machine learning models presented in this paper are (tra-\nditional) regression-based models and neural-based models.\nThey are learned in a supervised way with machine learning\nalgorithms on data sets, where the data consists of knowledge\nbases represented as feature vectors, and the label is the in-\nconsistency measure Im\u0131 or Iat.\nWe differ between four machine learning models. The first\nthree models are regression-based and built using the machine\nlearning algorithms linear regression (LR), ridge regression\n(Ridge), and lasso regression (Lasso). The linear regres-\nsion models the linear relationship between a label (depen-\ndent variable) and the features of the feature vectors (inde-\npendent variables). In doing so, the effect of each feature on\nthe model output is represented by a coefficient. The ridge\nregression is an extension of the linear regression and adds a\npenalty on the size of coefficients to prevent overfitting. The\nlasso regression reduces overfitting but can also perform fea-\nture selection by shrinking coefficients to zero.\nFor all three regression-based models, we differ between\ntwo variants: i) the feature vectors only including features de-\nscribing the propositional logic formulas, and ii) the feature\nvectors as in i) + additional features describing (symbolic)\ndomain knowledge (see Section 5.2). To clarify, these ad-\nditional features are binary features encoding some external\nproperty, where the value 0/1 indicates whether this property\nholds for the KB instance. We refer to the variants i/ii) as\nwithout/with flags.\nThe last model is built with a multi-layer perceptron\n(MLP). The MLP consists of three fully-connected (dense)\nlayers. The first layer is the input layer, which maps the in-\nput to a hidden state. The second one is a hidden layer and\nmaps the hidden state from the previous layer to a more ab-\nstract hidden state. The last layer maps the hidden state of\nthe previous layer to the final prediction. In addition, a tanh\nactivation function is applied to the output of the first layer\nand the second layer to model non-linearities.\nFor this model, we differ between three variants. The first\ntwo are similar to the variants of the regression-based mod-\nels, that is, i) only the KB data without flags, and ii) KB data\nwith additional features encoding domain knowledge. The\nthird variant is an extension of the second one and considers\nsymbolic domain knowledge in two respects: i) via flags in\nthe feature vectors, and ii) via external constraints in a cus-\ntomized loss function. The customized loss L* used in our\nMLP models is formalized as\nL* =\nEpred\nPrediction loss\n+ Chr,1 ++ Lhr,i + \u00b7\u00b7\u00b7 + Lhr,N,\n(Symbolic) domain knowledge loss\n(1)\nwhere Lpred is the prediction loss calculated as L1 loss,\nN is the number of heuristics (i.e., external constraints), and\nChr, i is the loss for the i-th heuristic of the (symbolic) domain\nknowledge. Chr,i is defined by\nLpred * Thr,i,\n(2)\nwhere Thr,i is the arithmetic mean of the binary values of\nthe feature Xhr,i, describing the i-th heuristic of the (sym-\nbolic) domain knowledge.\nFurther, if a heuristic i is described by J features, first,\nEpred * Thr,i',\n(3)\nis calculated per feature j, denoting Chr,i, and then\n\u2211Lhr,i' =\u2211j=1JChr,i',(4)\nis calculated, denoting the sum of the losses over the J\nfeatures describing the i-th heuristic.\nIn general, since the goal of the training procedure is to find\nthe best values of model parameters (i.e., biases and weights)\nthat minimize the custom loss function, the model parameters\nare also adjusted depending on external constraints defined in\nthe custom loss function.\nTo clarify, the second and third variants of the MLP\ncan be considered a neuro-symbolic approach as here sym-\nbolic knowledge is used for building neural network models\n[Kautz, 2022]. The difference is how the domain knowledge\nis integrated. That is, for variant ii), integrated into the fea-\nture vector of the data, and for variant iii), integrated into the\nmodel via the custom loss function.\n5\nIn summary, the considere models are as follows:\n1. LR (with/without flags in feature vector)\n2. Ridge (with/without flags in feature vector)\n3. Lasso (with/without flags in feature vector)\n4. MLP (with/without flags in feature vector; with flags in\nfeature vector and constraints in loss function)"}, {"title": "5 Experimental Setup", "content": "In this section, we continue to describe the data set genera-\ntion, the applied symbolic rules/heuristics (\u201cflags\u201d), and the\ntraining configuration of our experiments.\u00b9\n5.1 Data Set Generation\nWe implemented a generator for creating synthetic knowl-\nedge bases. Importantly, the Tweety-library\u00b2 could be used\nfor computing the inconsistency measures with a conven-\ntional solver-based approach (the exact solver is discussed in\nSection 6.1). So for all knowledge bases, we have the actual\nvalue of IMI/Iat as ground truth in the data set (i.e., a triple\n(K,IMI(K), Imv(K))). For knowledge base creation w.r.t. a\nset of atoms At, formulas of the knowledge base were cre-\nated via the following syntax:\n6 ::= 1 | 41 \u2228 21 2\n(5)\nwhere l is a literal (i.e., a simple atom or its negated form)\nover At. In other words, we consider a general propositional\nlogic where every formula consists of an arbitrary amount\nof literals that can be combined arbitrarily with V/A. For\ngenerating the knowledge bases, we considered as parame-\nters the number of distinct atoms in At from {3,6,9} and\nthe number of distinct formulas per knowledge base from\n{\u2264 5, \u2264 10, \u2264 15}. As a design choice, every formula had at\nmost 10 con-/disjuncts."}, {"title": "5.2 Symbolic Rules/Heuristics", "content": "As a basis for our approach, the machine learning models will\nbe trained on the knowledge base data itself. However, we are\nalso interested in how adding (symbolic) domain knowledge\ncan improve the predictions. For this, we revisit the following\nrationality postulates.\nUpper Bound. The first symbolic rule is in regard to the\nso-called expressivity of the considered inconsistency\nEntropy is a measure of the \u201cspread\" of values that an inconsis-\ntency measure assigns to a sequence of knowledge bases [Thimm,\n2019a]. Let an inconsistency measure I and a sequence of knowl-\nedge bases K = K1, ..., Kn, and denote I = I(K1), ..., I(Kn) as a\nsequence of values I(K\u2081) over all elements of K; with IU being the\nset of unique values in I. Then, the entropy of all measure values\nH(K, I) is defined as H(K,I) =\n\u2211v\u2208I\u03c5fulnfn, where fo\nK\nis the frequency of v in I and In is the natural logarithm.\nfu\nK\nLet KAt(n) = {K \u2208 K | |At(K)| \u2264 n} be the set of all\nknowledge bases with at most n atoms, then, the expressivity e of\nan inconsistency measure I w.r.t. a number of atoms n is defined as\ne(I, n) = |{I(K)|K\u2208 KAt(n)}|.\nmeasures [Thimm, 2016]. To recall, the range of val-\nues that can be returned by Iat is limited by the num-\nber of atoms. So any prediction should never exceed\nthis value. For the feature vector VK, we, therefore, add\na feature \u201cupper-bound-x\u201d, where x is the number of\ndistinct atoms in K and the upper-bound indicates the\ncorrect inconsistency degree value w.r.t. Zat is bounded\nby x. The goal of this rule is to see whether the machine\nlearning-based approaches can leverage this insight to\npenalize all predictions > X. Note that for the Imi mea-\nsure, the number of values that can be attained w.r.t. the\nnumber of formulas grows binomial [Thimm, 2016], so\nthe upper-bound flag is likely not useful in vectors for\nIMI (and we only use it for Iat).\nConsistency (Heuristic). The second symbolic rule is about\nconsistent knowledge bases: If K is consistent, any in-\nconsistency degree value, or prediction, must be 0 (both\nfor Im\u0131 and Iat). For generating domain knowledge on\nconsistency, a core problem is that we do not want to per-\nform any form of (computationally expensive) solving.\nSo the general information on whether an input knowl-\nedge base is consistent is not available in our setting.\nHowever, for the considered propositional logic, we can\napply the following heuristic to correctly flag at least\nsome consistent knowledge bases: Let K be a knowl-\nedge base, then by definition, a set of formulas Kis\ninconsistent if its smallest closed set of literals contains\na, a for an atom. Thus, if for any K, we do not have\nany atom a which is present in simple and negated form,\nK cannot be inconsistent (For example, we can infer that\n{a, b\u2227 c, d} cannot be inconsistent as it does not con-\ntain an atom present in both forms as described). So for\nthe feature vector Vk, we add a feature \u201cconsistent\u201d,\nwhich is true if K does not contain a pair of literals a, \u00aca\nover all atoms as described. In this case, the correct in-\nconsistency degree value must be 0. The goal of this rule\nis to see whether the approaches can leverage this insight\nto penalize all predictions > 0 in this case."}, {"title": "5.3 Training Configuration", "content": "We performed a ten-fold cross-validation with random shuf-\nfling for each data set and machine learning approach. We\nfurther split the training set of each fold into a validation set\nhaving the same size as the test set and a subtraining set in-\ncluding the remaining instances of the training set to perform\na hyperparameter optimization in the form of a grid search. In\nparticular, we fitted multiple machine learning models on the\ntraining set, selected the model with the best validation mean\nabsolute error (MAE), and applied this model to the test set.\nThe hyperparameters used in the grid search can be found in\nthe appendix.\nTo measure the prediction performance of the machine\nlearning models, we first calculated an MAE value for each\ntest set, and subsequently the average and the standard devia-\ntion across all of the MAE values. We selected the MAE be-\ncause our machine learning models address a regression task\nand it is commonly used for this type of task.\nFor the MLPs, which are neural networks, we addressed\nthe common problem of overfitting the training criterion in"}, {"title": "6 Results", "content": "6.1 Experiment Results\nThe experiment results are shown in tables 2 and 3. The MAE\nindicates that the models can produce good predictions for\nthe intended use case. Take for example the IMI measure and\nthe dataset for the setting \u201c3 atoms/15 formulas\u201d: For this\ndataset, the actual ground truth values of ZMI ranged between\n0-51. Here, having a (predicted) value that deviates on aver-\nage only 0.547 from the ground truth value may be a valuable\napproximation in many settings, for example, for ranking in-\nconsistencies by their severity.\nThe results for both measures further indicate that the neu-\nral network architecture (MLP) achieves the best MAE values\nin all settings. This shows that the MLPs are able to detect\nnon-linearities that exist in the data and are therefore more\nsuitable than the baseline regressions in our setting.\nFor both measures, all MLP models with flags outperform\ntheir MLP counterparts without flags. This is a key out-\ncome of our experiments, as it shows that incorporating do-\nmain knowledge in the form of symbolic constraints can in-\ndeed improve prediction performance. This is exemplified in\nFigure 2, which shows Shapley Additive eXplanation Values\n(SHAP) for an exemplary prediction instance where symbolic\nknowledge was added in the feature vector.\nThe knowledge base instance predicted for Figure 2 was\n{\u00abb, \u00abc, \u00abb\u00abc}, which is consistent (and the corresponding\n\u201cconsistent\u201d flag could be set for the example). The shown\nSHAP values can be read s.t. the concrete values indicate the\nimpact of the respective feature on the prediction outcome\n[Molnar, 2020]. As can be seen, the feature corresponding\nto the \u201cconsistent\u201d flag (set to 1 for the instance) has by far\nthe highest impact on the prediction outcome. The model thus\nrecognized this flag as an important feature for the prediction.\nWe continue with results about the experiment runtimes.\nRecalling one of the main motivations of this work, a\nproblem of computing the inconsistency measure values\nconventionally-especially in the envisaged continuous set-\nting from the introduction is that it may be computationally\nexpensive. This is further underlined by the results shown in\nFigure 3."}, {"title": "6.2 Discussion", "content": "Based on our experiments, the machine learning approaches\ncould successfully be applied to predict inconsistent measure\nvalues for the analyzed data sets. In this section, we discuss\nthe generalizability of our results.\nA general problem for machine-learning-based approaches\nis that of overfitting. In our experiments, we addressed this\nproblem in three regards. First, we integrated a weight decay\nregularization into the training procedure of the MLPs. Sec-\nond, we applied early stopping in the training procedure of\nthe MLPs, with a patience of ten epochs and the validation\nMAE as the stopping criterion. This ensures that the models\nstop training before they learn data-specific patterns too well.\nThird, we performed a ten-fold cross-validation and repeat-\nedly tested the models' ability to generalize from the training\ndata to unseen data.\nA limitation (by design) is that labeled training data needs\nto be available. However, for the envisaged setting, there is\na need to continuously compute inconsistency degree values.\nSo it seems plausible that a couple of instances have to be\nsolved anyway first, which can then be leveraged with our\napproach. Intuitively, for such an ML-based approach, one\nhas to pay attention to issues such as distribution shift. Re-\nlated to this, note that it is not necessary to know all distinct\nformulas in advance (e.g., this was exactly the case in all ex-\nperiments, where some formulas from the test set were not\nin the training set). These formulas are fitted as new features,\nand the scalability results from Section 7 show how (well) the\nconsidered models could work with this. In cases of heavy\ndistribution shift over time, naturally, it might at some point\nbe necessary to retrain models. Determining this is however\nbeyond the scope of this paper. The field of lifelong machine\nlearning (or continual or incremental machine learning) pro-\nvides approaches to relax this limitation by further training\nand adapting machine learning models over time.\nFinally, regarding the considered learning approaches in\ngeneral, a limitation is that for regressions one assumption\nis that the relationship between the independent variables and\nthe dependent variable is linear, that is, expanding infinitely.\nIn our setting, however, some of the target variables are\nbounded, and in general, all target values are non-negative.\nSo the assumptions of this model type might not be aligned\nwith our use cases. Nevertheless, in this context, we demon-\nstrated that other model types with matching assumptions can\nbe successfully applied.\nIn our experiments, we found that a careful definition and\nintegration of knowledge into the models is necessary to\nimprove the prediction performance. In particular, for the\nMLPs, we integrated knowledge as flags in the feature vec-\ntor and constraints in the loss function used in model train-\ning. According to our results, models with only flags in the\nfeature vector and models with both flags in the feature vec-\ntor and constraints in the loss function outperform all models\nwithout flags. However, the results can be different in other\ndomains. Thus, it is important to decide how knowledge is\ndefined and integrated into the models [Besold et al., 2017].\nIn future research, similar experiments should be repeated\nfor inconsistency measures based on completely different\nprinciples, such as distance-based measures or semantic mea-\nsures [Thimm, 2019b]."}, {"title": "7 Scalability", "content": "We performed additional experiments to test the scalability\nof the machine learning approaches presented in this work.\nAs scalability, we understand the ability of machine learning\nalgorithms to learn more accurate models from (and gener-\nally handle) higher amounts of data. In our case, an issue\nwe wanted to investigate in particular was the models abil-\nity to handle (larger amounts of) previously unseen formu-\nlas/features. For this, we conducted the following experi-\nment. Figure 4 shows the average MAE values for the ma-\nchine learning approaches with flags and constraints when\nthe size of the training set is extended from 1,000 to 9,000\nsamples. We can see that all approaches yield improvements\nin the prediction performance up to the largest training set of\n9,000 instances. In general, all model types did not face any\ntechnical issues when dealing with the larger feature vectors"}, {"title": "8 Related Work and Conclusion", "content": "Our work is related to approaches applying (sub-symbolic)\nlearning approaches to symbolic domains. In particular, our\napproach applies machine learning to the field of inconsis-\ntency measurement.\nMost related works concerning machine learning and\npropositional logic are on the level of satisfiability check-\ning. For example, works such as [Cameron et al., 2020;\nB\u00fcnz and Lamm, 2017] present approaches for using graph\nneural networks to predict satisfiability. In this work, we\nfocus on the measurement of inconsistency, which goes be-\nyond the binary satisfiability notion and aims to provide\nmore fine-grained insights. In this context, there are some\nrecent approaches that apply machine learning-based tech-\nniques to predict unsatisfiable cores in propositional logic\n[van Driel and Yorke-Smith, 2020; Selsam and Bj\u00f8rner, 2019;\nShirokikh et al., 2023], which are referred to as minimal in-\nconsistent subsets in this work. While such approaches could\nbe used to compute degree values for some inconsistency\nmeasures (those based on Mls), note that as stated many other\nmeasures are not based on unsatisfiable cores. So the prob-\nlem and architecture addressed in this work are more general\nin that it allows to provide target values for arbitrary inconsis-\ntency measures in the scope of model training. To the best of\nour knowledge, this work is the first to investigate the prob-\nlem of predicting degree values for inconsistency measures.\nFrom a machine learning perspective, related works in the\narea of ML4KR focus on deep learning architectures. So our\napproach seems in line with the architectures applied in re-\nlated works. It is notable here that graph neural networks\nhave been very successfully applied to represent propositional\nlogic for (predicting) satisfiability problems [Cameron et al.,\n2020; B\u00fcnz and Lamm, 2017]. Therefore, it seems promis-\ning to also try to use such neural network architectures for\nthe problem of inconsistency measurement, which we will\ninvestigate in future works. One factor in which our work\nis however very much aligned with related works (regardless\nof the architecture) is that there seems a consensus that com-\nbining symbolic constraints into the (various) deep-learning\narchitectures seems advisable in many concrete use-cases.\nThe inherent complexity of computing inconsistency\nmeasures has motivated various recent works to devise\nnovel algorithmic approaches [Kuhlmann and Thimm, 2021;\nKuhlmann et al., 2023]. In this context, this work proposes\na learning-based architecture. As a central distinction, the\nmachine learning-based approach allows after training\nto obtain approximations in constant time. We argue there\nmight well be various use cases where approximations are\nsufficient, especially in the envisaged continuous setting pre-\nsented in the Introduction. Our empirical evidence shows\nthat we could reach a clear break-even point as to where the\nmachine learning-based approach (including training) can be\nperformed in a faster time than with a conventional solver\n(see Figure 3).\nFor our concrete approach, we applied a binary encod-\ning for representing knowledge bases. In the case of larger\nknowledge bases, this might lead to large feature vectors.\nFrom Section 7 (Scalability), we could not identify any in-\nherent technical difficulties in handling larger feature vectors.\nStill, in future work, we aim to investigate additional means\nfor feature reduction that would allow us to reduce vector di-\nmensionality. Also, different encoding forms, such as encod-\ning knowledge with some form of abstraction, or graph neural\nnetworks, could be investigated.\nFinally, while the problem investigated in this work was\nframed as a regression problem, a related interesting prob-\nlem could be to classify two knowledge bases in which one\nis more inconsistent than the other. While this will not of-\nfer granular insights as in this work, there could still exist\nuse cases where this insight would be useful, and it might be\nsolvable with a simpler classification setup.\nIn general, it seems the areas of machine learning and in-\nconsistency measurement can be well aligned and may pro-\nvide further opportunities for future work."}, {"title": "Appendix", "content": "A grid search was performed to tune the hyperparameters of\nthe machine learning models. Table 4 summarizes the hyper-\nparameters used in the grid search."}]}