{"title": "Beyond Grid Data: Exploring Graph Neural Networks for Earth Observation", "authors": ["Shan Zhao", "Zhaiyu Chen", "Zhitong Xiong", "Yilei Shi", "Sudipan Saha", "Xiao Xiang Zhu"], "abstract": "Earth Observation (EO) data analysis has been significantly revolutionized by deep learning (DL), with applications typically limited to grid-like data structures. Graph Neural Networks (GNNs) emerge as an important innovation, propelling DL into the non-Euclidean domain. Naturally, GNNs can effectively tackle the challenges posed by diverse modalities, multiple sensors, and the heterogeneous nature of EO data. To introduce GNNs in the related domains, our review begins by offering fundamental knowledge on GNNs. Then, we summarize the generic problems in EO, to which GNNs can offer potential solutions. Following this, we explore a broad spectrum of GNNs' applications to scientific problems in Earth systems, covering areas such as weather and climate analysis, disaster management, air quality monitoring, agriculture, land cover classification, hydrological process modeling, and urban modeling. The rationale behind adopting GNNs in these fields is explained, alongside methodologies for organizing graphs and designing favorable architectures for various tasks. Furthermore, we highlight methodological challenges of implementing GNNs in these domains and possible solutions that could guide future research. While acknowledging that GNNs are not a universal solution, we conclude the paper by comparing them with other popular architectures like transformers and analyzing their potential synergies.", "sections": [{"title": "I. INTRODUCTION", "content": "Earth Observation (EO) data, acquired by various sensors across different locations and times, presents as diverse modalities. Each of these modalities provides unique insights into the status of our planet, facilitating an understanding of the Earth. Deep learning (DL) is particularly appealing in parsing the abundant information in the EO field [1]\u2013[3].\nThese data-driven models excel in extracting feature representations solely from the data, thereby eliminating the need for manually crafting features based on domain-specific knowledge. When it comes to images, they can be conceptualized as functions in Euclidean space, sampled on a grid where proximity is associated with local connectivity. Convolutional Neural Networks (CNNs) effectively harness the inductive bias of translation invariance and locality by employing convolutions in conjunction with other operations such as downsampling (pooling [4]). The convolution operation allows the extraction of local features shared across the entire image domain, as CNNs apply filters in a \u201csliding window\" fashion across the input layer. This approach significantly reduces the number of learnable parameters, facilitating the training of very deep architectures [5]. Moreover, it enables CNNs to learn features independent of the specific region within the input [6]. These characteristics make CNNs well-suited for handling image datasets in computer vision applications [7]\u2013[9].\nHowever, EO data sometimes deviates from grids or regular formats alike, with an example being Light Detection and Ranging (LiDAR) point clouds, which are discrete points in space without predefined regularity between them. Moreover, EO data, in contrast to traditional vision images, are characterized by specific attributes such as geographical context, spatial-temporal dynamics, adherence to physical processes, and often limited visual saliency. These attributes necessitate a different space to decipher their complexities. Representing such data as graphs offers a compelling alternative, yet effectively handling graph-structured data poses significant challenges. Unlike images, which have a fixed size and spatial characteristics, graphs can exhibit arbitrary structures. They lack a well-defined beginning or end, where connected nodes may not necessarily be spatially adjacent. Besides, nodes in a graph may have a varying number of neighbors, a feature that hinders the straightforward application of two-dimensional (2D) convolution on graphs. Moreover, the traditional DL algorithms often assume that samples are independent of each other. However, this assumption may not hold for graph data, as the samples (nodes) are interconnected through links or edges. This interdependence among nodes adds a layer of complexity to the modeling process [10], [11].\nIn response to the challenges posed by graph data, a novel class of methods has emerged, known as Graph Neural Networks (GNNs) [12]. The essence of GNNs lies in the interactive aggregation and processing of the information across nodes and their connectivities (edges). These innovative approaches involve the development of new definitions"}, {"title": "II. FUNDAMENTAL KNOWLEDGE ON EO AND GNNS", "content": "The advent of sensing techniques has broadened the spectrum of data sources accessible for EO. These sources encompass a diverse array of formats, as Fig.1 demonstrates.\nDL has significantly impacted the field of EO, where most of the data is organized in a Cartesian coordinate system and where network architectures are designed to model the invariances of these structures [40]. Euclidean data is data that follows the principles of Euclidean geometry and can be sensibly modeled in n-dimensional linear space, ranging from sequential time series data, satellite imagery, and grided measurements, to hyperspectral imagery. While the locality and invariance of convolutional kernels significantly reduce the number of parameters required for training, they often fall short in capturing the complex spatial-temporal characteristics inherent in EO data. Specifically, each data type presents unique challenges when processed with traditional DL methods. Below, we discuss these limitations and how GNNs offer promising solutions.\n*   Sequential Time Series: Temporal features are crucial for analyzing the dynamics of Earth events. Traditional models like one-dimensional (1D) CNNs and Recurrent Neural Networks (RNNs) are commonly used to process sequential data, but they often neglect spatial patterns and constrain the input to a strict sequential order. In contrast, GNNs allow for capturing spatial and temporal patterns simultaneously. By representing each sequence as a node in a graph, GNNs can integrate multiple sequences and facilitate the exploration of graph-level attributes, thereby simplifying the identification of common or abnormal signal among sequences. Additionally, when each time step is represented as a node, the flexible design of connectivity enables the arbitrary interactions among time steps.\n*   Remote Sensing Images: CNNs are well-suited for processing regular inputs like RS images; however, their convolutional kernels are limited to local receptive fields, which restricts the model's ability to capture broader contextual information. GNNs address this limitation by incorporating spatial relationships into the graph structure or by facilitating information exchange between distant neighbors. Furthermore, traditional CNN layers and downsampling layers often produce overly smoothed outputs, which is particularly problematic in tasks requiring precise boundaries such as urban mapping or disaster monitoring. GNNs, by adaptively learning the significance of different nodes and edges, provide a more detailed representation of spatial features.\n*   Global Gridded Inputs: In weather and climate analysis, EO data are often mosaicked from dispersed stations and then resampled into a uniform grid covering the entire globe. While these grids simplify the processing with traditional models, it introduces training biases towards polar areas. GNNs can mitigate this issue by mapping the grids back to a spherical representation, thereby aligning the data more closely with its physical properties.\n*   Data Cubes: The joint analysis of multiple Earth snapshots, or data cubes, is valuable for monitoring changes over time. Although video-analysis techniques like ConvLSTM [41] can be applied, they are still constrained by the limitations inherent in convolutional operations. GNNs, especially their spatiotemporal variants, offer a better understanding of the evolution of Earth phenomena.\nOn the contrary, a substantial segment of geospatial research investigates EO data characterized by an inherent non-Euclidean spatial structure. This includes diverse data types such as LiDAR point clouds, Global Navigation Satellite System (GNSS) points, ship trajectories [42], [43], geo-tagged social media data [44], [45], and sensor networks. Traditional DL models struggle with directly handle such data. They often require specialized preprocessing steps like voxelization. However, GNNs offer a robust solution for handling such irregularity.\n*   Point Clouds: Point clouds are particularly prevalent in urban environment modeling. A point cloud is a collection of data points in a three-dimensional space, typically scattered on surfaces of objects and scenes. Each point in the point cloud is identified by its position (x, y, z) in three-dimensional (3D) space, and may also include auxiliary information such as intensity or color. Point clouds are commonly obtained through 3D scanning technologies like LiDAR, photogrammetry, or synthetic-aperture radar tomography (TomoSAR). The representation of point clouds as graphs is a natural fit due to the inherent spatial relationships between points. In this representation, each point serves as a node, and the spatial connections between points are captured by edges in the graph.\n*   Vector Data: Vector data, such as networks of rivers or transportation systems, has inherent graph topology. GNNs can incorporate domain-specific knowledge into their architecture. Therefore, the alignment between the data structure and the model architecture allows for the enhanced physical feasibility of the models.\n*   3D Mesh Data: Similarly, 3D mesh data, depicting surfaces through interconnected vertices, edges, and faces, provides a structured representation of 3D objects. Mesh can also be represented as a graph, with vertices as nodes and edges connecting them.\nIn summary, the diverse data types provide complementary perspectives on our Earth, and GNNs are well-suited to address the irregularity, physical consistency, dynamics, and complexity in EO data."}, {"title": "B. Graph Neural Networks", "content": "1) Graphs: Formally, the two components of a graph G = (V,E) are vertices (nodes) V and edges E. There are various types of E; for example, they can be weighted or unweighted, directed or undirected, depending on the given application [46].\nA prevalent approach to denoting a graph structure is using an adjacency matrix A. In the context of a graph with N nodes, the corresponding adjacency matrix A takes the form of an N \u00d7 N matrix, where each row and column represents an individual node, and the intersected value is the connectivity between these two nodes. To mitigate computational complexity, a sparsity matrix is often employed, retaining only the indices and values of the non-zero edges. Another approach to represent the graph is the adjacency list, where the neighbors of each node or all edges between node pairs are stored.\n2) GNNs: GNNs extend DL to graph-structured data. As part of feature engineering, the first step often involves projecting nodes and edges into a feature space, a process known as node embedding or edge embedding. These embeddings consist of vector representations of node or edge properties within a graph, serving as ingredients for subsequent GNN training.\nMessage passing: The key idea in GNNs is the differentiable message passing. Consider a graph G = (V,E), where eij is the edge weight between node vi and node vj. Every node vi has feature vector $h_i \\in \\mathbb{R}^d$. Let $h_i^{l-1}$ be the hidden representation of node $v_i$ at the l \u2212 1 layer. For each node, two operations are conducted:\n1,\nThe first is to gather messages from all neighbors $N_i$,\n$m_i = \\sum_{v_j \\in N(v_i)} f_m (h_i^{l-1}, h_j^{l-1}, e_{ij}). \n         \\tag{1}$    \nThe second is to update the hidden representation of layer l,\n$h_i^l = f_u (h_i^{l-1}, m_i), \n         \\tag{2}$    \nwhere $f_m$, $f_u$ are any differentiable functions, e.g. Neural Networks (NNs). Message passing is explicitly implemented via spatial graph convolution, where the operation involves direct and localized node-to-node communication. For example, Graph Attention Networks (GATs) [47], GraphSAGE [48], and Message Passing Neural Networks [49] leverage the intrinsic relationships and features within the graph's topology for enhanced data processing and analysis. Figure 2 compares the evolution of hidden states through a single-layer CNN and a single-layer GNN.\nAnother effective implementation is the spectral GNNs [50], which deal with the properties and analysis of graphs through the lens of eigenvalues and eigenvectors. In spectral graph convolution, the convolution operation is defined in the spectral domain by multiplying the Fourier transform of the graph signals (node features) with a filter. Bianchi et al. [51] employ AutoRegressive Moving Average (ARMA) filters in the spectral domain for graph convolution, allowing for more flexible and powerful spectral filtering. In comparison to spatial graph convolution, spectral graph convolution excels at capturing the global structure of the graph. To reduce the cost associated with eigenvalue and eigenvector computation, Chebyshev polynomials have been employed to approximate the spectral filters of the graph Laplacian [14]. Kipf and Welling [13] propose a simplification of the convolutional operation via a localized first-order approximation, known as Graph Convolutional Networks (GCNs).\nPooling: Pooling is an important operation in CNNs to reduce dimensionality and improve computation efficiency; moreover, it prompts translation and feature invariance. In GNNs, there are similar layers to help reduce the graph size and improve graph generalizability. To get a coarsened graph, the pooling operation firstly selects subsets of nodes from the whole graph, then aggregates each subset to an output node, and finally connects reduced nodes with edges [52]. A graph pooling layer can be represented as\n$\\nu', \\varepsilon' = \\text{Pool}(\\nu, \\varepsilon).\n         \\tag{3}$\nGlobal pooling uses a set of readout functions such as global add, mean, or max pooling to condense a graph to a single node. Hierarchical pooling, on the contrary, provides a multi-resolution representation of the graph. This also allows deeper GNN models. Figure 3 compares the pooling operation on grided data and on graph-structured data.\nThe past few years have witnessed rapid advancements in vision GNNs, whose application to EO tasks effectively breaks through some bottlenecks of traditional DL methods. Table I presents a comparison of the limitations in traditional DL methods and highlights the advantages of GNNs as emerging solutions for handling EO data."}, {"title": "III. KEY PROBLEMS IN EO AND GNNS AS SOLUTIONS", "content": "EO data exhibits unique characteristics such as spatial autocorrelation, complexity, irregularity, and multi-modality. Additionally, it requires specialized expert knowledge for effective processing and analysis due to the complex physical processes involved. This further complicates the acquisition of labeled data for efficient supervised learning. In this section, we identify five important generic challenges common in the EO field. While traditional DL methods often struggle with these challenges, GNNs offer promising solutions due to their ability to model complex relationships, provide contextual information, and process non-Euclidean data. In general, the decision to model the EO data using GNNs arises from two aspects. On the one hand, GNNs overcome the CNNs' limitation in processing the non-Euclidean data. On the other hand, gridded data can be conceptualized as graphs to address the unique EO-related challenges.\nFigure 4 provides an overview of the rationale behind selecting specific GNN architectures to tackle various EO challenges, supported by successful application cases for reference."}, {"title": "A. Geographical Dependence", "content": "Unlike common vision data features that exhibit positional invariance, geographical features are often associated with specific geographic locations. While most convolutional kernels are shift-invariant, they may struggle to capture location-dependent variations. GNNs address these variations across longitudinal and latitudinal dimensions by 1) considering spatial autocorrelation into adjacency matrix design [74], 2) using positional-agnostic nodes or augment node features with location information [75], and 3) capturing long-distance contextual-aware information [62].\nThe distribution of EO data often exhibits spatial auto-correlation, where similar values tend to cluster together. To quantify this similarity between nodes, a distance-based adjacency matrix can be employed [31], [74], [76], promoting information aggregation among similar objects. However, spatially adjacent values may not necessarily be similar; hence, the utilization of heterogeneous graphs and multiple graphs is encouraged [77], [78]. These approaches are well-suited for handling geometrically and topologically complex domains to satisfy spatial and locality requirements.\nFurthermore, many Earth phenomena show strong affiliations to geographical positions [79]. For instance, a temperature anomaly in the North Pacific should be distinguished from one in the Arctic. While most convolutional kernels are shift-invariant, they may overlook location-dependent variations. GNNs excel in mapping observations from different locations. This is achieved by projecting different regions to distinct nodes or incorporating location information as node or edge attributes [74], [75], [80]. Weyn et al. [65] train separate weights for faces on the equator and at polars to capture the markedly divergent evolution of weather patterns across different geographical faces. Additionally, to harmonize atmospheric motions in the Arctic with those in the Southern Pole, an ingenious flipping is conducted preceding the convolution operation. These approaches enhance the modeling of location-specific characteristics of EO data.\nGeographical phenomena often converge over larger spatial and temporal coverage. Consequently, it is essential to consider the broader contextual information. GNNs offer a solution to incorporate long-distance information flow and nonlocal"}, {"title": "B. Complex Network Analysis", "content": "The occurrence of certain phenomena on Earth is often influenced by multiple variables that exhibit complex and interconnected relationships. Complex network analysis offers an effective approach to unravel these complex interaction patterns. Commonly used graph analysis based on correlation coefficient is prone to pseudolinks [83].\nThough there are promising tendencies of analyzing causal graphs [84], [85], GNN-based graphs lead to another possible interpretation. For instance, graph measures of the adjacency matrix manifest the emergence mechanism of El Ni\u00f1o events [86]. The high eigenvector centrality near the Oceanic Ni\u00f1o Index (ONI) region for one lead month serves as a triggering signal for the El Ni\u00f1o events, while a more widespread distribution of centrality over longer horizons explains how the El Ni\u00f1o phenomenon aggregates from drivers across broader geographical ranges."}, {"title": "C. Irregular, Heterogeneous, and Noisy Data", "content": "Given the wealth of available data sources, they often vary significantly in terms of coordinates, resolution, temporal and spatial coverage, quality, and modalities. While these diverse data sources offer the potential for richer perspectives on phenomena, integrating them into an end-to-end DL framework is inherently demanding. GNNs offer a solution to organize irregular data. They can manage unstructured data, deal with variables of various types and sources [60], accommodate variables with varying resolutions in space, address data distortions caused by transforming from spherical coordinates to a planar coordinate system [74], and contribute to robust prediction by handing noisy inputs.\nTo integrate variables from heterogeneous sources, Zhang et al. [87] differentiate nodes by their types. Up to 78 atmospheric variables with auxiliary variables are attached as initial node features. In [25], node feature types transcend scalar data and extend to vectors. The vector data, such as water flow velocities, are processed by Geometric Vector Perceptrons in order to preserve their geometric properties.\nGNNs also offer solutions to handle varying resolutions in space, often achieved by adopting hierarchical graph structures. Shi et al. [74] store a graph hierarchy by graph coarsen, and generate adaptive resolution outputs for future simulation"}, {"title": "D. Physical Procedure Modeling", "content": "The evolution of Earth-related events adheres to specific physical constraints. Typical DL models function as \"black boxes\", which lack interpretability and physical feasibility. By contrast, graph-based structures can be naturally linked to the physical processes, making them more resilient to over-fitting compared to simple statistical methods. Usually, integrating physical knowledge into GNNs can be achieved through the following approaches: 1) node attribute design [23], [68], 2) graph structure design [90], [91], 3) graph regularization [86], and 4) message passing procedure [92].\nOne straightforward approach is to attach potential influencing variables as additional node features, a skill prevalent in tasks involving complex interdependencies among variables [30], [70]. Despite the added value auxiliary data can provide, it increases the computational burden. Thereafter, a remedy for this is to ground the physical model within the graph topology. Li et al. [26] employ a graph search algorithm that rapidly traverses the sewer network, considering both the topology and physical processes governing the sewer system. Liu et al. [93] use the fast marching method given a geological model to estimate connectivity between injectors and producers for production forecast. Wang et al. [69] take an advection coefficient as the activated projection of the wind vector on node pairs, together with node attributes covering physical, chemical, and biological reactions, to enhance the domain knowledge in graph learning. Seo et al. [94] summarize graph updating functions and corresponding physical equations, as shown in Table II. Furthermore, the physical knowledge can guide the training procedure [95]. Utilizing"}, {"title": "E. Label Scarcity", "content": "Annotating EO datasets is an exceptionally labor-intensive, time-consuming, and costly procedure. EO imagery often lacks distinct visual features, therefore it requires huge labeling efforts from experts. Furthermore, the volume of data collected by sensors is rapidly increasing. Adding to the challenge, labels can quickly become outdated due to the pronounced changes in targets and sensing conditions. For example, there is often a dearth of timely, relevant training data in post-disaster areas. In such scenarios, supervised learning models, which typically excel in settings where they are trained on comprehensive, well-labeled datasets, struggle to generalize to new, unseen scenarios.\nSemi-supervised or unsupervised learning alleviates the dependency on label information in the EO domain [16], [17], [21], [98], [99]. Label propagation by GNNs is a special case of transductive learning. The underlying principle of label propagation is based on the assumption that when nodes are connected by an edge, they are likely to share similar labels. Graph-based transductive learning or semi-supervised learning can achieve adaptive classification performance across various sensors, seasonal changes, and geographical locations [54], [55]. Such approaches are also beneficial in scenarios with missing values [31] or when certain measurements are unavailable. Guan et al. [31] use unsupervised graph learning to deal with partially missing geochemical samples. Its improved adaptability paves the way for more robust industrial deployment, avoiding the whole system collapsing when a single station corrupts [100]. In the evaluation of landslide susceptibility, Zeng et al. [60] notice that the inherent heterogeneity of complex geoenvironmental settings leads to diverse landslide characteristics. Therefore, the GraphSAGE [48] algorithm is adopted to generalize the sampling approach to unseen areas through inductive learning."}, {"title": "IV. BRING GNNS TO EO APPLICATIONS", "content": "The advanced GNNs are important in a wide array of tasks such as predicting climate dynamics and meteorological patterns, offering insights for environmental analysis, managing and mitigating the impacts of natural disasters, accurate classification of land cover, and developing smart cities, etc. Figure 5 presents a relative estimate of the number of publications about GNNs within the EO domain. The data includes the number of papers gathered from the Web of Science and the number of high-quality papers selected for this survey. From this figure, it is evident that GNNs are particularly popular in topics related to Land Cover Land Use (LCLU), which are mainly based on hyperspectral image analysis. They are also extensively applied in air quality monitoring and weather forecasting tasks. This trend suggests that the data type largely drives the motivation for adopting GNNs, as these unstructured data (e.g., stations) requires new techniques to handle their irregularity.\nIn the subsequent section, we will delve into the key methodological considerations for designing and implementing GNNs across different EO applications, as well as their real-world implications."}, {"title": "A. Weather and Climate Analysis", "content": "1) Weather forecast: Weather forecasting and meteorological variable analysis, in particular severe and extreme weather, have always been the most important subject in meteorology. To predict the atmospheric conditions in the future, Numerical Weather Prediction (NWP) approximates the governing equations of fluid mechanics through discretization [101]; but there remain considerable uncertainties [102] due to the finite grid resolution and errors in parameterizing unresolved processes. Recently, DL has led to significant advancements in medium-range weather forecasts. These breakthroughs include extended forecast horizons, improved accuracy, reduced uncertainty, much faster inference time, and handling a larger set of variables. Conventional DL-based weather forecasting relies on latitude and longitude projections, which introduce singularities at the North and South poles. This results in an imbalance in training models due to the larger area along the equator compared to higher altitude areas.\nTo mitigate distortions arising from Earth's spherical geometry, Weyn et al. [65] remap the Earth to an equiangular gnomonic cubed sphere and introduce convolutional and padding operations on it. While the Graph Network (GN) shows promising forecasting ability, it still failed to compete with NWP. Later, Keisler [29] use an encoder to map latitude-longitude grided data to an icosahedron. Their approach allows for aggregation on the sphere across physically uniform neighborhoods and enables adaptive mesh refinement. It marked the first time that GNNs achieved Root Mean Squared Error (RMSE) values on Z500 (geopotential height at pressure level 500 meters) and T850 (temperature at pressure level 850 meters) comparable to those of operational, full-resolution physical models from Global Forecast System (GFS) and European Centre for Medium-Range Weather Forecasts (ECMWF). Building on this, GraphCast [30], whose graph organization is detailed in Table III, extends the mesh representation to multiple scales by iteratively refining a regular icosahedron six times (M_0 to M_6). The 16 simultaneous message-passing layers transmit and aggregate spatial patterns over arbitrary ranges, and the nodes and edges are updated iteratively, as depicted in Fig.6. Ultimately, GraphCast outperformed HRES (atmospheric model high resolution 10-day forecast) in skill scores across all lead times (1 day to 10 days) for Z500, with improvements around 7% to 14%. Its real-time forecasts are available on ECMWF's OpenCharts2. This GNN-based model overcomes the limitation of regularly strided ranges in CNNs and shows higher computational efficiency compared to the pairwise interactions computation in Transformers [103]. Nevertheless, it faces some problems such as a lack of explicit incorporation of physical knowledge, deterministic outputs, and inherited bias from training data. To evaluate the added value of DL-based weather forecast for end users, more comprehensive protocols are necessary. Specifically, model performance should be validated by testing temporal consistency, the distribution of extreme events, and the capacity to preserve meteorological features, etc.\nGNNs also demonstrate proficiency in handling meteorological observations from dispersed monitoring stations. For weather observations from weather stations, it is customary to conceive each station as a node, upon which meteorological measurements are affixed. The spectral convolution GNN [104], [105] utilizes temporal features from wind farms as nodes to forecast short-term wind speed. Given the important role that geography plays in shaping precipitation patterns, Huang et al. [77] organize clusters of ground radar stations as graphs based on their locations. Consequently, distinctive attributes characterizing diverse precipitation types are projected onto separate graphs. Similarly, Ma et al. organize hierarchical graphs to model correlations between meteorological variables across weather stations (regions) [106].\n2) Climate analysis: In addition to atmospheric variables, Earth involves a myriad of other variables that engage in complex interactions. GNN-based learned simulators demonstrate promising performance in studying the complex physical dynamics of fluids and materials [107], [108], thus they have found applications in oceanic systems that show similar motion properties.\nGNNs demonstrate remarkable predictability in complex systems dynamics, such as the prediction of sea surface temperature (SST) [109], [110], modeling of large ocean-circulation dynamics [86], and reconstruction of ocean deoxygenation [111]. To model the SST dynamics, Wang et al. [109] use an adaptive graph trained from the dot product of node embeddings, indicating the pair-wise interactions in a high-dimensional feature space. Gao et al. [112] superimpose a static A derived from pair-wise node similarity and a dynamic A composed of attention coefficients for SST prediction. This approach allows for the capture of adaptive node importance, as SST changes may be driven by signals originating from diverse regions of the ocean. Seo et al. [92] integrate transportation functions, primarily advection and diffusion,"}, {"title": "B. Disaster Management", "content": "Disasters and their cascading effects incur huge social and economic losses. Effective disaster management requires timely and precise disaster detection, including its characterization and temporal derivation. In this part, through examining a vast number of natural hazards such as landslides [82], tropical cyclones [73], floods [25], earthquakes [115], frost [113], and heatwaves [72], we find GNNs are broadly adopted in all phases of disaster management, including pre-disaster prediction, mid-disaster mapping, and post-disaster reconstruction stage. Figure 7 provides an overview of various natural hazards for which GNNs have been adopted for detection. The following capacities of GNNs make them particularly popular: 1) handling the irregular spatial arrangement of disaster observations [116], 2) integrating a variety of factors as augmented node features [60], 3) adjusting node density [59] for rapid response, 4) extracting fine-grained features for detailed damage mapping, and 5) managing complex non-uniform layouts in post-disaster environments.\n1) Disaster mapping: Successful monitoring and detection of potential hazards entail the use of various sensors, such as seismometers for seismic activity monitoring, weather stations for tracking meteorological conditions, and satellite imagery for remote sensing and observation. GNNs effectively leverage these observations to enhance hazard detection, tracking, and monitoring. Their ability to map fine-grained features alleviates the scarcity of semantic information, enabling scene representations that better align with the cognitive needs of the public [117].\nSeismic activity: A sudden release of energy in the Earth's lithosphere creates seismic waves, which bring huge effect to human life and the natural environment. Seismic stations collect measurements for seismic event prediction, detection [115], classification [100], and source characterization [33], [75], [95], [116]. Traditional methods treat this as an inverse problem, attempting to ascertain the location and magnitude of seismic events from arrival times or waveforms at a single station. However, these methods are computationally expensive and susceptible to signal noise. Hence, joint analysis of data from multiple seismic stations is widely adopted to reduce false detections [100], [115] and identify even faint seismic signals.\nTo address the irregular geometry of station networks and account for correlated noise between stations, graph regression and classification methods are employed. In related works, each seismic station is organized as a node in the graph, with graph connectivity determined by geographical proximity (threshold by distance or neighbor quantity) [75], [100], [115], feature similarity, or a hybrid use of both [33]. Nodes are attached with time-series waveforms processed by CNNs with varying kernel sizes or pooling techniques for temporal feature selection. Subsequently, GCNs or message-passing layers are used to encourage information exchange and aggregation across multiple sites [75], [95], [100]. In this context, the output is primarily graph-level attributes aggregated from node-specific features. Thereafter, concerns have arisen regarding potential feature loss incurred by such"}, {"title": "C. Environmental Analysis", "content": "Environmental monitoring plays an important role in safeguarding ecosystems and human health by tracking changes in air quality, water resources, biodiversity, and others. Tradi-"}, {"title": "V. CHALLENGES OF IMPLEMENTING GNNS", "content": "Despite the merits of GNNs in addressing EO challenges, as discussed in the previous chapter, their adoption in the EO domain remains relatively underexplored. This discrepancy primarily arises at various stages, including data formatting, graph design, subsequent graph learning, and deployment to large-scale scenarios. Addressing these methodological challenges would pave the way for developing innovative approaches to analyze and interpret the Earth."}, {"title": "A. Low-level Inputs", "content": "Most GNNs are typically developed for graph-structured data. In other fields like chemistry, defining a graph is straightforward; for instance, atoms can serve as nodes, molecular bonds as edges, and molecules as graphs. This ease of definition has led to the widespread adoption of GNNs in biochemistry science, such as protein-to-protein prediction. However, many EO datasets lack inherent node definitions.\nThe primary challenges revolve around extracting relevant variables from frequently noisy measurements or high-dimensional spatio-temporal datasets. To understand the scene depicted in an RS image, recognizing semantic relationships between pixels is important. This motivates the organization of pixels or superpixels as nodes. Another strategy entails mapping gridded measurements onto a spherical space, where the data distribution is more uniform and better aligned with Earth's physical attributes [30]. Furthermore, dimensionality reduction can be used to extract meaningful nodes from these lower-level inputs. To detect tropical cyclone intensity from satellite images, Xu et al. [73] conceive a specific wind scale as a node, with its vector attribute computed from the mean wind speed associated with that scale from all training data. Beyond the data domain, node definition can extend to other spaces. At the task level, Wang et al. [63] exemplify this by organizing the three-level subtasks 1) whether it is a building; 2) whether the building is damaged; 3) to what extent the building is damaged (minor, major, destroyed) as three"}, {"title": "B. Implicit Graph Structure", "content": "While most EO data is organized in a regular format, implementing GNNs involves crafting graph structures from data lacking inherent graph topology.\nWhen designing the graph topology, the choice hinges on the specific scientific research question at hand. Geographical, environmental, and physical processes can be incorporated into the graph topology design. The configuration of the graph presents itself through an array of possibilities: one may base it on geographical proximities [24], exploring the mutual information between node pairs [104], feature similarities [70], or embrace a trainable paradigm [86], [105], [168]. The direction of edges defines the desired information flow, and often under certain constrictions to align the graph with reality. For example, Qiao et al. [32] enforce temporal edges to direct toward the future. Yang et al. use an attention based directed graph generator for automatic vector extraction from RS images [169]. Recently, there has been growing interest in eliminating superficial edges by studying the underlying data causality for trustworthy GNNs [170]. In line with this, Zhao et al. [114] explore a causality-based adjacency matrix to capture the synergistic effect of variables driving wildfires."}, {"title": "C. Adversarial Vulnerability", "content": "Like other DL models, GNNs are inherently vulnerable to adversarial attacks [171]\u2013[173], which hinders their deployment in real-world applications and critical decision-making processes.\nAdversarial modifications to graph topology or node features can significantly degrade model performance. For instance, even minor manipulations of pixel values in SAR images can lead to substantial drops in GNN accuracy [174]. While there is extensive literature on adversarial attacks in DL for RS scene classification [175] and object detection [176], the adaptation of these concepts to GNNs in the EO domain remains underexplored. Adversarial attacks may involve adding or removing edges, altering node embeddings, or introducing new nodes [177], [178]. Future research should focus on exploring more sophisticated adversarial perturbations and developing corresponding defenses to enhance the robustness of GNNs."}, {"title": "D. Graph Learning Design", "content": "GNN-like models tend to overly smooth predictions with increasing depth [179", "35": [181], "184": ".", "185": "and S2GAE [186", "187": ".", "188": "and GCA [189", "190": "introduces pooling and unpooling operations on graph-structured data, adept at capturing hierarchical features for EO"}]}