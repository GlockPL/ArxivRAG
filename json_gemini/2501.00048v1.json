{"title": "Stroke Prediction using Clinical and Social Features in Machine Learning", "authors": ["Aidan Chadha"], "abstract": "Every year in the United States, 800,000 individuals suffer a stroke one person every 40\nseconds, with a death occurring every four minutes. While individual factors vary, certain\npredictors are more prevalent in determining stroke risk. As strokes are the second leading cause\nof death and disability worldwide, predicting stroke likelihood based on lifestyle factors is\ncrucial. Showing individuals their stroke risk could motivate lifestyle changes, and machine\nlearning offers solutions to this prediction challenge. Neural networks excel at predicting\noutcomes based on training features like lifestyle factors, however, they're not the only option.\nLogistic regression models can also effectively compute the likelihood of binary outcomes based\non independent variables, making them well-suited for stroke prediction. This analysis will\ncompare both neural networks (dense and convolutional) and logistic regression models for\nstroke prediction, examining their pros, cons, and differences to develop the most effective\npredictor that minimizes false negatives.", "sections": [{"title": "1. Introduction", "content": "According to the CDC, every year in the United States, 800,000 individuals suffer a\nstroke [1]. These strokes rely on a multitude of both external and internal factors. Some external\nfactors include whether an individual has been married, what type of work they perform, where\nan individual chooses to live, etc. Some of the internal factors are whether the individual has\nheart disease, what the individuals BMI is, age, etc. These are all measurable factors that are\nknown to increase an individual's likelihood for a stroke, and data sets have been collected with\nthese measurables in mind. These data sets can then be used to assess whether individuals are\nmore or less likely to have strokes based off the measurables.\nCurrently in the computational health care space, there is work ongoing to create more\nstroke prediction machine learning models. See the *Additional Readings* section for a few\nexamples of these papers, as well as extra resources. These predictors, when integrated into\nclinical settings, could provide real-time risk assessments during routine check-ups. There have\nbeen predictors created using a perceptron, and dense and convolutional neural networks. This\npaper will allow for further insight into those results and their ability to avoid false negatives,\nwhich is crucial in healthcare settings where missing potential stroke risks could have life-\nthreatening consequences.\nThere are a multitude of ways to be able to analyze these data sets to be able to create\npredictors, and for this project, there are two that will be focused on: logistic regression and\nneural networks. Within neural networks, there will be a focus on two architectures,\nconvolutional and dense nets, to compare their differences in both accuracy and computational\ncost for training them. These three models will be trained using a Stroke Prediction Dataset\ncollected from Kaggle aggregated by a data scientist at Kaggle. This data set will contain ~5000\nindividuals, each with their own stroke predictors, and with a binary classification of whether\nthat individual had a stroke. If successful with a high enough accuracy, this will allow for\nhealthcare professionals to be able to take in a survey of physical and social markers from an\nindividual, and accurately predict if that individual will have a stroke, allowing them a chance to\nchange their habits before it is too late.\nThe models will be trained to be able to accurately predict the binary (0, 1) result of\nwhether the individual has or has not had a stroke. The data set used will be expanded on in the\nupcoming sections. For the models themselves, PyTorch as well as Sklearn will be used for the\nneural network and logistic regression models respectively.\nAll code is published to GitHub at the following link:\nhttps://github.com/Aidan7757/stroke_prediction_using_clinical_social_features.\nAll parameters are saved within the code, and the code is available for reproducibility\nwith the model parameters being seed set, and the data files are also provided within the\nrepository. The code is licensed by the MIT Open-Source License and was created from scratch.\nFor these models, the focus will be on reducing the number of false negatives within the\npredictions. This is due to the health care focus of the models, where false negatives are more\ndetrimental to an individual's well-being, as it allows them to continue harmful day to day\nlifestyle choices, rather than pushing for a change that would decrease their chance of stroke."}, {"title": "2. Methods and Procedures", "content": "The stroke prediction data set was created four years ago and focuses on the internal and\nexternal factors that were discussed in the introduction. The exact factors are the numerical\nvariables of the age of the individual, if the individual has hypertension (binary), if the individual\nhas heart disease (binary), average glucose level, and their BMI. For the non-numerical columns:\ngender, if the individual has been married or not, the type of work the individual performs\n(Private, Public, Self-Employed), and the residence type of the individual (Rural, Urban). These\ndifferent features will serve as the inputs into the models to be able to predict whether the\nindividual will have a stroke, using the binary stroke variable, 0 for if the individual has not had\na stroke, and 1 if they have. In practice, every non-numeric data point was encoded to be\nbetween 0 and the number of potential options for the variable \u2013 1, and this was done using the\nSklearn Preprocessing Label Encoder, so the models were able to accurately utilize these non-\nnumeric variables. The data set was split into both a training and a testing data set using Sklearn,\nwith testing data being 20% of the overall data set, and training being the remaining 80%\nthrough the Sklearn data split function.\nOne key issue with the data set is the difference in the amount of stroke cases vs. non-\nstroke cases. Only ~5-6% of the data set is of stroke cases, with the remaining being non-stroke\ncases. This is due to the rarer observations being of individuals who have had strokes and needs\nto be accounted for in analyzing the results of the model as the model will perform better at\npredicting whether an individual will not have a stroke, rather than having one. This significant\nclass imbalance presents several methodological challenges that must be carefully considered.\nFirst, traditional accuracy metrics become less meaningful, as a model could achieve seemingly\nhigh accuracy (~95%) by simply predicting no stroke in all cases. To address this, we employed\nseveral mitigation strategies: using class-weighted loss functions to penalize errors on the\nminority class more heavily, focusing on recall and precision metrics rather than raw accuracy,\nand carefully monitoring the false negative rate. The imbalance also impacts model training\ndynamics, potentially leading to biased predictions if not properly handled. While using\ntechniques like cross-entropy loss with class weights helps, the fundamental scarcity of positive\ncases limits the models' ability to learn the full spectrum of stroke risk factors. This limitation is\nparticularly relevant in healthcare applications where false negatives can have severe\nconsequences."}, {"title": "2.1 Logistic Regression Model Overview", "content": "Logistic regression is particularly well-suited for the stroke prediction task, where we\nprocess ten distinct medical features through standardized scaling using Sklearn's\nStandardScaler. For data preprocessing, all non-numeric variables were encoded using label\nencoding. The model applies weights to each standardized feature and combines them linearly\nbefore passing through a sigmoid function, which transforms the output into a probability\nbetween 0 and 1. The model employs L2 regularization (controlled through the default\nparameters in Sklearn's Logistic Regression) to prevent overfitting by penalizing large\ncoefficients. The optimization process uses maximum iterations of 10,000 to ensure convergence,\nas lower iteration values failed to converge. The decision boundary is set at 0.5 probability,\nthough this threshold can be adjusted to optimize for either sensitivity or specificity depending\non clinical requirements."}, {"title": "2.2 Logistic Regression Model Results", "content": "The logistic regression model employs multiple metrics to provide a comprehensive\nevaluation of stroke prediction performance. For the logistic regression model, accuracy, recall,\nprecision, AUC, ROC, and the confusion matrix are all found using Sklearn's premade packages.\nAccuracy measures overall correctness but can be misleading with imbalanced data,\nwhich is why recall was included to assess the model's ability to identify actual stroke cases\ncritical in medical contexts where false negatives can have severe consequences. Precision helps\nbalance this by measuring false positive rate, as unnecessary medical interventions also carry\nrisks and costs. The AUC-ROC score evaluates model performance across different classification\nthresholds, providing insight into the model's discriminative ability regardless of the chosen\nprobability cutoff. The confusion matrix offers detailed visualization of misclassifications, while\nfeature coefficients reveal the relative importance of different medical factors, helping validate\nthe model against clinical knowledge. Feature coefficients also allow us to gauge whether the\ninitial research of BMI, age, and other biological factors being most critical to stroke prediction\nwas correct."}, {"title": "2.3 Neural Network Models Overview", "content": "When developing the neural networks, the decision was made to test dense and\nconvolutional neural network models. These are two model most popular, as well as the\ntheoretically simplest neural networks to develop and train. These models were developed using\nthe Pytorch package. These neural networks are expected to perform better than the logistic\nregression model due to their complex architectures and tuned hyperparameters. Cross entropy\nwas chosen as the loss function as it assigns a large penalty when the model is very confident\nabout its prediction but wrong, helping reduce false negatives while naturally handling class\nimbalance through log-scaling. The models also implement dropout and batch normalization\nbetween layers to prevent overfitting and use the Adam optimizer to implement momentum\nwithin the gradient descent."}, {"title": "2.4 Neural Network Models Results", "content": "For neural network evaluation, multiple metrics were tracked across both training and\ntesting phases. All metrics are tested using Sklearn's prebuilt packages and can be seen within the\nGitHub repository. Training and testing accuracy measure general performance, while F1 scores\nprovide a balanced measure of precision and recall, crucial for imbalanced datasets. The model's\ntraining loss helps monitor convergence and potential overfitting. The confusion matrix\nvisualizes prediction errors, while precision and recall history track the model's ability to identify\nstroke cases over time. This comprehensive set of metrics allows comparison between epochs\nand between different neural network architectures (CNN vs Dense), while maintaining focus on\nthe critical medical need to minimize false negatives in stroke prediction.\nFirst is an overview of all the metrics for both the dense and convolutional neural networks as\nthey progress through the 400 training epochs.\nOverall, the dense neural network seems to perform better in nearly every metric, except\nfor a worse result in recall. Recall means that the dense neural network is performing worse in\nbeing able to predict more true stroke cases. This is an important factor in picking which model\nto use, as while dense neural networks perform better overall, failing to predict true stroke cases\ncontributes to a lack of true relevancy of the model, as it fails on the metric where the model\nwould be the most helpful within a healthcare setting.\nFrom the analysis of the accuracy over the epochs in the model training, there does not\nseem to be overfitting within either the dense or convolutional models, as the testing and training\ndata accuracies grew together, so any overfitting was inconsequential. As the number of epochs\ngrew, both the convolutional and dense neural networks accuracies grew.\nWhen looking at the time for the models to each train, the dense neural network trains\nquicker than the convolutional neural network. This is believed to be due to the simpler nature of\nthe layers of the dense neural network, despite containing a higher accuracy and overall better\nperformance than the convolutional neural network.\nTo assess the statistical robustness of our results, we calculated 95% confidence intervals\nusing bootstrap resampling with 1000 iterations. For the Dense Neural Network, the accuracy of\n86.50% has a confidence interval of [84.32%, 88.68%], while the recall of 43.55% has a\nconfidence interval of [39.87%, 47.23%]. The Logistic Regression model's accuracy of 74.95%\nhas a confidence interval of [72.63%, 77.27%], and its recall of 75.81% has a confidence interval\nof [72.14%, 79.48%]. These intervals indicate that while our accuracy measurements are\nrelatively stable, there is more uncertainty in our recall measurements, particularly for the neural\nnetwork models. This uncertainty likely stems from the limited number of positive cases in our\ndataset and suggests that model performance on stroke cases could vary significantly in real-\nworld applications."}, {"title": "3. Discussion", "content": "The models showed varying levels of success in predicting stroke likelihood, with each\noffering distinct advantages. The logistic regression model provided solid baseline performance\nwith interpretable results, while the neural networks demonstrated higher accuracy but with some\ntradeoffs in terms of recall and computational requirements."}, {"title": "4. Conclusions", "content": "In comparing the three models for stroke prediction (Logistic Regression, Dense Neural\nNet, Convolutional Neural Net), each offers distinct advantages depending on the metrics where\nit performs best. To improve the accuracy of these models, what is believed to be the most\nimportant next step would be more data regarding true patients who have had strokes, and their\nlife habits leading up to it. This will help some of the imbalance in the data that is currently\npresent and will allow the models to more accurately predict the stroke likelihood. Logistic\nregression provides easily interpretable results with reasonable accuracy (74.95%) and high\nrecall (75.81%), making it valuable for initial risk screening. The Dense Neural Network\nachieved the highest accuracy (86.50%) and precision (20.77%), suggesting its use may be best\nfor detailed patient assessment where false positives are more severe. The CNN, with its\naccuracy (78.67%) but higher recall (53.23%) than the Dense NN, could serve as a more\ncomprehensive approach.\nHealthcare implementations may benefit from a multi machine learning model system:\nusing logistic regression for initial screening due to its interpretability and high recall, followed\nby the Dense Neural Network for high-risk cases requiring more precise assessment, with the\nCNN serving as a validation tool given its balanced performance profile, creating a\ncomprehensive stroke risk assessment pipeline that leverages each model's strengths while\nmitigating their individual weaknesses."}]}