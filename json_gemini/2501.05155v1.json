{"title": "Biomedical Relation Extraction via Adaptive Document-Relation Cross-Mapping and Concept Unique Identifier", "authors": ["Yufei Shang", "Yanrong Guo", "Shijie Hao", "Richang Hong"], "abstract": "Document-Level Biomedical Relation Extraction (Bio-RE) aims to identify relations between biomedical entities within extensive texts, serving as a crucial subfield of biomedical text mining. Existing Bio-RE methods struggle with cross-sentence inference, which is essential for capturing relations spanning multiple sentences. Moreover, previous methods often overlook the incompleteness of documents and lack the integration of external knowledge, limiting contextual richness. Besides, the scarcity of annotated data further hampers model training. Recent advancements in large language models (LLMs) have inspired us to explore all the above issues for document-level Bio-RE. Specifically, we propose a document-level Bio-RE framework via LLM Adaptive Document-Relation Cross-Mapping (ADRCM) Fine-Tuning and Concept Unique Identifier (CUI) Retrieval-Augmented Generation (RAG). First, we introduce the Iteration-of-REsummary (IoRs) prompt for solving the data scarcity issue. In this way, Bio-RE task-specific synthetic data can be generated by guiding ChatGPT to focus on entity relations and iteratively refining synthetic data. Next, we propose ADRCM fine-tuning, a novel fine-tuning recipe that establishes mappings across different documents and relations, enhancing the model's contextual understanding and cross-sentence inference capabilities. Finally, during the inference, a biomedical-specific RAG approach, named CUI RAG, is designed to leverage CUIs as indexes for entities, narrowing the retrieval scope and enriching the relevant document contexts. Experiments conducted on three Bio-RE datasets-GDA, CDR, and BioRED-demonstrate the state-of-the-art performance of our proposed method by comparing it with other related works.", "sections": [{"title": "I. INTRODUCTION", "content": "BIOMEDICAL Relation Extraction (Bio-RE) plays a crucial role in the field of biomedical text mining, aiming to identify the relations between two entities within biomedical texts automatically. Bio-RE is pivotal in developing applications such as medical knowledge graph construction, question-answering systems, and biomedical text analysis, which enhances the accessibility and comprehension of complex biological data.\nGenerally, Bio-RE is classified into two primary categories based on the length of text processed: document-level and sentence-level. Prior studies primarily concentrate on sentence-level RE [1]-[6]. However, in real-world scenarios, a significant number of relational facts are expressed across multiple sentences. Research indicates that over 40.7% of relational facts necessitate the analysis of multiple sentences [7], illustrating the complexity and value involved in document-level Bio-RE.\nAs for document-level RE, a considerable amount of information regarding entities and their relations within a document can only be identified through cross-sentence analysis [8]. The need for cross-sentence inference is especially critical in biomedical documents. Unlike general-domain texts, biomedical documents often contain aliases and identical terms sometimes exhibiting polysemy, thereby referring to entirely different entities. Moreover, the high level of professionalism and logical structure in biomedical texts intensifies the demand for robust cross-sentence inference in document-level Bio-RE compared to conventional document-level RE.\nFurthermore, documents for document-level RE often come from sources like Wikipedia and Wikidata [10], which provide detailed explanations. In contrast, documents for document-level Bio-RE are typically sourced from more condensed materials, such as biomedical article abstracts, which may lack comprehensive information. Consequently, a significant challenge faced by document-level Bio-RE is the increasing necessity to draw upon external world knowledge. This need arises not only to compensate for the inherent incompleteness of documents but also to provide more accurate and referable contexts.\nAnother major challenge in document-level Bio-RE is the scarcity of annotated data. For example, the CDR dataset [11], a key resource for chemical-disease RE, includes only 500 documents in its training set. This is considerably fewer than the general-domain DocRED dataset [7], which provides 104,926 documents in its training set. Not only is the amount of annotated data limited, but the inherent professionalism and logical structure of biomedical documents also make the manual annotation process time-consuming, labor-intensive, and highly specialized. The shortage of well-annotated data hampers the development and refinement of Bio-RE models that predominantly rely on large datasets for training and validation.\nWith the recent development of LLMs such as ChatGPT [12] and LLaMA2 [13], there has been growing research interest in leveraging LLMs for document-level RE [14]\u2013[16]. Consequently, we evaluated several LLMs on the document-level Bio-RE task, using test sets from the CDR [11], GDA [9], and BioRED [17] datasets. Our results indicate that the direct application of LLMs to the document-level Bio-RE task yields suboptimal performance, particularly on the BioRED dataset, which involves a multi-class classification scenario. LLMs face significant limitations when directly applied to the document-level Bio-RE task, as they lack the necessary medical knowledge and effective fine-tuning specifically for document-level Bio-RE. Furthermore, when faced with complex, incomplete, and cross-sentence inference-intensive biomedical documents, their sophisticated text analysis capabilities fall short.\nTo address the aforementioned challenges of document-level Bio-RE and the limitations of directly applying LLMs, we introduce a novel framework for document-level Bio-RE via LLM Adaptive Document-Relation Cross-Mapping (ADRCM) fine-tuning and Concept Unique Identifier (CUI) Retrieval-Augmented Generation (RAG), specifically designed to enhance document-level Bio-RE. We evaluated this framework on three document-level Bio-RE datasets: GDA [9], CDR [11], and BioRED [17], where it achieves state-of-the-art performance across all. Our contributions are summarized as follows:\n\u2022\tWe propose ADRCM fine-tuning, a novel fine-tuning recipe for LLMs in document-level Bio-RE, which establishes mutual mappings between documents and relations, enabling the model to capture domain-specific language nuances and enhance cross-sentence inference.\n\u2022\tWe develop CUI RAG, which uses CUIs as indexes for entities, not only narrowing the retrieval scope and enhancing relevance in specialized biomedical contexts, but also reducing the impact of different aliases for entities on retrieval.\n\u2022\tWe propose the Iteration-of-REsummary (IoRs) prompt, which guides ChatGPT to generate focused summaries by concentrating on specified entity relations and iteratively refining the data. This cost-effective strategy enhances the generalization and accuracy of LLM without significantly increasing annotation costs."}, {"title": "II. RELATED WORK", "content": "Current methods for document-level RE including document-level Bio-RE, can be primarily categorized into graph-based, transformer-based, and LLM-based methods.\nGraph-based Methods. These methods typically build a document-level graph using words, mentions, entities, or sentences as nodes, and predict relations by performing reasoning on the graph. Christopoulou et al. [18] proposed an edge-oriented model for document-level relation extraction that emphasizes edge representations over node representations to more effectively model entity relations. The model constructs nodes at various levels, including sentence, mention, and entity levels, and employs a partially-connected document graph with heterogeneous node and edge types. LSR [19] treats the graph structure as a latent variable, automatically inducing the optimal structure in an end-to-end manner without relying on pre-defined syntactic or co-reference structures. It employs an iterative refinement strategy that incrementally improves the latent structure, enabling the model to dynamically refine the graph across multiple iterations for effective multi-hop reasoning.\nTo further enhance relational reasoning over graphs, several efforts were made to design specialized reasoning networks [20]\u2013[23]. For example, SGR [20] focuses on extracting a simplified subgraph around the target entity pair, which contains the most relevant paths for relational reasoning. The approach generates reasoning paths through a heuristic strategy that explicitly models essential reasoning skills, such as logical reasoning and co-reference resolution. By applying a Relational Graph Convolutional Network to the extracted subgraph, SGR allows the model to focus on the most crucial entities, mentions, and sentences, enabling more effective joint reasoning over multiple paths. Xu et al. [22] proposed a novel path reasoning method that uses a breadth-first search (BFS) algorithm to extract multiple reasoning paths in a document-level graph. The extracted paths are then encoded using a long-short term memory (LSTM) network, and an attention layer is employed to summarize these paths, simulating complete reasoning paths between entities. To better differentiate the importance of various nodes and edges while filtering out irrelevant information, several studies integrated attention mechanisms into these models [24]\u2013[26]. For example, DAGCN [24] establishes bidirectional information flow and enables multi-turn interactions between contextual and dependency information through a parallel structure. Additionally, it employs a multi-layer Adjacency Matrix-Aware Multi-Head Attention mechanism, which effectively preserves the structural information of sentences and dependency trees during interactions.\nGraph-based document-level Bio-RE methods share similarities with general graph-based document-level RE methods in their underlying approach. For example, both Topic-BiGRU-U-Net [27] and FILR [28] integrate contextual information with graph-based representations and employ specialized multi-granularity reasoning networks to capture interactions between entities and mentions across sentences in biomedical texts. Additionally, AGCN [29], DAM-GAN [30] and HTGRS [31] incorporate attention mechanisms into graph-based methods to enhance their effectiveness.\nHowever, graph-based methods are significantly influenced by the quality of the constructed document-level graph and typically consider only edge and entity information during relational reasoning. These methods often neglect many non-entity clues present in the document, thereby limiting the further enhancement of the model's reasoning capability.\nTransformer-based Methods. Transformer-based methods leverage the capability of pre-trained language models (PLMs) to capture long-range dependencies by implicitly modeling long-distance relations through multi-head attention. These methods have gained significant attention for their effectiveness in performing relational reasoning and enhancing entity representations. SSAN [32] uses a unified framework to capture various mention dependencies and fully integrates structural dependencies within the encoding network. It extends the self-attention mechanism by incorporating Biaffine and Decomposed Linear Transformations, allowing the model to capture entity relations and structural dependencies across the document more effectively. ALOTP [33] employs adaptive thresholding, replacing the traditional global threshold with a learnable, entity pair-specific threshold that allows the model to dynamically adjust to different entity pairs. Moreover, it utilizes localized context pooling, refining entity embeddings by focusing on the context most relevant to each specific entity pair. DocRE-II [34] initially predicts relations and then iteratively refines them using Extended Cross Attention units, which capture dependencies among overlapping entity pairs by integrating both feature-level and relation-level information. SAIS [35] enhances RE by explicitly supervising intermediate steps through four tasks: Coreference Resolution, Entity Typing, Pooled Evidence Retrieval, and Fine-grained Evidence Retrieval. These tasks help the model capture textual contexts and entity types more effectively, leading to more accurate and interpretable RE. Additionally, SAIS employs evidence-based data augmentation, selectively refining predictions when model uncertainty is detected. DocRE-SD [36] introduces a reasoning multi-head self-attention mechanism that models four common reasoning patterns, enhancing relational triple coverage. It also employs a self-distillation framework to explicitly model relational reasoning by masking entity pairs during training. Additionally, a curriculum learning strategy is used to gradually increase the complexity of masked pairs, resulting in more robust learning.\nBuilding on the success of Transformer-based methods in document-level RE, similar strategies were adopted in the realm of document-level Bio-RE. For instance, TriA-BioRE [37], incorporating a Triangular Attention Module, enhances pair-level modeling for Bio-RE by comprehensively capturing interdependencies between entity pairs through a combination of triangular multiplications and self-attention mechanisms.\nTransformer-based methods, although powerful, have limitations in document-level RE due to a fixed maximum input length, which restricts their ability to effectively handle long documents by potentially truncating important contexts. Additionally, in specific domains, PLMs often struggle to keep pace with the latest knowledge. Continuous pretraining or fine-tuning is necessary to keep PLMs updated with the most recent information. However, this process is resource-intensive and demands access to up-to-date, high-quality training data.\nLLM-based Methods. In recent years, the rise of LLMs has revolutionized document-level Bio-RE by leveraging their vast contextual understanding, extensive pre-trained knowledge, and ability to capture complex dependencies across long textual spans. ChatIE [14] leverages a multi-turn question-answering approach with ChatGPT to decompose complex information extraction (IE) tasks into simpler sub-tasks. GPT-RE [15] enhances in-context learning for RE by employing task-aware demonstration retrieval and gold label-induced reasoning. AutoRE [16] employs a novel Relation-Head-Facts paradigm and Parameter Efficient Fine-Tuning (PEFT) with LLM, achieving state-of-the-art results on the Re-DocRED dataset. Multi-Span [38] redefines document-level RE as a machine reading comprehension problem by transforming the identification of entities and relations into a structured question-answering process. To generate example answers, the approach integrates LLMs during the question construction phase, enhancing the model's contextual understanding and reasoning capabilities. Furthermore, it introduces a hybrid pointer-sequence labeling model that effectively handles the extraction of zero or multiple answers. Additionally, several studies have explored the application of LLMs for code generation (Code-LLMs) in IE tasks [39]\u2013[41]. These methods highlight the potential of LLMs in RE by leveraging contextual understanding and pre-trained knowledge.\nTo the best of our knowledge, none of these approaches has introduced a fine-tuning recipe specifically tailored to document-level Bio-RE, nor have they developed a dedicated RAG approach for it, let alone integrated the two."}, {"title": "III. METHODOLOGY", "content": "In this section, we provide a detailed introduction to our proposed framework. As illustrated in Figure 3, our framework consists of two stages: the ADRCM fine-tuning stage and the CUI RAG stage. In the ADRCM fine-tuning stage, the IoRs prompt iteratively guides ChatGPT to generate synthetic data labeled consistently with the original training data. The training data is split according to the head-relation-tail triplet and then merged with the synthetic data to form ADRCM-structured data. This combined data is used to fine-tune the LLaMA2-7B-Chat model with Low-Rank Adaptation (LORA) [42]. In the CUI RAG stage, relevant snippets are retrieved from biomedical databases based on the entities in the test data and their corresponding CUIs. These snippets, together with the test data, are analyzed by the fine-tuned LLaMA2-7B-Chat model to determine the predicted relations.\nGiven a biomedical document $d_i$ containing a set of biomedical entities $E_i$, with $h_{i,j} \\in E_i$ and $t_{i,j} \\in E_i$ denoting the pair of head and tail entity. Given a predefined set of relation classes $R$, the document-level Bio-RE task is to predict the relation $r_{i,j} \\in R$ between the pair of entities $h_{i,j}, t_{i,j}$. Here, $i$ indexes the document, and $j$ indexes the entity pair within that document.\nIn recent years, LLMs have been extensively applied to data augmentation due to their powerful generative capabilities. These models can produce high-quality synthetic data that closely mirrors real-world data, which is particularly valuable in the field of document-level Bio-RE. This field often faces challenges with the scarcity and high cost of obtaining annotated data, making LLMs an essential tool for improving data availability and model performance. However, most current approaches are designed for sentence-level data [43]\u2013[46], which typically feature a single semantic structure, making them overly simplistic and lacking the broader context found in longer texts. Furthermore, approaches targeting document-level data often rely on LLMs to generate multiple labels simultaneously [47], [48]. This practice exacerbates the issue of hallucinations, thereby reducing the reliability of the generated annotations.\nTo address these issues, we propose the IoRs prompt, which guides ChatGPT to summarize a specific pair of entities and their relation, ensuring that the synthetic data matches the original training labels through iteration, as illustrated in Algorithm 1. An example of the IoRs prompt is presented in Figure 4, and the procedure for generating synthetic data is described as follows:\n1)\tWe prompt ChatGPT to create a summary based on document $d_i$, the head entity $h_{i,j}$, the tail entity $t_{i,j}$, and the relation $r_{i,j}$. The prompt guides the model to focus on $h_{i,j}$, $t_{i,j}$, and $r_{i,j}$ to produce a focused and stylistically consistent summary of $d_i$, yielding the summary $ds_{i,j}$.\n2)\tSubsequently, ChatGPT is used to perform relation confirmation based on the summary $ds_{i,j}$, head entity $h_{i,j},$\n\t\nFirstly, for each sample $o_i$ in the original training dataset $D_o$, we split it based on the triplets to create $sp_i$, in which each document corresponds to a single triplet. This process is illustrated in the following equations.\n$D_o = \\{o_i \\mid i = 1, 2, ..., N\\}$ (1)\n$o_i = (d_i, \\{(h_{i,j}, t_{i,j}, r_{i,j}) \\mid j = 1, 2, ..., J_i\\})$ (2)\n$\\xrightarrow[o_i]{split} sp_i = \\{(d_i, h_{i,j}, t_{i,j}, r_{i,j}) \\mid j = 1, 2, ..., J_i\\}$ (3)\nIn Equation 1, the original training dataset $D_o$ is defined as containing $N$ samples $o_i$. Each sample $o_i$, as shown in Equation 2, consists of a document $d_i$ and $J_i$ triplets $(h_{i,j}, t_{i,j}, r_{i,j})$. In Equation 3, each $o_i$ is split into $sp_i$, a set containing $J_i$ elements, where each element is composed of the same document $d_i$ and a different triplet $(h_{i,j}, t_{i,j}, r_{i,j})$. This structure in $sp_i$ represents a mapping of multiple triplets to a single document.\nNext, we generate synthetic data $sd_i$ corresponding to $o_i$ using the IoRs prompt.\n$o_i \\xrightarrow{IoRs} sd_i = \\{(ds_{i,j}, h_{i,j}, t_{i,j}, r_{i,j}) \\mid j = 1, 2, ..., J_i\\}$ (4)\nHere, the IoRs prompt generates a different document $ds_{i,j}$ for each triplet $(h_{i,j}, t_{i,j}, r_{i,j})$, resulting in $sd_i$ as a mapping of each unique triplet to a distinct document.\nThen, $sp_i$ is merged with the synthetic data $sd_i$ to create ADRCM-structured data $Asd_i$, which can be expressed as:\n$Asd_i = sp_i \\cup sd_i = \\{(d, h_{i,j}, t_{i,j}, r_{i,j}) \\mid d \\in \\{d_i, ds_{i,j}\\}, j = 1, 2, ..., J_i\\}$ (5)\nIn this structure, $d$ represents either the original document $d_i$ or the synthetic document $ds_{i,j}$, each corresponding to a triplet $(h_{i,j}, t_{i,j}, r_{i,j})$.\nBy iterating over all samples $o_i$ in the original training dataset $D_o$, we combine $Asd_i$ to form the ADRCM-structured dataset $AsD$. This can be expressed as follows:\n$AsD = \\{Asd_i \\mid i = 1, 2, ..., N\\}$ (6)\nADRCM enables $AsD$ to include diverse entity pairs and relations mapped to the same document. Fine-tuning with this data implicitly trains the model to focus on document sections that are crucial for accurately understanding specific relations. This targeted learning process allows the model to more effectively isolate relevant information during inference. Moreover, $AsD$ includes instances where the same entity pair and relation are mapped to different documents. Fine-tuning with such data exposes the model to varied contexts for each entity-relation pair, allowing it to develop a deeper understanding of how relational meaning shifts depending on context. This capability is particularly valuable for capturing the domain-specific nuances of biomedical texts. Together, these characteristics foster the development of cross-sentence inference skills, enabling the model to track relational cues across different sections of a document and effectively interpret the diverse expressions of relations across sentences. This approach enhances the model's ability to capture complex, cross-sentence relations, which is essential for effective document-level Bio-RE.\nFinally, we use $AsD$ to fine-tune the LLaMA2-7B-Chat model through LoRA. The fine-tuning procedure can be formally described as follows:\n$M \\leftarrow LORA(M, I, AsD)$ (7)"}, {"title": "D. CUI RAG", "content": "To address the prevalent challenges of factual hallucination [49], knowledge obsolescence [50], the lack of domain-specific knowledge in LLMs [51], as well as the effects of biomedical entity synonymy and aliases on retrieval accuracy, we propose a specialized RAG method tailored for the biomedical domain, termed CUI RAG. This method employs Concept Unique Identifiers (CUIs) from the Unified Medical Language System (UMLS) [52] as indexes to define the retrieval scope and enhance the relevance of retrieval results. In the following sections, we provide a detailed description of our CUI RAG method.\n\u2022\tRetrieval Source. We primarily use Wikipedia and several NCBI biomedical databases, such as Gene, MeSH, and Protein, as our retrieval sources. These biomedical-specific sources provide a rich repository of accurate and up-to-date information, ensuring a broad and reliable foundation for incorporating external biomedical knowledge.\n\u2022\tHierarchical Indexing Strategy. For the Bio-RE task, we propose a Hierarchical Indexing Strategy. Traditional indexing strategies often rely on simple chunking methods [53]\u2013[55]. However, due to the synonymy and aliases of biomedical entities, as well as the vastness of biomedical databases, these chunking strategies no longer meet the requirements of the Bio-RE task. Inspired by the CUIs from the UMLS, we propose an indexing strategy that combines CUIs with chunking, ensuring more precise and comprehensive indexing for biomedical data. Specifically, we construct a hierarchical indexing structure by first indexing the CUIs of biomedical entities as the primary layer. Next, we assign each document related to an entity to its corresponding CUI index and then further index the document chunks as the secondary layer.\nUsing CUIs instead of entity names as indexes mitigates the effects of synonymy and aliases in biomedical entities. CUIs serve as unique identifiers that consolidate synonyms and alternative terms for the same concept, reducing inconsistencies arising from varied terminologies. This approach thus enhances retrieval accuracy and relevance, particularly in complex biomedical contexts where entities often have aliases or ambiguous meanings.\n\u2022\tCUI Retrieval and Generation. We use an embedding model to convert the document chunks into vectors, creating a hierarchical vector structure with a similar organization. The retriever, using the input head and tail biomedical entities $(h_{i,j}, t_{i,j})$ along with their corresponding CUIs, searches this hierarchical vector structure to locate the relevant document chunk vectors. Next, it selects the relevant biomedical snippets $dr_{i,j}$ based on cosine similarity. These relevant biomedical snippets $dr_{i,j}$ are combined with the original input to form the final inference prompt, which is fed into the fine-tuned model $M$ to obtain the predicted relation $r_{i,j}$. This process can be formally described as follows:\n$f_{i,j} = M(I, d_i, dr_{i,j}, h_{i,j}, t_{i,j})$ (8)\nIn this equation, $i$ denotes the index of the sample in the dataset, and $j$ represents the $j$-th entity pair within that sample. $r_{i,j}$ represents the predicted relation. The fine-tuned model $M$ receives the task instruction $I$, the original document $d_i$, the relevant biomedical snippets $dr_{i,j}$ and the head and tail entities $(h_{i,j}, t_{i,j})$ as inputs. An example of this process is illustrated in the Figure 5. Compared to traditional RAG methods, CUI RAG leverages CUIs to restrict the retrieval scope to documents specifically focused on the head and tail entities, significantly narrowing the search range, improving retrieval relevance, and reducing the impact of entity synonymy and aliases on retrieval."}, {"title": "IV. EXPERIMENTS", "content": "We evaluated our framework on three public document-level Bio-RE datasets: CDR, GDA, and BioRED. The dataset statistics are shown in Table I.\nCDR [11]. The Chemical-Disease Reactions (CDR) dataset, constructed from PubMed abstracts, contains 1,500 human-annotated documents divided equally into training, development, and test sets. It focuses on the binary classification task of identifying Chemical-Induced-Disease relations between chemical and disease entities.\nGDA [9]. The Gene-Disease Associations (GDA) dataset is a large-scale biomedical dataset constructed from MEDLINE abstracts using distant supervision. Following Christopoulou et al. [18], we split the training set into 23,353 training documents and 5,839 development documents. The primary task is to predict binary interactions between Gene and Disease entities.\nBioRED [17]. Unlike previous datasets that focus only on binary relations and a single entity pair, the biomedical relation extraction dataset (BioRED) includes various entity types such as gene, disease, chemical, variant, species, and cell line. It also encompasses multiple relation pairs (e.g., gene-disease, chemical-chemical) and various types of relations.\nDuring the ADRCM fine-tuning stage, we set the threshold $\\beta$ for IoRs to 3 and utilized the GPT-3.5-turbo-0125 API for ChatGPT. LLaMA2-7B-Chat was selected as the backbone model, and the PEFT method, LoRA, was employed. For the CDR dataset, we set the LoRA decomposition rank to 16 and LORA alpha to 32. For the GDA and BioRED datasets, we set the LORA decomposition rank to 64 and LoRA alpha to 16. Across all three datasets, a learning rate of 2e-4 and a LORA dropout rate of 0.1 were used. During the inference stage, jina-embeddings-v2-base-en was chosen as the embedding model [58]. This model uses Attention with Linear Biases instead of traditional positional embeddings to efficiently encode extended text sequences while maintaining strong performance. Additionally, it supports a sequence length of up to 8192 tokens.\n1)\tCDR and GDA Results: We conducted comprehensive and comparative experiments on the CDR and GDA datasets, with the results presented in Table II. The baseline models are categorized into three groups: graph-based, transformer-based, and LLM-based models.\nGraph-based models include CGM2IR [21], FILR [28], HTGRS [31], FCDS [56], and Topic-BiGRU-U-Net [27]. Transformer-based models include TriA-BioRE [37], SSAN [32], ALOTP [33], DocRE-II [34], DocRE-SD [36], SAIS [35], and PSD [57]. LLM-based models include Multi-Span [38], LLaMA2-7B-Chat, GPT-3.5, and GPT-4.\nAs shown in Table II, our framework (Ours) demonstrates significant improvements in the CDR and GDA datasets, achieving new state-of-the-art performance.\nOn the CDR dataset, our framework achieves overall $F_1$ of 88.2%, Intra-$F_1$ of 90.8%, and Inter-$F_1$ of 82.3%. This performance surpasses the current state-of-the-art graph-based model, Topic-BiGRU-U-Net, by 1.1% in overall $F_1$. Compared to the powerful GPT-4 model, our framework shows an improvement of 8.2% in overall $F_1$, and compared to the backbone model LLaMA2-7B-Chat, it achieves a substantial enhancement of 16.1%.\nOn the GDA dataset, our framework attains overall $F_1$ of 88.7%, Intra-$F_1$ of 90.9%, and Inter-$F_1$ of 77.1%. This represents a 1.3% improvement over FCDS, 24.1% improvement over GPT-4, and 19.3% improvement compared to the backbone model LLaMA2-7B-Chat. Additionally, we observe that our framework exhibits a notable enhancement in Inter-$F_1$. On the CDR dataset, it outperforms the backbone model LLaMA2-7B-Chat by 19.3% and GPT-4 by 9.8%. Similarly, on the GDA dataset, our framework demonstrates a remarkable improvement, surpassing LLaMA2-7B-Chat by 32.3% and GPT-4 by an even more substantial 37.4%, and outperforming HTGRS by 7.4%. Notably, it also achieves approximately 10% improvement over most graph-based and transformer-based models. The significant performance improvement is primarily attributed to the effectiveness of ADRCM fine-tuning. ADRCM enables the model to focus on the most relevant information for each specific relation, while also allowing it to capture and distinguish critical relational cues across sentences. The observed gains on the CDR and GDA datasets underscore that ADRCM fine-tuning strengthens the model's cross-sentence inference capabilities, enabling it to better understand complex biomedical relations and achieve superior performance compared to other models.\n2)\tBioRED Results: The CDR and GDA datasets have relatively limited types of relations and entities. To further evaluate the performance of our framework in scenarios involving multiple entity types, multiple relation types, and a higher density of information (with more relations per document on average), we conducted experiments on the BioRED dataset. The results of these experiments are presented in Table III. We compare the performance of our framework against nine baseline models: TriA-BioRE [37], BERT-GT [59], PubMed-BERT [60], ATLOP [33], SAIS [35], HTGRS [31], LLaMA2-7B-Chat, GPT-3.5, and GPT-4. As shown in Table III, our framework achieves $F_1$ of 72.7%, demonstrating state-of-the-art performance on the BioRED dataset, consistent with results on the previous two datasets. Although HTGRS has the highest recall, its $F_1$ is lower due to a relatively low precision. In contrast, our framework sets a new benchmark by surpassing HTGRS by 5.8% and outperforming GPT-4 by 25.9% in $F_1$. Additionally, compared to the backbone model LLaMA2-7B-Chat, our framework achieves a substantial improvement, increasing $F_1$ from 24.9% to 72.7%. These results underscore the exceptional performance and robustness of our framework in handling information-dense datasets with diverse relations.\nTo further assess the impact of our proposed IoRs prompt, we generated synthetic data using three different prompts: IoRs prompt, vanilla prompt, and chain-of-thought prompt, as illustrated in Figure 6. To ensure the fairness of the experiment, we randomly sampled 487 examples from each dataset produced by these prompts. The LLaMA2-7B-Chat model was then fine-tuned using the synthetic data generated by each prompt, and its performance was evaluated on the CDR and GDA datasets.\nAs shown in Table IV, the LLaMA2-7B-Chat model, fine-tuned using synthetic data generated by the IoRs prompt, achieves overall $F_1$ of 80.0%, Intra-$F_1$ of 84.1%, and Inter-$F_1$ of 70.4% on the CDR dataset. On the GDA dataset, it achieves overall $F_1$ of 80.7%, Intra-$F_1$ of 84.5%, and Inter-$F_1$ of 61.2%. Furthermore, it outperforms the model fine-tuned with data from the chain-of-thought prompt by 1.4% on the CDR dataset and 4.3% on the GDA dataset in $F_1$. It also surpasses the model fine-tuned with data from the vanilla prompt by 2.4% on the CDR dataset and 7.4% on the GDA dataset in $F_1$. Additionally, it achieves superior performance in both Intra-$F_1$ and Inter-$F_1$. Based on our analysis and observations, IoRs outperforms Chain of Thought for two key reasons. First, Chain of Thought suffers from error propagation, caused by an incorrect relation identified in the initial step. Second, its summaries in the second step sometimes fail to focus on the specific entity pair and their relation. In contrast, our proposed IoRs effectively address these issues. Through relation confirmation, it ensures that the generated summary corresponds to the original relation, and by iteratively refining mismatched summaries, it enables the model to concentrate on the specific entity pair and their relation."}, {"title": "E. Ablation Study", "content": "To analyze the role and impact of each component of our framework", "components": "synthetic data, ADRCM fine-tuning, and CUI RAG.\nAs shown in Table V, the performance decreases with the removal of each component, demonstrating the contribution and importance of every element in our framework. Specifically, the removal of synthetic data during fine-tuning results in 2.9% $F_1$ decrease on the CDR dataset and 2.4% $F_1$ decrease on the GDA dataset. This highlights the significant impact of synthetic data generated by the IoRs prompt. When we skip ADRCM fine-tuning and use the backbone model with CUI RAG for inference, we observe a substantial performance drop of 11.2% $F_1$ on the CDR dataset and 15.5% $F_1$ on the GDA dataset, with an even more pronounced decline in Inter-$F_1$ of 14.7% and 29%, respectively. This further demonstrates the critical role of ADRCM fine-tuning in improving the model's cross-sentence inference capabilities.\nTo further validate the impact of ADRCM, we conducted an experiment in which ADRCM was removed during fine-tuning, using only the original training data and synthetic data. In this scenario, the model predominantly predicts positive relations, leading to a recall close to 100%. This outcome highlights the critical role of ADRCM in the fine-tuning process, indicating that the improvements achieved with ADRCM fine-tuning are specifically due to ADRCM itself, rather than the fine-tuning process.\nFurthermore, directly using the ADRCM fine-tuned model for inference without CUI RAG results in a 3.3% $F_1$ decrease on the CDR dataset and a 1% $F_1$ decrease on the GDA dataset. Combined with the comparisons in the second (w/o ADRCM fine-tuning) and sixth rows (LLaMA2-7B-Chat), CUI RAG enhances performance by increasing $F_1$ by 4.9% on the CDR dataset and 3.8% on the GDA dataset. These results suggest that our CUI RAG enhances retrieval relevance and supplies the model with valuable information, thereby aiding in solving the Bio-RE task. Finally, the removal of CUI in RAG, with only the chunking strategy used during inference, leads to 5.8% decrease in $F_1$ on the CDR dataset and 3.2% decrease in the GDA dataset. Notably, $F_1$ of RAG without CUI is even lower than that of without CUI RAG. Based on our observations, the cause of this outcome is the inherent polysemy and aliases of biomedical entities. The chunking strategy, which relies solely on text"}]}