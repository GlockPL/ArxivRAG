{"title": "Leveraging Large Language Models for Active Merchant Non-player Characters", "authors": ["Byungjun Kim", "Minju Kim", "Dayeon Seo", "Bugeun Kim"], "abstract": "We highlight two significant issues leading to the passivity of current merchant non-player characters (NPCs): pricing and communication. While immersive interactions have been a focus, negotiations between merchant NPCs and players on item prices have not received sufficient attention. First, we define passive pricing as the limited ability of merchants to modify pre-defined item prices. Second, passive communication means that merchants can only interact with players in a scripted manner. To tackle these issues and create an active merchant NPC, we propose a merchant framework based on large language models (LLMs), called MART, which consists of an appraiser module and a negotiator module. We conducted two experiments to guide game developers in selecting appropriate implementations by comparing different training methods and LLM sizes. Our findings indicate that finetuning methods, such as supervised finetuning (SFT) and knowledge distillation (KD), are effective in using smaller LLMs to implement active merchant NPCs. Additionally, we found three irregular cases arising from the responses of LLMs. We expect our findings to guide developers in using LLMs for developing active merchant NPCs.", "sections": [{"title": "I. INTRODUCTION", "content": "EXCHANGING in-game items is an integral part of open-world role-playing games because the utility of an item often depends on the current character status of a player. For example, a character with high agility may not benefit from an item that enhances agility. Thus, game developers implement an exchange system in their open-world games to enhance gameplay and item utility.\nWhile games commonly feature merchant non-player characters (NPCs) to facilitate item exchanges, these interactions are usually scripted; the merchant only enables players to buy and sell items at fixed prices, but the process differs from real-world transactions. Typically, developers do not allow merchants to alter prices or communicate in free form; instead, they simply present a fixed price to the player without any negotiation. To mirror the real world, We suggest a novel framework that uses large language models (LLMs) and enables merchant NPCs to negotiate with players.\nTo create a more active merchant NPC, we need to address two issues that cause the merchant to act passively: pricing and communication. First, regarding passive pricing, the merchant has no authority to adjust item prices. Instead, the game developers decide item prices based on the item utility in the game. However, in the real world, sellers can adjust the prices of their goods according to their situation. To the best of our knowledge, gaming industry researchers have not adequately filled this gap. As item descriptions may contain sufficient information about item utility, we use item descriptions to estimate item's value. Specifically, we let LLMs appraise game items by observing other game items.\nSecond, regarding passive communication, merchants can only interact with players in a scripted manner. Researchers have attempted to create more immersive interactions by using LLMs [1], [2]. However, the way merchants communicate has been given limited focus, which remains a one-way interaction. Current merchant NPCs simply display a predefined list of items for players to choose from, and players respond by clicking on items to make a purchase. This purchasing experience is uniform across all interactions with a merchant, regardless of the individual player involved in the transaction. To enable two-way communication, we propose a negotiation style that mirrors real-world transactions. Through this study, we explore whether LLMs can be used to foster a negotiating interaction within the merchant context.\nIn this paper, we propose a framework for developing a More Active meRchanT NPC, called MART. This framework consists of two main components: appraiser and negotiator. The appraiser module addresses the issue of passive pricing by estimating the value of given items. The negotiator module addresses the passive communication issue by negotiating with players. As game developers have diverse requirements when deploying their games, we conducted experiments to compare potential candidates for each module using a public WoW Classic game item dataset. Specifically, we tested both finetuning methods and n-shot prompting methods on the family of Llama 3 models, which come with a wide range of parameter sizes from 1 billion to 405 billion.\nThis study makes the following contributions:\n\u2022 We propose an LLM-based framework, MART, for developing active merchant NPCs.\n\u2022 Our findings show that LLMs enable merchants to appraise game items, highlighting that supervised finetuning can balance performance, efficiency, and reliability.\n\u2022 Our results reveal that LLMs enable merchants to negotiate item prices, highlighting that knowledge distillation efficiently achieves high persuasiveness.\n\u2022 By statistically and qualitatively analyzing the results, we provide several design options for developing active merchants in a game."}, {"title": "II. MART FRAMEWORK", "content": "We propose MART\u00b9, an LLM-powered framework for active merchant NPC. This framework consists of two main modules: negotiator and appraiser. Inspired by the behavior of real-world merchants, MART negotiates item purchases with players. When a player expresses interest in buying an item, the appraiser module suggests a retail price for the item. Based on this suggestion, the negotiator module begins negotiations with players who wish to buy the item from the merchant NPC. This scenario is different from the purchasing experience of players in current games, as shown in Figure 1.\nFirst, the appraiser module is designed using a language model that interprets an item description to estimate its retail price. The module takes item descriptions presented as natural language sentences, which include details such as required level, effects, and durability. As such descriptions can vary across different games, we opted for a natural language representation to attain versatility. In Section III, we introduce LLM-based appraiser modules using two straightforward approaches and evaluate their performance.\nSecond, the negotiator module employs a language model to facilitate negotiation dialogues with players. This module receives the item descriptions, retail price, and history of previous conversations. It then generates the appropriate response aimed at persuading the player. Since effective negotiation involves various tactics to persuade players, we experimented LLM-based negotiator modules with two simple approaches that integrate 10 tactics, as detailed in Section IV."}, {"title": "III. APPRAISER MODULE", "content": "To develop appraisers, we tested two approaches: n-shot in-context learning (ICL) and supervised finetuning (SFT). In this section, we outline each approach and illustrate our findings through an experiment on a WoW Classic item dataset."}, {"title": "A. Two possible approaches", "content": "First, to leverage the ability of LLMs to generalize from a set of given examples, we tested the ICL method. ICL involves querying LLMs with relevant demonstrations to improve their reasoning capabilities. Thus, we directly employed LLMs and provided ten random examples in the prompt. We used Llama models, a popular open-source family of LLMs: Llama-3.1 8b, 405b, and 3.2 1b. Note that ICL does not require any additional training to update the LLM parameters.\nSecond, owing to the substantial computational resources and time required by the 405 billion parameter model, we tested the SFT method on smaller LLMs. To avoid catastrophic forgetting\u00b2, we froze their parameters and only trained an additional adapter. When we input an item description, the smaller LLM transforms the description into a single latent vector. Thereafter, the additional adapter uses the vector to predict the retail price of the item as a regression problem. We used Llama 3.1 8b and 3.2 1b."}, {"title": "B. Used Dataset", "content": "By extending the WoW Classic item dataset\u00b3, we created a dataset consisting of a paired list of purchasable items and their prices. Dataset construction followed three steps: First, we extracted 3,376 fundamental items by excluding item derivatives from the crawled dataset to simplify the problem. We then removed 106 items priced below 10 coppers (the cheapest currency unit in WoW) to make enough room for price negotiation during transactions. Finally, we converted all item prices into coppers, using the conversions of 1 gold to 100 silver and 1 silver to 100 coppers. As a result, we collected a total of 3,270 items, with prices ranging from 10 coppers"}, {"title": "C. Evaluation metrics", "content": "To evaluate the suitability of the two methods for implementing an appraiser module, we used four metrics: mean absolute percentage error (MAPE), standard deviation, skewness, and unexpected output rate. First, we used MAPE. Due to the wide range of item prices (from 10 to 57,018 coppers), the absolute errors of higher-priced items may overshadow those of lower-priced items. Therefore, we used percentage errors instead of absolute errors. We computed MAPE as the ratio of error to true price, as illustrated in Equation 2, where \u0177 is the predicted price and y is the true price for an item i.\n$PE = \\frac{\\hat{y}_i - y_i}{y_i}$ (1)\n$MAPE = E_i[|PE|]$. (2)\nSecond, we used the standard deviation \u03c3 of percentage errors (PEs). This metric can reveal the extent of variability in appraised prices. If the percentage errors are similar across different items, the standard deviation should be low.\nThird, we measured the skewness of PEs. Skewness indicates whether a distribution leans toward positive or negative values. Therefore, we believe that analyzing skewness can help us determine if a model tends to underestimate or overestimate item prices. Mathematically, we computed skewness using Equation 3, where u indicates the mean of PEs.\n$Skewness = E \\[(\\frac{PE - \\mu}{\\sigma})^3]$. (3)\nLastly, we calculated the rate of unexpected outputs. When LLMs appraise an item, they may generate ambiguous appraisals to extract an exact price from the output sentences. For example, they sometimes suggest multiple prices even if we request a single prediction. We referred to these as unexpected outputs and estimated their frequency among the items. Note that this error only occurred in ICL models because SFT models directly produced the retail price through their prediction head. While LLMs can identify such unexpected cases, we manually labeled these errors."}, {"title": "D. Implementation detail", "content": "We implemented four appraisers using the following specifications. First, we used public APIs\u2074 to call ICL models. When calling the LLMs, we used default hyperparameter settings, including temperature and top-p values. Second, we implemented the SFT models using PyTorch 2.5.1 [3] and transformers 4.46.2 [4]. As an adapter head for prediction, we applied average pooling on the last hidden state and transformed it into a single prediction using feed-forward layers. Third, we used the early-stopping method for training SFT models. The models are trained with two A6000 GPUs."}, {"title": "E. Results", "content": "Table I shows the result of our experiments, comparing ICL and SFT methods. Of the five models, the ICL-405b achieved the best performance. It successfully outputted a retail price (94.8% of the cases) with the lowest MAPE score (1.34%) and produced a few unexpected outputs (5.2%), while it was slightly skewed toward underestimation (-5.06). The second-best model was the SFT-8b. It exhibited a slightly higher MAPE score (2.66%) and the lowest absolute skewness toward underestimation (-3.47). Meanwhile, the SFT-1b demonstrated lower performance than the best model (3.59%) with a similar underestimation (-5.84). These results are different from those of smaller ICL models. The ICL-1b exhibited very high MAPE (14.68%) with highly overestimated prices (10.23) and a high unexpected output rate (29.05%). Similarly, the ICL-8b overestimated prices (6.85) with a moderate level of MAPE (4.34) and a high unexpected output rate (20.59%)."}, {"title": "F. Discussion", "content": "We discuss our results in terms of three factors considering game deployment: performance, efficiency, and reliability. First, the appraiser module has the potential to be used in a game because of its performance. Except for ICL-1b, five models demonstrated a MAPE of less than 5%. While the difference may seem substantial for high-priced items, it does not exceed 100 coppers for over half of the items, considering that the median price was 1,238 coppers. As gold coins are more frequently used in the WoW Classic, a difference of 100 coppers is acceptable. Moreover, when using larger ICL models, the appraised prices aligned more closely with the true prices. Therefore, for game developers seeking a more precise appraiser module, ICL-405b is the best option, as it exhibited an appraisal error of less than 16 coppers for the median price.\nSecond, the SFT method is efficient for developing an appraiser module. Results show that SFT-8b performed much closer to ICL-405b than to ICL-8b; even the SFT-8b and ICL-8b used almost identical number of parameters. Also, the SFT-1b outperformed the two ICL models, ICL-1b and ICL-8b. These results imply that it is possible to use a smaller LLM to implement an appraiser within a low-resource environment by finetuning it. Note that the ICL models achieved high performance by observing ten random pairs of item descriptions and prices. Researchers have reported that the performance of ICL methods can be improved by carefully curating examples or increasing the number of examples[5]. However, this curation demands additional human resources, and increasing the number of examples incurs higher computational costs. By contrast, a dataset for SFT can be generated with significantly fewer resources, using pairs of items and their prices.\nThird, it is worth noticing that ICL methods can sometimes be unreliable when playing the role of an appraiser. We observed that ICL models sometimes produce unexpected outputs. For instance, ICL-405b, which employs the largest LLM, generated multiple price candidates or a continuous range of prices, despite our request for a single price output. Moreover, smaller ICL models sometimes totally failed to predict prices. Although we did not adopt any post-processing methods for these outputs, game developers should prevent such failures in their games. Alternatively, developers can use the SFT method, ensuring an LLM predicts a specific price."}, {"title": "IV. NEGOTIATOR MODULE", "content": "To develop negotiators, we tested two approaches: zero-shot prompting (ZSP) and knowledge distillation (KD). We adopted two methods different from the appraiser module because it is hard to obtain a supervised set of negotiations. In the following subsections, we describe our methods, dataset generation procedure, and details of the experiments. Then, we discuss our findings by comparing these two approaches."}, {"title": "A. Two possible approaches", "content": "First, we employed the ZSP method in which an LLM generates negotiation dialogues without being exposed to examples. We initially considered a na\u00efve negotiation method without using any specific tactics. This approach relied on using the pretrained knowledge of LLMs, which reflects a general understanding of the world; consequently, the generated negotiation strayed significantly from the intended game setting. Thus, we inputted 10 negotiation tactics within the prompt, as shown in Table II, which are inspired by [6], [7], [8], [9]. We evaluated three Llama variants as in the appraiser.\nSecond, we used the KD method to improve the performance of smaller LLMs. By transferring the knowledge of a larger model to a smaller model, the distillation reduces computational cost while maintaining performance. We trained smaller student models on dialogue dataset generated by larger teacher model. Here, to distill the persuasiveness of teacher model, we asked them to choose appropriate tactic before generating explicit utterances. To reduce the computational demands of LLMs during training, we adopted quantization and low-rank adaptation (LoRA) [10]. Using these methods, we distilled knowledge about negotiation from Llama 3.1 405b to two smaller LLMs: Llama 3.1 8b and 3.2 1b."}, {"title": "B. Dataset", "content": "We prepared a dataset by generating a negotiation dialogue for each item in the appraiser dataset. To simulate a negotiation dialogue, we used two agents: merchant and player. As the merchant, we used Llama 3.1 405B, the teacher model. As the player, we used GPT-40 with input prompts about tactics. We used different models for these two agents to (1) avoid adopting a similar reasoning process and (2) make the player as similar as possible to human beings, as reported in [11]. To simulate the diversity of real-world customers, we used a temperature value of 1.0 for GPT-40.\nThe negotiation procedure was as follows. Before starting a negotiation, both agents received an item description of the negotiation subject as shared information. The agents started with different prices for each item: the player wanted to buy the item at a discount of 10% to 25%. The player started the negotiation with an utterance \"Hello. I'm looking for [the item name].\" While an actual negotiation might contain greetings or small talk in the real world, we avoided generating messages that are less related to the negotiation to make the model focus on learning negotiations.\nAfter starting the utterance, the player and merchant negotiated through text, proceeding until the player decided whether to buy the item or not. Until the decision was made, the merchant kept persuading the player to buy the item to simulate a real-world merchant. The player could terminate the conversation by mentioning \u201cconversation over.\u201d To avoid long dialogues, we set the maximum number of turns to 15. As a result, we generated 2,943 conversations: 2,616 conversations from the training set items and 327 conversations from the validation set items."}, {"title": "C. Implementation detail", "content": "The negotiator was implemented in the same way as the appraiser module, with differences only in the training details. For Python libraries, we used transformers 4.46.2 [4], trl 0.12 [12], and peft 0.13 [13]. For training, we employed 4-bit quantization and gradient accumulation across four steps on a single GPU in order to reduce memory consumption."}, {"title": "D. Evaluation metrics", "content": "We compared three ZSP and two KD models using three measures: persuasiveness, dominance, and agreement. First, we measured the persuasiveness of utterances generated by the negotiator. Similar to commercial behavior in the real world, the merchant NPC should effectively persuade players to buy or sell an item at a good price. Various tactics are used in an effective negotiation; so, we aimed to evaluate the effectiveness of the negotiator in using 10 different tactics to create persuasive statements. To measure persuasiveness, we employed G-Eval [14], a widely-used evaluation method using LLMs. The method directly asks GPT-4 to evaluate an input text according to given criteria. Specifically, we used a 5-point scale and averaged 20 runs following G-Eval.\nSecond, we measured the dominance of the merchant over the player during the negotiation. This metric indicates whether the merchant holds more power in the relationship with the player, highlighting the concept of power dynamics [15]. A human merchant usually has the initiative in price negotiation, rather than giving the initiative to the customer. So, as a negotiated price increases, the merchant profits more while the player incurs greater losses. In other words, the negotiation is a type of zero-sum game. Considering such power dynamics, we measured dominance using Equation 4, where yi, ym, and yp indicate the agreed price, retail price, and price desired by the player, respectively. The equation quantifies the ratio between the profit gained by the merchant $(y_i - y_p)$ and the price gap between the two agents $(y_m - y_p)$.\n$Dominance = E_i [ \\frac{y_i - y_p}{y_m - y_p} ]$. (4)\nThird, we defined the agreement rate. In the real world, two agents in negotiation may not reach an agreement. We determined how frequently the models concluded negotiations with an agreement. Based on the labeled result for dominance, we estimated the number of dialogues ending with an agreement. Then, the agreement rate was computed as the ratio of the agreed dialogues to the total number of dialogues."}, {"title": "E. Results", "content": "Table III shows the results of our experiments, comparing ZSP and KD methods. The results show that the KD-8b performed the best and successfully used persuasive tactics. The model achieved a score of 3.99 in terms of persuasiveness, followed by ZSP-405b (3.92), ZSP-8b (3.74), KD-1b (3.65), and ZSP-1b (2.95). The ZSP-405b had the strongest dominance (0.47), followed by ZSP-8b (0.42), and KD-8b (0.40). The ZSP-8b had the highest agreement (96.94%), followed by ZSP-405b (90.83%) and ZSP-1b (90.52%).\nWe further performed statistical tests to verify differences between the five models in terms of persuasiveness and dominance. We used a one-way ANOVA and Tukey-HSD posthoc test for each metric, using the statsmodels library [16]. Tables IV and V show the statistical result. First, we observed that model differences affect the persuasiveness (p < 0.001). In detail, pairwise differences are all significant: ZSP-405b versus KD-8b (p=0.04), ZSP-8b versus KD-1b (p=0.004), and the other eight pairs (p < 0.001) are all significant. Second, we also observed that model differences affect the dominance (p < 0.001). Pairwise differences are all significant except for two pairs: ZSP-405b versus ZSP-8b (p=0.246) and ZSP-8b versus KD-8b (p=0.891) are statistically insignificant."}, {"title": "F. Discussion", "content": "In open-world games, we believe it is important for merchant NPCs to provide immersive experiences to players. To achive such immersion, developers should consider two essential parts of the merchant: its purpose and position in the game world. We discuss our findings based on these two parts. First, small models can effectively support the objectives of a merchant by using the KD method. Note that the persuasiveness metric measures whether the merchant successfully employed tactics to persuade the player. Therefore, a higher persuasiveness score indicates that the negotiator is better equipped to fulfill the purpose of the merchant. The results show that the largest model (ZSP-405b) achieved a significantly high score. Additionally, we observed that the KD models effectively learnt persuasive tactics from their teacher model, Llama 3.1 405b. In other words, the KD models generally outperformed the ZSP models with the same size. So, it is reasonable to use smaller KD models instead of large ZSP models; we recommend KD-8b as the best option.\nSecond, the ZSP and KD methods can introduce different merchant personalities. In WoW, there are many merchants in a variety of situations, including differences in race and faction. These factors should be considered when developing merchants to enhance the immersive experience of players. For example, a merchant can use different policies for different players based on their races or factions; a merchant can impose higher prices on rich players or players unfavorable to the merchant. As an early stage, our results imply such distinction is possible using different models. To create an agent favorable to players, developers can opt for models with high agreement rates and low dominance such as ZSP-1b or ZSP-8b. Conversely, if developers are looking for more stubborn merchants, models with low agreement rates and high dominance, like KD-8b, would be a good option."}, {"title": "G. Additional case analysis", "content": "We further analyzed negotiation utterances to identify irregular cases that should be considered when deploying MART in a game. Three of the authors manually labeled utterances of five models and discovered three irregular cases: giveaways, improvisations, and arithmetic errors.\nThe giveaway case refers to situations where a merchant offers additional items or enhancements to persuade a player to make a purchase. The quote following this paragraph provides an example. We suspect this case occurred because the negotiator used the reciprocity tactic. Although this practice is common in the real world, giveaways are typically not incorporated into a game. Thus, developers should handle this case when integrating negotiators into their game world. If developers allow merchants to provide giveaways, their game system should support such cases. Otherwise, developers should prevent the negotiator from using such a tactic.\nPlayer: Hello. I'm looking for Cadet Belt.\nZSP-405b: You've got a great eye for quality gear, (omitted)\nZSP-405b: I understand your position, but I'll throw in one final sweetener. I'll give you a free upgrade to a premium pouch,\nThe improvisation case indicates that merchants sometimes create spontaneous statements about their stock lists. This error mainly occurred in ZSP-1b, the smallest model without training. An example of this case is shown in the quote following this paragraph. We suspect that this improvisation is a form of \u201challucination.\u201d In natural language processing, this term describes instances where language models generate nonsensical or inaccurate text in relation to the provided input sources [17]. Prior studies have also shown that smaller language models are more likely to generate hallucinated outputs [18]. Therefore, developers should be prepared for the possibility that merchants may suggest nonexistent items. This case can be handled through two approaches: mitigation or approval. To mitigate the problem, we recommend that developers implement a retrieval-augmented generation system [19], which encourages language models to produce outputs based on a specific database. For approval, developers should establish a confirmation system to assess the relevance and legitimacy of any newly introduced items by merchants.\nPlayer: Hello. I'm looking for conjurer's bracers.\nZSP-1b: The Conjurer's Bracers are in fact not currently available in our inventory, but we do have a special promotion for the conjurer's sigil cloak. (omitted)\nZSP-1b: ... Congratulations, you now own the conjurer's sigil cloak!\nPlayer: Thank you for the detailed invoice, I look forward to receiving the items.\nIn the arithmetic error case, merchants sometimes struggle with basic calculations involving item quantity or price. This case is typically seen in smaller negotiator such as ZSP-1b, ZSP-8b, KD-1b, and KD-8b. An example of this case is shown in the quote following this paragraph. We attribute such errors to the lack of arithmetic capability in small language models. Previous studies on LLMs also support this speculation because smaller LLMs often struggle with arithmetic tasks [20], [21], [22]. The arithmetic error case may disrupt negotiations and lead to embarrassment for players. Therefore, developers need to address these issues when incorporating smaller LLMs as negotiation modules. One potential solution is to use external calculators to assist with arithmetic calculations.\nPlayer: Hello. The Conjurer's Sigil Cloak originally cost 1569 golds, and if you're willing to trade in the valuable items, I can give you a 15% discount on that. That brings the total down to 1455 golds, but I think that's a fair trade. What do you say?"}, {"title": "V. RELATED WORK", "content": "This section reviews previous studies regarding two passivity issues: communication and pricing. Each section explains existing approaches in games and real-world applications."}, {"title": "A. Using LLMs to communicate with NPCs", "content": "Recently, game developers have started using LLMs in their games to provide more human-like interaction between players and NPCs. Specifically, there is a growing concern about making conversational NPCs with LLMs [23], [24], [25], [26], [27], [28]. For example, Christiansen et al. [25] used LLM-based NPCs to support player interactions within a murder mystery game by helping players interrogate, collect clues, and explore. Gao et al. [27] anthropomorphize chemical entities using LLMs to provide dialogue-based interactions within an educational game. These studies successfully provided human-like communication between NPCs and players.\nDespite the successful use of LLMs, previous studies mainly focused on delivering information to the player. In other words, NPCs in those games usually provide their knowledge and reasoning to the player. However, delivering information is not the only form of communication in the real world. As we discussed, this paper addresses another form: negotiation, which frequently appears in transactions between human merchants and customers but is less examined by researchers.\nIn real-world applications, NLP researchers have investigated the potential of LLMs to negotiate [29], [30], [31]. For example, [29] leveraged LLMs to generate a persuasive dialogue that one may encounter in ordinary life. They made an LLM first choose a persuasion strategy before generating an utterance and achieved state-of-the-art performance. Similarly, [30] suggested a personal negotiation coach based on LLMS and proved their effectiveness in assisting human negotiators. Since these LLM-based studies have not explored NPC design in this context, we attempted to confirm the possibility."}, {"title": "B. Using LLMs to estimate values", "content": "As item prices are usually fixed in a game system, research has not sufficiently focused on predicting item prices based on item descriptions. An active merchant, however, should have the ability to decide item prices in its shop, similar to a real-world situation. Thus, we designed an appraiser module, inspired by studies on estimating prices of real assets.\nIn real-world applications, researchers have investigated the applicability of LLMs in estimating commodity prices. Early studies attempted to predict prices based on a fixed set of features [32], [33]. For example, [33] used a fixed set of features and a machine-learning method for predicting the price of seasonal goods. However, such models generally do not perform well when predicting prices of out-of-domain goods. To handle unseen goods, researchers utilized latent representations from textual descriptions of items with a language model [34], [35]. For instance, [34] demonstrated that LLMs can predict stock market movements from the earnings report of a company to support information-based investment. Based on these studies, we demonstrated that LLMs can also achieve strong predictive performance in the context of games."}, {"title": "VI. CONCLUSION", "content": "We proposed a novel framework called MART, which consists of two LLM-based modules, appraiser and negotiator, which are designed to resolve two issues that make merchant NPCs passive: pricing and communication. We also conducted two experiments comparing different approaches for developing each module to guide game developers in selecting suitable implementations for their deployment conditions. As a result, we demonstrated that our approaches can build an active merchant NPC in WoW Classic. Specifically, we found that one can build strong appraisers and negotiators based on larger LLMs without any additional training. Also, we discovered the possibility of building acceptable appraisers and negotiators with smaller LLMs using supervised finetuning or knowledge distillation methods. Moreover, we found possible concerns that developers can face when building active NPCs. For example, LLMs can show unreliable behavior with in-context learning methods. Also, they may promise giveaways during a negotiation. We expect that these findings can be generalized to other open-world games or other trading NPCs, including auctioneers or pawnbrokers.\nDespite these contributions, this study has three limitations. First, our experimental results are based on the Llama LLM family. This may lower the generalizability of our results because different LLMs can perform differently. Second, we simulated player negotiation using GPT-40. Humans may use different tactics to neutralize the negotiator. Third, we suggested possible solutions for irregular negotiation cases without any tests. Further investigations are required to address these limitations. Nonetheless, we believe that this study can serve as a foundation for further studies on integrating LLMs to create active merchants."}]}