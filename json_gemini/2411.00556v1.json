{"title": "LLM-KT: A Versatile Framework for Knowledge Transfer from Large Language Models to Collaborative Filtering", "authors": ["Nikita Severin", "Aleksei Ziablitsev", "Yulia Savelyeva", "Valeriy Tashchilin", "Ivan Bulychev", "Mikhail Yushkov", "Artem Kushneruk", "Amaliya Zaryvnykh", "Dmitrii Kiselev", "Andrey Savchenko", "Ilya Makarov"], "abstract": "We present LLM-KT, a flexible framework designed to enhance collaborative filtering (CF) models by seamlessly integrating LLM (Large Language Model)-generated features. Unlike existing methods that rely on passing LLM-generated features as direct inputs, our framework injects these features into an intermediate layer of any CF model, allowing the model to reconstruct and leverage the embeddings internally. This model-agnostic approach works with a wide range of CF models without requiring architectural changes, making it adaptable to various recommendation scenarios.\nOur framework is built for easy integration and modification, providing researchers and developers with a powerful tool for extending CF model capabilities through efficient knowledge transfer. We demonstrate its effectiveness through experiments on the MovieLens and Amazon datasets, where it consistently improves baseline CF models. Experimental studies showed that LLM-KT is competitive with the state-of-the-art methods in context-aware settings but can be applied to a broader range of CF models than current approaches.", "sections": [{"title": "I. INTRODUCTION", "content": "Many recommender systems use Collaborative Filtering (CF) methods to model user preferences and match items to them [1]\u2013[3]. However, these models often struggle to understand nuanced relationships and adapt to dynamic user-item interactions [4], [5]. To tackle this issue, applying Large Language Models (LLMs) for recommendations has been actively studied since LLMs offer new ways to represent knowledge with their strong reasoning capabilities.\nAs a result, current studies have integrated LLMs into various stages of recommender systems, from open-world knowledge generation [6], [7] to candidate ranking [8], [9]. Since LLMs are expensive to use, recently, several works proposed to directly use LLM for improving the quality of CF models by performing knowledge transfer (e.g., KAR [10],\nLLM-CF [9]). They create textual features from reasoning chains of LLM and integrate them as input to CF models. However, such an approach limits their applicability to only context-aware models, making their direct usage impossible for other types of CF models that don't handle input features.\nGiven these limitations, we developed a method that ex- tends the applicability of knowledge transfer from LLMs to a broader range of CF models. We introduce \u201cLLM-KT\", a novel framework that facilitates seamless integration with various CF models and provides a robust environment for testing and modifying the approach. Our framework enables efficient knowledge transfer by embedding LLM-generated features into the intermediate layers of CF models, training the models to reconstruct these features as a pretext task internally. This process allows the CF model to develop a more refined understanding of user preferences, resulting in more accurate recommendations. Experiments on two well- known benchmarks demonstrate that the proposed method significantly improves the performance of CF models (+ up to 21% improvement in NDCG@10) while applying to a broader range of models than existing approaches and achieving results comparable to the state-of-the-art KAR [10] in context-aware setting.\""}, {"title": "II. PROPOSED METHOD", "content": "The primary concept of our knowledge transfer method is to let the CF model reconstruct user preferences from the LLM within a specific internal layer without altering its architecture. This approach mirrors the intuitive process of identifying user interests in the early layers and making recommendations based on these learned interests in the later layers."}, {"title": "A. Proposed Knowledge Transfer", "content": "Our method consists of the following steps.\nProfile Generation. First, we use an LLM to generate short preference descriptions for each user based on their user-item interaction data. Following the terminology from [10]\u2013[12], we refer to these descriptions as \"profiles\". Notably, any LLM- based framework can be used for this process, making our method flexible and adaptable to various scenarios [10], [11]. This flexibility allows the framework to accommodate different LLMs and approaches for generating personalized profiles, enhancing its adaptability to various use cases.\nTo maintain efficiency and reduce the number of calls to pretrained LLMs, we create these profiles by independently processing each user's interactions using customized interest reasoning prompts. For our dataset, we used the following prompt structure: \"Based on the user's ratings, provide a general summary of their preferences, paying attention to... The response should be organized into several parts...\". As can be seen, we explicitly define the required components of the response to ensure the consistency of representations across users. A typical profile might look like this: \u201cIt seems that you enjoy a mix of classic and modern movies, with a preference for...", "text-embedding-ada-002\" is used.\nTraining with auxiliary pretext task. We add an auxiliary pretext task for a given CF model to reconstruct user profiles in a predefined internal layer. This is done without altering the model's architecture using a weighted sum of the model's loss and a reconstruction loss with the weight \u03b1 \u2208 [0, 1": "n$L_{combined} = \\alpha \\cdot L_{KT} + (1 - \\alpha) \\cdot L_{model}$                                                     (1)\nHere, $L_{model}$ denotes the model-specific loss of a chosen CF model, e.g., BCE (Binary Cross Entropy) for interaction prediction, MSE (Mean Squared Error) for rating prediction, etc.). The reconstruction loss, denoted as $L_{KT}$, is defined as follows. Let $P_u$ represent the profile embedding of user u, and let $Z_u$ denote the output of the Kth layer of the CF model after processing the interactions of user u. Generally, the knowledge-transfer loss is defined as:\n$L_{KT}(Z_u, P_u) = L_{reconstruct}(Z_u, Trans(P_u))$,                                                      (2)\nwhere Trans is a transformation function that aligns profile embedding to layer representation space.\nFor simplicity, we utilized a nonlearnable Trans func- tion to match the dimensions of profile embeddings with the dimensions of the model's internal layers. Although our framework supports any dimensionality reduction method, we selected UMAP [13] for our experiments because it preserves the distances between embeddings more effectively than con- ventional PCA (Principal Component Analysis) [14] and can reduce dimensions to any desired number, unlike t-SNE (t-distributed Stochastic Neighbor Embedding) [15]. It enables the transformed embeddings to maintain relationships captured by LLM profiles. Our framework supports several options for reconstruction loss. AS RMSE (Root Mean Squared Error) produced the best results, we used it in the remaining part."}, {"title": "B. Training process", "content": "We train a CF model with LLM knowledge transfer for N epochs during two phases:\nPhase 1: Knowledge transfer. During the first N/2 epochs, we train the model using an auxiliary pretext task and a combined loss function, as defined in equation 1. This phase optimizes the model for learning to reconstruct LLM-generated features together with the recommendation task.\nPhase 2: Fine-tuning. After completing the knowledge transfer, we remove the reconstruction loss and train the model for the remaining N/2 epochs, focusing solely on the predic- tion task to optimize the model for accurate recommendations."}, {"title": "III. LLM-KT FRAMEWORK", "content": "We developed a flexible experimentation framework (see Fig. 1) on top of RecBole [16], which allows seamless integration of LLM-generated features into CF models. The framework is designed to enable users to define complex ex- perimental pipelines using a single configuration file, offering a versatile solution for knowledge transfer and finetuning pro- cesses in CF models. By supporting a variety of configuration options and predefined commands, it empowers researchers and developers to conduct experiments that explore different aspects of integration."}, {"title": "B. Framework Features", "content": "Support for Any LLM-Generated Profiles: The frame- work seamlessly integrates LLM-generated user profiles, supporting outputs from any existing methodology. This allows us to experiment with and compare different methods for profile construction.\nFlexible Experiment Configuration: A key feature of the framework is its highly flexible configuration system for defining experimental pipelines. These configurations typically include standard RecBole setups (e.g., dataset splits for training, validation, and testing) and custom pipeline instructions. Users can define entire experiments by specifying sequences of predefined commands exe- cuted in order. Available commands include setting loss functions at various stages, selecting specific layers for knowledge transfer, freezing weights at chosen layers, and selecting subsets from the training dataset to transfer knowledge and finetune the CF model.\nBatch Experiment Execution and Comparison: The framework enables users to run multiple experiments in batches, facilitating a more efficient and streamlined experimentation workflow.\nAnalytical Tools: Following the execution of experi- ments, the framework provides built-in tools for result analysis, allowing users to compare outcomes through visualizations and other analytical methods."}, {"title": "C. Internal Structure", "content": "The core of the framework is the Model Wrapper, which acts as an interface between the configuration and the underlying CF model. This wrapper manages key aspects of model manipulation through specialized components:\nThe Hook Manager provides access to the outputs of specific layers within the model, enabling detailed analysis and extraction of intermediate representations.\nThe Weights Manager controls the freezing and un- freezing of trainable parameters, making it easy to apply selective finetuning strategies.\nThe Loss Manager facilitates adding or removing cus- tom losses, supporting advanced experimentation with different loss functions across various training stages.\nThe framework also includes an execution module for the training and testing phases and a journaling system that logs experimental outcomes for subsequent evaluation."}, {"title": "IV. EXPERIMENTAL SETUP", "content": "Scenarios Under Analysis. We analyzed our method from two perspectives. First, we evaluated its applicability to tra- ditional CF models that rely only on user-item interaction data, showing that our framework enhances these models by capturing nuanced relationships through LLM-generated profile reconstruction. Second, we examined its use with context-aware models, where current LLM knowledge transfer methods pass LLM-generated features as input.\nDatasets. We conducted experiments on two conventional datasets (Table I), namely, Amazon \u201cCD and Vinyl\" (CDs) and MovieLens (ML-1M). In all our experiments, we split the dataset into time-ordered training, validation, and test sets with ratios of 70-10-20%, following previous studies [17], [18].\nBaselines: To test the effectiveness of our approach, we se- lected three widely used neural CF baselines, each representing different architecture types:\nNeuMF [19]: Neural matrix factorization.\nSimpleX [20]: An efficient CF model using contrastive learning.\""}, {"title": "V. EXPERIMENTAL RESULTS", "content": "When presenting the results in tables, we use the following notation: mark \"Base.\" is the baseline CF model, \u201cLLM-KT", "KAR": "tands for the baseline model enhanced by KAR.\nWe tested the proposed method on a reranking task for general CF models. We assessed performance by using ranking metrics such as NDCG@K, Hits@K, and Recall@K.\nOur method demonstrates consistent performance with KAR. The proposed pretext task of internally reconstructing features proves competitive by explicitly providing them as inputs.\nThus, the proposed knowledge transfer method performs comparably to existing ones but is more versatile, as it can be generalized to any CF model that does not support input features."}, {"title": "VI. CONCLUSION", "content": "In this work, we present LLM-KT, an experimental frame- work\u00b9 that enables efficient knowledge transfer from LLMs to CF models.\nLeveraging the RecBole platform, LLM-KT seamlessly in- tegrates into diverse applications and existing systems, benefit- ting from RecBole's comprehensive suite of algorithms, met- rics, and methods. This adaptability allows it to support various"}]}