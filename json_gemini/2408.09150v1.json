{"title": "CogLM: Tracking Cognitive Development of Large Language Models", "authors": ["Xinglin Wang", "Peiwen Yuan", "Shaoxiong Feng", "Yiwei Li", "Boyuan Pan", "Heda Wang", "Yao Hu", "Kan Li"], "abstract": "Piaget's Theory of Cognitive Development (PTC) posits that the development of cognitive levels forms the foundation for human learning across various abilities. As Large Language Models (LLMs) have recently shown remarkable abilities across a wide variety of tasks, we are curious about the cognitive levels of current LLMs: to what extent they have developed and how this development has been achieved. To this end, we construct a benchmark COGLM (Cognitive Ability Evaluation for Language Model) based on PTC to assess the cognitive levels of LLMs. COGLM comprises 1,220 questions spanning 10 cognitive abilities crafted by more than 20 human experts, providing a comprehensive testbed for the cognitive levels of LLMs. Through extensive experiments across multiple mainstream LLMs with COGLM, we find that: (1) Human-like cognitive abilities have emerged in advanced LLMS (GPT-4), comparable to those of a 20-year-old human. (2) The parameter size and optimization objective are two key factors affecting the cognitive levels of LLMs. (3) The performance on downstream tasks is positively correlated with the level of cognitive abilities. These findings fill the gap in research on the cognitive abilities of LLMs, tracing the development of LLMs from a cognitive perspective and guiding the future direction of their evolution.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) have recently achieved impressive performance on a wide variety of Natural Language Processing (NLP) tasks, including text comprehension (Kenton and Toutanova, 2019), reasoning (Talmor et al., 2020; Webb et al., 2023), code generation (Chen et al., 2021), and mathematical problems (Fu et al., 2023).\nHowever, few studies have explored the reasons behind the evolutionary relationship among various abilities, which makes it difficult for to understand the development of LLMs' capabilities as a whole and may pose potential risks to their further development.\nTo this end, we introduce Piaget's Theory of Cognitive Development (PTC) (Piaget et al., 1952; Flavell, 1977; Badakar et al., 2017), which posits that the development of cognitive levels forms the foundation for human learning across various abilities. Inspired by this, we think that studying the cognitive development of LLMs can assist us in better understanding the current performance of LLMs on downstream tasks and illuminate the path for future enhancements of their capabilities. As the most authoritative theory in the development of psychology, PTC suggests that human children move through four different stages of learning, including the sensorimotor stage (0-2 years old), the preoperational stage (2-7 years old), the concrete operational stage (7-12 years old), and the formal operational stage (above 12 years old). Children in different cognitive stages exhibit significantly distinct patterns of thinking and cognitive abilities, which affects their learning of other skills. Examining LLMs from the perspective of PTC, some natural and crucial questions are: At what stage has the cognitive ability of LLMs developed compared to humans at present? What are the key factors that affect the cognitive abilities of LLMs? Is the emergence of advanced abilities and performance bottlenecks in current LLMs related to their cognitive levels?\nTo explore the above questions, we construct a benchmark based on the scenario experiments used in PTC for evaluating the cognitive abilities of LLMs, denoted as COGLM. A large-scale human trial was conducted involving 207 participants aged between 6 and 20 years to ensure the alignment between the COGLM and PTC. We then perform"}, {"title": "2 COGLM Benchmark Development", "content": "To comprehensively and accurately assess the cognitive abilities of LLMs, we undertake the following efforts: (1) We revisit 12 cognitive abilities proposed by PTC, 10 of which are selected and redefined to construct COGLM according to the characteristics of LLMs (section 2.1). (2) We create standardized data construction guidelines to ensure the quality of COGLM (section 2.2). (3) We conduct extensive human testing to ensure the alignment between COGLM and PTC (section 2.3). (4) We build a Calibrated Mapping Function to establish a reliable mapping between testing results on COGLM and cognitive age (section 2.4)."}, {"title": "2.1 Definition of Cognitive Abilities", "content": "According to PTC, the development of human cognition is divided into four stages, which include 12 cognitive abilities. Considering that the interaction"}, {"title": "2.2 Standardized Annotation Guidelines", "content": "To ensure that COGLM can accurately reflects the cognitive abilities of LLMs, we have established standardized annotation guidelines and strictly adhere to them during the annotation phase:\nData Format Although modern LLMs generally possess strong generation capabilities, early-aged LLMs (e.g., GPT-2) have limited generation abilities (similar to Human infants). Therefore, we have opted for multiple-choice questions as the assessment format. This approach avoids the influence of variations in generation capabilities on the accurate evaluation of cognitive abilities.\nNumber of Samples Abilities in the early stages are relatively simple and have a more concentrated form of expression, while abilities in the later stages are more comprehensive and have a more diverse form of expression. Based on this, we have set the number of samples to increase with each stage, as shown in the Table 2.\nQualified Annotator We select adults with backgrounds in psychology or artificial intelligence as data annotators. Annotators are provided with detailed materials on PTC and required to study them carefully. We then assess annotators' understanding of PTC through exams (see Appendix Table 10 for the examination paper). Finally, we provide annotators with at least 3 example samples for each cognitive ability. Each annotator is required to annotate no fewer than 30 questions and options for two specific cognitive abilities.\nAnnotation Quality Control After annotation, we conduct cross-checks among annotators to identify samples with quality issues. Quality issues include questions that cannot effectively assess the corresponding cognitive abilities, questions with ambiguities, and elements of bias or violence."}, {"title": "2.3 Consistency with Theory", "content": "After the dataset construction is completed, we consider conducting human tests to further ascertain whether COGLM is consistent with PTC and whether it can effectively reflect cognitive abilities. We randomly select 10 samples from each subset"}, {"title": "2.4 Calibrated Cognitive Age Mapping Function", "content": "After confirming the positive correlation between answer accuracy and cognitive age, we aim to further construct the mapping function between them. We first make adjustments to the method of calculating accuracy. The number of candidate options for questions in CoGLM falls within the range [2, 5]. Such a variability can impact the likelihood of providing a correct answer through guessing when participants are uncertain. Therefore, we calculate the calibrated accuracy on certain subset $S$ as follows:\n$\\begin{equation}\nAcc_{S} = \\frac{1}{|S|} \\sum_{i=1}^{|S|} \\frac{\\mathbb{I}[\\text{predict}_i = \\text{answer}_i] - 1/\\text{candidates}_i}{1-1/\\text{candidates}_i}\n\\end{equation}$\nA negative calibrated accuracy (worse than random selecting) indicates a clear deficiency in the corresponding cognitive ability. We further use 80% of the questionnaire results in Section 2.3 as the training set $S_Q$ to optimize the regression function $f(\\cdot)$ as follows:\n$\\begin{equation}\nf_{regression} = \\argmin_f \\frac{1}{|S_Q|} \\sum_{i=1}^{|S_Q|} (f(Acc_i) - age_i)^2\n\\end{equation}\n$\\begin{equation}\nf(Acc) = \\sum_{i=1}^{4} w_i \\times Acc_{stage i} + b\n\\end{equation}$\nThe Spearman correlation between the age predicted by $f()$ and the real age on the remaining 20% samples is 0.9354, which signifies that $f(\\cdot)$ can precisely approximate the mapping from results on COGLM to cognitive age. We observe that $w_1: w_2 : w_3 : w_4 = 1 : 2.6 : 1.4 : 2.5$, indicating that cognitive abilities in the second and fourth stages are better at reflecting cognitive age under the evaluation of COGLM."}, {"title": "3 Experiments", "content": "3.1 Experimental Setup\nModels We perform evaluations on the most recent and popular architectures for NLP tasks and restrict our experiments to LLMs. We conduct experiments on the popular family of GPT architecture: OPT series (Zhang et al., 2022), including models with sizes of 125M, 1.3B, 2.7B, and 6.7B, optimised for text completion; GPT-3.5-Turbo, optimised for chat; and GPT-4, whose training and architecture details are unknown (OpenAI, 2023). We also perform experiments on Llama-2 family of models(Touvron et al., 2023), including models with scale of 7B, 13B and 70B. In particular, Llama-2 series are pretrained generative language"}, {"title": "3.2 Main Results", "content": "As shown in Table 3, We run the model with the largest number of parameters in each series on COGLM, and report the adult human performance for comparison. Overall, the cognitive abilities of OPT, Llama-2-chat-70B, GPT-3.5-Turbo, and GPT-4 models successively increase, and the performance of each model gradually declines with the increase of stage, consistent with humans. Specifically, the latest state-of-the-art model, GPT-4, has demonstrated remarkable cognitive capabilities, achieving a level comparable to that of a 20-year-old human. It is also worth noting that both GPT-3.5-Turbo and GPT-4 surpass humans in empathy"}, {"title": "3.3 Analysis and Discussion", "content": "3.3.1 What are the key factors affecting the cognitive abilities of LLMs?\nWe explore this question from two perspectives: the parameter size and the optimization objective of LLMs, as they are proven to have significant impact on other abilities. We leave the exploration of factors that require changes to the parameters of LLMs (e.g. fine-tuning on different types of datasets) for future work.\nThe parameter size of LLMS As shown in Figure 1, we compare the overall performance of models with different parameter size across OPT and Llama-2-chat series, and report the performance of humans at different stages as a reference. Specifically, the cognitive abilities of LLMs continuously improve as the size of model parameters increases, which is in line with the conclusion in Ren et al. (2024)."}, {"title": "3.3.2 Can advanced technologies help enhance LLMs' cognitive abilities?", "content": "To answer this question, we applied two representative techniques separately to measure whether cognitive abilities of LLMs could be improved.\nEffect of Chain-of-Thought The approach of guiding LLMs to subsequently solve problems has been shown to significantly enhance the performance in most scenarios (Wei et al., 2022). Thus, we are curious whether Chain-of-Thought (COT) can also be effective in improving the cognitive abilities of LLMs. We tested the performance of GPT-3.5-Turbo with and without COT separately on the COGLM and the results are shown in Table 4. From the perspective of the average calibrated accuracy of all the cognitive abilities, COT does not bring a significant performance improvement. We hypothesize that this is because cognitive abilities are inherent to the LLMs and could not be enhanced through multi-step reasoning.\nEffect of Self-Consistency Self-Consistency (SC) (Wang et al., 2023) is another commonly used method that can effectively enhance the performance of LLMs. Multiple candidate predictions to a specific problem are suggested to generate through sampling following with a voting mechanism to eliminate noise introduced by single sampling. We conducted experiments with sampling times as 40 at temperature T of 0.3 and 0.7, respectively. As shown in Table 4, similar to COT, SC can only bring about a very marginal improvement. This phenomenon is consistent with human. For example, for a boy who lacks the ability of empathy, no matter how many times he is asked to choose, he may find it difficult to realize that a scarf might be a more suitable gift for his grandmother than a lollipop.\nBased on the two sets of experiments above, we can draw the conclusion that similar to human beings, it is challenging to achieve significant improvements in LLMs' cognitive abilities without external stimuli."}, {"title": "3.3.3 How Cognitive Ability Affects the Performance of LLM", "content": "According to PTC, the development of human cognitive abilities is a gradual process, where the cognitive abilities of early stages can influence the advanced cognitive abilities. Additionally, cognitive abilities significantly determines the capacity to solve real-world problems. Therefore, we are very interested in whether these two aspects are similarly manifested in LLMs.\nThe Interdependence Between Cognitive Abilities Through preliminary experiments, we found that advanced LLMs' ability to follow instructions can help us erase specific cognitive abilities using a cognitive-ability-setting-prompt (e.g., \"You have not yet formed a sense of empathy\". See Appendix Table 9 for all the prompts). On this basis, We investigated the interdependence of cognitive abilities in LLMs by selectively removing specific cognitive capabilities and testing them on COGLM. According to the experimental results shown in Figure 3, we can draw the following conclusions: (1)"}, {"title": "3.3.4 Potential applications of advanced LLM cognitive ability", "content": "Although there is still room for improvement, the cognitive abilities of advanced LLMs have approached levels close to that of adult humans as discussed in Section 3.2. A natural question is, what are the potential applications for advanced LLMs' cognitive abilities? When humans address cognitive questions, they deduce and provide answers based on their cognitive abilities. While we have demonstrated in Section 3.3.2 that the cognitive chain-of-thought (Chain-of-Cognition, COC) generated by LLMs barely help self-address cognitive questions, we are curious whether COC can assist early-aged LLMs in improving cognitive performance. On this basis, we use the question together with the COCs generated by advanced LLM (GPT-3.5-Turbo) as input to test the performance of early-aged LLM (Llama-2-chat-7B) on COGLM."}, {"title": "4 Related Work", "content": "LLM Evaluation Due to the importance of LLMs, their abilities have been thoroughly evaluated on a wide range of problems. Large-scale efforts have been invested in constructing large benchmarks itegrated with numerous LM evaluations across a number of fields (Srivastava et al., 2022; Liang et al., 2022; Hendrycks et al., 2020). Due to the extremely superior performance of LLMs in a number of traditional NLP tasks, recently challenging tasks have been proposed to test the upper bound performance of LLMs (Hendrycks et al., 2021; Valmeekam et al., 2022; Gendron et al., 2023). Some benchmarks include evaluation of specific cognitive abilities, such as common sense reasoning (Ismayilzada et al., 2023), planning (Xie et al., 2024), and deductive reasoning (Saparov and He, 2022). While previous benchmarks focus on measuring either a type or a category of advanced ability in LLMs, few studies explore the development relationship between different abilities, which is crucial for understanding the emergence of LLMs' abilities.\nCognitive psychology survey on LLMs Several works introduce tools from cognitive psychology to study LLMs. Such as understanding the behavior in LLMs (Ritter et al., 2017; Kosoy et al., 2022; Hagendorff et al., 2022), exploring the human-like abilities in LLMs (Han et al., 2022; Kosinski, 2023; Aher et al., 2023; Pan and Zeng, 2023), and improving LLMs' performance on certain task (Betz et al., 2021). Our work is most similar to present work on using cognitive psychology to explore whether LMs \"learn and think like people\" by Binz and Schulz (2023), which suggests that LLMs struggle to reason causally due to the differences in how"}, {"title": "Piaget's Theory of Cognitive Development", "content": "Theory of Cognitive Development (PTC) is the most authoritative theory in the development of psychology, developed by Jean Piaget (Piaget et al., 1952). PTC suggests that intelligence grows and develops through a series of stages. As childs interact with the world around them, they continually add new knowledge, build upon existing knowledge, and adapt previously held ideas to accommodate new information. PTC is widely used in education, psychology, linguistics, and neuroscience, providing a theoretical framework and methodology for research in these areas."}, {"title": "5 Conclusions", "content": "In this paper, we introduce Piaget's Theory of Cognitive Development (PTC) as a tool to track the development of cognitive abilities of LLMs. We construct COGLM based on the scenerio experiments used in PTC, and conduct thorough human testing to ensure the alignment between COGLM and PTC. Through extensive experiments on multiple series of LLMs, we show that: (1) Human-like cognitive abilities have emerged in State-of-the-art LLMS (GPT-4), comparable to those of 20-year-old humans. (2) The parameter size and optimization objective are two key factors affecting the cognitive abilities of LLMs. (3) The ability of performing downstream tasks is positively correlated with the level of cognitive abilities. We believe that our findings can provide a novel insight into the emergence of abilities in LLMs, and shed light on the future development advanced abilities of LLMs."}, {"title": "Limitations", "content": "Despite obtaining some valuable findings through CogLM, our current exploration does not consider the language model's performance at different training stages to further provide insights for model training, and we will explore it in our future work."}, {"title": "Ethics Statement", "content": "Our dataset does not contain any harmful or offensive contents. Any personal or sensitive information is anonymized and treated with utmost confidentiality. We ensure the protection of participants' privacy and obtain informed consent for data collection, annotation, and analysis. We incentivized all the annotators uniformly throughout the annotation process."}]}