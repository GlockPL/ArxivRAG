{"title": "BeSimulator: A Large Language Model Powered Text-based Behavior Simulator", "authors": ["Jianan Wang", "Bin Li", "Xueying Wang", "Fu Li", "Yunlong Wu", "Juan Chen", "Xiaodong Yi"], "abstract": "Traditional robot simulators focus on physical process modeling and realistic rendering, often suffering from high computational costs, inefficiencies, and limited adaptability. To handle this issue, we propose Behavior Simulation in robotics to emphasize checking the behavior logic of robots and achieving sufficient alignment between the outcome of robot actions and real scenarios. In this paper, we introduce BeSimulator, a modular and novel LLM-powered framework, as an attempt towards behavior simulation in the context of text-based environments. By constructing text-based virtual environments and performing semantic-level simulation, BeSimulator can generalize across scenarios and achieve long-horizon complex simulation. Inspired by human cognition processes, it employs a \"consider-decide-capture-transfer\" methodology, termed Chain of Behavior Simulation, which excels at analyzing action feasibility and state transitions. Additionally, BeSimulator incorporates code-driven reasoning to enable arithmetic operations and enhance reliability, as well as integrates reflective feedback to refine simulation. Based on our manually constructed behavior-tree-based simulation benchmark BTSIMBENCH, our experiments show a significant performance improvement in behavior simulation compared to baselines, ranging from 14.7% to 26.6%.", "sections": [{"title": "I. INTRODUCTION", "content": "Simulation plays a pivotal role in robotics, providing a controlled platform for iterative testing and refinement of robotic systems, thus circumventing the inherent risks and expenses associated with physical prototyping[1]. Conventional simulation tools, like Gazebo[2], Unreal Engine[3], etc., have been extensively utilized for tasks involving navigation and human-robot interaction[4], [5]. However, these platforms are predominantly domain-specific, and focus on modeling physical processes as well as pursuing realistic rendering, which struggle from high computational demands, inefficiencies, and restricted adaptability to the dynamic and diverse nature of environments[6]. This underscores the need for more efficient and versatile simulators capable of operating across domains.\nThe evolution of robotics towards embodied artificial intelligence in open environments has amplified the need for general-purpose simulation tools. Therefore, we propose Behavior Simulation in robotics, which is based on the hypothesis that the complex physical modeling between robots and environments may not be necessary, so that the behavior simulation emphasizes the control logic of behavior planning solutions (BPS) of robots, like Finite State Machines (FSMs)[7], Hierarchical Task Networks (HTNs) [8], and Behavior Trees (BTs)[9]. By pursuing action outcomes that are sufficiently similar to real scenarios, behavior simulation can efficiently"}, {"title": "II. RELATED WORKS", "content": "Compared to simulating on real robots, robot simulators provide a secure platform for the evaluation of new strategies, solutions, or algorithms, which accelerate robot development and save costs[1]. Currently, common robot simulators include general simulators like Gazebo [2], Isaac Sim[20], V-REP[21], and some game engines like Unreal Engine[3]. Robot simulators have been widely used for tasks related to navigation[4], human-robot interaction[5], vehicle driving[22], etc. Their performance is primarily determined by the physics and rendering engine. The physics engine is used to mathematically model complex physical processes like motion, collisions, etc. The rendering engine provides a visual interface to enhance simulation realism. However, these simulators are limited to low efficiency, high computational cost, and poor generalization[6][23], which our study aims to solve."}, {"title": "B. Conventional Behavior Simulation", "content": "Traditionally, behavioral simulation refers to simulating the behavior patterns of specific subjects. Most researches focus on user-behavior simulation to evaluate the effectiveness of evacuation systems[24][25]. Moreover, some researchers focus on behavior simulation of various subjects, like infants[26], humans living in atypical buildings[27], etc. There are also research efforts [28] [29] that utilize behavior simulators to provide a simulation environment for reinforcement learning (RL). These are fundamentally different from the behavior simulation expounded in this paper."}, {"title": "C. LLMs for Logical Reasoning", "content": "Trained on the large-scale corpus, LLMs exhibit remarkable reasoning capability. LLMs are typically prompted to decompose complex problems and engage in step-by-step thinking and reasoning, exemplified by CoT[16], Zero-shot-CoT[30], self-consistency[31], etc. Some methods combine reasoning problems with search algorithms like ToT[32], RAP[14], etc. Moreover, some researchers focus on supervised fine-tuning of LLMs to improve reasoning, such as WOMD-Reasoning[33], CPO[34], etc. Methods like CoC[35] and ToRA[36] apply external tools such as code interpreters, computation libraries, etc., aiming to reduce computational hallucination and enhance reasoning. In this paper, we propose Chain of Behavior Simulation containing four phases from shallow to deep, which conforms to the human cognition process further."}, {"title": "III. PROBLEM FORMALIZATION", "content": "Based on research [9] [37], a behavior planning problem can be formalized as a quintet: $<S, A, T, S_{initial}, g>$, where $S$ is state space, $A$ is action space, $T : S \\times A \\rightarrow S$ is the state transition rules, $S_{initial}$ is the initial scene state and $g$ is goal condition. After executing action $a$ in the state $s_t$, the next state $s_{t+1} = T(s_t, a)$. The target of the behavior planning problem is to produce a solution capable of transferring $S_{initial}$ to $g$ in finite steps. In this paper, we aim to determine whether one behavior planning solution is effective through behavior simulation. Our main idea is that based on the initial scene states $S_{initial}$ and the control logic of the solution $\\pi$, step by step perform state transitions and finally determine whether the goal condition $g$ is achieved, as is shown in Eq 1. In this paper, we integrate LLMs to implement this process to achieve automated and long-horizon behavior simulation.\n$$g \\subseteq T(S_{initial}, \\pi)$$"}, {"title": "IV. METHOD", "content": "In this paper, we propose BeSimulator, illustrated in Figure 1, a modular and novel LLM-powered framework that conducts behavior simulation in text-based environments. Through generating scenes and implementing semantic-level simulation, BeSimulator is general across different domains. It consists of three key modules, including Case Generation, BPS Simulation, and BPS Evaluation. Based on robot tasks, BeSimulator first generates simulation cases, including various world states. Then, according to the control logic of the behavior planning solution, BeSimulator analyzes the action feasibility and performs state transitions step by step. Finally, in view of the simulation results, BeSimulator evaluates the solution based on whether the task is reached."}, {"title": "B. Case Generation", "content": "Given a robot task and the behavior planning solution, BeSimulator first generates the corresponding simulation case. Specifically, the simulation case is composed of three parts: Entity Information, Relationship Information and Environment Information. Based on the scene imagination and generation capabilities of LLMs, the case generation has good generalization and is conducive to constructing complex scene cases.\nEntity Information: Entity information is composed of robot entities and object entities. The robot entities are conscious and of action ability, like sweeping robots, quadruped robots, etc. The object entities are static, like tables, chairs, etc. For each entity, the generated elements include id, type, position, size, and other necessary properties. The id property"}, {"title": "C. BPS Simulation", "content": "Based on the generated case states, BeSimulator continuously simulates action occurrence according to the control logic of the behavior planning solution. Our approach, which utilizes the reasoning capability and embedded knowledge of LLMs, is able to support long-horizon complex simulation while improving the simulation efficiency. Specifically, considering the lack of reliability in directly utilizing LLMs for simulation, inspired by the human cognition process, we introduce Chain of Behavior Simulation for behavior simulation. Meanwhile, we integrate code-driven reasoning to address issues involving numerical reasoning. We also implement reflective feedback to refine simulation.\nFor each action, BeSimulator utilizes CBS to simulate behavior occurrence, which includes four phases: \"consider-decide-capture-transfer\u201d. Through CBS, BeSimulator can thoroughly analyze the action feasibility, and predict how the action changes states."}, {"title": "D. BPS Evaluation", "content": "Based on the control logic of the BPS, BeSimulator step-by-step transfers from the initial scene states and finally achieves the ended states. Then, according to the task goal, BeSimulator reasons and derives the evaluation result based on the initial and final scene states, as well as action flow, termed Chain of Task. The evaluation result can be divided into two types: Good and Bad. The Good result indicates that the robot can complete the given task equipped with the solution, while the Bad result indicates the failure of task completion, which exists for two reasons:\nIf the execution logic of the solution conflicts with the reality logic, causing the robot to be unable to complete the task, it is Bad Logic. For example, when executing the action \"clean_book\u201d that is based on \u201chold_rag_in_gripper?=true\u201d as a realistic precondition, but currently robot does not hold the rag, then the action can not be executed and return failure. And finally, this failure results in task failure, which is bad logic, as is shown in Figure 3. Tracing back to the source, this is because the logical feasibility of this critical action is not guaranteed before execution, resulting in bad logic.\nIf the behavior planning solution is logically sound in reality, but it conflicts with the task logic, preventing task completion, then it is Unreachable. For example, for the task \"Clean book\u201d, after executing the solution, the robot only grasps the rag and book, which will be unreachable, as is shown in Figure 3."}, {"title": "V. EXPERIMENTS", "content": "In this section, to demonstrate the effectiveness of BeSimulator, we first develop a new benchmark based on behavior tree simulation. Then, we conduct adequate experiments to answer two research questions:\nHow much can BeSimulator improve LLMs on behavior simulation? (Section V-C)\nTo what extent do our deliberate mechanisms help for simulation, including CBS, code-driven reasoning, and reflective feedback? (Section V-D)"}, {"title": "A. BTs Simulation", "content": "Our approach is versatile and general, which is adaptable across different behavior planning solutions. In this paper, we take behavior tree simulation as an example and conduct experiments to prove the effectiveness of our approach. Behavior trees are a directed rooted tree architecture in which the leaf nodes control the robot's perception and actions, while the internal nodes manage the logical structuring of leaf nodes[9]. BTs typically contain five types of nodes, namely Sequence, Fallback, Parallel, Condition, and Action. The execution of a BT starts from the root node, which ticks its child nodes at each time step through Depth First Search (DFS). This mechanism flexibly controls the behaviors of robots. For our experiments, we utilize py_trees as BTs engineer that sends tick signal and controls BTs nodes execution. For control nodes, they are executed according to their established rules. While leaf nodes are executed based on CBS. Specifically, for action nodes, BeSimulator implements the \"consider-decide-capture-transfer\u201d four-phase of CBS. For condition nodes, BeSimulator applies the variant of CBS, which contains the first two phases \u201cconsider-decide\u201d."}, {"title": "B. Experimental Setup", "content": "Based on BEHAVIOR-1K [19] which is a comprehensive simulation benchmark for human-centered robots, we construct BTSIMBENCH, a new behavior tree simulation benchmark. BEHAVIOR-1K includes the definitions of 1000 daily activities, which are described based on BEHAVIOR Domain Definition Language (BDDL). We select 25 tasks from them while keeping diversity in both task categories and behavior types, then we utilize LLMs to convert them into textual descriptions and adjust them manually. For each task, we first construct a good behavior tree that can complete the task in correct action logic and provide the corresponding node descriptions, which is shown in Figure 2. Additionally, by altering some nodes from the good behavior tree, we construct a behavior tree with bad logic and a behavior tree that is unreachable, aiming to measure the simulation capability of BeSimulator for both good and bad behavior trees simultaneously, as shown in Figure 3. Then, 75 behavior trees are generated, which are from three categories and each category contains 25 behavior trees. For each behavior tree, we conduct multiple rounds of manual verification and adjustment to ensure its availability.\nWe select four well-known LLMS in the field of closed source and open source as our base LLMs, including Claude-3.5-Sonnet [38], Deepseek-V2-Chat[39], Qwen2-72B-Instruct[40] and Llama3.1-70B-Instruct[41].\nTo fairly compare the effectiveness improvement of BeSimulator, we use the following evaluation metrics:\nThis metric assesses whether an LLM-based simulator can successfully deliver a simulation result within finite steps. Exceeding the maximum feedback limit (5 times in our experiment settings) will result in delivery failure.\nThis metric represents the proportion of behavior trees that are correctly evaluated for the corresponding categories. It acts as an indicator of the simulator's effectiveness for BPS."}, {"title": "C. Simulation Performance", "content": "In our experiments, we employ our designed BTSIM-BENCH to evaluate the efficacy of BeSimulator. Table I presents the final simulation results. We measure to what extent our approach improves the simulation capability of LLMs. For baseline methods, we input the robot task, the behavior tree represented by XML format, and node descriptions, to prompt LLMs to assess the effectiveness of BT and identify reasons if ineffective. To fairly compare, we provide few-shot demonstrations and incorporate the CoT[16] mechanism into the sole LLM.\nAcross all base LLMs, BeSimulator persistently achieves notable enhancements in performance. And the results indicate that BeSimulator has substantially enhanced the accuracy of all categories. Specifically, for Deepseek-V2-Chat, we observe an utmost rise of 26.6%, which translates to a 42.4% relative uplift compared to the baseline. The enhancements of other LLMs range from 14.7% to a remarkable 26.6%, demonstrating the efficacy of our proposed approach. Notably, for behavior trees of bad logic, simulating them with the baseline method often fails to uncover latent conflicts with reality logic, lacking thorough consideration of the action execution process. Conversely, the application of our approach has led to significant improvement. This demonstrates that based on the Chain of Behavior Simulation to enhance the analysis of action execution, and code-driven reasoning as well as reflective feedback to advance simulation, the complex challenges of the LLM-based simulation have been effectively tackled."}, {"title": "D. Ablation Study", "content": "In this section, we aim to answer the following questions to validate the effectiveness of three core mechanisms in BeSimulator:\nDoes the \"consider-decide-capture-transfer\" four-phase thought mode of CBS improve LLMs' reliability on behavior simulation?\nCan leveraging the code-driven reasoning mechanism alleviate the numerical hallucination of LLMs and enhance simulation fidelity?"}, {"title": "VI. CONCLUSION", "content": "We formalize the simulation problems for behavior planning solutions to evolve the real-world simulation challenges. To enhance the efficiency and generalization of simulation, we propose behavior simulation in robotics and introduce a novel LLM-based framework, BeSimulator, as an effort toward behavior simulation in the context of text-based environments. BeSimulator first generates text-based simulation scenes, then performs semantic-level simulation and ultimately evaluates. We integrate mechanisms including Chain of Behavior Simulation, code-driven reasoning, and reflective feedback to ensure the effectiveness of the simulation. Experimental results across four LLMs on our proposed behavior tree simulation benchmark BTSIMBENCH demonstrate that BeSimulator achieves a significant enhancement in the efficiency and generalization of simulation while ensuring effectiveness."}]}