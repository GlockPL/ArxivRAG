{"title": "Belief sharing: a blessing or a curse", "authors": ["Ozan \u00c7atal", "Toon Van de Maele", "Riddhi J. Pitliya", "Mahault Albarracin", "Candice Pattisapu", "and Tim Verbelen"], "abstract": "When collaborating with multiple parties, communicating relevant information is of utmost importance to efficiently completing the tasks at hand. Under active inference, communication can be cast as sharing beliefs between free-energy minimizing agents, where one agent's beliefs get transformed into an observation modality for the other. However, the best approach for transforming beliefs into observations remains an open question. In this paper, we demonstrate that naively sharing posterior beliefs can give rise to the negative social dynamics of echo chambers and self-doubt. We propose an alternate belief sharing strategy which mitigates these issues.", "sections": [{"title": "1 Introduction", "content": "Communication and the emergence of language have been a cornerstone in the development of human intelligence, as they enable human collaboration at multiple communal scales [1]. This collaborative capability hinges significantly on how agents share and process information, particularly requiring their internal beliefs about the world to be aligned [2,3]. Active inference provides a compelling framework for understanding and designing such collaborative interactions in the interest of building ecosystems of intelligence [4,5,6]. In this paradigm, agents minimize variational free energy [7], as each agent maintains a generative model of the world which it uses to make inferences about hidden states and to plan actions. Then, communication between agents at the lowest level can be conceptualized as sharing these internal beliefs, transforming the beliefs of one agent into observable data for another [8], these beliefs can be shared directly as we will demonstrate in this paper, but could also be present in the environment more permanently in the form of scripts[9] and texts [10,11]. This belief-sharing mechanism is intended to facilitate a more coherent and efficient joint exploration of the environment.\nHowever, translating and sharing beliefs has its challenges, as the messages shared are typically colored by one's personal priors and biases [12]. We found that naively sharing posterior beliefs can inadvertently lead to detrimental social dynamics, such as echo chambers, in which agents reinforce each other's biases, and self-doubt, in which agents discount their observations to favor shared, yet incorrect, beliefs. These phenomena can significantly impair the collective performance of the agents, highlighting the need for more sophisticated strategies in belief communication. In this paper, we explore these dynamics in depth. We begin by modeling the communication between agents as belief sharing under the active inference framework, demonstrating the pitfalls of straightforward belief sharing. We then propose an alternative strategy that mitigates these issues by adjusting how beliefs are communicated. Specifically, we advocate for sharing likelihood information rather than posterior beliefs, treating other agents' observations as additional independent sources of information. This approach aims to harness the benefits of collaborative inference while avoiding the pitfalls of misleading belief reinforcement.\nOur contributions are threefold: (i) We provide a detailed analysis of how naive belief-sharing can lead to echo chambers and self-doubt. (ii) We propose a novel communication strategy that mitigates these issues by sharing likelihoods. (iii) We validate our approach through simulations, demonstrating improved performance and robustness in collaborative tasks. The following sections outline our active inference model for communication, describe the experimental setup used to test our hypotheses, present our findings on echo chambers and self-doubt, and discuss our proposed solution and its implications for designing collaborative AI systems."}, {"title": "2 An active inference model for communication", "content": "In this section, we provide a summary overview of active inference, and how it can be adopted to model communication between agents. For a more in depth overview of active inference we refer the reader to [7]."}, {"title": "2.1 Perception and planning as inference", "content": "Active inference posits that agents entertain a generative model of the environment they operate in, and casts perception and action as Bayesian inference [7]. In general, the agent's generative model can be written as the joint probability distribution over states s, observations o and actions a, with tilde denoting a time sequence of those over timesteps t:\n$$P(\\tilde{s}, \\tilde{o}, \\tilde{a}) = P(s_0) \\prod_t P(o_t|s_t) P(s_t|s_{t-1}, a_{t-1}) P(a_{t-1})$$\nPerception now becomes inferring the posterior distributions of states given the performed actions and observations. As this is typically intractable, agents resort to variational Bayesian inference, where an approximate posterior Q(\u0161\u00f5) is optimized instead, by minimizing the variational Free Energy:"}, {"title": "2.2 Communication as belief sharing", "content": "When agents share a common world and world model, they can benefit from sharing beliefs among each other [8]. The most straightforward way to realize this would be to share the agent's respective posterior beliefs on some shared modality. In order to achieve this, the agents generative model is expanded as shown in Fig. 1. In particular, any agent, for example., the primary focal agent, assumes other agents with a similar generative model will communicate information about its beliefs of the world. To do so, we equip the focal agent with an extra observation modality of. Instead of being observed from the environment, of is an observation generated by another agent based on its internal beliefs st. This approach is the kind of model posited in earlier work [8].\nTo realize posterior belief-sharing, agents require a likelihood mapping between posterior beliefs about latent states that are shareable among agents, i.e., st, and this observation modality of. In natural systems, these can be a very complex likelihood mapping, e.g., language [14] or birdsong [15]. However, in the case of AI agents, we can decide on the communication channel ourselves. One particular naive choice is to directly share the sufficient statistics of one's internal beliefs s' and integrate these with an identity likelihood mapping, as used in [8]. However, in the remainder of this paper, we will demonstrate the fallacies of using this approach and propose a different format for shared messages."}, {"title": "3 Experimental setup", "content": "To demonstrate multi-agent belief sharing, we simulate an object-finding task, where multiple agents search for a rewarding object in the same environment, and can potentially share beliefs on where they think the object is. The setup and generative model for this task is depicted in Figure 2. The world is represented by a graph of N locations that can be visited by the agents, and agents can move between connected nodes in the graph. Each agent has two state factors, a Categorical(N) variable st which is the belief about the agent's location, and a Categorical (N) variable si which is the belief about the object location. An agent can perform one of N move actions a, modeled using the three-dimensional dynamics tensor B1.\n$$B_{ija} = \\begin{cases}1.0, & \\text{if } a = i \\land \\text{connected}(i, j)\\\\1.0, & \\text{if } i = j\\\\0.0, & \\text{otherwise}\\end{cases}$$"}, {"title": "4 Echo chambers", "content": "In a model which shares the posterior beliefs of one agent as observations of another, Bayesian model updating reinforces redundant priors shared among them. The consequent simulated behavior mirrors the \"echo chamber effect\" wherein messages communicated by like-minded agents are amplified and returned. Psychological interpretations of the echo chamber effect are illustrated in the consequences of social media feed algorithms, which are often engineered to encourage user engagement with sympathetic posts [16]. An algorithmically curated social media curriculum increases engagement by anticipating a user's expected social media observations and fulfilling those expectations. Promoted content thereby constructs homophilic interaction networks which facilitate the construction and reinforcement of shared narratives among users. In worst case scenarios, the result is the unimpeded flow of misinformation on social media platforms. More generally, shared narratives facilitated by social media feed algorithms result in an increase in confidence of posterior beliefs even when external evidence is absent or intentionally excluded.\nIgnoring new evidence can be adaptive, such as when this strategy facilitates in-group cooperation [17]. However, negative consequences also result, such as when outside sources are discredited or distrusted.\nCorresponding to the echo chamber effect, one pitfall of belief sharing is that when agents have established even small prior beliefs on their goal, if those priors"}, {"title": "5 Self-doubt", "content": "In an echo chamber, a belief sharing agent's confidence about their priors is reinforced in the absence of external evidence. Conversely, self-doubt refers to a scenario in which the agent's self-confidence is degraded as a result of belief sharing. In our simulations, the paradigmatic example is when multiple agents are fixated on a search task with complimentary plans for exploring the envi-"}, {"title": "6 To share or not to share?", "content": "Given that sharing agents' beliefs can give rise to the aforementioned issues, it is worth wondering what information can best be shared to allow multi-agent cooperation in active inference agents. In particular, the update rule for si,"}, {"title": "7 Discussion", "content": "The results presented in this paper highlight the potential pitfalls of belief-sharing in multi-agent systems under the framework of active inference. Our findings suggest that naive sharing of posterior beliefs can lead to undesirable social dynamics such as echo chambers and self-doubt, severely hampering the agents' performance in collaborative tasks."}]}