{"title": "Computational Dynamical Systems", "authors": ["Jordan Cotler", "Semon Rezchikov"], "abstract": "We study the computational complexity theory of smooth, finite-dimensional dynamical systems. Building off of previous work, we give definitions for what it means for a smooth dynamical system to simulate a Turing machine. We then show that 'chaotic' dynamical systems (more precisely, Axiom A systems) and 'integrable' dynamical systems (more generally, measure-preserving systems) cannot robustly simulate universal Turing machines, although such machines can be robustly simulated by other kinds of dynamical systems. Subsequently, we show that any Turing machine that can be encoded into a structurally stable one-dimensional dynamical system must have a decidable halting problem, and moreover an explicit time complexity bound in instances where it does halt. More broadly, our work elucidates what it means for one 'machine' to simulate another, and emphasizes the necessity of defining low-complexity 'encoders' and 'decoders' to translate between the dynamics of the simulation and the system being simulated. We highlight how the notion of a computational dynamical system leads to questions at the intersection of computational complexity theory, dynamical systems theory, and real algebraic geometry.", "sections": [{"title": "Introduction", "content": "Models of digital computation, which lie at the foundation of computer science, are typically discrete, while most of our fundamental models of the physical world are essentially continuous. Nonetheless, the Church-Turing thesis [Tur39] and its physical counterparts [Gan80, CS07] state that this difference is illusory: the discrete computations we can perform reliably in the physical world should be the same as those which can be performed by a Turing machine, possibly by one having access to random bits. The validity of the physical Church-Turing thesis is a subject of debate, and a number of variants of the thesis have been proposed [Cop97]. Furthermore, from the perspective of complexity theory rather than computatibility theory, the possibility for quantum computers to solve with high probability, in polynomial time, decision problems which are not in P, is a basic motivation for research on quantum computation [NC10, ACQ22].\nIn a different (non-quantum) direction, there have been multiple models proposed for a definition of a computable real function [Grz55, Lac59, Blu98, Sma97, Bra05a], and using this language, it has been found that simple finite-dimensional continuous dynamical systems defined by polynomial equations with integral coefficients can exhibit non-computable dynamical properties [Moo90, BY06]. In general it is known that the existence of natural problems with no computable solution (such as the problem of recognizing presentations of the trivial group [PS]) forces complex behaviour of various continuous mathematical objects related to geometry and dynamics [Wei20, Sei08]. In yet a different direction, there has been a sequence of papers asking whether universal computation can be realized by various ordinary [Bra94] and partial differential equations, including in single-particle potential energy systems [Tao17] and in solutions to fluid dynamics equations [CMPSP21]; this was in part motivated by the hope of showing the existence of blow-up solutions to the Navier-Stokes equations by finding fluid flows which \u2018replicate themselves' at smaller and smaller scales [Tao16]. Such works on realizing universal computation in natural continuous physical models can be seen as a continuation of Moore's earlier work [Moo98, Moo90], which realized universal computation in a simple 2-dimensional piecewise-linear map, as well as in a Lipschitz map on the interval and an analytic map on R. The relation between the computational capacity and the analytic or dynamical properties of a continuous dynamical system, such as its topological entropy or its regularity, are known to be subtle: for example, depending on the formalization, the topological entropy of a Turing-universal system can be zero [CMPS23] or can be forced to be nonnegative [BCMPS24].\nResearchers in both machine learning and computational neuroscience are often forced to posit that various continuous systems (recurrent neural networks, transformers, models of brains) implement certain computations [Sus14, CSY16, MPVL19, KKS+15, KF22, CTH+23], and indeed part of the problem of neuroscience is to extract, from neuronal measurements, the 'computations' implemented by the brain. Such scientific applications were part of the motivation for the founders of the mathematical field of differentiable dynamical systems theory [Sma67, Tho69], who originally tried to extract simple \u2018discrete' descriptions of the dynamics of systems like Axiom A systems. The development of differentiable dynamical systems theory led to a collection of powerful mathematical methods for understanding dynamical systems. Nonetheless, these methods are rarely used by non-mathematicians, perhaps because they do not connect straightforwardly with the kinds of questions the researchers in neural network interpretability and computational neuroscience typically ask.\nTo 'do' complexity theory with continuous dynamical systems, one must know what it means for a continuous system to 'implement' a discrete computation. Unfortunately, this notion is not completely clear and many of the works cited above do not give precise definitions for this notion. Here we propose an answer to this question via a perspective which is natural to computer scientists. We will show that without some definition like the one we propose, computability questions about continuous dynamical systems become trivialized. Our proposed definition differs from other proposals connected to the Space-Bounded Church-Turing Thesis [BSR15, BGR12] by not requiring for \u2018noise' to be introduced in the continuous dynamics. Moreover, our proposed framework naturally leads to interesting questions that should feel familiar to those interested in the mathematical study of differentiable dynamical systems. In"}, {"title": "Introduction", "content": "particular, we prove several results regarding complexity and computability theory in the context of our framework by utilizing results from differentiable dynamical systems theory.\nTo explain our proposal, let us recall how computer scientists ask computational complexity questions about discrete systems. Given some machine $T: S \\to S$ with discrete configuration space $S$ (where $x \\in S$ describes the configuration of a machine including all of its tapes at a given moment), we would say that $T$ is Turing universal if it can do the same computations as any fixed universal Turing machine $T_{univ}$. To establish this property of $T$, we always need to find some encoder $E$ which lets us encode configurations of $T_{univ}$ into configurations of $T$, and some decoder $D$ which lets us decode a configuration of $T_{univ}$ from a configuration of $T$. In fact, since there are many definitions of a Turing machine (e.g. with one-sided or two-sided tapes, with multiple tapes, as well as more exotic variants), such constructions are needed when setting up the theory of computation; many implicit examples of such encoders and decoders can be found in basic textbooks like [Sip12, AB09]. For such constructions to make sense, one must require that the encoder and decoder are themselves computationally simple, e.g. that they can be implemented by a low-time complexity Turing machine or a uniform family of low-depth circuits. Otherwise, one can package all the computation into the encoder and decoder themselves (see Section 3.1.2); thus, the notion of a Turing-universal system already presupposes the existence of a basic theory of computational complexity to constrain the encoder and decoder.\nLuckily, in the continuous domain there is already a well-developed theory of computable real functions and uniform real circuits [Blu98, Bra05a]. Thus, to ask if a continuous system $f: M \\to M$ (where $M$ is continuous, e.g. $M = [0,1]^n$) is Turing-universal, we can require for there to be low-time complexity $R$-Turing machines $E, D$ which respectively encode bit strings from the configuration space of the Turing machine into the domain of $f$, and decode regions in the domain of $f$ to e.g. bit strings from the configuration space of the Turing machine."}, {"title": "Introduction", "content": "Definition 1.1 (informal; see Definition 3.19). A computational dynamical system (or CDS) is a tuple $(f,E,D,\\tau,T)$ where:\n$\\bullet$ $f: M \\to M$ is a dynamical system, with $M \\subset \\mathbb{R}^k$;\n$\\bullet$ $E: S \\to M$ is a function which can be implemented by a BSSC machine (a model of real computation; see Definition 3.13 and Appendix A) that runs in time $O(t(n))$ for some function $t(n)$ of the length of the input;\n$\\bullet$ $D: M \\to S$ is a partially defined function (i.e. a function $M \\to S \\cup \\{ Error \\}$) which can be implemented by a BSSC machine that runs in time $O(t(n))$, for the same function $t(n)$ of the length of the output of $D$;\n$\\bullet$ $\\tau: M \\to \\mathbb{Z}_{>0}$ is a function which is constant on connected components of $D^{-1}(s)$; and\n$\\bullet$ $T: S \\to S$ is a discrete computational system, e.g. a Turing machine (although variants can be defined e.g. for pushdown automata).\nThis tuple is required to satisfy the condition that $D \\circ E = Id$, as well as the condition that for $s \\in S$, we have\n$$D \\circ f^{\\tau} \\circ D^{-1}(s) = T(s) .$$\nHere $f^{\\tau}: M \\to M$ where $f^{\\tau}: x \\to f^{\\tau(x)}(x)$. Thus the encoder-decoder pair along with $f$ can simulate $T$ with a slowdown determined by $\\tau$ and $t(n)$.\nRemark 1.2. An equivalent condition to the above is that $f^{\\tau}$ takes all of $D^{-1}(s)$ into $D^{-1}(s)$. If $D^{-1}(s) = \\{E(s)\\}$, then this is equivalent to the condition that $D \\circ f^{\\tau} \\circ E = T$. However, for general $D$ for which $D^{-1}(s)$ may have non-empty interior, this notion corresponds to requiring that the computation be robust: any perturbation of the ideal input $E(s)$ corresponding to $s$, which still lies in a 'validity region' $D^{-1}(s)$, will continue to compute the correct answer. Thus, the above definition encapsulates a model of computation"}, {"title": "Introduction", "content": "which is robust to non-uniform errors, i.e. the amount of error allowed may depend on the input and may go to zero in certain regions of the domain of $f$. It is the non-uniformity of the allowed amount of error that enables universal computation on compact domains (see the discussion regarding robustness in Section 2).\nEssentially all previous work on computational properties of continuous dynamical systems (e.g. [Moo98]) can be put into this framework; our definition gives a precise notion of a 'reasonable' encoding of states of $T$ into $M$, which has thus far been without a definition in the literature. Without such a condition on $D$ and $E$, the notion of simulation becomes essentially trivial (Example 3.23), just as in the case of Turing machines.\nHowever, with bounds on $\\tau(x)$ and $t(n)$ (e.g. $\\tau(x) = O(|D^{-1}(x)|)$ and $t(n) = O(n)$) the notion of simulation is nontrivial, and we can say that a continuous dynamical system $f$ is Turing-universal when there exists a CDS $(f,E,D,\\tau,T_{univ})$ for some universal Turing machine $T_{univ}$. Thus universality is an intrinsic property of $f$; we will see that dynamical systems $f$ which in our sense are both \u2018robust' and universal exist, even though many natural dynamical conditions on $f$ will be shown to preclude universality. It is natural to generalize CDSs to the setting of forced dynamical systems, as would be appropriate for studying e.g. finite state machines, RNNs, transformers, etc. We develop the theory of forced CDSs in [CR]."}, {"title": "Our results", "content": "One of the benefits of our notion of a CDS is that it is straightforward to define various conditions for the decoder $D$ in order to model different ways of encoding. For instance:\nDefinition 1.3. Let $(f,E,D,\\tau,T)$ be a CDS. We say that the decoder $D$, as well as the CDS, is robust if for every $s \\in S$ (where $S$ is the configuration space of $T$) we have that $D^{-1}(s)$ is the closure of its interior, and $E(s)$ lies in the interior of $D^{-1}(s)$.\nClearly, the notion of a robust CDS models the idea that if a state is encoded via the encoder $E$, then some amount of $C^0$-bounded noise $\\eta$ can be allowed in the encoding $E(s)$ of $s$ such that the states $D \\circ (f^{\\tau})^k(E(s) + \\eta)$ correctly simulate the dynamics of $T$ starting from $s$. (Here $f^0 = f$ if $\\tau = 1$; see Definition 3.19.) This is different from other notions of robustness in the literature, which we will discuss in Section 2 below."}, {"title": "Universality: existence and obstructions", "content": "The first result of the paper, beyond setting up the definitions, shows that the resulting theory is non-vacuous:\nTheorem 1.4. There exists a robustly Turing-universal CDS $(f,E,D,\\tau,T_{univ})$ with $\\tau(x) = 1$, $t(n) = O(n)$, and $f$ a smooth diffeomorphism of the closed 2-disk.\nThis construction is modeled off that of Moore [Moo91], using an idea similar to that of [CMPSP21]. The construction of [Moo91] provides a map of a square that is piecewise linear, as well as an associated smooth map that, while having correct dynamics for a decoder $D$ with $D^{-1}(s) = \\{E(s)\\}$ for all $s \\in S$, cannot in any evident way be upgraded to a robust decoder; the construction of [CMPSP21] shows how to make $f$ a smooth area-preserving map, but suffers from the same problem as the construction of [Moo91]. In fact, area-preserving maps can never furnish a robustly Turing-universal CDS:\nTheorem 1.5 (see Corollary 4.21). Let $f: M \\to M$ be such that $M$ is a codimension 0 submanifold of $\\mathbb{R}^n$, and suppose that there is an an $f$-invariant Borel measure $\\mu$ on $M$ which is nonzero on all nonempty open sets and such that $\\mu(M) < \\infty$. Then $f$ cannot be extended to a robustly Turing-universal CDS $(f, E, D, T, T_{univ})$ for any $\\tau$ or $T$."}, {"title": "Introduction", "content": "In particular, the examples of [CMPSP21] and subsequent papers cannot be made into robustly Turing-universal CDSs in our sense. As a consequence of a general result about measure-preserving dynamics (Theorem 4.24), we prove an analog of Theorem 1.5 for \u201cintegrable systems\u201d, e.g. $f$ is a linear translation on a torus, or a family of these depending on an additional parameter, such as if $f$ is the Hamiltonian dynamics for a Hamiltonian $H : M \\to \\mathbb{R}$ where $M$ is a \"computable manifold\" (see Remark 3.20) with a symplectic form $\\omega$ such that $H$ is part of a system of pairwise Poisson-commuting Hamiltonians $(H_1,..., H_n)$ with $H_1 = H$.\nIntegrable systems are among the simplest possible model systems in physics, as their behavior is completely and efficiently predictable. On the other extreme, we have systems which are 'completely chaotic': their behavior is sensitive to their initial conditions in a strong sense. In differentiable dynamics, these are axiomatized under the guise of uniformly hyperbolic, or Anosov, diffeomorphisms, and form fundamental examples in differentiable dynamical systems theory. Another natural class of examples in dynamical systems theory are time-1-gradient flows of generic Morse functions. Their common generalization is the class of Axiom A systems, which we review in Section 4.2; a fundamental theorem is that the structurally stable systems, i.e. those diffeomorphisms $f$ such that any nearby diffeomorphism $\\tilde{f}$ has the same dynamics (from a topological perspective) as $f$, are exactly the Axiom A systems satisfying a transversality assumption (see Theorem 4.11).\nIt turns out that just as the least chaotic, i.e. integrable, systems cannot be robustly Turing universal, the 'most chaotic' systems, and more generally the structurally stable systems, likewise cannot be robustly Turing universal:\nTheorem 1.6. Let $M$ be a manifold, and let $f : M \\to M$ be an Axiom A diffeomorphism. Then $f$ cannot be extended to a robustly Turing-universal CDS $(f,E,D,\\tau,T_{univ})$ for any $\\tau$ or $T$.\nRemark 1.7. The manifold $M$ does not need to be compact; however, by definition (Definition 4.9), the nonwandering set of $f$ is compact.\nThe argument used to prove Theorem 1.6 uses deep structural results about the dynamics of $f$ due to Smale [Sma67] and others [HP70]. Moreover, the arguments proving Theorems 1.5 and 1.6 do not use all of the structure of the universal Turing machine $T_{univ}$. Indeed, we define a notion of a sub-machine of $T_{univ}$ such that if $f$ simulates $T_{univ}$ and $N$ is a sub-machine of $T_{univ}$, then $f$ also simulates $N$ (possibly with modified $\\tau$ and $\\tau$, i.e. with a slowdown).\nTheorem 1.8 (see Theorem 4.20). In the setting of Theorem 1.5, in fact $f$ cannot be extended to a robust CDS $(f,E,D,T,\\tau)$ if $T$ contains as a sub-machine the machine Plus : $\\{1\\}^* \\to \\{1\\}^*$ defined by Plus([n]_1) = [n + 1]_1, where $[n]_1$ denotes $n$ expressed in unary. Similarly, in the setting of Theorem 1.6, $f$ cannot be extended to a robust CDS $(f,E,D,T,\\tau)$ if $T$ contains as sub-machines $T_n$ for all $n > 0$, where $T_n : S \\to S$ is simply the identity map and $|S| = n$.\nThe method of proof of Theorem 1.5 from earlier is to note that if $f$ simulates the the sub-machine Plus, then there must be an infinite collection of disjoint regions $C_i$ such that $f^{\\tau_i}(C_i) \\subset C_{i+1}$ and such that the sum of the measures of the $C_i$ is finite; thus the measures of the $C_i$ must decrease to zero, which contradicts the requirement that $f$ is measure-preserving.\nIn contrast, the proof of Theorem 1.6, namely a proof by contradiction, uses the sub-machines $T_n$ to produce an arbitrarily large finite disjoint collection of closed subsets $C_i$ with nonempty interiors such that $f^n(C_i) \\subset C_i$ for each $i$. Then, one invokes the spectral decomposition of $f$, decomposing its nonwandering set into finitely many basic sets, and then uses stable manifold theory to force each $C_i$ to contain at least one of the basic sets. Essentially, points in $C_i$ must be attracted to one of the basic sets, so they lie on the stable manifold of one of the points on the basic sets; perturbing this point a small amount and following the stable manifold back to $C_i$, one finds a new point asymptotic to a point on a basic set with a dense periodic orbit. Thus since $C_i$ is closed, it must contain that entire basic set; the argument concludes with a contradiction because there are more sets $C_i$ than there are basic sets, and yet the $C_i$ are pairwise disjoint."}, {"title": "Time complexity bounds", "content": "These results suggest future research directions for exactly characterizing the 'computational complexity classes' that can be assigned to various types of dynamical systems. There is an expectation in the differentiable dynamics literature that as one allows for non-uniform hyperbolicity, and more generally for mixtures of integrable and chaotic behavior (such as that arising in Henon system [PC10]), then more complex types of dynamical behavior can occur [PM80]. It would be desirable to identify precise differences between the types of computations that can be implemented by such systems. We venture the following conjecture:\nConjecture 1.9. A $C^\\infty$ generic $f : M \\to M$ cannot be extended to a robustly Turing-universal CDS.\nWe are able to prove this conjecture under a strong additional assumption on the decoder $D$ as well as a constant slowdown function (see Theorem 4.15) via a periodic-point argument and the Kupka-Smale Theorem (see [KKH95, Chapter 7]). It may be possible to resolve this conjecture under the assumption of the well known Palis conjectures on the dynamics of generic smooth dynamical systems [Pal00]; any argument for this conjecture, like the Axiom A argument, is likely to require sophisticated input from differentiable dynamical systems theory."}, {"title": "Time complexity bounds", "content": "Going beyond statements about decidability or universality, it is natural to ask more refined questions about the computational capacity of smooth dynamical systems. In particular, it is desirable to show that various natural dynamical conditions on $f$, e.g. Axiom A, exponential mixing, genericity, etc., bound the computational capacity of $f$ such that one can identify a comparatively small complexity class of problems solvable by such $f$. For example, it is natural to ask whether generic one-dimensional systems can recognize languages that are not in P. We formalize such questions in Appendix B, and proceed by proving some initial time complexity results in this setting:\nTheorem 1.10. Let $f : [0,1] \\to [0,1]$ be an Axiom A diffeomorphism (this property is generic and equivalent to structural stability). For any CDS $(f,E,D,1,T)$ where $t(n) = n$ and $\\tau$ is constant, if $T$ halts on a configuration then it will halt in time $O(F(n))$, where\n$$F(n) = D^{2^n}$$\nfor some constant $D$. In other words, in the sense of Appendix B, $f$ can recognize languages in at best $DTIME(O(F(n)))$.\nRemark 1.11. The result actually holds for a much wider class of slowdown functions $\\tau$; see Remark 4.34.\nThe proof relies on the structure theory of one-dimensional Axiom A systems. Standard results [KKH95] imply that such systems have only finitely many hyperbolic attracting periodic points, and the complement of their basins of attraction is a (possibly fractal) repelling set. Now, each configuration of $T$ is associated to some disjoint union of subintervals of $[0, 1]$. One then uses (i) lower bounds from real algebraic geometry about the minimum separation between roots of real polynomials as a function of their coefficients [Rum79], (ii) the construction of symbolic dynamics controlling the dynamics of the chaotic hyperbolic repeller of $f$ [KKH95], and (iii) the complexity condition on the decoder, in order to show that one of these $[0, 1]$ subintervals contains a point that must get very close to the hyperbolic periodic point attractor in time $O(F(n))$. Subsequently, either one sees that the rest of the interval must still be stuck near the hyperbolic repelling set for several iterations, which is a contradiction if we do not halt since regions corresponding to configurations cannot overlap; or the entire interval must have escaped a neighborhood of the hyperbolic repelling set, in which case waiting another $O(F(n))$ time will allow us to decide if the computation will halt or not."}, {"title": "Time complexity bounds", "content": "In higher dimensions, analogs of the real algebraic geometry bound [Rum79] seem not to have been established, while the dynamics of Axiom A systems are comparatively more complicated. Thus, we restrict ourselves to the simplest Axiom A systems, the Anosov ones, and prove an inexplicit complexity bound:\nTheorem 1.12. Let $f: M \\to M$ be Anosov and volume-preserving. Consider a CDS $(f,E,D,T,T)$ where $t(n) = n$, the decoder is Cantor-like (Definition 4.36), and the encoder and decoder are implemented by BSSC machines with the finite set of computable constants being $\\{a_1,...,a_\\rho\\}$. Then the CDS halts on all configurations in time $O(C(n))$, where $C(n)$ is a computable function depending on $a_1,...,a_\\rho$.\nNote that unlike in the Axiom A case, such systems must always halt. This feature arises from the topological mixing of Anosov systems, since robust CDSs with topologically mixing dynamics must always halt (Lemma 4.35). To establish a computable halting time bound, one must know how fast these systems mix. We do this via the Sinai-Bowen-Ruelle theory of exponential mixing of Anosov systems [Bow78, BR75], together with some elementary real algebraic geometry counting argument to get a bound on how fast the sets corresponding to configurations of $f$ can shrink as $n$ increases. In short, exponential mixing means that the time evolution of the space correlation between for $F_1$ and $F_2$, where $F_1$ is a nonnegative function supported in a ball inside $C_s := D^{-1}(s)$, and $F_2$ is a nonnegative function supported inside the halting set, must converge to a positive number $\\int F_1 \\int F_2$ at an exponential rate. This gives us an upper bound on how long the correlation can be zero, i.e. on how long the images of $C_s$ (corresponding to input configuration $s$ of the machine $T$ simulated by $f$) do not intersect the halting set. Since the sets $C_s$ do not shrink too fast as $n$ increases, we can argue that the bound for the halting time of this CDS is computable.\nWe expect that the dependence on the computable constants $(a_1,..., a_\\ell)$ can be removed and a bound on $C(n)$ can be made explicit, but this depends on a natural problem in real algebraic geometry which we explain in the text. We expect that in fact one can give polynomial time halting bounds. Moreover, the condition that $f$ is volume-preserving is likely to be inessential, but removing this condition involves more subtle arguments about the invariant SRB measure for $f$, which in general is not absolutely continuous with respect to the Lebesgue measure, even for Anosov systems. We leave these improvements to future work."}, {"title": "Related work", "content": "This paper contributes a precise definition that allows one to probe the intrinsic computational capacity of a continuous dynamical system $f$. Moreover, the results of Section 1.2 show that the resulting theory is nontrivial. As mentioned in the introduction, there have been many previous approaches to this problem. Below, we compare our work with the different perspectives taken previously.\nReal computation. One might ask for the dynamical system $f$ to be computable in one of the many senses of the term [Blu98, Bra05b, Ko12, Weil2], and apply one of the different theories of computable real functions. Crucially, in our theory, the continuous dynamical system $f$ is not required to be a computable map, and even for uncomputable $f$, the theory remains nontrivial. Moreover, using the notion of a robust decoder means that we are not studying the dynamics of $f$ on a countable set of computable points, as is done in many previous works [CMPSP21, CMPS22, CMPS23, Moo90, Moo91, Moo98], but instead studying its behavior on certain open domains of controlled complexity. These two conditions together force one to use results about $f$ involving its continuous dynamical properties (preserving measures, Axiom A-ness, etc.) rather than its properties in terms of some language used to describe $f$. As such, we elucidate the computational significance of various notions in differentiable dynamics. In particular, probing $f$ only along the points of $E(S)$ rather than over the sets $D^{-1}(S)$ means that much of the global behavior of $f$ is neglected in the analysis. Since we think of $f$ as a \u2018natural system' (i.e. a brain or a neural network), from this perspective it is unnatural to expect that we can prepare continuous parameters of states in any experiment without introducing some 'error tolerance'.\nRobustness. There are two flavors of previous perspectives on 'robust computation' in continuous dy- namics. The first is exemplified by [BGR12, BSR15], where one asks that the dynamics is modified by the addition of some uniform noise. In this case, the system becomes essentially indistinguishable from"}, {"title": "Related work", "content": "a finite state Markov process, and because of this most properties of the system become computable in a suitable sense [BGR12]. This makes it difficult to ask computational complexity questions about the intrinsic dynamics of $f$.\nThe other notion of \u2018robust computation' in continuous dynamics is exemplified by [AB01, BGH13, GCB08], which essentially fix a robust decoder for $f$ and require that there is an $\\epsilon$ such that the same robust decoder suffices to simulate the desired machine for all $f$ which are $\\epsilon$-close to $f$ in the $C^0$ norm. In this formalization, one also finds that universal computation cannot be achieved robustly by finite-dimensional dynamical systems [BGH13], essentially by approximating the behavior of $f$ by its behavior viewed through a 'pixelated lens' of the domain, which is again simply the behavior of a finite state machine. By defining robust computation as an asymptotic condition as the amount of uniform noise added goes to zero, [BGH13, GCB08] show that systems $f$ can be than finite state machines: in fact, they can robustly recognize precisely the recursive languages. Moreover, approaches like [BGH13] focus on asking dynamical systems to recognize languages rather than to simulate machines, as we do. Our approach leads to a different class of questions, which are entwined with the theory of differentiable dynamical systems and the notion of simulation, and are less focused on the question of deciding reachability of the halting set. In our approach, we prove computational restrictions on an individual $f$, without any perturbations made to $f$, and for arbitrary decoders coupled to $f$. This is a very different setup from results which fix a decoder; our approach aims to probe the 'intrinsic' computational capacity of $f$. Moreover, our notion of robustness does not allow for arguments which boil down the dynamics of $f$ to that of a finite state machine due to the lack of uniformity in the 'noise' allowed when simulating $f$. (Analogously, although every physical computer is in effect a finite state machine, we do not model them as such in order to understand the computations they are performing, and so it is appropriate not to turn every continuous dynamical system into a finite state machine.) Our notion of robustness models the idea of preparing an initial state of an experiment to 'sufficiently high precision', with the precision required described by the decoder; as such, it is analogous to a variant of the noise models of [BGR12] with highly non-uniform noise, or to asking for robustness to perturbations of $f$ where the norm of the perturbation is allowed to depend on $x \\in M$ (with $M$ the domain of $f$) in a non-uniform way.\n'Reasonable' state encodings. There have been many clever constructions of various mechanisms implementing computation in continuous dynamical systems [Moo90, Moo91, Moo98, CMPSP21, Car23]. Most often, these encode states of some discrete computational system via points of the continuous state space $M$, i.e. the decoder satisfies $D^{-1}(s) = \\{E(s)\\}$. As mentioned before, this ignores robustness, and only probes the behavior of $f$ on some Cantor set of points, making it difficult to prove upper bounds on the computational capacity of $f$.\nMoreover, previous works usually ask for the state encoding to be \u2018reasonable' [Moo98], usually without making precise what this means [CMPSP21]. In this paper we give a precise definition of a 'reasonable' state encoding, and also advocate for focusing on dynamics of open sets (or sets with non-empty interior) rather than of individual points in the continuous state space. Although our definition of a \u2018reasonable' state encoding may seem natural after reading it, our use of the theory of real computation as a bootstrap to make sense of the computational power of more general continuous dynamical systems is new, and is carefully designed to avoid many potential issues having to do with the theory of real computation. For example, BSSR machines (which were the ones originally defined by Blum-Shub-Smale [BSS89], rather than the later BSSC-machines) are capable of strong super-Turing computation via access to uncomputable constants [Bra05b]. Additionally, decoders defined using non-uniform circuit families also lead to pathologies like Example 3.23. Finally, formulating the decoding of states in terms of bit complexity either leads to pathologies involving states encoded in regions which are essentially \u2018pixelated' (if the decoder can be bit- computed in finite time) or only being able to define the encoder and decoder via an infinite computation, making it more challenging to state the required complexity constraints on the encoder and decoder. We do not explicate these alternative problematic formalizations in this work, but it is a central contribution of this paper to define CDSs such that they formalize previously existing intuitions while avoiding many"}, {"title": "Related work", "content": "possible technical pitfalls.\nSymbolic dynamics. A popular approach in the mathematical literature on continuous dynamical sys- tems is to study the dynamics of $f$ via symbolic dynamics", "sigma": "M \\setminus M_0 \\to \\Sigma$ for some discrete alphabet $\\Sigma$", "tau_f(x)": "x \\in M \\setminus M_0\\"}, "tau_f(x) := (\\sigma(x), \\sigma(f(x)), \\sigma(f^2(x)),...)$$\nOne hopes to find a $\\sigma$ for which the map $x \\to \\tau_f(x)$ is injective on $x \\in M \\setminus M_0$, but for which the number of symbols is small, e.g. finite. This approach is reviewed in Appendix C. It turns out that it is often possible to achieve this, and the method and its variations are very helpful for studying dynamical properties of $f$. Thus, one might be tempted to say that one should identify $f$ with the corresponding discrete language $L_{f,\\sigma}$.\nHowever, this approach leads to several challenges. The first is that one might have different discretiza- tion maps $\\sigma_1$ and $\\sigma_2$ such that the resulting languages $L_{f,\\sigma_1}$ and $L_{f,\\sigma_2}$ are of vastly different computational complexity. As such, there is no obvious mechanism for 'upper bounding' the computational capacity of a differentiable dynamical system if one measures computational capacity in terms of the corresponding language $L_{f,\\sigma}$. The second is that while the symbolic dynamics allows one to associate notions of language"]}