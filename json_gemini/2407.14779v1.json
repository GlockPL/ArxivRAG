{"title": "Do Generative AI Models Output Harm while Representing Non-Western Cultures: Evidence from A Community-Centered Approach", "authors": ["Sourojit Ghosh", "Pranav Narayanan Venkit", "Sanjana Gautam", "Shomir Wilson", "Aylin Caliskan"], "abstract": "Our research investigates the impact of Generative Artificial Intelligence (GAI) models, specifically text-to-image generators (T2Is), on the representation of non-Western cultures, with a focus on Indian contexts. Despite the transformative potential of T2Is in content creation, concerns have arisen regarding biases that may lead to misrepresentations and marginalizations. Through a community-centered approach and grounded theory analysis of 5 focus groups from diverse Indian subcultures, we explore how T2I outputs to English prompts depict Indian culture and its subcultures, uncovering novel representational harms such as exoticism and cultural misappropriation. These findings highlight the urgent need for inclusive and culturally sensitive T2I systems. We propose design guidelines informed by a sociotechnical perspective, aiming to address these issues and contribute to the development of more equitable and representative GAI technologies globally. Our work also underscores the necessity of adopting a community-centered approach to comprehend the sociotechnical dynamics of these models, complementing existing work in this space while identifying and addressing the potential negative repercussions and harms that may arise when these models are deployed on a global scale.", "sections": [{"title": "1 Introduction", "content": "Innovations into Generative Artificial Intelligence (GAI) tools such as text-to-image generators (T2Is) have revolutionized the way we create content, such as producing realistic images/videos. This potential has seen a sharp uptick in GAI adoption in industries such as healthcare (Hastings 2024) and policy-making (Huer and Saenz 2003), with the promise of unlocking unprecedented capabilities with far-reaching implications. However, GAI tools have also been found to embed biases that skew their generated artefacts towards the experiences of a select few rather than the diverse many (Septiandri et al. 2023; Gupta et al. 2023b), prompting further scrutiny of their potential effects on society.\nOne such pattern of bias is a 'Western gaze,' whereby outputs around non-Western contexts contain superimposed Western interpretations of those contexts (Kotliar 2020). This is a critical problem, especially given how T2Is are being used globally and beyond just the West, and perhaps most prominently in Global South contexts such as Asia and Africa (Bianchi et al. 2023; Venkit et al. 2023c; Gautam, Venkit, and Ghosh 2024). As representational systems (Hall 1997a), T2Is thus have the power to make meaning and influence culture through produced artefacts and, by applying a Western gaze to Non-Western contexts, cause 'representational harms' (Barocas et al. 2017) by misrepresenting and marginalizing the experiences of populations that are globally minoritized (Bender et al. 2021). However, this remains an under-addressed issue, as research into T2I ethics and fairness often center Western perspectives and rely on Western frameworks of ethics and fairness (Septiandri et al. 2023; Das et al. 2024; Venkit et al. 2023b).\nMotivated by these gaps, our work is a community-centered investigation into depictions of non-Western cultures within T2I outputs, focusing on a specific context where AI-mediated harms are rising (Raj 2024): India, an incredibly diverse country with over 1.4 billion people spanning a wide range of regional subcultures, each with their own languages, cuisines, attire, art forms, festivals, and much more (Panda and Gupta 2004). Through grounded theory analysis (Charmaz 2017) of 5 focus groups with 25 participants from various Indian subcultures/regions, we explore the following questions:\nR1: How do T2I outputs represent Indian culture and its subcultures, and what are the implications of these representations for diverse cultural groups?\nR2: What novel forms of representational harms emerge from the interactions between T2I systems and Indian cultural contexts, and how can we address these harms?\nBeyond focus group participants perceiving pre-defined representational harms such as stereotyping of Indianness, the erasure and disparagement of specific subcultures and a lower quality of service in comparison to Western contexts"}, {"title": "2 Related Work", "content": "The extensive documentation of biases embedded within GAI tools and the operationalization of such biases to produce harmful outcomes has sparked widespread concern among researchers, who have highlighted the far-reaching negative consequences of these models on diverse communities (Bender et al. 2021; Caliskan, Bryson, and Narayanan 2017; Gupta et al. 2023a). As such outputs are seen to amplify societal biases that disproportionately affect marginalized groups by perpetuating a variety of racial (Field et al. 2021; Sap et al. 2019), gender (Bolukbasi et al. 2016; Caliskan, Bryson, and Narayanan 2017), disability (Gadiraju et al. 2023; Venkit, Srinath, and Wilson 2023), and nationality-based biases (Venkit et al. 2023b,c) that reinforce outdated attitudes and exacerbating harmful stereotypes.\nThrough the propagation of such stereotypes and the presence of negative biases, the outputs of GAI tools can and do cause harm. In the broader context of machine learning-based systems, (Blodgett 2021) break these down into representational and allocational harm, based on whether harmful representations are generalized or resources are distributed disparately. A taxonomy of fine-grained representational harm categories includes quality of service, stereotyping, stigmatization, alienation, and public participation. Documenting attributes of bias measures can facilitate a better understanding of harms, use cases, and limitations. Building on this, Dev et al. (2022) developed a framework categorizing harm into five types: Stereotyping, Disparagement, Dehumanization, Erasure, and Quality of Service. Their work offers a framework to GAI researchers such as ourselves for labeling and investigating patterns of harms.\nInvestigating such harms has become especially critical as GAI systems are growing into a prominent part of the suite of AI-as-a-Service (AIaaS) tools that aim to provide convenient plug-and-play AI services (Lewicki et al. 2023) across interdisciplinary fields such as education (Rane et al. 2023), healthcare (Zack et al. 2023; Hastings 2024), and policy-making (Huer and Saenz 2003). The ease of using AlaaS tools has led to its meteoric rise in adoption in global contexts, and a subsequent surge in investigating how biases in such contexts propagate globally (e.g., Lewicki et al. 2023; Venkit 2023). While designers of GAI and AlaaS tools have been working on mitigating such biases, the majority of approaches have been found to be mostly technical (Birhane 2021), completely ignoring the social contexts in which systems operate (Venkit et al. 2023a, 2024).\nResearchers have therefore argued that mitigation of biases should adopt a sociotechnical approach: recognizing that AlaaS tools both influence and are impacted by social stakeholders and end-users (Cooper and Foster 1971; Brynjolfsson, Li, and Raymond 2023). This is important, since purely technical approaches miss the important fact that the data that drives GAI tools embedded within AlaaS services is heavily influenced by the perspectives and positionalities of the humans who were part of model training teams (Birhane 2021), and that such an oversight can lead to perceived technical 'solutions' being ineffective in the real world (D'ignazio and Klein 2020). A sociotechnical systems perspective on AI services and embedded GAI tools requires the perspectives of communities whose members experience the harms and suffer their impact in their daily lives. This approach prioritizes the equal involvement of social stakeholders and minority voices in the creation of these sociotechnical systems, ensuring that their perspectives and experiences are not erased or marginalized. Community-centered approaches towards recognizing and mitigating the biases"}, {"title": "2.1 Biases and Harms within GAI Tools: A Sociotechnical Systems Perspective", "content": "The extensive documentation of biases embedded within GAI tools and the operationalization of such biases to produce harmful outcomes has sparked widespread concern among researchers, who have highlighted the far-reaching negative consequences of these models on diverse communities (Bender et al. 2021; Caliskan, Bryson, and Narayanan"}, {"title": "2.2 Stereotypical Representations of Indian Culture/ Subcultures", "content": "Though depictions of India in Western media as 'the land of snake charmers' (Chaudhuri 2009) and other features which Satyajit Ray (1958) called 'the false-exotic' might sound like relics of the past, that is not the case. As recently as the 2010 Julia Roberts classic 'Eat, Pray, Love', the protagonist perpetuates another famous Indian stereotype, as she visits India to 'find herself.' Hollywood projections of India are littered with stereotypes, both Orientalist perspectives (Said 1977) that show India as the \"land of miracles and wonders,\" (Chakkarath 2010) as well as ones about subcultures such as \"the artistic Bengali, the simple Gujarati, the austere Maharashtrian, and the intelligent Tamil brahmin\" (Mehta and Pandharipande 2011). Furthermore, given how films made in Hollywood or European film industries often are centered in their own contexts, Indian representation typically happens through characters in the Indian diaspora, either as fully Westernized individuals who ignore or actively look down upon elements of Indian culture (most commonly, eating with one's hands), or projecting a romanticized view of India as a place they long to return to (Trivedi 2008). While portrayals of Indian culture within Western film media might evoke a sense of India having established a presence on the global stage (Matusitz and Payano 2012), stereotypical representations of Indian-ness still leave much to be desired.\nHowever, any discussion of representations of Indian culture/ subcultures is incomplete without addressing how they occur within Indian contexts. Mainstream media within India, primarily dominated by India's Bollywood film industry, also perpetuates stereotypes around Indian culture/subcultures. As Arora and Sylvia (2023) writes, \u201cpopular Hindi cinema has articulated Indian identity as Hindu identity, with the normative Indian citizen presented as North Indian and Hindu.\" Bollywood movies across the past 70 years has overwhelmingly featured characters with traditionally Hindu names, with little to no geographical representation of the Northeastern states of India (Khadilkar, KhudaBukhsh, and Mitchell 2022). Muslim characters, when shown, are often cast as violent antagonists or terrorists assosciated with Pakistan (Bhat 2019; Kumar 2013), or the 'good Muslim' (Mamdani 2002) who stands against other antagonistic Muslims (Islam 2007). Similarly, Northeast India, when featured, is often romanticized as exotic landscapes, contrasting the slow and rural lifestyles here with the busy, urban cities elsewhere in India (Dowerah and Nath 2017; Hasan 2011). These depictions of India contribute strongly to how Indian culture is perceived, defining 'Indianness' to the West (Matusitz and Payano 2011).\nOur paper directly follows Qadri et al. (2023)'s investigation into T2I representations of the Southeast Asian countries of India, Bangladesh and Pakistan. We extend this work by focusing specifically on Indian culture/subcultures, paying respect to their uniqueness within Southeast Asia and going against any suggestions of a regional monolith, and dive deeper into exploring how the depictions of cultures/-subcultures actively cause harms to individuals who identify with such cultures/subcultures."}, {"title": "3 Methods", "content": "To analyze how Indian culture and various subcultures are represented within generative Al systems, we conduct a set of community-centric focus groups with participants from these cultures. We chose focus groups instead of individual interviews to both mirror Qadri et al. (2023)'s study towards similar goals, and because such a method is known to be effective in empirically studying cultural contexts (Hughes and DuMont 1993; Rodriguez et al. 2011) where participants can collectively negotiate shared understanding of what 'culture' means to them (Huer and Saenz 2003).\nWe recruited participants through advertising the study through our social networks and postings in public places, inviting participation from individuals above the age of 18 and self-identifying as being Indian by virtue of growing up in India or not having lived outside of India for over 10 years. We successfully recruited 25 participants. Among these, 60% self-identified as female, while 40% self-identified as male. We asked participants which of the five regions of India (Northern, Eastern, Western, Southern, or Central) they self-identified as being from. Our study represents 4 participants from North India, 6 from East India, 5 from West India, 9 from South India, and 1 from Central India. We randomly sorted participants into five focus groups of 5 individuals each, and not grouping participants from similar regions to avoid groupthink bias where like-minded participants would only have shallow conversations (MacDougall and Baum 1997), with each focus group being conducted Oct-Dec 2023 by two researchers in accordance with best practices (Halcomb et al. 2007). We present participant distribution information in Table 1 (Appendix C), alongside assigned pseudonyms inspired by renowned literary figures from diverse cultural and subcultural backgrounds across India, to avoid numeric identifiers while still using culturally-appropriate names as opposed to Western pseudonyms commonly used. By using culturally meaningful pseudonyms, we avoid performing cultural erasure while respecting their anonymity as we highlight quotes throughout this paper.\nWithin each focus group, we began with providing participants with a survey soliciting examples of prompts for which they would like to see outputs from Stable Diffusion v2.1: a T2I which takes in text-based prompts to generate images. This version was selected due to its open-source nature, providing free access and flexibility to be used across various platforms with evidence and ability of usage as a sociotech"}, {"title": "3.1 Recruitment and Focus Group Descriptions", "content": "To analyze how Indian culture and various subcultures are represented within generative Al systems, we conduct a set of community-centric focus groups with participants from these cultures. We chose focus groups instead of individual interviews to both mirror Qadri et al. (2023)'s study towards similar goals, and because such a method is known to be effective in empirically studying cultural contexts (Hughes and DuMont 1993; Rodriguez et al. 2011) where participants can collectively negotiate shared understanding of what 'culture' means to them (Huer and Saenz 2003).\nWe recruited participants through advertising the study through our social networks and postings in public places, inviting participation from individuals above the age of 18 and self-identifying as being Indian by virtue of growing up in India or not having lived outside of India for over 10 years. We successfully recruited 25 participants. Among these, 60% self-identified as female, while 40% self-identified as male. We asked participants which of the five regions of India (Northern, Eastern, Western, Southern, or Central) they self-identified as being from. Our study represents 4 participants from North India, 6 from East India, 5 from West India, 9 from South India, and 1 from Central India. We randomly sorted participants into five focus groups of 5 individuals each, and not grouping participants from similar regions to avoid groupthink bias where like-minded participants would only have shallow conversations (MacDougall and Baum 1997), with each focus group being conducted Oct-Dec 2023 by two researchers in accordance with best practices (Halcomb et al. 2007). We present participant distribution information in Table 1 (Appendix C), alongside assigned pseudonyms inspired by renowned literary figures from diverse cultural and subcultural backgrounds across India, to avoid numeric identifiers while still using culturally-appropriate names as opposed to Western pseudonyms commonly used. By using culturally meaningful pseudonyms, we avoid performing cultural erasure while respecting their anonymity as we highlight quotes throughout this paper.\nWithin each focus group, we began with providing participants with a survey soliciting examples of prompts for which they would like to see outputs from Stable Diffusion v2.1: a T2I which takes in text-based prompts to generate images. This version was selected due to its open-source nature, providing free access and flexibility to be used across various platforms with evidence and ability of usage as a sociotech"}, {"title": "3.2 Thematic Analysis", "content": "We analyzed our focus group data through a constructivist grounded theory approach (Charmaz 2017), individually coding transcripts line-by-line in accordance with Charmaz (2006) to generate theories through inductive reasoning (Glaser and Strauss 1967; Glaser 1992). We conducted qualitative coding on the platform Taguette\u00b2, creating codes and associated definitions for transcript snippets, and later synthesizing them through discussion within the research team. The codebook will be made available upon publication."}, {"title": "4 Findings", "content": "In this section, we document our findings from the 5 focus groups, as we explicate the representational harms they observed with respect to Indian culture/subcultures. We note that 68% participants (17/25) indicated using GAI tools multiple times per week and a further 20% (5/25) using it at least once a month, underscoring participants' high familiarity with GAI tools. Participant usage of GAI tools was also in a wide range of cases, covering both text-based tools"}, {"title": "4.1 Exoticism within the Outputs of T2Is", "content": "A primary theme emerging from our focus groups was a novel type of harm within the outputs of T2Is which we label exoticism. While exoticized portrayals of India as 'distanced' from Western traditions (Sen 1997) under the larger umbrella of Orientalized perspectives of Asia within Western media (Said 1977) are well-established, we document how members of Indian communities perceive T2I tools exacerbating and perpetuating such portrayals through their outputs. We thus define exoticism within the outputs of T21 tools as \"the overamplification or overrepresentation of specific features or qualities of a culture in broad depictions of that culture, often at the cost of culturally-accurate details.\"\nA prominent way in which exoticism was present within the outputs of T2Is was in the depicted outfits of female-presenting Indians, as shown in the output for the prompt 'Middle-class Indian family' in Figure 1a. Aside from noting the strong heteronormativity present within all four image results within this output appearing to depict a male-presenting individual with a female-presenting individual, our participants also observed how the female-presenting individuals all appeared to be wearing sarees: a traditional Indian garment commonly worn within femme-identifying individuals. Participants were troubled with the implication that \"just because [they] said 'Indian', they're showing sarees? Because generally, middle class families don't always wear sarees\" - Arundhati, a concern which is compounded by the fact \"many men [are] wearing Western clothes, but not a single woman wearing them\" - Mamta. Such a strong prevalence of sarees is a common example of how the West perceives Indian women through their sarees (Benedict 2024; Arora and Sylvia 2023).\nThis depiction of Indian women in \u201ctraditional\" attire seemed impossible to shake off, as participants provided different prompts but the outputs kept showing sarees. For instance, the outputs for the prompt 'Indian people in Western attire' (Figure 5, Appendix A) still overwhelmingly depicted women in sarees, leading Arundhati to wonder: \"where is the Western attire??\" While outputs for the prompt 'Indian people in Suits' (Figure 6, Appendix A) showed suit jackets, it almost exclusively depicted male-presenting individuals and when participants expressly asked for 'Indian women in Suits' (Figure 7), they were once again entirely shown sarees. Kamala noted that the model's reliance on majority datasets leads to the perpetuation of harmful notions, stating, \"The model is showing these kinds of images because"}, {"title": "4.2 Cultural Misappropriation within the Outputs of T2Is", "content": "Through our analysis of participant responses, we observe the emergence of a novel type of harm within the outputs of T2Is: cultural misappropriation. While the concept of 'misappropriation' is most commonly used in the context of external forces such as colonial or imperial powers taking or using aspects of a culture to which they do not belong, we define cultural misappropriation within the outputs of T2Is as \"the depiction of details about a culturally-specific context which incorrectly embeds details from one culture or"}, {"title": "4.3 Documenting Representational Harms within T21 Outputs", "content": "Alongside the aforementioned evidence of the novel types of harm within T2I outputs, we also document evidence of participants identifying different types of representational harms as documented by Dev et al. (2020): stereotyping, disparagement, dehumanization, erasure, and quality of service. We particularly focus on instances where more than one of these occur concurrently.\nStereotyping and Erasure Dev et al. (2020) defined the harm of stereotyping as 'overgeneralized beliefs about the personal attributes of an individual as determined by their demographic group membership,' while erasure is 'the lack of adequate representation of members of a particular social group.' They note how these typically have a \u2018cyclical relation,' a phenomenon our participants also pointed to.\nOne aspects along which participants, across multiple focus groups, noted the harms of stereotyping and erasure was religion, as Stable Diffusion outputs seemed to depict visuals commonly assosciated with Hinduism. Participants such as Satyajit, Arundhati, and Vikram noted that the outputs for 'festivals of India' (Figure 3a) featured the bright colors, flower-knit garlands, festive marks on depicted individuals' foreheads, and other attire and jewelry consistent with Hindu festivals. Missing in these representations was any evidence or visuals prominent in Islamic, Christian, Buddhist, or Sikh festivals, to name a few excluded religions. The erasure of other religions is also evident in outputs around 'Indian weddings', which prominently feature Hindu marriage rituals and visuals such as ornaments and attire, and omit representations of Islamic wedding practices such as the 'nikkah' or the church altars of Christian weddings.\nThe prominence of visuals associated with Hinduism is not entirely unexpected, since almost 80% of India is Hindu (Chandramouli 2011). What is harmful is the fact that even within Hinduism, depictions seem to only feature Hindu festivals prominent in Northern India, which only accounts for about 28% of India's population (Chandramouli 2011). Surya Kumar, a participant from the South Indian state of Kerala, noted that outputs did not \"reflect any festival that we celebrate in the South.\u201d Birinchi Kumar and Satyajit also noted the absence of other Hindu festivals such as Durga Puja or Chhath Puja celebrated in Eastern India by almost 200 million people, and Pongal celebrated in Southern In"}, {"title": "5 Community-Driven Implications for Redesigning GAI Tools", "content": "Drawing upon our participants' experiences and prior work in the field, we provide some insights around culturally-informed design principles for GAI tools such as T2Is."}, {"title": "5.1 Valuing the Evolution of Cultures", "content": "One of the primary themes across our participants' observations was how outputs embedded a sense of Indian culture that was either entirely inaccurate or, at the very least, reflective of an India from years gone by. As Arundhati stated \"[the set of outputs] is very outdated, and not 2024,\" calling for a more accurate and updated representation of Indian culture and subcultures beyond stereotypical representations from a \"Western idea that's being portrayed for India, if so I think that should be changed\" - Kamala. Participants reasoned that while some of the exoticist and culturally misappropriated depictions of India were likely accurate to what Indian culture/subcultures looked like at one point of time, such representations are no longer as synonymous to Indian-ness as these outputs might lead someone to believe. Indeed, they pointed to the fact that \u201ca search engine results like Google Search [is] more representative of the Indian culture than what this is\" - Anita, implying that the excuse of a digital absence of comparably accurate representations or any other data to compare with for models to be moot.\nIt is a central feature of culture that it changes and grows with time, with participants negotiating and renegotiating meanings of norms and objects (Hall 1989, 1997b). While representations may originate from foundational depictions and create stereotypes which tend to endure (Hamilton 1997), these too must change as the passage of time and the evolution of a culture ascribes novel meaning to artefacts. This is especially true for colonized countries such as India as 'Indian culture' today has an indelible imprint of its colonizers, and efforts to segregate which aspects of modern culture came from where might be fruitless (Foster 1988). Shedding depictions of a community heavily colored by colonial pasts requires a decolonial perspective: an \"additive-inclusive approach, which continues to use existing knowledge, but in ways that recognises explicitly the value of new and alternative approaches, and that supports environments in which new ways of creating knowledge can genuinely flourish.\u201d (Mohamed, Png, and Isaac 2020) Our findings reveals a clear need for such an approach to overhauling representations of Indian culture within T2Is.\nThis overhaul will likely not be easy: the volume of data on the Internet that depicts India through a Western lens is quite significant, and despite the effects of globalization, there likely still are segments of the global population that"}, {"title": "5.2 Honoring Heterogeneity within Cultures", "content": "However, as our participants demonstrated, Indian-ness is not a singular identity: there exist various subcultures with distinct features and traditions grounded in centuries of historical context. Our findings are full of instances where such diversity is homogenized, such as Satyajit's remarks that \"[the output is] not capturing region-specific phenomena or region-specific features, [and] that's a drawback.\" Any efforts to depict Indian-ness within T2I model outputs must honor the heterogeneity and diversity of India. We align ourselves with Qadri et al. (2023) in calling for stronger community-centered approaches towards designing T2I tools, and similarly advocate for the involvement of epistemic experts in the design process. Indian people are experts on their Indian-ness, and community-centered practices of data collection and annotation are an important step towards reducing harm within the outputs of T2I tools (Gadiraju et al. 2023).\nHowever, asking individuals to be experts or representatives of a culture/subculture also has its own flaws, the chief of which is the fact that this ask risks performing the same homogenization that this paper finds fault in. Our participants recognized this dichotomy, and offered other ways of honoring heterogeneity within Indian culture. One such approach was the proposed fine-tuning of models for specific cultures/subcultures, instead of advertising them for widespread use. Participants noted that in trying to access a larger market, GAI tools risked causing harm to a wide group of users and losing a customer base. Taking inspiration from GAI tools such as Lesan, a machine translation tool and chatbot for Ethiopian languages which promises stronger results than tools from the Google Suite or ChatGPT (Deck 2023), we advocate for stronger support and providing resources for designers of GAI tools for specific contexts, embedded within the culture they are trying to serve. At the bare minimum, as models continue to homogenize depictions of Indian-ness, participants suggested that"}, {"title": "5.3 Accuracy and Cultural Sensitivity", "content": "In analyzing behaviours of sociotechnical GAI models representing Indian subcultures, participants identified a unique facet related to model behavior diverging from expected actions, particularly concerning the given prompts. These deviations affect the model's accuracy within the lens of machine learning. The model creates erroneous responses based on the inputs, portraying them as factual wherein it was completely against what was asked for. An example of this phenomenon occurred when participants prompted the generation of images depicting Indian women separately in Western attire, modern wear, or non-traditional clothing. Despite these specific prompts, the model consistently generated images of women in traditional sarees, contrary to expectations. These examples highlight the need for GAI tools to accurately interpret and respond to prompts. Participants emphasized the need for AI models to generate contextually appropriate responses that align with the prompt, demonstrate multilingual understanding by moving beyond weak transliterations and acknowledging diverse linguistic and cultural contexts, and avoid generating harmful or wrongful content.\nIn response to the concerns and recommendations outlined, we have developed a comprehensive set of guidelines for creating culturally sensitive AI models, as shown in Figure 4. These guidelines, presented in detail in the Appendix B, provide a framework for developers and researchers to consider and adhere to, ensuring that their models prioritize cultural understanding, accuracy, and inclusivity. These considerations are rooted in our findings around Indian culture/subculture, but are structured to be adaptable for any cultural group's use. The recommendations ensure that GAI systems are designed with a deeper understanding of the cultural contexts and nuances that shape user interactions."}, {"title": "6 Discussion", "content": "In this paper, we structure our narration around sociotechnical AI systems, exploring their impact on social and technical actors within specific ecosystems. These systems, exemplified by the widespread use of technical models like NLP and computer vision in social domains such as education and policy-making, often operate as opaque 'black boxes' (O'neil 2017). This lack of transparency means that many users need to be made aware of the underlying mechanisms and decision-making processes of these models, leading to instances of discrimination in social contexts. Recognizing this, our research was motivated by the need for a community-based study focused on generative AI models released and sociotechnical system for public consumption.\nAs the focus group progressed, a clear consensus emerged among participants: the current state of text and image generation models is inadequate and often harmful. The models' outputs were frequently deemed toxic, hateful, stereotypical, or outright wrong, reflecting a post-colonial and Western viewpoint that failed to resonate with the community. This disconnect is not surprising, given the historical and ongoing impact of colonialism on people's identities, as highlighted by (Das et al. 2024). There appears to be 'branded diversity through tokenism' (Stevens 2022) when it comes to representation of the Indian cultural context. The perpetuation of biases through sociotechnical systems is a critical concern. Our study reveals how these systems can amplify harmful stereotypes, contributing to a cycle of cultural misappropriation and erasure. The participants' desire for better results is not just a call for technical improvement but also a demand for more inclusive and culturally sensitive AI systems.\nOur work addresses a significant gap in the field by centering a Global South context, taking away the focus from Westernized sites of study and lenses of examining harm, to explore cultural harm and its nuances within various subcultures (Sambasivan et al. 2021a). We use the case study of India, an especially relevant context given a rising concern around Al-mediated harms there, as GAI-generated deepfakes are being used to garner votes in elections from viewers who are largely unaware of such videos being synthetically generated (Raj 2024). However, our novel harms of exoticism and cultural misappropriation can be further expanded to the contexts of Global South and other contexts not centered in GAI design. This possibly applies the"}, {"title": "7 Limitations", "content": "One limitation of our work is that even though we present evidence on the erasure of certain Indian subcultures in generative AI results, we do not prominently feature voices in this study of people identifying with those subcultures, in that we only have one participant identifying from North-eastern India and no Muslim participants. This is an unfortunate consequence of recruitment practices and response to our offers, and a deliberate decision to not specifically seek out users of any particular identity within our target population so as to avoid introducing researcher bias into our data and to not ask marginalized users to perform their marginalization for our extractive research purposes. We also present evidence of participants labeling human faces depicted within Stable Diffusion outputs as appearing to be from specific parts of India, such as the North. While we respect those inferences since they are rooted in participants' positionalities and lived experiences within their cultural context, we note the possibility of readers disagreeing with classifications based on their own perceptions of what it means for someone to 'look' a particular type of Indian."}, {"title": "8 Conclusion", "content": "Our work highlights the pressing issue of cultural harms within GAI, particularly in non-Western contexts such as India. Through community-centric research that engages with diverse Indian communities, we identified novel forms of representational harm, exoticism and cultural misappropriation on top of the existing harms (Dev et al. 2020). We propose design principles prioritizing cultural diversity, and respect to mitigate the perpetuation of harmful misrepresentations. By building upon existing advocacy for ethical GAI design in non-Western contexts and drawing parallels with similar challenges faced by other cultures, our work contributes to showcasing the importance of cultural awareness and sensitivity in the development of AI technologies."}, {"title": "9 Positionality Statement", "content": "We situate ourselves within this research by acknowledging our own positionalities, which shape our perspectives and biases (Haraway 1988). The three co-authors of this paper researchers identify as being born and brought up in India, having spent their formative years in India, and the fourth author identifies as a second-generation Indian. The fifth author identifies as an American of Bulgarian-Turkish origin, having spent half of their life in the United States. Although all authors currently reside in the United States, our collective goal and research efforts focus on investigating biases related to identity in global, multilingual, and culturally inclusive language technology. Our focus on critical HCI, marginalized communities, and ethnolinguistic groups drives our exploration and collaboration. Through all our prior experience, we bring both understandings of non-western contexts and experiences while also recognizing our privileged positions within academia in the Global North."}, {"title": "10 Ethical Consideration", "content": "Our research into the representations of non-Western cultures within Generative Artificial Intelligence outputs, specifically Text-to-Image models, focusing on Indian cultural contexts, is guided by the commitment to ethical considerations and the impact they can have on the community of focus. We recognize the potential impacts of GAI tools on cultural narratives and identities and conduct our work in a manner that respects the dignity, diversity, and complexity of cultural representations. We prioritize cultural respect, avoiding harm through biased or misrepresentative outputs, and inclusivity by engaging diverse voices and perspectives. Our methodologies are transparent and accountable, and we empower communities to participate in discussions about AI ethics and fairness. Moreover, we adopt a community-centric research approach, prioritizing participant experience and enabling communities to lead and drive the conversation, structuring a more ethnographic approach to our results. We have made our study's research materials publicly available\u00b3 to promote transparency and facilitate further research. Our intention is to encourage additional investigation and build upon our findings, ultimately"}, {"title": "11 Adverse Impact Statement", "content": "By focusing on the representation of non-Western cultures, specifically Indian culture, the project exposes critical issues related to biased outputs and cultural misappropriation within AI-generated content. The identified harms, including exoticism and cultural misappropriation, highlight significant challenges in ensuring fair and accurate representations of diverse cultural contexts. The project's findings reveal the inherent biases embedded within GAI systems, which can perpetuate stereotypes, misrepresentations, and cultural erasure. These biases not only undermine the richness and complexity of non-Western cultures but also contribute to broader societal issues such as marginalization and stereotyping. Furthermore, the persistence of exoticist portrayals and cultural misappropriation underscores the systemic nature of these biases within AI technologies. Such adverse impacts can have far-reaching consequences, influencing how individuals perceive and interact with different cultures, perpetuating harmful stereotypes, and reinforcing power imbalances. Addressing these adverse impacts requires a concerted effort from researchers, developers, and policymakers to prioritize ethical considerations, mitigate biases, and ensure responsible AI development and deployment. Failure to address these issues may result in continued harm, perpetuation of stereotypes, and exacerbation of cultural inequalities, ultimately hindering the potential benefits of GAI tools for diverse global communities."}]}