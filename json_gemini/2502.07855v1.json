{"title": "Vision-Language Models for Edge Networks: A Comprehensive Survey", "authors": ["Ahmed Sharshar", "Latif U. Khan", "Waseem Ullah", "Mohsen Guizani"], "abstract": "Vision Large Language Models (VLMs) combine visual understanding with natural language processing, enabling tasks like image captioning, visual question answering, and video analysis. While VLMs show impressive capabilities across domains such as autonomous vehicles, smart surveillance, and healthcare, their deployment on resource-constrained edge devices remains challenging due to processing power, memory, and energy limitations. This survey explores recent advancements in optimizing VLMs for edge environments, focusing on model compression techniques, including pruning, quantization, knowledge distillation, and specialized hardware solutions that enhance efficiency. We provide a detailed discussion of efficient training and fine-tuning methods, edge deployment challenges, and privacy considerations. Additionally, we discuss the diverse applications of lightweight VLMs across healthcare, environmental monitoring, and autonomous systems, illustrating their growing impact. By highlighting key design strategies, current challenges, and offering recommendations for future directions, this survey aims to inspire further research into the practical deployment of VLMs, ultimately making advanced AI accessible in resource-limited settings.", "sections": [{"title": "I. INTRODUCTION", "content": "The integration of vision and language understanding in artificial intelligence has given rise to VLMs, which combine visual inputs with natural language processing to perform tasks such as image captioning, visual question answering, and visual content generation [1]-[4]. These models have demonstrated promising capabilities in various domains, from social media content moderation to assisting autonomous vehicle navigation, enabling machines to interact with their environment more intuitively and human-likely. Although VLMs offer many benefits, it is challenging to extend VLMs at the network edge. Extending VLMs to edge devices remains very challenging due to resource limitations of edge devices (e.g., smartphone and wearable). Edge devices, characterized by their limited processing power, memory, and energy consumption, require VLMs that are accurate but also lightweight and efficient [5], [6]. The challenges posed by these constraints necessitate innovative approaches to model design and optimization to ensure that VLMs can be effectively deployed on edge platforms [7].\nRecent studies have aimed to compress VLMs and use edge deployment with pruning, quantization, and Knowledge Distillation methods [8]. Pruning consists of removing redundant or insignificant parameters from the model, reducing the model's size and computational overhead while maintaining similar performance [9]. Quantization reduces the precision of model weights and activations, which can greatly impact memory usage and inference speed [10]. In knowledge distillation, knowledge from a large, cumbersome model (teacher) is distilled into a smaller model (student) [11]. Moreover, purpose-built hardware accelerators (e.g., Googles Edge TPU) and edge-native architectures have also played a crucial role in enhancing the accessibility in deploying VLMs on edge-constrained hardware [12], [13]. This survey highlights these advancements and presents a comprehensive overview of lightweight visual language models (VLMs) for edge applications, discussing the trade-offs involved in striking the balance between model efficiency and performance."}, {"title": "A. Motivation", "content": "The demand for real-time processing of visual tasks, for example, autonomous driving, smart surveillance, and augmented reality, is one of the primary reasons to deploy VLMs on edge devices [14]\u2013[16]. ITS, one of the crucial applications, includes object detection, traffic sign recognition, and pedestrian detection. Offloading this processing to the cloud incurs latency, impeding time-critical use cases. Likewise, edge processing in smart surveillance: Processing video features on edge devices (e.g., IP cameras) protects the privacy of target information by reducing private data transmission over networks [17]. Augmented reality applications also use low-latency processing to interact seamlessly. These applications are made possible by lightweight VLMs that guarantee high-performance resource usage at the edge [18]. Calculations performed closer to the data reduce latency and add reliability by reducing reliance on stable connections.\nThe use of VLMs on edge devices faces challenges. Current VLMs are unusually large and do not fit into the memory/storage of most edge devices. For instance, the GPT-3 model with 175 billion parameters demands about 350 GB for inference memory alone [19], while CLIP, a common VLM, has 63 million parameters [20], which is not appropriate for edge devices and other limited resources regions. These models require considerable hardware resources and energy, which is typically a limitation for low backup energy devices. Edge devices, including smartphones and Internet of Things (IoT) sensors, are typically equipped with a backup energy capacity of 1,000 mAh to 5,000 mAh [21], making it challenging to run power-hungry computations locally with these models. In addition, when such models perform inference, they may quickly consume the energy supplies of edge devices, restricting their operational time and efficiency [22]. Moreover, the computational complexity of these models often requires hardware accelerators (GPUs, TPUs, etc.), which may not be realistic for many edge computing applications due to cost and power availability [23]. Figure 1 shows an overview of using VLM in the IOT framework.\nWe address these issues with a balance of model complexities over resource allocations. Compromises in performance and accuracy are often required to balance model complexity against resource efficiency in addressing these issues. One specific type of low-resource VLMs is model compression methods, including pruning, quantization, and knowledge distillation, which can significantly decrease VLMs\u2019size and computational cost. However, this may result in a momentary drop in accuracy, which ought to be judiciously managed to make the model effective for the application [9]\u2013[11].\nThe second key issue comes from the devices' heterogeneity in computing power and local energy reserves. This variability adds complexity to the deployment process for VLMs, as the models must be tuned to the capabilities of each device. Some works, such as dynamic inference, have attempted this by scaling the network with respect to the computation available at inference, balancing resource use and accuracy [24], [25]. Model scaling, for instance, makes several models of different complexities so they can be deployed on edge devices with differing capabilities. Dynamic inference techniques can account for this by adjusting the computation at inference time and balancing speed and accuracy based on real-time resource availability.\nFurther research is, however, required to create solutions that are domain-agnostic and can be adapted to the different constraints of different edge environments. To facilitate edge-native VLM adoption, it is crucial to have these models work with reasonable efficiency over significant device variance with minor device specialization.\nFurthermore, optimizing VLMs for edge devices includes research on novel model architectures with lower computational requirements by design. One such adaptation, for example, is using transformer-based models that offer more efficient variants for edge deployment [26], [27]. These adaptations generally include simplifying the attention mechanisms or reducing the layers in the model to reduce computational overhead. In addition, there is a trend of using attention approaches and lightweight CNNs to achieve trade-offs between effectiveness and resources [28], [29]. To boost performance on mobile devices, MobileNetV3 is proposed with architectural innovations: depthwise separable convolutions that compress the number of parameters and the computations required [29]. These architectural advances play an important role in expanding the potential of what is possible with VLMs on edge devices, allowing more capable models to run within the constraints of simpler hardware.\nLightweight VLMs can have a variety of application domains that are growing rapidly. For instance, through VLMs, medical image analysis and diagnostics can be performed directly on portable devices, enabling immediate feedback and decision support [30], [31]. This capability is invaluable in remote or resource-poor environments where access to advanced medical care is restricted. Through visual recognition and language understanding capabilities, VLMs allow for next-generation inventory management and customer interaction in retail [32], [33]. For example, VLMs can examine smart shop assistants that identify and explain products in detail to customers seamlessly and grammatically. These models can have implications for multiple domains, showcasing the potential versatility of lightweight VLMs. VLMs cover a tremendous spectrum of applications, from driving efficiency in industries where real-time visual inspections can be automated through VLMs to enabling everyday experiences for those with disabilities by describing the contents of the camera stream captured in the real world."}, {"title": "B. Market Statistics and Research Trends", "content": "VLMs have rapidly emerged as a new market in recent years, fueled by the rising demand for intelligent systems that can understand and reason with both visual and textual information. The global AI market was valued at USD 58.3 billion in 2021, and it is expected to reach USD 309.6 billion by 2026, with a CAGR of 39.7% [42]. This segment of the VLM market is projected to grow at the most rapid rate. The overall VLM market is anticipated to grow significantly over the projection period. The global market size of VLMs is estimated to reach around $2.5 billion in 2024, increasing from $1.8 billion in 2023 and $1.2 billion in 2022 [43]. Why is everyone talking about it? Because VLMs find application in diverse sectors, including healthcare, automotive, and consumer electronics. For example, one of the factors driving the growth of the VLMs market is the adoption of VLMs to develop ADAS and autonomous driving solutions in the automotive industry. At the same time, with the increase in smart devices and the IoT, the need for lightweight VLMs that perform well on edge devices has become increasingly urgent.\nResearch trends in VLMs indicate a strong focus on enhancing model efficiency and accuracy while reducing computational overhead. Recent studies have explored various techniques for model compression, including pruning, quantization, and knowledge distillation [9]-[11]. Additionally, there is growing interest in developing new architectures that leverage the strengths of both CNNs and transformer models [26], [29]. These hybrid models aim to balance the computational efficiency of CNNs with the powerful representation capabilities of transformers. Another emerging trend is using multi-task learning frameworks, where a single VLM is trained to perform multiple related tasks, improving overall efficiency and reducing the need for task-specific models. Notably, the number of research papers published on VLMs and AI on edge devices has increased significantly, reflecting the growing academic interest in this field.\nThe applications of VLMs are expanding rapidly, with significant investments being made in sectors such as healthcare, retail, and security. In healthcare, VLMs are utilized for tasks such as medical image analysis, disease diagnosis, and telemedicine, providing real-time assistance to healthcare professionals [30], [31]. The retail sector is leveraging VLMs for enhanced customer experiences through smart shopping assistants and personalized marketing [32], [33]. Security applications include automated surveillance systems that can analyze and interpret visual data to detect anomalies and potential threats. These applications demonstrate the versatility and impact of VLMs across various industries, driving further research and development in this field. AI development on edge devices has become a critical area of focus due to the need for real-time processing, reduced latency, and improved privacy. Edge AI involves deploying AI models directly on devices such as smartphones, cameras, and IoT sensors, enabling local data processing without relying on cloud infrastructure [17]. This shift towards edge computing is driven by the limitations of cloud-based AI, including latency issues, bandwidth constraints, and data privacy concerns. Research in edge AI is focused on optimizing model architectures and developing"}, {"title": "C. Existing Surveys and Tutorials", "content": "Few surveys and tutorials have reviewed VLMs, their efficiency, and applications [34]-[41]. Table I summarizes some of this work Scopes and how it is different than ours. The authors in[34] focused on vision-language pre-trained models, discussing the evolution of these models, different architectures used, and methods for integrating vision and language modalities. Another work [35] explored vision-language intelligence, emphasizing tasks, representation learning, and the development of large models. They provided insights into the performance improvements and future research directions in this area. Xing et al. [36] surveyed efficient fine-tuning methods for vision-language models, focusing on Prompt and Adapter techniques. They discussed various strategies to enhance fine-tuning efficiency and addressed challenges related to efficient fine-tuning. Ghosh et al. [37] provided a comprehensive overview of the current methodologies and future directions of vision-language models, highlighting the strengths and limitations of existing approaches and suggesting areas for further exploration. Zhang et al. [38] surveyed vision-language models for vision tasks, discussing the theoretical foundations, practical applications, and identifying challenges and opportunities in applying these models in fields like medical imaging and industrial automation. Another survey [39] focused on multimodal large language models for autonomous driving, discussing the integration of different modalities, methodologies to enhance model performance, and specific applications in autonomous driving scenarios. Yin et al. [40] surveyed multimodal large language models with a focus on efficient design and diverse applications, covering architectures, strategies to enhance efficiency, and applications in fields like biomedical analysis and document understanding. Lastly, Jin et al. [41] provided a survey on efficient multimodal large language models, discussing methods to reduce computational costs, improve efficiency, and applications in areas like high-resolution image understanding and medical question-answering, highlighting future research directions and challenges in the field.\nDifferent from existing works [34]-[41], we present a comprehensive overview of VLMs, including key design aspects and high-level architecture. We also provide deployment challenges on edge devices. Furthermore, several open research challenges are discussed, along with promising solution approaches."}, {"title": "D. Our Survey", "content": "This survey aims to examine the techniques, architectures, and applications that define the rapidly evolving area of VLMs for edge networks. By addressing the challenges and showcasing the solutions, this paper contributes to the ongoing efforts to make sophisticated VLMs accessible and practical for edge computing environments. The continued innovation in this field promises to unlock new capabilities and applications, bringing the power of AI-driven vision and language understanding to a broader range of devices and use cases. Our survey aims to answer the following questions:\n\u2022 How do we efficiently enable VLM at the network edge?\n\u2022 What are the existing schemes and their limitations that will help deploy VLM at the network edge?\n\u2022 How does one enable secure and privacy-ware VLM?\n\u2022 What are the challenges and their possible solutions in allowing VLMs to at the network edge?\n\u2022 What are the different application domains for VLMs, and what opportunities are available?\nOur contributions are summarized as follows:\n\u2022 We present the key concepts, main design aspects, and high-level architecture for Vision-Language Models.\n\u2022 A comprehensive cycle for extending the VLMs from the cloud to the edge is provided, considering efficient training and fine-tuning methods, edge deployment challenges, and privacy and security issues. We consider issues related to designing efficient VLMs, deploying them on edge devices, addressing privacy and security concerns, and enhancing their performance on low-resource devices.\n\u2022 Several open challenges are presented, including the difficulties of deploying VLMs on edge devices and fine-tuning them with limited resources. Moreover, we discussed about promising solution approaches."}, {"title": "II. FUNDAMENTALS OF VISION LANGUAGE MODELS", "content": "VLMs are designed to process and integrate visual and textual information simultaneously. These models leverage the combined power of computer vision and natural language processing to perform various multimodal tasks such as image captioning, visual question answering (VQA), and image-text retrieval. This section provides a detailed theoretical understanding of how VLMs work, including their mathematical representation and model architectures."}, {"title": "A. Key Concepts", "content": "They learn to align visual and textual modalities in a shared representation space, enabling cross-modal understanding and interaction. This process is a series of steps per modality (text and image) of tokenization, embedding, and encoding. In doing so, VLMs are able to model rich semantic interactions both within a single modality and cross-modality as one unified feature that connects image, text, and sound representations, improving downstream tasks like captioning, retrieval, and question answering.\nText Representation\nAssuming a text input sequence $T = [t_1, t_2,...,t_n]$ where each $t_i$ is the i-th token, the representation for T can be obtained through tokenization and embedding. Steps in the Flow: Each token $t_i$ is mapped to a high-dimensional word"}, {"title": "B. Mechanisms for Vision-Language Interaction", "content": "At the center of VLMs is the integration of textual and visual embeddings. There are two main architectures to achieve this fusion and dual encoders. Fig. 2 illustrates the key dissimilarity between the two Architectures.\nSingle-Stream Architecture (Fusion Encoders):\nIn contrast, single-stream models do early fusion by interleaving visual and textual encodings into a single sequence fed through a common encoder often, a transformer [50], [51]. This architecture relies on the assumption that a single transformer encoder can adequately model the interactions among the modalities. This means that the language and image tokens are tokenized and embedded and then combined into one sequence the model processes them together, having the ability to learn visual and textual attributes at the same time. This approach encodes the two modalities using this common representation, which can help efficiently model the intricate relationships and interactions between them. In the single-stream framework, text embeddings $h_i$ and image embeddings $v_j$ are concatenated and processed through a transformer [50], [51]:\n$z_k = Transformer([h_1, h_2, . . ., h_N; v_1, v_2, . . ., v_M]).$ (4)\nA single model that can perform all tasks is usually a huge benefit because the implementation is much simpler and more efficient. They reduce memory and potential inference times by using one encoder instead of two, simplifying the architecture. Moreover, such a unified approach becomes a powerful tool for tasks demanding rich interaction between text and image, like image captioning and VQA. This has been evidenced by models like ViLT [52], which utilize a vision-and-language transformer without convolutional or region-based supervision and still perform strongly.\nHowever, the single-stream approach has its problems, too, such as the increasing computational burden as longer sequences have to be concatenated and processed, which can be computationally intensive. In addition, the model has to learn from both modalities simultaneously, resulting in potentially non-ideal performance."}, {"title": "Dual-Stream Architecture (i.e., Dual Encoders)", "content": "On the other hand, dual-stream models adopt independent encoders for both visual and textual data, encode each modality separately, and then join their representation either through cross-attention mechanisms or other approaches. This architecture is especially useful when each input modality has limited overlapping features and can be processed differently. These independent processing streams are then merged in a higher-level step (usually through a cross-modal attention mechanism) that allows the model to learn how the modalities interact with each other after being processed and encoded independently. Treating individual modality streams with flexible structures provides full flexibility and may lead to more robust performance, as the model can capture and preserve the unique characteristics of each modality before combining them. Text and image embeddings are processed independently and later merged in the dual-stream architecture [53]\u2013[55]:\n$h' = TextEncoder(h_i),$ (5)\n$v' = ImageEncoder(v_j),$ (6)\n$z_k = CrossAttention([h'_1, . . ., h'_N], [v'_1,..., v'_M]).$ (7)\nThe most notable are dual-stream models, such as ViLBERT [54] and LXMERT [55], which use separate transformers for image and text. This is especially useful for tasks in which the relationships between the modalities are complex and need to be modeled in detail, such as VQA and image-text retrieval. Because each stream can process and encode its own domain separately, dual-stream models may outperform single-stream models on tasks requiring deep, specialized processing of images and text.\nHowever, this method can be computationally complex in terms of having more than one set of encoders and an additional step for the integration (often requiring some kind of sophisticated attention mechanism to align the modalities effectively)."}, {"title": "C. Efficient Fine-Tuning Methods for Vision-Language Models", "content": "Proper fine-tuning mechanisms are critical when adapting large-scale VLMs to downstream tasks with limited computational budgets. Due to their effectiveness in alleviating resource burden related to retraining and full fine-tuning of large models, these techniques have become increasingly popular. This section describes a few diverse lines of research on efficient fine-tuning that emerged in recent years, centering on the topics of prompt-based methods and adapter-based methods.\n1) Fine-tuning with Prompts: Their methodology for practicing a specific task with few parameter updates is to shape the input in such a way as to activate the pre-trained models capacity, known as prompt-based fine-tuning methods.\na. Prompt Tuning: Creating prompts to prompt the model to produce task-appropriate outputs. Prompts can be hard (discrete text) or soft (continuous vectors). Hard prompts refer to fixed text templates that you include in your input; soft prompts are the continuous embedding of learned vectors injected into your input sequence. CoOp (Context Optimization) and CoCoOp (Conditional Context Optimization) apply learnable soft prompts to enhance the adaptability of the model across varied image recognition tasks [57], [58].\nb. Prefix Tuning: Prefix tuning introduces continuous task-specific vectors (prefixes) to the input of each transformer layer. These prefixes act as virtual tokens, guiding the model's attention mechanism. Lester et al. demonstrated that prefix tuning could achieve competitive performance with minimal additional parameters by adding prefixes to the transformer layers without modifying the original model weights [59].\nc. P-Tuning: P-tuning extends prompt tuning by using a trainable prefix of virtual tokens that guide the model to focus on task-relevant information. This method is particularly effective in few-shot learning scenarios, where it significantly improves the model's performance with limited data [60].\nd. Prompt Tuning for Vision-Language Models: Techniques like DenseCLIP and ProDA have been developed to extend prompt tuning specifically for vision-language tasks. These methods use prompt-based learning to align visual and textual features more effectively, achieving performance comparable to full fine-tuning [61], [62].\n2) Adapter-Based Fine-Tuning: Adapter-based methods introduce lightweight, task-specific modules into the pre-trained model, allowing efficient adaptation without full model fine-tuning.\na. Adapter Modules: Adapters are small feed-forward networks inserted between the layers of the pre-trained model. They enable task-specific learning by adjusting only the adapter parameters while keeping the original model weights frozen. Houlsby et al. demonstrated that adapter modules could achieve performance comparable to full fine-tuning with significantly fewer trainable parameters [63].\nb. LoRA (Low-Rank Adaptation): LoRA reduces the number of trainable parameters by decomposing the weight updates into low-rank matrices. This method allows efficient adaptation of large models with a minimal computational footprint. Hu et al. showed that LoRA could achieve substantial parameter efficiency while maintaining high performance on various downstream tasks [64].\nc. Parallel Adapter Networks: Parallel adapters introduce additional parallel pathways in the transformer architecture, allowing for efficient multi-task learning. Pfeiffer et al. proposed AdapterFusion, which combines multiple adapter modules trained on different tasks, enabling the model to leverage shared knowledge across tasks [65].\nd. Task-Specific Adapters: Techniques like VL-Adapter and Clip-Adapter have been developed to provide efficient task-specific fine-tuning for vision-language tasks. These adapters are designed to handle the unique requirements of multimodal data, improving performance while minimizing computational costs [66], [67].\ne. Hybrid Methods: Some recent approaches combine prompt-based and adapter-based methods to leverage the advantages of both. APoLLo (Adaptive Prompt Learning) integrates prompts and adapters to achieve efficient and robust fine-tuning for vision-language models [56]."}, {"title": "D. Existing VLM Models", "content": "Vision-language models have advanced significantly in recent years, offering capabilities that span across various domains such as image classification, autonomous driving, UI understanding, and more. Table II shows a comparision between some of the lightweight VLMs, where here we discuss some of the available VLMs, especially those lightweight:\nViTamin is a vision-language model for scalable applications emphasizing image classification and open-vocabulary detection. It uses a Vision Transformer (ViT) base and the CLIP framework, achieving improved zero-shot performance on ImageNet while remaining small. ViTamin processes large datasets, making it suitable for visual recognition tasks and automatic visual description [83].\nLINGO-2, developed by Wayve, extends vision-language-action models for autonomous driving. It combines visual input, natural language, and action sequences to generate driving behaviors and textual commentaries, increasing explainability. Using a multimodal encoder-decoder architecture, the lightweight 5-billion-parameter model achieves real-world and simulation-capable performance [84].\nInstructBLIP advances vision-language modeling through instruction tuning, transforming datasets into instruction-following formats. Built on BLIP-2, it surpasses prior state-of-the-art in tasks like question-answering and image captioning, using a Query Transformer for improved adaptability and performance [85].\nRAVEN integrates a base VLM with retrieval-augmented frameworks for general-purpose vision-language tasks, excelling in VQA and captioning. Its CLIP-based encoder and transformer decoder enable fine-tuning without retrieval-specific parameters, supporting diverse multimodal applications [86].\nScreenAI focuses on understanding UIs and infographics through a multimodal encoder-decoder framework. Extending PaLI and incorporating pix2struct's patching strategy, it excels in UI navigation, question-answering, and summarization, leveraging annotated screenshots and infographics [87].\nALLAVA uses synthetic data from GPT-4V, employing a captioning-then-QA pipeline with a pre-trained vision encoder and small language model. Fine-tuning on synthesized datasets improves comprehension and reduces hallucinations, achieving strong performance with fewer parameters [79].\nXmodel-VLM, a lightweight vision-language model for consumer devices, pairs a CLIP ViT-L/14 visual encoder with Xmodel-LM 1.1B, achieving low computational cost and competitive performance on benchmarks [76].\nMobileVLM V2, optimized for mobile devices, incorporates a Lightweight Downsample Projector (LDPv2) to reduce visual tokens and speed up inference. Its MobileLLaMA architecture excels in fast, reliable multimodal processing [68]. Figure 4 illustrates the basic model architecture of mobile VLM.\nLightVLP adopts the Gated Interactive Masked AutoEn-coder architecture for lightweight pre-training. Its multimodal encoder aligns visual and textual inputs efficiently, enabling high-quality outputs with fewer parameters [75].\nEM-VLM4AD, designed for VQA in autonomous driving, combines multi-view image embedding with a gated pooling attention mechanism and a scaled-down T5 language model. It achieves strong performance in perception and planning tasks [77].\nThe lightweight VLMs discussed show efficiency and specialization but face challenges in robustness, adaptability, and"}, {"title": "III. VLMS FOR EDGE NETWORKS", "content": "Edge devices form an important layer in the IoT architecture and are stationed at the periphery of a network. This allows for real-time insights as they process, store, and compute data locally, transferring less data to potential server farms for processing. The main reasons to deploy edge devices are to deal with lower latency (reduced response time, less significant temporal variability), less usage of data bandwidth, and improved data privacy (sensitive data handling locally) [89].\nThere are conventional edge devices and intelligent edge devices. Examples of regular edge devices are routers and switches that control the flow of data between the networks with low computation power [90]. On the contrary, intelligent edge devices (e.g., IoT gateways and smart cameras) have richer processing abilities to accomplish machine learning inference or data analytics tasks [91]. Mobile devices employ hardware such as System-on-Chip (SoC), Graphics Processing Units (GPUs), and specific processors, making it easier to run complex algorithms on less power [92].\nBelow are the key features of edge devices:\n\u2022 On-Premises Processing: Local data can be processed at the edge to facilitate rapid data analysis, computation, and feedback without relying on external cloud systems [93].\n\u2022 Autonomy and Low Latency: These devices provide autonomous decision-making abilities, which are highly necessary for use cases such as self-operated vehicles and manufacturing [94].\n\u2022 Higher Security and Privacy: Data processed at the edge limits exposure of sensitive information, resulting in a higher level of data security and privacy [90].\n\u2022 Versatile: Edge devices can be used for a diverse range of applications, including smart cities, industry monitoring, healthcare, and consumer electronic applications [95].\nEdge devices have specific technical characteristics depending on the application. SoCs are very much used in the IoT gateways for effective data processing between balanced computational time and energy efficiency. On the other hand, for heavy computing tasks, such as real-time image processing in smart cameras, GPUs or special processors like Application-Specific Integrated Circuits (ASICs) may be used [92]."}, {"title": "A. Existing Low Complexity VLMs", "content": "IoT is a network of devices that connect to the internet to collect, transmit, and analyze data. These may include sensors, smart appliances, wearables, and industrial devices. With the combination of IoT systems with advanced technologies such as Large Language Models (LLMs) and VLMs, sophisticated applications have been achieved, enabling automation, decision-making, and user interaction. In contrast, IoT systems generally consist of three essential layers: perception layer, network layer, and application layer [93], [94]. Sensors and actuators responsible for data collection and control actions are also part of the perception layer.\nData Network Layer: Securing communications between devices and centralized systems, the network layer makes sure that the data can be sent from one device to another or to a centralized system and is often based on protocols such as Wi-Fi, Bluetooth, or LPWAN. Here, the application layer operates over wired or wireless mediums to process and analyze the data to provide useful insights and services to end users [93], [94].\nVLMs are models that combine visual understanding with human-like text generation or understanding to enhance the human-machine IoT interaction experience. The integration of LLMs and VLMs has also resulted in Generative IoT (GIoT) systems, which support the automation of complex tasks, enrich user interactions, and enable real-time decisions [96], [97].\nMany papers and models have been developed to run VLM on edge devices. EdgeVL is a novel framework designed to adapt large VLMs for edge devices by leveraging dual-modality knowledge distillation and quantization-aware contrastive learning. Fig.5 illustrates how the model focuses on efficiently aligning features from RGB and non-RGB images without manual annotation, making it versatile for various visual modalities. EdgeVL achieves up to a 15.4% improvement in accuracy and a 93-fold reduction in model size, which is crucial for deployment on resource-limited devices. The model's design allows for a streamlined adaptation process, where a student encoder is trained to mimic a large, pre-trained teacher model like CLIP, ensuring high-quality feature extraction despite the reduced model size [88].\n\u2022 Moondream2: Moondream2 is an open-source, lightweight vision-language model (VLM) optimized for mobile and edge devices. With 1.8 billion parameters, it requires under 5GB of memory, making it deployable on low-cost, single-board computers such as Raspberry Pi. Its architecture is designed for efficiency, enabling real-time image recognition and understanding capabilities. This model is suitable for applications such as security and behavioral analysis, showcasing its utility in low-resource environments [98].\n\u2022 VILA (Visual Language) model: VILA focuses on pre-training techniques optimized for efficient edge deployment. The model employs interleaving data and instruction fine-tuning to maintain high performance while reducing computational demands. It is adaptable to various hardware, including devices like Jetson Orin. VILA also emphasizes multi-modal pre-training, enhancing in-context learning and multi-image reasoning capabilities [99].\n\u2022 Mobile VLM V2: Building upon the MobileLLaMA series, MobileVLM V2 emphasizes lightweight design for edge deployment. It introduces a novel Lightweight Downsample Projector (LDPv2) that improves vision-language feature alignment with minimal parameters. This approach involves pointwise and depthwise convolutions, along with a pooling layer to compress image tokens. MobileVLM V2 achieves significant reductions in model size and computational requirements, making it ideal for real-time applications on resource-constrained devices [68].\n\u2022 EDGE-LLM: EDGE-LLM is a framework designed to adapt large language models for efficient deployment on edge devices. It addresses computational and memory overhead challenges through techniques like efficient tuning and memory management. This model supports"}, {"title": "B. Deployment of VLMs on Edge Devices", "content": "In order to deploy the VLM model on edge devices, several important steps are required to achieve efficient deployment. These steps (as shown in Fig. 6) include:\n1) Data Selection and Pre-processing: Pre-processing data effectively is crucial for optimizing performance, particularly when dealing with heterogeneous data distributed across various edge devices. The process begins with Data Collection, where diverse data types such as images, text, and other relevant formats are gathered from multiple sources. The collected data must be segmented to ensure efficient processing across different environments, categorizing the data into Edge-Appropriate Data and Cloud-Appropriate Data. Edge-appropriate data generally consists of smaller, less complex datasets that can be processed in real-time on edge devices using lightweight models, while cloud-appropriate data involves more complex or sensitive information that necessitates extensive computational resources available in cloud environments [102], [103].\nThe next phase is Feature Extraction and Selection. During this step, relevant features are extracted from the raw data, enabling the child model on the edge device to process it efficiently. Feature selection determines which features should be processed locally and which should be sent to the cloud for further analysis, often using heuristics or lightweight models to assess data importance or complexity [104], [105].\nTo optimize further, Data Compression techniques minimize the bandwidth required for data transmission between edge and cloud. Standard methods include quantization, dimensionality reduction, and image compression. Local pre-processing on edge devices also helps reduce the volume of data transmitted, enhancing system efficiency [103], [104]. Advanced methodologies such as Asynchronous Aggregation and Cluster Pairing introduce an intermediate layer of edge servers between clients and the cloud, aggregating local models asynchronously to reduce communication overhead and speed up convergence. This method is effective in managing system heterogeneity [104]. Another approach is using Bioinspired Computing (BIC) algorithms, like Particle Swarm Optimization (PSO) and Genetic Algorithms, which address challenges in federated learning (FL), such as communication costs and system heterogeneity. These algorithms optimize resource allocation and data partitioning, ensuring relevant and manageable local processing [103]. Synchronous-Asynchronous Hybrid Update Strategy combines synchronous and asynchronous updates to mitigate staleness effects caused by Non-IID data, integrating local updates with global synchronization to enhance model accuracy and reduce idle times [104]. These pre-processing strategies are essential for enhancing the efficiency and performance of federated learning models in distributed, resource-constrained environments."}, {"title": "2) Model Choice on Edge and Cloud", "content": "Performing better when one tries to deploy models on edge or cloud must involve a thoughtful choice as a tradeoff between performance and resources. Deciding where to process information is influenced by the computational capacity of edge devices, task complexity, and the need for real-time processing, among others.\nEdge-Appropriate Models are lightweight models meant to work under low computational power constraints. These models should also be computationally less expensive and, therefore, capable of performing inference in real-time on more straightforward tasks. Examples include MobileNet and SqueezeNet, which have fewer parameters and optimized architecture for low-power environments [106], [107].\nCloud-Appropriate Models, on the other hand, refer to deeper and resource-heavy architectures such as ResNet-50, BERT, as well as other large transformer-based architectures that require a considerable amount of computing resources to maintain but offer improved accuracy and broader analysis capabilities when processed from cloud environments [108], [109].\nCloud-native models can also be very complex and resource-intensive. Larger models designed for advanced tasks need high computational power and significant memory resources. These models include ResNet-50, BERT, or even larger transformer architectures, which require more resources than are suitable for edge execution but can achieve better accuracy and more profound analysis when executed in cloud environments [108], [109]."}, {"title": "Compression Techniques", "content": "Various model compression techniques enable deploying more complex models on resource-constrained edge devices by reducing model size and computational requirements without significantly compromising performance. Fig. 7 summarizes these techniques. These techniques include quantization, model compression, and knowledge distillation, among others. In Quantization, the precision of weights and activations is reduced from 32-bit floating-point to lower-bit representations (e.g., 16-bit or 8-bit integers), drastically reducing model size and computational overhead"}]}