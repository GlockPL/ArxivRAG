{"title": "Zero-Shot Image Moderation in Google Ads with LLM-Assisted\nTextual Descriptions and Cross-modal Co-embeddings", "authors": ["Enming Luo", "Wei Qiao", "Katie Warren", "Jingxiang Li", "Eric Xiao", "Krishna Viswanathan", "Yuan Wang", "Yintao Liu", "Jimin Li", "Ariel Fuxman"], "abstract": "We present a scalable and agile approach for ads image content\nmoderation at Google, addressing the challenges of moderating\nmassive volumes of ads with diverse content and evolving policies.\nThe proposed method utilizes human-curated textual descriptions\nand cross-modal text-image co-embeddings to enable zero-shot\nclassification of policy violating ads images, bypassing the need for\nextensive supervised training data and human labeling. By leverag-\ning large language models (LLMs) and user expertise, the system\ngenerates and refines a comprehensive set of textual descriptions\nrepresenting policy guidelines. During inference, co-embedding\nsimilarity between incoming images and the textual descriptions\nserves as a reliable signal for policy violation detection, enabling\nefficient and adaptable ads content moderation. Evaluation results\ndemonstrate the efficacy of this framework in significantly boosting\nthe detection of policy violating content.", "sections": [{"title": "1 INTRODUCTION", "content": "Google's advertising platform handles a massive volume of ads\ndaily. To maintain user trust and platform integrity, every ad must\nbe reviewed for policy violating content before it can reach the\npublic. Ads content moderation at this scale presents a formidable\nchallenge given the dynamic nature of online ads and evolving pol-\nicy guidelines. Traditional ads content moderation approaches rely\nheavily on supervised machine learning models and human label-\ning [3] and often struggle to keep up with the volume, diversity and\never-changing nature of ads content and policy guidelines. This pa-\nper introduces a scalable and agile ads content moderation solution\ndesigned to address these challenges at Google. Our approach uti-\nlizes text-image co-embeddings to achieve zero-shot classification"}, {"title": "2 PROPOSED METHOD", "content": "We propose a user-centric approach where domain experts, with the\nassistance of LLMs, create detailed textual descriptions that encom-\npass the policy space. These descriptions are then transformed into\ncross-modal co-embeddings, capturing their semantic relationship\nwith images. During inference, incoming ads images are compared\nagainst these textual descriptions based on co-embedding similar-\nity, facilitating efficient policy violation detection. Specifically, the\nmethod comprises three key components."}, {"title": "2.1 Generation of Textual Descriptions", "content": "Our approach leverages LLMs to generate a rich and varied set of\ntextual descriptions, which comprehensively captures the different\nmodes of a given policy. We also empower users with domain\nexpertise to craft their own textual descriptions, enhancing the LLM-\ngenerated output. Figure 1 illustrates how users can generate textual\ndescriptions. Users can provide policy language, their own expertise,\nor guidance from a subject matter expert to craft descriptions. They\ncan also leverage an LLM to uncover previously unrecorded \"blind\nspots\" by asking for additional suggestions. The LLM generates\nsuggestions and assists in breaking down a complex policy into"}, {"title": "2.2 Validation of Textual Descriptions", "content": "While most crafted textual descriptions are accurate, some might\ninadvertently misalign with the given policy. These can cause false\npositives, undermining the precision of the zero-shot classification\nmodel. To mitigate this, our system presents users with a selec-\ntion of closely related images retrieved from existing datasets for\neach textual description. Leveraging their domain expertise and\nthe visual context provided, users evaluate and label each descrip-\ntion as either \"in-scope\" (aligned with the policy) or \"out-of-scope\"\n(misaligned with the policy).\nTo further refine the labels of the textual description set, we\nemploy a secondary validation step. The labeled descriptions are\nmatched against a corpus of known ads images with ground-truth\nlabels for the given policy. In-scope descriptions that frequently\nmatch out-of-scope images are flagged as potentially problematic\nand subsequently removed. Similarly, out-of-scope descriptions that\nfrequently match violating images are flagged and removed. This\ntwo-step approach ensures a high-quality set of textual descriptions,\nboosting the accuracy and reliability of our zero-shot classification\nmodel. Ultimately, we obtain both \"in-scope\" and \"out-of-scope\"\ntextual descriptions for each policy."}, {"title": "2.3 Policy Enforcement", "content": "We employ a multi-stage approach leveraging cross-modal co-\nembeddings and the power of advanced multi-modal LLMs (illus-\ntrated in Figure 2).\n\u2022 Cross-modal co-embedding and matching: The labeled\ntextual descriptions are transformed into co-embeddings.\nEach incoming ads image is also embedded into the same\nsemantic space. A fast approximate kNN search [1] is per-\nformed to compare the ads image with every description.\n\u2022 Automated decision: If the image matches more in-scope\ndescriptions than out-of-scope descriptions by a predeter-\nmined margin, it is automatically flagged as a policy violation.\nConversely, if it matches more out-of-scope descriptions than\nin-scope descriptions by the same margin, it is considered\npolicy compliant.\n\u2022 LLM review: Images that match some textual descriptions\nbut do not fall into the clear-cut categories for automated"}, {"title": "3 RESULTS", "content": "As an example, we conducted experiments on tobacco images to\nevaluate our approach's ability to detect tobacco-related image con-\ntent. The metrics, based on human reviews, are defined as follows:\n\u2022 Precision: The percentage of the true positives (TPs) among\nthe ads labeled as positive by a model.\n\u2022 Incremental Coverage Significance: The percentage in-\ncrease in TPs identified by a model, relative to the TPs already\nidentified by another model.\n\u2022 Relative recall: The percentage of the TPs labeled by a\nmodel among all TPs labeled by all models.\nThe comparison between this approach and an existing binary\nclassification model on an internal dataset is shown as below."}, {"title": "4 ADVANTAGES OF THIS APPROACH", "content": "Our approach offers several advantages for content moderation\ncompared to other approaches:\n\u2022 Minimal training data is required. The user can focus\nsolely on designing textual descriptions. While some data is\nneeded for the LLM and user to design textual descriptions, it\ndoesn't need a large-scale labeled dataset for model training.\n\u2022 Fast turnaround time No model training is needed, and\ntextual description design allows for faster iteration from\ndefinition to launch.\n\u2022 Resource efficiency. The same workflow can be used for\nmultiple policies with one scalable search."}]}