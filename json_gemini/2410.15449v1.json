{"title": "Heterogeneous Graph Reinforcement Learning for Dependency-aware Multi-task Allocation in Spatial Crowdsourcing", "authors": ["Yong Zhao", "Zhengqiu Zhu", "Chen Gao", "En Wang", "Jincai Huang", "Fei-Yue Wang"], "abstract": "Spatial Crowdsourcing (SC) is gaining traction in both academia and industry, with tasks on SC platforms becoming increasingly complex and requiring collaboration among workers with diverse skills. Recent research works address complex tasks by dividing them into subtasks with dependencies and assigning them to suitable workers. However, the dependencies among subtasks and their heterogeneous skill requirements, as well as the need for efficient utilization of workers' limited work time in the multi-task allocation mode, pose challenges in achieving an optimal task allocation scheme. Therefore, this paper formally investigates the problem of Dependency-aware Multi-task Allocation (DMA) and presents a well-designed framework to solve it, known as Heterogeneous Graph Reinforcement Learning-based Task Allocation (HGRL-TA). To address the challenges associated with representing and embedding diverse problem instances to ensure robust generalization, we propose a multi-relation graph model and a Compound-path-based Heterogeneous Graph Attention Network (CHANet) for effectively representing and capturing intricate relations among tasks and workers, as well as providing embedding of problem state. The task allocation decision is determined sequentially by a policy network, which undergoes simultaneous training with CHANet using the proximal policy optimization algorithm. Extensive experiment results demonstrate the effectiveness and generality of the proposed HGRL-TA in solving the DMA problem, leading to average profits that is 21.78% higher than those achieved using the metaheuristic methods.", "sections": [{"title": "I. INTRODUCTION", "content": "THE advent and widespread adoption of smart devices and 5G technology have facilitated the extensive development of Spatial Crowdsourcing (SC) [1]-[6], attracting attention from both academic and industry. Different from traditional crowdsourcing [7], SC requires workers to arrive at the specific spatial and temporal location to participate and complete tasks. To facilitate the SC campaign, tasks are usually collected and allocated periodically by the platforms. These tasks can range from simple and straightforward activities like delivering food [8], [9] or capturing images of landmarks [10], [11], to more intricate campaigns that require the collaborative efforts of workers with diverse skills, such as holding a wedding [12], repairing the house [13], and refereeing a sports game [14].\nTo tackle the problem of complex spatial task allocation, several studies concentrate on matching a group of workers possessing the requisite skills essential for complex tasks [15], [16]. Nevertheless, workers are often scarce, making it challenging to assemble a group of workers that fulfills all the skills needed for complex tasks. Therefore, the decomposition-based methods have been utilized in some research, wherein complex tasks are decomposed into multiple subtasks (or stages) with different skill requirements. These subtasks are then assigned independently to suitable workers [14], as shown in Fig. 1. For example, the complex task like house repairing can be divided into repairing the main body, installing electronic components and pipe systems, tiling the floor, and finally cleaning the rooms [13]. It is noteworthy that in this case, the subtask of repairing the main body must be completed prior to any other subtasks, while the subtask of cleaning the rooms typically follows the completion of all other subtasks. This exemplifies a common reality where dependency constraints often arise among subtasks resulting from complex task decomposition. Therefore, the Dependency-aware Task Allocation (DTA) problem has gained increasing attention. In this problem, dependency relationships among subtasks are formulated as constraints and recent works have provided solutions for both the offline and online versions of this problem [12]\u2013[14]. However, these works predominantly employ a single-task allocation mode, in which each worker is assigned only one task once. Under this mode, if a worker desires to undertake multiple tasks for increased profitability, they are required to wait and engage with the platform over several rounds of allocations. Given that both tasks and workers are typically time-sensitive, the single-task allocation may result in suboptimal utilization of workers' limited work time, as shown in Fig. 1.\nIn contrast, multi-task allocation have been investigated by many studies as a more effective model, where multiple tasks are assigned to workers within each time slot, allowing for high utilization of workers' limited work time [17], as shown"}, {"title": "II. RELATED WORKS", "content": "This section provides a comprehensive review of the relevant literature in this paper, primarily encompassing task allocation in spatial crowdsourcing and graph reinforcement learning for spatial crowdsourcing.\nA. Task Allocation in Spatial Crowdsourcing\nThe task allocation problem, which involves recruiting a group of workers to complete a set of tasks, is one of the fundamental topic in SC. Previous studies have predominantly formulated this problem as an optimization problem, considering various optimization objectives and constraints [29]\u2013[33]. The objectives encompass maximizing task completion, increasing profitability, and reducing costs, among others. Additionally, constraints are typically considered from perspectives such as time, cost, privacy protection, and the matching of worker skills with tasks. In recent years, some studies have begun to focus on task allocation problems with dependency constraints [12]\u2013[14]. Ni et al. [14] initially integrated multiple tasks with dependencies into an associative task set, which was subsequently treated as a complex task and assigned to a group of workers for completion. Besides, Liu et al. [12] investigated the Multi-Stage Complex Task Assignment (MSCTA) problem, which involves decomposing complex tasks into multiple dependent subtasks and allocating separate workers to each subtask. They devised a greedy algorithm and a game-theoretica algorithm for efficiently assigning the most profitable workers to these subtasks and achieved a provably approximate solution. Yao et al. [13] studied an On-line Dependent Task Allocation (ODTA) problem, taking into account spatial worker preferences. To maximize profits, they developed a threshold-based algorithm within the adversarial order model and achieved a near-optimal theoretical bound on the competitive ratio. However, these research has primarily focused on single-task allocation, which is suboptimal in scenarios where multiple tasks can be handled by a worker.\nTo fully utilize workers' limited work time, the multi-task allocation problem has been investigated in recent years, leading researchers to propose diverse solutions from various perspectives. Zhang et al. [34] proposed a improved evolu-tionary algorithm to solve the multi-task allocation problem to maximize the task completion, taking into account the daily routes of workers. Besides, Liu et al. [18] proposed a new minimum cost maximum flow model to solve the multi-task allocation problem efficiently. The genetic algorithm is widely utilized for optimizing the allocation of multiple tasks to workers, aiming to maximize the platform's utility or enhance task quality of service [17]. Moreover, an particle swarm optimization technique-based method was proposed by Estrada et al. [35], which aims to maximize the ratio of aggregated quality of information to budget. Shen et al. [20] investigated a heterogeneous multi-project multi-task allocation problem based on the group collaboration mode, and proposed a multi-objective fireworks algorithm with dual-feedback ensemble learning framework to sovle the problem. However, most of these studies overlooked the dependencies among tasks.\nIn this paper, we take into account the dependencies among tasks (or subtasks) and multi-task allocation, while employing the HGRL-based approach to address the problem.\nB. Graph Reinforcement Learning for Spatial Crowdsourcing\nThe effectiveness of Deep Reinforcement Learning (DRL) in solving sequential decision-making problems has been well-established, and in recent years it has been successfully integrated with Graph Neural Networks (GNNs) to address combinatorial optimization problems [36]\u2013[38]. GNNs are deep learning models inherently designed to generalize over graphs of different sizes and structures, enabling the Graph Reinforcement Learning (GRL) approach to learn and gen-eralize across diverse network topologies [39]. For instance, Song et al. [27] demonstrated that the GRL method exhibits computational efficiency and outperforms traditional priority dispatching rules on the flexible job-shop scheduling problem, even when dealing with larger-scale instances and diverse properties not encountered during training. Moreover, Xu et al. [40] integrated a dedicatedly designed graph attention network into DRL to solve an multi-task allocation problem. Specifically, a homogeneous graph model is employed to represent the problem state, that is, worker and task nodes are represented by a same set of features, and edges between nodes are only characterized by the distance. However, the utilization of HGNNs becomes essential when the problem involves heterogeneous nodes or edges, as it enables a com-prehensive representation of the problem state by incorporating rich semantics and structural information [41].\nThe use of HGNNs has expanded to various tasks, including node classification, edge predictions, and analysis in domains like social networks, recommendation systems, and knowledge graph inference. [42]\u2013[45]. The meta-path-based methods are extensively employed in HGNNs to capture the structural information of the same semantic and subsequently integrate diverse semantic information. Initially, neighbor features are aggregated at the scope of each meta-path to generate semantic vectors, which are then fused to produce the final embedding vector [46]. The DMA problem addressed in this paper involves heterogeneous nodes and multiple relationships between these nodes, making it well-suited for resolution using HGNNs. However, to our knowledge, HGNN has not yet been applied to task allocation issues in spatial crowdsourcing. Therefore, this paper is the first to apply HGNN to the DMA problem and introduces a compound-path-based method, which demonstrates superior performance compared to the Meta-path-based method in addressing the DMA problem."}, {"title": "III. SYSTEM MODEL AND PROBLEM FORMULATION", "content": "In this section, we present the main definitions and the for-mulation of the DMA problem. For clarity, the main notations are summarized in Table I.\nDefinition 1 (Heterogeneous worker). At a time slot, the spatial crowdsourcing platform collects a set of workers $U =$"}, {"title": "A. System Model", "content": "{U1, U2,... Un}. Each worker $u \\in U$ can be characterized by a tuple of several attributes, i.e., $u = [l^{u}, \\tau^{a},\\tau^{w}, \\rho, S^{k}_{u}]$. The $l^{u}$ denotes the initial location of the worker, while the $[\\tau^{a}, \\tau^{a} + \\tau^{w}]$ is the work time window. The $\\rho$ represents the movement speed of the worker, while the $S^{k}_{u}$ is a set of skill that the worker has mastered.\nDefinition 2 (Task and dependency-aware subtask). At a time slot, the spatial crowdsourcing platform collects a set of tasks $P = {P1,P2,...pm}$. Each task $p\\in P$ consists of several subtasks (or stages), i.e., $p = {v1, v2, ... vl}$ and each subtask $v \\in p$ can be characterized as $v = [l^{v}, t^{s}, t^{e}, t^{p}, b, S^{k}_{v}, D]$. The $l^{v}$ is the location of the subtask, while the $[t^{s}, t^{e}]$ is the valid time window. To motivate workers to complete tasks, each subtask provides a budget $b$. In addition, the completion of each subtask requires a specific amount of time $t^{p}$ and can only be achieved by a worker who possesses at least one of the required skills in $S^{k}_{v}$. Besides, the subtasks contained in a task are dependent, implying that the execution of the subtask $v$ can only occur once all its dependent subtasks in the set $D$ have been completed. The dependency set of the subtask $v_{k}$ can be denoted as $D(v_{k}) = {v1, v2, . . . vk\u22121}$. For clarity, the set of all subtasks is represented as $V = {v1, v2, ... vml}$, where ml is the total number of subtasks.\nDefinition 3 (Multi-task Allocation). The worker on the platform is willing to undertake multiple subtasks, provided that they possess the requisite skills and sufficient time. Therefore, for each worker $u \\in U$, the platform will allocate several subtasks to he/she and the multi-task allocation is represented as $< u, V_{u} >$, where $V_{u} = {v^{1}_{u}, v^{2}_{u},... v^{o}_{u}}$ denotes the set of assigned subtasks and o is the number of assigned subtasks. Upon receiving the multi-task allocations, workers will launch from their initial location and move to the assigned subtasks' location to complete them sequentially. The start time of a subtask $v$ is denoted as $\\tau^{b}(v)$, which is not only determined by the time that the worker arrives the subtask, but also depends on the completion time of the subtasks in its dependency set. Specifically, the start time of the subtask $v \\in V_{u}$ is calculated as:\n$\\tau^{b}(v) = max (f_{r} (D(v)), f_{v} (u, v))$ (1)\nwhere the $f_{r} (D(v))$ represents the latest completion time of the subtasks in the dependency set $D(v)$, and the $f_{v} (u, v)$ denotes the arrive time of worker u for the subtask v. They are calculated as follows:\n$f_{r} (D(v)) = \\begin{cases} max_{v' \\in D(v)} (b(v') + \\tau^{p}(v')) \\\\  ta(u) + \\rho(u) \\cdot f_{D} (l_{u} (u), l_{u} (v)), i = 1 \\\\ f_{u} (u, v) = b(v^{i-1}) + \\tau^{p}(v^{i-1})+ \\rho(u) \\cdot f_{D} (l_{u} (v^{i-1}), l_{u} (v)), i > 1  \\end{cases}$ (2)\n$f_{u} (u, v) = \\begin{cases}  ta(u) + \\rho(u) \\cdot f_{D} (l_{u} (u), l_{u} (v)), i = 1 \\\\ b(v^{i-1}) + \\tau^{p}(v^{i-1})+ \\rho(u) \\cdot f_{D} (l_{u} (v^{i-1}), l_{u} (v)), i > 1  \\end{cases}$ (3)\nIn Eq. 3, the $f_{D} (.)$ denotes the distance function between the two input locations, whereas in this paper, we employ the Euclidean distance in the function. When all assigned subtasks in $V_{u}$ are completed by the worker u, the platform will receive payment as a profit denoted by:\n$f_{p} (V_{u}) = \\sum_{v_{u} \\in V_{u}} b(v_{u})$ (4)"}, {"title": "B. Problem Formulation", "content": "Based on the system model, the DMA problem is defined and formulated here.\nDefinition 4 (DMA problem). Given a set of heterogeneous workers $U = {U1, U2, ... Un}$ and a set of dependency-aware subtasks $V = {v1, v2,... vml}$, the spatial crowdsourcing platform needs to implement the multi-task allocation for each worker as $< u, V_{u} >$ where $V_{u} \\subset V$. The objective of the DMA problem is to maximize the overall profit of the platform, taking into account various constraints such as dependencies, skill matching, and time window limitation. Therefore, the DMA problem can be formulated as a combinatorial optimization problem:\n$\\begin{aligned} &\\max_{V_{u}: V_{u} \\in U} \\sum_{u \\in U} f_{p} (V_{u}) \\\\ &s.t. t^{s}(v) <\\tau^{b}(v^{i}) \\leq t^{e}(v) - \\tau^{p}(v), \\\\ &\\forall v_{u} \\in V_{u}, \\forall u \\in U\\\\ &ta(u) \\leq \\tau^{b}(v), \\tau^{b}(v) + \\tau^{p}(v) \\leq ta(u) + tw(u), \\\\ &\\forall v, v' \\in V_{u}, \\forall u \\in U\\\\ &t^{s}(v') + \\tau^{p}(v') \\leq t^{s}(v_{u}), \\\\ &\\forall v' \\in D(v_{u}), \\forall v_{u} \\in V_{u}, \\forall u \\in U\\\\ &S^{k}_{u} (u) \\cap S^{k}_{u} (v_{u}) \\neq 0, \\forall v_{u} \\in V_{u},\\forall u \\in U\\\\ &V_{u} \\cap V_{u'} = \\varnothing, \\forall u, u' \\in U, u \\neq u'  \\end{aligned}$ (5)\n$t^{s}(v) <\\tau^{b}(v^{i}) \\leq t^{e}(v) - \\tau^{p}(v), \\forall v_{u} \\in V_{u}, \\forall u \\in U$ (6)\n$\\tau^{a}(u) \\leq \\tau^{b}(v),\\tau^{b}(v) + \\tau^{p}(v) \\leq \\tau^{a}(u) + \\tau^{w}(u), \\forall v, v' \\in V_{u}, \\forall u \\in U$ (7)\n$t^{s}(v') + \\tau^{p}(v') \\leq t^{s}(v_{u}), \\forall v' \\in D(v_{u}), \\forall v_{u} \\in V_{u}, \\forall u \\in U$ (8)\n$S^{k}_{u} (u) \\cap S^{k}_{u} (v_{u}) \\neq 0, \\forall v_{u} \\in V_{u},\\forall u \\in U$ (9)\n$V_{u} \\cap V_{u'} = \\varnothing, \\forall u, u' \\in U, u \\neq u'$ (10)\nEq. 5 is the goal of the problem. Eq. 7 and Eq. 6 demonstrate the time-window constraints of subtask and worker respec-tively. In Eq. 7, the $v^{1}$ and $v^{o}$ denote the first and the last subtasks in the set $V_{u}$. Eq. 8 represents the dependency constraints among subtasks, while Eq. 9 ensures that the worker has the requisite skills to execute the assigned subtasks. Eq. 10 restricts that each subtask can be completed only once.\nIt is difficult to find the optimal solution of the DMA problem due to the large solution space. In fact, we can prove that the DMA problem is NP-hard.\nTheorem 1. The DMA problem is NP-hard."}, {"title": "C. Illustrative Instance", "content": "We present an instance of the DMA problem that involves three complex tasks and three workers, with the three complex tasks decomposed into a total of six subtasks to be executed, as illustrated in Table II. The skill requirements for each subtask vary, and the workers possess diverse skills. Both workers and subtasks can involve multiple skills. The dependencies among subtasks can be determined based on the complex tasks they are associated with.\nThe data from the table is further transformed into a graph, as depicted in Fig. 2. In this graph, workers and subtasks are spatially distributed within a range, while the skill matching and dependency relationships are visually presented. Additionally, Fig. 2 (b) and (c) provide two solutions for the instance. Each worker sequentially performs the assigned subtasks along the path indicated in the figure, with corresponding travel times displayed for each segment. The start time $\\tau_{b}$ for each subtask is also provided, and the execution time for each subtask is uniformly set to 1.\nThe optimal solution successfully completes five subtasks and attains a total profit of 8. In contrast, the suboptimal solution only accomplishes four subtasks and yields a total profit of 6. The key disparity between these two solutions lies in the timely completion of subtask $v_{2}$ by worker $u_{2}$ in (b), enabling worker $u_{3}$ to undertake the more lucrative subtask $v_{3}$. Additionally, it is noteworthy that the execution of subtasks is dependent on the completion of their preceding subtasks, regardless of whether a worker arrives at the subtask location early. For example, in (b), worker $u_{2}$ reaches the location of subtask $v_{2}$ at timeslot 2, but $v_{1}$ has just started its execution. Consequently, $u_{2}$ must wait for the completion of $v_{1}$ before commencing $v_{2}$, resulting in an actual start time for $v_{2}$ as 3."}, {"title": "IV. METHODOLOGY", "content": "A. Heterogeneous Graph Reinforcement Learning-based Task Allocation\nThe overview of the proposed HGRL-TA framework is depicted in Fig. 3. HGRL-TA employs three specific compo-nents to determine the optimal decision at each iteration. First, the problem state is formulated based on the multi-relation graph. Subsequently, the proposed CHANet is employed to"}, {"title": "B. Multi-relation Graph", "content": "encode the graph. After that, the embedding is subsequently fed into the policy network to obtain decisions, while both the policy network and embedding network are concurrently trained using the PPO method. The details are presented in this section.\nThe MDP mainly consists of five elements (S, A, T, R, \u03c0). The state space and the action space of the MDP are denoted by S and A, respectively. The transition function T is utilized to facilitate the environment's transition to new states based on actions, while the reward function R provides the reward from state transition. The policy \u03c0 is employed to optimize the selection of actions from the action space in order to maximize long-term rewards.\nThe state in each step consists of the conditions of all the subtasks and workers, as well as the multiple relations among them. The detailed representation of the state and the corresponding transition function will be described based on the multi-relation graph model in the next section. In each step, an action a = (v, u) \u2208 A is taken, which is defined as a pair of a feasible worker and an incomplete subtask. The action means the subtask is assigned to the worker. Given the constraints stated in Eq. 7-10, not all subtask-worker pairs are valid at every step. Therefore, we employ an action masking process to filter out valid actions at each step, which also reduces the decision complexity. When the action a = (v, u) is selected, the worker takes a certain amount of time to travel and execute the subtask, while the platform receives the budget b(v) after the subtask is completed. Thus, we define the reward for taking the action as follows:\nr = b(v) \u2013 \u03b1 (\u03c1(u) \u00b7 fp(locu, lv (v)) + \u03c4\u03c1(v)) (11)\nwhere the \u03c1(u) \u00b7 fp(locu, lv (v)) represents the travel time of the worker to reach the subtask from his/her location locu. The locu can refer to either the initial location of the worker or the location of the previous subtask that was executed by the worker. The \u03b1 represents a constant that is utilized to account for the impact of the time consumed by worker on the reward. In addition, the policy network is utilized to select an action from a probability distribution over the set of valid actions at each step.\nThe utilization of heterogeneous graph models is prevalent in representing combinatorial optimization problems, owing to their efficient representation of multiple node types and relations within the problem. Additionally, these models offer a unified representation framework that accommodates instances with varying numbers of nodes. For DMA problem, worker and subtask can be processed as heterogeneous nodes since they has different features, while the skill matching and depen-dency constraints can be modeled as the edge with according semantic relation. Besides, the spatial relation among workers and subtasks is also taken into consideration, as it directly impacts the worker's ability to access subtasks and the time required for movement. Consequently, a multi-relation graph model is established to represent the DMA problem, consid-ering that there can be various types of relations between two nodes.\nTheoretically, given an instance of the DMA problem that contains a set of workers $U = {U1, U2, ... Un}$ and a set of subtasks $V = {v1, v2, ... vml}$, its state can be represented by a multi-relation graph $G = {U, V, E, Z}$. The U and V are the set of worker nodes and subtask nodes, respectively. The $\\mathcal{E}$ is the set of edge with a mapping function $\\psi: \\mathcal{E} \\rightarrow \\mathcal{Z}$, that is, each edge e \u2208 E is attached with a relation $z = \\psi(e) \\in \\mathcal{Z}$. In this paper, three types of relations are considered, i.e., zsm: skill matching, $z_{dp}$: dependent, and $z_{ad}$: adjacent. Therefore, there can be multiple edges between two nodes and the edges with different semantic relations exist independently.\n1) Edge representation: For the worker node u and subtask node v, there is an edge with relation zsm between them when the worker has the skill required by the subtask, i.e., $S^{k}_{u} (u) \\cap S^{k}_{u} (v) \\neq \\varnothing$. As for the edge with relation $z_{dp}$, it exists between every subtask node that belongs to the same task. On the one hand, the execution of a subtask depends on the completion of its predecessor subtask. On the other hand, the successor subtasks of a subtask are related to the long-term"}, {"title": "C. Compound-based Heterogeneous Graph Attention Network", "content": "reward of the execution of the subtask. Besides, the edge with relation zad can occur between any two nodes, as long as the distance between them is less than a certain threshold.\n2) Node representation: In the multi-relation graph model, each node can be represented by a set of raw features. Two types of heterogeneous nodes are represented using different features that encompass both static and dynamic characteris-tics. Specifically, we represent raw features of each worker node as $x^{u} = [x^{u}_{1},x^{u}_{2},...x^{u}_{7}]$, where $x^{u}_{1}$ - $x^{u}_{3}$ denotes the dy-namic features of the worker, which are continuously updated throughout the sequential decision-making process. The $x^{u}_{1}$ denotes the available time for the worker, which is the moment when the worker joins in the platform or completes the predecessor subtask. The $x^{u}_{2}$ and $x^{u}_{3}$ are the two-dimensional location. The $x^{u}_{4}$ represents the number of accessible subtasks that the worker can complete under various constraints, while $x^{u}_{5}$ denotes the total budget of these accessible subtasks. The $x^{u}_{6}$ is the profit that has obtained by the worker. The $x^{u}_{4}$ and $x^{u}_{7}$ are static features that represent the worker's speed and expire time, respectively.\nMoreover, raw features of each subtask node can be repre-sented as $x^{v} = [x^{v}_{1}, x^{v}_{2},...x^{v}_{8}]$, where $x^{v}_{1}$-$x^{v}_{6}$ denotes dynamic features. The $x^{v}_{1}$ is a Boolean variable used to represent the status of the subtask, where $x^{v}_{1} = 1$ indicates that the subtask has been assigned, and $x^{v}_{1} = 0$ indicates that the subtask has not been assigned. The $x^{v}_{2}$ represents the start time of the subtask, and in cases where the subtask has not been assigned, we assign it a value of a significantly large constant. The $x^{v}_{3}$ represents the number of workers capable of completing the subtasks and the $x^{v}_{4}$ indicates the number of incomplete subtasks within the dependency set of the subtask. The $x^{v}_{5}$ signifies the total budget for all incomplete subtasks that belong to the same task. This reflects the future profits associated with the subtask. The $x^{v}_{7}$-$x^{v}_{8}$ represents static features, specifically the two-dimensional location, budget, and deadline of the subtask.\n3) Graph Update: The status and start time of subtask v are updated when it is assigned to worker u. Subsequently, the available time of the worker is updated to the completion time of the subtask, and the location of the worker is set to match that of the subtask. The worker's ability to complete other subtasks is then evaluated based on their new location and available time, and the remaining dynamic features for both the worker and the subtask nodes are updated accordingly. Additionally, it is necessary to update the edges with relation Zad among nodes due to the change in location.\nThe CHANet customized for the DMA problem is proposed in this paper, and the embedding process based on CHANet is presented in Algorithm 1. First, various meta-paths with distinct semantics are integrated into compound-paths during the pre-processing stage (Line 1-3). Subsequently, a two-stage node embedding process is employed to acquire the node embedding (Line 4-8). Finally, the state and action embeddings are derived from transforming the node embeddings through graph embedding (Line 9-10)."}, {"title": "C. Compound-path integrating:", "content": "The meta-path-based method is a prominent category within the field of HGNNs, which finds extensive application in tasks such as node classification and link prediction. The meta-path-based approach utilizes meta-paths to establish high-level semantic connections between two nodes, subsequently performing the neighbor fusion to aggregate the neighbor information of the same semantic within each meta-path and then integrating diverse semantic information, as illustrated in Fig. 4(b). Theoretically, a meta-path defines a composite relation of several relations and nodes in the forms of $N^{s} = N_{n1n2...nsq}$ which denotes a directed q-hop relation from the source node $n_{s}$ to the target node $n_{t}$. Furthermore, the meta-path-based neighborhood is represented as $N_{P}$, which contains all nodes connected with the target node via the meta-path P.\nIn this paper, the one-hop meta-paths encompass multiple relations, allowing for different one-hop meta-paths to connect two given nodes. For instance, a worker node u may be connected with other nodes via three types of meta-path that are denoted as $P^{uu} =  \\\\_ {z_{ad}} u', P^{uv} =  \\\\_ {z_{ad}} v$, and $P^{uv} =  \\\\_ {z_{sm}} v$, where u' \u2208 U and v \u2208 V. Similarly, a subtask node v may be connected with other nodes via four types of meta-path that are denoted as $P^{vu} =  \\\\_ {z_{ad}} u, P^{vv} =  \\\\_ {z_{ad}} v', P^{vu} =  \\\\_ {z_{sm}} u, and $P^{vv} =  \\\\_ {z_{dp}} v'$, where u \u2208 U and v' \u2208 V. Therefore, there are total seven types of meta-path considered in this paper.\nThe performance of downstream tasks, such as node clas-sification and link prediction, typically relies solely on the final representation of the target node or edge that requires classification or prediction. Hence, in scenarios where multiple meta-paths exist between two nodes, employing a meta-path-based approach can facilitate more nuanced semantic informa-tion propagation, thereby leading to enhanced performance in these tasks. However, for task allocation problems such as the DMA, the downstream task relies on the representation of each node (i.e., selecting from all worker-subtask pairs). Therefore, instead of considering meta-paths as the fundamental unit of feature aggregation, it is more appropriate to regard nodes as"}, {"title": "Algorithm 1 State and Action Embedding based on CHANet.", "content": "The CHANet customized for the DMA problem is proposed in this paper, and the embedding process based on CHANet is presented in Algorithm 1. First, various meta-paths with distinct semantics are integrated into compound-paths during the pre-processing stage (Line 1-3). Subsequently, a two-stage node embedding process is employed to acquire the node embedding (Line 4-8). Finally, the state and action embeddings are derived from transforming the node embeddings through graph embedding (Line 9-10).\nInputs:Heterogeneous graph $\\mathcal{G} = {\\mathcal{U},\\mathcal{V},\\mathcal{E}, \\mathcal{Z}}$, embedding round K\nOutputs:Embedding vectors of state $h_{s}$ and action $h_{a}$\n1: Obtain raw features of compound-paths\n2: Obtain compound-path-based neighborhoods of each node\n3: Project raw features of nodes and compound-paths to obtain their initial vector\n4: for $k$ = 1: $K$ do\n5:  for $\\mathcal{u} \\in \\mathcal{U}$ do\n6:   Update $h_{u}$ according to Eq. 15\n7:  for $\\mathcal{u} \\in \\mathcal{V}$ do\n8:   Update $h_{v}$ according to Eq. 16\n9: Construct the state embedding $h^{s}$ according to Eq. 17\n10: Construct the action embedding $h^{a}$ according to Eq. 18\n11: Return"}, {"title": "2) Two-stage node embedding:", "content": "This paper adopts a two-stage node embedding method and utilizes the graph attention network to perform feature aggregation of neighboring nodes [27]. The architecture of CHANet is illustrated in Fig. 5. The embedding process of worker nodes and subtask nodes is performed iteratively for K rounds, similar to previous studies employing the two-stage embedding approach, in order to obtain the final vector representation hk for each node. The raw features of both nodes and edges are projected to the same dimension $\\Lambda$ through linear transformations to form the initial vector before embedding: $h^{u}_{0} = w_{u}x^{u}, h^{v}_{0} = w_{v}x^{v}, h^{uu} = w^{uu} \\chi^{uu}, h^{uv} = w^{uv}\\chi^{uv}, h^{vv} = w^{vv}\\chi^{vv}$, where the $w_{u} \\in R^{\\Lambda \\times 8}, w_{v} \\in R^{\\Lambda \\times 9}, w^{uu} \\in R^{\\Lambda}, and w^{uv},w^{vv} \\in R^{\\Lambda \\times 2}$ are trainable weights of linear transformations.\nFor the worker node u, it has two compound-path-based neighborhoods Nuu and Nuv, comprising numerous nodes that may have different importance to u. Therefore, the Graph At-tention neTwork (GAT) is employed to aggregate the neighbor features of the same node type within each compound-path, leveraging the attention mechanism to automatically learn their respective importance. Specifically, given the vector $h^{t}$ of target node, the vector $h^{s}$ of source node in the neighborhood $N_{ts}$, and the vector $h^{ts}$ of their compound relation, the attention coefficient between the two nodes can be calculated as:\n$e_{ts} = elu (a^{T} \\cdot w_{e} cat(h^{t},h^{s},h^{ts}))$ (12)\nwhere $a \\in R^{\\Lambda}$ and $w_{e} \\in R^{3\\Lambda \\times 1}$ are the trainable weight of linear transformation. The elu(.) is the activation function and"}, {"title": "Algorithm 2 Training process based on PPO.", "content": "cat(.) is the short-hand of the concatenation function. Then the coefficients are normalized across the neighborhood using softmax function:\n$\\alpha_{ts} = \\frac{exp(e_{ts})}{\\sum_{n_{s'} \\in N_{ts}} exp(e_{ts'"}]}