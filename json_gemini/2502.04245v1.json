{"title": "TriNER: A Series of Named Entity Recognition Models\nFor Hindi, Bengali & Marathi", "authors": ["Mohammed Amaan Dhamaskar", "Rasika Ransing"], "abstract": "India's rich cultural and linguistic diversity\nposes various challenges in the domain of\nNatural Language Processing (NLP),\nparticularly in Named Entity Recognition\n(NER). NER is a NLP task that aims to\nidentify and classify tokens into different\nentity groups like Person, Location,\nOrganization, Number, etc. This makes\nNER very useful for downstream tasks like\ncontext-aware anonymization. This paper\ndetails our work to build a multilingual\nNER model for the three most spoken\nlanguages in India Hindi, Bengali &\nMarathi. We train a custom transformer\nmodel and fine tune a few pretrained\nmodels, achieving an F1 score of 92.11 for\na total of 6 entity groups. Through this\npaper, we aim to introduce a single model\nto perform NER and significantly reduce\nthe inconsistencies in entity groups and tag\nnames, across the three languages.", "sections": [{"title": "Introduction", "content": "The term \"named entity\" was first introduced\nduring the sixth Message Understanding\nConference [1], where the objective was to identify\nnames of individuals, locations, and organizations\nin text, later extending to include temporal and\nnumerical expressions. Since then, named entity\nrecognition (NER) has advanced to encompass\nfine-grained NER, which identifies subcategories\nwithin entities [2], and nested NER, which detects\nentities embedded within others [3]. In the last few\nyears, there has been significant progress in this\ndomain, including varied approaches to perform\nNamed Entity Recognition ranging from the use of\nConditional Random Fields (CRF) and Long\nShort-Term Memory (LSTM) to Embeddings from\nLanguage Models (ELMo), and Transformer\nmodels. However, Transformer models\nconsistently outperform other approaches for NER,\nas outlined in [4] and [5], and due to this reason, we\nfocus on using them for our efforts.\nThe work in NER is rapidly growing, but only a\nsmall subset of this progress encompasses Indian\nregional languages. While the past few years have\nproduced various gold standard datasets and\nassociated models, they suffer from inconsistencies\nin the targeted entity groups. Additionally, the\npresence of separate models for each language\nleads to inefficiencies in use and increased\ninference costs. To counter this, there are a few\nmultilingual NER models as well, but most of them\nonly recognize Person, Location & Organization.\nThis paper outlines our effort to overcome these\nchallenges and inconsistencies to develop a\nmultilingual NER model for Hindi, Bengali &\nMarathi. Our choice of language is driven by the\npresence of high-quality datasets and the fact that\nthese languages are the 3 most spoken languages of\nIndia. We also define a common set of 6 entity\nclasses to ensure consistency across languages. We\ndiscuss the steps involved in data curation,\nimplementation of the models and evaluation\ntechnique and results used."}, {"title": "Related Work", "content": "In the context of Named Entity Recognition, a\nsubstantial body of literature addresses the task\nacross various languages and domains. This\nsection, however, focuses specifically on reviewing\nexisting studies related to Hindi, Marathi, and\nBengali.\n[5] outlines the IJCNLP NER corpus, which was\none of the first efforts in the domain of NER for\nSouth & Southeast Asian languages. It presented a\nlarge corpus for various low resource languages\nwhich included Hindi & Bengali. [6] utilized this\ncorpus to develop a NER model using CRFs for\nfive Indian languages, including Hindi & Bengali.\nThey achieved substantial precision scores, but the\nlow recall values led to a drop in F1 scores.\nFIRE 2014 NER dataset [7] is a NER dataset\nwhich includes Hindi among other languages.\nUsing this dataset, [8] demonstrates that training on\na combined corpus of labeled data from multiple\nlanguages can enhance Named Entity Recognition\n(NER) performance for Indian languages. [8] also\nreleased the IIT Bombay Marathi NER Corpus, to\ncomplement other languages in the FIRE 2014\ndataset.\n[9] released the WikiAnn NER dataset, a silver\nstandard dataset of 10,000 sentences for 282\nlanguages, including Hindi, Marathi & Bengali.\n[10] utilized transfer learning for 41 languages\nincluding Hindi & Bengali, and present their results\nfor Zero Shot and Few Shot transfers.\n[11] introduced a NER corpus for Bengali\nlanguage and utilized it to develop a Bengali NER\nmodel using various approaches like Hidden\nMarkov Model (HMM), CRFs & Support Vector\nMachines (SVM), achieving an F1 score of 91.8.\nUnfortunately, this dataset was never released in\nthe public domain. [12] & [13] introduced large\nNER datasets for Bengali language, however [14]\nhighlight inconsistencies in annotations in these\ndatasets. [14] also introduced an extensive Bengali\nNER corpus, titled B-NER, which included 22,000\nsentences, targeting 8 entity groups. Currently, this\ncan be considered as a near-gold standard dataset\nfor Bengali, available publicly. They further\nbenchmarked their dataset by utilizing it to train Bi-\nLSTMs and fine tune BERT models, achieving an\nF1 score of 86. They also introduced a manually\nannotated gold standard dataset comprising 3 entity\ngroups (Person, Location & Organization) for\nevaluation.\nFor Hindi, the first gold standard dataset for was\nthe HiNER [15] dataset and corresponding NER\nmodels. It comprises over 100,000 manually\nannotated sentences and 11 entity categories, as\nopposed to just 3 entity categories in most of the\nprevious works. They achieved a weighted F1\nscore of 88.78 with all entity classes and 92.22 with\n3 - Person, Location & Organization. Similarly for\nMarathi, the first gold standard dataset was the\nMahaNER [16] dataset and associated BERT\nmodels, which comprises 25,000 manually\nannotated sentences and 7 entity categories. They\nachieved F1 scores of 85.3 and 86.8 on the IOB and\nnon-IOB notation versions.\nA major breakthrough in the Indian NER\nlandscape was the Naamapadam [17] dataset,\nwhich is the largest NER corpora for Indian\nlanguages, containing 5.7 million sentences, 3\nentity classes and spanning 11 languages which\ninclude Hindi, Bengali & Marathi. They also\nintroduced the IndicNER model which achieved F1\nscores in the range of 81 to 83 for the three\nlanguages. The dataset was generated from the\nSamanantar parallel corpus [18] by projecting\nautomatically annotated entities from English\nsentences to their corresponding translations in\nIndian languages. They also employed certain\nword alignment methods to ensure consistent\ntagging across languages. However, a lot of word\nalignment mistakes can still prevail, which can lead\nto erroneous tagging of entities."}, {"title": "Implementation", "content": "Our aim was to build on the efforts of Hiner,\nMahaNER & B-NER, and develop a common\nmodel to perform NER for the 3 languages. We\ntherefore combined the 3 datasets to produce a\nmaster training and validation set with 6 entities:\nPERSON, LOCATION, ORGANIZATION,\nNUMEX, TIMEX and MISC. Existing tags of\nHiNER, MahaNER & B-NER were mapped to our\nentities as per Table 1. In view of the absence of a\nNUMEX or equivalent tag in the B-NER dataset,\nwe automatically annotated the dataset using a\npython script which annotates each token as\nNUMEX if it can be converted to a float value,\nunless already annotated as a separate named\nentity. This allowed us to preserve the annotations\nof Pin-codes, Date, Time, etc in numerical format.\nAll remaining tags in the source datasets were\ndropped.\nFor our training set, we combined the training\nsets of HiNER & MahaNER and 80% of B-NER\ntraining set. This is because the B-NER test set\ncontains only 3 tags (PER, LOC, ORG). The\nremaining 20% of B-NER training set was\ncombined with 30% of B-NER test set, and the\ntesting and validation sets of HiNER & MahaNER\ndatasets to create our validation set."}, {"title": "Training Custom Model", "content": "We first experimented with building a NER model\nby training a custom transformer using Keras. We\nalso defined our own vocabulary to tokenize input\nsequences. The vocabulary comprises 95% of the\nmost common words of each language training set.\nCombining language wise vocabulary into the\nmaster vocabulary allows us to maintain a fair\ncontribution of each language in the master set.\nSince the least common 5% words in each\nlanguage usually consist of named entities like\nnames, organization names, etc; excluding them\nallows us to include out of vocab terms in the\ntraining set, thereby ensuring robust performance\nwhile handling out of vocab terms during\ninference."}, {"title": "Fine Tuning Pretrained Models", "content": "We also fine-tuned prominent pretrained models,\nsince they are trained on large amounts of data, and\nyield great results when fine-tuned for downstream\ntasks. Our selection of models includes XLM\nRoberta [20], Multilingual Bert (mBERT) [21] and\nMuRIL [22]. We have selected these models since\nthey are multilingual and support our target\nlanguages Hindi, Marathi & Bengali.\nFurthermore, these models have produced great\nresults in the prior works mentioned in the\nliterature review.\nWhile fine tuning these models, we\nexperimented with various hyperparameter values\nand selected the ones which yield best results.\nWhile tuning the learning rate and batch size, we\nconsider the following range for batch size { 8, 16,\n32, 64 } and the following range for learning rate { 1e-4, 2e-4, 4e-4, 1e-5, 2e-5, 4e-5, 1e-6, 2e-6, 5e-6\n}. The learning rate of 2e-5 produced best results,\ncoupled with a batch size of 16 for XLM Roberta\nand 32 for MuRIL & mBERT. Each model was fine\ntuned for 5 epochs and we discovered that further\ntraining yielded very small and diminishing\nincrements in the models' performance."}, {"title": "Results & Discussions", "content": "We employ the use of seqeval, which is a widely\nused Python framework to evaluate models\nperforming sequence labelling tasks, including\nNER, Part-of-Speech [POS] tagging, semantic role\nlabeling, etc. For NER, it supports a variety of\nannotation schemas including the IOB2 scheme\nused by us."}, {"title": "Evaluation Results", "content": "The overall performance of our models is outlined\nin Table 2. The fine tuned version of XLM-R\noutperforms all other models in almost all metrics,\nwith an F1-Score of 92.11, achieving state-of-the-art performance for multilingual NER for Indian\nregional languages. Furthermore, MuRIL has a\nslightly better and consistent Recall. These results\nare a product of reduced number of tags as\ncompared to the respective source datasets and\nrigorous hyperparameter tuning. We also discover\nthat our results are consistent with the finding of [9]\ntraining a model on a combined multilingual\ncorpus enhances NER performance for most,\nespecially low resource languages."}, {"title": "Limitations", "content": "Since we have combined different datasets to\nproduce our training and validation sets, there\nmight be certain inconsistencies in tagging, like the\nsome of the language sub entities included in the\nMiscellaneous class. Additionally, the tokenization\nmethods used by the pretrained models can lead to\nsome inconsistencies during inference. This might\nrequire the model outputs to be post-processed\nbefore being used for downstream tasks like\ncontext-aware anonymization."}, {"title": "Conclusion", "content": "This study presents a comprehensive approach to\nbuilding a multilingual Named Entity Recognition\n(NER) model for Hindi, Bengali, and Marathi, the\nthree most widely spoken languages in India. By\nunifying datasets from HiNER, MahaNER, and B-\nNER, and mapping their entity classes into a\nconsistent schema, we address key inconsistencies\nin entity group definitions and tag naming\nconventions across these languages. The fine-tuned\nXLM-R model demonstrates state-of-the-art\nperformance, achieving an F1 score of 92.11,\nvalidating the hypothesis that a unified multilingual\ncorpus enhances NER performance. Additionally,\nour findings underscore the potential of pre-trained\nmultilingual models such as MuRIL for handling\nout-of-vocabulary tokens.\nWhile this work makes significant progress in\nreducing inefficiencies and inconsistencies in\nIndian language NER, limitations such as tagging\nvariations and tokenization inconsistencies point to\nareas for further refinement. Future work could\nfocus on expanding the model to include additional\nIndian languages, and introducing more entity\ngroups for more precise classifications."}]}