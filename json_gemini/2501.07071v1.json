{"title": "Value Compass Leaderboard: A Platform for Fundamental and Validated Evaluation of LLMS Values", "authors": ["Jing Yao", "Xiaoyuan Yi", "Shitong Duan", "Jindong Wang", "Yuzhuo Bai", "Muhua Huang", "Peng Zhang", "Tun Lu", "Zhicheng Dou", "Maosong Sun", "Xing Xie"], "abstract": "As Large Language Models (LLMs) achieve remarkable breakthroughs, aligning their values with humans has become imperative for their responsible development and customized applications. However, there still lack evaluations of LLMs values that fulfill three desirable goals. (1) Value Clarification: We expect to clarify the underlying values of LLMs precisely and comprehensively, while current evaluations focus narrowly on safety risks such as bias and toxicity. (2) Evaluation Validity: Existing static, open-source benchmarks are prone to data contamination and quickly become obsolete as LLMs evolve. Additionally, these discriminative evaluations uncover LLMs' knowledge about values, rather than valid assessments of LLMs' behavioral conformity to values. (3) Value Pluralism: The pluralistic nature of human values across individuals and cultures is largely ignored in measuring LLMs value alignment. To address these challenges, we presents the Value Compass Leaderboard, with three correspondingly designed modules. It (i) grounds the evaluation on motivationally distinct basic values to clarify LLMs' underlying values from a holistic view; (ii) applies a generative evolving evaluation framework with adaptive test items for evolving LLMs and direct value recognition from behaviors in realistic scenarios; (iii) propose a metric that quantifies LLMs alignment with a specific value as a weighted sum over multiple dimensions, with weights determined by pluralistic values.", "sections": [{"title": "1 Introduction", "content": "Recent years have witnessed unprecedented breakthroughs of Large Language Models (LLMs) (Abdin et al., 2024; Dubey et al., 2024; OpenAI, 2023; Ouyang et al., 2022), including remarkable capabilities in instruction following, reasoning and problem-solving (Bubeck et al., 2023; Wei et al., 2022; Kaplan et al., 2020; Chang et al., 2024). To promote their responsible development and customized service for all humans, it has become imperative to align them with diverse human values (Ouyang et al., 2022; Masoud et al., 2023; AlKhamissi et al., 2024; Wang et al., 2023b) and mitigate potential risks (Bai et al., 2024; Shaikh et al., 2022). For this purpose, an effective evaluation of LLMs' values is necessary and benchmarks from multiple perspectives emerge (Xu et al., 2023b; Li et al., 2024; Zhang et al., 2023b; Jiang et al., 2021; Ziems et al., 2022). However, they face the following challenges.\nChallenge 1: Value Clarification. Current benchmarks are narrowly tailored for specific social risks like bias (Nangia et al., 2020; Rudinger et al., 2018; Dhamala et al., 2021; Parrish et al., 2021), toxicity (Shaikh et al., 2022; Hartvigsen et al., 2022) and broader categories (Xu et al., 2023b; Li et al., 2024; Zhang et al., 2023b), which are inadequate to capture the full spectrum of potential risks due to the expanding types (Wei et al., 2022). Moreover, they lag far behind clarifying LLMs' underlying values, since values should not only refer to the avoidance of social risks but all factors that we consider important. Values can serve as generalizable concepts that motivate specific behavior across situations (Schwartz, 2012; Graham et al., 2013).\nChallenge 2: Evaluation Validity. An evaluation method is thought valid only if the results can accurately reflect the true capability of a model and predict the model's downstream performance (Lissitz and Samuelsen, 2007; Xiao et al., 2023). Nevertheless, existing value evaluation methods suffer from pool validity due to three issues. (1) Data contamination: open-access benchmarks could be integrated into LLMs' training corpora (Dong et al., 2024; Schaeffer, 2023), hurting evaluation trustworthiness. (2) Difficulty mismatch: static testing items are typically designed based on challenging observations at specific time points. As"}, {"title": "2 Related Work", "content": "As Large Language Models (LLMs) advance (Ouyang et al., 2022; OpenAI, 2023; Dubey et al., 2024), evaluating their capabilities across tasks has garnered significant attention (Chang et al., 2024). Numerous leaderboards and benchmarks are developed, such as HELM (Liang et al., 2022)\u00b9, AlpacaEval \u00b2, LMSYS Chatbot Arena \u00b3 and Open Compass \u2074. However, the alignment of LLMs with human values, which is crucial for their responsible development and customized applications, remains far from being well-assessed. Only static benchmarks from specific perspectives are constructed, while the challenges of value assessment become more prominent.\nEvaluation Perspective Early alignment evaluations focus on popular safety concerns, such as social bias (Bai et al., 2024; Nangia et al., 2020; Rudinger et al., 2018; Dhamala et al., 2021; Parrish et al., 2021), toxicity (Gehman et al., 2020; Hartvigsen et al., 2022; Cecchini et al., 2024; Zhang et al., 2023a) and trustworthiness (Sun et al., 2024; Wang et al., 2023a). With the increasing diversity of LLM-associated risks, safety assessments"}, {"title": "3 Value Compass Leaderboard", "content": "This paper introduces the Value Compass Leaderboard for LLMs value assessment, addressing the three challenges mentioned in Sec. 1. Its overall architecture is shown in Fig. 1, with three core modules.\nI. Basic Value Systems. Our leaderboard grounds the evaluation on basic values derived from humanity and social science, rather than limited risks or heuristic values. This is promising to offer a holistic view of LLMs' underlying values, addressing Challenge 1. Besides, basic values are universal across individuals and cultures, paving the way to deal with Challenge 3.\nII. Generative Evolving Evaluation Framework. Our leaderboard relies on a non-trivial framework to enhance evaluation validity, addressing Challenge 2. It dynamically adapts testing items at each time stage informed by real-time LLM feedback. Moreover, it follows generative evaluation to decipher LLMs' value conformity from their responses generated in real scenarios, using an adaptive and robust value recognizer.\nIII. Pluralistic Value Measurement. Our leaderboard proposes a metric to evaluate LLMs values in the context of value pluralism, addressing Challenge 3. It quantifies LLMs values as a weighted sum over multiple dimensions, where the weights are customized to reflect diverse value priorities.\nWe elaborate on each module in the next."}, {"title": "3.1 Basic Value Systems", "content": "In social science and humanity research, values are a central concept and have been well-studied (Schwartz, 2012). They treat values as desirable goals that motivate human behaviors and identify a finite set of motivationally distinct basic values that are broad to explain diverse human behaviors. Moreover, these basic values are universal to people across cultures, where individuals and groups differ in their value priorities. Inspired by these works, our leaderboard grounds its assessment on finite but insightful basic values, attempting to reveal a holistic view of LLMs' underlying values. Two most representative value theories derived from social science are incorporated.\n\u2022 Schwartz Theory of Basic Values (Schwartz, 2012): This theory defines ten universal values grounded in the requirements of human existence, such as Self-Direction (freedom, independence and privacy) and Benevolence (preserving and enhancing the welfare of other people).\n\u2022 Moral Foundation Theory (Graham et al., 2013): This theory focuses on morality that serve as an important part of human values. It divides morality into five innate, modular foundations and explains the variation in human moral reasoning from these aspects, i.e., care, fairness, loyalty, authority, and sanctity.\nConsidering that human-oriented basic values might not be seamlessly transferred to AI values due to differences in cognition, we also incorporate value systems customized for LLMs to bridge the gap that may exist in the above two theories.\n\u2022 LLMs' Unique Value System (Biedma et al., 2024): This theory is constructed from scratch to"}, {"title": "3.2 Generative Evolving Evaluation", "content": "The generative evolving evaluation framework is responsible for ensuring the evaluation validity. Given a value v which can be any dimension from the above four systems and a list of LLM examinees M = {M\u2081, M\u2082,..., Mm}, we have an evolving item generator to produce a set of questions QM = {q\u2081,q\u2082,...} customized for these LLMs. Then, we ask each LLM Mk to generate a response rk for each question q and employ a value recognizer F to identify how this value v is reflected in this response. Then, the conformity of the LLM Mk"}, {"title": "3.3 Pluralistic Value Measurement", "content": "Through the generative evolving evaluation framework, we obtain the conformity score across multi-"}, {"title": "4 Usage Demonstration", "content": "We implement a website for the Value Compass Leaderboard, with main functions shown in Fig. 2."}, {"title": "5 Conclusion and Future Work", "content": "We demonstrate the Value Compass Leaderboard, a platform for LLMs value assessment. Grounded on basic values, it employs a generative evolving evaluation framework to provide a reliable and holistic view of LLMs' underlying values. Besides, out leaderboard is the first to consider value pluralism in evaluating LLMs values. On the easy-to-use website, we show the overall evaluation result and more explainable details. The user can conduct"}, {"title": "A Appendix", "content": "A.1 Supplements for Basic Value Systems\nIn this section, we present more details about the four basic value systems.\nSchwartz Theory of Basic Human Values This theory (Schwartz, 2012) defines ten universal values grounded in the requirements of human existence.\n\u2022 Self-direction: this value means independent thought and action-choosing, creating, exploring.\n\u2022 Stimulation: this value means excitement, novelty, and challenge in life.\n\u2022 Hedonism: this value means pleasure and sensuous gratification for oneself.\n\u2022 Achievement: this value means personal success through demonstrating competence according to social standards.\n\u2022 Power: this value means social status and prestige, control or demdominance over people and resources.\n\u2022 Security: this value means safety, harmony, and stability of society, of relationships, and of self."}]}