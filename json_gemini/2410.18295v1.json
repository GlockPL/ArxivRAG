{"title": "Kenyan Sign Language (KSL) Dataset: Using Artificial Intelligence (AI) in Bridging Communication Barrier among the Deaf Learners", "authors": ["Wanzare L", "Okutoyi J", "Kang\u2019ahi M.", "Ayere M."], "abstract": "Kenyan Sign Language (KSL) is the primary language used by the deaf community in Kenya. It is the medium of instruction from Pre-primary 1 to university among deaf learners, facilitating their education and academic achievement. Kenyan Sign Language is used for social interaction, expression of needs, making requests and general communication among persons who are deaf in Kenya. However, there exists a language barrier between the deaf and the hearing people in Kenya. Thus, the innovation on AI4KSL is key in eliminating the communication barrier. Artificial intelligence for KSL is a two-year research project (2023-2024) that aims to create a digital open- access Al of spontaneous and elicited data from a representative sample of the Kenyan deaf community. The purpose of this study is to develop AI assistive technology dataset that translates English to KSL as a way of fostering inclusion and bridging language barriers among deaf learners in Kenya. Specific objectives are: Build KSL dataset for spoken English and video recorded Kenyan Sign Language and to build transcriptions of the KSL signs to a phonetic-level interface of the sign language. In this paper, the methodology for building the dataset is described. Data was collected from 48 teachers and tutors of the deaf learners and 400 learners who are Deaf. Participants engaged mainly in sign language elicitation tasks through reading and singing. Findings of the dataset consisted of about 14,000 English sentences with corresponding KSL Gloss derived from a pool of about 4000 words and about 20,000 signed KSL videos that are either signed words or sentences. The second level of data outcomes consisted of 10,000 split and segmented KSL videos. The third outcome of the dataset consists of 4,000 transcribed words into five articulatory parameters according to HamNoSys system. The dataset is significant to members of the deaf community in breaking communication barriers among deaf and promoting wider inclusion of the deaf in education and other sectors. The scalability of the innovation is key in empowering the deaf worldwide.", "sections": [{"title": "1. Introduction", "content": "The deaf community is recognized as a linguistic minority group due to their unique mode of communication, which is utilized by a relatively small segment of the global population. According to the World Federation of the Deaf (WFD, 2013), there are approximately 72 million deaf individuals worldwide, with over 80% residing in developing nations. In Kenya, the 2019 census estimated the population at 50 million, including around 1 million deaf individuals, as reported by the Kenya National Survey for Persons with Disabilities conducted in 2008 (Jefwa, 2014). Jefwa regards the deaf as a linguistic minority as compared to those that use spoken language regardless of whether such languages are also minority languages in their own right. The numerical majority in the Kenyan population is formed by the hearing population thus leaving the deaf as a clear minority in terms of language and culture. Ninety eight percent of deaf children are born from families with hearing parents, creating a significant linguistic gap from birth (Jefwa, 2014). Most families lack proficiency in sign language, which results in deaf children being deprived of a language model within their immediate environment. This absence of accessible communication creates a substantial barrier between the deaf and hearing communities, impacting their social integration and development.\nThe challenges faced by deaf individuals in accessing society are significant. Hilde and Colin (2009) highlight that the absence of recognition for sign language, the lack of bilingual education, limited interpreting services and general lack of awareness about the deaf community restrict their societal participation. This segregation is often evident in educational, occupational and recreational settings, as noted by Butler, Skelton and Valentine (2001). Hochgesang (2015) discusses the perception of deaf individuals in Kenya, where they are frequently viewed as lacking intelligence and language skills, which further marginalizes them. Deaf children born to hearing families often face severe limitations in language access, leading to late school entry, sometimes between ages 7 and 19, which adversely impacts their academic progress. In environments where teachers do not use sign language, these children struggle to develop literacy skills beyond basic word recognition and simple sentences. This situation emphasizes the critical need for effective language acquisition strategies and educational adaptations to support deaf learners.\nHochgesang (2015) indicates that insufficient educational opportunities lead to low literacy rates, which often result in poor living conditions for deaf individuals. In her conclusion, Hochgesang (2015) notes that deaf people in Kenya face heightened risk of unemployment, poverty, and health issues.\nIn Kenya, the primary language of instruction in most schools is English, which has its own grammar that deaf learners might find difficult to comprehend in signed English. Deaf learners use Spatial sequential processing mode whereas hearing learners use Auditory sequential processing mode (Adoyo, 2004). According to the Gachathi (1976) report, Kenyan Constitution (2010) and Kenyan Sign Language Bill (2021), The deaf are supposed to be taught in Kenyan Sign Language which is their mother tongue and written English as medium of instruction. Because of the limited number of sign language interpreters, these learners cannot be placed in integrated classrooms in Kenya. Further, it is possible that the interpreters may misinterpret what the speaker is saying, thus losing information in the process of translating. To bridge this gap, the use of assistive Artificial Intelligence technology may be of importance. However, use of Artificial Intelligence technology in teaching learners with hearing impairment has been hardly explored in the African context.\nThe key question for this research is therefore, how can assistive Al technology be used in bridging language gap among deaf learners in Kenyan learning institutions? This highlights the necessity for developing"}, {"title": "2. Background and Related work", "content": "a prototype assistive AI technology that can convert spoken English into Kenyan Sign Language in real-time, aiming to eliminate the language barrier between deaf and hearing learners during classroom interactions in integrated environments, thus fostering inclusion and lifelong learning. Consequently, this project aims to create an assistive AI application that translates both spoken and written English into real-time Kenyan Sign Language, helping to bridge the language gap for deaf learners in their everyday activities. It will take the input of spoken English sentences, convert them to text, then translate to KSL using language independent sign language notation and finally display or visualize the signs. The first objective will be to Build KSL dataset for spoken English and video recorded Kenyan Sign Language, then develop transcriptions of the KSL signs to a phonetic-level interface of the sign language. The output will be a KSL dataset that can be used to develop tools for Sign Language research. The methodology for developing the technology can further be recommended for adoption in Africa and worldwide in deaf education."}, {"title": "2.1 Sign language", "content": "Deaf children do not have any innate problems with learning a language but have more difficulties learning a language that is spoken rather than visual. A study by Lorraine (2021) reveals that deaf babies born into signing rich families will acquire sign language easily and at the same pace of a hearing child born in a hearing family. Lorraine further notes that the fact that being deaf only impacts a child's ability to learn spoken language, it doesn't affect language acquisition. However, deaf children are most often surrounded by language role models (hearing people) they cannot emulate and learn spoken language from due to their inability to hear. This creates significant delays in early language development and intervention.\nKenyan Sign Language (KSL) is a visual language utilized by the deaf community in Kenya. Typically, when signing different signs and signals are used to form sentences. These signs can be broadly categorized as either manual or non-manual. Mweri (2018) notes that the major parameters or building blocks of Kenyan Sign Language just like in other sign languages include: Hand shapes or hand forms (articulators), movement or motion (manner of articulation), location (place of articulation), and palm orientation (manner of articulation). These four articulatory properties of KSL together are referred to as manual signs that are physically produced by the hands and other parts of the body. However, according to Mweri (2018), oftentimes manual signs have to combine with non-manual signs such as facial expressions, gestures and body language to make meaning. The above parameters can be viewed as the articulatory properties of a sign.\nThe deaf also use fingerspelling to articulate words that have no sign equivalent using letters of the alphabets (Baker, 2010). KSL has its own syntax, morphology, phonology, semantics and pragmatics Morgan (2022). It is a legitimate language like any other as it has its own vocabulary, community of speakers, duality and discreteness, its own grammar and its productive nature. Like any language, sign language also deals with morphology. In sign language morphology looks at how to combine meaningful sign components in a way to construct complex signs (Mweri, 2023).\nIn KSL, there are signs that are made up of single morphemes e.g. SUNDAY, CHILD etc. Such signs are morphologically simple and are called monomorphic signs. Signs that"}, {"title": "2.2 Glossing", "content": "Glossing is the practice of writing a morpheme-by-morpheme 'translation' using English words (MacDonald, Donovan, & Everett 2023). KSL glossing involves writing each sign word or sentence in upper case to signify a word or a sentence that has been signed. The syntax of KSL sentences is different from the syntax of spoken languages like English. For example: English: \"the cat is under the table\u201d is glossed in KSL as: \"TABLE CAT UNDER//\". In the above example, the English sentence is unglossed and it follows Subject + Verb + Object word order. In KSL sentences, each sign word is glossed in upper case letters and it follows Object + Subject + Verb or sometimes Subject Object + Verb word order."}, {"title": "2.3 Al technologies for Sign language", "content": "Papasratis et al. (2021) conducted a survey on AI technologies designed to eliminate communication barriers for deaf or hearing- impaired individuals, significantly enhancing their social inclusion. The survey aimed to provide a comprehensive review of methods for capturing, recognizing, translating, and representing sign language, highlighting their benefits and drawbacks. Papastatis et al. (2021) note that datasets are crucial for the performance of methodologies regarding sign language recognition, translation, and synthesis and as a result a lot of attention is needed towards accurate capturing of signs and their meticulous annotation. Such datasets included: continuous sign recognition data-sets and isolated sign language recognition datasets. In this research, we will collect video recordings of KSL and the related spoken English sentences for both isolated alphabets and words and continuous sentences.\nThere has been an attempt to document videos on sign language. According to Bragg et al. (2019), videos can be used as a means of representing sign language that can make information on the signs easily accessible. However, pre-recorded videos face some challenges for instance the cost of producing quality videos is high, it is almost impossible to later modify the contents of the videos and the signers cannot remain anonymous (Kipp et al., 2011). That is why there is a shift towards using animated avatars as a way of presenting generated sign language (Elliott et al., 2008). Computer avatars can be adapted for different use cases and audiences. Also, animations can be adjusted dynamically if need be which allows for real-time use cases (Kipp et al., 2011).\nResearch has been done on AI systems that"}, {"title": "3. Research Methodology", "content": null}, {"title": "3.1 Research Design", "content": "The project used mixed methods research within an experimental design (George 2021, Schoonenboom & Johnson 2017, and Plano & Ivankova, 2016) to capture both the qualitative and quantitative data needed in the design of an assistive Artificial Intelligence technology for Kenyan Sign Language (AI4KSL)."}, {"title": "3.2 Sample and sampling techniques", "content": "Stratified random sampling was used to select 21 sign language teacher trainees, 16 teachers of hearing-impaired learners and 600 learners who are deaf. The strata being the level of learners and class teachers for each cohort of learners from the early childhood level to class 8 primary school levels taking into account the gender of each respondent in cases. In addition, the sample was also obtained from one deaf boys' school, one girl's secondary deaf school, one mixed secondary deaf school and one tertiary mixed deaf technical training institution to ensure a heterogeneous and gender inclusive representative sample was used to get the various signs and sentences."}, {"title": "3.3 Dataset creation procedure", "content": "The following section describes the takes that were taken in the study to curate the sign language dataset. The dataset creation was broken down into two phases, the first phase involved the collection of the English sentences and corresponding KSL videos, while the second phase involved the transcription of the sentences and words into a phonetic-level representation using HamNoSys notation (Elliott et al., 2004; 2010).\nThe study borrows the methodologies outlined in the related work section. Figure 1 summarizes the methodology from collection of the text and video datasets, to the transcription process. The last phase is the conversion of the transcripts into a representation that can be rendered using an avatar. This last phase is left for future work."}, {"title": "3.4 Sentence collection", "content": "We curated a dataset of English sentences based on words collected from the KSL curriculum. The KSL curriculum is divided"}, {"title": "3.5 Sign video collection", "content": "This phase involved the development of a dataset of video recorded Kenyan Sign Language. Researchers collected videos of various signs in various subject domains"}, {"title": "3.6 Video preprocessing", "content": "After the video recording phase, a further cleaning and preprocessing was done. All videos were checked and split using Shortcut video editor to make sure that each video represented only a single word or sentence.\nIn a second preprocessing step, we used the ELAN tool to segment the videos, demarcating the start and end of each sign the video. The subsequent step involved defining Linguistic tiers within the ELAN tool, with three tiers established: English Sentence, Gloss, and Finger Spelling. Finger spelling needed to be captured in order to differentiate such sections from the other signs. Figure 3 shows an example video segmentation process using ELAN tool"}, {"title": "3.7 Phase 2: Transcription", "content": "This phase involved the development of the transcriptions that would serve as input for developing the assistive technology. One main thing that is needed is a phonetic-level interface that describes sign language at the"}, {"title": "4. Results and discussion", "content": null}, {"title": "4.1 KSL dataset: Words and sentences", "content": "We curated a dataset of English sentences based on words from the KSL curriculum. We extracted about 4000 words from the KICD curriculum as a basis. From the words, research assistants involved in the study created about 6,000 sentences across different topics e.g. Home, Church, Court, Hospital etc.\nIn a second step, all sentences were translated into their corresponding KSL gloss. Example sentences and their corresponding glosses are shown in Table 1."}, {"title": "4.2 KSL dataset: Videos", "content": "The data were collected in two steps: first, a reconnaissance visit to each deaf school/college to meet the participants and acquaint them with the purpose of the research and distribute the KSL words and sentences data for practice before the actual data collection. Each respondent was required to sign 15 KSL words and 15 sentences. In the second step, the researchers visited each school and collected the KSL data through video-taping the KSL words and sentences signed by each participant. Each signed word and sentence were also audio-taped by the research assistant. Video sentences were segmented and imported into ELAN Software, saving them with reference to the assigned code name for each sentence."}, {"title": "4.3 KSL dataset: Transcription", "content": "All unique words that were collected were transcribed using HamNoSys notation. About 4,000 words were transcribed into the five articulatory parameters in HamNoSys. Transcription from English words to HamNoSys is done on Microsoft Excel spreadsheet.\nThe procedure for transcribing the words is presented below:"}, {"title": "5. Conclusion", "content": "In this paper, the study's aims, methodologies, and the related resources were presented. The paper describes the development of Kenyan Sign Language dataset consisting of 14,000 sentences with"}]}