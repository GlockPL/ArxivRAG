{"title": "Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual Program Generation", "authors": ["Deokhyung Kang", "Jeonghun Cho", "Yejin Jeon", "Sunbin Jang", "Minsub Lee", "Jawoon Cho", "Gary Geunbae Lee"], "abstract": "Visual programming languages (VPLs) allow users to create programs through graphical interfaces, which results in easier accessibility and their widespread usage in various domains. To further enhance this accessibility, recent research has focused on generating VPL code from user instructions using large language models (LLMs). Specifically, by employing prompting-based methods, these studies have shown promising results. Nevertheless, such approaches can be less effective for industrial VPLs such as Ladder Diagram (LD). LD is a pivotal language used in industrial automation processes and involves extensive domain-specific configurations, which are difficult to capture in a single prompt. In this work, we demonstrate that training-based methods outperform prompting-based methods for LD generation accuracy, even with smaller backbone models. Building on these findings, we propose a two-stage training strategy to further enhance VPL generation. First, we employ retrieval-augmented fine-tuning to leverage the repetitive use of subroutines commonly seen in industrial VPLs. Second, we apply direct preference optimization (DPO) to further guide the model toward accurate outputs, using systematically generated preference pairs through graph editing operations. Extensive experiments on real-world LD data demonstrate that our approach improves program-level accuracy by over 10% compared to supervised fine-tuning, which highlights its potential to advance industrial automation.", "sections": [{"title": "1 Introduction", "content": "Recent advances in large language models (LLMs) have significantly improved their capabilities in code generation. Moreover, LLMs such as GPT-4 (Achiam et al., 2023), StarCoder (Li et al., 2023), and DeepSeek-Coder (Guo et al., 2024) are able to automate large parts of programming tasks and substantially improve programmers' efficiency. Yet, despite these achievements, most of the previous research has focused on text-based programming languages (TPLs) such as Python or Java, which leaves visual programming languages (VPLs) relatively unexplored.\nVPLs typically represent programs as node graphs (Figure 1), which allow users with limited programming backgrounds to create and modify programs by graphical manipulation (DeLozier and Shey, 2023). As such, due to their easier accessibility, VPLs have been widely adopted across various domains, from Ladder Diagram (LD) in industrial control systems (IEC, 2013) to Unreal Engine's Blueprints in game development (Games, 2010). Although VPLs lower the barrier to programming, creating such visual programs from scratch can still be cumbersome. Consequently, recent studies (Zhang et al., 2024b; Xue et al., 2024; Zhou et al., 2025) have explored generating visual programs in text formats (e.g., JSON) from user instructions using prompting-based approaches.\nWhile these studies have shown promising results in VPL generation, the sole reliance on prompting-based methods can be less effective for industrial VPLs like LD. This is because these languages are widely used in industrial automation, which follow domain-specific configurations (e.g., address mapping) that vary drastically by environments (Alphonsus and Abdullah, 2016). Given the vast number of these configurations, it is challenging to include all such information in a single prompt. In contrast, training-based approaches can implicitly learn these configurations during fine-tuning. Therefore, we argue that training-based methods are necessary for this setting.\nTo validate this, we select LD as a test language and compare supervised fine-tuning (SFT) with retrieval-augmented generation (RAG), where the latter is a commonly used prompting-based method for VPL generation (Zhang et al., 2024b; Xue et al., 2024). Experimental results show that SFT outperforms RAG even with a smaller LLM backbone, which highlights the advantage of training-based approaches for industrial VPL generation.\nMotivated by these findings, we propose a two-stage training approach to enhance VPL generation. First, we adopt retrieval-augmented fine-tuning, as VPL often reuses subroutines in similar contexts (Terra-Neves et al., 2021). During both training and inference, we retrieve similar examples from a corpus and incorporate them into the model input to improve generation quality. Second, we apply offline direct preference optimization (DPO) (Rafailov et al., 2023) to further guide the model toward accurate outputs. Since VPLs are represented as node-based graphs, we construct preference pairs by systematically applying graph editing operations to transform ground-truth (preferred) VPL code into unpreferred variants. By learning from these pairs, the model captures the preference relationship between the preferred and unpreferred code, thereby enhancing its fine-grained understanding of VPL's structural properties.\nTo evaluate our approach, we collect LD data from an actual production environment and conduct extensive evaluations across various text formats and models. Results demonstrate a consistent improvement in generation performance. Notably, our approach improves exact-match accuracy at the program level by more than 10% compared to SFT. The advantages of our methodology are substantiated by further analyses and ablation studies.\nOur contributions are as follows: (1) We present a pioneering study on training-based VPL generation and demonstrate its effectiveness for industrial VPL. (2) We propose a two-stage training strategy that combines retrieval-based fine-tuning and preference optimization via graph editing, which yields significant performance improvements. (3) To the best of our knowledge, this is the first work to effectively generate Ladder Diagrams using LLMs, underscoring its potential to enhance industrial automation."}, {"title": "2 Is Training-Based Approach Effective?", "content": "In this section, we investigate the effectiveness of the training-based approach in comparison to the prompting-based approach for industrial VPL generation. We introduce Ladder Diagram (LD) as our test language (\u00a72.1), then describe text format conversion in \u00a72.2 to explore results across different text formats. Their results are presented in \u00a72.3."}, {"title": "2.1 Ladder Diagram", "content": "Programmable Logic Controller (PLC) (Erickson, 1996) controls physical devices such as sensors and actuators in industrial automation systems. For example, in a conveyor system, PLC logic enables a robotic arm to detect products via sensors and control its joints to transfer items between conveyors. This logic is typically implemented using Ladder Diagram (LD) (Malik, 2024), which consists of multiple rungs, each executing a specific task (e.g., operating a motor). Figure 1 illustrates an LD with a single rung.\nEach rung is further composed of contacts, coils, and function blocks and can be represented as a node-based graph, where each visual element is a node. These individual elements serve a distinct role in the logic sequence; contacts control the power flow, coils activate machinery, and function blocks (e.g., timers, counters) provide advanced control functions. They are connected to the PLC and mapped to I/O addresses that vary with the environment and hardware setup. This domain-specific address mapping enables customized control, as each rung manages unique I/O settings tailored to its setup."}, {"title": "2.2 Text Format Conversion", "content": "As LLMs cannot generate complex visual elements directly, prior studies (Xue et al., 2024; Zhang et al., 2024b) generate VPL in text formats. As each format has unique characteristics, we convert VPL into various text formats to conduct comprehensive experiments. We consider three standard text formats for VPL: (1) XML, which represents visual elements sequentially; (2) JSON, which explicitly captures relationships between elements; (3) Metaprogram (code), which encodes VPL using a code-based syntax.\nSpecifically, Figure 1 illustrates that XML format represents LD as a list of visual elements, including contacts, lines, and function blocks. Each visual element corresponds to an <Element> tag containing its element type, coordinates, and other attributes. Since XML does not explicitly define relationships between elements, we extract these relationships using rule-based methods and convert them into a graph. We iterate through the visual elements in coordinate-based order, adding all elements except lines as nodes to the graph. We implement this graph using NetworkX (Hagberg et al., 2008), which is a widely used Python library for graph representation. We assign Node IDs starting from 0, increasing sequentially in coordinate order. To determine edges, we analyze node coordinates and line positions. Using this information, we construct a directed acyclic graph (DAG).\nUsing this graph representation of LD, we represent LD in both JSON and metaprogram formats. In the JSON format, we represent the LD as a dictionary; each node ID in the graph is a key, and its attributes and outgoing node IDs form the values. For the metaprogram (code) format, we represent the LD in Python syntax using NetworkX. We traverse the graph starting from the smallest node ID, visiting each node and its successors. Upon first visiting a node, we append a G.add_node(...) statement with its attributes to the code. Similarly, we append a G.add_edge(...) statement to the code for each neighbor relationship. This process continues until all nodes from the graph are visited. The generated code can be executed to reconstruct the original graph."}, {"title": "2.3 Results", "content": "Training-based method outperforms prompting-based method To evaluate the effectiveness of the training-based approach compared to the prompting-based approach for industrial VPL generation, we conduct a comparison between the supervised fine-tuning (SFT) method and Retrieval-Augmented Generation (RAG). Among prompting-based methods, we select RAG because this approach has been widely used in prior studies on VPL generation (Xue et al., 2024; Zhang et al., 2024b), and retrieval can provide examples that reflect the domain-specific configurations relevant to generation. SFT uses Llama3.1-8B-Instruct model as the backbone, while RAG uses Llama-3.1-70B-Instruct. The RAG approach utilizes BM25 (Robertson et al., 2009) to retrieve N similar prompt-code pairs from the SFT training dataset. We then append them to the input to generate code for the test prompt.\nAs can be seen in Figure 2, SFT consistently outperforms RAG across different number of retrieved examples (1, 3, 5, 7, and 9), despite its smaller backbone. Although RAG's performance improves as N increases, it eventually degrades, suggesting that learning domain-specific configurations in industrial VPL from retrieved examples alone is challenging. Therefore, these results demonstrate that SFT is an effective choice in this setting. We observe similar trends with a different LLM (Appendix F), and the prompt template for the RAG model is provided in Appendix E.\nTraining-based method excels across text formats To investigate whether the prior results are consistent across different text formats, we extend our experiments to include JSON and the metaprogram formats. We compare SFT with RAG, where performance is reported based on the number of retrieved examples that achieves the highest Program EM for each text format, as the optimal number of examples can vary across formats.\nFrom the results in Table 1, we can observe the following: (1) While SFT shows stable performance across different formats, RAG exhibits performance differences in Node/Edge F1, with the metaprogram-based format showing better performance. This aligns with prior results on prompting-based approaches from Xue et al. (2024). (2) SFT outperforms RAG across all formats. These results further validate the effectiveness of the training-based approach."}, {"title": "3 Proposed Methodology", "content": "In this section, we present a two-stage training strategy to further improve the accuracy of VPL generation. Figure 3 illustrates an overview of our proposed methodology."}, {"title": "3.1 Stage 1: Retrieval-augmented Fine-Tuning for Visual Program Generation (RAFT-V)", "content": "Visual programming languages often contain recurring subroutines and modules that are reused in similar contexts (Terra-Neves et al., 2021). To leverage this property, we retrieve related examples from a training data pool and use them to guide the generation process. Inspired by Zhang et al. (2024a), which incorporates relevant documents as context during fine-tuning to improve domain-specific question answering, we extend this idea to the generation of VPL code. Specifically, we retrieve relevant prompt-code pairs as context to enhance the model's performance. Let D be a training dataset consisting of N prompt-code pairs, where p is a prompt and c is a corresponding VLP code. Given a new input prompt q, we aim to generate the target code cq. We augment the input to the model with additional prompt-code pairs that are most similar to q. This process is driven by a retriever R, which identifies similar prompts from D. R ranks all prompts in D based on their similarity to q. We then select the top-k most similar prompts:\n\n{(p\u2081, c\u2081)}^k_{i=1} = R(q, D)\n\nwhere p and cf denote the retrieved prompt and code, respectively. We then concatenate the original prompt q with each retrieved pair (p, c) to form the augmented input qa for the model:\n\nqa = (q, [(p\u2081, c\u2081), (p\u2082, c\u2082), ..., (pk, ck)])\n\nDuring fine-tuning, the model takes the qa and learns to generate the target code cq from qa via SFT. At inference, the trained model predicts the code \u00eaq from qa."}, {"title": "3.2 Stage 2: Preference Optimization", "content": "Preference optimization techniques, such as DPO (Rafailov et al., 2023), are widely used as a post-training step following supervised learning in reasoning tasks like code generation (Hui et al., 2024; Le et al., 2022; Weyssow et al., 2024). These methods rely on high-quality labels to construct preference pairs (Pace et al., 2024). However, in domain-specific applications, particularly in underexplored areas such as VPLs, the available preference pairs are virtually nonexistent. To mitigate this limitation, we propose a graph editing approach to construct preference pairs.\nOverall graph editing process As described in \u00a72.2, we transform visually structured programs into NetworkX graphs to facilitate access to nodes and edges. Based on this graphical representation, we introduce a preference pair collection method. Furthermore, we utilize Graph Edit Distance (GED) (Sanfeliu and Fu, 1983; Abu-Aisheh et al., 2015) to enable the extraction of hard negative samples from the edited graphs. Algorithm 1 provides the detailed process for sampling negative graphs, where we use 10 seeds in our experiments. Based on our empirical observations, we set the deletion ratio \u03c4 to 0.1, modifying approximately 10% of the graph structure. Accordingly, no nodes are deleted for graphs with fewer than 10 nodes. Instead, as shown in line 15, the graph is augmented by duplicating and adding node-edge pairs. The impact of varying \u03c4 is discussed in \u00a75.3.\nHard negative selection Preference optimization using hard negative samples is beneficial for learning subtle differences that supervised learning alone may not capture (Zhu et al., 2024; Chen et al., 2024). This suggests that the difference in connectivity between hub nodes and leaf nodes is substantial, and when nodes are randomly deleted, the quality of negative data varies considerably. Therefore, we select hard negative samples from the negative set collected via graph editing (Algorithm 1). We employ the GED-based metric for selection:\n\nGED(G, G') = min_{T \u2208 T(G,G')} \u2211_{e \u2208 E_T} cost(e)\n\nwhere T(G, G') is the set of all possible edit operation that transform G' into G. Given T(G, G') and the cost, the GED is the minimum associative cost of each edit operation across all possible edit paths. In this study, the cost of an edit path is measured using the Levenshtein distance (Black, 1998). To construct preference pairs, we select the graph with the lowest edit distance to the reference graph from G = {G\u2081 . . . G'}. collected through multiple seeds. We designate the graph with the lowest score as the hard negative GHard. Finally, we construct preference pair by pairing ground-truth graph G with GHard.\nDirect preference optimization Preference learning is conducted using the selected preference pairs, with the retrieved prompt and its corresponding VPL code augmented as input. Implementation details are provided in Appendix B."}, {"title": "4 Experimental Settings", "content": "Dataset Due to the lack of publicly available datasets, we created our own by annotating ladder diagrams from actual production environments. Using XG5000 (XG5, 2009), we exported these diagrams as XML files and divided them into functional units, where each unit consists of one or more interconnected rungs designed to perform a specific function. An experienced PLC programmer then annotated natural language instructions for each unit. The dataset was randomly split into training, validation, and test sets of 13,124, 500, and 500 samples. 80% of the training data was used for SFT, while the remaining 20% was used for preference learning. Appendix C shows an example of the dataset utilized.\nImplementation details We utilize Llama-3.1-8B-Instruct (Dubey et al., 2024) as the main backbone model and also use Qwen2.5-7B-Instruct (Yang et al., 2024) to assess the generalizability of our method. To facilitate task understanding, we provide a detailed task description and explanations of the visual elements used in ladder diagrams via the system prompt. For models using retrieval, we utilize BM25 (Robertson et al., 2009), which is a widely used lexical matching-based method. Using BM25, we augment the input to these retrieval-based models with a top-1 retrieved prompt-code pair from the training dataset.\nEvaluation metrics Text-based programming languages like Python are typically evaluated for correctness by unit tests (Chen et al., 2021; Austin et al., 2021; Chen et al., 2023). In contrast, industrial visual programming languages often rely on separate simulators for evaluation, which limit consistent automated assessment across program variations and diverse environments (Ray, 2017; Ren et al., 2024).\nTo address this, we introduce graph-based automatic evaluation by transforming visually structured programs into NetworkX, as introduced in \u00a72.2. Specifically, we measure partial correctness in the graph representation by comparing it with the ground-truth graph using Node F1 and Edge F1 at the node and edge levels. For exact matches, we use Node EM and Edge EM to assess complete accuracy at the node and edge levels. Finally, Program EM evaluates whether the entire graph matches the ground-truth graph precisely in terms of both nodes and edges. Detailed explanations are provided in Appendix A."}, {"title": "5 Results & Discussion", "content": "5.1 Main Results\nStage 1 (RAFT-V) improves upon SFT Table 2 compares the performance of SFT, RAFT-V, and our two-stage method across different output formats (XML, JSON, metaprogram) with two backbone models. By incorporating retrieval augmentation, RAFT-V consistently outperforms SFT and significantly enhances VPL generation. For example, in the JSON format, RAFT-V raises the Program EM from 52.6% to 63.2%, demonstrating more accurate VPL generation. Similar improvements are observed for other metrics.\nPreference optimization (Stage 2) yields further gains Building on Stage 1's improvements, Stage 2 further boosts correctness through preference optimization, particularly in terms of exact match (EM) scores. As shown in Table 2, our two-stage approach improves Program EM over RAFT-V by 3.4% in the metaprogram format and achieves an overall 13.2% gain compared to SFT. Because EM only assigns a score when the entire graph exactly matches, even minor generation failures can significantly impact the metric. These results show that preference optimization reduces such minor generation errors and ensures more precise outputs. Notably, these gains are consistent across all output formats and base models, demonstrating the robustness of our approach."}, {"title": "5.2 Impact of Number of Retrieved Examples", "content": "To assess whether the number of retrieved examples affects performance, we evaluate RAFT-V trained with different numbers of retrieval examples k \u2208 {1,2,3} (Table 3). Although increasing retrieval examples k generally improves generation quality, the gains are marginal, which indicates that even a few examples are able to capture functional patterns in visual programming languages. Based on this observation, we set k = 1 for our main experiments."}, {"title": "5.3 Variation in Deletion Ratio", "content": "Furthermore, we report the performance variation depending on the deletion ratio \u03c4. We train the model using preference pairs with different \u03c4 values, where \u03c4\u2208 {0, 0.1, 0.5, 0.9}. Table 4 shows that F1 scores remain stable across 7 values, while EM scores decrease as t increases. In particular, when 7 is 0.9, the negative samples during preference training are graphs with 90% of the original graph removed. As a result, the model can easily distinguish them, making the training less effective. Based on these results, we set \u03c4 to 0.1."}, {"title": "5.4 Analysis of Graph Editing", "content": "We validate our graph editing approach for collecting preference pairs by comparing it with Best-of-N (BON) sampling (Stiennon et al., 2020; Snell et al., 2025), which selects the best generation among N candidates. We generate N = 10 outputs from the RAFT-V model and compare them with our negative candidate set G = {G\u2081 . . . G10}, which is derived from graph editing (algorithm 1).\nPreference learning is effective To address the concern that the gains in the 2-stage approach may result from the additional data used for preference learning, we compare it with a 1-stage approach, where the model is trained on all the data without a second stage, and is referred to as RAFT-V (100%). As shown in Table 5, RAFT-V improves performance as the dataset size increases. However, RAFT-V (100%) shows only marginal improvement in EM scores compared to preference-learned models. Although RAFT-V (100%) demonstrates effectiveness in improving F1 scores when compared to BoN-based preference learning baselines, it is insufficient to minimize minor errors (EM).\nEditing-based negative selection is efficient We introduce four baselines for comparison with graph editing: BoN (Random), where G is sampled from BON, and GHard is randomly selected from BoN-sampled G; BoN (Unstrict), which selects preference pairs based on GED; and BoN (Strict), which considers preference pairs for training only when the sampled output includes an exact match with the correct answer (i.e., GED = 0). Finally, in the case of Ours (Random), G is sampled from graph editing, but GHard is randomly selected instead of using GED.\nAs shown in Table 5, BoN (Strict) constructs preference pairs based on exact matches and achieves the highest accuracy among BoN-based"}, {"title": "5.5 Performance Across Program Complexity", "content": "To evaluate our methodology's performance across varying program complexities, we convert each program (VPL code) in the test split into NetworkX graphs. We define complexity as the total number of nodes and edges in the graph. We then sort programs by complexity and split them into five percentile ranges: 0\u201320%, 20\u201340%, 40-60%, 60\u201380%, and 80-100%, labeling them from 1 to 5. Figure 4 shows the average Program EM across these categories. Our approach consistently outperforms the SFT baseline, widening the gap at higher complexities (+18.3% in 4, +16.3% in 5). These findings highlight our method's robustness, with benefits increasing in challenging scenarios."}, {"title": "6 Related Work", "content": "LLMs for Visual Program Generation Visual programming systems (e.g., LabView (Bitter et al., 2006), XG5000 (XG5, 2009)) typically feature node-based interfaces that let users visually write and modify programs. Recently, researchers have begun utilizing LLMs to generate VPLs, as they are known for their powerful text-based code generation capabilities. For example, Cai et al. (2024) integrates low-code visual programming with LLM-based task execution for direct interaction with LLMs, while Zhang et al. (2024b) studies generation of node-based visual dataflow languages in audio programming. Similarly, Xue et al. (2024); Zhou et al. (2025) investigates Machine Learning workflow generation from natural language commands and demonstrates that metaprogram-based text formats outperform other formats like JSON. However, these prompting-based methods face limitations for VPLs like Ladder Diagram, where custom I/O mapping and domain-specific syntax are crucial. Thus, we study fine-tuning approaches with domain-specific data to better capture these details.\nLLM-based PLC code generation Programmable Logic Controllers (PLCs) are essential components in industrial automation and are used to control machinery and processes reliably and efficiently. Among the programming languages defined by the IEC 61131-3 standard (IEC, 2013), Structured Text (ST) and Ladder Diagram (LD) are commonly used for programming PLCs. Research in this area has focused on utilizing LLMs to generate ST code from natural language descriptions. Recent studies have demonstrated the potential of LLMs in generating high-quality ST code (Koziolek et al., 2023, 2024), enhancing safety and accuracy with verification tools and user feedback (Fakih et al., 2024), and automating code generation and verification using multi-agent frameworks (Liu et al., 2024). Although these advances have improved PLC code generation, they primarily focus on ST, despite LD being widely used in industrial settings due to its similarity to electrical circuits (Malik, 2024). While Zhang and de Sousa (2024) attempts to generate LD as an ASCII art based on user instructions in a zero-shot manner, their findings show that even advanced LLMs struggle with basic LD generation. These limitations highlight the necessity of training-based methods for LD generation. In this work, we address this gap by introducing a training-based approach for LLMs to generate LD and thus pave the way for the broader adoption of AI-assisted PLC programming."}, {"title": "7 Conclusion", "content": "In this paper, we have demonstrated the importance of fine-tuning for VPL generation and introduced a novel two-stage training strategy. By combining retrieval augmentation leveraging repetitive subroutines in VPLs with preference learning through graph editing, we achieved significant improvements in LD generation. Our work marks a crucial step toward LLM-based LD generation, and given that the method leverages VPL characteristics, it holds potential for broader applicability."}, {"title": "Limitations", "content": "One limitation of our study is that the experiments were conducted exclusively on ladder diagrams. Although ladder diagrams are widely used in visual programming languages (VPLs), extending our methodology to other VPLs is necessary for broader applicability. Nonetheless, ladder diagrams remain crucial in industrial automation but have been largely overlooked due to the text-centric design of most large language models (LLMs). Prior studies have struggled to generate even basic ladder diagrams, highlighting a significant gap. To bridge this, we proposed a method to represent ladder diagrams in multiple text formats, enabling LLMs to process them as a graphical language. This approach addresses the limitations of previous studies and opens new possibilities for LLM-based generation of visual programming languages.\nAnother limitation is that our dataset cannot be publicly released due to strict confidentiality constraints, as it contains proprietary industrial processes used in manufacturing. To safeguard sensitive information, we have anonymized and provided only a partial subset. Our dataset adhered to the IEC 61131-3 international standard and specifically utilized ladder diagrams, which are a widely adopted language in PLC programming. While our dataset has unique attributes for ladder elements and rung structures that differ across users, it remains applicable to other ladder diagram-based programs that adhere to the IEC 61131-3 standard. Consequently, our methodology is not restricted to this particular dataset but rather is applicable to other industrial formats, which demonstrates scalability and adaptability. Yet, recognizing the importance of further generalization, we acknowledge the need for a publicly available VPL-based benchmark, which we leave as future work."}, {"title": "Ethical Considerations", "content": "In our research, we employed models such as Llama-3.1-8B-Instruct and Meta Llama-3.1-70B-Instruct-AWQ-INT4, both of which are released under the Llama 3.1 Community License, as well as Qwen2.5-7B-Instruct, released under the Apache License 2.0, and Qwen2.5-72B-Instruct-AWQ, released under the Qwen license. All models were used strictly for research purposes, and no artifacts were utilized beyond the scope of the study."}, {"title": "A Evaluation Metrics", "content": "As mentioned in \u00a72.2, Ladder Diagram (LD) can be represented as NetworkX graphs. We evaluate LD programs from two perspectives: node and edge levels and the overall graph level. To assess the accuracy of node and edge predictions, we compute the F1 score, which considers both precision and recall for the sets of nodes and edges in each ground truth and predicted graph. These metrics are defined as Node F1 and Edge F1, respectively. Furthermore, to verify the correct execution of LD, we use Exact Match (EM), which strictly measures the structural accuracy by comparing the entire node and edge sets between the predicted and reference graphs. We define Node EM and Edge EM to measure the exact match between the entire sets of nodes and edges, respectively. Moreover, Program EM represents the overall structural alignment, which is achieved only when both node and edge sets are perfectly matched.\nLet the reference graph be denoted as G = (V, E) and the predicted graph be denoted as \u011c = (V, \u00ca). Here, comparisons between nodes and edges are evaluated by considering all required attributes (e.g., names, types) for both F1 score and exact match.\nFor nodes: $TP_N = |V \u2229 \\hat{V}|$, $FP_N = |\\hat{V} \\backslash V|$, $FN_N = |V \\backslash \\hat{V}|$\n\nPrecision_N = \\frac{TP_N}{|\\hat{V}|}, Recall_N = \\frac{TP_N}{|V|},  Node F1 = \\frac{2TP_N}{|V| + |\\hat{V}|}\n\nFor edges: $TP_E = |E \u2229 \\hat{E}|$, $FP_E = |\\hat{E} \\backslash E|$, $FN_E = |E \\backslash \\hat{E}|$\n\nPrecision_E = \\frac{TP_E}{|\\hat{E}|}, Recall_E = \\frac{TP_E}{|E|},  Edge F1 = \\frac{2TP_E}{|E| + |\\hat{E}|}\n\nThe Exact Match (EM) scores are defined as follows:\nNode EM = $1{\\{V = \\hat{V}\\}}$, Edge EM = $1{\\{\\hat{E} = E\\}}$, Program EM = $1{\\{V = \\hat{V} and \\hat{E} = E\\}}$"}, {"title": "B Further Implementation Details", "content": "Supervised fine-tuning (including RAFT-V) We fine-tuned models using SFT with 10 epochs, a batch size of 8, and a learning rate of 5 \u00d7 10-5. We applied LoRA (Hu et al., 2022) with a rank of 256, a = 256, and a dropout rate of 0.05. LoRA adaptation was applied to the following target modules: q_proj, v_proj, k_proj, o_proj. Using the AdamW (Loshchilov and Hutter, 2019) optimizer, we minimized the cross-entropy loss LCE between ground-truth code c and the predicted code \u0109 as follows:\n\nL_{CE} = - \\sum_{t=1}^{T} \\sum_{v \\in V} \u03b1(v) log \\hat{c}_{t}(v)\n\nwhere T is the sequence length and V is a vocabulary size. The SFT process took 6 hours using 4 A100-80GB GPUs, while the SFT process for RAFT-V took 8 hours using the same hardware configuration.\nPreference learning For preference learning, we utilized Direct Preference Optimization (DPO) (Rafailov et al., 2023), and trained models for 5 epochs with a batch size of 64. The learning rate was set to 1 \u00d7 10\u22127, with a warmup ratio of 0.03, a weight decay of 0.01, and \u03b2 = 0.1. As with SFT, LORA was applied with the same rank, \u03b1, dropout rate, and target modules.\nGiven a pair of responses, a preferred response y+ and a dispreferred response y\u2212 for a given input x, we minimize the following DPO loss:\n\nL_{DPO}(\u03b8) = - E_{(x,y^+,y^-) \\sim D} log \u03c3 \\Bigg( \u03b2 \\Bigg( log \\frac{\u03c0_\u03b8(y^+ | x, R(x))}{\u03c0_{ref}(y^+ | x, R(x))} - log \\frac{\u03c0_\u03b8(y^- | x, R(x))}{\u03c0_{ref}(y^- | x, R(x))}\\Bigg)\\Bigg)\n\nwhere \u03c3(z) is the sigmoid function, \u03b2 is a scaling factor controlling the strength of preference optimization, R(x) = (pr, cr) represents a retrieved prompt and its corresponding VPL code obtained from a retriever R, and D represents the dataset of preference-labeled samples. The reference model \u03c0ref serves as a baseline to prevent reward overoptimization, ensuring stable preference learning. The preference training stage took 6 hours on 4 A100-80GB GPUs. We measured the loss on the validation set at each epoch in both training stages and applied early stopping based on this criterion, with a patience value of 2.\nSampling parameters We employed beam search decoding with a beam size of 4 during inference."}, {"title": "C Data Samples", "content": "An example from the dataset used in this study is provided. The dataset consists of prompt and code pairs. The prompt was collected in Korean and used without translation for model training and evaluation. The prompt is further divided into Program Description, providing a high-level summary of the functionality, and Detailed Description, specifying task parameters and conditions. The prompts were created by an experienced PLC programmer from the Republic of Korea, ensuring the incorporation of domain expertise into the collected data. The programmer was explicitly informed that the dataset would be collected for model training and evaluation and used strictly for research purposes. We obtained consent prior to data collection. The code is represented in XML format, which describes the ladder diagram with elements. These elements are listed sequentially, and each element includes its attributes (e.g., variable names, parameters) and coordinate information. The datasets were constructed by an experienced PLC engineer, and all sensitive information was anonymized to ensure data confidentiality."}, {"title": "D Human Evaluation", "content": "To further evaluate the effectiveness of our methods, we conduct human evaluations on a randomly selected 50 test set examples. Due to the dataset's security sensitivity, human evaluations were conducted exclusively by PLC engineers who had authorized access to confidential information. Three experienced LD programmers evaluated the generated code based on functionality, and assigned scores"}]}