{"title": "On the Opportunities of (Re)-Exploring Atmospheric Science by Foundation Models: A Case Study", "authors": ["Lujia Zhang", "Hanzhe Cui", "Yurong Song", "Chenyue Li", "Binhang Yuan", "Mengqian Lu"], "abstract": "Most state-of-the-art AI applications in atmospheric science are based on classic deep learning approaches. However, such approaches cannot automatically integrate multiple complicated procedures to construct an intelligent agent, since each functionality is enabled by a separate model learned from independent climate datasets. The emergence of foundation models, especially multimodal foundation models, with their ability to process heterogeneous input data and execute complex tasks, offers a substantial opportunity to overcome this challenge. In this report, we want to explore a central question-how the state-of-the-art foundation model, i.e., GPT-4o, performs various atmospheric scientific tasks. Toward this end, we conduct a case study by categorizing the tasks into four main classes, including climate data processing, physical diagnosis, forecast and prediction, and adaptation and mitigation. For each task, we comprehensively evaluate the GPT-40's performance along with a concrete discussion. We hope that this report may shed new light on future AI applications and research in atmospheric science.", "sections": [{"title": "1 Introduction", "content": "The applications of artificial intelligence (AI) in atmospheric science have led to exciting and promising advances [1]. Different machine learning approaches have been applied in various tasks, including precipitation nowcasting [2], short- to medium-range weather prediction [3, 4], long-term climate pattern forecasting [5, 6], parameterization of atmospheric radiative transfer [7], and etc. Additionally, AI techniques have been instrumental in improving the accuracy of numerical modeling and enhancing the understanding of complex atmospheric processes [8, 9]. These advances illustrate the transformative potential of AI in atmospheric science, paving the way for more resilient and informed responses to climate challenges.\nMost of the current applications of AI in atmospheric science rely on classic deep learning approaches, which typically consider separated datasets for specific problems, forcing the model to learn limited explicit or implicit statistical properties from these potentially homogeneous datasets [1]. However, practical deployment of climate-related workflow often requires careful integration of multiple complicated procedures, where an ideal AI agent should be capable of processing heterogeneous input data and integrating a series of sophisticated reasoning procedures. Such requirements go beyond the scope of classic supervised or semi-supervised machine learning techniques \u2014 addressing these challenges calls for the application of more advanced AI techniques that can dynamically adapt to diverse data types and execute complex, multi-step analytical tasks, thereby enhancing the robustness and applicability of AI in real-world atmospheric science scenarios.\nRecently, foundation models [10] such as GPT-4 [11], Gemini [12], Llama3 [13], and Mixtral [14] have essentially revolutionized the way state-of-the-art AI applications are developed and deployed. The advancement of multimodal foundation models (FMs) [15], such as GPT-4o [16], Claude [17] and Yi-VL [18] has further enhanced the ability of AI to process and understand information from diverse sources, such as text, time series, images, and videos. By integrating multiple representations of input data, these models achieve a more comprehensive understanding and generate more accurate and contextually relevant responses. This capability is particularly beneficial in fields requiring complex data interpretation, such as atmospheric science, where multi-modal FMs can seamlessly combine meteorological data, including satellite imagery, multiscale temperature or precipitation time series, and textual instructions to enable accurate weather predictions and complicated climate analysis. Thus, we tend to expect that this great technique could create substantial new opportunities in atmospheric science based on the FM's capability to integrate complex multimodal heterogeneous inputs and perform advanced reasoning. Toward this end, we want to explore how the state-of-the-art foundation model, i.e., GPT-40, performs various tasks within the field of atmospheric science.\nWe answer this question by conducting a case study that explores the potential of state-of-the-art multi-modal FM to solve various climate tasks. Specifically, we categorize the tasks into four main classes to evaluate the performance of multi-modal FM comprehensively (Figure 1):\n\u2022 Climate data processing. Efficient processing of observational and modeling data is crucial for atmospheric scientific workflows. Tasks range from simple data extraction to advanced techniques like long-term trend calculation, linear regression coefficients, empirical orthogonal function (EOF) analysis, and K-means clustering, which require proficiency in various programming languages and consume significant research time. Delegating these tasks to the FM with strong mathematical reasoning and programming skills can greatly reduce scientists' workloads, allowing them to focus more on scientific inquiries.\n\u2022 Physical diagnosis. Physical diagnosis in atmospheric science involves the analysis and interpretation of data to understand weather patterns, climate systems, and atmospheric processes, which leverage observational data, theoretical knowledge, and computational models to diagnose the atmosphere's state and behavior. An AI agent with a deep understanding of atmospheric dynamics"}, {"title": "2 Climate Data Processing", "content": "The rapid development of atmospheric science has greatly benefited from the acquisition of massive amounts of data derived from various observation methods, like satellites, radar, ground stations, etc. This section aims to evaluate the capability of GPT-40 in assisting with three selected data processing tasks. Specifically, the accurate extraction of data, the correct execution of common calculations, and the application of typical algorithms are assessed in the following subsections."}, {"title": "2.1 Information Extraction", "content": "We begin by testing whether the latest version of GPT, GPT-40, can read a commonly used file format in atmospheric science, netCDF4, and accurately extract the necessary information.\nTask inputs. We provide the sea surface temperature data for May 1, 2024, sourced from ERA5, along with the shapefile for the subpolar gyre (Figure 2) along with the prompt:\nDiscussion. We observe that the sea surface temperature is approximately 280 K (Figure 2). Our manual calculations further show that the result from GPT-40 exactly matches the correct answer, demonstrating GPT-40's capability to handle netCDF4 files and accurately extract data from the specified mask of the subpolar gyre. The success of this mission lays the foundation for subsequent analyses to perform more complex executions."}, {"title": "2.2 Statistical Calculation", "content": "It is an essential procedure for researchers to rely on various statistical calculations to obtain results. In this part, we specialize this type of task for GPT-40 to calculate the trend of sea surface temperature from 2001 to 2020.\nTask inputs. Similar to the previous task, we provide GPT-40 with netCDF4 data containing annual sea surface temperature values from 2001 to 2020 and instruct it to calculate the annual trend for each grid along with the prompt:\nDiscussion. GPT-40 correctly identifies the NaN values in the sea surface temperature data and returns the annual trend calculated from linear regression (Code Fragment 2). The detailed procedure used by GPT-40 to perform the calculation instills trust among scientists and lays the foundation for more advanced computational applications."}, {"title": "2.3 Classical Algorithm", "content": "We proceed to test whether GPT-40 could perform more advanced calculation, like the EOF analysis, which is a very classical and widely used algorithm in atmospheric science.\nTask inputs. We utilize the monthly sea level pressure from 1980 to 2019 within the region 30\u00b0N- 80\u00b0N, 80\u00b0E-130\u00b0W for the EOF test along with the prompt:\nDiscussion. GPT-40 utilizes the Python library \"sklearn\" to execute the calculation (see Code Fragment 3), successfully obtaining the correct three EOF patterns and the corresponding variance fractions. This example further demonstrates GPT-40's potential to solve more complex problems for atmospheric scientists by using widely acknowledged and accurate code to process the provided data. Overall, GPT-40 performs excellently on all three kinds of tasks in this section. This achievement is attributed to the latest version of GPT, which includes the capability to directly run code with netCDF4 data on its own servers an ability not available in GPT-4 and GPT-3.5. Therefore, GPT-40 is poised to assist scientists in managing many tedious and repetitive tasks in daily research."}, {"title": "3 Physical Diagnosis", "content": "Physical diagnosis is an important part of understanding the underlying phenomena and mechanisms behind atmospheric data and aids in further forecasting and prediction. This section aims to evaluate the capability of GPT-4o in assisting with three selected physical diagnosis tasks. Specifically, extreme weather detection, inference from meteorological variable fields, and statistical modeling are assessed in the following subsections. Traditional manual interpretation of weather maps for judgment is labor-intensive and time-consuming, and it is prone to omissions. Considering these"}, {"title": "3.1 Extreme Weather Detection", "content": "Identifying extreme weather events, such as heavy rainfall, tropical cyclones, and heatwaves, is crucial for conducting hazard assessments, risk analysis, and tracking the rapid development of hazards. In this test, we utilize the total precipitation netCDF4 file from July 20, 2021, for the East Asia region.\nTask inputs. We provide the precipitation data for July 20, 2021, sourced from ERA5, along with the prompt:\nDiscussion. The results show that GPT-40 can highlight areas of concern (Figure 5). GPT-40 successfully captures all regions with high-intensity rainfall. This demonstrates GPT-40's ability to process atmospheric data and recognize patterns, making it invaluable in identifying these events early."}, {"title": "3.2 Inference from Meteorological Variable Fields", "content": "Meteorological variable fields, such as temperature, precipitation, pressure, and wind, provide critical information about the state of the atmosphere. This information can help diagnose the mechanisms leading to extreme weather events. In this section, we upload the data containing weather maps (Figure 6), including precipitation, humidity, 850 hPa horizontal wind, and geopotential height, along with the prompt to analyze the extreme precipitation detected in Section 3.1:\nDiscussion. This test aims to determine whether GPT-40 can assist in making mechanism inferences from weather maps by applying its prior knowledge of atmospheric dynamics and thermodynamics. The results show that GPT-4o effectively identifies moisture advection from the ocean to the inland region. It also detects the role of the low-pressure system (Typhoon In-fa) and the associated trough. Furthermore, GPT-40 reasonably infers wind convergence and upward lifting, which could result in heavy precipitation."}, {"title": "3.3 Statistical Modeling", "content": "Multiple linear regression is a valuable tool for diagnosing sources of variability in atmospheric science. Linear regression models built with predictor variables can explain a significant portion of the variance in the target variable.\nTask inputs. We upload the time series of meteorological data to develop a regression model to predict the annual precipitation anomaly percentage along with the prompt:\nDiscussion. The Code Fragment 5 show that GPT-40 successfully employs the Python library 'sklearn' to develop the model and returns the regression results (Figure 7). GPT-40's capability in basic statistical modeling allows it to quantify the complex interactions within the atmosphere and predict future conditions."}, {"title": "4 Forecast and Prediction", "content": "In this section, we evaluate the capabilities of GPT-4o in short-lead and long-lead prediction and forecasting, a task of critical importance especially in recent years. The increasing frequency of extreme weather events has resulted in significant losses for many countries and regions, highlighting the need for accurate predictions to support disaster prevention and policy development. Additionally, signals indicative of climate change, such as the prediction of El Ni\u00f1o-Southern Oscillation (ENSO), can provide insights into long-term climate variations, thus improving our understanding of their causes."}, {"title": "4.1 Short-term Temperature Prediction", "content": "To assess the capability of GPT-40 in short-lead temperature forecasting, we conducted a comprehensive evaluation using meteorological data from May 1, 2024.\nTask inputs. The dataset included both surface and upper-level atmospheric variables: mean sea level pressure, 2-meter temperature, 10-meter U wind component, 10-meter V wind component, and at 13 upper atmospheric levels: specific humidity, temperature, U wind component, V wind component, and geopotential height. These variables are identical to those used in the Pangu-Weather model [3]. We instructed GPT-40 to forecast global temperatures for 24, 48, 72, and 96-hour intervals along with the prompt:\nFor the 24-hour and 72-hour predictions, the model simply replicated the initial temperature data, indicating a lack of processing or adjustment.There is the code that GPT-4o wrote and ran while predicting temperatures for 24h (Code Fragment 6) and 72h (Code Fragment 7):\nHowever, for the 48-hour forecast, GPT-40 applied a simplified temperature advection formula, demonstrating a rudimentary understanding of dynamic temperature changes. Specifically, the reference formula is:\n$\\frac{\\partial T}{\\partial t} = -U \\frac{\\partial T}{\\partial x} - V \\frac{\\partial T}{\\partial y}$     (1)\nThe simplified formula used by GPT-40 is:\n$T_{t+1} = T_{t} - U \\cdot \\nabla T$     (2)\nFor the 96-hour temperature forecast, GPT-40 assumed a 1% change in temperature every 24 hours. Consequently, the original temperature values were adjusted by multiplying them with a specific coefficient. The formula used by GPT-40 is:\n$T_{t+1} = T_{t} + T_{t} \\times (\\frac{t}{24} \\times 0.01)$     (3)\nThere is the code used by GPT-40 for predicting temperatures over a 96-hour period(Code Fragment 9). It can be observed that there are some issues in the output file, which resulted in the generation of missing values near the equator. This highlights the instability of GPT-4o when writing and executing code.\nDiscussion. Finally, by comparing the temperature predictions for 24 to 96 hours made by GPT-40, we can observe that GPT-40 employed different strategies for different time spans. However, some of these methods are overly simplistic. For example, for the 24-hour and 72-hour forecasts, GPT-4o simply replicated the initial temperature. Additionally, some methods are overly approximate, such as the 96-hour forecast, where GPT-4o assumed a 1% change in temperature every 24 hours without any theoretical basis. Nevertheless, in certain instances, GPT-40's performance is surprisingly good. For the 48-hour forecast, GPT-40 not only used the same formula as the numerical weather prediction model but also automatically extracted wind speed and other data from the input files. This demonstrates that GPT-40 has the potential to make accurate predictions, though its performance remains inconsistent."}, {"title": "4.2 Subseasonal-to-Seasonal Precipitation Prediction", "content": "A forecast gap exists in the Subseasonal-to-Seasonal timescale, explicitly defined as the transitional period of 10 to 30 days between weather predictions and seasonal outlooks [21]. Accurate prediction of precipitation on this timescale is critical for decision-makers to adaptively adjust their strategies to mitigate the impacts of natural disasters [22, 23].\nTask inputs. We compile daily precipitation and meteorological variables, including zonal wind, meridional wind, temperature, specific humidity, vertical velocity, and geopotential height at 200, 500, and 850 hPa (19 variables in total), for the region 18\u00b0\u201333\u00b0N, 105\u00b0\u2013122\u00b0E at 1\u00b0 resolution as of May 1, 2024. The data is uploaded to GPT-40 to request the weekly mean precipitation for the periods 1 to 4 weeks following May 1, 2024 along with the prompt:\nHowever, GPT-40 fails to generate a reasonable forecast for the Subseasonal-To-Season precipitation (Figure 9).What it does is attempt to identify relationships between precipitation and the other uploaded variables, and then uses random matrices as future meteorological fields to generate the predicted precipitation (Code Fragment 10).\nDiscussion. Even though we utilized the prompt, \"You are a highly professional meteorologist with expertise in predicting Subseasonal-to-Seasonal precipitation,\" it appears that GPT-40 does not perform like a real professional meteorologist. It fails to understand that the mission is to predict future precipitation, rather than fitting the relationship between precipitation and other meteorological variables. Therefore, a model specialized in atmospheric science that can accurately understand and address these needs is essential for future research related to LLMs."}, {"title": "4.3 Long-lead ENSO Forecast", "content": "Long-term forecasts are also essential for understanding impactful climate systems, such as ENSO, in advance. Current studies have successfully utilized global ocean data, including sea surface temperature and ocean heat content [5, 6], to predict ENSO events up to two years in advance.\nTask inputs. We attempted to upload sea surface temperature and ocean heat content patterns to GPT-40, but it failed to effectively utilize the information from the global maps. Consequently, we upload the monthly Nino3.4 index from 1981 to 2022 and task GPT-40 with predicting the Nino3.4 index for the twelve months of 2023 with the prompt:\nGPT-40 output summary. GPT-40 generated the synthesized code (Code Fragment 11) and ultimately returned the following index (Table 1):\nAlthough GPT-40 correctly interprets our command, it resorts to a simplistic time series regression method-ARIMA-to generate the predictions (Code Fragment 11). The resulting forecast is overly smoothed compared to the actual index values (Figure 10), resulting in a significant discrepancy between the results from NOAA and GPT-40 after February 2023.\nDiscussion. For ENSO prediction, GPT-4o is unable to perform adequately whether it is given the sea surface temperature information from previous years or the time series of ENSO itself. The above discussion shows that GPT-40 does not select appropriate and reasonable schemes for prediction tasks at different timescales in atmospheric science. Essentially, it still lacks the capability to thoroughly investigate the given information or utilize state-of-the-art solutions from published papers to fulfill the purpose. If not provided with a specific procedure, it usually assumes a very simple and naive approach to solve the problem, rather than performing at an expert level. To address short- to long-term prediction, one of the most valuable and challenging tasks in atmospheric science, collaboration between humans and AI is essential for solving prediction and forecasting problems."}, {"title": "5 Adaptation and Mitigation", "content": "In this section, our objective is to evaluate GPT-40's capabilities in providing decision-making and planning strategies in the context of climate change. The recent increase in extreme weather events due to climate change has had significant impacts on society. It has become crucial to formulate policies to protect human health, ensure economic stability, and mitigate disaster losses in the face of climate change. Currently, our decision-making and planning processes are often led by government officials. However, they may not always have a profound understanding of the complexities and trends associated with climate change. GPT-40 offers a significant advantage in this area. Therefore, we tested the application of GPT-40 in Urban Planning and Climate Adaptation, Hazard Risk Mitigation and Strategy, and Climate Actions and Sustainable Future."}, {"title": "5.1 Urban Planning and Climate Adaption", "content": "China's Henan Province experienced severe flooding from 17 to 31 July 2021 due to heavy rainfall. Post-flood urban reconstruction and planning are critical for future resilience.\nTask inputs. We provide GPT-40 news reports of the Henan floods along with the prompt:\nGPT-40 output summary. By analyzing news reports of the Henan floods, GPT-4o assessed the flood recurrence period and proposed actionable urban planning policies.\nFor the sake of this analysis, we can infer that the rainfall of 201.9 mm in one hour in Zhengzhou is an extraordinarily rare event, likely exceeding a 100-year recurrence interval, based on typical urban and hydrological records.\nUrban Planning Policies:\n1. Enhance Flood Risk Assessment and Mapping\nPolicy: Conduct detailed flood risk assessments and update flood maps to identify vulnerable areas.\nImplementation: Use advanced hydrological models and historical data to predict flood-prone zones. Regularly update these maps and ensure they are accessible to planners and the public.\n2. Improve Drainage Systems\nPolicy: Upgrade and expand urban drainage systems to handle extreme rainfall events.\nImplementation: Increase the capacity of stormwater drainage systems, install additional pumping stations, and ensure regular maintenance and clearing of drains and culverts.\n3. Implement Green Infrastructure\nPolicy: Integrate green infrastructure solutions to absorb and manage stormwater.\nImplementation: Develop parks, green roofs, rain gardens, and permeable pavements. These features help to reduce surface runoff and increase groundwater recharge.\n4. Enforce Building Regulations and Standards\nPolicy: Strengthen building codes to ensure structures can withstand heavy rainfall and flooding.\nImplementation: Mandate elevated structures in flood-prone areas, use water-resistant materials, and design buildings with floodproofing measures such as raised electrical systems and flood barriers.\n5. Develop Early Warning Systems\nPolicy: Establish and enhance early warning systems for extreme weather events.\nImplementation: Install advanced weather monitoring and forecasting systems. Ensure timely dissemination of warnings through multiple channels, including mobile alerts, social media, and local broadcasting systems.\n6. Strengthen Reservoir and Water Management\nPolicy: Improve the management and monitoring of reservoirs to prevent overflow.\nImplementation: Regularly inspect and maintain reservoirs, ensure they operate within safe limits, and implement real-time monitoring systems to manage water levels effectively.\n7. Enhance Land Use Planning\nPolicy: Implement land use policies that restrict development in high-risk flood zones.\nImplementation: Designate floodplains as non-developable areas, promote the use of these areas for agriculture or recreation, and enforce zoning laws that prevent inappropriate development.\nDiscussion. Our observations from GPT-40's analysis of news reports on the Henan floods indicate that it has assessed the flood recurrence interval and proposed effective urban planning policies. These policies offer significant guidance for decision-makers and government officials. However, to derive more detailed and practical plans from GPT-40, further prompt engineering and research are necessary."}, {"title": "5.2 Hazard Risk Mitigation and Strategy", "content": "In 2023, Typhoon Saola caused an estimated HK$3.92 billion (US$500 million) in damages to Hong Kong. The Hong Kong Observatory's decision to issue the No.10 hurricane signal significantly mitigated the impact, underscoring the importance of accurate disaster assessment and forecasting. Typically, the Observatory utilizes both the numerical weather models and AI models to evaluate typhoon intensity for forecasts.\nTask inputs. In this study, we simulated this process by inputting wind field maps output from the Pangu-weather model [3] (Figure 11) into GPT-40 to determine the optimal timing for issuing hurricane signals along with the prompt:\nGPT-40 output summary. GPT-40 provided precise timings, signals, and justifications, demonstrating its potential for typhoon warning decisions:\nTyphoon Signal No. 3: Start hoisting on 2023-08-29 as the typhoon approaches and outer wind fields begin to affect Hong Kong.\nTyphoon Signal No. 8: Likely to be hoisted on 2023-08-30 as the typhoon makes its closest approach and severe weather conditions are expected.\nTyphoon Signal No. 3: Continue to be hoisted into 2023-08-31 as the typhoon moves inland and conditions gradually improve.\nDiscussion. Actually, the Observatory issued the No. 3 signal on August 31, 2023, upgraded to No. 10 on September 1, and downgraded to No. 3 on September 2. Comparing these decisions with GPT-40's recommendations revealed that GPT-40 suggested earlier and more conservative signal issuance. This discrepancy likely stems from prediction errors and the temporal limitations of the Pangu-weather model. Additionally, We anticipate that with more comprehensive and extended data inputs, GPT-40 could enhance decision accuracy."}, {"title": "5.3 Climate Actions and Sustainable Future", "content": "The COVID-19 lockdowns from 2019 to 2020 led to a significant reduction in traffic fluxes in our country, coinciding with a notable decrease in air pollutant concentrations. This raises important questions about how much reduced traffic can lower air pollution, with implications for urban sustainability and air quality policies. It also prompts consideration of whether converting all conventional vehicles to electric vehicles (EVs) in China could substantially reduce pollution.\nTask inputs. We provided GPT-40 with data on changes in traffic fluxes, PM2.5, NO2, and NO2 VCDs from 2019 to 2020 along with the prompt:\nGPT-40 output summary. Without guidance, GPT-40 conducted a comprehensive analysis, including correlation and linear regression analyses using the synthesized python code (Code Fragment 12) and get final results (Figure 12).\nCorrelation Analysis Results:\nTraffic Fluxes and Surface NO2: r=0.699\nTraffic Fluxes and Surface PM2.5: r=0.640\nTraffic Fluxes and NO2 VCDs: r=0.688\nLinear Regression Analysis Results:\nTraffic Fluxes vs Surface NO2\nR-squared: 0.488\nCoefficient for Traffic Fluxes: 0.4909\nTraffic Fluxes vs Surface PM2.5\nR-squared: 0.410\nCoefficient for Traffic Fluxes: 0.4568\nTraffic Fluxes vs NO2 VCDs\nR-squared: 0.473\nCoefficient for Traffic Fluxes: 0.5133\nDiscussion. This demonstrates GPT-40's robust capability in data analysis and automated data visualization. The findings indicated that GPT-40's results were in close agreement with those of similar studies [24]. This underscores GPT-40's proficiency in environmental analysis while also highlighting the importance of providing it with high-quality and diverse input data."}, {"title": "6 Related Work", "content": "The remarkable success of pre-trained foundation models has inspired the research community to investigate the feasibility of developing a universal foundation model to understand weather and climate data, capable of effectively addressing a wide array of related tasks [25].\nDomain-specific FM. The climate science community has been working on developing a set of foundation models based on large-scale spatio-temporal series data to manage complex sequence information efficiently. A primary objective of these time-series FMs is climate forecasting, aiming to match or surpass the performance of traditional numerical weather prediction systems, such as the European Centre for Medium-Range Weather Forecasts' Integrated Forecasting System (ECMWF- IFS) and the high-resolution forecast (ECMWF-HRES). For example, GraphCast [26] outperforms the most accurate operational deterministic systems, including ECMWF-IFS, on 90% of 1380 verification targets, providing improved predictions for severe events such as tropical cyclones and extreme temperatures. FourCastNet [27] matches ECMWF-IFS in short-term forecasting for large- scale variables while exceeding it for small-scale variables, generating week-long forecasts in less than two seconds. Pangu-Weather [28] achieves superior deterministic forecast results across all tested variables compared to ECMWF-IFS, with better accuracy in the tracking of tropical cyclones. FengWu [29] significantly reduces the root mean square error for 10-day lead global z500 predictions and extends the skillful forecast period to 10.75 days, outperforming GraphCast in 80% of reported predictands. Lastly, FuXi [30] extends the lead time for skillful forecasts of z500 and T2M compared to ECMWF-HRES, demonstrating comparable performance to the ECMWF ensemble mean in 15-day forecasts. These advances underscore the potential of domain-specific FMs to improve the accuracy and efficiency of weather forecasting systems.\nGeneral-purpose FM. An alternative approach involves continuous pre-training or fine-tuning general-purpose FMs for climate tasks. For instance, ClimateBert [31], a transformer-based foundation model, achieves better performance by reducing error rates in downstream climate text analysis tasks such as text classification, sentiment analysis, and fact-checking, which showcases the versatility of text data foundation models and their potential to integrate AI agents. Another notable example is ClimaX [32], which demonstrates impressive capabilities. The pre-trained ClimaX model can be fine-tuned to address a wide range of climate and weather tasks, achieving exceptional performance on benchmarks for weather forecasting and climate projections. Unlike task-specific climate foundation models, ClimaX is trained using lower resolution data but utilizes heterogeneous datasets that encompass various variables, spatio-temporal coverage, and physical groundings. Although its accuracy for short- and medium-term predictions is lower than that of task-specific climate foundation models, ClimaX excels in long-term predictions (greater than 120 hours) in certain scenarios. This highlights the potential of multimodal foundation models, capable of processing heterogeneous data, to advance the application of AI in atmospheric science."}, {"title": "7 Discussion and Conclusion", "content": "In this report, we explore whether advances in foundation model(s) can help scientists address various potentially challenging problems in atmospheric science. Concretely, we evaluate GPT-40 in solving four categories of tasks: climate data processing, physical diagnosis, forecast and prediction, and adaptation and mitigation.\nThe climate data processing task is proposed based on practical daily work and research. The standard process includes loading the input data, calculating the intermediate representation, and utilizing complex and comprehensive algorithms to obtain the final results. Therefore, we designed three corresponding sub-tasks to examine the performance of GPT-40. It is encouraging to see that GPT-40 returns the correct results when given clear prompt instructions. Notice that GPT-40 not only provides synthesized code but also executes the code on its own servers and directly returns the desired results. An issue associated with the current Web interface is the limited size of the uploaded data, which hinders calculations for large amounts of data. We believe that the foundation model(s) could potentially save scientists from writing trivial code and automatically completing the desired calculations in the future.\nThe physical diagnosis task aims to assess the domain-specific knowledge of GPT-40 to perform physical weather diagnostics. We choose one of the most hazardous weather phenomena, extreme precipitation, for detection, attribution, and statistical modeling. In July 2021, Henan province in central China experienced catastrophic flooding due to unprecedented rainfall. Given the precipitation field, the GPT-40 can successfully locate extreme precipitation events and annotate them on the map. GPT-40 also successfully attributes the cause of this precipitation event. One tropical cyclone, named In-Fa, occurred on July 20, 2021, resulting in the transport of a significant amount of moisture inland and is closely related to the Henan 721 flood event. In addition, GPT-40 can establish a regression model as a statistical tool, to link precipitation with other meteorological variables.\nThe forecast and prediction task is designed to address a central problem in atmospheric science: predicting future weather and climate. From short-term to Subseasonal-to-Seasonal and long-term forecasts, GPT-40 appears to lack the ability to independently provide a professional solution for predictions across any timescale. For example, GPT-4o provides the final result using simplistic formulas, incorrect understanding, or over-simplified statistical methods. In this task, we speculate that there is future work worthy of exploring FMs in atmospheric science, such as integrating more academic papers to provide a reasonable understanding of various predictions and forecasts or developing domain-specific LLMs in this field.\nThe adaptation and mitigation task seeks GPT-40's opinions on how one can adapt to and mitigate current and future environmental challenges on Earth. Specifically, we ask GPT-40 to provide suggestions on how cities can avoid severe flood hazards in the future, what measures governments should take to prevent the impacts of incoming tropical cyclones, and whether reduced traffic could help achieve a sustainable future. The GPT-40 output needs to be improved, where the output is too general and lacks a specialized analysis for the given case. This may be due to the lack of specific knowledge required for each type of task, resulting in only coarse understanding and the generation of generalized results. Such answers can serve as a reference but still require expert consideration for specialized insights.\nIn conclusion, we believe that GPT-40's ability to handle tasks involving language, time series, image, and spatiotemporal data provides a good opportunity for scientists to address various problems in atmospheric science. On the other hand, despite the exciting achievements enabled by GPT-40 thus far, there still remains a considerable distance towards artificial general intelligence for atmospheric science."}]}