{"title": "Preoperative Rotator Cuff Tear Prediction from Shoulder Radiographs using a Convolutional Block Attention Module-Integrated Neural Network", "authors": ["Chris Hyunchul Jo", "Jiwoong Yang", "Byunghwan Jeon", "Hackjoon Shim", "Ikbeom Jang"], "abstract": "This study validates the efficacy of our deep learning model to accurately detect rotation cuff tears from radiographs, offering a viable pre-assessment or alternative to more expensive imaging techniques such as MRI.", "sections": [{"title": "Introduction", "content": "Initial radiograph evaluations often fail to identify soft tissue injuries such as rotator cuff tears. It necessitates further imaging with more expensive MRI examinations, increasing healthcare costs. In this study, we show that a convolutional neural network with channel attention and spatial attention modules can significantly enhance the accuracy of rotator cuff tear detection, only using a single shoulder radiograph. All shoulder radiograph data used for training the deep learning model were collected from our local clinic. It may offer a viable pre-assessment or alternative to more expensive imaging techniques such as MRI."}, {"title": "Material and methods", "content": ""}, {"title": "Data", "content": "We retrospectively collected a dataset of shoulder radiographs from 99 patients from our clinic. The dataset comprises 50 patients with full-thickness rotator cuff tears (fRCT) and 49 without tears. We acquired radiographs in four angles - axial, glenoid, outlet, and anteroposterior (AP) \u2013 totaling 396 images. All the images were acquired before surgery. Regions of interest (ROIs) essential for fRCT diagnosis were identified and annotated with bounding boxes on all images. These annotations were used to train the YOLO v5 model to automatically crop ROIs from all radiographs, and to efficiently handle the annotation process for all future data. The dataset was divided based on subject IDs with each containing four view-specific images. We applied 5-fold cross-validation due to the limited size of the dataset, resulting in 316 training images from 79 subjects and 80 test images from 20 subjects, ensuring no subject overlap between folds."}, {"title": "Network Architecture and Training", "content": "The ROIs extracted were further processed using Contrast-Limited Adaptive Histogram Equalization (CLAHE) to enhance bone structures and edge visibility, facilitating more detailed recognition of fractures and structural integrity. We employed a ResNet50 model applied with a Convolutional Block Attention Module (CBAM) to diagnose rotator cuff tears. CBAM enhances the model's learning focus on essential features in medical image by sequentially applying channel attention and spatial attention. This method allows for a concentrated analysis of salient features crucial for accurately diagnosing rotator cuff tears. The pretrained ResNet50 was adapted to classify between the presence and absence of fRCT, with only two output classes in the final layer. Due to the limited dataset of 99 subjects, we employ k-fold cross-validation to enhance the accuracy of the model's performance. Each fold in the k-fold cross-validation setup was balanced to have an equal ratio of fRCT and no-tear cases in both the train and validation datasets."}, {"title": "Implementation Details", "content": "We trained models on an NVIDIA RTX 3090 GPU using the SGD optimizer with a learning rate of 0.01 and a batch size of 8. To prevent overfitting, we employed various data augmentation techniques including rotation, horizontal flipping, random crop, scaling, translation, brightness adjustment, and inversion, as well as implementing a dropout rate of 0.2. All data was resized to 512x512 pixels prior to training. We utilized a CrossEntropyLoss for the loss function and a CosineAnnealingWarmupRestarts scheduler to dynamically adjust the learning rate during the training process."}, {"title": "Results", "content": "Using k-fold cross-validation, we evaluated the performance of our model across each fold. The average accuracy achieved was 0.831 (329/396). The AUROC for the two classes was 0.889, indicating a high level of discriminative ability. The Positive Predictive Value (PPV) was 0.852 (161/189), and the Negative Predictive Value (NPV) was 0.812 (168 /207). The findings demonstrate that radiographs alone can effectively classify patients with fRCT, underscoring its potential utility in diagnostic settings."}, {"title": "Discussion and Conclusion", "content": "Our proposed method demonstrates that radiographs alone can effectively diagnose fRCT. This approach calculates the probability of rotator cuff tears, thereby assisting in the decision-making process of whether to proceed with MRI imaging. To increase the generalizability of the model, we plan to collaborate with multiple centers to incorporate a larger and more diverse set of radiograph data. Future research will aim to expand the dataset, which was collected from our clinic, and analyze the impact of different radiographic views (axial, glenoid, outlet, and AP) on the diagnosis of rotator cuff tears to improve the current model's performance. In the long term, we aim to achieve a level of diagnostic accuracy close to that of MRI-based diagnostics for rotator cuff tears."}]}