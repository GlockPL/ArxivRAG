{"title": "An Introduction to Cognidynamics*", "authors": ["Marco Gori"], "abstract": "This paper gives an introduction to Cognidynamics, that is to the dynamics of cognitive systems driven by optimal objectives imposed over time when they interact either with a defined virtual or with a real-world environment. The proposed theory is developed in the general framework of dynamic programming which leads to think of computational laws dictated by classic Hamiltonian equations. Those equations lead to the formulation of a neural propagation scheme in cognitive agents modeled by dynamic neural networks which exhibits locality in both space and time, thus contributing the longstanding debate on biological plausibility of learning algorithms like Backpropagation. We interpret the learning process in terms of energy exchange with the environment and show the crucial role of energy dissipation and its links with focus of attention mechanisms and conscious behavior.", "sections": [{"title": "1 Introduction", "content": "The introduction of focus of attention in the Transformer architecture [23] can likely be regarded as a paradigm-shift in Machine Learning. Interestingly, transformer-based architectures mostly reported superior results compared to recurrent neural networks, whose architecture may potentially be more adequate for sequential tasks. However, one should bear in mind that the limitation of capturing long-term dependencies by gradient-based learning algorithms were early pointed out about three decades ago [2, 17, 10]. A remarkable ingredient to face the problems of gradient vanishing is that of adopting the gating mechanisms proposed in the LSTM architecture (see e.g. [9] for an early evidence of the effectiveness of the proposal). LSTM architectures have been in fact the reference architecture for challenging experiments in the last decades and, especially, in conjunction with the explosion of Deep Learning.\nThis paper proposes a reformulation of learning which relies on full human-based protocols, where machines are expected to conquer cognitive skills from"}, {"title": "2 Collectionless AI", "content": "The big picture of Artificial Intelligence that emerges from by Russel and Norvig [19] is centered around a few classic topics, whose methodologies can, amongst others, be characterized by the noticeable difference that while \"symbolic AI\" is mostly collectionless, \"sub-symbolic AI\" is currently strongly relying on huge data collections. Interestingly, Machine Learning, Communicating, Perceiving, and Acting relies mostly on Statistical methodologies whose effectiveness has been dramatically improved in the last decade because of the access to huge data collections. This has been in fact likely the most important ingredient of the success of Machine Learning that has found a comfortable place under the umbrella of Statistics. As such, by and large, scientists have gradually become accustomed to taking for granted the fact that it is necessary to progressively accumulate increasingly large data collections. It is noteworthy that even symbolic approaches to AI are based on relevant collections of information, but in that case they are primarily knowledge bases and there is no data directly collected from the environment. When focusing on the difference of information that is stored, a question naturally arises concerning the possibility of exhibiting intelligent behavior only thanks to an appropriate internal representation of knowledge. Clearly, while the knowledge representation typically enjoys the elegance and compactness of logic formalism, the storage of patterns apparently leads to the inevitable direction of accumulating big data collections. However this is indeed very unlikely to happen in nature. Animals of all species organize environmental information for their own purposes without collecting the patterns that they acquire every day at every moment of their life. This leads to believe that there is room for collapsing to the common framework\u00b3 of \"Collectionless AI\" also for Machine Learning. The environmental interaction, including the information coming from humans plays a crucial role in the learning process, as well as the agent-by-agent communication. We think of agents that can be managed by edge computing devices, without necessarily having access to servers, cloud computing and, more generally, to the Internet. This requires thinking of new learning protocols where machines learn in life-long manner and are expected to conquer cognitive skills in a truly human-like context that is characterized by environmental interactions, without storing the information acquired from the environment.\nThe former completely depends on data collections (clouds) that were possibly supervised beforehand, and where there is no direct/interactive connection"}, {"title": "3 Why do we need a theory of Cognidynamics?", "content": "Beginning from the excellent models for the behavior of single neurons [11], the dynamical system hypothesis in neuroscience and cognition has been massively investigated over the past decades. As early as at the beginning of the nineties, Anderson, Pellionisz, and Rosenfeld [1] edited a seminal book where, amongst others, an important part was devoted to \"Computation and Neurobiology.\""}, {"title": "4 Formulation of Lifelong Learning", "content": "In this section we propose a formulation of Lifelong Learning where the classic notion of time plays the role of protagonist. We introduce a class of intelligent agents that we call NARNIAN: NAtuRe-iNspIred computational Intelligence agents. In particular we consider the continuous interpretation of time mostly used in Physics, though an associated discrete-time setting can replace the analysis carried out in this paper without significant differences. The choice of the continuous setting of computation comes from the mentioned objective of exploring laws of cognition following the spirit that drives other temporal laws in Science. As mentioned in Section 3, once the temporal environment is given, one can think of intelligent agents as dynamical systems that are expected to exhibit a high degree of adaptation capabilities. Moreover, just like any living organism, in addition to continuously react to the environment, intelligent agents in temporal environments can likely benefit from inheriting the capacity of reproduction, growth and development, and energy utilization.\nSURVIVAL AND REPRODUCTION\nSurvival is a slippery topic, but one could easily think of intelligent agents which"}, {"title": "5 Hamiltonian spatiotemporal locality", "content": "We begin considering the optimal problem defined by Eq. (4), for which we can offer the classic solution from the theory of Optimal Control (see Section A in the Appendix). The classic framework of the theory of optimal control suggests to express compactly the pair Neural Network - Lagrangian by the corresponding"}, {"title": "6 Co-state heuristics for learning (", "content": "Here we discuss some fundamental necessary conditions that we need to guarantee to allow an intelligent agent to learn. Basically, we need to upper bound both the state and co-state dynamics, which is a well-known problem in the optimal control theory.\n6.1 Boundedness of the state i\nWe begin stating a proposition on the BIBO stability of the recurrent neural network model described by ODE 1 which comes from a classic result of System Theory stated in the following Lemma.\nLemma 3. Let is consider the ODE\n$\\dot{x}(t)+a(t)x(t) = u(t).$\nThen the solution can be expressed as\n$x(t) = x(0) \\exp(-\\int_0^t a(\\tau) d\\tau) + \\int_0^t \\exp(-\\int_s^t a(\\tau) d\\tau) u(s)ds$\nProof. Let us define the integrating factor\n$I(s) := \\exp(\\int_0^s a(\\tau) d\\tau)$.\nIf we multiply both sides of ODE (18) we get\n$I(s)x(s) + a(s)I(s)x(s) = I(s)u(s)$.\nNow we have $D(I(s)x(s)) = x(s)\\dot{I}(s) + I(s)\\dot{x}(s)$ and then we get\n$D(I(s)x(s)) \u2013 x(s)\\dot{I}(s) + a(s)I(s)x(s) = I(s)u(s)$.\nNow we have $\\dot{I}(s) = a(s)I(s)$ and, therefore, if we integrate over [0,t] we have\n$I(t)x(t) - I(0)x(0) = \\int_0^t I(s)u(s)ds$\nand, finally,\n$x(t) = x(0)I^{-1}(t) + \\int_0^t I^{-1}(t)I(s)u(s)ds$\n$= x(0) \\exp(-\\int_0^t a(\\tau) d\\tau) + \\int_0^t \\exp(-\\int_0^t a(\\tau) d\\tau) I(s)u(s)ds$\n$= x(0) \\exp(-\\int_0^t a(\\tau) d\\tau) + \\int_0^t \\exp(-\\int_0^t a(\\tau) d\\tau + \\int_0^s a(\\tau) d\\tau )u(s)ds$\n$= x(0) \\exp(-\\int_0^t a(\\tau) d\\tau) + \\int_0^t \\exp(-\\int_s^t a(\\tau) d\\tau) u(s)ds$\n6.2 Co-state boundedness and \u03da heuristics\nIn addition to bounding the state, clearly the system dynamics imposes also to bound the co-state. This also corresponds with the need of bounding the energy exchanged with the environment that, as it will be shown in the remainder of the paper, also involves the expression of the Hamiltonian.\nANALYSIS ON Pi\nWe are interested in analysing dynamical modes for which $d/dt((1/2)p_i^2) < 0$. From eq. 10 we get\n$\\dot{p_i}(t)p_i(t) = \u2212 s_i(t)p_i(t)V_{\\xi_i} (\\xi(t), t)p_i(t) + s_i(t)a_i(t)p_i(t)$\n$- s_i(t)p_i(t) \\sum_{k \\in ch[i]} a_k(t)w_{ki}(t)\u03c3' (\\sum_{j \\in pa[k]} w_{kj} (t)w_{kj} (t)\\xi_j(t) ) w_{ki}(t)p_k(t);$\nWe can promptly end up into the following proposition:"}, {"title": "7 Energy balance", "content": "Now we carry out a classic analysis on the energy balance coming from the interaction of the agent with the environment. We begin considering the contribution $H_t$. In case $s_i(t) = 1$ we have $H_\\xi \\cdot \\dot{\\xi} + H_p \\cdot \\dot{p} = 0$, which leads to $H = (d/dt)H = H_t$.\nDefinition 2. The terms\n$E := \\int_0^t \u03a6_\u03b9(\u03c4) V_{\\xi_\u03b9} (\\xi_\u03b9(\u03c4), \u03c4)d\u03c4$\n$D := D_E + D_B + D_a + D_w$\nare referred to as the environmental energy and the dissipated energy, respectively, where\n$D := -\\int_0^t \u03a6_\u03b5(\u03c4)V(\\xi_\u03b5(\u03c4), \u03c4)d\u03c4$\n$D= \\frac{1}{2} ( \\dot{w}_{ij}(\u03c4))^2d\u03c4$\n$D_a := -\\int_0^t \\sum_i a_i(\u03c4)p_i(\u03c4) [ - \\dot{\\xi_i}(\u03c4) + \u03c3(a_i(\u03c4))]d\u03c4$\n$D_w := -\\int_0^t \\sum_i a_i(\u03c4)p_i(\u03c4)\u03c3'(a_i(\u03c4)) \\sum_j w_{ij} (\u03c4)w_{ij} (\u03c4)\\xi_j (t)dt$\nThe dissipation energy arises because of the temporal changes of $a_i, w_{ij}, \u03c4_i, \u03a6_i$, even though the role of $w_{ij}$ is replaced with $\u03b2_{ij}$.\nTheorem 4. - I Principle of Cognidynamics\nThe system dynamics evolves under the energy balance\n$\u0395 = \u0394\u0397 + D$"}, {"title": "8 Gravitational neural networks", "content": "A fundamental problem that plagues neural network-based approaches to lifelong learning is that when attacking new tasks they typically offer no guarantees against catastrophically adapting learned weights that were already used for successfully solving previously learned tasks. While the proposed Hamiltonian learning scheme offers a truly new scheme of learning for recurrent neural networks, in principle, it shares this shortcoming with related gradient-based methods. The problem seems to have an architectural origin that certainly remains in dynamic neural networks. Furthermore, it is worth mentioning that the natural dynamic behavior suitable for the interpretation of cognitive processes is to continuously generate trajectories in the phase space. In other words, while some neurons can be deactivated, convergence to fixed points is not biologically plausible. It is very interesting to note that these needs are satisfied simply"}, {"title": "9 Conclusions", "content": "This paper focuses on the interpretation of natural learning in the optimization framework of dynamic programming which gives rise to Hamiltonian-Jacobi-Bellman equations. The paper promotes a collectionless approach to Machine Learning that strongly parallels what happens in nature and uses basic ideas that are massively adopted in Theoretical Physics. The system dynamics which drives the learning process is in fact dictated by Hamiltonian ODE, which turns out to parallel classic gradient descent methods in Statistical Machine Learning.\nThe most important contribution of the paper is that of addressing the longstanding questions on the stability of learning in recurrent neural networks, and to show that the answer comes from the introduction of an appropriate law which drives the control of dissipative weights. The proposed mathematical framework offers the appropriate tools for understanding the exchange of energy between the agent and the environment and suggests that the process of dissipation decreases the entropy of the system, thus creating ordered structures. In particularly, it becomes clear that we need an appropriate developmental scheme which requires filtering the inputs coming from the environment for offering a well-posed formulation of learning.\nInterestingly, the adoption of the proposal Hamiltonian learning approach leads to also to a computational scheme that, unlike BPTT and RTRL, is local in both time and space.\nThe proposed theory makes use of the continuous setting of computation to interpret learning as the discovery of a stationary point of the cognitive action, which tightly parallels the interpretation of Newtonian laws in Mechanics. This facilitates the development of the main results of the paper and offers the substrate for investigating links with Developmental Psychology and Neuroscience. However, we are mostly planning to work towards the translation in the discrete setting of computation of the proposed learning approach, which is in fact quite straightforward. It can open the doors to any application of Machine Learning involving time, where the emphasis is moved to the collectionless approach joined with the central role of focus of attention."}, {"title": "A HJB equations", "content": "Let us consider of the Value Function V : [0,T] \u00d7 X \u2192 R : (t,\u00a7) \u2192 V(t, x)\n$V(t, x) := J_T + \\min_w \\int_t^T ds L(\\xi(s), w(s), s).$\nHere, \u00a7(s) is the trajectory in [t, T] driven by\n$\\dot{\\xi}(s) = f(\\xi(s), w(s), s)$\nwhich begins with \u00a7(t) = x. Function V is sometimes also referred to as the cost-to-go. Here $J_T \\geq 0$ is the final value that might be regarded as\n$J_T = \\int_t^T ds L(\\xi(s), w(s), s)$.\nBasically, the introduction of $J_T$ leads to consider the special case in which T = \u221e when there exists the integral $V(t, x) := \\min_w \\int_t^\u221e ds L(\\xi(s), w(s), s)$. We begin with a couple of premises on (f, L) that are very important in the following.\n\u2022 The mentioned case of Mechanics is a classic example in which the action, in general, does not admit minimum.\n\u2022 Function f and L are supposed to be continuous and differentiable with respect to x,w whereas we make no assumption on the continuity with respect to t.\nThe optimum is determined by using Bellman's principle. We consider the general case in which \u0192 and L posses analytical regularities only with respect to x, that is we assume that f(x, w,t) and L(x, w,t) admit continuous partial derivates with respect to x only. In particular we assume that w and t only posses a finite number of discontinuities and that $f(x, w, t), L(x, w, t)$ are always bounded in [0,T]. Under this assumption we can always grid [0,T] in such a way that the mentioned discontinuities correspond with nodes in the grid.\nGiven At > 0, we want to see the relationship between the value function at t and at t + At, where the optimal value on the trajectory x* is correspondently moved to x* + \u2206x*. We have\n$V(t, x^*) = \\min_{w([t,T])} (V(t + \u0394t, x + \u0394x) + \\int_{t}^{t+\u0394t} ds L(x(s), w(s), 5))$"}, {"title": "B Method of characteristics", "content": "The HJB approach to optimization assumes that one knows the boundary conditions at the end-point of the interval. Unfortunately, in that form, they are neither useful for conception nor for the understanding of learning schemes Now we will shown that classic Hamiltonian dynamics that satisfies the HJB equations for time-independent Hamiltonians also works for the general case of time-variant Hamiltonians.\nHAMILTONIAN DYNAMICS IS SUFFICIENT\nLet us consider the following (HJ) initial-point problem\n(HJ)\n$V(t,x) + H(x, V_x(t,x,t)) = 0.$\n$V(0,x) = g(x).$\nWe want to convert this PDE problem into an ODE that can open a dramatically different computational perspective. We use the method of characteristic. Now, let us introduce the co-state p as $p := V_x$ and consider the total derivative of its coordinate\n$p_k(t) = V_{xxt}(t, x(t)) + V_{xxi}.\\dot{x_i}.$"}, {"title": "C Hamiltonian equations and Lagrangian multipliers", "content": "A possible way to attack optimization under constraints is to use the Lagrangian approach and find the stationary points of\n$J_L = J_T + \\int_0^T dt (L(x(t), w(t),t) + \u03bb(t). (f(x(t), w(t), t)) - \\dot{x(t)}))$.\nWe introduce the Hamiltonian on the optimal trajectory by setting\n$H(x(t), \u03bb(t), w(t),t) := L(x(t), w(t), t) + \u03bb(t) \u00b7 f(x(t), w(t), t),$\nin such a way to re-write $J_L$ as\n$J_L(x, \u03bb) = J_T + \\int_0^T dt (H(x(t), \u03bb(t), w(t),t) - \u03bb(t) \u00b7 \\dot{x(t)})$.\nNow, in order to determine a stationary solution of $J_L$, if we use by part integration, we can promptly see that we can replace $\\dot{\u03bb}(t) \u00b7 \\dot{x(t)}$ with $\u2212\\dot{\u03bb}(t) \u00b7 x(t)$. We have\n$\\int_0^T dt \u03bb(t) \\dot{x(t)} = [\u03bb(t) x(t)]^T_0 - \\int_0^T dt \\dot{\u03bb(t)} x(t)$\nHence we reformulate the problem of determining the stationary solution of\n$J_L(x, \u03bb) = J_T- [\u03bb(t)x(t)]^T_0 + \\int_0^T dt(H(x(t), \u03bb(t), w(t), t) + \\dot{\u03bb(t)} \u00b7 x(t)).$\nWhen using the Euler-Lagrange equations on functional $J_L$ it is convenient to use both its representations given by eq. (43) and eq. (44). We get\n$0 = \\frac{d}{dt}\\frac{\\delta}{\\delta \\dot{x}}L-\\frac{\\delta}{\\delta x}L (t)+ H_x(x(t), \u03bb(t), w(t), t) = 0$\n$0 = \\dot{\u03bb(t)} - H_x(x(t), \u03bb(t), w(t), t) = 0$\n$0 = \\frac{d}{dt}\\frac{\\delta}{\\delta \\dot{\u03bb}}L-\\frac{\\delta}{\\delta \u03bb}L - H_z(x(t), \u03bb(t), w(t), t) = 0.$\nClearly, the last equation can also be found by using $\\frac{\\delta}{\\delta x}L$. The third condition leads to marginalize w. In particular, when the stationary point corresponds with a minimum we have\n$H(x, x, t) = \\min_w H(x, \u03bb, w, t)$.\nFinally, this leads to the Hamiltonian equations\n$\\dot{\u03bb(t)} = -H_x(x(t), \u03bb(t), t)$\n$\\dot{x(t)} = \u2212H_\u03bb(x(t), \u03bb(t), t).$"}, {"title": "D Links with Analytic Mechanics", "content": "Let us consider the following causal optimization\n$\\dot{x} = \u03c5$\n$L(x, \u03c5) = \\frac{1}{2} m\u03c5^2 + V(x)$\nwhere v is regarded as the control variable. Then we can determine the Hamiltonian by defining $H(v) = \\frac{1}{2} m\u03c5^2 + V(x)+p\u03c5$. Now, the minimum is achieved for $v = -p/m$ and, therefore, we have $H = V(x) \u2013 p^2/2m$. Let us see the outcome of causal optimization $s = -1$. We have\n$\\dot{x} = H_p = \\frac{p}{m}$\n$\\dot{p} = H_x = V_x$,\nfrom which we get the Newtonian equations\n$\\ddot{x} = \\frac{\\dot{p}}{m} = \\frac{V_x}{m} \u2192 m\\ddot{x} + V = 0$.\nNow we want to see how the temporal evolution of the Hamiltonian. If we consider the classic Lagrangian $L(x,v) = 1/2 \u00b7 mv^2 \u2013 V(x)$ then $H(x,p) = p^2/2m + V(x)$ and we know that\n$\\frac{dH}{dt} = [H, H] = 0$.\nWhen offering the interpretation of causal optimization we have\n$\\frac{d}{dt}H(x,p,t) = H_x\\dot{x} + H_p\\dot{p} + H_t = 2p \u00b7 \\dot{x} + H_t$"}]}