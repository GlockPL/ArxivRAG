{"title": "Brain-inspired Artificial Intelligence: A Comprehensive Review", "authors": ["JING REN", "FENG XIA"], "abstract": "Current artificial intelligence (AI) models often focus on enhancing performance through meticulous parameter tuning and optimization techniques. However, the fundamental design principles behind these models receive comparatively less attention, which can limit our understanding of their potential and constraints. This comprehensive review explores the diverse design inspirations that have shaped modern AI models, i.e., brain-inspired artificial intelligence (BIAI). We present a classification framework that categorizes BIAI approaches into physical structure-inspired and human behavior-inspired models. We also examine the real-world applications where different BIAI models excel, highlighting their practical benefits and deployment challenges. By delving into these areas, we provide new insights and propose future research directions to drive innovation and address current gaps in the field. This review offers researchers and practitioners a comprehensive overview of the BIAI landscape, helping them harness its potential and expedite advancements in AI development.", "sections": [{"title": "1 INTRODUCTION", "content": "A fundamental goal of artificial intelligence (AI) is to create machines that can learn and think like humans. In pursuit of this goal, artificial learners have achieved remarkable milestones across various domains, including object and speech recognition [131, 151], image processing [115], robotics [50], medical data analysis [161], natural language processing (NLP) [114], and more. These successes have accelerated the progress of AI to the point where it can rival and even surpass humans in certain areas. For instance, AI models now outperform humans in specific tasks such as language translation [134], image recognition [63], and even strategic games like chess and Go [155]. More recently, a new family of multimodal models, capable of image, audio, video, and text understanding similar to those of humans have been proposed by many companies [3, 7, 169]. This rapid progress underscores Al's transformative potential across diverse fields, pushing the boundaries of what technology can achieve. However, general AI approaches, which aim to create machines capable of human-like thought and reasoning, still have limitations in terms of scalability, robustness, energy efficiency, interpretability, learning efficiency, and adaptability [98].\nHuman brain, which is acknowledged as the most sophisticated information processing system, is capable of solving complex tasks such as learning, reasoning, and perception. Based on recent advancements in the study of the human brain, researchers are integrating neuroscience insights into AI systems. They aim to develop Brain-Inspired Artificial Intelligence (BIAI) systems that can perceive, reason, and act in ways more akin to human behavior [128, 163]. This endeavor is rooted in the desire to understand the underlying principles of biological intelligence and to harness them for building more intelligent, adaptive, and robust Al systems.\nWhat is BIAI? BIAI refers to AI systems and algorithms that take inspiration from the biological structure, function, and principles of the human brain and neural system. It focuses on replicating or imitating the complex processes and functionalities observed in biologies to achieve more human-like or brain-like behavior in artificial systems [197]. Compared with general AI algorithms, BIAI typically concentrates on specific aspects of human behavior, such as learning from experience, adapting to new environments, and paying attention to important information."}, {"title": "1.1 Motivation", "content": "The human brain is the pinnacle of biological complexity. It not only regulates all bodily functions and processes but also enables advanced cognitive abilities such as thinking, memory, and emotion [16]. Integrating neuroscience with Al system can help solve many pressing issues and certain bottlenecks in various real-world applications [204]. On the one hand, the human brain is remarkably efficient in processing vast amounts of information while consuming relatively low amounts of energy. Mimicking its architecture and processes can lead to AI systems that are similarly efficient and elegant in their operations. For example, traditional robots cannot acquire timely environmental knowledge in complex environments, which limits its capacity of making accurate and fast decisions. Additionally, issues such as low learning efficiency, poor generalization, difficulty in developing goal-oriented strategies, and slow adaptation to dynamic environments still persist in this area. Integrating BIAI into robotic systems can dramatically improve robotic motion and manipulation capabilities [132]. Moreover, BIAI can also be applied into solving many other real-world problems, such as medical diagnostics, self-driving cars, chatbots and virtual assistant, cyber threat detection, tutoring systems, supply chain optimization, content creation, and personalized recommendations. These applications highlight the broad impact and relevance of BIAI in different aspects.\nOn the other hand, understanding the brain's mechanisms not only provides insights into how intelligence emerges but also offers clues for solving complex problems in AI. By studying biological neural networks, researchers can develop algorithms and architectures that better capture the intricacies of cognition and perception. For instance, neural networks, one of the foundational and fundamental models in AI, draw inspiration from the brain's structure and computational processes. As a cornerstone of modern AI, neural networks power"}, {"title": "1.2 Related Surveys and Novelty", "content": "Previous works cover similar topics within the scope of brain-inspired/brain-like learning or computing [62, 74, 132, 149], but none focused on the specific knowledge that neuroscience brought to AI models and introduced BIAI systems comprehensively and in detail. In [132], the authors seek to summarize the advancements in brain-inspired algorithms for intelligent robots, delving into key areas such as visual cognition, emotion-modulated decision making, musculoskeletal robotics, and motion control. Ou et al. [122] provided an introduction to brain-like computing models and chips, their evolution history, common application scenarios, and future prospects. Hassabis et al. [62] explored the historical connections between AI and neuroscience, and examined recent advancements in AI that are inspired by research into neural computing in both humans and other animals. In [106], the authors demonstrated how machine learning and neural networks have transformed the fields of animal behavior and neuroimaging research. As for brain-inspired learning in ANNs, the biological basis and algorithm introduction can be found in [149]. This comprehensive review mostly focused on introducing how to learn from the physical structure of human brain. None of them noticed and reviewed AI models that were inspired by human behaviors and learning mechanism. Moreover, they have not comprehensively discussed which part of human brain and nervous system AI can learn to design models.\nIn this review, we mainly answer the following questions: What is BIAI? What's the difference between BIAI and general AI? What advantages can BIAI bring to us? Which perspectives of human brain can we learn to design Al models? What kind of BIAI models have been used in the real world? Which research areas could be further promoted by introducing BIAI? What challenges are researchers facing when integrating neuroscience with Al models? What kind of gaps are existing in the current BIAI technologies and are there any works can be done in the future? By answering these questions, we hope that researchers could increase their understanding of BIAI systems and enhance their ability to design more suitable BIAI algorithms for different applications."}, {"title": "1.3 Contributions", "content": "The coverage of this paper is shown in Fig. 1. Our main contributions are summarized as follows:\n\u2022 We introduce knowledge and insights from neuroscience and human behavior research, highlighting how AI can learn from the neural architecture, learning mechanisms, attention and focus, memory and recall, cognitive process, and creativity and imagination observed in the human brain.\n\u2022 We categorize BIAI studies into two main types: physical structure-inspired models and human behavior-inspired models, providing a framework for understanding different approaches in the field.\n\u2022 We explore diverse applications of BIAI models, including their use in robotics, healthcare, emotion perception, and creative content generation, showcasing the broad potential of these models across various domains.\n\u2022 We discuss the challenges faced in the development and implementation of BIAI, such as understanding brain functionality, integrating with neuroscience, and building efficient, robust, ethical, conscious, and interpretable models. We also outline future research directions to address these challenges."}, {"title": "2 AI LEARNING FROM HUMAN BRAIN", "content": "In this section, we explore the inspiration source of AI models that they may refer to when designing algorithm structures. These inspirations are mainly acquired by learning knowledge from neuroscience and human behavior research. Detailed techniques of existing BIAI models will be introduced in the next section. From the previous introduction, it is evident that the human brain, being the most intricate and extraordinary organ in the body, offers numerous strengths for Al models to learn from. According to our tentative understandings of how human brain controls the bodily functions and processes, Al models may be inspired from: the neural architecture, learning mechanism, attention and focus, memory and recall, cognitive process, and creativity and imagination capacity of human brain. It should be noted that the brain possesses numerous mechanisms and processes, including many that humans have yet to discover, all of which hold potential for developing advanced AI models. Here, we will introduce several aspects that have been studied in neuroscience."}, {"title": "2.1 Neural Architecture", "content": "The neural architecture of the human brain provides the foundational blueprint for many AI models. At its core, the brain comprises billions of interconnected neurons. These specialized cells exchange information using electrical and chemical signals. Neurons interconnect to create complex networks that underpin perception, learning, memory, decision-making, and other cognitive functions. A notable feature of the brain's architecture is its capacity for plasticity-its ability to adapt and reorganize in response to new stimuli and experiences [36]. This adaptability is crucial for how AI models learn from the brain.\nDeep neural networks (DNNs) employ a hierarchical structure, stacking layers of artificial neurons to emulate the brain's neural organization [88]. Each layer processes and transforms information before passing it to the next layer, similar to the brain's network of neurons. Connections between artificial neurons, akin to synapses in the brain, are assigned weights that determine the influence of one neuron on another. These weights are adjusted during the learning process, much like how the brain refines its understanding through environmental interactions. DNNs receive feedback in the form of error signals or rewards, depending on the learning paradigm [143], which helps the model adjust its parameters to minimize errors or maximize rewards. DNNs underpin many popular Al models. For example, convolutional neural networks (CNNs) are modeled after the brain's visual processing pathways [89], and recurrent neural networks (RNNs) draw on the brain's sequential processing capabilities [43]."}, {"title": "2.2 Learning Mechanism", "content": "The human brain's learning mechanism is a sophisticated and adaptive system involving perception, memory formation, decision-making, and other cognitive processes. A key principle underlying learning in the brain is neural plasticity [184]. This concept describes the brain's remarkable ability to modify its neural connections and functions in response to new experiences and stimuli. Neural connections can be strengthened or weakened, new connections can be established, and existing ones can be eliminated based on activity patterns. Al models emulate this process by adjusting the weights between artificial neurons according to patterns found in training data. This adjustment process, known as training or learning, involves updating the model's parameters to reduce errors or enhance rewards [155].\nBesides, the brain encodes information in a hierarchical and distributed manner. Complex ideas are built upon simpler ones, with information spread across different brain regions. AI models, especially DNNs, use analogous principles of representation learning to understand data hierarchically. Lower layers of these models identify basic patterns, while higher layers interpret more abstract concepts [17]. Techniques such as transfer learning and unsupervised learning mimic this brain-like learning process. Transfer learning leverages knowledge acquired from one task to enhance performance on a related but distinct task. Unsupervised learning allows models to learn from data that is either unlabeled or only minimally supervised. Both techniques improve the model's generalization capabilities and reduce the dependency on extensive labeled datasets."}, {"title": "2.3 Attention and Focus", "content": "The attention and focus of the human brain are crucial cognitive mechanisms that allow us to selectively process information, allocate mental resources, and concentrate on specific tasks or stimuli while ignoring distractions [142]. Understanding how attention works in the brain has inspired the development of attention mechanisms in AI models, especially in the realm of deep learning. The human brain can attend to multiple aspects of information simultaneously, a capability known as parallel or multi-head attention. This allows us to process complex stimuli and perform multiple tasks in parallel to some extent. Al models employ multi-head attention mechanisms to simultaneously attend to different parts or features of the input data. By splitting the attention mechanism into multiple heads, models can capture diverse aspects of the input and integrate information from multiple sources, improving robustness and performance [180].\nHuman attention is dynamic and adaptive, meaning it can shift rapidly in response to changing task demands, environmental cues, and internal states. Al models learn dynamic and adaptive attention mechanisms through training on diverse datasets and learning from feedback signals. Reinforcement learning techniques can be used to train models to adaptively allocate attention based on rewards or task performance, enabling them to learn optimal attention strategies over time [166]. Inspired by the human brain's attentional focus, AI researchers have developed sophisticated attention mechanisms. These mechanisms significantly enhance the performance and interpretability of AI models across various applications [139]."}, {"title": "2.4 Memory and Recall", "content": "The human brain comprises multiple memory systems [9]. Sensory memory temporarily holds sensory information from the environment and acts as a buffer for stimuli received through sight, hearing, touch, smell, and taste. Short-term memory serves as a temporary storage system with limited capacity, maintaining information that is readily accessible for immediate use. Long-term memory is responsible for storing information for extended periods, potentially without limit. AI models can emulate these memory systems using various architectures and mechanisms. For example, RNNs and transformers employ recurrent connections and attention mechanisms to model short-term dependencies and long-term context in sequential data, enabling the retention and retrieval of information over time.\nRecall refers to the process of accessing and retrieving information stored in memory. It can occur spontaneously or be triggered by external cues or internal associations. AI models perform recall and retrieval by accessing stored representations through inference or query mechanisms [83]. Memory-based architectures, such as memory networks and neural Turing machines, enable models to retrieve relevant information from memory based on input queries or context. By drawing inspiration from the memory and recall mechanisms of the human brain, Al researchers have developed memory-augmented architectures and learning algorithms that enhance the capabilities of AI models in storing, retrieving, and leveraging information over time. Long-Short-Term Memory (LSTM) neural networks [67] are among the most commonly used memory models in AI."}, {"title": "2.5 Consciousness", "content": "While consciousness remains a subject of philosophical and scientific exploration, it is closely tied to cogni-tive processes like attention, memory, decision-making, and self-awareness [143]. Although AI models do not experience consciousness as humans do, they can leverage aspects of conscious processing to enhance their performance and capabilities. Consciousness supports social cognition, including the ability to understand and predict others' mental states, beliefs, and intentions. This is known as the theory of mind, which facilitates social interactions and empathy.\nAl models can draw from social cognition and theory of mind to create more human-like interactions and behaviors in social contexts. Techniques like sentiment analysis and empathy modeling allow models to interpret and respond to users' emotional states and intentions, thereby improving human-AI interactions [183]. While AI does not possess consciousness per se, learning from the principles of conscious processing can lead to more sophisticated and effective models and algorithms. By incorporating these cognitive processes, researchers aim to develop AI systems with increasingly advanced behaviors and interactions."}, {"title": "2.6 Creativity and Imagination", "content": "The creativity and imagination of the human brain are remarkable cognitive abilities that enable us to generate novel ideas, insights, and solutions, as well as to envision hypothetical scenarios and possibilities [176]. Creativity often involves the ability to combine existing concepts, ideas, or elements in novel and unexpected ways. The human brain achieves this by flexibly manipulating and recombining mental representations. Al models learn from flexible representation learning techniques that enable them to generate new and diverse outputs. Variational autoencoders (VAEs) [81], generative adversarial networks (GANs) [56], and transformers [153, 180] with self-attention mechanisms allow models to generate realistic and novel content by learning rich and structured representations of data.\nCreativity often involves emotional and aesthetic dimensions, such as appreciation of beauty, novelty, and emotional resonance. Emotions play a crucial role in guiding creative expression and evaluation. AI models learn from emotional and aesthetic dimensions of creativity through sentiment analysis, style transfer, and affective computing techniques. Models can generate content with desired emotional qualities, adapt to user preferences, and create aesthetically pleasing outputs [194]. Furthermore, creativity often involves making connections between seemingly unrelated domains or concepts, drawing analogies, and transferring knowledge from one context to another [200]. AI models learn from analogical reasoning and transfer learning techniques that enable them to generalize knowledge and skills across different domains. Transfer learning [123], few-shot learning [191], and meta-learning algorithms [157] allow models to transfer knowledge from related tasks or domains to new, unseen tasks, facilitating creativity and adaptability."}, {"title": "3 BRAIN-INSPIRED AI MODELS", "content": "In this section, we categorize existing BIAI techniques based on the specific brain-inspired mechanisms they incorporate. By drawing insights from neuroscience, we can apply this knowledge to computational modeling, which involves creating and implementing algorithms and systems that emulate the brain's structure and function. This process can be divided into two categories: models and algorithms inspired by the brain's physical architecture, and those inspired by human behavior. The introduction order of these techniques will mainly follow the order shown in Fig. 1."}, {"title": "3.1 Physical structure-inspired Al Models", "content": "Several prominent AI models seek to emulate the human brain's architecture and processes, leveraging neuro-science to develop more biologically plausible and powerful systems. Here are a few notable examples. We will only list the most representative models and their concepts in this section to help understand the theoretical basis and internal mechanism of these models."}, {"title": "3.1.1 Hierarchical Models", "content": "A representative mechanism of the PS-inspired model is to learn from the information processing meachanism of human brain. The human brain processes information in a hierarchical manner, with sensory inputs processed at lower levels and abstract concepts at higher levels. Learning from this process, DNNs where entities are organized into levels or layers, each layer representing different levels of abstraction or processing are designed. Representative hierarchical models include CNNs, Capsule Networks (CapsNets), RNNs, Echo State Networks (ESNs), and Deep Belief Networks (DBNs). Considering that these models are the most basic models that have been used in different algorithms, we only introduce the basic concepts and how they are inspired by human brain. As for the characteristics, realization, equations, and real application scenarios of these models, we refer readers to [86, 185, 205] for more details.\nCNNs are a specialized type of ANNs designed for processing structured grid data. The concept was inspired by the work of biologists Hubel and Wiesel, who conducted pioneering research on the visual cortex of the cat brain [76]. They discovered the phenomenon known as receptive field mechanisms: neurons in the primary visual cortex respond to specific features in the visual environment. Hubel and Wiesel identified two types of cells: simple cells respond strongly to specific spatial positions and orientations, while complex cells have larger receptive fields and remain responsive even when the position of the features shifts slightly.\nWhen we view an image, our attention is initially drawn to the most prominent and informative local features. For instance, in a picture of a pet dog, our eyes typically focus on the dog first, noticing its face, legs, and other distinct parts. Based on our experience, we recognize that it is a picture of a dog. CNNs emulate this principle of the human visual system. Initially, a CNN identifies low-level features by detecting edges and curves within the image. Through a series of convolutional layers, these low-level features are gradually combined into more complex, high-level features [85]. Since high-level features are composed of multiple low-level feature convolutions, they encapsulate more comprehensive information from the original image.\nCNNs use convolutional layers to apply filters to input data, extracting hierarchical features like edges, textures, and shapes. This enables CNNs to effectively capture spatial dependencies and patterns within the data. Following these layers, pooling layers reduce the spatial dimensions, which helps manage computational complexity and mitigate overfitting. The integration of these layers, along with fully connected layers at the end, enables CNNs to excel in tasks such as object detection, segmentation, and image classification, establishing them as a fundamental component of modern computer vision applications [94]. However, CNNs also face challenges [84], including the need for large labeled datasets to achieve high performance, high computational costs, and the potential loss of valuable spatial information due to pooling layers. Additionally, CNNs can struggle with understanding spatial hierarchies and complex part-whole relationships, which has led to the development of alternative architectures like capsule networks to address these limitations.\nCapsNets, proposed by Geoffrey Hinton and his team in 2017 [145], aim to challenge the traditional CNN architecture by addressing a critical flaw in CNNs: the use of pooling layers. Hinton argues that pooling, particularly max pooling, is a significant mistake despite its widespread success. The max pooling process discards valuable spatial information by only passing the most active neurons to the next layer, leading to a loss of crucial details between layers. CapsNets aim to preserve this spatial hierarchy, offering a more nuanced understanding of the relationship between parts and wholes in an image, thereby potentially improving performance on tasks requiring precise spatial information.\nCapsNets use capsules, which are neuron groups encoding both the probability of an entity's presence and its properties, thereby preserving more detailed spatial information. This leads to better generalization and robustness, especially in tasks involving viewpoint variations and part-whole relationships. However, CapsNets also face challenges [40], such as higher computational complexity and the need for more sophisticated training algorithms, which can make them less efficient and harder to implement compared to CNNs. Additionally, the field is still developing, and practical applications and optimizations are ongoing areas of research.\nCapsNets can preserve spatial hierarchies and relationships within data, making them effective in various applications. One notable application domain is medical imaging [196], where CapsNets have demonstrated improved accuracy in tasks such as tumor detection and organ segmentation by maintaining spatial integrity of anatomical structures. In computer vision, CapsNets are used for image classification and object recognition, providing better robustness to affine transformations compared to traditional CNNs [127]. Additionally, they are being explored in NLP tasks like sentiment analysis and entity recognition, benefiting from their capability of capturing complex relationships within sequences of text. These applications highlight the potential of CapsNets to enhance the performance and reliability of machine learning models in diverse and complex domains.\nRNNs are built to process sequential data by retaining internal memory states. They are inspired by the human brain's ability to process sequences of information and retain memory over time [96]. Just as our brain remembers previous experiences and uses them to understand current events, RNNs use their internal memory to process and remember information from previous steps in a sequence. For example, consider how we understand a sentence. When reading the sentence \"the cat sat on the mat,\" our brain doesn't start from scratch with each word. Instead, it retains the context provided by earlier words to make sense of the entire sentence. We remember \"the cat\" as we read \"sat on the mat\", allowing us to understand the sentence's meaning in context.\nSimilarly, RNNs manage sequences by maintaining a hidden state that stores information from earlier steps. With each new step, the RNN updates this hidden state by incorporating both the current input and the hidden state from the previous step. This mechanism allows RNNs to retain context and make informed predictions or decisions based on the entire sequence of data. For instance, RNNs can be used for language translation. When translating a sentence from English to French, an RNN processes the English words one by one, retaining the context of the entire sentence. This context helps RNN generate the correct translation in French, even for complex sentence structures where the relationship between words must be understood in sequence. LSTM [67] and Gated Recurrent Unit (GRU) [34] are advanced RNN architectures developed to address the vanishing gradient problem. They enable the effective capture and utilization of long-range dependencies in sequential data.\nRNNs have found numerous real-world applications due to their ability to process and analyze sequential data. In the field of NLP, for instance, RNNs drive advances in machine translation, sentiment analysis, language modeling, and many other applications [114], enabling more accurate, context-aware text generation and interpretation. In the speech recognition domain, RNNs are used to convert spoken language into written text, enhancing the functionality of virtual assistants [147]. In finance, RNNs help in predicting stock prices and analyzing market trends by processing time series data [144]. Additionally, RNNs are employed in healthcare for early diagnosis by analyzing patient history [129] and in video analysis for understanding and predicting sequences of frames [46], making them invaluable in diverse fields that require sequence prediction and temporal pattern recognition.\nDBNs are generative models composed of stacked Restricted Boltzmann Machines (RBMs). These models learn layer-by-layer through unsupervised techniques like contrastive divergence [65]. Information from sensory inputs is processed through multiple stages, with each stage extracting more abstract and complex features from the input. Similar to human brain, DBNs process data through multiple layers, with each layer learning increasingly complex representations. DBNs are used for tasks such as unsupervised feature learning, dimensionality reduction, and collaborative filtering.\nThanks to their capacity to learn complex representations from big data, DBNs have been utilized in numerous real-world applications. In speech recognition, for example, DBNs have been used to enhance transcription accuracy by learning hierarchical audio features [118]. In image recognition, they are used to enhance object detection and classification tasks by capturing intricate patterns and textures in images [2]. In NLP, DBNs help in understanding and generating human language, improving the performance of sentiment analysis and other tasks [148]. Additionally, DBNs are applied in recommendation systems, where they analyze user behaviors and preferences to suggest relevant content or products [190]. Their ability to model deep, layered representations makes DBNs valuable in any domain requiring sophisticated data interpretation and prediction.\nThese hierarchical models have many advantages [99]. Firstly, DBNs can autonomously learn rich hierarchical features from unlabeled data. This eliminates the need for manual feature extraction. Secondly, by extracting abstract features layer by layer, DBNs effectively capture the deep structure of data, which is beneficial for handling complex, high-dimensional problems. Thirdly, the pretraining phase helps in escaping local optima and provides a good initialization for subsequent fine-tuning. However, implementing hierarchical models can be challenging due to the complexity of designing and training multi-level architectures. DBNs consist of multiple layers of RBMs, and the training process involves multiple iterations of contrastive divergence, which is computationally intensive and has a slow convergence rate. Additionally, deep networks are prone to overfitting, especially when the amount of data is limited. It is necessary to employ strategies such as regularization and early stopping to prevent overfitting. As a deep generative model, the decision-making process of a DBN is difficult to understand and lacks intuitive interpretability."}, {"title": "3.1.2 SNNs", "content": "Spiking neural networks depart from traditional neural networks by modeling neurons as spiking units, aligning more closely with the brain's computational mechanisms [167]. They belong to the third generation of neural network models, achieving a more advanced level of biological neural simulation.\nSNNs use discrete events called spikes to represent neuron activations. These spikes are initiated when a neuron's membrane potential attains a critical threshold, closely replicating the mechanism of action potentials in biological neurons. SNNs can be distinguished from traditional DNNs in four key aspects [188]: 1. SNNs employ temporal encoding, representing information as spike trains, while DNNs use rate encoding, converting data into scalar values. This temporal encoding grants SNNs superior capabilities for handling complex temporal or spatiotemporal data. 2. SNNs are built upon spiking neurons modeled by differential equations, contrasting with the artificial neurons and activation functions used in DNNs. Moreover, SNN simulations often leverage clock-driven or event-driven approaches, differing from DNNs' step-by-step method. 3. SNNs adopt spike-timing-dependent plasticity (STDP) for synaptic learning, departing from DNNs' reliance on the Hebbian rule. Training methodologies also vary, with SNNs exploring diverse techniques compared to DNNs' predominant use of loss function derivatives. 4. SNNs excel at rapid, parallel processing due to their discrete spike-based computations, offering potential energy efficiency advantages over DNNs' analog-like operations [48].\nThe inspiration for SNNs comes from the way the human brain processes information [52, 198]. In the brain, neurons communicate via electrical impulses or spikes, which encode information through the timing and frequency of these spikes. This spiking mechanism allows for highly efficient and precise information processing. SNNs attempt to replicate this by using similar spiking mechanisms to transmit information between artificial neurons. This leads to potentially more efficient computing, especially in tasks involving temporal patterns and sequences, such as speech and motion recognition. By capturing the temporal dynamics of neural processing, SNNs aim to achieve more powerful and efficient models for complex tasks [206]. SNNs can also leverage spiking behavior for real-time processing, making them suitable for applications in robotics and neuromorphic computing [90]. However, SNNs face several challenges, including the complexity of designing and training models as spiking neurons are non-differentiable by nature, which complicates the use of traditional gradient-based optimization methods [26]. Additionally, there is a lack of mature software and hardware infrastructure compared to more established neural network models, making practical implementation and scaling of SNNs more difficult [201]. Despite these challenges, ongoing research aims to harness the potential of SNNs for advanced AI applications."}, {"title": "3.2 Human behavior-inspired Al Models", "content": "There are also many AI models inspired by human behaviors and cognitive processes in several ways. The learning mechanisms of these models usually leverage insights from cognitive psychology, neuroscience, and behavioral science to create more effective and intelligent systems. Instead of introducing the specific models, we only summarize and classify the most popular learning mechanisms of these models in recent years. In each learning paradigm, we select a representative situation to concrete and better understand the internal operating mechanisms of these models."}, {"title": "3.2.1 Machine Unlearning", "content": "It involves selectively removing the influence of specific data points from a trained machine learning model. It can be used to protect users' privacy when they want their data forgotten by a trained machine learning model. Instead of simply erasing their data from database, the deletion needs to eliminate the contribution of the erased training data from the already trained model, which process was first defined as machine unlearning [186]. To better understand how unlearning mechanisms work, we first introduce the unlearning problem and process following the machine unlearning framework demonstrated in Fig 2. Assuming that a model M is trained on the dataset D with algorithm A, this could be denoted as\n$M = A(D),                                                                              \\qquad(1)$\nwhere $D \\in Z$. Here, Z is the space of data items and model M is in a hypothesis space H. If a user wants to remove his data $D_e$ from the trained model, then the server removes the contribution of $D_e$ using a machine unlearning algorithm U, which is denoted as\n$M_{D\\backslash D_e} = U(D, D_e, A(D)).                                                                               \\qquad(2)$\nAfter providing an unlearning request, the unlearned model $U(D, D_e, A(D))$ is expected to be same as the retrained model $A(D \\backslash D_e)$. The evaluation distance metrics in the verification process are diverse, including\n$L_2-norm = ||\\theta_{A(D\\backslash D_e)} - \\theta_{U(D,D_e,A(D))} ||,                                                                              \\qquad(3)$\nand\n$KL-Divergence = KL[\\theta_{A(D\\backslash D_e)}||\\theta_{U(D,D_e,A(D))}],                                                                              \\qquad(4)$\nwhere $\\theta_{A(D\\backslash D_e)}$ is the model parameters of retraining from the scratch and $\\theta_{U(D,D_e,A(D))}$ is the parameters of unlearning algorithms $U(\\cdot)$.\nThis technique is crucial for addressing privacy concerns, correcting errors, and maintaining model relevance as data evolves. By effectively \"forgetting\" certain data, models can comply with privacy regulations, such as General Data Protection Regulation (GDPR) [108]. Machine unlearning enhances model efficiency and fairness by ensuring that outdated, incorrect, or biased data does not negatively impact predictions [175], while avoiding the computational cost and time required for complete model retraining.\nThe theoretical foundation of machine unlearning is inspired by the brain's ability to selectively forget and rewire neural connections, a process known as synaptic pruning [186]. This mechanism enables the brain to maintain cognitive efficiency by removing less useful or redundant information, thereby optimizing memory storage and retrieval. Similarly, machine unlearning seeks to enhance machine learning models by selectively eliminating the impact of particular data points, ensuring that the model remains efficient and accurate without being burdened by obsolete or incorrect information. This parallel to human cognitive processes highlights the importance of adaptability and memory management in both biological and artificial systems.\nMost machine unlearning models are designed to delete regularly structured data, aiming primarily to reduce computation and storage costs while minimizing performance degradation. Recently, some researchers have also focused on achieving unlearning in scenarios involving irregular data, such as graph unlearning [29]. Graph-structured data are more complex than standard structured data because they encompass not only the feature information of individual nodes but also the connectivity information inside edges between different nodes [137]. The first step in general process of graph unlearning is to cut off some connecting edges to split the graph into several sub-graphs. Then, the constituent graph models could be trained on these subgraphs respectively, and ensemble them for final prediction. As for the knowledge unlearning of a specific node, a method to efficiently remove node features by projecting model parameters onto an irrelevant subspace has been proposed [35]. In this model, challenges caused by node dependency could be solved, and the deleted node features are guaranteed to be unlearned from the pre-trained model."}, {"title": "3.2.2 Attention and Self-Attention Mechanism", "content": "In AI, the attention mechanism enables machine learning models to focus on relevant input data, leading to improved performance. Inspired by human cognitive processes [130], particularly selective attention in psychology, attention mechanisms allow models to dynamically prioritize different parts of input data. By assigning varying degrees of attention, typically through learned weights [120], the mechanism enables models to prioritize certain features or contextually relevant information while filtering out noise or irrelevant details. This adaptive focus not only improves the model's performance in terms of, e.g., accuracy and efficiency in many tasks like NLP, image recognition, and sequence prediction but also enhances its interpretability by revealing which parts of the input are most influential in generating predictions or outputs [70]. Despite that models inspired by the attention mechanism [11, 180] have been proposed and successfully applied into different scenarios, the mechanisms underlying consciousness are still not well understood. Creating Al that can mimic or exhibit conscious-like states is a profound challenge. For example, emotions are vital to decision-making and learning. However, the neural basis of emotions and their integration with cognitive processes is not fully understood. Grabbing knowledge of this process can help complete tasks like sentiment analysis, and emotion perception in robotics [38]."}, {"title": "3.2.3 Imitation Learning", "content": "It is a machine learning approach where agents learn tasks by copying expert behavior. This is often more efficient than trial-and-error, as it leverages expert knowledge to avoid exploring countless potential action sequences [22", "71": "."}]}