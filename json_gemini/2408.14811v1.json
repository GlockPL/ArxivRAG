{"title": "Brain-inspired Artificial Intelligence: A Comprehensive Review", "authors": ["JING REN", "FENG XIA"], "abstract": "Current artificial intelligence (AI) models often focus on enhancing performance through meticulous parameter tuning\nand optimization techniques. However, the fundamental design principles behind these models receive comparatively less\nattention, which can limit our understanding of their potential and constraints. This comprehensive review explores the\ndiverse design inspirations that have shaped modern AI models, i.e., brain-inspired artificial intelligence (BIAI). We present a\nclassification framework that categorizes BIAI approaches into physical structure-inspired and human behavior-inspired\nmodels. We also examine the real-world applications where different BIAI models excel, highlighting their practical benefits\nand deployment challenges. By delving into these areas, we provide new insights and propose future research directions\nto drive innovation and address current gaps in the field. This review offers researchers and practitioners a comprehensive\noverview of the BIAI landscape, helping them harness its potential and expedite advancements in AI development.", "sections": [{"title": "1 INTRODUCTION", "content": "A fundamental goal of artificial intelligence (AI) is to create machines that can learn and think like humans. In\npursuit of this goal, artificial learners have achieved remarkable milestones across various domains, including\nobject and speech recognition [131, 151], image processing [115], robotics [50], medical data analysis [161],\nnatural language processing (NLP) [114], and more. These successes have accelerated the progress of AI to the\npoint where it can rival and even surpass humans in certain areas. For instance, AI models now outperform\nhumans in specific tasks such as language translation [134], image recognition [63], and even strategic games like\nchess and Go [155]. More recently, a new family of multimodal models, capable of image, audio, video, and text\nunderstanding similar to those of humans have been proposed by many companies [3, 7, 169]. This rapid progress\nunderscores Al's transformative potential across diverse fields, pushing the boundaries of what technology can\nachieve. However, general AI approaches, which aim to create machines capable of human-like thought and\nreasoning, still have limitations in terms of scalability, robustness, energy efficiency, interpretability, learning\nefficiency, and adaptability [98].\nHuman brain, which is acknowledged as the most sophisticated information processing system, is capable of\nsolving complex tasks such as learning, reasoning, and perception. Based on recent advancements in the study\nof the human brain, researchers are integrating neuroscience insights into AI systems. They aim to develop\nBrain-Inspired Artificial Intelligence (BIAI) systems that can perceive, reason, and act in ways more akin to\nhuman behavior [128, 163]. This endeavor is rooted in the desire to understand the underlying principles of\nbiological intelligence and to harness them for building more intelligent, adaptive, and robust Al systems.\nWhat is BIAI? BIAI refers to AI systems and algorithms that take inspiration from the biological structure,\nfunction, and principles of the human brain and neural system. It focuses on replicating or imitating the complex\nprocesses and functionalities observed in biologies to achieve more human-like or brain-like behavior in artificial\nsystems [197]. Compared with general AI algorithms, BIAI typically concentrates on specific aspects of human\nbehavior, such as learning from experience, adapting to new environments, and paying attention to important\ninformation."}, {"title": "2 Ren and Xia", "content": "In this comprehensive review, the literature of BIAI is roughly divided into physical structure (PS)-inspired and\nhuman behavior (HB)-inspired models. PS-inspired models refer to models imitating the structure of biological\nneurons, synapses, and neural circuits to perform tasks such as learning, reasoning, and decision-making.\nRepresentative models include Multi-layer Perceptron (MLP), Artificial Neural Networks (ANNs), and more\nrecently, Spiking Neural Networks (SNNs). HB-inspired models are defined as models that replicate the biological\nmechanisms and processes observed in human behaviors. These models aim to capture the dynamics of biological\nsystems while providing insights into how human perceive, learn, adapt, and interact with the environment.\nAttention mechanism, transfer learning, and reinforcement learning are common deep learning methods inspired\nby human behaviors.\nDifferences between BIAI and general Al are manifested in different approaches and goals within the field\nof AI [31, 77]. Specifically, general AI is not necessarily inspired by the specific workings of the human brain\nbut aims to achieve or even surpass human-level intelligence in a broader sense. On the contrary, the aim of\ndesigning BIAI system is to replicate or mimic the biological mechanisms and processes underlying human\ncognition. These systems generally excel in tasks such as image recognition and robotic control, but they may\nnot necessarily possess the full spectrum of human intelligence. A more comprehensive comparision between\nBIAI and traditional Al is shown in Table 1.\nWhy is BIAI significant? BIAI holds significant importance mainly from two perspectives. On the one hand, BIAI\nhas the potential to outperform traditional AI approaches in many aspects, including adaptability, generalization,\nand interpretability. On the other hand, BIAI models aim to mimic the brain's structure and function, thereby\nincreasing their biological plausibility. This alignment with biological principles not only deepens our scientific\nunderstanding of intelligence but also fosters new opportunities for collaboration between neuroscience and AI\nresearch. In essence, by drawing inspiration from the human brain-the most advanced information processing\nsystem-researchers are setting the stage for the development of intelligent systems that could potentially match\nor even exceed human-level capabilities [47, 103, 125]."}, {"title": "1.1 Motivation", "content": "The human brain is the pinnacle of biological complexity. It not only regulates all bodily functions and processes\nbut also enables advanced cognitive abilities such as thinking, memory, and emotion [16]. Integrating neuroscience\nwith Al system can help solve many pressing issues and certain bottlenecks in various real-world applications [204].\nOn the one hand, the human brain is remarkably efficient in processing vast amounts of information while\nconsuming relatively low amounts of energy. Mimicking its architecture and processes can lead to AI systems\nthat are similarly efficient and elegant in their operations. For example, traditional robots cannot acquire timely\nenvironmental knowledge in complex environments, which limits its capacity of making accurate and fast\ndecisions. Additionally, issues such as low learning efficiency, poor generalization, difficulty in developing goal-\noriented strategies, and slow adaptation to dynamic environments still persist in this area. Integrating BIAI\ninto robotic systems can dramatically improve robotic motion and manipulation capabilities [132]. Moreover,\nBIAI can also be applied into solving many other real-world problems, such as medical diagnostics, self-driving\ncars, chatbots and virtual assistant, cyber threat detection, tutoring systems, supply chain optimization, content\ncreation, and personalized recommendations. These applications highlight the broad impact and relevance of\nBIAI in different aspects.\nOn the other hand, understanding the brain's mechanisms not only provides insights into how intelligence\nemerges but also offers clues for solving complex problems in AI. By studying biological neural networks,\nresearchers can develop algorithms and architectures that better capture the intricacies of cognition and perception.\nFor instance, neural networks, one of the foundational and fundamental models in AI, draw inspiration from\nthe brain's structure and computational processes. As a cornerstone of modern AI, neural networks power"}, {"title": "1.2 Related Surveys and Novelty", "content": "Previous works cover similar topics within the scope of brain-inspired/brain-like learning or computing [62, 74,\n132, 149], but none focused on the specific knowledge that neuroscience brought to AI models and introduced\nBIAI systems comprehensively and in detail. In [132], the authors seek to summarize the advancements in brain-\ninspired algorithms for intelligent robots, delving into key areas such as visual cognition, emotion-modulated\ndecision making, musculoskeletal robotics, and motion control. Ou et al. [122] provided an introduction to brain-\nlike computing models and chips, their evolution history, common application scenarios, and future prospects.\nHassabis et al. [62] explored the historical connections between AI and neuroscience, and examined recent\nadvancements in AI that are inspired by research into neural computing in both humans and other animals.\nIn [106], the authors demonstrated how machine learning and neural networks have transformed the fields of\nanimal behavior and neuroimaging research. As for brain-inspired learning in ANNs, the biological basis and\nalgorithm introduction can be found in [149]. This comprehensive review mostly focused on introducing how\nto learn from the physical structure of human brain. None of them noticed and reviewed AI models that were\ninspired by human behaviors and learning mechanism. Moreover, they have not comprehensively discussed\nwhich part of human brain and nervous system AI can learn to design models.\nIn this review, we mainly answer the following questions: What is BIAI? What's the difference between BIAI\nand general AI? What advantages can BIAI bring to us? Which perspectives of human brain can we learn to\ndesign Al models? What kind of BIAI models have been used in the real world? Which research areas could be\nfurther promoted by introducing BIAI? What challenges are researchers facing when integrating neuroscience\nwith Al models? What kind of gaps are existing in the current BIAI technologies and are there any works can be\ndone in the future? By answering these questions, we hope that researchers could increase their understanding\nof BIAI systems and enhance their ability to design more suitable BIAI algorithms for different applications."}, {"title": "1.3 Contributions", "content": "The coverage of this paper is shown in Fig. 1. Our main contributions are summarized as follows:\n\u2022 We introduce knowledge and insights from neuroscience and human behavior research, highlighting how\nAI can learn from the neural architecture, learning mechanisms, attention and focus, memory and recall,\ncognitive process, and creativity and imagination observed in the human brain.\n\u2022 We categorize BIAI studies into two main types: physical structure-inspired models and human behavior-\ninspired models, providing a framework for understanding different approaches in the field.\n\u2022 We explore diverse applications of BIAI models, including their use in robotics, healthcare, emotion\nperception, and creative content generation, showcasing the broad potential of these models across various\ndomains.\n\u2022 We discuss the challenges faced in the development and implementation of BIAI, such as understanding\nbrain functionality, integrating with neuroscience, and building efficient, robust, ethical, conscious, and\ninterpretable models. We also outline future research directions to address these challenges."}, {"title": "2 AI LEARNING FROM HUMAN BRAIN", "content": "In this section, we explore the inspiration source of AI models that they may refer to when designing algorithm\nstructures. These inspirations are mainly acquired by learning knowledge from neuroscience and human behavior\nresearch. Detailed techniques of existing BIAI models will be introduced in the next section. From the previous\nintroduction, it is evident that the human brain, being the most intricate and extraordinary organ in the body,\noffers numerous strengths for Al models to learn from. According to our tentative understandings of how human\nbrain controls the bodily functions and processes, Al models may be inspired from: the neural architecture,\nlearning mechanism, attention and focus, memory and recall, cognitive process, and creativity and imagination\ncapacity of human brain. It should be noted that the brain possesses numerous mechanisms and processes,\nincluding many that humans have yet to discover, all of which hold potential for developing advanced AI models.\nHere, we will introduce several aspects that have been studied in neuroscience."}, {"title": "2.1 Neural Architecture", "content": "The neural architecture of the human brain provides the foundational blueprint for many AI models. At its\ncore, the brain comprises billions of interconnected neurons. These specialized cells exchange information using\nelectrical and chemical signals. Neurons interconnect to create complex networks that underpin perception,\nlearning, memory, decision-making, and other cognitive functions. A notable feature of the brain's architecture is\nits capacity for plasticity-its ability to adapt and reorganize in response to new stimuli and experiences [36].\nThis adaptability is crucial for how AI models learn from the brain.\nDeep neural networks (DNNs) employ a hierarchical structure, stacking layers of artificial neurons to emulate\nthe brain's neural organization [88]. Each layer processes and transforms information before passing it to the\nnext layer, similar to the brain's network of neurons. Connections between artificial neurons, akin to synapses in\nthe brain, are assigned weights that determine the influence of one neuron on another. These weights are adjusted\nduring the learning process, much like how the brain refines its understanding through environmental interactions.\nDNNs receive feedback in the form of error signals or rewards, depending on the learning paradigm [143], which\nhelps the model adjust its parameters to minimize errors or maximize rewards. DNNs underpin many popular\nAl models. For example, convolutional neural networks (CNNs) are modeled after the brain's visual processing\npathways [89], and recurrent neural networks (RNNs) draw on the brain's sequential processing capabilities [43]."}, {"title": "2.2 Learning Mechanism", "content": "The human brain's learning mechanism is a sophisticated and adaptive system involving perception, memory\nformation, decision-making, and other cognitive processes. A key principle underlying learning in the brain is\nneural plasticity [184]. This concept describes the brain's remarkable ability to modify its neural connections and\nfunctions in response to new experiences and stimuli. Neural connections can be strengthened or weakened,\nnew connections can be established, and existing ones can be eliminated based on activity patterns. Al models\nemulate this process by adjusting the weights between artificial neurons according to patterns found in training\ndata. This adjustment process, known as training or learning, involves updating the model's parameters to reduce\nerrors or enhance rewards [155].\nBesides, the brain encodes information in a hierarchical and distributed manner. Complex ideas are built upon\nsimpler ones, with information spread across different brain regions. AI models, especially DNNs, use analogous\nprinciples of representation learning to understand data hierarchically. Lower layers of these models identify\nbasic patterns, while higher layers interpret more abstract concepts [17]. Techniques such as transfer learning and\nunsupervised learning mimic this brain-like learning process. Transfer learning leverages knowledge acquired\nfrom one task to enhance performance on a related but distinct task. Unsupervised learning allows models to\nlearn from data that is either unlabeled or only minimally supervised. Both techniques improve the model's\ngeneralization capabilities and reduce the dependency on extensive labeled datasets."}, {"title": "2.3 Attention and Focus", "content": "The attention and focus of the human brain are crucial cognitive mechanisms that allow us to selectively\nprocess information, allocate mental resources, and concentrate on specific tasks or stimuli while ignoring\ndistractions [142]. Understanding how attention works in the brain has inspired the development of attention\nmechanisms in AI models, especially in the realm of deep learning. The human brain can attend to multiple\naspects of information simultaneously, a capability known as parallel or multi-head attention. This allows us to\nprocess complex stimuli and perform multiple tasks in parallel to some extent. Al models employ multi-head\nattention mechanisms to simultaneously attend to different parts or features of the input data. By splitting\nthe attention mechanism into multiple heads, models can capture diverse aspects of the input and integrate\ninformation from multiple sources, improving robustness and performance [180]."}, {"title": "2.4 Memory and Recall", "content": "The human brain comprises multiple memory systems [9]. Sensory memory temporarily holds sensory information\nfrom the environment and acts as a buffer for stimuli received through sight, hearing, touch, smell, and taste.\nShort-term memory serves as a temporary storage system with limited capacity, maintaining information that\nis readily accessible for immediate use. Long-term memory is responsible for storing information for extended\nperiods, potentially without limit. AI models can emulate these memory systems using various architectures and\nmechanisms. For example, RNNs and transformers employ recurrent connections and attention mechanisms to\nmodel short-term dependencies and long-term context in sequential data, enabling the retention and retrieval of\ninformation over time.\nRecall refers to the process of accessing and retrieving information stored in memory. It can occur spontaneously\nor be triggered by external cues or internal associations. AI models perform recall and retrieval by accessing stored\nrepresentations through inference or query mechanisms [83]. Memory-based architectures, such as memory\nnetworks and neural Turing machines, enable models to retrieve relevant information from memory based on\ninput queries or context. By drawing inspiration from the memory and recall mechanisms of the human brain,\nAl researchers have developed memory-augmented architectures and learning algorithms that enhance the\ncapabilities of AI models in storing, retrieving, and leveraging information over time. Long-Short-Term Memory\n(LSTM) neural networks [67] are among the most commonly used memory models in AI."}, {"title": "2.5 Consciousness", "content": "While consciousness remains a subject of philosophical and scientific exploration, it is closely tied to cogni-\ntive processes like attention, memory, decision-making, and self-awareness [143]. Although AI models do not\nexperience consciousness as humans do, they can leverage aspects of conscious processing to enhance their\nperformance and capabilities. Consciousness supports social cognition, including the ability to understand and\npredict others' mental states, beliefs, and intentions. This is known as the theory of mind, which facilitates social\ninteractions and empathy.\nAl models can draw from social cognition and theory of mind to create more human-like interactions and\nbehaviors in social contexts. Techniques like sentiment analysis and empathy modeling allow models to interpret\nand respond to users' emotional states and intentions, thereby improving human-AI interactions [183]. While AI\ndoes not possess consciousness per se, learning from the principles of conscious processing can lead to more\nsophisticated and effective models and algorithms. By incorporating these cognitive processes, researchers aim\nto develop AI systems with increasingly advanced behaviors and interactions."}, {"title": "2.6 Creativity and Imagination", "content": "The creativity and imagination of the human brain are remarkable cognitive abilities that enable us to generate\nnovel ideas, insights, and solutions, as well as to envision hypothetical scenarios and possibilities [176]. Creativity\noften involves the ability to combine existing concepts, ideas, or elements in novel and unexpected ways. The\nhuman brain achieves this by flexibly manipulating and recombining mental representations. Al models learn"}, {"title": "3 BRAIN-INSPIRED AI MODELS", "content": "In this section, we categorize existing BIAI techniques based on the specific brain-inspired mechanisms they\nincorporate. By drawing insights from neuroscience, we can apply this knowledge to computational modeling,\nwhich involves creating and implementing algorithms and systems that emulate the brain's structure and\nfunction. This process can be divided into two categories: models and algorithms inspired by the brain's physical\narchitecture, and those inspired by human behavior. The introduction order of these techniques will mainly\nfollow the order shown in Fig. 1."}, {"title": "3.1 Physical structure-inspired Al Models", "content": "Several prominent AI models seek to emulate the human brain's architecture and processes, leveraging neuro-\nscience to develop more biologically plausible and powerful systems. Here are a few notable examples. We will\nonly list the most representative models and their concepts in this section to help understand the theoretical\nbasis and internal mechanism of these models."}, {"title": "3.1.1 Hierarchical Models", "content": "A representative mechanism of the PS-inspired model is to learn from the information\nprocessing meachanism of human brain. The human brain processes information in a hierarchical manner, with\nsensory inputs processed at lower levels and abstract concepts at higher levels. Learning from this process,\nDNNs where entities are organized into levels or layers, each layer representing different levels of abstraction\nor processing are designed. Representative hierarchical models include CNNs, Capsule Networks (CapsNets),\nRNNs, Echo State Networks (ESNs), and Deep Belief Networks (DBNs). Considering that these models are the\nmost basic models that have been used in different algorithms, we only introduce the basic concepts and how\nthey are inspired by human brain. As for the characteristics, realization, equations, and real application scenarios\nof these models, we refer readers to [86, 185, 205] for more details.\nCNNs are a specialized type of ANNs designed for processing structured grid data. The concept was inspired\nby the work of biologists Hubel and Wiesel, who conducted pioneering research on the visual cortex of the cat\nbrain [76]. They discovered the phenomenon known as receptive field mechanisms: neurons in the primary\nvisual cortex respond to specific features in the visual environment. Hubel and Wiesel identified two types of\ncells: simple cells respond strongly to specific spatial positions and orientations, while complex cells have larger\nreceptive fields and remain responsive even when the position of the features shifts slightly.\nWhen we view an image, our attention is initially drawn to the most prominent and informative local features.\nFor instance, in a picture of a pet dog, our eyes typically focus on the dog first, noticing its face, legs, and"}, {"title": "3.1.2 SNNs", "content": "Spiking neural networks depart from traditional neural networks by modeling neurons as spiking\nunits, aligning more closely with the brain's computational mechanisms [167]. They belong to the third generation\nof neural network models, achieving a more advanced level of biological neural simulation.\nSNNs use discrete events called spikes to represent neuron activations. These spikes are initiated when a\nneuron's membrane potential attains a critical threshold, closely replicating the mechanism of action potentials in\nbiological neurons. SNNs can be distinguished from traditional DNNs in four key aspects [188]: 1. SNNs employ"}, {"title": "3.2 Human behavior-inspired Al Models", "content": "There are also many AI models inspired by human behaviors and cognitive processes in several ways. The\nlearning mechanisms of these models usually leverage insights from cognitive psychology, neuroscience, and\nbehavioral science to create more effective and intelligent systems. Instead of introducing the specific models,\nwe only summarize and classify the most popular learning mechanisms of these models in recent years. In each\nlearning paradigm, we select a representative situation to concrete and better understand the internal operating\nmechanisms of these models."}, {"title": "3.2.1 Machine Unlearning", "content": "It involves selectively removing the influence of specific data points from a trained\nmachine learning model. It can be used to protect users' privacy when they want their data forgotten by a trained\nmachine learning model. Instead of simply erasing their data from database, the deletion needs to eliminate\nthe contribution of the erased training data from the already trained model, which process was first defined\nas machine unlearning [186]. To better understand how unlearning mechanisms work, we first introduce the\nunlearning problem and process following the machine unlearning framework demonstrated in Fig 2. Assuming\nthat a model M is trained on the dataset D with algorithm A, this could be denoted as\n$M = A(D)$,\nwhere $D \\in Z$. Here, $Z$ is the space of data items and model M is in a hypothesis space H. If a user wants to\nremove his data $D_e$ from the trained model, then the server removes the contribution of $D_e$ using a machine\nunlearning algorithm U, which is denoted as\n$M_{D\\backslash D_e} = U(D, D_e, A(D)).$"}, {"title": "3.2.2 Attention and Self-Attention Mechanism", "content": "In AI, the attention mechanism enables machine learning models\nto focus on relevant input data, leading to improved performance. Inspired by human cognitive processes [130],\nparticularly selective attention in psychology, attention mechanisms allow models to dynamically prioritize\ndifferent parts of input data. By assigning varying degrees of attention, typically through learned weights [120],\nthe mechanism enables models to prioritize certain features or contextually relevant information while filtering\nout noise or irrelevant details. This adaptive focus not only improves the model's performance in terms of, e.g.,\naccuracy and efficiency in many tasks like NLP, image recognition, and sequence prediction but also enhances its\ninterpretability by revealing which parts of the input are most influential in generating predictions or outputs [70].\nDespite that models inspired by the attention mechanism [11, 180] have been proposed and successfully\napplied into different scenarios, the mechanisms underlying consciousness are still not well understood. Creating\nAl that can mimic or exhibit conscious-like states is a profound challenge. For example, emotions are vital\nto decision-making and learning. However, the neural basis of emotions and their integration with cognitive\nprocesses is not fully understood. Grabbing knowledge of this process can help complete tasks like sentiment\nanalysis, and emotion perception in robotics [38]."}, {"title": "3.2.3 Imitation Learning", "content": "It is a machine learning approach where agents learn tasks by copying expert behavior.\nThis is often more efficient than trial-and-error, as it leverages expert knowledge to avoid exploring countless\npotential action sequences [22]. This approach tends to leverage demonstrations (pairs of input and output)\nprovided by the expert to train the agent, enabling it to acquire complex skills more efficiently. By observing"}, {"title": "3.2.4 Transfer Learning", "content": "As a popular machine learning technique, transfer learning applies knowledge from\none task to improve performance on a different but related task. For instance, a child's surprise at a floating toy\nreveals the transfer of learned knowledge about gravity, even without explicit teaching [87].\nAccording to the generalization theory of transfer, the capacity to transfer knowledge stems from the ability\nto generalize experience [210]. In other words, when a person applies their past experiences to new situations,\nthey enable the possibility of transferring knowledge from one context to another. This theory posits that a\nconnection between two learning activities is necessary for transfer to occur. For instance, a violinist often learns\npiano faster due to shared musical fundamentals."}, {"title": "3.2.5 Reinforcement Learning (RL)", "content": "It is a popular machine learning approach in which agents learn to make\ndecisions through interactions with an environment [189]. The goal of the agent is to maximize rewards by\nselecting optimal actions. Learning occurs by means of trial-and-error, in which the agent receives feedback\nin the form of rewards or penalties. RL is particularly effective for problems where the correct actions are not\nimmediately clear and must be discovered through a balance of exploration and exploitation.\nRL draws substantial inspiration from behavioral psychology, particularly the principles of operant conditioning\n[15]. In operant conditioning, behaviors are influenced by their consequences: actions leading to rewards (positive\nreinforcement) are more likely to be repeated, whereas those followed by punishments (negative reinforcement)\nare less likely to occur again. RL mirrors this framework by having an agent interact with an environment,\nperform actions, and receive feedback in the form of rewards or penalties. This feedback loop enables the agent\nto learn optimal behaviors to maximize cumulative rewards. Furthermore, RL incorporates the concepts of\nexploration (trying new actions to observe their effects) and exploitation (choosing known actions that yield\nhigh rewards), akin to how humans balance curiosity with the use of established strategies to learn from their\nenvironment [140]. These parallels illustrate how RL algorithms emulate human learning processes to develop\nintelligent, adaptive systems.\nDeep Reinforcement Learning (DRL) integrates RL with DNNs to facilitate agents' learning and decision-\nmaking in complex, high-dimensional environments. DRL takes advantage of the deep networks' powerful ability\nto learn representations from raw sensory inputs, e.g., images or audio, to extract relevant features that guide the\nagent's decisions. A notable example of DRL is Deep Q-Networks (DQN) [117], which uses a CNN to estimate\nthe value of actions in different states. The network is trained to minimize the difference between predicted and\nactual rewards.\nBy combining the strengths of deep learning and RL, DRL excels in handling high-dimensional input spaces,\nsuch as images or raw sensory data, by leveraging DNNs to extract and learn relevant features automatically. This\ncapability allows DRL agents to make decisions directly from complex and unstructured data without requiring\nextensive feature engineering. Additionally, DRL can learn sophisticated policies and strategies in environments\nwith complex dynamics and long-term dependencies, making it suitable for tasks like game playing, robotics,\nautonomous driving, and resource management. The ability to learn from trial and error and continuously improve\nthrough interacting with the environment enables RL to solve problems that are challenging for traditional\nmachine learning approaches."}, {"title": "3.2.6 Self-supervised Learning (SSL)", "content": "Supervised deep learning models generally require vast amounts of labeled\ndata, which can be costly and time-consuming to obtain. To address this, SSL extracts meaningful features from\nunlabeled data without human intervention [57]. This method typically involves tasks like predicting missing\nsegments of input data, generating data transformations, or distinguishing between modified and original data\nsamples. By creating pretext tasks-artificial labels generated from the data itself, such as predicting the next\nframe in a video, completing missing parts of an image, or determining the temporal order of events, the model\ntrains itself to understand complex patterns and structures. This method leverages the inherent information in\nthe data to build robust and transferable features, reducing the reliance on expensive and time-consuming human"}, {"title": "3.2.7 Few-shot learning (FSL)", "content": "Traditional machine learning and deep learning models struggle with extremely\nlimited data. When models are trained on only a few hundred or fewer examples, they often overfit, memorizing\nthe training data rather than learning general patterns, which might potentially result in poor performance on\nnew data. However, there is a widespread demand in the industry for training models based on small samples,\nsuch as single-user face and voice recognition, recommendation cold-start, fraud detection, and other scenarios\nwhere sample sizes are small or data collection costs are high. FSL addresses the challenge of learning from limited\ndata by incorporating additional information. This includes unlabeled data, other datasets, or prior knowledge to\nenhance learning from scarce labeled samples [159].\nFSL refers to the capability of a model to learn from extremely limited data [191]. Unlike traditional machine\nlearning, which often requires vast amounts of labeled examples, FSL aims to achieve high performance with only\na handful of training instances. This approach is especially valuable in situations where acquiring supervised\nexamples is challenging or impossible due to privacy, safety, or ethical concerns [8, 159]. Drug discovery, for\ninstance, often faces challenges due to the limited availability of real biological data on clinical candidates [5].\nIdentifying new molecules for drug development requires learning from scarce data due to factors like toxicity,\nlow activity, and solubility. This necessitates efficient learning from minimal examples.\nFSL in machine learning takes inspiration from neuroscience, especially the brain's exceptional capability\nto learn new concepts with minimal examples [19]. Humans can quickly learn new tasks by leveraging their\nprevious knowledge and experiences. They generalize from just a few instances due to mechanisms like synaptic\nplasticity, which allows neurons to adjust their connections based on experience [158]. Similarly, FSL algorithms\nemploy techniques such as meta-learning [92]. By training on diverse tasks, models develop a general learning\nability that can be quickly adapted to new, data-scarce scenarios [93]. This approach mirrors the brain's efficiency\nin leveraging prior knowledge and context to understand and learn from new situations rapidly.\nFSL offers significant advantages by enabling models to learn effectively from limited data, mimicking human\nlearning. This is crucial in data-scarce environments, reducing reliance on extensive labeled datasets and accelerat-\ning training. By quickly adapting to new tasks with minimal data, FSL enhances model adaptability [13]. However,\nseveral challenges remain, including achieving robust generalization across diverse and complex tasks, sensitivity\nto the quality and representativeness of the provided examples, and the need for more efficient algorithms to"}, {"title": "4 APPLICATIONS", "content": "The applications of BIAI models are vast and diverse, spanning across industries and disciplines, and they\ncontinue to drive innovation and advancement in a wide range of fields. A summarization of these applications\nis given in Fig. 3. Due to space limitations, we only highlight four representative applications in this section,\ndemonstrating how popular tasks within these areas are effectively addressed by incorporating BIAI."}, {"title": "4.1 Robotics", "content": "Traditional Al models often struggle to make accurate and rapid decisions in complex environments, especially\nfor tasks involving robotic movements and dexterous manipulations. Additionally, current robotics research\noften focuses on specific tasks, limiting broader applications, such as precise manipulation or deep collaboration\nbetween humans and robots. These challenges hinder the broader application of robotics in various fields. To\novercome these challenges, researchers are turning to the brain for inspiration, leading to the development of\nbrain-inspired intelligent robots. By mimicking the brain's neural networks, robots can perceive, learn, and\ninteract with their environment more naturally, paving the way for more human-like robotic capabilities [132]. A\nconcret comparison between traditional robots and brain-inspired robots is shown in Fig. 4."}, {"title": "4.1.1 Visual cognition", "content": "Traditional deep-learning-based models for visual cognition face several challenges.\nFirstly, they require extensive datasets for training, which are often unavailable in real-world applications [138].\nAdditionally, these models are typically sensitive to disturbances. Even minor noise in input image data can lead\nto significant deviations in the output [68]. Furthermore, these models operate as black boxes, with their internal\nworkings largely unexplained. This makes it very hard, if not impossible, to understand the decision-making\nprocesses of models. Lastly, these visual models are usually designed for certain specific tasks, and hence they\nmay lack the flexibility to quickly adapt to new tasks."}, {"title": "4.1.2 Decision making", "content": "In decision-making, key challenges include autonomously acquiring environmental\nknowledge and making swift, accurate decisions in complex scenarios. Advances in this field could significantly\nenhance the efficiency and precision of robotic movements and complex manipulations, impacting intelligent\nmanufacturing and everyday life. Recently, progress in integrating AI, robotics, and neuroscience has led to\nthe development of various learning-based decision-making techniques that have demonstrated impressive\nperformance in autonomously acquiring robotic knowledge and skills [61]. Despite these advancements, several\ncommon issues persist, such as low learning efficiency, difficulty in developing goal-oriented strategies, and\nlimited generalization capability."}, {"title": "4.1.3 Body and motion control", "content": "In the realm of robotic body and motion control, current joint-link robots\nare designed to emulate human appearance and functions. However, they fall short in achieving human-like\nmanipulation and interaction capabilities. Conversely, musculoskeletal robots replicate the human skeletal\nstructure, joints, muscles, and the interactions between these components. This design offers greater flexibility,\ncompliance, robustness, safety, and adaptability, making these robots more promising for human-like manipulation\nand interaction [132]. Nonetheless, the high redundancy, coupling, and nonlinearity inherent in musculoskeletal\nrobots introduce significant challenges in motion control. To address these challenges, various methods grounded"}, {"title": "4.2 Healthcare", "content": "BIAI in healthcare utilizes computational models and algorithms to improve medical diagnostics"}]}