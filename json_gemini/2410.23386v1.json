{"title": "STIED: A deep learning model for the Spatio Temporal detection of focal Interictal Epileptiform Discharges with MEG", "authors": ["Raquel Fern\u00e1ndez-Mart\u00edn", "Alfonso Gij\u00f3n", "Odile Feys", "Elodie Juven\u00e9", "Alec Aeby", "Charline Urbain", "Xavier De Ti\u00e8ge", "Vincent Wens"], "abstract": "Abstract-Magnetoencephalography (MEG) allows the non-invasive detection of interictal epileptiform discharges (IEDs). Clinical MEG analysis in epileptic patients traditionally relies on the visual identification of IEDs, which is time consuming and partially subjective. Automatic, data-driven detection methods exist but show limited performance. Still, the rise of deep learning (DL) \u2014 with its ability to reproduce human-like abilities-could revolutionize clinical MEG practice. Here, we developed and validated STIED, a simple yet powerful supervised DL algorithm combining two convolutional neural networks with temporal (1D time-course) and spatial (2D topography) features of MEG signals inspired from current clinical guidelines. Our DL model enabled both temporal and spatial localization of IEDs in patients suffering from focal epilepsy with frequent and high amplitude spikes (FE group), with high-performance metrics-accuracy, specificity, and sensitivity all exceeding 85%-when learning from spatiotemporal features of IEDs. This performance can be attributed to our handling of input data, which mimics established clinical MEG practice. Reverse engineering further revealed that STIED encodes fine spatiotemporal features of IEDs rather than their mere amplitude. The model trained on the FE group also showed promising results when applied to a separate group of presurgical patients with different types of refractory focal epilepsy, though further work is needed to distinguish IEDs from physiological transients. This study paves the way of incorporating STIED and DL algorithms into the routine clinical MEG evaluation of epilepsy.\nIndex Terms-Automatic interictal epileptiform discharges detection, Convolutional Neural Networks, Deep Learning, Epilepsy, Magnetoencephalography.", "sections": [{"title": "I. INTRODUCTION", "content": "Epilepsy is a disorder of the brain characterized by an enduring predisposition to generate epileptic seizure [1]. It affects people of all ages and has neurobiological, cognitive, psychological and social consequences. While pharmacological treatments work successfully in most patients, approximately one-third of them suffer from refractory (i.e., drug-resistant) epilepsy [2]. These patients are possible epilepsy surgery candidates and must therefore undergo a presurgical evaluation aiming at delineating as precisely as possible the epileptogenic zone.\nMagnetoencephalography (MEG) contributes to this evaluation, mainly by allowing the non-invasive detection of interictal epileptiform discharges (IEDs)\u2014subclinical events occurring between seizures [3], [4]\u2014which are markers of the localization of the epileptogenic zone [5], [6]. Clinical MEG analysis of patients with epilepsy traditionally relies on the visual identification of IEDs by an experienced clinical magnetoencephalographer, who inspects both IED sensor time courses and spatial topographies along with their source localization usually by equivalent current dipole (ECD) modeling [7], [8]. This approach is highly time consuming (on average 8 hours per patient [9]) and partially subjective (notwithstanding existing guidelines [10]). The development of efficient data-driven, automatic approaches to IED detection would represent a major advance in clinical MEG practice. Several proposals based on unsupervised algorithms have been"}, {"title": "II. METHODS", "content": "Participants: We trained and validated our DL models using a small dataset of 10 children (age: 5-11 years; 5 females and 5 males) suffering from FE, most of them from self-limited epilepsy with centro-temporal spikes (SeLECTS), with a high number of visually detected IEDs (VDS-IED) marked by a clinical magnetoencephalographer (O.F.). The trained\n\n\n\nB. MEG data preparation\nThe overall pipeline is illustrated in Fig. 1 (upper panel).\nMEG preprocessing: We followed standard denoising steps of MEG data, i.e., signal space separation to correct for environmental magnetic interferences and head movements (Maxfilter v2.2.14, MEGIN, with default parameters [26]), and ICA (FastICA, [27]) of band-filtered data (0.5-45 Hz) to remove physiological artifacts (eye blinks and cardiac activity) [28]. The resulting data were further band-filtered between 4 and 30 Hz and temporally segmented into 200 ms-long non-overlapping windows. This length was chosen to enable full inclusion of isolated IEDs, whose typical duration range from 50 to 100 ms [29].\nSpatial/temporal feature extraction: Input data for training/testing of subsequent DL models was extracted from each window by applying principal component analysis (PCA) separately to the 204 planar gradiometer signals and to the 102 magnetometer signals. The first principal component (PC) of gradiometers determined a single waveform per window (size 1 \u00d7 200 time samples) that explained the largest fraction of variance in the window. The first PC of magnetometers determined a single magnetic topography (size 102 channels \u00d7 1), which was then converted into a 2D image by a fourth order polynomial interpolation over a 60 \u00d7 60 pixel grid using the open-source software FieldTrip [30]. The splitting of gradiometers/magnetometers to extract temporal/spatial features broadly reproduces the visual IED identification procedure typically followed by our clinical magnetoencephalographers; the higher signal-to-noise ratio of gradiometers yields a cleaner visualization of MEG time courses [10], [31] (notwithstanding lesser sensitivity to deep IED activity in, e.g., mesiotemporal epilepsy [32]) whereas magnetometers show higher sensitivity to dipolar magnetic patterns [33] (as well as to deep IEDs [32]). Extracting a single waveform or image per window also allowed to reduce the size and redundancy of input data, the size and complexity of our DL network models, and the computational load of model training. Since this data reduction could miss potentially relevant, low-variance IED features included in higher-order PCs, we also used second PCs as inputs to DL models and checked whether they bear predictive power for IED detection. Each of these PC data were further standardized per subject.\nMachine learning preprocessing of training data (FE group): Each window was labeled according to a binary classification ('Spike'/'Non-spike') depending on whether or not it contains an annotated VDS-IED [17] (see Fig. 1, lower left panel). Over the resulting classification dataset, we performed a threefold data augmentation. First, each 'Spike' window was shifted 15 times to the past and future by 7 ms steps, hence allowing to train our DL models independently of the precise IED timing within a window. The number of 30 replicas per 'Spike' window was determined through trial and error. Then, we randomly removed 'Non-spike' windows to achieve a balanced training dataset. Second, we further augmented the dataset spatially by rotating magnetic topographical images four times at 90-degree intervals, so as to train our DL model independently of the precise IED dipole position. Last, we"}, {"title": "C. Model architectures", "content": "The architecture of our three DL models is illustrated in Figs. 2-4. All these models were implemented using the Tensorflow library [35] and run on a laptop equipped with an AMD Ryzen 7 5800H processor, 40 GB RAM memory and NVIDIA GeForce RTX 3060 graphic card. Of note, non-trainable hyperparameters were chosen by exploring the space generated by the combination of different number of CNN layers (1, 2, or 3), CNN filters (8, 16, 32, or 64), dense layers (1, 2, or 4), and dense-layer neurons (8, 16, 32, 64).\nTemporal model (1D-CNN): In the temporal model, the gradiometric PC waveform of a window is passed through three successive blocks made of a 1D convolutional layer followed by dropout and maxpooling layers (Fig. 2). The output was then flattened and fed to a two-layer decision block. Each convolutional layer has a different number of filters (16, 32, 64), a leaky rectified linear unit (ReLU) as activation function, and subsequent dropout layer (probability value 0.5) to prevent overfitting and maxpooling layer (pooling size 2) for downsampling. The decision block was composed of a dense layer with 16 neurons and ReLU activation functions, followed by a single neuron with sigmoid activation function providing a probability between 0 and 1 for a window to contain a spike. The final binary yes/no (\u2018Spike'/'Non-spike') decision was based on a non-trainable probability threshold set to 0.5.\nSpatial model (2D-CNN): The model design to analyze spatial features was exactly the same as for the temporal model, except that the inputs consisted here in images of\nSpatiotemporal model (STIED): To incorporate both temporal and spatial features in a genuinely spatiotemporal IED detection, we designed a model architecture that processes temporal and spatial inputs in parallel using the same 1D-CNN (Fig. 2) and 2D-CNN (Fig. 3) up to the first dense layer of their decision block. The feature vectors from the outputs of the temporal and spatial dense layers were downsampled (0.5 dropout), combined using weighted concatenation with one trainable scalar weight for the temporal features (wt) and one for the spatial features (ws = 1 - wt), and finally fed to the same decision block as above (Fig. 4).\nAmplitude normalized models and threshold models: Since IEDs are primarily high-amplitude events, we sought to examine whether our STIED models are merely driven by the gross amplitude of IEDs or if they learn subtler features. To design a classifier independent of amplitude, we applied the same 1D-CNN, 2D-CNN, and STIED models on input data after normalizing their peak amplitude to one within each window (NormAmplitude models). The specific importance of amplitude, independently of IED morphological features, was assessed using a classical DL classification model (multilayer perceptron with two fully connected dense layers of 8 neurons each and ReLU activation function) determining a trainable threshold for the scalar peak amplitude of each input data (ThresholdAmplitude model).\nD. Training and performance evaluation\nModel training: Model training was performed using an Adam optimizer algorithm with a batch size of 128 windows, binary cross-entropy as loss function, and a reduced learning rate when loss stopped improving. As preliminary sanity check, we trained our STIED models by randomly extracting 80% of the entire dataset for training and using the remaining 20% for testing. We did not observe overfitting and determined that 150 epochs/training steps were enough to reach a learning plateau in all models. For model performance evaluation, given that our dataset was composed of 10 patients, we performed a 10-fold repeated LOOCV wherein all windows of 9 out of 10 subjects were used for training, and all windows of the remaining subject for testing. This allowed to evaluate model performance in a clinically oriented setup (i.e., generalizability to the inclusion of new patients with similar epilepsy) and inter-individual variability of performance metrics.\nPerformance metrics: For each cross-validation iterate, we compared model window classification (yes/no) to the actual presence of VDS-IEDs (\u2018Spikes'/'Non-Spike') using accuracy,"}, {"title": "III. RESULTS", "content": "We now report the detection performance of these supervised DL models and analyze the impact of using temporal, spatial, or spatiotemporal features. We also explore the validity of our data reduction, assess the relevance of IED amplitude and IED morphology in STIED, and compare it with previous unsupervised detection algorithms. Then, we test the generalizability of STIED to another, unlabeled dataset of patients with RFE.\nA. Detection performance of STIED in SeLECTS\nThe performance metrics for the three DL model types (temporal 1D-CNN, spatial 2D-CNN, spatiotemporal STIED) are summarized in TABLE II for balanced and unbalanced test data. Results at each cross-validation iterate are detailed in TABLE III for unbalanced test data.\nImpact of model type: Classification accuracy and specificity were consistently large whatever the model type, both for balanced and unbalanced test data (accuracy >85%, specificity >93%; mean over 10 cross-validation iterates), with no significant effect of model type (p>0.12). So, all three DL models were equivalent in their ability to correctly predict VDS-IEDs. Sensitivity was on average larger for the temporal and spatiotemporal models (>84%) than for the spatial model (75%), though this observation was not statistically significant due to large inter-subject variability in sensitivity (p>0.26). This suggests that temporal features of IED waveforms are most useful to avoid false detections. Despite the absence of statistical effects, combining spatiotemporal features maximized all three performance metrics in the realistic setup of unbalanced test data (TABLE II), indicating a slight but possible superiority of the STIED model, on which we shall focus hereafter. Interestingly, the trained weights Wt and ws, were both close to 0.5, showing that while STIED did not perform significantly better than the temporal 1D-CNN model, it effectively used both temporal and spatial features in its decision process.\nBalanced vs. unbalanced metrics: The observation of similar performance metrics from balanced and unbalanced test data (TABLE II) further advocates for the robustness of our DL algorithms. Specifically, the identical sensitivities (combined with consistently large specificities) indicate that all three models identified the same IEDs regardless of the amount of\nImpact of data reduction: The first PC used for data reduction explained significantly more data variance than the second PC of same windowed data (t test on window covariance eigenvalues, p<3e-6), but this does not preclude that the latter contains useful IED features. Figure 5 compares performance metrics (unbalanced test data) for our three DL models applied to the first vs. second PC. All metrics were significantly smaller when using the second PC in STIED (p<0.01), with a particularly strong drop in mean sensitivity of 52%. The drop in accuracy and sensitivity were similarly significant in the temporal and spatial models (p<0.05) but not in specificity (p>0.11). Thus, the second PC contains remnant, low-variance features of IEDs excluded by our data reduction procedure, though these features are less effective at IED detection and are poorly specific to IEDs.\nContribution of IED amplitude: Figure 6 compares our DL models (Full) to similar models wherein the encoding of IED amplitude is explicitly precluded (NormAmplitude), and to a simple amplitude threshold model that solely encodes IED amplitude (ThresholdAmplitude). Remarkably, eliminating the amplitude feature did not alter performance metrics (unbalanced test data) for the three model types, except for a significant decrease of accuracy/specificity (p<0.01; NormAmplitude vs. Full) in the spatial model (2D-CNN) and a marginal (non-significant; p=0.09) decrease of sensitivity in the spatiotemporal model (STIED). Amplitude-based classification led to significantly lower accuracy/specificity (p<0.004; except for spatial ThresholdAmplitude vs. NormAmplitude where p>0.09) but higher sensitivity, though the latter effect was marginal in the original STIED model (p>0.25). We conclude that IED amplitude is not effective in recognizing IEDs and plays a relatively marginal role in STIED. In other words, STIED is mostly driven by IED waveform morphology and dipolar topography.\nComparison with unsupervised classifications: TABLE IV compares performance metrics of STIED (unbalanced test data) to those of two unsupervised detection algorithms (ICA and HMM) developed in a previous work and tested on the same dataset [17]. All approaches showed similar sensitivities (p=0.67), but STIED was significantly more specific to IEDs than both supervised methods (<55%; p<2e-9). This merely reflects the expected fact that the supervised DL algorithm learns from VDS-IEDs and thus follows closely the clinical magnetoencephalographer's decision."}, {"title": "B. Generalizability of FE-group-trained STIED to RFE patients", "content": "As a final step, we sought to evaluate the performance of our STIED model, trained in our FE group, on 12 patients with RFE. Besides differences in the type of epilepsy, this test dataset differs from the training dataset in that (i) it contains both children and adults, (ii) patients slept during MEG recording, and (iii) IEDs were not marked, though their ECD location was available, allowing comparison of localization with STIED detection. Perphaps unsurprisingly, results were mitigated with only 2 patients reproducing exactly the location of IED events, 9 patients in which additional non-epileptiform events were detected besides the accurate location of VDS-IEDs, and 1 patient in which a cluster of VDS-IEDs was missed altogether.\nFigure 7 illustrates these results by comparing the density map of predicted IEDs (Fig. 7, left) and ECD localization of VDS-IEDs (Fig. 7, right) in three patients. Patient 11 (Fig. 7a) is representative of the successful cases where STIED co-localizes IEDs with VDS-IEDs. Both approaches were consistent with multifocal independent irritative zones, with the most active being posterior to the left frontal lesion. Patient 12 (Fig. 7b) illustrates a case of partial success. Clinical analysis reported few VDS-IEDs, which were accurately identified by the STIED model. Nonetheless, Rolandic spikes in the centrotemporal area and sleep-related events in the occipital areas were also wrongly predicted, likely indicative of physiological transients [10], [36]. Patient 20 (Fig. 7c) illustrates the case of mitigated success. Clinical assessment revealed two active, independent irritative zones located at the left opercular/periinsular and ventral occipital regions, which might be part of a common epileptogenic network, but STIED missed the ventral occipital cluster of VDS-IEDs. We conclude that, while STIED trained on FE patients learned IED features that generalize to all patients with RFE, other types of epileptiform activities were not recognized (such as polymorphic waveform), while some forms of physiological activity were falsely detected."}, {"title": "IV. DISCUSSION", "content": "The development of fully automated tools for the detection and localization of IEDs is a long-standing goal in the field of clinical epilepsy. Here, we introduced STIED, a simple yet effective DL solution for IED automatic detection in clinical MEG recordings. This is part of the global momentum that \"artificial intelligence\" bears in technology, not the least in medical fields\u2014including neuroscience [37], [38] and clinical epilepsy [39]. In fact, STIED is not the first attempt in applying supervised DL to the evaluation of epilepsy with MEG ([18]- [21]). Here, we strived to design a computationally reasonable architecture that encodes both temporal and spatial features in a way analogous to how clinical magnetoencephalographers analyze their clinical MEG recordings [10]. This allowed us to train our STIED model with high sensitivity and specificity, despite a relatively small training dataset, at least in the context of our FE group. We focused here on patients with FE, mainly SELECTS, because their high IED amplitude and frequency yielded a relatively large count of IED events in a limited duration of MEG signals, which admittedly may have contributed to the efficient training of STIED at small dataset size. Interestingly, our results suggest that, after training, detection performance does not depend closely on IED frequency and thus could generalize to epileptic patients with scarcer interictal events. This contrasts with previous recent studies [18]-[20] proposing DL-based IED detection, which showed a substantial drop in sensitivity to less than 50% when assessed with unbalanced compared to balanced test data [20]. While authors overcame this issue ad-hoc by adjusting the probability threshold at the end of their decision blocks (using a thresholding moving strategy to enhance performance [18]\u2013 [20]), one advantage of our DL models is that they showed high sensitivity without such adjustment. Still, the generalizability of our current version of STIED to other types of epilepsy such as RFE was partial, presumably because it does not capture sufficiently the variety of IED field patterns and waveform morphologies (which may be different in deep medial temporal epilepsy [40] or change as the type of epilepsy evolves with age [41]). This being said, this paper provides proof of concept for the effectiveness of the STIED model architecture. Future updates of STIED with a larger and more diverse training dataset should dramatically widen its range of applicability. STIED could also be an efficient and fast approach to assess the spike-wave index (i.e., fraction of recording time showing spike-and-wave activity [42]), a key diagnostic element for some pediatric epileptic conditions (reaching up to 85% in our training dataset [43]).\nThe STIED architecture is the result of several trials not reported here. Regarding artificial neural network design, we quickly settled for a quite classical setup that combines 1D- CNN as done in previous works to analyze temporal signals [44], 2D-CNN typical of spatial image processing [45], and dense layers with sigmoid final neuron for classification. The number and size of layers were varied to maximize performance while minimizing complexity. In this endeavor, the identification of CNN inputs with relevant low-dimensional features amongst high-dimensional MEG data, proved key. We did so using a data reduction based on PCA that loosely follows what is done during clinical MEG visual analysis, i.e., extract IED waveform signals from gradiometers and images of IED dipolar patterns from magnetometers. This likely explains why STIED could learn from, and closely agree with, clinical magnetoencephalographers. A caveat of this procedure was the exclusion of MEG features specific of, though poorly sensitive to, IEDs. It might also miss deep epileptiform activity [32]. On the other hand, it allowed to train and run the model on affordable hardware with reasonable training times (about 4 hours for 10 subjects with 5-min MEG recordings) and small processing time of new data (less than 30 seconds for 1 hour MEG recording). This means that STIED can detect IEDS similarly to clinical magnetoencephalographers, about 300 time faster again at least within our FE group.\nBeyond sheer performance, we sought to partially reverse engineer the STIED model and investigate what features of MEG signals drive IED detection. A surprising finding is that the amplitude of IED waveforms\u2014 at first sight a primary gross characteristic of epileptiform activity was not critical in the STIED decision process. In fact, IED amplitude alone was poorly specific of visually identified epileptiform activity. Interestingly, a similarly low specificity was found in unsupervised algorithms based on ICA and HMM, for which arguments were given for the hypothesis that false positive events actually correspond to genuine but small-amplitude IEDs unidentified by clinical MEG evaluation [17]. This illustrates a possible advantage of unsupervised models. On the other hand, STIED yielded a fully automated decision, whereas both ICA and HMM were semi-automated. Further, whether such small-amplitude events, unidentified by STIED too, represent IEDs or clinically irrelevant physiological events, remains to be fully clarified. In the current state of knowledge, a conservative approach may be warranted for clinical applications so STIED likely represents the best data-driven approach so far. In the future, it will be interesting to compare the outcome of STIED and unsupervised algorithms in other types of IED recordings, such as the ICA of MEG based on optically pumped magnetometers [46] or the HMM of stereo-electroencephalography data [47].\nOur reverse engineering analysis also revealed that, while STIED does rely on both its spatial and temporal inputs (as we intended), the spatial features of IED magnetic topography bring at most a subtle added value to detection performance, compared with the temporal morphology of IEDs. In hindsight, this is likely because IED spiking waveforms are automatically accompanied with dipolar magnetic field patterns, so the latter do not add independent information to the former. Indeed, epileptiform spikes originate from bursts of hyperexcitable neurons within focal neural populations. In neocortical epilepsies (as was the case in our training group), focal excitation leads to post-synaptic current flows along apical dendrites of pyramidal neurons that are necessarily dipolar [48]. More generally, all sharp electrophysiological events-not only IEDs but also physiological transients typically occurring in Rolandic, supramarginal, and occipital areas [10], [36] as well as transient oscillatory bursts emerging in brain functional networks [49]-[51] are focal and thus dipolar. Spatial features thus hardly distinguish sharp physiological events from IEDs, which presumably explains the poorer performance of the spatial DL model. Another, more technical implication is that data augmentation by rotation of topographical patterns should not be overdone. While we initially reasoned (following standard image recognition processing) that such rotations would improve model generalizability across patients by allowing more diverse IED localizations, during our trial phase we found that coarse 90-degree rotations used here worked better than finer rotations (e.g., at 12 degrees, the sensitivity of the spatial DL model tended to increase slightly, but specificity dropped significantly, p<0.03). Associating IEDs with too many dipolar patterns presumably renders DL models oversensitive to sharp physiological events. This aspect will require further consideration when updating STIED with a larger training dataset. On the other hand, including spatial features might help against false detections of spike-like artefacts that may arise in MEG signals with atypical dipolar patterns.\nThe problem of physiological confounds was somewhat alleviated by the inclusion of temporal features, yet physiological transients with spiking waveform morphology remain a critical challenge to overcome [10], [36] as they are detrimental to detection specificity. This was illustrated by the high rate of false detections, together with the accurate location of VDS-IEDs, when applying our current version of STIED to sleep recordings of 9 out 12 patients with RFE. Some physiological transients typically emerge during drowsiness and sleep [28], so a critical next step might be to include sleep recordings of healthy controls to help STIED learn to distinguish them from epileptiform activity."}, {"title": "V. CONCLUSION", "content": "In sum, we provided proof of concept that STIED is a promising DL solution for the automated detection of IEDs in focal epilepsy. In future work, we intend to update the current version with a large-scale training dataset of labelled MEG recordings in patients with different types of epilepsies, including sleep recordings to discriminate physiological spikes. If expected improvements in model generalizability and detection specificity are confirmed, this would establish STIED as an invaluable tool to assist clinical magnetoencephalographers in getting a fast and accurate clinical evaluation of epilepsy from MEG recordings."}]}