{"title": "MULTI-STYLE CONVERSION FOR SEMANTIC SEGMENTATION OF LESIONS IN FUNDUS IMAGES BY ADVERSARIAL ATTACKS", "authors": ["Cl\u00e9ment Playout", "Renaud Duval", "Marie Carole Boucher", "Farida Cheriet"], "abstract": "The diagnosis of diabetic retinopathy, which relies on fundus images, faces challenges in achieving transparency and interpretability when using a global classification approach. However, segmentation-based databases are significantly more expensive to acquire and combining them is often problematic. This paper introduces a novel method, termed adversarial style conversion, to address the lack of standardization in annotation styles across diverse databases. By training a single architecture on combined databases, the model spontaneously modifies its segmentation style depending on the input, demonstrating the ability to convert among different labeling styles. The proposed methodology adds a linear probe to detect dataset origin based on encoder features and employs adversarial attacks to condition the model's segmentation style. Results indicate significant qualitative and quantitative gains through dataset combination, offering avenues for improved model generalization, uncertainty estimation and continuous interpolation between annotation styles. Our approach enables training a segmentation model with diverse databases while controlling and leveraging annotation styles for improved retinopathy diagnosis.", "sections": [{"title": "1 Introduction", "content": "The identification of anatomical and pathological markers visible in the fundus of the eye is the very first step toward its diagnosis. This observation holds particularly for diabetic retinopathy (DR), which is monitored longitudinally by characterising certain lesions. In contrast, for automatic diagnosis, many studies (Fauw u. a. (2018), Gulshan u. a. (2019), Yang u. a. (2021), Gu u. a. (2023)) choose a global approach that bypasses the explicit recognition of lesions. Although they achieve impressive performance, these approaches raise several issues frequently discussed in the literature as pointed by Islam u. a. (2020). First and foremost, global classification lacks transparency and interpretability for the user (physician or patient), as the diagnosis is not supported by elements seen in the image that influenced the algorithm's decision. This has motivated others works on joint lesion segmentation and classification, such as the DeepDR system proposed by Dai u. a. (2021) and recently extended by Dai u. a. (2024) for prognosis. However, these approaches require a considerable amount of data. Furthermore, the scale chosen for grading the disease relies on clinical standards that have been constructed according to precise rules for identifying lesions. However, these scales are not universal, and multiple systems coexist (ETDRS, ICDR, Scottish DR GS or Canadian Guideline among others Sun u. a. (2021)), defining more or less compatible rules. These scales are not static and evolve based on clinical understanding of the disease and the imaging modalities (Sun u. a. (2021), Yang u. a. (2022)). These considerations justify the pursuit of research on semantic segmentation of retinal lesions in fundus images alongside the global approach.\nOne of the main difficulties is obtaining sufficient annotations from qualified experts. To overcome this barrier, several teams have made their collected and annotated databases publicly available along with their models, thus promoting reproducibility and research in the field. However, despite the growing number of publicly accessible datasets, there is significant variability in the composition of these databases, both in terms of image quality and quantity, as well as the type of annotations provided. The acquisition itself may induce a distribution shift between different databases: indeed,"}, {"title": "2 Related works", "content": "Despite these considerations, research into lesions segmentation rarely addresses the issue of characterisation and comparison between databases. But their differences raise fundamental questions about interoperability: what does a model learn from databases with heterogeneous annotations? Can its behaviour be explicitly controlled? These questions echo, to some extent, the domain adaptation problem, from which we borrow certain ideas. But given that our segmentation work uses fundus images acquired under similar conditions regardless of the database considered, and that we restrict ourselves to a space of classes common to all databases, we prefer the notion of style conversion: the same types of lesions will be labelled differently depending on the annotation protocol (which we conflate with the database itself).\nOur work starts by training a single architecture on multiple combined databases, from which we highlight an unexpected result: when tested on the different databases' test sets, the model spontaneously converts its segmentation style to match the expected one and thus maximise its performance on a priori non-compatible labelling styles. This means that the network learns to recognize the origin of an image (in terms of database) and to adapt its prediction to match the expected style. To better understand and harness this behaviour, we train a probe to identify each image's database using the encoder's features. Following this, our main contributions are based on two considerations:\n\u2022 The probe's ability to detect the image's origin based on the features maps extracted by the segmentation model's encoder and decoder.\n\u2022 The well-known effectiveness of adversarial attacks to fool a classifier into moving in a targeted direction.\nWe propose to use adversarial attack to modify an image toward the distribution of any given training database with a known labelling style. By doing so, we constrain the segmentation style of the model, which provides us with an effective multi-style conversion procedure, including the ability to continuously sample different segmentation hypotheses. Notably, our methodology works on any segmentation model based on neural networks and trained on multiple databases with a regular segmentation training procedure. The style conversion is done post-training by incorporating the probe, but this operation does not require modifying the segmentation model in any way. We explore three applications of our method:\n1. Improving the performance of a model trained with multiples datasets, especially in the case where we only have a small fraction of finely labelled data.\n2. Refining a model's performance on an external (previously unseen) database by properly matching the expected style of the database per lesion.\n3. Generating an uncertainty map for the segmentation produced by a model by sampling through multiples styles. To this end, we introduce the notion of continuous conversion between two styles.\nThe rest of this paper is organised as follows: the next section situates our work within the existing literature. Section 3 describes the different stages of our methodology: characterizing the different databases considered, constructing an efficient segmentation model, and introducing a formalism describing the proposed approach to condition the model to a specific style of annotations. The details of the experimental protocol are provided in Section 4. Section 5 presents two applications of our method to style distillation and uncertainty estimation. Finally, Sections 6 and 7 provide a discussion and conclusion."}, {"title": "2.1 Fundus Segmentation Architecture", "content": "Research on lesion segmentation in the fundus of the eye has a rich history, significantly expanded in recent years. A substantial portion of this research is dedicated to designing new neural network architectures specifically tailored for lesion segmentation. Here, we focus on the most recent works related to multi-lesion segmentation of the four lesions introduced earlier. These architectures commonly emphasise the multi-scale aspect of the problem, as lesions vary greatly in size within an image and depending on their class. Guo u. a. (2019) propose L-Seg, which is based on the"}, {"title": "2.2 Multi-style conversion", "content": "The conversion to different style of segmentation is a notion rarely covered in the literature, whether for retinal images or other applications. However, it is thematically closely related to the much more covered field of uncertainty assessment, as it also involves predicting multiple plausible segmentation hypotheses from one image. The pioneering work of Gal u. Ghahramani (2016) introduced an innovative approach to uncertainty estimation in deep models. It reinterprets Dropout as a Bayesian process over the state of all possible models. Concretely, the network's inner connection are randomly dropped at inference time, the final prediction being obtained by averaging multiple forward passes following a Monte-Carlo-like sampling. To our knowledge, Garifullin u. a. (2021)'s work is the only one aiming at modelling the aleatoric uncertainty in fundus retinal lesions segmentation and it is built upon this latter approach. We take inspiration from their work to suggest a similar generation of uncertainty maps from multiple samples.\nIn style conversion, the hypotheses correspond to various ways of labelling the images, not necessarily due to the uncertainty around the lesion's structure but rather cause by the diversity of annotation protocol proper to each dataset. This observation, at the core of our experiments, has also motivated a recent paper by Zepf u. a. (2023), which distinguishes uncertainties from the style specific to each annotator. In their methodology, the style is explicitly embedded as an input of the prior network and conditions a latent space distribution. Their work expands on a rich literature on noisy labels for medical image segmentation motivated by the difficulty of acquiring (or even defining) an universal groundtruth for many tasks in this field (Kohl u. a. (2018, 2019), Bhat u. a. (2023), Qiu u. Lui (2021), Monteiro u. a. (2020)). The Probabilistic U-net by Kohl u. a. (2018) is recognised as an important milestone for the segmentation of ambiguous structures. It integrates the conditional variational autoencoder paradigm with a U-net by broadcasting a latent variable sampled from a learned Gaussian distribution inside the last stage of the decoder. The latent space encompasses the diversity of plausible segmentations given the input image and the annotator's manual labelling. Kohl u. a. (2019) extends their previous work by using multiple distributions and integrating different sampled latent variables (one for each distribution) at every steps of the decoder, thereby controlling the hypotheses at different resolutions. More recent papers have explored more complex distributional spaces (Gaussian Mixture by Bhat u. a. (2023) or discrete variable by Qiu u. Lui (2021))."}, {"title": "2.3 From Adversarial Domain Adaptation to Conversion", "content": "In contrast to these works, our approach does not explicitly model the style distribution. We share the objective of generating multiple segmentation hypotheses from a single model, but we rely on the model's ability to implicitly learn different styles. We introduce a post-training method to manipulate the input images in a way that induces a bias toward a predefined learned style. This approach aligns closely with the field of adversarial domain adaptation. In adversarial domain adaptation, the typical approach involves a min-max game between a generator and a discriminator. The generator is trained to match a source distribution to a target one, while the discriminator detects the distribution shift in the generator's output. Numerous applications based on this general idea exist, including those involving fundus images. For example, Cao u. a. (2022) uses a Cycle-GAN to improve DR classification performance by combining weak and strong supervision, while Kadambi u. a. (2020), Zhou u. a. (2024) incorporates a Wasserstein-GAN into their architecture to minimize the domain shift between different databases, achieving domain-independent semantic segmentation of the optic disc and cup. Contrary to these approaches, we do not train a generator, having observed that the regular segmentation model already behaves like one. Instead, we propose to modify the image using adversarial attacks Szegedy u. a. (2014). Adversarial attacks are less commonly applied to segmentation than to classification, due to the unique challenge posed by the large combinatorial space of outcomes (each pixel being a classification problem in itself). Works such as Rony u. a. (2023), Croce u. a. (2023) have addressed these challenges, but we adopt a simpler approach by building a proxy linear classification model as the basis of our attack."}, {"title": "3 Methodology and material", "content": "Our methodology follows from an initially counter-intuitive observation: after being trained on multiple datasets simultaneously, a model tends to adopt one style conditionally to the input image. In other words, the image's appearance betrays its origin; and since each database is characterized by a labelling style, the network matches the corresponding style to maximize its performance. The tendency of a segmentation model to be very sensitive to biased errors in annotations has been observed before by Vorontsov u. Kadoury (2021), although not specifically for retinal lesions. They conclude that it is a problem to be mitigated during training, whereas we take advantage of it in a post-training step. Indeed, further analysis of this property has led to a simple but theoretically grounded method to manipulate a model toward a specific style, which generalizes to images and databases never seen by the network during training. As a result, we can sample multiple stylised segmentations from a single conventional model."}, {"title": "3.1 Clinical elements", "content": "Our clinical framework focuses on four types of lesions, which are the most common manifestations of the first stages of diabetic retinopathy. Microaneurysms (MA) are small dilations of the capillaries appearing in very early stages of the disease. Among other causes, the rupture of a microaneurysm can cause a blood leakage, which can take many different shapes (dot, flame-like, pre-retinal, vitreous...) We refer to these as Hemorrhages (HEM) indiscriminately. The leakage from damage capillaries can also cause lipoprotein exudations called Exudates (EX) that appear as bright lesions with well defined contours. Conversely Cotton Wool Spots (CWS), corresponding to an accumulation of axoplasmic material, tend to have blurrier borders."}, {"title": "3.2 Datasets characterisation", "content": "Five distinct and publicly available databases are used throughout our study for training and validation. Each one is split into three sets (train, validation and test). We also use a sixth database named TJ-DR, recently introduced by Mao u. a. (2023), for external validation only (this database is never used for training purposes). Table 1 summarises the characteristics of the data we collected, and briefly describes the labelling procedures when known. For more details, we refer to the original papers, as the labelling procedures vary greatly between sources. It should be noted that the heterogeneity of the databases arises from two sources: the images X on one hand, and the style of the annotations Y on the other. Characterising the differences between databases within these two distribution spaces is not straightforward. For the images, we restrict our comparison to the quality of the acquisitions. We use the Multiple Color-space Fusion Network (MCF-Net) developed by Fu u. a. (2019) to classify the images into three classes: Good, Usable, Reject (Figure 1). Regarding the annotation style, we characterise it by a pair of variables (S, Q) representing the average size and number of annotated structures per image and lesion category. Figure 2 depicts the distributions obtained with Kernel Density Estimation for the five databases."}, {"title": "3.3 Segmentation models", "content": "Our methodology focuses primarily on the interaction between various databases with heterogeneous annotations. In that light, the choice of a particular segmentation architecture is secondary. However, considering the limitations highlighted in our literature review, we have undertaken to provide a standardized re-implementation of several models (specific to retinal lesions or not), accessible as a python package structured in the form of a \u201cmodel zoo\". Whenever"}, {"title": "3.5 Style conversion", "content": "In the interest of clarity, we introduce a set of notations that will be used throughout the rest of the paper. Each train (respectively test) set is referenced as $B^{(i)}$ (resp. $B^{(j)}$), where i spans across the set of databases by their initials, i.e $i \\in \\{I, M, D, R, F\\}$. An architecture trained on $B^{(i)}$ and tested on $B^{(j)}$ is noted $M[B^{(i)}](B^{(i)})$ or simply $M_{(i)}^{(j)}$. It can also be trained on multiple databases $M[\\cup_i B^{(i)}]$. In particular, we note $S = \\cup\\{I,M,D,R,F\\} B^{(i)}$ the union of all"}, {"title": "3.5.1 Notations", "content": "In the interest of clarity, we introduce a set of notations that will be used throughout the rest of the paper. Each train (respectively test) set is referenced as $B^{(i)}$ (resp. $B^{(j)}$), where i spans across the set of databases by their initials, i.e $i \\in \\{I, M, D, R, F\\}$. An architecture trained on $B^{(i)}$ and tested on $B^{(j)}$ is noted $M[B^{(i)}](B^{(i)})$ or simply $M_{(i)}^{(j)}$. It can also be trained on multiple databases $M[\\cup_i B^{(i)}]$. In particular, we note $S = \\cup\\{I,M,D,R,F\\} B^{(i)}$ the union of all"}, {"title": "3.5.2 Cross-dataset evaluation", "content": "We investigate the performance obtained by $M[B^{(i)}]$ when tested on $B^{(i)}\\forall(i,j) \\in \\{I,M,D, R, F, S\\} \\times \\{I, M, D, R, F\\}$. This is summarised in matrix form in Table 2.\nThe first five rows pertain to models that we identify as \u201cspecialised\u201d. Having been trained on only one database (and therefore a single style), they tend to adopt the style of that particular database, thereby maximising their performance on the corresponding test set. This explains the matrix's diagonal predominance in mIoU $mIoU(M_{(i)}^{(j)}, B^{(j)})$. It is noteworthy that, on average, all models tend to behave relatively similarly (last column). A column-wise reading of this matrix is also useful: it can serve as a proxy for the similarity between datasets. Expanding on this idea, the standard deviation column-wise provides a compatibility measure between datasets. As reported in Table 3, it tends to confirm that IDRID and RETINAL-LESIONS are the least compatible with (or the most different from) the other datasets."}, {"title": "3.5.3 Source identification by feature probing", "content": "In Table 2, we observe a counterintuitive behaviour of the generalist model $M[S]$: its ability to maximize the performance on a majority of test sets (excepting solely MESSIDOR), even outperforming the \u201cspecialised\u201d models. In our notation, this translates into:\n$D(M_{(S)}^{(j)}, B^{(j)}) \\geq D(M_{(i)}^{(j)}, B^{(j)}), \\forall j \\neq M$  \nThis observation holds in particular for the databases IDRID and RETINAL-LESIONS, which have radically different labelling styles. Therefore, the only way for the model to maximise its performance on both test sets is to change its segmentation style on the fly. This effect is shown in Table 4. However, the model is never explicitly fed with information regarding the source of the images; therefore the only explanation behind this behaviour is that the images"}, {"title": "3.6 Adversarial attack on the probe", "content": "Being able to detect the image's origin with an external probe serves little purpose in itself. Our main contribution relies on its accuracy and tweaks it to convert the segmentation model's style using adversarial attacks on the probe. The concept of adversarial attacks was originally discovered by Szegedy u. a. (2014) who describe them as an intriguing property of neural networks. Adversarial attacks are usually considered as a serious vulnerability of neural networks caused by their mostly linear nature and their sensitivity to gradients; however they can also be used as a form of regularisation (as in the work of Goodfellow u. a. (2015) or more recently of Croce u. a. (2023) for semantic segmentation). Targeted adversarial attacks modify the input image in an imperceptible way (to the human eye) in order to force the classifier to predict a specific class called the target. The alteration is obtained using gradient descent in the direction that minimises the loss computed between the prediction and the target t. To conceive an optimal attack, Goodfellow u. a. (2015) suggest the \"Fast Gradient Sign Method\" (FGSM):\n$X_{perturbed} = X \u2013 \\epsilon \\cdot sign(\\nabla_xL(y_x, t))$ \nwhere x is the original image, $y_x$ the prediction of the classifier from x, t the target class and L a loss function (usually Categorical Cross Entropy). Madry u. a. (2018) further elaborates on this method by suggesting an iterative scheme called \"Projected Gradients\":\n$x^{n+1} = Proj_{x+\\mathbb{S}}(FGSM(x))$ \nwhere $\\mathbb{S}$ is the sphere centred on x of allowed perturbations and Proj is a re-normalisation operator casting the perturbed image within the radius of $\\mathbb{S}$. This approach adds two additional parameters: the radius r of $\\mathbb{S}$ and the number of steps"}, {"title": "4 Experimental results", "content": "In this section, we explore in depth the results obtained with the different aspects of our methodology and extend the spectrum of its applications."}, {"title": "4.1 Segmentation comparative performance", "content": "To validate our training protocol and the choice of our architecture, we compared the segmentation performance obtained with various architectures (and encoders per architecture). The models were trained (this included checkpointing at regular interval and selecting a model based on the best validation performance ) and tested on IDRID following the conditions of the competition (Porwal u. a. (2020)). The results are reported in Table 6; we observe that our training procedure provides scores comparable with the best performances reported in the literature, even with different architectures. For the rest of this paper, we present the measures obtained with the UNet architecture with a ResNet-34 encoder."}, {"title": "4.2 Origin marker and sensitivity to perturbation", "content": "The spontaneous conversion of Ms's style depending on the data fed to it was unexpected and brings into question how the model learns to do this. We conducted a set of experiments to assess if this conversion behaviour could be altered by simple transformations of the input images. Our initial hypothesis was that different clusters of images could have been identified by Ms in an unsupervised way based either on their resolution (despite our standardisation protocol, the databases originally have varying image sizes), on the images' colour distribution (due to the diversity of acquisition hardware used or population ethnicities) or on the compression format used for storing the images (PNG or JPEG with different levels of compression). We tested this hypothesis qualitatively by trying to alter Ms's segmentation by incorporating random image modifications. Results are shown in Figure 4. Overall, we did not observe a radical shift in the model's output style with these simple perturbations."}, {"title": "4.3 Probe positioning within the network", "content": "We studied different placements of the probe within the encoder and the decoder of the segmentation model. Depending on the features received, the probe has more or less context to accurately predict the image's origin. Figure 5 illustrates this effect: for all the images in our validation sets, we measured the ability of the probe $P_{(1)}$ to predict $P_{(1)}(B^{(i)})$ i,"}, {"title": "4.4 Generalising conversion to external data", "content": "So far, we have highlighted the effect of the conversion on data distributions that were seen by the segmentation models and/or the probe, i.e. coming from one of the five datasets studied. To broaden the applicability of our methodology, we introduce a supplementary dataset in our work. APTOS (for Asia Pacific Tele-Ophthalmology Society) was released in 2019 as part of a Kaggle competition Karthik (2019). It provides 3662 images from the Aravind Eye Hospital in India. Segmentation-wise, these images are unlabelled. We refer to this base as $B^{(A)}$, and used it to demonstrate the"}, {"title": "4.4.1 Adversarial attack on the probe", "content": "We evaluated the ability to fool the probe into predicting a target class from images of the APTOS dataset, i.e:\n$P(B^{(A)\u2192i}) \\approx i$\nThis experiment also served to clarify the parameters' roles in the Projected Gradient algorithm (Equation 3). Table 7 details these results. In addition, we use this experiment to measure the speed of the conversion. It varies from 18 images per second (N = 1) to 1.1 i.p.s (N = 25). In all experiments, we set r = $\\frac{5}{255}$"}, {"title": "4.4.2 Segmentation style conversion", "content": "As observed in Table 5, the adversarial attack does not only affect the probe, but also the whole segmentation model. Effectively, the style conversion appears to work on the Aptos images (as shown in Figure 9). However, it is hard to quantitatively evaluate this effect, given that we don't have labels for Aptos, not to mention different groundtruth styles per image. As a proxy, we generate our own groundtruths using the different specialised models $M[B^{(i)}]$, which we compare with the predictions $M[S](B^{(A) \u2192 i)}$. Formally, using our notation, this is equivalent to measuring:\n$D(M_{(i)}^{(A)}, M_{S(A->i)})$"}, {"title": "4.5 Comparison with an existing approach", "content": "As we mentioned in our literature review, our work is at the relatively unique intersection of semantic segmentation of retinal lesions and style adaptation from multiple domains. To our knowledge, the work of Zepf u. a. (2023) is the only"}, {"title": "4.6 Does adversarial conversion leads to semantic alteration?", "content": "By manipulating the input image through an adversarial attack, we succeed in deceiving the classification probe and thus altering the segmentation style of the dedicated network. This raises a legitimate question: what is the risk of altering the semantic content of the input image during the conversion? To verify the integrity of the image after conversion, we have implemented a set of constraints and validations:\n1. Small Magnitude of Changes: The modifications applied to the image were of minimal magnitude, carefully controlled to avoid altering the semantic information. We expressed the maximum modification r of an image as a fraction of 255 (typically ensuring that the changes were at a level close to the acquisition quantification and imperceptible to human observers.\n5\n2. Visual Validation: We visually inspected the original and style-converted images to confirm that there were no perceptible differences. This manual check was complemented by plotting the log-residual image, $X_{plotted}$, defined as:\n$X_{plotted} = 10 log_{10}(\\frac{(x-x^{i})^2}{x^{2}})$\nFigure 7 illustrates the result obtained.\n3. Testing a classification model. We trained a DR classification model (not segmentation-based) on independent databases (EyePACS + APTOS). We assessed that the grades remained unchanged before and after conversion, which should guarantee the semantic consistency of the images before/after conversion.\nEven if there is no difference to the human eye, this does not prove that the alteration maintains consistent semantic content for a neural network. Therefore, we added an experiment to validate the semantic integrity with regard to a proxy-CNN. We trained a ConvNext-Base (Liu u. a., 2022) to classify images according to the severity of diabetic retinopathy (DR), assigning classes \u201cNo DR\u201d, \u201cModerate\u201d, \u201cMild\u201d, \u201cSevere\u201d and \u201cProliferative\u201d to each image. To train the model, we combined two publicly available datasets: APTOS and EyePACS (Emma Dugas, 2015), for a total of 38,788 images. To precisely quantify the effect of the image modification, the model was trained to perform regression toward the DR grade, offering the benefit of continuous prediction. This is a common practice as there is a natural ordering of the five classes. We ensured that the performance of the classification model aligned with the literature, suggesting that it was a good fit to classify our images before and after conversion. Any changes in this model's predictions would indicate that an adversarial conversion added or removed important structures. The continuous DR score before and after conversion for each image of the five databases is shown in Figure 8. The mean square error for each segmentation dataset varies in the range [0.11 - 0.32]. Given that a variation of 1 is needed to change the discrete diagnosis associated with an image, we conclude that the adversarial conversion does not significantly modify the semantic content of the image. Specifically, out of 1000 test images, 964 retained the same discrete grade. Upon inspection of the 36 remaining cases, the discrepancies were found where the predicted score was very close to the boundary between two discrete grades (e.g., 1.49, at the boundary between grade 1 and 2)."}, {"title": "4.7 Continuous style-to-style interpolation", "content": "Due to the nature of targeted adversarial attacks, our methodology only allows sampling among one of the five predefined styles, in a discrete form. We propose two simple ways to obtain continuous conversion using linear interpolation:"}, {"title": "5 Applications", "content": "In this section, we demonstrate three possibles applications of our method. For the first one, we illustrate how style conversion can enhance the segmentation performance by homogenising the prediction of a model trained on low and high quality annotations. Furthermore, only a small subset of the labels need to be fined grained. Secondly, we demonstrate that style conversion can significantly improve the performance on external data. Finally, we propose a method to generate uncertainty maps for a model's predicted segmentations by adapting the input space image modification used for style interpolation."}, {"title": "5.1 Style distillation to improve performance under unbalanced distribution", "content": "In this setup, we trained a model $M[B^{(I)} \\cupB^{(R)}]$ using only two datasets: IDRID and RETINAL-LESIONS. Arguably, the first one can be considered as the finest-grain dataset in term of annotations but is also the smallest with only 54 training images, whereas the second one is by far the coarsest but contains 1115 images. We tested $M[B^{(I)} \\cupB^{(R)}]$ on the DDR test, which has a style very visibly finer grained than RETINAL-LESIONS. We compared $M[B^{(I)} \\cupB^{(R)}](B^{(D)})$, $M[B^{(I) \\cupB^{(R)}]}(B^{(D)} \u2192 I)$ and $M[B^{(I) \\cupB^{(R)}]}(B^{(D)} \u2192 R)$. This required us to retrain a new two-class probe, but this operation only took 28 minutes on a RTX A6000. The conversion was done using interpolation in the input space as defined in Equation 10; the parameters \u03b1, \u03b5, N and r were adjusted qualitatively on a subset of the DDR validation set. The results are shown in Figure 10; we observe an important performance gain on the DDR test set when taking IDRID as the target style. Figure 11 highlights the effectiveness of the conversion visually. Considering that only 4.8% of the train set were finely labelled (the images from IDRiD), this demonstrates the ability to distillate a style even with a very limited amount of images corresponding to it. Conversely, as we can see in Figure 11a, without explicit conversion, the model segments in the style of the (vastly) predominant dataset (RETINAL-LESIONS). Yet, it still has learned IDRiD's style and can be biased toward it. With a priori knowledge of the expected style of a given test set, we can boost the model's performance at inference time by matching the test set's style. In particular, we observe the following hierarchy: $D(M[B^{(I)} \\cupB^{(R)}](B^{(D)} \u2192 I)) > D(M[B^{(I)}](B^{(D)})) > D(M[B^{(I) \\cupB^{(R)}]}(B^{(D)}))$. In other words, adding more"}, {"title": "5.3 Uncertainty estimation", "content": "Estimating the uncertainty of a model's predictions is useful to gain a better understanding of its internal behaviour. Inspired by the work of Garifullin u. a. (2021), we propose an estimation of the model's aleatoric uncertainty using a local perturbation-based approach. The idea is to sample Na points in the image's neighbourhood and use the predicted samples to calculate a predictive mean and standard deviation across the distribution. The sampling process reformulates Equation 10 as:\n$x_a = (1 \u2212 \u03b1) \u00b7 x + \u03b1 \u00b7 (x \u2192 j) with \u03b1 ~ U(0, 1)$\nThe aleatoric uncertainty map UA is then obtained as:\n$U_A = \u03c3_a (M[S](x_a))$ \nwhere $\u03c3_a$ denotes the standard deviation taken across the NA points. In general, the computed uncertainty $(0)$ is large in the neighbourhoods around the lesions, which can be interpreted as revealing the different styles learned by the network, but also as highlighting the ambiguous nature of some lesions' boundaries. On the other hand, it can also highlight areas corresponding to potential false negatives, particularly in the case of microaneurysms. Both situations can be seen in Figure 12."}, {"title": "6 Discussion", "content": "Our work has highlighted the concept of style adoption by a model throughout its training trajectory, contingent upon the chosen dataset. By combining several of these datasets, each characterized by a distinct annotation style, the model acquires the capacity to selectively adopt a style at inference time based on the input image. This suggests that it is able to trace back the origin of an image to an implicit latent variable. We demonstrated the robustness of this ability to various forms of simple perturbations. This in turn motivated our choice to train a linear identification probe based on the features computed by the segmentation model's encoder.\nThis probe can subsequently be subjected to manipulation through adversarial attacks, allowing a subtle alteration of the input image to deceive both the probe and the model. We highlighted that this perturbation also affects the segmentation model. Through a series of experiments, we illustrated the potential of this framework to sample multiple segmentations reflecting different styles, and even to interpolate continuously among them, all for a single image. Our approach has the distinct advantage of not necessitating any alteration to the model and is amenable to implementation within a conventional architecture. It only requires to train an external model (the probe), which is not resource intensive."}, {"title": "6.1 Limitations and future work", "content": "We acknowledge several limitations of this work, which would warrant further investigation:\n\u2022 By assumption, we equate the notion of annotation style with that of the original database. This assumption is justified by our experience that annotation style significantly depends on the protocol and tools provided to annotators. In practice, however, there will be a certain variability among annotators even within the same database. Lacking information about individual annotators, we are compelled to assume a degree of homogeneity in annotation style within a given database. Access to annotator-specific information per image rather than per database could potentially yield a finer style conversion.\n\u2022 Our style conversion is achieved through adversarial attacks, i.e., by backpropagation of gradients towards a perturbation that leads to the desired target. Deliberately, we minimize the magnitude of this perturbation, with the idea that it should not induce hallucinations of features akin to what certain GANs might produce. While this notion seems crucial in a clinical context, it complicates the hypothetical deployment of our method,"}, {"title": "7 Conclusion", "content": "This work provides an approach for training with multiple databases despite their diverse annotation styles. Indeed", "applications": "n\u2022 Model training can proceed conventionally, even on heterogeneous data, given that its behavior can be guaranteed a posteriori to match a known style.\n\u2022 By training a model on multiple databases, its generalization capabilities improve, thereby offering an avenue for leveraging a larger quantity of data.\n\u2022 Through the continuous interpolation principle between two styles, it becomes possible to generate different segmentation hypotheses. Given the substantial variability among annotators in the recognition"}]}