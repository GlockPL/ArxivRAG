{"title": "SPECIFICATION GENERATION FOR NEURAL NETWORKS IN SYSTEMS", "authors": ["Isha Chaudhary", "Shuyi Lin", "Cheng Tan", "Gagandeep Singh"], "abstract": "Specifications - precise mathematical representations of correct domain-specific behaviors are crucial to\nguarantee the trustworthiness of computer systems. With the increasing development of neural networks as\ncomputer system components, specifications gain more importance as they can be used to regulate the behaviors\nof these black-box models. Traditionally, specifications are designed by domain experts based on their intuition\nof correct behavior. However, this is labor-intensive and hence not a scalable approach as computer system\napplications diversify. We hypothesize that the traditional (aka reference) algorithms that neural networks replace\nfor higher performance can act as effective proxies for correct behaviors of the models, when available. This\nis because they have been used and tested for long enough to encode several aspects of the trustworthy/correct\nbehaviors in the underlying domain. Driven by our hypothesis, we develop a novel automated framework, Spec-\nTRA (Specifications from Trustworthy Reference Algorithms) to generate specifications for neural networks\nusing references. We formulate specification generation as an optimization problem and solve it with observations\nof reference behaviors. SpecTRA clusters similar observations into compact specifications. We present specifi-\ncations generated by SpecTRA for neural networks in adaptive bit rate and congestion control algorithms. Our\nspecifications show evidence of being correct and matching intuition. Moreover, we use our specifications to show\nseveral unknown vulnerabilities of the SOTA models for computer systems.", "sections": [{"title": "1 INTRODUCTION", "content": "Neural Networks (NNs) have recently found numerous ap-\nplications as integral components in computer systems (Jay\net al., 2019; Mao et al., 2017; 2019; Mendis et al., 2019). For\nexample, they have been applied to enhance video stream-\ning quality, congestion control, database query optimization,\nindexing, scheduling, and various other system tasks. Com-\npared to traditional heuristic-based approaches, NNs reduce\ndevelopment overheads and offer improved average perfor-\nmance (Kraska, 2021).\nDespite recent advancements, skepticism remains about\nthe practicality of NNs in computer systems. A key con-\ncern is that user-facing systems, like video streaming, re-\nquire high standards of performance and reliability in dy-\nnamic environments. Although NNs often surpass tradi-\ntional methods in average performance, they are fundamen-\ntally opaque (Chaudhary et al., 2024) and lack guarantees.\nIndeed, researchers have identified numerous counterintu-\nitive behaviors of these NNs in computer systems. For\nexample, Eliyahu et al. (2021) observed that Aurora (Jay\net al., 2019), a congestion control system, in certain condi-\ntions, would repeatedly decrease its sending rate, ultimately\nreaching and maintaining the minimal rate despite excellent\nnetwork conditions. In another example, Meng et al. (2020,\n\u00a76.3) \"debugged\" Pensieve (Mao et al., 2017), a bitrate con-\ntroller for video streaming, which systematically avoided\ntwo specific bitrates (1200 and 2850kbps); they introduced\nthese bitrates back to enhance performance.\nNote that these observations are not unique; similar behav-\niors have been extensively studied in other domains, such as\nvision (Szegedy et al., 2014; Liu et al., 2023; Athalye et al.,\n2018). For instance, in image classification, researchers\nhave identified adversarial images that can mislead vision\nmodels, such as altering a stop sign to resemble a speed limit\nsign (Eykholt et al., 2018). To address this issue, robustness\nspecifications have been introduced-requiring that, despite\nnoise, the image should still be classified correctly (Gehr\net al., 2018; Balunovic et al., 2019; Mirman et al., 2020).\nHowever, unlike vision tasks, where some notions of cor-\nrectness exist (Athalye et al., 2018; Yang et al., 2023), deter-\nmining correctness in system applications is more challeng-\ning. Typically, manually-designed specifications are hard\nto design, error-prone, and limited to some corner-cases.\nConsider the example of a video bitrate controller: given\nthe current network conditions and buffered video frames,\nit is difficult to manually label bitrate choices as \"incorrect\".\nPrior work (Eliyahu et al., 2021) has introduced specifica-\ntions based on extreme cases, excluding several desirable\ntrustworthy behaviors as we observe in our experiments.\nFurthermore, the authors of NN4SysBench (He et al., 2022),\na benchmark suite for NNs in systems, acknowledge that"}, {"title": "2 BACKGROUND", "content": "We demonstrate specifications for 2 applications - Adap-\ntive Bit Rate (ABR) video streaming (Sani et al., 2017) and\nNetwork Congestion Control (CC) (Jiang et al., 2020).\nAdaptive Bitrate. Adaptive Bit Rate (ABR) algorithms\nare used to optimize the bit rate for streaming videos\nfrom servers to clients such that the Quality of Experience,\nQoE (Balachandran et al., 2013) for the users is maximized.\nQuality of experience is typically determined by the bit rate\nof video chunks (higher is better), and the startup time, re-\nbuffering time, and bitrate variations (lower is better). An\nABR algorithm observes the video streaming system's state\nconsisting of buffer size and video chunk download time,\nobserved throughput, size of the next video chunk at all pos-\nsible bit rates, etc. to determine the bit rate at which the next\nvideo chunk should be fetched. Pensieve (Mao et al., 2017)\nis a popular neural network (NN) used for ABR. It is trained\nusing reinforcement learning (RL) to maximize the QoE.\nWe provide Pensieve's architectural details in Appendix A.\nCongestion control. Congestion control is a regulatory pro-\ncess that determines the packet sending rate across a given\nnetwork at any time, to maximize the network through-\nput (packets sent over the network) and minimize latency\nand packet loss (Jay et al., 2019). Congestion control al-\ngorithms use latency gradient (Dong et al., 2018) and la-\ntency ratio (Winstein et al., 2013) as input features and\noutput the change in sending rate for the next time step.\nAurora (Jay et al., 2019) is a popular NN-based solution for\ncongestion control, trained with RL (architectural details\nin Appendix B). The reward here is a combination of the\nthroughput, latency, and packet loss observed in the system."}, {"title": "3 FORMALIZING SPECIFICATIONS FROM\nREFERENCE ALGORITHMS", "content": "While neural networks attempt to maximize aggregate per-\nformance, we develop a set of specifications \u03a8 for individ-\nual inferences to satisfy for greater trust. Let X \u2286 R^m be\nthe sets of all possible m-dimensional (m > 0) inputs to\nthe neural network for which we want to generate \u03a8. Let\nY = [1,..., k] be the (discrete) set of all possible outputs of\nthe neural network, where 1 < k < \u221e. Such instances with\nfinite output sets are fairly common, e.g., in neural-network\nclassifiers (Zhang, 2000; Deng, 2012) and RL agents over fi-\nnite action spaces such as Pensieve (Mao et al., 2017). If that\nis not the case, we discretize Y when possible. For example,\nthe output of the Aurora congestion control model (Jay et al.,\n2019) is continuous-valued and we generate specifications\nfor it. We provide details of the output discretization for\nAurora's specifications in \u00a75.1. Each specification S \u2208 \u03a8\ndescribes the desirable behavior over a set of possible inputs\ncalled a precondition, denoted by the Boolean predicate\nO_S that evaluates to true for inputs in the precondition. S\nmandates that for all inputs x \u2208 X such that O_S(x), the\noutput y \u2208 Y should follow a postcondition, denoted by the\nBoolean predicate \u03c8_S, i.e., S(x, y) \u2252 O_S(x) \u21d2 \u03c8_S(y).\nThe specifications in \u03a8 are considered to be in conjunction,\ni.e., the overall desirable behavior is A_{S\u2208\u03a8}S.\nWe leverage the behavior of q (> 0) traditional algorithms,\naka references R_1, . . . R_q to determine \u03a8. We use multiple\nreferences to avoid \u03a8 that overfit the behavior of one refer-\nence and contain its suboptimal behaviors. Specifically, we\nconsider inputs x \u2208 X for which the combined set of out-\nputs from all the references U_{j\u2208[q]} R_j(x) is non-trivial, i.e.,\nexcludes some possible outputs from Y. For other inputs,\nthe references are not selective and do not provide useful\ninformation about the desirable behaviors in the target do-\nmain. Hence, they are not used to form the specifications.\nWe use \u03b3, the mapping between such x and their correspond-\ning outputs from references U_{j\u2208[q]} R_j (x), as the interesting\nbehaviors of references (Definition 1), which are used for\ngenerating specifications \u03a8. We hypothesize and empiri-\ncally show that if a neural network's output matches that of\nany reference for inputs in the interesting behaviors, then it\nwill be more trustworthy.\nDefinition 1. (Interesting behaviors of references). Inter-\nesting behaviors \u03b3 contain inputs x \u2208 X for which all refer-\nences R_1,..., R_q collectively lead to a non-trivial output\nset \u03b3 \u2282 Y, which is a strict subset of all possible outputs.\n\u03b3 = { (x, y) | x \u2208 X \u2227 y = U_{j\u2208[q]} R_j(x) \u2227 y \u2282 Y}\nWe use Y_x to denote the inputs x in the interesting behaviors\n\u03b3. A lookup table mapping Y_x to the corresponding outputs\nfrom the references is an exact set of specifications. How-\never, it is not amenable to downstream applications such as\nverification of the neural networks as it can potentially con-\nsist of uncountably many entries. The lookup table may not\nhave finite representations in a general case. Therefore, we\ncombine several x \u2208 \u03b3 into a single concise representation\nO_S via overapproximation in each of our specifications S\nand map it to \u03c8_S which captures the permissible output of\nx. The downside of simple and concise representations is\nthat they can potentially introduce errors by restricting the\noutputs of the additional inputs x' \u2260 x that satisfy O_S to\nY_S \u2282 Y. We attempt to minimize such overapproximation\nerrors when developing our specifications.\nTypically, concise representations consist of polyhedral con-\nstraints on permissible inputs, each of which is mapped to a\ncommon set of outputs (Brix et al., 2023). The simplest and\nwidely used polyhedral representation consists of interval\nconstraints. It leads to easily interpretable specifications.\nHence, our specifications are defined using intervals that"}, {"title": "4 SPECTRA- SPECIFICATIONS FROM\nREFERENCE ALGORITHMS", "content": "In this section, building on our formalism from Section 3, we\ndescribe our algorithm SpecTRA, for automatically generat-\ning high-quality specifications from reference algorithms.\n4.1 Practical optimization problem\nThe optimization problem (4) is hard to solve in general\nsettings, as identifying all the interesting behaviors for\nany given references is not trivial. The references can be\ncomplex functions and may lack closed-form expression.\nTo identify the interesting behaviors across multiple refer-\nences, we need to encode them in languages such as SMT-\nLib (Barrett et al., 2016) to use specialized solvers, such as\nZ3 (De Moura and Bj\u00f8rner, 2008), which requires extensive\nmanual efforts and may not be feasible for complicated ref-\nerences based on thousands of lines of intricate low-level\ncode (e.g., for congestion control). Thus, for general ap-\nplicability and ease of usage of our framework, we only\nassume access to the references through availability of some\nof their observations, from which we identify the interesting\nbehaviors. Note that we do not assume the ability to control\nthe observations by not assuming query-access to the refer-\nences unlike prior specification generation works (Astorga\net al., 2019; 2021). This causes us to use the observations\navailable from the references in production settings, while"}, {"title": "5 EXPERIMENTS", "content": "In this section, we study the quality and utility of Spec-\nTRA's specifications. We illustrate SpecTRA's specifica-\ntions in two applications having reference algorithms and\ntheir neural counterparts - Adaptive Bit Rate (ABR) al-\ngorithms in video streaming and Congestion Control (CC)\nalgorithms. Pensieve (Mao et al., 2017) is a popular neu-\nral network (NN) based RL-agent for ABR that decides\nthe bit rate for the next video chunk. Pensieve needs\nto choose from 6 possible bit rates for the next video\nchunk - 300, 750, 1200, 1850, 2850, 4300 kbps. While\nABR has several traditional (reference) algorithms, there are\ntwo salient ones, that we use as references for generating\nspecifications for Pensieve - the Buffer-based (BB) algo-\nrithm (Huang et al., 2014) and the Model Predictive Control\n(MPC) algorithm (Yin et al., 2015). Aurora (Jay et al., 2019)\nis a popular NN-based RL-agent for CC that proposes real-\nvalued changes to the rate of sending packets over a network\nto reduce congestion. The CC references that we consider\nfor generating specifications for Aurora are the BBR (Card-\nwell et al., 2017) and Cubic (Ha et al., 2008) algorithms.\nNote that our framework is general to handle more than two\nreferences. However, we expect to get fewer interesting\nbehavior regions with additional references, which may de-\nteriorate the quality of the specifications. Hence, we choose\nto limit to two references for each application. As Spec-\nTRA uses several thresholds and parameters to generate\nspecifications, we show an ablation study (Appendix D) to\nknow their effects on the specifications' quality and generate\nspecifications with the best settings.\n5.1 Experimental setup\nWe conducted our experiments on a 12th Gen 20-core Intel\ni9 processor. We collect the observations from references\nin the training environments of the NN, to generate relevant\nspecifications. For ABR, as we have the implementations of\nthe references readily available, we run them in the training\nenvironment of the target model Pensieve, with its train-\ning traces that govern the network characteristics for video\nstreaming at each time step. We use the publicly available\ntraining dataset of Pensieve consisting of 128 traces, each\nhaving 100s of time steps. We test the specifications on Pen-\nsieve's test set that consists of 143 traces, also having 100s\nof time steps each. For CC, however, the reference algo-\nrithms are embedded in the operating system kernels, mak-\ning them less amenable to run in the target model Aurora's\ntraining environment. Hence, we obtain observations for\nthem from their execution logs in the Pantheon project (Yan\net al., 2018). We retrain the Aurora models using some of\nthe corresponding network traces from Pantheon so as to\nalign the reference observations with the training environ-\nment of the models. We use 75% traces for training and\nremaining for testing the Aurora models. We describe the\ndetails of the retraining and mention the specific traces used\nin training and testing in Appendix B. We experiment with\nboth the retrained and original Aurora models. We generate\nspecifications for both applications with the observations\nfrom references on the training traces and use the observa-\ntions from the testing traces to evaluate the specifications.\nAs SpecTRA assumes a finite discrete set of outputs, which\nis not the case for Aurora (output is real-valued change of\npacket sending rate), we discretize the output using the sign\nfunction, which gives the sign of the change resulting in\n3 possible outcomes: '+', '-', and '0'. SpecTRA uses the\nDBSCAN (Ester et al., 1996) clustering algorithm to solve\nthe optimization problem in (7). We detail the settings of\nDBSCAN in Appendix C. SpecTRA develops the specifi-\ncations on a subset of input features of the target NN for\nwhich we empirically observe the best quality of specifica-\ntions. For ABR, SpecTRA uses the current buffer size and\nthe download times observed in the last 3 time steps. For CC,\nSpecTRA uses the history of the latency gradient, latency\nratio, and sending ratio features used by Aurora, over previ-\nous 4 time steps. We have selected these specific features\nfor the two applications following those in the manually-\ndesigned specifications in Eliyahu et al. (2021) and selected\nthe history of the features in specifications with an ablation\nstudy in Appendix D. We keep the coverage threshold, T_cov\nto be 1, so as to get specification sets with the highest possi-\nble coverage. SpecTRA generates specifications for either\napplication in less than 30 seconds.\n5.2 Quality of Specifications\n5.2.1 Quantitative analysis\nTo evaluate the quality of the specifications, we check\nthem against the observations from the references over\nthe training and testing environments for the neural mod-\nels. We use the specification evaluation metrics of support\nand confidence inspired from prior specification mining\nwork, Lemieux et al. (2015) and data mining literature (Han\net al., 2011). We formally define these metrics next.\nWe want the specifications to cover most of the observations\nD_j from each reference R_j to correctly describe their be-\nhavior. For this, we measure the fraction of observations"}, {"title": "6 RELATED WORK", "content": "Specifications for neural networks. The current approach\nto generate specifications for neural networks (NNs) is\nlargely dependent on human design. Many existing works,\nsuch as (Eliyahu et al., 2021; Wu et al., 2022; Wei et al.,\n2023), rely on experts to design their specifications. Also,\nin the International Verification of Neural Networks Compe-\ntition, VNN-Comp (Brix et al., 2023), expert-designed spec-\nifications are used in benchmarks, including for Adaptive\nBit Rate and Congestion Control. However, the quality and\nrelevance of these expert-designed specifications remain un-\nclear. Recent work (Geng et al., 2023) proposes to automati-\ncally mine neural activation patterns (NAP) as specifications.\nNAP refers to the pattern of activation functions\u2014whether\nthey are activated or deactivated\u2014given a specific neural\nnetwork and an input. Geng et al. (2024) introduces mul-\ntiple approaches to mine NAPs for a given neural network.\nSpecTRA differs from NAP mining as SpecTRA's specifica-\ntions can generalize beyond the target neural networks and\ncan be intuitively validated with domain knowledge.\nSpecification generation for programs. There is a long\nhistory of work focused on synthesizing specifications for\ntraditional programs, which has inspired SpecTRA. Unlike\nprior work (Ernst et al., 1999; Ammons et al., 2002; Park\net al., 2023; Astorga et al., 2019; 2021), SpecTRA targets\nneural networks instead of traditional general programs. To\nthe best of our knowledge, SpecTRA is the first to mine spec-\nifications for neural networks in computer systems using\nreference algorithms. Astorga et al. (2023) also synthesize\ncontracts for neural networks, but they operate in a setting\nwith query-access to an oracle, which is not practically ex-\ntensible to the applications we study.\nNN verification. NN verification formally verifies given\nneural networks for desirable properties such as robustness\nto input perturbations. It can be broadly classified as com-\nplete (Jaeckle et al., 2021; Ferrari et al., 2022; Xu et al.,\n2021) and incomplete (Xu et al., 2020; Singh et al., 2019)\nverification. NN verification is NP-complete (Katz et al.,\n2017), which is hard to scale to larger NNs. However, the\nNNs in computer systems are generally small due to effi-\nciency requirements and hence are conducive to verification."}, {"title": "7 CONCLUSION", "content": "We present an automated approach for generating specifica-\ntions for neural networks in applications where trustworthy\nreference algorithms exist. We formalize specification gen-\neration as an optimization problem and propose an effective\nalgorithm SpecTRA. We show specifications for two impor-\ntant applications \u2014 adaptive bit rate setting and congestion\ncontrol. We analyze the quality of SpecTRA's specifications\nand use them to verify and identify previously unknown\nvulnerabilities in SOTA neural networks."}, {"title": "A PENSIEVE'S ARCHITECTURAL DETAILS", "content": "Pensieve's original architecture (Mao et al., 2017), that cor-\nresponds to our mid model has the following structure:\nFirst Layer: 3 parallel fully connected layer, each contains\n128 neurons, and an 1D convolution layer with 128 filters\nand kernel size is 4. These 4 layers take the input features\nin parallel.\nSecond Layer: A fully connected (linear) layer with 128\nneurons.\nOutput Layer: A fully connected (linear) layer with 6\nneurons.\nFollowing the NN4Sys benchmarks in VNN Comp 2024\n(https://sites.google.com/view/vnn2024),\nwe also include the small and big models for Pensieve,\nhaving the following architectures.\nSmall\nFirst Layer: 4 parallel fully connected layer, each contains\n128 neurons.\nSecond Layer: A fully connected (linear) layer with 128\nneurons.\nOutput Layer: fully connected (linear) layer with 6 neurons.\nBig\nFirst Layer: 3 parallel fully connected layer, each contains\n128 neurons, and an 1D convolution layer with 128 filters\nand kernel size is 4. These 4 layers are parallel.\nSecond Layer: A fully connected (linear) layer with 256\nneurons.\nOutput Layer: fully connected (linear) layer with 6 neurons."}, {"title": "B TRAINING AURORA", "content": "Aurora model architectures. In this paper, we provide\ntwo different architectures for the Aurora model: the small\nmodel and the mid model. The mid model retains the same\narchitecture as the initial Aurora policy agent from the origi-\nnal paper (Jay et al., 2019), which utilized a fully-connected\nneural network with two hidden layers of 32 \u2192 16 neurons\nand employed a tanh nonlinearity function. We have also de-\nveloped a small model with a similar architecture but scaled\ndown to two hidden layers of 16 \u2192 8 neurons, also using\nthe tanh nonlinearity.\nTraining and testing setting. The original Aurora model\nwas trained in a gym simulation environment designed to\nreplicate network links, with bandwidth and latency ran-\ndomized to reflect real-world conditions.\nTo adapt Aurora for conditions similar to those experienced\nby BBR and Cubic, we made slight modifications to the\nsimulation. This included using varied bandwidth from\nPantheon traces (11 in total, available at Pantheon Traces),\nas well as adjusting loss rate, packet queue size, and one-way\ndelay. To ensure broad coverage of bandwidth scenarios,\nwe increased the training steps.\nIn training, we simulate network conditions using Pantheon\ntraces. Each condition includes:\n\u2022 Bandwidth Trace: Patterns of bandwidth over time.\n\u2022 Loss Rate: Percentage of packets dropped.\n\u2022 Delay: Time for a packet to travel one way.\n\u2022 Queue Size: Maximum packets held in the network\nbuffer before forwarding or dropping.\nUsing 11 traces, we had 18 distinct network conditions by\nvarying loss, delay, and queue size. We split these con-\nditions, with 75% used for training and 25% for testing,\nensuring the RL-based Aurora model is not exposed to test\npatterns during training. During training and testing, we\nensure that all testing network conditions are run at least\nonce.\nIn our experiment, with a fixed random seed of 0, the split\nis as follows:\n\u2022 Training Conditions: 13, 14, 2, 5, 9, 8, 7, 15, 18, 6, 4,\n11, 16\n\u2022 Testing Conditions: 1, 3, 10, 12, 17\nNetwork condition details can refer below:"}, {"title": "C DBSCAN CLUSTERING SETTINGS", "content": "DBSCAN operates by identifying core points in given data.\nCore points have a prespecified minimum number of points\nin their neighborhood, specified by a given radius r. We\nset the minimum number of samples min, to the number\nof points that make the cluster achieve the representation\nthreshold Trep. For a low volume of specifications, we\nkeep r as the minimum radius that can ideally contain the\nminimum number of points, if densely packed."}, {"title": "D ABLATIONS", "content": "To select the best thresholds and SpecTRA's parameters,\nwe study the variation in the support and confidence of\nSpecTRA's specifications over the training observations\nwith the various settings. Specifically, we consider the\nhistory length of the features used in the specifications,\nrepresentation threshold Trep, the number of partitions (p)\nof the input space X along each dimension, and the maxi-\nmum permissible number of outputs in each specification\nTmax. Figures 2a and 2b show the quality of the specifi-\ncations for ABR and CC respectively. We select those pa-\nrameters for our main experiments that yield specifications\nwith high support and confidence over all the references,\nas observed in this ablation study. We select history = 3\n(previous 3 download times will be used in specifications),\nTrep = 0.01, p = 100, Tmax = 5 for ABR and history = 4\n(previous 4 observed features will be used in specifications),\nTrep = 0.01, p = 50, Tmax = 2 for CC."}, {"title": "E SPECTRA'S GENERATED\nSPECIFICATION SET FOR ABR", "content": "The following specifications 3 were generated by SpecTRA\nfor ABR, to be used in conjunction.\nSpecifications 3: Conjunctive specifications for ABR. (BS:\nBuffer Size, DT[-i]: ith last download time, BR: Bit Rate)\nPrecondition\nBS \u2208 [0.4,0.5],\nDT[-1] \u2208 [0.15, 0.66],\nDT[-2] \u2208 [0.15, 0.79],\nDT[-3] \u2208 [0.54, 1.05]\nPostcondition\nBR \u2208 {300.0, 750.0, 1200.0, 2850.0}\n1\nPrecondition\nBS \u2208 [0.4,0.5],\nDT[-1] \u2208 [0.15, 1.05],\nDT[-2] \u2208 [0.02, 0.79],\nDT[-3] \u2208 [0.15, 1.05]\nPostcondition\nBR \u2208 {300.0,750.0, 1200.0, 2850.0, 4300.0}\n2\nPrecondition\nBS \u2208 [0.4, 0.5],\nDT[-1] \u2208 [0.28, 0.66],\nDT[-2] \u2208 [0.15, 0.66],\nDT[-3] \u2208 [0.54, 0.92]\nPostcondition\nBR \u2208 {300.0, 750.0, 2850.0}\n3\nPrecondition\nBS \u2208 [0.4, 0.5],\nDT[-1] \u2208 [0.28, 0.66],\nDT[-2] \u2208 [0.15, 0.79],\nDT[-3] \u2208 [0.41, 1.05]\nPostcondition\nBR \u2208 {300.0, 750.0, 1200.0, 4300.0}\n4"}]}