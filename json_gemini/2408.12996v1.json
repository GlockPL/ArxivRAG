{"title": "Enhancing Knowledge Tracing with Concept Map and Response Disentanglement", "authors": ["Soonwook Park", "Donghoon Lee", "Hogun Park"], "abstract": "In the rapidly advancing realm of educational technology, it becomes critical to accurately trace and understand student knowledge states. Conventional Knowledge Tracing (KT) models have mainly focused on binary responses (i.e., correct and incorrect answers) to questions. Unfortunately, they largely overlook the essential information in students' actual answer choices, particularly for Multiple Choice Questions (MCQs), which could help reveal each learner's misconceptions or knowledge gaps. To tackle these challenges, we propose the Concept map-driven Response disentanglement method for enhancing Knowledge Tracing (CRKT) model. CRKT benefits KT by directly leveraging answer choices\u2014beyond merely identifying correct or incorrect answers- -to distinguish responses with different incorrect choices. We further introduce the novel use of unchosen responses by employing disentangled representations to get insights from options not selected by students. Additionally, CRKT tracks the student's knowledge state at the concept level and encodes the concept map, representing the relationships between them, to better predict unseen concepts. This approach is expected to provide actionable feedback, improving the learning experience. Our comprehensive experiments across multiple datasets demonstrate CRKT's effectiveness, achieving superior performance in prediction accuracy and interpretability over state- of-the-art models.", "sections": [{"title": "1. Introduction", "content": "Knowledge Tracing (KT) serves as a critical component in educational technology, capturing the dynamic processes of human learning [2, 10, 29]. It outlines a learner's cognitive state through their interaction history with educational materials, predicting future achievements and potential misun- derstandings. Recent advances in KT methodologies, particularly through deep learning, have significantly enhanced our ability to understand and pre- dict learning trajectories with remarkable accuracy [8, 14, 30]. Despite such progress, conventional KT models still exhibit some limi- tations. Primarily, those models often rely only on binary responses, i.e., correct or incorrect, to infer students' knowledge states. These responses overlook the differences that can be drawn from the multifaceted nature of student responses, especially in the context of Multiple Choice Questions (MCQs) [15]. Such questions typically provide various incorrect options, each potentially reflecting different student misconceptions or knowledge gaps. This reliance on binary responses limits the depth and accuracy of insights gained from KT, as it fails to capture the nuances in student responses. Furthermore, the valuable data inherent in unchosen responses\u2014options considered but not selected by the student\u2014remains largely unexplored. These unchosen options offer critical insights into students' decision-making processes and conceptual understanding, providing a more comprehensive view of their knowledge states. While a few KT models have leveraged op- tions in the KT scenario [3], they are still limited in obtaining robust and rich knowledge state representations. Deep learning models have recently enhanced the capability to track com- plex patterns in learning data by representing knowledge states in multi- dimensional vectors [28]. While effective in capturing intricate learning trajectories, this approach often obscures the interpretability of knowledge states, making it challenging to provide actionable feedback to learners or ed- ucators [6]. In other words, representing knowledge states in multi-dimensional vector spaces does little to clarify specific areas of strength or improvement for individual learners. Additionally, some existing models acknowledge the relevance of concepts associated with questions but largely neglect the complex relationships be- tween these concepts [24, 41]. These concepts often serve as prerequisites for"}, {"title": "2. Related Work", "content": "Knowledge Tracing is crucial in educational data mining, offering a method- ology to assess and model students' knowledge over time. [14, 29, 30, 39] This process predicts the likelihood of a student correctly answering upcoming questions, thus providing a dynamic snapshot of their learning trajectory. KT methodologies have evolved from Item Response Theory models [12, 23], which utilize user and item parameters to measure question difficulty and student ability, to more sophisticated sequential approaches that capture the subtle differences of learning history [19, 40]. Recent advancements have in- troduced Recurrent Neural Networks (RNN), Dynamic Key-Value Memory Networks (DKVMN), and transformer-based models, significantly broaden- ing the scope and accuracy of KT."}, {"title": "2.B. Concept Relations in Knowledge Tracing", "content": "The performance enhancements in KT have been achieved through vari- ous features, among which concepts have played a crucial role in compressing the representation between numerous questions and sharing knowledge mas- tery. Recent studies have strived to represent the relationships between these concepts, either directly or indirectly [24, 35, 42]. Various approaches have been employed to form these relations, such as viewing the relationships be- tween concepts as a dense graph [26], creating a joint graph with questions or students through the student's problem-solving history [13, 33], and forming a hypergraph with various features like templates [38]. Additionally, varia- tions of Graph Neural Networks (GNNs) have been widely used to encode these structures efficiently. However, these studies have limitations in forming the interrelations within the concepts; they directly generate relations using problem-solving history or statistical methods not designed by experts. Therefore, these approaches can potentially create incorrect connections or omit meaningful relationships, acting as noise in tracking the knowledge state."}, {"title": "2.C. Option Tracing", "content": "Option Tracing (OT) advances KT by analyzing students' choices on MCQs beyond simply whether answers are correct or not [15]. Conventional KT methods focus on binary response data, offering a broad estimate of stu- dent mastery but neglecting the detailed insights that can be obtained from"}, {"title": "2.D. Disentangled Representation Learning", "content": "Disentangled learning aims to separately represent underlying factors within complex data [7, 16, 21]. This method organizes information into distinct vector segments, focusing on reducing the overlap or mutual infor- mation between these segments, promoting a more precise and interpretable representation of each factor. By doing so, disentangled learning enhances models' accuracy and explainability across various domains [25, 34]. The goal is to better understand the data by isolating its components, which can significantly improve decision-making and predictive performance. In recommendation systems, user preferences are filtered by multi-feedback, including negative and unclicked items, enhancing performance and inter- pretability [5, 36]. Inspired by such research, we introduce disentangled representations to extract a more precise knowledge state from the user's responses."}, {"title": "3. Preliminary", "content": "This section provides an overview of knowledge tracing tasks and intro- duces essential concepts and terms for this study."}, {"title": "3.A. Problem Statement", "content": "Knowledge tracing aims to track a student's current knowledge state based on their past problem-solving history and to predict whether a given target question will be answered correctly. For a student s, assuming the student s has sequentially solved questions up to time t, the problem-solving"}, {"title": "3.B. Unchosen Response", "content": "In existing research, correct and incorrect responses have been utilized as indicators of student responses to questions [30]. Given KT's goal of deducing a student's knowledge state from a sequence of responses, it logically follows that representations of these responses in KT models reflect the degree of mastery increase or decrease over knowledge elements like concepts. This paper expands upon traditional binary response models by incorporating detailed option responses for each question, characterized by which option was chosen. Thus, the representation of each option response is interpreted as signaling a change in the knowledge state upon the selection of that option. Building on the discussion of selection responses, this study also incor- porates responses that are not chosen. Under the assumption that a stu- dent did not choose an answer due to guessing or mistakenly not following their original intention, a student's decision to exclude specific options in favor of another indicates positive or negative discrimination between chosen and unchosen options. This discrimination offers additional insights into the strengths or weaknesses that the student may perceive in the chosen option"}, {"title": "3.C. Concept Map", "content": "Previous research has explored the connections among concepts by gen- erating graphs from a key-value memory [24] or employing dense graphs [26]. Such approaches have been deemed valuable for representing knowledge states"}, {"title": "3.D. Item Response Theory", "content": "Item Response Theory (IRT) [12] is a foundational framework in edu- cational assessment designed to model the relationship between a student's latent ability and their responses to questions. In the mid-20th century, IRT has evolved to provide more accurate insights into learner performance and question attributes than traditional scoring methods. Central to IRT is the Item Characteristic Curve (ICC) [22], a mathematical model that connects a student's ability to the difficulty level of an item. This model posits that the probability of a correct response is influenced by the interaction between the student's ability and specific features of the question, such as its difficulty. Integrating IRT into deep learning-based KT models enhances interpretabil- ity by leveraging the student's history of item responses to predict the like- lihood of accurately answering future questions [13]. The ICC, fundamental to IRT, expresses the probability of a student answering a question correctly, based on their ability and the item's difficulty, which can be denoted as:\n$$p(correct response) = \\frac{1}{1 + e^{-(ability - difficulty)}}.$$"}, {"title": "4. Method", "content": "This section provides a detailed explanation of the CRKT. The foun- dational architecture of CRKT is illustrated in Fig. 3. CRKT processes the student's selected and unchosen option responses through response en- coders, accounting for the context of responses and generating a compre- hensive representation of the student's responses. A unified knowledge state is constructed using an attention-based knowledge retriever in conjunction with the question representation. This mechanism is further refined at the concept level, integrating into a concept map with question-specific edge weights. The knowledge state for each concept is then established by ap- plying a GNN [17], converting each knowledge state into a scalar value. To enhance interpretability in prediction, the relevance of each concept to the target question is calculated, aiding in deducing the student's ability to solve the target question. Finally, predictions about the accuracy of responses are made by incorporating IRT [12] to consider the questions' difficulty."}, {"title": "4.A. Disentangled Response Encoder", "content": "A student's knowledge state at time t can be determined through his history of item responses from time 1 to t. We aim to compile a student's"}, {"title": "4.B. Knowledge Retriever", "content": "Attention-based methods offer distinct advantages over traditional sequence- based KT approaches. One of the primary strengths of attention-based meth- ods is their ability to assign different levels of importance to past response records by applying weights that consider the target question. We aim to retrieve knowledge states by integrating the question representation sequence with the disentangled response representation sequence. Inspired by DTrans- former [40], we utilize a temporal and cumulative attention mechanism that leverages the following attention calculation:\n$$AttentionMax(Q, K, V) = MaxOut(\\frac{Q K^T \\cdot e^{-\\eta \\cdot d(\\Delta t)}}{\\sqrt{d_k}}) V$$\nwith\n$$MaxOut(x_i) = \\frac{softmax(x_i)}{max_j{softmax(x_j)}}.$$\nwhere \\eta is the parameter that controls the strength of the temporal effect, and d(\\Delta t) is the distance function measuring the temporal and semantic distance between a query and a key. This approach helps aggregate rele- vant experiences while considering the learning process's temporal aspects. The MaxOut operation ensures that repeated efforts on the same concept or question are properly weighted, reflecting the cumulative effect of learn- ing. By combining temporal and cumulative considerations, this attention mechanism allows the DTransformer to estimate the knowledge state better. The specific implementation details of this module are outlined in Al- gorithm 1. Similar to the disentangled response representation d_t on line 10, the question representation q_t \\in \\mathbb{R}^{d_q} is also subjected to a self-attention mechanism to derive context-aware representation \\hat{q}_t on line 9 in Algorithm 1. The knowledge retriever also employs the temporal and cumulative atten- tion mechanism to discover a student's knowledge state h_t at time t, using the sequence of questions as both the query and key, and the sequence of responses as the value on line 12 in Algorithm 1. This approach ensures that the derived knowledge state is closely aligned with the contextual relevance of the question and the student's cumulative response pattern, enabling a precise evaluation of the student's current understanding."}, {"title": "4.C. Concept Map Encoder", "content": "To leverage the relationships between concepts and improve interpretabil- ity, we first extend the knowledge state to the concept level for mapping onto a concept map as follows:\n$$M_t = {m_{t,1},..., m_{t,|\\mathcal{C}|}},$$\nwhere\n$$m_{t,i} = f_{concept}([h_t \\oplus c_i]).$$\nHere |\\mathcal{C}| is the number of concepts in \\mathcal{C}, c_i \\in \\mathbb{R}^{d_c} is the d_c-dimensional embedding vector of concept c_i, and \\oplus is the concatenation operation. To formulate the knowledge state related to concept c_i, denoted as m_{t,i} \\in \\mathbb{R}^{d_g}, we concatenate corresponding concept representation c_i with the aggregated knowledge state h_t extracted from the student's item response record. This concatenation is processed through a 2-layer MLP, f_{concept}, which transforms a (d_q + d_c)-dimensional input into a d_g-dimensional representation, thereby yielding m_{t,i}. Accordingly, the collective knowledge state for all |\\mathcal{C}| concepts at time t, represented as M_t \\in \\mathbb{R}^{|\\mathcal{C}| \\times d_g}, is obtained, enabling a comprehensive mapping of concept-related knowledge states to the concept map."}, {"title": "4.D. IRT-based Prediction", "content": "We do not merely feed the knowledge state and target question into a final MLP to get the probability of a student accurately answering the target"}, {"title": "4.E. Model Training", "content": "Finally, to optimize the predicted probability \\hat{y} of students correctly an- swering the target question at all times T, we apply the binary cross-entropy loss:\n$$L_{\\mathcal{KT}} = -\\sum_{t=1}^{T} (y_t \\log \\hat{y_t} + (1 - y_t) \\log (1 - \\hat{y_t})).$$\nAdditionally, we introduce two more loss functions to enhance the model's performance. The first additional loss function is designed to encourage the relevance score r_{q_{t+1},c_i} to correctly identify the top-k concepts related to the target question q_{t+1}:\n$$L_{topk} = -\\sum_{t=1}^T \\sum_{i=1}^{\\mathcal{C}} (g_{q_{t+1},c_i} \\log r_{q_{t+1},c_i} + (1 - g_{q_{t+1},c_i}) \\log (1 - r_{q_{t+1},c_i}))$$\nwith\n$$g_{q_{t+1},c_i} = \\mathbb{1} [c_i \\in \\mathcal{C}_{q_{t+1}}].$$\nThis loss function ensures that the concepts most relevant to the target ques- tion are ranked higher, thereby improving the relevance and interpretability of the model's predictions. We applied weight to the positive label when con- ducting experiments to address the imbalance between positive and negative labels. The weight of the positive label is (|\\mathcal{C}| \u2014 |\\mathcal{C}_{q_{t+1}}|)/k, where \\mathcal{C} represents the entire set of concepts and \\mathcal{C}_{q_{t+1}} is the concept set of question q_{t+1}. The second additional loss function is for contrastive learning applied to the student's knowledge state, with a specific focus on questions that have an average correct rate of 40% to 60%. These questions are notably chal- lenging for KT models to predict, largely because KT models' predictions tend to overfit to the average correct rate of the questions. To address this issue, we aim to provide a stronger supervision signal to the knowledge states when students solve these questions, enhancing the differentiation between the knowledge states of students who answer correctly and those who do not. We propose a correct rate-aware response flip augmentation to gener- ate positive and negative histories for each student. From these modified histories, we derive corresponding positive h^{s+} and negative h^{s-} knowledge states. Through contrastive learning, we train our model to align the stu- dent's original knowledge state h^s close to h^{s+} and further from h^{s-}."}, {"title": "4.F. Time Complexity Analysis", "content": "The CRKT model is composed of four distinct modules: the disentangled response encoder, knowledge retriever, concept map encoder, and IRT-based prediction module. The disentangled response encoder initially processes the accuracy of selected responses over time, necessitating a time complexity of O(T), where T is the total length of response history. Given that the sequence"}, {"title": "5. Experiment", "content": "In this section, we conduct experiments to answer the following five re- search questions:\nRQ1 How does CRKT perform compared to existing KT models?\nRQ2 How do different components affect the performance of CRKT?\nRQ3 How do text-based representations compare to general learning-based models?\nRQ4 Where does CRKT improve over existing KT models?\nRQ5 How can CRKT be applied in real-world scenarios?"}, {"title": "5.A. Datasets", "content": "In this section, we describe five datasets used for our experiments. Our method applies only to datasets that include students' option responses and concept maps. Table 1 presents the statistics for each dataset."}, {"title": "5.B. Baselines", "content": "For an exhaustive comparison with our proposed model, CRKT, we se- lected seven KT models as baselines. The descriptions of the baseline models are provided below."}, {"title": "5.C. Experimental Setup", "content": "We set the maximum length of the input sequence to 200 and conducted 5-fold cross-validation for all models and datasets. Additionally, we exclude sequences shorter than 5 that are too short to extract meaningful knowledge states. We use 80% of the student sequences for training and validation, with the remaining 20% for testing. All models and experiments were implemented using the PyTorch library with version 2.3. We employ the ADAM optimizer for a maximum of 200 epochs, with an early-stop mechanism ceasing training if there is no improvement in validation loss over 10 consecutive epochs. The embedding dimensions da and d_c are set to 32. The learning rate, the hyperparameter \\lambda, the number of layers in GNN of the concept map encoder L, and the embedding dimension d_g are searched from [1e-3, 1e-4, 1e-5], [0.2, 0.5, 0.8], [1, 2, 3, 4], and [16, 32], respectively. For IRT-based prediction, k, for top-k concepts, was tuned from the values [5, 7, 10, 20] to find the optimal setting that maximizes relevance accuracy. Additionally, the coefficients \\alpha and \\beta were explored within the range [0.01, 0.1, 1.0] to balance the contributions of the top-k loss and contrastive learning loss to the overall model performance."}, {"title": "5.D. Prediction Performance (RQ1)", "content": "We employ accuracy (ACC) and the area under the curve (AUC) as eval- uation metrics for all datasets. Additionally, we conduct a t-test against the best baseline, where * indicates p-value < 0.01 in the t-test. According"}, {"title": "5.E. Ablation Study (RQ2)", "content": "To explore the individual impact of each module in CRKT, we design four variations and perform an ablation study. Each variant is as follows:\n\u2022 noOpt removes the option responses and instead uses binary responses like other KT models.\n\u2022 noUnc removes the unchosen response, utilizing only the chosen option response.\n\u2022 noMap removes the concept map, utilizing the concept-level knowl- edge state directly extracted from the knowledge retriever.\n\u2022 noTopK allows the knowledge states of all concepts to contribute to the ability calculation."}, {"title": "5.F. Usage of Textual Information (RQ3)", "content": "We investigate the effectiveness of utilizing textual information within the proposed CRKT model, which typically derives question and response rep- resentations through learning-based approaches. We aim to determine how effectively the dataset, which provides detailed information about questions and options, can leverage textual information from the question's text. Given the inherent challenge of distinguishing between option represen- tations directly from their text, we utilize the capabilities of a large language model (LLM) to enhance our representations. Specifically, we provided the question information to OpenAI's ChatGPT7, which then generated expla- nations for the solution approach and reasons why a student might choose each option. These generated texts were then employed as representations for questions and each option's responses."}, {"title": "5.G. Performance via Correct Rate (RQ4)", "content": "In this section, we analyze the performance of different models across four datasets based on the average correct rate of questions. As depicted in Fig. 5, we observe that model accuracy tends to increase at the extremes of the average correct rate spectrum. This trend likely stems from the skewed distribution of score labels for questions at these extremes. Notably, the models struggle most with questions with an average correct rate between 40% and 60%, indicating these are the most challenging for prediction."}, {"title": "5.H. Case Study (RQ5)", "content": "We conduct a visualization analysis to validate the representational ca- pabilities and interpretability of CRKT's knowledge states. Fig. 6 above"}, {"title": "6. Discussion and Conclusion", "content": "CRKT meets the research objective of enabling the practical application of KT models in educational services. However, there are still limitations that need to be addressed.\nA limitation of CRKT is its reliance on predefined concept maps to ac- curately encode the correct relationships among concepts. In this paper, we employ statistical methods to infer these relationships in datasets lacking such concept maps. However, the effect of these inferred relationships is not as large as expected, suggesting that the effectiveness of the currently employed statistical approach could be improved. Enhancing these methods could improve our model's accuracy and efficiency by better capturing the interdependencies among concepts. For future research, we aim to refine CRKT to ensure it can provide stable, reliable, and interpretable feedback within actual educational ser- vices. This includes improving the model's ability to integrate and utilize concept relationships without the need for predefined maps and advancing the statistical methods used to determine these relationships. For example, the work in [20] preliminarily proposed a method to tag knowledge concepts for questions with Large Language Models (LLMs). Authors in [11] also suggested the potential usefulness of structuring textual data by extracting hierarchical relationships among concepts. By developing more sophisticated approaches to identify concept interactions dynamically, we hope to create a more versatile and universally applicable model that can function effectively across diverse educational datasets without the need for manual input of con- cept maps. These advancements will support CRKT's broader application in real-world educational settings, enhancing personalized learning experiences through more accurate and meaningful feedback."}, {"title": "6.B. Conclusion", "content": "In this paper, we introduce the Concept map-driven Response disentan- glement method for enhancing Knowledge Tracing (CRKT) model, a new approach to knowledge tracing that enhances prediction performance and interpretability by utilizing student responses and concept maps. With the novel use of unchosen MCQ options and concept-level knowledge through the concept map, CRKT provides a more accurate update to knowledge states,"}]}