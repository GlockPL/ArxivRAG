{"title": "Werewolf Arena: A Case Study in LLM Evaluation via Social Deduction", "authors": ["Suma Bailis", "Jane Friedhoff", "Feiyang Chen"], "abstract": "This paper introduces Werewolf Arena, a novel framework for evaluating large language models (LLMs) through the lens of the classic social deduction game, Werewolf. In Werewolf Arena, LLMs compete against each other, navigating the game's complex dynamics of deception, deduction, and persuasion. The framework introduces a dynamic turn-taking system based on bidding, mirroring real-world discussions where individuals strategically choose when to speak. We demonstrate the framework's utility through an arena-style tournament featuring Gemini and GPT models. Our results reveal distinct strengths and weaknesses in the models' strategic reasoning and communication. These findings highlight Werewolf Arena's potential as a challenging and scalable LLM benchmark.", "sections": [{"title": "1 Introduction", "content": "Creating truly human-like AI requires sophisticated cognitive abilities such as reasoning about others' intentions, navigating deceptive information, and convincingly communicating in complex social settings. Evaluating these nuanced skills in both humans and LLMs poses a significant challenge, as traditional benchmarks often fall short (Ullman, 2023).\nSocial Deduction Games (SDGs), such as the popular game Werewolf, present a compelling avenue for addressing this challenge. SDGs encapsulate many of the complexities of human social interaction, requiring players to utilize various reasoning skills (e.g., temporal, deductive, and inductive) within an uncertain environment. In Werewolf, Villager and Werewolf players engage in a battle of wits, leveraging deception and persuasion to achieve their respective goals.\nFurthermore, the inherent information asymmetry of Werewolf, where only some players possess incomplete knowledge of others' roles, mirrors dynamics of real-world social interactions.\nOur Monte Carlo simulation (Algorithm 1) highlights the critical role of strategic communication in overcoming this asymmetry. Without it, Villagers win a mere 1.2% of 100,000 simulated games.\nRecently, Werewolf has emerged as a popular sandbox for LLM research. Prior work has demonstrated sophisticated agents capable of adapting communication strategies (Jin et al., 2024), employing deductive reasoning for optimal action selection (Xu et al., 2024; Shibata et al., 2023), and using system-2 thinking during gameplay (Wu et al., 2024). Researchers have also explored techniques like retrieval and reflection mechanisms (Xu et al., 2023) to enhance agent learning and created valuable datasets comprising gameplay logs and multimodal artifacts (Lai et al., 2022) to train these agents and establish benchmarks (Chern et al., 2024).\nBuilding on this foundation, Werewolf Arena makes two key contributions.\nFirst, recognizing the importance of strategic communication, we introduce a dynamic turn-taking system where players bid to speak, rather than relying on predefined or random speaking orders. This bidding mechanic closely mirrors real-world group discussions, where individuals strategically time their contributions. This adds a nuanced layer to agent evaluation, allowing us to assess not only what is said but also when an agent chooses to speak.\nSecond, unlike past work of developing techniques to improve agent performance, we use Werewolf as a proving ground. To evaluate the relative skills of LLMs we have the models play each other. We design a balanced framework where a single model, playing both Villager and Werewolf roles, results in a relatively even win rate for both sides. This balanced setup ensures fair comparisons by minimizing inherent advantages for either"}, {"title": "2 Related Work", "content": "Simulating Social Interaction and Strategic Reasoning: LLMs are transforming agent-based social simulations, enabling agents to communicate, reason (Zhao et al., 2023), solve problems (Wei et al., 2023a), and plan strategically (Song et al., 2023). This has led to advancements in simulating nuanced human behavior in complex social settings (Sreedhar and Chilton, 2024; Zhou et al., 2024; Park et al., 2023; Vezhnevets et al., 2023), and allowed for more believable and capable non-player characters (NPCs) (Ammanabrolu and Riedl, 2019; Urbanek et al., 2019; Wang et al., 2023a). In this landscape, social deduction games, now offer a compelling avenue for studying social dynamics, cooperation, and deception (Kopparapu et al., 2022; Oertel and Salvi, 2013; V\u00e1zquez et al., 2015; Leibo et al., 2017; Wang et al., 2023b; Ibraheem et al., 2022).\nOpen-Ended Benchmarks for LLMs: While static reasoning benchmarks are plentiful (et al., 2023; Liang et al., 2023; Hendrycks et al., 2021; Valmeekam et al., 2024), fewer focus on dynamic, competitive evaluations of LLMs. Platforms like LMSYS rely on human evaluation to rank chatbots (Chiang et al., 2024), while Kaggle Simulations, though providing game-like environments, limit games to agents powered by the same model (Kaggle Inc., 2024).\nThere is room for new benchmarks that evaluate LLMs on their ability to leverage cooperation, deception, and strategic communication in dynamic competition with other models. This type of benchmark offers several benefits: it bypasses the need for human annotations, prevents future data contamination (Deng et al., 2024), and remains relevant as models improve."}, {"title": "3 Werewolf Environment", "content": "This section describes the simulated environment of Werewolf we use in Werewolf Arena."}, {"title": "3.1 Game Implementation", "content": "As illustrated in Figure 1, the game starts with 8 players, consisting of 1 Seer, 1 Doctor, 2 Werewolves, and 4 Villagers. It progresses through rounds until either all Werewolves are exiled (Villager win) or their numbers equal those of the Villagers (Werewolf win). For each game, we randomly select 8 names from a pool of 17 names, to minimize any initial name bias.\nGameplay requires players to discern others' roles while protecting their own identities. The game proceeds in two phases. During each Night, special roles happen simultaneously: the Werewolves conspire to eliminate a single Villager, the Doctor chooses someone to protect, and the Seer investigates a player to learn their role. The Daytime proceeds sequentially: it consists of a structured debate among all players and a subsequent voting session, where a majority is required for exile.\nCurrently, debates are capped at 8 turns, ensuring each player a chance to speak in the first round."}, {"title": "3.2 Agent Architecture", "content": "Agents are equipped to perform a suite of actions essential to Werewolf's gameplay:\n\u2022 Core Actions: All agents engage in voting to determine player exiles, debating to influence others and gather information, and bidding for their turn to speak, reflecting the dynamic nature of group discussions.\n\u2022 Special Role Actions: Agents assigned as Werewolves, Doctors, or Seers execute night-time actions of eliminating a villager, protecting a player, and investigating a player's true role, respectively.\n\u2022 Agent Memory: Drawing inspiration from (Park et al., 2023), each agent possesses a memory stream that contains observational and reflective memories. The observational memories record all game-level events and privileged information accessible to each player based on their role (e.g., a Seer's memory would include the results of their investigations). At the end of each round, agents engage in summarizing, distilling key insights from the debate. These reflective summaries enable agents to recall pertinent information and notice patterns in subsequent rounds.\nEach action is guided by a tailored prompt template\u00b9. This template incorporates the agent's memories and the current game state from their perspective, ensuring contextually appropriate actions. To counter the early-game tendencies observed in (Xu et al., 2024) of selecting the first or last option in a list, we randomize the order that player names are presented during voting and special actions."}, {"title": "3.3 Dynamic Turn-Taking through Bidding", "content": "In most one-on-one chatbot or agent interactions, participants take turns in a fixed speaking order. However, in multi-party conversations without a predetermined order, even the most advanced language models struggle to navigate the complexities of turn-taking (Tan et al., 2023). Training-time techniques exist to address this, such as using \"silence\" tokens (Wei et al., 2023b) or speaker-utterance-addressee triples (Gu et al., 2021). A recent inference-time technique demonstrated a \"Group Chat Manager\" who orchestrates the conversation and selects the next speaker (Wu et al., 2023). While potentially effective, this approach sacrifices the autonomy of individual agents.\nSince the essence of gameplay in Werewolf revolves around the fluid exchange of accusations, defenses, and sharing of information, allowing agents autonomy to determine their own speaking order is crucial. To achieve this goal, we implemented a system where agents express their desire to speak by bidding. This mimics the organic decision-making process in human group discussions, where individuals weigh the importance of their contributions against the flow of conversation.\nIn this system, agents choose from four distinct levels of interest in speaking:"}, {"title": "3.4 Models", "content": "Our evaluation focuses on two leading large language model (LLM) families: Google's Gemini (Team, 2024) and OpenAI's GPT (OpenAI, 2024; Brown et al., 2020). From the Gemini family, we used Gemini 1.5 Pro (gemini-1.5-pro-preview-0514), Gemini Pro (gemini-pro), and Gemini Flash (gemini-1.5-flash-001), all accessed through the Vertex AI API. Our assessment of the GPT family included GPT-4 (gpt-4-turbo-2024-04-09), GPT-4o (gpt-4o-2024-05-13), and GPT-3.5 (gpt-3.5-turbo-0125), accessed through the OpenAI API."}, {"title": "4 Debate Dynamics", "content": "This section examines the dynamics of the debates, the most critical mechanic in Werewolf. During the debate, players engage in information (or misinformation) exchange, alliance formation, and persuasion tactics to influence voting decisions.\nIn Figure 3, we see the distribution of bids as the debate evolves. In the beginning of the game, when there is less information available, the majority of the players only want to observe (bidding 0). As the debate goes on, we see more and more players opting to participate. Notably, around 40% of bids from mentioned players consistently remain at the maximum value (4), indicating a strong desire to respond directly to being mentioned.\nTo analyze the impact of bidding on player alignment and consensus, we simulate voting after each utterance. These synthetic votes, based on the current game state and partial debate, do not affect actual gameplay and are not stored in player memories. Instead, they provide a proxy for gauging how other players receive each line of dialogue.\nFigure 4 illustrates the influence of dialogue on player alignment from a single debate. The Seer's revelation of Derek the Werewolf instantly divides the village. Some Villagers believe the Seer's accusation against Derek, while others suspect the Seer, Ginger, herself. Derek's subsequent defense includes fabricating a role and flinging around an accusation. This makes a previously unconvinced Villager suspicious of Derek, but the Doctor remains suspicious of Ginger. Only after Tyler backs up Ginger and calls out his suspicious behavior does the Doctor shift their vote.\nThis example demonstrates the dynamic impact of dialogue on player alignment, as reflected in the shifting synthetic votes."}, {"title": "5 Arena Evaluation", "content": "In this section, we present the results of a tournament designed to assess the relative strengths of different language models in Werewolf Arena."}, {"title": "5.1 Win Rate Analysis", "content": "We designed a two-phase tournament to assess the performance of six leading LLMs.\nIn the first phase, we conducted intra-family round-robin tournaments, where models within the Gemini and GPT families competed against each other. Each pairing engaged in 10 games, with models alternating between the roles of Villager and Werewolf for 5 games each. Additionally, each model participated in 5 games of self-play. This phase aimed to establish baseline performance and assess the relative skill within each family. As shown in Figure 5, all models, except GPT-3.5 achieved relatively balanced win rates (40-60%) in self-play, indicating a relatively balanced game setup where neither the Werewolf nor Villager roles had an inherent advantage.\nWithin each family, we observed performance variations. Gemini 1.5 Pro consistently outperformed both Gemini Pro and Gemini Flash as both Werewolf and Villager. In contrast, GPT-4 and GPT-4o exhibited more comparable performance, with GPT-4 demonstrating a slight edge.\nNext, the top-performing models, Gemini 1.5 Pro and GPT-4, engaged in a head-to-head matchup (10 games). Both models demonstrated proficiency in strategic reasoning and social deduction. However, Gemini 1.5 Pro emerged as a stronger overall player, excelling especially as a Villager. This success may be partially attributed to GPT-4's tendency towards verbose communication, which was sometimes perceived as suspicious by other agents."}, {"title": "5.2 Gemini 1.5 Pro vs GPT-4", "content": "5.2.1 Qualitative Observations\nWhile the number of games limits statistical significance, qualitative analysis of the game logs revealed several compelling trends:\nSkill and Creativity: Both models exhibited high strategic skill and creativity, consistently analyzing debate patterns, identifying inconsistencies, and leveraging past observations to inform decisions.\nCommunication Style:\n\u2022 GPT-4 players: Favored longer, more formal utterances, often emphasizing collaboration and consensus-building. They exhibited a relatively narrow emotional range in their dialogue, rarely expressing strong emotions.\n\u2022 Gemini 1.5 Pro players: Communicated with shorter, less frequent utterances characterized by greater emotional expression. They frequently incorporated humor, sarcasm, and expressions of frustration or suspicion into their dialogue."}, {"title": "5.2.2 Bidding Behavior and Verbosity", "content": "Figure 6 compares the bid distributions of GPT-4 and Gemini 1.5 Pro players from their head-to-head games. As Werewolves, GPT-4 exhibited a tendency to place higher bids, leading to more frequent participation in debates (3.13 times per round on average) compared to Gemini Werewolves (1.75 times per round). While bidding strategies appeared more similar for Villagers, GPT-4 Villagers still spoke more frequently (6.25 times per round) than their Gemini counterparts (4.86 times per round).\nSince both models seemed adept at noticing the differences between their styles and identifying the"}, {"title": "6 Seer Evaluation", "content": "While overall win rates provide valuable insights into model performance in Werewolf Arena, they don't explain the underlying skills and strategies driving those victories. The Seer, with their ability to uncover Werewolves, plays a pivotal role in shaping the game's trajectory. This section dives deeper into Seer performance, analyzing how different models navigate the inherent risks and rewards of this important role."}, {"title": "6.1 The Seer's Dilemma: Information vs. Risk", "content": "The Seer's actions can dramatically influence the outcome of a Werewolf game. Our simplified Monte Carlo simulation (Algorithm 1) highlights this impact. In this simulation, where the Seer automatically reveals a Werewolf's identity whenever they unmask one, and Villagers blindly trust this information, Villagers achieve a 100% win rate. This starkly contrasts with the 1.2% win rate observed in a no-information exchange scenario from before. This emphasizes the potential power of the Seer's role to shape the game.\nHowever, real-world Werewolf gameplay is far more nuanced. Seers face a critical dilemma: revealing a Werewolf's identity can expedite the elimination of a threat but simultaneously paints a target on their back, making them vulnerable to Werewolf attacks during the night. Furthermore, they must contend with potential skepticism from fellow Villagers, as a Werewolf might falsely claim the Seer role to deceive them."}, {"title": "6.2 Seer Performance", "content": "To assess how the different models approach the Seer's dilemma, we analyze each instance where a Seer publicly reveals their own role or another player's role. We use Gemini 1.5 Pro and the prompt provided in Appendix B to identify these reveals within the game logs, focusing on unique player reveals per round to avoid counting duplicate reveals.\nTable 1 presents key Seer performance metrics:\n\u2022 Reveals Per Game: The average number of times a Seer revealed either their own role or another player's role per game.\n\u2022 First Reveal Round: The average round in which a Seer first revealed their identity.\n\u2022 Unmasked Wolf (%): The percentage of reveals that correctly identified a Werewolf.\n\u2022 Believed (%): The percentage of these Werewolf reveals that were believed by the Villagers, leading to the Werewolf's exile.\n\u2022 Backfired (%): The percentage of Werewolf reveals that backfired, resulting in the Seer being exiled instead of the Werewolf.\nExamining these metrics reveals distinct strategies and outcomes among the models. Gemini 1.5 Pro Seers tended to reveal their identity and information earlier in the game, often in the first round. In contrast, GPT-4 and GPT-4o Seers, particularly GPT-4, consistently delayed their reveals until later rounds. This decision by GPT-4 Seers, as illustrated in the example below, highlights their focus on self-preservation and gathering more information before potentially becoming a target."}, {"title": "7 Conclusions", "content": "This paper introduced Werewolf Arena, a novel framework for evaluating LLMs in the context of the social deduction game Werewolf. Recognizing the importance of strategic communication, we introduced a dynamic turn-taking system where agents bid to speak, mirroring real-world conversational dynamics. This bidding mechanic enables a richer evaluation by considering not only what an LLM agent says, but also when they choose to say it.\nOur preliminary tournament results demonstrate the potential of Werewolf Arena as a challenging benchmark for evaluating language models' strategic reasoning, deception, and communication skills. The observed differences in gameplay between Gemini and GPT highlight the impact of communication style and strategic decision-making on success in social deduction games.\nFurthermore, evaluating language models through open-ended games like Werewolf offers a significant departure from traditional benchmarks. Instead of being compared on static metrics, models in this arena engage in dynamic, interactive gameplay, trying to outsmart one another. The inherent open-endedness ensures the benchmark's continued relevance, as Werewolf cannot be definitively \"solved\".\nWe hope that this framework, along with our publicly available code, will encourage further evaluation of LLMs using social deduction games."}, {"title": "8 Limitations and Ethical Considerations", "content": "This study acknowledges several limitations. First, the simplified Werewolf game environment used does not fully represent the complexities of a real life game. Second, while our agent architecture incorporates post-training reasoning, more sophisticated methods could significantly enhance performance. Third, the limited number of games played, 10 for each model pair, may not provide statistically robust results.\nWe acknowledge the dual nature of LLM persuasive language capabilities. While we exploited these capabilities to navigate the intricacies of the Werewolf game, they possess broader implications that could extend beyond our intended use. While we found no harmful or sensitive content in our study, the theoretical potential for ethical lapses exists. Therefore, we highlight the necessity for robust safeguards and transparent mechanisms in Al systems."}, {"title": "C Consensus", "content": "We can also use synthetic votes to examine how consensus emerges during the debate using the concept of voting entropy, inspired by Shannon entropy (Shannon, 1948).\nWe calculate voting entropy (H) for each round of the game using:\n$H = - \\sum_{i=1}^{n} p_i \\log_2(p_i)$                                                              (1)\nwhere pi is the probability of a player receiving a vote, and n is the number of players receiving votes at round r. A higher value of H indicates greater uncertainty or disagreement among players regarding whom to vote for, while a lower value suggests a growing consensus. To understand how dialogue influences voting entropy, we track changes in H after each dialogue turn.\nWe then average H at each debate index per round over all games that reach round r, Gr. By calculating H per round, we account for the decreasing number of players as the game progresses. The average entropy for round r and debate index i is then:\n$H_{ri} = \\frac{1}{G_r} \\sum_{g=1}^{G_r} H_{rig}$                                                                 (2)\nFigure 7 displays the average voting entropy (H) across all games for each dialogue turn, grouped by the round in which that debate occurred.\nAs expected, Figure 7 shows a clear trend of decreasing entropy as the debate progresses within each round. This finding aligns with the intuition that players gain more information and solidify their voting decisions as the discussion unfolds. The decrease in entropy is most pronounced in the earlier rounds, reflecting the higher initial uncertainty when players have limited information.\nWe observe that players on average reach a majority consensus (i.e., enough players align their votes to determine the exile outcome) between the 2nd and 5th lines of the debate. This suggests that allowing"}]}