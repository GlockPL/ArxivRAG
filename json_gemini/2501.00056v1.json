{"title": "Transforming CCTV cameras into NO2 sensors at city scale for adaptive policymaking", "authors": ["Mohamed R. Ibrahima", "Terry Lyons"], "abstract": "Air pollution in cities, especially NO2, is linked to numerous health problems, ranging from mortality to mental health challenges and attention deficits in children. While cities globally have initiated policies to curtail emissions, real-time monitoring remains challenging due to limited environmental sensors and their inconsistent distribution. This gap hinders the creation of adaptive urban policies that respond to the sequence of events and daily activities affecting pollution in cities. Here, we demonstrate how city CCTV cameras can act as a pseudo-NO2 sensors. Using a predictive graph deep model, we utilised traffic flow from London's cameras in addition to environmental and spatial factors, generating NO2 predictions from over 133 million frames. Our analysis of London's mobility patterns unveiled critical spatiotemporal connections, showing how specific traffic patterns affect NO2 levels, sometimes with temporal lags of up to 6 hours. For instance, if trucks only drive at night, their effects on NO2 levels are most likely to be seen in the morning when people commute. These findings cast doubt on the efficacy of some of the urban policies currently being implemented to reduce pollution. By leveraging existing camera infrastructure and our introduced methods, city planners and policymakers could cost-effectively monitor and mitigate the impact of NO2 and other pollutants.", "sections": [{"title": "Introduction", "content": "Cities house more than half of the world's population [1], which influence individuals' behaviour [2] as well as their physical [3, 4] and mental health [5]. Every day, hundreds of millions of people spend several hours commuting on the spatial network of cities exposed to several risks, including air pollution. There is no dispute about the need for developing a fundamental understanding of how, collectively, individuals move from one location to another in their daily lives. This could be linked with pollution indicators to aid in emission reduction.\nNitrogen dioxide (NO2) is a major pollutant that can harm severely one's health [6-12]. NO2 is formed by the combustion of fuels such as natural gas, diesel, petrol, and coal, and it can be found in the air as a result of traffic or a variety of land uses in cities, including industrial processes. NO2 levels (measured in \u00b5g/m\u00b3) vary in major cities worldwide [13]. Several studies have mapped NO2 emissions from space [13-21], whether during pandemics [13, 22] or after a policy is implemented [14, 16, 20, 23]. While relying on satellite imagery is beneficial for many cases, including understanding the change in emission over a long period or across several large cities [15, 16, 20, 22, 24], the spatial and temporal representations are often limited for understanding the dynamics of emission at a neighbourhood, district, or even many of the cities globally. Consequently, a substantial knowledge gap exists in linking micro-level events occurring frequently to their impact on emissions, thereby hindering the ability of policymakers to take localised actions. The objectives of this study are as follows: 1) to what extent the existence of specific traffic modes influences the surface NO2 level, 2) what effect congestion and stationary modes have on the level of NO2, and 3) whether there is a significant temporal lag between what happens in traffic now and its impact on the future level of NO2 at a given location.\nAnalysing urban dynamics at the street level through visual data can uncover details that may be missed when when observing from space [25]. Recent progress in deep learning for predicting traffic flow [26] aids in estimating pollutant levels in cities. Multi-modal sensor fusion has advanced by integrating data from various sensors to improve environmental predictions [27]. These techniques could enable air quality estimation by combining CCTV visuals with other sensor data. Effective sensor deployment is crucial for urban-scale monitoring to ensure comprehensive coverage and reliable data collection [28]. In this study, we introduce innovative techniques that leverage statistical analysis and graph neural networks to sense ambient ground-level NO2 concentrations and their underlying factors using CCTV camera feeds on a city-wide scale. This approach proves invaluable, especially in cities lacking an extensive network of environmental sensors. It provides an automated means of detecting the concentration of NO2 levels and their causes related to the dynamics of traffic, empowering urban planners, and policymakers to actively monitor and respond to emerging issues in real-time, guided by the dynamic flow patterns within cities. Our methodology offers a non-physical (hardware-free) solution for monitoring ground-level NO2 in urban areas where CCTV cameras are prevalent but NO2 sensors are scarce, a situation encountered in numerous cities worldwide."}, {"title": "Results", "content": ""}, {"title": "Multi-level Spatiotemporal representation of traffic modes", "content": "To understand the influence of individual road users and their transportation modes on NO2 ground-levels within the city, adopting a bottom-up approach that details individual trajectories is crucial. This strategy is invaluable for accurately assessing the real-time NO2 concentrations at specific locations and times, as well as evaluating the exposure that individuals face during their commutes. Previous research across various domains has explored the use of human trajectories from GPS data for similar assessments [29-32]. However, the limited availability of such data and substantial privacy concerns complicate the widespread replication of these methods. Therefore, it is imperative to discover alternative data sources that can accurately reflect traffic dynamics and roadway user behaviours while preserving anonymity. Successfully"}, {"title": "The effect of location and environment on ground-level NO2", "content": "Geographical factors, such as the proximity to farmland, industrial zones, or various land uses, significantly influence traffic patterns and, as a result, levels of NO2 (See Fig. 3-A). To investigate the spatial relationship between NO2 and traffic, we developed a hot spot analysis to cluster total traffic and NO2 levels based on the spatial dependency of neighbouring high or low values, yielding statistically significant clusters (p < 0.05) of spatial outliers. Here, we show a spatial lag when examining the locations of hot spots for both variables at a given time (See Fig. 3-B and 3-C).\nWe observe a spatial lag which could be attributed to confounding variables related to environmental factors such as rainfall, wind speed, and direction that either concentrate or disperse emissions from their sources. Moreover, the observed spatial lag may also be linked to the lifetime of NO2 [20, 37-42], which introduces a temporal delay between traffic emissions and the resultant ground-level concentration of NO2 detected in a specific area. We will further investigate this in the following section by relying on"}, {"title": "The effect of time and the dynamics of traffic modes on ground-level NO2", "content": "Given the relationship between NO2 levels and total traffic is nonlinear at all times and locations (See Fig. S2-A in supplementary), modelling NO2 ground-levels requires considering the entire urban landscape as an integrated dynamic system. This approach is especially pertinent because air pollution tends to diffuse and is influenced by numerous factors, such as wind speed, direction, existing green spaces, and proximity to industrial zones or farmlands, in which we have studied. These elements collectively contribute to a nonlinear impact on localised NO2 levels within the network.\nMoreover, NO2's behaviour in the atmosphere adds another layer of complexity to this topic. NO2 can have variable lifetimes in the air, ranging from a few hours to a whole day depending on meteorological conditions and the presence of other chemical species [20, 37-42]. During daylight hours, UV light from the sun can drive photolytic reactions that convert other nitrogen oxides such as NO into NO2, further altering the dynamics of air quality. This chemical interplay indicates that emissions and concentrations of NO2 are fluid, changing not just with traffic flow and industrial activity, but also with the shifting patterns of sunlight and weather.\nDespite the complicated dynamics influenced by environmental and chemical processes, there is a discernible linear relationship between NO2 and types of traffic observed over the course of a day at specific camera locations. This linearity in smaller, more controlled environments suggests that while broader city-wide models must account for complex inter-dependencies and nonlinear behaviours, localised predictions and assessments can successfully utilise simpler linear models. This dichotomy highlights the need for a layered approach in environmental monitoring and management, blending both detailed, location-specific data and broader, systemic perspectives to form a comprehensive understanding of urban air quality.\nBuilding on this, the temporal dynamics play a crucial role in analysing the patterns of NO2. To dissect how each factor influences NO2 levels at distinct times, we implemented two distinct statistical methodologies. Firstly, we employed a spatial regression model for each hour of the day, resulting in 24 unique models. This method helps identify the direct impact of various factors on NO2 levels at specific hours. Secondly, to explore how each factor may influence future levels of NO2, we developed a Granger Causality analysis model for each factor (8 models in total). This technique is particularly useful for pinpointing significant temporal lags and understanding the predictive relationship between the factors and subsequent NO2 concentrations. These approaches allow us to identify not only the immediate effects of factors on NO2 levels but also their delayed impacts, thus providing a more comprehensive understanding of the temporal dynamics at play. This layered analysis ensures a more nuanced insight"}, {"title": "NO2 Clock.", "content": "Furthering our understanding of the temporal dynamics, Fig. 4 shows a novel visual representation of the NO2 clock, showcasing statistically significant linear relations between certain factors and NO2 levels, characterised for each hour of the day. This graphical display helps to encapsulate NO2 levels and the main associations observed: for instance, trucks exhibit a consistent linear correlation with NO2 during midday, night, and the early hours of the morning. In contrast, buses tend to influence NO2 levels predominantly during the morning and afternoon peak traffic periods. Stationary cars contribute to air pollution during the peak morning hours around 10 am, and their influence extends into midday, primarily while idling in traffic jams. This is different from other periods when stationary vehicles, mainly parked, have little or no impact on pollution. During busy traffic, however, the idling of these cars significantly elevates NO2 levels. Expanding on these observations, the data also reveals that stationary buses notably contribute to NO2 during the morning rush hours (8-9 AM). Furthermore, locality factors such as proximity to industrial areas (within a one-mile radius) demonstrate a substantial effect on NO2 concentrations during specific times specifically in the evening (7-8 PM) and early morning hours. These insights underscore not only the diverse temporal relationships between different vehicles and NO2 concentrations but also illuminate the role of geographic and stationary factors in influencing air quality at different times of the day. This level of detail enriches our understanding of urban air pollution dynamics and highlights the critical interplay between temporal, vehicular, and locational determinants in shaping urban NO2 levels.\nExpanding on the analysis of significant temporal lags where specific traffic modes influence and Granger-cause future NO2 levels, our data demonstrates that the time series of each traffic mode Granger-causes the series of NO2 with notable statistically significant lagged values. For instance, car flows are likely to Granger-cause NO2 levels with lag times ranging from 2 to 6 hours, varying by location. Meanwhile, stationary cars manifest a more immediate impact on NO2 concentrations, typically with a 2-hour lag. In terms of heavier traffic elements, congested traffic flows and stationary buses exert a more prolonged effect on NO2 levels, showing significant impacts at lags of 5 and 6 hours. Stationary trucks, on the other hand, show a swift influence with only a one-hour lag, suggesting their emissions rapidly integrate into the local atmosphere. Conversely, moving trucks have a more extended influence, where the current flows can predict NO2 levels up to 5 hours into the future. These findings are also linked to the chemical behaviour of NO2 in urban air. The timeline of influence observed ties back to the variable atmospheric lifetime of NO2 [20, 37-42], which can differ from several hours to a full day, influenced by ambient conditions such as sunlight and temperature. Solar radiation promotes the photolytic cycle that converts NO to NO2, fundamentally affecting how quickly emissions from traffic transform into atmospheric NO2. Therefore, the timing of traffic flows and their characteristic effects on NO2 can directly correlate with these natural diurnal variations, reinforcing the need to consider both chemical kinetics and traffic dynamics when analysing urban air quality patterns. This multi-faceted approach provides a richer, more accurate"}, {"title": "The impact of policies on the dynamics of ground-level NO2", "content": "Not only do factors connected to place and time have a significant impact on NO2 levels, but so do the measures and regulations implemented in London driven by specific location and time. According to our Granger analysis, the effect of traffic in a given location on the level of NO2 can appear after several hours, we found that limiting certain traffic modes, such as trucks, under certain policies (i.e. London Lorry"}, {"title": "Transforming CCTV cameras into NO2 sensors with a Graph-to-Graph Neural Network", "content": "Building on our understanding of the complex spatiotemporal dynamics of NO2 levels, we are faced with the challenge of deducing these levels from the complex and nonlinear interactions among various variables. To address this, we developed a Graph-to-Graph deep model using deep learning [44, 45], specifically geometric deep learning [46-50], to learn the presented spatiotemporal links and other latent ones that could contribute to the level of NO2 at a given location while accounting for the dynamics of the entire network, traffic flows in London, and fluid dynamics derived from wind direction and speed. Fig. 5-A shows the overall conceptual framework of the developed pipeline to forecast NO2 in London using hourly traffic modal flows in London. The introduced framework also integrates additional secondary data such as weather conditions and spatial features, among other variables (See Fig. S1 in supplementary). The developed model learns in semi-supervised settings from both the states of a given node represented in terms of traffic flows for each mode and the links between nodes represented in their adjacency and their potential influence elsewhere.\nGiven that the positions of both cameras and environmental sensors are not constrained to one another (as previously shown in Fig. 1-B), the stated problem shifts from identifying regressor values on the same graph to generating a whole graph of a different adjacency matrix than the one given as an input. It is important to note that we used a weighted graph in which fewer links for traffic modes are identified based on the number of nearest neighbours to mimic the actual spatial network, whereas, for the graph of environmental sensors, we used a fully-connected network because air can diffuse freely from one location to another without the spatial constraints of a given network. The model was able to learn to create spatially distributed NO2 values, resulting in a surface of NO2 concentration over London at a given hour, using the described method (See Fig. 5). We also trained several models to assess our method (refer to the methodology section and Table S5)."}, {"title": "Discussion", "content": "Monitoring the dynamics of the environment and tracking the progress of environmental policies remains a difficult but critical issue in achieving urban sustainability. In this study, we demonstrated how CCTV cameras and autonomous vision systems"}, {"title": "Limitations", "content": "There are still data uncertainties in big data, particularly video streams, making the presented traffic counts an approximation of day-to-day operations in Greater London. These uncertainties stem from factors such as camera field of view, obstruction, or biases due to the chosen locations for sensors [51]. Effective sensor deployment is essential for urban-scale monitoring to ensure comprehensive coverage and reliable data collection [28]; however, this study assumes both cameras and NO2 sensors are provided and does not cover sensor placement. The placement of CCTV cameras can introduce biases into our NO2 predictions. Cameras are typically located in high-traffic areas, which may not fully represent overall urban air quality. We have discussed this limitation and the measures taken to mitigate its impact. As a result, we considered numerous strategies such as recognising outliers and data stationary wherever it is acceptable for a certain method. Furthermore, many features derived from data tend to follow rational thinking of patterns that are predicted to be shown, according to descriptive analysis. For example, cars contribute to traffic congestion but not bicycles, the two traffic peaks of a given day when the total flow is distributed throughout all hours of a given day, and the negative relationship between cycling and the level of NO2, among other things.\nWhile the presented models require minimal inference time (<0.1sec) to generate NO2 at a given hour, it is critical to understand the centralised computational requirements for computing and extracting traffic flow data from CCTV video feeds"}, {"title": "Methods", "content": "Our study enhances CCTV-based analysis and NO2 monitoring by demonstrating the use of existing infrastructure for environmental sensing, which is especially beneficial for cities with limited access to specialised air quality sensors. Our method can be implemented in other cities with a sufficient number of CCTV cameras. For city-wide NO2 prediction, our model utilises traffic data extracted from cameras, along with environmental and locational factors, and the computed signature of this data to predict city-wide NO2 levels. The camera and NO2 sensor locations do not have to coincide, providing flexibility in applying and transferring this method to any location. The input data comprises traffic data extracted from CCTV camera footage, including various road users' modal flows and their stationary statuses. Additionally, we included environmental factors such as average wind speed, wind direction, wet hours, sun hours, rainfall, average pressure, average humidity, average temperature, and proximity to industrial zones. The ground truth data for training and validating our models were sourced from hourly NO2 sensor measurements across multiple locations within London. The target features for our models were the NO2 levels, either at specific sensor locations or across a generated surface for city-wide prediction. By integrating the computed signature of the traffic data with locational and environmental features, our models provided accurate predictions of NO2 levels, demonstrating the feasibility of using existing CCTV infrastructure for environmental monitoring and policy-making. Here, we describe the materials and methods utilised to develop this research.\nHere we describe our materials and the different methods utilised to develop this research."}, {"title": "Materials", "content": "All raw data sources can be accessed online.\nLondon CCTV data: We collected video streams that represent 892 unique camera locations across London for 56 different hours of scattered days in the year 2021. This data includes 65,493,858 sequential frames, in which the total data or a subset of it has been used for different analyses represented in the paper. We also collected additional video data for a given camera (ID) for a given hour (12 am-1 pm) across all the days of the year to show the seasonal dynamics of traffic patterns. The data can be accessed via API permissions from Transport for London (TfL).\nHourly NO2 data: We extracted hourly N02 data of 144 unique sensors that link to the extracted video hours. The raw data can be accessed through an API from London Air: https://www.londonair.org.uk/london/asp/annualmaps.asp\nWeather data: We linked the camera and NO2 data to the weather day based on a day resolution. We included nine variables as a representation of the environmental conditions of a given day. This data, includes 1) average wind speed, 2) wind direction, 3) wet hours, 4) sun hours, 5) rainfalls, 6) average pressure, 7) average humidity, 8) average temperature, and 9) average feels like temperature. The raw data can be accessed from: http://nw3weather.co.uk/wxdataday.php?vartype=wmean&year=2021\nSpatial data: We used GIS shapefile data for the spatial representations of London's boroughs, spatial network, and the boundary of the city. The spatial network data included 1) whether a given street is two-directional, 2) average speed and 3) the type of the street. The raw data can be accessed from Greater London Authority: https://data.london.gov.uk/dataset/statistical-gis-boundary-files-london\nCar flows based on engine types: To evaluate the percentage of electric cars to petrol and diesel ones in each borough, we used the traffic flow data provided by London Council. This data is used for statistical analysis to account for the ratio of cars based on the engine types that we observe in CCTV cameras at a given location. The data is entitled: \"laei-2019-major-roads-vkm-flows-speeds\" and can be accessed from: https://data.london.gov.uk/dataset/london-atmospheric-emissions-inventory--laei--2019\nProximity to industrial zones: We used Strategic Industrial Location Points to calculate a buffer zone of 1 mile and account for the camera's locations that are within this zone. The raw dataset can be accessed online from: https://data.london.gov.uk/dataset/strategic-industrial-location-points-london-plan-consultation-2009"}, {"title": "Extracting road users from video streams", "content": "To extract the six types of road users from video streams and their relevant information, we used a deep learning framework that comprises multiple deep models including, You Look Only Once (YOLO) architecture [52, 53]. Particularly, we relied on YoloV5m [54] coupled with DeepSort architecture [55] to detect and track road users throughout a given video file. DeepSort architecture is built on a deep learning model with Sort algorithms [56] to account for object occlusion. We used a pre-trained weight of YOLOV5m model trained on COCO dataset [57]. It's worth mentioning that computing this data and transforming it from raw video streams to vector data took almost 18 hours for analysing one hour across all cameras for a given day (84 days in total) on a single GPU."}, {"title": "Projecting road users in a bird's eye view map", "content": "Transforming moving objects from CCTV footage to a top-view perspective is crucial for accurately analysing and verifying various traffic factors. This perspective allows for the consistent identification and tracking of road users, regardless of obstructions"}, {"title": "Tokenizing road users and counting flows", "content": "To detect modal flows, we first tracked road users in a given file, where each road user has a unique ID, and then the number of road users is counted throughout the file. The road users are vectorized based on their tracked ID data and visualised based on when they appear and disappear in the video files while keeping in mind that multi-dimensional data, such as stationary status, road user categories, and trajectory line in the bird's eye view, has been retrieved."}, {"title": "Ranks of traffic composition", "content": "We estimated the ranks of traffic composition by separating the total counts into unique values that indicate nodes (n=1,n=2, etc.) to grasp the collective behaviour of road users from the local site of all cameras to the city scale. Following that, we computed the unique patterns across each node value (i.e., in the case of n=2, the possible scenarios are vehicle and person, car and car, etc.) and assigned a unique id to each unique pattern. Instead of summing the counts for each mode, we sum the structure at the city level, for example (1-1 + 2-2 + 3-1) up to the number of files."}, {"title": "Granger Causality", "content": "Granger causality [63-66] is tested in the context of linear regression, and it is significant when the previous values of a given variable $X_1$ contribute to the forecasting of the current value of variable $X_2$ or vice versa. By considering a bivariate autoregressive model for these two variables:\n$X_1(t) = \\sum_{j=1}^{p} A_{11,j} X_1(t - j) + \\sum_{j=1}^{p} A_{12,j}X_2(t - j) + \\epsilon_1(t)$\n$X_2(t) = \\sum_{j=1}^{p} A_{21,j} X_1(t - j) + \\sum_{j=1}^{p} A_{22,j}X_2(t - j) + \\epsilon_2(t)$\ngiven that p represents the number of lagged observations in the model order. The matrix A comprises the coefficients of the model such as the contributions of each lagged observation to the predicted values of $X_1(t)$ and $X_2(t)$, and $ \\epsilon_1$ and $ \\epsilon_2$ are the model residuals for each time series.\nIf the coefficients in $A_{12}$ are all considerably different from zero, then $X_2(t)$ Granger causes $X_1(t)$. The model significance is tested by computing an F-test of the null hypothesis that $A_{12} = 0$, assuming that the stationarity of the covariance on $X_1(t)$ and $X_2(t)$. The logarithm of the associated F-statistic can be used to determine the size of a Granger causality interaction [67, 68].\nAccording to the Granger test, it is worth mentioning that causality is evaluated on the grounds that 1) the cause precedes the effect and 2) the cause has specific knowledge about the potential outcomes of its impact. To demonstrate the significant findings of Granger testing, we show the results of four parameters, including the parameters for the F-test and ssr-F-test which are based on the F-distribution and the parameters for the ssr-based chi-squared test and the likelihood ratio test, which are based on the chi-square distribution."}, {"title": "Spatial weight", "content": "Using the K-Nearest Neighbour weights technique [69], we estimated the spatial weight matrix ($w_{ijt}$) between the various camera sites at a particular time (t). It is a set of neighbours defined by distance-based weights based on (K) observations. We investigated several (K) values and found that 10 was the best approximation of the number of neighbours where the different camera locations closely matched the"}, {"title": "Spatial clustering and outliers detection", "content": "We computed statistically significant spatial clusters and hot-spot analysis based on Local Moran's I [70, 71]. If the value of I is positive, it means that a feature is part of a cluster and that it is surrounded by other features that have similar attributes that are either high or low. A negative value for I implies that an outlier feature has nearby features with values that differ from its own. For the cluster or outlier to be regarded as statistically significant, the p-value for the feature must be low enough in both cases.\n$I_i = \\frac{(x_i - \\overline{X})}{S^2} \\sum_{j=1, j \\neq i}^{n} w_{ij}(x_j - \\overline{X})$\nGiven that $x_i$ is the attribute for feature i, $ \\overline{X}$ is the mean for the corresponding attribute, $w_{ij}$ is the spatial weight between feature i and j.\n$S = \\frac{\\sum_{j=1, j \\neq i}^{n} (x_j - \\overline{X})^2}{n-1}$\nGiven that n is the total number of features.\nThe Z-score for the statistics is defined as:\n$Z_I = \\frac{I - E[I]}{\\sqrt{V[I]}}$\n$E[I] = \\frac{\\sum_{j=1, j \\neq i} w_{ij}}{n-1}$\n$V[I] = E[I] - E[I]^2$"}, {"title": "Spatial Regression model", "content": "Given the geographical dependency of the observed variables, we employed a spatial regression model [72, 73] rather than a simple regression model to assess the statistically significant links between NO2 levels and the various values of road users and the built environment. We explored three different approaches in which spatial weight can be applied including, the spatial dependency model, spatial error model, and spatial lag model. First, in the spatial dependency model, the previously computed spatial weight $w_{ij}$ is accounted in the model as an additional independent variable as follows:\nlog(Pi) = a + $X\\beta$ + WXy + $ \\epsilon$\nlog(Pi) = a + $\\sum_{k=1}^{p} X_i\\beta_k$ + $\\sum_{k=1}^{p} \\sum_{i=1}^{N} W_{ij}X_{ki}\\gamma_k$ + $ \\epsilon_i$"}, {"title": "Signature of paths", "content": "This research is concerned with multi-level temporal scales that go from the temporal representation of a certain sequence of a video file at a given location to the hourly temporal representation of video files that can correspond to the temporal scale of NO2 Data. As a result, in addition to depending on a straightforward strategy of summing the data increments of a given hour at a specific site, we relied on rough path theory and path signature [35, 36, 74-76] to summarise the multidimensional temporal representation of the presented data. As a result, we developed a method for summarising the key patterns within the video increments of an hour without losing the raw data relying on signature due to its invariance to reparameterisations. The truncated signature of a path t at a given depth N at a given hour is defined as:\n$S_{a,b}(t) = \\bigoplus_{n=0}^{N} S_{a,b}( \\gamma)$, given that $S_{a,b}(t) = ( \\gamma_{b} - \\gamma_{a})^{\\otimes n}$\nThe signature transform given that $Sig_N = S(\\mathbb{R}^d) \\rightarrow \\prod_{n=1}^{N} (\\mathbb{R}^d)^{\\otimes n}$ is computed as:\n$Sig^{N*}(X) = (\\int_{0<t_1<...<t_n<1} \\frac{df}{dt}(t_1) ... \\frac{df}{dt}(t_n) dt_1....dt_n)$\nfor $1 \\leq n \\leq N$\nThe log signature of t is defined as:"}, {"title": "Graph model architectures", "content": "We developed an undirected weighted Graph G(V, E, A, w), where V is the set of nodes with |V| = N is the number of nodes, E represents the set of the edges of the graph, A is the adjacency matrix and is an N\u00d7N sparse matrix, and $w_{ij}$ represents the adjacency matrix between node $v_i$ and $v_j$. A graph signal $f: V \\rightarrow \\mathbb{R}$ represents a function defined on the vertices of a graph G which maps every vertex $V_i, i=1,...,n$ to a real number $f_i$. The graph signal f can be projected to the eigenvectors of the Laplacian matrix L and by assuming that $ \\lambda_i$ and $ \\mu_i$ are the lth eigenvalue and eigenvector of the Laplacian matrix L, the graph Fourier transform f of the graph signal can be defined as:\nGF[f]($\\lambda_l$) = $f(\\lambda_l)$ = (f, $ \\mu_l$) = $\\sum_{i=1}^{N} f(i) \\mu_l(i)$, given that $ \\mu^T \\mu = \\mu^T$\nIn the context of graph [45, 47, 49], the convolution operation between two functions f and g can be applied by relying on graph Laplacian eigenvectors and can be defined as:\n(f*g) = IGF[GF[f] \u00b7 GF[g]], (f *g)(i) = $\\sum_{l=0}^{N-1} \\hat{f}(\\lambda_l)\\hat{g}(\\lambda_l)\\mu_l(i)$\nThe Graph model comprises $L^{th}$ graph convolution layers, in which each layer constructs an embedding for each node by fusing the embeddings of the neighbours of a given node from the previous layer as follows:\n$Z^{(l+1)} = A'X^{(l)}W^{(l)}, X^{(l+1)} = \\sigma(Z^{(l+1)})$\ngiven that $X^{(l)} \\in \\mathbb{R}^{N \\times F_l}$ represents the embedding of the l-th layer for all N nodes, $X^{(0)} = X$, A' is the weighted and normalized adjacency matrix, $W^{(l)} \\in \\mathbb{R}^{F_l \\times F_{l+1}}$ is the feature transformation matrix that will be learned, and $ \\sigma(.)$ is the activation function for which we implemented an element-wise ReLU.\nWe also used a Graph Attention layer [46], given an input of a set of node features $h = {h_1, h_2, . . . , h_N}$, $h_i \\in \\mathbb{R}^{F}$ where F is the number of features in each node. The layer outputs a new set of node features $F', {h_1, h_2, ..., h_N}, h \\in \\mathbb{R}^{F'}$. The linear transformation of the layer is applied to each node, parameterised by a weight matrix, $W \\in \\mathbb{R}^{F' \\times F}$, in which a shared attentional mechanism is performed on the nodes to indicate the importance of features in a given node j to node i. Their attention coefficients are defined as:\n$e_{ij} = a(Wh_i, Wh_j)$"}]}