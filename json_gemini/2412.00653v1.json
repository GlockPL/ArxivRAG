{"title": "Predictive Inference With Fast Feature Conformal Prediction", "authors": ["Zihao Tang", "Boyuan Wang", "Chuan Wen", "Jiaye Teng"], "abstract": "Conformal prediction is widely adopted in uncertainty quantification, due to its post-hoc, distribution-free, and model-agnostic properties. In the realm of modern deep learning, researchers have proposed Feature Conformal Prediction (FCP), which deploys conformal prediction in a feature space, yielding reduced band lengths. However, the practical utility of FCP is limited due to the time-consuming non-linear operations required to transform confidence bands from feature space to output space. In this paper, we introduce Fast Feature Conformal Prediction (FFCP), which features a novel non-conformity score and is convenient for practical applications. FFCP serves as a fast version of FCP, in that it equivalently employs a Taylor expansion to approximate the aforementioned non-linear operations in FCP. Empirical validations showcase that FFCP performs comparably with FCP (both outperforming the vanilla version) while achieving a significant reduction in computational time by approximately 50x. The code is available at https://github.com/ElvisWang1111/FastFeatureCP", "sections": [{"title": "1 Introduction", "content": "Machine learning has been successfully applied into various fields (Jordan and Mitchell, 2015; Silver et al., 2017). However, machine learning models often face overconfidence issues (Wei et al., 2022) and even hallucinations in large language models (LLMs) (Ji et al., 2023), which makes them unreliable and cannot be deployed in fields like finance and medicines (Gelijns et al., 2001; Thirumurthy et al., 2019; Morduch and Schneider, 2017). Therefore, it is essential to develop techniques for uncertainty quantification and calibrate the original model Abdar et al. (2021); Guo et al. (2017); Chen et al. (2021); Gawlikowski et al. (2021) Among the uncertainty quantification techniques, Conformal Prediction (Vanilla CP or split conformal prediction, Vovk et al. (2005); Shafer and Vovk (2008a); Burnaev and Vovk (2014)) stands out, because it is distribution-free, does not require retraining, and can be directly applied to various models. Conformal prediction uses a calibration step to calibrate a base model and then construct the confidence band. The goal of conformal prediction is to return a band $C_{1-\\alpha}$ such that\n\n$\\mathbb{P}(Y' \\in C_{1-\\alpha}(X')) \\geq 1 - \\alpha$.\n\nwhere $(X', Y')$ is a test point and $1-\\alpha$ represents the confidence level.\n\nIn deep learning regimes, researchers try to utilize feature information in Vanilla CP, since the feature space usually contains meaningful semantic information in neural networks (Shen et al., 2014). This leads to Feature Conformal Prediction (FCP, Teng et al. (2022)). Fortunately, one may get different band lengths on different individuals by using the feature information, leading to a shorter confidence band. For comparison, on the regression task, Vanilla CP only returns the same band length for all individuals, which indicates a longer length. We refer to Teng et al. (2022) for more discussion.\n\nHowever, the practical applications of FCP are limited because (a) it is time-consuming, and (b) it only returns estimated bands on the output space, making it less efficient. These two issues come from the step Band Estimation, which transfers the confidence band from feature space to output space. This step involves complex non-linear operations called LiPRA (Xu et al., 2020) and therefore (a) the non-linear operation requires high computational costs, and (b) the configurations in LiPRA might finally influence the estimated band, further harming the performance of FCP.\n\nIn this paper, we present Fast Feature Conformal Prediction (FFCP), which offers a fast version for handling the aforementioned nonlinear operations. Different from Vanilla CP and FCP, FFCP introduces a novel non-conformity score $s_{ff}(\\cdot)$ that is simple to compute and does not require additional training,\n\n$s_{ff}(X, Y, g\\circ h) = \\frac{|Y - g\\circ h(X)|}{|\\nabla g(v)| |}.$\n\nwhere $(X, Y)$ denotes a sample, $g \\circ h$ denotes a neural network where $h$ denotes the feature layers and $g$ denotes the prediction head, and the gradient $\\nabla g(v)$ denotes the gradient of"}, {"title": "2 Related Work", "content": "Conformal prediction is a post-hoc calibration method dealing with uncertainty quantification (Vovk et al., 2005; Shafer and Vovk, 2008b; Barber et al., 2020), which is deployed in numerous fields (Ye et al., 2024; Kumar et al., 2023; Quach et al., 2023). The variants of conformal prediction typically revolve around the concept of non-conformity scores, with four main branches of development.\n\nRelaxing Exchangeability. The first branch relaxes the exchangeability requirement (Tibshirani et al., 2019a; Hu and Lei, 2020; Podkopaev and Ramdas, 2021; Barber et al., 2022),"}, {"title": "3 Preliminaries", "content": "We begin by introducing a dataset $\\mathcal{D} = \\{(X_i, Y_i)\\}_{i\\in[n]}$ indexed by $\\mathcal{I}$. We split the dataset into two folds: a training fold $\\mathcal{D}_{tra}$ indexed by $\\mathcal{I}_{tra}$, and a calibration fold $\\mathcal{D}_{cal}$ indexed by $\\mathcal{I}_{cal}$. Denote the testing point by $(X', Y')$. For the model part, define $f$ as a neural network. We partition $f = g\\circ h$, where $h$ denotes the feature function (the initial layers of the neural network) and $g$ denotes the prediction head. For a sample $(X, Y)$, we define $v = h(X)$ as the trained feature. We follow the ideas in Teng et al. (2022) and define the surrogate feature as any feature $v$ such that $g(v) = Y$.\n\nAssumption 1 (exchangeability). Assume that the calibration data $(X_i, Y_i) \\in \\mathcal{D}_{cal}$ and the testing point $(X', Y')$ are exchangeable. Formally, define $Z_i, i = 1, ..., |\\mathcal{I}_{cal}| + 1$, as the above data pair. Then $Z_i$ are exchangeable if arbitrary permutation follows the same distribution, i.e.,\n\n$(Z_1,..., Z_{|\\mathcal{I}_{cal}|+1}) \\overset{d}{=} (Z_{\\pi(1)},..., Z_{\\pi(|\\mathcal{I}_{cal}|+1)})$, \n\nwith arbitrary permutation $\\pi$ over ${1,\\cdots,|\\mathcal{I}_{cal}| + 1}$.\n\nTypically, Vanilla CP is composed of three key steps.\n\nI. Training Step. We first train a base model using the training fold $\\mathcal{D}_{tra}$.\n\nII. Calibration Step. We calculate a non-conformity score $R_i = |Y_i - f(X_i)|$ using the calibration fold $\\mathcal{D}_{cal}$. The form of the score function might vary case by case, quantifying the divergence between ground truth and predicted values.\n\nIII. Testing Step. We construct the confidence band for the testing point $(X', Y')$ using the quantile of the non-conformity score $Q_{1-\\alpha}$.\n\nWe present Vanilla CP in Algorithm 11, and provide its theoretical guarantee in Theorem 2.\n\nTheorem 2. Under Assumption 1, the confidence band $C_{1-\\alpha}(X')$ returned by Algorithm 1"}, {"title": "4 Methodology", "content": "In this section, we first illustrate the motivation behind FFCP in Section 4.1. Specifically, we address the complexity of non-linear operators in FCP and provide how we derive FFCP from FCP. We then formally present the specific form of FFCP, including the non-conformity score, the returned bands, and the corresponding pseudocode. We finally provide theoretical analyses on the coverage and band length in Section 4.2.\n\n4.1 Relationship between FFCP and FCP\n\nIn this section, we discuss the motivation behind FFCP. FFCP is inspired by FCP (Teng et al., 2022), which conducts conformal prediction in the feature space. However, since the band is constructed in the feature space, FCP requires a Band Estimation process to go from feature space to output space. Specifically, FCP applies LiPRA (Xu et al., 2020) which derives the band in the output space ${g(v) : ||v - \\hat{v}|| \\leq Q_{1-\\alpha}}$. Unfortunately, the exact band is difficult to represent explicitly since the prediction head $g$ is usually highly non-linear, thereby resulting in significant computational complexity in terms of time. Therefore, we propose approximating $g$ using a first-order Taylor expansion to simplify the aforementioned non-linear operator.\n\nThe core steps of FCP include: (a) calculating the non-conformity score (from output space to feature space), followed by (b) deriving the confidence band (from feature space to output space). We next introduce the concrete formulation of how FFCP approximates FCP.\n\nFrom output space to feature space. FCP uses the non-conformity score $s_f(\\cdot)$ in the feature space\n\n$S_f(X, Y, g \\circ h) = \\inf_{v\\in\\{v: g(v)=Y\\}} ||v - \\hat{v}||.$"}, {"title": "5 Experiments", "content": "This section presents the experiments to validate the utility of FFCP. Firstly, we detail the experimental setup in Section 5.1. Secondly, we present that FFCP achieves both effectiveness and efficiency with faster execution in Section 5.2. Thirdly, in Section 5.3.1, we verify that FFCP can be easily deployed and performs robustly across various tasks, including classification and segmentation. Furthermore, in Section 5.3.2, we show that the gradient-level techniques used in FFCP can be extended to classic CP models such as CQR (Romano et al., 2019a) and LCP (Guan, 2023). A more detailed account of this extension can be found in Section 5.3. Finally, we conduct several more experiments in Section 5.4 to establish the close relationship between FFCP and FCP, to demonstrate the benefits of FFCP from the good representation of gradient, and to provide empirical validations for the theoretical insights.\n\n5.1 Experiments Setups\n\nDatasets. We consider both synthetic datasets and realistic datasets, including (a) synthetic dataset: $Y = WX + \\epsilon$, where $X \\in [0, 1]^{100}$, $Y \\in \\mathbb{R}$, $\\epsilon \\sim \\mathcal{N}(0, 1)$, $W$ is a fixed randomly matrix. (b) real-world unidimensional target datasets: ten datasets from UCI machine learning (Asuncion, 2007) and other sources: community and crimes (COM), Facebook comment volume variants one and two (FB1 and FB2), medical expenditure panel survey (MEPS19\u201321) (Cohen et al., 2009), Tennessee's student teacher achievement ratio (STAR) (Achilles et al., 2008), physicochemical properties of protein tertiary structure (BIO), blog feedback (BLOG) (Buza, 2014), and bike sharing (BIKE). and (c) real-world semantic segmentation dataset: Cityscapes (Cordts et al., 2016). (d) real-world semantic classification dataset: Imagenet-Val.\n\nAlgorithms. We compare three methods: Vanilla CP, FCP, and FFCP, with Vanilla CP serving as the baseline. For the one-dimensional scenario, we perform direct calculations. For higher-dimensional cases, we use a coordinate-wise level non-conformity score.\n\nEvaluation. The algorithmic empirical performance is evaluated with the following metrics:\n\n\u2022 Runtime For runtime evaluation of the algorithm, the timing starts at the score calculation and ends with the final prediction bands returned. All the tests are performed on a desktop with an Intel Core i9-12900H CPU, NVIDIA GeForce RTX 4090 GPU, and 32 GB memory.\n\n\u2022 Coverage (Effectiveness) Coverage refers to the observed frequency with which a test point falls within the predicted confidence interval. Ideally, a predictive inference method should yield a coverage rate that is slightly higher than $1 - \\alpha$ for a given confidence level $\\alpha$."}, {"title": "5.2 Results on Coverage, Band Length and Runtime", "content": "Runtime Comparison. The runtime comparison is presented in Table 1. The results show that FFCP outperforms FCP with an approximate 50x speedup in runtime. Notably, since"}, {"title": "5.3 Extensions of FFCP", "content": "This section provides the extensions of FFCP, which is divided into two parts. Section 5.3.1 mainly discusses the applications of FFCP beyond regression tasks, specifically in image classification (Angelopoulos et al., 2020) and segmentation tasks. Section 5.3.2 focuses on how the gradient-level techniques in FFCP can be extended to other CP variants, e.g., CQR (Romano et al., 2019a) and LCP (Guan, 2023).\n\n5.3.1 Other Tasks\n\nClassification. We extend the FFCP techniques to classification tasks using the baseline RAPS (Angelopoulos et al., 2020) model, creating a new variant called FFRAPS (Fast Feature RAPS, Algorithm 5 in Appendix B.7). According to the experimental findings"}, {"title": "5.4 Discussion", "content": "Robustness for FFCP. The empirical performance of FFCP demonstrates its robustness, as seen in the ablation studies on splitting points. We demonstrate that coverage remains robust across different splitting points in neural networks, as detailed in Table 7 in Appendix B.3. Furthermore, the results from different layers of the FFCP network are consistent, as presented in Table 5\n\nFFCP is similar to FCP. We compare the relationship between the scores of FCP and FFCP through experiments. Figure 3 indicates a positive correlation between the non-conformity scores of the two algorithms, suggesting that FFCP shares similarities with FCP in score function.\n\nFFCP on untrained network. We propose that FFCP returns shorter band lengths through its deployment of deep representations from the gradients. To test this view, we contrast FFCP's performance using an untrained neural network against a baseline model. Using an incompletely trained neural network, FFCP's performance deteriorates and becomes comparable to that of Vanilla CP. This is due to the partially incorrect semantic information in the gradient, which misleads FFCP. We defer the results to Table 6 and related discussion to Appendix B.4."}, {"title": "6 Conclusion", "content": "In this paper, we propose FFCP, a gradient-based non-conformity score that serves as a faster alternative to FCP, achieving processing times 50 times faster than FCP. Theoretically, we have established the effectiveness and efficiency of FFCP under mild assumptions. In our experiments, we apply FFCP to a variety of tasks, including basic regression tasks, classification tasks with FFRAPS based on RAPS, and segmentation. Additionally, we introduce FFCQR based on CQR, as well as FFLCP based on LCP. These experimental results demonstrate the broad adaptability of our techniques.\n\nFor future work, the following points could be considered: (1) We use information from the first derivative and have not delved into higher-order derivatives, which may contain more feature information; (2) The computation of gradients becomes very costly as dimensionality increases, thus special methods are needed to handle large-scale tasks; and (3) The gradient at a single point may be unstable, especially when the gradient is zero, so methods such as random smoothing could be considered."}, {"title": "A Theoretical Proofs", "content": "We prove the theoretical guarantee for FFCP concerning coverage (effectiveness) in Section A.1 and band length (efficiency) in Section A.2.\n\nA.1 Proofs of Theorem 4\n\nThe proof is based on the exchangeability of data (Assumption 1) on the calibration fold and test fold, hence the key step we need to derive is the exchangeability of the non-conformity scores $s_{ff}(X, Y, g\\circ h) = \\frac{|Y - f(X)|}{|\\nabla g(v)| |}$. We define the relevant symbols: $\\mathcal{D}_{tra}$ represents the train fold, $\\mathcal{D}_{tes}$ represents the test fold, $\\mathcal{D}_{cal}$ represents the calibration fold, and $\\mathcal{D}' = \\{(X_i, Y_i)\\}_{i\\in[m]}$ is the intersection of the two folds. m is the number of data points in $\\mathcal{D}'$.\n\nSimilar to Teng et al. (2022), we first prove that for any function $\\hat{h} : \\mathcal{X} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$, which is independent of $\\mathcal{D}'$, $\\hat{h}(X_i, Y_i)$ satisfies exchangeability. For the CDF $F_R$ of $\\hat{h}$ and its perturbation CDF $F_{R,\\pi}$, $\\pi$ is a random perturbation. We can conclude,\n\n$F_R(u_1,..., u_n | \\mathcal{D}_{tra})$\n$= \\mathbb{P}(\\hat{h}(X_1,Y_1) \\leq u_1,..., \\hat{h}(X_n, Y_n) \\leq u_n | \\mathcal{D}_{tra})$\n$= \\mathbb{P}((X_1,Y_1) \\in C_{\\hat{h}^{-1}}(u_1-),..., (X_n, Y_n) \\in C_{\\hat{h}^{-1}}(u_n-) | \\mathcal{D}_{tra})$\n$= \\mathbb{P}((X_{\\pi(1)}, Y_{\\pi(1)}) \\in C_{\\hat{h}^{-1}}(u_1-), ..., (X_{\\pi(n)}, Y_{\\pi(n)}) \\in C_{\\hat{h}^{-1}}(u_n-) | \\mathcal{D}_{tra})$\n$= \\mathbb{P}(\\hat{h}(X_{\\pi(1)}, Y_{\\pi(1)}) \\leq u_1,..., \\hat{h}(X_{\\pi(n)}, Y_{\\pi(n)}) \\leq u_n | \\mathcal{D}_{tra})$\n$= F_R(u_1,..., u_n | \\mathcal{D}_{tra}),$\n\nwhere $C_{\\hat{h}^{-1}}(u-) = \\{(X,Y) : \\hat{h}(X, Y) \\leq u\\}$.\n\nNext, we need to show the non-conformity score function\n\n$S_{ff}(X, Y, g\\circ h) = \\frac{|Y - f(X)|}{|\\nabla g(\\hat{v})| |},$\n\nwhich is independent of the dataset $\\mathcal{D}'$."}, {"title": "B Experimental Details", "content": "Section B.1 introduces the omitted experimental details. Section B.2 certifies the square conditions. Section B.3 discusses discusses the robustness of FFCP coverage with respect to the splitting point and across each network layer. Section B.4 demonstrates that FFCP performs similarly to vanilla CP in untrained neural networks, confirming that FFCP's efficiency is due to the semantic information trained in the feature space. Section B.5 proposes FFCQR after applying the gradient-level techniques of FFCP to CQR. Section B.6 proposes FFLCP after applying the gradient-level techniques of FFCP to LCP. Section B.7 proposes FFRAPS after applying the gradient-level techniques of FFCP to RAPS. Finally, Section B.8 provides additional experimental results."}]}