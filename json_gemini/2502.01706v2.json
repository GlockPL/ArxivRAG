{"title": "Comply: Learning Sentences with Complex Weights\ninspired by Fruit Fly Olfaction", "authors": ["Alexei Figueroa", "Justus Westerhoff", "Golzar Atefi", "Dennis Fast", "Benjamin Winter", "Felix Alexader Gers", "Alexander L\u00f6ser", "Wolfang Nejdl"], "abstract": "Biologically inspired neural networks offer alternative avenues to model data\ndistributions. FlyVec is a recent example that draws inspiration from the fruit fly's\nolfactory circuit to tackle the task of learning word embeddings. Surprisingly, this\nmodel performs competitively even against deep learning approaches specifically\ndesigned to encode text, and it does so with the highest degree of computational\nefficiency. We pose the question of whether this performance can be improved\nfurther. For this, we introduce Comply. By incorporating positional information\nthrough complex weights, we enable a single-layer neural network to learn sequence\nrepresentations. Our experiments show that Comply not only supersedes FlyVec but\nalso performs on par with significantly larger state-of-the-art models. We achieve\nthis without additional parameters. Comply yields sparse contextual representations\nof sentences that can be interpreted explicitly from the neuron weights.", "sections": [{"title": "Introduction", "content": "A large variety of deep learning models have centered on creating distributional language repre-\nsentations in recent years. Among these, Transformer-based architectures such as BERT [Kenton\nand Toutanova, 2019] have consistently set the state-of-the-art and are now considered baselines for\nNatural Language Processing (NLP) tasks. However, better performance in metrics has come at the\nexpense of a seemingly ever-growing computational complexity. Naturally, there is a competing\ninterest in developing efficient architectures, and often, these are inspired by intelligent biological\nsystems that are efficient by nature. Recently, FlyVec was proposed as a simple approach for creating\ncontextual word embeddings motivated by the olfactory circuit of the fruit fly [Yuchen et al., 2021].\nThese embeddings are binary vectors (hash codes) that are formed through neural inhibition via the\nk-Winner-Takes-All (k-WTA) activation. While FlyVec is competitive with traditional word embed-\nding methods like word2vec [Mikolov et al., 2013] and GloVe [Pennington et al., 2014], it is still\nsuperseded by contextual embedding methods such as BERT [Kenton and Toutanova, 2019]. Although\nFlyVec demonstrates an elegant approach that is more computationally efficient, it motivates the\nquestion of whether the performance can still be improved, while maintaining the same scale and\narchitectural simplicity.\nWe attempt to tackle this by, yet again, gathering inspiration from how fruit flies learn to identify\nodors. Previous research has focused on the spatial bundling and modularity of neurons to create\nhigh-dimensional representations. However, olfactory processing also involves processing temporal\npatterns, e.g., firing delays and duration. We highlight two ways in which fruit flies utilize temporal\ninformation.\nRelevance of odor arrival time: The way fruit flies perceive a mixture of odors hints at how the\narrival order of stimuli leads to better segregation and classification capabilities. Multiple odors can\nbe emitted either from the same source or from different sources. Odors emitted from a single source\nhave an approximately simultaneous arrival time due to the physical process of turbulent diffusion, as\nopposed to odors propagating from multiple sources, which results in distinct arrival times. Several\nstudies have shown that fruit flies [Szyszka et al., 2012, Hopfield, 1991, Sehdev et al., 2019], as well\nas other insects [Baker et al., 1998, Saha et al., 2013, Nikonov and Leal, 2002, Witzgall and Priesner,\n1991, Andersson et al., 2011], likely use this asynchronous arrival time to perceptually segregate\nmixed odors.\nUsing time as a medium to encode odors: Olfactory receptor neurons (ORNs) respond in a temporally\nheterogeneous manner that depends on both the type of odor and the type of ORNs [Raman et al.,\n2010]. This heterogeneity encompasses the firing rate and the time course (latency and duration),\nwhich results in odor identification irrespective of stimulus concentration [Stopfer et al., 2003].\nMutant flies that are ablated of spatial coding retain odor discriminatory capacity only through the\ntemporal responses of ORNs [DasGupta and Waddell, 2008, Olsen et al., 2007].\nThese two perspectives regarding time illustrate how spatial encoding (in the sense of neuron\ncollocation) is not the only process employed to generate odor embeddings. We investigate the impact\nof integrating this temporal information in the quality of the embeddings. Our method, Comply,\ngeneralizes FlyVec to incorporate time information (word positions) in the analogy of mirroring\ntext sequences (sentences) to odor segregation. This is accomplished by expressing the input with\nphase differences and exploiting the semantics of complex numbers. Consequently, we learn a\ncomplex-valued parameter matrix through an extension of an unsupervised energy function. We\nsubject our models to a comprehensive evaluation in semantic sentence similarity tasks, as well\nas a text-based Reinforcement Learning environment. Our experiments show how the features\ngenerated by Comply boost the performance significantly, while preserving the parameter complexity,\ncomputational efficiency, and biological plausibility of FlyVec. The main contributions of this work\ncan be summarized as follows:\n\u2022 We introduce a novel architecture that can produce sparse encodings (binary hashes) incor-\nporating positional information, while preserving computational efficiency and significantly\nboosting performance.\n\u2022 Through a comprehensive quantitative evaluation of the unsupervised representations, we\nshow the enhanced quality of the produced embeddings, being competitive with significantly\nlarger architectures in NLP.\n\u2022 We showcase qualitatively that the simplicity of our approach, Comply, retains interpretable\nproperties of FlyVec, while extending to the temporal dimension of sequences.\nWe make the source code\u00b2 available to reproduce the results of our experiments."}, {"title": "Related Work", "content": "Bio hashing. The mushroom body of the fruit fly is considered to be the center of olfactory learning\nand memory formation [de Belle and Heisenberg, 1994]. It is where projection neurons (PN) make\nsynaptic connections with Kenyon cells (KC). In contrast to PNs, KCs have much more odor-selective\nresponses [Turner et al., 2008, Honegger et al., 2011]. In other words, only a small proportion of them\nbecomes activated for a given odor due to inhibition [Lin et al., 2014, Papadopoulou et al., 2011].\nTherefore, the KCs represent odors as sparse and distributed hash codes [Lin et al., 2014]. These\ncodes are high-dimensional representations that the mushroom body output neurons (MBONs) use to\nform memories. The sparsity and high specificity of these KC responses are thought to support the\naccuracy of this process [Laurent, 2002].\nThe FlyVec [Yuchen et al., 2021] model repurposes bio hashing into learning word embeddings\nfrom raw text. Using a one-layer neural network from PNs to KCs, it creates representations of a"}, {"title": "Methods", "content": "This model adapts a single parameter matrix $W \\in \\mathbb{R}^{K \\times 2N_{voc}}$, modeling the PNs\u2192KCs synapses\n(projection neurons to Kenyon cells) and using a biologically inspired mechanism. Here, K is the\nnumber KCs, and $N_{voc}$ is the size of the word vocabulary. For training, every input sentence is\nsplit into sliding text windows of fixed length $w \\in \\mathbb{N}$ disregarding positions, thus modeling sets\n(bag-of-words). The inputs $v \\in \\mathbb{R}^{2N_{voc}}$ are crafted as follows: the first $N_{voc}$ components are the sum"}, {"title": "Comply", "content": "Our extension revolvese around capturing the sequential nature of text data through added positional\ninformation. We leverage the semantics of complex numbers and keep the same biologically inspired\nmechanisms, namely sparsity through k-Winner-Takes-All (k-WTA) activations. We aim to preserve\nthe properties of FlyVec regarding efficiency, simplicity, and interpretability. Thus, we constrain\nourselves to a single-parameter matrix. Additionally, we focus on an extension that considers a\ncomplex-valued input, a single complex parameter matrix W, and a compatible energy function E.\nComplex sequential input. For each sentence expressed as a concatenation of one-hot encoded\nvectors, we multiply each vector by $e^{i \\frac{\\pi l}{L}}$, where L is the length of the sentence, $l \\in \\{0, 1, . . ., L - 1 \\}$\ndenotes the position of the respective word in the sentence and i is the imaginary unit, see fig. 2.\nWe denote this preprocessed input by $z \\in \\mathbb{C}^{L \\times N_{voc}}$ and its complex conjugate by $\\overline{z}$. Note that this\nmodification, compared to FlyVec, expands the dimension of the input by L, and reduces the length\nof each word vector by half since we do not have a target word as in fig. 1. Consequently, our\nparameter matrix W is in $\\mathbb{C}^{K \\times N_{voc}}$ and has the same number of parameters as FlyVec (2KNvoc),\nsince for each complex parameter two real numbers are required.\nWith this modified input, an immediate extension of eq. (1) with the Hermitian inner product $\\langle\\cdot,\\cdot\\rangle_H$\nis not directly applicable, since for a sentence the quantity\n$\\sum_{l \\in L} \\langle W_\\mu, z_l\\rangle = \\sum_{l\\in L} W_\\mu\\overline{z_l} \\in \\mathbb{C}$                                                    (3)\nis complex and C is unordered, hence finding the argmax as in eq. (2) is not possible. Thus, we\nadapt E to find a coherent maximally activated neuron \u03bc.\nAdapting E. Due to the complex-valued nature of the Hermitian inner product, an alternative\nextension must be considered. If we disregard word repetition, we can think of eq. (3) as $\\langle W_\\mu, \\tilde{z} \\rangle_H$,\nwhere $\\tilde{z} := \\sum_{l\\in L} z_l$ is a multi-hot encoded version of the input (similar to FlyVec). We can\ndecompose $\\langle W_\\mu, \\tilde{z} \\rangle_H$ into two steps, element-wise multiplication and aggregation, and yield real\nvalues that are proportional to neuron activation and can be sorted:\n\u2022 Element-wise multiplication: For every word and neuron, we perform a complex multipli-\ncation, which translates to scaling absolutes and subtracting phases. The former indicates\nthe correlation between the input intensity and the neuron's output, while the latter gives us\na measure of the distance (temporal difference) between the word in neuron $W_\\mu$ and the\nsentence.\n\u2022 Aggregation: Simply adding these complex numbers does not retain positional difference\ninformation, since $e^{i \\theta} = e^{i (\\theta + 2\\pi \\eta)}$ for any $0 \\in \\mathbb{R}$. Hence, we instead sum the magnitudes and\nabsolute values of phase differences to capture both the effect of maximum word activation\n(as in the FlyVec model) and the word position distance.\nEquation (4) reflects these modifications to the energy function E. Note that the energy of the original\nFlyVec model (see eq. (1)) is a special case of our approach when W is real and the inputs are\npreprocessed as in fig. 1. We slightly abuse notation by writing L and {1, . . ., L} interchangeably,\nand define\n$\\mathcal{E} := -\\sum_{z \\in Data} \\frac{\\sum_{l \\in L} |\\langle W_\\mu, z_l\\rangle_H|}{|W_\\mu|^2^{1/2}} + \\frac{\\sum_{l \\in L} |Arg \\langle W_\\mu, z_l\\rangle_H|}{|W_\\mu|^2^{1/2}} $                                               (4)\nwhere\n$ \\mu := \\underset{\\mu \\in \\{0,...,K-1\\}}{argmax} \\sum_{l \\in L} |\\langle W_\\mu, z_l\\rangle_H| + |Arg \\langle W_\\mu, z_l\\rangle_H |$                                                   (5)\nArg is the function that extracts the phases from the complex numbers, and $s_l$ is the index in the\nvocabulary of the lth word in a sentence [$s_0, ..., s_{L-1}$]. Equation (4) favors learning complex weights\nfor words in one half of the complex plane, since the absolute angle difference | Arg | is maximized,\nand its maximum is at \u03c0. If we replaced the additions in both eqs. (4) and (5) with subtractions,\nthe synapses would be learned on the same half-plane as the input vectors z. Either option is of no\nconsequence for the model and we choose the additive expression for our experiments. Furthermore,\nwe highlight that the two summands in eq. (5) are not of the same scale; the former, $\\langle W_\\mu, z_l\\rangle_H|$, is\nin [0,\u221e), whereas the latter, |Arg\u3008W\u00b5, zl\u3009H|, is in [0, \u03c0]. To consider this, we experimented with\nreplacing addition (+) by multiplication (\u2022) in eq. (4) and eq. (5). This however resulted in instability\nleading to model overfitting (multiple neurons learn the same sequences) and, more prominently,\nwould not constitute a generalization of the original energy presented in eq. (1). Nevertheless, in the\ncase of inference, we also test the multiplicative approach.\nNote that, as depicted in fig. 2, we limit the phases in the input z to lie in [0, \u03c0) to enforce learning\nphases in W that also only span half of the complex plane. This resolves the ambiguity of having\ndistinct positions in word phases that would be mapped equivalently in the phase distance component\nof our energy function, e.g., a word appearing in $\\frac{\\pi}{2}$ and the weight of that word in $W_\\mu$ with\nphase 0.\nTo summarize, the semantics and operations of complex numbers naturally give us a framework to\ngeneralize the objective of minimizing E, while capturing positional information."}, {"title": "Experiments", "content": "We evaluate our methods in sentence semantic similarity tasks, as well as in a text-based Reinforce-\nment Learning (RL) environment."}, {"title": "Baselines", "content": "We focus on FlyVec since it is the architecture we extend. For the sentence similarity tasks, we also\ncompare against BERT embeddings which are contextual representations based on the Transformer\narchitecture. We use the bert-base-uncased weights publicly available on Hugging Face.\nLikewise, we use the publicly available weights of FlyVec. * Following the evaluation in [Yuchen\net al., 2021], we constrain the tokenizer of BERT to the top 20,000 word indices for a fair comparison\nagainst FlyVec and our models.\nIn the RL evaluation, we compare against a FlyVec model that we pretrain on PubMed (P-FlyVec),\nand the best performing Transformer-based encoder model in [Winter et al., 2024], denoted as\nTransformer-MLM. This architecture provides a policy with an auxiliary language modeling objective\nthat is crucial to stabilize Transformer-encoder learning in online RL settings. We use this approach\nfor both P-FlyVec and Comply."}, {"title": "Data and model training", "content": "We use large text corpora to train the models for our experiments. Sentences are the largest sequence\nstructure that we model with Comply (see section 3.2) and we create batches accordingly. Although\nthe sliding window approach is only relevant for FlyVec (see fig. 1), we use it in our implementation\nonly to construct batches of the same shape (phases of the input are independent of this), and guarantee\nthat Comply sees tokens as often as FlyVec. We pretrain our models on two different text corpora\ndepending on the domain of the target task:\nOpen Web Corpus (OWC) [Gokaslan and Cohen, 2019]. For the sake of comparability with\n[Yuchen et al., 2021], we use the OWC dataset to train Comply. It consists of roughly eight million\nweb documents filtered to be longer than 128 tokens in English, resulting in about 40GB of text files.\nWe preprocess and encode these text data with the FlyVec tokenizer provided in [Yuchen et al., 2021].\nIt maps every word to a single integer in a vocabulary of 20,000 IDs, resulting in approximately 6.5B\ntokens. This model is evaluated against the semantic similarity tasks.\nPubMed. We construct a dataset from the PubMed database keeping only abstracts of articles as\nin [Gu et al., 2021]. Their model, PubMedBERT, highlights that in-domain abstracts are sufficient\nto achieve competitive results in biomedical tasks. We filter for abstracts in English and use this\ntokenizer to yield approximately 6.9B tokens. We pretrain both P-FlyVec and Comply with these\ndata. The resulting models have the same number of parameters and we use them in the RL evaluation."}, {"title": "Semantic similarity evaluation", "content": "We emphasize that Comply creates representations for sentences. We are interested in evaluating the\npretrained embeddings learned in an unsupervised manner without further fine-tuning. Hence, we\nselect the subset of tasks compiled in the Massive Text Embedding Benchmark (MTEB) [Muennighoff\net al., 2023] that targets sentence embeddings without additional models (classification heads or\nclustering algorithms). Furthermore, we focus on tasks comprising English sentences. This results in\nthe majority of the Semantic Textual Similarity (STS), as well as Pair Classification tasks.\nThe STS tasks are the SemEval workshop tasks STS12-17 in addition to BIOSESS, SICK-R, and\nSTSBenchmark. In these tasks, the similarity between two sentences is assessed based on the\nembeddings produced by a model. For FlyVec and Comply, we construct their respective contextual\nfeature hashes and for BERT we use the average of all token embeddings. We report Spearman rank\ncorrelation based on cosine similarity as in [Reimers et al., 2016].\nIn the Pair Classification (PC) tasks, a model predicts whether two sentences are duplicates in a binary\nsetting. The metric reported for these PC tasks is the average precision based on cosine similarity.\nThese tasks are SprintDuplicateQuestions, TwitterSemEval2015, and TwitterURLCorpus.\nFinally, we include the Words in Context (WiC) [Pilehvar and Camacho-Collados, 2019] task for\ncomparability with the accuracy scores reported in [Yuchen et al., 2021]. Here, the goal is to\ndisambiguate, in a binary sense, whether a specific word appearing in two sentences conveys the\nsame meaning, given their context. We closely follow the evaluation protocol explained in [Yuchen\net al., 2021] when evaluating our models.\nFor all tasks, we conduct a 5-fold cross-validation analysis. Following [Yuchen et al., 2021], we\nuse only one fold to determine the hyperparameters for testing on the remaining four folds. For the\nMTEB tasks, we optimize the hash length k. For WiC, we optimize the same hyperparameters as\nin [Yuchen et al., 2021]."}, {"title": "Reinforcement Learning (RL) evaluation", "content": "In practice, learning policies for RL environments require a significantly large number of environment\ninteractions and training iterations. We argue that P-FlyVec and Comply are computationally\nefficient, and thus, well-suited for this scenario. RL involves simulation environments phrased as\nMarkov Decision Processes (MDP) that involve a very large number of learning iterations. For\nour evaluation, we use DDxGym [Winter et al., 2024], which is an RL environment focused on"}, {"title": "Hyperparameters and implementation", "content": "When compared, we use the same number of parameters for FlyVec and Comply in all experiments.\nNamely, 400 Kenyon cells (K = 400) and their respective tokenizers: 20,000-word indices for OWC\nand 30,522 for PubMed, i.e., Nvoc = 20,000 and Nvoc = 30,522, respectively. We follow FlyVec\nto pretrain our models for 15 epochs with a learning rate of 4 \u00d7 10\u00af\u2074, which is linearly annealed\ntowards 0.\nOur models are developed with PyTorch [Paszke et al., 2019]. For multiprocess parallelization and\nRL, we use Ray [Moritz et al., 2018] and RLlib [Liang et al., 2018]. For the WiC task, we conduct\nhyperparameter tuning using the hyperopt [Bergstra et al., 2013] scheduler. For training, we use\nAdam [Kingma and Ba, 2015] as optimizer. The sparse matrix multiplications in our model are mainly\nindexing operations, which we favor over the sparse abstractions in PyTorch, due to a much lower\nmemory footprint.\nFor pretraining, we use eight A100 GPUs and a batch size of 0.8 million samples. In contrast, the\nsentence similarity evaluation on FlyVec and Comply is run on 64 CPU cores to compute all hashes.\nFor BERT we use one V100 GPU and a batch size of 8 in the evaluations. In the RL evaluation, for\nP-FlyVec and Comply we use four P100 GPUs and the same learning rate as in pretraining. For\nTransformer-MLM we report the results stated in [Winter et al., 2024]."}, {"title": "Results and Discussion", "content": "In the following sections, we present the results of our experiments in both semantic similarity and\nReinforcement Learning (RL) tasks."}, {"title": "Semantic similarity", "content": "Table 1 presents our results for the semantic similarity tasks.\nTask scores. The scores show that on seven out of 13 datasets, Comply outperforms all other\nmethods. Except for STS12, Comply consistently outperforms FlyVec by a large margin, signaling\nthat for these tasks the added positional information is beneficial. BERT outperforms on five out of 13\ntasks. However, in two of these, TwitterSemEval2015 and STSBenchmark, Comply is very close in\nsecond place. FlyVec outperforms in STS12, where Comply follows closely. Similarly, ComplyM\noutperforms FlyVec and BERT in six tasks, however falls short of Comply on all tasks except for\nSTS13. Nevertheless, these results show that ComplyM is an additional viable method to compute\nsentence hashes.\nIt is remarkable that Comply manages to bridge the performance gap and improve on BERT with only\n14.56% of the parameters, and that this is achieved solely by incorporating positional information.\nNote that only unsupervised pretraining is involved and no post-hoc methods of model compression\n[Xu and McAuley, 2023] are employed. In practice, the latter is the most popular avenue to achieving\nsignificantly smaller models with comparable performance.\nTask evaluation time. The evaluation times of FlyVec and Comply on CPUs are significantly\nsmaller than those of BERT on GPU. BIOSSES and STS17 are the only tasks for which BERT shows a\ncomparatively shorter time. We argue that this is solely due to the small number of samples in these\ntasks. This effect is confirmed with datasets like TwitterURLCorpus, where the number of samples\nis significantly larger. Here, the efficiency benefits of FlyVec and Comply variants become evident\n(only \u22487 compared to \u224885 seconds of evaluation time). We argue that the differences in efficiency\nobserved in the evaluation time of FlyVec, Comply, and ComplyM are mainly due to tokenization,\nhardware optimization, and implementation details. Still, in terms of the hash computation both\nComply and ComplyM are mathematically more complex as can be inferred from the times of larger\ntasks, such as TwitterURLCorpus.\nThis is reinforced when considering pretraining time. Comply takes approximately 15 minutes per\nepoch, which is significantly higher than the reported time for FlyVec on the OWC corpus \u2013 eight\nminutes on less powerful hardware (8 \u00d7 A100 vs. 3 \u00d7 V100) [Yuchen et al., 2021]. This difference\ncomes from our choice of implementation. We favor an automatic differentiation framework, while\n[Yuchen et al., 2021] computes analytically a learning rule to fit the parameters. Even in this setting,\nour training resources of \u22484 hours on 8\u00d7A100 are significantly inferior to the \u224896 hours of pretraining\nof BERT on 16 TPUs reported in [Kenton and Toutanova, 2019]. When we pretrain P-FlyVec for\nthe RL evaluation with the PubMed corpus with our implementation (optimizing eq. (1)), we report\nthat P-FlyVec and Comply take roughly 12 and 15 minutes per epoch, respectively, highlighting the\nadded complexity of our energy proposed in eq. (4).\nHash length. Additionally, we survey the relationship between the mean test performance in the\nMTEB tasks and the chosen hash length k. We present this in fig. 4 comparing FlyVec and Comply.\nNotably, the scores of Comply are not only higher, but also more regular and concave, allowing for a\nhash length k that is optimal with sparsity in the neighborhood of 150 KCs. In contrast, FlyVec tends\nto have an optimal k either with very low or high values (very high and low sparsity). Minimizing\nthe energy of Comply in eq. (4) can be interpreted as memorizing sequences. Hence, we argue that\nthe relationship between the scores and k is due to these sequences being partially distributed across\nmultiple neurons. Although the energy optimized in FlyVec could accomplish the same (due to the\nsliding window, and as confirmed with the tasks that perform better with very dense hashes), we argue\nthat presenting the additional positional information explicitly in C creates more distinct hashes. We"}, {"title": "Reinforcement Learning (RL)", "content": "In fig. 6, we present the results of the evaluation on DDxGym [Winter et al., 2024]. Both mean\nepisode reward and mean episode length estimate how well the models learn to solve this environment.\nFor the Transformer baseline both metrics are taken from [Winter et al., 2024]. Comply outperforms\nthe Transformer baseline roughly after 15M environment steps, and it continues to improve until\nthe 80M mark. The Transformer converges to a mean reward of 400 after roughly 10M steps. Since\nthe theoretical maximum for the reward in DDxGym is at about 1200, there is significant room for\nimprovement. The mean episode length shows a similar behavior \u2013 here a lower value means that\nthe episode ends successfully with the diagnosis both uncovered and treated. While the Transformer\nconverges at around 18 steps per episode, Comply improves until the experiment stops at 80M\nepisodes with around 16 steps per episode. Although P-FlyVec initially reaches a reward of almost 0,\nit fails to improve further and shortly collapses in performance. This further confirms that capturing\npositional information significantly improves the performance of Comply, and makes the method\nmore competitive to larger sequence-to-sequence models like Transformers."}, {"title": "Conclusions", "content": "We present Comply, an approach to improve learning of sequences by introducing positional informa-\ntion to a biologically-motivated model of the mushroom body of a fruit fly. We achieve this by a novel\nloss that leverages representations in the complex field C and generalizes FlyVec [Yuchen et al.,\n2021] to learning sentences. Our experiments show that Comply improves sequence representations\nwithout adding more parameters. In sentence similarity tasks we significantly bridge the gap between\nthese biologically-inspired models and larger Transformer encoders like BERT. We show that the\nresource efficiency of our method makes it suitable for challenging settings like Reinforcement\nLearning (RL), where it outperforms a Transformer baseline. Our analysis expands on the mechanism\nof the loss we introduce and the interpretability of the learned feature representations."}, {"title": "Limitations and future work", "content": "Tasks and modalities. We limit our experiments to pretraining our model on large general-purpose\ncorpora. Including the objective of sequence similarity as in sentence Transformers [Reimers and\nGurevych, 2019] would expand the comparison to such models. Although our work presents results\non the textual modality for comparability with previous work, we believe that our method is applicable\nto different modalities. Thus a more extensive evaluation of, e.g., different RL environments or\ntime-series tasks is needed.\nLoss and model design. Word repetition is supported in our model in a limited way. Namely, the\nphases of repeated words are averaged by the aggregation (see eq. (4)) during training. Improvements\nin our method could stem from incorporating word repetition as a factor when learning sub-sequences\nacross neurons as we show qualitatively in fig. 5. Furthermore, for the sake of comparability, we do\nnot extend our evaluation to larger models (larger K). Scaling induces problems such as dead neurons,\nso strategies like the GABA switch as proposed by [Bricken et al., 2023] or similar extensions could\nbe needed. Thus, future work would involve a study on the effect of scale on our approach. Finally,\nthe inherent benefit of adding positional information into a learned representation yields the potential\nfor sequence generation. We do not explore this in our work, but we see making the model generative\nas a future direction of research."}]}