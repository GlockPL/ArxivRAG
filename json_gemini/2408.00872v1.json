{"title": "Online Detection of Anomalies in Temporal Knowledge Graphs with Interpretability", "authors": ["Jiasheng Zhang", "Jie Shao", "Rex Ying"], "abstract": "Temporal knowledge graphs (TKGs) are valuable resources for capturing evolving relationships among entities, yet they are often plagued by noise, necessitating robust anomaly detection mechanisms. Existing dynamic graph anomaly detection approaches struggle to capture the rich semantics introduced by node and edge categories within TKGs, while TKG embedding methods lack interpretability, undermining the credibility of anomaly detection. Moreover, these methods falter in adapting to pattern changes and semantic drifts resulting from knowledge updates. To tackle these challenges, we introduce ANOT, an efficient TKG summarization method tailored for interpretable online anomaly detection in TKGs. ANOT begins by summarizing a TKG into a novel rule graph, enabling flexible inference of complex patterns in TKGs. When new knowledge emerges, ANOT maps it onto a node in the rule graph and traverses the rule graph recursively to derive the anomaly score of the knowledge. The traversal yields reachable nodes that furnish interpretable evidence for the validity or the anomalous of the new knowledge. Overall, ANOT embodies a detector-updater-monitor architecture, encompassing a detector for offline TKG summarization and online scoring, an updater for real-time rule graph updates based on emerging knowledge, and a monitor for estimating the approximation error of the rule graph. Experimental results on four real-world datasets demonstrate that ANOT surpasses existing methods significantly in terms of accuracy and interoperability. All of the raw datasets and the implementation of ANOT are provided in https://github.com/zjs123/ANOT.", "sections": [{"title": "1 INTRODUCTION", "content": "Many human activities, such as political interactions [14] and ecommerce [30], can be effectively represented as time-evolving graphs with semantics, which are referred to as temporal knowledge graphs (TKGs). These TKGs are dynamic directed graphs characterized by node and edge categories. In this context, nodes represent entities in the real world (e.g., United States), while labeled edges signify the relations between these entities (e.g., Born In). Each edge in conjunction with its connected nodes can constitute a tuple (s, r, o, t) that encapsulates a piece of real-world knowledge, where s and o denote the subject and object entities, r denotes the relation, and t represents the occurrence timestamp of the knowledge.\nWhile TKGs have demonstrated their value across various applications [22, 63], they often contain numerous anomalies that can significantly impede their reliability. As illustrated in Figure 1, TKG construction relies on automatic extraction from unstructured text [64]. However, existing extraction techniques often encounter conceptual confusion [36] and inaccurate relation matching [46], potentially introducing noisy tuples with erroneous entities or relations, termed as conceptual errors. Furthermore, ongoing interactions in the real world lead to the formation of new knowledge or render existing knowledge obsolete. However, knowledge-updating processes are often insufficient and delayed [48], resulting in either the omission of new knowledge or the retention of invalid knowledge, termed missing errors and time errors. Specifically, these errors are indicated by their conflicts with preserved knowledge. Conceptual errors conflict with the interaction preference of entities, while time errors conflict with other timely updated knowledge in their time order. The missing errors are valid knowledge not included in TKGs and should have few conflicts. TKG anomaly detection refers to detecting conceptual, time, and missing errors by measuring conflicts. Unfortunately, this field receives little attention.\nOne closely related research field is dynamic graph anomaly detection [44], aimed at identifying abnormal connections in time-evolving graphs. However, existing methods primarily rely on simple structural properties, such as connectivity [1] or clusters [34], thus failing to capture the intricate patterns present in TKGs such as relational closures [61] and temporal paths [14]. Furthermore, these methods do not consider the semantic attributes of nodes and are thus ineffective in handling the rich semantics introduced by node and edge categories. Another related field is TKG embedding [50], which aims to represent entities and relations as low-dimensional"}, {"title": "2 RELATED WORK", "content": "Dynamic graph anomaly detection. Existing methods fall into two categories. One is statistical methods, which leverage the shallow mechanisms to extract the structural information [12, 13, 34, 39]. For example, CAD [47] detects abnormal edges by tracking changes in structure and weight. DynAnom [21] uses the dynamic forward push algorithm to calculate the personalized PageRank vector for each node. AnoGraph [5] extends the count-min sketch data structure to detect anomalous edges through dense subgraph searches. F-FADE [8] models the time-evolving distributions of node interactions using frequency factorization. However, they cannot capture complex patterns brought by entity and relation semantics in TKGs. The other is deep learning-based methods, which detect anomalies by learning vector representations for nodes [2, 15, 32, 62]. AEGIS [11] proposes a graph differentiation network to learn node representations. Netwalk [59] combines random walk and a dynamic clustering-based model to score anomalies. AER [16] uses an anonymous representation strategy to identify edges by their local structures. TADDY [32] uses a dynamic graph transformer model to aggregate spatial and temporal information. However, they lack enough high-quality labels [18] and the learned representations are not interpretable, making their detection less convincing.\nTKG embedding. Factorization-based methods [50, 57, 60] regard TKGs as 4-order tensors and use tensor factorization for embeddings. TNT [28] builds on the complex vector model ComplEx [49] with temporal regularization. Timeplex [25] extends TNT by capturing the recurrent nature of relations. TELM [54] learns multi-vector representations with canonical decomposition. However, they learn tensors with fixed shapes, limiting their ability to handle new entities and timestamps. Diachronic embedding-based methods [10, 56] model entity representations as time-related functions. DE-simple [20] uses nonlinear operations to model various evolution trends of entity semantics. ATISE [55] uses multi-dimensional Gaussian distributions to model the uncertainty of entity semantics. TA-DistMult [19] uses a sequence model for time-specific relation representations. However, they over-simplify the evolution of TKG and ignore the graph structure. GNN-based methods [31, 37, 40] employ the message-passing mechanism to simulate the entity interactions. TeMP [52] uses self-attention to model the spatial and temporal locality. RE-GCN [29] auto-regressively models historical sequence and imposes attribute constraints on entity representations. However, they lack interpretability and cannot handle online changes."}, {"title": "3 PRELIMINARIES", "content": "3.1 Temporal Knowledge Graph\nA temporal knowledge graph is denoted as \\(G = (\\mathcal{E},\\mathcal{R},\\mathcal{T},\\mathcal{F})\\). \\(\\mathcal{E}\\) and \\(\\mathcal{R}\\) are entity set and relation set, respectively. \\(\\mathcal{T}\\) is the set of observed timestamps and \\(\\mathcal{F}\\) is the set of facts. In real-world scenarios, \\(\\mathcal{E}\\), \\(\\mathcal{T}\\), and \\(\\mathcal{F}\\) will be continuously enriched. Each tuple (s, r, o, t) \\(\\in\\) \\(\\mathcal{F}\\) connects the subject and object entities s, o \\(\\in\\) \\(\\mathcal{E}\\) via a relation r\\(\\in\\) \\(\\mathcal{R}\\) in timestamp t \\(\\in\\) \\(\\mathcal{T}\\), which means a unit knowledge (i.e., a fact). We represent the connectivity of G in each timestamp t with a |\\(\\mathcal{E}\\)| x |\\(\\mathcal{E}\\)|\\(\\times\\) |\\(\\mathcal{R}\\)| adjacency tensor At, where 1 represents that the entities are connected by the relation in timestamp t. There are two common occurring relationships exist in TKGs. One is chain occurring defined as \\(\\{(s, r_i, o, t_i) \\rightarrow (s, r_j, o, t_j)|t_j \\geq t_i\\}\\), e.g., (Obama, WintheSelection, UnitedStates, 2008/11/04) \\(\\rightarrow\\) (Obama, Presidentof, UnitedStates, 2009/01/20). The other is triadic occurring defined as \\(\\{((s, r_i, o, t_i), (s, r_j, p, t_j)) \\rightarrow (o, r_k, p, t_k)|t_k \\geq max(t_i, t_j)\\}\\), e.g., ((China, HostVisit, SaudiArabia, 2023/03/06), (China, HostVisit, Iran, 2023/03/06) \\(\\rightarrow\\) (Saudi Arabia, SignAgree ment, Iran, 2023/03/10). The facts on the left of the arrow are called head facts, and those on the right are called tail facts.\n3.2 Anomalies in TKGS\nHere, we formally define three kinds of typical anomalies in TKGs. Given a TKG G, we first define its corresponding ideal TKG as \\(\\hat{G} = (\\mathcal{E},\\mathcal{R},\\mathcal{T},\\hat{\\mathcal{F}})\\) which removes all the incorrect facts from \\(\\mathcal{F}\\) and complete all the missing facts into \\(\\mathcal{F}\\) (i.e., (s, r, o, t) \\(\\in\\) \\(\\hat{\\mathcal{F}}\\) if and only if it holds in reality). We further define the ideal triple set \\(\\mathcal{L} = \\{(s,r,o)|(s, r,o, t) \\in\\ \\hat{\\mathcal{F}}\\}\\). Note that, G and \\(\\hat{\\mathcal{L}}\\) are only conceptual aids that do not exist. We then use it to define anomalies.\n3.2.1 Conceptual Errors. Extraction methods may introduce noised facts with error entities or relations in TKGs. Formally, we define the conceptual errors as \\(\\mathcal{F}_c = \\{(s_c, r_c, o_c, t_c)|(s_c, r_c, o_c, t_c) \\in\\ \\mathcal{F}, (s_c, r_c, o_c) \\notin \\mathcal{L}\\}\\), e.g., (JoeBiden, BornIn, Ireland, 1942/11/20).\n3.2.2 Time Errors. Knowledge updating may make existing facts invalid, but update delays will let these invalid facts not be removed from TKGs. Formally, we define the time errors as \\(\\mathcal{F}_t = \\{(s_t, r_t, o_t, t_t)|(s_t, r_t, o_t, t_t) \\in\\ \\mathcal{F}, (s_t, r_t, o_t) \\in\\ \\mathcal{L}, (s_t, r_t, o_t, t_t) \\notin \\hat{\\mathcal{F}}\\}\\). For example, (Obama, Presidentof, UnitedStates, 2023/10/21).\n3.2.3 Missing Errors. Insufficient updates also prevent some correct facts not being added to TKGs. Formally, we define the missing"}, {"title": "3.3 Minimum Description Length Principle", "content": "In the two-part minimum description length (MDL) principle [41], given a set of models \\(\\mathcal{M}\\), the best model M\\(\\in\\) \\(\\mathcal{M}\\) on data D minimizes \\(L(M) + L(D|M)\\), where L(M) is the length (in bits) of the description of M, and L(D|M) is the length of the description of the data when encoded using M. In this work, we leverage MDL to find the optimal summarization model of a given TKG. Each MDL-based approach must devise its definitions for the description lengths, and here we follow the most commonly used primitives [17]."}, {"title": "3.4 Summarization of A TKG", "content": "The summarization of a graph is a more refined and compact representation of the graph [6], including super-graphs [9], sparsified graphs [33], and independent rules [45]. However, they fail to handle rich semantics and temporal relevance in TKGs, inspiring us to propose a novel rule graph as the summarization of a TKG.\n3.4.1 Atomic Rules. Given a TKG G, we first construct a function C(\u00b7), which takes each entity as input and outputs its category. Based on this, each knowledge (s, r, o, t) \\(\\in\\) G can be mapped as an atomic rule (C(s), r, C(o)), which summarizes the interaction pattern of the knowledge (e.g., (Obama, Win, NobelPeacePrize, 2019/ 10/09) can be mapped as (PERSON, Win, PRIZE)).\n3.4.2 Rule Graph. A rule graph is a directed graph \\(G = \\{V, E\\}\\), where each v \\(\\in\\) V is a node indicating an atomic rule, and each e \\(\\in\\) E is a rule edge preserving the sequential relevance between atomic rules. There are two kinds of rule edges in E. One is derived from the chain occurring (e.g., (PERSON, Nominated, PRIZE) \\(\\rightarrow\\) (PERSON, Win, PRIZE)), termed as \\((v_h \\rightarrow v_t)\\) where \\(v_h\\) is the head atomic rule and \\(v_t\\) is the tail atomic rule. The other is derived from the triadic occurring (e.g., (PERSON, Write, BOOK), (BOOK, Nominated, PRIZE) \\(\\rightarrow\\) (PERSON, Win, PRIZE)), termed as \\(((v_h, v_m) \\rightarrow v_t)\\), where \\(v_m\\) is the middle atomic rule. By associating atomic rules with rule edges, paths between atomic rules can describe the occurrence relevance between two kinds of interactions."}, {"title": "3.5 Problem Definition", "content": "Detecting anomalies for TKGs that have been offline preserved in the database is meaningful. However, it is a more valuable but difficult problem to detect anomalies for TKGs that are online updating, requiring the model to be efficient, adaptive to online changes, and easy to rebuild. We term it inductive anomaly detection in TKGs.\nDefinition 3.1 (Inductive anomaly detection in TKGs). Given an online updating TKG G where the most recently updated timestamp is te, inductive anomaly detection aims to construct a model M based on G to find anomalies in the future timestamps t > te. It contains classifying whether each newly arrived knowledge (s, r, o, t) is an anomaly (i.e., conceptual or time errors), and determining whether some knowledge is missing in t (i.e., missing error)."}, {"title": "4 METHOD", "content": "4.1 Overview\nMotivation. Reflecting on the challenges in TKG anomaly detection, we recognize that a rule-based summarization approach could effectively tackle these issues. First, rules encapsulate the most common patterns within a graph in a human-readable form. If we can map new knowledge as a set of rules, then they can provide interpretable evidence for its validity. Second, the complex patterns observed in TKGs stem from the composition of simpler, independent patterns. If we can appropriately link these simple rules, then the complex patterns can be flexibly deduced based on the individual rules. Last, rules describe the properties of a TKG in a more compact and refined way. Thus ideally, any semantic and pattern shifts can be described as modifications of the rules.\nSolution. In this paper, we propose ANOT, a novel summarization method for TKG anomaly detection. As depicted in Figure 2(a), ANOT takes an online updating TKG as input, identifies anomalies, and then filters valid knowledge. The process initiates with the detector module, which constructs a rule graph based on the offline preserved part of TKG. Upon the arrival of new knowledge, this module evaluates it against the rule graph to compute an anomaly score. Subsequently, the updater module receives valid knowledge identified by the detector module, and then reforms them as edit operations on the rule graph to handle online semantic and pattern changes. The monitor module estimates the approximate error of the rule graph in representing the TKG. When the approximate error exceeds the threshold, the monitor will inform the detector to refresh the rule graph based on the current TKG. In this way, the reachable nodes during walking will give readable evidence for detection, while the complex patterns can be flexibly described by the walking paths, and the online changes are uniformly handled.\nIn the following, we first define the description length of G used to find the optimal rule graph, and then detail each part of A\u039d\u039f\u03a4."}, {"title": "4.2 Description Length of The Rule Graph", "content": "We employ the minimum description length principle to guide the construction of the optimal rule graph. In other words, we consider it as a classic information-theoretic transmitter/receiver setting [51], where the goal is to describe the graph to the receiver using as few bits as possible. As a result, we should first define the number of bits required to describe the TKG (i.e., L(M) and L(G|M)).\nDefinition 3.2 (Inductive TKG summarization with MDL). Given an online updating TKG G, we seek to find the model M* (i.e., the optimal rule graph) that minimizes the description length of G,\n\\(M^* = arg \\min_{M \\in \\mathcal{M}} \\{ L(M) + L(G|M) \\}\\).   (1)\nWith the constant enrichment of G, M* varies across timestamps. However, it is time-consuming to construct M* from scratch in every timestamp, requiring a strategy to update M* incrementally.\n4.2.1 L(M). Based on the primitives of MDL principle [17] and the definition of the rule graph, the encoding cost of a rule graph \\(G = \\{V, E\\}\\) consists of the number of atomic rules V, the number of rule edges E (both upper bounded by the number of possible candidates), and the encoding cost of V and E, which is defined as\n\\(L(M) = log(2 * |\\mathcal{C}_\\mathcal{E}|^2 * |\\mathcal{R}|) + log \\binom{2* |\\mathcal{C}_\\mathcal{E}|^2 * |\\mathcal{R}|}{3} + \\sum_{v \\in V}L(v) + \\sum_{e \\in E}L(e)\\),  (2)\nwhere the first term is the upper bound of the number of candidate atomic rules. |\\(\\mathcal{C}_\\varepsilon\\)| is the total number of entity categories derived from function C(\u00b7) (see Section 4.3.1). R is the number of relations. Each atomic rule has the form of (CATEGORY, relation, CATEGORY), and thus results in |\\(\\mathcal{C}_\\varepsilon\\)|^2 * |R|. Twice because each relation has two directions. The second term is the upper bound of the number of candidate rule edges, where \\(log \\binom{A}{B}\\) means the description length of uniformly choosing B elements from A elements. Each rule edge associates two or three atomic rules (i.e., chain or triadic occurring), and thus results in B=3 as the upper bound. L(v) and L(e) are respectively the encoding costs of each atomic rule and each rule edge, defined as\n\\(L(v) = log|\\mathcal{C}_\\varepsilon| + (-log \\frac{n_{c_s}}{|\\mathcal{E}|}) + (-log \\frac{n_{c_o}}{|\\mathcal{E}|}) + (-log \\frac{n^r}{1})\\), (3)\nwhere the first term is the number of the categories of entities. The second to fourth terms are the number of bits used to encode subject categories, object categories, and relations respectively. Note that we use optimal prefix code [24] to encode actual categories, so \\(n_{c_s}\\) is the number of times category \\(c_s \\in \\mathcal{C}_\\varepsilon\\) occurs in G (\\(n_{c_o}\\) is similar), while n\\(^r\\) is the number of times relation r\\(\\in\\) R occurs in G and 1 represents the direction of the relation. Since the number of relations is constant across different models, we ignore it during model selection. We define the encoding cost of each rule edge as\n\\(L(e) = log|E| + (-log \\frac{n_{v_h}}{|E|}) + (-log \\frac{n_{v_m}}{|E|}) + (-log \\frac{n_{v_t}}{1})\\), (4)\nwhere E is the number of the rule edges and \\(n_{v_h}\\) is the number of head atomic rule on occurs in rule graph G. 1 represents the direction of the edge. Note that for brevity, we only give L(e) of the triadic occurring and the chain occurring can be easily extended by removing the auxiliary atomic rule part (i.e., the third term).\n4.2.2 L(G|M). Each atomic rule can describe a set of facts in TKG (e.g., atomic rule (PERSON, Wins, PRIZE) can describe fact (Obama, Win, NobelPeacePrize, 2019/10/09)), and each rule edge can describe a set of occurring relationships among facts. For example, rule edge (PERSON, WintheSelection, COUNTRY) \\(\\rightarrow\\) (PERSON, Presidentof, COUNTRY) can describe the relationship that fact (Obama, Presidentof, UnitedStates, 2009/01/20) occurs subsequently after the fact (Obama, WintheSelection, UnitedStates, 2008/11/04). These described facts are called correct assertions. They can be encoded by the given rule graph. Moreover, TKGs inevitably contain noise and uncommon facts and thus there may be facts that cannot be encoded by the rule graph, called negative errors. Therefore, the encoding cost of G by the rule graph M is L(G|M) = L(AG) + L(NG). L(AG) is the encoding cost of the"}, {"title": "4.3 Detector", "content": "The detector module has two functions: 1) Construct the optimal rule graph. As shown in Figure 2(b), a category function is first constructed based on existing knowledge (Section 4.3.1), and then it will be used to map knowledge as candidate atomic rules and candidate rule edges (Section 4.3.2). Finally, the most expressive candidates will be iteratively selected to construct the rule graph (Section 4.3.3). More details can be found in Algorithm 1. 2) Generate anomaly scores. As shown in the upper part of Figure 2(c), new knowledge will be first mapped as a set of atomic rules. Atomic rules that exist in the rule graph can give evidence of their conceptual validity, which will derive the static scores (Section 4.3.4). Then, the evidence of time validity is gathered by recursively walking on the rule graph and instantiating the processor nodes, which will derive the temporal scores. More details can be found in Algorithm 2.\n4.3.1 Construct Category Function. Entity categories are often missing in real-world TKGs [58]. Fortunately, we find that the category of an entity is largely related to the relations it interacts with. For example, an entity that interacts with relations BornIn and Plays For should have a category of ATHLETE, and an entity that"}, {"title": "4.3.2 Candidate Generation.", "content": "To construct the rule graph, we should first generate all possible rules and rule edges as candidates based on the input TKG. For each fact (s, r, o, t), we generate the corresponding candidate atomic rules as \\(\\{(c_i, r, c_j)|c_i \\in C(s), c_j \\in C(o)\\}\\), where C(s) is the category set of s. We gather the rules derived from all facts (s, r, o, t) \\(\\in\\) F as the candidate set of atomic rules.\nTo generate all possible chain-occurring-based rule edges, we first construct the interaction sequence S(s, o) = {1, 2, ...} for each entity pair appeared in G. The interaction sequence preserves all the relations that occurred between s and o and is sorted by the ascending order of their occurrence timestamps. Thus, any adjacent relations in the sequence represent two interactions between s and o that occur successively, which may imply a chain-occurring pattern. Formally, given each entity pair (s, o) and its corresponding interaction sequence, we generate the candidate rule edges as \\(\\{(c_s, r_m, c_o) \\rightarrow (c_s, r_n, c_o) | c_s \\in C(s), c_o \\in C(o), r_m,r_n \\in S(s, o), m < n\\}\\). We gather the rule edges derived from all entity pairs that appear in G as the candidate set of chain-occurring-based rule edges. Since the occurrence timespan between different relations may vary, e.g., MakeStatement may occur a few days after"}, {"title": "4.3.3 Ranking and Selection.", "content": "We propose a greedy approach to select the most representative candidate into the rule graph iteratively. Our objective is to select the candidate that leads to the largest encoding cost reduction in each iteration. Recognizing that varying orders of selection may yield inconsistent models, thus affecting reproducibility, we implement a structured ranking mechanism that ensures a consistent selection order of candidates. Since the more a candidate can reduce negative errors, the more valuable it might be, we first rank candidates based on the descending order of their error reduction \\(\\Delta L(G|M\\cup\\{x\\}) = L(G|M)-L(G|M\\cup\\{x\\})\\), where x represents candidate atomic rule v or rule edge e. The ties in the ranking are broken by selecting candidates with more correct assertions. The final tie-breaker is the ID of each candidate. We separately rank atomic rules and rule edges since they have different magnitudes in the cost reduction. The ranked candidate rules and rule edges are respectively termed as P(v) and P(e).\nAfter ranking the candidates, M is initialized as \u00d8 and each v \\(\\in\\) P(v) is first selected in ranked order. For each v, we compute the description length when u is added into M (i.e., L(G, M\\(\\cup\\) {v})). If it is less than L(G, M), u can enhance the expressive capability of M. Thus, we add v into M. We perform the selection passes over P(v) until no new atomic rules can be added. We then perform the same selection process on P(e) to add rule edges into M. Note that some selected rule edges may contain atomic rules that are not selected in the former process. We restrict the usage of these atomic rules only to verify the time errors. The obtained approximately optimized rule graph is termed as \\(M^* = \\{V^*, E^*\\}\\)."}, {"title": "4.3.4 Deriving Anomaly Scores.", "content": "Intuitively, nodes and edges in the rule graph explain the common patterns of knowledge occurring in TKG. Thus, new knowledge that cannot be mapped as nodes or cannot be associated with other knowledge via edges is unexplained and likely to be anomalous. We make this intuition more principled by defining static scores and temporal scores for tuples.\nStatic scores. Nodes in M* represent valid interaction patterns found in the TKG. When new knowledge is mapped to a node in M*, it means that the knowledge can be explained by an observed"}, {"title": "Algorithm 2 Derive the anomaly scores", "content": "1: Input: New knowledge (s, r, o, t) and rule graph M*\n2: Output: Static score \\(S(s, r, o, t)\\) and temporal score \\(T(s, r, o, t)\\)\n3: Generate mapped atomic rule set \\(V^\\*(s, r, o, t)\\)\n4: temps \u2190 0\n5: for \\(e \\in\\) E(s, o) do\n6:   for \\(v \\in V^\\*(s, r, o, t)\\) do\n7:     if r \\(\\notin\\) R(e) then\n8:       temps \u2190 temps + |AGv|\n9: \\(S(s, r, o,t) = temps\\)\n10: if \\(temps < \\Delta\\) then\n11:   return \\(S(s, r, o, t)\\)\n12: \\(V' \\leftarrow V(s, r, o, t)\\), tmpt \u2190 0, MAXSTEP \u2190 0\n13: tmpList \u2190 \\(\\emptyset\\)\n14: for v \\(\\in V'\\) do\n15:   for vi \\(\\in N\\_{in}(v)\\) do\n16:     if vi is instantiable then\n17:       tmpt \u2190 tmpt + x(vi) + 1\n18:     else\n19:       tmpList \u2190 tmpList \\(\\cup\\) vi\n20:   if MAX STEP < K then\n21:     MAX STEP \u2190 MAX STEP + 1\n22:     \\(V' \\leftarrow\\) tmpList\n23:     Go to 11\n24: \\(T(s, r, o,t) = tmpt\\)"}, {"title": "Equation annotations", "content": "\u2022 Equation 9  where V* (s, r, o, t) is the set of nodes that new knowledge (s, r, o, t) can be mapped to. |AY| is the number of correct assertions of v. The higher S means it is more likely to be a conceptual error."}, {"title": "Temporal scores", "content": "Each in-coming edge of a node v in the rule graph provides an inducement for the interaction represented by v to occur, while the timespans preserved in the edge provide the prompt of when it should occur. Therefore, we propose to walk on the rule graph starting from the mapped nodes of new knowledge to find evidence for it to occur. Specifically, given the new knowledge (s, r, o, t), we first map it to nodes in the rule graph by conceptualizing it as a set of atomic rules V* (s, r, o, t). Then, for each v \\(\\in\\) V* (s, r, o, t), we find all of its in-coming edges (i.e., (vi \\(\\rightarrow\\) v) or ((vi, vk) \\(\\rightarrow\\) v)) and gather all precursor nodes (i.e., {vil(vi \\(\\rightarrow\\) v) \\(\\in\\) E*or((vi, vk) \\(\\rightarrow\\) v) \\(\\in\\) E*\\}). We then perform the instantiate on these precursor nodes. For each vi, it is instantiable if there is a fact in vi's correct assertions that can form an occurring relationship (i.e., chain or triadic occurring) with new knowledge (s, r, o, t). The instantiable precursor nodes give evidence for the occurrence of new knowledge. Note that TKG inevitably contains noise such as knowledge missing, which can cause node instantiation to fail. We propose a recursive strategy to enhance the robustness of our scoring. If precursor node vi fails to be instantiated, we find all the precursor nodes of vi and use the instantiation of them as alternative evidence from vi. Our algorithm will traverse the rule graph depth-first to gather evidence until the maximum number of hops is reached. The temporal score is formally defined as\n\\(T(s, r, o, t) = \\frac{1}{\\sum_{v \\in V^*(s,r,o,t)} \\sum_{v_i \\in \\mathcal{N}_{in}(v)} x},\\)\n\\(\\sum_{v_j \\in \\mathcal{N}_{in}(v_i)} x\\)where \\(x = \\frac{\\Theta}{\\vert \\mathcal{T}((v_i \\rightarrow v)), \\vert }\\) if \\(v_i\\) is instantiable, else x = \\(\\emptyset\\). where \\(\\mathcal{N}_{in}(v)\\) is the set of in-coming neighbors of v. \\(\\Theta = |\\{\\tau_j | \\tau_j \\in\\mathcal{T}((v_i \\rightarrow v)), |t_j|t-t_i|| \\le L\\}|\\) which indicates the gap between the timespan of the instantiations and the preserved timespans. ti is the occurrence timestamp of the instantiated previous knowledge. Temporal scores can be further extended by adding the number of instantiable out-coming edges to the numerator of Eq. 10. Specifically, each out-coming edge of node v describes an interaction that should occur after v. Therefore, if it can be instantiated by previous knowledge, it means the occurrence of new knowledge violates a common occurrence order. The higher T means it is the more likely to be a time error. Meanwhile, if knowledge gets both low S and T but is not preserved in TKG, it is likely to be a missing error.\nCorrecting prompts. For conceptual errors, we use the atomic rules that can partially describe the anomaly knowledge (s, r, o, t) as its correcting prompts, e.g., \\(\\{(c_s, r, c_e)|c_e \\in C(e), e \\in \\mathcal{E}, (c_s, r, c_e) \\in V^*\\}\\) and \\(\\{(c_s, r_i, c_o)|c_s \\in C(s), c_o \\in C(o), (c_s, r_i, c_o) \\in V^*\\}\\), which tell us how to revise the entity or relation in anomaly knowledge to make it valid. For time errors, the instantiable in-coming edges (evidence of correctness) and instantiable out-coming edges (evidence of anomaly) give prompts of when the new knowledge occurs is appropriate (i.e., maximize the instantiable in-coming edges and minimize the instantiable out-coming edges). During walking, precursor nodes that fail to instantiate may indicate a missing knowledge, and thus give us prompts to extract new knowledge.\nCase demonstration. Here we demonstrate how our strategies detect anomalies in Figure 1. (KimJongUN, HeldMilitaryExercises, SouthKorea, 2020/08/23) will be assigned with a high S due to the interaction preference conflict of category PRESIDENT, and thus be detected a conceptual error. (Trump, Presidentof, UnitedStates, 2023/01/20) will be assigned with a high T since it has occurrence order conflict with (Trump, OutgoingPresident, UnitedStates, 2021 /01/19), and thus be a time error. During temporal scoring, ANOT needs to traverse the rule graph to find instantiateable nodes, and (PERSON, WintheElection, UnitedStates) will be found uninstantiateable. By verifying the low S and T of instantiating it using JoeBiden, this knowledge will be detected as a missing error."}, {"title": "Annotation on functions and  algorithm", "content": "\u2022 Algorithm 3  Algorithm 3 Update the rule graph  Input: New valid knowledge (s, r, o, t) and rule graph M* Output: The updated rule graph M* G \u2190 G\u222a {(s, r, o, t)} handle graph structure changes temps \u2190 0"}, {"title": "Equation annotations", "content": "\u2022 Equation 10 :  where V* (s"}]}