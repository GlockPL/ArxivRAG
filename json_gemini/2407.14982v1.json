{"title": "GreenStableYolo: Optimizing Inference Time and Image Quality of Text-to-Image Generation", "authors": ["Jingzhi Gong", "Sisi Li", "Giordano d'Aloisio", "Zishuo Ding", "Yulong Ye", "William B. Langdon", "Federica Sarro"], "abstract": "Tuning the parameters and prompts for improving AI-based text-to-image generation has remained a substantial yet unaddressed challenge. Hence we introduce GreenStableYolo, which improves the parameters and prompts for Stable Diffusion to both reduce GPU inference time and increase image generation quality using NSGA-II and Yolo. Our experiments show that despite a relatively slight trade-off (18%) in image quality compared to StableYolo (which only considers image quality), GreenStableYolo achieves a substantial reduction in inference time (266% less) and a 526% higher hypervolume, thereby advancing the state-of-the-art for text-to-image generation.", "sections": [{"title": "1 Introduction", "content": "In recent years Generative Artificial Intelligence (GenAI) has emerged as a powerful approach encompassing various techniques that enable machines to generate new content, such as text [13], images [19], and videos [14]. Particularly, image generation and text-to-image synthesis have garnered significant attention due to their potential in bridging the gap between textual descriptions and visual representations [18]. It enables systems to understand and interpret human language and automatically translate it to a visually meaningful way, facilitating tasks such as generating accompanying images for books [4], generating product images for advertising [22], and inspiring artists to create new forms of art [12]. However, achieving optimal performance in image generation tasks involves fine-tuning various aspects of a GenAI model, such as the number of inference steps, positive and negative prompts [1,3]. These parameters play a crucial role in determining the quality and efficiency of the generated images and tuning these parameters is essential to unlock the full potential of image generation models [3,15]. At the same time, GenAI model are energy demanding and largely contribute to the increased CO2 emissions[8,20].\nBerger et al. [3] proposed a search-based approach, dubbed StableYolo, to optimize the image quality of Stable Diffusion by assessing image quality using Yolo [17]. However, their approach do not take into account the aspect of inference time, which is a cornerstone for both ensuring user experience and minimizing the energy consumption of GenAI models. Especially in real-world scenarios, where responsiveness and energy efficiency are vital, addressing this aspect is vital for the widespread adoption of such models [5,11,20,21].\nTo address this gap, we present GreenStableYolo, a novel approach that addresses the challenge of optimizing the trade-off between inference time and image quality using a search-based multi-objective optimization method, namely Non-dominated Sorting Genetic Algorithm (NSGA-II) [6]. We provide initial empirical evidence that by using GreenStableYolo Stable Diffusion achieves a satisfactory equilibrium between inference time and image quality, making it suitable for real-world applications where both factors play a crucial role.\nIn a nutshell, the key contributions of this work include:\n The development of a novel system that seeks for an optimal trade-off between inference time and image quality by optimizing the prompts and parameters for Stable Diffusion, dubbed GreenStableYolo;\n Empirical evidence on the effectiveness of GreenStableYolo in achieving significantly less inference time and higher hypervolume compared to StableYolo, thereby advancing the state-of-the-art multi-objective optimization for text-to-image generation;\n A comprehensive analysis to understand the influence of different parameters and prompts on both inference time and image quality in Stable Diffusion."}, {"title": "2 Related Work", "content": "To improve image generation quality, Berger et al. [3] were the first to propose the use of a Genetic Algorithm (GA) able to simultaneously tune the prompt and parameters of Stable Diffusion. Magliani et al. [15] use GA to find the best diffusion parameters for automated image retrieval from a dataset. While some research [5,11] has been carried out to optimize inference time, from hardware design to model architecture, there has been limited work focusing on optimizing the prompts and parameters. Our work builds upon previous work by considering both inference time and image quality as optimization objectives."}, {"title": "3 Methodology", "content": "To mitigate the aforementioned challenge, we propose GreenStableYolo, a novel multi-objective search-based approach that, given a text prompt for image generation, searches for the optimal parameters that can strike a balance between: (1) Inference time, which is measured by the GPU time taken for the execution of the StableDiffusionPipeline; and (2) Image quality, which is determined by performing object recognition with Yolo, then selecting objects that match the input prompt, and computing their average probabilities [3].\nNSGA-II Optimization Algorithm To simultaneously enhance image quality and reduce inference time, we leverage NSGA-II, a well-known and efficient multi-objective evolutionary algorithm [10,16]. Specifically, NSGA-II works as follows: (1) Initialize a population with N individuals; (2) Perform crossover and mutation operations, generating an offspring population denoted as Po; (3) Reassemble the parent population Pt-1 and Po into a temporary population with the size of 2N, and formulate individuals into i non-inferior frontier through fast non-dominating sorting; (4) Select N individuals from the temporary population to form the next population for the tth iteration, denoted as Pt. (5) Repeat steps (2)-(4) until the termination condition is met; and (6) The algorithm ends up and returns the current Pareto-Optimal set.\nSelected Parameters To make a straightforward comparison with StableYolo, we adopt the same settings as used by Berger et al. [3]. Specifically, the following parameters and prompts are tuned and searched with NSGA-II: (1) Inference steps (1 to 100): the AI's image generation iterations; (2) Guidance scale (1 to 20): the impact of the prompt on image generation; (3) Guidance rescale (0 to 1): rescales the guidance factor to prevent over-fitting; (4) Seed (1 to 512): randomization seed; (5) Positive prompt: used to describe images and improve their details, e.g., \"photograph\", \"color\", and \"ultra real\" [2]; and (6) Negative prompt: avoided description during image generation, e.g., \"sketch\", \"cropped\", and \"low quality\" [2]."}, {"title": "4 Evaluation", "content": "To evaluate our proposal, we address the following research questions (RQs):\n RQ1: To what extent can GreenStableYolo improve image quality and inference time compared with StableYolo?\n RQ2: How do parameters/prompts of Stable Diffusion influence the inference time for image generation?\n RQ3: How do parameters/prompts of Stable Diffusion influence the quality of the generated images?\nExperimental Setup To ensure a fair evaluation of the optimization effectiveness, we employed the same hyperparameter setup as StableYolo for NSGA-II, e.g., the population size was set to 25, the number of generations was set to 50, and both the mutation rate and crossover rate were set to 0.2. We selected the weights of 0.001 for image quality and -1000 for inference time based on empirical investigation of different weight combinations. In addition, we used Stable Diffusion version v2 and Yolo version v8. To assess variability, we evaluated each model 15 times using different random seeds, focusing solely on the prompt \"two people and a bus\" due to time constraints. Any future studies can explore additional prompts. All experiments were conducted on a virtual machine hosted on Google Colaboratory, with an NVIDIA Tesla T4 GPU with 16 GB of RAM.\nRQ1 Results Figure 1 presents the performance comparisons between GreenStableYolo and StableYolo. Specifically, Figure 1a reveals that GreenStableYolo achieves an average inference time of 9.4 seconds with an interquartile range (IQR) of 4.7 seconds. Conversely, StableYolo exhibits an average inference time of 25.0 seconds, which is 1.66 times higher than GreenStableYolo, with an IQR of 9.1 seconds. That is, GreenStableYolo generates images much faster.\nThis improvement in inference time comes at a slight cost to image quality. As illustrated in Figure 1b, GreenStableYolo experiences approximately an average degradation of 0.18 points in image quality. We also compute the hypervolume [9] for both models for a more comprehensive comparison. Figure 1c presents the hypervolume values with the reference point set as (1, 50000), where GreenStableYolo achieves an average hypervolume of 29074.11, surpassing StableYolo's score of 4642.17 by 5.26 times. This substantial difference demonstrates the clear dominance of GreenStableYolo over StableYolo in this two-objective optimization problem for text-to-image generation.\nRQs2-3 Results To investigate RQs2-3, we followed previous work [7] and built two Random Forest regression models using scikit-learn. The features of these models include the number of iteration steps, guidance scale, guidance rescale, positive prompts, and negative prompts (excluding the random seed). The target variables are inference time and image quality score, respectively. We use the RandomizedSearchCV function from scikit-learn to find the optimal hyperparameters during model training. The feature_importances_ function is then used to compute the importance of each parameter and prompt based on the Mean Decrease Impurity (MDI), a.k.a. as Gini importance. To ensure reliability, we repeat this process 10 times.\nFigures 2a and 2b present the calculated importance of parameters and prompts based on the mean decrease in impurity, with respect to inference time"}, {"title": "5 Conclusion", "content": "In GenAI text-to-image, achieving images of high-quality is often not the only important aspect to consider, as inference time, which directly impacts user experience and energy consumption, also plays a critical role. In this work we introduced GreenStableYolo, the first approach leveraging NSGA-II to strike an optimal trade-off between these two objectives for Stable Diffusion. Experimental comparisons with StableYolo demonstrate that GreenStableYolo achieves significantly reduced inference time while maintaining a relatively high image quality. Future research can expand upon our evaluation by incorporating alternative initial prompts, optimizing different performance metrics such as energy consumption, and broadening to other GenAI systems such as DALL-E, ImageFX, or Midjourney."}]}