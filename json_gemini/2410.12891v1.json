{"title": "Multi-trait User Simulation with Adaptive Decoding for Conversational Task Assistants", "authors": ["Rafael Ferreira", "David Semedo", "Jo\u00e3o Magalh\u00e3es"], "abstract": "Conversational systems must be robust to user interactions that naturally exhibit diverse conversational traits. Capturing and simulating these diverse traits coherently and efficiently presents a complex challenge. This paper introduces Multi-Trait Adaptive Decoding (mTAD), a method that generates diverse user profiles at decoding-time by sampling from various trait-specific Language Models (LMs). mTAD provides an adaptive and scalable approach to user simulation, enabling the creation of multiple user profiles without the need for additional fine-tuning. By analyzing real-world dialogues from the Conversational Task Assistant (CTA) domain, we identify key conversational traits and developed a framework to generate profile-aware dialogues that enhance conversational diversity. Experimental results validate the effectiveness of our approach in modeling single-traits using specialized LMs, which can capture less common patterns, even in out-of-domain tasks. Furthermore, the results demonstrate that mTAD is a robust and flexible framework for combining diverse user simulators.", "sections": [{"title": "Introduction", "content": "Thoroughly testing a conversational system with real users is a costly and time consuming process. Part of this cost lies in the myriad of conversational traits, reflecting user's behaviors, knowledge, and goals, which when diverse have shown to help improve performance of conversational systems (Tang et al., 2021; Shi et al., 2019). User simulators have been a successful approach to model real user conversational traits and discover errors and limitations in conversational systems (Shi et al., 2019; Rastogi et al., 2020; Liu et al., 2023; Zhao et al., 2023). Prior research investigated user simulators across diverse settings, including task-oriented dialogues (Lin et al., 2021; Shi et al., 2019; Liu et al., 2023) and recommendation (Zhang and Balog, 2020; Afzali et al., 2023; Zhao et al., 2023) contexts. However, designing user simulators that can effectively engage with a system is challenging, due to the need for adaptability and controllability across various user conversational patterns.\nSimulating a user conversational profile entails a combination of diverse conversational traits, as shown in Table 1. In this work, we follow model-based approaches (Liu et al., 2023; Lin et al., 2021; Shi et al., 2019) by learning trait-specific Language Models (LMs) and combining them into multiple different user profiles. Approaches to combine models include weight level approaches (Wortsman et al., 2022; Ilharco et al., 2023; Yu et al., 2023; Yadav et al., 2023), and trainable Mixture-of-Experts (MoE) (Feng et al., 2024; Chen et al., 2024a; Wu et al., 2024; Jiang et al., 2024). Instead of combining LMs before inference time, we propose an adaptive and scalable method that combines user traits at decoding-time by sampling from distributions from each trait-specific LM. With the proposed multi-Trait Adaptive Decoding method (mTAD), we are able to sidestep the need for combinatory training datasets or extra model fine-tuning. In addition, new LM traits can be adaptively added to the pool of traits creating a new user profile, without the need to retrain existing LMs. As we show, combining these traits is crucial for fostering more diverse conversational patterns.\nTo identify these traits, we analyzed real-world dialogues in the novel Conversational Task Assistant (CTA) domain (Gottardi et al., 2022; Agichtein et al., 2023) and extracted the most relevant traits. In CTA scenarios, users actively engage in completing manual tasks (e.g., baking a cake) with the system's assistance, fostering mixed-initiative dialogues that pose unique user modeling challenges.\nIn summary, one of the core contributions of this paper is the Multi-Trait Adaptive Decoding method (mTAD), which allows for the combination of LMs to simulate multiple different user profiles at decoding time, removing the need for combinatory data or additional fine-tuning. The second contribution is the introduction of a set of user conversational traits at dialogue-level and utterance-level, derived from real-world CTA data collected during the Alexa TaskBot Challenge (Gottardi et al., 2022). Experimental results support the need for specialized LMs to accurately represent each trait. Additionally, the results show the scalability and performance of mTAD, which can flexibly simulate users with arbitrary combinations of traits, without user profile-specific training."}, {"title": "Related Work", "content": "Conversational Assistants Prior work has focused on task-oriented (Budzianowski et al., 2018; Rastogi et al., 2020) and recommendation systems (Li et al., 2018; Lei et al., 2020), where the assistant performs tasks based on user input (e.g. buying a ticket). Our work departs from these traditional settings and explores CTAs (Gottardi et al., 2022), where users complete tasks (e.g., cooking) with help from the assistant, presenting unique modeling challenges (Chan et al., 2023), which we investigate in the context of user simulation.\nUser simulators Initial works (Schatzmann et al., 2007; Li et al., 2016) used rule-based agendas to model user actions. More recently, model-based approaches (Shi et al., 2019), in specific with LLMs (Lin et al., 2021; Li et al., 2022; Liu et al., 2023) have been used. Additionally, diverse user simulators have shown to improve system performance (Liu et al., 2023; Tang et al., 2021). We believe more attention should be given to modeling specific user traits, which we address by modeling user profiles as combinations of specialized LMs.\nModel Combination User simulators must exhibit diverse conversational patterns to effectively evaluate conversational systems. Model merging techniques (Yadav et al., 2023; Yu et al., 2023; Ilharco et al., 2023) combine models at a weight level, enhancing their capabilities across various NLP tasks. Alternatively, mixture-of-experts approaches (Chen et al., 2024b; Feng et al., 2024; Jiang et al., 2024) use a trainable router in the Transformer (Vaswani et al., 2017) to integrate information from multiple models. In a different vein Sitdikov et al. (2022) uses a classifier to adjust token probabilities, while Shen et al. (2024) applies a classifier to determine when to activate the decoding process of different models. In this work, we propose mTAD, a controllable and adaptable method that combines token distributions from various models at decoding time without requiring additional fine-tuning."}, {"title": "Adaptable Multi-Trait User Simulators", "content": "End-to-end simulators (Lin et al., 2021; Kim and Lipani, 2022) may overlook less common styles and language subtleties due to smoothing or potential forgetting (Luo et al., 2023), while being limited w.r.t. generalization to novel traits. Therefore, we consider a trait-oriented model-based approach, in which specialized trait simulators are created and flexibly combined at decoding time."}, {"title": "Trait-Specialized User Simulators", "content": "Given a dialogue domain \\(M\\) (e.g. TOD or CTA), we define a conversational trait \\(t_i\\) in a discrete three-intensity level range \\(l_i \\in \\{low, neutral, high\\}\\). Each trait-intensity pair \\((t_i, l_i)\\) has an associated dialogue language modeling distribution:\n\\[P_\\theta(t_i,l_i)(w_j/w_{<j}, H, M, (t_i, l_i)),\\]\nwhere \\(w_j\\) is the next token to be generated, \\(H\\) the dialogue history, and \\(\\theta(t_i,l_i)\\) the distribution's parameters. Traits can encompass any conversational characteristic measurable across a dialogue, such as cooperativeness and fluency \u2013 in Section 4, we introduce the set of traits used in this work. This formulation, allows us to categorize and simulate diverse user traits at different levels of intensity.\nGiven the set of all traits \\(T\\), a user profile \\(U\\) is defined as the set of traits:\n\\[U = \\{(t_1,l_1),..., (t_{|T|}, l_{|T|})\\}.\\]\nAs an example, we can define an *unco-operative but fluent user profile*: \\(U_{e.g.} = \\{(t_{\\text{cooperativeness}}, \\text{low}), (t_{\\text{fluency}}, \\text{high})\\}\\).\nA user profile \\(U\\) is thus modeled as the conditional probability distribution:\n\\[P_{\\theta_U}(w_j/w_{<j}, H, M, \\{(t_i, l_i)\\}_{i=T}),\\]\nwith \\(\\theta_U\\) being the profile distribution parameters. Our proposed simulator is designed to maximize the expectation \\(E[P_{\\theta_U}]\\) in a zero-shot manner."}, {"title": "User Simulator LMs", "content": "Due to the combinatory nature of user profiles, maximizing the expectation \\(E[P_{\\theta_U}]\\) on demand, for every possible trait-combination, is infeasible. Instead, to provide an adaptable and controllable user simulator, given a target user profile \\(U\\), we focus on learning individual traits distributions \\(P_{\\theta(t_i,l_i)}\\), and combine them at inference time to maximize \\(E[P_U]\\). This is accomplished with mTAD, our proposed zero-shot trait-combination strategy (Section 3.3).\nApproximating \\(P_{\\theta(t_i,l_i)}\\) with a LoRA-based Specialized Trait Simulator (STS). The goal is to have one Specialized-Trait Simulator (STS) per trait. This enables each model to capture the subtleties of specific traits, with minimal interference from others, by learning an independent distribution \\(P_{\\theta(t_i,l_i)}\\) for each one. In addition, given our focus on delivering adaptable simulators, this strategy makes the incorporation of new traits seamless since each model operates independently.\nTo model the distribution \\(P_{\\theta_U}\\) we adopt a model-based approach (Lin et al., 2021; Kim and Lipani, 2022), using an LLM to capture each trait. In practice, maximizing the log-likelihood \\(P_{\\theta(t_i,l_i)}\\) corresponds to minimizing the LLM's language modeling cross-entropy over trait-specific dialogues."}, {"title": "Approximating \\(P_\\theta U\\) with Multi-Trait Adaptive Decoding (mTAD)", "content": "To deliver an on-demand simulator of a user profile \\(U\\), with a set of traits and corresponding intensities, while avoiding additional fine-tuning, we propose to approximate \\(P_{\\theta U}\\) as a combination of independent trait distributions \\(P_{\\theta(t_i,l_i)}\\), and implicitly maximize \\(E[P_{\\theta U}]\\). Namely, we propose Multi-Trait Adaptive Decoding (mTAD), to combine multiple user traits at decoding level as the following:\n\\[P_{\\theta_U}(w_j/w_{<j}, H, M, \\{(t_i, l_i)\\}_{i=1}^{|T|}) = \\sum_{i=1}^{|T|} \\lambda_i \\cdot P_{\\theta(t_i,l_i)}(w_j/w_{<j}, H, M, (t_i, l_i)),\\]\nwhere \\(\\lambda_i\\) are tunable trait weight parameters, which offer controllability in the profile modeling process, where one can easily select and activate each specialized trait simulator (STS).\nIn practice, each \\(P_{\\theta(t_i,l_i)}\\) is modeled by a language model \\(M_i\\), where, to ensure compatibility, all models \\(M\\) share the same vocabulary. During decoding, at each step, given the distribution \\(P_{\\theta_U}\\), we sample tokens using a given decoding strategy. This implies sampling each specialized trait LM independently for each decoding step, which has minimal requirements due to the selective activation of different LoRA adapters. Figure 1 represents an overview of the mTAD framework."}, {"title": "User Simulator Grounding", "content": "To materialize the probability distribution of Eq. 1 and ground the behavior of each STS, we define the input sequence:\n\\[P \\oplus U \\oplus S,\\]\nwhere \\(\\oplus\\) denotes the concatenation operation, \\(P\\) is an optional preamble, which varies based on the model used (Chiang et al., 2023), \\(H\\) represents the dialogue history, including \\(n\\) previous turns (each consisting of a user and system utterance), \\(U\\) is the user profile, encoded as a unique token sequence, and \\(S\\) is a suffix used to prompt generation.\nThe learning objective becomes the causal language modeling task, which corresponds to minimizing the loss:\n\\[L = -\\sum_{j=1}^{N} \\log(P_{\\theta(t_i,l_i)}(w_j/w_{<j}, P, H, U, S)),\\]\nwhere \\(j\\) is the \\(j\\)-th token and \\(N\\) the number of tokens in the response, which comprises both the a user intent and the utterance. The model is trained on this dual-generation task to enhance interpretability by enabling the analysis of intent distribution probabilities. In Appendix C, we present an example of the input and response formats."}, {"title": "User Simulation in Conversational Task Assistants (CTAs)", "content": "Conversational Task Assistants (CTAs) guide users through tasks such as cooking or DIY (Gottardi et al., 2022; Agichtein et al., 2023). This setting raises a number of challenges (Chan et al., 2023; Choi et al., 2022), that are particularly well addressed by mTAD: dialogues have mixed-initiative, users follow a task plan with the aim of completing a manual task, ask explorative questions, and engage in chit-chat as shown in Table 1."}, {"title": "Real World Conversational Data", "content": "To ensure the most representative user simulator, we ground the trait and models on real-world dialogue data. Specifically, we used the dataset from Gl\u00f3ria-Silva et al. (2024) composed of 3.6k conversations collected during the Alexa TaskBot Challenge (Gottardi et al., 2022). This dataset is composed of a generated dialogue graph based on intent transitions and ASR transcribed real user utterances. We extend this pipeline to include a diverse profile-aware creation process detailed in Appendix B."}, {"title": "Modeling User Traits", "content": "To define the set of traits (T) characterizing a user profile (U), we carefully analyzed human-system conversations (for statistics, refer to Appendix A), identifying two categories at different levels: 1) Dialog-level, and 2) Utterance-level."}, {"title": "Dialog-Level Traits", "content": "Dialog-Level traits influence the overall progression of a conversation by impacting the probability of transitioning between intents.\nEngagement. Reflects the user's willingness to engage with the system for a longer period of time as in (Salle et al., 2021). We measure engagement by the number of turns in the dialogue.\nCooperativeness. Users' tendency to follow the system's instructions and reduce unrelated interactions. It is measured by the probability of in-domain intents in the dialogue. Cooperativeness is a trait also discussed in (Salle et al., 2021; Lei et al., 2022), which we include here for task-guiding dialogues.\nExploration. This trait strikes the balance between exploitation, which involves moving forward in the task, and exploration, which entails engaging with optional system features (Zou et al., 2022). It is measured by the probability of explorative intents (e.g. QA) that differ from the default navigational requests (e.g. \"next step\").\nTolerance. Represents the user's tolerance for system mistakes, where less tolerant users conclude the interaction sooner (Pearl, 2016). Represented by the tolerance rate, defined as the number of system mistakes tolerated divided by the number of turns."}, {"title": "Utterance-Level Traits", "content": "These traits consider a more fine-grained behavior, which given an intent, chooses the style of the utterance according to the user profile.\nVerbosity. Verboseness of the user's requests. Measured by the average number of words in each utterance.\nEmotion. Refers to the overall tone (negative or positive) expressed towards the system. Emotion level is measured in a 0-1 scale using the model from (Camacho-Collados et al., 2022).\nFluency. Represents the ability to express oneself clearly and coherently without hesitations, disruptions, or ASR errors. The fluency level is measured in a 0-1 scale using model 2.\nRepetition. Consistent use of the same lexicon throughout the dialogue. Measured through word overlap between consecutive utterances."}, {"title": "Trait Distribution and Intensity", "content": "Figure 2 shows the dialogue data distribution per trait and intensity pair. It shows that certain traits exhibit longer tails and have more noticeable differences across intensities, which is expected to have a direct influence on their modeling challenges."}, {"title": "Experimental Setup", "content": "Dataset\nTasks and Training Dialogues. We focus on the task execution phase (Gottardi et al., 2022), where the user has an ongoing task such as \u201cbaking a cake\". We focus on task assistance in the cooking domain (M) and use 1000 unique recipes to ground the dialogue flow. Given these, we randomly sample tasks to generate a total of 20k dialogues with an average of 9.6 turns. Finally, we use a 1000/100/100 dialogue split for each trait-intensity pair and ensure generalization by not sharing tasks between splits.\nSimulator Inference. We evaluate various user simulators by interacting with a live system, Plan-LLM (Gl\u00f3ria-Silva et al., 2024), known for its task-guiding capabilities. For each experiment, we generate 100 dialogues per profile, with interactions ending either by the simulator's side (i.e. the user) or upon reaching a maximum turn limit of 20.\nModels and Baselines.\nAs the backbone for our simulators, we used the Transformer-based (Vaswani et al., 2017) Mistral-7B (Jiang et al., 2023) and Vicuna-7B (Chiang et al., 2023). The results for Vicuna are in annex and support generalization across LLMs.\nWe evaluated two types of simulators: the proposed Specialized Trait Simulators (STS) from Section 3.1, which models each trait independently. And as a strong baseline, we consider a Joint Trait Simulator (JTS), that jointly learns a distribution for all traits in a single model.3\nImplementation Details In all experiments, we use LORA (Hu et al., 2022) adapters and a 4-turn context size. To account for the variability of users, we employ sampling decoding. For detailed information about the training procedure, refer to Appendix D.\nAutomatic Metrics Evaluating user simulators is challenging (Shi et al., 2019; Li et al., 2022; Zhao et al., 2023) due to the absence of a single correct"}, {"title": "Results and Discussion", "content": "Single-Trait Evaluation\nIn this setting, we create user profiles by adjusting each trait from Section 4.2 to a non-neutral (i.e. *Low* or *High*) intensity level. Additionally, we create a profile called *Regular*, where all traits are set to neutral.\nTrait Matching\nIn Figure 3, we compare the performance of STS and JTS across trait intensities, aiming for values closer to the reference. As expected, both methods exhibit increasing metrics with trait intensity. However, JTS shows a greater deviation from the reference at both *Low* and *High* intensities especially noticeable in utterance-level traits.\nIn Table 2, we use distance-based metrics to assess the simulators' modeling of the reference distributions. STS generally represents trait behaviors more closely, especially at *Low* and *High* intensities, as each model learns specific profiles independently. For some traits, JTS represents the Regular profile (neutral intensity for all traits) closer. This is a result of having been exposed to all profiles during training, resulting in an overall smoother distribution that fails to capture extreme trait-intensity subtleties. See Appendix K for examples of generated dialogues.\nModeling Traits Difficulty. Each trait poses unique modeling challenges. JTS struggles with *Low Fluency* since LLMs are trained to generate coherent text. It also struggles with *High Fluency* due to smoothing effects from the Regular profile, while STS is able to learn these patterns.\nGeneralization to Unseen Domains\nTo assess how user simulators adapt to new domains M, with out-of-domain tasks, we randomly sampled 100 DIY tasks from WikiHow, generated 100 more dialogues per profile, and evaluated whether the trend follows the correct pattern.\nThe results in Table 3 indicate good generalization, showing an upward tendency in all cases. As before, STS achieves more pronounced metrics over intensity ranges, demonstrating the simulator's ability to generalize to novel tasks."}, {"title": "Multi-Trait Combination Evaluation", "content": "We now evaluate trait combinations, using STS to model individual traits. We defined a total of 14 profiles: 8 with 2 traits, 4 with 3 traits, and 2 with 4 traits (full list in Appendix F). For evaluation purposes, we create dialogs for these combinations and use the same evaluation protocol, generating 100 dialogues for each profile and method.\nMulti-Trait Combination Results\nTable 4 presents the average results for all profiles, and grouped by the number of combined traits. mTAD-based methods outperform *Sampling*, as they combine multiple models instead of relying on a single one per turn. *Sampling* also produces inconsistent behavior by mimicking different profiles across turns.\nUsing the mTAD framework, it is important to consider the current decoding step, evident by the best performing method mTAD-LA, which activates relevant models depending on the current generation step. As the number of traits increases, modeling difficulty also rises due to distribution dilution across profiles. In these experiments, mTAD weights were fixed and uniformly split across each profile, in Appendix G, we show mTAD's controllability by varying these weights.\nIn summary, we show models can be combined at decoding time using mTAD without additional training, and that activating models at the appropriate time enhances profile modeling performance."}, {"title": "Multi-Level Simulator Evaluation", "content": "To further validate the simulators' behavior, we use the best methods for Single-Trait (STS) and Multi-Trait (mTAD-LA), sampling 10 dialogues from each user profile, resulting in a total of 300 dialogues.\nMulti-Level Evaluation Metrics\nFor turn-level evaluation, we considered the following metrics:\n\u2022 Degeneration - A rule-based binary metric that flags degeneration if: 1) the output does not have a valid user intent, or 2) special tokens (e.g., speaker labels, SOS, EOS) appear within the middle of a generated utterance.\n\u2022 Uniqueness - A binary metric that checks if the generated utterance is novel, i.e., it does not appear in the training data, indicating the model's ability to generate original responses.\n\u2022 System Response Quality - A rating from 0 to 2, assessing the quality of the system's response in relation to the ongoing dialogue.\nAt the dialogue level, we measured *Trait Modeling Accuracy* by comparing each profile's generated dialogue across its defining traits (i.e. \\(l_i \\neq neutral\\)), with a dialogue from the test set with the same task but an opposite trait intensity, as well as comparing with a *Regular* dialogue."}, {"title": "Turn Level Results.", "content": "Analyzing turn-level metrics in Table 5, we observe that degenarations are rare (\u2264 4%), indicating the methods' ability to generate and combine profiles effectively.\nRegarding uniqueness, both methods have similar values, with over 50% of the utterances not appearing in the training set, demonstrating good generalization to other requests and tasks.\nThe system's response quality is generally good with the model achieving an average score over 1.4. A closer analysis by trait revealed that the system achieves higher response quality scores (\u22651.57) handling higher fluency, exploration, and emotion, while scoring lower (\u2264 1.34) for low engagement, tolerance and high verbosity. These results allow to understand system limitation and in turn create more robust systems, as it has been shown that simulator variability can improve system performance (Liu et al., 2023; Tang et al., 2021)."}, {"title": "Trait Modeling Accuracy Results.", "content": "Table 6 presents the results of trait modeling accuracy. On average, we observe a small drop in performance when moving from single to multi-trait settings. As expected, model accuracy is higher when comparing opposite intensity traits, due to the more pronounced differences between them compared to a Regular dialogue. Performance significantly declines in the multi-trait setting with Regular dialogues, as the model must integrate multiple profiles, resulting in a smoothing effect that makes it harder to distinguish traits compared to the single-trait setting.\nExamining individual traits, modeling low verbosity and high emotion is particularly challenging since their Regular values are similar to these traits. Conversely, engagement is easier to model because it relies on the number of turns, and low emotion is detectable due to utterances indicating low motivation. Full results by trait are provided in Appendix J.\nIn summary, the results show good performance in both single-trait and multi-trait settings, allowing for diverse simulators that can be effectively combined at decoding time."}, {"title": "Conclusions", "content": "This paper addresses the challenge of simulating diverse user traits and effectively combining them in a conversational setting. Using real-world data to identify user traits, we developed a framework to generate profile-aware conversations, being one of the first to deliver user simulators for the Conversational Task Assistance (CTA) setting.\nOur results demonstrate the need for specialized simulators for each trait (STS), which produce a more accurate trait adherence when compared to jointly learning all traits with a single model. The latter converges to highly smoothed trait distributions that tend to overlook subtle trait characteristics. With STS, trait-specific characteristics are better preserved, including in unseen domains with different tasks, highlighting its generalizability.\nTo flexibly combine diverse user traits and profiles without extra fine-tuning, we proposed Multi-Trait Adaptive Decoding (mTAD). The results show that mTAD effectively combines multiple user traits. This shows that our framework provides an adaptable and controllable approach to create user simulators that can accommodate a wide range of profiles and tasks."}, {"title": "Limitations", "content": "Our analysis focuses on a particular set of conversational traits. Given the versatility and broadness of this setting, additional traits could be considered to have a more comprehensive user simulator. Additionally, given the combinatorial nature of possible trait combinations, despite our approach supporting it, we did not exhaustively explore all combinations of the various traits. Furthermore, our simulator focuses on the task execution level, leaving room for future work in the retrieval and grounding processes of Conversational Task Assistants (Chan et al., 2023).\nTo conclude, we believe our work presents a step forward in creating adaptable user simulators, however, subsequent studies should broaden the scope to allow for a more comprehensive understanding of user simulation dynamics."}, {"title": "Ethical Considerations", "content": "All human interactions considered in this study were obtained voluntarily, with users having the ability to withdraw at any point. Prior to each interaction with the system, users were informed that all information would be saved and shared with the authors. Subsequently, users were given the option to proceed with the interaction, indicating their understanding of the terms and conditions. Moreover, the responses collected were anonymous and devoid of user demographics. Additionally, we conducted a thorough review of the data to ensure that no personal information was included.\nRegarding the annotators, all individuals volunteered and provided consent to participate in the experiment. They were fully informed about the study and its implications."}, {"title": "Adaptable Multi-Trait User Simulators", "content": "End-to-end simulators (Lin et al., 2021; Kim and Lipani, 2022) may overlook less common styles and language subtleties due to smoothing or potential forgetting (Luo et al., 2023), while being limited w.r.t. generalization to novel traits. Therefore, we consider a trait-oriented model-based approach, in which specialized trait simulators are created and flexibly combined at decoding time."}]}