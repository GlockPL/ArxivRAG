{"title": "Learning How to Vote With Principles", "authors": ["Levin Hornischer", "Zoi Terzopoulou"], "abstract": "Can neural networks be applied in voting theory, while satisfying the need for transparency in collective decisions? We propose axiomatic deep voting: a framework to build and evaluate neural networks that aggregate preferences, using the well-established axiomatic method of voting theory. Our findings are: (1) Neural networks, despite being highly accurate, often fail to align with the core axioms of voting rules, revealing a disconnect between mimicking outcomes and reasoning. (2) Training with axiom-specific data does not enhance alignment with those axioms. (3) By solely optimizing axiom satisfaction, neural networks can synthesize new voting rules that often surpass and substantially differ from existing ones. This offers insights for both fields: For AI, important concepts like bias and value-alignment are studied in a mathematically rigorous way; for voting theory, new areas of the space of voting rules are explored.", "sections": [{"title": "1. Introduction", "content": "Artificial intelligence (AI) is increasingly applied in many domains, including not just scientific and technological but also societal domains. This poses a dilemma when it comes to social choice, i.e., voting, preference aggregation, and other processes of collective decisions. On the one hand voting systems should be transparent, but the neural networks on which modern Al is built are notoriously opaque. On the other hand neural networks could unearth novel and tailor-made collective decision procedures. Already, state-of-the-art techniques for alignment of Large Language Models (LLMs) with human values-like RLHF (Bai et al., 2022) or DPO (Rafailov et al., 2024)-rely on the aggregation of human preferences about the generated outputs to fine-tune LLMs. This triggered recent research in guiding such Al alignment using social choice (Conitzer et al., 2024). In this paper, we study how neural networks aggregate votes and preferences. When they form such collective decisions, do they adhere to the normative principles that social choice theory formulated as axioms? This is fundamental both for a discussion of the dilemma and for using social choice for Al alignment. Moreover, it offers new insights for both AI and voting theory. For Al, this provides a rich testing ground to study pressing machine learning concepts like bias, value-alignment and interpretability in a mathematically rigorous way. For example, a network is not biased towards specific individuals if it aggregates their preferences in accordance with the axiom of anonymity; the so-called Pareto principle requires the neural network to align with any preference shared among all individuals; and the well-known axiom of independence entails a certain compositional interpretability of the network. For voting theory, axiomatic deep voting provides a new method for the central quest of exploring the space of voting rules."}, {"title": "Social choice.", "content": "How are individual preferences best turned into a collective decision? This question is studied by social choice theory (Brandt et al., 2016; List, 2022) and, specifically, voting theory (Zwicker, 2016). A voting rule is a function that takes as input a profile-i.e., a list of each individual's preferences among a given set of alternatives- and produces as output a collective decision, i.e., the alternative(s) that the rule takes to be most preferred for the group as a whole (see Section 3 for the formal definitions). The most straightforward rule is Plurality (which picks the alternative that is considered best by the most individuals); other classic rules include Borda and Copeland, while a more recent suggestion is Split Cylce."}, {"title": "Axiomatic deep voting.", "content": "To study the collective choices of neural networks, we develop the axiomatic deep voting framework (sketched in Figure 1). Deep neural networks are (parametrized) functions that map vectors (typically of a high dimension) to vectors (typically of a low dimension). So, after suitably encoding profiles and collective decisions as vectors, neural networks realize voting rules, i.e., functions from profiles to collective decisions. Discovering a voting rule can then be seen as an optimization problem: updating the neural network parameters until a given desired property is fulfilled. We evaluate a trained neural network in terms of accuracy and axiom satisfaction. While the former is standard in machine learning, the latter is specific to voting theory and its axiomatic method (Thomson, 2001; List, 2011). Different axioms describe different desirable properties of voting rules. An example is the already mentioned anonymity axiom which requires that the names of the voters should not influence the collective decision."}, {"title": "Research questions.", "content": "With this framework, we investigate three specific questions."}, {"title": "2. Related Work", "content": "We identify three main streams of relevant literature."}, {"title": "2.1. Axiomatic Evaluation of Voting Rules", "content": "Social choice theory has extensively quantified the axiom satisfaction of various voting rules, with a significant focus on the concept of manipulability, i.e., the propensity of voters to be untruthful in order to sway the outcome in their favor (Favardin et al., 2002; Favardin and Lepelley, 2006; Nitzan, 1985). Numerous studies (Fishburn and Gehrlein, 1982; Merrill, 1984; Nurmi, 1988) examine how often voting rules elect the Condorcet winner (that is, the alternative representing a majoritarian consensus) for relatively small elections all having the same probability of materializing (that is, assuming the Impartial Culture distribution). In line with our findings, the Borda rule is found to elect the Condorcet winner more often than the Plurality rule (Nurmi, 1988). When considering the axiom of independence- the main trigger of Arrow's impossibility theorem\u2014the Borda rule fulfills it more frequently than Copeland, which in turn satisfies it more than Plurality (Dougherty and Heckelman, 2020). For the special case of 3 voters and 3 alternatives, an anonymous voting rule satisfies independence between 1.3% and 25.5% of the time (Powers, 2007). Overall, our work aligns with the traditional concept of evaluating voting rules based on axioms. However, we also consider learning voting rules and not just evaluating existing ones."}, {"title": "2.2. Neural Networks and Voting", "content": "The synergy between voting and machine learning has recently garnered more and more attention. Kujawska et al. (2020) use, among others, multi-layer perceptrons (MLPs) on elections of 20 alternatives and 25 voters to predict the winners of different voting rules. The study's primary aim is to identify an effective computational technique on top of the classical ones of the voting literature. The authors find that the Borda rule is predicted by the neural networks with high accuracy (up to 99%), but more complex rules are predicted with lower accuracy (up to 85% for Kemeny and 89% for Dodgson). Burka et al. (2022) employ MLPs to investigate the relation between sample size and accuracy when learning different voting rules, including Plurality, Borda, and Copeland. In that work, up to 3000 data points are used based on the Impartial Culture assumption, with at most 5 alternatives and 11 voters. The MLP is found to mimic more closely Borda, no matter on which rule it is trained: e.g., for 3 alternatives and 7 voters, trained on Plurality, the MLP mimiced Borda with 95% accuracy and Plurality with 86% accuracy. However, the size of the training data exhibits an impact on the results: e.g., when trained on elections with a Condorcet winner, the MLP mimics more closely Borda in sample-size up to 1000, and Copeland in larger samples. Increasing the size of the MLP by adding layers does not seem important. Anil and Bao (2021) study more complex neural network architectures (such as Set Transformers and DeepSets), improving the accuracy of MLPs by up to 4% in learning Plurality and Copeland. With sufficiently many data points, those networks are shown to match almost perfectly each voting rule, and to also generalize to elections with an unseen number of voters. Similarly to all these works, our first experiment considers precisely the problem of using neural networks to learn existing rules from voting theory. However, we systematically study this with axioms: instead of only targeting the right outcomes, we test whether they are obtained via the right principles. In an initial exploration towards the same direction, Armstrong and Larson (2019) use a single axiom-prescribing the election of a Condorcet winner when one exists-to train normatively appealing neural networks. This work relies on real data from Canadian federal elections, while ours builds on extensive synthetic data. Additionally, our third experiment illustrates original interactions between sets of different axioms that have not been explored in the literature yet. However, one of the more intricate voting principles not tackled in our paper is fairness. After observing a theoretical trade-off between fairness and certain notions of economic efficiency (some related to the Condorcet winner), Mohsin et al. (2022) train two machine learning models on synthetic data and discover new voting rules that compete well against both Plurality and Borda. Although rule synthesis and axiomatic analysis is not a main focus of that work, the obtained results enforce the idea that machine learning methods can beat existing ones from economic theory when optimized for principled learning. Other promising lines of research target learning an abstract voting rule given examples about its choices (Procaccia et al., 2009) and designing a voting rule that maximizes some notion of social wel- fare (Anil and Bao, 2021). Holliday et al. (2024) explore the strategic manipulation of voting rules by MLPs of different sizes, generat- ing elections of up to 6 alternatives and 21 voters. They find that"}, {"title": "2.3. Social Choice for Al Alignment", "content": "A growing research area studies how social choice theory can be used to guide the alignment of modern AI methods with human values and moral judgments. Conitzer et al. (2024) highlight a series of technical connections-for example, the alternatives in a voting context could be treated as all possible parameterizations of a network, or as all its possible answers. As an indication, in a popular work about a controversial topic, Noothigattu et al. (2018) use data from the online 'moral machine experiment' to build a model of aggregated moral preferences aimed at guiding the decision making of autonomous vehicles. On a more theoretical level, Mishra (2023) utilize Arrow's theorem to prove that there does not exist any AI system that can treat all its users and human supervisors equally. We do not directly engage with the ethical dimension of this research area; still, we participate in the related foundational discussion by studying whether neural networks can learn to vote with principles."}, {"title": "3. Preliminaries on Voting Theory", "content": "We work in the standard setting of voting theory, where a finite set N of voters N have preferences, which are linear orders (also called rankings) over a finite set A of alternatives (Zwicker, 2016). Set $m := |A|$ and $n := |N|$. We denote by $P = (P_1,..., P_n)$ a preference profile, i.e., a vector with the preference $P_i$ for every voter $i \\in N$. For a permutation of the alternatives $\\sigma: A \\rightarrow A$, the ranking $\\sigma(P)$ is obtained by applying $\\sigma$ elementwise to the ranking P, and $\\sigma(P) = (\\sigma(P_1),..., \\sigma(P_n))$. For a permutation of the voters $\\pi : N \\rightarrow N$, we define $\\pi(P) = (P_{\\pi(1)},..., P_{\\pi(n)})$. A voting rule is a function F that determines the winning alternatives for each such profile. Formally, $F: P\\rightarrow S$, where $\\emptyset \\neq S \\subset A$."}, {"title": "3.1. Voting Rules", "content": "Voting rules usually fit into one of two categories: scoring rules and tournament solutions. Scoring rules assign a score to each alternative depending on its position in the linear preference of each voter and declare as winners those alternatives with the highest score across all voters. The two primary scoring rules are Plurality (assigning score 1 to an alternative each time it is ranked first by a voter, and score 0 otherwise) and Borda (assigning score $m - 1$ to an alternative ranked first by a voter, score $m - 2$ to an alternative ranked second, and so on, until score 0 is assigned to an alternative ranked last by a voter). Tournament solutions on the other hand are based on tournaments that capture pairwise comparisons between the alternatives, induced by the voters' preferences. For $x,y \\in A$, let $N_{xy}$ be the set of voters i in the profile P that consider x better than y in $P_i$, and $n_{xy} := |N_{xy}|$. A characteristic tournament solution is the Copeland rule, which selects as winners the alternatives that beat the most other alternatives in a pairwise majority contest: $argmax_{x \\in A} |\\{y \\in A : n_{xy} \\geq n_{yx}\\}|$. The weighted tournament of a profile is a weighted directed graph the nodes of which are alternatives with an edge from x to y of weight $n_{xy}$. Suppose that in each cycle of the graph, we simultaneously delete the edges with minimal weight. Then the alternatives with no incoming edges are the winners of Split Cycle (Holliday and Pacuit, 2023a). If there is only one Split Cycle winner in a profile P, then this also is the winner of Stable Voting; otherwise x is a winner of Stable Voting if for some alternative y it holds that x is a Split Cycle winner with the maximal margin $n_{P-y}$ such that x is a Stable Voting winner in the profile $P-y$ obtained from P after deleting alternative y (Holliday and Pacuit, 2023b)."}, {"title": "3.2. Axioms", "content": "We define axioms as functions that map a voting rule and a preference profile to a value in {-1,1,0}, where 0 means that the axiom is not applicable, -1 means that the desideratum is violated, and 1 that it is satisfied. The satisfaction degree of an axiom is the ratio of the number of sampled profiles in which the axiom is satisfied to the number of sampled profiles in which it is applicable. We focus on axioms that capture basic and diverse normative properties of a voting rule F.\n\u2022 Anonymity is always applicable; it is satisfied in P if for all permutations of voters $\\pi : N \\rightarrow N$, $F(\\pi(P)) = F(P)$. In words, the winners should be invariant under permutations of the voters.\n\u2022 Neutrality is always applicable; it is satisfied in P if for all permutations of alternatives $\\sigma: A \\rightarrow A$, $F(\\sigma(P)) = \\sigma(F(P))$. In words, under permutations of the alternatives, the winners should be permuted respectively.\n\u2022 Condorcet principle is applicable in P if some $x \\in A$ is such that $n_{px} > n/2$ for all $y \\in A \\setminus \\{x\\}$; it is satisfied if $F(P) = \\{x\\}$. In words, if a Condorcet winner exists, then it should be the unique winner of the voting rule."}, {"title": "3.3. Distributions of Preference Profiles", "content": "Specifying the distribution of preference data is essential to study- ing the voting behavior of a society. To ensure that our results are independent of the specific choice of the distribution, we employ four different ones. Impartial Culture (IC) assumes that all preference profiles have the same probability of appearing. Each preference of a voter in a profile is sampled uniformly at random. The Mallows distribution (Mallows, 1957) fixes a reference ranking P and assumes that each voter's preference is close to that ranking. Closeness to the reference ranking is defined using the Kendall-tau distance, parameterized by a dispersion parameter $\\Phi \\in (0,1]$. This distribution reduces to IC when $\\Phi = 1$ and concentrates all mass on $P$ as $\\Phi$ tends to 0. The IC and Mallows distributions are complementary: IC is sim- plistic and widely employed in theoretical works on voting rules; it captures an extreme case with no correlation between preferences of voters. Mallows is often employed in numerical studies of voting rules that use artificial data but wish to capture more realistic voting scenarios (Caragiannis and Micha, 2017; Lee et al., 2014). The next two distributions also capture more intricate relationships between the preferences in a profile. According to the 2D-Euclidean distribution, voters and alternatives are distributed randomly in 2- dimensional Euclidean space, and the closer an alternative is to a voter the more the voter prefers that alternative. Finally, the Urn distribution (Eggenberger and P\u00f3lya, 1923) generates a profile given a parameter $\\alpha \\in [0,\\infty)$. Voters randomly draw their ranking from an urn. Initially, the urn includes all possible rankings over the alternatives. After a voter randomly draws from the urn, we add to the urn $\\alpha n!$ copies of that ranking. When $\\alpha = 0$, this reduces to IC."}, {"title": "4. Method", "content": "To answer our research questions, we develop the axiomatic deep voting framework, visualized in Figure 3. It is built around a neural network, which is a function $f_w: R^i \\rightarrow R^j$ parametrized by wights $w \\in R^k$. We will instantiate this with three different neural network architectures (see Section 4.1). Every profile P is mapped, via an encoding function e (see Section 4.2), to a vector $x = e(P) \\in R^i$, for which the neural network produces an output $\\hat{y} \\in R^j$. The decoding function d (see Section 4.3) turns this output into a winning set $S = d(\\hat{y})$. Thus, this setup realizes the voting rule:\n$F_w (P) := d(f_w(e(P)))$.\nThe network is trained, as usual, using backpropagation with respect to a loss function (in Section 4.4), which relies on training data. Finally, we evaluate (in Section 4.5) the trained network not only with respect"}, {"title": "4.1. Architectures", "content": "We use three paradigmatic neural network architectures from mod- ern machine learning. First, multi-layer perceptrons (MLPs)-also known as feed-forward neural network-are the classic deep neural net (see, e.g., Goodfellow et al., 2016, ch. 6). They consist of an input layer of neurons, one or more hidden layers, and an output layer. Second, convolutional neural networks (CNNs) are a standard ar- chitecture to process grid-like input data such as images (see, e.g., Goodfellow et al., 2016, ch. 9), and in our case profiles. Compared to MLPs, they additionally use so-called convolutional layers to capture local, invariant patterns in the input. Third, we device an architecture that satisfies the anonymity ax- iom by design: We view profiles as sentences whose words are the rankings. We use the word embedding algorithm Word2vec (Mikolov et al., 2013) to map each ranking to a high-dimensional embedding vector. These vectors are averaged-hence we get anonymity-and an MLP then classifies this average into a winning set. This combined architecture we call here word embedding classifiers (WECs)."}, {"title": "4.2. Encoding", "content": "To ensure our neural networks learn general patterns, we do not work with a fixed number of voters and alternatives, but only with a maximal number of voters $n_{max}$ and a maximal number of alterna- tives $m_{max}$. So the model should allow as input any profile P over the set of voters $N = \\{0,..., n-1\\}$ with $n \\leq n_{max}$ and set of alter- natives $M = \\{0,..., m - 1\\}$ with $m \\leq m_{max}$. We write $a_{rs}$ for the r-th most preferred alternative of voter s, so the profile P is represented as the matrix $(a_{rs})$, whose columns are the rankings. We write $\\overline{P} = (a_{rs})$ for the result of padding the $m \\times n$ matrix P with the symbol ~ to the maximal input dimensions $m_{max} \\times N_{max}$. How should we encode $\\overline{P}$ so it can be inputted to a neural net- work? The most straightforward way is to read each alternative a $a \\in M$ as the number that it is and the padding symbol as, say, -1. Then the matrix $\\overline{P}$ is regarded as a vector of dimension $m_{max}N_{max}$. However, this does not perform well, so, following Anil and Bao (2021), we represent an alternative not as a number but as a one-hot vector. For $a \\in \\{0,..., m_{max} - 1\\}$, let $a^o$ be the vector of length $m_{max}$ that is 1 at position a and 0 everywhere else. For the padding symbol ~, let $\\sim^o$ be the vector of length $m_{max}$ that is 0 everywhere. We write $\\overline{P} = (a_{rs}^o)$. The encoding function for MLPs, $e_{MLP}$, maps profile $\\overline{P}$ to the vector x obtained by casting the matrix $\\overline{P}$ column by column into a flattened vector (of dimension $m_{max}n_{max}$). This vector x can then be inputted into the MLP. The encoding function for CNNs regards the matrix $\\overline{P}$ as a pixel im- age: the 'pixel' at position (r, s) has the 'color value' $a_{rs}^o$. Thus, $e_{CNN}$ maps profile $\\overline{P}$ to the matrix $\\overline{P}$ recast as a tensor with dimensions (channel, height, width) = ($m_{max}, M_{max}, N_{max}$). This tensor can then be inputted into the CNN. The encoding function for WECs regards the profile P = $(P_1,..., P_n)$ as a sentence with words $P_i$. We train it to embed these words into vectors of a fixed high dimension. Thus, unlike the previous encoding functions, this one is not separate from the neural network but rather forms the first layer of the WEC, with the remaining layers processing the embedding vectors. More pre- cisely, we first pre-train the embeddings as follows. For a given corpus size c, we sample c-many profiles from a given distribution of profiles (e.g., IC) to form our corpus (i.e., a set of sentences). The rankings occurring in the profiles form the vocabulary of this corpus, to which we add the unk token (to later represent unknown rankings,"}, {"title": "4.3. Decoding", "content": "Given a profile P as input, all neural network architectures produce as output the logits $\\hat{y} = (\\hat{y}_0,..., \\hat{y}_{m_{max}})$ in $R^{m_{max}}$. We apply the sigmoid function $\\sigma$ elementwise to obtain the probability that alter- native r is in the winning set. With m the number of alternatives in profile P, we define the decoding function\n$d_m (\\hat{y}) := \\{r \\in \\{0,..., m\\} : \\sigma(\\hat{y}_r) > 0.5\\}.$In experiment 3, we will consider further versions of this decoding function (see Section 6.3)."}, {"title": "4.4. Loss Functions", "content": "Since multiple alternatives can win, we cast the task of finding a voting rule as a multi-label classification problem. Each input profile P is associated with m binary labels (where m is the number of alternatives in P), and the r-th label is 1 if and only if the r-th alternative is in the winning set associated with P. Hence we use binary cross entropy as loss function. For each axiom, we also design a loss function that enforces sat- isfaction of that axiom. Concretely, for the anonymity axiom, this is done as follows. Given the network $f_w$ and profile P, uniformly sample N-many permutations $\\pi_1,..., \\pi_N$ of the set of voters of P and define\n$L_A (f_w, P):= -\\frac{1}{N} \\sum_{r=1}^N KL(f_w (e(P), f_w (e(\\pi_r (P))))$,where KL is Kullback-Leibler divergence. For the other axioms, we proceed similarly (see Appendix A, where we also discuss differentiability)."}, {"title": "4.5. Evaluation Metrics", "content": "We have two ways of evaluating the model: accuracy and axioms. First, we calculate the accuracy of the trained neural network on a"}, {"title": "5. Experimental Setup", "content": "We work with $n_{max} = 7$ and $m_{max} = 7$ and all four profile distribu- tions in the first experiment and with $n_{max} = 5$ and $m_{max} = 5$ and with IC and Mallows in the other experiments. The first experiment does not show a qualitative difference between these settings, but the latter is computationally more efficient. We use the Mallows distribution with a parameter $r_{rel}$ that, together with the number of alternatives, determines the value of the dispersion parameter $\\phi$. According to Boehmer et al. (2021) and Boehmer et al. (2023), this methodology generates data that resemble more closely those of real elections. We use the Urn-R distribution (Boehmer et al., 2021), where, for each generated profile, a is chosen according to a Gamma distribution with shape parameter k = 0.8 and scale parameter $\\theta$ = 1. The other distributions do not need further parameters."}, {"title": "5.2. Synthetic Data Generation", "content": "We can sample profiles in a controlled and realistic manner and pro- duce their corresponding winning sets with existing voting rules. So we generate synthetic data: Given a profile distribu- tion $\\mu$ and a voting rule F, we randomly pick integers $n \\in [1, n_{max}]$ and $m \\in [1, m_{max}]$ and $\\mu$-sample a profile P with n voters and m alternatives and compute S = F(P). Thus, we generate a dataset $D = \\{(P_1, S_1),..., (P_k, S_k)\\}$."}, {"title": "5.3. Evaluating Axiom Satisfaction", "content": "To evaluate the axiom satisfaction of a voting rule (be it realized by a neural network or an existing one), we sample 400 profiles on which the axioms are applicable. We use the same profile distribu- tion $\\mu$ as was used for training the neural network, and we again randomly choose integers $n \\in [1, n_{max}]$ and $m \\in [1, m_{max}]$ before $\\mu$-sampling a profile with n voters and m alternatives. To compute whether an axiom is satisfied for a profile, the axioms of anonymity, neutrality, and independence require sampling of permutations. We sample, per profile, 50, 50, and $4^n$ permutations, respectively."}, {"title": "5.4. Hyperparameters", "content": "All models use ReLU as activation function. Our MLP has three hidden layers with 128 neurons each. The CNN has two convolu- tion layers with kernel size (5,1) and (1,5), respectively (and 32 or 64 channels), followed by three linear layers with 128 neurons. The WEC has the word embedding layer, then the averaging layer, and then three linear layers with 128 neurons. For pre-training the embedding layer with word2vec, we use a corpus size of $10^5$, an embedding dimension of 200, and a window size of 7. This results in the following numbers of parameters in the setting $n_{max} = 7$ and $m_{max} = 7$: the MLP has 500.487 parameters, the CNN has 1.834.439 parameters, and the WEC has 1.226.143 parameters. Thus, the models are roughly comparable in size. For training, we use the AdamW algorithm (Loshchilov and Hutter, 2019). We use a batch size of 200. Since we have synthetic data, we do not use epochs and hence only specify the number of gradient steps. In experiment 1, 2, and 3, these are 15.000, 5.000, and 15.000, respectively. Similar to Anil and Bao (2021), we use as a learning rate scheduler cosine annealing with warm restarts (Loshchilov and Hutter, 2017). All results are reported for one fixed seed. All experiments have been run on a laptop without GPU."}, {"title": "6. Results and Analysis", "content": "Within our axiomatic deep voting framework, we answer our three research questions: (1) Are preferences-aggregating neural networks correct for the right reasons? No. (2) Can they learn voting-theoretic principles by example? No. (3) Can they synthesize new rules guided by the principles? Yes."}, {"title": "6.1. Correct for the Right Reasons?", "content": "Recent work in computer science has studied the capabilities of neural networks to learn voting rules (Anil and Bao, 2021; Burka et al., 2022), but without asking whether \"the system performs well for the right reasons\" (Bender and Koller, 2020, p. 5192). Here we use voting-theoretic axioms to shed light on the learning behavior of neural networks, specifically aiming to distinguish solely accurate versus principled learning."}, {"title": "Design.", "content": "We train each one of the three neural network architectures (MLP, CNN, and WEC) on data from each one of the three basic voting rules (Plurality, Borda, and Copeland) using four different sampling distributions (IC, Urn, Mallows, and Euclidean). We report the results as relative accuracy and axiom satisfaction, i.e.,\n(relative evaluation) = (rule evaluation) - (model evaluation).\nFor example, if the model has 95% identity accuracy, then, since the rule trivially has 100% accuracy, the relative identity accuracy is 100%-95% = 5% (i.e., the error). If the model has 35% satisfaction of the independence axiom and the rule only 30%, then the relative independence satisfaction is 30% - 35% = -5%."}, {"title": "Results.", "content": "The relative accuracy and axiom satisfaction when sam- pling with the IC distribution are given in Figure 4. The three architectures do not differ much in accuracy. The best accuracy is achieved for the simple Plurality rule, while the complex Copeland rule decreases accuracy. Notably, across all voting rules, architectures, and distributions, we see large violations of neutrality despite high accuracy (e.g., 4.6% identity-accuracy error for the WEC architecture when trained on"}, {"title": "Discussion.", "content": "Regarding the learnability of different voting rules, the simplicity of Plurality is probably the reason behind the high accuracy with which all models learn it. However, this simplicity also renders Plurality problematic in other contexts (Laslier, 2011). The models take a stance on the well-documented tension between anonymity and neutrality. They tend to favor outcomes that align more closely with the former than with the latter. This inclination exposes an inherent bias within neural networks when navigating fundamental democratic axioms. As the architectures are not invariant to permutations of the input data, the severe violations neutrality are not a priori surprising. What is surprising is that this violation persists even for high accuracy with respect to rules that are perfectly neutral and anonymous. Overall, our experiment on accurate versus principled learning within voting contexts highlights precisely the importance of the reasons behind automated decision-making. Outcomes that are mim- icking well-defined voting rules are arguably still unsafe to rely on, since they do not come with a guarantee of respecting the principles on which those rules are built."}, {"title": "6.2. Learning Principles by Example?", "content": "Can we teach neural networks voting-theoretic principles, beyond merely presenting data from various voting rules? A natural ap- proach for integrating expert knowledge in neural networks is data augmentation. In the voting-context, this was proposed by Xia (2013) but has not been tested in practice, to the best of our knowledge. We focus on the neutrality axiom, since it was violated most, and we also test the effects of data augmentation on the model's accuracy."}, {"title": "Design.", "content": "We train each one of the three neural network architectures (MLP, CNN, and WEC) on data from each one of the three basic voting rules (Plurality, Borda, and Copeland); but we vary the ratio p of sampled data and augmented data, while keeping the total number of data points fixed. Thereby, any improvement comes from the quality of the augmented data points and not from merely a higher quantity of data points. Specifically, given a percentage 1 < p < 100, we first sample p many profiles and compute the correspond- ing winning sets according to the considered rule; call these the sampled data points. Then we generate the remaining 100 p many data points as follows: we randomly pick one of the sampled data"}, {"title": "Results.", "content": "Results for IC sampling are exhibited in Figure 5 and for the Mallows model in Figure 8 in the Appendix). We find that data augmentation does not improve adherence to neutrality: the ratio p between sampled and augmented data does not seem to correlate with neutrality satisfaction. For p < 10%, i.e., with al- most only augmented data, both accuracy and neutrality satisfaction are unsatisfactory, so data augmentation only becomes relevant for p\\geq 10%. Here accuracy is stable: it does not vary by more than 5%. In some cases, neutrality is equally stable: for the CNN on all rules and the MLP on Borda (certainly for p \\geq 25%, with slightly worse neutrality satisfaction for smaller p). In the remaining non- stable cases, the best neutrality satisfaction is achieved for p = 100%, i.e., without augmented data with only negligible exceptions. Thus, neither in the stable nor the unstable cases can we see reli- able comparative improvements in neutrality satisfaction with more neutrality-augmented data."}, {"title": "Discussion.", "content": "Learning voting-theoretic principles by examples- augmented to the training data-does not seem to work for neural networks: Comparatively more neutrality-augmented data does not lead to higher neutrality satisfaction. However, an advantage of data augmentation is a drastic increase in data efficiency when we only aim for accuracy. Sampling only 10% of the total data set (and using neutrality augmented data for the remaining 90%) does not substantially decrease the MLP's or WEC's accuracy in comparison to sampling the whole data set. This is crucial if we use real and not sampled election data, where having access"}]}