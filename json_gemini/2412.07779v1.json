{"title": "Evolution of Thought: Diverse and High-Quality Reasoning via Multi-Objective Optimization", "authors": ["Biqing Qi", "Zhouyi Qian", "Yiang Luo", "Junqi Gao", "Dong Li", "Kaiyan Zhang", "Bowen Zhou"], "abstract": "As multi-modal large language models (MLLMs) are increasingly applied to complex reasoning tasks, the diversity and quality of reasoning paths become crucial factors affecting their performance. Although current methods aim to enhance reasoning quality through path expansion, they often neglect the diversity of reasoning paths and effective information sharing, leading to local optima and inefficiency. To address these challenges, we propose Evolution of Thought (EoT), a multi-objective framework designed to improve reasoning by fostering both high-quality and diverse reasoning paths. Specifically, we introduce the Non-dominated Sorting Genetic Algorithm II for multi-objective optimization, utilizing crossover and mutation operators to promote greater diversity in reasoning solutions. Additionally, we propose a Condensation-Aggregation mechanism to cluster and eliminate redundant paths, facilitate improved information sharing among parent nodes, and ultimately enhance both the efficiency and quality of the reasoning process. Validation experiments on various vision-language and language reasoning tasks demonstrate that EoT achieves superior reasoning performance and efficiency compared to other competitive baselines. Our study provides a novel perspective on the design of heuristic reasoning frameworks for MLLMs.", "sections": [{"title": "1. Introduction", "content": "Multi-modal large language models (MLLMs) are widely adopted due to their generalization capabilities and exceptional performance across various tasks [33]. However, MLLMs often face challenges in achieving accuracy and consistency in open-domain question answering, complex mathematical reasoning, and tasks requiring strict logical reasoning [1, 15]. This is primarily due to their reliance on a 'black-box reasoning approach' [12]. Typically, these models generate responses in a single step, directly based on the input, without sufficient control over the reasoning process needed to maintain logical coherence in complex tasks [31]. As a result, the generated answers often suffer from causal ambiguity or internal inconsistencies. In tasks requiring multiple sequential reasoning steps, errors can accumulate, leading to a significant degradation in the quality of the final output. To address this limitation, it is crucial to introduce an explicit reasoning mechanism that enables the model to progress through the reasoning process step by step, thereby improving both accuracy and logical consistency.\nTo address these challenges, Chain of Thoughts (CoT) [31] emerges as a promising solution. By explicitly breaking down the reasoning process into multiple logical steps, CoT not only significantly enhances the model's reasoning capabilities in highly uncertain contexts but also improves its adaptability and generalization to complex tasks through a multi-step reasoning strategy. However, CoT relies on a greedy decoding (top-1) strategy along a single path, selecting only the optimal path at each step, which restricts the diversity of reasoning paths. This design limits the model's ability to explore alternative answer paths in complex tasks, thereby affecting both the quality of solutions and completion reliability.\nTo overcome the single-path limitation of CoT, Tree of Thoughts (ToT) [36] has been proposed. ToT enables the model to explore multiple reasoning paths concurrently using depth- and breadth-first search within a tree structure, increasing the probability of finding the optimal solution. Expanding upon ToT, the Graph of Thoughts (GoT) [2] introduces node aggregation, integrating a graph structure information into the search process to allow the model to leverage prior reasoning steps, thereby enhancing generation quality. However, GoT relies on predefined aggregation operations, making it better suited to well-structured, fixed-state problems (e.g., numerical sorting) and less flexible for complex, dynamic reasoning tasks. Moreover, both ToT and GoT experience rapid search path expansion with increasing task complexity, leading to lower reasoning efficiency. To address the challenge of search efficiency, the Monte Carlo Tree Self-refine (MCTSr) method [38] leverages dynamic pruning strategies to improve reasoning efficiency. Although MCTSr increases both path diversity and search efficiency to some extent, it tends to neglect diversity when optimizing reasoning paths makes it prone to converging to local optima. As paths are expanded, the model's generated paths tend to converge on a few high-scoring paths, restricting the method's overall global exploration.\nIn summary, two major challenges remain in current reasoning path optimization: 1) Convergence to Local Optima. Although ToT and MCTSr improve path diversity, their optimization primarily focuses on generation quality, which often causes paths to converge on high-scoring branches, thereby limiting diversity and the achievement of global optima [39]; 2) Information Sharing and Search Efficiency Limitations. Current methods often lack mechanisms for effectively sharing information from parent nodes, reducing search efficiency. This lack of information reuse from parent nodes hinders search efficiency during tree expansion. Although GoT introduces an aggregation mechanism, it relies on predefined operations, limiting its flexibility and broader applicability.\nTo address these limitations, we introduce the Evolution of Thoughts (EoT) framework for enhancing reasoning. EoT formulates reasoning as a multi-objective optimization (MOO) problem, balancing both answer quality and diversity. To solve this MOO effectively, we introduce the Non-dominated Sorting Genetic Algorithm II (NSGA-II) [5], which utilizes non-dominated sorting to optimize both diversity and quality. By maintaining a diverse set of solutions and preventing convergence to narrow thought patterns, NSGA-II mitigates the tendency of traditional genetic algorithms to become trapped in local optima, thus enhancing the overall optimization process. To prevent redundant paths in NSGA-II's search process, we propose a Condensation-Aggregation (CA) mechanism that clusters paths to reduce redundancy and enhances information sharing for improved reasoning efficiency. The framework operates in three main steps: 1) Quality and diversity assessment. Using MLLMs to score generated answers and construct a quality metric, while defining a novelty metric based on semantic similarity, forming a MOO problem that balances quality and diversity; 2) Multi-objective sorting. Utilizing non-dominated sorting to rank solutions by quality and diversity across different dominance layers, selecting high-quality solutions on the Pareto frontier as the new parent generation; 3) Crossover and mutation. Designing crossover and mutation strategies that aggregate information from parent generations and generate diverse new candidate solutions, enhancing answer diversity.\nFinally, through the CA mechanism, EoT removes redundant information while ensuring answer quality and diversity, thereby enhancing the summarization efficiency and stability of MLLMs. Experimental results show that EoT outperforms existing baselines on various vision-language and language-only reasoning tasks.\nTherefore, our contributions can be outlined as follows:\n\u2022 We extend reasoning path search from a single-objective focus on answer quality to MOO, improving generalization and adaptability by considering both quality and diversity.\n\u2022 Building on MOO, we propose EoT, which uses NSGA-II to optimize both answer quality and diversity, generating diverse candidate solutions while preserving quality.\n\u2022 To reduce redundancy in NSGA-II's optimization, we"}, {"title": "3. The Framework of EoT", "content": "In this section, we introduce the EoT framework, depicted in Figure 2, and describe its core components and workflow in detail. We begin by defining the reasoning enhancement process as a MOO problem, with two primary objectives: answer quality and diversity. Next, we design the evolutionary search process of EoT and define each operation to optimize the search for high-quality and diverse answers. Finally, we introduce the CA mechanism to help the model refine, summarize, and provide reliable responses.\n3.1. Problem Formulation\nLet the user query prompt be denoted as $p_q$, and let the MLLM (or LLM) be represented by $f$. Given an evaluation criterion $M$, where higher values of $M$ correspond to better performance, the objective is to design a search strategy $S$ that optimizes the model's output based on $M$. Specifically, the goal is to maximize $M(S(f, p_q))$.\nProviding excellent solutions often requires creative and practical thinking, where humans have a significant advantage over MLLMs: for a given question, humans can offer high-quality, diverse solutions, while MLLMs often struggle to generate ideas that are both innovative and feasible [10, 11]. To help MLLMs balance answer quality and diversity during the optimization process, we formalize this task as a MOO problem, acknowledging its inherent multi-objective nature:\n$\\underset{A \\in \\mathcal{A}}{\\text{Maximize}} M(A) = [M^Q(A), M^N(A)]^T,$ (1)\nwhere $A = S(f, p_q)$ is the set of answers returned after the search strategy $S$ is executed. $M^Q(A)$ denotes the quality score of an answer, with higher values indicating a greater likelihood of correctness; $M^N(A)$ represents the novelty score of answer $A$, with a higher score signifying greater distinctiveness compared to other answers. By optimizing for both $M(A)$ and $M^N(A)$, the search process can"}, {"title": "3.2. Multi Objective Evolutionary Optimization", "content": "Compared to single-objective optimization, multi-objective optimization (MOO) problems involve a larger and more complex solution space. Directly combining objectives into a single one can obscure important trade-offs and conflicts [40], and determining appropriate weights is challenging. Therefore, an approach that effectively balances multiple independent objectives during optimization is crucial. Evolutionary algorithms, as global heuristic search methods, offer a more effective and comprehensive solution to MOO problems. Among these, NSGA-II is particularly well-suited due to its ability to efficiently handle multiple conflicting objectives while maintaining diversity in the solution set. Inspired by NSGA-II, the widely adopted MOO algorithm in evolutionary computation, we frame the optimization of MLLM reasoning as a genetic evolution process for answers. This approach strikes a balance between answer quality and novelty. The following sections describe each step in detail.\nInitialization. For each input question $p_q$, we first use the MLLM to perform reasoning and generate $N$ initial candidate answers: $A_i = f(p_q), i \\in \\{1, 2, ..., N\\}$, along with a reference answer $A_{ref}$. The candidate answers are then added to the candidate answer set $A$: $A = \\{A_i\\}_{i=1}^N$.\nStep 1: Scoring. For each candidate answer $A_i$ in the candidate answer set $A$, calculate the quality score $M^Q(A_i)$ and the novelty score $M^N(A_i)$. Additionally, since adding new candidate answers affects the novelty scores of previously scored answers, we recalculate and update the novelty scores $M^N(\\bar{A}_i)$ for all previously scored answers $A_i$ in each scoring round.\nStep 2: Ranking & Selection. Since quality and novelty are often conflicting objectives [13], a ranking algorithm is needed that balances both without prioritizing one over the other. To achieve this, we introduce the non-dominated sorting [6], which concentrates high-quality candidates on the Pareto front, balancing the trade-offs between objectives. Specifically, for any two candidate answers $A_i$ and $A_j$, $A_i$ is considered dominated by $A_j$ ($A_i \\prec A_j$) if and only if both $M^N(A_i) \\leq M^N(A_j)$ and $M^Q(A_i) \\leq M^Q(A_j)$ hold simultaneously. Conversely, $A_j$ dominates $A_i$ under the same condition. We calculate the dominance relationships for all pairs of candidates and rank them according to the number of candidates they dominate. Candidates that dominate more others are assigned higher priority levels (i.e., higher non-dominated levels), while those with the same dominance count are placed in the same level. This results in $L$ non-dominated levels, with each level $1 \\leq l \\leq L$ containing a set $A_l$. Within each level, candidates are ranked according to their quality score $M^Q(A)$. Furthermore, we select $K$ parent candidates for the next generation by performing non-dominated sorting from the highest (starting at level 1) to the lowest levels. Within each non-dominated level, candidates are sorted by their quality score $M^Q(A)$. These parent candidates will then be used to generate offspring answers.\nStep 3: Crossover & Mutation. To guide the search process toward high-quality and diverse answers, we introduce crossover and mutation operations to continually optimize the existing candidates in terms of both quality and novelty, while generating offspring candidates. The crossover operation randomly selects two parent candidates $A_i$ and $A_{i'}$ from the chosen parent candidate set $\\{A\\}_l^{K}$, and summarizes them using the MLLM to produce a new high-quality offspring $A_C$ that retains the advantages of both: $A_C = f(p_q, p_C, A_i, A_{i'})$, where $p_C$ is the crossover prompt. In the mutation operation, one parent candidate $A_i$ is randomly selected, and the MLLM generates a novel offspring $A_M$ that is distinct from it, ensuring higher novelty: $A_M = f(p_q, p_M, A_i)$, where $p_M$ is the mutation prompt. By combining the designed crossover and mutation operations, we generate $N_C$ crossover offspring $\\{A_C\\}_{r=1}^{N_C}$ to search for high-quality answers, and simultaneously generate $N_M$ mutation offspring $\\{A_M\\}_{m=1}^{N_M}$ from $K$ parents to search for answers with high novelty, maintaining the ratio $\\frac{N_C}{N_M}= r$, ($N_C + N_M = N$). Subsequently, we integrate the new offspring into the existing set of candidate answers: $A = A \\cup \\{A_C\\}_{r=1}^{N_C} \\cup \\{A_M\\}_{m=1}^{N_M}$ to update the candidate set and expand the number of offspring to $N_x = 2$. Throughout the optimization process, we conduct $T$ generations based on Steps 1-3 to obtain the final set of candidate answers. Since the offspring generation process is independent of any specific optimization path, it is fully parallelizable, thereby enhancing search efficiency compared to tree search algorithms. The pseudocode for the three steps of the EoT reasoning enhancement framework is presented in Appendix 1."}, {"title": "3.3. Condensation & Aggregation Mechanism", "content": "In practical MLLM-based question-answering systems, users typically expect a single, definitive answer. Simply returning a response based on the candidate set $A$ obtained through the MOO process, such as the Pass@k setting, is often insufficient to meet user needs. Therefore, it is necessary to enable the MLLM to summarize a precise answer from $A$. However, directly summarizing the entire set of candidates could lead to excessively long contexts, thereby constraining reasoning efficiency and accuracy, and potentially introducing low-quality answers that cause interference. Therefore, directly summarizing all candidate answers with the MLLM does not support accurate information aggregation. We propose the CA mechanism, which consists of two stages: condensation and aggregation. Specifically, in the condensation stage, we measure the distance $D$ between different candidate answers $A$ and $A'$ in $A$, based on their edit distance $D^{Ed}(A, A')$ and semantic distance $D^{SE}(A, A') = \\frac{(E(A), E(A'))}{2||E(A)||||E(A')||}$ (the scaling here is also for standardizing the magnitudes of $D^{Ed}$ and $D^{SE}$). The overall distance is computed as $D(A, A') = \\frac{D^{Ed}(A,A')}{\\text{max}_{A,A'} D^{Ed}} + D^{SE}(A, A')$, yielding the distance matrix $D(A, A) \\in \\mathbb{R}^{N \\times N}$, where $D(A, A)_{i,j} = D(A_i, A_j)$.\nNext, we apply K-Medoids clustering [20] on $D(A, A)$ to form $\\mathbb{K}$ clusters $\\{C_j\\}_{j=1}^{\\mathbb{K}}$, with the center of each cluster defined as the answer $A_{c_j} = \\underset{A_c \\in C_j}{\\text{arg min}} \\sum_{A'\\in C_j} D(A_c, A')$, which minimizes the average distance to all other answers in the cluster. We then compute the average quality score for each cluster: $M^Q(C_j) = \\sum_{A\\in C_j} M^Q(A)$, and sort the clusters in descending order based on $M^Q(C_j)$. To eliminate the influence of low-quality answers, we remove the $m$ clusters with the lowest average quality scores. From the remaining $\\mathbb{K}-m$ clusters, we select the center answer from each one to form the condensed candidate set $\\{A_{c_j}\\}_{j=1}^{\\mathbb{K}-m}$, which helps the MLLM more efficiently extract precise information from a large number of candidates. Finally, we pass the condensed candidate set to the MLLM for aggregation, resulting in a clear, accurate answer $A^* = f(p_q, p_A, \\{A_{c_j}\\}_{j=1}^{\\mathbb{K}-m})$, where $p_A$ is the aggregation prompt.\nIn summary, EoT serves as a versatile and efficient reasoning enhancement framework that balances answer quality and diversity during the search process, while effectively generating accurate final answers through the CA mechanism as required."}, {"title": "4. Experiments", "content": "Models and Datasets. To evaluate the effectiveness of our approach, we employ three based models: Qwen2VL [29], Llava [16], and Phi-3.5 [19]. These three models are all common multimodal models. For benchmarking, we use test sets from MathVista [17], Math-Vision [28], and GSM8K [4], where MathVista and Math-Vision are multi-modal datasets and GSM8K is a text-only dataset. To evaluate answer accuracy, we instruct the models to respond in the format \"The Answer is \\boxed{\\{}\\}\" and then extract the final answers for comparison against ground truth labels. An answer is considered correct if it matches the ground truth exactly. All experiments were conducted on a single Nvidia A100 80GB GPU.\nBaselines.\nWe compare EoT with several existing methods, including closed-source models such as Gemini [26] and GPT-4V [34], as well as open methods like IO, CoT [31], Self-Refine [18], MCTSr [38], SPP [30], MAD [14], and ToT [36]. For the IO baseline, we use a standard zero-shot input-output prompt. In CoT, we apply prompting formats such as \"[Reasoning process]... [Verification]\" and \"Let's think step by step\" to encourage the model to generate reasoning steps. Self-Refine is implemented with one refinement iteration, while MCTSr uses four expansion steps. SPP is implemented using the standard prompt defined in [30]. For MAD, we set the number of agents to 3 and conduct two rounds of discussion. ToT utilize a greedy search strategy with two rounds of exploration, sampling five answers per round and selecting the best answer via voting for further reasoning. Detailed prompts for EoT can be found in the Appendix C."}, {"title": "4.1. Evaluation of Diversity", "content": "The Pass@K metric is an evaluation metric used to measure the accuracy of MLLM in generating answers, specifically focusing on whether the correct answer appears within the top K generated answers. More precisely, Pass@K is defined as the probability that the correct answer is among the top K answers generated by the model. It can be calculated as Pass@k:= $\\frac{1}{N} \\sum_{i=1}^N \\mathbb{I}(G \\in A_k)$, where N is the total number of test cases, $A_k:= \\{A_i\\}_{i=1}^k$ denotes the set of candidate answers, and $\\mathbb{I}$ is the indicator function. This metric provides a comprehensive evaluation of the model's performance for a given K value. To compare the performance of different models based on the Pass@K metric, we conduct a comparative analysis of methods that generate answer lists during the answering process, such as EoT, MCTSr, and ToT. For MCTSr, the answer list is generated by the model during the exploration process and sorted by answer scores from high to low. For ToT, the answer list is sorted by rounds in reverse order, with answers within the same round sorted by vote count from high to low. For EoT, the answer list is sorted based on non-dominated sorting. Based on the experimental results, under the Pass@k evaluation metric, applying EoT to the three models achieved superior performance on the MathVista, Math-Vision, and GSM8K datasets compared to ToT and MCTSr. This demonstrates that EoT not only maintains answer diversity but also improves accuracy in generating correct answers. These results highlight that EoT, while preserving diversity, delivers higher-quality answer generation than alternative methods."}, {"title": "4.2. Evaluation of Quality", "content": "To assess the impact of introducing the diversity metric $M^N(A)$ on answer quality during the reasoning path search, we evaluate EoT using Pass@1 on the MathVista,"}, {"title": "4.3. Evaluation of Efficiency", "content": "Additionally, to demonstrate the efficiency of the EoT method, we compare EoT with ToT and MCTSr in terms of the number of reasoning steps required to generate K answers, as well as the average time taken to generate each answer when producing 12 answers. From the results, it can be observed that, under the condition of generating the same number of K answers, EoT requires fewer reasoning steps and less time per step. This indicates that the EoT method achieves higher reasoning efficiency and lower overhead compared to other methods."}, {"title": "4.4. Ablation Studies", "content": "To better demonstrate the excellent properties of EoT, we design four sets of ablation experiments. Through these experiments, we aim to answer three key questions.\nQ1: Does the advantage of EoT rely on a large population size and more evolutionary generations? To address this question, we evaluate the model's pass@4 metric under different candidate answers N and the number of generations T, specifically with N = 3,6,9 and T = 1,2,3. From the experimental results, we observe that EoT exhibits highly consistent pass@4 inference performance across different values of N and T, with the maximum performance fluctuation being just 5.13%. This indicates that the outstanding performance of EoT does not depend on generating a large number of mutated offspring, meaning that EoT can robustly enhance the model's inference capability without significantly increasing computational resource consumption.\nQ2: How do the number of candidate parent nodes and the crossover/mutation ratio impact model inference? We set the crossover-to-mutation ratios to 1:1, 1:2, 1:5, 5:1, and 2:1; and selected candidate parents $K$ = 3,4,5,6 from non-dominated sorted set $A_l$. From the results, we observe that on the simpler Math-Vista and GSM8K datasets, the pass@k curves exhibit high consistency across different settings. On the more challenging Math-Vision dataset, the configuration with r = 1:5 and K = 3 demonstrates the best performance. This suggests that, in complex reasoning scenarios, a more diverse offspring population and high-quality parents can significantly enhance the model's reasoning performance.\nQ3: How does the CA mechanism impact the model's performance when generating diverse answers? To address this question, we divide the generated answers into 3, 4, 5, and 6 clusters, and drop the 1, 2, and 3 clusters with the poorest quality answers. We then compare how the model's average performance changes across three datasets as the number of clusters increases, reflecting the increase in answer diversity. From this, we can observe that as the diversity of generated answers increases, the CA mechanism can effectively help improve model performance. However, when the number of clusters is K < 4, the CA mechanism does not help performance improvements. This may be because the quality of the generated answers is already high, and drop certain answers limits the model's potential."}, {"title": "5. Conclusion", "content": "In this work, we propose the EOT framework, which formulates the search for reasoning paths as a MOO problem, balancing both quality and diversity. EOT overcomes the limitations of local optima in traditional methods by employing non-dominated sorting to explore candidate solutions along the Pareto front, achieving a balanced improvement in both quality and diversity. By utilizing specially designed crossover and mutation operations, EOT enables offspring solutions to inherit strengths from diverse parent solutions, consistently producing diverse reasoning results. EOT further incorporates an efficient CA mechanism that streamlines candidate answers based on semantic similarity, preserving both diversity and quality to enable accurate and efficient answer summarization for MLLMs. We believe this work provides a valuable new perspective for designing advanced reasoning frameworks based on heuristic methods."}]}