{"title": "A data-driven learned discretization approach in finite volume schemes for hyperbolic conservation laws and varying boundary conditions", "authors": ["G. de Rom\u00e8mont", "F. Renaca", "J. Nunez", "D. Gueyffier", "F. Chinesta"], "abstract": "This paper presents a data-driven finite volume method for solving 1D and 2D hyperbolic partial differential equations. This work builds upon the prior research [Bar-Sinai et al., 2019; Zhuang et al., 2021; Kochkov et al., 2021] incorporating a data-driven finite-difference approximation of smooth solutions of scalar conservation laws, where optimal coefficients of neural networks approximating space derivatives are learned based on accurate, but cumbersome solutions to these equations. We extend this approach to flux-limited finite volume schemes for hyperbolic scalar and systems of conservation laws. We also train the discretization to efficiently capture discontinuous solutions with shock and contact waves, as well as to the application of boundary conditions. The learning procedure of the data-driven model is extended through the definition of a new loss, paddings and adequate database. These new ingredients guarantee computational stability, preserve the accuracy of fine-grid solutions, and enhance overall performance. Numerical experiments using test cases from the literature in both one- and two-dimensional spaces demonstrate that the learned model accurately reproduces fine-grid results on very coarse meshes.", "sections": [{"title": "1. Introduction", "content": "Numerical fluid mechanics typically deals with nonlinear hyperbolic partial differential equations (PDEs) to represent complex fluid phenomena of various types. Regardless of the smoothness of initial or boundary data, discontinuities may develop after a finite time [Toro and Billett, 2000, Sec. 2.4.2]. Therefore, appropriate numerical methods must be designed for these scenarios, particularly for approximating discontinuous solutions. The simulation of complex physical systems is fundamental, in practice, the sheer scale of these simulations-whether in terms of spatial resolution, temporal accuracy, or the complexity of the underlying physical processes-means that simulating systems at realistic levels is not feasible due to the computational time required for a given simulation.\nThe numerical integration of fluid equations on a coarse grid relative to a fully resolved integration of a given problem is a field of active research. Practically, coarse graining facilitates the computation of significantly larger systems. In this context, a number of works assessed the use of Neural Networks (NN) to solve PDEs using different methodologies have been developed. One enables neural ansatz to simultaneously align with target data while reducing a PDE residual [Lagaris et al., 1998; Raissi and Karniadakis, 2018; Raissi et al., 2019; Sun et al., 2020]. Other methodologies such as operator learning [Tran et al., 2021; Hao et al., 2023; Li et al., 2020], or purely learned surrogates [Pfaff et al., 2020; Ronneberger et al., 2015; Dolz et al., 2018; Sanchez-Gonzalez et al., 2020] have found application across a wide range of applied mathematics problems.\nIn practice, a significant advancement has been the capacity to precisely satisfy certain physical or numerical constraints by incorporating learned models into a fixed equation of motion. To this end and for forward problems, a number of hybrid physics-ML methods have emerged to train Neural Networks in the frame of existing numerical methods. This has been applied to a variety of topics such as turbulence [List et al., 2022; Stachenfeld et al., 2021; Kochkov et al., 2021], with learned artificial viscosity [Schwander et al., 2021] or the use of constrained PINNs [Patel et al., 2022; Coutinho et al., 2023; Yu et al., 2018; Kharazmi et al., 2019].\nRecent studies have employed machine learning (ML) techniques to enhance the resolution of shocks in hyperbolic PDEs, these problems are particularly challenging due to the potential for instabilities to occur. This has been achieved by utilizing the finite-volume method and several enhanced approaches have been proposed, among which popular ones are optimised shock-capturing schemes [Stevens and Colonius, 2020a; Kossaczk\u00e1 et al., 2021], learning flux-limiters [Nguyen-Fotiadis et al., 2022; Schwarz et al., 2023], learning corrections [Discacciati et al., 2020] or coupling finite-volume with PINNs methodology [Ranade et al., 2021; Cen and Zou, 2024]. Other ideas within the finite-volume framework have been explored, with LSTM model [Stevens and Colonius, 2020b] or for variational finite volume scheme [Zhou et al., 2024]. Other methods have also been developed on unstructured grids [Jessica et al., 2023; Li et al., 2023].\nWith the same objective in mind, Bar-Sinai et al. [2019] proposed a learned interpolation of the gradient that achieves the same accuracy as traditional finite difference methods but with"}, {"title": "2. Model problem", "content": "We are here interested in the approximation of first-order nonlinear hyperbolic conservation laws and consider initial and boundary value problems in d \u2265 1 space dimensions of the form\n$\\begin{aligned}\n  &\\partial_t w + \\nabla \\cdot f(w) = 0 \\text{ in } \\Omega \\times (0, \\infty),  \\tag{1a}\\\\\n  & w(x, 0) = w_0(x) \\text{ in } \\Omega, \\tag{1b} \\\\\n  & B(w, w_{bc}, n) = 0 \\text{ on } \\partial\\Omega \\times (0, \\infty), \\tag{1c}\n\\end{aligned}$\nwith $ \\Omega \\subset \\mathbb{R}^d $ a bounded domain, $ w : \\Omega \\times [0, T] \\to \\mathbb{Q} \\subset \\mathbb{R}^r $ denotes the vector of r conservative variables with initial data $ w_0 \\in L^{\\infty}(\\Omega) $ and $ f : \\mathbb{Q} \\to \\mathbb{R}^r \\times \\mathbb{R}^d $ are the physical fluxes. The solution is known to lie within a convex set of admissible states $ \\mathbb{Q} $. Boundary conditions are imposed on $ \\partial\\Omega $ through the boundary operator in (1c) and some prescribed boundary data $ w_{bc} $ defined on $ \\partial\\Omega $, while n denotes the unit outward normal vector to $ \\partial\\Omega $. The operator B depends on the type on condition to be imposed and the equations under consideration. Examples are provided in section 2.3.\nSolutions to (1) may develop discontinuities in finite time even if $ w_0 $ is smooth, therefore the equations have to be understood in the sense of distributions. Weak solutions are not necessarily unique and (1) must be supplemented with further admissibility conditions to select the physical solution. We here focus on entropy inequalities of the form [Godlewski and Raviart, 2013, sec. I.5][Dafermos, 2005, sec. III][LeVeque, 1992, sec. III.8]\n$\\partial_t \\eta(w) + \\nabla \\cdot q(w) \\leq 0, \\tag{2}$\nwhere $ \\eta : \\mathbb{Q} \\to \\mathbb{R} $ is a convex entropy function and $ q(w) : \\mathbb{Q} \\to \\mathbb{R}^d $ is the entropy flux satisfying the compatibility condition\n$\\nabla_w \\eta(w)^T \\times \\nabla_w f_i(w) = \\nabla_w q_i(w), \\quad 1 \\leq i \\leq d. \\tag{3}$\nThe inequality (2) becomes an equality for smooth solutions, while strict convexity of $ \\eta(w) $ implies hyperbolicity of (1a) [Godlewski and Raviart, 2013; Dafermos, 2005].\nWe here aim at satisfying these properties at the discrete level with our data-driven finite volume scheme."}, {"title": "2.1. Nonlinear hyperbolic conservation laws", "content": null}, {"title": "2.2. Model examples", "content": "We will first investigate the linear stability properties of the data-driven scheme with a von Neumann analysis. To this end, we consider the linear scalar advection equation in one space dimension:\n$\\partial_t w + a \\partial_x w = 0, \\tag{4}$\nwith a > 0 the transport velocity which is assumed to be constant."}, {"title": "2.2.1. Scalar equations", "content": null}, {"title": "2.2.2. Compressible Euler equations", "content": "We will consider numerical experiments with the nonlinear scalar Burgers' equation in one space dimension:\n$\\partial_t w + \\partial_x \\Big(\\frac{w^2}{2}\\Big) = 0, \\tag{5}$\nfor which the physical weak solutions satisfy the entropy inequality (2) for the entropy pair $ \\eta(w) = \\frac{w^2}{2} $ and $ q(w) = \\frac{w^3}{6} $, together with a maximum principle on w which may define $ \\mathbb{Q} = [\\min_\\Omega w_0, \\max_\\Omega w_0] $. Solutions to scalar equations are known to be of bounded total variation [Godlewski and Raviart, 2013; Dafermos, 2005].\nWe will also consider numerical experiments with the compressible Euler equations in one, d = 1, and two space dimensions, d = 2, for which\n$\\begin{aligned}\nw &= (\\rho, \\rho v^T, E)^T,\\\\\nf(w) &= (\\rho v, \\rho vv^T + pI_d, (E + p)v)^T,\n\\end{aligned}$\nwhere $I_d$ is the identity matrix of size d, while $ \\rho, v $ and E denote the density, velocity vector and total energy, respectively. We close the system with an equation of state for a polytropic ideal gas law, so $ E = \\frac{p}{\\gamma -1} + \\frac{\\rho}{2} ||v||^2 $ with $ \\gamma > 1 $ the ratio of specific heats and p the pressure. Note that it will be convenient to consider the numerical discretization as a function of the primitive variables\n$ u = (\\rho, v^T, p)^T $.\nNote that for scalar equations, u = w.\nThis system is hyperbolic in every unit direction n over the set of admissible states $ \\mathbb{Q} = \\{ w \\in \\mathbb{R}^{d+2} : \\rho > 0, v \\in \\mathbb{R}^d, E - \\frac{p}{(\\gamma-1)} + \\frac{\\rho}{2} ||v||^2  > 0 \\} $ with eigenvalues $v \\cdot n - c, v \\cdot n, v \\cdot n + c$, where $ c = (\\frac{\\gamma p}{\\rho})^{1/2} $ is the speed of sound. An entropy pair is given by\n$\\begin{aligned}\n& \\eta = - \\rho s, \\quad q(w) = - \\rho sv, \\tag{6}\n\\end{aligned}$\nwhere $ s = C_v \\log(\\frac{p}{\\rho^\\gamma}) $ is the physical specific entropy defined by the Gibbs relation."}, {"title": "2.3. Boundary conditions", "content": "To a given boundary $ \\Gamma \\subset \\Omega $ in (1c), we associate an admissible boundary state\n$ w_{\\Gamma} : \\mathbb{Q} \\times S^{d-1} \\ni (w, n) \\to w_{\\Gamma}(w, n) \\in \\mathbb{Q}, \\tag{7}$\nwhich we assume to be admissible, $ w_{\\Gamma} (\\mathbb{Q} \\times S^{d-1} ) \\subset \\mathbb{Q} $, and consistent: B(w, wbc, n) = 0 implies $ w_{\\Gamma}(w, n) = w $.\nBoundary operators. Several boundary conditions have been implemented. The treatment of boundary conditions is a critical aspect in every CFD solver, as the way boundaries are handled can significantly influence the overall accuracy and stability of the solution, which is essential for capturing the true behavior of the system\nIn the above scenario, location a is outside the domain and corresponds to a ghost cell, $ \\Gamma $ is the boundary interface, and location d is inside the physical domain. The unit normal vector n = [$ n_x, n_y $] points outwards of the domain.\nThe flux Jacobian $ A(w, n) = \\partial_w f(w) \\cdot n $ has eigenvalues $ (\\lambda_i)_{1 \\leq i \\leq r} $ and is diagonalized as $ A(w, n) = R^{-1} A R $ with $ \\Lambda = diag(\\lambda) $. Depending on the sign of the eigenvalues, we introduce the upwind decomposition of $ A(w, n) $ as follows\n$A(w, n) = A^+(w, n) + A^-(w, n),$\nwith\n$\\begin{aligned}\nA^{\\pm}(w, n) = R^{-1} \\Lambda^{\\pm} R, \\quad \\Lambda^{\\pm} = \\frac{1}{2} diag(\\lambda_i \\pm |\\lambda_i|).\n\\end{aligned}$\nEach eigenvalue is associated to a given characteristics. The characteristics are used to determine the number of boundary conditions to be imposed [Goncalv\u00e8s da Silva, 2008; Hartmann and Houston, 2002], which correspond to the inflow characteristics that propagate from outside to inside the computational domain.\nCompressible Euler equations. The flux Jacobian $ A(w, n) = \\partial_w f(w) \\cdot n $ has eigenvalues\n$ \\lambda_1 = v \\cdot n - c, \\lambda_2 = \\cdots = \\lambda_{d+1} = v \\cdot n, \\lambda_{d+2} = v \\cdot n + c $.\nFarfield conditions. We can apply characteristic boundary conditions on the farfield boundary from a freestream state $ w_\\infty $ with\n$B(w, w_{bc}, n) = A^-(w - w_\\infty), \\tag{8}$\nwhere $ w_\\infty $ denotes a given freestream state. For instance, for a supersonic inflow boundary condition, we have A\u00af = A, corresponding to the Dirichlet boundary conditions\n$w_{\\Gamma} (w, n) = w_{\\infty}, \\tag{9}$\nwhile for the supersonic outflow boundary condition, we have $A^+ = A $ and $ A^- = 0 $, corresponding to an extrapolation condition\n$ w_{\\Gamma}(w, n) = w. \\tag{10}$\nSlip boundary condition. Considering an impermeability condition, $v \\cdot n = 0 $, at a wall $ \\Gamma \\subset \\partial\\Gamma $, the associated boundary data is $ w_{\\Gamma}(w, n) = (\\rho, \\rho(v - (v \\cdot n)n), \\rho E) $. The condition is commonly imposed through the use of a mirror state $ 2 w_{\\Gamma}(w, n) - w = (\\rho, \\rho (v - 2(v \\cdot n)n), pE) $. The mirror state $ w^\\ddagger (w, n) $ follows from imposing a linear reconstruction interpolating the right and left states at the interface : $ \\frac{1}{2}(w^- + w^\\ddagger(w^-, n)) = w^-(w^-, n) $ hence $ w^\\ddagger(w^-, n)) = 2 w^-(w, n) - w^- $\nPeriodic condition. This boundary is established when physical geometry of interest and expected flow pattern are of a periodically repeating nature. This reduces computational effort in our problems."}, {"title": "3. Finite volume solver", "content": "We describe below the finite volume solver used to generate the data. We use a MUSCL reconstruction of the slopes [Van Leer, 1979] on 1D and 2D Cartesian meshes to get a formally second-order scheme. In section 3.1, we introduce the scheme in 1D for the sake of clarity, while the treatment of boundary conditions is described in section 3.2."}, {"title": "3.1. Finite volume solver and reference solution", "content": "The domain is partitioned with a uniform and Cartesian mesh with cells $ I_i = [x_{i-\\frac{1}{2}}, x_{i+\\frac{1}{2}}] $ of size $ \\Delta x $; in 1D and we look for an approximate solution to problem (1) of the form of a piecewise constant solution where the degrees of freedom approximate the cell-averaged solutions in each cell:\n$W_i(t) = \\frac{1}{\\Delta x_i} \\int_{I_i} w(x, t) dV.$\nIntegrating (1a) over a fixed volume V and using the divergence theorem over the surface $ \\partial V $ gives\n$ \\frac{\\partial}{\\partial t} \\int_V w(t) dV + \\oint_{\\partial V} f(w) \\cdot n dS = 0. \\tag{11}$\nThe discrete scheme in cell $I_i$ with an explicit Euler time integration approximates this conservation law as follows:\n$\\frac{w_i^{n+1} - w_i^n}{\\Delta t_n} + \\frac{1}{\\Delta x_i} ( f_{i+\\frac{1}{2}}^{n+1/2} - f_{i-\\frac{1}{2}}^{n+1/2} ) = 0 \\tag{12}$\nwhere $ w^n = w_i(t^n) $ and $ f_{i+\\frac{1}{2}}^{n+1/2} = f(w_{i+\\frac{1}{2}}^{n, L}, w_{i+\\frac{1}{2}}^{n, R}) $ with $ t^{n+1} - t^n = \\Delta t_n > 0 $ the time step, while f(\u00b7,\u00b7) denotes a two-point numerical flux that is assumed to be consistent $ f(w, w) = f(w) $. By $w_{i+\\frac{1}{2}}^{n, L} $ we denote approximate values of the reconstructed left and right traces at interface $ x_{i+\\frac{1}{2}} $ (see Figure 1).\nAs a reference solver, we use a second-order MUSCL [Van Leer, 1979] finite volume scheme with a Rusanov numerical flux [Lax, 2005; Rusanov, 1961] and a van Albada limiter [van Albada et al., 1982] which is used because it is a smooth differentiable function as opposed for example to the minmod slope limiter [Roe, 1986]. The flux can be written\n$f(w^*, w^+) = \\frac{1}{2} (f(w^-) + f(w^+) - \\rho(w^-, w^+) (w^+ - w^-))$"}, {"title": "3.2. Boundary conditions", "content": "as the van Albada limiter, the second-order MUSCL reconstruction is defined on the primitive variables u as\n$\\begin{aligned}\nu_{i+1/2} &= u_i + \\Phi_i(u_{i+1} - u_i), \\\\\n\\upsilon_{i+1/2} &= u_{i+1} - \\Phi_{i+1}(u_{i+2} - u_{i+1}), \\\\\n\\Phi_i &= \\Phi(\\frac{u_i - u_{i-1}}{u_{i+1} - u_i}) \\tag{13}\n\\end{aligned}$\nfor every component u in u. The reference solution is computed at a sufficiently high resolution, then down-sampled keeping only every R-th sample to produce the test and training datasets.\nThe rational for using a first order time integration is as follows. Tests have been performed with a second order time discretization scheme using the Heun Runge-Kutta method but no improvement was observed in the produced reference solutions. It also increased the training time.\nThe implementation of far-field boundary conditions for a flow problem is contingent upon two prerequisites. Primarily, the truncation of the domain must not have a discernible impact on the flow solution when compared to that of an infinite domain. Secondly, any outgoing disturbances must not be reflected back into the flow field. Frequently, the far-field values are not known; only the freestream values are typically available.\nIn order to achieve this, the computational domain is modified by the introduction of so-called \"ghost cells\" situated outside of the boundary. The introduction of fictitious flow in the ghost cells will yield the desired boundary conditions at the edge.\nSupersonic inflow. The conservative variables on the boundary are determined exclusively on the basis of freestream values.\n$ w_{\\Gamma} = w_{-1} $\nSupersonic outflow. The conservative variables on the boundary are determined exclusively on the basis of inner flow field values.\n$ w_{\\Gamma} = w_{1} $\nSubsonic inflow. Four characteristic variables are prescribed based on the freestream values, which are defined as follows: One characteristic variable is derived from the interior of the"}, {"title": "4. Data driven solution for hyperbolic equations", "content": "physical domain. This results in the following set of boundary conditions:\n$\\begin{aligned}\n& p_{\\Gamma} = \\frac{1}{2}[p_{-1} + p_{1} - \\rho_0 c_0 [ (v_{-1} - v_{1}) \\cdot n ]]\n& v_{\\Gamma} = v_{-1} - \\frac{n (p_{-1} - p_{\\Gamma})}{\\rho_0 c_0}\n& p_{\\Gamma} = p_{-1} - \\frac{n(p_{-1} - p_{\\Gamma})}{\\rho_0 c_0}\n\\end{aligned}$\nwhere $p_0$ and $c_0$ represent a reference state. The reference state is normally set equal to the state at the interior.\nSubsonic outflow.\n$\\begin{aligned}\n& p_{\\Gamma} = p_{-1}\n& v_{\\Gamma} = v_{1} + \\frac{n(p_{1} - p_{\\Gamma})}{\\rho_0 c_0}\n& p_{\\Gamma} = p_{1} + \\frac{(p_{\\Gamma} - p_{1})}{c_0}\n\\end{aligned}$\nwith $p_{-1}$ being the prescribed static pressure.\nNo-slip boundary. The implementation of the no-slip boundary condition can be simplified through the incorporation of ghost cells.\n$\\begin{aligned}\n& \\rho_{-1} = \\rho_1\n& p_{-1} = p_1\n& v_{-1} = v_{1} - 2(v_1 \\cdot n)n\n\\end{aligned}$\nPeriodic condition. Due to the periodicity condition, the first ghost-cell layer $ w_{-1} $ corresponds to the inner flow field value at the opposite periodic boundary."}, {"title": "4.1. Learning the derivatives", "content": "One of our main goal is to improve accuracy without compromising generalization on a standard second-order finite volume solver as described in section 3.1. To that extent, we consider a ML modeling to approach the derivatives. We expect that ML models can improve the accuracy of a CFD solver when run on inexpensive-to-simulate coarse grids even in cases where the solutions exhibit shocks, discontinuities, or large gradients. By using a limiter and a MUSCL scheme, our solution is naturally limited to remove spurious oscillations [Harten, 1997] that would otherwise occur around discontinuities. This ensures the robustness of the solution.\nWe assume a Cartesian grid in d space dimensions. The accuracy of finite volume schemes relies on local high-order reconstructions of the solution, which are based on the evaluation of the space derivatives of the solution from its values in neighboring elements using finite differences. For a field w(x, t), the $i^{th}$ space derivateive can be approximated by\n$\\frac{\\partial w}{\\partial x_i}(x, t) \\approx \\sum_{j=-k}^k a_j w(x_1, x_2,..., x_i + jh,..., x, t), \\tag{14}$\nwhere $x_1, ..., x_N$ are the spatial coordinates and h the size of the element which is here assumed constant. As an example, a first order approximation of the derivative on a field w in 1D gives $ \\partial_x w = \\frac{w_{i+1}-w_i}{\\Delta x} + O(\\Delta x) $ with $a_1 = \\frac{1}{\\Delta x} $, $a_0 = -\\frac{1}{\\Delta x} $ and $a_{-1} = 0$.\nIn this work, we follow the idea of Bar-Sinai et al. [2019] and Zhuang et al. [2021] and extend it to finite volume schemes for hyperbolic conservation laws. The algorithm works as follows, at each time step, the neural networks generates a latent vector $a = (a_{-k}, ..., a_k)$ at each cell location for each variable based on the current primitive variables u of the PDE. The latent vectors are then used to reconstruct the space gradient of the primitives variables $ \\nabla u $ using a convolution as in equation (14). All derivatives in equation (13) are then replaced by their respective reconstructions $ \\widehat{\\partial_x u_i} $; to predict the next time step. The new MUSCL scheme reads\n$\\begin{aligned}\nu_{i+1/2} &= u_i + \\Phi_i \\widehat{\\partial x u_i}, \\\\\n\\upsilon_{i+1/2} &= u_{i+1} - \\Phi_{i+1} \\widehat{\\partial_x u_{i+1}}, \\\\\n\\Phi_i &= \\Phi(\\frac{ \\widehat{\\partial u_{i}} } {\\widehat{\\partial u_{i+1}} }) \\tag{15}\n\\end{aligned}$\nBecause the derivative operator $ \\partial_x $ applied on a function f at a point $ x \\in \\Omega $ is local, independent of the size of the mesh and invariant by translation; the neural network used for learning the operator $ \\partial_x \\cdot $ also needs to verify these properties. The convolution operator satisfies the same properties as the derivative thus convolutionnal Neural Networks (CNNs) are used for the model.\nThe training of a neural network inside a classic numerical solver is made possible by writing the entire program in a differentiable programming framework. Indeed the computation of the gradients of the loss is made possible using a differentiable CFD solver. This differentiable framework allows Automatic Differentiation [Baydin et al., 2018] for any parameter of the solver. Multiple frameworks have been recently developed like TensorFlow [Abadi et al., 2016], Pytorch [Paszke et al., 2017], Flux.jl [Innes, 2018], JAX [Bradbury et al., 2018] and are more and more efficient on hardware accelerator (GPUs, TPUs). These user-friendly frameworks make it easier to incorporate neural networks techniques into scientific codes. We have implemented our solver using TensorFlow Eager [Agrawal et al., 2019]."}, {"title": "4.2. Learned interpolation model", "content": "The learned interpolation model is introduced in Bar-Sinai et al. [2019] and extended in [Zhuang et al., 2021; Kochkov et al., 2021; Alieva et al., 2023]. It is a data-driven method which uses the outputs of the neural network to generate interpolation based on local variables or features of the PDE.\nAs shown on Figure 3, the model is composed of several convolutionnal and padding layers stacked together so that the output shape matches the input shape. The discrete convolution operator reduces the dimension of any input vector. Consequently, the output solution vector size is equal to the input solution vector size, as required by the padding layers. Paddings are adapted to the type of boundary condition during training and inference stages. The normalization layer outputs all variables"}, {"title": "4.3. Padding", "content": "to [-1, 1] with a min-max normalization. The linear constraint reads $ \\sum_j a_j = 0 $. It is similar to the ones introduced by Bar-Sinai et al. [2019] and Zhuang et al. [2021] and enforces the derivative to be at least first-order accurate. (see next section below).\nAn essential feature of our model lies in how we handle the boundaries. It is imperative to guarantee that the model remains invariant by translation in space. Consequently, the convolutional layers illustrated in Figure 3 cannot be truncated in the direction normal to the boundary. In contrast, the flow variables are extended beyond the boundary via the use of a padding to set ghost cells. The extension method must ensure the preservation of the boundary condition on the coarse grid.\nThe boundary condition is also applied as a padding for the periodic, inflow, or outflow boundary condition; however, it must be adapted for the slip boundary condition.\nFor the slip boundary condition, a first guess would be to mirror the flow across the wall, although this would result in the creation of an artificial discontinuity (see section 3.2) at the boundary. In order to guarantee the stability of the algorithm, the ML contribution of the learned discretization is set to zero at the interface for slip boundary conditions. This guarantees that the boundary condition is clearly defined and that the ML scheme is stabilized globally."}, {"title": "4.4. Loss", "content": "The training time tunes the ML parameters so that the weights and biases reduce the difference between a costly high-resolution simulation and a simulation generated by the model on a coarse grid. This refinement is achieved through supervised training where we use as the loss function $ L_{tot} $ the cumulative pointwise error between predicted and reference primitive"}, {"title": "5. von Neumann stability analysis", "content": "variables. Because the numerical scheme is an inherently stable flux-limited second order scheme, it is unnecessary to accumulate the error over multiple steps for further stabilization.\n$L_{tot} = (||u_{ref} - \\hat{u}||_1 + \\lambda_2 ||u_{ref} - \\hat{u}||_2) + L_{penalization}, \\tag{16}$\nwhere $ \\hat{u} $ is the machine learning solution, while $ u_{ref} $ denotes the reference solution obtained on fine grids using the finite volume scheme. We have found that using a mix of the $ L_1 $ and $ L_2 $ (with a mean reduction operator) norms added with a penalization described later stabilizes efficiently the solution over time. Here the reference solution is a solution computed on a fine grid and projected on a coarser grid, the neural network solution is computed on the coarser grid. During training, the ratio $ R = \\frac{\\Delta x_{coarse}}{\\Delta x_{fine}} $ is 2 for stability reasons, but during inference, the ratio can be changed and increased.\nEven if the method implemented without penalizations is stable and quite robust, penalization allows for an extra regularization and robustness, especially around shocks where spurious oscillations can appear even in the presence of a flux limiter. Extra penalizations terms are called soft constraints [Raissi and Karniadakis, 2018]. The Entropy and Total Variation Diminishing (TVD) penalizations were first introduced in Patel et al. [2022] for hyperbolic PDEs. Here, we use\n$L_{penalization} = \\lambda_{ent} L_{ent} + \\lambda_{TVD} L_{TVD} + \\lambda_{reg} L_{reg} \\tag{17}$\nFor the total loss (16), the parameter $ \\lambda_2 $ is set equal to 1, the three parameters $ \\lambda_{ent}, \\lambda_{TVD} $ and $ \\lambda_{reg} $ are tuned through Bayesian optimization [Frazier, 2018] on the validation loss which is $ L_{tot} - L_{penalization} $.\nEntropy inequality penalization. Defining as in Patel et al. [2022], an entropy-flux loss can be written following equation (2) and be rewritten as a conservation law\n$ \\int_{\\Omega \\times T} \\partial_t \\eta + \\nabla \\cdot q dw dt \\leq 0 \\tag{18}$\nthus defining the inequality as a penalization,\n$ L_{ent} = \\frac{\\epsilon_{max}}{N_c} \\sum_{j=1}^{N_c} \\Big( \\frac{\\int_{I_j \\times T_j} \\partial_t \\eta + \\nabla \\cdot q dw dt}{\\delta_{j}} \\Big)^2 \\tag{19}$\nWhere $ I_j \\times T_j \\in \\Omega \\times T $ are the $ N_c $ space-time cells on which we want to compute the loss. Giving in discrete form\n$\\begin{aligned}\nK_j &= \\int_{I_j \\times T_j} \\partial_t \\eta + \\nabla \\cdot q dw dt \\\\\nK_j &= h [\\eta(x_j, t + \\delta t) - \\eta(x_j, t) + \\sum_i \\frac{q_i(x_j, t) - q_i(x_j - h e_i, t)}{h} ]\n\\end{aligned}$\nwhere $ q_{eia} = q_{ia} $.\nTotal Variation penalization. The TVD property on a 1D Cartesian mesh can often be given as\n$ \\forall t \\in [O, T], TV(u^{i+\\Delta t}) \\leq TV(u^i), \\tag{20}$"}, {"title": "4.5. Dataset", "content": "We here analyze the linear stability properties of the data driven scheme by performing a von Neumann stability analysis. We consider the scalar linear advection equation (4) with periodic boundary conditions. For a given real wavenumber k, (4) admits exact solution of the form $ e^{i(kx-\\omega n\\Delta t)} $, with $ \\omega = ka $ the complex frequency, as elementary solutions.\nAs described in section 3, the discrete scheme reads on a Cartesian mesh\n$\\begin{aligned}w_j^{n+1} &= w_j^n - C_0 (w_{j+\\frac{1}{2}}^n - w_{j-\\frac{1}{2}}^n) - \\frac{C_0}{2 \\Delta x} (\\hat{\\partial_x w_j^n} - \\Phi_{j-1} \\hat{\\partial_x w_{j-1}^n})\n\\end{aligned}$\nwith $C_0 = \\frac{c \\Delta t}{\\Delta x}$ the CFL number. In order to facilitate the analysis, we set the limiter to 1 and linearize the non-linear operator $ \\widehat{\\partial x} $. This operator can be written as\n$\\widehat{\\partial x} w_j = \\frac{a_{-1} w_{j-1} + a_0 w_j + a_1 w"}]}