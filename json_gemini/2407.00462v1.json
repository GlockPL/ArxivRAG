{"title": "pFLFE: Cross-silo Personalized Federated Learning via Feature Enhancement on Medical Image Segmentation", "authors": ["Luyuan Xie", "Manqing Lin", "Siyuan Liu", "ChenMing Xu", "Tianyu Luan", "Cong Li", "Yuejian Fang", "Qingni Shen", "Zhonghai Wu"], "abstract": "In medical image segmentation, personalized cross-silo federated learning (FL) is becoming popular for utilizing varied data across healthcare settings to overcome data scarcity and privacy concerns. However, existing methods often suffer from client drift, leading to inconsistent performance and delayed training. We propose a new framework, Personalized Federated Learning via Feature Enhancement (pFLFE), designed to mitigate these challenges. pFLFE consists of two main stages: feature enhancement and supervised learning. The first stage improves differentiation between foreground and background features, and the second uses these enhanced features for learning from segmentation masks. We also design an alternative training approach that requires fewer communication rounds without compromising segmentation quality, even with limited communication resources. Through experiments on three medical segmentation tasks, we demonstrate that pFLFE outperforms the state-of-the-art methods.", "sections": [{"title": "1 Introduction", "content": "Cross-silo Federated Learning (FL) [10,13,14,17] has recently achieved promising progress in medical image segmentation tasks such as [20,25,22]. It trains the network to gather data information from all clients without actually accessing data. Considering strict privacy regulation requirements of medical data, exploring cross-silo FL in medical image segmentation is important and useful to real-world applications [4,7,15,26]. To deal with data heterogeneous among clients caused by different medical protocols, personalized federated learning approaches such as [3,9,27,28] have made significant progress by using an aggregation of centralized and client-specific network design [18]. However, despite the recent progress made in personalized FL [5,8,16,12], previous works such as FedRep [1] and LG-FedAvg [2] still suffer from client drifting problems in medical image segmentation tasks [11,20,22]. The simple feature extraction and aggregation process would cause client drifting problems, which would degrade the performance and make the training process unstable. We show the training process of FedRep and LG-FedAvg in Fig.1 (a). It is easy to observe that both FedRep and LG-FedAvg are not stable in training, and their performance drops as the training converges. To analyze the reasons that cause this issue, we visualize the t-distributed stochastic neighbor embedding (t-SNE) figure of foreground and background samples of FedRep and LG-FedAvg features in Fig.1 (b) and Fig.1 (c). The figures show clear distribution overlappings of foreground samples and background samples for both FedRep and LG-FedAvg. The indistinguishable feature distributions of foreground and background samples make the following network harder to classify foreground and background pixels.\nTo address these challenges, we introduce a new framework, namely personalized cross-silo Federated medical image Segmentation via Feature Enhancement (pFLFE), to enhance feature representation on each client without compromising data privacy. Our framework employs a self-supervised, contrastive approach for feature enhancement that relies solely on positive samples [30,19,31,32], reducing the need for large batch sizes and avoiding the sharing of features between clients [23,24,29]. This approach ensures data privacy and is particularly designed for medical applications where data is often limited.\nSpecifically, we design two federated learning frameworks including one with better performance and one that achieves comparable performance while using much fewer communication rounds. Our first framework consists of 4 main phases: local feature enhancement, local supervised training, and a global aggregation process after each local step, which together improve segmentation performance and training stability. The local supervised training will extract the information from each local client, and the local feature enhancement step will make personalized corrections to the shifted global parts after local training and aggregation. For our fast convergence framework, we use two similar local training steps but only one global aggregation process. The simplified communication design is found to have similar segmentation performance while converging much faster.\nIn summary, our contributions include the following:\nWe propose a novel personalized FL framework called pFLFE for medical image segmentation. pFLFE tackles client drift problems in medical image segmentation FL with a feature enhancement network using only positive samples, which eliminates the requirements of negative samples or features from other clients.\nWe design an alternative fast-converging framework that can reach comparable performance in a few communication rounds, which is useful when communication resources are limited.\nOur experiments on 3 segmentation tasks involving in total of 17 datasets show that, PFLFE outperforms state-of-the-art results and achieves comparable performance with centralized learning, with high training stability and faster convergence."}, {"title": "2 Methods", "content": null}, {"title": "2.1 PFLFE Framework", "content": "In Fig.2 (a), we present the pFLFE framework, consisting of 4 key stages: Local Feature Enhancement, Global Aggregation I, Local Supervised Learning, and Global Aggregation II, with stages 1 and 3 involving model uploads and stages 2 and 4 involving downloads. First, we enhance local feature extraction through a local feature enhancement module, which we will introduce details in Sec. 2.2. Then, during Global Aggregation I, encoders from all clients are aggregated. Subsequently, Local Supervised Learning refines segmentation networks on individual clients, extracting information from local data with annotation. Finally, Global Aggregation II shares refined encoders, further integrating supervised learning information across clients. In total, pFLFE uniquely improves local feature extraction and personalization, enabling superior performance and faster convergence without requiring data sharing, thus maintaining data privacy.\nThe components \\(E_i\\), \\(D_i\\), and \\(P_i\\) represent the encoder, decoder, and projector of the i-th client in Fig.2 (a), respectively. \\(E_r\\) is a shared parameter, and considering the issue of imbalanced client data and fairness in performance distribution [7,21], we adopt an average client weights approach rather than average data [21]. Due to the two-stage training of pFLFE, optimization losses for client i are as follows:\n\n\\(L_{1,i} = L_{MSE} (P_i(E_i(x)), P'_i(E'(x'))) + L_{MSE} (P_i(E_i(x')), P'_i(E'(x))')\\)\n\\(L_{2,i} = L_{Dice}(D_i(E_i(x_i)), y_i) + L_{CE}(D_i(E_i(x_i)), y_i)\\)   (1)\n\n\\(L_{1,i}\\) and \\(L_{2,i}\\) are the loss functions of the first and second stages, respectively. \\(L_{MSE}\\) means mean squared error loss, \\(L_{CE}\\) is cross-entropy loss and \\(L_{Dice}\\) is Dice loss [20]. \\(P()\\) and \\(E()\\) are another branch of client i in first stage. \\(x_i\\) and \\(y_i\\) are the data and labels on client i. \\(\\alpha\\) and \\(\\alpha'\\) are two different types of data augmentation."}, {"title": "2.2 Local Feature Enhancement", "content": "As shown in Fig.2 (b), the Local Feature Enhancement (LFE) consists of two branches: an online network O and a target network T. The target network is initialized with the same parameters as the online network. We train both branches using only positive samples, eliminating the need for negative samples or features from other clients. Given image I, we use two different data augmentation strategies for the same image. The resulting images are denoted as V and V', respectively. V and V' are passed through the encoder and projector in both the online and target branches, resulting in O(V) and T(V'). In order for the encoder to learn the representation invariance of the same data, we calculate the mean squared error (MSE) between the normalized O(V) and T(V') like [?]:\n\n\\(L = \\|\\|O(V) - T(V')\\|\\|^2 = 2 - 2 \\frac{(O(V), T(V'))}{\\|O(V)\\|^2 \\|T(V')\\|^2}\\) (2)\n\nO(V) and T(V') are the \\(l_2\\)-normalize of O(V) and T(V'), respectively. (\\cdot) means dot product, and \\|\\cdot\\| represents the \\(l_2\\)-norm of the features. We separately feed V' to the online network and V to the target network to compute \\(L' = \\|\\|O(V') - T(V)\\|\\|^2\\), respectively. The total loss function is defined as:\n\n\\(L_{total} = L + L'\\)   (3)\n\nThe target network updates through Exponential Moving Average (EMA) [23]. And we remove it after first training stage, which reduces the burden of local storage. In online branch, we upload encoder and retain the projector after the first training stage. Local Feature Enhancement can make personalized corrections to the previous round second stage of training and aggregated encoder that generates drift in each round."}, {"title": "2.3 Fast Converging PFLFE", "content": "It is crucial to evaluate the communication overhead of federated learning. However, a complete training round of pFLFE includes two communication processes. This significantly increases the communication cost. To mitigate this issue, we provide a fast converging version of pFLFE named Fast Converging pFLFE (FC-pFLFE) as illustrated in Fig.2 (c), which can provide comparable results with very few communication rounds.\nIn the FC-pFLFE training phase, we begin with Local Feature Enhancement, which is the same feature enhancement procedure as in pFLFE. Then, the trained encoder is passed to the local segmentation model for Local Supervised Learning. After that, the encoder is then uploaded to the server for aggregation. FC-pFLFE only uses 1 aggregation step for 1 round of local feature enhancement and supervised learning, unlike pFLFE which uses 2 aggregation steps. This design allows us to reduce the number of communication rounds while largely preserving the feature enhancement and local knowledge acquisition of pFLFE."}, {"title": "3 Experiment Setup", "content": "Task and Dataset. We evaluate our proposed pFLFE on 3 tasks. Optic Disc/Cup segmentation: We use 7 datasets from [20,22]. Each dataset represents a client, so there are 7 clients. Polyp segmentation: The endoscopic images dataset is collected and annotated from four different centers [33,34,35,36], and each center's dataset is treated as a separate client. This task has 4 clients. Prostate segmentation: We use MRI data collected and annotated by 6 institutions [11]. Each institution's dataset is treated as a client, resulting in 6 clients for this task. Considering that some clients have limited data, we employed a widely used 1:1 train-test split for optic disc/cup and polyp segmentation. The train-test split protocol follows the standard split used in the latest work for prostate segmentation.\nImplementation Details. To ensure reliability of our experiments, we employ a five-fold cross-validation and report the mean Dice coefficient [20]. We calculate the average Dice coefficient for each client (DiceAcli), the average Dice coefficient for all test images (DiceAImg), and the variance of Dice across clients (VDiceacli) to evaluate the model's performance and client discrepancy. (More details in supplementary materials.)"}, {"title": "4 Results and Discussion", "content": "State-of-the-art comparison. Table 1, Table 2, and Table 3 present the comparisons between pFLFE and previous approaches on 3 tasks. We can easily observe that our pFLFE achieves optimal performance compared to other FL frameworks in all three tasks. And the performance of pFLFE is close to that of centralized learning, even surpassing centralized learning in polyp segmentation task. The FC-pFLFE performs slightly lower than pFLFE in all three tasks.\nAblation experiment. In Table 4, we conduct ablation experiments on pFLFE and adjusted the number of personalized layers of pFLFE. The results show that both LFE and the number of personalized layers have a significant impact on the performance of pFLFE. We use all decoders as personalized layers. This not only has performance advantages but also reduces the amount of parameters transmitted from the client to the server.\nFeature distribution. In order to evaluate the quality of our enhanced feature, we compare the KL divergence of the feature distribution of the foreground and background samples. Smaller KL divergence indicates the global feature of foreground and background are better separated. As shown in Table.5, pFLFE feature has a smaller KL divergence than our baseline and previous works on all 3 tasks. These results verify the effectiveness of our feature enhancement design and the quality of our global feature.\nThe impact of different models. To demonstrate the impact of different models on pFLFE, we use different encoder-decoder segmentation networks on pFLFE. In Table 6, results show that using more complex models such as Unet++ and Res-Unet can help improve the performance of pFLFE."}, {"title": "The domain adaptation capability of pFLFE.", "content": "We verify the domain adaptation capability on Optic Disc/Cup segmentation tasks. In an unseen client, we extract and freeze their encoders trained on other clients, only fine-tuning the decoders. In Table 7, pFLFE obtains the optimal result. (More relevant experiments in supplementary materials.)"}, {"title": "5 Conclusion", "content": "Our proposed pFLFE addresses features challenge faced in personalized cross-silo federated medical image segmentation. pFLFE incorporates Local Feature Enhancement and utilizes decoder as the personalized layer, ensuring both convergence and performance stability. We perform two-stage training and aggregation on global part (encoder), effectively improving its generalization and robustness. This enables it to adapt to new domains on unseen clients. Extensive experiments demonstrate superiority of our approach over existing personalized methods, approaching the performance of centralized learning."}]}