{"title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection", "authors": ["Yang Cao", "Sikun Yang", "Chen Li", "Haolong Xiang", "Lianyong Qi", "Bo Liu", "Rongsheng Li", "Ming Liu"], "abstract": "Text anomaly detection is crucial for identifying spam, misinformation, and offensive language in natural language processing tasks. Despite the growing adoption of embedding-based methods, their effectiveness and generalizability across diverse application scenarios remain under-explored. To address this, we present TAD-Bench, a comprehensive benchmark designed to systematically evaluate embedding-based approaches for text anomaly detection. TAD-Bench integrates multiple datasets spanning different domains, combining state-of-the-art embeddings from large language models with a variety of anomaly detection algorithms. Through extensive experiments, we analyze the interplay between embeddings and detection methods, uncovering their strengths, weaknesses, and applicability to different tasks. These findings offer new perspectives on building more robust, efficient, and generalizable anomaly detection systems for real-world applications.", "sections": [{"title": "Introduction", "content": "Anomaly detection is a critical task in machine learning, with applications ranging from fraud detection and content moderation to user behavior analysis. Within natural language processing (NLP), anomaly detection has become increasingly relevant for identifying outliers such as harmful content, phishing attempts, and spam reviews. However, while AD tasks in structured data (e.g., tabular, time series, graphs) have achieved significant maturity, anomaly detection in the unstructured and high-dimensional domain of text remains under-explored. The complexity of textual data\u2014driven by its diverse syntactic, semantic, and pragmatic structures\u2014presents unique challenges for robust anomaly detection.\nThe rise of deep learning and transformer-based models has revolutionized natural language processing (NLP), enabling the development of contextualized embeddings that encode rich semantic and syntactic information. Techniques such as BERT and OpenAI's text-embedding models have demonstrated remarkable success across a wide range of NLP tasks, offering dense, high-dimensional representations that effectively capture linguistic nuances. These embeddings have become a cornerstone for many downstream tasks, providing powerful tools for applications such as text classification and retrieval. Their ability to generalize across tasks and domains has positioned them as a promising foundation for more complex challenges, including anomaly detection.\nIn recent years, embedding-based methods have gained significant attention in anomaly detection tasks, particularly for capturing deviations in textual data. While promising, several challenges remain unaddressed. Existing studies often lack systematic evaluations of how different embeddings perform across diverse anomaly types, raising questions about their generalization capabilities in complex, real-world scenarios such as multilingual settings or domain-specific anomalies. Recent efforts, such as AD-NLP and NLP-ADBench, have significantly advanced anomaly detection in NLP. AD-NLP provides valuable insights into different types of anomalies, while NLP-ADBench expands evaluations to a wide range of algorithms and datasets. However, AD-NLP evaluates few detection algorithms while NLP-ADBench considers only a few embedding methods, respectively. Our work aims to move beyond simply filling these gaps, by systematically exploring the following questions:"}, {"title": "Problem Definitions", "content": "In the context of NLP, an anomaly refers to a text instance that exhibits characteristics or patterns that are significantly different from the majority of the dataset. Such anomalies can manifest in various ways, including rare topics, unusual syntax or semantics, domain-specific jargon, or even intentionally manipulated language, such as spam, fake news, or offensive content. Detecting these anomalies is critical for numerous applications, such as content moderation, fraud detection, and identifying novel or emerging patterns in large text corpora.\nFormally, let $D = \\{X_1, X_2,...,X_N\\}$ represent a corpus of N textual instances, where each instance $x_i \u2208 X$ is a sequence of tokens: $x_i = [t_1, t_2,..., t_{L_i}]$, and $L_i$ denotes the sequence length. The goal of NLP-AD is to identify a subset of instances $D_{anomaly} \u2286 D$, such that $D_{anomaly}$ contains samples that deviate significantly from the majority of the dataset $D_{normal} = D \\setminus D_{anomaly}$.\nTo achieve this, an anomaly detection algorithm $g : \\mathbb{R}^d \u2192 \\mathbb{R}$ is applied to the representations of the textual instances. (1) Each text instance $x_i$ is first mapped to a fixed-dimensional vector $z_i \u2208 \\mathbb{R}^d$ using an embedding model $\u03c6: X \u2192 \\mathbb{R}^d$, such that $z_i = \u03c6(x_i)$. (2) The anomaly detection algorithm then assigns an anomaly score $s_i = g(z_i)$ to each instance. Based on a predefined threshold $\u03c4$, an instance $x_i$ is classified as anomalous if:\n$x_i \u2208 D_{anomaly} \\rightleftharpoons s_i \u2265 \u03c4$.\nThe objective of NLP-AD is to ensure that g effectively distinguishes between normal and anomalous instances, even in the absence of labeled data, while being robust to the inherent variability and high dimensionality of textual data."}, {"title": "Related Work", "content": "Embedding-based text anomaly detection typically involves two stages: extracting representations from text using pre-trained language models and detecting anomalies using dedicated algorithms. In this section, we review prior work on these two aspects to provide context for our benchmark."}, {"title": "Text representations", "content": "The development of text representations extraction techniques has been fundamental to progress in natural language processing (NLP). Early methods like TF-IDF (Term Frequency-Inverse Document Frequency) represented text in sparse vector spaces by measuring word importance relative to a corpus. While interpretable and computationally efficient, TF-IDF could not capture semantic relationships between words. Later, dense embeddings such as Word2Vec and GloVe addressed this limitation by mapping words into continuous vector spaces based on their co-occurrence patterns in large corpora. However, these embeddings were static, assigning the same vector to a word regardless of its context.\nTo overcome the limitations of static embeddings, contextualized embeddings were introduced, with models like ELMo producing word representations that vary based on context. This innovation was further advanced by transformer-based models like BERT which used bidirectional attention mechanisms to simultaneously capture left and right context. BERT set new benchmarks in NLP and inspired numerous improvements, including ROBERTa and ALBERT.\nMore recently, large language models such as GPT have pushed the boundaries of embedding methods. These models, trained on massive datasets, produce versatile embeddings that capture both semantic and generative properties of text. LLMs have demonstrated unprecedented performance across a wide range of NLP tasks, establishing them as dominant tools for text representation in various applications, including anomaly detection."}, {"title": "Anomaly Detection", "content": "Existing anomaly detection methods can be broadly categorized into 6 classes: distance, density, isolation, statistical, projection and deep learning-based approaches. Each category offers distinct advantages and is suited for different types of data distributions and anomaly patterns.\nDistance-based methods, such as k-Nearest Neighbors (kNN), identify anomalies by measuring the distance of a given data point to its nearest neighbors. Points that are far from their neighbors are considered anomalous. These methods are intuitive and straightforward but suffer from the curse of dimensionality in high-dimensional spaces, where distances lose their discriminative power, reducing their effectiveness.\nDensity-based methods identify points with significantly lower local density compared to their surroundings as anomaly. Local Outlier Factor (LOF) measures the local density of a point relative to its neighbors. Histogram-Based Outlier Score (HBOS) estimates densities using histograms for individual features.\nIsolation-based methods assume anomalies are rare and different, Isolation Forest (iForest), detect anomalies by recursively partitioning the feature space where anomalies require fewer partitions than normal points. Improved techniques, such as iNNE (Isolation-based Nearest Neighbor Ensembles), use hypersphere to partition data space and assigns larger hyperspheres to anomalies, improving robustness in detecting local anomalies.\nProbabilistic and statistical methods identify anomalies based on deviations from the data distribution. ECOD uses cumulative distribution functions for efficient anomaly scoring, while COPOD leverages copulas to model feature dependencies, handling multivariate data effectively. Projection-based methods, such as One-Class SVM (OCSVM), separate normal and anomalous data by learning a decision boundary in a high-dimensional feature space. While effective for complex distributions.\nDeep learning-based methods train on normal data to learn representations, identifying anomalies as deviations. Approaches like Deep SVDD and LUNAR capture nonlinear patterns but require substantial data and computational resources."}, {"title": "Benchmark Settings", "content": "The limited availability of purpose-built datasets constrains the development and evaluation of effective methods in NLP-AD. To address this gap, we curated and transformed 6 existing classification datasets from three common NLP domains: spam detection, fake news detection, and offensive language detection. By selecting datasets from diverse domains, we aim to explore the applicability of embedding-based anomaly detection methods across different NLP scenarios.\nAnomalies, as defined in our problem, are inherently rare. However, due to the lack of dedicated datasets for text anomaly detection, we adapted classification datasets by designating specific classes as anomalies and down-sampling them to simulate realistic anomaly rates. For each dataset, the anomaly rate was set to approximately 3%, reflecting the typical rarity of anomalies in real-world scenarios.\nUnlike traditional text classification tasks, no additional preprocessing was applied to the source text, as any token, word, or symbol could potentially carry critical information indicative of an anomaly. By preserving the original text in its raw form, we aim to retain all features that may contribute to the detection of anomalous patterns."}, {"title": "Embedding Models", "content": "summarizes the embedding models employed in this paper. To extract high-quality embeddings from the datasets, 8 embedding models were utilized. These include BERT (bert-base-uncased), MiniLM (all-MiniLM-L6-v2), LLAMA (Llama-3.2-1B), stella (stella_en_400M_v5), and Qwen (Qwen2.5-1.5B) from the HuggingFace platform, as well as OpenAI-provided models: O-ada (text-embedding-ada-002), O-small (text-embedding-3-small), and O-large (text-embedding-3-large). All these models are based on the Transformer architecture, which has become the standard for representation learning in NLP tasks. The OpenAI models (O-ada, O-small, O-large) are specifically designed for embedding generation, offering embeddings with varying levels of granularity. On the other hand, LLAMA and Qwen are primarily auto-regressive language models optimized for text generation. In this paper, we repurposed these models for embedding extraction by computing the attention-weighted mean of their last hidden states, ensuring that only valid tokens contribute to the final sentence embeddings.\nNotably, LLAMA and Qwen were constrained to a maximum token length of 512 tokens, same as BERT, due to computational resource limitations. Other models, such as MiniLM, Stella, and the OpenAI embeddings, utilized automatic truncation to process longer input sequences. This limitation may restrict LLAMA and Qwen's ability to fully leverage their extended context capabilities, particularly for datasets with longer text instances, such as LIAR2 and Hate-Speech. However, this unified token length ensures a fair comparison of runtime efficiency across models under consistent experimental conditions. It also highlights the trade-offs between computational cost and embedding quality, particularly when resource constraints are a factor in model deployment."}, {"title": "Anomaly Detectors", "content": "The embeddings derived from these models were subsequently used as input features for anomaly detection algorithms. To identify anomalous instances, we employed 8 state-of-the-art anomaly detection methods sourced from the PyOD library . These algorithms include KNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS and COPOD . These algorithms were selected to capture diverse anomaly detection paradigms, ensuring robust detection across varying dataset characteristics."}, {"title": "Evaluation Criteria and Trials", "content": "Performance was evaluated using the Area Under the Receiver Operating Characteristic Curve (AUROC), which is a widely used criteria in anomaly detection tasks. Each experiment was conducted 5 times, and the average AUROC was reported to ensure result reliability.\nThe entire pipeline, including embedding extraction and anomaly detection, was implemented in PyTorch. Experiments were executed on a computational setup equipped with a Ryzen 9 5900X 12-core CPU for data preprocessing and model orchestration, and an Nvidia RTX 3060 GPU with 12GB of memory for model inference and embedding generation."}, {"title": "Experiments", "content": ""}, {"title": "Applicability of LLM Embeddings with Anomaly Detectors", "content": "summarizes the performance of various anomaly detectors combined with LLM-derived embeddings across different datasets, while Figure 1 highlights their strong performance in specific tasks, particularly spam detection. In both the email spam and SMS spam detection tasks (Figure 1a and Figure 1d, many embedding-detector combinations achieve high AUC scores, with several exceeding 0.8. This strong performance can be attributed to the explicit nature of spam-related features, such as the presence of URLs, nonsensical text, or repetitive patterns. An example from the Email Spam dataset is shown below:\nSubject: oxyccontttin no script needeeed\nyour place to ggo too for all ur prreexxxxis-\ncrlpt 10 n pi sx, paaaaain killerzxss noeoo\npresscippt http://hyyydroccodeeeine vic-\nccodinne / vic geeet reeeliefff noowee http:\n// offfmeebabyy\nThese features are effectively represented in the semantic spaces created by general-purpose embeddings, enabling anomaly detectors to distinguish spam messages from legitimate ones. Additionally, the relatively small variance in detection performance across embeddings suggests that spam detection relies on surface-level linguistic patterns that are well captured by the embeddings used in this study.\nFor fake news detection, the results indicate a more mixed performance across datasets. On the Covid Fake News dataset multiple embedding-detector combinations achieve AUC scores close to or exceeding 0.8, suggesting that these methods are capable of identifying subtle stylistic and linguistic differences between fake and real news. These differences may include deviations in tone, phrasing, or structural composition of the text. However, on the LIAR2 dataset the AUC scores exhibit much greater variability across different combinations of embeddings and detectors. This variability likely stems from the greater factual complexity of the LIAR2 dataset, where detecting anomalies may require external knowledge or sophisticated reasoning that is not inherently encoded within the embeddings. Despite this variability, the relatively strong performance on the Covid Fake News dataset underscores the potential of embedding-based approaches for fake news detection, particularly when the anomalies are stylistic or linguistic in nature.\nIn contrast, the performance on hate speech and offensive language detection tasks is consistently weaker, with AUC scores rarely exceeding 0.6 across embedding-detector combinations. This suggests that the embeddings struggle to capture the nuanced and context-dependent features necessary for these tasks. For example, hate speech often involves implicit cues such as sarcasm, cultural references, or indirect hostility, which may not be adequately represented in the embeddings. Similarly, offensive language detection, as seen in the OLID dataset, requires distinguishing fine-grained differences in tone or intent, such as the distinction between neutral, offensive, or subjective language. These distinctions often depend on broader contextual information, such as the discourse or dialogue in which the language appears. These distinctions often depend on broader contextual information, such as the discourse or dialogue in which the language appears. For example, without additional context, such as the speaker's intent or the conversational background, the following statement from OLID dataset remains ambiguous whether this statement qualifies as hate speech:\n@USER #metoo are all racist!"}, {"title": "Comparative Effectiveness of Embeddings in Anomaly Detection", "content": "The results in demonstrate the remarkable capabilities of the OpenAI family of embeddings (O-ada, O-small, and O-large), consistently outperforming other embeddings across a variety of anomaly detection tasks. Specifically, O-ada achieves the highest average AUC scores with the ECOD detector (0.8822) on the SMS Spam dataset and with kNN (0.7921) on the LIAR2 dataset. Similarly, O-small demonstrates outstanding performance, achieving the highest AUC scores with KNN on the Hate Speech (0.6416) and OLID (0.5587) datasets. Additionally, O-large secures top AUC scores with COPOD (0.9639) on the Email Spam dataset and with kNN (0.9537) on the COVID Fake News dataset.\nIn comparison, other embeddings, such as MINILM, exhibit strong performance in specific tasks but lack consistency across more complex datasets. For instance, MINILM achieves exceptional AUC scores of 0.9526 and 0.9626 on the Email Spam datasets, respectively, when used with INNE and OCSVM. However, its performance drops significantly on datasets like OLID and LIAR2, indicating limitations in handling tasks where deeper contextual or domain-specific cues are required. Similarly, embeddings such as stella and Qwen show moderate performance, excelling in a limited subset of tasks but failing to achieve the same level of versatility as the OpenAI embeddings.\nThese observations suggest that the OpenAI embeddings, particularly O-small and O-large, provide the most robust and consistent performance across a wide range of tasks. Their ability to effectively represent both explicit textual features (e.g., spam detection tasks) and subtle contextual variations underscores their suitability for anomaly detection scenarios that require both surface-level semantic extraction and deeper linguistic understanding. Moreover, the collective performance of the OpenAI family emphasizes the adaptability and efficacy of transformer-based embeddings in addressing anomaly detection challenges across datasets with diverse linguistic and semantic complexities. OpenAI embeddings consistently emerge as dominant and versatile solutions in various scenarios, making them highly effective for a wide range of applications."}, {"title": "Performance Across Anomaly Detectors", "content": "To evaluate the robustness of anomaly detection algorithms across various embeddings and tasks, we analyze their average rankings using OpenAI embeddings (O-ada, O-small, and O-large) as representative examples (Figure 2). These embeddings were selected based on their strong and consistent performance across datasets, as demonstrated in Section 5.2. The rankings provide insight into which detection algorithms perform reliably regardless of the embedding or task.\nAcross all three embeddings, kNN and INNE consistently rank as the top-performing algorithms. This indicates their robustness and adaptability to the semantic structures of LLM-derived embeddings. kNN, in particular, excels due to its ability to effectively model local density variations in feature space, making it well-suited for both explicit-pattern tasks like spam detection and nuanced tasks like fake news and hate speech detection. INNE, with its efficiency and strong generalization capabilities, complements kNN as a reliable alternative in diverse anomaly detection scenarios.\nECOD also ranks highly, consistently appearing among the top three detectors across embeddings. Its lightweight design and ability to estimate density-based anomalies make it a strong candidate for scenarios where computational efficiency is critical. On the other hand, methods like LOF, COPOD, and iForest consistently rank lower, highlighting their limitations in high-dimensional and semantically complex embedding spaces. These methods struggle with noise, data sparsity, and the nuanced patterns encoded in LLM embeddings, which limits their effectiveness across diverse tasks.\nOverall, KNN, INNE, and ECOD demonstrate robust and consistent performance across embeddings and tasks, making them well-suited for general-purpose anomaly detection pipelines. In contrast, methods like LOF, COPOD, and iForest show weaker adaptability, likely due to their limitations in handling high-dimensional and semantically rich embeddings."}, {"title": "Conclusion", "content": "In this work, we present a comprehensive benchmark for embedding-based anomaly detection in natural language processing, evaluating the interplay between large language model (LLM) embeddings and classical anomaly detection algorithms across three diverse domains: spam detection, fake news detection, and offensive language detection. Our results reveal both the strengths and limitations of LLM embeddings, demonstrating their effectiveness in tasks with explicit patterns but highlighting challenges in capturing implicit, context-dependent anomalies."}, {"title": "Limitations and Future Works", "content": "TAD-Bench evaluates anomaly detection across three domains: spam detection, fake news detection, and offensive language detection. While these tasks provide diverse and relevant benchmarks, they do not fully capture the complexity of real-world applications. Strong performance in spam detection highlights the ability of LLM embeddings to capture explicit patterns, while mixed results in fake news detection and poor performance in offensive language detection reveal their limitations in modeling implicit, context-sensitive cues. Expanding to domains like medical, financial, or legal texts that involve unique challenges, and exploring datasets with more implicit anomalies, could better evaluate the adaptability and robustness of these methods.\nIn addition, our work uses pre-trained LLM embeddings and default hyperparameters for anomaly detectors, ensuring consistency but potentially underestimating their best-case performance. Fine-tuning LLMs on domain-specific data could improve embedding quality, while systematic hyperparameter optimization might unlock the full potential of anomaly detectors. Future research should explore these directions, leveraging techniques like AutoML to streamline both embedding fine-tuning and parameter tuning, thereby achieving more competitive performance.\nMoreover, TAD-Bench focuses solely on embedding-based methods, excluding end-to-end approaches that directly process raw text. While embeddings offer modularity and efficiency, end-to-end models like autoencoders or transformer-based systems may capture richer contextual information and handle more complex anomalies. Future work should incorporate end-to-end models and explore hybrid approaches that combine the strengths of both paradigms, providing a more comprehensive evaluation of anomaly detection methods in NLP."}, {"title": "Ethic Statement", "content": "All the data and information in this paper are from public source."}]}