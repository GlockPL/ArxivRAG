{"title": "DISSECTING MISALIGNMENT OF MULTIMODAL\nLarge LANGUAGE MODELS VIA INFLUENCE FUNCTION", "authors": ["Lijie Hu", "Chenyang Ren", "Huanyi Xie", "Khouloud Saadi", "Shu Yang", "Jingfeng Zhang", "Di Wang"], "abstract": "Multi-modal Large Language models (MLLMs) are always trained on data from\ndiverse and unreliable sources, which may contain misaligned or mislabeled text-\nimage pairs. This frequently causes robustness issues and hallucinations, leading\nto performance degradation. Data valuation is an efficient way to detect and trace\nthese misalignments. Nevertheless, existing methods are computationally expen-\nsive for MLLMs. While computationally efficient, the classical influence func-\ntions are inadequate for contrastive learning models because they were originally\ndesigned for pointwise loss. Additionally, contrastive learning involves minimiz-\ning the distance between the modalities of positive samples and maximizing the\ndistance between the modalities of negative samples. This requires us to evalu-\nate the influence of samples from both perspectives. To tackle these challenges,\nwe introduce the Extended Influence Function for Contrastive Loss (ECIF), an\ninfluence function crafted for contrastive loss. ECIF considers both positive and\nnegative samples and provides a closed-form approximation of contrastive learn-\ning models, eliminating the need for retraining. Building upon ECIF, we develop\na series of algorithms for data evaluation in MLLM, misalignment detection, and\nmisprediction trace-back tasks. Experimental results demonstrate our ECIF ad-\nvances the transparency and interpretability of MLLMs by offering a more ac-\ncurate assessment of data impact and model alignment compared to traditional\nbaseline methods.", "sections": [{"title": "1 INTRODUCTION", "content": "Multi-modal Large Language models (MLLMs) (Yin et al., 2023; Koh et al., 2024) have garnered\nsignificant attention for their ability to integrate and understand various data types, such as image,\ntext, and audio. Despite their growing application, existing MLLMs often suffer from robustness\nissues (Carlini & Terzis, 2021) and hallucinations, primarily stemming from misaligned text-image\npairs in the training data (Kim et al., 2023). These misalignments, manifesting as semantic mis-\nmatches, contextual inconsistencies, or discrepancies between abstract and concrete elements, can\nseverely degrade model performance. MLLMs assume consistent alignment between image-text\npairs, but when this assumption fails, it leads to incorrect interpretations, ultimately degrading model\nperformance. Consequently, improving dataset transparency is crucial, as model developers need the\nability to trace and identify problematic data samples. However, diagnosing issues caused by mis-\naligned data, such as mislabeled or biased samples, is difficult when working with large text-image\ndatasets.\nAlthough the critical role of training data in shaping MLLM capabilities is well recognized, there\nremains a lack of robust evaluation mechanisms for data quality (Nguyen et al., 2022). To address\nthis, various data valuation methods (Jia et al., 2019; Ghorbani & Zou, 2019; Yoon et al., 2020;"}, {"title": "2 RELATED WORK", "content": "Contrastive Learning. Recently, self-supervised contrastive learning (Chen et al., 2020b) has\nemerged as a highly effective approach for acquiring representations without the need for labeled\ndata (Donahue & Simonyan, 2019). This model utilizes a contrastive loss, which pushes dissimilar\ndata pairs apart while pulling similar pairs closer together. Contrastive learning plays a pivotal role in\nadvancing MLLMs by integrating and understanding information across diverse modalities, such as\ntext and images (Radford et al., 2021; Jiang et al., 2024). In multi-modal contrastive learning tasks,\nproper alignment of the training data ensures accurate cross-modal associations, enabling models to\nlearn and extract consistent feature representations (Wang & Isola, 2020). One of the key challenges\nin training with noisy, large-scale image-text pairs sourced from the internet is achieving effective\nalignment between these modalities. To address this, researchers have developed various methods,\nsuch as those proposed by Gao et al. (2022) and Yao et al. (2021), which introduce finer-grained"}, {"title": "3 PRELIMINARIES", "content": "Contrastive Loss. Contrastive loss is an effective tool in multi-modal models for aligning and\nlearning relationships between different types of data, such as images and text 1. Specifically, given\na set of paired data consisting of text $x^T$ and image $x^I$, we aim to construct embedding vectors $u$\nand $v$ for text and image respectively via the encoder parameterized as $\\theta$. In a batch of $N$ text-image\npairs, each pair $(x^T_k, x^I_k)$ is embedded as $(u_k, v_k)$. We denote the text embeddings for this batch as\n$U = (u_1,..., u_N)$, and similarly, the image embeddings as $V = (v_1,..., v_N)$.\nThe contrastive loss is designed to minimize the distance between embeddings of matching pairs\nwhile maximizing the distance between non-matching pairs. Define the cosine similarity function\nas $s(u, v) = \\frac{u^T v}{\\|u\\| \\|v\\|}/\\tau$, where $\\tau$ is a trainable temperature parameter. For brevity, we will omit\ndetailing $\\tau$ in subsequent discussions. For each batch, we construct a similarity matrix $S$ with\n$S_{i,j} = s(u_i, v_j)$. Then, the self-supervised contrastive loss is defined as\n$L_{Batch} (U, V; \\theta) = \\sum_{i=1}^{N} - log(\\frac{e^{S_{i,i}}}{\\sum_{j=1}^{N} e^{S_{i,j}}}) = \\sum_{i=1}^{N} - log(e_i^T \\sigma(S_{i,*}))$\n$L_{Batch} (U, V; \\theta) = \\sum_{i=1}^{N} L_{T2I}(u_i, V; \\theta) + L_{I2T}(v_i, U; \\theta)$,\nwhere $e_i$ is the i-th standard basis vector in N-dimensional space, $\\sigma$ is softmax function. Observing\nfrom (1), we can separate the loss to image-to-text (I2T) and text-to-image (T2I) denoted in (2) and\ndefine loss function on similarity matrix as $L_{T2I}(S; \\theta)$ (and $L_{I2T}(S; \\theta)$). We will incorporate an $L_2$\nregularization term into the loss function, which allows us to avoid overfitting. Thus, for a given set\nof batches $\\mathcal{B}$, the objective loss can be written as\n$L_{Total} (\\mathcal{B}; \\theta) = \\sum_{(U,V) \\in \\mathcal{B}} L_{Batch} (U, V; \\theta) + \\frac{\\delta}{2} ||\\theta||^2$"}, {"title": "4 INFLUENCE FUNCTION IN CONTRASTIVE LEARNING", "content": "In this section, we will consider how to estimate the value of a given sample $(x^T, x^I)$ in the con-\ntrastive loss (3) using the influence function method. Generally, in the original influence function\nmethod, a term in the loss function which only contain the fully information from the target sample\nis up-weighted by $\\epsilon$. Then, a response function in (4) related to $\\epsilon$ is derived. Within this analyti-\ncal framework, when $\\epsilon$ is set to -1, the resultant loss and model parameters are the same as those\nobtained by removing the sample via retraining. However, in the context of contrastive learning,\nbecause the information of the sample point appears in every term of the loss function for its batch,\nit is not feasible to isolate the relevant information of this sample within a batch into an independent\nterm and then perform an up-weight operation on this sample to derive the influence function.\nThus, we need to execute fine-grained analysis of the specific contribution of sample $(x^T, x^I)$ within\ncontrastive loss. Assume $(x^T, x^I)$ is assigned as the n-th pair in the m-th batch, in which the text\nand image data are embedded into matrix $U_m$ and $V_m$. Then $(x^T, x^I)$ serves as positive samples\nfor each other in the n-th pairing loss $L_{T2I}(u_n, V_m; \\theta)$ and $L_{I2T}(v_n, U_m; \\theta)$ in (2). And $x^I$ and $x^T$\nserve as negative samples in other pairing losses.\nThrough simple observation about (2), it can be noted that when the data serves as a positive sample,\nits influence can be explicitly isolated. However, its information is coupled with other data when\nacting as a negative sample, necessitating further analysis. We provide the derivation of the influence\nfunction for these two scenarios separately."}, {"title": "4.1 INFLUENCE AS POSITIVE SAMPLES", "content": "To quantify the impact of $x^T$ and $x^I$ as positive samples, ideally, we can retrain the model after re-\nmoving the corresponding n-th pairing tasks, i.e., removing $L_{T2I}(u_n, V_m; \\theta)$ and $L_{I2T}(v_n, U_m; \\theta)$\nin the loss function. Thus, following the idea of influence function, we can up-weight these\ntwo parts by $\\epsilon$ and obtain an up-weighted loss function as the following with $Pos(x^T, x^I; \\theta) =$\n$L_{T2I}(u_n, V_m; \\theta) + L_{I2T}(v_n, U_m; \\theta)$.\n$L_{Total, \\epsilon} (\\theta) = \\sum_{(U,V) \\in \\mathcal{B}} L_{Batch} (U, V; \\theta) + \\frac{\\delta}{2} ||\\theta||^2 + \\epsilon \\cdot Pos(x^T, x^I; \\theta)$"}, {"title": "4.2 INFLUENCE AS NEGATIVE SAMPLES", "content": "In Section 4.1, we quantified the impact of $x^T$ and $x^I$ as positive samples by removing related\npairing tasks. Next, we attempt to estimate their impact as negative samples by removing them from\ntasks where they serve as negative samples. To achieve this, we need to delve into the specific form\nof contrastive loss.\nTake the text2image (T2I) loss for the k-th text embedding $u_k$ as the example, we first calculate its\nsimilarity with all image embeddings in the batch to form a similarity vector $S(u_k, V)$, which is then\nprocessed through a softmax layer $\\sigma(\\cdot)$ to yield a probability distribution. The k-th element indicates\nthe probability of correctly pairing the text $u_k$ with its corresponding image: $[\\sigma(S(u_k, V))]_k =$\n$\\frac{e^{S_{k,k}}}{\\sum_{j \\in [B]} e^{S_{k,j}}}$, where $B$ is the batchsize. The model is encouraged to enhance the probability of\ncorrect pairing by minimizing the negative logarithm of this value. For $n \\neq k$, $u_n$ serves as a\nnegative sample in this task and appears in the $S_{k,n}$ term in the denominator. Thus, after removing\nthe impact of $(x^T, x^I)$ as a negative sample from the m-th batch, the loss function corresponding to\nthis batch should become:\n$L_{T2I, -neg}((x^T, x^I), S; \\theta) = \\sum_{k \\in [B]} - log(\\frac{e^{S_{k,k}}}{\\sum_{j \\in [B]} e^{S_{k,j}}} + Pos((x^T, x^I); \\theta)$,\nj \\neq n\nk \\neq n\nThe original influence function method evaluates a data point's impact by adjusting its weight via\na separate term in the loss function and getting the response function (4). In Contrastive Learning,\nhowever, the influence of data points as negative samples is coupled with information from other\ndata, which can observed from (6). We will try to separate an influence term related to the data effect\nwhen it serves as a negative sample. Actually, the modification in (6) is analogous to eliminating\nthe n-th row and column from the original similarity matrix. Leveraging the idea of deriving the\ninfluence function, we aim to develop a response function that converges to the target loss by up-\nweighting specific components.\nConsidering that similarities vectors are processed through the softmax layer, if we increase the sim-\nilarity associated with $u_n$ and $v_n$ to a value approaching negative infinity, then after the exponential\noperation and the logarithmic function, the influence of $e^{S_{*,k}}$ and $e^{S_{*,n}}$ will become negligible.\nMathematically, let $E_n$ be an B $\\times$ B matrix such that its n-th column and the n-th row comprises\nones, while all other entries are zero. We add the matrix $\\log \\zeta \\times E_n$ to the similarity matrix. Then\nthe loss function based on the revised similarity matrix becomes:\n$L_{T2I,\\zeta}((x^T, x^I), S; \\theta) = \\sum_{k \\in [B]} - log(\\frac{e^{S_{k,k}}}{\\sum_{j \\in [B]} e^{S_{k,j}} + (\\zeta - 1) \\cdot e^{S_{k,n}}} + Pos((x^T, x^I); \\theta)$"}, {"title": "5 APPLICATIONS OF ECIF", "content": "We have proposed ECIF to evaluate the contribution of training data in contrastive learning. The\nECIF method enables us to estimate the change in the learned parameters $\\theta$ if a training example\npair is removed. Based on this, in this section, we will apply ECIF to two applications: misalignment\ndetection and misprediction trace back."}, {"title": "5.1 MISALIGNMENT DETECTION", "content": "MLLMs typically assume a consistent alignment between all image-text pairs, and thus, misaligned\ndata can lead to incorrect interpretations of these relationships, ultimately degrading model perfor-\nmance. Intuitively, given a high-quality validation data $\\mathcal{D}'$, if $\\mathcal{D}^*$ is a misaligned set, then the loss of\n$\\mathcal{D}'$ over the original model $\\theta$ should be greater than it over the model after deleting these misaligned\ndata. And such a difference can be approximated by ECIF.\nProperty 5.1. Considering a specific set $\\mathcal{D}'$ with text and image embeddings $\\mathcal{U}'$ and $\\mathcal{V}'$, and a\ndataset $\\mathcal{D}^*$ to be removed, then we have\n$L_{Batch}(\\mathcal{U}', \\mathcal{V}'; \\theta^{(-D^*)}) - L_{Batch}(\\mathcal{U}', \\mathcal{V}'; \\theta) \\approx \\nabla L_{Batch}(\\mathcal{U}', \\mathcal{V}'; \\theta)^T (\\theta^{(-D^*)} - \\theta)$\n$L_{Batch}(\\mathcal{U}', \\mathcal{V}'; \\theta^{(-D^*)}) - L_{Batch}(\\mathcal{U}', \\mathcal{V}'; \\theta) = -\\nabla L_{Batch}(\\mathcal{U}', \\mathcal{V}'; \\theta)^T \\cdot (positive-IF(\\mathcal{D}^*, Seg; \\theta) + negative-IF(\\mathcal{D}^*, Seg; \\theta))$\nwhere $\\theta^{(-D^*)}$ is the optimal model for the loss eliminating $\\mathcal{D}^*$, positive-IF($\\mathcal{D}^*$; Seg; $\\theta$) and\nnegative-IF($\\mathcal{D}^*$, Seg; $\\theta$) are obtained from Proposition 4.3 for $\\mathcal{D}^*$. We define term (8) as the task-\nrelated influence score, denoted as IS($\\mathcal{D}', \\mathcal{D}^*, Seg; \\theta$).\nRemark 5.2. Task-related influence score estimates the actual impact of a data subset on a spe-\ncific task. The sign of this score indicates whether the evaluated set $\\mathcal{D}^*$ has a positive or nega-\ntive impact on the correct execution of the test task, while the absolute value of the score repre-\nsents the magnitude of this impact. Therefore, the misalignment detection problem is sum up as\n$arg \\underset{\\mathcal{D}^* \\subset \\mathcal{D}}{max} IS(\\mathcal{D}', \\mathcal{D}^*, Seg; \\theta)$. See Appendix Algorithm 2 for details."}, {"title": "5.2 MISPREDICTION TRACE BACK", "content": "From a transparency perspective, if the model makes prediction errors on certain tasks, the model\ntrainers should be able to trace back to the samples in the training set associated with these erroneous\npredictions.\nIf we utilize the previous method for backtracking and choose the correct-labeled data which the\nmodel mispredicts to serve as the dataset $\\mathcal{D}'$, then there is a significant possibility that the identified\ndata are misaligned samples unrelated to the prediction errors. This is because, in the definition of\ntask-relative IS, the term on the right side of the multiplication sign represents the change in model\nparameters. Even if certain samples are not related to the task we are tracing back, they may still\nhave a high task-relative IS due to their substantial impact on the model parameters. Thus, compared\nto the above application, we need to constrain the change of model parameters.\nTo address this, consider imposing a constraint $\\delta$ on the permissible changes in model parameters\nwhen tracing back from mispredicted data, while accounting for the process of upweighting the\ninfluence of samples as positive by $\\epsilon$ and as negative by $\\zeta$. Then we transform the trace back\nproblem to identify which training example $x$ we should re-weight to most significantly impact the\nloss on the test sample set $\\mathcal{D}'$ when given a small permissible change in model parameters $\\delta$.\n$arg \\underset{x \\in \\mathcal{D}}{max} \\underset{\\epsilon,\\zeta}{max} |L_{Batch} (\\mathcal{U}', \\mathcal{V}'; \\theta + \\Delta \\theta_{\\epsilon,\\zeta}(x)) - L_{Batch}(\\mathcal{U}', \\mathcal{V}'; \\theta)| s.t. ||\\Delta \\theta_{\\epsilon,\\zeta}(x)||^2 < \\delta^2$\n$arg \\underset{x \\in \\mathcal{D}}{max} \\underset{\\epsilon,\\zeta}{max} |\\nabla L_{Batch}(\\mathcal{U}', \\mathcal{V}'; \\theta) \\Delta \\theta_{\\epsilon,\\zeta}(x)| s.t. || \\Delta \\theta_{\\epsilon,\\zeta}(x)||^2 < \\delta^2$,\nwhere $\\Delta \\theta_{\\epsilon,\\zeta}$ = $\\epsilon \\cdot positive-IF(x; \\theta) + (\\zeta - 1) \\cdot negative-IF(x; \\theta)$ is the model parameter change\nestimated by ECIF when the influence of sample $x = (x^T, x^I)$ is upweighted by $\\epsilon$ and $\\zeta$.\nProposition 5.3. Define $I = [positive-IF(x), negative-IF(x)]$. If the 2$\\times$2 matrix $I^T \\cdot I$ is irreversible,\nthen equation (10) is equivalent to\n$arg \\underset{x \\in \\mathcal{D}}{max} ||negative-IF(x;\\theta)||^{-1} |\\nabla L_{Batch}(\\mathcal{U}', \\mathcal{V}'; \\theta) \\cdot negative-IF(x; \\theta)|$.\nElse, $I^T \\cdot I$ is reversible, then (10) is equivalent to\n$arg \\underset{x \\in \\mathcal{D}}{max} ||\\nabla L_{Batch}(\\mathcal{U}', \\mathcal{V}'; \\theta)||^2 |\\nabla L_{Batch}(\\mathcal{U}', \\mathcal{V}'; \\theta)^T \\cdot I \\cdot [I^T \\cdot I]^{-1} \\cdot I^T \\cdot \\nabla L_{Batch}(\\mathcal{U}', \\mathcal{V}'; \\theta)|$."}, {"title": "6 EXPERIMENT", "content": "In our experiments, we will apply our above methods to tasks, including identifying influential data\n(harmful data and valuable data) for fine-tuning through the task-related influence score, mispredic-\ntions trace-back, and detecting misaligned data."}, {"title": "6.1 EXPERIMENTAL SETTINGS", "content": "Datasets. We employ three datasets for utility and efficiency evaluation and the misprediction\ntrace-back: FGVC-Aircraft dataset (Maji et al., 2013), Food101 dataset (Bossard et al., 2014), Flow-\ners102 dataset (Nilsback & Zisserman, 2008). For the identifying influential data experiments, we\ninclude Describable Textures Dataset(DTD) dataset (Sharan et al., 2014) except for the above ones.\nFor misalignment detection tasks, we use Cifar-10dataset (Krizhevsky, 2009), and Imagenette, a\nsmaller subset of 10 easily classified classes from Imagenet (Deng et al., 2009).\nAlgorithm. The tasks described below are direct implementations of the algorithms for the ap-\nplications in the previous section. Algorithm 1 functions as the foundational algorithm, offering\nmethods to calculate ECIF and providing model editing based on ECIF. Algorithm 2 and 3 com-\npute task-related IS in Property 5.1 to evaluate samples, indicating both the direction and intensity\nof their impact on the task. Meanwhile, Algorithm 4 is for relative-IS in Prop. 5.3, which aids in\ntracing back specific samples.\nBaselines and Evaluation Metric. We employ two baseline methods: Retrain and ECIF. Retrain:\nWe will finetune the CLIP from scratch after sample removal. ECIF: This method is a direct imple-\nmentation of Algorithm 1, utilizing positive and negative IF to modify the model for sample removal.\nWe utilize two main evaluation metrics to assess our models: accuracy and runtime (RT). Accuracy\nevaluates the model's performance by measuring the proportion of correctly classified instances out\nof the total instances. Runtime, measured in seconds, assesses the time required for each method to\nupdate the model.\nImplementation Details. Our experiments utilized an Nvidia V100-32G GPU and 10 CPU cores\nwith 64 GB memory. For all experiments, we employ the CLIP model \u2018ViT-B/16' and use\nLORA few-shot learning. For utility evaluation, when testing our method on a random sample-removing task,\n10% samples are randomly removed. For valuable (harmful) samples, we remove 10% of the valu-\nable (harmful) data identified by ECIF. Each removal is repeated for 3 times with different seeds."}, {"title": "6.2 UTILITY AND EFFICIENCY EVALUATION", "content": "We evaluate the utility and efficiency of ECIF for data evaluation, whose results are in Table 1.\nThe results underscore the superior performance of ECIF compared to classical retraining. Notably,\nECIF retains computational efficiency without sacrificing accuracy. We can easily observe that\nwith random data removal, ECIF achieves an accuracy nearly equivalent to retraining (84.8784.87\ncompared to 84.9384.93) while significantly reducing runtime from 14.5914.59 seconds to 7.287.28\nseconds on the Food101 dataset. A similar trend was observed in the Flowers102 dataset, where\nECIF reduces runtime from 16.5916.59 seconds for retraining to 7.297.29 seconds, along with a\nmodest 0.370.37 point improvement in accuracy. These findings demonstrate the ability of ECIF to\nsave approximately 4040-50\nWhen valuable data identified by ECIF are removed, the accuracy of both the retrained model and\nECIF's edited version closely align, and both are significantly lower than those observed with ran-\ndom removal. This suggests that ECIF is capable of not only accurately editing the model but also"}, {"title": "6.3 IDENTIFYING INFLUENTIAL DATA FOR FINE-TUNING VIA TASK-RELATED IS", "content": "Task-related IS can identify the most valuable data. To numerically assess the precision of data\nvaluation algorithms, we employ the brittleness test (Ilyas et al., 2022), which evaluates the al-\ngorithm's ability to accurately identify the most valuable data for a specific task. Our evaluation\nprocess is as follows: utilizing the validation set within Algorithm 2, we compute the task-related\nIS for each individual training data point. We then remove the top-k valuable data points, with k\nranging from 5% to 30%, retrain the model multiple times using different random seeds, and assess\nthe resultant change in overall model accuracy.\nResults in Figure 1b reveal that removing valuable data identified by ECIF leads to a consistent de-\ncline in model accuracy, from 84.7 to 84.1. Conversely, random data removal triggers an increase in\nmodel accuracy once the removal proportion reaches 0.3. This suggests Food101 contains substan-\ntial noise, and our algorithm can effectively identify data points that genuinely enhance the model's\npredictive accuracy.\nTask-related IS can identify harmful data. The influence analysis from Algorithm 2 identifies data\npairs with negative task-related IS as harmful data for the task. To demonstrate the effectiveness of\nour algorithm in identifying detrimental data to specific tasks, we conducted experiments on several\nnoisy datasets, such as Food101, and used the validation dataset in Algorithm 2.\nWe collected the harmful data identified by ECIF and then retrained the model multiple times with\nvarying harmful data removal ratios and different random seeds. We compared its accuracy to that\nof a model retrained after randomly removing an equivalent number of data points. Results in Figure\n1a demonstrate the effectiveness of our approach in improving model performance by eliminating\nharmful data using task-related IS. Figure 1a indicates that with varying proportions of harmful\ndata removal, the accuracy of the retrained model consistently fluctuates around its original level.\nWhen 10% of harmful data is removed, accuracy increases by approximately 1%. Conversely, with\nrandom deletions, accuracy continues to decrease. This suggests that the accuracy improvement\nfrom removing harmful data with ECIF is not merely due to the removal action itself but rather"}, {"title": "6.4 VISUALIZATION OF MISPREDICTION TRACE BACK", "content": "We apply Algorithm 4 to identify training data that are most relevant to specific mispredicted test\nsamples. In this process, we select samples in the test data on which the model made a misclassi-\nfication. Using the relative IS, we can identify the training data with the highest influence on the\nmisprediction and visualize it. Table 2 shows the results of this misprediction trace-back process\n(see Appendix F.4 for additional results). Each pair of images compares a test sample with its most\ninfluential training counterpart. On the left, we show examples from the test set where the model\nproduced incorrect predictions. On the right, the corresponding training data are shown, i.e., these\ndata points hold the highest relative ISs in relation to the mispredicted test samples. This compari-\nson helps shed light on how specific training samples may have contributed to the model's incorrect\noutputs. According to the visualization results, it can be observed that the samples traced back to\nthe original task exhibit similarities in shape or texture with the original task."}, {"title": "6.5 DATASET CLEANING: MISALIGNMENT DATA DETECTION", "content": "We employed the relative IF to detect misaligned data pairs. Regarding the selection of the validation\ndataset, we experimented with two approaches: randomly selecting samples from the gold dataset\n(Algorithm 2) and calculating based on the influence of the evaluated sample points (Algorithm 3),\nin which the test loss is defined as the CLIP score (Hessel et al., 2022) of the evaluated data pair.\nWe first mislabeled 10%-30% training samples and then identified the misaligned pairs by select-\ning those with the highest negative IS. These pairs are visualized in Table 3 (see Appendix F.5 for\nadditional results). The visualization results reveal that the 8 data points with the highest IS are en-\ntirely within the mislabeled data in our training set. This suggests that our algorithm has effectively\nidentified the noise data artificially introduced into the dataset."}, {"title": "7 CONCLUSION", "content": "In this paper, we introduced the Extended Influence Function for Contrastive Loss (ECIF), a novel\nmethod to quantify data valuation in MLLMs. ECIF provides a dual-perspective analysis of data\npoints by considering both positive and negative samples, offering a more comprehensive under-\nstanding of their impact on model performance. By utilizing a closed-form approximation, ECIF\neliminates the need for re-training, making it highly practical for large models. Our approach is\napplicable to enhancing fine-tuning, tracing mispredicted data, and detecting misaligned data, with\nresults demonstrating its effectiveness in real-world tasks."}, {"title": "A ALGORITHM", "content": "Algorithm 1 ECIF\n1: Input: Training Dataset D = {$(x^T, x^I)$}, dataset D* to be evaluated, the parameters $\\theta$ which\nis involved in IF calculation in the model and the regularization parameter $\\delta$.\n2: Define S(,) as the similarity score.\n3: Compute the text embedding and image embedding for D* as u and v.\n4: Random divide the training dataset D into MM batches and obtain the position index of D* as\nSeg = {($m, E_m$)|m $\\in$ S}.\n5: Compute the influence term as positive and negative samples for the m-th batch in S by:\n$Pos_m = \\sum_{n \\in E_m}(-log(\\frac{e^{S(u_n, u_n)}}{\\sum_{i=1}^N e^{S(u_n, v_j)}}) +\\frac{e^{S(u_n, u_n)}}{log\\sum_{i=1}^N e^{S(v_n, u_j)}}$.\n$Neg_m = \\sum_{i \\in [N]/E_m}(\\frac{e^{S(u_i, v_n)}}{\\sum_{j=1}^N e^{S(u_i, v_j)}})+\\frac{e^{S(v_i, u_n)}}{\\sum_{j=1}^N e^{S(v_i, u_j)}}$.\n6: Compute the sum of the gradient of $Pos_m$ and $Neg_m$ as\n$Pos = \\sum_{m \\in S} \\nabla_{\\theta} Pos_m$, and $Neg = \\sum_{m \\in S} \\nabla_{\\theta} Neg_m$.\n7: Compute the batch embedding for D as {$B_m, m\\in[M]$}.\n8: Compute the inverse Hessian matrix of the loss function with respect to $\\theta$ as\nG = (${\\sum_{m \\in [M]} L_{Batch}(B_m; \\theta) + \\delta \\cdot I}$)$^{-1}$\n9: Compute the positive-IF(D*, Seg) and negative-IF(D*, Seg) as:\npositive-IF(D*, Seg) = -G $\\cdot$ $Pos$, negative-IF(D*, Seg) = \u2212G $\\cdot$ $Neg$\n10: Obtain the ECIF as\nECIF(D*, D) = (positive-IF, negative-IF)\n11: Edit model parameter to unlearn dataset D* by\n$\\theta = \\theta$ \u2013 positive-IF \u2013 negative-IF\n12: Return: ECIF(D*, D), Edited parameter $\\theta$."}, {"title": "B ACCELERATION FOR INFLUENCE FUNCTION", "content": "LOGRA. For one layer, given the input xi, output x, and the weight W, the forward and backward\ncomputation can be written as $x_o = Wx_i, vec(\\Delta W) = \\sum_{t=1}^T x_{i,t} \\bigotimes \\Delta x_{o,t}, \\Delta x_i = W^T \\Delta x_o$, where\nT denotes for the sequence dimension in language modeling, $\\bigotimes$ the derivative with respect to the\nloss, the Kronecker product, and vec(\u00b7) the vectorization operation. Observing gradient vec($\\Delta$W)\nobtained during backpropagation is structured as a sum of Kronecker products between forward and\nbackward activations, LOGRA imposes an additional Kronecker-product structure on the projection"}, {"title": "C INFLUENCE FUNCTION IN CONTRASTIVE LEARNING", "content": "C.1 INFLUENCE FUNCTION FOR POSITIVE SAMPLES.\nWe first consider the influence function for positive samples.\nSingle Data Pair Version. To quantify the impact of $x^T$ and $x^I$ as positive samples, we first define\n$L_{T2I}(u_n, V_m; \\theta) + L_{I2T}(v_n, U_m; \\theta)$ as $Pos((x^T, x^I); \\theta)$. Following the idea of influence function,\nwe can up-weight these two parts by $\\epsilon$ and obtain an up-weighted loss function as\n$L_{Total,\\epsilon}(\\theta) = \\sum_{(U,V) \\in \\mathcal{B}} L_{Batch}(U, V; \\theta) + \\frac{\\delta}{2} ||\\theta||^2 + \\epsilon \\cdot Pos((x^T, x^I); \\theta)$"}, {"title": "C.2 INFLUENCE FUNCTION FOR NEGATIVE SAMPLES.", "content": "Then, we come to derive the influence function for the negative sample.\nIn this part, we will illustrate how we give an approximation function for the loss function in"}]}