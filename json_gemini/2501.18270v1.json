{"title": "The iToBoS dataset: skin region images extracted\nfrom 3D total body photographs for lesion detection", "authors": ["Anup Saha", "Joseph Adeola", "Nuria Ferrera", "Adam Mothershaw", "Gisele Rezze", "S\u00e9raphin Gaborit", "Brian D'Alessandro", "James Hudson", "Gyula Szab\u00f3", "Balazs Pataki", "Hayat Rajani", "Sana Nazari", "Hassan Hayat", "Clare Primiero", "H. Peter Soyer", "Josep Malvehy", "Rafael Garcia"], "abstract": "Artificial intelligence has significantly advanced skin cancer diagnosis by enabling rapid and accurate detection of malignant\nlesions. In this domain, most publicly available image datasets consist of single, isolated skin lesions positioned at the center\nof the image. While these lesion-centric datasets have been fundamental for developing diagnostic algorithms, they lack the\ncontext of the surrounding skin, which is critical for improving lesion detection. The iToBoS dataset was created to address\nthis challenge. It includes 16,954 images of skin regions from 100 participants, captured using 3D total body photography.\nEach image roughly corresponds to a 7 x 9 cm section of skin with all suspicious lesions annotated using bounding boxes.\nAdditionally, the dataset provides metadata such as anatomical location, age group, and sun damage score for each image.\nThis dataset aims to facilitate training and benchmarking of algorithms, with the goal of enabling early detection of skin cancer\nand deployment of this technology in non-clinical environments.", "sections": [{"title": "Background & Summary", "content": "Skin cancer is the most prevalent form of cancer globally, with Melanoma (MEL), Basal Cell Carcinoma (BCC), and Squamous\nCell Carcinoma (SCC) representing the most common malignancies. These cancers have reached epidemic proportions,\nunderscoring the critical need for effective diagnostic and monitoring solutions\u00b9. Traditionally, the diagnosis of skin cancer has\nrelied heavily on the expertise of dermatologists and the use of dermatoscopy. Dermatoscopy is a non-invasive approach that\nuses a dermoscope to enhance the view of the sub-macroscopic structures in pigmented skin lesions, which vary widely across\ndermatological conditions2,3. As a result, they provide critical cues, not only for the visual examination of suspicious lesions by\ntrained dermatologists but also for AI-based diagnostic tools4\u201311 that aid in differentiating between malignant and benign skin\nconditions. Consequently, most publicly available skin lesion datasets for training AI models are dominated by dermoscopic\nimages12-15.\nHowever, while dermoscopy has resulted in improved diagnostic precision, its reliance on specialised equipment and skilled\npractitioners poses significant barriers to early detection and triage. In such contexts, computer-aided diagnosis systems that\nutilise conventional camera images offer a more practical and scalable solution. These systems, designed to work with standard\nsmartphone cameras, can be deployed in resource-constrained environments, enabling non-specialist healthcare providers\u2014such\nas general practitioners or community health workers\u2014to identify potentially malignant lesions. 3D total-body photography\n(3D-TBP) is increasingly gaining recognition as a foundational tool in this regard16\u201318. Such imaging systems use a coordinated\nsetup of cameras to capture comprehensive, high-resolution views of almost the entire skin surface in a single session, providing\na detailed and holistic representation of a patient's skin. This not only provides a broader perspective for lesion analysis by\nincorporating the surrounding skin area that might be otherwise excluded when assessing a single localised lesion, but it can"}, {"title": "Methods", "content": "The process for generating the dataset involved three key phases: (i) data collection, (ii) data annotation, and (iii) public subset\nselection, as summarised in Figure 1. Phase (i), data collection, began with patient recruitment at two clinical sites, followed by\ncapturing 3D-TBP images using the VECTRA WB360 scanner and the extraction of 2D tiles from the 3D avatar. Phase (ii),\ndata annotation, included hosting these tiles on the iToBoS cloud platform, annotation and quality control. Finally, phase (iii)\ninvolved the careful selection of a public subset for release, resulting in the challenge dataset. Each of these phases is elaborated\nin the following subsections."}, {"title": "Data Collection", "content": "The study was conducted in two locations: Brisbane (Australia) and Barcelona (Spain). Participants in Australia were recruited\nvia email between October 2022 and April 2023 and provided online consent for the use of existing 3D-TBP images captured\nduring previous research visits, which took place from September 2016 to February 2020 using the VECTRA WB360 system."}, {"title": "3D-TBP image acquisition system of VECTRA WB360", "content": "Each participant underwent total body imaging using the VECTRA WB360 system. This imaging system was designed for\ncomprehensive skin documentation through efficient, high-resolution capture. The system utilizes 92 fixed cameras (arranged\nin 46 stereo pairs) and xenon flashes to photograph the entire exposed body in a single capture. To ensure standardised image\nquality, participants were instructed to maintain a specific anatomical position while the system captured detailed images using\nboth polarised and non-polarised lighting. The captured images were processed by the VECTRA software to create a precise\n3D avatar, enabling full 360-degree rotation for thorough examination of all body surfaces, including curved areas that are often\nchallenging to assess with traditional 2D imaging20. All imaging data was saved in DX2 format, a well-known file type used\nfor various applications, including medical imaging and dermatological assessments. Each DX2 file contains the original 2D\nimages, the reconstructed 3D avatar, and all associated metadata required for dermatological assessment."}, {"title": "2D tile generation from 3D-TBP avatar", "content": "The process of extracting images corresponding to 2D tiles of the skin surface from 3D avatars was accomplished using\nWbTilingTool, a specialised module within the VectraDBTool developed by Canfield Scientific. This tool was designed to\nstreamline and enhance image processing by automatically detecting the patient's head in 3D avatars and applying inpainting\ntechniques to mask facial features, ensuring patient anonymity. Its robust functionality includes batch processing, enabling the\nsimultaneous handling of multiple scans from various patients, significantly improving efficiency for large datasets.\nEach avatar was split into tiles with an average\ndimension of 1012\u00d7827 pixels (px), with a 45px overlap between adjacent tiles. This overlap was crucial for maintaining\nlesion visibility across tile boundaries, particularly important for lesions that might otherwise be split between tiles. Tiles at\nthe edges and bottom of the avatar had smaller dimensions to accommodate the natural boundaries of the body surface. This\nvariation in tile size occurred specifically at these boundary regions to ensure complete coverage of the avatar while avoiding\ntruncation. Each tile was tagged with its corresponding anatomical region to preserve the anatomical context. The images were\ncategorised into five anatomical regions plus an Unknown category for ambiguous cases, as summarised in Table 1. This step,\nalong with the extraction of metadata such as age and sex-at-birth from questionnaires collected from each participant, was"}, {"title": "Data annotation", "content": "The 2D tiles extracted from the 3D avatars were annotated by a team of 25 annotators coordinated by Isahit, a company\nspecialised in annotation services across various domains, including medical and image-based data. The team, consisting of\nmedical students, nurses and doctors, received specialised training to accurately identify and label skin lesions. At the beginning\nof the annotation process, the annotators were divided into two groups: labellers, responsible for the initial annotations, and\nreviewers, who ensured the quality of the annotations.\nThe labellers began by assessing the level of sun damage on each tile, assigning a severity tag from 1 to 3, with level 1\nindicating low and level 3 indicating high sun damage. Then, each lesion was outlined using a bounding box and its colour\nwas annotated to enhance characterisation. Each tile was also tagged if it contained any tattoos or identifiable marks, thereby\nproviding an additional layer of verification for challenging cases and enabling their subsequent annotation and masking.\nFinally, reviewers manually checked each tile to verify the accuracy of the annotations. If a tile met the quality standards, it was\nmarked as complete; otherwise, it was sent back to the labellers for re-annotation."}, {"title": "2D tiles hosted on iToBoS cloud", "content": "The iToBoS cloud, managed by the Computing and Automation Research Institute, HUN-REN SZTAKI, played a crucial role in\nthe annotation process by taking on two key responsibilities: providing secure storage for the 2D tiles and managing the transfer\nof these data to and from the V7 Darwin annotation platform. This process was handled via a NextCloud service, supported by\nHUN-REN's cloud infrastructure. NextCloud allowed for seamless data uploads and management within a structured directory\nsystem, with strict authentication and authorisation protocols to ensure that only authorised personnel could access these files.\nOnce the files to be annotated were gathered in specific folders on the NextCloud platform, the upload scripts were used to\ncreate datasets in V7 Darwin platform. Then, Isahit's annotators used these datasets to perform the necessary annotations on\nthe tiles. Therefore, dermatologists verified the Isahit annotation on V7 Darwin platform. After all datasets had been annotated\nand verified, the annotations were downloaded from V7 Darwin platform back into designated folders on NextCloud.\nThis workflow provided a flexible and asynchronous approach, facilitating the smooth transfer of primary data to NextCloud,\nas well as the generation and retrieval of derivative data, including the annotations, back into the system."}, {"title": "2D tiles annotation and review", "content": "The V7 Darwin platform was used to annotate the tiles. This platform provided facilities for viewing the tiles and included a\npre-defined set of tools, not only for polygonal annotation of lesions but also for assigning a sun damage score to each tile.\nThe assessment of sun damage provided additional information for lesion analysis, as areas with higher sun damage typically\npresented a greater risk for developing skin lesions and influenced their appearance and characteristics. A circular \"ruler\" with a\ndiameter of 2.5 mm was also provided with each tile to help the annotators determine the size of the lesions being annotated. In\nthis dataset, a minimum threshold of 2.5 mm was established because, although smaller lesions may occasionally be melanomas,\nthey are less common and often present significant diagnostic challenges21. In addition, V7 Darwin platform enabled the design\nand deployment of custom workflows. These workflows facilitated the assignment of lesion annotation and review tasks to\nIsahit's labellers and reviewers, followed by a final review by clinicians. The platform also enabled simultaneous operations\nby all participants in the workflow, allowing them to annotate lesions, add tags, accept or reject annotations, and provide\nfeedback, thereby streamlining the annotation process and ensuring efficiency across tasks. The workflows were modular and\nwere adjusted throughout the project to achieve the highest possible level of accuracy. For example, requirements for multiple\nreviewers in sequence were introduced as needed.\nThe annotation workflow began with the upload of tiles to the V7 Darwin platform. Within the\ndesigned workflow system, labeller were assigned batches of images to process. Once completed, the batch of images was\nautomatically routed to the next available labeller or reviewer depending on the assigned workflow. The labeller would assign\nsun damage and/or tattoo tags, as applicable, and triggered the \"Auto Annotate\" feature of V7 by creating rough bounding\nboxes around the lesions. This feature used a pre-trained segmentation model to automatically generate polygons for the lesions,\nwhich were subsequently refined to ensure accuracy. While the reviewer would conduct a quality control check for annotation\naccuracy. An example of masked (inpainting) tattoos is provided in Figure 5, which depicts certain examples of tiles that\ncontain masked tattoos."}, {"title": "Public subset selection", "content": "To select an optimal data subset for public release, we began by analysing potential dataset biases. We identified one extreme\ncategory: participants under 30 years of age, which only included two patients. These outlier cases were initially set aside to be\nstrategically distributed throughout the final train and test sets, ensuring that rare but clinically significant cases were preserved\nin public release. For the remaining tiles, we adapted the Wallace rule of nines22, a method traditionally used for assessing burn\nsurface area in dermatology, to establish sampling proportions across anatomical regions. This approach allocated 37.5% of the"}, {"title": "Acquiring ethical authorisation for data sharing", "content": "This study received the approval of two ethics committees: the Human Research Ethics Committee in Brisbane, Australia, and the\nHospital Clinic Barcelona Research Ethics Committee (REC) in Spain. The research was registered with ClinicalTrials.\ngov and conducted in accordance with Good Clinical Practice guidelines. All study procedures adhered to\nthe ethical principles outlined in the Declaration of Helsinki (1964). Findings from this research will be shared in peer-reviewed\njournals and presented at international scientific conferences."}, {"title": "Data Records", "content": "The dataset is available at https://www.kaggle.com/competitions/itobos-2024-detection/data and\nis organised in a manner that facilitates easy navigation and usability for research purposes. The dataset is released under a\nCreative Commons Non-Commercial Attribution (CC-BY NC) license, in accordance with the licensing terms and conditions\nagreed upon by the providing institutions. It comprises categorised image tiles in PNG format and their corresponding\nannotations in two formats: text files using YOLO format and JSON files using COCO format. Since this is a single-label\ndataset, all annotations are assigned the label '0'. Each subset (training and test) is accompanied by a metadata file in CSV\nformat that provides additional information for each image, including anatomical location, patient demographics (age and sex\nat birth), and sun damage score. The complete organisation of the dataset on Kaggle is illustrated in Figure 7.\nHowever, it should be noted that while the test set images and metadata are currently accessible, the corresponding labels\nwill remain private at least until the completion of the iToBoS lesion detection challenge."}, {"title": "Data Description", "content": "The dataset consists of 8,473 images in the training set and 8,481 images in the test set. In the training set, 6,723 images contain\nlesions (2,412 from Barcelona and 4,311 from Brisbane) and 1,750 images are without lesions (770 from Barcelona and 980\nfrom Brisbane). Similarly, the test set contains 6,750 images with lesions (3,633 from Barcelona and 3,117 from Brisbane) and\n1,731 images without lesions (914 from Barcelona and 817 from Brisbane). To better illustrate the composition of the dataset,\nwe present a comprehensive breakdown of the dataset characteristics in Table 2.\nAs shown in Table 2, the dataset maintains varying proportions between Barcelona and Brisbane. The training set exhibits an\napproximate 4:1 ratio of lesion to non-lesion cases, comprising 6,723 lesion cases and 1,750 non-lesion cases. Similarly, the"}, {"title": "Data Analysis", "content": "We analysed five key aspects of the dataset: (i) spatial distribution of lesions within images, (ii) bounding box properties,\n(iii) lesion size characteristics (including both categorisation and distribution), (iv) sun damage assessment, and (v) image\ndimensions.\nThe spatial distribution analysis examines the normalised locations of lesion centers across all images.\nTo create comparable spatial distributions regardless of original image dimensions, we normalised all bounding box center\ncoordinates by their respective image widths and heights. These normalised coordinates were then used to generate density\nheatmaps for both training and test sets. The resulting visualisation reveals an even distribution of lesions across the normalised\nimage space. To illustrate the difference in annotation density between sets, we highlight a sample circular region (r = 0.25,\ncentered at (0.3,0.3), marked by white dashed circle) where, like in other areas of the image, the test set shows higher\nannotation density compared to the training set, consistent with its larger number of total annotations. For analysing bounding\nbox characteristics, we collected all boxes in a common center to compare their sizes. The bounding boxes\nmaintain similar dimensions across both sets, with train set showing width $\\mu = 0.033\\pm0.021$, height $\\mu = 0.039\\pm0.024$, and\ntest set showing width $\\mu = 0.034\\pm0.019$, height $\\mu = 0.039\\pm0.022$.\nAnalysing lesion diameters, which we calculate as the maximum distance between any two points on the\nlesion boundary (hull distance) and convert to millimeters using the pixel size information, we grouped the lesions into three\nclinically relevant categories used by dermatologists in diagnosis: small (< 3mm), medium (3-5mm), and large (> 5mm).\nWe observed that the majority of lesions in both train and test sets fall within the 3-5mm range (train: 14,277, test: 15,900),\nfollowed by large (train: 9,655, test: 9,839) and small categories (train: 5,471, test: 4,855). The diameter distribution exhibits a right-skewed pattern, with a peak around 4mm and a long tail extending toward larger diameters. The\nmeasurements show similar ranges in both sets (train: min=0.14mm, max=56.37mm; test: min=0.28mm, max=92.62mm) with\nidentical means (train: $\\mu$ = 4.76, 2$\\sigma$ = 2.76 mm; test: $\\mu$ = 4.76, 2$\\sigma$ = 2.57 mm)."}, {"title": "Technical Validation", "content": "All annotated tiles were manually reviewed by a team of dermatologists to ensure the highest level of precision and reliability.\nThese experts carefully evaluated the quality of the annotations carried out by Isahit's labellers and reviewers, verifying their\nconsistency and accuracy in representing the required details. In cases where discrepancies or inaccuracies were identified, the\ndermatologists corrected the annotations themselves to align with the expected standards. This rigorous quality control process"}, {"title": "Usage Notes", "content": "Pixel sizes varied across images due to the different angles and distances between the skin of the patient and the configuration\nsettings of the VECTRA WB360 scanner at both data acquisition sites. When analysing lesion sizes, users are advised to\nconvert pixel measurements using the pixel spacing information provided in the metadata, rather than relying on raw pixel\ncounts, to ensure accurate physical dimensions. To protect patient privacy, name anonymisation process was implemented\nto ensure that multiple image tiles from the same patient remain untraceable. The dataset predominantly contains benign\nlesions, which users may observe when inspecting the types of lesions present in the images. While annotations underwent\ncareful review, users should note there may be occasional inconsistencies. For comprehensive understanding of the dataset\ncharacteristics, we direct readers to the statistical analysis in Appendix A."}, {"title": "Code availability", "content": "To support research with this dataset, we provide helper scripts in our GitHub repository for tasks such as data loading, preprocessing, and annotation visualisation. Users\nseeking additional information should consult the repository documentation or contact the dataset maintainers."}]}