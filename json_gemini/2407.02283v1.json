{"title": "A Refreshed Similarity-based Upsampler for Direct High-Ratio Feature Upsampling", "authors": ["Minghao Zhou", "Hong Wang", "Yefeng Zheng", "Deyu Meng"], "abstract": "Feature upsampling is a fundamental and indispensable ingredient of almost all current network structures for image segmentation tasks. Very recently, a popular similarity-based feature upsampling pipeline has been proposed, which utilizes a high-resolution (HR) feature as guidance to help upsample the low-resolution (LR) deep feature based on their local similarity. Albeit achieving promising performance, this pipeline has specific limitations in methodological designs: 1) HR query and LR key features are not well aligned in a controllable manner; 2) the similarity between query-key features is computed based on the fixed inner product form, lacking flexibility; 3) neighbor selection is coarsely operated on LR features, resulting in mosaic artifacts. These shortcomings make the existing methods along this pipeline primarily applicable to hierarchical network architectures with iterative features as guidance and they are not readily extended to a broader range of structures, especially for a direct high-ratio upsampling. Against these issues, we thoroughly refresh this pipeline and meticulously optimize every methodological design. Specifically, we firstly propose an explicitly controllable query-key feature alignment from both semantic-aware and detail-aware perspectives, and then construct a parameterized paired central difference convolution block for flexibly calculating the similarity between the well-aligned query-key features. Besides, we develop a fine-grained neighbor selection strategy on HR features, which is simple yet effective for alleviating mosaic artifacts. Based on these careful designs, we systematically construct a refreshed similarity-based feature upsampling framework named ReSFU. Comprehensive experiments substantiate that our proposed ReSFU is finely applicable to various types of architectures in a direct high-ratio upsampling manner, and consistently achieves satisfactory performance on different applications, including semantic segmentation, medical image segmentation, instance segmentation, and panoptic segmentation, showing superior generality and ease of deployment beyond the existing upsamplers. Codes are available at https://github.com/zmhhmz/ReSFU.", "sections": [{"title": "INTRODUCTION", "content": "As a fundamental ingredient in deep network architectures, feature upsampling aims to restore the spatial resolution of low-resolution (LR) features, which is widely used in image segmentation tasks, such as semantic segmentation [4], instance segmentation [5], and panoptic segmentation [6].\nDuring the feature upsampling process, each high-resolution (HR) feature element is typically estimated by weighting its neighboring elements from the input LR feature. To generate the weights (also known as the upsampling kernels [2], [7]), in recent years, various upsampling research lines have been proposed. Specifically, bilinear and nearest-neighbor interpolation are the most widely-adopted feature upsampling methods, which are implemented based on hand-crafted weighting rules and often cause blurry effects. To enhance the flexibility of feature upsampling, some studies have developed different content-aware dynamic upsamplers [7]\u2013[11]. For example, in [7], the authors devised a dynamic network to generate the upsampling kernel from LR features. Despite promising performance, they usually struggle to restore clear object boundaries due to the loss of fine-grained details in LR features.\nAgainst this issue, a novel similarity-based feature upsampling pipeline SAPA [2] has been proposed, which utilizes an HR feature y as the guidance to help accomplish"}, {"title": null, "content": "the upsampling process from the LR feature x to the HR one x. Taking the representative base version of SAPA as an example, the HR feature element \u017e\u2081 at pixel i is estimated as (see Sec. 3 for more details):\n$$x_i = \\text{Softmax}(s_i) X_{N(i)},$$\nupsampling kernel\n(1)\nwhere the HR query q and the LR key k are linear projections of y and \u00e6, respectively; N(i) is the neighborhood of i; the upsampling kernel is computed on the inner produced-based similarity between the query-key pair. We can easily see that the entire upsampling framework along the similarity-based pipeline is closely related to the design of three main components: \u25cf the acquisition of query-key features; \u25cf the similarity calculation manner between the query-key pair; \u25cf the neighbor selection N(i).\nAlbeit obtaining impressive success, we carefully delve into this pipeline and find that each of the aforementioned components in SAPA still suffers from unresolved issues. Specifically, considering that the HR guidance feature y is usually shallower than the LR deep feature \u00e6, only with the content-agnostic linear projection operation, the generated q and k are generally not well semantically aligned in a controllable manner. This would adversely interfere with the subsequent similarity calculation; The inner product-based similarity calculation manner in Eq. (1) lacks enough flexibility and often results in blurry effects in the upsampled features (see C4 in Fig. 1 (a)); From Eq. (1), the neighbor selection N(i) is coarsely executed on LR features k and \u00e6, which would incur mosaic artifacts, especially in a direct high-ratio upsampling (see x in Fig. 1 (c)).\nThese three methodological design limitations weaken the potential application of SAPA, making it usually only applicable to iterative \u00d72 upsampling structures with hierarchical guidances but less suitable for direct high-ratio upsampling without iterative features as guidance. For instance, for the hierarchical architecture SegFormer [1] with four levels of features as shown in Fig. 1 (a), to accomplish the \u00d78 upsampling from C4 to C4, SAPA, as well as other existing feature upsampling methods [7], [12], [13], performs three consecutive \u00d72 upsampling processes with C3, C2, and C1 as guidance features, respectively. Such an iterative pattern definitely leads to the laborious deployment of more upsampling modules. Besides, for the non-hierarchical structures, such as Segmenter [3] in Fig. 1 (c), the deep LR feature x requires a direct \u00d74 upsampling under the guidance of a shallow HR feature y. Without iterative guidance features, the upsampled feature x exhibits adverse visual artifacts. These issues generally exist in most of the current feature upsampling methods (see Sec. 5.2). Faced with this tricky scenario, is it possible to build an architecture-agnostic feature upsampling framework that is applicable to different types of network architectures and can always achieve satisfactory effects in direct high-ratio upsampling without complicated iterative processes?\nTo answer this question, in this paper, we meticulously refresh the pipeline in Eq. (1) and carefully optimize the involved three main components one by one. Then we propose a Refreshed Similarity-based Feature Upsampling framework, called ReSFU, with higher flexibility and better"}, {"title": null, "content": "universality, which can be easily embedded in a direct high-ratio upsampling manner for different architectures as shown in Figs. 1 (b) and (d). Specifically, our contributions are mainly four-fold:\n1) Firstly, we propose an explicitly controllable algorithm to finely align query-key features from both semantic-aware and detail-aware perspectives. Concretely, we utilize guided filter (GF) [14] to explicitly optimize the original linearly-projected HR query q and execute a controllable transformation on it to promote semantic alignment with the key. Meanwhile, we further investigate the HR query q itself and adopt an explicit Gaussian smoothing to help accomplish the HR feature self-alignment for better detail preservation. Such careful query-key alignment designs facilitate more accurate similarity computation and make it possible to flexibly select the guidance features, such as the cross-level guided high-ratio upsampling from C4 to C4 in Fig. 1 (b) without complicated iterative procedures as in SAPA.\n2) Secondly, for the well-aligned pairs, we propose a paired central difference convolution (PCDC) to inherently capture the local relevance between the query-key features, and then correspondingly construct a parameterized PCDC-Block to flexibly calculate the similarity between every pair. Compared with the non-parametric inner product in Eq. (1), the proposed PCDC-Block can help better ameliorate blurry artifacts, as experimentally validated by comparing C4 in Figs. 1 (a) and (b).\n3) Thirdly, we propose a fine-grained neighbor selection strategy by selecting the neighbors N(i) of every HR pixel i based on the bilinearly-upsampled HR version of the LR features k and x. Such a simple yet effective design introduces no extra parameters and can be seamlessly incorporated into our ReSFU framework with ease, which evidently reduces mosaic artifacts even in case of the direct high-ratio upsampling, as presented in Fig. 1 (d).\n4) Finally, by correspondingly replacing the three main components in Eq. (1) with our proposed aforementioned three designs, we systematically build ReSFU. Extensive experiments comprehensively demonstrate that compared to baselines, the proposed ReSFU consistently (i) achieves better results in direct high-ratio upsampling on various types of architectures, and (ii) shows superior generality across different segmentation tasks, such as, semantic/instance/panoptic segmentation, and across various types of datasets, including natural and medical images. Moreover, we provide detailed model visualizations and ablation studies to verify the working mechanism underlying ReSFU.\nThe rest of the paper is organized as follows: Sec. 2 introduces the related work. Sec. 3 reformulates and analyzes the current similarity-based feature upsampling framework based on experimental visualization. Sec. 4 presents the specific designs of our proposed ReSFU. Sec. 5 substantiates the effectiveness of our method through comprehensive experiments. Finally, Sec. 6 concludes the paper."}, {"title": "RELATED WORK", "content": null}, {"title": "Feature Upsampling", "content": "Guidance-Free Upsampling Methods. Nearest neighbor and bilinear interpolation are two widely adopted feature"}, {"title": null, "content": "upsampling methods that are implemented based on pre-defined distance-aware rules. For higher flexibility, several techniques have been proposed to learn the upsampling kernels in an end-to-end manner, such as Deconvolution [15]. PixelShuffle [8] is also commonly adopted to perform efficient sub-pixel convolution for upsampling, which rearranges the elements within the channel dimension to increase the spatial resolution. Although these approaches and their subsequent improvements [9]\u2013[11] achieve certain performance gains, they cannot dynamically adjust the upsampling kernels based on feature contents.\nRecently, CARAFE [7], [16] firstly proposed to dynamically learn the upsampling kernels from the to-be-upsampled LR features. Alternatively, DySample [13] generated the point sampling offsets of the upsampled pixels from the deep LR features. In these methods, the upsampling procedure can be dynamically adjusted based on deep LR features, further improving the upsampling flexibility. However, due to the loss of fine-grained details in deep LR features and the lack of HR guidance features, the upsampled features achieved by these guidance-free methods usually have blurry effects.\nGuidance-based Upsampling Methods. To enhance the detail recovery in upsampled features, a research line has been proposed to utilize the information from shallow HR features to guide the upsampling process [17], [18]. For example, IndexNet [19], A2U [20], and FADE [12] were developed in succession to generate the dynamic upsampling kernels from both the HR guidance and LR deep features. Along this line, SAPA [2], [21] proposed to generate the upsampling kernels by modelling the local similarity between HR guidance and LR deep features. FeatUp [22] introduced a multi-view consistency learning framework based on the stacked parameterized joint bilateral upsampler (JBU) [23] and an implicit multilayer perceptron (MLP) upsampler, respectively. The implicit version requires inference-time training, which is extremely time-consuming. In this paper, driven by the competitive performance of the latest representative SAPA, we follow its similarity-based feature upsampling framework, thoroughly analyze the inherent characteristics, and then specifically propose optimization designs for better upsampling effects."}, {"title": "Convolution Operators", "content": "To adapt to different application needs, many convolution operators have emerged as replacements for standard convolution in recent years [24]. For instance, based on local binary pattern [25], LBC [26], [27] proposed a set of fixed sparse pre-defined binary convolutional filters, which can significantly save the computational overhead while approximating the capability of traditional convolutional layers. CDC [28]\u2013[31] constructed a specific convolution based on central difference maps to capture boundary information. Along this line, PDC [32], [33] further considered the difference between different pixel pairs and SDC [34] introduced both central difference and similarity into the convolution design. They have been effectively applied to vision tasks, such as face anti-spoofing, edge detection, and semantic segmentation. These convolution operators are usually executed on a single input feature. However, in this"}, {"title": null, "content": "paper, we aim to novelly design a convolution operation for flexible similarity computation between a pair of content-aligned input features."}, {"title": "Image Segmentation", "content": "In this field of computer vision, image segmentation is a fundamental task in widespread applications, such as medical imaging [35] and autonomous driving [36], which includes semantic segmentation [4], instance segmentation [5], and panoptic segmentation [6]. The goal is to predict semantic labels or delineate individual instances of objects in images, helping provide essential scene understanding.\nAgainst these tasks, various network architectures have been constructed in the past few years. For example, for scene parsing and semantic segmentation of natural images, CNN-based PSPNet [37] and DeepLab-V3+ [38] achieved prominent outcomes by utilizing atrous convolutions and spatial pyramid pooling to effectively capture multi-scale information. Inspired by the successful application of Transformer in computer vision [39], [40], various Transformer-based network architectures have been proposed for semantic segmentation, such as Segmenter [3], SegFormer [1], and SegNeXt [41], which demonstrated impressive performance by leveraging the power of long-range dependencies. For instance segmentation, Mask R-CNN [42] and its variants [43]\u2013[45] have been widely used due to the robust performance. For panoptic segmentation, the representative Panoptic FPN [6], UPSNet [46], and EfficientPS [47] sequentially consist of two procedures, i.e., semantic segmentation and instance segmentation. Besides, the U-shape network architectures [35], [48]\u2013[50] have been broadly utilized for medical image segmentation. Recently, researchers [51]\u2013[53] explored an alternative approach to the traditional pixel-wise classification and proposed to adopt a Transformer-based decoder for mask classification, which shows remarkable performance in different image segmentation tasks.\nFor these network architectures, the spatial size of intermediate features usually gradually reduces to efficiently encode high-level semantic information, and thus feature upsampling is an indispensable module for the final prediction. In this paper, we aim to design a general feature upsampling framework, which can be easily encapsulated into various structures for more accurate segmentation."}, {"title": "REVISITING SIMILARITY-BASED FEATURE UPSAMPLING PIPELINE", "content": "In this section, we carefully reformulate and delve into the current similarity-based feature upsampling pipeline.\nGiven an LR deep feature $x \\in \\mathbb{R}^{hw \\times C}$ and an HR guidance feature $y \\in \\mathbb{R}^{HW \\times c}$, the existing similarity-based feature upsampling framework SAPA [2], [21] aims to upsample x to an HR deep feature $\\hat{x} \\in \\mathbb{R}^{HW \\times C}$ under the guidance of y. Specifically, for each HR pixel $i \\in \\{1,...,HW\\}$, the HR deep feature element $\\hat{x}_i \\in \\mathbb{R}^{C}$ is generally estimated by weighting its neighboring LR deep feature elements based on an upsampling kernel Softmax(si) as:\n$$\\hat{x}_i = \\text{Softmax}(s_i)X_{N(i)},$$\n1For simplicity, we aggregate the spatial dimensions H \u00d7 W as HW."}, {"title": null, "content": "where $X_{N(i)} \\in \\mathbb{R}^{K^2 \\times C}$ denotes the neighboring LR feature elements of pixel i; $|N(i)| = K^2$ is the number of neighboring LR pixels with a pre-defined kernel size K; $s_i \\in \\mathbb{R}^{K^2}$ is the similarity scores assigned to the $K^2$ neighbors of pixel i. In the representative base version of SAPA [2], si is computed as:\n$$s_i \\triangleq \\text{sim}(q_i, k_{N(i)}) \\triangleq q_i^T k_{N(i)},$$\n(3)\nwhere q and k are linear projections of y and \u00e6, respectively, with D channels; $q_i \\in \\mathbb{R}^D$ is the i-th feature element of $q \\in \\mathbb{R}^{HW \\times D}$; $k_{N(i)} \\in \\mathbb{R}^{K^2 \\times D}$ represents the $K^2$ neighboring feature elements of pixel i in $k \\in \\mathbb{R}^{hw \\times D}$; $\\text{sim} (\\cdot,\\cdot)$ is a general similarity function, designed as the inner product between $q_i$ and $k_{N(i)}$ in SAPA. We regard q, k, and x as the HR query, LR key, and LR value features, respectively.\nAs seen, the entire similarity-based feature upsampling pipeline is strongly associated with the design of three main parts: query-key feature acquisition for facilitating the computation of similarity si; the similarity function $\\text{sim} (\\cdot,\\cdot)$; neighbor selection $N (i)$. For better understanding, based on the backbone Segmenter-S with a direct \u00d74 upsampling for the last-layer feature under the guidance of a shallow feature (see Fig. 10), we experimentally visualize SAPA in Fig. 2 (a) and identify the following issues:\n1) Uncontrollable Query-Key Alignment. In such a direct high-ratio upsampling case, the HR guidance feature y is relatively shallow and it generally contains low-level information, such as texture patterns, while the LR deep feature x usually contains high-level semantics [40], [54]. Since the linear projection operation with fixed weights is not sensitive to the content of either y or x, the linearly-projected query and key cannot be well-aligned in the feature space without extra control, which would seriously mislead the subsequent similarity computation.\n2) Inflexible Similarity Computation. The conventional inner product operation in Eq. (3) is non-parametric and lacks flexibility in capturing the relations between the query and key. Directly adopting this inner product form would cause that within a small local region N(i), the computed K\u00b2 scores $q_i^T k_{N(i)}$ are close to each other (see Fig. 6 (a)). This would consequently generate an overly smooth upsampling"}, {"title": null, "content": "kernel, leading to blurry artifacts in the upsampled \u017e.\n3) Coarse Neighbor Selection. From Eqs. (2) and (3), the neighbors N(i) of pixel i are correspondingly selected on the LR key k and the LR value \u00e6, respectively. This manner is coarse. Specifically, taking the neighbor selection on k as an example, as shown in Fig. 2 (a), for the \u00d74 upsampling, all the sixteen pixels in the 4 \u00d7 4 red box marked in q share identical neighbors, i.e., the nine pixels marked in k. On the other hand, for two adjacent pixels i and j in q from two different 4 \u00d7 4 boxes, the selected neighbors N(i) and N(j) in k would differ abruptly. Such a grid-wise neighbor selection strategy on LR features often results in mosaic artifacts in \u00e6, especially for a direct high-ratio upsampling.\nThese limitations in methodological designs constrain that most of the existing feature upsampling methods along this similarity-based pipeline are always injected into network backbones in a step-by-step \u00d7 2 upsampling manner. They are generally suitable for hierarchical architectures with the iterative upsampling process, like SegFormer in Fig. 1 (a), and are difficult to be extended to more types of backbones, such as non-hierarchical architectures with a direct high-ratio upsampling, like Segmenter in Fig. 1 (c)."}, {"title": "METHOD", "content": "Motivated by the analysis in Sec. 3, in this section, we aim to refresh the current similarity-based feature upsampling framework by carefully optimizing every involved component in Eqs. (2) and (3), including query-key alignment, similarity computation, and neighbor selection. Then we correspondingly construct a more flexible and universal upsampling framework, called ReSFU, which has the potential to adapt to various network structures.\nSpecifically, as shown in Fig. 2 (b), we first propose a controllable query-key feature alignment method from both semantic-aware and detail-aware perspectives. Then, we design a specific paired central difference convolution (PCDC) block for flexibly calculating the similarity between the aligned query-key pairs. Finally, we devise a fine-grained neighbor selection (FNS) strategy to alleviate mosaic artifacts. For each part, the detailed designs are given below."}, {"title": "Explicitly Controllable Query-Key Alignment", "content": "From [40], [54], an HR guidance feature y from a shallow layer usually captures more detail-related information while the LR deep feature x encodes more semantic-related information. Thus, we informally refer to y (and its linear projection, the query feature q) and \u00e6 (and its linear projection, the key feature k) as residing in the detail space and the semantic space, respectively, as presented in Fig. 3.\nConfronted with the representational discrepancy between the detail and semantic spaces, it is inaccurate to directly calculate the similarity score between the original query-key feature pair, i.e., q and k, across different spaces. To fully capture and exploit the relations among different neighboring pixels that share similar information both at the detail and semantic levels for guiding the upsampling process, we propose a two-pronged approach to explicitly transform the original features and generate two query-key pairs aligned in detail space and semantic space, respectively, to facilitate accurate similarity computation. Please refer to the lower row of Fig. 3 for the overall design."}, {"title": "Semantic-Aware Mutual-Alignment", "content": "Firstly, our goal is to project the original query q into the semantic space so that it can better align with the key feature k in the semantic space, while also preserving the structural details in the detail space. To this end, inspired by the guided filter (GF) [14], [55], we propose to linearly transform q in every local window for detail preservation while minimizing the distance between the transformed query and the key k for the mutual-alignment in the semantic space. In this manner, the structural information of q can be efficiently integrated with the semantic information of k into the transformed query [14].\nMathematically, let $q^{GF} \\in \\mathbb{R}^{HW \\times D}$ be the transformed query and each of its element $(q^{GF})_{id}$ can be estimated via solving the following optimization problem [14]:\n$$\\min_{m_{jd},n_{jd}} \\sum_{i \\in I_j}\\left(((q^{GF})_{id} - k_{id})^2 + \\epsilon m_{jd}^2\\right),$$\ns.t. $(q^{GF})_{id} = m_{jd}q_{id} + n_{jd}, \\forall i \\in I_j,$\n(4)\nwhere $(q^{GF})_{id}$, $q_{id}$, and $k_{id}$ are the feature elements of $q^{GF}$, q, and k at pixel i and channel d, respectively; $k \\in \\mathbb{R}^{HW \\times D}$ is the bilinearly upsampled HR result of the original LR key k; $d \\in \\{1, ..., D\\}$; $m_{jd}$ and $n_{jd}$ are linear coefficients for pixel j at channel d; $I_j$ is a square window with radius r centered at pixel $j \\in \\{1,...,HW\\}$; and \u0454 is a small regularization weight. In experiments, the radius r is experimentally set to 8 and \u0454 is set to 0.001. Please note that for element-wise minimization computation in Eq. (4), we adopt the upsampled key feature k for keeping the same size with $q^{GF}$, which also belongs to the semantic space.\nFrom [56], the explicit solution of Eq. (4) can be easily derived as:\n$$m_{jd} = \\frac{\\sum_{i \\in I_j} I_{id}k_{id} - \\mu_I \\mu_k}{\\sigma^2_I + \\epsilon}, n_{jd} = \\bar{k} - m_{jd} \\bar{q},$$\n(5)\nwhere $\\bar{I} = \\sum_{i \\in I_j} I_{id}$, $\\mu_q = \\bar{I} / |I_j|$, and $\\sigma^2_I = \\mu_I^2 - \\bar{I}^2$", "latex": true}, {"title": null, "content": "as $\\bar{k} = \\sum_{i \\in I_j} k_{id}$; and $|I_j|$ is the number of pixels contained in the local window $I_j$, which is $r^2$.\nSince a pixel i is involved in different overlapping window $I_j$ that covers the pixel i, $(q^{GF})_{id}$ would change with these local windows. Following [14], by averaging all these overlapping local windows $I_j$, we can get the final transformed query as:\n$$(q^{GF})_{id} = \\frac{1}{N} \\sum_{j \\in I_i} m_{jd}q_{id} + n_{id},$$\n(6)\nwhere $m_{id} = \\frac{1}{N} \\sum_{j \\in I_i} m_{jd}$ and $n_{id} = \\frac{1}{N} \\sum_{j \\in I_i} n_{jd}$.\nAs seen, the optimized query $q^{GF}$ is explicitly derived on the basis of the original query q and key k, achieving the controllable alignment with key in the semantic space. From Eq. (3), for the explicitly optimized query-key pair $q^{GF}$ and k, the similarity $(s_s)_i$ for pixel i is calculated as:\n$$(s_s)_i \\triangleq \\text{sim}((q^{GF})_i, k_{N(i)}).$$       (7)\nWe call ss \u2208 RHW \u00d7K\u00b2 as semantic-aware mutual similarity.\nRemark 1: From the visualization in Fig. 2 (b), we can clearly observe that: 1) compared to the original linearly-projected query q, the explicitly optimized query $q^{GF}$ exhibits a stronger semantic resemblance to the key k. This can promote more accurate semantic-aware similarity computation of ss for better performance (see Sec. 5.3.2); 2) $q^{GF}$ effectively preserves the original intricate structures in q, which would guide the upsampling to achieve a higher structural fidelity in the upsampled feature \u017e (also see Fig. 16). All these advantages finely comply with our design motivation for Eq. (4) and substantiate its rationality."}, {"title": "Detail-Aware Self-Alignment", "content": "In addition to the semantic space, we also seek to fully exploit the structural information in the detail space and generate the aligned query-key pair in this space for better guiding the upsampling process. Unfortunately, unlike the"}, {"title": null, "content": "semantic space, it is hard to project the key feature into the detail space to achieve the query-key mutual-alignment. This is because that deep semantic information is more abstract and the features in the detail space generally reside in a higher-dimensional manifold than that in the semantic space. For example, in Fig. 3, the blue and green boxes highlight areas belong to the same semantic category, i.e., house, with closer distance in the semantic space. However, they possess highly diverse detail information, i.e., roof and wall, with farther distance in the detail space. In this case, it is hardly feasible to find a proper projection to finely transform the original key k to the detail space, which can reproduce the level of detail variations in the query feature.\nConfronted with the above issue, we propose a detail-aware self-alignment approach that exploits the query in the detail space to generate the aligned key feature for the space. One intuitive way is to directly regard q as both the query and key features in the detail space. However, we further analyze that to avoid significant fluctuations in local similarity scores, the real key feature is generally expected to have the property of smoothness [39], [57], like the original key k in the semantic space containing minimal semantically irrelevant noises. Motivated by this analysis, we propose to execute a simple Gaussian smoothing operator on q to suppress high-frequency noisy details to obtain a smoothed key feature $q^{GS} \\in \\mathbb{R}^{HW \\times D}$.\nThen, for pixel i, the self-similarity $(s_d)_i$ for the aligned pair q and qGs in the detail space is computed as:\n$$(s_d)_i \\triangleq \\text{sim}(q_i, (q^{GS})_{N(i)}),$$\n(8)\nwhere $q^{GS} = f \\otimes q$ and $f \\in \\mathbb{R}^{3 \\times 3}$ represents the Gaussian filter with the unit standard deviation. Here $s_d \\in \\mathbb{R}^{HW \\times K^2}$ is the detail-aware self-similarity.\nAs seen, on the basis of the original linearly-projected query q and k, we introduce explicit optimization controls to further make them better aligned from both semantic-aware and detail-aware perspectives. Correspondingly, for our method, the similarity score si in Eq. (2) is designed as:\n$$s_i = (s_s)_i + (s_d)_i.$$\n(9)\nPlease note that the similarity function sim (\u00b7, \u00b7) for computing ss and sa is implemented based on learnable parameterized form as formulated in Sec. 4.2 below. Hence, it is unnecessary to assign extra weighting coefficients on these two terms ss and sd in Eq. (9).\nRemark 2: 1) The rationality of the detail-aware self-alignment can be explained from another perspective. Specifically, it is well-acknowledged that within a small local region of a relatively shallow feature, if two pixels exhibit similarity in detail structures, there is a high likelihood that they should possess similar semantics in the upsampled feature \u017e [58]. Thus, it is reasonable to exploit the self-similarity on query q itself for guiding the upsampling process; 2) The incorporation of the detail-aware similarity favorably encourages fine-grained detail preservation and the smoothed key generation design would indeed bring some performance improvement as validated in Sec. 5.3.2."}, {"title": "PCDC for Flexible Similarity Calculation", "content": "To compute ss and sa in Eq. (9), instead of adopting the fixed inner product-based manner for sim(,) in [2], [21], here we aim to specifically design a parameterized convolution operation to flexibly model the inherent relevance between every query-key pair, i.e., qGF and k, q and qGs, for more accurate similarity calculation."}, {"title": "Paired Central Difference Convolution", "content": "For a vanilla convolution layer with G groups, given an arbitrary input $x \\in \\mathbb{R}^{HW \\times D}$ with D input channels, each element vil in the convolution result $v \\in \\mathbb{R}^{HW \\times L}$ with L output channels is calculated by:\n$$v_{il} = \\sum_{d=gD/G}^{(g+1)D/G-1} \\sum_{n=1}^{K^2} w_{ndl} x_{ind} + b_l, j_n \\in N(i),$$\n(10)\nwhere i is the pixel index; the output channel index $l \\in \\{0, . . ., L \u2212 1\\}$; $g = \\lfloor \\frac{d}{D/G} \\rfloor$ is the group index ranging from 0 to G \u2013 1; d is the input channel index; $j_n \\in N(i)$ indexes a neighbor of the pixel i, with n = 1,\u2026\u2026, $K^2$; $w_{ndl}$ is an element of $w \\in \\mathbb{R}^{K^2 \\times D/G \\times L}$ representing the grouped convolution weights; the index d = d%(\ub05d), where % is the modulo operation; $b \\in \\mathbb{R}^{L}$ is the bias.\nInspired by the ability of central difference convolution [28] in combining the flexibility of learnable convolution and the awareness of local gradient information, here we propose a paired central difference convolution (PCDC) to capture the relations between the query and key features. Specifically, following the framework of the vanilla grouped convolution in Eq. (10), we replace its input with the \"paired central difference\" between any aligned query-key pair, q and k, and then obtain the PCDC output v as:\n$$v_{il} = \\sum_{d=gD/G}^{(g+1)D/G-1} \\sum_{n=1}^{K^2} w_{ndl} (k_{ind} - \\hat{q}_{id}) + b_l, j_n \\in N(i).$$\n(11)\nFor a better understanding of the working mechanism of the proposed PCDC, we provide a visual illustration of Eq. (11) with the kernel size K as 3. As observed from Fig. 4, through the learnable convolution weights, the differences between the central query element $\\hat{q}_i$ and its neighboring key el-ements $k_{j_n}$ can be well captured and flexibly processed. Naturally, the PCDC output v has the capability to encode the local similarity information between \u011f and k."}, {"title": "PCDC-Block for Similarity Calculation", "content": "Based on the capability of the proposed PCDC in capturing the local similarity between the query-key pair, here we construct a PCDC-Block to finally implement the function sim(,) for similarity computation as given in Fig. 5.\nConcretely, for each aligned query-key pair, i.e., qGF and k, q and qgs, they are first separately input to a group normalization layer with shared affine parameters to get the normalized query-key pair \u012b and k. Then the normalized pair is passed through a PCDC computation layer, i.e., Eq. (12), to obtain the intermediate result v. Then by feeding v to a channel compressor to transform the channel number from L to K2, we can get the corresponding similarity scores for every query-key pair, i.e., ss and sd. Here the channel compressor is sequentially composed of a 1 \u00d7 1 convolution layer, a ReLU layer, a group normalization layer, and a 1\u00d71 convolution layer, where these two convolution layers are both with 4 groups and the intermediate channel size is 128."}, {"title": null, "content": "Equivalently", "as": "n$$v_{il} = \\sum_{d=gD/G}^{(g+1)D/G-1} \\sum_{n=1}^{K^2} w_{ndl} k_{ind}$$\n$$- (\\sum_{d=gD/G}^{(g+1)D/G-1} \\sum_{n=1}^{K^2} w_{ndl}) \\hat{q}_{id} + b_l, j_n \\in N(i).$$\n(12)\nWe can find that the proposed PCDC inherently consists of a vanilla grouped convolution on k with weight w (the first term in Eq. (12)), and a 1 \u00d7 1 convolution on \u011f with the weight as the aggregation of w in the spatial dimension (the second term in Eq. (12)). These operations can be easily and efficiently implemented based on PyTorch [59"}]}