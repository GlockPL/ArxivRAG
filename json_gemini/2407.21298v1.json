{"title": "A Vectorization Method Induced By Maximal Margin Classification For Persistent Diagrams", "authors": ["An Wu", "Yu Pan", "Fuqi Zhou", "Jinghui Yan", "Chuanlu Liu"], "abstract": "Persistent homology is an effective method for extracting topological information, represented as persistent diagrams, of spatial structure data. Hence it is well-suited for the study of protein structures. Attempts to incorporate Persistent homology in machine learning methods of protein function prediction have resulted in several techniques for vectorizing persistent diagrams. However, current vectorization methods are excessively artificial and cannot ensure the effective utilization of information or the rationality of the methods. To address this problem, we propose a more geometrical vectorization method of persistent diagrams based on maximal margin classification for Banach space, and additionaly propose a framework that utilizes topological data analysis to identify proteins with specific functions. We evaluated our vectorization method using a binary classification task on proteins and compared it with the statistical methods that exhibit the best performance among thirteen commonly used vectorization methods. The experimental results indicate that our approach surpasses the statistical methods in both robustness and precision.", "sections": [{"title": "I. INTRODUCTION", "content": "Topological data analysis (TDA) is a computational technique which has been developed to study the topological structure of data over the past 20 years [4], [5]. The theoretical foundation of TDA is the algebraic topology, and combined with computer technology TDA has been applied to various practical problems, such as image processing, material structure analysis and quantum computing to name a few as in [7], [17], [26] and [24].\nThe primary methods in Topological Data Analysis are persistent homology and Mapper, and we focus on the persistent homology approach in this paper. Based on the persistent homology there are many interesting works. The research team led by Rongling Wu implemented GLMY homology theory proposed by Shing-Tung Yau to analyze and interpret the topological change of health state from symbiosis to dysbiosis, and they successfully described the topological difference and commonality between Crohn's disease and ulcerative colitis [30]. Perea introduced how to combine dynamical systems and topological data analysis to gain insights from time-varying data [27]. For more applications of persistent homology, one can refer to the review paper of Chazal and Michel [6]. Previous works have primarily focused on classification problems as an application of persistent homology. This is because the number of bars in the barcode (Betti numbers) offers a direct measure for classification, or because researchers can define similar functions (such as bottleneck distance and p-Wasserstein distance) based on the persistent diagrams. However, if we want to combine persistent diagrams with more advanced artificial intelligence technologies, there is a critical problem that most machine learning algorithms assume that the input data is from Rn or, more generally, some Hilbert space, but the space of persistent diagrams is not a vector space even if they are from the similar samples. Hence we want to find a reasonable embedding of persistent diagrams which can be a pre-encoder for any other topological artificial intelligence frameworks.\nMany researchers have tried to solve this problem which is called vectorization. Barnes, Polanco and Perea provided a comparative study of six such methods and they applied and compared popular machine learning methods on five data sets [2]. Chung and Lawson developed a framework of vectorization and showed several well-known summaries fall in this framework [9]. In [11] and [12], stable vector representations were developed and these methods were tested on several data sets to show their effectiveness and efficiency. Ali et al. [1] summarized thirteen vectorization methods, and they examined these methods on three well-known classification tasks. They discovered that the best-performing method is a simple vectorization by a few statistics. Besides these methods, there are numerous approaches of vectorization as in [8], [22]"}, {"title": "II. MAXIMAL MARGIN CLASSIFICATION METHOD", "content": "In this section, we will introduce the main idea of TDA first. Then we will review the principle of the maximal margin classification for Banach spaces, and one can check the details in the publication of Hein, Bousquet and Sch\u00f6lkopf [16]. In particular, we will regard the space of persistent diagrams as a Banach space, which allows us to analyze the space of persistent diagrams by maximal margin classification."}, {"title": "A. The topological data analysis", "content": "The main idea of TDA is to find some topological features to describe the difference of data. As an example, assume we have a deflated balloon. When we inflate it, it remains a balloon, because this process is a continuous transformation. However, if we blow in enough gas to cause an explosion, it ceases to be a balloon and becomes a \"burst balloon\". Hence the topological feature that distinguishes burst balloons from intact balloons is the presence or absence of holes in the balloons. By popularizing this idea, researchers have developed a major technique in TDA called persistent homology [4], [13]. The word \"persistent\" means that there is a continuous variation of a parameter which is call the filtration. If we can construct a series of complexes suitable with the continuous variation, then the homological information of the complexes illustrate the topological structure of data. For example, Fig. 2 shows the process of increasing the radius of points, and it is easy to find that the topological structure of top left three points is different to that of bottom right two points, as the former would create a hole.\nBased on this idea, persistent homology is good at dealing with classification tasks, and the topological features are usually taken as the connect components, holes, and voids which are denoted by Hi,i = 1,2,3 respectively. Typically, there are two visualization methods for this information, known as the persistent diagram and the barcode, which are essentially equivalent to each other. In Fig. 3, we show both visualizations of topological information extracted from Fig. 2."}, {"title": "B. The maximal margin classification", "content": "Considering the space of persistent diagrams Xpd, we can define a distance function d(\u00b7,\u00b7) on Xpd to make it a metric space (Xpd, d). In practical problems, the number of generated persistent diagrams is always finite, then we can assume that d(X, Y) is bounded for any sample X, Y \u2208 Xpd, and we use the same symbol Xpd to denote the subspace generated by sample set. Hence we obtain a compact metric space (Xpd, d), which can be embedded into a Banach space isometrically by the observation of Kuratowski as in [16], [21].\nLet Cb (Xpd) be the Banach space of continuous and bounded functions on Xpd endowed with infinite norm ||.||\u221e. Take an arbitrary point 20 \u2208 Xpd and define a map from Xpd to real-valued functions on Xpd\n\n$\\varphi : x \\rightarrow \\varphi_x := d(x, \\cdot) - d(x_0,\\cdot)$.\n\nThen consider the space D := span{$\\varphi_x : x \\in Xpd$}, in which the closure is taken in (Cb(Xpd), ||.||\u221e), we have the following lemma:\nLemma 2.1: $ is a total isometric embedding from (Xpd, d) into the Bananch space (D, ||.||\u221e) \u2282 (Cb(Xpd), ||.||\u221e).\nThrough Lemma 2.1, we can transform the data processing problem on space (Xpd, d) to that on space (D, ||.||\u221e). In the current paper, we focus on the maximal margin classification of persistent diagrams. Recall that, the margin formulation on a Banach space is\n\n$\\min_{W'\\in D',b\\in R} ||W'||$\n\ns.t. $y_j((W',\\varphi_{x_j})_{D',D} + b) \\geq 1,\\forall j = 1,\\ldots,n,$\n\nwhere D' is the dual space of D, yj is the label corresponding to x_j and the product $(W', \\varphi_{x_j})_{D',D}$ is naturally defined by W' (;)."}, {"title": "III. EXPERIMENTS AND ANALYSIS", "content": "In this section, we will illustrate our experiments of maximal margin classification of persistent diagrams. We will apply our Banach space based method, which will be referred as BS method in the following context, to the classification of proteins. Then we will compare the experiment results of BS method with two widely used methods which are based on dimension reduction techniques. Finally, I will analyze the significance of BS method and its applications in the exploration of novel proteins."}, {"title": "A. Experiment Setup", "content": "Our experimental setup employs a server equipped with an Intel\u00ae Xeon\u00ae CPU E7-4870 operating at a frequency of 2.40 GHz, and we use the Python library ripser [3], [29] to compute persistent homology. For solving the quadratic programming problem, we use the quadratic programming solver CVX\u041e\u0420\u0422."}, {"title": "B. Dataset", "content": "The original dataset we deal with consists of 161 protein PDB files of Cas-associated proteins and 197 files of transposases, and our goal is to classify these proteins correctly. Each PDB file includes the coordinates of atoms in the proteins, and it is easy to extract these coordinate information from PDB files. After extracting the atomic coordinates, the traditional approach of TDA is computing the persistent homology of the atomic point clouds directly. However, this methodology encounters computational challenges, particularly in the calculation of the second persistent homology group (H2), which is often exceedingly difficult and necessitates substantial computational expenditures. The main reason is that compared to general chemical molecules and structural materials, proteins are typically composed of tens of thousands of atoms. But when calculating homology information of H2, it is necessary to traverse all combinations of four atomic interactions. Therefore, in this paper, we modify the persistent homology method at the beginning."}, {"title": "C. Preprocessing", "content": "We extract the topological information of protein atomic point clouds according to the following approach. Firstly, we derive the coordinates of 358 proteins from the input files. Subsequently, we construct the residue connection matrix of each protein based on the relative positions of the Ca atoms. For more details, we consider the Ca atoms within a protein as nodes, and an edge is created between two Ca atoms if the inter-atomic distance is below this established threshold of 5 angstroms (\u00c5). Following the construction of residue connection matrices, we can use graph embedding methods to generate point clouds which include less points than the original atomic point clouds. There are many graph embedding methods, and here we choose Node2vec [14] method to generate new point clouds. After the embedding of residue connection matrices, we calculate the persistent homology of point clouds including Ho, H\u2081 and H2. With the topological features captured, the final step is preprocessing of these topological information. We set a cutoff of 0.01 to filter out H\u2081 and H2 information whose persistent times are shorter than this value. We summarize the topological feature extraction algorithm as Algorithm 1."}, {"title": "D. Baselines and Main Method", "content": "After the modified persistent homology, we will get persistent diagrams with three components H1, H2 and H3 which are essentially point sets. Next, we will introduce three widely used topological features analysis methods which are based on different statistics as baselines for our BS method as follows:\n\nStatistical Method I [7], [30]: We count the cardinality of each point set for persistent diagram PD, which is equivalent to the persistent Betti number, directly to construct a 3-dimensional feature vector vi. And the first element is normalized by multiplying with a factor 0.01.\n\nStatistical Method II: We compute the statistical information (the maximum, the minimum, the variance, the mean"}, {"title": "E. Results and Analysis", "content": "We perform five-fold cross-validation experiments and continuously increase the proportion of training data for all methods mentioned before. The experimental results are presented in the following Table I.\nThe accuracies of the BS method and Statistical methods are noted to increase with the expansion of the training set size. While the Statistical method I has relatively small change around 84%-85%, which means this method exhibits robustness. As a comparison, the Statistical method II and III are more sensitive to the size of training date, and these methods have lower accuracies in the case with small training set. It is worth mentioning that Statistical methods require manual feature selection, and this example demonstrates that different feature selection approaches have a significant impact on the accuracy. Therefore, it needs a prior understanding of the original data which will impact the feature selection.\nHowever, our BS method uses the information of all features and has a fixed processing procedure, which reduces errors that may arise from poor feature selection. Moreover, the BS method also has robustness, and when the training date size reaches eighty percent, BS method becomes the best method in accuracy. More importantly, the BS method is more generalizable. Because for any persistent diagrams with more topological information (H4, H5,\u2026), we can also define a distance function like Eq. (10) and we can apply the neural network to determine the weight vector W in practice."}, {"title": "F. Case Study", "content": "In the end, we will illustrate the classification of proteins in the view of biology and propose a framework of finding new proteins with certain functions by topological data analysis.\nFor giving a biological explanation, we take 80% of the data to be the training set randomly and use the remaining data to test as well as to build an evolutionary tree. In Fig. 4, we show the evolutionary tree and in experiment result we find that 7 proteins have been misclassified. These proteins are 'z7m9a', 'c5vgb', 'c6eyy', 'c6jhv', 'c6jhw', 'c7msl' and 'c7tun', in which we use the characters \"c\" and \"z\" to denote Cas-associated proteins and transposases respectively.\nIt is obvious that, Fig. 4 can be primarily divided into two components: the upper component mainly consists of Cas-associated proteins, while the lower component mainly consists of transposases. And we find that classification errors can be divided into two parts:\n\nType I: The first involves the occurrence of another class of proteins within a particular category (such as 'c5vgb', 'c6eyy', 'c6jhv', 'c6hjw' and 'c7msl').\nType II: The second involves the presence of errors in the crossover region in which both classes of proteins appear alternatively (such as 'z7m9a' and 'c7utn').\n\nHowever, if we focus on the instances of misclassification, we find that the reason for Type I error is that the sample classification can be further refined, whereas the reason for Type II error is that the sample classification is overly granular. In details, Cas-associated proteins can be further subdivided into Cas proteins and anti-Cas proteins. Particularly, we find that proteins 'c5vgb', 'c6eyy', 'c6jhv', 'c6jhw' and 'c7msl' are anti-Cas proteins as in [15], [19], [23] and [18] which are distinct from the majority of other Cas-associated proteins, hence they are misclassified. On the other hand, proteins 'z7m9a' and 'c7utn' are Cas proteins as well as transposases as in [25] and [28], and the fact suggests that this dual nature has resulted in their misclassification. Therefore, our classification methodology aligns with the established principles and demonstrates superior performance."}, {"title": "G. Framework for Protein Function Prediction", "content": "Moreover, Type II error approves a new method for discovering novel proteins with specific functionalities. For example, if a transposase in the crossover region is misclassified, we can suspect reasonably that it exhibits structural and functional features similar to those of Cas proteins. Finally, we summarize this framework for exploring protein functions by their spatial structures in Fig. 1:\n\nIn the first step, we input the PDB files {f;} of proteins with a known specific function and {gi} of validation proteins;\nIn the second step, we calculate the topological information for every PDB file from its spatial structure;\nIn the third step, we conduct the binary classification task described in Section II to differentiate between the sets {fj} and {gi} using our vectorization method of persistent diagrams;\nFinally, we confirm those proteins with the second type of error and identify the subset {gk} of proteins that exhibit this function."}, {"title": "IV. CONCLUSION AND DISCUSSION", "content": "We propose a novel vectorization method, which not only attains the best performance in processing topological infor- mation compared with conventional methods but also exhibits robustness against the size of the training dataset, to analysis persistent diagrams. We derive the process for handling persistent diagrams using the maximal margin classification method of a Banach space, and discover that once the metric space of persistent diagrams is embedded by Kuratowski's embedding then the final result is equivalent to an encoder that calculates the distances between a given persistent diagram and all other diagrams. Hence our result proposes a more reasonable feature selection which use more topological information extracted than statistical methods that are the best method between thirteen alternative methods [1].\nAnother result with more profound implications for biology is that we propose a framework of using spatial topological information of proteins to identify their functions. Because we find that in our binary classification experiment, the second type of error typically arises from proteins that belong to both classes. Therefore, to verify whether certain proteins possess a specific function, we need only focus on whether they would result in a Type II error when classified alongside proteins which are known to exhibit this function.\nAs a byproduct of our processing, we have optimized the persistent homology algorithm for protein analysis, therefore its computational efficiency is enhanced and it is permitted to calculate the second Betti number."}, {"title": "B. Discussion", "content": "In future work, we plan to investigate that whether the Banach space based method can be improved by following modifications:\n\nFirst, we intend to examine the performance of our method across various distances;\nSecond, we plan to combine our method with neural network methods;\nFinally, we aim to propose additional vectorization methods for persistent diagrams, informed by geometric perspectives\nIn the derivation process of the BS method, we used information from the distance function. Compared to traditional methods of comparing persistence diagrams, such as the bottleneck distance, the theoretical computational complexity of our method is lower because it does not require enumerating all possible matchings. However, we may get a better performance distance by training the metric matrix with the neural network.\nOur method can be integrated with the neural network in more aspects, because our method maps proteins into a vector space of relative topological information, and this vector representation offers greater interpretability. In our subsequent work, we will combine the vectorization approach presented in this paper with neural networks to address further problems related to the spatial structure of proteins.\nFinally, since the vectorization method proposed in this paper originates from a geometric embedding, we aim to consider more vectorization methods inspired by other geometric structures such as Lie groups and homogeneous spaces. Particularly, we can choose different embedding methods"}]}