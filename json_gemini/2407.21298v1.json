{"title": "A Vectorization Method Induced By Maximal Margin Classification For Persistent Diagrams", "authors": ["An Wu", "Yu Pan", "Fuqi Zhou", "Jinghui Yan", "Chuanlu Liu"], "abstract": "Persistent homology is an effective method for extracting topological information, represented as persistent diagrams, of spatial structure data. Hence it is well-suited for the study of protein structures. Attempts to incorporate Persistent homology in machine learning methods of protein function prediction have resulted in several techniques for vectorizing persistent diagrams. However, current vectorization methods are excessively artificial and cannot ensure the effective utilization of information or the rationality of the methods. To address this problem, we propose a more geometrical vectorization method of persistent diagrams based on maximal margin classification for Banach space, and additionaly propose a framework that utilizes topological data analysis to identify proteins with specific functions. We evaluated our vectorization method using a binary classification task on proteins and compared it with the statistical methods that exhibit the best performance among thirteen commonly used vectorization methods. The experimental results indicate that our approach surpasses the statistical methods in both robustness and precision.", "sections": [{"title": "I. INTRODUCTION", "content": "Topological data analysis (TDA) is a computational technique which has been developed to study the topological structure of data over the past 20 years [4], [5]. The theoretical foundation of TDA is the algebraic topology, and combined with computer technology TDA has been applied to various practical problems, such as image processing, material structure analysis and quantum computing to name a few as in [7], [17], [26] and [24].\nThe primary methods in Topological Data Analysis are persistent homology and Mapper, and we focus on the persistent homology approach in this paper. Based on the persistent homology there are many interesting works. The research team led by Rongling Wu implemented GLMY homology theory proposed by Shing-Tung Yau to analyze and interpret the topological change of health state from symbiosis to dysbiosis, and they successfully described the topological difference and commonality between Crohn's disease and ulcerative colitis [30]. Perea introduced how to combine dynamical systems and topological data analysis to gain insights from time-varying data [27]. For more applications of persistent homology, one can refer to the review paper of Chazal and Michel [6]. Previous works have primarily focused on classification problems as an application of persistent homology. This is because the number of bars in the barcode (Betti numbers) offers a direct measure for classification, or because researchers can define similar functions (such as bottleneck distance and p-Wasserstein distance) based on the persistent diagrams. However, if we want to combine persistent diagrams with more advanced artificial intelligence technologies, there is a critical problem that most machine learning algorithms assume that the input data is from Rn or, more generally, some Hilbert space, but the space of persistent diagrams is not a vector space even if they are from the similar samples. Hence we want to find a reasonable embedding of persistent diagrams which can be a pre-encoder for any other topological artificial intelligence frameworks.\nMany researchers have tried to solve this problem which is called vectorization. Barnes, Polanco and Perea provided a comparative study of six such methods and they applied and compared popular machine learning methods on five data sets [2]. Chung and Lawson developed a framework of vectorization and showed several well-known summaries fall in this framework [9]. In [11] and [12], stable vector representations were developed and these methods were tested on several data sets to show their effectiveness and efficiency. Ali et al. [1] summarized thirteen vectorization methods, and they examined these methods on three well-known classification tasks. They discovered that the best-performing method is a simple vectorization by a few statistics. Besides these methods, there are numerous approaches of vectorization as in [8], [22]"}, {"title": "II. MAXIMAL MARGIN CLASSIFICATION METHOD", "content": "In this section, we will introduce the main idea of TDA first. Then we will review the principle of the maximal margin classification for Banach spaces, and one can check the details in the publication of Hein, Bousquet and Sch\u00f6lkopf [16]. In particular, we will regard the space of persistent diagrams as a Banach space, which allows us to analyze the space of persistent diagrams by maximal margin classification.\nConsidering the space of persistent diagrams $X_{pd}$, we can define a distance function $d(\\cdot,\\cdot)$ on $X_{pd}$ to make it a metric space $(X_{pd}, d)$. In practical problems, the number of generated persistent diagrams is always finite, then we can assume that $d(X, Y)$ is bounded for any sample $X, Y \\in X_{pd}$, and we use the same symbol $X_{pd}$ to denote the subspace generated by sample set. Hence we obtain a compact metric space $(X_{pd}, d)$, which can be embedded into a Banach space isometrically by the observation of Kuratowski as in [16], [21].\nLet $C_b(X_{pd})$ be the Banach space of continuous and bounded functions on $X_{pd}$ endowed with infinite norm $||\\cdot||_{\\infty}$. Take an arbitrary point $x_0 \\in X_{pd}$ and define a map from $X_{pd}$ to real-valued functions on $X_{pd}$:\n$\\varphi : x \\rightarrow \\varphi_x := d(x, \\cdot) - d(x_0,\\cdot)$.\nThen consider the space $D := span{\\varphi_x : x \\in X_{pd}}$, in which the closure is taken in $(C_b(X_{pd}), ||\\cdot||_{\\infty})$, we have the following lemma:\nThrough Lemma 2.1, we can transform the data processing problem on space $(X_{pd}, d)$ to that on space $(D, ||\\cdot||_{\\infty})$. In the current paper, we focus on the maximal margin classification of persistent diagrams. Recall that, the margin formulation on a Banach space is\n$\\min ||W'||$\n$W'\\in D',b\\in R$\n$s.t. y_j(\\langle W',\\varphi_{x_j} \\rangle_{D',D} + b) \\geq 1,\\forall j = 1,\\ldots,n,$\nwhere $D'$ is the dual space of D, $y_j$ is the label corresponding to $\\varphi_{x_j}$; and the product $\\langle W', x_i \\rangle_{D',D}$ is naturally defined by $W'(\\varphi_i)$.\nThen inspired by the theory of maximal margin classification for Banach spaces [16], we embed $(X_{pd}, d)$ into the Banach space $C_b(X_{pd})$ by Kuratowski's embedding, then we consider the maximal margin classification for space $C_b(X_{pd})$. As a result, we transform the maximum margin problem into a classical quadratic programming problem as Eq. (9). Moreover, in the derivation process, we find the following result:\nTheorem 1.1: Given a set of persistent diagram $X_{pd}$ endowed with metric d, we define the vectorization $X_{pd} \\rightarrow R^n$ by $x \\rightarrow (d(x,x_1),\\ldots,d(x, x_n))$, where $x_i \\in X_{pd}$ and n is the cardinal number of $X_{pd}$. In addition, this simple vectorization method corresponds to the quadratic programming problem Eq. (9).\nNext, we apply the maximal margin classification for persistent diagrams on the data of Cas-associated proteins, which are closely related to gene editing technology as in [10] and [20], and transposases. We choose a simple distance defined by Eq. (10) which requires less computation than the bottleneck distance, and we compare our method with statistical methods which are the best-performing methods in the thirteen vectorization methods [1] mentioned before. As a consequent, our method achieves superior performance both in robust and accuracy.\nFinally, we present a framework that uses the TDA processing methodology introduced in this paper to predict proteins with specific functions, and the total framework is exhibited in Fig. 1. We will discuss more details in Section III.\nLemma 1.1: A compact metric space can always be embedded into a Banach space.\nThen we can solve the challenge above on a Banach space.\nIn the current paper, we focus on the space $(X_{pd}, d)$ generated by finite persistent diagrams endowed with a fixed metric."}, {"title": "III. EXPERIMENTS AND ANALYSIS", "content": "In this section, we will illustrate our experiments of maximal margin classification of persistent diagrams. We will apply our Banach space based method, which will be referred as BS method in the following context, to the classification of proteins. Then we will compare the experiment results of BS method with two widely used methods which are based on dimension reduction techniques. Finally, I will analyze the significance of BS method and its applications in the exploration of novel proteins.\nOur experimental setup employs a server equipped with an Intel\u00ae Xeon\u00ae CPU E7-4870 operating at a frequency of 2.40 GHz, and we use the Python library ripser [3], [29] to compute persistent homology. For solving the quadratic programming problem, we use the quadratic programming solver CVX\u041e\u0420\u0422.\nThe original dataset we deal with consists of 161 protein PDB files of Cas-associated proteins and 197 files of transposases, and our goal is to classify these proteins correctly. Each PDB file includes the coordinates of atoms in the proteins, and it is easy to extract these coordinate information from PDB files. After extracting the atomic coordinates, the traditional approach of TDA is computing the persistent homology of the atomic point clouds directly. However, this methodology encounters computational challenges, particularly in the calculation of the second persistent homology group (H2), which is often exceedingly difficult and necessitates substantial computational expenditures. The main reason is that compared to general chemical molecules and structural materials, proteins are typically composed of tens of thousands of atoms. But when calculating homology information of H2, it is necessary to traverse all combinations of four atomic interactions. Therefore, in this paper, we modify the persistent homology method at the beginning.\nWe extract the topological information of protein atomic point clouds according to the following approach. Firstly, we derive the coordinates of 358 proteins from the input files. Subsequently, we construct the residue connection matrix of each protein based on the relative positions of the Ca atoms. For more details, we consider the Ca atoms within a protein as nodes, and an edge is created between two Ca atoms if the inter-atomic distance is below this established threshold of 5 angstroms (\u00c5). Following the construction of residue connection matrices, we can use graph embedding methods to generate point clouds which include less points than the original atomic point clouds. There are many graph embedding methods, and here we choose Node2vec [14] method to generate new point clouds. After the embedding of residue connection matrices, we calculate the persistent homology of point clouds including Ho, H\u2081 and H2. With the topological features captured, the final step is preprocessing of these topological information. We set a cutoff of 0.01 to filter out H\u2081 and H2 information whose persistent times are shorter than this value. We summarize the topological feature extraction algorithm as Algorithm 1.\nBy using the residue connection matrix and graph embedding, we reduce the number of points in the point clouds. Hence, it is foreseeable that the aforementioned approach to extracting topological features will have a substantial time-saving advantage. In addition, because we only use the inter-atomic distances of the Ca atoms, some information is inevitably omitted, which is acceptable in our experiment.\nThe results of preprocess is that the computation time required for calculating H1, H2, and H3 using the modified persistent homology approach is comparable to the time taken for calculating H\u2081 and H2 using the original persistent homology method, with both processes approximately lasting around 10 days. Roughly speaking, this implies that the new persistent homology algorithm omits certain two-dimensional topological information, and the computational resources saved are redirected towards the calculation of three-dimensional topological information. Although not the focus of this paper, it is worth mentioning that this strategy has a distinct advantage in that it introduces three-dimensional information that was previously unavailable, which will finally provide an additional weight parameter for learning in other machine learning processes.\nAfter the modified persistent homology, we will get persistent diagrams with three components H1, H2 and H3 which are essentially point sets. Next, we will introduce three widely used topological features analysis methods which are based on different statistics as baselines for our BS method as follows:\n*   Statistical Method I [7], [30]: We count the cardinality of each point set for persistent diagram PD, which is equivalent to the persistent Betti number, directly to construct a 3-dimensional feature vector vi. And the first element is normalized by multiplying with a factor 0.01.\n*   Statistical Method II: We compute the statistical information (the maximum, the minimum, the variance, the mean value and the median) for 5 indicators, corresponding to the birth or death times of H1, H2 and H3, to generate the feature vector of each persistent diagram. Then we extract a 25-dimensional feature vector for each persistent diagram.\n*   Statistical Method III: We apply the feature vectors proposed in the Definition 3.1 of the survey paper [1]. This statistical vectorization method incorporates more statistical information than the two methods mentioned above, and it is the best-performing method of the thirteen alternative methods in three well-known classification tasks.\nIn comparison with the statistical methods, the BS method needs a distance function d to make the space of persistent diagrams Xpd be a metric space. In this paper, we define the distance function as follows:\n$d(X, Y) := \\sum_{i=1}^{3} w_i d_i (X,Y), \\forall X,Y \\in X_{pd}$,\nwhere $d_i(X, Y)$ is the maximum Euclidean distance between $H_i$-components of persistent diagrams X and Y, and W = ($w_1, w_2, w_3$) is weight vector which is fixed as (1/3, 1/3, 1/3) in our experiment.\nIn order to compare the effects of different vectorization methods, we apply all methods on the dataset by soft-SVM to obtain classification results.\nThe accuracies of the BS method and Statistical methods are noted to increase with the expansion of the training set size. While the Statistical method I has relatively small change around 84%-85%, which means this method exhibits robustness. As a comparison, the Statistical method II and III are more sensitive to the size of training date, and these methods have lower accuracies in the case with small training set. It is worth mentioning that Statistical methods require manual feature selection, and this example demonstrates that different feature selection approaches have a significant impact on the accuracy. Therefore, it needs a prior understanding of the original data which will impact the feature selection.\nHowever, our BS method uses the information of all features and has a fixed processing procedure, which reduces errors that may arise from poor feature selection. Moreover, the BS method also has robustness, and when the training date size reaches eighty percent, BS method becomes the best method in accuracy. More importantly, the BS method is more generalizable. Because for any persistent diagrams with more topological information (H4, H5,\u2026), we can also define a distance function like Eq. (10) and we can apply the neural network to determine the weight vector W in practice.\nIn the end, we will illustrate the classification of proteins in the view of biology and propose a framework of finding new proteins with certain functions by topological data analysis. For giving a biological explanation, we take 80% of the data to be the training set randomly and use the remaining data to test as well as to build an evolutionary tree. In Fig. 4, we show the evolutionary tree and in experiment result we find that 7 proteins have been misclassified. These proteins are 'z7m9a', 'c5vgb', 'c6eyy', 'c6jhv', 'c6jhw', 'c7msl' and 'c7tun', in which we use the characters \"c\" and \"z\" to denote Cas-associated proteins and transposases respectively.\nIt is obvious that, Fig. 4 can be primarily divided into two components: the upper component mainly consists of Cas-associated proteins, while the lower component mainly consists of transposases. And we find that classification errors can be divided into two parts:\n*   Type I: The first involves the occurrence of another class of proteins within a particular category (such as 'c5vgb', 'c6eyy', 'c6jhv', 'c6hjw' and 'c7msl').\n*   Type II: The second involves the presence of errors in the crossover region in which both classes of proteins appear alternatively (such as 'z7m9a' and 'c7utn').\nHowever, if we focus on the instances of misclassification, we find that the reason for Type I error is that the sample classification can be further refined, whereas the reason for Type II error is that the sample classification is overly granular. In details, Cas-associated proteins can be further subdivided into Cas proteins and anti-Cas proteins. Particularly, we find that proteins 'c5vgb', 'c6eyy', 'c6jhv', 'c6jhw' and 'c7msl' are anti-Cas proteins as in [15], [19], [23] and [18] which are distinct from the majority of other Cas-associated proteins, hence they are misclassified. On the other hand, proteins 'z7m9a' and 'c7utn' are Cas proteins as well as transposases as in [25] and [28], and the fact suggests that this dual nature has resulted in their misclassification. Therefore, our classification methodology aligns with the established principles and demonstrates superior performance."}, {"title": "G. Framework for Protein Function Prediction", "content": "Moreover, Type II error approves a new method for discovering novel proteins with specific functionalities. For example, if a transposase in the crossover region is misclassified, we can suspect reasonably that it exhibits structural and functional features similar to those of Cas proteins. Finally, we summarize this framework for exploring protein functions by their spatial structures in Fig. 1:\n*   In the first step, we input the PDB files {fj} of proteins with a known specific function and {gi} of validation proteins;\n*   In the second step, we calculate the topological information for every PDB file from its spatial structure;\n*   In the third step, we conduct the binary classification task described in Section II to differentiate between the sets {fj} and {gi} using our vectorization method of persistent diagrams;\n*   Finally, we confirm those proteins with the second type of error and identify the subset {gk} of proteins that exhibit this function."}, {"title": "IV. CONCLUSION AND DISCUSSION", "content": "We propose a novel vectorization method, which not only attains the best performance in processing topological infor-mation compared with conventional methods but also exhibits robustness against the size of the training dataset, to analysis persistent diagrams. We derive the process for handling persistent diagrams using the maximal margin classification method of a Banach space, and discover that once the metric space of persistent diagrams is embedded by Kuratowski's embedding then the final result is equivalent to an encoder that calculates the distances between a given persistent diagram and all other diagrams. Hence our result proposes a more reasonable feature selection which use more topological information extracted than statistical methods that are the best method between thirteen alternative methods [1].\nAnother result with more profound implications for biology is that we propose a framework of using spatial topological information of proteins to identify their functions. Because we find that in our binary classification experiment, the second type of error typically arises from proteins that belong to both classes. Therefore, to verify whether certain proteins possess a specific function, we need only focus on whether they would result in a Type II error when classified alongside proteins which are known to exhibit this function.\nAs a byproduct of our processing, we have optimized the persistent homology algorithm for protein analysis, therefore its computational efficiency is enhanced and it is permitted to calculate the second Betti number.\nIn future work, we plan to investigate that whether the Banach space based method can be improved by following modifications:\n*   First, we intend to examine the performance of our method across various distances;\n*   Second, we plan to combine our method with neural network methods;\n*   Finally, we aim to propose additional vectorization methods for persistent diagrams, informed by geometric perspectives\nIn the derivation process of the BS method, we used information from the distance function. Compared to traditional methods of comparing persistence diagrams, such as the bottleneck distance, the theoretical computational complexity of our method is lower because it does not require enumerating all possible matchings. However, we may get a better performance distance by training the metric matrix with the neural network. Our method can be integrated with the neural network in more aspects, because our method maps proteins into a vector space of relative topological information, and this vector representation offers greater interpretability. In our subsequent work, we will combine the vectorization approach presented in this paper with neural networks to address further problems related to the spatial structure of proteins.\nFinally, since the vectorization method proposed in this paper originates from a geometric embedding, we aim to consider more vectorization methods inspired by other geo-metric structures such as Lie groups and homogeneous spaces. Particularly, we can choose different embedding methods"}]}