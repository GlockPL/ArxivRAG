{"title": "Agentic LLMs in the Supply Chain: Towards Autonomous Multi-Agent Consensus-Seeking", "authors": ["Valeria Jannelli", "Stefan Sch\u00f6pf", "Matthias Bickel", "Torbj\u00f8rn Netland", "Alexandra Brintrup"], "abstract": "This paper explores how Large Language Models (LLMs) can automate consensus-seeking in supply chain management (SCM), where frequent decisions on problems such as inventory levels and delivery times require coordination among companies. Traditional SCM relies on human consensus in decision-making to avoid emergent problems like the bullwhip effect. Some routine consensus processes, especially those that are time-intensive and costly, can be automated. Existing solutions for automated coordination have faced challenges due to high entry barriers locking out SMEs, limited capabilities, and limited adaptability in complex scenarios. However, recent advances in Generative AI, particularly LLMs, show promise in overcoming these barriers. LLMs, trained on vast datasets can negotiate, reason, and plan, facilitating near-human-level consensus at scale with minimal entry barriers. In this work, we identify key limitations in existing approaches and propose autonomous LLM agents to address these gaps. We introduce a series of novel, supply chain-specific consensus-seeking frameworks tailored for LLM agents and validate the effectiveness of our approach through a case study in inventory management. To accelerate progress within the SCM community, we open-source our code, providing a foundation for further advancements in LLM-powered autonomous supply chain solutions.\nSDG 9: Industry, innovation and infrastructure", "sections": [{"title": "1. Introduction", "content": "Supply chain management (SCM) requires continuous decision-making during day-to-day operations, on a multitude of problems ranging from inventory planning to delivery scheduling (Christopher 2016). As supply chains are interdependent systems of multiple companies, these decisions often need to be made via consensus between self-interested companies. Here, consensus-seeking is defined as a process that involves multiple parties interacting to reach a decision, whereby each party, in our case a supply chain firm, has different beliefs and goals. However, all parties have a common interest in reaching an agreement on selecting the best decision. Within the context of supply chains, consensus-seeking is closely related to supply chain coordination - defined as \"collaborative working for joint planning, joint product development, mutual exchange of information and integrated information systems, cross coordination on several levels in the companies on the network, long-term cooperation and fair sharing of risks and benefits\u201d (Skjoett-Larsen 2000). A common example of consensus-seeking occurs in demand planning, where participants along a chain need to agree on appropriate order quantities. Failure to achieve consensus results in the bullwhip effect, where small demand changes can cause large production fluctuations (Lee, Padmanabhan, and Whang 1997a,b). Coordination and consensus form a rich part of supply chain management research, from a range of disciplinary input and discourse on information asymmetry and information sharing, planning and uncertainty, the role of technology and other coordination instruments such as contracts.\nThis paper focuses on a subset of supply chain consensus-seeking problems, that could benefit from automated handling using AI. Decisions on delivery quantities, order frequency, and capacity allocation are given frequently and often involve situations where end-to-end coordination would yield superior solution outcomes (Xu et al. 2024; Viswanadham 2002). However end-to-end coordination requires manual orchestration, which in turn requires time and resources to be allocated to consensus building among self-interested supply chain actors. While humans are able to solve complex consensus tasks, they are limited in the volume of tasks they can fulfil in a given time window as illustrated in Fig. 1. End-to-end consensus itself is a particularly difficult task that involves multiple actors to iteratively communicate with one another to achieve consensus. Given the high complexity of doing so at scale, individual firms are disincentivised to take part in consensus-seeking, unless the relationship or the end goal \"is worth it\".\nA lack of end-to-end consensus often results in small problems to aggregate and lead to sub-optimal outcomes, such as loss of efficiency (e.g., low utilization of capacity (Mak et al. 2023)) and information distortion (e.g., bullwhip effect (Lee, Padmanabhan, and Whang 1997a), shortage gaming (Samuel and Mahanty 2003)). Some examples of issues that arise between companies include lack of timely information and inefficient crisis response due to ineffective communication exchange between supply chain players (Pan, Pan, and Leidner 2012). Ma, Pal, and Gustafsson (2019) argues that more effective consensus-seeking and coordination should be aspired to in a world with increasing supply chain disruptions.\nResearchers have, in the past, proposed autonomous algorithms to handle low-level operational coordination in supply chains (Xu et al. 2024). The idea behind these proposals was that automation would alleviate manual effort, therefore allowing end-to-end, systemic solution optimality. Decisions would have become more traceable and transparent. Most of these proposals centred around intelligent software agents, which are computer programs that mimic humans and act on their behalf (Wooldridge and"}, {"title": "2. Related Work", "content": "The global supply chain ecosystem is becoming increasingly complex and intricate, characterized by different product lines, supplier relationships, and scheduling needs. On top of this, disruptions in the supply chain are becoming more frequent (Ivanov et al. 2023; Bode et al. 2011) due to increasing symptoms of climate change, regional epidemics or global pandemics, as well as recurring regional conflicts. Due to the increasing scale and complexity of SCs, companies are facing difficulties in optimizing supply chain processes, as traditional optimization methods lack the ability to capture the complexity ad vulnerabilities of real-world SCs (Smyth et al. 2024).\nThis state of affairs calls for faster, more automated, and more scalable supply chain consensus-seeking and coordination, that allows supply chain actors to improve their coordination and respond to frequent changes (Marty and Ruel 2024).\nIn the following, we discuss how multi-agent systems can be used to improve automated consensus-seeking and coordination in supply chain management research, the challenges with previous approaches, as well as the benefits of introducing Generative AI technology, and LLMs in particular. We will also discuss why companies struggle with coordination and the role of technological support to achieve it. We look into the availability of benchmarking environments both in supply chain management re-\nsearch and in computer science research which we draw inspiration from to build our frameworks.\nIn computer science, agents are defined as computational entities in an environment from which they perceive different parameters that are used to make decisions, take goal-directed decisions and actuate them (Dorri, Kanhere, and Jurdak 2018). A Multi-Agent System (MAS) is comprised of multiple interacting agents with distinct goals and behaviours, working together or competing in a shared environment to carry out tasks Wooldridge, Jennings, and Kinny (2000). In cooperative settings, agents consider each other's information and decisions, aiming for consensus and optimal coordination (Dorri, Kanhere, and Jurdak 2018). Each entity operates with limited information and must make decisions autonomously, while depending on the performance and actions of other entities in upstream and downstream tiers. These characteristics make MAS particularly suited to study sequential supply chains with multiple tiers of dependency and partial observability. In fact, a large number of multi-agent simulation studies in supply chains exist. However, we note that a MAS, as opposed to a simulation, is a system that hosts computational agents that interact with and impact real life. Therefore, a topic of interest is the degree of autonomy of the agents should have in a SCM environment Xu et al. (2024), which is defined as the degree to which a subset of agents has \"the capability to determine, conduct and control the actions or behaviours independently, without external input\".\nSC automation with agents have started with eProcurement (Neef 2001), and led to automated negotiation (Jiao, You, and Kumar 2006) and learning in business-to-business environments (Coehoorn and Jennings 2004). Beginning in the 2000s, SCM researchers turned their attention to supply chain coordination using software agent technology, focusing on the efficient division of agent roles, to achieve decision optimality, an effective information sharing on end-to-end supply chains (Xue et al. 2005). Works attempted to tackle a diverse range of problems such as inventory planning and order scheduling (Julka, Karimi, and Srinivasan 2002), collaborative production planning (Dangelmaier, Heidenreich, and Pape 2005), automated procurement (Brintrup et al. 2011), disruption management (Behdani, Lukszo, and Srinivasan 2019) across various industrial sectors such as aerospace, logistics, recycling, construction and food, and agriculture (see Xu et al. (2024) for a review).\nThe main way of achieving consensus in the software agent research in SCM, has been through optimization functions, either through a global objective function (e.g., Fung and Chen 2005), often pursued through a mediator agent (e.g., Pan et al. 2009), a pareto optimal solution search between conflicting objectives (e.g., Wong and Fang 2010), or ensuring that individual objectives do not conflict, by fine-tuning them a priori (e.g., Lim, Tan, and Leung 2013). A recent survey of these approaches by Xu et al. (2024) argues that the field has stagnated due to low industrial adoption, which is partly due to the difficulty in creating bespoke, tailored solutions, as well as interoper-ability and system integration issues, leading to a lack of uptake from multiple supply chain partners. Lack of trust in automation and lack of explainability and decision traceability were other reasons cited.\nMore recently, another agent based automation paradigm, Reinforcement Learning (RL) has gained attention in SCM. RL is a comprehensive AI framework, wherein agents equipped with RL capability determine how to act upon an environment to maximize a reward function (Boute et al. 2022). The main applications of RL in supply chain management are information handling, transportation, and inventory management, RL agents coordinate material flows across sites (Rolf et al. 2023). In particular, Multi-Agent Reinforcement Learning (MARL) is a paradigm that studies"}, {"title": "2.1. Available Benchmarking Environments in Supply Chain Management Research", "content": "There is a lack of multi-agent LLM-powered benchmarking environments where long-standing challenges such as inventory management can be investigated. While there is a large corpus of existing research on AI applications for SC automation involving distributed agent architectures (Xu, Mak, and Brintrup 2021; Liu et al. 2022; Yuan et al. 2023), the supply chain research community does not have an SC-specific LLM-powered benchmarking environment with communication frameworks that reflects partial observability and a scalable sequential supply chain.\nWhile there is no SC-specific LLM-powered benchmarking environment, the field of Computer Science has made numerous advancements in developing environments that study behaviours of cooperative and competitive LLM-powered agents (Zhao et al. 2024; Mukobi et al. 2023). By drawing inspiration from LLM-powered decision-making frameworks from computer science research, as well as multi-agent supply chain environments that don't make use of LLMs, we can design a set of LLM-powered SC-specific consensus-seeking frameworks that reflect partial observability and collab-oration between neighbours.\nExamples of these environments developed by computer science research include: Zhao et al. (2024), which simulates competitive agent dynamics in a marketplace setting. Though this environment illustrates an industry example with partial observability, it lacks the sequential supply chain structure with partial observability that would be useful to study inventory management challenges. Mukobi et al. (2023) focus on multi-agent collaboration in a general-sum setting, which would also be interesting\nfor LLM-powered supply chain interactions. However, a similar supply chain environment would have to include sequential dependencies, partial observability, as well as real-time decision-making and consensus-seeking. There is very limited research on LLM-powered decision-making in a supply chain setting, but Quan and Liu (2024) introduces LLMs to manage inventory systems by leveraging zero-shot learning capabilities to minimize costs and stockouts. Despite testing Chain-of-Thought reasoning for LLM-powered agents in various supply chain scenarios, this implementation relies on standalone agents that don't negotiate with their neighbours to make their decisions.\nHence, another key contribution of this paper is an LLM-powered SC-specific consensus-seeking framework that focuses on varying types of interactions between neighbouring agents."}, {"title": "3. Problem Setting", "content": "We place our multi-agent communication frameworks in an environment that simulates an end-to-end supply chain inventory management setting, based on the work by Liu et al. (2022). This environment has desirable features for our purposes such as partial observability, multiple tiers of dependency, as well as a general sum setting. Our choice to focus our implementation on the end-to-end supply chain is due to the fact that this setting allows us to explore and tackle longstanding challenges in SCM research, such as the bullwhip effect, while allowing for a simple implementation of our communication framework that can be extended to a supply chain network.\nWe implement our communication framework on top of Liu et al. (2022) because of its intuitive inventory management setting and built-in bullwhip effect metrics, as well as its easy extendability to a supply chain network setting with multiple parallel layers of echelons.\nFig. 2 shows a sequential supply chain that reflects the exchanges in order requests (\u201cdemand\u201d), material products (\u201creplenishment\u201d), and additional insights (\u201cinformation\") that flow between the communicating agents in our sequential supply chain setting. In the following, we describe the metrics that we will attempt to mitigate by using our increasingly sophisticated communication frameworks, as well as dedicated tools."}, {"title": "3.1. Global Costs in the end-to-end Supply Chain", "content": "The global costs of our end-to-end supply chain are based on the implementation of local costs by Liu et al. (2022). Specifically, the global costs are given by the"}, {"title": "3.2. The Bullwhip Effect in end-to-end Supply Chains", "content": "The bullwhip effect is a phenomenon of the increase in variability of orders as one moves upstream in a supply chain (Disney et al. 2005). It has been advocated that sharing information between neighbouring agents in the supply chain can mitigate the bullwhip effect (Wang and Disney 2016). To compute the bullwhip effect in our sequential supply chain setting, we consider a formula derived by Liu et al. (2022) and based on Fransoo and Wouters (2000), which considers the coefficient of variation of demand generated by a given echelon, i.e., the ratio between the standard deviation of demand and the mean of demand, as expressed by the following formula:\n$\\text{coeffvar} = \\frac{\\sigma(\\text{demand};(t, t + 1))}{\\mu(\\text{demand};(t, t + 1))}$\nwhere demand is given by the list of historical actions of agent $i$, and $t$ is the current time interval. Therefore, a coefficient of variability of demand below 1 indicates that the bullwhip effect is negligible.\nTo compute the aggregate bullwhip effect, we use the insight from Fransoo and Wouters (2000), who conclude that the aggregate bullwhip effect for a (strictly) end-to-end supply chain can be achieved by multiplying all of the coefficients of variation (i.e., the bullwhip effects) of each individual echelon.\nIn order to mitigate the bullwhip effect, we implement a traditional extant approach to order an optimal quantity based on SCM restocking policies. The metric used to optimize for the bullwhip effect is based on the Economic Order Quantity (EOQ) measure for each agent (Kuncova 2002), motivated by a similar approach which was adopted by Jackson, Saenz, and Ivanov (2024). However, the challenge that arises is that the EOQ quantity picked by each individual agent may not be optimal for the entire supply chain. Kuncova (2002) and Dejonckheere et al. (2004) underline that agreements on order amounts between neighbouring agents help mitigate the bullwhip effect. According to this insight, our implementation of communication frameworks based negotiation should aid in mitigating the bullwhip effect. We deliberately adapt the original EOQ formula as a benchmark, and make it suitable for our environment (Liu et al. 2022), as follows:\n$\\text{EOQ} = \\sqrt{\\frac{2* \\text{Demand} * \\text{Ordering Cost}}{\\text{Holding Cost}}}$\n, where Demand is derived from the mean of historical demand data from the down-"}, {"title": "4. Methodology", "content": "An overview of our LLM-powered consensus-seeking frameworks is shown in Fig. 3. Our frameworks are for \"consensus-seeking\" because they are orchestrating and steering our SC agents towards an agreement. Whether they ultimately find consensus or not, will depend on the prompt-specific interaction between the agents. In particular, our frameworks include: standalone LLM-powered agents (3a), information sharing between neighbouring agents (3b), standalone LLM-powered agents with tools (3c), information sharing between neighbouring agents with tools (3d), and negotiation between neighbouring agents (3e). The underlying inventory management setting for our frameworks comes from the research by Liu et al. (2022), which we augment by building LLM-powered agents on top of it.\nWe utilize existing memory structures to aid the agents in storing previous local observations about the status of the environment, namely the specific agent's inventory state, backlog state and previous orders. Beyond this structure, we rely exclusively on context to create the memory of the agents, also as we progress to consensus-seeking frameworks for decision-making."}, {"title": "4.1. LLM-powered Decision-Making without Communication", "content": "The standalone LLM-powered agents constitute the first step in our ablation study. Fig. 4 illustrates the decision-making process for standalone LLM-powered agents that we employ for a 3-tier sequential supply chain. For each agent, there is the environment perception step, where the agent perceives its observation from the environment. After this, the state is stored in the memory, and the memory is also used to provide some examples for the LLM agent on previous actions. This information from memory and from the observation is contextualized in a prompt for the agent, containing the following elements:\n\u2022 General description of sequential supply chain problem setting.\n\u2022 Description of objective function: the function for cost minimization, or the function for the coefficient of variability which we use as a proxy for the bullwhip effect.\n\u2022 Agent's observation of the environment, containing: inventory, backlog, last or-der, incoming/transfer orders, demand from downstream neighbour.\n\u2022 Memory: information on previous ten observations on inventory, backlog and order amounts.\n\u2022 Final question on order amount (action) and instruction on formatting LLM output.\nThe result output by the LLM is interpreted as the order amount or action that is executed upon the environment. The input information served to the standalone LLM-powered agent reflects the local view that it has of the supply chain. A detailed breakdown of the prompt components can be found in Appendix B."}, {"title": "4.1.1. Standalone LLM-powered Agents", "content": "We introduce the tool on top of the decision made by the standalone LLM-powered agents. The output of the tool embedded in the prompt with the necessary contextualization, to allow the agent to benefit from more information, as illustrated in the example in Appendix B. The wrench symbol indicates where the tool is invoked in the decision-making process, when the tool is included in the framework."}, {"title": "4.1.2. Communicating LLM-powered Agents", "content": "Collaboration between agents requires coordination between agents in neighbouring echelons. We thus develop a cognitive-inspired modular framework that integrates with perception, memory and execution, as illustrated in Fig. Al in Appendix A and inspired by the cooperative embodied agents paper by Zhang et al. (2023). At each step of the simulation, after perceiving the environment, each agent can save to and receive information from memory, make a tentative decision based on its standalone viewpoint of the supply chain, and then proceed to a communication stage with a neighbouring agent to seek consensus. Finally, the agent makes a final decision based on all these previous steps and executes it upon the environment. This execution stage after all communication interactions allows the agents to avoid making decisions based on partial information. Fig. 5 illustrates the details of how information is passed throughout each step for a 3-tier supply chain until it reaches the final decision and execution stage that exercises the final action on the environment.\nThere are different orchestration frameworks for multi-agent workflows, such as LangGraph (LangChain AI 2024) or AutoGen (Wu et al. 2023). We opted for Lang-Graph as it offers a simple but versatile implementation and can be easily extended to tool-calling with LangChain. To reflect the partial observability described in Marty and Ruel (2024), our framework limits communication to neighbouring agents. In particular, our implementation considers a use case where each agent initiates com-munication with its immediately upstream neighbour. A single interaction therefore always involves two neighbouring agents."}, {"title": "4.2.1. Communication between Agents", "content": "There are two types of communication frameworks that we define to be executed between neighbouring agents, corresponding to the stage shaped as a hexagon in Fig. 5. These communication frameworks are information sharing and negotiation, which both reflect the partial observability of sequential supply chains by allowing agents to only interact with their immediate neighbours. We begin by defining information sharing, which involves enriching each agent's information for the standalone decision with information from the neighbouring (upstream) agent. The framework-related choice of implementing interactions with the upstream neighbour comes from the need to mitigate demand amplification, which usually affects upstream echelons in the sequential supply chain; therefore, the framework favours informing upstream agents of details on their downstream neighbours, attempting to steer the former's decision-making pro-cess. Intermediate agents in the supply chain still have interactions with both upstream and downstream neighbours before making their final decision. Also this type of com-munication can be enhanced by including the results from the tool to the information shared between neighbouring agents.\nFig. 6 shows the consensus-seeking framework based on information sharing between neighbouring agents without additional steps taken for negotiation. As we embed the outputs of our tool-calling functions directly in the prompt, the figure applies to both information sharing with tools and without tools.\nThe second type of communication framework, which builds upon the information sharing framework, is the negotiation framework. Negotiation allows for the agents to interact and agree on an order amount, by taking the output of each tool and using these values as upper and lower bounds for a negotiation range. The reasoning behind this comes from the idea of finding a trade-off between the values that each agent would have otherwise decided upon. Therefore, the negotiation framework always includes tool usage, as the tool outputs of communicating agents are used as the starting point for negotiation. The agents have a predefined number of iterations to negotiate the final order amount and subsequently have to name their definitive order amount in a final agreement stage.\nThe reasoning behind this is that if the agents manage to find an agreement, this should decrease the amplification of demand as one moves upstream in the supply chain, reducing both costs and the bullwhip effect. For the experiments assessing the global costs of the supply chain, the tool output for each agent constitutes the cost-minimizing amount at each echelon in the sequential supply chain. Our experiments test if a further layer of negotiation on these order amounts improves the global supply chain costs even further.\nThe communication framework implemented with LangGraph (LangChain AI 2024) for each pair of communicating neighbors is illustrated in Fig. 7. Our implementation dynamically creates nodes and edges for a sequential supply chain of any length,"}, {"title": "4.3. Prompt Engineering for different Consensus-Seeking Frameworks and different Metrics", "content": "In this section we discuss the properties of the prompts that we used for different models and metrics. We underline that we undertook manual prompt engineering for our experiments. As a result, the prompts are not fully optimized and largely the same between different foundation models. We will discuss in the Limitations section how model-specific optimization can be achieved in future research."}, {"title": "4.3.1. Zero-shot Prompting", "content": "Our benchmarking environment utilizes pre-trained LLMs to tackle inventory management challenges. We use zero-shot learning to query our models, thereby requesting that the agents apply their pre-trained knowledge directly to our inventory manage-ment tasks, interpreting information that is supply chain-related based on their insights acquired on large knowledge corpora (Kojima et al. 2022).\nWe exclude in-context learning from our prompts, because its performance is unsta-ble, and subject to many factors (Dong et al. 2022). Additionally, we have opted to keep prompts as similar as possible throughout our experiments, even as we compare the performance with different language models.\nMoreover, limiting our prompts to zero-shot learning allows us to minimize the amount of changes we make between different metrics. In particular, the optimization functions change between metrics, as well as the formulation of the question, but the formulation of the observation and description of the sequential supply chain setting remain largely unchanged, as illustrated in Appendix B."}, {"title": "4.3.2. Prompt Engineering between different Supply Chain Metrics", "content": "Moving from one metric to the other in our implementation only requires adapting the input prompts that get passed into the consensus-seeking frameworks, without changing the implementation of the frameworks themselves and how the messages are"}, {"title": "4.3.3. Prompt Engineering to introduce Tool Usage", "content": "As can be observed in Appendix B, the prompts used in our inventory management setting comprise different parts, with details to describe all of the observations and supply chain metrics necessary for each agent to make a decision. As a result, when we want an agent to make a decision based on a tool output, we have to underline the importance of this tool in our prompt. This is achieved by simple means of directives such as inciting the LLM-powered agent through the prompt to give a lot of weight to the tool output in its final decision, as illustrated in Appendix C. The optimal prompts to achieved this results were determined experimentally, and we discuss them in the experimental setup."}, {"title": "4.4. Tools used by Agents", "content": "We implement two different tools that can be used by the agents based on the metric which they are optimizing.\nTo minimize each agent's costs in the end to end supply chain, we use a demand forecasting tool that uses linear regression to estimate the next order amount, thereby keeping orders similar to past orders and avoiding spikes in demand. The tool utilizes a look-back window of 30 periods to train this model on recent demand data, aiming to anticipate future demand accurately. At the beginning of the simulation, when the dataset is insufficient, the agent defaults to the most recently observed order quantity.\nTo minimize the bullwhip effect of an individual agent in the sequential supply chain, we use a tool that calculates the EOQ formula, as defined in the Problem Setting section, and place the tool output within the LLM prompt.\nIn both cases, the tool output for the LLM-powered agent is presented to the LLM-powered agent along with a directive on how to use the result in its decision-making."}, {"title": "5. Experimental Setup", "content": "We run a total of 24 experiments to compare our communication frameworks on differ-ent optimization metrics (global bullwhip effect and global costs) and on LLM models of different size. The summary of our experiments is detailed in Table 1. As the tem-perature used for the LLMs in our experiments is close to zero, the outputs of our runs are near-deterministic. The decision to limit our experiments to specific scenarios without stochastic elements also comes from the fact that running experiments with these models is expensive.\nWe conduct our experiments with an underlying customer demand that is based on the Merton Jump Diffusion Model, as described in Liu et al. (2022). We consider an end-to-end supply chain with 3 agents, and a lead time of 2 steps, to reflect the presence of the bullwhip effect as highlighted by Chen et al. (2000) and using the measure from Fransoo and Wouters (2000) to assess whether the bullwhip effect can be mitigated with our approach. These parameters can be set via the underlying agentic environment from the research by Liu et al. (2022), which we augment by building on top of it LLM-powered agents."}, {"title": "5.1. Agent Policies used as Baselines for LLM-powered Agents", "content": "To compare the performance of our LLM-powered consensus-seeking frameworks with increasing levels of sophistication, we establish different baselines based on traditional extant approaches for restocking. One of the most widely used approaches according to Visentin et al. (2021) is the (S,s) policy (Shang 2011), therefore we use this as a baseline. The (S, s) restocking policy reorders to a maximum level (S) when inventory falls below a certain threshold (s). In particular, we use values of (S=100,s=60), which reduce the global costs. This decision-making, based on threshold values, can lead to variability amplification up the supply chain, thereby exacerbating the bullwhip effect (Chen et al. 2000) and increasing global supply chain costs.\nOn the other hand, the strong baseline for our experiments is given by the decisions of a tool-based agent: contrary to LLM-powered agents, which embed the tool output into the LLM prompt, these baseline tool agents use the tool output directly as their final decision. Therefore, we have two strong baselines: one for experiments on the global costs metric, and the other for experiments on the global bullwhip effect metric. When optimizing for costs, we obtained a strong baseline by running the tool agent with the output of the linear regression demand forecasting tool, implemented with the previous 30 observations. Similarly, for the bullwhip effect metric, we used the tool agent with EOQ tool, using the previous 30 observations to calculate the average demand from the downstream agent. The ordering costs and holding costs used in the EOQ formula are set to 1 for all agents across all our experiments, as detailed in Table F1."}, {"title": "5.2. LLMs used", "content": "We conduct all of our experiments with two different foundation models from the Gemini family, developed by Google Deepmind, namely Gemini Flash and Gemini Pro, to illustrate the performance of our communication frameworks with models of different parameter counts (Gemini Team 2024). Gemini Flash represents a smaller"}, {"title": "6. Results & Discussion", "content": "To illustrate the performance of our consensus-seeking communication frameworks, we conduct experiments focusing on two different problem settings for inventory man-agement in the sequential supply chain: global cost minimization and global bullwhip effect minimization."}, {"title": "6.1. Global Cost Minimization", "content": "Fig. 8 visualizes the global costs achieved by each consensus-seeking framework, for two foundation models, and compares the results to the two baselines achieved by the baseline agent implementations: a weak baseline given by the performance of an agent employing an (S=100,s=60) restocking policy, and a strong baseline given by"}, {"title": "6.1.1. Cost Performance of Gemini Flash", "content": "For Gemini Flash, we observe a gradual cost reduction as we introduce the demand forecasting tools, and as we introduce increasing levels of sophistication in the consensus-seeking framework, first with information sharing between neighbour-ing agents, and subsequently with negotiation around the value of the tool output. In particular, for Gemini Flash, we observe:\n\u2022 63.5% cost reduction when adding tools to the standalone agents,\n\u2022 92.8% cost reduction when comparing information sharing agents to standalone agents,\n\u2022 67.9% cost reduction when adding tools to information sharing agents,\n\u2022 50.7% cost reduction when adding negotiation to agents implementing informa-tion sharing with tool usage.\nThis is in line with our expectations that communication between neighbouring agents and additional information about the status of the supply chain can aid individual agents in making more informed decisions. Additionally, the only framework that un-derperforms the weak baseline is the standalone LLM agent without tool usage."}, {"title": "6.1.2. Cost Performance of Gemini Pro", "content": "For Gemini Pro, we observe that the trend in cost reduction is similar to that ob-tained with Gemini Flash, but there is not a consistent performance improvement achieved when using a larger model, even if both models are from the same devel-oper organization (Google DeepMind). Existing research confirms that prompt-based interactions are still brittle (Zamfirescu-Pereira et al. 2023) and that \u201cperformance can vary non-monotonically with model size\" (Wei et al. 2022a). Wang et al. (2024) also finds that different prompts had variable effects across various models. Our case study optimizes the prompts for the smaller model, Gemini Flash, using manual opti-mization techniques. For the Gemini Pro, the prompts are identical except for the way the tool output is introduced, as can be observed in Fig. C1 in Appendix C. Prior to these prompt modifications, the performance achieved with a larger model was more unstable. Table D1 in Appendix D shows the performance of our consensus-seeking frameworks relative to global costs, considering a Merton Jump Diffusion (spike) de-mand and a prediction tool for demand forecasting.\nFinally, it is also interesting to note that, for both models used, the performance of the negotiation framework beats the hard baseline involving tool-based restocking policy by the agent. This shows that LLM-powered agent interactions with high degrees of orchestration can outperform even mathematical tool-driven performances."}, {"title": "6.1.3. Effect of Metric Complexity on Tool Performance", "content": "The experiments relative to the cost minimization objective illustrate that, when a tool is highly suited for a given metric, such as our linear regression tool to predict future demand and minimize costs, the highest performance is achieved by those frameworks that give strong weight to the tool itself, without necessarily needing an elaborate communication framework between agents. Despite this, additional orchestration on top of the tool implementation, such as with the negotiation framework, can improve tool-driven results even further. This is in line with existing SC research that highlights how sophisticated tools in the form of algorithms can yield optimization of resource allocation and cost reductions (Bu 2024).\nHowever, demand forecasting to minimize costs is a relatively simple challenge in inventory management, defined by a formula which considers a simple sum of different costs. This is simple enough for a foundation model, which is a probabilistic machine, not a tool suited for complex calculations. In cases where the metric is more complex, such as the minimization of the bullwhip effect via a coefficient of variability, commu-nication between neighbouring agents to increase awareness about the status of the supply chain becomes crucial. In these cases, the communication frameworks become the key factors in improving performance, as we illustrate in the following results."}, {"title": "6.2. Global Bullwhip Effect Minimization", "content": "Table 2 shows whether or not the global bullwhip effect achieved by each consensus-seeking framework is below 1. A value below 1 is desirable as it indicates a negligible amount of bullwhip effect, according to the metric by (Fransoo and Wouters 2000) which we used in our inventory management setting and is already implemented by Liu et al. (2022). Table 2 illustrates the results of our consensus-seeking frameworks, as well as the results achieved by the baseline agents. In particular, the strong baseline, based on the agent that calculates the EOQ and uses this amount as the order quantity, successfully reduces the bullwhip effect to a value below 1.\nRegarding our LLM-powered consensus-seeking frameworks, we can observe that introducing a tool to the standalone"}]}