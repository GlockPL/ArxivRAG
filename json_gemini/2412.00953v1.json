{"title": "BIGCity: A Universal Spatiotemporal Model for Unified Trajectory and Traffic State Data Analysis", "authors": ["Xie Yu", "Jingyuan Wang", "Yifan Yang", "Qian Huang", "Ke Qu"], "abstract": "Spatiotemporal (ST) data analysis is a critical area of research in data engineering. Typical dynamic ST data includes trajectory data (representing individual-level mobility) and traffic state data (representing population-level mobility). Traditional studies often treat trajectory and traffic state data as distinct, independent modalities, each tailored to specific tasks within a single modality. However, real-world applications, such as navigation apps, require joint analysis of trajectory and traffic state data. Treating these data types as two separate domains can lead to suboptimal model performance. Although recent advances in ST data pre-training and ST foundation models aim to develop universal models for ST data analysis, most existing models are \"multi-task, solo-data modality\" (MTSM), meaning they can handle multiple tasks within either trajectory data or traffic state data, but not both simultaneously.\nTo address this gap, this paper introduces BIGCity, the first multi-task, multi-data modality (MTMD) model for ST data analysis. The model targets two key challenges in designing an MTMD ST model: (1) unifying the representations of different ST data modalities, and (2) unifying heterogeneous ST analysis tasks. To overcome the first challenge, BIGCity introduces a novel ST-unit that represents both trajectories and traffic states in a unified format. Additionally, for the second challenge, BIGCity adopts a tunable large model with ST task-oriented prompt, enabling it to perform a range of heterogeneous tasks without the need for fine-tuning. Extensive experiments on real-world datasets demonstrate that BIGCity achieves state-of-the-art performance across 8 tasks, outperforming 18 baselines. To the best of our knowledge, BIGCity is the first model capable of handling both trajectories and traffic states for diverse heterogeneous tasks.", "sections": [{"title": "I. INTRODUCTION", "content": "Spatiotemporal (ST) data analysis has been a cornerstone of research in data engineering, with models such as trajectory analysis and traffic state prediction playing critical roles in various domains. These models are integral to the development of intelligent transportation systems (ITS) [1], [2], smart cities [3]\u2013[8], and location-based service (LBS) ap- plications [9], enabling advanced solutions for urban mobility, infrastructure planning, and personalized services.\nFrom a data perspective, ST data analysis models are cate- gorized into two types based on the targeted data: individual- level models for trajectory data and population-level models for traffic state data. Individual-level trajectory models, such as next-hop prediction [10]\u2013[13], trajectory-user linkage [14], [15], and trajectory traffic pattern classification [16], pro- cess mobility trajectories of individuals on road networks or among POIs to uncover patterns in individual human mobility. Population-level traffic state models, including traffic state prediction [17], [18], traffic state imputation [19], [20] and etc, analyze time series data on traffic metrics like speed, density, and flow volumes. These models aim to capture spatiotemporal correlations at a population level, reflecting crowd behaviors in transportation systems, such as urban road networks.\nIn the literature, current ST data analysis methods are often narrowly tailored to specific types of data, focusing either on trajectories or traffic states. Most studies treat trajectories and traffic states as entirely distinct data modalities, designing task-specific models for one modality (sole task in sole data modality (STSD)). A model designed for trajectory next- hop prediction cannot be applied to tasks like trajectory-user linkage, let alone traffic state prediction. While some ST data pre-training models, such as trajectory or time-series represen- tation learning models, can generate universal representation vectors for multiple downstream tasks [16], [21], they remain limited to handling a single data modality, either trajectories or traffic states (multiple tasks in sole data modality (MTSD)). However, individual-level behaviors mobility and population-level traffic states are intrinsically interconnected. Macro-level traffic states are aggregated from micro-level individual trajectories, while population traffic states influence individual mobility patterns. Many ITS and LBS applications require analyzing trajectory and traffic state data jointly. For example, car-hailing platforms need to predict the location"}, {"title": "of a taxi while considering traffic speed predictions. Treating trajectories and traffic states as separate domains in such scenarios can lead to suboptimal model performance.", "content": "In recent years, significant efforts have been made to develop universal foundation models for ST data. Models such as UniST [22], UrbanGPT [23], and OpenCity [24] focus on unified frameworks for traffic state analysis across cities, while UniTraj [25] and TrajCogn [26] aim to handle diverse trajectory analysis tasks using a single model. CityFM [27] generates universal representations for static geographical units. Despite their success in supporting multiple tasks [25], cross-dataset knowledge transfer [22], and few-/zero-shot data analysis [24], these models remain limited to MTSD. A truly versatile model capable of handling diverse ST data analysis tasks across both trajectories and traffic states (multiple tasks in multiple data modalities (MTMD)) is still lacking.\nOutside the field of ST data analysis, versatile and universal foundation models capable of processing heterogeneous data with a single framework have become widespread in domains such as text processing and image processing [28]. Notable examples include the success of large language models (LLMs) like [29], [30] in natural language processing and visual-language multimodal data analysis [31]. Despite the achievements of versatile models in these fields, developing a MTMD model for ST data remains constrained by several unique challenges, as outlined below.\n(1) Challenges in unified representations of ST data: In NLP, all text data can be uniformly represented as sequences"}, {"title": "of characters (unified units), and in CV, images are uniformly represented as matrices or tensors of pixels (unified units).", "content": "However, in ST data analysis, trajectories are modeled as sequences of geographical units (e.g., road segments or POIs), while traffic states are represented as graphs with dynamic sig- nals (e.g., traffic speed over road networks). The differing basic units make developing a unified representation framework for the two data modalities a significant challenge.\n(2) Challenges in unifying heterogeneous ST analysis tasks: In NLP, diverse tasks can be unified as next-word generation, enabling a single model to handle various tasks efficiently. However, in ST data analysis, tasks are highly heterogeneous, with even identical inputs requiring different outputs. For instance, given the same trajectory inputs, travel time estimation outputs continuous timestamps, while user- trajectory linkage outputs discrete user IDs. Unifying such heterogeneous tasks within a single data processing and model training framework remains a significant challenge.\nTo address these challenges, we propose a Bi-modality unIfied General model for ST data analysis in road network- based City scenarios (BIGCity). BIGCity focuses on road networks as the foundational scenario for ST data analysis. To tackle the challenge of unified data representation, BIGCity introduces ST-units (see Sec. IV-A), enabling the expression of ST data from both trajectories and traffic state series in a unified format, i.e., a sequence of ST-units. These ST-units are further embedded into token sequences via a neural network- based Spatiotemporal Tokenizer (see Sec. IV-B). To address"}, {"title": "the challenge of task heterogeneity, we propose a Universal ST Model with Task-oriented Prompt (VMTP) (see Sec. V), which employs novel Task-oriented Prompts to guide an LLM-based Tunable Model for executing diverse ST analysis tasks.", "content": "Addi- tionally, we design a two-stage training strategy (see Sec. VI), combining self-supervised masked reconstruction and task- oriented prompt tuning, to train the model on heterogeneous ST data for multiple tasks. Extensive experiments on three real-world datasets involving both trajectory and traffic state data demonstrate that BIGCity outperforms 18 baselines across 8 tasks, highlighting its superior performance and versatility.\nHere, we summarize our key contributions:\nTo the best of our knowledge, BIGCity is the first model capable of handling multiple types of data analysis tasks for both trajectory and traffic state data, making it the first MTMD ST data analysis model.\nWe propose a unified ST data representation method, i.e., ST-units and ST tokens, along with a novel universal model with task-oriented prompts to unify heterogeneous ST analysis tasks. These methods address the challenges of constructing unified representations for distinct ST data modalities and adapting to heterogeneous ST analysis tasks.\nOur model achieves state-of-the-art performance on 3 real- world datasets, surpassing 18 baselines across 8 tasks. To our knowledge, BIGCity is the first model to achieve SOTA performance over such a wide range of baselines and tasks."}, {"title": "II. RELATED WORKS", "content": null}, {"title": "A. Spatiotemporal Data Analysis Models (STSD Models)", "content": "STSD models are trained to capture specific temporal and spatial dependencies, addressing a specific task such as traf- fic state prediction [32]\u2013[36], trajectory prediction [37]\u2013[40], trajectory classification [41], [42]. As a result, the model archi- tectures vary with task type. For temporal dependency mod- eling, current models employ recurrent neural networks [43], [44], temporal convolutional networks [45], [46], or attention mechanism [47]. For spatial dependency modeling, they utilize graph neural networks [17], [48], [49] or attention mechanism over graphs [2]. Beyond the above models, physics-guided deep learning approaches have recently emerged, providing deeper theoretical insights into spatiotemporal data analysis (STSD) [5], [46], [50]\u2013[52]. These models provide stronger interpretable ability, addressing limitations of deep models. Summary: Despite their success, most of the existing meth- ods are specifically designed for a single data modality and specific tasks, i.e., STSM. They requires separate models to handle trajectory and traffic state data. In contrast, BIGCity can handle trajectories and traffic states within a single model."}, {"title": "B. Spatiotemporal Representation learning (MTSD Models)", "content": "Self-supervised pre-training representation learning is cru- cial for multi-task ST data analysis. Existing trajectory mod- els [3], [15], [53]\u2013[59] employ sequential models with self- supervised tasks, while traffic state models [17], [32], [43], [45], [60]\u2013[65] leverage graph neural networks (GNNs) [66] to capture spatiotemporal dependencies for predicting future"}, {"title": "traffic states.", "content": "Recent models have focused on integrating more comprehensive ST features. For example, trajectory models like TremBR [14] and START [15] account for temporal periodicity, while traffic state models such as T-wave [67], TrajNet [68], and TrGNN [69] capture multi-hop spatial de- pendencies along trajectories. Beyond these models, VecC- ity [70] proposed a comprehensive ST models library, where each map entity is represented as a vector. Furthermore, recent works [27], [71] have introduced text representations using large language models. Summary: While existing models often overlap in the trajectory and traffic state domains, such as incorporating traffic state into trajectory representations, they are typi- cally focused on a single data modality, i.e., MTSD models. Furthermore, these models require fine-tuning for different downstream tasks, resulting in \u201csemi-multi-task\u201d functionality. While BIGCity handles various tasks without task-specific fine-tuning."}, {"title": "C. Universal Spatiotemporal Models (ST Foundation Models)", "content": "The target of this kind of model is to design a universal foundation model for ST data analysis, similar to LLMs for NLP. There are two main research directions for spatiotem- poral universal models: 1) Cross-Dataset Universal Models: These models aim to generalize across different datasets (e.g., datasets from various cities), enabling rapid adaptation to new datasets through few-shot or zero-shot learning [22]\u2013 [24], [72]\u2013[79] for traffic states or trajectory analysis. For example, approaches [80], [81] treat LLMs as spatio-temporal encoders, training them for traffic prediction over cross-data sets. UniST [22] introduced spatiotemporal prompt learning, using statistical features of the dataset as prompts for the prediction of cross-dataset traffic. 2) Universal Models for Heterogeneous Tasks: These models focus on multi-task capa- bilities, with one strategy involving training from scratch on large datasets [82] to adapting heterogeneous with the same data modalities. Recent works [26], [83]\u2013[88] exploit LLMs' multi-task capabilities by converting trajectory data into tex- tual format. Other works leverage LLMs' linguistic abilities to improve model generalization via in-context learning [23] and provide interpretable outputs [89]. Some efforts explore LLMs as spatiotemporal agents, bridging LLMs with tools to perform traffic-related queries and reasoning based on human instructions [90]. Summary: Many of these universal ST models leverage LLM technologies for task versatility and cross-dataset knowl- edge transfer. These models effectively address the \"semi-multi-task\" limitation of ST representation learning by elim- inating the need for fine-tuning in downstream applications. However, most of these models are limited to handling either trajectory or traffic state data, but not both. In contrast, BIGCity not only addresses the \u201csemi-multi-task\" issue by offering task versatility but also handles both trajectory and traffic state data, achieving true data modality versatility.\""}, {"title": "III. PRELIMINARIES", "content": "Our model is designed for road network-based urban traffic scenarios, where the city is represented as a road network and ST data are generated from individuals' movements. These scenarios are common in many widely used ST datasets. This section outlines the basic spatial and temporal components of such scenarios, defining the two types of dynamic spatiotem- poral data: trajectories and traffic states."}, {"title": "A. Basic Spatial and Temporal Elements", "content": "The basic spatial elements in the scenario are road segments.\nDefinition 1 (Road Segment). Consider a city map with $I$\nroad segments, denoted as $r_i$ for the $i$-th segment. The set\nof segments is $R = \\{r_1,\\dots,r_i,\\dots,\\ r_I\\}$. Each segment $r_i$ is\nassociated with a static feature vector $e_i^{(s)} \\in \\mathbb{R}^{D_r}$, describing\nattributes such as road ID, type, length, lane count, in-degree,\nout-degree, speed limit, and other relevant characteristics.\nAll road segments collectively form a road network.\nDefinition 2 (Road Network). A road network is a directed\ngraph denoted as $\\mathcal{G} = \\{\\mathcal{R}, \\mathcal{A}, \\mathcal{E}^{(s)}\\}$, where $\\mathcal{R}$ is the set of\nvertices corresponding to road segments. $\\mathcal{A} \\in \\mathbb{R}^{|\\mathcal{R}| \\times |\\mathcal{R}|}$ is the\nbinary adjacency matrix indicating connectivity between road\nsegments. $\\mathcal{E}^{(s)} = \\{e_1^{(s)},\\dots, e_i^{(s)}, \\dots, e_I^{(s)}\\}$ represents the static\nfeature vectors for all road segments.\nThe basic temporal elements are conceptualized in two\nforms: discrete time slice and continuous timestamp.\nDefinition 3 (Time Slice). A time slice is a fixed-length in- terval partitioning the timeline, indexed as $\\{1,\\cdots,t,\\cdots,\\mathcal{T}\\}$.\nFor the $t$-th time slice, a feature vector $L_t \\in \\mathbb{R}^{D_t}$ is defined to\ndescribe its attributes, such as the slice's start time, its index\nwithin a day, the day index within a week, and so on.\nDefinition 4 (Timestamp). A timestamp represents an instan- taneous UTC time, denoted as $\\tau$. For a given timestamp $\\tau$, a feature vector $L_{\\tau} \\in \\mathbb{R}^{D_{\\tau}}$ describes its attributes, including its absolute timeand the features of the time slice it belongs to.\nIn BIGCity, both discrete and continuous temporal elements coexist. For a time slice $t$, its start time is represented by the timestamp $\\tau_t$, and for a timestamp $\\tau$, the corresponding time slice is denoted as $t_{\\tau}$."}, {"title": "B. Dynamic Spatiotemporal Data", "content": "Based on the above elements, dynamic ST data can be categorized into two types: individual-level trajectories and population-level traffic states. Trajectories capture individual mobility behaviors, defined as follows:\nDefinition 5 (Trajectory). A trajectory is a time-ordered sequence of road segments with associated timestamps, defined as $tr = \\{ (r_{tr_1}, \\tau_{tr_1}), \\dots,(r_{tr_l}, \\tau_{tr_l}),\\dots, (r_{tr_L}, \\tau_{tr_L})\\}$, where $(r_{tr_l}, \\tau_{tr_l})$ is the $l$-th sample in the trajectory. Here, $r_{tr_l} \\in \\mathcal{R}$ is the road segment, and $\\tau_{tr_l}$ is the corresponding timestamp. The trajectory can also be expressed as $tr = \\{ (e_{tr_1}^{(s)}, \\tau_{tr_1}),"}, {"title": ".., ($e_{tr_l}^{(s)}, \\tau_{tr_l}), ..., (e_{tr_L}^{(s)}, \\tau_{tr_L})\\}$, where $e_{tr_l}^{(s)}$ denotes the static feature of road segment $r_{tr_l}$.", "content": "Definition 6 (Traffic State). For a given time slice $t$, the traffic state of the road segment $r_i$ is represented as a vector $e_{i,t}^{(d)} \\in \\mathbb{R}^{D_d}$, contains the dynamic characteristics of $r_i$, such as average speed, traffic entry and exit. $D_d$ is the number of traffic state channels. The traffic state series for $r_i$ is $tsi = \\{e_{i,1}^{(d)}, \\dots, e_{i,t}^{(d)}, \\dots, e_{i,T}^{(d)}\\}$. Using the start time of each time slice as its timestamp, we have $tsi = \\{ (e_{i,1}^{(d)}, \\tau_1), \\dots, (e_{i,t}^{(d)}, \\tau_t), \\dots, (e_{i,T}^{(d)}, \\tau_T)\\}$, where $\\tau_t$ is the timestamp of time slice $t$.\nAccording to Def. 5 and 6, both trajectories and traffic states are sequences of the basic spatial and temporal elements."}, {"title": "C. Motivation of BIGCity", "content": "Trajectories and traffic states represent human mobility patterns at different levels: individual-level and population- level, respectively. Although typically treated as distinct, het- erogeneous data modalities, these two types of data are in- herently interconnected. According to Def. 5 and Def. 6, both trajectories and traffic states share similar structural formats.\nFor a trajectory, a sample corresponds to the road segment where an individual is located at a given sampling time, and the location is associated with a corresponding traffic state.\nFor a traffic state series, a sample represents the dynamic traffic state of a road segment at a given sampling time.\nThus, the triple (segment, traffic state, sampling time), i.e., \"a road segment with its traffic state sampled at a specific time\", can be seen as the basic unit of ST data, analogous to words in NLP or pixels in image data. This insight suggests a viable opportunity to develop a versatile MTMD model that simultaneously handles both trajectories and traffic states.\nBased on this idea, we propose BIGCity as to achieve MTMD ST modeling. Figure 2 illustrates the framework, which consists of two core components: i) a Unified ST Tok- enizer to address heterogeneous data representation (Sec. IV), and ii) a Versatile ST Model with Task-oriented Prompt to handle distinct ST tasks (Sec. V)."}, {"title": "IV. UNIFIED REPRESENTATIONS FOR ST DATA", "content": "In this section, we address Challenge 1: the unification of spatiotemporal data representations for MTMD model design. We first define spatiotemporal units (ST-units) as a unified representation for both trajectories and traffic states. Then, we introduce the Spatiotemporal Tokenizer to encode these ST- units into input tokens (ST tokens) for BIGCity."}, {"title": "A. Basic Spatiotemporal Units", "content": "Building on the motivation in Sec. III-C, we define the triple (segment, traffic state, sampling time) as the basic spatiotemporal unit (ST-unit) for both trajectory and traffic state data. Formally, for a road segment $r_i$ and a timestamp $\\tau$, an ST-unit is expressed as:\n$U_{i,\\tau} = (e_i^{(s)}, e_{i,\\tau}^{(d)}, L_{\\tau}),$\n(1)\nwhere $e_i^{(s)}$ represents the static features of segment $r_i$, $L_{\\tau}$ is the timestamp feature for $\\tau$, and $e_{i,\\tau}^{(d)}$ represents the dynamic traffic state of segment $r_i$ at the time slice containing $\\tau$.\nUsing the ST-unit in Eq. (1), we redefine traffic states and trajectories in a unified format as sequences of ST-units."}, {"title": "Definition 7 (ST-unit-based Traffic State).", "content": "For a road segment $r_i$, its traffic state series is redefined as:\n$U_i = \\{ U_{i,\\tau_1},\\dots, U_{i,t},\\dots, U_{i,\\tau_T}\\} ,$\n(2)\nwhere $U_{i,t} = (e_i^{(s)}, e_{i,t}^{(d)}, L_{t})$. Here, $L_t$ represents the features of the timestamp $\\tau_t$, and $\\tau_t$ is the start time of time slice $t$.\nDefinition 8 (ST-unit-based Trajectory). Given a trajectory $tr$ of length $L$, its ST-unit-based representation is defined as:\n$U_{tr} = \\{U_{tr_1},\\dots, U_{tr_l},\\dots, U_{tr_L}\\},$\n(3)\nwhere $U_{tr_l} = (e_{tr_l}^{(s)}, e_{tr_l,t_{tr_l}}^{(d)}, L_{tr_l})$ denotes the ST-unit for the $l$-th sample. Here, $e_{tr_l}^{(s)}$ represents the static features of road segment $r_{tr_l}$, $e_{tr_l,t_{tr_l}}^{(d)}$ the dynamic features at time slice $t_{tr_l}$, and $L_{tr_l}$ the timestamp feature of $\\tau_{tr_l}$.\nIn certain datasets, road segments may lack dynamic fea- tures. In such cases, we set $e_{tr_l, t_{tr_l}}^{(d)} = NULL$.\nRemark: In Eq. (3) and Eq. (2), both individual-level tra- jectories and population-level traffic states, despite their het- erogeneous modalities, are represented in a unified format \u2013"}, {"title": "sequences of ST-units.", "content": "This unification resolves the challenge of heterogeneous data representation, enabling the design of a model capable of analyzing multiple ST data modalities."}, {"title": "B. Spatiotemporal Tokenizer", "content": "This subsection presents the spatiotemporal (ST) tokenizer, which converts ST-units into token vectors (ST-tokens). Specif- ically, it first generates dynamic road network representations as ST feature library, and then samples specific features for input data according to ST-units. The tokenizer comprises four modules: a static feature encoder, a dynamic feature encoder, a fusion encoder, and a temporal integration module.\nStatic Feature Encoder. This module encodes the static features $e_i^{(s)}$ of an ST-unit into a representation vector. To capture the spatial and topological relationships among road segments, the encoder employs a graph attention network (GAT) [91], generating segment representations based on the road network $\\mathcal{G} = \\{\\mathcal{R}, \\mathcal{A}, \\mathcal{E}^{(s)}\\}$ defined in Def. 2. Specifically, for the static feature matrix $\\mathcal{E}^{(s)} = \\{e_1^{(s)},\\dots, e_I^{(s)}\\}$, the encoder outputs a representation matrix $\\mathcal{H}^{(s)}$ as follows:\n$\\mathcal{H}^{(s)} = FFN\\left(GAT_s\\left(\\mathcal{E}^{(s)}, \\mathcal{G}\\right)\\right),$\n(4)\nwhere $GAT_s(\\cdot, \\cdot)$ is the GAT model and $FFN(\\cdot)$ a feed-forward network for dimensional transformation. The result is $\\mathcal{H}^{(s)} = \\{h_1^{(s)},\\dots,h_i^{(s)},\\dots, h_I^{(s)}\\}$, with $h_i^{(s)} \\in \\mathbb{R}^{D_h}$ as the static representation for road segment $r_i$.\nDynamic Feature Encoder. This module encodes the dynamic features $e_i^{(d)}$ of an ST-unit into a representation vector. To capture temporal dependencies, historical features are incor- porated from a time window of length $T'$. For time slice $t$, the window is defined as $W_t = \\{t-T',\\dots,t-1,t\\}$, and the concatenated historical features for segment $r_i$ are\n$\\tilde{e_{i,t}^{(d)}} = ||\\{ e_{i,t'}^{(d)} | t' \\in W_t\\}$, where $||$ denotes concatenation. The integrated historical dynamic feature matrix is $\\tilde{\\mathcal{E}}^{(d)} = \\{\\tilde{e_{1,t}^{(d)}}, \\dots, \\tilde{e_{I,t}^{(d)}}\\}$. By replacing the static feature matrix in the road network with $\\tilde{\\mathcal{E}}^{(d)}$, a dynamic road network $\\mathcal{G}_t = \\{\\mathcal{R}, \\mathcal{A}, \\tilde{\\mathcal{E}}^{(d)} \\}$ is constructed. The dynamic feature encoder uses a GAT to encode $\\mathcal{G}_t$ as:\n$\\mathcal{H}^{(d)} = FFN\\left(GAT_d\\left(\\tilde{\\mathcal{E}}^{(d)}, \\mathcal{G}_t\\right)\\right),$\n(5)\nwhere the result $\\mathcal{H}^{(d)} = \\{h_{1,t}^{(d)}, \\dots,h_{i,t}^{(d)},\\dots, h_{I,t}^{(d)}\\}$ represents the dy- namic representation of segment $r_i$ at time slice $t$.\nFusion Encoder. This module fuses static and dynamic repre- sentations of road segments to generate comprehensive spatial representations. The concatenated representation for segment $r_i$ at time slice $t$ is $h_{i,t} = \\{h_i^{(s)}, h_{i,t}^{(d)}\\}$. A cross-attention mechanism is employed to capture long-range dependencies among these representations. Specifically, for segments $r_i$ and $r_j$, their relationship is computed as:\n$\\alpha_{ij} = (q_i^\\top h_{j,t})/\\sqrt{2D_h},$\n(6)"}, {"title": "where $W_Q \\in \\mathbb{R}^{I \\times D_h}$ is a learnable query matrix, and $q_i$ is the $i$-th vector The fused spatial representation for $r_i$ at time slice $t$ is then:", "content": "$s_{i,t} = \\sum_{j=1}^{I}ATT_{ij}h_{j,t}, \\text{ where } ATT_{ij} = \\frac{A_{ij}}{\\sum_{j=1}^{I}A_{ij}}.$\n(7)\nUnlike the GAT used in the static and dynamic encoders, which only capture correlations between directly connected segments, the cross-attention mechanism enables long-range dependencies across all segments.\nTemporal Integration & ST Tokens. This module integrates the timestamp and its features with the spatial representation to generate an ST token. Specifically, for a ST-unit $U_{i,\\tau} = (e_i^{(s)}, e_{i,\\tau}^{(d)}, L_{\\tau})$, the static and dynamic features $e_i^{(s)}$ and $e_{i,\\tau}^{(d)}$ are encoded into a spatial representation $s_{i,t}$. An MLP then combines $s_{i,t}$ with the timestamp feature $L_{\\tau}$ and the time interval $\\delta_{\\tau}$ between adjacent ST-units to generate the ST token:\n$x_{i,\\tau} = MLP\\left( s_{i,t} || L_{\\tau} || \\delta_{\\tau} \\right),$\n(8)\nwhere $\\delta_{\\tau}$ is the time interval between consecutive ST-units in a sequence. For a sequence of ST-units $\\{U_1, \\cdots ,U_l, \\cdots ,U_L\\}$ corresponding to a trajectory or traffic state series, the interval is $\\delta_{\\tau_l} = \\tau_l - \\tau_{l-1}$. Including $\\delta_{\\tau}$ helps the model handle non- uniformly spaced ST-unit sequences, which is crucial for real- world trajectory data with irregular sampling intervals. The resulting vector $x_{i,\\tau}$ is the ST Token for ST-unit $U_{i,\\tau}$.\nRemark: The ST tokenizer converts a sequence of ST-units, representing either a trajectory or a traffic state series, into an ST-token sequence. Specifically, it transforms the trajectory $U_{tr}$ (Eq. (3)) into $X_{tr} = \\{x_{tr_1},\\dots, x_{tr_L}\\}$, and the traffic state series $U_i$ (Eq. (2)) into $X_i = \\{x_{i,1},\\dots, x_{i,\\tau_T}\\}$. These ST- token sequences serve as unified inputs for the BIGCity model, allowing it to process heterogeneous ST data across modali- ties. Thus, both individual-level trajectories and population- level traffic states are represented in a unified form, enabling seamless processing by a single model."}, {"title": "V. VERSATILE MODEL WITH TASK ORIENTED PROMPT", "content": "This section introduces a method to address the challenge of adapting to diverse ST analysis tasks (Challenge 2) for designing an MTMD model. A key difficulty for this challenge lies in informing the model about the specific task it should perform. Even with identical data inputs, different tasks require distinct types of outputs. For instance, given the same trajec- tory inputs, the travel time estimation task outputs continuous arrival time predictions, while the user-trajectory linkage task outputs discrete user ID.\nDrawing inspiration from the prompt mechanism in LLMs, we propose a Versatile Model with Task-oriented Prompts (VMTP) to address this difficulty. VMTP employs textual instructions as prompts to guide the model on the desired task and utilizes a tunable LLM with ST tokens as inputs to perform specific ST data analysis tasks. The model consists of three"}, {"title": "modules: Task-oriented Prompts (input module), LLM-based", "content": "Backbone Model (data-processing module), and General-task Heads (output module).\nA. Task-oriented Prompts\nThe input to our model is a task-oriented prompt that com- bines the ST token sequences generated by the ST tokenizer in Sec. IV-B with textual instructions specifying the type of task to be performed.\nPrompt Contents. The task-oriented prompt consists of three components:\nTextual Instructions. This part of the prompt is a textual description of the data analysis task to be executed. For example, the instruction \"Where is the next hop position of the input trajectory?\" informs the model to perform a next hop prediction task. We use the tokenizer of the backbone LLM (see Sec. V-B) to converts the instructions into a sequence of Text Tokens, denoted as $X^{(txt)}$.\nInput Data. This part of the prompt provides the spatiotem- poral data to be analyzed, such as a traffic state series or a trajectory, formatted as ST-unit sequences according to Eq. (2) or Eq. (3). The ST tokenizer, as described in Sec. IV-B, converts these sequences into a series of ST Tokens, denoted as $X^{(st)}$.\nTask Placeholders. This part of the prompt provides a format guide for the task outputs. Two types of placeholders are used: the classification placeholder, denoted as [CLAS], and the regression placeholder, denoted as [REG]. These placeholders represent the expected output structure of the ST data analysis task. We use two learnable token vectors, $x^{(clas)}$ and $x^{(reg)}$, to corresponding to the two types of placeholders. The sequence of learnable token vectors is named as Task Tokens and denoted as $X^{(tsk)}$.\nThe complete inputs to the VMTP model is a combined sequence consisting of the text tokens $X^{(txt)}$, the ST tokens $X^{(st)}$, and the task tokens $X^{(tsk)}$, named as input prompt tokens, represented as:\n$X = (X^{(txt)}, X^{(st)}, X^{(tsk)})$.\n(9)\nPrompt Templates. As illustrated in the examples in Fig. 3, we use a template to organize the instructions, input data, and task placeholders of task-oriented prompts into a unified structure for various tasks.\nThe first part of the template is the instruction. For each task, we start by using a language model, specifically ChatGPT, to understand the task's function. Then, the language model"}, {"title": "generates a set of candidate instructions describing the task.", "content": "For example", "include": "Give me the estimated time of arrival for the input trajectory\" or \"When will I walk to the ending position in this trajectory?\". Finally", "task": "nFor classification tasks, such as trajectory next hop pre- diction and user-trajectory linkage, the input data consists of a sequence of ST tokens corresponding to a trajectory to be classified. The task placeholder is a classification placeholder [CLAS", "REG": "see Fig. 3b and Fig. 3c).\nFor generation tasks, such as trajectory recovery, the input consists of a sequence of ST tokens with [MASK", "MASK": "are placed between adjacent samples in a low-rate trajectory. The task placeholders are sequences of classification pairs, denoted as (CLAS", "CLAS": ["CLAS"]}, {"MASK": "tokens, with each pair corresponding to a specific [MASK"}, {"MASK": "see Sec. V-C).\nThe task-oriented prompts structured by this template serve as the"}]}