{"title": "A Visualized Malware Detection Framework with CNN and Conditional GAN", "authors": ["Fang Wang", "Hussam Al Hamadi", "Ernesto Damiani"], "abstract": "Malware visualization analysis incorporating with Machine Learning (ML) has been proven to be a promising solution for improving security defenses on different platforms. In this work, we propose an integrated framework for addressing common problems experienced by ML utilizers in developing malware detection systems. Namely, a pictorial presentation system with extensions is designed to preserve the identities of benign/malign samples by encoding each variable into binary digits and mapping them into black and white pixels. A conditional Generative Adversarial Network based model is adopted to produce synthetic images and mitigate issues of imbalance classes. Detection models architected by Convolutional Neural Networks are for validating performances while training on datasets with and without artifactual samples. Result demonstrates accuracy rates of 98.51% and 97.26% for these two training scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "The rapidly increasing number of cyberattacks and data breaches over years caused by malicious software (malware) has raised serious issues. Consequently, identifying malware using machine learning techniques has become a shortcut method to keep up with the complex malware metamorphoses nowadays. The visualization analysis approach [1] combined with advanced Machine Learning (ML) techniques has been proved to be a promising solution for malicious software detection. The approach extracts behaviors' features, such as network activities, instruction sequences, and system calls [2, 3] to convert them into an image, thus, preserving abnormal patterns as special textures for further image classification and detection purposes. An advantage of malware visualization analysis is that it enhances recognizabilities for both human and ML classifiers, regardless of other information such as technique modifications.\nExtensive research on malware visualization analysis has been bridged with various ML methods and made progress in tackling different sets of problems. For example, the choice between grayscale or colored images as transformed outputs is\nbeing explored and debated for achieving better results [1, 4, 5] and lowering computational costs. Moreover, Convolutional Neural Networks (CNNs) with different architectures [6,7,8] have been experimented with to improve the accuracy of detection performance and malware classifications. Additionally, the class imbalance problem is common due to uneven distributions of benign software and varieties of malware. Several models were proposed to handle such problems, including a CNN based model with weighted softmax loss [9], a DenseNet model with reweighting losses method [10], an ensemble learning model [11], and others. Meanwhile, Generative Adversarial Network (GAN) [12] has led to a significant foresight by generating images that resemble the original data, promising a better solution for balancing data. Reference [13] employed transferred deep convolutional GAN (DCGAN) and generated fake malware for simulating zero-day attacks. In [14] work, adversarial malware examples were modeled to improve detection on black-box attacks. However, most previous studies have focused on very specific problems.\nIn this work, we propose an integrated framework that involves a Pictorial Representation System (PRS) with applicable features under various scenarios, a conditional Generative Adversarial Network (cGAN) based image augmentation model for mitigating data scarcity, and several CNN-based detection models for performance comparison on different datasets. The proposed model was practically assessed using TensorFlow [15] and Keras [16] Python library.\nThe contribution of this work is as follows:\nWe developed a new visualized system that targets behavior patterns of malware with a flexible mapping algorithm and could be implemented in different situations. Compared to previous visualization methods, the simplicity of only two RGB color codes - (255, 255, 255) and (0,0,0) - involved in the transformed image significantly reduces the complexity of CNN architecture and computational costs. The images can be easily identified by both human and programmed classifiers.\nThe synthetic augmentation of malware images method on the basis of CGAN allows for strengthening the robustness of malware detection solutions. The conditional parameter setup in GAN model contributes to effective image gen-"}, {"title": "II. PROPOSED FRAMEWORK", "content": "Our research approach takes four steps to realize the application of a detection framework on pictorial formatted data, namely tabular data preparation and augmentation, pictorial representation system development, and, CNN and CGAN modelling. First, we implement Synthetic Minority Oversampling Technique (SMOTE) [17] on tabular data to synthesize new examples for the minority class (malign) and to obtain a balanced training dataset as baseline training set. Meanwhile, we design a binary pictorial system to transform each tabular data sample from training and testing datasets into a 64 \u00d7 64 pixels grayscale image. Second, a baseline CNN model is developed for image classification and also for comparing detection performance while excluding and including artificial pictorial data. Third, a cGAN model is designed to generate artificial pictorial data, which will be included into the original imbalanced training dataset for new balancing purpose. Finally, the CNN model is tuned to obtain new result based on the artificial dataset. Through this procedure, we will be able to learn how the detection model performs with the aid of pictorial data transformation. Additionally, we expect that the visualization approach makes malign samples easily distinguishable from the benign samples. Due to the information loss caused by the pictorial transformation, we expect a slightly lower accuracy while including artificial image data in the training set."}, {"title": "A. Tabular Data Preparation and Augmentation", "content": "1) Preparation: 1693 malign samples are firstly extracted from 50 malware that are validated by VirusTotal and collected from the Androzoo [18] database. Within a sandbox environment, each of these 50 malware was observed in action on an Android-based smartphone to gather the malign samples. To avoid the biases related to data coming from different sources, 60 trusted apps from Google Play Store and factory/system are selected as the source providing 3228 benign samples. In total 1465 malign samples and 3000 benign samples are randomly selected as our training dataset. The remain parts of data belong to the testing dataset - a balanced set with the same amount (228) of malign and benign samples. Applications' behaviors across the kernel's system were collected from a\nprobe we developed called map. The final datasets include 128 variables representing 128 time windows of same duration, in which the number of system call (behavior) is recorded. We also label the malign sample as 1 and benign as 0.\n2) Augmentation - SMOTE: Comparing with the data from benign apps, data from malware are limited and fall into minority category. The training dataset suffers from an imbalanced issue with 3000 data in majority class and only 1465 belonging to the minority class. Therefore, SMOTE is implemented to balance the training dataset that will be used to the CNN baseline model. Instead over-sampling with replacement of data in the minority class, the approach of SMOTE is to over-sample data by creating \u201csynthetic\u201d examples. Namely, for each sample $t_j$ in minority class, k nearest neighbors of this sample will be searched. Then a random neighbor will be chosen and defined as $t'$. Number $\\alpha$,$\\alpha \\in [0,1]$, is randomly generated. Then, as a new artificial sample, $t_{new}$ is introduced by:\n$t_{new} = t_j + (t' - t_j)\\alpha$\nBy implementing SMOTE method, the training dataset is balanced with 3000 samples in each category."}, {"title": "B. Pictorial Representation System (PRS)", "content": "1) PRS Denotation: A pictorial representation system is designed to transfer tabular data into image data. We propose $J = 128$ as a fundamental size for PRS, where J is the number of variables, and use \"padding\" for handling other sizes of J. The output image is set to square, with each dimension $D = \\frac{J}{2}$, and K is the number of pixels for each variable on the output image as well as the upper limit of the number of binary digits. We set $K = \\frac{J}{4}$. In our case $D = 64$ and $K = 32$ with predefined $J = 128$.\nFor each sample $X_i$, with $X_i = \\{x_1,...,x_J\\}$, where $x_j \\in \\mathbb{N}^0$, for each j = 1, \u2026, J, is the number of behaviors in a given time window. The sample $X_i$ is transformed into a grayscale image $M_i$ of dimension $D \\times D$ pixels. Thus, $X_i$ is mapped to $M_i$, where $M_i = \\{m_1,...,m_J\\}$ and $m_j$ represents a variable, for each j = 1, .., J. Hence, $x_j = m_j$. We convert each tabular input data from decimal integer into binary format, denoting as $x'_j = x_j$, so $x'_j = m_j$.\nWe extract each binary digit $p_k$ from $x'_j$ and get a set of 0 and 1 within the same order as the original binary digits, presenting as $x'_j = \\{p_1, ..., p_K\\}$, where $p'_k \\in \\{0,1\\}$ and $k \\leq K$. In other words, if $k > K$, it means $x'_j > 2^{32} (4, 294, 967, 296)$ as $K=32$ in proposed scenario. In such case, we set $x_j = 4,294,967,296$ and $p_1 = p_2= ... = p_K = 1$, because 4,294,967,296 is large enough to include majority cases in reality. Any larger number could be an outlier.\nWe assign each $p'_k$ to a pixel data $p_{r,c}$ on $m_j$, bringing us to $m_j = \\{p_1,..., p_K\\}$. Deriving from decimal code RGB, we acquire $p_{r,c} = (255, 255, 255)$ (white) if $p'_k = 0$ while $p_{r,c} = (0,0,0)$ (black) indicating $p'_k = 1$. Additionally, $p_{r,c}$ on the image $M_i$ can be located by row number r and column number c, for each $r,c = \\{1, ..., D\\}$ due to the dimension of $M_i$ is D \u00d7 D pixels. By combining location and color"}, {"title": "C. Convolutional Neural Network", "content": "Convolutional neural network (CNN) is defined as deep learning algorithms, primarily using to solve difficult image-driven pattern recognition tasks [19]. CNNs are comprised of three types of layers, namely convolutional, pooling, and fully-connected layers.\nConvolutional layers are designed to learn procedure of feature representations of the inputs. In convolutional layers, a series of different sizes convolution kernels/ filters are implemented for computing different feature maps. Mathematically, for each input $X_{p,q}$ at location(p,q) of the $l$ \u2013 th layer, the feature value $v_{p,q,n}^l$ is calculated as\n$v_{p,q,n}^l = w_n^l X_{p,q} + b_n^l$\nwhere n represents the n - th feature map of the l - th layer. w and b are the weight vector and bias term. Additionally w is shared with the next layer. In our model, two two-dimensional (2D) convolutional layers are proposed. In the first hidden layer, the input image with the dimensions of 64 by 64 is convolved with 32, 3 by 3, filters. For the second layer, 64, 3 by 3, filters are applied to the inputs for capturing 64 feature maps. The rectified linear activation function (ReLU) is used as nonlinear activation function on top of convolution in our model [20]. The activation value $A_{p,q,n}$ can be computed as:\n$A_{p,q,n} = max(v_{p,q,n}^l, 0)$\nOver each convolutional layer, we operate a max pooling layer to reduce the dimensions through extracting maximum value from every 2 by 2 patch on input data [21]. Thus, after the second max pooling layer, 64, 14 by 14, feature maps stack together. Then, a flatten layer is added on to shape pooled feature maps into a one-dimensional (1D) array (size 12544) of numbers (or vectors). A fully connected layer (known as dense layer) is imposed to connect each of 12544 inputs to each of 128 outputs. On this step, a ReLU activation function as described above is used. As a final touch, we add a softmax unit with two features, representing 0 and 1 classes. Fig. 2 shows the architecture of our CNN model."}, {"title": "D. Conditional Generative Adversarial Network", "content": "Reference [12] first introduced Generative Adversarial Network (GAN) as a pair of neural networks: a generative model\nG and a discriminative model D. In the G model, input noise vectors z with a predefined probability distribution pz are mapped from the noise space $N_z$ to the image space $N_x$ for capturing the distribution $P_{data}$ of all possible data in $N_x$, as D model is to distinguish the real data from $P_{data}$ and fake ones synthesized by G model. Model G and D are simultaneously trained and optimized in an adversarial situation. A value function is proposed by [12] as :\n$\\min_G \\max_D V (D,G) = \\mathbb{E}_{x \\sim p_{data}(x)}[log D(x)] + \\mathbb{E}_{z \\sim p_z(z)} [log(1 \u2013 D(G(z)))]$\nConditional GAN (cGAN) [22, 23] is an extension of GAN model with certain information (\"conditions\") included in the inputs. In our model, conditions $y \\in \\mathcal{N}$ are class labels, 0 or 1, representing benign or malign. y is fed into both G and D models as additional input layer. Therefore, the new value function is developed as:\n$\\min_G \\max_D V (D,G) = \\mathbb{E}_{x \\sim p_{data}(x)}[log D(x|y)] + \\mathbb{E}_{z \\sim p_z(z)}[log(1 \u2013 D(G(z|y)))]$\nAs mentioned above, for both G and D model, we first need to create a layer embedded for class input and merged with image inputs. After the first step, D model is composed with 3 hidden layers with 128, 256, and 516 feature outputs, each followed by a Leaky version of ReLU activation layer (LeakyReLU) with threshold $a = 0.2$, allowing a small gradient 0.2 * x when the unit x < 0. The added out layer is activated with"}, {"title": "III. EXPERIMENTS", "content": "Training and testing data are processed and transformed into pictorial format through the PRS system. Samples with two classes are presented on Fig. 4. Comparing to samples with malign label, images with benign label have less amount of black colors, most of which are only scattered around corners and edges, indicating variables with smaller values. This result matches our expectations. According to observations on tabular data, we notice that large numbers are concentrated in malign samples. Additionally, a larger proportion of non-zero variables per sample appears frequently in malign class. Therefore, on average, more black pixels occur on malign samples and are inclined to drift from both left and right sides to the middle part of the image."}, {"title": "B. Generating Artificial Malware Images", "content": "As introduced in previous section, 3000 benign samples and 3000 malign samples are fed to the cGan model. We experiment with different options and combinations of hyperparameters to tune the model. Finally, we select 0.0002 learning rate for the optimizer of D model. The best performance CGAN model is realized with epochs = 100 and batch_size = 128. Fig. 5 shows the learning curve of cGan model. We can conclude that after passing initial somewhat erratic stage, models D and G reach convergence after about 1500 iterations. At convergence, the loss of G model and the loss of D model on both discriminating real and generated data are all stabilized around 0.69, meaning that for both models, improvements to one model will not come at the expense of the other model. A point of equilibrium between the two competing concerns is reached.\nSamples of malware images generated by the model are presented in Fig. 6. Artificial malware image samples exhibit very similar patterns with the real ones. In both cases, a large amount of black pixel blocks are dispersed on the images. This procedure brings us 1535 artificial malign samples, which will be included in the training data for the next step."}, {"title": "C. Comparing Malware Detection Performances", "content": "Two sets of training data have been obtained, namely, the original dataset and the one containing artificial samples generated through cGAN model. We feed both sets to CNN models and compare their performances on detecting malware from the same testing set. The goal of the comparison involves finding whether visualized malware according to PRS could be easily identified by similar models without complex feature tuning procedures.\nThe baseline model proposed in the previous section is composed according to the original dataset. We also implement 5-fold cross validation technique on the training set for evaluating the model. The average accuracy of the baseline model during cross validations is 98.51%. We apply the same procedure on the dataset with artificial images, bringing us a slightly lower average validation accuracy, 97.26%. We proceed to fit the models to the same testing dataset in order to compare detection performances using different training sets. We summarize the performance of both CNN models in Table\nI and Fig. 7.\nAccording to F1-score on Table I, we can see that model trained on the original dataset shows slightly better performance than the one trained on the dataset with artificial images. The accuracy score is 1.1 percentage higher. As reported in the confusion matrix in Fig. 7, it is noticeable that the model performing on the artificial dataset generates fewer"}, {"title": "IV. CONCLUSION AND FUTURE WORK", "content": "In this work, we have proposed a Pictorial Representation System (PRS) of transforming tabular data into images, visualizing the behavioral patterns on malware for identifying purpose. We have developed a conditional Generative Adversarial Network (cGAN), by which the same type of malware images could be successfully synthesized to tackle imbalanced data problems caused by uneven distribution of benign and malicious software. We have implemented Convolution Neural Networks (CNNs) to compare the classification accuracy with and without training on synthetic images. We obtained comparable malware detection performance on both datasets.\nThe proposed PRS approach can be used to preserve malware identity not only for being easily recognized by human eyes but also for analyzing malicious behavioral patterns. Our procedure involved with CNN and CGAN can be used to achieve synthetic augmentation of malware datasets as well as for improving the robustness of malware detection solutions. Moreover, we have introduced a padding method to extend the PRS for generating images of arbitrary sizes. In the future, we plan to explore other methods for extensions of the PRS and combine improved CNN and cGAN in a wide range of applications for malware detection purpose."}]}