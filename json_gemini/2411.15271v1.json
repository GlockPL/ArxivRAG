{"title": "EADReg: Probabilistic Correspondence Generation with Efficient\nAutoregressive Diffusion Model for Outdoor Point Cloud Registration", "authors": ["Linrui Gong", "Jiuming Liu", "Junyi Ma", "Lihao Liu", "Yaonan Wang", "Hesheng Wang"], "abstract": "Diffusion models have shown the great potential in the\npoint cloud registration (PCR) task, especially for enhanc-\ning the robustness to challenging cases. However, existing\ndiffusion-based PCR methods primarily focus on instance-\nlevel scenarios and struggle with outdoor LiDAR points,\nwhere the sparsity, irregularity, and huge point scale in-\nherent in LiDAR points pose challenges to establishing\ndense global point-to-point correspondences. To address\nthis issue, we propose a novel framework named EAD-\nReg for efficient and robust registration of LiDAR point\nclouds based on autoregressive diffusion models. EAD-\nReg follows a coarse-to-fine registration paradigm. In the\ncoarse stage, we employ a Bi-directional Gaussian Mixture\nModel (BGMM) to reject outlier points and obtain puri-\nfied point cloud pairs. BGMM establishes correspondences\nbetween the Gaussian Mixture Models (GMMs) from the\nsource and target frames, enabling reliable coarse regis-\ntration based on filtered features and geometric informa-\ntion. In the fine stage, we treat diffusion-based PCR as\nan autoregressive process to generate robust point corre-\nspondences, which are then iteratively refined on upper lay-\ners. Despite common criticisms of diffusion-based meth-\nods regarding inference speed, EADReg achieves runtime\ncomparable to convolutional-based methods. Extensive ex-\nperiments on the KITTI and NuScenes benchmark datasets\nhighlight the state-of-the-art performance of our proposed\nmethod. Codes will be released upon publication.", "sections": [{"title": "1. Introduction", "content": "Point cloud registration (PCR) in outdoor environments is a\nfundamental task, which aims to compute the 6-DOF rigid\ntransformation between two LiDAR frames. It is essential\nto various downstream applications, such as global local-\nization [11, 44, 50, 60], SLAM [4, 18, 25], navigation and\nauto-driving applications [10, 26, 31, 34, 35, 42, 44]. The\nformal procedure for PCR involves extracting reliable point\nfeatures using hand-crafted or learning-based methods, in-\ntroducing alignment algorithms to establish point-to-point\n(P2P) correspondences, and finally calculating the transfor-\nmation parameters via singular value decomposition (SVD).\nEstablishing accurate P2P correspondences is a key issue\nin PCR [7, 33, 47, 69]. Recent methods have concentrated\non enhancing the reliability of point correspondences. Geo-\nTransformer [47] improves the correspondence establish-\nment by introducing the geometric transformer into PCR\ntasks. DiffusionPCR [7] constructs a powerful transformer\nfeature extraction module to ensure high-quality correspon-"}, {"title": "2. Related Work", "content": "PCR is a fundamental research task in 3D computer vi-\nsion field. In this section, we respectively discuss prior\nLearning-based PCR Methods, GMMs-based PCR Meth-\nods, and Diffusion-based PCR Methods.\nLearning-based PCR Methods. Traditional methods\nlike Iterative Closest Point (ICP) [2] and RANSAC [13] are\ndesigned for the registration task. However, these meth-\nods require either favorable initial transformations or point-\nlevel correspondences. With the advent of deep learning\ntechniques, learning-based methods [29, 36, 39, 47] have\nachieved significant success in the PCR task. Relying on\npowerful backbones like PointNet [45], KPConv [52], and\nPoint TransFormer [66], these methods generally downsam-\nple the original point cloud into superpoints and generate\nassociated features with informative information. Subse-\nquently, the transformation can be derived by construct-\ning accurate point-to-point (P2P) correspondences. Unlike\nindoor and object-level registration, outdoor point clouds\nscanned from LiDAR sensors typically exhibit higher spar-\nsity and larger point magnitude, leading to more challenging\nregistration issues. To address these challenges, specific de-\nsigns have been made to ease the difficulty and reduce the\nnetwork burden during training. HRegNet [39] and Reg-\nFormer [32] introduce a coarse-to-fine framework to per-\nform registration hierarchically, which accommodates the\ntraining process with increasing point magnitudes. How-\never, employing prevalent powerful Transformer architec-\nture to extract representative features is inevitable leading\nto slow convergence and significant memory usage.\nGMMs-based PCR Methods. Unlike point-level reg-\nistration, GMMs-based PCR methods model point clouds\nvia the Expectation-Maximization (EM) optimization algo-\nrithm into several clusters and perform alignment based on\nthe modeling results. DeepGMR [64] estimates transfor-"}, {"title": "3. EADReg", "content": "Establishing dense point-to-point correspondence is infeasi-\nble and computationally-denied due to the huge point scales\nin outdoor scenes. Therefore, EADReg adopts a coarse-to-\nfine paradigm, which firstly utilizes the descriptor-detector\nbackbone [39] to hierarchically down-sample the point\nclouds and extract the corresponding multi-scalefeatures.\nSpecifically, given source and target point clouds $P_S$, $P_T \\in$"}, {"title": "3.1. Network Pipeline", "content": "IR^{N\\times3}, the detector utilizes Weighted Furthest Point Sam-\npling (WFPS) [68] to downsample the point clouds to dif-\nferent scales of superpoints $P_i \\in R^{N_i\\times3}$, then the descrip-\ntor module extracts their corresponding descriptor $D_i \\in$\n$R^{N_i\\times C}$ and uncertainty values $U_i \\in R^{N_i}$, where $N_i$, $C_i$\nare the number of superpoint and channel, the corner mark\n$l\\in \\{c, f\\}$ indicates the coarse and fine registration stage.\nThe details of the detector-descriptor backbone will be pro-\nvided in supplementary material.\nSince the PCR task has a demand for high inference\nspeed, the prediction networks $F_c$ we used in the coarse and\n$F_f$ in fine stage are similar and only constitute with several\nlight-weight CBR (Convolution, Batch Normalization and\nReLU) modules, the details of $F_f$ is shown in the bottom of\nFig. 2, the forward process will be discussed in the Sec. 3.2\nand Sec. 3.3."}, {"title": "3.2. Bi-directional GMMs for Outlier Removal", "content": "In previous works, GMMs are widely used to perform reg-\nistration between point cloud pairs [12, 14, 46, 64]. Specif-\nically, they first model the point cloud pairs with GMMs,\nthen use the Expectation Maximization (EM) algorithm [9]\nto estimate the real transformation between GMM clusters,\nwhich alternates between Expectation step and Maximiza-\ntion step for several iterations.\nHowever, the estimation performance of the GMMs-\nbased registration method heavily relies on the modeling\nquality of GMMs. Due to the presence of noise and out-\nliers in outdoor scenes, performing registration between the\nGMMs group of the LiDAR point cloud pairs will lead to\nthe poor performance. In this work, instead of leveraging\nGMMs as a predictor to estimate the transformation matrix,\nwe adopt it as an outlier-rejection module based on the ge-\nometric features of GMMs. Unlike previous learning-based\noutlier prediction methods [5, 6, 61], we introduce no extra\nparameters leading to high efficiency. Specifically, GMMs\nare first used to establish a multi-modal probability distribu-\ntion over 3D space which can be represented as a weighted\nsum of $J$ Gaussian distributions as follows:\n$p(x | \\Theta) := \\sum_{j=1}^{J}\\pi_jN(x | \\mu_j, \\Sigma_j),$ (1)\nwhere $x$, $\\Theta$ represent the points and GMMs parameters re-\nspectively. $\\Theta$ consists of $J$ triplets $(\\pi_j, \\mu_j, \\Sigma_j)$, where $\\pi_j$\nis a scalar mixture weight and $\\sum_j \\pi_j = 1$, $\\mu_j \\in R^{3\\times1}$ is\nthe mean vector and $\\Sigma_j \\in R^{3\\times3}$ is the covariance matrix of\nthe $j$-th component.\nFor filtering out the outliers, simply using bi-directional\nfirst nearest nei maching can lead to plenty of misjudge-\nments, due to the randomness of the probabilistic model.\nWe loose the strict rules by only removing the GMMs which"}, {"title": "3.3. Efficient Autoregressive Diffusion", "content": "Previous correspondence-based registration methods [47,\n58, 63] focus on directly generating the global P2P cor-\nrespondence with dimension $N_S \\times N_T$, However, the\ndiffusion-based methods are roundly criticized for the low\nconvergence speed, predicting global dense P2P correspon-\ndences will aggravate the burden of training computation as"}, {"title": "3.4. Loss Function", "content": "The overall loss function can be written as:\n$L = L_{trans} + \\alpha L_{rot} + L_{diff},$ (17)\nwhere $L_{trans}$ and $L_{rot}$ are translation loss and rotation loss,\nrespectively. $L_{diff}$ is the loss in diffusion model training.\nSpecifically, given each estimated transformation in the for-\nward process $\\hat{R}$, $\\hat{t}$ and the ground truth $R$, $t$, $L_{trans}$ and $L_{rot}$\ncan be calculated as:\n$L_{trans} = ||\\hat{t} - t_1||^2, l \\in \\{c, f\\},$ (18)\n$L_{rot} = ||\\hat{R}^TR - I||^2, l \\in \\{c, f\\},$ (19)\nwhere $I$ denotes identity matrix. The training loss for the\ndiffusion model $\\mu_f$ is presented as:\n$L_{diff} = E_{t\\sim[0, T]} ||F_f[C_t, t, F_G, F_D] - C_{gt}||^2.$ (20)\nIn order to get the supervision $C_{gt}$, we first use the GT trans-\nformation $R,t$ to warp the source superpoints as $P'=$\n$RPS + t$. Then, we obtain the global correspondence ma-\ntrix $C_{gt}$ by utilizing the Optimal Transport algorithm [54]\nto refine the distance matrix between $P'$ and $PT$. Fi-\nnally, each source superpoint $P_S$ searches its $K$ nearest\ntarget superpoints $P_T$ to build the local GT corresponding\n$C_{gt} \\in R^{N\\times K}$."}, {"title": "4. Experiments", "content": "Datasets. We conduct extensive experiments on three large-\nscale point cloud datasets, KITTI [15], NuScenes [3] and\nApollo [40]. KITTI odometry dataset consists of 11 se-\nquences (00-10) with ground truth vehicles poses. It is\nworth noting that, in the outdoor PCR field, the point cloud"}, {"title": "4.2. Evaluation", "content": "Qualitative Visualization We visualize the registration re-\nsults with 3 samples from KITTI, Nuscenes and Apollo\ndatasets in Fig.3.\nSpecifically, we first select the correspondences with\nconfidence weights $w$ greater than 0.001. Then, we warp the\nselected source points using the ground truth transforma-\ntion. If the distance between a warped source point and the\ntarget point exceeds 5 meters, the correspondence is consid-\nered a wrong prediction; otherwise, it is regarded as correct.\nTo verify the effectiveness of our proposed BGMM Out-\nlier Removal module, we present four removal results in\nFig. 4. From the visualization, it is evident that BGMM\nsuccessfully removes outlier points and retains all the points\nrelevant for registration.\nQuantitative Evaluation We adopt relative translation\nerror (RTE), relative rotation error (RRE), registration recal\n(RR) and average running time on the test point cloud pairs\nto evaluate the registration performance. Specifically, since\nthe failed registrations can result in exceptionally large RRE\nand RTE values, leading to unreliable error metrics [39]."}, {"title": "4.3. Ablation Study", "content": "We perform abundant ablation studies on KITTI dataset to\ndemonstrate the effectiveness of the hierarchical structure\nand the introduction of the similarity features.\nNetwork Structure: We use the output transformation $R, t$\nfrom the coarse stage and the fine stage respectively for\nevaluation. The registration results are shown in Tab.3.\nSince the average RRE of the coarse stage with 0.119cm\nis better than the learning based method DGR [8] with 0.32,\nwe can demonstrates that the coarse stage do provide a reli-\nable initial transformation.\nNumber of GMM Clusters: According to the results in\nTab. 4, although the results show minimal changes as $J$ in-\ncreases, the inference time increases steadily, from 129.4\nms to 143.5 ms. Thus, we choose $J = 8$ for experiments.\nWeight of the a: EADReg is trained with combinations\nof translation loss $L_{trans}$, rotation loss $\\alpha L_{rot}$ and diffusion\nloss $L_{diff}$. We leave the ablation study of different set the\nweights of $L_{diff}$ and $L_{trans}$ to 1 for experiments and leave\nthe ablation study in the supplementary materials. Accord-\ning to Tab.5, as the $\\alpha$ increases, the average RRE monoton-\nically decreases from 0.154 to 0.100 and RTE reaches the\nbest when $\\alpha = 4$. In order to balance the performance be-\ntween RTE and RRE metrics, we choose $\\alpha = 4$ for our ex-\nperiments, which achieves the best RTE with 4cm and sub-\noptimal RRE with 0.115 degree, and the best recall 100%.\nNumber of Correspondence Candidate: In this part,\nwe demonstrate the reason why generating the global P2P\ncorrespondenceC $E R^{N\\times N}$ can be impractical for de-\nployment. From Table 6, we observe that increasing $K$ only\nslightly affects registration performance, supporting our hy-\npothesis that true correspondences lie in the nearest top-$K$\nneighbors after reliable coarse registration. However, GPU\nmemory usage rises sharply from 19,083 MB to 23,571 MB,\nindicating that predicting global P2P correspondences will\ninevitably lead to prohibitive training overhead.\nNumber of Sampling Steps: We further conduct sev-\neral experiments with different diffusion step numbers and\npresent the results in Tab.7. We observe that the perfor-\nmance stabilize after $S = 3$, and shows minor improve-\nments when $S > 3$. Meanwhile, the inference time of EAD-\nReg monotonically increasing, from 115.6ms to 148.8ms,\nin order to balance the accuracy and efficiency, we choose\n$S = 3$ in our method."}, {"title": "5. Conclusion", "content": "In this paper, we provide an efficient diffusion-based net-\nwork for large-scale outdoor LiDAR point cloud registra-"}]}