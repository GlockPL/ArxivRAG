{"title": "R-MTLLMF: Resilient Multi-Task Large Language Model Fusion at the Wireless Edge", "authors": ["Aladin Djuhera", "Vlad C. Andrei", "Mohsen Pourghasemian", "Haris Gacanin", "Holger Boche", "Walid Saad"], "abstract": "Multi-task large language models (MTLLMs) are important for many applications at the wireless edge, where users demand specialized models to handle multiple tasks efficiently. However, training MTLLMs is complex and exhaustive, particularly when tasks are subject to change. Recently, the concept of model fusion via task vectors has emerged as an efficient approach for combining fine-tuning parameters to produce an MTLLM. In this paper, the problem of enabling edge users to collaboratively craft such MTTLMs via tasks vectors is studied, under the assumption of worst-case adversarial attacks. To this end, first the influence of adversarial noise to multi-task model fusion is investigated and a relationship between the so-called weight disentanglement error and the mean squared error (MSE) is derived. Using hypothesis testing, it is directly shown that the MSE increases interference between task vectors, thereby rendering model fusion ineffective. Then, a novel resilient MTLLM fusion (R-MTLLMF) is proposed, which leverages insights about the LLM architecture and fine-tuning process to safeguard task vector aggregation under adversarial noise by realigning the MTLLM. The proposed R-MTLLMF is then compared for both worst-case and ideal transmission scenarios to study the impact of the wireless channel. Extensive model fusion experiments with vision LLMs demonstrate R-MTLLMF's effectiveness, achieving close-to-baseline performance across eight different tasks in ideal noise scenarios and significantly outperforming unprotected model fusion in worst-case scenarios. The results further advocate for additional physical layer protection for a holistic approach to resilience, from both a wireless and LLM perspective.", "sections": [{"title": "I. INTRODUCTION AND MOTIVATION", "content": "Future 6G wireless networks will enable reliable, low-latency, and intelligent communications to support critical technologies such as artificial intelligence (AI) [1], distributed and collaborative machine learning (ML) [2], and intelligent edge computing [3]. Recent advancements in large language models (LLMs) in particular have motivated several use cases for the wireless industry, including network design, resource allocation, and standardization [4]. In this generative AI vision of the future, distributed agents will play a central role in fine-tuning, sharing and merging LLMs at the wireless edge [5]. For example, [6] presents a framework where distributed agents use LLMs for reasoning and collaboration in wireless networks, supporting knowledge-based edge device queries.\nHowever, due to the large size of LLMs, traditional fed-erated learning (FL) [7] approaches are often inefficient in scenarios where users demand multi-task capabilities that may change over time. FL typically requires extensive training over multiple communication rounds and assumes that users have limited data and compute resources, which can be restrictive for specialized edge devices with significant processing power and data. In contrast, multi-task model fusion (MTMF) enables each client to contribute a task-specific model directly without collaboratively fine-tuning a single multi-task LLM (MTLLM). Instead, the authors in [8] introduce the concept of task vectors which capture task-specific adjustments that can be efficiently aggregated to produce a high-performing MTLLM with minimal computation and communication over-head at the aggregator. This approach avoids the inflexibility of FL by enabling quick adaptation to new tasks as they arise, without re-training from scratch. In addition, it is amenable for various parameter-efficient fine-tuning (PEFT) methods [9]. Thus, MTMF is better suited for scenarios where user requirements and tasks change dynamically, providing a more efficient and adaptable framework than conventional FL.\nHowever, task vector transmissions may be prone to both adversarial attacks and suboptimal channel conditions, which may significantly increase task interference. In our previous work in [10], for example, we investigated worst-case jamming for split FL where intermediate model parameters were trans-mitted. We explicitly showed that worst-case jammers lead to worst-case performance and developed an effective, sensing-assisted physical layer protection scheme. In contrast, MTMF represents a distributed inference scenario in which adversarial noise during task vector aggregation may be catastrophic.\nThe main contribution of this paper is, thus, an analysis of adversarial attacks on MTMF over wireless channels and the development of a resilient MTLLM fusion framework (R-MTLLMF), which leverages the unique architecture and fine-tuning characteristics of LLMs within MTMF to safeguard task vector aggregation against adversarial noise. To this end, we investigate worst-case channel conditions in which adversarial noise, induced by a malicious attacker with optimal attack strategy, considerably decreases the communication rate below a certain threshold, such that reactive network defenses and other upper-layer resilience mechanisms are insufficient"}, {"title": "II. MULTI-TASK MODEL FUSION AT THE WIRELESS EDGE", "content": "In this section, we introduce MTMF, derive the relationship between the WDE and the wireless MSE, and design the worst-case adversarial noise covariance. The system model as well as our R-MTLLMF framework to safeguard MTMF at the wireless edge are shown in Figure 1.\nA. Wireless MTMF System Model\nWe consider a collaborative inference setup in which a set Q of Q single-antenna users construct MTLLMs for several different tasks at a time, starting from the same pre-trained LLM. To this end, each user $q \\in Q$ first fine-tunes the LLM on its respective task and data, and computes the task vector $\\tau_q$ by subtracting fine-tuned and base model parameters, i.e.\n$\\tau_q = \\Theta_{fine-tuned,q} - \\Theta_{base}$.\nThen, each user encodes its task vector and transmits unit variance symbols $s_q$ with power $p_q \\leq P_q$ over a MIMO multiple access channel (MAC) to a base station (BS) with $N_R$ receive antennas. The wireless transmission model is given as:\n$y = \\sum_{q=1}^Q h_q\\sqrt{P_q}s_q + z, z \\sim \\mathcal{N}(0,C_z)$,\nwith noise covariance $C_z$, total noise power $P_N \\geq tr(C_z)$, and with Rayleigh distributed user channels $h_q$. We further assume that the BS performs successive interference cancellation (SIC), and set the SIC ordering to $p_1 \\|h_1\\|^2 < \\dots < p_Q \\|h_Q\\|^2$. With that, the achievable rate of each user q will be given by:\n$R_q = \\log\\Big(1 + \\frac{p_q |h_q^H h_q|}{h_q^H X_q h_q}\\Big)$,\nwhere we abbreviated $X_q = \\sum_{q'>q}P_{q'}h_{q'}h_{q'}^H+C_z$. Further, we can write the corresponding sum rate for all users as:\n$R = \\log\\Big(|I + \\sum_{q=1}^Q p_q h_q h_q^H C_z^{-1}|\\Big)$.\nWe assume that the BS performs minimum MSE (MMSE) equalization, such that the achievable MSE per user q is\n$\\epsilon_q = \\Big(1 + p_q h_q^H X_q^{-1} h_q\\Big)^{-1} = e^{-R_q}$.\nUpon receiving the task vector symbols $\\hat{s}_q$, the BS then aggregates all decoded $\\tau_q$ to define the new MTLLM parameters using a heuristic scaling term $\\lambda_N \\in [0, 1]$, which is only dependent on the number of tasks N as outlined in [8], i.e.\n$ \\Theta_{MTLLM} = \\Theta_{base} + \\lambda_N \\sum_{q=1}^{N=Q} \\tau_q$.\nThe BS then broadcasts $\\Theta_{MTLLM}$ to the requesting parties for inference and thus acts as an on-demand model fusion server. Such individually fine-tuned LLMs, initialized from the same pre-trained model $\\Theta_{base}$, effectively share a part of the optimization trajectory and can therefore often be efficiently merged while increasing the cross-task performance [8]. However, worst-case channel conditions may lead to decoding er-rors where $\\hat{\\tau}_q \\neq \\tau_q$, thereby significantly altering the decoded task vectors and introducing severe task interference. In order to analyze the effect of such errors on MTMF, we investigate worst-case adversarial noise attacks [11] and develop an AI-based protection scheme using insights on LLM fine-tuning."}, {"title": "B. Wireless Influence on Cross-Task Interference", "content": "In general, MTMF may introduce task interference if orthogonality between task vectors cannot be ensured, particu-larly as the task count increases [8]. The WDE [9] measures cross-task interference by comparing model predictions for in-dividual versus simultaneous task vector additions. For N > 2 tasks and task dataset distribution P(DT\u2081), it is defined as:\n$\\xi(\\lambda) = \\sum_{i=1}^{N} E_{x \\sim P(DT_i)} \\Gamma$,\nwhere \u0393 is a distance metric, for example the indicator function 1(.) for classification tasks, between two model outputs f(x, \u03b8), with input data x and model parameters \u03b8, i.e.\n$\\Gamma = 1 \\Big[ f\\Big(x; \\Theta_{base} + \\lambda_i\\tau_i\\Big), f \\Big(x; \\Theta_{base} + \\lambda_N \\sum_{j=1}^{N} \\tau_j\\Big)\\Big]$.\nA lower value of \u03be indicates that the task vectors are well-disentangled, implying less task interference. In order to better capture the change when task vectors are exposed to wireless noise, we model the indicator function as a hypothesis test:\nNull Hypothesis H\u2080: The noise in the task vectors does not significantly alter the model's predictions.\nAlternative Hypothesis H\u2081: The noise in the task vectors leads to a significant change in the model's predictions.\nLet $z_u(x)$ and $z_d(x)$ be the logits of the undisturbed and disturbed MTLLMs, respectively. The test statistic is the ratio $\\mathcal{R}(x) = \\frac{z_u(x)}{z_d(x)}$. Under H\u2080, we thus require $\\mathcal{R}(x) \\approx 1$. In case of noisy $\\tau_q$, the difference in model parameters will be:\n$\\Delta \\Theta = \\sum_q \\lambda_N (\\tau_q + \\epsilon_q) - \\sum_q \\tau_q = \\sum_q \\epsilon_q$,\nwhere $ \\epsilon_q = \\lambda_N \\tilde{\\epsilon}_q$, reflects the cumulative post-decoding errors. Assuming that $\\epsilon_q$ are small, we can perform a first-order Taylor expansion of the logits around the undisturbed parameters, i.e.\n$z_d(x) \\approx z_u(x) + J_{\\Theta} \\Delta \\Theta = z_u(x) + J_{\\Theta} \\sum_q \\epsilon_q$,\nwhere $J_{\\Theta}$ is the Jacobian of the logits with respect to \u0398. The deviation in the logits is thus directly proportional to $\\epsilon_q$. With $||J_{\\Theta} \\epsilon_q|| < z_u(x)$, we then have for the test statistic that $\\mathcal{R}(x) \\approx 1 - \\sum_q \\epsilon_q$, which shows that $|\\mathcal{R}(x) - 1|$ is proportional to $\\epsilon_q$. For both $\\epsilon_q$ to remain small, we thus minimize the wireless sum MSE, i.e. $\\sum_q \\epsilon_q = \\sum_q \\mathbb{E} [|\\epsilon_q|^2]$. To determine the hypothesis threshold T, we further consider the distribution of $\\mathcal{R}(x)$ under H\u2080. Assuming that the perturbations $\\epsilon_q$ are random variables with zero mean and variance related to the MSE, $|\\mathcal{R}(x) - 1|$ can be modeled as:\n$\\mathbb{Var}[|\\mathcal{R}(x) - 1|] \\approx \\Big| \\frac{J_{\\Theta}}{z_u(x)} \\Big|^2 \\sum_q \\sigma^2_{\\epsilon_q}$.\nWe thus set T based on the standard deviation of $|\\mathcal{R}(x) - 1|$, i.e. $T = z_{\\beta} \\cdot \\sqrt{\\mathbb{Var}[|\\mathcal{R}(x) - 1|]}$, where $z_{\\beta}$ is the z-score w.r.t. to a significance level \u03b2. Alternatively, T can also be chosen depending on additional insights, for example, on the model architecture and data quality. The null hypothesis is then rejected if $|\\mathcal{R}(x) - 1| > T$. Thus, minimizing the sum MSE increases the likelihood of satisfying H\u2080, i.e.\n$\\Pr(|\\mathcal{R}(x) - 1| \\leq T) \\to 1 \\text{ as } \\sum_q \\sigma^2_{\\epsilon_q} \\to 0$.\nModeling the indicator function in (8) as a hypothesis test reveals that the wireless MSE directly impacts the cross-task interference. When H\u2080 is unmet, interference increases with \u0393 and WDE values, degrading multi-task performance due to increased weight entanglement. This insight underscores the need for resilient MTMF strategies under worst-case adversar-ial attacks where standard resilience measures fall short. As we explore AI-based methods for mitigating adversarial noise, understanding the limits under such conditions is essential before deploying additional wireless or AI countermeasures."}, {"title": "C. Worst-Case Adversarial Noise Covariance Design", "content": "To design $C_z$ for the worst-case attack strategy, we consider adversarial noise for both system sum rate (P1) and strongest user (P2). This allows us to study the impact of the attack on the network as well as on individual task vectors. Formally, we investigate the following saddle point problems:\n$\\begin{aligned} &C_z^{(1)} = \\underset{C_z \\in \\mathcal{S}(P_N)}{\\arg \\min} \\underset{P \\in \\mathcal{P}}{\\max} R(p, C_z),&\\text{(P1)} \\\\ &C_z^{(2)} = \\underset{C_z \\in \\mathcal{S}(P_N)}{\\arg \\min} \\underset{P \\in \\mathcal{P}}{\\max} \\underset{q \\in Q}{\\max} R_q(p, C_z),&\\text{(P2)} \\end{aligned}$ where $p = [p_1, ..., p_Q] \\in \\mathbb{R}^Q$, $\\mathcal{P} = \\{ p | p > 0, p_q \\leq P_q \\}$, and $\\mathcal{S}(P_N) = \\{ C | C_z = C_z^H, C_z \\geq 0, tr(C_z) < P_N \\}$.\n1) Ideal Case: First, we discuss the ideal transmission case corresponding to the scenario in which we solve the inner maximizations in (P1) and (P2). In this setup, $h_q C_z^{-1} h_q \\geq 0$, making the sum rate an increasing function of p. Since $\\mathcal{P}$ is a convex set, the maximum in (P1) and (P2) is attained at the boundary, i.e., when each user transmits with maximum power $p = P_q$. We define this as the ideal case, used as a benchmark for typical channel conditions in our experiments.\n2) Solution to (P1): Setting $p = P_q$ accordingly and defining $P = diag(p^*) \\in \\mathbb{R}^{Q \\times Q}$, we can rewrite (P1) as:\n$C_z^{(1)} = \\underset{C_z \\in \\mathcal{S}(P_N)}{\\min} \\log \\text{ det }\\Big(I + HPH^H C_z^{-1}\\Big)$.\nBy Hadamard's inequality, $C_z = U \\Sigma U^H$ is the optimal so-lution with eigenvectors U of $HPH^H$, reducing the problem to optimizing the eigenvalues $\\Sigma = diag(\\sigma_i)$ as in [11]:\n$\\sigma_i = \\frac{1}{2} \\Big(-1 + \\sqrt{1 + \\frac{4 P_i v_i}{\\nu}} \\Big)^{-1}$,\nwhere $v_i$ are the eigenvalues of $HPH^H$, and $v \\geq 0$ is chosen to satisfy $\\sum_i^{N_R} \\sigma_i \\leq P_N$, computed via the bisection method.\n3) Solution to (P2): Following similar arguments for the inner maximization, we use the SIC ordering from Section II.A, noting that $\\underset{q \\in Q}{\\max} R_q = R_Q$. This rewrites (P2) as:\n$C_z^{(2)} = \\underset{C_z \\in \\mathcal{S}(P_N)}{\\min} \\log \\text{ det }\\Big(I + P_Q h_Q h_Q^H C_z^{-1}\\Big)$,\nwhere the optimal $C_z = \\frac{P_Q h_Q h_Q^H}{\\|h_Q\\|^2}$ is obtained by aligning the noise covariance with the strongest user channel."}, {"title": "III. R-MTLLMF: AI-DRIVEN RESILIENCE AGAINST ADVERSARIAL NOISE", "content": "To address the challenges posed by adversarial noise on task vector aggregation in MTMF, we approach resilience from an AI perspective by introducing R-MTLLMF, an AI-based framework designed to mitigate adversarial cross-task interference. As shown in Figure 1, it consists of two core modules which work together by leveraging insights on both LLM architecture and task vector characteristics in MTMF:\nTask Vector Aggregation with Frozen LLM Parameters: Given the severity of noise at inference time, we freeze sensitive position, patch and class embeddings of the base model $ \\Theta_{base}$, and reload them into $ \\Theta_{MTLLM}$ after task vector aggregation. Freezing these parameters ensures that funda-mental data representations remain intact, reducing the risk of noise-induced shifts in essential encodings. This is a valid approach since fine-tuning pre-trained models mostly affects the self-attention layers, and since $ \\Theta_{base}$ remains identical across tasks [5]. Thus, by preserving embeddings, we main-tain the integrity of structural representations learned during pre-training, thereby stabilizing the model's output.\nFew-Shot Realignment: To correct for noise-induced per-turbations in self-attention parameters, we apply a few-shot fine-tuning step to realign the MTLLM on a small, represen-tative data subset (typically 10 samples per class). This can be sourced from episodic memory, as in [13], or a public dataset for privacy considerations, and can be performed at the MTMF BS. By realigning the attention mechanism on few samples, the model restores the contextual relationships between tokens that may be distorted due to noise. Drawing on insights from task vector research in [5], [8], this heuristic relies on the notion that noise, if not substantial, leaves the underlying task vector directionality of $\\tau_q$ largely intact, allowing the model's performance to be recovered with minimal fine-tuning. Thus, realignment addresses moderate perturbations, restoring the model's reasoning capabilities.\nR-MTLLMF introduces an AI-based protection scheme to ensure resilient model outputs at inference time. It per-forms few-shot fine-tuning to realign the perturbed model, and freezes sensitive embedding parameters to ensure criti-cal integrity of data representations. While typical resilience methods in distributed learning often rely on additional phys-ical layer measures [10], R-MTLLMF focuses on enhancing resilience within the LLM architecture itself. This heuristic, grounded in recent findings on task vectors, thus provides a flexible, low-overhead resilience layer, optimized for dynamic MTMF scenarios. However, R-MTLLMF may be insufficient if the channel conditions are detrimental, such that the low-noise assumption for few-shot realignment is invalidated. To this end, we will investigate both ideal and worst-case adversarial noise scenarios in the subsequent experiments, demonstrating R-MTLLMF's effectiveness in typical condi-tions while examining its limits under adversarial interference. To ensure the best possible protection against worst-case con-ditions, including noise and adversarial attacks, R-MTLLMF can be further augmented by physical layer resilience schemes as in [12]. However, this is out of the scope of this study."}, {"title": "IV. SIMULATION RESULTS AND ANALYSIS", "content": "We follow the experimental setup in in [9] and fine-tune OpenAI's CLIP ViT-B/16 ViT-LLM [14] for 2000 iterations with batch size 128 on eight different image classification datasets (tasks): Cars [15], DTD [16], EuroSAT [17], GTSRB [18], MNIST [19], RESISC45 [20], SUN397 [21], and SVHN [22]. We then compute the task vectors and construct the MTLLM with parameters $\\Theta_{MTLLM}$ as defined in (6) with heuristic values for \u03bb from [8]. We vary the number of tasks between 2 and 8, and, for each case, we generate all possible task combinations and evaluate the MTMF cross-task perfor-mance by measuring accuracy on each dataset, normalized to the individual fine-tuning performance. We report the average of the normalized accuracies as in [9]. To simulate ideal and adversarial channel noise conditions for sum rate (SR) and strongest user (SU) per (P1) and (P2), we consider the MIMO setup from Section II with |Q| = 8 single-antenna users, each of which fine-tunes on one of above datasets, and $N_R$ = 16 BS receive antennas. We set the maximum transmit power to 0.1 mW. We initialize the user positions randomly between 100 to 1000 meters from the BS and employ 64-QAM modulation. To induce parameter deviation from post-decoding errors $\\epsilon_q$, we compute the MSE and add Gaussian noise with variance proportional to it to the task vectors, resulting in $\\hat{\\tau_q} = \\tau_q + \\epsilon_q$. We apply R-MTLLMF with few-shot realignment, using 10 random samples per class as in [13].\n1) R-MTLLMF Results: Results for MTMF with 8 tasks are shown in Figure 2 where shaded areas represent the variance in accuracies for all task combinations. R-MTLLMF achieves close-to-baseline performance for the ideal transmission case, having 89.1% normalized average accuracy compared to the 91.2% baseline when aggregating all 8 tasks. In contrast, R-MTLLMF has equally degraded performance for both SR and SU worst-case scenarios with 54.8% and 53.3% accuracies, respectively. This is due to the significantly increased noise during task aggregation. Whereas the ideal scenario results in a signal-to-noise-ratio (SNR) of around -16.2 dB with an average MSE of 0.013 across all 8 users, results for SU (SR) yield an SNR of -21.7 dB (-27.3 dB) with an average MSE of 0.16 (0.21). The severe increase in noise shows some limitations of our AI-based framework where neither parameter freezing nor few-shot realignment can fully restore the model's classification capabilities as the cross-task interference is too high. However, even in this worst-case, R-MTLLMF ensures significantly better model performance (9-14 times better) as compared to scenarios without protection.\nMore concretely, unprotected SR and SU scenarios lead to catastrophic perturbances with average normalized accuracies between 4% and 6% across all tasks, resulting in worst-case single- and multi-task performance, which ultimately renders MTMF ineffective. Surprisingly, even the unprotected ideal case results in subpar performance with total aggregation accuracy of 36.3% due to noise at inference time. Further-more, accuracies seem to be generally non-increasing with the number of tasks, except for R-MTLLMF in the ideal case. This indicates that the perturbed model is unable to generalize across tasks. In addition, the heuristic choice for $\\lambda_N$ may be suboptimal, indicated by random improvements and deteriorations. This signifies the importance of resilient aggregation strategies in distributed inference scenarios, where noise, even if small, may be detrimental.\n2) Weight Disentanglement Error Analysis: To investigate the influence of wireless noise from a weight disentanglement perspective, we present the cosine similarities between task vectors as an alternative measure for WDE as in [9]. Figure 3 shows results for R-MTLLMF (ideal case), and Figure 4 presents the adversarial worst-case (SR) without protection. A cosine similarity score of 0 indicates that the task vectors are orthogonal to each other and have no directional overlap. In contrast, a similarity of 1 indicates that all task vectors are perfectly aligned in the same direction and thus identical (same task). As can be seen, resilient R-MTLLMF protection helps to maintain small cosine similarities of at most 0.24, indicating that all task vectors are well disentangled and increasingly orthogonal to each other. This results in less cross-task in-terference and improved MTMF performance. In contrast, Figure 4 shows severe entanglement with cosine similarities between 0.48 and 0.52 across all tasks. This indicates that the task vectors are partially aligned, sharing increased directional similarity, which results in significant cross-task interference, reflected by the results in Figure 2. This also explains why per-formance remains detrimental regardless of the task count as entanglement is equally high for any considered combination.\n3) Ablation Studies: To understand the effectiveness of our R-MTLLMF framework better, we perform ablation studies in Figure 5 to study the importance of both parameter freezing and realignment, as well as the significance of the number of few-shot fine-tuning samples. Our results show that neither parameter freezing nor realignment alone can yield satisfactory performance, resulting in 21% - 53% worse average normal-ized accuracies as compared to full R-MTLLMF. We thus conjecture that alignment is more effective when essential embedding parameters are frozen, preserving the integrity of core data representations without the need for further optimiza-tion through fine-tuning. Furthermore, adding more samples to realignment generally increases performance, though with diminishing returns beyond 10 samples. This is especially true for the combined approach compared to realignment alone without parameter freezing. Therefore, both AI resilience strategies are necessary for R-MTLLMF's effectiveness.\nIn summary, MTMF improves the average performance as the number of tasks increases without the need for constant re-training. Furthermore, our R-MTLLMF framework provides an effective AI-based MTMF resilience framework for most"}, {"title": "V. CONCLUSION", "content": "In this paper, we have studied the problem of adversarial noise attacks in MTMF at the wireless edge. To this end, we have first introduced MTMF via task vectors as a cost-effective alternative to construct MTLLMs without re-training. Second, we have derived a relationship between the cross-task interference and the MSE, showing a direct impact on performance. To mitigate this, we proposed R-MTLLMF, an AI-based framework for resilient task vector aggregation that employs few-shot fine-tuning and parameter freezing to realign the perturbed model. We have shown in extensive experiments that R-MTLLMF achieves close-to-baseline performance un-der typical wireless noise and effectively decreases cross-task interference. However, R-MTLLMF cannot fully compensate for worst-case adversarial noise as it does not ensure a resilient wireless link. We hypothesize that integrating physical layer protection schemes could further improve performance in extreme scenarios, creating holistic resilience from both wireless and AI perspectives. We leave this investigation for future work and advocate for further research into hybrid AI resilience mechanisms for distributed inference scenarios."}]}