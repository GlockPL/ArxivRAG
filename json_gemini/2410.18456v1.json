{"title": "Multi-Stage Airway Segmentation in Lung CT\nBased on Multi-scale Nested Residual UNet", "authors": ["Bingyu Yang", "Huai Liao", "Xinyan Huang", "Qingyao Tian", "Jinlin Wu", "Jingdi Hu", "Hongbin Liu"], "abstract": "Accurate and complete segmentation of airways in\nchest CT images is essential for the quantitative assessment of\nlung diseases and the facilitation of pulmonary interventional\nprocedures. Although deep learning has led to significant ad-\nvancements in medical image segmentation, maintaining air-\nway continuity remains particularly challenging. This difficulty\narises primarily from the small and dispersed nature of airway\nstructures, as well as class imbalance in CT scans. To address\nthese challenges, we designed a Multi-scale Nested Residual U-\nNet (MNR-UNet), incorporating multi-scale inputs and Residual\nMulti-scale Modules (RMM) into a nested residual framework\nto enhance information flow, effectively capturing the intricate\ndetails of small airways and mitigating gradient vanishing. Build-\ning on this, we developed a three-stage segmentation pipeline to\noptimize the training of the MNR-UNet. The first two stages\nprioritize high accuracy and sensitivity, while the third stage\nfocuses on repairing airway breakages to balance topological\ncompleteness and correctness. To further address class imbalance,\nwe introduced a weighted Breakage-Aware Loss (wBAL) to\nheighten focus on challenging samples, penalizing breakages and\nthereby extending the length of the airway tree. Additionally,\nwe proposed a hierarchical evaluation framework to offer more\nclinically meaningful analysis. Validation on both in-house and\npublic datasets demonstrates that our approach achieves superior\nperformance in detecting more accurate airway voxels and\nidentifying additional branches, significantly improving airway\ntopological completeness. The code will be released publicly\nfollowing the publication of the paper.", "sections": [{"title": "I. INTRODUCTION", "content": "Chronic Respiratory Diseases (CRD), including Chronic\nObstructive Pulmonary Disease (COPD), asthma, Interstitial\nLung Disease (ILD), and sarcoidosis, remain leading causes\nof mortality worldwide [1]. With advancements in computer\ntechnology and medical imaging, Computed Tomography (CT)\nhas become vital for diagnosing and evaluating these diseases.\nAccurate CT-based airway segmentation and reconstruction are\nessential for preoperative planning and real-time navigation,\nparticularly in detecting peripheral pulmonary lesions [2].\nHowever, the complexity of pulmonary airway structures in\nCT images makes manual segmentation time-consuming and\nprone to errors.\nOver the past two decades, traditional methods for airway\nsegmentation, such as threshold segmentation [3], morpholog-\nical processing [4], region growing [5], and template match-\ning [6], have been used. Yet, due to their lack of semantic\nfeatures, these methods often fail to achieve complete seg-\nmentation. Recently, deep learning has revolutionized medical\nimage processing, with many researchers employing deep\nconvolutional networks [7]\u2013[13] to automatically segment air-\nway structures in lung CT images. Compared to traditional\napproaches, deep learning can better mitigate airway leakage\nand improve overlap accuracy. However, in clinical practice,\nonly the largest connected airway component is typically\nused for localization and navigation during bronchoscopic\ninterventions, making segmentation continuity critical. Despite\nadvancements, achieving complete and continuous airway seg-\nmentation remains challenging.\nComplexity of airway structures. The lung airways form\na tree-like topology with branches of varying scales, from the\ntrachea to small airways [14]. These varying sizes challenge\nsegmentation algorithms, as the small size of distal airways\nand imaging noise reduce contrast between the airway lumen\nand wall, leading to feature vanishing during CNN propa-\ngation. This results in segmentation discontinuities and false\nnegatives, as shown in Fig. 1. Deep learning networks must\nimprove multi-scale feature extraction and contextual informa-\ntion capture to maintain airway integrity and continuity.\nClass imbalance. Pulmonary CT images exhibit significant\nclass imbalance (airway voxels vs. background voxels) and\nintra-class imbalance (large airways vs. small airways). Zheng\net al. [11] showed that such imbalances lead to gradient vanish-\ning in small airways during network backpropagation, causing\nsegmentation discontinuities. Although they introduced a new\nsupervision method and distance-based loss function, disconti-\nnuities in small peripheral airways persist, as shown in Fig. 1."}, {"title": "II. RELATED WORK", "content": "Airway segmentation is essential for diagnosing and plan-\nning surgery for pulmonary diseases. Traditional methods [3]\u2013\n[6], [15] have been applied, but the EXACT'09 challenge [16]\nshowed these approaches are inadequate for small airway\nextraction.\nRecent advances in deep learning have enhanced automatic\nairway segmentation. Charbonnier et al. [7] used 2D CNNS\nto address airway leakage, but with limited success. The U-\nNet architecture has advanced the field, with Juarez et al. [8]\nproposing a 3D U-Net that improved feature representation\nbut struggled with small airway detection. New modules have\nbeen introduced to improve feature extraction. Qin et al. [10]\nadded feature recalibration and attention distillation modules,\nand Selvan et al. [17] treated the problem as graph refinement.\nHowever, the varying sizes of airway branches remain a\nchallenge. Airway connectivity has also gained attention. Qin\net al. [9] proposed AirwayNet to enhance voxel connectivity,\nand centerline tracking algorithms [18] have been developed.\nZheng et al. [11] addressed class imbalance affecting connec-\ntivity with General Union Loss (GUL), though distance-based\nlosses still struggle with airway discontinuity. Nan et al. [12]\nintroduced JCAM loss to improve continuity."}, {"title": "B. Multi-scale Fusion", "content": "Multi-scale or pyramid methods are widely used in image\nsegmentation for richer feature representation. First intro-\nduced by Burt et al. [19] in the Laplacian pyramid, this\napproach transforms images into a series of progressively\nlower-resolution images, helping the model capture diverse\nfeatures at different scales.\nIn U-Net, multi-scale information is often integrated during\nthe encoder or decoder stages. Techniques like image pyramid\ninput layers or side outputs are aggregated into the U-Net\nframework. Abraham et al. [20] improved performance with\nthe Focal Tversky Attention U-Net by incorporating multi-\nscale inputs into an attention-based U-Net with deep supervi-\nsion. Similarly, Fu et al. [21] enhanced optic disc and cup\nsegmentation in fundus images by introducing polar trans-\nformation into a U-shaped network with multi-scale inputs,\nenriching contextual representations. In scene parsing, Zhao\net al. [22] extended this concept with a pyramid pooling\nmodule, enhancing global context and improving object size\nperception."}, {"title": "III. METHOD", "content": "The three-stage training pipeline is depicted in Fig. 2. In\nStage one, the network is trained to predict the main airways\nusing random crop sampling and Dice loss [23]. The epoch\nwith the highest accuracy serves as the foundation for the\nStage two. In Stage three, General Union Loss (GUL) [11]\nand hard-mining crop sampling are introduced to address the\nchallenges of small airway extraction, yielding predictions\nwith the highest recall. Stage three is specifically designed to\naddress discontinuities in predictions. This stage incorporates\nbreakage crop sampling alongside a combined loss function\nthat integrates weighted Breakage-Aware Loss (wBAL) and\nGUL, aiming to penalize central line voxels that compromise\nairway continuity, thereby extending the length of the airway\ntree. The optimal model from Stage three is subsequently used\nfor testing. Details of crop sampling are provided in Section\nIII.A, the weighted loss functions in Section III.C, and the\nhierarchical evaluation metrics in Section III.D.\nThe same network architecture shown in Fig. 3 is employed\nacross all stages. The Multi-scale Nested Residual U-Net\n(MNR-UNet) is designed to enhance the learning of airway\nfeatures at various scales by incorporating multi-scale inputs\nwith feature information encoded by Residual Multi-scale\nModules (RMMs). Further details on the MNR-UNet are\ndiscussed in Section III.\u0412."}, {"title": "A. Crop Sampling", "content": "Given the large volume of 3D lung CT data and the con-\nstraints of GPU memory, the MNR-UNet is trained on patches\nextracted from lung regions, a widely adopted method [8],\n[12], [18]. Patch-based training serves as an effective hard\nattention, mitigating the class imbalance issue in airway\nsegmentation. However, relying exclusively on random patch\nsampling may not sufficiently capture crucial information.\nTo address this, a Hard-mining crop sampling strategy\nis introduced in the second stage of our training pipeline.\nThis strategy involves randomly selecting unextracted airway\nskeleton points from the first stage's predictions and gener-\nating patches containing these points, thereby increasing the\nnetwork's focus on peripheral small airways. In the third\nstage, Breakage crop sampling is proposed as an advanced\nform of Hard-mining crop sampling. This method processes\nthe challenging airway skeleton points from the second stage\nusing a 3\u00d73\u00d73 all-ones convolution kernel, effectively filtering\nout the centerline segments associated with breakages, as\nillustrated in Fig. 4. Patches containing these points are then\nused as input to the network in the third stage."}, {"title": "B. Multi-scale Nested Residual UNet", "content": "The pulmonary airway structure is complex, consisting of\nmulti-scale airway branches that pose significant challenges\nin feature extraction due to imaging noise and intra-class\nimbalance. To address these issues, we propose a novel U-\nNet architecture called the Multi-scale Nested Residual U-Net\n(MNR-UNet). This architecture achieves hierarchical residual\nnesting through the use of multi-scale inputs and Residual\nMulti-scale Modules (RMMs). The overall network structure\nis depicted in Fig. 3. Specifically, the 3D patches input to\nthe network are pyramid-pooled into three resolutions, with\nresiduals computed using a 1\u00d71\u00d71 convolution layer and\nthe output features from the residual multi-scale encoder at\neach stage. The MNR-UNet effectively captures and integrates"}, {"title": "C. Weighted Breakage-Aware Loss", "content": "During training, when the input patch contains both large\nand small airways, Dice loss tends to be dominated by the\nlarger airways, exacerbating gradient erosion in smaller air-\nways and making it insensitive to breakages in the results [11].\nTo address this, we propose a weighted Breakage-Aware Loss\n(wBAL), as defined in Eq. (4). This loss function penalizes\nvoxels that are difficult to detect within the airway skeleton,\nplacing greater emphasis on the continuity of the airway.\n$L_{BA} = 1- \\frac{C}{\\sum_{i=1} \\frac{w_ip_ig_i}{w_i(p_i + g_i)}}$"}, {"title": "D. Evaluation Metrics", "content": "Based on the public benchmark for lung airway segmenta-\ntion [26], we selected two categories of metrics to evaluate the\nairway segmentation algorithm. The first focuses on topologi-\ncal correctness, including Dice Similarity Coefficient (DSC,%)\nand Precision (Pre,%). The second focuses on topological in-\ntegirty, using Tree Length Detection Rate (TD,%) and Branch\nDetection Rate (BD,%).\nTo assess performance on smaller airways, we evaluated\nTD and BD across different airway levels. Following the\nanatomical labeling from [14], we divided the airway tree into\ntwo categories: Trachea+Main Bronchi+Lobar Bronchus (gray\nairways after anatomy matching in Fig. 5) and Segmental Air-\nways (colored airways). The topological analysis process, il-\nlustrated in Fig. 5, includes skeletonization, skeleton topology\ngrading, skeleton-to-volume and anatomical grading matching.\nThe skeleton topology grading identifies branch points and\nnumbers them sequentially through recursive exploration of\nthe skeleton line, while anatomical grading matching aligns\nthe original numbering with anatomical grades based on level\nrelationships and airway angles."}, {"title": "IV. EXPERIMENTS", "content": "We evaluated our method on two datasets: in-house dataset\nused for training, assessment, and ablation studies; the\nATM'22 challenge dataset [26] for fair comparative testing."}, {"title": "B. Implementation Details", "content": "Data processing: Preprocessing involved truncating CT\nvoxel intensities to [-1000, 500] and [-1024, 1024], followed\nby normalization to [0, 1]. Network training used CT patches\nsized 128 x 128 \u00d7 128 as inputs. Post-processing included\nDual Threshold Iteration (DTI) [30] to convert the probability\nmap to a binary mask, morphological hole filling, and extract-\ning the largest connected component. Thresholds in DTI were\nset at $T_h = 0.5$ and $T_l = 0.35$.\nModel training and experimental environment: The\nthree-stage training used the AdamW optimizer with a batch\nsize of 8 and a learning rate of 0.0001. The network was first\ntrained for 100 epochs with Random Crop, followed by 50\nepochs using Hard-mining Crop (50%), Small Airway Crop\n(25%), and Random Crop (25%). The final stage comprised 50\nepochs with Breakage Crop (40%), Hard-mining Crop (20%),\nSmall Airway Crop (20%), and Random Crop (20%). The\nframework was implemented in PyTorch 2.0.0 and ran on an\nNVIDIA A800 80GB GPU."}, {"title": "V. RESULTS", "content": "The ATM22 challenge organizers conducted a quantitative\nanalysis of our method's performance on a hidden test set."}, {"title": "B. Ablation Studies", "content": "In our in-house dataset, we conducted a detailed analysis\nof the proposed method's components: (1) the importance of\nthe second and third stages in the multi-stage pipeline; (2) the\neffectiveness of the Multi-scale Nested Residual architecture\n(MNR); and (3) the impact of the weighted Breakage-Aware\nLoss (wBAL). Table III presents the quantitative results of this\nablation study.\nFirstly, we compared networks trained through all three\nstages with those trained through only the first stage or the first\ntwo stages. The second and third stages improved Tree Length\nDetection (TD) and Branch Detection (BD) by 16.146% and\n4.716%, and by 21.264% and 8.490%, respectively. It shows\nthat the second stage enhances peripheral airway detection,\nwhile the third stage further improves airway integrity by\naddressing discontinuities.\nSecondly, we evaluated the impact of removing the MNR\narchitecture (Fig. 8). Omitting MNR (Ours w/o MNR) slightly\naffected Dice Similarity Coefficient (DSC) and Precision but\nsignificantly reduced TD and BD by 4.426% and 7.640%,"}, {"title": "VI. CONCLUSION", "content": "In this study, to address local discontinuities in the air-\nway tree, we designed a Multi-scale Nested Residual U-Net\n(MNR-UNet) that effectively reduces information loss and\nimproves gradient propagation. Additionally, we proposed a\nweighted Breakage-Aware Loss (wBAL) to tackle intra-class\nimbalance issues and enhance airway continuity. To balance\ntopological completeness and accuracy, we employed a three-\nstage training process optimized for main airways extraction,\nsmall airways mining, and breakage repair. Experimental re-\nsults on public and in-house datasets demonstrate that our\nmethod offers significant advantages in improving airway tree\ntopological integrity and small airway extraction compared to\nother state-of-the-art methods."}, {"title": "$w_i =w_r + w_c$", "content": null}, {"title": "$w_c =\\left(1 - \\frac{d_i}{d_{max}}\\right)^2+ \u03b1 \\cdot min(1-d_i, K),$", "content": null}, {"title": "$L_3 = L_{GU}+ L_{BA}$.", "content": null}, {"title": "$F_{RMM_{i}} = Conv1(Cat(f_{i,1}, f_{i,2},..., f_{i,n}))$,", "content": null}, {"title": "$F_{en_{i}} := Conv1(Maxpool_i(F_{in})) \u2295 F_{RMM_{i}},$", "content": null}, {"title": "$F_{de_{i}} = F_{RMM_{i}}.$", "content": null}]}