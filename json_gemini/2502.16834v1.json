{"title": "A NOVEL MULTI-TASK TEACHER\u2013STUDENT ARCHITECTURE WITH SELF-SUPERVISED PRETRAINING FOR 48-HOUR VASOACTIVE-INOTROPIC TREND ANALYSIS IN SEPSIS MORTALITY PREDICTION", "authors": ["Houji Jin", "Negin Ashrafi", "Kamiar Alaei", "Elham Pishgar", "Greg Placencia", "Maryam Pishgar"], "abstract": "Sepsis is a major cause of ICU mortality, where early recognition and effective interventions are essential for improving patient outcomes. However, the vasoactive-inotropic score (VIS) varies dynamically with a patient's hemodynamic status, complicated by irregular medication patterns, missing data, and confounders, making sepsis prediction challenging. To address this, we propose a novel Teacher-Student multitask framework with self-supervised VIS pretraining via a Masked Au-toencoder (MAE). The teacher model performs mortality classification and severity-score regression, while the student distills robust time-series representations, enhancing adaptation to heterogeneous VIS data. Compared to LSTM-based methods, our approach achieves an AUROC of 0.82 on MIMIC-IV 3.0 (9,476 patients), outperforming the baseline (0.74). SHAP analysis revealed that SOFA score (0.147) had the greatest impact on ICU mortality, followed by LODS (0.033), single marital status (0.031), and Medicaid insurance (0.023), highlighting the role of sociodemographic factors. SAPSII (0.020) also contributed significantly. These findings suggest that both clinical and social factors should be considered in ICU decision-making. Our novel multitask and distillation strategies enable earlier identification of high-risk patients, improving prediction accuracy and disease management, offering new tools for ICU decision support.", "sections": [{"title": "1 Introduction", "content": "Sepsis is a syndrome that results from a dysregulated response to infection leading to life-threatening organ dysfunction [1, 2]. It remains one of the primary causes of morbidity and mortality in intensive care units (ICUs) [1]. Clinically, stabilizing the hemodynamic status of patients with septic shock requires the administration of a vasoactive-inotropic score (VIS), which includes medications such as dopamine, norepinephrine, dobutamine, epinephrine, milrinone, and vasopressin. However, accurately modeling and predicting the dosage and trends of these medications within the first 48 hours is challenging due to the variable physiology of ICU patients, irregular and incomplete medication records, and the presence of numerous clinical confounding factors [3, 4, 5]."}, {"title": "2 Data Acquisition and Experimental Setup", "content": "We utilized data from 9,476 sepsis patients (defined by Sepsis-3 criteria [1]) in the MIMIC-IV v3.0 database [3]. All patients received a vasoactive-inotropic score (VIS) within the first 48 hours of ICU admission, and those discharged against medical advice were excluded. Each patient's 7-dimensional VIS time series included doses for dopamine, dobutamine, epinephrine, milrinone, vasopressin, norepinephrine, and total VIS. Additionally, static features such as gender, admission age, insurance, marital status, and severity scores (SOFA, SAPS-II, LODS, OASIS)\u2014were recorded, with ICU mortality serving as the binary outcome label. As shown in Equation (1), the VIS is calculated by summing the contributions of various medications.\nVIS = dopamine + dobutamine + 100 epinephrine + 10 milrinone + 100 norepinephrine + 10000 vasopressin. (1)\nIn this formula, each medication dose is weighted according to its relative potency and clinical impact on hemodynamic support [33]. For instance, epinephrine and norepinephrine are multiplied by 100, while milrinone is multiplied by 10, and vasopressin by 10,000, reflecting their stronger vasoactive effects compared to dopamine and dobutamine [34]. This weighted sum provides a comprehensive measure of the overall vasoactive support administered, which is critical for accurately assessing the severity of a patient's condition in the ICU."}, {"title": "2.1 Data Description", "content": "The MIMIC-IV (Medical Information Mart for Intensive Care-IV) database, jointly developed by MIT and Beth Israel Deaconess Medical Center [3], is a publicly accessible repository of anonymized electronic health records that builds upon the foundations of MIMIC-III/II. It offers a comprehensive range of patient data-including demographics, diagnoses, laboratory tests, medications, nursing notes, vital signs, and outcomes\u2014with timestamped, heterogeneous records that enable dynamic modeling of patient trajectories. This rich data composition is particularly valuable for sepsis research, as sepsis remains a leading cause of ICU mortality [1, 5] and often requires detailed analyses of vasoactive support and hemodynamic interventions. The availability of VIS dosing, laboratory values, and physiological measurements within MIMIC-IV facilitates in-depth investigations into sepsis progression and the effectiveness of"}, {"title": "2.2 Patient Inclusion Criteria", "content": "Our cohort was constructed by applying specific inclusion and exclusion criteria. Patients were included if they had a Sepsis-3 diagnosis, were aged \u2265 18 years, received VIS administration within the first 48 hours of ICU admission, had complete ICU outcome records (survival/death), and were administered VIS agents for therapy within 24 hours of ICU admission with an ICU stay lasting more than 24 hours following the commencement of vasoactive-inotropic therapy. Patients discharged against medical advice or those missing entire VIS infusion data were excluded. This resulted in a final cohort of 9,476 patients-slightly larger than the MIMIC-IV v2.0 cohort (8,887) in [17]-reflecting the expanded coverage in version 3.0.\nFor missing value imputation, hourly missing doses in the VIS time series were imputed as 0 (indicating no drug use), while static continuous features (e.g., severity scores) were imputed using the median value. Categorical variables (e.g., marital status) incorporated an \"Unknown\" category for missing values.\nTo address the class imbalance between survival and death outcomes, we employed two strategies. First, a weighted cross-entropy loss was used, assigning higher weights to the minority class (death), with class weights computed as the total size of the training set divided by two times the class counts (see Equation (2)). Second, stratified sampling was utilized to preserve the label distribution across training, validation, and test splits (0.72%, 0.08%, and 0.2%, respectively).\nclass_weights = \\frac{size(train)}{2 \\cdot class\\_counts} (2)\nThe numerical features underwent a two-step normalization process. VIS values were first transformed using log(1+x) to suppress extreme values and stabilize the distribution, and then standardized via Z-score normalization using training-set parameters, which were also applied to the test and validation sets. Categorical features were one-hot encoded (e.g., gender, insurance). This preprocessing strategy facilitates model convergence and reduces the influence of extreme values, thus improving the model's ability to learn robust feature-label relationships."}, {"title": "2.3 Feature Extraction", "content": "We integrated three categories of features for multitask modeling. First, the VIS time series (7-dimensional) includes individual agents-dopamine, norepinephrine, vasopressin, milrinone, epinephrine, and dobutamine\u2014as well as the total VIS, a weighted sum that reflects cumulative vasoactive support [17]. Second, static features comprise demographics (gender, age, marital status, insurance, and race), which capture socioeconomic factors linked to ICU outcomes, and severity scores (SOFA, SAPS-II, LODS, and OASIS) that serve as regression targets for multitask learning by quantifying multiorgan dysfunction [32, 30, 19]. Third, our feature selection is driven by several considerations: evidence-based predictors such as VIS dynamics [10] and severity scores; the novelty of incorporating socioeconomic variables to address understudied prognostic factors; and interpretability, facilitated by SHAP [31] to quantify feature contributions.\nThis integrated framework offers distinct comparative advantages by combining 7-dimensional VIS trends, severity scores, and socioeconomic variables to capture early (48-hour) hemodynamic responses and to identify vulnerable subgroups through an expanded feature space. In particular, socioeconomic factors are emphasized through a careful selection rationale. Marital status, for example, has been shown in retrospective analyses [36] to correlate with delayed clinical visits, increased hospitalization costs, and higher mortality, likely due to its association with social support and healthcare access. Similarly, insurance type and race, as evidenced in studies on severe sepsis in U.S. children [35], influence resource access and survival outcomes. Finally, while age and gender are routinely recorded, their established clinical significance older age being associated with higher mortality risk and gender potentially affecting immune responses-reinforces their inclusion in our feature set."}, {"title": "3 Overall Architecture", "content": "The Vasoactive-Inotropic Score (VIS) quantifies the intensity of medications required to maintain hemodynamic stability in patients with septic shock, providing an objective measure for assessing disease progression and treatment efficacy [10]. However, VIS data recorded in the ICU are often characterized by irregular sampling and missing values, posing significant challenges for time series modeling. The Masked AutoEncoder (MAE) addresses these challenges by"}, {"title": "4 MAE Pretraining and Teacher\u2013Student Distillation", "content": "Let X \u2208 R^{B\u00d7T\u00d77} denote the VIS time series for a batch of B patients, where T = 48 represents the 48-hour monitoring\nperiod and 7 denotes the number of VIS features. To enable self-supervised learning, we randomly mask 5% of the time\nsteps or feature dimensions in X, yielding a masked input X' = Mask(X). This masked input is then processed by the\nMAE_Encoder\u2014a Transformer-based module-that encodes the partial information into latent representations. The\ncorresponding MAE_Decoder reconstructs the missing portions to generate X. The reconstruction loss is computed\nusing the mean squared error (MSE) only over the masked positions, as defined in Equation (3):\nL_{MAE} = MSE(X_{masked}, X'_{masked}). (3)\nThis objective forces the encoder to learn robust representations that capture the underlying structure of the VIS data\ndespite missing or irregularly sampled values."}, {"title": "4.2 Teacher Setup", "content": "After completing MAE pretraining, the learned encoder is repurposed as the Teacher_Encoder. In this phase, the pretrained encoder weights are loaded into a teacher model, which is then fixed-meaning no further gradient updates are applied during subsequent training on labeled data. The teacher model serves as a stable reference by providing fixed encodings or classification logits for knowledge distillation. It is important to note that the teacher does not undergo any additional multi-task supervision (i.e., no further cross-entropy or MSE loss on labeled data is applied), thereby preserving the robust representations it learned during the self-supervised phase. This frozen teacher model is then used to guide the training of the student model in later stages."}, {"title": "4.3 Student and Distillation", "content": "After the teacher model has been established, a student model with an identical architecture is trained on labeled data (X, y, s), where y is a binary mortality label and s represents auxiliary continuous targets (e.g., severity scores). The student model is designed to perform multitask learning by simultaneously addressing both classification and regression objectives. Its loss function, given in Equation (4), is a weighted combination of the two tasks:\nL_{student} = \\lambda_{cls} \\cdot CE(z_{s}^{(cls)}, y) + \\lambda_{reg} \\cdot MSE(z_{s}^{(reg)}, s), (4)\nwhere z_{s}^{(cls)} and z_{s}^{(reg)} are the student's outputs for classification and regression, respectively, and the hyperparameters \\lambda_{cls} and \\lambda_{reg} balance the two tasks.\nIn addition to this multitask objective, we incorporate knowledge distillation (KD) to further enhance the student model's performance. To achieve this, we compute the softmax probabilities for both teacher and student, as described in Equation (5):\np_{T} = softmax(z_{T}^{(cls)}), \\quad p_{S} = softmax(z_{S}^{(cls)}). (5)\nThe distillation loss, shown in Equation (6), is defined as the squared Euclidean distance between these probability distributions:\nL_{KD} = ||p_{S} - p_{T}||^{2}. (6)"}, {"title": "4.4 Additional Parameter Explanations", "content": "Throughout the paper, we use the following notations: X denotes the input VIS sequences of size B \u00d7 48 \u00d7 7, where B represents the batch size. The binary mortality label is represented by y, and s denotes the continuous severity score. The student's classification logits and regression outputs are represented by z_{s}^{(cls)} and z_{s}^{(reg)}, respectively, while the teacher and student classification probability distributions (obtained via softmax) are denoted by p_T and p_S. The loss function incorporates weighting coefficients \\lambda_{cls}, \\lambda_{reg}, and \\lambda_{KD} for the classification, regression, and distillation components, respectively.\nIn our implementation, we adopt an approximate 5% masking ratio for the 48-hour VIS data. Although computer vision applications sometimes employ higher masking ratios (e.g., 30%), a 5% ratio strikes a balance by providing a sufficient challenge for the model while ensuring stable training. Excessive masking can destabilize early reconstruction, whereas insufficient masking may not fully leverage the model's ability to learn robust representations.\nThe loss coefficients are chosen so that \\lambda_{cls} = 1.0, thereby giving primary focus to the classification task through the cross-entropy loss, while \\lambda_{reg} = 0.1 ensures that the regression loss (for severity scores) acts as a complementary signal. The distillation loss, which aligns the student's classification output with that of the teacher, is weighted by \\lambda_{KD} = 0.05.\nMoreover, the teacher model, initialized from the pretrained MAE encoder, is not fine-tuned on the labeled data; it is set to eval() mode with all parameters frozen (i.e., requires_grad=False). Only the student model's encoder and its classification/regression heads are updated during training. We optimize using AdamW with a learning rate of 10^{-3}, a weight decay of 10^{-4}, and a batch size of 64. Each training stage\u2014MAE pretraining, teacher setup, and student training is run for up to 20-30 epochs, with early stopping employed if the validation AUROC fails to improve for several epochs. This training protocol has been found to yield stable convergence and improved generalization across both tasks."}, {"title": "4.5 Overall Training Procedure", "content": "Our overall pipeline proceeds in three distinct stages. First, we perform MAE pretraining on unlabeled VIS data, during which the encoder learns robust representations by reconstructing masked portions of the input (as quantified by the reconstruction loss in Equation (3)). Next, the pretrained encoder is loaded into a teacher model, whose parameters are then frozen; this teacher model provides fixed encodings or classification logits that serve as a stable reference for knowledge distillation. Finally, we train a student model of the same architecture-on labeled data (X, y, s) using a composite loss function. This loss comprises the primary objectives of binary mortality classification and severity score regression (as defined in Equation (4)), augmented by a knowledge distillation loss (see Equation (6)). The hyperparameter \\lambda_{KD} controls the influence of the distillation term, ensuring that the student model gradually aligns its classification output with that of the teacher while simultaneously learning from the labeled data."}, {"title": "5 Results and Ablation Analysis", "content": "In this section, we present our multi-task Teacher-Student framework with MAE pretraining and analyze its ablation variants."}, {"title": "5.1 Metric Definitions and Formulas", "content": "To evaluate the performance of our binary classification model for ICU mortality prediction, we employ a comprehensive set of metrics that capture both the discriminative power and diagnostic utility of the model. Specifically, we use the area under the ROC curve (AUROC) to assess how well the model distinguishes between death and survival across various decision thresholds. In addition, we report the Positive Predictive Value (PPV) and Negative Predictive Value (NPV) to quantify the reliability of the model's positive and negative predictions, respectively. Sensitivity (or recall) and specificity are calculated to measure the model's ability to correctly identify actual death and survival cases. Furthermore, we compute the Positive Likelihood Ratio (PLR) and Negative Likelihood Ratio (NLR) to evaluate the diagnostic strength of positive and negative predictions, along with overall accuracy (ACC) as a measure of the proportion of correctly classified instances."}, {"title": "5.2 Ablation Study", "content": "We conducted an extensive ablation study to assess the contributions of knowledge distillation (KD) and multi-task learning (MT) within our full Teacher-Student multi-task framework."}, {"title": "5.3 ROC Curves Analysis", "content": "Figure 5 shows the ROC curves of the three ablation configurations on the test set. The baseline model (kd=True, mt=True) achieves the highest AUROC (0.822), followed by no_kd (0.817) and no_mt (0.808). Notably, baseline maintains a better ROC curve across most thresholds, indicating stronger overall discrimination. Removing knowledge distillation (no_kd) slightly reduces AUROC, while removing the severity regression branch (no_mt) further decreases performance, illustrating the benefits of combining multi-task learning and distillation."}, {"title": "5.4 Loss Curves and Convergence", "content": "Figure 6 presents the training and validation loss trajectories for each ablation configuration. The baseline model (kd=True, mt=True) converges smoothly, suggesting that the synergy of knowledge distillation and multi-task objectives stabilizes training. In contrast, removing the severity regression branch (no_mt) leads to a sharper spike in the validation loss during later epochs, indicative of reduced regularization. Meanwhile, no_kd (no knowledge distillation) remains relatively steady but converges more slowly, underscoring the teacher model's influence in guiding classification boundaries."}, {"title": "5.5 SHAP Analysis for Interpretability", "content": "Table 3 presents the top five static features ranked by mean absolute SHAP value, with sofa_score_24h demonstrating the highest impact (approximately 0.1467). This outcome aligns with clinical intuition, as an elevated SOFA score typically signifies more severe organ dysfunction and an increased likelihood of mortality. Other prominent features include lods, marital_status_SINGLE, insurance_Medicaid, and sapsii, underscoring the combined relevance of both pathophysiologic and sociodemographic variables in sepsis outcomes.\nFigure 7 illustrates the distribution of SHAP values, revealing that sofa_score_24h displays the broadest range and hence wields substantial influence over the model's predictions. Likewise, the prominence of lods is consistent with its well-established role in quantifying organ dysfunction, which is a critical determinant of sepsis severity and subsequent mortality risk [1]. These findings reinforce the understanding that multiorgan failure is a principal driver of sepsis-related mortality in the ICU.\nNotably, single marital status and Medicaid insurance emerge as influential factors, indicating that social support systems and healthcare access can significantly affect patient outcomes. This observation aligns with the work of Seymour et al. [36] and Mitchell et al. [35], who found that patients lacking robust social or financial support are more susceptible to delayed interventions and poorer prognoses. Even when organ dysfunction levels are similar, individuals with limited resources may experience worse outcomes, highlighting the nuanced interplay between physiological and socioeconomic determinants of sepsis mortality.\nAlthough sapsii appears slightly lower on the SHAP importance list, it remains an integral severity scoring system that integrates various physiological and laboratory measurements. While partially overlapping with SOFA, SAPSII contributes additional insights into disease progression, bolstering the overall interpretability and accuracy of the model's predictions.\nOverall, these results illustrate that organ dysfunction indicators (e.g., SOFA, LODS) remain core drivers of ICU mortality prediction, yet demographic and socioeconomic factors (e.g., marital status, insurance type) can critically modulate risk. Patients exhibiting equivalent organ failure may nevertheless face higher mortality if they lack social support or adequate healthcare coverage. Consequently, the SHAP analysis underscores the importance of incorporating"}, {"title": "6 Discussion", "content": "Table 2 includes the prior LSTM study [10] for comparison, which reported an AUROC of approximately 0.74 (95% CI: 0.70-0.77), PPV = 0.39 (0.35-0.44), NPV = 0.89 (0.87\u20130.91), PLR = 2.56 (2.25-2.91), and NLR = 0.47 (0.40-0.55), but did not provide Sensitivity, Specificity, or Accuracy. In contrast, our baseline model (incorporating MAE pretraining, knowledge distillation, and multi-task learning) achieves an AUROC of about 0.82, with higher PPV (0.45 vs. 0.39), NPV (0.91 vs. 0.89), and PLR (3.16 vs. 2.56), alongside a lower NLR (0.38 vs. 0.47). These improvements across multiple metrics suggest that MAE pretraining effectively addresses missing or irregular VIS data by randomly masking and reconstructing time-series signals, knowledge distillation provides robust classification boundaries while balancing model size and accuracy, and multi-task learning with severity regression adds auxiliary signals that mitigate overfitting and enrich the learned representations.\nA closer look at the LSTM-based approach of Ning et al. [10] helps clarify why our framework outperforms their model. In ICU settings, medication and physiological indicators often suffer from discontinuity and missing values, and the LSTM models in the comparative studies rely on the method proposed by Thorsen Meyer et al. [40] for processing dynamic time series. While this method offers a structured way to handle irregularly sampled data, it may not fully capture the latent patterns or relationships present in highly variable ICU data. In contrast, our MAE pretraining phase leverages random masking of the VIS sequence, compelling the network to reconstruct missing information and learn more noise-resistant embeddings. This approach reduces the likelihood of training instability or overfitting, resulting in features that are comprehensive and robust. Consequently, when these enriched features are fed into subsequent classification and regression tasks, the overall performance benefits from their resilience to data sparsity and fluctuations, thereby exceeding the capabilities of traditional LSTM methods."}, {"title": "6.1 Guidance from Teacher-Student Knowledge Distillation", "content": "Traditional LSTM models are typically single architectures that must handle multiple feature dimensions, often leading to unstable training or insufficient generalization when faced with high-dimensional, complex dose sequences. By contrast, our approach leverages a \u201cteacher model\" obtained from MAE pretraining, which remains fixed during"}, {"title": "6.2 Collaborative Reinforcement of Data Features by Multi-Task Learning (MTL)", "content": "In the comparative LSTM study [10], only a single mortality classification objective was employed, offering no direct supervision for organ function or severity scores (e.g., SOFA). In our approach, however, the model simultaneously predicts mortality and performs severity regression, thereby capturing the dynamic interplay between VIS changes and organ function. By learning both tasks concurrently, the shared layers receive more interrelated gradient information, forming richer internal representations. This advantage is reflected in our experimental results, where enabling multi-task learning boosts AUROC, NLR, and NPV, while the regression branch achieves an R\u00b2 of over 0.2. These findings show that including severity regression provides valuable complementary supervision rather than conflicting with mortality prediction."}, {"title": "6.3 More Flexible Handling of Irregular and Missing Data", "content": "ICU data, including VIS and other measurements, frequently contain missing values and exhibit extreme imbalance. The LSTM methods in the comparative studies rely on the strategy proposed by Thorsen Meyer et al. [40], which involves discarding patient data that do not align with predefined time points (e.g., 1\u201348 h). This procedure risks losing informative samples and potential nuances in the data. In contrast, our MAE pretraining phase simulates random missingness through masking, enabling the model to learn robust inferences even with incomplete information. Furthermore, multi-task learning and knowledge distillation help focus the model on key features, thereby enhancing generalizability and mitigating the adverse effects of missing data."}, {"title": "6.4 Demographic Information and Severity Scores as Features", "content": "A distinctive aspect of our framework is the integration of demographic information and various severity scores alongside the student model's classification module. This design allows the network to capture differences in demographic distributions while concurrently leveraging the impact of severity scores on patient mortality. Consequently, the model gains a broader perspective on the factors influencing outcomes, encompassing both the clinical severity of organ dysfunction and the patient's sociodemographic context."}, {"title": "6.5 Experimental Results and Clinical Implications", "content": "In comparison to the LSTM approach, which achieved an AUROC of approximately 0.74, our proposed method attains an AUROC of around 0.82. Additionally, key metrics such as PPV, NPV, PLR, and NLR all show marked improvements, indicating that our model can more accurately identify high-risk patients and reduce misclassifications in a similar ICU setting. When combined with severity regression, the model further assists clinicians in understanding a patient's condition trajectory, facilitating timely interventions and enabling more personalized treatment strategies."}, {"title": "7 Study Limitations and Future Work", "content": "Although this study achieved notable predictive performance and interpretability on the MIMIC-IV database, several directions warrant further exploration and refinement. First, despite MIMIC-IV's breadth, it remains a single database. Previous research has highlighted that models trained and tested on the same source may lack external consistency. Accordingly, testing or retraining on other independent datasets would confirm whether the model maintains accuracy and robustness across varying healthcare settings, time frames, and patient populations.\nIn real clinical workflows, seamless integration into ICU information systems is essential for practical adoption. To achieve this, the model must provide real-time risk alerts and interpretable outputs (e.g., SHAP visualizations) without disrupting standard diagnostic and therapeutic procedures. Additionally, high-frequency data synchronization is critical, ensuring the model receives up-to-date electronic medical records, medication dosages, and monitoring indicators. From a usability standpoint, computing resource demands, latency, and interoperability with hospital systems must also be considered, particularly during peak care periods or emergency scenarios.\nBeyond the current focus on 48-hour VIS dynamics and static characteristics (including severity scores and socioe-conomic indicators), there exists a wide range of potentially valuable information in the ICU. Multimodal data, such"}, {"title": "8 Conclusion", "content": "This study conducted an in-depth modeling of vasoactive-inotropic score (VIS) dynamics in septic patients over a 48-hour period, integrating Masked Autoencoder (MAE) pretraining, Teacher\u2013Student knowledge distillation, and Multi-Task Learning (MTL) on MIMIC-IV data. Our final model achieved notably strong performance on the test set, with an AUROC of approximately 0.8223, PPV of 0.4483, NPV of 0.9103, PLR of 3.1573, NLR of 0.3821, Sensitivity of 0.7033, Specificity of 0.7767, and Accuracy of 0.7616. Compared to traditional LSTM-based methods (which yielded an AUROC around 0.74), our approach not only improved the identification of high-risk patients (e.g., higher PPV, PLR) but also enhanced the reliable detection of surviving patients (higher NPV, Specificity) while maintaining a more balanced overall classification (Accuracy of about 0.76). Additionally, our multitask framework demonstrated a regression capability for severity scores, reflected in an R\u00b2 exceeding 0.2, suggesting complementary support for assessing organ failure trends in clinical practice.\nMechanistically, MAE pretraining capitalizes on missing and irregular time-series data by randomly masking inputs and learning robust representations. Teacher-Student knowledge distillation further refines classification boundaries by transferring latent information from the teacher model to the student, preserving accuracy while reducing the risk of overfitting. Meanwhile, MTL leverages the shared objective of mortality classification and severity regression, leading to more comprehensive feature extraction and improved robustness to incomplete data. This synergy of MAE, knowledge distillation, and MTL ultimately strengthens both classification and regression performance, even in challenging ICU environments.\nIn practical clinical scenarios, the proposed model can be embedded into ICU information systems to track patients' medications and vital indicators in real time, offering clinicians an early warning of mortality risk alongside a predictive severity score. Such insights facilitate earlier interventions, more efficient resource allocation, and improved patient prognosis. Furthermore, interpretability tools like SHAP provide transparency into the model's decision logic, enabling healthcare providers to understand how clinical severity scores and sociodemographic factors shape patient outcomes. Nonetheless, additional validation and refinement in external databases and prospective trials remain essential for ensuring the model's applicability across diverse populations and settings. With these steps, the proposed framework holds promise for enhancing ICU decision-making, optimizing sepsis management, and ultimately improving patient survival."}]}