{"title": "Hypergraph based Understanding for Document Semantic Entity Recognition", "authors": ["Qiwei Li", "Zuchao Li", "Ping Wang", "Haojun Ai", "Hai Zhao"], "abstract": "Semantic entity recognition is an important task in the field of visually-rich document understanding. It distinguishes the semantic types of text by analyzing the position relationship between text nodes and the relation between text content. The existing document understanding models mainly focus on entity categories while ignoring the extraction of entity boundaries. We build a novel hypergraph attention document semantic entity recognition framework, HGA, which uses hypergraph attention to focus on entity boundaries and entity categories at the same time. It can conduct a more detailed analysis of the document text representation analyzed by the upstream model and achieves a better performance of semantic information. We apply this method on the basis of GraphLayoutLM to construct a new semantic entity recognition model HGALayoutLM. Our experiment results on FUNSD, CORD, XFUND and SROIE show that our method can effectively improve the performance of semantic entity recognition tasks based on the original model. The results of HGALayoutLM on FUNSD and XFUND reach the new state-of-the-art results.", "sections": [{"title": "Introduction", "content": "With the development of information technology, documents have become a main information carrier nowadays, which contains kinds of information type, such as text, table and image. Manual recognition of these documents often requires plenty of manpower. OCR tools can only help us to identify the text, layout and other simple information in the document. To further understand documents, Visually-rich Document Understanding (VRDU) (Xu et al., 2020b) is proposed to make use of visual, textual and other information for more in-depth analysis.\nSemantic Entity Recognition (SER) is an important task in the field of VRDU. Its purpose is to extract and classify the text with special semantic information in documents. Different from text sequences in traditional natural language processing tasks, the information in documents is not one-dimensional, single-modal and continuous, but two-dimensional, multimodal and discrete. It is necessary to analyze not only text information, but also other modal information such as layout and vision in the document. Firstly, the text form of a single modal text task is a fixed text sequence, while the discrete text in a document is composed of text nodes in different locations. Secondly, the named entity recognition task of a single modal text only needs to consider the semantic relationship between the tokens in the text sequence. However, the semantic entity recognition task on the document needs to consider not only the semantic relationship between nodes, but also the position relationship between nodes. Finally, the span range of entity tags of NER task is flexible, while the range of task tags of semantic entity recognition task on document is affected by nodes. Texts of the same node in the document share the same label in most cases.\nWith the development of pre-training technology, document pre-training model has become popular. LayoutLM (Xu et al., 2020b) is the first multi-modal pre-trained model to associate text with layout and vision, achieving leading results on multiple downstream document understanding tasks including semantic entity recognition. Subsequently, more multi-mode pretraining models, such"}, {"title": "Hypergraph Semantic Entity Recognition", "content": "Inspired by Global Pointer (Su et al., 2022), we use the idea of hypergraph to extract the semantic information of documents and propose a Hypergraph Attention(HGA) strategy for document semantic entity recognition. Different from the traditional classification method, the semantic entity recognition idea of HGA regard the document token features as graph nodes. The target entity is the set of nodes with the same hyperedge and the hyperedge type represents the entity label type. The process of hypergraph extraction is to establish hyperedges between token feature nodes. Besides, we use the span hyperedge encoding to add the span information of text nodes. Through the hypergraph and span position, the head can better focus on the entity boundary information and establish the relationship between the document discrete text span and the entity boundary.\nOur main contributions are as follows:\n\u2022 We construct a novel hypergraph attention document semantic entity recognition method, HGA. It transforms the traditional token sequence classification problem into a hypergraph construction process. By establishing different types of hyperedges between text nodes, the head can extract semantic entities.\n\u2022 We propose a novel span hyperedge position encoding and balanced hyperedge loss. Span hyperedge position encoding makes the head focus more on the same text span prompt during hyperedge construction. Balanced hyperedge loss can help to solve the problem of matrix sparsity caused by too many hyperedge types in some scenarios.\n\u2022 We construct a novel document semantic entity recognition model HGALayoutLM based on the HGA method. Our code will be available at https://github.com/Line-Kite/HGALayoutLM. The experiment results show that the model has good performance in the scene with few types of labels. HGALayoutLM has obtained the best results on the FUNSD, SROIE and XFUND datasets."}, {"title": "Related Work", "content": "In recent years, self-supervised pre-training technology has become the mainstream trend in the fields of natural language processing (NLP) and computer vision (CV). BERT (Devlin et al., 2018) is a classic pre-training model that has shown great effectiveness in various tasks such as question answering, natural language generation and text classification. Masked Language Modeling (MLM) is a significant pre-training task proposed by BERT that enables models to learn textual representations by predicting the raw vocabulary ids of randomly masked word markers based on context. Since then, a series of mask language models such as RoBERTa (Liu et al., 2019), ALBERT (Lan et al., 2019) and XLNet (Yang et al., 2019) have been proposed successively. These models achieve good results on natural language understanding tasks.\nHowever, the single modal language model (Lan et al., 2019; Liu et al., 2019; Peng et al., 2023; Li et al., 2023b) can not understand documents with complex formats and diverse types well. To fully understand the content of complex documents, LayoutLM (Xu et al., 2020b) adds layout and document information on the basis of BERT to supplement the document format missing from plain text. Following LayoutLM, BROS (Hong et al., 2022), LayoutLMv2 (Xu et al., 2020a), XYLayoutLM (Gu et al., 2022), ERNIE-Layout (Peng et al., 2022), LayoutLMv3 (Huang et al., 2022) and other multi-modal pre-training document understanding models have been proposed successively and constantly make breakthroughs in various tasks in the field of document understanding. These models understand the document through the fusion of text, layout and vision information. Since document nodes are suitable to be represented by graph structures, some works begin to apply graph structures to document understanding models, such as ERNIE-mmLayout (Wang et al., 2022), ROPE (Lee et al., 2021), FormNet (Lee et al., 2022) and GraphLayoutLM (Li et al., 2023a).\nThe latest GraphLayoutLM and GeoLayoutLM (Luo et al., 2023) are both built on the basis of LayoutLMv3. They have achieved the most excellent results in several tasks of document information extraction. Inspired by some graph based works (Kipf and Welling, 2016; Velickovic et al., 2017; Wang et al., 2023), GraphLayoutLM models the document structure based on the hierarchical and positional layout of the document and represents the document layout modeling with a graph structure. To integrate graph structure information into the process of document understanding, GraphLayoutLM proposes graph reordering and graph masking strategies, adding graph information into the document understanding model in the form of sequence and self-attention mask. GeoLayoutLM implements geometric pre-training to enrich and enhance feature representation through three specially designed geometry-related pre-training tasks. In addition, GeoLayoutLM uses a novel relation head in the fine-tuning phase and obtains a big improvement over LayoutLMv3 in the relation extraction task. At present, little attention is paid to the effects of downstream task heads on the performance of various types of tasks. GeoLayoutLM proposes a novel relational head, but there is still a lack of research on the downstream task of semantic entity recognition in the field of document understanding. Most of the current models use a linear layer and cross-entropy to predict BIO label probabilities when dealing with semantic entity recognition tasks, such as LayoutLM, BROS, Lay-"}, {"title": "Methodology", "content": "3.1 Overview\nThe process of semantic entity recognition based on Hypergraph Attention is shown in Figure 3. Different from traditional semantic entity recognition methods, HGA focuses on extracting special entities. Instead of using BIO annotation method as the label annotation strategy for model input, we regard each special label (such as header, question and answer) as a label type. The entity without special meaning represented by the Other label in the BIO annotation will not be labeled as a hyperedge type in the hypergraph construction process. HGA regards token features as unit nodes and the process of establishing hyperedges between tokens can realize the extraction of special entities. It is worth noting that the node referred to here correspond to each token of token sequence. Text nodes, as mentioned earlier, are discrete pieces of text at different locations in the document. A text node corresponds to one or more token feature nodes. The process of hyperedge extraction can realize the extraction of special semantic entites and classification of different entity labels. Entities that do not have the meaning of a special label (that is, the entities of the Other label in the BIO annotation) will not have the connection of any special hyperedge.\nTo assist the construction of hyperedges, we use the span of each text node to generate the span position corresponding to the feature sequence. Then we use the span position encoding to add span information to the hypergraph construction process. In this way, the model can divide the hyperedge according to the text node span, so as to achieve more accurate extraction of the special entity range. In the stage of semantic entity extraction, we use multi-label classification to determine whether a node is connected by a hyperedge. Since there may be more than one type of hyperedges satisfying the join condition. To ensure the uniqueness of"}, {"title": "Hypergraph Attention Head", "content": "We use the multi-head self-attention matrices to represent the hypergraph. Consider a hypergraph with L number of nodes and N class of hyperedges. We use a multihead attention score of shape \\(N \\times L \\times L\\) as the representation of this hypergraph. Hyperedge classes are represented by different heads of multi-head attention. The attention matrix corresponding to each head represents the distribution of a type hyperedge.\nIn the hypergraph, each token corresponds to a node. Assume the document token sequence is\n\\(x = \\{x_1, x_2, ..., x_n\\}\\). After understanding the document model, we convert the input token sequence into a high-dimensional feature representation sequence of the tokens:\n\\(\\hat{h} = \\{h_1, h_2, ..., h_n\\} = Model(\\{x_1, x_2, ..., x_n\\})\\),\nwhere \\(h \\in R^{L \\times H}\\) is the high-dimensional feature representation sequence of the token and Model(.) is the document understanding model. L indicates the token sequence length, which also represents the number of token nodes. His the feature dimension size. Based on h, we can obtain the query vector q and the key vector k:\n\\(q = \\{q_a : W_{q,a}\\hat{h} + b_{q,a}\\}\\), \n\\(k = \\{k_a: W_{k,a}\\hat{h} + b_{k,a}\\}\\),\nwhere \\(a \\in Z^D\\) is one head in multi-head attention, which can be regarded as a type in D kinds of hyperedges. With multi-head query vector and key vector, hypergraphs can be represented by a self-attention score calculated by q and k:\n\\(s = q^Tk = \\{s_a(i, j) : q_{i,a}^T k_{j,a}, i \\in Z^L, j \\in Z^L\\}\\).\n\\(s_a(i, j)\\) is the attention score at the a type hyperedge span with [i, j]. \\(q_{i,a}\\) and \\(k_{j,a}\\) are the start and end of the span with [i, j] in the a type hyperedge matrix. In this way, we implement hypergraph extraction of semantic entities."}, {"title": "Span Position Encoding", "content": "As we mentioned in Introduction, tokens of the same text node normally share the same semantic label in the process of semantic entity recognition of documents. We hope that the head can consider this span boundary prompt during entity extraction. Therefore, we construct the span position of the token sequence based on the text nodes and incorporate span information into the heads through position encoding. As shown in Figure 3, token feature sequence \\(\\hat{h}=\\{h_1, h_2, ..., h_n\\}\\) and text node sequence \\(N = \\{N_0, N_1, ..., N_m\\}\\) has a surjective relation. We define this relational mapping as:\n\\(f(h_i) = N_j, h_i \\in \\hat{h}, N_j \\in N\\).\nBased on this relation mapping, we construct the span position. For the same text node \\(N_j\\), all token feature nodes that have a mapping relationship with the same text node \\(N_j\\) share the same position:\n\\(p_i = Position(f(h_i))\\)\n\\(= Position(N_j)\\)\n\\(= j, h_i \\in \\hat{h}, N_j \\in N\\),\nwhere \\(p_i\\) is the span position of token feature \\(h_i\\), Position is the index of \\(N_j\\). In this way, we can obtain the span position sequence \\(p = \\{p_1, p_2, ..., p_n\\}\\). On the basis of p, we use rotary position coding (Su et al., 2021) to generate position encoding R, which satisfies \\(R_i^T R_j = R_{j-i}\\). Then the calulation of multi-head hypergraph score will be adjust to the following form:\n\\(s_a(i, j) = (R_i q_i,a)^T(R_j k_j,a)\\)\n\\(= q_i,a^T R_i^T R_j k_j,a\\)\n\\(= q_i,a^T R_{j-i} k_j,a\\).\nBecause the start is always before the end when the span of token sequence is extracted. Span extraction nodes should not appear in the lower triangular region of the hypergraph attention score. For the purpose of making the hyperedge construction more reasonable, we add mtril to the hypergraph matrix and the final hypergraph score format is as follow:\n\\(s_a(i, j) = q_i,a^T R_{j-i} k_j,a + Mtril(i, j)\\)."}, {"title": "Balanced Hyperedge Loss", "content": "In the process of loss calculation, we collect positive samples \\(P_a\\) and negative samples \\(N_a\\) respectively for each type of hyperedge a . The positive sample indicates that there is a a type hyperedge span with [i, j] in a type hypergraph, while the reverse is a negative sample. The formats of \\(P_a\\) and \\(N_a\\) are as follows:\n\\(P_a = \\{s_a(i, j)|l_a(i, j) = 1\\},\\)\n\\(N_a = \\{s_a(i, j)|l_a(i, j) = 0\\},\\)\nwhere l is the hypergraph label matrix corresponding to s. With the sets of positive and negative samples, we can get the positive sample loss \\(L_p\\) and the negative sample loss \\(L_n\\):\n\\(L_p = log \\bigg(1 + \\sum_{(i,j)\\in P_a} e^{-s_a(i,j)}\\bigg)\\)\n\\(L_n = log \\bigg(1 + \\sum_{(i,j)\\in N_a} e^{s_a(i,j)}\\bigg)\\\nDifferent from Global Pointer (Su et al., 2022), we gain the final loss with a balance factor \\(b \\in [0,1)\\) to avoid the matrix sparsity caused by too many label types. The final training loss of hypergraph attention score can be expressed in the following form:\n\\(L = (1 + b)L_p + (1 - b)L_n\\)."}, {"title": "HGALayoutLM", "content": "To verify the performance of the HGA method, we apply HGA to the latest GraphLayoutLM to build a novel semantic entity recognition model, HGALayoutLM. We use GraphLayoutLM as the base model for feature encoding. According to its input requirements, we input four multi-modal document information of the document: text, layout, visual and graph to obtain the feature sequence of the text tokens. Before input, we sort the sequence of text tokens using the layout graph according to the reordering strategy of GraphLayoutLM. On the basis of this graph structure-prompted document understanding model, we use the hypergraph attention layer as the head for document semantic entity recognition. The feature sequence of the token and the generated span position are used as the head input. The HGA method is used to help the model extract and classify semantic entities according to the text node span prompts."}, {"title": "Experiment", "content": "4.1 Experimental Setup\nModel Settings. The model settings are consistent with those of GraphLayoutLM. The text sequence length is 512 and the document image is resized to 3 \u00d7 224 \u00d7 224 dimensions. The image is cut into 196 patches in the size of 16 \u00d7 16. Transformer self-attention layer scaling factor \u03b1 is set to 32. For HGALayoutLMBASE, the hidden layer dimensions, the number of encoder self-attention"}, {"title": "Main Results", "content": "The English datasets experiment results are shown in Table 3. The BASE version of HGALayoutLM using hypergraph attention layer as the head has achieved the best results on FUNSD and SROIE datasets (94.32 on FUNSD and 99.53 on SROIE), even when compared to the LARGE versions of"}, {"title": "Ablation Study", "content": "To verify the effectiveness of our Span Position Encoding. We conduct ablation study on FUNSD. We can see from Figure 4 that the entity extraction effect without position encoding (w/o pos) is much worse than that with position encoding. In addition, we also compare the performance of our span position encoding (w/ span pos) with that of traditional position encoding (w/ pos). We can find that the performance of our span position encoding is obviously better than that of traditional position encoding.This demonstrates the effectiveness of our span position encoding with span prompt.\nIn order to prove that Balanced Hyperedge Loss can solve the problem of sparse hyperedge matrix caused by too many entity types. We conduct experiment statistics on different value of balance factor on CORD dataset with plenty of entity types and present the results in Figure 5. We can see that the performance of the unbalanced model (b = 0) is not ideal, even worse than the performance of the MLP head. However, proper balance factor allow the model to pay more attention to the hyperedge entities and achieve better results. For example, the performance when b is 0.4 exceeds the performance when the MLP is used as the head."}, {"title": "Anaysis of Different Head", "content": "To analyze the effects of different head, we adopt GraphLayoutLMBASE and HGALayoutLMBASE as the base model to conduct comparative experiments on three different heads: linear layer, MLP and HGA. The experiments are carried out on FUNSD, CORD, SROIE and XFUND datasets.\nThe experiment results are shown in Table 5. As the simplest network structure, the linear layer has the worst classification effect. The MLP increases the number of linear layers on top of the linear layer. It also joins activation layers and dropout layers to linear layers. The more complex network structure makes MLP slightly better than the semantic entity recognition of a single linear layer on most datasets. As our proposed hypergraph attention method, HGA performs significantly better than the other two classifiers, which shows the effectiveness of HGA, which demonstrates the superior performance of HGA.\nTo test the complexity of HGA, we compare HGALayoutLM with the model with traditional heads. The PyTorch-OpCounter tool is used to calculate the time and space complexity. The number of entity types is set to 3. As we can see from Table 6, HGA does not bring a large cost of time and space calculation and HGA is even less costly than MLP in terms of time and space computation. This indicates that our performance improvement is not due to the increase in the number of parameters."}, {"title": "Comparison with Large Language Model", "content": "We conduct a comparative analysis of our HGALayoutLM with the latest document multimodal large language model, LayoutLLM (Luo et al., 2024), to analyze the advantages and disadvantages of the models. LayoutLLM, which uses LayoutLMv3 as encoder and Llama as decoder, has so far achieved the state of the art results on several document intelligence tasks. We show the comparison results in Table 7. We can see that our HGALayoutLM slightly underperforms compared to the professionally fine-tuned document large language model."}, {"title": "Conclusion", "content": "In this work, we propose a semantic entity recognition method (HGA) based on hypergraph attention. This method extracts semantic information from documents by establishing different hyperedges between feature nodes. On the basis of the hypergraph, we design span position encoding and balanced hyperedge loss to enhance the entity extraction capability of the hypergraph attention head. We use the HGA method to build a novel semantic entity recognition model HGALayoutLM based on GraphLayoutLM. This model has good performance in SER tasks. Experiments show that our method achieves the state of art on semantic entity recognition tasks on the FUNSD and XFUND datasets."}, {"title": "Limitation", "content": "The HGA method can achieve good performance on semantic entity recognition tasks, but there is still a lot of work for us to improve. On the one hand, when there are more types of semantic entities, the cost of improvement from HGA becomes higher. The number of superedge matrices increases because of more semantic entity categories. This not only leads to sparse label matrices, but also to more model parameters. How to solve the matrix sparsity and parameter growth caused by the number of label types is the future work we need to study. On the other hand, since our proposed head is currently targeted at semantic entity recognition tasks in the document domain. In the future, we will explore more general head to adapt to diverse document task types."}]}