{"title": "Anonymization of Documents for Law Enforcement with Machine Learning", "authors": ["Manuel Eberhardinger", "Patrick Takenaka", "Daniel Grie\u00dfhaber", "Johannes Maucher"], "abstract": "The steadily increasing utilization of data-driven methods and approaches in areas that handle sensitive personal information such as in law enforcement mandates an ever increasing effort in these institutions to comply with data protection guidelines. In this work, we present a system for automatically anonymizing images of scanned documents, reducing manual effort while ensuring data protection compliance. Our method considers the viability of further forensic processing after anonymization by minimizing automatically redacted areas by combining automatic detection of sensitive regions with knowledge from a manually anonymized reference document. Using a self-supervised image model for instance retrieval of the reference document, our approach requires only one anonymized example to efficiently redact all documents of the same type, significantly reducing processing time. We show that our approach outperforms both a purely automatic redaction system and also a naive copy-paste scheme of the reference anonymization to other documents on a hand-crafted dataset of ground truth redactions.", "sections": [{"title": "I. INTRODUCTION", "content": "With the proliferation of data-driven processing methods into many areas of daily life, data protection has also become increasingly important in recent years. In the European Union, the General Data Protection Regulation [1] was introduced in 2016 to protect personal information. At the same time, similar regulations in the US were updated and made more strict, such as the California Consumer Privacy Act [2]. These regulations must be implemented by all companies and government agencies that want to operate in these jurisdictions. For law enforcement authorities compliance is particularly important due to the sensitivity of the data involved, which is commonly achieved by not storing such data, thereby preventing the use of data-driven methods. Still, the utilization of large-scale processing of this data would promise greater efficiency and efficacy in many work processes in this area, but would also require longer and more extensive data storage. To allow storage of this data, one cornerstone is the thorough redaction of all Personally Identifiable Information (PII) in collected documents, e.g. by using named entity recognition [3]-[5]. Many documents that are relevant to law enforcement-such as travel and identity documents contain a lot of PII in different forms. The structure and elements on the documents may vary greatly from country to country, and even within one country the layout of documents is updated from time to time, resulting in multiple document models of the same type. Some documents contain barcodes with personal information such as names, pictures and biometric data. Others have a Machine-Readable Zone (MRZ) that also contains the holder's name and date of birth. These characteristics make purely text-based processing insufficient to achieve data protection compliance. However, for specific models of documents the data and layout are normally well defined.\nIn this work, we present a framework for automatic redaction of PII in any document by combining machine learning-based models with image redactions based on the knowledge of domain experts for document anonymization. This results in a system that is capable of large-scale data anonymization given only a single, already anonymized reference document. Given a collection of redacted documents, we are able to obtain the correct reference document using instance retrieval based on image embeddings generated by a self-supervised vision model, therefore not requiring any manual classification of the document beforehand. This minimizes the requirements on the underlying database by not requiring any document metadata for the selection process, making this framework applicable in diverse environments. We show that our joint approach outperforms both a purely data-driven approach and a naive use of the reference redactions as true redactions for the target document by evaluating the framework on a dataset annotated by experts in the specific domain. Our code and data are part of proprietary software and therefore cannot be made available as open source.\nThe structure of the paper is as follows: We first give a brief overview of related work on machine learning methods for data privacy in section II. Afterwards, the dataset and the problem domain are presented in section III. In section IV, we introduce the proposed method for anonymizing documents, followed by a detailed evaluation of the trained models on our dataset in section V. Finally, we discuss the limitations and future work of the approach presented in section VI, and conclude our findings in section VII."}, {"title": "II. RELATED WORK", "content": "Most research for data protection and anonymization focuses on text-based document data [3]. In [4] several deep learning based methods are studied to anonymize German financial documents. AGORA [5], the first anonymization model introduced in a police context in Spain, is based on named entity recognition and used to anonymize Spanish text documents.\nThe work that is most similar to ours is [6]. However, the main difference is in how the textual content is redacted. Their approach is more rigid and performs Optical Character Recognition (OCR) to find sensitive, predefined keywords in the document (such as \"Name\"), whose position, if found, is used to mask a predefined text region relative to it. In our case, we do not need keyword texts in the document to be able to find regions to be redacted, and we are also more robust against OCR failures, e.g. in the case of handwritten text or varying writing systems. Furthermore, their document type recognition is fixed to five different classes representing different countries, whereas our document recognition is based on instance retrieval and therefore does not need to be retrained to support new document types or models. We also perform a more thorough evaluation based on typical object detection metrics, which provides better insights into the performance of the approach. In follow-up work, Van Rooji et al. [7], presented a federated tool for anonymization and annotation of image data. Similar to our work, they use YOLOv5 [8], but evaluate the model only on the Flicker logo dataset [9] and not on travel and identity documents. Another method for image anonymization was introduced by S\u00e1nchez et al. [10] which, however, only used Spanish invoices for evaluation.\nBesides data protection, the field of forensics and law enforcement already utilizes machine learning methods in various other settings, such as for network or mobile forensics, or for detecting malware [11]. Another study used machine learning to analyze sexual predatory online chats [12]. Other work focuses on person re-identification [13]\u2013[15] or identify-ing the printer for specific documents from a given scan [16]-[18]."}, {"title": "III. DATA", "content": "Our evaluation data consists of digital scans of six different document types from seven countries, including identity and travel documents, as well as bank transfer forms. We manually annotated 206 images of documents containing PII, resulting in 1452 bounding boxes. We anonymized the PII in accordance with the regulations of the European Union, which is defined as \"any information that relates to an identified or identifiable living individual.\"\u00b9 Figure 2 on the left shows four redacted samples of this dataset. Each bounding box is labeled with a class that describes its redacted content, which we use to fine-tune our redaction predictions for each type."}, {"title": "IV. METHOD", "content": "The redaction process begins by retrieving an already redacted reference document from the database of the same model as the document to be redacted. We find this reference document by measuring the similarity between documents through a trained instance retrieval network. In this work, instance retrieval is used at the category level, since documents matching the country, document type and model are to be returned [19]. For this purpose, we learn image representations with deep learning and perform feature matching with the cosine similarity. For its deep feature extraction, we leverage the DinoV2 framework [20], a state-of-the-art self-supervised learning method for images based on vision transformers [21]. Since our domain differs significantly from common public vision datasets, we train a new DinoV2 model from scratch on our own dataset, which is composed of a large collection of various scanned documents. This ensures that the image encoders can extract meaningful features of the document images.\nNext, we use a set of object detection algorithms to predict the locations of text, images of faces, the MRZ, and barcodes in the given document. The predicted bounding boxes are then matched, filtered, and adapted to the redactions of the reference document, the details are described in section IV-A. Based on the class of the redaction (such as text or barcode), we vary our matching process in order to account for their unique characteristics. Since the format of the given and the reference document may not match exactly-i.e. the document may be shifted, scaled, or cropped\u2014we transform the refer-ence redaction bounding boxes using an affine transformation that we estimate by matching key points in both images. For this, we first use the A-KAZE algorithm [22] to find key points in both documents and then match them using a best-fit matcher that minimizes the Hamming distance. Finally, we compute the affine transformation using the RANSAC algorithm [23].\nFigure 1 shows an overview of the proposed framework, and in the following sections we describe the details of the redaction matching for each type in more detail."}, {"title": "A. Redaction Prediction", "content": "1) Face Image: Face detection is a common task not only applicable in forensics and therefore there exist readily avail-able models. We apply a pre-trained YuNet model [24]2, which recognizes faces in real-time and is based on a Convolutional Neural Network (CNN). Since ID documents often contain hard to detect changeable laser images, relying solely on pre-trained face detectors is not sufficient in order to cover all face images in the document. Thus, we also take into account the redactions of face images of the reference document and add any (transformed) reference bounding box that does not overlap with any of the predicted bounding boxes.\n2) Text: For detecting text on documents, we use a pre-trained PP OCRv3 model [25]. PP OCRv3 is a sophisticated and lightweight OCR system based on a collaborative mutual distillation learning framework [26], transformers, and CNN. Since our method requires only positional information for the detected text on the document, we only use the differential binarization-based text detection before the rectification and recognition steps of the model.\nUnlike to the other types of redactions, for text it is important to distinguish between text that needs to be redacted, and text that is unrelated to PII. We accomplish this by taking into account the transformed text redaction bounding boxes of the reference document. For each reference bounding box, we map it to the predicted bounding box with the highest Intersection over Union (IoU). For any reference bounding box that has an assigned IoU greater than 0.1 we fine-tune its width $W_{ref}$ given the best-matching predicted bounding box width $W_{pred}$, and its two top-left x coordinates $x_{ref}$ and $x_{pred}$ as in:\n$W_{ref} = W_{pred} + (x_{ref} - x_{pred})$\nThis results in bounding boxes that match the reference boxes on the left, while taking the adjusted width from the assigned bounding box prediction. For areas where there was no text prediction, we take the transformed reference bounding box directly, since we have found that some textual descriptions in official documents can be difficult for typical text detectors to detect because the background of the document often contains high-frequency features such as microscript or fine patterns, making forgery in these areas more difficult.\n3) Barcode: For barcode detection, we trained a custom model based on the YOLO architecture [8] using a custom dataset including different barcode classes, such as linear barcodes, QR barcodes, PDF417 barcodes. Although not needed for the redaction aspect, we have found that combining our barcode detection model with a stamp detection model used for other applications led to better performance in both domains. We match the detected barcodes with the barcodes in the reference document using the same scheme as for the text redactions.\n4) MRZ: To detect a MRZ on the document, we follow the method proposed by Rosebrock [27] and exploit the fact that the characters are printed in black on a bright background and can therefore be found using morphological closing operations after calculating the Scharr gradient [28] on the image. We use the PassportEye implementation of this algorithm [29] without the additional step of character recognition.\nWe apply the same matching scheme between reference and predicted redactions as for text and barcodes.\n5) Signature: Although there exist datasets for training signature detection models [30] and even pre-trained mod-els [31], [32], our data used in the evaluations contained a large enough domain shift that resulted in these models not showing satisfactory performance. Therefore, the transformed reference bounding boxes are used as final redactions. It is our plan to create a custom dataset in the future to include in the trained YOLO detection model."}, {"title": "V. EVALUATION", "content": "We first evaluate the instance retrieval component to obtain the reference bounding boxes, then the custom YOLO model for barcode detection, and finally the method to anonymize the documents as a whole."}, {"title": "VI. LIMITATIONS & FUTURE WORK", "content": "Despite considerable improvements, there are still some limitations that need to be addressed. Currently, our system mainly uses pre-trained models that are not fine-tuned on our data to match the use case. Training custom models for each anonymization type would mitigate the issues that were visible with the signature element type and also with the OCR on the bank transfer form. In particular, our current approach would benefit greatly from a working signature detection model, as using only the transformed reference document redactions did not yield sufficient performance.\nFinally, even with our approach, it is still recommended that a human verifies the correctness of the predicted redactions, as"}, {"title": "VII. CONCLUSION", "content": "We presented a framework for anonymizing personal data on various scanned documents. We have combined a set of automatic document element detectors with redactions from a reference document to produce anonymizations that are better than both; solely relying on the automatic detectors alone, as well as simply applying the reference redactions directly. We believe this is a major step forward in reducing the time required to process sensitive and confidential images containing personal information. In addition, the presented framework is useful not only for government agencies, but also for private companies, as data regulations are becoming more stringent worldwide."}, {"title": "ETHICAL IMPACT STATEMENT", "content": "This work directly addresses a key issue of ethical Al systems: Data protection. Our main intention of this work is to improve upon current automatic anonymization techniques in order to (1) prevent information leakage in large-scale data, and (2) to allow training of AI models without capturing biases of the personal information in the data. In particular, the latter point is a major concern in many domains where decision makers-for example, in law enforcement\u2014are increasingly relying on trained models to take advantage of statistical relationships observed in the respective domain."}]}