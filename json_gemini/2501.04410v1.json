{"title": "User Simulation in the Era of Generative Al: User Modeling, Synthetic Data Generation, and System Evaluation", "authors": ["Krisztian Balog", "ChengXiang Zhai"], "abstract": "User simulation is an emerging interdisciplinary topic with multiple critical applications in the era of Generative AI. It involves creating an intelligent agent that mimics the actions of a human user interacting with an AI system, enabling researchers to model and analyze user behaviour, generate synthetic data for training, and evaluate interactive Al systems in a controlled and reproducible manner. User simulation has profound implications for diverse fields and plays a vital role in the pursuit of Artificial General Intelligence. This paper provides an overview of user simulation, highlighting its key applications, connections to various disciplines, and outlining future research directions to advance this increasingly important technology.", "sections": [{"title": "1 Introduction", "content": "Advancements in generative artificial intelligence (AI) are presenting unprecedented opportunities for innovation across diverse fields, while simultaneously introducing complex challenges. Effective personalization in generative AI demands precise user modeling, which can be difficult to achieve due to the complexity and variability of individual preferences. Additionally, the success of interactive AI algorithms relies heavily on access to comprehensive interaction data for training, posing challenges in data collection and privacy. Finally, the evaluation of these AI systems is particularly difficult at scale via repeatable and reproducible experiments because of their interactive nature. User simulation, which involves using an intelligent agent to mimic a real user's decisions during interactions with an AI system, offers a promising solution to all these challenges. By providing a controlled environment for training, testing, and refining AI systems, user simulation becomes a key enabler of safe and responsible advancements in generative AI. This article provides an overview of this important emerging topic, highlighting its interdisciplinary nature and its broad impact.\nAs a research topic, user simulation is inherently interdisciplinary, intersecting with diverse fields both within and beyond computer science. For example, it draws upon concepts from psychology, economics, and human-computer interaction to create accurate and representative models of user behaviour [5]. The recent success of large language models (LLMs) has made it possible to simulate complex user actions and led to their widespread use in simulation tasks across different domains and application scenarios, including generating realistic conversations for dialogue systems [19], performing automatic relevance assessment of search results [27], simulating specific human subpopulations in social science research [1], and simulating the behaviour of communities [22]. Realizing the potential of user simulation, there has been a surge of interest and activity in this area, evidenced by the growing number of related workshops [3, 24] and tutorials [4, 12].\nThis article aims to synthesize research dispersed across various fields, review the current state of the art, and highlight potential future directions. Specifically, we provide a brief historical review of how simulation techniques can be employed for (1) user behaviour modeling, by creating realistic simulations of how users interact with a system when attempting to complete some task (Section 3), (2) data augmentation, by generating synthetic user interactions to improve the training of machine learning models (Section 4), and (3) system evaluation, by measuring the perceived utility and cost/effort from a user's perspective when completing a task (Section 5). Next, we broaden our perspective on user simulation to explore its role in integrating multiple research fields (Section 6). Finally, we discuss the role user simulation may play in the quest for Artificial General Intelligence (AGI), the ultimate goal of developing Al systems with human-like intelligence (Section 7).\nWe believe that this synthesis will be valuable not only to researchers but also to engineers and practitioners working broadly with generative AI techniques. Additionally, given the numerous difficult open challenges and the substantial work that remains, this article will also be of interest to funding agencies, as addressing these issues will require substantial support and investment."}, {"title": "2 User Simulation", "content": "What exactly do we mean by user simulation? In essence, it involves creating an intelligent agent that mimics how a user interacts with a system. This agent can be built based on models/algorithms/rules and any knowledge we have about the user (their behaviour, knowledge, etc.). Crucially, the agent can be parameterized to simulate a diverse range of users with varying characteristics.\nAs illustrated in Figure 1, once constructed, a user simulator can be used with any interactive Al system for evaluation or training purposes. Specifically, simulation has the potential to enable repeatable and reproducible evaluations at a low cost, without using invaluable user time (human assessor time or online experimentation bandwidth). In addition, simulation can augment traditional evaluation methodologies by offering possibilities to gain insights into how system performance changes under different conditions and user behaviour. Simulation techniques can also be leveraged to generate large amounts of synthetic data, which can be used for training Al models, especially in scenarios where real data is scarce or expensive to collect. Moreover, user simulation facilitates human-in-the-loop training, where human feedback is integrated into the learning process, known as Reinforcement Learning from AI Feedback (RLAIF) [2]. Finally, by comparing the observed real user interaction data with the synthetic data produced by an interpretable user simulator, we can model any user or any group of users and test hypotheses about their behaviour and preferences."}, {"title": "2.1 Definition", "content": "User simulation is the process of modeling a user's behaviour and decision-making patterns within an interactive system, specifically designed to mimic and predict how a user will act in various interaction contexts or scenarios related to completing a task. To effectively simulate a user's behaviour within an interactive system, configuration variables that influence this behaviour must be defined:\n\u2022 Task (T): A user's behaviour varies according to nature of the user's task. Tasks vary in complexity, and different tasks require different types and levels of interaction, decision-making processes, and completion strategies."}, {"title": "2.2 Scope", "content": "User simulation encompasses a wide spectrum, ranging from predicting single actions to modeling complex behaviour across multiple tasks. In our formulation, this scope is primarily determined by how the task information (T) is defined. At one end of the spectrum, T might represent a very specific interaction context, such as predicting whether a user would click on a particular search result snippet. Here, the focus is on simulating a single, isolated action. Moving along the spectrum, T could encompass a sequence of actions within a given context, such as reformulating search queries within a search session, requiring the model to consider dependencies between actions. Further expanding the scope, T might represent an entire task, such as finding information on a particular topic or completing a purchase, where the simulation would involve multiple sequences of interactions. Finally, at the broadest level, T could encompass a user's general preferences and behaviour across various tasks, necessitating models that capture long-term patterns and adapt to different contexts. Thus, by varying the granularity"}, {"title": "2.3 Approaches", "content": "The problem of simulating the action a user takes in a given context (represented by the policy function \u03c0) can often be framed as a classification problem when there is a relatively small set of actions to choose from; for example, simulation of a user's clicking action may be framed as a binary classification problem, where the algorithm would predict whether the simulated user would click on a specific item. When there are potentially infinitely many actions to choose from (e.g., when formulating a query, any valid query would be potentially an option), simulating user actions becomes significantly more challenging. The vast action space can lead to computational complexity and makes it difficult to define a meaningful probability distribution over possible actions. In practice, we often make assumptions to restrict the number of actions to be considered when simulating those actions (e.g., assuming the user will only use keywords from a predefined vocabulary, or that the query will follow a specific structure). However, other approaches, such as using generative models, may also be employed to handle large or infinite action spaces more effectively.\nWith the problem framed as a classification problem, different approaches generally vary in how they perform the classification (equivalently prediction) task. At a high level, we can distinguish two broad approaches: model-based and data-driven.\n\u2022 Model-based approaches may be based on rules designed with knowledge about how users behave or on interpretable probabilistic models that can more flexibly capture uncertainties using interpretable parameters. The parameters of such models may be set heuristically or empirically derived from observed user data. By varying those parameters, different types of users can be simulated.\n\u2022 Data-driven (or machine-learned) approaches emphasize maximizing accuracy of fitting any observed real user data, without necessarily imposing interpretability. Almost all such approaches are based on supervised machine learning, notably using deep neural networks which can learn effective, but non-interpretable representations from the data for predictive modeling.\nThese two families of approaches may also be combined, e.g., by utilizing model-based techniques to compute effective features for"}, {"title": "2.4 Uses of Simulation", "content": "User simulation has many uses, including:\n\u2022 Gaining insight into user behaviour to inform the design of systems and evaluation measures.\n\u2022 Performing large-scale automatic evaluation of interactive systems (i.e., without the involvement of real users), and analyzing system performance under various conditions and user behaviours (answering what-if questions, such as \"What is the influence of X on Y?\").\n\u2022 Augmenting data with human feedback and generating synthetic data with the purpose of training machine learning models and addressing data scarcity or privacy concerns. More broadly, user simulation can facilitate machine learning approaches that require human input (interactive learning, reinforcement learning, or human-in-the-loop systems)."}, {"title": "2.5 Requirements and Desiderata", "content": "Effective user simulators depend on a range of carefully considered properties, including:\n\u2022 Validity: Simulated users must exhibit behaviours that align with empirical observations of real user behaviour in similar contexts. This includes both high-level strategies (e.g., information seeking patterns) and low-level actions (e.g., clicking behaviour). Without validity, the insights gained from simulation cannot be trusted.\n\u2022 Interpretability: While not strictly a requirement, interpretability is a highly desirable property. Interpretability means that the simulated behaviour can be understood and adjusted through controllable parameters. This allows researchers to (1) understand why the simulator produced certain behaviours and (2) investigate how changes in specific parameters influence the behaviour of users. Since user behaviour and preferences vary significantly across users, interpretability is crucial for understanding which real-world users can be expected to produce results similar to the simulations.\n\u2022 Cognitive plausibility: The decision-making processes underlying simulated user behaviour should be grounded in theories or"}, {"title": "3 User Simulation for User Modeling", "content": "Understanding users is key to any personalized system, and the the study of user behaviour in interactive systems has been the subject of decades of user-oriented research [18]. Conceptually, a user model is an explicit representation of the user's background, goals, and expected behaviour when interacting with a system. User models can be utilized to optimize the design of user interfaces and algorithms, enabling them to adapt effectively to the specific needs of each individual user.\nAnalysis of user behaviour is often performed via controlled user studies. However, a major challenge in user studies is that the experimental conditions can introduce variables that are difficult to control (e.g., users' background, domain knowledge, or perseverance), but they can affect how users interact with the system. Another approach to studying user behaviour is to analyze historical log data generated by real users. While log-based studies allow for the verification of certain assumptions about user behaviour, they are limited to a specific version of the system in use at the"}, {"title": "4 User Simulation for Data Augmentation", "content": "As data is the \"fuel\" to power Al systems, both its quality and quantity directly affect system effectiveness. The type of data available also determines the kind of intelligence a system can acquire. For example, the abundance of textual data on the Web has enabled the training of powerful LLMs like ChatGPT and Gemini, which have acquired linguistic knowledge and much common sense knowledge. However, user interaction data is scarce, as generating it requires actual user interactions, which are time-consuming and expensive to collect. For instance, even the search log data of a major commercial search engine would still be limited in its coverage of diverse information needs, user behaviours, and preferences. Moreover, user interaction data generally contains sensitive user information, restricting its access for researchers outside the company where it is collected. User simulation offers a natural solution by generating large amounts of synthetic user interaction data. This can be done in various ways, including augmenting existing user interaction datasets for offline model training or employing user simulators in interactive, human-in-the-loop training scenarios.\nWhile interpretability is crucial for user simulation in evaluation, it is less critical for data augmentation. The usefulness of synthetic data often depends more on its distributional similarity to real user data than on the simulator's realism. For instance, in Reinforcement Learning from AI Feedback (RLAIF) [2], the learned reward model, which implicitly captures user preferences, can be considered a non-interpretable user simulator. This relaxed requirement-that interpretability is not essential for effective data augmentation-coupled with advances in deep learning, particularly the rise of LLMs capable of generating realistic text, has facilitated progress in user simulation for data augmentation, especially in the context of conversational systems [26]. However, concerns remain about the diversity of LLM-generated text [9]. Interpretable simulators, with their ability to vary meaningful user parameters in a counterfactual way (e.g., by making a simulated user increasingly more patient), offer greater control and flexibility for data augmentation compared to non-interpretable ones.\nIt is worth noting that while simulating users holistically is desirable, even simulating specific user actions can still be valuable for generating additional task-specific training data (e.g., generating queries that might lead to clicks on a particular item [10]). Focusing on specific actions would also simplify making progress in data augmentation. Since data augmentation benefits various machine learning models, utilizing user simulation for this purpose expands its scope into potentially many other areas of Al research."}, {"title": "5 User Simulation for Evaluating Interactive AI Systems", "content": "Evaluation of Al systems is crucial for both advancing Al research and deploying production systems. In research, rigorous evaluation allows us to compare algorithms and understand the relative strengths and weaknesses of different approaches. This knowledge guides further research and development. For deployed systems, evaluation ensures that the chosen algorithm meets the specific needs and expectations of its users. Inaccurate evaluation can misdirect research efforts or lead to the deployment of suboptimal systems, hindering progress and potentially having negative consequences for users.\nThere are three widely-used evaluation methodologies for AI systems: reusable test collections, user studies, and online evaluation.\nReusable test collections (or offline evaluation) enable large-scale automatic evaluation, facilitating algorithm comparison and advancement. They ensure repeatability and allow for the study of individual components within complex methods. However, these static evaluations often fail to capture user interactions and behaviours adequately, relying on simplified models of processes and user behaviour. This methodology, while standard for making relative comparisons between systems, struggles with evaluating the actual utility of interactive systems due to its inherent abstraction and deviation from the dynamic complexities of real-world applications.\nUser studies capture real users' interactions in controlled settings, providing high-fidelity insights into a system's actual utility. However, they are costly, time-consuming, and often suffer from reproducibility issues due to user fatigue and learning effects. Moreover, recruiting a sufficient and representative user base often proves challenging, making this method less accessible for smaller companies and academic settings.\nOnline evaluation (or log-based studies) observes real users interacting with a fully operational system, offering reliable measurements of quality and user experience through large-scale data analysis. A/B testing is a common example [20]. While this method enables utility assessment with many users, it lacks control over user variables, complicating result interpretation. Additionally, it cannot accommodate counterfactual evaluation and poses risks if new system versions perform poorly, potentially impacting user perception of the system.\nIn general, all the three methodologies above can be applied to, and indeed have been regularly used for, evaluating interactive AI systems. However, these approaches have limitations when it comes to conducting reproducible experiments: the test collection-based approach is static by its very nature, while there is an inherent lack of reproducibility when real users are involved. User simulation can help address these challenges: simulated users can be controlled, enabling reproducible experiments and systematic analysis of system performance. Figure 2 illustrates how user simulation relates to and complements these traditional evaluation methodologies.\nGenerally, we may consider interactions with an Al system as \"moves\" in an interactive game, where the user and the AI system take turns making moves based on the current interaction environment. A user simulator is an operational agent that can simulate how a user makes those decisions. To evaluate an Al system, we can let it interact with a simulated user and measure its performance based on the interaction data generated. This approach allows for a controlled and systematic evaluation of how the system responds to different user behaviours and preferences.\nA general simulation-based evaluation framework can thus be defined as consisting of the following elements:\n(1) A collection of user simulators are constructed to approximate real users."}, {"title": "6 User Simulation as an Interdisciplinary Research Field", "content": "User simulation research is inherently interdisciplinary, intersecting with a multitude of fields, including that of information science, information access, machine learning, natural language processing, knowledge representation, human-computer interaction, and psychology. Recognizing this, future research will benefit significantly from integrating insights and approaches from these diverse areas. Below, we briefly discuss some of the connections and potential synergies between user simulation and related fields.\nIntelligent Agents. A sophisticated user simulator can be regarded as an intelligent agent interacting within a system's environment. Consequently, techniques used for developing intelligent agents can also prove valuable in the construction of user simulators. More specifically, multi-agent systems are particularly well-suited for simulating communities of users, as they enable the modeling of complex interactions among multiple individuals within the simulated environment [28]. A perfect user simulation agent can also be regarded as a basis to implement a human digital twin, which has widespread applications [31]. Conversely, building upon user simulation research, intelligent agents can benefit from even more precise modeling of individual behaviour.\nMachine Learning. The extent to which machine learning is incorporated into user simulators can vary based on interpretability needs. For applications demanding high interpretability, like user modeling, machine learning might be employed for specific simulator components. When interpretability is less critical, as in data augmentation, end-to-end simulators can even be directly learned from observational data. From the perspective of machine learning, there are numerous tasks that require human involvement, such as labeling, annotation, human-in-the-loop learning, and model evaluation. User simulation offers a promising avenue to streamline these processes by reducing reliance on human labor, thereby cutting costs and saving time. Notably, recent research exploring the use of LLMs for data labeling and relevance assessment can be viewed as developing specialized user simulators that emulate the actions of human annotators [8, 27]. Another pertinent example is reinforcement learning with human feedback (RLHF), which has recently gained significant attention for its use in training LLMs [21]. In RLHF, a machine-learned reward model is trained to capture human preferences and subsequently used to guide the training of the primary machine learning model-this reward model is essentially a user simulator.\nKnowledge Representation. A realistic user simulator requires a model of the user's knowledge state, encompassing both their general world knowledge and specific understanding of the application domain and the AI system itself. As user actions are often a consequence of their particular knowledge state, user simulation is inherently linked to the study of knowledge representation and involves reasoning over knowledge (to decide which action to take). Furthermore, the user's knowledge model needs to be dynamically updated to reflect learning through interaction with the AI system [29]. While existing work has often relied on simple knowledge representations, future research could explore more sophisticated techniques, such as personal knowledge graphs [25], to enhance the realism of user simulators. Broadly speaking, how to represent and reason over a user's knowledge, and how to capture their knowledge acquisition during interaction, remain crucial"}, {"title": "7 User Simulation as a Step toward AGI", "content": "The overarching goal of developing a realistic user simulator is, in many respects, aligned with the broader objective of creating intelligent agents with human-like intelligence, namely, the pursuit of AGI. A sophisticated user simulator that mimics human behaviour would respond to system interactions and select appropriate actions to accomplish a given task. In a similar way, an intelligent agent designed to assist a user in completing a task would respond to the user's actions and select appropriate actions (such as choosing suitable system services to support the user). Thus, both user simulation agents and intelligent task agents share a common modeling approach, enabling optimization through reinforcement learning algorithms. The key differences lie in the definitions of states, actions, and reward functions. For user simulation, the goal (reward) is to mimic real user behaviour, while for task agents, the reward is typically tied to providing an effective and user-friendly service for task completion. Additionally, user simulation centers on user actions, whereas intelligent agents focus on system responses. Because of this similarity, the technical challenges in building intelligent user simulators may mirror those encountered in developing intelligent task agents. Consequently, we anticipate broader connections between research in user simulation and various other fields of AI.\nThe Importance of User Simulation in Human-Al Collaboration. Realizing the full potential of human-AI collaboration requires more than just superhuman performance from Al agents. To truly maximize combined intelligence, these agents must also account for the inherent variability in human behaviour, including suboptimal actions, diverse problem-solving approaches, and individual preferences. Recent work in chess, a domain that has long served as a Petri dish for AI research, underscores this challenge. Studies have shown that human players paired with AI agents tailored to their skill level outperform those partnered with more powerful Al agents that are not adjusted for skill-compatibility [16]. This suggests that simply providing the most powerful AI assistance may not be optimal. Instead, simulating the user's knowledge, preferences, and decision-making processes, and adjusting the Al's assistance accordingly can lead to more effective collaboration.\u00b9 Such an approach requires user simulation agents to be closely integrated with task agents, allowing the task agent to leverage the user simulation agent to receive feedback and optimize its interaction policy. Likewise, the user simulation agent must adapt to model how new Al systems behave over time. Therefore, the interdependence between research on intelligent task agents and user simulation is inherent and may persist until AGI is achieved.\nLarge Language Models as Building Blocks for Intelligent Agents. The emergence of LLMs could accelerate this integration and synergy, as these models may very well serve as a foundational building block for both types of agents. Indeed, LLMs have already fueled their extensive adoption as both task agents and simulation tools in various domains and applications. For comprehensive surveys of work combining agent-based modeling and LLMs across various fields (social science, natural science, and engineering) and domains (e.g., cyber, physical, social environment) we refer readers to [14] and [32].\nAs the uses of LLMs for building user simulation agents and task agents are rapidly expanding, it is also crucial to recognize their limitations. LLM-generated responses can be unpredictable and sometimes unsafe, causing concerns about the safety of an intelligent task agent when deployed in the real world and the realisticity of a user simulation agent. For user simulation, current LLMs would inevitably exhibit unrealistic or incoherent behaviours and may also lack the natural variation observed in real human interactions. Furthermore, LLMs often possess more knowledge than average humans and generate overly \"perfect\" responses, which may not be a problem for an intelligent task agent (indeed, it could be a feature!), but would likely lead to the simulation of unrealistic \"superusers\" by a user simulation agent. While prompting techniques can guide LLM behaviour, ensuring strict adherence to instructions remains a challenge [5]. Importantly, more fundamental challenges suggest that LLMs alone will not be sufficient. Critically, LLMs have insufficient knowledge of human behaviour. While they might be aware of concepts like patience or satisfaction, they lack the training data to model the human dynamics of such behaviours. Similarly, LLMs lack a deep understanding of human cognitive processes, such as decision-making, memory recall, and attention span. They may fail to accurately simulate phenomena like cognitive biases or the limitations of working memory. These shortcomings hinder their ability"}, {"title": "8 Conclusion and Outlook", "content": "User simulation plays an increasingly important role in the era of Generative Al with a wide range of applications, including user behaviour modeling and analysis, data augmentation, and system evaluation. Each application area may require different simulation techniques and will likely lead to the development of specialized simulators. At the same time, there is clear synergy among the different lines of exploration and the various research directions can enhance and inform one another. Over time, these diverse lines of research may even converge as we advance toward AGI. Much of the research today on user simulation is scattered across different communities. We envision a convergence of research in this area in the future, where researchers from multiple communities and disciplines would have increasingly more engagement and collaboration. The user simulation portal at http://usersim.ai is an emerging platform with the potential to facilitate this, though further effort is required to accelerate interdisciplinary research and foster cross-disciplinary collaboration. In the short term, progress can be made by regularly hosting workshops on user simulation at different major conferences of different communities, which would facilitate the creation and growth of an interdisciplinary research community around the general topic of user simulation.\nTo facilitate validation of user simulators at scale, it is essential to involve industry partners who have access to real user behaviour data. Since industry partners would benefit from access to user simulators relevant to their businesses, there may be incentive for them to collaborate with academic researchers on establishing a sustainable ecosystem for accelerating research, development, and applications of user simulation. For example, user simulators built by academic researchers can be made available via open source and can then be validated by industry partners using their real user"}]}