{"title": "THE RESTAURANT MEAL DELIVERY PROBLEM\nWITH GHOST KITCHENS", "authors": ["Gal Neria", "Michal Tzur", "Florentin D Hildebrandt", "Marlin W Ulmer"], "abstract": "Restaurant meal delivery has been rapidly growing in the last few years. The main challenges in\noperating it are the temporally and spatially dispersed stochastic demand that arrives from customers\nall over town as well as the customers' expectation of timely and fresh delivery. To overcome these\nchallenges a new business concept emerged, \u201cGhost kitchens\". This concept proposes synchronized\nfood preparation of several restaurants in a central complex, exploiting consolidation benefits. How-\never, dynamically scheduling food preparation and delivery is challenging and we propose operational\nstrategies for the effective operations of ghost kitchens. We model the problem as a sequential\ndecision process. For the complex, combinatorial decision space of scheduling order preparations,\nconsolidating orders to trips, and scheduling trip departures, we propose a large neighborhood search\nprocedure based on partial decisions and driven by analytical properties. Within the large neigh-\nborhood search, decisions are evaluated via a value function approximation, enabling anticipatory\nand real-time decision making. We show the effectiveness of our method and demonstrate the value\nof ghost kitchens compared to conventional meal delivery systems. We show that both integrated\noptimization of cook scheduling and vehicle dispatching, as well as anticipation of future demand\nand decisions, are essential for successful operations. We further derive several managerial insights,\namongst others, that companies should carefully consider the trade-off between fast delivery and\nfresh food.", "sections": [{"title": "1 Introduction", "content": "The demand for restaurant meal delivery is booming. More and more people order food online and expect a fast and\nfresh delivery at low cost. The high expectations are often not met in practice, and customers complain about long\nwwaits and cold food. At the same time, restaurants and delivery platforms struggle to become profitable with meal\ndelivery. One reason is the limited consolidation potential of orders. Customer orders come in over time from locations\nall over the city. Restaurants are distributed all over the cities as well. Combined with very tight delivery promises,\nthis makes consolidation nearly impossible, or, when consolidated, food likely arrives not fresh at the customers. With\nthese challenges in mind, new business concepts emerge, called \u201cGhost kitchens\u201d, \u201cDark kitchens\u201d, or \u201cCloud kitchens\""}, {"title": "2 Literature Review", "content": "Our work addresses the problem field of restaurant meal delivery, its model requires dynamic scheduling and routing,\nand the methodology focuses on quickly searching a large and complex decision space and evaluating decisions via\nvalue function approximation. In the following, we discuss related problem, model, and methodology literature."}, {"title": "2.1 Problem: Meal Delivery Routing", "content": "Work on restaurant meal delivery has surged in the last years. The majority of work aims on efficient and flexible\nrouting strategies to deliver meals from different restaurants to dynamically requesting customers. Early work by\nReyes et al. (2018), Steever et al. (2019), Liu (2019) and Ulmer et al. (2021) present intuitive heuristic methods to\ndynamically assign orders to vehicles. The general goal is to ensure timely service by balancing routing efficiency\nwith fleet flexibility. Yildiz and Savelsbergh (2019) analyze optimal dispatching strategies in a deterministic setting\nderiving insights in the value of bundling operations and giving guidelines in demand management and the scheduling\nof delivery vehicles. Recently, first work on reinforcement learning was proposed by Jahanshahi et al. (2022) to\ndetermine anticipatory assignments and rejections of orders, i.e., learning the expected future revenue when a decision\nis taken. However, scheduling or routing decisions were not considered. Other work on meal delivery addresses\narrival time predictions (Hildebrandt and Ulmer 2022) with the goal of providing accurate delivery time information\nto customers, the scheduling of the workforce (Ulmer and Savelsbergh 2020, Dai and Liu 2020, Auad et al. 2024) to\nensure timely delivery without excessive workforce cost, or the zoning of the service area with respect to current and\nfuture demand (Ulmer et al. 2022, Auad et al. 2023). While most of the studies focus on timely delivery for customers,\nnone of the considered studies analyzes ghost kitchens or considers integrated scheduling and routing decisions. In the\nproblem addressed in this paper, we consider the assignment and scheduling of orders in combination with the vehicle\ndispatching. To achieve efficiency (and sometimes even feasibility) in the overall process, decisions regarding order\npreparation and the vehicle dispatching operations need to be coordinated in an integrated and anticipatory fashion.\nWhile synchronization in meal delivery has not been considered in the literature yet, the importance of synchronization\nin vehicle routing problems has been highlighted by Drexl (2012), who present a survey on vehicle routing problems\nwith synchronization constraints."}, {"title": "2.2 Model: Combined Scheduling and Routing", "content": "From a modeling perspective, our problem may be considered as a combination of models for dynamic order scheduling,\ne.g., Xu et al. (2016), Zhao et al. (2018a), Zhao et al. (2018b) and D'Haen et al. (2023), and dynamic vehicle dispatching,\ne.g., Klapp et al. (2018). A combination of both is relatively rare, and we list here a few exceptions."}, {"title": "2.3 Methodology: Search and Evaluation of Complex Decision Spaces", "content": "The methodological contribution of our work is to combine the search of a complex decision space with an evaluation\nvia value function approximation (also known as reinforcement learning, RL). Value function approximations (and\nRL-methods in general) repeatedly simulate the decision process and store the observed values of decisions in an\naggregated form. The values are used for decision making and updated over the simulation. As a recent review by\nHildebrandt et al. (2023) shows, past research either focused on a comprehensive search without explicit evaluation\nor alternatively, an explicit evaluation via RL, but only for a very few potential decisions. There are, however, a few\nexceptions.\nRivera and Mes (2017, 2022) and Heinold et al. (2023) use RL to decide which freight to dispatch. The values are\napproximated via a linear function based on a set of post-decision state features. Mixed integer programming is used for\nsearching the decision space. A similar concept is proposed by Silva et al. (2023) to decide about assignments in urban\ndelivery, however, a neural net is used for approximation. This neural net is again linearized to allow the application of\nmixed integer programming. None of the works considers more complex decision spaces and problems that involve\nrouting decisions with complex constraints. This slows down the search of the decision space while at the same time\nmakes linearization of the features and the value function approximation more challenging.\nRecently, Neria and Tzur (2024) proposed using a metaheuristic instead to search the decision space quickly and\nevaluate decisions with a value function approximation. The general idea is similar to our approach. However, while\nour works share the general combination, our problem differs significantly from Neria and Tzur (2024) and the design\nof both search and evaluation methodology is therefore essentially different. For our problem, the decision space is\nvery large and finding feasible decisions is a challenge. Thus, we propose an alternative decision formulation that\nreduces the burden to determine a complete decision and allows for fast feasibility checks based on a set of carefully\nderived propositions. With the more complex decision space and larger problem size, learning the values becomes more\nchallenging as well. While the mentioned fast search reduces the training time significantly, simulating systems of\nrealistic size and learning the values is still computationally expensive. Thus, we propose transfer learning, training our\npolicy on small instances and transferring our trained policy to realistically sized instances."}, {"title": "3 Problem Statement", "content": "In this section, we introduce the Restaurant Meal Delivery Problem with Ghost Kitchens (RMD-GK). First, we describe\nthe problem. Then, we illustrate the model's components with an example. Finally, we formally define the problem as a\nsequential decision process."}, {"title": "3.1 Problem Description", "content": "A ghost kitchen is a facility for the sole purpose of preparing delivery-only meals. It is partitioned into a set of kitchens,\neach with dedicated cooks, and uses a joint fleet of capacitated vehicles for delivery (e.g., cargo bikes or delivery cars).\nEach kitchen is associated with a fixed ghost restaurant that we refer to as a food type and prepares only orders from\nthat food type.\nOver the course of the day, customers order food from the restaurants. In our setting, each order includes only one of\nthe food types, i.e., can be prepared by one of the ghost restaurants. Each order is associated with a known preparation\ntime and a customer location. Once an order is prepared, a vehicle picks up the order and delivers it (immediately or\nafter some waiting time) to the respective customer, with or without other customers' orders at the same trip. If orders\nare bundled, and more than one order is dispatched in the same trip, the trip also captures the sequence of orders.\nThe scheduling of the orders in the restaurants and the scheduling of the delivery vehicles is done by a central information\nsystem. This system maintains and updates a schedule over time. The schedule determines for each restaurant which\ncook prepares which order, and when. We refer to this as the cook schedule. It further decides about the bundling of\norders to trips, their assignment to vehicles, and the departure times of each trip. We refer to this as the vehicle schedule.\nA schedule is only feasible if each order's freshness is guaranteed when arriving at the customers. Thus, a schedule\nmust ensure for each order that the ready-to-door time, i.e., the difference between the ready time of the food at the\nrestaurant and the arrival time at the customer, does not exceed an order-specific duration. E.g., in case a cook is ready\nbut upon the order preparation completion, a vehicle might not be available to deliver it fresh, the starting time of the\norder preparation may need to be postponed until a fresh delivery can be guaranteed. Customers expect fast delivery,\nideally within 30 minutes after the order was placed. The goal of the platform is to meet the expectation by minimizing\nthe average exceedance of delivery time (delay) over all orders."}, {"title": "3.3 Sequential Decision Process", "content": "The RMD-GK is stochastic and dynamic. It is stochastic, as orders are unknown until they are placed and their\nrealizations follow known probability distributions in time and space. It is dynamic because decisions are made\nrepeatedly over time. We model the problem as a sequential decision process. To that end, we first introduce the\nglobal problem notation. Then, we formally define the process components, namely, decision points, states, decisions,\npost-decision states, costs, stochastic information, transitions, and objective."}, {"title": "Decision Points.", "content": "A decision point $k$ occurs whenever a new order is placed and at the end of the order capture phase at\ntime $T^c$ when no more orders will arrive. As the realization of orders is stochastic, the number of decision\npoints $K$ is a random variable."}, {"title": "States.", "content": "A state $S_k \\in \\mathcal{S}$ comprises all information relevant for decision-making. We categorize the state information\naccording to order information, currently planned cook schedules, and currently planned vehicle schedules.\nFirst, we describe the order information. Except for the final state $S_K$ in $T^c$, a state contains a new order. The\nnew order in state $S_k$ at time $t_k$ is denoted by $i_k$. The set of open orders, i.e., orders that have been placed but\nhave not yet left the ghost kitchen for delivery, is denoted by $I_k$ and includes order $i_k$. Each order $i \\in I_k$ is\nrepresented by four variables indicating the food type $f_i \\in \\mathcal{F}$ of order $i$; the time of day at which order $i$ was\nplaced $t_i \\in [0, T^c]$; the preparation time of the corresponding meal $t_i^p \\in \\mathbb{R}_{>0}$; and the location of the order $l_i$.\nIn summary, each order $i \\in I_k$ is associated with $(f_i, t_i, t_i^p, l_i)$.\nSecond, we describe the currently planned cook schedules. The cook schedules were decided on in the last\ndecision point $k-1$ and pruned in the transition to the current state (see Transition). They include all orders\nin $I_k$ except the new order $i_k$. In state $S_k$, the currently planned sequence of orders prepared by cook $c \\in \\mathcal{C}$ is\ngiven by $\\psi_{kc} = (i_1^c, i_2^c, \\dots ) \\subseteq I_k \\setminus \\{i_k\\}$. The set of all preparation sequences is given by $\\Psi_k = \\{\\psi_{kc} \\mid c \\in \\mathcal{C}\\}$.\nThe planned time of day at which the preparation of order $i \\in I_k \\setminus \\{i_k\\}$ is started is denoted by $t_i^s \\in [t_i, T]$\nwhere $s$ is a symbol. The corresponding set is given by $\\textbf{t}_k^s = \\{t_i^s \\mid i \\in I_k \\setminus \\{i_k\\}\\}$. In summary, the state\nvariables corresponding to the cook schedules are given by $(\\Psi_k, \\textbf{t}_k^s)$.\nThird, we describe the currently planned vehicle schedules. Analogous to the cook schedules, the currently\nplanned vehicle schedules were decided on in the last decision point and pruned in the transition to the current\nstate (see Transition). The schedules contain all orders in $I_k$ except the new order $i_k$. The sequence of trips\nperformed by vehicle $v \\in \\mathcal{V}$ is denoted by $\\Theta_{kv} = (\\theta_{kv1}, \\theta_{kv2}, ...)$. Each trip $\\theta \\in \\Theta_{kv}$ consists of a sequence\nof orders $(i_1, i_2, \\dots) \\subseteq I_k \\setminus \\{i_k\\}$. The set of all planned trip sequences is given by $\\Theta_k = \\{\\Theta_{kv} \\mid v \\in \\mathcal{V}\\}$.\nThe planned time of day at which trip $\\theta \\in \\Theta_k$ departs is denoted by $t_\\theta^d \\in [t_k, T]$ where $d$ is a symbol. The set\nof all departure times is denoted by $\\textbf{t}_k^d = \\{t_\\theta^d \\mid \\theta \\in \\Theta_k\\}$. Each vehicle's $v \\in \\mathcal{V}$ (next) return time to the ghost\nkitchen is denoted by $t_{rv} \\in [t_k, T]$ ($r$ is a symbol), where its value is either $t_k$ if the vehicle is idling or its\nreturn time from its last trip that departed before $t_k$ (note that the trip itself is not part of the state $S_k$). The set\nof all vehicles' return times is given by $\\textbf{t}_k^r$. To summarize, we represent a state as the tuple\n\n$S_k = (t_k, I_k, \\Psi_k, \\textbf{t}_k^s, \\Theta_k, \\textbf{t}_k^d, \\textbf{t}_k^r).$   (1)"}, {"title": "Decisions.", "content": "A decision $x_k \\in X(S_k)$ is an update $X_k = (\\Psi_k^\\star, \\textbf{t}_k^{s,\\star}, \\Theta_k^\\star, \\textbf{t}_k^{d,\\star})$\non the current plan $(\\Psi_k, \\textbf{t}_k^s, \\Theta_k, \\textbf{t}_k^d)$. This\nupdate must integrate the new order $i_k$ into the current plan (except for the final state $S_K$ in $T^c$) but may also"}, {"title": "Objective.", "content": "A mapping that assigns each state $S_k$ a decision $\\pi(S_k) = x_k$ is called a policy and denoted by $\\pi \\in \\Pi$.\nGiven an initial state $S_0 = (0, \\emptyset, \\emptyset, \\emptyset, \\emptyset, \\emptyset, \\emptyset)$, the objective is to find an optimal policy $\\pi^\\star$ that minimizes the\nexpected sum of delay. This coincides with minimizing the expected marginal costs over all decision points\nwhen starting in $S_0$ and applying policy $\\pi$ throughout the process:\n$\\\\\\min_{\\pi \\in \\Pi} \\mathbb{E} \\Big[ \\sum_{k=0}^K D^\\Delta(S_k, \\pi(S_k))\\,\\Big|\\, S_0 \\Big]. $  (5)"}, {"title": "4 Solution Method", "content": "In this section, we present our solution method. We first give a motivation and an overview in Section 4.1 before\ndefining the two main components, search (Section 4.2) and evaluation (Section 4.3), in detail."}, {"title": "4.1 Motivation and Overview", "content": "The problem at hand requires fast and effective decisions. The small example in Figure 3.2 already illustrates the\ncomplexity of finding a feasible and effective decision for cook and vehicle schedules. Even for this small example, the\nnumber of potential decisions is already vast. Also, it is not clear which of the two decisions shown in the example is\nmore effective as it depends on future orders and decisions. The first one avoids delay now, but binds more vehicle\nresources while the second causes a slight delay now, but saves vehicle resources. The first might be advantageous if the\nexpected number of future orders is small while the latter becomes more effective in case many orders can be expected\nin the future. Hence, the evaluation of a decision should anticipate potential future delay when a specific decision is\ntaken. The two challenges of a thorough search of the decision space and an anticipatory evaluation of decisions are\ncaptured in the Bellman Equation:$\\\\pi^\\star(S_k) \\in \\arg \\min_{x \\in X(S_k)} D^\\Delta(S_k, x) + V(S_k').$    (6)\nThe Bellman Equation defines an optimal decision $\\pi^\\star(S_k)$ from the set of overall decisions $X (S_k)$ in a state $S_k$ based\non the (known) immediate cost $D^\\Delta(S_k, x)$ and the expected cost-to-go when taking a decision $x$. The cost-to-go is\nmodeled via the value function $V$ mapping post-decision states $S'$ to the expected future cost $V(S')$:\n\n$V(S) = \\mathbb{E} \\Big[ \\sum_{k'=k+1}^K D^\\Delta(S_{k'}, \\pi^\\star(S_{k'})) \\,\\Big|\\, S \\Big]. $  (7)\nThus, finding an effective policy poses two main challenges. First, a comprehensive, but runtime-efficient search of the\ncomplex combinatorial decision space is required, indicated by $\\arg \\min_{x \\in X(S_k)}$ in the Bellman Equation. Second, the\ndecisions need to be evaluated instantly with respect to their immediate and future impact, with the latter represented\nby the (unknown) value function $V(S')$ in the Bellman Equation. We address these challenges by combining a large\nneighborhood search (LNS) of the decision space driven by analytical insights with a value function approximation\n(VFA) tuned via transfer learning.\nSpecifically, we propose an LNS to search the decision space. Since the decision space is vast, a large number of\nLNS-iterations are required to search it thoroughly. However, many decision candidates turn out infeasible in the end\ndue to the capacity or freshness constraints and need to be discarded. To allow a fast but thorough search and quickly\nidentify infeasible decision candidates, we base our LNS on a condensed representation of a decision, i.e., one that\nreduces the decision space without loss of optimality. Within the LNS we search on condensed partial decisions, i.e.,\nwhere the planned sequence of orders at the cooks and trips of vehicles is determined but their exact timing is not. To\ndetermine feasibility and timing of the corresponding (partial) sequencing decision, we propose a polynomial algorithm,\nbased on a dynamic programming formulation and a set of analytical propositions.\nTo evaluate a feasible decision candidate, we propose a VFA. The VFA approximates values $V(S')$ via repeated\nsimulations. Once the values are learned, decisions can be evaluated instantly. For the VFA, a post-decision state"}, {"title": "4.2 The Large Neighborhood Search", "content": "In this section we describe our method to search the decision space whenever a new order arrives in the system and\na decision needs to be made. We follow the steps proposed in Figure 1. We first introduce the condensed decision\nrepresentation and, building on it, the notion of a partial decision. We describe the LNS-operators for the partial decision\nspace. We then present the PDFT-algorithm to check feasibility and create the full decision."}, {"title": "4.2.1 A Condensed Representation of a Decision and a Partial Decision.", "content": "We start with a formal definition of a condensed decision representation. To that end, we denote by $I_{kf} = \\{i \\in I_k \\mid\nf_i = f\\}$ the set of open orders of food type $f \\in \\mathcal{F}$. Recall that $x_k$ includes assignments of orders to specific cooks and\nassignments of trips to specific vehicles. The idea of a condensed decision is to combine together all orders that have\nthe same food type (all trips) instead of assigning each order to a specific cook of the respective food type (specific\nvehicle).\n\nDefinition 4.1 (A condensed decision representation) A condensed decision representation of $x_k$ includes the follow-\ning components. For each food type $f \\in \\mathcal{F}$, a sequence of processing all orders in $I_{kf}$ is given by $\\psi_{k}^f = (i_{f1}, i_{f2}, ... )$.\nThe set of all preparation sequences (for all food types) is given by $\\Psi_{k}^x = \\{\\psi_{k}^f \\mid f \\in \\mathcal{F}\\}$. The sequence of trips to\ndispatch by all vehicles in $\\mathcal{V}$ is given by a single vector $\\Theta_k^x = (\\theta_1, \\theta_2, ...)$. The associated times $\\textbf{t}_k^{s,x}$ and $\\textbf{t}_k^{d,x}$ to start\neach order and depart each trip, respectively, remain as in the original decision representation (Section 3.3).\nThat is, $\\Psi_{k}^x$ replaces $\\Psi_{k}$ in the original decision representation by storing the sequences of processing all orders by\nfood types instead of by specific cooks. Similarly, $\\Theta_k^x$ replaces $\\Theta_k$ in the original decision representation by storing a"}, {"title": "Definition 4.2 (Symmetric decisions)", "content": "Given a state $S_k$, two decisions $x$ and $x'$ are symmetric if they include the same\nset of trips as well as the same sets of starting times $\\textbf{t}_k^{s,x}$ and $\\textbf{t}_k^{d,x}$ for orders and trips.\nTwo symmetric decisions can only differ in the specific cook and vehicle assignments.\nClaim 4.1 (Condensed representation of symmetric decisions) Given a state $S_k$, decisions are represented by the\nsame condensed decision representation if and only if they are symmetric decisions.\nProof: Proof of Claim 4.1. Immediately derived from Definitions 4.1 and 4.2.\nClaim 4.2 (Symmetric decision costs) Given a state $S_k$, the resulting post-decision states of symmetric decisions\nhave the same immediate cost and the same cost-to-go.\nProof: Proof of Claim 4.2. In each pair of symmetric decisions the starting preparation and departure times of all\norders and trips, respectively, are identical and hence the arrival time of each order $i \\in I_k$ to the customer is identical,\ni.e., the total delay is the same (the immediate cost). For the same reason, at each point of time $t > t_k$, the number of\navailable cooks of each food type and the number of available vehicles is the same in both post-decision states. As\ncooks and vehicles are homogeneous and their indexes are therefore interchangeable, the cost-to-go is also identical.\n\nTheorem 4.1 Given a state $S_k$, an optimal decision can be found by searching over all (feasible) condensed decision\nrepresentations rather than over all original decision representations.\nProof: Proof of Theorem 4.1. Every original decision representation has a corresponding condensed decision\nrepresentation, and every feasible condensed decision is associated with a non empty set of (feasible) original decision\nrepresentations. Thus, all original decision representations are included in the search, and only feasible original decision\nrepresentations are considered. Moreover, all original representations that are associated with the same condensed\nrepresentation are symmetric and have an equal immediate cost and cost to go (Claims 4.1 and 4.2).\nConsequently, in our search heuristic we use the condensed decision representation to reduce the decision space.\nTowards a further reduction of the decision space, we next present the notion of a partial decision, which reduces the\ndecision space we have to explore at any given state."}, {"title": "Definition 4.3 (A partial decision)", "content": "A partial decision includes only the sequences parts of a condensed decision, i.e.,\nthe sets of preparation and trip sequences, $\\Psi_k^x$ and $\\Theta_k^x$, respectively.\nFor the example in Figure 3.2, this would leave the food type sequences (1,3,5) and (2,4) for the German and US\nfood types, respectively, without the preparation starting times. It would also contain the condensed vehicle sequence\n((1, 2), (4), (3), (5)), but without the departure times."}, {"title": "4.2.2 The LNS-Procedure.", "content": "We now define our LNS-procedure operating on partial decisions. We start by generating an initial decision using\na first-in-first-out (FIFO) procedure (Algorithm 1 in Appendix A.2). Then, we generate new partial decisions using\noperators that alter task sequences in $\\Psi_k^x$ and $\\Theta_k^x$, as described below. The feasibility of each partial decision is checked\nusing a polynomial algorithm, the PDFT (Appendix A.4). If a partial decision is feasible, this algorithm also assigns\ntasks to cooks and vehicles as well as task starting times. A pseudo code of the LNS is given by Algorithm 2 in\nAppendix A.2.\nThe FIFO procedure generates the initial decision by appending the new order $i_k$ to the planned schedule\n$(\\Psi_k, \\textbf{t}_k^s, \\Theta_k, \\textbf{t}_k^d)$ (as defined by the state variables of $S_k$), i.e., by assigning $i_k$ to a cook and a vehicle trip. It starts by\nassigning order $i_k$ to the first available cook $c \\in \\mathcal{C}_{f_{i_k}}$, initially at the earliest time $t > t_k$ in which $c$ is first available\nafter the last scheduled order in $\\Psi_{kc}$ is prepared (according to the plan in $I_k$ and $\\textbf{t}_k^s$). Then, it searches for all vehicles\n$v \\in \\mathcal{V}$ that have less than $\\kappa$ orders assigned on their last scheduled trips according to $\\Theta_{kv}$ and their departure time is\nno earlier than $t + t_{i_k}^p$, the time order $i_k$ can be ready. The selected trip is the one that can get $i_k$ to the customer with\nminimum tardiness. We note that if order $i_k$ joins a tour with other orders, the trip is determined to minimize the total\ntardiness over the orders included in it (and $i_k$) such that it is feasible. If there is no existing scheduled trip the new\norder can join, then, it is assigned on a new trip that will depart as soon as both the order finishes preparation and there\nis an available vehicle. If the earliest time, a vehicle can reach $i_k$ extends its freshness constraint, then, the time of\npreparation by cook $c$, $t$, is postponed such that the order will arrive fresh. The described procedure to insert order $i_k$ to\nthe planned schedules $(\\Psi_k, \\textbf{t}_k^s, \\Theta_k, \\textbf{t}_k^d)$, without additional search steps, is used in Section 5.3 as a first benchmark, that\nwe refer to as FIFO. This heuristic represents what is often done in practice. A pseudo code of the FIFO benchmark is\ngiven by Algorithm 1 in Appendix A.2.\nBased on the initial decision (or current decision), new decisions are generated to search the decision space, as follows.\nLet $\\psi_k^{x'} = (i_{f1}, i_{f2}, ...), \\forall f \\in \\mathcal{F}$ and $\\Theta_k^{x'}$ be the partial decision of the current decision, referred to as the current\npartial decision. We generate the next decision by using one of seven operators to alter one of the sequences in\n$\\psi_{k}^{x'f},\\forall f \\in \\mathcal{F}$ or $\\Theta_k^{x'}$ such that we obtain a new partial decision, represented by new sequences: $\\Psi_{k'}^{x''}, \\forall f \\in \\mathcal{F}$ and\n$\\Theta_k^{x'y}$ (where $\\Psi_{k'}^{x'''} = \\{\\psi_{fx''},\\forall f \\in \\mathcal{F}\\}$). The operators are randomly selected with equal probabilities. The operators\nwere chosen according to our understanding of the problem domain, based on analytical properties as well as random\nprocedures that assure that a large portion of the decision space can be covered. The individual operators are described\nin detail in Appendix A.3. Generally, Operators 1 and 2 make changes in the order preparation sequences; Operators 3\nand 4 change the trips sequence; and Operators 5-7 change the vehicle trips.\nAfter an operator is applied, we check if the new partial decision is feasible using the PDFT, which we describe in\nthe next section. If not, we discard it. Else (if it is feasible), the PDFT also derives timing sets $\\textbf{t}_k^{s,\\star}$ and $\\textbf{t}_k^{d,\\star}$. If the\ndecision has a lower (cost) value than the current one (see Section 4.3), it becomes the new current partial decision from\nwhich the search continues."}, {"title": "4.2.3 The PDFT.", "content": "We next summarize our PDFT-algorithm (for all details, we refer to Appendix A.4). The input of the PDFT is a state $S_k$\nand a partial decision, $\\Psi_k^{x'},\\forall f \\in \\mathcal{F}$ and $\\Theta_k^{x'}$. Its output is whether the partial decision is feasible or not, and, if yes,\nthe starting times of order preparations and trip departure times. To describe the PDFT we first sketch the problem\nit is aimed to solved, referred as the Assignment and Timing Sub-Problem (ATP): Given a state $S_k$ in the RMD-GK\nproblem and a partial decision, i.e., set of sequences of orders to prepare for each food type and a sequence of trips to\ndispatch, $\\psi_k^{x'},\\forall f \\in \\mathcal{F}$ and $\\Theta_k^{x'}$, respectively; the goal of the ATP is to assign the orders (trips) to the cooks (vehicles)\nand determine feasible task starting times such that the orders and trips are processed according to the given sequences\nand the total delay of the open orders in $I_k$ (given by $S_k$) is minimized. In Appendix A.4 we present a dynamic\nprogramming (DP) formulation of the ATP. We further present a set of analytical propositions that narrow down the\nstate and decision space of the ATP without loss of optimality. We also present properties of the optimal solution to the\nDP formulation, which form the basis to the PDFT-algorithm."}, {"title": "4.3 Decision Evaluation", "content": "Ideally, we would like to evaluate each feasible decision $\\textbf{t}_k^{d,x}$ in the LNS exactly, i.e., with respect to the sum of its\nimmediate cost $D^\\Delta(S_k, x)$ and the expected cost-to-go of the post-decision state, $V(S')$. While the immediate cost\ncan be computed directly as defined in Equation 3, the value function is unknown and may only be approximated. As\ndecisions are evaluated not only in every state but also in every iteration of the LNS, it is crucial that the approximation\nof the value function is computationally fast. For that reason, we use a VFA given by a neural network $V_\\omega$, using a set of\nfeatures associated with the post-decision state. These features are based on aggregated values of the post-decision state.\nIn our case, the aggregated post-decision states are defined by summary statistics reflecting our available resources,\ni.e., the current status of cooks and vehicles (see Appendix A.5). The aggregation of the post-decision state is required\nfor two reasons. First, the dimension of the post-decision state can be vast and, therefore, impede the approximation\naccuracy of the VFA, a phenomenon known as curse of dimensionality. Second, we later aim to employ the same neural\nnetwork for instances of different numbers of cooks and vehicles, a practice that is called transfer learning, which\nrequires the dimension of the network's input to remain fixed. Thus, aggregation of post-decision states of different\nsizes to the same features is required (In Appendix A.7, we show the value of transfer learning).\nThe mapping of aggregated post-decision states to their estimated cost-to-go is defined by the neural network's weights\\"}]}