{"title": "Adaptive Active Inference Agents for Heterogeneous and Lifelong Federated Learning", "authors": ["Anastasiya Danilenka", "Alireza Furutanpey", "Victor Casamayor Pujol", "Boris Sedlak", "Anna Lackinger", "Maria Ganzha", "Marcin Paprzycki", "Schahram Dustdar"], "abstract": "Handling heterogeneity and unpredictability are two core problems in pervasive computing. The challenge is to seamlessly integrate devices with varying computational resources in a dynamic environment to form a cohesive system that can fulfill the needs of all participants. Existing work on systems that adapt to changing requirements typically focuses on optimizing individual variables or low-level Service Level Objectives (SLOs), such as constraining the usage of specific resources. While low-level control mechanisms permit fine-grained control over a system, they introduce considerable complexity, particularly in dynamic environments. To this end, we propose drawing from Active Inference (AIF), a neuroscientific framework for designing adaptive agents. Specifically, we introduce a conceptual agent for heterogeneous pervasive systems that permits setting global systems constraints as high-level SLOs. Instead of manually setting low-level SLOs, the system finds an equilibrium that can adapt to environmental changes. We demonstrate the viability of AIF agents with an extensive experiment design, using heterogeneous and lifelong federated learning as an application scenario. We conduct our experiments on a physical testbed of devices with different resource types and vendor specifications. The results provide convincing evidence that an AIF agent can adapt a system to environmental changes. In particular, the AIF agent can balance competing SLOs in resource heterogeneous environments to ensure up to 98% fulfillment rate.", "sections": [{"title": "I. INTRODUCTION", "content": "The Distributed Computing Continuum is an emerging paradigm for systems that can seamlessly integrate multiple layers of computing infrastructure [1]. Computing continuum systems promise to enable infrastructure-critical pervasive applications with stringent requirements, such as Mobile Augmented Reality (MAR) for cognitive applications [2] and Remote Sensing for Disaster Management [3]. There are three recurrent characteristics among pervasive applications deployed on a continuum. First is their reliance on AI-based methods for tasks that classical control structures cannot solve efficiently or with sufficient precision [4]. For example, MAR applications must process streams of high-dimensional data that a service could ideally process at the source to fulfill a sub-10 millisecond latency Service Level Objective (SLO). The caveat is that resources in proximity are constrained. Typical solutions involve task partitioning and lightweight data reduction methods that minimize the penalty for offloading to remote resources [5]. The second is heterogeneity, i.e., resource-asymmetry, vendor specifications, and usage patterns. Although pervasive applications follow an overall common objective, a system must consider the individual properties and objectives of participants. The third is the continuously drifting problem domain intrinsic to the dynamic environments of pervasive applications, such that the source distribution drifts over time and data volume is non-static. Conclusively, a necessary precondition is a system that can adapt to non-identically and independently distributed (non-IID) data. Moreover, the system must facilitate collaboration between heterogeneous devices to fulfill their SLOs by distributing workload fairly and considering the individual properties of participants. The focus is on lifelong heterogeneous federated learning (FL) as we find it best encapsulates the primary challenges of pervasive applications that share the described characteristics. In general, FL participants collaborate for a common objective, i.e., to maximize the prediction performance. Yet, each participant has a private local validation set to determine whether their criteria are locally met. Time constraints that ensure smooth operations and resource asymmetry further instigate friction when attempting to satisfy local objectives. Hence, despite a common objective, to fulfill the SLOs of each participant individually, a delicate balance is necessary. Lastly, the dynamic environment gradually drifts the distribution and varies the data volume.\nThis work aims to demonstrate the viability of Active Inference (AIF) in designing adaptive agents that can gracefully handle the challenging requirements of pervasive applications. While Active Inference is a neuroscientific framework, recent work has shown promising results by conceiving methods from the underlying ideas for workload scheduling in distributed systems. In particular, we find that the objectives of Active Inference and pervasive computing intrinsically intertwine. Context awareness is crucial for pervasive applications as these systems operate in dynamic environments and must adapt to changes in their surroundings. Precisely context awareness is a defining characteristic of AIF agents. However, the current application of AIF for systems is more conceptual and only partially implements the core components of the AIF framework [6], [7]. Other work on systems that adapt to changing requirements typically focuses on optimizing individual variables, such as learning rate or setting low-level SLOs as constraints on specific resources [8], [9]. Despite providing more fine-grained control, it is unreasonable to expect application developers to understand the implications of each low-level constraint to the overall system, particularly in dynamic environments where resources are scarce and availability is less predictable. In contrast, our AIF agent permits setting high-level SLO targets to find an equilibrium without attempting to enforce constraints from possibly conflicting low-level SLOS.\nWe design experiments that accurately reflect the relevant real-world conditions by implementing a physical testbed consisting of heterogeneous devices with varying resource types and computational capabilities. Additionally, we leverage a controlled process for data generation to evaluate the adaptability to a dynamic environment precisely. We extensively evaluate our agents with a strong emphasis on reproducibility. The results underpin the claim that an AIF agent can successfully balance competing SLOs among clients despite considerable resource asymmetry and adapt to the dynamic environment. Still, we transparently discuss current limitations by accentuating the parts of our result that best show our agent's weaknesses. The intention is to foster research interest in AIF from a systems perspective, as we sincerely believe that it poses an exceptionally promising research direction for pervasive applications and the compute continuum. Naturally, we open-source our repository as an addition to the community to reproduce, scrutinize, and extend our approach 1.\nWe summarize our contributions as:\n\u2022 An adaptive mechanism for heterogeneous lifelong FL based on AIF which allows handling non-IID data distributions and heterogeneous device characteristics inherent in pervasive computing environments.\n\u2022 A conceptual AIF agent that balances multiple SLOs during model training. When SLOs compete, agents can autonomously infer optimal training configurations without manual intervention.\n\u2022 The empirical evaluation of AIF agents for pervasive FL tasks; experiments were designed to reflect real-world conditions, such as data and resource heterogeneity"}, {"title": "II. BACKGROUND", "content": "A. Lifelong Heterogeneous Federated Learning\nIn Federated Learning, participants train a global model to maximize prediction performance without disclosing private data. Participants optimize and validate the model parameters with their local dataset in a training round before aggregating their weights globally.\n1) Heterogeneous Federated Learning: We refer to Federated Learning as heterogeneous when data is non-IID and hardware specifications vary among participants. Moreover, hardware heterogeneity typically implies that resources are constrained, i.e., to not discriminate against computationally less powerful devices closer to the source.\n2) Lifelong Federated Learning: FL is lifelong when training continuously adapts to concept drifts [10]. Introducing concept drifts is an intrinsic property of the dynamic deployment environment of pervasive applications. Yet, there is limited research interest in lifelong learning for FL [11].\n3) Service Level Objectives for Federated Learning: SLOs are definable constraints on a system that operators may use as contracts with application developers [12], [13]. Low-level SLOs quantify directly observable measures, such as CPU or memory usage. High-level SLOs abstract low-level SLOs to reduce the difficulty of diagnosing and configuring complex and wide-spanning systems, i.e., compute continuums with measures such as throughput or monetary costs.\nFor our purposes, high-level SLOs provide an intuitive interface to set targets for an AIF agent and quantitative measures to determine its adaptability to a dynamic environment. In particular, maintaining prediction performance and minimizing round duration are two primary objectives for lifelong heterogeneous federated learning. An SLO on prediction performance ensures consistent solution quality. In contrast, an SLO on timeliness is crucial as resources are constrained, and a considerably slower client can delay global weight updates.\nB. Active Inference\nActive inference is a neuroscientific framework based on the free energy principle (FEP) [14]. AIF agents adjust their"}, {"title": "III. PROBLEM STATEMENT", "content": "We consider a lifelong heterogeneous FL system consisting of an orchestrator with N participants."}, {"title": "IV. PROPOSED METHOD", "content": "This section presents the design of the AIF agents that optimize a heterogeneous and lifelong federated system to fulfill SLOs. Algorithm 1 summarizes the overall procedure for client-side training. The following elaborates on notable details about the process for an agent to find and choose optimal FL training configurations in a dynamic environment.\nA. Learning a Simple Causal World Model\nThe generative model is at the core of an AIF agent, i.e., as an agent interacts with its environment, it updates its internal world representation in a perception-action cycle. We choose Bayesian Networks (BNs) as they provide interpretable graphical representations of learned causal structures. This work considers discrete BNs with uniform priors. Each agent's initial Bayesian network structure is unknown, as there are no assumptions on prior knowledge of the environmental dynamic. The agents require only starting knowledge of the BN variables and their respective cardinalities. We define the BN B of an agent as:\n$B = (G,P)$"}, {"title": "V. EVALUATION", "content": "The experiment design examines the AIF agent's behavior and adaptability to heterogeneity and lifelong FL.\n1) Test Bed: We implement a physical testbed with constrained devices to replicate a heterogeneous resource environment. Additionally, we use a virtual machine with server-grade hardware for experiments in more controlled environments.\n2) Implementation Details: We implement the prediction model as a simple Artificial Neural Network (ANN) with PyTorch consisting of two fully connected layers using ReLU activation for non-linearity.\nWe extend the Flower [19] framework to support FL. We implement the agent BNs with pgmpy [20] and information gain with pymdp [18]. We implement a controllable data generation process using River [21]. A more detailed technical description is out of scope and we refer interested readers to the accompanying repository.\n3) Application Scenario: We emulate a dynamic environment by controlling the data generation process to introduce concept and volume drifts. Each client device represents a different participant. The challenge is, for the system to adapt to the drifts or to the varying computational resources of participants. The experiments consider the fulfillment of two high-level SLOs:\n1) Time: fulfilled if a local training round does not exceed a set limit (e.g., 2 seconds).\n2) Prediction Performance: fulfilled if the primary validation metric (accuracy) exceeds a set value.\nWe choose time and performance as SLOs as balancing them is non-trivial. For example, focusing exclusively on fulfilling prediction performance may require spending an excessive amount of time and vice versa. The configurable hyperparameters are Batch Size $BS \\in \\{8,32, 64, 256, 512\\}$ and Learning Rate $LR \\in \\{0.0005, 0.001,0.005, 0.01\\}$, as there is a clear connection to them and the system's training objective and considered drift types, e.g. learning rate tuning was proposed to battle concept drift [11]. Each client initialized a separate datastream locally, using their identifier as a random seed for the stream to promote variability in the data across clients. However, the rest of the data stream parameters were set to the same values across clients inside one run. This way, the number of features and classes are kept the same, showcasing that all clients are part of the same ML task. Other parameters, such as the number of clusters (groups of data points represented by centroids), the random seed for cluster initialization, and the cluster drift, are kept constant to ensure a proper comparison of the agents'/clients' behavior and to maintain the reproducibility of the generated data inside one repetition. The data generator G is also parametrized by a drift parameter, drift, which controls the presence and speed of data drifts, where $drift = 0$ indicates no data drift.\nIn each federated round, clients train and validate their prediction model using the data samples available in an online learning fashion. At round t, each client n possesses two datasets: $Validation = \\{(x_b, y_b)\\}_{b=1}^{B_t} \\sim G_n$ and $Traint = Validation_{t-1}$, where x is a feature vector, y label assigned to the data sample and Bt the size of the data set drawn from the data generator at round t.\nThis way, clients acquire a new batch of data for validation while the previous batch is re-used for training. Previous round training samples are discarded.\n4) Baselines: The baselines focus on the best- and worst-case scenarios rather than existing methods to avoid misleading comparisons with the tangentially related problem definitions and methods and concentrate on depicting the dynamics and capabilities of AIF agents. We define two baselines for experiments with data distribution drifts:\n1) Random: Represents a complete lack of adaptability and intelligent choice of hyperparameters. This baseline randomly chooses a new configuration for each federated training round.\n2) Fixed optimal: Represents the case where parameter tuning was performed and the optimal configuration is set once at the beginning of the training and is never changed. To select this configuration, each of the possible configurations was tested and the one with the highest mean SLOs fulfillment at the end of the observed period (around round 50) was taken as the optimal."}, {"title": "VI. RELATED WORK", "content": "We identified three topics within related work: SLO fulfillment through dynamic adaptations in distributed computing systems, applications of the AIF framework, and optimization techniques in FL.\nA. Optimization in Federated Learning\nOptimizing FL workflows is important for minimizing the time-to-accuracy of model training [23]. In that context, Kundroo et al. [9] proposed FedHPO, a federated optimization algorithm that accelerates each client's training by modifying its hyperparameters, such as learning rate or epochs.\nFurthermore, several studies have focused on multi-objective optimization in FL. One possible approach is optimizing neural network models instead of client-specific hyper-parameter optimization [24], [25]. Additionally, a significant number of existing research focuses on optimizing client selection or clustering instead of adjusting the parameters of individual clients to reach multi-dimensional goals [26]\u2013[28].\nTherefore, existing work on optimization in FL does not consider changing environments and lifelong FL scenarios or lacks individual clients' hyperparameter tuning in general, which is crucial for pervasive applications.\nB. Dynamic Adaptation for SLO Fulfillment\nThere exist multiple approaches that aim to combine SLOs with dynamic processing requirements: Zhang et al. [29] presented Octopus the framework that finds optimal services configurations in multi-tenant edge computing scenarios. Octopus predicts SLO fulfillment of two variables based on a deep neural network. Shubha et al. [8] presented AdaInf, which detects SLO violations of a GPU scheduling task whenever variable drifts occur. Through AdaInf, it is possible to find SLO-fulfilling resource allocations between model training and inference."}, {"title": "VII. CONCLUSION", "content": "This work presented AIF agents that are able to adaptively change their behavior in response to dynamic environments. We evaluated the proposed AIF agents in lifelong heterogeneous FL, utilizing a set of both dynamic data and diverse devices. We showed that AIF agents are able to fulfill competing SLOs and unfolded the behaviors of agents and intricate connections between the defined SLOs and strategies for fulfilling them.\nFuture work can further expand the usage of the active inference framework to orchestrate distributed learning systems, for instance, by fulfilling system-level SLOs, such as fairness of participation or global model performance. Enhancements of the current method can improve the ability of the agents to find causal dependencies in limited data, making them more robust, targeting the limitations of the discrete BN, introducing temporal dependencies to capture the environmental dynamics more precisely, and providing more nuanced SLOs specifications to enable tracking SLOs in a range."}]}