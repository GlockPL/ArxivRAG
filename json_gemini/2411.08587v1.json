{"title": "DeepUQ: Assessing the Aleatoric Uncertainties from two Deep Learning Methods", "authors": ["Rebecca Nevin", "Aleksandra \u0106iprijanovi\u0107", "Brian D. Nord"], "abstract": "Assessing the quality of aleatoric uncertainty estimates from uncertainty quantification (UQ) deep learning methods is important in scientific contexts, where uncertainty is physically meaningful and important to characterize and interpret exactly. We systematically compare aleatoric uncertainty measured by two UQ techniques, Deep Ensembles (DE) and Deep Evidential Regression (DER). Our method focuses on both zero-dimensional (0D) and two-dimensional (2D) data, to explore how the UQ methods function for different data dimensionalities. We investigate uncertainty injected on the input and output variables and include a method to propagate uncertainty in the case of input uncertainty so that we can compare the predicted aleatoric uncertainty to the known values. We experiment with three levels of noise. The aleatoric uncertainty predicted across all models and experiments scales with the injected noise level. However, the predicted uncertainty is miscalibrated to std(al) with the true uncertainty for half of the DE experiments and almost all of the DER experiments. The predicted uncertainty is the least accurate for both UQ methods for the 2D input uncertainty experiment and the high-noise level. While these results do not apply to more complex data, they highlight that further research on post-facto calibration for these methods would be beneficial, particularly for high-noise and high-dimensional settings.", "sections": [{"title": "1 Introduction", "content": "Physically and statistically interpretable uncertainties are critical for applications in science and industry. Uncertainty quantification (UQ) in deep neural networks has gained significant attention, with recent work exploring taxonomies of uncertainties, including domain, epistemic, and aleatoric uncertainties, e.g., [4, 5, 10]. Aleatoric uncertainty, oal, is significant because, unlike epistemic uncertainty, it is not a result of model limitations but rather an inherent property of the data. In many cases, aleatoric uncertainty is exactly known because it is produced by a well-understood physical process, allowing us to anticipate not only its expected amplitude but also its distributional characteristics. For instance, in astrophysics, the Poisson distribution\u00b9 characterizes 'shot' or photon noise, while the Normal distribution characterizes read and other forms of thermal or electronic noise. Developing a coherent framework for benchmarking aleatoric uncertainty estimates from deep"}, {"title": "2 Deep Learning Methods for Predicting Uncertainty", "content": "Deep Ensemble: Ensembling mean-variance estimation networks (MVEs) produces a set of predicted mean and variance values 'Deep Ensembles' [DE; 14]. We build upon the DE framework from [14] incorporating several modifications inspired by previous work, including a softplus activation for the 62 output neuron to enforce a positive output value and a \u1e9e modification to the loss function, as introduced in [22]. The modified loss function we use is:\n$L_{\\beta-NLL} = \\frac{1}{N} \\sum_{i=1}^{N} [\\frac{\\beta}{2} \\log \\sigma^{2}(x_{i}) + \\frac{(y_{i} - \\mu(x_{i}))^{2}}{2\\sigma^{2}(x_{i})} + c]$. The B-modified loss function helps ensure convergence of the network predictions, avoiding a commonly observed problem in MVEs, where the variance artificially enlarges resulting in a poor estimate of the mean. We use a \u1e9e value of 0.5, which is recommended by [22], and described in more depth in Appendix D. The aleatoric uncertainty is the mean of the predicted standard deviations for the ensemble of K = 10 models: $\\sigma_{al} = \\sqrt{\\frac{1}{K} \\sum_{k=1}^{K} \\sigma_{k}^{2}}$, where $\u03c3_{k}^{2}$ is the variance predicted by the k-th network.\nDeep Evidential Regression: Deep Evidential Regression (DER) estimates aleatoric uncertainties via evidential distributions that are directly incorporated into the loss function [1]. Instead of requiring an ensemble of networks, it places evidential priors over a Gaussian likelihood function, and the network is trained to learn the hyperparameters of the evidential distribution.\nWe use the normal-inverse-gamma (NIG) loss from [16], which includes an additional term weighted by the width of the t-distribution. This formulation improves the efficiency and accuracy of training:"}, {"title": "Experimental Design", "content": "Experimental Design: Figure 1 illustrates the experimental setup for an example of high-noise data.\nThe OD data are from a simple linear regression model: y = mx. The values of x are linearly spaced between 0 and 10. The data are designed so that the y distribution is uniform, U[0, 2]. The training/validation/test set size is 90k/10k/10k. To create data for the output uncertainty experiments, we inject noise directly on the prediction or label, such that Ynoisy = y + N(0,02). The models are trained on (x, Ynoisy) pairs. In the input uncertainty experiments, we inject noise via the input variable xnoisy = x + N(0, 2) and the models are trained on (xnoisy, y) pairs.\nFor the 2D data, we use the software package DeepBench ([28] in prep) to generate 32 \u00d7 32-pixel galaxy images by varying the S\u00e9rsic radius, amplitude, and position angle within ranges [0, 0.01], [1,10], and [-1.5, 1.5], respectively. We are motivated by real-world uncertainty examples in astronomical imaging to generate a 2D dataset in addition to the OD tabular dataset. The output variable y is the sum of the pixel values. The dataset is designed to be uniform in y over a range [0, 2] for a training/validation/test set size of 4500/500/500. For the output uncertainty experiments, we inject a random normal distribution with mean zero and standard deviation \u03c3y directly on y. For the input uncertainty experiments, we inject a random normal distribution with mean zero and standard deviation \u03c3\u03b5 on each pixel, which results in a normal distribution in \u03c3y after propagation. We use a random normal distribution because the DE and the DER methods assume that the output variable is distributed as a random normal distribution.\nWe distinguish between the predicted aleatoric uncertainty from the methods, \u03c3al, which is measured as an uncertainty on the output variable, and the true uncertainty on the output variable, \u03c3\u1fc3. The true uncertainty on the output variable is either directly known in the case of the output uncertainty experiments or is known through uncertainty propagation for the input uncertainty experiments. The true output uncertainty has low, medium, and high values: \u03c3y \u2208 [0.01, 0.05, 0.1]. These noise levels are chosen such that the high noise value datasets have an uncertainty level that is on average 10% of the output variable y. For input uncertainty, we inject noise \u03c3\u03b5 and calculate the expected \u03c3\u03c5 uncertainty value via standard rules of error propagation described in Appendix C. The relationship between \u03c3y and \u03c3\u03b5 for the OD data is \u03c3\u03c5 = |m|\u03c3\u03b1, where m is the slope of the line, and the relationship for the 2D data is \u03c3\u03b7 = 32\u03c3\u03b1.\nUQ Model Architectures: We use the DeepUQ package to define the model architecture and perform our experiments. We also present the DeepUQ-neurIPS-WS-2024 repository as an accompaniment to the paper, with notebook examples of how to reproduce the exact models, figures, and tables in this paper. Both UQ methods use the same fully connected layer network architecture, which is two hidden layers of 64 neurons each. The hidden layer neurons utilize a ReLu activation function. For the OD experiments, the networks use two input neurons (the m value and the x value for a single point), while the 2D experiments use the 32 \u00d7 32 pixel input. We use five convolutional layers for the"}, {"title": "3 Results", "content": "We run both UQ methods for all four experimental setups and all three noise levels and find that all models converge, with final mean-square error (MSE) values at epoch 99 ranging from 0.0001 to 0.01 (Appendix G). Furthermore, the DE and DER methods have comparable final MSE values for each noise level, and the NIG loss and 3-NLL loss values are similar for each UQ method across experiments for a fixed noise level. This indicates that the different methods of uncertainty injection and the different data dimensionalities are all equally adequately learning to predict the relationship between input and output values. To test desideratum (i), we display the distribution of predicted aleatoric uncertainties for the test set for the different noise levels in Figure 2. We use the standard deviation of the predicted uncertainty values, std(al), to assess desiderata (ii) and (iii): whether the predicted uncertainty value oal is consistent with the true value \u03c3y for all four experiments and all three noise levels."}, {"title": "4 Discussion", "content": "The predicted aleatoric uncertainty increases proportionately with the true injected uncertainty. The models are sensitive to the true uncertainty, which bolsters confidence in these UQ methods. It further confirms the findings of [8], where the automated Deep Ensemble method (AutoDEUQ) produces predicted aleatoric uncertainty that scales with uncertainty injected on the output variable. Additionally, [3] find that the predicted aleatoric uncertainty from DER models increases for OD and 2D experiments where uncertainty is increased on both the input and output variables.\nWhen we require that the predicted uncertainty falls within std(al) of the true uncertainty to be considered 'well calibrated', we find that only seven of the twelve DE experiments and two of the twelve of the DER experiments satisfy this requirement. Furthermore, for both methods, the degree of miscalibration depends on the experiment's dimensionality and the type of uncertainty injection. Desiderata (ii) and (iii) are therefore violated for both experiments.\nFor the DE method, the OD experiments are calibrated for the medium- and high-noise models (Figure 2, left). Both of the OD low-noise experiments slightly overestimate the uncertainty. Overall, the uncertainty estimates are the least calibrated for the most complex experimental setup (input, 2D; bottom row). For the DER method (Figure 2, right), the majority of experiments across all noise levels produce miscalibrated uncertainty estimates, over-estimating (low-noise) and under-estimating (medium- and high-noise) the predictive uncertainty. The exceptions are the OD output low-noise model and the 2D output medium-noise model, which are calibrated. For both methods, the most"}, {"title": "5 Conclusions and Outlook", "content": "We explore aleatoric uncertainties predicted by two deep learning UQ approaches \u2014 Deep Ensembles (DE) and Deep Evidential Regression (DER). We compare the aleatoric uncertainty predictions of these two methods to the true uncertainty for four different experiments and three noise levels. Both methods meet desideratum (i): the aleatoric uncertainties scale with the injected uncertainty.\nHowever, for our experiments, the methods both fail to meet desiderata (ii) and (iii), that the predicted aleatoric uncertainties be well-calibrated, i.e., consistent to std(al) with the true uncertainties, and that they meet this requirement across all experiments. Notably, most DER experiments underestimate the uncertainty for medium- and high-noise models and overestimate the uncertainty for low-noise models. The DE experiments deviate mostly for the more complex 2D input uncertainty experiments. The predicted uncertainties are the least accurate for both methods for the 2D, input uncertainty, and high-noise experiments. While these observations do not imply inherent deficiencies in DE and DER, they highlight that further research would be beneficial to assess whether these methods require post-facto calibration, particularly for high-noise and high-dimensional settings.\nSome limitations of our work are: Our conclusions apply only to our toy datasets. We do not demonstrate performance of these methods on real world datasets with higher complexity. Additionally, our conclusions apply only to homoskedastic noise generated from a Gaussian distribution; expanding this to non-Gaussian distributions and heteroskedastic noise is a direction for future work."}, {"title": "C Uncertainty propagation", "content": "Here we describe our process for propagating uncertainty injected on the input variable \u03c3\u03b5 onto uncertainty on the output variable \u03c3y. For a generic function y = f(x1,x2,...XN), where y is the dependent variable and x1, x2, and so on are the independent variables, the standard deviation of y, \u03c3y, can be written in terms of uncertainty on the x variables [13]:\n$\\sigma_{y} = \\sqrt{(\\frac{\\partial f}{\\partial x_{1}})^{2} \\sigma_{x_{1}}^{2} + (\\frac{\\partial f}{\\partial x_{2}})^{2} \\sigma_{x_{2}}^{2} + 2(\\frac{\\partial f}{\\partial x_{1}})(\\frac{\\partial f}{\\partial x_{2}}) \\sigma_{x_{1}x_{2}}^{2}}$,\nwhere the final covariance term (8x112) can be dropped when the correlation between uncertainty terms is negligible, as is the case for both of our data dimensionalities.\nFor the OD linear regression case, y = mx, the partial derivative only exists relative to x, which has associated uncertainty, so this equation reduces to:\n$\\sigma_{y} = |m|\\sigma_{x}$.\nFor the case of the 2D image noise injection, we inject a standard normal value for each pixel and calculate the predicted value y as a sum of all pixel values. The partial derivative terms are all equal to 1 because this is a summation. Since we inject the same value of o for all pixels, the formula then becomes:\n$\\sigma_{y} = \\sqrt{\\sum_{i=1}^{N} \\sigma_{x_{i}}^{2}} = 32 \\sigma_{x}$\nwhere i is the index of all (N) pixels, and the images are 32 \u00d7 32 pixels."}, {"title": "D Deep Ensembles", "content": "A common approach for quantifying aleatoric uncertainty in regression tasks with deep neural networks is to assume that the regression output y follows a distribution and to predict the parameters of this distribution. One standard technique is to assume that the errors are heteroskedastic\u00b2 and to model the distribution of y as a Gaussian parameterized by mean \u03bc and variance \u03c3\u00b2, where the predicted values yi ~ N(\u03bc(xi), \u03c3\u00b2(xi)). The model is trained using maximum likelihood estimation by minimizing the negative log likelihood loss under the training set distribution p(X, Y):\n$L_{NLL} = -log p(Y|X)$\n$ = \\frac{1}{N} \\sum_{i=0}^{N} [- \\frac{1}{2} log \\sigma^{2}(x_{i}) + \\frac{(y_{i} - \\mu(x_{i}))^{2}}{2\\sigma^{2}(x_{i})} +c]$,\nwhere \u03bc(xi) and o\u00b2(xi) are the model outputs for each training data point using the model with the optimal set of internal parameters. This technique is known as mean-variance estimation [MVE; 17, 12].\nWe use a modified loss function for training, known as the B-NLL loss. This loss is proposed by [23] as a means for avoiding a commonly observed problem in MVEs, where the variance artificially enlarges resulting in a poor estimate of the mean. The \u1e9e parameter helps ensure convergence of the network predictions for \u03bc(xi) and o\u00b2(xi):\n$L_{\\beta-NLL} = \\frac{1}{N} \\sum_{i=0}^{N} [\\frac{\\beta}{2} log \\sigma^{2}(x_{i}) + \\frac{(y_{i} - \\mu(x_{i}))^{2}}{2\\sigma^{2}(x_{i})} +c]$,"}, {"title": "E Deep Evidential Regression", "content": "Similar to MVE, we assume the training data are drawn from a Gaussian likelihood distribution Yi ~ \u039d(\u03bc(xi), \u03c3\u00b2(xi)). We also place a Gaussian prior on the mean \u00b5 and an Inverse-Gamma prior on the variance 02:\n$\\mu_{j} \\sim N(\\gamma_{j}, \\frac{\\sigma_{j}^{2}}{\\nu_{j}})$,$\n\\sigma_{j}^{2} \\sim \\Gamma^{-1} (\\alpha_{j}, \\beta_{j}),$\nwhere j is a sample drawn from these hyperprior distributions; \u0393(\u00b7) is the gamma function; and m = (\u03b3,\u03bd, \u03b1, \u03b2) are hyperparameters of these distributions, where \u03b3 \u2208 R, \u03bd > 0, \u03b1 > 1, and \u03b2 > 0.\nOne can then formulate the conjugate prior distribution as a Normal-Inverse-Gamma (NIG) distri-bution; for a full derivation, see [1]. Drawing a sample from the NIG distribution yields a single instance j of the likelihood function: the NIG hyperparameters m control the location and dispersion (uncertainty) of the likelihood function N(\u03bc;, \u03c33). We will later use the hyperparameters of this higher-order evidential distribution to define the aleatoric uncertainty; these higher-order parameters determine the lower-order likelihood distribution from which observations are drawn.\nTo fit the model, we define a marginal likelihood p(yi|m), which is done using Bayesian probability theory in [1]: the conjugate prior defined above is combined with the Gaussian likelihood and integrated over the parameters \u03bc and 02. An analytic solution to the marginal likelihood is the Student t-distribution:\n$L_{i,NIG} = St_{2\\alpha}(y_{i}|\\gamma, \\frac{\\beta(1 + \\nu)}{\\alpha \\nu})$,\nwhere St2a is a t-distribution with 2a degrees of freedom.\nThe negative log-likelihood loss of this distribution and the addition of an additional term weighted by the width of the t-distribution provides the LNIG loss that we use for training: LNIG = $\\sum_{i=1}^{N} [-\\log L_{NIG} + \\Phi \\frac{y_{i}-\\gamma}{wst} + \\Phi]$."}, {"title": "F Software package DeepUQ", "content": "DeepUQ is a software package that provides modules, utilities, and scripts for setting the hyperparam-eters and training both DE and DER models and analyzing the predicted aleatoric uncertainties. It is also designed to be tunable to insert additional UQ methods and/or to create additional noise profiles for uncertainty injection on the OD or 2D data.\nDeepUQ provides the following modules and scripts:\n\u2022\ndata.py - A module for generating data with accompanying controllable injected aleatoric uncertainty on either the input or output variables.\n\u2022\nmodel.py - A module that provides tunable loss functions, network architecture, and hyperparameters for the DE and DER methods.\n\u2022\ntrain.py - A module for the training procedure for both models.\n\u2022\nDeepEnsemble.py and DeepEvidentialRegression.py - Scripts for generating data, initializing the methods, and training the models."}]}