{"title": "LEARNING CHAOTIC SYSTEMS AND LONG-TERM PREDICTIONS WITH NEURAL JUMP ODES", "authors": ["Florian Krach", "Josef Teichmann"], "abstract": "The Path-dependent Neural Jump ODE (PD-NJ-ODE) is a model for online prediction of generic (possibly non-Markovian) stochastic processes with irregular (in time) and potentially incomplete (with respect to coordinates) observations. It is a model for which convergence to the $L^{2}$-optimal predictor, which is given by the conditional expectation, is established theoretically. Thereby, the training of the model is solely based on a dataset of realizations of the underlying stochastic process, without the need of knowledge of the law of the process. In the case where the underlying process is deterministic, the conditional expectation coincides with the process itself. Therefore, this framework can equivalently be used to learn the dynamics of ODE or PDE systems solely from realizations of the dynamical system with different initial conditions. We showcase the potential of our method by applying it to the chaotic system of a double pendulum. When training the standard PD-NJ-ODE method, we see that the prediction starts to diverge from the true path after about half of the evaluation time. In this work we enhance the model with two novel ideas, which independently of each other improve the performance of our modelling setup. The resulting dynamics match the true dynamics of the chaotic system very closely. The same enhancements can be used to provably enable the PD-NJ-ODE to learn long-term predictions for general stochastic datasets, where the standard model fails. This is verified in several experiments.", "sections": [{"title": "1 INTRODUCTION", "content": "The Path-dependent Neural Jump ODE (PD-NJ-ODE) (Krach et al., 2022) is a model for online prediction of generic (possibly non-Markovian) stochastic processes with irregular and potentially incomplete observations. It is the first model for which convergence to the $L^{2}$-optimal predictor, which is given by the conditional expectation, is established theoretically. Thereby, the training of the model is solely based on a dataset of realizations of the underlying stochastic process, without the need of knowledge of the law of the process. This result was further generalized in the follow-up work Andersson et al. (2024). In particular, let $\\left(X_{t}\right)_{t \\in[0, T]}$ be a stochastic process taking values in $\\mathbb{R}^{d}$, let $t_{i} \\in[0, T]$ be random observations times for $1 \\leq i \\leq n$, where $n$ can be a random variable describing the total number of observations (i.e., the number of observations can be different for each realization) and let $M_{i} \\in\\{0,1\\}^{d}$ be the corresponding random observation masks, telling which coordinates $X_{t_{i}, j}$ are observed (if $M_{t_{j}}=1$ ) at each observation time $t_{i}$. The $\\sigma$-algebra of the currently available information at any time $t \\in[0, T]$ is defined as \n\n$$\n\\mathcal{A}_{t}:=\boldsymbol{\\sigma}\\left(X_{t_{i}, j}, t_{i}, M_{t_{i}} \\mid t_{i} \\leq t, j \\in\\left\\{1 \\leq l \\leq d \\mid M_{t_{i}, l}=1\right\\}\right)\n$$\n\nwhere $\boldsymbol{\\sigma}(\\cdot)$ denotes the generated $\\sigma$-algebra. Then, Andersson et al. (2024, Theorem 4.3) states that the output $Y_{m, n_{m}}^{\theta_{m, n_{m}}^{\text {min }}}$ of the PD-NJ-ODE model (where $\theta$ are the trainable parameters of the model, $m$ is the size of the used neural networks and $N_{m}$ is the number of training paths, i.e., realizations of $X$ ) converges to the $L^{2}$-optimal prediction $\\hat{X}=\\left(\\mathbb{E}\\left[X_{t} \\mid \\mathcal{A}_{t}\right]\right)_{t \\in[0, T]}$ as $m$ tends to $\\infty$. This convergence holds under weak assumptions on $X$ and the observation framework $\\left(t_{i}, M_{i}, n\right)$, which basically require some integrability properties and continuous differentiability of $t \\mapsto \\hat{X}_{t}$. \n\nIn Krach et al. (2022); Andersson et al. (2024), the focus lies on optimal prediction of generic stochastic processes, as for example processes defined via an stochastic differential equation, given the currently available information. In particular, this means that the model never predicts further than until the next observation time, since then the available information changes. If the next observation time is deterministically (or with very high probability) smaller than $r$, then it is unlikely that the model learns to predict well for $t>r$, without getting the new information as input, when it becomes available at the next observation time. In this work, we focus on a provable training strategy, that makes such long-term predictions possible. \n\nThis is of particular importance in the case of a deterministic (given the initial condition) underlying process, as in (chaotic) ODE or PDE systems. Importantly, in this setting the conditional expectation coincides with the process itself. In particular, if $X_{0}$ is observed, i.e., if $X_{0}$ is $\\mathcal{A}_{t}$-measurable for any $t \\in[0, T]$, then $\\hat{X}_{t}=\\mathbb{E}\\left[X_{t} \\mid \\mathcal{A}_{t}\right]=X_{t}$. Therefore, Andersson et al. (2024, Theorem 4.3) implies that the PD-NJ-ODE framework can equivalently be used to learn the dynamics of ODE or PDE systems solely from realizations of the dynamical system with different initial conditions. This result was already stated in Krach et al. (2022, Appendix B.3) and was used in the experiments in Krach et al. (2022, Appendix C.3). Even though the theoretical results are promising, it can be seen in the empirical results of Krach et al. (2022, Appendix C.3) (and in Figure 1 left) that the PD-NJ-ODE has problems to predict a chaotic system well over longer time periods, when the prediction is only based on the initial value. In particular, the prediction starts to diverge from the true path after about half of the evaluation time. The problem is that during the training, the model never needs to predict so far ahead (since it gets intermediate observations as input). Hence, it also does not learn to do this well. In this work, we analyse the PD-NJ-ODE model from the perspective of learning long-term predictions of stochastic or deterministic (differential) systems and introduce two novel ideas, which enhance the training of the model significantly and independently of each other in this context."}, {"title": "1.1 RELATED WORK", "content": "This work is based on the sequence of papers introducing NJ-ODE (Herrera et al., 2021), extending it to a path-dependent setting with incomplete observations (Krach et al., 2022) and further to noisy observations with dependence between the observation framework and the underlying process (Andersson et al., 2024). The focus of this paper lies on long-term predictions (i.e., multiple observation times ahead), with a special emphasis on fully observed (chaotic) deterministic systems. The framework of (Krach et al., 2022) also allows for partially observed chaotic systems, which are not deterministic. Such cases resemble stochastic processes, where the optimal prediction, given by the conditional expectation, is learnt. Hence, they can be treated with the provided result for general stochastic processes. \n\nNavone \\& Ceccatto (1995) were one of the first to use neural networks to learn chaotic dynamics and several other works followed using RNNs, reservoir computing and neural ODEs (Vlachas et al., 2018; Pathak et al., 2018; Vlachas et al., 2020; Brenner et al., 2022; Chen et al., 2018; Raissi, 2018). Churchill \\& Xiu (2022) propose a memory-based residual deep neural network (DNN) architecture to learn chaotic systems from fully or partially observed data and apply it to the chaotic Lorenz 63 and 96 systems. Hess et al. (2023) use piece-wise linear RNNs together with teacher forcing to effectively learn chaotic dynamics and provide an extensive overview of related work and numerical comparison to many state-of-the-art models. Our approach, using neural ODEs, is particularly related to Chen et al. (2018) and Rubanova et al. (2019). However, in contrast to all these methods, our approach comes with theoretical learning guarantees even in the most general case of irregularly and incompletely observed path-dependent stochastic processes."}, {"title": "2 MAIN RESULTS", "content": "In the results of Krach et al. (2022, Appendix C.3) we see that the empirical performance of the PD-NJ-ODE applied to chaotic systems could be improved, especially for long prediction horizons, even though the theoretical results suggest that the model should learn to predict chaotic systems correctly at any time. This is related to the inductive bias when training the model with a finite amount of training samples (see Andersson et al. (2024, Appendix B) for more details on the inductive bias of the PD-NJ-ODE). In particular, even if the distribution of the observation times is such that it is (theoretically) possible to have very long periods without observations, the probability of experiencing this necessarily becomes smaller the larger the period is. Hence, the respective training samples where this happens are scarce and consequently the empirical results of the model fall short of the theoretical expectations. \n\nTherefore, we suggest two enhancements of the PD-NJ-ODE model for learning long-term predictions in deterministic (differential) as well as stochastic systems. In Section 2.1.1 we prove that in the deterministic case, the model only taking the initial value as input (and potentially some of the following ones), converges to the same limiting process as the standard model, since all the observations are still used in the loss function. This should improve the inductive bias of the training, since the model is now forced to predict further into the future. In Section 2.1.3 we show that the same training enhancement also leads to accurate long-term predictions in stochastic systems. Moreover, in Section 2.2 we discuss that using output feedback (which is known to stabilize the training of dynamical systems) in the PD-NJ-ODE model framework, still yields the same theoretical results."}, {"title": "2.1 LONG-TERM PREDICTIONS WITH PD-NJ-ODE", "content": "In our context, long-term predictions always refer to predictions within the time horizon $[0, T]$, where for any $0 \\leq s \\leq t \\leq T$, the information available up to time $s$ is used to predict the process at time $t$. This is a generalization of the standard framework, where we have $s=t$, i.e., where predictions are based on all available information up to the prediction time. Importantly, we make no claim for $t>T$. To extend our results for $t>T$, additional assumptions on the time-invariance of the underlying system would be necessary, which we do not require here. \n\nWe start by discussing the special case of deterministic (chaotic) systems in Section 2.1.1, then propose a training procedure in Section 2.1.2 based on those insights, and finally show that the same method also applies in the general case of stochastic systems in Section 2.1.3."}, {"title": "2.1.1 THE SPECIAL CASE OF DETERMINISTIC SYSTEMS", "content": "As described in Section 1, the PD-NJ-ODE is a model that can be used to predict a stochastic process $X$ given its previous discrete and possibly incomplete observations summarized in $\\mathcal{A}_{t}$ for any $t \\in[0, T]$. In particular this model directly uses every new observation as input when the observation becomes available and predicts for all times afterwards based additionally on this new observation. In the setting of stochastic processes this behaviour makes perfect sense, since every new piece of information changes (improves) the following forecasts. However, in the setting of deterministic (differential) systems, which are fully determined by their initial value, using new observations as input for the PD-NJ-ODE model is (in principle) not needed, since they do not provide any new information about $X$. In particular, we have \n\n$$\n\\hat{X}_{t}=\\mathbb{E}\\left[X_{t} \\mid \\mathcal{A}_{t}\right]=X_{t}=\\mathbb{E}\\left[X_{t} \\mid \\mathcal{A}_{0}\right]\n$$\n\nif $\boldsymbol{\\sigma}\\left(X_{0}\right) \\subseteq \\mathcal{A}_{0}$. This allows us to formulate the following corollary of Andersson et al. (2024, Theorem 4.3). \n\nCorollary 2.1. Under the same assumptions as in Andersson et al. (2024, Theorem 4.3) with the additional assumption that $X$ is deterministic given its initial value $X_{0}$, we denote by $\\hat{Y}_{m, n_{m}}^{\theta_{m, n_{m}}^{\\min }}$ the output of the PD-NJ-ODE model, where only the fully observed initial value $X_{0}$ is used as input to the model (in the training). Then, the same convergence result holds for $\\hat{Y}_{m, n_{m}}^{\theta_{m, n_{m}}^{\\min }}$ as for $Y_{m, n_{m}}^{\theta_{m, n_{m}}^{\\min }}$ in Andersson et al. (2024, Theorem 4.3). In particular, $\\hat{Y}_{m, n_{m}}^{\theta_{m, n_{m}}^{\\min }}$ converges to $\\hat{X}$ as $m \rightarrow \\infty$. \n\nRemark 2.2. We emphasize that all available observations of $X$ are still used in the loss function to train the model, they are only not used as input to the model. Therefore, we still have convergence in the metrics $d_{k}$ for all $1 \\leq k \\leq K$. \n\nProof of Corollary 2.1. First note that $X_{0}$ being fully observed implies that $\boldsymbol{\\sigma}\\left(X_{0}\right)=\\mathcal{A}_{0}$. Revisiting the proof of Andersson et al. (2024, Theorem 4.3), it is easy to see that the $L^{2}$-optimal $\boldsymbol{\\sigma}\\left(X_{0}\right)$ measurable prediction $\\left(\\mathbb{E}\\left[X_{t} \\mid \\mathcal{A}_{0}\right]\right)_{t \\in[0, T]}$ of $X$ is the unique minimizer (up to indistinguishability) of the loss function amongst all $\boldsymbol{\\sigma}\\left(X_{0}\right)$-measurable processes. Moreover, it follows as before that the PD-NJ-ODE model can approximate $\\left(\\mathbb{E}\\left[X_{t} \\mid \\mathcal{A}_{0}\right]\right)_{t \\in[0, T]}$ arbitrarily well. Therefore, training the PD-NJ-ODE model, which only takes $X_{0}$ as input, with the same training framework yields \n\nconvergence of $\tilde{Y}_{m, N_{m}}^{\theta_{m, N_{m}}^{\\min }}$ to $\\left(\\mathbb{E}\\left[X_{t} \\mid \\mathcal{A}_{0}\right]\right)_{t \\in] 0, T]}$. Finally, Equation (1) implies that $\tilde{Y}_{m, N_{m}}^{\theta_{m, N_{m}}^{\\min }}$ actually converges to $\\hat{X}=\\left(\\mathbb{E}\\left[X_{t} \\mid \\mathcal{A}_{t}\right]\right)_{t \\in] 0, T]}$. \n\nClearly, for any PD-NJ-ODE model, taking $X_{0}$ and some of the following observations as input, the same convergence result holds, since the result holds for the two extreme cases of models taking all or none of the following observations as input. \n\nWhile Corollary 2.1 might seem to be a trivial extension of the original result, its practical importance is large in the context of learning deterministic (differential) systems. As outlined in the beginning of Section 2, the model which only takes $X_{0}$ as input is forced to learn to predict well over the entire time period. Hence, we effectively improve the inductive bias of the model without changing the theoretical guarantees."}, {"title": "2.1.2 SUGGESTED TRAINING PROCEDURE", "content": "We note that using the observations as input is not only disadvantageous but also has a positive effect on the inductive bias. In particular, every (full) observation that is used as input for the model basically amounts to using this observation as new initial value for the system, hence, increasing the amount of initial values used to train the PD-NJ-ODE model. This is particularly useful in the beginning of the training. Therefore, we introduce a probability $p \\in[0,1]$ and use i.i.d. Bernoulli random variables $I_{k} \\sim \\operatorname{Ber}(p)$, which decide whether an observation is used as input to the model during training. By decreasing the probability $p$ throughout the training we can therefore first use the observations as additional initial values and then focus the training more and more on predicting well over a long time period. Since there exists one solution which is optimal for all $p \\in[0,1]$, this procedure additionally encourages the model to learn it. The effectiveness of this procedure can be seen in Section 3. Nevertheless, we note that theoretically, choosing any fixed $p \\in(0,1)$ leads to the same optimal solution, as proven in the following section."}, {"title": "2.1.3 GENERAL STOCHASTIC SYSTEMS", "content": "Similarly as in the case of a deterministic (chaotic) $X$, also in the stochastic case, we might be interested in learning to predict multiple time steps ahead. In the standard framework, the PD-NJ-ODE model only learns to predict until the next observation time, since it converges to $\\mathbb{E}\\left[X_{t} \\mid \\mathcal{A}_{t}\right]$, which is the optimal prediction of $X_{t}$ given all information available up to $t$, i.e., all information gathered at observation times before or at $t$. However, the training procedure suggested in Section 2.1.2 allows to generalise this, such that the PD-NJ-ODE model learns to correctly predict \n\n$$\n\\hat{X}_{t, s}:=\\mathbb{E}\\left[X_{t} \\mid \\mathcal{A}_{s \\wedge t}\right]\n$$\n\nfor any $0 \\leq s, t \\leq T$, which is shown in the following two results. \n\nCorollary 2.3. Let $p \\in(0,1)$ and $I_{k} \\sim \\operatorname{Ber}(p)$ be i.i.d. random variables for $k \\in \\mathbb{N}$, which are independent of $X$ and the observation framework $n, t_{i}, M_{i}$. Under the same assumptions as in Andersson et al. (2024, Theorem 4.3), with $\\mathbb{A}$ replaced by $\\hat{\\mathbb{A}}$ defined below, we denote by $\tilde{Y}_{m, N_{m}}^{\theta_{m, N_{m}}^{\\min }}$ the output of the PD-NJ-ODE model, where $I_{k}$ determines whether the $k$-th observation is used as input to the PD-NJ-ODE model during training. In particular, the model only uses the information available in the $\\sigma$-algebra \n\n$$\n\\hat{\\mathcal{A}}_{t}:=\boldsymbol{\\sigma}\\left(X_{t_{i}, j}, t_{i}, M_{t_{i}} \\mid I_{i}=1, t_{i} \\leq t, j \\in\\left\\{1 \\leq l \\leq d \\mid M_{t_{i}, l}=1\right\\}\right)\n$$\n\nWe denote the corresponding filtration by $\\hat{\\mathbb{A}}$. Then $\tilde{Y}_{m, N_{m}}^{\theta_{m, N_{m}}^{\\min }}$ is $\\hat{\\mathbb{A}}$-adapted and converges to the unique (up to indistinguishability) $\\hat{\\mathbb{A}}$-adapted minimizer $t \\mapsto \\mathbb{E}\\left[X_{t} \\mid \\hat{\\mathcal{A}}_{t}\right]$ of the loss function. \n\nProof. Adaptedness of the model output $\tilde{Y}_{m, N_{m}}^{\theta_{m, N_{m}}^{\\min }}$ to $\\hat{\\mathbb{A}}$ follows from the used input and the model architecture. The remainder of the statement follows equivalently as in the proof of Andersson et al. (2024, Theorem 4.3). \n\nIn the following proposition we show that for all $s \\in[0, T),\\left(\\mathbb{E}\\left[X_{t} \\mid \\hat{\\mathcal{A}}_{t}\right]\right)_{0 \\leq t \\leq T}$ coincides with $\\left(\\hat{X}_{t, s}\right)_{0 \\leq t \\leq T}$ conditioned on the event $B_{s}:=\\left\\{\\forall k \\leq n: I_{k}=\\mathbf{1}_{\\left\\{t_{k} \\leq s\right\\}}\right\\}$, which has positive probability. Hence, the PD-NJ-ODE model learns to predict $\\left(\\hat{X}_{t, s}\right)_{0 \\leq t \\leq T}$ on $B_{s}$. \n\nProposition 2.4. For all $s, t \\in[0, T]$ we have $\\mathbb{P}\\left(B_{s}\right)>0$ and $\\mathbb{P}$-a.s. \n\n$$\n\begin{aligned}\n\\mathbf{1}_{B_{s}} \\mathbb{E}\\left[X_{t} \\mid \\overline{\\mathcal{A}}_{t}\right] & =\\mathbf{1}_{B_{s}} \tilde{X}_{t, s}, \\quad \text { and } \\\n\\mathbf{1}_{B_{s}} \tilde{Y}_{t}^{\theta_{m, N_{m}}^{\\min }} & =\\mathbf{1}_{B_{s}} \tilde{Y}_{t}^{\theta_{m, N_{m}}^{\\min }}\\left(\tilde{X}^{\\leq t \\wedge s}\right)\n\\end{aligned}\n$$\n\nhence, $\\mathbf{1}_{B_{s}}\\left(\tilde{Y}_{t}^{\theta_{m, N_{m}}^{\\min }}\\left(\tilde{X}^{\\leq t \\wedge s}\right)\right)_{0 \\leq t \\leq T}$ converges (as in Andersson et al., 2024, Theorem 4.3) to $\\mathbf{1}_{B_{s}}\\left(\tilde{X}_{t, s}\right)_{0 \\leq t \\leq T}$ as $m \rightarrow \\infty$. \n\nProof. Fix $s \\in[0, T] . B_{s}$ can be written as the disjoint union $B_{s}=\\cup_{m \\geq 1} \\cup_{0 \\leq k \\leq m}\\{n=m, \tau(s)=$ $\\left.t_{k}, \\forall j \\leq m: I_{j}=\\mathbf{1}_{\\left\\{t_{k} \\leq s\right\\}}\right\\}$, hence, independence of $I_{k}$ to $n$ and $t_{i}$ implies \n\n$$\n\\mathbb{P}\\left(B_{s}\right)=\\sum_{m \\geq 1} \\sum_{k=0}^{m} \\mathbb{P}\\left(n=m, \tau(s)=t_{k}\right) p^{k}(1-p)^{m-k}>0\n$$\n\nwhere $\tau(s)$ is the last observation time before or at time $s$, which shows the first part of the claim. Next, we note that on $B_{s}$ we have $\\overline{\\mathcal{A}}_{t}=\\mathcal{A}_{t \\wedge s}$, since all observations before and no observations after $s$ are \"used\". By the same reasoning we have on $B_{s}$ that $\tilde{Y}_{t}^{\theta_{m, N_{m}}^{\\min }}\\left(\tilde{X}^{\\leq t \\wedge s}\right)=\tilde{Y}_{t}^{\theta_{m, N_{m}}^{\\min }}\\left(\tilde{X}^{\\leq t}\right)=\tilde{Y}_{t}^{\theta_{m, N_{m}}^{\\min }}$, hence (3) follows. Finally, we show the convergence in the metrics $d_{k}$ for any $1 \\leq k \\leq K$. With (3) we have \n\n$$\n\begin{gathered}\nd_{k}\\left(\\mathbf{1}_{B_{s}} \tilde{Y}_{m, N_{m}}^{\theta_{m, N_{m}}^{\\min }}\\left(\tilde{X}^{\\leq \\wedge s}\right), \\mathbf{1}_{B_{s}} \tilde{X}_{., s}\right)=d_{k}\\left(\\mathbf{1}_{B_{s}} \tilde{Y}_{m, N_{m}}^{\theta_{m}^{\\min }}, \\mathbf{1}_{B_{s}} \\mathbb{E}\\left[X_{t} \\mid \\overline{\\mathcal{A}}_{t}\right]\right) \\\n\\leq d_{k}\\left(\tilde{Y}_{m, N_{m}}^{\theta_{m, N_{m}}^{\\min }}, \\mathbb{E}\\left[X_{t} \\mid \\overline{\\mathcal{A}}_{t}\right]\right) \\xrightarrow{m \rightarrow \\infty} 0\n\\end{gathered}\n$$\n\nwhere the convergence follows from Corollary 2.3. \n\nRemark 2.5. There are many equivalent options to choose the observations that are used as input to the model. Selecting them via i.i.d. Bernoulli random variables is one possibility that we use due to its simplicity. However, the same results can be derived with any other method of choosing the observations as inputs, as long as the probability of arbitrarily long periods without new inputs is positive, i.e., $\\mathbb{P}\\left(B_{s}\right)>0$ for all $s \\in[0, T]$ (where the $I_{k}$ are defined through the chosen method). \n\nOne explicit alternative method is to use exponentially distributed random variables to determine the time within which no observations are used as input. In particular, assuming that the current observation at $t_{i}$ is used as input and that $e_{i} \\sim \\operatorname{Exp}(\\lambda)$ for some $\\lambda>0$, the next observation that is used as input is at the first observation time $t_{k}$ such that $t_{k}-t_{i} \\geq e_{i}$. This sub-sampling procedure has the advantage that the probability of not using any observation as input during a certain period only depends on the length of the period but not on the amount of observations during this period (as is the case for the i.i.d. Bernoulli random variables)."}, {"title": "2.2 Output FEEDBACK in the PD-NJ-ODE MODEL", "content": "Using the output of a discrete dynamical system at time $t$ as additional input to the system at the following time $t+1$ is denoted as output feedback in the literature of reservoir computing and known to stabilize the training of such dynamical systems (Reinhart, 2011). In line with this, we propose to use output feedback in the PD-NJ-ODE framework and remark that this does not change the theoretical guarantees of the model. Indeed, the model can always just ignore this additional input, hence, the same results hold. However, the inductive bias when training the model with this additional input is better as we see in Section 3."}, {"title": "3 EXPERIMENTS", "content": "The code with all experiments is available at https://github.com/FlorianKrach/ PD-NJODE. For the experiments on synthetic stochastic datasets, we use the evaluation metric of Krach et al. (2022, Section 8). On all synthetic datasets, we use a previously unseen and independent test set to evaluate the models. \n\nIn Section 3.1 we show that the enhanced training framework together with output feedback enables the PD-NJ-ODE to predict (deterministic) chaotic systems with great accuracy over a long time horizon. The enhanced training framework also leads to better long-term predictions for stochastic datasets, as shown on 3 examples in Section 3.2."}, {"title": "3.1 LONG-TERM PREDICTION OF CHAOTIC SYSTEMS", "content": "We showcase the potential of our enhanced PD-NJ-ODE model for deterministic (differential) systems by applying it to the chaotic system of a double pendulum, that was already described and used in Krach et al. (2022, Appendix B. 3 \\& C.3). This chaotic system can be described by an ODE in 4 variables (the two angles $\\alpha_{i}$ of the pendulums and their two generalized momenta $p_{i}$ ). By choosing the initial value of $\\alpha_{1}=\\alpha_{2}$ randomly around $\\pi$ we introduce small deviations in the initial conditions of this chaotic system, which lead to highly diverse paths. For more details on the setup of the experiment see Appendix A. \n\nWe use the same setting as in Krach et al. (2022, Appendix C.3) and compare the standard PD-NJODE model (labelled \"N\") to i) the PD-NJ-ODE with output feedback (N-OF), ii) the PD-NJ-ODE with input skipping (N-IS), iii) the PD-NJ-ODE with output feedback and input skipping (N-OF-IS), iv) the PD-NJ-ODE with increasing input skipping (N-IIS) and v) the PD-NJ-ODE with output feedback and increasing input skipping (N-OF-IIS). In particular, N-IS refers to the model where none of the observations after $X_{0}$ are use as input and N-IIS refers to the procedure of Section 2.1.2, where we define $p(E)=\\max \\left(0,1-\\frac{E}{100}\right)$, where $E$ denotes the current training epoch. All of these models use the same architecture and are trained for 200 epochs. Moreover, we additionally train the N-OF-IIS again with the same architecture, however with a 5 times larger dataset having a 2.5 times larger observation probability and with 300 epochs (N-OF-IIS-large). \n\nWe evaluate the trained models on the test set, by computing the MSE between their predictions and the true paths on a fine equidistant grid (the same as used for sampling the ODE paths). The results are given in Table 1. In particular, we see that output feedback and input skipping independently of each other improve the results, where the impact of input skipping is larger than the one of output feedback. Moreover, we see a clear increase in performance when switching from input skipping to increasing input skipping (with and without output feedback). In particular, this shows that the model benefits from the additional \"initial values\" used in the beginning of the training. Overall, the performance increases by more than a factor 5 from N to N-OF-IIS and by more than a factor 13 from N to N-OF-IIS-large. \n\nIn Figure 1 we show the comparison of N and N-OF-IIS-large on two samples of the test set. While the standard PD-NJ-ODE model starts to diverge from the true path after about half of the evaluation time, the enhanced PD-NJ-ODE model nearly perfectly predicts the path over the entire period."}, {"title": "3.2 LONG-TERM PREDICTIONS IN STOCHASTIC SYSTEMS", "content": "We use 3 different geometric Brownian motion (Black-Scholes) dataset with similar specifics as in Herrera et al. (2021). Two of the datasets have constant drift and are identical except that they either use an observation probability of $10 \\%$ (BS-Base) or $40 \\%$ (BS-HighFreq). The 3rd dataset uses a time-dependent drift and an observation probability of $10 \\%$ and is otherwise identical to the other datasets (BS-TimeDep). \n\nIn the BS-Base dataset, each of the 100 points of the sampling grid is randomly chosen as observation time with probability $10 \\%$. Hence, the probability of not having an observation for 100 consecutive steps is smaller than $0.01 \\%$. Therefore, it is very unlikely that the model will learn to correctly predict for such a long time (without intermediate observations), when trained with the standard training framework. For the BS-HighFreq dataset, this probability is further reduced to below $10^{-22}$, making it even more unlikely that the standard model will learn to correctly predict over long terms. The difficulty of the BS-TimeDep dataset is that the dynamic changes with time (as in the chaotic system dataset). This makes it more difficult for the standard model to learn, when observations are not far enough apart. The enhanced training framework (Section 2.1.3) should allow the model to circumvent these challenges, as shown theoretically. We compare the standard PD-NJ-ODE (N) with the PD-NJ-ODE with output feedback and increasing input skipping (N-OF-IIS), where an observation is used as input to the model with probability $p(E)=\\max \\left(0,1-\\frac{E}{100}\right)$, decreasing with the training epoch $E$ during the 200 epochs of training. \n\nWe evaluate and compare both models on the test sets of the 3 datasets and see in Table 2 that the enhanced training framework leads to large improvements in terms of the evaluation metric. Moreover, this improvement is also well visible in Figure 2. For BS-Base we see the (slightly) degrading performance of the standard model N approaching the time horizon, which is not prevalent for the enhanced model N-OF-IIS. On the BS-HighFreq dataset the standard model N performs much worse, diverging from the true conditional expectation already after a short time, while the enhanced model predicts nearly perfectly. This was expected, since the model N is much less exposed to predicting over longer time intervals during the training. Finally, in contrast to N-OF-IIS, the standard model does not learn the correct dynamic in the long run on the BS-TimeDep dataset. Comparing the results of N-OF-IIS on the BS-Base and BS-HighFreq dataset, it might seems surprising at first that the model performs better on the latter dataset, where the model N performs much worse. However, this can be explained by the much larger number of observed samples available in BS-HighFreq that the model can make use of with the enhanced training procedure."}, {"title": "4 CONCLUSION", "content": "While it has been known before that the PD-NJ-ODE model can be used to learn (chaotic) deterministic systems, given for example through ODEs or PDEs, a limiting factor for the use in practice was the degrading prediction accuracy for increasing prediction time. In this work we proposed two enhancements of the PD-NJ-ODE model as a remedy for this problem. Simultaneously, these enhancements also enable long-term predictions with the PD-NJ-ODE model in the case of generic stochastic datasets. In particular, convergence of the model output to a much more general conditional expectation process (with arbitrary sub-information) is guaranteed by the suggested new training procedure. Since there are no known drawbacks, the use of this new training procedure is always recommended."}]}