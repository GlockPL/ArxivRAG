{"title": "LEARNING CHAOTIC SYSTEMS AND LONG-TERM PREDICTIONS WITH NEURAL JUMP ODES", "authors": ["Florian Krach", "Josef Teichmann"], "abstract": "The Path-dependent Neural Jump ODE (PD-NJ-ODE) is a model for online prediction of generic (possibly non-Markovian) stochastic processes with irregular (in time) and potentially incomplete (with respect to coordinates) observations. It is a model for which convergence to the L2-optimal predictor, which is given by the conditional expectation, is established theoretically. Thereby, the training of the model is solely based on a dataset of realizations of the underlying stochastic process, without the need of knowledge of the law of the process. In the case where the underlying process is deterministic, the conditional expectation coincides with the process itself. Therefore, this framework can equivalently be used to learn the dynamics of ODE or PDE systems solely from realizations of the dynamical system with different initial conditions. We showcase the potential of our method by applying it to the chaotic system of a double pendulum. When training the standard PD-NJ-ODE method, we see that the prediction starts to diverge from the true path after about half of the evaluation time. In this work we enhance the model with two novel ideas, which independently of each other improve the performance of our modelling setup. The resulting dynamics match the true dynamics of the chaotic system very closely. The same enhancements can be used to provably enable the PD-NJ-ODE to learn long-term predictions for general stochastic datasets, where the standard model fails. This is verified in several experiments.", "sections": [{"title": "1 INTRODUCTION", "content": "The Path-dependent Neural Jump ODE (PD-NJ-ODE) (Krach et al., 2022) is a model for online prediction of generic (possibly non-Markovian) stochastic processes with irregular and potentially incomplete observations. It is the first model for which convergence to the L2-optimal predictor, which is given by the conditional expectation, is established theoretically. Thereby, the training of the model is solely based on a dataset of realizations of the underlying stochastic process, without the need of knowledge of the law of the process. This result was further generalized in the follow-up work Andersson et al. (2024). In particular, let $(X_t)_{t\\in[0,T]}$ be a stochastic process taking values in $R^d$, let $t_i \\in [0, T]$ be random observations times for $1 < i < n$, where $n$ can be a random variable describing the total number of observations (i.e., the number of observations can be different for each realization) and let $M_i \\in \\{0,1\\}^d$ be the corresponding random observation masks, telling which coordinates $X_{t_i,j}$ are observed (if $M_{i,j} = 1$) at each observation time $t_i$. The $\\sigma$-algebra of the currently available information at any time $t \\in [0, T]$ is defined as\n\n$A_t := \\sigma (X_{t_i,j},t_i, M_i|t_i \\leq t, j \\in \\{1 \\leq I \\leq d|M_{t_i,1} = 1\\}),$\n\nwhere $\\sigma(\\cdot)$ denotes the generated $\\sigma$-algebra. Then, Andersson et al. (2024, Theorem 4.3) states that the output $Y_{\\Theta,m}^{om,N_m}$ of the PD-NJ-ODE model (where $\\Theta$ are the trainable parameters of the model, $m$ is the size of the used neural networks and $N_m$ is the number of training paths, i.e., realizations of $X$) converges to the $L^2$-optimal prediction $X = (E[X_t|A_t])_{t\\in[0,T]}$ as $m$ tends to $\\infty$. This convergence holds under weak assumptions on $X$ and the observation framework $(t_i, M_i, n)$, which basically require some integrability properties and continuous differentiability of $t \\rightarrow X_t$."}, {"title": "1.1 RELATED WORK", "content": "This work is based on the sequence of papers introducing NJ-ODE (Herrera et al., 2021), extending it to a path-dependent setting with incomplete observations (Krach et al., 2022) and further to noisy observations with dependence between the observation framework and the underlying process (Andersson et al., 2024). The focus of this paper lies on long-term predictions (i.e., multiple observation times ahead), with a special emphasis on fully observed (chaotic) deterministic systems. The framework of (Krach et al., 2022) also allows for partially observed chaotic systems, which are not deterministic. Such cases resemble stochastic processes, where the optimal prediction, given by the conditional expectation, is learnt. Hence, they can be treated with the provided result for general stochastic processes.\nNavone & Ceccatto (1995) were one of the first to use neural networks to learn chaotic dynamics and several other works followed using RNNs, reservoir computing and neural ODEs (Vlachas et al., 2018; Pathak et al., 2018; Vlachas et al., 2020; Brenner et al., 2022; Chen et al., 2018; Raissi, 2018). Churchill & Xiu (2022) propose a memory-based residual deep neural network (DNN) architecture to learn chaotic systems from fully or partially observed data and apply it to the chaotic Lorenz 63 and 96 systems. Hess et al. (2023) use piece-wise linear RNNs together with teacher forcing to effectively learn chaotic dynamics and provide an extensive overview of related work and numerical comparison to many state-of-the-art models. Our approach, using neural ODEs, is particularly related to Chen et al. (2018) and Rubanova et al. (2019). However, in contrast to all these methods, our approach comes with theoretical learning guarantees even in the most general case of irregularly and incompletely observed path-dependent stochastic processes."}, {"title": "2 MAIN RESULTS", "content": "In the results of Krach et al. (2022, Appendix C.3) we see that the empirical performance of the PD-NJ-ODE applied to chaotic systems could be improved, especially for long prediction horizons, even though the theoretical results suggest that the model should learn to predict chaotic systems correctly at any time. This is related to the inductive bias when training the model with a finite amount of training samples (see Andersson et al. (2024, Appendix B) for more details on the inductive bias of the PD-NJ-ODE). In particular, even if the distribution of the observation times is such that it is (theoretically) possible to have very long periods without observations, the probability of experiencing"}, {"title": "2.1 LONG-TERM PREDICTIONS WITH PD-NJ-ODE", "content": "In our context, long-term predictions always refer to predictions within the time horizon [0, T], where for any $0 < s < t < T$, the information available up to time $s$ is used to predict the process at time $t$. This is a generalization of the standard framework, where we have $s = t$, i.e., where predictions are based on all available information up to the prediction time. Importantly, we make no claim for $t > T$. To extend our results for $t > T$, additional assumptions on the time-invariance of the underlying system would be necessary, which we do not require here.\nWe start by discussing the special case of deterministic (chaotic) systems in Section 2.1.1, then propose a training procedure in Section 2.1.2 based on those insights, and finally show that the same method also applies in the general case of stochastic systems in Section 2.1.3."}, {"title": "2.1.1 THE SPECIAL CASE OF DETERMINISTIC SYSTEMS", "content": "As described in Section 1, the PD-NJ-ODE is a model that can be used to predict a stochastic process $X$ given its previous discrete and possibly incomplete observations summarized in $A_t$ for any $t\\in [0, T]$. In particular this model directly uses every new observation as input when the observation becomes available and predicts for all times afterwards based additionally on this new observation. In the setting of stochastic processes this behaviour makes perfect sense, since every new piece of information changes (improves) the following forecasts. However, in the setting of deterministic (differential) systems, which are fully determined by their initial value, using new observations as input for the PD-NJ-ODE model is (in principle) not needed, since they do not provide any new information about $X$. In particular, we have\n\n$X_t = E[X_t|A_t] = X_t = E[X_t|A_0]$\n\nif $\\sigma(X_0) \\subseteq A_0$. This allows us to formulate the following corollary of Andersson et al. (2024, Theorem 4.3).\nCorollary 2.1. Under the same assumptions as in Andersson et al. (2024, Theorem 4.3) with the additional assumption that $X$ is deterministic given its initial value $X_0$, we denote by $Y_{\\Theta,m}^{om,N_m}$ the output of the PD-NJ-ODE model, where only the fully observed initial value $X_0$ is used as input to the model (in the training). Then, the same convergence result holds for $Y_{\\Theta,m}^{om,N_m}$ as for $Y_{\\Theta,m}^{om,N_m}$ in Andersson et al. (2024, Theorem 4.3). In particular, $Y_{\\Theta,m}^{om,N_m}$ converges to $X$ as $m \\rightarrow \\infty$.\nRemark 2.2. We emphasize that all available observations of $X$ are still used in the loss function to train the model, they are only not used as input to the model. Therefore, we still have convergence in the metrics $d_k$ for all $1 \\leq k \\leq K$.\nProof of Corollary 2.1. First note that $X_0$ being fully observed implies that $\\sigma(X_0) = A_0$. Revisiting the proof of Andersson et al. (2024, Theorem 4.3), it is easy to see that the $L^2$-optimal $\\sigma(X_0)$-measurable prediction $(E[X_t|A_0])_{t\\in[0,T]}$ of $X$ is the unique minimizer (up to indistinguishability) of the loss function amongst all $\\sigma(X_0)$-measurable processes. Moreover, it follows as before that the PD-NJ-ODE model can approximate $(E[X_t|A_0])_{t\\in[0,T]}$ arbitrarily well. Therefore, training the PD-NJ-ODE model, which only takes $X_0$ as input, with the same training framework yields"}, {"title": "2.1.2 SUGGESTED TRAINING PROCEDURE", "content": "We note that using the observations as input is not only disadvantageous but also has a positive effect on the inductive bias. In particular, every (full) observation that is used as input for the model basically amounts to using this observation as new initial value for the system, hence, increasing the amount of initial values used to train the PD-NJ-ODE model. This is particularly useful in the beginning of the training. Therefore, we introduce a probability $p \\in [0, 1]$ and use i.i.d. Bernoulli random variables $I_k \\sim Ber(p)$, which decide whether an observation is used as input to the model during training. By decreasing the probability $p$ throughout the training we can therefore first use the observations as additional initial values and then focus the training more and more on predicting well over a long time period. Since there exists one solution which is optimal for all $p \\in [0, 1]$, this procedure additionally encourages the model to learn it. The effectiveness of this procedure can be seen in Section 3. Nevertheless, we note that theoretically, choosing any fixed $p\\in (0, 1)$ leads to the same optimal solution, as proven in the following section."}, {"title": "2.1.3 GENERAL STOCHASTIC SYSTEMS", "content": "Similarly as in the case of a deterministic (chaotic) $X$, also in the stochastic case, we might be interested in learning to predict multiple time steps ahead. In the standard framework, the PD-NJ-ODE model only learns to predict until the next observation time, since it converges to $E[X_t|A_t]$, which is the optimal prediction of $X_t$ given all information available up to $t$, i.e., all information gathered at observation times before or at $t$. However, the training procedure suggested in Section 2.1.2 allows to generalise this, such that the PD-NJ-ODE model learns to correctly predict\n\n$X_{t,s} := E[X_t|A_{s\\wedge t}],$\n\nfor any $0 \\leq s, t < T$, which is shown in the following two results.\nCorollary 2.3. Let $p \\in (0,1)$ and $I_k \\sim Ber(p)$ be i.i.d. random variables for $k \\in \\mathbb{N}$, which are independent of $X$ and the observation framework $n,t_i, M_i$. Under the same assumptions as in Andersson et al. (2024, Theorem 4.3), with $A_t$ replaced by $\\tilde{A}_t$ defined below, we denote by $\\tilde{Y}_{\\Theta,m}^{om,N_m}$ the output of the PD-NJ-ODE model, where $I_k$ determines whether the $k$-th observation is used as input to the PD-NJ-ODE model during training. In particular, the model only uses the information available in the $\\sigma$-algebra\n\n$\\tilde{A}_t := \\sigma (X_{t_i,j}, t_i, M_i|I_i = 1, t_i < t, j \\in \\{1 \\leq I \\leq d|M_{t_i,1} = 1\\}).$\n\nWe denote the corresponding filtration by $\\tilde{A}$. Then $\\tilde{Y}_{\\Theta,m}^{om,N_m}$ is $\\tilde{A}$-adapted and converges to the unique (up to indistinguishability) $\\tilde{A}$-adapted minimizer $t \\rightarrow E[X_t|\\tilde{A}_t]$ of the loss function.\nProof. Adaptedness of the model output $\\tilde{Y}_{\\Theta,m}^{om,N_m}$ to $\\tilde{A}$ follows from the used input and the model architecture. The remainder of the statement follows equivalently as in the proof of Andersson et al. (2024, Theorem 4.3).\nIn the following proposition we show that for all $s \\in [0,T]$, $(E[X_t|\\tilde{A}_t])_{0<t<T}$ coincides with $(X_{t,s})_{0<t<T}$ conditioned on the event $B_s := \\{\\forall k \\leq n : I_k = 1\\{t_k\\leq s\\}\\}$, which has positive probability. Hence, the PD-NJ-ODE model learns to predict $(X_{t,s})_{0<t<T}$ on $B_s$"}, {"title": "Proposition 2.4.", "content": "For all $s, t \\in [0, T]$ we have $\\mathbb{P}(B_s) > 0$ and $\\mathbb{P}$-a.s.\n\n$1_{B_s}E[X_t|\\tilde{A}_t] = 1_{B_s}X_{t,s}$, and\n\n$1_{B_s} \\tilde{Y}_{t}^{om,N_m} = 1_{B_s} \\tilde{Y}_{t}^{om,N_m} (X_{<t\\wedge s}),$\n\nhence, $1_{B_s} \\tilde{Y}_{t}^{om,N_m}\n\n^{<t<T}$ converges (as in Andersson et al., 2024, Theorem 4.3) to\n$1_{B_s}(X_{t,s})_{0<t<T}$ as $m \\rightarrow \\infty$.\nProof. Fix $s \\in [0,T]$. $B_s$ can be written as the disjoint union $B_s = \\bigcup_{m>1} \\bigcup_{0<k<m} \\{n = m, \\tau(s) = t_k,\\forall j < m : I_j = 1\\{t_k<s\\}\\}$, hence, independence of $I_k$ to $n$ and $t_i$ implies\n\n$\\mathbb{P}(B_s) = \\sum_{m\\geq 1} \\sum_{k=0}^{m} \\mathbb{P}(n = m, \\tau(s) = t_k)p^k(1 - p)^{m-k} > 0,$\n\nwhere $\\tau(s)$ is the last observation time before or at time $s$, which shows the first part of the claim. Next, we note that on $B_s$ we have $\\tilde{A}_t = A_{t\\wedge s}$, since all observations before and no observations after $s$ are \u201cused\u201d. By the same reasoning we have on $B_s$ that $\\tilde{Y}_{t}^{om,N_m} (X_{<t\\wedge s}) = \\tilde{Y}_{t\\wedge s}^{om,N_m} (t) = \\tilde{Y}_{t}^{om,N_m}$, hence (3) follows. Finally, we show the convergence in the metrics $d_k$ for any $1 \\leq k \\leq K$. With (3) we have\n\n$d_k (1_{B_s} \\tilde{Y}_{t}^{om,N_m} (X_{<t\\wedge s}), 1_{B_s}X_{t,s})\n\n= d_k (1_{B_s} (\\tilde{Y}_{t}^{om,N_m}, 1_{B_s} E[X_t|\\tilde{A}_t])\n\n\\leq d_k ((\\tilde{Y}_{t}^{om,N_m}, E[X_t|\\tilde{A}_t]) \\xrightarrow{m\\rightarrow \\infty} 0,$\n\nwhere the convergence follows from Corollary 2.3.\nRemark 2.5. There are many equivalent options to choose the observations that are used as input to the model. Selecting them via i.i.d. Bernoulli random variables is one possibility that we use due to its simplicity. However, the same results can be derived with any other method of choosing the observations as inputs, as long as the probability of arbitrarily long periods without new inputs is positive, i.e., $\\mathbb{P}(B_s) > 0$ for all $s \\in [0,T]$ (where the $I_k$ are defined through the chosen method).\nOne explicit alternative method is to use exponentially distributed random variables to determine the time within which no observations are used as input. In particular, assuming that the current observation at $t_i$ is used as input and that $e_i \\sim Exp(\\lambda)$ for some $\\lambda > 0$, the next observation that is used as input is at the first observation time $t_k$ such that $t_k - t_i \\geq e_i$. This sub-sampling procedure has the advantage that the probability of not using any observation as input during a certain period only depends on the length of the period but not on the amount of observations during this period (as is the case for the i.i.d. Bernoulli random variables)."}, {"title": "2.2 OUTPUT FEEDBACK IN THE PD-NJ-ODE MODEL", "content": "Using the output of a discrete dynamical system at time t as additional input to the system at the following time t + 1 is denoted as output feedback in the literature of reservoir computing and known to stabilize the training of such dynamical systems (Reinhart, 2011). In line with this, we propose to use output feedback in the PD-NJ-ODE framework and remark that this does not change the theoretical guarantees of the model. Indeed, the model can always just ignore this additional input, hence, the same results hold. However, the inductive bias when training the model with this additional input is better as we see in Section 3."}, {"title": "3 EXPERIMENTS", "content": "The code with all experiments is available at https://github.com/FlorianKrach/\nPD-NJODE. For the experiments on synthetic stochastic datasets, we use the evaluation metric of Krach et al. (2022, Section 8). On all synthetic datasets, we use a previously unseen and independent test set to evaluate the models."}, {"title": "3.1 LONG-TERM PREDICTION OF CHAOTIC SYSTEMS", "content": "We showcase the potential of our enhanced PD-NJ-ODE model for deterministic (differential) systems by applying it to the chaotic system of a double pendulum, that was already described and used in Krach et al. (2022, Appendix B.3 & C.3). This chaotic system can be described by an ODE in 4 variables (the two angles $a_i$ of the pendulums and their two generalized momenta $p_i$). By choosing the initial value of $a_1 = a_2$ randomly around $\\pi$ we introduce small deviations in the initial conditions of this chaotic system, which lead to highly diverse paths. For more details on the setup of the experiment see Appendix A.\nWe use the same setting as in Krach et al. (2022, Appendix C.3) and compare the standard PD-NJ-ODE model (labelled \"N\") to i) the PD-NJ-ODE with output feedback (N-OF), ii) the PD-NJ-ODE with input skipping (N-IS), iii) the PD-NJ-ODE with output feedback and input skipping (N-OF-IS), iv) the PD-NJ-ODE with increasing input skipping (N-IIS) and v) the PD-NJ-ODE with output feedback and increasing input skipping (N-OF-IIS). In particular, N-IS refers to the model where none of the observations after $X_0$ are use as input and N-IIS refers to the procedure of Section 2.1.2, where we define $p(E) = max(0,1-\\frac{E}{100})$, where $E$ denotes the current training epoch. All of these models use the same architecture and are trained for 200 epochs. Moreover, we additionally train the N-OF-IIS again with the same architecture, however with a 5 times larger dataset having a 2.5 times larger observation probability and with 300 epochs (N-OF-IIS-large).\nWe evaluate the trained models on the test set, by computing the MSE between their predictions and the true paths on a fine equidistant grid (the same as used for sampling the ODE paths). Overall, the performance increases by more than a factor 5 from N to N-OF-IIS and by more than a factor 13 from N to N-OF-IIS-large.\nIn Figure 1 we show the comparison of N and N-OF-IIS-large on two samples of the test set. While the standard PD-NJ-ODE model starts to diverge from the true path after about half of the evaluation time, the enhanced PD-NJ-ODE model nearly perfectly predicts the path over the entire period."}, {"title": "3.2 LONG-TERM PREDICTIONS IN STOCHASTIC SYSTEMS", "content": "We use 3 different geometric Brownian motion (Black-Scholes) dataset with similar specifics as in Herrera et al. (2021). Two of the datasets have constant drift and are identical except that they either use an observation probability of 10% (BS-Base) or 40% (BS-HighFreq). The 3rd dataset uses a time-dependent drift and an observation probability of 10% and is otherwise identical to the other datasets (BS-TimeDep).\nIn the BS-Base dataset, each of the 100 points of the sampling grid is randomly chosen as observation time with probability 10%. Hence, the probability of not having an observation for 100 consecutive steps is smaller than 0.01%. Therefore, it is very unlikely that the model will learn to correctly predict for such a long time (without intermediate observations), when trained with the standard training framework. For the BS-HighFreq dataset, this probability is further reduced to below $10^{-22}$,"}, {"title": "4 CONCLUSION", "content": "While it has been known before that the PD-NJ-ODE model can be used to learn (chaotic) deterministic systems, given for example through ODEs or PDEs, a limiting factor for the use in practice was the degrading prediction accuracy for increasing prediction time. In this work we proposed two enhancements of the PD-NJ-ODE model as a remedy for this problem. Simultaneously, these enhancements also enable long-term predictions with the PD-NJ-ODE model in the case of generic stochastic datasets. In particular, convergence of the model output to a much more general conditional expectation process (with arbitrary sub-information) is guaranteed by the suggested new training procedure. Since there are no known drawbacks, the use of this new training procedure is always recommended."}, {"title": "A EXPERIMENTAL DETAILS", "content": ""}, {"title": "A.1 DOUBLE PENDULUM", "content": "Dataset. We explain the chaotic system of a double pendulum, depicted in Figure 3, following Svirin (2009); Krach et al. (2022). The dynamical system is determined completely by a 4-dimensional"}, {"title": "A.2 GEOMETRIC BROWNIAN MOTION DATASETS", "content": "The datasets are the same as the Black-Scholes datasets in Herrera et al. (2021, Section 6.1 and 6.2).\nDataset. The geometric Brownian motion is defined by the SDE\n\n$dX_t = \\mu X_tdt + \\sigma X_tdW_t,$\n\nwhere W is a Brownian motion. For all datasets, we use $\\sigma = 0.3, X_0 = 1$, and sample 20'000 paths using the Euler-Maruyama method with time step $\\Delta t = 0.01$ on the time interval [0, T]. For BS-Base and BS-HighFreq we choose drift $\\mu = 2$, while we use the time dependent drift $\\mu(t) = \\frac{1}{2}sin(2\\pi t) + 1$ for the BS-TimeDep dataset. Each time point is independently chosen as observation with probability 0.1 for the datasets BS-Base and BS-TimeDep, and with probability 0.4 for BS-HighFreq (leading to shorter intervals between any two observations)."}]}