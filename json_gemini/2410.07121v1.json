{"title": "Transfer Learning for E-commerce Query Product Type Prediction", "authors": ["Anna Tigunova", "Thomas Ricatte", "Ghadir Eraisha"], "abstract": "Getting a good understanding of the customer intent is essential in e-commerce search engines. In particular, associating the correct product type to a search query plays a vital role in surfacing correct products to the customers.\nQuery product type classification (Q2PT) is a particularly challenging task because search queries are short and ambiguous, the number of existing product categories is extremely large, spanning thousands of values. Moreover, international marketplaces face additional challenges, such as language and dialect diversity and cultural differences, influencing the interpretation of the query.\nIn this work we focus on Q2PT prediction in the global multi-locale e-commerce markets. The common approach of training Q2PT models for each locale separately shows significant performance drops in low-resource stores. Moreover, this method does not allow for a smooth expansion to a new country, requiring to collect the data and train a new locale-specific Q2PT model from scratch.\nTo tackle this, we propose to use transfer learning from the high-resource to the low-resource locales, to achieve global parity of Q2PT performance. We benchmark the per-locale Q2PT model against the unified one, which shares the training data and model structure across all worldwide stores. Additionally, we compare locale-aware and locale-agnostic Q2PT models, showing the task dependency on the country-specific traits.\nWe conduct extensive quantiative and qualitative analysis of Q2PT models on the large-scale e-commerce dataset across 20 worldwide locales, which shows that unified locale-aware Q2PT model has superior performance over the alternatives.", "sections": [{"title": "1 Introduction", "content": "Problem statement. Query understanding in e-commerce extracts customer shopping intent from their search queries, by classifying the query as having a target brand, color, size, etc. The extracted attributes are extremely important for search results ranking and filtering, query augmentation, recommendations and many other usecases [3]. One of the most critical components in query understanding isa Query-to-Product Type (Q2PT) classifier, which associates customer search query with a product type (PT) that the customer intended to browse.\nQ2PT signal has a direct impact on the customer experience, as it can significantly alter search results shown to the user. For example, for a search query \"harry potter mug\", even if the matched Harry Potter book has a high TF-IDF score, it should not be surfaced in the search results, since the customer is interested in another product type (mugs). Moreover, Q2PT signal helps to optimize the computation of the search results, narrowing the retrieval to a specific product category shard [7], which yields search latency improvements.\nQuery category prediction has received significant attention in related works [6, 9, 17-19]: the proposed approaches target various challenges associated with Q2PT prediction, such as short queries [6, 9], long-tail queries [17, 18], product type hierarchy [19], etc. However, to the best of our knowledge, there has not yet been studies, which target the issues of Q2PT classification in the multi-locale setting.\nIn international marketplaces, query understanding and ranking models are often trained on a per-locale basis, using the data from a single store [1, 10]. This approach ensures that the peculiarities of various locales are captured: for instance, in case of Q2PT prediction, same keywords may convey different product type intents, depending on the store (query 'pants' in UK would mean that the user is searching for underwear, while in the US it means the intent to buy trousers); Bonab et al. [1] show that users in multiple locales have different preferences for the same product set.\nMost related studies develop and test query understanding models for high-resource locales, such as United States, achieving remarkable results. However, many recently launched stores in new countries suffer from data shortage [5], which is a major blocker for applying per-locale Q2PT models.\nThe issue is further aggravated by the long-tail nature of the product category distribution; in large online stores there are thousands of product types, with a small fraction of most popular categories dominating the distribution [16]. This discrepancy is amplified in the emerging stores, as shown in Figure 1, where we use our experimental dataset to plot the number of queries per product type, sorted by their frequency, in the emerging locale and aggregated worldwide. In both graphs, we observe that the majority of queries"}, {"title": "2 Related Work", "content": "Search query classification. E-commerce query understanding signals are essential for search rankers and other downstream services, and thus have received significant attention from the research community [6, 8, 9, 12, 15, 17-19].\nAn important challenge in Q2PT is classifying long-tail queries, which have scarce training data. Zhu et al. [18] improve long-tail query classification by transferring knowledge from the frequent queries, which are similar to them. The effects of query variation are studied in [17]; the authors notice that slight variation to the query can flip the category prediction, and they train the classification model to distinguish between pairs of queries, which share most of the terms but have different intent. This training strategy helps to overcome data sparsity for long-tail queries.\nMultiple studies propose solutions to tailor existing classification models for short and ambiguous search queries. For instance, Liu et al. [9] propose a hybrid system which uses different models to serve long and short queries. Jiang et al. [6] develop a new pretraining task to improve over the standard term masking, which is detrimental for short texts: instead, they concatenate the input query with generated words and pretrain the model on identifying the extra terms.\nAnother issue is the shortage of query classification training data. To tackle this issue, Skinner and Kallumadi [15] propose to use transfer learning to infer query category using the model trained on product-category pairs. Alternatively Qiu et al. [12] propose generating synthetic queries, obtained from the product description substring, to pretrain the transformer models.\nFinally, there are various other strategies proposed to improve search query classification. Zhu et al. [19] incorporate category contrastive loss into the model training, showing performance improvement for query classification with hierarchical classes. Zhang et al. [16] augment query category prediction by jointly training it with query-item semantic matching in a multi-task framework.\nHandling data from multiple locales. Cross-market recommendations and search is an important problem for international e-commerce stores: the developed solutions need to meet the performance bar globally and be able to generalize to new locales. However, there has been only a few studies addressing this setup [1, 5, 13].\nBonab et al. [1] investigate market adaptation through finetuning a general model with limited data from a new locale. In this work, the product recommendation model is pretrained on all locales, but afterwards is fine-tuned on each store separately. Such approach helps the models to share some knowledge, but it complicates model training and serving, and incurs high storage costs. The method proposed in our paper, to fine-tune a unified model jointly on all locales, helps to overcome this problem.\nIn the area of multi-locale query classification, Lin et al. [7] develop a shard selection method for e-commerce product search. They conduct experiments under high-resource conditions, thus not addressing the low-resource issue in the smaller stores. Close to our work is [10], proposing a BERT-based query classification model, which has a separate product type classification layer for each locale. The unified backbone allows to reduce storage requirements, however, training the classification layer for each locale"}, {"title": "3 Methodology", "content": "We study the task of predicting product type intent for a given e-commerce search query (Q2PT) in a multi-locale setting. This is a multi-label classification task: for an input query in each locale, the Q2PT model needs to return all product types associated with the query. In the multi-locale setup, each store has an independent catalogue of items, potentially a different language and different volumes of traffic.\nIn our study we propose an alternative to an existing method of training Q2PT models for each locale separately [10], replacing it with a unified architecture, which shares model parameters and training data across all stores.\nWe use BERT-based encoder [4] to create the representations of the input queries, following current research in query classification [10, 12, 18, 19]. The encoder is followed by a fully-connected layer with sigmoid activation, applied to the [CLS] token.\nBuilding on this base architecture, we compare three variants:\n\u2022 non-unified (NU) [10] - which has a common DistilBert backbone but separate classifiers for all locales. Each locale-specific classifier is trained only on the data from this specific store.\n\u2022 unified locale-agnostic (Uag) - in this model both Distil-Bert encoder and classifier are shared across all locales and trained on the mixture of the global data.\n\u2022 unified locale-aware (Uaw) - this model is similar tho the locale-agnostic version, however, it conditions the product type prediction on the locale-id. To achieve it, we prepend the locale-id token to the input keywords, separated with a special [SEP] token.\nBoth unified model variants have their merits and drawbacks. Uag solves the problem of data shortage in low-resource stores, but does not account for local specifics in different locales. Specifically, it can lead to biases in smaller locales, transferred from the bigger ones. Uaw overcomes this problem by encoding the input locale information alongside with the query. This effectively allows the model to produce different product type distributions for each locale.\nOn the other hand, locale-agnostic model has its advantages over locale-aware one: Uag model is more practical for the cases of cold-start launches of new stores, with no prior training data. In this scenario Uaw needs to be retained to learn about new locale-id, while Uag can be readily used out of the box."}, {"title": "4 Experimental Setup", "content": "4.1 Datasets\nWe use an experimental data set sampled from real data, covering 1414 product types and 20 locales: (US - United States, DE - Germany, UK - United Kingdom, JP - Japan, IN - India, IT - Italy, CA - Canada, FR - France, ES - Spain, MX - Mexico, BR - Brazil, AE - United Arab Emirates, AU - Australia, SA - Saudi Arabia, EG - Egypt, NL - Netherlands, TR - Turkey, SE - Sweden, SG - Singapore, PL - Poland). To the best of our knowledge, there are no existing studies benchmarking query classification models across this large number of locales.\n4.2 Training data\nThe data for training Q2PT models is created by aggregating fully anonymized customer click-through behavior, following previous research [7, 9, 17]. The product type for the user search query is derived as the majority product type of items, that the user clicked following that query. Formally, we define the probability of the query q belonging to the product type p as follows:\n$P(q, p) = \\frac{num\\_clicks(q, item \\ item \\in p)}{num\\_clicks(q, item)}$\nAfter that we select all <query, product type> pairs that have P(q, p) > 0.5.\nThe collected data has immense discrepancy in sample distribution among the locales: the large stores take over 90% share of the dataset. We split the locales into 2 buckets: High-Resource (Hi-Re) locales, including US, DE, UK, JP, IN, IT, CA, FR, ES stores, and Low-Resource (Lo-Re) locales, including MX, BR, AE, AU, SA, EG, NL, TR, SE, SG, PL stores, based on the number of training samples. In our experiments we compare the models' results per bucket, to assess the effects of unified and disjoint training for these two groups.\nWe use 100s of millions samples for model training and 10s of millions for validation and hyperparameter selection.\n4.3 Evaluation Data\nAs the customer click-through data is noisy and prone to trends and seasonality, we cannot rely on it for accurate model performance evaluation. Instead, we create two separate evaluation datasets: human-annotated and automatically weakly labeled.\nHuman-labeled data. We recruited professional annotators to label search queries with all applicable product types; for each locale we got around 1k human-labeled queries. The human-annotated dataset is high-quality, however, it mostly consists of queries associated with popular PTs. Thus, this dataset has a very low coverage of the product type label space: on average only around 600 product types (42% of the whole list) are included for each locale, moreover, on average only 22 PTs are associated with at least 20 labeled samples.\nAs an alternative, to be able to conduct a more fine-grained per-PT anaysis, we created a large-scale automatically labeled dataset.\nAutomatically labeled data. To create this dataset we leverage relevance labels for the <query, item> pairs, obtained from a pretrained classifier. For each query we collect the categories of all items that are predicted relevant to it. The query label is then selected as a majority category from relevant items.\nThe resulting dataset consists of 2.7M labels in total, with an average of 120k labels per locale. To check the correctness of this labelling, we manually inspected 200 queries from different locales, and verified that this labeling method achieves almost 90% accuracy."}, {"title": "4.4 Model Implementation and Training", "content": "We used a multilingual pretrained DistilBert [14] checkpoint, which was fine-tuned on e-commerce queries; we further fine-tuned the model on the Q2PT task. We used Adam optimizer and trained the model with 8e-5 learning rate, 0.001 dropout and 211 batch size until convergence, using binary cross-entropy loss. The hyperparameters were chosen through grid search on the validation split.\n4.5 Evaluation Metrics\nWe report recall at 0.8 precision: the fixed high-precision setting is a standard in evaluating customer-facing applications, such as e-commerce sites. Given the importance of Q2PT signal for the downstream search and recommendation components, the query classification models have to meet high precision bar."}, {"title": "5 Experiment Results", "content": "Results on the human-labeled data. In Table 1 we report recall at 0.8 precision for all 20 locales. Additionally, we aggregate the results separately for established High-Resource (Hi-Re) and emerging Low-Resource (Lo-Re) stores, and worldwide (WW).\nWe observe that both variants of the unified model outperform the non-unified one for all locales, with the total increase of 2% recall worldwide. Notably, the most benefiting locales are small ones, e.g. PL (+6%) and SE (+5%). It shows that the unified models can efficiently transfer knowledge from high-resource to the low-resource locales. Importantly, we notice that even on the Hi-Re locales a generalist Uaw model performs slightly better than a specialist Uaw model.\nBetween the two variants of a unified model, Uaw has slightly more pronounced gains over Uag. This illustrates that the task of product type prediction is not locale-invariant: conditioning on the locale information helps the model to distinguish locale-specific peculiarities (we discuss it further in Section 6.1).\nTo further assess the models on low- and high-resource locales we plot precision-recall curves for one of the high-resource (US) and one of the small-resource (PL) locales in Figure 2. For US, Uaw slightly dominates for the high precision values, thanks to the both more diverse training data from the other locales and preserved information about the current locale. In PL, there is a significant gap between NU and consolidated models, because the latter were trained on 1000 times more data.\nAdditionally, we experimented with a completely disjoint model architecture: for each locale all model parts are shared among the locales, and they are trained and stored separately. We found that this variation performs on par with Uaw and has 2% performance increase compared no NU. Given that this model takes 7 times longer to train (assuming sequential training on all locales) and 20 times greater memory requirements, without significant performance improvements, we did not consider this model for our analyses.\nResults on the automatically-labeled data. We compute recall at 0.8 precision on the automatically-labeled evaluation set, and present the aggregated results in Table 3. On this dataset the gap between NU and unified models considerably increases, which can be attributed to the automated data having more long-tail product types, which are challenging to predict, and which have extremely scarce training data in low-resource locales. At the same time, human data is largely composed of the most popular product types, on which the performance of all models is on par.\nIn this dataset, however, the trend between both unified models changes, with Uag having slightly better performance. After examining the performance of the models per locale, we found that Uag has superior results in all but two of the biggest locales: US and UK (in these locales Uag performance is 1% worse than Uaw). It shows that conditioning on locale-id helps the model to develop"}, {"title": "5.1 Analysis on the Product Type Level", "content": "In this analysis we aim to evaluate the models on different product type groups, based on their frequency in the training data. As shown in Figure 1, the distribution of product types is very skewed, and thus it is desirable to assess the models' capabilities to correctly infer long-tail product types.\nFor this analysis we split the list of PTs into 3 parts: head (very frequent PTs, e.g. book), torso (average frequency, e.g. wall ornament) and tail (niche PTs, e.g. mounted storage system kit), so that each part has 1/3 of query mass of the whole dataset. As a result we got 48 head, 198 torso and 1168 tail product types.\nFor this experiment we use automatically-labeled data, because it evenly covers all product types. We compare the performance of non-unified model against unified locale-aware model, as it has shown superior performance to the Uag on the human-labeled benchmark. We compute per-PT accuracy, which is defined as the number of correctly predicted occurrences of a product type, over"}, {"title": "6 Discussion", "content": "6.1 Analysis of Locale Differences\nIn our experiments we observe that the same search query might have different meanings depending on the locale, and thus yield different product type distributions. We conduct additional analyses to quantify how frequent this phenomenon occurs.\nWe focus on two pairs of locales that share the same language: FR \u2192 CA (French) and EG \u2192 SA (Arabic); for each pair of stores, we consider the queries that exist in the training sets in both markets and measure the difference between per-PT click distributions (from Equation 1). To this end, we compute the classic Earth Moving Distance (EMD) [2, 11]. In Figure 3 we illustrate one example of such computation.\nWe depict the histograms of EMD distributions for each locale pair in Figure 4: the smaller the EMD, the more similar the locale per-PT distributions are. We observe an expected peak near zero, because largely the customers in different stores should have the same PT in mind in their search. However, the amount of dissimilar modes is significant, ranging from small differences to completely different distributions (EMD near 1).\n6.2 Categorization of Local Differences\nDuring analysis of query differences, we found multiple cases where the product type distributions significantly vary across locales. We attribute those discrepancies to one of the following cases:\n1. Dialectal differences: despite the same language, the query has a different meaning to the users in different stores. One particular example is the word 'liqueur', which means an alcoholic drink in France, but a non-alcoholic drink or syrup in Canada (see Figure 5a). Another example is 'vaporizer', which means a smoking gadget in France and an air humidifier appliance in Canada (depicted in Figure 5b). These discrepancies can be explained by cultural and historical factors, e.g. language drift from the neighbouring countries. Although such cases are pretty rare in the data, they can have a profound impact on the user experience, especially in the cases of products under legal regulations.\n2. Selection differences: the query has different meaning with respect to the product type, that is caused by a mismatch in the selection of products offered in corresponding markets. For example, a query \"carpe\" that means \"a carp\" in French leads to fishing accessories in FR store. However, in Canada it is mapped to a popular cosmetic brand marketed under the same name (see Figure 5c).\n3. Noisy differences: in many cases we observe a large discrepancy for a given query as measured by EMD between PT click"}, {"title": "7 Conclusion and Future Work", "content": "In this study we investigate the task of e-commerce query product type prediction in a multi-locale setup and propose a transfer learning solution to augment Q2PT predictions in low-resource stores to achieve global parity.\nThe evidence from our offline experiments and user studies shows that the unified Q2PT model, sharing the parameters and training data across all locales, outperforms the non-unified model, on both low- and high-resource locales, additionally decreasing infrastructure requirements. We compare locale-agnostic and locale-aware variants of the unified model, showing that it is important to capture store-specific characteristics by conditioning the prediction on the locale-id. The findings from our work will be useful for practitioners developing multi-locale query classification models.\nWe identify the following avenues for our future work. We plan to investigate the impact of language variation on the Q2PT task, both in terms of the language of the input query as well as the model's pre-training data. Additionally, we plan to conduct similar analyses for other related query understanding models, such as brand classifiers."}]}