{"title": "Predicting Stock Prices with FinBERT-LSTM: Integrating News Sentiment Analysis", "authors": ["WENJUN GU", "Yihao Zhong", "Shizun Li", "Changsong Wei", "Liting Dong", "Zhuoyue Wang", "CHAO YAN"], "abstract": "The stock market's ascent typically mirrors the flourishing state of the economy, whereas its decline is often an indicator of an economic downturn. Therefore, for a long time, significant correlation elements for predicting trends in financial stock markets have been widely discussed, and people are becoming increasingly interested in the task of financial text mining. The inherent instability of stock prices makes them acutely responsive to fluctuations within the financial markets. In this article, we use deep learning networks, based on the history of stock prices and articles of financial, business, technical news that introduce market information to predict stock prices. We illustrate the enhancement of predictive precision by integrating weighted news categories into the forecasting model. We developed a pre-trained NLP model known as FinBERT, designed to discern the sentiments within financial texts. Subsequently, we advanced this model by incorporating the sophisticated Long Short Term Memory (LSTM) architecture, thus constructing the innovative FinBERT-LSTM model. This model utilizes news categories related to the stock market structure hierarchy, namely market, industry, and stock related news categories, combined with the stock market's stock price situation in the previous week for prediction. We selected NASDAQ-100 index stock data and trained the model on Benzinga news articles, and utilized Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and Accuracy as the key metrics for the assessment and comparative analysis of the model's performance. The results indicate that FinBERT-LSTM performs the best, followed by LSTM, and DNN model ranks third in terms of effectiveness.", "sections": [{"title": "1 INTRODUCTION", "content": "The stock market is a key component of the economic ecosystem [1]. It serves as a conduit through which publicly traded corporations secure financial resources, which provides funding for various research and development projects to create services, products, and employment opportunities that contribute to economic growth. Should a company's performance falter, its share value is likely to experience a sharp decline; Should a company's performance excel, its stock value is likely to experience a dramatic surge. Investors are thus encouraged to delve into the intricacies of the stock market to discern which ventures are poised to yield a return. Anticipating stock price movements is inherently challenging, as it is not governed by a set of rigid mathematical formulas. The market is subject to fluctuation at any given moment, influenced by a myriad of elements including economic inflation and international tensions [2]. Nonetheless, by identifying trends within the data, it is possible to formulate reasonably precise short-term forecasts.\nAnalyzing current events can significantly contribute to forecasting stock movements, given that the stock market is profoundly swayed by news pertinent to the financial sphere [3]. News articles contain market information, negative articles are related to poor company performance, and positive articles are related to good performance. Therefore, it is possible to understand the trend of stocks by studying news articles, and incisive news analysis can yield substantial advantages by enhancing the accuracy of stock trend forecasts. Over recent years, individuals have examined stock-related news from a variety of angles, yet the potential for extracting valuable insights from financial news archives remains largely untapped. Despite the complexity introduced by a multitude of factors, the task of analyzing news remains a formidable challenge. Sentiment analysis, a subset of textual analysis, is employed to gauge the sentiment polarity of written content. This method evaluates the intrinsic sentiment of a text, categorizing it into positive or negative sentiments [4]. By doing so, it captures the public's emotional response to news stories. For instance, a report highlighting profits and acquisitions can evoke positive sentiments, potentially elevating a company's stock value, whereas a piece detailing layoffs and bankruptcy may incite negative reactions, contributing to a decrease in stock prices. Consequently, discerning the emotional undertones of news articles can offer a more profound insight into a company's operational success and inform predictions regarding its stock market trajectory.\nConversely, technical analysis techniques concentrate on examining the dynamics of stock prices, trading volumes, and the psychological expectations of investors. This approach leverages tools such as K-line charts to scrutinize the trajectory of stock indices for individual equities or the market as a whole, utilizing numerical data to forecast stock prices. Throughout history, a significant portion of initial scholarly work has focused on leveraging data from a particular moment, denoted as time t, to forecast the direction of stock prices at the immediately following moment, time t+1. In recent years, there has been a shift in the academic discourse, with some researchers framing the challenge of stock market prediction within the framework of sequential analysis. In this approach, the forecasting model processes a series of data points that span an ongoing timeline, as referenced in the literature [5-7]."}, {"title": "2 STATE OF THE ART", "content": "Over an extended timeframe, the domain of predicting stock market movements has increasingly relied on the employment of sophisticated machine learning and deep learning methodologies, as highlighted in recent scholarly works [8-9]. Advancements in the field, notably the progression of Recurrent Neural Networks (RNNs), have been pivotal, especially the variants equipped with Long Short-Term Memory (LSTM) features, which have"}, {"title": "3 METHODOLOGY", "content": "In this section, our work presents an in-depth account of the experimental procedures and evaluation metrics employed to validate the effectiveness of the proposed techniques and models. Our study leverages a comprehensive dataset of historical stock market news from Benzinga, complemented by US stock codes and pricing data sourced from Yahoo Finance. Utilizing the Keras open-source deep learning framework, which is integrated with a TensorFlow backend [10], we have constructed and refined convolutional neural network models. The execution of all experimental trials was conducted on cloud-based servers equipped with NVIDIA Tesla P100 GPU, which provides a unified platform using the NVIDIA Pascal GPU architecture."}, {"title": "3.1 Dataset", "content": "The dataset used in this work is a carefully compiled collection of news information, containing a total of 843062 articles, published from February 15, 2009 to June 12, 2020. It comprehensively covers key information from multiple dimensions, aiming to provide a solid data foundation for in-depth insights into media trends, stock market dynamics, and their interrelationships. This dataset not only includes the title of each news article and the URL link to directly access the article content, ensuring the traceability of information and the possibility of instant access, but also accurately records the publisher information of each news article, which is particularly"}, {"title": "3.2 Fin-BERT Embedding LSTM Architecture", "content": "In this segment, we delve into the intricacies of the proposed model. The pipeline of this model first applies Fin-BERT word embedding to news data to generate news sentiment analysis indicators with ratings. At the same time, a LSTM is trained by combining historical stock price data to integrate the two models, enabling them to use all the features extracted from the two models (from \"digital+news\" data) to predict the closing price and reduce errors.\nFin-BERT is a language model based on BERT [23-24]. Fin-BERT represents an evolution in the domain of natural language processing (NLP), specifically tailored for financial sector applications. Its technological leap stems from the adoption of the Transformer architecture's bidirectional training mechanism for language modeling, marking a departure from prior studies [25] that predominantly focused on unidirectional, left-to-right text sequence analysis or a hybrid approach. Empirical evidence from scholarly work suggests that bidirectional training enables language models to achieve a more nuanced comprehension of linguistic contexts and flows. A key element of this architectural design is the integration of an attention mechanism, which is engineered to identify and understand the contextual interconnections between words and sub-word units within textual data. The BERT model stands out by featuring two principal components: an encoder that analyzes the input text and a decoder that generates task-specific predictions. Given BERT's objective to construct a comprehensive language model, it exclusively employs the encoder phase. This selective use of the encoder facilitates the model's ability to deduce word contexts from their immediate surroundings, thereby enhancing its interpretive"}, {"title": "3.3 LSTM Architecture", "content": "In this method, unlike the data used in the previous section, we did not use the sentiment analysis score of stocks as input. Instead, we directly used the closing prices of stocks from the past 8 days as input data and reshaped the data into a two-dimensional array, where each row represents a sample containing the closing"}, {"title": "3.4 DNN Architecture", "content": "In this section, we also use the closing prices of stocks from the past 8 days as input data. The deep learning model's schematic illustrate a sequential arrangement of layers. Each layer integrates the output from its predecessor and subsequently forwards its own output to the next in line. The model initiates with a normalization layer to standardize the data, which is then processed through three fully connected layers containing 256, 128, and 64 neurons respectively. The constituent layers of the model employ a rectified linear unit (ReLU) activation function, augmented with a leaky parameter set to 0.01, addressing the issue of zero gradients for negative inputs. Concluding the sequence, a single-neuron fully connected layer is employed with a linear activation function, which is apt for regression analysis, and the model's objective is quantified by the MSE, a widely accepted metric for gauging the discrepancy between the predicted outcomes and the actual data points."}, {"title": "4 RESULTS", "content": "In this chapter, we conducted a detailed analysis and comparison of the predictive effects of three different models and methods on stock prices. Both the training and testing phases are conducted utilizing identical hardware setups. The training process encompasses a total of 100 epochs through the data. Additionally, a checkpoint mechanism is implemented to capture the optimal model parameters at various stages of training, with a focus on monitoring the model's performance based on the validation loss to ensure the most accurate predictions."}, {"title": "4.1 Performance Indicator", "content": "Performance metrics serve as critical tools for assessing the efficacy of machine learning and deep learning models. A variety of evaluative measures are at our disposal to gauge model performance. We have conducted a comparative analysis of the methodologies and models employed, focusing on three key metrics:"}, {"title": "4.2 Fin-BERT Embedding LSTM Architecture", "content": "Our model achieved smaller loss within 77 epochs; Consequently, the model expedites the attainment of high precision. The validation dataset recorded a minimal loss value of 0.00036. The test dataset, as depicted in Figure 1, exhibited a slightly higher loss of 0.00083. Our model's predictions were characterized by a MAE of 173.67 and a MAPE of 0.045, alongside an impressive accuracy score of 0.955. To vividly illustrate the model's forecasting capabilities, we applied it to anticipate eBay's stock price trajectory for the subsequent 100-day period, as shown in Figure 2."}, {"title": "4.3 LSTM Architecture", "content": "Our model achieved smaller loss within 100 epochs. The validation set obtained a loss of 0.00085. The test dataset, as illustrated in Figure 3, reported a loss value of 0.00092. Our model, upon evaluation, produced a MAE of 183.36 and a MAPE of 0.072, achieving an accuracy level of 0.928. To provide a visual representation"}, {"title": "4.4 DNN Architecture", "content": "Our model achieved smaller loss within 100 epochs. The validation set obtained a loss of 0.458. The test set achieved a loss of 21.77, and our proposed model generated a MAE of 489.32 and a MAPE of 0.22, with an accuracy of 0.78. As shown in Figure 5. To visually demonstrate the predictive performance of the model, We deployed the model to project eBay's stock price trends for the forthcoming 100 trading days, as shown in Figure 6."}, {"title": "5 CONCLUSION", "content": "Our work proposes three models and methods for predicting financial stock market prices, namely Fin-BERT Embedded LSTM Architecture, LSTM Architecture, and DNN Architecture. The Fin-BERT Embedding LSTM Architecture utilizes stock news content to quantitatively analyze news sentiment. At the same time, combining the past closing price trends of stocks with sequential data, the aim is to comprehensively extract features from the dual perspectives of numerical data and news information, to enhance the precision of forecasting stock closing prices and substantially diminish the predictive error. LSTM Architecture and DNN Architecture, on the other hand, only predict historical stock closing prices. The proposed Fin-BERT Embedding LSTM Architecture method performed the best, with a Testing loss of 0.00083, MAE of 173.67, MAPE of 0.045, and Accuracy of 0.955 at 77 epochs, resulting in better performance with less computation time. LSTM Architecture performed second, while DNN Architecture performed the worst. However, there is not much difference in performance between Fin-BERT Embedding LSTM Architecture and LSTM Architecture. In our future research, our goal will focus on two core directions: firstly, expanding the experimental scope, validating model performance on larger datasets, and deploying it to the current state-of-the-art model framework for in-depth testing. The second is to deepen the emotional analysis of stock market news, and it is expected that this strategy can significantly enhance the stability and reliability of model predictions. In addition, the plan is to include a fake news identification mechanism to distinguish the authenticity of financial reports, which is also expected to improve the robustness of predictions. The research perspective will not only be limited to the stock market, but also cross over to other investment sectors with huge potential, such as precious metals (such as gold), energy (oil), and the real estate industry, The aim is to validate and refine the model's performance across a variety of market conditions"}]}