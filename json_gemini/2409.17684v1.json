{"title": "Preserving logical and functional dependencies in synthetic tabular data", "authors": ["Chaithra Umesha", "Kristian Schultz", "Manjunath Mahendra", "Saptarshi Bej", "Olaf Wolkenhauer"], "abstract": "Dependencies among attributes are a common aspect of tabular data. However, whether existing tabular data generation algorithms preserve these dependencies while generating synthetic data is yet to be explored. In addition to the existing notion of functional dependencies, we introduce the notion of logical dependencies among the attributes in this article. Moreover, we provide a measure to quantify logical dependencies among attributes in tabular data. Utilizing this measure, we compare several state-of-the-art synthetic data generation algorithms and test their capability to preserve logical and functional dependencies on several publicly available datasets. We demonstrate that currently available synthetic tabular data generation algorithms do not fully preserve functional dependencies when they generate synthetic datasets. In addition, we also showed that some tabular synthetic data generation models can preserve inter-attribute logical dependencies. Our review and comparison of the state-of-the-art reveal research needs and opportunities to develop task-specific synthetic tabular data generation models.", "sections": [{"title": "1. Introduction", "content": "Dependencies among attributes are a common aspect of tabular data. For instance, two attributes, such as Gender and Pregnancy, in some clinical data have a clear dependency in a logical sense because it is not possible for a male to be pregnant. A well-known fact in Database Management Systems is that if one wants to remove redundancies by dividing larger tables into smaller ones (Normalization) [1], one needs tools to identify functional dependencies present among the attributes of the larger table [2]. Preserving functional dependencies in synthetic tabular data is an area that has not been explored. Dependencies exist in both tabular and image data. A recent study by Tongzhen Si et al., published in Pattern Recognition, discusses capturing inter-image dependencies between pedestrian images and intra-pixel dependencies within each image using attention mechanism [3]. Functional dependencies (FD). Functional dependency describes a relationship between attributes (columns/features) in a table. For two functionally dependent features, for each value of one feature, there is a unique value for the other feature [4]. Given a tabular dataset T with values $T_{ij}$ for row i in R = {1, 2, 3, ..., n} and column j in C = {1, 2, 3, ..., m}. Let A = (a1, a2, a3, ...) be a subset of columns with $a_k \\in \u0421$. The term $T_{i,A} = (\u03a4_{i,a1}, \u03a4_{i,a2}, \u03a4_{i,a3}, ...)$ denotes the tuple that represents the values of row i for the selected columns in A. The set A = {$T_{i,a}$: i \u2208 R} is the set of all tuples that exists in the table for the given selection of columns A. In the same way, we have a second selection of columns B and the corresponding set of tuples B = {$T_{i,s}$: i \u2208 R}. Let be a \u2208 A and b \u2208 B. Our table T implies a relation ~$T\u2286 A \u00d7 B$ where (a, b) is in ~$T$ if and only if there exists an i \u2208 R that $T_{i,A} = a$ and $T_{i,\u00df} = b$ [5]. For short we write a~$r$b when (a, b) is in ~$r$. A functional dependency between A and B is denoted as $A \u2192 B$ (B is functionally dependent on A), meaning that for every value a in A, there is a unique value b for that a~$r$b holds [6]. We can write:\n$(A\u2192 B) \u21d4 (Vi1, i2 \u2208 R : T_{i1,A} = T_{i2,A}   T_{i1,B} = T_{i2,B})$\nIn Table 1, an example of functional dependency is that the disease uniquely determines the examiner. Another example is the association between DNA segments and diseases [1]. Identifying functional dependencies plays a role in diagnostics, prognostics, and therapeutic decisions. The literature provides several algorithms for extracting functional dependencies"}, {"title": null, "content": "for a given data [7, 8, 2]. However, research in the field of synthetic data has yet to explore how well synthetic data generation algorithms can preserve functional dependencies in synthetic data compared to real data. Logical dependencies describe how one attribute's value can logically determine another attribute's value. Let's collect all values of B that are in the same row as a given a \u2208 A with D(a) = {b \u2208 B: a ~$r$ b}. So D(a) is the set of all b in B that are dependent of a given a. Obviously, we have that D(a) is a subset of B or D(a) is equal to B. Assume there are some b \u2208 B that are missing in D(a). Then we can tell by knowing the value for a = $T_{i,a}$ for a chosen row i that these b \u2208 B \\ D(a) will never occur in this particular $T_{i,B}$. The smaller the set D(a), the better our prediction for possible b will be. In the case of |D(a)| = 1 for all a \u2208 A, we have a functional dependency of $A \u2192 B$ given by our table. Table 1 illustrates a logical dependency between the Gender being M(Male) and Pregnancy being No. When certain conditions consistently hold across different categories, a logical dependency exists between them. It is important to note that if attributes are functionally dependent, they are also naturally logically dependent. When we create synthetic data, it is important to respect logical dependencies, for example, to avoid generating synthetic tables with males being pregnant. In contrast to the well-explored concept of functional dependencies, the idea of logical dependencies remains largely unexplored for synthetic data. Measures to quantify logical dependencies among attributes. Currently, no standard measures are available to determine the logical dependencies between attributes in a given dataset. In Section 3, we introduce a novel measure to identify inter-attribute logical and functional dependencies."}, {"title": null, "content": "Defining with C* = {(a1, ...): {a\u2081, . . .} \u2286 C} the set that contains all possible selection of columns. The Q-function $QT : C* \u00d7 C* \u2192 [0, 1]$ provides Q-scores between 0 and 1 for every pair of column selections A \u2208 C* and B \u2208 C* within the dataset. In our study, we concentrate on column selections that contain only one column. If there are k attributes, then (k\u00b2 \u2013 k) Q-scores are generated. A score of 0 in the Q function indicates that the attributes are functionally dependent on each other. If the score is 1, then the attributes are not dependent on each other. The attributes are logically dependent if the score is between 0 and 1. We refer to Section 3 for a detailed mathematical explanation of the Q-function. Chen et al. [9] investigated the preservation of functional dependencies in synthetic data generated by GAN-based models and introduced a novel approach emphasizing functional dependencies. However, this approach was limited to bounded real data and did not encompass the entire scope of tabular data [9]. Given the importance of logical and functional dependencies in ensuring the authenticity of synthetic data, there is a gap in our understanding of how to preserve these dependencies effectively. Therefore, as a first step in this research direction, an empirical data-driven analysis of the capabilities of synthetic data generation algorithms to retain logical and functional dependencies is"}, {"title": null, "content": "essential to enhance the reliability and applicability of synthetic datasets across various analytical domains. In recent years, there has been a significant increase in research efforts focused on generating synthetic tabular data [10, 11, 12, 13]. Along with these models, various performance measures are aimed at evaluating synthetic data's utility, fidelity, and privacy compared to real data [10]. Despite the challenges in creating synthetic tabular data, many models have demonstrated their ability to generate data that maintains privacy while preserving its utility [14, 15]. However, it is worth noting that preserving dependencies among attributes in synthetic data compared to real data can enhance the semantic correctness of the synthetic data. In this article, we perform a comparative analysis of synthetic data generation strategies in the context of preservation of logical and functional dependencies on five publicly available datasets, comprising four clinical datasets and one business dataset. We employed seven generative models to create synthetic data for all five datasets. Subsequently, we employed the Q-function to extract logical dependencies and FD-Tool [16] to extract functional dependencies from real and synthetic data. Then, we compared the percentage of preserved logical and functional dependencies across all models. There are various publicly available algorithms to extract functional dependencies, and we chose FDTool due to its validation on clinical datasets [16]. Our findings reveal that while some generative models preserve logical dependencies to a reasonable extent, none adequately maintain functional dependencies. This study underscores the need for further research to address attribute-dependency preserving generative modeling for tabular data."}, {"title": "2. Related research", "content": "We focus on generating synthetic tabular data rather than synthetic data in general. Recently, researchers developed several advanced methods to create realistic tabular datasets [10]. Models such as Generative Adversarial Networks (GANs) [17], Variational Autoencoders (VAEs) [18], diffusion models [19], convex space generators [20] and Large Language Models (LLMs) [21] have shown the ability to replicate complex patterns found in real tabular data accurately. Each of these models offers unique approaches and advantages for addressing the specific challenges of tabular data, including handling various data types, preserving relationships between columns, and managing high-dimensional spaces [10]. In the following sections, we will explore some of the advanced models we utilized in our experiments."}, {"title": "2.1. State-of-the-art models employed in the comparative study to generate synthetic tabular data", "content": "CTGAN, introduced by Xu et al. in 2019 for synthetic tabular data generation using Conditional Generative Adversarial Networks. The training process incorporates mode-specific normalization to model Non-Gaussian and multimodal continuous distributions [11]. A variational Gaussian mixture model (VGM) is employed to determine the number of modes for a continuous column, followed by calculating the probability of each value in the column belonging to a specific mode. This results in each continuous value represented by a one-hot encoded mode and a continuous mode-specific normalized scalar. Discrete data is represented using one-hot encoding [22]. A training-by-sampling strategy addresses the imbalance in categorical features during training to ensure an even sampling of all categories from discrete attributes [11]. A conditional vector is employed to select a specific value for each discrete column, with the size of the vector being the sum of the cardinality of each discrete column. The PMF (Probability Mass Function) across all possible values is calculated using the logarithm of the frequency of each value in the column, and the conditional vector is set accordingly once a value is selected in the column [22]. The generator is then provided with this conditional vector and a noise vector containing random values. The idea of 'packing' was introduced to prevent mode collapse, where the discriminator works on multiple samples simultaneously [23]. CTGAN has been benchmarked with multiple datasets, and the results indicate that it can learn more accurate distributions than Bayesian networks [11]. Zhao et al. [12] developed CTABGAN to generate synthetic tabular data using Conditional Adversarial Networks. This approach addresses the limitations of previous generative models and incorporates an auxiliary classifier, along with a generator and discriminator, to enhance the integrity of the synthetic data [12]. Unlike CTGAN, CTABGAN can handle mixed data types, skewed multimode continuous features, and long tail distributions. CTABGAN uses a mixed-type Encoder to address mixed data types, treating mixed variables as value pairs consisting of categorical and continuous parts [12]. Additionally, CTABGAN includes a training method that ensures each column has an equal probability of being selected and uses a specific mode sampled from the probability distribution (logarithm of the frequency) for continuous variables [12]. Zhao et al. pre-process variables with a logarithm transformation to handle long tail distributions [12]. Through comparative evaluation against four other tabular data generators, it has been shown that CTABGAN produces synthetic data with high utility, statistical similarity to real data, and reasonable safeguards for sensitive information [12]. However, it is important to note that GAN-based models require a considerable number of samples for training, which should be considered when assessing the practical applicability of CTABGAN. CTABGAN Plus is an extended version of the CTABGAN algorithm, designed to enhance the quality of synthetic data for machine learning utility and statistical similarity. This version introduces a new feature encoder tailored to variables following a single Gaussian distribution. It includes a redesigned shifted and scaled min-max transformation for normalizing these variables [24]. Additionally, CTABGAN Plus features a mixed-type encoder, which effectively represents mixed categorical-continuous variables and handles missing values. The algorithm utilizes the Wasserstein distance with a gradient penalty loss to improve the stability and effectiveness of GAN training [25]. Furthermore, an auxiliary classifier or regressor model is integrated to enhance synthesis performance for classification and regression tasks [24]. CTABGAN Plus introduces a newly designed conditional vector that uses log probabilities instead of original frequencies to address mode-collapse in imbalanced categorical and continuous variables [24]. Moreover, it integrates efficient Differential Privacy (DP) into tabular GAN training through the DP-SGD algorithm, which trains a single discriminator, reducing complexity [24]. The results show that CTABGAN Plus produces synthetic data with higher machine-learning utility and greater similarity than ten baselines across seven tabular datasets [24]. TVAE is a type of deep learning model that utilizes probabilistic modeling techniques to generate synthetic data [26]. VAEs are equipped with both an encoder and a decoder, which allows them to introduce a unique approach to the latent space and inherent variability in the generated data. To maximize the likelihood of observed data and minimize the divergence between the latent distribution and a predefined prior, VAEs use a reparameterization strategy that enables backpropagation through the stochastic sampling process [27]. While VAEs can enhance data augmentation and enrichment, they face challenges in handling discrete data and may experience information loss, posterior collapse, and sensitivity to prior distribution [28]. TabDDPM is a state-of-the-art generative model introduced by Kotelnikov et al. [13] that utilizes diffusion models to generate tabular data [29]. It applies noise to the input data through iterative diffusion and then reverses the process to create synthetic samples that closely resemble the original distribution [13]. TabDDPM addresses variations in feature types by preprocessing continuous features using Gaussian quantile transformation and representing categorical features with one hot encoding. The model employs multinomial diffusion for categorical features and Gaussian diffusion for continuous features, and each categorical feature undergoes a separate diffusion process [13]. A multilayer perceptron predicts Gaussian and multinomial diffusion outcomes during the reverse diffusion step. The training process minimizes mean squared error for Gaussian diffusion and KL divergence for multinomial diffusion [13]. TabDDPM has demonstrated strong performance on benchmark datasets, consistently generating high-quality synthetic samples compared to existing GAN or VAE-based models. NextConvGeN is designed to create synthetic tabular data using convex space learning. It generates synthetic samples similar to the original data by working within the boundaries of the original data neighborhoods [20]. The generator in NextConvGeN combines batches of closely located real data points to learn the convex coefficients. This process is repeated iteratively between two neural networks to learn convex combinations. NextConvGeN uses the same generator-discriminator architecture as ConvGeN [22] but is customized for tabular datasets. The generator operates on randomized neighborhoods of real data points rather than minority-class neighborhoods, which are determined using the Feature Distributed Clustering (FDC) approach. FDC effectively stratifies high-dimensional clinical tabular data [30]. The discriminator in NextConvGeN learns to classify synthetic points against shuffled batches of data points sampled from the complement of the input neighborhood provided to the generator, aiming to enhance classification performance. TabuLa, developed by Zilong Zhao et al. [31] in 2023, is a new LLM-based framework to synthesize tabular data. The primary goal of Tabula is to accelerate the convergence speed of LLM-based methods for tabular data synthesis tasks. Two notable state-of-the-art tabular data synthesizers, GReaT [32] and REaLTabFormer [33], are based on LLMs but are hindered by extensive training time. TabuLa addresses this challenge through four key features: i) Using a randomly initialized language model for data synthesis instead of relying on pre-trained models utilized in GReaT and RE-aLTabFormer. This strategic decision allows for a faster adaptation of the model to the requirements of tabular data synthesis tasks [31]. ii) Initialization of a foundational model from scratch and optimization specifically for tabular synthesis tasks, departing from the traditional reliance on pre-trained models [31]. This contributes to an effective learning process. iii) Reduction of token sequence length by consolidating all column"}, {"title": null, "content": "names and categorical values into a single token each. This significantly decreases training time and enhances the model's capability to efficiently learn and represent the relationships during training [31]. iv) Implementation of middle padding instead of the conventional left or right padding. This ensures that features within the same data column in the original data maintain identical absolute positions in the newly encoded token sequence, thereby enhancing the representation of tabular data for LLMs and resulting in improved synthesis quality [31]. The results of experiments using TabuLa on seven different datasets demonstrate that TabuLa reduces training time per epoch by an average of 46.2% compared to the current state-of-the-art algorithm based on LLMs. Additionally, TabuLa consistently achieves even higher utility with synthetic data [31]. Generative models discussed above have been evaluated based on the quality of the synthetic data, particularly in terms of utility and privacy measures. However, preserving inter-attribute dependencies in synthetic data has yet to be thoroughly explored. Preserving these dependencies is crucial for downstream analysis. The extent to which current models retain inter-attribute dependencies in the synthetic data remains an open question. Furthermore, there is no standard way to measure these dependencies. This study seeks to fill this gap by evaluating how well these models preserve functional and logical dependencies. It introduces a novel measure, the Q-function, to capture logical dependencies and utilizes the publicly accessible FDTool to identify functional dependencies. The detailed findings of this analysis are presented in Section 5."}, {"title": "3. Introducing the Q-function for quantifying inter-attribute logical dependencies", "content": "Using the notation from the introduction, we have a tabular dataset T with m \u2265 2 columns and n \u2265 1 rows. The term $T_{i,j}$ denotes the value in the i-th row and j-th column. The tuple $T_{i,A} = (T_{i,a1}, T_{i,a2}, T_{i,a3}, ...)$ represents the values of row i for the columns selected with the tuple A = (a1, a2, a3, ...). The set A = {$T_{i,a}$: i = 1, 2, ..., n} is the set of all tuples that exists in the table for the given selection of columns A. We defined the selection of columns B and the set of tuples B = {$T_{i,B}$: i = 1,2,..., n} for that selection in the same way. Define the relation ~$T\u2286 A \u00d7 B$ between A and B with a ~$r$ b holds if and only if a \u2208 A and b \u2208 B are in the same row in the table T (meaning there is an i so that\n$T_{i,A} = a$ and $T_{i.B} = b$).\nDefine C* = {(a1, . . .): {a1, ...} \u2286 {1, 2, 3, . . ., m}} as the set containing all possible selection of columns. The aim was to have a function $QT : C* \u00d7 C* \u2192 [0, 1]$ that:\n$QT(A, B)$ should be zero if the table and column selections produces a function\nf : A\u2192B\n$QT(A, B)$ should be one if for all a \u2208 A and all b \u2208 B the relation a ~$r$ b holds.\nEvery other value of $QT (A, B)$ should be between zero and one\nWe construct this function as follows: For a given a \u2208 A we can count how many b\u2208 B holds a ~$r$ b by |D(a)| = |{b \u2208 B: a ~$r$ b}|. The more values are excluded, the closer we are to a function that takes this a and gives us a b. If there is a function from A to B for this value a, then |D(a)| = 1. By the definition of our table (not empty) and A, B (= sets of the actual values in the table) we know that |D(a)| has to be greater or equal to 1. By subtracting 1, we get: n' = |D(a)| \u2212 1 \u2265 0 If a ~$r$ b for all b \u2208 B for this a \u2208 A then n' = |B| \u2013 1. Assuming |B| > 1 we can divide this value and get the function:\n$GB(a) = \\frac{|D(a)| - 1}{|B|-1}$ that maps to the interval [0, 1]. We can collect this information for all a \u2208 A by\n$so = \\sum_{a \\in A} GB(a) = \\sum_{a \\in A} \\frac{|D(a)| - 1}{|B|-1}  = \\frac{1}{|B|-1} \\sum_{a \\in A} (F(a) - 1)$\nWe can easily see that 0 \u2264 so \u2264 |A|. Dividing |A| gives us one solution to our wishlist for B > 1:\n$s1 = \\frac{so}{|A|} =  \\frac{1}{|A|(|B|-1)} \\sum_{a \\in A} (|{b \u2208 B: a ~T b}| - 1)$\nIf we put a in the set, we can omit the sum and get the easier term:\n$s1 = \\frac{|{(a,b): a \u2208 A, b \u2208 B and a ~r b}| \u2013 |A|}{|A|(|B|-1)}$"}, {"title": null, "content": "For the special case that there is only one value in column B (e.g. B = {b}) we have the obvious constant function f(a) = b. In the special case of an empty set A or empty set, B, there is no pair left to disprove the existence of a function. This leads to our final definition:\n$QT(A, B) = \\begin{cases}\n\\frac{|\\{(a,b): a\u2208A,b\u2208B \\text{ and } a~rb\\}|-|A|}{|A|\u22c5(|B|\u22121)} & \\text{if } |A| \u2265 1 \\text{ and } |B| > 1 \\\\\n0 & \\text{if } |A| = 0 \\text{ or } |B| \u2264 1\n\\end{cases}$\n(1)"}, {"title": "4. Experimental protocols", "content": "Preserving logical and functional dependencies is essential for assessing the quality of synthetic tabular data. To address this, we conducted a comparative study to investigate how well different generative models preserve these dependencies. The experimental workflow in Figure 1 involved generating synthetic tabular data using CTGAN, CTABGAN, CTABGAN Plus, TVAE, NextConvGeN, TabDDPM, and TabuLa. The following are the steps involved in the experiment:\nData preparation and model training: We used seven well-known generative models for effectively generating synthetic tabular data. Unlike the usual practice of splitting data into training and testing subsets, we trained the models on the complete tabular dataset. This approach ensured that the models were fully exposed to the nuances of the data, potentially improving their ability to replicate the underlying inter-attribute relationships. We used the default parameters to train all models.\nGeneration of synthetic data: After training each generative model, we generated synthetic data of the same size as the original dataset, ensuring equal comparisons between real and synthetic data and facilitating a more accurate evaluation of the models' performance.\nExtraction of functional and logical dependencies: We utilized the FDTool algorithm [16] to extract functional dependencies from real and synthetic datasets, focusing on categorical features. We employed the Q-function approach outlined in this paper to evaluate logical dependencies. Following this, we graphed the"}, {"title": null, "content": "Q-scores for the real and synthetic data and identified feature pairs with similar scores in both datasets, revealing logical dependence.\nComparative analysis: We used Venn diagrams to compare the functional dependencies in real and synthetic datasets. These diagrams show where the dependencies overlap, clearly showing how well the generative models maintain functional relationships between the attributes (Figure 4 and 5. Additionally, we used bar plots to illustrate the percentage of logical dependencies preserved by the synthetic data compared to the real data. This visual representation makes it easier to understand how each model performs (Figure 3)."}, {"title": "4.1. Datasets used in the comparative analysis:", "content": "There are no well-known datasets that have functional and logical dependencies. Finding datasets with such conditions is difficult. We have chosen five publicly available datasets for our bench-marking analysis. The choice of datasets covers a variety of situations, including observational studies, clinical trials, and surveys; therefore, it is more comprehensive. There is also variation in the number of attributes they contain, ranging from one to 11 continuous attributes and from eight up to 17 categorical attributes, and the size of datasets varies from 377 to 4908."}, {"title": "5. Results", "content": "Our experiment is designed to assess the ability of tabular generative models to retain inter-attribute logical and functional relationships from real data to synthetic data using the Q-function and FDTool algorithms."}, {"title": null, "content": "GAN-based and VAE models fail to capture logical dependencies in the data:\nFor features $f_i$ and $f_j$ in a tabular data T, the smaller the value of |$Qr({fi}, {fj}) - Qs ({fi}, {fj})$| the better the functional and logical dependencies are preserved for a synthetic table S. We investigated this with various generative models and noticed that CTGAN, CTABGAN, CTABGAN Plus, and TVAE do not always effectively maintain logical connections compared to other generative models (refer to Figure 3). One explanation is that training GANs requires a large amount of data, and our experiments were conducted using small tabular datasets, which is more consistent with real-world scenarios from the biomedical domain. We observed that, among the GAN models, CTGAN showed comparatively better performance in preserving logical dependencies in the Stroke dataset due to its relatively larger size (4908 samples). From Figure 9, we can deduce that the CTGAN-generated synthetic Stroke data produces a similar Q-score compared to real Stroke data for more feature pairs, as we observe that there are more points along the diagonal line of the plot. On the other hand, CTABGAN failed to maintain a single logical dependency, except for the Airbnb dataset, which had a preservation rate of only 0.68%. This lack of preservation can be observed in Figures 6, 8, 9, 10, where all the points lie at one, indicating no dependencies between feature pairs. Our results indicate that the CTABGAN model focuses on modeling multimode and long-tail distributions rather than preserving dependencies. Interestingly, the CTABGAN Plus model, despite having fewer data points, exhibited a higher percentage of logical dependency preservation in the Migraine dataset compared to other datasets. Note that the Migraine dataset contains 17 categorical attributes, the highest among all the datasets used in the experiment. The CTABGAN Plus model incorporates a specialized encoder to effectively handle mixed categorical attributes, making it adept at capturing relationships and distributions within categorical attributes, contributing to its superior performance in logical dependency preservation. The TVAE could capture logical dependencies only for the Airbnb dataset, for which it achieved a preservation rate of around 56.79%. The main reason behind this limitation of TVAE is the phenomenon of mode collapse. TVAEs compress the data into a latent space where each dimension captures some aspect of the data. However, the"}, {"title": null, "content": "dominant category may occupy a larger portion of the latent space for imbalanced attributes. This could cause the model to generate the same value for the entire column, which is not ideal for analyzing logical dependencies between attributes. Therefore, GANs and TVAEs may not be the best choice for certain datasets where logical dependencies between attributes are important and require accurate modeling. Convex space, diffusion-based, and transformer-based models are effective in preserving logical dependencies: A direct illustrative comparison of NextConvGeN, TabDDPM, and TabuLa models can be seen in Figure 3. Our experiments imply that the NextConvGeN model performs well in Liver Cirrhosis and Migraine, with logical dependencies captured up to 86.39% and 100%, respectively. In comparison, TabDDPM retains 75% and 80.92% of the logical dependencies in the Liver Cirrhosis and Migraine datasets and all the dependencies in the Stroke dataset. On the other hand, TabuLa can preserve most of the inter-attribute logical dependencies present in real data for all datasets. Our results indicate that TabuLa, TabDDPM, and NextConvGeN produce comparable performances in the context of logical dependency preservation, and these three models are superior to the rest of the compared models. None of the generative models satisfactorily preserved inter-attribute functional dependencies: Two datasets that exhibit functional dependencies are Airbnb and Migraine. The Migraine dataset displays 136 functional dependencies, while the Airbnb dataset has 32 functional dependencies. Tabular generative models tested on these datasets demonstrate that they can rarely capture the functional dependencies present in these datasets (See Figure 5 and 4). In particular, CTGAN, CTABGAN Plus, and TVAE could not capture functional dependencies in the two mentioned datasets. Interestingly, in the synthetic data generated by CTABGAN, functional dependencies were observed that were not present in the real data. NextConvGeN managed to preserve only nine out of the 136 functional dependencies in the Migraine dataset and none in the Airbnb dataset. TabDDPM preserved four functional dependencies in the Migraine dataset and 17 in the Airbnb dataset, but it also resulted in several functional dependencies that were not present in the actual data. TabuLa preserved 13 functional dependencies in the Airbnb dataset and none in the Migraine dataset. These results highlight the inability of current generative models to capture functional dependencies, particularly in datasets with a higher number of categorical features. While these models aim to generate synthetic data that resembles real data properties without compromising privacy, they were not designed to preserve functional dependencies. However, we would also like to point out that preserving functional dependencies in synthetic data can be challenging, as even a single contradiction in a data point in the synthetic data disregards two attributes in the synthetic dataset to be functionally dependent. In conclusion, observed that, unlike logical dependencies, current tabular generative models struggle to retain functional dependencies in synthetic data."}, {"title": "6. Discussion", "content": "One intriguing question that arises from our experiments is why GAN and VAE-based models are not as effective in preserving inter-attribute logical relationships as convex-space, diffusion, and transformer-based models. One key distinction is that GAN-based models rely on a generative approach that does not directly utilize real data to create synthetic samples. Instead, these models aim to map random noise to the distribution of the training data. This poses challenges when working with limited data, often encountered in several practical scenarios, such as clinical data obtained from a single healthcare facility, as substantial training data is required. On the other hand, NextConvGeN, TabDDPM, and TabuLa use real data to generate synthetic samples. NextConvGeN produces samples from the convex hull of a sampled data neighborhood, while TabDDPM adds noise to real data (forward diffusion) and then iteratively denoises the real data (reverse diffusion) to generate synthetic data. Additionally, TabuLa utilizes real data for model training by converting each row into a format of sentence in a text. Since these approaches have access to real data while generating synthetic data, we argue that they produce superior results in preserving inter-attribute logical dependencies. This can be observed in Figures 6, 7, 8, 9, 10, which demonstrate inter-attribute logical dependencies between the real data and its respective synthetic data generated using seven generative models. Figures 6, 7, 8, 9, 10 show how closely the Q-scores of the synthetic data align with those of the real data, indicating the preserved dependencies along the diagonal line. Note that in Figure 3, for small clinical tabular data (Liver cirrhosis and Migraine data), TabuLa, TabDDPM, and NextConvGeN outperform GAN-based models in preserving inter-attribute logical relationships. A comparison of the Q-scores of real and synthetic Liver Cirrhosis data (418 samples) from seven generative models is shown in Figure 10, indicating common dependencies along the diagonal line. TabuLa, TabDDPM, and NextConvGeN demonstrate the unique ability to capture specific logical dependencies, whereas GAN-based and TVAE models do not exhibit this capability. Notably, the Q-scores of synthetic data are consistently one for all GAN-based models, suggesting that these models failed to capture a single dependency present in real data, possibly due to the limited training data."}, {"title": null, "content": "It is important to note that even if any model preserves 100% of the inter-attribute logical dependencies, the Q-scores of real and synthetic data may not always align on the diagonal line when plotted. For instance, in the case of Stroke data generated by the TabDDPM model, the total number of inter-attribute logical dependencies in real data is 12. The synthetic Stroke data generated by TabDDPM also has 12 inter-attribute logical dependencies, and all inter-attribute logical dependencies from the real data are preserved in the synthetic data as shown in Figure 3 (preserved logical dependencies of Stroke data generated by TabDDPM is 100%). However, when we plot Q-scores of real and synthetic data (See TabDDPM plot in Figure 10), only some points fall on the diagonal line, indicating common dependencies. Ideally, we expect all the points to be on the diagonal. This discrepancy occurs because the synthetic data introduces additional dependencies on a particular feature pair absent in the real data, thereby altering the Q-scores. The calculation of Q-scores depends entirely on the conditional probabilities between feature pairs. For instance, consider features A and B, where feature A has three classes and feature B has four. The conditional probabilities of feature pairs in real and synthetic data are provided by Tables 3 and 4. When we calculate the Q-scores for this feature pair in real and synthetic data using Equation 1, we get 0.87 for real data and 0.75 for synthetic data. The synthetic data maintains the underlying relationships found in real data, such as the probability of feature A belonging to class 2 given that feature B belongs to class 0. However, the Q-scores differ due to the existence of additional logical dependencies between attributes in the synthetic data, such as the probability of feature A being in class 0 or 1 given that feature B is in class 0. This is an empirical explanation for why not all data points align perfectly along the diagonal line. Furthermore, mode collapse is a common issue observed in TVAE and CTABGAN Plus models. This occurs when generative models converge on a limited set of outputs, resulting in the same value for an entire feature, particularly in cases of high imbalance. When a feature has the same value for all rows, it indicates that this feature is functionally dependent on other features in the dataset. In Figure 6, Migraine data generated by TVAE exhibited Q-scores of 0 for many feature pairs (154 out of 272), indicating that these feature pairs are functionally dependent. In contrast, these pairs logically depend on real data as the scores lie between 0 and 1. Furthermore, TVAE's encoding of information compression in the latent space may limit the decoder's ability to reconstruct all target classes accurately. On the other hand, NextConvGeN's approach involves training generators within each minority sample neighborhood and generating samples accordingly. Our study demonstrates that Tabula, a transformer-based model, outperformed other models in maintaining inter-attribute logical dependencies across various datasets. This is evident from the Figure 3. The self-attention mechanism of TabuLa enables it to capture more inter-attribute logical dependencies than other models. Generally speaking, self-attention calculates the response at a position in a sequence by attending to all positions within the same sequence. The attention mechanism"}]}