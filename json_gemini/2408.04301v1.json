{"title": "Tackling Noisy Clients in Federated Learning with End-to-end Label Correction", "authors": ["Xuefeng Jiang", "Sheng Sun", "Jia Li", "Jingjing Xue", "Runhan Li", "Zhiyuan Wu", "Gang Xu", "Yuwei Wang", "Min Liu"], "abstract": "Recently, federated learning (FL) has achieved wide successes for diverse privacy-sensitive applications without sacrificing the sensitive private information of clients. However, the data quality of client datasets can not be guaranteed since corresponding annotations of different clients often contain complex label noise of varying degrees, which inevitably causes the performance degradation. Intuitively, the performance degradation is dominated by clients with higher noise rates since their trained models contain more misinformation from data, thus it is necessary to devise an effective optimization scheme to mitigate the negative impacts of these noisy clients. In this work, we propose a two-stage framework FedELC to tackle this complicated label noise issue. The first stage aims to guide the detection of noisy clients with higher label noise, while the second stage aims to correct the labels of noisy clients' data via an end-to-end label correction framework which is achieved by learning possible ground-truth labels of noisy clients' datasets via back propagation. We implement sixteen related methods and evaluate five datasets with three types of complicated label noise scenarios for a comprehensive comparison. Extensive experimental results demonstrate our proposed framework achieves superior performance than its counterparts for different scenarios. Additionally, we effectively improve the data quality of detected noisy clients' local datasets with our label correction framework. The code is available at https://github.com/Sprinter1999/FedELC.", "sections": [{"title": "1 INTRODUCTION", "content": "The pervasiveness of mobile devices contributes more than half of the internet traffic [58], which empowers a variety of intelligent applications. To exploit these distributed datasets from these mobile clients in a privacy-preserving manner, federated learning (FL) [31, 38, 60] has evolved as a promising collaborative training paradigm, which has shown significant successes in real-world applications like health-care [63, 67] and recommendation system [53, 68].\nData are often not independent identically distributed (Non-IID) across all clients, and many methods have been proposed to address the data heterogeneity or challenge in recent years. Another potential issue concerning incorrect labels (a.k.a. noisy labels) contained in client-side datasets has been long overlooked. Specifically, it is hard to promise the client-side datasets are well-annotated in practice. Each client is usually not given enough incentives [75] to provide a well-annotated dataset, while the server is not authorized to directly and accurately inspect the data quality of the client datasets due to privacy concerns [18]. More commonly, these client-side datasets tend to contain varying degrees of label noise since different clients have diverse approaches to collecting annotations or have respective limited budgets to annotate their datasets. As deep neural networks have the capacity to fit local datasets containing noisy labels [2], the negative information from incorrect data can be injected into model parameters, further perturbing the overall training of FL. Therefore, data with noisy labels pose critical challenges in the real-world applications of FL, which evidently decrease the convergence rate and final performance of FL [21]. To tackle these challenges, there have been some early attempts [10, 18, 69] to improve the trained model's robustness against noisy labels in the recent two years. However, these methods often neglect one challenge that different clients tend to have distinctly inconsistent label noise rates. Specifically, different clients tend to have different annotation quality in practice [21, 65]. Even worse, some underlying malicious clients might aim to provide low-quality datasets containing high label noise rate to perturb the FL training on purpose [52]. In the practical noisy scenario, clients with high noise rates play detrimental roles in the model performance of FL since more negative information is injected into their trained models caused by data with higher label noise [21]. Therefore, it is of significance to devise the specific training scheme for noisy clients with higher noise rates. One recent state-of-the-art method FedNoRo [63] attempts to detect noisy clients via exploiting a two-component Gaussian mixture model [37] based on fine-grained indicators, and then applies different robust loss terms for detected clean clients and noisy clients. All aforementioned methods only focus on improving robustness against the label noise, however, they neglect the potential of correcting the underlying noisy samples in client-side datasets to further improve model performance of FL, especially for clients with higher label noise rates.\nIn this work, we focus on the challenge of FL regarding data quality, where the clients can have heterogeneous data and different noise rates. The participating clients can be divided into the relatively clean group and the relatively noisy group, referring to FedNoRo [63]. Considering that the detected noisy clients have more negative impacts on the final performance of the trained model, we exploit an end-to-end label correction scheme to gradually refine the corrupted local datasets of the detected noisy clients. Specifically, a differentiable variable is designed to model the possible underlying ground-truth label distribution of each sample. We incorporate this variable into the optimization objectives of the local update procedure, and both the model and this variable can be simultaneously updated through the back propagation. To put it briefly, our main contributions can be summarized as follows:\n\u2022 We present a two-stage robust FL framework to tackle clients of different noise rates. The first stage aims to detect the underlying noisy clients and the second stage aims to correct labels of detected noisy clients via end-to-end label optimization.\n\u2022 We implement sixteen baseline methods for comparison, and showcase the superiority of our proposed method against its counterparts through extensive experiments on multiple label noise scenarios derived from four benchmark datasets.\n\u2022 We further evaluate the effectiveness of our method on one large-scale real-world Clothing1M dataset, which contains one million images crawled from several famous shopping websites annotated with complicated systematic noisy labels."}, {"title": "2 RELATED WORKS", "content": ""}, {"title": "2.1 Federated Learning", "content": "Federated learning (FL) is an emerging distributed machine learning paradigm across clients over the network, which provides an opportunity to further exploit the distributed client datasets [20, 34, 38]. One general issue in such distributed datasets is data distributions from different clients are usually non-identically distributed (non-IID). There are many previous works addressing this issue and herein we discuss some representative methods. FedAvg [38] averages updated model parameters to aggregate diverse information from client datasets. FedProx [32] proposes a proximal term during the client-side local update phase to restrain the local model parameters from deviating too much from the received global model parameters of the current communication round. Favor [57] aims to learn an optimal client subset selection strategy based on deep Q-learning [15]. FedMC [6] proposes a personalized FL optimization framework via meta learning [16] which also supports heterogeneous local model architectures. More recently, FedExP [17] speeds up FedAvg via parameter extrapolation on the server side. To support training with lower computation costs in the deployment of FL, some works propose light-weight training strategies like model pruning and parameter sparsification [36, 66, 77]. Above methods mainly focus on the non-IID issue of distributed client datasets, which we name by general FL methods. However, besides the non-IID issue, another challenge is long neglected. That is, to provide a high-quality annotated dataset is too expensive [51] which requires much human effort and expertise. Some methods like utilizing crowd-sourcing [52] and machine-generated labels [18, 22, 69] seem to be lower-cost approaches to annotating a collected dataset. In the specific context of FL, since the central server cannot enforce clients' behavior [52], data are more easily to be annotated with noisy labels. Meanwhile, owing to the extremely high expressive power of deep networks, networks can memorize training data even when labels are extremely noisy [50]. Training on data with wrong labels (i.e. noisy labels) evidently decreases the convergence rate and final performance [18, 69]."}, {"title": "2.2 Noisy Label Learning", "content": "To tackle data with noisy labels is widely discussed in centralized learning scenarios, so we firstly discuss some representative noisy label learning (NLL) methods [12, 41, 51]. One prominent research direction aims to conduct sample selection. Co-teaching [13] and its derivative method Co-teaching+ [72] simultaneously maintain two peer networks of the same architecture with different initialization. For each batch, each network selects samples from the batch to its peer network according to different techniques. For instance, Co-teaching supposes samples with lower losses are more reliable and they are selected and fed into its peer network to perform training with more reliable supervision information. Another prominent research line focuses on designing robust loss [61] or robust training strategies [27, 50, 54]. Since the given labels can be noisy and the model can give correct predictions, Symmetric Cross Entropy (Symmetric CE [61]) includes the model prediction into loss terms. Tanaka et al. [54] propose joint optimization framework (Joint Optim), which can correct labels during training by alternating update of network parameters and labels."}, {"title": "2.3 Federated Noisy Label Learning", "content": "In the community of FL, to address the label noise issue, a simple research line of studies aims to design robust aggregation methods [5, 30, 71] instead of simply averaging the model parameters used in many previous works [32, 38]. One commonly utilized aggregation method Median [30] is based on the median value of the clients' models, instead of the weighted averaged value as FedAvg. In this way, extremely bad weights may affect less to the global model. Similarly, TrimmedMean [71] removes the largest and smallest one for each parameter of selected clients' models, and computes the mean of the remaining parameters as the global model. Krum [5] firstly computes the nearest neighbors to each local model. Then, it calculates the sum of the distance between each client and their closest local models. Finally, it selects the local model with the smallest sum of distance as the global model. These methods mainly focus on decreasing the effects of bad model weights caused by noisy labels via more robust aggregation methods, but they do not directly tackle the data with noisy labels. There are also some emerging methods that aim to directly deal with the noisy labels in the context of FL, and we name them by federated noisy label learning (FNLL) methods [18, 63]. To the best of our knowledge, Robust FL [69] is the first work to directly deal with data with noisy labels without the requirement of extra perfectly-annotated auxiliary dataset [18, 65], which collects the local class-wise centroids to form global averaged class-wise centroids as extra global supervision to regularize the local training phase. However, the transmitted class-wise centroids carry sensitive information of client data, which can be easily exploited to reveal private information via inverse engineering [18, 49]. To further maintain data privacy, FedLSR [18] proposes a local regularization method based on self-distillation [1]. FedRN [20] maintains a server-side client model pool to exploit reliable neighbor models (RN) for each client, where the RNs refer to the models owned by other clients that possess data of similar distributions or lower label noise. FedRN then detects clean samples for each client, using ensembled Gaussian Mixture Models trained to fit loss function values of local data assessed by these RNs. A recent work FedNoRo [63] proposes a two-stage framework to identify the noisy clients and design different local optimization objectives for clean clients and noisy clients, which reports a satisfying noisy client detection accuracy and final performance of the trained model. Different from the above FNLL methods, RHFL [10] supports different client model architectures with the assistance of an auxiliary dataset which is a hard assumption in practice, so we do not include RHFL for evaluations. Meanwhile, we find the experimental settings are not unified to a certain degree. For example, some works [10, 18, 69] neglect the Non-IID characteristic of FL. Therefore, we cover more general settings that approximate the diverse label noise scenarios in practice. We prepare Table 1 to better illustrate the differences (especially in the methodology and experimental settings) between our method and related works that we implement and evaluate in this study."}, {"title": "3 PRELIMINARY", "content": ""}, {"title": "3.1 Problem Definition", "content": "Without loss of generality, assume the federated learning (FL) system consists of N clients and a server. Let S represent the set for all N clients. Each client indexed by k maintains a local dataset with $n_k$ samples $D_k = \\{(x_i, \\hat{y}_i)\\}_{i=1}^{n_k}$, and we denote the total data quantity as $n = \\sum_{k \\in S} n_k$. Note that the one-hot label $\\hat{y}_i$ can be noisy and we denote the unknown real ground-truth label is $y^*$. The overall objective of FL is solving the optimization problem for N clients over their own local datasets, which can be formulated as:\n$\\min_w f(w) := \\sum_{k \\in S} \\frac{n_k}{n}F_k(w)$.\nLocal objective of client k is to minimize empirical risks on $D_k$:\n$F_k(w) = E_{(x,y) \\sim D_k}[l_f(\\hat{y}, f_k(x; w_k))]$,\nwhere $l_f$ is the loss function on the $k$ - th client local dataset and $f_k(x; w_k)$ is the local prediction on each sample x with the local trained model parameterized by $w_k$."}, {"title": "3.2 Label Noise Patterns", "content": "Herein we discuss three common label noise patterns in our study:\nManually-injected label noise We use the label transition matrix M to add manual label noise to local datasets, where $M_{i,j}$ = flip($\\hat{y} = j \\mid y^* = i$) represents that the true ground-truth label $y^*$ is flipped from the clean class i to the noisy class $\\hat{y}$. There are two commonly-used structures for the matrix M [10, 18, 69], symmetric flipping and asymmetric (or pairwise) flipping [13, 45]. Symmetric flipping means that the original class label will be flipped to any wrong class labels with equal probability. For asymmetric flipping, it means that the original class label will only be flipped to another wrong category. In FL, given the maximum noise rate e, we generate each client k with corresponding noise level increasing linearly from 0 to e as the client's index k increases. Besides the symmetric and asymmetric label noise scenarios, inspired by FedRN [20], we also generate mixed label noise scenario where clients are divided into two halves, and one half of clients follow the symmetric label noise and the remainder follows the asymmetric label noise.\nHuman annotation error caused label noise Evaluations on datasets approximating real-world human annotation error patterns are less considered in previous works. Fortunately, Amazon Mechanical Turk provides CIFAR-N [62] datasets, which collect labels purely from human annotators. These datasets begin to be utilized in some recent attempts [21, 56, 62]. There are several versions of CIFAR-N datasets, and we utilize the CIFAR-10-N-Worst and CIFAR-100-N-Fine since they possess the highest noise rates. The noise rates are 40.208% and 40.200%, respectively.\nSystematic label noise In practice, it is expensive to obtain high-quality labels for large-scale datasets. One commonly-utilized method is to collect images from websites and yield annotations by filtering out the surrounding context (e.g. image captions [47]) in the web page. Clothing1M [64] is a large-scale real-world dataset of 14 categories, which contains 1 million images of clothing with noisy labels crawled from several famous online shopping websites. It is reported that the overall noise ratio is approximately 38.46% and contains unstructured complicated label noise [43]."}, {"title": "4 METHOD", "content": "To deal with the complicated issue introduced by heterogeneous and noisy clients, we propose a two-stage method FedELC as illustrated in Figure 4. During the first stage, all clients are orchestrated to follow the FedAvg [38] procedure to aggregate client updated models, which is used in previous works [18, 63, 69]. The first stage (stage #1) mainly aims to divide the total clients into one relatively clean group and the other relatively noisy group. The second stage (stage #2) mainly aims to gradually correct the data with noisy labels located at noisy clients which are detected in the stage#1."}, {"title": "4.1 Stage #1: Noisy Client Detection", "content": "Our method is divided into two stages where stage #1 lasts for $T_w$ global communication rounds. We follow FedNoRo [63] to perform the first stage. During the stage#1, a warm-up model is firstly trained based on FedAvg [38]. When the stage#1 ends, we exploit a two-component Gaussian Mixture Model (GMM) to divide total clients into a relatively clean group and a relatively noisy group.\nFor the each round t in the first stage, each selected client k updates the local model with the vanilla cross entropy loss and conduct model aggregation with FedAvg in Eq. 3. Different from the original FedAvg [38], considering the local data heterogeneity, each selected client firstly computes the local class distribution $\\pi$ of the local dataset, which is often used as class prior. We use this class prior $\\pi$ to conduct logit adjustment [39] before we compute the vanilla cross entropy loss, which is demonstrated to be effective in previous works [39, 55, 76] and used in FedNoRo. As discussed in [63], logit adjustment is to make the local model treat each class equally rather than being biased. We use $\\theta$ to denote the current trained local model weight of w. For a sample (x, $\\hat{y}$), the model yields the output prediction p = f(x;$\\theta$). We use this prior $\\pi$ to adjust the logit into $p + \\log(\\pi)$ before computing cross entropy (CE) loss, and then we formulate the local training objective as:\n$L_{cls} = CE(p, \\pi, \\hat{y})$\nAfter $T_w$ global training rounds, we conduct the noisy client detection. Many previous works aim to conduct noisy client detection [8] with the overall local loss value. For example, one commonly used assumption is that samples with higher loss are more likely to be mistakenly labeled [2, 13, 69], thus clients with higher loss are more possible to be noisy clients. However, since each client in FL possesses Non-IID data, such coarse grained division technique can be less effective as analyzed in [63, 65].\nFollowing FedNoRo [63], we consider one fine-grained class-aware noisy client detection method. For each client indexed by k participating in FL training, each client used the global model $w^{T_w}$ of $T_w$ \u2013 th global round to compute the local class-wise loss. The average loss values of all classes on each client k denoted as $l_k = (l_1, ...., l_M) \\in R^M$ do not contain private information, and they are transmitted to the server for further noisy client detection. Since we have N clients in total, now we construct a loss matrix $L = [l_1, l_2, l_3, ..., l_N] \\in R^{N*M}$, which reflects the client-wise per-class loss vectors. Then, a two-component GMM is deployed onto L to partition all N clients into two subsets: the relatively clean group $S_{clean}$ and detected relatively noisy group $S_{noisy}$. More details are available in [63]. We analyze its performance in Section 5.5."}, {"title": "4.2 Stage #2: End-to-end Label Correction", "content": "Now we have two groups $S_{clean}$ and $S_{noisy}$. For clients in $S_{clean}$, we use the same optimization objective in Eq. 4 to conduct local update (more explanations in Section 5.2). For clients in $S_{noisy}$, to further exploit data from detected noisy clients, we adopt the following method to conduct both robust local model update and local data refinery by end-to-end correcting the local labels inspired by [70] which shows promising noisy label refining performance.\nEnd-to-end label correction For starters, we clarify concepts of hard/soft label for M-way classification. We denote 1 is a vector of all-ones. For the label of a certain sample, the one-hot hard label space is $H = \\{y : y \\in \\{0, 1\\}^m, 1^T y = 1\\}$, and the soft label space is $S = \\{y : y \\in [0, 1]^m, 1^T y = 1\\}$, which reflects a probabilistic label distribution. For a sample (x, $\\hat{y}$) in the local dataset, we suppose it has the unknown ground-truth label $y^*$, and both $y^*$ and $\\hat{y}$ is a one-hot hard label. We initialize a distribution $\\tilde{y} \\in S = \\{y : y \\in [0,1]^m, 1^T y = 1\\}$ to denote our estimation of the underlying pseudo-ground-truth soft label distribution, which is initialized by the original $\\hat{y}$ and can be gradually updated via back propagation:\n$\\tilde{y} = K\\hat{y}$,\n$\\tilde{y}_d = SoftMax(\\tilde{y})$,\nwhere $\\tilde{y}$ is a differentiable variable which can be updated by back propagation and K is a large constant (K = 10 by directly following the original implementation of [70]).\nFor noisy clients, the local optimization objective is combined of three terms. The first one is the basic classification loss $L_c$. Rather than using the original label $\\hat{y}$, we compute the classification loss between the model prediction p and the learnable distribution $\\tilde{y}$:\n$L_c = CE(p, \\tilde{y})$\nThe second one is compatibility regularization loss. For most scenarios where the noise levels of most clients are not too high, the original label $\\hat{y}$ can also provide useful supervision [70]. In other words, for the overall samples, the optimized distribution $\\tilde{y}$ should not be very far from the original labels $\\hat{y}$. Therefore, the compatibility regularization loss can be formulated as:\n$L_{comp} = Compatibility(\\hat{y}, \\tilde{y}) = - \\sum_{m=1}^{M} \\hat{y}_m \\log(\\tilde{y}_m)$.\nThe third one is entropy regularization loss, which is used in FedLSR [18], Robust FL [69] and semi-supervised learning methods [11, 27]. The main target is to encourage the model to output sharper and more confident prediction, which can be formulated as:\n$L_e = Entropy(p) = \u2013 \\sum_{m=1}^{M} p_m \\log(p_m)$,\nwhere $p_{model}$ is the model's output softmax probability for the m - th class. Combining all three terms together, we form triplet supervision for the detected noisy clients as follows\n$L = L_c + \\alpha * L_{comp} + \\beta * L_e$,\nwhere $\\alpha$ and $\\beta$ represent the trade-off coefficients to balance these loss terms. $L_e$ and $L_{comp}$ provide supervisions to optimze the learnable $\\tilde{y}$, thus, the optimzation process of y can be formulated as\n$\\tilde{y} = \\tilde{y} - \\eta * \\nabla_{\\tilde{y}}$\nNote that the learning rate $\\eta$ for $\\tilde{y}$ is different from the learning rate for the optimized model $\\theta$. We elaborate more on its selection in Section 5.4. After E epochs of local updating, we can provide our estimation of the corrected label which is an approximation of the possible ground-truth label $y^*$ via fusing two ways of estimation including the trained model's prediction and the updated $\\tilde{y}$.\nWe record the wall-clock training time of the clean clients and noisy clients, and on average the training time of noisy clients is almost \u00d70.3 longer than clean clients. Therefore, considering the computation cost and noisy clients can have higher risks to bring negative impacts to FL training, we choose to apply the end-to-end correction procedures only to the detected noisy clients.\nDistance-aware (DA) aggregation In the second stage, besides the label correction operation, we refer to exploit distance-aware aggregation method instead of the vanilla model averaging of FedAvg [38]. Considering the co-existing of the clean and the noisy clients, intuitively, models from clean and noisy clients are of different importance. Inspired by robust aggregation method Krum [5] and previous FL method [33, 63], we utilize one commonly-used distance-aware client-wise distance metric is defined as\n$d(i) = \\min_{j \\in S_t} ||w_i - w_j||^2$,\nwhere $w_i$ indicates the weights of local model of $i$ \u2013 th client. This metric measures the distance between a model $w_i$ and the nearest model of other clients. Note that d(i) is equal to 0 if $i$ \u2013 th client is clean. Considering the bound of d(i), it is further normalized to [0, 1] as $D(i) = \\frac{d(i)}{\\max_{j \\in S_t} d(j)}$. Then, local models are aggregated to update the global model by\n$w^{t+1}= \\frac{\\sum_{i \\in S_t} n_i e^{-D(i)} w_i}{\\sum_{j \\in S_t} n_j e^{-D(j)}}$.\nIn this way, the aggregation weight of any clean client is constant due to D(i) = 0, while the weights of noisy clients are multiplied by a scaling factor in [0, 1]. Moreover, the weights would decrease as the model distance increases, adaptively adjusting the contributions of noisy clients in global model updating [63]."}, {"title": "5 EXPERIMENTS", "content": ""}, {"title": "5.1 Experimental Setup", "content": "Datasets In this study, we consider three types of label noise (detailedly discussed in Section 3.2) and conduct experiments on five datasets and their statistics are shown in Table 2. We normalize the images by the dataset's overall mean and standard deviation [42]. For data heterogeneity, we utilize Dirichlet distribution to distribute total data to different clients, where each client is assigned with training data partitioned from the Dirichlet distribution with a concentration parameter y, where a lower y indicates a higher Non-IID degree [29]. We set y to 1.0 and 0.5 to generate two Non-IID degree. For CIFAR-N datasets, we additionaly conduct experiments with IID partitioning, since it is less explored in previous works.\nBaselines For main experiments, we implement sixteen state-of-the-art methods (discussed in Section 2 and Table 1). Unless otherwise specified, most hyperparameters of these methods are configured favorably in line with the original literature. We refer to official open-source codes of these methods. For convenience, we clarify some important hyper-parameter settings as follows:"}, {"title": "5.4 Sensitivity & Ablation Study", "content": "Herein we elaborate on the robustness of FedELC by conducting ablation study on hyper-parameter selection and two utilized techniques in our framework. Experimental settings are in accordance with the setting of CIFAR-10 of manual label noise (0.0 \u2013 0.4).\nSensitivity on the hyper-parameter selection We study the sensitivity of introduced hyper-parameters and the experimental results are shown in Figure 2. From these results, we can observe that: (1) Our method has robust performance on the selection of the trade-off coefficients $\\alpha$ and $\\beta$. The recommended selection is that $\\alpha$ and $\\beta$ are smaller than 0.5. (2) A larger $T_w$ can lead to higher final performance. (3) Our method has robust performance on the selection of $\\eta$ while a mild learning rate $\\eta$ for $\\tilde{y}$ updating can lead to a slightly better performance. A small $\\eta$ yield a slight performance degrade and perhaps it is because a small $\\eta$ leads a slow update of the $\\tilde{y}$ and also decreases the training efficiency. For guidance, when applying to other datasets, it is suggested to observe the gradient value of $\\tilde{y}$ to select the suitable $\\eta$ which can effectively update $\\tilde{y}$.\nAblation on the logit adjustment & model aggregation We conduct ablation experiments in Table 7 by removing the logit adjustment technique [39] discussed in Eq. 4 and DA aggregation technique [63]. The performance get degraded by removing each, which reflects the effectiveness of these incorporated techniques."}, {"title": "5.5 Analysis on Noisy Client Detection", "content": "Here we visualize the detection and average noise rates within detected clean group and noisy group in Figure 3. Experiments are repeated for five times. For datasets containing manual label noise, we can compute the average noise rate within each group, since we linearly generate the label noise rate according to the client index (e.g., for symmetric label noise scenario, client#1 has all clean labels while client#100 has the biggest noise rate). From these results, this division can relatively divide the total clients into the relatively clean group and the relatively noisy group, and the noisy group has higher averaged noise rate than the clean group. For datasets containing human-annotation errors, we find the clean group has a bit more clients than the noisy group while clients of both groups have similar noise rate (about 40% as discussed in Section 3.2)."}, {"title": "5.6 Analysis on End-to-end Label Correction", "content": "We reckon considering noisy labels in FL, we can not only improve the trained model's robustness against label noise but also try to conduct label correction. In Figure 4, we visualize the label correction performance of FedELC and Joint Optimization framework [54] after $T_w$ global rounds for manual label noise scenarios, which are harder than human label noise as analyzed in Section 5.3. We use our estimated label $y_{estimate}$ in Algorithm 1 and compare it with the true ground-truth label. We backup the true labels before adding label noise to the dataset to conveniently compute this correction accuracy. The results demonstrate our method shows higher label estimation accuracy than another label correction method. Additionally, participants of FL can take fewer efforts to compare the original labels $\\hat{y}$ with our estimated label $y_{estimate}$ and re-label some inconsistent samples ($\\hat{y} \\neq Y_{estimate}$) to further improve the local data quality, which saves a lot of human efforts."}, {"title": "5.7 Analysis on large-scale Clothing1M dataset", "content": "For preprocessing, all images are resized to 224\u00d7224 and normalized. The global communication lasts for 40 rounds. Results are shown in Table 8. We additionally evaluate FedCorr [65] and ELR [35] following the open-source codes. For #15, learning rate is fixed to 0.1 to achieve higher performance. For Robust FL [69] and FedNoRo [63], warm-up period lasts 10 global rounds. Experimental results verify combining the fine-grained noisy client identification and online end-to-end label correction, our method FedELC achieves more reliable performance against its counterparts without compromising the privacy. Robust FL shows higher performance in the complicated systematic label noise scenarios, which indicates the potential of utilizing the class-wise feature centroids as extra supervision to robustly regularize the model training (refer to Section 2.3). We can introduce similar ideas into our method to further enhance the robustness, which we leave for future directions."}, {"title": "6 DISCUSSION & CONCLUSION", "content": "In this work, we focus on improving robustness against noisy data in federated learning (FL), which is an underlying prominent challenge when deploying a practical FL system. We propose a two-stage framework FedELC to detect the clients with possible higher noise levels, and also refine the unreliable labels of these noisy clients via an end-to-end correction manner. One side effect of the proposed FedELC framework lies in it requires extra computation (about \u00d70.3 extra wall-clock time for local training) to simultaneously conduct local training and end-to-end label correction for detected noisy clients. Extensive experiments demonstrate FedELC's robustness against sixteen baseline methods. We showcase the effectiveness of FedELC to correct local labels. Meanwhile, noisy clients can compare our given corrected labels with original labels to refine local datasets with less human efforts which further improves the quality of local data. For future works, we aim to inspect model pruning [66], gradient clipping [26], contribution estimation [7, 59], generating reliable data [25] and other regularization techniques [19, 24, 28] for federated noisy label learning and also improve robustness against noisy data in more applications [48, 68]."}]}