{"title": "Strassen Multisystolic Array Hardware Architectures", "authors": ["Trevor E. Pogue", "Nicola Nicolici"], "abstract": "While Strassen's matrix multiplication algorithm reduces the complexity of naive matrix multiplication, general-purpose hardware is not suitable for achieving the algorithm's promised theoretical speedups. This leaves the question of if it could be better exploited in custom hardware architectures designed specifically for executing the algorithm. However, there is limited prior work on this and it is not immediately clear how to derive such architectures or if they can ultimately lead to real improvements. We bridge this gap, presenting and evaluating new systolic array architectures that efficiently translate the theoretical complexity reductions of Strassen's algorithm directly into hardware resource savings. Furthermore, the architectures are multisystolic array designs that can multiply smaller matrices with higher utilization than single-systolic array designs. The proposed designs implemented on FPGA reduce DSP requirements by a factor of 1.14\" for r implemented Strassen recursion levels, and otherwise require overall similar soft logic resources when instantiated to support matrix sizes down to 32\u00d732 and 24\u00d724 at 1-2 levels of Strassen recursion, respectively. We evaluate the proposed designs both in isolation and in an end-to-end machine learning accelerator compared to baseline designs and prior works, achieving state-of-the-art performance.", "sections": [{"title": "I. INTRODUCTION", "content": "DUE to the rising demand for optimized hardware ac-celeration of general matrix multiplication (GEMM),the field of hardware design continues to see innovation forways of better exploiting the inherent parallelism to speedup computation. However, at a certain point, after technologyscaling slows to a halt and the system-level optimizations andknown parallelism are exhausted, an accelerator wall existswhich limits further progress on the implementation side [1]. Aless-explored path for advancement beyond this wall is throughreducing the computation at the algebraic level, by computingthe same output from a re-arranged compute pattern requiringfewer or cheaper operations to be executed in hardware.\nOne of the area-dominant computational resources inGEMM and deep learning accelerators can commonly bethe multiply-accumulate (MAC) units [2], [3], [4], and anaccelerator's throughput can be directly limited by how manyMAC units can be afforded in its hardware budget. As aresult, surpassing this performance per MAC limit has beenfocused on recently with minimal filtering algorithms appliedto convolutional neural networks [2], [5] and with applicationof fast inner-product algorithms for speeding up deep learningand GEMM workloads [6].\nThe Strassen matrix multiplication algorithm [7] can alsotheoretically be used to reduce the complexity of naive ma-trix multiplication. However, its execution on general-purposecentral processing units (CPU)s and graphics processing units(GPU)s has been shown to be not suitable for achievingthe algorithm's promised theoretical speedups [8], [9], [10],[11], [12], [13], [14], [15]. Strassen's algorithm even in-creases execution time on CPUs/GPUs unless the matrixwidths/heights are in the range of at least 1024 elementsor larger. This limits the benefits of using the algorithm onthese devices for modern workloads that do not decomposeto such large matrix multiplications. Strassen's algorithm con-tains hidden overheads such as extra data accesses requiredfor reading/computing/storing additional intermediate matricesbefore/after the matrix multiplication steps. These extra stepsall add to the overall execution time beyond what is expectedfrom a theoretical analysis based on the number of arithmeticoperations performed alone.\nThis then leaves questions surrounding if the promised theo-retical complexity reductions can be more efficiently achievedin custom hardware architectures designed specifically forexecuting Strassen's algorithm. However, prior work on thistopic is limited and it is not immediately clear how todesign such architectures or if they can truly lead to realimprovements. In this work, we bridge this gap by presentingand evaluating new systolic array hardware architectures forefficiently exploiting Strassen's algorithm. The proposed archi-tectures achieve a more efficient implementation of Strassen'salgorithm compared to what is possible through execution onCPUs and GPUs by pipelining and performing the extra datamovement and addition steps at all levels of recursion in paral-lel with the matrix multiplications. The Strassen architecturesare functionally equivalent to conventional multisystolic arraydesigns while allowing the theoretical complexity reductionsof Strassen's algorithm to be translated directly into hardwareresource savings, even for multiplication of small matrices.Furthermore, the architectures are multisystolic array designs,which is a type of design that can multiply smaller matriceswith higher utilization than a single-systolic array design.\nCompared to a conventional multisystolic array design, theproposed architecture implemented on FPGA uses 1.3\u00d7 fewerDSP units and a similar amount of soft logic resources wheninstantiated for multiplying matrix sizes down to 24\u00d724 at 2levels of Strassen recursion. We demonstrate how the proposedsystolic array architectures are able to increase conventionalmultiplications/multiplier/clock cycle limits while also allow-ing the design to scale up in size without increasing theminimum supported matrix sizes."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "A. Conventional Matrix Multiplication\nA conventional matrix multiplication algorithm computesC = AB for A of size MXK and B of size K\u00d7N, whereeach element Ci,j of C is calculated as follows:\nK\n$C_{i,j} = \\sum a_{i,k}b_{k,j}$ (1)\nk=1\nAlternatively, C can also be computed by dividing A andB into 4 matrix blocks, where C is then computed by carryingout 8 matrix block multiplications and 4 matrix block addition\nbetween the A and B blocks as follows:\n$\\begin{bmatrix} C_{11} & C_{12} \\\\ C_{21} & C_{22} \\end{bmatrix} = \\begin{bmatrix} A_{11}B_{11}+A_{12}B_{21} & A_{11}B_{12}+A_{12}B_{22} \\\\ A_{21}B_{11}+A_{22}B_{21} & A_{21}B_{12}+A_{22}B_{22} \\end{bmatrix}$ (2)\nThis process can then be carried out recursively again for eachmatrix block product by splitting the matrix blocks again intosmaller blocks and repeating the same process.\nB. Strassen Matrix Multiplication\nStrassen's fast matrix multiplication algorithm [7] providesa way to carry out (2) instead using 7 matrix block multipli-cations and 18 matrix block additions as follows:\nT1 = A11 + A22 S1 = B11 + B22\nT2 = A21 + A22 S2 = B11\nT3 = A11 S3 = B12 \u2212 B22\nT4 = A22 S4 = B21\u2212 B11 (3)\nT5 = A11 + A12 S5 = B22\nT6 = A21 \u2212 A11 S6 = B11 + B12\nT7 = A12 \u2212 A22 S7 = B21 + B22\nQ1 = T1S1 C11 = Q1 + Q4 \u2212 Q5 + Q7\nQ2 = T2S2 C12 = Q3 + Q5\nQ3 = T3 S3 C21 = Q2 + Q4\nQ4 = T4S4 C22 = Q1 \u2212 Q2 + Q3 + Q6 (4)\nQ5 = T5S5\nQ6 = T6S6\nQ7 = T7 S7\nSimilarly to (2), this algorithm can also be repeated recursivelyfor each matrix block multiplication, leading to an asymptoticcomplexity reduction compared to conventional matrix multi-plication algorithms such as (1) and (2).\n1) Winograd Form: The Winograd form of the Strassenalgorithm [16] has the same asymptotic complexity but requires 15 matrix block additions at each level of recursionrather than 18. However, for fixed-point data types, this formincreases the multiplier input datapath bitwidth by up to 2 bitsfor each recursion level implemented rather than 1 bit, whichreduces the implementation benefits. Due to this, we focus onthe original form of the Strassen algorithm from (3)-(4) in ourwork instead."}, {"title": "C. Prior Work on Multisystolic Array Systems", "content": "Systolic arrays, which we also refer to as matrix multipli-cation units (MXU)s for convenience, are an effective choicefor use in GEMM accelerators as they significantly reducethe required memory traffic and can reach high clock frequenciesdue to their short and regular interconnects. Systolic arrayarchitectures have been used in state-of-the-art GEMM anddeep learning accelerators such as the Tensor Processing Unit(TPU) [3], [4], [17], among others [6], [18]. However, asystolic array can only be fully utilized when the input matrixsizes at minimum match the dimensions of the systolic arrayor are larger, and real workloads have limits to the matrix sizesbeing multiplied.\nThere is then a limit to how fast the workload can beaccelerated on a single-systolic array design. This is because,even if more compute resources are instantiated to scale upthe size of the systolic array, the systolic array will beginto be underutilized after its size surpasses the workload'smatrix sizes, and the workload will not be able to executeany faster. This is particularly true in modern workloads suchas deep learning acceleration, where the matrix sizes that theworkloads break down to can be smaller than the maximumsystolic array size that could be instantiated in an accelerator[4], [17], [19], [20].\nTo combat this, multiple smaller systolic arrays can be usedin parallel, which allows for the total compute power in thesystolic array system to increase while the minimum supportedmatrix sizes remain the same. Prior works [19], [20] achievethis by implementing variations of (2) by dividing larger ma-trices into smaller matrix blocks, executing the smaller matrixblock multiplications on multiple smaller systolic arrays. Theblock products are then later summed up to form the finallarger matrix multiplication product. In this work, we showhow to efficiently implement (3)-(4) in hardware to achievethis same goal with less hardware resources."}, {"title": "D. Prior Work on Executing Strassen on CPUs and GPUs", "content": "Strassen's algorithm has been well explored in prior workfor execution on general-purpose CPUs and GPUs [8], [9],[10], [11], [12], [13], [14], [15]. However, its execution onCPUs and GPUs in these prior works is unable to efficientlyachieve the algorithm's promised theoretical speedups unlessthe widths/heights of the matrices being multiplied are in therange of at least 1024 elements or even much larger.\nThis non-optimal execution of Strassen's algorithm inCPUs and GPUs stems from irregularities introduced in thealgorithm such as extra data accesses required for read-ing/computing/storing additional intermediate matrices be-fore/after the matrix multiplication steps. These irregularitiesall add to the overall execution time beyond what would beexpected purely from a theoretical analysis of only the numberof required arithmetic operations [10], [14].\n1) Theoretical Complexity Reductions of Strassen's Algo-rithm: In this subsection, we establish what the expectedtheoretical complexity reductions of Strassen's algorithm arebased on number of operations, and how the achieved speedups"}, {"title": "", "content": "in prior works on CPU/GPU Strassen implementations fallshort of achieving these theoretical complexity reductions.\nLetting M = N = K = n, the complexity of Strassen'salgorithm in number of arithmetic operations is O ($n^{2.8074}$) [7]. Conventional matrix multiplication (1) requires n\u00b3 multi-plications and n\u00b2 (n - 1) additions for the following numberof total operations:\nn\u00b3 + n\u00b2 (n \u2212 1) . (5)\nIn contrast, Strassen's algorithm (3) for 1 recursion level requires 7n\u00b3/8 multiplications and 7 n\u00b2 (n/2 \u2013 1) /4+18 n\u00b3/8additions for the following number of total operations:\n7n\u00b3/8 + 7 \u043f\u00b2 (\u043f/2 \u2013 1) /4 + 18 n\u00b3/8. (6)\nThe Winograd form of Strassen's algorithm [16] for1 recursion level requires 7n\u00b3/8 multiplications and7 \u043f\u00b2 (\u043f/2 \u2013 1) /4+15 n\u00b3/8 additions for the following num-ber of total operations:\n7n\u00b3/8 + 7 \u043f\u00b2 (n/2 \u2013 1) /4 + 15 n\u00b3/8. (7)\nBy comparing (5) to (6) and (7) for different values of nwe can then see that Strassen's algorithm requires feweroperations than conventional matrix multiplication for matrixsizes of n \u2265 16, and n > 13 for the Winograd form ofStrassen's algorithm.\nHowever, Strassen's algorithm on CPUs and GPUs in priorworks only starts providing some speedups over traditionalmatrix multiplication for matrix sizes n of at least 20000[8], 16384 [9], 896 [10], 5000 [11], 1536 [12], 1006 [13],and 1000 [14] [15]. This limits the applicability of Strassen'salgorithm on CPUs and GPUs for modern workloads such asdeep learning that do not always decompose to such largematrix multiplications.\nAs derived above, prior works on CPU/GPU implementations require matrix sizes of at least 896-16384 before havingbenefits rather than the much lower theoretical threshold of 13or 16. In contrast, the custom Strassen hardware architecturespresented in this work translate the benefits of Strassen'salgorithm into hardware resource savings rather than reductionsin execution time. The proposed designs more closely achievethe theoretical complexity reductions of Strassen's algorithmcompared to prior works on CPU/GPU implementations. Thisis demonstrated in our results through the fact that the pro-posed architectures present area savings while achieving thesame throughput/clock cycle as traditional designs even wheninstantiated for multiplying matrices down to size 24\u00d724.Additionally, for r Strassen recursion levels implemented, theproposed designs achieve (8/7)\" times reduction in multipliersas expected from (3)-(4) compared to conventional designswithout significant increase in other hardware components orany increase in throughput/clock cycle.\nE. Prior Work on Custom Strassen Hardware Architectures\nWhile software implementations of Strassen's algorithm onCPUs and GPUs have been well explored in prior work,custom hardware designs for efficiently exploiting the algo-rithm in hardware remain under-explored. A systolic array\""}, {"title": "", "content": "design concept for implementing Strassen's algorithm for onelevel of recursion on 2\u00d72 matrices has been proposed inthe work by Elfimova et al. [21] without evaluation of animplementation. Another hardware design for implementingStrassen's algorithm for one level of recursion on 2\u00d72 matriceshas also been proposed in the work by Le\u00f3n-Vega et al. [22],where the Strassen architecture reduced FPGA DSP usageby up to 12.5% at the expense of 25-40% increase in LUTresources to implement the additional adders.\nUnlike the only two prior works on custom hardwaredesigns for executing the Strassen algorithm, we proposearchitectures in this work that allow for Strassen's algorithm tobe implemented on matrices larger than 2\u00d72. This is essentialfor minimizing the complexity penalty of the additional adders.Additionally, the architectures are capable of implementingmultiple levels of Strassen recursion to achieve greater hard-ware resource savings. Furthermore, the proposed architecturesallow proven traditional systolic arrays to be still used at thecore. Alternatively, they can allow Strassen's algorithm to beused in combination with other hardware designs that canefficiently perform further algebraic optimizations on matricesafter the Strassen portion is carried out, such as techniquesfrom our prior work [6]. Finally, the proposed Strassen ar-chitectures are multisystolic array designs, meaning they canmultiply smaller matrices with higher utilization than single-systolic array designs with the same computational strength.\nF. Notation\nThe following notation is used throughput the remainderthis work for describing different systolic array architecturesor their workloads:\n\u2022 r: The number of recursion levels in (2) or (3)-(4) thatare implemented in a hardware architecture.\n\u2022 MM: A traditional single-systolic array implementingconventional matrix multiplication (1) in hardware.\n\u2022 MM: A traditional multisystolic array implementingconventional blocked matrix multiplication (2) in hard-ware for r levels of recursion.\n\u2022 SMM: The proposed Strassen multisystolic array imple-menting (3)-(4) in hardware for r levels of recursion.\n\u2022 MXU: In this work, systolic arrays may also be referredto as matrix multiplication units (MXU)s for convenience.\n\u2022 (S)MM(r) X\u00d7Y: An MM, MM, or SMM architecturemay also be referred to with two numbers XXY specifiedbeside it. Here, X and Y represent the width and height,respectively, in number of MAC units of each MMsystolic array instantiated at the lowest level of recursionin the architecture. For example, an MM 64\u00d764 MXU(meaning X = Y = 64) would contain 64\u00b2 MAC units,an MM1 32\u00d732 MXU (meaning r = 1 and X = Y = 32)would contain 81 \u00d7 32\u00b2 MAC units, and an SMM2 8\u00d78MXU (meaning r = 2 and X = Y = 8) would contain7\u00b2 \u00d7 8\u00b2 multipliers.\n\u2022 n: The width/height of the matrices that are being fed asinputs to a systolic array to be multiplied."}, {"title": "III. STRASSEN ARCHITECTURE", "content": "The proposed architectures achieve a more efficient im-plementation of Strassen's algorithm than what is possiblethrough execution on CPUs and GPUs by pipelining andperforming the extra additions and data movement steps at alllevels of recursion in parallel with the matrix multiplications.The architectures are functionally equivalent to conventionalmultisystolic array designs while allowing the theoreticalcomplexity reductions of Strassen's algorithm to be translateddirectly into hardware resource savings.\nA. Memory Layout and Access Algorithm\nIn order to perform the extra Strassen data movement andaddition steps at all levels of recursion in parallel with thematrix multiplications, the architecture reads one row/columnat a time of the A and B input matrix sub-blocks from thelowest level of recursion in (3) simultaneously. This generatesand provides all T and S sub-blocks one row/column at atime for performing all the matrix multiplications in (4) atthe lowest level of recursion in parallel. The T and S sub-blocks are all immediately generated from the A and B inputsub-blocks and consumed in parallel like this to eliminate anyadditional execution time or hardware resources needed forstoring/re-accessing them for later use.\nTo achieve this, each A and B matrix fed into the MXUis divided into 4\" equal sub-blocks of size mxk for A andof size kon for B, where each row/column i/j of each A/Bsub-block is stored in the accelerator's A and B memories atlocation ilj plus an offset. An example of this memory layoutfor implementing 2 levels of Strassen recursion is shown inFig. 1. This means that each A memory location i is a vectorcontaining every mth row of A starting at row i concatenated"}, {"title": "", "content": "together (notated as Ai:m:,:), and each B memory location j isa vector containing every nth column of B starting at columnj concatenated together (notated as B.,j:n:). This allows onerow or column of all 4 A/B sub-blocks from the lowest levelof recursion in (3) to all be read at once from a single memorylocation and fed into the MXU each clock cycle. Ai:m:,: andB.,j:n: rows/columns are then read consecutively when feedingthe A and B blocks into the MXU.\nAs shown in (3), the input A and B matrices at each levelof recursion are divided into four block quadrants labelled Aijand Bji of size MXK for Aij quadrants and of size KXN forBji quadrants. The portions of each Ai:m:,: and B.,j:n: vectorbelonging to quadrant Aij and Bji are notated as Aiji:m:,: andBji,j:n:. The MXU then computes and returns row i of all Csub-blocks from the lowest level of recursion in (4) in everyclock cycle i, allowing Ci:m:,: to be stored in the same formatas A in memory for if C will later be taken as an A inputfor a later matrix multiplication.\nB. Strassen Multisystolic Array Design\nFig. 2 shows the proposed SMM, multisystolic array archi-tecture. Rather than having one XXY MXU with X columnsand Y rows of MAC units for efficiently multiplying matricesdown to size XXY, this architecture consists of 7\" smallerX/2\" \u00d7Y/2\" MXUs that together efficiently multiply matricesdown to the same size but at a higher throughput. Furthermore,it achieves this with fewer MAC units than a conventionalmultisystolic array design. This both allows smaller matricesto be multiplied at a higher utilization and increases thethroughput per MAC unit.\nThe Ai:m:,: and B:,j:n: vectors read into the MXU arefirst divided into their four Aiji:m:,: and Bji.j:n: portionsdepending on which quadrant of A/B each element belongs to"}, {"title": "", "content": "as shown in Fig. 2. They then pass through the A/B additionvectors shown in Fig. 3 (a) and (b) to form the Ti:m:,:/S:,j:n:matrices. The A/B addition vectors both contain 5 additionvectors each consisting of K scalar adders or subtractors,where K is the width of the four Aij blocks and the heightof the four Bji blocks as defined in Section III-A. The 7Ti:m:,:/S:,j:n: vectors then pass into the next level of SMM-1MXUs to perform the 7 matrix block multiplications. TheQi:m:,: vectors of the matrix block multiplication outputs thenpass through the Qi:m:,: addition vectors shown in Fig. 3(c) consisting of 8 addition vectors each containing N scalaradders or subtractors. This forms the final C product, whereN is the width of the four Bji blocks as defined in SectionIII-A.\nEach of the 7 SMM-1 MXUs can contain 7 more SMM-2MXUs for implementing another level of Strassen recursionand repeating the process above, or they can be instantiatedas a baseline MM MXU shown in Fig. 4. For implementingthe next level of SMM-2 MXUs inside each SMM\u22121 MXU,each Ti:m:,:/S:,j:n: input passed into an SMM\u22121 MXU willthen be considered as the full Aim:,:/B:,j:n: inputs withinthat MXU and are split again into the next level of fourAiji:m:,:/Bji:,j:n: vectors. The dimensions of the matrix blocksbeing read/computed and the number of scalar adders inthe addition vectors within each SMM-1 MXU will then"}, {"title": "", "content": "B GEMM tile into the MXU as the current GEMM tile isbeing multiplied.\nEach A, B, and C sub-block entering or exiting the top-level MXU for the SMM and baseline MXUs first passthrough triangular-shaped register arrays each containing Xshift registers of varying depths. Here, each shift register SRkhas a depth of k and loads one ai,k or bk,j element per clockcycle. These triangular buffers are explained further in ourprior work [6] and they allow the vector elements to enter theMXU in the necessary order as depicted in the element indicesin Figs. 4 and 6.\nB. Multiplier Compute Efficiency\nIn this subsection, we define an efficiency metric calledthe multiplier compute efficiency (MCE) in (8) which we useto compare the SMM architectures against baseline designsand prior works. This is used to quantify how much thealgebraic optimizations exploited in an architecture reducethe computational complexity. Reductions in computationalcomplexity allow an architecture to utilize its multipliersmore effectively than conventional designs using no algebraicoptimizations. The multiplier compute efficiency is defined asfollows:\n$MCE = \\frac{mults/multiplier}{clock cycle} = \\frac{(mults/s)/\\#multipliers}{f}$ (8)\nHere, mults/s above is measured by taking the number of mul-tiplications required to carry out an execution using conven-tional algebra and dividing it by the measured execution time.Finally, #multipliers is the number of instantiated multipliersin the design, and f is the clock frequency that the hardwaredesign is operating at.\nConventional matrix multiplication algorithms such as (2)have no algebraic optimizations for reducing the computationalcomplexity. Therefore, the limit/maximum achievable value(also referred to as the roof) of the metric in (8) is thefollowing when using conventional matrix multiplication inhardware:\nroof ($\u041c\u0421\u0415_{MM}$) = 1. (9)\nIn contrast, Strassen's algorithm requires 8\"/7\" times fewermultiplications than a conventional matrix multiplication al-gorithm, where r is the number of levels of recursion im-plemented in Strassen's algorithm. Therefore, the multipliercompute efficiency can reach the following limit in SMMarchitectures:\nroof $(MCESMM) = (\\frac{8}{7})^{r}$ (10)\nAs discussed in Section II, Strassen's algorithm reduces theoverall number of operations in matrix multiplication. Further-more, any additions required before the matrix multiplicationsin the algorithm are even less of a concern in fixed-pointimplementations. This is because the hardware complexity offixed-point multipliers typically scale quadratically with theinput bitwidth compared to linearly for adders and registers[24], [25], [26], causing the hardware footprint of multipliersto dominate that of adders and registers."}, {"title": "", "content": "However, one of the impediments of using Strassen'salgorithm for fixed-point implementations is that the bitwidthsof the multiplication inputs increase by r bits for r levelsof Strassen recursion that are implemented, reducing its po-tential area savings for custom fixed-point hardware designs.Nonetheless, this impediment for fixed-point designs can beinherently mitigated in FPGA implementations so long as rplus the initial input width is not larger than the maximuminput width supported by the FPGA's DSP units. For ex-ample, each DSP in common Intel/Altera FPGAs instantiatetwo 18\u00d719-bit multipliers [27], and common input bitwidthsfor applications such as deep learning are 16 bits or less.This leaves room for at least 2 or more levels of Strassenrecursion to be implemented before surpassing the bitwidthlimit supported by the DSPs.\nFurthermore, due to the flexible nature of custom hardwaredesign, the SMM, architectures can be efficiently mapped ontoother DSP units in general which support input bitwidths up ton bits by customizing the input datapath bitwidth w andvalue of r as necessary to ensure that w + r < n. So long asthe accuracy requirements of the application are still met, thiswill allow the SMM, designs and their increase in multiplierbitwidth to still be efficiently mapped onto DSP units of anybitwidth in a general way.\nC. Supporting Smaller Matrices with the Same Performance\nMultisystolic array designs such as the SMM, and baselineMM architectures have the ability to efficiently multiplysmaller matrices than a single-systolic array design with thesame performance capability. By executing (2) or (3)-(4) fullyin parallel for r levels of recursion, matrix products of sizeas small as nxn can be computed up to once every n/2\"clock cycles in an MM, or SMM, multisystolic array design.Furthermore, these matrix products require n\u00b3 multiplicationsto calculate using conventional algebra. Therefore, the ratio ofan architecture's throughput per clock cycle versus its smallestsupported matrix sizes it can multiply, which we refer to asthe matrix size efficiency (MSE), is the following:\n$MSE = \\frac{mults/clock cycle}{min. mat. size (hxw)}$ (11)\nwhich has the following roof for multisystolic arrays:\nroof $(MSE(S)MM)) = \\frac{n^{3}/(n/2^{r})}{nx n} = 2^{r}.$ (12)\nIn contrast, a single-systolic array design can produce matrixproducts of size as small as n x n up to once every n clockcycles, making this ratio the following for a single-systolicarray design:\nroof $(MSE_{MM}) = \\frac{n^{3}/n}{nx n} = 1$. (13)\nThis shows that the SMM and baseline MM, multisystolicarray designs can efficiently multiply matrices 2\" times smallerthan a single-systolic array architecture with the same perfor-mance capability.\nAs discussed in Section II-C, this is an important propertyfor increasing a systolic array accelerator's maximum achiev-"}, {"title": "", "content": "able throughput on real-life workloads. Even if more computresources are instantiated to scale up the size of the systolicarray, the systolic array will begin to be underutilized after itssize surpasses the workload's matrix sizes. This is particularlytrue in modern workloads such as deep learning acceleration,where the matrix sizes that the workloads break down to canbe smaller than the maximum systolic array size that could beinstantiated in an accelerator [4], [17], [19], [20]. In SectionIV-E, we demonstrate how this property allowed us to scaleup our deep learning accelerator design without compromisingutilization to achieve state-of-the-art ResNet [28] throughput.\nD. Comparison to Baseline Designs\nTable I shows the resource usage and performance compar-ison between the proposed SMM, and baseline MM/MMmultisystolic array architectures in isolation (without integrationinto a deep learning accelerator system). The SMM1 andSMM2 architectures overall have a similar amount of soft logicresources and the same throughput per clock cycle roof as theMM1 and MM2 architectures, respectively, but they require1.14-1.31\u00d7 fewer DSP units. Compared to the multisystolicarray MM1 and MM2 designs, the SMM\u2081 and SMM2 architec-tures are also functionally equivalent, respectively, other thanhaving a lower clock frequency. To help mitigate the limitationof having a lower frequency, we added an extra SMM2 design(which had the biggest issue with clock frequency) on the farright of Table I containing additional pipelining registers inthe addition logic of each Q Addition Vectors unit from Fig.3 (c). This extra design demonstrates how a trade-off can beoptionally made to increase the design's clock frequency atthe cost of some extra soft logic resources.\nNonetheless, the lower clock frequencies of the SMMdesigns in Table I are compensated by the fact that the SMMdesigns achieve more effective operations from the samenumber DSP units. Since the reduction in DSP units is greaterthan the reduction in clock frequency in the SMM\u2081 designand SMM2 design with extra registers relative to their MMcounterparts, they would be able to achieve a higher overallthroughput if scaled up in size to use the same number ofDSPs. This is shown by the Throughput/DSP metric in Table Iwhich shows that the SMM designs achieve up to 22% morethroughput per DSP than their MM counterparts. Finally,if the frequency-limiting critical path is in external control orother logic outside of the systolic array after integrating itinto an end-to-end accelerator system, as was the case in ourfull-system accelerators from Tables II-III, this limitation of alower frequency is further mitigated.\nThe throughput per clock cycle roof of the MM and MM2baseline designs in Table I are equal and they consume thesame number of DSP resources, but the MM2 design requiresslightly fewer ALM and register resources. However, thispenalty may be justified in the MM2 design when consideringthat the minimum matrix size (height\u00d7width) that can bemultiplied while fully utilizing the MXU is 4\u00d7 smaller inthe MM2 design compared to the MM design. This increasesits performance scalability for accelerating modern workloadssuch as deep learning as discussed in Section II-C and IV-C."}, {"title": "", "content": "This ability of the multisystolic array designs to more effi-ciently multiply smaller matrices is further illustrated in Fig.7. This same property is true for the SMM2 design, exceptit achieves this with fewer DSP resources. This benefit isdemonstrated in Section IV-E, where this property allowedus to scale up our deep learning accelerator design withoutcompromising utilization to achieve state-of-the-art ResNetthroughput.\nE. Comparison to Prior Work\nFull system-level validation of the experimental acceleratoras integrated into the system from our previous work [6] has"}, {"title": "", "content": "been done on an Arria 10 SoC Developement Kit [29] con-taining the Arria 10 SX 660 device by measuring throughputin real-time. However, this device contains fewer soft logicresources than the Arria 10 GX 1150 used in the prior workwe compare against, and we generate compilation results forour design on the same Arria 10 GX 1150 device used in priorworks for a more fair and consistent comparison. Throughputvalues of our designs on the Arria 10 GX 1150 device arethen calculated using an accurate throughput estimation modelbased on our highly deterministic and time-predictable systemimplementation, which accurately predicts actual throughputsmeasured on the Arria 10 SX 660 device available to us. TablesII-III show throughputs for ResNet [28] neural networks.\nThe works from Liu et al. [30] and Fan et al. [31]in Table II use a technique to pack two 8-bit multiplicationsonto each 18\u00d719-bit multiplier in the DSPs and additionalALMs, and therefore the number of multipliers is calculatedas #DSP\u00d74 in those works. The number of multipliers inthe works [32], [33] from Table IV is calculated as #DSPsince they are implemented on AMD FPGAs where each DSPinstantiates one 18\u00d727-bit multiplier [34]. In Tables II and IV,the number of multipliers in the prior works [35], [36] is equalto #DSPs\u00d72, where each DSP in the Altera FPGAs instantiatestwo 18\u00d719-bit multipliers [27]. The number of multipliersused in the MXUs from our architectures in Tables I-II is equalto 8 or 7 times XXY for the MM and SMM MXUs,respectively. For example, an MM 64\u00d764 MXU (meaningr = 0 and X = Y = 64) would contain 8\u00ba \u00d7 64\u00b2 multipliers,an MM\u2081 32\u00d732 MXU would contain 81 \u00d7 32\u00b2 multipliers, andan SMM2 8\u00d78 MXU would contain 7\u00b2 \u00d7 8\u00b2 multipliers. Due to the FFIP reduction in multipliers as described in our priorwork [6], the number of multipliers for the FFIP architecturesin Table III is equal to 8 or 7 times X \u00d7 Y/2+ X/2 for theFFIP and FFIP+SMM, designs, respectively. Additionally, for"}, {"title": "", "content": "2 levels of Strassen recursion use 1.14x and 1.31x fewerDSP units and an overall comparable amount of soft logicresources when instantiated for multiplying n\u00d7n matricesdown to sizes n = 32 and n = 24, respectively. The proposedsystolic array architectures increase conventional multiplica-tions/multiplier/clock cycle limits by a factor of 1.14\" for rimplemented levels of Strassen recursion. Furthermore, theyallow the throughput per clock cycle roof of an acceleratorto double for each implemented level of Strassen recursionwithout increasing the minimum supported matrix sizes thatcan be efficiently multiplied.\nV. CONCLUSION"}]}