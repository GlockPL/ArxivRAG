{"title": "Murine AI excels at cats and cheese: Structural differences between human and mouse neurons and their implementation in generative AIs", "authors": ["Rino Saiga", "Kaede Shiga", "Yo Maruta", "Chie Inomoto", "Hiroshi Kajiwara", "Naoya Nakamura", "Yu Kakimoto", "Yoshiro Yamamoto", "Masahiro Yasutake", "Masayuki Uesugi", "Akihisa Takeuchi", "Kentaro Uesugi", "Yasuko Terada", "Yoshio Suzuki", "Viktor Nikitin", "Vincent De Andrade", "Francesco De Carlo", "Yuichi Yamashita", "Masanari Itokawa", "Soichiro Ide", "Kazutaka Ikeda", "Ryuta Mizutani"], "abstract": "Mouse and human brains have different functions that depend on their neuronal networks. In this study, we analyzed nanometer-scale three-dimensional structures of brain tissues of the mouse medial prefrontal cortex and compared them with structures of the human anterior cingulate cortex. The obtained results indicated that mouse neuronal somata are smaller and neurites are thinner than those of human neurons. These structural features allow mouse neurons to be integrated in the limited space of the brain, though thin neurites should suppress distal connections according to cable theory. We implemented this mouse-mimetic constraint in convolutional layers of a generative adversarial network (GAN) and a denoising diffusion implicit model (DDIM), which were then subjected to image generation tasks using photo datasets of cat faces, cheese, human faces, and birds. The mouse-mimetic GAN outperformed a standard GAN in the image generation task using the cat faces and cheese photo datasets, but underperformed for human faces and birds. The mouse-mimetic DDIM gave similar results, suggesting that the nature of the datasets affected the results. Analyses of the four datasets indicated differences in their image entropy, which should influence the number of parameters required for image generation. The preferences of the mouse-mimetic Als coincided with the impressions commonly associated with mice. The relationship between the neuronal network and brain function should be investigated by implementing other biological findings in artificial neural networks.", "sections": [{"title": "Introduction", "content": "Human and mouse brains differ in a number of aspects. The most obvious one is their size. The human brain is characterized by its folded cerebral cortex, of which the area is estimated to be 1500\u20132000 cm\u00b2 (Van Essen & Drury, 1997; Im et al., 2008; Kang et al., 2012; Schnack et al., 2015). Moreover, the human cerebral cortex is typically 1.5-3.5 mm thick (Fischl & Dale, 2000; Schnack et al., 2015; Wagstyl et al. 2020) and consists of 10\u201320 billion neurons (Larsen et al., 2006; Herculano-Houzel, 2009; von Bartheld et al., 2016). Hence, the mean areal density of neurons in the human cerebral cortex is estimated to be approximately 10\u2077 neurons/cm\u00b2. In contrast, mice have tiny brains with a smooth cerebral cortex having a thickness of typically 1 mm (Pagani et al., 2016; Hammelrath et al., 2016) and an area of approximately 2 cm\u00b2. The mean areal density of neurons in the mouse cerebral cortex is reported to be 9.3 \u00d7 10\u2076 neurons/cm\u00b2 (Keller et al., 2018). This value nearly coincides with that of the human brain, though the cortical thickness differs by a factor of 2 to 3 between human and mouse.\nThese anatomical differences between human and mouse brains should originate from their cellular makeup. Comparative studies on the microscopic or cellular constitution of human and mouse brains have been reported from a wide variety of perspectives and have revealed similarities and differences between them (Tecott, 2003; Y\u00e1\u00f1ez et al., 2005; Strand et al., 2007; Katzner & Weigelt, 2013; Hodge et al., 2019; Benavides-Piccione et al., 2020; Szegedi et al., 2020; Bakken et al., 2021; Beauchamp et al., 2022; Loomba et al., 2022; Kim et al., 2023; Ragone et al., 2024). A study on brain-wide transcriptomic data on humans and mice indicated that sensorimotor brain areas exhibit a higher degree of similarity than supramodal areas (Beauchamp et al., 2022). Indeed, the visual cortexes of humans and mice have been reported to share structural and functional principles (Katzner & Weigelt, 2013). Single-nucleus RNA-sequencing analysis of the temporal cortex revealed a well-conserved cellular architecture between humans and mice (Hodge et al., 2019). Transcriptomic and epigenomic profiling of cells in the primary motor cortex also showed a broadly conserved cellular composition (Bakken et al., 2021). However, it is not fully understood how the cellular makeup is translated into functional differences of the brain between humans and mice.\nAnalyses of the relationships between the neuronal network and brain function can provide clues to understanding the functional basis of the brain. We have recently reported nanometer-scale three-dimensional studies of human cerebral tissues of the"}, {"title": "Results", "content": "Three-dimensional structures of mouse brain tissues\nBrain tissue structures of layer V of the medial prefrontal cortex of nine mice (M1\u2013 M9) were visualized with nano-CT (Supplementary Table S1), in the same manner as previously reported for the corresponding layer of the anterior cingulate cortex of eight human control cases (Mizutani et al., 2019, 2023). Tomographic slices were reconstructed from the obtained X-ray images and stacked to reproduce three-dimensional structures (Figure 1A, Supplementary Figures S1-S20). The tissue structures were traced in order to build Cartesian-coordinate models (Figure 1B), as was previously performed for human cases (Figure 1C, D). The traced structures of the nine mice consisted of 109 neurons, 5665 neuronal processes, and 65541 dendritic spines in total (Supplementary Table S2\u2013S4). The tissue structures of the eight human control cases consisted of 150 neurons, 4597 neuronal processes and 18559 spines (Mizutani et al., 2019, 2023). Differences between the human and mouse structures are discernible in Figure 1, such as in the shape of neuronal somata and the spatial trajectory of neurites, which indicates that human and mouse cerebral tissues can be distinguished simply by visualizing their structures."}, {"title": "Structural differences between human and mouse brain tissues", "content": "The human and mouse brain tissues (Figure 1) show differences in their neuronal soma shape. The somata of the mouse neurons are nearly spherical, while those of human are vertically triangular. Another difference is in their neurite structures. Mouse neurites are tortuous and thin, while human neurites are rather straight and thick (Figure 1).\nFigure 2 summarizes differences in the soma shape. The most significant difference is in the neuronal soma length, which was defined as the length along spherical nodes having a diameter larger than half the diameter of cell soma (Figure 2A). Mean soma length for mouse is less than 60% that of human (Figure 2B; p = 1.10 \u00d7 10\u207b\u2076, two-sided Welch's t-test, Holm-Bonferroni corrected, same hereafter unless otherwise noted). The mouse soma width, which was defined with the diameter of the largest spherical node in the neuron, is approximately 85% of the human soma width (Figure 2B; p = 0.025). The shape difference is discernible from three-dimensional renderings of the neuronal somata (Figure 2E). The mouse soma is small and spherical, and hence compatible with thin and areally-confined cortex of the mouse brain. The human soma is long and wide, and hence conforms to the human cerebral cortex with sufficient depth and area.\nThe soma length difference was further examined by classifying neurons into pyramidal neurons and interneurons. Here, the difference was highly significant for pyramidal neurons (Figure 2C; p = 6.3 \u00d7 10\u207b\u2078). In contrast, the difference in interneuron length was insignificant (Figure 2D), though interneurons are less abundant and were identified only in five mouse and three human cases. These results indicated that the structural difference between human and mouse soma observed in this study is ascribable to pyramidal neurons."}, {"title": "Implementation of structural differences in generative Als", "content": "Major structural differences between human and mouse were found in 1) the shape of the pyramidal soma and in 2) the thickness and curvature of the neurites. These differences should be related to each other, and this issue is addressed in the discussion section below. The thin and tortuous neurites in the mouse brain should suppress connections between distant neurons according to cable theory (Hansson et al., 1994)."}, {"title": "Discussion", "content": "The results of this study indicated that the neurons of human and mouse differ in a number of structural parameters, including soma length (Figure 2) and neurite thickness (Figure 3D). A difference in size of neuronal soma between humans and mice was also reported for hippocampal CA1 neurons (Benavides-Piccione et al., 2020). The soma downsizing and the neurite thinning allow neurons to be integrated in a limited thickness and area of the mouse cerebral cortex and, therefore, should be the results of adaptation to the limited volume of the mouse brain. In contrast to the mouse brain, the human brain occupies a large volume and bears a thick and folded cerebral cortex (Van Essen & Drury, 1997; Im et al., 2008; Kang et al., 2012; Schnack et al., 2015), which can accommodate long and thick neurons. If mouse neurons are integrated into the volume of the human brain, the number of neurons per cortical area can be increased by two times or more and the amount of information that are processed simultaneously can be doubled, though the energy supply issue (Roy & Sherrington, 1890; Leybaert, 2005; Saiga et al., 2021) remains.\nSince the mean stem-dendrite diameter is proportional to the neuronal soma diameter (Zwaagstra & Kernell, 1981), the differences in soma size and neurite diameter should be related to each other. The soma size correlates also with the dendrite extent (Fiala & Harris, 1999). These results along with ours suggest that a neuron with a large soma has thick dendrites innervating widely, while a neuron with a small soma has thin dendrites wherein the network is confined to the vicinity of the soma. It has been reported that a neuregulin-4 knock-out mouse showed a reduced soma size of pyramidal neurons in the motor cortex and exhibited defects in motor performance (Paramo et al., 2021). A mouse model of Rett syndrome exhibited reduced dendritic arborization (Jentarra et al., 2010) and a reduced soma size (Rangasamy et al., 2016). Therefore, the soma downsizing and the neurite thinning in the mouse brain should correlate with each other and affect the performance of the neuronal network.\nDifferences between the dendritic spines were observed in their curvature and density (Figure 3F-I). Since the spine curvature reciprocally correlates with the spine thickness (Mizutani et al., 2021) and the spine thickness correlates with the neurite thickness (Mizutani et al., 2021), the tortuous spines in the mouse brain should affect the neuronal network concomitantly with the neurite thinning. The mouse spine density determined with our method was 2.6 times as high as that of humans (Figure 31). Though the staining efficiency of the Golgi impregnation used in our studies should have affected the density estimation, a similar difference in synapse density between humans and mice was reported in a dense connectomic study (Loomba et al., 2022). The two- to three-fold higher spine density in mice can compensate for the 2- to 3-fold thinner cortex compared to the human cortex, allowing neurons to form a comparable number of spines per cortical area. We suggest that dendritic spines of humans and mice are regulated to keep their areal density constant.\nThis study compared three-dimensional structures of neurons between the medial prefrontal cortex of mice and the anterior cingulate cortex of humans. The comparison revealed multiple differences as described above. It has been reported that the anterior cingulate cortex of humans exerts emotional and cognitive functions (Botvinick et al., 1999; Bush et al., 2000). Moreover, neurons in the medial prefrontal cortex of mice receive long-range inputs from brain regions involved in cognition, motivation, and emotion (Anastasiades & Carter, 2022). Therefore, the neuronal differences observed in this study should be relevant to cognitive and emotional brain functions in humans and mice, including functions for finding food and fleeing from enemies.\nThe structural comparison of human and mouse neurons suggested that neuronal connections are spatially confined in the mouse brain network. We incorporated this finding in DC-GAN and DDIM by masking the weight matrix depending on the two-dimensional distance between nodes. The resultant FID scores for human faces and birds were worsened by the parameter reduction for both the GAN and the DDIM (Figure 4C, 4D). The constraints in the weight matrix should have degraded the performance of the generative Als. In contrast, the FID scores for cat faces and cheese were improved by the parameter reduction (Figure 4B, 4D). The sparse weight matrix of the mouse-mimetic layer can eliminate extra degrees of freedom and thus may have improved the performance. These results suggest that the number of parameters appropriate for generating cat faces and cheese photos is lower than those for human faces and birds. The four datasets used in this study showed differences in image entropy, which can affect the number of parameters required for the image generation task. We suggest that the statistics of the input dataset including the image entropy determine the degree of freedom suited for generating images from that dataset.\nThe results for the mouse-mimetic networks indicated that the number of parameters can be adjusted by using the mouse-mimetic layers without changing the network architecture or dimensions. Since the shape of the weight matrix of the mouse layer is the same with that of its original one, any convolutional layer can be replaced with its mouse-mimetic version. Although the parameter %usage needs to be optimized to obtain the best result, we suggest 30\u201350% as a first choice to examine whether the mouse-mimetic layer works in the target application. Since it has been reported that the brain-wide circuitry associated with higher intelligence is organized in a sparse manner (Gen\u00e7 et al., 2018), parameter reduction should also be a strategy to improve the performance in biological systems. The results of this study indicated that the number of parameters used for the image generation task can be halved by introducing mouse-mimetic layers. Although the computation time for training the mouse-mimetic AI is the same with that of its standard version in the present implementation, there is a possibility to reduce the computational cost by taking account of the sparse architecture of the mouse-mimetic layer into the library code of the neural network calculation.\nThe ages of the mice used in this study were in the young adult range, while the human cases ranged in age from their early 40's to 70's (Mizutani et al, 2023). This age difference can affect the structure of the neuronal network, though a significant correlation between the age and the structural parameter was observed only for the standard deviation of the neurite curvature in the human study (Mizutani et al., 2023).\nWe suggest that age-related effects on the human neuronal structure are rather limited compared with the differences between human and mouse. Another limitation of this study is the difference in the tissue fixation method. The mouse tissues were fixed with a perfusion fixation, while the human tissues were fixed by immersing them in a fixation solution. This methodological difference can affect neuron structures.\nIn this study, we analyzed three-dimensional structures of mouse brain tissues and compared them with those of human brain tissues. The neurons in the mouse brain showed comparably downsized somata and thin neurites, allowing the neurons to be integrated in a limited space of the mouse brain. This finding was applied to generative Als to examine its computational consequences. The mouse-mimetic Als outperformed the conventional Als in image generation tasks using cat faces and cheese datasets. The preferences of the mouse-mimetic Als coincided with the impressions commonly associated with mice, though its biological implication remains to be clarified. The structure of mouse neurons would have adapted to the environment that mice live in to optimize their brain functions for their survival. We suggest that relationship between neuronal structure and brain function should be investigated by implementing other biological findings in artificial neural networks."}, {"title": "Methods", "content": "Human cerebral data\nHuman data were obtained in our previous studies (Mizutani et al., 2019, 2023). Post-mortem human cerebral tissues were collected with written informed consent from the legal next of kin using protocols approved by the Clinical Study Reviewing Board of Tokai University School of Medicine (application no. 07R-018). The human studies were conducted according to the Declaration of Helsinki. The method used for the structural analysis of human tissues (Mizutani et al., 2019, 2023) is the same as the method applied to the mouse samples described below.\nMouse cerebral tissue\nNine male C57BL/6J mice were housed in a conventional environment with ad libitum feeding under a 12 h / 12 h light and dark cycle. All mouse experiments were performed with the approval from the Institutional Animal Care and Use Committee at the Tokyo Metropolitan Institute of Medical Science (protocol code: 18028) in accordance with relevant guidelines and regulations. The mice at 16 weeks of age were deeply anesthetized with an overdose of sodium pentobarbital and subjected to perfusion fixation using phosphate-buffered saline containing 4% formaldehyde. Brains were dissected and stained with Golgi impregnation. Left medial prefrontal cortexes were taken from the stained tissues and embedded in epoxy resin. The staining and embedding procedures were performed as reported previously (Mizutani et al., 2019).\nSynchrotron radiation X-ray microtomography and nanotomography\nThe resin-embedded samples were first subjected to simple projection microtomography at the BL20XU beamline (Suzuki et al., 2004) of the SPring-8 synchrotron radiation facility to visualize the structure of the entire tissue. The data collection conditions are summarized in Supplementary Table S1. Absorption contrast X-ray images were collected using a visible-light conversion type X-ray imaging detector consisting of a phosphor screen, optical lenses and complementary metal-oxide semiconductor (CMOS) camera (ORCA-Flash4.0, Hamamatsu Photonics, Japan), as reported previously (Mizutani et al., 2019). Three-dimensional structures of the samples were reconstructed with the convolution back-projection method in order to determine layer positions. An example of the structure is shown in Supplementary Figure S28.\nTissue volumes corresponding to layer V were then visualized with synchrotron radiation X-ray nanotomography (nano-CT) equipped with Fresnel zone plate optics (Takeuchi et al., 2002). The nano-CT experiments were performed as reported previously (Mizutani et al., 2019, 2021, 2023) at the BL37XU (Suzuki et al., 2016) and the BL47XU (Takeuchi et al., 2009) beamlines of SPring-8, and at the 32-ID beamline (De Andrade et al., 2016, 2021) of the Advanced Photon Source of Argonne National Laboratory. The data collection conditions are summarized in Supplementary Table S1. Photon flux at the sample position in the BL47XU experiment was determined to be 1.0 \u00d7 10\u00b9\u2075 photons/mm\u00b2/s by using Al\u2082O\u2083:C dosimeters (Nagase-Landauer, Japan). Photon fluxes at the BL37XU and at the 32-ID beamlines were reported previously (Mizutani et al., 2023). Spatial resolutions were estimated from the Fourier domain plot (Mizutani et al., 2016) or by using three-dimensional test patterns (Mizutani et al., 2008).\nTissue structure analysis\nThe obtained datasets were processed with the convolution-back-projection method in the RecView software (RRID: SCR_016531; https://mizutanilab.github.io/) (Mizutani et al., 2010) to reconstruct three-dimensional images (Figure 1A), as reported previously (Mizutani et al., 2019, 2023). The image reconstruction was conducted by RS and KS. The obtained image datasets were shuffled with human datasets from our previous study (Mizutani et al., 2023) and provided to RM without any data attributes. RM built Cartesian coordinate models of tissue structures from the three-dimensional images using the MCTrace software (RRID: SCR_016532; https://mizutanilab.github.io/) (Mizutani et al., 2013). After the model building of each dataset finished, the coordinate files of the structural models were locked down. Then, RM reported the number of neurite segments to RS. RS aggregated the numbers in order to equalize analysis amounts between mouse individuals and between human and mouse. Datasets that should be further analyzed were determined by RS and provided to RM without any data attributes or aggregation results.\nThese model building procedures were repeated for three batches of nano-CT datasets. The first two batches consisted of eight mouse datasets (M1A, M1B, M1C, M2A, M2B, M3A, M3B, and M4A) and 12 human datasets of our previous study (Mizutani et al., 2023). The information of these datasets was disclosed to RM after the model building of these two batches was finished in order to report the human study (Mizutani et al., 2023). The other batch consisted of 13 mouse datasets, two dummy mouse datasets unrelated to this study, and eight human datasets. The dummy mouse and human datasets were included in order to shuffle the datasets. After the model building of the entire batch finished, the dataset collection date was first disclosed to RM to correct the voxel width which was tentatively defined. After the voxel width was corrected, the coordinate files were locked down and all attributes of the datasets were opened to assign each dataset to mouse individuals.\nThe human datasets and the two dummy mouse datasets unrelated to this study were not used in the subsequent analysis. All other 21 datasets were subjected to structural analysis. Structural parameters were calculated from Cartesian coordinate models by using the MCTrace software, as reported previously (Mizutani et al., 2019, 2023). The soma width was defined with the diameter of the largest spherical nodes composing the neuron. The soma length was defined as the length along spherical nodes having a diameter larger than half the soma width (Figure 2A). Statistics of the obtained structural parameters are summarized in Supplementary Tables S2\u2013S4.\nPhoto image datasets\nThe photo image datasets used for training generative Als were taken from hyperlinks in the Datasets page of the kaggle.com website (https://www.kaggle.com/datasets). The CelebA dataset (Liu et al., 2015) was used as the dataset of human-face photos. A partial CelebA dataset consisting of the first 5199 images in numerical filename order was also prepared to examine the effect of the number of images per dataset. The train-cat folder of the Animal Faces HQ dataset (Choi et al., 2020) was used as the dataset of cat face photos. The Birds 525 Species dataset was used as the dataset of bird photos. The Cheese Pics dataset was used as the source of cheese photos. Since the Cheese Pics dataset contains photos of humans, buildings, packages, and cooked foods, we examined the contents of all 1824 folders of this dataset and chose 165 folders (Supplementary Table S10) which mainly contain cheese photos. All images of these datasets were scaled to 64 \u00d7 64 pixel dimensions and to pixel values in a 0\u20131 range prior to training.\nThe analysis of the dataset statistics and the AKAZE local feature matching (Alcantarilla et al., 2011) were conducted using the OpenCV-4.10.0 library (https://opencv.org/releases/). The AKAZE feature matching was performed using the first 2000 images of each dataset. Prior to the feature point detection, the images in the 64 \u00d7 64 pixel dimensions were converted to gray scale and resized to 256 \u00d7 256 pixels.\nGenerative adversarial network\nThe structural analysis of mouse cerebral tissue indicated that mouse neurites are thin and tortuous compared with those of humans. This means that neuronal connections are confined depending on the distance between neurons. We incorporated this finding in an artificial neural network by masking weights with a window matrix, which are multiplied with the weight matrix in an element-by-element manner (Mizutani et al., 2022). In this study, the inter-node distance was defined by assuming a two-dimensional arrangement of nodes (node position x, y) in order to mimic the laminar organization of neurons in the cerebral cortex. The inter-node distance was defined along the channel dimensions (Figure 4A). Fractional coordinates (x / total nodes along x dimension, y / total nodes along y dimension) were used to calculate the Euclidean distance between nodes. Elements of the window matrix were set to 1 if the fractional distance between a node pair is less than a predefined threshold, and set to 0 if the distance is equal to or larger than the threshold.\nThe mouse-mimetic convolutional layers with the two-dimensional window were implemented in the generator of the DC-GAN (Supplementary Table S5A; Radford et al., 2016). The discriminator of the GAN was made of four standard convolutional layers and a fully-connected top layer (Supplementary Table S5B). Batch normalization (Ioffe & Szegedy, 2015) was applied to hidden layers of the generator, and spectral normalization (Miyato et al., 2018) to hidden layers of the discriminator. ReLU activation function was used in the hidden layers of the generator, and leaky ReLU in the hidden layers of the discriminator.\nConditional GAN (Mirza & Osindero, 2014) was performed by using the same configurations as the unconditional GAN described above, except for adding image class inputs. The datasets of CelebA, Birds 525 Species, and Cheese Pics were sharded in order to extract approximately 5,000 images for each image class. The extracted images of the three image classes along with the entire Animal Faces HQ cat faces dataset were merged and shuffled to compose a class-labeled dataset used for training the conditional GAN model.\nThese GAN models were trained from scratch using the Adam algorithm (Kingma & Ba, 2015) with a batch size of 32, learning rates of 1 \u00d7 10\u207b\u2074, and \u1e9e\u2081 of 0.5 for both the generator and the discriminator. The discriminator was trained once per cycle. The number of training epochs was set to 25 for the CelebA dataset. This corresponds to approximately 160,000 steps of training. The number of training epochs for other datasets was determined so as to set the total number of steps to be approximately 80,000. The Fr\u00e9chet inception distance (FID; Heusel et al., 2017) was calculated from 51200 images by using the code provided at https://github.com/jleinonen/keras-fid. The training and evaluation were repeated for 10 runs. Examples of the FID score progress during training are shown in Supplementary Figure S22. The calculations were performed using Tensorflow 2.16.1 and Keras 3.3.3 running on the g4dn.xlarge instance (NVIDIA T4 Tensor Core GPU with Intel Xeon Cascade Lake P-8259CL processor operated at 2.5 GHz) of Amazon Web Service. The training for 80,000 steps took typically 3 hours. Python codes are available from our GitHub repository (https://mizutanilab.github.io).\nDenoising diffusion implicit model\nThe mouse-mimetic convolutional layers were implemented in the U-Net (Ronneberger et al., 2015) of the DDIM (Song et al., 2021). The U-Net was downsized to [64, 128, 256, 512] channels from [128, 256, 256, 256, 512] channels of the original implementation for the CelebA dataset (Song et al., 2021) to halve the computation time required for training. The mouse-mimetic parameter reduction was applied to the convolutional layers of the residual blocks with channel dimensions of 256 and 512. The parameter %usage is summarized in Supplementary Table S8. Attention layers were introduced at the 16 \u00d7 16 feature map resolution. Group normalization (Wu & He, 2018) and a swish activation function (Ramachandran et al., 2017) were used in accordance with the GitHub repository of the original DDIM report (Song et al., 2021).\nThe DDIM was trained from scratch using the Adam algorithm (Kingma & Ba, 2014) with a batch size of 64, learning rate of 2 \u00d7 10\u207b\u2074, and \u1e9e\u2081 of 0.9. The number of training epochs was determined so as to set the total number of steps to be approximately 500,000. The Fr\u00e9chet inception distance (FID; Heusel et al., 2017) was calculated from 51200 images generated by 20 diffusion steps. The training and evaluation were repeated for 5 runs using the same environment as the GAN. Examples of the FID scores' progress during training are shown in Supplementary Figure S24. The DDIM training for 500,000 steps typically took about 70 hours. Python codes are available from our GitHub repository (https://mizutanilab.github.io).\nStatistical tests\nThe statistical tests of the structural parameters and FID scores were performed using the R software, as reported previously (Mizutani et al., 2019, 2021, 2022, 2023). Significance was defined as p < 0.05. Differences in the means of the structural parameters between human and mouse were examined using a two-sided Welch's t-test. The relation between the mean FID score and the mean parameter usage ratio was examined by linear regression analysis. Differences in the means of the FID scores were examined using a two-sided Welch's t-test. The p-values of multiple tests were corrected with the Holm-Bonferroni method."}, {"title": "Conflict of interest", "content": "All authors declare no conflict of interest."}]}