{"title": "Bench4Merge: A Comprehensive Benchmark for Merging in Realistic Dense Traffic with Micro-Interactive Vehicles", "authors": ["Zhengming Wang", "Junli Wang", "Pengfei Li", "Zhaohan Li", "Peng Li", "Yilun Chen"], "abstract": "While the capabilities of autonomous driving have advanced rapidly, merging into dense traffic remains a significant challenge, many motion planning methods for this scenario have been proposed but it is hard to evaluate them. Most existing closed-loop simulators rely on rule-based controls for other vehicles, which results in a lack of diversity and randomness, thus failing to accurately assess the motion planning capabilities in highly interactive scenarios. Moreover, traditional evaluation metrics are insufficient for comprehensively evaluating the performance of merging in dense traffic. In response, we proposed a closed-loop evaluation benchmark for assessing motion planning capabilities in merging scenarios. Our approach involves other vehicles trained in large scale datasets with micro-behavioral characteristics that significantly enhance the complexity and diversity. Additionally, we have restructured the evaluation mechanism by leveraging large language models to assess each autonomous vehicle merging onto the main road. Extensive experiments have demonstrated the advanced nature of this evaluation benchmark. Through this benchmark, we have obtained an evaluation of existing methods and identified common issues. The environment and vehicle motion planning models we have designed can be accessed at https://anonymous.4open.science/r/Bench4Merge-EB5D.", "sections": [{"title": "I. INTRODUCTION", "content": "Merging into dense traffic is a typical scenario of highly interactive driving, where autonomous vehicles face significant challenges [1]. The difficulty often arises from the inability to effectively interact with surrounding vehicles to create sufficient space for merging, leading to stagnation. Recently, there has been a growing in research on motion planning in such scenarios [2]-[4], with the hope to enhance the traffic-handling capability in dense merging scenarios. However, a comprehensive evaluation of these methods in simulation remains an unresolved issue. This is primarily due to the interactivity of the merging process, the lack of realistic micro-level interaction behaviors in surrounding vehicles limits further analysis, training, and ultimately, the optimization of these methods.\nTypical closed-loop benchmarks for autonomous driving primarily consists of three components: initial scenario generation, scenario iterative updating, and evaluation metrics, Fig. 1 shows the comparison. In existing studies, generating initial scenarios can be categorized into rule-based arrangements and neural network-based generation. Rule-based methods typically adopt predefined definitions of dense traffic flows from previous research [2], [5]. However, those approaches struggle to reflect the realism of the environment [6]. On the other hand, neural network-based methods for generating initial states usually involve updating the environment over a period of time [7], during which the interaction between vehicles is not well-represented. As a result, these methods are unsuitable for closed-loop simulations in dense merging scenarios [8]. Therefore, a realistic and interactive environment is essential.\nThe primary aspect of iterative scenario updates is the state updating of surrounding vehicles. In closed-loop simulation environments, vehicle movements are typically determined using rule-based methods [9]. Efforts have been made to improve these rules to achieve more diverse behaviors for surrounding vehicles [3]. However, representing micro-level interactions, such as lateral displacements (Y Interaction) of vehicles within a lane, remains a challenge, as shown in Fig. 1, which is a key behavior in dense traffic [10]. Data-driven approaches have increasingly been used for surrounding vehicles, but as mentioned earlier, these generated behaviors are often in the form of pre-determined trajectories, making them unsuitable for real-time interaction [6]. Iterative update planning methods have gained attention as they address the limitations regarding interactions [11]. Nevertheless, these methods still struggle to capture the diversity of behaviors, as neural networks tend to produce averaged strategies. Therefore, the simulation of dense merging scenario requires surrounding vehicles that exhibit microscopic interaction characteristics.\nThe design of evaluation metrics has a profound impact on the final assessment of algorithms. Traditionally, metrics have been discretely categorized into three aspects: safety, efficiency, and comfort [12]\u2013[14]. Existing studies select some of those aspects, as shown in Fig. 1, and fail to consider the drive mode, such as the vehicle is in a hurry or relax. For instance, sharp acceleration rate can improve merging efficiency but significantly compromise safety and comfort, and drive mode also effect the behaviors. This reliance on a single metric leads to a one-sided evaluation of algorithms, failing to capture their overall performance. Therefore, a comprehensive evaluation framework is required to analyze the performance of different methods.\nIn this work, we propose a new benchmark named Bench4Merge for evaluating merging in realistic dense traffic, leveraging large-scale data to filter and extract realistic initial states and classify the initial scenarios to select more targeted environments. We developed a deep neural network architecture to capture the micro-level interaction behaviors from the data. The vehicles update their planning and state based on the frequency of the environment. By incorporating vectorized labels, we achieve diverse interaction styles, addressing the previous limitations of interaction and behavioral diversity in surrounding vehicles. To enable a comprehensive evaluation, we reconstruct the evaluation mechanism, utilizing large language models (LLMs) to score and assess the entire merging process. This approach overcomes the limitations of previous evaluations that relied on single categorical metrics.\nTo summarize, our contributions are as follows:\n\u2022 We highlight key challenges in evaluating motion planning methods for dense merging scenarios.\n\u2022 We propose a new benchmark for merging, named Bench4Merge, which incorporates more realistic merging scenarios, richer microscopic interactive behaviors, and more comprehensive evaluation mechanism.\n\u2022 We have implemented various motion planning algorithms for merging scenarios, uncovering issues that were previously overlooked in evaluations. The complete project has been open-sourced."}, {"title": "II. RELATED WORKS", "content": "Closed-Loop Simulation for Merging Scenarios. The IDM-based approach has been validated to effectively simulate the longitudinal behavior of vehicles [15]. Initially, researchers used improved IDM-based methods to control the surrounding vehicles, capturing the diversity behaviors [4] and adding a prediction module [3], allowing surrounding vehicles to exhibit reactive capabilities. Some also utilized the real data to cluster different types of vehicles [2]. However, this approach is limited in its inability to simulate the microscopic lateral behaviors. Additionally, they conducted a classification of vehicle styles but did not perform a classification of the associated scenarios. To capture realistic microscopic behaviors, real-world dataset has been used to extract vehicle behavior characteristics [16], and diffusion models has been applied to generate diverse scenarios [17], yielding promising results in traffic scenario generation [7]. However, since the generated trajectories lack interactivity, they cannot be applied in closed-loop simulations [18]. Iterative generation methods, which allow other vehicles planning to update with the frequency of the environment [11]. By encoding historical trajectories, maps, and other information into neural networks, real-time planning and execution for environment vehicles can be achieved [19]. We extract the initial scenarios from a well-classified set, building on the capability for closed-loop updates to reflect interactivity, meanwhile, we employed additional data labeling to enable the vehicle to exhibit different interaction styles.\nEvaluation Metrics for Merging in Dense Traffic. The evaluation metrics for motion planning in dense merging scenarios are generally categorized into safety, efficiency, and comfort. Safety can be further divided into explicit and implicit safety. Collision rates represent explicit safety, while metrics TTC (Time to Collision) and TH (Time Headway) indicate implicit safety [20], [21]. For traffic efficiency, metrics such as average travel time, timeout rates and average speed [22]-[24] are used. There has been a growing interest in the microscopic aspects of merging maneuvers, including the distribution of merging zones and the distance traveled before merging [25], [26]. Additionally, some researchers have analyzed the fluctuations in overall traffic flow caused by merging behavior to assess the impact of the merging vehicle [27]. For comfort, initial assessments often relying on defining acceleration ranges [28] or calculating Jerk to measure fluctuations in vehicle acceleration [14]. Most of the existing research primarily considers only a single metric. Some studies have considered multiple metrics and assigned weights to each [29], yet the specific values of these weights remain highly arbitrary. Our evaluation are more comprehensive and better aligned with human evaluations."}, {"title": "III. BENCH4MERGE", "content": "Overview\nBench4Merge consists of three main components: Scenario-level Generation, Micro-Controllable Model for Main-Lane Vehicles, and LLM-Based Evaluation, as shown in Fig. 2. Firstly, unlike the method of randomly arranging the initial scene based on predefined rules, our scenarios are derived entirely from classified real-world data. Secondly, the motion policy of surrounding vehicles are trained on large-scale dense merging traffic datasets, effectively capturing micro-level interactive characteristics. We incorporate feature tags to reflect different vehicle personalities, enabling each vehicle in the environment to individually observe states, plan trajectories, and dynamically update them iteratively to achieve real-time micro-interactions. Finally, the final evaluation module is based on an LLM. Our approach leverages the LLM to score the merging process of the tested vehicle and provide improvement suggestions. This method addresses the limitations of previous discrete metrics and allows for dynamic adjustments based on the driving mode of a vehicle.\nInitial Scenarios\nTo achieve realistic initial environment generation, we extracted initial scenarios from the real world [30] and classified these scenarios to provide Bench4Merge with a more diverse set of scenes for comprehensive evaluation of different methods. This approach overcomes the limitations where vehicles were merely arranged along the centerline according to predefined rules [3], [4], lacking realism and diversity in initial environment generation.\nUltimately, we extracted over 50,000 initial scenarios from the DJI Dense Traffic Dataset [30]. As shown in Fig. 3, it is evident that the average speed and average distance in each scenario exhibit a linear relationship: the lower the average spacing, the slower the average speed. We classified the scenarios using the Gaussian Mixture Model (GMM) algorithm [31], with the average speed and average spacing as classification features, dividing the scenarios into three categories: highly dense environments, medium dense environments, and lower dense environments. Table. IV in Chapter IV demonstrates the significance of classifying these environments.\nMicro-Controllable Vehicles Model\nTraining Data Construction. We selected the DJI Dense Traffic Dataset as the primary data source [30]. To enhance data diversity and improve the generalization capability of the vehicle control model, we also extracted a significant amount of related data from merging scenarios within the nu-Plan [32] and ExiD [33] datasets. To better represent a variety of behavioral types among those vehicles, we conducted an analysis of the selected data, ultimately classified the vehicles into three categories: long vehicles, offensive vehicles, and friendly vehicles, as these three types exhibit significant differences in interaction behaviors. Fig. 4(a) shows the distribution of vehicle lengths, according to Chinese traffic regulations, the dividing line between long and short vehicles is defined as 6m, with average length of 4.7m and 11.5m. Both offensive and friendly vehicles fall into the category of short vehicles.\nWe define vehicles that have not been cut in line through- out the entire process as offensive vehicles, while others are classified as friendly vehicles. As shown in Fig. 4(b), offensive vehicles exhibit a greater degree of lateral deviation from the centerline, whereas friendly vehicles demonstrate smaller lateral shifts. This further reinforces the significance of microscopic lateral interactions exhibited by the main road vehicles. Table. III in Chapter IV summarizes the specific data, long vehicles exhibit distinct characteristics compared to the other two types.\nFinally, we constructed each training sample according to Equation. 1. Each sample includes the state of the target vehicle and other vehicles, as well as map information, as shown in Fig. 5. The \"other vehicles\" category includes all vehicles that fall within the ego vehicle's leading range and interactive range.\n$samp_{i} = \\begin{cases} vech_{ego} = \\{x, y, \\theta, v_{x}, v_{y}, a_{x}, a_{y}, d, label\\} \\\\ vech_{i}^{other} = \\{x, y, \\theta, v_{x}, v_{y}\\} \\\\ road = \\{x_{main}, y_{main}, x_{merge}, y_{main}, x_{merge}^{inter}, y_{merge}^{inter}\\} \\end{cases}$ (1)\nwhere the coordinate system is centered at the rear axle of the target vehicle, $\\theta$ represents the heading angle, $v$ denotes the velocity, $a$ signifies the acceleration, and $d$ indicates the distance to the vehicle ahead. The $label$ corresponds to the vehicle's style labels. $x_{main}$, $y_{main}$ are the waypoints of main lane and $x_{merge}$, $y_{merge}$ are the waypints of merging lane. Our environment updates at a frequency of 10 Hz, with each data sample comprising 50 frames of information. The first 10 frames serve as input, while the subsequent 40 frames are used as ground truth. It is worth noting that our vehicle classification method can be adapted to distinguish a wider range of styles as needed.\nTraining Setting. We design an imitation-learning-based model, to simulate the driving behaviours of the main-lane vehicles, which is shown in the bottom right part of Fig. 2. Aiming at effectively capturing micro-level interactive characteristics, the model takes all the vehicles states $V = \\{V_{i}\\}_{i=1}^{N_{v}}$, including selected vehicle $V$ and main-lane vehicle $V_{m}$, and road lanes $R = \\{R_{j}\\}_{j=1}^{N_{r}}$ as input, planning the future trajectory for each main-lane vehicle based on attention mechanisms. Here, $N_{v}$ and $N_{r}$ represent the number of vehicle and road polylines.\nSpecifically, we represent each vehicle state as $V_{i} \\in \\mathbb{R}^{T_{his} \\times D_{v}}$ and road polyline as $R_{j} \\in \\mathbb{R}^{N_{r} \\times D_{r}}$, where $T_{his}$ and $N_{r}$ correspond to the history frame count and polyline point count, respectively. $D_{v}$ and $D_{r}$ are the dimensions of the input features, where $D_{v}$ consists of the position, velocity, acceleration and the personality label of each vehicle at each timestamp, while $D_{r}$ contains the coordinates of each point. We first normalize these feature to the local coordinate system of a target main-lane vehicle $V_{j}$. Then, the vehicle features and road features are flattened and projected to the same dimension $D$ with two specific linear networks for future attention operation:\n$F_{v} = Linear(\\{V_{i}\\}_{i=1}^{N_{v}}), F_{r} = Linear(\\mathbb{R}, \\{R_{j}\\}_{j=1}^{N_{r}})$. (2)\nThen, the projected features $F_{v} \\in \\mathbb{R}^{N_{v} \\times D}$ and $F_{r} \\in \\mathbb{R}^{N_{r} \\times D}$ are fed into two attention-based modules. A module built with self-attention is first leveraged for $F_{v}$, in which all the vehicle features interact with each other, such that the micro-level interactive characteristics of the vehicles can be captured. In the second module, the updated vehicle features serve as queries and the road features serve as keys and values, together fed into the cross-attention layers. After that, the vehicle features obtain the information of both other vehicles and road structure.\n$F_{v}' = Cross - Attn(Self - Attn(F_{v}, F_{v}), F_{r})$. (3)\nFinally, another linear network is used to predict the future trajectory $p_{pred}^{i} \\in \\mathbb{R}^{T_{fut} \\times D_{v}}$ of the target vehicle:\n$p_{pred}^{i} = Linear_{out}(F_{v}')$. (4)\nNote that we only take the prediction result of the target vehicle for simulation to keep the coordinates consistent. After processing each main-lane vehicle, the whole scenario can be updated.\nDuring training, a driving scene is split into several data samples, each containing one target vehicle. For each data sample, we employ the Mean Squared Error (MSE) loss to supervise the predicted future positions, speeds, and heading angles of the target vehicle:\n$\\mathcal{L}_{tar} = \\frac{1}{T_{fut}} \\sum_{t=0}^{T_{fut}-1} \\lambda (t) ||p_{pred}^{i}(t) - p_{gt}^{i}(t)||_{2}^{2}$, (5)\nwhere $\\lambda (t)$ represents an exponentially decaying weighting mechanism, which allows the prediction errors at different time steps to be weighted according to their significance:\n$\\lambda (t) = e^{-t} + 1$. (6)"}, {"title": "IV. EXPERIMENTS", "content": "Effectiveness of LLM-Based Evaluation\nWe introduce an LLM-based evaluator, specifically, Alibaba's Qwen 70B [35]. To demonstrate the effectiveness of LLM as an evaluation mechanism, we introduced a comparison with human experts [36]. We conducted 100 experiments, saving both video and data, and presented them to human experts in the same format as they were input to the LLM. We invited 10 experts, dividing them into five pairs, with each pair of experts responsible for scoring the same set of 20 samples, as shown in Table. I. We then compared the scores from the experts with those from the LLM. The Pearson correlation coefficient and MSE were used to assess the correlation and differences between the human scores and the LLM scores, with correlation coefficients exceeding 0.8, which can be considered a strong correlation [37]. The differences in scores were all within a range of 1 to 2 points.\nWe further demonstrated the effectiveness of the LLM by instructing it to analyze only one specific aspect. The results, as shown in Table. II, when tasked solely with evaluating efficiency, and when the data was adjusted to reflect a more efficient process, the LLM assigned significantly higher scores for the higher speed. Additionally, when the driving style was altered to a \u201crelax\u201d mode while keeping other data constant, the model's assessment of comfort decreased, this shift occurred because the model prioritized comfort over efficiency in this mode, thereby highlighting the comprehensiveness of our evaluation mechanism.\nEffectiveness of Micro-Controllable Vehicles Model\nWe then demonstrate that the vehicles are capable of reflecting the micro-level characteristics. To this end, we test the environment 100 times, during which we analyzed the differences in key metrics among three vehicle styles we configured. As shown in Table. III, The average distance between friendly and offensive vehicles in the environment is 5.31m and 3.45m, respectively, which closely aligns with 5.35m and 4.07m from the dataset. This demonstrates that our model effectively captures the micro behaviors.\nWe implemented a RL-based method [38] within our environment, the average scores and success rates are lower compared to those in the previous environment as shown in Table. IV. Indicating that previously rule-defined main road vehicles lack the micro-level behaviors of real-world traffic participants, resulting in overly simplistic scenarios. Notably, the vehicles exhibited varying success rates across the three different initial scenarios in our environment, underscoring the significance of our initial environment classification (Section III-B).\nEvaluation of Representative Methods\nWe introduced five representative methods and evaluated them in Bench4Merge. These methods fall into two main categories: optimization-based and neural network-based approaches. For each method, we conducted 100 tests in high-density environments and recorded both the average score and the frequency of suggestions provided by the LLM for each scenario.\nAs shown in Figure 7, we can draw the following conclusions: First, we observed that none of the methods performed well across all aspects. The RL-based method achieved the highest score but exhibited issues with sharply acceleration changes [38]. In contrast, the Imitation Learning method had the lowest score but demonstrated advantages in passing speed [39]. Second, the suggestion \u201cEnhance awareness\" was the most frequently given for optimization-based methods [40], [41], indicating a significant lack of interaction with surrounding vehicles. On the other hand, \"Smooth Acceleration\" was the most common suggestion for neural network-based methods [3], [38], [39], highlighting a deficiency in comfort. Finally, Bench4Merge also revealed issues that had not been identified in previous work, Hierarchical RL have shown significant advantages over Spatio-temporal Planner [41] in previous work [3]. However, in Bench4Merge, the average score reflects only a marginal advantage and is lower than that of RL method. This is because prior metrics did not account for comfort, whereas Bench4Merge offers a more comprehensive evaluation."}, {"title": "V. CONCLUSION", "content": "In this work, we introduced the Bench4Merge for dense merging scenarios, aimed at evaluating the performance of motion planning methods comprehensively. We extracted initial scenarios from large-scale data and classify them accordingly and trained surrounding vehicles to exhibit realistic and diverse interaction behaviors. Finally, we redefine the evaluation mechanism by leveraging an LLM to score and analyze each sample. This evaluation approach overcoming the limitations of previous evaluation methods. From the analysis, we have distilled valuable analysises from various methods, and have open-sourced all environments and algorithms. Future work will focus on generating 3D environments for dense interaction scenarios with scene rendering, catering to the closed-loop testing needs of the increasingly prominent multimodal end-to-end autonomous driving systems."}]}