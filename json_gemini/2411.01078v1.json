{"title": "Effective ML Model Versioning in Edge Networks", "authors": ["Fin Gentzen", "Mounir Bensalem", "Admela Jukan"], "abstract": "Machine learning (ML) models, data and software need to be regularly updated whenever essential version updates are released and feasible for integration. This is a basic but most challenging requirement to satisfy in the edge, due to the various system constraints and the major impact that an update can have on robustness and stability. In this paper, we formulate for the first time the ML model versioning optimization problem, and propose effective solutions, including the automation with reinforcement learning (RL) based algorithm. Without loss of generality, we choose the edge network environment due to the known constraints in performance, response time, security, and reliability. The performance study shows that ML model version updates can be fully and effectively automated with reinforcement learning method as compared to other approaches. We show that with a carefully chosen range of traffic load values, the proper versioning can improve the security, reliability and ML model accuracy, while assuring a comparably lower response time.", "sections": [{"title": "I. INTRODUCTION", "content": "The field of AI and ML has seen unprecedented advance-ments over the past decade, where AI models are continuously being improved in terms of size, performance, robustness and accuracy [1]. In this rapidly evolving domain, ML-based domain applications, such a industry and health care, need to be continuously updated. This comes in addition to related ML software updates as well as data updates. Recent ML Operations (MLOps) advancements recognize that automating and operationalizing ML products presents a new challenge [2]. To assure stability and manage applications and systems that use ML, an effective versioning of ML models, data and code is critical. Considering that most network management operations rely on ML based models, and most applications in IoT, cloud and edge computing today require ML-based functions, this challenge appears even more significant.\nModel robustness is one of the key challenges in ML today, which requires creation of new versions of ML models [3]. The ML model updates on the other hand add performance over-head, and in general can decrease the stability of the system. In some domain applications, like health care, updating ML model is also a matter of safety [4]. In edge networks with constrained resources, several conflicting objectives need to be considered when updating ML models, such as constraints on accuracy, reliability, security, system stability, and resource utilization [5]. Adding any new and enhanced model is con-tingent upon modifying the existing system, and any changes fundamentally carry risks to destabilize the performance [6]. Only a few papers so far addressed this issue, like in [7] on how to update ML model for data series prediction, focused on a a single ML model. Today, multiple ML models updates need to be considered with various conflicting constraints.\nIn this paper, we focus on the problem of ML model versioning and updates in constrained networks. To this end, we formulate for the first time the ML versioning optimization problem and propose an RL-based decision making algorithm to automate and optimize the ML model update process. We also propose the related functional network management archi-tecture of the ML model Update Manager in edge networks. We analyze the performance of our proposed approach by comparing it to conventional update methods used in today's systems. The results show that under a certain network load, RL algorithm achieves a comparably faster response times, while improving model related parameters, such as accuracy, security and reliability. When the network load is higher, the automation with the RL algorithm becomes comparable to a random update process, guess process, which can be explained by the fact that under stressed system, the queue becomes constantly full and replicas remain alive during the whole runtime, not allowing the update agent for downgrading the deployed version to an older one.\nThe rest of the paper is organized as follows. Section II describes the reference architecture. Section III formulates the ML model versioning problem. Section IV describes the RL-based solution. Section V presents numerical results. Section VI concludes the paper."}, {"title": "II. REFERENCE ARCHITECTURE", "content": "Fig. 1.a) depicts the reference system architecture, which features a sample physical infrastructure. The sample network consists of four edge computing nodes (E1, E2, E3 and E4) connected by links (L1, L2, L3 and L4), along with the related worker machines (W1, W2, W3 and W4), similar to our previous work [8]. To control this infrastructure, we assume a container orchestrator, typically Kubernetes, an API gateway, a replication manager, and an Update Manager (our proposal). The system can run multiple IoT-based domain applications, as shown on the left hand side, such as vehicular, smart city, etc. The ML training is assumed in the cloud. As such, the entire system is an example of what is today known as IoT-edge-cloud continuum.\nApplications communicate via API Gateway from the IoT sources via the use of HTTP requests. Let us assume that all application functions are ML applications, and that for each ML application, i.e., ML model, the replication manager decides the creation and removal of model replicas as well as the queuing of the received HTTP requests towards the updates. The nodes in the edge network are assumed to be edge devices that can host a number of dockerized containers,"}, {"title": "III. ML MODEL VERSIONING PROBLEM FORMULATION", "content": "The notation is provided in Table I. We consider a single master multi-worker deployment, including a set of edge nodes $\\Epsilon = \\{E_1, ..., E_n,..., E_N\\}$, where $E_n$ represents the nth edge node. We assume that each edge node is constrained by a certain amount of capacity modeled as a number of CPU units $C_n$, RAM space $R_n$ and Disk space $D_n$. We consider a set of ML models denoted as $\\kappa = \\{1, ..., k, ..., K\\}$. We assume that each ML model k, can have a main version $x \\in [0, X]$, and a subversion $y \\in [0, Y]$. We define a decision variable $a = 1$ when updating a ML model k of version x.y to a newer version $[x + 1].y$ or $x.[y+ 1]$, 0 otherwise. We define a mapping function $g(x, y, a)$ that gives the new version of an ML model k of version x.y after a decision update a. Each version x.y of a ML model k requires an amount of resources $b_{k,x,y} = [b_{k,x,y}^{cpu}, b_{k,x,y}^{ram}, b_{k,x,y}^{disk}]$, of CPU units, RAM and disk space. Each ML model k of version x.y has a average service rate $p_{k,x,y}$ and an average inter-arrival rate $\\lambda_{k,x,y}$, assuming for simplification that $p_{k,x,y} = \\mu, \\lambda_{k,x,y} = \\lambda, \\forall k,x,y$. We adopt an M/M/N queuing system to analyze the system behavior and to compute the traffic load (in Erlang):\n\\begin{equation}\nload = \\frac{\\lambda}{N \\cdot \\mu}\n\\end{equation}\n1) ML Model Placement: Each ML model of class k requires an amount of resource that can be served by at least one available edge node, such that:\n$\\begin{aligned}\nb_{k,x,y}^{cpu} \\leq max\\{C_n\\}, \\forall k,x,y \\in [1, K] \\times [0, X] \\times [0, Y]\n\\forall n \\in [1,N]\n\\end{aligned}$\n$\\begin{aligned}\nb_{k,x,y}^{ram} \\leq max\\{R_n\\}, \\forall k,x,y \\in [1, K] \\times [0, X] \\times [0, Y]\n\\forall n \\in [1,N]\n\\end{aligned}$\n$\\begin{aligned}\nb_{k,x,y}^{disk} \\leq max\\{D_n\\}, \\forall k,x,y \\in [1, K] \\times [0, X] \\times [0, Y]\n\\forall n \\in [1,N]\n\\end{aligned}$\nWe denote by $\\delta_{k,x,y}(n)$ the number of replicas from ML model k of version x.y allocated in node $E_n$. The resource allocation has the capacity constraints, i.e.,\n$\\begin{aligned}\n\\sum_{k=1}^{K} \\sum_{x=1}^{X} \\sum_{y=1}^{Y} b_{k,x,y}^{cpu} \\delta_{k,x,y}(n) \\leq C_n, \\forall n \\in [1,N]\n\\end{aligned}$\n$\\begin{aligned}\n\\sum_{k=1}^{K} \\sum_{x=1}^{X} \\sum_{y=1}^{Y} b_{k,x,y}^{ram} \\delta_{k,x,y}(n) \\leq R_n, \\forall n \\in [1,N]\n\\end{aligned}$\n$\\begin{aligned}\n\\sum_{k=1}^{K} \\sum_{x=1}^{X} \\sum_{y=1}^{Y} b_{k,x,y}^{disk} \\delta_{k,x,y}(n) \\leq D_n, \\forall n \\in [1,N]\n\\end{aligned}$\n2) Delays: We consider four types of delays: processing delay, transmission delay, delay to spawn a replica (where applicable) time and queuing delay. The processing delay $T_{k,x,y,n}^p$ of an ML model k of version x.y deployed through a pod in node $E_n$ is distributed around an average value. We consider transmission and propagation times to be a constant parameter since they depend on the distance between worker (edge) nodes and the so-called master node (corresponding to the practical case in Kubernetes). In a single master multi-worker deployment, the routing and path computation is typi-cally managed by the container orchestrator (e.g., Kubernetes). We denote by $T_{k,n}^t$ the transmission delay of a request $f(k)$ between master node and worker node $E_n$. The spawn time $T_{k,n}^{spawn}(a)$ of a replica of ML model k of version x.y with a decision update a is assumed to be constant for all type of ML models. Considering that the creation of a new replica is triggered by either the Replication Manager while scaling up the system, or by Update Manager, when we decide to update the deployed replica of the ML model k with version x.y to a newer version $x.[y + 1]$ or $[x + 1].y$. When the ML model k is not updated, we set the spawn time $T_{k,n}^{spawn}(a = 0) = 0$.\nWe assume the system has a queuing buffer for each ML model k, assessed by Replication Manager, which can use a smart monitoring algorithm, such as the described in [9], to scale the system. We denote by $T_q^f(k)$ the total queuing delay of a request $f(k)$ of ML model k. The queuing delay is measured as the difference between the departure request time and the arrival request time plus the transmission plus the spawn time and the processing time. Finally, the total delay $T_{f(k)}$ for each request $f(k)$ of ML model k, processed using a replica that runs version x.y is given as:\n$\\begin{aligned}\nT_{f(k)}(x, y, a) = T_{k,g(x,y,a), n}^p + T_{k,n}^t + T_{k,n}^{spawn}(a)\n+ T_q^{f(k)}, \\forall k \\in [1, K]\n\\end{aligned}$\nThe average delay for all the requests, defined as an objective to minimize, is given by:\n$\\begin{aligned}\nO_1(\\Delta, a) = \\frac{1}{KF} \\sum_{k=1}^{K} \\sum_{f=1}^{F} T_{f(k)}(x, y, a)\n\\end{aligned}$\nwhere $\\Delta$ describes the state of the network, including nodes, and deployed replicas of ML models and their versions.\n3) ML Model Accuracy: After training an ML model k, we obtain a new version that is assumed to have a higher accuracy. We denote by $Acc_k(x, y, a)$ the accuracy of a ML model k with version x.y after taking an update decision a. The average accuracy of all requests is given by:\n$\\begin{aligned}\nO_2(\\Delta, a) = \\frac{1}{KF} \\sum_{k=1}^{K} \\sum_{f=1}^{F} Acc_k(x, y, a)\n\\end{aligned}$\n4) Security and Reliability: We assume that updates can improve the security and reliability of an ML model, defined as parameters $Sec_k(x, y, a), Rel_k(x, y, a)$ assigned to ML model k with version x.y after taking an update decision a. We define two objective functions for the security and reliability as an average among all requests given by:\n$\\begin{aligned}\nO_3(\\Delta, a) = \\frac{1}{KF} \\sum_{k=1}^{K} \\sum_{f=1}^{F} Sec_k(x, y, a)\n\\end{aligned}$\n$\\begin{aligned}\nO_4(\\Delta, a) = \\frac{1}{KF} \\sum_{k=1}^{K} \\sum_{f=1}^{F} Rel_k(x, y, a)\n\\end{aligned}$\nB. Problem Formulation\nWe define our ML Model Versioning Problem (MMV) as a multi-objective optimization problem, aiming at maximizing the average ML model accuracy, security and reliability of all processed requests while minimizing the average delay. The MMV problem is formulated as follows:\n$\\max_{a \\in A} (-O_1(\\Delta, a), O_2(\\Delta, a), O_3(\\Delta, a), O_4(\\Delta, a))$\nsubject to: Eq.(2), (3), (4), (5), (6), (7)"}, {"title": "IV. Q-LEARNING BASED UPDATE DECISION MANAGEMENT", "content": "The previous problem formulation requires optimizations, which even for small networks, and multiple versions of ML models, and under multiple constraints, can be prohibitively complex. We therefore go immediately in media res of an RL based approach, and leave the optimization programming and the complexity analysis for future work. WIth RL, the system will make decisions when either: i) creating a replica during system scaling the system, or ii) processing of a request from the queue. The former concerns the deployment of a replica with either the most recent version of the ML model, or the initial version; the latter makes the decision on the basis whether the currently deployed replica should be utilized, or a newer version, if available, is to be deployed."}, {"title": "Algorithm 1 RL-based Update Decision Algorithm", "content": "1: Input: events, bk, \u00b5k, network state (Z, Q)\n2: Initialization: Qt, \u03b5, \u03b1, \u03b3, episodes, decay\n3: for each event do\n4:  if update available then\n5:   s\u2190 (Z, Q, e, f),  a = UpdateDecision(s)\n6:   Z', Q', e', f'\u2190 Find next state parameters\n7:   s'  (A', Q', e', f')\n8:   Qt UpdateQTable(s, a, s')\n9:   sts'\n10:  else\n11:   pass\n12:  end if\n13:  if \u20ac > Emin then\n14:   \u20ac \u2190 decay e\n15:  end if\n16: end for\nThe goal of the Algorithm 1 is to select an action, as defined in Eq. 14. During warm-up, where previous actions were taken, or the RL model has not learned yet to accurately choose ac-tions, an exploration phase is needed. We consider an e-greedy approach to explore the search space and try new actions. We denote by e the exploration probability, where at each step the RL agent chooses randomly an action with probability \u20ac and uses the accumulated knowledge with probability 1 \u2013 \u0454. As the simulation progresses, the exploration-exploitation factor declines linearly until it reaches a minimal value. At each point of decision, the agent checks the state of the environment from"}, {"title": "V. NUMERICAL EVALUATION", "content": "The objective of our numerical evaluation is to assess the performance of the RL update agent in determining whether to proceed with an update to the newest version of an ML model, or to maintain operation of the existing stable ML version. To this end, we used an event based simulator running up to 2 million arrival request events and around 5000 version update events, which assured a 98% confidence. We used a First-fit algorithm for resource allocation, a monitoring-based scaling for creating and removing replicas, which simply replicate whenever a the load reach a certain threshold, and remove replicas when the queue gets empty, the allocation and scaling were well analyzed in [9], and theoretically in [10].\nWe compare different types of update strategies in order to evaluate the performance of the RL update agent: i) always update, ii) never update and iii) select an update randomly. Our topology consists of 4 nodes in a star topology around the master node of a cluster, which in our case is node 1, see Table III, considered as a worker node as well. All nodes are assumed to have 16 CPU cores, 16 GB of RAM, and 1 TB of disk capacity. The transmission delay between each node to the master node is assumed to be 0, 2.75, 7.25, and 10.25 (ms).\nWe consider 5 distinct ML models to be deployed in the system, as outlined in Table II. The main versions of each ML model vary from 1 to 10, subversions from 0 to 104, with average service time \u03bc = 10, average inter-arrival time from 3.25 to 8, the spawn time is 10 ms, for all ML models. We assume that the CPU requirement is different between models, k CPU units for ML model k. The RAM requirements is 1 BG for model 1 and 2, and 2 GB for model 3 and 4, and 6 for model 5. The disk req. is the same for all models with 0.1 TB. We set a security parameter per version between 0.6 and 1 for model 1, 2, 3, and 5, and between 0.7 and 1 for model 5. The reliability parameter varies between 0.9 and 1 for all models, and the model accuracy between 0.5 and 1 for model 1, 2, and 3, and between 0.7 and 1 for model 4 and 5. A subversion update will randomly alter the values of reliability, security or accuracy by a small margin. For the reward function defined in eq. (15), the weights were chosen to be w\u2081 = 1, W2 = 10 , w3 = 10 and w4 = 10. For Q-table update, we set a = 0.01, \u03b3 = 0.99, the initial exploration probability \u20ac = 1, this will decay with an decay up to an minimal Emin = 0.001 which will be reached after half of the scheduled events have been processed. The RL settings are mostly used for training and proved a good performance.\nFig. 2 illustrates the performance metrics for various update approaches under different traffic load conditions using Eq. 1, varying from 30% up to a maximum value of about 80%. Figs. 2a, 2b, 2c display the average security (03), average reliability (04), and average accuracy (O2) as a function of the system load. The performance achieved follow follow the same trend. As the traffic load increases, the parameters for all update policies are observed to decrease. As anticipated, the method always update is performing the best, as it consistently selects the most recent version with the best parameters (security, reliability, accuracy), i.e., with latest security updates. Never-theless, it decreases with increasing traffic load, because the higher the traffic load the less updates received and processed by the system for the same number of requests. For low traffic load, RL is the second-best approach after always update, as it learns to enhance the parameter values. For higher traffic loads, RL behaves similar to random update, because when the traffic load is high, the system never scales-down replicas, which prevents the system from using old and stable versions and there is minor variation in the decision space. The performance of never update remains consistent for all system loads, as the system maintains identical versions of all ML models.\nFigure 2d shows the average delay for all update strategies. As expected, the delay increases with increasing load. Never update performs the best, which avoids the additional spawn time periods. In order to update a deployed ML model, we shut-down the existing replica and spawn a new one with the most recent ML model, which adds additional delays. RL achieves a lower delay than the random for lower traffic loads. For higher loads, it again exhibits behavior similar to random. As expected, always update performs comparably worse, due to the additional delays at each possible update.\nWe also illustrate of the evolution of the deployed subver-sion for the various decision models, see Figure 3. We show an interval of 1,000 events (after a phase of RL exploitation, and for that we plot the versions after 2 10\u00ba events), showcasing the deployed subversion for ML model 5. Always update (Figure 3a) shows the progressive increase in subversion over time. The minor regressions are due to a not-yet updated replicas for the same ML model, while other replicas have finished the update faster. Never update (Figure 3b) always deploys the oldest version and does not undergo any updates. Random update (Figure 3c) shows the decision of either to"}, {"title": "VI. CONCLUSION", "content": "In this paper, we addressed the problem of automating ML model versioning in constrained edge networks, considering different kind of updates to ML models. We compared a RL based approach to other update strategies, which today are common practice. The simulation results demonstrate that the quality of RL-based decision depends on the traffic load. For less load, RL achieves comparable results to the always update strategy. At the same time, it outperforms the random update in all measurements. Perhaps most importantly, our study showed important limitations and thus directions for further research. We assumed that subversion updates always improve (linearly or exponentially), which is practically not always the case. Also we did not take the stability as a values for the optimization problem into consideration yet, which also is premium in real world systems. Also many more, and larger topologies need to be studied, along with the proper optimizations of the solution. Finally, we did not take into account any downgrading of a version. These and many other interesting findings are subject of future research."}]}