{"title": "A Reliable Common-Sense Reasoning Socialbot Built Using LLMs and Goal-Directed ASP.", "authors": ["ZENG, YANK\u0391\u0399", "WANG, HUADUO", "RAJASHEKHARAN, ABHIRAMON", "ARIAS, JOAQU\u00cdN", "BASU, KINJAL", "GUPTA, GOPAL"], "abstract": "The development of large language models (LLMs), such as GPT, has enabled the construction of several socialbots, like ChatGPT, that are receiving a lot of attention for their ability to simulate a human conversation. However, the conversation is not guided by a goal and is hard to control. In addition, because LLMs rely more on pattern recognition than deductive reasoning, they can give confusing answers and have difficulty integrating multiple topics into a cohesive response. These limitations often lead the LLM to deviate from the main topic to keep the conversation interesting. We propose AutoCompanion, a socialbot that uses an LLM model to translate natural language into predicates (and vice versa) and employs commonsense reasoning based on Answer Set Programming (ASP) to hold a social conversation with a human. In particular, we rely on s(CASP), a goal-directed implementation of ASP as the backend. This paper presents the framework design and how an LLM is used to parse user messages and generate a response from the s(CASP) engine output. To validate our proposal, we describe (real) conversations in which the chatbot's goal is to keep the user entertained by talking about movies and books, and s(CASP) ensures (i) correctness of answers, (ii) coherence (and precision) during the conversation\u2014which it dynamically regulates to achieve its specific purpose\u2014and (iii) no deviation from the main topic.", "sections": [{"title": "1 Introduction", "content": "Conversational agents are designed to understand dialogs and generate meaningful responses to communicate with humans. After the popularity of ChatGPT, with its surprising performance and powerful conversational ability, commercial Large Language Models (LLMs) for general NLP tasks such as GPT-4 by Achiam et al. (2023), Gemini from Anil et al. (2023), etc., sprung up and brought the generative AI as a solution to the public view. These LLMs work quite well in content generation tasks, but their deficiency in knowledge-and-reasoning-oriented tasks are well-established by now, according to Nezhurina et al. (2024). These models themselves cannot tell whether the text they generate is based on facts or made-up stories, and they cannot always follow the given data and rules strictly and sometimes even modify the data at will, also called hallucination. The reasoning that these LLMs appear to perform is also at a very shallow level. These are serious flaws that make the LLMs unsuitable for fact-based conversations such as providing correct information to a user. The reason for this flaw is that LLMs generate text that"}, {"title": "2 Background and Related Work", "content": "This section introduces s(CASP), the reasoner used to control the conversations. It also presents state-of-the-art Chatbots and discusses their limitations."}, {"title": "2.1 Answer Set Programming and s(CASP)", "content": "Answer Set Programming (ASP), according to Brewka et al. (2011) and Gelfond and Kahl (2014), is a logic programming paradigm suited for knowledge representation and reasoning that facilitates commonsense reasoning. The s(CASP) system proposed by Arias et al. (2018), is an answer set programming system that supports predicates, constraints over non-ground variables, uninterpreted functions, and, most importantly, a top-down, query-driven execution strategy. These features make it possible to return answers with non-ground variables (possibly including constraints among them) and compute partial models by returning only the fragment of a stable model that is necessary to support the answer.\nComplex commonsense knowledge can be represented in ASP and the s(CASP) query-driven predicate ASP system can be used for querying it, as shown in the work done by Chen et al. (2016) and Xu et al. (2023). Commonsense knowledge can be emulated using (i) default rules, (ii) integrity constraints, and (iii) multiple possible worlds, according to Gelfond and Kahl (2014) and Gupta (2022). Default rules are used for jumping to a conclusion in the absence of exceptions, e.g., a bird normally flies, unless it's a penguin.\n\nflies(X) :- bird(X), not abnormal_bird(X).\nabnormal_bird (X) :- penguin(X).\n\nIntegrity constraints allow us to express impossible situations and invariants. For example, a person cannot be dead and alive at the same time.\n\nfalse :- person(X), dead(X), alive(X).\n\nFinally, multiple possible worlds allow us to construct alternative universes that may have some parts common but other parts inconsistent. For example, the cartoon world of children's books has a lot in common with the real world (e.g., birds can fly in both worlds), yet in the former birds can talk like humans but in the latter they cannot.\nA large number of commonsense reasoning applications have already been developed using ASP and the s(CASP) system: Sartor et al. (2022); Chen et al. (2016); Xu et al. (2023). Justification for each response can also be given as the s(CASP) system can generate justifications for successful queries as proof trees as shown by Arias et al. (2020)."}, {"title": "2.2 State-of-the-art Chatbots and Their Limitations", "content": "Conversational agents (chatbots) have been an active area of research for a long time. Rule-based or finite-state-based systems, like Eliza by Weizenbaum (1966), Chat-80 by Warren and Pereira (1982), and PARRY by Colby et al. (1971), encode the mapping of user commands to ontology using rules and state transitions. The Conversational Knowledge Template (CKT) approach proposed by Basu et al. (2021b) enables the system to control the dialog flow and change topics. Here, the main challenge is parsing the dialogs and correctly extracting the knowledge conveyed in the dialogs.\nUntil recently, transformer-based Large Language Models, pre-trained on an enormous quantity of well-annotated data, have been applied to general NLP tasks. With the advent of Large Language Models, the paradigm changed from pre-training and fine-tuning (Casola et al. (2022)) to teaching a language model any arbitrary task using just a few demonstrations, called in-context learning, a method of prompt engineering. Brown et al. (2020) introduced an LLM called GPT-3 containing approximately 175 billion parameters that have been trained on a massive corpus of filtered online text, on which the well-known ChatGPT is based. GPT-3 and its successor GPT-4"}, {"title": "3 Socialbot Design", "content": "The AutoCompanion is designed to model the human thought process during conversations. When humans hear a sentence, they parse it to extract its meaning and represent the meaning in their minds as knowledge. Humans will check for consistency and correctness of this knowledge using additional (commonsense) knowledge, that also resides in their mind, to find any gaps in the captured knowledge wrt their goal. If human reasoning reveals gaps in this knowledge, they may ask further questions to cover this gap. Once the knowledge is (reasonably) complete, humans will draw a conclusion. This conclusion\u2014that also represents knowledge\u2014will be translated into a natural language response. Therefore, similar to humans, when AutoCompanion receives a user sentence, it will also process it using three stages: First, it will parse the natural language input to knowledge, which is done by LLMs reliably. Next, it will check the consistency and correctness of the input knowledge and use the knowledge extracted from the dialog, in conjunction with commonsense knowledge it already possesses, to reason out the next action. The ASP reasoning system is used to implement this capability. Finally, the knowledge representing the next step (conclusion) is converted into a natural language response by another invocation of the LLM and communicated.\nThis mechanism is embodied and known as the STAR framework by Rajasekharan et al. (2023), which leverages the advantages of LLMs and ASP systems by combining them systematically. It parses the semantics of the text sentences to generate the predicates using LLMs such as GPT 3.5 or GPT 4. After that, it sends the predicates to the ASP system to get reliable answers through reasoning. This framework was previously applied to task-oriented chatbots such as AutoConcierge by Zeng et al. (2024) and has proved to work well. Indeed, LLMs do not parse the sentences to knowledge with 100% accuracy, but LLMs have proven to be the most effective semantic parsers by far. Prior to LLMs, Basu et al. (2021a) used parsers such as the Stanford CoreNLP parser and the spaCy parser, and those methods were largely ineffective in extracting semantics. Besides, the wrong predicate generated by LLMs can often be checked by additional logic written in ASP.\nUnlike task-oriented chatbots, socialbots are not set to complete a task. Hence, they can chat without a goal, until whenever the user likes to end the conversation. This requires AutoCom-"}, {"title": "3.1 LLM Parser and Ontology", "content": "AutoCompanion leverages LLMs such as the GPT series to parse the natural language sentences to knowledge. The prompts are given to LLMs including the knowledge ontology, which is represented in the predicates used in the reasoning part, and several examples covering the use cases."}, {"title": "3.2 Topic Control", "content": "We leverage an ASP reasoner to guide and switch between the topics. Predicates from the LLM parser are separated into themes and preferences that are recorded and updated, and one theme is randomly picked to respond with. The remaining themes will be used in later rounds where nothing is captured from the user's input. Then, the ASP reasoner chooses whether to remain in the same topic instance or switch to a relevant one by the below strategy: if the instance is first mentioned, the reasoner maintains it for one more round; otherwise, a random function is applied to decide whether to continue the current instance, the current property, or start a relevant one. The maintaining and shifting can be well described by two separate mechanisms, CKT and RCC.\nConversational Knowledge Template (CKT) by Basu et al. (2021b) is used when the ASP reasoner continues the current topic instance. It maintains a state with a list of properties that can be discussed for each topic instance. Once the reasoner chooses to go deeper into one instance using other properties, the CKT will be triggered to pick up one property that has not been discussed yet for this topic instance. On the other hand, the CKT can also choose to remain on the current property, which will lead the LLM response generator (see Section 3.3) to tell something new about this property (e.g., depict another plot, etc.).\nCKT also controls AutoCompanion's attitude about an instance and its properties. Four kinds of attitudes are used in AutoCompanion: positive, negative, ask, and acknowledge. For a new"}, {"title": "3.3 Response Generation", "content": "Due to the lack of detailed information about each movie (e.g. for plots, lines, etc.), book (e.g. for plots, characters, etc.), and person (e.g. for skills, appearance, etc.), our AutoCompanion leaves the generation of these specifics to LLM, controlling only the topic and property for each round. We assume that the LLMs are experts in common topics such as famous movies and books, which makes it possible for us to leverage this advantage of LLMs in constructing AutoCompanion. Once a comprehensive knowledge base is built for these topics, control over the specific content level can also be exerted.\nWhile leveraging the LLMs for content generation, a proper prompt makes the output closer to the expected performance. In our designed prompt, we first describe the conversation situation and the LLM's role and define the response tone and length. Then we provide the LLM with some examples and ask it to generate the content following the format of the examples. The examples always start with a question with the template:\nWhat are the most interesting [property] for [topic] (instance]? [attitude] ->\nAnd LLM would generate an answer for that. For example, If we ask about the value expressed in Batman Begin:\nWhat are the most interesting value expressed for Batman Begins? positive ->\nThe LLM would generate:\nI feel like Batman Begins nails it with the whole inner battle vibe. It's not\njust about taking down bad guys; it's Bruce Wayne wrestling with his own demons,\nand that's what makes it hit home. Do you have the same feeling as me?\nIf the LLM cannot find any specific content that supports the given attitude, we allow the LLM to oppose its attitude toward the content, and this will be captured by the topic controller.\nThe function of the \u201cattitude\" predicate is to help LLMs generate some alternative perspectives other than the mainstream ones. During the AutoCompanion construction, we found out that LLMs seldom create a view that strays too much from the common views of the public. However, for an ordinary human, not all of their opinions may match the mainstream. Therefore, randomness should be added to the attitude to help LLMs generate \u201csurprising\u201d responses.\nIf the RCC mechanism is invoked, the response generator will also create cohesive sentences that naturally mention the next topic instance to discuss. The template for a cohesive sentence is:\n\"Because you mentioned [source_topic_instance], it makes me think of the\n[next_topic] [next_topic_instance), since [relation_of_them].\"\nSimilarly, if the reasoner answers the questions from the user, one of the following templates will be used according to the condition:"}, {"title": "4 Implementation", "content": "AutoCompanion is constructed in Python with the s(CASP) goal-directed ASP Reasoning Engine (Arias et al. (2018)). GPT-4 is chosen as the LLM in both the LLM Parser and Response Generation stages."}, {"title": "4.1 Data Collection", "content": "We deployed our AutoCompanion to discuss movies, books, and the people involved.\nMovies: The movie data is from IMDb dataset, where we collected the information of release year, runtime, rating, countries involved, languages, genres, top 10 casts with their characters, directors, writers, editors, composers, producers, cinematographers, and the plot summary. The above information is then marked as properties for answering users' questions and linking the movies to related people. Other than those above, the properties of the movie topic include plot episodes, scenes, lines, costumes, awards, music, values expressed, characterization, cinematography, technique, actor performance, adaption, and social impact, which are out of the knowledge base but are likely to be mentioned by the users. We store the database locally with a selection of 500 top-rated movies, and the 500 most popular movies since 2010, resulting in 931 movies.\nBooks: They were collected from the Users-Books-Dataset, including 528 books with information about their series, author, rating, language, genres, awards, setting places, characters, and plot description. These are also recorded as properties along with their writing style, symbolism, emotional impact, and social background.\nPeople: The data of the people associated with the movies are also extracted from the IMDb database and stored locally. The people topic contains properties of birth year, death year, profession, and representative work, whereas the skills, awards, appearance, and personal life require an LLM to generate. We extracted all people linked to the selected movies, resulting in a knowledge base of 5625 data. The authors in the book's knowledge base are also matched to the corresponding movie people.\nIdentifying in-theater movies and bestsellers in bookstores is also required for recommendation mode. We leveraged IMDb's website for movie in-theater by providing location information, and chose USA Today's Best-Selling Booklist as our best-selling book data and extract further details from Open Library. The knowledge from the recommendation knowledge base is used"}, {"title": "4.2 ASP Coding", "content": "Below are several coding examples of the ASP implementation of the reasoning part of our AutoCompanion. In this part, we will elaborate on how the CKT and topic switching work in our s(CASP) program.\nCKT implementation. The CKT component chooses what property to discuss under a topic. The code for CKT is shown below:\n\nnext_attr(Topic, Name, Attr) :- continue_attr, talk(Topic, Name, Attr),\nresponse_attr(Topic, Attr).\nnext_attr(Topic, Name, Attr) :- response_attr(Topic, Attr),\nnot neg_next_attr(Topic, Name, Attr).\nneg_next_attr(Topic, Name, Attr) :- not next_attr(Topic, Name, Attr).\nneg_next_attr(Topic, Name, Attr) :- hist(I, Topic, Name, Attr, Attitude, From).\n\nThe first rule indicates to continue the current property if continue_attr, which is evoked by a random function, is true. The second and third rule forms an even loop, making it possible to choose any available property. The fourth rule defines that the discussed property should not be selected.\nTopic switching. When a topic continues for several rounds, the reasoner may switch to a related topic. This is implemented by the codes below.\n\nnext_topic(Topic, Name, Attr, 'None', 'None') :-\nround(I), hist(I, Topic, Name, Attr, Attitude, 'user'),\nnot discussed_before(Topic, Name, Attr).\nnext_topic(Topic, Name, Attr, 'None', 'None') :-\ncontinue_topic, talk (Topic, Name, Attr1),\nnext_attr(Topic, Name, Attr).\nnext_topic(Topic, Name, Attr, Source, Relation) :-\nlen_rcc(I), random(1, I, N), rcc(N, Topic, Name, Source, Relation),\nnext_attr(Topic, Name, Attr).\n\nThe first rule sets out that a new topic should continue for at least one round. The second rule indicates to continue the current topic if continue_topic is true. The third rule describes how to switch the topic to another linked one by a random RCC."}, {"title": "4.3 Leveraging LLMs", "content": "Besides parsing and response generation, LLMs are also used for other purposes.\nProperty enumeration. Before constructing the AutoCompanion, a detailed list of properties is needed for each topic. Although the property list has been equipped with information extracted from the knowledge base, more properties are required to cover as many themes as people might be interested in while chatting. Therefore, an LLM is used to seek a comprehensive list of properties. We used GPT-4 with the following prompt to list the properties.\n\"When people talk about their interests in [topic] in a social chat, what\naspects will they discuss? Please make each point as much different as possible\nfrom others. Summarize each point in a short name.\""}, {"title": "5 Conversation Samples", "content": "Below we display one conversation between the AutoCompanion and a human user, which demonstrates how the AutoCompanion directs and switches between topics.\nBot: Hello! It's delightful coming across another cinema enthusiast. Seen any\nnoteworthy films lately? Or maybe you've been immersed in a captivating\nread? My enthusiasm seems to oscillate between both constantly!\nUser: Me too! I just saw Inception. It is a great idea to take action on one's\ndream! Dreams in the dreams! What a fabulous idea!\nThemes:\n\ntalk(movie, Inception, plot episode). content (plot episode, actions in dreams).\nattitude(positive).\n\nNext:\n\ntalk(movie, Inception, plot episode). attitude(positive).\n\nBot: Absolutely! The concept of a dream within a dream in Inception is simply\nastonishing. Who could forget that sensational zero-gravity hotel scene?\nThe representation of physics and action was remarkable, wasn't it?\nUser: Yeah! And those people are kicked to wake up from their level of dreams one\nafter another. very impressive and surprising, right?\nThemes:\n\ntalk(movie, Inception, plot episode). content (plot episode, waking up one after\nanother). attitude(positive).\n\nNext:"}, {"title": "6 Evaluation", "content": "Next, we evaluate AutoCompanion's execution efficiency and quality of dialog generation."}, {"title": "7 Discussion", "content": "In this section, we discuss the features of AutoCompanion and the proper ways to use LLMs.\nWhy is AutoCompanion better than the LLM-only socialbots? Compared with LLM-only socialbot, our AutoCompanion has the following advantages: (i) Our AutoCompanion is based on the knowledge base, not pattern matching alone, which allows retrieval of relevant information about any topic instance through a query, avoiding factual errors. When we only use LLM to build socialbots, since the knowledge is not explicitly stored in a specific library, but is compressed and stored using neural networks and weights, this will inevitably lead to confusion between concepts, and hallucinations will emerge. For instance, when asking GPT-4 the below question:\nIs Currie Graham in the movie Hitchcock?\nIt would reply:\nYes, Currie Graham is in the movie \"Hitchcock.\" He plays the role of Bertie,\none of the characters involved in the production of \"Psycho.\"\nHowever, according to IMDb, Currie Graham acts as a PR called Flack in this movie and thus can be corrected through AutoCompanion. There are other advantages of AutoCompanion:\n\u2022 The use of an information database enhances the scalability of AutoCompanion. To update in LLM, we need to either load extremely long relevant texts at any time or train the LLM for a long time. But if a database supplements our information, an update to the knowledge base is all that is needed.\n\u2022 ASP reasoner's ability to control LLM is also a major advantage. LLMs usually require to describe the instructions in as much detail as possible to complete the task better (change topic, recommend, etc.). In the socialbot task for LLMs, this is reflected in the limitation of conversation topics, the choice of strategies for talking about a certain topic for several rounds and then jumping to another topic, the choice of recommendation timing for the latest popular topic instances, etc. However, these instructions usually require a large amount of token space, which will gradually be ignored as the conversation length increases. On the other hand, we don't record the specific content of the conversation but the state is saved in the summary.\n\u2022 The ASP reasoner can specify some less common, out-of-the-box-thinking for an LLM. Even with a certain degree of randomness, it is difficult for LLMs to truly generate some opinions that are far away from most people's thinking. Yet, even if a movie has excellent reviews, there remains a small group of people who don't like it for various reasons. However, when using an LLM directly, it almost always caters to the mainstream views of the public and lacks its \u201cown unique insights\u201d. This can also be avoided by cleverly using an ASP reasoner.\nIs it proper to let LLM generate the fact-based content for use by AutoCompanion? It is well known that LLMs are good at generating coherent text. However, the accuracy of the generated content is not guaranteed. If we have certain requirements on the correctness of the generated content, relying only on an LLM may not be a good choice. Nonetheless, with the increase in training materials, the reliability of LLM has also improved to a certain extent. In such a case then, would it be better to rely only on the knowledge in the knowledge base, and allow LLM to only paraphrase? Not necessarily, because this requires an extremely detailed and complete knowledge base, which we may not have, such as storing all the information about each movie, including all plots, shots, lines, costumes, sets, and other information, as well as opinions about them, and this is almost impossible. For our AutoCompanion, since almost all movies/books/people are well-known to the public, GPT-4 has also been exposed to relevant materials and is familiar with relevant information, so it is feasible for GPT-4 to generate content directly, but it also sacrifices some accuracy. And, since enough constraints are imposed and the sentences are short, we have not observed hallucinated responses in our reasonably extensive experiments. In our future work, the knowledge base will be expanded to cover most movies and books, but if so, a detailed knowledge base is required.\nWhy does LLM always generate answers lacking novelty? When we used GPT-4 to build and use an LLM-only socialbot, we found that the views generated by GPT-4 were often old and boring, not only wrt the property of a certain topic instance, but also wrt the association of one instance to another. For example, when discussing fantasy literature, GPT-4 will always mention \u201cMiddle-Earth\u201d or the \u201cHarry Potter\u201d series first and express its appreciation for them. As another example, when we mention the movie Inception or other acclaimed movies, GPT-4 always speaks highly of it. Even when we ask it to talk about its shortcomings about a certain property, it sometimes replies, \u201cI can't think of any shortcomings.\u201d Work of Gallegos et al. (2023) suggests that this is related to the bias and fairness of LLM to a certain extent. Since the data injected into"}, {"title": "8 Conclusion and Future Work", "content": "This paper presents an approach to building a socialbot that utilizes LLM to translate between natural language and predicates while employing an ASP reasoner as the backend. We used this framework to develop the AutoCompanion socialbot to chat about movies and book-related topics. AutoCompanion outperforms LLM-only socialbots in reliability, scalability, ease of use, and creativity. We believe this organic combination of LLM and ASP is one of the most effective ways to realize the control of LLM-based socialbots.\nOur future work includes building a more complete knowledge base that allows socialbots to query most of the topic knowledge rather than generating it using an LLM; it also includes field testing and evaluation of socialbots. We expect to make our AutoCompanion Socialbot available on online platforms shortly. Feedback from users will be one of the criteria to measure the performance of our AutoCompanion. Additionally, continuing to explore how to better utilize LLMs to generate unstructured knowledge and ensure its reliability is also part of our future work. We are also planning to add multi-modality, like importing movie clips and voice I/O to our AutoCompanion."}]}