{"title": "TNNGen: Automated Design of Neuromorphic Sensory Processing Units for Time-Series Clustering", "authors": ["Prabhu Vellaisamy", "Harideep Nair", "Vamsikrishna Ratnakaram", "Dhruv Gupta", "John Paul Shen"], "abstract": "Temporal Neural Networks (TNNs), a special class of spiking neural networks, draw inspiration from the neocortex in utilizing spike-timings for information processing. Recent works proposed a microarchitecture framework and custom macro suite for designing highly energy-efficient application-specific TNNs. These recent works rely on manual hardware design, a labor-intensive and time-consuming process. Further, there is no open-source functional simulation framework for TNNs. This paper introduces TNNGen, a pioneering effort towards the automated design of TNNs from PyTorch software models to post-layout netlists. TNNGen comprises a novel PyTorch functional simulator (for TNN modeling and application exploration) coupled with a Python-based hardware generator (for PyTorch-to-RTL and RTL-to-Layout conversions). Seven representative TNN designs for time-series signal clustering across diverse sensory modalities are simulated and their post-layout hardware complexity and design runtimes are assessed to demonstrate the effectiveness of TNNGen. We also highlight TNNGen's ability to accurately forecast silicon metrics without running hardware process flow.", "sections": [{"title": "I. INTRODUCTION AND BACKGROUND", "content": "Deep neural networks (DNNs) [5] have emerged as the de facto technology for artificial intelligence (AI), even surpassing human-like sensory processing capabilities. However, this impressive progress comes with an exponential surge in compute demands and energy consumption, raising concerns about long term sustainability of this trend [9], [11], [18]. Temporal Neural Networks (TNNs), a special class of spiking neural networks (SNNs) employing spike time-based processing with close adherence to biological plausibility [14]\u2013[16], offer a promising alternative path for AI compute, with potential for orders of magnitude improvements on energy efficiency.\nRecent research [2] demonstrates that single-layered TNNs excel in unsupervised time-series clustering [1], [6], [20] and are amenable for resource-constrained edge devices. Further works in advancing TNN research include a microarchitecture framework for TNN implementation in 45nm CMOS [7], and augmenting the ASAP7 process design kit (PDK) [3] with TNN-tailored custom macros for improved energy-efficiency [8]. Recently, the idea of creating an end-to-end framework that can automate the design of specialized TNN chiplets for online sensory processing applications was suggested in [19].\nThis work serves as the first attempt at realizing such a framework for the automated design of application-specific TNNs, or Neuromorphic Sensory Processing Units (NSPU), for online clustering of time-series sensory signals. As illustrated in Fig. 1, the framework leverages PyTorch [12], PyVerilog [17], Python, Cadence toolchain, and open-source FreePDK45 [10], ASAP7, and TNN7 libraries [8]. Starting from high-level modeling of TNNs in PyTorch, this framework enables the generation of post-layout netlists of the models along with resulting hardware metrics in a single automated flow. It facilitates the development of optimized energy-efficient TNN designs without expert involvement, integrating previously segregated software-only and hardware-only TNN developments. Further, we enable users without EDA access to obtain key hardware results without running the actual process flow, via forecasting. Key contributions of this work are:\n\u2022 TNNGen a pioneering attempt at a design framework for automated design of custom TNN-based NSPUs.\n\u2022 A novel TNNGen functional simulator based on PyTorch for robust modeling and rapid application exploration.\n\u2022 A novel TNNGen hardware generator based on PyVerilog that translates TNN PyTorch models to layout in conjunction with Cadence EDA tools and a library of finely-tailored TCL scripts for optimizing the TNN designs.\n\u2022 Time-series clustering performance and post-layout hardware metrics for seven representative TNN designs generated using TNNGen across different technology nodes, extending beyond previous post-synthesis studies.\n\u2022 Accurate forecasting of post-layout die area and leakage power for a quick evaluation of hardware complexity in lieu of the time-consuming hardware process flow.\nThe next section details the TNNGen framework and its key components. Section III describes our experimental setup and evaluation results, highlighting the optimized TNN designs generated and design flow runtimes, along with forecasting. Finally, Section IV summarizes key findings and future work."}, {"title": "II. TNNGEN DESIGN FRAMEWORK", "content": "The proposed TNNGen framework orchestrates the entire TNN design flow by providing user-tunable parameters. It facilitates rapid TNN model development and application performance evaluation using a PyTorch-based simulator, which then provides the model specifications to an automated hardware flow that delivers highly optimized physical design netlists."}, {"title": "A. Functional Simulator", "content": "A novel PyTorch-based functional simulator is developed as part of TNNGen for swift design space exploration and precise evaluation of application-specific metrics (e.g., classification accuracy, clustering rand index, F1 score, etc.). The simulator is flexible, offering users the ability to quickly explore a vast design space and use the resulting insights to develop optimized TNN models. Some key design space configurations include: (i) single-column TNNs with an arbitrary number of neurons (q) and synapses per neuron (p), and (ii) large multi-layer TNNs with an arbitrary number of layers and columns per layer with configurable inter-layer connectivity. It supports various neuron response function models (including step-no-leak, ramp-no-leak, leaky-integrate-and-fire), winner-take-all inhibition (with customizable winner count and tie-breaking options), and spike timing dependent plasticity (STDP) learning in both supervised and unsupervised modes. Pytorch's tensor operations are utilized to implement all the TNN functionalities for high simulation speed. Further, it also supports GPU acceleration through PyTorch's CUDA API. TNNGen simulator models the time dimension precisely, aligning with the direct implementation methodology in [7] wherein spike times are dictated by precise hardware clock cycles. The simulator performs cycle-accurate temporal modeling for time windows around onset of spikes, and dynamically switches to an event-driven approach in time windows where spikes are absent to speed up the simulation. TNNGen employs a modular and parameterized approach, leveraging key functional blocks of TNNs."}, {"title": "B. Hardware Generator", "content": "TNNGen automates the hardware design process flow by facilitating automated RTL generation, RTL simulation, logic synthesis, and place-and-route while ensuring a smooth design flow. It leverages Veriloggen package built on top of PyVerilog [17] to provide a Python interface to the user for converting PyTorch model specifications to Verilog RTL codes.\nTable I specifies the process flows within TNNGen, the Cadence tools utilized during each flow, and the various libraries currently supported by the framework. Cadence EDA tools are specifically chosen as the ASAP7 and TNN7 libraries are primarily supported in the Cadence toolchain. However, TNNGen is built with huge focus on flexibility and modularity to enable easy integration of other toolchains and libraries. We plan to open-source TNNGen for the research community to not only leverage it for their custom TNN design flow but also enhance it with additional capabilities.\nIn the TNNGen backend, to enable PyTorch-to-RTL conversion, we implemented all the TNN functionalities in PyVerilog, ensuring the generated RTL is highly optimized and aligns with the microarchitecture in [7]. TNN7 custom macros are incorporated to help accelerate runtime. [8] reports a 3x speedup for logic synthesis; we go a step further and report the place-and-route speedup in Section III. Further, TNNGen contains a library of specifically tailored TCL scripts and templates for automating the various design flows and PDKs, while providing end-user with complete freedom to configure the flow as needed. Note that TNNGen does not cover DRC & LVS checks for signoff as it requires expert intervention."}, {"title": "III. RESULTS AND EVALUATION", "content": "We adopt the same seven single-column designs in [13], targeting different sensory modalities within the UCR archive [4], as representative benchmarks to showcase TNN designs (Table II). The designs are evaluated using three approaches:\n\u2022 Develop PyTorch TNN models as per p, q parameters in Table II and report corresponding clustering performance.\n\u2022 Use TNNGen to generate post-layout hardware metrics across multiple cell libraries and technology nodes.\n\u2022 Predict the hardware metrics without actually running any of the process flows, using TNNGen's forecasting feature.\nThis research extends beyond previous post-synthesis studies on TNN implementations by presenting post-layout results using multiple cell libraries. Further, we provide layout runtime comparisons and assess the forecasting feature of TNNGen that can predict post-layout hardware metrics without EDA runs. Our runtime simulations are run on a server with 8 Intel Xeon(R) E5-2680 CPU cores."}, {"title": "B. TNNGen Design Performance and Hardware Complexity", "content": "TNNGen simulator is used for modeling and rapidly simulating different single-column TNN designs targeting seven different sensory modalities. To evaluate the unsupervised clustering performance, rand index is utilized, following the method outlined in [2]. Table II shows the rand index results normalized to k-means for TNN and a state-of-the-art deep learning algorithm DTCR [6]. The table shows that a single TNN column performs nearly as well as DTCR for four of the seven benchmarks but underperforms for the remaining three. On average, DTCR outperforms TNNs by nearly 12%, aligning with the results in [2]. It is essential to note that DTCR employs a significantly more complex DNN model, rendering it impractical for edge hardware deployment due to its computational demands. The simulator results demonstrate the efficacy of small TNN designs for time-series clustering.\nTNNGen hardware generator translates the above software models to layouts. We employ various open cell libraries, with resulting hardware metrics reported in Tables III and IV. With TNN7, there is a 32.1% and 38.6% decrease in area and leakage power compared to ASAP7, respectively, aligning with the findings in [8]. We report only leakage power here as total power requires fine-tuned physical rules specific to each design, including clock tree synthesis. Nevertheless, we do report the total power specifically for the largest column (6750 synapses) with TNN7 library for evaluation purposes.\nUsing the TNN7 macros, the largest column results in just 0.035 mm\u00b2 area and consumes only 0.067 mW total (leakage + dynamic) power after layout, going beyond the post-synthesis area and total power reported in [8]. The corresponding FreePDK45 and ASAP7 area/leakage values are 0.744 mm\u00b2/15.66 mW and 0.051 mm\u00b2/0.047 mW respectively. The advantage of 7nm designs vs. 45nm is clear. We also see from Tables III and IV that TNN7 (with custom macro cells) achieves better area and leakage than ASAP7.\nFor computation latency (i.e., per sample inference) evaluation, we first consider three smaller columns (65 \u00d7 2, 96 \u00d7 2, 152 x 2) fitted for the same floorplan size. The resulting computation times are 79.2 ns, 93.36 ns, and 98.4 ns, respectively. For the largest 270 \u00d7 25 column, the resulting latency is 180 ns. We can see that these TNN designs are extremely fast in performing inference and thereby ideal for low power real-time edge AI deployment."}, {"title": "C. Runtime Evaluation", "content": "Authors in [8] report an approximate 3x speedup during logic synthesis due to the use of TNN7 macros during the mapping and optimization phases. We further validate and extend their empirical results by taking a step further and evaluating runtime speedup during place-and-route using Innovus. Fig. 3 illustrates the runtime for place-and-route for increasing column sizes using only ASAP7 cells vs. TNN7 macros. As depicted, runtime scales with increasing column sizes, but TNN7 macros yield a slower trend. On average, the layout runtime using TNN7 in Innovus place-and-route is roughly 32% better than ASAP7. For the largest column, the entire hardware process flow (synthesis + place-and-route runtime) is reduced by almost 47%, indicating larger designs benefit more in runtime speedup with TNN7's custom macros."}, {"title": "D. Area and Leakage Power Forecasting", "content": "Hardware development is typically time-consuming. Many researchers may not have access to commercial EDA tools. Hence, we integrate a forecasting feature for predicting silicon die area based on TNN synapse count without actually running the TNNGen hardware flow. This feature leverages the linear trends of area and leakage power with respect to total synapse count to build a linear regression model, which is trained on many TNNGen runs with varying TNN sizes.\nThe regression model for area follows the equation:\n$Area = 5.56 * SynapseCount - 94.9$\nand leakage power follows the equation:\n$Leakage = 0.00541 * SynapseCount \u2013 0.725$\nTable V along with Fig. 4 report the forecasting (FC) results for area and leakage power, along with their forecasting errors. It can be seen that area can be predicted very accurately within 1% of the original values for large designs. Leakage power, although inaccurate for small designs (omitted for the two smallest designs), is also highly accurate for large designs (the largest design only incurs 0.52% error). Fig. 4 illustrates the efficacy of the linear trendline. The forecasting regression model is part of the TNNGen framework and can be continually refined with more actual design data points."}, {"title": "IV. CONCLUSION", "content": "This paper serves as the first effort in creating an automated design framework (from PyTorch model to chip layout) for the design of application-specific TNN-based neuromorphic sensory processing units (NSPUs). TNNGen confirms the feasibility of such a framework. Initial results indicate automated designs are highly efficient. Post-layout 7nm results show our largest benchmark design requires only 0.035 mm\u00b2 die area and 0.067 mW total power, with a compute latency of 180 ns. This work also demonstrates the benefits of leveraging custom macros in improving both hardware metrics and design flow runtimes. We plan to develop a full library of custom macros that can be smoothly integrated into the framework. We also plan to extend the framework to support more diverse applications and much more complex multi-layer TNN designs. The current framework stands as an important milestone for demonstrating the feasibility and effectiveness of an end-to-end toolchain for the automated design of application-specific TNNs for online sensory signal processing. We plan to open source this framework to facilitate the experimentation and further enhancements by the research community."}]}