{"title": "Beyond Right and Wrong: Mitigating Cold Start in Knowledge Tracing Using Large Language Model and Option Weight", "authors": ["JongWoo Kim", "SeongYeub Chu", "Bryan Wong", "Mun Yi"], "abstract": "Knowledge Tracing (KT) is vital in educational data mining, enabling personalized learning by tracking learners' knowledge states and forecasting their academic outcomes. This study introduces the LOKT (Large Language Model Option-weighted Knowledge Tracing) model to address the cold start problem where limited historical data available using large language models (LLMs). While traditional KT models have incorporated option weights, our research extends this by integrating these weights into an LLM-based KT framework. Moving beyond the binary classification of correct and incorrect responses, we emphasize that different types of incorrect answers offer valuable insights into a learner's knowledge state. By converting these responses into text-based ordinal categories, we enable LLMs to assess learner understanding with greater clarity, although our approach focuses on the final knowledge state rather than the progression of learning over time. Using five public datasets, we demonstrate that the LOKT model sustains high predictive accuracy even with limited data, effectively addressing both \"learner cold-start\" and \"system cold-start\" scenarios. These findings showcase LOKT's potential to enhance LLM-based learning tools and support early-stage personalization.", "sections": [{"title": "1 INTRODUCTION", "content": "Knowledge Tracing (KT) is a crucial area in educational data mining that contributes to personalized learning by monitoring learners' knowledge states and predicting academic performance [7, 8, 15, 20, 27, 29]. However, in cold-start situations, where interaction data is scarce, accurate initial assessment becomes challenging. This limitation hinders the provision of personalized feedback and learning paths to new learners. Recently, Large Language Models (LLMs) have been introduced to overcome these challenges. LLMs, trained on vast amounts of textual data, possess the ability to deeply analyze learners' response patterns [1, 3]. Specifically, LLMs hold the potential to compensate for the shortcomings of traditional KT models in cold-start scenarios by estimating learners' knowledge states and proficiency levels even with limited interaction data [10, 19]."}, {"title": "2 RELATED WORK", "content": "Despite recent advancements, KT models using LLMs still have limitations. These models often categorize learner responses as simply correct or incorrect, missing the multidimensional aspects of learner answers [10, 19, 26]. This makes it hard to differentiate between various knowledge states accurately. The Number-Right scoring method, which only considers correctness, falls short for complex knowledge structures [17, 22]. This issue becomes even more challenging in cold-start situations, where limited data hinders accurate knowledge state estimation.\nTo address these limitations, we propose the LOKT (Large Language Model Option-weighted Knowledge Tracing) model, which incorporates information beyond simple correctness by considering the options selected by learners. This model leverages both the selected options and their assigned weights to maximize the strengths of LLMs, enabling a deeper analysis of learners' knowledge states. Since not all incorrect answers reflect the same level of misunderstanding, the model can capture subtle variations in learners' understanding for a more fine-grained assessment. For example, in Figure 1, if learners A and B select options A and C, respectively, for the same question (Qid. 7, KC 2), this indicates distinct misunderstandings (partial and limited), necessitating differentiated evaluations of their knowledge states [5]. Conversely, when two learners select the same answer (Qid. 16, KC 3), changes in knowledge state may not be observed, as they share the same option weight, such as Inadequate.\nBy assigning weights to options and analyzing learner responses, the LOKT model goes beyond simple correctness to enable a more precise estimation of the learner's knowledge state. Specifically, learners' incorrect answers may indicate partial understanding of certain knowledge concepts rather than a complete lack of knowledge, thus providing insights into how learners comprehend specific concepts [5, 18]. This approach is especially useful in cold-start scenarios, as it allows for accurate identification of partial understandings or misconceptions even with limited initial data. Importantly, the LOKT model addresses both learner and system cold-start problems, facilitating detailed analysis that contributes to continuous improvement in learning outcomes [6, 18].\nIn this study, we incorporate option weights in LLMs' predicting learners' learning states to enhance its accuracy. Inspired by WEKT [16], we obtain the selection frequency for each option and calculate the difference in average scores between learners who selected the option and those who did not. Based on this difference, we compute the weight for each option, adjusting the weights by considering additional factors such as difficulty and selection frequency. This approach enables a more fine-grained assessment of how well each option reflects a learner's level of understanding.\nTo effectively use option weights, we propose converting continuous weight values into text-based ordinal values, making it easier for LLMs to understand option weights in the choices made by problem solvers. This approach takes advantage of LLMs' natural language processing abilities, helping them better interpret numerical data in linguistic form [28]. For example, rather than using numeric values like 0.2 or 0.9, we assign descriptive terms such as Inadequate or Proficient. An option with a high weight, indicating strong understanding, classifies the learner as Proficient in that concept, while a low weight signals Inadequate, suggesting further learning is necessary. This text-based ordinal conversion"}, {"title": "2.1 Knowledge Tracing", "content": "Knowledge Tracing (KT) originated with statistical models such as Maximum Likelihood Estimation, Item Response Theory [25], and Bayesian Knowledge Tracing [8]. With the advent of deep neural networks, models like Deep Knowledge Tracing (DKT) [27] leveraged recurrent neural networks (RNNs) to analyze sequences of learner interactions. Building upon this, DKT+ [7] introduced regularization techniques to address prediction inconsistencies and data reconstruction challenges. Subsequently, attention-based models such as the Knowledge Question Network [23], Self-Attentive Knowledge Tracing [29], and Separated Self-Attentive Neural Knowledge Tracing [20] enhanced accuracy by focusing on critical aspects of learner interactions. The Attention-based Knowledge Tracing model [15] further incorporated an attention-based LSTM to mitigate overfitting and improve generalization. Despite these advancements, traditional KT models predominantly rely on binary indicators of correctness, which constrains their ability to fully capture the multifaceted nature of learner knowledge [27]."}, {"title": "2.2 Knowledge Tracing with LLMs", "content": "LLMs present an alternative approach by enabling the interpretation of learners' reasoning processes and misconceptions [4, 19]. By capturing richer contextual information, LLMs enhance the tracking of knowledge states and facilitate more accurate predictions, thereby addressing some of the inherent limitations of traditional KT methods [10]. Recent research has explored the application of LLMs to mitigate KT's cold start problem. For instance, [26] proposed a model that monitors knowledge states across various concepts using learners' problem-solving histories, while [19] and [24] employed text-based representations to effectively predict performance even for new learners. These studies demonstrate that LLMs can manage cold start scenarios more efficiently than traditional methods that depend on limited interaction data.\nHowever, even LLM-based KT models often utilize binary correctness assessments, which do not fully encapsulate the complexity of learner understanding and decision-making processes. This binary approach may overlook the dynamic nature of knowledge acquisition and fail to accurately reflect a learner's proficiency level. To bridge these gaps, our study integrates option data, providing a more granular view of learners' understanding. By incorporating option-specific information, we enhance the ability of KT models"}, {"title": "2.3 Option in Knowledge Tracing", "content": "Incorporating option data allows for more accurate differentiation of learners' knowledge states, addressing the limitations of traditional KT models that typically classify responses as either correct or incorrect. By integrating option information, our study moves beyond this binary (coarse-grained) approach, providing a more comprehensive depiction of learners' understanding. Since different incorrect options can reflect varying levels of misconception, option tracing [2, 13] enables models to predict multiple response types, allowing for a more detailed analysis of learner interactions and more precise predictions.\nHowever, this approach alone has limitations, as it may not explicitly link specific options to the proficiency levels of learners, which can be influenced by factors like question difficulty and choice tendencies [9, 11, 14]. Recent studies have explored option weighting using the Point-Biserial criterion, quantifying option weights on a scale from -1 to 1, and factoring in proficiency, question difficulty, and selection rates [16]. Building on these developments, we modify the option weights in ways that LLMs can effectively understand, enhancing the KT models. This integration improves the precision of learning analytics, allowing for a deeper understanding of learners' knowledge states and evaluating the pupils more tuned to the individual."}, {"title": "3 METHODOLOGY", "content": ""}, {"title": "3.1 Overview", "content": "Figure 2 illustrates the assignment of weights to each option within a question, which are then provided to LLMs to enhance the accuracy of knowledge state predictions. These weights are determined based on both the difficulty of the questions and the selection rates of the options by learners. Our method leverages the LLM's inference capabilities through prompt-engineering strategies without the need for fine-tuning. The detailed methodology is outlined below."}, {"title": "3.2 Problem Definition", "content": "The objective of KT is to predict the correctness of a learner's next response by considering their previous interaction data. This interaction data that considers option and weight is denoted as $x_{t,i}$, where $i \\in I$ represents an individual learner's case from a set of cases $I$, and $t$ indicates the sequence of interactions. The interaction data comprises several components: $q_{t,i}$ is the question presented in case $i$ at time $t$; $c_{t,i}$ denotes the knowledge components associated with $q_{t,i}$; $o_{t,i}$ refers to the selected option for the question; $w_{t,i}$ represents the corresponding selected option weight; and $y_{t,i}$ indicates the correctness of the previous response. Using a interaction data as input to predict the correctness $\\hat{y}_{t+1,i}$ of the upcoming response. The prediction is formulated as follows:\n$\\hat{y}_{t+1,i} = \\arg \\max P(w | q_{t,i}, c_{t,i}, o_{t,i}, w_{t,i})$,\nHere, $w$ represents the predicted correctness of the next response in case $i$. By incorporating the selected option $o_{t,i}$ and its weight $w_{t,i}$ into the interaction data, the LLM gains deeper insights into the significance of each option."}, {"title": "3.3 Option Weight Calculation", "content": "Option weighting provides a nuanced assessment of learner knowledge by capturing information beyond the binary correct/incorrect paradigm used in traditional models [7, 27]. This approach enables a more detailed representation of learner knowledge states and enhances prediction accuracy by accounting for multiple response types [2, 13].\nTo calculate option weights, we adapt learner scores following [16], recognizing the variability in individual practice logs. Rather than total scores, learner performance is evaluated by integrating question difficulty, defined as $d_q = \\frac{\\text{correct count}_q}{\\text{total answer count}_q}$, where $d_q$ indicates the difficulty of question $q$. Lower values correspond to higher difficulty.\nA learner's score $x_i$ is calculated as:\n$x_i = N_i\\frac{\\Sigma_{q\\in Q_i} d_q}{|Q_i|}$\nHere, $Q_i$ is the set of exercises attempted by learner i and $N_i$ is the count of exercises they correctly answered. This score accounts for exercise difficulty, penalizing mistakes on easier questions while rewarding correct answers on more difficult ones.\nTo standardize scores across learners, we calculate the average score $\\bar{x}$ and standard deviation $S_x$ as follows:\n$\\bar{x} = \\frac{1}{|I|} \\Sigma_{i \\in I} x_i, S_x = \\sqrt{\\frac{1}{|I|} \\Sigma_{i \\in I} (x_i - \\bar{x})^2}$\nFor each option $o$ in question $q$, selection $C_q$ and non-selection $NC_q$ ratios are determined by:\n$C_q = \\frac{c_q}{c_q + nc_q}$,\n$NC_q = \\frac{nc_q}{c_q + nc_q}$\nwhere $c_q$ and $nc_q$ are the counts of learners who selected and did not select option $o$, respectively.\nThe average scores for learners selecting and not selecting $o$ are given by:\n$\\bar{x}_s = \\frac{\\Sigma_{s\\in S_q} x_s}{|S_q|}$,\n$\\bar{x}_{nc} = \\frac{\\Sigma_{s\\in NC_q} x_s}{|NC|}$\nThe option weight $w_q^o$ is then computed as:\n$w_q^o = (\\bar{x}_s - \\bar{x}_{nc}) \\times \\frac{C_q \\sqrt{NC_q}}{S_x}$\nThis formula reflects the score difference normalized by $S_x$, scaled by selection ratios, with higher weights indicating options more frequently chosen by high-scoring learners."}, {"title": "3.3.1 Conversion to text-based ordinal Weights", "content": "LLMs are particularly effective at processing data with well-defined categorical structures, making the conversion of continuous option weights into text-based ordinal formats crucial for enhancing LLM performance in KT tasks. In this study, we use multiple-choice questions with four answer options, which generally allows us to convert continuous weights into the following four categories: Proficient, Partial, Limited, and Inadequate. Here, Proficient corresponds to the correct answer, while the other categories reflect varying levels of incorrect responses, with each subsequent category representing a lower level of understanding.\nThe conversion process involves the following steps:\nRanking of Option Weights: We start by calculating the option weights for each question and ranking them in descending order to establish a hierarchy.\nCategory Assignment: Based on the ranked weights, the highest-weighted option is assigned as Proficient, followed by Partial, Limited, and finally, Inadequate.\nCategory Extension for Additional Options: For questions with more than four options, the lower categories are repeated to accommodate additional options. Details on this extension process are provided in the Appendix D.\nAs illustrated in Figure 3 (right figure), this text-based categorical structure tends to demonstrate an ordinal relationship among the categories. The Proficient category denotes the correct response, while the incorrect options exhibit a structured hierarchy among themselves. This approach improves LLM's understanding, enabling the model to differentiate between various levels of learner comprehension and misconceptions. Consequently, this framework supports a more granular analysis of learners' knowledge states and enhances the model's capacity for accurate assessments."}, {"title": "3.4 Prompt Design", "content": "This study aims to predict the probability that a learner will answer correctly at a future time point (t + 1) based on the historical sequence of their problem-solving up to time (t). To achieve this, we construct input prompts that preserve the sequential structure of learner interactions. These prompts capture the essential elements of the learner's prior activities, maintaining the temporal and contextual information necessary for the model to accurately predict the knowledge state.\nThe input prompts reflect the temporal order of the learner's learning patterns and include the following components:\nQuestion ID Sequence ({question_ids}): The sequence of problems solved.\nKnowledge Component (KC) ID Sequence ({kc_ids}): The knowledge domains associated with each problem.\nSelected Option Sequence ({option_sequence}): The answers selected for each problem.\nSelected Option Weights ({option_weights}): The importance or weight of the selected options.\nCorrectness Sequence ({answer_sequence}): Record of either correctness or incorrectness.\nThese components are formatted into structured prompts that can be effectively interpreted by the LLM. To evaluate the importance of incorporating option weights, we additionally applied two modes:"}, {"title": "4 EXPERIMENT", "content": "This section details the performance of the proposed methodology, including the construction of datasets, model implementation, and baselines. Additionally, we evaluate the effectiveness of our model in addressing two types of cold start problems, demonstrating the superiority of our approach.\n(1) RQ1: Does LOKT outperform existing methodologies with a smaller number of learners?\n(2) RQ2: Can LOKT predict learners' knowledge states more accurately compared to existing methodologies with a limited problem-solving history?\n(3) RQ3: Does converting option weights into text-based ordinal categories improve the model's performance, particularly in cold start scenarios?"}, {"title": "4.1 Experiment Settings", "content": ""}, {"title": "4.1.1 Dataset", "content": "We used five open datasets of learner problem-solving data: Assistment09\u00b9, DBE-KT22\u00b2, EdNet\u00b3, Eedi A4, and Eedi B5. The statistical details of each dataset are illustrated in Table 2. Unlike Eedi A, Eedi B, and EdNet, which have a fixed number of 4 options, Assistment09 and DBE-KT22 have varying numbers of options per question. Therefore, we set the maximum number of options to 7 and 5, respectively, to construct the option weight. In all datasets, we removed cases where the learner did not select an option or where no answer to the problem-solving task was available. Notably, Assistment09 differs from the other datasets as learners are required to provide open-ended answers. We treated these responses as selected options and converted them into standardized options for consistency in problem-solving analysis."}, {"title": "4.1.2 Implementation Details", "content": "For fair comparison across the seven non-LLM based parametric baseline models, the embedding dimension was fixed at 100. The learning rate was set to 0.001, with a weight decay of 0.001. The Adam [21] optimizer was utilized. The early stopping criterion was configured with a patience of 3 epochs. The batch size was set to 256, and the dataset was split into training, validation, and test sets in the ratio of 70%, 15%, and 15%, respectively. For the test set, the dataset was reconstructed by sampling 50 instances each from the correct and incorrect response categories."}, {"title": "4.1.3 Baseline Models", "content": "In this study, we compare our model with state-of-the-art non-LLM-based KT models such as DKT [27], DKT+ [7], KQN [23], DKVMN [30], SAKT [29], SAINT [20] and AKT [12]. Additionally, we include recent LLM-based approaches like [26], LOKT(w/o option, weight), and CLST [19] to evaluate performance on key tasks such as knowledge state prediction and cold-start problem resolution."}, {"title": "4.2 Task Descriptions", "content": "The current study aims to mitigate the two aforementioned types of cold start problems commonly discussed in existing research [19, 24, 26]. The first scenario involves predicting a learner's knowledge state at the onset of a new system, while the second scenario addresses the arrival of new learners within an existing system."}, {"title": "4.2.1 Task 1: New System", "content": "To compare model performance in a new system scenario, problem-solving sequences were constrained to establish the experimental environment. Non-LLM baseline models were trained using few-shot learning, with each model trained on a limited dataset consisting of 20 problem-solving sequences. In contrast, the LLM-based models were evaluated through zero-shot inference on a test dataset with 20 sequences, without any prior training. Positioned between these approaches, LOKT does not require fine-tuning; instead, it utilizes option weights derived from limited historical data. Unobserved problems or options are assigned a weight of NaN during inference.\nThe mathematical formulation for Task 1 is as follows:\n$\\hat{y}_{t+1,i'} = \\arg \\max P(w | q_{t,i'}, c_{t,i'}, o_{t,i'}, w_{t,i'}), i'\\in I', I' \\subseteq I$\nHere, $i' \\in I'$ indicates that the training data is extracted from a subset $I'$ of the full set of cases $I$, representing the few-shot learning scenario in Task 1."}, {"title": "4.2.2 Task 2: New learner", "content": "This task focuses on evaluating new learners within an existing system. New learners are defined as those with limited problem-solving history compared to existing learners, meaning they possess less problem-solving sequence data than the learned sequences of existing learners. To simulate this, the problem-solving history for these new learners was restricted to a certain number of sequences through Random Sampling. Both the baseline models and the proposed LLM were evaluated on this data, with both models being limited to 100 interaction sequences.\nThe mathematical formulation for Task 2 is expressed as:\n$\\hat{y}_{t'+1,i} = \\arg \\max P(w | q_{t',i}, c_{t',i}, o_{t',i}, w_{t',i}), t'\\subseteq t$"}, {"title": "5 RESULTS", "content": ""}, {"title": "5.1 Task 1: New System (RQ 1)", "content": "The performance of LOKT was evaluated across five datasets, and the results demonstrate that LOKT consistently outperforms traditional models. In particular, it achieved an ACC of 0.818 and an F1 score of 0.875 on the DBE-KT22 dataset, the highest among all"}, {"title": "5.2 Task 2: New learner (RQ 2)", "content": "In the new learner scenario, LOKT exhibits a distinct performance by effectively predicting knowledge states with minimal interaction data, as reflected in Table 3. Rather than merely evaluating correct or incorrect responses, LOKT's integration of option weights enables it to capture the underlying learning state of learners in a more granular manner. This allows the model to derive meaningful insights even when faced with limited sequences, a crucial aspect when dealing with new learners who lack sufficient interaction histories.\nOne key strength of LOKT, illustrated in Figure 5, is its ability to deliver early and accurate predictions, particularly in educational settings where timely feedback is essential. By excelling with shorter test sequences, LOKT provides educators with the ability to intervene earlier in the learning process, identifying potential learning difficulties in learners before they become significant obstacles. This early intervention capability makes LOKT highly practical for real-time educational applications."}, {"title": "5.3 Weight Mode Analysis (RQ 3)", "content": "This study evaluates the effectiveness of transforming continuous option weights (e.g.,-0.1,0.3,0.12,-0.53) into text-based ordinal representations (Limited, Proficient, Partial, Inadequate) to enhance a LLM's comprehension and prediction accuracy. We assessed text-based ordinal weights from two perspectives. First, by converting continuous weights into text-based ordinal forms, we confirmed that LLMs can interpret learner states with greater clarity. Second, we analyzed these weights by converting them into int-based ordinal forms (3,1,2,4)."}, {"title": "5.3.1 Performance Evaluation of Text-Based Ordinal Weights", "content": "Figure 6 illustrates performance based on training data size in a new system setting, with text-based ordinal models generally outperforming both continuous and int-based ordinal models except for only the case when training data size is 0.2 in Assistment09 dataset. This suggests that converting the continuous option weights into text-based ordinal format enables LLMs to interpret learner states more effectively, enhancing predictive reliability with limited data.\nIn Figure 7, we analyzed the impact of sequence length in a new learner environment. The text-based ordinal models consistently showed superior performance, especially with shorter sequences on DBE and Eedi B datasets. This indicates that text-based ordinal weights align well with LLMs' strengths, supporting reliable learning state prediction with short sequence of problem-solving. Even as sequence length increases, text-based ordinal models maintain superior performance.\nThese results underscore the effectiveness of text-based ordinal weights in LLM-based models, enabling accurate learner state assessments and pattern recognition across data sizes and sequence lengths."}, {"title": "5.3.2 Effectiveness of Coarse-Grained vs. Fine-Grained Text-Based Ordinal Weighting", "content": "In Figure 8, we compared a binary coarse-grained text-based ordinal with the LOKT model's approach. The coarse-grained model classifies correct answers as Proficient and all incorrect answers as Inadequate, while the LOKT model categorizes incorrect answers into multiple levels, offering a nuanced view of learner understanding. Our results show that the LOKT model consistently outperforms the coarse-grained approach. By incorporating varied levels of incorrect responses, LOKT enables LLMs to capture finer distinctions in learners' knowledge, thus enhancing accuracy in predicting learning states."}, {"title": "6 ABLATION STUDY", "content": ""}, {"title": "6.1 Prompt Mode Analysis", "content": "The performance comparison across different sequence lengths and few-shot learning scenarios was conducted on various datasets, including Assistment09, DBE-KT22, EdNet, Eedi A, and Eedi B, using three configurations: LOKT (w/o option, weight), LOKT (w/o weight), and LOKT. LOKT (w/o option, weight) uses basic sequences like Question ID, KC ID, and Correctness, while LOKT (w/o weight) only incorporates selected option information. LOKT integrates both options and their weights, enhancing predictions by reflecting the importance of each choice and improving KT accuracy.\nIn few-shot settings, as shown in Figure 9, LOKT demonstrated robust performance, particularly on the DBE dataset, where option weights captured learning patterns effectively even with limited data. This contributed to better predictions in scenarios involving"}, {"title": "7 CONCLUSION", "content": "This study introduces a novel approach to LLM-based KT that leverages option weighting to enhance predictions of learners' knowledge states. By integrating option-level data, our method overcomes the limitations of traditional KT models reliant on binary correctness indicators, improving the accuracy of knowledge state estimations, particularly in cold start scenarios with limited interaction data. Extensive experiments demonstrate superior performance in both learner and system cold-start situations, highlighting the value of examining subtle differences in learners' proficiency by analyzing options and their weights, which in turn improves prediction accuracy. Future work will focus on refining the option weighting methodology and expanding its applications in various educational contexts, contributing to advancements in educational data mining and intelligent tutoring system."}, {"title": "D OPTION WEIGHT EXPAND METHOD", "content": "Table 4 outlines the categorical assignments based on the number of non-zero option values in a multiple-choice question:\nThe categorical assignment of option weights is designed to reflect varying levels of learner understanding based on the number of options in a multiple-choice question. For standard four-options of multiple choice questions (MCQs), the categories Proficient, Partial, Limited, and Inadequate provide a balanced representation of different knowledge states. However, when the number of options increases beyond four, additional Inadequate categories are appended to maintain consistency and adequately capture the depth of learner misconceptions.\nFor instance, in a question with five options, the categories are assigned as Proficient, Partial, Limited, Inadequate, and Inadequate. This repetition of the lowest category allows the model to differentiate between multiple incorrect options that may represent varying degrees of misunderstanding. Similarly, for questions with more than five options, the second lowest one, Limited category is repeated accordingly to match the number of choices.\nThis method ensures that the LOKT model can handle diverse question formats across different datasets, providing a nuanced and scalable approach to knowledge state tracking. By categorizing responses into multiple levels, the model moves beyond the traditional binary correct/incorrect framework, enabling more precise assessments and predictions of learner performance, especially in scenarios with limited interaction data, namely cold start."}]}