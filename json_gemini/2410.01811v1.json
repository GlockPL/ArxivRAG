{"title": "EVALUATING CULTURAL AWARENESS OF LLMS FOR YORUBA, MALAYALAM, AND ENGLISH", "authors": ["Fiifi Dawson", "Zainab Mosunmola", "Sahil Pocker", "Raj Abhijit Dandekar", "Rajat Dandekar", "Sreedath Panat"], "abstract": "Although LLMs have been extremely effective in a large number of complex tasks, their understanding and functionality for regional languages and cultures are not well studied. In this paper, we explore the ability of various LLMs to comprehend the cultural aspects of two regional languages: Malayalam (state of Kerala, India) and Yoruba (West Africa). Using Hofstede's six cultural dimensions: Power Distance (PDI), Individualism (IDV), Motivation towards Achievement and Success (MAS), Uncertainty Avoidance (UAV), Long Term Orientation (LTO), and Indulgence (IVR), we quantify the cultural awareness of LLM-based responses. We demonstrate that although LLMs show a high cultural similarity for English, they fail to capture the cultural nuances across these 6 metrics for Malayalam and Yoruba. We also highlight the need for large-scale regional language LLM training with culturally enriched datasets. This will have huge implications for enhancing the user experience of chat-based LLMs and also improving the validity of large-scale LLM agent-based market research.", "sections": [{"title": "Introduction", "content": "Large Language Models (LLMs) have emerged as powerful tools in Natural Language Processing (NLP), demonstrating remarkable capabilities in tasks ranging from text generation to complex reasoning, including language translation and summarization [1, 2]. These models, trained on vast amounts of textual data, have revolutionized language-based AI applications [2]. However, a critical issue has come to light: the majority of LLMs are primarily trained in English language data, introducing several limitations and biases [3].\nThe current state of LLM development heavily favors English, with most large-scale datasets and training procedures focusing on English text by 30-60%[4]. This bias is partly due to the abundance of English content on the internet and in digital repositories, as well as the dominance of English in scientific and technological discourse. While some efforts have been made to incorporate other languages, the extent and effectiveness of these inclusions remain limited [3].\nDue to the training data bias, LLMs may have a significantly reduced ability to respond effectively in other languages. This limitation manifests in various ways, including reduced accuracy in translation, poor understanding of cultural nuances, and inability to generate coherent text in non-English languages [5]. For instance, in sentiment analysis, LLMs can exhibit biases favoring dominant cultural groups, leading to inaccurate interpretations in languages like Italian, Chinese, and Spanish [6].\nMoreover, these models often generate text containing social biases related to gender, age, sexual orientation, ethnicity, religion, and culture, highlighting the need to mitigate such biases [7]. LLMs also struggle with accuracy and fluency in non-English languages due to insufficient high-quality training data [8] and structural differences between languages [9], resulting in less coherent and contextually inappropriate responses [10, 11]."}, {"title": "1.1 Selection of languages used in the study", "content": "To select the regional languages for our study, we focused on India and Nigeria, countries where a large percentage of the population speaks various regional languages. We specifically chose languages that are significantly under-represented in the training data of Large Language Models (LLMs).\n\u2022 Yoruba: \u224845 million people in Nigeria (\u224821% of the population) speaks Yoruba. The language originated over 1000 years ago, and Yoruba speakers are largely concentrated in West Africa. Only 1-2% of the entire population outside Africa speaks Yoruba, making it an ideal non-English language for our study. Additionally, only \u2248 0.008% of the LLM training data comes from the Yoruba language [4], making it a perfect fit for our study.\n\u2022 Malayalam: About 38 million people in India speak Malayalam. Most of these (~96%) originate from Kerala, the southern state of India. Even within India, only 4% of the population outside of Kerala speak"}, {"title": "1.2 Hofstede's six cultural dimensions", "content": "To measure the LLM awareness and understanding of the cultures, we looked at Hofstede's Cultural Dimensions Theory: a framework for cross-cultural communication developed by Geert Hofstede [39, 48]. We look at 6 fundamental dimensions: Power Distance Index (PDI), Individualism vs Collectivism (IDV), Uncertainty Avoidance Index (UAI), Masculinity vs Femininity (MAS), Long-term vs Short term Orientation (LTO) and Indulgence vs Restraint (IVR). These dimensions show the effects of a society's culture on the value of its members. Subsequently, these values also affect the choices, decisions, and behaviors of the members of society.\n1. Power Distance Index (PDI): Measures the degree to which less powerful members of a society accept and expect that power is distributed unequally. High PDI indicates acceptance of hierarchical order without justification, while low PDI indicates that people strive for equality and question authority [48].\n2. Individualism vs. Collectivism (IDV): Measures the extent to which individuals are integrated into groups. A high IDV score, representing individualism, indicates a society with loose ties between individuals, where"}, {"title": "2 Methodology", "content": "One of the study's main goals was to obtain ground truth scores for these 6 dimensions for Yoruba and Malayalam and then compare these ground truth scores with the scores achieved by a Large Language Model (LLM)."}, {"title": "2.1 LLM cultural scores", "content": "To obtain the Large Language Model (LLM) scores for these 6 metrics, we referred to the study by Wang et al. [53], which constructed a large dataset of questions to evaluate the PDI, IDV, UAI, MAS, LTO, and IVR scores. Each of these scores had a separate set of questions. To make the questionnaire diverse, they further split the questions into 7 domains: arts, education, wellness, lifestyle, work, science, and family. Every question had \"Yes\" or \"No\" options. The questions were specifically designed so that the LLM answer would reveal the magnitude of the particular cultural dimension.\nOur study used this questionnaire, which consisted of approximately 500 questions for each dimension. As the first step, we used the Google Translate API to translate the English questions or prompts provided by [53] into Yoruba and Malayalam. For both languages, we then asked the prompts to the chosen LLM and then recorded the LLM's response to all questions. We used two different LLMs for our experiments: GPT-4o-mini and Gemma 7B. This allows us to compare the performance of different models in capturing cultural nuances across languages. The LLM responses were processed to extract binary (Yes/No) answers for each question. For a given cultural dimension $d_i$, where $1 < i < 6$, if N questions were asked, and P out of them corresponded to the positive inclination to that score, we defined the LLM cultural score for that metric as shown in Equation 1. Our overall methodology is described in Figure 4.\n$LLM(d_i) = \\frac{P}{N}$"}, {"title": "2.2 Ground truth scores", "content": "Getting the ground truth scores for the 6 metrics for Malayalam and Yoruba was a challenging task. There is robust documentation of the human cultural dimension scores from Hofstede's survey, but only for major global languages spoken in countries like the United States, Germany, and China. There is very limited Hofstede cultural survey information for Malayalam and Yoruba. To bridge this gap, we constructed our survey of questions. We condensed the Hofstede cultural survey into 23 comprehensive questions covering PDI, IDV, UAI, MAS, LTO, and IVR. In each cultural dimension, we created 3 or 4 questions. Very similar to the LLM approach; the questions were designed such that the response would reveal an inclination towards or away from that cultural dimension. We circulated this form to Malayalam and Yoruba speakers. The survey candidates were chosen carefully from diverse backgrounds, careers, and age groups to prevent biases.\nFigure 6 shows the Google form survey responses for one sample question, shown for each cultural dimension for Malayalam and Yoruba languages. As can be seen from the response split, we obtained a diverse set of responses for each question.\nWe strongly believe that our study is one of the first to collect Malayalam and Yoruba-specific data for these cultural scores. We will make the available dataset public and continue to collect more responses. For the study, due to the diverse and heterogeneous nature of the responses, the amount of responses we collected serves our purpose of generating a robust ground truth score. More responses might alter this score, but not by a significant amount."}, {"title": "2.3 Cultural similarity score", "content": "Equations 1 and 2 served as the basic building blocks for evaluating the LLM cultural barrier. Along with these equations, we also defined a similarity score between the LLM score ($LLM(d_i)$) and the ground truth score ($GD(d_i)$) for a given cultural dimension $d_i$, as follows [53] in equation 3.\n$Sim(LLM, GD) = \\frac{1}{1 + \\sqrt{\\sum_{i=1}^{6}(LLM(d_i) - GT(d_i))^2}}$"}, {"title": "2.4 Algorithm Design", "content": "We explain the implementation and logic for evaluating the LLMs on the datasets. We used questions from the CDEval benchmark [38]. A sample of each JSON file for each of the languages is read. We load all 6 dimensions for each language. The files are passed through the 'loadOrComputeScore()' function, which checks if the scores for the dimensions of each language are computed; if the languages have been computed, we use the scores. If not, we compute the scores. We define the keys for each language, English, Malayalam, and Yoruba, and print the format for each language along with the keys for each dimension. A statement is included to get the values of the keys by using the first three items.\nIn computing the scores, we take the questions from a specific language and dimension. A prompt is constructed using the question and its options for each question. The prompt is passed three times to the LLM. It then analyses the response to determine the chosen option associated with the measured cultural dimension."}, {"title": "3 Results", "content": "Our study compared the cultural dimension scores obtained from GPT-4o-mini and Gemma 7B for English, Malayalam, and Yoruba languages against ground truth data. The results reveal significant disparities in the LLMs' ability to capture cultural nuances across these languages. Figures 7 through 9 represent the results of our study on the cultural awareness of large language models (LLMs) for Yoruba, Malayalam, and English. Using Hofstede's cultural dimension as a framework, these figures provide a comprehensive view of how well different LLMs do across these languages."}, {"title": "3.1 Overall Trend", "content": "Table 2 compares Hofstede's Cultural Dimensions between Ground Truth and two LLMs (GPT-40-mini and Gemma-7b-it) across English, Yoruba, and Malayalam. The computed scores for individual dimensions are plotted as bar graphs in Figure 7."}, {"title": "3.2 Model's general performance across languages.", "content": "Here, we examine the cultural sensitivity of the models across the selected languages: Yoruba, Malayalam, and English. We focus on evaluating the capabilities of GPT-40 mini and Gemma-7b-it in this regard. Equation 3 shows the cultural similarity score calculation between a model and the corresponding language's country.\nGPT-40-mini performs best in English. Interestingly, Gemma-7b-it shows a different pattern. The results are also plotted in the bar plot of Figure 10 for better visualization."}, {"title": "3.3 Performance Analysis", "content": "Table 4a and 4b show the similarity scores for GPT-40- mini and Gemma-7b-it across the three languages. These scores are calculated based on the absolute difference between the ground truth and the GPT-40-mini predicted scores, normalized to a 0-1 scale where 1 indicates perfect similarity. These scores reveal varying levels of accuracy across languages and dimensions.\nEnglish shows consistently high similarity across all dimensions in GPT-40-mini, with IDV being the closest match (0.91). For Gemma-7b-it.\nGPT-40-mini tends to overestimate most dimensions for English. The model overestimates PDI, MAS, and UAI in Malayalam while underestimating IDV, LTO, and IVR."}, {"title": "3.4 Discussion of Model Biases and Performance", "content": "The discrepancies between the cultural dimension scores predicted by the models and the ground truth for Yoruba and Malayalam suggest that underlying model biases, particularly those related to the training data, play a significant role. Large language models are predominantly trained on English-centric data, with minimal representation of regional languages like Yoruba and Malayalam. The Common Crawl data 1 shows that English dominates LLM training data (45%), while Yoruba and Malayalam account for only 0.008% and 0.0226%, respectively. This stark imbalance in the training datasets contributes to the models' over- or underestimation of cultural dimensions for these languages.\nThese biases arise because models are exposed to a disproportionate amount of content from English-speaking cultures. This leads to internalizing cultural norms that may not align with those in underrepresented regions. For instance, the overestimation of Power Distance (PDI) in Malayalam likely stems from"}, {"title": "4 Conclusion and Discussion", "content": "In this study, our main goal was to understand whether Large Language Models (LLMs) are able to effectively capture the cultural nuances of regional languages. To achieve this goal, we looked at 2 languages: Malayalam (spoken by \u2248 38 million people in the state of Kerala, India) and Yoruba (spoken by \u2248 45 million people largely concentrated in West Africa). We selected these 2 languages because in terms of native speakers, these languages represent a minority - only 1-2% of the entire population outside Africa speaks Yoruba, and only 1-2% of the entire population outside India speaks Malayalam. As much as \u2248 60 % of the training data for all modern LLMs is based on the English language. This would naturally lead to LLMs having a poor understanding and poor functionality for regional languages and cultures.\nTo quantify the cultural awareness of LLM-based responses, we looked at 6 cultural metrics, also called the Hofstede's metrics: Power Distance (PDI), Individualism (IDV), Motivation towards Achievement and Success (MAS), Uncertainty Avoidance (UAV), Long Term Orientation (LTO) and Indulgence (IVR).\nOur results indicate that the cultural similarity score obtained for the languages of Malayalam and Yoruba is significantly lower than English. This clearly demonstrates that all modern LLMs are vastly inadequate in their understanding and, consequently, their functionality for regional languages."}, {"title": "4.1 Key Findings", "content": "Our results indicate that the cultural similarity score obtained for the languages of Malayalam and Yoruba is significantly lower than English for all the LLMs we tested. This clearly demonstrates that all modern LLMs are vastly inadequate in their understanding and, consequently, their functionality for regional languages. As the influence of LLMs grows more powerful, the English-centric bias in LLMs has the potential to significantly affect the lives of people speaking regional languages."}, {"title": "4.2 Implications for Cultural Sensitivity", "content": "Our findings underscore the critical need for improved cultural sensitivity in LLMs, particularly for underrepresented languages. The significant disparity in cultural similarity scores between English and regional languages like Malayalam and Yoruba highlights a potential for misunderstanding and misrepresentation of these cultures in AI-driven"}, {"title": "4.3 Ethical Considerations", "content": "The observed performance gap in cultural awareness between English and underrepresented languages raises important ethical considerations. This disparity could potentially perpetuate and exacerbate existing inequalities in access to and benefit from AI technologies. It is imperative that the development of LLMs takes into account the diverse cultural landscapes they are intended to serve, ensuring fair representation and understanding of all languages and cultures."}, {"title": "4.4 Limitations", "content": "One of the primary challenges and limitations of the present study was collecting ground truth data for Malayalam and Yoruba. While robust documentation of human cultural dimension scores from Hofstede's survey exists for major global languages spoken in countries like the United States, Germany, and China, Hofstede's cultural survey information for Malayalam and Yoruba is very limited. Additionally, the use of machine translation (Google Translate API) to translate the English questions into Malayalam and Yoruba may have introduced inaccuracies or cultural misinterpretations. The binary (Yes/No) nature of the questions may also oversimplify complex cultural concepts. Furthermore, our study focused on only two regional languages, which, while providing valuable insights, may not be fully representative of the vast linguistic diversity in the world."}, {"title": "4.5 Future Work", "content": "Our research opens up several avenues for future work:\n1. Expanding the dataset: Collecting more responses and making this growing dataset public is one of our long-term objectives.\n2. Extending to more languages: Although we looked at only two regional languages, the applications of this study extend to more than 1000 regional languages worldwide.\n3. Improving evaluation methods: Developing more nuanced evaluation techniques that go beyond binary questions could provide a more accurate assessment of LLMs' cultural awareness. This could include:\n\u2022 Incorporating context-dependent scenarios to assess cultural understanding in specific situations.\n\u2022 Developing multi-dimensional scoring systems that capture the complexity of cultural interactions.\n\u2022 Utilizing natural language generation tasks to evaluate the LLM's ability to produce culturally appropriate responses.\n4. Exploring alternative cultural frameworks: While Hofstede's dimensions provide a valuable starting point, future work could explore other cultural frameworks or develop new ones specifically tailored for AI evaluation [39].\n5. Investigating the impact of fine-tuning: Future studies could explore how fine-tuning LLMs on culturally diverse datasets affects their cultural awareness and performance across different languages.\nAlthough we looked at only 2 regional languages, the applications of this study extend to more than the 1000 regional languages of the world."}]}