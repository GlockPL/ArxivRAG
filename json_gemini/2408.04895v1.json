{"title": "Better Not to Propagate: Understanding Edge Uncertainty and Over-smoothing in Signed Graph Neural Networks", "authors": ["Yoonhyuk Choi", "Jiho Choi", "Taewook Ko", "Chong-Kwon Kim"], "abstract": "Traditional Graph Neural Networks (GNNs) rely on network homophily, which can lead to performance degradation due to over-smoothing in many real-world heterophily scenarios. Recent studies analyze the smoothing effect (separability) after message-passing (MP), depending on the expectation of node features. Regarding separability gain, they provided theoretical backgrounds on over-smoothing caused by various propagation schemes, including positive, signed, and blocked MPs. More recently, by extending these theorems, some works have suggested improvements in signed propagation under multiple classes. However, prior works assume that the error ratio of all propagation schemes is fixed, failing to investigate this phenomenon correctly. To solve this problem, we propose a novel method for estimating homophily and edge error ratio, integrated with dynamic selection between blocked and signed propagation during training. Our theoretical analysis, supported by extensive experiments, demonstrates that blocking MP can be more effective than signed propagation under high edge error ratios, improving the performance in both homophilic and heterophilic graphs.", "sections": [{"title": "Introduction", "content": "Graph Neural Networks (GNNs) have shown remarkable performance with the aid of a message-passing scheme, where the representation of each node is recursively updated using its neighboring nodes based on structural properties (Defferrard, Bresson, and Vandergheynst 2016; Kipf and Welling 2016; Velickovic et al. 2017). Early GNNs rely on network homophily, assuming that connected nodes will likely share similar labels. However, many real-world graphs have low homophily (heterophily) (Zhu et al. 2020; Ma et al. 2021; Luan et al. 2022), where spectral-based GNNs (Wang and Zhang 2022) achieve dismal performance under this condition (graph heterophily) as Laplacian smoothing only receives low-frequency signals from neighboring nodes.\nTo separate the embedding of connected but dissimilar nodes, recent algorithms employ high-pass filters by adjusting edge weights for message-passing (Velickovic et al. 2017; Brody, Alon, and Yahav 2021; Chen et al. 2023; Liao et al. 2024). Notably, flipping the sign of edges from positive to negative, referred to as signed propagation, has recently achieved remarkable performance (Chien et al. 2020;"}, {"title": "Motivation", "content": "We first categorize various message-passing algorithms into the following three types: plane, signed, and blocking (pruning). Then, we introduce the prior theorems on the smoothing effect under these message-passing schemes. Lastly, we point out the drawbacks of their understanding, followed by our new theorems with a novel strategy."}, {"title": "Prior Understanding on Smoothing Effect", "content": "We introduce the smoothing effect of three message-passing types under multiple classes (Baranwal, Fountoulakis, and Jagannath 2021; Yan et al. 2021; Choi et al. 2023), demonstrating the superiority of signed propagation.\nDefinition 1 (Message-Passing Schemes). For theoretical analysis, let us define three message-passing (MP) schemes built upon the Laplacian-based degree normalization (Kipf and Welling 2016). The adjacency matrix $\\bar{A} = D^{-1}A$ (Eq. 1) of each propagation scheme follows the condition below:\n\u2022 Plane MP stands for the original matrix, consisting only of positive edges.\n$\\forall(i, j) \\in E, \\bar{A} = D^{-1}A > 0$ (6)\n\u2022 Signed MP assigns negative values to the heterophilic edges, where $Y_i \\neq Y_j$.\n$\\forall(i, j) \\in E, \\bar{A} \\in \\begin{cases} D^{-1}A, & Y_i = Y_j \\\\ -D^{-1}A, & Y_i \\neq Y_j \\end{cases}$ (7)\n\u2022 Blocked MP blocks the information propagation for heterophilic edges by assigning zero.\n$\\forall(i, j) \\in E, \\bar{A} \\in \\begin{cases} D^{-1}A, & Y_i = Y_j \\\\ 0, & Y_i \\neq Y_j \\end{cases}$ (8)\nTo analyze the smoothing effect, we first inherit several useful notations defined in (Yan et al. 2021) as follows: (1) For all nodes $i = \\{1,...,n\\}$, their degrees $\\{d_i\\}$ and latent features $\\{h_i\\}$ are i.i.d. random variables. (2) Each class has the same population. (3) The scale of each class distribution after initial embedding is identical, $||E(h) = \\Sigma XW^{(0)}|_{y_i}|| = \\mu$. The latent feature after a single hop propagation $E(h^{(1)}|y_i)$ can be defined as follows.\nDefinition 2 (Binary Contextual Stochastic Block Models). Assume a binary class $E(h^{\\{0\\}} |y_i) \\sim (\\pm \\mu, 0|y_i)$ with probability (p+q = 1) and node feature is sampled from Gaussian distribution (N) (Deshpande et al. 2018). If $y_i = 0$, the updated distribution is given by:\n$E(h^{(1)}|y_i) \\sim N((\\frac{p-q}{p+q})\\mu, \\frac{1}{\\sqrt{deg(i)}})$ (9)\n(Choi et al. 2023) extended binary CSBM (Eq. 9) to multiple (ternary) classes using additional angle $\\phi$ as below:\n$E(h)[y_i) = (\\mu, \\phi, \\theta)$, (10)\nwhere $\\phi = \\frac{\\pi}{2}$, and $0 \\le \\theta < 2\\pi$. Note that the above equation satisfies the origin symmetry as in the binary case since $(\\mu, \\frac{\\pi}{2}, 0) = -(\\mu,\\frac{\\pi}{2}, \\pi)$. The CSBM in multiple classes can be defined as follows."}, {"title": "Edge Classification Error and Over-smoothing", "content": "Based on this understanding, we derive a new insight into the smoothing effect of each propagation scheme. To begin with, message-passing has lower separability (discrimination power) in case the coefficient of a specific MP $E(h|y_i)$ is smaller than others (Yan et al. 2021). Based on this observation, we first compare the plane MP with the signed and blocked MPs below.\nCorollary 6 (Plane vs Signed, Blocked MPs). Since $d'_i/(d_i + 1)$ is shared for all MPs (Eq. 11 - 13), we can compare the separability by omitting them as follows:\n\u2022 (Plane vs Signed MP) By comparing Eq. 11 and 12:\n$Z_1 = E_p - E_s = (2e - 1)\\{b_ik + (b - 1)k'\\}$ (14)\n\u2022 (Plane vs Blocked MP) By comparing Eq. 11 and 13:\n$Z_2 = E_p - E_b = eb_ik + (1 - e)(1 - b_i)k'$ (15)\nRegardless of the variables $b_i$ and $e$, the $\\int\\int Z_1$, $\\int\\int Z_2$ are always negative, meaning that plane MP shows inferior performance compared to the signed and blocked MPs. Thus, we can focus solely on the separability of the signed and blocked MPs to find the best propagation scheme.\nCorollary 7 (Signed vs Blocked MP). The difference between signed and blocked MP is given by:\n$Z_3 = E_s - E_b = (1 - 2e)k + (b_i - e)k'$ (16)\nUnder the condition of i.i.d. neighbors ($k' = -k$), the above equation becomes $Z_3 = (1 - e - b_i)k$ (Choi et al. 2023).\nPrevious studies assume a perfect edge classification scenario ($e = 0$), leading to the conclusion that $Z = 1 - b \\ge 0$ (signed MP outperforms blocked MP). However, this optimal condition is hard to achieve under a semi-supervised setting with few training nodes. Therefore, we propose estimating two parameters, $e$ and $b_i$, for the selection of precise MP schemes. For better understanding, we provide an example by varying $e$ below.\nCorollary 8 (Numerical example on edge error ratio). We employ three different edge error ratios, $e = \\{1,0.5,0\\}$ given that $Z = (1 - e - b_i)k$ in Eq. 16 as follows:\n$Z_4 = E_s - E_b = \\begin{cases} -b_ik, & e=1 \\\\ (-b +0.5)k, & e = 0.5 \\\\ (1-b_i)k, & e=0 \\end{cases}$ (17)\nWe can infer some useful insights from the above Corollary: (1) Under a high error ratio ($e = 1$, initial stage of training), it might be better to not propagate rather than using signed edges since $-b_ik < 0$ ($E_s < E_b$). In addition, an error in signed propagation increases the uncertainty more than blocked GNNs as shown in Lemma 9. (2) If the error is mediocre ($e = 0.5$), the sign of $Z_4$ is dependent on the homophily ratio $b_i$. In this condition, signed MP may perform well ($Z_4 \\ge 0$) under heterophily ($b < 0.5$), but it is still advantageous not to propagate messages under homophily. (3) However, if the edges are perfectly classified ($e = 0$), signed MP might be the best option, as demonstrated in prior work (Choi et al. 2023). Therefore, we suggest the estimation of these two parameters, $b_i$ and $e$ for precise training. The details are introduced in the following section.\nLemma 9 (Uncertainty). Under a high error ratio e, the uncertainty of signed GNNs is greater than the blocked GNNs. Proof can be found in Appendix A."}, {"title": "Methodology", "content": "Selecting an appropriate MP scheme during training is crucial for reducing smoothing and uncertainty. However, this may not be tractable under semi-supervised learning. Thus, we employ an EM algorithm, where the E-step estimates the homophily ($b_i$) and edge error ratio ($e$), followed by the M-step for optimization."}, {"title": "(E-Step) Parameter Estimation", "content": "We introduce the strategy of homophily ($b_i$) and edge error ($e_t$) estimation in Theorem 10 and 11, respectively.\nTheorem 10 (Homophily estimation). The homophily ratio $b_i$ can be inferred using the mechanism of MLP (Wang et al. 2022) and EvenNet (Lei et al. 2022) as follows:\n$b_i = BB^T, B := \\sigma(\\Sigma_{l=0}^{[L/2]}XW^l + \\Sigma_{l=0}^{[L/2]}A^{2l}XW^l)$ (18)\nwhich can take advantage of both the heterophily robustness of MLP and the low variance of EvenNet. The proof is provided in Appendix A."}, {"title": "(M-Step) Optimization with Calibration", "content": "Based on the separability of signed and blocked MP in Corollary 7, one can determine the propagation type given the estimated values, $b_i$ (Eq. 18) and $e$ (Eq. 19). For each training step $t$, we first compare their discrimination power as below:\n$Z_t = (1 - b_i - e_t)k$ (22)\nIf $Z_t < 0$, we block signed messages to reduce the smoothing effect (Corollary 7) and uncertainty (Lemma 9). For a numerical definition, let us assume the adjacency matrix derived from the downstream task as $\\bar{A}$ as defined from Eq. 6 to 8. Then, we can calibrate the edges based on the following conditions:\n$\\bar{A}_{ij} = \\begin{cases} 0, & \\bar{A}_{ij} < 0 \\land Z_t < 0 \\\\ A_{ij}, & otherwise \\end{cases}$ (23)\nThe above method is very simple and intuitive and can be applied to general GNNs. Given this, we can replace the normalized adjacency matrix ($\\tilde{A}$) in Eq. 1 with $A$ as follows:\n$H^{(l+1)} = \\sigma(AH^{(l)}W^{(l)})$ (24)\nwhich can be optimized through Eq. 2."}, {"title": "Theoretical Justification", "content": "In this section, we aim to show that the proposed method can relieve the smoothing effect of signed MP using the notion of (1) spectral radius (Thm. 16) and (2) CSBM (Thm. 17).\nDefinition 12 (Spectral Radius, Perron-Frobenius eigenvalue). Let $\\lambda_1, ..., \\lambda_n$ be the eigenvalues of an adjacency matrix $A \\in \\mathbb{R}^{n\\times n}$. Then, the spectral radius of A is given by:\n$\\rho(A) = max\\{\\left|\\lambda_1\\right|, ..., \\left|\\lambda_n\\right|\\}$ (25)\nA is well known to converge $\\Leftrightarrow \\rho(A) < 1$ or $\\rho(A) = 1$ and $\\lambda_1 = 1$ is the only eigenvalue on the unit circle."}, {"title": "Analysis on Discrimination Power (Q2)", "content": "In Figure 2, we present the inter-class distances for three GNNs with signed MP (GPRGNN, FAGCN, and GGCN) across four benchmark graphs (Cora, Citeseer, Actor, Squirrel) to investigate a neural collapse perspective (Kothapalli,"}, {"title": "Importance of Proper MP Schemes (Q3)", "content": "We aim to show that selecting a proper propagation scheme between signed or blocked MPs is crucial for GNNs. As described in Figure 3, the x-axis stands for the $Z_t$ in Eq. 22, and the y-axis represents node classification accuracy. For a fair comparison, we remove the randomness for all methods (e.g., parameter initialization) by fixing the seed. The left figure is Cora and the right one is Chameleon. We have proved that blocked MP outperforms signed MP in the case of $Z_t < 0$, and vice versa. To verify this, we assume two types of MPs: signed (S) and blocked (B) under two different conditions: $Z_t < 0$ and $Z_t \\ge 0$. For example, S-S means that signed MPs are used independent of $Z_t$, while B-S utilizes blocked MP if $Z_t < 0$ and signed MP for $Z_t \\ge 0$. As illustrated, selecting the proper propagation scheme (B-S) achieves the best quality, where the performance gap becomes greater in the heterophilic graph (Chameleon). Conversely, improper MPs (S-B or S-S) when $Z_t < 0$ show low accuracy, showing that blocked MP can improve the quality of prediction under this condition significantly."}, {"title": "Analysis on Large Graphs (Q4)", "content": "We conduct experiments on large benchmarks (Lim et al. 2021) and describe the results in Table 3. Due to the OOM issue, we apply our method to one of the signed GNNS, GPRGNN (Chien et al. 2020). As shown in the table, our method GPRGNN* demonstrates notable improvements in node classification accuracy across large graphs. Specifically, on the three datasets, GPRGNN* achieves an accuracy improvement of 2.72%, 2.98%, and 5.3% over the baseline GPRGNN, respectively. Although H2GCN (Zhu et al. 2020) and GCNII (Chen et al. 2020) show the best performance on arXiv and snap, this is because the accuracy of the original GPRGNN is quite lower compared to the other methods. To summarize, these results highlight the effectiveness of our approach in enhancing the performance of GNNs on large-scale benchmarks."}, {"title": "Related Work", "content": "Heterophilic GNNs. Starting from Laplacian decomposition (Defferrard, Bresson, and Vandergheynst 2016), spectral GNNs (Kipf and Welling 2016; Wang and Zhang 2022; Du et al. 2022; Bo et al. 2023; Lu et al. 2024) have achieved remarkable performance on homophilic graphs. However, as the homophily (Platonov et al. 2024) of the graph decreases, their performance sharply declines due to local smoothing (Pei et al. 2020). To address this limitation, spatial-based GNNs have emerged, developing many powerful schemes that adjust edge weights for message-passing (Velickovic et al. 2017; Brody, Alon, and Yahav 2021; Chen et al. 2023; Liao et al. 2024). Specifically, some studies handle disassortative edges by capturing node differences or incorporating similar remote nodes as neighbors (Derr, Ma, and Tang 2018; Huang et al. 2019; Zhu et al. 2020; Choi et al. 2022; Lei et al. 2022; Wang et al. 2022; Zhao et al. 2023; Zheng et al. 2023; Mao et al. 2024; Yan et al. 2024; Li, Pan, and Kang 2024; Qiu et al. 2024). Among these, methods that either change the sign of the edge (Chien et al. 2020; Bo et al. 2021; Fang et al. 2022; Guo and Wei 2022) or opt not to transmit information (Luo et al. 2021; Hu et al. 2021; Tian et al. 2022) have recently been proposed.\nOver-smoothing in GNNs. In addition to the above methods, theoretical analyses have emerged explaining why each message-passing technique works well from the perspective of node separability (reduced smoothing effect). For example, (Yan et al. 2021; Baranwal, Fountoulakis, and Jagannath 2021) analyzed the separability of the plane, signed, and blocked propagation after message-passing under binary class graphs. Recently, (Choi et al. 2023) extended the theorems to multi-class scenarios, and (Li, Mei, and Ma 2024) suggested their degree-corrected version. However, these methods assume a fixed edge classification error, which may fail to induce the smoothing effect precisely."}, {"title": "Conclusion", "content": "In this paper, we have presented a comprehensive study on the impact of edge uncertainty and over-smoothing in signed Graph Neural Networks (GNNs). Our key contributions are two-fold. Firstly, we scrutinize the smoothing effect under different edge error ratios, providing a novel perspective that challenges the assumption that all propagation schemes exhibit similar edge classification error ratios. Secondly, we introduce an innovative training mechanism that dynamically selects between blocked and signed propagation based on these error ratios, effectively mitigating over-smoothing and enhancing performance. Our theoretical analysis, supported by extensive experiments, demonstrates that blocking message propagation can be more effective than traditional message-passing schemes under high edge error ratios. This insight is crucial for improving node classification accuracy in both homophilic and heterophilic graphs. We hope that future work can explore further refinements of these techniques for more complex graph structures."}]}