{"title": "TACOS: Task Agnostic Continual Learning in Spiking Neural Networks", "authors": ["Nicholas Soures", "Peter Helfer", "Anurag Daram", "Tej Pandit", "Dhireesha Kudithipudi"], "abstract": "Catastrophic interference, the loss of previously learned information when learning new information, remains a major challenge in machine learning. Since living organisms do not seem to suffer from this problem, researchers have taken inspiration from biology to improve memory retention in artificial intelligence systems. However, previous attempts to use bio-inspired mechanisms have typically resulted in systems that rely on task boundary information during training and/or explicit task identification during inference, information that is not available in real-world scenarios. Here, we show that neuro-inspired mechanisms such as synaptic consolidation and metaplasticity can mitigate catastrophic interference in a spiking neural network, using only synapse-local information, with no need for task awareness, and with a fixed memory size that does not need to be increased when training on new tasks. Our model, TACOS, combines neuromodulation with complex synaptic dynamics to enable new learning while protecting previous information. We evaluate TACOS on sequential image recognition tasks and demonstrate its effectiveness in reducing catastrophic interference. Our results show that TACOS outperforms existing regularization techniques in domain-incremental learning scenarios. We also report the results of an ablation study to elucidate the contribution of each neuro-inspired mechanism separately.", "sections": [{"title": "1. Introduction", "content": "When artificial neural networks are presented with new learning tasks, they are prone to forget previously acquired material. This problem, known as catastrophic interference (or catastrophic forgetting), was first identified in 1989 (McCloskey & Cohen, 1989) and continues to be a challenge in the field of artificial intelligence (Parisi et al., 2019). By contrast, humans and other mammals do not seem to suffer from this problem. Neuroscientists and machine learning researchers have therefore sought to understand how biological neural systems are able to avoid catastrophic interference, and several explanations have been proposed, most of them variations of metaplasticity (Abraham & Bear, 1996; Finnie & Nader, 2012), neurogenesis (Parisi et al., 2018), or episodic replay (McClelland et al., 1995; Robins, 1995; French et al., 2001). Although direct evidence for such hypotheses is difficult to come by, computational modeling has demonstrated that analogous mechanisms can reduce catastrophic interference in artificial neural networks. (Meeter & Murre, 2005; O'Reilly et al., 2011; Draelos et al., 2017).\nIn this paper we introduce TACOS, a spiking neural network (SNN) that addresses continual learning. Sequential learning of tasks is enabled by error-driven neuromodulation. To mitigate catastrophic forgetting we propose a complex synaptic model that utilizes a form of activity-dependent metaplasticity with synaptic consolidation and heterosynaptic decay.\nWhy a spiking model? Spiking neural networks are considered more neurally plausible than rate-based networks (Pfeiffer & Pfeil, 2018), and are orders of magnitude more energy-efficient (Neftci et al., 2017; Nawrocki et al., 2016), yet are at least as computationally powerful as rate-based networks (Gerstner & Kistler, 2002). Nevertheless, unlike rate-based networks, SNNs have not yet achieved a level of performance suitable for practical applications, mainly because of a lack of efficient and scalable learning algorithms. This situation is, however, beginning to change as new SNN learning algorithms are being introduced, including surrogate-gradient back-propagation (Neftci et al., 2019), three-factor Hebbian learning (Fr\u00e9maux & Gerstner, 2016), and homeostatic or non-Hebbian plasticity (Watt & Desai, 2010). We thus find ourselves at a moment in time when spiking neural networks are coming into their own, and addressing the continual learning problem in the spiking domain is an important step on the way forward. Recent contributions to this effort include investigations of the benefits of local Hebbian learning (Mu\u00f1oz-Mart\u00edn et al., 2019), Hebbian learning with weight decay (Panda et al., 2017),\nand controlled forgetting, a technique that directs plasticity toward the least active regions of the network (Allred & Roy, 2020). These techniques have, however, been limited to spiking models that are not capable of supervised training, or only able to train a single layer. TACOS does not suffer from these limitations, and also differs from previously published models (Kirkpatrick et al., 2017; Chaudhry et al., 2018; Kolouri et al., 2020; Lee et al., 2017; Zenke et al., 2017) in that it does not require any task-identifying information during training or inference, the learning rules are entirely synapse-local, and the algorithm is scalable to multi-layer spiking networks.\nOur results show that TACOS outperforms several state-of-the-art regularization models in the domain-incremental scenario (van de Ven & Tolias, 2019). Importantly, TACOS achieves these results with a small number of added parameters, using a fixed memory size that does not depend on the number of tasks to be learned.\nIn addition to comparing TACOS to other models, we provide an analysis of TACOS' performance in continual learning by i) studying how the model performs when the amount of training data is reduced, ii) studying how the trade-off between stability and plasticity depends on the degree of metaplasticity, and iii) performing an ablation study to investigate the effects of metaplasticity and consolidation separately."}, {"title": "2. Background", "content": ""}, {"title": "2.1. Neural Mechanisms", "content": "There is near-universal agreement among neuroscientists that brains store memories in the strengths of synapses (Langille & Brown, 2018). The ability of synapses to weaken or strengthen over time is called synaptic plasticity, and a number of cellular mechanisms for plasticity have been discovered (Kandel et al., 2014). Among them, long-term potentiation (LTP) (Nicoll, 2017) is the one most studied, and it is considered a major cellular mechanism underlying learning and memory (Frankland & Bontempi, 2005; Kandel et al., 2014). Early-phase LTP (E-LTP) results from moderately strong stimulation and lasts from minutes to hours (Abraham, 2003; Malenka & Bear, 2004); late-phase LTP (L-LTP) requires more intense stimulation and can persist for weeks, months, or even years (Abraham et al., 2002). The transition from E-LTP to L-LTP is known as synaptic consolidation, and it has been identified with the transformation of short-term memories into long-term memories (Sossin, 2008; Morris, 2003).\nThe increase in memory lifetime (reduced spontaneous decay rate) that characterizes consolidation is accompanied by an increased resistance to memory disruption and modification (Dudai), corresponding to reduced plasticity at the synaptic level (Richards & Frankland, 2017), a form of metaplasticity (\"plasticity of synaptic plasticity\") (Abraham & Bear, 1996). Both of these transformations - reduced decay rate and reduced susceptibility to disruption - are important aspects of memory stability.\nAnother physiological process of importance for learning and memory is neuromodulation. Unlike point-to-point synaptic transmission, neuromodulation can simultaneously affect the activity and plasticity of large numbers of neurons through widespread release of neurotransmitters in response to novelty, surprise, reward, etc. (Marder, 2012)."}, {"title": "2.2. Related Work", "content": "Many previously published regularization approaches (Kirkpatrick et al., 2017; Zenke et al., 2017; Kolouri et al., 2020; Chaudhry et al., 2018; Ahn et al., 2019) achieve effects similar to those observed in biology by modifying the loss function to retain information or regularize the model's likelihood distribution to protect important synapses. Techniques like EWC (Kirkpatrick et al., 2017) and SI (Zenke et al., 2017) select important parameters by using a Fisher Information matrix or tracking synapses' credit in improvement on a task, respectively. The models presented in (Chaudhry et al., 2018; Kolouri et al., 2020; Lee et al., 2017) select parameters that preserve the distribution of latent representation of the task. A similar research direction has been to leverage metaplasticity for continual learning. Laborieux et al. (2020) apply a version of metaplasticity to a binary neural network model, making synapses with weights of greater magnitude less plastic, to protect them from modification by subsequent training."}, {"title": "2.3. Main Contribution", "content": "Using a combination of synaptic consolidation, metaplasticity and neuromodulation, TACOS is able to protect knowledge from catastrophic interference with the use of local information, and without recourse to task awareness, and operates with bounded resources, all of which are important characteristics for systems targeted for real-world deployment. We also demonstrate TACOS effectiveness when constrained to more realistic scenarios where data samples are only seen once. Furthermore, we explore the stability-plasticity trade-off to identify the inflection point where the network is performing at an optimum state and the dependencies of this point on the number and duration of each task."}, {"title": "3. Methodology", "content": ""}, {"title": "3.1. Problem Formulation", "content": "Continual learning is the ability to learn tasks sequentially, without suffering severe performance loss on previously learned tasks when new ones are learned. Formally, we define a task, $\\mathcal{T}_t$, to be a set {$\\mathcal{X}_t$, $\\mathcal{Y}_t$} of ordered pairs of input data points and their corresponding class labels. The continual learning problem is formulated as maximizing the performance of a system across all tasks, $\\mathcal{I}$, when trained sequentially."}, {"title": "3.2. Preliminaries", "content": "We describe the TACOS framework for continual learning in SNNs in discrete time. The basic building block is a spiking neuron model, the leaky integrate and fire (LIF) neuron, with dynamics described by\n$V(t+1) = V(t)+ \\frac{\\Delta t}{\\tau_{mem}}\\left((V_{rest}-V(t))+I(t)R\\right)$, (1)\nwhere t is the simulation time step counter, $\\Delta t$ is the length of a time step, the membrane potential V(t) integrates synaptic current I(t) over time, R is the membrane resistance, and $\\tau_{mem}$ is the membrane time constant which controls the rates of integration and decay. The synaptic current is a summation of the presynaptic action potentials integrated according to\n$I(t + 1) = I(t) + \\frac{\\Delta t}{\\tau_{syn}} \\sum_{j=1}^{N} (w_jS_j(t) - I(t))$. (2)\nAt each time step, the synaptic input current, I(t), is incremented by the summation of incoming N presynaptic action potentials, $S_j$, which have the value 1 for neurons that have fired and 0 otherwise, weighted by the synaptic strengths, $w_j$, and decays exponentially towards zero with the synaptic time constant $\\tau_{syn}$.\nWhen the membrane potential crosses a threshold $V_{th}$, an action potential is emitted (S = 1) and the membrane potential is reset to zero (V = 0). Any neuron that has recently fired undergoes a short time period where its membrane potential is frozen at zero as a simple model of a refractory period. The neural network used in this work is strictly feed-forward, as shown in Figure 1. Input is received as spike trains, one per input neuron, generated from input data, e.g. by Poisson or population encoding."}, {"title": "3.3. Surrogate Gradient Learning", "content": "To train the model, we implement a surrogate gradient learning rule known as event-driven random backpropagation (eRBP) (Neftci et al., 2017). eRBP relies on presynaptic firing, postsynaptic surrogate gradients, and error feedback through fixed random weights, approximating backpropagation. In eRBP, each neuron has a second compartment U (in addition to the membrane potential V) for integrating the error feedback as described in the following.\nAt each time step, the difference between the output neurons' spiking activity, $S^{out}$, and a target spiking activity or label, L, is used to generate an error current\n$I^{err}(t) = S^{out}(t) - L(t)$. (3)\nThe error current is passed as input to two sets of error-encoding neurons; one set for false positives (neurons that fire when they should not), which receives $I^{err}$, and a second set for false negatives (neurons that do not fire when they should), which receives $-I^{err}$. The two sets of error-encoding neurons are implemented using integrate-and-fire dynamics, and emit spikes $S^{fp}$ and $S^{fn}$ when the accumulated error crosses their membrane threshold.\nThe $i^{th}$ output neuron receives the error signal\n$E_i(t) = S^{fp}_i(t) - S^{fn}_i(t)$, (4)\nwhile the $j^{th}$ hidden neuron in layer h receives the error signal\n$E_j^h(t) = \\sum_{i=1}^{O} (w_{ij}^{fp,h}S_i^{fp}(t) - w_{ij}^{fn,h}S_i^{fn}(t))$, (5)\nwhere O is the number of output neurons, and $w_{ij}^{fp,h}$ and $w_{ij}^{fn,h}$ are random feedback weights from the error neurons encoding false positives and false negatives, respectively.\nThe hidden and output neurons integrate the received error signal in a separate compartment U, in a manner similar to the way their membrane potentials integrate forward spikes:\n$U(t + 1) = U(t) + \\frac{\\Delta t}{\\tau_{mem}}E(t)R$. (6)\nWhenever a presynaptic neuron fires, the weights of synapses connecting that neuron to postsynaptic neurons are updated, provided the total synaptic current flowing into the postsynaptic neuron falls in a specified interval, $I_{post} \\in \\{I_{min}, I_{max}\\}$. This condition on post-synaptic current is an approximate surrogate gradient for the LIF neuron based on the relation between LIF firing rates and a ReLU activation, though other surrogate gradient models can be used. The weight update is proportional to the accumulated error in the corresponding post-synaptic neuron's second compartment U (positive or negative):\n$w_{i,j}(t + 1) = w_{i,j}(t) - \\eta S_j(t)U_i(t)\\Theta(I_i(t))$, (7)"}, {"title": "3.4. Continual Learning with eRBP", "content": "Our objective in the present work is to preserve synaptic knowledge using only information locally available in individual neurons and synapses. To achieve this, we introduce neuro-inspired mechanisms that preserve synaptic knowledge and add complexity to the synapse itself, shown in Figure 2.\nA synapse's plasticity is calculated as a function of its weight and its metaplasticity parameter:\n$f(m,w) = exp(- abs(mw))$, (8)\nand is used to modulate weight updates, where w is the synaptic weight.\nThe second mechanism is known as synaptic consolidation. The general notion is that synapses have more complexity than can be captured by a single, plastic weight. One approach is to include two weight components that interact with each other and may have different dynamics, e.g. one fast-changing and one slow-changing (Zenke et al., 2015; Leimer et al., 2019; Munkhdalai, 2020)). In TACOS we use a two-component model where in addition to the actual synaptic weight w, each synapse has a hidden slower-changing reference weight $w^{ref}$ that tracks the actual weight according to\n$w^{ref}(t + 1) = w^{ref}(t) + \\frac{\\Delta t}{\\tau_{ref}} (w(t) - w^{ref}(t))$, (9)\nwhere $\\tau_{ref}$ is the time constant for the evolution of $w^{ref}(t)$.\nThe change in $w^{ref}(t)$ is driven by its difference from w(t).\nWhenever the postsynaptic neuron spikes, the actual weights of all its inbound synapses drift towards their reference weights through heterosynaptic plasticity according to\n$w_{ij}(t + 1) = -\\alpha (w_{ij}(t) - w_{ij}^{ref}(t))$, (10)\nwhere $\\alpha$ is the decay rate. This decay back towards the reference weight, dependent on the postsynaptic activity, acts as a regularizer for neurons that are actively learning. This helps maintain a balance between the current synaptic changes and consolidated knowledge stored in the reference weight.\nIn summary, while metaplasticity slows down synaptic weight changes, it does not prevent long-term shifts in synaptic strengths. Synaptic consolidation works in tandem with metaplasticity to regulate changes in synaptic values: i) slow adjustment of reference weights ensures that repeated plasticity updates, driven by error-modulated plasticity for the current task, will become permanent, ii) small sporadic weight changes, restricted by metaplasticity, are undone by heterosynaptic decay before they have time to consolidate, allowing synaptic weights to remain at values learned from previous tasks. The complete formula for weight update in TACOS is:\n$w_{ij}(t + 1) = w_{i,j}(t) - exp(- abs(m_{i,j}(t)w_{i,j}(t))) ( \\eta S_j(t)U_i(t)\\Theta(I_i(t)) + \\alpha (w_{ij}(t) - w_{ij}^{ref}(t))S_i(t))$, (11)\nEssentially, the weight update is now a combination of the update from the error-driven surrogate gradient model and a decay term based on the consolidation mechanism. Metaplasticity is used to control the strength of change induced by both error-driven plasticity and decay. These mechanisms come together to mitigate catastrophic interference, relying only on local information."}, {"title": "4. Results", "content": "We evaluate TACOS on split image classification benchmarks using 5-Split MNIST (LeCun et al., 1998) and Fashion-MNIST (Xiao et al., 2017) datasets under the task-agnostic domain-incremental continual learning scenario (van de Ven & Tolias, 2019; Hsu et al., 2018), where tasks share the same output layer while the model is unaware of task identity during both training and inference. The network configuration was fixed to 200 neurons per hidden layer (1-2 hidden layers), and a two-neuron output layer. Unlike most models, TACOS only sees each data sample once (i.e one training epoch), as would be the case in a real-world scenario (Lopez-Paz et al., 2017).\nMetrics: To assess the performance of TACOS and other models, we measure the mean accuracy, MA, across the entire set of tasks $T_1$ \u2013 $T_N$, after training on the final task $T_N$: MA = $\\frac{1}{N}\\sum_{t=1}^{N} R_{t, N}$, where $R_{t,N}$ is the accuracy on task $T_t$ after training task $T_N$. As a measure of a model's cost we use the memory overhead, MO, calculated as the average amount of memory that a model requires per task, Mem($T_t$), in units of the baseline model's memory size Mem:\nMO = $min(1, \\frac{1}{Mem}Mem(T_t))$.\nAnother important metric when studying catastrophic forgetting is backwards transfer BWT = $\\frac{1}{N-k}\\sum_{t=1}^{k-1} R_{t,k}$-\n$R_{t,k}$, the average change in accuracy on tasks t < k, after learning task $T_k$. A negative BWT reflects catastrophic interference (the smaller the value, the greater the interference), whereas a positive BWT reflects that training the current task improves the performance on previous tasks. The final metric included in this analysis is forward transfer (FWT) of knowledge; FWT = $\\frac{1}{N-k}\\sum_{t=k+1}(R_{t,k}$ \u2013 $b_t)$, the average performance improvement across all tasks t > k, after learning task $T_k$, with respect to the baseline performance $b_t$ of the untrained model.\nContinual Learning Analysis: From Table 1 we can see that TACOS outperforms its similar rate-based counterparts in the Domain-IL scenarios. TACOS is able to achieve this performance with a memory overhead lower than the other models, with the exception of LwF (Li & Hoiem, 2017) and SS (Schug. Simon, 2020). It is, however, important to note that the number of parameters or memory overhead of TACOS does not grow with the number of tasks. In order to assess the role of metaplasticity and consolidation, we perform an ablation study by testing the two mechanisms on their own. This can be see in Table 1, where SNN + Metaplasticity and SNN + Consolidation both perform significantly worse than TACOS.\nTACOS Plasticity-Stability trade-off: To study the plasticity-stability trade-off, we observe learning in three different models. The first model is TACOS, where the maximum metaplastic state is set to different values (see Table 3). The second model is where the metaplastic state is fixed as proposed in (Laborieux et al., 2020) with synaptic consolidation (referred to as Fixed in Table 3). The third and last model is the baseline SNN with no metaplasticity or consolidation incorporated.\nFirst, we compare knowledge retention (i.e. stability) across models, by measuring the degradation in accuracy on prior tasks. We also monitor the degree of perturbation of the network by measuring the cosine similarity between network representations of the same input after learning each task. As seen in Figure 3, TACOS shows lower degradation of accuracy than either the fixed model or the SNN. This result is dramatic when TACOS has a maximum metaplastic state greater than 25; a setting with which the fixed model is incapable of learning. The backwards transfer analysis in Table 3 shows that TACOS has 4-10x less catastrophic interference than the baseline SNN.\nSimilarly, the cosine similarity of network representations for the digits in task 1 ({0,1}), after learning task 1 and after learning task 5 is 0.98 vs 0.86 on class 1 in TACOS (m=25) compared to the baseline SNN and 0.98 vs 0.85 compared to fixed metaplasticity (m=10) as shown in Table 2.\nEqually important in addressing catastrophic forgetting is the plasticity of the model, ensuring that the model is capable of learning future tasks. To assess the plasticity of each model, we compare the single-task accuracy on the most recently trained task, as well as the average weight change during learning. For single-task accuracy (see Table 3), it can be observed that the gap between TACOS and the baseline SNN performance becomes progressively larger as the number of tasks learned increases with TACOS performance culminating between ~6% to ~30% lower than the baseline SNN on the final task. This can be attributed to metaplasticity and consolidation restricting weight changes to preserve knowledge on prior tasks. This is also reflected in Figure 4, where the SNN is seen to have ~3x the plasticity of a TACOS model. In comparison to fixed metaplasticity, TACOS allows for significantly more plasticity. Finally, when varying the metaplastic limit in TACOS, there is little change to the average plasticity induced in the network.\nWhen considering the optimal trade-off between plasticity and stability there are three main takeaways;\n\u2022 Using a dynamic metaplastic state as proposed in TACOS shows both greater plasticity and better retention of knowledge than a fixed metaplastic state.\n\u2022 Although the plasticity of TACOS is ~3x lower than that of the baseline SNN, the mean accuracy is ~22% higher and catastrophic interference is ~5x lower.\n\u2022 The stability-plasticity trade-off in TACOS on the split-MNIST and split-FMNIST tasks shows an inflection point in mean accuracy when the maximum metaplastic state is set to m = 25.\nFrom this analysis, it is clear that stability increases in TACOS as the number of tasks learned progresses. In the early phases of the split MNIST task the reduction in plasticity is almost negligible, by the final task there is a substantial decrease in the single-task accuracy. In situations where the number of tasks, or even the amount of time spent on each task, is known, the trade-off in plasticity and stability can be optimized by controlling the metaplasticity and consolidation. We demonstrate this by showing the impact on TACOS of reducing the dataset size in Figure 5. Some performance degradation is expected due to the reduced number of training samples per task, but the main take-away is that TACOS can largely maintain the same performance, if the metaplasticity and consolidation parameters are scaled based on the time spent learning each task. However, this can become a limitation in deployment on unknown task distributions where potential solutions can be decaying metaplastic updates or scaling metaplastic updates with the magnitude of error on a given sample. Finally, to explore the performance of TACOS over a large family of tasks we create a 50-task Domain-IL scenario with the Omniglot dataset by randomly grouping 5 characters into each task. This is a rather challenging problem for TACOS because each task consists of 75 training images only seen once, leaving very little time for the network to learn the correct patterns, update the metaplastic state, and consolidate information. As seen in Figure 6 a low metaplastic state (blue) increases the final mean accuracy by 6% compared to the baseline SNN (red), while the single task accuracy is relatively similar. Once the metaplasticity is increased by 5x (green), we see that not only does the mean accuracy drop to the same as the baseline SNN, learning of downstream tasks is greatly reduced very early. However, we can see from the first task accuracy that recall of the first task is significantly increased with high metaplasticity, while low metaplasticity barely slows down the forgetting with respect to the baseline SNN."}, {"title": "5. Conclusion", "content": "TACOS results demonstrate that progress towards continual learning in spiking networks is possible using a combination of local plasticity mechanisms. Specifically, we demonstrate that the combination of activity-dependent metaplasticity, synaptic consolidation, heterosynaptic decay, and error-driven neuromodulation can outperform similar rate-based models in domain-IL scenarios. Crucially, TACOS achieves this in a task-agnostic manner, relying only on local information, with a memory budget that does not grow with the number of tasks. By exploring the stability-plasticity trade-off as a function of metaplasticity, we demonstrate that activity-dependent metaplasticity offers significant improvement over a fixed metaplastic state. As learning models in SNNs progress, the mechanisms demonstrated in TACOS will be applicable to spiking CNNs for more complex problems such as Cifar10/100 and ImageNet. In future work, we anticipate to further boost TACOS by : i) allowing for reduction in the metaplastic state, ii) incorporating neurogenesis to introduce neurons with low metaplastic states, or iii) resetting the metaplastic state when long-term consolidation of knowledge can occur through rehearsal."}]}