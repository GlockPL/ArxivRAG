{"title": "Convolutional Deep Colorization for Image Compression: A Color Grid Based Approach", "authors": ["Ian Tassin", "Kristen Goebel", "Brittany Lasher"], "abstract": "The search for image compression optimization techniques is a topic of constant interest both in and out of academic circles. One method that shows promise toward future improvements in this field is image colorization since image colorization algorithms can reduce the amount of color data that needs to be stored for an image. Our work focuses on optimizing a 'color grid' based approach to fully-automated image color information retention with regard to convolutional colorization network architecture for the purposes of image compression. More generally, using a convolutional neural network for image re-colorization, we want to minimize the amount of color information that is stored while still being able to faithfully re-color images. Our results yielded a promising image compression ratio, while still allowing for successful image recolorization reaching high CSIM values.", "sections": [{"title": "1. Research Overview", "content": "Colorization of decolorized or black and white images is an important task that can be completed through deep learning approaches. Previous studies have identified that retaining points of color within an image lead to improved results when coloring images. In this work, we aim to investigate how retaining a different number of colored pixels within an image will help with reconstitution of the original colors, when using a convolutional neural network. We also evaluate how partial decolorization of images improves compression or storage size."}, {"title": "1.1. Introduction", "content": "Image colorization of grey-scale images to increase visual appeal is a research area with over 20 years of history [14]. The primary appeal of this research historically has focused on improving images aesthetics by the addition of color. Particularly this has been motivated by a desire to breathe new life into historical photographs taken before color photography.\nA subsequent off shoot of this research has considered the potential for image decolorization as a method of image compression since it requires less data to store a grey-scale image compared to a color image. Given a sufficiently accurate model for re-colorization of the image when it needs to be retrieved this could lead to image storage improvements. Retaining some color information has been shown to lead to dramatic improvements in colorization [13]. However, without user intervention, knowing at what locations to store color information proves tricky and, in research thus far, necessitates the storage of more color information in a systematic way. These automated methods have also proven very effective [5]."}, {"title": "1.2. Related Work", "content": "With the rise of deep learning, many different studies have focused on a broad range of deep learning techniques and model architectures to accomplish the task of adding color to black and white images [3]. These approaches can quickly and easily handle large amounts of data and have demonstrated effective results. Since the first deep learning image colorization method in 2015 [3], the field has rapidly grown. Various approaches have been applied, such as convolutional neural networks [4, 6, 10, 12, 17], which allow for retaining spatial information, generative adversarial networks (GANs) [8, 15], which are advantageous for preserving details and high-quality image generation, and transformer networks [9] that excel at applying color with context to the entire image. Previous studies have also identified that color fidelity was improved when some original color from the image was retained [2,5]. In [5], they applied two different automated approaches for choosing the pixel location(s) for color retention. Such approaches included grid-based, where every n-th pixel remained colored, and segment-based, where segments in the images were identified and a pixel within each segment was chosen to retain color. Another recent study of particular interest for our paper is [13] which proposes a convolutional, U-net architecture for image recolorization. Hence forth we will refer to this model architecture as XiaoNet. Our study will focus on the marriage of two methods: the use of grid-based, automated color retention like the method described in [5] with a convolutional U-net architecture derived from the XiaoNet architecture. Furthermore, we aim to find the optimal amount of color-information retention to maximize the image compression while maintaining enough information to make highly accurate predictions using our XiaoNet-like architecture More information on our architecture is available in Section 3."}, {"title": "2. Methodology", "content": "We used the Crayon model architecture, see Section 3, and passed it color information at regular intervals along a 'color grid' in the AB color channels. A similar, grid-based color encoding was used in [5], however they use a significantly different network architecture. Our paper uses a grid-based color encoding with a model architecture derived from [13]."}, {"title": "2.1. Data Set", "content": "Within this work, we analyzed the results of our method on the Imagenette version two data set, which is composed of 9469 training images and 3925 validation images. We removed 50 images from the validation set to use as a test set for our experiments. For consistency and convenience, we cropped all images to size 320x320 regardless of n value before inputting them into the model."}, {"title": "2.2. Data Processing", "content": "In order to test our model on colorization, we needed to remove the the bulk of color from the images in our data set. To accomplish this task, we first converted the color from RGB color space to LAB color space as is standard for image colorization tasks. The LAB color mode represents greyscale as a single channel lightness (L) and represents color information with 2 channels (A and B). This color space in generally believed to better match human perception of color, and increase the semantic meaning of distance measurements. Next, most of the color was removed from each image in the data set, retaining only every nth colored pixel in a grid formation. This will enable a smaller storage size of images, while also retaining key color information advantageous for color regeneration. In this work, we test n-values of 6, 15, 20, 40, 50, 60, 80, and 100, to determine what level of retained color results in the highest overall performance."}, {"title": "2.3. Training", "content": ""}, {"title": "2.3.1 Loss function", "content": "We used mean squared error (MSE) as our loss function, rather than the Huber loss used in [13], based on empirically better results when training our model."}, {"title": "2.3.2 Optimizer", "content": "For model training we used the ADAM optimizer with a step size of 10-4."}, {"title": "2.3.3 Training Evaluation", "content": "We collected data across many color-grid spacing values, n. For each value of n, we trained a model for 30 epochs. After each epoch we saved our model if its validation accuracy was higher than the previous version, these best-forming trained models are heretoafter referred to as the canonical model for a given n value.\nOnce training was complete for each n value we evaluated the canonical model for that n value on our test set. Our evaluation metrics were calculated with regard to color-tone similarity index measure (CSIM) and peak signal to noise ratio (PSNR). These results, along with examples of the models predictions for each n value can be examined in more detail in Section 4."}, {"title": "3. The Crayon Model Architecture", "content": ""}, {"title": "3.1. Overview", "content": "Our model architecture, Crayon, which stands for Convolutional Recolorization Architecture for Yielding Ocular Niceties, was derived from the XiaoNet model architecture [13]. Crayon consists of a 4 stage U-net followed by a small residual network. A detailed breakdown of the model can be found in Section 3.2."}, {"title": "3.2. Architecture Details", "content": "A full breakdown of the Crayon architecture can be found in tables 1 and 2."}, {"title": "Key for Tables 1 and 2.", "content": "\u2022 Xi indicates spacial dimensions (width and height) of the input.\n\u2022 X, indicates spacial dimensions (width and height) of the output.\n\u2022 Ci indicates the number of channels of input.\n\u2022 Co indicates the number of channels of output.\n\u2022 K indicates the kernel size.\n\u2022 S indicates the stride.\n\u2022 P indicates the padding.\n\u2022 D indicates the dilation.\n\u2022 \"Data From\" indicates which layer(s) output is input to the current layer.\n[x, y] Brackets indicate that the output of the contained layers is being concatenated together along the channel axis.\n{x,y} Curly brackets braces indicates the contained layers are undergoing element wise addition."}, {"title": "4. Evaluation of Colorization", "content": "To evaluate our image colorization performance, we examine two metrics, color-tone similarity index measure (CSIM) and peak signal to noise ratio (PSNR)."}, {"title": "4.1. Results and Data", "content": "Each model is evaluated on a held-out test set of 50 images. The recolorization quality of the images is evaluted using CSIM and PSNR. For both metrics, a higher value indicated a better quality recoloring. The quality of the images for each n as well as a theoretical upper bound for the compression size relative to the original image size are shown in Figure 2. As n increases and retained color information becomes sparser, both PSNR and CSIM decrease.\nWe calculate the theoretical upper bound for the image compression size, relative to the original image, using\n$\\text{relativeSize} = \\frac{1}{3} + \\frac{1}{n^2}$ (1)\nwhich is a combination of the size of the grey scale image and the remaining colored pixels. As n increases, the overall size will approach 1/3, so any compression size near this value is maximizing the capabilities of this method. The best n appears to be around n=20, after this point the compression size does not improve significantly but the image recolorization continues to decrease in quality.\nThe differences in recolorization on an example test image are shown in Figure 3. After n=20, the differences between the recolorization and the original image are more easily noticed, such as a lack of red in the window frames or a brown coloring on the walls of the building. The CSIM results we observed for lower n-values (< 20) are comparable to results observed through a GAN-based colorization approach, where the CSIM of their autocolorization mode reached values of roughly 0.87 - 0.88. When comparing our PSNR results to other method's results (Fig. 2) [1, 7, 16], our method reached a higher PSNR. However, this is not a direct comparison, as the data set and number of samples varies between our evaluation and other studies. Furthermore, when examining our compression results to those from other studies, we found them to be comparable [11]."}, {"title": "4.2. Conclusion", "content": "Our results are very promising regarding the used of recolorizaton as a form of image compression. We find very minimal losses with regard to PSNR and CSIM when using n values between 6 and 15 (Fig. 2) as well as little to no visual artifacts in the recolored images (Fig. 3). Additionally, the compression gain from values larger than n = 20 are very minimal (Eq. (1)) while the number of visual artifacts (Fig. 3) and measured losses increase dramatically (Fig. 2). It is not clear to what extent these results will generalize to all other model architectures, however a previous study using a GAN-based method for image colorization applied a similar approach to automatically choosing colored pixels, and showed successful results [5]. Additionally, alternative algorithmic approaches for selecting which pixels to keep or discard color information for may lead to improved performance. For example, future research could select color pixels based on their dis-similarity to adjacent pixels, this could ensure that small features are correctly colored instead of accidentally being skipped-over and having no encoded color information saved which can be a problem for this approach, especially for larger n values.\nWe doubt that encoding less n = 20 color information will proved viable for any model architecture since the compression benefits are very minor above n = 20 and the sparsity of color data above that range makes inaccurate coloring predictions much more likely."}]}