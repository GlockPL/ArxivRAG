{"title": "Curriculum-enhanced GroupDRO: Challenging the Norm of Avoiding Curriculum Learning in Subpopulation Shift Setups", "authors": ["Antonio Barbalau"], "abstract": "In subpopulation shift scenarios, a Curriculum Learning (CL) approach would only serve to imprint the model weights, early on, with the easily learnable spurious correlations featured. To the best of our knowledge, none of the current state-of-the-art subpopulation shift approaches employ any kind of curriculum. To overcome this, we design a CL approach aimed at initializing the model weights in an unbiased vantage point in the hypothesis space which sabotages easy convergence towards biased hypotheses during the final optimization based on the entirety of the available data. We hereby propose a Curriculum-enhanced Group Distributionally Robust Optimization (CeGDRO) approach, which prioritizes the hardest bias-confirming samples and the easiest bias-conflicting samples, leveraging GroupDRO to balance the initial discrepancy in terms of difficulty. We benchmark our proposed method against the most popular subpopulation shift datasets, showing an increase over the state-of-the-art results across all scenarios, up to 6.2% on Waterbirds.", "sections": [{"title": "Introduction", "content": "Curriculum learning [3, 14, 16] is a widely adopted strategy in deep learning, serving to improve model generalization capabilities and convergence time, by means of incrementally increasing training difficulty, starting from the easiest samples, and gradually moving to harder ones as the learning progresses. However, as noted by Wang et al. [16], not all circumstances benefit from a curriculum learning approach; at least, not in its standard easiest-first design. In a subpopulation shift scenario [17], the training data naturally presents itself with strong correlations between certain environments and certain classes. As an example, a model trained using the standard Empirical Risk Minimization (ERM) procedure on the Waterbirds [15] benchmark will associate water backgrounds with the waterbird class and land backgrounds with the landbird class. These spurious cues are easy to learn and convenient to use as biases to short-circuit decisions, leaving the model vulnerable at test time, when the subpopulation of waterbirds on land backgrounds increases. In such a scenario, a standard curriculum approach would only serve to prioritize the easy biased samples, serving the spurious features as the first thing to be imprinted upon the model weights, deepening test-time inadequacy.\nIn fact, the latest state-of-the-art methods [6, 10, 12, 18, 19] on environment discovery for distributionally robust optimization rely precisely and explicitly on the observation that the easiest samples to learn are the ones which confirm the class-environment biases the most. Liu et al. (JTT) [10] fit an ERM model on the training data and denote the samples classified correctly as bias-confirming, and the misclassified samples and bias-conflicting. Zare et al. (FEED) [19] remove the samples with the highest loss from the training pool after each epoch, in order to arrive at a subset containing only biased samples. We emphasize the pronounced simlilarity between FEED [19] and Self-Paced Curriculum Learning [7], and the fact that it leads to biasing the model to the highest degree possible.\nWe aim to overcome this limitation and bring the benefits of curriculum learning into the subpopulation shift scenery. We hereby propose a novel general Curriculum Learning design, meant to enhance Group Distributionally Robust Optimization (GroupDRO) [13] for subpopulation shift setups. In its original form, GroupDRO adjusts the training loss across a set of given or discovered environments in order to address the class-environment imbalances featured in the training dataset. We further enhance this procedure by designing a training curriculum aimed at presetting the model weights, before the final GroupDRO training procedure, in an unbiased vantage point within the hypothesis space which sabotages easy convergence towards biased hypotheses. To this end, we leverage discovered environments to prioritize the easiest bias-conflicting samples and the hardest bias-confirming samples in equal amount during the curriculum procedure, balancing the loss discrepancy by means of the GroupDRO update rule, thus initializing the model weights without bias or with a very slight opposite bias, and delaying the association between the strongly correlated classes and environments for as long as possible. Our curriculum is illustrated in Figure 2 for CelebA, where the bias consists in associating non-blonde hair with men and blonde hair with women. To the best of our knowledge, we are the first to propose a generic Curriculum Learning design for subpopulation shift setups. We evaluate our Curriculum-enhanced GroupDRO (CeGDRO) approach on the most popular benchmarks, achieving consistent improvements over the state-of-the art results, e.g. up to 6.2% on Waterbirds."}, {"title": "Background", "content": "In a subpopulation shift setup, the dataset features a set of spurious attributes A, i.e. \\(D = (X, Y, A)\\), and each data sample \\(x_i \\in X\\) has an associated spurious attribute \\(a_i \\in A\\). Discrete subpopulation groups \\(g \\in G\\) are formed based on some function \\(h : Y \\times A \\rightarrow G\\). We illustrate the sample distribution of Waterbirds [15] over the training and test groups in Figure 1, showcasing how the training dataset naturally emphasizes some groups more than others. In such a scenario, the average accuracy is not a good predictor of the real-world capabilities of the model, as it could just heavily rely on just predicting the spurious features. The end goal is thus to learn a set of weights which only accounts for the relevant features, yielding good performance across all environments by means of disregarding spurious features. Formally, given a loss function \\(L\\), the end goal, defined by Eq. (1), is to optimize \\(M^* : X \\rightarrow Y\\) to minimize the worst group loss for a given target probability distribution:\n\\(M^* = \\arg \\min_M \\max_{g \\in G} E_{p(x,y) \\sim p_g} L(y, M(x)).\\)\nAt test time, ground-truth groups are always used to evaluate the model. During training, current state-of-the-art approaches [1, 5, 10, 12, 19] follow a two step procedure: firstly, an environment discovery method is employed to determine spurious attributes, and secondly, a distributionally robust optimization procedure is used to balance out these environments. In the first, step env-discovery methods can either determine semantic groups [1, 8] or bias-confirming (easy) and bias-conflicting (hard) splits directly [6, 12, 18, 19]. The current two main options for the second step are Invariant Risk Minimization (IRM) [2] and GroupDRO [13]. In the case of the latter, at each training step, for a given group g and a sample (x, y), a group weight \\(q_g\\) is updated via the rule described in Eq. (2). After this update is performed, the group weight is balanced with respect to that of other groups, that is, \\(q_g \\leftarrow q_g / \\sum_{g'} q_{g'}\\). This serves to allocate high masses to high loss groups.\n\\(q_g \\leftarrow q_g \\cdot \\exp(\\eta L(y, M(x))), \\text{ where } \\eta \\text{ is a hyperparameter}.\\)\nFinally, these weights intervene to scale the gradient for samples in their corresponding group. In the context of our current proposal, we work to improve upon the GroupDRO post-environment discovery optimization protocol, proposed by Sagawa et al. [13]."}, {"title": "Method", "content": "Our Curriculum-enhanced GroupDRO method is formally described in Algorithm 1. Prior to our procedure, we separate the training data, based on G, in two main subsets: bias-confirming \\(D_B \\subset D\\) and bias-conflicting \\(D_C \\subset D\\), as described in Section 4. We then, at line 1, train an ERM model, \\(M'\\), featuring the same architecture as our final desired model, for a single epoch on the entire training set. The loss of \\(M'\\) with respect to \\(D_B\\) and \\(D_C\\) is used to sort out the samples from each subset. We store the sorted indices of samples from \\(D_C\\) in \\(J\\) at line 3, and the sorted indices of samples from \\(D_B\\), in reversed order, prioritizing the hardest ones, in \\(I\\) at line 2. At line 4, we initialize the percentage of available samples \\(P\\) with a hyperparameter \\(R\\), which controls the rate of increase for the percentage of available samples at each stage during the procedure. The number of samples available at a given stage of the curriculum is \\(N = [|D_C| * P)]\\), computed at line 6. We define the training subset \\(S\\) for the current stage, by selecting the first \\(N\\) samples from \\(D_B\\) and \\(D_C\\), in terms of the sorted indices from \\(I\\) and \\(J\\) respectively, at line 7.\nThis selection ensures that the features of what will become, in the last stage of training, the worst represented groups, are readily available at the beginning. It further ensures that it is as hard as possible for the network to associate the biased features with their respective classes. Though this selection is likely to slightly imprint the model weights with the opposite bias, by means of providing an equal number of bias-conflicting and bias-confirming samples at each training stage, and by leveraging GroupDRO to balance the initial discrepancy in terms of difficulty, we aim to skim this likelihood as much as possible. At each stage, we train the model \\(M\\) on the subset \\(S\\) for \\(E_S\\) epochs. We then increase \\(P\\) by \\(R\\) and continue the process while \\(P < 1\\). When \\(P = 1\\), the entirety of the bias-conflicting data is available for training, together with an equal amount of bias-confirming data. After the curriculum procedure reaches completion, we continue training the model for \\(E_f\\) epochs on the entirety of \\(D\\), while always ensuring that samples from \\(D_B\\) and \\(D_C\\) are sampled equally."}, {"title": "Experiments", "content": "Datasets and bias-confirming splits. We benchmark our method on the most popular subpopulation shift setups: Waterbirds [15], CelebA [11] and CivilComments [4]. The Waterbirds dataset features a waterbird and a landbird class strongly correlated in the training set with their respective water backgrounds and land backgrounds. In order to properly compare ourselves with the environment-aware IRM and GroupDRO approaches, as our method is not concerned with environment discovery, but rather with the post environment discovery optimization procedure, we use the ground-truth annotations and denote waterbirds on water backgrounds and landbirds on landbackgrounds as bias-confirming and the rest as bias-conflicting. CelebA features two classes, blond and non-blond hair, with the spurious attributes revolving around male and female features. For CelebA, \\(D_B\\) is\nExperimental setup. To ensure fair comparison and reproducibility, we follow the exact setup of Yang et al. [17]. A ResNet50 model pretrained on ImageNet is employed for image datasets and a pretrained BERT model for text datasets. For all benchmarks, we use a curriculum rate R of 0.2, and we iterate over the samples available at each stage \\(E_S = 8\\) times. We train the models for up to 30000 steps in all cases, except for the Waterbirds dataset, where 1300 steps is enough to ensure convergence. As with GroupDRO and IRM, our method is only concerned with post environment discovery optimization, thus, ground-truth environments are used in evaluating all methods presented in Table 1. We follow the exact procedure proposed by Yang et al. [17] with regards to optimizing hyperparameters; for each scenario, we perform 16 runs with different random seeds to determine the best hyperparameter configuration and then report the performance of the model across three runs using the best configuration. Worst group accuracy is used as a selection criteria across all instances.\nResults. We benchmark our method against the state-of-the-art post environment-discovery opti-mization protocols: IRM [2] and GroupDRO [13]. We showcase results in Table 1. We report, for each dataset, the average performance and standard deviation across three runs, measured both in terms of the domain-standard target optimization objective, the worst group accuracy, as defined in Eq. (1), as well as in terms of the average accuracy. In addition to the state-of-the-art results, we also provide as references, the performance levels of: (i) the standard Empirical Risk Minimiazation (ERM) approach, (ii) a Standard Curriculum learning approach, feeding the easiest samples first and gradually proceeding to harder data points, empowered by GroupDRO (GroupDRO + SC), and (iii) a modified version of CeGDRO for which we set the bias-confirming samples to follow an easy-first (CeGDRO - EF) line up. Our proposed Curriculum-enhanced GroupDRO (CeGDRO) approach outperforms the state-of-the-art methods across all scenarios. For example, CeGDRO surpasses GroupDRO by 6.2% on Waterbirds, 0.8% on CelebA, and 2.9% on CivilComments, while improving training stability, reducing the standard deviation of models across multiple runs on all benchmarks."}, {"title": "Conclusion", "content": "We propose Curriculum-enhanced GroupDRO (CeGDRO) as an optimization protocol for bias prevention in subpopulation shift setups. We redesign the curriculum approach for the task at hand, prioritizing the hardest bias-confirming samples and the easiest bias-conflicting samples first, initializing the model weights in an unbiased vantage point in the hypothesis space which sabotages easy convergence towards biased hypotheses during the final optimization stage. To the best of our knowledge, we are the first to adapt and propose a curriculum learning approach for this domain. We benchmark our approach against the most popular subpopulation shift data set, showing an improvement upon the state-of-the-art results across all benchmarks, while improving model stability. We aim to expand upon this work in the future, creating a context for a general bias-prevention curriculum, applicable to all general settings, regardless of the optimization protocol employed."}]}