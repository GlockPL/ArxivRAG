{"title": "A Data-Driven Framework for Discovering Fractional Differential Equations in Complex Systems", "authors": ["Xiangnan Yu", "Hao Xu", "Zhiping Mao", "HongGuang Sun", "Yong Zhang", "Dongxiao Zhang", "Yuntian Chen"], "abstract": "In complex physical systems, conventional differential equations often fall short in capturing non-local and memory effects, as they are limited to local dynamics and integer-order interactions. This study introduces a stepwise data-driven framework for discovering fractional differential equations (FDEs) directly from data. FDEs, known for their capacity to model non-local dynamics with fewer parameters than integer-order derivatives, can represent complex systems with long-range interactions. Our framework applies deep neural networks as surrogate models for denoising and reconstructing sparse and noisy observations while using Gaussian-Jacobi quadrature to handle the challenges posed by singularities in fractional derivatives. To optimize both the sparse coefficients and fractional order, we employ an alternating optimization approach that combines sparse regression with global optimization techniques. We validate the framework across various datasets, including synthetic anomalous diffusion data, experimental data on the creep behavior of frozen soils, and single-particle trajectories modeled by L\u00e9vy motion. Results demonstrate the framework's robustness in identifying the structure of FDEs across diverse noise levels and its capacity to capture integer-order dynamics, offering a flexible approach for modeling memory effects in complex systems.", "sections": [{"title": "1. Introduction", "content": "Differential equations, typically derived from fundamental physical principles, are important for modeling physical phenomena. However, progress in developing these differential models is often hindered by limited physical intuition and mathematical expertise. Advancing in data acquisition and storage capabilities have created new opportunities for deriving differential equations through data-driven methodologies [1]. The data-driven discovery approach aims to automatically extract the governing equations from data without prior knowledge.\nA pioneering method in this field is symbolic regression [2], which uses an evolutionary algorithm to find optimal combinations of coefficients and candidate analytical equations, balancing model simplicity with accuracy. Based on symbolic regression, Bongard and Lipson [3] introduced a technique to learn coupled nonlinear ordinary equations directly from time series, while Schmidt and Lipson [4] expanded this to derive conservation laws in dynamic systems from motion-tracking data. Sparse regression is another important framework for identifying structural forms of differential equations, Brunton et al. [5] proposed the SINDy framework, a sparse regression method for deriving the governing equation from noisy data, particularly, through dimensionality reduction for partial differential equation extraction. However, SINDy struggles with high-dimensional data, limiting its applicability, as many experiments collect observations in high-dimensional space (e.g., tracer concentration time-series at various locations in dispersive transport studies). Rudy et al. [6] extended SINDy to handle spatio-temporal synthetic data via STRidge, a sequential"}, {"title": "2. FDE discovery framework", "content": ""}, {"title": "2.1. Fractional differential equation", "content": "We consider a general form of a partial differential equation extended by incorporating fractional derivatives as follows:\n$\\kappa^{(\\alpha)} = F (u, u_t, u_x, u_{xx}, u_{tt}, ...),$ (1)\nwhere the subscripts t and x denote the derivative of function u with respect to time and space. The superscripts \"(\\alpha)\" and \"(\\beta)\" denote the fractional order of differentiation in time and space, F(\u00b7) is a linear operator to be found, formed by the linear combination of the coefficient vector & and the various derivatives of u.\nIn engineering fields, fractional calculus is commonly defined in two forms: the Riemann-Liouville (R-L) definition and the Caputo definition. The R-L derivative is expressed as\n$\\frac{d^{n}}{dx^{n}}$\n$RLD_x^{\\gamma}u(x) = \\frac{d^{n}}{dx^{n}}I^{n-\\gamma}u(x),$\n(2)\nand the Caputo derivative is given by\n$u^{(\\gamma)} = D^{\\gamma}u(t) = I^{m-\\gamma}\\frac{d^{m}u(t)}{dt^{m}},$ (3)\nwhere I denotes the y-th (arbitrary real number) order of fractional integrals,\n$I^{\\gamma}u(t) = \\frac{1}{\\Gamma(\\gamma)}\\int_{0}^{t} (t - \\tau)^{\\gamma-1}u(t)d\\tau,$ (4)\nand n represents the integer obtained by rounding up the value of a. For fractional derivatives with respect to time, the Caputo definition is commonly used because it provides reasonable initial conditions [38]. Conversely, space frac-tional derivatives are often defined by the R-L definition, given the common assumption of an infinite computational domain. There is a relationship between the two definitions:"}, {"title": "2.2. Sparse regression", "content": "Assuming that the function F (see Equation (1)) is composed of a linear multiplication of coefficients and candidate derivative terms, Equation (1) can be discretized as\n$u^{(\\alpha)} = \\Theta(\\beta) \\cdot \\xi,$\n(6)\nwhere denotes the candidate library, containing all possible (linear or nonlinear) terms including fractional order \u03b2 with respect to space, expressed as\n$\\Theta(\\beta) = \\begin{bmatrix} 1 & u(x_1, t_1) & u_x^{(\\beta)}(x_1, t_1) & ... \\\\ 1 & u(x_2, t_1) & u_x^{(\\beta)}(x_2, t_1) & ... \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ 1 & u(x_M, t_1) & u_x^{(\\beta)}(x_M, t_1) & ... \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ 1 & u(x_i, t_j) & u_x^{(\\beta)}(x_i, t_j) & ... \\\\ \\end{bmatrix},$ (7)\nand u() should be calculated prior to solving the learning problem, which involves evaluating the sparse coefficient vector \u00a7. The primary objective of this study is to determine a, \u03b2 and \u00a7 by solving the following regression problem:\n$(\\xi, \\tilde{\\alpha}, \\beta) = arg \\min_{(\\xi,\\alpha,\\beta)} (||u^{(\\alpha)} - \\Theta(\\beta) \\cdot \\xi|| + \\lambda||\\xi||_0),$ (8)\nwhere A denotes the regularization parameter, which is crucial for balancing parsimony and accuracy in the governing function."}, {"title": "2.3. Generating the library of candidate derivative terms", "content": "The elements in Equation (7) should be predefined, with integer-order derivatives conveniently computed us-ing automatic differentiation. While generating fractional derivative terms is complex. Calculating fractional-order derivatives requires function values from both local and nonlocal regions due to the inherent nonlocality in their definitions: as demonstrated in Equations (2) and (3), where the convolution integrals extend from the origin to distant regions. Moreover, data sparsity and noise complicate the calculation of derivative terms. To address these challenges, we employ deep neural networks (DNN) to simultaneously denoise and perform super-resolution reconstruction of sparse data fields. DNN serves as a surrogate model, with its capabilities of data interpolation and noise smoothing, making it well-suited for handling sparse and noisy data. Moreover, the automatic differentiation embedded in DNN can calculate the integer-order derivative component in fractional derivatives in high precision and robustness. The dataset is processed with a DNN as follows:\n$u(z) \\approx \\hat{u}(z) = y_n(y_{n-1}(...(y_2(z)))),$\n(9)\nwhere u(z) and \u00fb(z) denote the original dataset and reconstructed data, respectively, z = (x, y, z, t) is the coordinate vector in space and time, and\n$y_i(z) = \\sigma(w_iz + b_i), i = 1, 2, ...n,$\n(10)"}, {"title": "2.4. Stepwise optimization approach", "content": "According to Equation (8), the cost function comprised of the mean squared error (MSE) related to the sparse vector \u00a7, fractional orders a and \u03b2, and a regularization term, formulated as follows\n$L(\\alpha, \\beta, \\xi) = ||u^{(\\alpha)} - \\Theta(\\beta) \\cdot \\xi|| + \\lambda||\\xi||_0.$ (14)\nTo extract the structural form of integer-order differential equations, sparse regression algorithms such as STRidge [6] have proven effective and are integrated into various advanced PDE discovery frameworks [10, 48]. However, applying the sparse regression to discover FDEs poses challenges due to the nonlocal nature of fractional derivatives. The STRidge algorithm identifies a sparse coefficient vector \u00a7 that linearly multiplies prescribed derivative terms, but cannot estimate the fractional order, a continuously latent parameter [49] hidden within the candidate library rather than represented by sparse coefficients. [50] proposed a framework using two DNNs to capture physical dynamics, effectively avoiding issues with latent parameters. However, the resulting model is a black-box, lacking a closed-form governing equation. The black-box nature hinders researchers to further study the theoretical properties of governing equations."}, {"title": "3. Results", "content": "In this section, we validate the applicability of our method for identifying fractional differential equations directly from data, without requiring prior knowledge of the equation structure. We present a series of case studies, including synthetic data for the fractional advection-diffusion equation, experimental data on the creep process of frozen soils, and time-series data from single particle tracking that conforms to an a-stable distribution. Initially, we consider a straightforward case study involving experimental data that is described by a fractional ODE. The experimental data for this scenario is relatively straightforward to obtain."}, {"title": "3.1. Discovering the fractional Kelvin model from experimental data", "content": "We examine the uniaxial compression creep of frozen soil as a case study. This creep process is complex, influ-enced by mechanical properties that include multiphase components and various environmental conditions. Tradi-tionally, it has been modeled using ordinary differential equations (ODEs) to describe stress-strain relationships and incorporate the memory effects. Studies show that fractional constitutive models better capture the time-dependent behavior and memory effects in the creep process [43]. Here, we applied our method to derive the constitutive rela-tionship (expressed by ODEs) between stress and strain in frozen soil, using data from a coal mine in Huainan, China, measured by [51]. In [51], the fractional Kelvin model successfully characterized this constitutive relationship, expressed as\n$\\frac{d^{\\alpha}\\varepsilon}{dt^{\\alpha}} + \\frac{E}{\\eta} \\varepsilon = \\frac{\\sigma}{\\eta},$ (15)\nwhere & and o denote strain and stress, respectively, d\u00ba/dt represents the Caputo derivative of fractional order a (0 < a < 1), E is the elasticity modulus, and \u03b7 is the viscosity coefficient. Two types of frozen soil, clay and silt, were tested with sample sizes of 56 and 43, respectively. Note that the sampling interval is uneven, and the data contains natural noise. To generate candidate terms for integer- or fractional-order derivatives, data denoising and interpolation at specified positions were necessary. For both datasets, 15 samples were used as the training set, with the remainder for prediction. Using the trained DNN, 400 equidistant reconstructed data points for sparse regression and five auxiliary nodes for each reconstructed points (to compute fractional derivatives) were generated. As illustrated in Figure 3, the dataset was effectively denoised, and auxiliary points required for computing fractional derivatives were arbitrarily prescribed. Time evolutionary \u025b) involving fractional derivative is computed by G-J quadrature, and candidate library is generated via automatic differentiation as follows:\n$\\Theta = [1 \\varepsilon \\varepsilon_t \\varepsilon_{tt} \\frac{d^{\\alpha}\\varepsilon}{dt^{\\alpha}} \\sigma \\varepsilon \\sigma_t \\sigma_{tt} \\sigma \\frac{d^{\\alpha}\\varepsilon}{dt^{\\alpha}} \\varepsilon^2 \\varepsilon \\varepsilon_t \\varepsilon \\varepsilon_{tt} \\varepsilon_{tt}^2 ],$ (16)\nand the right-hand-side the of equation is \u025b\u00ba), whose parameter a is unknown and is optimized by Difference Evo-lution algorithm (DE), as in Table 1. The discovery results, detailed in Table 2, demonstrate that our algorithm successfully identified the fractional Kelvin model structure directly from experimental data, without prior knowledge of the structural form of the differential equations. The parameter estimation error for clay was lower than that for silt (see Table 2), likely due to (1) the sharper transition in the silt stress-strain curve, which provides less information for learning; (2) loss of accuracy in G-J quadrature due to insufficient quadrature points; (3) the cumulative error of stepwise optimization leads to the deviation of parameters. Improving the parameter optimization for FDEs discovery is a potential topic in the future work."}, {"title": "3.2. Discovering FADE from synthetic data", "content": "In this section, we assess the effectiveness of our method in identifying fractional partial differential equations, with the Fractional Advection-Diffusion Equation (FADE) chosen as the case study. FADE is a parsimonious model that captures anomalous solute diffusion in aquifers [32]. The mechanisms underlying FADEs vary depending on whether the fractional derivatives relate to time or space: FADEs with time fractional derivatives model delayed transport due to solute retention, while those with space fractional derivatives describe rapid solute displacement along preferential flow paths [52]. For generality, we examine FADE with both space and time fractional derivatives. To demonstrate the feasibility of our method in discovering FADE, synthetic data generated through numerical simulation of FADE is employed. The FADE and its initial and boundary conditions in this study are provided as follows:\n$ \\frac{\\partial c(x, t)}{\\partial t^\\alpha} = -v \\frac{\\partial c(x, t)}{\\partial x} + D \\frac{\\partial^\\beta c(x, t)}{\\partial x^\\beta},$\n$ c(x, 0) = 10e^{-[(x-6)/10]^2},$\n$ c(0, t) = c(30, t),$\n(17)\nwhere a = 0.8 and \u03b2 = 1.7 denote the time and space fractional orders, respectively. A closed-form analytical solution has not yet been found, so we use the fast Fourier transform (FFT) to obtain E&[(\u2212ivk + D(ik)\u03b2)t\u00ba], where k represents the variable in frequency domain, and Ea(.) denotes the single-parameter Mittag-Leffler function [38], expressed as\n$E_a(z) = \\sum_{n=0}^{\\infty} \\frac{z^n}{\\Gamma(an + 1)},$\n(18)\nwhere a denotes the shape parameter, which represents the fractional order here. An inverse fast Fourier transform (IFFT) is then employed to obtain high-precision semi-analytical solutions, which serve as synthetic data. The candi-date library constructed as\n$\\Theta(\\beta) = [ 1 c c_x c_{xx} c_{xxx} c^2 cc_x cc_{xx} cc_{xxx} c^2c_x c^2c_{xx} c^2c_{xxx}],$\n(19)\nand the right-hand-side of equation is temporal fractional derivative c\u00ba). Generally, the advection term of solute transport is usually characterized by spatial gradient of concentration, which is first-order derivative, so we assume"}, {"title": "3.3. Data-driven derivation of Stable Laws", "content": "The previous study has demonstrated success in data-driven discovery of diffusion equations from Brownian mo-tion [6]. According to the central limit theorem, random walks with probability density function (PDF) in jump sizes characterized by finite mean and variance (such as Brownian motion), converge to a Gaussian distribution. How-ever, in complex systems where the temporal-spatial distribution of random walker velocities exhibits a long-tail (i.e., power-law) property, this convergence does not hold. Under these conditions, particle trajectories cannot be accu-rately described by standard second-order diffusion equation. For example, L\u00e9vy motions, which are memoryless process characterized by finite mean displacement and divergent displacement variance, result in position densities that converges to the fractional diffusion equation based on the generalized central limit theory [53, 54]. Consider a random walk for L\u00e9vy motions\n$Y = X_1 + X_2 + ... + X_n,$\n(20)\nwhere the random variable Y represents the location after n jumps, and X denotes the independent and identically distributed (i.i.d.) jump lengths following an a-stable distribution p(X) = S(\u03b2, \u03c3, \u03bc) [55] with parameters 1 < a < 2,"}, {"title": "4. Discussion", "content": ""}, {"title": "4.1. Method comparison", "content": "To the best of our knowledge, our method is the first to directly extract FDEs from data without relying on any prior knowledge. To further prove the advancements of our method in discovering FDEs, we compare it with a representative PDE discovery framework, DL-PDE [10], which has shown robust performance in discovering many classical PDEs. The candidate library of DL-PDE is restricted to integer-order derivative terms, and it lacks an"}, {"title": "4.2. The effect of regularization", "content": "Our method employs lo-regularization with a regularization factor A (refer to Equation (14)) to achieve an effective balance between model parsimony and accuracy in the discovered equations. Particularly, the appropriate setting of A is crucial for accurately identifying the governing equations (especially in terms of their structure). To determine the suitable magnitudes of a within our framework, we perform a series of numerical experiments on the FADE model under three levels of noise (see also in Section 3.2). Four different magnitudes of regularization coefficients are considered: \u03bb = 10\u22125, \u03bb = 10\u22124, \u03bb = 10\u22123, and \u03bb = 10-2. The comparison results of discovered structures are shown in Table 6."}, {"title": "5. Conclusions", "content": "In this study, we present a stepwise framework for identifying fractional differential equations (FDEs) directly from data. We validate our approach by recovering commonly-used FDEs across three scenarios: experimental data of frozen soil creep behavior, synthetic data of solute transport in aquifers, and a single particle trajectory of L\u00e9vy motion. These case studies demonstrate that our algorithm effectively extracts practical FDEs, showing robustness across various levels of natural and artificial noise. The algorithm integrates both fractional-order and integer-order derivatives into the candidate library, broadening its scope of applicability. Moreover, memoryless dynamics can be captured by calibrating the fractional order to approximate integer values. To further validate the advancements of our framework in identifying FDEs, a comparative analysis with a representative existing method, DL-PDE, is conducted. Additionally, the applicable range of the regularization factor for different levels of data noise is analyzed. The results indicate that as noise intensity decreases, the range of suitable regularization values broadens. And \u03bb = 10-3 falls within the optimal range across different noise levels.\nThe current approach remains several limitations. Firstly, the proposed framework is relatively time-consuming, requiring multiple steps to optimize different parameter groups. Future work could focus on developing a more effi-cient algorithm to reduce the computational cost of the proposed framework. Secondly, although the method performs robustly in discovering the correct structure of FDEs, the accuracy of parameter estimation is limited likely due to the data quality and the optimization algorithm's capabilities. In some cases (e.g., contaminant transport in groundwater), sample availability is extremely limited due to challenging data acquisition in complex systems, and high noise in-tensity. Future work could focus enhancing the algorithm to effectively discover FDEs from highly sparse and noisy data. Finally, besides the FDEs in this study, there is a wide spectrum of parsimonious models aimed at capturing different mechanisms that play important roles in the dynamics of complex systems. Discovering these models could be a promising direction for future work. To achieve this goal, a large, closed library that encompassed all possible candidate terms for describing the dynamics of complex systems is required, which is unrealistic. Improving the flexibility of our algorithm by reducing the reliance on overcomplete candidate library offers promising solutions to this challenge, for example, adopting expandable libraries [57] or using open-formed algorithms [21]."}, {"title": "Appendix A. Gaussian-Jacobi quadrature", "content": "Due to their nonlocal and singular nature, approximating fractional derivatives presents numerical challenges. Nonlocality increases computational cost, particularly at large time or space scales, as it requires dividing the com-putation region into a fine unit grid. To address this issue, we employ Gaussian-Jacobi (G-J) quadrature, an effective method for integrands with endpoint singularities. G-J quadrature is a refined numerical integration technique that provides accurate approximations for integrals with power-law weight functions like (1 \u2212 x)^(1 + x)\u201c. The general quadrature formula is as follows\n$\\int_{-1}^{+1}f(x) \\rho^{\\mu,\\lambda}(x)dx = \\sum_{i=1}^{N} w_i f(\\xi_i),$ (A.1)\nwhere \u03c1(\u03bc,\u03bb) = (1 \u2212 x)^(1 + x)\u201c denotes the singular kernel function, and w\u00a1 represents weight factors determined by G-J rule, as referenced in [58], N denotes the prescribed number of quadrature nodes. The quadrature nodes, denoted by \u00a7, are associated with the weight factors wi, both of which can be determined using the Golub-Welsch algorithm or, alternatively, by directly using SciPy Python package, which includes this algorithm. The G-J rule efficiently computes the fractional integral of any smooth function. By substituting e(t) = (t \u2212 a)(1 + \u03c4)/2, Equation (4) can be rewritten as\n$I^{\\gamma}f(t) = \\frac{(t-a)}{\\Gamma(\\gamma)} \\int_{-1}^{1} (1 + \\tau)^{-1} f[e(t, \\tau)]d\\tau,$ (A.2)\nwhich can be regarded as the Gaussian-Jacobi quadrature (A.1) with \u00b5 = 0 and \u03bb = y \u2212 1. The fractional derivatives can then be obtained using Equations (2) and (3). The G-J rule's ability to handle singular integrals is a crucial advantage in solving fractional differential equations, enabling effective and accurate solutions. This approach allows us to embed the fractional derivative term into the candidate library, resulting in solving this system, we obtain approximate solutions that accurately capture the behavior of fractional differential equations, even in the presence of singularities.\n$\\frac{d^{4/5}t^{1/2}}{dr^{4/5}}$\nWe examine the example , using the Caputo definition of the fractional derivative. The exact solution is given by \u0393(1.5)t-0.3/\u0393(2.3), highlighting the singularity at the origin. We compare the numerical performance of the finite difference method (FDM) [59] and G-J quadrature. As shown in Figure A.6, the inherent singularity in fractional derivatives results in insufficient accuracy for FDM, and precision does not improve (see Table A.7) as the temporal grid At decreases from 0.1 (Fig. A.6a) to 0.01 (Fig. A.6b). Accuracy is particularly low near the origin. In contrast, the G-J quadrature method achieves a high precision with only five quadrature points, and performs well at the origin. Moreover, With higher accuracy, G-J quadrature is more efficient than the finite difference method (Table A.7). Thus, G-J quadrature outperforms FDM, especially in scenario where singularities exist."}, {"title": "Appendix B. Stable Law", "content": ""}, {"title": "Appendix B.1. Stable distribution", "content": "The probability density function of a stable distribution has no explicit formula; it is represented by its Fourier transform [60]\n$\\hat{p(k)} = exp \\left[-|k|^\\alpha \\sigma^\\alpha \\left(1 + i\\beta sign(k) tan(\\frac{\\pi \\alpha}{2}) \\right) - \\mu ik \\right],$ (B.1)\nwhere 0 < a < 2, \u03c3 > 0, \u22121 \u2264 \u03b2 \u2264 1, and u represent the shape, scale, skewness and drift respectively. Setting \u03c3 = (C|cos(\u03c0\u03b1/2)|)1/\u00ba and\u1e9e = p \u2212 q, where C is a positive parameter and p + q = 1, we obtain the equivalent form [54]\n$\\hat{p(k)} = exp[qC(-ik)^{\\alpha} + pC(ik)^{\\alpha} - \\mu ik].$ (B.2)\nParticularly, when \u03b2 = 1 (i.e., p = 1 and q = 0), \u03bc = v and C = Dt, the function in p(k) in (B.2) is equal to the function (21), which is the solution to the space fractional advection-diffusion (22) under the application of the Fourier transform."}, {"title": "Appendix B.2. L\u00e9vy motion", "content": "Now consider the Langevin equation for single particle motion\n$dX(t) = Vdt + BdL_{\\alpha}(t).$ (B.3)\nFollowing the detailed study by [61], when V = v, B = [D|cos(\u03c0\u03b1/2)|]1/& and dLq(t) = (dt)1/@S&(\u03b2 = 1, \u03c3 = 1,\u03bc = 0), the particle number density for Equation (B.3) satisfies the space-fractional advection-diffusion equation (22). By coarse-graining the Langevin equation (B.3) with At \u2248 dt, we obtain\n$X(t_{i+1}) = X(t_i) + V\\Delta t + B\\Delta t^{1/\\alpha} S_{\\alpha}(\\beta = 1, \\sigma = 1, \\mu = 0),$ (B.4)\nwhere At = ti+1 \u2013 ti and i = 1, 2, ..., n. According to the parameterization law by [62], X(t) follows\n$X(t_{i+1}) = X(t_i) + S_{\\alpha}(1, r, v \\Delta t + \\sigma \\beta tan(\\pi \\alpha / 2)),$ (B.5)\nwhere r = (AtD\\cos(\u03c0\u03b1/2)|)1/a. The recursion for the random variable X in Equation (B.5) represents the L\u00e9vy motion (20), which is equivalent to the space FADE (22). Thus, the L\u00e9vy motion (20) can be considered a coarse-grained representation of the Markov process (B.3), whose scale limit is the space FADE (22)."}]}