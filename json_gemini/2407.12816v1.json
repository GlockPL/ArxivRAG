{"title": "Quantum Algorithms for Weighted Constrained Sampling and Weighted Model Counting", "authors": ["Fabrizio Riguzzi"], "abstract": "We consider the problems of weighted constrained sampling and weighted model counting, where we are given a propositional formula and a weight for each world. The first problem consists of sampling worlds with a probability proportional to their weight given that the formula is satisfied. The latter is the problem of computing the sum of the weights of the models of the formula. Both have applications in many fields such as probabilistic reasoning, graphical models, statistical physics, statistics and hardware verification. In this article, we propose QWCS and QWMC, quantum algorithms for performing weighted constrained sampling and weighted model counting, respectively. Both are based on the quantum search/quantum model counting algorithms that are modified to take into account the weights. In the black box model of computation, where we can only query an oracle for evaluating the Boolean function given an assignment, QWCS requires $O(2^{n/2} + 1/\\sqrt{WMC})$ oracle calls, where where n is the number of Boolean variables and WMC is the normalized between 0 and 1 weighted model count of the formula, while a classical algorithm has a complexity of $\\Omega(1/WMC)$. QWMC takes $(\\Theta(2^{n/2}))$ oracle calss, while classically the best complexity is $(\\Theta(2^n))$, thus achieving a quadratic speedup.", "sections": [{"title": "Introduction", "content": "Given a Boolean formula and a functions assigning weights to assignments of values to the Boolean variable, we consider the problems of Weighted Constrained Sampling (WCS) and Weighted Model Counting (WMC). The first, also called distribution-aware sampling (Chakraborty et al, 2014), involves sampling assignments to the Boolean variables with a probability proportional to their weight given that the formula is satisfied. The latter (Sang et al, 2005) consists in computing the sum of the weights of the models of the formula, i.e. the weighted model count.\nWCS has important applications in a variety of domanis, including statistical physics (Jerrum and Sinclair, 1996), statistics (Madras and Piccioni, 1999), hardware verification (Naveh et al, 2006), and probabilistic reasoning, where it can be used to solve the problem of Most Probable Explanation (MPE) and Maximum A Posteriori (MAP). MPE (Sang et al, 2007) involves finding an assignment to all variables that satisfies a Boolean formula and has the maximum weight. The related MAP problem means finding an assignment of a subset of the variables such that the sum of the weights of the models of the formula that agree on the assignment is maximum.\nWMC was successfully applied, among others, to the problem of performing inference in graphical models (Chavira and Darwiche, 2008; Sang et al, 2005). In particular, other graphical model inference algorithms (Lauritzen and Spiegelhalter, 1988; Zhang and Poole, 1996; Dechter, 1999; Darwiche, 2001) take time $(\\Theta(n2w))$, where n is the number of variables and w is the treewidth (Bodlaender et al, 1993) of the network, a measure of the complexity of the network. WMC instead takes time $O(n2w)$, i.e., exponential in the treewidth in the worst case (Chavira and Darwiche, 2008). This is possible because WMC exploits the structure of graphical models in the form of context-specific independence and determinism.\nIn this paper we propose to use quantum computing for performing WCS and WMC. We call QWCS and QWMC the resulting algorithms. The first is based on quantum search using Grover's algorithm (Grover, 1996a,b, 1997). The latter on quantum model counting (Boyer et al, 1998; Brassard et al, 1998). We modified these algorithms to take into account weights. In particular, the proposed algorithms modify the algorithms for unweighted search and counting by replacing the Hadamard gates with rotation gates, with the rotations depending on the weights.\nQWCS and QWMC work under a black box computation model where we don't know anything about the propositional formula, we only have the possibility of querying an oracle giving the value of the formula for an assignment of the propositional variables. QWCS take $O(2^{n/2} + 1/\\sqrt{WMC})$ oracle calls to solve WCS with a probability of at least $ \\approx 0.707$, where WMC is the weighted model count normalized between 0 and 1 and n is the number of variables, while any classical algorithm takes $\\Omega(1/WMC)$ oracle calls.\nQWMC takes $(\\Theta(2^{n/2}))$ oracle calls, to bound the error to $2^{-n/2}$ with probability $\\approx \\frac{11}{12}$, while any classical algorithm takes $(\\Theta(2^n))$ oracle calls, thus achieving a quadratic speedup.\nExisting approaches for WMC (knowledge compilation (Darwiche and Marquis, 2002; Lagniez and Marquis, 2017; Huang et al, 2006), backtracking search (Bacchus"}, {"title": "Weighted Constrained Sampling and Weighted Model Counting", "content": "Let X be a vector of n Boolean variables $[X_1,..., X_n]$ and let x be an assignment of values to X, i.e., a vector of n Boolean values $[x_1,...,x_n]$. We call x a world, a configuration or an assignment. Consider a propositional logic formula $\\phi$ over X built from the standard propositional connectives $[\\, \\land, \\lor, \\rightarrow, \\leftrightarrow, \\oplus]$ (not, and, or, imply, iff, xor). If an assignment x of variables X makes formula $\\phi$ evaluate to true, we write $x \\models \\phi$ and we say that x satisfies $\\phi$ or that x is a model of $\\phi$. Let us call M the number of models. We can also see $\\phi$ as a function from $B^n$ to B, where B = {0,1}, and express that x makes $\\phi$ evaluate to true by $\\phi(x) = 1$.\nThe Satisfiability problem (SAT) is the problem of deciding whether a formula $\\phi$ has a model, i.e., whether M > 0. The Functional Satisfiability Problem (FSAT) is defined as: given a formula $\\phi$, return an assignment x that is a model of $\\phi$ or answer NO if no such assignment exists. The problem of Model Counting (#SAT) (Gomes et al, 2009) is the problem of computing M.\nThe problem of Constrained Sampling (CS) (Meel et al, 2016) consists of sampling configurations x with a uniform distribution given that $\\phi(x) = 1$. In other words, we"}, {"title": null, "content": "want to sample following this distribution\n$\\begin{aligned}\nP(x) = \\begin{cases}\n\\frac{1}{M} & \\text{if } \\phi(x) = 1 \\\\\n0 & \\text{if } \\phi(x) = 0\n\\end{cases}\n\\end{aligned}$\nIn some case we want to sample a configuration q of a subset Q of the variables X with a probability proportional to the number of models in which q can be extended. Supposing, without loss of generality, that Q is equal to the first $l$ bits, then we want to sample configurations q with probability\n$\\begin{aligned}\nP(q) = \\frac{\\sum_{y: qy \\models \\phi} 1}{M}\n\\end{aligned}$\nwhere $qy$ is a world where variables in Q take value q and variables in $Y = X \\backslash Q$ take value y and the sum is over all values y of Y such that $qy \\models \\phi$.\nIn this article we are concerned with weighted Boolean formulas which are pairs $(\\phi, W)$ where $\\phi$ is a Boolean formula over variables X and $W : B^n \\rightarrow R^{\\geq 0}$ is a weight function over the configurations of X, i.e., it assigns a weight $W(x)$ to a configuration x, that we abbreviate with $W_x$. Then the Weighted Model Count (WMC) is defined as the sum of the weights of all satisfying assignments:\n$\\begin{aligned}\nWMC(\\phi, W) = \\sum_{x: x \\models \\phi} W_x.\n\\end{aligned}$\nWhen $\\phi$ and W are clear from the context, we simply indicate $WMC(\\phi, W)$ with WMC. Weighted Model Counting (WMC) (Chavira and Darwiche, 2008) is the problem of computing WMC.\nWe restrict our analysis to factorized weight functions, i.e., weight functions expressible as product of weights over the literals built on X (Boolean variables or their negation). Seeing a configuration x as a set of literals (e.g. [0,1,0,1] = [$\\neg X_1, X_2, \\neg X_3, X_4$], we can compute the weights $W_x$ with a function $w : L \\rightarrow R^{\\geq 0}$, where L is the set of literals, such that\n$\\begin{aligned}\nW_x = \\prod_{l \\in x} w(l).\n\\end{aligned}$\nAn important special case is that in which $w(X_i) + w(\\neg X_i) = 1$, where the weights can be considered as the probabilities of the Boolean literals of being true and WMC is then the probability that $\\phi$ takes value 1 assuming that the Boolean variables are independent random variables.\nWeighted Constrained Sampling (WCS) or Distribution-Aware Sampling (Chakraborty et al, 2014) is the problem of sampling a configuration x with a"}, {"title": null, "content": "probability proportional to its weight given that the formula is satisfied, i.e.:\n$\\begin{aligned}\nP(x) =\\begin{cases}\n\\frac{W_x}{\\sum_{x:\\phi(x)=1} W_x} & \\text{if } \\phi(x) = 1 \\\\\n0 & \\text{if } \\phi(x) = 0\n\\end{cases}\n\\begin{cases}\n\\frac{W_x}{WMC} & \\text{if } \\phi(x) = 1 \\\\\n0 & \\text{if } \\phi(x) = 0\n\\end{cases}\n\\begin{cases}\n\\frac{W_x}{WMC} & \\text{if } \\phi(x) = 1 \\\\\n0 & \\text{if } \\phi(x) = 0\n\\end{cases}\n\\end{aligned}$  (1)\nIt is a special case of the problem of sampling a set of query variables Q with a probability proportional to the sum of the weights of the models in which q can be extended:\n$\\begin{aligned}\nP(q) = \\frac{\\sum_{y: \\phi(qy)=1} W_{qy}}{\\sum_{q,y: \\phi(qy)=1} W_{qy}} = \\frac{\\sum_{y: \\phi(qy)=1} W_{qy}}{WMC)}\n\\end{aligned}$ (2)\nWCS can play a role for the following problems. The Most Probable Explanation (MPE) (Sang et al, 2007) problem involves finding the model that has the maximum weight. The Maximum A Posteriori (MAP) problem means finding an assignment of a subset of the variables such that the sum of the weights of the models that agree on the assignment is maximum.\nGiven a formula $\\phi$ and a weight function $w : L \\rightarrow R^{\\geq 0}$, the most probable state (Most Probable Explanation, MPE) of the variables is\n$\\begin{aligned}\nMPE(\\phi, w) = \\underset{x: x \\models \\phi}{\\text{argmax}} W_x\n\\end{aligned}$\nLet $MPE^{\\text{w}}(\\phi, w)$ be the weight of $MPE(\\phi, w)$, i.e.,\n$\\begin{aligned}\nMPE^{\\text{w}}(\\phi, w) = \\underset{x: x \\models \\phi}{\\text{max}} W_x.\n\\end{aligned}$\nGiven formula $\\phi$, a weight function $w : L \\rightarrow R^{\\geq 0}$ and a set of query variables Q, the most probable state of the query variables (Maximum A Posteriori, MAP) is\n$\\begin{aligned}\nMAP_Q(\\phi, w) = \\underset{q}{\\text{argmax}} \\sum_{y: qy \\models \\phi} W_{qy}\n\\end{aligned}$\nLet $MAP^{\\text{w}}(\\phi, w)$ be the sum of the weights of the models that agree on the assignment $MAP_Q(\\phi, w)$:\n$\\begin{aligned}\nMAP^{\\text{w}}(\\phi, w) = \\underset{y: qy \\models \\phi}{\\text{max}} \\sum_{y: qy \\models \\phi} W_{qy}\n\\end{aligned}$\nClearly MPE is a special case of MAP when Q = X.\nExample 1. Let us consider an example inspired by the sprinkler problem of (Pearl, 1988): we have three Boolean variables, S, R, W representing propositions \u201cthe sprinkler was on\u201d, \u201cit rained last night\u201d and \u201cthe grass is wet\u201d, respectively. We know that: if the sprinkler was on, the grass is wet ($S \\rightarrow W$); if it rained last night, the grass is wet ($R \\rightarrow W$); and the sprinkler being on and rain last night cannot be true at the same time ($S \\land R \\rightarrow \\neg$). The formula for this problem is:\n$\\begin{aligned}\n\\phi = (\\neg S \\lor W) \\land (\\neg R \\lor W) \\land (\\neg S \\lor \\neg R).\n\\end{aligned}"}, {"title": "Quantum Search", "content": "CS can be seen as a search problem: find a satisfying assignment of bits. A quantum algorithm for solving this problem was proposed in (Grover, 1996a,b, 1997). Here we follow the exposition of (Nielsen and Chuang, 2010) and (Hirvensalo, 2013).\nWe assume we have a black box quantum circuit that evaluates $\\phi$, called an oracle O, that is such that\n$\\begin{aligned}\nO \\ket{x} = (-1)^{\\phi(x)} \\ket{x}\n\\end{aligned}$\ni.e., the oracle marks solutions to the search problems by changing the sign of the state. The oracle may use extra ancilla bits to do so."}, {"title": null, "content": "Lemma 1. The Grover operation applied to the uniform superposition state $\\ket{\\psi}$ rotates it by angle $2 \\arcsin \\sqrt{M/N}$ where M is the number of solutions of $\\phi(x) = 1$.\nProof. Consider the two states\n$\\begin{aligned}\n\\ket{\\alpha} = \\frac{1}{\\sqrt{N-M}} \\sum_{x:\\phi(x)=0} \\ket{x}\n\\end{aligned}"}, {"title": "Comparison of Quantum Search with Classical Algorithms", "content": "Let us discuss classical algorithms for solving FSAT under a black box model of computation (Nielsen and Chuang, 2010), where the only knowledge we have of the Boolean function $\\phi$ is the ability to evaluate it given an assignment of the Boolean variables, i.e., we have an oracle that answers queries over $\\phi$ of the form \"given assignment x, is $\\phi(x)$ equal to 1?\u201d\nConsider first the case that M = 1. A deterministic algorithm for finding the single configuration x of n bits such that f(x) = 1 under the black box model clearly requires N = $2^n$ evaluations of $\\phi$ in the worst case.\nLet us consider a probabilistic algorithm, i.e. an algorithm that returns the solution of the problem with probability p, with 0 < p < 1, and returns \"no answer\" with probability 1 \u2013 p.\nA classical probabilistic algorithm for solving the search problem with M = 1 is the following: take s samples of configurations of X with uniform probability. This can be performed by sampling each Boolean variable uniformly and combining the bit samples obtaining a configuration. Then, for each configurations, test whether it is a solution. If it is a solution, return it and stop. The probability of finding the single solution x is $\\frac{s}{N}$ so we need at least $\\frac{N}{p}$ queries to find x with a probability at least p.\nWe may think that using a sampling distribution different from uniform we may do better, but the following lemma proves that this is not true."}, {"title": "Quantum Weighted Constrained Sampling", "content": "Suppose first that the literal weights sum to 1, i.e., that $w(X_i) + w(\\neg X_i) = 1$ for all bits $X_i$.\nGiven a Boolean function $\\phi : B^n \\rightarrow B$, a weight function $w : L \\rightarrow [0,1]$ and set of variables Q, we want to sample values for the variables Q so that the probability of sampling configuration q is\n$\\begin{aligned}\nP(q) = \\frac{\\sum_{y: \\phi(qy)=1} W_{qy}}{WMC(\\phi, w)}\n\\end{aligned}$\nSuppose, without loss of generality, that the query bits Q come first and there are l of them, while there are and there are n-l bits in Y. Assume also that we add an extra bit $X_{n+1}$ So $X' = [X_1, ..., X_{n+1}]$, $x' = [x_1,...,x_{n+1}]$, $\\phi' = \\phi \\land X_{n+1}$. Let Y' be Y with the extra bit $X_{n+1}$, so overall Y' has n \u2212 1 + 1 bits.\nWe perform quantum WCS by modifying the algorithm for quantum search, obtaining QWCS. The circuit for performing QWCS differs from the one in Figure 2 because the Hadamard operations applied to the lower register are replaced by rotations $R_y(\\theta_i)$"}, {"title": "Comparison of QWCS with Classical Algorithms", "content": "For classical probabilistic algorithms under a black box model of computation we have the following results.\nTheorem 11. Any classical probabilistic algorithm for solving WCS under the black box model of computation takes $\\Omega(\\frac{1}{WMC})$ oracle queries."}, {"title": "Quantum Model Counting", "content": "We now present the QWMC algorithm. For the moment suppose that the literal weights sum to 1, i.e., that $w(X_i) + w(\\neg X_i) = 1$ for all bits $X_i$.\nWe can repeat the reasoning used for quantum counting: the application of the weighted Grover operator rotates $\\ket{\\phi}$ in the space spanned by $\\ket{\\gamma}$ and $\\ket{\\delta}$ by angle $\\theta$ and $e^{id}$ and $e^{i(2\\pi-d)}$ are the eigenvalues of WG. $\\theta$ can be found by quantum phase estimation."}, {"title": "Comparison of QWMC with Classical Algorithms", "content": "Let us now discuss the advantages of QWMC with respect to WMC under a black box model of computation.\nFor WMC, consider the following classical algorithm: take s assignment samples by sampling each bit according to its normalized weight. For each assignment sample, query the oracle obtaining value Fi with i = 1,...,s and estimate the WMC as for the unweighted case: $S = \\sum_{i=1}^s F_i$. Variable $\\frac{Ss}{N}$ is again binomially distributed with s the number of trials and probability of success WMC. In fact, the probability P(F1 = 1) is given by $P(F_1 = 1) = \\sum P(F_1 = 1,x) = \\sum_{x} P(F_1 = 1|x)P(x)$ where P(F = 1|x) is 1 if x is a model of $\\phi$ and 0 otherwise. So"}, {"title": "Discussion", "content": "The idea of using rotation gates to represent weights was first proposed in (Riguzzi, 2020) but the QWMC algorithm there contained an error: it used the regular Grover operator instead of the weighted Grover operator where H gates are replaced by Rot.\nThis article fixes this problem and proposes one more algorithm, QWCS, for solving the weighted constrained sampling problem. This algorithm exploits the same trick of using rotations to represent weights and basically combines weighted searching together with projection on the variables of interest.\nWe have shown that QWMC has a complexity of $(\\Theta(2^{\\frac{n}{2}}))$ evaluations of the Boolean formula, while QWCS solve its problem with a complexity of $O(2^{\\frac{n}{2}} + 1/\\sqrt{WMC})$, where WMC is the normalized weighted model count of the formula. We have also shown that if we consider the Boolean formula as a black box that we can only query asking for the value of the function given the inputs, QWMC provides a quadratic speedup over classical algorithms with the same limitation. The black box setting may be of interest when the Boolean formula is given by a quantum physical system of which we don't know the internals. In that case the quantum algorithms can plug in the system directly, improving over classical algorithms.\nIn the majority of cases where we want to perform WMC, WCS, we know the Boolean formula and, assuming the cost of implementing the circuit is linear in the number n of variables, the complexity will be worse than classical algorithms for WMC, QWCS unless the treewidth of the model is larger than n/2.\nHowever, QWMC can also be used as a subroutine in the junction tree algorithm (Shenoy and Shafer, 1990; Lauritzen and Spiegelhalter, 1988): after the probabilities are propagated in the tree, the nodes, whose maximum size minus 1 is the treewidth, have to be processed to find the marginals of the individual variables. In this QWMC can help with a complexity of $\\Theta(2^{\\frac{n}{2}})$ with n the number of variables in the node.\nIn general, the algorithms exploit quantum parallelism: all the models of the formula are superimposed in the quantum state of the system. Unfortunately, however,"}, {"title": "Conclusions", "content": "We have proposed quantum algorithms for performing WMC and WCS. The algorithms modify the quantum search and quantum counting algorithms by taking into account weights.\nUsing the black box model of computation, QWMC makes $\\Theta(\\sqrt{N})$ oracle calls to return a result whose errors is bounded by $2^{-\\frac{n}{2}}$ with probability $\\frac{11}{12}$. By contrast, the best classical algorithm requires $\\Omega(N)$ calls to the oracle. Thus QWMC offers a quadratic speedup that may be useful, for example, for computing marginals for the variables of a tree node in the junction tree algorithm.\nSimilarly, QWCS requires $O(2^{\\frac{n}{2}} + 1/\\sqrt{WMC})$ oracle queries, while classical probabilistic algorithms take $\\Omega(1/WMC)$ oracle queries under the black box model of computation, again providing a quadratic improvement.\nIn the future, we plan to investigate the influence of noise on the quality of the results."}, {"title": "A Introduction to Quantum Computing", "content": "Here we provide a brief introduction to quantum computing following (Nielsen and Chuang, 2010). The bit is at the basis of classical computing and has a single value, either 0 or 1. The quantum bit or qubit is a generalization of the bit and is at the basis of quantum computing. A qubit represents a state defined by a pair of complex numbers that can have various physical implementations. From a mathematical point of view, a qubit is a unit vector in the $C^2$ space, where C is the set of complex numbers, i.e.,\n$\\begin{aligned}\n \\begin{bmatrix}\n \\alpha \\\\\n \\beta\n \\end{bmatrix}\n\\end{aligned}$\nwhere the normalization requirement is that $|\\alpha|^2 + |\\beta|^2 = 1$.\nQubits are represented using the Dirac notation, where $\\ket{\\psi}$ (read \u201cket psi", "bra psi\") is a two dimensional complex conjugate row vector. The notation $\\langle \\psi|\\phi \\rangle$ (read \u201cbraket": "is the inner product of the $C^2$ space, i.e., it is the dot product between $\\ket{\\phi}$ and the complex conjugate $\\ket{\\psi}^*$. The special states $\\ket{0}$ and $\\ket{1}$ are called computational basis states and form the orthonormal basis\n$\\begin{aligned}\n\\ket{0} = \\begin{bmatrix}\n1 \\\\\n0\n \\end{bmatrix}\n\\ket{1} = \\begin{bmatrix}\n0 \\\\\n1\n \\end{bmatrix}\n\\end{aligned}$\nfor $C^2$. Any qubit state $\\ket{\\psi}$ can be expressed as a linear combination of the computational basis states:\n$\\begin{aligned}\n\\ket{\\psi} = \\alpha \\ket{0} + \\beta \\ket{1} = \\begin{bmatrix}\n \\alpha \\\\\n \\beta\n \\end{bmatrix}\n\\end{aligned}$\nIn this case we say that $\\ket{\\psi}$ is in a superposition of states $\\ket{0}$ and $\\ket{1}$. Note that computational basis state are orthonormal: $\\langle 0|1 \\rangle = \\langle 1|0 \\rangle = 0$"}, {"title": "Composite Systems", "content": "Whenever we have more than one qubit, we have a composite physical system (also called a quantum register) and the state space expands accordingly: for n qubits, their state is a unit vector in the $C^{2^n}$ space and there are $2^n$ computational basis states, e.g., if n = 2, the basis states are $\\ket{00}$, $\\ket{01}$, $\\ket{10}$ and $\\ket{11}$, and the state of the qubits can be written as\n$\\begin{aligned}\n\\ket{\\psi} = \\alpha_{00} \\ket{00} + \\alpha_{01} \\ket{01} + \\alpha_{10} \\ket{10} + \\alpha_{11} \\ket{11}\n\\end{aligned}$\nwhere $\\alpha_{00}, ..., \\alpha_{11}$ are complex numbers that form a unit length vector, i.e., such that $|\\alpha_{00}|^2 + |\\alpha_{01}|^2 + |\\alpha_{10}|^2 + |\\alpha_{11}|^2 = 1$. The state space of a composite physical system given the component physical systems can be obtained using the tensor product of the states of the components."}, {"title": null, "content": "The tensor product of two qubits\n$\\begin{aligned}\n\\ket{a} = a_0 \\ket{0} + a_1 \\ket{1} = \\begin{bmatrix}\n a_0 \\\\\n a_1\n \\end{bmatrix}\n\\end{aligned}\n$\\begin{aligned}\n\\ket{b} = b_0 \\ket{0} + b_1 \\ket{1} = \\begin{bmatrix}\n b_0 \\\\\n b_1\n \\end{bmatrix}\n\\end{aligned}\nis\n$\\begin{aligned}\n \\ket{a} \\otimes \\ket{b} = \\begin{bmatrix}\n a_0b_0 \\\\\n a_0b_1 \\\\\n a_1b_0 \\\\\n a_1b_1\n \\end{bmatrix} = a_0b_0 \\ket{00} + a_0b_1 \\ket{01} + a_1b_0 \\ket{10} + a_1b_1 \\ket{11}\n\\end{aligned}$\nThe tensor product $\\ket{a} \\otimes \\ket{b}$ is also written succinctly as $\\ket{a} \\ket{b}$ or also as $\\ket{ab}$, so for example $\\ket{0} \\ket{0} = \\ket{0} \\ket{0} = \\ket{00}$.\nThe Dirac notation is also useful for representing outer products $\\ket{a} \\bra{b}$:\n$\\begin{aligned}\n\\ket{a} \\bra{b} = \\begin{bmatrix}\n a_0 \\\\\n a_1\n \\end{bmatrix} \\begin{bmatrix}\n b_0^* & b_1^*\n \\end{bmatrix} = \\begin{bmatrix}\n a_0b_0^* & a_0b_1^* \\\\\n a_1b_0^* & a_1b_1^*\n \\end{bmatrix}\n\\end{aligned}"}, {"title": "Measurement", "content": "One of the operations that can be performed on a quantum system is measurement. There are various types of measurements, the simplest is measurement in the computational basis. When we have a qubit in the state $\\ket{\\psi} = \\alpha\\ket{0} + \\beta\\ket{1}$ and we measure it in the computational basis, we obtain a classical bit as a result: 0 with probability $|\\alpha|^2$ and 1 with probability $|\\beta|^2$. Since the states of qubits are unit vectors, then $|\\alpha|^2 + |\\beta|^2 = 1$ and the probabilities of the outcomes are well-defined. We can also measure multi-qubit systems and in that case we obtain a vector of classical bits."}, {"title": "Density Operators", "content": "A qubit in a superposition state encodes uncertainty on the result of its measurement. In this case, the state is known with certainty, it is only the result of measurement that is uncertain. Sometimes we want to represent uncertainty also on the state of the system. For example, we may know that the system is in one of several states $\\ket{\\Psi_i}$, where i is an index, with respective probabilities $p_i$. In this case we can represent the state of the system using a density operator $\\rho$ defined by the equation\n$\\begin{aligned}\n\\rho = \\sum_i p_i \\ket{\\Psi_i} \\bra{\\Psi_i}\n\\end{aligned}$\nso density operators are matrices. If the state $\\ket{\\psi}$ of a quantum system is known exactly, the system is said to be in a pure state and the density operator is simply $\\rho = \\ket{\\psi} \\bra{\\psi}$. Otherwise, the system is said to be in a mixed state and that it is in a mixture of different pure states in the ensemble ${(p_i, \\ket{\\Psi_i})}$ for $\\rho$."}, {"title": "Quantum Circuits", "content": "To present quantum algorithms, we use the quantum circuit model of computation, where each qubit corresponds to a wire and quantum gates are applied to sets of wires. Quantum gates are linear operators represented by matrices with complex elements that must be unitary. A matrix is unitary if $M^\\dagger M = I$, where $M^\\dagger$ is the adjoint or Hermitian conjugate of a matrix M, i.e., the complex conjugate transpose matrix $M^\\dagger = (M^*)^T$. We start from gates operating on single qubits that are described by matrices belonging to $C^{2\\times 2}$. For example, the quantum counterpart of the NOT Boolean gate for classical bits is the X gate, defined as\n$\\begin{aligned}\nX = \\begin{bmatrix}\n0 & 1 \\\\\n1 & 0\n \\end{bmatrix}\n\\end{aligned}$\nand drawn in circuits as in Figure 12a. Quantum gates can also be defined by the effect they have on an orthonormal basis. For example, applying the X gate to the computational basis produces:\n$\\begin{aligned}\nX \\ket{0} = \\begin{bmatrix}\n0 & 1 \\\\\n1 & 0\n \\end{bmatrix} \\begin{bmatrix}\n1 \\\\\n0\n \\end{bmatrix} = \\begin{bmatrix}\n0 \\\\\n1\n \\end{bmatrix} = \\ket{1}\n\\end{aligned}$\nand\n$\\begin{aligned}\nX \\ket{1} = \\begin{bmatrix}\n0 & 1 \\\\\n1 & 0\n \\end{bmatrix} \\begin{bmatrix}\n0 \\\\\n1\n \\end{bmatrix} = \\begin{bmatrix}\n1 \\\\\n0\n \\end{bmatrix} = \\ket{0}\n\\end{aligned}$\nso X exchanges $\\ket{0}$ and $\\ket{1}$, justifying its role as the quantum counterpart of the NOT Boolean gate.\nThe Z gate (see Figure 12b) is defined as\n$\\begin{aligned}\nZ = \\begin{bmatrix}\n1 & 0 \\\\\n0 & -1\n \\end{bmatrix}\n\\end{aligned}$\ni.e, it transforms $\\ket{0}$ to $Z \\ket{0} = \\ket{0}$ and $\\ket{1}$ to $Z \\ket{1} = -\\ket{1}$.\nThe Hadamard gate (see Figure 12c) is\n$\\begin{aligned}\nH = \\frac{1}{\\sqrt{2}} \\begin{bmatrix}\n1 & 1 \\\\\n1 & -1\n \\end{bmatrix}\n\\end{aligned}$\nand transforms $\\ket{0}$ to $H \\ket{0} = \\frac{1}{\\sqrt{2}} (\\ket{0} + \\ket{1})$ and $\\ket{1}$ to $H \\ket{1} = \\frac{1}{\\sqrt{2}} (\\ket{0} - \\ket{1})$.\nAnother useful gate is the parameterized $R_y$ rotation gate (see Figure 12d)\n$\\begin{aligned}\nR_y(\\theta) = \\begin{bmatrix}\n \\cos{\\frac{\\theta}{2}} & -\\sin{\\frac{\\theta}{2}} \\\\\n \\sin{\\frac{\\theta}{2}} & \\cos{\\frac{\\theta}{2}}\n \\end{bmatrix}\n\\end{aligned}"}]}