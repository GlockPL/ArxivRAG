{"title": "One-step Noisy Label Mitigation", "authors": ["Hao Li", "Jiayang Gu", "Jingkuan Song", "An Zhang", "Lianli Gao"], "abstract": "Mitigating the detrimental effects of noisy labels on the training process has become increasingly critical, as obtaining entirely clean or human-annotated samples for large-scale pre-training tasks is often impractical. Nonetheless, existing noise mitigation methods often encounter limitations in practical applications due to their task-specific design, model dependency, and significant computational overhead. In this work, we exploit the properties of high-dimensional orthogonality to identify a robust and effective boundary in cone space for separating clean and noisy samples. Building on this, we propose One-step Anti-Noise (OSA), a model-agnostic noisy label mitigation paradigm that employs an estimator model and a scoring function to assess the noise level of input pairs through just one-step inference, a cost-efficient process. We empirically demonstrate the superiority of OSA, highlighting its enhanced training robustness, improved task transferability, ease of deployment, and reduced computational costs across various benchmarks, models, and tasks. Our code is released at https://github.com/leolee99/OSA.", "sections": [{"title": "Introduction", "content": "Noise mitigation aims to handle the detriment of noisy labels encountered during the training process. The advancement of large-scale pre-training has significantly increased data scale to the trillion level. Much of this data is sourced from the internet, inevitably introducing considerable noise, which severely impedes the training process. This poses a substantial challenge for robust model training in various tasks, such as cross-modal matching [1, 2], image-classification [3, 4], and image-retrieval [5].\nTraditional noise mitigation approaches encounter several limitations that constrain their practical applicability: 1) Task specificity: Existing methods [1, 3, 6] are tailored to specific tasks, limiting their applicability across different tasks. 2) Model dependency: Most noise mitigation techniques [5, 7] are tightly coupled with specific models, requiring extensive modifications for adaptation to different models. 3) Computational cost: Numerous existing methods necessitate dual-model collaborations [1, 4] or multiple training passes [1], i.e., they require at least two backward passes per training step, effectively doubling the computational expense and substantially increasing the training burden (see Figure. 1a).\nTo tackle these challenges, we use an external estimator to assess the noise level of each sample, ensuring a model-agnostic approach. This estimator adjusts the training loss by reducing the influence"}, {"title": "Boundary Principle Analysis", "content": "In Figure. 1c-1f, we observe a natural boundary emerging in the pre-trained model's ability to distinguish between clean and noisy samples. In this section, we explain the principle of boundary forming from high-dimensional perspectives, and how robust it is in general noise mitigation."}, {"title": "Hypothesis: Interaction Boundary is Shifted from Orthogonal Boundary", "content": "We first elaborate on the gap extent between the positive and negative sides kept by the orthogonal boundary. Then, we present the reasoning behind the hypothesis that the intersection boundary in Figure. 1 is a shifted orthogonal boundary in the cone space."}, {"title": "The orthogonal boundary largely separates the positive and negative sides.", "content": "High-dimensional orthogonality is a general phenomenon caused by dimension disaster, where the angles between randomly selected vectors typically approximate 90 degrees, suggesting the cosine similarity that trends toward zero. For instance, in a 1024-dimensional space, the probability of two random vectors having a cosine similarity within [-0.1, 0.1] is approximately 99.86% (details are provided in Appendix. C.1). In this case, a natural boundary of cosine similarity zero forms, capably separating the positive side and negative side with a huge gap."}, {"title": "Cone effect may induce orthogonal boundary shift.", "content": "Recent literature [14-16] has demonstrated that the cone effect is a general phenomenon in deep neural networks, where the learned embedding subspace forms a narrow cone and the orthogonal boundary encounters a positive shift. Based on this, a hypothesis is that the interaction boundary in Figure. 1 is the shifted orthogonal boundary. To prove this, we simulate the process of selecting random vectors in high-dimensional space and randomly generate thousands of pairs mapped into the shared embedding space. We find that all similarity of these random vector pairs tends to a fixed value, with the low-variance cosine similarity almost lying in the middle of clean and noise distributions (see Table. 1). An interesting phenomenon is that if we compare the mean with the intersection points in Figure. 1c-1f, we find they are almost exactly the same. This suggests that the interaction boundary is highly likely to be a shifted orthogonal boundary in cone space."}, {"title": "Theoretical verification of the Interaction Boundary Origin", "content": "Here, we theoretically investigate whether the origin of the interaction boundary is a shifted orthogonal boundary. We first show that (i) contrastive learning separates clean and noisy samples on opposite sides of the orthogonal boundary and (ii) The relative relationships of pairs' cosine similarity stays unchanged after transmitting into the narrow cone space. Based on (i) and (ii), we can confirm that the intersection boundary at the center of the clean and noisy distributions is the shifted orthogonal boundary."}, {"title": "Contrastive learning empowers the separation of clean and noisy samples.", "content": "For an initialized model intending to learn an embedding space, both clean and noisy samples are treated as orthogonal"}, {"title": "Qualitative analysis of robustness and applicability", "content": "Next, we perform a qualitative analysis to explore (i) the robustness and generality of the boundary in distinguishing between clean and noisy samples, and (ii) how the boundary's properties can be leveraged to achieve more reasonable and precise overlap handling."}, {"title": "How about the boundary robustness even in unfamiliar domains?", "content": "Although the boundary's ability to distinguish clean and noisy samples is proven, its robustness and generality still require further exploration. For practical pre-training, it must maintain accuracy and robustness even in unfamiliar domain datasets. Since the capabilities of the pre-trained model are difficult to quantify, we conduct a qualitative analysis from the perspective of pre-trained model inference. The models pre-trained on millions of samples already possess somewhat semantic understanding capabilities. Given a positive pair from an unseen domain, due to the contrastive learning process during pre-training, it still has a strong likelihood of moving toward the positive side of the boundary, while the negative pair tends toward the negative side. Although the cosine similarity difference might be slight, as we have shown in Section. 2.1, the boundary constructs a significant gap from the perspective of high-dimensional orthogonality."}, {"title": "How to handle the overlaps through imbalanced probability?", "content": "Due to the properties of orthogonal boundary, as cosine similarity decreases and approaches zero from the positive side, the probability"}, {"title": "Method", "content": "In this section, we present our One-Step Anti-Noise (OSA) paradigm with a workflow shown in Figure. 2. We first define the pair-based noise mitigation tasks for image-text matching, image classification, and image retrieval tasks in Sec. 3.1. Consequently, the detailed description of OSA is clarified in Sec. 3.2."}, {"title": "Task Definition", "content": "Let $D = \\{(x_i, y_i, c_i)\\}_{i=1}^N$ denote a paired dataset, where $(x_i, y_i)$ represents the $i$-th pair in the dataset, and $c_i$ indicates a noise label for that pair. Specifically, when $c_i = 0$, $(x_i, y_i)$ forms a correct (paired) match, while $c_i = 1$ denotes an incorrect (unpaired) match. The objective of noise mitigation in contrastive learning is to construct a shared embedding space that brings $x_i$ and $y_i$ closer when $c_i = 1$. In different tasks, $x_i$ and $y_i$ are distinct data types. For instance, in the image-text retrieval task, $x_i$ and $y_i$ represent images and texts, respectively. In the image classification task, $x_i$ and $y_i$ represent images and categories, respectively. In the image retrieval task, $x_i$ and $y_i$ represent images and relevant images, respectively. The paired sample $(x, y)$ could be encoded into a shared embedding space by corresponding encoders $\\Phi_x(\\cdot)$ and $\\Phi_y(\\cdot)$. Afterward, the cosine similarity $s(x, y)$ is calculated through Eq. 3 as semantic relevance of $(x, y)$ to guide the training."}, {"title": "One-step Anti-Noise", "content": "The workflow of our noise mitigation approach OSA is depicted in Figure. 2. Initially, we utilize an estimator model to encode the input pair to a shared embedding space and continue to compute the cosine similarity between the paired embedding. Afterward, the cosine similarity is converted to a cleanliness score $w_i$, $(0 < w_i < 1)$ through a scoring function designed based on orthogonal properties (Section. 2.3). This score quantifies the clean degree of the sample, the smaller $w_i$ is, the noisier the sample.\nDuring the target model training phase, this cleanliness score is used as a weight, directly multiplied by the loss of the corresponding sample to facilitate selective learning. This noise mitigation process, being solely dependent on the estimator model, is readily adaptable to the training of various target models by simply adding an extra coefficient to the loss function, ensuring the model-agnostic property. Therefore, the key of our noise mitigation approach revolves around the estimator model and noise score assessment."}, {"title": "Estimator Model", "content": "Estimator model selection. In our approach, the Estimator Model must satisfy two critical requirements: 1) effectively mapping input pairs into a unified embedding space and 2) possessing basic semantic understanding capabilities. To meet these requirements, we employ CLIP [8], a commonly used multimodal pre-trained models, as our estimator model. It is equipped with a text encoder $\\phi_t(\\cdot)$ and an image encoder $\\phi_i(\\cdot)$, enabling it to perform basic zero-shot tasks efficiently."}, {"title": "Domain adaptation (Optional).", "content": "While we have performed a qualitative analysis of the zero-shot pre-trained model's robustness on out-of-domain data in Section. 2.3, and shown strong robustness for edge cases in Figure. 1, considering the domain diversity in real-world scenarios, we provide an optional Domain Adaptation (DA) approach to enhance the estimator model's adaptability when encountering edge domains. Following NPC [2], we first employ a Gaussian Mixture Model (GMM) coupled with strict selection thresholds to ensure the absolute cleanliness of the chosen samples."}, {"title": "Noise Score Assessment", "content": "Spatial Debiasing. The cone effect phenomenon has been demonstrated as a general phenomenon for deep neural networks, typically resulting in a narrow embedding space that causes a shift of space center to a narrow cone center [14]. Specifically, when paired randomly generated inputs are mapped into a shared embedding space through model encoders, the resultant vectors exhibit an average cosine similarity that deviates from zero and tends to another fixed angle. To counteract this shift and mitigate its impact on the estimator's ability to accurately recognize noises through high-dimensional orthogonality, a random sampling method is developed. We begin by constructing K random sample pairs $R = \\{(x_j, y_j) | j = 1, 2, ..., K\\}$ and processing them through the estimator's encoder to generate a set of vectors. Then the average cosine similarity among these vectors will be calculated as the space shift $\\beta$ through:"}, {"title": "Scoring Function.", "content": "After spatial debiasing, we employ a scoring function $w(\\cdot)$ to evaluate the cleanliness of the input pair $(x, y)$. In section. 2.3, we have elaborate how to handle overlaps based on the orthogonal boundary property. For an estimator model trained on millions of samples using contrastive learning, clean pairs (diagonal elements) are optimized to positive side, while noise pairs (non-diagonal elements) are optimized to negative side. Given unfamiliar pairs, the model also tends to map clean pairs towards positive and noisy pairs towards negative. Despite the potentially slight similarity difference between clean and noisy pairs, high-dimensional orthogonality ensures a substantial gap between them. In this case, a negative cosine similarity $s(x, y)$ computed by the estimator, indicating the pair is almost certainly noise, should be assigned a score of zero. For samples with $s(x, y)$ greater than zero, the probability of the sample being positive sharply decreases as the cosine similarity approaches zero from the positive side. Therefore, the function gradient should increase rapidly as the cosine similarity moves further from zero. To systematically score the noise, we design the scoring function as:"}, {"title": "Re-weight Training.", "content": "After scoring, the target model can selectively learn from the samples by re-weighting the loss. Noise samples with smaller weights will have a reduced impact on model updates and will be effectively mitigated. For a sample $(x, y)$, let $L_{x,y}$ denote its loss, the re-computed loss"}, {"title": "Experiments", "content": "In this section, we present experiments on multiple datasets with label noise, demonstrating the effectiveness of our methods. Firstly, we describe the datasets, metrics, and implementation details. Then, we report our results on several downstream tasks. Lastly, we conduct ablation studies to show how each part of our method contributes and examine how these parts interact. The literature involved in our experiments and richer related work are detailed in Appendix. B."}, {"title": "Evaluation Setting", "content": "In this section, we briefly introduce the datasets and evaluation metrics used in the experiments. For more dataset and implementation details, please refer to Appendix. A."}, {"title": "Datasets.", "content": "We evaluate our method on three downstream tasks with noisy labels, including one multimodal task and two visual tasks. For the cross-modal matching task, we perform experiments on the MSCOCO [12] and Flickr30K [17] datasets. Following NPC [2], we further carry out evaluations on a real-world noisy dataset CC120K. For image classification tasks, experiments are conducted under three subsets of WebFG-496 [3]\u2014Aircraft, Bird, and Car. For image retrieval tasks, we conduct experiments on the CARS98N dataset under PRISM [5] setting."}, {"title": "Evaluation Metrics.", "content": "For the image-text matching task, the recall value of the top-K retrieved results (R@K) is used. For classification tasks, accuracy serves as the evaluation metric. For the image retrieval task, we use Precision@1 and mAP@R for evaluation."}, {"title": "Comparisons with State of The Arts", "content": "Results on MSCOCO. To fairly demonstrate the effectiveness of our method, we compare OSA with various robust learning image-text matching approaches using the same ViT-B/32 CLIP as"}, {"title": "Results on Flickr30K.", "content": "To further demonstrate the generalization ability of OSA, we evaluate on the Flickr30K dataset and compare with several anti-noise methods, including NCR [1], DECL [9], BiCro [7], and NPC [2]. The results are presented in Table. 3 of Appendix. It is evident that OSA consistently outperforms all models on the R@1 metric. Notably, compared with the baseline CLIP, training with OSA at a 60% noise ratio achieves 20.9% R@1 improvement for i2t and a 22.3% R@1 improvement in t2i, further indicating the effectiveness of OSA on noise mitigation. Additionally, OSA demonstrates similar noise robustness on the Flickr30K dataset as observed on MSCOCO, with only 1.4% R@1 drop on i2t and 1.2% R@1 drop on t2i ranging from 0% noise to 60% noise, while all of the other anti-noise approaches hardly resist the detriment from high-ratio noise. All of these results demonstrate the effectiveness and robustness of OSA on anti-noise tasks."}, {"title": "Results on CC120K.", "content": "To further verify the reliability of OSA in real scenarios, we conduct evaluations on a large-scale real-world noisy dataset, CC120K, with 3%-20% noise ratio. The results shown in Table. 4 indicate that OSA outperforms the current state-of-the-art method NPC, even in larger-scale real-world domains. This demonstrates the feasibility and generality of OSA even in practical training scenarios."}, {"title": "Results on Other Downstream Tasks.", "content": "To validate the transferability of OSA across different tasks, we evaluate it on two additional tasks: image classification and image retrieval. The results are presented in Table. 5. The baseline method for both tasks leverages contrastive learning. In the image classification task, OSA outperforms the baseline by 7.74%, 8.21%, and 4.28% on the Aircraft, Bird, and Car subsets, respectively. In the image retrieval task, OSA improves performance by 6.76% in precision and 6.83% in mAP. These improvements demonstrate the strong task transferability and generality of OSA."}, {"title": "Target Model-Agnostic Analysis", "content": "OSA is an architecture-agnostic paradigm that can be easily adapted to various models. To verify its model-agnostic property, we evaluate it across models with different architectures. Subsequently, we apply it to other anti-noise models to demonstrate its generalization capability in noise mitigation."}, {"title": "Architecture-agnostic Analysis.", "content": "The effectiveness of OSA on Vision Transformer (ViT) has been proven in Section. 4.2. We further explore the generality of OSA on target models with other architectures. Specifically, we deploy OSA above the VSE++ [21] model with two different architecture types: ResNet-152 [22] and VGG-19 [23]. These two architectures have revealed significant sensitivity and vulnerability to noise [1]. In this experiment, all estimator models employ zero-shot CLIP and we utilize the original VSE++ as our baseline. The results in Table. 6 indicate a significant performance degradation emerged for the baseline methods in noisy setting, while a stable performance is achieved after employing OSA. The stable performance on these two noise-vulnerable architectures fully demonstrates that OSA possesses the architecture-agnostic property."}, {"title": "Adaptability to Other Anti-Noise Models.", "content": "Theoretically, OSA can be adapted to any target model, providing noise resistance. However, can OSA further enhance the robustness of models specifically designed for noise mitigation? To investigate this, we applied OSA to the current state-of-the-art model, NPC [2]. As shown in Table. 7 of Appendix, even for noise-mitigating models, OSA consistently improves training robustness. This finding further demonstrates the broad adaptability of OSA across different model types."}, {"title": "Estimator Model Analysis.", "content": "The estimator model is the basis of OSA's anti-noise capability. In this section, we explore the impact of different estimator models on noise mitigation, and examine the impact of domain adaptation in noise mitigation. In Table. 8 of Appendix, we investigate four types of estimators: \u201cNone\u201d refers to training CLIP directly without using OSA. \u201cCLIP (w/o DA)\u201d and \u201cALIGN (w/o DA)\" represent using CLIP and ALIGN without domain adaptation as estimators, respectively, i.e., zero-shot CLIP and ALIGN. \u201cCLIP (w DA)\u201d indicates the CLIP with domain adaptation. The target models are all CLIP."}, {"title": "Noise Assessment Accuracy", "content": "Noise Detection Accuracy Analysis. To figure out how accurate OSA is in recognizing noise, we evaluate the accuracy and recall on CLIP without Domain-Adaptation (w/o DA) and CLIP with Domain-Adaptation (w DA) on noisy MSCOCO. We utilize zero as the threshold to roughly divide pairs into noise and clean sets, respectively. Concretely, we classify scores less than or equal to 0 as noise, and scores greater than 0 as clean. The Accuracy means the proportion of the clean pairs correctly classified into the clean set, while the Recall indicates the noisy pairs correctly classified into the noisy set. The results presented in Table. 10 indicates the powerful noise recognizing capability of OSA. The remarkable performance on CLIP (w/o DA) fully demonstrates the generality of OSA. Another notable phenomenon is that all recall scores converge towards 100, indicating that OSA achieves greater accuracy in noise detection. This suggests that OSA can almost entirely eliminate the impact of noise on training."}, {"title": "Noise Re-weighting Accuracy Comparison.", "content": "Some anti-noise methods, like NPC, also employ loss re-weighting for optimization. To assess whether our method assigns relatively smaller weights to noise than these methods, we first analyze the weights generated by NPC and OSA. Due to differences in weight scales across methods, a direct comparison is unfair. Therefore, to unify the scale, we adopt a ranking-based approach, sorting weights in descending order and calculating the Mean Noise Rank. This metric evaluates whether smaller weights are consistently assigned to noisy samples relative to clean ones. Our experiments use 2,000 randomly selected samples from the MSCOCO dataset under two noise conditions: 20% noise (370 noisy samples) and 50% noise (953 noisy samples). The theoretical optimal Mean Noise Ranks, where all noisy weights are ranked last, are 1815.5 and 1524.0, respectively. Results presented in Table. 9 of Appendix show that OSA achieves a higher Mean Noise Rank compared to NPC, demonstrating greater accuracy in re-weighting. Moreover, OSA's rankings are nearly optimal (20% noise: 1809.1 for OSA versus 1815.5 optimal; 50% noise:"}, {"title": "Computational Cost Analysis", "content": "Cost in Pre-training. To evaluate the practicality of OSA in a real-world pre-training scenario, we estimate the additional computational cost for processing 1 billion data points. Using an NVIDIA RTX 3090 with an inference batch size of 4096, utilizing approximately 24 GB of GPU memory, processing the MS-COCO dataset consisting of 566,435 pairs takes approximately 153 seconds. At this inference rate, processing 1 billion data points would require approximately 75 hours on a single RTX 3090. This cost is negligible within the context of large-scale pre-training, especially when leveraging multiple GPUs for parallel inference."}, {"title": "Time Cost Comparison.", "content": "To further examine the computational efficiency of OSA compared to other anti-noise techniques, we evaluate training time against two representative approaches: CLIP and NPC. CLIP, which serves as the baseline, is trained directly without any additional technique. NPC, the current state-of-the-art, also uses CLIP as its backbone but applies an anti-noise technique by estimating the negative impact of each sample, necessitating double backward passes. The training time comparison, presented in Table. 11, shows that our method introduces only a minimal increase in training time compared to direct training, requiring just one-tenth of the additional time needed by NPC. This highlights the efficiency of OSA, making it well-suited for large-scale robust training."}, {"title": "Conclusion", "content": "Broader Impacts. In this work, we investigated the possibility of anti-noise in practical large-scale training. We introduced a novel model-agnostic anti-noise paradigm with advantages such as task transferability, model adaptability, and low computational overhead. By leveraging the properties of high-dimensional spaces, we found a robust and effective boundary for distinguishing between noisy and clean samples. Through rigorous theoretical analysis and comprehensive experimentation, we validated the efficacy and robustness of OSA for general noise mitigation. Although our primary objective is to adapt to practical large-scale training, OSA also achieves SOTA performance in standard anti-noise settings. To the best of our knowledge, this is the first work to explore anti-noise in practical large-scale training scenarios, as well as the first to propose a general anti-noise approach."}, {"title": "Limitations and Future Works.", "content": "Limited by the significant computational cost of pre-training, it is difficult for us to evaluate in a real pre-training process. Instead, we simulate large-scale pre-training processes to the greatest extent possible, such as evaluating on the real-world noisy dataset CC120K, which shares similar domains with mainstream pre-training datasets like CC4M and CC12M. Exploring the broad domain adaptability of OSA in real pre-training scenarios will be a valuable direction for future work."}, {"title": "Details of Implementation and Datasets", "content": "Dataset Details. MSCOCO is widely used for noisy cross-modal matching, with each image accompanied by five descriptive captions. Following the setting of [1], we utilize 113,287 images for training, 5,000 for validation, and 5,000 for testing. The Flickr30K dataset encompasses 31,783 image-text instances, each image paired with five textual annotations. Adhering to the NCR [1], we use 29,783 images for training and 1,000 images each for validation and testing. Regarding noise splits, following the NCR categorization, we conduct experiments at noise ratios of 0%, 20%, 40%, and 60%. CC120K is a real-world multimodal noisy dataset collected by [2] from the Internet, with about 3%-20% noise ratio. There are 118,851 image-text pairs for training, 1,000 for validation, and 1,000 for testing.\nThe Aircraft, Bird, and Car we used in the image classification task are three non-overlapping subsets of the WebFG-496 [3] dataset. WebFG-496 consists of 53,339 images, totaling 496 subcategories. This dataset is annotated using a webly supervised approach, which leverages resources from web search engines (e.g., Google Image Search Engine, Bing Image Search Engine) to expand the annotated image dataset.\nFor the image retrieval task, we conduct experiments on the CARS98N dataset under PRISM's setting [5]. We utilize 9,558 car-related images sourced from text-based searches on Pinterest as the training set, and employ the remaining 98 categories from CARS, unsearched on Pinterest, as a clean test set. The dataset's noise is inherently real-world, with its creators estimating a noise ratio of approximately 50%."}, {"title": "Implementation Details.", "content": "To demonstrate the effectiveness of the OSA, we incorporate an estimator, built around the core of CLIP, and re-weighting operations based on the Estimator's outcomes into numerous downstream tasks. In the principal task of cross-modal image-text retrieval, we employ CLIP with ViT-B/32 as the baseline and target model by default. All experiments are conducted on a single RTX 3090 GPU using the AdamW optimizer. During both training phases, the model is trained for five epochs with a batch size of 256 and 500 warmup steps.\nFor the image classification task on the WebFG dataset, we align with the field's prevalent models for a fair comparison by employing the ResNet-50 model enhanced by CLIP for feature extraction and the CLIP image encoder as our estimator. Training and testing are executed on single RTX 3090 GPU, with an input image resolution of 448 \u00d7 448. The batch size and initial learning rate are specified as 64 and 1e-5, respectively. In the first phase, the estimator is trained with data modeled by a Gaussian Mixture Model (GMM), which considers the classification and matching losses of all training samples, with the GMM probability threshold of 0.95. The classification task leverages the CLIP protocol, where a fixed prompt (\u201cThis is a picture of\u201d) is prepended to category texts.\nFor the image retrieval task, we use CLIP ViT-B/32 as the baseline, with a batch size set to 128, an initial learning rate of 5e-6, and the number of epochs set to 10. Following the setup of the PRISM [5], we set the parameter for sampling positive examples by the random sampler of the dataloader to 4, and adjust the number of positive examples sampled per epoch to one-fourth of the original parameter according to the increase in batch size. In this task, we also adopt a two-stage training approach. The strictly clean in-domain training data for the first stage is obtained using a GMM model with a probability setting of 0.8."}, {"title": "Related work", "content": "Noise Mitigation in Cross-Modal Matching\nThe cross-modal matching task [24-28] serves as a fundamental component in multimodal learn- ing. However, the inherent difference in information density between these modalities leads to high annotation costs and inconsistent annotation quality, rendering cross-modal tasks particularly vulnerable to label noise. Some approaches explicitly identify and correct noisy samples through cross-prediction between concurrently trained dual models [1, 7, 29], while others [2, 9] implicitly estimate the probability of sample noise, reducing its training impact by adjusting the loss function."}, {"title": "Noise Mitigation in Image Classification", "content": "Image classification is vulnerable to training data noise, due to varied noise types and strong model memorization. Noise in datasets manifests in two primary forms: synthetic alterations and those arising from real-world scenarios. The former typically involves shuffling the labels of a subset of the data or retaining the labels while introducing corresponding category images from external datasets. The latter entails substituting images for a random selection of data points with those sourced from image search engines. Existing approaches are categorized based on their operational focus: loss correction [30-40] and sample selection [41-43, 10, 44]. Loss correction methods typically incorporate a regularization term into the loss function, implicitly reweighting clean and noisy samples within the loss. Sample selection strategies, in contrast, explicitly differentiate between clean and noisy samples, applying distinct processing to each category during loss computation. Representative for the loss correction category, [31] aims to generalize ordinary Cross-Entropy loss and MAE loss by setting the loss threshold to iid and ood noisy samples. DivideMix [10] concurrently trains two networks, each utilizing the data partitioning from the other network to distinguish between clean and noisy samples based on loss values, thereby mitigating the influence of confirmation bias inherent within each network. PNP [41] framework employs a unified predictive network to estimate the in-distribution (iid), out-of-distribution (ood), and clean probabilities for a given sample. Co-training trained on a sample that has a lower loss, and with the different predictions by its siamese network."}, {"title": "Noise Mitigation in Image Retrieval.", "content": "Although image retrieval tasks focus on pairwise relationships, the noise predominantly originates from image categorization errors. Analogous to image classification tasks, this can be bifurcated into in-domain [45] and open-set noise [5]. In terms of task configuration, noise retrieval typically operates at the category level, treating images within the same category as positive instances. PRISM [5] tries to find noisy image samples by finding the outliers score in the whole similarity matrix from the same category. The generalization ability of the image feature is ensured by a broader query bank restored multi-view of it. TITAN [46] utilizes prototypes to be representative of the anchor of the clean and noisy samples and then generates synthetic samples by a combination of prototypes for substitution of noisy samples. T-SINT [47] utilizes more negative samples by the interaction between noisy samples and negative samples that belong to another category."}, {"title": "Proofs", "content": "Proof of High-dimensional Orthogonality\nSuppose $u, v \\in R^d$ are any two random vectors. The cosine similarity $\\cos(u, v) \\sim N(0, d^{-1})$. The probability that $\\cos(u, v)$ is within a specific range $[-a, a]$ is denoted as:\n$P(-a \\le \\cos(u, v) \\le \\alpha) = \\Phi\\left(\\frac{a}{\\varsigma}\\right) - \\Phi\\left(\\frac{-a}{\\varsigma}\\right)$                                                                                                                                                                                (7)\nwhere $\\Phi$ represents the CDF of the standard normal distribution, and $\\varsigma = \\frac{1}{\\sqrt{d}}$ is the standard deviation of the cosine similarity. When $d = 1024$ and $a = 0.1$, there are\n$\\varsigma = \\frac{1}{\\sqrt{1024}} = \\frac{1}{32}$,(8)"}, {"title": "Proof of Theorem 1", "content": "In the Section. 2.2, we propose that Theorem 1 about the relative relationship of pairs in the original entire space, will not change after transmitting to the narrow cone space of the trained model, and there is always a boundary r concentrated on most random vectors.\nTo prove this Theorem, we first introduce a useful lemma of monotonicity of cosine similarity proposed by [14", "d_{out}": "l \\in [d_{in}"}, {"d_{out}": "."}]}