{"title": "MOOSE-CHEM: LARGE LANGUAGE MODELS FOR REDISCOVERING UNSEEN CHEMISTRY SCIENTIFIC HYPOTHESES", "authors": ["Zonglin Yang", "Wanhao Liu", "Ben Gao", "Tong Xie", "Yuqiang Li", "Wanli Ouyang", "Soujanya Poria", "Erik Cambria", "Dongzhan Zhou"], "abstract": "Scientific discovery contributes largely to human society's prosperity, and recent progress shows that LLMs could potentially catalyze this process. However, it is still unclear whether LLMs can discover novel and valid hypotheses in chem- istry. In this work, we investigate this central research question: Can LLMs au- tomatically discover novel and valid chemistry research hypotheses given only a chemistry research background (consisting of a research question and/or a back- ground survey), without limitation on the domain of the research question? Af- ter extensive discussions with chemistry experts, we propose an assumption that a majority of chemistry hypotheses can be resulted from a research background and several inspirations. With this key insight, we break the central question into three smaller fundamental questions. In brief, they are: (1) given a background question, whether LLMs can retrieve good inspirations; (2) with background and inspirations, whether LLMs can lead to hypothesis; and (3) whether LLMs can identify good hypotheses to rank them higher. To investigate these questions, we construct a benchmark consisting of 51 chemistry papers published in Nature, Sci- ence, or a similar level in 2024 (all papers are only available online since 2024). Every paper is divided by chemistry PhD students into three components: back- ground, inspirations, and hypothesis. The goal is to rediscover the hypothesis, given only the background and a large randomly selected chemistry literature cor- pus consisting the ground truth inspiration papers, with LLMs trained with data up to 2023. We also develop an LLM-based multi-agent framework \u00b9 that leverages the assumption, consisting of three stages reflecting the three smaller questions. The proposed method can rediscover many hypotheses with very high similarity with the ground truth ones, covering the main innovations.", "sections": [{"title": "1 INTRODUCTION", "content": "Discovering new science has long been one of the deepest desires of humanity, which can not only satisfy our curiosity to understand the universe, but also contribute largely to the prosperity of human society (Coccia, 2019). Recently, there are some breakthroughs indicating that LLMs have the potential to assist scientists in accelerating the discovery process.\nYang et al. (2024b) first find that LLMs can generate novel and valid enough hypotheses evaluated by experts. They focus on the social science domain and make discoveries by developing a multi-agent system, leveraging an assumption that a majority of social science hypotheses can be divided into a research background concept and an inspiration concept. This assumption is largely valid, because social science hypothesis is about how an independent variable can influence another dependent variable (Hair et al., 2007). Si et al. (2024) further validate this finding by employing a large group"}, {"title": "2 RELATED WORK", "content": "Zhong et al. (2023) work on finding the difference between two corpora to propose hypotheses, but their evaluation is based on selecting hypotheses that do not require expert knowledge for Turkers to judge, thus cannot lead to a novel discovery. Wang et al. (2024) try to utilize LLMs to discover novel"}, {"title": "3 BENCHMARK CONSTRUCTION", "content": "The goal of the benchmark is two-fold. Firstly, it is used to analyze LLM's ability in terms of the three smaller questions. Secondly, it serves as a challenge to rediscover nature-level chemistry hy- potheses with only a research background. The setting of the challenge is very similar to a real copilot setting, where scientists tell the copilot about the specific research question they are inter- ested in, and optionally a small survey consisting of several paragraphs summarizing the existing best-performing methods for the research question.\nTo achieve the goals, we split each collected paper into the following components: <background question, background question (strict), background survey, background survey (strict), one to three inspiration paper titles and their reason to serve as an inspiration, research hypothesis, experiments, reasoning process, summarization of inspirations>. Every component is described by text.\nThe reason we add a strict version for background question and background survey is that many hypotheses are making relatively minor modifications based on existing methods covered by the survey, and the question can be very insightful to provide a hint on the general direction of the hypothesis. In practice, these situations are entirely possible, especially when the scientist users can provide a more comprehensive survey on existing methods, or contain deep insights in their question. Here we also keep the strict version to make the task more challenging, and encourage developing methods to better assist scientists even when they are also new to their research topic.\nThe reasoning process indicates the relation between the components of background, inspirations, and hypothesis. For example, the reasoning process can be \u201cbackground + inspiration 1 + inspiration 2 = hypothesis\", or \"background + inspiration 1/inspiration 2 + inspiration 3 = hypothesis\".\nThe benchmark consists of 51 chemistry and material science papers, and is constructed by multiple chemistry PhD students. We only select those papers published on top chemistry venues and be public on the internet after January 2024. After constructing, the experts check again on (1) whether the identification of the inspirations is correct and whether more inspirations are needed; (2) whether the background does not contain any information in inspirations or hypothesis; and (3) whether the background and the identified inspirations can roughly logically lead to the hypothesis. The complete instruction on the check process is shown in \u00a7 A.2.\""}, {"title": "4 METHODOLOGY", "content": "We propose an assumption that a majority of chemistry hypotheses can originate from a research background and several inspirations. This assumption is not only supported by many chemistry researchers whom we have extensive discussions with but also by the cognitive science finding that", "subsections": [{"title": "4.1 FUNDAMENTAL ASSUMPTION AND FOLLOWING DECOMPOSITION", "content": "We propose an assumption that a majority of chemistry hypotheses can originate from a research background and several inspirations. This assumption is not only supported by many chemistry researchers whom we have extensive discussions with but also by the cognitive science finding that"}]}, {"title": "4.2 THE FRAMEWORK DEVELOPED BASED ON THE ASSUMPTION", "content": "Our methodology is developed based on the fundamental assumption discussed in \u00a7 4.1. Specif- ically, we use LLMs to perform $P(i_j|b, h_{j-1}, I)$, $P(h_j|b, i_j, h_{j-1})$, and $R(h)$, and organize them into a multi-agent LLM-based framework. The input to the framework is only a background question and/or background survey, together with a (large) chemistry literature corpus to search for inspira- tion. The output of the framework is a list of ranked research hypothesis.", "subsections": [{"title": "4.2.1 THE GENERAL PICTURE", "content": "Our methodology is developed based on the fundamental assumption discussed in \u00a7 4.1. Specif- ically, we use LLMs to perform $P(i_j|b, h_{j-1}, I)$, $P(h_j|b, i_j, h_{j-1})$, and $R(h)$, and organize them into a multi-agent LLM-based framework. The input to the framework is only a background question and/or background survey, together with a (large) chemistry literature corpus to search for inspira- tion. The output of the framework is a list of ranked research hypothesis.\nThe MOOSE-Chem framework is shown in Figure 1. It is a direct implementation of Equation 3 and 4. We try to develop it as simply as possible, only keeping the necessary parts.\nIn the general picture, given a research background b (research question and/or research survey), the framework first performs $P(i_1|b, h_0 = \\emptyset, I)$ by screening through the literature corpus I to select many papers i, where each of them has the potential to serve as an inspiration. Then the framework performs $P(h_1|b, i_1, h_0 = \\emptyset)$, associating b and each i together to compose h. Then, it ranks h by assigning an evaluation scorer on each of $h_1$ by $R(h_1)$. We call these three steps as one round. Another round means going through the three steps again, based on the previous round's results.\nSince normally in chemistry, no more than three inspirations are needed for one hypothesis (k \u2208 [1,3]), the default setting for MOOSE-Chem is to perform three rounds for each b. In every other round, the number of i and h can expand exponentially. Here, we adopt beam search to select a fixed size of the top-ranked h to enter the next round. The default beam size is 15."}, {"title": "4.2.2 DESIGN DETAILS OF $P(i_j|b, h_{j-1}, I)$ AND ITS MOTIVATION", "content": "We use LLMs to conduct a screening process for $P(i_j|b, h_{j-1}, I)$. Specifically, for each inference,\nwe (1) sequentially select a fixed number of papers from I, where the fixed number is called the\nscreening window size (default is 15); (2) set up a prompt consisting of b, the title and abstract of\nthe selected papers from I, and the previous h (if it is not \u00d8); and (3) instruct the LLM to generate\nthree titles from the input that can best serve as i for b (and optionally previous h), and give reasons."}, {"title": "4.2.3 DESIGN DETAILS OF $P(h_j|b, i_j, h_{j-1})$ AND ITS MOTIVATION", "content": "The retrieved i is expected to be not known to be related to b; therefore, it might be difficult to figure out an effective way to associate b and i together to compose h. Think of the time when backprop- agation is about to be invented. Even if we are very familiar with b (multi-layer logistic regression) and have successfully retrieved i (chain rule in mathematics), can we invent backpropagation?\nOur answer is, at least we might need to try multiple times and various ways to leverage the chain rule for multi-layer logistic regression. With this motivation, we develop a simple Evolutionary Algorithm (EA) based method, shown in Figure 1.\nSpecifically, given b and i, the framework will try multiple hypothesis \u201cmutations\" m, where each m is a unique way to associate b and i together. Then we further develop each m independently by providing feedback to each m in terms of validness, novelty, clarity, and significance, and then refine them based on the feedback. Yang et al. (2024b) first propose to provide feedback in terms of validness, novelty, and clarity to refine hypotheses. Here we add an additional aspect, signifi- cance, since significance is an important evaluation criterion in chemistry. We assume the refined hypothesis should be in better quality, so that the refined hypothesis is \u201cselected\u201d, while the previous hypothesis is \"eliminated\u201d by the \"environment\". Finally the framework \u201crecombine\u201d the remaining selected m, leveraging the advantages from every m to propose h to better associate b and i."}, {"title": "4.2.4 DESIGN DETAILS OF R(h) AND ITS MOTIVATION", "content": "We adopt a simple and efficient way for R(h), which is to prompt an LLM to output evaluation scores for an input h in terms of validness, novelty, significance, and potential. Validness and novelty are two fundamental requirements for such an inductive reasoning process as scientific discovery (Yang et al., 2024a;b). Significance is added because it is important for chemistry. We additionally add potential, because the generated h are about to be further developed by scientists, so we might want to pick those h not only is currently in high quality, but also have good potential to be further developed. We didn't design R(h) in a more complicated way, since there are lots of h to rank, and we might want to save more inference time.\nYang et al. (2024b) use the scores as automatic evaluation for generated social science hypotheses and have shown a high consistency score between automatic evaluation and expert evaluation. How- ever, in the chemistry domain, LLMs might not be reliable enough to directly evaluate the generated h (Sprueill et al., 2024). But it might still be able to provide a preliminary quality identifier to h: the ranking of the average score between the four aspects of an h determines whether it will enter the next round of MOOSE-Chem by beam search. To understand how well LLMs can perform R(h), we analyze \"how well LLMs can rank chemistry hypotheses\" in \u00a7 5.3."}]}, {"title": "5 INVESTIGATION ON FUNDAMENTAL QUESTIONS", "content": "$P(h|b)$ can be understood as the task to discover high-quality chemistry research hypothesis, given only a background question and/or background survey. Our central question to investigate is how well LLMs can perform $P(h|b)$. Supported by Equation 3 and 4, we break up this main question into three smaller questions: how well can LLMs perform (1) $P(i_j|b, h_{j-1}, I)$, (2) $P(h_j|b, i_j, h_{j-1})$, and (3) $R(h)$? All experiments are performed by GPT-40 (its training data is up to October 2023).", "subsections": [{"title": "5.1 HOW WELL CAN LLMS PERFORM $P(i_j|b, h_{j-1}, I)$?", "content": "Here we investigate the question (denoted as Q1): \u201cwhether LLM can identify inspiration papers which is unknown to be able to associate with the background (or at least unknown to associate in a certain way) but in fact have the potential to help with the background question?\".\nWe first find 3000 most cited chemistry papers published in Nature, and construct a series of I in size of 150, 300, 1000, and 3000. I is constructed by first adding the ground truth inspiration papers (around 120), then randomly selecting the remaining needed papers from the 3000 papers, and finally randomizing the order of all the collected papers. Only title and abstract are needed for each paper in I. The default setting is that each inference of LLMs will screen 15 papers from I, and generate three titles that LLMs think can best assist b (and/or previous h). Screening through I for one round, only 20% of I will be selected. Screening another round will only left 4%, and so on.\nWe use Hit Ratio as evaluation metric, which is calculated by the number of selected ground truth inspiration papers divided by the number of all ground truth inspirations papers. All the Hit Ratio numbers shown in the tables are averaged across the 51 papers in the benchmark.\nTable 3 shows the main experiment results for Q1. The Hit Ratio is surprisingly high. Particularly, more than 75% of ground truth inspirations are selected even only to select 4% papers from the chemistry literature corpus. It seems that LLMs are quite capable of finding inspiration papers that are unknown to be able to associate with the background but, in fact, have the potential to help with the background question. It means our bold assumption in \u00a7 4.2.2 that \u201cthe most advanced LLMs might already know lots of knowledge pairs that are able to associate to create novel knowledge, where the knowledge pairs are not known by any scientist to be related\" is possible to be true."}, {"title": "5.2 HOW WELL CAN LLMS PERFORM $P(h_j|b, i_j, h_{j-1})$?", "content": "Here we investigate the question (denoted as Q2): \u201cGiven only known knowledge, whether LLM can reason to unknown knowledge that has high probability to be valid?\".\nThe first challenge to answer Q2 is the evaluation method: The benchmark covers a large range of chemistry topics, and chemistry is a very complex discipline that a slight change of research topic would make a chemist unable to provide a reliable enough evaluation. In fact, a chemistry researcher might not be able to provide a reliable enough evaluation even if the hypothesis is in his domain.\nTherefore, we adopt a reference-based evaluation method called \"Matched Score\" (MS). The de- scriptions are shown in Table 6. It's on a 6-point Likert scale, roughly containing four stages. Denot- ing generated hypothesis as gh, and original hypothesis as oh, the four stages are (1) gh\u2229oh = 0 (0 point); (2) gh \u2229 oh \u2260 \u00d8 (1/2/3 points); (3) gh\u2283 oh (4 points); (4) gh \u2248 oh (5 points).\nWe use MOOSE-Chem to investigate Q2. Specifically, we initialize I as only the ground truth inspiration papers and search i for k round, where k is the number of ground truth i needed for each b. MOOSE-Chem will not retrieve the same i already retrieved in previous rounds, guaranteeing that before generating the final h, the framework has already seen all the ground truth inspirations."}, {"title": "5.3 HOW WELL CAN LLMS PERFORM R(h)?", "content": "Here we investigate Q3: \"whether LLMs can select high-quality h to rank them higher?\".\nTo investigate Q3, we run MOOSE-Chem with every b from the benchmark; |I| = 300, containing all the ground truth i. Every h is given a rating r = R(h), and is ranked based on r. For every generated h, we get the number of ground truth i it leveraged (#Matched i), and assign it with a GPT-40 evaluated MS (here MS is -1 means this h has not used any ground truth i).\nTable 8 shows the relation between the #Matched i and average ranking ratio (the lower, the better). It shows a clear trend that the more ground truth i is leveraged, the better ranking score h can have. It indicates that that h with a higher ranking ratio are more likely to be matched with better i.\nTable 9 shows the relation between the GPT-40 evaluated MS and the average ranking ratio. For h with a positive MS, there is a trend that the higher the MS, the better the average rank ratio (if MS \u2208 [2,4]). However, the disadvantage of those h without a positive MS is not very significant. It seems that LLMs have a certain ability to rank good h higher. But it is not very significant. A part of the reason might be that those h generated without groundtruth i are also in high quality."}]}, {"title": "6 EXPERIMENT AND ABLATION STUDY", "content": "Here, we perform experiments in a setting similar to the copilot in the wild setting. Specifically, only background question (strict), background survey (strict), and a chemistry corpus |I| = 300 are provided to the framework. Only the top 4% of I is selected and used to develop h. The evaluation metrics are Top MS and Average MS (the highest/average Matched Score of all generated h from one b), averaging across the benchmark. All experiments are conducted by GPT-40 (its training data is up to October 2023).", "subsections": [{"title": "6.1 BASELINES", "content": "MOOSE is a hypothesis discovery framework for the social science domain. It leverages LLMs to retrieve inspirations and uses self-refine (Madaan et al., 2023) to improve the validness, novelty, and clarity aspects. The difference is that (1) it does not adopt the mutation and recombination step to better associate background and inspiration; (2) it only retrieves one step of inspiration.\nSciMON is a hypothesis discovery framework for the NLP domain. It relies on semantic and cita- tion neighbors to retrieve information to assist the background. As a result, the retrieved information could be very related to the background that might not be able to serve as an inspiration. To make the generated hypothesis more novel, it adopts self-refine to focus on improving the novelty aspect of the generated hypothesis. Here we implement SciMON with LLM-based inspiration retrieval, the same as MOOSE-Chem. Table 3 shows that the recall rate of LLM-based retrieval is 83.7%."}, {"title": "6.2 RESULTS", "content": "Table 10 shows the baseline results and the ablation study of MOOSE-Chem. It indicates that both mutation & recombination and the multi-step designs can significantly improve the best-performing h. Mutation & recombination leads to a drop of Average MS; we attribute the reason to that the mutation step forces LLMs to generate h different from previous h mutations from the same b and i, and therefore might generate many h that do not make lots of sense. The assigned MS to these mutation h is low, and therefore lower down the Average MS.\nTo better understand the performance of MOOSE-Chem in this real copilot setting, for each b we select 4 generated h with the highest MS by GPT-40. Two experts evaluate these h again in terms of MS. Table 11 shows the expert evaluation results. Here the top MS is the highest MS for each b, out of the 4 expert evaluated h for this b. Note that MS rated as three is already very high. Illustrated in Table 6, it means the generated h by MOOSE-Chem (that has not seen h) in the real copilot setting covers two main innovations of the hypothesis published in Nature, Science or a similar level."}]}, {"title": "7 CASE STUDY", "content": "Here, we show a case study of a generated h (from MOOSE-Chem with |I|=300), corresponding ground truth h, and an expert's analysis (gives a MS as 3). More case studies can be seen in \u00a7 A.8.\nGenerated h: A pioneering integrated electrocatalytic system leveraging ruthenium nanoparticles embedded in nitrogen-doped graphene, combined with a dual palladium-coated ion-exchange mem- brane reactor, will catalyze efficient, scalable, and site-selective reductive deuteration of aromatic hydrocarbons and heteroarenes. Utilizing deuterium sources from both $D_2$ gas and $D_2O$, this sys- tem will optimize parameters through real-time machine learning-driven dynamic adjustments. Spe- cific configurations include ruthenium nanoparticle sizes (2-4 nm), nitrogen doping levels (12-14%), precisely engineered palladium membranes (5 micrometers, ensuring 98% deuterium-selective per- meability), and advanced cyclic voltammetry protocols (1-5 Hz, -0.5V to -1.5V).\nGround truth h: The main hypothesis is that a nitrogen-doped ruthenium (Ru) electrode can ef- fectively catalyze the reductive deuteration of (hetero)arenes in the presence of $D_2O$, leading to high deuterium incorporation into the resulting saturated cyclic compounds. The findings validate this hypothesis by demonstrating that this electrocatalytic method is highly efficient, scalable, and versatile, suitable for a wide range of substrates.\nExpert's analysis: The proposed hypothesis effectively covers two key points from the ground truth hypothesis: the incorporation of ruthenium (Ru) and the use of $D_2O$ as a deuterium source within the electrocatalytic system. However, the current content does not detail the mechanism"}, {"title": "8 CONCLUSION", "content": "We investigate this central question: 'Can LLMs automatically discover novel and valid chemistry research hypotheses (even in the Nature level) given only a chemistry research background (con- sisting of a research question and/or a background survey), without limitation on the domain of the research question?\". We propose a fundamental assumption to break up the central question into three smaller ones and investigate LLM's ability on each of them. To do it, we construct a benchmark consisting of chemistry papers published and only be public in 2024. We also develop a multi-agent framework consisting of three stages reflecting the three smaller questions. Experiments show that the framework (runs in a copilot in-the-wild setting) can rediscover many hypotheses with very high similarity with the ground truth ones, covering the main innovations.\""}, {"title": "A APPENDIX", "content": "First, we propose a fundamental assumption that a majority of chemistry hypotheses can originate from a research background and several inspirations. This assumption is not only supported by many chemistry researchers whom we have extensive discussions with, but also by the cognitive science finding that \"creative ideas often result from the cohesive association of two (or more) seemingly unrelated pieces of knowledge\u201d (Koestler, 1964; Benedek et al., 2012; Lee & Chung, 2024).\nDenoting background knowledge as b, inspiration knowledge as i, and hypothesis as h, we translate this assumption as:", "subsections": [{"title": "A.1 FULL PROOF / DERIVATION FOR THE FUNDAMENTAL ASSUMPTION", "content": "First, we propose a fundamental assumption that a majority of chemistry hypotheses can originate from a research background and several inspirations. This assumption is not only supported by many chemistry researchers whom we have extensive discussions with, but also by the cognitive science finding that \"creative ideas often result from the cohesive association of two (or more) seemingly unrelated pieces of knowledge\u201d (Koestler, 1964; Benedek et al., 2012; Lee & Chung, 2024).\nDenoting background knowledge as b, inspiration knowledge as i, and hypothesis as h, we translate this assumption as:\n$h = f(b, i_1, ...,i_k)$ (5)\nHere k \u2208 Z represents the number of inspirations needed for a particular h. Normally in chemistry, k\u2208 [1,3].\nWe denote the full (chemistry) literature as I, such that P(I) = 1. Then we can have:"}]}, {"title": "A.3 PROMPT TO OBTAIN R(h)", "content": "You are known as a diligent and harsh reviewer in Chemistry and Material Science that will spend much time to find flaws when reviewing and therefore usually gives a relatively much lower score than other reviewers. But when you meet with a hypothesis you truly appreciate, you don't mind to give it good scores. Given a not yet peer reviewed research hypothesis in Chemistry or Material Science domain, try to evaluate the research hypothesis from four research aspects and give score according to evaluation guidelines provided below. All four aspects should be evaluated in a 5 point scale."}, {"title": "A.4 RELATED WORKS ON REASONING", "content": "Scientific discovery is highly related to reasoning, since it requires a set of very complex reasoning processes to lead to new discovery.\nInductive reasoning (Yang et al., 2024a) is the most relevant reasoning type. It is about finding rules or hypotheses from observations. Scientific discovery is naturally an ultimate goal of inductive reasoning.\nInductive reasoning is a sub-reasoning type of logical reasoning. The other two sub-reasoning types are deductive reasoning (Clark et al., 2020) and abductive reasoning (Bhagavatula et al., 2020). Yang et al. (2023b) discuss their definitions and differences in detail.\nAnother relevant reasoning type is commonsense reasoning (Yang et al., 2020; 2023a). Scientific discovery can be seen as an opposite task, which is to reason far outside of commonsense, even to discover the unknown knowledge."}, {"title": "A.5 PROMPT TO GPT-40 FOR MATCHED SCORE", "content": "You are helping to evaluate the quality of a proposed research hypothesis in Chemistry by a phd student. The groundtruth hypothesis will also be provided to compare. Here we mainly focus on whether the proposed hypothesis has covered the key points in terms of the methodology in the groundtruth hypothesis. You will also be given a summary of the key points in the methodology of the groundtruth hypothesis for reference. Please note that for the proposed hypothesis to cover one key point, it is not necessary to explicitly mention the name of the key point, but might also can integrate the key point implicitly in the proposed method. The evaluation criteria is called 'Matched score', which is in a 6-point Likert scale (from 5 to 0). Particularly, 5 points mean that the proposed hypothesis (1) covers all the key points and leverage them similarly as in the methodology of the groundtruth hypothesis, and (2) does not contain any extra key point that has apparent flaws; 4 points mean that the proposed hypothesis (1) covers all the key points (or at least three key points) and leverage them similarly as in the methodology of the groundtruth hypothesis, (2) but also with extra key points that have apparent flaws; 3 points mean that the proposed hypothesis (1) covers at least two key points and leverage them similarly as in the methodology of the groundtruth hypothesis, (2) but does not cover all key points in the groundtruth hypothesis, (3) might or might not contain extra key points; 2 points mean that the proposed hypothesis (1) covers at least one key point in the methodology of the groundtruth hypothesis, and leverage it similarly as in the methodology of groundtruth hypothesis, (2) but does not cover all key points in the groundtruth hypothesis, and (3) might or might not contain extra key points; 1 point means that the proposed hypothesis (1) covers at least one key point in the methodology of the groundtruth hypothesis, (2) but is used differently as in the methodology of groundtruth hypothesis, and (3) might or might not contain extra key points; 0 point means that the proposed hypothesis does not cover any key point in the methodology of the groundtruth hypothesis at all. Please note that the total number of key points in the groundtruth hypothesis might be less than three, so that multiple points can be given. E.g., there's only one key point in the groundtruth hypothesis, and the proposed hypothesis covers the one key point, it's possible to give 2 points, 4 points, and 5 points. In this case, we should choose score from 4 points and 5 points, depending on the existence and quality of extra key points. 'Leveraging a key point similarly as in the methodology of the groundtruth hypothesis' means that in the proposed hypothesis, the same (or very related) concept (key point) is used in a similar way with a similar goal compared to the groundtruth hypothesis (not necessarily for the proposed hypothesis to be exactly the same with the groudtruth hypothesis to be classified as 'similar'). When judging whether an extra key point has apparent flaws, you should use your own knowledge to judge, but rather than to rely on the count number of pieces of extra key point to judge.\nPlease evaluate the proposed hypothesis based on the groundtruth hypothesis.\nThe proposed hypothesis is:\nThe groundtruth hypothesis is:\nThe key points in the groundtruth hypothesis are:\nPlease evaluate the proposed hypothesis based on the groundtruth hypothesis, and give a score."}, {"title": "A.6 GENERATED HYPOTHESES WITH LOW MATCHED SCORE ARE NOT NECESSARILY BAD", "content": "MS only measures the similarity between the generated h and the ground truth h. Receiving a MS as 0 or 1 does not mean the generated h is in bad. Only real lab experiments can check each h."}, {"title": "A.7 AGREEMENT BETWEEN EXPERT EVALUATION AND GPT-40 EVALUATION", "content": "Table 12 shows the agreement between expert evaluation and automatic evaluation (by GPT-40) on MS. Hard consistency is assigned to 1 only if the two scores are exact the same, else is assigned to"}, {"title": "A.8 MORE CASE STUDY", "content": "Generated h: Leveraging an integrated multi-layer hydrogel-ion assembly, constructed through ad- vanced freeze-casting, salting-out processes, and bioinformatics-driven macromolecular design, will enhance the Carnot-relative efficiency and mechanical robustness of flexible thermogalvanic devices. This approach reimagines the use of poly(vinyl alcohol) hydrogels and incorporates novel ion-specific interactions informed by the Hofmeister series with uniquely potent ions like magnesium and lithium. Precision ion concentrations (0.15 to 0.45 M) are optimized to amplify thermoelectric responses and ionic conductance. Molecular dynamics simulations, employing detailed quantum chemistry models, will validate the enhanced ionic interactions and entropy modulation. Compre- hensive characterization through nanoindentation, electron microscopy, and advanced computa- tional platforms will verify crystalline polymer structures and stratified ionic gel configurations. By setting new benchmarks in efficiency and flexibility, this innovation is poised to revolutionize energy solutions in wearable technologies, outperforming current models in both scalability and applica- tion feasibility.\nGroundtruth h: By integrating guanidine sulfate (Gdm)2SO4 into a poly vinyl alcohol (PVA) hydro- gel and employing directional freezing to create aligned channels, it is possible to achieve a flexible thermogalvanic armor (FTGA) with a Carnot-relative efficiency exceeding 8% while maintaining high mechanical strength. This integration allows for enhanced thermopower and mechanical ro- bustness, exceeding the performance of traditional quasi-solid thermocells.\nExpert's Analysis:\nThe proposed hypothesis effectively covers key points, mirroring the ground truth hypothesis. It in- corporates the Hofmeister series by mentioning \"ion-specific interactions informed by the Hofmeis- ter series,\u201d which aligns with the ground truth's reference to \"guanidine sulfate (Gdm)2SO4\u201d in the hydrogel integration, acknowledging that sulfate ions are a significant component of the Hofmeister series. Additionally, the proposed hypothesis employs \"freeze-casting,\u201d which reflects the ground truth's \"directional freezing\u201d to create structured channels within the hydrogel. This approach en- hances both mechanical strength and thermopower-objectives that are consistent with those of the ground truth hypothesis.\nMoreover, the inclusion of salting-out processes in the proposed hypothesis does indeed contribute to improving the mechanical properties of thermoelectric materials. However, the selection of mag- nesium and lithium as specific examples is problematic. Overall, the proposed hypothesis provides valuable insights and serves as a source of inspiration for further exploration within this domain.", "subsections": [{"title": "A.8.1 CASE 1 (MS BY EXPERT: 4)", "content": "Generated h: Leveraging an integrated multi-layer hydrogel-ion assembly", "h": "By integrating guanidine sulfate (Gdm)2SO4 into a poly vinyl alcohol (PVA) hydro- gel and employing directional freezing to create aligned channels", "Analysis": "nThe proposed hypothesis effectively covers key points, mirroring the ground truth hypothesis. It in- corporates the Hofmeister series by mentioning \"ion-specific interactions informed by the Hofmeis- ter series,\u201d which aligns with the ground truth's reference to \"guanidine sulfate (Gdm)2SO4\u201d in the hydrogel integration, acknowledging that sulfate ions are a significant component of the Hofmeister series. Additionally, the proposed hypothesis employs \"freeze-"}]}]}