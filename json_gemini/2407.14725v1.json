{"title": "CrowdMAC: Masked Crowd Density Completion for Robust Crowd Density Forecasting", "authors": ["Ryo Fujii", "Ryo Hachiuma", "Hideo Saito"], "abstract": "A crowd density forecasting task aims to predict how the crowd density map will change in the future from observed past crowd density maps. However, the past crowd density maps are often incomplete due to the miss-detection of pedestrians, and it is crucial to develop a robust crowd density forecasting model against the miss-detection. This paper presents a MAsked crowd density Completion framework for crowd density forecasting (CrowdMAC), which is simultaneously trained to forecast future crowd density maps from partially masked past crowd density maps (i.e., forecasting maps from past maps with miss-detection) while reconstructing the masked observation maps (i.e., imputing past maps with miss-detection). Additionally, we propose Temporal-Density-aware Masking (TDM), which non-uniformly masks tokens in the observed crowd density map, considering the sparsity of the crowd density maps and the informativeness of the subsequent frames for the forecasting task. Moreover, we introduce multi-task masking to enhance training efficiency. In the experiments, CrowdMAC achieves state-of-the-art performance on seven large-scale datasets, including SDD, ETH-UCY, inD, JRDB, VSCrowd, FDST, and croHD. We also demonstrate the robustness of the proposed method against both synthetic and realistic miss-detections.", "sections": [{"title": "1. Introduction", "content": "Accurately forecasting a crowd's movement in a video is crucial for various applications, such as advancing navigation systems to select an optimal route for agents (robots) and effectively minimizing the risk of collisions [2, 25]. A crowd's movement can be naively forecasted by applying the well-studied trajectory prediction framework [1, 14, 27, 42]. Despite significant attention and numerous proposed works on the trajectory prediction task, most existing works [1, 14, 27, 42] rely on the critical assumption that each trajectory is successfully obtained by two preprocessing (i.e., upstream perception) modules, pedestrian detection [5, 24, 37, 38] and tracking [3, 6,51,55]. However, this assumption is not feasible for real-world scenarios since the complete trajectory for each pedestrian is not always available due to the miss-detection of pedestrians or incorrect tracking. Using estimated trajectories as the input for existing trajectory predictors could lead to significant accumulated errors and pose serious threats to safety [53].\nCrowd density forecasting task [34], which directly forecasts future crowd density maps from the past crowd density maps that are estimated from either pedestrian detection [5,24,37,38] or crowd density estimation [12,22,50,56] modules, offers the potential as an alternative approach for forecasting the movements of pedestrians in real-world robotic applications, even though the movement of each pedestrian is not forecasted. However, the accuracy of the crowd density forecasting task still highly relies on the obtained past crowd density maps. Thus, it is crucial to develop a robust crowd density forecasting model against the error accumulated by the upstream crowd density estimation or pedestrian detection modules. (i.e., miss-detection).\nThe masked autoencoders (MAE) [16] has garnered significant attention due to its recent achievements in image-based self-supervised learning. This approach involves masking a portion of patches in the input data and reconstructing the missing patches using an autoencoder structure. Inspired by the remarkable capabilities of MAE in reconstructing masked patches (interpolation) of spatiotemporal data, we explore its potential for forecasting future patches (extrapolation) in the crowd density forecasting task. This paper presents CrowdMAC, which forecasts future crowd maps from observed crowd maps. Unlike MAE, which masks a subset of patches during training, we mask frames (entire patches) in the future density maps, and the model is trained to reconstruct the masked future frames.\nAs previously mentioned, to robustly forecast the crowd density map with the miss-detection of the pedestrians, the patches in the input past observed crowd density maps are masked. During training, the model jointly reconstructs the masked patches in past observed maps and predicts the patches in future maps. Through the simultaneous training of reconstruction and future prediction, the model acquires meaningful representations that enhance its ability to predict future maps while improving its robustness against miss-detections.\nIn addition, drawing inspiration from representation learning approaches that utilize MAE with non-uniform masking based on token informativeness across various domain data inputs [20, 30, 33, 44], we propose temporal-density-aware masking (TDM) strategy that non-uniformly masks observed maps during the training to facilitate the training and obtain better forecasting performance. The TDM comprises two components: temporal-aware ratio and density-aware masking. First, since the last observed frame is the most informative in the forecasting task compared to the first observed frame, the first module increases the masking ratio along the time index of the maps. Second, given the observation that the input crowd density maps are sparse (e.g., pedestrians may not exist in all pixels in the map) and that reconstructing these sparse pixels doesn't aid model training, we propose to use the accumulated density as empirical semantic richness prior to effectively guiding the crowd density map masking process, enabling enhanced attention to semantically rich spatial regions.\nMoreover, we adopt multi-task learning using different masks inspired by MegVit [54], which addresses various video synthesis tasks with a single model using different masking schemes for efficient training. Specifically, we train the model with three tasks: future prediction, past prediction, and interpolation. Training with these tasks enables the model to establish a robust bidirectional relationship between past and future motion and serves as a form of regularization, enhancing overall performance.\nOur contributions are summarized as follows:\n\u2022 We present a robust crowd density forecasting approach, CrowdMAC, that simultaneously reconstructs the masked tokens in the past crowd density maps and predicts the future crowd density maps during the training.\n\u2022 We propose temporal-density-aware masking (TDM) strategy that non-uniformly masks observed maps during the training to facilitate the training and obtain better forecasting performance.\n\u2022 We introduce a straightforward yet highly effective multi-task masking scheme that facilitates the learning of bidirectional motion connections and serves as a form of regularization to enhance performance.\n\u2022 We extensively benchmark the performance of the proposed model well-established trajectory prediction datasets, ETH-UCY [19, 36], SDD [39], inD [4], and JRDB [31] and crowd analysis datasets, FDST [9], croHD [45], and VSCrowd [21]. Despite the simplicity of the proposed framework, it outperforms previous crowd forecasting methods by large margins under two evaluation settings: ground truth inputs and pedestrian detection inputs. Moreover, our model surpasses conventional trajectory prediction approaches in both settings.\n\u2022 We investigate the robustness of crowd density forecasting approaches against pedestrian miss-detection, a critical consideration in practical scenarios. The study validates that the proposed method outperforms previous approaches."}, {"title": "2. Related Work", "content": "2.1. Trajectory Prediction\nHuman trajectory forecasting aims to infer plausible future positions from observed trajectories. Deep learning-based trajectory prediction approaches [1, 11, 13, 14, 14, 17, 18, 18, 27-29, 35, 41, 42, 52] have become dominant due to their impressive representational ability. Some studies focus on better modeling interactions with other agents, such as pedestrians [1, 14, 35, 52] and the environment [18, 27] and some works [13, 14, 17, 18, 28, 29, 41, 42] aim to model the multi-modality of future motions.\nHowever, despite the increasing accuracy of trajectory prediction methods, they work on trajectory prediction in an idealized setting where ground truth past trajectories are used as inputs for both training and evaluation without considering upstream perception errors (i.e., pedestrian detection and tracking error). However, this idealized setting is not feasible in the real world since the trajectories that contain errors estimated from the upstream modules are inputted to the trajectory forecasting approaches.\n2.2. Crowd Density Forecasting\nCrowd density forecasting aims to forecast crowd density maps of future frames. PDFN-ST [34], the patch-based crowd density forecasting model, is pioneering work in the field of crowd density forecasting. It models the diverse and complex crowd density dynamics of the scene based on spatially or spatiotemporally overlapping patches. Crowd density forecasting directly forecasts future crowd density maps from past crowd density maps. The past crowd density maps are estimated either from upstream crowd density estimation or the object detection modules. Thus, similar to the trajectory prediction method, the crowd density forecasting method highly depends on the accuracy of the upstream module. Therefore, developing a robust crowd density forecasting model against errors accumulated by the upstream modules, such as object detection, is of critical importance and serves as the motivation for this work. Crowd-"}, {"title": "3. CrowdMAC", "content": "3.1. Problem Definition\nThe goal of crowd density forecasting is to predict future crowd density maps over $T_{pred}$ timesteps (i.e., future frames), $C_{pred} = [C_{T_{obs}+1},...,C_{T_{obs}+T_{pred}}]$ from the observed past crowd density maps over $T_{obs}$ timesteps (i.e., past frames), $C_{obs} = [C_1,...,C_{T_{obs}}]$. $c_t \\in [0,1]^{W\\times H}$ represents the crowd density map at time step $t$ with a size of $(W, H)$. The observed crowd density maps $C_{obs}$ are extracted from each input RGB video frame $I_t$ using the off-the-shelf pedestrian detection [5, 15, 24] or crowd density estimation [12, 50] approaches.\n3.2. Overview\nFig. 1 illustrates the overview of the proposed Crowd-MAC. CrowdMAC takes crowd density maps $C \\in \\mathbb{R}^{T \\times H \\times W}$ as input, comprising of observed crowd density maps $C_{obs} \\in \\mathbb{R}^{T_{obs} \\times H \\times W}$ and future crowd density maps $C_{pred} \\in \\mathbb{R}^{T_{pred} \\times H \\times W}$, where $T = T_{obs} + T_{pred}$. It employs the space-time cube embedding [46] to transform the input maps into a set of token embeddings $X \\in \\mathbb{R}^{F \\times N_s}$, where $F$ is the channel dimension of the tokens,"}, {"title": "3.3. Multi-Task Masking", "content": "Instead of training with a single future prediction task, we train the model on three tasks: future prediction, past prediction, and interpolation. At each training step, we sample one of the tasks. This multi-task training enables the model to establish a robust bidirectional relationship between past and future motion. Additionally, multi-task learning serves as a form of regularization, mitigating the risk of overfitting. This is achieved by training the model to perform well across multiple objectives, resulting in more robust and generalized learning.\nFor future prediction and past prediction tasks, the proposed temporal-density-aware masking (TDM) and frame masking are utilized to select tokens to be masked. For the interpolation task, the TDM is utilized to select tokens to be masked."}, {"title": "3.4. Temporal-Density-aware Masking (TDM)", "content": "Instead of uniformly masking tokens in frames via random sampling with a fixed masking ratio, like MAE or VideoMAE, during the training, we propose Temporal-Density-aware Masking (TDM) that randomly masks informative tokens. The overview of TDM is visualized in Fig. 3. TDM consists of two modules: temporal-aware masking (TM) ratio and density-aware masking (DM). TM calculates the number of masked tokens for each time step from the tokens' time index, and the sampling probability of each token in each time step is calculated from DM based on the accumulated density value of each token. The details of each module are explained in the following sections.\n3.4.1 Temporal-aware Masking (TM) Ratio\nFor the future prediction task and interpolation, we assume the latter frame is more informative than the first frame. Therefore, instead of sampling tokens randomly with a fixed masking ratio $\\gamma$ that computes the number of the tokens to be masked, the proposed TM ratio $\\gamma(t)$ is a monotonically increasing function of the tokens' time index of the observation tokens $t \\in \\{1,...,T_{max}\\}$, where $T_{max} = T_{obs}/T_c$ for future prediction task and $T_{max} = T/T_c$ for interpolation task. By designing $\\gamma(t)$ to increase along with the time index, the model is trained to reconstruct more informative tokens in the subsequent frames. Concretely, we design the $\\gamma(t)$ as follows:\n$\\gamma(t) = 1 - e^{(-xt/T_{max})}$, (1)\nwhere $x$ is sampled from the uniform distribution $U[0, A_{max}]$ every epoch with hyper-parameter $A_{max}$.\nFor the past prediction task, we assume the earlier frame is more informative than the last frame. The TM ratio $\\gamma(t)$ is a monotonically decreasing function of the tokens' time index of the future tokens $t \\in \\{1,...,T_{max}\\}$, where $T_{max} = T_{pred}/T_c$. We design the $\\gamma(t)$ as follows:\n$\\gamma(t) = 1 - e^{(-1(T_{max}-t)/T_{max})}$. (2)\n3.4.2 Density-aware Masking (DM)\nIn contrast to RGB images or videos, crowd density maps are often sparse, meaning that pedestrians do not exist in all the pixels in the maps, and most pixel values are empirically 0. For example, Fig. 2 visualizes the estimated crowd density maps from RGB images in the various datasets (e.g. SDD [39], inD [4], and ETH-UCY [19, 36]). We observe that most of the tokens are sparse\u00b9 (the accumulated pixel density values of patches mostly, being 0), and training to reconstruct these tokens through MAE is not effective [30, 44] (the patch lacks informativeness during the training). Therefore, we propose to non-uniformly sample"}, {"title": "4. Experiments", "content": "4.1. Datasets\nWe use a total of seven datasets to investigate the performance of CrowdMAC. Specifically, we conduct experiments on four datasets for trajectory prediction: ETH-UCY [19, 36], Stanford Drone Dataset (SDD) [39], Intersection Drone Dataset (InD) [4], and JackRabbot Dataset (JRDB) [31]. Furthermore, we evaluate our approach on three datasets for crowd analysis tasks (e.g., crowd detection, localization, and counting), including Fudan-ShanghaiTech (FDST) [9], Crowd of Heads Dataset (CroHD) [45], and surveillance-view Video Crowd dataset (VSCrowd) [21]. As the croHD dataset only provided detection results from the detector for the test set, we use the detection results for training and evaluation.\n4.2. Implementation Details\nWe employ the the ViT-Small [8] backbone. Following prior work [34], we use the input size of $80 \\times 80$ for 20 frames which consists of 8 past frames ($T_{obs}$) and 12 future frames ($T_{pred}$) in Sec. 3.1. Note that the 8 past frames are used as input during the inference. We set the space-time cube size for the embedding along the spatial dimensions as $W_c = 8$, $H_c = 8$, and along the temporal dimension as $T_c = 4$. We employ the mean squared error (MSE) loss between the masked pixels and the reconstructed pixels for training. We train our model with AdamW optimizer [26] with a base learning rate 5e-4 and weight decay 1e-5 for 1200 epochs. We train the model from scratch for SDD and use the pretrained model from SDD for initialization when training on other datasets. The hyperparameters were determined through a standard coarse-to-fine grid search or step-by-step tuning. We warm up training for 60 epochs, starting from learning rate 1e-6, and decay it to 0 throughout training using cosine decay. We set the batch size to 256 and train the model using two NVIDIA TITAN RTX GPUs. We employ spatial data augmentation techniques, such as rotation, scaling, horizontal flip, and vertical flip of the crowd density maps. We empirically set $A_{max}$ (Eq. (2)) of temporal-aware masking as 9. Also, we set $\\tau$ in density-aware masking (Eq. (4)) to 500.\n4.3. Evaluation Metrics\nFollowed by prior work [34], we use Jensen-Shannon (JS) divergence to measure the performance of the forecasting:\n$D_{JS}(g_t||C_t) = \\frac{1}{2}(D_{KL}(g_t||\\bar{g}_t)+D_{KL}(\\bar{g}_t||g_t))$, (5)\nwhere $g_t = \\frac{g_t}{\\sum_{i,j} g_t(i, j)}$, $C_t = \\frac{C_t}{\\sum_{i,j} C_t(i, j)}$ are the predicted and ground truth normalized density maps, $i, j$ are the indices of pixel position, and $D_{KL}$ is Kullback-Leibler (KL) divergence:\n$D_{KL}(g_t||C_t) = \\frac{1}{WH} \\sum_{i,j} g_t(i, j) log(\\frac{g_t(i, j)}{C_t(i, j)})$. (6)\nWe report the Average JS divergence (ADJs) and the Final JS divergence (FDJs). ADJs is the divergence between the predicted and the ground truth map averaged over all the future time steps, while FDJs is the divergence between the predicted and ground truth map at the final time step.\n4.4. Comparison Models\nSince only one previous work has tackled the crowd density forecasting task, in addition to the crowd density forecasting method [34], we apply standard and state-of-the-art trajectory forecasting approaches [27,40] to address the crowd density forecasting task following the previous method [34]. We employ the following methods for comparison:\nPDFN-ST [34]: PDFN-ST is a pioneering work that tackles the crowd density forecasting task by using 3D CNNs to learn local crowd density dynamics in 3D receptive fields, regarded as spatiotemporal patches.\nY-Net: Y-Net [27] is a heatmap-based model that predicts future human trajectories by estimating distributions over long-term goals and intermediate waypoints.\nSocial-Transmotion: Social-Transmotion [40] is a Transformer-based model for human trajectory prediction, leveraging diverse visual cues. The model is designed to predict human behavior by capturing spatiotemporal interactions between agents."}, {"title": "4.5. Evaluation Protocols", "content": "We evaluate the efficacy of our method under a common setting in the state-of-the-art trajectory prediction model, which involves observing trajectories over 8-time steps (equivalent to 3.2 seconds) and subsequently predicting future trajectories spanning the next 12 time steps (equivalent to 4.8 seconds), employing two distinct protocols.\nGround Truth Input. To evaluate the performance of crowd density forecasting models independent of the accuracy of the upstream crowd density estimation module, we conduct experiments using ground truth as input. We train the model with ground truth maps and evaluate the accuracy with them. Since the ground truth 2D positions of the pedestrians are annotated in the above trajectory prediction datasets, we generate ground truth crowd density maps from the pedestrians' positions. We apply a 2D Gaussian filter (with a standard deviation of 3 px) following the previous approach [34].\nUpstream Perception Modules Input. To validate the robustness of our method against errors (e.g. miss-detection of the pedestrians) in upstream perception modules, we also evaluate the forecasting accuracy in a realistic setting that uses the estimated results from the upstream perception module as inputs in the evaluation phase. We train the model on ground truth inputs and evaluate the accuracy of the crowd forecasting and trajectory prediction approaches using upstream perception module results. We use the detection and crowd density estimation for crowd density forecasting approaches and the detection&tracking for trajectory prediction approaches as upstream modules. Following PDFN-ST [34], we employ UCY in this protocol for upstream detection results input setting. As the students001 and uni examples videos in the UNIV scene are not publicly available, we do not use them in this setting. For the upstream crowd density estimation results input setting, we choose the dataset with annotations of pedestrian heads. We use the Faster R-CNN model [38] with FPN [23] as the detector, along with Deep-SORT [51] as the tracker, pretrained on the MOT17 [32] dataset. For the detector, we set the confidence threshold to 0.2. We utilize the implementation of MMTracking [7]. We use the STEERER [15], pretrained with the JHU-CROWD++ [43], as a crowd density estimator."}, {"title": "4.6. Forecasting Accuracy Comparison", "content": "Ground Truth Input. We compare our model with crowd density forecasting and trajectory prediction models using the ground truth input evaluation protocol. Tab. 1 summarizes the performance of the methods on trajectory prediction and crowd analysis datasets. As shown in Tab. 1, our approach outperforms previous state-of-the-art method PDFN-ST on all trajectory prediction datasets: SDD, ETH-UCY, inD, and JRDB datasets. For instance, on SDD, we reduce ADJs by 5.6% (from 0.072 to 0.068), and reduce FDJs by 18% (from 0.158 to 0.129) compared to PDFN-ST. Additionally, our CrowdMAC significantly outperforms the trajectory comparison models. CrowdMAC achieves a substantial gain on SDD, ETH-UCY, inD, and JRDB on ADJs metric compared to the Social-Transmotion. Unlike existing trajectory prediction methods, our approach does not assume complete input trajectories. Therefore, we also evaluate cases where the observed trajectories are incomplete due to occlusions or individuals entering the frame partway through the observation timesteps. Such cases can adversely affect the performance of the trajectory prediction results. This degrades the performance of trajectory prediction results.\nAs shown in Tab. 1, CrowdMAC also outperforms existing both crowd density forecasting method and trajectory prediction methods on all crowd analysis datasets: FDST, croHD, and VSCrowd datasets on ADJs and FDJs metric. The performance of the trajectory prediction model on crowd analysis datasets is significantly worse than on trajectory prediction datasets. This discrepancy arises because, unlike trajectory prediction datasets captured from a high and distant bird's-eye view, crowd analysis datasets often include scenes recorded from surveillance cameras that are relatively close to people. Consequently, many individuals appear partway through the observation frames. The trajectory prediction model, which assumes that the all pedestrians are present in all observation frames, fails to handle such cases effectively."}, {"title": "4.7. Robustness against Miss-detection", "content": "We explore the robustness of the crowd density forecasting models against the miss-detection of pedestrians with the synthetically-generated and realistic miss-detections.\nSynthetic Miss-Detection. We evaluate the robustness against synthetically generated miss-detections. We train the models with ground-truth input, and synthetic miss-detections are generated by randomly sampling pedestrians in the frames that will not be used as input during the evaluation. Fig. 4 (a) summarizes the ADJs metric of the previous approach (PDFN-ST) and CrowdMAC with various miss-detection ratios. Since the performance drop of our"}, {"title": "4.8. Ablation Studies", "content": "We perform two ablation studies on the proposed TDM module to assess its effectiveness. In this section, we use the ground truth input evaluation protocol as mentioned in Sec. 4.6.\nEffect of the Temporal-Density-aware Masking. Tab. 4 shows the effect of each component (TM, DM), in TDM. It can be seen that both of the components improved the density forecasting performance.\nEffect of multi-task masking. Tab. 5 shows the effect of mul-task masking. The model trained with a single future prediction task performs considerably worse compared to the model trained with the multi-task approach. In particular, the history prediction task significantly contributes to the improved performance.\nChoice of Temporal-aware Masking (TM) Ratio Function. We explore the design of the TM ratio function in Eq. (2). We compare the results with the approaches that employ different masking ratio functions in Tab. 6. The first row shows the results of the approach that uses the constant masking ratio during the training. From the second row to the fifth row show the approaches that employ various masking ratio functions instead of the function in Eq. (2), such as concave (square root), linear, convex (square, cubic), respectively. We observe that our temporal-aware masking ratio function outperforms the approach with the fixed masking ratio as well as the approaches that employ the other mask ratio functions."}, {"title": "4.9. Qualitative Evaluation", "content": "Fig. 5 visualizes the qualitative results of the proposed method as well as the ground-truth density maps on the SDD and FDST datasets. The proposed method accurately forecasts the crowd density maps."}, {"title": "5. Conclusion", "content": "In summary, we propose CrowdMAC, a new learning framework for crowd density forecasting, which operates in a masked completion fashion. CrowdMAC is simultaneously trained to forecast future crowd density maps from masked past observation maps and reconstruct the masked observation maps to improve the robustness of the crowd density forecasting task against the miss-detection of pedestrians. We further propose Temporal-Density-aware Masking (TDM) that non-uniformly masks the patches in the observed crowd density maps, facilitating training and obtaining better forecasting performance. Moreover, we introduce multi-task masking to enhance the efficiency in training. Empirical results show that our method outperforms the state-of-the-art crowd density forecasting methods, as well as trajectory prediction approaches, and achieves robustness against synthetically generated or realistically occurring miss-detections."}]}