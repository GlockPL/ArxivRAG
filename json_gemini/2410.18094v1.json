{"title": "Self-supervised inter-intra period-aware ECG representation learning for detecting atrial fibrillation", "authors": ["Xiangqian Zhu", "Mengnan Shi", "Xuexin Yu", "Chang Liu", "Xiaocong Lian", "Jintao Fei", "Jiangying Luo", "Xin Jin", "Ping Zhang", "Xiangyang Ji"], "abstract": "Atrial fibrillation is a commonly encountered clinical arrhythmia associated with stroke and increased mortality. Since professional medical knowledge is required for annotation, exploiting a large corpus of ECGs to develop accurate supervised learning-based atrial fibrillation algorithms remains challenging. Self-supervised learning (SSL) is a promising recipe for generalized ECG representation learning, eliminating the dependence on expensive labeling. However, without well-designed incorporations of knowledge related to atrial fibrillation, existing SSL approaches typically suffer from unsatisfactory capture of robust ECG representations. In this paper, we propose an inter-intra period-aware ECG representation learning approach. Considering ECGs of atrial fibrillation patients exhibit the irregularity in RR intervals and the absence of P-waves, we develop specific pre-training tasks for interperiod and intraperiod representations, aiming to learn the single-period stable morphology representation while retaining crucial interperiod features. After further fine-tuning, our approach demonstrates remarkable AUC performances on the BTCH dataset, i.e., 0.953/0.996 for paroxysmal/persistent atrial fibrillation detection. On commonly used benchmarks of CinC2017 and CPSC2021, the generalization capability and effectiveness of our methodology are substantiated with competitive results.", "sections": [{"title": "1. Introduction", "content": "Atrial fibrillation (AF) is the most prevalent arrhythmia [1] characterized by irregular heart rate patterns that often begin as paroxysmal episodes and gradually progress to persistent forms. It is frequently associated with high-risk clinical cardiovascular complications, such as stroke and heart failure, which ultimately lead to increased mortality [2-4]. As a common clinical tool for detecting AF, the electrocardiogram (ECG) captures physiological signals that reflect the periodic activities of the human heart [5-8]. The essential information in the ECG lies within the morphology and intervals (the distance between waves) on the curve [9], as illustrated in Fig. 1. Typically, morphological changes and irregular intervals often indicate corresponding diseases like AF (e.g., the irregularity in RR intervals and absence of P waves). However, the manual interpretation of ECG not only depends on professional knowledge but also introduces an element of subjectivity. This is particularly evident in paroxysmal cases, where subtle features might not be distinctly visible, potentially leading to misinterpretations due to the inherent limitation of human visual perception. Therefore, developing high-performance algorithms for the automated interpretation and detection of AF in the ECG is of paramount importance and necessity.\nCurrently, relevant algorithms can be broadly categorized into three types:\n\u2022 Handcrafted feature-based algorithms rely on manually extracting features from ECG waves [10-12]. Generally, these features relate to P-waves or R-waves obtained manually or through techniques such as symbolization [13]. Subsequently, machine learning classifiers like support vector machines (SVM) or logistic regression (LR) are employed to discriminate and determine the presence of AF. These algorithms mitigate the subjectivity associated with manual ECG interpretation. However, their performance is hindered by the empirical nature of handcrafted feature construction, which struggles to capture rich and complex patterns.\n\u2022 Supervised deep learning algorithms automatically extract features [1, 14] from ECG signals. For AF detection tasks, popular deep learning architectures include convolutional neural network (CNN) [15-17], long short-term memory (LSTM) networks [18], Transformers [19], and relevant fusion methods [20, 21]. These algorithms offer the advantage of automatically constructing complex features in adaptive high-dimensional spaces but are constrained by the limited availability of large annotated datasets.\n\u2022 Self-supervised learning (SSL) algorithms obtain corresponding representations through pre-training and fine-tuning for downstream tasks. Typically, contrastive learning demonstrates significant potential in ECG representation, involving the construction of a model to assess similarities and differences of pairwise ECG signals, such as mixing up contrastive learning (MCL) [22] and SimCLR [23]. In addition, other SSL methods, such as T-S manipulation of temporal-spatial reverse detection [24], utilize general transformation discrimination pretext tasks. These approaches, leveraging unlabeled data [25-28], present an opportunity to enhance the performance of AF detection. However, existing SSL methods for AF detection often involve simply transferring image or time-series techniques to ECG representations without incorporating medical knowledge, leading to unsatisfactory results, particularly for paroxysmal atrial fibrillation with less prominent features."}, {"title": "2. Materials and methods", "content": "In this study, we propose a novel self-supervised inter-intra period-aware ECG representation learning approach guided by medical domain knowledge, as shown in Fig. 2. Given that the ECGs of patients with AF are commonly related to the irregularity in RR intervals [29, 30] and the absence of P-waves [31-33], we design pre-training tasks to learn representations that can capture interperiod variability in the RR intervals and recognize the intraperiod absence of P-waves. Specifically, the interperiod pre-training task encourages the model to perceive periodic representations which facilitates the recognition of the irregularity in RR intervals. In the interperiod task, we first isolate the R-wave positions from the multi-period ECG input and process them independently to calculate the RR intervals, whose statistics, i.e., mean and standard deviation, serve as prediction targets. The task then requires the multi-period encoder to extract representations from the multi-period ECG to accurately predict these targets. Moreover, the intraperiod pre-training task enhances its ability to represent the stable morphology of a single cycle, thereby better capturing the absence of the P-waves. In the intraperiod task, the multi-period ECG is decomposed into multiple single-period segments, then aligned with the primary beats, and the median values are utilized to generate a single-period representative morphology with less noise. Subsequently, we utilize the encoders to extract representations separately and apply contrastive learning to align the multi-period and single-period stable representations from the same ECG record. Combining the proposed tasks, our model can learn ECG representations from vast amounts of unlabeled data, focusing not only on representative morphologies within individual periods but also on preserving information across multiple periods. Following the acquisition of ECG representations, the model undergoes fine-tuning for AF detection on a relatively small set of labeled target data.\nWe focus mainly on paroxysmal atrial fibrillation (AFp) because it is challenging and crucial for early treatment, and conduct preliminary tests on persistent atrial fibrillation (AFf) to demonstrate the effectiveness of our approach. Our approach leverages prior medical knowledge related to AF, including the irregularity of RR intervals and the absence of P waves. After pre-training on a large amount of unlabeled data, our model gains a comprehensive understanding of ECG from both interperiod and intraperiod perspectives. Subsequent fine-tuning on small annotated datasets improves the performance of detection, even in situations of AFp where features are not prominently discernible. This method allows for robust detection by enhancing the distinguishability of relevant features from both interperiod and intraperiod perspectives. Experimental results indicate that the inter-intra period-aware ECG representation learning outperforms previous methods, confirming the significance of period awareness, including both interperiod and intraperiod representations for ECG signals. This holds significant promise for large-scale AF screening and health monitoring, potentially reducing medical professionals' workload and healthcare costs."}, {"title": "2.1. Dataset description", "content": "Our private dataset is collected from Beijing Tsinghua Changgung Hospital (BTCH) from January 2016 to November 2021. The ECG signals are acquired using GE Healthcare's Marquette ECG device. The device records signals with a duration of 10 seconds and a sampling rate of 500 Hz. These signals consist of 12 leads, where eight of the leads are acquired directly (I, II, and V1-V6), and the remaining four are derived via Einthoven's law (III) and Goldberger's equations (aVR, aVL, and aVF):\nIII = II-I\naVR = -(I + II)/2\naVL = I - II/2\naVF = II - I/2"}, {"title": "2.2. Signal preprocessing", "content": "In general, the collection of ECG signals is susceptible to several forms of noises such as baseline drift and powerline interference, which make it challenging to realize AF detection precisely and robustly [36]. To remove the above noises, we analyze the frequency characteristics of ECG signals by Fast Fourier Transform (FFT) [37]. Based on the fact that ECG signals typically exhibit small frequencies and low amplitudes [38], we employ bandpass filtering from 0.5 Hz to 35 Hz and median filtering for further smoothing and denoising. As shown in Fig. 3, the jagged noise in the original signal is removed, resulting in a relatively clean ECG signal. Additionally, for the CinC2017 and CPSC2021 datasets, we segment variable-length ECG records into 10-second segments using a sliding window and resample them to 500 Hz. Finally, Z-score normalization is applied to facilitate fast and stable convergence when training models, as shown in Eq. (2).\nX_{normalized} = \\frac{X - \\mu}{\\sigma}"}, {"title": "2.3. Pre-training based on period awareness", "content": "To capture effective feature representations for AF detection from large-scale unlabeled ECG data, we propose an inter-intra period-aware ECG pre-training method, as illustrated in Fig. 4. Based on medical prior knowledge that ECGs of atrial fibrillation patients exhibit the irregularity in RR intervals and the absence of P-waves, we propose our method to capture the stable morphology representation within single-period and valuable representation across periods by exploring interperiod and intraperiod representation, respectively.\n\u2022 Interperiod representation learning: we design an R-wave extractor to determine the absolute positions of R-waves on the time axis. Subsequently, through differential operations, we obtain the RR interval sequence and calculate their mean and standard deviation as prediction targets, which largely reflect the irregularity of RR intervals. For multi-period ECG signals, we develop an encoder to extract features and further predict the above targets. Correspondingly, the mean squared error can measure the loss $l_i$ for the $i$th example, with the optimization objective of minimizing the interperiod loss $L_{inter}$ for a minibatch containing N examples, as shown in Eq. (3).\n$l_i = \\sum_{n}^{i=1} (y_i - \\hat{y_i})^2$\n$L_{inter} = \\sum_{i=1}^{N} l_i$\n\u2022 Intraperiod representation learning: Multi-period ECG signals are decomposed into multiple single-period morphologies, then aligned with the primary beats, and the median values are utilized to generate a single-period representative stable morphology, which can dramatically reduce noise. After that, we leverage separate encoders for multi-period and single-period ECG signals, extracting representations denoted as $h_{multi}$ and $h_{single}$, respectively. Employing a projection head, these representations are further transformed into $Z_{multi}$ and $Z_{single}$ in the latent space. A multi-period representation and its corresponding single-period representation, derived from the same ECG record, constitute a positive example pair, while those originating from different ECG records form a negative example pair. Subsequently, intraperiod representations can be learned by maximizing agreement between via a contrastive loss in the latent space. We randomly sample a minibatch of N examples, comprising 2N data points from single-period and multi-period ECGs. Given a positive pair, we treat the other 2(N \u2212 1) examples within a minibatch as negative examples [39]. Let $sim(u, v) = uv/||u||||V||$ denote the dot product between $l_2$ normalized u and v (i.e. cosine similarity). Then the normalized temperature-scaled cross entropy loss $l(i, j)$ can be calculated for a positive pair of examples (i, j) [23], with the optimization objective of minimizing the intraperiod loss $L_{intra}$ for a minibatch, as shown in Eq. (4)\nl(i, j) = -log \\frac{exp (sim (z_i, z_j) /\\tau)}{\\sum_{k=1}^{2N} 1_{[k\\neq i]} exp (sim (z_i, z_k) /\\tau)}\nL_{intra} = \\frac{1}{N} \\sum_{k=1}^{N} [l(2k - 1, 2k) + l(2k, 2k - 1)]\nwhere $1_{[k\\neq i]} \\in \\{0,1\\}$ is an indicator function evaluating to 1 iff $k \\neq i$ and $\\tau$ denotes a temperature parameter to scale the similarity.\nThe total loss of our method combines the above pre-training losses for intraperiod and interperiod representation learning, which is formulated as\nL_{all} = \\alpha * L_{intra} + (1 - \\alpha) * L_{inter}"}, {"title": "2.4. Fine-tuning for atrial fibrillation detection", "content": "During the pre-training, the model's encoders gradually absorb prior knowledge, gaining a comprehensive understanding of ECGs from both interperiod and intraperiod perspectives. Subsequently, the knowledge embedded in the encoder of the pre-trained model is transferred to the downstream model by weight sharing. As illustrated in Fig. 5, ECG signals are processed through the encoder and produce refined ECG representations. Subsequently, the ECG representations are fed into a classifier to obtain the probabilities of normal rhythm and atrial fibrillation. Specifically, a fully connected layer outputs two nodes, one for normal rhythm and one for atrial fibrillation, which are then normalized using the Softmax function to yield the respective probabilities. Considering that relevant physiological features, such as sex and age, can provide additional information to enhance atrial fibrillation detection performance, these features can be incorporated with the ECG representations whenever available. Specifically, the physiological features are concatenated with the ECG representations obtained from the encoder and then fed into the fully connected layer for integration and further classification. When assessing the representational capability of the SSL encoder in practical scenarios, two approaches are considered: one involves freezing the weights of the encoder and only updating the weights of the classifier for linear evaluation, while the other entails updating all parameters for full fine-tuning. In our experiments, we exclusively employ the multi-period encoder for both evaluations, highlighting its effectiveness and robustness in learning ECG representation. It is worth mentioning that the single-period encoder is valuable even for datasets consisting solely of single-period data, which enhances the model's scalability and applicability."}, {"title": "2.5. Visualization and model interpretation", "content": "It is widely recognized that interpretability is crucial for models in medical scenarios, ensuring acceptance and application by healthcare professionals and patients. Unlike traditional approaches that rely on post hoc interpretations to uncover the model's decision rationale, our approach is primarily guided by medical prior knowledge in algorithm design and pre-training tasks. Initially, we leverage clinical expertise to analyze and deduce features associated with AF in ECG signals. Notably, AF may manifest as irregular RR intervals and the absence of P-waves. On the one hand, visualizing the RR interval information within ECG signals confirms its correlation with AF, thereby validating the rationality of its guidance in the task of interperiod representation. On the other hand, statistical analysis of P-waves, which illustrates their association with AF, enabled the decomposition of multi-period signals into single-period representative morphologies. This significantly aids in the extraction of intraperiod features, such as the absence of P-waves. Visualization and statistical analysis have underscored the significance of period awareness and have augmented the interpretability of the proposed pre-training tasks from interperiod and intraperiod perspectives. This ensures that the mechanisms behind our proposed self-supervised learning approach for detecting AF are comprehensible, making it more suitable for clinical acceptance and application."}, {"title": "3. Experiment details", "content": "All models are implemented in Python 3.7 and PyTorch on a server with an NVIDIA GeForce RTX 3090 GPU. During the pre-training phase, the batch size is 16. The Adam optimizer is utilized with an initial learning rate of 0.0003. The scheduler employed is StepLR with a rate decay of 0.9 every 3 epochs, ensuring the stability of the overall optimization process. The entire pre-training process lasts for 30 epochs, which is determined based on the progression of the loss decline in early exploration. During the fine-tuning phase, we use the same initial learning rate as the pre-training phase for the Adam optimizer, and the scheduler with a rate decay of 0.9 every epoch for expedited convergence. A smaller batch size of 4 is adopted, along with a label smoothing rate of 0.1. In addressing the issue of class imbalance in AFp detection, the loss of positive samples is weighted with a factor of 3. This strategy significantly improves the model's performance in scenarios where imbalanced class distribution poses a challenge."}, {"title": "3.2. Evaluation metrics", "content": "The primary evaluation metric for AF detection is the area under the receiver operating characteristics curve (AUC), which is not affected by sample imbalance and can effectively reflect detection performance. In addition, several auxiliary metrics are employed, including accuracy (ACC), sensitivity (SEN), specificity (SPE), positive predictive value (PPV), and negative predictive value (NPV). Their formulas are as follows:\nACC = \\frac{TP+TN}{TP+TN + FP + FN}\nSEN = \\frac{TP}{TP+FN}\nSPE = \\frac{TN}{TN+FP}\nPPV = \\frac{TP}{TP+FP}\nNPV = \\frac{TN}{TN+FN}"}, {"title": "3.3. Baseline methods", "content": "To comprehensively evaluate our proposed model in AF detection, we compare it against handcrafted feature algorithms and deep learning methods, including supervised and self-supervised approaches. Details of each baseline method are as follows.\n(a) Handcrafted feature-based methods: These typically involve manual feature extraction followed by a classifier for detection. BOSS [13] and ROCKET [44] are advanced techniques for extracting manual features. Some traditional machine learning algorithms serve as classifiers in this context, such as SVM and LR. We choose the best result as the final performance of handcrafted feature-based methods from the following four combinations: BOSS + LR, BOSS + SVM, ROCKET + LR and ROCKET + SVM.\n(b) CNN: CNN is a type of artificial neural network commonly used in ECG classification tasks [41]. It consists of multiple layers, including convolutional layers, pooling layers, and the fully-connected layer. The convolutional layers apply convolution operations to extract features such as sharp peaks. The pooling layers downsample the feature maps to reduce computation and control overfitting. Finally, the fully-connected layer combines the features extracted by the convolutional layers to make predictions.\n(c) LSTM: LSTM is a type of recurrent neural network architecture designed to capture long-term dependencies in sequential data. It has a complex structure that includes memory cells, input and forget gates, and output gates. This architecture allows the LSTM network to selectively remember or forget information over long sequences, making it particularly effective for tasks such as physiological signals classification [45].\n(d) Transformer: Transformer is a sequence-to-sequence model that relies on self-attention mechanisms, which allows the model to weigh the importance of different parts of the input sequence when generating an output. The Encoder of Transformer was used for ECG classification, showcasing their potential in capturing long-range dependencies in ECG signals [46].\n(e) SimCLR [23]: SimCLR is a simple framework for contrastive learning of representations. It forms positive sample pairs through two types of data augmentation and maximizes the agreement of these pairs through contrastive loss. Such a pre-training method for learning corresponding representations plays a crucial role in enhancing predictive tasks.\n(f) MCL [22]: MCL is an unsupervised contrastive learning framework that is motivated from the perspective of label smoothing. This innovative approach leverages a unique contrastive loss function that seamlessly incorporates a data augmentation strategy. This strategy involves creating new samples by blending two data samples along with a mixing component. The primary objective is to predict the mixing component, which is utilized as soft targets in the loss function.\n(g) T-S [24]: T-S is a simple yet effective self-supervised approach for ECG representation learning. Inspired by the temporal and spatial characteristics of ECG signals, the original signals are flipped horizontally (temporal reverse), vertically (spatial reverse), and both horizontally and vertically (temporal-spatial reverse). Learning is then done by classifying four types of signals including the original one."}, {"title": "3.4. Ablation study", "content": "To thoroughly verify the effectiveness of the proposed self-supervised learning strategy, we conduct ablation studies to investigate intraperiod and interperiod representations by comparing the following variants.\n\u2022 Interperiod representation detection: $\u03b1$ in the total loss $L_{all}$ is set to 0, resulting in the model only focusing on interperiod RR interval information related to AF. By exclusively considering the broader temporal context between periods, the model aims to enhance its understanding of patterns that extend beyond individual periods.\n\u2022 Intraperiod representation detection: this task entails setting $\u03b1$ in the total loss $L_{all}$ to 1, emphasizing information within a single period exclusively. Through contrastive learning, the primary objective is to align multi-period ECG signals to stable morphologies within individual periods.\n\u2022 Inter-Intraperiod representation detection: $\u03b1$ in the total loss $L_{all}$ is set to 0.5, concurrently considering interperiod and intraperiod information. The comprehensive objective is to align multi-period ECG signals to single-period stable morphologies while preserving interperiod differences. This approach seeks to strike a balance, acknowledging the significance of both intraperiod and interperiod representations, aiming for a holistic representation that captures the intricacies of the underlying physiological patterns."}, {"title": "3.5. Scalability experiments", "content": "Considering the standard 12-lead ECG, with 8 leads obtained directly, the remaining 4 leads can be calculated using simple formulas. Therefore, our primary experiments focus on the 8-lead ECG signals to reduce computation and speed up training. Subsequently, we extensively conduct experiments involving single-lead and two-lead configurations, in order to validate the potential application of our approach for wearable devices and large-scale health monitoring initiatives. Additionally, we delve into an exploration of the effectiveness of our self-supervised learning approach in comparison to supervised learning, considering diverse data volumes. This comparative analysis aims to provide insights into the scalability and robustness of our methodology across different datasets, shedding light on its potential for real-world applications in various healthcare scenarios."}, {"title": "4. Results", "content": "Table 3 presents the comparative results of baseline methods and our self-supervised inter-intra period-aware ECG representation learning for AFp detection on the BTCH dataset. Despite differences in feature extraction and classification methods, handcrafted feature algorithms tend to show lower AUC and sensitivity. Although Transformer and LSTM models are adept at processing general sequence data, their effectiveness is limited in the context of multi-lead and multi-period ECG signals, where they marginally outperform handcrafted features. CNN excels in identifying morphological variations in ECG signals, resulting in superior disease detection capabilities with a competitive AUC score and high sensitivity. The performance of these supervised learning methods is constrained by the labeled data, making it difficult to achieve further improvement.\nFurthermore, we compare it with existing popular self-supervised methods, including SimCLR [23], MCL [22], and T-S [24] methods. To objectively evaluate the performance of models, the final results of SimCLR are the average outcomes derived from the following two pairs of augmentation methods: (1) adding noise and random permutation; (2) horizontal flipping and vertical flipping. After completing the pre-training task, we load the pre-trained model weights and perform full fine-tuning for AF detection. As shown in Table 3, self-supervised learning methods generally outperform supervised learning methods because self-supervised learning leverages unlabeled data to mine more information. Besides, the proposed inter-intra period-aware ECG representation method outperforms existing self-supervised learning methods, achieving outstanding results with an AUC of 0.953 and sensitivity of 0.854. The SimCLR and T-S exhibit improvement when utilizing horizontal flipping and vertical flipping transformations. MCL employs the mixture of two data samples with hyperparameter-adjusted similarity, which also yields favorable results. This means that after pre-training of these transformations, models are able to capture features beneficial to downstream AF detection.\nAdditionally, we conduct linear evaluations of the capacity AF detection on the models after pre-training. As depicted in Fig. 7, despite all methods performance not matching that of full fine-tuning, our method outperforms previous self-supervised methods in linear evaluation and exhibits a significant advantage in the pre-training task for ECG signals, which further verifies the effectiveness of our intraperiod and interperiod representations.\nTo validate the efficacy of our self-supervised learning method, we conduct experiments on publicly available datasets, specifically CPSC2021 and CinC2017, as shown in Table 4. The CPSC2021 dataset distinguishes between paroxysmal atrial fibrillation (AFp) and persistent atrial fibrillation (AFf), while the CinC2017 dataset does not differentiate between types of atrial fibrillation (AF). On the CPSC2021 dataset, our proposed method outperforms existing self-supervised learning methods for both paroxysmal and persistent atrial fibrillation. The detection performance for persistent atrial fibrillation is better than for paroxysmal atrial fibrillation because persistent atrial fibrillation exhibits more distinct features. Even on the CinC2017 dataset, which does not differentiate between types of atrial fibrillation, our method demonstrates excellent detection performance, confirming the effectiveness and generalization capability."}, {"title": "4.2. Results of ablation study", "content": "Table 3 and Fig. 6 show the results of the ablation study for AFp detection on the BTCH dataset. The results illustrate that intraperiod representation exhibits relatively superior interperiod representation in AUC. This disparity may arise from the relatively simplistic nature of the interperiod task, which concentrates solely on RR interval information. In contrast, the intraperiod representation method captures a more extensive set of morphological information, providing a richer context throughout the entire stable period in ECG signals. Meanwhile, the performance is best when intraperiod and interperiod representations are combined, which indicates both representations capture complementary features."}, {"title": "4.3. Results of scalability experiments", "content": "We conduct experiments using single-lead (lead I) and two-lead (lead I, II) configurations, aiming to explore the potential application of the proposed method in wearable devices and large-scale health monitoring with reduced data acquisition costs. As shown in Table 5, the application of our self-supervised learning method on single-lead ECG demonstrates an improvement compared to pure supervised learning. Furthermore, it reveals that the improvement in performance from using our self-supervised learning exceeds that of adding an extra lead (AUC, 0.916 vs. 0.899), affirming the efficacy and effectiveness of using fewer leads with self-supervised learning for AF detection.\nAdditionally, we compare the performance of our self-supervised learning method and supervised learning method trained from scratch under different data volumes. As shown in Table 6, our self-supervised method generally outperforms the supervised learning method trained from scratch across varying data volumes. Notably, the performance improvement of our self-supervised learning method is particularly pronounced when dealing with limited labeled data."}, {"title": "4.4. Visualization and model interpretation", "content": "In order to enhance the interpretability of our method used for AF detection, we conduct a series of corresponding visualizations and analyses about interperiod and intraperiod representations. In the context of interperiod representation, Fig. 8 illustrates the distribution of mean and standard deviation of RR intervals based on the BTCH dataset. We could observe clear differences between normal and AFf, while the distinctions related to AFp are relatively subtle, contributing to the greater challenge and value in AFp detection. For intraperiod representation, we conduct a statistical analysis of the absence of the P-waves feature. The findings indicate that AFf exhibits the absence of P-waves in 97.8% of cases, whereas AFp shows the absence of P-waves in only 20.7% of cases. In normal individuals, the absence of P-waves in a very rare few cases, approximately 0.9% of instances. These confirm the rationality of prior knowledge used to guide pre-training tasks from the perspectives of interperiod and intraperiod representations."}, {"title": "5. Discussion", "content": "Our self-supervised learning method conducts ECG representations from interperiod and intraperiod perspectives. Self-supervised pre-training is employed to obtain ECG representations from massive unlabeled data, overcoming the time-consuming and labor-intensive challenges of data annotation. The design of the pre-training task is guided by medical expertise, recognizing that AF patients often exhibit the irregularity RR intervals and the absence of P-waves in their ECG signals, corresponding to interperiod and intraperiod features, respectively. Further, fine-tuning is performed with a small amount of annotated data to enhance the performance of downstream AF detection.\nSubsequently, the models are fine-tuned on a relatively small labeled dataset, primarily focusing on AFp detection. As shown in Fig. 6 and Table 3, both interperiod and intraperiod pre-training tasks make substantial contributions. The amalgamated representation of interperiod and intraperiod features notably enhances AF detection, surpassing the performance of existing self-supervised learning methods. Additionally, experiments on ECG of partial leads confirm the effectiveness of using fewer leads with self-supervised learning for AF detection. These offer potential support for wearable devices and large-scale health screenings. Table 6 shows that compared to training from scratch, our self-supervised learning method enhances performance, particularly in scenarios with limited data.\nIn future work, we plan to explore the representation of other cardiovascular diseases in ECG data based on medical prior knowledge, guiding pre-training tasks to improve the detection capabilities for specific conditions. Additionally, we aim to collect ECG data from wearable devices and evaluate their effectiveness in detecting AF, particularly in the context of early screening and large-scale health monitoring, with the expectation of simplifying medical procedures."}, {"title": "6. Conclusion", "content": "In this study, we propose a self-supervised inter-intra period-aware ECG representation learning method specifically designed for detecting atrial fibrillation (AF). Our approach consists of two key stages: pre-training on a large unlabeled dataset to learn robust ECG representations, and fine-tuning on a relatively small labeled dataset for AF detection. Guided by medical prior knowledge, we design pre-training tasks that capture periodic features of ECG signals. This enables our model to develop a comprehensive understanding of ECG patterns from both interperiod and intraperiod perspectives. During the fine-tuning stage, these learned representations are further refined to enhance their suitability for AF detection. Our experimental results demonstrate that the proposed method outperforms existing self-supervised approaches in terms of AF detection performance. The ablation study confirms the importance and effectiveness of incorporating both interperiod and intraperiod representation learning. Additionally, leveraging medical knowledge not only improves model performance but also enhances interpretability, making our model more clinically acceptable. Furthermore, we assess the scalability of our model on partial-lead ECG signals, confirming its superiority in configurations with a small number of leads, with the expectation of reducing data collection costs. This suggests potential applications in wearable devices and large-scale health monitoring systems, offering prospects for reducing healthcare costs through efficient AF detection. In summary, our method presents a significant advancement in self-supervised ECG representation learning, effectively combining medical insights with advanced machine learning techniques to deliver a robust and viable solution for AF detection."}]}