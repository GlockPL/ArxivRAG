{"title": "Interpret Your Decision: Logical Reasoning Regularization for Generalization in Visual Classification", "authors": ["Zhaorui Tan", "Xi Yang", "Qiufeng Wang", "Anh Nguyen", "Kaizhu Huang"], "abstract": "Vision models excel in image classification but struggle to generalize to unseen data, such as classifying images from unseen domains or discovering novel categories. In this paper, we explore the relationship between logical reasoning and deep learning generalization in visual classification. A logical regularization termed L-Reg is derived which bridges a logical analysis framework to image classification. Our work reveals that L-Reg reduces the complexity of the model in terms of the feature distribution and classifier weights. Specifically, we unveil the interpretability brought by L-Reg, as it enables the model to extract the salient features, such as faces to persons, for classification. Theoretical analysis and experiments demonstrate that L-Reg enhances generalization across various scenarios, including multi-domain generalization and generalized category discovery. In complex real-world scenarios where images span unknown classes and unseen domains, L-Reg consistently improves generalization, highlighting its practical efficacy.", "sections": [{"title": "Introduction", "content": "One critical challenge in visual classification models is their ability to generalize effectively to unseen samples or unknown classes. For instance, a model trained on real images of various animals should ideally classify animal sketches accurately (referred to as multi-domain generalization classification [20, 35, 34, 23, 25, 37, 50]) or discover novel categories not present in the training set (referred to as generalized category discovery [54, 16]). These problems are prevalent in real-world scenarios, where training data-target pairs are usually insufficient, and labeling is time-consuming so that not every data is paired with a label. Meanwhile, test data is likely to contain shifts in both data and targets, making it essential to propose methods that generalize to border scenarios."}, {"title": "Preliminaries and generalization settings for visual classification", "content": "Consider paired $(X, Y) \\sim (\\mathcal{X},\\mathcal{Y}), (X_s, Y_s) \\sim (\\mathcal{X}_s, \\mathcal{Y}_s)$, and $(\\mathcal{X}_u, \\mathcal{Y}_u) \\sim (\\mathcal{X}_u, \\mathcal{Y}_u)$ denote all sets of inputs and labels, seen paired subsets of $(X, Y)$, and unseen paired subsets of $(X, Y)$, respectively. Note that $X_u, Y_u$ may be accessible for the model separately, but their pairing relationships are not accessible. Let $\\mathcal{D}$ denote the possible domains, with $\\mathcal{D}_s, \\mathcal{D}_u \\subset \\mathcal{D}$ representing the seen and unseen domains. In classification tasks, an encoding function $g(x) \\rightarrow \\mathcal{Z} \\in \\mathbb{R}^M$ is commonly introduced to map $\\mathcal{X}$ into the latent feature set $\\mathcal{Z}$, where each latent feature has $M$ dimensions. A predictor $h(\\mathcal{Z}) \\rightarrow \\hat{\\mathcal{Y}} \\in \\mathbb{R}^K$\nmaps $\\mathcal{Z}$ to predictions $\\hat{\\mathcal{Y}}$, where $K$ denotes the number of classes and the dimensions of predictions. $P(\\cdot)$ and $H(\\cdot)$ symbolize probability and entropy, respectively. This paper discusses two typical cases for generalization in image classification tasks: (1) Data-shift generalization: $X_s$ and $X_u$ have distribution shifts, such as multi-domain generalization (mDG); and (2) Target-shift generalization: $Y_s$ and $Y_u$ have distribution shifts, which stands for tasks like generalized category discovery (GCD). We additionally explore a challenging scenario called All-shift generalization: both $X_s$ and $X_u$, $Y_s$ and $Y_u$ have distribution shifts, which is a combination of mDG and GCD tasks (mDG + GCD). The following lists the detailed settings for generalization. Please refer to Fig. 2 for brief diagrams.\nData-shift generalization: Problem setting for mDG. Illustrated in Fig. 2 (a), mDG [9] intends to generalize well to unseen domains having the objective of $\\min H(X_s, Y_s | \\mathcal{D}_s)$ and expecting the model to be generalized to $X_u$ when predicting $Y_u$ from the unseen domain $\\mathcal{D}_u$. In such cases, $Y_u$ is fully accessible to the model since $Y_s$ and $Y_u$ share the same domain: $Y_s = Y_u$ but there are shifts in $X$ where $X_s \\neq X_u$.\nTarget-shift generalization: Problem setting for GCD. GCD [54] (Fig. 2 (b)) aims to discover possible unseen labels among unlabeled datasets $X_u$. The challenge is that the samples in $X_u$ may belong to known classes or unknown classes: $Y_s \\neq Y_u$ and probably $Y_s \\cap Y_u \\neq 0$). The model should be able to distinguish the samples from the known classes and cluster the samples for unknown classes simultaneously. Note that $X_u$ is used for model training, but the relationship between $X_u$ and $Y_u$ is unseen for the model. In summary, shifts exist between $Y_s$ and $Y_u$ but not between $X_s$ and $X_u$.\nAll-shift generalization: Problem setting for mDG + GCD. To explore the generalization problem further, we introduce a setting that is the combination of mDG and GCD as shown in Fig. 2 (c). Specifically, the model is trained on the labeled pairs $(X, Y)$ and unlabeled set $X_u$ from the seen domains $\\mathcal{D}_s$; $X_u$ may belong to known and unknown classes. Furthermore, the model is tested on $X_u$ from the unseen domain $\\mathcal{D}_u$, where $X_u$ may also come from the known and unknown classes. In this setting, the model is expected to 1) classify samples to the seen classes and discover the unseen classes among unlabeled samples from seen domains and 2) generalize this ability to the samples from the unseen domain. In this scenario, $X_s$ and $X_u$ have shifts, and so do $Y_s$ and $Y_u$.\nFor all aforementioned generalization settings, the objective can be summarized as minimizing the generalization loss:\nDefinition 2.1 (Generalization loss). Let the target model $f^* : f^*(X,Y) : X \\rightarrow Y$, can generalize across both seen and unseen sets $X, Y$. Denote its trainable $f$, which is only trained on the seen sets. The generalization loss for the unseen sets is defined as:\n$\\text{GL}(f, f^*, (X_u, Y_u)) = \\mathbb{E}_{(x,y)\\in(X_u,Y_u)}||f(x,y) - f^*(x, y)||^2.$"}, {"title": "Logical regularization for generalization in image classification", "content": "Under the problem settings defined in Section 2, we introduce Logic regularization (L-Reg) targeting the objective:\n$\\min_{h,g} \\mathbb{E}_{z_i\\in \\mathcal{Z}, z_j\\in \\mathcal{Z}} [H(\\hat{\\mathcal{Y}}|z_i, \\mathcal{D})] - \\mathbb{E}_{z\\in \\mathcal{Z}} [H(\\hat{\\mathcal{Y}}|\\mathcal{Z}, \\mathcal{D})],$"}, {"title": "Logical framework for visual classification", "content": "This part provides the connections between logical reasoning and visual classification tasks. We would like to remind readers of the framework for studying logics and link it with our practical scenarios.\nDefinition 3.1. Following [4], a logic $\\mathcal{L}$ is defined as a five-tuple in the form:\n$\\mathcal{L} = <\\mathcal{F}_c, \\mathcal{M}_c, \\vDash_c, mng_c, \\mathcal{F}_c,\\vdash>,$"}, {"title": "Constructing atomic formulas using L-Reg", "content": "In this part, we show the derivation details of L-Reg the aims to ensure the formation of suitable atomic formulas, as depicted in Eq. (6). As highlighted in [1], current algorithms may induce implicit biases towards unseen data, resulting in varied solutions for such data. However, expecting an algorithm to generalize effectively to unseen data domains without appropriate incentivization, such as specifically designed regularization, is unreasonable. Therefore, we aim to enhance the generalization capability of models by employing a logic-based regularization approach. To this end, we introduce the concept of semantic support for image classification.\nDefinition 3.2 (Semantic support). We denote $z = g(x)$, where $z \\in \\mathcal{Z}$, as a set of compositions of these semantics: $z := \\{ z_i \\}_{i=1}^{M}$, where $M$ is the number of dimensions or semantics. Notably, not all semantics in $z$ may be useful for deduction or inference. We define the subset $y$ of $z$, extracted from the sample $x \\sim \\mathcal{X}$, as the semantic support of $x$ if $y$ is sufficient for deducing the relationship between $x$ and a $y \\sim \\mathcal{Y}$.\nFor instance, if the subset $\\{ z_1, z_2 \\} \\subseteq z$ is sufficient for accurate inference, the values of other semantics $\\{ z_i \\}_{i=3}^{M}$ will not impact the inference process. When $\\{ z_1, z_2 \\}$ constitutes the minimal combination of semantics required for inference, it is termed the semantic support. We denote $\\Gamma$ as the set of semantic supports of $\\mathcal{X}$ for deducing each individual class.\nDerivation of L-Reg. Regarding Eq. (6), if the semantic supports and their relationship with $\\mathcal{Y}$ form atomic formulas, Eq. (6) holds as a good general logic, and the generalization would be improved. Thus, we aim to learn the latent features $\\mathcal{Z}$, which contain sufficient semantic supports for the deduction of $\\mathcal{Y}$:\n$\\exists \\mathbf{y} \\in \\Gamma, \\mathbf{y} \\subseteq z, \\forall (z, y) \\in (\\mathcal{Z}, \\mathcal{Y}), \\forall d \\in \\mathcal{D}, h(y|d) \\rightarrow y.$\nSpecifically, $g(\\cdot)$ should meet the following:\n$\\forall (\\Gamma_i, \\Upsilon_i), (\\Gamma_j, \\Upsilon_j) \\in (\\mathcal{Z}, \\mathcal{Y}), \\forall d \\in \\mathcal{D}, \\Upsilon_i \\neq y_j \\leftrightarrow \\Gamma_i \\neq \\Gamma_j,$"}, {"title": "L-Reg under different generalization settings", "content": "L-Reg under data-shift generalization. The task mDG endeavors to facilitate a model's ability to generalize to unseen domains by fostering invariance across seen domains [50]. In the context of mDG, the term $|\\mathcal{D}| \\ge 2$ in Eq. (8) typically denotes multiple domains. Traditionally, existing methods focus on minimizing domain gaps, leading to remarkable results [25, 50]. However, it is noteworthy that even when the domain gap is effectively minimized, and $|\\mathcal{D}| = 1$ for the latent features can be considered, L-Reg still demonstrates its efficacy in promoting the generalization of $X_u$ from $\\mathcal{D}_u$.\nProposition 4.1 (Effectiveness of L-Reg in enhancing data-shift generalization.). Assume the gap across all domains is well minimized. Let $f^*$ denote the target model that generalizes to the data $X_u$ from the unseen domain with the lowest complexity. For a model $f_{(X,Y)}^R$ with the form $f(x,y), f(X,Y)$ trained under the data-shift generalization setting (i.e., $(X_s, Y_s)$ is accessible and $Y_s = Y_u$). We have:\n$\\text{GL}(f^R_{(X,Y)}, f^*, X_u) \\le \\text{GL}(f_{(X_s,Y_s)}, f^*, X_u).$\nL-Reg under target-shift generalization. We demonstrate how L-Reg enhances generalized discovery in scenarios where only a subset of classes ($Y_s$) is available for training, and there may exist an overlap between the unseen classes ($Y_u$) and the seen classes ($Y_s$), denoted as $Y_u \\cap Y_s \\neq 0$. We define"}, {"title": "Experiments", "content": "To validate L-Reg, three groups of experiments under the three kinds of settings are conducted. Notably, all baselines we used already incorporate the $L_2$ regulation in the form of weight decay. We also compare other commonly used regularization terms, such as independence or sparsity regularization on $\\mathcal{Z}$. More results in Appendix Findicate that our L-Reg also surpasses them."}, {"title": "Experiments on mDG", "content": "Experimental settings. We operate on the DomainBed suite [21] and leverage standard leave-one-out cross-validation as the evaluation protocol. We test L-Reg with GMDG [50] on 5 real-world benchmark datasets: PACS [32], VLCS [18], OfficeHome [55], TerraIncognita [7], and DomainNet [42]. Following MIRO [25] and GMDG [50], the RegNetY-16GF backbone with SWAG pre-training [47]) is used. Specifically, we train the backbone using GMDG with L-Reg. Accuracy is"}, {"title": "Experiments on GCD", "content": "Experimental settings. We validate our approach through training PIM additionally with L-Reg. Six image datasets are adopted to validate the feasibility of our proposed RPIM compared to other competitors, including three generic object recognition datasets, CIFAR10 [29], CIFAR100 [29] and ImageNet-100 [17]; two fine-grained datasets CUB [56] and Stanford Cars [28]; and the long-tail dataset Herbarium19 [49]. Following prior works [54, 16], we use the proposed accuracy metric from [54] of all classes, known classes, and unknown classes for evaluation. Please see a detailed description of the experimental setup in Appendix H.2.\nResults. The average results across all datasets for utilizing L-Reg with PIM are presented in Table 2, while detailed dataset-specific information is available in Appendix H Table 17. The results highlight that L-Reg consistently increases the accuracy of all unknown classes across all datasets, thus confirming the validity of Proposition 4.2. However, it is notable that L-Reg may marginally compromise the performance of known classes, as it reduces the size of semantic support for deducing Y, thereby reducing the information available for known classification. Nevertheless, this compromise is deemed acceptable given the significant improvements observed for the unknown classes."}, {"title": "Experiments on mDG + GCD", "content": "Experimental settings. We utilize datasets designed for mDG tasks to conduct mDG + GCD experiments. During the training stage, only samples from seen domains are available, with half of the classes masked as unknown, and only their unlabeled data are utilized. Notably, even though all the unlabeled data originates from unknown classes during training, this prior knowledge is not assumed or constrained, aligning the setting with GCD. Similar to mDG, we adopt the leave-one-out cross-validation method. This entails testing each domain in each dataset as the unseen domain. The performance is tested on unseen domains by employing GCD metrics. To validate L-Reg's efficacy comprehensively, we re-implement four methods under the mDG + GCD setting, testing them both with and without L-Reg. The four methods include ERM, PIM, MIRO, and GMDG. ERM serves as the baseline approach without additional regularization, while PIM maximizes information without minimizing domain gaps. MIRO and GMDG focus on minimizing domain gaps, with GMDG offering a comprehensive approach in this regard. It is worth noting that PIM has been re-implemented. For further experimental details, please refer to Appendix H.3.\nResults. The averaged results across all unseen domains of all datasets are summarized in Table 3. For a detailed breakdown of results for each domain in each dataset, please refer to Appendix H.3. As discussed in Proposition 4.1 and Proposition 4.2, a noticeable trend is observed wherein, as the domain gap is gradually minimized, the improvements for unknown classes increase, with the best results achieved using GMDG with L-Reg."}, {"title": "Apply L-Reg to congestion prediction for circuit design", "content": "Experimental settings. We also test L-Reg in Congestion prediction on the CircuitNet [15] dataset by using CircuitFormer [63] backbone. The congestion prediction is for circuit design and benefits from logical reasoning-based approaches. All parameters, except for L-Reg, remain consistent with CircuitFormer, and we follow its metrics."}, {"title": "Related work", "content": "Logical reasoning for deep learning. Current studies focus on length generalization or symbolic reasoning in the logic-based scope. For length generalization, [1] proposes the generalization to the unseen setting, theoretically verifying that commonly used models can generalize to the unseen and degree curriculum promotes the generalization ability of the transformer, followed by [3, 2, 60]. Another branch is to improve the logical reasoning ability for abstract symbols, such as learning the logical-based temples and expecting the model to generalize to unseen samples [10, 36]. These studies are closely related to languages, such as generating longer answering sequences or solving mathematical problems in large language models, lacking explicit connections to visual tasks. [6] delves into the logical explanations in image classification by explicitly extracting logical relationships. While this logical-based approach sheds light on the interpretability of image classification models, its specific benefits for visual generalization remain relatively unexplored.\nMulti-domain generalization. Current approaches for mDG in image classification focus on learning invariant representation across domains. Previous approaches like DANN [20] minimize feature divergences between source domains. CDANN [35], CIDG [34], and MDA [23] consider conditions for learning conditionally invariant features. MIRO [25] and GMDG [50] take advantage of pre-trained models to improve generalization. Specifically, in comparison to MIRO, GMDG proposes a general entropy-based learning objective for mDG and sufficiently minimizes the domain gaps, yielding better generalization results.\nGeneralized category discovery. Generalized category discovery, pioneered by [54], addresses unlabeled samples with both known and unknown classes. Furthermore, PIM [16] integrates InfoMax into generalized category discovery, effectively handling imbalanced datasets and surpassing GCD on both short- and long-tailed datasets."}, {"title": "Conclusion", "content": "This paper presents L-Reg, a logical regularization approach tailored for image classification tasks using logic analysis frameworks. L-Reg yields better generalization across different settings by fostering balanced feature distributions and streamlining the classification model's complexity. Rigorous theoretical analyses and empirical validations underscore its efficacy, as L-reg consistently improves generalization performance with different frameworks under various scenarios.\nLimitation. L-Reg narrows the extent of semantic supports, potentially diminishing the amount of information available for classification and leading to certain trade-offs in the performance of seen datasets. This effect is evidenced by the slight decline in the accuracy of known classes when L-Reg is applied, as shown in Table 2. A similar phenomenon is observed in Fig. 5, where the model fails to recognize a person in the sketch domain lacking facial features. Analysis from Table 4 suggests that these compromises may result from improper Z. Future work should focus on mitigating potential compromises on seen datasets by exploring strategies for better capturing Z through improved model architecture design. We offer more experimental results of possible solutions to this limitation in Appendix G, such as further constraining the independence of each dimension in Z. Those results may suggest a direction for future work."}, {"title": "Broader impact", "content": "Our regularization term based on logic for image classification offers significant potential beyond academia. By integrating logical constraints, our approach enhances model robustness, interpretability, and ethical alignment. This translates into improved performance on real-world tasks such as disease diagnosis in healthcare and mitigating biases in decision-making systems. Our work fosters interdisciplinary collaboration and contributes to the responsible deployment of AI technologies, ultimately benefiting society through enhanced efficiency, fairness, and transparency in machine learning applications."}, {"title": "Details of the logical framework for visual classification task", "content": "We provide more details of the connections between logical reasoning and visual classification tasks.\nDefinition B.1. Following [4], a logic $\\mathcal{L}$ is a five-tuple defined in the form:\n$\\mathcal{L} = <\\mathcal{F}_c, \\mathcal{M}_c, \\vDash_c, mng_c, \\mathcal{F}_c,\\vdash>,$\nAccordingly and still following [4], a good general logic is defined as:\nDefinition B.2 (General logic). : A general logic is a class:\n$\\mathcal{L}^* := (\\mathcal{L}^P : P \\in Sig),$"}, {"title": "Details of proofs", "content": "Proposition C.1 (L-Reg reduces the complexity of the model, promoting data-shift generalization performance.). Assume the domain gap is well minimized. Consider a $f^*$ is the target model that generalizes to the unseen with the lowest complexity. There are $f^R_{(X,Y)}, f(X,Y)$ trained under the setting of data-shift generalization (i.e., $(X_s, Y_s)$ is accessible and $Y_s = Y_u$), it has that:\n$\\text{GL}(f^R_{(X,Y)}, f^*, X_u) \\le \\text{GL}(f_{(X_s,Y_s)}, f^*, X_u),$"}, {"title": "One toy example", "content": "We present a simplified informal illustrative example to compare the efficacy of our proposed L-Reg against conventional L1 and L2 regularization methods. As depicted in Fig. 6, the ground truth (GT) image represents the underlying data, generated according to $f^*(x_1, x_2) = \\sin(2\\pi x_1) \\cdot \\sin(2\\pi x_2)$, where $x_1$ and $x_2$ denote the horizontal and vertical coordinates respectively, and the pixel color corresponds to the value of $f^* (x_1, x_2)$. The training domain is delineated by the black box, while the testing domain encompasses the area outside of this boundary.\nFor our experiments, we use a 6-linear-layer size-110 ReLU model network. Mean squared error serves as the loss function.\nOur experimental results reveal that L-Reg enhances the model's ability to extrapolate beyond the training domain. Notably, our proposed L-Reg demonstrates superior extrapolative capabilities compared to traditional $L_1$ and $L_2$ regularization methods. This observation highlights the efficacy of L-Reg in fostering improved generalization."}, {"title": "Apply L-Reg to ERM Baseline for mDG", "content": "To further validate L-Reg's efficacy for mDG, we use ERM as the baseline on the TerraInc dataset. For a fair comparison, all experiments share the same hyperparameter settings and use the Regnety-16gf backbone. Original ERM results are also included alongside our reproduced results. The results in Table 8 reveal that ERM with L-Reg significantly improves mDG performance (from 49.9% to 52.9%)."}, {"title": "Compare L-Reg with more regularization terms", "content": "We also compare L-Reg with other regularization terms: The Ortho-Reg - the orthogonality regularization that constrains the independence of each dimension of the semantic feature z; and Sparsity - implemented as Bernoulli Sample of the latent features from the sparse linear concept discovery models [41] on our used PIM backbone. Table 6&Table 7 demonstrate that L-Reg outperforms Ortho-Reg and Sparsity."}, {"title": "Limitation of L-Reg and possible solutions", "content": "As analyzed and discussed in the paper, L-Reg is based on the precondition that each dimension of the latent features represents an independent semantic. Thus, improper semantic features which do not meet this precondition may lead to sub-optimal results. To validate this hypothesis, we test L-Reg by reinforcing independence with Ortho-Reg. MDG results in Table 8 and GCD results in Table 6&Table 7 show that combining L-Reg with Ortho-Reg leads to further improvements, whereas Ortho-Reg alone may not guarantee improvements. This suggests a direction for future work."}, {"title": "More experimental details and results", "content": "All experiments can be conducted on one NVIDIA GeForce RTX 3090 GPU."}, {"title": "Multi-domain generalization", "content": "Competitors. We listed results from previous important work in the mDG field for better validation. They are: MMD [33], Mixstyle [62], GroupDRO [44], IRM [5], ARM [61], VREx [30], CDANN [35], DANN [20], RSC [24], MTL [8], MLDG [31], Fish [46], ERM [53], SagNet [40], SelfReg [26], CORAL [48], mDSDI [12], MIRO [25], and GMDG [50]. Among them, GMDG is treated as our baseline since it sufficiently minimizes the domain gaps.\nDatasets. We use PACS (4 domains, 9,991 samples, 7 classes) [32], VLCS (4 domains, 10, 729 samples, 5 classes) [18], OfficeHome (4 domains, 15,588 samples, 65 classes) [55], TerraIncognita"}, {"title": "Generalized category discovery", "content": "Competitors. We compare our proposed method with existing generalized category discovery methods: GCD [54], and PIM [16]. In particular, PIM based on information maximization is the current state-of-the-art (SOTA) generalized category discovery method. Additionally, the traditional machine learning method, k-means [38]; three novel category discovery methods: RankStats+ [22], UNO+ [19], ORCA [13]; and several information maximization methods: RIM [27], and TIM [11] are adapted for generalized category discovery as competitors. The results of the modified novel category discovery methods are reported in [54], and the modified information maximization methods are reported in [16].\nUsage details of datasets for GCD. Following the protocols of GCD and PIM [54, 16], the initial training set of each dataset is divided into labeled and unlabeled subsets; samples from half of the classes are assigned as unlabeled, and their labels are not used for training. Specifically, half of the image samples from known classes are allocated to the labeled subset, while the remaining half are assigned to the unlabeled subset. Additionally, the unlabeled subset includes all image samples from the novel classes in the original dataset. As a result, the unlabeled subset consists of instances from K different classes. The detailed statistics of datasets are listed in Table 15.\nTraining details. Consistent with PIM, we utilize latent features extracted by the feature encoder DINO (VIT-B/16) [14] that is pre-trained on ImageNet [17] through self-supervised learning. The losses proposed in PIM are treated as Lmain. The original PIM freezes the feature extractor during the training, directly using the pre-saved extracted features as the model input. For a fair comparison, we only added one linear layer as g on the extracted features, which is the minimal modification.\nL2 (weight decay) value searching. For a more fair comparison, we conduct weight decay value searching to ensure that the weight of L2 is the best. To address this, we devised a methodology for weight decay searching involving the construction of smaller labeled and unlabeled subsets derived solely from the labeled data. To conduct parameter searching, we split the labeled samples to construct a 'smaller' sub-labeled and sub-unlabeled set. Specifically, we take 50% of the samples from known classes as sub-unlabeled samples from unknown classes. Additionally, we take 25% of the samples from the remaining 50% of known classes as sub-unlabeled samples from known classes. The remaining samples are treated as sub-labeled samples. Hyper-parameters are then searched on these sub-labeled and sub-unlabeled sets."}, {"title": "Combination of multi-domain generalization and generalized category discovery", "content": "Datasets. We leverage the datasets utilized in mDG tasks to construct the mDG+GCD datasets. Specifically, during the seen domains of training, labels from approximately half of the classes are masked. For instance, in the PCAS dataset comprising 7 classes, classes labeled within the range [0, 1, 2, 3] are retained, while classes in [4, 5, 6] are masked. It is noteworthy that data categorized as unknown classes in our setup are from unknown classes. However, we acknowledge that this prior is not explicitly known. To align with the GCD setting, we operate under the assumption that the unlabeled set may potentially include samples from known classes. Consequently, we refrain from constraining the model by mandating that unlabeled data be classified solely as unknown classes. This adjustment introduces a more challenging generalization scenario.\nTraining details. For all experiments, the implementation directly adds L-Reg to their previously proposed loss sets. The models are trained with the aforementioned labeled and unlabeled sets from the seen domains and tested on the samples from the unseen domain.\nParameters. We include all the parameters for reproducing our experiments in the code. Please refer to the code for details.\nEvaluation metric. We use the same metric from the GCD task for the mDG+GCD task. Similarly, the metrics include the accuracy for all, known and unknown classes."}, {"title": "More GradCAM visualizations", "content": "We provide more visualized examples of L-Reg. Examples of known classes can be seen in Figs. 7 to 10 and unknown classes in Figs. 11 and 12. Compromises in known sets, as discussed in the limitations, can be seen in Figs. 8 and 12."}]}