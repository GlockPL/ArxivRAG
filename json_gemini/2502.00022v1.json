{"title": "A Dynamic and High-Precision Method for Scenario-Based HRA Synthetic Data Collection in Multi-Agent Collaborative Environments Driven by LLMS", "authors": ["Xingyu Xiao", "Peng Chen", "Qianqian Jia", "Jiejuan Tong", "Jingang Liang", "Haitao Wang"], "abstract": "HRA (Human Reliability Analysis) data is crucial for advancing HRA method- ologies. however, existing data collection methods lack the necessary gran- ularity, and most approaches fail to capture dynamic features. Addition- ally, many methods require expert knowledge as input, making them time- consuming and labor-intensive. To address these challenges, we propose a new paradigm for the automated collection of HRA data. Our approach focuses on key indicators behind human error, specifically measuring work- load in collaborative settings. This study introduces a novel, scenario-driven method for workload estimation, leveraging fine-tuned large language mod- els (LLMs). By training LLMs on real-world operational data from high- temperature gas-cooled reactors (HTGRs), we simulate human behavior and cognitive load in real time across various collaborative scenarios. The method dynamically adapts to changes in operator workload, providing more accu- rate, flexible, and scalable workload estimates. The results demonstrate that the proposed WELLA (Workload Estimation with LLMs and Agents) out- performs existing commercial LLM-based methods in terms of prediction accuracy.", "sections": [{"title": "1. Introduction", "content": "Human error is critically important, with statistics indicating that ap- proximately 50%-80% of incidents in high-risk industries are caused by hu- man error. Therefore, human reliability analysis (HRA) is a systematic ap- proach to assessing and improving the reliability of human performance in complex systems, particularly in high-risk industries such as nuclear power, aviation, and healthcare. However, most HRA methods rely on expert es- timations rather than empirical data [1]. Examples of such methods in- clude human cognitive reliability (HCR) [2], standardized plant analysis risk-human reliability analysis (SPAR-H) [3], and cognitive reliability and error analysis method (CREAM) [4]. Consequently, numerous scholars have focused on improving data collection in HRA, which is crucial for revolution- izing HRA algorithms. A notable example is the integrated human event analysis system for event and condition assessment (IDHEAS-ECA) [5], the latest method developed by the NRC based on IDHEAS-DATA [6]. Xiao et al. developed a fast and efficient base human error probability solving algorithm based on the IDHEAS-DATA and a large model knowledge graph [1].\nHowever, HRA data is particularly scarce, and traditional methods typ- ically rely on manually completed surveys to label the data, such as human reliability data extraction (HuREX) [7] and scenario authoring, characteriza- tion, and debriefing application (SACADA) [8], are labor-intensive and time- consuming. Furthermore, small sample sizes of operators for low-probability events present a significant challenge. For example, when dealing with prob- abilities as low as 1E-3, it may require up to 1,000 data points to observe a naturally occurring error. This often necessitates the introduction of artifi- cial errors in complex scenarios to ensure an adequate dataset for analysis [9]. These method is often collected through surveys, which are typically adminis- tered static post facto. Boring et al. [10] emphasize the use of the HUNTER dynamic HRA to simulate operator performance. This approach aims to un- derstand both the limitations of synthetic data and its potential advantages compared to expert estimation methods. This method temporarily addresses the issue of static. However, there is still a critical issue, as emphasized by the U.S. NRC: the focus should not solely be on the manifestation of human error but rather on the underlying causes behind human error [5]. The data generated by existing methods predominantly reflect error of omission (EOO) and error of commission (EOC) [11]. As introduced in Heinrich's Theory and\nTo address this, a new paradigm for scenario-based HRA data automa- tion collection is proposed, leveraging large language models (LLMs). The scenario we investigate involves multi-agent collaboration, as most real-world tasks require teamwork. Specifically, we use the example of the main con- trol room in a multi-module high-temperature gas-cooled reactor (HTGR) nuclear power plant. In this scenario, the main control room operates under the 'one operator controls two or more reactors' model. The staffing of the multi-module HTGR control room includes three reactor operators (RO1, RO2, RO3), one secondary loop operator (CO), and one shift supervisor (SO).\nWe begin by collecting workload data through surveys to measure the cognitive load during team collaboration. Building on macro-cognitive the- ories, we use large models to generate virtual cognitive trajectories. Next, using the Llama-factory framework, we implement the supervised fine-tuning (SFT) process for the Qwen2.5-7B model. Through this fine-tuning, we de- velop WELLA: Workload Estimation with LLMs and Agents. The results demonstrate that WELLA outperforms current commercial models for pre- dicting workload for roles including RO1, RO2, RO3, CO, and SO.\nSection 2 reviews foundational studies on human error, workload esti- mation models, and the application of large language models for simulating human behavior. Section 3 presents the comprehensive framework employed in this research. Section 4 outlines the experimental design and key find- ings. Section 5 summarizes the contributions of this research, reflects on its limitations, and proposes directions for future work."}, {"title": "2. Related Work", "content": "This section presents an in-depth analysis of the underlying factors con- tributing to human error, explores various workload estimation models, and discusses the application of large language models in simulating human be- havior."}, {"title": "2.1. Underlying Factors Contributing to Human Error", "content": "Human error, a critical element in safety analysis across various domains, is often the result of multiple interacting factors. These factors can be broadly categorized into cognitive, environmental, organizational, and physiological influences [12], all of which shape an individual's performance and decision- making process. Understanding these underlying causes is essential for mit- igating risks and improving system design.\nIt is often compared to the iceberg theory [13], suggesting that there is much more beneath the surface of visible behavior. Prior to the occurrence of an incident, there are numerous underlying representations that influence the final outcome. The theory posits that an individual's \"self\" resembles an iceberg, where only a small portion\u2014behavior\u2014is observable above the surface, while the larger, more complex inner world remains hidden beneath. This hidden world encompasses seven layers: behavior, coping mechanisms, emotions, perspectives, expectations, desires, and the self [14]. Each of these deeper layers plays a pivotal role in shaping behavior and ultimately influ- encing the occurrence of errors or accidents.\nTherefore, it is crucial to focus not only on the visible actions during the event but also on the factors and conditions that precede it.\nThe Heinrich Law,[15] formulated by the renowned American safety en- gineer H.W. Heinrich, is a principle commonly known as the 300:29:1 ratio. Based on his analysis of workplace injury and accident statistics, Heinrich proposed this law to provide insights into accident prediction and risk man- agement, particularly for insurance companies. The law stipulates that for every 300 unsafe acts or conditions present in a workplace, 29 will result in minor injuries or incidents, and of these 29 minor incidents, one will in- evitably lead to a serious injury, fatality, or major disaster.\nThis ratio emphasizes the critical importance of addressing hazards before they escalate into accidents. Heinrich's research underscores the need for proactive safety measures and the systematic identification and elimination of risks to prevent catastrophic outcomes. The principle serves as a foundational concept in safety engineering and risk management, influencing policies and safety protocols in various industries.\nTo prevent human-factor accidents, it is essential not only to focus on external errors but also to pay attention to underlying indicators. Work- load serves as a valuable indicator in this regard and is widely applied in high-risk industries such as aviation [16] and nuclear power plants [17]. This"}, {"title": "2.2. Workload Estimation Models", "content": "Workload estimation is a critical component in ensuring optimal hu- man performance, particularly in high-risk industries such as nuclear power, aerospace, and healthcare. A variety of models have been developed to assess the cognitive, physical, and emotional demands placed on operators, with the aim of predicting potential overload and improving safety and efficiency.\nSpecifically, workload estimation can be divided into contact-based, non- contact-based and a mixed-based measurements. The most common contact- based approach involves EEG-based methods [18, 19], where EEG signals are collected and analyzed using various deep learning techniques such as CNN, LSTM, and Transformer for prediction and early warning [20]. In addition, other physiological signals, such as Heart Rate Variability [21] and eye activity features [22], have also been explored. Some studies combine multiple signals for multimodal inference. For instance, Planke et al. [23] proposed different configurations to fuse data from an Electroencephalogram (EEG) model's output, four eye activity features, and a control input feature. Xing et al. [24] utilized a variety of sensors to provide signals that can assist in workload estimation. However, measuring EEG, eye movement, and other signals under normal working conditions is not always feasible, as such measurements may interfere with the regular tasks and operations.\nFor non-contact measurements, the primary approach involves Subjective Measures of Mental Workload [25], such as SWAT, WP, NASA-TLX, RSME, and DALI questionnaires. However, subjective methods can only be used for post-task evaluation, making them a static and passive approach. De- spite this limitation, several studies confirm the value of subjective measures. Mental workload is a multi-faceted phenomenon, as reflected in the litera- ture. It can be related to physiological states of stress and effort, subjective experiences of stress, mental effort, and time pressure, as well as objective measures of performance levels and performance breakdowns. Therefore, despite various physiological and psychological assessments, subjective mea- sures indicate that subjects tend to be consistent in their workload ratings. Mental workload is typically categorized into time-load, mental effort load, and psychological stress load."}, {"title": "2.3. Large Language Models in Simulating Human Behavior", "content": "The emergence of large language models (LLMs) has prompted significant research across various specialized domains. Many scholars have explored the use of LLMs for simulating human behavior. For instance, Wang et al. pro- pose the Learning through Communication (LTC) framework to enhance the"}, {"title": "3. Methodology", "content": ""}, {"title": "3.1. Framework of the study", "content": "As illustrated in Figure 1, our framework is divided into three key com- ponents: real-world data collection, virtual cognitive trajectory generation, and digital brother building. First, we employed a testbed to identify real nuclear power plant operators and collected data from multiple scenarios to"}, {"title": "3.2. Real-World Data Collection", "content": "Next, we examine the main control room of a multi-module High-Temperature Gas-Cooled Reactor (HTGR) nuclear power plant. In this setting, the main control room operates under the one operator controls two or more reactors. The control room is staffed by three reactor operators (RO1, RO2, RO3), one secondary loop operator (CO), and one shift supervisor (SO). RO1 is responsible for the operation of the 1 and 2 Nuclear Steam Supply System"}, {"title": "3.3. Vitural cognitive trajectory Generation", "content": "We refer to the macro-cognitive theory [41], which is primarily divided into five categories: detection, understanding, decision-making, action exe- cution, and inter-team coordination. Although it is challenging to obtain real human cognitive trajectorys, studies suggest that a cognitive trajectory indeed exists during human actions [1], and this is the underlying reason behind workload. Therefore, we leverage large language models (LLMs) to generate human-like cognitive trajectorys, enabling the model to think more like a human. A simplified model of macrocognitive functions is shown in Figure 3"}, {"title": "3.4. Language Model Fine-Tuning", "content": "Supervised fine-tuning (SFT) [42] enables large language models (LLMs) to perform specific tasks, such as question answering, dialogue, and reason- ing, as anticipated [36]. With the availability of instructional data, SFT is utilized to guide the models in executing tasks related to the semiconductor industry.\nWe use Qwen2.5-7B [43] as the base model and fine-tune it using the Llama-factory framework. Qwen2.5-7B is the latest publicly available ver- sion, suitable for a wide range of applications, including but not limited to natural language processing, text generation, code writing, and mathemat- ical computations. With its extensive knowledge base and robust encoding and mathematical capabilities, the model is particularly well-suited for tasks requiring these skills. Additionally, it can generate long texts exceeding 8K tokens, understand structured data (e.g., tables), and produce structured outputs, especially in JSON format. The model also supports up to 29 lan- guages, including Chinese, English, French, and Spanish, making it highly effective for multilingual applications. Llama-factory [44], as the latest Llama framework, is known for its efficiency, significantly reducing training time and computational resources, while offering exceptional flexibility."}, {"title": "3.5. Scenario Analysis", "content": "The specific generation process for scenario analysis is detailed in Figure 4. Given an input scenario, the output consists of the workload for different workers with distinct roles. This process effectively enables the generation of synthetic human workload data."}, {"title": "4. Experiments and Results", "content": "This section provides a detailed of the implementation details, workload estimation accuracy, comparisons with existing methods, and scenario anal- ysis."}, {"title": "4.1. Implementation Detail", "content": "For training WELLA, we utilized 2 NVIDIA A800 80GB GPUs. We followed guidelines from transformers huggingFace, HuggingFace Accelerator, and the LLaMA-Factory library for fine-tuning a LLM. The hyperparameters for pretraining and SFT included a batch size of 2 and a learning rate of 1.0e-5. The training was conducted 8 epochs. It is worth noting that we incorporated SFT data along with a special token [45]. The use of special tokens is a validated practice, which helps balance the pretraining and SFT processes of the model. Detailed implementation can be found in ??, and will not be discussed further in this paper."}, {"title": "4.2. Workload Estimation", "content": "This section presents the results of our model in terms of workload es- timation accuracy. To highlight the effectiveness of our model, we compare"}, {"title": "4.3. Comparisons with Existing Methods", "content": "The most widely used model for HRA synthetic data generation is the human unimodel for nuclear technology to enhance reliability (HUNTER)"}, {"title": "4.4. Scenario Analysis", "content": "Next, we will test the performance of our model in substituting control room personnel across different scenarios.\nGiven the scarcity of operational data in nuclear power plants, especially for high-temperature gas-cooled reactors (HTGR), this methodology offers a novel solution to bridge the data gap. By leveraging WELLA, the proposed approach can simulate realistic workload scenarios based on predefined pro- tocols, thereby generating synthetic workload data for analysis and training purposes. This case study demonstrates how the methodology can be applied to create workload data in the absence of comprehensive real-world datasets, providing valuable insights into system behavior and operator performance in complex operational settings. The ability to automatically generate work- load data also offers significant advantages for improving safety training, system design, and operational planning in nuclear power plants, where data availability is often limited.\nFigure 7 demonstrates the application of the VELLA model for situational awareness assessment in the context of high-temperature reactor operations, specifically focusing on the No. 1 and No. 2 NSSS (Nuclear Steam Supply System) modules. The upper section of the figure represents the model's input, including a structured scenario detailing the operational states of six NSSS units (e.g., water flow rates and shutdown statuses) and a standardized questionnaire assessing three key factors on a 7-point Likert scale: instability of the plant's status, complexity of the plant's situation, and the number of parameter changes. The lower section illustrates the model's output, encom- passing a virtual cognitive journey that simulates the operator's reasoning process and the final results of the questionnaire. In this example, the oper- ator assessed the scenario with scores of 3 (instability), 4 (complexity), and 4 (parameter changes), yielding a total situational demand score of 11. By integrating scenario analysis, cognitive reasoning, and standardized evalua- tion, the VELLA model provides a structured and transparent framework for assessing situational awareness in complex operational environments."}, {"title": "5. Conclusion and Discussion", "content": "This study presents a pioneering approach to workload estimation in hu- man reliability analysis (HRA) by leveraging fine-tuned large language mod- els (LLMs) in real-world collaborative scenarios. Our method addresses the limitations of traditional data collection techniques by automating the gath- ering of HRA data and capturing dynamic, real-time cognitive load across different operator roles. Through training LLMs on operational data from"}]}