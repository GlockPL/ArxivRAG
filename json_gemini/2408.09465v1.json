{"title": "MedMAP: Promoting Incomplete Multi-modal Brain Tumor Segmentation with Alignment", "authors": ["Tianyi Liu", "Zhaorui Tan", "Muyin Chen", "Xi Yang", "Haochuan Jiang", "Kaizhu Huang"], "abstract": "Brain tumor segmentation is often based on multiple magnetic resonance imaging (MRI). However, in clinical practice, certain modalities of MRI may be missing, which presents a more difficult scenario. To cope with this challenge, Knowledge Distillation, Domain Adaption, and Shared Latent Space have emerged as commonly promising strategies. However, recent efforts typically overlook the modality gaps and thus fail to learn important invariant feature representations across different modalities. Such drawback consequently leads to limited performance for missing modality models. To ameliorate these problems, pre-trained models are used in natural visual segmentation tasks to minimize the gaps. However, promising pre-trained models are often unavailable in medical image segmentation tasks. Along this line, in this paper, we propose a novel paradigm that aligns latent features of involved modalities to a well-defined distribution anchor as the substitution of the pre-trained model. As a major contribution, we prove that our novel training paradigm ensures a tight evidence lower bound, thus theoretically certifying its effectiveness. Extensive experiments on different backbones validate that the proposed paradigm can enable invariant feature representations and produce models with narrowed modality gaps. Models with our alignment paradigm show their superior performance on both BraTS2018 and BraTS2020 datasets.", "sections": [{"title": "I. INTRODUCTION", "content": "BRAIN tumors pose severe risks to human life, making precise medical segmentation essential as it devises effective treatment planning and strategies [1]. Brain tumor"}, {"title": "II. RELATED WORK", "content": "Flair, T1, T2, and Tlce are complementary modalities uti-lized to segment brain tumors [2]. Segmentation performance unfortunately drops drastically in the scenario when some modalities are missing due to practical difficulties such as data corruption and/or scanning protocol variations [8]\u2013[11], [21]. Prior arts have proposed several methods to deal with the missing modality problem, which can be generally divided into three categories: Knowledge Distillation, Share Latent Space, and Domain Adaption.\nKnowledge Distillation (KD) based approaches transfer knowledge from teachers with complete modality informa-tion to students with missing modality information. In [1], Kullback-Leibler (KL) loss and an additional contrastive loss are engaged to guide the student to imitate soft distributed features from the teacher and reduce latent space divergence between them respectively. ProtoKD [13] employs a proto-type knowledge distillation loss to encourage simultaneous intra-class concentration and inter-class divergence. In these methods, students' performance is always based on teachers' performance. However, students often lead to sub-optimal seg-mentation performance since their teachers do not consider the feature invariant information and domain-specific information among those modalities.\nShared Latent Space (SLS) methods retrieve missing information by exploiting the multimodal latent feature space. RFnet [7] uses different encoders to extract the modality-specific information and a decoder to share the weights for those modalities to build a shared representation. Differentmodality features are fused at different levels. MmFormer [18]"}, {"title": "III. THEORETICAL MOTIVATION", "content": "In this section, we underscore the significance of reducing modality gaps that prior methodologies have overlooked. We present the problem formulations for three distinct types of approaches and illustrate the enhancement of domain align-ment through the strategic use of $P_{mix}$. Furthermore, we explore different techniques for deriving practical empirical representations of $P_{mix}$.\nNotations. We denote the model, i.e., the teacher model for knowledge distillation, the model for shared latent space, or the model pretrained for domain adaptation as the base model. Considering $J$ as the number of the set of modalities of medi-cal images with paired observations and targets ${X_j, Y;}_{j=1}$ from the modality $j$. Note for medical modalities, Y remains static for all modalities. The encoders of the base model are denoted as $T: T(X_j) \\rightarrow Z$ where Z denotes the latent feature obtained from the base model of the $j^{th}$ modality. Simultaneously, a predictor $C^*$ that predicts segmentation masks from ${Z_j}_{j=1}$ as $C^*: C^*({Z_j}_{j=1}) \\rightarrow Y$. Correspondingly, we denote the possible downstream model, e.g., the student models for knowledge distillation and the adapted model for the domain adaptation, for the $j^{th}$ target modality as $S_j: S_j(X_j) \\rightarrow Z_j$ of each modality with their predictor $C_j: C_j(Z_j) \\rightarrow Y$. Let $P(\\cdot)$, $D_{KL}(\\cdot||\\cdot)$, $H(\\cdot)$, $H_c(\\cdot, \\cdot)$, $I(\\cdot; \\cdot)$ denote the probability of a random variable from the distribu-tion, Kullback\u2013Leibler divergence, entropy, cross-entropy, and mutual information respectively."}, {"title": "A. Previous Methods", "content": "Despite the various approaches adopted to handle missing modalities, the common strategy involves training a base model T that retains information from all modalities as its foundation. Therefore, the objective for training T can be summarized as:\n$\\max E_{Z_j~P(Z_j)} [\\ln P(Y|C^*(Z))] + \\zeta,$\t(1)\nwhere $\\zeta$ denotes any possible regularization. Eq. 1 can be changed in the form of information entropy as:\n$\\min \\sum_{j=1}^J H_c(P(C^*(Z_j)), P(Y)) + \\zeta.$\t(2)\n$C^*$\nThe base model can be adapted for different downstream approaches under the missing modality scenario. We provide details for each type of missing modality approaches as follows:\nKD. In knowledge distillation for medical segmentation with missing modality, the process involves two main steps: training the teacher and student models. As previously men-tioned, the teacher model is denoted as the base model T; its objective is in the form of Eq. 1. Notably, previous methods [1], [12], [13] uses no extra regularization for training T, i.e., $\\hat{S}_{KD} := 0$. Meanwhile, for one possible student model $S_j$ encoder and $C_j$ classifier trained with missing modalities that leverages knowledge from T, its objective is:\n$\\max E_{Z_j ~ P(Z_j)} [\\ln P(Y | C_j(Z_j))]$\n$S_j C_j$\n$- D_{KL}(P(S_j(X_j))||P(Z)).$\t(3)\nSLS. For approaches aiming to achieve better-fused repre-sentations from a shared latent space of all modalities, the focus is on enhancing the fusion mechanism of T through additional losses and modifications to model architectures, de-noted as $ \\hat{S}_{SLS}$. However, it is important to note that the current shared latent space (SLS methods often do not adequately address the mitigation of modality gaps.\nDA. Domain adaptation methods address modality gaps by continually adapting the base model T through specific training with missing modality settings. Considering a possible adaptation $S_j$ encoder and $C_j$ classifier derived from T trained with missing modalities, its objective can be simplified as:\n$\\max E_{Z_j ~ P(Z_j)} [\\ln P(Y | C_j(S_j(X_j)))].$\t(4)\n$S_j C_j$\nLimitations. Albeit their impressive results, most existing methods in the mentioned categories share a common limi-tation: they often disregard the potential modality gap in T, which can hinder the performance of missing modality tasks."}, {"title": "B. Alignment in Multi-domain Generalization", "content": "Gaps in the latent space arise not only across various modalities but also span across distinct data domains. To address the domain generalization task, many attempts have been made towards a narrowed gap. For instance, recent efforts [22]\u2013[25] learn domain-independent representations by reducing the gaps to improve generalization to classify im-ages, which are, however, not directly applicable to semantic segmentation. In our research, we borrow the idea from the domain generalization to perform proper alignment between latent distributions in the teacher. To this end, we successfully reduce the modality gaps to overcome the difficulty of missing modality, thereby improving the segmentation of the medical image in all categories."}, {"title": "B. Aligning Medical Multi-modalities", "content": "This section explores an innovative strategy designed to bridge the modality gap, specifically for the base model T. We also demonstrate that our approach can improve many methods across all three categories.\nMinimizing modality gap improve generalization ability of the T. In the context of domain generalization, minimizing the modality gap can be interpreted as reducing the distribu-tional discrepancy between the source domain S and the target domain T as [27]:\n$\\epsilon_{\\mathcal{T}}(h) \\leq \\epsilon_{\\mathcal{S}}(h) + d_{H\\Delta H}(\\mathcal{S},\\mathcal{T}) + \\lambda$\t(6)\nwhere $\\epsilon_{\\mathcal{T}}(h)$ is the error rate of the model on the target domain, $\\epsilon_{\\mathcal{S}}(h)$ is the error rate of the model on the source domain, $d_{H\\Delta H}(\\mathcal{S},\\mathcal{T})$ is the distributional discrepancy between the source and target domains, and $\\lambda$ is a term related to the complexity of the hypothesis space.\nReducing the distributional discrepancy between the source and target domains, thereby reducing $d_{H\\Delta H}(\\mathcal{S},\\mathcal{T})$, which theoretically lowers the error rate on the target domain and thus improves the model's generalization ability. In the modality generalization tasks, reducing $d_{H\\Delta H}$ of different modalities can also improves the model's generalization ability.\nHow to align to the pre-defined anchor $P_{mix}$. Assum-ing that there is a feasible $P_{mix}$ in the latent space which preserves the prediction performance, i.e., the minimization of $\\int L(Z, Y_1) dP(\\theta)$ in Eq. 5 is guaranteed, minimization of Eq. 5 can be changed as:\n$\\min D_{KL}(P(Z)||P_{mix}) + H_c(P(C^*(Z)); P(Y)).$\t(7)\nTo derive an empirical form of minimizing the term $D_{KL}(P(Z)||P_{mix})$, we first introduce Proposition 1:\nProposition 1: For training a multi-modal teacher model, it is assumed that the existence of one modality $Z_i$ is inde-pendent of the other modality $Z_j$ where $i \\in \\{1, ..., J\\}$, $j \\in \\{1, ..., J\\}$, $i \\neq j$. In other words, if one modality is missing or corrupted, other modalities can still exist. In this scenario, there exists a probability distribution $P_{mix}$ that can be used as an anchor distribution to align the latent variables $Z^*$, while preserving sufficient information for accurate prediction of the segmentation labels $Y$.\nProof: The modality existence independent assumption is derived from the fact that each modality is independent of each other. If $P_{mix}$ preserves sufficient information for accurate prediction of the segmentation labels $Y$, based on the joint and marginal mutual information, we have\n$\\sum_{j=1}^J I(P_{mix}(Z^*); P(Z_j)) \\leq I(P_{mix}(Z^*); P(Z^*)).$\t(8)\nEq. 8 shows that individually mapping each modality Zj to $P_{mix}$ is a lower bound of mapping all modalities together to $P_{mix}$.\nProposition 1 is single-letterization that simplifies the op-timization problem over a large-dimensional (i.e., multi-letter) problem. Therefore, we individually align representations of each modality to the anchor $P_{mix}$ rather than the whole distri-bution of all representations from all modalities. Furthermore, the former term of Eq. 8 can be derived as:\n$\\sum_{j=1}^J E_{Z_j~P(Z)} [\\ln P(Y|C^* (Z)) - D_{KL} (P(Z)||P_{mix})],$\t(9)\nwhile the latter term is reformed as:\n$E_{Z^*~P(Z^*)} [\\ln P(Y|C^*(Z^*)) - D_{KL} (P(Z^*)||P_{mix})].$\t(10)\nEq. 9 presents the Evidence Lower Bound (ELBO) and we have Eq. 9 $\\lt$ Eq. 10 which indicates that Eq. 9 is tighter than the latter. Thus, instead of minimizing the gap between all modalities and $P_{mix}$, the alternative objective for T is derived from Eq. 9 as:\n$\\min \\sum_{j=1}^J [D_{KL} (P(Z) || P_{mix}) + H_c(P(C^*(Z^*)); P(Y))].$\t(11)\nAs shown in Eq. 11, the essential point is finding a feasible $P_{mix}$ that anchors all latent features in the space while preserving the prediction ability from the latent features to targets for all downstream adaptations. We introduce possible forms of $P_{mix}$ as follows.\nPossible approximations of pre-defined anchor $P_{mix}$. The selection of $P_{mix}$ is critical for MedMAP and may vary across different base model backbones. Thus, instead of manual selection, we empirically determine that the optimal $P_{mix}$ is a weighted mixture of all modalities' latent feature distributions. Specifically, $P_{mix} = \\sum_{j=1}^J w_jP(Z_j)$ where $w_i$ is the associated weight of each modality. To validate $\\hat{P}_{mix}$, we compare it to two other possible empirical forms of $P_{mix}$: 1) Intuitive selection $P^{k}_{mix}$ where a latent distribution of one modality is selected from ${P(Z_i)}_{i=1}^J$ (i.e., $P_{mix} = P(Z_{i=k})$ where $k \\in J$). 2) Assume that $P_{mix}$ follows a normal dis-tribution denoted as $P_N$. Extensive experiments in Section V demonstrate that using $\\hat{P}_{mix}$ consistently yields improvements across different base model backbones under various missing modality settings. validating $\\hat{P}_{mix}$'s superiority in comparison to $P_k$ and $P_N$"}, {"title": "IV. METHODOLOGY", "content": "MedMAP consists of a feature encoding pipeline and an anchor that latent space of the features will be aligned to. The encoder is a simple convolution that aims to map all the modal-ity features into a shared latent space, so that alignment can be"}, {"title": "B. Backbones", "content": "1) KD: As shown in Fig. 3a, in the KD methods, there are two branches: the teacher, and the student. Teacher models are trained with a full-modality dataset. Student models are trained with an incomplete-modality dataset and soft labels from the teacher model.\nFor training the teacher, each modality is encoded into a shared latent space and then aligned to the pre-defined $P_{mix}$. Specifically, as shown in Eq. 8, each modality representation is individually aligned to $P_{mix}$. The aligned features then become the input to the original teacher backbone. Therefore, the objective of training the teacher will be:\n$\\mathcal{L}_{KD base} = \\mathcal{L}_{seg} + \\alpha \\mathcal{L}_{a},$\t(14)\nwhere Leg is the segmentation loss of teacher and L\u2081 is the alignment loss. a is a parameter which is empirically set to 0.125 in this work. Given that students harness the distilled knowledge from their teachers during training, their perfor-mance serves as a valuable indicator of teacher effectiveness. Therefore, we employ the student performance as a means to validate the feasibility of MedMAP for KD.\nSpecifically, the teacher model remains frozen, which pre-serves the integrity of the pre-learned representations and enables us to concentrate on assessing how effectively the student model can emulate the fixed knowledge rather than updating the teachers during student training. Consequently, the learning process of the student model is supported by the ground truth and the teacher's knowledge with the overall objective L as:\n$\\mathcal{L}_{KD} = \\mathcal{L}_{seg} + \\mathcal{L}^{KD}_{base},$\t(15)\nwhere Leg is the hybrid segmentation loss supervised by the hard labels of the student, and LT denotes the loss that receives supervision from the teacher.\n2) SLS: As shown in Fig. 3c, SLS models always have a modality-specific encoder, a modality fusion encoder, and"}, {"title": "3) DA", "content": "As shown in Fig. 3b, similar to KD, DA also has two branches: the full modality branch and the incomplete modal-ity branch. It distills semantic knowledge by minimizing the Kullback-Leibler (KL) between the two branches. Meanwhile, besides the KL loss, it considers the domain gaps between the full modality model and the incomplete modality model. In ACN [15], it optimizes the hierarchical mutual information by minimizing the mutual information loss (LMI) between these two paths. We argue that we need not only consider the domain gap between the two branches, but also emphasize the domain gap among different modalities. Therefore, we add the MedMAP at the same place with LMI. It is noted that different from KD, DA is a co-training network. The full-modality model will not be frozen when training. Therefore, the whole objective will be:\n$\\mathcal{L}^{DA} = \\mathcal{L}^{F}_{seg} + \\mathcal{L}^{M}_{seg} + \\mathcal{L}_{MI} + \\alpha \\mathcal{L}_{a},$\t(17)\nwhere Leg and Leg seg are the segmentation loss of the full modality model and incomplete model respectively and LA is the alignment loss. a is a parameter which is also set to 0.125 empirically in this paper."}, {"title": "V. EXPERIMENT CONFIGURATIONS", "content": ""}, {"title": "A. Datasets", "content": "The BraTS datasets in 2018 and 2020 [4], [28], consisting of 285 and 369 subjects respectively, are employed for evaluation. Four individual modalities including T1, T1ce, T2, and Flair construct a specific subject, displaying brain tumor sub-regions i.e. enhancing tumor (ET), peritumoral edema (ED), and the necrotic and non-enhancing tumor core (NCR/NET). Specif-ically, each modality captures different properties of brain tumor sub-regions: GD-enhancing tumor (ET), peritumoral edema (ED), and the necrotic and non-enhancing tumor core (NCR/NET), nesting into three key segmentation targets, i.e., whole tumor (WT, ET+ED+NCR/NET), tumor core (TC, ET+NCR/NET), and ET. For both datasets, we use Dice Score"}, {"title": "B. Implementation", "content": "For comparison fairness, we implant the proposed alignment paradigm to retrain each employed backbones [1], [15], [18] following identical respective experimental settings except the dataset configuration and the batch size, given by each author's released codes. The BraTS 2018 dataset is split into training, validation, and testing sets following Proto-KD [13], while the other BraTS 2020 dataset is used with three-fold cross-validations. In contrast to its official version, the batch size of mmFormer [18] is set to 1 and the batch size of PMKL [1] is set to 4 while the others remain the same. Models are implemented on one Nvidia GeForce RTX 3090Ti GPU with Pytorch."}, {"title": "VI. EXPERIMENT RESULTS", "content": "As discussed in Sec. II-A, recent approaches to predict annotations in the Missing Modality scenarios (MM) mainly include Knowledge Distillation (e.g. PMKL [1]), Shared La-tent Space (e.g. mmFormer [18]), and Domain Adaption (e.g. ACN [15]). The proposed Alignment Paradigm will be im-planted into the aforementioned recent SOTAs to evaluate the effectiveness. Specifically, Section VI-A will present statistical improvements given by the proposed MedMAP, measured by averaged dice as well as improvement (marked in red) and decline (in blue) in Table I. Details can also be found across various MM on both datasets in Table II. Sec. VI-B visualizes examples with and without Pmix. In Sec. VI-C, we compare several possible structures in key components of the proposed MedMAP, which guide us to find the most suitable encoder and anchor. In Sec. VI-D, the selection of hyperparameters will be introduced."}, {"title": "A. Quantitative Comparisons", "content": "As seen from Table I, we can conclude that the proposed MedMAP effectively promotes the prediction performance. Specifically, on the BraTS2018 dataset, it improves 3.68%, 7.67%, and 2.30% of the Dice Scores on PMKL, mmFormer, and ACN respectively. Improvements are 1.31%, 6.76%, and 0.38% of the Dice Scores on PMKL, mmFormer, and ACN respectively on the BraTS2020 dataset.\nNotably, on both datasets, predictions obtain lower dice scores on TC and ET than on the WT. The presence of the proposed MedMAP significantly promotes the degraded pre-dictions of TC and ET by 4.97% and 11.72% respectively on BraTS2018, and 2.99% and 15.29% on BraTS2020. Moreover,"}, {"title": "B. Qualitative Comparison", "content": "We can observe from Fig. 4 that in general, the performance of the model with $P_{mix}$is superior to that without it. When"}, {"title": "C. Comparison of Alignment Paradigm components", "content": "As part of the proposed MedMAP with an encoder and an aligning anchor, we conduct ablation studies to evaluate the effectiveness of both components. Regarding the encoder, we compare the enhanced and the non-shared encoder. For the anchor $P_{mix}$, we compare the proposed $P_{mix}$ with the standard normal distribution [30]. Furthermore, we assess two different $P_{mix}$ options namely $P^{k}_{mix}$ and $\\hat{P}_{mix}$"}, {"title": "1) Encoder", "content": "As discussed in Sec. IV-A, the proposed align-ment paradigm will only be possible when latent features are placed in the same space, by using some encoding architec-tures. In this sense, we would like to evaluate the prediction performance based on two different encoder configurations: the non-shared encoder and the enhanced encoder, termed as non-shared $\\mathcal{T}$ and $\\mathcal{T^*}$, respectively. In non-shared $\\mathcal{T}$, an"}, {"title": "VII. CONCLUSION", "content": "In this paper, we present a novel Medical Modality Align-ment Paradigm to mitigate the modality gaps whilst learning simultaneously invariant feature representations in segmenting brain tumors with missing modalities. Specifically, we invent an alignment paradigm for the models with an encoder encour-aging that all modalities are in the same space and a latent space distribution $P_{mix}^*$ as the aligning anchor. Meanwhile, we provide theoretical support for the proposed alignment paradigm, demonstrating that individual alignment of each modality to $P_{mix}$ certifies a tighter evidence lower bound than mapping all modalities as a whole. Extensive experiments have demonstrated the superiority of the proposed paradigm over several latest state-of-the-art approaches, enabling better segment the brain tumor with missing modalities."}]}