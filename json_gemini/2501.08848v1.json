{"title": "RouteNet-Gauss: Hardware-Enhanced Network Modeling with Machine Learning", "authors": ["Carlos G\u00fcemes-Palau", "Miquel Ferriol-Galm\u00e9s", "Jordi Paillisse-Vilanova", "Albert L\u00f3pez-Bresc\u00f3", "Pere Barlet-Ros", "Albert Cabellos-Aparicio"], "abstract": "Network simulation is pivotal in network modeling, assisting with tasks ranging from capacity planning to perfor- mance estimation. Traditional approaches such as Discrete Event Simulation (DES) face limitations in terms of computational cost and accuracy. This paper introduces RouteNet-Gauss, a novel integration of a testbed network with a Machine Learning (ML) model to address these challenges. By using the testbed as a hardware accelerator, RouteNet-Gauss generates training datasets rapidly and simulates network scenarios with high fidelity to real-world conditions. Experimental results show that RouteNet-Gauss significantly reduces prediction errors by up to 95% and achieves a 488x speedup in inference time com- pared to state-of-the-art DES-based methods. RouteNet-Gauss's modular architecture is dynamically constructed based on the specific characteristics of the network scenario, such as topology and routing. This enables it to understand and generalize to different network configurations beyond those seen during training, including networks up to 10x larger. Additionally, it supports Temporal Aggregated Performance Estimation (TAPE), providing configurable temporal granularity and maintaining high accuracy in flow performance metrics. This approach shows promise in improving both simulation efficiency and accuracy, offering a valuable tool for network operators.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, there has been significant progress in the development of accurate network models, which have become essential tools for network operators. These models play a pivotal role in facilitating various tasks, including capacity planning [1], topology design [2], and traffic engineering [3]. By providing a controlled and safe environment for testing network configurations, these models eliminate the need to modify production networks directly. This capability enables researchers and operators to explore scenarios that would otherwise be too risky or impractical to test in operational environments.\nA widely adopted approach to building these network models involves the use of Discrete Event Simulation (DES) methodologies, such as ns-3 [4] and OMNET++ [5]. DES- based models are highly valued for their ability to provide packet-level visibility, enabling detailed tracking of individual packets as they traverse a network. This level of granularity has made DES methodologies a standard in a wide range of applications, including protocol debugging, performance estimation, topology design, and SLA assurance. However, these models also face notable challenges (explored more thoroughly in Section II):\n1) Issue #1 - Computational Complexity: DES-based sim- ulators are computationally intensive, as they simulate each individual event in a network (e.g., packet trans- mission), which can become prohibitive in scenarios involving millions or billions of packets per second [6].\n2) Issue #2 - Potential Inaccuracies: DES-based simulators often rely on idealized assumptions and scenarios, which may not fully capture the complexities of real-world networks [7], [8]. Furthermore, the lack of access to proprietary details, such as the precise configurations of commercial hardware devices (e.g., queue sizes), potentially limits their accuracy.\nSignificant research efforts have focused on reducing the computational cost of DES-based simulations. For example, novel DES designs like DONS [9] have introduced paralleliza- tion techniques, achieving remarkable speedups up to 65 times faster than the standard OMNeT++. Similarly, hybrid approaches such as DeepQueueNet (DQN) [10] leverage Ma- chine Learning (ML) models to accelerate specific components of the simulation pipeline, offering comparable efficiency im- provements. These advances represent significant steps toward improving simulation performance. However, these methods do not address Issue #2, and are therefore constrained by the accuracy ceiling of DES itself. This includes ML models trained on simulated data [6], [9]\u2013[11].\nIn this paper, we propose a hybrid approach that combines a network testbed with Machine Learning (ML) to address both Issue #1 and Issue #2. By leveraging real data from a network testbed, we aim to enhance the accuracy of network modeling and bridge the gap inherent in DES-based solutions (Issue #2). Additionally, the testbed's capability to execute network scenarios at line rate enables the model to capture the performance characteristics of high-speed traffic while maintaining efficient inference times (Issue #1).\nThis approach, however, involves a trade-off. To ensure computational efficiency when modeling high-speed traffic, our method operates at flow-level granularity rather than packet-level granularity. While many existing solutions rely on packet-level analysis, flow-level granularity can effectively meet the requirements of various network operation tasks, such as capacity planning, QoS assurance, topology design, traffic engineering, and performance estimation [6], [11], [12]. This simplification is particularly suited for scenarios where aggregated flow-level information provides sufficient detail for practical applications.\nWith this in mind, we introduce RouteNet-Gauss (hereafter referred to as RouteNet-G), an ML-based model trained on a representative dataset generated from a real-world testbed"}, {"title": "II. MOTIVATION", "content": "Discrete Event Simulation (DES) remains one of the most commonly used tools for network operators to model network scenarios. DES works by breaking down network activity into discrete \"events,\u201d such as packet generation, traversal through physical links, queuing, and eventual exit from the network. Each event is processed sequentially, updating the overall network state to simulate its behavior. This level of detail gives DES a high degree of accuracy, provided that the simulator faithfully updates the scenario's state to reflect real- world conditions.\nDespite its strengths, the event-driven design of DES in- troduces certain limitations, particularly when it comes to parallelization. Simulators like ns-3 [4] and OMNET++ [5] struggle with efficiently parallelizing event processing due to the inherent sequential nature of identifying and processing events. While these tools can divide network scenarios into smaller segments to process independently, events that span across multiple segments require inter-process communication. This overhead can significantly reduce overall performance and scalability [9].\nTo address these limitations, current state-of-the-art solu- tions focus on enhancing DES-based simulators with paral- lelization techniques (e.g., DONS [9]) or by incorporating ML models to improve performance (e.g., DQN [10]). While these approaches have made notable progress, DES-based simulations remain computationally expensive. Even with par- allelization, the huge volume of events in large-scale network scenarios can make processing impractical. For instance, a single 1 Gbps link may process 250,000 500-byte packets per second, illustrating the immense computational demand of DES-based methods."}, {"title": "A. DES's elevated computational cost", "content": "To illustrate the high computational cost of DES, we refer to Figure 2, showing the relationship between simulation time and the number of packets in a network scenario. This analysis is performed by using the same network setup while incre- mentally increasing the traffic volume. The dashed lines in the figure provide an approximation of the expected simulation times as the number of packets grows. Additionally, the dotted"}, {"title": "B. Inaccuracy of DES when compared to reality", "content": "Another important but less frequently discussed challenge is the inaccuracies inherent in DES-based simulators. These tools are designed to model the behavior of network devices under specific scenarios. However, they often face limitations when the precise design and implementation details of commercial devices are unavailable, either due to proprietary restrictions or lack of documentation. This gap in information can lead to discrepancies between simulated and real-world results.\nTo demonstrate the extent of these inaccuracies, we con- ducted an experiment comparing the predictions of OMNET++ with actual measurements obtained from running the same network scenarios on a physical testbed. The results from these traffic scenarios are further analyzed in Section V to assess the accuracy and reliability of the proposed solution.\nThe results are summarized in Table I. The Mean Abso- lute Percentage Error (MAPE) and the Mean Absolute Error (MAE) were used to measure the discrepancies between the simulator's predictions and the actual testbed measurements. The results show that the simulator introduces a significant error, with MAPE values ranging from 46% to 54%, depending on the traffic distribution. In absolute terms, this corresponds to an average deviation of 62 to 80 \u00b5s in the mean packet"}, {"title": "III. ROUTENET-GAUSS", "content": "In the following section, we propose RouteNet-G to address the limitations of existing simulation-based methods. By train- ing on high-fidelity data from a physical testbed, RouteNet-G learns the intricate interactions between network components, enabling it to generalize effectively to unseen network sce- narios. We first explain the intuition behind RouteNet-G and then describe its architecture, highlighting how it captures and leverages these interactions."}, {"title": "A. RouteNet-Gauss's network decomposition", "content": "RouteNet-G takes as input a network scenario, including the traffic, routing, and network configuration, and outputs per- flow performance metrics. This includes critical metrics such as delay, packet loss, and queue occupancy. By training on high-fidelity testbed data, RouteNet-G is designed to model these scenarios accurately while maintaining the flexibility to generalize to unseen network topologies and configurations.\nA straightforward approach \u2014such as to model the entire network as a single neural network trained end-to-end- might seem appealing but introduces critical challenges. Specifi- cally, such an architecture would be heavily biased toward the specific topologies and scenarios used during training, making it difficult to generalize to unseen or larger networks. To overcome this, RouteNet-G adopts a divide-and-conquer strategy: it models the individual elements in the network (i.\u0435., queues, links, devices, and flows) and, more importantly, learns how these elements interact.\nTo do so, the simplest solution would consist on creating a graph that connects the different devices according to the network topology. However, this is not sufficiently detailed to capture the complexities of computer networks. For instance, a forwarding device that has several ports in it may or may not be affected by the status of the other devices, depending on the traffic present. Instead, RouteNet-G builds an extended graph that reflects the finer-grained interactions between network"}, {"title": "B. RouteNet-Gauss's temporal reasoning decomposition", "content": "RouteNet-G incorporates the temporal dimension, striking a balance between computational efficiency and model ex- pressiveness. Unlike traditional methods that either ignore the temporal aspect with aggregated predictions or process indi- vidual packets at high computational cost, RouteNet-G uses a middle-ground approach. It divides the network scenario into fixed-sized time windows and generates predictions for each window. This allows users to adjust the window size to suit their needs, balancing precision and efficiency. Although each window is processed independently, RouteNet-G reintroduces state dependencies using its internal state representations of network elements, encoding temporal information. This gives RouteNet-G the ability to handle scenarios with non-stationary traffic patterns.\nFor flows and links, RouteNet-G defines their initial state using measurable time-dependent metrics (e.g., current flow bandwidth and link load). This is not an option for queues and network devices, whose characteristics might be hard to measure in real-time (e.g., queue occupancy) or unaffected by time (e.g., buffer size). Instead, RouteNet-G uses these static descriptions to build the initial state in the first window. Then, the final internal states from one window become the initial states for the next, ensuring temporal continuity."}, {"title": "C. RouteNet-Gauss's architecture", "content": "We now proceed to explain RouteNet-G's architecture, which follows the same three-part structure as MPNNs: (1) encoding of the internal states for each element, (2) the"}, {"title": "Algorithm 1 RouteNet-Gauss", "content": "Input: F, L, Q, N, X f , X1, X q\nOutput: y f\n1: for all q \u2208 Q do h\u00ba) \u2190 Eq(xq)\n2: for all d\u2208 N do\n3:\nMa - \u03a3 h\u00ba\n4: h\u2190UD(M; 0)\n5: for t 0 to T-1 do\n6:\nfor all f\u2208 F do ht \u2190 Ef(x))\n7:\nfor all l\u2208 L do h\n(t)\nht\u2190 E1(x(t))\n8:\nYf,\n\u00fbt), {h(t+1)\\q \u2208 Q}, {h(t+1)\\d\n(t+1) Vd \u2208 D} \u2190\nMP({h\\\u221af \u2208 F}, {h{\\\u2200l \u2208 L}, {h{\\\u2200q \u2208\nQ}, {hd \u2208 D})"}, {"title": "Algorithm 2 Message Passing Algorithm", "content": "Input: hhhh\u2084;\u2200f \u2208 F,l \u2208 L, q \u2208 Q, d \u2208 N\nT\nOutput: yf, ha, h;\u2200f \u2208 F, q \u2208 Q, d \u2208 N\n1: for t 1 to T do\n2:\nfor all f\u2208 F do\n3:\npos - 0\n4:\nh\u2190h\n5:\nfor all (l, q) \u2208 f do\n6:\nmf,pos, h\u2190 UF(h-1h-1h)\n7:\npos pos +1\n8:\nfor all q\u2208Q do\n9:\nM\u2190\nQd(q)\nhaa\n(f,pos)\u2208Qf(q) M(f,pos)\n10:\nh0UQ(Mh1)\n11:\nmtha\n12:\nfor all de D do\n13:\n\u039c - \u03a3ged m\n14:\nha,\u2190UD(M; h)\n15:\nfor all le L do\n16:\nMm\nQq(1)\n17:\nhig, UL (Mig; ha\u00b9)\n18:\nmlahia\n19: for all f\u2208 F do\n20:\n\u0177f Empos em R(mf,pos)\nThe MP phase is presented in Algorithm 2, lines 1-18. It is an iterative process, in which the internal states of each element are updated according to their interactions with each other. The outer loop represents the number of times the states of the network elements are updated. In its body, the \"building blocks\" NNs introduced back in Section III-A are executed, here referred to as update functions U. Each function takes as input the relevant network elements and updates the current one. Note again that the same U functions are applied for all network elements and across all windows, as otherwise, the model would not adapt to unseen topologies. All of these functions are modeled through the use of Gated Recurrent Unit (GRU) [18] cells. Finally, in the readout phase (lines 19- 20), the readout function R takes as input the final flow states and returns the predicted performance metrics. Function R is implemented through an MLP."}, {"title": "IV. TESTBED IMPLEMENTATION", "content": "In the following section, we cover the specific testbed implementation used to run network scenarios. The testbed, illustrated at Figure 4, is summarized as follows:\n\u2022\n\u2022\n\u2022\n\u2022\nThe testbed comprises 8 Huawei NetEngine 8000 M1A routers connected to one of the two Huawei S5732- H48UM 2CC 5G Bundle switches.\nThe switches act as the backbone, connecting the routers, and using VLANs to generate the desired topology.\nA server generates the traffic, assigning a pool of ad- dresses and VLANs per path, which is then forwarded through the network and back. TREX software is used to generate synthetic traffic.\nThe traffic-generating server is connected to one of the switches. Traffic going through this connection is copied using the optical splitter and then sent to the packet capture server. The packet capture server runs custom- made software, which utilizes the DPDK framework and a Network Interface Controller, to record the hardware timestamp of each captured packet.\nDifferent link bandwidths are chosen to be representative of those in modern networks:\nLinks between routers and switches are 1 Gbps each.\nLinks between switches and the traffic generator and the packet capture server are 10 Gbps each."}, {"title": "V. EVALUATION", "content": "To assess our claims, we have implemented RouteNet-G and trained it on network scenarios generated from the testbed network to answer the following questions:\n\u2022\n\u2022\n\u2022\n\u2022\nDoes RouteNet-G improve the computational cost com- pared to DES (Issue #1)?\nDoes RouteNet-G improve prediction accuracy compared to DES (Issue #2)?\nDoes RouteNet-G generalize to unseen network scenarios with differing amounts of traffic and network sizes?\nWhat is the impact of RouteNet-G's temporal aggrega- tion?\nAll the following experiments use a server with an AMD Ryzen 9 3950X 16-Core 32 Threads 3.5 GHz CPU and 64 GiB of RAM. This server uses Ubuntu 22.04 LTS as its oper- ating system. We implemented RouteNet-G using TensorFlow 2.11 [19]. The implementation details and source code are recollected both in Appendix A and in a public repository\u00b9."}, {"title": "A. Evaluation of RouteNet-G's temporal cost", "content": "First, we compare RouteNet-G's performance in evaluating network scenarios against current state-of-the-art methods. We specifically assess the inference time of the trained RouteNet-G model relative to other alternatives, including OMNET++ [5], DONS [9], and DQN [10]. Both RouteNet-G and the baseline methods are executed in a single thread, ex- cept for DQN, which utilizes 4 GPUs. The scenarios evaluated correspond to those illustrated in Figure 2, back in Section II. We analyze the inference time required by each method to process these scenarios and generate its corresponding predictions."}, {"title": "B. Evaluation of RouteNet-G's accuracy", "content": "Next, we evaluate RouteNet-G's accuracy when predicting flow performance metrics compared to OMNET++ [5]. As discussed earlier, current state-of-the-art solutions are either DES-based simulators (e.g., DONS, Parsimon) or ML models trained with samples generated through DES (e.g., DQN). Hence, using OMNET++, an established DES-based simulator, acts as an upper bound for the accuracy achievable by the current network modeling solutions based on DES.\nIn each network scenario, we compare the per-flow and per-window metrics computed by RouteNet-G and OMNET++. For instance, when predicting the average packet delay, we consider packets generated within the same flow and during the same temporal window. For each flow-window pair, we extract metrics such as the average, median, 90th, 95th, and 99th percentiles of the packet delays and jitter. While the model could also be used to predict other performance metrics, such as the packet loss rate, we decided to focus on the delay and jitter as they are two of the most commonly studied performance metrics in network modeling. The RouteNet-G model is trained using three datasets, each using a different traffic distribution, generated in our testbed:\n1) TREX Synthetic (TREX-S): packets are generated in regular-high frequency bursts, each under 1 ms.\n2) TREX Multi-burst (TREX-MB): packets are generated from synthetic multiple burst distributions, each defined by their intensity and spacing between bursts. The gen- erated packets at a given instant are the sum of packets generated by each of the defined burst distributions.\n3) Real-World Packet Traces (RWPT): generated flows fol- low the traffic distribution from real-world traffic traces in the MAWI Working Group Traffic Archive [20].\nFor each distribution 1823, 700, and 2190 samples were generated, respectively, and then split into training, validation, and test partitions following a 75/15/10 ratio. Partitioning the datasets is common practice to later ensure that the model has not over-fitted to the training data. Each of the samples in these datasets represents a network scenario, consisting of a combination of network topology, input traffic, routing configuration, and a collection of per-flow metrics. Each"}, {"title": "C. RouteNet-Gauss's generalization", "content": "One of the key aspects of RouteNet-G is its generaliza- tion capabilities when working with unseen scenarios. In the previous sections, we showed RouteNet-G's ability to model different traffic distributions and generalize across topologies. In this section, we focus on proving RouteNet-G's generaliza- tion towards larger, unseen topologies than those seen during training. This property is essential to RouteNet-G's ability to work on production networks, as it would be prohibitively expensive to build a testbed network that size. Similarly, our testbed network is limited to up to 8 node configurations, so we exceptionally use simulated samples to generate the training and evaluation samples to test RouteNet-G's generalization capabilities. We argue that the source of the data does not condition RouteNet-G's ability to generalize.\nIn this section, the RouteNet-G model is trained using network scenarios with topologies ranging from 5-8 nodes and then evaluated in unseen topologies with up to 110 nodes gathered from the Topology Zoo repository [21]. Samples followed the TREX-MB traffic distribution. The model was tasked to predict the average packet delay per-packet and per-window. The results are illustrated in Figure 8. The bar plot"}, {"title": "D. Impact of RouteNet-G's temporal aggregation", "content": "In this section, we explore how RouteNet-G's temporal aggregation affects its predictions, its accuracy, and its costs. Figure 9 illustrates how the introduction of temporal ag- gregation in RouteNet-G offers a significant enhancement in predictive granularity. This figure shows three randomly selected flows, each lasting 5 seconds and divided into 100ms windows. When utilizing windows, the predictions exhibit a detailed view of flow behavior, showcasing variations over"}, {"title": "VI. DISCUSSION AND LIMITATIONS", "content": "This paper proposes a novel approach to improve the accu- racy of network modeling by leveraging a testbed for training. By grounding the model in real-world data, we aim to address the limitations of simulation-based methods while enabling it to generalize to production networks, which are often much larger and more complex than the testbed used for training. This balance between high-fidelity data and scalability is at the core of RouteNet-G's design."}, {"title": "A. Generalization to larger networks", "content": "One of the standout aspects of RouteNet-G is its ability to generalize to unseen network topologies, including those significantly larger than the ones encountered during train- ing. This is achieved through the model's ability to learn how various network components such as links, queues, routers, switches, and flows interact during training. Since these interactions remain similar independently on the network topology, it allows RouteNet-G to predict performance metrics in unseen network topologies. This applies for even networks of orders of magnitude larger than those in the training set, as evidenced in Section V-C.\nHowever, for this property to hold, the training set for RouteNet-G must be diverse to cover as many interactions present in production networks as possible. Hence, correct"}, {"title": "B. Handling arbitrary traffic distributions", "content": "One way RouteNet-G differs from its predecessors, like RouteNet-Fermi, is how it encodes traffic information. Unlike them, RouteNet-G neither makes assumptions about the flow's traffic distribution nor uses parameters of such distributions as part of its input. Instead, RouteNet-G describes flows utilizing the evolution of the traffic bandwidth and packet rate over the scenario duration.\nThis allows RouteNet-G to learn realistic non-parametric traffic flows, such as the RWPT dataset (Section V-B). How- ever, unlike the features used to characterize link capacity, these are scale-dependent. Consequently, the model performs well with traffic distributions similar to those seen during train- ing but may struggle if drastically different. Addressing this limitation would require replacing scale-dependent features with invariant alternatives in future work."}, {"title": "C. Hardware and protocol limitations", "content": "While RouteNet-G demonstrates strong generalization to network sizes, it faces challenges when encountering entirely new types of data. Like most ML-based models, it relies on training data to understand patterns and may falter with unseen hardware or protocols. For example:\n\u2022\nHardware Variability: RouteNet-G was trained on a spe- cific set of routers and switches. For deployment in networks with devices from different manufacturers, addi- tional training with data from those devices would likely be necessary."}, {"title": "D. Impact of the temporal component and TAPE", "content": "One of the key innovations of RouteNet-G is its ability to work with different temporal granularities (TAPE). While previous RouteNet versions, including RouteNet-Fermi [11], assume stationary traffic, RouteNet-G relaxes the assumption by only expecting stationary traffic within the same window. As a result, it can model non-stationary traffic by analyzing it within time windows of an appropriate size\u2014that is, the more volatile the traffic, the smaller the windows.\nThat said, this flexibility comes with some trade-offs. First, as explored in Section V-D, smaller windows result in increased inference cost, albeit still under the cost of running the same scenario in DES-based alternatives. Second, RouteNet-G must be retrained if users need to work with different time scales. For example, predictions made using 10ms windows cannot simply be extrapolated to a 1ms window without retraining. While these limitations do not diminish the current contributions, they highlight an area for future im- provement-such as enabling dynamic adaptation to multiple time scales."}, {"title": "VII. RELATED WORKS", "content": "The field of network modeling via simulation has a long trajectory within network research, with early works such as REAL [23] dating back to 1988. Nevertheless, thanks to new technologies and programming paradigms, such as Machine Learning, the field is continuing to evolve even as of today.\nOriginally, network modeling research fell into one of two fields: simulation and analytical models. Analytical models such as Queuing Theory and Network Calculus [24], [25], benefited from quick inference time relative to simulation. However, these models fell out of favor due to their stringent assumptions, such as using over-simplistic distributions (e.g. Poisson distribution) to describe network traffic, which is measured to be auto-correlated with a heavy tail [26]-[28].\nArguably, Discrete Event Simulation (DES) is one of the most widespread tools to simulate any kind of network to obtain performance estimations. Paramount examples are NS-3 [4] and OMNET++ [5], two network simulators with a large community, and the possibility to add plugins to ex- pand their functionalities. As we mentioned, these simulators offer packet-level visibility, albeit with a high computational cost [29]. Therefore, we can find multiple proposals that aim to accelerate these simulators without losing packet-level"}, {"title": "VIII. CONCLUSIONS", "content": "In summary, this paper introduces a novel approach to enhance the cost-effectiveness and accuracy of network mod- eling by replacing DES with real network hardware. Through the utilization of a testbed network instead of a DES-based simulator, we address both computational cost concerns and inaccuracies arising from idealized scenario assumptions.\nUsing this approach we propose RouteNet-Gauss, a modular ML model trained using samples obtained from an imple- mented testbed network, whose architecture can adapt to the"}, {"title": "APPENDIX A", "content": "ROUTENET-GAUSS HYPERPARAMETERS"}]}