{"title": "Whisper D-SGD: Correlated Noise Across Agents for Differentially Private Decentralized Learning", "authors": ["Angelo Rodio", "Zheng Chen", "Erik G. Larsson"], "abstract": "Decentralized learning enables distributed agents to train a shared machine learning model through local computation and peer-to-peer communication. Although each agent retains its dataset locally, the communication of local models can still expose private information to adversaries. To mitigate these threats, local differential privacy (LDP) injects independent noise per agent, but it suffers a larger utility gap than central differential privacy (CDP). We introduce Whisper D-SGD, a novel covariance-based approach that generates correlated privacy noise across agents, unifying several state-of-the-art methods as special cases. By leveraging network topology and mixing weights, Whisper D-SGD optimizes the noise covariance to achieve network-wide noise cancellation. Experimental results show that Whisper D-SGD cancels more noise than existing pairwise-correlation schemes, substantially narrowing the CDP-LDP gap and improving model performance under the same privacy guarantees.", "sections": [{"title": "I. INTRODUCTION", "content": "Training machine learning models traditionally involves centralizing data on a single server, which raises scalability and privacy risks [1]. To address these issues, federated learning allows distributed agents (e.g., personal devices, organization, or computing nodes in a network) to retain their data locally while sharing only data-dependent computations (e.g., local gradients or models) with a central server [2], [3]. Decentralized learning further removes the need for a central server by allowing agents to update local models and mix them directly with neighbors according to predefined mixing weights [4]\u2013[7]. Although federated and decentralized learning algorithms avoid sharing raw data over the network, local models may still expose sensitive information to adversaries- i.e., external eavesdroppers-through attacks, e.g., membership inference or gradient inversion [8].\nA widely adopted theoretical framework for mitigating such threats is differential privacy (DP), which involves injecting random noise into data-dependent computations, under strong, formal privacy guarantees [9]. While the privacy-utility trade- off of DP has been extensively studied in the central DP (CDP) setting-where a server injects noise on the central model [10]\u2013[12]-adapting DP to decentralized settings proves substantially more challenging. Under the local DP (LDP) setting [13], [14], each agent individually adds noise to its local model before mixing, protecting its local dataset from eavesdroppers. However, LDP demands substantially more noise than CDP to attain the same privacy guarantees [15].\nRecent works on differentially private decentralized learning seek to reconcile the utility of CDP with the local privacy of LDP by combining (i) a small amount of independent noise per agent, sufficient to ensure local privacy, and (ii) a large amount of correlated noise among agents, designed to cancel out dur- ing mixing [16]\u2013[18]. In principle, this cancellation preserves local privacy while reducing the overall noise after mixing, such that the learned models approach CDP-level utility. Among these works, [16], [17] rely on zero-sum correlation, which is well-suited for addressing honest-but-curious internal neighbors, but ineffective against external eavesdroppers as no privacy noise persists in the final model. Meanwhile, [18] proposes pairwise-canceling correlated noise, which restricts noise correlation to pairs of neighboring agents, overlooking how local models are mixed across the network and limiting the potential for broader correlation design.\nIn this paper, we argue that extending beyond pair- wise, neighbor-only correlations can significantly improve the privacy-utility trade-off in decentralized learning. The key contributions of this paper are as follows:\n\u2022 We present a novel, covariance-based framework for the design of correlated noise across agents, that recovers state-of-the-art approaches as special cases;\n\u2022 We generalize existing analyses on the privacy-utility tradeoff, showing that the optimal covariance matrix must account for the network topology and mixing weights. Building on this insight, we propose the Whisper D- SGD algorithm, which optimizes the noise covariance to reconcile CDP-level utility with LDP-level privacy.\nExperiments with various privacy budgets and network con- nectivity levels show that Whisper D-SGD amplifies noise can- cellation over pairwise approaches, achieving superior privacy- utility trade-offs, particularly in weakly connected networks."}, {"title": "II. PRIVACY-PRESERVING DECENTRALIZED LEARNING", "content": "We consider n agents, V = {1,...,n}, each with a local dataset D\u2081, aiming to learn the parameters x \u2208 Rd of a shared machine learning model, by minimizing the global objective:\n$$F(x)=\\frac{1}{n}\\sum_{i=1}^{n}F_i(x) \\triangleq \\frac{1}{n}\\sum_{i=1}^{n}l(x,\\xi_i),$$\nwhere l(x, \u00a7i) is the loss of parameter x on sample \u00a7i \u2208 Di and F(x) is the local objective, known only to agent i. Agents communicate over a network modeled by an undirected graph G = (V,E), where an edge (i, j) \u2208 E indicates that agents i and j are neighbors, i.e., they can directly communicate. For simplicity, we present the case of scalar parameters (d = 1), with straightforward extension to vector parameters."}, {"title": "A. Decentralized Stochastic Gradient Descent (D-SGD)", "content": "Problem (1) is commonly solved via decentralized optimiza- tion algorithms like Decentralized Stochastic Gradient Descent (D-SGD) [6]. Each iteration t \u2208 {1, . . ., T} involves two steps:\na) Local step: Each agent i samples $\\xi_i^{(t)} \\sim D_i$, computes stochastic gradient $g_i^{(t)} = l'(x_i^{(t)}, \\xi_i^{(t)})$, and updates parameter:\n$$x_i^{(t+1)} = x_i^{(t)} - \\eta_t g_i^{(t)},$$\nwhere \u03b7t is the step-size.\nb) Mixing step: Agents exchange parameters with neighbors and compute a weighted average:\n$$x_i^{(t+1)} = \\sum_{j=1}^{n} W_{ij}x_j^{(t+1)},$$\nwhere $W_{ij} \\triangleq [W]_{ij}$ are mixing weights defined by the mixing matrix W\u2208 Rnxn, with Wij = 0 whenever (i,j) \u2209 E. Convergence conditions for D-SGD require W to be doubly stochastic (W1 = 1 and 1TW = 1T) and the second largest eigenvalue \u03bb2(WTW) strictly below one [19, Section II.B]."}, {"title": "B. Differentially Private D-SGD", "content": "The DP framework protects the final models {$x_i^{(T)}$}$_{i=1}^n$ against adversaries (e.g., external eavesdroppers). At each iteration t, agent i clips its local gradient $g_i^{(t)}$ to norm C, then adds privacy noise $v_i^{(t)}$:\n$$\\hat{g}_i^{(t)} = g_i^{(t)} + v_i^{(t)},\\quad g_i^{(t)} = \\min\\bigg\\{ 1,\\frac{C}{\\|g_i^{(t)}\\|}\\bigg\\}g_i^{(t)}.$$\nThe resulting update is $x_i^{(t+1)} = \\sum_{j=1}^{n}W_{ij} (x_j^{(t)} - \\eta_t \\hat{g}_j^{(t)})$. By relating $v_i^{(t)}$ to privacy parameters (\u03b5, \u03b4), the DP frame- work guarantees that the final models {$x_i^{(T)}$}$_{i=1}^n$, trained on any adjacent datasets D, D' (differing in at most one agent's dataset) satisfy, for any measurable set S in the parameter space:\n$$P[\\hat{x}_i^{(T)} (D) \\in S] \\leq e^{\\epsilon}P[\\hat{x}_i^{(T)} (D') \\in S] + \\delta.$$\nCommon designs for $v_i^{(t)}$ include:\n1) LDP [13], [14]. This is the standard approach, with pri- vacy noise $v_i^{(t)}$ ~N(0, $\\sigma_{ldp}^2$) independent across agents;\n2) DECOR [18]. The privacy noise is designed as $v_i^{(t)} = u_i^{(t)} + \\sum_{j\\in N_i} v_{ji}^{(t)}$, where $u_i^{(t)}$ ~N(0, $\\sigma_{pair}^2$) is independent local noise, and each pair of neighbors (i, j) \u2208 E shares a correlated noise term $v_{ij}^{(t)} = -v_{ji}^{(t)}$ ~ N(0, $\\sigma_{cor}^2$) that cancel during mixing. Distinct pairs of neighbors produce mutually uncorrelated components, so that $v_{ij}^{(t)}$ is independent of $v_{kl}^{(t)}$ whenever {i, j} \u2229 {k, l} = \u2205."}, {"title": "III. A COVARIANCE-BASED FRAMEWORK FOR GENERATING CORRELATED NOISE ACROSS AGENTS", "content": "We reinterpret the differentially private D-SGD framework from a noise-covariance perspective. Instead of drawing noise components {$v_i^{(t)}$}$_{i=1}^n$ independently or from pairwise correla- tions, we allow agents to sample from a multivariate Gaussian:\n$$[v_1^{(t)},..., v_n^{(t)}] \\triangleq v^{(t)} ~ N(0, R),$$\nwhere R \u2208 Rnxn is an arbitrary covariance matrix. By defining x(t) = $[x_1^{(t)},...,x_n^{(t)}]$ and g(t) = $[g_1^{(t)},...,g_n^{(t)}]$, the perturbed model-update at iteration t becomes:\n$$x^{(t+1)} = W (x^{(t)} \u2013 \\eta g^{(t)}).$$This covariance-based approach offers several advantages:\n(i) it allows for more flexible correlation structures with noise cancellation beyond pairs of neighbors; (ii) it is directly applicable to directed graphs, unlike pairwise correlation; and (iii) it recovers state-of-the-art approaches as special cases:\n1) LDP. With independent noise, the covariance matrix is R = $\\sigma_{ldp}^2$In, where In \u2208 Rn\u00d7n is the identity matrix;\n2) DECOR. The independent noise term $u_i^{(t)}$ ~N(0, $\\sigma_{pair}^2$) contributes $\\sigma_{pair}^2$In to R. In addition, each edge (i, j) \u2208 E adds a pairwise correlated component $v_{ij}^{(t)} = -v_{ji}^{(t)}$ ~N(0, $\\sigma_{cor}^2$). In matrix form, each edge contributes $\\sigma_{cor}^2$(ei-ej)(ei-ej)T, where ez is the i-th standard basis vector, and summing over all edges yields $\\sigma_{cor}^2$ L, where L = $ \\sum_{(i,j)\\in\\varepsilon} (e_i \u2013 e_j)(e_i \u2013 e_j)^T$ is the undirected graph Laplacian. The total covariance is R = $\\sigma_{pair}^2$ In + $\\sigma_{cor}^2$L.\nRemark 1. The privacy noise generation mechanism v(t) ~ N(0,R) can be implemented in a distributed fashion. A common practice is to share R and a random seed s among the agents. At iteration t, each agent independently samples s(t) ~ N(0, In) using the random seed s and then locally computes v(t) = R1/2s(t).\nThe covariance matrix R controls both the level of privacy (in terms of (\u03b5, \u03b4)-DP guarantees) and the model-update variance (hence convergence speed or utility). Intuitively, the noise must be \u201csufficiently large\u201d to ensure LDP-level privacy, yet \u201csufficiently small\u201d to achieve CDP-level utility."}, {"title": "IV. PRIVACY-UTILITY ANALYSIS", "content": "In this section, we study how the correlated noise in our general framework affects both convergence (utility) perfor- mance and (\u03b5, \u03b4)-DP (privacy) level. Our analysis shows the interplay between noise covariance R and mixing matrix W, yielding new insights into optimal noise design strategies.\nA. Utility Analysis\nTo analyze utility, we introduce a virtual sequence x(t+1) = W(x(t) - tg(t)), which begins at the noisy iterate x(t) but applies a noise-free D-SGD step. This construction isolates the error introduced by the privacy noise and simplifies previous analyses (e.g., [18, Theorem 2])."}, {"title": "Assumption 1.", "content": "At iteration t, the privacy noise v(t) is inde- pendent of the noise-free state x(t+1) and prior states F(t) = {(v(1), (2)),..., (v(t-1), x(t))}: E[v(t)|x(t+1), F(t)] = 0."}, {"title": "Theorem 1.", "content": "Under Assumption 1, the expected squared error between consecutive iterates of our covariance-based frame- work satisfies:\n$$E[\\|x^{(t+1)} \u2013 \\hat{x}^{(t)} \\|_2^2 | F^{(t)}] = \\underbrace{E[\\|x^{(t+1)} \u2013 x^{(t+1)} \\|_2^2 | F^{(t)}]}_{Noise-free D-SGD error with clipped gradients} + \\eta_t^2 Tr(WRW^T).$$\nTheorem 1 shows that each iteration of our covariance-based framework incurs a baseline D-SGD error (independent of R) plus a variance term proportional to Tr(WRWT).\nOur analysis captures the interplay between W and R, explaining how correlated noise propagates and potentially cancels across agents. Prior analyses overlooked this mutual dependency, which is central to our covariance-based view. Another remark from Theorem 1 is that the variance Tr(WRWT) is linear in R: smaller [R]ii components speed- up convergence. At extreme cases, one may try to minimize this variance by enforcing Tr(WRWT) = 0:\n(i) If W is invertible, then R = 0 is the only solution, implying no added noise and hence no privacy.\n(ii) If W is singular, there exists a nontrivial null space: Wz = 0, z \u2260 0. One can then construct R = zzT \u2260 0 such that WRWT = 0; however, R becomes singular. Our privacy analysis will show that invertibility of R is necessary for general (\u03b5, \u03b4)-DP guarantees."}, {"title": "B. Privacy Analysis", "content": "We show that our framework ensures agent-level (\u03b5, \u03b4)-DP for arbitrary covariance R > 0. The following theorem bounds & in terms of the number of iterations T, clipping threshold C, and the inverse covariance R-1."}, {"title": "Theorem 2.", "content": "Our covariance-based framework satisfies (\u03b5, \u03b4)- DP with:\n$$\\epsilon < \\frac{2C^2T}{n} \\max_{i\\in V}[R^{-1}]_{ii} + \\sqrt{\\frac{2C^2T}{n} \\log(\\frac{1}{\\delta})} \\max_{i\\in V}[R^{-1}]_{ii}.$$\nTheorem 2 directly relates the diagonal elements of R-1, specifically maxi\u2208v[R\u00af\u00b9]ii, to the per-agent privacy budget \u03b5. This result immediately recovers well-known LDP bounds (e.g., [12, Prop. 7]) when R = $\\sigma_{ldp}^2$In: larger [R]ii (i.e., larger variance of privacy noise) implies smaller [R-\u00b9]ii, thus smaller \u025b (that is, strengthened (\u03b5, \u03b4)-DP guarantees).\nInvertibility (R > 0) is a necessary condition for ensuring agent-level privacy under correlated noise: if R were singular, linear combinations of noise could cancel completely among agents, directly exposing their local models.\nBoth the number of iterations T and the clipping thresh- old Cappear as multiplicative factors in Eq. (8), increasing \u03b5. Intuitively, more rounds of communication or higher gradient sensitivity (larger C) amplify privacy loss, requiring more noise to protect local models."}, {"title": "V. THE \"WHISPER D-SGD\" ALGORITHM", "content": "Theorems 1 and 2 together highlight a fundamental tension between utility and privacy: smaller diagonal entries [R]ii reduce the model-update variance Tr(WRWT) in Eq. (7) (expediting convergence), yet they increase [R\u00af\u00b9]ii and thus amplify \u025b in Eq. (8) (weaker privacy). Conversely, making [R]ii large improves privacy but slows convergence. A careful choice of R is therefore crucial to optimize this trade-off.\nFrom our analysis, we draw the following guidelines:\n(G1) Invertibility. A necessary condition for LDP-level privacy is R > 0 (Theorem 2). For this reason, we partition R into an independent noise component ($ \\sigma_{mix}^2$In), that ensures invertibility, and an arbitrary correlated component (Rcor):\n$$R_{mix} = \\sigma_{mix}^2 I_n + R_{cor}.$$"}, {"title": "(G2) Optimization Problem.", "content": "We optimize Rmix to balance utility (Theorem 1) and (\u03b5, \u03b4)-LDP privacy (Theorem 2):\n$$\\underset{R_{mix}>0}{minimize} Tr (WR_{mix} W^T)$$\nsubject to $\\frac{\\epsilon^2}{16C^2T log(1/\\delta)} \\leq [R_{mix}^{-1}]_{ii}, \\forall i\\in V.$\nProposition 1. Let \u025b < log(1/\u03b4). Problem (10) maximizes the utility of our covariance-based framework under (\u03b5, \u03b4)-DP."}, {"title": "Algorithm 1", "content": "WHISPER D-SGD\nInput: mixing matrix W, (\u03b5, \u03b4)-DP parameters, number of iterations T, clipping threshold C, random seed s.\n1: Initialize Rmix = $\\sigma_{mix}^2 I_n$ + Rcor \u25b7 guideline (G1)\n2: Optimize (10) to find Rmix \u25b7 guideline (G2)\n3: Share (Rmix, s) among all agents\n4: for t in 0...T - 1 do\n5: $\\hat{g}^{(t)} = clip(g^{(t)}; C)$ \u25b7 clipped gradient\n6: $v^{(t)} = R^{*1/2}s^{(t)}, s^{(t)} ~ N(0, I_n)$ \u25b7 privacy noise\n7: $g^{(t)} = g^{(t)} + v^{(t)}$ \u25b7 perturbed gradient\n8: $x^{(t+1)} = W (x^{(t)} \u2013 \\eta_t\\hat{g}^{(t)})$ \u25b7 perturbed update\n9: end for\n10: return x(T)\nIn Whisper D-SGD, each agent contributes a \u201cwhisper\u201d of noise (with variance $\\sigma_{mix}^2$) sufficient to protect its local model, thus to ensure LDP-level privacy. By design, correlated noise (with covariance Rcor) cancels during mixing, so that the final models reap many of the performance benefits typically associated with CDP-level approaches. We evaluate our correlated-noise design, we compare $\\sigma_{mix}^2$ (the effective independent variance in Whisper D-SGD) against LDP, with $R_{ldp} = \\sigma_{ldp}^2I_n$."}, {"title": "VI. EXPERIMENTAL EVALUATION", "content": "We evaluate Whisper D-SGD on synthetic quadratic objec- tives and real-world logistic regression, under varying privacy budgets & and network connectivity p. Our code is available at https://github.com/arodio/WhisperDSGD."}, {"title": "A. Experimental Setup", "content": "1) Network and DP parameters: We simulate n = 20 agents on an Erd\u0151s-R\u00e9nyi graph with varying con- nectivity p\u2208 {0.2,0.4,0.6,0.8, 1.0}. We adopt Metropo- lis-Hastings weights $W_{ij} = \\frac{1}{W_i+1}$ if j\u2208 Ni [19]. Fol- lowing standard benchmarks [18], we set DP parameters \u03b5\u2208 {3,5,7,10, 15, 20, 25, 30, 40}, \u03b4 = 10-5, and clipping threshold C = 0.1.\n2) Algorithms: We compare (i) LDP [13], [14], which adds independent local noise; (ii) DECOR [18], representative of pairwise correlation; and (iii) Whisper D-SGD, our mixing- based correlation approach. All algorithms run for T = 5000 iterations. Results are averaged over 10 random seeds.\n3) Tasks: We consider two machine learning tasks:\n(i) Quadratic Optimization with strictly convex objectives:\n$$f_i(x_1, x_2) = \\begin{cases} 15(x_1+i)^2 + x_2, i = 1,...,\\frac{n}{2} \\\\ 15(x_1 - i)^2 + x_2, i = \\frac{n}{2}+1,...,n. \\end{cases}$$\nTo introduce data heterogeneity, we rotate fi, i = 2+1,...,n around the local minimizers (i, 0) by an angle \u03b8 = 15\u00b0 [25]. We use a diminishing step size nt = 1/\u221at, with n\u2081 = 10-2.\n(ii) Logistic Regression. We train a regularized linear model on the a9a LIBSVM dataset [26], with an 80-20 train-test split. We simulate data heterogeneity by randomly parti- tioning samples among agents using a Dirichlet distribution with parameter 10 [18]. We tune the step-size in {10-1,5\u00b7 10-2,10-2,5\u00b710-3,10-3} and fix batch size to 128."}, {"title": "VII. CONCLUSION", "content": "In decentralized learning systems, sensitive information about training data can be exposed through shared local models. While LDP mitigates such privacy risks, it suffers from reduced utility compared to CDP due to accumulated local privacy noise. To address this challenge, we propose the Whisper D-SGD algorithm, which generates correlated noise across agents using a covariance-based approach. This method incorporates the mixing matrix into the design of correlated noise, providing strong privacy guarantees with minimal im- pact on utility. Both theoretical analysis and empirical results demonstrate that Whisper D-SGD improves the privacy-utility trade-off compared to existing methods (e.g., LDP, pairwise correlation) under various privacy budgets, particularly in sparse network topologies. Future directions include extending this framework to directed graphs and jointly optimizing mix- ing weights and the covariance matrix to improve convergence and further enhance noise cancellation."}]}