{"title": "Improving 3D Few-Shot Segmentation with Inference-Time Pseudo-Labeling", "authors": ["Mohammad Mozafari", "Hosein Hasani", "Reza Vahidimajd", "Mohamadreza Fereydooni", "Mahdieh Soleymani Baghshah"], "abstract": "In recent years, few-shot segmentation (FSS) models have emerged as a promising\napproach in medical imaging analysis, offering remarkable adaptability to segment\nnovel classes with limited annotated data. Existing approaches to few-shot segmen-\ntation have often overlooked the potential of the query itself, failing to fully utilize\nthe valuable information it contains. However, treating the query as unlabeled data\nprovides an opportunity to enhance prediction accuracy. Specifically in the domain\nof medical imaging, the volumetric structure of queries offers a considerable source\nof valuable information that can be used to improve the target slice segmentation.\nIn this work, we present a novel strategy to efficiently leverage the intrinsic infor-\nmation of the query sample for final segmentation during inference. First, we use\nthe support slices from a reference volume to generate an initial segmentation score\nfor the query slices through a prototypical approach. Subsequently, we apply a\nconfidence-aware pseudo-labeling procedure to transfer the most informative parts\nof query slices to the support set. The final prediction is performed based on the\nnew expanded support set, enabling the prediction of a more accurate segmentation\nmask for the query volume. Extensive experiments show that the proposed method\ncan effectively boost performance across diverse settings and datasets.", "sections": [{"title": "Introduction", "content": "Image segmentation is a primary problem in the medical imaging field, crucial for tasks like disease\ndiagnosis and treatment planning. Deep learning methods\nhave sped up progress in medical image analysis, particularly in automated image segmentation.\nHowever, their effectiveness heavily relies on extensive annotated data, which is often scarce,\nespecially for 3D volumetric images that require distinct annotations for the 2D slices of each 3D\nscan. Supervised deep learning methods struggle with generalizing to novel classes, necessitating\ninnovative segmentation strategies for limited annotated data."}, {"title": "Method", "content": "In this section, we begin by reviewing the problem formulation for few-shot segmentation in medical\nimaging. Subsequently, we introduce our method, which focuses on effectively leveraging query data\nto enhance segmentation accuracy during inference. The methodology encompasses key components\nsuch as support slice utilization, pseudo-labeling techniques, and an expanded support set to improve\nsegmentation outcomes."}, {"title": "Problem Setup", "content": "In the context of few-shot medical image segmentation, the problem is formulated as follows. Let\nthe source training dataset be denoted as Dsrc = {(xi, Yi(c))}1, where x\u2081 represents the medical\nimage and y is the corresponding binary mask with semantic label c. Similarly, the target dataset\ncontaining novel classes is denoted as Dtrg = {(Xi, Yi(c))}1. Here, Nsrc and Ntrg denote the\nnumber of samples in the training and testing datasets, respectively. The sets of source and target\nclasses are denoted as Csrc = {c|c \u2208 Dsrc} and Ctrg = {c|c \u2208 Dtrg}, where Csrc \u2229 Ctrg = \u00d8.\nIn the few-shot learning paradigm, the model fe is trained on Dsre with the objective of predicting an\nunseen class c \u2208 Ctrg during the meta-testing phase, given only a few support examples from Dtrg.\nSpecifically, the few-shot segmentation model is trained to operate in an N-way K-shot setting, where\nN represents the number of semantic classes to be segmented, and K is the number of examples\navailable for each class during the query phase.\nDuring training, an episodic training strategy is employed, simulating the conditions of the final\ntesting phase where only K examples for each class are available. Each episode consists of two\nsets of data randomly sampled from Dsre, a support set S = {S\u00a9}1 with S = {(x,y}K=1\nrepresenting few-shot training samples and a query set Q, representing the unseen classes to be\nsegmented. The model is trained to distill knowledge about a semantic class from the support set and\napply this knowledge to segment the query set during the testing phase. During inference, only the\nsupport images and their corresponding labels are provided, and the model performs segmentation on\nthe query images.\nThe goal is to develop a few-shot segmentation model fe that can generalize effectively to novel\nclasses during the testing phase, addressing the challenges posed by limited annotated data in the\nmedical imaging domain."}, {"title": "Confidence-Aware Semi-Supervised FSS", "content": "To address the challenges posed by limited annotated data in few-shot segmentation for medical\nimaging, we introduce a novel procedure designed to efficiently exploit the intrinsic information\ncontained within query samples for precise segmentation during inference. The main steps are outlined\nas follows.\nTo initiate the segmentation process, we leverage the support slices from a reference volume to\ngenerate an initial segmentation score for the corresponding query slices. Following a prototypical\napproach, we calculate the prototype vectors for each class based on the annotated support slices.\nUsing feature embeddings of support set fo(x) \u2208 RH\u00d7W\u00d7Z, the prototype for class c is computed\nthrough the masked average pooling:\n$P_{s,c} = \\frac{1}{K} \\sum_{k=1}^{K} \\frac{\\sum_{h,w} fo(x)(h, w) \\cdot y_{x}(h, w)}{\\sum_{h,w} y_{x}(h, w)} \\in \\mathbb{R}^{Z}$\nHere, the indices (h, w) reference pixels on the feature map, and y(h, w) denotes spatial locations\nwithin the binary mask for class c. The prototype vectors are then used to obtain the initial segmenta-\ntion score for the query slices. Probabilities of all classes are obtained by applying a softmax function\nto query distances. Here we use cosine distance to calculate distances between each query embedding\nand support prototypes. Specifically, for each pixel at location (h, w) within the query feature map\nfo (q), the cosine distance and softmax probabilities are expressed as:\n$d(f_{\\theta}^{\\phi}(x)(h, w), P_{s,c}) = \\frac{f_{\\theta}^{\\phi}(x)(h, w) \\cdot P_{s,c}}{||f_{\\theta}^{\\phi}(x) (h, w) ||_2||P_{S,C} ||_2}$\n$p_{q,c}^{\\phi}(h, w) = \\frac{exp(-d(f_{\\theta}^{\\phi}(x)(h, w), P_{s,c}))}{\\sum_{n=1}^{N} exp(-d(f_{\\theta}^{\\phi}(x)(h, w), P_{s,n}))}$\nIn the above equations, d(., .) represents the cosine distance between two vectors, and pq,c(h, w)\ndenotes the probability that the query pixel at location (h, w) belongs to class c. In the second step,"}, {"title": "", "content": "we employ a confidence-aware pseudo-labeling procedure. This step is crucial for transferring key\ninformative segments from the query slices to enrich the support set. By considering a confidence\nlevel y for the initial query segmentation probabilities, we identify the most informative regions\nwithin the query slices. Specifically, our model predicts a segmentation probability map for each\npixel in the query images, indicating the probability of each pixel belonging to different classes.\nSubsequently, these informative segments are selected to be incorporated into the support set with\npseudo-labels \u0177q:\n$\\hat{y}^{q}(h, w) = argmax_{C}p_{q,c}^{\\phi}(h, w)$\nThis pseudo-labeling procedure is applied to the M consecutive slices of the same query volume.\nMore confident pixels of each slice are selected to extract prototypes of query slices. Regions in\nthe query images with probability scores exceeding a threshold y, will be used to form the query\nprototypes:\n$P_{q,c} = \\frac{1}{M} \\sum_{m=1}^{M} \\frac{\\sum_{h,w} f_{\\theta}^{\\phi}(x_{m})(h, w) \\hat{y}_{m}(h, w)}{\\sum_{y_{m}^{\\phi}(h, w)}}$ where $p^{\\phi}(h,w) \\geq \\gamma \\in \\mathbb{R}^{Z}$\nThe term Pq, denotes the query prototype for class c, derived using the pseudo-labeling method.\nThe final step involves performing the prediction based on the augmented support set, which now\nincludes the enriched information from the consecutive query slices by adding query prototypes.\n$P^{aug} = P_{s} \\cup P_{q}$\nBy leveraging the intrinsic information obtained from the query samples and expanding the support\nset through confidence-aware pseudo-labeling, our method aims to achieve superior segmentation\nperformance in diverse settings and datasets. the inference process can be divided into three\nstages. The first and third stages follow the traditional prototypical FSS approach, while the second\nstage represents the key contribution of our work, enhancing prediction accuracy in a plug-and-play\nmanner."}, {"title": "Experiments", "content": "In order to ensure consistency across experimental outcomes, we follow the evaluation guidelines in\nOuyang et al. [2020], including the use of consistent hyperparameters, data preprocessing methods,\nevaluation metrics, and comparison techniques. The network architecture, implementation, and\ntraining procedure closely follow the SSLALPNet Ouyang et al. [2020] approach. For inference, we\nemploy a support volume containing three annotated slices (K = 3) to segment each query volume,\nconsistent with the methodology explained in Ouyang et al. [2020]. Furthermore, to comprehensively\nassess our method's performance, we conduct tests under both settings introduced in Ouyang et al.\n[2020]. Setting 1 involves training the model in a self-supervised manner on all available slices across\nall scans, while Setting 2 involves partitioning the test label set into two groups-upper (spleen and\nliver) and lower abdomen (right and left kidney). In this setting, when testing on a specific group, all\nslices containing those organs will be excluded from the training set.\nDatasets We conducted experiments on two widely-used medical datasets, specifically abdominal\nCT scans from the MICCAI 2015 MultiAtlas Abdomen Labeling Challenge and abdominal MRI scans from the ISBI 2019 Combined Healthy Abdominal Organ Segmentation\nChallenge Kavur et al. [2021]. Our experiments involved reporting average Dice scores based on\n5-fold cross-validation. Following the previous studies Ouyang et al. [2020], results of experiments\nare reported for four anatomical organs: the left kidney (LK), right kidney (RK), spleen, and liver."}, {"title": "Results and Discussion", "content": "Comparison with Other Methods We conduct a comparative analysis involving PANet Wang\net al. [2019], SSLALPNet Ouyang et al. [2020], and ADNet Hansen et al. [2022]. Our approach"}, {"title": "Conclusion", "content": "This study presents a novel three-stage inference-time method for few-shot segmentation (FSS),\nintroducing a confidence-aware pseudo-labeling process to refine predictions. The proposed approach\nmodifies only the inference phase, keeping the training procedure intact, which makes it a plug-and-\nplay enhancement to existing FSS frameworks. In the first stage, initial segmentation is performed\nusing prototypes derived from the support set. In the second stage, the confidence-aware pseudo-\nlabeling mechanism identifies reliable regions in the query slices, which are then used to update the\nquery prototypes. Finally, the augmented prototype set, combining support and query information, is\nemployed for final segmentation.\nOur approach effectively leverages the information from unlabeled query samples to improve segmen-\ntation performance without additional supervision. By focusing on inference-time optimization, this\nmethod avoids the complexities of retraining and shows potential for practical application across a\nvariety of FSS tasks. Empirical results demonstrate that this technique yields enhanced segmentation\naccuracy, particularly in scenarios where labeled support data is scarce, underlining the significance\nof incorporating query data into the prototype refinement process."}]}