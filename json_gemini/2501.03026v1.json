{"title": "Putnam's Critical and Explanatory Tendencies Interpreted from a Machine Learning Perspective", "authors": ["Sheldon Z. Soudin"], "abstract": "The emergence of machine learning models has the potential to act as a wrench in the gears of current debates in the philosophy of science. This paper reconstructs Putnam's critical and explanatory tendency distinction, argues for the biconditional necessity of the tendencies, and conceptualizes that wrench through a machine learning interpretation.", "sections": [{"title": "Introduction", "content": "Making sense of theory choice in normal and across extraordinary science is central to philosophy of science. The emergence of machine learning models has the potential to act as a wrench in the gears of current debates. In this paper, I will attempt to reconstruct the main movements that lead to and came out of Putnam's critical and explanatory tendency distinction, argue for the biconditional necessity of the tendencies, and conceptualize that wrench through a machine learning interpretation of my claim. Some preliminary definitions and statements of assumptions are in order.\nKuhn's picture of normal versus extraordinary science is presented in his 1962 book \u201cThe Structure of Scientific Revolution\". In a short caricature of the distinction, normal science takes place within paradigms and extraordinary science takes place across paradigms. As such, extraordinary science entails scientific revolutions and paradigm shifts. The term \"paradigm\" thus becomes an important term for Kuhn's argument; however, it remains relatively ambiguously defined. For the purposes of this paper a paradigm may be reduced to established scientific theories, symbolic generalizations, and heuristic models. As a response to Kuhn's and Popper's positions on the nature of good theory choice, Putnam constructs schemata to illustrate two tendencies in the consideration of scientific problems. (The \u2018Corroboration' of Theories)\nThe critical tendency:\n66\nSCHEMA I\nTHEORY\nAUXILIARY STATEMENTS\n\"\nPREDICTION \u2013 TRUE OR FALSE? (Putnam, 1979)\nThe explanatory tendency:\n66\nSCHEMA II\nTHEORY\n??????????\n\"\nFACT TO BE EXPLAINED (Putnam, 1979)\nPutnam endeavors to argue that Popper's falsifiability criterion is captured by schema I, and that theories alone cannot predict anything. It is rather the conjunction of theory and auxiliary statements that make a prediction. He suggests the explanatory tendency better captures the process of theory choice that occurs in normal science.\nMachine learning, and more specifically deep learning is a computer science and applied mathematics method that constructs neural networks, trains it on a given data set and ultimately outputs recreations/predictions that emulate the data set, upon which it was trained. The specific training methods and modes of application vary, from convolutional neural networks to recurrent"}, {"title": "Support for P1", "content": "The first premise of my argument is that when a scientific problem can be represented with the first schema; the auxiliary statements must have explanatory power for the representation to be successful.\nIn the same paper, (The \u2018Corroboration' of Theories), Putnam makes use of an example to show that a theory is in fact never used on its own to make a prediction. He states that when attempting to predict the orbit of earth; as a rudimentary example, the following statements would be assumed.\n66\n(I)\nNo bodies exist except the sun and the earth.\n(II)\nThe sun and the earth exist in a hard vacuum.\n(III)\nThe sun and the earth are subject to no forces except mutually induced gravitational forces.\n(Putnam, 1979)\nInterpreted with the first schema, the theory of universal gravitation conjoined with these assumptions allows for predictions to be made, it also entails that there is ambiguity, when prediction fails, as to what lead to the failure. He further suggests that the auxiliary statements will be questioned and reformulated before the theory itself would be falsified. Thus, theory does not predict alone. My point here, and with this example is that the auxiliary statements also provide explanatory support for the theory. Furthermore, I suggest that in a similar manner to the way theory alone cannot make predictions without auxiliary statements, theory alone cannot make predictions without auxiliary explanatory power. The argument is much the same as"}, {"title": "Support for P2", "content": "I shall reconstruct Putnam's argument on why a schema II type problem may be dependent on a schema I type problem, and support why I think this dependence is a necessity. Putnam does defend the possible interdependence of the two schemata in his paper. More specifically, he shows with an example, how the missing auxiliary statements required to explain a given fact from a specified theory can themselves be statements of a critical tendency. The example given is that a of explaining the orbit of Uranus. Put forth as such:\n66\nTheory: U.G.\nA.S.: S1\nFurther A.S.: ???????????\nExplanandum: The orbit of Uranus\n(Putnam, 1979)\nS1 represents the basic assumptions typically assumed when applying the law of universal gravitation and known planets prior to 1846. To solve the puzzle or fill the hole of this schema II type problem, two further auxiliary statements were needed. First (S2), the assumption that \u201cthere is one and only one planet in the solar system in addition to the planets mentioned in S1\" (Putnam, 1979). And second (S3), the predictive statement that given Universal Gravitation, S1 and S2; there is a planet moving along a specified orbit. S3 has the following schema I structure:\n66\nTheory: U. G.\nA.S.: S1, S2\nPrediction: A planet exists moving in orbit O \u2013 TRUE OR FALSE?\n\u201d (Putnam, 1979)\nS3 thus acts as a low-level hypothesis whose success permits the resolution of the original schema II problem. That is:\n66\nTheory: U.G.\nA.S.: S1, S2, S3\nExplanandum: the orbit of Uranus\n\u201d\n(Putnam, 1979)"}, {"title": "", "content": "This example makes it clear how a dependence of schema II representations on schema I representations is possible. Putnam mentions that these types of representations (schema II, where there is a schema I auxiliary statement) are rarely talked about by philosophers of science and that commonly, schema I representations have law-like auxiliary statements. It is debatable whether a prediction must be based on observation. It seems acceptable to admit that a low-level hypothesis that is also a law or theory has predictive power. A schema II interpretation of a scientific problem that depends on predictive auxiliary law-like statement would look like this.\nTheory\nAS: (Theory\nA.S.\nPrediction: A law \u2013 True or False?)\nExplanandum: Fact to be explained.\nOf course, one might immediately refute by saying that predictions must indeed be about observation and ask how a representation such as that above would be relevant. A response could point to the interplay of theories in the practice of science. That is, one scientist may use another's theory for the purpose of conjecture. Furthermore, a defence for the analytical connection between theoretical conjecture and statement about observation (predictions) may be explored in Carnap's Aufbau. Given these considerations, it seems reasonable for schema II type representations to use predictive law-like auxiliary statements. These A.S. would act like low- level hypotheses whose success depends on the explanatory power of the overarching schema II representation.\nA parallelism can be drawn when it comes to machine learning models, more specifically with regards to extracting information from the parameters of the models. During the training process of deep learning models, no attention is generally given to the meaning of the resulting parameters. The focus is on minimalizing the loss function; that is, the difference between the predicted and the actual output after a particular training input. After the loss is considered minimized, then the model is considered trained. At this point the study of model explainability tries to derive meaning from these parameters. A successful example of such a process (for large language models) would be the clustering of vectors to general semantic categories. One among the many other methods, that does not directly manipulate the parameters, is testing various prompts to better understand how and why the model responds the way it does. As such it would schematically look something like this:\nMolel (Parameters)\nInput ... Expected Output \u2013 True or False\nModel feature to be explained\nIn a similar manner to schema II representations of scientific problems, successful prediction from input to output, not for model training purposes but to understand model features, support the explanatory power of the schematic representation. So far, I have shown and explained how Putnam's tendencies can be interpreted through machine learning. In the conclusion I support why I think there is significant philosophical weight to this."}, {"title": "Conclusion", "content": "At the core, it looks like my philosophical claim becomes one of emphasis, and otherwise is a reconstruction of many of the same movements as Putnam's in \u201cThe \u2018Corroboration' of Theories", "successfully\u201d when first presenting the argument was to make it clear that a schematic representation of either tendency is arguably more successful because of its dependence on the other tendency. It can be put forth that it is possible to represent a scientific problem without the other tendency; however, I suggest that it is the worse for it. Second and surely more glaringly, I have suggested a rather bold equivocation; that of theory to machine learning model. I believe this is an appropriate equivocation for a few reasons.\nEvidence points to continued and significant advancement of the capability of these models. The paper \u201cAttention is All You Need\u201d, a seminal work that introduced the transformer architecture upon which major gains in LLM capabilities were achieve, was published in 2017. Today LLM Chatbots are capable enough to have become an everyday tool for many. A study published in 2024 by Porter and Machery at the University of Pittsburgh has shown that \u201cAI- generated poetry is indistinguishable from human-written poetry and is rated more favorably": "In another 2024 paper published by the Palo Alto Archetype AI research team, Phenomenological AI Foundation Model For Physical Signals, a model was trained on \u201c0.59 billion samples of cross-modal sensor measurements\u201d. It was shown that without specific instruction regarding established physical laws, the model was able to predict physical phenomena on new data. Such phenomena included tracking trajectories of spring mass systems and forecasting large electrical grid dynamics.\nThis recent significant progress and continued investment into the infrastructure required to train machine learning models, i.e. computing facilities and power plants, point towards the continued incremental but significant progress of machine learning models. Assuming there is enough available raw data, compute, and energy; and that certain technological scalability issues are overcome; there is a reasonable amount of evidence to suggest that machine learning models will be able to provide significantly qualitatively better predictions than presently is the case. For example, a model such as that trained by the Archetype AI research team could make better predictions than what is possible by our current physical laws. Of course, this is only a possibility if such a discovery exists within the data, and that this information is not filtered out"}, {"title": "", "content": "by the means by which the data is captured. The point being the limitation may be our understanding of the data, not the data itself. It is for this reason that I think that understanding and applying the parallels between Putnam's schemata and machine learning models is pertinent, and that more generally applying philosophy to machine learning is an important avenue of research. That small wrench that I hope to better understand is the idea that through an analysis of various machine learning models, model-independent objective parameters may conceivably be discovered. It would certainly be paradigm shifting if one day the talk was about the parameter-ladenness of theories."}]}