{"title": "Leveraging Large Language Models to Geolocate Linguistic Variations in Social Media Posts", "authors": ["Davide Savarro", "Davide Zago", "Stefano Zoia"], "abstract": "Geolocalization of social media content is the task of determining the geographical location of a user based on textual data, that may show linguistic variations and informal language. In this project, we address the GeoLingIt challenge of geolocalizing tweets written in Italian by leveraging large language models (LLMs). GeoLingIt requires the prediction of both the region and the precise coordinates of the tweet. Our approach involves fine-tuning pre-trained LLMs to simultaneously predict these geolocalization aspects. By integrating innovative methodologies, we enhance the models' ability to understand the nuances of Italian social media text to improve the state-of-the-art in this domain. This work is conducted as part of the Large Language Models course at the Bertinoro International Spring School 2024. We make our code publicly available on GitHub 1.", "sections": [{"title": "1 Introduction", "content": "GeoLingIt is the first shared task focused on geolocating linguistic variation in Italy using social media posts with non-standard Italian language. Part of the EVALITA evaluation campaign, it aims to advance natural language processing (NLP) for non-standard Italian and provide sociolinguistic insights through quantitative analysis.\nSocial media offers a unique opportunity to study informal language use across sociolinguistic dimensions, particularly diatopic variation (variation across geographic space). Italy's linguistic diversity includes numerous local languages, dialects, and regional varieties of Standard Italian. Online, Italians often use local language elements to signal social identities.\nGeoLingIt seeks to understand linguistic variation in Italy by developing methods to predict the locations of Twitter posts based solely on linguistic content. Unlike other geolocation tasks, it filters posts for non-standard Italian, focusing on linguistic rather than lexical variations. Variations in GeoLingIt data may include local words, code-switching, or entire posts in a local language or dialect.\nGeoLingIt includes two subtasks. Coarse-grained geolocation, named subtask A, consists in the classification of the region of provenance of a given text. Fine-grained geolocation, named subtask B, is a double regression task, in which the algorithm must predict the coordinates of the given social media post.\nOur approach involves fine-tuning pre-trained large language models (LLMs) to solve both sub-tasks in a single generation step. Our methodology is inspired by ExtremITA (Hromei et al., 2023), where a multi-task approach was used to train LLMs to solve all EVALITA tasks. We fine-tune and compare three decoder-only LLMs on GeoLingIt and analyze the obtained results."}, {"title": "2 Data and models", "content": "In this section we describe the GeoLingIt dataset and we outline the characteristics of the three LLMs used in our experiments. We also discuss the pre-processing steps and the methodologies employed for fine-tuning these models."}, {"title": "2.1 Dataset description", "content": "The GeoLingIt dataset contains 15039 samples and it is divided in a specific train-evaluation-test split of 13669 (90.09%), 552 (3.67%) and 818 (5.44%) samples, to enable a fair comparison between the different approaches. Furthermore, the dataset is divided into 2 subsets that correspond respectively to subtask A and B. Since our approach tackles both tasks simultaneously, we join the two portions into a new merged dataset and we use it during training."}, {"title": "2.2 Models description", "content": "In recent years pre-trained LLMs have been effectively used to solve varied problems in natural language processing. In our setting, we fine-tune and compare three different pre-trained LLMs on the Italian language: Camoscio-7B (Santilli and Rodol\u00e0, 2023), ANITA-8B (Polignano et al., 2024) and Minerva-3B (Orlando et al., 2024).\nCamoscio is an Italian instruction-tuned 7 billion parameters model based on LLaMA (Touvron et al., 2023). The training of the model follows the one of (Taori et al., 2023) with Low-Rank Adaptation (LoRA) (Hu et al., 2021). We use a slightly modified version of that model implemented by the ExtremITA (Hromei et al., 2023) team.\nANITA is a 8 billion parameter instruction-tuning of the LLaMAntino family (Basile et al., 2023). This model was obtained by fine-tuning LLaMA 3 (AI@Meta, 2024) with Direct Preference Optimization (DPO) (Rafailov et al., 2024). ANITA aims to be a multilingual model to be used for further fine-tunings on Italian language tasks.\nMinerva is the first family of LLMs pre-trained from scratch on the Italian language. This set includes three model sizes of 350 millions, 1 billion and 3 billions parameters respectively. We include Minerva in our study to test the capability of a pre-trained LLM on Italian, and we use the largest (3 billion) version to obtain a comparison that is as fair as possible with the other larger models."}, {"title": "3 Experiments and result analysis", "content": "We will now briefly present the hardware used, the experiments performed and we will analyze the metrics and the results we obtained."}, {"title": "3.1 Hardware", "content": "All our experiments are run on a single machine equipped with a Tesla T4 GPU with 16 GB of VRAM. Due to the limited amount of compute power, we had to make some compromises when choosing how to train and test our models (see subsection 3.2)."}, {"title": "3.2 Experiment settings", "content": "All the previously mentioned models have been fine-tuned and tested on the GeoLingIt dataset following the ExtremITA instruction encoding:\n(instruction)(post_content)\n[regione] (region) [geo] (lat)(long)\nIn this way, both subtasks A and B have been solved with a single model fine-tuning with the language modeling objective.\nThe upper panel of Table 2 shows the hyperparameters we used for fine-tuning across all the experiments except for Minerva, for which we used a larger batch and minibatch size. Due to our limited disposal of GPU memory of 16 GB, we used gradient accumulation to simulate larger batch sizes and stabilize training.\nTo further reduce the memory footprint we used 4-bit quantized versions of the three considered models, and we used LoRA to reduce the number of training parameters and therefore the training time. Although smaller models such as Minerva (3 bilion parameters) would have benefited from a more conservative LoRA configuration (e.g. higher rank values or greater bit precision), those same settings would not have been viable for Camoscio and ANITA with our computational resources. For these reasons, we kept the same configuration for all the tested models. The lower panel of Table 2 sums up the parameters we used for LoRA with quantization.\nIt is worth noting that we performed 10 epochs of training for each of the models analyzed in order to compensate for the aggressive LoRA settings. In this way we were able to still get some noteworthy results when comparing them with the ones presented in (Hromei et al., 2023)."}, {"title": "3.3 Metrics and result analysis", "content": "We choose to use the same metrics that were adopted for the EVALITA 2023 campaign to evaluate our models and enable a fair comparison with the other competitors: macro (unweighted) F1-score for subtask A, and average distance error in km for subtask B.\nThe average distance error is a precise and intuitive metric when comparing the regressive capabilities of the models in predicting the right coordinates. On the other hand, we argue that the macro F1-score is not the best metric for evaluating region classification capabilities in our setting. Given the fact that the GeoLingIt dataset is highly unbalanced (see subsection 2.1 for details), we expect that most represented classes would show lower prediction error, and, on the contrary, samples of less represented classes would be more often misclassified. We believe that the F1-score weighted by class cardinality (also known as \"micro\") is a more appropriate choice of metric, and envision additional experiments with this considerations.\nAnalyzing the results reported in Table 3 it is interesting to see how a 1 year evolution of LLM research actually influences the performances. We can assert the performance of Minerva is comparable with Camoscio even though Minerva is less than half the size of Camoscio. Moreover, ANITA produced very strong results, almost matching the ones obtained by the top performing models of the EVALITA 2023 campaign."}, {"title": "4 Error analysis", "content": "For subtask A (region classification), the models showed varying performance in classifying the region of provenance, particularly struggling with less represented regions in the dataset (e.g. Trentino-Alto Adige). Due to space reasons we include the confusion matrices of the test set classification in the Appendix. Figures 3a, 3b and 3c reveal that the most frequent errors occurred in predicting regions with fewer samples. As expected, the models tend to favor regions with higher representation, such as Lazio and Campania, leading to biased predictions. It is still interesting to see that often misclassifications happen between nearby regions (e.g. Umbria and Lazio or Piemonte and Lombardia) highlighting linguistic similarities that are difficult for the LLM to distinguish.\nIn subtask B (coordinate regression), predicting precise coordinates posed a challenge due to the fine-grained nature of the task. Figures 4b, 4d and 4f show the average distance errors in Italian provinces. It is evident from the figures that while the models could approximate the general area, pinpointing exact locations was difficult. ANITA-8B outperformed the others, likely due to its larger parameter size and advanced training techniques.\nObserving the sum of distance errors evidences how much the models predicted distant values despite the number of samples, as shown in figures 4a, 4c and 4e. From these figures we can see that non negligible amounts of error also come from frequently represented areas (see Figure 2b)."}, {"title": "5 Conclusions", "content": "This project tackled the challenge of geolocating social media posts written in non-standard Italian using large language models (LLMs). By fine-tuning pre-trained LLMs, we aimed to predict both the region and precise coordinates of tweets, addressing the GeoLingIt subtasks simultaneously. Our experiments with Camoscio-7B, ANITA-8B, and Minerva-3B demonstrated encouraging results in geolocation accuracy. Despite the dataset's non-uniform distribution posing challenges, our experiments showed that recent advancements in LLMs significantly enhance geolocation performance, with the ANITA-8B model achieving the best results among the tested models.\nFuture work could explore advanced pre-processing techniques (e.g. including additional information in the prompt, like the coordinate centroid of a given region) and different models to further improve geolocation accuracy. Additionally, class imbalance issues could be addressed with data augmentation or re-sampling techniques.\nOverall, this project contributes to the research on using LLMs for sociolinguistic analysis and geolocation tasks, offering a foundation for developing more accurate and sophisticated models."}]}