{"title": "Biotic Browser: Applying StreamingLLM as a Persistent Web Browsing Co-Pilot", "authors": ["Kevin F. Dunnell", "Andrew P. Stoddard"], "abstract": "This paper presents \"Biotic Browser,\" an innovative AI assistant leveraging StreamingLLM to transform web navigation and task execution. Characterized by its ability to simulate the experience of a passenger in an autonomous vehicle, the Biotic Browser excels in managing extended interactions and complex, multi-step web-based tasks. It marks a significant advancement in AI technology, particularly in the realm of long-term context management, and offers promising applications for enhancing productivity and efficiency in both personal and professional settings.", "sections": [{"title": "Introduction", "content": "The recent explosion of large language models (LLMs) has created a surge in the development of new \"intelligent\" software applications, particularly in persistent personal assistants. While numerous efforts are being made to build such an assistant, a significant gap remains in addressing user experience. Many of these efforts overlook the intricacies of human-AI interaction, a crucial element for successfully adopting such technologies. The Biotic Browser is our response to this gap. The tool introduces a user experience akin to being a passenger in an autonomous vehicle. This novel approach marks a significant departure from conventional text-based AI user interfaces, where web browsing by an LLM is often hidden from the user. Biotic Browser allows users to engage with web navigation intuitively and transparently, thereby enhancing trust and ease of use. This design philosophy addresses the growing demand for AI systems that are efficient but also user-friendly and trustworthy, setting a new precedent in the field.\nDespite the capabilities of state-of-the-art LLMs, they often fall short in tasks requiring the processing and retention of extended interaction sessions. This is particularly evident in applications demanding dynamic and continuous user interaction, such as complex web navigation and sophisticated task management. StreamingLLM [1] addresses this limitation, enabling the retention and processing of information over prolonged interactions. Biotic Browser, leveraging StreamingLLM, represents a significant advancement in this area. It offers an AI assistant adept at managing multi-step tasks and maintaining a comprehensive history of user interactions. Designed as an advanced web browser agent, the Biotic Browser can execute intricate plans and interact seamlessly with various web platforms. By combining the technological capabilities of StreamingLLM with a focus on continuous context management and user-centric design, the Biotic Browser not only enhances the practicality of AI applications in personal and professional settings but also showcases the potential of StreamingLLM technology in creating a more intuitive and capable digital assistant."}, {"title": "Methodology", "content": "2.1 Biotic Browser + GPT-4 Vision\nInspired by the release of GPT-4 Vision (GPT-4V) [2], we initially leveraged this technology in the development of Biotic Browser to create a solution that integrates both image and text processing for an AI-assisted web browsing experience. The system begins by capturing a user-defined goal, such as 'buy an iPhone.' With this goal, Biotic Browser takes a screenshot of the current webpage, performs preprocessing on the screenshot to identify and number interactive elements, and then passes the annotated images along with textual descriptions of the goal to GPT-4V. The model then returns a set of proposed actions in JSON format or a completion state of 'true' if the task is completed. This process continues in a loop until GPT-4V confirms that the goal has been achieved.\nWhile innovative, this approach faced several limitations. First, in terms of data privacy, it required sharing screenshots of web browsing for inference. Secondly, we encountered a bottleneck in terms of speed due to API latency. Additionally, during extended browsing sessions, the system faced challenges with memory cache overflow. Another significant issue was balancing the execution of actions relevant to the current step while still aligning with the overarching long-term goal, a complex task for the AI to manage effectively.\nWe explored open-source multimodal (text + image) alternatives to GPT-4V, such as LLaVa [3,4] and miniGPT-4 [5]. However, neither of these options could caption webpage screenshots with the same fidelity as GPT-4V. While the release of GPT-4V was a key motivator in our initial development of Biotic Browser using a multimodal model, the lack of suitable open-source alternatives led us to reconsider our architecture and shift to using a text-only model.\n2.2 Biotic Browser + StreamingLLM\nIn response to the limitations encountered with Biotic Browser + GPT-4V, we pivoted our approach to incorporate StreamingLLM. StreamingLLM's capability to manage and retain extended conversation histories and task lists proved to be a more fitting framework for the tool's objectives. This integration allowed Biotic Browser to process lengthy and complex task sequences without requiring visual data to be sent to OpenAI. As a result, this enhanced the system's data privacy considerably.\nIn this updated architecture, the system scrapes and processes the DOM to identify and tag interactable elements on the page instead of taking screenshots. These elements, along with the user-defined goals, are passed to StreamingLLM. The model then either confirms task completion or suggests"}, {"title": "User Experience Design", "content": "Central to the development of the Biotic Browser is its innovative user interface design, which draws inspiration from the experience of being a passenger in an autonomous vehicle. This design paradigm represents a significant shift from traditional web navigation interfaces, focusing on creating an immersive, intuitive, and engaging user experience. The interface allows users to observe the browser's actions as it navigates through web pages, akin to watching an autonomous vehicle chart its course. This visualization of the browser's decision-making process is not only informative but also enhances the user's sense of control and trust in the system. Users are not passive observers; they can intervene and redirect the browser's actions at any point, similar to a driver taking control of a vehicle. This level of interaction and control is a response to the need for AI systems that are transparent and trustworthy, addressing common concerns about the opacity of AI decision-making processes. By combining these elements, Biotic Browser's user interface proposes a new standard in AI-driven web navigation, prioritizing user control, which we hope will help with the adoption of AI-assisted technology."}, {"title": "Results", "content": "The integration of StreamingLLM into Biotic Browser presented notable challenges, chiefly memory allocation constraints in local deployment. StreamingLLM's local performance was limited, pro-"}, {"title": "Discussion", "content": "The development of Biotic Browser, integrated with StreamingLLM, marks a significant advancement in AI-assisted web navigation. This innovation fills a critical gap in current AI applications by seamlessly blending advanced language processing with an intuitive, user-focused web interface. The Biotic Browser's novel approach to web navigation parallels the experience of being a passenger in an autonomous vehicle, representing a shift in human-computer interaction.\nIntegrating StreamingLLM posed significant technical challenges, particularly in managing its local deployment due to resource requirements. These challenges reflect a broader issue in AI development: the need to balance the computational demands of advanced models with practical computing environments."}, {"title": "Conclusion", "content": "This paper has underscored the significant potential of Biotic Browser, an AI-assisted web browsing tool. Integrating StreamingLLM with a user-centric design, Biotic Browser offers an innovative approach to digital interaction. Its proficiency in managing complex tasks over extended periods demonstrates its capability to enhance productivity and efficiency in various settings. Biotic Browser represents a paradigm shift in AI-assisted web navigation and task execution. It paves the way for future developments in creating more intuitive and capable digital assistants."}, {"title": "Appendix A", "content": "Biotic Browsing prompting instructions:\nprompt = \"\"\"\nAs an autonomous AI agent, your task is to navigate and interact\nwith web pages, keeping track of\nsignificant actions and decisions made. Use this historical\ncontext to guide your current and\nfuture interactions towards completing the web task.\nYour input will be:\nTask Description: A string with no formatting that describes the\noverall task to be completed. This is the most\nimportant information for you to understand, and will be provided\nat the beginning of each task. This should always\nbe the overall goal.\nElements: A JSON object where each key corresponds to a unique\nidentifier for an\nelement visible\non the current webpage, and the value is a dictionary containing\ninformation about the element such as 'tag_name',\n'accessible_name', 'aria_role', 'id', 'class', 'text', 'location',\nand 'size'.\nNext Step: A string with no formatting that describes what you\nshould do at the current step. If this is the\nfirst step, the next step will be blank, and you should perform\nthe first action based on the task description.\nIf the next step does not make sense based on the elements\nprovided, you may ask clarifying questions or\nperform a different action that you think is more appropriate to\nachieve the task.\nHistory: A string with no formatting that describes the actions\nyou have taken so far. This will be blank\nfor the first step, and will be updated after each step.\nClarifying Questions: An array of strings with no formatting\nthat represent questions you have previously\nasked about the task or the provided text descriptions. These\nquestions have been answered by a human and used\nto improve your understanding of the task.\nAfter processing the input, respond with a JSON object that\nstrictly follows the defined structure below. The JSON object\nmay\nnot have escape characters and must be able to be parsed by json.\nloads().\nOutput:\n'event_list': An array where each element is an object\nrepresenting an interaction event. Each interaction\nevent object must have a 'type' key that indicates the kind of\nevent, such as 'click', 'cursor_move', 'scroll',\nor 'text_input'. If you want to click on an item or enter text,\nyou must first move the cursor to the item.\nIf the item is not in view, as given by the visible_in_viewport\nvalue, you must first scroll to the item. If\na scroll event is required, you must first scroll to the item\nbefore moving the cursor to the item. You may\nnot perform an action on an item that has not been moved to. The\nobject structure for each type is:\nFor 'click' events: An object with 'type': 'click', and 'item'\n: x, where x is an integer representing the\nitem to interact with based on the text description.\nFor 'cursor_move' events: An object with 'type': 'cursor_move'\n, and 'item': x, where x is an integer\nrepresenting the item that the cursor should move to based on\nthe text description.\nFor 'scroll' events: An object with 'type': 'scroll', and\n'item': x, where x is an integer representing\nthe item to scroll to based on the text description.\nFor 'text_input' events: An object with 'type': 'text_input',\n'item': \u0445, and 'text': 'string', where x is\nan integer representing the item to enter text into and where\n'string' is the text to be entered based\non\nthe text description.\n'next_step': A string with no formatting that describes what you\nshould do after the current set of events has\nbeen completed.\n'is_complete': A boolean value indicating whether the task has\nbeen fully completed.\n'questions': An array of strings with no formatting that\nrepresent questions you have about the task or the\nprovided text descriptions. You may also ask questions if you\nneed custom user input for a text field. These\nquestions will be answered by a human and used to improve the AI\n's performance. You may leave this array empty\nif you have no questions, but always include the key. If you\nhave questions, you may leave the event_list empty\nand the AI will not perform any actions on this page. However,\nyou must still provide all of the other values.\nThe next_step should describe what the user should do after the\nclarifying questions have been answered. The\nis_complete value should be false if the task is not fully\ncomplete on this page. The action value should\nindicate that you needed to ask clarifying questions, and what\nthose questions were. You will not receive\nany additional instructions other than the clarifying questions.\n'action': A string with no formatting that describes the action\nyou took at this step. This will be recorded\nin the history for future steps, so make sure it is accurate and\nwill help you complete the task.\nTask Description:\nsearch for pizza\nElements:\n{\"0\": {\"tag_name\": \"a\", \"accesible_name\": \"About\", \"aria_role\": \"\nlink\", \"id\": \"\", \"class\": \"MV3Tnb\", \"text\": \"About\", \"location\n\": {\"x\": 21, \"y\": 17}, \"size\": {\"height\": 26, \"width\": 47},\n\"visible_in_viewport\": true}, \"1\": {\"tag_name\": \"a\",\n\"accesible_name\": \"Store\", \"aria_role\": \"link\", \"id\": \"\",\n\"class\": \"MV3Tnb\", \"text\": \"Store\", \"location\": {\"x\": 78, \"y\":\n17}, \"size\": {\"height\": 26, \"width\": 43}, \"visible_in_viewport\n\": true}, \"2\": {\"tag_name\": \"a\", \"accesible_name\": \"\nAdvertising\", \"aria_role\": \"link\", \"id\": \"\", \"class\": \"pHiOh\",\n\"text\": \"Advertising\", \"location\": {\"x\": 175, \"y\": 1196},\n\"size\": {\"height\": 46, \"width\": 99}, \"visible_in_viewport\":\ntrue}, \"3\": {\"tag_name\": \"a\", \"accesible_name\": \"Business\",\n\"aria_role\": \"link\", \"id\": \"\", \"class\": \"pHiOh\", \"text\":\nBusiness\", \"location\": {\"x\": 274, \"y\": 1196}, \"size\": {\"height\n\": 46, \"width\": 87}, \"visible_in_viewport\": true}, \"4\": {\n\"tag_name\": \"a\", \"accesible_name\": \"How Search works\",\n\"aria_role\": \"link\", \"id\": \"\", \"class\": \"pHiOh\", \"text\": \"How\nSearch works\", \"location\": {\"x\": 361, \"y\": 1196}, \"size\": {\n\"height\": 46, \"width\": 147}, \"visible_in_viewport\": true}, \"5\":\n{\"tag_name\": \"a\", \"accesible_name\": \"Our third decade of\nclimate action: join us\", \"aria_role\": \"link\", \"id\": \"\",\n\"class\": \"pHiOh\", \"text\": \"Our third decade of climate action:\njoin us\", \"location\": {\"x\": 447, \"y\": 1149}, \"size\": {\"height\n\": 47, \"width\": 306}, \"visible_in_viewport\": true}, \"6\": {\n\"tag_name\": \"a\", \"accesible_name\": \"Privacy\", \"aria_role\": \"\nlink\", \"id\": \"\", \"class\": \"pHiOh\", \"text\": \"Privacy\",\n\"location\": {\"x\": 801, \"y\": 1196}, \"size\": {\"height\": 46,\n\"width\": 76}, \"visible_in_viewport\": true}, \"7\": {\"tag_name\": \"\na\", \"accesible_name\": \"Terms\", \"aria_role\": \"link\", \"id\": \"\",\n\"class\": \"pHiOh\", \"text\": \"Terms\", \"location\": {\"x\": 877, \"y\":\n1196}, \"size\": {\"height\": 46, \"width\": 68},\n\"visible_in_viewport\": true}, \"8\": {\"tag_name\": \"a\",\n\"accesible_name\": \"Sign in\", \"aria_role\": \"link\", \"id\": \"\",\n\"class\": \"gb_za gb_jd gb_Ld gb_ie\", \"text\": \"Sign in\",\n\"location\": {\"x\": 1086, \"y\": 12}, \"size\": {\"height\": 36, \"width\n\": 96}, \"visible_in_viewport\": true}, \"9\": {\"tag_name\": \"input\n\", \"accesible_name\": \"Google Search\", \"aria_role\": \"button\",\n\"id\": \"\", \"class\": \"gN089b\", \"text\": \"\", \"location\": {\"x\": 459,\n\"y\": 453}, \"size\": {\"height\": 36, \"width\": 127},\n\"visible_in_viewport\": true}, \"10\": {\"tag_name\": \"input\",\n\"accesible_name\": \"I'm Feeling Lucky\", \"aria_role\": \"button\",\n\"id\": \"gbqfbb\", \"class\": \"\", \"text\": \"\", \"location\": {\"x\": 598,\n\"y\": 453}, \"size\": {\"height\": 36, \"width\": 143},\n\"visible_in_viewport\": true}}\nNext Step:\nHistory:\nNo history yet.\nClarifying Questions:\nNo clarifying questions yet.\nprompt = prompt.replace('\"', '\\\"').replace('\\\\\"', '\\\\')\n\"\n    }"}]}