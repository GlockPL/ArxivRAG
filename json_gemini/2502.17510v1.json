{"title": "Recurrent Knowledge Identification and Fusion for Language Model Continual Learning", "authors": ["Yujie Feng", "Xujia Wang", "Zexin Lu", "Shenghong Fu", "Guangyuan Shi", "Yongxin Xu", "Yasha Wang", "Philip S. Yu", "Xu Chu", "Xiao-Ming Wu"], "abstract": "Continual learning (CL) is crucial for deploying large language models (LLMs) in dynamic real-world environments without costly retraining. While recent model ensemble and model merging methods guided by parameter importance have gained popularity, they often struggle to balance knowledge transfer and forgetting, mainly due to the reliance on static importance estimates during sequential training. In this paper, we present Recurrent-KIF, a novel CL framework for Recurrent Knowledge Identification and Fusion, which enables dynamic estimation of parameter importance distributions to enhance knowledge transfer. Inspired by human continual learning, Recurrent-KIF employs an inner loop that rapidly adapts to new tasks while identifying important parameters, coupled with an outer loop that globally manages the fusion of new and historical knowledge through redundant knowledge pruning and key knowledge merging. These inner-outer loops iteratively perform multiple rounds of fusion, allowing Recurrent-KIF to leverage intermediate training information and adaptively adjust fusion strategies based on evolving importance distributions. Extensive experiments on two CL benchmarks with various model sizes (from 770M to 13B) demonstrate that Recurrent-KIF effectively mitigates catastrophic forgetting and enhances knowledge transfer.", "sections": [{"title": "Introduction", "content": "Incorporating continual learning (CL) capability into large language models (LLMs) is essential for enabling them to acquire knowledge from diverse tasks sequentially, a critical requirement for adapting to ever-changing environments without extensive retraining (Wang et al., 2024b; Jiang et al., 2024; Yu et al., 2024; Chang et al., 2024). An effective CL system must address two key challenges: (1) Catastrophic Forgetting (CF) (McCloskey and Cohen, 1989), where previously acquired knowledge is lost when learning new tasks, and (2) Knowledge Transfer (KT) (Ke et al., 2021), which involves leveraging new, related tasks to improve performance on prior tasks, and vice versa.\nRecently, model mixture-based methods have emerged as a mainstream approach for CL in LLMs (Chen et al., 2023; Wu et al., 2024a; Rype\u015b\u0107 et al., 2024). By leveraging parameter-efficient finetuning (PEFT) techniques, which reduce the computational burden, these methods can be broadly classified into two categories: model ensemble and model merging. Model ensemble methods assign a dedicated PEFT block to each task, capturing task-specific knowledge, which is then stored in a pool and dynamically selected during inference (Zhu et al., 2024; Wang et al., 2024c). While effective, these methods require storing all task-specific models, leading to high memory consumption that grows with the number of tasks, which limits their scalability for long task sequences.\nAnother line of research focuses on model merging approaches (Dou et al., 2024; Wan et al., 2024; Yadav et al., 2024a), which integrate new task knowledge after training into the historical model, maintaining a single unified model and reducing memory costs compared to model ensemble methods. Consequently, our work primarily focuses on model merging approaches. However, determining which parameters to merge and how to merge remains an open challenge (Qin et al., 2024).\nLocalizing important parameters in LLMs has recently gained significant interest, a topic widely explored in fields like model pruning and compression (Lu et al., 2021a; Panigrahi et al., 2023; Sun et al., 2023; Yadav et al., 2024b). Building on this foundation, Feng et al. (2024b) and Du et al. (2024) have utilized gradient-based importance metrics, such as Hessian approximations, to identify critical parameters. By selectively or partially merging weights based on parameter importance, these methods have shown effectiveness in CL tasks.\nHowever, the success of these approaches is contingent on the accurate estimation of parameter importance. A key limitation lies in their reliance on static importance estimations, where the parameter importance scores for previous tasks remain unchanged and are not updated during subsequent training. Over time, as model parameters gradually diverge from the state at which the Hessian was originally computed, these unadjusted importance estimates become increasingly inaccurate due to the growing truncation error in the Taylor expansion. This issue is further detailed in the experiments section (Figure 5).\nThe human brain demonstrates remarkable CL ability through two alternating systems: the hippocampus, which quickly acquires representations for specific experiences, and the neocortex, which selectively consolidates useful memories into long-term storage. This process is known as the Complementary Learning Systems (CLS) theory (McClelland et al., 1995) in neuroscience.\nDrawing inspiration from the CLS theory, we propose Recurrent Knowledge Identification and Fusion (Recurrent-KIF), a novel CL framework that dynamically estimates parameter importance and iteratively fuses knowledge. Recurrent-KIF integrates an inner learner, which rapidly adapts to new task-specific knowledge, and an outer learner, which manages the global fusion of new and historical knowledge (see Figure 1).\nIn detail, the inner learner adapts to new knowledge while utilizing the proposed knowledge identification method to identify important parameters. The outer learner then retrieves historical task information from a memory buffer based on the latest model state, enabling dynamic updates of the importance distributions for previous tasks. Subsequently, a knowledge fusion mechanism is employed to integrate new and historical knowledge by pruning redundant information to mitigate CF and merging key knowledge to enhance KT. Through iterative cycles of multiple rounds of fusion, Recurrent-KIF effectively captures valuable information throughout the model training process, distinguishing it from traditional posttraining fusion methods. Each knowledge fusion step adaptively updates fusion weights according to the most recent importance distributions, resulting in smoother and more controlled optimization.\nWe conduct extensive experiments to assess the effectiveness of Recurrent-KIF on two CL benchmarks for LLMs. The results consistently highlight the superiority of Recurrent-KIF in mitigating CF while exhibiting exceptional KT capabilities, outperforming state-of-the-art methods. Furthermore, Recurrent-KIF exhibits robust scalability across various model architectures and sizes (from 770M to 13B), underscoring its generalization ability.\nOur main contributions are summarized as:\n\u2022 We propose Recurrent-KIF, a novel CL framework for recurrent knowledge identification and fusion that dynamically estimates parameter importance and iteratively integrates knowledge.\n\u2022 We introduce a new learning paradigm for Recurrent-KIF, featuring an inner learner that rapidly captures and localizes new information, and an outer learner that globally controls the fusion of new and historical knowledge.\n\u2022 Extensive evaluation validates the effectiveness of Recurrent-KIF in addressing CL challenges."}, {"title": "Related Work", "content": "Continual Learning for LLMs\nContinual learning (CL) (Zhou et al., 2024) focuses on developing algorithms that accumulate knowledge from non-stationary data. In the LLM era, model mixture-based methods using PEFT have become dominant (Wang et al., 2023b; Huang et al., 2024; Wang et al., 2024e), typically divided into model ensemble and merging approaches.\nModel ensemble methods isolate parameters by assigning independent PEFT blocks to each task (Feng et al., 2023; Pham et al., 2023; Ke et al., 2023; Li et al., 2024; He et al., 2024; Wang et al., 2024a). For example, O-LoRA (Wang et al., 2023a) enforces orthogonality among LoRA adapters, while SAPT (Zhao et al., 2024) uses a selection module to combine blocks based on task correlations. While preserving task-specific knowledge, they hinder inter-task transfer and incur high memory overhead as the number of tasks increases, limiting their scalability.\nIn contrast, model merging methods combine multiple models into a single model (Cheng et al., 2024; Alexandrov et al., 2024; Ren et al., 2024), alleviating memory constraints. For example, global model merging approaches (Wortsman et al., 2022; Ilharco et al., 2023) perform a weighted fusion of models before and after training, typically assuming that all model weights contribute equally to each task. However, determining which and how to merge parameters remains an open problem.\nIn this paper, we propose Recurrent-KIF, a novel framework that leverages the dynamic importance of parameters across different tasks by employing knowledge identification and fusion techniques to mitigate CF and promote KT."}, {"title": "Parameter Importance Identification", "content": "Identifying important parameters or knowledge regions within LLMs has gained significant attention in the NLP community (Zhao et al., 2023; Liu et al., 2023; Feng et al., 2024a; Xu et al., 2024; Shi et al., 2024). This research improves our understanding of LLMs and enhances their performance across a variety of tasks, including model editing (Wang et al., 2024d), compression (Zhang et al., 2023).\nIn the context of CL, Du et al. (2024) use the gradient magnitudes to selectively update parameters. Feng et al. (2024b) employ gradient-based metrics to compare the parameter importance distributions of current and historical tasks, merging task-shared regions to promote KT and retaining task-specific regions to prevent CF. However, these approaches are limited by their reliance on static importance estimations for previous tasks, which become outdated as the model evolves.\nTo address this limitation, Wu et al. (2024b) introduce VR-MCL, a replay-based method that dynamically updates importance information while reducing variance from random sampling. Although VR-MCL achieves dynamic importance estimation for historical tasks, it mainly focuses on preserving task-specific knowledge and does not update taskshared regions, thus limiting KT across tasks. In contrast, inspired by the CLS theory, we propose a dynamic importance estimation method that iteratively updates parameter importance through inner and outer loops. Our approach performs multi-round knowledge fusion, adaptively adjusting the integration of new and historical knowledge based on the latest model state. This method outperforms traditional post-training fusion by enhancing robustness and enabling smoother optimization."}, {"title": "Proposed Method: Recurrent-KIF", "content": "Problem Formulation Continual learning aims to progressively accumulate knowledge from a sequence of tasks {T\u2081, . . . , Tk}. Each task Tk includes a distinct dataset Dk = {(xk, yk)}^Nk of size Nk, where xk \u2208 Xk and yk \u2208 Yk. The model, parameterized by \u0398, is trained sequentially on these tasks to minimize the following objective:\n$\\mathcal{L}=\\mathbb{E}_{(x, y)\\sim \\cup_{k=1}^{K} D_{k}}[-\\log p_{\\Theta}(y|x)]$\\ \nIn this work, we consider a practical scenario where a small portion of data from previous tasks is stored in a memory buffer to facilitate the CL process. Specifically, we randomly store |M| samples from each task Ti in memory Mi. During training, the model is jointly optimized on the new task data Dk and the memory buffer M<k.\nNotation We consider a pre-trained model \u03b8 \u2208 Rn with n parameters. After training on task Tk\u22121, the model are denoted as \u03b8k\u22121. Fine-tuning on a new task Tk produces updated parameters \u03b8k. The difference Tk = \u03b8k \u2212 \u03b8k\u22121, referred to as the task vector or training residual (Ilharco et al., 2023), represents task-specific parameter updates. In the Recurrent-KIF framework, we obtain transient training residuals through each iteration of the inner and outer loops. Specifically, two task vectors are employed to capture and quantify the new knowledge learned in the inner loop and the historical knowledge retrieved in the outer loop.\nOverview Recurrent-KIF restructures the training process into multiple iterative learning cycles, each comprising two key components as illustrated in Figure 2: (i) Inner Learner with Knowledge Identification: rapidly acquires new task knowledge while estimating the corresponding parameter importance, and (ii) Outer Learner with Knowledge Fusion: utilizes a memory buffer to retrieve historical task information. By leveraging the importance distributions of both current and historical tasks, it provides global control for effective knowledge transfer through redundant knowledge pruning and key knowledge merging."}, {"title": "Inner Learner with Knowledge Identification", "content": "Assume the current task is Tk, and the iterative update for the model parameters \u03b8k\u22121 at the b-th iteration are denoted by \u03b8b\u22121. In the inner loop, the model initializes with \u03b8b(0) = \u03b8b and is rapidly updated over Q gradient steps using batch data \u03be sampled from Dk at the q-th step. After obtaining \u03b8b(Q), the task-specific updates are encapsulated in the task vector Tin \u2208 Rn:\n$T_{in}^b = \\theta_{b(Q)} - \\theta_{b(0)}$\nThis task vector captures the knowledge acquired for the current task. However, Tin often contains redundant information, and directly merging it into the model may compromise historical knowledge, leading to catastrophic forgetting. To address this, we propose a knowledge identification technique to identify the key parameters which storing critical knowledge within the task vector.\nWe use a commonly adopted importance metric in model pruning (Konishi et al., 2023), defined as the magnitude of the gradient-weight product:\n$I(\\omega_{ij}) = |\\omega_{ij} \\nabla_{\\omega_{ij}} \\mathcal{L}|$\nwhere \u03c9ij represents trainable parameters.\nDue to stochastic batch sampling and training dynamics, the metric in Eq. (3) may be unreliable, introducing variability (Zhang et al., 2022). To mitigate this, we apply an exponential moving average (Zhang et al., 2023) to smooth the trajectory gradients over Q inner loop iterations:\n$I_b(q) = \\alpha_1I_b(q-1) + (1 - \\alpha_1) I_b(q)$\nwhere \u03b1\u2081 is the smoothing factor, q \u2208 {1, 2, . . . , Q} is the iteration number in the inner loop, and Ib(q) represents smoothed importance. The inner task vector Tin and its associated parameter importance Iin are then passed to the outer learner."}, {"title": "Outer Learner with Knowledge Fusion", "content": "The outer loop manages the global merging of knowledge, guided by parameter importance. To access historical knowledge, after acquiring \u03b8b(Q), the outer loop samples data \u03be from the memory buffer Mk. It then performs a single training iteration, updating the parameters to \u03b8b(M). Then the outer task vector Tout \u2208 Rn, capturing historical task information, is defined as:\n$T_{out} = \\theta_{b(M)} - \\theta_{b(Q)}$"}, {"title": "Dynamic Update of Historical Importance Distribution", "content": "While obtaining the outer task vector, we calculate the historical task importance distribution based on the latest model state \u03b8b(Q), using Eq. (3). The update process is then expressed as:\n$T_{out} = \\mathcal{P}(I_{out} | \\theta_{b(Q)})$\nThis update, based on conditional probability, enables the computation of the historical importance distribution Iout using the current model state. This distinguishes it from traditional static importance estimation methods and ensures more accurate knowledge identification. However, the limited sample size from the memory buffer can introduce significant variance in the importance estimates. To address this, we also apply exponential smoothing to the previous outer loop distribution Iout:\n$\\mathcal{I}^{out} = \\alpha_2\\mathcal{I}^{out} + (1 - \\alpha_2)\\mathcal{I}$\nwhere \u03b1\u2082 is the smoothing factor, enhancing stability and robustness in importance estimation."}, {"title": "Knowledge Fusion via Importance-based Binary Mask", "content": "Knowledge fusion is guided by the importance distributions Iin and Iout. To binarize the importance distributions, a quantile-based threshold \u03b4 is applied to select the top 20% of parameters from both In and Iout. This generates binary masks min \u2208 Rn and mout \u2208 Rn, defined as:\n$m_{in} = I(I_{in} \\ge \\delta_{in}),  m_{out} = I(I_{out} > \\delta_{out})$\nwhere I(\u00b7) is the indicator function that outputs 1 if the condition is met and 0 otherwise. Knowledge fusion is then performed as follows:\n$\\theta_{b+1} = \\theta_b + (m_{in} T_{in} + m_{out} T_{out})$\nwhere \u2299 denotes element-wise multiplication.\nThis knowledge fusion mechanism provides precise global control, effectively tackling key challenges in CL. First, redundant information in the task vectors Tin and Tout is filtered out via the mask operation. Second, task-shared knowledge is effectively merged to facilitate knowledge transfer. Lastly, task-specific knowledge is preserved to prevent catastrophic forgetting.\nThe inner and outer loops operate iteratively, enabling multi-round fusion of knowledge. This iterative process facilitates the capture and absorption of useful information generated during training, providing smoother optimization compared to traditional post-training fusion methods. Detailed implementation of Recurrent-KIF algorithm is provided in the Appendix (Algorithm 1)."}, {"title": "Experiments and Analysis", "content": "Dataset We adopt the experimental setup from Du et al. (2024), using two CL benchmark datasets: (i) Standard CL Benchmark, which consists of five text classification tasks from Zhang et al. (2015): AG News, Amazon Reviews, Yelp Reviews, DBpedia, and Yahoo Answers. (ii) Long Sequence Benchmark, a more challenging evaluation scenario comprising 15 tasks (Razdaibiedina et al., 2023): five from the Standard CL Benchmark, four from the GLUE benchmark (Wang, 2018), five from SuperGLUE (Wang et al., 2019), and the IMDB Movie Reviews dataset (Maas et al., 2011). Following Wang et al. (2023a), we sample 1000 instances for training on each task and reserve 500 per class for validation. Three task sequences are evaluated for each benchmark, with detailed descriptions and orderings provided in Appendix C.\nMetrics Let \u03b1i,j denote the testing performance on task Ti after training on task Tj. We evaluate the overall performance (OP) (Chaudhry et al., 2018) and backward transfer (BWT) (Lopez-Paz and Ranzato, 2017) after training on the final task:\n$OP = \\frac{1}{K} \\sum_{i=1}^{K} \\alpha_{i, K}$\n$BWT = \\frac{1}{K-1} \\sum_{i=1}^{K-1} (\\alpha_{i, K} - \\alpha_{i, i})$\nBaselines We compare Recurrent-KIF against a range of baseline methods, including traditional CL approaches, recent PEFT-based model ensemble and merging methods. (1) SeqLoRA: LoRA parameters are trained on a task sequence without regularization or sample replay. (2) IncLoRA: incremental learning of LoRA parameters without regularization or sample replay. (3) LoRAReplay: LORA fine-tuning with a memory buffer. (4) EWC (Kirkpatrick et al., 2017): finetune LoRA with a regularization loss to prevent interference with previous tasks. (5) L2P (Wang et al., 2022b): dynamically selects and updates prompts from a pool on an instance-by-instance basis. (6) LFPT5 (Qin and Joty, 2021): learns a soft prompt that solves tasks and generates training samples for replay. (7) O-LORA (Wang et al., 2023a): extends IncLORA to learn different LoRAs in orthogonal subspaces. (8) MoELORA (Luo et al., 2024): a vanilla MoE with LoRA number equals to the task number. (9) SAPT (Zhao et al., 2024): uses pseudo samples and a shared attention framework to align PEFT block learning and selection (10) TaSL (Feng et al., 2024b): selectively updates or retains skill regions based on parameter importance. (11) MIGU (Du et al., 2024): updates important parameters based on gradient magnitude. (12) VR-MCL (Wu et al., 2024b): dynamically updates historical task parameter importance distributions using memory replay. Additionally, multi-task learning with LoRA, referred to as MTL, serves as the upper bound.\nTraining Details We evaluate Recurrent-KIF using two distinct language model architectures: the encoder-decoder T5 model (Raffel et al., 2020) (T5-large and T5-xl), and the decoder-only LLaMA model (Touvron et al., 2023) (LLaMA2-7B and LLaMA2-13B). Hyperparameters \u03b1\u2081 and \u03b1\u2082 in Eq. (4) and Eq. (7) are set to 0.55, with the number of inner loop iterations Q set to 8. Following Zhao et al. (2024), 2% of the original training set is used for replay samples. All experiments are averaged over 3 runs. More details are in Appendix D."}, {"title": "Main Results", "content": "The overall CL results using the same T5-large backbone are summarized in Table 1.\nOur Recurrent-KIF effectively addresses the challenges of CF and KT simultaneously. Compared to both traditional CL methods (LoRAReplay, L2P) and model ensemble-based methods (MOELORA, O-LoRA), Recurrent-KIF outperforms them in both CF (increasing average OP from 72.7% to 78.1% compared to O-LoRA) and KT (increasing average BWT from -13.6% to 3.2% compared to LoRAReplay). SAPT achieves the highest performance by leveraging generative replay-based data augmentation, surpassing MTL result. However, it relies heavily on external data synthesis, which can be costly in LLM settings.\nMoreover, when compared to parameter importance-based methods like TaSL and VRMCL, Recurrent-KIF consistently delivers the best OP and BWT scores. Notably, Recurrent-KIF outperforms the state-of-the-art CL method, MIGU, increasing OP from 76.6% to 78.1%. These results underscore the effectiveness of our recurrent knowledge identification and fusion framework, validating the advantages of dynamic parameter importance estimation in mitigating CF and promoting KT.\nRecurrent-KIF demonstrates consistent superiority across various backbones. To further validate the robustness of Recurrent-KIF, we conduct experiments across different backbones (Figure 3). Across all backbone sizes, from 770M to 13B, Recurrent-KIF consistently outperforms all baseline models. For instance, using the LLaMA27B backbone, Recurrent-KIF boosts the OP metric from 75.6% to 78.2% compared to VR-MCL. These results emphasize the critical role of accurate parameter importance estimation and demonstrate the robust generalization capability of RecurrentKIF across different model scales."}, {"title": "Ablation Study", "content": "We conduct ablation studies to assess the effectiveness of the proposed techniques in Recurrent-KIF. The results for task order 1 on the Long Sequence Benchmark are shown in Table 2. Additional experiments, such as time complexity analysis, the impact of memory size, and hyperparameter sensiEffect of Dynamic Importance Estimations. To validate the role of dynamic importance estimation, we replace it with a static version (\u201c- DIE\u201d), where importance scores for historical tasks remain fixed after their initial computation. The significant performance decline (3.1% on OP and 1.4% on BWT) highlights the necessity of dynamically updating historical task importance distributions. By maintaining up-to-date importance scores, our approach improves both robustness and accuracy, thereby enhancing knowledge retention and transfer.\nEffect of Importance-Based Binary Mask Strategy in Knowledge Fusion. We replace our knowledge fusion mechanism with three alternative model merging strategies: (i) Without knowledge identification (\u201c- KI\u201d): Directly merge Tin and Tout in Eq.(9) without applying importance-based fusion. (ii) Global importance-based merging (\u201c+ GM\u201d): Use a global weighted sum of importance scores Iin and Iout for fusion instead of applying element-wise masking. (iii) Adaptive Fusion (Yang et al., 2024) (\u201c+ Adaptive\u201d): A soft masking method that uses raw importance scores directly for fusion instead of binary masks. Additionally, we evaluate the effectiveness of updating the task-shared region by introducing \u201c- Share\u201d, where min is set to 0 when both min and mout are 1.\nThe results in Table 2 confirm the effectiveness of importance-based binary masking in filtering redundant information and preserving task-specific knowledge. Moreover, disabling updates to the task-shared region leads to performance drops of 2.1% and 0.9% on two evaluation metrics, demonstrating that updating task-shared parameters is critical for effective knowledge transfer between tasks."}, {"title": "Visualization", "content": "We present two key visualizations to analyze the effectiveness of our proposed methods:\nCan the Magnitude of the Task Vector Reflect Parameter Importance? We explore the relationship between task vector magnitude and parameter importance scores. As shown in Figure 5(a), although the magnitude of parameter updates is generally large, only a subset of parameters, mainly in the encoder, are truly important. This indicates that a large portion of the parameters are redundant, highlighting the need for our importance-based knowledge fusion mechanism.\nDoes the Importance Distribution of Historical Tasks Change with Model State? Figure 5(b) illustrates the shift in the importance distribution of historical tasks before and after training on a new task. While the overall distribution remains stable across model states, notable changes in specific importance scores are observed, highlighted by the dashed box. This demonstrates the value of dynamic estimation, enabling more precise identification of key parameters and enhancing knowledge fusion across tasks. A more detail analysis is provided in Appendix A."}, {"title": "Conclusion", "content": "In this paper, we introduce Recurrent Knowledge Identification and Fusion (Recurrent-KIF), a novel CL framework that dynamically estimates the importance of parameters for previous tasks. Recurrent-KIF iteratively employs an inner learner to localize new knowledge and an outer learner to manage the global fusion of knowledge, enabling real-time and adaptive adjustments to the fusion strategy based on evolving importance distributions. Extensive experiments demonstrate the effectiveness of Recurrent-KIF in addressing continual learning challenges."}, {"title": "Limitations", "content": "We acknowledge two limitations in this work. Firstly, Recurrent-KIF is a rehearsal-based method. The outer loop relies on memory data to retrieve and dynamically update the parameter importance distributions of historical tasks. This reliance may limit its applicability in scenarios where privacy concerns or data retention restrictions are present. Generative replay techniques could provide a solution by simulating the distribution of previous tasks without direct access to historical data.\nSecondly, the time complexity of Recurrent-KIF increases with larger backbone models, primarily due to element-wise operations and multi-round fusion. For element-wise operations, global merging strategies have proven suboptimal, highlighting the need for balanced fusion granularity. Future work could explore focusing on specific important layers or adopting modular approaches to enhance efficiency. For multi-round fusion, we could further investigate how fusion frequency impacts performance and analyze the semantic knowledge learned at different stages of the training process. This could help minimize unnecessary iterations, while still preserving the benefits of iterative integration."}, {"title": "Limitations of Static Parameter Importance Estimation", "content": "In this section, we empirically demonstrate the limitations of static parameter importance estimation by analyzing how historical parameter importance distributions change under different conditions. Static importance estimation assumes that the importance scores of historical tasks remain fixed, which is both inaccurate and introduces biases during the knowledge fusion process. To highlight the dynamic nature of parameter importance, we analyze the following two aspects:\nChanges in Historical Importance After Learning Different New Tasks. We investigate how the parameter importance distribution for a fixed historical task changes after the model is fine-tuned on different new tasks. Specifically, the model is trained sequentially on various new tasks, and the importance scores of the same historical task are re-evaluated using the updated model parameters. As shown in Figure 7, although the regions identified as important for the historical task remain largely consistent after learning different new tasks, the specific importance values exhibit noticeable differences. This variability demonstrates that historical parameter importance is heavily influenced by the specific characteristics of the new task, making static importance estimation insufficient for accurately capturing the evolving model dynamics."}, {"title": "Sensitivity Analysis for Hyperparameters", "content": "The proposed framework incorporates three key hyperparameters, including the smoothing factor \u03b1 for computing importance scores in Equations (4) and (7), the threshold \u03b4 for determining the importance of parameters, and the number of inner and outer loop training steps. Our analysis aims to assess the impact of varying these hyperparameters on our method's performance, testing on the T5large backbone model.\nAs evidenced in Table 6, we determine that the optimal setting for \u03b1 is 0.55. An \u03b1 value too low results in a performance decline, indicating that the calculated importance scores are not accurate."}, {"title": "Time Complexity Analysis", "content": "In this section, we discuss the time complexity issues introduced by the techniques used in Recurrent-KIF. The additional time complexity can be explained qualitatively: assuming the number of training iterations for vanilla training is N', we set the total number of iterations for the inner loop to N' as well. This ensures a fair comparison with traditional methods, while also minimizing the number of iterations in our approach. In this case, the total number of iterations for our method is N' + (N'/Q), where N'/Q corresponds to the iterations of the outer loop. Typically, N' is 1024, and with Q set to 8, this results in an additional 12% increase in training time.\nRegarding the time consumption of knowledge identification and fusion, the variables used in the knowledge identification phase are derived from the gradients produced during normal training, requiring no extra computation time, only additional space to store parameter importance information. The knowledge fusion phase involves only simple univariate calculations, as shown in Equation (9). Therefore, the overall time complexity does not increase significantly."}, {"title": "Effect of the Different Importance Metric in Knowledge Identification", "content": "We compare two alternative importance scoring approaches with Eq. (3): (i) using absolute gradients (Michel et al., 2019), |\u2207wij L|, instead of the gradient-weight product; and (ii) removing exponential moving average, relying only on importance scores computed from a single batch.\nAs shown in Table 10, our method with exponential smoothing outperforms the alternatives, with performance drops of up to 2.0% and 1.3% without smoothing. Similarly, using absolute gradients leads to lower performance compared to the gradient-weight product, underscoring the effectiveness of our approach in enhancing knowledge identification and model performance."}, {"title": "Dataset Statistics", "content": "Table 11 show details of the datasets we used for our experiments, along with their evaluation metrics (Wang et al., 2023a; Feng et al., 2024c; Xu et al., 2023). For the Long Sequence benchmark, this includes five tasks from the standard CL benchmark (AG News, Amazon reviews, Yelp reviews, DBpedia and Yahoo Answers), four from GLUE benchmark (MNLI, QQP, RTE, SST2), five from SuperGLUE benchmark (WiC, CB, COPA, MultiRC, BoolQ), and the IMDB movie reviews dataset. We report 6 different task orders used for our experiments in Table 12. Table 13 shows prompts for different tasks. NLI denotes natural language inference (Lu et al., 2021b), including MNLI, RTE and CB. SC denotes sentiment analysis, including Amazon, Yelp, SST-2 and IMDB. TC denotes topic classification, including AG News, Dbpedia and Yahoo."}, {"title": "Implementation Details", "content": "Experiments are implemented using PyTorch and the Transformer library, running on a single NVIDIA A100 GPU with 80GB memory. The following hyperparameters are used:\n\u2022 T5-large (770M) and FLAN-T5-XL (3B): Learning rate of 3e-4 for both loops, inner and outer batch sizes of 8, max input length 512, max target length 128, and 10 epochs. LoRA settings: r = 8, \u03b1 = 32, dropout = 0.05, targeting modules [q,v]. Testing: max new tokens = 128.\n\u2022 LLAMA-2 (7B) and LLAMA-2 (13B): Learning rate of 3e-4 for both loops, inner and outer batch sizes of 64, cutoff length 512, and 10 epochs. LORA settings: r = 8, \u03b1 = 32, dropout = 0.05, targeting modules [q_proj,v_proj]. Testing: temperature = 0.02, top_p = 0, top_k = 1, num_beams = 1, max new tokens = 128.\nIt is worth noting that we used the same hyperparameters across different datasets and backbones, demonstrating the generalizability of our method without requiring extensive hyperparameter tuning for each specific setting."}, {"title": "Algorithm", "content": "In this section, we provide the detailed implementation of Recurrent-KIF algorithm (see Algorithm 1)."}]}