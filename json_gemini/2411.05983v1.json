{"title": "LONGITUDINAL ENSEMBLE INTEGRATION FOR SEQUENTIAL CLASSIFICATION WITH MULTIMODAL DATA", "authors": ["Aviad Susman", "Richard Yan Chak Li", "Serdar Bozdag", "Nasim Sheikh-Bahaei", "Rupak Krishnamurthy", "Mohammad Al Olaimat", "Bino Varghese", "Gaurav Pandey"], "abstract": "Effectively modeling multimodal longitudinal data is a pressing need in various application areas, especially biomedicine. Despite this, few approaches exist in the literature for this problem, with most not adequately taking into account the multimodality of the data. In this study, we developed multiple configurations of a novel multimodal and longitudinal learning framework, Longitudinal Ensemble Integration (LEI), for sequential classification. We evaluated LEI's performance, and compared it against existing approaches, for the early detection of dementia, which is among the most studied multimodal sequential classification tasks. LEI outperformed these approaches due to its use of intermediate base predictions arising from the individual data modalities, which enabled their better integration over time. LEI's design also enabled the identification of features that were consistently important across time for the effective prediction of dementia-related diagnoses. Overall, our work demonstrates the potential of LEI for sequential classification from longitudinal multimodal data.", "sections": [{"title": "INTRODUCTION", "content": "Data that are both longitudinal/temporal and multimodal are increasingly being used in combination with machine learning for forecasting, especially in medical diagnosis (Brand et al., 2019; Zhang & Shen, 2012; Feis et al., 2019; Li et al., 2023). Recently, a number of promising approaches for sequential classification from such data have been introduced (Eslami et al., 2023; Zhang et al., 2011; Wang et al., 2016; Zhang et al., 2024). For instance, some approaches have used recurrent neural network (RNN)-based models applied to data sequences where the modalities at each time point have been concatenated into a long feature vector, sometimes referred to as early fusion (Nguyen et al., 2020; Olaimat et al., 2023; Maheux et al., 2023). Generally, due to the complexity of this modeling, these approaches generally consider only a limited set of modalities, samples, or time points. In addition to computational issues, the early fusion of data across modalities may obfuscate signals local to the individual data modalities (Zitnik et al., 2019; Li et al., 2022). This may hinder model performance, as the differing semantics and scales of the various modalities are not adequately accounted for. This represents a major challenge for the automated classification of multimodal"}, {"title": "2 PROPOSED APPROACH", "content": "Below, we describe the methods used in our study. All the code used to implement these methods is available at the LEI GitHub repository."}, {"title": "LONGITUDINAL ENSEMBLE INTEGRATION (LEI)", "content": "Our proposed approach, LEI, extends the capabilities of EI (Figure 1) for sequential classification from longitudinal multimodal data. In LEI, we first apply base predictors to data from multiple modalities at the studied time points (top half of Figure 2; see Li et al. (2022) for the implementation details of EI used in this work). Longitudinal models for the target label(s) are then built upon the probabilities from the base predictors using stacking (Sesmero & Ledezma, 2015) (bottom half of Figure 2). Stacking traditionally learns a static meta-predictor over the base predictors using any applicable classification algorithm, e.g., SVM and Random Forest, as is done in EI. However due to the longitudinal aspect of the current work, a sequence-to-sequence LSTM was used as the stacking algorithm. Specifically, in this work, each set of multiclass base predictors (such as KNN, Logistic Regression, SVM, Random Forest, and XGBoost), derived from the individual TADPOLE modalities, output probability vectors of a length equal to the number of classes, indicating whether a patient would receive a diagnosis of CN, MCI or Dementia at the corresponding time point. An ordinal representation of the labels by way of the mapping CN \u2192 0, MCI \u2192 1, Dementia \u2192 2 was used for training the base predictors. In our stacking architecture, the hidden states produced by all the LSTM nodes up to and including time point t were processed to produce the predicted label(s) at time point t + 1. We took the sequence-to-sequence approach to reduce computational complexity and build models whose parameters could be optimized by complete sequences of longitudinal data."}, {"title": "LEI CONFIGURATIONS", "content": "Although the basic design of LEI is straightforward, (Figure 2), the availability of several base predictors at multiple time points, as well as the architecture of the LSTM stacker, lend the design to be implemented in multiple configurations. Four such configurations were developed and evaluated. They are distinguished by the modeling approaches taken at the beginning base predictor step and the final classification. In the regime of sequential classification with machine learning, three broad strategies are common.\n\u2022 What we refer to as time-dependent modeling involves setting up and solving a separate modeling problem at every time point within a sequence of data and therefore only uses a cross section of the data for model training and evaluation of all models involved.\n\u2022 In the time-distributed modeling approach, a single static model is trained and evaluated on all of the cross sections of data from all time points within a sequence of data but separate time points are treated as independent.\n\u2022 In longitudinal modeling, a model capable of leveraging longitudinal patterns in a sequence of data is used to classify the elements of the sequence, such as with RNNs or LSTMs.\nIn this work, different combinations of these three strategies were used at different steps in the LEI algorithm to yield the four combinations evaluated:\n1. Time-dependent base predictors (BPs) that are stacked by an LSTM with a time-distributed classification head.\n2. Time-dependent BPs that are stacked by an LSTM with a longitudinal classification head.\n3. Time-distributed BPs that are stacked by an LSTM with a time-dependent classification head.\n4. Time-distributed BPs that are stacked by an LSTM with a longitudinal classification head.\nBelow, we describe each of these configurations of LEI in detail."}, {"title": "CONFIGURING BASE PREDICTION GENERATION/AGGREGATION", "content": "For generating base predictions in the first step of LEI (top half of Figure 2), both time-dependent modeling (Configurations 1 and 2) and time-distributed modeling (Configurations 3 and 4) were explored. In the time-dependent approach, separate sets of base predictors were trained and used to generate predictions at each time point, followed by their concatenation for the final ensemble (Figure 3). This approach has the potential advantage of generating predictions for the stacker that are optimized for the time point corresponding to the original data.\nIn the time-distributed approach, the longitudinal data were flattened across the time dimension and a single instance of each of the base predictors was trained on all the data across all time points (Figure 4). A numerical feature indicating the time point corresponding to a sample was concatenated to the original data as a form of positional encoding for this approach as well. In all data splitting steps, feature vectors of the same sample were always kept in the same split to prevent data leakage. A practical advantage of this approach is that each base predictor is trained on $TN$ samples, as opposed to $N$ in the time-dependent case. Similarly, a factor of $T$ fewer total models are trained in the time-distributed base predictor approach than in the time-dependent setting, which can reduce computational complexity. A more subtle potential strength of time-distributed base predictors is that training the same instances of each model on all of the longitudinal data within a modality guarantees the semantic consistency of the base predictions when used as longitudinal features for classification by the downstream LSTM. This is because for a given modality/base predictor pairing, the corresponding feature at every time point represents a prediction arising from the same decision boundary. The semantic consistency of features across time is an essential aspect of the inductive bias of models like RNNs and LSTMs (Hochreiter & Schmidhuber, 1997)."}, {"title": "CONFIGURING THE SEQUENTIAL CLASSIFICATION HEAD WITHIN LEI", "content": "While LSTMs were used in all configurations of LEI, different approaches were taken for the final sequential classification of the data. The standard approach, as in Foumani et al. (2024), employs time-distributed modeling where the hidden states output at every time point by the LSTM are processed by a classifying MLP (Configurations 1 and 3). This approach has the possible benefit of consistently strong performance across time due the model's focus on feature level information independent of time point. There is also the general possibility of modest gains across time due to the richer temporal information stored in hidden states from later time points.\nWe also employed a longitudinal modeling approach at this stage, where a multi-layered LSTM was used. The softmax activated hidden states from the last layer, equal in length to the number of classes, were output to the loss function (Configurations 2 and 4). This approach may have the advantage of improved performance across time as the classifier can capture temporal dependencies and use them to make a classification.\nA time-dependent sequential classification approach was also explored. However, this approach did not perform on the same level as the other approaches due to the limited training data available to the classifiers at each time point."}, {"title": "INTERPRETATION OF LONGITUDINAL EI MODELS", "content": "The original EI framework enabled the identification of the most predictive features at individual time points. Since deep learning methods like LSTMs are well-known to be hard to interpret, as demonstrated by Zhang et al. (2021), we adopted an alternate approach based on the interpretation of static EI models (Li et al., 2022). Specifically, we used the latter's algorithm to identify the ten most predictive features at each time point, and then analyzed how these sets varied over the temporal trajectory. To make the interpretations consistent with the LEI algorithm, the stacking algorithms used in static EI were trained with the labels at time t + 1."}, {"title": "EVALUATION METHODOLOGY", "content": "The longitudinal multimodal data used to evaluate LEI were from (Marinescu, 2019)'s TADPOLE Challenge, which were derived from the ADNI 1, 2, and GO studies (Petersen, 2010; Beckett et al., 2015; Toga & Crawford, 2015). These data modalities included cognitive test scores, demographic information and neuroanatomical measurements from MRI and PET scans. However, several of the original TDAPOLE modalities included features that were missing for a substantial fraction of the patients at one or more time points, which would have been difficult to impute reliably, as shown in Dziura et al. (2013), and were likely to adversely affect downstream analyses (Nijman, 2022). So the features that were missing in at least 30% of the patients at any time point were removed from our dataset. This also resulted in some modalities, such as PET scans, being excluded from our analyses."}, {"title": "TRAINING AND EVALUATION", "content": "We translated the nested cross-validation setup for the training and evaluation of the static EI framework introduced in (Li et al., 2022) to the various configurations of LEI as well. Specifically, the overall evaluation of LEI was conducted in a five-fold cross-validation (CV) setup, where 80% of the cohort was used for training the models, and the remaining 20% for evaluation. Furthermore, the base predictors at each time point were trained using the diagnosis labels at the same time point,"}, {"title": "RESULTS", "content": "Below, we describe our observations on the performance and interpretation of LEI."}, {"title": "RELATIVE PERFORMANCE OF LEI CONFIGURATIONS", "content": "Figure 6 shows how the performance of LEI was affected by altering its configuration in the ways described in Section 2.2 and evaluated as specified in section 3.2. The results show how effective each configuration is at using the longitudinal multimodal data available until a particular time point to make a diagnosis prediction at the next time point. It can be seen from these results that a time-distributed approach to base predictor generation was preferable in this study, with respect to both stacking approaches, but especially when combined with a longitudinal stacker and at later time points when more longitudinal data could be leveraged (dotted green curve in Figure 6). Here, the advantage of training each base predictor on $T$ times the number of feature vectors as in the time-dependent approach, (Figures 3 and 4) may be responsible for improved downstream performance. Similarly, as explained in Section 2.2.1., time-distributed modeling guarantees semantic consistency across time in the base predictions when they are used as features in the downstream longitudinal modeling.\nAn observation of note is the different behaviors that arise from the use of a longitudinal classifier and a time-distributed classifier at the stacking step. Configurations with longitudinal stackers consistently performed weaker at the earlier time points but improved significantly in performance over time, eventually outperforming the time-distributed configurations. This was likely due to the longitudinal stackers' ability to aggregate information across time, whereas the time-distributed stackers were able to maintain a consistent performance at all time points due their focus on feature level information contained in the hidden states while being agnostic to the time points the hidden state vectors corresponded to. It is also worth noting that the time-distributed models do marginally increase in performance across time, although not consistently. This may be attributable not to the architectures of the classifiers but the quality of their inputs. Specifically, hidden state vectors corresponding to later time points have richer temporal information embedded within them and so can help to make more accurate predictions."}, {"title": "COMPARISON OF LEI AND BENCHMARK METHODS", "content": "Figure 7 shows the performance of the best performing configuration of LEI (time-distributed base predictors + longitudinal stacker, see dotted green curve in Figure 6) with respect to that of the benchmarks described in Section 3.3. These results further demonstrate the ability of longitudinal sequential classifiers to aggregate information across time for increased classification performance. The baseline LSTM + MLP classifier (represented by the solid red curve), that both ignored the multimodality of the data and used time-distributed classification, performed significantly worse than all others over time. Specifically, due to its ability to leverage the complementarity and consensus"}, {"title": "INTERPRETATION THE LEI-BASED EARLY DEMENTIA DETECTION MODEL", "content": "Finally, we interpreted the best-performing LEI model as described in Section 2.4. The interpretation was done with respect to what was previously described as the best LEI configuration. Figure 8 shows the results of this interpretation in terms of the ten most predictive features at each time point. Our data driven algorithm showed and confirmed that CDR-SB is one of the top predictors of future cognitive outcome in line with the prior literature in Alzheimer's research (Tzeng et al., 2022; Williams et al., 2013). Also in agreement with the literature in this field, we found Entorhinal cortical thickness and volume to be major contributors to predicting patients' future diagnoses (Igarashi, 2023; Newton et al., 2024; G\u00f3mez-Isla et al., 1996; Astillero-Lopez et al., 2022; Bobinski et al., 1999). Perhaps most interestingly, the importance of the Functional Activities Questionnaire (FAQ) increased at later time points. This is consistent with the importance of FAQ as a key examination in differentiating MCI from dementia when the cognitive evaluations are similar (Marshall et al., 2015; Teng et al., 2010). Thus, it is sensible that the importance of this feature increased as LEI was trying to make more predictions of dementia cases at later time points (Figure 5). Observations such as the above suggest the utility of LEI for uncovering useful domain knowledge about longitudinal multimodal prediction problems like the early detection of dementia."}, {"title": "DISCUSSION", "content": "This work investigated the potential of our novel Longitudinal Ensemble Integration (LEI) framework, for sequential classification from temporal multimodal data. LEI builds upon the success of the existing El framework by integrating base predictors inferred from the multimodal data over time through an LSTM stacker. We tested LEI on longitudinal multimodal clinical data from the ADNI-derived TADPOLE cohort to predict the likelihood of patients' progression to dementia. LEI performed better than several other approaches that have been used for predicting Dementia progression, such as an LSTM and PPAD applied to the raw TADPOLE data. The framework also identified several predictive features and their variations over time that could expand our knowledge of the key characteristics of progression to dementia. In conclusion, our work demonstrates the potential of LEI for effectively integrating longitudinal multimodal data for sequential classification.\nHowever, our work also had some limitations. During our processing of the TADPOLE data, any feature with missing values for over 30% of patients at any time point was eliminated. This resulted in several clinically useful imaging modalities, such as FDG PET, AV45 PET, AV1451 PET and DTI, being removed, potentially deteriorating prediction performance. The exclusion of the"}, {"title": "EQUATION", "content": "$$DWCCE(y, \\hat{y}) = - \\sum_{t=1}^{T} \\sum_{c=1}^{C}  \\omega_c \\cdot w_o(\\hat{y}, y^t) \\cdot y_c^t \\log(\\hat{y}_c^t)$$"}]}