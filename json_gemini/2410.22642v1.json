{"title": "Prove Your Point!: Bringing Proof-Enhancement Principles to Argumentative Essay Generation", "authors": ["Ruiyu Xiao", "Lei Wu", "Yuhang Gou", "Weinan Zhang", "Ting Liu"], "abstract": "Argumentative essay generation (AEG) aims to generate complete texts on specific controversial topics or debates. Although current AEG methods can generate individual opinions, they often overlook the high-level connections between these opinions. This often leads to the generated results being mired in logical confusion, unable to proof their own arguments effectively. The generated essay may present evidence that contradicts the claims or they may fail to assemble the claims into logical flow. In this paper, we present a unified two-stage framework: Proof-Enhancement and Self-Annotation (PESA) for AEG with a focus on logical enhancement. Specifically, we first construct pseudo-labels for logical information, claims and grounds, using a large language model. We then propose a tree planning approach that introduces proof principles and ensures logical consistency. Extensive experimental results show that, benefiting from proof principle guidance, PESA generates argumentative essays with better logical validity and persuasiveness than strong baseline models.", "sections": [{"title": "1 Introduction", "content": "From decision-making to public discussions, argumentative texts serve to proclaim ideas or defend a point of view in a wide range of scenarios Sato et al. (2015). Argumentative essay generation (AEG) is a task designed to generate a persuasive argumentative text containing several arguments on a given controversial debate topic (e.g., whether euthanasia should be legalized). Bao et al. (2022) introduced a keywords text-planning method to the AEG task. The plan-and-write paradigm used in this method enriches the length and content of argumentative text, yielding impressive results. However, due to the lack of logical and proof guidance in planning, current AEG methods tend to overlook the high-level connections between individual opinions.\nExisting AEG methods, although capable of generating meaningful opinions, consistently struggle with providing compelling proof. Specifically, the generated essay may present evidence that contradicts the claims or they may fail to assemble the claims into logical flow. In Figure 1, we give a example of logical disorganization leading to impaired persuasiveness. In the upper example of Figure 1, we observe that the data and evidence given in the paragraph not only fail to proof the claim but even contradict it. These instances highlight a significant challenge in the AEG task: the generated claims and evidence are not not been proven properly and organize into logically consistent, persuasive argumentative texts.\nHuman writers encounter difficulties in providing evidence when engaging in argumentative writing. To address this, educators have introduced a set of proof guidelines and norms to guide students"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Text-planning Method in Neural Generation", "content": "Given that natural language generation models often produce texts that lack relevance to the topic or exhibits a deficiency in high-level structure(Zhao et al., 2017; Xu et al., 2020), the idea of using external information as text-planning to guide generative models has a long history.\nCurrently, researchers have shown great interest in applying text-planning to large-scale pre-trained language models such as GPT. Tan et al. (2021) used several keywords as planning and progressively refined them via multiple stages into generate coherent long texts. Mirowski et al. (2023) built structural context via prompt chaining and large language model to enhance usefulness for long-form creative writing. Guan et al. (2023) extended Transformer model to dynamically learn and update text planning, which led a more coherent and diverse stories and news generation.\nThe study of the AEG began relatively late and research on relevant methodologies is still in its infancy due to its remarkable challenging nature. Bao et al. (2022) first proposed ArgEssay, a large-scale standard dataset that collected 11,000 high-quality argumentative essays. In AEG-related tasks, such as argument generation, we could also witness great attempts to utilize text-planning. Hua et al. (2021) used concepts and knowledge relevant to viewpoints as planning to increase the persuasiveness of argument generation. Hu et al. (2022) amplified Transformer decoder with latent representations and maintained sentence-level text-planning based on word packets, succeeding in generating more content-rich coherent text.\nHowever, all these existing methods failed in generating the structure of argumentative texts. Moreover, current planning methods often rely on unreadable hidden variables or a series of keywords, which is lack of interpretation for language models."}, {"title": "2.2 Opinion Text Generation", "content": "Opinion generation produces arguments for or against a given topic. Unlike the AEG task, generating a number of major claims is enough for opinion generation task and it does not require a full essay with detailed argumentative process.\nWith the development of large-scale pre-trained generative language models, recent research has emphasized the direct generation of arguments using generative methods. Gretz et al. (2020) devised an opinion generation pipeline using GPT-2. Schiller et al. (2021) proposed a controlled opinion generation model capable of producing sentence-level arguments based on given topics, positions, and aspects. Al Khatib et al. (2021) developed three argumentative knowledge graphs and extracted knowledge from that to formulate prompts for training end-to-end opinion generation models. Hu et al. (2023) proposed a agent interaction framework for opinion and counter-arguments generation using ChatGPT.\nThe above approaches mainly focused on generating single and brief arguments, without considering the generation of coherent long argumentative texts encompassing multiple arguments."}, {"title": "3 Method", "content": ""}, {"title": "3.1 Overview", "content": "The AEG task can be formally defined as follows: given a writing prompt $X = \\{w_1, w_2, ..., w_n\\}$, generate coherent and persuasive argumentative text $Y = \\{w_1, w_2, ..., w_m\\}$ associated with the writing prompt.\nDrawing inspiration from the theory of Toulmin Argumentation Model, we propose a unified framework that brings hierarchical proof principles and logical information i.e., claims and grounds, to AEG task, named PESA. As shown in Figure 2, PESA is consists of two approaches: (i) Self-Annotation and (ii) Proof-Enhancement.\nThe Self-Annotation approach creates a model $f$, that inputs a writing prompt $X$ and its ground truth $Y$, and outputs the fine-grained logical pseudo labels $U^h$, such that, $f(X,Y) = U^h$. Next the Proof-Enhancement approach employs a model $g$ that uses the pseudo labels $U^h$ and the writing prompt $X$ to generate argumentative text, that is $g(X,U^h) = Y$."}, {"title": "3.2 Proof-Enhancement", "content": "Proof-Enhancement abstract Toulmin Argumentation Model into two-tier tree to finely organize claim proof flow and detail grounds. The first level generates a set of major claims to dictate the overall logical structure. The second level generates data, evidence, and other supplemental writing materials to guide sentence-level writing.\nProof-Enhancement approach introduces structural information using two levels of tree text-planning. Specifically, this planning contains two components: (i) Claims Planning: a list of major claims based on the essay's topic, and each of them should build a complete logical chain to argue for a particular topic or express a specific point of view. (ii) Grounds Planning: a list of supporting evidence or the process of logical reasoning to justify each claim respectively. Finally, the generative model expands the Proof-Enhancement into a complete argumentative essay.\nThese two-tier planning are formally notated as $U^c$ and $U^g$. Notably, unlike most of the previous work, we employ $U^c$ and $U^g$ constructed in natural language similar to a human outline instead of using unreadable hidden variables or embedding. This is because utilizing methods like self-instruction learning that allows models to understand natural, readable planning, can be seen as a more user-friendly approach for generative LLM.\nMore specifically, the first step is to train the model $M_g$, this model aims to generate the major claims for each paragraph, considering their relevance to the given topic and the logical structure, such as juxtaposition and progression among these claims, which shape the overall logical flow of the full text.\n$\\hat{U}^c = M_g(x)$.\nAfter that, the next model $M_e$ is trained. This model needs to generate evidence and data for each major claim in form of brief paragraph, considering proper logical reasoning to support the claim accordingly, which consist the intra-paragraph logical structure.\n$\\hat{U}^g = M_e(x, \\hat{U}^c)$.\nFinally, the generate model $M_o$ expands claim planning and ground planning to complete the AEG task.\n$\\tilde{Y} = M_o(x, \\hat{U}^c, \\hat{U}^g)$.\nFigure 2 illustrates detailed process diagram of this method, while figure in Appendix B provides an in-depth overview of the Proof-Enhancement design. Through this methodology, a Toulmin Model structure is explicitly introduced into the generation process, enabling the model to generate human-like logical structures that better fulfill the requirements of the AEG task."}, {"title": "3.3 Self-Annotation", "content": "Self-Annotation data augmentation method resembles the condensation process of discursive text examples, constructing text-planning ground truth step by step from the argumentative text paradigm. Tree logical structure is attaining through a layer-by-layer summary of the text, yielding both abstract claims and specific grounds.\nThe process of Self-Annotation acts as the inverse process of the Proof-Enhancement. Drawing inspiration from the hierarchical summary technique proposed by Wu et al. (2021), we construct claim and ground planning pseudo-labels using logical information naturally contained in multi-layer summaries. For scalability reasons, we use LLM automatic annotation instead of human annotation to generate pseudo-labels for Proof-Enhancement training. Manual evaluation shows that our proposed Self-Annotation method has similar accuracy and high consistency with human labeling results.\nFor each writing prompt $x \\in X$ and argumentative text ground truth $y \\in Y$, firstly, we use GPT-4 to generate summaries for each paragraph of $y$. These summaries are instructed to contain complete logical structure and grounds such as examples and logical reasoning sentences, and serve as the ground planning $U^g$. Then these summaries are used as a foundation to extract the paragraph major claims, which could constitute the claim planning $U^c$.\n$U^g = \\psi(y)$,\n$U^c = \\psi(y, U^g)$,\nwhere $\\psi$ is a function to summaries y layer-by-layer using LLM to extract logical and proof information from the given text. In this way, we extend the labeled dataset D into a pseudo-labeled dataset $D^P = \\{(x_i, Y_i, U_i^c, U_i^g, U_i^h)\\}$. Intuitively, logical information can bring additional supervision signals for training Proof-Enhancement.\nWe illustrate this pair of processes in Figure 2, it is clear that the Self-Annotation process is similar to long text compression. Several studies have shown that LLMs such as ChatGPT and GPT-4, are good data annotators and generators because they could produce data whose quality is comparable to those manually created by humans. As a result, the quality of the generated text-planning using this approach can be guaranteed."}, {"title": "3.4 Training and Inference", "content": "PESA framework is designed to train three generative models: (i) a model $M_g$ aims to generate claims planning (ii) a model $M_e$ aims to generate ground planning and (iii) a model $M_o$ aims to generate the whole argumentative essay. The above three models are individually trained with the following loss functions:\n$L_c = \\sum_{X} \\sum_{t=1} log P(U_t^c|X_t)$,\n$L_g = \\sum_{X} \\sum_{t=1} log P(U_t^g|U_t^c, X_t)$,\n$L_e = \\sum_{X} \\sum_{t=1} log P(Y_t|U_t^g, U_t^c, X_t)$,\nwhere X, $U^c$, $U^g$, and Y represent writing prompt, claims planning, ground planning, and argumentative essay, respectively. We introduce an algorithm using pseudo-label data and Proof-Enhancement, as shown in Algorithm 1.\nAs for the inference process, we generate $U^c$, $U^g$ and Y sequentially using a form of pipeline, and all generation steps are done using an autoregressive large language model."}, {"title": "4 Experimental Setting", "content": ""}, {"title": "4.1 Dataset", "content": "We evaluated our model on the ArgEssay(Bao et al., 2022), the largest standardized assessment dataset currently available for the AEG task. This dataset comprises 11,000 high-quality argumentative essays and corresponding writing topics sourced from various international standardized English writing tests (e.g., IELTS and TOEFL). It covers a range of common controversial topics such as technological advances, educational approaches, and environmental issues. The final dataset consists of 11,282 writing topic-argumentative text pairs, of which 9,277 pairs are allocated to the training set, 1,002 pairs to the validation set, and 1,003 pairs to the test set."}, {"title": "4.2 Baselines", "content": "We compared our proposed approach with several strong baseline models to showcase its effectiveness. Given the absence of typical LLM-based approaches in the AEG task for fair comparison, we established several LLM-based strong baselines and conducted comprehensive comparisons.\nDD-KW. The text-planning method proposed by Bao et al. (2022). This method uses a series of keyword sets as planning, and designs a dual decoder structure based on BART, one is a planning decoder (PD) to generate text-planning, and the other is a writing decoder (WD) finally generates argumentative texts.\nDD-Rel. Another text-planning method proposed by Bao et al. (2022) using same framework, and changes the text-planning from keywords to the relational triples drawn from open source knowledge graph.\nLLaMA-base. Touvron et al. (2023) presents a collection of baseline language models from 7B to 65B parameters LLaMA. LLaMA-13B achieve SOTA results on various benchmarks, which is a very strong baseline model especially for text generation tasks. We fine-tuned LLaMA2-13B-chat as an end-to-end generation model for AEG task named LLaMA-base.\nLLaMA-CoT. Wei et al. (2022) presents a chain of thought prompt that significantly improves the ability of large language models without training. We design a CoT prompts on the LLaMA2 base model to fit the AEG task named LLaMA2-COT."}, {"title": "4.3 Evaluation Metrics", "content": "Automatically evaluating open-domain text generation text is a challenging task(Celikyilmaz et al., 2021). For the AEG task, evaluating the quality of generated text solely based on automatic metrics such as BLEU can be insufficient, as there can be multiple valid argumentative essays in the ground truth. To solve this problem, some works in recent years have utilized GPT-4 for ground-truth-free evaluation, which significantly enhance the consistency of automatic evaluation metrics with manual evaluation(Hu et al., 2023; Liu et al., 2023; Fu et al., 2023). Inspired by these work, we propose a GPT-4-based AEG evaluation approach.\nAutomatic evaluation. Based on the systems theory of argumentation(Van Eemeren et al., 2004), we evaluate the persuasive of argumentative essay from the following five aspects: Relevance, Validity of the Reasoning, Credibility of Evidence, Language and Rhetoric and Overall Persuasiveness. We design prompts for each evaluation aspect with specific task instructions and a comprehensive list of detailed criteria. To reduce the variance of the evaluation results, we prompt model to give a detailed explanation for evaluation results before the final prediction of score. Detailed prompts for each evaluation aspect will be given in Appendix C.\nHuman evaluation. We employed three skilled English speakers with NLP background to perform manual evaluation of the generated results. We set up the following two evaluation tasks: (i) Scoring the generated text. Same as GPT-4 based evaluation, score the generated results in terms of five aspects with the same criteria as the prompt used in GPT-4. (ii) Compare the results with baselines. The annotator will compare the outputs of our proposed method with all the baselines and give an overall evaluation of Win, Loss and Tie for each test sample pair."}, {"title": "4.4 Implementation Details", "content": "We finetune LLaMA2-13B-chat with all parameters with the help of huggingface and DeepSpeed. AdamW optimizer is adopted for optimization, and initial learning rates are set to le-5 with linear descent schedule. We train the model 5 epochs. The batch size per-device is set to 8. All experiments are conducted with NVIDIA Tesla A100 GPU."}, {"title": "5 Results and Analysis", "content": ""}, {"title": "5.1 Main Results", "content": "Performance on automatic evaluations. As shown in Table 1, experimental results demonstrate the promising potential of the PESA framework. For both Relevance, Validity of the Reasoning, Credibility of Evidence, Language and Rhetoric and Overall Persuasiveness, our method demonstrates varying degrees of improvement. Notably, our framework has exhibited more significant improvements in the Validity of the Reasoning and Credibility of Evidence metric, which assess logical structure and correctness. These improvements indicates a more reliable logical structure and persuasive argumentative essay. Specifically, we observe 0.35 points improvement on Relevance metric, 4.38 points improvement on Validity of the Reasoning, 3.28 points improvement on Credibility of Evidence metric, 3.24 points improvement on Language and Rhetoric metric and 4.50 points improvement on Overall Persuasiveness. Furthermore, experimental results show that the claim and ground planning effects the generation results in different ways. Claim planning contributes more to the Validity of Reasoning metric, while the effects of ground planning are more focused on the Credibility of Evidence metric. This distinction arises because claim planning controls the essay's overarching logical structure, thereby significantly influencing reasoning generation. In contrast, ground planning manages the detailed substantiation process of the claim, affecting the generation of evidence. These finding indicates the efficacy of the PESA method, confirming its alignment with our motivation.\nPerformance on human evaluation. The human evaluation metrics are presented in Table 2 and Figure 3. When compared to the state-of-the-art model with the same parameter size like LLaMA2-base, our PESA method demonstrates superior performance across all five evaluated aspects. This suggests that our proposed approach effectively directs the model towards generating diverse and high-quality texts. In comparison to larger language models, such as ChatGPT, the PESA method achieves comparable outcomes across all five aspects and surpasses ChatGPT in Validity of Reasoning. The direct comparison of our method with strong baseline models, as depicted in Figure 3, reveals that our model exceeds the current state-of-the-art models, DD-KW and LLaMA, by 64% and 86%, respectively, and is not inferior to ChatGPT by 62%. Taken together, these experimental and human evaluation results indicate that the PESA method not only significantly outperforms models of similar parameter size but also competes favorably with models of larger parameter sizes."}, {"title": "5.2 Ablation Study", "content": "Effectiveness of Proof-Enhancement Method. We evaluate the performance of Proof-Enhancement without the claim planning and without the ground planning. As shown in Table 1, experimental results show that the performance of the PESA framework decreases when either the claim planning or ground planning is removed, which indicates that both of them play a positive role. Notably, claim planning and ground planning have different impacts on the results. Claim planning exerts the greatest influence on the Validity of Reasoning metric, surpassing ground planning by 1.02 points. Conversely, ground planning has the largest effect on the Language and Rhetoric metric, exceeding claim planning by 1.1 points. This distinction reveals that within Proof-Enhancement, claim planning guides more macro-level connections, while ground planning affects more granular aspects. Such findings align with the intended design motivations of Proof-Enhancement and demonstrate its effectiveness."}, {"title": "5.3 Case Study", "content": "We give an example in the Appendix D that includes all baselines and our model outputs. In this example, the Writing Prompt is \"In countries with a high rate of unemployment, numerous pupils should do offered only predominant education. There is no point in offering secondary education to those who have no hope of finding a job. To what extent do you agree or disagree with this statement\". It can be seen that our method and ChatGPT provide a clear and complete global logic chain, and also have good performance in logical coherence within paragraphs.\nIn contrast, the two claims given by the LLaMA2-base are not deeply related to unemployment in Writing Prompt, and the internal logic is not smooth with no examples or logical reasoning to prove its own opinions. The DD-KW method generated an article that overall conforms to the topic, but the logical structure is very confusing. In the first paragraph, DD-KW believes that \u201cthe government should not offer tertiary education to those who are unemployed\u201d is wrong, but the following two major claims turn to support this view. The DD-Rel method is similar to the DD-KW method and produces serious logical errors. For example, DD-Rel believes that \u201coffering secondary education to pupils who have no hope of finding employment is not beneficial\", but in the following two paragraphs, one introduces university education at length, and the other is more inclined to support this view."}, {"title": "6 Conclusion", "content": "In this paper, we present a unified two-stage framework (PESA) for AEG with a focus on proof and logical correctness. The framework is composed of two components: The Self-Annotation method leverages a large language model to progressively extract logical information from AEG data, obtaining high-quality training data; the Proof-Enhancement method enhances the persuasive power of generative results by explicitly incorporating proof principles into the planning process, enabling the language model to produce argumentative texts in line with the Toulmin Argumentation Model. Automatic and manual evaluation metrics show that our method could produce fluent, coherent, and persuasive argumentative text with a significant improvement in the logical structure."}, {"title": "Limitation", "content": "Despite the excellent results of our model on the AEG task, a potential limitation exists in our model due to the absence of explicit modeling for causal relationships among major claims, topics, and writing materials within paragraphs. In future studies, we plan to use causal modeling approaches to target logical structures in argumentative texts for more in-depth control."}, {"title": "Ethical Consideration", "content": "The ethical risks of our proposed methods and models are low. This is because we used a publicly published dataset that has passed ethical review and does not contain sensitive or private content. Moreover, the open source models we use such as LLaMA have undergone strict security training, and the output content complies with ethical standards."}, {"title": "A Example of Argumentative Essay Logical Structure", "content": "An example of logical structure that exists in real argumentative essays is given in Figure 4."}, {"title": "B Detailed Design Of Proof-Enhancement", "content": "The detailed design of the Proof-Enhancement is given in Figure 5."}, {"title": "C Automatic Evaluation Prompts", "content": "For GPT4-based automatic evaluation as described in section Experiments, we present the detailed prompts for each metric in Table 4. The scoring range of the model is given after each prompt, and the model is required to give a brief explanation before scoring. This is to constrain the model output and reduce the randomness and variance."}, {"title": "D Example of Outputs", "content": "We present additional examples with different model outputs in Table 5 and 6."}]}