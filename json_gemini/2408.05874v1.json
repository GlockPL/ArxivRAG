{"title": "LLM-Based Robust Product Classification in Commerce and Compliance", "authors": ["Sina Gholamian", "Gianfranco Romani", "Bartosz Rudnikowicz", "Laura Skylaki"], "abstract": "Product classification is a crucial task in international trade, as compliance regulations are verified and taxes and duties are applied based on product categories. Manual classification of products is time-consuming and error-prone, and the sheer volume of products imported and exported renders the manual process infeasible. Consequently, e-commerce platforms and enterprises involved in international trade have turned to automatic product classification using machine learning. However, current approaches do not consider the real-world challenges associated with product classification, such as very abbreviated and incomplete product descriptions. In addition, recent advancements in generative Large Language Models (LLMs) and their reasoning capabilities are mainly untapped in product classification and e-commerce. In this research, we explore the real-life challenges of industrial classification and we propose data perturbations\u00b9 that allow for realistic data simulation. Furthermore, we employ LLM-based product classification to improve the robustness of the prediction in presence of incomplete data. Our research shows that LLMs with in-context learning outperform the supervised approaches in the clean-data scenario. Additionally, we illustrate that LLMs are significantly more robust than the supervised approaches when data attacks are present.", "sections": [{"title": "1 Introduction", "content": "Product classification plays an important role in international trade and e-commerce. This is because import and export tariffs are assigned based on the category of products. According to the latest report from World Custom Organization (WCO, 2023), in Year 2022-2023 more than 1.3 billion declarations are booked through customs worldwide (World Customs Organization, 2023a). This massive workload, a result of trade globalization, can impose a significant burden on human experts such as customs personnel and the companies involved in import, export, and e-commerce.\nIn addition, product classification can often be a complicated task and require subject matter expertise, as there is a wide range of products traded across various industries. As such, for human personnel to become competent in understanding the nuances of different products and how to classify them in compliance with WCO guidelines is a non-trivial task and requires several months of training, according to our subject matter expertise. Moreover, correct and detailed classification is critical, as incorrect classification can lead to tax liabilities owed to authorities. This can result in fines, penalties, and in some cases, legal repercussions and business discontinuation bans in the jurisdictions affected by a tax breach.\nManaging the increasing workload of product classification in global trade is difficult. This challenge is further compounded by the continuous globalization of e-commerce. Additionally, staying accurate and up-to-date as global trade classification guidelines, such as the Harmonized System (U.S. Department of Commerce, 2023), which continuously change, further adds to the challenges of manual product classification. Therefore, many organizations active in industry have adopted automated methods of product classification using machine learning (Avigdor et al., 2023; Hasson et al., 2021; Lee et al., 2021; Chen et al., 2021; Nguyen and Khatwani, 2022). However, the issue with current classification approaches is that they primarily focus on the 'clean' version of data, often ignoring the common data perturbations that happen in real-world product classification during inference time. In this context, 'perturbations' or 'attacks' refer to issues in data that limit the classifier's performance, such as incomplete or abbreviated data. The ability to robustly predict correct product classifications in scenarios where data might be far from perfect is of paramount importance, especially in cases where incorrect classification can lead to incorrect taxation and trade liabilities in international trade under the harmonized system (World Customs Organization, 2023b). Therefore, in this research, we aim to understand which models perform better in scenarios with potential data attacks. This not only facilitates more informed model decision-making, but also considers real-life data challenges. Consequently, our contributions are as follows:\n\u2022 We introduce a framework designed to simulate real-life data attacks on clean data. This is particularly crucial for product classification with compliance implications, where incorrect classifications can lead to wrong taxation.\n\u2022 Utilizing realistic data attacks, we propose an LLM-based classification approach that outperforms the prior supervised approaches, and is more robust to real-life data attacks.\n\u2022 Lastly, we offer a comprehensive evaluation of human annotators and various models across different attack scenarios and compare their robustness. We draw conclusions from our findings, which we believe are instrumental in guiding design decisions for the practical aspects of product classification."}, {"title": "2 Background", "content": "This section provides a review of the related work and essential background that supports our research."}, {"title": "2.1 Product Classification", "content": "Product classification based on product description text has been a focal point in several industrial research efforts (Kondadadi et al., 2022; Nguyen and Khatwani, 2022; Hasson et al., 2021; Avigdor et al., 2023). In real-world scenarios, product descriptions often lack completeness and in many cases are abbreviated and brief. This provides very limited context for accurate product classification using Natural Language Processing (NLP) approaches. Kondadadi et al. (Kondadadi et al., 2022) presented a Question Answering (QA) framework for Data Quality Estimation (DQE) with the goal of improving product classification for tax code assignment. This approach detects the quality of available data by extracting attribute-value pairs. The authors similarly observed that the input product description data is generally vague and noisy. Hasson et al. (Hasson et al., 2021) discussed the classification challenges in e-commerce systems. Notably, the high diversity of products to classify and highly granular hierarchy of these products result in hundreds or thousands of possible categories, which can present challenges for both manual and automated classification approaches. Considering that automated product classification is a more cost-efficient and scalable approach to adopt, the development of robust product classification in presence of data attacks still remains largely unexplored."}, {"title": "2.2 Input Perturbation", "content": "Perturbations in data, specifically in text data, have been investigated in several prior studies (Behjati et al., 2019; Zhang et al., 2020; Zou et al., 2023). Generally, for LLMs, adversarial attacks can involve malicious tokens added to the prompt that causes the model to generate undesired outputs (Zou et al., 2023). Beyond malicious intents, adversarial attacks can be beneficial and be leveraged as data augmentation to improve the robustness of text classification approaches (Yoo and Qi, 2021; Wang et al., 2020, 2022) in scenarios where the inference data can be noisy (Morris et al., 2020). Our work focuses on product classification based on the text description of products, which in real life can be incomplete and far removed from the clean training data. Therefore, in this research, we focus on formulating data perturbations that aim to simulate the real-world data incompleteness often encountered in product descriptions."}, {"title": "3 Methodology", "content": "Although product classification is generally tested on datasets free of inaccuracies, in real-world scenarios the data received from users is often very short and abbreviated. As such we define an adversarial attack framework to simulate realistic data from clean data. For data perturbation method, we follow the approach introduced in (Behjati et al., 2019). Similar to the method explained in GPT3Mix approach (Yoo et al., 2021), we use GPT-4 (version: 0613) to create perturbations and generate synthetic yet highly realistic datasets to resemble the real-life scenario of the data. We write a prompt that includes the instructions to GPT-4 for different variations of data perturbations. These instructions are then passed to GPT-4 along the original product description to perform perturbations. In response, GPT-4 completion returns the perturbed product description. Additional details on prompt templates are provided in Figures 2 and 3 in Appendix A."}, {"title": "3.1 Data Perturbation Framework", "content": "To simulate real-world data scenarios, we introduce realistic data perturbations and attacks. Our perturbation model is defined as follows: consider a classifier f, which maps an input x \u2208 X to its corresponding class c\u2208 C, denoted as f(x) = c. In this model, x is a sequence of tokens, x = (x\u2081, x\u2082,..., xn). Data perturbation can involve either removing or modifying tokens within x, leading to a new sequence, x' = (x'\u2081, x'\u2082,..., x'n). This perturbation may result in f(x') = c', where c' \u2260 c, indicating a change in classification. To mimic the real-life data, we apply two distinct perturbation methods that we will discuss in the following."}, {"title": "3.2 Amputation", "content": "In this approach, we perturb the product description by randomly removing some of its tokens. We investigate this scenario because real data often is missing critical attributes, which limits accurate classification of products (Kondadadi et al., 2022). Here, we do not introduce new tokens (i.e., new attributes) nor change the order of the existing tokens; instead we only omit some tokens from the product descriptions. Formally speaking, the input x = (x\u2081, x\u2082,..., xn) is transformed into xm = (xi\u2081, xi\u2082,..., xir) where 1 \u2264 i\u2081 < i\u2082 < ... < ik \u2264 n and \u2200xi\u2081, k \u2208 X."}, {"title": "3.3 Abbreviation", "content": "In this approach, we attack product descriptions by replacing a subset of words with their abbreviated forms. This scenario does not fully remove any tokens but converts certain tokens into their abbreviated versions. For example, the word 'mobile' could be replaced by 'mob.' (refer to Table 1). Formally, the input x = (x\u2081, x\u2082,..., xn) is transformed into xa = (x'\u2081, x'\u2082,..., x'n) where S \u2286 {1,2,..., n} and \u2200i \u2208 S : x'i = Abbr(xi), and \u2200i \u2208 {1, 2, ..., n} \\ S : x'i = xi\nIt should be noted that our framework does not encompass a comprehensive list of data perturbation that can happen in real-world scenarios, and only models the common perturbations in our enterprise global trade use case. Other data perturbations, such as typos, can also be quite prevalent in real scenarios which can be investigated as per use case."}, {"title": "3.4 Example - Data Perturbation", "content": "Table 1 provides examples of various attacks based on our data perturbation framework. In a combined attack, both abbreviation and amputation approaches are applied."}, {"title": "3.5 Robustness Metric", "content": "We define the robustness of classifier f as the delta (\u0394r) of the performance metric (M) on the clean data (Dc) versus the performance of the classifier on the perturbed data (Dp): \u0394r(f) = |M(Dc)-M(Dp)|/M(Dc). The lower the \u0394r, the more robust the model is to the data perturbations."}, {"title": "3.6 Research Hypothesis", "content": "Our hypothesis posits that LLMs with in-context learning not only can outperform supervised models in the product classification task, but also show greater robustness to adversarial attacks such as abbreviation and amputation. Furthermore, we assert that informing an LLM about the potential data attacks can improve the classification performance by allowing the LLM to more effectively leverage its reasoning capabilities."}, {"title": "4 Evaluation", "content": "In the following, we outline the details of our evaluation."}, {"title": "4.1 Datasets", "content": "We experiment on two publicly available datasets, namely Icecat (ice) and WDC-222 (wdc), to demonstrate our perturbation framework and evaluate the robustness of different classification models in the presence of data attacks. Although we have observed the aforementioned attack scenarios in our proprietary data, we believe our perturbation framework can be readily applied to any arbitrary dataset. Therefore, we opt to conduct our evaluation on public datasets to ensure higher visibility and reproducibility. The datasets are as follows:"}, {"title": "4.2 Icecat (ice)", "content": "This dataset features products in the \"Computers & Electronics\" category, organized in a hierarchical structure. Each record includes a product description and a corresponding text label. For example, as shown in Table 1, the product described as \u201cSamsung ALC820 mobile phone case Cover Brown\" falls under the hierarchy Computers & Electronics \u2192 Telecom & Navigation \u2192 Mobile Phone Cases, with the label being the leaf node of this hierarchy, i.e., Mobile Phone Cases. The dataset has 370 leaf nodes, with 489,902 entries for training and 153,095 for testing. We utilized the entire training set for training supervised models and identifying few-shot examples for LLMs. However, to contain LLM inference costs, we conducted stratified random sampling on test set to comprise a smaller set of 5,000 examples, with at least one data point from each class."}, {"title": "4.3 WDC-222 (wdc)", "content": "This dataset contains 222 leaf nodes in the same hierarchy as Icecat. It includes 2,984 entries solely for testing, thereby serving as the gold standard for this classification task. This dataset is generally more difficult than Icecat for classification, and prior approaches (wdc) achieve a lower performance on this dataset than Icecat. We utilize the entire size of this dataset to test both supervised and large language models."}, {"title": "4.4 Models", "content": "We conduct our evaluation using both supervised and LLM-based approaches."}, {"title": "4.5 Supervised Baseline", "content": "To compare the performance of generative models against supervised models, we experiment with the DeBERTaV3-base model (He et al., 2023) as our baseline. This architecture achieves state-of-the-art performance on several text classification benchmarks. Specifically, we used the pretrained model available from HuggingFace (Wolf et al., 2020), and fine-tuned it on the full training set of the Icecat dataset. By doing so, we replicate a scenario where the model is trained on clean data and tested on perturbed data, which is a common situation in our real-world use case. For the supervised baseline, experiments are repeated several times with different seeds, and thus error ranges are provided."}, {"title": "4.6 Training Details", "content": "In the following, we review the training details for supervised baseline models."}, {"title": "4.6.1 Flat Classification", "content": "To train both hierarchical and flat baselines, we used the DeBERTaV3-base model (He et al., 2023). We fine-tuned the pretrained model provided by the authors of the model and available on the Hugging Face (Microsoft). We used the default tokenizer provided by Hugging Face for the DeBERTaV3-base model and the following hyperparameters: batch size of 32, learning rate of 2e-5, and weight decay of 0.01. The rest of the parameters were equal to default values for the Hugging Face Trainer class. We trained the model for a maximum 100 epochs with early stopping enabled and the patience parameter was set to 5 epochs. The model was trained on 5 different random seeds, and each converged before reaching the maximum number of epochs."}, {"title": "4.6.2 Hierarchical Classification", "content": "For the hierarchical classification, we used the same model, tokenizer, and hyperparameters as for the flat classification. However, we trained two separate models: one with the task to classify the products to the second level of the hierarchy (first level was shared among all products), and the second model for final label prediction. The top-level model was trained on the same data as the flat classification model. The second model was trained on the same data, but the description was augmented with the top-level category label (in textual form) in the following format \"original_description, category_name\". During inference, we used predictions from the top-level model and appended them to the description before passing it to the second model for the final classification. The results were averaged for the models trained on five different seeds and rounded to three decimal digits. We also reported the 95% interval which was calculated as follows: \u00b11.96. std/\u221a5"}, {"title": "5 LLMs", "content": "We experiment with both open-source and proprietary LLMs, including Llama 2 Chat with 70B parameters (Touvron et al., 2023), GPT3.5, and GPT4 (model version: 0613) (OpenAI, 2023). Unlike the supervised approach, we were not able to perform multiple runs and report error ranges for LLMs due to the excessive cost of inference. However, we set the temperature values to 0 to minimize potential variations in the LLM outputs across multiple runs."}, {"title": "5.1 Models Configurations", "content": "For classification configurations, we consider Flat, Hierarchical, and Few-shot configurations. In the flat configuration, the model is tasked with directly predicting the leaf node label of the product, corresponding to 370 and 222 classes for the Icecat and WDC datasets, respectively. In the hierarchical configuration, the model initially predicts the second-level hierarchy of the product which is 17 classes for both Icecat and WDC-222 dataset (first-level hierarchy, Computers & Electronics, is shared among all products). This is followed by predicting the final leaf label from the predicted second-level hierarchy. For the few-shot configuration, we select the top-5 semantically similar examples to the test product from the training set, using the Sentence-Transformer model (Reimers and Gurevych, 2019). These examples are then included in the prompt as in-context learning examples for the LLMs (Brown et al., 2020)."}, {"title": "5.2 Attack Configurations", "content": "We explore four different attack configurations as discussed in our data perturbation framework in Section 3. Clean: this configuration presents the original data without any attacks, e.g., the original product descriptions are used for classification. This serves as a benchmark for the highest possible classification performance. Amputated: in this configuration, the product descriptions are amputated by randomly removing a subset of tokens. Abbreviated: this attack involves abbreviating a subset of product description tokens. Combined: this configuration involves combining both the amputation and abbreviation attacks, such that the product description is first amputated and then the resulting description is further abbreviated. Combined-Reason: this configuration uses the combined attack on the product description, with an additional note in the prompt to enable the LLM to reason about possible data perturbations. LLMs have demonstrated emerging capabilities in common-sense reasoning (Wei et al., 2022). Therefore, in this configuration, we include an extra note in the prompt, \u201cBe aware that some parts of the product description might have been abbreviated or amputated.\u201d, to let the LLM reason on possible perturbation patterns in the product description, which may lead to more accurate classification."}, {"title": "5.3 Data Analysis", "content": "In this section, we present a statistical analysis of the data attributes for the clean data as compared to the post-attack scenarios. Table 2 shows the average semantic similarity scores for both the clean dataset and its perturbed ones. We used 'multi-qa-mpnet-base-dot-v1' model from SentenceTransformers (Reimers and Gurevych, 2019) to calculate these similarity scores. The results show that as more attacks are introduced on the dataset, the similarity scores decrease. However, even for the 'Combined' configuration, the dataset is still over 84% similar to the original dataset. In addition to the similarity scores, we have plotted the distribution of token sizes for product descriptions in Figure 1 for both the Icecat (1a) and WDC-222 (1b) datasets. Kullback-Leibler (KL) divergence values (Kullback and Leibler, 1951) are also provided for different data configurations. Across all configurations, the KL values are less than or equal to 0.2, and a value of < 0.2 typically signifies a small divergence between the distributions. This analysis is crucial as we later evaluate how these small divergences in distributions translates to a greater scale of model performance unrobustness."}, {"title": "5.4 Human Annotation Analysis", "content": "The importance of the quality of perturbed data prompted us to engage human annotators to assess the quality and ensure its similarity to the intended real data. During the design of the data perturbation framework, we leveraged human expert knowledge to ensure our perturbations aligned with the in-field data. In addition, through human manual evaluation, we confirmed that the perturbed data appears realistic and plausible in real-life scenarios.\nTo further solidify the data quality analysis, we picked 100 random sample data points from each dataset (200 samples in total) that were perturbed and asked our human annotators to expand the abbreviated words to ensure the majority of perturbations are recoverable from a human perspective and they did not semantically alter the meaning of product descriptions. Through this, annotators were able to identify and create the clean full form of the abbreviated tokens in the product descriptions 80% and 85% of times for the Icecat and WDC-222 datasets, respectively.\nTo evaluate that the perturbation process did not semantically alter the descriptions in a significant way, we asked the annotators to label the descriptions with clean descriptions and also combined attack for both datasets ('Clean' and 'Combined' in Table 3). Furthermore, to check if historical classifications of clean descriptions semantically similar to perturbed data would aid annotators, for each combined attack description in the set of 100 randomly selected product descriptions, we provided five most semantically similar examples, using SentenceTransformer (Reimers and Gurevych, 2019) ('Combined+FS' in Table 3). We then asked the annotator to map the description that is attacked with combined perturbation to its closest clean description. Then we calculate the accuracy of the annotator mapped labels versus the true label of the perturbed data points. The design for this experiment is similar to adding few-shot similar examples to the LLM prompt to allow the model to find semantic similarities between the original clean data and the perturbed data."}, {"title": "5.5 Metrics", "content": "We assess the classification performance using both macro (ma) and weighted (we) Precision, Recall, and F1-Score values to compare different approaches. Additionally, for each model, we also calculate its most robust (i.e., the smallest) \u0394r score."}, {"title": "5.6 Robustness Analysis", "content": "Table 4 shows the performance and robustness of various configurations that were experimented with. It should be noted that we chose to exclude certain configurations from execution in order to manage the models inference API cost and also because we were able to extract patterns from the configurations that were executed. We summarize the key observations from the results as follows. GPT-4 model with few-shot prompting delivers the best classification results on both datasets among all models and shows the highest level of robustness to the introduced data attacks. As expected, the 'Clean' data approach yields the best results, with performance marginally decreasing as data attacks are introduced for 'Amputated' and 'Abbreviated' data configurations. Supervised model achieved the second highest performance after GPT-4 for the 'Clean' scenario. However, the performance values for this model significantly drop as the attacks are introduced. In general, LLMs show more robustness to the introduced attacks in the product description as they are able to better reason on the details of the product description. In addition, few-shot examples allow LLMs to further learn from the context and improve their performance, compared to our experimented supervised classification models which cannot leverage this capability.\nHierarchical classification generally performed equally or worse than flat classification and inferior to few-shot prompting. We rationalize that since the errors from the first level of classification propagate to the second level, this compounding effect results in lower performance in hierarchical classification compared to flat configuration. In some cases, we observed that hierarchical classification improves macro scores, which indicates that this method achieves a more balanced prediction across different classes. For example, Llama-2 achieves better results with hierarchical classification than with the flat classification method. This is because the hierarchical approach allows the model to focus on a smaller set of classes at each hierarchy.\nComparing the results for two different datasets, Icecat and WDC-222, we observe that LLM-based approaches show a significant improvement for the WDC-222 dataset but a less noticeable improvement for Icecat. The reason is that the classification of the Icecat dataset is simpler than that of WDC-222, as the latter comes from heterogeneous data sources (wdc). As such, the baseline supervised values for the Icecat dataset are also higher than those for the WDC-222 dataset. This also provides grounds for our observation that SOTA LLMs can generalize better than supervised approaches on heterogeneous datasets, based on the noteacible improvement observed in the WDC-222 dataset.\nThe Few-shot scenario further improves the performance of the LLMs, and GPT-4 achieves a new state-of-the-art result on classification task on Icecat and WDC-222 datasets (wdc; Brinkmann and Bizer, 2021). Additionally, the 'Combined-Reason' scenario improves classification performance in cases where a combined attack is present. This added reasoning in the prompt allows to recover some of the performance loss observed between clean data and combined-attack configurations by further leveraging the reasoning capabilities of LLMs. Our findings suggest that while LLMs are more robust in classification compared to supervised approaches, i.e., have lower \u0394r, this robustness can be further improved with informing the model of potential data issues, such as missing characteristics and abbreviations. This observation also underlines the need for more practical designs of ML approaches while considering real-world challenges."}, {"title": "6 Discussion", "content": ""}, {"title": "6.1 Data Leakage", "content": "One concern that exists is that the LLMs' training dataset, like GPT-4 as an example, might have already included our experimented datasets. Although this cannot be entirely ruled out, our approach is still valid for two key reasons. Firstly, GPT-4 initially shows lower performance, but significantly improves in our few-shot scenario, outperforming the supervised models. This indicates that the effectiveness of GPT-4 extends beyond merely memorization. Secondly, the robustness of LLMs, particularly in our data perturbation framework with Combined-Reason, is evident. The perturbed dataset, as it is novel and not included in prior training, shows GPT-4's ability to understand product semantics and effectively recover from data perturbations."}, {"title": "6.2 Impact and Deployment", "content": "Our research has partially enabled AI-based product categorization in our global trade service which is crucial and sensitive for compliance and regulatory aspects for large corporations active in cross-border trade. Our research is impactful as it has enabled more efficient and accurate classification, and thus reduces the regulatory and compliance risk. The discovery phase of the project has been completed with testing on millions of data records and the second phase of the project which expands to multiple users and more data is ongoing."}, {"title": "7 Conclusion", "content": "In this research, we presented a data perturbation framework to simulate the real-world data deficiencies for ML-based product classification. We then proceeded with a comprehensive evaluation of different supervised and LLM-based classification approaches in presence and absence of data attacks. Our findings show that LLM-based approaches are generally more robust against adversarial attacks and more suitable for applications that require high robustness in predictions and misclassification can cause compliance repercussions. As future work, we will further investigate the security robustness of LLMs in data-critical applications and explore leveraging LLMs for providing classification rationales in addition to label predictions."}, {"title": "8 Limitations", "content": "Our analysis has limitations, particularly as we observed that the results from Llama-2, are not completely stable, and small variations within the prompt can lead to noticeable changes in classification performance. We believe these limitations are largely addressed in SOTA models, like GPT-4. Additionally, our data perturbation framework models a limited set of data attacks that are relevant to our industrial use case, however, other use cases might face different data challenges, which should be dealt with per use case."}, {"title": "9 Ethical and Practical Considerations", "content": "This study has been carried out by following the privacy requirements of our organization. The research has been reviewed by research directors and legal counsel to ensure adherence to privacy of our users data and information. Furthermore, the authors of this work have been committed to adhering to the highest standards of ethical responsibility throughout the research. In product environments where automated product classification models are deployed, the predictions are presented to the end user as suggestions, and it is then the end user's sole responsibility to accept, reject, or manually adjust these predictions as necessary. This work presents a general perspective on the product classification task and does not incorporate additional sources of information that could be leveraged for specific use cases, such as the Harmonized System classification, which utilizes tariff schedules, rulings, and keywords."}, {"title": "A Prompts", "content": "Figure 2 shows the prompt for simulating data attacks with the help of GPT-4, as explained in the data perturbation framework, while Figure 3 displays the prompt for the classification of products. The first prompt aims to is to accurately automate the data perturbation framework, and the second prompt allows to classify the products, using an LLM. As the data is manipulated by an LLM, we investigate the correctness of the approach in comparison to the intended outcomes through human analysis in Section 5.3."}]}