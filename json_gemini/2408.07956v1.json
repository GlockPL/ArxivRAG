{"title": "RandomNet: Clustering Time Series Using\nUntrained Deep Neural Networks", "authors": ["Xiaosheng Li", "Wenjie Xi", "Jessica Lin"], "abstract": "Neural networks are widely used in machine learning and data mining. Typically,\nthese networks need to be trained, implying the adjustment of weights (parame-\nters) within the network based on the input data. In this work, we propose a novel\napproach, RandomNet, that employs untrained deep neural networks to cluster\ntime series. RandomNet uses different sets of random weights to extract diverse\nrepresentations of time series and then ensembles the clustering relationships\nderived from these different representations to build the final clustering results.\nBy extracting diverse representations, our model can effectively handle time series\nwith different characteristics. Since all parameters are randomly generated, no\ntraining is required during the process. We provide a theoretical analysis of the\neffectiveness of the method. To validate its performance, we conduct extensive\nexperiments on all of the 128 datasets in the well-known UCR time series archive\nand perform statistical analysis of the results. These datasets have different sizes,\nsequence lengths, and they are from diverse fields. The experimental results show\nthat the proposed method is competitive compared with existing state-of-the-art\nmethods.", "sections": [{"title": "1 Introduction", "content": "Neural networks serve as fundamental learning models across disciplines such as\nmachine learning, data mining, and artificial intelligence. Typically, these networks go\nthrough a training phase during which their parameters are tuned according to specific\nlearning rules and the data provided. A popular training paradigm involves backprop-\nagation for optimizing an objective function. Once trained, these networks can be\ndeployed for a variety of tasks, including classification, clustering, and regression.\nA time series is a real-valued ordered sequence. The task of time series clustering\nassigns time series instances into homogeneous groups. It is one of the most important\nand challenging tasks in time series data mining and has been applied in various fields\nsuch as finance (Kumar et al., 2002), biology (Subhani et al., 2010; Fujita et al., 2012),\nclimate (Steinbach et al., 2003), medicine (Wism\u00fcller et al., 2002) and so on. In this\nwork, we consider the partitional clustering problem, wherein the given time series\ninstances are grouped into pairwise-disjoint clusters.\nExisting time series clustering methods achieve good performance (Paparrizos and\nGravano, 2015; Petitjean et al., 2011; Li et al., 2019), but since they form clusters\nbased on a single focus, such as shape or point-to-point distance, they are sub-\noptimal for some specific data types. Here, we introduce a novel method named\nRandomNet for time series clustering using untrained deep neural networks. Differ-\nent from conventional training methods that adjust network weights (parameters)\nusing backpropagation, RandomNet utilizes different sets of random parameters to\nextract various representations of the data. By extracting diverse representations, it\ncan effectively handle time series with different characteristics. These representations\nare clustered; the results from the clusters are then selected and ensembled to pro-\nduce the final clustering. This approach ensures that data only needs to pass through\nthe networks once to obtain the final result, obviating the need for backpropagation.\nTherefore, the time complexity of RandomNet is linear in the number of instances in\nthe dataset, providing a more efficient solution for time series clustering tasks.\nGiven a neural network, the various sets of parameters in the network can be\nthought of as performing different types of feature extraction on the input data. As\na result, these varied parameters can generate diverse data representations. Some of\nthese representations may be relevant to a clustering task, producing meaningful clus-\nterings, while others may be less useful or entirely irrelevant, leading to less accurate\nor meaningless clustering. This concept forms the basis of RandomNet: by combining\nclustering results derived from all these diverse representations, the meaningful and\nlatent group structure within the data can be discovered. This is because the noise\nintroduced by irrelevant representations tends to cancel each other out during the\nensemble process whereas the connections provided by relevant representations are\nstrengthened. Therefore, efficient and reliable clustering can be achieved despite the\nrandomness of the network parameters.\nTo demonstrate the effectiveness of RandomNet, we provide theoretical analysis.\nThe analysis shows that RandomNet has the ability to effectively identify the latent\ngroup structure in the dataset as long as the ensemble size is large enough. Moreover,\nthe analysis also provides a lower bound for the ensemble size. Notably, this lower\nbound is independent of the number of instances or the length of the time series in the\ndataset, given that the data in the dataset are generated from the same mechanism.\nThis provides the ability to use a fixed, large ensemble size to achieve satisfactory"}, {"title": "2 Background and Related Work", "content": "2.1 Definitions and notations\nDefinition 1. A time series $T = [t_1, t_2,...,t_m]$ is an ordered sequence of real-value\ndata points, where m is the length of the time series.\nDefinition 2. Given a set of time series ${T_i}_{i=1}^n$ and the number of clusters k, the\nobjective of time series clustering is to assign each time series instance $T_i$ a group\nlabel $c_j$, where $j \\in \\{1, ..., k\\}$. n is the number of instances in the dataset. We would\nlike the instances in the same group to be similar to each other and dissimilar to the\ninstances in other groups.\n2.2 Related work\nThere has been much work on time series clustering, and we categorize them into\nfour groups: raw-data-based methods, feature-based methods, deep-learning-based\nmethods, and others.\nRaw-data-based methods. The raw-data-based methods directly apply classic\nclustering algorithms such as k-means (MacQueen et al., 1967) on raw time series. The\nstandard k-means algorithm adopts Euclidean distance to measure the dissimilarity\nof the instances and often cannot handle the scale-variance, phase-shifting, distortion,\nand noise in the time series data. To cope with these challenges, dozens of distance\nmeasures for time series data have been proposed.\nDynamic Time Warping (DTW) (Berndt and Clifford, 1994) is one of the most pop-\nular distance measures that can find the optimal alignment between two sequences. It\nis used in Dynamic time warping Barycenter Averaging (DBA) (Petitjean et al., 2011)"}, {"title": "3 The Proposed Method", "content": "3.1 Architecture and algorithm\nFigure 1 shows the architecture of RandomNet. The method is structured with B\nbranches, each containing a CNN-LSTM block, designed to capture both spatial and\ntemporal dependencies of time series, followed by k-means clustering. Each CNN-\nLSTM block contains multiple groups of CNN networks and an LSTM network, and\neach group of CNN network consists of a one-dimensional convolutional layer, a Recti-\nfied Linear Units (ReLU) layer, and a pooling layer. The output of the CNN networks\nis flattened. In our experiments, we set the number of groups of the CNN network\nequal to $log_2 m$, where m represents the length of the time series. We fix the number\nof filters of the 1D convolution to 8, the filter size to 3, and the pooling size to 2. We\nset the number of LSTM units to 8. The weights used within the network are ran-\ndomly chosen from $\\{-1,0,1\\}$. We opt for this finite parameter set over a continuous\ninterval (e.g., [-1,1]) for the purpose of simplifying the parameter space.\nEach branch produces its own clustering, however, some clusterings might be\nskewed or deviant due to the inherent randomness of the weights. To alleviate this\nproblem, we propose a selection mechanism to remove any clusterings that contain\nclusters that are either too small or too large.\nConcretely, the method sets a lower bound $l_r$ and an upper bound $u_r$ for the cluster\nsize. The number of instances that violate the bounds in each clustering is counted as\nviolation. For example, suppose a clustering contains two clusters with sizes 40 and\n52, respectively. If the lower bound is 5 and the upper bound is 50, then the number of\nviolations for this clustering is 52-50 = 2. The clusterings are sorted according to the\nnumber of violations and the method selects the top S clusterings for the ensemble.\nHere, $S = max(z_v, s_r \\times B)$, where $z_v$ is the number of clusterings with zero violation\nvalues, $s_r$ is a selection rate, and B is the number of branches in the method.\nFinally, we ensemble the results to form the final clustering. While the diversity\nof clustering results from a large number of different branches helps reveal various\nintrinsic patterns in the data, it introduces the challenge of combining these different\nresults into a cohesive unified clustering. To address this challenge, we adopt the\nHybrid Bipartite Graph Formulation (HBGF) (Fern and Brodley, 2004) to perform\nclustering ensemble. This technique builds a bipartite graph for the clusterings in\nthe ensemble, where the instances and clusters become the vertices. If an instance\nbelongs to a cluster, then there is an edge connecting the two respective vertices in the\ngraph. Partitioning the graph gives a consensus clustering for the ensemble. HBGF\nhas two main advantages. First, it can extract consensus from differences, identifying\nand strengthening the repeated patterns of grouping across the clustering set. Second,\nit has linear time complexity, which ensures the scalability of our model for large\ndatasets. In our implementation, we use Metis (Karypis and Kumar, 1998) library to\npartition the graph."}, {"title": "3.2 Effectiveness of RandomNet", "content": "Given the network architecture, its parameters (weights) represent a form of feature\nextraction from the data and thus produce a kind of representation. With multiple\nrandom parameters, we can have multiple representations.\nSome representations are relevant to the clustering task. The instances that are\nsimilar to each other are more likely to be put in the same cluster under these relevant\nrepresentations. Other representations are irrelevant to the clustering task. Under\nthese representations, two similar instances may not be assigned in the same cluster.\nThe intuition is that, in the ensemble, the effect of irrelevant representations can\ncancel each other out, and the effect of relevant representations can dominate the\nensemble. Inspired by (Li et al., 2019) which is described in the previous section, we\nprovide effectiveness analysis for RandomNet.\nWe assume the data contains k distinct clusters which correspond to k different\nclasses. We have the following theorem:"}, {"title": "4 Experimental Evaluation", "content": "4.1 Experimental setup\nTo evaluate the effectiveness of RandomNet, we run the algorithm on all 128 datasets\nfrom the well-known UCR time series archive (Dau et al., 2019). These datasets come\nfrom different disciplines with various characteristics. Each dataset in the archive is\nsplit into a training set and a testing set. We fuse the two sets and utilize the entire\ndataset in the experiment. Some of these datasets contain varying-length time series.\nTo ensure that all time series in a dataset have the same length, we append zeros at\nthe end of the shorter series.\nFor benchmarking purposes, we run kDBA (Petitjean et al., 2011), KSC (Yang\nand Leskovec, 2011), k-shape (Paparrizos and Gravano, 2015), SPIRAL (Lei et al.,\n2019), and SPF (Li et al., 2019) on the same datasets. These methods are used as\nrepresentatives of the state-of-the-art for time series clustering. Additionally, we incor-\nporated deep-learning-based methods, Improved Deep Embedding Clustering (IDEC)\n(Guo et al., 2017) and DTC (Madiraju et al., 2018), for comparison. While DTC\nis specifically designed for time series data, as discussed in Section 2.2, IDEC is a\ngeneral clustering method. We also compare our method with ROCKET (Dempster\net al., 2020) and its variants, MiniRocket (Dempster et al., 2021) and MultiRocket\n(Tan et al., 2022), since we are interested in how other models that also used random\nparameters compare to ours. As they are all specifically designed for time series clas-\nsification, we adapt them to our use case by removing the classifier component and\nreplacing it with k-means. All references to them will pertain to this adapted version.\nWe do not include DTCR (Ma et al., 2019) in the comparison, as we are unable to\nreproduce the results reported in its paper, despite using the code provided by its\nauthors. This issue has been similarly reported by others on the GitHub issue web-\npage for the project. We do not include CRLI (Ma et al., 2021) since it is specially\ndesigned for incomplete time series data which is outside the scope of our study. Table\n1 provides a concise comparison of our method and various baselines we used in exper-\niments, outlining their applicable data types, method types, main focuses, and time\ncomplexity in terms of the number of instances (n) and the length of time series (l).\nNote that due to the complexity involved in training deep learning models, we have\nnot included the time complexity for the two deep learning methods, DTC and IDEC,"}, {"title": "4.2 Hyperparameter analysis", "content": "To fine-tune and investigate the influence of hyperparameters on model performance,\nwe conduct a series of experiments. We select 20 datasets from the UCR time series\narchive (Dau et al., 2019) and run each experiment 10 times and take the average\nRand Index as the result.\nNumber of branches. The number of branches B plays a pivotal role in our\nmodel, affecting both the quality of the clustering and the computational efficiency.\nWe test B values ranging from 100 to 1000, in increments of 100, and keep all other\nsettings default.\nThe left plot of Fig. 2 shows that the average Rand Index improves with an increase\nin the number of branches until B 800. Increasing the number of branches beyond\n800 only results in a rise in running time, without contributing to better clustering\nquality. Therefore, we set the default B for all datasets to 800.\nSelection rate. The selection rate $s_r$ controls the lower bound of the number of\nselected clustering. We test $s_r$ values ranging from 0.1 to 1, in increments of 0.1, and\nkeep all other settings default.\nThe middle plot of Fig. 2 shows slight changes in the average Rand index as $s_r$\nchanges. Since a larger $s_r$ will increase the running time of the model, we choose\n$s_r = 0.1$ as the default value.\nLower bound and upper bound. The lower bound $l_r$ and the upper bound $u_r$\nare crucial in detecting the number of violation, which affects the quality of clustering.\nWe evaluate three pairs of $l_r$ and $u_r$, (0.1,1.8), (0.3, 1.5), and (0.5, 1.2), representing\nwide intervals, intermediate intervals, and narrow intervals, respectively. For simplicity,\nwe present these as multipliers; the actual lower and upper bounds are obtained by\nmultiplying these values with the average cluster size $a_{cs}$. Narrower intervals are more\nrestrictive to the size of the clustering and thus will increase the number of violations.\nWe keep all other settings as default."}, {"title": "4.3 Experimental results", "content": "Since we use 20 of the 128 datasets to select the hyperparameters, for the sake of\nfairness, we remove them in the following comparison and only show the results for\nthe remaining 108 datasets.\nComparison with k-means.\nAs RandomNet uses k-means to generate clustering assignments, we are interested\nin how they compare. We also run k-means 800 times and use HBGF (Fern and\nBrodley, 2004) to ensemble the results, which is denoted as kmeansE.\nWe run the methods under comparison on the 108 datasets and record the Rand\nIndex. Figure 3 presents a critical difference diagram (Dem\u0161ar, 2006) for the compari-\nson based on Rand Index. The values adjacent to each method represent the respective"}, {"title": "4.4 Ablation study", "content": "To verify the effectiveness of each component in RandomNet, we compare the per-\nformance of full RandomNet and its four variants on 108 UCR datasets, which are\nshown in Table 6. The four variants are, 1) RandomNet w/ GRU (replaces LSTM\nwith GRU), 2) RandomNet w/o LSTM (removes LSTM), 3) RandomNet w/o LSTM\n& ReLU (removes LSTM and ReLU), and 4) RandomNet w/o LSTM & ReLU &\npooling (removes LSTM, ReLU and pooling).\nThe results show that full RandomNet is better than the four variants in average\nrand index and average rank, reflecting the effectiveness of each part of RandomNet.\nIt is worth noting that pooling is important in the model. Removing pooling will\nsignificantly increase the running time and decrease the performance."}, {"title": "4.5 Visualizing clusters for different methods", "content": "Figure 6 shows the 2D embeddings of the Cylinder-Bell-Funnel (CBF) (Saito and\nCoifman, 1994) dataset using t-distributed Stochastic Neighbor Embedding (t-SNE)\nalgorithm (Van der Maaten and Hinton, 2008), as well as cluster assignments by k-\nmeans, MiniRocket, and RandomNet compared with the true labels. We can see clearly\nthat k-means and MiniRocket both have difficulty distinguishing the blue and green\nclasses, which correspond to the Bell and the Cylinder classes, respectively."}, {"title": "4.6 Testing the time complexity", "content": "In real-world applications, the size of datasets and the length of time series can be\nhuge, making linear time complexity with respect to the number of instances and\nlength of time series an essential characteristic of any practical model. To test the\nscalability and effectiveness of our proposed method, we use the same mechanism to\ngenerate datasets of varying sizes. For different time series lengths, we supplement the\noriginal time series (length of 128) with random noise to reach the required length. In\nthis experiment, we use the CBF dataset (Saito and Coifman, 1994). For testing linear\ncomplexity w.r.t the number of instances, the number of instances is set from 200 to\n10,000 with a fixed time series length of 100. For testing linear complexity w.r.t the"}, {"title": "4.7 Analyzing noise sensitivity", "content": "We use three different datasets, SmallKitchen Appliances, ECG200, and FiftyWords,\nfrom three different application domains to test the noise sensitivity of the model.\nThese datasets are injected with six levels of random Gaussian noise (scales of 0.05,\n0.1, 0.2, 0.3, 0.4, and 0.5). This setting ensures that most values in the time series\nare valid, unlike in the previous section, where most values are noise. We evaluate\nthe performance of RandomNet against the second-best model, SPF, by running each\nmodel 10 times and calculating the average Rand Index.\nAs illustrated in Fig. 9, while both models exhibit a strong resilience to noise, our\nmodel is slightly better than SPF. For the SmallKitchenAppliances dataset, the per-\nformance of RandomNet has little effect as the noise level increases. On the contrary,\nthe performance of SPF decreases more obviously. In the ECG200 dataset, both mod-\nels experience small fluctuations in performance at different noise levels, indicating\nsimilar effects on noise in this case. For the FiftyWords dataset, both models remain\nhighly stable and show minimal performance differences despite the introduced noise.\nOverall, these observations highlight RandomNet's competitive ability to handle\nnoise, confirming its effectiveness and robustness in noisy scenarios."}, {"title": "4.8 Finding the optimal number of clusters", "content": "In many real-world data mining scenarios, the true number of clusters (k) within the\ndataset is unknown, so whether the model has the ability to determine the optimal k\nis crucial. The Elbow Method is a widely accepted heuristic used in determining the\noptimal k. It entails plotting the explained variation as a function of k and picking\nthe \"elbow\" of the curve as the optimal k to use.\nWe apply the Elbow Method to the clustering performed by both k-means and\nRandomNet on the CBF dataset, which contains three classes. As shown in Fig. 10,\nRandomNet can find an obvious \"elbow\" at k = 3, whereas for k-means, it is hard to\nlocate a clear \"elbow\"."}, {"title": "5 Conclusion and Future Work", "content": "In this paper, we introduces RandomNet, a novel method for time series clustering that\nutilizes deep neural networks with random parameters to extract diverse representa-\ntions of the input time series for clustering. The data only passes through the network\nonce, and no backpropagation is involved. The selection mechanism and ensemble in\nthe proposed method cancel irrelevant representations out and strengthen relevant\nrepresentations to provide reliable clustering. Extensive evaluations conducted across\nall 128 UCR datasets demonstrate competitive accuracy compared to state-of-the-art\nmethods, as well as superior efficiency. Future research directions may involve integrat-\ning more complex or domain-specific network structures into our method. Additionally,\nincorporating some level of training into the framework could potentially improve\nperformance. We will also try to explore the potential of applying our method to\nmultivariate time series or other data types, such as image data."}]}