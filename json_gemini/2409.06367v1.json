{"title": "Texture-AD: An Anomaly Detection Dataset and Benchmark for Real Algorithm Development", "authors": ["Tianwu Lei", "Bohan Wang", "Silin Chen", "Shurong Cao", "Ningmu Zou"], "abstract": "Anomaly detection is a crucial process in industrial manufacturing and has made significant advancements recently. However, there is a large variance between the data used in the development and the data collected by the production environment. Therefore, we present the Texture-AD benchmark based on representative texture-based anomaly detection to evaluate the effectiveness of unsupervised anomaly detection algorithms in real-world applications. This dataset includes images of 15 different cloth, 14 semiconductor wafers and 10 metal plates acquired under different optical schemes. In addition, it includes more than 10 different types of defects produced during real manufacturing processes, such as scratches, wrinkles, color variations and point defects, which are often more difficult to detect than existing datasets. All anomalous areas are provided with pixel-level annotations to facilitate comprehensive evaluation using anomaly detection models. Specifically, to adapt to diverse products in automated pipelines, we present a new evaluation method and results of baseline algorithms. The experimental results show that Texture-AD is a difficult challenge for state-of-the-art algorithms. To our knowledge, Texture-AD is the first dataset to be devoted to evaluating industrial defect detection algorithms in the real world.", "sections": [{"title": "Introduction", "content": "Industrial inspection algorithms are typically developed and tested using collected data before deployment, for use in automated quality control equipment on production lines. In recent years, a variety of detection methods have developed for detecting an anomalous image region in image data through contemporary machine learning approaches. These methodologies have demonstrated promising results on established datasets. Present evaluation strategies typically entail integrating flawless production data of a single object category during the training stage and evaluating performance using data containing anomalies.\nThe acquisition of flawless production data has become more accessible when contrasted with defective data. However, a production line is often required to deal with various specifications of similar products, such as gray cloth, red cloth, mesh cloth, different types of wafers as well as black brushed metal plates, gold frosted metal plates, etc. While these different specifications share certain common features, they also present significant differences. Additionally, minor fluctuations in external conditions, such as lighting environment and camera settings, result in a data distribution after deployment that is unlikely to align with the data collected during the training phase. This situation places increased requirements on the robustness of the algorithms.\nHumans have the natural ability to visually discern the similarities and differences in images and to detect defects and irregularities within them. Currently, there are many commonly used datasets for anomaly detection, which vary greatly in the scenes and scale they contain. For example, datasets related to cloth texture generally have a good amount of data, but they differ significantly from actual production scenarios. In addition, as chips become an increasingly important field of research worldwide, wafer defect detection has become an essential part of the process. Therefore, the demand for wafer defect detection datasets in industrial inspection is also growing, yet there are very few open-source wafer defect detection datasets available. Moreover, there are more datasets related to metal defects in industrial production, but they generally include material types and apply to a more limited range of scenarios. There are also datasets related to crack defects, such as cracks in bridge surfaces and concrete floors.\nSo far, modern machine learning systems have encountered considerable challenges in addressing related issues, mainly because the existing datasets are not particularly well-suited to real-world scenarios. Currently, the evaluation of anomaly detection algorithms often relies on datasets such as MVTec, where the features of flawless and defective items show a high degree of consistency, leading to higher performance metrics than actual deployment. Therefore, this paper proposes the Texture-AD dataset, which clearly demonstrates the differences between Texture-AD and the MVTec dataset."}, {"title": "Related Work", "content": "Computer vision equipment for detecting surface defects has largely replaced manual inspections across industries like 3C electronics, automotive, machinery, semiconductors, chemicals and so on. Traditional methods use standard image processing and classifiers with handcrafted features, while effective imaging schemes ensure clear defect visibility under uniform lighting. Recently, deep learning has become prevalent for defect detection.\nDAGM2007 dataset is artificially generated but resembles real-world problems. Six categories referred to as the development dataset, should be used for algorithm development. The remaining four categories (referred to as the competition dataset) can be used to evaluate performance. AITEX dataset is an image dataset focused on the textile industry, designed to support research and application of machine learning and computer vision technology in the field of textile quality inspection. However, the aforementioned two datasets have issues with unclear defect labeling and a rather singular background type and defect type, which cannot fully simulate the complex detection scenarios in actual industrial environments.\nThe WM-811K dataset is a dataset specifically for semiconductor wafer map defect type identification, with images in the dataset mainly coming from actual production environments of wafer maps, obtained through electrical testing, and used to describe the state of wafer defects. However, the WM-811K represents without texture details and pattern information.\nA dataset collected six typical surface defects of hot-rolled steel strips. This surface defect dataset faces two major challenges: large differences in appearance among defects within the same category, and similarities between defects of different categories, with defect images affected by lighting and material changes. The NEU-surface-defect-database has six typical surface defects of hot-rolled steel strips, namely rolling scale, patches, cracks, pitted surfaces, inclusions and scratches. The improved X-SDD dataset includes: seven typical types of hot-rolled steel strip defect images, due to the imbalance of sample quantity in X-SDD, it provides conditions for researchers to solve the problem of sample imbalance. The SD-saliency-900 dataset includes three types of steel strip surface defects (inclusions, patches and scratches), including steel surface defect detection images and corresponding pixel-level binary masks. RSDDS-113 dataset, with samples taken from the actual industrial production line of a section steel factory, collects 20 track sections with defect information. Each pair of images in this dataset consists of a left camera image and the corresponding depth image; the dataset has a high degree of annotation credibility, but the amount of data samples is fewer. The Rail-5k dataset is used for the task of steel rail surface defect detection. The dataset can be used for two settings, the first is a supervised setting trained with marked images, the fine-grained nature of defect categories and long-tail distribution makes it difficult for visual algorithms to solve. The second is a semi-supervised learning setting promoted by unmarked images, including possible image damage and domain shift with marked images. The dataset can support both supervised and semi-supervised learning settings. In actual production, there may be unknown types of defects, making it difficult for the aforementioned traditional datasets based on known defect patterns to cope. In addition, it is difficult to obtain a large number of defect samples in the aforementioned datasets, leading to the problem of small sample sizes, when training deep learning models.\nThe Concrete Crack Images for Classification dataset is created specifically for the task of concrete crack classification. This dataset typically contains tens of thousands of images of concrete surfaces, showing cracks of different types and severities. The Crack-Detection dataset is designed specifically for crack detection tasks, containing images for training and evaluating crack identification algorithms. These images usually come from various material surfaces, especially concrete and other construction engineering materials, because cracks in these materials may lead to structural problems. The images in the aforementioned datasets have issues with varying quality, including resolution, lighting conditions, angles and background complexity, which may affect the performance of crack detection algorithms in the deployment process.\nMVTec contains images of anomalous samples with various defects, manually generated. This is a popular dataset for unsupervised anomaly detection that simulates real-world industrial inspection scenarios. The dataset provides the possibility of evaluating unsupervised anomaly detection methods for various textures and object classes with different types of anomalies. Since it provides pixel-level precise ground truth labels for the abnormal areas in the images, it is possible to evaluate anomaly detection methods for image-level classification and pixel-level segmentation.\nIn industrial settings, the prevalence of normal samples over defective ones creates a dataset imbalance, affecting model training and generalization. Acquiring a significant number of defective samples is costly and time-consuming, especially for rare defects. Current datasets may not cover all defect types, limiting the model's ability to identify unusual defects. The complexity of industrial products' appearance and potential labeling inconsistencies add to the challenge of defect detection. Moreover, the need for real-time responses in industry is often not met by existing datasets, leading to models that may not perform well in new environments."}, {"title": "Dataset", "content": "The anomaly detection dataset we propose includes 15 subclasses of cloth, covering a variety of colors, materials and texture defects, 14 different subclasses of wafers and 10 subclasses of metal plates, including 5 colors each with brushed and matte finishes, totaling 10 subclasses of textures. The defects in our dataset are imperfections that occur in actual production environments, making it extremely valuable for the study of industrial quality inspection algorithms. Cloth defects include pencil marks, cuts, marker stains, water stains, black and white dots, threads, inconsistent sewing distances and color differences caused by dyeing. Wafer and metal plate defects include scratches, stains and inherent manufacturing defects, all of which naturally occur in the production process. Our dataset contains a total of 43120 images, with 28973 images used for training and validation, and 14147 images for testing. The training set includes only defect-free images. The test set contains two types of images: images with various types of defects and defect-free images. Figure 3 shows the percentage of the image area occupied by the anomalous regions.\nSpecific to the division of the dataset, we provide good production images from multiple subclasses for each category as the training set, allowing the model to learn the characteristics and differences of each subclass. At the same time, we also provide defect images and good production images from the same category for the test set to evaluate the model's recognition ability when facing actual defects."}, {"title": "Data Generation", "content": "All images were captured using a high-resolution industrial camera (MV-CS200-10 GC) at a resolution of 5472 \u00d7 3648 pixels, in conjunction with two light sources. The optical scheme was altered by adjusting the position and brightness of the light sources. Our image acquisition and defect annotation process is depicted in Figure 4. The defects in our dataset were manually annotated using the Labelme annotation tool. To better align with the defects produced in the industrial manufacturing process, we created some artificial defects on the cloth, while the wafers and metal plates exhibited naturally occurring defects. Subsequently, these images were cropped to the appropriate output size. All images have a resolution of 1024 \u00d7 1024 pixels. The training set images were obtained under relatively stable lighting conditions. However, for the test set, we intentionally varied the optical scheme to simulate the imaging discrepancies between the algorithm training phase and actual deployment. We provided pixel-level ground truth annotations for each defective image area."}, {"title": "Anomaly Detection Methods", "content": "The current research trend in anomaly detection is primarily focused on unsupervised anomaly detection. This trend has emerged due to the fact that obtaining anomalous samples requires a significant investment of human and financial resources. In this research context, training data contains only normal samples, while test data includes both normal and anomalous samples. Industrial image anomaly detection is a specific branch within the field of anomaly detection, and we mainly evaluate and compare it using the following three research directions."}, {"title": "Synthesis-based Anomaly Detection", "content": "Some supervised learning methods use a limited number of anomaly samples to synthesize more anomaly samples to enhance training effectiveness. For example, A basic architecture that integrates CycleGAN with ResNet/U-Net as the generator is used to transfer defects from one image to another. SDGAN achieved better results than CycleGAN by improving the style transfer network. DRAEM first restores the normal image with pseudo-anomaly interference to obtain feature representation and then uses a discriminator network to distinguish anomalies, demonstrating excellent performance. Although this field has made certain research progress, it still has a huge development space compared to other fields with clear research directions."}, {"title": "Reconstruction-based Anomaly Detection", "content": "These methods are based on the assumption that a reconstruction model trained only on normal samples can successfully reconstruct images in normal areas but fail in abnormal areas. Early attempts included autoencoders(AE), variational autoencoders(VAE) and generative adversarial networks(GAN). However, these methods may cause the model to learn certain tricks, leading to the effective recovery of anomalies as well. To address this issue, researchers have adopted various strategies, such as introducing guidance information (structure or semantics), memory mechanisms, iterative mechanisms, image masking strategies and pseudo-anomaly .PyramidFlow based on the transformer and further design set a new record on MVTec\u0441."}, {"title": "Feature-Embedding Based Methods", "content": "Feature embedding methods are committed to distinguishing normal and abnormal samples at the feature representation level. Uniformed Students pioneered the use of discriminative latent embeddings for anomaly detection. This model is simple and effective, significantly outperforming other benchmark methods. STPM and MKD utilize multi-scale features on different network layers for feature distillation, although there are differences in their methods. In addition, SimpleNet has achieved satisfactory results by introducing noise into the feature embedding to simulate negative samples."}, {"title": "Benchmark", "content": ""}, {"title": "Baseline Methods", "content": "SimpleNet SimpleNet proposed a simple and easy-to-apply network for detecting and localizing anomalies in images. We evaluated using the publicly available SimpleNet implementation on Pytorch. The backbone network used Wide Resnet50 as the backbone network, setting the feature dimension of the feature extractor to 1536 to accommodate 329 \u00d7 329 sized input images. The anomaly feature generator added isotropic Gaussian noise $N(0, \\sigma^2)$, where o defaults to 0.015. The subsequent discriminator includes a linear layer, batch normalization layer, leaky ReLU with a slope of 0.2 and a linear layer. The Adam optimizer was used, with learning rates of 0.0001 and 0.0002 set for the feature adapter and discriminator, respectively and a weight decay of 0.00001. Each dataset was trained for 160 epochs with a batch size of 8.\nPyramidFlow PyramidFlow proposed a new anomaly localization method, which is based on the defect contrastive localization paradigm using a pyramid of normalization flows for multi-scale fusion and volume normalization to achieve high-resolution defect localization. We used a fixed pyramid layer number $L = 8$, image resolution of 256 x 256 and channel number $C = 24$, and varied the stacked layer number D to explore the trends in memory usage and model parameterization. During training, sample mean normalization was used, and the running mean was updated with a momentum of 0.1. At test time, volume normalization was based on the running mean.\nMean-Shift Mean-Shift introduced a novel self-supervised representation learning method to improve anomaly detection. It pointed out that traditional contrastive learning methods are not suitable for pre-trained features, hence they proposed the Mean-Shifted Contrastive Loss. In the experiments targeting ResNet152, we fine-tuned the last two blocks of a ResNet152 model pre-trained on the ImageNet dataset and added an 12 normalization layer, a process that lasted for 10 training epochs. For the experiments with ResNet18, we fine-tuned the entire backbone of a ResNet18 model pre-trained on ImageNet and similarly added an 12 normalization layer, a process that included 20 training epochs. In both cases, we minimized the Mean-Shifted Contrastive loss function with a temperature parameter T set to 0.25. We used the Stochastic Gradient Descent (SGD) optimizer with a weight decay of 5 \u00d7 10\u22125, and without momentum. We set the size of each mini-batch to 64."}, {"title": "Evaluation Method", "content": "Train and Test data As shown in Table 1, the information available during the training process is the same as for MVTec, but the sub-category labels cannot be used during the testing process.\nData Augmentation Since the evaluated methods based on deep learning are typically trained on large datasets, data augmentation is performed for these methods for both textures and objects. We resize the image to fit the shape of the model input. Additional mirroring is applied. We augment each category to create 10000 training images.\nEvaluation Metric Following prior works, the Area Under the Receiver Operating Curve (AUROC)is used as the evaluation metric for anomaly detection. Image-level anomaly detection performance is measured via the standard Area Under the Receiver Operator Curve, which we denote as I-AUROC. For anomaly localization, we use an evaluation of pixel-wise AUROC (denoted as P-AUROC)."}, {"title": "Result", "content": "As shown in Table 2, Table 3 and Table 4, we present the evaluation results of anomaly image classification and anomaly region segmentation for all methods and dataset categories, respectively. No method performs consistently well across all texture categories. In the cloth category, SimpleNet outperforms the other methods. But in the wafer category, DRAEM performs better than SimpleNet. In the metal plate category, EfficientAD leads the second place by 4.38% in I-AUROC. As shown in Figure 5, when applying our dataset Texture-AD for evaluation alongside the MVTec dataset, it was found that the evaluation results of our dataset are generally lower, which can expose the problem domains where the algorithm fails, facilitating targeted optimization of the algorithm's weak points in subsequent improvements. Here are the evaluation results of each method. Some examples of performance were provided. All experimental results are the mean of 3 replicates."}, {"title": "Conclusion", "content": "We introduce the Texture-AD Anomaly Detection Benchmark, a novel dataset for unsupervised anomaly detection that mimics real-world industrial detection scenarios. The dataset provides a way to evaluate unsupervised anomaly detection methods in realistic algorithm development scenarios. Since pixel-accurate ground truth labels of anomaly regions in images are provided, both image-level classification and pixel-level segmentation anomaly detection methods can be evaluated. Several state-of-the-art methods are evaluated on this dataset. The evaluation provided a benchmark for showing how different algorithms perform in real-world application scenarios and indicating that there is still much room for improvement. We hope that the proposed dataset will stimulate the development of new unsupervised anomaly detection methods."}]}