{"title": "ALPHAEDIT: NULL-SPACE CONSTRAINED\nKNOWLEDGE EDITING FOR LANGUAGE MODELS", "authors": ["Junfeng Fang", "Houcheng Jiang", "Kun Wang", "Xiang Wang", "Xiangnan He", "Yunshan Ma", "Tat-Seng Chua"], "abstract": "Large language models (LLMs) often exhibit hallucinations due to incorrect or\noutdated knowledge. Hence, model editing methods have emerged to enable\ntargeted knowledge updates. To achieve this, a prevailing paradigm is the locating-\nthen-editing approach, which first locates influential parameters and then edits them\nby introducing a perturbation. While effective, current studies have demonstrated\nthat this perturbation inevitably disrupt the originally preserved knowledge within\nLLMs, especially in sequential editing scenarios. To address this, we introduce\nAlphaEdit, a novel solution that projects perturbation onto the null space of the\npreserved knowledge before applying it to the parameters. We theoretically prove\nthat this projection ensures the output of post-edited LLMs remains unchanged\nwhen queried about the preserved knowledge, thereby mitigating the issue of\ndisruption. Extensive experiments on various LLMs, including LLaMA3, GPT2-\nXL, and GPT-J, show that AlphaEdit boosts the performance of most locating-\nthen-editing methods by an average of 36.4% with a single line of additional\ncode for projection solely. Our code is available at: https://github.com/\njianghoucheng/AlphaEdit.", "sections": [{"title": "INTRODUCTION", "content": "Large language models (LLMs) have demonstrated the capability to store extensive knowledge during\npre-training and recall it during inference (Brown et al., 2020; Petroni et al., 2019; Roberts et al.,\n2020; Radford et al., 2019). Despite this, they frequently exhibit hallucinations, producing incorrect\nor outdated information (Cao et al., 2021; Mitchell et al., 2022a). While fine-tuning with updated\nknowledge offers a straightforward solution, it is often prohibitively time-consuming (Mitchell et al.,\n2022b). In sight of this, model editing methods have emerged, enabling updating the target knowledge\nwhile preserving other knowledge (Meng et al., 2022). Broadly, model editing approaches fall into\ntwo categories: (1) parameter-modifying methods, which directly adjust a small subset of parameters\n(Zhu et al., 2020; Mitchell et al., 2022a; Meng et al., 2022), and (2) parameter-preserving methods\nthat integrate additional modules without altering the original parameters (Mitchell et al., 2022b;\nZheng et al., 2023a; Huang et al., 2023; Yu et al., 2024; Hartvigsen et al., 2023).\nIn this paper, we aim to explore the parameter-modifying methods for model editing. Concretely,\ncurrent parameter-modifying methods typically follow the locate-then-edit paradigm (Meng et al.,\n2022; 2023). The basic idea is to first locate influential parameters W through causal tracing, and then\nedit them by introducing a perturbation \\(\\Delta\\) (Meng et al., 2023). The common objective for solving\n\\(\\Delta\\) is to minimize the output error on the to-be-updated knowledge, denoted as \\(e_1\\). Additionally,\nthe output error on the to-be-preserved knowledge, \\(e_0\\), is typically incorporated into the objective\nfunction, acting as a constraint to ensure the model's accuracy on the preserved knowledge."}, {"title": "PRELIMINARY", "content": ""}, {"title": "AUTOREGRESSIVE LANGUAGE MODEL", "content": "An autoregressive large language model (LLM) predicts the next token \u00e6 in a sequence based on the\npreceding tokens. Specifically, the hidden state of \u00e6 at layer l within the model, denoted as \\(h^l\\), can\nbe calculated as:\n\\[h^l = h^{l-1} + a^l + m^l, \\quad m^l = W_{\\text{out}} \\sigma (W_{\\text{in}} (h^{l-1} + a^l)),\\]\nwhere \\(a^l\\) and \\(m^l\\) represent the outputs of the attention block and the feed-forward network (FFN)\nlayer, respectively; \\(W_{\\text{in}}\\) and \\(W_{\\text{out}}\\) are the weight matrices of the FFN layers; \\(\\sigma\\) is the non-linear\nactivation function, and \\(\\gamma\\) denotes the layer normalization. Following Meng et al. (2022), we express\nthe attention and FFN modules in parallel here.\nIt is worth noting that \\(W_{\\text{out}}\\) within FFN layers is often interpreted as a linear associative memory,\nfunctioning as key-value storage for information retrieval (Geva et al., 2021). Specifically, if the\nknowledge stored in LLMs is formalized as (s, r, o) \u2014 representing subject s, relation r, and object\no (e.g., s = \"The latest Olympic Game\", r = \u201cwas held in\", o = \"Paris\") - \\(W_{\\text{out}}\\) associates a set\nof input keys k encoding (s,r) with corresponding values v encoding (0). That is,\n\\[m^l = W_{\\text{out}} \\sigma (W_{\\text{in}} (h^{l-1} + a^l)).\\]"}, {"title": "MODEL EDITING IN LLMS", "content": "Model editing aims to update knowledge stored in LLMs through a single edit or multiple edits (i.e.,\nsequential editing). Each edit modifies the model parameters W by adding a perturbation \\(\\Delta\\) in\nlocate-then-edit paradigm. Specifically, suppose each edit needs to update u new pieces of knowledge\nin the form of (s, r, o). The perturbed W is expected to associate u new k-v pairs, where k and\nv encode (s,r) and (o) of the new knowledge, respectively. Let \\(W \\in \\mathbb{R}^{d_1 \\times d_0}\\), where \\(d_0\\) and \\(d_1\\)\nrepresent the dimensions of the FFN's intermediate and output layers. Then, we can stack these keys\nand values into matrices following:\n\\[K_1 = [k_1 | k_2 | ... | k_u] \\in \\mathbb{R}^{d_0 \\times u}, \\quad V_1 = [v_1 | v_2 | ... | v_u] \\in \\mathbb{R}^{d_1 \\times u},\\]\nwhere the subscripts of k and v represent the index of the to-be-updated knowledge. Based on these,\nthe objective can be expressed as:\n\\[\\Delta = \\underset{\\Lambda}{\\text{argmin}} || (W+\\Delta)K_1 - V_1||^2,\\]\nwhere \\(||\\cdot||_2\\) denotes the sum of the squared elements in the matrix.\nAdditionally, let \\(K_0\\) and \\(V_0\\) represent the matrices formed by stacking the k and v of the preserved\nknowledge. Current methods (Meng et al., 2023; Gu et al., 2024) typically incorporate the error\ninvolving \\(K_0\\) and \\(V_0\\) to preserve it, as follows:\n\\[\\Delta = \\underset{\\Lambda}{\\text{argmin}}(||(W+\\Delta)K_1 - V_1||^2 + \\lambda || (W+\\Delta)K_0 - V_0||^2).\\]\nSince \\(K_0\\) and \\(V_0\\) encode the preserved knowledge in LLMs, we have \\(WK_0 = V_0\\) (cf. Eqn. 2).\nThus, by applying the normal equation (Lang, 2012), if the closed-form solution of Eqn. 5 exists, it\ncan be written as:\n\\[\\Delta = (V_1 - WK_1) K_1^T (K_1 K_1^T + K_0 K_0^T)^{-1}.\\]"}, {"title": "METHOD", "content": "In this section, we first introduce the concept of the null space and its relationship to model editing\n(Section 3.1). Based on this, we present the method for projecting a given perturbation \\(\\Delta\\) onto the\nnull space of the matrix \\(K_0\\), which encodes the persevered knowledge (Section 3.2). Following\nthat, a new editing objective that incorporates the aforementioned projection method is introduced in\nSection 3.3."}, {"title": "NULL SPACE", "content": "Null space is at the core of our work. Here we first introduce the definition of the left null space\n(hereafter referred to simply as null space). Specifically, given two matrices A and B, B is in the\nnull space of B if and only if \\(BA = 0\\). See Adam-NSCL (Wang et al., 2021) for more details.\nIn the context of model editing, if the perturbation \\(\\Delta\\) is projected into the null space of \\(K_0\\) (i.e.,\n\\(\\Delta K_0 = 0\\)), adding it to the model parameters W results in:\n\\[(W+\\Delta)K_0 = WK_0 = V_0.\\]\nThis implies that the projected \\(\\Delta\\) will not disrupt the key-value associations of the preserved\nknowledge (i.e., \\({K_0, V_0}\\)), ensuring that the storage of the preserved knowledge remains intact.\nTherefore, in this work, before adding perturbation \\(\\Delta\\) to the model parameters W, we project it onto\nthe null space of \\(K_0\\) to protect the preserved knowledge. This protection allows us to remove the first\nterm \u2014 the term focusing on protecting the preserved knowledge \u2014 from the objective in Eqn. 5."}, {"title": "NULL SPACE PROJECTING", "content": "In Section 3.1, we briefly explained why \\(\\Delta\\) should be projected into the null space of \\(K_0\\). In this\npart, we focus on how to implement this projection.\nAs introduced at the end of Section 2.2, the matrix \\(K_0 \\in \\mathbb{R}^{d_0 \\times 100,000}\\) has a high dimensionality\nwith 100, 000 columns. Hence, directly projecting the given perturbation \\(\\Delta\\) onto the null space of\n\\(K_0\\) presents significant computational and storage challenges. In sight of this, we adopt the null\nspace of the non-central covariance matrix \\(K_0 K_0^T \\in \\mathbb{R}^{d_0 \\times d_0}\\) as a substitute to reduce computational\ncomplexity, as \\(d_0\\) is typically much smaller than 100,000. This matrix's null space is consistent with\nthat of \\(K_0\\) (please see Appendix B.2 for detailed proof).\nFollowing the existing methods for conducting null space projection (Wang et al., 2021), we first\napply a Singular Value Decomposition (SVD) to \\(K_0 (K_0)^T\\):\n\\[\\{U, \\Lambda, (U)^T\\} = \\text{SVD} (K_0 (K_0)^T),\\]\nwhere each column in U is an eigenvector of \\(K_0 (K_0)^T\\). Then, we remove the eigenvectors in U\nthat correspond to non-zero eigenvalues\u00b2, and define the remaining submatrix as \\(\\hat{U}\\). Based on this,\nthe projection matrix P can be defined as follows:\n\\[P = \\hat{U} (\\hat{U})^T.\\]\nThis projection matrix can map the column vectors of \\(\\Delta\\) into the null space of \\(K_0 (K_0)^T\\), as it\nsatisfies the condition \\(\\Delta P \\cdot K_0 (K_0)^T = 0\\). The detailed derivation is exhibited in Appendix B.3.\nSince \\(K_0\\) and \\(K_0 (K_0)^T\\) share the same null space, we can derive \\(\\Delta P \\cdot K_0 = 0\\). Hence, we have:\n\\[(W + \\Delta P) K_0 = WK_0 = V_0.\\]\nThis shows the projection matrix P ensures that the model edits occur without interference with the\npreserved knowledge in LLMs."}, {"title": "NULL-SPACE CONSTRAINED MODEL EDITING", "content": "Section 3.2 has provided how to apply projection to ensure that preserved knowledge is not disrupted.\nHere, we introduce how to leverage this projection to optimize the current model editing objective.\nStarting with the single-edit objective in Eqn. 5, the optimization follows three steps: (1) Replace\n\\(\\Delta\\) with the projected perturbation \\(\\Delta P\\), ensuring that the perturbation would not disrupt the pre-\nserved knowledge; (2) Remove the first term involving \\(K_0\\), as Step (1) has already protected the\npreserved knowledge from being disrupted; (3) Add a regularization term \\(||\\Delta P||^2\\) to guarantee stable\nconvergence. With these optimizations, Eqn. 5 becomes:\n\\[\\Lambda = \\underset{\\Lambda}{\\text{argmin}} (||(W+\\Delta P)K_1 - V_1||^2 + \\lambda ||\\Delta P||^2),\\]\nwhere \\(K_1\\) and \\(V_1\\) denote the key and value matrices of to-be-updated knowledge defined in Eqn. 3.\nIn sequential editing tasks, during the current edit, we also need to add a term to the objective (cf.\nEqn. 11) to prevent the perturbation from disrupting the updated knowledge in previous edits. Let\n\\(K_p\\) and \\(V_p\\) present the key and value matrices of the previously updated knowledge, analogous to the\nearlier definitions of \\(K_1\\) and \\(V_1\\). This term should minimize \\(||(W + \\Delta P)K_p - V_p||^2\\) to protect the\nassociation. Since the related knowledge has been updated in previous edits, we have \\(WK_p = V_p\\).\nHence, this term can be simplified to \\(||\\Delta PK_p||^2\\), and adding it to Eqn. 11 gives the new objective:\n\\[\\Lambda = \\underset{\\Lambda}{\\text{argmin}} (||(W+\\Delta P)K_1 - V_1||^2 + \\lambda ||\\Delta P||^2 + ||\\Delta PK_p||^2).\\]\nTo facilitate expression, we define the residual vector of the current edit as \\(R = V_1 - WK_1\\). Based\non this, Eqn. 12 can be solved using the normal equation (Lang, 2012):\n\\[(\\Delta P K_1 - R) K_1^T P + \\lambda \\Delta P + \\Delta P K_p K_p^T = 0.\\]\nSolving Eqn. 13 yields the final perturbation \\(\\Delta_{\\text{AlphaEdit}}\\) \\(\\Delta P\\) which will be added to the model\nparameters W:\n\\[\\Delta_{\\text{AlphaEdit}} = R K_1^T (K_p K_p^T + K_1 K_1^T P + \\lambda I)^{-1}.\\]\nThe invertibility of the term within the brackets in the above equation is proved in Appendix B.4.\nThis solution \\(\\Delta_{\\text{AlphaEdit}}\\) could not only store the to-be-updated knowledge in the current edit, but also\nensure that both the preserved knowledge and the previously updated knowledge remain unaffected.\nFurthermore, for better comparison, we also present the commonly used solution in existing methods\nlike MEMIT (Meng et al., 2023) as follows\u00b3:\n\\[\\Delta_{\\text{MEMIT}} = R K_1^T (K_p K_p^T + K_1 K_1^T + K_0 K_0^T)^{-1}.\\]\nBy comparing Eqn. 14 and 15, it is evident that our approach requires only a minor modification\nto the standard solution by incorporating the projection matrix P. This makes our method easily\nintegrable into existing model editing algorithms. Figure 3 summarizes this modification from the\nperspective of convergence objectives. We emphasize that by adding just a single line of code for\nthis modification, the performance of most editing methods could be significantly enhanced, as\nshown in Figure 2. More detailed experimental results are exhibited in Section 4."}, {"title": "EXPERIMENT", "content": "In this section, we conduct experiments to address the following research questions:\n\u2022 RQ1: How does AlphaEdit perform on sequential editing tasks compared to baseline methods?\nCan it mitigate the issues of model forgetting and model collapse exhibited in Figure 1?\n\u2022 RQ2: How does AlphaEdit-edited LLM perform on general ability evaluations? Does the post-\nedited LLM successfully retain its inherent capabilities?\n\u2022 RQ3: Can AlphaEdit effectively prevent the model from overfitting to updated knowledge?\nSpecifically, can the post-edited LLM avoid shifts in the distribution of hidden representations?\n\u2022 RQ4: Can the performance of baseline methods be significantly improved with a single line of\ncode in AlphaEdit (i.e., the code for projection)?"}, {"title": "EXPERIMENTAL SETUP", "content": "We begin by briefly outlining the evaluation metrics, datasets, and baseline methods. For more\ndetailed descriptions of the experimental settings, please refer to Appendix A."}, {"title": "PERFORMANCE ON KNOWLEDGE UPDATE AND PRESERVATION (RQ1)", "content": "To evaluate the performance of different editing methods in terms of knowledge update and retention,\nwe conducted sequential editing on three base LLMs using AlphaEdit and the baseline methods.\nTable 1 presents the results under a commonly used configuration for the sequential editing task,\nwhere 2,000 samples are randomly drawn from the dataset for updates, with 100 samples per edit\n(i.e., a batch size of 100). For additional experimental results, such as case studies of model outputs\nafter editing, please refer to Appendix C. Based on Table 1, we can draw the following observations:\n\u2022 Obs 1: AlphaEdit achieves superior performance across nearly all metrics and base models.\nSpecifically, in terms of Efficacy and Generalization metrics, AlphaEdit provides an average\nimprovement of 12.54% and 16.78%, respectively, over the best baseline. On Llama3, these\nperformance boosts are even more remarkable (i.e., 32.85%\u2191 and 30.60%\u2191). These gains arise\nfrom AlphaEdit's ability to mitigate the trade-off between updating and preserving knowledge.\n\u2022 Obs 2: AlphaEdit enhances text generation fluency and coherence. In addition to editing\ncapabilities, AlphaEdit also exhibits substantial improvements in Fluency and Coherence. For\ninstance, on GPT2-XL, AlphaEdit achieves an 18.33% improvement over the strongest baseline.\nWhile other methods often degrade text generation quality to complete the sequential editing task,\nAlphaEdit preserves both the knowledge and the ability to generate coherent and fluent text."}, {"title": "GENERAL CAPABILITY TESTS (RQ2)", "content": "To further evaluate the intrinsic knowledge of post-edited LLMs, we perform General Capability\nTests using six natural language tasks from the General Language Understanding Evaluation (GLUE)\nbenchmark (Wang et al., 2019). Specifically, the evaluation tasks include:"}, {"title": "HIDDEN REPRESENTATIONS ANALYSIS (RQ3)", "content": "As discussed in previous sections, current editing methods often cause post-edited LLMs to overfit\nto the updated knowledge, leading to a shift in the distribution of hidden representations. Hence,\nhere we aim to empirically verify that AlphaEdit can prevent overfitting and avoid this distributional\nshift. To validate it, we conducted the following steps: (1) We randomly select 1,000 factual prompts\nand extract the hidden representations within pre-edited LLMs. (2) Subsequently, we performed"}, {"title": "PERFORMANCE IMPROVEMENTS OF BASELINE METHODS (RQ4)", "content": "We conclude by evaluating whether integrating AlphaEdit's projection strategy can comprehensively\nenhance current editing methods. To achieve this, we add one line of code from AlphaEdit (the code\nfor projection) to baselines and measure their performance before and after the addition. Following\nprevious works (Meng et al., 2023; Gu et al., 2024), we analyze (1) the average performance across\nall editing samples, (2) the performance on editing samples involving specific semantics and (3) the\ngeneral capability of post-edited LLMs. Results are shown in Figure 6, 7 (a), and 7 (b), respectively.\nDetailed experimental settings can be found in Appendix C.4. The results show that:\n\u2022 Obs 7: AlphaEdit seamlessly integrates with other model editing methods, significantly\nboosting their overall performance. Specifically, in terms of editing capability, the optimized\nbaseline methods show an average improvement of 28.24%, while the general capability improves\nby 42.65%. These results underscore the substantial potential and broad applicability of the\nnull-space projection approach in enhancing model editing approaches."}, {"title": "RELATED WORK", "content": "Parameter-modifying Model Editing. This approach typically employs meta-learning or locating-\nthen-editing strategies (Ma et al., 2024; Gu et al., 2024; Zhang et al., 2024b) to conduct editing.\nMeta-learning, as implemented by KE (Cao et al., 2021) and MEND (Mitchell et al., 2022a), involves"}, {"title": "CONCLUSION", "content": "In this work, we introduced AlphaEdit, a novel model editing method to address a critical challenge\nin current approaches \u2014 the trade-off between knowledge update and preservation \u2014 with only a\nsingle line of code. Specifically, AlphaEdit minimizes disruption to the preserved knowledge by\nprojecting parameter perturbations onto the null space of its key matrices. It then removes the output\nerror related to it from the current objective, allowing the model to focus solely on knowledge update\nwithout trade-off. Extensive experiments on multiple base LLMs, including LLaMA3, GPT-2 XL,\nand GPT-J, demonstrate that AlphaEdit significantly enhances the performance of existing model\nediting methods, delivering an average improvement of 36.4% in editing capabilities."}, {"title": "ETHICS STATEMENT", "content": "Our AlphaEdit method significantly enhances the performance of sequential model editing, making\nit invaluable for updating and managing knowledge in real-world applications. While the ability\nto directly modify stored knowledge introduces potential risks, such as the introduction of false\nor harmful information, we strongly urge researchers to implement strict validation and oversight\nto ensure the ethical use of these techniques. Nevertheless, the original goal of model editing is\npositive, aiming to facilitate efficient updates of large models in the future. Therefore, we encourage\nresearchers to leverage this technology responsibly and with care."}, {"title": "REPRODUCIBILITY", "content": "To ensure the reproducibility of our findings, detailed implementation instructions for AlphaEdit\ncan be found in Appendix A. Additionally, the source code is publicly available at the following\nURL: https://github.com/jianghoucheng/AlphaEdit. These measures are intended\nto facilitate the verification and replication of our results by other researchers in the field."}, {"title": "LIMITATIONS & FUTURE DISCUSSION", "content": "While we acknowledge the effectiveness of our method, we also recognize its limitations. Concretely,\nour method has been tested exclusively within the locating-and-editing paradigm, but we have\nnot extended it to other frameworks, such as parameter-preserving methods. Additionally, our\nexperimental results indicate that in cases where the number of edits is very small, baselines perform\nsufficiently well (i.e., causing minimal degradation to the model). As a result, AlphaEdit's advantages\nare less pronounced in these scenarios. Moving forward, future research could focus on extending\nAlphaEdit to a broader range of editing paradigms and exploring its potential for enhancing single-edit\nperformance. These directions offer promising avenues for improving both the generality and impact\nof our approach. Furthermore, we plan to extract the null space for \u201cdifficult samples\" (Hu et al.,\n2024) utilizing techniques such as explainability (Fang et al., 2023) and anomaly detection Gao et al.\n(2024) to optimize the knowledge updating."}, {"title": "VISUALIZING THE ZSRE AND COUNTERFACT DATASETS THROUGH\nEXAMPLES", "content": "To help readers unfamiliar with model editing tasks better understand the Counterfact and ZSRE\ndatasets, we provide two examples from them in Figure 11 and 12. These examples illustrate the\ntypes of modifications and factual updates applied to the models during the editing process."}]}