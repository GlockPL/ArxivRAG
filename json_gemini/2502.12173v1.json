{"title": "nanoML for Human Activity Recognition", "authors": ["Alan T. L. Bacellar", "Mugdha P. Jadhao", "Shashank Nag", "Priscila M. V. Lima", "Felipe M. G. Fran\u00e7a", "Lizy K. John"], "abstract": "Human Activity Recognition (HAR) is critical for applications in healthcare, fitness, and IoT, but deploying accurate models on resource-constrained devices remains challenging due to high energy and memory demands. This paper demonstrates the application of Differentiable Weightless Neural Networks (DWNs) to HAR, achieving competitive accuracies of 96.34% and 96.67% while consuming only 56nJ and 104nJ per sample, with an inference time of just 5ns per sample. The DWNs were implemented and evaluated on an FPGA, showcasing their pratical feasibility for energy-efficient hardware deployment. DWNs achieve up to 926,000x energy savings and 260x memory reduction compared to state-of-the-art deep learning methods. These results position DWNs as a nano-machine learning (nanoML) model for HAR, setting a new benchmark in energy efficiency and compactness for edge and wearable devices, paving the way for ultra-efficient edge AI.", "sections": [{"title": "1 INTRODUCTION", "content": "Human activity recognition (HAR) is a pivotal area of research with applications spanning healthcare, fitness, and workplace monitoring. By enabling the automated identification of activities such as walking, running, or sitting, HAR systems have significantly enhanced our ability to monitor and improve human health and well-being. These advancements are particularly valuable in healthcare, where HAR plays a critical role in early disease detection, rehabilitation monitoring, and elder care. Furthermore, HAR facilitates the development of personalized fitness programs and ensures workplace safety by monitoring posture and movement patterns. With the rapid proliferation of digital health solutions, the demand for accurate, efficient, and scalable HAR systems has grown exponentially.\nWearable devices, such as smartwatches, fitness bands, and IoT-enabled sensors, serve as the primary platforms for HAR. These devices are equipped with sensors like accelerometers and gyroscopes, which continuously collect rich data streams about users' activities. However, the constrained hardware capabilities of wearables pose significant challenges, especially in terms of energy efficiency. As wearables are often battery-powered and expected to operate for extended periods without frequent charging, developing low-energy models for HAR becomes crucial. Energy-efficient models not only extend device battery life but also enable seamless, real-time activity recognition, ensuring their adoption in resource-constrained environments.\nSeveral recent models for HAR have demonstrated impressive accuracy [9-11, 13, 14], leveraging advancements in deep learning and other machine learning approaches. These models, however, often rely on architectures with massive computational demands, requiring millions of floating-point operations (FLOPs), or computationally expensive preprocessing steps. Unfortunately, these energy-intensive aspects are frequently overlooked or insufficiently addressed in the presentation of results, creating a disconnect between reported performance and their practical deployment on resource-constrained wearable devices. The mismatch between the energy-efficient hardware of edge devices and the computational needs of these models poses a significant barrier to their widespread adoption in real-world applications.\nRecently, Differentiable Weightless Neural Networks (DWNs) have emerged as a promising solution for edge devices [4], offering energy-efficient models. DWNs are capable of performing inference with minimal energy consumption-often measured in nanojoules (nJ)-and executing in just nanoseconds (ns). While DWNs have demonstrated significant potential in other domains, their application to human activity recognition has not yet been explored.\nIn this paper, we address the critical gap in energy-efficient HAR solutions by showcasing DWNs as a nano-machine learning approach for human activity recognition (HAR). We demonstrate their ability to achieve accurate recognition with extremely low energy consumption, deploying them on FPGA and highlighting their performance for edge devices. Additionally, we estimate the energy costs of recent state-of-the-art convolutional neural networks (CNNs) [10, 14] and Transformers [9, 13]. By comparing"}, {"title": "2 DEEP NEURAL NETWORKS MODELS FOR HUMAN ACTIVITY RECOGNITION", "content": "Deep neural networks (DNNs) have been extensively explored for human activity recognition (HAR), spannig various architectures, including multi-layer perceptrons (MLPs), Convolutional Neural Networks (CNNs), Transformers, and Hybrid Models. While DNNs have achieved high accuracy on benchmark datasets, including UCI-HAR, their practical deployment on wearable devices remains challenging due to their reliance on computationally expensive preprocessing pipelines and hardware-intensive architectures."}, {"title": "2.1 Preprocessing in Neural Network-Based HAR", "content": "Many HAR approaches rely on extensive preprocessing steps to extract high-level statistical and spectral features from raw sensor signals. Commonly used features include mean, standard deviation, energy, entropy, and correlation, alongside frequency-domain representations obtained via Fast Fourier Transform (FFT) or wavelet transforms. These preprocessing steps enhance the input data's representation for neural network models, enabling superior accuracy but at a substantial computational cost. For instance, FFT operations require O(N log N) complexity, which is resource-intensive for edge devices like FPGAs and ASICs. Similarly, the calculation of entropy and correlation involves non-linear operations that are impractical for real-time, low-power environments.\nThe UCI-HAR dataset [2, 8], a widely used benchmark, exemplifies this dependency on preprocessing. The highest reported accuracy for CNNs on UCI-HAR, 97.62%, is achieved by elaborate preprocessing pipelines [11]. While effective, such approaches are unsuitable for edge deployment due to their significant preprocessing and computational overhead."}, {"title": "2.2 State-of-the-art Models", "content": "Recent studies have demonstrated the feasibility of deploying HAR models directly on raw sensor data without preprocessing. For instance, CNNs applied to raw UCI-HAR data achieved an accuracy of 96.27% [14]. However, this approach incurs a significant computational cost, requiring 33.7 million floating-point operations (FLOPs) per inference. This substantial demand translates to high energy consumption, as quantified in the experimental section of this paper. These findings highlight the trade-off between eliminating preprocessing and managing model complexity, underscoring the need for lightweight, energy-efficient alternatives for resource-constrained environments.\nIn addition to CNNs, transformers have been explored for HAR due to their ability to model long-term dependencies in sequential data. HARMamba, a transformer-based model, achieved a state-of-the-art accuracy of 97.65% on UCI-HAR by leveraging self-attention mechanisms [13]. However, the model still relies on some preprocessing, and its large parameter count and complex operations result in significant energy and memory requirements, limiting its suitability for edge devices. Similarly, TSLANet, another transformer-based architecture, tailored for time series, achieved 96.06% accuracy [9]. Despite their strong performance, transformer models remain computationally intensive, necessitating millions of FLOPS per inference. These challenges underscore the demand for more energy-efficient architectures to meet the constraints of edge and wearable devices."}, {"title": "3 DIFFERENTIABLE WEIGHTLESS NEURAL NETWORKS (DWN)", "content": "Weightless Neural Networks (WNNs) [1] are a class of neural architectures that uses lookup tables (LUTs) as neurons instead of weighted connections and dot products used by DNNs. The expressive power of a neural network neuron is characterized by its Vapnik-Chervonenkis (VC) dimension, which quantifies the model's capacity to distinguish complex patterns. Notably, the VC dimension of a LUT scales exponentially with the number of inputs n, as $2^n$ [7], whereas, for a conventional deep neural network (DNN) neuron with n inputs, the VC dimension is limited to n + 1. For example, to accurately model a simple XOR pattern of 2 bits, a WNN requires only one LUT with 4 entries. In contrast, a DNN would need 3 neurons, resulting in 6 weights and 3 biases, totalizing 9 parameters. This stark difference highlights the efficiency of LUT-based models in representing complex patterns within a single computational unit compared to the relatively parameter-intensive approach of DNNs.\nDespite their theoretical advantages, traditional WNNs have primarily been confined to single-layer architectures and random connections of inputs to LUTs. This limitation arises from the non-differentiable nature of LUTs, which has historically posed challenges for gradient-based optimization techniques, impeding the development of multi-layer architectures.\nRecently, Differentiable Weightless Neural Networks (DWNs) [4] have been proposed to address this limitation by introducing differentiability to LUT-based architectures, thereby enabling the training of multi-layer WNNs. These networks achieve up to a 286\u00d7 reduction in energy costs and a 60\u00d7 reduction in latency compared to FINN [15], the state-of-the-art Binary Neural Network (BNN) framework, under iso-accuracy scenarios."}, {"title": "3.1 DWN Architecture and Training", "content": "DWN architecture is built entirely from LUTs, routing connections, and a final population count (popcount) operation.\nAs illustrated in Figure 1, DWNs operate on binary inputs, which are routed to form the addresses for the first layer of LUTs. Each LUT indexes trainable binary values corresponding to these addresses, producing binary outputs. These outputs serve as inputs for the next layer, propagating through the network without any intermediate arithmetic operations. The outputs from the final layer of LUTs are aggregated using a popcount operation, which calculates the total"}, {"title": "3.2 Thermometer Unary Encoding", "content": "Weightless Neural Networks (WNNs) require binary inputs, making the method of binarizing continuous sensor data critical for"}, {"title": "4 EXPERIMENTAL EVALUATION", "content": null}, {"title": "4.1 Dataset Description", "content": "The UCI Human Activity Recognition (HAR) Dataset [2] is a widely used benchmark for evaluating human activity recognition models. The dataset was collected from 30 participants aged between 19 and 48 years as they performed six basic activities: walking, walking upstairs, walking downstairs, sitting, standing, and lying down. Each participant carried a smartphone (Samsung Galaxy S II) on their waist, which recorded sensor data from a 3-axis accelerometer and a 3-axis gyroscope.\nRaw Signals. The raw sensor data consists of 128 samples per activity segment, corresponding to a window of 2.56 seconds sampled at 50 Hz. These raw signals capture the accelerometer and gyroscope readings along three spatial axes (X, Y, Z), providing a direct representation of the participants' movements.\nHand-Crafted Features. In addition to the raw signals, the dataset includes 561 hand-crafted features derived from the time and frequency domains. These features, used by many traditional models, include statistical metrics such as mean, standard deviation, skewness, and kurtosis, as well as frequency-domain features obtained via the Fast Fourier Transform (FFT). While these features enhance the representational power of the data, their extraction is computationally and energetically expensive, posing significant challenges for deployment on hardware-constrained wearable devices.\nIn this work, we deploy our model exclusively on the raw 128-sample signals, excluding the hand-crafted signals and without using any preprocessing on the signals. By eliminating the need for feature extraction, we demonstrate the feasibility of achieving accurate human activity recognition while adhering to the strict energy constraints of real-world wearable devices.\nData Splits. The dataset is pre-divided into training and testing sets in an inter-patient fashion, where data from 70% of the participants are used for training, and the remaining 30% are reserved for testing. This ensures that the model is evaluated on entirely unseen participants, providing a robust assessment of its ability to generalize to new users."}, {"title": "4.2 Thermometer Encoding", "content": "Each of the 9 raw sensor signals in the dataset is converted to unary encoding using a 20-bit Distributive Thermometer Encoding scheme [3], as described in section 3.2."}, {"title": "4.3 Model Configurations and Training Details", "content": "To identify the optimal DWN configuration, we split the training set into a training subset (80% of the training data) and a validation subset (20%) for hyperparameter search and Neural Architecture Search (NAS). The search explored the following ranges:\n\u2022 Number of Layers: [1, 2, 3, 4]\n\u2022 LUT Size: [2, 3, 4, 5, 6, 7, 8]\n\u2022 Softmax Temperature (t): [$\\frac{1}{8}$, $\\frac{1}{4}$, $\\frac{1}{2}$, 1, 2]\nThe best-performing architecture consists of a single layer of LUT-4 with a softmax temperature of t = 3. 0.03."}, {"title": "4.3.1 Data Augmentation.", "content": "To enhance generalization, we applied a range of standard 1D signal augmentations to the training data. Each augmentation was applied with a probability of p = 0.3, including:\n\u2022 Time Shift: Randomly shifts signals along the time axis by up to 10 steps.\n\u2022 Scaling: Multiplies signals by a random scaling factor uniformly sampled from [0.9, 1.1].\n\u2022 Jitter: Adds Gaussian noise with a standard deviation of 0.05 to simulate signal variability.\n\u2022 Time Masking: Masks a random section of the signal (up to 10 time steps) by setting it to zero.\n\u2022 Axis Flip: Randomly inverts one or more signal axes.\n\u2022 Rotation: Applies a small rotation (up to 10\u00b0) to the first three axes, simulating spatial transformations.\n\u2022 Low-Pass Filtering: Smoothens the signal using a low-pass Butterworth filter with a cutoff frequency of 20 Hz."}, {"title": "4.3.2 Training Procedure.", "content": "The DWN was trained using the Adam optimizer with the following settings:\n\u2022 Batch Size: 100\n\u2022 Learning Rate: 0.01, decayed by a factor of 0.1 every 14 epochs.\n\u2022 Total Training Epochs: 32\nWe trained two DWN models for evaluation: one with 10,000 LUTs and another with 20,000 LUTs. The training process was conducted using the full training set, and the final models were obtained after completing all 32 epochs. This ensures the model fully leverages the available training data to achieve optimal performance."}, {"title": "4.4 FPGA Board Deployment", "content": "We deployed the DWN models on the Xilinx XC7Z020CLG400 FPGA, operating in out-of-context mode. This configuration allows us to isolate and demonstrate the model's computational capabilities independently of specific data transfer constraints. We write SystemVerilog RTL codes for the design using mako templating scripts [5] based on the hardware architecture proposed by the authors of DWN [4]. The design is synthesized on the target FPGA using the Xilinx Vivado 2022.1 tool, with a target clock of 200 MHz."}, {"title": "4.5 Energy Estimation for Other Models", "content": "To compare DWN's energy efficiency with other models, we estimated the energy consumption of prior work based on the FLOP counts reported in their respective papers. We consider Verilog-based RTL designs for individual floating-point operation units and synthesize these on the same target Xilinx XC7Z020CLG400 FPGA with Xilinx Vivado 2022.1 to report vectorless power estimation for a 12.5% switching activity. With this approach, the energy per floating-point operation (FLOP) on the FPGA was determined as:\n\u2022 Multiplication (FP32): 0.928nJ\n\u2022 Addition (FP32): 0.594nJ\nOn average, a FLOP in neural network architectures involves roughly equal proportions of multiplications and additions, as a DNN neuron with n inputs performs n multiplications and n additions. Using this assumption, we estimated the energy per FLOP as the average of the two operations: 0.761nJ.\nThe total energy consumption of other models was calculated by multiplying the reported FLOP counts from their respective papers with this estimated energy per FLOP. It is important to note that we do not know whether the reported FLOP counts include only the model computations or also account for any preprocessing steps required for those architectures. If preprocessing FLOPs are excluded, it puts these models at an advantage over DWNs in our comparison."}, {"title": "4.6 Results", "content": "The application of Differentiable Weightless Neural Networks (DWNs) to Human Activity Recognition (HAR) underscores their unparalleled energy efficiency and suitability for edge deployment compared to state-of-the-art methods.\nAccuracy and Energy Efficiency. The DWN models achieve accuracies of 96.34% and 96.67%, closing the gap with the state-of-the-art HAR methods while consuming just 56nJ and 104nJ per sample. These energy consumption levels represent a dramatic 77,000x to 926,000x reduction compared to other models, which require between 8mJ and 52mJ per inference.\nModel Size and Compactness. The DWN models are significantly smaller than traditional state-of-the-art solutions. With sizes of 19.5KiB and 39.1KiB, they achieve a 33x to 260x reduction compared to models such as CNN and HARMamba, which range from 1.3MiB to 5.1MiB. This compactness, combined with their hardware-friendly design, supports their deployment on resource-constrained devices.\nHardware Performance. Unlike traditional neural networks, DWNs operate without any floating-point operations (FLOPs). Instead, they rely entirely on LUTs, routing, and a final population count (popcount) operation, which drastically reduces computation overhead. The DWN models perform one inference per clock cycle, resulting in a total processing time of 5ns per sample on the Xilinx XC7Z020CLG400 FPGA, running at 199MHz. This fully pipelined design ensures consistently low inference times, further emphasizing their potential for real-time HAR applications."}, {"title": "5 CONCLUSION AND FUTURE WORK", "content": "This study demonstrates that Differentiable Weightless Neural Networks (DWNs) embody the principles of nano-machine learning (nanoML), achieving unprecedented levels of energy efficiency and compactness in Human Activity Recognition (HAR). DWNs deliver competitive accuracies of 96.34% and 96.67% while consuming just 56nJ and 104nJ per sample, setting a new benchmark for energy-efficient HAR systems.\nIn comparison to state-of-the-art models, DWNs achieve up to 926,000x energy savings and a 260x reduction in memory size, while maintaining low latency with a processing time of 5ns per sample. Furthermore, DWNs can be directly converted into logic gates [4] and implemented as custom ASICs, making them ready for immediate integration into wearable devices.\nFuture work will investigate the extension of DWNs to multimodal sensor data and explore their scalability for more complex HAR scenarios. Additionally, efforts will focus on designing custom ASICs for DWNs to further enhance their efficiency in wearable applications, optimizing DWNs for diverse hardware platforms, and expanding their applications beyond HAR."}]}