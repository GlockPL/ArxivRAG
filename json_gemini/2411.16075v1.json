{"title": "The brain versus Al: World-model-based versatile circuit computation underlying diverse functions in the neocortex and cerebellum", "authors": ["Shogo Ohmae", "Keiko Ohmae"], "abstract": "Al's significant recent advances using general-purpose circuit computations offer a potential window into how the neocortex and cerebellum of the brain are able to achieve a diverse range of functions across sensory, cognitive, and motor domains, despite their uniform circuit structures. However, comparing the brain and Al is challenging unless clear similarities exist, and past reviews have been limited to comparison of brain-inspired vision Al and the visual neocortex. Here, to enable comparisons across diverse functional domains, we subdivide circuit computation into three elements circuit structure, input/outputs, and the learning algorithm - and evaluate the similarities for each element. With this novel approach, we identify wide-ranging similarities and convergent evolution in the brain and Al, providing new insights into key concepts in neuroscience. Furthermore, inspired by processing mechanisms of Al, we propose a new theory that integrates established neuroscience theories, particularly the theories of internal models and the mirror neuron system. Both the neocortex and cerebellum predict future world events from past information and learn from prediction errors, thereby acquiring models of the world. These models enable three core processes: (1) Prediction \u2014 generating future information, (2) Understanding \u2014 interpreting the external world via compressed and abstracted sensory information, and (3) Generation - repurposing the future-information generation mechanism to produce other types of outputs. The universal application of these processes underlies the ability of the neocortex and cerebellum to accomplish diverse functions with uniform circuits. Our systematic approach, insights, and theory promise groundbreaking advances in understanding the brain.", "sections": [{"title": "Introduction", "content": "Al development and brain research have a long history of mutual influence. In light of recent advancements in Al, there is a high expectation that studying the brain with reference to brain-like Al will lead to new theories and concepts in neuroscience 1-10. In the past, Als generally had a single function, but since 2018, general-purpose Als have emerged that are capable of performing multiple functions with a single circuit. By comparing the brain with these general-purpose Als, we may be able to unravel the enduring mystery of how the neocortex and cerebellum are each able to execute a wide variety of functions across multiple domains, despite their relatively uniform circuit structures and local-circuit computations 2,11-13. To address the mystery of the brain's universal local-circuit level computations (hereafter, circuit computations), a comprehensive comparison of the brain and Al across various functional domains is essential. Such comparison is straightforward when there is a high degree of similarity in most aspects of the circuit computations; however, when there is only partial similarity, it is challenging to assess which aspects of the circuit computations are similar and to what extent, and to avoid merely listing fragmentary similarities. In fact, previous reviews comparing the brain and Al have been heavily biased toward visual neocortex and brain-inspired vision Al because of their high degree of similarity, while failing to address representative neuroscience theories or historically successful Al circuits in other functional domains 1,3-7,14. A comparison that focuses solely on visual processing is insufficient to satisfy the needs of Al experts seeking new insights from the brain, neuroscientists looking for novel perspectives from Al, or, more broadly, anyone curious about the secrets of human intelligence.\nTo provide a comprehensive and structured comparison, we decided to break down the circuit-computation mechanisms into three elements and analyze the similarities between the brain and Al for each element. (i) Circuit structure: In the brain, specific constraints on circuit architectures are imposed by the particular neuronal subtypes, the anatomical neuronal connections, and the learning sites at the connections. By contrast, the design of Al circuits is flexible and can be adjusted according to the task demands. In both cases, the circuit structure is a critical factor that determines the upper limit of the capacity of the circuit computation. For example, the structure of an Al circuit determines its limits, which cannot be surpassed even with large-scale learning 15,16. (ii) Input/output signals: Information processing in the brain is fundamentally a transformation from input to output, so the input/output signals correspond one-to-one to the function of the circuit. (iii) Circuit learning: Even if the input/output characteristics of circuits are similar, different learning methods (e.g., supervised vs. unsupervised learning) can result in different intermediate processes from one circuit to the next 17-23. By breaking down the circuit computation into these three elements and evaluating the similarities for each, we are able to comprehensively"}, {"title": "1. Sensory Information Processing", "content": "The ultimate goal of sensory information processing is to accurately infer the state of the external world from limited sensory signals through internal \u201cworld models\" in the neocortex 12,24-35 and in the cerebellum 15,36-43, which are acquired through sensory experience. In vision, for example, the goal is to reconstruct 3D models of objects and space from 2D retinal images 44,45. In this section, we compare sensory brain circuits with Al circuits to deepen our understanding of circuit computation in sensory information processing in the brain. We start with object recognition in vision, the field where the theoretical understanding of the brain and Al circuits have most closely influenced each other."}, {"title": "1.1 Visual Processing", "content": "Deep-layered autoencoders as a circuit computation theory of the visual neocortex\nThe visual recognition circuit, located in the cerebral visual neocortex, is primarily trained through unsupervised learning 4,14,21,46-48. Generally, the brain must learn to perform appropriate information processing without explicit instruction on the correct processing or outputs 14,48. In the visual system, for instance, humans learn to distinguish animals such as dogs from other objects during childhood. However, during this learning process, our visual system is not explicitly taught the correct boundary between dogs and other visual objects, nor the correct instruction for dog recognition (i.e., the correct label). Learning under such conditions is known as unsupervised learning, and the sensory neocortices, including the visual neocortex, are considered representative unsupervised-learning circuits 21,46. According to this learning theory of the neocortex, a representative strategy for learning without explicit instruction is unsupervised \u201cautoencoder\u201d learning, where the original input image serves as the target information to learn 14,21. The circuit is trained such that the input neurons receive a 2D visual image and the downstream restoration neurons reconstruct the original input. Because the output needs to encode the input, this type of circuit is termed an \u201cautoencoder\u201d in machine learning. When there are fewer neurons in the middle layer than in the input neurons, information needs to be compressed into a lower-dimensional space, resulting in the generation of compressed visual information as a secondary output.\nThe idea that the visual neocortex can function as an autoencoder has a long history 21. In fact, when an autoencoder circuit of an artificial neural network (ANN) was trained with numerous natural images, the compressed-representation neurons acquired receptive fields similar to those of the primary visual neocortex. That is, the optimal visual inputs to activate the neurons were local line/stripe patterns, described by Gabor functions, that detect object contours and edges. Interestingly, the compression in those neurons reflects the features of natural images; when trained with artificial images with non-natural features, the receptive fields of the neurons adapted. This observation aligns with the finding that cats raised in an environment with vertical stripes develop visual neurons with receptive fields that predominantly prefer vertical lines/stripes 49. This similarity suggests that the receptive fields in primary visual neocortex develop through a process of feature extraction from natural images analogous to an autoencoder.\nLater, to achieve more advanced information processing to extract more abstract visual features, researchers attempted to create a deep-layered (hierarchical) autoencoder by stacking the data-compression functions of autoencoders. The entire block shown in Figure 1a is referred to here as a layer and is stacked multiple times such that the signal of the compressed-representation neurons is the output to the next layer. Initially, training all layers simultaneously by backpropagation proved challenging. However, in 2006, Hinton and colleagues succeeded in training a deep-layered autoencoder using a method called greedy layer-wise training, in which the deep autoencoder was trained one layer at a time, starting from the lowest layer (that received the raw image input) 50,51. This learning procedure is analogous to the critical period in the visual neocortices (during which the lower visual neocortices largely determine the characteristics of information processing at an early stage in life) 52.\nFurthermore, in 2012, a group of researchers at Google successfully enabled neurons at the highest layer of a deep autoencoder to acquire specific responses to and recognition of human and cat faces. This was achieved by implementing tolerance sub-layers (more concretely, a pooling sub-layer and a contrast normalization sub-layer) in each layer, as first proposed in the \u201cneocognitron\u201d network 53, and by training the circuit through unsupervised autoencoder learning with large amounts of image data (Figure 1c) 54. The optimal stimulus for the cat-recognizing neuron, called \u201cGoogle's cat,\u201d gained significant attention because the Al circuit autonomously acquired the concept of a cat without being provided any labeled information about cats during training. This result demonstrated the remarkable potential of the deep autoencoder to autonomously learn not only feature extraction of visual information but also object recognition and classification."}, {"title": "Shift of image-recognition Al from deep-layered autoencoders to convolutional neural networks", "content": "In 2012, a pivotal event occurred at a competition for image-recognition Al. While the mainstream methods for image recognition at the time (methods without neural networks) were unable to surpass the 75% correct rate barrier, AlexNet, created by the Hinton group using convolutional neural network (CNN) architecture, achieved an 84% correct rate and won by a wide margin (Supplementary Fig. 1). After that, the mainstream of object recognition Al shifted to CNNs, and AlexNet became the trigger for the subsequent widespread popularity of deep-layered neural networks, known as deep learning 55-57.\nAlexNet and subsequent CNNs have a structure quite similar to deep autoencoders, with repeated layers of receptive-field processing and tolerance sub-layers, but there are two major differences. The first difference is that CNNs employ shared receptive-field processing across different positions in the image (see Figure 1d-f). This change significantly reduced the number of parameters to be trained and, for the first time, enabled easy training of deep layers. However, not sharing receptive-field processing is more biologically plausible and can yield greater invariance and robustness 54,58. The second difference is that CNNs rely solely on supervised learning with correct labels (made by humans) and include no unsupervised learning. Since the goal of Al object recognition is to classify/label the input image (e.g., \u201cThis image is a dog.\"), deep autoencoders that undergo unsupervised pre-training require an additional output layer for labeling to be added to the last layer that is trained by supervised learning (fine-tuning), so that the circuit can generate the label output 59,60. By contrast, CNNs do not require pre-training and complete their training with supervised learning alone. While this was seen as an advantage of CNNs, it diverges from the learning process in the visual system of the brain, which progresses almost entirely without correct labels 14,48\nThe information processing in AlexNet and deep autoencoders contains similarities and differences (Figure 1d) 61-64. In both, neurons in the lowest layer acquire receptive fields for line segments or local stripes, while neurons in the highest layer acquire specific responses to higher-level features (Figures 1b-c and e-f). However, a major difference is that in the highest convolution layer of AlexNet, neurons emerged that recognized cat faces, which were included in the labeled training data (i.e., in the instruction signals), whereas neurons that specifically recognized human faces\u2014which were not included in the instruction signals\u2014did not appear, unlike in the deep autoencoder 61,62. This lack of generalization in AlexNet aligns with the observation that supervised learning circuits tend to develop information processing that is specialized to the instruction signals and ignore information not included in the instruction signals 17-20. Furthermore, the emergence of human-face-detecting neurons in CNNs trained with unsupervised learning suggests that the difference in information processing is due to the difference in learning methods rather than differences in the circuit architecture (for intermediate stages of information processing, refer to Supplementary Fig. 2) 65.\""}, {"title": "Direct comparison of object-recognition processing by the brain and Al", "content": "Inspired by advances in object-recognition Al, Yanis and colleagues conducted the first direct quantitative comparison between information processing in the brain and in Al 1,66-68. They presented the same eight-category images to both a CNN trained with supervised learning and to monkeys, then compared the response signals in the Al and in visual neocortices. The information in higher visual neocortex was accurately reproduced by a linear combination of signals from the higher layers of the CNN. This suggests that the deep-layered structures of the CNN and visual neocortices produce a similar flow of information processing.\nSubsequently, a CNN trained in object recognition through unsupervised learning was compared with the visual neocortex, and similarities were observed between information processing in the lower layers of the CNN and lower visual neocortex, as well as in the higher layers of the CNN and higher visual neocortex 48,69. Interestingly, when comparing the recognition accuracy of different learning methods, the highest accuracy was achieved by supervised learning and the second highest accuracy was achieved by contrastive learning, an unsupervised-learning method, whereas an autoencoder produced considerably lower accuracy. In contrastive learning, neuronal activity for the current input image is compared with the neuronal activities for thousands of past input images and the synaptic weights are updated such that neural representations (i.e., neural response patterns) for the same object become more similar and neural representations for different objects become more different. This type of learning has gained popularity since 2020. To perform contrastive learning without human-made labels, several approaches have been proposed (For example, one method uses cluster analysis to regard the cluster which the neural response to the current image belongs to as the cluster of responses to the same object. Another method regards the responses to derivative images of the current image, such as inverted or grayscale images, as the responses to the same object). While the power of contrastive learning is impressive, comparing current activity with the responses to thousands of past images seems to lack physiologically feasibility, and there is no evidence yet that such learning is performed in the brain. On the other hand, the lower accuracy of the autoencoder was likely due to their use of a pre-2006 training method in which all layers are trained at once. We await future research on a direct comparison between neural activity in the visual neocortex and high-performing, biologically plausible Al circuits trained with unsupervised learning, such as unsupervised autoencoders. (The closest reported similarity to unsupervised learning Al is in auditory cortex and is discussed in section 1.2.)"}, {"title": "Evolution of circuit computation theory of the visual neocortex: Extension of autoencoders to prediction-error-learning RNNs", "content": "As we have seen, deep autoencoder circuits trained through unsupervised learning have evolved from theories of brain circuits. When trained with natural images, the autoencoders develop Gabor-filter-like neurons in lower layers, and high-level feature-detection neurons in higher layers, just like in the brain. In this sense, autoencoders have succeeded in theoretically reproducing certain aspects of the circuit computations of the visual neocortex. However, deep autoencoders differ from the brain in several critical points. First, deep autoencoders are feedforward circuits, whereas the brain is characterized by abundant complex recurrent connections 70-73. Second, because of this feedforward structure, autoencoders cannot integrate past and current information, making them incapable of processing dynamic or sequential visual images, such as videos, thereby differing from neocortical processing 15,71,74-84 (3D-CNN and vision transformer circuits will be discussed later in this section). To address this mismatch, adding recurrent connections to an autoencoder to form a recurrent neural network (RNN) circuit, which allows for the integration of information over time, would provide a more accurate theoretical replication of brain circuitry. For the input-output signals and learning of the RNN, we propose \u201cprediction-error learning\u201d\u2014where the RNN predicts future inputs on the basis of past inputs and learns from the prediction errors\u2014for the following reasons. First, prediction-error learning allows for numerous cycles of unsupervised learning, making it a promising learning method for the brain, which requires extensive unsupervised learning 1,20,85-87. Second, prediction-error learning facilitates the separation of background and foreground (objects) and the learning of physical laws, which are difficult for autoencoders lacking temporal information 20,88-90. Experiencing changes in the 2D projections of objects and their motion over time is a critical signal for learning about 3D object structure and physical laws 47,72,91-101. We therefore propose that an \u201cRNN circuit that predicts future input signals on the basis of past input signals and learns from prediction errors\" (hereinafter, a \u201cprediction-error-learning RNN\u201d) is a more biologically plausible theoretical circuit of the neocortex than a deep autoencoder.\nA circuit that fits the criteria of the \"prediction-error-learning RNN\" has already been proposed as a theoretical circuit for the neocortex: the predictive coding circuit (Figure 2a) 29,102-104. Predictive coding was originally proposed to explain receptive field properties that could not be explained by classical theories of the visual neocortex. A growing body of experimental evidence supports this theory 8,103,105. The theory has also been generalized to other sensory areas, including the somatosensory and auditory neocortices 8,106-110. The predictive coding circuit resembles the autoencoder circuit but differs in three major points (compare Figures 1a and 2a). First, the autoencoder circuit receives input only once for the current visual image, whereas the predictive coding circuit receives input continuously in a sequential manner. Second, the predictive coding circuit includes a loop pathway with a delay at the compressed-prediction neuron, enabling temporal integration of past compressed predictions with the new input. Third, instead of directly transmitting input information to the compressed-prediction neurons, the predictive coding circuit calculates the difference between the prediction and the input and transmits only the prediction error (hence the name \u201cpredictive coding\"). In the autoencoder, the error information is computed solely for learning (Figure 1a, green), whereas in the predictive coding circuit, the error is generated within the main circuit and directly contributes to the output. Fourth, while the autoencoder uses the current input as the correct information to reconstruct, the predictive coding circuit uses the future input as the correct information for prediction-error learning. When the predictive coding circuit processes a static image, the past and new inputs are identical, and the input information is compressed by the compressed-prediction neurons and reconstructed by the prediction neurons, which is equivalent to the autoencoder process. In other words, the predictive coding circuit can be interpreted as a time-oriented extension of the autoencoder to an RNN.\nFurthermore, predictive coding circuits can be stacked to form deep-layered structure to incorporate the reciprocal connections between the lower and higher visual neocortices 12,103,104,111. In a deep-layered predictive coding circuit, each layer sends the error signal of the prediction-error neurons to the next higher layer (Figure 2b) and receives the compressed prediction signal from that higher layer, which serves as an additional input signal to the compressed-prediction neurons (see also Figure 2c). In other words, a signal that was not predicted in the lower layer is transmitted to the higher layer to become the new prediction target (an unpredicted \"newsworthy\" signal; Friston), and the higher-level prediction signal is fed back as a top-down signal to the lower layer. Moreover, the \"free energy principle\" theory, which abstractly and mathematically formalizes the prediction errors in predictive coding circuits as \"entropy,\" suggests that the dynamics of the world/environment, which usually has deep-layered structure, can be modeled by mapping/embedding the dynamics onto a deep predictive coding circuit 12. The deep predictive coding circuit generates prediction errors at each layer and prediction errors are consumed at each layer for learning, thus it can be viewed as a deep-layered prediction-error-learning RNN.\""}, {"title": "Hints on how the brain achieves synaptic updates equivalent to backpropagation", "content": "Circuit architectures that locally generate and locally consume error signals, such as deep autoencoders and predictive coding circuits, could be the key to solving the problem that it is not biologically plausible to assume backpropagation in the brain. The brain achieves hierarchical/deep-layered visual processing in ways that are comparable to Al, but it remains largely unknown how the updated synaptic weights in the brain are linked to improvements in the final output (i.e., how the brain accomplishes the credit-assignment problem). During supervised learning in deep-layered Al circuits such as CNNs, the error information generated in the final layer is necessary for synaptic updates in the first layer. Backpropagation solves this problem in a mathematically elegant way, but no equivalent signal for backpropagation has been confirmed to exist in the brain (i.e., the top-down signals from higher layers to lower layers in the brain match backpropagation only in the signal direction: the information conveyed is quite different) 4. In deep autoencoders or predictive coding circuits, however, the error signal generated by each layer is consumed only within the same layer, so there is no need to carry the error signal far across layers. Transporting error signals over long distances can cause issues like the gradient exploding or vanishing, where the backpropagated signal can become too large or approach zero, often leading to learning failures. Assuming that deep autoencoders and the predictive coding circuits are plausible theoretical circuits of the neocortex, we can infer that the brain\u2014which cannot afford to fail to learn-avoids such learning problems by generating error signals locally and consuming them locally."}, {"title": "Prediction-error-learning RNNs among video processing Al: PredNet, CNN-RNN", "content": "Given that prediction-error-learning RNN circuits are superior to autoencoders in processing dynamic signals (such as videos, as opposed to still images), we here focus on Al circuits designed for video analysis in our comparison of Al and the brain. Notably, an Al circuit named the Deep Predictive Coding Network (PredNet) was inspired by deep-layered predictive coding theory in the neocortex (Figure 2c) 70,72. PredNet is a practical implementation of a deep predictive coding circuit, but it differs from neocortical circuitry in its use of LSTM for the RNN component because the detailed interconnection patterns between different cell types in the neocortex are still largely unknown. Although LSTM is an excellent RNN circuit commonly used in Al to achieve integration of temporally distant past and current information and efficient backpropagation, it is not designed to replicate the neocortical circuit structure or the attention mechanism (discussed later). On the other hand, in terms of input/output signals and the learning process, PredNet faithfully implements deep predictive coding and adheres to neocortical theory by predicting future inputs from past inputs and learning from the prediction errors. PredNet achieved high prediction accuracy for the next frame of rotating objects in a 3D environment (Figure 2d). Furthermore, PredNet developed internal representations that efficiently coded object parameters (e.g., identity, view, rotation speed) in the intermediate layer. This demonstrates that PredNet, aligned with the circuit theory of the visual neocortex, replicates certain functional aspects of the neocortex that autoencoders could not.\nIn addition to PredNet, CNN-RNNs form another type of Al circuit within the \"prediction-error-learning RNN\" category. Here, we particularly highlight a CNN-RNN that has succeeded in acquiring models of video game worlds through the processing of game video information (Figure 2e,f) 112,113 . Traditional Al circuits for playing video games did not separate the video processing unit from the controller unit (i.e., the action selection unit to select the button to press), and the video processing unit was trained via backpropagation of the reinforcement learning signal from the controller unit. This approach produced slow learning and limited the trainable size of circuits (e.g., DQN, see 2.2). Therefore, instead, Ha and Schmidhuber trained a large-scale CNN-RNN as the video processing unit\u2014independent of the controller unit\u2014using unsupervised prediction-error learning, in which the CNN-RNN predicted the future frame from past frames (Schmidhuber is a proponent of LSTM). Interestingly, this CNN-RNN acquired \"world models\" of the games, including information on game events and event transitions. The combination of CNN and RNN was chosen because the CNN first compresses the visual information, making it efficient for the subsequent RNN to integrate information in the time direction. The world models acquired by this circuit proved so effective and powerful that the CNN-RNN was able to provide virtual games within the world models and thus improve the capabilities of the controller unit without any actual game inputs (below)."}, {"title": "1.2 Cognitive Processing in Sensory Systems", "content": "Sensory information processing includes highly sophisticated cognitive processing, such as human-characteristic language processing. Since voice recognition is commonly found in other animals rather than being unique to humans, our particular focus here is on sensory language processing of sentence comprehension after word recognition."}, {"title": "A theory of circuit computation in the cerebellum for language processing: A three-layer RNN circuit with prediction-error learning for next-word prediction", "content": "While the cerebellum is often considered a center for motor control, it is also responsible for a wide range of cognitive functions, including language processing 116-123. The right lateral cerebellum (Crus I/II) is involved in two important non-motor language-processing functions: predicting the next word in a sentence 124-127 and grammatical processing, particularly syntactic processing 121,128-131.\nIn cerebellar language processing, the three elements of circuit computation (circuit structure, input/output, and learning) are considered as follows: Regarding the circuit structure, the details of the uniform cytoarchitecture of the cerebellum are well studied 2,123,132-134. Although the cerebellum is often described as a typical feedforward circuit, recent studies have revealed that there are abundant feedback projections from the cerebellar nucleus neurons (the output neurons; Figure 3a) to the granule cells (the input neurons), including both direct projections 133,135-137 and indirect projections through the pontine or brain stem 138-141. These feedback projections are essential for the predictive functions of the cerebellum 137,142,143. Regarding the input and output signals of the circuit, historical cerebellar research has revealed that the function of the cerebellum is to create internal brain models of the world and predict the future (the widely-accepted \u201ccerebellar internal model\u201d theory discussed below) 15,36-43. Extending this to language processing, it has been proposed that next-word prediction is achieved by the cerebellum receiving sequential word inputs and generating a prediction (output) of the next word 124,125,144. Regarding learning, it has been proposed that the inferior olive, which sends signals essential for cerebellar learning, compares the next-word prediction (the output of the cerebellum) with the actual next word to calculate the prediction error, which is then used to update synaptic weights to improve future predictions 122, 144\nUsing these elements as the basis, and with the aim of reproducing cerebellar language functions, we created an artificial neural network that imitates the cerebellar circuit structure, including the connection patterns among different cell types in the cerebellum. We connected the three layers of input, Purkinje, and output neurons with feedforward and feedback pathways according to recent knowledge (outlined above) to create a three-layered RNN circuit (Figure 3a). Interestingly, when the cerebellar ANN was trained to perform next-word prediction, not only did the output of the circuit acquire the ability to predict the next word in a sentence (Figure 3b, red arrow), but the intermediate layer of the word-prediction circuit (Purkinje cells) spontaneously acquired another cerebellar language function, syntactic processing (Figure 3b, blue) 145. To the best of our knowledge, this is the first brain-imitating artificial circuit that aligns with neuroscientific findings for all three of circuit structure, input/output, and learning and that reproduces sophisticated human-characteristic cognitive functions. This result demonstrates that the two cerebellar language functions (next-word prediction and syntactic processing) can be viewed as a unified computation of a single circuit. Given the uniform cytoarchitecture of cerebellum, this result also indicates the possibility of unified comprehension of two distinctive cerebellar functions of predicting future events (the function of the cerebellar internal model) and extracting temporal features from sequential events (sequence processing). In other words, by viewing the cerebellum as a three-layer RNN circuit that predicts future words from past words and learns via prediction errors, we provided a unified explanation of the two cerebellar language functions as well as insights into the mechanisms underlying universal cerebellar circuit computation.\nWhile prediction-error learning in the cerebellum has traditionally been called \u201csupervised learning\u201d in the neuroscience field, here we follow recent terminology and refer to prediction-error learning in general (including that of the cerebellum) as \u201cunsupervised learning.\u201d (Supervised learning refers to learning in which the correct signal explicitly includes the information that the circuit should learn.)"}, {"title": "Circuit computation in the neocortex for language processing: A deep-layered RNN circuit that predicts the next word and learns through the prediction error", "content": "Compared with the cerebellum, neocortical circuits contain a wider variety of cell types and have complex multiple loops connecting these cell types 15,74-78,80,81,83,84. Given that the same circuit architecture in the neocortex is used for various types of information processing 11,15, the neocortical language circuitry is similar in structure to the circuitry in the visual neocortices. Like visual processing, language processing occurs hierarchically in the neocortex 146-152 and can be summarized as hierarchical processing by deep-layered RNNs with complex recurrent connections. With regard to learning and how the brain acquires language, the innate theory of language (in which basic language functions are innate and genetic) has historically been favored 153-155, but recent evidence has challenged this theory, including simulation experiments demonstrating that language functions that had been assumed impossible to learn can in fact be acquired through biological postnatal experiences and unsupervised learning 156,157. In this way, although room for controversy remains over the extent of innate language knowledge in the brain prior to learning, there is abundant evidence of similarities in information processing between the neocortex after language acquisition and Al trained on word prediction through prediction-error learning. In 2021, a functional MRI study reported that among recent high-performance Als, the one with signals most similar to those of the neocortical language area was a prediction-error-learning Al 158. In 2022, a human electrocorticography study demonstrated that that the signals in the broad neocortical language area contain both word-prediction and prediction-error information 159. Additionally, electroencephalographic (EEG) and magnetoencephalographic (MEG) recordings indicated that language comprehension is supported by hierarchical predictions like linguistic Al 160. In 2023, another human electrocorticography study found that the signals in high-order auditory neocortex (in the superior temporal gyrus) more closely resemble the signals of prediction-error-learning Al than those of supervised-learning Al 150. In 2024, human single-neuron recordings revealed that word prediction contributes to word representation by neurons in the prefrontal cortex 161. Taken together, these findings strongly support the view that, after language acquisition, language processing in the neocortex is conducted by a deep-layered RNN circuit that predicts future words from past words and learns via prediction errors."}, {"title": "The lineage of language processing Al: deep-layered RNN (GNMT), transformer circuits (BERT, GPT)", "content": "In the field of language-processing Al, artificial RNNs have been highly anticipated since the early 2010s 156,162,163. A notable example is Google Neural Machine Translation (GNMT), which was adopted by Google Translate in 2016 and dramatically improved translation accuracy over previous methods 164,165. GNMT employs a deep-layered RNN circuit that uses LSTM (Figure 4a) and consists of an encoder-decoder. However, while the deep-layered predictive coding circuit (Figure 2a-c) has an encoder-decoder in each layer, GNMT has an eight-layer encoder unit followed by an eight-layer decoder unit, so the encoder-decoder combination exists only once. As a result, whereas the predictive coding circuit calculates the prediction error at each layer, GNMT makes word predictions and calculates the prediction error only in the final, 16th, layer and propagates this error signal to all layers by backpropagation. Furthermore, GNMT relies on supervised learning, where human-made translation examples are used as the correct targets. Thus, while GNMT is similar to the neocortex because it is a deep-layered RNN, it differs in that prediction errors are generated only in the final layer and propagated to all layers by backpropagation, and in that it is trained through supervised learning. Nevertheless, the GNMT encoder can convert a sentence in one language into a semantic vector (the population activity of a group of neurons), and the decoder, upon receiving this vector, can generate a sentence with the same meaning in another language with near-human precision. This demonstrates that the GNMT encoder, an artificial deep-layered RNN, has the capacity to convert sentences into semantic population-coding vectors at a level close to that of humans, which was groundbreaking from the neuroscience perspective (also see seq2seq and seq2vec) 166,167.\nAfter GNMT, because of issues related to computational cost and speed (low efficiency of parallel processing with GPUs), Al language processing shifted away from the method of feeding words one by one into an RNN. Instead, the community moved toward the method of feeding an entire sentence into a feedforward circuit called a transformer 168,169. This process differs from that of the brain, which receives sequential word-by-word input. But, interestingly, the prevailing learning method subsequently also shifted from supervised learning to unsupervised prediction-error learning, similar to learning in the brain.\nThe first to demonstrate the power and versatility of unsupervised prediction-error learning in a transformer circuit was Google's BERT (bidirectional encoder representations from transformers). BERT achieved top-level or best performance in 11 language tasks 18. The pre-BERT language Als (GNMT and its successors) suffered from the problem that supervised learning is not versatile (i.e., accuracy dropped significantly outside of the trained tasks), and the cost of preparing large training datasets is substantial. BERT solved this by first conducting large-scale unsupervised learning with an encoder-decoder circuit, then discarding the decoder unit and attaching a small output layer to the remaining encoder unit (which was able to convert sentences into semantic vectors, like GNMT), and performing additional small-scale supervised learning on the output layer for new language tasks. Thus, BERT needs different output layers for different tasks. With this method, BERT achieved strong performance across various language tasks. The circuit structure of BERT is a deep-layered transformer circuit, and the main learning method is unsupervised prediction-error learning that predicts a masked word. This prediction is different from next-word prediction in that it can also utilize words that come after the masked word.\nThe power of unsupervised prediction-error learning was demonstrated even more sensationally by the GPT (generative pre-trained transformer) series, including ChatGPT (Figure 4d) 170-172. Especially since GPT-2, GPTs have been thoroughly trained in next-word prediction. When generating sentences, GPTs directly use the ability to sequentially select the word that follows the previous word sequence, learned by next-word prediction. This sentence-generation ability has allowed GPTs to solve various language tasks. (For example, in the task of scoring a product comment, when GPT is asked, \u201cOn a scale of 1 to 10, what is the positivity of this comment?\u201d, GPT can score it by sequentially selecting the most appropriate words to follow, like \u201cThis is an 8"}]}