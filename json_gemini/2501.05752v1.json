{"title": "Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models", "authors": ["Sungjae Lee", "Hyejin Park", "Jaechang Kim", "Jungseul Ok"], "abstract": "Recent advancements in large language models (LLMs) have shown remarkable potential in various complex tasks requiring multi-step reasoning methods like tree search to explore diverse reasoning paths. However, existing methods often suffer from computational inefficiency and redundancy. First, they overlook the diversity of task difficulties, leading to unnecessarily extensive searches even for easy tasks. Second, they neglect the semantics of reasoning paths, resulting in redundant exploration of semantically identical paths. To address these limitations, we propose Semantic Exploration with Adaptive Gating (SEAG), a computationally efficient method. SEAG employs an adaptive gating mechanism that dynamically decides whether to conduct a tree search, based on the confidence level of answers from a preceding simple reasoning method. Furthermore, its tree-based exploration consolidates semantically identical reasoning steps, reducing redundant explorations while maintaining or even improving accuracy. Our extensive experiments demonstrate that SEAG significantly improves accuracy by 4.3% on average while requiring only 31% of computational costs compared to existing tree search-based methods on complex reasoning benchmarks including GSM8K and ARC with diverse language models such as Llama2, Llama3, and Mistral.", "sections": [{"title": "1 Introduction", "content": "Recent advances in Large Language Models (LLMs) (Brown et al., 2020; Chowdhery et al., 2023; Team et al., 2023; Touvron et al., 2023; Achiam et al., 2023) have demonstrated potentials in a wide range of complex reasoning tasks including mathematical problem-solving (Lewkowycz et al., 2022; Wu et al., 2022; Mishra et al., 2022), knowledge application (Zhang et al., 2018; Yavuz"}, {"title": "2 Related Work", "content": "Reasoning with LLMs Eliciting the reasoning capabilities of LLMs has been a key focus of recent research, leading to various reasoning methods to improve their performance on complex, multi-step tasks. One notable approach is Chain-of-Thought (CoT) prompting (Wei et al., 2022), which encourages LLMs to generate intermediate reasoning steps. Self-consistency of CoT (CoT-SC) (Wang et al., 2023b) extends CoT by sampling multiple reasoning paths and selecting the most frequently answers, instead of relying on a single greedy decoding pass.\nTree search-based approaches, such as Tree-of-Thoughts (ToT) (Yao et al., 2023; Long, 2023) and Reasoning-via-Planning (RAP) (Hao et al., 2023), enhance reasoning by structuring the exploration of reasoning paths on trees using search algorithms such as breadth/depth-first search (BFS/DFS) and Monte Carlo Tree Search (MCTS). In addition, recent studies on MCTS-based reasoning have extended the settings involving additional training costs (Wan et al., 2024; Zhang et al., 2024a) or external feedback (Zhou et al., 2024). However, these tree search-based methods incur considerably higher computation costs compared to simpler methods such as CoT-SC.\nLinguistic semantics Measuring semantic relation is essential for reducing semantic redundancy in LLM reasoning. Traditional approaches have relied on lexical feature-based (Fernando and Stevenson, 2008; Socher et al., 2011) or embedding-based similarity metrics (Yu et al., 2014; Issa et al., 2018)."}, {"title": "3 Preliminaries", "content": "In this section, we first define our problem setting as Markov Decision Process (MDP) reasoning in Section 3.1. Section 3.2 explains Monte Carlo Tree"}, {"title": "3.1 Markov Decision Process Reasoning", "content": "Let $p_\\theta$ denote a pre-trained language model (LM) parameterized by $\\theta$, and an input sequence $x = (x_1,...,x_l_x)$, where $l_x$ represents the token lengths of the input. The model's probability of generating $x$ is expressed by $p_\\theta(x) = \\prod_{i=1}^{l_x}(x_i|x_{<i})$, where $x_{<i}$ represents the sequence of tokens preceding $x_i$. An output sequence $y = (y_1,\u2026\u2026\u2026, y_{l_y})$ is generated by autorgressively, where $l_y$ denotes the token lengths of the output. The previously generated tokens are used to predict the next token as $p_\\theta(y|x) = \\prod_{i=1}^{l_y} p_\\theta(y_i|x, y_{<i})$.\nRather than directly mapping the input $x$ to the output $y$, several reasoning methods have been developed to enhance reasoning by breaking down complex tasks into step-by-step thoughts, with each generated token $y_i$ representing an intermediate reasoning step. Detailed explanations of these methods are provided in Appendix A. Following the approach in RAP (Hao et al., 2023), we define our problem as an MDP to effectively model the reasoning task. We leverages LMs in two complementary roles: (i) a reasoning agent and (ii) a world model. This approach frames the reasoning process as an MDP, enabling iterative reasoning through planning and simulation. At each time step $t$, the state $s_t$ represents the current context, including both the input sequence and the reasoning history. In the first role, the LM acts as the reasoning agent, generating actions $a_t \\sim p_\\theta(a|s_t, m)$ based on the current state $s_t$ and a task-specific instruction $m$. Subsequently, the LM functions as a world model, predicting the next state $s_{t+1}$ based on the current state and the chosen action, i.e., $p_\\theta(S_{t+1}|s_t, a_t, m')$, where $m'$ is an additional prompt guiding the tran-"}, {"title": "3.2 Monte Carlo Tree Search (MCTS)", "content": "To enhance strategic exploration, we incorporate planning with MCTS (Coulom, 2006), which is particularly effective for decision-making in high-dimensional spaces. MCTS builds a search tree over k iterations to explore decision space through four main operators: selection, expansion, simulation, and back-propagation. At each node, which represents a state s, the standard MCTS uses UCT (Kocsis and Szepesv\u00e1ri, 2006; Auer et al., 2002) algorithm to select the optimal action $a^*$ based on Q-value as follows:\n$a^* = arg \\underset{a\u2208A(s)}{max}(Q(s,a) + w \\frac{\\sqrt{ln N(s)}}{N(s, a)})$,   (1)\nwhere N(\u00b7) denotes the total number of visits in previous iterations, A(s) is the set of possible actions at state s, and w is the constant of balancing exploration and exploitation.\nPUCT (Silver et al., 2016, 2017) provides a viable alternative to UCT by incorporating \u03c0(\u03b1|s), a predictor of the prior action distribution, into its formulation as follows:\n$a^* = arg \\underset{a\u2208A(s)}{max} (Q(s,a)+w\u03c0(\u03b1|s)\\frac{\\sqrt{N(s)}}{(sa)+1}) $(2)\nThe predictor \u03c0(\u03b1|s) can be defined as the sequence probability $p_\\theta(a|s, m)$ in the context of LLMs. A more detailed description of the operators used in MCTS can be found in Appendix C."}, {"title": "4 Method", "content": "Our method consists of adaptive gating (Section 4.1), semantic exploration (Section 4.2), and early stopping with weighted aggregation (Section 4.3), as shown in Figure 1. A detailed description of the algorithm is provided in Appendix D."}, {"title": "4.1 Adaptive Gating (AG)", "content": "AG adaptively determines when to expand the search tree based on the confidence of generated answers. Specifically, k answers are sampled using a single-path method, such as CoT, and the confidence of these answers is used to determine whether to initiate tree search. The key insight is that not all problems require the same level of complexity in reasoning.\nFirst, we generate k reasoning paths using CoT, each producing an output $y^i \\sim p_\\theta(y|x, z_{i<1}), \\forall i \u2208 [k]$, i.e., corresponding to CoT-SC. Let $Y$ denote the set of possible candidate outputs across k reasoning paths. We define q(y) as the estimated probability of output y \u2208 Y, computed as:\n$q(y) = \\frac{1}{k} \\sum_{i=1}^{k} \u2161(y = y^i)$,    (3)\nwhere \u2161 is the indicator function. Notice that semantical clustering in Section 4.2 can be used when calculating q(y), while the indicator function handles cases where the final answer is numeric or discrete. We use entropy H(y) as a gating function across the k reasoning paths, calculated as:\n$H(y) = - \\sum_{Y\u2208Y} q(y) log q(y)$,   (4)\nwhich reflects the uncertainty in the model's reasoning. Based on this, if H(y) is smaller than a predefined threshold \u03c4 indicating high confidence, the final answer $y^*$ is determined through majority voting as follows:\n$y^* = arg \\underset{y}{max}  \\sum_{i=1}^{k} \u2161(y = y^i) if H(y) \\leq \u0442$.  (5)\nOtherwise, if H(y) > \u03c4, indicating lower confidence, we proceed by constructing a search tree and employing our proposed method, Semantic Exploration, as described in the following section. An analysis of entropy distribution is shown in Figure 4 in Section 5.3."}, {"title": "4.2 Semantic Exploration (SE)", "content": "For tree-based search, we propose SE, which leverages linguistic semantics to avoid exploring semantically similar nodes. For example, as illustrated in Figure 3, node 1 (\u201cHow many pages did Julie read yesterday?\u201d) and node 3 (\u201cWhat is the number of pages Julie finished reading yesterday?\u201d) convey the identical meaning. The key components of SE are semantic clustering and semantic PUCT.\nSemantic clustering Semantic clustering groups generated actions based on their semantic equivalence. At the current node s, the tree generates d candidate actions, A(s), using a language model. For each pair of actions (a, a') in A(s), a semantic equivalence relation E(a, a') (Kuhn et al., 2023; Farquhar et al., 2024) is used to determine if the two actions have bi-directional entailment, as evaluated by the DeBERTa-large model (He et al., 2020a), which is relatively lightweight compared to LLMs and processes only single-sentence actions as input. Actions with equivalent meanings are grouped into semantic equivalence clusters $C = {C_1, C_2, ..., C_{d'} }$, where each cluster $C_i \\subseteq A(s)$ contains semantically identical actions and $d'$ represents the total number of clusters. To expand the tree, actions $c_i$ where i \u2208 [d'] are uniformly sampled from each cluster $C_i$, respectively, forming C(s), the set of unique actions for expansion. As illustrated in Figure 3, semantic clustering prevents the redundant expansion of subsequent sub-trees from nodes containing actions with equivalent meanings. Our analysis of semantically unique actions is presented in Section 5.3.\nSemantic PUCT To achieve efficient exploration with semantic clusters C(s), we propose semantic PUCT. Previous research in LLMs has shown that more frequently generated samples indicate higher significance (Wang et al., 2023b). Leveraging this self consistency principle, we prioritize the exploration of semantic clusters with higher probabilities, defined by the semantic predictor \u03c0(c|s):\n$\u03c0(c|s) = \\sum_{c\u2208C}p_\\theta(c|s, m)$. (6)\nWe extend PUCT algorithm (Equation (2)) to operate at the level of semantic clusters as follows:\n$c^* = arg \\underset{C\u2208C(s)}{max}(Q(sc)+w\u03c0(cs) \\frac{\\sqrt{N(s)}}{N(s, c) + 1})$.(7)\nThe effect of Semantic PUCT is shown as ablation study in Section 5.4."}, {"title": "4.3 Early Stopping", "content": "We introduce an early stopping phase in MCTS to decide whether to terminate iterations early based on the confidence of the most probable answer. To measure this confidence, we use weighted aggregation rewards, which account for the semantic importance of nodes in the search tree.\nLet T denote the set of terminal nodes, and P(nj) be the set of nodes along the path from the root node to terminal node nj \u2208 T. The reward of a terminal node nj is computed by weighting the size of the semantic cluster |C(n)|, where C(n) is the cluster including the node n:\n$R(nj) = \\sum_{n\u2208P(nj)} |C(n)|r(n), \\forall nj\u2208T$. (8)\nWe define Y(nj) as the extracted answer of a terminal node nj, and Y' as the set of all extracted answers. The aggregated reward Ragg(y) for each answer y \u2208 Y' is then computed by summing the rewards of all terminal nodes that produce the same answer y:\n$Ragg(y) = \\sum_{nj\u2208T,Y(nj)=y}R(nj)$. (9)\nThis weighted aggregation ensures that nodes in larger semantic clusters, i.e., more significant"}, {"title": "5 Experiments", "content": "In this section, we present the experimental evaluation of SEAG. Section 5.1 describes the experimental setup, including datasets and models. The main evaluation results are presented in Section 5.2. Detailed analyses follows in Section 5.3, along with ablation studies in Section 5.4. Additional experimental details are provided in Appendix E."}, {"title": "5.1 Experimental Setup", "content": "Baselines We consider four reasoning methods as baselines across sequential and tree-based reasoning approaches. CoT (Wei et al., 2022) and CoT-SC (Wang et al., 2023b) are sequential reasoning approaches, where CoT generates step-by-step reasoning paths, and CoT-SC extends this by incorporating self-consistency. ToT (Yao et al., 2023) and RAP (Hao et al., 2023) use tree search algorithms to explore multiple reasoning paths, utilizing algorithms such as beam search and MCTS, respectively. For SEAG, SE, and RAP, the number of MCTS iterations is 10 and the number of actions is 4. For AG, we set $k = 10$ across all experiments. To ensure a fair comparison, we use identical prompts and the same number of in-context examples across all methods. The primary difference lies in the specific search mechanisms employed by each method. We present the detailed prompts for each baseline in Appendix I.\nDatasets For evaluating the reasoning ability, we use two standard reasoning tasks: GSM8K (Cobbe et al., 2021), a dataset of 8.5k math word problems requiring multi-step numerical reasoning, and AI2 Reasoning Challenge (ARC) (Clark et al., 2018), a dataset containing 7.8k multiple-choice science questions sourced from grade-level science exams. For evaluation, we randomly sample 400 instances from the test sets of GSM8K and ARC."}, {"title": "5.2 Main Results", "content": "Table 1 compares the accuracy and inference efficiency of six reasoning methods evaluated on the GSM8K and ARC using three different LLMs. The results for the base LLM are presented in in Appendix G. SEAG consistently outperforms all baseline methods in accuracy across all datasets and models, demonstrating its robustness and effectiveness. Notably, compared to RAP, which is our closest baseline, SEAG achieves a 4.3% increase in accuracy while requiring only 31% as many inferences as RAP, on average. This highlights SEAG's ability to deliver superior reasoning performance with improved computational efficiency. Further discussions on inference cost in terms of tokens are provided in Appendix G.\nWhen evaluating SE independently, SE also achieves higher accuracy and the fewer number of inference cost compared to tree search-based methods, RAP and ToT, as illustrated in Figure 2. By incorporating AG, SEAG further improves performance by adaptively determining reasoning paths. This allows SEAG to capitalize on CoT-SC's strength in internal reasoning, achieving higher accuracy while also enhancing computational efficiency. Additional plots using token cost as an alternative cost metric are presented in Appendix F."}, {"title": "5.3 Analyses", "content": "Necessity of AG Using the results of 10 independent CoT-SC samplings, we calculate confidence in terms of entropy values as defined in Equation (4). Problems are categorized into several groups based on their entropy values. Figure 4 presents the results of applying CoT, RAP, and SE to problems within each group. Notice that"}, {"title": "Efficiency improvement by SE", "content": "To evaluate the impact of SE, we measure the number of unique semantic clusters $d'$ (i.e., the number of nodes expanded after applying semantic clustering) and the reduction rate at each depth when four actions, d = 4, are generated in each state. Table 2 presents that semantic clustering effectively reduces the redundant search space from 25-45% at depth 1 to 50-65% at depth 4. In overall, semantic clustering eliminates approximately 20\u201360% of semantically redundant paths, significantly reducing the search space across different depths and datasets. These results indicate that SE avoids repeatedly expanding and exploring semantically redundant paths by incorporating semantic equivalence. Additionally, in Appendix H, we provide a brief analysis on prompt design modification to encourage diverse action sampling as an alternative approach to SE."}, {"title": "Effect of the number of tokens", "content": "We analyze the effect of increasing average token cost on the accuracy improvement of the methods in Figure 5. Token cost is calculated based on the pricing policy of commercial LLM APIs, where output tokens"}, {"title": "5.4 Ablation Studies", "content": "Improvement by semantic PUCT To evaluate the effectiveness of the proposed action selection algorithm, semantic PUCT in equation (7), we conduct an ablation study with two existing algorithms: UCT, which relies solely on a count-based uncertainty term in equation (2), and PUCT, which incorporates an uncertainty term involving \u03c0(a|s) and a count-based term in equation (2). In Table 4, we demonstrate that Semantic PUCT outperforms the existing algorithms while maintaining comparable efficiency by encouraging exploration of semantically probable clusters with \u03c0(c|s).\nImprovement by weighted aggregation of rewards To evaluate the effectiveness of the aggregation strategy weighted by lcl, we conducted a comparison with an aggregation strategy where all actions were weighted equally (i.e., |c| = 1), regardless of clustering. The experiments were conducted using the SEAG method. To ensure a fair comparison of LLM computation costs, a was set to 11 for the weighted aggregation and 8 for the equal weighting strategy. As shown in Table 4, the weighted aggregation consistently achieved higher accuracy across both benchmarks while incurring lower LLM computation costs."}, {"title": "6 Conclusion", "content": "In this paper, we propose Semantic Exploration with Adaptive Gating (SEAG), a framework that enhances the efficiency and accuracy of multi-step reasoning tasks in LLMs. SEAG addresses two key issues in tree-based reasoning methods: (i) the unnecessary use of complex reasoning techniques for tasks solvable with simpler approaches, and (ii) the generation of semantically redundant nodes during exploration. By combining adaptive gating to evaluate task complexity, semantic exploration to minimize redundancy, and early stopping to reduce computational overhead, SEAG achieves significant performance improvements."}, {"title": "Limitations", "content": "Our method focuses on leveraging only internal knowledge to enhance the efficiency of tree search-based reasoning methods. This focus ensures a fair evaluation of the method's inherent efficiency without reliance on external tools or feedback. Expanding the approach to incorporate such external resources could further improve the reasoning process, presenting a promising direction for future work. Furthermore, the experiments are primarily conducted on benchmarks where final answers are provided in a discrete form, rather than free-form natural language generation. Evaluating the method on tasks requiring open-ended responses is left as future work."}, {"title": "Appendix", "content": "A Further Details of Reasoning Frameworks in Language Models\nChain-of-Thought (CoT) prompting (Wei et al., 2022) sequentially generates thoughts z1,..., Z1, where zi ~ Po(zi|x, z<i), and then generates the output with these thoughts, i.e., y ~ po(y|x, z\u22641).\nSelf-Consistency with CoT (CoT-SC) (Wang et al., 2023b). CoT-SC is an ensemble-based method that leverages k independently sampled reasoning paths, each generated using CoT prompting. Specifically, for each i \u2208 [k], a reasoning path generates an output y\u00b2 ~ po(y|x, z\u00b21). The final output is determined by majority voting across k paths: arg maxyey \u03a3=1 \u2161(y\u00b2 = y), where y is the set of all possible candidate outputs and \u2161(\u00b7) is the indicator function.\nTree-of-Thought (ToT) prompting (Yao et al., 2023). For exploring multiple reasoning paths, ToT prompting extends CoT by structuring the reasoning process as a tree structure, where each node represents a reasoning state s = [x, 21, ..., zi] with input x and the sequence of intermediate thoughts. Intermediate thoughts are generated sequentially as Zi ~ Po(ZiX, Z<i). The exploration relies on search algorithms, such as Breath-First Search (BFS) or Depth-First Search (DFS), to evaluate and prioritize paths using heuristics based on LM evaluations of each state.\nB Reward Design in MDP\nWe adapt the reward design proposed in RAP (Hao et al., 2023), focuses on evaluating the feasibility and desirability of reasoning steps. This approach incorporates a reward function rt = r(st, at) \u2208R to assess the impact of an action at to a state st. Our reward design integrates two key components: self-evaluation of the action's helpfulness and confidence of the resulting state.\nSelf-Evaluation by the LLM The model can self-assess the helpfulness of reasoning by answering questions, such as \u201cIs this reasoning step useful?"}, {"title": "D SEAG Algorithm", "content": "Algorithm 1 presents the detailed procedure of SEAG, illustrating its key steps: adaptive gating, semantic exploration, and early stopping."}, {"title": "E Experimental Settings", "content": "We describe the detailed experimental settings to ensure reproducibility. Table Al presents the default hyperparameters for each method.\nAll experiments were conducted using a single GPU and for Llama3-8B and Mistral-7B models, and two GPUs for Llama2-13B model. The total computational resource is required to produce the results in Table 1 is approximately 832 GPU hours. We utilize RTX 3090 and A6000 GPUs for all experiments. Due to the high computational cost, we report results based on a single run."}, {"title": "F Computational Efficiency with Token Cost", "content": "We provide additional scatter plots in Figure A1 where token cost is used as the cost metric instead of the number of inferences as shown in Figure 2. The token cost metric represents the cu-"}, {"title": "G Extended Experimental Results", "content": "In this section, we provide additional experimental results comparing the accuracy and computational costs of various methods on the GSM8K and ARC benchmarks. Specifically, we present results using both Llama3-8B-Base in Table A2 and Llama3-8B-Instruct models in Table A3. Both tables highlight the improvements in accuracy and efficiency achieved by our proposed methods, SE (Ours) and SEAG (Ours), across benchmarks. These improvements are evident not only in accuracy across all baselines but also in reductions in the number of inferences, input tokens, and output tokens compared to tree search-based methods."}, {"title": "H Prompt Design Modification for Diverse Action Sampling", "content": "To encourage the generation of semantically unique actions, one can consider sampling actions in a"}]}