{"title": "SatFed: A Resource-Efficient LEO Satellite-Assisted Heterogeneous Federated Learning Framework", "authors": ["Yuxin Zhang", "Zheng Lin", "Zhe Chen", "Zihan Fang", "Wenjun Zhu", "Xianhao Chen", "Jin Zhao", "Yue Gao"], "abstract": "Traditional federated learning (FL) frameworks rely heavily on terrestrial networks, where coverage limitations and increasing bandwidth congestion significantly hinder model convergence. Fortunately, the advancement of low-Earth orbit (LEO) satellite networks offers promising new communication avenues to augment traditional terrestrial FL. Despite this potential, the limited satellite-ground communication bandwidth and the heterogeneous operating environments of ground devices\u2014including variations in data, bandwidth, and computing power\u2014pose substantial challenges for effective and robust satellite-assisted FL. To address these challenges, we propose SatFed, a resource-efficient satellite-assisted heterogeneous FL framework. SatFed implements freshness-based model prioritization queues to optimize the use of highly constrained satellite-ground bandwidth, ensuring the transmission of the most critical models. Additionally, a multigraph is constructed to capture real-time heterogeneous relationships between devices, including data distribution, terrestrial bandwidth, and computing capability. This multigraph enables SatFed to aggregate satellite-transmitted models into peer guidance, enhancing local training in heterogeneous environments. Extensive experiments with real-world LEO satellite networks demonstrate that SatFed achieves superior performance and robustness compared to state-of-the-art benchmarks.", "sections": [{"title": "I. INTRODUCTION", "content": "As edge devices like drones, smart cameras, and IoT sensors proliferate [1]\u2013[3], they generate vast amounts of data at the network edge [4], [5]. This data drives significant advancements in key domains such as resource management [6], [7], authentication [8], image compression [9], and autonomous driving [10]\u2013[13] through machine learning (ML). However, privacy considerations [14], [15] and bandwidth constraints [16] render transferring large volumes of data to a cloud server impractical, necessitating the adoption of distributed ML training methods.\nTo address these challenges, federated learning (FL) [17] has emerged as a promising distributed machine learning framework, allowing edge devices to collaboratively train models without sharing local data [18]-[20]. FL typically employs a parameter server (PS) architecture, where a central server aggregates model updates from participating devices. The efficiency of FL training is heavily dependent on the quality of communication, given the continuous exchange of large volumes of parameters [21]. However, existing FL systems solely rely on terrestrial networks, which are increasingly strained by rising user numbers and service demands [22]-[24]. This often results in delays or congestion in parameter transmission [25], significantly affecting FL convergence, especially in remote or underdeveloped regions with poor signal coverage [26].\nFortunately, the proliferation of low Earth orbit (LEO) satellites is revolutionizing satellite broadband Internet [27]-[31], providing a crucial solution to the limitations of traditional terrestrial FL. Specifically, SpaceX plans to deploy about 42,000 LEO satellites for its Starlink constellation [32]. LEO satellite networks offer broad coverage, facilitating peer-to-peer communication among numerous edge devices [33]. For example, when devices engaged in FL experience unstable terrestrial connections with central servers, satellite connectivity allows them to rapidly obtain knowledge from multiple peers, thereby improving their local training.\nHowever, despite its promise, FL within satellite-assisted terrestrial networks remains largely unexplored. This is a complex endeavor requiring meticulous design of transmission modes tailored to the intrinsic characteristics of satellite networks and effective utilization of satellite transmissions to address various performance challenges posed by system heterogeneity. Firstly, the limited contact time and bandwidth"}, {"title": "II. MOTIVATION", "content": "In this section, we present empirical measurements that underscore the challenges inherent in satellite-assisted FL, thereby strengthening the motivation for the design of SatFed."}, {"title": "A. Constrained Satellite Network Transmission", "content": "LEO satellites orbit periodically, engaging in bidirectional data transmission when within range of ground devices, primarily constrained by brief contact times and limited uplink bandwidth. For instance, satellites orbiting at an altitude of 700 km complete one orbit approximately every 100 minutes, with contact windows to ground devices lasting only about 10 minutes [36]. As illustrated in Fig. 2a, we assess parameter transmission efficiency during these fleeting contact periods using the Starlink LEO satellite communication system. presents the cumulative distribution function (CDF) derived from Iperf [37], a widely used network measurement tool, revealing an average downlink rate of approximately 100 Mbps and an uplink rate around 12 Mbps. For example, downloading a 98 MB ResNet-50 model [38] from the satellite to each device takes about 8 seconds, whereas uploading the model back to the satellite requires more than a minute. Thus, the principal bottleneck in satellite network transmission lies in the uplink direction.\nIn an ideal scenario, each connection between devices and satellites involves extensive model exchanges (as detailed further in Sec. III-B). However, due to limitations in uplink transmission rates, the successful transmission of"}, {"title": "B. Data Heterogeneity", "content": "The performance of satellite-assisted FL is significantly impacted by data heterogeneity, as devices distributed globally encounter data from diverse contexts [39]. These devices exhibit non-independent and non-identically distributed (non-IID) data, resulting in varied local optimization objectives [40]. Consequently, model updates from different devices are biased toward their local data distributions. Directly averaging these updates, as is done in the widely used FL method FedAvg [17], often leads to suboptimal performance. To better understand the impact of data heterogeneity on training, we conducted experiments with the ResNet-50 model using FedAvg at varying levels of heterogeneity, as shown in Fig. 3a. The results clearly indicate that as data heterogeneity increases, performance degrades significantly.\nMoreover, relying solely on a single global model can lead to fairness challenges across devices. To investigate this issue, we evaluate each device's local test accuracy under various heterogeneous conditions, as shown in Fig. 3b (with the dashed line representing the average). It is evident that as heterogeneity increases, the global model exhibits greater performance variance among devices, significantly reducing fairness. Although extensive research has been conducted on the impact of data heterogeneity on FL, most studies focus on PS communication frameworks [41] and do not adapt to emerging hybrid satellite-terrestrial network architectures."}, {"title": "C. Bandwidth Heterogeneity", "content": "Terrestrial networks generally provide higher bandwidth than satellite networks, but they are subject to variability and heterogeneity due to factors such as fluctuating user volumes, routing conditions, and regional infrastructure disparities [42]. Devices operating in remote areas or congested environments (a.k.a., stragglers) experience longer delays in parameter transmission, which in turn slows down their local updates and ultimately hampers training performance.\nTo better understand the impact of bandwidth heterogeneity on FL, we conduct experiments with varying proportions of"}, {"title": "D. Computation Heterogeneity", "content": "Another challenge in satellite-assisted FL arises from the difference in computing capabilities among devices [40], [44]. Certain devices are undertrained due to insufficient computational power within the same local update cycle. We conduct experiments to investigate how this uneven training in local updates across devices affects FL. Fig. 5a shows that as the number of undertrained devices increases, the test accuracy of the global model significantly decreases. It should be noted that, as illustrated in Fig.5b, the imbalance in the model updates resulting from computation heterogeneity can be mitigated by raising the learning rate for undertrained devices. Increasing the learning rates for normal devices does not improve performance, highlighting that the improvement in performance comes from balancing update scales.\nMotivated by this, the peer-to-peer communication mode of satellite networks is more conducive to edge devices promptly perceiving the model update scales of their peers and accordingly adjusting local learning rates to ensure that all edge devices update with relatively consistent scales. However, in a hybrid satellite-assisted FL framework, strategies for real-time and precise perception of peer update scales and the corresponding adjustment of local learning rates to achieve optimal performance require careful design."}, {"title": "III. FRAMEWORK DESIGN", "content": "In this section, we will elaborate on the SatFed framework and its well-designed components."}, {"title": "A. Preliminaries and Overview", "content": "We consider a typical scenario of LEO satellite-assisted FL. Each edge device \\(i \\in [m]\\) possesses its own private dataset \\(D_i\\) from distribution \\(P_i(x, y)\\), where \\(x\\) and \\(y\\) denote the input features and corresponding labels, \\(m\\) is the number of devices. Devices share a model \\(f(w^*)\\) parameterized by weights \\(w^*\\). However, as outlined in Section II-B, this model cannot effectively accommodate the diverse local data distributions of all devices. Therefore, we utilize personalized device models for local inference, \\({f_i(v_i; \\cdot)}\\)_{i\\in[m]}. The optimization objective follows the state-of-the-art FL methods using personalized models [45], where all devices are trained within the FedAvg framework to update the global model \\(w^*\\) while using it to guide their own personalized model updates:\n\\[\\min_{\\{v_i\\}_{i=1}^m} \\frac{1}{m} \\sum_{i=1}^m \\{L_i(v_i) + \\mu Regu(v_i, w^*)\\},\\qquad(1)\\]\n\\[s.t.\\ w^* = arg \\min_{\\omega} \\sum_{i=1}^m L_i(\\omega),\\qquad(2)\\]\nwhere \\(L_i(w) = E_{(x,y)\\sim D_i}l(f(w; x); y)\\) is the empirical loss of edge device \\(i\\), \\(\\mu\\) is a hyper-parameter, \\(N\\) denotes the total number of instances over all devices, and \\(Regu(\\cdot,\\cdot)\\) regulates model difference.\nIn SatFed, local updates of the global model are asynchronously transmitted to the server for aggregation via the terrestrial network. Simultaneously, personalized models are transferred peer-to-peer through the satellite network in a decentralized manner. The personalized model training is guided by both the global model and peers' personalized models.\nSatFed employs a model freshness-based priority transmission mode, enabling edge devices to obtain more up-to-date"}, {"title": "B. Satellite Network Transmission", "content": "For the transmission of satellite networks, satellite \\(k\\) and device \\(i\\) maintain model caches \\(C_{k,i}^{sat}\\) and \\(C_i^{edge}\\) respectively, for storing personalized models from various devices. As depicted in Fig. 6, when device \\(i\\) connects to satellite \\(k\\), it uploads models through the satellite network uplink. Satellite \\(k\\) subsequently transmits models via the downlink to device \\(j\\) as it passes overhead. However, the intricate topology and stringent bandwidth constraints of satellite networks, as discussed in Section II-A, present significant challenges to naive satellite transmission.\n1) Drawbacks of Naive Transmission: Given \\(L\\) LEO satellite orbits with multiple satellites operating on each, for each orbit \\(l \\in [L]\\), the set \\(S_l\\subseteq [m]\\) represents the edge devices it covers. When two edge devices \\(i\\) and \\(j\\) are simultaneously covered by any orbit, i.e., \\(\\exists l \\in [L], i \\in S_l\\) and \\(j \\in S_l\\), we term them satellite-network direct, denoted as \\(SatDir_{i,j} = 1\\); otherwise, \\(SatDir_{i,j} = 0\\). Notably, any device \\(i\\) may also be simultaneously covered by multiple orbits, denoted as the orbit set \\(S_{orb}\\). It can be inferred that \\(S_{Sat Dir} = \\{j|j \\in m, SatDir_{i,j} = 1\\}\\) is the union \\(\\cup \\{S_l|l \\in S_{orb}\\} \\).\nWe consider two naive transmission modes: when device \\(i\\) connects to satellite \\(k\\), it either i) uploads only its personalized model \\(v_i\\) or ii) additionally uploads all cached peer models \\(\\{v_j|v_j \\in C_i^{edge}\\} \\). The former method restricts satellite \\(k\\) in orbit \\(l\\) to caching only \\(\\{v_i|i \\in S_l\\}\\), which limits device \\(j\\) to receiving models solely from devices in \\(S_{Sat Dir}\\), thereby causing transmission bias. As shown in Fig. 7a, even with an average LEO satellite orbit covering up to 10 devices and increasing the"}, {"title": "C. Heterogeneous multigraph", "content": "To address the multifaceted heterogeneity issues highlighted in Sec. II, SatFed constructs a global multigraph, aiming to leverage model exchanges across satellite networks to capture the diverse relationships between devices, ultimately guiding local updates. Specifically, we document three types of heterogeneous relationships to construct the multigraph \\(G_m = ([m], A^{sim}, A^{con}, A^{cmp})\\): i) similarity edges \\(A^{sim}\\); ii) connectivity edges \\(A^{con}\\); and iii) computation edges \\(A^{cmp}\\). The details are as follows.\n1) Similarity Edges: As described in Sec II-B, diverse devices exhibit unique local empirical risks \\(\\{L_i\\}_{i\\in[m]}\\) attributed to differences in training data distribution. Similarity edges \\(A^{sim}\\) aim to aid devices in discerning which peer models obtained from the satellite network better align with their optimization goals. Borrowing from state-of-the-art methods [46], we measure the similarity of local optimization objectives by calculating the cosine similarity of model parameters during training. However, in satellite networks where model freshness varies, simple cosine similarity may lead to inaccurate measurements, necessitating freshness calibration. Therefore, we compute similarity edge \\(A^{sim}\\) between devices \\(i\\) and \\(j\\) with confidence \\(\\kappa = e^{-|t^1 - t^2|}\\) as:\n\\[A^{sim}(i, j) = 1 - \\frac{|v_i^T v_j|}{\\|v_i\\|\\|v_j\\|} \\kappa,\\qquad(3)\\]\nIn short, when two models have similar freshness (\\(\\kappa \\to 1\\)), cosine similarity accurately reflects the similarity of their local optimization objectives. Conversely, when their freshness differs significantly (\\(\\kappa \\to 0\\)), cosine similarity fails to reflect their data distribution accurately. The confidence \\(\\kappa\\) adjusts the similarity edge updates, as detailed in Sec. III-C4.\n2) Connection Edges: As discussed in Sec. II-C, terrestrial bandwidth stragglers result in relatively outdated models. Connection edges help stragglers identify potential helpers. We monitor the communication frequency \\(C_s^i\\) between each edge device \\(i\\) and the parameter server over a specified time window \\(W\\). Similarly, we record the frequency \\(C_i^j\\) of successful transmissions of personalized models from device \\(j\\) to \\(i\\) via the satellite networks. Subsequently, the connection edge is denoted as:\n\\[A^{con}(i, j) = (C_i^j + \\lambda \\times C_s^j) / C_s^i,\\qquad(4)\\]\nwhere \\(\\lambda > 0\\) is the weight balancing the two indicators. \\(A^{con}(i, j)\\) is large if device \\(j\\) has significantly more exchanges"}, {"title": "D. Model Training", "content": "This section will elucidate how SatFed leverages multigraph \\(G_m\\) to guide devices in extracting beneficial knowledge from transmitted models in satellite networks, thereby enhancing local updates and improving training performance."}, {"title": "1) Peer Guide Model:", "content": "In SatFed, devices cache many peer models from the satellite network, but these models differ greatly in their usefulness for local updates. Thus, using \\(G_m\\), we calculate the weight \\(T(i, j)\\), representing device \\(i\\)'s dependency on model \\(v_j\\) for local updates. The dependency conforms to the two principles, consistent with the design goals of \\(A^{sim}\\) and \\(A^{con}\\): i) the more similar their local optimization objectives, the stronger the mutual dependency; ii) the more frequent the recent communication between device \\(j\\) and the server, and the more often device \\(j\\)'s model is sent to device \\(i\\), the stronger \\(i\\)'s dependency on \\(j\\). Therefore, \\(T(i, j)\\) is defined as follows:\n\\[T(i, j) = A^{sim}(i, j) + \\alpha \\times A^{con}(i, j),\\qquad(8)\\]\nwhere \\(\\alpha\\) is a balancing factor.\nUsing all peer model \\(v_j\\) in cache \\(C_i^{edge}\\), combined with the respective dependency \\(T(i, j)\\), we generate a peer-guided model \\(\\Omega_i\\) for device \\(i\\):\n\\[\\Omega_i = \\frac{1}{|C_i^{edge}|} \\sum_{v_j \\in C_i^{edge}} e^{-t-t^1} \\times T(i, j) \\times v_j,\\qquad(9)\\]\nwhere \\(|C_i^{edge}|\\) is the cache size, \\(t\\) is the current time, and the exponential term aims to diminish the impact of outdated models in the cache. In short, \\(\\Omega_i\\) represents a synthesis of peer models that are ahead in global update progress and closely aligned with the optimization goals of \\(v_i\\).\n2) Global Model Update: In SatFed, the global model \\(w^*\\) is locally trained by devices, with model parameters transmitted via the terrestrial network to a parameter server for asynchronous updates. However, naive local updates result in uneven training mentioned in Sec section II-D, significantly affecting model performance. We address this by using \\(A^{cmp}\\) to dynamically adjust the local learning rate based on the real-time peer model update speeds. Specifically, we use \\(U_i = \\sum_{j\\in[m]} A^{cmp}(i,j)/m\\) to denote the average update scale of peers for each device \\(i\\). If \\(U_i \\gg 1\\), it indicates that device \\(i\\) is globally lagging behind and its learning rate needs to be increased appropriately for better global model aggregation.\nThus, SatFed establishes dynamic adaptive learning rate for device \\(i\\):\n\\[\\eta^i = \\eta \\times (1 + \\gamma \\times ln\\ max(1, U_i)),\\qquad(10)\\]\nwhere \\(\\gamma\\) represents the gain coefficient. If the updating speed of \\(v_i\\) outpaces the global (\\(U_i \\in (0,1)\\)), its learning rate \\(\\eta\\) remains hyperparameter \\(\\eta\\); otherwise, \\(\\eta^i\\) is logarithmically increased with \\(U_i\\). After each round of local updates begins, device \\(i\\) receives the latest global model \\(w^*\\) from the server. It uses a learning rate \\(\\eta^i\\) to train for \\(R\\) rounds of gradient descent on its dataset \\(D_i\\), obtaining updated parameters \\(w^i\\). The updated parameters are then sent back to the server for asynchronous aggregation with a fixed weight \\(\\beta\\)."}, {"title": "IV. PERFORMANCE EVALUATION", "content": "This section presents numerical results to evaluate the training performance of the proposed SatFed framework and the effectiveness of each individual component."}, {"title": "A. Implementation", "content": "We implement SatFed using Python 3.7 and PyTorch 1.12.1 and train it with the NVIDIA GeForce RTX 3090 GPUs. In the experiments, \\(N = 20\\) edge devices are deployed, along with \\(K = 20\\) satellites orbiting the Earth, distributed across \\(J = 10\\) LEO orbits. We use two widely acclaimed image datasets image datasets: Fashion-MNIST [47] and CIFAR-100 [34], using a Dirichlet distribution to generate non-IID label distributions for devices [35], and set the \\(\\alpha\\) parameter to 0.2 for strongly non-IID settings and 0.5 for relatively IID settings. Data quantities per device are randomly assigned, ranging from 1500 to 2000. We employe a ResNet-50 model of 98 MB size for CIFAR-100 (ResNet-18 for Fashion-MNIST). The Adam optimizer [48] is used, with the learning rate \\(\\eta\\) set to 0.001 and the batch size set to 128. The loss function \\(L_i\\) is the cross-entropy loss.\nAccording to real LEO satellite networks [36], each satellite orbit has an operational cycle of 100 minutes and covers approximately 3 edge devices, with a contact time of about 10 minutes per device. The bandwidth of the satellite network is set to 100 Mbps for downlink and 10 Mbps for uplink as measured. The local update period is set to 30 minutes. Half of the devices have a compute power of 4 GFLOPS (equivalent to a Raspberry Pi 4 Model B), while the others have only 1/5 of that. Half of the devices typically operate under ideal 200 Mbps terrestrial network bandwidth, while the other half have a 90% chance of communication blockage or disconnecting from the server, retrying every 30 minutes."}, {"title": "B. Overall Performance", "content": "In this section, we evaluate the overall performance of the SatFed framework in terms of test accuracy and convergence speed. In addition, we assess the impact of satellite network transmission on SatFed's training. To investigate the advantages of SatFed, we compare it with five other benchmarks:\n\\end{itemize}\n1) The Overall Performance of SatFed: Fig. 8 presents the test accuracy of SatFed compared to other benchmarks on the Fashion-MNIST and CIFAR-100 datasets. FedAvg and Ditto exhibit significantly slower convergence due to waiting for bandwidth-straggling devices during each global model aggregation. In contrast, FedAsync and Ditto-Async accelerate convergence at the cost of training instability, attributed to the degradation caused by outdated models from asynchronous updates. It is evident that SatFed achieves the fastest convergence among all benchmarks, facilitated by its connection edges, enabling stragglers to learn from high-bandwidth peers via satellite networks, thereby alleviating"}, {"title": "C. Micro-benchmark", "content": "1) Similarity Edges: Fig. 10 illustrates the effect of similarity edges on the training of the CIFAR-100 dataset. Clearly, SatFed with \\(A^{sim}\\) achieves optimal performance in both IID and non-IID settings. Remarkably, SatFed demonstrates performance enhancements over Ditto even without similarity edges. This suggests that using the simply averaged peer"}, {"title": "2) Connection Edges:", "content": "Fig. 11 presents the impact of connection edges on CIFAR-100 dataset training performance. Comparing with and without \\(A^{con}\\), it's evident that the edge connection's impact is most significant in the early stages of training. At this point, all devices' parameter updates are relatively similar. Models with poor terrestrial bandwidth can learn directly from the faster-progressing models through \\(A^{con}\\), significantly accelerating overall convergence. However, in the later stages, due to the impact of data heterogeneity, the update directions of different devices diverge significantly, reducing the effectiveness of \\(A^{con}\\)."}, {"title": "3) Computation Edges:", "content": "Fig. 12 illustrates the effect of computation edges on the SatFed training. Clearly, \\(A^{cmp}\\) assisting in increasing the learning rate of undertrained models significantly enhances the performance of aggregated global models in IID scenarios. Although the improvement in non-IID scenarios is less pronounced, it still effectively enhances the injection of global knowledge into personalized models. In summary, computation edges effectively enhance SatFed's performance across both IID and non-IID settings. This underscores their ability to capture differences in local training progress and effectively address these differences through learning rate adjustments."}, {"title": "V. RELATED WORK", "content": "The system heterogeneity in FL, encompassing data, bandwidth, and computation heterogeneity, is a well-established field with various approaches. To address data heterogeneity challenges, Li et al. [45] introduce personalized devices models, enhancing the fairness and robustness of the system. Smith et al. [50] adapts multitask learning for personalization by treating different devices as distinct learning tasks. Ye et"}, {"title": "VI. CONCLUSION", "content": "In this paper, we propose SatFed, a resource-efficient satellite-assisted FL framework designed to enhance training performance and convergence speed in complex heterogeneous environments. Initially, SatFed designs a priority transmission queue based on model freshness differences, enabling devices in satellite networks with highly constrained transmission rates and complex topologies to receive near real-time peer models."}]}