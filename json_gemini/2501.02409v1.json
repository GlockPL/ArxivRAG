{"title": "INTERPRETABLE NEURAL ODES FOR GENE REGULATORY NETWORK DISCOVERY UNDER PERTURBATIONS", "authors": ["Zaikang Lin", "Sei Chang", "Aaron Zweig", "Elham Azizi", "David A. Knowles"], "abstract": "Modern high-throughput biological datasets with thousands of perturbations provide the opportunity for large-scale discovery of causal graphs that represent the regulatory interactions between genes. Numerous methods have been proposed to infer a directed acyclic graph (DAG) corresponding to the underlying gene regulatory network (GRN) that captures causal gene relationships. However, existing models have restrictive assumptions (e.g. linearity, acyclicity), limited scalability, and/or fail to address the dynamic nature of biological processes such as cellular differentiation. We propose PerturbODE, a novel framework that incorporates biologically informative neural ordinary differential equations (neural ODEs) to model cell state trajectories under perturbations and derive the causal GRN from the neural ODE's parameters. We demonstrate PerturbODE's efficacy in trajectory prediction and GRN inference across simulated and real over-expression datasets.", "sections": [{"title": "1 INTRODUCTION", "content": "GRNs capture the complex regulatory interactions between genes that dictate cell function, development, and responses to environmental changes. High-throughput perturbation assays with single-cell RNA sequencing (scRNA-seq) readouts, such as Perturb-seq, enable precise measurement of gene expression changes across cell types resulting from genetic perturbations. However, inferring GRNS from scRNA-seq experiments remains challenging due to the problem's exponential search space. To overcome the inherent combinatorial complexity of GRN discovery, recent causal graphical modeling approaches relax the problem into a continuous, albeit non-convex, optimization program that learns a directed acyclic graph (DAG) corresponding to the underlying GRN (Zheng et al., 2018; Fang et al., 2023; Brouillard et al., 2020; Lopez et al., 2022).\nWhile causal graphical models have predominantly focused on learning structure from gene knockdown-based perturbations, new interventional single-cell experiments offer insights into previously unexplored aspects of gene regulation at an unprecedented scale. In particular, the Transcription Factor (TF) Atlas applied single-cell resolution assays to systematically study the effects of overexpression of 1,836 TFs on cell differentiation, generating over 1.1 million cell profiles measured 7 days following TF perturbation (Joung et al., 2023). TFs, proteins that bind to the genome to regulate gene expression, play a crucial role in defining cell states. Their overexpression can induce significant changes in cell fate, directing the differentiation of stem cells into various cell types such as myocytes and neurons. Since gene regulation during differentiation is inherently dynamic, accurately capturing these dynamics is essential for models aiming to uncover the underlying regulatory network. Previous experiments in yeast and E. coli have demonstrated that gene regulatory dynamics can be effectively modeled by complex non-linear dynamical systems (Alon, 2006; Setty et al., 2003; Kalir and Alon, 2004). Their experimentally validated GRNs contain negative self-loops, which contradicts the assumption of graph acyclicity imposed by most structure learning methods.\nCausal structure learning methods are limited in their ability to model the full complexity of interventional data generated by emerging single-cell assays. To address these limitations, we propose PerturbODE, a novel neural ODE-based framework that 1) implicitly encodes the GRN in its parameters, enabling simultaneous trajectory inference and GRN discovery, 2) maps cell states into"}, {"title": "2 RELATED WORK", "content": "Causal graph discovery from genetic perturbations. Structure learning of causal graphs has recently been applied to Perturb-seq interventional experiments to infer an underlying GRN. The nodes in the encoded causal graph correspond to genes and the directed edges ideally correspond to direct causal regulatory relationships between genes. Since the number of possible DAGs grows exponentially with the number of nodes, classical causal graph discovery approaches are unable to scale beyond a modest number of genes (typically 50-200). NO-TEARS (Zheng et al., 2018) introduced a continuous optimization objective via the trace exponential acyclicity constraint, significantly simplifying the problem complexity and enabling gradient descent-based structure learning. Extensions have further improved scalability. NO-TEARS-LR (Fang et al., 2024) adds a low-rank assumption to NO-TEARS to efficiently infer large and dense DAGs. DCDI (Brouillard et al., 2020) extends the continuous optimization formulation to interventional data but can only scale up to 50 dimensions in their original implementation with the trace exponential acyclicity constraint. DCDFG (Lopez et al., 2022) addresses DCDI's limited scalability by employing a low-rank factor graph structure and spectral radius acyclicity constraint.\nNeural ODEs for cell trajectory inference and modeling gene regulation. Differential equation-based models have long been the preferred framework for describing dynamical systems in biology due to their interpretability and flexibility in incorporating known properties of the system. Neural ODEs extend this framework by leveraging neural networks to learn the dynamics directly from data, making them particularly suited for modeling complex, high-dimensional systems without explicit formulations. Neural ODEs and their stochastic variants have been applied to trajectory inference, where the continuous development of cellular states is mapped over time. Some authors fit a discrete ODE specified by a gene regulatory function to temporal pairs of cells sampled from the optimal transport plan (Schiebinger et al., 2019). The gene regulatory function encodes information about the cell-autonomous regulatory networks. Jackson et al. (2023) parameterizes ODEs with recurrent neural networks (RNNs) to model dynamics before obtaining the coefficient of partial determination to represent the contribution of each TF.\nCausal Graph learning through stationary diffusion. The recently proposed method BICYCLE (Rohbeck et al., 2024) parameterizes the GRN adjacency matrix as the linear drift of a stable Olstein-Uhlenbeck (OU) process, approximating the steady state distribution under each intervention induced by the OU process by solving the Lyapunov equation. Despite the novelty in methodologies, it can currently only handle tens of observed genes.\nKey Limitations. Despite recent improvements to structure learning, causal GRN inference methods remain difficult to scale and are limited in their modeling capabilities. While they can learn some causal regulatory relationships from knockdown data, they lack the expressivity to capture how gene regulation affects cellular dynamics across time. Schiebinger et al. (2019) and Jackson et al. (2023) applied neural ODE-based methods for learning GRNs from a single perturbation or reprogramming trajectory, but provide no framework for leveraging datasets with multiple known genetic perturbations. PerturbODE combines ideas from causal structure learning and trajectory inference to provide a flexible and scalable framework that accurately captures cell dynamics and learns gene regulation from thousands of perturbations."}, {"title": "3 METHODS", "content": "Let I = {I0, I1, . . ., Ik } represent a collection of k + 1 intervention regimes, with I0 denoting the control regime (no intervention). The training dataset D = {Yi}i=0k represents gene expression data, where Yi \u2208 Rnixd corresponds to the d-dimensional gene expression measurements for ni cells"}, {"title": "3.1 NEURAL ODE FORMULATION FOR OVER-EXPRESSION WITH IMPERFECT INTERVENTION", "content": "For each cell subjected to an intervention Ii \u2208 I\\{I0}, which specifies a set of over-expressed genes, its cellular dynamics is described by the ODE,\n$\\frac{\\partial Y_t}{\\partial t} = f_i(Y_t) = A \\sigma(\\alpha \\circ (BY_t - \\beta)) + \\sum_{j \\in I_i} s_j \\cdot \\delta_j - WY_t,$\nwhere Yt \u2208 Rd represents the expression vector of a given cell at time t for d genes.\nThis system encapsulates the interaction between genes through a Multi-layer Perceptron (MLP) with a single hidden layer. Each neuron in the hidden layer is analogous to a gene module, similar to Segal et al. (2005). Such regulatory structure is known in the biology, such as production of flagella in E. coli (Macnab, 2003; Alon, 2006). For more details, appendix 6.10 illustrates the representation of the regulatory circuit of E. coli's flagella as a two-layer MLP.\nThe matrix B \u2208 Rl\u00d7d represents a linear transformation from the d-dimensional gene expression Yt to a lower l-dimensional latent (\"module\") space (l < d). Bjm is the signed effect of j-th gene's expression on the the m-th module.\nThe gene module signals are then non-linearly transformed after shift and scaling to give module activations. The non-linear activation function \u03c3(\u00b7) : R1 \u2192 R1 models the activation of the gene modules, with the logistic sigmoid function used as the default choice for (\u00b7). This activation function is chosen because of its relationship to the Hill function, which is well-studied and biophysically motivated for representing the effect of TF concentration on target gene transcription rate (Alon, 2006). The vector \u03b2\u2208 Rl is a strictly positive bias that shifts the activation threshold of the function"}, {"title": "3.2 NEURAL ODE FORMULATION WITH PERFECT INTERVENTION", "content": "PerturbODE is also capable of modeling perfect intervention. Gene knockout or over-expression (CRISPR-a) under perfect intervention is modeled by removing the intervened genes' dependencies on parent nodes. In a system subject to a set S of perfect interventions, where S contains the indices of the intervened genes, the corresponding ODE is,\n$\\frac{\\Theta Y_t}{\\Theta t} = M A \\sigma(\\alpha \\circ (BY_t - \\beta)) + \\sum_{j \\in I_i} s_j \\cdot \\delta_j - WY_t$\nwhere M = I \u2212 \u2211j\u2208S diag(\u03b4j) is a masking matrix that removes the effect of other genes on the perturbed gene(s). For over-expression sj > 0 for all j, whereas for knockout we set sj = 0 for all j."}, {"title": "3.3 MAPPING DYNAMICS TO TARGETS USING OPTIMAL TRANSPORT", "content": "fi (Yt) is learned by mapping the initial gene expression state Y0 to the observed target state Yi by intervening genes specified by Ii. We compute our target predictions Y by solving the ODE integration with the initial state Y0,\n$Y_i = \\phi_i(Y_0) = Y_0 + \\int_0^T F_i(Y_t) dt$\nwhere \u03d5i(Y0) is the flow map of the ODE under intervention Ii mapping initial condition Y0 to its position at time T through the numerical solution to the ODE for this initial value problem.\nGiven the lack of one-to-one correspondence between samples (cells) in the initial distribution and the samples in the target distributions, we assess the quality of our predictions by measuring the Wasserstein-2 distance between observed targets Yi and predicted targets Y , i.e.\n$W_2(X, \\hat{X}) = (\\min_{\\Gamma \\sim \\Pi(X, \\hat{X})} \\sum_{x, y} \\Gamma_{xy} ||x - y||^2)^{1/2},$\nwhere \u03a0 represents the set of all optimal transport plans between each sample from data distributions X and X, and \u0393 represents the minimal-cost transport plan used to measure the dissimilarity between"}, {"title": "3.4 DIFFUSION-BASED REGULARIZATION OF NEURAL DYNAMICS", "content": "PerturbODE can optionally augment the primary training objective by using diffused target samples as alternative initial states. This additional regularization encodes our prior expectation that the final cell states should be locally stable, helping to form a local contraction map that implies a locally stable fixed point, as ensured by the Contraction Mapping Theorem (Hunter and Nachtergaele, 2000). Further, the stable fixed points establish the theoretical equivalence between PerturbODE and a deterministic structural causal model (SCM), endowing it with its causal mechanism (Mooij et al., 2013; Sch\u00f6lkopf et al., 2021).\nThe augmentation involves diffusing Y using Brownian motion with a time step \u0394t to generate diffused targets Y . Across a reduced time span t \u2264 T, \u0178i is pushed forward through \u03d5i to obtain the predicted targets Y', and we backpropagate against the augmented loss L\u2081 = W2(Yi', Y ) + \u03bb|B|. During training, we alternate between using control samples Y0 and diffused targets Y for each intervention. Information on the exact training hyperparameters can be found in Appendix 6.2.2."}, {"title": "4 RESULTS", "content": "We compare PerturbODE to the causal graph discovery methods DCDFG (Lopez et al., 2022), DCDI (Brouillard et al., 2020), NO-TEARS (Zheng et al., 2018), and NO-TEARS-LR (Fang et al., 2023) through extensive experiments on both simulated and large-scale perturbational scRNA-seq datasets. These methods are good comparisons since, similar to PerturbODE, they also embed GRNs as matrices either in neural networks or directly in linear models.\nPerturbODE not only infers cycles but also detects both positive and negative edges, whereas the DCDI and DCDFG only identify edge existence under the DAG constraint. To enable benchmarking, the ground truth GRNs used in simulated data are DAGs with positive edges, and we validate solely against positive edges in the reference GRNs in the scRNA-seq dataset. As ground truth negative edges are unavailable for evaluation, we classify any negative edge inferred by PerturbODE as the absence of an edge. This setup gives PerturbODE a more difficult task in predicting the correct edge sign and prevents it from leveraging its full range of capabilities. Therefore, we provide further downstream analysis on PerturbODE's model parameters when trained on real datasets, showcasing its strengths in uncovering network structures through its biologically faithful and interpretable modeling approach."}, {"title": "4.1 GRN INFERENCE ON SERGIO SIMULATED DATASETS", "content": "SERGIO (Dibaeinia and Sinha, 2020) simulates single-cell gene expression data by modeling gene regulation of each gene by multiple TFs according to a user-provided DAG representing the GRN. SERGIO can simulate any number of cell types in steady state or cells differentiating to multiple fates. The simulator samples single-cell gene expression data through a stochastic differential equation (SDE) initialized at the expected steady state."}, {"title": "4.2 GRN INFERENCE ON THE TF ATLAS", "content": "We trained PerturbODE on the TF Atlas to evaluate its performance on large-scale real experimental datasets. The TF Atlas over-expresses TFs and uses scRNA-seq to measure cell states after 7 days of perturbation (Joung et al., 2023). As this dataset maps the interventional effects of TF over-expression, PerturbODE's inferred GRNs can uncover TF-to-TF interactions and higher-level network structure through TF modules.\nIn this setup, we used the control samples (mCherry) as the initial gene expression state for solving the neural ODE, while the final gene expression states correspond to cells with TF over-expressions that induced differentiation after 7 days. We evaluate the model's performance using three well-studied and experimentally validated human GRNs derived from extensive RNA-seq and ATAC-seq measurements. See Appendix 6.8 for further details on the GRNs used for evaluation. Notably, the ground truth GRNs only contain positive directed edges, restricting our evaluation to true positives and false negatives for benchmarking GRN edge detection. Consequently, we compute p-value and total recall score based on predictions of directed edges across all three GRNs. In addition, Figure 9 in Appendix shows recall scores across models in various sparsity levels."}, {"title": "4.2.1 PREDICTION OF HELDOUT INTERVENTIONS", "content": "Predicting the effects of unseen, i.e., heldout, interventions is a particularly challenging task. Here we randomly select ten overexpressed TFs to be held out simultaneously during training. Note that their expression levels are observed, but their perturbations are not trained on. For this task, we only compare PerturbODE with linear SCMs (NO-TEARS and NO-TEARS-LR). DCDFG cannot sample cells given a learned GRN, and DCDI lacks scalability for large datasets. For the linear SCMs, over-expression is implemented as imperfect shift intervention by adding a bias to the mean of the distribution modeling the intervened nodes (for details, see Appendix 6.4).\nWe evaluate the predictive performance through Pearson correlation, W2 distance between the distributions, and manual inspection via low dimensional embeddings. Pearson correlation is computed between the average predicted gene expression and the average gene expression of experimentally perturbed cells, while W2 distance is calculated between the full distributions of predicted and observed gene expressions."}, {"title": "4.2.2 NEGATIVE AUTOREGULATION IN PERTURBODE INFERRED GRNS", "content": "PerturbODE's unique ability to learn cyclic GRNs sets it apart from other causal methods that assume acyclicity. Cycles, especially negative autoregulation, are known to be a prevalent network motif in gene regulation. Negative autoregulation accelerates response times by enabling quicker adjustments to input signals and enhances robustness by stabilizing gene expression levels against fluctuations in production rates (Alon, 2006). Approximately 40% of known E. coli TFs exhibit negative feedback regulation (Rosenfeld et al., 2002).\nWhen trained on the TF Atlas, PerturbODE naturally incorporate this network motif (pattern) without the need for explicit priors. The model predicts that 26.4% of modeled genes are subject to negative autoregulation, which aligns with the expected prevalence of the motif according to prior studies. To assess the statistical significance, we numerically compute the frequency of negative self-loops in random graphs with the same graph density, yielding a highly significant p-value of less than 0.001. The result underscores both the statistical significance and biological realism of PerturbODE's predictions. By inferring the GRN from interventional dynamics, PerturbODE could learn network structures that can not be captured by strictly acyclic approaches."}, {"title": "4.2.3 ANALYSIS OF INFERRED GENE MODULES", "content": "PerturbODE's framework enables direct interpretation of the inferred gene modules, which encapsulate multiple gene to gene interactions. These interactions are extracted from the A and B matrices (Eq. 1), where the entries in B represent directed edges from upstream genes to gene modules, and the entries in A map the modules to downstream genes."}, {"title": "5 CONCLUSION", "content": "PerturbODE's main contribution is a highly scalable and biologically realistic approach to discover gene regulatory network with thousands of genes from perturbation data. Given that dynamical systems are well-established for modeling gene regulation and have seen substantial success for single trajectory inference, PerturbODE presents a compelling alternative to traditional SCM methods. Using a two-layer neural network with sigmoid activation, we can achieve a close approximation of the actual cellular regulatory processes. Our framework ensures both strong predictive performance and biological interpretability of the learned parameters. For GRN inference, PerturbODE outperforms existing scalable methods on SERGIO-simulated datasets and large-scale single-cell experiments, while performing competitively against state-of-the-art methods, such as DCDI. It is also capable of predicting cellular responses to unseen perturbations. Future work will focus on understanding the conditions under which identifiability is assured to further solidify PerturbODE's theoretical foundations."}, {"title": "6 APPENDIX", "content": "6.1 PREPROCESSING\nThe scRNA-seq gene expression matrix is normalized per cell by 104 and log(1 + X) transformed. The total gene expression vector comprises RNA counts for N genes consisting of all the TF over-expression genes j and the top k = 817 variable genes.\nFor each TF gene j, we perform a Mann-Whitney U test on differential gene expression of TF j between the unperturbed control samples in X0 and over-expressed samples in Xj consisting of nj cells. The returned p-value pj from the U test determines whether over-expression of the targeted TF gene j is sufficiently induced in the experiments. The dataset is then filtered based on the criteria D = {Xj | pj < 0.1 and nj \u2265 10, \u2200j \u2208 {1, 2, . . ., M}}.\nOver-expression distributions of the genes encoding the GRNs of interest are added to the training and validation dataset. In addition, when training for GRN inference only without trajectory prediction, distributions of TF over-expression encoded by the marker genes of the cell types or the developmental role targeted by the genes in the GRNs are included in the joint train, test, and validation dataset.\nWe design a train-test split based on TF over-expression genes to select Dtrain, val and Dtest. For each Xj\u2208 Dtrain,val where nj \u2265 100, we apply a 80% to 20% training-validation split of the over-expression samples. If nj < 100, we would use all the samples in Xj for Dtrain due to an insufficient number of training samples.\nFurthermore, we apply the log1p transformation to prevent negative predictions of gene expression and mitigate length biases in expression counts (Gorin and Pachter, 2023). This transformation results in a substantial improvement in model performance."}, {"title": "6.2 MODEL SPECIFICATIONS", "content": "PerturbODE utilizes adaptive Runge-Kutta of order 5 of Dormand-Prince-Shampine which provides an exceptionally high order of accuracy and leverages its adaptive step size for efficient ODE solving. The adaptive step size also detects and handles a wide range of stiff ODEs. Differentiable numerical solution is computed via the adjoint method implemented in PyTorch by Chen (2021), available at https://github.com/rtqichen/torchdiffeq. The Sinkhorn-based W2 distance is differentiable through the GeomLoss implementation in PyTorch (Feydy et al., 2019).\nFor the baseline methods, the authors of DCDFG have implemented DCDI, DCDFG, NO-TEARS, and NO-TEARS-LR in the repository Lopez (2024), available at https://github.com/ Genentech/dcdfg."}, {"title": "6.2.1 THRESHOLDS", "content": "We apply a threshold \u03f5 to the GRN matrix W, where any edge with a weight below \u03f5 is set to 0 and any edge whose weight exceeds \u03f5 is set to 1.\nPerturbODE's \u03f5 threshold is determined using the formula \u03f5 = c\u00b7\u03c3, where \u03c3 represents the standard deviation of the inferred GRN matrix W across all entries, and c is a positive scalar. For SERGIO simulated data with 400 genes, c = 0.1, while for SERGIO simulated data with 100 genes and TF Atlas, c = 0.01. c is chosen so that the PerturbODE predicts a reasonable number of edges (no more than 30% of possible edges). A lower threshold is chosen for the clarity of presentation by getting similar number of edges as DCDI.\nAs recommended by their authors, DCDFG determines the threshold \u03f5 through binary search, using depth of 20 evaluations of an exact acyclicity test to find the largest possible DAG for each method. NO-TEARS and NO-TEARS-LR's \u03f5 are chosen to be 0.3 while DCDI's is set to 0.5 as recommended by the respective authors. For DCDI, NO-TEARS and NO-TEARS-LR different thresholdings such as binary search are attempted without meaningful change to the result. Different fixed values for \u03f5 were also experimented for DCDFG without improvements."}, {"title": "6.2.2 HYPERPARAMETERS", "content": "Spectral radius is used as the DAG constraint for DCDI, DCDFG, NO-TEARS, and NO-TEARS-LR. Notably, NO-TEARS and DCDI fail to run at dimensions higher than tens of variables with the trace exponential constraint, making experiments using the original DCDI implementation infeasible. As recommended by the authors, we set the optimizer learning rate to 0.001 and the regularization coefficient to 0.1.\nThe number of modules is optimally set to 10 for NO-TEARS-LR and DCDFG. For PerturbODE, we set the number of modules to 100 for simulated data and 200 for TF Atlas. Details on performances across different number of modules in all models can be found in Figure 10.\nAs the number of modules increases, the model becomes closer to approximating the full graph. On the TF Atlas dataset, we demonstrate that the validation loss for PerturbODE decreases as the number of modules increases, plateauing after reaching 200 modules when training on TF Atlas (Fig. 8)."}, {"title": "6.3 COMPARISON TO ERD\u0150S-R\u00c9NYI RANDOM GRAPHS", "content": "We generate 10,000 random graphs with the same density as our inferred GRN to numerically simulate the test statistics under Erd\u0151s-R\u00e9nyi random matrices. The p-value is calculated using the equation,\np-value = $\\frac{1 + #{T^* > T}}{1 + \u03a0}$\nwhere is the test statistic, \u03a0 indicates the total number of random graphs, and T* denotes the test statistics computed from each graph. The p-value quantifies how often a test statistic is observed (or a more extreme one) purely by chance.\nWhen evaluating SERGIO simulated data, the test statistics used is the F1 score, whereas recall score is used for TF Atlas due to availability of only positive benchmark edges. To identify gene modules, we use test statistics based on the count of incoming edges to the module and outgoing edges from the module that are consistent with known regulatory relationships. Further, to identify the network motif of negative auto-regulation, test statistics is the number of negative self-loops."}, {"title": "6.4 SAMPLING FROM LINEAR SCMS FOR TF ATLAS", "content": "For a learned GRN represented by W (ensured to be a DAG, or thresholded to enforce acyclicity), we sample from linear structural causal models (SCMs) using the following procedure. First, for each parent gene i (master regulator) in the GRN, if not over-expressed, its expression level Xi is sampled from a normal distribution, Xi ~ \u039d(\u03bc, \u03c3), where \u03bc and \u03c3 represent the mean and standard deviation of gene expression levels across all genes and cells in the TF Atlas, respectively. If Xi is over-expressed, it is instead sampled from Xi ~ \u039d(\u03bc\u03b3, \u03c3\u03b3) where \u03bc\u03b7 and \u03c3\u03b3 are the mean and standard deviation of gene expression levels in over-expression genes across all over-expressed cells.\nDownstream genes are realized in Equation 7:\nX\u2081 = $\\sum_{X_j\\in pa(X_i,W)} W_{ji}X_j,$\nif Xi is not over-expressed,\nX\u2081 = $\\sum_{X_j\\in pa(X_i,W)} W_{ji}X_j + V_i, \\gamma_i ~ N(\\mu_{\\gamma} - \\mu,\\sigma_{\\Delta \\gamma}),$\nif Xi is over-expressed,\nwhere \u03c3\u0394\u03b3 is the standard deviation of the differences between over-expressed genes and mean expression levels (average over genes) across all over-expressed cells. Further, pa(Xi, W) denotes all the parent genes (regulators) of gene i in the GRN W."}, {"title": "6.5 ADDITIONAL RESULTS", "content": "6.5.1 MEAN AND STANDARD DEVIATION OF RESULTS"}, {"title": "6.5.2 PREDICTION ON UNSEEN INTERVENTIONS (INDIVIDUAL TFS)", "content": ""}, {"title": "6.5.3 NUMBER OF EDGES PREDICTED", "content": ""}, {"title": "6.5.4 GRN INFERENCE RESULTS WITH DIFFERENT NUMBER OF MODULES", "content": ""}, {"title": "6.6 ABLATION STUDY", "content": "6.6.1 PREDICTION ON UNSEEN INTERVENTION ALL UMAP AND PCA PLOTS"}, {"title": "6.7 PERTURBODE MODEL TRAINING", "content": "After training, the average W2 distance on both the training and held-out validation datasets decreases significantly and converges. The convergence rate of the W2 distance varies for each TF in the training and validation sets."}, {"title": "6.8 GROUND TRUTH GRNS FROM TF ATLAS", "content": "The three GRNs with high confidence inferred in Joung et al. (2023) are consistent with their induced cell types and roles in development. GRHL1 and GRHL3 target TFAP2C and the TEAD family of TFs to induce trophoblasts, while FLI1 targets AP-1 family TFs (such as JUN and FOS) and ETV2 to induce vascular endothelial cells (Krendl et al., 2017; Dejana et al., 2007). The GRN consisting of CDX1, CDX2, and HOXD11 influences posterior HOX genes is known to contribute to the definition of the anterior-posterior axis (Neijts et al., 2017). The three GRNs are in Figures 17, 18, 19."}, {"title": "6.9 SERGIO SIMULATION", "content": "SERGIO proposes simulation of scRNA-seq data by sampling a directed acyclic GRN through a SDE (Dibaeinia and Sinha, 2020). Although SERGIO does not support interventional data, we modified its framework to simulate gene over-expression with perfect interventions (CRISPR-a). For each interventional regime I \u2208 I, the SDE is parameterized in the following Equation 8.\ndXt = $(M P_j(X_t) - \\lambda X_t ) + (\\sum_{j \\in I} \\gamma_j \\delta_j ) dt + q^o (\\sqrt {P_j(X_t)}dW_a + \\sqrt{\\lambda X_t} dW_p)$\nThe infinitesimal change of expression level (which is the stochastic process Xt) of gene j at time t over an infinitesimal time interval dt, denoted as (dXt)j, is governed by its production rate Pj(Xt), which is modulated by its regulators according to a given GRN in Equation 9. It also depends on the decay rate \u03bb \u2208 R and the noise amplitude q \u2208 Rd influencing its transcriptional variability. M and  \u03a3j\u2208I \u03b3j \u03b4j are the masking matrix and the over-expression term analogous to those in Equations 1 and 2.\nPj(X) = $\\sum_{j=0}^d p_{ji}(X) + b_j$\nfor pji in 10, 11"}, {"title": "6.10 GENE MODULE EXAMPLE: FLAGELLA OF E. COLI", "content": "It is well established that the regulatory circuit responsible for the production of E. coli follows the network motif of multiple-output Feedforward Loop (Alon, 2006, pp. 64-68). Its circuit is shown on the left of Figure 20, where FlhDC and FliA regulate Z1, Z2, and Z3, which are operons encoding the proteins that make up the flagella of E. coli. (In fact, there are in total 6 operons for this process.) Each operon consists of a group of genes, and it is regulated by a weighted sum of non-linearly activated signals from FlhDC and FliA through Hill functions.\nThe order in which the operons are activated matches the order of proteins needed to assemble the flagella. The timing of activation is achieved by different activation thresholds in the Hill functions. If Z1 is activated before Z2, which is activated before Z3, then K2 < K3 < K4. In other words, Z1 needs a lower concentration of FliA to be switched on. For example, Z1 would include the group of genes encoding the proteins for MS ring (base of flagella) and Z3 would be for the filament (tail of flagella). In PerturbODE, the activation threshold is tuned by the bias term, \u03b2, to the hidden neurons.\nThis structure can be represented in a two-layer MLP shown on the right of Figure 20. Each operon Zi is regulated by the weighted sum of signals from two modules Mi and M. The signals from FliA and FlhDC are first activated by Hill functions with different activation thresholds before being transferred to modules Mi and M respectively.\nTo represent this gene regulatory circuit with an adjacency matrix W = A diag(\u03b1\u25cb1N)B, we multiply the two coefficient weight matrices of the MLP with an additional scaling to account for the rate of activation controlled by a."}, {"title": "6.11 STATISTICAL INFERENCE: GENERALIZABILITY AND STABILITY ANALYSIS", "content": "For stability analysis, we bootstrapped (sampled with replacement) TF Atlas dataset 105 times to evaluate consistency in the edges selected by PerturbODE. We also filtered the list of TFs perturbations that PerturbODE trains on down to the TFs pertinent to the ground truth GRNs in order to reduce training time. Then the gene expression space is the union between the filtered TF list and the top 50"}, {"title": "6.12 GENE ENRICHMENT ANALYSIS", "content": "We performed gene enrichment analysis using the Reactome Pathway Database (2022) and the Gene Ontology Biological Process (2021) with hypergeometric test. The examined pathways were filtered to those relevant to the anterior-posterior axis and vascular endothelial cells. The upstream genes and downstream genes of each module are selected by taking those edges whose weights are greater than 2 standard deviations of B and A respectively. Figure 24 illustrates the clustering of modules based on specific functions. A significant number of modules exhibit enrichment for anterior-posterior specification- a pathway crucial in development. This observation is expected, considering that the TF Atlas comprises human embryonic stem cells.\nTo show that the modules are not selecting identical genes, we plotted histograms of genes selected by various modules. Figure 22 shows a histogram of genes selected by the highlighted modules we selected for evaluation in Section 4.2.3, and Figure 23 showcases that of 10 randomly selected modules. Both histograms show clear clustering of gene selections by modules."}]}