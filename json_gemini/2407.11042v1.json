{"title": "An Automated Approach to Collecting and Labeling Time Series Data for Event Detection Using Elastic Node Hardware", "authors": ["Tianheng Ling", "Islam Mansour", "Chao Qian", "Gregor Schiele"], "abstract": "Recent advancements in IoT technologies have underscored the importance of using sensor data to understand environmental contexts effectively. This paper introduces a novel embedded system designed to autonomously label sensor data directly on IoT devices, thereby enhancing the efficiency of data collection methods. We present an integrated hardware and software solution equipped with specialized labeling sensors that streamline the capture and labeling of diverse types of sensor data. By implementing local processing with lightweight labeling methods, our system minimizes the need for extensive data transmission and reduces dependence on external resources. Experimental validation with collected data and a Convolutional Neural Network (CNN) model achieved a high classification accuracy of up to 91.67%, as confirmed through 4-fold cross-validation. These results demonstrate the system's robust capability to collect audio and vibration data with correct labels.", "sections": [{"title": "1 Introduction", "content": "Event detection has become a popular topic in pervasive computing [1], enabling intelligent systems to interpret environmental contexts and adapt config-urations within various spaces, for example, offices or kitchens [2,3]. Traditional IoT methods often utilize multiple types of indirect sensor data, such as audio and vibrations [4], which are processed through Deep Learning (DL) models for event recognition.\nSufficiently labeled datasets are necessary to train DL models effectively [5]. Typically, data streams are segmented and annotated with labels [6]. One common approach to collecting these datasets involves transmitting sensor data to the cloud [7], where labeling algorithms are applied [8], or storing the data streams for subsequent manual labeling by human workers [9]. Both methods, however, introduce significant delays and dependencies on external resources.\nInstead of transmitting data while collecting them, we propose a local pro-cessing approach. Given that IoT devices generally possess limited processing power [10], applying complex labeling algorithms in real-time during data col-lection poses significant challenges. To overcome this obstacle, we have developed a novel embedded system designed to collect and automatically label data using light-weight methods. This approach significantly reduces the need for continu-ous data transmission, aligning with the constraints of power, energy, and latency typical in the IoT context. The main contributions of this research include:\nWe designed an integrated hardware system equipped with various sensors and an SD card slot to facilitate on-device data and label storage. We also included additional labeling sensors to ensure accurate and efficient event detection.\nWe developed software that features a predefined set of labels. The labeling process is automated through an interrupt- and threshold-based detection mechanism, significantly simplifying the computation required for label ex-traction.\nWe validated the efficacy of our collected dataset through experiments with event classification using a Convolutional Neural Network (CNN) model. On our custom dataset across three event types, our model achieved up to 91.67% test accuracy, verified through 4-fold cross-validation.\nThe remainder of this paper is organized as follows: Section 2 reviews relevant literature, setting the stage for our research. Section 3 details our hardware design, while Section 4 discusses the software implementation. Section 5 presents experiment setups and analyzes our findings. Finally, Section 6 concludes the paper and outlines directions for future research."}, {"title": "2 Related Work", "content": "Previous studies predominantly relied on human involvement in the recording and labeling process, which not only complicates the procedure but also increases costs and the potential for errors during manual operations.\nSpecifically, Koch et al. [11] manually controlled the start and stop of record-ings for each event. While this method minimizes storage requirements, it intro-duces complexity and heightens the risk of human error. In contrast, Anand et al. [12] implemented continuous data recording with post-collection labels based on timestamps and event types. This method simplifies the recording process but often accumulates large volumes of irrelevant data, leading to inefficient storage usage, especially when events are infrequent. Furthermore, while humans can feasibly label audio data by listening, this approach is impractical for vibration data.\nIn response to these challenges, our research introduces a novel automated system that significantly reduces the need for manual intervention by automating the collection of reference labels. Our approach utilizes additional sensors that only need light-weight computation to determine the event type locally. With"}, {"title": "3 Hardware System Design", "content": "In this study, we propose a hardware platform named Elastic Node Sensor Log-ger. Figure 1 illustrates the architecture of our hardware platform, centered around the RP2040, an ARM Cortex-M0+ Microcontroller Unit (MCU) known for its low power consumption. In addition, its performance is sufficient for run-ning FreeRTOS to make our multi-task scheduling easier than just using a bare-metal setup. This MCU also owns enough analog and digital I/O capabilities, which are crucial for managing the various sensors and storage modules incor-porated into our system.\nOur system includes two categories of sensors: feature and labeling sensors. The feature sensors are supposed to monitor the events indirectly. There is a Pulse Density Modulation (PDM) microphone for collecting audio data, and an Inertial Measurement Unit (IMU) programmed as an accelerator meter for collecting vibration data. Their sampling frequency is a parameter that the user can adjust. This configuration facilitates the generation of time series data, which is vital for training our DL models.\nFor event labeling, we utilize a reed sensor and a current sensor. The reed sensor detects door states by issuing a rising edge interrupt to the MCU when the door opens and a falling edge interrupt upon closing. Concurrently, the current sensor monitors the power consumption of a kettle. We use the analog-to-digital converter on MCU to detect the 'water has boiled' event based on a predefined current threshold (zero). In addition, a lower-power Real Time Clock (RTC) is embedded in the board to provide the timestamp for events.\nAdditionally, an SD Card, connected to the MCU via the Serial Peripheral Interface, has been configured to operate at a writing speed with a clock fre-"}, {"title": "4 Software Implementation", "content": "The main software loop, executed on the MCU, is depicted in Figure 2. At the outset, we initialize the sensor drivers and mount the SD card, setting the stage for data collection.\nTo optimize memory management and processing efficiency, we implement a ping-pong buffer strategy on the MCU for handling sensor data, a method akin to that described in [13]. Data is initially collected in the 'ping' buffer until it reaches capacity. At this point, data storage is switched to the 'pong' buffer. This cycle alternates to ensure continuous data acquisition. Upon filling either buffer, a Direct Memory Access (DMA) is triggered to transfer the data to the SD card, thereby offloading the data writing task from the MCU. This setup ensures that the SD card's write speed surpasses our data acquisition rate and provides ample buffer time to prevent overwriting and maintain data integrity.\nThe system has three event flags, two set by external interrupt callbacks and the third by a threshold-based trigger following ADC readings in a separate periodic task. This event detection logic is straightforward and computationally efficient, avoiding disruptions in data collection.\nThe system checks for flagged events once the DMA completes the data transfer from one buffer. If an event has been flagged, the corresponding label is immediately written to the SD card. The recording file may be closed promptly or left open for several seconds to capture additional post-event data, and the duration of the continuous recording is user-configurable."}, {"title": "5 Experiments and Results", "content": "Building upon the hardware system design outlined in Section 3, we success-fully implemented the hardware platform as depicted in Figure 3. Utilizing this hardware and following the software implementation described in Section 4, we conducted multi-sensor data collection and labeling directly on our hardware platform. Subsequently, the collected dataset underwent preprocessing and val-idation on a desktop computer.", "subsections": [{"title": "5.1 Multi-Sensor Data Collection", "content": "The data collection process solely requires the use of the Elastic Node Sensor Logger hardware. As mentioned in Section 4, once the recording process initi-ates, our system simultaneously collects data from the microphone and the IMU sensor. The labeling sensors operate in the background as described. The audio data is captured at a sampling rate of 16 kHz in a mono-channel format. The"}, {"title": "5.2 Data Preprocessing", "content": "Before we fed our custom dataset to the model, audio and vibration data were preprocessed separately to accommodate their unique characteristics. Audio recordings were read from WAV files using torchaudio [14]. To standardize the lengths of these recordings, zero-padding was symmetrically applied to both ends to have the same length as the longest audio data in the dataset. For feature extraction, we transformed the recordings into Mel spectrograms using the following parameters: Nmels = 64, nfft = 1024, with hoplength at default settings, and topdb = 80 for dynamic range compression. Figure 4 displays these spectrograms for three events, showcasing their distinct spectral characteristics. For example, door-related events exhibit short-term peaks along the time axis and a broader range of frequency coverage compared to kettle-boiling events. Furthermore, distinguishable patterns are evident between door opening and closing events, such as the longer duration of closing events compared to opening events.\nVibration recordings, comprised of channel measurements, varied in length across samples. We addressed this by applying a zero-padding strategy similar to that used for audio data. In instances of missing values, we imputed these by calculating and using the mean of the respective dimension. Figure 5 displays the visualization of vibration data, categorized in terms of the three sample events. Distinct patterns are identifiable between the door-related events, and there is a clear difference between these and the water-boiling events in the time domain."}, {"title": "5.3 Data Validation", "content": "To verify the quality of the collected data and the accuracy of labeling, we conducted a three-class classification task based on audio and vibration data. We consider the quality of our collected dataset to be high if the collected data and labels can train a deep learning model to converge and achieve test high accuracy. We split the entire dataset into training, validation, and testing sets in a 3:1:1 ratio. Afterward, we utilized an oversampling strategy to balance the distribution of samples across different labels for both data types. Training and validation sets underwent a 4-fold cross-validation process. Moreover, we computed the mean and standard deviation based on the training set to normalize all datasets.\nWe adopted a simple CNN model for event classification under the PyTorch framework. As depicted in Figure 6, this model features two convolutional lay-ers, with the first layer having 64 filters and the second 32 filters using a kernel"}]}, {"title": "6 Conclusion and Future Work", "content": "Our study successfully developed a robust approach for autonomously labeling sensor data directly on IoT devices. Experiments demonstrated that our models achieved up to 91.67% test accuracy in controlled settings, highlighting the high quality of our sensor data and the reliability of our labeling approach. This method significantly improves the feasibility of collecting and processing large-scale IoT data in diverse field environments, enhancing efficiency and accuracy.\nIn our ongoing efforts to enhance event detection capabilities, we plan to integrate additional types of feature sensors into our system. This expansion will enable the support and recognition of a broader array of event types, further improving the versatility and applicability of our solution in diverse scenarios. By broadening the sensor array, we aim to capture more comprehensive feature data from the device surroundings, significantly refining our system's responsiveness and accuracy in real-world applications."}]}