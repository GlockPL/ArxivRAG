{"title": "Rethinking Transformer-based Multi-document Summarization: An Empirical Investigation", "authors": ["Congbo Ma", "Wei Emma Zhang", "Dileepa Pitawela", "Haojie Zhuang", "Yanfeng Shu"], "abstract": "The utilization of Transformer-based models prospers the growth of multi-document summarization (MDS). Given the huge impact and widespread adoption of Transformer-based models in various natural language processing tasks, investigating their performance and behaviors in the context of MDS becomes crucial for advancing the field and enhancing the quality of summary. To thoroughly examine the behaviours of Transformer-based MDS models, this paper presents five empirical studies on (1) measuring the impact of document boundary separators quantitatively; (2) exploring the effectiveness of different mainstream Transformer structures; (3) examining the sensitivity of the encoder and decoder; (4) discussing different training strategies; and (5) discovering the repetition in a summary generation. The experimental results on prevalent MDS datasets and eleven evaluation metrics show the influence of document boundary separators, the granularity of different level features and different model training strategies. The results also reveal that the decoder exhibits greater sensitivity to noises compared to the encoder. This underscores the important role played by the decoder, suggesting a potential direction for future research in MDS. Furthermore, the experimental results indicate that the repetition problem in the generated summaries has correlations with the high uncertainty scores.", "sections": [{"title": "1 Introduction", "content": "The innovation and contemporary developments of Transformer architecture (Vaswani et al., 2017) thrives multi-document summarization (MDS) (Ma et al., 2022a). This motivates us to study the behaviors of the Transformer structure MDS models. Through these analyses, we aim to provide a thorough understanding of MDS and its intricacies within the MDS model framework. We undertake a comprehensive investigation from five distinct perspectives covering the Transformer-based MDS model design pipeline: (1) Document input perspective: we conduct experiments to quantitatively assess the impact of document boundary separators from a standpoint of document input; (2) Transformer structure perspective: we explore the effectiveness of different mainstream Transformer structures; (3) The significance of encoder and decoder perspective: we design empirical studies by adding noises on top of the encoder and decoder; (4) Training strategy perspective: we restructure the source documents and include self-supervised learning; (5) Summary generation perspective, we explore the uncertainties when repetition problems occur in the summary generation process.\nThe primary distinction between SDS and MDS lies in the variance of source document numbers. One straightforward way that convert MDS to SDS is concatenating text spans and processing them as a flat sequence (Liu et al., 2018; Chu and Liu, 2019; Brazinskas et al., 2020; Mao et al., 2020; Zhao et al., 2022). One way to aid the models in detecting and modeling document-to-document relationships in one flat sequence is to utilize document boundary separators (Fabbri et al., 2019; Xiao et al., 2022). However, there is a notable gap in the current literature regarding a qualitative and quantitative examination of the influence of document boundary separators. This absence of exploration serves as the driving force behind our initiative to investigate whether these separators contribute to enhanced model performance and foster awareness of document boundaries within the feature space of MDS models. Through experiments conducted on three distinct Transformer structures, we discerned that the impact of document boundary separators varies among models with differing hierarchies. Uncertainty analysis is a pivotal approach employed in the examination and assessment of generation systems (Xu et al., 2020) which can serve as an important indicator to show how the model performs during the summary generation."}, {"title": "2 Methodology", "content": "We introduce how to design the MDS experiments from the following angles: input data, Transformer structures, training strategies and summary generation. Therefore, we design five experiments to evaluate the behaviors of Transformer-based MDS models: (1) the measurable impact of document boundary separators; (2) the effectiveness of different Transformer structures; (3) the sensitivity of the encoder and decoder; (4) different training strategies; (5) repetition in document generation."}, {"title": "2.1 The Measurable Impact of Document Separators", "content": "We modify the source documents instead of the summarization models to the format of: \\(D = {d^1, s, d^2, s, ..., s, d^N}\\), where \\(N\\) is the number of documents in a document set \\(D\\), the superscript \\(d^n\\) represents the n-th document in the set, and \\(s\\) denotes the special tokens. We investigate different Transformer models on two MDS datasets and eleven evaluation metrics to explore the impact of the document boundary separators qualitatively and quantitatively. We analyze and compare the prediction uncertainty from different datasets and different formats of source documents by inspecting entropy values during summary generation. We aim to understand how decisions by adding document boundary separators are reflected in the model's uncertainty. In the generation process, each predictive position \\(X_i\\) has an outcome probabilistic distribution \\(X_{i1}, ..., X_{im}\\), \\(m\\) is the number of a corpus pool. We use entropy as an uncertainty measurement which can be calculated as follows:\n\\[H(X) = - \\sum_{j=1}^{m} P(x_{ij}) \\log P(x_{ij})\\qquad(1)\\]\nBecause the size of the corpus pool is large and the prediction distribution is usually long-tailed (Xu et al., 2020), we sort the prediction distribution \\(X_i\\) in descending order and get a minimal set of tokens where the sum prediction values are larger than 0.95, and then normalize the distribution. We calculate the entropy value based on the new distribution \\(P'(x_{ij})\\). The utilization of entropy as a measure allows us to gauge the distribution of probabilities across different tokens within the predictive positions of the summaries. Higher entropy values indicate a wider spread of probabilities, suggesting that the model is less certain about the most appropriate token to choose. Conversely, lower entropy values suggest that the model is more confident in its token predictions. The quantification of uncertainty through entropy measurements and its qualitative analysis enables us to assess how the introduction of document boundary separators influences the performance of the summaries generated by Transformer-based models. This holistic approach helps us unravel the nuanced impact of document boundary separators on the MDS process and gain valuable insights into the behavior of these models in handling multiple document inputs."}, {"title": "2.2 The Effectiveness of Different Transformer Structures", "content": "Transformer structures have become an essential component of many state-of-the-art natural language processing models. However, the design of the Transformer architecture can vary dramatically, and different structures may impact the performance of the model on different tasks. In this study, we aim to evaluate the effectiveness of different Transformer structures for MDS tasks. Specifically, we focus on two types of structures: flat Transformer and hierarchical Transformer.\nThe flat Transformer consists of a single layer of self-attention and feed-forward neural network layers that process the input tokens sequentially. In contrast, the hierarchical Transformer has a more complex structure, where the input tokens are first grouped into sentences or documents, and then processed by local and global Transformer layers. To explore the hierarchical Transformer structure, we investigate two different granularities of high-level Transformer: sentence-level and document-level. Building on the work of Liu (Liu and Lapata, 2019), we make modifications to the local Transformer layers to encode individual documents. The global Transformer layers are then able to exchange information at the sentence or document level.\nOur analysis is motivated by the need to better understand how different Transformer structures can impact the performance of MDS models. By comparing the performance of the flat Transformer and hierarchical Transformer structures, we aim to identify which structure is more effective for multiple document summarization data."}, {"title": "2.3 The Sensitivity of Encoder and Decoder", "content": "In summarization tasks, the encoder plays a crucial role in extracting representations from the input text, while the decoder is responsible for generating the output summary, which requires producing coherent and meaningful language. Given the intricate nature of summary generation, the decoder's role demands fine-grained control and precision, making it potentially more sensitive than the encoder. To explore the sensitivity of the encoder-decoder in Transformer-based summarization models, we add Gaussian noise at the parameter space of the encoder or decoder. We devise this experiment based on the intuition that a module (whether it's the encoder or decoder) exhibits varying sensitivity to noise, thereby signifying the differing degrees of importance each module holds for overall performance. Formally, we have:\n\\[z = f(x; \\Theta + \\alpha \\eta), \\eta \\sim \\mathcal{N}(\\mu, \\delta)\\qquad(2)\\]\nwhere \\(f(\\cdot)\\) is the component in Transformer; \\(\\Theta\\) is the parameters in \\(f(\\cdot)\\); \\(\\eta\\) represents Gaussian noise; \\(\\mu, \\delta\\) are mean and variance in the Gaussian noise, \\(\\alpha\\) is the weighted factor."}, {"title": "2.4 Different Training Strategies", "content": "In this study, we aim to investigate the impact of different training strategies on Transformer models for abstractive summarization. While we have previously examined the components of Transformer models, the specific influence of training strategies remains unexplored. Our objective is to identify the most effective training strategies by leveraging the inherent characteristics of MDS datasets, without the need for external data sources. To create pseudo data utilizing the characteristic MDS, we adopt a straightforward approach. We treat one document from a given document set as a pseudo-summary while considering the remaining documents as input documents. This process is iterated, systematically selecting each document in the set as a pseudo-summary, until all input documents have served as pseudo-summaries. Consequently, we generate multiple sets of pseudo-document-summary pairs, which we refer to as pseudo-MDS dataset. The original MDS dataset is denoted as the original dataset in the subsequent analysis.\nTo evaluate the effectiveness of different training strategies, we design three distinct approaches. Firstly, we train the MDS model exclusively on the pseudo dataset. Secondly, we mix the pseudo dataset with the original dataset, creating a comprehensive mega dataset, on which the MDS model is trained. Lastly, we employ a two-step process, initially training the model on the pseudo dataset and subsequently fine-tuning it on the original dataset."}, {"title": "2.5 Repetition in Document Generation", "content": "For abstractive MDS, a persistent challenge arises from the inclination of models to produce repetitive sentences or words during the summarization process. This tendency creates a loop that is difficult to break, hampering the generation of accurate summaries. To analyze what may cause repetitive problems, we delve into an analysis of prediction uncertainty, examining uncertainty scores throughout the generation process and localizing uncertainty to certain positions in a repetition behavior.\nTo quantify uncertainty, we employ Equation 1, which calculates the uncertainty score for each time slot during the summarization generation. By applying this equation, we obtain a measure of uncertainty that corresponds to the level of doubt or ambiguity associated with the generated output. The analysis focuses on observing how the uncertainty score evolves in response to the occurrence of repetition phenomena."}, {"title": "3 Empirical Studies and Analyses", "content": "We evaluate the performance of three Transformer models: Vanilla Transformer (VT) (Vaswani et al., 2017), Vanilla Transformer with copy mechanism (VTC), and modified Hierarchical Transformer (HT) (Liu and Lapata, 2019). These models are assessed on two widely used MDS datasets: Multi-XScience (Lu et al., 2020) and Multi-News (Fabbri et al., 2019). To comprehensively analyze their performance, we employ eleven evaluation metrics: ROUGE (Lin, 2004) including ROUGE-1 (R-1), ROUGE-2(R-2), ROUGE-L (R-L), ROUGE-SU (R-SU), ROUGE-WE (R-WE) (Ng and Abrecht, 2015), BLEU (Papineni et al., 2002), S\u00b3 (Peyrard et al., 2017) including pyramid (pyr) and responsiveness (resp) scores, BertScore (BS) (Zhang et al., 2020), Relevance (Rel) (Peyrard, 2019), Redundancy(Red) (Peyrard, 2019)."}, {"title": "3.2 Impact of Document Separators", "content": "We investigate the VT, VTC, and HT models on both datasets and report the eleven evaluation metrics to explore the impact of the document boundary separators. From Table 1, interestingly, we find that adding separators reduces models' performance in half of the cases (3 out of 6). For example, model VT with separators performs relatively worse on Multi-News (the results of 8 evaluation metrics are worse among 11 evaluation metrics); model VTC performs relatively worse on both Multi-XScience (the results of 9 evaluation metrics are worse among 11 evaluation metrics) and Multi-News (the results of 8 evaluation metrics are worse among 11 evaluation metrics) when with separators. These results indicate input documents with separators are not very helpful for flat Transformer models. However, we can perceive that the HT model achieves better performance on both datasets with document boundary separators.\nAnother interesting finding is the most commonly used ROUGE, in a few cases, shows the opposite result from other evaluation metrics. For instance, on the Multi-XScience dataset, the VT (with document boundary separators) shows better ROUGE results than VT (without document boundary separators) but contradicts the results on \u201cR-WE\", \u201cBLEU\u201d, \u201cS\u00b3\u201d, \"BertScore\", \"Redundancy\u201d and \"Relevance\". It indicates that the ROUGE-centric evaluation system needs to be updated and the measurement of summarization can not rely solely on ROUGE.\nWe also discover the relations between document boundary separators and token uncertainty scores. Figure 1 shows the uncertainty scores of generated tokens of VTC models on both datasets. Surprisingly, the figure reflects that separators are associated with high uncertainty score actions which means the separators increase the predictive uncertainty of models. Possible because the separators have no semantic relations with the source documents and separators may be regarded as noise to increase the predictive uncertainty. The median uncertainty score of the Multi-News is larger than the Multi-XScience aligning with the size of datasets.\""}, {"title": "3.3 Quantitative Performance on Different Transformer Structures", "content": "We investigate (1) the effectiveness of different Transformer architectures: flat Transformer (VT,VTC) and hierarchical Transformer (HT); (2) the influences of different granularities within hierarchical Transformer structure. The results are also found in Table 1. In most evaluation metrics, the HT model can not achieve as good results as two flat Transformer models on both datasets. The two potential reasons are: (1) the pipeline of the HT model is longer than the flat Transformer models which makes the HT model hard to train. (2) the Multi-XScience and Multi-New datasets are not long document summarization datasets. The average document length of Multi-XScience and Multi-New are 778.08 and 2103.49. From the experimental results, we can conclude that the HT model is more suitable for lengthy documents, implying that flat Transformer models are a good choice for tasks with shorter documents.\nAs mentioned in Section 2.2, to evaluate the influences of different granularities within the hierarchical Transformer structure, we modify the local Transformer layers to encode individual documents. Figure 2 shows the performances of document-level and sentence-level HT models. All the metrics are showing better performances with the document-level HT compared to the sentence-level HT as the green line exceeds the boundary of the orange line in every dimension (redundancy is the lower the better). The apparent trend implies that a higher level of granularity is more favorable for the hierarchical Transformer structure."}, {"title": "3.4 Quantitative Performance on the Sensitivity of Encoder and Decoder", "content": "To investigate the hypothesis in section 2.3, we select the VTC model as the foundation for evaluating the effectiveness of the encoder-decoder structure on the Multi-XScience and Multi-News datasets. By examining Table 2, we observe large differences in performance when introducing noise to the encoder and decoder in highly noisy scenarios (with \\(\\alpha = 1e-1\\) and \\(\\alpha = 1e-2\\)). Specifically, in noisy conditions, we find that adding noise to the decoder has a more substantial impact on performance compared to adding noise to the encoder. However, as the noise levels decreased, the performance gaps between the two approaches narrowed. This observation supports our initial hypothesis that the decoder is more sensitive than the encoder. The potential reasons are: (1) errors or inaccuracies in the decoder can have a cascading effect on subsequent tokens generated during decoding. This error propagation phenomenon can make the decoder more sensitive to small perturbations, as any mistakes or noise introduced during decoding can amplify and affect the overall quality of the generated summary; (2) Transformer-based models often employ an attention mechanism that allows the decoder to focus on different parts of the encoded input during the decoding process. The decoder's sensitivity is crucial in effectively attending to relevant information, and even slight perturbations in the encoded input can impact the attention weights and subsequently influence the decoding process. Consequently, it underscores the crucial role played by the decoder in summarization tasks. These findings shed light on the high importance of the decoder's contribution to the overall summarization process."}, {"title": "3.5 Quantitative Performance of Different Training Strategies", "content": "The experimental results presented in Table 3 provide an overview of the performance of the VTC model trained using different pretraining strategies on the Multi-XScience and Multi-News datasets. In the table, the VTC is trained on the original document set and golden summary pairs. The \u201cfinetune\" strategy refers to the training of the model on the pseudo dataset (introduced in Section 2.4) first and then fine-tuning on the original dataset. The \"self-supervised\" strategy denotes training the VTC model exclusively on the pseudo dataset. The \"mix\" strategy illustrates training the model using a combination of the pseudo dataset and the original dataset. By comparing the results obtained from these different training strategies, we aim to identify the most effective approach for each dataset.\nFor the Multi-XScience, the results show that the VTC (pretrain-finetune) strategy outperforms the VTC trained on the original dataset across most metrics, indicating the effectiveness of the pretrain-finetune strategy in improving summarization quality. In contrast, the VTC (self-supervised) exhibits lower performance compared to the VTC (pretrain-finetune), suggesting that just self-supervised training is less effective for this dataset.\nSimilarly, for the Multi-News dataset, the results imply the VTC model achieves good performance across all metrics, with higher scores on the VTC (pretrain-finetune) strategy, showcasing improved summarization quality. Conversely, the VTC (self-supervised) and VTC (mix) strategy yields lower performance compared to the other strategies.\nThe comparison of these different training strategies reveals that the pretrain-finetune approach consistently leads to better summarization performance compared to the baseline VTC model and other training strategy, highlighting its effectiveness in improving summarization quality.\nTo find the potential reason why the finetune strategy works well, we visualize the feature distributions of three training strategies: VTC, VTC (self-supervised) VTC (finetune) using Principal Component Analysis (PCA) as illustrated in Figure 3. For the Multi-News, the features come from the encoder of the VTC (self-supervised) and the VTC (finetuning) exhibits overlapping, while maintaining distance from the plain VTC. In contrast, for the Multi-XScience, the VTC (finetune) is more similar to the plain VTC but still noticeably distinct from the VTC (self-supervised). This observation is consistent with the performance results presented in Table 3. In the case of the Multi-XScience, fine-tuning the model after self-supervised training significantly improves the model's performance compared to the VTC. However, when the model is only pretrained using self-supervised learning, it performs worse than the VTC. This discrepancy can be attributed to the fact that the features of the finetuned model closely align with the VTC model's distribution since both models possess better representations for the final prediction. Conversely, for the Multi-News, the finetuned model exhibits only marginal improvements over the VTC. This observation also explains the overlap between features from the finetuned model and the self-supervised model, as finetuning adjusts the feature distribution towards the 'genuine' distribution, albeit to a limited extent."}, {"title": "3.6 The Relation Between Repetition and Uncertainty", "content": "We examine the correlation between repetition and uncertainty in the process of generating summaries. To assess uncertainty, we compute a score for each token generated. Two summaries are presented: one featuring repetition and the other as a standard summary without repetition. The outcomes are depicted in Figure 4. The X-axis represents token indexes, while the Y-axis illustrates uncertainty scores for each token. In summary #1, where no repetitions occur, the uncertainties of tokens remain within a \u201cnormal\" range. This suggests that the model successfully avoids repetitive patterns, resulting in lower uncertainty scores throughout the summary generation process. Conversely, in summaries #2, we observe a distinct pattern. As the repetition of tokens or phrases begins, the uncertainty scores escalate rapidly.\nBy comparing uncertainty scores across different time slots, we gain insights into the relationship between repetition and uncertainty in abstractive summarization. When a repetition phenomenon occurs, we observe notable changes in the uncertainty score, indicating a correlation between the two factors. Specifically, as the model generates repetitive sentences or words, the uncertainty score tends to increase. This increase in uncertainty suggests that the model becomes less confident and more uncertain about the appropriateness or relevance of the repeated elements within the summary. By understanding this relationship, we can devise strategies to mitigate repetition and subsequently enhance the quality of generated summaries. By reducing uncertainty through the minimization of repetition, we pave the way for more accurate and reliable abstractive summarization."}, {"title": "4 Conclusion and Discussion", "content": "This study attempts to empirically examine the influences on Transformer behaviors from five important perspectives: document boundary separators, Transformer structures, the sensitivity of encoder-decoder architecture, training strategies, and the relationship between repetition and uncertainty in generated summaries. We first explore the impact of separators on two flat Transformer and one hierarchical Transformer structure.\nExperiments indicate that adding separators makes hierarchical Transformers aware of document boundaries, unlike flat Transformers. This suggests that for models handling complex structures, separators can enhance performance. The necessity of adopting separators should be considered depending on the Transformer structure applied.\nThe Transformer structure exploring experiments demonstrate that a higher level of granularity is favorable for the hierarchical Transformer structure. The experiments also demonstrate the simple structure, flat Transformer, has been able to show better performance on the Multi-XScience and Multi-News datasets than the complicated hierarchical Transformer structure. The flat Transformer models are sufficient for MDS tasks with relatively short length of documents.\nFurthermore, adding noise to the decoder affects performance more than adding noise to the encoder. This sensitivity is likely due to error propagation during decoding and the attention mechanism's dependence on accurate encoding. These results emphasize the decoder's crucial role in producing high-quality summaries and its significant impact on the summarization process.\nThe pretrain-finetune strategy that trains the model on the pseudo labels first and then fine-tuning it on the original dataset consistently leads to improved summarization performance when compared to other training strategies. This finding highlights the effectiveness of the pretrain-finetune strategy in enhancing MDS model performance.\nMoreover, the analysis of the relations between repetition and uncertainty provides valuable insights into improving the quality of generated summaries. The findings suggest that as repetition occurs in the summaries, there is a noticeable increase in uncertainty scores. By recognizing this relationship, strategies can be developed to mitigate repetition and reduce uncertainty, ultimately enhancing the overall quality of abstractive summaries. These insights contribute to the advancement of abstractive summarization techniques and open avenues for further research in improving the reliability and effectiveness of summary generation.\nWe also point out the possible exploring direction for future MDS work: (1) evaluate the generated summaries from multiple evaluations; (2) add the higher level of granularity information into the models; (3) investigate the MDS method for particularly long input documents; (4) pay more attention to the decoder when designing the Transformer-based summarization models; (5) try to reduce the Sudden sharp increase and high uncertainty score during the summary generation process."}]}