{"title": "Robust Guided Diffusion for Offline Black-Box Optimization", "authors": ["Can (Sam) Chen", "Christopher Beckham", "Zixuan Liu", "Xue Liu", "Christopher Pal"], "abstract": "Offline black-box optimization aims to maximize a black-box function using an offline dataset of designs and their measured properties. Two main approaches have emerged: the forward approach, which learns a mapping from input to its value, thereby acting as a proxy to guide optimization, and the inverse approach, which learns a mapping from value to input for conditional generation. (a) Although proxy-free (classifier-free) diffusion shows promise in robustly modeling the inverse mapping, it lacks explicit guidance from proxies, essential for generating high-performance samples beyond the training distribution. Therefore, we propose proxy-enhanced sampling which utilizes the explicit guidance from a trained proxy to bolster proxy-free diffusion with enhanced sampling control. (b) Yet, the trained proxy is susceptible to out-of-distribution issues. To address this, we devise the module diffusion-based proxy refinement, which seamlessly integrates insights from proxy-free diffusion back into the proxy for refinement. To sum up, we propose Robust Guided Diffusion for Offline Black-box Optimization (RGD), combining the advantages of proxy (explicit guidance) and proxy-free diffusion (robustness) for effective conditional generation. RGD achieves state-of-the-art results on various design-bench tasks, underscoring its efficacy. Our code is here.", "sections": [{"title": "1 Introduction", "content": "Creating new objects to optimize specific properties is a ubiquitous challenge that spans a multitude of fields, including material science, robotic design, and genetic engineering. Traditional methods generally require interaction with a black-box function to generate new designs, a process that could be financially burdensome and potentially perilous [1, 2]. Addressing this, recent research endeavors have pivoted toward a more relevant and practical context, termed offline black-box optimization (BBO) [3, 4]. In this context, the goal is to maximize a black-box function exclusively utilizing an offline dataset of designs and their measured properties.\nThere are two main approaches for this task: the forward approach and the reverse approach. The forward approach entails training a deep neural network (DNN), parameterized as I\u2084(\u00b7), using the offline dataset. Once trained, the DNN acts as a proxy and provides explicit gradient guidance to enhance existing designs. However, this technique is susceptible to the out-of-distribution (OOD) issue, leading to potential overestimation of unseen designs and resulting in adversarial solutions [5].\nThe reverse approach aims to learn a mapping from property value to input. Inputting a high value into this mapping directly yields a high-performance design. For example, MINs [6] adopts GAN [7] to model this inverse mapping, and demonstrate some success. Recent works [4] have applied"}, {"title": "2 Preliminaries", "content": null}, {"title": "2.1 Offline Black-box Optimization", "content": "Offline black-box optimization (BBO) aims to maximize a black-box function with an offline dataset. Imagine a design space as X = Rd, where d is the design dimension. The offline BBO [3] is:\nx* = arg max J(x). (1)\n\u0395\u03a7\nIn this equation, J(\u00b7) is the unknown objective function, and x \u2208 X is a possible design. In this context, there is an offline dataset, D, that consists of pairs of designs and their measured properties. Specifically, each \u00e6 denotes a particular design, like the size of a robot, while y indicates its related metric, such as its speed.\nA common approach gradient ascent fits a proxy distribution pp(y|x) = N(J\u2084(x),\u03c3\u03c6(x)) to the offline dataset where & denote the proxy parameters:\narg min E(x,y)\u2208D[\u2212log p\u00a2(y|x)].\n\u03a6\n= arg min E(x,y)\u2208D log(\u221a2\u03c0\u03c3\u03c6(x)) + (y - J$(x))2 . (2)\n\u03a6 203(x)\nFor the sake of consistency with terminology used in the forthcoming subsection on guided diffusion, we will refer to pp(\u00b7|\u00b7) as the proxy distribution and J\u2084(\u00b7) as the proxy. Subsequently, this approach performs gradient ascent with J\u2084(x), leading to high-performance designs \u00e6*:\nX7+1 = x+ + nxJp(x)|x=x+, for\u315c\u2208 [0, M \u2013 1], (3)\nconverging to x\u2122 after M steps. However, this method suffers from the out-of-distribution issue where the proxy predicts values that are notably higher than the actual values."}, {"title": "2.2 Diffusion Models", "content": "Diffusion models, a type of latent variable models, progressively introduce Gaussian noise to data in the forward process, while the reverse process aims to iteratively remove this noise through a learned score estimator. In this work, we utilize continuous time diffusion models governed by a stochastic differential equation (SDE), as presented in [10]. The forward SDE is formulated as:\ndx = f(x,t)dt + g(t)dw. (4)\nwhere f(, t) : Rd \u2192 Rd represents the drift coefficient, g(\u00b7) : R \u2192 R denotes the diffusion coefficient and w is the standard Wiener process. This SDE transforms data distribution into noise distribution. The reverse SDE is:\ndx = [f(x,t) - g(t)2\u2207x log p(x)] dt + g(t)dw, (5)\nwith \u2207 log p(x) representing the score of the marginal distribution at time t, and w symbolizing the reverse Wiener process. The score function \u2207 log p(x) is estimated using a time-dependent neural network se(x, t), enabling us to transform noise into samples. For simplicity, we will use so(xt), implicitly including the time dependency t."}, {"title": "2.3 Guided Diffusion", "content": "Guided diffusion seeks to produce samples with specific desirable attributes, falling into two cate-gories: proxy diffusion [11] and proxy-free diffusion [8]. While these were initially termed classifier diffusion and classifier-free diffusion in classification tasks, we have renamed them to proxy diffu-sion and proxy-free diffusion, respectively, to generalize to our regression context. Proxy diffusion"}, {"title": "3 Method", "content": "In this section, we present our method RGD, melding the strengths of proxy and proxy-free diffu-sion for effective conditional generation. Firstly, we describe a newly developed module termedproxy-enhanced sampling. It integrates explicit proxy guidance into proxy-free diffusion to enableenhanced sampling control, as detailed in Section 3.1. Subsequently, we explore diffusion-basedproxy refinement which incorporates insights gleaned from proxy-free diffusion back into the proxy,further elaborated in Section 3.2. The overall algorithm is shown in Algorithm 1."}, {"title": "3.1 Proxy-enhanced Sampling", "content": "As discussed in Section 2.3, proxy-free diffusion trains an unconditionalmodel and conditional models. Althoughproxy-free diffusion can generate samplesaligned with most conditions, it tradition-ally lacks control due to the absence ofan explicit proxy. This is particularly sig-nificant in offline BBO where we aim toobtain samples beyond the training dis-tribution. Therefore, we require explicitproxy guidance to achieve enhanced sam-pling control. This module is outlined inAlgorithm 1, Line 8- Line 16.\nOptimization of w. Directly updating the design \u00e6t with proxy gradient suffersfrom the OOD issue and determining aproper condition y necessitates the man-ual adjustment of multiple hyperparamethrough Eq. (9).\nAlgorithm 1 Robust Guided Diffusion for Offline BBO\nInput: offline dataset D, # of diffusion steps T.\n1: Train proxy distribution p\u2084(y|x) on D by Eq. (2).\n2: Train proxy-free diffusion model se(xt, y) on D.\n3: /*Diffusion-based proxy refinement */\n4: Identify adversarial samples via grad ascent.\n5: Compute diffusion distribution po(y|x) by Eq. (12).\n6: Compute KL divergence loss as per Eq. (13).\n7: Refine proxy distribution p\u2084(yx) through Eq. (15).\n8: /*Proxy-enhanced sampling*/\n9: Begin with \u00e6\u0442 ~ N(0, I)\n10: fort T-1 to 0 do\n11:\n12:\n13:\n14:\n15: end for\nDerive the score \u0161e (xt+1, y, w) from Eq. (6).\nUpdate xt+1 to xt (w) using was per Eq. (7).\nOptimize w to w following Eq. (8).\nFinalize the update of xt with \u0175\n16: Return x* = X0\nters [6]. Thus, we propose to introduceproxy guidance by only optimizing the strength parameter w within \u0161e(xt,y,w) in Eq. (6). Asdiscussed in Section 2.3, the parameter w balances the condition and diversity, and an optimized wcould achieve a better balance in the sampling process, leading to more effective generation.\nEnhanced Sampling. With the score function, the update of a noisy sample xt+1 is computed as:\nxt(w) = solver(Xt+1, \u0160o (Xt+1, Y, W)), (7)\nwhere the solver is the second-order Heun solver [12], chosen for its enhanced accuracy through apredictor-corrector method. A proxy is then trained to predict the property of noise \u00e6t at time stept,denoted as J(xt, t). By maximizing J\u00f8(x+(w), t) with respect to w, we can incorporate the explicitproxy guidance into proxy-free diffusion to enable enhanced sampling control in the balance betweencondition and diversity. This maximization process is:\nw = w + \u03b7 \u03c6(xt(w), t) (8)\n= \u03c9\n\u03b8\u03c9"}, {"title": "3.2 Diffusion-based Proxy Refinement", "content": "In the proxy-enhanced sampling module, the proxy J$(\u00b7) is employed to update the parameter wto enable enhanced control. However, J$(\u00b7) may still be prone to the OOD issue, especially onadversarial samples [5]. To address this, we refine the proxy by using insights from proxy-freediffusion. The procedure of this module is specified in Algorithm 1, Lines 3-7.\nDiffusion Distribution. Adversarial samples are identified by gradient ascent on the proxy as perEq. (3) to form the distribution q(x). We utilize a vanilla proxy to perform 300 gradient ascent steps,identifying samples with unusually high prediction scores as adversarial. This method is based onthe limited extrapolation capability of the vanilla proxy, as demonstrated in Figure 3 in COMs [5].Consequently, these samples are vulnerable to the proxy distribution. Conversely, the proxy-freediffusion, which functions without depending on a proxy, inherently offers greater resilience againstthese samples, thus producing a more robust distribution. For an adversarial sample x ~ q(x), wecompute po(2), po(x|y) via the probability flow ODE, and p(y) through Gaussian kernel-densityestimation. The diffusion distribution regarding y is derived as:\nPo(yx) = po(xy)p(y) , (12)\nPo(x)\nwhich demonstrates inherent robustness over the proxy distribution pp(y|x). Yet, directly applyingdiffusion distribution to design optimization by gradient ascent is computationally intensive andpotentially unstable due to the demands of reversing ODEs and scoring steps.\nProxy Refinement. We opt for a more feasible approach: refine the proxy distribution p\u2084(y|x)N(J\u2084(x), \u03c3\u03c6(x)) by minimizing its distance to the diffusion distribution po(y|2). The distance isquantified by the Kullback-Leibler (KL) divergence:\nEq[D(po||po)] = Eq(x) P(y) log P\u00a2(y|x) dy. (13)\nPo (yx)\nWe avoid the parameterization trick for minimizing this divergence as it necessitates backpropagationthrough po (y), which is prohibitively expensive. Instead, for the sample \u00e2n, the gradient of the KLdivergence D(p4||p\u04e9) with respect to the proxy parameters $ is computed as:\n\u0395\u03c1\u03c6(y) dlog p(yx)\nd\nl (1+log Pp(yx) )\ndy,\n(14)\nComplete derivations are in Appendix A. The KL divergence then acts as regularization in our loss L:\nL(\u03c6, \u03b1) = Ep[\u2212logp\u00a2(y|x)] + &Eq(x)[D(p\u03c6||p\u04e9)], (15)\nwhere D is the training dataset and a is a hyperparameter. We propose to optimize a based on thevalidation loss via bi-level optimization as detailed in Appendix B."}, {"title": "4 Experiments", "content": "In this section, we conduct comprehensive experiments to evaluate our method's performance."}, {"title": "4.1 Benchmarks", "content": "Tasks. Our experiments encompass a variety of tasks, split into continuous and discrete categories.\nThe continuous category includes four tasks: (1) Superconductor (SuperC) 5: The objective hereis to engineer a superconductor composed of 86 continuous elements. The goal is to enhance thecritical temperature using 17,010 design samples. This task is based on the dataset from [1]. (2) AntMorphology (Ant): In this task, the focus is on developing a quadrupedal ant robot, comprising 60continuous parts, to augment its crawling velocity. It uses 10, 004 design instances from the datasetin [3, 14]. (3) D'Kitty Morphology (D'Kitty): Similar to Ant Morphology, this task involves thedesign of a quadrupedal D'Kitty robot with 56 components, aiming to improve its crawling speedwith 10,004 designs, as described in [3, 15]. (4) Rosenbrock (Rosen): The aim of this task is tooptimize a 60-dimension continuous vector to maximize the Rosenbrock black-box function. It uses50000 designs from the low-scoring part [9].\nFor the discrete category, we explore three tasks: (1) TF Bind 8 (TF8): The goal is to identify an8-unit DNA sequence that maximizes binding activity. This task uses 32, 898 designs and is detailedin [16]. (2) TF Bind 10 (TF10): Similar to TF8, but with a 10-unit DNA sequence and a larger poolof 50, 000 samples, as described in [16]. (3) Neural Architecture Search (NAS): This task focuseson discovering the optimal neural network architecture to improve test accuracy on the CIFAR-10dataset, using 1,771 designs [17].\nEvaluation. In this study, we utilize the oracle evaluation from design-bench [3]. Adhering to thisestablished protocol, we analyze the top 128 promising designs from each method. The evaluationmetric employed is the 100th percentile normalized ground-truth score, calculated using the formulay-Ymin\nYn\nYmax-Ymin\n, where Ymin and Ymax signify the lowest and highest scores respectively in thecomprehensive, yet unobserved, dataset. In addition to these scores, we provide an overview of eachmethod's effectiveness through the mean and median rankings across all evaluated tasks. Notably,the best design discovered in the offline dataset, designated as D(best), is also included for reference.For further details on the 50th percentile (median) scores, please refer to Appendix C."}, {"title": "4.2 Comparison Methods", "content": "Our approach is evaluated against two primary groups of baseline methods: forward and inverseapproaches. Forward approaches enhance existing designs through gradient ascent. This includes: (i)Grad: utilizes simple gradient ascent on current designs for new creations; (ii) ROMA [18]: imple-ments smoothness regularization on proxies; (iii) COMs [5]: applies regularization to assign lowerscores to adversarial designs; (iv) NEMO [19]: bridges the gap between proxy and actual functionsusing normalized maximum likelihood; (v) BDI [20]: utilizes both forward and inverse mappings totransfer knowledge from offline datasets to the designs; (vi) IOM [21]: ensures consistency betweenrepresentations of training datasets and optimized designs.\nInverse approaches focus on learning a mapping from a design's property value back to its input.High property values are input into this inverse mapping to yield enhanced designs. This includes: (i)CbAS [22]: CbAS employs a VAE model to implicitly implement the inverse mapping. It graduallytunes its distribution toward higher scores by raising the scoring threshold. This process can beinterpreted as incrementally increasing the conditional score within the inverse mapping framework.(ii) Autofocused CbAS (Auto.CbAS) [23]: adopts importance sampling for retraining a regressionmodel based on CbAS. (iii) MIN [6]: maps scores to designs via a GAN model and explore thismapping for optimal designs. (iv) BONET [24]: introduces an autoregressive model for samplinghigh-scoring designs. (v) DDOM [4]: utilizes proxy-free diffusion to model the inverse mapping.\nTraditional methods as detailed in [3] are also considered: (i) CMA-ES [25]: modifies the covariancematrix to progressively shift the distribution towards optimal designs; (ii) BO-qEI [26]: implements"}, {"title": "4.3 Experimental Configuration", "content": "In alignment with the experimental protocols established in [3, 20], we have tailored our trainingmethodologies for all approaches, except where specified otherwise. For methods such as BO-qEI,CMA-ES, REINFORCE, CbAS, and Auto.CbAS that do not utilize gradient ascent, we base ourapproach on the findings reported in [3]. We adopted T = 1000 diffusion sampling steps, set thecondition y to Ymax, and initial strength w as 2 in line with [4]. To ensure reliability and consistency inour comparative analysis, each experimental setting was replicated across 8 independent runs, unlessstated otherwise, with the presentation of both mean values and standard errors. These experimentswere conducted using a NVIDIA GeForce V100 GPU. We've detailed the computational overhead ofour approach in Appendix D to provide a comprehensive view of its practicality."}, {"title": "4.4 Results and Analysis", "content": "In Tables 1 and 2, we showcase our experimental results for both continuous and discrete tasks.To clearly differentiate among the various approaches, distinct lines separate traditional, forward,and inverse approaches within the tables For every task, algorithms performing within a standarddeviation of the highest score are emphasized by bolding following [5]."}, {"title": "4.5 Ablation Studies", "content": "In this section, we present a series of ablation studies to scrutinize the individual contributions ofdistinct components in our methodology. We employ our proposed approach as a benchmark andmethodically exclude key modules, such as the proxy-enhanced sampling and diffusion-based proxyrefinement, to assess their influence on performance. These variants are denoted as w/o proxy-e andw/o diffusion-b r. Additionally, we explore the strategy of directly performing gradient ascent onthe diffusion intermediate state, referred to as direct grad update. The results from these ablationexperiments are detailed in Table 3.\nOur analysis reveals that omitting either module results in a decrease in performance, thereby affirmingthe importance of each component. The w/o diffusion-b r variant generally surpasses w/o proxy-e,highlighting the utility of the proxy-enhanced sampling even with a basic proxy setup. Conversely,direct grad update tends to produce subpar results across tasks, likely attributable to the proxy'slimitation"}]}