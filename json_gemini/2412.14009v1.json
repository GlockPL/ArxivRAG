{"title": "Cognition Chain for Explainable Psychological Stress Detection on Social Media", "authors": ["Xin Wang", "Boyan Gao", "Yi Dai", "Lei Cao", "Liang Zhao", "Yibo Yang", "David Clifton"], "abstract": "Stress is a pervasive global health issue that can lead to severe mental health problems, including anxiety, depression, and suicide. Early detection offers timely intervention and prevention of stress-related disorders. The current early detection models perform \"black box\" inference suffering from limited explainability and trust which blocks the real-world clinical application. Thanks to the generative properties introduced by the Large Language Models (LLMs), the decision and the prediction from such models are semi-interpretable through the corresponding description. However, the existing LLMs are mostly trained for general purposes without the guidance of psychological cognitive theory. To this end, we first highlight the importance of prior theory with the observation of performance boosted by the chain-of-thoughts tailored for stress detection. This method termed Cognition Chain explicates the generation of stress through a step-by-step cognitive perspective based on cognitive appraisal theory with a progress pipeline: Stimulus \u2192 Evaluation \u2192 Reaction \u2192 Stress State, guiding LLMs to provide comprehensive reasoning explanations. We further study the benefits brought by the proposed Cognition Chain format by utilising it as a synthetic dataset generation template for LLMs instruction-tuning and introduce CogInstruct, an instruction-tuning dataset for cognitive stress detection. This dataset is developed using a three-stage self-reflective annotation pipeline that enables LLMs to autonomously generate and refine instructional data. By instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable stress detection model. Evaluations demonstrate that CogLLM achieves outstanding performance while enhancing explainability. Our work contributes a novel approach to stress detection by integrating cognitive theories into LLM reasoning processes, offering a promising direction for future explainable AI research.", "sections": [{"title": "1 Introduction", "content": "Stress is a pervasive issue, causing severe mental health issues such as anxiety, depression, self-harm, and suicide, which significantly impair individuals' health worldwide (Foundation, 2022). Fortunately, timely interventions can prevent the escalation of stress-related disorders through early stress detection, which improves overall well-being and reduces long-term health risks.\nDiffering from traditional counseling (Goodman et al., 1984) and questionnaires (Holmes and Rahe, 1967) based stress detection methods, daily expression reflects a person's mental state in real-time. Building on this, natural language-based approaches, particularly those analyzing social media content (Guntuku et al., 2019), leverage platforms like Twitter, Reddit, and Weibo, where individuals increasingly share emotions, thoughts, and experiences. These methods enable real-time analysis and provide insights into societal trends."}, {"title": null, "content": "Despite advancements in stress detection algorithms, lacking explainability in model predictions remains a significant challenge, rendering the results difficult to trust and interpret. Most existing stress detection studies (Guntuku et al., 2019; Turcan et al., 2021; Wang et al., 2023b) approach stress detection as a binary classification task, simply outputting 0 or 1 to indicate stress states. These models often operate as \"black boxes\", providing little to no explanation about how conclusions about an individual's stress states are drawn. As a result, these unexplained outcomes may lead to user mistrust and hinder the adoption of such technologies in clinical settings. Therefore, integrating explainable methods into stress detection models is crucial for improving reliability, building trust, and supporting more effective decision-making.\nThanks to the generative properties introduced by the Large Language Models (LLMs), the prediction from such models is semi-explainable through the corresponding description. Recently, a few works (Alghamdi et al., 2024) have designed direct prompt to instruct LLMs to infer stress states. Due to the generative nature, LLMs will also generate some explanations for their predictions. However, the direct prompting method still have limitations. First, the generation process lacks guidance from psychological cognitive theories, leading to inadequate or unreasonable explanations of stress generation. Furthermore, since LLMs generate tokens sequentially, where each token depends on the previously generated ones, uncomprehensive or incorrect explanations can propagate errors and degrade the detection performance.\nCognitive appraisal theory (Lazarus, 1991; Arnold, 1960) explains individuals' emotional generation from a cognitive perspective. The theory suggests that the generation of human emotion can be summarized as 'stimulus-appraisal-emotion'. For example, imagine receiving an unexpected job offer. The job offer is the stimulus. You appraise this event by considering factors like how it aligns with your career goals, the job location, salary, and potential challenges. If the appraisal leads you to see the offer as a great opportunity that advances your career, you may feel excited and happy. Conversely, if you perceive the job as unsuitable or threatening to your current work-life balance, you might feel anxious or stressed.\nThese inspire us to integrate cognitive appraisal theory into the Chain-of-Thought (CoT) prompt (Wei et al., 2022) to achieve comprehensive reasoning explanations for stress detection. Specifically, we propose a Cognition Chain, defined as Stimulus \u2192 Evaluation \u2192 Reaction \u2192 Stress State, to steer LLMs to explain the generation of stress step by step from a cognitive perspective. As shown in Figure 1, the process begins with a stimulus, which undergoes cognitive evaluation as the individual assesses its implications. This evaluation shapes the subsequent emotional response and ultimately leads to a stress state. To operationalize this approach, we design a prompt template for LLMs to implement our Cognition Chain.\nTo train a model capable of generating effective Cognition Chain for explainable stress detection, we propose an instruction tuning dataset, CogInstruct, which is composed of cognition chain data. Specifically, we introduce a three-stage self-reflection pipeline. The pipeline begins by automatically generating Cognition Chain data using our prompt template and GPT-4o, followed by correcting erroneous data through self-reflection. Finally, any remaining incorrect data is corrected through answer-reflection. Beyond the automatic processes, we manually annotate a portion of the data and train a classifier to further eliminate low-quality data. Through the above process, we obtain CogInstruct. Subsequently, we choose the Llama3, an open-source large language model as our base model. By instruction-tuning the Llama3 model on CogInstruct, we obtain the CogLLM model. The experimental results demonstrate that CogLLM not only achieves outstanding detection performance but also provides comprehensive explanations about stress generation.\nWe highlight the following contributions\u00b9:"}, {"title": null, "content": "\u2022 We propose the Cognition Chain, a method to explain the generation of stress step by step from a cognitive perspective. We design a Cognition Chain prompt template to guide the reasoning processes of large language models.\n\u2022 We construct CogInstruct, an instruction-tuning dataset containing Cognition Chain data for explainable stress detection. Moreover, we propose a three-stage self-reflective annotation pipeline that enables LLMs to autonomously curate instruction datasets.\n\u2022 We present CogLLM, an instruction-tuned LLama3 on the Construct dataset. Experiment"}, {"title": "2 Related Work", "content": null}, {"title": "2.1 Stress Detection on Social Media", "content": "These stress detection on social media studies aim to determine whether an individual is stressed or not (Xue et al., 2016; Saha and De Choudhury, 2017; Lin et al., 2017). Thelwall proposed TensiStrength (Thelwall, 2017), a system for detecting stress and relaxation levels in social media text, using lexical and machine learning approaches. Pillai et al. (Gopalakrishna Pillai et al., 2018) developed an improved method by incorporating word sense disambiguation, enhancing the performance of the TensiStrength algorithm. Guntuku et al. (Guntuku et al., 2019) developed domain adaptation models to predict stress using Facebook and Twitter data, with potential applications for monitoring stress at individual and county levels. Wang et al. (Wang et al., 2020) introduced a three-level personalized stress detection framework, which integrates individual's group characteristics and personality traits. Turcan et al. (Turcan et al., 2021) developed emotion-infused models for psychological stress detection, using multi-task learning and fine-tuning with emotion detection tasks. ContrasRL (Wang et al., 2023b) proposed contrastive learning tasks to enhance stress representation learning for social media-based stress detection. More recently, Alghamdi et al. (Alghamdi et al., 2024) utilized large language models (LLMs) for stress detection by designing a simple prompt to tell GPT-3.5 (Ye et al., 2023) summary and answer stressed or not.\nHowever, these methods typically output the category of stress states but rarely provide comprehensive reasoning explanations, which is crucial for making the results more convincing and reliable in real-world applications. To address this issue, we propose Cognition Chain to guide large models in generating step by step reasoning processes. Additionally, we constructed the first instruction tuning dataset, CogInstruct, which includes cognitive reasoning processes, and developed CogLLM, the first large language model designed for explainable stress detection from a cognitive perspective."}, {"title": "2.2 Chain-of-Thought Prompting", "content": "Chain-of-Thought (CoT) prompting has gained significant attention in recent years as a technique to enhance the reasoning capabilities of large language models (Chu et al., 2024). Wei et al (Wei et al., 2022) were the first to propose chain-of-thought prompting, where a few chain of thought demonstrations are provided as references in prompting. Subsequently, numerous studies have continued to explore ways to improve CoT prompting methods, such as: Zero-shot CoT (Kojima et al., 2022), PAL (Gao et al., 2023), Auto-CoT (Zhang et al.), AutoMate-CoT (Shum et al., 2023), and BoostedPrompt (Pitis et al., 2023). Zero-shot CoT (Kojima et al., 2022) is a method that essentially involves appending the phrase 'Let's think step by step' to the original prompt. Moreover, CoT has been used in some domains such as dialogue and medical systems. For example, Chae et al. (Chae et al., 2023) proposed decomposing commonsense reasoning into sequential steps, generating rationale to enhance Dialogue CoT reasoning. Wang et al. (Wang et al., 2023a) proposed two dialogue CoTs that enable advanced reasoning and planning based on user statuses. Lievin et al. (Li\u00e9vin et al., 2024) directly adopted Zero-shot CoT to generate accurate responses to medical-related questions. Mao et al. (Miao et al., 2024) utilized and analyzed CoT application in answer to nephrology-related questions. Hagan et al. (O'Hagan et al., 2023) used Zero-shot CoT to improve the accuracy and appropriateness of ChatGPT responses on skin cancer Information.\nInspired by the above works, we design an improved Chain-of-Thought (CoT) prompting method for explainable stress detection. Our key innovation is integrating cognitive appraisal theory to propose the Cognition Chain that can generate comprehensive reasoning process."}, {"title": "3 Methodology", "content": "In this section, we present Cognition Chain, beginning with a brief overview of Chain-of-Thought reasoning and Cognitive Appraisal Theory. We then formalize the proposed reasoning process, following the Stimulus \u2192 Evaluation \u2192 Reaction \u2192 Stress State framework, integrating these two complementary approaches. To generalize this reasoning process, we construct a prompt template, which is subsequently used to generate CogInstruct data for model instruction-tuning. Finally, we tune CogLLM base on CogInstruct."}, {"title": "3.1 Background for Chain-of-Thought", "content": "We provide a brief background on standard chain-of-thought (CoT) reasoning (Wei et al., 2022). We define the notations as follows: Q denotes the question; T denotes the prompt; and F denotes the final answer. The CoT prompt P = I, (x1, \u20ac1,Y1), ..., (Xn, en, Yn) consists of an instruction I and a few examples, each comprising a question xi, a rationale ei, and an answer yi. In chain-of-thought reasoning, the model generates step-by-step reasoning steps G before producing the final answer F, as shown in the equation below:\n$$p(F,G | P, Q) = p(G | P, Q) \\cdot p(F | P, Q, G)$$\n(1)"}, {"title": "3.2 Background for Cognitive Appraisal Theory", "content": "We improve chain-of-thought reasoning for stress detection drawing inspiration from the cognitive appraisal theory (Lazarus, 1991; Arnold, 1960), which explains how emotions are generated through a specific mental process. In essence, this process can be encapsulated in the sequence: \u2018stimulus-appraisal-emotion'. It begins when an individual perceives or pays attention to particular stimuli in their environment or to specific events. These stimuli prompt the person to engage in internal evaluations or interpretations, as beneficial, harmful, or irrelevant. Based on this appraisal, a corresponding emotional response is triggered, shaping how the person feels and reacts to the situation. For example, an oncoming interview can be a stimulus, the individual's appraisal can be beneficial or harmful, if negative, the stimulus may form a bad emotional response like anxiety."}, {"title": "3.3 Cognition Chain Creation", "content": "To achieve reliable stress detection, we propose a step-by-step Cognition Chain, given the insights of human cognitive process when forming stress (Lazarus, 1991; Arnold, 1960). The reasoning process can be summarized as Stimulus \u2192 Evaluation \u2192 Reaction \u2192 Stress State. The specific meaning of each element in the chain is as follows:\n\u2022 Stimulus S refers to any potential trigger that initiates an individual's emotional cognitive process. It can be external, such as an event or object, or internal, such as a thought or memory."}, {"title": null, "content": "\u2022 Evaluation & refers to an individual's personal interpretation, assessment, and internal reaction to a stimulus, shaped by their personality, experiences, beliefs, and expectations. The evaluation of the stimulus can result in three outcomes: \"beneficial,\" \"harmful,\" or \"irrelevant\" to the individual.\n\u2022 Reaction R presents an individual's reaction or state and the corresponding emotions due to stimulus and evaluation.\n\u2022 Stress State A summarises whether the individual is stressed based on the previous inference results.\nGiven a large language model, the generation process of our Cognition Chain is as follows:\n$$p(A,S,E,R|T,C) = p(S | T,C)$$\n$$ \\cdot p(E | T,C,S)$$\n$$\\cdot p(R|T,C,S,E)$$\n$$\\cdotp(A|T,C,S,E,R)$$\n(2)\nwhere C denotes the individual's post content. T is the prompt template we propose for implementing our Cognition Chain. S, E, R, and A represent the sequential steps."}, {"title": "3.4 Cognition Chain Prompt Template Design", "content": "We designed a prompt template to guide LLMs in thinking step by step, forming what we refer to as our Cognition Chain. As illustrated in Figure 2, our prompt template consists of five main parts.\nIdentity Instruction: This part is to prompt LLMs act as a psychological expert."}, {"title": "3.5 CogInstruct Dataset Construction", "content": "We aim to build an instruction-tuning dataset containing Cognition Chains for training an explainable stress detection model. However, existing public stress detection datasets lack cognition chain data. Manually annotating a large amount of cognition chain data is undoubtedly costly because analyzing and writing cognition chains is very time-consuming. Furthermore, the required qualifications for labelers are high, usually necessitating psychology experts. Therefore, we introduce an AI-assisted expert approach. Specifically, we first use a three-stage self-reflection pipeline based on GPT-4 to obtain initial annotated data. Then, experts manually verify a small portion of the sampled data and use the verification results to train an annotation quality classifier. We use this quality classifier to eliminate low-quality samples from the initial annotated data, retaining only those of good quality for our final dataset."}, {"title": "3.5.1 Self-Reflection Annotation", "content": "We employ a powerful large language model (GPT-4o) to assist us in constructing the CogInstruct dataset. GPT-4o generates high-quality rationales when the derived answer is correct, as these rationales have been shown to effectively guide the model toward our expected outcomes. Unfortunately, it may also produce incorrect answers accompanied by misleading reasoning steps. LLM has been proven to have ability of self-correction (Zelikman et al., 2022). Therefore, to generate and refine reasoning steps, we propose a three-stage self-reflection annotation pipeline comprising Cognition Chain Prompt, Self-reflection, and Answer-reflection stages.\nWe use raw data from two public datasets, dreaddit (Turcan and McKeown, 2019) and WBSD (Wang et al., 2023b). Merging their training sets yields a total of 5,295 samples. Each sample consists of a post and its label. We then annotate the cognition chains for each sample.\n1) Cognition Chain Prompt Stage: In this stage, we use GPT-4o and the Cognition Chain prompt template, as illustrated in Figure 2, to generate responses for each post. After filtering out the incorrect responses, we are left with 3,960 correct ones. The remaining incorrect responses, along with their corresponding posts, are then passed on to stage two.\n2) Self-Reflection Stage: In this stage, we prompt GPT-4o to reflect on the samples with incorrect answers from the first stage. We inform GPT-4o that errors exist but do not provide the correct answers, encouraging it to review and analyze"}, {"title": "3.5.2 Human Filter", "content": "Although the previous process generates cognition chain reasoning steps, erroneous ones could be introduced due to two main reasons: 1) Even if the LLM generates the correct answer, the intermediate reasoning steps may still be flawed (Lanham et al., 2023). 2) Despite specifying the output format, the model may occasionally produce extraneous information that deviates from the expected output.\nWe randomly selected a subset of 531 samples annotated by GPT-4o for manual verification. A group of professional psychology experts evaluated the quality of the automatically generated cognition chains by rating 388 samples as qualified and the remaining 143 as unqualified.\nTo improve the quality of our dataset, we developed a quality classifier using expert-annotated samples and RoBERTa (Liu, 2019). Specifically, we labeled qualified samples as positive and unqualified samples as negative to train a binary classifier. This classifier determines whether the cognition chain quality of a sample meets the required standard. It was used to filter qualified samples into our CogInstruct dataset. After classification, we"}, {"title": "3.6 CogLLM Tuning", "content": "We follow the standard Supervised Instruction-Tuning (SIT) protocol to optimize pre-trained models using the CogInstruct dataset. Specifically, given a model parameterized by @ and input-answer pairs ((T,C); (A, S, E,R)), we minimize the losses generated under the next-token prediction paradigm, while masking out those associated with T and C. The process can be expressed as:\n$$min L_{SFT}((T,C); (A, S, E, R))$$\n$$= - log p_{\\theta}(A, S,E,R)|T,C).$$\n(3)\nWithout losing generality, we choose Llama-3-8B-Instruct (Touvron et al., 2023) as the pre-trained model regarding both the performance and computational cost."}, {"title": "4 Experiment", "content": null}, {"title": "4.1 Experiment Details", "content": "To prepare the dataset for tuning the large language model (LLM), we converted it into the Alpaca format. All experiments during the instruction-tuning process were conducted using the Huggingface Transformers library. We employed LoRA"}, {"title": "4.3 Effectiveness of Cognition Chain", "content": "Table 2 presents the main results of our Cognition Chain approach. Prior research (Wei et al., 2022) indicates that chain-of-thought only reasoning effects significantly when models exceed 100B parameters. Following this instruction, we selected three large-scale industry level LLMs as base models for comparison, which include GPT-3.5 (OpenAI, 2022), Gemini-15 (Reid et al., 2024), and GPT-4o (OpenAI, 2024). We compare our Cognition Chain method against both direct prompting (Alghamdi et al., 2024) and the standard chain-of-thought (Wei et al., 2022) approach. Further details about the baselines are provided in Appendix C. Our results show that our Cognition Chain consistently achieves the highest performance in the comparison with all the baselines. Moreover, simply introducing the standard chain-of-thought into stress detection offers only marginal improvement over direct prompting, underscoring the value of our enhancements, which integrate Cognitive Appraisal Theory and construct a well-designed template to improve upon standard CoT reasoning.\nWe conduct further ablation study about the steps derived from the psychology routines within our Cognition Chain. The results in Table 3 show that including all four steps of the Cognition Chain (Stimulus, Evaluation, Reaction, and Stress State) consistently improves performance. When the full configuration is used, both accuracy and F1-scores are highest, indicating that each step contributes valuable information. As we remove steps, performance decreases steadily, confirming their complementary roles. Notably, discarding the Evaluation and Reaction steps leads to a notable drop in scores, and relying solely on the Stress State step yields the lowest overall performance. These findings highlight the importance of modelling all four steps to achieve accurate detection results."}, {"title": "4.4 Effectiveness of CogLLM", "content": "Table 4 presents a summary of our CogLLM results. To conduct a comprehensive comparison, we employ two categories of baselines. The first category comprises proprietary LLMs including GPT-3.5 (OpenAI, 2022), Gemini-1.5 (Reid et al., 2024), and GPT-4o (OpenAI, 2024). The second category encompasses open-source LLMs such as Llama-2 (Touvron et al., 2023), GLM-4 (GLM et al., 2024), and Llama-3 (Dubey et al., 2024). Details of the baselines are provided in Appendix C."}, {"title": "4.5 Evaluation for Explanations", "content": "To assess the quality of the generated explanations, we consider five aspects for human evaluation (Zhou et al., 2024; Cai et al., 2023; Stenning and van Lambalgen, 2011): (i) Comprehension. Comprehensive reasoning explanations for the generation of stress. (ii) Depth. Insight and reasonable inference beyond the literal text. (iii) Relevance. The relevance of the reasoning chains to the original post. (iv) Logic. The logical coherence within the reasoning chains. (v) Overall. The average"}, {"title": "5 Conclusion", "content": "In this paper, we introduced the Cognition Chain, a method inspired by cognitive appraisal theory explaining the generation of stress step-by-step. Based on this, we further presented a three-stage self-reflective annotation pipeline to create CogInstruct, a new dataset for instruction-tuning large language models (LLMs), and developed a specialized model termed CogLLM. Experimental results validate the effectiveness of both the Cognition Chain and CogLLM in the comparison with the industry-level baselines. Our work marks an initial step toward leveraging cognitive theory for more explainable psychological detection, setting a foundation for future research to explore the intersection of LLM reasoning processes and cognitive theory. Ultimately, we hope this line of inquiry will foster more trustable and reliable approaches to modeling psychological phenomena."}, {"title": "6 Limitation", "content": "The quality and quantity of the cognition chain dataset are critical factors in determining the performance of our model. To minimize the cost associated with generating each cognition chain through human expertise, we have developed a three-stage self-reflection pipeline utilizing GPT-4o. A precise and lightweight classifier plays a important role in this pipeline; however, training such a classifier still necessitates a small amount of human effort for labelling. We believe that replacing the current classifier with a more advanced one may further improve data quality, though this improvement might require additional human labelling. Addressing these challenges remains a future objective, as we aim to develop a framework capable of generating high-quality datasets without human involvement."}, {"title": "7 Ethics Statement", "content": "In this study, all data utilized are sourced from publicly available social media platforms. The training and fine-tuning of large language models (LLMs) require substantial computational resources, which result in a significant environmental footprint. Increased energy consumption, along with the associated carbon emissions, represents an important ethical consideration in our work. To mitigate this concern, we have employed resource-efficient tuning strategies, such as LoRA (Low-Rank Adaptation), to minimize computational overhead wherever possible. We also acknowledge that while LLMs can generate informative and context-rich responses, they are not substitutes for licensed professionals in mental health or medicine. Specifically, we caution against using our tuned models as replacements for trained psychological practitioners. Any information or support provided by our LLMs should be considered an assistance to professional advice, not a replacement for it."}]}