{"title": "An Approach To Enhance IoT Security in 6G Networks Through Explainable AI", "authors": ["Navneet Kaur", "Lav Gupta"], "abstract": "The evolution of wireless communication has driven many technological advancements, significantly improving connectivity, accessibility, and user experience with each generation. Looking at the 6G framework recently finalized by ITU, the proposed advancements promise unprecedented capabilities, especially for the use cases that are heavily dependent on the Internet of Things (IoT). However, integrating IoT with the 6G infrastructure introduces complex security challenges, many of which remain unexplored. The interconnection of 6G and IoT broadens the attack surface, introducing new vulnerabilities. Also, with the anticipated incorporation of advanced technologies in 6G such as open RAN, terahertz (THz) communication, intelligent reflecting surfaces (IRS), massive MIMO, increased use of AI and disaggregated het-clouds, and many of its proposed use cases like immersive communication, collaborative robotics and native Al support present new security risks while continuing the mutated old ones. Thus, we have new threats relating to Al exploitation, open-source software and increased virtualization along with the existing ones like data manipulation, signal interference, and man-in-the-middle attacks. The complexity and dynamic nature of these technologies can create security blind spots that are difficult to anticipate and mitigate. The 6G standards are expected to be finalized by 2030, with ITU working groups and members focused on aligning security specifications with technological advancements. While many researchers are actively addressing security challenges, significant gaps remain in developing a comprehensive framework to tackle the complex vulnerabilities of integrated IoT and 6G networks. Our research aims to make a meaningful contribution towards addressing some of these gaps by making innovative use of tree-based machine learning algorithm for its ability to manage complex tabular datasets and provide robust feature importance scoring. By employing a cutting-edge dataset that captures 6G network complexities, we implement data balancing to ensure equal representation of attack subcategories. The study also employs interpretability techniques such as SHAP (Shapley Additive Explanations) and LIME (Local Interpretable Model-Agnostic Explanations) for enhanced model transparency, providing both global and local insights. Additionally, our approach involves analyzing the feature importance scores of the model and results of XAI methods, to ensure the alignment between them, cross-validating XAI techniques for consistency, and applying feature elimination to concentrate on the most relevant features, thereby enhancing the model's accuracy. This comprehensive strategy significantly boosts the model's performance and effectiveness in securing IoT within the 6G framework.", "sections": [{"title": "I. INTRODUCTION", "content": "Advancements in wireless communication from 3G to 5G have significantly improved technology, connectivity, and user experience, but they have also introduced serious security concerns. Despite 5G's intended security enhancements, research by GlobalData commissioned by Nokia reveals that nearly three-quarters of 5G network operators have experienced multiple security breaches, leading to network downtime, data leaks, and financial losses. Even after nearly four years since the launch of 5G network, operators report that their defenses remain inadequate against these emerging threats. Considering these concerns, network operators are expected to encounter even greater challenges with the introduction of 6G. Its increased speed, connectivity, and capabilities, coupled with new use cases, may bring about unforeseen vulnerabilities. The integration of massive IoT with 6G could open new avenues for cybercriminals, increasing the number of potential attack vectors and making it more challenging to secure the vast and complex network infrastructure.\nMoreover, the adoption of various new technologies in 6G and their potential use cases could create blind spots for security experts, leaving room for exploitation. For example, the integration of advanced technologies like Open RAN (Open Radio Access Network) disaggregates traditional network components into modular elements, promoting innovation but also increasing the attack surface and introducing supply chain risks such as compromised hardware or software from multiple vendors, inconsistent security standards, and potential third-party risks. Terahertz (THz) communication, operating at extremely high frequencies, offers benefits such as low latency and high data rates, yet it is susceptible to signal blockage, eavesdropping, and denial-of-service attacks. Intelligent Reflecting Surfaces (IRS), designed to boost signal strength, can be manipulated to redirect signals, leading to communication failures or enabling man-in-the-middle attacks. The use of massive MIMO (Multiple Input Multiple Output) technology, which significantly enhances network capacity, also presents complex security challenges, including pilot contamination and the difficulty of securing a vast array of antennas. The increased use of Al within 6G networks, while optimizing network performance, introduces risks like algorithm manipulation and vulnerability to adversarial attacks. Disaggregated heterogeneous cloud computing (Het-clouds) complicates security further by distributing services across multiple providers, increasing the likelihood of data breaches and insider threats.\nAnticipated 6G use cases, such as immersive communication (AR/VR), collaborative robotics, and native Al support, also present unique security vulnerabilities. AR/VR technologies can be exploited for data manipulation, where attackers might inject or alter sensory data, leading to misleading or harmful outcomes. Collaborative robotics, relying on real-time communication and coordination, are vulnerable to operational disruptions, hijacking, and other cyber-attacks that could compromise their functionality. Native AI support, deeply integrated into the network, could be manipulated or misused, leading to unintended security consequences and the spread of malicious activities across the network.\nThese use cases, combined with the inherent complexity and dynamism of 6G technologies, highlight the need for robust and adaptive security measures to counter both existing and emerging threats. While AI plays a key role in enabling and securing these new use cases, its lack of transparency can undermine trust, which is essential for the success of advanced IoT-6G applications. Transparency in security systems is absolutely crucial for understanding decision-making processes and ensuring the fairness of security measures. Without clear visibility into AI algorithms, users face significant challenges in validating threat assessments and comprehending the rationale behind security decisions. This lack of transparency severely limits accountability and collaboration, potentially resulting in overlooked threats or misinterpretations. To effectively address these critical issues and protect the evolving 6G and IoT landscape, it is imperative to integrate AI within transparent frameworks and maintain robust human oversight.\nTo ensure transparency in security decision-making for IoT and 6G systems, Explainable AI (XAI) is crucial. XAI helps security professionals understand and manage risks associated with Al-driven decisions, clarifies Al's role in security processes, and facilitates accountability for breaches or lapses. This transparency builds trust in AI systems, making security measures more effective and strengthening the overall security framework in the 6G and IoT ecosystem.\nDespite the significant contributions of existing studies, as outlined in Section 2, several critical challenges remain. Many researchers tend to prioritize Convolutional Neural Network (CNN) models for security applications, often overlooking the superior performance and feature importance that tree-based models can offer, especially with complex tabular data. Additionally, new datasets that could significantly enhance security analytics in real IoT environments are frequently underutilized. Often, these datasets may not be optimally balanced or may not account for subcategories balance within classes, leading to skewed distributions and unreliable predictions. Explainable AI, which could offer insights into the decision-making processes of complex models, has not been thoroughly explored to explain the reasoning behind model predictions. The potential benefits of feature refinement, which could streamline models and enhance accuracy, based on insights from Explainable AI (XAI), have not been thoroughly investigated. Moreover, there is a significant lack of comprehensive studies that compare the model predictions with the insights obtained from the X\u0391\u0399 methods to verify the consistency and accuracy of the model's prediction. There is also a considerable gap in the research that thoroughly assesses and cross-verifies the results obtained from various XAI techniques to identify inconsistencies or discrepancies among them. Addressing these challenges is crucial for developing robust and effective IoT security solutions, which is the primary motivation behind our research.\nThis paper tackles the identified challenges by implementing effective strategies in innovative ways to strengthen the security within 6G networks. While the techniques themselves are well established, their customized application to the complex and evolving demands of 6G and IoT environments introduces a novel perspective. By integrating these strategies with the latest advancements in network technology, we worked towards creating a more robust and adaptive security framework. These approaches address specific security gaps and emerging threats in ways that have not been previously investigated. First, we leverage tree-based models (XGBoost, Random Forest, KNN) known for their high performance and ability to handle complex datasets efficiently. This approach provides robust feature importance scoring, allowing us to identify the most relevant features and improve IoT security within the 6G framework. Second, we employ comprehensive datasets that encapsulate the diverse landscape of IoT attacks. This wider scope empowers the model to identify and defend against a broader range of threats, both present and anticipated, thus improving its resilience. Third, we implement robust data balancing technique to ensure that all attack types, including less frequently occurring subcategories, are adequately represented in the training dataset. This strategy enhances the model's ability to learn from a diverse array of scenarios, ultimately improving its generalization capabilities. Fourth, we apply Explainable Artificial Intelligence (XAI) techniques to bolster model transparency and interpretability. This facilitates clear and understandable explanations for the model's predictions, fostering greater transparency and trust in the system. Finally, we incorporate feature elimination technique to refine the model's accuracy by integrating insights from both XAI and the feature importance scores derived from the model. This combined approach demonstrates how these enhancements effectively improve the accuracy of IoT attack detection. Additionally, we verify the model's prediction by comparing the high-impact features identified by the selected model against those highlighted by the XAI methods LIME and SHAP. This comprehensive approach assesses whether the same features are consistently important across different methods, thereby validating the model's accuracy and trustworthiness in its predictions. Finally, we cross-verified the results of XAI methods against each other to ensure that both models yield consistent outcomes for each data instance used in the analysis. This approach ensures transparency and reliability of the results. Through these advancements, our paper contributes significantly to the development of more robust and trustworthy AI-powered security solutions for the ever-evolving world of IoT. In summary, the contribution of this paper are as follows:\n1. Utilizing tree-based machine learning models\n(Random Forest, XGBoost, and KNN) for our security solution, as they demonstrate superior performance compared"}, {"title": "II. RELATED WORKS", "content": "Several studies have effectively used neural networks to detect network traffic vulnerabilities, often preferring CNNs over tree-based models. For instance, in a recent paper , the authors evaluate the performance of various deep learning models in detecting cybersecurity attacks within IoT networks. They compare three architectures: Deep Neural Networks (DNN), Long Short-Term Memory (LSTM), and Convolutional Neural Networks (CNN). Another study presents a hybrid oracle-explainer approach for intrusion detection systems (IDS) that uses artificial neural networks (ANNs) and was evaluated on the CICIDS2017 dataset, offering human-understandable interpretations. While these studies make valuable contributions by applying neural networks to intrusion and anomaly detection, there is a growing consensus among researchers that tree based models may provide a more robust and interpretable alternative , particularly due to their superior capability in handling complex tabular data .\nMany studies rely on outdated datasets that do not reflect the complexities of modern networks, such as extensive topologies and new attack types , limiting their relevance to current network scenarios. For instance, used an XAI framework with SHAP, LIME, CEM, ProtoDash, and BRCG on the NSL-KDD dataset for intrusion detection, while applies SHAP to a multiclass classification problem using the same dataset. Another paper uses XAI with a decision tree algorithm on the KDD dataset to enhance trust management in IDSs. Similarly, the authors in conduct experiments on the NSL-KDD dataset using linear and multilayer perceptron classifiers, providing explanations through intuitive plots. Though these studies offer valuable insights, their findings are constrained because of the use of outdated datasets, reducing their applicability to today's more complex network environments.\nWhile some studies have used new datasets, they often overlook balancing subcategories and do not integrate XA\u0399 techniques for explaining the decisions provided by their AI models. For example, the author in uses machine learning algorithms to detect network intrusions in IoT botnet attacks but does not incorporate Explainable AI (XAI) techniques or balance the dataset, leading to potential bias and reduced accuracy in predictions. Similarly, the authors in propose a lightweight deep learning technique for detecting DDoS attacks in IoT environments. Their approach also does not include XA\u0399 methods or address dataset balancing. In  the author proposes a novel approach to intrusion detection in IoT environments, addressing challenges like resource constraints, security, and privacy, yet it also lacks the integration of XAI and dataset balancing techniques. The study in  utilizes tree-based machine learning algorithms for binary, 8-class, and 34-class classification tasks in IoT anomaly detection. The authors balance the dataset and employ a relevant and recent dataset but do not integrate Explainable AI (XAI) techniques to elucidate the reasoning behind the model's predictions, resulting in restricted transparency and interpretability. Another research , proposes a hybrid sampling strategy to improve the classification of IoT malicious traffic using tree based algorithms; however, it also does not incorporate XAI methods or balance the dataset. These gaps can lead to the AI models that perform unevenly across different subcategories , compromising the overall effectiveness and reliability of the security solutions.\nBased on the related work and our own research, it becomes apparent that a successful security framework used in the IoT-6G environment provides better outcomes if it concurrently employs tree based models, uses recent datasets, carries out up to sub-category level balancing of datasets and uses XA\u0399 techniques for explaining results and improving the accuracy of predictions.\nFurthermore, it is seen that while some researchers utilize explainable AI (XAI) to interpret the results, they do not apply iterative improvements through recursive feature elimination technique, which plays an important role in enhancing model performance model accuracy. The research  proposes intrusion detection system (IDS) methods and employed SHAP to interpret the classification decisions of ML models on NetFlow feature sets, including BoT-IoT and ToN-IoT, demonstrating enhanced detection accuracy, but it does not extend these insights to further refine the model through feature elimination technique, which could have led to greater model performance optimization. The paper focuses on explainability in IoT intrusion detection using recent datasets like CICIoT2023 and IoTID20 and applies methods such as LIME and Counterfactual XAI. However, despite employing"}, {"title": "III. PROPOSED APPROACH", "content": "The proposed model presents an effective application of various methods and techniques for IoT network security. This approach involves multiple stages, as illustrated in Fig 2. The initial stage involves collecting the dataset, where we acquire an IoT attack dataset to train and evaluate the performance of our tree-based models for classifying IoT network traffic. In the second stage, we preprocess the dataset by addressing missing or null values and perform label encoding and data standardization to ensure data consistency. In the third stage, we balance the dataset using the SMOTE technique to address class imbalances and improve the model's ability to generalize across different classes and sub-categories of classes. In the fourth stage, we split the dataset into training and testing sets, using the training set to develop and refine the models and the testing set to evaluate their performance. In the fifth stage, we classify network traffic, using tree-based models (Random Forest, XGBoost, and KNN), to accurately identify and differentiate between benign and malicious network activities. In the sixth stage, we compare the results from these models to identify the best-performing model based on accuracy and feature importance score, for further evaluation and integration with XAI methods. In the seventh stage, we apply XAI techniques\u2014LIME and SHAP\u2014 to enhance transparency and to provide insights into the selected model's decision-making process. In the eighth stage, we verify high-impact features identified by the model against those highlighted by XAI methods to assess consistency and evaluate the model's reliability. In the ninth stage, we cross-validate the results obtained from LIME and SHAP to ensure accurate predictions for individual records. Finally, in the tenth stage, we use a recursive feature elimination approach to enhance the model's detection accuracy and refine its predictive capabilities. These techniques help in understanding and optimizing the model's decisions, enhancing performance and reliability, and ensuring robust and trustworthy IoT security for advanced 5G and emerging 6G networks. In the subsequent sub-sections, we provide an in-depth explanation of each of these stages."}, {"title": "3.1 Dataset Overview and Collection Process", "content": "Selecting an appropriate dataset is crucial for providing effective security solutions within the system. As network attacks continuously evolve, relying on outdated datasets may yield less accurate and meaningful results. Therefore, our proposed IoT attack detecting system leverages the latest 'CICIoT2023' dataset from the University of New Brunswick . The dataset comprises 46686579 samples, with 46 attributes. It has one benign class and 33 distinct attack types, categorized into seven primary attack classes - distributed denial of service (DDoS), denial of service (DoS), reconnaissance, web-based, brute-force, spoofing, and the Mirai botnet. The dataset is divided into 169 separate CSV files, each containing a mix of benign and malicious network traffic. Encompassing a wide range of attacks, the dataset provides a robust foundation for developing and evaluating comprehensive security solutions against a diverse threat landscape. Additionally, it is collected from a heterogeneous environment of 105 real IoT devices including smart home devices, cameras, sensors, and microcontrollers, which mirrors the complexity of 5G and 6G networks, making it an ideal dataset for testing and validating advanced security frameworks tailored to these evolving technologies."}, {"title": "3.2 Dataset Pre-Processing", "content": "Dataset preprocessing involves several crucial steps to enhance data quality and improve model performance. First, the data was converted into Pandas data frames, preparing it for modeling and analysis, which ensures more accurate and efficient workflows. After that, infinite and missing values were addressed to prevent errors and biases in subsequent modeling stages. Duplicate records were removed to ensure the integrity and uniqueness of the data. Categorical labels were converted to numerical representations to enable compatibility with machine learning algorithms. Columns which were containing missing data were eliminated to streamline the dataset and reduce unnecessary complexity. Data normalization was applied to ensure numerical consistency, which enhances model stability and accelerates convergence by bringing all features to a comparable scale. Lastly, features with zero variance were excluded, narrowing the feature set from 46 to 40 attributes, thereby concentrating on the most relevant variables and improving model efficiency. Detailed descriptions of these features are presented in Table I."}, {"title": "3.3 Data Balancing and Data Splitting", "content": "To address class imbalances within the dataset, SMOTE was applied to generate synthetic samples for the minority classes, thereby ensuring a more even distribution of data across all classes. SMOTE is an over-sampling technique used to address class imbalance in datasets by generating synthetic instances of the minority class . Given a minority class instance $X_i$, SMOTE generates synthetic instance $X_{new}$ by linearly interpolating between $x_i$ and its k nearest neighbors.\n$X_{new} = X_i + \\lambda \\cdot (X_{nm} - X_i)$ (1)\nwhere $\\lambda$ is a random number between 0 and 1 and $x_{nm}$ is one of the k nearest neighbors of $x_i$.\nWe chose to use the SMOTE technique in our work because it creates new synthetic data points or samples, considering its nearest neighbor, rather than duplicating or removing existing ones, thus preserving all critical information from the majority class. Unlike under-sampling, which can lead to the loss of important data, SMOTE provides a more balanced and informative dataset , improving model performance without compromising valuable information. We also converted the"}, {"title": "3.4 Model Training", "content": "For model training, we utilized three tree-based classifiers: XGBoost, Random Forest, and KNN. XGBoost (Extreme Gradient Boosting) is an efficient and high-performance supervised learning algorithm for regression and classification tasks . It builds and combines multiple decision trees sequentially to combine predictive accuracy. Given dataset D = {($x_i$, $y_i$)}^N_{i=1} where $x_i$ are input features and $y_i$ are corresponding labels, the prediction y\u0302 made by XGBoost for an instance i is given by:\ny\u0302i = \u03a6($x_i$) = \u03a3^K_{k=1}f_k($x_i$)) (2)\nWhere K is the number of trees, $f_k$ represents the prediction of the k-th tree, and \u03a6($x_i$) is the final prediction after summing all predictions.\nRandom Forest is another ensemble learning method that builds multiple decision trees during training and outputs the mode of the classes (classification) or the mean prediction (regression) of the individual trees . Let T(x, \u00d8k) denote the prediction of the k-th tree, for classification, the prediction y\u0302 of the Random Forest is given by:\ny\u0302 = 1/K \u03a3^K_{i=1} (\u03a4(x, \u00d8ki) (3)\nwhere K is the number of trees and \u00d8k represents the parameters of the k-th tree.\nAnother model which we utilized is KNN (K-Nearest Neighbor) is a simple algorithm that classifies data points based on the most common class among their nearest neighbors in the training dataset. It works by finding the k closest data points to a new point and making a prediction based on the majority class or average value of these neighbors . For classification task, the predicted class y\u0302 of an instance of x, is determined by:\ny\u0302 = arg $max_{y_j}$ \u03a3_{i \u2208 N_k (x)} I(yi = yj) (4)\nwhere $N_k$ (x) is the set of k nearest neighbors of x, $y_i$ is the class of i- th neighbor and I is the indicator function.\nWe trained our models using these classifiers to leverage their individual strengths such as XGBoost and Random Forest are known for their robustness in handling complex datasets and capturing intricate patterns , while KNN offers simplicity and effectiveness in various scenarios, such as dealing with smaller datasets or when interpretability is crucial . By using these models, we aimed to address the different complexities and challenges inherent in the dataset, leading to a more reliable and accurate classification."}, {"title": "3.5 Data Explainability", "content": "For our work, we used SHAP and LIME to clearly explain and interpret the model's predictions. SHAP is a method used"}, {"title": "3.6 Recursive Feature Elimination", "content": "In our work, we utilized the recursive feature elimination technique (RFE). It is a feature selection method  that improves model performance by iteratively removing less relevant or redundant features, based on their impact on predictive power. Let X represent the feature matrix with n features, and y denote the target variable. Start with X' = X (all features included). Develop Machine learning model using X' and y. Calculate the feature importance scores, F = {$f_1$, $f_2$, \u00b7 \u00b7 \u00b7 $f_n$}. Identify the least important feature, $f_{min}$ = argmin (F). Remove $f_{min}$ from X'. Continue the process until a stopping criterion is reached or the desired number of features are removed, aiming to identify a new feature set that either maintains or improves the score compared to the previous set. The mathematical expression can be written as:\nScore(Xnew) =\nargminxnew Score( Xnew) subject to Score( Xnew) \u2265 Score (Xold) (7)\nThe purpose of using Recursive Feature Elimination (RFE) is to enhance model performance by identifying and retaining only the most critical features, thereby reducing the noise and improving the model's accuracy."}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "The experiments are carried out on a GPU-enabled Google Colab environment, utilizing Python 3.7. Several libraries and packages are used for dataset preprocessing, model training, explanations, feature selection, elimination, and visualization. These include Pandas and NumPy for data manipulation, Scikit-learn for machine learning algorithms and preprocessing techniques, TensorFlow and Keras for our learning model development, Matplotlib and Seaborn for visualization, and SHAP and LIME for model explanation and interpretability. This comprehensive toolkit ensures efficient handling of data, robust model training, insightful visualizations and explanations of the results."}, {"title": "4.1 Data Handling For Model Training", "content": "Due to the dataset's large size and computational constraints, processing all files at once was not feasible. To manage this, we randomly selected 18 CSV data files out of 169 CSV data files, with a total of 100,000 records for training and evaluating our machine learning models, as detailed in Table II. Our main goal is to build a transparent and reliable model using various techniques, including Explainable AI (XAI) methods. By focusing on a subset of the original dataset, we prioritize model interpretability and prediction clarity over comprehensive dataset coverage."}, {"title": "4.2 Balancing Using SMOTE", "content": "While balancing the dataset, we ensured that the total number of samples in the attack classes equaled that of the Benign class. Additionally, we also ensured that each of the attack class subcategory is also adequately balanced to avoid bias. This approach avoids scenarios where the model might favor majority classes over minority ones, which could negatively impact overall performance and accuracy. As can be seen from Fig. 3(a), the distribution of samples across different categories is uneven, therefore we applied SMOTE to each class and its sub-categories to achieve balanced representation.\nFor the Benign class, which originally had 2376 samples (refer Table II), we standardized the number to 2100 to ensure better comparability with other classes while maintaining the dataset's robustness and manageability. We then used SMOTE to adjust each attack subcategory, including DDoS (which initially had the highest number of samples), to 300 samples each. This adjustment resulted in a total of 2100 samples for the attack classes, aligning with the count in the benign class. This"}, {"title": "4.3 Model Training Using Tree Based Classifiers", "content": "In this section, model training was done, to effectively classify the network traffic as either malicious or benign. We also evaluated the performance metrics of three tree-based models: XGBoost, Random Forest, and KNN, -to compare their results and select the best one. Please note that the results presented are based on an optimal experimentation process designed to maximize insights and practical applicability, rather than solely focusing on accuracy. Our primary goal was to showcase how these techniques can enhance model explainability and transparency, ultimately contributing to a more secure environment. Further refinement and fine-tuning of these processes could be explored to achieve enhanced accuracy."}, {"title": "4.3.1 Implementing XGBoost For Model Training", "content": "XGBoost achieved an impressive accuracy of 95.59% on the dataset, showcasing its effectiveness in identifying patterns associated with malicious or benign activity. Fig. 5 displays a"}, {"title": "4.3.2 Implementing Random Forest for Model Training", "content": "Random Forest achieved an accuracy of 94.04%, slightly lower than that of the XGBoost model. However, it is noteworthy that both models identified Feature 15 (rst_count) as the most influential, followed by Feature 32 (IAT) as shown in Fig. 6. This consistency in feature importance highlights the critical role of these features in the model's predictions and underscores their significance in achieving high accuracy."}, {"title": "4.3.3 Implementing KNN For Model Training", "content": "KNN (K-Nearest Neighbor) achieved an accuracy of 87.50%, slightly lower than the XGBoost and the Random Forest model. The most influential feature is Feature 32 (IAT), followed by Feature 1 (Header_Length) as shown in Fig. 7. Many features have negative importance scores, suggesting they detract from the model's predictive performance. This indicates that these features might be introducing noise or causing misleading predictions, rather than enhancing accuracy."}, {"title": "4.4 Comparative Analysis of XGBoost, KNN, and Random Forest Models", "content": "This section compares the performance of XGBoost, Random Forest, and KNN to identify the most accurate and reliable model for detecting IoT attacks. Further analysis is carried out on the chosen model to leverage its strengths in achieving optimal performance and mitigating security threats in IoT environment."}, {"title": "4.4.1 Comparison Based on Accuracy", "content": "Comparative analysis reveals that XGBoost surpasses both KNN and Random Forest in terms of accuracy, as detailed in Table III. Although the XGBoost model achieved an accuracy of 95.59%, which offers a strong baseline, further optimization can be possible. Our objective is to develop a robust model capable of handling the dataset's diversity effectively, avoiding biases towards specific attack subtypes. This baseline model serves as a starting point for in-depth analysis using explainable AI and feature engineering to enhance performance and transparency."}, {"title": "4.4.2 Comparison Based on Feature Score", "content": "A comparative analysis of feature importance scores reveals a convergence between XGBoost and Random Forest, with both models identifying similar influential features. In contrast, KNN highlights a distinct set of important features, as detailed in Table IV.\nThis consistency between XGBoost and Random Forest makes sense as 'rst_count' (count of TCP reset packets in network traffic) is important for detecting patterns related to connection resets, which can be indicative of scanning or denial-of-service attacks. Similarly, 'IAT (Inter-Arrival Time) is crucial for detecting irregular traffic patterns, such as unusually high or low intervals between packets. For example, a sudden spike in IAT may indicate a Distributed Denial of Service (DDoS) attack, where multiple packets are sent at irregular intervals to overwhelm a network. Conversely, an unusually low IAT might suggest a Brute-Force attack, where rapid, consecutive attempts to breach a system are made. Other features like 'flow_duration' and 'HTTPS' are also essential for detecting network traffic because they provide important context about the nature of the traffic. The feature 'flow duration' tracks how long a connection persists, helping to identify anomalies such as unusually brief connections, which may signal a denial-of-service (DoS) attack. 'HTTPS' indicates whether the traffic is encrypted; attackers might target unencrypted traffic, while legitimate interactions are typically encrypted. By incorporating these features, the model can more accurately differentiate between standard and suspicious traffic, enhancing its ability to detect both benign activities and potential security threats."}, {"title": "4.5 Enhancing Model Accuracy and Transparency with SHAP and LIME", "content": "In this section, we provide insights into the model's decision-making process through SHAP and LIME. These explainability techniques help break down the model's predictions, offering a clear understanding of how each feature contributes to the outcome. By making the model's inner workings more transparent, we not only increase trust in its predictions but also enable more informed decisions for system administrators."}, {"title": "4.5.1 SHAP Global Behavior Analysis", "content": "We use the SHAP (SHapley Additive exPlanations) method to explain how our selected model arrives at specific classifications for each instance. Fig. 8 highlights the key features identified by SHAP and shows which features contribute the most or least to the model's predictions. Feature names are ordered along the Y-axis in descending order of their impact on the model's predictions, with \u2018rst_count' being the most influential and \u2018Protocol Type' the least. The X-axis represents the absolute means of the SHAP values, using distinct colors to represent different classes (0 \u2013 Benign Class and 1 - Attack Class). The plot shows that SHAP identifies only 20 out of 40 features as significant and influential, excluding those with minimal or no impact. From the plot we can also infer that 'IAT', 'rst_count', \u2018urg_count', 'Header Length', and 'flow_duration' are the top five features significantly influencing the model's outcome."}, {"title": "4.5.2 SHAP Local Behavior Analysis", "content": "The SHAP global summary plot offers a broad view of feature importance across the entire dataset, revealing which features are generally most and least influential in model predictions. However, it does not provide details about how these features affect individual predictions such as why the model made a particular decision for a given data point. This is where local analysis becomes essential. Local analysis using SHAP provides detailed, instance-specific insights into feature contributions, thus enhancing model interpretability and reliability."}, {"title": "A. SHAP Summary Plot", "content": "For SHAP local explanations, we analyzed two representative instances (Sample 1 and Sample 2) from the testing set. For each instance, we examined how individual features influenced the model's decision\u2014 \u2018Benign' or \u2018Attack'. We used SHAP local summary plot to visualize and assess the contribution of each feature to the final prediction, providing detailed insights into the model's decision-making process for these specific instances. Fig. 9 illustrates the SHAP plot, where red and blue colors denote high and low feature values, respectively. Features are ranked by their impact on the prediction, with 'rst_count' being the most influential and 'Protocol Type' being the least influential. Plot (A) clearly the 'Benign' class prediction, while plot (B) strongly suggests an 'Attack' classification."}, {"title": "B. SHAP Force Plot", "content": "To delve deeper into individual testing samples (Sample 1 and Sample 2), we employ SHAP force plots. These visualizations offer a granular breakdown of each feature's contribution to a specific prediction. The plot's base value represents the average model output over the training dataset and serves as a starting point for understanding how features influence predictions. Red bars indicate positive contributions, while blue bars represent negative contributions. The length of each bar illustrates the magnitude of a feature's influence, with longer bars reflecting a greater effect. The final prediction displayed at the end of the plot shows the cumulative effect of all feature contributions, starting from the base value.\nFig. 10 shows the SHAP force plot for testing sample 1. The following conclusions can be drawn from it:\nThe features 'rst_count', 'HTTPS', 'urg_count', 'Radius', 'ack_flag_number', 'flow_duration', and 'Header_Length' are displayed in red, collectively increasing the prediction score from the base value of 0.49 towards a higher value, supporting the model's classification of the network traffic as 'Benign'.\nRed color signifies a positive contribution to the prediction. For instance, higher values of \u2018rst_count' might suggest typical session terminations rather than suspicious activities, indicating benign traffic. Also, higher value of 'HTTPS' are usually associated with legitimate and secure communication, reinforcing the notion that the traffic is benign.\nInterestingly, the SHAP force plot for this instance does not highlight 'IAT', previously identified as a crucial feature in the global model. This discrepancy underscores the importance of local explanations, as feature influence can vary significantly across different data points. It suggests that while 'IAT' is generally influential, its impact on this specific case is minimal."}, {"title": "4.5.3 LIME Explainer", "content": "The LIME results present the prediction probabilities for each class and are divided into three sections:\nThe leftmost section displays the prediction probabilities.\nThe middle section highlights the most crucial features, with blue representing attributes that support Class 0 and orange representing those that support Class 1. The importance of these features is shown as floating-point numbers.\nThe same color scheme is used throughout all sections. The actual values of the top five variables are shown in the final section."}, {"title": "A. LIME Plot - Record Sample 1", "content": "Fig. 12 shows the LIME plot for record sample 1, where the prediction is 'Benign traffic. The following conclusions can be drawn:\nThe features 'IAT', 'rst count', 'Std', 'rst_flag_number', and 'flow_duration' are all depicted in blue, indicating that these features negatively impact the prediction,"}, {"title": "B. LIME Plot - Record Sample 2", "content": "Fig. 13 displays the LIME plot for record sample 2, where the prediction is 'Attack' traffic. The following conclusions can be drawn:\nThe features such as 'syn_flag_number', 'rst_flag_number', 'IAT', 'rst_count', and 'ARP' are highlighted in orange, indicating their positive contribution to"}, {"title": "4.6 Feature Analysis and Cross Validation Using SHAP, LIME, and XGBoost", "content": "In this section, we perform a detailed feature analysis by comparing XGBoost's predictions with the explanations provided by SHAP and LIME. We also assess the consistency of SHAP and LIME in identifying key features. This comparison helps validate the crucial factors driving the model's decisions, enhancing transparency and reliability in detecting IoT attacks. Through this analysis, we aim to establish a"}]}