{"title": "FedDUAL: A Dual-Strategy with Adaptive Loss and Dynamic Aggregation for Mitigating Data Heterogeneity in Federated Learning", "authors": ["Pranab Sahoo", "Ashutosh Tripathi", "Sriparna Saha", "Samrat Mondal"], "abstract": "Federated Learning (FL) marks a transformative approach to distributed model training by combining locally optimized models from various clients into a unified global model. While FL preserves data privacy by eliminating centralized storage, it encounters significant challenges such as performance degradation, slower convergence, and reduced robustness of the global model due to the heterogeneity in client data distributions. Among the various forms of data heterogeneity, label skew emerges as a particularly formidable and prevalent issue, especially in domains such as image classification. To address these challenges, we begin with comprehensive experiments to pinpoint the underlying issues in the FL training process. Based on our findings, we then introduce an innovative dual-strategy approach designed to effectively resolve these issues. First, we introduce an adaptive loss function for client-side training, meticulously crafted to preserve previously acquired knowledge while maintaining an optimal equilibrium between local optimization and global model coherence. Secondly, we develop a dynamic aggregation strategy for aggregating client models at the server. This approach adapts to each client's unique learning patterns, effectively addressing the challenges of diverse data across the network. Our comprehensive evaluation, conducted across three diverse real-world datasets, coupled with theoretical convergence guarantees, demonstrates the superior efficacy of our method compared to several established state-of-the-art approaches. The code can be found at https://github.com/Pranabiitp/FedDUAL.", "sections": [{"title": "Introduction", "content": "Federated learning (FL) has revolutionized collaborative model training by enabling multiple clients to contribute to a global model without compromising the privacy of their local data (McMahan et al., 2017). This decentralized strategy avoids the need for sending data to a central server, thus maintaining data privacy. As the digital landscape evolves, with an increasing number of distributed data sources emerging from mobile devices, healthcare institutions, and Internet of Things (IoT) networks, FL has emerged as a pivotal solution for training sophisticated deep networks across geographically dispersed and heterogeneous environments (Bonawitz et al., 2016), Sahoo et al. (2024b), (Hu et al., 2024). However, a significant practical obstacle encountered during federated training is data heterogeneity in the form of skewness in labels and quantity of the data across various clients (Kairouz et al., 2021), (Li et al., 2020). Diverse user behaviors can lead to significant heterogeneity in the local data of different clients, leading to non-independent and identically distributed (non-IID) data. This variability can introduce biases in model training, leading to unstable convergence and potentially degrading the model's performance or making it counterproductive (Li et al., 2022), (Zhao et al., 2018). While FedAvg (McMahan et al., 2017) is effective and widely used, it often falls short in accuracy and convergence with static aggregation methods. These methods combine model updates from different clients in a fixed manner, failing to adapt to heterogeneous data distributions and client drift, as discussed in (Karimireddy et al., 2020).\nPrevious studies have addressed the issue of client drift by implementing penalties for deviations between client and server models (Li et al., 2020), (Li et al., 2021a), employing variance reduction techniques during client updates (Karimireddy et al., 2020), (Acar et al., 2021), or utilizing novel aggregation methods on the server side (Chen et al., 2023), (Chowdhury & Halder, 2024)."}, {"title": "1.1 Motivation", "content": "Prior studies by Yashwanth et al. (2024), Hu et al. (2024) have demonstrated that in non-IID scenarios, federated models tend to converge to 'sharp minima', resulting in significant performance degradation and compromised generalizability. In this study, we investigate the root causes of this phenomenon and propose a novel solution to mitigate its effects. Our study begins with a detailed analysis of loss landscapes for FedAvg-trained models across IID and non-IID data distributions. \nThis prompts one critical question: Can static aggregation methods effectively address severe non-IID data distributions across clients while maintaining higher convergence, performance, and generalizability in federated models? The answer is decidedly negative. Static aggregation methods inherently struggle with the dynamic heterogeneity present in federated networks, where adjusting parameters based on client distributions and performance in each communication round is crucial. Although incorporating predetermined parameters into the aggregation process may provide some partial mitigation, these methods fail to address the complex challenges posed by non-IID data distributions. A more dynamic and nuanced approach is necessary to effectively manage these multifaceted issues. To address this challenge, we apply dynamic aggregation to the model's final layers, where gradient norms fluctuate significantly in non-IID scenarios, while using traditional aggregation (FedAvg) for the lower layers. For dynamic aggregation, we leverage the concept of Wasserstein Barycenter (Agueh & Carlier, 2011), derived from optimal transport theory, to integrate client-specific learning behaviors in these affected layers. By minimizing discrepancies from non-IID data, the Wasserstein Barycenter helps to align gradients from diverse clients, offering precise model updates. This approach ensures fair aggregation, adapts to data heterogeneity, reduces bias, and enhances robustness, ultimately leading to more stable model convergence and improved generalization.\nIn addition to the server-side dynamic aggregation, we introduce an adaptive loss function for local training on the client side. This function allows clients to effectively explore the minima on their local datasets while preventing overfitting, thereby enhancing local optimization. Simultaneously, it preserves the global knowledge of the federated model, ensuring that the benefits from all participating clients are integrated. By incorporating a regularization parameter, \u03b2, the local loss function dynamically balances the trade-offs between local and global objectives. The contributions of this paper are as follows:\n\u2022 We introduce FedDUAL, an innovative dual-strategy approach designed to effectively develop a robust and generalized federated model in highly heterogeneous data environments.\n\u2022 We introduce an adaptive loss function for client-side training to balance the trade-offs between local and global objectives.\n\u2022 Instead of straightforward server-side averaging, we propose a dynamic aggregation technique that uses Wasserstein Barycenter to reduce the effects of non-IID data by integrating the learning behaviors of participating clients.\n\u2022 We conducted extensive experiments on three real-world datasets, demonstrating significant performance improvements over state-of-the-art methods and offering theoretical convergence guarantees for both convex and non-convex scenarios."}, {"title": "2 Related Work", "content": "The landscape of FL research has been significantly shaped by efforts to address data heterogeneity challenges, yielding a diverse array of innovative solutions. These approaches can be divided into three primary categories: (1) client drift mitigation strategies, which refine local client objectives to foster better alignment with the global model (Li et al., 2021a), (Karimireddy et al., 2020), (Acar et al., 2021), (Luo et al., 2021), (Li et al., 2023) (2) aggregation scheme optimization, aimed at enhancing server-side fusion of model updates (Hsu et al., 2019), (Lin et al., 2020), (Wang et al., 2020b), (Wang et al., 2020a) and (3) personalized FL, which tailors models to individual clients (Fallah et al., 2020), (Sattler et al., 2020), (Bui et al., 2019). Our research primarily focuses on two interconnected aspects of FL: mitigating client drift and optimizing server-side aggregation, and we will discuss the same in the literature review.\nMcMahan et al. (2017) introduced FL as an extension of local Stochastic Gradient Descent (SGD) (Stich, 2019), enabling increased local gradient updates on client devices before server synchronization and significantly reducing communication costs in identically distributed data settings. However, the method faces considerable obstacles when dealing with non-IID scenarios. Since then, various methods have emerged to address the challenge of data heterogeneity in FL (Li et al., 2019), (Yang et al., 2021), (Lin et al., 2018), (Hsu et al., 2019). FedProx (Li et al., 2020) incorporates a proximal regularization term to the optimization function to reduce model drift and addresses client stragglers. However, this term can also lead to local updates being biased towards the previous global model, which may result in misalignment between local and global optima. Building on previous work, Acar et al. (2021) introduced a dynamic regularization term to align local updates more closely with global model parameters, effectively reducing client drift caused by local model overfitting. Sun et al. (2023) further advanced the field with a momentum-based algorithm that accelerates convergence by combining global gradient descent with a locally adaptive optimizer. Similarly, several studies use variance reduction techniques, such as SCAFFOLD (Karimireddy et al., 2020). However, this approach often results in higher communication costs due to the transmission of additional control variates (Halgamuge et al., 2009). FedPVR (Li et al., 2023) addresses these limitations by reassessing FedAvg's performance on deep neural networks, uncovering substantial diversity in the final classification layers. By proposing a targeted variance reduction strategy focused solely on these final layers, FedPVR outperforms several benchmarks. MOON (Li et al., 2021a) introduces an innovative model-contrastive framework leveraging a contrastive loss to align local client representations with the global model, effectively mitigating client drift, and enhancing convergence, particularly in challenging non-IID environments. Luo et al. (2021) introduced CCVR (Classifier Calibration and Variance Reduction), which employs a classifier regularization and calibration method to enhance federated learning performance. CCVR's approach involves fine-tuning the classifier using virtual representations sampled from an approximated Gaussian mixture model. Shi et al. (2023) introduced a novel differentially private federated learning (DPFL) algorithm that integrates the Sharpness-Aware Minimization (SAM) optimizer to enhance stability and robustness against weight perturbations. By generating flatter loss landscapes and reducing the impact of differential privacy (DP) noise, it mitigates performance degradation and achieves state-of-the-art results, supported by theoretical analysis and rigorous privacy guarantees. Fan\u00ec et al. (2024) proposed FED3R, leveraging Ridge Regression on pretrained features to tackle non-IID data challenges, effectively mitigating client drift, enhancing convergence, and optimizing efficiency in cross-device settings.\nAnother line of research targets optimizing server-side aggregation in FL. For instance, Hsu et al. (2019) investigated the impact of non-IID data on visual classification by creating datasets with diverse distributions and found that increased data heterogeneity negatively affected performance, leading them to propose server momentum as a potential solution. FedNova (Wang et al., 2020b) addressed the problem of objective inconsistency due to client heterogeneity in federated optimization by introducing a normalized averaging technique, which resolves this inconsistency and ensures rapid error convergence. Addressing the limitations of traditional parameter averaging methods, Lin et al. (2020) introduced ensemble distillation for model fusion. This approach allows for the flexible aggregation of heterogeneous client models by training a central classifier on unlabeled data, using the outputs from the client models as guidance. FedMRL (Sahoo et al., 2024a) introduced a novel framework by using a loss function that promotes fairness among clients and employed a multi-agent reinforcement learning for personalized proximal terms, and a self-organizing map to dynamically adjust server-side weights during aggregation."}, {"title": "3 Methods and Materials", "content": "We consider a practical FL scenario with non-IID data distribution among K independent clients, each with local training data $D_k(x,y)$, where $(x,y)$ denoting the data points. We initialize the global model weights $\u03b8^g$ and share it to the participating clients. The clients download the weighs from the server and train it using their local dataset $D_k(x,y)$. The updated model parameters from each client k for rth communication round are uploaded to the server to aggregate into a global model $\u03b8^g$. Our objective is to develop a robust global model by collaboratively training local models across clients, even under varying heterogeneous conditions. To formalize, we define the optimal global model $\u03b8^*$ as follows:\n$\u03b8^* = \\underset{\u03b8}{min} F(\u03b8) = \\frac{1}{K} \\sum_{k=1}^{K} f_k(\u03b8)$\nwhere $f_k(\u03b8)$ is defined in Eq. 2.\n$f_k(\u03b8) = E_{(x,y)\u223cD_k}[l(f_\u03b8(x), y)]$\nwhere \u03b8 represents the global model parameters, $f_\u03b8(x)$ is the model's prediction, and l is the loss function."}, {"title": "3.0.1 Client Side Update.", "content": "At the beginning of each round t, the server randomly selects a subset $S_t \u2282 K$ of clients to participate in the federated training process and subsequently shares the current global model $\u03b8_t^g$ to these participating clients. Each client updates its local model by initializing with the global model parameters $(\u03b8_t^l)_k = \u03b8_t^g$ and then updates its local model by minimizing the local objective function. For local training, we have developed an adaptive objective function that balances local loss with the divergence between local and global models. The extent of this divergence is quantified using the Kullback-Leibler (KL) divergence (Csisz\u00e1r, 1975), which effectively compares the probability distributions of the local model weights $p_k(w)$ with the global model weights $q(w)$. The KL divergence is mathematically defined in Eq. 4. To obtain the probability distributions of the local and global model weights, we first flatten the weights and then apply the softmax function. This process yields the desired probability distributions (p), as specified in Eq. 3.\n$p = \\frac{exp(flatten weights)}{\\sum exp(flatten weights)}$\n$D_{KL} (p_k || q) = \\sum p_i^k(w) log(\\frac{p_i^k(w)}{q_i(w)})$ \nwhere $p_i^k$ and $q_i$ are the probabilities associated with the $i^{th}$ component of the weight vectors. The local model must excel on local data while maintaining alignment with the global model to enhance overall generalization. This balance between minimizing local loss and aligning with the global model is defined as local adaptive function $L_{adaptive}^k$ in Eq. 5.\n$L_{adaptive}^k = (1 - \u03b2) * L_{Local}^k + \u03b2 * D_{KL}(p_k || q)$\nwhere $L_{Local}^k$ is cross-entropy loss for kth client and \u03b2 is a regularization parameter and should be adaptive to account for the performance discrepancy between the local and global models. When the local model substantially outperforms the global model, \u03b2 should increase to enforce greater alignment. Conversely, if the models perform similarly, \u03b2 should decrease, allowing the local model to focus more on local optimization. The definition of \u03b2 is given in Eq. 6.\n$\u03b2^k = \u03c3(A_{local}^k - A_{global}^k)$"}, {"title": "3.0.2 Server Side Update.", "content": "where \u03c3 is the sigmoid function, $A_{local}^k$ represents the local model accuracy, and $A_{global}^k$ is the global model accuracy for client k. We calculated the global model's accuracy $A_{global}^k$ for client k by evaluating it on the training data of client k prior to performing local updates in the current round. Incorporating the adaptive parameter \u03b2 in Eq. 5, the adaptive loss function for client k is represented in Eq. 7.\n$L_{adaptive}^k = (1 \u2013 (\u03c3(A_{local}^k - A_{global}^k)) * L_{Local}^k + \u03c3(A_{local}^k - A_{global}^k) * D_{KL}(p_k || q)$\nAfter defining the adaptive loss function for each client, we optimize the local model parameters using stochastic gradient descent (SGD). The gradient update for the local model weights $w_t^k$ based on the adaptive loss function is given in Eq. 8.\n$w_{t+1}^k = w_t^k \u2013 \u03b7 \\nabla_{w} L_{adaptive}^k(w_t^k)$\nwhere \u03b7 is the local learning rate. Expanding the gradient term $\\nabla_{w} L_{adaptive}^k(w_t^k)$, we obtain Eq. 9.\n$\\nabla_{w} L_{adaptive}(w_t^k) = (1 - (\u03c3(A_{local}^k - A_{global}^k))\\nabla_{w} L_{Local}^k (w_t^k) + \u03c3(A_{local}^k - A_{global}^k) \\nabla_{w} D_{KL}(p_k || q)$\nThe KL divergence term, $\u03c3(A_{local}^k - A_{global}^k)\\nabla_{w} D_{KL}(p_k || q)$ in Eq. 9, acts as a regularizer to keep the local model gradients aligned with the global model gradients, thereby preserving model coherence despite non-IID data.\nBy dynamically adjusting the regularization parameter \u03b2 based on the performance difference between local and global models, the adaptive loss function enhances the alignment of local models with the global model, thereby improving generalization and performance in non-IID scenarios. When local performance is less compared to global, the regularization term \u03b2 amplifies the focus on local optimization (first term in Eq. 5), enabling better-performing clients to explore local optima more effectively. Conversely, if the global model performs better, this term shifts the emphasis towards aligning with the global model (second term in Eq. 5), thereby supporting clients that are struggling by incorporating global knowledge.\nAfter obtaining the weights from the participating clients at round t, the server calculates the Wasserstein Barycenter to effectively aggregate the weights of the last layers of the client models. Computing exact Wasserstein Barycenter can be computationally expensive, so we have approximated it using the Sinkhorn-Knopp (Knight, 2008) algorithm for efficient computation. We consider the local model weights as distributions and assign equal importance to each client in the computation of the Wasserstein Barycenter (\u03bc). This barycenter represents the distribution that minimizes the sum of Wasserstein distances to the individual client gradient distributions, as formally defined in Eq. 10.\n$\u03bc = \\underset{\u03bd}{arg min} \\sum_{k=1}^{K} W (\u03bc_\u03ba, \u03bd)$\nwhere $\u03bb_k$ are weights corresponding to the importance or reliability of the client k. The Wasserstein distance $W(\u03bc_\u03ba, \u03bc_j)$ between two gradient distributions $\u03bc_\u03ba$ and $\u03bc_j$ of clients j and k is defined in Eq. 11.\n$W (\u03bc_\u03ba, \u03bc_j) = \\underset{\u03b3\u2208\u0393(\u03bc_\u03ba,\u03bc_j)}{inf}  (\\int_{XXX} d(x, y)^p d\u03b3(x, y))^{1/p}$\nwhere $\u0393(\u03bc_\u03ba, \u03bc_j)$ denotes the set of all couplings (or joint distributions) \u03b3 on X \u00d7 X with marginals $\u03bc_\u03ba$ and $\u03bc_j$ respectively, and d(x, y) is the distance between points x and y in the metric space X. After that, we use Sinkhorn-Knopp algorithm to calculate the Wasserstein Barycenter."}, {"title": "4 Experimental Results", "content": "To assess the effectiveness of the proposed FedDUAL approach, we conducted extensive experiments using three widely recognized classification benchmarks: CIFAR10 (Krizhevsky et al., 2009), CI-"}, {"title": "4.1 Experimental Setup", "content": "FAR100 (Krizhevsky, 2009), and FMNIST (Xiao et al., 2017). To simulate real-world non-IID data distributions, we employed a client-wise partitioning strategy based on the Dirichlet distribution (Hsu et al., 2019). This distribution is governed by a concentration parameter \u03b1, which controls the degree of data heterogeneity among clients. Lower \u03b1 values result in more skewed data distributions, closely mimicking uneven data partitions. In all experiments, we set \u03b1 = 0.01 to simulate severe data heterogeneity, closely approximating real-world conditions. Throughout the communication rounds, each client retains a fixed local data partition. To evaluate the global model's classification performance, we use a separate test dataset maintained at the server, which remains unseen during training. For our experiments, we used LeNet (LeCun et al., 1998) for FMNIST dataset and a pre-trained VGG16 (Simonyan & Zisserman, 2015) for CIFAR-10 and CIFAR-100 dataset, following the methodology outlined in (Hu et al., 2024). We applied the proposed dynamic aggregation mechanism only to the last two layers of these models. Our setup involved 100 clients, with 10% randomly sampled per communication round, and a batch size of 32. Each client performed three local epochs of model updates. We have computed each result three times with different seed values and reported the mean value with standard deviation. To determine the optimal client learning rate for each experiment, we conducted a grid search over 0.05, 0.01, 0.2, 0.3. For the baseline FedProx, we tested proximal values of 0.001, 0.1, 0.4, 0.7 to find the optimal setting, and for FedNova, we evaluated proximal SGD values from 0.001, 0.003, 0.05, 0.1, following the recommendations in Li et al. (2024). Across all experiments, we used the Adam optimizer for consistency. We have run each algorithm three times and reported the average outcome. The experimental setup utilized an NVIDIA Quadro RTX 4000 GPU boasting 40GB of memory. The implementation was crafted using Python, leveraging the TensorFlow framework utilizing Windows 11."}, {"title": "4.2 Comparison with the State-of-the-art Methods", "content": "We evaluate the proposed FedDUAL method against eight notable state-of-the-art (SOTA) FL baselines, including FedAvg (McMahan et al., 2017), FedProx (Li et al., 2020), FedNova (Wang et al., 2020b), SCAF-FOLD (Karimireddy et al., 2020), FedBN (Li et al., 2021b), FedDyn (Acar et al., 2021), MOON (Li et al., 2021a) and FedPVR (Li et al., 2023)."}, {"title": "4.2.1 Baseline.", "content": "We evaluate the proposed FedDUAL method against eight notable state-of-the-art (SOTA) FL baselines, including FedAvg (McMahan et al., 2017), FedProx (Li et al., 2020), FedNova (Wang et al., 2020b), SCAF-FOLD (Karimireddy et al., 2020), FedBN (Li et al., 2021b), FedDyn (Acar et al., 2021), MOON (Li et al., 2021a) and FedPVR (Li et al., 2023)."}, {"title": "4.2.2 Comparison of Accuracy.", "content": "The results, detailed in Table 1, reveal that many recent FL methods often fall short compared to the standard FedAvg baseline. In contrast, our proposed method consistently achieves SOTA performance, surpassing FedAvg along with other baselines across all evaluated scenarios. Furthermore, our approach exhibits remarkable adaptability across diverse datasets. Unlike some algorithms that excel on specific datasets but falter on others, the proposed FedDUAL consistently outperforms baselines across a wide range of data environments. This improvement suggests that our method addresses fundamental challenges in FL, potentially offering a more generalizable solution to the issues posed by data heterogeneity in federated settings. We also observed that FedNova, FedBN, and Scaffold did not perform effectively in our experimental setup."}, {"title": "4.2.3 Comparison of Convergence.", "content": "We also provide a comparative review of learning process, as shown in Fig. 3, where we present the learning curves of our method with the baselines. The results demonstrate a consistent pattern: our approach exhibits accelerated learning and achieves superior accuracy across all tested scenarios. While the communication rounds vary by dataset, we observe that model performance reaches a saturation point by the conclusion of these rounds. Notably, our method not only attains a more robust final model but also displays markedly faster convergence across all datasets examined. This effectiveness is further highlighted in Fig. 4, where it consistently reaches target accuracy with far fewer communication rounds compared to baseline approaches."}, {"title": "4.3 Validation of the Motivation", "content": "To substantiate our claim that the proposed method yields models in flatter loss landscapes compared to FedAvg, we conducted a comparative analysis. Using VGG-16 models trained on the FMNIST dataset under non-IID conditions (\u03b1 = 0.01), we visualized their respective loss landscapes following the approach outlined in Li et al. (2018). Figure 6 in the Appendix depicts these landscapes, with each model centrally located within its respective terrain. The visualization reveals that our proposed method situates the model in a notably flatter region compared to FedAvg. This finding supports our assertion that our approach guides federated training towards more stable and generalizable solutions, characterized by flatter loss landscapes."}, {"title": "5 Ablation Study", "content": "In our ablation study, we performed all experiments on the FMNIST dataset with \u03b1 = 0.01. The study comprised four types of experiments: (1) performance analysis of the individual modules, (2) assessment of the impact of dynamic aggregation across different neural network layers, (3) hyperparameter analysis, and (4) evaluation of various levels of data heterogeneity. The results of the first and second experiments are detailed in the following subsections, while the third and fourth experiments are presented in Sections F of the Appendix."}, {"title": "5.0.1 Performance Analysis of Individual Modules.", "content": "To demonstrate the significance of our proposed adaptive loss function and dynamic aggregation technique, we conducted three distinct experiments, with results summarized in Table 2. The first experiment utilized only the adaptive loss function, paired with simple server-side aggregation. The second implemented our dynamic aggregation technique at the server, while retaining the conventional cross-entropy loss function locally. Finally, the third experiment combined both proposed methods: the adaptive loss function and dynamic aggregation technique. As evidenced by Table 2, the integration of both proposed approaches in the third experiment yielded the highest accuracy, highlighting the impact of our dual strategy on model performance. The learning curves for these experiments are illustrated in Fig. 7 of the Appendix."}, {"title": "5.0.2 Impact of Dynamic Aggregation on Different Network Layers.", "content": "To substantiate our decision to apply dynamic aggregation technique selectively to last layers, we examined its impact across various layers of the neural network. Our earlier findings highlighted that data heterogeneity primarily affects last layers of the network. Figure 5 illustrates that random utilization of the dynamic aggregation to all layers diminishes performance. Conversely, targeted implementation on layers proximal to the classifier yielded optimal accuracy and convergence. These outcomes validate our hypothesis and demonstrate the method's efficacy in mitigating heterogeneity-induced issues. By focusing our dynamic aggregation technique on the most susceptible layers, we directly address the core challenge of data heterogeneity in federated training, resulting in enhanced model performance and faster convergence."}, {"title": "6 Limitation", "content": "The proposed FedDUAL framework tackles heterogeneous data challenges in federated training, outperforming baselines through an adaptive client-side loss function and dynamic server-side aggregation via the Wasserstein Barycenter. While the proposed method significantly enhance performance and accelerate convergence, they introduce additional computational overhead at the server due to the iterative calculation of the Wasserstein Barycenter. Conversely, the adaptive loss function on the client side is computationally efficient, incurring minimal cost. Future research will focus on reducing the computational burden of the Wasserstein Barycenter calculation by developing more efficient algorithms, aiming to maintain or even improve the performance of the proposed framework."}, {"title": "7 Conclusion", "content": "This research presents a novel approach to address the challenges posed by data heterogeneity among clients in the federated approach. We systematically analyze the factors contributing to federated model performance degradation under severe data heterogeneity and propose an architecture incorporating dual-strategy innovations. First, we implement an adaptive loss function for client-side training. Second, we create a dynamic aggregation strategy for server side aggregation, tailored to client-specific learning behaviors. The proposed FedDUAL effectively overcomes the challenges of heterogeneous data, outperforming eight SOTA baselines. It demonstrates faster convergence and consistently improved performance, making it an excellent solution for large-scale FL applications in real-world scenarios. Our approach's flexibility paves the way for research into hybrid federated learning models that adapt to changing client environments and data. Future studies will focus on integrating personalized learning paths to enhance model adaptability and efficiency across various datasets."}, {"title": "A Appendix", "content": null}, {"title": "B Convergence Proof", "content": null}, {"title": "B.1 Preliminaries", "content": null}, {"title": "B.1.1 Notation", "content": "Let W denote the parameter space, $f_i : W \u2192 R$ be the loss function for the ith client, and F: W\u2192 R be the global objective function."}, {"title": "B.2 Assumptions", "content": null}, {"title": "1. Lipschitz Smoothness", "content": "For all i, $f_i$ is L-smooth such that it follows Eq. 14.\n$\\Vert \\nabla f_i(w) \u2013 \\nabla f_i(w')\\Vert \u2264 L\\Vert w \u2013 w'\\Vert, \u2200w, w' \u2208 W$"}, {"title": "2. Bounded Variance", "content": "The variance of stochastic gradients is bounded by Eq. 15.\n$E\\Vert \\nabla f_i(w, \u03be) \u2013 \\nabla f_i(w)\\Vert^2 < \u03c3^2,\u2200w \u2208 W$\nwhere \u03be represents the random sampling of data."}, {"title": "C Convergence Analysis for Convex Setting", "content": "Under Assumptions 1-2, for the proposed federated learning algorithm FedDUAL with adaptive loss and Wasserstein barycenter based dynalic aggregation, if the objective function F is convex, we have the inequality 16.\n$E[F(w_T) - F(w^*)] \u2264 \\frac{C}{\\sqrt{T}}$\nwhere $\\omega_T = \\frac{1}{T} \\sum_{t=1}^T w_t$ is the average of the iterates, $w^*$ is the optimal parameter, and C is a constant depending on the problem parameters.\nStarting from inequality 16, we get the inequality 17.\n$E[F(w_{t+1}) \u2013 F(w_t)] \u2264 \u2212\u03b7_t\\Vert\u2207F(w_t)\\Vert^2 + \\frac{L\u03b7_t}{2}E\\Vert\u0394_t\\Vert^2$\nSo We have bounded $E\\Vert\u0394_t\\Vert^2 < 2(\u03bb_{max}L_{KL})^2 + 2\u03c3^2/K$. Let's denote $G^2 = 2(\u03bb_{max}L_{KL})^2 + 2\u03c3^2/K$ for simplicity.\nNow, by convexity of F, we have the inequalty 18.\n$F(w_t) - F(w^*) < \\langle \u2207F(w_t), w_t \u2013 w^* \\rangle$"}, {"title": "D Convergence Analysis for Non-Convex Setting", "content": "Under Assumptions 1-2, for the proposed federated learning algorithm with adaptive loss and Wasserstein barycenter based dynamic aggregation in the non-convex setting, we have the inequality 19:\n$\\frac{1}{T}\\sum_{t=0}^{T-1} E \\Vert \u2207F(w_t) \\Vert^2 \\le \\frac{C}{\\sqrt{T}}$\nwhere C is a constant depending on the problem parameters.\nWe start with the same inequality given in 20.\n$E[F(w_{t+1}) - F(w_t)] \\le -\u03b7_t\\Vert \u2207F(w_t)\\Vert^2 + \\frac{L\u03b7_tG^2}{2}$"}, {"title": "E Discussion on convergence rates", "content": null}, {"title": "E.1 Convex Setting", "content": "In the convex setting, The rate is optimal for first-order stochastic methods in convex optimization. The key points are:\n1. The result is for the average iterate $\u1ff6_\u03c4$, which is common in convex stochastic optimization.\n2. The rate depends on the initial distance to the optimum $||w_0 \u2013 w^*||$, the initial suboptimality F($w_0$)\n\u2013 F($w^*$), and the bound on the stochastic gradients $G^2$."}, {"title": "E.2 Non-Convex Setting", "content": "For the non-convex setting, The result is significantly different from the convex case:\n1. We measure convergence in terms of the gradient norm, not the function value, as finding global minima is generally intractable in non-convex settings.\n2. The result is for the average of the squared gradient norms, not the minimum.\n3. This rate is also optimal for first-order stochastic methods in non-convex smooth optimization."}, {"title": "E.3 Comparison and Implications", "content": "1. Different Metrics: The convex and non-convex results use different metrics for convergence, which is standard in optimization theory. In the convex case, we bound the suboptimality of the function value, while in the non-convex case, we bound the average squared gradient norm.\n2. Similarity in Rates: Both settings achieve an O(1/\u221aT) rate, but the meaning is different. In the convex case, this rate applies to the optimality gap, while in the non-convex case, it applies to the average squared gradient norm."}, {"title": "F Ablation Study", "content": null}, {"title": "F.1 Hyperparameter Analysis", "content": "In the proposed architecture, there are two key hyperparameters to consider: the scaling factor (\u03b3) and the number of iterations used to compute the Wasserstein Barycenter. The detailed analysis of these hyperparameters is provided below.\nThe proposed FedDUAL approach utilizes dynamic server-side aggregation by applying the Wasserstein Barycenter concept to combine the weights of the final layers from local models. This iterative process involves a small positive constant (\u03f5) to determine the scaling factor (\u03b3). To optimize performance, we conducted two sets of experiments on the FMNIST dataset with \u03b1 = 0.01, each exploring a range of values for these crucial hyperparameters. The hyperparameter \u03f5 influences the sensitivity of the barycenter calculation to variations in Wasserstein distance. A smaller \u03f5 makes the barycenter more responsive to differences in"}, {"title": "4.2.1 Baseline", "content": "We evaluate the proposed FedDUAL method against eight notable state-of-the-art (SOTA) FL baselines, including FedAvg (McM"}]}