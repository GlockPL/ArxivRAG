{"title": "Discern-XR: An Online Classifier for Metaverse Network Traffic", "authors": ["Yoga Suhas Kuruba Manjunath", "Austin Wissborn", "Mathew Szymanowski", "Mushu Li", "Lian Zhao", "Xiao-Ping Zhang"], "abstract": "In this paper, we design an exclusive Metaverse network traffic classifier, named Discern-XR, to help Internet service providers (ISP) and router manufacturers enhance the quality of Metaverse services. Leveraging segmented learning, the Frame Vector Representation (FVR) algorithm and Frame Identification Algorithm (FIA) are proposed to extract critical frame-related statistics from raw network data having only four application-level features. A novel Augmentation, Aggregation, and Retention Online Training (A2R-OT) algorithm is proposed to find an accurate classification model through online training methodology. In addition, we contribute to the real-world Metaverse dataset comprising virtual reality (VR) games, VR video, VR chat, augmented reality (AR), and mixed reality (MR) traffic, providing a comprehensive benchmark. Discern-XR outperforms state-of-the-art classifiers by 7% while improving training efficiency and reducing false-negative rates. Our work advances Metaverse network traffic classification by standing as the state-of-the-art solution.", "sections": [{"title": "I. INTRODUCTION", "content": "The Metaverse, a concept combining virtually shared spaces and extended reality (XR), encompasses VR, AR, and MR, transforming how people interact, work, and play. Users require a head-mounted display (HMD), software platforms, services, and network connectivity to experience the Metaverse, making exceptional network traffic management (NTM) essential for Internet Service Providers (ISPs) to deliver optimal Quality of Service (QoS) and Quality of Experience (QoE) [1]. Low latency and adequate bandwidth are crucial for Metavrese to avoid cybersickness [2]. Therefore, efficient resource allocation and network tuning are vital for ISPs to manage the increasing demand, which requires accurate identification of Metaverse network traffic through network traffic classification (NTC) [3]. Identifying Metaverse network traffic serves multiple purposes, including traffic prioritization, resource allocation, security, and monetization [1]. Also, the NTC is required to optimize the QoS, UE route selection policy (URSP), and for security, highlighting the need for further research in this area [4], especially for the unexplored Metaverse network traffic.\nA decision trees-based AR and cloud gaming traffic classification is proposed in [5]. The work also provides pre-processed uplink and downlink AR traffic data. While, on average, the work achieves 96% accuracy in classifying uplink traffic, the accuracy in classifying downlink traffic is limited on 89%. Downlink traffic is bandwidth-demanding, and the classification accuracy achieved by this work is not sufficient to help efficient traffic management. Other work [6] helps classify VR traffic using application-level information, which is imperative in avoiding expensive deep packet inspection (DPI) software that violates privacy-related policies. The solution provides stellar 99% accuracy in classifying VR traffic among other applications. However, it is difficult for the proposed method to be further generalized to classify the traffic of other Metaverse services, such as AR, MR, and other VR-related services. Recently, a deep learning-based solution is proposed for Metaverse traffic classification [7]. The solution achieves 87% accuracy while classifying the traffic of three Metaverse classes: network infrastructure, real-time conversation, and non-conversational applications. Based on the literature survey, we identify the following research gaps: i) non-availability of comprehensive real-world Metaverse network traffic data, and ii) accurate Metaverse network traffic classifer. We address both gaps in this paper. The work [7] is considered a state-of-the-art work (SoA) since it is close to our experiment; however, the data used in the work are not pure Metaverse network traffic.\nWe propose a segmented learning-based Metaverse network traffic classifer, called Discern-XR. Our solution treats the Metaverse network traffic in segments of traffic packets with four raw features: time, packet length, packet direction, and packet inter-arrival time. We propose a Frame Vector Representation (FVR) algorithm that uses the Frame Identification Algorithm (FIA) to extract frame-related statistics and the statistics of the segments from the four raw features. The working principle behind the proposed algorithm is to identify the different statistical behaviours in the Metaverse services that provide vital and distinctive information for a superior classification. We propose an Augmentation, Aggregation, and Retention Online Training (A2R-(OT)) algorithm that"}, {"title": "II. SYSTEM MODEL", "content": "Let $p_{j,i}$ represent the packet of a Metaverse traffic service $s_i$, where $i$ is an index for different services and $j$ is an index of packets. Each packet $p$ is a vector with four raw features: time, packet length, packet direction, and packet inter-arrival time. Let $X = {X_1, X_2, ..., X_N}$ represent the set of $N$ network traffic segments. The element $X_k$, for $k = {1,2,..., N}$, is a matrix of dimension $(S \\times 4)$, where $S$ is the size of the segment, and 4 is the number of features. The raw network traffic segment $X_k$ is transformed into a set of statistical feature vectors $v(X_k)$ through a feature transformation function $\\phi$, which transforms the raw matrix into a statistical feature vector, which is given as\n$\\upsilon(X_k) = \\phi(X_k).$\nAfter integrating the feature vectors for all traffic segments, the resultant feature matrix is given as ${(\\upsilon(X_1), \\upsilon(X_2), ..., v(X))}$. Each statistical vector $v(X_k)$ is associated with a service label $y \\in {1,2,3, ..., C'}$, where $C$ represents the number of services. A mapping function $F$ classifies each segment into its correct service category, which is given as\n$F(v(X_k)) = Y_k.$\nWe need to maximize the accuracy while finding a mapping function $F$ by minimizing the error. Let $L(y_k, \\hat{y}_k)$ be the loss function that quantifies the error between the true label $y_k$ and the predicted label $\\hat{y}_k$. The training objective is\n$\\min_{F}\\sum_{k=1}^{N}L (Y_k, \\hat{y}_k),$\nwhere $F$ represents the mapping function and $N$ represents the number of segments. Data, segment size, and statistical features during the training play a crucial role in minimizing the loss function.\nThe proposed solution operates on two principles: the similarity of statistical characteristics for the traffic segments from the same service and the uniqueness of these statistical patterns across different services.\nPrinciple 1: Vector s represents a set of different services, where i is the index of services. Vector v denotes the statistical vector of the k-th traffic segment of i-th service corresponding to $s_i$. For all statistical vectors of segments, $v$, within a service $s_i$, the statistical features should follow a similar distribution, denoted as $f(s_i)$. The property is given as\n$f(v) \\approx f(s_i), \\forall k,$\nindicating that the segments from the same service exhibit statistical similarity.\nPrinciple 2: Let $s_i$ and $s_j$ be different services, where i \u2260 j. According to principle 1, a similar statistical distribution is expected among the segments for each service. However, the statistical distributions of those segments for two services are different, which is given as\n$f(s_i) \\neq f(s_j).$\nNote that Principle 1 holds well with the optimal segment size to capture statistical similarities. If the size of segments is too small, the statistical features might not capture the underlying distribution of the service; if it is too large, the data may be overly generalized, losing service-specific patterns. By nature, different Metaverse services exhibit unique statistical behaviour for Principle 2 to work."}, {"title": "III. DISCERN-XR: METAVERSE NETWORK TRAFFIC CLASSIFCAITON", "content": "We select diverse and popular Metaverse services cloud-rendered to an Oculus Quest 2 HMD [10] using Virtual Desktop Streamer (VDS) [11]. The rendered traffic is tapped on a cloud computer using a traffic sniffer, i.e., Wireshark [12]. Wireshark extracts the captured traffic in packet captures (.pcap) files from which network traffic data is extracted into comma-separated values (CSV). The extracted CSV for a given service consists of four application-level features. The structural components of the Metaverse testbed is shown in Figure 1 (a). The devised Metaverse traffic classifier, Discren-XR receives the Metaverse network traffic at the A2R-(OT) that invokes the FVR and FIA with the required segment size to form statistical frame vectors that are used in finding the classification model in training. Once the A2R-(OT) finds the accurate classifier, the training is stopped, and the learned model is deployed for further classification as shwon in Figure 1 (b).\nMetaverse network traffic is significant in the downlink direction while rendering video and audio frames. Insignificant uplink traffic consists of control flow generated from sensors/joystick at the HMD end [13]. The patterns of video frames provide unique information about the type of Metaverse"}, {"title": "A. Frame Identification Algorithm", "content": "services. Therefore, identifying frames regardless of rendering platforms can be crucial in Metaverse traffic classification. The FIA algorithm relies on the traffic behaviour, including packet length and inter-arrival time, to accurately identify video frames. This is because multiple consecutive packets are often required to transmit a relatively large, uniform frame-related video traffic compared to non-frame traffic. The flow of frame-related video traffic is similar and relatively large compared to non-frame-related traffic flow. In addition, packets related to the same frame are sent consecutively and in quick succession. The disparity in packet length allows the algorithm to define a minimum packet length threshold for identifying frames as depicted in Figure 2a. The reliability in frame packet inter-arrival times allows the algorithm to define the maximum frame duration as the difference in mode inter-arrival times. As illustrated in Figure 2b, the first mode (T1) represents video and acknowledgement packets to the video traffic flow, whereas the second mode (T2) represents audio and control traffic flow. In Figure 2 it is shown that len\u0442\u043d is determined as 25% of the maximum length of the observed packet length. durth is the frame duration threshold determined between the first two peaks. The first peak represents the start of the video frame packet with less inter-arrival time, and the second peak represents the end of the video frame. The FIA algorithm uses this to guarantee that packets with significant inter-arrival times are not considered frames-related traffic flow and to ensure that multiple transmitted frames are not identified as single frames."}, {"title": "B. Frame Vector Representation", "content": "The FVR algorithm represents a given traffic segment into a statistical frame vector vi, which contains 13 statistical features derived from the four raw features, as shown in Figure 3. The first ten features are related to the statistical information on"}, {"title": "C. Augmentation, Aggregation, and Retention-Online Training Algorithm", "content": "Algorithm 1 A2R-(OT) and segment size selection\nData: Metaverse network traffic data\nResult: final model, ST,S\ninitialization\n$T_i = 50$; $Z_{error} = 0$; $E_{stop} = 0$; models = [ ]; data = [ ]\nwhile $S_i != S_{max}$ do\ndata.append($S_i$)\ntrainData = FVR($S_i$, $N_f$, Network data)\nvalData = split(trainData, $V_R$) \u25b7 split() will split the\ntrainData at $V_R$, which is a validation ratio;\nmodel = RandomForest((50xT), trainData)\nmodels.append(model)\n$E_{curr}$ = model.test(valData)\n$S_i$++\nwhile ($E_{stop} < E_{STH}$) and ($Z_{error} < Z_{ETH}$) do\ncurrentError = $E_{curr}$\ndata.append($S_i$)\ntrainData = FVR($S_i$, $N_f$, Network data)\nvalData = split(trainData, $V_R$)\nmodel = RandomForest((50xT), trainData)\nmodels.append(model)\nerror = model.test(valData)\n$S_i$++\nif $E_{curr} == 0$ then\n$Z_{error}$ ++\n\u0394\u0395 = currentError - error\nif abosluteValue(\u0394\u0395) < \u0415\u0442\u043d then\n$E_{stop}$ ++\nwhile $N_f != N_{opt}$ do\n$N_f$ += 500\ntrainData = FVR(data, $N_f$, Network data)\nvalData = split(trainData, $V_r$)\nmodel = RandomForest((50xT), trainData)\nmodels.append(model)\n$S$ = $N_f$; $S_T$ = $S_i$\nfinal model = combine(models) \u25b7 concatenate all trained models;\nreturn final model, $S_T$,$S$\nThe proposed A2R-(OT) algorithm, presented in Algorithm 1, adopts the random forest algorithm, which continuously refines the Metaverse classifier by iterating through various segment sizes to find the optimal segment size (S), number of training segments ($S_T$), and final classification model (final model). The outer loop determines the number of training segments ($S_T$), while the inner loop refines the segment size (S). The algorithm start by forming segment. The FVR forms the vectors of the respective segments. Split function helps splitting the segment vectors into train and validation data at ration $V_R$. Random forest is trained with train data until the validation meet the stopping criteria: 1) zero error conditions and 2) early stopping conditions. As given in Algorithm 1, zero error flag ($Z_{error}$) is incremented when the current error ($E_{curr}$) is 0. Similarly if the change in the error (\u0394\u0395) is less than error threshold (ETH), early stop flag ($E_{stop}$) is incremented. The optimization process is stopped when one of the conditions is met: 1) $Z_{error} \\geq Z_{ETH}$, and 2) $E_{stop} \\geq E_{STH}$.\nThe objective function of the A2R-(OT) algorithm is given in Eq.(3). Hyperparameters of random forest affect the optimization process. The classification model's error can be minimized by reducing the variance by increasing the number of trees ($T_{RF}$). In other words, mathematically given as Accuracy \u00d7 \u221aTRF [14]. Warm-start is enforced to increase the trees' depth. However, we will use smaller segments during the training to avoid overfitting. The time complexity of the A2R-(OT) algorithm is approximately O $(S_{max} *\\frac{AN_f}{\u0394N_f})*T*N *log(N_f))$, where Smax represents the total number of segment sizes, $N_{opt}$ is the optimal segment size, \u0394Nf is the increment in segment size, T is the number of trees in the random forest, and Nf is the segment size. Random forest training is the most computationally expensive part of this process, especially as the segment size Nf increases with higher dynamic behaviour.\nThe A2R-(OT) algorithm operates on three core principles: Augmentation, where new network traffic segments are continuously added to improve generalization; Aggregation, where multiple models trained on different segments are combined for a more robust final model; and Retention, which ensures the model retains and builds on previous knowledge in dynamic environments like Metaverse traffic, ensuring sustained accuracy and efficiency."}, {"title": "IV. EXPERIMENTATION SETUP AND RESULTS", "content": "The dataset from our testbed is available in [8]. We use the datasets Dataset I, [8], Dataset II, [13], and Dataset III, [15]. Table I shows the experimental plan. Datasets I, II, and III are used in all experiments. Dataset III provides two different data labels, as experiments 3 and 4 show in the Table I. In experiment 5, we use Dataset III in the training and Dataset II for testing to explore the generalization of our solution. We separately train the model for each service. Once the algorithm finishes converging, the remaining data is used for testing. Each of the above mentioned experiments is executed five times to check the robustness of the A2R-(OT) algorithm's convergence. The FVR algorithm finds the weight & in Eq. (1). Initial segment size (Nf) in Algorithm 1 is set to 500 and increments with 500 packets per iteration; the number is selected because of the dynamic nature of Metaverse services. smaller numbers might not help capture statistical similarities explained in Section II. For our experiment, Smax is capped at 200 to avoid data exhaustion, and training continues until the minimum error threshold of 2% or zero error is met. During the empirical test, we noticed the minimum error was 2%, therefore the threshold is determined at this value. Some segments provide holistic information that helps to converge to zero error. On average, we use 40% of the data in training, 20% of the data for validation, and 40% of the data for testing. The solution is implemented in Python using data science libraries such as Sklearn, NumPy and Pandas. The implementation of the solution is available at [9]. The experiment is conducted on a Windows platform with an NVIDIA RTX2800S graphical processing unit. The Windows platform is installed with the Anaconda environment to necessitate ML-related libraries to run along with TensorFlow."}, {"title": "B. Performance Metrics", "content": "We use Accuracy, Recall, Precision, F1 score, and False Negative Rate (FNR) to evaluate the classification model. These metrics are defined based on True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN). Accuracy measures the proportion of correct predictions, calculated as\nAccuracy = $\\frac{TP+TN}{TP+TN+FP+ FN}$\nRecall, or Sensitivity, is the ratio of correctly predicted positive instances, given by\nRecall = $\\frac{\u03a4\u03a1}{TP+FN}$\nPrecision evaluates the accuracy of positive predictions, expressed as\nPrecision = $\\frac{TP}{TP+FP}$\nThe F1 score is the harmonic mean of Precision and Recall, providing a balance between the two, and is defined as\n$F\\_1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$\nFinally, the False Negative Rate (FNR), which is critical in Network Traffic Classification (NTC) problems, represents the proportion of missed positive instances and is given by\nFNR = $\\frac{FN}{TP+FN}$\nA model with a higher F1 score is generally considered robust, but reducing the FNR is crucial, as it indicates situations where the model fails to detect actual traffic. Ideally, a classification model should aim for a high F1 score and a low FNR for better reliability and accuracy."}, {"title": "C. Performance of Frame Identification Algorithm", "content": "Table II provides the frame rate from the FIA for 60 Hz. We also verified the results with the VDS readings during the data capture and found the findings accurate. Ten thousand bytes is the packet threshold, and the inter-arrival time threshold for each service is given in the second column of Table II. Please refer to Section III-A for the information on the packet and the inter-arrival time threshold required for FIA. The FIA provides accurate results for all services except for VR chat. The asynchronicity from VR chat poses a challenge for an accurate frame identification in our solution."}, {"title": "D. Performance of the A2R-(OT) algorithm", "content": "Figure 5 shows the performance of our solution for various experiments presented in Table I. The solution consistently produces accuracy higher than 93% for in-house and public datasets. We provide accuracy and FNR per service from each experiment in Table III along with a number of test segments utilized in the experiments. FNR is smaller in all cases. However, VR games, AR, and MR services show less accuracy because of higher dynamicity and minor inconsistency with the FIA algorithm when considering the traffic in segments. Overall, the accuracy and FNR for all services are satisfactory and 7% better than the SoA [7]."}, {"title": "E. Discussions", "content": "In each experiment, the A2R-(OT) algorithm plays a crucial role in determining the appropriate segment size and the number of segments used for training, as shown in Table IV. The highly dynamic nature of Metaverse traffic is evident in the large segment size. However, the A2R-(OT) converges faster with fewer segments, which aligns with our expectations to reduce training time. The Metaverse traffic is highly random at the start of the session, and unless the user or network health introduces uncertainty, it remains predictable. Figure 6 shows the frame-related information, shown in red, provides better information for the classification."}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "We have proposed the Discenr-XR classification framework for Metaverse network, i.e., Discern-XR, to identify VR, AR, and MR service traffics. Using our SoA algorithms, FIA, FVR, and A2R-(OT), the framework demonstrates superior accuracy and performance, improving the detection of Metaverse-related traffic by 7% compared to existing methods while reducing the modelling time. Discern-XR can play a crucial role in the rapidly evolving Metaverse environment, enhancing the ability of ISPs to manage traffic efficiently and improving QoS and QoE for users. Future efforts will further extend Discern-XR's scalability to accommodate the increasing variety of Metaverse services. The framework will be adapted for next-generation networks, such as 5G and beyond, where low latency and high bandwidth are critical."}]}