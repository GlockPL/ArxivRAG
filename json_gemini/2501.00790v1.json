{"title": "LENS-XAI: Redefining Lightweight and Explainable Network Security through Knowledge Distillation and Variational Autoencoders for Scalable Intrusion Detection in Cybersecurity", "authors": ["Muhammet Anil Yagiz", "Polat Goktas"], "abstract": "The rapid proliferation of Industrial Internet of Things (IIoT) systems necessitates advanced, interpretable, and scalable intrusion detection systems (IDS) to combat emerging cyber threats. Traditional IDS face challenges such as high computational demands, limited explainability, and inflexibility against evolving attack patterns. To address these limitations, this study introduces the Lightweight Explainable Network Security framework (LENS-XAI), which combines robust intrusion detection with enhanced interpretability and scalability. LENS-XAI integrates knowledge distillation, variational autoencoder models, and attribution-based explainability techniques to achieve high detection accuracy and transparency in decision-making. By leveraging a training set comprising 10% of the available data, the framework optimizes computational efficiency without sacrificing performance. Experimental evaluation on four benchmark datasets\u2500Edge-IIoTset, UKM-IDS20, CTU-13, and NSL-KDD\u2500demonstrates the framework's superior performance, achieving detection accuracies of 95.34%, 99.92%, 98.42%, and 99.34%, respectively. Additionally, the framework excels in reducing false positives and adapting to complex attack scenarios, outperforming existing state-of-the-art methods. Key strengths of LENS-XAI include its lightweight design, suitable for resource-constrained environments, and its scalability across diverse IIoT and cybersecurity contexts. Moreover, the explainability", "sections": [{"title": "1. Introduction", "content": "In the ever-expanding digital landscape, the rapid proliferation of interconnected devices has led to a corresponding rise in sophisticated cyber threats, challenging the efficacy of traditional network security measures [1]. Intrusion Detection Systems (IDS) have emerged as critical components in safeguarding networks by identifying and mitigating anomalous activities [2]. However, the increasing complexity of cyberattacks necessitates the adoption of advanced methodologies that can keep pace with evolving threats while maintaining interpretability and scalability [3]. Recent studies highlights the adoption of advanced methodologies, including the integration of deep learning (DL) techniques with artifical intelligence (AI) for enhanced intrusion detection [4, 5], federated incremental learning for Internet of Things (IoT) security monitoring [1], and blockchain-enhanced decision-making frameworks [5]. Furthermore, intelligent systems tailored for specialized environments like unmanned aerial vehicles highlight the potential of interpretable IDS in addressing domain-specific challenges [6].\nDespite this progress, a significant challenge persists: the \u201cblack-box\u201d nature of these models undermines their adoption in critical applications where explainability and transparency are paramount. Addressing this gap, Explainable AI (XAI) has gained prominence, enabling researchers and practitioners to understand and trust IDS based on machine learning (ML) / DL [7, 8]. Incorporating XAI frameworks into IDS improves both operational transparency and decision-making reliability. For example, models such as DeepRoughNetID [9] have demonstrated robust anomaly detection capabilities by combining feature engineering with interpretable algorithms. Similarly, the integration of XAI into IoT-based intrusion detection systems, as illustrated by TwinSec-IDS [10], highlights the potential of explainable"}, {"title": "2. Literature survey", "content": "IDSs have been widely researched to address the increasing sophistication of cyberattacks. This section reviews recent advances in IDS methodologies with an emphasis on using XAI and lightweight architectures to enhance interpretability and efficiency."}, {"title": "2.1. Explainable Deep Learning Approaches for IDS", "content": "DL models have dramatically transformed IDS by providing enhanced accuracy and adaptability in identifying malicious activities. However, their inherent \u201cblack-box\u201d nature raises significant concerns about trust and interpretability. To address these issues, Sindiramutty et al. [15] proposed a Bi-LSTM-based framework integrated with explainable mechanisms, including enhanced krill herd optimization, which provides valuable insights into its decision-making process. This framework has proven effective in industrial cyber-physical systems, emphasizing the need for models that balance interpretability with high performance. Similarly, Nalini et al. [9] introduced DeepRoughNetID, a model designed to enhance anomaly detection capabilities by combining robust feature engineering with interpretable algorithms. While achieving high detection rates, DeepRoughNetID highlights the importance of evaluating its effectiveness in resource-constrained environments, a domain where its applicability remains underexplored. Al-Essa et al. [13] extended this line of research by developing PANACEA, a neural model ensemble utilizing knowledge distillation to enhance both efficiency and explainability. While PANACEA demonstrates its potential through accurate detection rates, its reliance on specific datasets limits its generalizability across diverse network environments. Alotaibi et al. [16] applied XAI to web phishing classification in IoT and cyber-physical systems, achieving strong results but requiring further validation across diverse IoT architectures. Zhao et al. [17] also addressed these challenges by proposing a lightweight IDS framework based on knowledge distillation and deep metric learning. However, their approach fell short in addressing the few-shot learning problem, leaving room for further optimization."}, {"title": "2.2. Lightweight and Scalable Models", "content": "As IoT devices and edge computing architectures continue to proliferate, IDS models must adapt to operate effectively in resource-constrained settings. Lightweight and scalable frameworks have become essential in addressing these demands. Nkoro et al. [3] proposed the Zero-Trust Marine Cyberdefense framework, which integrates lightweight architectures with explainable mechanisms to ensure robust cybersecurity in IoT-based maritime networks. This approach exemplifies the effectiveness of models designed for specialized environments, emphasizing computational efficiency without compromising interpretability. Ullah et al. [2] presented IDS-INT, a transformer-based intrusion detection model that employs transfer learning to handle unbalanced network traffic. While its advanced architecture achieves high detection accuracy, the model's scalability across different network configurations remains a critical area for further validation.\nChen et al. [18] explored federated learning for IDS, incorporating differentially private knowledge distillation to preserve data privacy while en-"}, {"title": "2.3. Advanced Anomaly Detection Techniques", "content": "Modern anomaly detection methods emphasize the need to capture complex data patterns and deviations effectively, particularly in dynamic network environments. Gaspar et al. [8] explored the integration of SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-Agnostic Explanations) techniques in intrusion detection systems based on Multi-Layer Perceptron models. By combining local and global interpretability, their approach not only improves detection accuracy but also enhances the transparency of model predictions, fostering trust among users. Bacevicius et al. [19] investigated hybrid approaches to handle unbalanced intrusion detection datasets, demonstrating improved classification accuracy in multi-class scenarios. Roy et al. [20] proposed an explainable deep neural framework tailored for industrial settings, enabling trustworthy and transparent anomaly detection processes. In addition, Ahmed et al. [21] developed a hybrid ensemble IDS model incorporating bagging, boosting, and SHAP to achieve high accuracy. These methodologies underline the importance of combining interpretability with advanced learning mechanisms to address the complexities of modern cyber threats."}, {"title": "2.4. Knowledge Distillation & VAEs", "content": "Knowledge distillation and VAEs have emerged as powerful tools for building efficient and interpretable IDS frameworks. By transferring knowledge from high-capacity models to lightweight counterparts, knowledge distillation ensures that computationally efficient systems maintain high detection accuracy. Sindiramutty et al. [15] effectively combined these techniques to design an anomaly detection model capable of balancing efficiency and explainability in industrial applications. Similarly, Moustafa et al. [22] integrated VAEs with federated learning and XAI frameworks to develop a robust intrusion detection solution for IoT networks. Javeed et al. [6] further demonstrated the utility of these approaches in specialized domains, designing an interpretable IDS tailored for unmanned aerial vehicles.\nBuilding on prior advancements, our earlier study by Yagiz et al. [23] introduced the KD-XVAE system, integrating a Knowledge Distillation framework with VAEs. This model achieved exceptional performance, with perfect recall, precision, and F1 scores, while maintaining a lightweight computational design. By employing XAI techniques such as SHAP, the KD-XVAE system enabled interpretability by highlighting key latent features critical for decision-making. These studies highlight the transformative potential of integrating knowledge distillation and VAEs into XAI-based intrusion detection systems, paving the way for innovative solutions that meet the demands of modern network security."}, {"title": "2.5. Research Gap", "content": "The reviewed works highlight several research gaps in IDS development. Dalal et al. [24] and Almuqren et al.[25] emphasized the limitations of scalability and adaptability in feature selection. HIDM [26] and RTIDS [27] demonstrated effective anomaly detection but underperformed in few-shot classification. Nasir et al. [28] and Osa et al. [29] focused on privacy and data imbalance but lacked comprehensive evaluations across diverse scenarios. Notably, static feature selection methods in GJOA [30] and DSbDNM [31] restricted their application in dynamic environments. The computational challenges faced by GRDN [32] and RTIDS [27] highlighted the need for resource-efficient solutions. Additionally, the lack of multi-scenario evaluations and generalization across datasets remains a persistent issue in existing models.\nIn response to these gaps, our proposed LENS-XAI framework integrates knowledge distillation and VAEs within a lightweight architecture, tailored for resource-constrained IoT and edge computing environments. Emphasizing scalability, interpretability, and efficiency, it employs variable attribution-based XAI mechanisms to provide transparent insights into decision-making processes. By validating its performance across diverse datasets and scenarios, this framework advances the state-of-the-art in IDS."}, {"title": "2.6. Problem Statement and Motivation", "content": "Existing IDS frameworks face significant challenges in scalability, dataset-specific performance, and adaptability to dynamic environments. Many models rely on static feature selection techniques and heuristic-driven metrics, which limit their ability to identify critical relationships among features, particularly in the context of imbalanced datasets. Additionally, the computational overhead of existing solutions restricts their real-time applicability, especially in resource-constrained environments like IoT and edge computing. The limited scenario-based evaluations and reliance on specific datasets further constrain the generalizability of these models, leaving critical gaps in their ability to address diverse real-world applications. Moreover, the absence of dynamic threat adaptation mechanisms undermines the effectiveness of IDS frameworks in handling evolving cyber threats. These challenges necessitate the development of robust, scalable, and generalizable IDS solutions capable of operating efficiently in resource-constrained environments.\nBy addressing these limitations, it becomes possible to enhance the overall efficiency, adaptability, and reliability of IDS frameworks, ensuring improved security across diverse and dynamic network scenarios."}, {"title": "3. Methodology", "content": ""}, {"title": "3.1. Framework Overview", "content": "The proposed workflow begins with input datasets, which undergo preprocessing to remove inconsistencies, transform categorical attributes, and normalize numerical features. The processed data is fed into a VAE, capturing latent representations critical for anomaly detection. To enhance efficiency, Knowledge Distillation transfers the learned representations from a robust teacher model to a lightweight student model, optimizing computational performance for resource-constrained environments. Finally, a variable attribution-based explainability method provides transparent insights into the decision-making process, enhancing trust and usability in the detection framework."}, {"title": "3.2. Data Preprocessing and Feature Engineering", "content": "Real-world intrusion detection datasets (e.g., CTU-13, UKM20, NSL-KDD, and Edge-IIoTset) often contain missing values, categorical features,"}, {"title": "3.2.1. Missing Value Handling", "content": "We adopt a hybrid strategy to address missing entries:\n1. Imputation: For minor gaps, we replace missing values with the mean or median, preserving overall statistical distributions.\n2. Exclusion: For records with extensive missingness, we remove them to minimize noise and bias.\nThis approach retains the majority of the data while limiting the distortion introduced by imputation."}, {"title": "3.2.2. Feature Encoding and Transformation", "content": "Categorical and non-numerical features must be translated into numerical forms for downstream ML models:\n\u2022 One-hot encoding: Converts nominal categories into binary indicator variables.\n\u2022 Ordinal encoding: Maps ordered categories to integer values when a natural order is relevant.\nWe choose the encoding method on a feature-by-feature basis, prioritizing minimal information loss."}, {"title": "3.2.3. Standardization", "content": "To standardize the range of numerical attributes, we employ Z-score standardization. Each feature x is scaled to x' via\n$x' = \\frac{x - \\mu}{\\sigma}$ (1)\nwhere $\\mu$and $\\sigma$ are the mean and standard deviation of the feature, respectively. This standardization ensures that the features have a mean of 0 and a standard deviation of 1, facilitating balanced gradient updates during model training."}, {"title": "3.3. Representation Learning with Variational Autoencoders", "content": "Following preprocessing, we employ VAEs to model the underlying data distribution and derive expressive latent representations that facilitate anomaly detection."}, {"title": "3.3.1. VAE Architecture", "content": "A standard VAE comprises two main components:\n\u2022 Encoder: A neural network $q_{\\theta}(z | x)$ that maps the input $x \\in \\mathbb{R}^d$ to a latent distribution over $z\\in \\mathbb{R}^k$.\n\u2022 Decoder: A neural network $p_{\\phi}(x | z)$ that reconstructs $x$ from latent variables $z$.\nHere, $\\phi$ and $\\theta$ denote the trainable parameters of the encoder and decoder, respectively, while k is typically chosen to be much smaller than d."}, {"title": "3.3.2. VAE Loss Formulation", "content": "We optimize the VAE via the following objective:\n$\\mathcal{L}_{VAE}(\\theta, \\phi; x) = \\mathbb{E}_{q_{\\theta}(z|x)} [ - \\log p_{\\phi} (x | z)] + \\beta D_{KL} (q_{\\theta}(Z | x) || p(z))$ (2)\nwhere:\n\u2022 $\\mathbb{E}_{q_{\\theta}(z|x)} [ - \\log p_{\\phi} (x | z)]$ measures the reconstruction error,\n\u2022 $D_{KL} (q_{\\phi}(Z | X) || p(z))$ enforces a structured latent space by penalizing divergence from the prior $p(z)$, often chosen as $\\mathcal{N}(0, I)$,\n\u2022 \u03b2 balances the trade-off between reconstruction fidelity and latent-space regularization [33]."}, {"title": "3.3.3. Latent Representation for Anomaly Detection", "content": "We use the encoder's learned representations to identify anomalous samples in subsequent classification or threshold-based detection steps. Intuitively, examples that yield high reconstruction error or have low likelihood under the learned latent distribution are flagged as potential intrusions."}, {"title": "3.4. Knowledge Distillation for Model Optimization", "content": "VAEs combined with high-capacity classification models can be computationally demanding. To alleviate inference costs without sacrificing performance, we employ Knowledge Distillation [34], transferring the \u201cknowledge\u201d from a powerful teacher model to a more compact student model."}, {"title": "3.4.1. Distillation Setup", "content": "1. Teacher Model: Trained on the full dataset (or its latent representations) to achieve high accuracy.\n2. Student Model: A lighter network optimized to reproduce the output distribution of the teacher."}, {"title": "3.4.2. Distillation Loss", "content": "To guide the student network, the teacher provides \"soft targets,\" which we combine with hard labels to form the distillation loss:\n$\\mathcal{L}_{distill}(\\theta_s) = (1 - \\alpha) \\mathcal{L}_{CE}(y, \\hat{y}_s) + \\alpha T^2 D_{KL} (\\sigma_T(\\hat{y}_t), \\sigma_T(\\hat{y}_s))$ (3)\nwhere:\n\u2022 $\\mathcal{L}_{CE}$ is cross-entropy between true labels y and student predictions $\\hat{y}_s$,\n\u2022 $D_{KL} (\\sigma_T(\\hat{y}_t), \\sigma_T(\\hat{y}_s))$ is the KL divergence between teacher and student outputs under a \u201csoftmax temperature\" T,\n\u2022 \u03b1 weights the relative contribution of hard and soft labels.\nHere, $\\sigma_T(\\cdot)$ denotes the temperature-scaled softmax operator [34]."}, {"title": "3.5. Variable Attribution-Based Explainability", "content": "Security analysts require interpretable results to validate and trust IDS outcomes. To meet this need, we incorporate a variable attribution-based explainability approach, as detailed in Algorithm 1, which quantifies the contributions of individual features in anomaly predictions [35, 36]. This algorithm computes feature attributions by decomposing the model prediction for a given test instance into baseline and individual feature contributions, ensuring the property of local accuracy. Specifically, the algorithm iteratively calculates the marginal contribution of each feature by comparing the"}, {"title": "3.5.1. Variable Attribution Computation", "content": "Given an instance $x^* = \\{x_1, x_2,...,x_p^*\\}$, the model prediction $f(x^*)$ is expressed as [37, 38]:\n$f(x^*) = v_0 + \\sum_{j=1}^p v(j, x^*),$ (4)\nwhere:\n\u2022 $v_0$ denotes the mean model prediction across all instances (baseline prediction),\n\u2022 $v(j, x^*)$ represents the contribution of the j-th variable to the prediction $f(x^*)$.\nThis decomposition ensures the property of local accuracy, such that:\n$\\sum_{j=0}^p v(j, x^*) = f(x^*)$. (5)\nTo compute the contribution $v(j, x^*)$, we leverage conditional expectations:\nv(j, x^*) = \\mathbb{E} [f(x) | x_1 = x_1^*, ..., x_j = x_j^*] - \\mathbb{E} [f(x) | x_1 = x_1^*, ..., x_{j-1} = x_{j-1}^*], (6)\nwhere:\n\u2022 $\\mathbb{E}[f(x) | x_1,... , x_j]$ is the expected value of the model's prediction when the first j features are fixed to their observed values,\n\u2022 The difference isolates the marginal contribution of the j-th variable."}, {"title": "3.5.2. Generalization to Subsets of Features", "content": "To handle more general cases, let $J = \\{l_1, l_2, ..., l_k\\}$ be a subset of K < p indices from $\\{1,2,...,p\\}$, and let $L = \\{i_1,i_2,...,i_m\\}$ be another subset of M \u2264 p - K indices, such that $J\\cap L = 0$. Define the conditional difference for L | J as [38]:\n$\\Delta_{L\\backslash J}(x^*) = \\mathbb{E} [f(X) | X_J = x_J^*, X_L = x_L^*] \u2013 \\mathbb{E} [f(x) | X_J = x_J^*]$, (7)\nwhere:\n\u2022 $X_J$ and $X_L$ denote the sets of variables indexed by J and L, respectively,\n\u2022 $x_J^*$ and $x_L^*$ represent their observed values.\nFor an individual variable $l \\in L$, the marginal contribution is:\n$\\Delta_{l\\backslash J}(x^*) = \\mathbb{E} [f(x) | X_l = x_l, x_J = x_J^*] - \\mathbb{E} [f(x) | x_J = x_J^*]$. (8)"}, {"title": "3.5.3. Order Sensitivity and Approximation", "content": "The contributions $v(j, x^*)$ depend on the order of the variables j, as interactions between variables may influence the result. To address this, we use a two-step heuristic [38, 39]:\n1. Variables are ordered based on their marginal importance $|\\Delta_{j|0}(x^*)|$, calculated without prior conditioning.\n2. Contributions $v(j, x^*)$ are then computed sequentially using the chosen order, capturing both individual and interaction effects.\nBy implementing the variable attribution method, as outlined in Algorithm 1, the framework enables robust, feature-level explanations, empowering analysts to make data-driven decisions and refine IDS configurations effectively."}, {"title": "3.6. Strategic Data Partitioning", "content": "To stress-test the model's generalization, we adopt a stringent partition:\n\u2022 Training set: 10% of the available data.\n\u2022 Test set: 90% of the data.\nAlthough unconventional, this setup closely mimics scenarios with limited labeled data, illuminating the framework's capacity to operate under realistic constraints."}, {"title": "3.7. Framework Contributions", "content": "Algorithm 2 outlines the complete pipeline of the proposed framework, integrating the components described above. The framework offers the following key contributions:\n\u2022 Unified Preprocessing for Heterogeneous Datasets: Ensures consistency and scalability by standardizing input features across diverse datasets.\n\u2022 Latent Representation Learning with VAEs: Introduces dynamically calibrated VAEs to capture robust latent representations, enhancing anomaly detection."}, {"title": "\u2022 Optimized Computational Efficiency", "content": "Leverages Knowledge Distillation to reduce model complexity, enabling deployment in resource-constrained environments."}, {"title": "\u2022 Explainability with Variable Attribution", "content": "Employs a variable attribution-based approach for transparent decision-making, enhancing trust and usability for security analysts."}, {"title": "\u2022 Rigorous Validation Across Scenarios", "content": "Implements a comprehensive evaluation strategy, showcasing robustness and adaptability under diverse operational constraints.\nThe integration of these elements positions the framework as a scalable and interpretable solution for intrusion detection, addressing challenges in modern IoT and edge computing environments."}, {"title": "4. Performance evaluation", "content": "We begin by assessing the intrusion detection performance of the proposed LENS-XAI framework, comparing it against baseline methods as outlined in Section 4.3. Furthermore, Section 4.5 provides a comprehensive evaluation of the framework's explainability, benchmarked against state-of-the-art techniques."}, {"title": "4.1. Experimental Setup and Evaluation Metrics", "content": "The proposed framework is implemented in Python, incorporating modern libraries such as TensorFlow and PyTorch for model development and leveraging variable attribution methods for explainability. The preprocessing pipeline is designed to ensure data consistency by addressing missing values, encoding categorical variables, and normalizing numerical features. Explainability is achieved through an attribution-based approach that highlights the contribution of individual features to the model's predictions, enabling interpretable anomaly detection. The experimental settings use a batch size of 64 across all datasets. Training epochs are set to 200 for UKM-IDS20, 500 for Edge-IIoTset, and 100 for NSL-KDD, with a consistent learning rate of 0.001, ensuring robust latent representations. Knowledge distillation is conducted with a temperature parameter T = 2 and a weighting coefficient \u03b1 = 0.5. The system configuration, tailored to support the integration of XAI principles, is summarized in Table 1.\nThe key evaluation metrics used in this study are defined as follows:"}, {"title": "4.2. Dataset Descriptions", "content": "The proposed LENS-XAI framework is assessed using four benchmark datasets: Edge-IIoTset, UKM20, CTU-13, and NSL-KDD. These datasets were carefully chosen for their distinctive features and their relevance to"}, {"title": "Edge-IIoTset Dataset", "content": "The Edge-IIoTset dataset is designed for cybersecurity research in IoT and edge computing environments. It features both benign and malicious network traffic, annotated with detailed labels, timestamps, and traffic characteristics. The dataset spans multiple protocols and includes diverse attack types such as Denial of Service (DoS), data exfiltration, and command injection. This comprehensive coverage makes Edge-IIoTset an invaluable resource for testing intrusion detection systems in complex and realistic network scenarios. Figure 1 shows the various classes of"}, {"title": "UKM20 Dataset", "content": "The UKM-IDS20 dataset is tailored for intrusion detection in vehicular networks, offering traffic data from Controller Area Network (CAN) buses. It encompasses both normal and attack scenarios, including message injection and spoofing attacks. Key features, such as CAN IDs, data length codes (DLC), and payload data, enable robust anomaly detection and the evaluation of IDS solutions specific to IVN environments. Figure 2 shows the class distribution of the UKM20. The dataset is publicly accessible at2."}, {"title": "CTU-13 Dataset", "content": "The CTU-13 dataset is a widely recognized benchmark for botnet traffic analysis. While not specific to IVNs, it contains a mix of normal and botnet-infected traffic with detailed flow-based features. The dataset is well-suited for evaluating generalized IDS models that can be adapted for IVN use cases. The CTU-13 dataset is publicly available at\u00b3.\nThis dataset consists of the following traffic types and their respective counts:"}, {"title": "NSL-KDD Dataset", "content": "The NSL-KDD dataset is a refined version of the KDD Cup 1999 dataset, addressing redundancy and imbalance issues. It provides labeled network traffic with 43 features, including protocol type, service, flag, and attack labels. The dataset includes separate training (KD-Train+) and testing (KDDTest+) subsets, facilitating model development and validation in diverse cybersecurity contexts. Figure 3 illustrates the distribution of classes within the NSL-KDD. This dataset is publicly available at4."}, {"title": "4.3. Performance Evaluation of the Introduced LENS-XAI Method", "content": ""}, {"title": "4.3.1. Analysis on Edge-IIoTset Dataset", "content": "Table 3 provides a comprehensive comparison of the proposed LENS-\u03a7\u0391\u0399 framework with state-of-the-art intrusion detection systems on the Edge-IIoTset dataset, evaluating multi-class classification tasks."}, {"title": "Multi-class Classification Results", "content": "\u2022 Accuracy: The LENS-XAI Teacher model achieved the highest accuracy of 95.34%, slightly outperforming the Student model at 95.31%, as well as other models such as NIDS-BAI (94.7%) and BGA (94.2%) [40]. These results highlight the robustness of the framework in handling complex IoT-specific attack scenarios.\n\u2022 Precision and Recall: The Teacher model demonstrated superior precision (96.75%) and recall (95.34%) compared to NIDS-BAI (94.7% precision, 94.8% recall) [40]. Similarly, the Student model maintained competitive precision (95.74%) and recall (95.31%), showcasing effective knowledge transfer and computational efficiency.\n\u2022 F1-Measure: Both models achieved balanced performance, with the Teacher model scoring an F1-measure of 95.09% and the Student model closely following with 95.36%. These values surpass traditional models like ICNN (91.6%) and BGA (94.3%) [40], underlining the versatility of LENS-XAI in IoT-based security tasks."}, {"title": "Performance Analysis Across Attack Types", "content": "Table 4 highlights the LENS-XAI framework's performance across various attack types for the Edge-IIoTset dataset. Both the Teacher and Student models excel in detecting frequent attacks like DDoS ICMP and DDoS UDP, achieving near-perfect accuracy (99.64%-100.00%). For Backdoor, the models perform strongly (97.89%-98.49%), while in rare attacks like SQL Injection, the Teacher outperforms the Student (34.21% vs. 19.13%). Both models achieve perfect detection (100.00%) for Normal traffic, showcasing reliability. The Teacher demonstrates better handling of rare scenarios, solidifying its robustness for IoT intrusion detection."}, {"title": "Confusion Matrix Analysis", "content": "Figure 4 illustrates the confusion matrices for the LENS-XAI framework, showcasing the performance of the Teacher and Student models on the Edge IIoT dataset for multiclass classification. The Teacher model achieves high accuracy across frequent attacks such as DDoS ICMP and DDoS UDP, with minimal misclassifications. For instance, only 1 instance of DDoS ICMP was misclassified as another type, demonstrating robust detection capabilities.\nSimilarly, the Student model exhibits strong performance, closely approximating the Teacher's accuracy. Notably, it correctly classifies 61,156 DDoS ICMP instances and 109,559 DDoS UDP instances. While both models perform exceptionally well for frequent attack types, rare attack types like SQL Injection and Uploading exhibit slightly higher misclassification rates. These results affirm the scalability and reliability of the LENS-\u03a7\u0391\u0399 framework in detecting a wide range of attack types within IoT environments."}, {"title": "4.3.2. Analysis on UKM20 Dataset", "content": "Table 5 provides a comparison of the performance metrics for the LENS-XAI framework, highlighting its effectiveness in multi-class classification tasks on the UKM20 dataset."}, {"title": "Multi-class Classification Results", "content": "\u2022 Accuracy: The LENS-XAI Teacher model achieved a near-perfect accuracy of 99.92%, outperforming the Student model's accuracy of 99.80%. These results demonstrate the robustness of the Teacher model in maintaining classification consistency, with the Student model closely approximating this performance.\n\u2022 Precision and Recall: Both models exhibit exceptionally high precision and recall values, with the Teacher model achieving 99.92% for both metrics, slightly higher than the Student model's 99.80%. These"}, {"title": "Performance Analysis Across Attack Types", "content": "Table 6 highlights the performance of the LENS-XAI Teacher and Student models across various attack types in the UKM20 dataset."}, {"title": "\u2022 Frequent Attacks", "content": "Both models excel in detecting common attacks such as BeEF HTTP Exploits, Metasploit Exploits, and Normal traffic, achieving perfect or near-perfect accuracy (99.95%-100.00%). The Teacher and Student models are equally capable in these scenarios, demonstrating high reliability for frequent attack detection."}, {"title": "\u2022 Rare Attacks", "content": "For less frequent attacks like ARP Poisoning and Mass HTTP Requests, the Student model slightly outperforms the Teacher model in accuracy (99.77% vs. 95.72% for ARP Poisoning). This reflects the effectiveness of knowledge distillation in the LENS-XAI framework, enabling the Student model to closely replicate the Teacher model's performance."}, {"title": "Confusion Matrix Analysis", "content": "Figure 5 presents the confusion matrices for the LENS-XAI framework, illustrating the performance of the Teacher and Student models on the UKM-IDS20 dataset for multiclass classification tasks. The Teacher model demonstrates high accuracy across all classes, with minimal misclassifications. For example, all 444 instances of ARP Poisoning are correctly classified, while only 7 Normal instances are misclassified. Similarly, frequent attack types such as BeEF HTTP Exploits,"}, {"title": "4.3.3. Analysis on CTU-13 Dataset", "content": "Table 7 presents a comparative analysis of the proposed LENS-XAI framework against state-of-the-art ML models on the CTU-13 dataset. The results underline the robustness and effectiveness of the proposed framework in intrusion detection."}, {"title": "\u2022 Accuracy", "content": "The LENSXAI Teacher achieved an exceptional accuracy of 98.42%, outperforming models like SVM-RBF (85.03%) and k-NN (93.00%) [41]. The LENSXAI Student also delivered a strong performance with an accuracy of 98.12%, demonstrating the efficiency of the knowledge distillation process."}, {"title": "\u2022 Recall", "content": "Both LENSXAI Teacher and Student achieved outstanding recall scores of 98.42% and 98.12%, respectively, ensuring high detection rates for malicious activities. These results outperform traditional methods such as NB (76.00%) and LR (86.00%) [42]."}, {"title": "\u2022 Precision", "content": "The precision scores of 98.43% for the Teacher model and 98.14% for the Student model highlight their capability to minimize false positives, ensuring reliability in real-world applications."}, {"title": "\u2022 F1 Score and Balanced Performance", "content": "The harmonic mean of precision and recall for LENSXAI Teacher and Student were 98.42% and 98.12%, respectively, showcasing balanced and consistent performance in intrusion detection tasks."}, {"title": "\u2022 Comparison with State-of-the-Art", "content": "FFS-HTTP [43]: Although achieving slightly higher accuracy (98.79%), FFS-HTTP lacks the interpretability and lightweight design offered by LENS-XA\u0399.\nbot-DL [44]: Demonstrated competitive accuracy (96.60%) but lacks the explainability critical for trust and transparency in intrusion detection systems, a key advantage of LENS-XAI.\nk-NN and SVM-RBF [41]: Fell short in both accuracy and scalability, with lower accuracy scores of 93.00% and 85.03%, respectively, underlining the efficacy of the advanced techniques integrated into LENS-\u03a7\u0391\u0399."}, {"title": "4.3.4. Analysis on NSL-KDD Dataset", "content": "Tables 8 comprehensively compares the proposed LENS-XAI framework with state-of-the-art ML models on the NSL-KDD dataset, evaluating multi-class tasks."}, {"title": "Multi-class Classification Results", "content": "\u2022 Accuracy: The LENSXAI Student achieved the highest accuracy of 99.34%", "50": "and MCNN-DFS (81.44%) [53", "Recall": "With a precision of 98.47% and recall"}]}