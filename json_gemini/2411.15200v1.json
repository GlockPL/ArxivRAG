{"title": "Deep Learning-Based Classification of Hyperkinetic Movement Disorders in Children", "authors": ["Nandika Ramamurthy"], "abstract": "Hyperkinetic movement disorders (HMDs) in children mainly comprise dystonia (ab-normal twisting) and chorea (irregular, random movements). HMDs present significant diagnostic challenges due to their complex and often overlapping clinical manifestations. Prevalence of these conditions ranges from 2 to 50 per million and 5 to 10 per 100,000 respectively. These patients typically experience diagnostic delays averaging 4.75 to 7.83 years. Traditional diagnostic methods rely on clinical history and physical examinations by an expert, as specialised tests do not improve detection due to their complex pathophysiology. To address challenges in diagnosis, this study develops a neural network model to differentiate between dystonia and chorea from video recordings of patients performing a specific task.\nThe model utilizes joint position data extracted from videos of paediatric patients perform-ing motor tasks. The model architecture integrates a Graph Convolutional Network (GCN), to capture spatial relationships, and Long Short-Term Memory (LSTM), to represent temporal dynamics. Attention mechanisms were incorporated to refine feature extraction and improve the model's interpretability. A dataset of 50 videos (31 chorea-predominant, 19 dystonia-predominant) was used to train and validate the model. All data was collected under regulatory approval by Guy's and St Thomas' NHS Foundation Trust (GSTT) Elec-tronic Records Research Interface (GERRI) (REC# 20EM/0112).\nThe model achieved an accuracy of 85%, and an F1 score of 81%. The model demonstrated high sensitivity (81%) and specificity (88%) at the optimal frame rate of 15 frames per second (fps). Attention maps provided valuable insights into the model's decision-making, highlighting the model's correct identification of involuntary movement patterns, while model misclassifications are often linked to occluded body parts or subtle movement variations. This study highlights the potential of deep learning to improve the accuracy and", "sections": [{"title": "1 Introduction", "content": "Paediatric movement disorders are broadly categorised into hypokinetic and hyperkinetic movement disorders. Hyperkinetic movement disorders (HMDs) are characterized by excessive or exaggerated movements (Stouwe et al., 2021). Hypokinetic movement disorders involve reduced voluntary movement (Kruer, 2015). The classification of paediatric movement disorders has primarily focused on HMDs as there are fewer types of hypokinetic movement disorders. Accurate and precise definitions of each type of HMD are essential for diagnosis, therapeutic decision-making, and effective communication between healthcare professionals.\nThe prevalence of HMDs in the paediatric population is not fully established due to the lack of comprehensive studies and the challenges associated with diagnosing these disorders (Kruer, 2015). There are specific estimates for only certain types of movement disorders. For instance, dystonia is observed in 2 to 50 cases per million individuals under the age of 26 (Fern\u00e1ndez-Alvarez and Nardocci, 2012). It is also commonly seen in dyskinetic cerebral palsy (CP), occurring 2\u20133 per 1000 live births (Lin, 2011). The prevalence of chorea is less clear due to limited studies, although conditions like Huntington's disease, which is one of several causes of chorea, is found in 5-10 cases per 100,000 individuals, and benign hereditary chorea occurs in approximately 1 per half a million individuals (Merical and S\u00e1nchez-Manso, 2024). The cited prevalences likely underestimate the true incidence in the population, due to the misdiagnosis of atypical presentations and insidious onset of symptoms (Fern\u00e1ndez-Alvarez and Nardocci, 2012). Given the prevalence and complexity of HMDs, accurate classification and characterization is crucial to advancing"}, {"title": "1.1. CLINICAL PROBLEM", "content": "research in their diagnosis and treatment. The following section will summarize the clinical presentation of two prominent HMDs\u2014dystonia and chorea\u2014and highlight the challenges in distinguishing between them.\nDystonia is characterized by abnormal twisting or posturing movements, which can affect either a single part of the body (focal) or multiple regions (generalized) (Fern\u00e1ndez-Alvarez and Nardocci, 2012). Diagnosing dystonia can be challenging, particularly when it presents with spasticity in conditions such as cerebral palsy, where the resulting \u201cmixed tone\" mimics patterns of multiple HMDs (Gorodetsky and Fasano, 2022). Dystonia can present alongside myoclonus, with more pronounced involvement of the upper body (Sanders et al., 2024). Developmentally normal children may be misdiagnosed due to \u201coverflow movements\u201d caused by an immature nervous system (Gorodetsky and Fasano, 2022).\nIn contrast, chorea presents as irregular, random, and brief movements that flow from one part of the body to another, often giving the appearance of restlessness. These continuous movements are generally considered non-suppressible, although one study found that 50% of patients could temporarily suppress their chorea (Koller and Biary, 1989). Additionally, ballismus is a type of chorea that affects the proximal limb (i.e. shoulder). It is a high-amplitude, forceful flinging motion of proximal joints (Nikkhah et al., 2019)."}, {"title": "1.1. CLINICAL PROBLEM", "content": "Associated forms with chorea involve athetosis, a slower, smooth, and writhing movement typically affecting the distal parts of the limbs. Athetosis is frequently observed in dyskinetic CP and often co-occurs with dystonia. The term \u201cchoreoathetosis\u201d is used by clinicians to describe movements that exhibit characteristics of both chorea and athetosis, as they often occur in combination (Yilmaz and Mink, 2020).\nUnderstanding the pathophysiology of different HMDs is essential for developing targeted treatments and predicting disease progression. Knowledge of the underlying disease processes can aid in distinguishing between different disorders to ensure accurate classification."}, {"title": "1.1.2 Clinical Diagnosis and Treatment", "content": "Diagnosis of HMDs relies on clinical history and a detailed physical examination (Mink and Sanger, 2017). Quantifying the severity of the disorder is also important to understand the progression of the disease and the effect of therapeutic interventions. Scales for assessing HMDs exist, but they tend to focus on one type of movement disorder and vary widely in their diagnostic properties, availability, and administration effort (Pietracupa et al., 2015). These systems may also need to be altered for the paediatric population by"}, {"title": "1.2. STATE-OF-THE-ART", "content": "replacing more advanced assessment tasks.\nCurrently, there are no specific diagnostic tests to distinguish dystonia from chorea, as clinicians must rely on recognising the nature of abnormal movements to differentiate between them. Existing scales measure the extent of dystonia or chorea but are limited in their ability to accurately diagnose and assess severity. To improve diagnosis, reduce variability among observers and better target treatments, more objective methods are needed. Further research is required to evaluate the effectiveness of clinical scales in characterizing HMDs and to ensure these scales are objective, time-efficient, and applicable across the various types."}, {"title": "1.2 State-of-the-art", "content": "Recognizing and diagnosing movement abnormalities can use features broadly classified into spatial (body part arrangement) or temporal dependencies (motion over time). Spatial features can detect abnormal postures or movement amplitudes, while temporal features reveal irregular patterns or movement frequency.\nTo capture spatial connections between joints, the human skeleton can be represented as a graph for input into Graph Convolutional Networks (GCNs). GCNs are a type of CNN designed to work with graph-structured data, making them ideal for learning spatial relationships in the graph (Kipf and Welling, 2017). In this context, skeleton joints are treated as graph nodes, and their connections as edges (Wu et al., 2021). GCNs transform these into feature vectors, like how CNNs process grid-like data (Defferrard et al., 2016). After applying a convolution, a weighted average is used to aggregate the features. Despite their effectiveness in capturing joint relationships, GCNs require normalization due to"}, {"title": "1.2. STATE-OF-THE-ART", "content": "sensitivity to input scale for stable training (Khemani et al., 2024).\nTo capture temporal features, Recurrent Neural Networks (RNNs) can be used to model sequential data by using previous outputs $h_{t\u22121}$, encoded as hidden states, along with the current input $x_t$ to produce a predicted output $h_t$ for the time point. These hidden states help the network learn temporal dependencies. However, RNNs can struggle with vanishing or exploding gradients during training, limiting their effectiveness on long sequences (Pascanu et al., 2013). To address this limitation, Long-Short Term Memory (LSTM) was developed with gated memory units to retain important information and discard irrelevant data (Hochreiter and Schmidhuber, 1997).\nAttention mechanisms are another valuable network component that can enhance fea-ture representation and adaptability to varied inputs. They enable the model to focus on key parts of the input sequence for better output prediction. The mechanism transforms each input element into three vectors: query (the element seeking information), key (elements in the sequence used for comparison), and value (information corresponding to each key). Attention weights are calculated by the dot product of the query and key, followed by SoftMax. These weights help capture dependencies within the data. In self-attention, the query, key, and value are the same, while multi-head attention uses multiple sets of these vectors for the final output. (Vaswani et al., 2023; Soydaner, 2022)"}, {"title": "1.2. STATE-OF-THE-ART", "content": "Equation 2: This equation represents the attention mechanism in terms of the query Q, key K, and value V. The dimension of key vectors $d_k$ is used to form a scaled dot product to keep the gradients of the network in a manageable range. (Vaswani et al., 2023)\nThe neural networks mentioned above have been employed to capture spatial and temporal information from human poses for action recognition (Qin et al., 2022) and movement prediction (Shu et al., 2022). For example, a study proposed the Skeleton-Joint Co-Attention Recurrent Neural Network (SC-RNN) to predict future motion of a skeleton representation of human movement (Shu et al., 2022). It maps the spatial and temporal coherence of joints onto a skeleton-joint co-attention feature map, which is then used with a Skeleton-Joint Co-Attention (SCA) mechanism to allow more informative features to predict motion (Shu et al., 2022). The model measured the coherence of joint motion with neighbouring joints and the coherence between observed motion and future motion of the entire skeleton. The model demonstrated a lower Mean Absolute Error (MAE) compared to other state-of-the-art models. However, it showed increased errors in longer sequences and sometimes predicted unnatural motions.\nA study introduced the ST-GCN (Spatial Temporal GCN) for skeleton-based action recognition, which captures spatial connections within the skeleton at each frame and temporal connections across frames (Yan et al., 2018). While spatial relations of GCNs"}, {"title": "1.2. STATE-OF-THE-ART", "content": "have been described in previous literature, this method uses GCNs to capture temporal connections too. The model used hierarchical and localised representations of the joints and their trajectories by restricting the model to the local regions of the graph. A hierarchical representation involving multiple GCN layers captured finer details at lower layers and more abstract features at higher layers to reduce the overall complexity of the model.\nHierarchical network architectures are explored in a study proposing a Hierarchical Spatial Reasoning and Temporal Stack Learning network (HSR-TSL), which uses GNN intra-parts and inter-parts networks to capture spatial relations within each body part and between body parts respectively (Si et al., 2020). Temporal dynamics were captured by dividing videos into short clips and processing each clip using an LSTM. Although the spatial and temporal GCNs did not use co-occurrence information, the model achieves high accuracy compared to other state-of-the-art models (87.7% in cross-subject settings).\nAnother study presented a self-attention mechanism to improve GCN performance for skeleton-based action recognition, achieving 90.5% accuracy (Qin et al., 2022). The model represented connected the input data using a directed graph to improve the model performance. Multi-head attention was explored in a study introducing an action transformer (AcT) that utilised minimal architectural priors in the network, allowing a less computationally intensive network with improved generalisation capability (Mazzia et al., 2022)."}, {"title": "1.2.2 Models for Joint and Motion Tracking", "content": "Many of the previously discussed models require an algorithm to detect joints as a pre-processing step, also known as human pose estimation. It is defined as the localization of human joints or predefined landmarks in images or videos to estimate the body's configuration (Chen et al., 2020). Whole-body pose estimation involves localising keypoints of the body, face, hand, and foot simultaneously, and is a challenging problem tackled using deep learning-based approaches (Jin et al., 2020).\nPose estimation algorithms follow two main approaches: top-down and bottom-up. In the top-down approach, models first detect a person often by using a bounding box after which individual body parts are identified. The bottom-up approach detects individual body parts first and then groups them to form a pose for one person. MoveNet is a notable top-down model, while OpenPose, DeepLabCut, and PoseNet are popular bottom-up models. Bottom-up methods are more efficient as they do not need to rerun for each person"}, {"title": "1.2. STATE-OF-THE-ART", "content": "in a frame (Osokin, 2018). However, they can suffer from scale variances when multiple people are in the frame (Jin et al., 2020).\nOpenPose is a deep learning model that provides 2D keypoints for the whole body. It first detects body and foot keypoints and then uses these to locate hand and face keypoints (Cao et al., 2019). OpenPose is highly accessible, running on various operating systems and hardware. It uses heatmap estimation at each stage to identify keypoints, enhancing robustness to noise while preserving gradient information (Luo et al., 2021). OpenPose can distinguish front and back unlike other pose estimation methods, thus reducing error in tracking joint positions (W. Kim et al., 2021). It uses part affinity fields to encode the location of the limbs as a vector magnitude and the orientation of the limbs as a vector direction (Jin et al., 2020). Optimised versions use dilated convolutions to increase the receptive field of the network by introducing gaps between kernel elements and reusing trained weights (Osokin, 2018).\nDeepLabCut is a pose estimation software that uses a variant of ResNet. It applies transfer learning to estimate 14 keypoints, adapting the model to new datasets using pre-trained weights (Nath et al., 2019). PoseNet employs pre-trained networks (ResNet-50 and MobileNetV1) to generate heatmaps for joint prediction, refining keypoints with offset vectors (Kendall et al., 2016). MoveNet uses a feature pyramid network with residual connections to localize 17 keypoints of the body (Joshi and Joshi, 2021). In a comparative study between OpenPose, MoveNet and DeepLabCut, OpenPose and MoveNet produced the lowest error in measuring hip kinematics, and OpenPose produced the lowest error in measuring knee kinematic errors (Washabaugh et al., 2022).\nOpenPose and other platforms have been trained and validated on able-bodied individuals, therefore, it is difficult to predict model performance in movement disorders where postural differences, impairments and physical deformities may lead to errors in pose estimation (Washabaugh et al., 2022). One study has demonstrated that OpenPose is effective in measuring joint angles in populations with postural abnormalities, even with occlusions and non-frontal views (W. Kim et al., 2021). However, in another study, Open-Pose's performance was 30% lower than other methods when incorrect camera position and self-occlusion were introduced (Chung et al., 2022). Therefore, these conditions need to be optimised to improve pose estimation."}, {"title": "1.2.3 Models for Diagnosis of Movement Disorders", "content": "Currently, no computational models can distinguish between different types of HMDs in patient care (M\u00e9neret et al., 2021). However, similar approaches for other medical conditions that affect movement may serve as a foundation for powerful HMD diagnostic tools.\nA proof-of-concept study employed a Random Forest algorithm to detect dystonia in individuals with dyskinetic CP (Haberfehlner et al., 2023). Using three limb length measurements from video frames, the model was trained with clinician-labelled data using the Dyskinesia Impairment Scale. This method demonstrated effective performance due to greater control over feature selection. However, the video recordings were labelled by three independent raters which resulted in moderate inter-rater variability, which complicates the establishment of a reliable \u201cground truth,\u201d hence questioning the trustworthiness of the labels. Additionally, the model did not analyse left and right limbs separately, which may have overlooked asymmetrical movement patterns.\nA follow-up study aimed to classify dystonia and choreoathetosis of the distal leg using short video sequences (Haberfehlner et al., 2024). It employed Hierarchical Vote Collective of Transformation-based Ensembles (HIVE-COTE 2.0), which are four time series-based classification algorithms. The study uses new pre-processing strategies including gap-filling to predict missing values in a dataset using multivariate iterative imputation, noise filtering, spatial normalization to correct camera angles, and temporal normalization to standardize video lengths. The study shows an accuracy of 81% for dystonia but only 53% for choreoathetosis, due to data scarcity for the latter class. Limitations of the study included difficulty in clinically validating automatically generated features and potential loss of critical information due to fixed video lengths.\nResNet-50-based neural network (He et al., 2015a) has been presented to diagnose dystonia using videos, achieving 93% sensitivity and 93% specificity (Miao et al., 2020). This approach uses clinically relevant features including inter-knee distance variance, foot angle variance and median difference of foot angle between limbs. These variables were calculated offline once the parts were identified by DeepLabCut. Similar work used a pre-trained ResNet50 model to classify head movement states (e.g., 'face forward', 'tilt left') (Peach et al., 2023). It was trained and validated using videos from both healthy controls and patients with dystonia, achieving an accuracy of 84%.\nRandom Forest and 3D ResNet-18 (Hara et al., 2017) were evaluated on their ability to detect tics from facial features on video (Br\u00fcgge et al., 2023). Bounding boxes were used"}, {"title": "1.3 Socioeconomic and Ethical Considerations", "content": "For deep learning models to effectively classify movement disorders, they must be inclu-sive across diverse populations to ensure equal representation and patient-centred care (Noseworthy et al., 2020). Incorporating varied demographic data in model training helps mitigate potential biases, which often arise from limited datasets that historically favoured able-bodied male subjects and excluded disabled populations (\u2018AI Is Being Built on Dated, Flawed Motion-Capture Data - IEEE Spectrum', n.d.). A systematic review of AI diversity and inclusion shows the growing emphasis on mitigating bias, ensuring fairness, and enhancing transparency in models (Shams et al., 2023), which aligns with the ethical principles of equality and non-discrimination in medical practice (De Micco and Scendoni, 2024). This approach is essential to prevent AI from perpetuating or exacerbating societal biases in healthcare.\nSocioeconomic factors significantly impact timely access to diagnosis and treatment for movement disorders. Specialists report that conditions like dystonia are often underestimated (Albanese et al., 2006), which leads to substantial diagnostic delays. For example, primary/primary-plus dystonia patients typically wait 4.75 years, while children with secondary dystonia experience delays of an average of 7.83 years. Delayed referrals result in delayed treatment and lowered quality of life while a definitive diagnosis is established. The study also noted referral bias, suggesting the study sample may not represent all children with dystonia but rather those severe enough to be referred to specialised services (Lin et al., 2014). Additionally, a study of dopa-responsive dystonia patients found that diagnostic delays have increased from 9 to 15 years since 1994 despite advances in genetic"}, {"title": "1.4 Aims", "content": "This proof-of-concept project aims to develop a robust neural network capable of differentiating between dystonia and chorea by analysing joint position data extracted using OpenPose, a software tool for human pose estimation. The proposed network integrates a GCN extract features for the spatial relationships between joint positions, and a LSTM, to extract features for the temporal dynamics of joints over time.\nThe performance of the network is evaluated using the accuracy, sensitivity, and specificity of the final predicted diagnosis (chorea or dystonia). Moreover, to enhance the transparency and interpretability of the model, attention mechanisms are added to enable weights of the features in the model contributing toward the final prediction. This will help provide insights into how the model differentiates between dystonia and chorea."}, {"title": "2 Methodology", "content": "This study used videos collected from the routine assessment of children and young people selected for deep brain stimulation (DBS) at the Evelina Children's Hospital (ECH). ECH is a supra-regional centre, with patients with complex, medication-refractory HMDs being referred from across the UK. Video recordings comprise patients being asked to perform various clinical tasks assessed using the BFMDRS recorded at baseline (before surgery) and then yearly following surgery. In this work, baseline assessment recordings were selected for further analysis.\nRegulatory approval was granted by the Guy's and St Thomas' NHS Foundation Trust (GSTT) Electronic Records Research Interface (GERRI) (REC# 20EM/0112), under the supervision of the Children's Neurosciences department (\u2018GSTT Electronic Records Re-search Interface (GERRI)', n.d.) for the use of videos from the last 100 children who had undergone DBS before December 2023.\nVideo recordings of baseline motor function for patients diagnosed with dyskinetic cerebral palsy (CP), and dystonia-predominant and chorea-predominant genetic disorders were selected. Patients were divided into two classes: chorea (dyskinetic CP and GNAO1) as the negative class, and isolated genetic dystonia (DYT-TOR1A, DYT-KMT2B and DYT-THAP1) as the positive class. Clinical diagnoses of these two groups are \u201cChorea pre-dominant\u201d and \u201cDystonia predominant\u201d, rather than pure chorea and dystonia, as patients with mixed presentation were included in the study to better reflect the patient population"}, {"title": "2.1. DATA COLLECTION AND PRE-PROCESSING", "content": "seen in neurology clinics.\nVideos were selected of a single task involving patients holding their hands upwards and outstretched for a few seconds. This task was chosen due to its simplicity and minimal need for staff assistance, making it accessible for patients who might have difficulty performing more complex tasks, such as walking unaided. Additionally, this task was chosen to minimize self-occlusion, as seen in tasks like the finger-to-nose test, ensuring clear detection of joint position."}, {"title": "2.1. DATA COLLECTION AND PRE-PROCESSING", "content": "were resampled to have a frame rate of 25 frames per second (fps) to ensure uniformity in the temporal domain."}, {"title": "2.1.2 Pose Extraction", "content": "The MoveSign application was used, which is a lightweight wrapper to OpenPose with specific features to maximise tracking and keypoint detection. The OpenPose model \u201cBody_25\u201d extracted 25 keypoints from each video as seen in Figure 3. Resolution-based normalization helped map the keypoint coordinate values between 0 and 1. To enhance the accuracy of keypoint detection, only keypoints detected with a confidence level greater than 5% were considered. Non-Maximum Suppression (NMS) was employed within each frame to prevent multiple detections of the same keypoint retaining only the most confident detection, enabling precise identification of keypoints.\nMoveSign enabled tracking to ensure the OpenPose model estimates the positions of keypoints even when occluded. Although these estimates are less precise, they maintain keypoint tracking continuity. MoveSign also implemented a smoothing algorithm to reduce jitter, thus ensuring stable detection of keypoints over time."}, {"title": "2.2. NETWORK ARCHITECTURE", "content": "The input spatiotemporal matrix was comprised of the x and y coordinates of 25 keypoints over 75 consecutive frames from the video (forming a matrix with the dimensions of batch size x 50 x 75). For the spatial network input, this matrix was divided into keypoints corresponding to the left arm, right arm, left leg, right leg, and torso following the hierarchical structure of human movement.\nKeypoints were recorded to form a travelling sequence as shown in Figure 4 to better model relationships between body parts. This method of ordering is supported by research indicating this arrangement is more effective in capturing the dynamics of human movement (Shu et al., 2022)."}, {"title": "2.2 Network Architecture", "content": "The network is designed with three components: a spatial network (top pathway in Figure 2.4), a temporal network (bottom pathway in Figure 2.4) and a combination of the two (right pathway in Figure 2.4) to generate a final combined classification. This approach follows recent studies in the field (as discussed in Section 1.2.1), to allow the network to learn spatial features independently from temporal dynamics to locate the important body"}, {"title": "2.2. NETWORK ARCHITECTURE", "content": "Every layer in the network is followed by the activation function Leaky ReLU due to its ability to handle negative and zero gradients effectively to overcome the vanishing gradient problem by allowing a small, non-zero gradient when the input is negative, where $a_i$ is a fixed parameter (typically 0.01) (Xu et al., 2015). Batch normalization is used to normalize the inputs to each layer, ensuring that the network converges quickly and effectively (Ioffe and Szegedy, 2015).\nThe spatial network models the spatial relationships between joints and captures the graph-like connections between different body parts within each video frame. This network uses three fully connected (FC) layers to encode the coordinates of each body part into a feature space. The FC layers share weights for symmetrical body parts (i.e. arms, legs) while maintaining distinct inputs and outputs, thus preserving unique characteristics for each side. This method enhances detecting similarities in motion patterns and improves generalization and efficiency (Si et al., 2020). The outputs of the FC layers represent relationships between the joints in each part.\nAfter encoding each body part, outputs from the FC layers are combined and input to a self-attention layer, to give a higher weight to the most relevant body parts for the final classification decision. The data then passes through a GCN to capture relationships between body parts. The GCN allows the network to represent interactions between non-adjacent parts, such as arm-leg coordination. Self-connections were excluded to ensure the network learns only meaningful relationships between parts. Max aggregation was performed after the GCN to select the most representative features (Li et al., 2020). The GCN is then followed by two FC layers to learn high-level spatial relationships of the skeleton within each frame.\nThe temporal network models relationships between frames to recognize the motion of joints over time using four bidirectional LSTM layers to capture temporal dependencies. The bidirectional LSTM differentiates poses that vary in time such as waving versus raising a hand. A self-attention layer weights important frames and helps to refine the temporal features. Finally, three FC layers learn high-level temporal features across frames. A residual connection is added to the final two FC layers to aid gradient flow and speed up convergence during training (Philipp et al., 2018).\nThe spatial and temporal network output features are combined using a multi-head attention layer, enabling the network to learn which features from both networks contribute most to the final classification and a residual connection to aid gradient flow. The integrated features then pass through two FC layers, condensing features, followed by a SoftMax layer"}, {"title": "2.3. LOSS FUNCTION", "content": "to determine the logistics of the video clip corresponding to the final binary classification task (chorea versus dystonia)."}, {"title": "2.3 Loss Function", "content": "In the context of classification involving imbalanced datasets traditional loss functions like Cross-Entropy may fail to achieve optimal performance as they do not consider the relative proportion of training data in each class. To address this issue in this project the network was trained using Focal Loss as the loss function as it can dynamically scale Cross-Entropy. Focal Loss is designed to down-weight easy training instances and accurately classify harder, misclassified instances (Lin et al., 2018).\nEquation 3: Focal Loss $L_{focal}(p_t)$, where $p_t$ is the model's predicted class probability. The parameter $\\alpha$ controls the relative importance of each class during training and $\\gamma$ controls the relative importance of harder, misclassified instances during training (Lin et al., 2018)."}, {"title": "2.4 Implementation", "content": "All experiments were performed in a Google Colab (\u2018Google Colab', n.d.) environment equipped with an Intel Xeon CPU @ 2.00GHz and NVIDIA Tesla T4 GPU with 16 GB of VRAM, and 12.67 GB of system RAM. The operating system was Ubuntu 22.04.3 LTS. The model was developed using Python 3.10.12 and PyTorch 2.3.1 (with CUDA 12.1 support) (Paszke et al., 2019). Scikit-learn 1.3.2 (Pedregosa et al., 2011), and Pandas 2.1.4 were utilized for data processing and evaluation."}, {"title": "2.4.1 Network Initialisation", "content": "Weights in all layers are set at the start of training by Kaiming initialization (He et al., 2015), except for the GCN, which is initialized with a small constant value to simulate equal node treatment during initial graph structure learning (Zhang et al., 2019). Kaiming initialization maintains activation variance and is especially useful for ReLU layers (He et al., 2015). All experiments were performed with a predefined manual seed for the random number generator to ensure reproducibility (Picard, 2023). To ensure consistency, hidden and cell states of the LSTM are initialized to zeros at the start of each sequence."}, {"title": "2.4. IMPLEMENTATION", "content": "Network model training used the Adam optimizer to learn weights. The Adam optimizer was chosen for its adaptive learning rate to enable efficient model convergence (Kingma and Ba, 2017). A scheduler adjusted the learning rate when validation loss plateaued to ensure continuous model improvement without overshooting (C. Kim et al., 2021). Regularization techniques were employed to prevent the model from becoming overly complex. The final loss function, shown in Equation 4, was comprised of Focal Loss and weight decay, a form of L2 regularization, to discourage overfitting (Cortes et al., 2012). Additionally, gradient clipping was utilized to prevent exploding gradients by scaling the gradients to a maximum norm, which ensures stable and controlled updates during training (Zhang et al., 2020).\nEquation 4: $L_2$ regularisation penalizes large weights by adding a term proportional to the sum of the squares of the weights to the loss function, where $\\lambda$ is the weight decay coefficient. The dataset was split using stratified sampling (80% training, 10% validation, 10% test) to preserve class distribution and ensure reliable evaluation. Training was performed for a total of 100 epochs. Early stopping monitored validation loss, and halting training if no improvement was seen over 10 epochs to prevent overfitting (Prechelt, 2012)."}, {"title": "2.4.3 Data Augmentation", "content": "Data augmentation, including horizontal flipping of keypoints, was used to increase the training dataset size and improve model generalization. Due to class imbalance, bootstrapping oversampled the minority class for training and validation to create class-balanced batches and prevent model bias. The test set remained unaltered to reflect realistic distributions to ensure accurate and reliable classification outcomes."}, {"title": "2.4.4 Hyperparameter Optimisation", "content": "Hyperparameters listed in Table 3 related to the complexity of features extracted by the network were tuned to balance network complexity and model performance against overfitting to the training set (LaValle et al., 2004). A grid search was used to systematically explore and identify the optimal network settings. After selecting the best hyperparameters (Table 4), model performance was evaluated on the test set to confirm its generalization ability. Dropout layers were added to prevent overfitting by randomly dropping neurons"}, {"title": "2.5. EXPERIMENTAL DESIGN", "content": "Extracted joint positions were downsampled videos from their original frame rate to a target frame rate by retaining a calculated number of time points within a \"block\" and skipping the rest. For example, downsampling from 25 fps to 10 fps involved skipping 15 frames and retaining 10 per block. The model was trained from scratch from each of the sampling frame rates. Model performance was compared as described in Section 2.4.2."}, {"title": "2.5.2 Performance Metrics", "content": "Model performance was performed quantitatively using the following metrics accuracy, sensitivity, and specificity (D\u00fcntsch and Gediga, 2019). Accuracy defined in Equation 5 is an overall performance metric. Sensitivity and specificity evaluate the model on its ability to correctly identify positive and negative cases respectively and are particularly important to verify model performance for imbalanced datasets (Baratloo et al., 2015)."}, {"title": "2.5. EXPERIMENTAL DESIGN", "content": "Equation 5: Calculates the true positive and true negative in all evaluated cases. TP = True positive, TN = True negative, FP = False positive, FN = False negative.\nEquation 6: Calculates the correct identification of the positive class out of all instances of the positive class.\nEquation 7: Calculates the correct identification of the negative class out of all instances of the negative class.\nEquation 8: The F1 score is the harmonic mean of precision and recall, providing a score that balances the trade-off between the two. Precision measures the accuracy of the positive predictions, while recall measures the ability of the model to find all relevant positive instances.\nF1-score was also calculated, which can help to evaluate model performance on imbalanced datasets (Christen et al., 2024)."}, {"title": "2.5.3 Cross-validation and STatistical Ananlysis", "content": "Cross-validation was employed to evaluate model performance (Refaeilzadeh et"}]}