{"title": "Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation", "authors": ["Krishan Agyakari Raja Babu", "Rachana Sathish", "Mrunal Pattanaik", "Rahul Venkataramani"], "abstract": "Synthetic data is becoming increasingly integral in data-scarce fields such as medical imaging, serving as a substitute for real data. However, its inherent statistical characteristics can significantly impact downstream tasks, potentially compromising deployment performance. In this study, we empirically investigate this issue and uncover a critical phenomenon: downstream neural networks often exploit spurious distinctions between real and synthetic data when there is a strong correlation between the data source and the task label. This exploitation manifests as simplicity bias, where models overly rely on superficial features rather than genuine task-related complexities. Through principled experiments, we demonstrate that the source of data (real vs. synthetic) can introduce spurious correlating factors leading to poor performance during deployment when the correlation is absent. We first demonstrate this vulnerability on a digit classification task, where the model spuriously utilizes the source of data instead of the digit to provide an inference. We provide further evidence of this phenomenon in a medical imaging problem related to cardiac view classification in echocardiograms, particularly distinguishing between 2-chamber and 4-chamber views. Given the increasing role of utilizing synthetic datasets, we hope that our experiments serve as effective guidelines for the utilization of synthetic datasets in model training.", "sections": [{"title": "Introduction", "content": "The acute challenge of data scarcity in medical imaging has spurred the development and application of various methods, including transfer learning, self-supervised learning, and data augmentation. More recently, synthetic data, either alone or combined with real data, has emerged as a popular technique to address the inherent data scarcity in medical imaging. The growing prominence of synthetic data is largely attributed to the efficiency of advanced generative techniques, such as generative adversarial networks (GANs), diffusion models [1], which produce high-quality visual images with relatively straightforward"}, {"title": "Related Work", "content": "Diffusion Probabilistic Models (DDPM), [6,14], have demonstrated remarkable performance in generating high-quality image samples. DDPMs leverage iterative denoising processes to model complex data distributions effectively. The core idea of DDPM revolves around iteratively applying a denoising process to generate samples from a target distribution. To enhance control over semantic details, recent advancements in generative modeling have focused on conditioning models on object-level segmentation masks. A semantic diffusion model (SDM) was proposed in a recent study [15] for generating synthetic 2D echocardiograms. In this study, we adopt the SDM framework as our model for generating synthetic images.\nThe promise shown by DDPMS, SDMs and similar models have spurred the utilization of synthetic data to enrich the training dataset [3,15], anomaly detection [16], super resolution [10] etc. Due to the increasing utilization of synthetic datasets in medical imaging, it is imperative to critically analyze the potential pitfalls carefully. Particularly, the phenomenon of simplicity bias has been observed in discriminative deep learning methods, where models tend to exploit"}, {"title": "Methodology", "content": "In order to explore the manifestation of synthetic simplicity in medical data augmentation, we consider the binary classification problem on a dataset $\\mathcal{D} = \\{(X_1, Y_1), (X_2, Y_2), ..., (X_N, Y_N)\\}$ comprising of N samples, where input images $X \\in \\mathbb{R}^{H \\times W}$ and labels $y \\in \\{-1,+1\\}$.Each image can be considered to possess M latent features represented as $f \\in \\mathbb{R}^M$ which can be leveraged for classification. One of the features can be assumed to be a binary feature $f_k \\in \\{0,1\\}$, where k denotes the feature index, representing whether a given sample is real or generated synthetically. We intentionally set the correlation between this binary feature and the output label to be high during training and evaluate during the testing phase when the correlation is lower. The test set consists of samples of the form $(X, y = 1, f_k = 0)$, indicating the low correlation between $y = 1$ and $f_k = 0$. We vary the degree of correlation using the parameter $\\alpha$ to explore different scenarios of synthetic simplicity.\nSo, with this configuration, the model during training has the potential to learn the simpler but spurious feature of real vs. synthetic. Since the correlation between the task label and data source is quite high, this will result in excellent performance during training. However, during evaluation when the correlation is lower, the performance may degrade if the simplicity bias is manifested. This test allows us to systematically investigate if the neural network utilizes the rest of the features $f_{i\\backslash k}$ or is predisposed to utilize feature $f_k$ due to it being simpler than other features."}, {"title": "Experiments", "content": "In this section, we will describe the dataset generation for both the digit classification and the echocardiographic view classification problem. The classification network was trained using real data augmented by the synthetic data in varying proportions to study the impact of the synthetic simplicity. Let $D_{R,C_1}^{Tr}$ denote the set of all real images of class 1, $D_{S,C_1}^{Tr}$ denote the set of all synthetic images of class 1, $D_{R,C_2}^{Tr}$ denote the set of all real images of class 2, and $D_{S,C_2}^{Tr}$ denote the set of all synthetic images of class 2. The composition of the training data is thus defined as follows:\n$|D^T| = \\alpha|D_{R,C_1}^{Tr}| + (1 - \\alpha)|D_{S,C_1}^{Tr}| + (1 - \\alpha)|D_{R,C_2}^{Tr}| + \\alpha|D_{S,C_2}^{Tr}|$\nwhere $\\alpha \\in [0, 1]$ is a hyperparameter and $\\alpha|D_{R,C_1}^{Tr}| + (1 - \\alpha)|D_{S,C_1}^{Tr}| = (1 - \\alpha)|D_{R,C_2}^{Tr}| + \\alpha|D_{S,C_2}^{Tr}| = k_{Tr}$. The test set has an equal number of real and synthetic images for both classes, i.e., $|D_{R,C_1}^{Ts}| = |D_{S,C_1}^{Ts}| = |D_{R,C_2}^{Ts}| = |D_{S,C_2}^{Ts}| = k_{Ts}$.\nWe design the experiments to include a mix of real and synthetic images of class 1 and 2 in the training dataset $D^{Tr}$, controlled by the hyperparameter $\\alpha$. When $\\alpha = 1$, the training dataset $D^{Tr}$ consists entirely of real images of class 1 ($D_{R,C_1}^{Tr}$) and synthetic images of class 2 ($D_{S,C_2}^{Tr}$). When $\\alpha = 0$, the training dataset $D^{Tr}$ consists entirely of synthetic images of class 1 ($D_{S,C_1}^{Tr}$) and real images of class 2 ($D_{R,C_2}^{Tr}$).\nFor values of $\\alpha$ between 0 and 1, the training dataset $D^{Tr}$ is a mix of real and synthetic images of both classes 0 and 1, with $\\alpha$ determining the specific proportion. If the model is able to maintain consistent performance regardless of the value of $\\alpha$, it can be considered robust. Otherwise, it may be affected by synthetic simplicity."}, {"title": "MNIST Digit Classification", "content": "We utilized the publicly available \"Modified National Institute of Standards and Technology\" (MNIST) [9] handwritten digits dataset for our experiment. It"}, {"title": "CAMUS Echocardiogram View Classification", "content": "After investigating the issue of synthetic simplicity in the digit classification task, we demonstrate the phenomenon on a representative medical imaging task of cardiac view classification from echocardiographs. We utilized the publicly available echocardiography dataset \"Cardiac Acquisitions for Multi-structure Ultrasound Segmentation\" (CAMUS) [8] for this experiment. The"}, {"title": "Results and Discussion", "content": "Experimental results for the CAMUS and MNIST classification tasks are presented in Figures 3 and 4, respectively. The following observations can be noted:\n1. Poor Performance in Extreme Cases of $\\alpha$: In the extreme case of $\\alpha =1$ (high positive correlation), the training dataset consists solely of real 2CH images and synthetic 4CH images. Under this condition, the model performs well on real 2CH images (Fig. 3(a)) and synthetic 4CH images (Fig. 3(d)). However, due to the simplicity bias, the model's performance on synthetic 2CH images (Fig. 3(b)) and real 4CH images (Fig. 3(c)) is nearly zero."}, {"title": "Conclusion", "content": "We clearly demonstrate that downstream tasks can leverage the binary feature of the dataset source (real v/s synthetic) for tasks such as classification. Therefore, it is crucial for practitioners to use synthetic data carefully during model development. This caution helps prevent the inclusion of spurious features and the generation of artificially high accuracy values on a test set derived from the same distribution. We hope that this work will stimulate more interest in understanding the risks associated with using synthetic data without domain expertise and encourage further research."}]}