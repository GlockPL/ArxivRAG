{"title": "Lifelong Person Search", "authors": ["Jae-Won Yang", "Seungbin Hong", "Jae-Young Sim"], "abstract": "Person search is the task to localize a query person\nin gallery datasets of scene images. Existing methods have been\nmainly developed to handle a single target dataset only, however\ndiverse datasets are continuously given in practical applications\nof person search. In such cases, they suffer from the catastrophic\nknowledge forgetting in the old datasets when trained on new\ndatasets. In this paper, we first introduce a novel problem of\nlifelong person search (LPS) where the model is incrementally\ntrained on the new datasets while preserving the knowledge\nlearned in the old datasets. We propose an end-to-end LPS\nframework that facilitates the knowledge distillation to enforce\nthe consistency learning between the old and new models by\nutilizing the prototype features of the foreground persons as well\nas the hard background proposals in the old domains. Moreover,\nwe also devise the rehearsal-based instance matching to further\nimprove the discrimination ability in the old domains by using\nthe unlabeled person instances additionally. Experimental results\ndemonstrate that the proposed method achieves significantly\nsuperior performance of both the detection and re-identification\nto preserve the knowledge learned in the old domains compared\nwith the existing methods.", "sections": [{"title": "I. INTRODUCTION", "content": "Person search is the technique to find the query person from\nthe gallery sets of scene images where multiple persons usually\nappear simultaneously in each image. It has been drawing\nmuch attention due to its practical applicability to various\nreal-world scenarios such as large-scale video understanding,\nsurveillance, and augmented reality. Different from the person\nre-identification (re-ID) [1], [2], [3], [4], [5], [6], [7] that finds\nthe query person from the sets of cropped person images, the\nperson search is a more challenging task that first localizes the\nbounding boxes of person instances in the scene images and\nthen matches the identities of the detected instances to the query\nperson. The person search can be implemented in the two-step\nmanner by using separately trained two sub-networks of the\nobject detection and re-ID. However, the training of the two-\nstep methods is usually inefficient requiring huge computational\ncomplexity, since the detection network extracts the bounding\nboxes for the person instances from the scene images which\nare then inputted to the re-ID network to retrieve the features\nagain tailored to the re-ID task.\nTo overcome this issue, the end-to-end learning was in-\ntroduced that jointly trains the person detection and re-ID\nnetworks. The end-to-end methods have been mainly developed\nin the supervised learning manner based on the assumption\nthat both of the training and test data come from a same\ntarget dataset [8], [9], [10], [11], [12], [13]. However, in many\npractical real-world applications, multiple datasets are generated\nin different places and times that exhibit domain gaps from\none another. In such cases, the existing supervised methods\ntrained on a certain dataset usually fail to work on other\ndatasets. Furthermore, re-training the network, whenever the\ntarget datasets are changed, suffers from the high computational\ncomplexity as well as the catastrophic forgetting [14] of the\nknowledge learned from the previously trained datasets.\nIn this paper, we first introduce a new problem of lifelong\nperson search (LPS) where the new datasets on different\ndomains are assumed to be sequentially given in order, as\nshown in Fig. 1. The model is forced to be generalized to all\ndomains while preserving the previously learned knowledge\nwithout entire re-training using all the datasets. The end-to-end\nLPS is more challenging compared to the lifelong object detec-\ntion [15], [16] and lifelong person re-ID [17], [18], [19], [20],\nsince it suffers from the catastrophic forgetting problem in\nboth sub-tasks of the person detection and re-ID. Whereas\nthe lifelong person detection is a domain-incremental task\nwhere only the same class of person is localized across\ndifferent domains, the lifelong person re-ID is related to\nboth domain-incremental and class-incremental tasks since\nthe new person identities are additionally given from different\ndomains. Moreover, the end-to-end person search also suffers\nfrom the task conflict problem where the person detection\nfocuses on extracting the common representation of persons\ndistinct from the backgrounds, but the person re-ID attempts\nto extract the unique representations according to the person\nidentities. This task conflict problem becomes more serious in\nLPS scenario where the model is encouraged to be continuously\nadapted to different domains. In addition, the lifelong re-ID"}, {"title": "II. RELATED WORKS", "content": "Person search has been studied mainly in the supervised\nmanner where the bounding boxes of person instances and\nthe person identities are labeled in the training datasets. The\ntwo-step methods train the person detection and re-ID networks\nseparately to prevent the conflict problem between the two tasks.\nZheng et al. [21] conducted extensive experiments by training\nthe state-of-the-art methods of the pedestrian detection and\nperson re-ID. They also provided a benchmark PRW dataset.\nPu et al. [22] proposed a segmentation masking scheme to\nforce the re-ID network to focus on the foreground regions\nof the detected persons. Lan et al. [23] extracted multi-scale\nfeatures to deal with the scale variation problem of person\nsize in the scene images. Wang et al. [24] made the re-ID\nnetwork more adapted to the detection results by composing\nthe training set with the person images cropped by the pre-\ntrained detection network and the person images cropped by\nusing the bounding box labels. Ke et al. [25] performed a data\naugmentation scheme that shifts the locations of the ground\ntruth bounding boxes for the re-ID network training.\nThe end-to-end methods jointly train the person detection\nand re-ID networks. Xiao et al. [26] firstly proposed an end-to-\nend person search network and provided a benchmark CUHK-\nSYSU dataset. Chen et al. [27] employed the background\nfeatures as negative samples to train the re-ID network.\nChen et al. [8] separated the feature embedding into the\nnorm and angle which are used as a detection confidence\nscore and an identity feature, respectively. Zhang et al. [28]\npretrained an external re-ID network which is then used as\na strong teacher model to supervise the re-ID network based\non the knowledge distillation framework. Li and Miao [29]\nemployed an additional Faster R-CNN header sequentially to\nextract the superior identity features from the high-quality\nperson proposals. Han et al. [11] adaptively controlled the\ngradient backpropagation to train the sub-networks of the re-\nID and part classification according to the quality of detection\nresults. Lee et al. [12] suggested a feature standardization\nscheme and a localization aware memory updating scheme\nto alleviate the effect of class imbalance and inaccurately\ndetected proposals, respectively. The transformer architectures\nwere also employed to improved the performance of person\nsearch [30], [13], [31], [32]. Recently, Oh et al. [33] assumed\nthe training data of real target domains are not available, and\nproposed a domain generalizable person search method that\nuses only an unreal dataset for training.\nOn the other hand, the weakly-supervised person search has\nbeen introduced that uses the labeled bounding boxes only with-\nout using the identity labels for training [34], [35], [36], [37].\nMoreover, domain-adaptation methods have been proposed to\naddress the unsupervised person search problem where both\nof the bounding box and identity labels are not available [38],\n[39]. Note that the existing methods of person search have\nbeen usually developed considering a single target dataset\nonly, and hence suffer from the catastrophic forgetting problem\nwhere new target datasets are continuously given in the lifelong\nlearning scenario."}, {"title": "B. Lifelong Object Detection", "content": "Lifelong object detection methods are classified into the class-\nincremental approach and the domain-incremental approach.\nThe class-incremental object detection considers a certain target\ndataset where the new object classes are incrementally added.\nShmelkov et al. [15] first introduced the problem of catastrophic\nforgetting in the object detection. Adaptive distillation has\nbeen performed between the intermediate features and the"}, {"title": "III. PROPOSED METHOD", "content": "Fig. 2 shows the overall architecture of the proposed end-\nto-end LPS framework. We use the SeqNet [29] as a baseline\nnetwork which consists of the Faster R-CNN [50] and the\nNAE (norm-aware embedding) [8] header. Let us assume that\na sequence of person search datasets in different domains are\ngiven in order, as $D_1 \\rightarrow D_2 \\rightarrow \\dots \\rightarrow D_N$. The model is\ntrained by using the first dataset $D_1$. When the new dataset\n$D_2$ is given, we regard the model trained on $D_1$ as the old\nmodel, and construct a new model by replicating the old model.\nThen the new model is trained by using $D_2$ and a small\nsubset of $D_1$, called exemplar data, to avoid the knowledge\nforgetting of $D_1$. We also use the representative features of\nperson identities, called prototypes [51], stored in the old look-\nup table (LUT) $T$. Whenever a new dataset $D_N$ is available,\nthe old model is replaced with the new model, and the new\nmodel is re-trained by using the new data $D_N$ as well as\nboth the old exemplar data and the old prototypes selected\nfrom ${D_1,\\dots, D_{n-1}}$ to mitigate the catastrophic forgetting.\nWe use a small subset of the old data following the typical\nrehearsal (replay) based methodology of lifelong learning [17],\n[19], [41], [51]. However, it is worth to note that we do not\nemploy multiple old models but always have a single old model\nwhich is updated whenever a new dataset is given. The old\nmodel conveys the knowledge of the previous domains and thus\nthe parameters of the old model are frozen during the training\nof the new model. We preserve the knowledge of the old data\nwhile training the model using the new data via knowledge\ndistillation between the old and new models."}, {"title": "A. Re-ID Knowledge Distillation", "content": "1) Prototype-Based Distillation: Existing methods of life-\nlong person re-ID [17], [19] perform the knowledge distillation"}, {"title": "2) Hard Background Proposal-Based Distillation", "content": "Though\nthe prototypes in the old LUT serve as a good prior for the re-ID\nknowledge distillation, we further improve the performance by\nusing the background proposals in the old domains additionally.\nAt each iteration, the new model detects the background\nproposals from the scene images in the exemplar data, as\ndepicted in the red boxes in Fig. 3. Inaccurate background\nproposals are often generated that partially overlap with the\nforeground person instances. We refer them as the hard\nbackground proposals. The hard background proposals convey\nthe partial information of the person identities, exploited to\nimprove the discrimination performance of the person identities.\nSpecifically, we sample the hard background proposals that\nhave the higher intersection over union (IoU) scores than a\ncertain threshold \u266d, with respect to the ground truth bounding\nboxes of the foreground persons, as depicted in the blue\nboxes in Fig. 3. Then we store the re-ID features of the hard\nbackground proposals into the feature memory $M$. We re-\ncompute the distributions of the feature similarity compared to\nall the prototypes in $T$ as well as all the features of the hard\nbackground proposals in $M$, such that the probabilities $q_{i,k}$\nand $p_{i,k}$ associated with $z_k$, the k-th element in $T \\cup M$, are\ngiven by\n$q_{i,k}=\\frac{\\exp{\\left(z_{k}^{T} \\mathbf{x}_{i}^{\\text {old }} / \\tau_{d}\\right)}}{\\sum_{z \\in{T \\cup M}} \\exp \\left(z^{T} \\mathbf{x}_{i}^{\\text {old }} / \\tau_{d}\\right)},$\\n$p_{i,k}=\\frac{\\exp{\\left(z_{k}^{T} \\mathbf{x}_{i}^{\\text {new }} / \\tau_{d}\\right)}}{\\sum_{z \\in{T \\cup M}} \\exp \\left(z^{T} \\mathbf{x}_{i}^{\\text {new }} / \\tau_{d}\\right)}.$\nAccordingly, we have the refined re-ID knowledge distillation\nloss as\n$L_{i k d}=\\frac{1}{|F||T \\cup M|} \\sum_{i \\in I(F)} \\sum_{k \\in I(T \\cup M)} q_{i, k} \\log \\frac{q_{i, k}}{p_{i, k}}.$\nConsequently, we improve the discrimination performance of\nthe person identities by exploiting more rich information carried\nby the hard background proposals. Furthermore, the features\nlearned by additionally using the hard background proposals are\nmore robust against the inaccurately detected person proposals,\nwhich alleviates the task conflict problem between the detection\nand re-ID even when the detection knowledge in the old\ndomains is forgotten."}, {"title": "B. Rehearsal-Based Instance Matching", "content": "The foreground and background proposals extracted from the\nexemplar data are used for consistent learning between the old\nand new models via the re-ID knowledge distillation. Note that,\nas depicted in the green boxes in Fig. 3, some foreground person\ninstances have no identity labels. Such unlabeled instances can\nalso serve as the negative samples for all the labeled identities\nto learn the discriminative feature representations. At the same\ntime, the new model should be guided to minimize the feature\ndiscrepancy across the person instances in the exemplar data\nthat have the same identity. Therefore, we also utilize the\nunlabeled instances in the exemplar data to further capture the\nre-ID knowledge in the old domains while the model is trained\non the new data.\nThe features of the unlabeled proposals are stored in the\nold circular queue $Q$. Let $F_L$ denote the set of the labeled\nproposals in $F$, and let $\\mathbf{x}^{\\text{new}}_{i}$ be the feature of the $i$-th proposal\nin $F_L$ extracted by the new model. We compute the probability\nthat $\\mathbf{x}^{\\text{new}}_{i}$ is classified into its ground truth label as\n$p_{i}=\\frac{\\exp {\\left(\\mathbf{z}^{(i) T} \\mathbf{x}_{i}^{\\text {new }} / \\tau_{r}\\right)}}{\\sum_{\\mathbf{z} \\in T} \\exp \\left(\\mathbf{z}^{T} \\mathbf{x}_{i}^{\\text {new }} / \\tau_{r}\\right)+\\sum_{\\mathbf{y} \\in Q} \\exp \\left(\\mathbf{y}^{T} \\mathbf{x}_{i}^{\\text {new }} / \\tau_{r}\\right)},$\nwhere $\\mathbf{z}^{(i)}$ means the prototype of the ground truth identity\nof the $i$-th proposal in $F_L$, and $\\mathbf{y}$ denotes the feature of the\nunlabeled proposals stored in $Q$. We train the new model to\nincrease the classification score of the extracted features by\nemploying the rehearsal-based instance matching loss given by\n$L_{r i m}=-\\frac{1}{|F_L|} \\sum_{i \\in I(F_L)} \\log p_{i}.$\nBy minimizing $L_{rim}$, we reduce the feature discrepancy between\nthe labeled proposal and its ground truth identity while\npreserving the discrimination performance in the old domains\nwith the help of the unlabeled proposals. It is worth to note that\nthe conventional OIM [26] loss considers the labeled identities\nand the unlabeled instances in a single target domain only. On\nthe contrary, the proposed rehearsal-based loss $L_{rim}$ employs\nthe labeled identities and the unlabeled instances across the\nold data, aiming to preserve the discrimination performance in\nthe old domains for lifelong learning purpose."}, {"title": "C. Training and Inference", "content": "At the training phase, both of the person detection and re-ID\nnetworks are trained in the end-to-end manner. Note that the\nbaseline network of SeqNet [29] also uses the losses of $L_{det}$\nand $L_{oim}$ when training the new model by using the new dataset.\nTo preserve the knowledge of the old domains in terms of the\nperson detection, we additionally use the detection knowledge\ndistillation loss $L_{dkd}$ of the existing lifelong object detection\nmethod [16]. Finally, the total loss function is given by\n$L_{\\text {total }}=L_{d k d}+L_{r k d}+L_{r i m}+L_{\\text {det }}+L_{o i m}.$\nAfter the new model is trained with the last dataset $D_N$,\nwe discard the old model and only utilize the new model to\ndetect the bounding boxes of the person instances and extract\nthe re-ID features for all the datasets ${D_1, D_2 . . . D_N}$ at the\ninference phase."}, {"title": "IV. EXPERIMENTAL RESULTS", "content": "1) Datasets: We used the three datasets to evaluate the\nperformance of the proposed lifelong person search method.\nCUHK-SYSU [26] and PRW [21] are widely used for the\nperson search task. The CUHK-SYSU dataset includes the\nimages obtained from the street snapshots and movies, with\nthe annotations of the bounding boxes and person identities.\nWe set the gallery size to 100. The PRW dataset is composed of\nthe video frames capturing a university campus by six different\ncameras. We also use a recently released large-scale person\nsearch dataset of MovieNet-PS [52] gathered from the 385\nmovie sequences. The MovieNet-PS is a challenging dataset\nsince it includes the scene images with diverse backgrounds,\nilluminations, and poses of persons to reflect more realistic and\nchallenging scenarios of person search. Moreover, there are\nmany persons partially appearing due to the occlusion, and the\nperson instances with the same identity often wear different\nclothes. The statistics of the three datasets are shown in Table I."}, {"title": "B. Lifelong Learning Performance", "content": "We evaluate the lifelong learning performance of the pro-\nposed method with the training order of CUHK-SYSU \u2192\nPRW \u2192 MovieNet-PS in Table II. We first compare two\ndifferent methods: Joint-Train and FineTune, implemented on\nour baseline network. The Joint-Train method trains the model\nby using all the available datasets simultaneously. The FineTune\nmethod trains the model on each dataset in order, where the\nmodel is initialized with the previously trained weights and\nthen re-trained by using the new dataset. At the inference phase,\nthe performance is evaluated on every dataset by using the\nmodel trained on the last dataset.\nThe Joint-Train method achieves the best performance since\nit uses all the training datasets at once, however, it requires a\nhuge burden of the computation as well as the storage space. We\nobserve that the proposed method provides comparable results\nto the Joint-Train method and outperforms the FineTune method\nin terms of the averaged mAP and Top-1 score, respectively.\nNote that the FineTune method sequentially re-trains the model\non each dataset without using the previous old datasets, and thus\nits performance on the last dataset, MovieNet-PS, is relatively\nhigh. On the contrary, the proposed method uses a small subset\nof the old data to alleviate the knowledge forgetting and slightly\ndegrades the performance on the last dataset compared to the\nFineTune method. However, the proposed method significantly\noutperforms the FineTune method in the old datasets of CUHK-\nSYSU and PRW."}, {"title": "D. Ablation Study", "content": "In Table III, we first evaluate the effect of the\nthree losses, the detection knowledge distillation loss $L_{dkd}$, the\nre-ID knowledge distillation loss $L_{rkd}$, and the rehearsal-based\ninstance matching loss $L_{rim}$, respectively. Note that detaching\nall the losses is the same as the FineTune method since the\nproposed losses are designed to work only when the old\ndata are available. We see that adding each loss improves\nthe performance, respectively. Specifically, when we use $L_{dkd}$,\nthe detection performance is largely increased from that of the\nFineTune method on the old datasets, and the re-ID performance\nis also increased accordingly. On the other hand, $L_{rkd}$ and $L_{rim}$\nslightly increase the detection performance of using $L_{dkd}$, but\nsignificantly improve the re-ID performance on the old datasets\nof CUHK-SYSU and PRW by huge margins, demonstrating\nthe effectiveness to preserve the re-ID knowledge in the old\ndomains."}, {"title": "E. Limitation", "content": "The proposed method stores 2% of the old data into the exem-\nplar memory the typical rehearsal (replay) based methodology\nof lifelong learning [17], [19], [41], [51]. Therefore, the size\nof the exemplar memory increases as we have more and more\ndatasets. As a future research topic, we will investigate other"}, {"title": "V. CONCLUSION", "content": "In this paper, we proposed a novel LPS framework where\nthe model needs to be incrementally trained on the new\ndatasets while preserving the knowledge of the old datasets.\nWe implemented the knowledge distillation between the old\nand new models based on the rehearsal methodology by using\nthe representative prototype features of the labeled foreground\npersons as well as the hard background proposals in the old\nexemplar data. We also designed the rehearsal-based instance\nmatching loss to improve the discrimination ability by using the\nunlabeled person instances in addition to the prototype features.\nExperimental results evaluated on three datasets of person\nsearch showed that the proposed method achieves significantly\nbetter performance of lifelong learning compared with the\nexisting methods, and successfully prevents the knowledge\nforgetting in the old domains. We expect this pioneering work\nwould encourage further research for practical LPS applications."}]}