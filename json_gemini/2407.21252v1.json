{"title": "Lifelong Person Search", "authors": ["Jae-Won Yang", "Seungbin Hong", "Jae-Young Sim"], "abstract": "Person search is the task to localize a query person in gallery datasets of scene images. Existing methods have been mainly developed to handle a single target dataset only, however diverse datasets are continuously given in practical applications of person search. In such cases, they suffer from the catastrophic knowledge forgetting in the old datasets when trained on new datasets. In this paper, we first introduce a novel problem of lifelong person search (LPS) where the model is incrementally trained on the new datasets while preserving the knowledge learned in the old datasets. We propose an end-to-end LPS framework that facilitates the knowledge distillation to enforce the consistency learning between the old and new models by utilizing the prototype features of the foreground persons as well as the hard background proposals in the old domains. Moreover, we also devise the rehearsal-based instance matching to further improve the discrimination ability in the old domains by using the unlabeled person instances additionally. Experimental results demonstrate that the proposed method achieves significantly superior performance of both the detection and re-identification to preserve the knowledge learned in the old domains compared with the existing methods.", "sections": [{"title": "I. INTRODUCTION", "content": "Person search is the technique to find the query person from the gallery sets of scene images where multiple persons usually appear simultaneously in each image. It has been drawing much attention due to its practical applicability to various real-world scenarios such as large-scale video understanding, surveillance, and augmented reality. Different from the person re-identification (re-ID) [1], [2], [3], [4], [5], [6], [7] that finds the query person from the sets of cropped person images, the person search is a more challenging task that first localizes the bounding boxes of person instances in the scene images and then matches the identities of the detected instances to the query person. The person search can be implemented in the two-step manner by using separately trained two sub-networks of the object detection and re-ID. However, the training of the two- step methods is usually inefficient requiring huge computational complexity, since the detection network extracts the bounding boxes for the person instances from the scene images which are then inputted to the re-ID network to retrieve the features again tailored to the re-ID task.\nTo overcome this issue, the end-to-end learning was in- troduced that jointly trains the person detection and re-ID networks. The end-to-end methods have been mainly developed in the supervised learning manner based on the assumption that both of the training and test data come from a same target dataset [8], [9], [10], [11], [12], [13]. However, in many practical real-world applications, multiple datasets are generated in different places and times that exhibit domain gaps from one another. In such cases, the existing supervised methods trained on a certain dataset usually fail to work on other datasets. Furthermore, re-training the network, whenever the target datasets are changed, suffers from the high computational complexity as well as the catastrophic forgetting [14] of the knowledge learned from the previously trained datasets.\nIn this paper, we first introduce a new problem of lifelong person search (LPS) where the new datasets on different domains are assumed to be sequentially given in order, as shown in Fig. 1. The model is forced to be generalized to all domains while preserving the previously learned knowledge without entire re-training using all the datasets. The end-to-end LPS is more challenging compared to the lifelong object detec- tion [15], [16] and lifelong person re-ID [17], [18], [19], [20], since it suffers from the catastrophic forgetting problem in both sub-tasks of the person detection and re-ID. Whereas the lifelong person detection is a domain-incremental task where only the same class of person is localized across different domains, the lifelong person re-ID is related to both domain-incremental and class-incremental tasks since the new person identities are additionally given from different domains. Moreover, the end-to-end person search also suffers from the task conflict problem where the person detection focuses on extracting the common representation of persons distinct from the backgrounds, but the person re-ID attempts to extract the unique representations according to the person identities. This task conflict problem becomes more serious in LPS scenario where the model is encouraged to be continuously adapted to different domains. In addition, the lifelong re-ID"}, {"title": "II. RELATED WORKS", "content": "Person search has been studied mainly in the supervised manner where the bounding boxes of person instances and the person identities are labeled in the training datasets. The two-step methods train the person detection and re-ID networks separately to prevent the conflict problem between the two tasks. Zheng et al. [21] conducted extensive experiments by training the state-of-the-art methods of the pedestrian detection and person re-ID. They also provided a benchmark PRW dataset.\nPu et al. [22] proposed a segmentation masking scheme to force the re-ID network to focus on the foreground regions of the detected persons. Lan et al. [23] extracted multi-scale features to deal with the scale variation problem of person size in the scene images. Wang et al. [24] made the re-ID network more adapted to the detection results by composing the training set with the person images cropped by the pre- trained detection network and the person images cropped by using the bounding box labels. Ke et al. [25] performed a data augmentation scheme that shifts the locations of the ground truth bounding boxes for the re-ID network training.\nThe end-to-end methods jointly train the person detection and re-ID networks. Xiao et al. [26] firstly proposed an end-to- end person search network and provided a benchmark CUHK- SYSU dataset. Chen et al. [27] employed the background features as negative samples to train the re-ID network. Chen et al. [8] separated the feature embedding into the norm and angle which are used as a detection confidence score and an identity feature, respectively. Zhang et al. [28] pretrained an external re-ID network which is then used as a strong teacher model to supervise the re-ID network based on the knowledge distillation framework. Li and Miao [29] employed an additional Faster R-CNN header sequentially to extract the superior identity features from the high-quality person proposals. Han et al. [11] adaptively controlled the gradient backpropagation to train the sub-networks of the re- ID and part classification according to the quality of detection results. Lee et al. [12] suggested a feature standardization scheme and a localization aware memory updating scheme to alleviate the effect of class imbalance and inaccurately detected proposals, respectively. The transformer architectures were also employed to improved the performance of person search [30], [13], [31], [32]. Recently, Oh et al. [33] assumed the training data of real target domains are not available, and proposed a domain generalizable person search method that uses only an unreal dataset for training.\nOn the other hand, the weakly-supervised person search has been introduced that uses the labeled bounding boxes only with- out using the identity labels for training [34], [35], [36], [37]. Moreover, domain-adaptation methods have been proposed to address the unsupervised person search problem where both of the bounding box and identity labels are not available [38], [39]. Note that the existing methods of person search have been usually developed considering a single target dataset only, and hence suffer from the catastrophic forgetting problem where new target datasets are continuously given in the lifelong learning scenario."}, {"title": "III. PROPOSED METHOD", "content": "Fig. 2 shows the overall architecture of the proposed end- to-end LPS framework. We use the SeqNet [29] as a baseline network which consists of the Faster R-CNN [50] and the NAE (norm-aware embedding) [8] header. Let us assume that a sequence of person search datasets in different domains are given in order, as $D_1 \\rightarrow D_2 \\rightarrow \\dots \\rightarrow D_N$. The model is trained by using the first dataset $D_1$. When the new dataset $D_2$ is given, we regard the model trained on $D_1$ as the old model, and construct a new model by replicating the old model. Then the new model is trained by using $D_2$ and a small subset of $D_1$, called exemplar data, to avoid the knowledge forgetting of $D_1$. We also use the representative features of person identities, called prototypes [51], stored in the old look- up table (LUT) $T$. Whenever a new dataset $D_N$ is available, the old model is replaced with the new model, and the new model is re-trained by using the new data $D_N$ as well as both the old exemplar data and the old prototypes selected from {$D_1,\\dots, D_{n-1}$} to mitigate the catastrophic forgetting. We use a small subset of the old data following the typical rehearsal (replay) based methodology of lifelong learning [17], [19], [41], [51]. However, it is worth to note that we do not employ multiple old models but always have a single old model which is updated whenever a new dataset is given. The old model conveys the knowledge of the previous domains and thus the parameters of the old model are frozen during the training of the new model. We preserve the knowledge of the old data while training the model using the new data via knowledge distillation between the old and new models.\nExisting methods of life- long person re-ID [17], [19] perform the knowledge distillation"}, {"title": "A. Re-ID Knowledge Distillation", "content": "1) Prototype-Based Distillation: Existing methods of life- long person re-ID [17], [19] perform the knowledge distillation by matching the distributions of the feature similarity between the old and new models within a mini-batch. However, it may not provide faithful results when applied to LPS, since a mini-batch is composed of relatively small numbers of scene images, and small numbers of identities accordingly, due to the memory constraints. Furthermore, multiple person instances with the same identity are rarely included in a single mini-batch according to the uniqueness prior [35].\nTo address this issue for LPS, we utilize the stored pro- totypes of person identities as informative guidance for the re-ID knowledge distillation. The prototype is computed by aggregating the features of diverse person instances with the same identity [8], [13], [26], [29]. Let $F$ denotes the set of the foreground proposals in the exemplar data of a single mini- batch, that is detected by the Faster R-CNN of the new model. Let $\\textbf{x}^{old}_i$ and $\\textbf{x}^{new}_i$ be the $L_2$-normalized features of the $i$-th proposal in $F$, that are extracted through the NAE headers of the old and new models, respectively. We estimate the target distribution of the feature similarity of $\\textbf{x}^{old}_i$ compared to all the prototypes in $T$, such that the probability $q_{i,k}$ associated with $\\textbf{x}^{old}_i$ and $\\textbf{z}_k$, the $k$-th prototype in $T$, is given by\n$q_{i,k} = \\frac{\\text{exp} (\\textbf{z}^T_k\\textbf{x}^{old}_i/T_d)}{\\sum_{\\textbf{z} \\in T} \\text{exp} (\\textbf{z}^T\\textbf{x}^{old}_i/T_d)}$  (1)\nWe also estimate the predicted distribution of the feature similarity of $\\textbf{x}^{new}_i$ compared to all the prototypes, such that the probability $p_{i,k}$ associated with $\\textbf{x}^{new}_i$ and $\\textbf{z}_k$ is given by\n$p_{i,k} = \\frac{\\text{exp} (\\textbf{z}^T_k\\textbf{x}^{new}_i/T_d)}{\\sum_{\\textbf{z} \\in T} \\text{exp} (\\textbf{z}^T\\textbf{x}^{new}_i/T_d)}$.  (2)\nNote that the predicted similarity distribution with respect to the prototypes in the old domains changes when the model is trained on the new domain, which could cause the forgetting of the re-ID knowledge learned on the old domains. Therefore, we train the new model to generate a more consistent distribution to the target distribution by employing a prototype-based re-ID knowledge distillation loss given by\n$L_{rkd} = \\frac{1}{|F||T|} \\sum_{i\\in I(F)} \\sum_{k\\in I(T)} q_{i,k} \\log \\frac{q_{i,k}}{p_{i,k}}$,  (3)\nwhere $I(\\cdot)$ means the index set. By minimizing $L_{rkd}$, the new model is trained to yield a more consistent distribution to the target distribution with respect to the prototypes in the old domains, and eventually extracts unique and representative features of all person identities alleviating the catastrophic forgetting in re-ID."}, {"title": "B. Rehearsal-Based Instance Matching", "content": "2) Hard Background Proposal-Based Distillation: Though the prototypes in the old LUT serve as a good prior for the re-ID knowledge distillation, we further improve the performance by using the background proposals in the old domains additionally. At each iteration, the new model detects the background proposals from the scene images in the exemplar data, as depicted in the red boxes in Fig. 3. Inaccurate background proposals are often generated that partially overlap with the foreground person instances. We refer them as the hard background proposals. The hard background proposals convey the partial information of the person identities, exploited to improve the discrimination performance of the person identities. Specifically, we sample the hard background proposals that have the higher intersection over union (IoU) scores than a certain threshold $\\flat$, with respect to the ground truth bounding boxes of the foreground persons, as depicted in the blue boxes in Fig. 3. Then we store the re-ID features of the hard background proposals into the feature memory $M$. We re- compute the distributions of the feature similarity compared to all the prototypes in $T$ as well as all the features of the hard background proposals in $M$, such that the probabilities $q^+_{i,k}$ and $p^+_{i,k}$ associated with $\\textbf{z}_k$, the $k$-th element in $T \\cup M$, are given by\n$q^+_{i,k} = \\frac{\\text{exp} (\\textbf{z}^T_k\\textbf{x}^{old}_i/T_d)}{\\sum_{\\textbf{z} \\in {T \\cup M}} \\text{exp} (\\textbf{z}^T\\textbf{x}^{old}_i/T_d)}$, (4)\n$p^+_{i,k} = \\frac{\\text{exp} (\\textbf{z}^T_k\\textbf{x}^{new}_i/T_d)}{\\sum_{\\textbf{z} \\in {T \\cup M}} \\text{exp} (\\textbf{z}^T\\textbf{x}^{new}_i/T_d)}$. (5)\nAccordingly, we have the refined re-ID knowledge distillation loss as\n$L^+_{rkd} = \\frac{1}{|F||T \\cup M|} \\sum_{i\\in I(F)} \\sum_{k\\in I(T \\cup M)} q^+_{i,k} \\log \\frac{q^+_{i,k}}{p^+_{i,k}}$. (6)\nConsequently, we improve the discrimination performance of the person identities by exploiting more rich information carried by the hard background proposals. Furthermore, the features learned by additionally using the hard background proposals are more robust against the inaccurately detected person proposals, which alleviates the task conflict problem between the detection and re-ID even when the detection knowledge in the old domains is forgotten."}, {"title": "C. Training and Inference", "content": "The foreground and background proposals extracted from the exemplar data are used for consistent learning between the old and new models via the re-ID knowledge distillation. Note that, as depicted in the green boxes in Fig. 3, some foreground person instances have no identity labels. Such unlabeled instances can also serve as the negative samples for all the labeled identities to learn the discriminative feature representations. At the same time, the new model should be guided to minimize the feature discrepancy across the person instances in the exemplar data that have the same identity. Therefore, we also utilize the unlabeled instances in the exemplar data to further capture the re-ID knowledge in the old domains while the model is trained on the new data.\nThe features of the unlabeled proposals are stored in the old circular queue $Q$. Let $F_L$ denote the set of the labeled proposals in $F$, and let $\\textbf{x}^{new}_i$ be the feature of the $i$-th proposal in $F_L$ extracted by the new model. We compute the probability that $\\textbf{x}^{new}_i$ is classified into its ground truth label as\n$p_i = \\frac{\\text{exp} (\\textbf{z}^{(i)T}\\textbf{x}^{new}_i/T_r)}{\\sum_{\\textbf{z} \\in T} \\text{exp} (\\textbf{z}^{T}\\textbf{x}^{new}_i/T_r) + \\sum_{\\textbf{y} \\in Q} \\text{exp} (\\textbf{y}^{T}\\textbf{x}^{new}_i/T_r)}$, (7)\nwhere $\\textbf{z}^{(i)}$ means the prototype of the ground truth identity of the $i$-th proposal in $F_L$, and $\\textbf{y}$ denotes the feature of the unlabeled proposals stored in $Q$. We train the new model to increase the classification score of the extracted features by employing the rehearsal-based instance matching loss given by\n$L_{rim} = -\\frac{1}{|F_L|} \\sum_{i\\in I(F_L)} \\log p_i$  (8)\nBy minimizing $L_{rim}$, we reduce the feature discrepancy between the labeled proposal and its ground truth identity while preserving the discrimination performance in the old domains with the help of the unlabeled proposals. It is worth to note that the conventional OIM [26] loss considers the labeled identities and the unlabeled instances in a single target domain only. On the contrary, the proposed rehearsal-based loss $L_{rim}$ employs the labeled identities and the unlabeled instances across the old data, aiming to preserve the discrimination performance in the old domains for lifelong learning purpose.\nAt the training phase, both of the person detection and re-ID networks are trained in the end-to-end manner. Note that the baseline network of SeqNet [29] also uses the losses of $L_{det}$ and $L_{oim}$ when training the new model by using the new dataset. To preserve the knowledge of the old domains in terms of the person detection, we additionally use the detection knowledge distillation loss $L_{dkd}$ of the existing lifelong object detection method [16]. Finally, the total loss function is given by\n$L_{total} = L_{dkd} + L_{rkd} + L_{rim} + L_{det} + L_{oim}$.  (9)\nAfter the new model is trained with the last dataset $D_N$, we discard the old model and only utilize the new model to detect the bounding boxes of the person instances and extract the re-ID features for all the datasets {$D_1, D_2 \\dots D_N$} at the inference phase."}, {"title": "IV. EXPERIMENTAL RESULTS", "content": "We used the three datasets to evaluate the performance of the proposed lifelong person search method. CUHK-SYSU [26] and PRW [21] are widely used for the person search task. The CUHK-SYSU dataset includes the images obtained from the street snapshots and movies, with the annotations of the bounding boxes and person identities. We set the gallery size to 100. The PRW dataset is composed of the video frames capturing a university campus by six different cameras. We also use a recently released large-scale person search dataset of MovieNet-PS [52] gathered from the 385 movie sequences. The MovieNet-PS is a challenging dataset since it includes the scene images with diverse backgrounds, illuminations, and poses of persons to reflect more realistic and challenging scenarios of person search. Moreover, there are many persons partially appearing due to the occlusion, and the person instances with the same identity often wear different clothes. The statistics of the three datasets are shown in Table I."}, {"title": "B. Lifelong Learning Performance", "content": "We evaluate the lifelong learning performance of the pro- posed method with the training order of CUHK-SYSU \u2192 PRW \u2192 MovieNet-PS in Table II. We first compare two different methods: Joint-Train and FineTune, implemented on our baseline network. The Joint-Train method trains the model by using all the available datasets simultaneously. The FineTune method trains the model on each dataset in order, where the model is initialized with the previously trained weights and then re-trained by using the new dataset. At the inference phase, the performance is evaluated on every dataset by using the model trained on the last dataset.\nThe Joint-Train method achieves the best performance since it uses all the training datasets at once, however, it requires a huge burden of the computation as well as the storage space. We observe that the proposed method provides comparable results to the Joint-Train method and outperforms the FineTune method in terms of the averaged mAP and Top-1 score, respectively. Note that the FineTune method sequentially re-trains the model on each dataset without using the previous old datasets, and thus its performance on the last dataset, MovieNet-PS, is relatively high. On the contrary, the proposed method uses a small subset of the old data to alleviate the knowledge forgetting and slightly degrades the performance on the last dataset compared to the FineTune method. However, the proposed method significantly outperforms the FineTune method in the old datasets of CUHK- SYSU and PRW.\nFig. 4 shows the performance evaluated on the old datasets of CUHK-SYSU (blue) and PRW (red), when the model is sequentially trained on the new datasets in the x-axis, in order. As shown by the dashed lines, both the AP and mAP scores are decreased in the FineTune method showing the knowledge forgetting effect of both the detection and re-ID tasks in the LPS scenario. However, the proposed method significantly mitigates such performance degradation as shown by the solid lines, and successfully preserves the old knowledge for LPS.\nIn addition, we show the performance of the proposed LPS method when the model is trained with different orders of the datasets. In Fig. 5, Order1 and Order2 represent the training orders of 'MovieNet-PS \u2192 CUHK-SYSU \u2192 PRW' and 'PRW \u2192 CUHK-SYSU \u2192 MovieNet-PS,' respectively. In both orders, we see that the proposed method still outperforms the FineTune methods in terms of the detection and re-ID performances, which indicates that the proposed method provides reliable performance regardless of the training orders."}, {"title": "C. Comparison with Two-Step Methods", "content": "Note that we first introduce the new problem of LPS in this paper, and there is no existing method fairly comparable to the proposed method. We attempted to conduct the additional comparative experiments by using the recent lifelong re-ID methods of AKA [18], PTKP [19] and KRKC [48]. The lifelong re-ID methods work on the cropped person images only and cannot be directly applied to our LPS framework that considers the scene images. We instead implemented the two-step person search framework by using the existing lifelong person re-ID methods, where the detection and re-ID networks are trained separately. We used the ResNet-50 as the backbone network for the compared methods. We also trained the detection network by using the detection knowledge distillation loss $L_{dkd}$ for fair comparison.\nTable II compares the quantitative performance of lifelong learning where we see that the proposed method outperforms the two-step methods of 'Det + AKA,' \u2018Det + PTKP,' and \u2018Det + KRKC' in terms of both the detection and re-ID performance. It means that whereas the two-step implementation of LPS by using the existing lifelong re-ID methods does not effectively reflect huge domain gaps among the person search datasets with severely different characteristics, the proposed end-to- end framework alleviates such domain gaps faithfully and is more generalizable to diverse person search datasets. We also compared the upper-bound performance of the person re-ID by adopting the ground-truth (GT) bounding boxes for person detection, denoted as 'Det* + AKA,' 'Det* + PTKP,' 'Det* + KRKC,' and Proposed*. Note that all the methods yield the perfect performance of detection in terms of the recall and AP, but the proposed method achieves better performance of re-ID compared with all the two-step methods.\nIt is worth to note that the two-step person search framework trains the backbone network when training the detection and re-ID networks, respectively, and hence requires high computational complexity and huge memory space. In contrary, the proposed end-to-end method shares the backbone network between the jointly trained detection and re-ID networks, and is a more promising tool for LPS considering practical real-world applications."}, {"title": "D. Ablation Study", "content": "1) Losses: In Table III, we first evaluate the effect of the three losses, the detection knowledge distillation loss $L_{dkd}$, the re-ID knowledge distillation loss $L_{rkd}$, and the rehearsal-based instance matching loss $L_{rim}$, respectively. Note that detaching all the losses is the same as the FineTune method since the proposed losses are designed to work only when the old data are available. We see that adding each loss improves the performance, respectively. Specifically, when we use $L_{dkd}$, the detection performance is largely increased from that of the FineTune method on the old datasets, and the re-ID performance is also increased accordingly. On the other hand, $L_{rkd}$ and $L_{rim}$ slightly increase the detection performance of using $L_{dkd}$, but significantly improve the re-ID performance on the old datasets of CUHK-SYSU and PRW by huge margins, demonstrating the effectiveness to preserve the re-ID knowledge in the old domains.\n2) Baseline Network: It is worth to note that the proposed method can be applied to any baseline network of person search. We conducted the additional experiment by implementing the proposed method on the transformer based architecture of COAT [13]. Table IV shows the results where we see that the proposed method significantly improves the performance compared to that of the FineTune method.\n3) Old Prototype-Based Knowledge Distillation: Table V shows the effect of using the old prototype features for re-ID knowledge distillation. The conventional method, Intra-batch, estimates the distributions of the feature similarity with respect to all the detected proposals within a mini-batch. On the other hand, the proposed method matches the distributions of the feature similarity by using the prototype features of all identities stored in the old LUT, and thus provides better results than the Intra-batch scheme."}, {"title": "E. Limitation", "content": "4) Exemplar Data Sampling: Table VI shows the results of using different sampling schemes to compose the exemplar data from the old datasets. 'Max BBox' samples the images that have the top 2% largest numbers of ground truth bounding boxes. 'Max ID' samples the images that have the top 2% largest numbers of person instances with identity labels. 'Random' samples 2% images randomly from the old datasets. We see that different sampling schemes provide similar performances to one another, and selected the uniform sampling that yields a slightly better performance of the old knowledge preservation compared to the other ones.\nThe proposed method stores 2% of the old data into the exem- plar memory the typical rehearsal (replay) based methodology of lifelong learning [17], [19], [41], [51]. Therefore, the size of the exemplar memory increases as we have more and more datasets. As a future research topic, we will investigate other"}, {"title": "V. CONCLUSION", "content": "In this paper, we proposed a novel LPS framework where the model needs to be incrementally trained on the new datasets while preserving the knowledge of the old datasets. We implemented the knowledge distillation between the old and new models based on the rehearsal methodology by using the representative prototype features of the labeled foreground persons as well as the hard background proposals in the old exemplar data. We also designed the rehearsal-based instance matching loss to improve the discrimination ability by using the unlabeled person instances in addition to the prototype features. Experimental results evaluated on three datasets of person search showed that the proposed method achieves significantly better performance of lifelong learning compared with the existing methods, and successfully prevents the knowledge forgetting in the old domains. We expect this pioneering work would encourage further research for practical LPS applications."}]}