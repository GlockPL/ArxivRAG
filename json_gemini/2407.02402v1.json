{"title": "Assessing the Code Clone Detection Capability of Large Language Models", "authors": ["Zixian Zhang", "Takfarinas Saber"], "abstract": "This study aims to assess the performance of two advanced Large Language Models (LLMs), GPT-3.5 and GPT-4, in the task of code clone detection. The evaluation involves testing the models on a variety of code pairs of different clone types and levels of similarity, sourced from two datasets: BigCloneBench (human-made) and GPTCloneBench (LLM-generated). Findings from the study indicate that GPT-4 consistently surpasses GPT-3.5 across all clone types. A correlation was observed between the GPTs' accuracy at identifying code clones and code similarity, with both GPT models exhibiting low effectiveness in detecting the most complex Type-4 code clones. Additionally, GPT models demonstrate a higher performance identifying code clones in LLM-generated code compared to humans-generated code. However, they do not reach impressive accuracy. These results emphasize the imperative for ongoing enhancements in LLM capabilities, particularly in the recognition of code clones and in mitigating their predisposition towards self-generated code clones-which is likely to become an issue as software engineers are more numerous to leverage LLM-enabled code generation and code refactoring tools.", "sections": [{"title": "1 Introduction", "content": "The detection of code clones as well as the assessment of code similarity hold considerable importance in the field of software engineering. Identifying and managing code clones is crucial for maintaining code quality and integrity [10]. It aids in reducing redundancy, preventing bugs, and ensuring consistency across the codebase. Furthermore, the assessment of code similarity helps detect code leaks/plagiarism [4, 14] and improve automatic code generation [32\u201334]. Extensive research efforts have been dedicated to code clone detection methodologies over the decades. Despite these efforts, identifying semantic clones-code pairs characterized by low textual similarity-remains a big challenge.\nIn the wake of artificial intelligence (AI) revolution, scholars have sought solutions through AI-based methods. Increasingly, Machine Learning (ML) and Deep Learning (DL) techniques have been harnessed to unearth code snippets bearing semantic or syntactic similarities, utilizing tools such as Convolutional Neural networks (CNNs) [21, 30], Recurrent Neural Networks (RNNs) [40], Graph Neural Networks (GNNs) [8, 22], and transformers [41]. Nonetheless, there have been no studies that specifically explore the application of Large Language Models (LLMs) in detecting code clones.\nRecent years have witnessed a rapid advancement in the field of Large Language Models (LLMs), characterized by their increasing complexity and capabilities. This evolution led to a wide range of new applications in various domains including healthcare [15, 23], machine translation [17, 42], and recommendation systems [9, 36]. In comparison to other domains addressed by LLMs, software engineering presents a unique set of challenges. The precision required in coding, coupled with the necessity for logical consistency, error-free execution, performance, quality, maintainability, and evolution, makes software engineering a significantly more complex domain for LLMs.\nSeveral studies have investigated the performance of LLMs in some aspects of software engineering. These studies have endeavored to explore and evaluate the efficacy of LLMs in understanding and generating code [11, 24, 35], generation of code documentation [20] or repairing code [19]. To the best of our knowledge, the study by Wang et al. [37] is the only to evaluate the performance of LLMs on code clone detection. However, this study is limited to ChatGPT, and does not explore diverse types of code clones or multiple sources of datasets (including real-world code clones and clones generated by the GPT model itself).\nTo fill this gap, in this paper, we aim to systematically evaluate the capabilities of two LLM models (i.e., GPT-3.5 and GPT-4) in identifying code clones. Furthermore, as Integrated Development Environments (IDEs) become integrated with LLM tools (e.g., GPT-4 and Microsoft Copilot) and software engineers are more numerous to leverage their capabilities for various software engineering tasks (e.g., code generation and refactoring), we would like to assess whether there is a difference between the performance of LLM models at identifying human-generated code clones in comparison to LLM-generated code clones.\nOur paper aims at answering the following Research Questions (RQs):\n\u2022 RQ1: How does the performance of GPT-3.5 compare to the performance of GPT-4 across various code clone types and code similarity levels?\n\u2022 RQ2: Do GPT models exhibit different performances when assessing human-generated versus LLM-generated code clones? If so, how do these differences manifest between GPT-3.5 and GPT-4?\nThe rest of the paper is organized as follows. Section 2 summarises the background of our study. Section 3 describes the approaches we used to select data and design GPT prompt. In Section 4, we analyze the performance of GPT through the data we selected. Finally, Section 5 concludes the paper."}, {"title": "2 Background", "content": "In this section, we describe the background of our study in two parts: Code Clones and Generative Pretrained Transformers."}, {"title": "2.1 Code Clones", "content": "A sequence of source code is known as a code fragment that is identical or very similar to another code fragment, this pair is known as clone pairs. These pairs are similar in terms of functionality, structure, or both. These pairs can be found within the same file, across different files in a single project, or even across projects. There are various clone types based on clone pair similarity. We use the definition of clones which has been widely accepted by many scholars [28]:\n\u2022 Type-1 (T1): syntactically identical code segments, with the exception of variations in whitespace, layout, and comments [5].\n\u2022 Type-2 (T2): syntactically identical code segments, with the sole distinctions being in identifier names and literal values, alongside the variances characteristic of Type-1 clones, such as those in whitespace, layout, and comments [5].\n\u2022 Type-3 (T3): syntactically similar code segments, exhibiting differences at the statement level. These segments demonstrate variations wherein statements are added, modified, and/or removed in relation to each other, in addition to the distinctions present in both Type-1 and Type-2 clones, such as disparities in whitespace, layout, comments, identifier names, and literal values [27].\n\u2022 Type-4 (T4): while syntactically dissimilar, code segments implement identical functionality [27].\nBasically, the definition of Type-1 clone and Type-2 clone, known as syntactic code clones, are pretty clear, grounded in the textual similarity of code fragments. This phenomenon is commonly observed in practices involving copying and pasting. Conversely, the classification of Type-3 and Type-4 clones, also referred to as semantic code clones, is always controversial. Distinct from syntactic clones, which are identified based on textual similarity, semantic clones may exhibit similar functionality but are often implemented using diverse syntactic structures.\nIn this study, we adopt the categorization framework of BigCloneBench (BCB) for code clones, which is predicated on their percentage of similarity. Clones are classified as Very-Strongly Type-3 (VST3) when they exhibit a similarity ranging from 90% (inclusive) to 100%. Clones falling within the 70-90% similarity bracket are categorized as Strongly Type-3 (ST3), those within 50-70% as Moderately Type-3 (MT3), and clones with a similarity percentage between 0-50% are designated as Weakly Type-3 or Type-4 (WT3/4)."}, {"title": "2.2 Generative Pretrained Transformers (GPTs)", "content": "With the success of Transformer-based LLMs, the field of natural language processing (NLP) has witnessed remarkable achievements. Brown et al. [6] introduce the GPT-3.5 model, this model, boasting 175 billion parameters, demonstrated the potential of scaling up parameters in auto-regressive language models for improved performance across a variety of NLP tasks."}, {"title": "3 Approach", "content": "In this section we describe our proposed approach to evaluate the performance of LLM models at identifying code clones in two parts: Code Clone Dataset, and GPT Prompt Engineering."}, {"title": "3.1 Datasets", "content": "In our study, we use two particular datasets: (i) Big-CloneBench is the most used in the literature and combines human-engineered code clones, and (ii) a new dataset that combines GPT-engineered code clones."}, {"title": "3.1.1 BigCloneBench [31]", "content": "A widely-used clone detection benchmark in code clone detection tasks. It is a comprehensive collection of 8 million validated clones within IJaDataset-2.0 [16], a repository containing 25,000 open-source Java systems. This benchmark covers both intra-project and inter-project clones across four primary clone types, spanning the entire range of clone syntactical similarity."}, {"title": "3.1.2 GPTCloneBench [3]", "content": "A comprehensive benchmark designed to evaluate semantic and cross-language code clones using GPT-3.5 [6] and SemanticCloneBench [2]. GPTCloneBench leverages GPT-3.5's capabilities to generate semantic and cross-language clones from code fragments in SemanticCloneBench. GPTCloneBench includes several true semantic clone pairs, false semantic pairs, and cross-language clones across four programming languages (Java, C, C#, and Python)."}, {"title": "3.1.3 Data Selection", "content": "To maximize the efficiency of evaluating GPT models' performance in code clone detection while minimizing experimental costs (specifically, the usage of API tokens), we have implemented a meticulous clone selection process before their analysis with GPT models. Within the constraints of our budget, we chose 300 samples for input into the GPT models for each dataset and clone type. For the BCB dataset, which comprises multiple open-source Java repositories and contains numerous replicated code clones, our initial step involves filtering out these replicated clones to ensure the uniqueness of the code clones submitted to the GPT models. Subsequently, for each clone type, we endeavor to maintain representative code pairs with diverse similarities across the 300 code pairs, aiming for a balanced representation of clone variations.\nIn the case of GPTCloneBench, which serves as a benchmark for comparing the performance of GPT models between LLM-generated and human-made code clones, we employ the same selection process as with BCB. Following this, for each clone type within GPT-CloneBench, we choose 300 samples to align the code size distribution for each clone type group as closely as possible with the code size distribution of the corresponding clone type in the selected samples from the BCB dataset.\nThe details of the selected data are presented in Table 1. Owing to the scarcity of clone types T1, T2, VST3, and ST3 in the GPTCloneBench dataset, our selection was limited to 300 samples each for MT3 and WT3/T4 types from this dataset. Additionally, it is important to note that both datasets are devoid of negative samples, which are non-clone pairs. Consequently, this study solely encompasses positive samples, necessitating the use of True Positive, False Negative, and Recall as the primary evaluation metrics."}, {"title": "3.1.4 Selected Data Profile", "content": "The distribution of code similarity for clone types WT3/T4, MT3, ST3, and VST3 in the selected data from BCB is illustrated in Figure 1. This figure reveals that the data selected from BCB for these types contains diverse similarities, signifying that the selected data is apt for reflecting GPT models' performance across a diverse range of code pair similarities.\nThe Program size distributions for the data selected from BCB and GPTCloneBench are depicted in Figure 2."}, {"title": "3.2 GPT Prompt Engineering", "content": "A clear and accurate prompt is essential in the execution of natural language processing tasks. A prompt constitutes a set of input instructions or guidelines aimed at eliciting a specific output or accomplishing a particular task. It may take the form of a question, a statement, or an instruction. Prompts play a pivotal role in facilitating interaction with LLMs, thereby aiding in achieving the intended outcome from the model's response.\nThere exist various techniques to define prompts, (e.g., zero-shot [26, 39], one-shot [13], few-shot [12], chain of thought [38], self-improving [7], or analogy-based [18]). Zero-shot employs direct instructions without the need for pre-training data or prior knowledge input. One-shot enables a model to perform tasks based on a single example. Few-shot trains a model using only a handful of examples for new tasks. Chain of thought prompts encourage models to detail their reasoning step by step. Self-improving prompts guide models to critique and enhance their outputs over time. Analogy-based prompts help models solve problems by drawing comparisons to familiar scenarios. Various prompt techniques are suitable for different situations. The selection of a prompt can substantially influence the performance of the model."}, {"title": "3.2.1 Impractical One-Shot Prompt", "content": "We first analyzed the feasibility of a one-shot prompt using this prompt: \"Determine whether two provided code snippets are code clones. Output yes or no with no explanation.\u201d. We conducted a manual evaluation of the one-shot prompt technique using several code pair samples. Our findings indicate that the GPT models do not yield consistent results from this one-shot prompt approach, showing whether the model provides explanations for its judgment or exhibits misunderstandings regarding code clones."}, {"title": "3.2.2 Selecting Few-Shot Prompt", "content": "We shifted our approach to a few-shot prompt technique to accurately assess and contrast the performance of the GPT models. Specifically, we constructed our prompt with simple instructions, an input sample, and definitions of code clones to direct GPT models in determining whether a given code pair is a clone or not. Figure 3 shows an example of the creation of the prompt with a code pair. The prompt is segmented into three distinct parts. The first section comprises the main instruction, which outlines the basic task description and provides a definition of code clones to the GPT model. The second section offers an example, supplying GPT with a sample input and its corresponding output. The final section poses a query to the GPT model, featuring two code snippets labeled with numbers and colons, requesting the GPT to render a determination on whether the specified code pair is a clone. By employing multiple code pair samples, we find that this few-shot prompt yields stable and expected results from the GPT model."}, {"title": "4 Results", "content": "In this section, we answer the two research questions defined in Section 1 based on our experimental analysis."}, {"title": "4.1 LLM Performance at Detecting Clone Clones", "content": "In our initial comparison of code clone detection performance between GPT-3.5 and GPT-4, we focused on the distributions of true positive and false negative answers across four different Clone Types, utilizing data selected from BCB. The findings are presented in Table 2. For clone Type T1, both GPT-3.5 and GPT-4 achieved a 100% rate of true positives with zero false negatives, demonstrating their proficiency in recognizing Type-1 clones. In the case of clone Type T2, GPT-3.5 exhibited a lower recall of 0.56 in contrast to GPT-4, which achieved 0.86, indicating a notably higher success rate for GPT-4 with this clone type.\nFor the more semantically complex clone types, VST3, ST3, and MT3, the performance of the GPT-3.5 model declined progressively, with recall generally falling below 0.50. Conversely, the GPT-4 model displayed significantly superior performance, with all recalls exceeding 0.85. For clone Type-4, characterized by pair similarities of less than 50%, both models showed relatively low performance levels; however, GPT-4 still outperformed GPT-3.5 with a recall of 0.23."}, {"title": "Difference Between Human-Made and LLM-Generated Code Clones", "content": "Table 3 presents the comparative analysis results from different data sources across various clone types (MT3 and WT3/T4) and GPT models (GPT-3.5 and GPT-4). The data sources in question include BCB, which consists of human-generated clones, and GPTCloneBench, comprising LLM-generated clones. The results demonstrate that the LLM-generated GPTCloneBench yields superior performance in terms of higher recall rates compared to the human-generated BCB data across both clone types. This suggests that GPT models exhibit enhanced proficiency in recognizing code clones that they themselves have generated, as opposed to real-world code clones. Nonetheless, for GPT-4, the difference in performance between BCB and GPTCloneBench is less marked in recognizing MT3 code clones, indicating its robustness in clone detection across sources.\nDespite the disparities in evaluation data, we have documented the performance metrics of learning-based code clone detection algorithms for comparison. For reference, existing code clone detection techniques achieve recall rates of 0.94 and 0.45 for clone Type-4 on the BCB [41] and GPTCloneBench [29] datasets, respectively. These references provide further evidence of a bias within GPT models towards more accurately identifying code clones that they themselves have generated, as opposed to recognizing clones originating from real-world scenarios.\nAnswer to RQ2: The findings indicate that both models perform better on LLM-generated clones compared to human-generated clones, with GPT-4 showing less performance difference between the two sources, suggesting its robustness in clone detection across sources."}, {"title": "5 Conclusion and Future work", "content": "While several advanced ML techniques have been proposed to detect code clones, no work has, so far, employed LLMs for that purpose. In this study, we explored the capabilities of GPT-3.5 and GPT-4 in detecting code clones, utilizing datasets of both human-made and LLM-generated clones.\nOur experiments show a superior performance GPT-4 over GPT-3.5 regardless of clone types and data sources. Notably, both models demonstrated lower effectiveness in identifying semantic (Type-4) clones, which presents a higher challenge in enabling LLMs to grasp semantic information in code. Additionally, LLM-generated clones were detected with greater accuracy compared to human-made clones, suggesting an intrinsic model bias toward recognizing familiar patterns.\nIn our future work, we will implement an evaluation on a larger scale, with a higher amounts of code clones and a variety of programming languages within open-source LLMs to get rid of budget constraints. Furthermore, we plan to compare the performance of LLMs with other state-of-art code clone detection tolls, as well as traditional code clone detection tools, to provide a comprehensive analysis of LLM's performance in code clone detection tasks."}]}