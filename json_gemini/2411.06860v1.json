{"title": "Enhancing Phishing Detection through Feature Importance Analysis and Explainable AI: A Comparative Study of CatBoost, XGBoost, and EBM Models", "authors": ["Abdullah Fajar", "Setiadi Yazid", "Indra Budi"], "abstract": "Phishing attacks remain a persistent threat to online security, demanding robust detection methods. This study investigates the use of machine learning to identify phishing URLs, emphasizing the crucial role of feature selection and model interpretability for improved performance. Employing Recursive Feature Elimination, the research pinpointed key features like \"length_url,\" \"time_domain_activation\" and \"Page_rank\" as strong indicators of phishing attempts. The study evaluated various algorithms, including CatBoost, XGBoost, and Explainable Boosting Machine, assessing their robustness and scalability. XGBoost emerged as highly efficient in terms of runtime, making it well-suited for large datasets. CatBoost, on the other hand, demonstrated resilience by maintaining high accuracy even with reduced features. To enhance transparency and trustworthiness, Explainable AI techniques, such as SHAP, were employed to provide insights into feature importance. The study's findings highlight that effective feature selection and model interpretability can significantly bolster phishing detection systems, paving the way for more efficient and adaptable defenses against evolving cyber threats.", "sections": [{"title": "1. INTRODUCTION", "content": "Phishing remains a significant cybersecurity threat that targets individuals and organizations by attempting to obtain sensitive information through deceptive means, such as fake websites, emails, or messages. Traditional signature-based detection methods are often inadequate in identifying newly created phishing sites, which constantly evolve to bypass detection. This limitation has prompted the need for machine learning-based approaches that can analyze and predict phishing attempts by examining various features of websites in real time [1], [2]. Machine learning models, when equipped with relevant features, have the potential to effectively predict phishing cases. However, the primary challenge lies in selecting the most relevant features to maximize detection accuracy while maintaining computational efficiency[3], [4].\nFeature selection plays a crucial role in building high- performance classification models, as it reduces the dimensionality of the dataset, minimizes overfitting, and enhances model efficiency without compromising accuracy[5]. Various feature selection techniques, such as Information Gain, TreeSHAP, and Principal Components Optimization, have been employed to identify the most significant features[6], [7]. Despite their effectiveness, there is no consensus on the best approach for feature selection in phishing detection, as the impact of each technique varies depending on the dataset and context.\nPhishing attacks utilize a range of deceptive techniques, including email spoofing, DNS spoofing, and social engineering, making them challenging to detect and counter. The increasing sophistication of these attacks necessitates the development of robust and adaptive detection methods. Recent studies have shown that machine learning algorithms, such as Random Forest, Naive Bayes, and XGBoost, are effective in detecting phishing websites. However, the performance of these models is highly dependent on the quality and relevance of the features selected from the dataset[8], [9].\nThe problem statement of this research revolves around the escalating threat of phishing attacks and the inadequacy of traditional detection methods to identify newly created phishing websites, commonly known as zero-day attacks. Traditional signature-based approaches are often ineffective against zero-day phishing attacks, leaving users vulnerable. Therefore, the challenge is to develop machine learning-based methods that can accurately and efficiently detect phishing websites by selecting the most relevant features from large and complex datasets.. This study addresses the following key research questions:\n1. How can feature selection methods reduce the number of features while improving the efficiency and accuracy of machine learning models in detecting phishing websites?\n2. Which machine learning algorithms perform best in phishing detection when combined with effective feature selection techniques?\n3. How can Explainable AI (XAI) methods be used to clearly identify the most influential features in phishing detection and provide a better understanding of their impact on the model's predictions?"}, {"title": "2. CONCEPTUAL REVIEW", "content": "2.1 Feature Selection in Phishing Detection\nThe features of the datasets that play an important role in the performance of phishing detection models include:\n1. URL-based Features: These features are derived from the characteristics of the URL itself. Examples include the length of the URL, the presence of an IP address, the use of HTTPS, and the presence of suspicious keywords. URL-based features are crucial because they can be quickly analyzed and are not dependent on the content of the webpage, making them suitable for real-time detection[2], [5]\n2. Content-based Features: These features involve an in-depth analysis of the webpage content, such as the presence of certain HTML tags, JavaScript functions, and the structure of the webpage. Content-based features help in identifying phishing websites that mimic legitimate ones by analyzing the actual content presented to the user[2], [5].\n3. External-based Features:These features rely on third-party services such as WHOIS information, search engine indexing, and page rank. They provide additional context about the legitimacy of the website by checking its registration details, popularity, and indexing status. External-based features are useful for cross-verifying the authenticity of a website [5].\nFeature selection plays a crucial role in improving phishing detection using machine learning. It helps identify the most relevant features, reducing model complexity and training time while maintaining or enhancing accuracy [1], [3]. Various feature selection techniques have been employed, including correlation-based methods, wrapper techniques, and ranking algorithms like Information Gain and TreeSHAP [5], [8]. Studies have shown that feature selection can significantly improve classification accuracies for algorithms such as Random Forest, Na\u00efve Bayes, and Neural Networks [2], [4]. However, the effectiveness of feature selection methods may vary depending on the dataset and chosen algorithms [9]. While feature selection enhances efficiency and accuracy, it's important to note that some approaches may still struggle with detecting zero-day phishing attacks [7]. Overall, feature selection is essential for developing efficient and effective phishing detection models.\nSeveral gaps are identified in the research on phishing detection using machine learning and feature selection techniques:\n1. Feature Selection Optimization: [2] highlights the need for effective feature selection techniques to improve classification accuracy. The study compares two feature selection methods, FSOR and FSFM, and finds that optimized feature selection can significantly enhance performance, but there is still room for improvement in reducing processing time and increasing accuracy. [6] proposes a new feature selection framework, HEFS, which shows promising results but still requires further validation and comparison with other datasets to confirm its effectiveness.\n2. Dataset Variability: Different studies use different datasets, which makes it challenging to compare results directly. For example, [1] and [2] use the UCI Phishing Websites dataset, while [5] uses ISCX-URL-2016 and another public dataset. This variability in datasets can lead to inconsistent performance metrics and hinders the generalizability of findings.\n3. Algorithm Performance: Different machine learning algorithms are tested across studies, but there is no consensus on the best-performing algorithm. [1], [4] find Random Forest to be the most effective, while [5] reports high performance with XGBoost. This discrepancy indicates a need for more extensive comparative studies to identify the most robust algorithms for phishing detection. [10] [11] both emphasize the importance of comparing different machine learning algorithms to find the most effective one for phishing detection. However, there is a need for more comprehensive comparisons involving a wider range of algorithms and datasets. [12] compares multiple algorithms but suggests that combining existing solutions like blacklisting, whitelisting, and heuristic methods could provide higher security, indicating a gap in integrating multiple approaches effectively.\n4. Hybrid Approaches: While some studies, like Zamir et al., (2020), explore hybrid models combining multiple algorithms, this approach is not widely adopted. There is potential for further research into hybrid models that leverage the strengths of different algorithms to improve detection accuracy and robustness. [10], [11] both emphasize the importance of comparing different machine learning algorithms to find the most effective one for phishing detection. However, there is a need for more comprehensive comparisons involving a wider range of algorithms and datasets. [12] compares multiple algorithms but suggests that combining existing solutions like blacklisting, whitelisting, and heuristic methods could provide higher security, indicating a gap in integrating multiple approaches effectively.\nAddressing these gaps could lead to more effective and universally applicable phishing detection systems"}, {"title": "2.2 URL and HTML Feature in Web Phishing Detection", "content": "Several studies highlight the importance of URL-based features, such as the presence of suspicious characters, domain age, and IP address information. Moreover, incorporating HTML features, such as hidden text and form action URLs, has been shown to further enhance detection accuracy, thereby underscoring the multifaceted approach necessary for effective phishing detection strategies across diverse datasets[13], [14] Additionally, the integration of machine learning algorithms with these feature sets significantly improves the overall detection capabilities, as evidenced by findings that report accuracy rates exceeding 96% when utilizing a combination of both URL and HTML features in phishing detection efforts [15]. Furthermore, studies indicate that the incorporation of advanced techniques, such as deep learning models, alongside traditional feature sets can lead to even higher detection rates, emphasizing the need for continuous innovation in phishing prevention methods to stay ahead of evolving threats in the digital landscape[13], [14], [15], [16]. This indicates that as phishing techniques become more sophisticated, the application of both established and emerging technologies in feature analysis is paramount in crafting resilient defenses against such attacks [15], [16]. Moreover, the effectiveness of using a blend of machine learning algorithms and comprehensive feature sets reflects the ongoing evolution of strategies required to combat phishing effectively, as recent studies demonstrate that leveraging URL and HTML features together leads to significant improvements in detection performance and reliability, making them a crucial component of robust phishing mitigation systems."}, {"title": "2.3 Summary of Feature Importance", "content": "While feature importance analysis offers valuable insights into the factors contributing to phishing detection, it is essential to recognize its limitations and potential drawbacks. Relying solely on feature importance as the primary metric for model evaluation and deployment can lead to an oversimplified understanding of model performance, potentially overlooking other critical aspects such as robustness, generalizability, and adaptability.[17]\nFeature importance, by its nature, provides a static snapshot of the model's decision-making process, failing to capture the dynamic and context-dependent nature of phishing attacks. Phishing tactics are continuously evolving, and what may be deemed an influential feature today may become obsolete or even adversarial in the future. Over-emphasis on feature importance could result in the development of brittle models that struggle to adapt to emerging threat patterns, undermining their long-term effectiveness in real-world deployment scenarios [18], [19].\nMoreover, feature importance analysis may be susceptible to biases, particularly in complex, high-dimensional datasets commonly encountered in phishing detection. Certain features may appear highly influential due to spurious correlations or the model's inability to capture the underlying causal relationships. This could lead to the prioritization of features that are not genuinely indicative of phishing behavior, potentially compromising the model's reliability and contributing to false positives or missed detections.[14], [20]\nTo address these concerns, a more comprehensive and balanced approach to model evaluation and deployment is essential. While feature importance remains a valuable metric, it should be considered in conjunction with other performance indicators, such as robustness, generalization, and interpretability. By adopting a multi-faceted evaluation framework, researchers and practitioners can develop detection systems that not only excel in identifying known phishing threats but also maintain their effectiveness in the face of evolving attack vectors, fostering trust and confidence among end-users[21], [22].\nFeature importance analysis is a crucial component in developing effective phishing detection models. It provides insights into the key factors contributing to accurate identification of phishing attempts, enabling the refinement of feature sets, targeted detection mechanisms, and enhanced user awareness. By understanding the most influential features, researchers and security professionals can focus on the relevant indicators of phishing behavior, improving the overall performance of detection systems and reducing false positives. [16], [23] However, overreliance on feature importance alone can lead to oversimplified models that struggle to adapt to evolving threats. A comprehensive, multi- faceted evaluation framework, incorporating robustness, generalizability, and interpretability, is essential to craft resilient and trustworthy phishing detection solutions. The synthesis of feature importance analysis and advanced techniques, such as \u03a7\u0391\u0399, can further enhance the understanding of feature interactions and foster the development of innovative, targeted approaches to combat the dynamic threat of phishing attacks.[24], [25], [26]\nIn summary, the extraction and analysis of feature importance in phishing detection models serve as a crucial tool in the continuous effort to combat the growing threat of phishing attacks, empowering researchers, security professionals, and end-users with the knowledge necessary to develop and implement more robust and responsive defense mechanisms. Moreover, understanding which features most significantly impact phishing detection allows for targeted improvements in both algorithm design and user education strategies, ultimately leading to a more informed and secure online environment [24], [27]. In this context, a synthesis of both theoretical insights and practical applications is essential to craft an effective response to evolving phishing threats, thereby enhancing the resilience of detection systems and user awareness initiatives.."}, {"title": "2.4 XAI Technique in Feature Importance Analysis", "content": "Applying Explainable Artificial Intelligence (XAI) techniques to enhance cybersecurity, particularly in phishing and malware detection intent to fulfilled lack of explainability in AI-based malware detection systems, which prevents their application in real-world scenarios. Popular XAI methods include SHAP, LIME, LRP, and attention mechanisms for explaining AI- based malware detection systems [28], [29]. For phishing detection, studies have explored using Explainable Boosting Machine [30], glass box models [31], and visual explanations [32], [33]. These approaches aim to improve user awareness, trust, and decision-making in cybersecurity contexts.\nHowever, some research suggests that certain XAI methods may have unintended negative impacts on overall system performance [34]. In malware detection, CNN-based models with LRP have shown promise for Linux systems. Overall, XAI in cybersecurity presents both opportunities for improved defenses and potential vulnerabilities to adversarial attacks[35].\nIn case phishing detection it is important to identify the most features that influence phishing behavior. Research on feature importance extraction with XAI in phishing detection has shown promising results. Machine learning models using feature selection techniques have achieved high accuracy in detecting phishing websites[3], [36]. Novel approaches like Lorenz Zonoids for feature selection have been proposed to enhance model interpretability[3]. XAI methods have been applied to explain phishing detection results, improving user awareness and trust [30], [33]. Studies have explored various feature extraction and selection techniques, including Chi- Square, Information Gain Ratio, PCA, and LSA, to improve classification performance [37]. Automated feature extraction tools have been developed to identify important characteristics of phishing websites [38]. These advancements in XAI and feature importance extraction contribute to more effective and interpretable phishing detection systems, enhancing cybersecurity efforts [31]."}, {"title": "3. METHODOLOGY", "content": "The methodologies to address the research questions involve\n1. Datasets collected and load from the UCI Phishing Websites, Kaggle and Mendeley Data are collected with various number of instances and features. A high-quality dataset that collected should be clean, representative, diverse, and well-labeled, with relevant and well-distributed features.\n2. Several datasets have an issue regarding imbalance class label distribution. An ideal distribution should be 50% of each class label. This work employs SMOTE technique to overcome this issue.\n3. Before Feature Selection process, initial modelling carried out to resume selection of subset features.\n4. Feature selection is essential for building efficient, interpretable, and accurate machine learning models. It reduces complexity, enhances performance, prevents overfitting, and makes models easier to explain. By carefully selecting the most relevant features, the model becomes not only faster and more reliable but also more focused on the most important patterns in the data. One of popular approaches such Recursive Feature Elimination employed at his work.\n5. Model Training and Evaluation is executed using selected features and several most suitable algorithms to result best performance. The model is evaluated using the test set and appropriate metrics, such as accuracy or F1-score, depending on the task. Models are evaluated based on accuracy, precision, recall, and processing time, with comparative analysis to identify the best-performing methods\n6. Feature Importance Analysis: Feature importance analysis using Explainable AI (XAI) is a powerful approach for understanding which features contribute the most to a machine learning model's predictions. XAI techniques such as SHAP (Shapley Additive Explanations) or LIME (Local Interpretable Model-agnostic Explanations) allow us to quantify the influence of each feature, either globally across all predictions or locally for specific instances. By analyzing feature importance, we gain insight into how the model makes decisions, identifying key drivers that affect the outcome. This is crucial for domains phishing detection, where understanding the reasoning behind predictions is as important as accuracy. XAI methods ensure transparency, enabling practitioners to detect biases, validate model behavior, and improve trust in machine learning systems by providing interpretable and actionable explanations of the model's decisions."}, {"title": "4. RESULT AND ANALYSIS", "content": "4.1 Dataset Evaluation\nDataset came from various sources and characteristics, such as describe below:"}, {"title": "4.2 Selected Featured", "content": "URL-based features have the most features in the datasets as table1 shown. Then Content-based and External-based features lesser than the URL-based Features. Selected Features may re-groups into several groups for phishing detection as follow:\n1. URL and Domain Structure: Features like qty_slash_url, length_url, and qty_dot_domain measure URL and domain characteristics, such as the number of slashes or dots, which can indicate suspicious domains.\n2. Directory and File Characteristics: Features such as directory_length and file_length assess the structure of directories and files in URLs. Long or complex directories can be a sign of phishing.\n3. Time and Certificate Information: Features like time_response and tls_ssl_certificate evaluate time-related characteristics and SSL certificate details. Short domain activation times or imminent expirations can signal phishing.\n4. IP and Nameserver Details: Features such as qty_ip_resolved and qty_nameservers measure the number of IP addresses and nameservers. Phishing sites often have unusual or minimal IP and nameserver information.\nBased on the frequency analysis of the selected features from various datasets above, the top 10 most frequently appearing features are:\n1. length_url: Appears 4 times\n2. qty_slash_url: Appears 2 times\n3. time_domain_activation: Appears 2 times\n4. web_traffic: Appears 2 times\n5. qty_redirects: Appears 2 times\n6. ttl_hostname: Appears 2 times\n7. qty_mx_servers: Appears 2 times\n8. qty_nameservers: Appears 2 times\n9. qty_ip_resolved: Appears 2 times\n10. time_domain_expiration: Appears 2 times\nThe feature length_url is the most frequently appearing, indicating that URL length is a crucial indicator in phishing detection. Other frequently appearing features like qty_slash_url, time_domain_activation, and web_traffic are also important, especially for examining URL characteristics and domain information."}, {"title": "4.3 Performance Analysis", "content": "This works employs two approaches for modelling such as black box modelling and white box modelling. Black box modelling means that the algorithm has no appropriate explanation how decision made to predict the label and explain what features influence to label prediction. In other hand white box modelling has several capabilities to explain how the model works. Three algorithms such as Random Forest, XGBoost and CatBoost represent as black box modelling approaches and EBM represent as white box modelling approaches. Hereby the performance resume of each models:\n1. CatBoost Model. Using this algorithm, A dataset with more features does not always yield the best accuracy. For instance, ds_235795_54 achieved 100% accuracy with fewer features and a smaller dataset. Selecting fewer features can maintain high accuracy, as shown by ds_11055_32 with 96.8% accuracy using only 10 features. Runtime generally increases with the number of features and instances in a dataset, but this does not always correlate directly with model accuracy. Here the result\n2. Random Forest. There is no direct correlation between the number of features used in a Random Forest model and its accuracy. For example, the dataset \"ds_235795_54\" achieved 100% accuracy using only 12 features, while \"ds_129K112,\" despite utilizing 50 features, achieved 99% accuracy. While execution time generally increases with a higher number of features and larger datasets, optimizing feature selection can reduce runtime without significantly impacting accuracy. Larger datasets like \"ds_129K112\" and \"ds_88K112\" have longer execution times but generally yield good accuracy. Therefore, carefully selecting the optimal number of features is essential to strike a balance between model accuracy and execution time in Random Forest models..\n3. XGBoost. The relationship between the number of features used in an XGBoost model and its accuracy or execution time is not straightforward. While larger datasets or those with more features might be assumed to yield higher accuracy, this is not always the case. For instance, the dataset \"ds_235795_54\" achieved 99.6% accuracy using only one feature. Conversely, \"ds_10K75,\" despite utilizing 21 features, only reached 90% accuracy. Execution time is generally lower for smaller datasets or those with fewer features. This is evident in datasets like \"ds_10K50\" and \"ds_11055_32.\" Notably, smaller datasets like \"ds_11K89\" can achieve high accuracy (97%) with significantly reduced execution times. These findings underscore that achieving high accuracy with efficient execution times in XGBoost models hinges on identifying and selecting the most relevant features. In cases where a single dominant feature exists, as observed in \"ds_235795_54,\" using fewer features can maintain or even improve model accuracy.\nWhen comparing CatBoost, XGBoost, and Random Forest for accuracy and execution time efficiency, CatBoost consistently outperforms the other two algorithms in terms of accuracy across most datasets.\nHowever, when execution time is prioritized, XGBoost emerges as the most efficient, particularly for smaller datasets, demonstrating faster processing times compared to both CatBoost and Random Forest. Here's a concise summary:\na. Prioritize Accuracy: CatBoost is the optimal choice.\nb. Prioritize Execution Time: XGBoost is more efficient, especially for smaller datasets.\nc. Balance Accuracy and Runtime: CatBoost generally offers a more consistent balance between these two metrics.\nIn conclusion, CatBoost presents a compelling combination of high accuracy and reasonable runtime efficiency, while XGBoost excels in minimizing execution time.\n4. EBM. The number of features used in an EBM model doesn't necessarily dictate its accuracy or execution time. For example, the \"ds_235795_54\" dataset achieved perfect accuracy (100%) with 17 features. In contrast, the \"ds_129K112\" dataset, despite utilizing 23 features, only reached 96.7% accuracy. Execution time for EBM models is heavily influenced by dataset size and the number of features. \"ds_129K112\" exhibited the longest execution time, even though it used only 23 features. Conversely, smaller datasets like \"ds 10K18\" and \"ds 11K89\" achieved high accuracy (97% and 97.7%, respectively) with significantly shorter execution times (57 and 34, respectively). These findings suggest that while EBM can achieve high accuracy with a substantial number of features, execution time increases with larger datasets. Therefore, to optimize EBM's efficiency, it's crucial to strike a balance between the number of features used and the desired runtime."}, {"title": "4.4 Feature Importance Analysis", "content": "Based on performance analysis, the Feature Importance Analysis focuses on two algorithms that have demonstrated the best robustness and scalability: XGBoost and CatBoost. The image is a SHAP (SHapley Additive explanations) summary plot, which visualizes the impact of various features on a model's output. Here's a detailed description:\n1. Axes:\n\u039f Horizontal Axis: Represents the SHAP value, indicating the impact of each feature on the model's output. Values to the left (negative) suggest a decrease in the model's prediction, while values to the right (positive) indicate an increase.\n\u039f Vertical Axis: Lists the features being analyzed\n2. Color Coding:\n\u039f The colors range from blue to pink, representing the feature values. Blue indicates lower feature values, while pink indicates higher feature values.\n3. Distribution of SHAP Values:\n\u039f Each feature has a distribution of SHAP values represented by dots along the horizontal axis. The spread of these dots shows how different values of each feature affect the model's predictions.\n4. Interpretation:\n\u039f Features show a wider spread, suggesting they have a more significant impact on the model's predictions.\n\u039f The plot helps identify which features are most influential and how their values correlate with the model's output, aiding in understanding the model's decision-making process.\n4.4.1 CatBoost SHAP Explanation\nHere the SHAP Explanation for CatBoost:\n1. Dataset 129K112 and 88K112\nThe figure above can be summarized as there are two features that are time_domain_activation and length_url shown most influential and clarity of color distribution to avoid label prediction bias.\n2. Dataset ds 235795 54\n\"URLSimilarityIndex\" in the figure above is the most influential feature rather than \"HasHiddenFields\" but feature value color distribution shown have bias. The color distribution shown is not well distributed between decrease or increase model prediction.\n3. Dataset ds 100K20\nThe feature URL_length is the most influential feature but still has potential bias whether higher or lower value in some interval my lead to increase or decrease label prediction.\n4. Dataset ds 11K89\nThe figure indicates \"Page_rank\" is the most important feature for predicting the label in the ds_100K20 dataset, it might still have some bias, similar to the \"url_length\" feature. On the other hand, \"google_index\" and \"nb_www\" show a clear separation in their feature value color distribution, suggesting they could be combined with \"page_rank\" for potentially better label prediction.\n5. Dataset ds 11055 32\nThe dataset result explanation as follow, The features \"URL of anchor\" and \"ssl final state\" have the biggest impact on predicting the label. However, it's not easy to tell from the color distribution of these features whether higher or lower values are more likely to be associated with a positive prediction.\n6. Dataset ds 10K75\nThe following explanation is derived from above figure, which \"URL_length\" appears to be the most important feature for predicting the label, but there's a potential bias. It's unclear whether a longer or shorter URL, within certain ranges, actually means a phishing attempt is more or less likely.\n7. Dataset ds 10K50\nThe feature PctExtNullSelfRedirectHyperlinksRT is the most influential feature but still has potential bias whether higher or lower value in some interval my lead to increase or decrease label prediction.\n8. Dataset ds 10K18\nThe feature URL_length is the most influential feature but still has potential bias whether higher or lower value in some interval my lead to increase or decrease label prediction."}, {"title": "4.4.2 XGBoost SHAP Explanation", "content": "Here the SHAP Explanation for XGBoost\n1. Dataset ds 129K112 and ds 88K112\nThe features tme_domain_activation and length_url is the most influential feature but still has potential bias whether higher or lower value in some interval my lead to increase or decrease label prediction.\n2. Dataset ds 235795 32\nThe figure highlights that a single feature, \"URLSimilarlyIndex,\" was selected during feature selection and is also identified as the most important feature for predicting the label. The author [39] provides further details and explanation regarding this finding.\n3. Dataset ds_100K20\nAs the figure below, although \"Page_rank\" is the most important factor for predicting the label in the ds_100K20 dataset, it may still have some bias, similar to the \"url_length\" feature. \"google_index\" and \"nb_www,\" on the other hand, have a clear color distribution for their feature values, implying that combining them with \"page_rank\" could improve label prediction accuracy.\n4. Dataset ds 11K89\n5. Dataset ds 11055 32\nThe SHAP figure visualize and highlights \"URL of anchor\" and \"ssl final state\" as the most important features for predicting the label. However, it's difficult to determine from the color distribution of these features whether higher or lower values are more likely to indicate phishing.\n6. Dataset ds 10K75"}, {"title": "5. Discussion And Findings", "content": "5.1 Discussion\nIn this part, discussion focuses to answer the following questions that previously state such as:\n1. How can feature selection methods reduce the number of features while improving the efficiency and accuracy of machine learning models in detecting phishing websites?\n2. Which machine learning algorithms perform best in phishing detection when combined with effective feature selection techniques?\n3. How can Explainable AI (XAI) methods be used to clearly identify the most influential features in phishing detection and provide a better understanding of their impact on the model's predictions?\nAnswer the first question, feature selection method that chosen is RFE or Recursive Feature Elimination. Recursive Feature Elimination (RFE) is a feature selection technique used to identify and select the most important features for a machine learning model. The goal of RFE is to select the subset of features that are most relevant and have the highest predictive power, thereby reducing the dimensionality of the dataset and potentially improving model performance.\nRFE is particularly useful when dealing with datasets that have many features, as it helps eliminate less important or redundant features, which can reduce overfitting and improve interpretability. RFE works with any estimator that exposes a feature importance attribute or can rank features by their coefficients. Since the dataset used in this works mostly have many features, the range from 18 to 112 Features. Dealing with many features has significantly consume higher computation resources. Here is the explanation about feature reduction by RFE\n1. Impact on Accuracy:\n\u2022 Using Recursive Feature Elimination (RFE) allows most algorithms to maintain accuracy above 95% even when reducing features by up to 75%. This is evident in datasets like ds_235795_54 and ds_129K112.\n\u2022 CatBoost and Random Forest exhibit slight accuracy decreases with feature reduction, while XGBoost is more sensitive and shows a significant drop in accuracy with fewer features.\n2. Impact on Runtime:\n\u2022 RFE significantly decreases runtime, particularly for XGBoost and Random Forest. For instance, in dataset ds 129K112, XGBoost's runtime drops to 9 with 17 features, while CatBoost requires 39 runtime units with 20 features.\n\u2022 Explainable Boosting Machine (EBM) continues to have higher runtime even after reducing features, indicating that feature reduction has less impact on its runtime.\n3. Feature Reduction Efficiency:\n\u2022 XGBoost shows the highest efficiency in feature reduction. It can reduce from 54 features to just 1, still achieving 99.6% accuracy with the lowest runtime of 14 units.\n\u2022 CatBoost and Random Forest also demonstrate good efficiency in feature reduction but need more features than XGBoost to reach similar accuracy levels.\nThe answer of the second question start from chosen algorithm such as Random Forest, XGBoost, CatBoost and EBM. This work utilizes two modeling approaches: black box and white box modeling. Black box models, such as Random Forest, XGBoost, and CatBoost, lack inherent mechanisms to explain their decision-making process or identify the specific features influencing their predictions. In contrast, white box models, represented in this work by EBM, offer transparency by providing insights into how the model operates and which features contribute to its predictions.\nIn comparing various machine learning algorithms for web URL phishing detection, CatBoost emerges as the top performer overall. Its impressive accuracy, coupled with its ability to efficiently handle large datasets, makes it a compelling choice. Furthermore, both CatBoost and Random Forest exhibit excellent robustness, maintaining high accuracy even when the number of features is reduced. While EBM also demonstrates good accuracy, it proves less efficient when dealing with larger datasets.\nTherefore, when considering both accuracy and efficiency, CatBoost is the recommended algorithm for web URL phishing detection. However, in scenarios where scalability with large datasets is paramount, XGBoost, with its superior runtime efficiency, emerges as the most suitable choice.\nThe last question to answer is how XAI method can explain clearly which features have most influence in phishing detection and also lead to clear in increasing or decreasing label prediction.\nGeneral observations from the SHAP summary plots reveal the influence of individual features on the model's prediction of phishing URLs. The plots illustrate whether a specific feature contributes to an increased or decreased probability of a URL being classified as phishing. Notably, features exhibiting a wider distribution of SHAP values exert a more substantial influence on the model's predictions, highlighting their importance in the decision-making process.\nComparing XGBoost and CatBoost reveals that both algorithms consistently identified \"length_url,\" \"time_domain_activation,\" and \"Page_rank\" as the most influential features across various datasets. However, a key distinction arises in their feature importance distribution. XGBoost exhibited a tendency to heavily rely on a single dominant feature, such as \"URLSimilarityIndex,\" in certain datasets. In contrast, CatBoost demonstrated a more balanced approach, with multiple features contributing significantly to its predictions. This suggests that CatBoost might offer greater generalizability and robustness by avoiding over-reliance on any single feature.\nThese features demonstrated significant influence, impacting the model's predictions both positively and negatively. SHAP plots provided valuable visualizations, illustrating how specific feature values contributed to an increased or decreased probability of predicting phishing labels, thereby enhancing the transparency of the models' decision-making processes. However, the analysis also revealed potential biases in certain cases, where higher or lower feature values did not consistently align with expected changes in predictions. This underscores the need for further refinement in feature interpretation to ensure accurate and unbiased phishing detection. Overall, the SHAP analysis effectively pinpointed the most critical features, elucidated their roles in phishing detection, and provided insights into the decision-making processes of both XGBoost and CatBoost models."}, {"title": "5.2 Findings", "content": "Interesting Findings from this works describe as follow:\n1. Feature Reduction Maintains Accuracy: Both CatBoost and XGBoost demonstrated the ability to maintain high accuracy even after significant feature reduction using Recursive Feature Elimination. For example", "ds_235795_54\" dataset using only one feature, highlighting that a single dominant feature can be highly predictive in certain cases.\n2. Key Features Remain Consistent": "Across various datasets", "length_url,\" \"time_domain_activation,\" and \"Page_rank\" consistently emerged as top predictors, indicating their importance in distinguishing phishing URLs. This consistency underscores their significance in the phishing detection process.\n3. Minimal Features Yield Strong Performance": "Remarkably", "Observed": "Interestingly", "ds_235795_54\" dataset, the \"URLSimilarityIndex\" feature alone proved sufficient for achieving high accuracy. This finding emphasizes that in specific datasets, a single well-selected feature can be dominant, leading to optimal performance and a simpler, faster model.\n5. Potential Bias Requires Attention": "SHAP analysis revealed potential biases in how some features", "URL_length,\" impacted predictions. Inconsistent impacts based on feature values, as observed in the \"ds_100K20\" dataset, suggest potential bias or non- linearity in feature influence, warranting further investigation.\n6. Algorithm Performance Comparison": "XGBoost consistently exhibited the shortest runtime across all datasets", "Summary": "The experiment identified \"length_url,\" \"time_domain_activation,\" and \"Page_rank\" as crucial features for phishing detection. XGBoost emerged as the most efficient and scalable algorithm, while CatBoost exhibited robustness in accuracy despite feature reduction. EBM, though accurate, faced limitations due to"}]}