{"title": "Chumor 2.0: Towards Benchmarking Chinese Humor Understanding", "authors": ["Ruiqi He", "Yushu He", "Longju Bai", "Jiarui Liu", "Zhenjie Sun", "Zenghao Tang", "He Wang", "Hanchen Xia", "Rada Mihalcea", "Naihao Deng"], "abstract": "Existing humor datasets and evaluations predominantly focus on English, leaving limited resources for culturally nuanced humor in non-English languages like Chinese. To address this gap, we construct Chumor, the first Chinese humor explanation dataset that exceeds the size of existing humor datasets. Chumor is sourced from Ruo Zhi Ba (RZB, \u5f31 \u667a\u5427), a Chinese Reddit-like platform known for sharing intellectually challenging and culturally specific jokes. We test ten LLMs through direct and chain-of-thought prompting, revealing that Chumor poses significant chal- lenges to existing LLMs, with their accuracy slightly above random and far below human. In addition, our analysis highlights that human- annotated humor explanations are significantly better than those generated by GPT-40 and ERNIE4-turbo. We release Chumor at https://huggingface.co/datasets/ dnaihao/Chumor, our project page is at https: //dnaihao.github.io/Chumor-dataset/, our leaderboard is at https://huggingface. co/spaces/dnaihao/Chumor, and our code- base is at https://github.com/dnaihao/ Chumor-dataset.", "sections": [{"title": "1 Introduction", "content": "Humor is an intrinsic human trait that touches the core of our social and emotional lives, making it a rich field of study across various disciplines (Lefcourt, 2001; Mihalcea and Strapparava, 2005; Gelkopf et al., 2011; Hessel et al., 2023). With the advent of Large Language Models (LLMs), re- searchers have evaluated LLMs' performance on diverse tasks (Liu et al., 2023a; Deng et al., 2024; Wu et al., 2023) and observed LLMs' extraordi- nary performance on many (Zhang et al., 2024b). In contrast, researchers have observed that LLMs still fail to understand humor (Ghanadian et al., 2023). However, with all these studies on humor,"}, {"title": "2 Related Works", "content": "Humor Datasets. Humor analysis in natural lan- guage processing (NLP) encompasses a wide range of tasks, each focused on different aspects of humor. For instance, researchers have proposed datasets"}, {"title": "3 Chumor Dataset", "content": "Data Collection. We construct our dataset by in- cluding RZB jokes from \"Best Annual Threads\" between 2018 and 2021 that have been previ- ously crawled*. In addition, we directly collect all threads in the \"Moderator's Recommendation\" section from RZB. Each thread in RZB consists of \u201c\u6807\u9898\u201d (title), \u201c\u4e00\u697c\u201d (content), and several \u201c\u8ddf\u5e16\u201d (follow-up posts). For threads from Best Annual Threads, the jokes are listed in the follow-up posts, which are selected by the forum moderator. For threads from Moderator's Recommendation, the jokes consist of the title and the content of each thread. We remove the content if it repeats the title.\nData Cleaning. We store both the title and the content of the raw data. However, due to the post- ing restrictions of the platform requiring non-empty content, many posts contain meaningless place- holder texts such as \".\", \"!\", \"0\", \"RT\", and others. We automatically identify and remove these pat- terns, and only keep the title which is the joke itself. Due to the length limitations on the original platform, many post titles are truncated from the beginning parts of the content. We identify these instances and replace the truncated title with the complete content to get the joke. We also remove duplicates that appear both in the \u201cModerator's Recommendation\" and the \"Best Annual Posts\".\nWe manually remove the threads related to fo- rum management and rules, threads that include excessively offensive content, threads with incom- plete content, and threads that focus more on philo- sophical insight rather than humor.\nHumor Explanation Classification. We design a humor explanation classification task that can be easily used to test LLMs' capabilities in humor understanding. Specifically, we use two LLMs, GPT-40 and ERNIE4-turbo to generae explanations for our collected jokes. We manually annotate the generated explanations as either \u201cfully explain the joke\" (good) or \u201cpartially explain or not explain the joke\" (bad) based on a majority vote among five of the authors who are native Chinese speakers. Each joke, along with its explanation, forms an individual instance in Chumor, leading to a total of 3,339 instances. Among these, 1,454 items are labeled as good and 1,887 as bad explanations."}, {"title": "4 Experiments", "content": "Models. We test ten LLMs, five from the open-source LLM families and five from the closed-source LLM families, all capable of handling Chinese. Specifically, we include the open-source LLMs of Yi34B (01.ai, 2024) from 01.AI, Nemotron70B (NVIDIA, 2024) from NVIDIA, Athene70B (Nexusflow, 2024) from Nexusflow, Qwen2.572B (Qwen, 2024) from Al- ibaba, Mistral123B (AI, 2024) from Mistral AI, alongside the closed-source LLMs of Gemini1.5-pro"}, {"title": "Evaluation Methods", "content": "We evaluate these LLMS using two prompting methods: direct prompting (DP) by\nDirect Prompting (DP)\nYou will see a joke and an explanation of the joke. Please determine whether this explanation fully explains the joke. Based on your judgment, choose either \"fully explain\" or \"partially/does not explain.\" You do not need to explain why it is correct or incorrect.\nJoke: {joke}\nExplanation: {explanation}\nand chain-of-thought (CoT) prompting (Wei et al.,"}, {"title": "5 Results and Discussions", "content": "Overall Model Performance. Figure 1 presents the accuracy of different LLMs on Chumor in DP and CoT settings. Appendix F presents additional results and analysis.\nOverall, we observe that all models perform poorly on Chinese humor comprehension, with ac- curacy scores ranging between 44.6% and 60.3%. ERNIE4-turbo and Gemini1.5-pro achieve the highest accuracy of 60.3%, and are just 10 points above the random baseline and far below human performance of 78.3%, highlighting the difficulty of Chumor and the limitations of these LLMs in understanding Chinese humor."}, {"title": "5.1 Error analysis by joke type", "content": "To better understand how LLMs perform on each joke type listed in Table 1, we sample 200 jokes for error analysis. Figure 2 and Figure 16 in Ap- pendix F present the results.\nWe highlight that model performance varies sig- nificantly across different joke types. While mod- els generally perform well on Situational jokes, achieving 60.0% to 70.0% accuracy in both DP and CoT settings, their performance difference on other joke types is more pronounced. For instance, GLM-4plus achieves 65.0% accuracy on Homo- phonic jokes in the DP setting, whereas Yi34B only reaches 30.0%. Nemotron70B performs well on Cul- tural jokes in the CoT setting with 72.0% accuracy, but Athene70b and ERNIE4-turbo achieve with only 43.0% and 42.0%, respectively. Such performance variance highlights LLMs' varied capabilities in specific domains such as cultural reasoning and situational reasoning, revealing the respective limi- tations of these LLMs."}, {"title": "5.2 Have LLMs achieved human-level understanding of humor?", "content": "Answer: No. To compare the performance of LLMs with humans, we conduct a human study"}, {"title": "5.3 Does chain-of-thought (CoT) help LLMS' humor understanding?", "content": "Answer: No. We observe that CoT does not necessarily improve model performance and, in most cases, even leads to performance decay. For instance, as shown in Figure 1, the accuracy of ERNIE4-turbo decreases from 60.3% to 45.2% when we switch to CoT prompting, Mistral123B's perfor- mance drops from 55.6% to 51.2%, GPT-4o's per- formance drops from 51.9% to 50.6%, GPT-4turbo's performance falls from 52.3% to 51.3%. Moreover, the MCC scores present a clearer trend of perfor- mance decline under CoT prompting. As shown in Figure 15 in Appendix F, eight of the ten LLMs' MCC scores decrease under CoT prompting. We hypothesize that CoT prompts may not help the model's reasoning when the model lacks a funda- mental grasp of humor understanding.\nWe observe that under CoT prompting, mod- els like GPT-40 tend to justify incorrect expla- nations as \"correct\", leading to an increase in false-positive rate from 80.0% for DP prompt- ing to 85.0% for CoT prompting (Table 4 in Ap- pendix F). ERNIE4-turbo exhibits the largest false- positive rate, rising from 59.8% to 96.9% (Table 4 in Appendix F). Figure 3 provides an example where CoT confuses the GPT-40 model. Under the DP prompting, the GPT-40 model chooses the answer correctly. However, CoT prompting causes the model to over-analyze and justify an incorrect explanation.\nOn the other hand, models like Nemotron70B may be overly critical of explanations under CoT prompting, resulting in a false-negative rate from 20.9% for DP prompting to 46.1% for CoT prompt- ing (Table 4 in Appendix F). We highlight that a recent work demonstrates that CoT can degrade performance in tasks requiring subtle comprehen- sion (Sprague et al., 2024), which aligns with our findings on its limitations in humor interpretation. Figure 14 in Appendix D discusses an example corresponding to the model being overly critical."}, {"title": "5.4 Case study: can GPT-40 and ERNIE4-turbo explain jokes as well as humans?", "content": "Answer: No. Apart from testing multiple LLMs on Chumor, we conduct case studies on GPT-40 and ERNIE4-turbo to assess the quality of their joke explanations compared to humans. We prompt them to explain the humor in two sentences, consis-"}, {"title": "6 Conclusion", "content": "We introduce Chumor, a Chinese humor under- standing dataset that includes intellectually chal- lenging and culturally specific humor in Chinese. We show that Chumor is challenging even for ad- vanced LLMs and provide analysis of their failure cases. We hope that Chumor can advance non- English humor research and contribute to evaluat-"}, {"title": "Limitations", "content": "We try our best to test the Chinese humor under- standing ability of different LLMs. However, due to the limited budget and API access, we cannot evaluate all possible LLMs in this paper. We en- courage future research to conduct further evalu- ations of humor understanding abilities in LLMs. In the meantime, we emphasize that our research focuses primarily on demonstrating how humor un- derstanding remains a significant challenge, even for SOTA LLMs. Our work shows that along with many other problems (Ignat et al., 2024), humor understanding, especially non-English and cultur- ally specific humor understanding, remains an un- solved problem in the era of LLMs. We hope Chu- mor can contribute to non-English humor under- standing evaluations for future multilingual LLMs."}, {"title": "Ethics Statement", "content": "We have made every effort to filter out excessively offensive content in RZB. However, due to the sub- jective nature of humor, some of our jokes may still be perceived as offensive by individuals with differ- ent cultural or personal standards. To address these concerns, we strongly recommend that researchers use Chumor with cultural sensitivity, recognizing that the jokes in the dataset reflect the sociocultural context in which they were created. We encour- age users of Chumor to approach the dataset with caution, remaining mindful of its potential to cause offense or harm, particularly when applying it in research or applications that involve diverse au- diences or address sensitive topics. We wish to foster an ethical and responsible approach to data collection and usage, and we welcome construc- tive feedback from the research community and stakeholders to continually improve Chumor and mitigate potential harm."}, {"title": "7 Acknowledgement", "content": "The GPT experiments are supported by credit from OpenAI through OpenAI Researcher Access as- signed to Naihao Deng. We appreciate Qiang Liu, and Xiaoyue Shi for helping with the human study."}]}