{"title": "Statistical Scenario Modelling and Lookalike Distributions for Multi-Variate AI Risk", "authors": ["Elija Perrier"], "abstract": "Evaluating AI safety requires statistically rigor-\nous methods and risk metrics for understanding\nhow the use of AI affects aggregated risk. How-\never, much AI safety literature focuses upon risks\narising from AI models in isolation, lacking con-\nsideration of how modular use of AI affects risk\ndistribution of workflow components or overall\nrisk metrics. There is also a lack of statistical\ngrounding enabling sensitisation of risk models in\nthe presence of absence of AI to estimate causal\ncontributions of AI. This is in part due to the\ndearth of AI impact data upon which to fit distribu-\ntions. In this work, we address these gaps in two\nways. First, we demonstrate how scenario mod-\nelling (grounded in established statistical tech-\nniques such as Markov chains, copulas and Monte\nCarlo simulation) can be used to model Al risk\nholistically. Second, we show how lookalike dis-\ntributions from phenomena analogous to AI can\nbe used to estimate AI impacts in the absence\nof directly observable data. We demonstrate the\nutility of our methods for benchmarking cumula-\ntive AI risk via risk analysis of a logistic scenario\nsimulations.", "sections": [{"title": "1. Introduction", "content": "Al systems are increasingly integrated within multi-stage\nscenarios, supply chains, industrial workflows, or large-\nscale production pipelines. These deployments carry new\nrisks regarding flow-on effects of AI use on other system\ncomponents that are poorly understood or underestimated.\nDespite a burgeoning literature on AI risk and safety , most AI evaluation\ntechniques focus only upon isolated model performance,\nsuch as classification accuracy, adversarial vulnerabilities\n, interpretability, misalignmnet or fairness in isolation\n, rather than the effects of AI use across in-\nterconnected component systems. AI risk evaluations also\ntypically lack a rigorous statistical grounding typical of con-\nventional risk analysis , including sampling\nstrategies, distribution fitting, likelihood estimation and hy-\npothesis testing of AI effects to be evaluated. Moreover,\nthere also tends to be a lack benchmarking practices which\nsensitise models to enable risk metrics from non-AI work-\nflows to be compared with AI-workflows. This is in part\ndue to a dearth of source data on the measurable impacts of\nAI from which to perform statistical analysis. It is also due\nto difficulties disentangling what is uniquely AI risk from\nother non-AI related procedures.\nWhile understanding model-specific risks is important, real-\nistic deployment of AI involves its modular integration as\none component of existing processes and risk frameworks.\nFor AI risk and safety protocols to be of any practical use,\nit is therefore crucial to understand how the modular inte-\ngrated use of AI, as a substitute for existing component, or\nadditional component, changes the multi-variate risk profile\nof complex workflows and processes. In almost all practical\nuse cases, the impact of an AI component failure is unlikely\nto be restricted to that component alone. As with any other\ntechnology, the effects of AI failure can be expected to prop-\nagate throughout workflows and processes. The failure of\nan AI component may have a significant follow-on effects\non interconnected components, altering their profile, dis-\ntribution and likelihood of failure. The use of AI across\nmultiple components of a process may also lead to an ac-\ncumulation of failures or produce unexpected side effects.\nConversely, the use of certain AI components might reduce\nboth total overall risk metrics and those of individual com-\nponents within a workflow. It is therefore reasonable to\nassume that any practical analysis of the integrated AI must\naccount for its use a component or module within a broader\nscenarios - sequence of interdependent and interconnected\nevents leading to a risk event."}, {"title": "1.1. Contributions", "content": "To this end, our contributions are as follows:\n1. Scenario modelling of AI risk. We demonstrate how to\npartition AI-related events into a multi-stage pipeline of\nsub-events $E_r$ whose properties (such as failure modes\nor loss) can be modelled as measurable random vari-\nables $X_i$ drawn from baseline distributions $F_i$. We\nthen substitute $F_i^{(AI)}$ where AI is adopted, capturing\nthe interplay of AI and non-AI components.\n2. Statistical empirical methods. We illustrate how to\ndeploy Markov chains and copulas to model dependen-\ncies among sequential failures and cumulative variation\nin risk metrics.\n3. Data scarcity solution via lookalike distributions. We\npropose adapting distributions from comparable pro-\ncesses or partial automation scenarios to approximate\n$F_i^{(AI)}$ until sufficient AI-specific data are available.\n4. Benchmarking AI vs. non-AI process risks. We show\nhow scenario modelling enables side-by-side compar-\nisons of baseline (no AI), partial AI, and full AI, reveal-\ning differences in probability of total overall loss or\nimpact $Pr(X_{total} > t)$, mean performance, and catas-\ntrophic tail events.\n5. Example simulation. We illustrate these methods on a\nthree-stage pipeline (demand forecasting, warehouse\npicking, last-mile delivery) to demonstrate how sce-\nnario modelling allows pragmatic assessment of multi-\nvariate Al risk.\nOverall, our framework aims to help operationalise AI\nrisk in a manner aligned with established operational risk\nmethodologies, bridging a gap in AI safety research and\noffering a replicable template for industry practitioners."}, {"title": "2. Background", "content": ""}, {"title": "2.1. Related Work", "content": "AI risk and safety is an emerging research discipline with\nparticular importance to the deployment of AI systems. At\none end of the spectrum, AI safety involves broad con-\nceptual discussions of alignment and existential threats\n. This includes the risk of\nexceeding human oversight ,\nmisalignment with human interests and catastrophic AI risk . At\nthe other, more technically focused end, AI safety exam-\nines specific model behaviour and artefacts that can give\nrise to adverse impacts. This includes substantial work\non adversarial robustness"}, {"title": "2.2. Statistical Scenario Modelling", "content": "Scenario modelling is a technique widely used in operational\nrisk analysis and reliability theory. It offers a systematic"}, {"title": "2.3. Event Sequencing", "content": "Scenario modelling relies upon decomposing an event, such\nas the chance of a system failure due to AI, into a sequential\npipeline of component sub-events. We consider a pipeline\nas a directed graph of events $E_1 \\rightarrow E_2 \\rightarrow\u2026\u2026\\rightarrow E_n$. Each\nevent $E_i$ is associated with a random variable $X_i$ drawn\nfrom a distribution $F_i$ that encodes a relevant outcome of\na component in the process, such as cost, delay, or a risk\nmeasure at that stage in the workflow. In a baseline (non-AI)\nscenario, $X_i \\sim F_i$, where $F_i$ is estimated from historical\ndata or domain knowledge. Introducing AI at event $E_i$\nmodifies that distribution to $F_i^{(AI)}$. This can lower average\nerrors or processing times while also shifting tail behaviour,\nfor instance by adding a small but increased chance of a\ncatastrophic failure. We let the aggregate system outcome\nbe either the sum:\n$X_{total} = \\sum_{i=1}^{n} X_i$                                                                                                      (1)\nor a more general function:\n$X_{total} = g(X_1, X_2, ..., X_n)$,\n(2)\ndepending on how sub-event outcomes interact. In our ex-\namples below, $X_i$ might be some measure of cost, adverse\nimpact or loss. Events $E_i$ and their impacts $X_i$ are often\ncorrelated in complex ways. This means that failure in\none stage may directly impact subsequent stages or that ex-\nogenous factors may affect multiple stages simultaneously.\nThus assessing the aggregate impact of events - and the inte-\ngration of AI within processes - is rarely straightforward. As\nnoted above, doing so ideally involves understanding the in-\nterconnected dependencies between events. Markov chains\nfor example can be used to capture these dependencies when\nthe system passes through discrete states like operational,\nminor-failure, and repair. Copulas are useful when continu-\nous variables have correlated or heavy-tailed joint behaviour.\nWe discuss both dependency relations below."}, {"title": "2.4. Data scarcity", "content": "Being able to model event dependencies relies upon having\ndata or information from which to estimate relevant distribu-\ntions (or probabilities) of those events occurring. Scenario\nmodelling works most effectively where there is an abun-\ndance of observational data that allows for rigorous fitting\nof distributions (such as data obtained via measurement of\nproduction processes or workflows). A major challenge in\nAI-integrated workflows is the lack of extensive historical\ndata to reliably estimate AI-specific failure distributions.\nThis contrasts with traditional automation or mechanical\nsystems, for which well-catalogued failure times or defects\nallow direct parameter fitting. To address this problem, we\npresent two approaches to constructing lookalike distribu-\ntions that serve as proxies for AI risk until more direct AI\ndata becomes available: (i) AI-specific tail adjustments and\n(ii) lookalike distributions with goodness-of-fit updates. We\ndemonstrate each using our logistics workflow example."}, {"title": "2.4.1. AI-SPECIFIC TAIL ADJUSTMENTS.", "content": "Suppose that in a three-stage logistics pipeline, the ware-\nhouse picking task $E_2$ is replaced by an AI-driven robotic\nsystem. If we have a known mechanical-automation distribu-\ntion from the literature, say a Gamma distribution :\n$T \\sim \\Gamma(\\alpha, \\beta)$,\n(3)\nwhere $\\alpha$ (shape) and $\\beta$ (scale) were estimated from non-AI\nrobotic picking data, we may use this as a starting point. To\nreflect new AI-specific risk, we can adjust the tail to allow\nfor a small probability $\\varepsilon$ of extreme failures:\n$T_{AI} = \\begin{cases}\nT, & \\text{with probability } (1 - \\varepsilon), \\\\\nZ, & \\text{with probability } \\varepsilon,\\end{cases}$                                     (4)\nwhere $Z$ is drawn from a heavy-tailed distribution such as a\nGeneralised Pareto distribution with shape parameter $\\xi > 0$."}, {"title": "2.4.2. LOOKALIKE PLUS GOODNESS-OF-FIT UPDATES", "content": "An alternative is to assume that AI initially follows the\nsame distribution as the non-AI component, then iteratively\nupdate parameters as AI usage data becomes available. For\nexample, suppose the pre-AI system's picking times follow\n$T \\sim Weibull (k, \\lambda)$                                                                                               (6)\na distribution commonly used in reliability analysis . In the absence of direct AI data, we can\ninitially set:\n$T_{AI} \\sim Weibull(k^{(0)}, \\lambda^{(0)}),$                                                                              (7)\nusing the same $(k, \\lambda)$ or minor adjustments $(k^{(0)}, \\lambda^{(0)})$ . As AI picking data\n${X_1,X_2,...,X_n}$ is obtained, we re-estimate parameters by\nmaximum likelihood:\n$(k, \\lambda)_{new} = arg max_{k, \\lambda} \\prod_{i=1}^{n} Weibull(x_i | k, \\lambda),$                                                     (8)\nor use a Bayesian update if we have prior distributions\non $k, \\Lambda$ . After refitting, we check\nwhether the Weibull form remains appropriate by applying\na goodness-of-fit test (for instance, a Kolmogorov-Smirnov\nor Anderson-Darling test) . If\nrepeated experimental data suggests a poor fit, we can con-\nsider a heavier-tailed family or mixture model to capture\nAI-specific anomalies. This iterative approach treats the\nnon-AI component as a lookalike baseline and adapts it us-\ning real operational data from the AI-driven system. In both\nmethods, these AI-related distributions can be inserted into\nthe scenario modelling framework described in Section 2.3,\nreplacing $F_i$ by $F_i^{(AI)}$. As more AI data accumulate, param-\neters can be continuously revised. Such iterative refinement\nis crucial for capturing novel failure modes and for high-\nlighting whether AI's true risk profile deviates from initial\nassumptions about mechanical or purely human-driven pro-\ncesses. A third approach, which we do not discuss here"}, {"title": "2.5. Dependency Structures", "content": "Multi-event scenario modelling requires a means of inter-\nconnecting each event distribution $F_i$ into an overall sce-\nnario evolution. Two commonly used methods for doing\nso are Markov Chains and copula methods together with\nMonte Carlo simulations . Markov chains suit\nevent pipelines where each sub-event is modelled in terms\nof states whose configurations, such as normal operation,\nminor failure, or critical failure, can be modelled via proba-\nbility distributions. These distributions are used to estimate\nthe likelihood of the component entering into a particular\nfailure mode (or sub-event). Alternatively, a copula-based\napproach can capture dependencies among continuous sub-\nevent distributions. Scenario modelling a way to assess how\nAI failure modes propagate through systems. This is can\nbe especially useful partial automation or full automation\nchanges the correlation structure among components"}, {"title": "2.5.1. MARKOV CHAINS", "content": "Markov chains are widely used for modelling state-based\ntransitions, commonly encountered in reliability engineer-\ning (operational/failure/repair states) . If we\nassume a discrete-time Markov chain, then at each time\nstep t, the system occupies a state $X_t$ from a finite set\n${0, 1, 2, . . . }$. The transitions obey:\n$P_{ij} = Pr(X_{t+1} = j | X_t = i)$\nand $\\sum_j P_{ij} = 1$. In the context of AI risk, a state might rep-\nresent different operational modes (e.g., normal operation,\npartial failure, major failure, under-repair). Substituting AI\nmay change specific transition probabilities. For instance,\nthe probability of going from normal operation to partial\nfailure could decrease (better performance on average), but\nthe probability of jumping directly to major failure might\nbe introduced or increased if the AI fails in an unanticipated\nway. A continuous-time Markov chain variant can also be\nused by defining exponential rates $\\Lambda_{ij}$. The choice depends\non whether the sub-event times are best approximated in\ndiscrete steps or continuous durations."}, {"title": "2.5.2. COPULAS", "content": "When the primary random variables of interest (e.g., time\nto completion, cost, or quantity of defects) are continu-\nous, a copula-based approach helps capture correlations\nand tail dependencies . Copulas are also of"}, {"title": "2.5.3. \u039c\u039fNTE-CARLO SIMULATIONS", "content": "Scenario models typically rely upon simulations for which\nMonte Carlo methods are the most common method. Each\nsimulation run draws one sample from each sub-event dis-\ntribution, subject to the chosen dependence model and then\ncomputes a system-wide outcome (for instance, total delay\nor cost). Repeating this many times yields an empirical\ndistribution of outcomes and measurement statistics, from\nwhich decision-relevant metrics can be derived. these in-\nclude the probability of exceeding certain thresholds, the\nValue at Risk (VaR) for a chosen confidence level, or the Ex-\npected Shortfall of catastrophic events . Such metrics can\nindicate whether AI adoption in a particular scenario merely\nshifts risk profiles or genuinely mitigates overall hazards.\nThey can also illuminate potential trade-offs between typical\ngains and the possibility of rare but extreme failures. We\ndiscuss these below."}, {"title": "2.6. Risk Measures", "content": "As noted above, the purpose of scenario modelling for AI is\nto enable statistically meaningful quantification of how risk\nmetrics vary under a range of conditions due to the integra-\ntion of AI. Risk measures in operational risk settings aim to\ncapture the likelihood or severity of adverse outcomes. Two\nwidely used measures are Value at Risk (VAR) and Expected\nShortfall (ES) (also known as conditional VAR)."}, {"title": "2.6.1. VALUE AT RISK (VAR)", "content": "Value at Risk is given by:\n$VaR_{\\alpha} (L) = inf{l : Pr(L < l) \\geq \\alpha }$                                                            (9)\nwhere L is the loss random variable and $\\alpha$ is a specified\nconfidence level (e.g. 0.95, 0.99). $VaR_{\\alpha} (L)$ is a threshold"}, {"title": "2.6.2. \u0415X\u0420\u0415\u0421TED SHORTFALL (ES)", "content": "Expected shortfall is given by:\n$ES(L) = \\frac{1}{1-\\alpha} \\int_{\\alpha}^{1} VaR_{u} (L) du$                                                                   (10)\nwhich captures the expected (or mean) loss in the worst\n$(1-\\alpha)$ fraction of cases. ES is considered more sensitive\nto tail behaviour than VaR and can give a clearer picture of\ncatastrophic outcomes . Other domain-specific thresholds or cost-based\nmetrics (e.g., probability that downtime exceeds 24 hours)\ncan also be used."}, {"title": "2.7. Sensitising AI Scenarios", "content": "The extent of AI integration in any workflow or process\nis a matter of degree. In almost all cases, AI is simply a\nsub-component of a particular process that involves non-AI\ncomponents (albeit advances in frontier and LLMs are see-\ning advances in capability that allow AI to construct and\nexecute across entire pipelines). To reliably analyse Al risk\nof any variety, it is useful where possible to benchmark the\nuse of AI against an equivalent or near-equivalent process\nusing sensitivity analysis . Doing so allows the appli-\ncation of statistical methods that can test for whether the\nintegration of AI gives rise to any statistically significant\ndifferences in risk measures, such as those identified above.\nBenchmark comparisons are also useful as a means of iden-\ntifying or detecting AI-related events themselves. In the\nsimulations below illustrating our methods, we introduce\nthree cases against which to test a scenario:\n1. Non-AI (Baseline). The system uses conventional pro-\ncesses, with established or historical data for each sub-\nevent. We can typically model these distributions more\nconfidently, given prior logs or well-understood relia-\nbility metrics. All events remain as historically mod-\nelled, e.g.,\n${F_1, F_2,..., F_n}$                                                                                                                     (11)\n2. Partial AI. AI replaces or augments only some sub-\nevents. For example, the warehouse picking process\nmight be automated, but forecasting and delivery re-\nmain unchanged. Suppose AI is introduced only for\nsub-event $E_k$, so that event has distribution\n$F_k^{(AI)}$,"}, {"title": "3. Methods", "content": "We demonstrate the use of scenario modelling and looka-\nlike distribution methods using a toy model of a logistics\nworkflow process. We adopt the following process based on\nthe scenario modelling and lookalike distribution principles\narticulated above for Al risk is set out below.\n1. Decompose the pipeline. Identify sub-events\n$E_1, E_2,..., E_n$, each with a random variable $X_i \\sim F_i$\nbelow.\n2. Baseline Distributions. Assign a baseline distribution\n$F_i$ (such as Gamma, Weibull, or Bernoulli) to charac-\nterise the event's cost, time, or failure frequency. This\nis done ideally using empirical methodology and data\nto estimate suitable $F_i$, but it can also draw upon results\nfrom the literature.\n3. Estimate Lookalike Distributions. When an AI module\nreplaces sub-event $E_i$, change $F_i$ to $F_i^{(AD)}$. This might\nreduce the mean but introduce heavier tails. In Markov\nsettings, the transition probabilities (or rates) are also\nmodified as a result. In a copula model, the relevant\nmarginal or dependence parameters may shift to reflect\nnew correlations.\n4. Set scenario model dependencies. Use a Markov chain\nwhen sub-events or system states are discrete. If sub-\nevents produce continuous outcomes, use a copula C to\nlink the marginal distributions $F_1,..., F_n$. For exam-\nple, in a Gaussian copula, one estimates the correlation\nmatrix among $\\Phi^{-1}(F_i(x))$ terms, where $\\Phi$ is the stan-\ndard normal CDF.\n5. Measure risk metrics. After specifying distributions,\nwe run Monte Carlo simulations to compute or simulate\n$X_{total}$ and evaluate metrics such as $Pr(X_{total} > T)$,\nor the following classical measures:\n$VaR_{\\alpha} (X_{total}) = inf{ x : Pr(X_{total} \\leq x) \\geq \\alpha},$                                                     (12)\n$ES_{\\alpha} (X_{total}) = \\frac{1}{1-\\alpha} \\int_{\\alpha}^{1} VaR_{u} (X_{total}) du.$                                                          (13)\nThese highlight both moderate and tail-based risks.\n6. Compare scenarios. The procedure above is imple-\nmented for three cases: no AI, partial AI, and full\nAI (where more events are substituted with AI). By\ncontrasting distributions and risk metrics across these\nscenarios, one can assess whether AI integration de-\ncreases mean system losses or inadvertently increases\nlow-probability, high-severity events."}, {"title": "3.1. Example: Hypothetical Multi-Stage Logistics Pipeline", "content": "We illustrate how scenario modelling can reveal the\nnet effect of AI in a hypothetical supply chain pipeline\nwith three sub-events: ($E_1$) Demand Forecasting, ($E_2$)\nWarehouse Picking, ($E_3$) Last-Mile Delivery where each\nprocess has a non-AI and AI instance.\nE1: Demand Forecasting.\n* Non-AI baseline: A simplistic statistical or manual\nforecast approach. Historical data is used to model\ndistribution of forecast errors, possibly Gaussian-like\nwith moderate variance.\n* AI-based scenario: A deep learning forecast system\nwith improved average accuracy but an uncertain tail\nthat might produce large outliers. The distribution\nmight show narrower bulk but heavier extremes.\nE2: Warehouse Picking.\n* Non-AI baseline: Manual or semi-automated picking.\nThe time distribution is known, with some moderate\ncorrelation to forecast accuracy.\n* AI-based scenario: A robotics-based system with ma-\nchine vision. This might reduce mean picking time but\nintroduce a small chance of catastrophic malfunction\nif the AI fails to identify items correctly."}, {"title": "E3: Last-Mile Delivery.", "content": "* Non-AI baseline: Traditional trucks or human couri-\ners, known average times with a certain tail for traffic\ndisruptions.\n* AI-based scenario: Drone delivery or autonomous ve-\nhicles. Potentially faster on average but with novel tail\nrisks (e.g., navigation glitch).\nWe can examine partial AI (replacing only $E_1, E_2$ or $E_3$)\nor full AI (all three replaced). The scenario modelling ap-\nproach draws from either discrete or continuous distribu-\ntions for sub-events, plus a mechanism (Markov chain or\ncopula) to handle correlations."}, {"title": "3.2. Setting and Parameters", "content": ""}, {"title": "3.2.1. BASELINE (NON-AI)", "content": "Assume the pipeline processes shipments daily, with each\nday representing a new run of the three-step chain. We\nchoose baseline distributions drawn from the literature as\nan example:\n* $E_1$: Forecast error distribution is approximate normal\nwith mean 0, standard deviation 15 (representing per-\ncent error). This leads to occasional overstock or un-\nderstock.\n* $E_2$: Picking times follow a Gamma distribution with\nshape $k = 5$ and scale $\\theta = 2$, giving a mean of 10\n(time units).\n* $E_3$: Delivery times are lognormal with parameters\n$(\\mu = 1.0, \\sigma = 0.5)$, yielding an average around 3.0\nbut a long right tail.\nFor forecasting error, normal distributions are often used\n. For travel time and\ntime to destination, lognormal distributions are sometimes\nchosen due to their relative simplicity . And for picking times the Gamma distribution is also\nseen in the literature. With our baseline distributions now\nchosen, we incorporate moderate correlation via a Gaussian\ncopula between $E_1$'s forecast error and $E_2$'s time, reflect-\ning that large understock or overstock can slow picking.\n$E_3$ is assumed partially correlated with $E_2$ but with lesser\nstrength."}, {"title": "3.2.2. PARTIAL AI", "content": "Suppose we replace $E_2$ alone with an AI-driven robotics\nsystem. For example we might hypothesise that $E_2$'s distri-\nbution changes to $\\Gamma(k = 8, \\theta = 1)$, indicating an improved\nmean picking time of 8. However, if the AI system fails,"}, {"title": "3.2.3. FULL AI", "content": "For the case where AI is substituted for each event, we\nmight consider $E_1$ being replaced by a deep learning model\nthat significantly reduces average forecast error to standard\ndeviation 10, but introduces a small probability of a large\nerror. $E_3$ may be substituted using autonomous drones\nor vehicles, cutting average delivery time but with new tail\nrisks (a chance of a major route glitch or regulatory hold-up).\nWe can adjust the copula parameters to reflect possible new\ncorrelations among $E_1, E_2, E_3$ if, for example, AI-based\nforecasting errors degrade the performance of AI-based\npicking or routing in correlated ways."}, {"title": "3.3. Simulation Procedure", "content": "To illustrate our method, we describe two simulations to\ncapture dependencies among sub-events and generate multi-\nstage risk samples. Code for our simulations is available\nvia an online repository . Both start by\nspecifying baseline (non-AI) and AI variants of $E_1, E_2$, and\n$E_3$, then combine them under a common framework (copula\nor Markov chain)."}, {"title": "3.3.1. DISTRIBUTIONS", "content": "We first assign marginal distributions. Let $E_1$ (forecasting)\nin the non-AI scenario have\n$E_1: Non-AI \\quad X_1 \\sim N(0, 15^2),$                                                                                         (14)\nwhere forecasting errors are normally distributed with mean\n0 and standard deviation 15. An AI-based forecaster uses a\nmixture model,\n$X_1^{(AI)} = \\begin{cases}\nN(0, 10^2), & \\text{with probability } 1 - \\epsilon_1, \\\\\nLognormal(\\mu, \\sigma), & \\text{with probability } \\epsilon_1\\end{cases}$                                 (15)\nwhere $\\epsilon_1 \\approx 0.02$ is a small probability mass accounting\nfor extreme outliers. Here we have assumed that an AI\nforecaster has reduced the error to $N(0, 10^2)$ for most cases.\nHowever, the corollary we assume here is that for a small\nnumber of (for example) out of distribution forecast, forecast\nerrors are considerable. The heavy-tailed lognormal is added\nto reflect occasional but extreme forecasting errors. We\nchoose parameters $\\mu = 1, \\sigma = 0.8$ (with mean $exp(1 +\\n0.8^2/2) \\approx 3.74$) which indicates that when error does occur,\nit is large compared to the revised forecasting errors."}, {"title": "and the AI version:", "content": "$X_2 \\sim \\Gamma(5, 2),, (16) , $X^{(AI)}_2  = \\begin{cases}\\Gamma(8, 1), & \\text{with probability } 1 - \\epsilon_2, \\\\Pareto(\\alpha_2), & \\text{with probability } \\epsilon_2.\\end{cases}, (17) We assume that an AI-driven picking system ought to reduce average picking times, but that occasional system faults or extreme operational disruptions may cause drastic delays due complex nature of warehouse organisation and that picking usually lacks redundancy (the correct item must be picked). A Pareto distribution, with its characteristic power-law decay, is chosen to capture such tail risks. Finally, E3 (delivery) uses a lognormal baseline: X3  \\sim Lognormal(1, 0.5)  (18) and for AI-based delivery,  X^{(AI)}_3 = \\begin{cases}Lognormal (0.8, 0.4), & \\text{with probability } 1 - \\epsilon_3, \\\\Weibull (k_3, \\lambda_3), & \\text{with probability } \\epsilon_3.\\end{cases} (19) In principle, the parameters $\\epsilon_i, \\alpha_2, k_3$, or $\\lambda_3$ can be up-dated as new data on AI performance emerge according to a chosen optimisation method (itself amenable to machine learning). Appendix A sets out a sketch of a potential simple method for doing so using LLMs."}, {"title": "3.3.2. COPULA-BASED SAMPLING", "content": "To encode dependencies, we choose a Gaussian copula C\nwith correlation matrix $\\Sigma$. If AI modifies correlations (e.g.,\ndecoupling picking times from forecasting errors), we ad-\njust $\\Sigma$ accordingly. For each Monte Carlo sample, we draw\n(u1, u2, u3) \\sim C\\Sigma and invert ui through the relevant\nmarginal (non-AI or AI). Summing or otherwise aggregat-\ning the resulting (X1, X2, X3) gives Xtotal. Repeating many\nsamples yields an empirical distribution from which we\ncompute risk metrics such as $Pr(X_{total} > t)$, VaR, or ES."}, {"title": "3.3.3. MARKOV CHAIN SAMPLING", "content": "In a Markov chain approach, each sub-\nevent transitions among discrete states (e.g.\n{Operational, MinorFail, MajorFail}). For the non-AI case,\ndefine a transition matrix $P^{nonAI}$ with entries\n$P^{(nonAI)}_{ij} = Pr(X_{t+1} = j | X_t = i),$                                                                                           (20)\nestimated from historical baselines. Introducing AI modifies\ncertain transitions by a small shift $\\Delta_{ij} (AI)$, resulting in\n$P^{(AI)}_{ij} = P^{(nonAI)}_{ij} + \\Delta_{ij} (AI),$                                                                                 (21)\nreflecting lower probabilities for minor failures but a new\n(small) route to catastrophic failure. If $E_1$ is replaced by\nAI forecasting, then $E_2$'s transition probabilities might also\nshift if picking states depend on the forecasting outcome.\nIn simulation, one initialises the chain in an operational\nstate and evolves it through the stages E1, E2, E3. At each\nstage, we sample a state transition using either $P^{(nonAI)}_{ij}$ or\n$P^{(AI)}_{ij}$ depending on which sub-events adopt AI. We then\naccumulate cost/time/loss variables, for example by assign-\ning a random cost distribution conditioned on the current\nstate. After running the chain to completion, we obtain a\ntotal outcome Xtotal. Repeating over many runs builds an\nempirical distribution from which we derive probabilities of\nlarge losses, VaR, or other performance measures. As real\nAI data arrives, parameters $P^{(AI)}_{ij}$ or the cost distributions\nassociated with each AI-related state can be updated."}, {"title": "4. Results", "content": ""}, {"title": "4.1. Hypothetical Outcomes", "content": "Results for the hypothetical scenario using the copula\nmethod and Markov chain method are set out in Tables\n1 and 2 respectively."}, {"title": "5. Discussion", "content": "Figure 1(a) and Table 1 present a copula-based analysis of\nhow $X_{total}$ (total cost or time) is distributed under Non-\nAI, Partial-AI, and Full-AI. In Figure 1(a), the Partial-AI\ncase reduces both the mean and moderate tail probabilities\ncompared to the Non-AI case, yet the Full-AI scenario,\nwhile potentially improving median performance, exhibits\na heavier tail. Table 1 confirms this by displaying a lower\nprobability $P(X_{total} > 30)$ for Full-AI but a significantly\nhigher Expected Shortfall (ES), underscoring the trade-off\nbetween average improvement and catastrophic failure risk."}, {"title": "6. Conclusion", "content": "We have demonstrated how a scenario-based framework,\nincorporating both Markov chains and copulas, can provide\na structured way to evaluate AI-induced shifts in multi-stage\nrisk profiles. By integrating lookalike distributions for AI\nevents with classical statistical methods (Monte Carlo sim-\nulation, VaR, ES), we see how partial or full AI adoption\ntypically lowers mean outcomes but introduces heavier tails,\nreflecting the potential for rare but severe failures. The\ntoy results highlight the importance of comparing baseline,\npartial, and full AI scenarios to understand how improve-\nments in one stage may propagate - and sometimes am-\nplify-downstream risks.\nDespite the intuitive nature of these methods, future work\nmust address the computational overhead of simulating\nlarge-scale models, as well"}]}