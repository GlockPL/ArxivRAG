{"title": "Generic Multimodal Spatially Graph Network for Spatially Embedded Network Representation Learning", "authors": ["Xudong Fan", "J\u00fcrgen Hackl"], "abstract": "Spatially embedded networks (SENs) represent a special type of complex graph, whose topologies are constrained by the networks' embedded spatial environments. The graph representation of such networks is thereby influenced by the embedded spatial features of both nodes and edges. Accurate network representation of the graph structure and graph features is a fundamental task for various graph-related tasks. In this study, a Generic Multimodal Spatially Graph Convolutional Network (GMu-SGCN) is developed for efficient representation of spatially embedded networks. The developed GMu-SGCN model has the ability to learn the node connection pattern via multimodal node and edge features. In order to evaluate the developed model, a river network dataset and a power network dataset have been used as test beds. The river network represents the naturally developed SENs, whereas the power network represents a man-made network. Both types of networks are heavily constrained by the spatial environments and uncertainties from nature. Comprehensive evaluation analysis shows the developed GMu-SGCN can improve accuracy of the edge existence prediction task by 37.1% compared to a GraphSAGE model which only considers the node's position feature in a power network test bed. Our model demonstrates the importance of considering the multidimensional spatial feature for spatially embedded network representation.", "sections": [{"title": "1 Introduction", "content": "Many real-world networked infrastructure or natural systems can be represented as spatially embedded networks (SENs), as their structures are constrained and shaped by the spatial environments [1]. For instance, road networks can be represented by using intersections as nodes and road segments as edges [2], and their topologies are shaped by land types and socio-economic factors. For another instance, the urban sensor networks can also be represented by using the sensors as nodes and the sensor connections as edges [3]. The functionalities and status of such SENs directly influence the city's sustainability and social equity [4-6]. To better manage these networked systems, such as status monitoring and automatic control, advanced techniques from Artificial Intelligence (AI) and Machine Learning (ML) have gained significant attention [7, 8]. However, the performance of AI and ML models heavily depends on accurate modeling and robust learning capabilities for these networked systems. To further improve the networked systems' management, there is an increasing demand for models that can effectively capture and represent the complex and intricate patterns of the SENs.\nThe graph representation learning aims to extract the complex intricate patterns and relationships within the networks by embedding high-dimensional sparse graph structured data into low-dimensional dense vectors [9]. Various techniques have been developed for efficient representation learning, including traditional graph embedding methods and geometric-based deep learning methods. Traditional graph embedding methods can be broadly grouped into matrix-based methods, random walk-based methods, and non-Graph Neural Network methods. Specifically, the matrix-based methods describes the networks with a proximity measure matrix, and the representation is computed based on that matrix. For example, the locally linear embedding (LLE) first constructs a weight matrix which includes the linear combination of node features. The low-dimensional representation for nodes can be then computed by solving the matrix's eigenvalues [10]. Random walks-based methods are also emerging in graph representation. The key idea behind random work is that the nodes should have similar features if they tend to co-occur in random short paths. For example, Deep- Walk [11] and Node2Vec [12] are two common traditional graph embedding methods. The former approach truncated random walks within a network and represented the networks by treating these walks as equivalent sentences. The latter approach used biased random walks to improve the efficiency of exploring diverse neighborhoods. Lastly, non-graph neural network-based algorithm can also work with graph structure data similar to the matrix-based methods. However, the dimensional reduce method is replaced with neural network structures, such as the autoencoder structure [13].\nRecently, the geometric-based deep learning algorithms have been emerging. The Graph Convolutional Network (GCN) was first proposed for graphs' semi-supervised learning tasks [14], which forms a foundation architecture in geometric deep-learning models. After that, several variants of GCN have been proposed for better network representation and pattern discovery, including the GraphSAGE [15], graph attention network (GAT) [16], and many others [17]. The neural networks have greatly extended the flexibility of traditional geometric algorithms by using a large set of linear transformation layers and non-linear activation functions [18]. Previous studies have shown that the precise feature representation of either the nodes or the graphs is the key for the accurate prediction or classification of graphs and their components. For example, the accurate prediction of traffic flow in a road network needs to embed the spatial- temporal features into each node [19]. For another example, the nodes' representative vectors of a stormwater distribution system have also been learned by combining the system topology and the spatial environmental factors, such as the rainfall data and surface runoff. The node's representative vectors are then used for the prediction of node and pipe status, i.e., the magnitude of junction inflows and pipe flow rates [6]. As a special type of complex networks, the SENs have been used to model many real-world physical networked systems. Examples of spatially embedded networks include road networks, water networks, and river networks [20, 21]. For example, stud- ies have observed that many real-world SENs can be modeled by the 'small world' and 'Erd\u0151s-R\u00e9nyi' networks [21]. However, learning the intricate patterns of SENs is still challenging due to the complex interactions between the SENs and the embedded envi- ronments. Both the node properties and edge properties may influence the topologies of SENs in different ways. In order to better learn the intricate patterns of the SENS, a model is expected to have the capability to use all the properties as input and obtain the relationship automatically. For example, recent studies have found that the classifi- cation accuracy of the atom network can be improved when adding the node's position feature into the dataset [22]. Previous studies have also highlighted the influence of road steepness on the walking paths [23]. However, due to the different data types and structures of these features, traditional single-modal learning methods are struggling to learn the representation from multimodal network features simultaneously.\nIn order to tackle the multi-modal challenging in the representation leading of complex SENs, this study develops a generic multimodel graph learning framework, which is named as Generic Multimodal Spatially Graph Convolutional Network (GMu- SGCN). The developed model can efficiently embed different spatial features in to the node's latent represent vectors. Given the flexibility of the developed GMu-SGCN model, two variants of the developed GMu-SGCN model, i.e., the Regional Spatial Graph Convolutional Network (RSGCN) and Edge Spatial Graph Convolutional Net- work (ESGCN), are also introduced. The RSGCN model only considers the network's node related features while ignores features related to the edge. On the contrary, the ESGCN model only considers the edge related features. Two different types of SENS are used in this study to evaluate the performances of considered models. It should be noted that the performance of the RSGCN model has been introduced in the authors' previous study [24]. However, the previous study did not consider the edge features, which is one of the key feature influences the topology of SENs. Moreover, unlike the previous study which used the same testbed for training and testing purposes, this study used two different test beds for training and testing separately. In summary, the contributions of this paper are listed as follows:"}, {"title": "2 Related work and motivation", "content": "Spatially Embedded Networks (SENs) and Network Connection Model- ing. The spatially embedded network is a special type of complex network whose structure is constrained by its embedded spatial environments. A simple synthetic spatially embedded random network can be created by randomly placing the nodes and creating edges based on the nodes' distances [25]. In real world, many natural and man-made network systems show constant patterns [20]. For example, the lengths of infrastructure systems are often limited by construction costs in the real world [26]. Previous studies have observed that the lengths of road segments in a transporta- tion network follow a power-law distribution [27], and the node degree density within a large power system follows a logarithmic distribution [28]. Because of such con- straints, the connection function within such SENs can be modeled mathematically, such as the small-world networks have been used to model the power networks [29], the single-parameter controlled hierarchical planer and spatial networks [30], the tun- able spanning tree [31], and a combination of relative neighborhood graphs (RNG), Gabriel Graphs (GG), and Erd\u0151s-R\u00e9nyi (ER) random graph [32]. Although previous studies have demonstrated the connection functions of SENs follow specific patterns, it is still challenging to identify accurate and efficient network connection models.\nTo better illustrate the concept of SENs and its relationship with the embedded spatial environment, Figure 1 shows an example of SEN and its embedded environ- ment. Specifically, four types of features may influence the connection patterns of the SEN, i.e., the node's point feature x, the node's regional feature r, the node's posi- tion feature pos, and the edge feature e. The node's point feature refers to the spatial feature that located at the node's point, such as the population density, the socioe- conomic data, and geological data of the node's location. Unlike to the node's point feature, the node's regional feature describes a region centered on the node, such as the topography change or soil type change within a specific distance of a node. The node's position feature is considered separately in this study, which refers to the node's"}, {"title": "Deep learning-based network representation learning:", "content": "Recently, the deep learning methods have been emerging and showed more promising performance in various applications. Unlike conventional mathematically modeled methods which use rigorous mathematical equations to describe the SENs' intricate patterns, geomet- ric deep-learning models offer a more flexible and end-to-end learning process, which facilitates network representation and intricate pattern discovery [33]. The deep learn- ing process of the Graph Convolutional Networks (GCNs) can be generally described as Eq. 1, i.e. the node features will be processed by the neurons and then convolved along the edges of the graph. Notable variants of the GCN include the GraphSAGE [15] and Spatial Graph Convolutional Networks (SGCN) [22]. The former architecture introduced advanced sampling strategies for the node's neighbors, resulting in a higher node classification accuracy in multiple datasets. The latter SGCN architecture first introduced the spatial features of nodes into the learning process of a molecular classi- fication task. The GCN and its variants have been receiving more and more attention in spatially embedded networks. For example, a graph attention architecture was used to capture the spatial correlations within traffic networks for traffic flow prediction [3]. The GCNs have also been used in power systems for fault detection, power out- age prediction, power flow simulation, and system control [34]. However, most of the GCN variants were mainly focusing on the features of nodes rather than the edges. Considering the significant influence of both node features and edge features on the spatially embedded networks, there is an urgent need for models that can process such heterogeneous features simultaneously."}, {"title": "Multimodal Data Fusion:", "content": "Multimodal data fusion represents a fundamental method for mining richer information from data with different distributions, sources, and types [35]. Compared to traditional big data, multimodal big data is composed of several modalities to describe the same thing. For example, an image and text infor- mation are often used together to describe an event in a newspaper. The fusion of information from multimodal data can be broadly classified into three groups, the early fusion, late fusion, and intermediate fusion [36]. The early fusion combines features from multi-modalities before the neural network training. For example, the eigenvector can be used as a representative of a data source. Then the combination of eigenvec- tors from multimodal data can be used as input of a traditional classifier, such as a Support Vector Machine(SVM) [37]. On contrary to the early fusion, the late fusion combines information from multimodal data after the training process. For example, after obtaining the prediction results based on each modality data, the final predic- tion can be made by using their averaging values or maximum values [38]. Lastly, in order to construct an end-to-end framework of multimodal learning, the intermedi- ate fusion has been widely proposed. A typical process of intermediate fusion includes three steps, (1) each modality is embedded into a latent space using a neural network layer, (2) the representations of each modality is fused into a single representative, and (3) a joint representation is learned to make a single prediction by using the step 2 as inputs [36]."}, {"title": "3 Methods", "content": "The following sections introduce the developed GMu-SGCN model and the two types of its variants, i.e., the Regional Spatially Graph Convolutional Neural Network (RSGCN) and the Edge Spatially Graph Convolutional Neural Network (ESGCN). In order to evaluate the performance of the developed model, the GMu-SGCN model and its variants are used for predicting the edge existence with given node locations and spatial environment. This section also introduces the developed framework for edge existence prediction."}, {"title": "3.1 GMu-SGCN Model", "content": "The developed GMu-SGCN model aims to provide a fusion learning framework for SENs with the consideration of multimodal features. The framework of the developed model is shown in Figure 2, which includes three main components, the input feature manipulation, the single modal feature processing, and the multimodal feature fusion.\nInput feature processing: Processing the input features is a common approach to improve the neural networks learning efficiency. For example, the feature normal- ization and feature selection are often used before the training process of the machine learning algorithms [39, 40]. For real-world SENs, the relative difference between the nodes' features often plays a more important role than the absolute feature values. For example, the elevation difference between the nodes (grade slope) is more impor- tant than the absolute elevation when designing the road segments [41]. Therefore, in the developed GMu-SGCN model, the node's point feature, regional feature, and position feature, are firstly normalized and then the relative difference is calculated when conducting the convolution process. Specifically, when coevolving the features from a neighbor node v to a target node u, the node's regional and position features of node v are abstracted by that of the node u, as shown in the Figure 2. This step aims to improve the learning efficiency of the neural networks. Experts opinions and domain knowledge can also be incorporated in this process in the future studies.\nSingle feature embedding: After conducting the input feature processing, the processed features are first fed into dedicated neural networks for a shallow feature extraction. Different types of neural network structures can be considered based on the data structures. For example, the fully connected neural networks can be used to extract features from the relative position feature using Eq 2. This equation includes the feature processing described in input feature processing. The edge feature is extracted by another fully connected neural network (Eq. 3). Meanwhile, the 2- dimensional convolutional neural networks can be used to process the relative regional feature (Eq 4), considering the regional feature is a two-dimensional data. In this study, only a single value from the spatial environment is used as the node's point feature. Therefore, this feature is directly fed into the next stage without embedding. For studies with a various number of node's point feature, fully connected neural networks can also be considered, which is similar to the process of feature embedding of node's position feature.\n$p = \\sigma [(P_u \u2013 P_v) W_1]$\nwhere o is the LeakyReLu activation function, pu is the position of node u, and W is the weights of layers.\n$\\bar{p} = \\sigma [e_{k,v} W_1]$\nwhere is the LeakyReLu activation function, eu,v is the edge between node u and node v, and W is the weights of layers.\n$r = \\sigma (r \u00b7 K) (i, j) = \\sigma (\\sum_{k}^{m_1} \\sum_{l}^{m_2} K[k l][i\u2212k,j-1])$\nwhere is the convolved value of the output, K is the kernel window, and r is the input 2-dimensional regional information, i.e., the regional spatial data (a) in this study. m\u2081 is the height of the input data and m2 is its width. i, j are the coordinates of the elements in r.\nMultimodal fusion and graph convolution: After each type of feature is embedded into a shallow representation, the multimodal feature fusion can be achieved by an element-wise multiply operation, as shown in Eq: 5. The feature convolution is then conducted by summarizing of all fused features from the node's neighbors. This convolved feature replaces the original node's point feature. The convolution process can be described by Eq: 6.\n$m=px.r$\nwhere m is the transformed message.\n$\\hat{x} = \\sigma (x^{-1+} \\sum_{j \\in N} m_j)$\nwhere x is the convolved feature of node i at Ith layer, o is the LeakyReLU activation function, mj are the transformed messages from neighbor nodes."}, {"title": "3.2 The variations of GMu-SGCN", "content": "Given the flexibility in feature embedding and multimodal fusion, the developed GMu- SGCN model can be modified to specifically working with only node's features or edge's features. The performance of the model that only considers node features or edge features has also been compared in this study. For the purposes of convenience, the variant that only considers node features is named as Regional Spatial Graph Con- volutional Network (RSGCN) and the variant only considers edge features is named as Edge Spatial Graph Convolutional Network (ESGCN). Notably, the RSGCN model has been introduced in our previous work [24]."}, {"title": "3.3 Link prediction task for SENS", "content": "In order to evaluate the performance and efficiency of the developed GMu-SGCN model and its variants, the link prediction task has been used in this study. Identifying the network connection function is a fundamental challenge in complex networks and crucial task in real-world applications [42]. The link prediction task aims to identify the most efficient model which can learn the network's connection patterns and then accurately predict the edge existence with given nodes. Both statistical and deep learning-based methods have been proposed in previous studies [43, 44].\nThe overall framework of the link prediction task used in this study is shown in the Fig 3. The developed framework contains three major components, i.e., the"}, {"title": "3.4 Model performance evaluation", "content": "The final reconstructed network is resembled by the averaging the prediction results of all samples. As shown in the last component of Fig. 3. The network resemble is only conducted for the test bed dataset. Given the testing SEN has never been used in the training process, the performance of different models can be evaluated by com- paring their resembled accuracies. An edge may exist in multiple subgraphs due to the sampling strategy. In this study, the final edge existence is determined by using the averaged edge existence probability. An edge is classified as existence if the averaged existence probability is higher than a predefined probability threshold. Consequently, this developed resembling process is highly efficient because this strategy automatically excludes edges between nodes that are extremely far apart."}, {"title": "4 Case study", "content": "Two river networks and two power networks are considered in this study. The river networks represent the natural developed systems and the power networks repre- sent man-made infrastructure systems. The following sections provide the detailed information of both SENS."}, {"title": "4.1 River Network", "content": "The river networks located in the Oregon state and California state are selected for the training and testing purposes, respectively. The states of Oregon state and California state are contiguous and located in the west side of the US. Figure 4 shows the overview of the California river network and Oregon river network, respectively. The elevation map of both states have also been visualized. The Oregon river network is used as the training set and the California river network is used as the testing set. The river networks are collected from the US National Weather Service [45]. The digital elevation map is downloaded from the NASA EarthData with a resolution of 30-meters [46].\nThe sampling window size is set at 40km. Figure 5 shows an example of the sampled subgraph. Each subgraph contains four different types of feature that sampled from the digital elevation map, i.e., the node's regional feature, the node's point feature, the edge feature, and the node's position feature. The regional window of each node is set at 1.5km. The elevation change within this window is used as the node's regional feature. The node's elevation value is used as the node's point value. In addition, 128 elevation"}, {"title": "4.2 Power Network", "content": "The New Jersey and the Connecticut are two states the located in the eastern part of the US. The transmission network data from both states is obtained from the Homeland Infrastructure Foundation-level Data (HIFLD) [47], which contains the national-wide transmission network varying from 69 kV up to 765 kV. The original graph is cleaned by merging close and parallel lines into a single line. The sampling window size is 20km. Figure 6 shows the overall map of the New Jersey power net- work and the Connecticut power networks with the digital elevation information. The New Jersey network is used as the training data and the Connecticut network is used as the testing data."}, {"title": "5 Results and Discussion", "content": ""}, {"title": "5.1 Evaluation", "content": "The considered models are compared by the edge existence prediction performance. Given the edge existence prediction is essentially a binary classification problem, the F1-score and accuracy are used for the evaluation purposes.\nEq. 7 shows the definition of the F1-Score, where the True Positive (TP) represents the edges that are originally existent and also predicted as existent. The True Negative (TN) represents the edges that were originally non-existent and also predicted as non- existent. The False Positive (FP) represents the edges that are originally non-existent but predicted as existent. And the False Negative (FN) represents the edges that are originally existent but predicted as non-existent. The Fl-score evaluates the average performance of the model on the prediction of positive and negative classes.\n$F1 = \\frac{TP}{TP + (FP + FN)}$\nThe existence accuracy represents the percentage of original edges which are accu- rately predicted, which can be mathematically represented by Eq. 8. The pred(ei) equals to 1 if the edge is predicted as 'existence', otherwise pred(ei) equals to 0. Com- pared to the Fl-score metric, this metric only evaluates the accuracy of the prediction results of the positive class.\n$acc = \\frac{\\sum_{1}^{n} pred(e_i)}{n}$\nwhere n is the number of total edges in original SEN."}, {"title": "5.2 Prediction results of the River Network", "content": "Fig 7 shows the reconstruction results of the river network located in California by the considered models. Only edges whose predicted existent probability higher than 0.5 are plotted. It can be seen that all considered models have certain level of capability to reconstruct the river network. In addition, most edges are predicted with a higher probability (larger than 90%) by all considered models. Only a few of the edges are predicted with a probability lower than 60%. Fig: 7 also shows the GMu-SGCN model has the lowest uncertain edges compared to other models. Only a few edges are predicted with a probability that lower than 90%. In addition, the predicted network has fewer false positive edges, compared to that of RSGCN, ESGCN and GraphSAGE. The network reconstructed by the GMu-SGCN model is more similar to the original network as shown in Figure: 4 (a).\nThe models have also been evaluated by using the Fl-score and accuracy as dis- cussed in section 5.1. The Fl-score evaluates the accuracy of the prediction of both"}, {"title": "5.3 Reconstruction results of the Power Network", "content": "As aforementioned, the NJ power network is used as the training set and the CT power network is used as the testing set. Figure 9 (a) shows all potential edges of CT power network based on the sampling method, as described in section 3.3. It can be seen that only nodes within the distance of sampling window size are potentially connected. The idea of this sampling aligns with many observed connection patterns in spatially embedded networks. Figure 9 (b) shows the final reconstruction results by GMu-SGCN model. Only the edges whose predicted existence probability higher than 0.5 are visualized. Similar to the river network, most of the edges are predicted with a higher confidence (higher than80%). Only a few edges are predicted with a relative low confidence (50% to 60%).\nThe performance of all the considered models is also summarized in Fig 9. It can be found that the developed GMu-SGCN model outperforms the other models. For example, the fl-score of the GMu-SGCN model is 37.1 % higher than the worst per- formance model, ESGCN. It is 1.13% higher than the second-best model, the RSGCN"}, {"title": "6 Conclusion", "content": "In this study, a generic multimodal graph convolutional neural network is developed for efficient network representation learning. Given the flexibility of the developed GMu-SGCN model, two variants have also been designed, i.e., the RSGCN model and ESGCN model. The former model only embeds the node's multimodal features, whereas the later model only considers the node's edge features. The network connec- tion prediction task was conducted to evaluate the models' performance. Specifically, each model was used to embed various node and edge features into latent vectors of nodes, and then the edge existence probability is predicted by using these latent vectors. Two real-world spatially embedded networks, the river networks and power networks have been used as the test beds. The results show that the developed GMu-SGCN model outperformed the other models in all test beds. Specifically, the GMu-SGCN model outperformed the GraphSAGE model, a widely used GCN model, 12.3% in river network test bed and 37.1% in the power network test bed. Further- more, the RSGCN variant and ESGCN variant are the second-best model for river network and power network, respectively. This result indicates that the connection of river network relies more on their edge features, whereas the connection of power network relies more on the node features.\nAlthough the developed models can efficiently learn the representation of the con- sidered SENs, there are some limitations which should be considered in the future studies. Firstly, the existence of all edges in the sample graphs are predicted simulta- neously. Although this approach is computational efficient, it does not predict the edge existence in a sequential approach as traditional methods. As a result, this approach cannot leverage the connection patterns of previous established edges, and it also can- not guarantee all nodes within a graph are connected. However, it should be noted that this approach can reduce the accumulated errors that existed in previous methods. The second limitation is that the developed method assumes the nodes' positions are known. However, such information is often missing in many real-world applications. Further studies should integrate the prediction of nodes into the developed framework."}]}