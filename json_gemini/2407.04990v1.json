{"title": "Conditional Semi-Supervised Data Augmentation for Spam\nMessage Detection with Low Resource Data", "authors": ["Ulin Nuha", "Chih-Hsueh Lin"], "abstract": "Several machine learning schemes have attempted to perform the detection of spam messages. However, those\nschemes mostly require a huge amount of labeled data. The existing techniques addressing the lack of data availability\nhave issues with effectiveness and robustness. Therefore, this paper proposes a conditional semi-supervised data\naugmentation (CSSDA) for a spam detection model lacking the availability of data. The main architecture of CSSDA\ncomprises feature extraction and enhanced generative network. Here, we exploit unlabeled data for data augmentation\nto extend training data. The enhanced generative in our proposed scheme produces latent variables as fake samples\nfrom unlabeled data through a conditional scheme. Latent variables can come from labeled and unlabeled data as the\ninput for the final classifier in our spam detection model. The experimental results indicate that our proposed CSSDA\nachieves excellent results compared to several related methods both exploiting unlabeled data and not. In the\nexperiment stage with various amounts of unlabeled data, CSSDA is the only robust model that obtains a balanced\naccuracy of about 85% when the availability of labeled data is large. We also conduct several ablation studies to\ninvestigate our proposed scheme in detail. The result also shows that several ablation studies strengthen our proposed\ninnovations. These experiments indicate that unlabeled data has a significant contribution to data augmentation using\nthe conditional semi-supervised scheme for spam detection.", "sections": [{"title": "Introduction", "content": "The growth of deep learning has penetrated various field studies. In recent years, the contribution of deep learning\nhas presented a significant impact resulting in state-of-the-art image processing and natural language processing (NLP)\nThe development of NLP specifically has undergone very rapid progress.\nNLP has various primary tasks such as text classification, natural language inference, text generation, and others. Then, one of the significant tasks in NLP applications is spam detection or\nclassification. Spam is a message having the aim of any prohibited aim such as fraud, fake news, promotion, and\nothers. Many spam messages often come to us through\nemail or mobile messages. Based on the DataProt reports, 56.5% of incoming emails in 2022 were categorized as\nspam. Therefore, unwanted messages such as spam or scam are critical to be filtered.\nVarious studies related to spam detection have been conducted by researchers using NLP approaches. One of the\ncrucial parts of NLP to perform various tasks lies in text representation and end-to-end training. Text\nrepresentation makes the computer understand text-based data by representing them in numerical form. Whereas end-\nto-end training is a deep learning technique where the model learns and trains all the steps simultaneously. A work of\nspam detection conducted by Galeano (2021) on short messages exploited several text representation schemes such\nas bidirectional encoder representations from transformers (BERT) or Bag-of-Words (BoW) and various classifiers\nfor final classification. Then, the result showed that the best text representation is BERT outperforming other text\nrepresentation models. Ahmed et al. (2022) performed a survey to find the best machine learning model for classifying\nspam emails. They revealed that excellent machine learning algorithms to filter those emails are support vector\nmachine (SVM), Na\u00efve Bayes, and logistic regression. Another spam detection scheme introduced by Yerima and\nBashar (2022) proposed semi-supervised spam message classification using one-class SVM (OC-SVM) that only\ntrained non-spam messages. Their proposed scheme outperformed the supervised learning with vectorization methods\nof text representation.\nHowever, there are several challenges encountered by researchers in the spam detection task. The availability of\ndata is one of them. Most schemes that performed the spam detection tasks utilized supervised learning for their\napproaches. Whereas supervised learning necessitates extensive labeled data to attain a robust\nmodel. On the other hand, the availability of labeled data becomes one issue, especially in"}, {"title": "", "content": "other than English such as the Indonesian language. Finding large-scale labeled data will be expensive and time-\nconsuming. Therefore, we introduce data augmentation to overcome those mentioned issues. To extend the training\ndata, we then exploit unlabeled data that are easier to obtain.\nFinally, this paper proposes conditional semi-supervised data augmentation (CSSDA) for spam detection. We\nwill address the issue of the lack of availability of labeled data in spam messages. The main architecture of our\nproposed model is a deep generative model based on adversarial learning. Here, our proposed model results in latent\nvariables as fake samples from unlabeled data. While real latent variables come from labeled data representation\nfeatures combined with its label embedding. Then, these latent variables become the input for the final classifier. We\nintroduce latent variables rather than text representation features as generated data since unlabeled and labeled data\npossess a similar distribution, the difference is only that the labeled data have extra information related to their\nannotation. In addition, CSSDA performs the conditional generative model to create the latent\nvariable influenced by the label embedding. Thus, the resulting synthetic data is not divergent from real data\ncharacteristics. Then, a discriminator acting as the classifier will identify whether the input is real or fake samples.\nHere, the discriminator also categorizes input samples into the related class if the input is real latent variables. To\nminimize vanishing gradient and bias-shift error, we perform derivation of the unsupervised loss during the training\nprocess explained in the third section.\nBased on the above analysis, the major contributions of our study are listed as follows:\nThis study proposes a detection model for spam messages that lack the availability of labeled data.\nOur main framework is a conditional semi-supervised deep generative model exploiting unlabeled data to extend\ntraining data.\nWe introduce the latent variable as generated synthetic data to implement conditional generation.\nWe report the result comparison between our proposed model and several counterpart models in performing\nspam detection in Indonesian Short Message Service (SMS) datasets.\nThe rest of this paper is organized as follows. In Section 2, we present several related works. We illustrate the\nbasic theory and framework of our proposed model in Section 3, and our proposed model will be presented in detail.\nSection 4 presents the experimental results and analysis of the results. Finally, Section 5 concludes this study."}, {"title": "Related work", "content": "There are several proposed schemes to overcome the lack of labeled data. One of them is data augmentation, a\nscheme utilizing a particular algorithm to generate new synthetic data from the available data. However, the implementation of data augmentation in NLP is more complicated than in image\nprocessing. Since the image originally is composed of individual pixels represented in numeric form, the data\naugmentation can be performed by adding some noises, translation, color space transformation, and others without\nlosing the critical information. In discrete data such as text processing, the data augmentation encounters difficulties\nduring the sampling process. Alkadri, Elkorany, and Ahmed (2022) conducted data augmentation\nfor the labeled spam in Arabic tweets. Their scheme randomly substitutes several words into their synonyms based on\nsimilarity. They performed the replacement of word tokens based on the similarity score also considering the\nsurrounding words. They changed about 60% of word tokens from the original data to generate new sentences.\nHowever, the data augmentation by synonym replacement has lacked generating new linguistic features, because their\nsentence structure is the same between the synthetic and original data. Another scheme to overcome the lack of labeled\ndata is unsupervised data augmentation (UDA) based on consistency training. Xie et al. (2020) introduced UDA to\naddress the lack of labeled data exploiting unlabeled data. The use of unlabeled data is for performing unsupervised\nconsistency training. They augmented unlabeled data through simple-noising operations such as back-translation.\nTheir proposed scheme tries to minimize unsupervised consistency training loss between unlabeled data and noised\nunlabeled data.\nAnother of the influential state-of-the-art works to augment data is generative adversarial networks (GAN) . The GAN model has two primary components, they are generator and discriminator which perform\nadversarial learning. The generator will generate some synthetic data based on real data distribution, whereas the\ndiscriminator distinguishes whether the coming input is real samples or fake samples . The generator\nwill try to fool the discriminator with its generated samples. Then, the discriminator should be able to detect that the\ngenerated sample from the generator is fake. A standard GAN in an image processing task can be extended by adding\nsome extra information in the generator or the discriminator as a conditional scheme . The extra information added to both components can be data labels or other modalities. For example,\nthe noise vector and the extra information are utilized as the generator inputs. Their experiment in applying the\nconditional GAN in image processing tasks showed promising results. However, the GAN model is quite complicated"}, {"title": "", "content": "to be implemented in text-based data since GAN is only introduced to result in real-numeric values, especially in\nimage processing. The generative model in text processing has a main\nchallenge in the discrete state space issue .\nCroce, Castellucci, and R. Basili (2020) proposed GAN-BERT performing text classification tasks in few labeled\ndata. Their model exploits an improved GAN scheme proposed by Salimans et al. (2016), implemented originally for\nimage-processing tasks. In this improved GAN model, the role of the discriminator does not only distinguish whether\nthe inputs are real or fake samples but also classifies them into related classes if the inputs originally are labeled data.\nThen, GAN-BERT brought this improved GAN model into text classification by adding BERT architecture to extract\ntext representation features. Although GAN-BERT performance outperforms the standard BERT model, the\nperformance immediately will be overcome by the standard BERT model if the availability of the labeled data\nincreases. Then, Riyadh and Shafiq (2022) proposed GAN-BElectra extending the GAN-BERT architecture to give\npseudo labels of the unlabeled data. Then, labeled data and unlabeled data that already received the pseudo labels were\ntrained using an Electra-based pre-trained model. However, the performance of text classification using GAN-\nBElectra was not satisfied. Based on these previous works, existing machine learning models perform spam detection\nthat relies on huge training data. Other methods that perform data augmentation did not utilize unlabeled data more\nadvanced."}, {"title": "Methods", "content": "In this section which first introduces the research objectives, we describe the basic method applied in conditional\nsemi-supervised data augmentation using deep generative model for text classification tasks. In addition, the training\nprocess of our proposed model is discussed."}, {"title": "Research objective", "content": "As discussed in Section 2.2, text classification including spam detection using machine learning has some\nchallenges since this task requires a large amount of labeled data, that is frequently difficult and costly to acquire. By\ninvestigating the previous studies, we reveal that data augmentation is a precise approach to address this issue by\nexpanding training samples. However, applying data augmentation in the machine learning model does not guarantee\nimproving the model's performance. Consequently, our first research objective is to develop a robust\nscheme for scientific text classification of spam messages with limited labeled data. Additionally, to enhance the"}, {"title": "Framework of the proposed model", "content": ""}, {"title": "Our proposed model architecture", "content": "The architecture of our proposed model is shown in Fig. 1. Here, our proposed CSSDA exploits both unlabeled\ndata and labeled data to perform semi-supervised data augmentation for spam message detection. Before we bring text\ndata to the generator or discriminator, we need to transform the message into a vector hcLs of sentence-level\nrepresentation. Sentence-level representation is the numerical feature vector of the message texts so that the computer\ncan understand the text data. In our proposed model, we utilize transformer-based encoder, i.e., BERT and its variant,\nas the text representation model. BERT is a pre-trained model that learns linguistic information from the corpus during\nthe pre-training process using deep learning schemes. Given a sentence t = (w1, ..., wn), BERT will generate an output\nin n + 2 vector representations, i.e., (hcLS, hw1, ..., hwn, hSEP).\nThen, the sentence-level representation of the unlabeled message will be input for the generator to produce the\nfake label yfake. Our proposed CSSDA employs the generator to produce an embedding of fake label yfake, instead of"}, {"title": "Text data representation", "content": "We select the Transformer-based model as the representation model of the texts to obtain the feature vector such\nas BERT and its variant. The original model of BERT is a multi-layer stack of Transformer encoders. The model\nutilizes the encoders to learn the sequence information, bidirectionally. The BERT model attains state-of-the-art in\ndiverse NLP tasks since it proposed two schemes during the pre-training process. They are masked language modeling\n(MLM) mechanism and next sentence prediction (NSP) mechanism."}, {"title": "Conditional generative model", "content": "The generator architecture basically is a multi-layer perceptron (MLP) with the input coming from the vector hCLS\nof the representation of unlabeled messages. In particular, the multi-layer perceptron in the generator is one hidden\nlayer with a leaky rectified linear unit (ReLU) as the activation function. Then, a dropout is applied after this hidden\nlayer to minimize overfitting. The vector dimension of the embedding of fake label yfake is 768- dimension such as\nBERT output dimension size. As shown in Fig. 1, we multiply the embedding of the fake label yfake and the\nrepresentation vector of the unlabeled message hcLs with the element-wise operation to generate fake latent variable\nVfake as conditional data generation.\nAfterward, the discriminator is basically also the multi-layer perceptron that consists of one hidden layer with the\nleaky-ReLU as the activation function and a softmax layer as the final layer. The discriminator inputs are the fake\nlatent variable vfake and the real latent variable vreal. The real latent variable vreal is obtained by the representation vector\nof the labeled message hcLs multiplied with the embedding of real label yreal in the element-wise operation. The use of\nthe real label combined with the vector representation is to control the model when generating fake data. Thus, the\ngenerated fake data have an imminent similarity to the real data distribution through adversarial learning. In the testing\nprocess, the CSSDA model relegates 1 + k label as the final class."}, {"title": "The proposed semi-supervised learning", "content": "Let us assume, pa and pg respectively represent the real latent variable distribution and the generated or fake latent\nvariable distribution. We define p\u201e(y = y | v, y = k + 1) as the probability from the model m where the latent variable\nv is attributed to the fake class. While p\u201e(y = y|v, y = 1,...,k) is the probability that the latent variable v is associated\nwith real data belonging to the one of k real classes. In the relationship between the generator and the discriminator,\nthere is a competition called adversarial learning in which the generator tries to deceive the discriminator, and the\ndiscriminator attempts to distinguish whether the input data are real or not. To optimize adversarial learning, the lost\nfunction comes from the generator and the discriminator. Since the proposed model in this study performs semi-\nsupervised learning, the loss function comprises supervised loss and unsupervised loss. Then, we formulate the\ndiscriminator loss LD as a summation of the discriminator's supervised loss LDsup and the discriminator's unsupervised\nloss LDunsup. The discriminator's supervised loss calculates the prediction error of the model in classifying the class of\nlabeled data. The expected value (E) of discriminator's supervised loss LDsup can be formulated as follows:\n$L_{D sup} = -E_{v,y~Pd} [log p_{m}(y = y | v, y \u2208 {1,...,k})]$,\nwhere v is the input for the discriminator assumed from the real latent variable. Then, the discriminator as the classifier\nwill output a class among the k classes. Since the original output is in the form of a k-dimensional vector of logits, we\napply the cross-entropy loss function between the actual label y and the predictive distribution (y = y|v).\nThen, the discriminator's unsupervised loss LDunsup calculates the error in incorrectly detecting the real latent\nvariable as fake and not recognizing the fake latent variable. The discriminator's unsupervised loss LDunsup can be\nformulated with the following equation:\n$L_{Dunsup} = -E_{v~Pd}[log(1\u2013 p_{m} (y = y | v, y = k + 1))]\u2013 E_{v~Pg} [log p_{m} (y = y | v, y = k + 1)],$\n$L_{Dunsup} = -E_{v~Pd} log D(v_{real}) \u2013 E_{v\u223c pg} log(1 \u2013 D(v_{ fake})),$\nwhere we substitute 1-pm(y=k+1) in Eq. (2) to D(v) in Eq. (3). D(v) is the softmax function operation over the k-\ndimensional logits and a vacant logit lk+1(v) of the fake class. Then, we set the logit of the fake class lk+1(v) to 0 (zero)\nresulting in e=1 since this vacant logit has no impact to the output of k classes (Salimans et al., 2016). The\ndiscriminator D(v) can be represented as follows:"}, {"title": "", "content": "$D(v) = -\\frac{Z(v)}{Z(v)+1}$\n$Z(v) = \\sum e^{l(v)}$\nBased on the equations above, Eq. (3) can be substituted through Eqs. (4) and (5) as below:\n$L_{Dunsup} = -E_{v~Pd} log \\frac{Z(v_{real})}{Z(v_{real})+1}  -E_{v~Pg} log 1-\\frac{Z(V fake)}{V fake) +1}$,\n$L_{Dunsup} = -E_{v~Pd} log Z(v_{real}) + E_{v}- E_{v~ Pd} log(Z(v_{real}) + 1) + E_{v\u223c pg} log(Z(v_{ fake}) + 1)$,\n$L_{Dunsup} = -E_{v~Pd} log e^{l(v_{real})} + E_{v}- E_{v\u223c Pd} log(e^{l(v_{real})} + 1) + E_{v~pg} log(e^{l(v_{ fake})} +1)$.\nThen, we introduce the Softplus function, a soft approximation of the ReLU function, to Eq. (8). In the Softplus\nfunction, the output will always be in the form of positive values. Since the Softplus function can be distinguished in\na range of (-\u221e, +\u221e), it can perform backpropagation of the gradient across the range (Zhao et al., 2017). Thus, the\nSoftplus function generates close real characteristics and can control vanishing gradient and bias-shift error. Since the\nSoftplus function is formulated in Softplus(x) = log (exp(x) + 1), Eq. (8) can be expressed in Eq. (9) as following:\n$L_{Dunsup} = -E_{v~Pd} log e^{l(v_{real})} + E_{v\u223cPd} Softplus(e^{l(v_{real})}) + E_{v~pg} Softplus(e^{l(v fake)})$.\nOur proposed model also formulates the generator loss LG as the summation of the generator's feature matching\nloss LGfm and the generator's unsupervised loss LGunsup. The generator's feature matching loss LGfm is presented to\ncalculate how the generator forms latent variables approximating the statistics of real latent variables. In other words,\nthe generator has to attempt to form fake samples as similar as possible to the expected value (E) of characteristics of\nthe real latent features in the discriminator intermediate layer. Let's define f(v) as the activation of the discriminator\nintermediate layer, the formula for the generator's feature matching loss LGfm is expressed below:\n$L_{Gfm} = criterionG(E_{v~Paf} f (v_{real}), E_{v\u223cp} f (v_{ fake})),$\nwhere we define criterionG as a parameter to calculate the generator's feature matching loss. We practically utilize\nmean squared error (MSE) as criterionG. Since there is adversarial learning between the generator and the\ndiscriminator through a backpropagation scheme, our proposed model also considers the unsupervised loss of the\ngenerator. The generator's unsupervised loss LGunsup computes the error of the fake latent variable that correctly is\nidentified by the discriminator. This loss function has a similar process to the unsupervised loss of the discriminator\nbut ignores the error in detecting the real latent variable. The generator's unsupervised loss LGunsup can be formulated"}, {"title": "", "content": "in Eqs. (11-15) below:\n$L_{Gunsup} = -E_{v~pg} [log(1\u2013 p_{m} (y = y | v, y = k + 1))],$\n$L_{Gunsup} = -E_{v~pg} log D(v_{ fake}),$\n$L_{Gunsup} = -E_{v-pg} log (v_{jake})+1)$\n$L_{Gunsup} =-E_{v~pg} log Z(v_{ fake}) + E_{v~pg} log(Z(v_{ fake} +1)$,\n$L_{Gunsup} = -E_{p} loge (Jake) + E_{V~Pg} Softplus((fake))."}, {"title": "Experimental evaluation and discussion", "content": "In this section, we will mainly evaluate the performance of our proposed model, i.e., CSSDA, and compare it\nwith several counterpart models. In addition, this section also conducts several ablation studies to identify the effect\nof each component on CSSDA performance."}, {"title": "Datasets and setup", "content": ""}, {"title": "Datasets", "content": "We take Indonesian SMS datasets to build spam detection from Rahmi and Wibisono (2016) and Tandra et al.\n(2021). We select Indonesian SMS texts as the dataset since the labeled data in this language lacks the availability.\nThe labeled SMS datasets consist of three labels, they are spam, promo, and normal messages. Spam messages contain"}, {"title": "Experimental setup", "content": "For the text representation model, we exploit the pre-trained Transformer-based model with 768-dimensional\nembeddings. Then, we set the batch size to 64 and the epoch size to 5 during the training process since the number of\ndata training is quite a lot. As the labeled SMS datasets have three categories, i.e., spam, promo, and ham (normal), \nwe set the k value = 3 (three) for the discriminator parameter. In the training process, we perform three training\nschemes to evaluate the robustness and consistency of the model in various amounts of unlabeled data. For the first\nscheme, we set training data in which 0.25 of training data is labeled data and the rest is unlabeled data. Then, the\nsecond scheme utilizes the unlabeled data same as the number of labeled data for the training process with the ratio of\n0.5:0.5 of training data. Lastly, we set training data for the third scheme in which 0.75 of training data is labeled data\nand the rest is unlabeled data."}, {"title": "Evaluation metrics", "content": "Since the amount of data in each class of datasets is not balanced, we utilized precision, recall, balanced accuracy, and F-score as evaluation metrics that are significant rather than standard accuracy (Bej et al., 2021; Ding et al., 2023).\nPrecision can be regarded as a measure of the model to identify only relevant data points, while recall is a measure of\nthe model to identify all relevant cases within the dataset. Balanced accuracy is the average of the correct prediction\nrates for each class separately. Then, the F-score is a harmonic mean score between precision and recall values. The\nformulas of the evaluation metrics are as follows:\n$precision=\\frac{TP}{TP+FP}$\n$recall=\\frac{TP}{TP + FN}$\n$balanced\\_accuracy=\\frac{1}{2} [\\frac{TP}{TP+FN} + \\frac{TN}{TN+FP}]$\n$F-score = \\frac{2\\times precision\\times recall}{precision+recall}.$\nwhere TP (true positive) is a scenario in which the model accurately identifies the positive class. FP (false positive)\nis a condition in which the model incorrectly identifies the positive class. FN (false negative) occurs when the model\nincorrectly identifies the negative class. Then, FN (false negative) is the result when the model incorrectly identifies\nthe negative class."}, {"title": "Performance comparison", "content": "To assess the performance of our proposed model in spam detection with the lack of availability of labeled data,\nwe conduct the performance comparison with several counterpart models. We present the performance comparison in\nseveral state-of-the-art algorithms using both machine learning and deep learning. In the machine learning approach,\nwe take several algorithms presented by Abid et al. (2022). They are SVM, random forest, and logistic regression as\nthe classifier while using the term frequency-inverse document frequency (TF-IDF) model as the text representation\nthat is based on the vectorization method. However, the machine learning approach only exploits the labeled data\nsince it does not perform data augmentation. The results of machine learning models for spam detection are presented\nin Table 2 in which we set all training data as labeled data. The results show that machine learning models\nunderperform in message classification since there is no model achieving a metric score of more than 60%. We argue\nthese machine learning models cannot address the prediction on testing data with large samples."}, {"title": "Ablation study on data augmentation", "content": "Since our work proposes the deep learning model along with data augmentation, the proposed model also exploits\nthe unlabeled data. In this ablation study, we will assess how the deep learning model performs the task of spam\ndetection but without performing data augmentation. Therefore, we utilized the BERT-MLP model for the counterpart\napproach as also proposed for spam detection in Fahfouh et al. (2022). The model utilizes the BERT model as text\nrepresentation and MLP as the classifier. The result will answer whether the data augmentation can improve the\nperformance of spam detection or not. Table 7 shows the result comparison of this ablation study between the standard\nBERT-MLP model without data augmentation and our proposed model that exploits all unlabeled data for data\naugmentation. We set half of training data in labeled data and the rest is unlabeled data. We can see that the non-data\naugmentation approach of the BERT-MLP model fails to outperform our proposed model in all evaluation metrics\ncompared. This indicates that the data augmentation approach in our proposed model can enhance the performance of\nspam detection."}, {"title": "Ablation study on conditional generative model", "content": "The generative scheme in our proposed model aims to form the fake latent variable instead of fake text\nrepresentation features. Therefore, CSSDA can control latent variable features through element-wise multiplication\nbetween label embedding and message representation feature vectors. We compare the performance of the conditional\ngenerative model with the generator that only produces text representation features with noise as the input of the"}, {"title": "", "content": "generator. Here, we set half of training data to labeled data and the rest is unlabeled data to perform this ablation study.\nIn this experiment, we set our proposed model with the conditional generative adversarial network, and without it.\nTable 8 shows the result comparison of the ablation study on the conditional generative model. The result indicates\nthat the proposed model exploiting the conditional scheme can improve performance. Through the conditional\ngenerative, generated data characteristics are forced to have similarity to real data characteristics. This paper performs\nthe conditional generative scheme by forming the fake latent variable from the combination of sentence representation\nvector hCLS with the fake label from the generator."}, {"title": "Ablation study on loss derivation", "content": "In our proposed CSSDA, we perform substituting and derivation schemes for unsupervised loss both for the\ngenerator and the discriminator. This ablation section presents the counterpart model that does not substitute and\nderives Eq. (2) from the discriminator's unsupervised loss and Eq. (11) from the generator's unsupervised loss. Our\nproposed model implementing loss derivation achieves the best result by achieving scores of about 85% in all metrics\nas shown in Table 9. When our proposed model does not implement loss derivation in Eq. (2) and Eq. (11), the\nperformance result of evaluation metrics cannot even exceed values of 70%. The findings from this ablation study\ndemonstrate that incorporating loss derivation into the unsupervised loss of both the discriminator and generator\nsignificantly enhances the performance of spam message detection in our work. This notable improvement in our\nproposed model is due to the use of the Log-Sum-Exp (LSE) function in Eqs. (8) and (15), which effectively addresses\nunderflow and overflow issues."}, {"title": "Conclusion", "content": "In this paper, we presented a conditional semi-supervised data augmentation, i.e., CSSDA. The primary goal of\nthis paper is to address the lack of availability of labeled data for spam detection. The proposed model introduces the\nfusion of conditional generation and semi-supervised data augmentation. Our approach in data augmentation exploits"}, {"title": "", "content": "unlabeled data not only for improving the training inconsistency but also for enhancing the model's final classifier. In\naddition, we also perform the derivation of unsupervised loss to minimize vanishing gradient. The extensive\nexperimental results indicate that the proposed CSSDA outperforms counterpart models. Study ablation also shows\nand strengthens the excellent performance of our proposed model. Thus, our proposed CDDA can address the lack of\ndata availability in the spam detection model by exploiting unlabeled data. There is a potential limitation of this paper.\nThat is, our model relies heavily on the content information provided by text data, not non-content-based features such\nas sender behaviors. Nevertheless, we assert that spam detection remains a persistent challenge, and the\naforementioned limitation does not diminish our paper's contribution. In future work, we will expect to extend our\nmodel not only for classification tasks but also for more complex tasks such as question answer and others."}]}