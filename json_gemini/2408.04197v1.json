{"title": "PAIRWISE JUDGMENT FORMULATION FOR SEMANTIC EMBEDDING MODEL IN WEB SEARCH", "authors": ["Mengze Hong", "Chen Jason Zhang"], "abstract": "Semantic Embedding Model (SEM), a neural network-based Siamese architecture, is gaining momentum in information retrieval and natural language processing. In order to train SEM in a supervised fashion for Web search, the search engine query log is typically utilized to automatically formulate pairwise judgments as training data. Despite the growing application of semantic embeddings in the search engine industry, little work has been done on formulating effective pairwise judgments for training SEM. In this paper, we make the first in-depth investigation of a wide range of strategies for generating pairwise judgments for SEM. An interesting (perhaps surprising) discovery reveals that the conventional pairwise judgment formulation strategy wildly used in the field of pairwise Learning-to-Rank (LTR) is not necessarily effective for training SEM. Through a large-scale empirical study based on query logs and click-through activities from a major commercial search engine, we demonstrate the effective strategies for SEM and highlight the advantages of a hybrid heuristic (i.e., Clicked > Non-Clicked) in comparison to the atomic heuristics (e.g., Clicked > Skipped) in LTR. We conclude with best practices for training SEM and offer promising insights for future research.", "sections": [{"title": "1 Introduction", "content": "With the increasing awareness of the importance of latent semantics within text [14, 21, 23], the Semantic Embedding Model (SEM) attracts lots of attention from the information retrieval and natural language processing [4, 5, 28]. For the purpose of Web information retrieval, SEM is trained based on the search engine query log, which consists of queries, search results, and the record of a variety of user activities [15]. In practice, the queries and search results (i.e., the titles of the retrieved Web pages) are utilized to compose pairwise training instances. Formally, for a query q, if a title pq is preferred to a title nq by the user, they are formulated as a pairwise judgment pq > nq, based on which SEM is trained in order to increase the similarity of (q, pq) and the dissimilarity of (q, nq).\nA crucial issue of training SEM is to automatically formulate high-quality pairwise judgments, i.e., how to infer the user's implicit preference based on the query log. The same problem is intensely studied in the field of pairwise Learning-to-Rank (LTR) [7, 20, 24]. Researchers propose an effective strategy for deriving pairwise judgment based on heuristics, which is inspired by the examination and click-through activities of users [11]. The core of these heuristics is to eliminate noise and position bias from the query log. Specifically, the heuristics proposed in [7, 20, 24] assume that a clicked document with the current query is preferred over an examined but not clicked document. With the intensive study of this topic in LTR, there exists little work on pairwise judgment formulation for embedding-based models such as SEM. Hence, it is interesting to study whether the well-established heuristics in LTR can be successfully applied to generate pairwise judgements for SEM."}, {"title": "2 Related Work", "content": "Formulating pairwise judgments is well-studied in pairwise LTR. Radlinksi et al. [24] proposed an approach to learning ranked retrieval functions by deriving pairwise judgment from a series of queries. Joachims et al. [20] examined the reliability of implicit feedback from click-through data in Web search. They show that preferences derived from user clicks are reasonably accurate, particularly when comparing results from the same query. The heuristics proposed in [20, 24] are widely used in conventional LTR scenarios.\nSearch engine users' browsing patterns are also intensively studied in the field of click models. Chapelle et al. [2] consider click logs as an important source of implicit feedback. They proposed a Dynamic Bayesian Network which aims at providing unbiased estimation of the relevance from the click logs. A personalized click model is proposed in [25] to describe the user-oriented click preferences, which applies and extends tensor factorization from the view of collaborative filtering. [3] proposed a Noise-aware Clicked Model by characterizing the noise degree of a click. With their individual differences, almost all click models assume that search engine users sequentially browse the results from top to bottom and click some results if they are perceived as relevant. This assumption is strictly aligned with those studied in [20].\nIn recent years, learning semantic embedding has attracted lots of research attention. For example, Huang et al. [6] developed deep structured semantic model that projects queries and documents into a common low-dimensional space where the relevance of a document given a query is readily computed as the distance between them. The proposed model is discriminatively trained by maximizing the conditional likelihood of the clicked documents given a query using the click-through data. Shen et al. [26] developed a variant of the deep structured semantic model by incorporating a convolutional-pooling structure over word sequences to learn low-dimensional, semantic vector representations for search queries and Web documents. Recently, SEM has been proposed in [28] and is considered to be a more efficient model for learning semantic embedding. The major difference between SEM and its counterparts is the use of hinge loss with pairwise training paradigm rather than softmax-based loss functions. Hence, training SEM is typically more efficient since it does not need to conduct backpropagation for every training instance. With the success of SEM and its related models in the search engine industry [22, 27], there is surprisingly little work on studying the best approach for deriving training data for them. To the best of our knowledge, this work presents the pioneering effort to study the strategies of formulating pairwise judgments for training SEM."}, {"title": "3 Prerequisites", "content": "In Section 3.1, we discuss the basic knowledge of semantic embedding model. In Section 3.2, we introduce the terminology that is utilized for describing the pairwise judgments. In Section 3.3, we describe the dataset that is used in our experiments."}, {"title": "3.1 Semantic Embedding Model for Web Search", "content": "In this subsection, we first elaborate the architecture of SEM and then we detail how to optimize its parameters."}, {"title": "Architecture", "content": "Inspired by the work in [28], we describe how the Semantic Embedding Model (SEM) works for information retrieval scenario. The architecture of SEM is shown in Figure 1. A hinge loss $\\mathcal{L}$ is used for training:\n$\\mathcal{L} = \\frac{1}{m} \\sum_{i=1}^m (cos(f(q_i), f(P_{q_i})) - cos(f(q_i), f(n_{q_i})))$ (1)\nwhere m is the amount of training instances, cos indicates cosine similarity and the function f(\u00b7) indicates the mapping from a query or a Web page title to a semantic embedding.\nAs shown in Figure 1, the bottom layer are the word embeddings. Through adding the embedding of words in query in an element-wise fashion, we obtain an intermediate representation of the query. If we denote x as the input word embedding, j = 1, ..., N as the term index of query, h as the intermediate representation of query, and i as the element id of h, then we have\n$h_i = \\sum_{j=0}^N x_i$ (2)\n$g_i = softsign(h_i) = \\frac{h_i}{1 + |h_i|}$ (3)\nThen the intermediate representation goes through fully-connected neural network layers and is mapped to a final embedding. We denote O as the final embedding, W as the fully-connected neural network layer's weight matrix, and b as the bias, then we have\n$O = Wh + b$ (4)\nThe two titles in a pairwise judgment are processing in analogous approach. Based on the final embeddings of the query and title that are denoted as $O_q$ and $O_d$, we calculate their cosine similarity as follows:"}, {"title": "Optimization", "content": "The neural network parameters and the word embeddings are updated by the conventional backpropagation. The SEM model is trained using stochastic gradient descent. Let A be the parameters and \u2206 = cos(f(qi), f(pq\u2081)), they are updated as follows:\n$A_t = A_{t-1} - \\gamma_t \\frac{\\partial \\Delta}{\\partial A_{t-1}}$ (6)\nwhere At and At\u22121 are the model parameters at tth iteration and (t \u2013 1)th iteration respectively. And Yt is the learning rate at tth iteration. This process is conducted for all training instances and repeated for several iterations until convergence is achieved. We derive the model parameters gradient as follows:\n$\\frac{\\partial \\Delta}{\\partial A_{t-1}} = \\frac{\\partial cos(O_q, O_{d+})}{\\partial A_{t-1}} - \\frac{\\partial cos(O_q, O_{d-})}{\\partial A_{t-1}}$ (7)\nTo simplify the notation of calculating the derivatives of W, we let d denote $d^+$ and $d^-$, and we let a, b, c be $O^T O_d$, $|O_q|$, $|O_d|$, respectively. Then, we can compute $\\frac{\\partial \\Delta}{\\partial W_q}$ and $\\frac{\\partial \\Delta}{\\partial W_d}$ by using the following formulas:\n$\\frac{\\partial cos(O_q, O_d)}{\\partial W_q} = \\frac{\\partial}{\\partial W_q} \\frac{O_q^T O_d}{||O_q|| ||O_d||} = \\delta_q^{T(q,d)} h$ (8)\n$\\frac{\\partial cos(O_q, O_d)}{\\partial W_d} = \\frac{\\partial}{\\partial W_d} \\frac{O_q^T O_d}{||O_q|| ||O_d||} = \\delta_d^{T(q,d)} h$ (9)\nwhere $\\delta_q^{(q,d)} = bcO_d - acb^3 O_q$ and $\\delta_d^{(q,d)} = bcO_q - acb^3 O_d$\nSimilarly, we can compute the gradient of intermediate representation $ \\partial \\Delta/\\partial h$, then get the gradient of element-wise adding result $ \\Delta/\\partial v$. With softsign function in our model, each $ \\delta $ in the element-wise adding result can be calculated by:\n$\\delta_{\\theta_d}^{(q,d)} = \\frac{1}{(1 + |V_{\\theta_d}|)^2} \\circ W^T \\delta_g^{q,d}$ (10)\n$\\delta_{g,d}^{(q,d)} = \\frac{1}{(1 + |V_{\\theta_d}|)^2} \\circ W^T \\delta^{T(q,d)}$ (11)\nIn the above two formulas, the operator \u2022 is the element-wise multiplication. Finally, we backpropagate the gradient of element-wise adding result $\\delta_{\\theta_d}$ and $\\delta_{q,d}$ to each word embedding of query and documents."}, {"title": "3.2 Terminology", "content": "The Web search results of a query can be categorized into three groups based on the user's click signals.\n1. Clicked: The title of the result that is clicked by the users.\n2. Skipped: The title of the result that is ranked above a clicked one, i.e., the result is examined by the user but no clicked.\n3. Non-Examined: The title of the result that is ranked below all clicked ones."}, {"title": "3.3 Experimental Data", "content": "In our experiments, we gauge the performance by two metrics. The first metric is whether the model can effectively predict future clicking by scoring clicked results higher than non-clicked results. To achieve this goal, we prepare a testing dataset named Test-1 by deriving 23,000,000 pairwise judgments from the holdout query log. For a specific query and its top ten results, the pairwise judgment in Test-1 contains a randomly chosen clicked result and a randomly chosen non-clicked result. The second metric is to test whether the model can generate results that are aligned with human judgment. The second testing dataset named Test-2 is manually prepared by human experts and contains 530,000 pairwise judgments."}, {"title": "4 Atomic Strategies", "content": "In LTR, it is well believed that the relative preferences of clicked documents over skipped ones are reasonably accurate [1, 19]. Therefore, based on a user's ranking preference reflected in his/her clicks, we propose several strategies to derive pairwise judgments. These strategies are mutually exclusive and can be used as the basic building blocks for deriving more complicated pairwise judgments.\n1. Clicked > Skipped: This strategy is widely utilized in LTR applications. It assumes that the clicked results should be preferred to the skipped results.\n2. Clicked > Clicked: This strategy differentiates clicked results by their click-through rate (CTR) and assumes that a result with higher CTR is preferred to that with lower CTR.\n3. Clicked > Non-Examined: This strategy assumes that the clicked results are preferred to those that are not examined by the users.\n4. Skipped > Non-Examined: This strategy is rarely applied in LTR since no click information is utilized. We include this strategy in our experiment for completeness.\nEmpirically, SEM usually takes several iterations to converge and we find that 50 iterations are typically enough to obtain a stable model. The experimental result on Test-1 is shown in Figure 2. We observe that Clicked>Non-Examined achieves the highest precision, showing that the pairwise judgments formed by Clicked>Non-Examined are of the best"}, {"title": "5 Hybrid Strategy", "content": "From Figures 2 and 3, a large performance discrepancy between any two atomic strategies is observed. Intuitively, combining any two of these atomic strategies will not bring better results than Clicked>Non-Examined since the low-quality training instances will \"contaminate\u201d the result. However, through extensive empirical evaluation, we find that the intuition holds but with one exception, which results in the following hybrid strategy: Clicked>Non-Clicked, which is a combination of Clicked>Skipped and Clicked>Non-Examined.\nBased on the experimental results shown in Figure 4, we can see that Clicked>Non-Clicked slightly outperforms the best atomic strategy Clicked>Non-Examined on Test-1. In order to reveal the underlying reason, we present the distribution of the four atomic strategies. Based on the statistics shown in Table 1, we can see that no single strategy covers a majority of the pairs. Clicked>Skipped and Clicked>Non-Examined are responsible for 22.25% and 38.85% of the potential training data. Hence, relying on a single strategy such as Clicked>Non-Examined rules out many \"fairly good\" training instances and misses the chance of updating the embedding of many words. In the long run, the model using Clicked>Non-Clicked strategy sees more training instances achieves slightly better performance than the atomic strategies. The result shows that seeing more training instances is sometimes useful for training. Another possible"}, {"title": "6 Conclusions", "content": "In this paper, we study the problem of formulating pairwise judgment for Semantic Embedding Model (SEM). We conduct an in-depth study of the information in the query log of a major search engine. Based on large-scale experiments, we quantitatively compare several strategies for pairwise judgment formulation. Experimental results verify the effectiveness of proposed strategies. More importantly, we reveal the fact that the pairwise judgment formulation for the neural network-based semantic embedding model is quite different from the pairwise LTR. Future work includes introducing more signals into the procedure of pairwise judgment formulation and investigating formulation strategies for SEM variants. The formulated pairwise judgment can also inspire downstream applications including topic discovery [9, 13, 16, 18], intent mining [10, 17], and user personalization [8, 12, 29]."}]}