{"title": "AsyCo: An Asymmetric Dual-task Co-training Model for Partial-label Learning", "authors": ["Beibei Li", "Yiyuan Zheng", "Beihong Jin", "Tao Xiang", "Haobo Wang", "Lei Feng"], "abstract": "Partial-Label Learning (PLL) is a typical problem of weakly supervised learning, where each training instance is annotated with a set of candidate labels. Self-training PLL models achieve state-of-the-art performance but suffer from error accumulation problem caused by mistakenly disambiguated instances. Although co-training can alleviate this issue by training two networks simultaneously and allowing them to interact with each other, most existing co-training methods train two structurally identical networks with the same task, i.e., are symmetric, rendering it insufficient for them to correct each other due to their similar limitations. Therefore, in this paper, we propose an asymmetric dual-task co-training PLL model called AsyCo, which forces its two networks, i.e., a disambiguation network and an auxiliary network, to learn from different views explicitly by optimizing distinct tasks. Specifically, the disambiguation network is trained with self-training PLL task to learn label confidence, while the auxiliary network is trained in a supervised learning paradigm to learn from the noisy pairwise similarity labels that are constructed according to the learned label confidence. Finally, the error accumulation problem is mitigated via information distillation and confidence refinement. Extensive experiments on both uniform and instance-dependent partially labeled datasets demonstrate the effectiveness of AsyCo. The code is available at https://github.com/libeibeics/AsyCo.", "sections": [{"title": "1 Introduction", "content": "Training deep neural networks via supervised learning requires massive accurately-annotated data, which are, however, expensive to be collected. To overcome this problem, weakly supervised learning [1-4] has been widely studied in recent years. Partial-Label Learning (PLL) [5,6] is a typical type of weakly supervised learning with inaccurate supervision, which assumes that each training instance is annotated with a candidate label set that contains the ground-truth label. As shown in Fig. 1, the visual resemblance between raccoons and Ailurus fulgens makes it challenging for annotators to confidently pinpoint the exact animal depicted in the images. As a result, they assign multiple candidate labels to each image, leading to partially labeled instances. Since label ambiguity is pervasive in data annotations, PLL has been widely applied in various real-world applications, such as automatic image annotation [7] and multimedia content analysis [8].\nRecent research on PLL has primarily concentrated on identification-based methods, which regard the ground-truth label as a latent variable and try to recognize the ground-truth label by conducting label disambiguation. To this end, various techniques have been employed, such as maximum margin [9], graph models [10-13], expectation-maximum algorithm [14], contrastive learning [15], and consistency"}, {"title": "2 Preliminaries", "content": null}, {"title": "2.1 Problem Settings", "content": "We denote $\\mathcal{X} \\subset \\mathbb{R}^d$ as the d-dimensional feature space and $y \\in \\{1,2,...,m\\}$ as the label space. In partially labeled datasets, each training instance $x_i \\in \\mathcal{X}$ is labeled with a candidate label set $Y_i \\subset \\mathcal{Y}$ that contains the ground-truth label $y_i$. Our goal is to learn a multi-class classifier f (\u2022) on partially label dataset $D = \\{(x_i, Y_i)|1 \\le i \\le n\\}$. We use $P_{ik} = f_k(x_i)$ to denote the predicted probability of classifier f (\u00b7) on label k given instance $x_i$.\nNote that for non-structural instances, such as images and text, their d-dimensional features are typ\u0456- cally extracted using Deep Neural Network(DNN)-based encoders from their raw feature. For instance, the feature encoder for images is commonly constructed based on convolutional neural networks like LeNet, ResNet, or WideResNet, etc."}, {"title": "2.2 Classifier-consistent PLL Loss", "content": "The Classifier-Consistent (CC) PLL loss [18] assumes each candidate label set is uniformly sampled and is presented as follows:\n$\\mathcal{L}_{cc} (x_i) = -log \\Big(\\sum_{k\\in Y_i} P_{ik}\\Big).$ (1)\nMinimizing the CC loss is equivalent to maximizing the sum of the classification probabilities of all the candidate labels while minimizing the sum of the classification probabilities of non-candidate labels."}, {"title": "2.3 Risk-consistent PLL Loss", "content": "The above classifier-consistent PLL loss [18] assigns the same weight to each candidate label and makes the ground-truth label easily overwhelmed by other false positive labels. Thus, a Risk-Consistent (RC) loss based on the importance-weighting strategy was proposed [18]. By leveraging the widely-used categorical cross entropy loss as the basic classification loss, the risk-consistent PLL loss is formulated as follows:\n$\\mathcal{L}_{rc} (x_i) = -\\sum_{k=1}^m C_{ik}log P_{ik}, \\qquad C_{ik} = \\frac{p(Y_i = k|x_i)}{\\sum_{j\\in Y_i} p(Y_i = j |x_i)},$ (2)\nwhere $p(y_i = k | x_i)$ represents the probability that instance $x_i$ belongs to category k. Actually, $C_{ik}$ implies how confident the probability of falling into category k is, thus, a confidence vector can be formed as $[C_{i0}, C_{i1},..., C_{im}]$. Since $p(y_i = k | x_i)$ is not accessible from the given data, it is approximated by the classification probability, shown as,\n$p(Y_i = k|x_i) =\\begin{cases} f_k(x_i) \\quad \\text{if } k \\in Y_i,\\\\ 0 \\quad \\text{otherwise}. \\end{cases}$ (3)\nBy calculating $p(y_i = k | x_i)$ as above, the RC PLL loss trains models in a self-training manner."}, {"title": "3 The Proposed Model", "content": "As shown in Fig. 2, our model is composed of a disambiguation network, an auxiliary network and an error correction module. The two networks have identical structures but are trained with different tasks and loss functions, leading to discrepancies in their parameters and capabilities. Specifically, the disambiguation network undergoes training using PLL losses and obtains the confidence of each label in the candidate label set, while the auxiliary network leverages low-noise pairwise similarity labels generated according to the learned label confidence and is trained via supervised learning losses. Finally, the auxiliary network addresses the issue of error accumulation in the disambiguation network through information distillation and confidence refinement. To facilitate understanding, the notations set in AsyCo are summarized in Table 1."}, {"title": "3.1 Disambiguation Network", "content": "Given an instance $x_i$, a classifier is proposed to compute classification logits using a Multi-Layer Perceptron (MLP). The classifier further calculates the classification probability $p_i \\in \\mathbb{R}^m$ by applying the softmax function. Specifically, the kth element of $p_i$, which represents the probability that the instance $x_i$ is classified into the kth category, is determined as follows:\n$P_{ik} = p(Y_i = k | x_i) = f(x_i) = \\frac{exp \\Big(MLP_k (x_i)/\\tau \\Big)}{\\sum_j exp \\Big(MLP_j (x_i)/\\tau \\Big)},$ (4)\nwhere $MLP_k (x_i)$ denotes the classification logit for classifying instance $x_i$ into label k. Additionally, $\\tau$ serves as a temperature parameter, wherein a higher value of $\\tau$ results in smoother classification probabilities.\nData augmentation, which generates richer and harder instances by making slight modifications to the original instances, benefits classification performance. Following DPLL [16], we apply two augmentation methods, i.e., Autoaugment [27] and Cutout [28], to generate two augmentated views for each instance, which are denoted as $x'_i = Aug_1(x_i)$ and $x''_i = Aug_2(x_i)$. The original instance and the augmented instances of $x_i$ form a instance set $\\mathcal{A}(x_i)$, i.e., $\\mathcal{A}(x_i) = \\{x_i, x'_i,x''_i \\}$. Besides, $x'_i$, $x''_i$ and $p'_i$, $p''_i$ denote the features and classification probabilities of the augmented instances, respectively. According to Equation 6, the label confidence vectors of the origin instance $x_i$ and its augmentations $c'_i$, $c''_i$ can be calculated successively, which are denoted as $c_i, c'_i, c''_i$, respectively.\nWe extend the original CC and RC losses to accommodate the augmented instances, and train the disambiguation network with the enhanced losses. Specifically, with data augmentation, the CC loss of"}, {"title": "3.2 Auxiliary Network", "content": "The auxiliary network has the same structure as the disambiguation network, but their parameters are trained differently. To symbolically differentiate the components and variables of these two networks, the symbols corresponding to the auxiliary network are augmented with tilde symbols. For example, in the auxiliary network, the classifier, the feature, the predicted classification probabilities and the final label confidence are denoted as $\\tilde{f}(\\cdot), \\tilde{x}_i, \\tilde{p}_i$ and $\\tilde{w}_i$ respectively.\nAs the disambiguation network undergoes training, the precision of confidence vector continually im- proves. For a certain portion of instances, their ground-truth labels are identified by the maximum confidence value. This motivates us to assign an exact pseudo class label to each instance according to its label confidence, thereby sufficiently utilizing this clarified information to enhance model train- ing. As shown in Fig. 3, assuming instance $x_i$ gets the largest confidence on the k'th label, i.e., $k' = \\text{argmax}_k \\{W_{ik} | Y_{ik} \\in Y_i\\}$, we generate a one-hot label vector for it, of which the k'th element is 1, other elements are 0. Consequently, we obtain a new dataset where each instance is annotated with an exact class label. Due to that some instances may be mistakenly disambiguated and annotated, there are some noisy data in the generated dataset.\nRefer to the work of Wu et al. [26], the noise rates of the pairwise similarity labels are lower than that of the intermediate noisy class labels in most practical scenarios. Therefore, we transform the pseudo class labels into pairwise similarity labels, and utilize the resulting similarity dataset to train the auxiliary network. Specifically, for each pair of instances, if they share the same pseudo class label, we assign a similarity label of 1 to them; otherwise, we assign a similarity label of 0. The generated similarity dataset is denoted as $\\mathcal{D}_{sim} = \\{(\\mathcal{X}_i, \\mathcal{X}_j), S_{ij}\\}$, where $(\\mathcal{X}_i, \\mathcal{X}_j) \\in \\mathcal{X} \\times \\mathcal{X}, S_{ij} \\in \\{0,1\\}$.\nFor pairs of instances with a similarity label of 1, it is expected that their predicted classification probabilities exhibit high similarity. To capture this inter-instance relationship, we propose a binary cross-entropy loss function as Equation 10. It should be noted that both $\\tilde{p}_i$ and $\\tilde{p}_j$ are classification probabilities normalized by the softmax function, thus, $0 \\le \\tilde{p}_i\\tilde{p}_j \\le 1$.\n$\\mathcal{L}_{sim} (x_i, x_j, S_{ij}) = -\\frac{1}{\\mid \\mathcal{A}(x_i)\\mid \\cdot \\mid \\mathcal{A}(x_j)\\mid} \\sum_{x_i,x_j\\in \\mathcal{A}} \\Big[ S_{ij} log(\\tilde{p_i}^T\\tilde{p_j}) - (1 - S_{ij}) log(1 - \\tilde{p_i}^T\\tilde{p_j}) \\Big].$ (10)\nFurthermore, in order to keep the consistency between the original instances and their augmentations, we construct the following cross entropy-based loss to learn self-supervised information:\n$\\mathcal{L}_{ssl} (x_i) = - \\sum_{y_i \\in Y_i} \\Big[ \\mathbb{I}_{y_i = k} \\text{stop-grad}(p_{ik}) log \\tilde{P}_{ik}\\Big],$ (11)\nwhere stop-grad($p_{ik}$) denotes that we stop the gradients of $p_{ik}$ in $\\mathcal{L}_{ssl}$ during back-propagation.\nFinally, the overall loss to train the auxiliary network is as follows:\n$\\mathcal{L}_{aux}(x_i) = \\mathcal{L}_{ssl}(x_i) + \\gamma(t) \\Big[\\frac{1}{n} \\sum_{j=0}^n \\mathcal{L}_{sim}(x_i, x_j, S_{ij})\\Big]$ (12)\nwhere $\\gamma(t)$ is defined in Equation 9. As the training process progresses, the noise rate of the generated similarity labels gradually decreases, thus the weight of $\\mathcal{L}_{sim}$ improves gradually."}, {"title": "3.3 Error Correction", "content": "We leverage the auxiliary network to alleviate the issue of error accumulation in disambiguation networks. To achieve this, two error correction strategies, i.e., information distillation and confidence refinement, are established, which affect the training of disambiguation network in direct and indirect ways, respectively.\nFor information distillation, regarding the predicted probability of the auxiliary network as ground- truth distribution, we introduce the following KL divergence-based loss to ensure that the predicted probability of the disambiguation network closely aligns with that of the auxiliary network,\n$\\mathcal{L}_{distill} (x_i) = KL(\\text{stop-grad}(p_i)||\\tilde{p}_i),$ (13)\nBy ignoring the gradients from $\\tilde{p}_i$ in $\\mathcal{L}_{distill}$, we avoid the impact of the disambiguation network's pre- diction on the auxiliary network.\nAdditionally, similarly to the confidence calculation in the disambiguation network as described in Equation 6, the comprehensive confidence vector $\\tilde{w}_i$ for instance $x_i$ is obtained using the prediction results of the auxiliary network. Then, $\\tilde{w}_i$ is utilized to refine the label confidence of the disambiguation network. During the t-th epoch, the refined confidence is computed as follows:\n$w_i(t) = (1 - \\mu(t))w_i(t) + \\mu(t)\\tilde{w}_i(t),$ (14)\nwhere $\\mu(t)$ is a non-decreasing function of training epoch t. Here, we set $\\mu(t) = \\text{min}(\\rho \\times \\text{max}(t - t_0, 0), \\mu_{max})$. $t_0$ and $\\mu_{max}$ are hyper-parameters, where $\\mu(t) = 0$ before the $t_0$-th training epoch and $0 \\le \\mu_{max} \\le 1$ is the upper bound of $\\mu(t)$. The increase speed of $\\mu$ depends on $\\rho$. During co-training, the original confidence $w_i$ in Equation 7 is replaced by the refined confidence $w_i$.\nEffective error correction enhances label disambiguation and enables the generation of purer pseudo class labels, further boosting the accuracy of the auxiliary network. The interplay between these two networks forms a virtuous cycle."}, {"title": "3.4 Training and Inference", "content": "The overall training loss is as follows:\n$\\mathcal{L}_{total} (x_i) = \\mathcal{L}_{disam} (x_i) + \\mathcal{L}_{aux} (x_i) + \\gamma(t)\\mathcal{L}_{distill} (x_i),$ (15)\nwhere the distillation loss based on confidence is also set to the weight $\\gamma(t)$.\nIn the training phase, the disambiguation network is initially warmed up for several epochs to ensure accurate identification of ground-truth labels for certain training instances by the confidence vectors. Subsequently, the pre-trained model parameters are employed to initialize the parameters of the auxiliary network. Moreover, to enhance the efficiency of model training, noisy similarity labels are generated using instances within the same mini batch.\nIn the inference phase, the predicted probability ensemble of the two learned classifiers naturally enhances performance but incurs additional prediction overhead. Consequently, we opt to utilize only one network for inference. The choice between the disambiguation network and the auxiliary network is insignificant as they ultimately converge to a similar level of performance. In the inference phase, we utilize the disambiguation network for prediction."}, {"title": "3.5 Complexity Analysis", "content": "In the training phase, compared to self-training PLL models without co-training, such as DPLL [16], AsyCo requires approximately twice the amount of space due to the co-training of two networks. As for the time complexity, the computational overhead of AsyCo mainly comes from backbone networks, classifiers and loss functions. Due to that backbone networks and classifiers are modular and replaceable in AsyCo, without loss of generality, we denote their computation complexity on an instance as O(B)and O(C), respectively. Let the total number of training instances be N, in the disambiguation network and auxiliary network, the classification probability of each instance is calculated via the backbone network and classifier once, so the time cost is O(2NB + 2NC). The time complexity of RC and CC loss in disambiguation network is O(3N + 3N). Since N2 similarity labels are constructed in the auxiliary network, the time complexity of supervised loss is O(N2). Besides, the time complexity of self-supervised"}, {"title": "4 Experiments", "content": null}, {"title": "4.1 Experimental Setup", "content": null}, {"title": "4.1.1 Datasets", "content": "We conduct experiments on five datasets, which include three widely used benchmark datasets, including SVHN [30], CIFAR-10 and CIFAR-100 [29], a text classification dataset CNAE-9 1), and a real-world partial label dataset BirdSong, which is for bird song classification task. Following [16], we construct partially labeled datasets for the four benchmark datasets via two generating processes, i.e., a uniform process and an instance-dependent process. In the uniform generating process, incorrect labels have the same probability q to be a candidate label, where q varies in {0.1, 0.3,0.5,0.7} on SVHN, CIFAR-10, and CNAE-9, and {0.01, 0.05,0.1,0.2} on CIFAR-100. We conduct the instance-dependent candidate generating process on the image datasets. We pretrain 18-layer ResNet (ResNet-18) firstly, and the probability of incorrect label j turning into a false positive label is calculated as:\n$\\frac{q'_j(x_i)}{\\text{max}_{k\\neq j} g_k(x_i)},$\nwhere $q'_j(x_i)$ is the classification probability into label j calculated by the pretrained ResNet-18 given input xi."}, {"title": "4.1.2 Compared Methods", "content": "To evaluate the performance of AsyCo, we choose the following deep PLL methods as competitors: (1) CC [18], a classifier-consistent method based on the assumption that candidate label sets are generated uniformly. (2) RC [18], a risk-consistent method based on the importance of re-weighting strategy. (3) PRODEN [19], a progressive identification method accomplishing classifier learning and label identifica- tion simultaneously. (4) PiCO [15], a PLL model utilizing contrastive learning module along with a novel class prototype-based label disambiguation algorithm. (5) DPLL [16], a model leveraging consistency regularization for deep PLL. (6) NCPD [25], a co-training based PLL model employing a progressive disambiguation strategy combined with a network cooperation mechanism for PLL. (7) Fully super- vised learning, a model trained with the exact ground-truth labels and cross-entropy loss enhanced by data augmentation."}, {"title": "4.1.3 Implementation Details", "content": "AsyCo is implemented using PyTorch, with an 18-layer ResNet utilized as the backbone network, i.e., serving as the feature encoder on image datasets. Since both CNAE-9 and BirdSong are not very large, we construct linear layers as their feature encoders. For these two non-image datasets, we augment the instances by adding random tokens and Gaussian noise, respectively. The optimization of the model is carried out using the SGD optimizer, with a momentum value set to 0.9 and a weight decay set to 1e-4. The initial learning rate is set to 0.1, and at the 100th and 150th epochs, the learning rate is divided by 10. The total number of training epochs is set to 200, with warm-up epochs accounting for 50 when q = 0.2 on CIFAR-100 and 20 in other scenarios. The batch size is set to 64. The value of is searched within the range of [1, 5, 10, 20,30], and ultimately selected as t = 20. When calculating A, the values of T and Amax = 1 are set to 100 and 1, respectively. Furthermore, for the hyper-parameters related to confidence refinement, p is set to 0.02, to is determined by adding the number of warm-up epochs to 50, and \u00b5max is set to 0.9. The source code can be found at https://github.com/libeibeics/AsyCo."}, {"title": "4.2 Performance Comparison", "content": "The performance comparison results are shown in Table 2. From the results, we have following observation and analysis.\nFirstly, DPLL, which is the state-of-the-art deep PLL model, performs differently across datasets. Specifically, in the experiments conducted on CIFAR-10 and CIFAR-100, it is observed that the DPLL"}, {"title": "4.3 Ablation Study", "content": null}, {"title": "4.3.1 Impact of the Auxiliary Network", "content": "In order to examine the impact of the auxiliary network, we conduct an experiment by excluding the aux- iliary network from AsyCo and training the disambiguation network separately. This setting is equivalent to directly removing the error correction module from AsyCo, thereby eliminating the impact of the aux- iliary network on the disambiguation network. The experimental results, shown in Table 7, demonstrate a decrease in performance across all datasets and p values, indicating that co-training can enhance the prediction accuracy of PLL. Particularly, AsyCo exhibits a more pronounced advantage as the value of q increases on CIFAR-10 and SVHN, providing further evidence that co-training enhances the robustness of the model."}, {"title": "4.3.2 Impact of Asymmetric Co-training Architecture", "content": "Different from existing co-training PLL models, AsyCo is built upon asymmetric co-training architec- ture. In this section, we construct a symmetric co-training model variant called SyCo to explore the impact of the asymmetric co-training architecture. In SyCo, the two networks are initialized differently and both trained with the same PLL loss as Equation 8. Additionally, SyCo employs a symmetric KL"}, {"title": "4.3.3 Impact of Error Correction Strategy", "content": "We perform an ablation study of the two error correction strategies, namely distillation and confidence refinement. The experimental results are presented in Table 9. It is evident that removing either strategy leads to a slight decrease in accuracy, which indicates that the combination of them plays a more substan- tial role. Refer to that the significant performance decrease caused by removing the auxiliary network, i.e., removing the whole error correction module shown in Table 7, it can be inferred that either of the proposed error correction strategies contributes to the final classification accuracy. Moreover, removing distillation results in a larger decline in performance compared to removing confidence refinement. This may result from the fact that distillation facilitates a more direct and timely influence of disambiguation models on auxiliary models."}, {"title": "4.3.4 Impact of Label Transformation", "content": "The impact of converting pseudo class labels into pairwise similarity labels is analyzed from two aspects. Firstly, a comparison is conducted between the noise rates of pairwise similarity labels and pseudo class labels while optimizing AsyCo, as depicted in Figure 4. It is obvious that the noise rate of similarity labels is significantly lower than that of the noisy class labels. Secondly, a model variant of AsyCo is constructed that disregards label transformation and instead trains the auxiliary network directly using pseudo class labels. The degradation in performance, as demonstrated in Table 10, clearly illustrates that transforming noisy class labels into noisy pairwise similarity labels reduces the influence of noise labels on prediction accuracy."}, {"title": "4.3.5 Ablation Study of Data Augmentation", "content": "In order to investigate the impact of data augmentation, we construct model variants based on AsyCo by removing data augmentation and varying the number of data augmentations per instance, as shown in Table 11. The experimental results show that removing data augmentation or over-increasing the number of times each sample is augmented, e.g., 3 augmentations per sample, brings about a decrease in classification accuracy. Generally, the model performs best on the CIFAR datasets with two data augmentations for each instance. This experiment illustrates the contribution of data augmentation to classification accuracy and the importance of choosing a proper number of data augmentations."}, {"title": "4.4 Further Analysis", "content": null}, {"title": "4.4.1 Impact of Backbone Network", "content": "We replace the backbone network ResNet-18 with Wide-ResNet-34-10 in order to analyze the impact of the backbone network on performance. The results presented in Table 12 demonstrate that a stronger back- bone network can lead to additional performance improvement in AsyCo. Specifically, when ResNet-18 is replaced with Wide-ResNet, we observe accuracy improvements of approximately 0.402 % and 1.093% on SVHN and CIFAR-10, respectively. These findings indicate the substantial performance potentials of AsyCo. As a comparison, we also investigate the performance of replacing the backbone network for the competitors. And due to space limitations, we list the accuracy of the strongest competitor, i.e., DPLL, on the CIFAR dataset after adopting wide-resnet as its backbone network. It can be seen that a stronger backbone network leads DPLL to a significant performance improvement, though the performance of DPLL is still significantly behind on the SVHN and CIFAR-10 datasets compared to AsyCo."}, {"title": "4.4.2 Impact of Temperature Parameter \u03c4", "content": "The temperature coefficient in Equation 4 determines the smoothness of the classification probability. Here, we study the effect of T on the disambiguation network. As shown in Figure 5, the accuracy of the disambiguation network is visualized when different values of \u315c (1, 10, 20, and 30) are applied, where the disambiguation network is trained individually. It is observed that an improvement in performance is evident when \u315c > 1, regardless of the q values. The reason is that properly smoothed confidence avoids aggressive optimization and reflects detailed information of instances, e.g, the correlation between the instance and false positive labels. However, excessively smooth confidence resulting from a very large value of T leads to a degradation in performance. This is due to the inability to clearly differentiate the weights of each candidate label."}, {"title": "5 Related Work", "content": null}, {"title": "5.1 Traditional Partial-label Learning", "content": "Traditional PLL methods can be divided into two categories, i.e., average-based methods and identification- based methods. The average-based methods treat each label in a candidate label set equally [5, 31-33]. However, the ground truth label of each instance is easily overwhelmed, especially when the number of candidate labels is large. To alleviate the problem, identification-based methods try to disambiguate ground-truth label from candidate label sets. Some of them utilize a two-phase strategy [32], i.e., first refining label confidence, then learning the classifier, while others progressively refine confidence during learning the classifier [9]. Besides, manifold consistency regularization, which assumes that similar in- stances are supposed to have similar label distributions, has been widely employed in PLL to estimate the label confidence and learn the classifier simultaneously [9,10,32,34]. Recently, an algorithm towards multi-instance PLL problem has been explored [35], which assumes each training sample is associated with not only multiple instances but also a candidate label set that contains one ground-truth label and some false positive labels. However, these traditional methods are usually linear or kernel-based models, which are hard to deal with large-scale datasets."}, {"title": "5.2 Deep Partial-label Learning", "content": "With the powerful modeling capability of deep learning, deep PLL methods can handle high-dimensional features and outperform traditional methods. Assuming a uniform set-level partial label generation process, Feng et al. [18] propose a classifier-consistent loss, which is model-agnostic and can be directly combined with deep classifiers and variant optimizers. However, it treats each candidate label equally. RC [18], PRODEN [19] and LWS [17] leverage self-training and estimate label confidence and train the model with it iteratively. PiCO [15] and DPLL [16] further explore contrastive learning and manifold consistency in self-training PLL models, respectively. Nevertheless, self-training PLL models suffer from error accumulation problem resulted from mistakenly disambiguated instances. To address this issue, NCPD [25] converts the patial labels into noisy labels via multi-birth duplication and adopts a typical co-training NLL method called co-teaching [24]. Unfortunately, the label transformation in NCPD results in a high noise rate, limiting classification accuracy and resulting high time and space complexity. Besides, the two networks in NCPD are trained with the same input data and loss functions and easily reach a consensus, thereby cannot correct errors for each other effectively, which naturally motivates us to improve them in our research."}, {"title": "6 Conclusion", "content": "In this paper, we propose an asymmetric dual-task co-training PLL model AsyCo, which forces them learn from different views explicitly by training a disambiguation network and an auxiliary network via optimizing different tasks. To alleviate the error accumulation problem of self-training PLL models, we establish an information flow loop between the two networks in AsyCo as their collaboration mechanism, i.e., the disambiguation network provides the auxiliary network with the identified pseudo class labels, while the auxiliary network conducts error correction for the disambiguation network through distillation and confidence refinement. Results of experiments on benchmark datasets fully demonstrate the superior performance of AsyCo compared to existing PLL models and the effectiveness of asymmetric co-training in error elimination. Though AsyCo achieves excellent performance, it also has limitations. Like other co-training-based models, it requires almost twice the computational space to complete the training, which brings higher training overhead. In the future, we will further conduct research on different co- training architectures and network cooperation mechanisms to tap the potential of dual-task co-training models for PLL."}]}