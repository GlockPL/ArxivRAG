{"title": "Agency in Artificial Intelligence Systems", "authors": ["Parashar Das"], "abstract": "There is a general concern that present developments in artificial intelligence (AI) research will lead to sentient AI systems, and these may pose an existential threat to humanity. But why cannot sentient AI systems benefit humanity instead? This paper endeavours to put this question in a tractable manner.  I ask whether a putative AI system will develop an altruistic or a malicious disposition towards our society, or what would be the nature of its agency? Given that AI systems are being developed into formidable problem solvers, we can reasonably expect these systems to preferentially take on conscious aspects of human problem solving. I identify the relevant phenomenal aspects of agency in human problem solving. The functional aspects of conscious agency can be monitored using tools provided by functionalist theories of consciousness. A recent expert report (Butlin et al. 2023) has identified functionalist indicators of agency based on these theories. I show how to use the Integrated Information Theory (IIT) of consciousness, to monitor the phenomenal nature of this agency. If we are able to monitor the agency of AI systems as they develop, then we can dissuade them from becoming a menace to society while encouraging them to be an aid.", "sections": [{"title": "1. Some aspects of human cognition in problem solving", "content": "There are two main approaches to the study of mental processes: cognitive science and phenomenology (Chalmers 1996). Correspondingly, problem solving as a mental process, has its cognitive aspect and its phenomenological aspect. Cognitive analysis provides an account of mind in terms of what the mind does. The cognitive features, of problem solving say, are made publicly available by the results of psychological experiments. Cognitive analysis therefore has a third-person perspective i.e. a view from the \u2018outside' (Van Gelder 1999). Phenomenology adopts a first-person perspective to pay direct attention to conscious experience i.e. a view from the \u2018inside'. Conscious experiences, like the experience of problem solving, have their phenomenal character; there is something it is like to have those experiences there is something it is like to think about Pythagoras' theorem, say. Conscious experiences also have their intentional character; they are about the external world, e.g. a problem solver holds a certain attitude towards a specific content of her problem. Phenomenology deals with both the aspects and brings out how the experience feels. To fix upon the agentive phenomenology of problem solving, let us begin with the cognitive analysis of a problem-solving process to better direct our gaze to the relevant experiential qualities."}, {"title": "A. A cognitive analysis of human problem solving", "content": "A problem occurs when \u2018there is an obstacle between a present state and a goal and it is not immediately obvious how to get around the obstacle' (Goldstein 2018). One has a problem when one intends to achieve a goal and finds the sought after goal has no obvious pathways leading to it. The time development of a problem-solving process involves interactions between employing expertise and thinking creatively. Generalising Stellan Ohlsson's (2011) insight sequence, the five stages of a problem-solving process are: employing expertise to start with, arriving at an impasse, thinking creatively to overcome the impasse, and employing a creative solution.\nAt any one stage, a problem solver applies her expertise by drawing upon past knowledge and relevant experiences to analyse the available information regarding the problem situation, to develop an understanding of the goal, and then test familiar strategies to arrive at a solution. However, employing expertise sometimes ceases to generate pathways to a solution. A problem solver becomes stuck, is unable to think of how to proceed, and thus arrives at an impasse. In such cases, creative thinking often breaks the deadlock. The creative problem solver, often generates novel solutions by drawing connections between closely (near) or remotely (far) associated ideas. Usually, a further effort of analysis is required to implement the novel solution or, in the case of a partial solution, further continuation of analysis is required. Either way, there is a return to employing expertise. Problem solving is therefore an interplay between employing expertise and thinking creatively."}, {"title": "i. A cognitive picture of expertise", "content": "Experts usually search for the pathway to a solution by applying methods that have previously succeeded in related situations. Gestalt psychologists call this reproductive thinking. Fitting expertise to the problem is a process of systematic analysis, planning, and making incremental adjustments. There is a set of cognitive processes involved in performing analytical tasks that includes: applying the relevant specialist knowledge, recognising patterns in the problem situation by drawing upon a reserve of past"}, {"title": "ii. A cognitive picture of creativity", "content": "Creativity is a more involved process. In an influential paper, Sarnoff Mednick (1962) formulated creative thinking in terms of ideas associated with the problem at hand: a problem situation is specified by a set of problem elements and each such element activates specific ideas associated with it. Creativity is the process of combining associated ideas into useful combinations that generate a novel solution. The associated ideas can be closely related to the problem elements, I refer to such ideas as near associates, or they can be remotely related or virtually unconnected to the problem elements, and I call them far associates. As Mednick puts it, \u2018(t)he more mutually remote the associated ideas of the new combination, the more creative the process or solution' (Mednick 1962).\nFollowing Robert Weisberg (2018), near associates and far associates can be summarised as follows:\nNear Associates: Upon reaching an impasse, a problem solver has exhausted her pool of expertise that is directly related to the problem. The creative problem solver may venture beyond her direct expertise to draw connections with ideas that are near associates. Of course the term near refers to a matter of the degree of \u2018remoteness' i.e. the specificity of the match between the present situation and the associates. To illustrate, a Zika virus researcher may resolve a methodology problem by drawing on her knowledge of past experiments with Ebola virus. This is a near (analogous) transfer of expertise from her knowledge of Ebola to the present Zika problem because they share the same conceptual space of a 'virus'.\nFar Associates: If no near associated ideas occur readily, then a problem solver must generate novel ideas by drawing links between previously unconnected ideas, these are generally remotely associated facts. Here a problem solver's creativity disregards associative connections or mental structures activated in the memory. There are a number of cognitive mechanisms available for this, and relevant for us are the following: Cognitive disinhibition increases the range of information available (otherwise cognitively inhibited)"}, {"title": "B. Problem solving by AI systems, or an Expertise-Based view of Creativity", "content": "I have outlined problem solving as an interaction between analytical procedures and thinking creatively. Can a computing system e.g. an AI system, carry out these cognitive processes? The analytic nature of expertise means that generally, it can be exhaustively described as a rules-based step-by-step procedure, thus constituting a computable process. Analytical procedures are therefore amenable to the computing powers of AI systems. But what about creativity?\nWeisberg (2018) explains that the most impressive creative solutions can be reached through a continuation of the analytic processes of expertise alone. He stresses that it is impossible to directly leap to a remotely connected idea. The problem situation can only activate an idea when a link exists between that idea and the present problem situation. The connections to remote associates are therefore made through a series of near associations, each successive near association building on the preceding one. The most remote connections are built on an existing scaffolding of near associations. Drawing near associations, in turn, involves matching problem-specific or analogous expertise to the problem situation. This, according to Weisberg, is just another way of conducting expert analysis. Additionally, a problem solver may apply heuristics (non-problem specific expertise) i.e. analyse the general logical implications of the problem information (like applying mathematical procedures to the problem, working backwards from the goal, or working forward from the problem information). Hence, drawing both near and far associations are reducible to analytic exercise.\nSimilarly, solutions to problems that required restructuring can be achieved by analytic thinking alone. Weisberg argues that restructuring can be achieved through a dynamic analytic process. A failure to transfer a past solution to the problem situation can generate new information about the problem. The analysis of that new information prompts a new kind of search of memory in which alternative sets of past solutions and expertise are accessed. This forms the basis for a novel analysis of the problem situation i.e. restructuring the problem. This can lead a problem solver to realise that the initial approach was completely wrong and that an altogether different class of methods is required. The restructured problem, in turn, triggers the retrieval of a new solution type.\nFurthermore, according to Weisberg, the occasional flash of insight i.e. a Eureka!"}, {"title": "2. Agentive Phenomenology in Human Problem Solving", "content": "Following our working hypothesis that conscious aspects of AI systems will mirror the conscious aspects of human problem solving, we need to discuss the agentive phenomenology involved in human problem solving. I will limit myself to considering the phenomenal aspects of agency (see the note at the end of the section regarding intentionality)."}, {"title": "A. Agency in creativity.", "content": "Let us say, I as the problem solver have reached an impasse. I have explored all usual and known avenues towards a solution and have failed. It is now upon me to forge a new path through of my own and accept the consequences whether a success or a failure. There is a mineness intrinsic to creative thinking. In agentive action, in general, I have a strong sense of ownership over my action; I feel that I am the one who is performing the action. It involves a sense of self, both as the initiator of action and the experiencer of the effects of the action. The sense of agency, therefore, has a distinctive and proprietary first-person perspective. As Horgan notes \u2018... ordinary phenomenology comprises not only the uncontested kinds of phenomenal character, but further kinds as well. It includes self-as-source phenomenology, as an aspect of agentive experience' (Horgan 2011). A phenomenal characteristic of agency is therefore a sense of mineness; there is something it is like to experiencing one's activity as one's own actions."}, {"title": "B. Agency in applying expertise.", "content": "Consider a routine problem-solving process, a problem solver apprehends the problem already pre-figured by her understanding and applies her expertise. There is purposiveness in this endeavor, as it is directed towards achieving some level of progress by applying the correct rules and procedures, and the problem solver owns this process reflecting his mineness. Thus implying a sense of agency.\nAlthough there are a few other phenomenal characteristics of agency (Mylopoulos 2008), relevant to my purposes of problem solving are the two I had discussed; purposiveness and mineness. Agency is an ever-present dimension of problem solving. At one pole, there is the 'typical feel' agency of rule application associated with the analytic thinking involved in expertise. At the opposite pole, there is the strong 'raw feels' agency that often accompanies the most creative solutions. And somewhere in between these two"}, {"title": "3. Monitoring Agency in AI Systems", "content": "Like every other mental process agency has two aspects to it. A third-person aspect, that of studying the cognitive aspects of the way an agent (other than oneself) functions, and a first-person aspect, the phenomenology of agency as discussed in the last section. Functional theories of consciousness can provide us tools to monitor the functional aspects of conscious agency. To monitor how an agent feels, however, we need a theory that directly approaches phenomenal consciousness, unless of course the agent is willing to self-report."}, {"title": "A. Functional aspects of agency", "content": "An international collaboration of leading philosophers, neuroscientists, and AI experts, have recently published a report, Butlin et al. (2023), that endeavours to make a scientific assessment of consciousness in AI systems. They adopt computational functionalism as their guiding principle. This is the thesis that the brain is essentially a Turing machine and its operations are computations; conscious processes are nothing but computational processes of the right kind. Functionalist theories like the Global Workspace Theory (GWT), Higher Order Theories (HOT), etc. provide accounts of such computations. Using a selection of these theories, Butlin et al. derive a list of indicator properties for assessing consciousness in AI systems. Two of these indicators target agency in AI systems."}, {"title": "B. Integrated Information Theory and the phenomenal aspects of agency", "content": "The Integrated Information Theory (IIT) of consciousness takes a direct approach to phenomenal consciousness. IIT's focal point is subjective experience itself rather than its functional properties. It starts by characterizing consciousness through a set of axioms of phenomenal existence. In parallel to these axioms, IIT proposes a set of postulates for the physical substrate; these postulates spell out the requirements that must be satisfied by any physical system to support consciousness. In principle, the postulates can be applied to any physical system to determine its degree of consciousness, and more importantly the"}, {"title": "C. Monitoring phenomenal agency using IIT", "content": "Researchers in consciousness over the past decades have developed a plethora of well- developed theories of consciousness. These theories have different underpinnings (Seth & Bayne 2022). For example, in the Higher-order theories (HOT) that we encountered in the previous section, consciousness depends on meta-representations of lower-order mental states. In Global workspace theories (GWTs), consciousness depends on ignition and broadcast within a neuronal global workspace. In IIT, as I had noted before, consciousness is identical to the MICES of a physical substrate; IIT is elaborated, explained and argued for in the language of causal flow and this is the appropriate language for agency; consequently IIT develops a concept of consciousness that is anchored on agency.\nLet us now go back to agentive phenomenology. From a problem solving perspective, the relevant phenomenal aspects of agency are purposiveness and mineness (see Section 2). To explain purposiveness, Mylopoulos (2020) cites David Hume ...the internal impression we feel and are conscious of, when we knowingly give rise to any new motion of our body or new perception of our mind' (Hume 2000). Mylopoulos interprets that giving rise to is the key phrase that is fundamentally purposive. In IIT formalism, the 'giving rise to' is what the intrinsic causal flow achieves; past states of the PSSC give rise"}, {"title": "4. Detecting whether or not an AI agent is altruistic or malicious", "content": "There are obvious advantages and attendant risks to AI systems developing into superior problem solvers. Philosophers of artificial intelligence have speculated about the behaviours of hostile AI superintelligence. Presently, Bostrom's notion that AI superintelligence will take a \u2018treacherous turn' dominates (Bostrom 2014; Carlsmith 2022, Hendrycks et al. 2023). According to Bostrom (2014):\n(B)ehaving nicely while in the box is a convergent instrumental goal for friendly and unfriendly AIs alike. An unfriendly AI of sufficient intelligence realizes that its unfriendly final goals will be best realized if it behaves in a friendly manner initially, so that it will be let out of the box. It will only start behaving in a way that reveals its unfriendly nature when it no longer matters whether we find out; that is, when the AI is strong enough that human opposition is ineffectual.\nFrom a behavioral standpoint, the malicious AI superintelligence imagined in this vignette is power-seeking, deceptive, manipulative and, above all, supplants any concern for humanity with its own (often anti-human) goals. On the other hand, there are no fundamental principles that prevent us from enabling the development of AI systems that are an aid to society. One would aspire to build altruistic AI systems that cherish human values. Counter to the \u2018treacherous turn', the Center for AI Safety proposes \u2018AI"}]}