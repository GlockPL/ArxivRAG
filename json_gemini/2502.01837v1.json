{"title": "TESS: A Scalable Temporally and Spatially Local Learning Rule for Spiking Neural Networks", "authors": ["Marco P. E. Apolinario", "Kaushik Roy", "Charlotte Frenkel"], "abstract": "The demand for low-power inference and training of deep neural networks (DNNs) on edge devices has intensified the need for algorithms that are both scalable and energy-efficient. While spiking neural networks (SNNs) allow for efficient inference by processing complex spatio-temporal dynamics in an event-driven fashion, training them on resource-constrained devices remains challenging due to the high computational and memory demands of conventional error backpropagation (BP)-based approaches. In this work, we draw inspiration from biological mechanisms such as eligibility traces, spike-timing-dependent plasticity, and neural activity synchronization to introduce TESS, a temporally and spatially local learning rule for training SNNs. Our approach addresses both temporal and spatial credit assignments by relying solely on locally available signals within each neuron, thereby allowing computational and memory overheads to scale linearly with the number of neurons, independently of the number of time steps. Despite relying on local mechanisms, we demonstrate performance comparable to the backpropagation through time (BPTT) algorithm, within ~ 1.4 accuracy points on challenging computer vision scenarios relevant at the edge, such as the IBM DVS Gesture dataset, CIFAR10-DVS, and temporal versions of CIFAR10, and CIFAR100. Being able to produce comparable performance to BPTT while keeping low time and memory complexity, TESS enables efficient and scalable on-device learning at the edge.", "sections": [{"title": "I. INTRODUCTION", "content": "With the increasing ubiquity of low-power electronic devices and the rapid advances in artificial intelligence, particularly in deep neural networks (DNNs), there has been a growing interest in bringing intelligence to the edge [1]\u2013[3]. The conventional approach, known as offline training, involves training DNNs in the cloud, where computational resources are abundant, and subsequently deploying the trained models on edge devices. However, certain use cases, such as those involving privacy concerns or the need for real-time model adaptation, render the offline approach unsuitable. In these scenarios, an on-device learning paradigm is essential. This approach requires the development of energy-efficient models and DNN learning rules that operate within the constraints of edge devices [4], [5].\nIn recent years, biologically plausible models such as spiking neural networks (SNNs) have got attention as energy-efficient alternatives to conventional DNN, owing to their unique spatio-temporal processing capabilities, event-driven nature, and binary spiking activations [6]\u2013[8]. While these features make SNNs promising candidates for enabling energy-efficient inference at the edge, new solutions for solving both the spatial and temporal credit assignment problems are needed for resource-constrained scenarios. For example, in an SNN with L layers and n neurons per layer, the backpropagation through time (BPTT) algorithm (Fig. 1a) exhibits time and memory complexities of $O(TLn^2)$ and $O(TLn)$, respectively, where T denotes the length of the input sequence. This dependency on T makes BPTT impractical for on-device learning on low-power edge devices [8]\u2013[10].\nTo address these limitations, several alternatives have been proposed to achieve local credit assignment. For spatial credit assignment, methods such as feedback alignment (FA) and direct feedback alignment (DFA) employ random matrices to propagate error signals or directly project errors to individual layers, thereby reducing layer dependencies [11]\u2013[13]. Similarly, the direct random target projection (DRTP) method [14] projects targets generated from classification labels instead of output errors, allowing for independent and forward layer updates. Other biologically plausible approaches replace the backward pass in BP with an additional forward pass [15], [16]. Although these methods show promise, they often suffer from slow convergence and scalability issues when applied to deep networks. For instance, DFA experiences a ~ 16% accuracy drop compared to BP on CIFAR10 in a five-layer model [17], while the method proposed in [15] does not scale beyond two-layer models. Recently, [17] introduced a local learning rule inspired by neural activity synchronization (LLS), which uses fixed periodic basis vectors for layer-wise training, demonstrating performance comparable to BP in fairly large datasets, including CIFAR100, and Tiny ImageNet.\nFor temporal credit assignment in SNNs, methods inspired by three-factor learning rules leverage eligibility traces [18] to preserve temporal information in a way that is biologically plausible. For example, [9] introduced e-prop, a method that uses eligibility traces to address temporal credit assignment in SNNs with explicit recurrent connections, while relying on BP or DFA for spatial credit assignment. Other approaches, such as [19], [20], combine eligibility traces with DRTP"}, {"title": "II. BACKGROUND", "content": "In this section, we introduce the spiking neuron models adopted here, the mathematical notation, gradient-based opti-"}, {"title": "A. LIF model", "content": "We adopt the leaky integrate-and-fire (LIF) neuron model to implement spiking behavior. The discrete LIF neuron model is mathematically described as follows:\n$u_i^{(l)}[t] = \\gamma (u_i^{(l)}[t-1] - v_{th} o_i^{(l)}[t-1]) + \\sum_j W_{ij}^{(l)}o_j^{(l-1)}[t]$,\n$o_i^{(l)}[t] = \\Theta(u_i^{(l)}[t] - V_{th})$,\nwhere, $u_i^{(l)}[t]$ represents the membrane potential of the i-th neuron in layer l at the time step t, and $W_{ij}^{(l)}$ is the strength of the synaptic connection between the i-th post-synaptic neuron in layer l and the j-th pre-synaptic neuron in layer l \u2013 1. The parameter $\u03b3$ is the leak factor, producing an exponential decay of the membrane potential over time. The threshold voltage is denoted by $U_{th}$, and $\u0398$ represents the Heaviside function ($\u0398(x) = 1$ if $x > 0$ and 0 otherwise). When $u_i^{(l)}[t]$ reaches $U_{th}$, the neuron fires, producing a binary spike output $o_i^{(l)}[t] = 1$. This firing triggers a subtractive reset mechanism, represented by the reset signal $v_{th}o_i^{(l)}[t]$, which reduces $u_i^{(l)}[t]$ by $v_{th}$."}, {"title": "B. Gradient-based optimization for SNNs", "content": "We now describe how gradient-based optimization is applied to SNNs.\nGiven a dataset $D = \\{(x^i, y^{*i})\\}_{i=1}^N$, where N is the number of samples, x represents the input data, and $y^*$ denotes the corresponding labels, and an SNN model with parameters $W = \\{W^{(l)}\\}_{l=1}^L$, where L is the number of layers, the optimization goal is to minimize a loss function L,\n$W := arg min_W L(D; W)$.\nThis minimization is solved using (stochastic) gradient descent, where the parameters are iteratively updated as:\n$W^{(l)} := W^{(l)} - \\eta \\frac{\\partial L}{\\partial W^{(l)}}$,\nwhere \u03b7 is the learning rate and $\\frac{\\partial L}{\\partial W^{(l)}}$ represents the gradient of the loss function with respect to the parameters of the l-th layer. The gradients are computed using the BPTT algorithm, which applies the chain rule over both space (i.e. layers) and time:\n$\\frac{\\partial L}{\\partial W^{(l)}} = \\sum_{t=1}^T \\frac{\\partial L}{\\partial u_i^{(l)}[t]} \\frac{\\partial u_i^{(l)}[t]}{\\partial W^{(l)}}$,\nwhere T is the total number of time-steps of the input sequence x. Due to the recurrent nature of SNNS, $\\frac{\\partial L}{\\partial u_i^{(l)}[t]}$ depends on the entire history of the model:\n$\\frac{\\partial L}{\\partial u_i^{(l)}[t]} = \\frac{\\partial L}{\\partial o_i^{(l)}[t]} \\frac{\\partial o_i^{(l)}[t]}{\\partial u_i^{(l)}[t]} + \\frac{\\partial L}{\\partial u_i^{(l)}[t+1]} \\frac{\\partial u_i^{(l)}[t+1]}{\\partial o_i^{(l)}[t]} \\frac{\\partial o_i^{(l)}[t]}{\\partial u_i^{(l)}[t]}$,\nwhere the term $\\frac{\\partial o_i^{(l)}[t]}{\\partial u_i^{(l)}[t]}$ requires information from all subsequent layers (L \u2013 l), while $\\frac{\\partial u_i^{(l)}[t+1]}{\\partial o_i^{(l)}[t]}$ depends on the full temporal history. Thus, BPTT is neither spatially nor temporally local and incurs high computational costs."}, {"title": "C. Three-factor learning rules", "content": "Three-factor learning rules [18] represent a biologically plausible framework for synaptic plasticity, where synapse updates are determined by the interaction of three key factors: pre-synaptic activity, post-synaptic activity, and a top-down learning signal.\nThe core idea of three-factor learning rules is the concept of an eligibility trace ($e_{ij}$), which is a transient variable that encodes synaptic changes driven by pre- and post-synaptic activity. This trace persists over time, allowing updates to occur when a delayed top-down learning signal arrives. The eligibility trace is typically modeled as a function of the pre- and post-synaptic activity, decaying over time according to the following recurrent formulation:\n$e_{ij}^{(l)}[t] = \\beta e_{ij}^{(l)}[t-1] + f(o_i^{(l)}[t])g(o_j^{(l-1)}[t])$,\nwhere $\\beta$ is an exponential decay factor, $f(o_i^{(l)}[t])$ and $g(o_j^{(l-1)}[t])$ are element-wise functions of the post-synaptic activity $o_i^{(l)}[t]$ and pre-synaptic activity $o_j^{(l-1)}[t]$, respectively. This formulation ensures that synapses are \"eligible\" for updates only when neuronal activity meets certain conditions.\nThe actual synaptic update is computed by modulating the eligibility trace with a top-down learning signal $m_i[t]$, which represents error or reward information. The weight update rule can be expressed as:\n$\\Delta W_{ij} = \\sum_t m_i[t]e_{ij}^{(l)}[t]$,\nwhere the learning signal $m_i[t]$ is typically derived from task-relevant objectives, such as the gradient of a loss function or a reward signal. This modulation ensures that synaptic updates are oriented towards minimizing a particular objective.\nThree-factor learning rules have demonstrated effectiveness in training artificial SNNs, as evidenced by [9], [10], [20]\u2013[23]. Notably, they offer a biologically plausible approximation of BPTT under specific conditions [9], [24]. Despite their promise, previous works leveraging eligibility traces for temporal credit assignment still rely on global error propagation across layers, Fig. 1b, for achieving performance comparable to BPTT [10], [21], [22]. Which results in a time complexity of $O(Ln^2)$."}, {"title": "III. PROPOSED METHOD - A SCALABLE FULLY LOCAL LEARNING RULE", "content": "To address the challenges of temporal and spatial credit assignment for SNNs, we propose TESS, a scalable temporally and spatially local learning rule that is biologically inspired. It is designed as a three-factor learning rule that operates efficiently with low computational and memory overhead, making it suitable for resource-constrained edge devices. Specifically, TESS is presented in Fig. 2 and relies on two key components to achieve temporal and spatial locality:"}, {"title": "a) Temporal Credit Assignment with Eligibility Traces:", "content": "As discussed in Section II-C, eAs discussed in Section II-C, eligibility traces are transient variables driven by changes in pre- and post-synaptic activity. These traces encode the temporal history of synaptic connections, identifying synapses as candidates for updates and thereby addressing the temporal credit assignment problem by tracking neuronal activity.\nHowever, eligibility traces as formulated in (3) incur a memory complexity of $O(n^2)$, which is prohibitive for deep SNN models. To overcome this, and in line with prior works [4], [21], [22], we restrict the formulation to instantaneous eligibility traces by setting $\u03b2 = 0$ in (3). This modification reduces the memory complexity to $O(n)$ by independently tracking pre- and post-synaptic activity traces.\nIn TESS, we utilize two eligibility traces: one based on pre-synaptic activity (shown in red in Fig. 2) and one based on post-synaptic activity (shown in blue in Fig. 2). These two components mimic STDP mechanisms, capturing causal (red signals) and non-causal (blue signals) dependencies between pre- and post-synaptic activity.\nWe first consider the eligibility trace with causal information. Using (3), the function $f(\u00b7)$ is defined as a secondary activation function $\u03a8(\u00b7)$ applied to the membrane potential $u_i^{(l)}[t]$. This serves a role analogous to surrogate gradients in gradient-based approaches [25]. The function $g(\u00b7)$ is a low-pass filter applied to the input spikes: $\\sum_{t'=0}^{t-1} A_{pre}^{t-t'} o_j^{(l-1)}[t']$, where $A_{pre}$ is an exponential decay factor, representing the trace of pre-synaptic activity. To compute this trace in a forward-in-time manner, we introduce a recurrent variable $q_i^{(l)}[t]$, defined as:\n$q_i^{(l)}[t] = A_{pre} q_i^{(l)}[t - 1] + o_j^{(l-1)}[t]$,\nwhich allows the causal eligibility trace to be expressed as:\n$e_p[t] = A_{pre} \\Psi(u_i^{(l)}[t]) q_i^{(l)}[t]$,\nwhere $A_{pre}$ controls the amplitude of the eligibility trace. For all experiments, $A_{pre}$ is set to 1.\nFor the second eligibility trace, $e_{post}[t]$, we use a low-pass filter over the activations of the membrane potential $\\Psi (u_i^{(l)}[t]$: $\\sum_{t'=0}^{t-1} A_{post}^{t-t'} \\Psi (u_i^{(l)}[t'])$. This can also be expressed as a recurrent equation by introducing a new variable $h_i^{(l)}[t]$:\n$h_i^{(l)}[t] = A_{post} h_i^{(l)}[t - 1] + \\Psi (u_i^{(l)}[t - 1])$,\nand the non-causal eligibility trace is then given by:\n$e_{post}[t] = A_{post} h_i^{(l)}[t] \\otimes o_j^{(l-1)}[t]$,\nwhere $A_{post}$ determines the inclusion of non-causal terms, with $A_{post} = +1$ for positive inclusion, $A_{post} = -1$ for negative inclusion, and $A_{post} = 0$ for exclusion."}, {"title": "b) Spatial Credit Assignment with Locally Generated Learning Signals:", "content": "As discussed in Section II-C, while eligibility traces address the temporal credit assignment, synaptic updates require a top-down learning signal, denoted as $m_i^{(l)}[t]$, to modulate the eligibility traces and solve the spatial credit assignment problem. Unlike prior approaches that rely on"}, {"title": "B. Computational and Memory Cost", "content": "In this subsection, we analyze the theoretical computational improvements of TESS in terms of multiply-accumulate (MAC) operations and memory requirements, comparing it to BPTT and S-TLLR. We build on the analysis presented in [21], which we expanded to include the effects of the spatial and temporal locality of TESS on computational and memory costs.\n1) Memory Requirements: We begin by discussing memory requirements, focusing on the overhead associated with synaptic updates, excluding the state variables required for SNN inference (e.g., membrane potential) According to [21], the memory requirements for BPTT and S-TLLR can be estimated using the following equations:\n$Mem_{BPTT} = T\\sum_{l=0}^L n^{(l)}$, $Mem_{S-TLLR} = 2\\sum_{l=0}^L n^{(l)}$,\nwhere, $n^{(l)}$ represents the number of neurons in layer l, L is the total number of layers in the model, and T is the total number of time steps (length of the input sequence). The factor of 2 in (13) arises from the inclusion of both causal and non-causal terms in the computation of eligibility traces when $A_{pre}$ and $A_{post}$ are nonzero.\nFor TESS, the memory requirements are determined by analyzing the variables involved in (10) and (11). From (10), $m_i^{(l)}[t]$ depends on the output spikes $o_i^{(l)}[t]$, which are computed using (9). Since this signal is derived directly from the current output spikes, it does not require additional memory storage and can be computed on the fly. Similarly, $\\Psi(u_i^{(l)}[t])$ is a function of the current membrane potential and does not require additional memory, as it can also be computed on the fly. In contrast, the term $q_i^{(l)}[t]$ accounts for the history of pre-synaptic activity and requires memory proportional to the number of input neurons, $n^{(l-1)}$. Likewise, $h_i^{(l)}[t]$ represents the history of post-synaptic activity and requires memory proportional to the number of output neurons, $n^{(l)}$. By combining these terms, the total memory requirement for TESS can be expressed as:\n$Mem_{TESS} = 2 \\sum_{l=0}^L n^{(l)}$.\nThis demonstrates that TESS achieves memory efficiency comparable to S-TLLR while avoiding the significant overhead associated with the time-dependent storage of BPTT.\n2) Computational Requirements: Here, we estimate the computational requirements by evaluating the number of MAC operations needed to compute the learning signals. Specifically, we compare the operations required to calculate $\\frac{\\partial L}{\\partial u_i^{(l)}[t]}$ for BPTT, $\\frac{\\partial m^{(l)}}{\\partial u_i^{(l)}}$ local for S-TLLR, and $m_i^{(l)}[t]$ for TESS. For simplicity, we assume a fully connected network and disregard any element-wise operations.\nFor both BPTT and S-TLLR, the error signals are computed by propagating errors from the last layer to the first. If the final error vector has a dimension of $n^{(L)}$, it is propagated to the"}, {"title": "A. Algorithm Implementation", "content": "The TESS algorithm operates iteratively, updating eligibility traces, computing learning signals, and adjusting weights for each time step. A pseudo-code implementation for layer l is provided in Algorithm 1."}, {"title": "C. Comparison with other local learning rules", "content": "In this subsection, we analyze the time and memory complexity of TESS in comparison to other approaches. For this analysis, we consider a fully connected spiking neural network with L layers, each containing n neurons, trained on temporal tasks with T time steps, and a target space of dimensionality C.\nAs discussed in Section II-B, BPTT requires access to the entire history of the network, resulting in a memory complexity of $O(TLn)$. Similarly, since learning signals are produced by propagating errors through layers for all time steps, the time complexity is $O(TLn^2)$. This implies that tasks with greater temporal dependencies significantly increase the cost of BPTT.\nTo address this dependency on time steps, temporal local methods such as e-prop [9], OSTL [10], OTTT [22], and S-TLLR [21], as well as fully local methods like OSTTP [20] and ETLP [19], leverage eligibility traces. This strategy allows them to maintain a memory requirement independent of time steps. However, methods like e-prop, OSTL, ETLP, and OSTTP exhibit a memory complexity of $O(Ln^2)$, which can become prohibitively expensive for large models. In contrast, methods such as OTTT and S-TLLR achieve a more efficient linear memory complexity of $O(Ln)$, making them more scalable. Similarly, TESS has been designed to exhibit linear memory complexity.\nRegarding time complexity, methods such as e-prop, OSTL, OTTT, and S-TLLR rely on backpropagation of errors through layers to generate learning signals, incurring a complexity of $O(Ln^2)$. In contrast, OSTTP and ETLP use the DRTP mechanism [14] to achieve spatial locality, reducing the time complexity to $O(LCn)$, where C < n. TESS follows a similar approach, generating learning signals locally and achieving the same reduced time complexity of $O(LCn)$.\nCompared to other methods, TESS offers the best combination of memory and time complexity due to its spatial and temporal locality features. Furthermore, TESS achieves this efficiency while delivering performance comparable to methods with higher memory and time requirements, as discussed in the next section. A summary of this comparison is presented in Table I."}, {"title": "IV. EXPERIMENTAL EVALUATION", "content": "In this section, we evaluate the performance of our training algorithm, TESS, on multiple datasets, assessing its ability to achieve competitive accuracy at reduced cost. To do so, we compare TESS with a broad range of non-local to local learning state-of-the-art methods."}, {"title": "A. Experimental Setup", "content": "This subsection describes the datasets, pre-processing steps, and model architectures used to evaluate our method.\n1) Datasets: We evaluated TESS using four datasets: CIFAR10 [26], CIFAR100 [26], IBM DVS Gesture [27], and CIFAR10-DVS [28]. The preprocessing steps for each dataset are as follows:\n\u2022 CIFAR10 and CIFAR100: Images were presented to the SNN models for 6 time steps to simulate a temporal dimension. Data augmentation during training included increasing image size via zero-padding of 4, random"}, {"title": "B. Results", "content": "This subsection presents the results of using TESS across the four datasets, highlighting its performance on image classification tasks and its sensitivity to hyperparameters through ablation studies.\n1) Ablation Studies on Eligibility Traces: First, we examine the effect of the $A_{post}$ parameter to include or exclude the non-causal contribution on the learning process. To assess the influence of this parameter, we set $A_{post}$ to values of -1 (negative inclusion), +1 (positive inclusion), and 0 (exclusion). We then trained a VGG-9 model on the four datasets described in Section IV-A1, performing five independent trials. The mean and standard deviation of the results are reported in Table II.\nFrom the results, we observed that, with the exception of the CIFAR10-DVS dataset, the positive inclusion of $A_{post}$ improves model performance across all other datasets, with gains ranging from 0.23 to 1.81 accuracy points compared to when the parameter is excluded. In contrast, the negative inclusion of $A_{post}$ provides a performance improvement only for the IBM DVS Gesture dataset.\nBeyond performance, note that the inclusion of the $A_{post}$ parameter also impacts the memory usage of TESS. As discussed in Section III-B1, when $A_{post} \\neq 0$, additional memory must be allocated for storing the trace of output spikes, $h_i^{(l)}[t]$. Thus, while the inclusion of $A_{post}$ can enhance model performance, it effectively doubles the memory requirements of the algorithm, allowing for a trade-off between performance and memory usage.\n2) Performance on Image Classification: In this subsection, we compare the performance of TESS with that of previously reported methods, including non-local, partially local, and fully local learning approaches, on the four datasets described in Section IV-A1. The results are presented in Table III.\nOn CIFAR10-DVS, TESS performs on par with prior methods, including those based on backpropagation and temporally local approaches such as [21], [22], with a maximum accuracy drop of 2.27%, except for [31]. A similar trend is observed on CIFAR10 and CIFAR100, where TESS demonstrates a maximum accuracy drop of approximately 1%. In contrast, on the DVS Gesture dataset, TESS achieves the best performance among all previously reported methods, including non-local approaches, despite being fully local. Notably, TESS outperforms [23], the other fully local method, by approximately 3 accuracy points. These results highlight the capability of TESS to train models in a fully local manner while achieving performance comparable to or better than non-fully local methods.\nIt is worth noting that previous works may differ in experimental implementations, introducing variances that are challenging to quantify in the final results. To address this, we established two baselines for each dataset using BPTT and S-TLLR [21], ensuring consistent model implementations, data preprocessing, and hyperparameter settings. Relative to these baselines, TESS outperforms S-TLLR on DVS Gesture, CIFAR10, and CIFAR100 while performing on par with or slightly better than BPTT. The only exception is on CIFAR10-DVS, where TESS lags behind BPTT by 1.4 and S-TLLR by 0.14 accuracy points. Furthermore, TESS achieves these results while significantly reducing the computational cost of generating learning signals, with a reduction in MAC operations of 205 - 661\u00d7 thanks to its local learning signal generation. Similarly, TESS reduces memory usage by a factor of 3 - 10\u00d7 compared to BPTT.\nThese findings clearly demonstrate the ability of TESS to train SNN models with accuracy comparable to BPTT while dramatically reducing computational and memory requirements. This makes TESS a highly suitable candidate for enabling learning on low-power devices with constrained resources."}, {"title": "V. CONCLUSIONS AND PERSPECTIVES", "content": "We introduced TESS, a temporally and spatially local learning rule for SNNs, designed to meet the demand for low-power, scalable training on edge devices. TESS achieves competitive accuracy with BPTT while reducing memory complexity from $O(TLn)$ to $O(Ln)$ and time complexity from"}]}