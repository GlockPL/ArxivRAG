{"title": "Language Models as Semiotic Machines: Reconceptualizing AI Language Systems through Structuralist and Post-Structuralist Theories of Language", "authors": ["Elad Vromen"], "abstract": "This paper proposes a novel framework for understanding large language models (LLMs) by reconceptualizing them as semiotic machines rather than as imitations of human cognition. Drawing from structuralist and post-structuralist theories of language specifically the works of Ferdinand de Saussure and Jacques Derrida-I argue that LLMs should be understood as models of language itself, aligning with Derrida's concept of \"writing\" (l'\u00e9criture).\n\nThe paper is structured into three parts. First, I lay the theoretical groundwork by explaining how the word2vec embedding algorithm operates within Saussure's framework of language as a relational system of signs. Second, I apply Derrida's critique of Saussure to position \"writing\" as the object modeled by LLMs, offering a view of the machine's \"mind\" as a statistical approximation of sign behavior. Finally, the third section addresses how modern LLMs reflect post-structuralist notions of unfixed meaning, arguing that the \"next token generation\" mechanism effectively captures the dynamic nature of meaning.\n\nBy reconceptualizing LLMs as semiotic machines rather than cognitive models, this framework provides an alternative lens through which to assess the strengths and limitations of LLMs, offering new avenues for future research.", "sections": [{"title": "Introduction", "content": "Recent advancements in artificial intelligence, particularly in language models,\nhave sparked lively debates in both casual conversations and academic circles.\nSome dismiss these models as mere poor imitations\u00b9 of the human mind, while\nothers herald them as \"innovative scientific explanations that push aside all\nprevious linguistic theories\" \u00b2. At the heart of this debate lies a fundamental\nquestion: how similar- or different are these AI systems to the way humans\nacquire and use language? And what, if any, is their contribution to our under-\nstanding of language?\n\nTwo long-standing issues often emerge in these discussions:\n\n1.  The vast gap between the training data used to develop language models\n    and the limited linguistic input that children are exposed to.\n2.  The contrast between our human notion of \"understanding\" the meaning\n    of a statement and AI's method of generating text through statistical\n    prediction of the next word.\n\nWhile these concerns are valid, I believe the confusion stems from a funda-\nmental lack of clarity: what exactly are language models modeling? Instead\nof viewing these systems as imitations of human minds or thinking processes\n(as the term \"artificial intelligence\" might imply), I propose that we see them\nas semiotic machines representations of language itself as a system of signs,\nspecifically in the form of writing.\n\nBy adopting this perspective, we can better grasp the true nature of lan-\nguage models, enhance their utility, and more accurately assess their scientific\nand epistemic contributions. I aim to apply structuralist and post-structuralist\ntheories to analyze the semiotic structure and concept of meaning in language\nmodels. This framework will help us both understand the epistemic status of\nthese models and consider them as potential empirical evidence for broader\nphilosophical theories of language.\n\nTo do this, I will first establish the theoretical groundwork by tracing the\ndevelopment of artificial intelligence algorithms as opposed to the formal encod-\ning of letters in computers, drawing from Ferdinand de Saussure's structuralist\nlinguistic theory in Course in General Linguistics\u00b3.\n\nNext, I will clarify the object of modeling in language models through\nJacques Derrida's concept of l'\u00e9criture (writing) as presented in Of Gramma-\ntology\u2074."}, {"title": "Part One - Structuralism and Word Embedding:\nFirst Steps Toward a Semantic Theory of AI", "content": "When selecting a theory of language especially concerning semantic meaning\nin Large Language Models (LLMs) it is crucial to consider specific constraints\nthat ensure the theory is both adequate and well-reasoned.\n\nThe first constraint is that the theory should be non-referential it should\nnot rely on the traditional distinction between sign and reference or define se-\nmantic meaning by denotation to objects in the world. This is because language\nmodels function entirely within a closed textual system, without engaging with\nany external world (I will not discuss RLHF techniques in this article, which\nrequires further consideration, and will primarily focus on LLM pretraining).\n\nThe second constraint is that the theory should ideally be non-mentalistic. In\nother words, it should avoid requiring concepts like \"consciousness\" or \"mind\"\nas we understand them in humans. While it's possible to develop a mentalistic\ntheory, this would involve proving that neural networks can achieve some form\nof consciousness a challenge that may be better avoided.\n\nSignifier, signified: what is missing in binary representation\nof words\n\nThe fundamental challenge in Natural Language Processing (NLP) arises from\nthe gap between the computer's ability to handle representations as a compu-\ntational machine and language as a system of meaning. In other words, how\ncan binary sequences in a computer's memory represent the semantic meaning\nof words and sentences?\n\nFerdinand de Saussure's work offers insight here. He posits that language\nis a system of signs. In his view, each sign consists of two parts: the signifier\n(the form, such as a word or sound) and the signified (the concept or meaning\nit represents). Crucially, Saussure argues that the relationship between these\ntwo components is arbitrary (there's no inherent reason why the word \"t-r-e-\ne\" represents the concept of a tall, woody plant, for example). Consequently, a\ndeterministic representation of the signifier through other signifiers (such as rep-\nresenting a letter by a number, like in the ASCII table) serves only to represent\nthe signifier, not the signified. This deterministic mapping allows computers to\nstore textual information, which can later be decoded by a human mind that\nknows the language. However, this process doesn't help machines decode the\ndeeper, signified layer of meaning on their own.\n\nHowever, Saussure's theory opens a promising path for modeling meaning.\nThis is because his conception of language is not subjective. Language, accord-\ning to Saussure, is not merely a cognitive function of individuals, but a collective\nproduct a socio-linguistic network that fixes signifiers and their relationships,\nforming a meaningful structure. A human mind can engage in language, but"}, {"title": "Word2Vec", "content": "Word2Vec (w2v) was the first algorithm to significantly enhance language mod-\nels' capability to represent semantic information. It tackles the 'language prob-\nlem' by generating a vector representation (an array of numbers) for each word,\nbased on its relationship to other words in the dataset. The algorithm, a neural\nnetwork, takes the current word as input and predicts the next word in the\nsequence. Through this iterative process, the network learns to refine its pre-\ndictions by statistically evaluating the contexts in which words appear within\nsentences. Essentially, the algorithm creates a multi-dimensional topographic\nmap of the statistical likelihood of word substitution.\n\nThe output of Word2Vec is a vector representation for each word, which\nencodes not only the deterministic signifier but also the contextual meaning\nof the word within the dataset. I contend that this contextual representation\nconstitutes the signified aspect of these signs, within a conceptual system, thus\nimbuing the vector array produced by Word2Vec with the qualities of a Saus-\nsurean sign."}, {"title": "Large Language Models", "content": "Large language models are a form of artificial intelligence that have achieved\nnear-human proficiency in language use at a communicative level. Several tech-\nnical aspects relevant to language and meaning arise from these models.\n\nFirst, it's important to note that the context-based representation intro-\nduced by Word2Vec remains foundational in training large language models.\nThe GPT series exemplifies this technology, and the paper introducing GPT-2\u2077\nemphasized generating contextual language representations before adapting to\nspecific tasks. In other words, these models focus on capturing the relationships\nbetween linguistic elements in the dataset as a precursor to solving particu-\nlar tasks. Understanding Word2Vec's semantic topography offers an intuitive\nexplanation of this pre-training process.\n\nSecond, It is essential to recognize that large language models go beyond\nthe basic Word2Vec framework. The representations created by these models\nencompass more than just individual words; they include sentences and other\nlinguistic structures (A thorough technical explanation of these complexities\nwould involve discussions of RNNs and LSTMs, but this falls outside the scope\nof this article)."}, {"title": null, "content": "Third, what sets large language models apart from other models is the num-\nber of parameters (i.e., the complexity of their modeling functions) and the size\nof the datasets used for training. Current language models are exposed to an ex-\ntensive amount of information representing significant portions of all content\navailable on the internet-which causes the object modeled by these language\nmodels to approximate language itself.\n\nTo summarize the first part, we have observed that modeling the semantic\nmeaning of text involves algorithms that create contextual representations of\nsigns, aligning with Saussure's structuralist perspective. In the next section, we\nwill explore the textual object that these algorithms model and explain why its\nstatistical analysis is a sufficient approach for capturing semantic meaning."}, {"title": "Part Two - Data as \"Writing\"", "content": "An important observation is that every language model develops its represen-\ntation of the signified and, consequently, its ability to use language through\nexposure to a multiplicity of written signifiers. Therefore, I will rely on Jacques\nDerrida's deconstruction of the pair of concepts: writing and speech. It is sig-\nnificant that in the introduction to Of Grammatology, Derrida states that \"the\nentire field covered by the cybernetic program will be the field of writing... To\nsuppose that the theory of cybernetics can dislodge by itself all the metaphysi-\ncal concepts all the way to the concepts of soul, of life, of value, of choice, of\nmemory which until recently served to separate the machine from man it must\nconserve, until its own historico- metaphysical belonging is also denounced, the\nnotion of writing\".8\n\nDerrida's reading of Saussure reveals a distinct preference in Saussure's work\nfor phonetic pronunciation, driven by the belief that it is \"closer\" to the signified\nor the ideal mental content. This contrasts with writing, which is depicted as a\n\"sign of a sign\", representing a system external to the primary coupling of the\nphonetic signifier to the signified. Derrida identifies this hierarchy as part of lo-\ngocentrism and the ancient perception that equates meaning with the speaker's\nintention. Moreover, logocentrism preserves \"the distinction between the sensi-\nble and the intelligible\" and \"the reference to a signified able to \"take place\",\nin its intelligibility, before its \"fall\", before any expulsion into the exteriority of\nthe sensible here below\" 10\n\nThis assumption is fundamentally challenged in the philosophy of language\nwithin artificial intelligence. When we discuss the linguistic qualities of a lan-\nguage model, we always start with written signs. Any ascent to the realm of\nmeaning is a byproduct of extensive statistical analysis of an array of exclusively\nwritten signs. The phonetic medium does not exist, and there is no basis for\nassuming its precedence or proximity to a \"mind\" that serves as the seat of the\nsignified. The \"meaning\" of language models results from mapping relation-\nships between instances of signs. The 'intelligible' emerges from the \"sensible\",\nempirically.\n\nThe perception of writing's inferiority to speech that Derrida identifies in\nSaussure arises from a set of hierarchical dichotomies embedded in logocentrism."}, {"title": "Presence/Representation, Reality/Image", "content": "In logocentric thought, \"one submits the sign to the question of essence\" 11.\nThere is a precedence of presence over the sign, which is perceived as represen-\ntation. One can summarize the logocentric perception as follows: the world is a\ncollection of states of affairs. Thought is an image of the world, and language is\nan image of thought. The truth values of all propositions are measured concern-"}, {"title": null, "content": "Derrida proposes to liberate the sign from its subordination to reality. This\nallows \"Reading, and therefore writing, the text...(to be) \"originary\" operations\nwith a view to a sense that they do not first have to transcribe or discover, which\nwould not therefore be a truth signified in the original element and presence\". 12\nThe representational model is thus turned on its head. Instead of writing being a\nparasite on language, thought, and the world, the system of signs is established\nas primary, and writing becomes the paradigm of an independent system of\nsigns.\n\nLet us understand this shift as a foundation for the algorithmic model of\nmeaning. A language model is a statistical approximation of the relationships\nbetween signifiers, leading to a contextual representation. This statistical \"pro-\njection\" is the only notion of signifieds that can be attributed to the computa-\ntional system. In fact, rather than \"thought\" being a projection of a \"world\"\nand language a projection of thought, the language model represents a \"thought\"\nor meaning that is a projection of writing. Writing consists of a collection of\nunique signifiers that appear in specific sequences. Post-textual thought (artifi-\ncial intelligence) serves as a statistical description of the relationships between\noccurrences of signifiers in the dataset."}, {"title": "Language-Thought-World Models", "content": "We can try to describe an extension of the logocentric model, which will include\nlanguage models, in the following way:"}, {"title": null, "content": "Let's refine the diagram using the Saussurian model, as described by Derrida:"}, {"title": null, "content": "The diagram draws a parallel between the phonetic signifier in traditional\nlinguistics and the token inserted into the algorithm in AI language models.\nBoth are signifiers they are nominal yet arbitrary. Their meanings are deter-\nmined by their connections to signifieds. The coupling between the phonetic\nsignifier and the ideal signified in Saussure corresponds to the relationship be-\ntween tokenization and the embedding as a coordinate within the network model\nin which it occupies a position in N-dimensional space. The resulting network\nmodel serves as the modeling of the system of signifieds.\n\nBoth diagrams position writing as an intermediate stage. On the side of\n\"presence\" (and mind), writing is a parasitic system, a \"sign of a sign\", in\ncontrast to the phonetic signifier's coupling to the signified.\n\nConversely, from the \"perspective\u201d of artificial intelligence, writing is the\npresence in relation to the \"thought model\" and the \"world model\", and it\nconstitutes the source that the signified network model represents. From this\nperspective, writing functions as a world."}, {"title": "Inside/Outside: Artificial Intelligence as the Ultimate Sin", "content": "Derrida identifies Saussure's and logocentrism's perception of writing as an ex-\nternal to the essential connection between the phonetic signifier and the mental\nsignified. \"Writing would thus have the exteriority that one attributes to uten-\nsils; in addition it is an imperfect tool and a dangerous, one would say almost\nmaleficent, technique... a sin... inversion of the natural relationship between\nthe soul and the body...\" 13\n\nDerrida's originality allows him to uncover the cultural bias against writing\nand to highlight the radical positions he describes. In contrast, the attitude\ntoward artificial intelligence is far more pronounced. Artificial intelligence is\nviewed as the ultimate \"sin\". The machine's use of language is inherently de-\ntached from the unity of language in the mind. According to the logocentric\nmodel of thought, writing is peripheral, while machine thought is even further\nremoved a derivative of writing itself (emerging from the statistical analysis of\ntext).\n\nDerrida exposes the logocentric fallacy: the longing for a clear hierarchy\nbetween origin and copy, reality and representation. Saussure and his tradition"}, {"title": null, "content": "always strive to restore the natural order, resisting \"temptation\" and \"arti-\nficiality\". Consequently, signs of inverted order are perceived as perversions.\nHowever, this hierarchical perception is misguided. Writing is woven into the\nessence of language. Derrida bases his critique on a commitment to Saussure's\nown principle of the arbitrariness of the sign- \"The thesis of the arbitrariness\nof the sign should interdict a radical distinction between the linguistic and the\ngraphic sign\" 14\n\nFor Derrida, writing is the fundamental paradigm of language. Language\nconsists of a collection of signifiers, whether vocal or written, governed by\n\"the regulated play of their differences.\" 15 This differentiated system gener-\nates 'meaning' independently of the signifier's proximity to any mind or its\nrepresentation of any world. The sign occupies a specific position within the\nsystem as a difference, distinct from any \"background\". No naturalistic entity\nserves as a source that language represents or from which meaning is derived.\nInstead, meaning is continuously established through differentiation. Hence,\nDerrida's concept of meaning as an attribute of the system of signs leads to\na non-mentalistic semantic theory. This approach weaves both \"writing\" and\nlanguage models from peripheral representations into the core and essence of\nwhat semantic meaning truly is."}, {"title": "Part Three - Post-Structuralism and Text Gen-\neration", "content": "Up to this point, we have established a non-referential and non-mentalistic se-\nmantic theory that can be attributed to both humans and artificial intelligence.\nHowever, we are left with a structuralist conception of meaning using the anal-\nogy of word embedding as if the meaning of a sign (the signified) is a nominal\nvalue which, although it is a function of the sign's position in the system of\nsigns, remains fixed. This concept has two significant issues:\n\n1.  From the philosophy of language perspective, it is evident that this is\n    not how meaning operates. \"The value of the notion of literal meaning\n    appears more problematic than ever.\" 16\n2.  This perception reduces large language models to mere embedding creation\n    algorithms. In practice, however, modern language models function\n    more dynamically, primarily performing the task of text generation.\n\nFortunately, we can address these two developments by referencing \"Signa-\nture Event Context\u201d and transitioning from a structuralist to a post-structuralist\ntheory. The discussion will include a brief technical overview of the mechanism\nof text generation and a theoretical shift from the term \"sign\" to the term\n\"signifying form\"."}, {"title": "Theoretical Position", "content": "In the article \"'Signature Event Context'... in, well, context\" 17, the genealogy\nof linguistic-philosophical approaches to the origin and locus of semantic mean-\ning is explored through the contrast between language (langue) and discourse\n(based on Saussure's parole). The article describes, on one hand, the structural-\nist school, which locates semantic meaning in language:\"language, accordingly,\nprecedes discourse and makes it possible by providing a store of meanings.\" 18\nOn the other hand, it discusses representatives of the \"second linguistic turn\",\nwho argue that semantic meaning should be situated precisely in discourse. It\nalso notes that proponents of the second linguistic turn were followers of phe-\nnomenology, and from their perspective, discourse (and the semantic meaning\nthey attributed to it) was inherently tied to the need for reference.\n\nA third theoretical tradition worth mentioning is the analytic tradition, with\nJohn Searle as its (self-appointed) representative in the discussion on SEC.\nSearle introduces the distinction between \"type\" the abstract category of the\nsign, which he argues inherently contains its potential semantic meaning and\n\"token\" the specific instance of a sign in discourse, whose semantic value is\ndetermined by the possibilities inherent in its type."}, {"title": null, "content": "In contrast, Derrida represents a post-structuralist approach that opposes\nthe second linguistic turn due to his principled opposition to the \"metaphysics\nof presence\". His goal is to create a semantical framework that is not based\non the transcendental signified (as we saw in Of Grammatology), does not \"col-\nlapse\" back into dependence on reference and presence, and avoids the complete\nsubordination of the token to the type. To achieve this, he seeks to establish a\nnew concept of signs that is not conditioned by the transcendental signified, an\na priori ideal linguistic entity (the type), or by presence."}, {"title": "Signifying Form", "content": "Derrida's concept of writing views writing and language as functional systems\nthat are shaped by the sum of sign occurrences within them. Writing has two\nnecessary and distinct formal characteristics:\n\n1.  Writing as a Collection of Sign-Occurrences: Writing consists of\n    signifying forms-specific instances of signs to which additional occur-\n    rences are continuously added. These sign occurrences are not simply the\n    'theoretical bag of words' found in language, but actual instances of these\n    signs in writing (and in language more broadly, where writing serves as the\n    paradigm). They represent \"single instances of language's employment\".19\n    Two occurrences of the same word in different contexts are distinct sig-\nnifying forms. However, these sign occurrences can preserve meaning in\na non-spatial and non-temporal manner, persisting materially over time.\nThis property makes iterability (repeatability) a necessary feature of the\nsystem.\n2.  Iterability and the Rupture of Presence: Iterability gives writing its\n    nature as a 'code' that inherently involves \"a rupture in presence\".\n    (a) The Structural Orphaning of Writing from the Addressee:\n    \"Communication must be repeatable iterable in the absolute ab-\nsence of the receiver or any empirically determinable collectivity of\nreceivers.\" 20\n    (b) The Structural Orphaning of Writing from the Addressor:\n    \"To write is to produce... a machine... which my future disappear-\nance will not hinder from functioning.\" 21\n    (c) The Limitation of the Original Context's Power to Fix Mean-\n    ing: \"The limiting of the concept of context... in as much as its\nrigorous theoretical determination... is rendered impossible by writ-\ning.\" 22"}, {"title": null, "content": "The \"signifying forms\" are the discursive moments of token occurrences:\n\"They include a moment of discourse, of language in use... tokens.\"\n\nAccording to Derrida, these forms, these instances of discourse, are not in\nopposition to language (in terms of the discourse-language separation), and are\nnot hierarchically subordinate to an a priori language, but part of the unified\nphenomenon of language, which is writing. He cancels the hierarchy between\nthe a priori 'language' (langue) and its use in discourse, and establishes writing\nas a formal 'signification' space that constitutes the space in which semantic\nmeaning is actively created by the fluidity of multiple unfixed contexts.\n\nThus, a more complex concept is created than any of the previous concepts\nseparately, containing an infinite process of dialectical preservation and change.\nThe differentiation process itself occurs in writing incessantly, but not in a\n\"one-time\" manner of an event, but as a timeless, spaceless process, of which\niterability is an integral part. In this, the concept of meaning derived from the\nconcept of writing escapes the \"sources\" that fix it:\n\nOn one hand, the signifying forms in writing are not subject (in terms of\ntheir semantic value) to an a priori set of rules of language or TYPE, but are\nopen to change and expansion.\n\nOn the other hand, signifying forms are not confined to their singular \"oc-\ncurrence\" in discourse. Instead, they persist and remain open to the indeter-\nminacy created by iterability-the indeterminacy resulting from the removal of\nthe sender, recipient, reference, and context:\n\n\"A written sign... does not exhaust itself in the moment... (a) force of\nrupture... separating... from... the internal contextual chain... (and) also from\nall forms of present reference.\" 23\n\nThis dialectical process is explored in \"Signature Event Context\" in relation\nto Husserl's concept of ideality. Ideality refers to the element in language that\nis preserved over time, allowing concepts to be understood in a timeless and\nspaceless way, enabling shared understanding across different individuals.\n\n\"Ideality applies to what can and must be referred to as the same, not\nsimilar, across various temporal instantiations.\u201d 24\n\nHowever, ideality, by enabling the timeless and spaceless retention of mean-\ning, also facilitates iterability. Iterability, in turn, allows for the involvement of\nnew speakers, recipients, and contexts, thereby preventing the final stabilization\nof meaning. While there is always an \"intention\" in language use, meaning is not\nfixed to a single instance but is shaped by a \"matrix of repetition\" -the range of\ndifferent contexts in which the sentence can appear at another time, in another\nplace, with different senders and recipients, all stemming from iterability.\n\n\"meaning... ultimately prove enmeshed in a greater matrix of repetition\" 25\n\nTherefore, we can never view ideality-the timeless and spaceless nature of\nmeaning as a nominal representation. It always remains open due to the possi-\nbility of iterability. Iterability expands the notion of context beyond traditional"}, {"title": null, "content": "views, such as Frege's context principle (which ties the meaning of a statement\nto the sentence it appears in) or de Saussure's focus on the synchronic system\nof language. Instead, it suggests that the meaning of a statement is shaped by\nall possible contexts-past, present, and crucially, future. This inclusion of po-\ntential future contexts introduces inherent indeterminacy to meaning. Context\nis no longer confined to what has been or what is, but also to what might be,\nrendering the meaning of any statement perpetually open and unfixed.\n\nThe multiplicity of contexts gives the signifier a new form as a signifying\nform. The signifying form is not a container of a single, fixed meaning tied to\nan exclusive signified; rather, it operates across different contexts and allows\nmeaning to evolve through iterative writing.\n\n\"there are only contexts without any center or absolute anchoring\" 26"}, {"title": "Text Generation", "content": "In simplified terms, the operation of language models can be described as follows:\n\nText generation occurs after the model has been trained and developed a\nsystem of representations from the dataset. In other words, the model's weights\nhave been calibrated, having learned both semantic and syntactic information\nabout language (this is the concept of pre-training).\n\nA trained base language model, such as GPT, performs one core task: it\nreceives a sequence of signs (tokens, which may represent fractions of words) as\ninput and outputs a single token at a time, based on the conditional probability\nof that token relative to the input. For clarity, let's call this task a generation\nunit. Thus, when a language model generates a 10-word sentence, its output\nconsists of 10 generation units, where each subsequent unit includes the output\nof previous units as part of its input.\n\nA crucial aspect of understanding text generation is that the selection of\ntokens in each generation unit involves a sampling function. The representations\nlearned during training span a vector space, where the current input is mapped.\nThrough the attention mechanism, the model dynamically prioritizes different\nparts of the input with varying importance. This mechanism allows the model\nto weigh the relevance of each input token when predicting the next token,\nenabling it to capture long-range dependencies and context-specific meanings,\nand thus locate the most relevant preceding tokens. The spatial view highlights\nthat the next token is not a fixed option but part of a spectrum of possibilities.\nIn fact, the value of each generation unit is not fixed.\n\nFirstly, even minor changes in the model's input (the prompt) can signif-\nicantly alter the probability distribution of words (via the attention mecha-\nnism). For example, using different verbs (explain/describe/justify) can lead to\nsubstantial variations in the output.\n\nSecondly, research on active language models (those optimized for conversa-\ntion with humans) found that selecting the single most probable word (token)\ndeterministically results in generic and often 'boring' output. Moreover, deter-"}, {"title": null, "content": "minism impairs performance in most language tasks. Complex language use\nrequires more than merely predicting the most likely next word-it demands an\nelement of what could be seen as \"creativity\" from a psychological perspective,\nparadigmatic selection from a linguistic standpoint, or statistical noise from a\ntechnical perspective.\n\nThis is where the temperature mechanism comes into play. Temperature is a\nparameter that controls the model's level of \"creativity\" during text generation.\nIt regulates how much the model can deviate from the most likely word and\nhow much randomness is introduced in the token selection process.\n\nAn important consideration regarding these random characteristics is that\nlanguage models generate sequences of consecutive generation units, and there-\nfore, changes have a cumulative effect. For example, if the first word generated\nin two instances differs (let's call them wl and w2), the input for the next\ngeneration unit will be [input + w1] in the first instance and [input + w2]\nin the second. Consequently, the cumulative effect of the changes compounds\nthroughout the response, amplifying the differences.\n\nThus, we can summarize the text generation process as follows. The lan-\nguage model learns a probabilistic function of word occurrences across the train-\ning dataset a distribution of signifying forms in various contexts. It constructs\na topographic model of language and, when given a prompt (a \"piece of lan-\nguage\"), spatially locates it within the vector space and matches it with a token\nthat is probabilistically appropriate. Rather than selecting a single possibility,\nthe model operates within a range of possibilities, and the selection method is\nnot deterministic but one of sampling."}, {"title": "Meaning as a Distribution Over Multiple Contexts in the\nDataset", "content": "As we've seen through the analysis of Signature Event Context (SEC), the struc-\nturalist perspective, as represented by the embedding analogy, falls short. It\nmaintains a conception of meaning as fixed and nominal. In contrast, the post-\nstructuralist idea of the contextual permeability of meaning offers a more fitting\nexplanation. This notion better aligns with modern language models' dynamic\nand flexible operation, presenting a more comprehensive understanding of how\nsemantic meaning is operationalized within them.\n\nI propose a new phrasing for understanding the post-structuralist concept\nof meaning. Meaning is a distribution over a space of sign occurrences (sig-\nnifying forms), defined by a (non-final) metric of repetitions across different\ncontexts in writing or language. This definition aligns with the mechanisms\nwe've described. The language model is exposed to the entirety of signifying\nforms within the dataset and builds a contextual representation of the semantic\nspace linked to each signifying form, shaped by the occurrences it encounters.\nMeaning here is not a nominal value but a distribution function a mechanism\nthat associates the probable occurrence of the next word, based on the specific\ncontext through the attention mechanism, using a statistical approximation of\nall prior occurrences of the signifying forms across various contexts in the data."}, {"title": null, "content": "The sensitivity of language models to prompts is a fundamental aspect of\nlanguage. Although the contextual representation is established during pre-\ntraining, the prompt, combined with the attention mechanism, allows the se-\nmantic meaning of a signifying form to remain open to new contexts, continually\nreshaping its semantic value. This contextual positioning occurs within a sub-\nspace of the language distribution but is undetermined, and its final meaning\nremains contingent on its usage. Additionally, the ability of large language mod-\nels (LLMs) to provide different responses to the same question is crucial. This\nreflects the inherently open and unfixed nature of the semantic meaning of a\nstatement, resulting from the separation of writing from senders, receivers, and\nfixed contexts, which makes it impossible to fully predetermine the semantic\nvalue of certain statements."}, {"title": "Summary", "content": "When we understand the object of modeling of a language model as language\nitself specifically writing and not as the human mind, we realize that the two\nproblems presented earlier are not actual problems.\n\nRegarding the comparison between children's learning and language models,\na language model operates by modeling the occurrences of signs in writing as\na relational system. In this system, the value of each sign arises from its rela-\ntionships with all other signs. When a language model is trained on a smaller\ndataset, the occurrences of signs and their interrelationships change, resulting in\na model of a language that differs from our own. Consequently, this limitation\nrenders it insufficient for our communicative needs (as discussed in Parts 1 and\n2).\n\nRegarding the gap between understanding and the statistical prediction of\nthe next word, we demonstrated that meaning is not a nominal value and that\na distribution over different contexts aligns with a post-structuralist conception\nof language. Therefore, using a sampling procedure from this distribution is an\nappropriate way to describe the behavior of meaning in language (as discussed\nin Part 3), independent of the understanding process employed by humans.\n\nWe have established that semantic meaning is a product of writing and that a\ncomputational system that approximates the behavior of signs in writing aligns\nwith the post-structuralist notion of meaning. However, we are left to question\nthe boundaries of this modeled semantic meaning concerning concepts such as\n\"knowledge\" and \"truth\", which lie beyond the scope of deeper exploration in\nthis paper."}]}