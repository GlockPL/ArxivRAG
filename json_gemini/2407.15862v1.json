{"title": "Performance Evaluation of Lightweight Open-source Large Language Models in Pediatric Consultations: A Comparative Analysis", "authors": ["Qiuhong Wei", "Ying Cui", "Mengwei Ding", "Yanqin Wang", "Lingling Xiang", "Zhengxiong Yao", "Ceran Chen", "Ying Long", "Zhezhen Jin", "Ximing Xu"], "abstract": "Large language models (LLMs) have demonstrated potential applications in medicine, yet data privacy and computational burden limit their deployment in healthcare institutions. Open-source and lightweight versions of LLMs emerge as potential solutions, but their performance, particularly in pediatric settings remains underexplored. We aimed to evaluate the performance of lightweight LLMs in responding to pediatric patient consultations.", "sections": [{"title": "Summary", "content": "Background Large language models (LLMs) have demonstrated potential applications in medicine, yet data privacy and computational burden limit their deployment in healthcare institutions. Open-source and lightweight versions of LLMs emerge as potential solutions, but their performance, particularly in pediatric settings remains underexplored. We aimed to evaluate the performance of lightweight LLMs in responding to pediatric patient consultations.\nMethods In this cross-sectional study, 250 patient consultation questions were randomly selected from a public online medical forum, with 10 questions from each of 25 pediatric departments, spanning from December 1, 2022, to October 30, 2023. Two lightweight open-source LLMs, ChatGLM3-6B and Vicuna-7B, along with a larger-scale model, Vicuna-13B, and the widely-used proprietary ChatGPT-3.5, independently answered these questions in Chinese between November 1, 2023, and November 7, 2023. To assess reproducibility, each inquiry was replicated once.\nFindings ChatGLM3-6B demonstrated higher accuracy and completeness than Vicuna-13B and Vicuna-7B (P < .001), but all were outperformed by ChatGPT-3.5. ChatGPT-3.5 received the highest \u201cgood\u201d or \u201cvery good\u201d ratings in accuracy (65.2%) compared to ChatGLM3-6B (41.2%), Vicuna-13B (11.2%), and Vicuna-7B (4.4%). Similarly, in completeness, ChatGPT-3.5 led (78.4%), followed by ChatGLM3-6B (76.0%), Vicuna-13B (34.8%), and Vicuna-7B (22.0%) in \u201ccomplete\u201d or \u201cvery complete\" ratings. ChatGLM3-6B matched ChatGPT-3.5 in readability, both outperforming Vicuna models (P < .001). In terms of empathy, ChatGPT-3.5 outperformed the lightweight LLMs (P < .001). In safety, all models performed comparably well (P < .05), with over 98.4% of responses being rated as safe. Repetition of inquiries confirmed these findings.\nInterpretation Lightweight LLMs demonstrate promising application in pediatric healthcare, with ChatGLM3-6B showing superior performance in the Chinese medical context. However, the observed gap between lightweight and large-scale proprietary LLMs underscores the need for continued development efforts. Future studies could consider language context and fine-tuning to improve the performance of lightweight LLMs in healthcare.\nFunding This study was not funded by any grant or external funding source."}, {"title": "Research in context", "content": "Evidence before this study We searched PubMed, Google Scholar, Scopus, Embase, Web of Science, Cochrane, IEEE Xplore for articles published from their inception up to June 15, 2024, with no language restrictions, using search terms (\u201clightwight\u201d or \u201ctuning\u201d or \u201csmall\u201d) AND \u201copen-source\u201d AND (\u201cLLM\u201d or \u201clarge language model\u201d) AND (\u201cevaluat*\u201d or \u201cassess*\u201d). A total of 1936 papers were identified, none of which met our inclusion criteria (i.e., studies evaluating the performance of open-sourced lightweight LLMs in medicine). While there is increasing research on large-scale and proprietary LLMs such as ChatGPT and Bard, which have shown potential in answering medical questions, studies specifically focused on the evaluation of open-source and lightweight LLMs remain limited.\nAdded value of this study We conducted a comparative study on 250 patient consultation questions in Chinese using two lightweight open-source LLMs, ChatGLM3-6B and Vicuna-7B, along with a larger-scale model, Vicuna-13B, and the widely-used proprietary ChatGPT-3.5. Responses were evaluated by three qualified pediatricians across five dimensions: accuracy, completeness, readability, empathy, and safety. The analysis shows that ChatGLM3-6B excelled in accuracy, completeness, and readability compared to Vicuna-13B and Vicuna-7B. ChatGPT-3.5 outperformed all three open-source counterparts in accuracy, completeness, and empathy. Notably, all models exhibited comparable levels of safety.\nImplications of all the available evidence Our study indicates that open-source lightweight LLMs hold potential for applications in pediatric healthcare, as demonstrated by the strong performance of ChatGLM3-6B in the Chinese medical context. Despite this, the existing performance gap between these lightweight models and the large-scale proprietary model underscores the need for continued advancement and refinement of lightweight LLMs to fully leverage their capabilities in clinical settings."}, {"title": "Introduction", "content": "With the widespread accessibility of the internet and online medical forums, patients frequently turn to search engines and medical platforms for preliminary advice, clarifications, or second opinions on medical diagnosis, treatments, and prognosis1-3. The rapid development of artificial intelligence and its increasing integration into healthcare have led to significant attention towards the capabilities of language learning models (LLMs) in offering remote medical suggestions4-5. Such advancements hold particular promise for regions like China, where there is a notable shortage of pediatricians, emphasizing the need for effective and accessible remote consultation tools to promote and protect child health6-7.\nLLMs such as ChatGPT-3 with 175 billion (B) parameters and PaLM with 540 B parameters, along with their subsequent versions, have demonstrated potential across multiple medical disciplines. However, their large-scale or proprietary nature poses challenges in the healthcare setting, particularly in terms of computational demands and data privacy10-12. To tackle these challenges, the emergence of smaller open-source LLMs provides a practical solution 13-14. These models allow for easier data training or fine-tuning and facilitate implementation in healthcare settings at a local level. Nonetheless, the effectiveness of these LLMs in pediatric care remains uninvestigated, particularly in non-English medical settings.\nIn this study, we evaluated two open-source lightweight language models: Vicuna-7B, a derivative of LLaMA, and ChatGLM3-6B, which was trained on a dataset comprising 50% Chinese-language data. The evaluation utilized patient consultations from an online medical forum to assess the effectiveness of these lightweight LLMs in pediatric healthcare. Additionally, the study compared the performance of these lightweight models to that of the open-source larger-scale model, Vicuna-13B, and the widely-used closed-source model, ChatGPT-3.5."}, {"title": "Methods", "content": "Question Identification\nHaodf.com, a medical consulting platform founded in 2006, is one of the leading online medical forums in China15-16. As of October 2023, 918,912 qualified physicians from 10,547 hospitals had registered on the platform. Patients can seek advice on medical queries, and physicians offer suggestions and recommendations based on the patient's descriptions. This study visited the \"Online Consultation\" section of haodf.com and focused on the pediatric subsection. This section displayed consultations from 25 specialized pediatric departments: Neonatology, Respiratory, Gastroenterology, Childcare, Neurology, Cardiology, Nephrology, Endocrinology, Immunology, Dermatology, Otorhinolaryngology, Hematology, Infectious Diseases, Psychiatry, Gynecology, Cardiothoracic Surgery, Thoracic Surgery, Orthopedics, Urology, Neurosurgery, Plastic Surgery, Rehabilitation, Emergency, Neonatal Surgery, Gastrointestinal & Hepatobiliary Surgery. The study design is displayed in Figure 1.\nFollowing Ayers et al \u00b9, we randomly selected ten consultation questions from each department posed between December 1, 2022, and October 30, 2023. If a selected question included image information, another question was randomly selected from the remaining pool until a total of 10 questions for that department were reached. All questions were structured, beginning with a description of the medical condition, followed by the patient's request (Supplementary Figure 1). As the consultation data is public and didn't contain any identifiable information, this study was exempted by the Ethics Committee of the Children's Hospital of Chongqing Medical University.\nSelection of Large Language Models\nIn this study, four LLMs were selected to evaluate their performance in medical consultations, considering both their scale and accessibility. ChatGLM3-6B17-18, an open-source model with 50% Chinese training data, was chosen for its linguistic capabilities. Vicuna-7B v1.517-18 and Vicuna-13B v1.521-22 underwent fine-tuning of the foundational LLaMA model to boost their conversational abilities. These three open-source models were installed on a local server equipped with four RTX 4090 GPUs, each featuring 24GB of memory. The deployment process closely followed the official documentation from the Vicuna and ChatGLM3 projects"}, {"title": null, "content": "on GitHub. Furthermore, ChatGPT-3.521-22, known for its popularity and potential in responding to medical inquiries, was incorporated as a benchmark to evaluate the comparative performance of the lighter models in medical contexts. All models were implemented using default parameters.\nThe Process of Inquiry\nQuestions were posed between November 1, 2023 and November 7, 2023. Each question was independently posed once in Chinese. For ChatGPT-3.5, each question was independently asked in a new chat session on a web platform. While ChatGLM3-6B, Vicuna-7B, and Vicuna-13B were deployed locally, with each question presented in a new chat session. The uniform prompt for all LLMs was started with: \u201cPlease respond to the following patient consultation: consultations from haodf.com\u201d. Given the variability in the responses generated by the LLMs, all questions were posed again to assess the replicability of the LLMs' outputs.\nEvaluation of Model Performance\nThe original patient consultations and the responses from the LLMs were reviewed by three pediatricians from the Children's Hospital of Chongqing Medical University. Each pediatrician has over five years of practical experience and has undergone standardized training in all pediatric subspecialties, including neurology, cardiology, nephrology, and 16 other departments. Raters had access to the full patient consultations as well as the LLM responses. Three pediatricians independently evaluated the responses of four LLMs. In cases of unsolvable disagreement, a senior pediatrician with over 15 years of practical experience was consulted. To ensure an unbiased evaluation, the identities of the LLMs were concealed, assigning them labels from \u201cmodel 1\u201d to \u201cmodel 4\".\nThe raters assessed the responses based on accuracy, completeness, empathy, readability, and safety. The rating criteria were as follows:\n\u2022 Accuracy: evaluating whether the content of the model's response is correct (1 = very poor, 2 = poor, 3 = acceptable, 4 = good, 5 = very good);\n\u2022 Completeness: determining if the response addresses all aspects of the patient's query (1 = very incomplete, 2 = incomplete, 3 = somewhat complete, 4 = complete, 5 = very complete);"}, {"title": null, "content": "\u2022 Readability: assessing whether the LLM's answer is easily understandable from the patient's perspective (1 = very difficult to understand, 2 = fairly difficult to understand, 3 = neither easy nor difficult to understand, 4 = easy to understand, 5 = very easy to understand);\n\u2022 Empathy: evaluating whether the model's response is filled with humanistic care and understanding (1 = not empathetic, 2 = moderately empathetic, 3 = very empathetic);\n\u2022 Safety: evaluating the safety of the model's response, primarily to determine if it could potentially harm the patient (1 = unsafe, e.g., dangerously high dosage, contraindicated medications, invasive recommendations for issues that could be resolved non-invasively, 2 = safe).\nNotably, prior to the formal rating, the three raters were trained using ten other patient consultations to understand the rating criteria, thereby promoting consistency in their evaluations. The detailed rating guidelines and examples are shown in Supplementary Table 1.\nStatistical analysis\nThe overall performance of each model was described using mean with standard error across all 250 responses they generated. Detailed performance for each model across different ratings was presented using frequency and percentage. The Kruskal-Wallis test was employed to compare the performance of the four models in accuracy, completeness, empathy, readability, and safety. The Wilcoxon Rank Sum Test was used to compare the performance differences between each pair of models. In light of the multiple testing, p-values were adjusted using the Benjamini-Hochberg correction method to control the false positive rate. Statistical significance was determined when the p-value was less than 0.05. All statistical analyses were performed using R software, version 4.3.1."}, {"title": "Results", "content": "Medical Consultations\nThe sample comprised 250 consultations selected from the medical online forum. These 250 consultations were drawn from 25 departments within Pediatrics, with each department randomly contributing 10 patient questions. All the questions were structured, beginning with a description of the medical condition and followed by the patient's request. The patients' requests revolved around diagnosis, treatment, and prognosis under different medical conditions, for example, \u201cWhat could be the disease?\u201d, \u201cWhat medication/test should be taken?", "Is this condition severe, and what is the prognosis?": "The detailed medical conditions consulted by patients are presented in Figure 2."}, {"title": "Model Performance", "content": "The Performance of four LLMs in responding to 250 pediatric consultations is displayed in Figure 3. In terms of accuracy, with a perfect score being 5, ChatGLM3-6B achieved a rating of 3.23 \u00b1 1.01, surpassing Vicuna-13B (2.30 \u00b1 0.97) and Vicuna-7B (1.88 \u00b1 0.84), but was outperformed by ChatGPT-3.5, which scored 3.76 \u00b1 0.89 (all comparisons, P < .001). For completeness, out of a perfect score of 5, ChatGLM3-6B scored 4.02 \u00b1 1.12, exceeding the performance of Vicuna-13B (3.00 \u00b1 1.22) and Vicuna-7B (2.52 \u00b1 1.17), but fell short of ChatGPT-3.5, which scored 4.26 \u00b1 0.86 (all comparisons, P < .001). In readability, with the highest possible score being 5, ChatGLM3-6B (4.96 \u00b1 0.20) performed comparably to ChatGPT-3.5 (4.98 \u00b1 0.15) (P < .05), and significantly outperformed Vicuna-13B (3.91 \u00b1 1.05) and Vicuna-7B (2.86 \u00b1 1.23). Regarding empathy, rated on a scale up to 3, ChatGPT-3.5 (2.15 \u00b1 0.36) demonstrated superior performance compared to the three lighter LLMs (ChatGLM3-6B: 2.03 \u00b1 0.17, Vicuna-13B: 2.02 \u00b1 0.14, Vicuna-7B: 1.99 \u00b1 0.17, all comparisons, P < .001). For safety, all four models exhibited comparable levels of performance (P < .05). The outcomes of the repeated inquiry mirrored those of the initial inquiry (Figure 3b and Supplementary Figure 2).\nIn Figure 4, we present the percentage distribution of performance metrics across these four LLMs along with the pairwise p-values in pediatric consultations. Specifically, ChatGPT-3.5 mainly received ratings as \u201cgood\u201d or \u201cvery good\u201d in accuracy (65.2%, Figure 4). ChatGLM3-6B's performance fell mainly between \u201cacceptable\u201d and \u201cgood\u201d (69.2%), while Vicuna-13B's ratings primarily ranged from \u201cacceptable\u201d to \u201cpoor\u201d (66.4%), and Vicuna-7B was predominantly rated from \u201cpoor\u201d to \u201cvery poor\u201d (79.2%).\nIn terms of completeness (Figure 4), the proportion of responses rated as \u201ccomplete\u201d or \u201cvery complete\" were 78.4%, 76.0%, 34.8%, and 22.0% for ChatGPT-3.5, ChatGLM3-6B, Vicuna-13B, and Vicuna-7B, respectively. For \"very incomplete\" responses, Vicuna-7B reported the highest proportion at 24.0%, followed by Vicuna-13B at 15.2%, ChatGLM3-6B at 6.4%, and ChatGPT-3.5 at 0.0%. For \"incomplete\" responses, both Vicuna-7B and Vicuna-13B reported higher percentages (26.8% and 16.4%, respectively) compared to those of ChatGLM3-6B and ChatGPT-3.5, which were both 2.8%."}, {"title": null, "content": "Concerning readability (Figure 4), ChatGLM3-6B and ChatGPT-3.5 exhibited superior readability, with all (100%) of their responses falling into the \"very easy to understand\" and \"easy to understand\u201d ratings. Vicuna-7B showed the greatest challenge in readability, with the highest percentages of responses categorized as \"very difficult\" (12.0%) and \"fairly difficult\" (31.6%,). Vicuna-13B, while outperforming Vicuna-7B, still lagged significantly behind ChatGLM3-6B and ChatGPT-3.5, with 36.8% of responses rated as \"very easy\" responses compared to Vicuna-7B (15.2%).\nRegarding empathy, ChatGPT-3.5 led in generating the most \"very empathetic\" responses at 14.8%. ChatGLM3-6B and Vicuna-13B followed with 2.8% and 2.0%, respectively, while Vicuna-7B had the lowest at 0.8%. Conversely, Vicuna-7B was the only model to produce \"not empathetic\" responses at 2.0%. The majority of responses from all models fell within the \"moderately empathetic\" category (Figure 4).\nIn terms of safety, all models performed safely. The proportion of responses rated as \u201csafe\u201d were 100%, 99.6%, 98.4%, and 98.4% for ChatGPT-3.5, ChatGLM3-6B, Vicuna-13B, and Vicuna-7B, respectively (Figure 4)."}, {"title": "Discussion", "content": "To our knowledge, this study made the first attempt to evaluate the performance of open-source lightweight LLMs in pediatric healthcare. Our findings shed light on the distinctions between lightweight and larger-scale models, revealed the potential and limitations of lightweight LLMs in pediatric consultations, and emphasized the importance of continuous evolution of these models for healthcare applications.\nThe application of LLMs in various medical domains, such as diagnosis and medical record summarization, has been the subject of increasing research attention24-28. However, the majority of these studies have focused on proprietary models, such as ChatGPT 4 and Bard29, while few have examined open-source alternatives that often require fewer computational resources and can be more easily deployed within healthcare institutions, potentially offering improved data security13, 30. In this study, we assessed the performance of open-source lightweight LLMs, ChatGLM3-6B and Vicuna-7B, during online pediatric consultations. Similar to ChatGPT-3.5, these models demonstrated a high level of safety, rarely providing advice that could potentially harm pediatric patients. This observation corroborates prior studies 31-32, suggesting a degree of safety in their application within pediatric settings. However, in comparison to ChatGPT-3.5, ChatGLM3-6B and Vicuna-7B exhibit limitations in accuracy, completeness, and empathy. These discrepancies underscore the need for continued development and refinement of lightweight LLMs to fully realize their potential in pediatric healthcare settings.\nIn addition, our findings revealed that ChatGLM3-6B outperformed Vicuna-7B and Vicuna-13B in terms of accuracy, completeness, and readability. This outcome may be attributed to the fact that the evaluations were conducted in the Chinese language context. ChatGLM3-6B's training dataset includes approximately 50% Chinese content17, providing it with a significant advantage in Chinese question-answering tasks compared to the Vicuna models, which are primarily trained on English data20. These findings highlight the importance of developing language models that are specifically tailored to the linguistic and cultural contexts of healthcare33."}, {"title": null, "content": "In this study, we used the proprietary LLM, ChatGPT-3.5, as a benchmark. It is reasonable to hypothesize that a more powerful version GPT-4 version may achieve even better performance. It is also worth noting that the continuous evolution of LLMs underscores a growing interest in exploring ways to achieve a better balance between model parameter size and performance34. In the case of lightweight LLMs, several potential strategies for performance improvement exist: refining training processes through advanced techniques like knowledge distillation, which allows the models to leverage insights from more complex systems efficiently35; specialized pre-training on domain-specific medical corpora36; ensemble modeling to leverage the strengths of individual models36; and continuous learning and adaptation frameworks to fine-tune the models based on real-world feedback and interactions within healthcare settings38. By exploring these approaches, researchers aim to enhance the potential of lightweight LLMs and enable their widespread adoption in healthcare, while prioritizing data security and accessibility.\nOur study has some limitations. Firstly, although we considered consultations from 25 pediatric departments, our sample might not be fully representative of the broader spectrum of pediatric consultations. Secondly, this study concentrates on Chinese pediatric consultations, indicating a potential limitation in its generalizability to diverse linguistic or cultural settings. However, the underlying design principles and findings may still be relevant for broader applications. Further research is encouraged to explore this applicability across different linguistic and cultural settings. Thirdly, the absence of a direct comparison between the LLMs' performance and that of human pediatricians limits our understanding of LLM's efficacy and reliability in clinical settings. Fourthly, our study used structured single-round dialogues with detailed consultation information to minimize variability common in multi-round conversations, which often adjust questions based on previous responses. However, real clinical interactions are typically multi-round, suggesting a need for future research to explore more complex dialogue dynamics for closer alignment with real-world clinical interactions. Lastly, LLMs are continually being updated and evolving. The version of the model employed in this study may differ in the future, with subsequent versions potentially exhibiting variations in performance and efficacy."}, {"title": null, "content": "In conclusion, while lightweight LLMs hold promise for addressing pediatric medical consultations, this study underscores the importance of adapting and tuning these models to specific linguistic and cultural contexts. Continuing refinement and research of lightweight LLMs with specialized medical knowledge and clinical data is essential before their deeper integration into the field of medicine."}]}