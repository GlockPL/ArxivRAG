{"title": "Fully Bayesian Differential Gaussian Processes through Stochastic Differential Equations", "authors": ["Jian Xu", "Zhiqi Lin", "Min Chen", "Junmei Yang", "Delu Zeng", "John Paisley"], "abstract": "Traditional deep Gaussian processes model the data evolution using a discrete hierarchy, whereas differential Gaussian processes (DIFFGPs) represent the evolution as an infinitely deep Gaussian process. However, prior DIFFGP methods often overlook the uncertainty of kernel hyperparameters and assume them to be fixed and time-invariant, failing to leverage the unique synergy between continuous-time models and approximate inference. In this work, we propose a fully Bayesian approach that treats the kernel hyperparameters as random variables and constructs coupled stochastic differential equations (SDEs) to learn their posterior distribution and that of inducing points. By incorporating estimation uncertainty on hyperparameters, our method enhances the model's flexibility and adaptability to complex dynamics. Additionally, our approach provides a time-varying, comprehensive, and realistic posterior approximation through coupling variables using SDE methods. Experimental results demonstrate the advantages of our method over traditional approaches, showcasing its superior performance in terms of flexibility, accuracy, and other metrics. Our work opens up exciting research avenues for advancing Bayesian inference and offers a powerful modeling tool for continuous-time Gaussian processes.", "sections": [{"title": "I. INTRODUCTION", "content": "Traditional Gaussian processes models [1] have limitations in handling non-Gaussian distributions, complex distributions, time series, and other challenging tasks. To address this, deep Gaussian processes (DGPs) have been introduced for more expressive representations. However, DGPs may face issues with degenerate models if individual GPs are not invertible [2], [3]. One approach to overcome these challenges is DIffGPs [4], which model data evolution in continuous time using stochastic differential equation systems. This allows for learning continuous-time transformations of the data, offering a more natural way to capture data dynamics compared to traditional methods. DIffGPs warp inputs through differential fields to generalize discrete layers into a dynamic system. The intuition of \"warping\" the inputs over time, as derived from the original DiffGP paper, is an extension of the concept of deep Gaussian processes in continuous layers. Similar to the transition from ResNet to neural ODEs, this approach aims to adapt and transform the input space progressively over time, allowing the model to better capture complex patterns and dependencies in the data.\n\nThe DIffGP methods [4] have been criticized for overlooking uncertainty in kernel hyperparameters, crucial for accurate modeling and reliable uncertainty estimation. The choice of covariance function in GPs significantly impacts the posterior distribution, highlighting the importance of selecting a proper covariance function [5], [6]. Model selection in GP modeling involves specifying covariance functions and selecting hyperparameters, typically done by maximizing the marginal likelihood or its lower bound. However, this approach faces challenges due to the non-convex nature of the marginal likelihood surface, especially with multiple modes and weakly identifiable hyperparameters. Maximizing the marginal likelihood may lead to overfitting and underestimation of prediction uncertainty, as gradient-based optimization is sensitive to initial values. Improved methods are needed to address these challenges in hyperparameter estimation for GP models.\n\nIn this work, we propose a fully Bayesian approach to Gaussian process regression, treating kernel hyperparameters as random variables and using coupled stochastic differential equations (SDEs) to learn their posterior distribution and that of inducing points. This method effectively addresses the non-convexity of the marginal likelihood surface, providing robust parameter estimation. By incorporating uncertainty in hyperparameters through the posterior distribution, overfitting is avoided, and generalization to new data is enhanced. Bayesian methods offer a comprehensive understanding of parameter estimation by capturing inherent uncertainty, improving model reliability and adaptability.\n\nExtending the Bayesian treatment of hyperparameters to a hierarchical framework presents challenges in computing posterior distributions, leading to increased complexity. We introduce a novel methodology using SDEs to learn the posterior distribution of hyperparameters and inducing points, capturing their uncertainty effectively. By integrating Bayesian inference with SDEs, our approach enhances model adaptability and robustness in capturing system dynamics.\n\nOur work introduces a novel network architecture that not only enhances the expressiveness of DIffGPs but also integrates the uncertainty of kernel parameters and inducing point distributions into a fully Bayesian inference framework, incorporating their time-correlated posterior SDEs. By leveraging state-of-the-art SDE gradient estimators, such as those in [7], [8], [9], [10], we demonstrate the effectiveness of approximate inference by maximizing our modified variational lower bound, significantly improving the scalability of gradient-based variational inference compared to previous studies. Computation of the output layer state is simplified using a black-box adaptive SDE solver, streamlining the modeling process and enhancing the efficiency of our proposed methodology.\n\nOur approach offers two distinct advantages over previous DIffGPs models: i). Incorporating the uncertainty of inducing points and kernel hyperparameters within a fully Bayesian framework enhances flexibility and adaptability in capturing complex dynamics. ii). By expanding the neural network that parameterizes the dynamics of the approximate posterior, the variational posterior can be made highly expressive. This enables accurate approximation of the true posterior, leading to a more comprehensive and realistic posterior approximation and preventing overfitting.\n\nExperimental evaluation showcases the superiority of our proposed method over traditional approaches in terms of flexibility, accuracy, and other relevant metrics. Our contributions are outlined as follows:\n\n\u2022 We introducing a fully Bayesian approach that treats kernel hyperparameters as random variables and utilizes coupled stochastic differential equations (SDEs) to learn their posterior distribution and that of inducing points for DIFFGPs, enhancing model flexibility and adaptability to complex dynamics by incorporating estimation uncertainty on hyperparameters.\n\n\u2022 Using advanced SDE gradient estimators, our approach scales up gradient-based variational inference significantly. The utilization of a black-box adaptive SDE solver for computing the output layer underpins our commitment to effective and innovative model computation.\n\n\u2022 Experimental results showcase the advantages of our method over traditional approaches, demonstrating superior performance in terms of flexibility, accuracy, and other metrics."}, {"title": "II. MODEL", "content": ""}, {"title": "A. Gaussian Processes and Sparse Representation", "content": "Gaussian processes (GPs) are powerful probabilistic models that define a distribution over functions. Given a collection of input points $X = \\{x_1,...,x_N\\}^T \\in \\mathbb{R}^{N\\times D}$, where $x \\in \\mathbb{R}^D$, a GP specifies a joint Gaussian distribution over the corresponding function values $f = \\{f(x_1),...,f(x_N)\\}^T \\in \\mathbb{R}^N$. The fundamental property of GPs is that the outputs at different points correlate based on their similarity, as measured by a kernel function $k(x, x')$, as described by Rasmussen and Williams [1].\n\nTraditionally, a zero-mean Gaussian process prior is defined on a function $f(x)$ over vector inputs $x \\in \\mathbb{R}^D$:\n\n$f(x) \\sim GP(0, k(x, x')),$\n\nwhere $k(x, x')$ is the kernel function, and it captures the covariance between function values at different inputs.\n\nTo handle large datasets effectively, we can employ sparse Gaussian processes that utilize a small set of inducing or landmark variables. These inducing variables $u = \\{u_1,...,u_M\\}^T \\in \\mathbb{R}^M$, where M is much smaller than N, are chosen from the dataset. By conditioning the GP prior on these inducing variables $u$ and their corresponding locations $Z = \\{Z_1,...,Z_M\\}^T$, we can obtain posterior predictions at the data points.\n\nThe sparse GP posterior predictions, given the inducing variables $u$ and their locations $Z$, are given by:\n\n$f | u, Z \\sim \\mathcal{N}(Qu, K_{XX} - QK_{ZZ}Q^T)$\n\n$Q = K_{XZ}(K_{ZZ} + \\sigma^2I)^{-1}$ is the matrix of the coefficients relating the inducing variables to the function values, $\\eta$ in $\\sigma_{\\eta}$ refers to the position of the sample point, $K_{XX}$ is the kernel matrix between the data points, $K_{ZZ}$ is the kernel matrix between the inducing points, $K_{XZ}$ is the kernel matrix between the data points and the inducing points, and $\\sigma^2$ is the noise variance of the observations.\n\nThe main inference problems for Gaussian Processes (GPs) are related to the inducing points $Z$, inducing variables $u$, and the kernel hyperparameters $\\lambda$. For instance, if we choose the classic Gaussian kernel, the formula for the kernel is:\n\n$k(x, x') = \\sigma_f^2 exp(-\\frac{||x - x'||^2}{2l^2})  \\qquad (1)$\n\nIn classical inference methods, VI [11] and Markov Chain Monte Carlo (MCMC) [12] have been widely successful. By incorporating sparse representation through inducing variables, we can effectively model and make predictions in large-scale datasets using Gaussian processes."}, {"title": "B. Continuous-Time Gaussian Processes", "content": "The continuous-time deep learning paradigm introduced by [4] focuses on a model called DIFFGP, which is a continuous-time deep Gaussian process model through infinite, infinitesimal differential compositions. In DIFFGP models, the input data is transformed using a stochastic differential equation (SDE) flow to obtain transformed inputs $X_T$, which are then used for model fitting after a predefined time $T$. The parameter $T$ determines the length of the flow and the system's capacity, similar to the number of layers in standard deep GPs or deep neural networks.\n\nIn this paradigm, the inputs are redefined as temporal functions $x : \\mathcal{T} \\rightarrow \\mathbb{R}^D$ over time, where state paths $x_t$ over time $t \\in \\mathcal{T} = \\mathbb{R}^+$ emerge. The observed inputs $x_{i,0}$ correspond to initial states. The task is to classify or regress the final data points $X_T = (X_{1,T},..., X_{N,T})$ after $T$ time of an SDE flow using a predictor Gaussian process. In above notation, the first index represents the dimension of the sample points, indicating the number of sample particles. The second index represents the dimension of the discrete time points. The predictor is denoted as $g (x_T)$ and is assumed to follow a Gaussian process prior with zero mean and a covariance function $K (x_T, x'_T)$. When $T = 0$, the framework reduces to a conventional Gaussian process.\n\nThe prediction depends on the final dataset $X_T$ structure, determined by the SDE flow $dx_t$ from the original data $X$. We consider SDE flows of Ito type\n\n$dx_t = \\mu (x_t) dt + \\sqrt{\\Sigma(x_t)}dW_t \\qquad (2)$\n\nwhere\n\n$\\mu(x_t) = K_{XZ}K_{ZZ}^{-1} vec (U)$\n\n$\\Sigma(x_t) = K_{XX} - K_{XZ}K_{ZZ}^{-1}K_{ZX}$\n\nare the vector-valued Gaussian process conditioned on inducing variable U = ($u_1,...,u_M$) defining function values $f(z)$ at inducing states Z = ($z_1, ..., z_M$). In Equation (2), the size of U is M \u00d7 D, corresponding to a multi-output Gaussian process where the output dimension is D. Consequently, the dimension of $K_{ZZ}$ is MD \u00d7 MD. This is a block matrix of matrix-valued kernels, reflecting the dependencies between the $M$ inducing points and the $D$ output dimensions.\n\nThe transformation process can be simulated using an SDE solver, such as Euler discretization [13]:\n\n$X_T = X_0 + \\int_{0}^{T} \\mu(x_t) dt + \\int_{0}^{T} \\sqrt{\\Sigma(x_t)} dW_t,  \\qquad (3)$\n\nThe DIFFGP model, which captures the time evolution and dynamics of data in a continuous manner, offers a more natural and flexible approach compared to traditional discrete-layered approaches like Deep GPs [14], [15]. However, the original DIFFGP model has limitations. For example, it treats the kernel parameters as point estimates and does not consider their uncertainty or fully incorporate a Bayesian perspective. Additionally, it does not account for the temporal variability of the kernel parameters and inducing points, similar to how each layer in a deep GP has its own kernel parameters and inducing points. In the following section, we will introduce a new fully Bayesian framework that addresses these issues by utilizing recent advancements in SDE theory and its connection to variational inference."}, {"title": "III. FULLY BAYESIAN VARIATIONAL INFERENCE", "content": ""}, {"title": "A. Modeling Uncertainty in Kernel Hyperparameters and Inducing Points", "content": "Within the realm of Gaussian process (GP) regression, the effectiveness of the model is intricately tied to the judicious selection of kernel hyperparameters and inducing points, a task renowned for its inherent complexity. The pursuit of optimal values for these parameters presents a formidable challenge that demands a strategic approach. In response to this challenge, our proposed methodology advocates for the adoption of a comprehensive Bayesian framework that explicitly acknowledges and encompasses the uncertainty inherent in the kernel hyperparameters and inducing points. By immersing this uncertainty into the very core of the inference process, we cultivate a model that not only exhibits heightened resilience but also demonstrates exceptional adaptability, poised to navigate the intricate nuances of the data landscape with enhanced agility and robustness.\n\nIn the generating process of the model, we assume that the kernel hyperparameters $\\Lambda_t$, inducing points $Z_t$, and inducing variables $U_t$ are drawn from certain prior distributions. These hyperparameters control the behavior of the Gaussian process model and are crucial for determining the smoothness and flexibility of the model. The inducing points $Z_t$ are any set of points within the input space that can be optimized to approximate the function values at all input points. The inducing variables $U_t$ are the corresponding function values at the inducing points.\n\nGiven these prior distributions, the model generates the observed data $X$ and $y$ by drawing samples from the Gaussian process defined by the kernel function with the hyperparameters $\\Lambda_t$ and the inducing variables $U_t$. For example, in the classic Gaussian kernel, $\\Lambda = \\{\\sigma_f,l\\}$. The posterior distribution of the hyperparameters, inducing points, and inducing variables can then be estimated based on the observed data using Bayesian inference techniques. This allows us to make predictions and infer the underlying structure of the data based on the Gaussian process model,\n\nPrior over hyperparameters $\\Lambda_t \\sim P(\\Lambda_t)$\n\nPrior over inducing points $Z_t \\sim p(Z_t)$\n\nPrior over inducing variables $U_t \\sim GP(0, K(Z_t, Z_t))$\n\nModel forward SDE $dx_t = \\mu (x_t) dt + \\sqrt{\\Sigma(x_t)}dW_t+  \\qquad (4)$\n\nPredictor Gaussian process $g \\sim GP(0, K (x_T, x'_T))$\n\nData likelihood $y | g \\sim \\mathcal{N} (g, I)$\n\nInspired by the ANODEV2 method [16], which extends a complex ODE model for evolving neural network parameters, we view the hyperparameters $\\Lambda_t$ and inducing points $Z_t$ as prior processes that evolve over time, in contrast to traditional fully-GP models and previous works like DIFFGPs. This approach departs from the fixed hyperparameters assumption and allows for a more dynamic modeling of the parameter evolution. Drawing parallels to evolutionary computing methods such as HyperNEAT [17], Compressed Weight Search [18], and Hypernetworks [19], which employ secondary networks to generate parameters for the main network, our approach extends this concept to parameter evolution in GP-SDE models. By adopting a Bayesian perspective, we aim to capture the time-varying distribution of hyperparameters, thereby enhancing the flexibility and adaptability of our model.\n\nWe can apply the concept of amortized variational inference, as introduced in the works of [20], [21], [5], to optimize the factorized approximate posterior distribution $q(x_t, Z_t, U_t) = q(x_t)q(Z_t)q(U_t)$. This requirement is met by employing the mean-field assumption, where the posterior is approximated as a product of several independent factors. The goal is to minimize the Kullback-Leibler (KL) divergence between this approximate posterior and the true posterior distribution. This optimization objective is equivalent to maximizing the Evidence Lower Bound (ELBO), which serves as a lower bound on the marginal likelihood of the data under the model. By maximizing the ELBO, we can efficiently approximate the true posterior distribution and make accurate inference about the model's parameters and latent variables,\n\n$\\log p(y)$\n\n$\\geq Eq(x_{0:T})q(Z_{0:T})q(U_{0:T})p(x_T|x_{0:T},Z_{0:T},U_{0:T})p(g|x_T) [\\logp(y | g)]$\n\n$- KL (q (\\lambda_{0:T}) || p (\\lambda_{0:T})) - KL (q (Z_{0:T}) || p (Z_{0:T}))$\n\n$- KL (q (U_{0:T}) || p (U_{0:T})) \\qquad (5)$\n\nwhere $\\Lambda_{0:T}, Z_{0:T}$, and $U_{0:T}$ represent the trajectory paths of $\\Lambda_t, Z_t$, and $U_t$ respectively. Next, we show how to do efficient variational inference in SDE models, and optimize the marginal log-likelihood to fit both prior hyperparameters"}, {"title": "B. Approximate Posterior through Latent Stochastic Differential Equations", "content": "To perform posterior inference in our model, we leverage latent stochastic differential equations [22], [7], [23], [24]. These SDEs provide a principled and flexible framework for modeling complex temporal dynamics. In particular, we can parameterize both a prior over functions and an approximate posterior using coupled SDEs in the following system of differential equations.\n\n$\\begin{cases}\n\td\\lambda_t = h_{0\\lambda} (\\Lambda_t, t) dt + l_{\\lambda} (\\Lambda_t, t) dW_t, (prior)\\\\\n\td\\lambda_t = h_{p\\lambda} (\\Lambda_t, t) dt + l_{\\lambda} (\\Lambda_t, t) dW_t, (approx.posterior)\\\\\n\tdZ_t = h_{0Z} (Z_t, t) dt + l_{Z} (Z_t, t) dW_t, (prior)\\\\\n\tdZ_t = h_{pZ} (Z_t, t) dt + l_{Z} (Z_t, t) dW_t, (approx.posterior)\n\n\\end{cases} \\qquad (6)$\n\nThe difference between the prior and posterior processes lies solely in their drift terms. Similar to classical Bayesian analysis, the parameters of the prior SDE can be set to simple, fixed values, such as constants or basic affine transformations, while the drift term of the posterior SDE is parameterized by a fully connected neural network. This allows us to compute the KL divergence between the prior and posterior SDEs using Girsanov's theorem [25]. We apply this approach to both Z and $\\Lambda$ to ensure that our model retains fully Bayesian properties. Although we currently assume the drift term to be a simple function, it is also feasible to employ complex networks to learn the prior, a direction we intend to explore in future work.\n\nFor instance, in the context of an Ornstein-Uhlenbeck (OU) prior stochastic differential equation (SDE), we specify fixed prior drift coefficients as $h_{0\\lambda} = -\\Lambda_t$ and $h_{0Z} = -Z_t$, along with fixed prior diffusion coefficients as $l_{\\lambda} = \\sigma_{\\lambda}\\mathbb{I}$ and $l_{Z} = \\sigma_{Z}\\mathbb{I}$. We choose to employ the OU process due to its simplicity and well-understood properties. This process can be represented by the following SDE:\n\n$\\begin{cases}\n\td\\lambda_t = -\\Lambda_tdt + \\sigma_{\\lambda}\\mathbb{I} dW_t, (prior(\\\\\n\tdZ_t = -Z_tdt + \\sigma_{Z}\\mathbb{I} dW_t, (prior)\n\n\\end{cases} \\qquad (7)$\n\nFor the approximate posterior processes of $\\Lambda_t$ and $Z_t$, we also employ an SDE representation, where $h_{0\\lambda}$ and $h_{0Z}$ are parameterized neural networks, and all drift and diffusion functions are Lipschitz continuous. With these drifts, the approximate posterior process will generally have nonGaussian, non-factorized marginals. It may seem very restrictive to assume that the diffusion terms of the prior and posterior are identical in Eq. (6). However, previous results from the Neural SDE literature demonstrate that any posterior can be approximated with arbitrary closeness using such a functional form given a sufficiently expressive drift process [26], [10], [7], [24].\n\nThen the Kullback-Leibler (KL) divergence between these distributions is finite and can be estimated by sampling paths from the posterior process [22], [7]. According to Girsanov's theorem [25], an essential result in stochastic calculus, it states how the probability measures change under a change of drift in stochastic processes. With respect to our context, Girsanov's theorem allows us to express the Evidence Lower Bound (ELBO) in a concise and insightful manner, capturing the essence of the relationship between the true and approximate distributions in a probabilistic framework,\n\n$\\log p(y)$\n\n$\\geqEq(x_{0:T})q(Z_{0:T})q(U_{0:T})p(x_T|x_{0:T},Z_{0:T},U_{0:T})p(g|x_T) [\\log p(y | g)]$\n\n$-\\frac{1}{2} \\int_{0}^{T} Eq(x_t) |u_{\\lambda} (\\lambda_t, t)|^2 dt$\n\n$-\\frac{1}{2} \\int_{0}^{T} Eq(z_t) |u_{Z} (Z_t, t)|^2 dt - KL (q (U_{0:T}) || p (U_{0:T})) \\qquad (8)$\n\nwhere\n\n$u_{\\lambda}(\\lambda_t, t) = l_{\\lambda}(\\lambda_t, t)^{-1} (h_{0\\lambda}(\\lambda_t, t) - h_{p\\lambda} (\\Lambda_t, t)),$\n\n$u_{Z} (Z_t, t) = l_{Z} (Z_t, t) ^{-1} (h_{0Z} (Z_t, t) - h_{pZ} (Z_t,t))$\n\n$l_{\\lambda}(\\lambda, t)^{-1}$ and $l_{Z}(Z_t, t)^{-1}$ are the left inverse, and the expectation is taken over the approximate posterior process defined by Eq. (6). The functions $u_{\\lambda}$ and $u_{Z}$ need to fulfill the Novikov condition [7], which ensures that the drift and diffusion terms of the SDE are well-defined and that the process remains consistent with the requirements of stochastic calculus.\n\nAll estimates of stochastic differential equation (SDE) paths and gradients are simulated and computed using cutting-edge SDE solvers, as outlined in the work by [7]. Furthermore, to address large-scale data challenges efficiently, we can utilize mini-batch surrogates for likelihood optimization. This approach harnesses concepts from backpropagation introduced by [27] and stochastic optimization techniques such as those discussed by [28], [29], [15]. By employing mini-batch surrogates, we can effectively optimize likelihood functions for models handling significant amounts of data while retaining computational efficiency.\n\n$\\log p (y|g) = \\frac{N}{B} \\sum_{i=1}^{B} log p (y_i|g) \\approx \\mathcal{N} (g,\\mathbb{I}) \\qquad (9)$\n\nFor variational inference of the inducing variable $U_t$, we follow the approach of previous work [4], by assuming that its posterior is a Gaussian distribution.\n\n$q (U_t) = \\mathcal{N} (m_t, S_t) \\qquad (10)$\n\nWhat sets this work apart from prior research is that $m_t$ and $S_t$ are time-dependent networks while in the original DiffGP, this term is modeled as a constant. We aim to characterize the dynamical system of the inducing variables over time. Since the fact that the Kullback-Leibler divergence between two Gaussian distributions is analytical, the expression $KL (q (U_t) || p (U_t))$ can be explicitly represented as,\n\n$KL (q (U_{0:T}) || p (U_{0:T})) = \\int_{0}^{T} Eq(\\lambda_t,Z_t) (\\int Eq(U_t,\\lambda_t,Z_t) log \\frac{q (U_t)}{p (U_t)} dt$\n\n$= \\int_{0}^{T} (Tr (K_{ZZ}^{-1} S_t) + m_t^T K_{ZZ}^{-1}m_t - M$\n\n$+ln \\frac{det (K_{Z_tZ_t})}{det(S_t)} ) dt \\qquad (11)$\n\nSince $U_t$ has already been integrated out, there is no need for an expectation with respect to $U_t$. However, the expectations with respect to $Z_t$ and $\\Lambda_t$ are still necessary."}, {"title": "C. Simulation and Predictions", "content": "By combining Eq. (2) and Eq. (6), we can derive:\n\n$\\begin{bmatrix} dX_t \\\\ d\\Lambda_t \\\\ dZ_t \\end{bmatrix} = \\begin{bmatrix} \\mu(X_t) \\\\ h_p (\\Lambda_t,t) \\\\ h_{0Z} (Z_t,t) \\end{bmatrix} dt + \\begin{bmatrix} \\sqrt{\\Sigma (X_t)} \\\\ l_{\\lambda} (\\Lambda_t,t) \\\\ l_{Z} (Z_t,t) \\end{bmatrix} dW_t \\qquad (12)$\n\nBy leveraging advanced SDE solvers for state trajectory approximation, we can effectively perform stochastic gradient estimation for optimizing Eq. (8). This technique enhances our understanding of the model's loss function and enables more efficient optimization. Integrating Bayesian methodologies for hyperparameters and inducing points with dynamic SDE posterior estimation leads to a more flexible and expressive posterior estimation for DIFFGPs. This advancement improves the model's adaptability in capturing complex system dynamics and enhances predictive capabilities, providing a powerful tool for robust and informed model predictions."}, {"title": "D. Related Work", "content": "a) Sparse GPs: Sparse Gaussian Processes are an extension of GPs that address scalability issues in modeling large datasets. Traditional GPs involve inverting the covariance matrix, which becomes computationally expensive as the size of the dataset increases. Sparse GPs\u00b9 alleviate this issue by introducing a smaller set of \"inducing points\" that approximate the latent function properties over the entire dataset. By assuming a joint distribution over the function values at the inducing points and the entire data points, Sparse GPs can approximate the true GP model while significantly reducing the computational complexity. Sparse GPs have gained popularity in various applications, including machine learning [11], robotics [30], and computer vision [31], where dealing with large datasets is common. Modeling and inference with Sparse GPs have evolved considerably over the last few years with key contributions in the direction of scalability to virtually any number of datapoints and generality within automatic differentiation frameworks [32], [33], [34]. This has been possible thanks to the combination of stochastic variational inference techniques [29] with representations based on inducing variables [35], [36], [11]. These advancements have now made GPs attractive to a variety of applications and likelihoods [32], [37], [38], [39]. However, it is worth noting that Sparse GPs still require selecting the appropriate hyperparameters and inducing points, which can be challenging in some cases.\n\nb) Fully bayesian GPs: The key distinction between Fully Bayesian GPs and traditional sparse Gaussian Processes lies in their modeling approach towards kernel hyperparameters. In traditional sparse Gaussian Processes, kernel hyperparameters are considered fixed or optimized model parameters. This means that during the modeling process, one needs to select a set of optimal hyperparameter values to fit the training data. While this approach can yield good results when the training data is abundant and of high quality, selecting appropriate hyperparameter values can become challenging, especially in situations with scarce or nonlinear data.\n\nFully Bayesian GPs treat kernel hyperparameters as random variables and introduce prior distributions to represent their uncertainty. This means that Fully Bayesian GPs no longer rely on fixed hyperparameter values but instead model the range of possible hyperparameter values and update their prior distributions based on the posterior distribution from the observed data. This approach enables the estimation of the true values of hyperparameters and their uncertainties using Bayesian inference, allowing for better adaptation to the data.\n\nFully Bayesian Gaussian processes have been extensively utilized by numerous researchers, resulting in the emergence of several variant approaches. In early studies, [40], [41] investigated the use of Hamiltonian Monte Carlo (HMC) methods to perform integration over covariance hyperparameters in the regression setting. [42] extended the application of HMC methods to the classification setting. They employed HMC for sampling in the hyperparameter space and utilized the Laplace approximation to compute the integral over function values. [43], [44] focused on MCMC schemes to sample covariance hyperparameters in conjunction with latent function values, mainly mitigating the coupling effect through reparameterisation. [12] considered joint sampling of inducing variables and hyperparameters from the optimal variational posterior distribution while [45] considered inference schemes for fully Bayesian sparse GPs in a streaming setting. The technique introduced by [5] incorporates Variational Inference (VI) into Fully Bayesian GPs, approximating the posterior over hyperparameters with a factorized Gaussian distribution (mean-field approximation). More recently, [46] modified the generative model by adding a prior over the inducing inputs, and performed inference using SG-HMC over the joint kernel hyperparameters $\\lambda$, inducing points Z, inducing variables U space. Subsequently, [6] extended this method to a doubly collapsed bound, which analytically selected the optimal distribution over the inducing points.\n\nc) GPs with deep architectures: We will also focus on the utilization of deep structures in GPs, specifically Deep Gaussian Processes (DGPs) and Differential Gaussian Processes (DIFFGPs) consisting of discrete layers and continuous layers. DGP [14] is a model composed of multiple layers of Gaussian processes. Each layer is a Gaussian process model used to model the nonlinear relationships in intermediate layers. The output layer of the DGP model provides the final prediction. In addition to traditional Bayesian inference methods, DGP introduces several new inference techniques. DSVI [15] introduced stochastic variational inference to handle large-scale data and learn the distribution of model parameters. SGHMC [47] is a model that uses Hamiltonian Monte Carlo method for inference in deep Gaussian processes. This method incorporates stochastic gradients for learning, allowing for large-scale data processing during the inference process. IPVI [48] constructed an approximate posterior by introducing Nash equilibrium. NOVI [49] is a method that uses neural networks and score-based approaches to approximate the complex posterior distribution in DGPs. Unlike traditional DGP methods that focus on iterative function mappings, DIFFGPS [4] utilized SDEs to characterize continuous-depth Gaussian processes. By transforming the GP modeling into a continuous-time"}, {"title": "IV. EXPERIMENTS", "content": "In this section, we evaluate the performance of our proposed approximate inference method, FB-DIFFGP, on UCI datasets for regression and classification tasks. We compare it against state-of-the-art techniques like SVGP [11], DGP [15], and DIFFGP [4]. The number of inducing points M is manually selected, balancing accuracy and computation time. We optimize all parameters jointly using the evidence lower bound and employ stochastic optimization with mini-batches and the Adam optimizer. Numerical solutions of SDEs are obtained using the Euler-Maruyama solver with 20 time steps. The number of time steps changes if T is increased. For larger T, we would typically need to increase the number of time steps to maintain the same level of accuracy in the discretization of the SDE. This ensures that the solution remains precise and the numerical methods used are effective for longer time intervals. Other solvers, such as higher-order or adaptive methods, can also be easily implemented in Python toolkits.\n\nOur model primarily handles classification and regression tasks, employing a simple network architecture with a few fully connected layers. The mini-batch size chosen is 10,000, and the learning rate is set to 0.01. We plan to compare more architectures in future work and explore their differences and applicability. Our implementation utilizes GPyTorch [34], a Gaussian processes framework based on PyTorch. For comparison, we used a simple two-layer BNN. The network consists of one hidden layer with a specified number of neurons, followed by an output layer. The DNN used for comparison is deployed as described in [57]. This network architecture includes several layers, with specifics provided in the paper."}, {"title": "A. Toy Dataset for Unsupervised Task", "content": "We applied our proposed model architecture to an unsupervised dimensionality reduction task using the Bayesian Gaussian Process Latent Variable Model (GPLVM) [58] for data reconstruction. Our toy dataset is the multi-phase Oilflow data [59], comprising 1,000 data points in 12 dimensions, categorized into three classes representing different phases of oil flow in a pipeline. We reduced the data's dimensionality to 10 while striving to retain as much information as possible. We report the reconstruction error and mean squared error (MSE) with \u00b12 standard errors across ten optimization runs. Since the training is unsupervised, the inherent ground-truth labels were not included in the training process. The 2D projections of the latent space for the Oilflow data clearly demonstrate that our model successfully uncovers the class structure. To emphasize the strengths of our model, we present the results of the 2D latent space for three models in Figure 4. As shown in Figure 4, the reconstructed data points for the three classes are more distinctly separated in our model, resulting in improved and more intuitive clustering. From Table II, we observe that our proposed FB-DIFFGP outperforms both the Standard GPLVM and DIFFGP methods, yielding lower reconstruction loss and improved uncertainty estimation."}, {"title": "B. UCI Regression Benchmarks", "content": "We compared our model against the state-of-the-art results reported in [4] on eight regression benchmarks. The datasets were tested with different flow time values ranging from 1 to 5."}, {"title": "V. CONCLUSION", "content": "Our research introduces a cutting-edge fully Bayesian approach that treats kernel hyperparameters as random variables and utilizes interconnected stochastic differential equations (SDEs) to infer the posterior distribution of DIFFGPs. By capturing uncertainty in hyperparameter estimation, our method significantly enhances model adaptability in capturing complex system dynamics. Through compelling experimental results, we demonstrate the superiority of our methodology over conventional techniques, showcasing improved performance in flexibility and accuracy. This research opens doors for advancements in Bayesian inference and provides a powerful tool for modeling continuous-time Gaussian processes. Future exploration includes expanding the application of our FBDIFFGP model in diverse domains such as image analysis and financial datasets, offering exciting opportunities for further discovery in probabilistic modeling."}]}