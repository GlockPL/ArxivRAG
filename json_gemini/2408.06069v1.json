{"title": "Fully Bayesian Differential Gaussian Processes through Stochastic Differential Equations", "authors": ["Jian Xu", "Zhiqi Lin", "Min Chen", "Junmei Yang", "Delu Zeng", "John Paisley"], "abstract": "Traditional deep Gaussian processes model the data evolution using a discrete hierarchy, whereas differential Gaussian processes (DIFFGPs) represent the evolution as an infinitely deep Gaussian process. However, prior DIFFGP methods often overlook the uncertainty of kernel hyperparameters and assume them to be fixed and time-invariant, failing to leverage the unique synergy between continuous-time models and approximate inference. In this work, we propose a fully Bayesian approach that treats the kernel hyperparameters as random variables and constructs coupled stochastic differential equations (SDEs) to learn their posterior distribution and that of inducing points. By incorporating estimation uncertainty on hyperparameters, our method enhances the model's flexibility and adaptability to complex dynamics. Additionally, our approach provides a time-varying, comprehensive, and realistic posterior approximation through coupling variables using SDE methods. Experimental results demonstrate the advantages of our method over traditional approaches, showcasing its superior performance in terms of flexibility, accuracy, and other metrics. Our work opens up exciting research avenues for advancing Bayesian inference and offers a powerful modeling tool for continuous-time Gaussian processes.", "sections": [{"title": "I. INTRODUCTION", "content": "Traditional Gaussian processes models [1] have limitations in handling non-Gaussian distributions, complex distributions, time series, and other challenging tasks. To address this, deep Gaussian processes (DGPs) have been introduced for more expressive representations. However, DGPs may face issues with degenerate models if individual GPs are not invertible [2], [3]. One approach to overcome these challenges is DIffGPs [4], which model data evolution in continuous time using stochastic differential equation systems. This allows for learning continuous-time transformations of the data, offering a more natural way to capture data dynamics compared to traditional methods. DIffGPs warp inputs through differential fields to generalize discrete layers into a dynamic system. The intuition of \"warping\" the inputs over time, as derived from the original DiffGP paper, is an extension of the concept of deep Gaussian processes in continuous layers. Similar to the transition from ResNet to neural ODEs, this approach aims to adapt and transform the input space progressively over time, allowing the model to better capture complex patterns and dependencies in the data.\nThe DIffGP methods [4] have been criticized for overlooking uncertainty in kernel hyperparameters, crucial for accurate modeling and reliable uncertainty estimation. The choice of covariance function in GPs significantly impacts the posterior distribution, highlighting the importance of selecting a proper covariance function [5], [6]. Model selection in GP modeling involves specifying covariance functions and selecting hyperparameters, typically done by maximizing the marginal likelihood or its lower bound. However, this approach faces challenges due to the non-convex nature of the marginal likelihood surface, especially with multiple modes and weakly identifiable hyperparameters. Maximizing the marginal likelihood may lead to overfitting and underestimation of prediction uncertainty, as gradient-based optimization is sensitive to initial values. Improved methods are needed to address these challenges in hyperparameter estimation for GP models.\nIn this work, we propose a fully Bayesian approach to Gaussian process regression, treating kernel hyperparameters as random variables and using coupled stochastic differential equations (SDEs) to learn their posterior distribution and that of inducing points. This method effectively addresses the non-convexity of the marginal likelihood surface, providing robust parameter estimation. By incorporating uncertainty in hyperparameters through the posterior distribution, overfitting is avoided, and generalization to new data is enhanced. Bayesian methods offer a comprehensive understanding of parameter estimation by capturing inherent uncertainty, improving model reliability and adaptability.\nExtending the Bayesian treatment of hyperparameters to a hierarchical framework presents challenges in computing posterior distributions, leading to increased complexity. We introduce a novel methodology using SDEs to learn the posterior distribution of hyperparameters and inducing points, capturing their uncertainty effectively. By integrating Bayesian inference with SDEs, our approach enhances model adaptability and robustness in capturing system dynamics.\nOur work introduces a novel network architecture that not only enhances the expressiveness of DIffGPs but also integrates the uncertainty of kernel parameters and inducing point distributions into a fully Bayesian inference frame-work, incorporating their time-correlated posterior SDEs. By leveraging state-of-the-art SDE gradient estimators, such as those in [7], [8], [9], [10], we demonstrate the effectiveness"}, {"title": "II. MODEL", "content": "Gaussian processes (GPs) are powerful probabilistic models that define a distribution over functions. Given a collection of input points $X = \\{x_1,...,x_N\\}^T \\in \\mathbb{R}^{N\\times D}$, where $x \\in \\mathbb{R}^D$, a GP specifies a joint Gaussian distribution over the corresponding function values $f = \\{f(x_1),...,f(x_N)\\}^T \\in \\mathbb{R}^N$. The fundamental property of GPs is that the outputs at different points correlate based on their similarity, as measured by a kernel function $k(x, x')$, as described by Rasmussen and Williams [1].\nTraditionally, a zero-mean Gaussian process prior is defined on a function $f(x)$ over vector inputs $x \\in \\mathbb{R}^D$:\n$f(x) \\sim GP(0, k(x, x'))$,\nwhere $k(x, x')$ is the kernel function, and it captures the covariance between function values at different inputs.\nTo handle large datasets effectively, we can employ sparse Gaussian processes that utilize a small set of induc-ing or landmark variables. These inducing variables $u = \\{u_1,...,u_M\\}^T \\in \\mathbb{R}^M$, where $M$ is much smaller than $N$, are chosen from the dataset. By conditioning the GP prior on these inducing variables $u$ and their corresponding locations $Z = \\{Z_1,...,Z_M\\}^T$, we can obtain posterior predictions at the data points.\nThe sparse GP posterior predictions, given the inducing variables $u$ and their locations $Z$, are given by:\n$f | u, Z \\sim N(Qu, K_{XX} - Q K_{ZZ} Q^T)$,\n$u \\sim N(0, K_{ZZ})$,\nwhere $Q = K_{XZ}(K_{ZZ} + \\sigma^2I)^{-1}$ is the matrix of the coefficients relating the inducing variables to the function values, $\\eta$ in $\\sigma_{\\eta}$ refers to the position of the sample point, $K_{XX}$ is the kernel matrix between the data points, $K_{ZZ}$ is the kernel matrix between the inducing points, $K_{XZ}$ is the kernel matrix between the data points and the inducing points, and $\\sigma^2$ is the noise variance of the observations.\nThe main inference problems for Gaussian Processes (GPs) are related to the inducing points $Z$, inducing variables $u$, and the kernel hyperparameters $\\lambda$. For instance, if we choose the classic Gaussian kernel, the formula for the kernel is:\n$k(x, x') = \\sigma_f^2 exp(-\\frac{||x - x'||^2}{2l^2})$ (1)\nIn classical inference methods, VI [11] and Markov Chain Monte Carlo (MCMC) [12] have been widely successful. By incorporating sparse representation through inducing variables, we can effectively model and make predictions in large-scale datasets using Gaussian processes."}, {"title": "B. Continuous-Time Gaussian Processes", "content": "The continuous-time deep learning paradigm introduced by [4] focuses on a model called DIFFGP, which is a continuous-time deep Gaussian process model through infinite, infinitesi-mal differential compositions. In DIFFGP models, the input data is transformed using a stochastic differential equation (SDE) flow to obtain transformed inputs $X_T$, which are then used for model fitting after a predefined time $T$. The parameter $T$ determines the length of the flow and the system's capacity, similar to the number of layers in standard deep GPs or deep neural networks.\nIn this paradigm, the inputs are redefined as temporal functions $x : T \\rightarrow \\mathbb{R}^D$ over time, where state paths $x_t$ over time $t \\in T = \\mathbb{R}^+$ emerge. The observed inputs $x_{i,0}$ correspond to initial states. The task is to classify or regress the final data points $X_T = (x_{1,T},..., x_{N,T})$ after $T$ time of an SDE flow using a predictor Gaussian process. In above notation, the first index represents the dimension of the sample points, indicating the number of sample particles. The second index represents the dimension of the discrete time points. The predictor is denoted as $g (x_T)$ and is assumed to follow a Gaussian process prior with zero mean and a covariance function $K (x_T, x'_T)$. When $T = 0$, the framework reduces to a conventional Gaussian process.\nThe prediction depends on the final dataset $X_T$ structure, determined by the SDE flow $dx_t$ from the original data $X$. We consider SDE flows of Ito type\n$dx_t = \\mu (x_t) dt + \\sqrt{\\Sigma(x_t)}dW_t$ (2)"}, {"title": "III. FULLY BAYESIAN VARIATIONAL INFERENCE", "content": "Within the realm of Gaussian process (GP) regression, the effectiveness of the model is intricately tied to the judicious selection of kernel hyperparameters and inducing points, a task renowned for its inherent complexity. The pursuit of optimal values for these parameters presents a formidable challenge that demands a strategic approach. In response to this challenge, our proposed methodology advocates for the adoption of a comprehensive Bayesian framework that explic-itly acknowledges and encompasses the uncertainty inherent in the kernel hyperparameters and inducing points. By immersing this uncertainty into the very core of the inference process, we cultivate a model that not only exhibits heightened resilience but also demonstrates exceptional adaptability, poised to navi-gate the intricate nuances of the data landscape with enhanced agility and robustness.\nIn the generating process of the model, we assume that the kernel hyperparameters $\\Lambda_t$, inducing points $Z_t$, and inducing variables $U_t$ are drawn from certain prior distributions. These hyperparameters control the behavior of the Gaussian process model and are crucial for determining the smoothness and flexibility of the model. The inducing points $Z_t$ are any set of points within the input space that can be optimized to approximate the function values at all input points. The inducing variables $U_t$ are the corresponding function values at the inducing points.\nGiven these prior distributions, the model generates the observed data $X$ and $y$ by drawing samples from the Gaussian process defined by the kernel function with the hyperparameters $\\Lambda_t$ and the inducing variables $U_t$. For example, in the classic Gaussian kernel, $\\Lambda = \\{\\sigma_f,l\\}$. The posterior distribution of the hyperparameters, inducing points, and inducing variables can then be estimated based on the observed data using Bayesian inference techniques. This allows us to make predictions and infer the underlying structure of the data based on the Gaussian process model,\nPrior over hyperparameters $\\Lambda_t \\sim P(\\Lambda_t)$\nPrior over inducing points $Z_t \\sim p(Z_t)$\nPrior over inducing variables $U_t \\sim GP(0, K(Z_t, Z))$\nModel forward SDE $dx_t = \\mu (x_t) dt + \\sqrt{\\Sigma(x_t)}dW_t$+\nPredictor Gaussian process $g \\sim GP(0, K (x_T, x'_T))$\nData likelihood $y | g \\sim N (g, I)$ (4)\nInspired by the ANODEV2 method [16], which extends a complex ODE model for evolving neural network parameters, we view the hyperparameters $\\Lambda_t$ and inducing points $Z_t$ as prior processes that evolve over time, in contrast to traditional fully-GP models and previous works like DIFFGPs. This approach departs from the fixed hyperparameters assumption and allows for a more dynamic modeling of the parameter evolution. Drawing parallels to evolutionary computing meth-ods such as HyperNEAT [17], Compressed Weight Search [18], and Hypernetworks [19], which employ secondary net-works to generate parameters for the main network, our approach extends this concept to parameter evolution in GP-SDE models. By adopting a Bayesian perspective, we aim to capture the time-varying distribution of hyperparameters, thereby enhancing the flexibility and adaptability of our model.\nWe can apply the concept of amortized variational inference, as introduced in the works of [20], [21], [5], to optimize the factorized approximate posterior distribution $q(x_t, Z_t, U_t) = q(x_t)q(Z_t)q(U_t)$. This requirement is met by employing the mean-field assumption, where the posterior is approximated as a product of several independent factors. The goal is to minimize the Kullback-Leibler (KL) divergence between this approximate posterior and the true posterior distribution. This optimization objective is equivalent to maximizing the Evidence Lower Bound (ELBO), which serves as a lower bound on the marginal likelihood of the data under the model. By maximizing the ELBO, we can efficiently approximate the true posterior distribution and make accurate inference about the model's parameters and latent variables,\n$log p(y) \\geq Eq(x_{0:T})q(Z_{0:T})q(U_{0:T})P(x_T|x_{0:T},Z_{0:T},U_{0:T})P(g|x_T) [logp(y | g)] - KL (q (\\Lambda_{0:T}) || p (\\Lambda_{0:T})) - KL (q (Z_{0:T}) || p (Z_{0:T})) - KL (q (U_{0:T}) || p (U_{0:T}))$ (5)\nwhere $\\Lambda_{0:T}, Z_{0:T}$, and $U_{0:T}$ represent the trajectory paths of $\\Lambda_t, Z_t$, and $U_t$ respectively. Next, we show how to do efficient variational inference in SDE models, and optimize the marginal log-likelihood to fit both prior hyperparameters"}, {"title": "B. Approximate Posterior through Latent Stochastic Differential Equations", "content": "To perform posterior inference in our model, we leverage latent stochastic differential equations [22], [7], [23], [24]. These SDEs provide a principled and flexible framework for modeling complex temporal dynamics. In particular, we can parameterize both a prior over functions and an approximate posterior using coupled SDEs in the following system of differential equations.\n$\\begin{cases} d\\Lambda_t = h_{0\\lambda} (\\Lambda_t, t) dt + l_{\\lambda} (\\Lambda_t, t) dW_t, \\text{ (prior)} \\\\ d\\Lambda_t = h_{p\\lambda} (\\Lambda_t, t) dt + l_{\\lambda} (\\Lambda_t, t) dW_t, \\text{ (approx.posterior)} \\\\ dZ_t = h_{0Z} (Z_t, t) dt + l_{Z} (Z_t, t) dW_t, \\text{ (prior)} \\\\ dZ_t = h_{pZ} (Z_t, t) dt + l_{Z} (Z_t, t) dW_t, \\text{ (approx.posterior)} \\end{cases}$ (6)\nThe difference between the prior and posterior processes lies solely in their drift terms. Similar to classical Bayesian analysis, the parameters of the prior SDE can be set to simple, fixed values, such as constants or basic affine transformations, while the drift term of the posterior SDE is parameterized by a fully connected neural network. This allows us to compute the KL divergence between the prior and posterior SDEs using Girsanov's theorem [25]. We apply this approach to both Z and $\\Lambda$ to ensure that our model retains fully Bayesian properties. Although we currently assume the drift term to be a simple function, it is also feasible to employ complex networks to learn the prior, a direction we intend to explore in future work.\nFor instance, in the context of an Ornstein-Uhlenbeck (OU) prior stochastic differential equation (SDE), we specify fixed prior drift coefficients as $h_{0\\Lambda} = -\\Lambda_t$ and $h_{0Z} = -Z_t$, along with fixed prior diffusion coefficients as $l_{\\lambda} = \\sigma_{\\lambda}I$ and $l_Z = \\sigma_Z I$. We choose to employ the OU process due to its simplicity and well-understood properties. This process can be represented by the following SDE:\n$\\begin{cases} d\\Lambda_t = -\\Lambda_tdt + \\sigma_{\\lambda}I dW_t, \\text{ (prior)} \\\\ dZ_t = -Z_tdt + \\sigma_ZI dW_t, \\text{ (prior)} \\end{cases}$ (7)\nFor the approximate posterior processes of $\\Lambda_t$ and $Z_t$, we also employ an SDE representation, where $h_{p\\lambda}$ and $h_{pZ}$ are parameterized neural networks, and all drift and diffusion functions are Lipschitz continuous. With these drifts, the approximate posterior process will generally have nonGaus-sian, non-factorized marginals. It may seem very restrictive to assume that the diffusion terms of the prior and posterior are identical in Eq. (6). However, previous results from the Neural SDE literature demonstrate that any posterior can be approximated with arbitrary closeness using such a functional form given a sufficiently expressive drift process [26], [10], [7], [24].\nThen the Kullback-Leibler (KL) divergence between these distributions is finite and can be estimated by sampling paths from the posterior process [22], [7]. According to Girsanov's theorem [25], an essential result in stochastic calculus, it states how the probability measures change under a change of drift in stochastic processes. With respect to our context, Girsanov's theorem allows us to express the Evidence Lower Bound (ELBO) in a concise and insightful manner, capturing the essence of the relationship between the true and approximate distributions in a probabilistic framework,\n$\\log p(y) \\geq Eq(\\Lambda_{0:T})q(Z_{0:T})q(U_{0:T})P(x_T|x_{0:T}, Z_{0:T}, U_{0:T})P(g|x_T) [\\log p(y | g)] - \\frac{1}{2} \\int_0^T Eq(\\lambda_t) |u_{\\lambda} (\\lambda_t,t)|^2 dt - \\frac{1}{2} \\int_0^T Eq(Z_t) |u_{Z} (Z_t,t)|^2 dt - KL (q (U_{0:T}) || p (U_{0:T}))$ (8)\nwhere\n$u_{\\lambda}(\\lambda_t,t) = l_{\\lambda}(\\lambda_t,t)^{-1} (h_{0\\lambda}(\\lambda_t, t) - h_{p\\lambda} (\\lambda_t, t))$,\n$u_Z(Z_t, t) = l_{Z} (Z_t, t) ^{-1} (h_{0Z} (Z_t, t) - h_{pZ} (Z_t, t))$\n$l_{\\lambda}(\\lambda, t)^{-1}$ and $l_{Z}(Z_t, t)^{-1}$ are the left inverse, and the expec-tation is taken over the approximate posterior process defined by Eq. (6). The functions $u_{\\lambda}$ and $u_Z$ need to fulfill the Novikov condition [7], which ensures that the drift and diffusion terms of the SDE are well-defined and that the process remains consistent with the requirements of stochastic calculus.\nAll estimates of stochastic differential equation (SDE) paths and gradients are simulated and computed using cutting-edge SDE solvers, as outlined in the work by [7]. Furthermore, to address large-scale data challenges efficiently, we can utilize mini-batch surrogates for likelihood optimization. This approach harnesses concepts from backpropagation introduced by [27] and stochastic optimization techniques such as those discussed by [28], [29], [15]. By employing mini-batch sur-rogates, we can effectively optimize likelihood functions for models handling significant amounts of data while retaining computational efficiency.\n$log p (y|g) = \\frac{N}{B}\\sum_{i=1}^{B} log p (y_i|g)$ (9)\nFor variational inference of the inducing variable $U_t$, we follow the approach of previous work [4], by assuming that its posterior is a Gaussian distribution.\nq (U_t) = N (m_t, S_t) (10)\nWhat sets this work apart from prior research is that $m_t$ and $S_t$ are time-dependent networks while in the original DiffGP, this term is modeled as a constant. We aim to characterize the dynamical system of the inducing variables over time. Since the fact that the Kullback-Leibler divergence between two Gaussian distributions is analytical, the expres-sion KL (q (U_t) || p (U_t)) can be explicitly represented as,\n$KL (q (U_{0:T}) || p (U_{0:T})) = \\int_0^T Eq(\\lambda_t,Z_t) \\Big(\\int Eq(U_t,\\lambda_t,Z_t) log \\frac{q (U_t)}{p (U_t)} dt\\Big) dt = \\frac{1}{2} \\int_0^T \\Big(Tr (K_{ZZ}^{-1} S_t) + m_t^T K_{ZZ}^{-1}m_t - M + ln \\frac{det(K_{Z_tZ_t})}{det(S_t)}\\Big) dt $ (11)\nSince $U_t$ has already been integrated out, there is no need for an expectation with respect to $U_t$. However, the expectations with respect to $Z_t$ and $\\Lambda_t$ are still necessary."}, {"title": "C. Simulation and Predictions", "content": "By combining Eq. (2) and Eq. (6), we can derive:\n$\\begin{pmatrix} dx_t \\\\ d\\Lambda_t \\\\ dZ_t \\end{pmatrix} = \\begin{pmatrix} \\mu(x_t) \\\\ h_p(\\Lambda_t,t) \\\\ h_{0Z} (Z_t,t) \\end{pmatrix} dt + \\begin{pmatrix} \\sqrt{\\Sigma (x_t)} \\\\ l_{\\lambda} (\\Lambda_t,t) \\\\ l_Z (Z_t,t) \\end{pmatrix} dW_t$ (12)\nBy leveraging advanced SDE solvers for state trajectory approximation, we can effectively perform stochastic gradient estimation for optimizing Eq. (8). This technique enhances our understanding of the model's loss function and enables more efficient optimization. Integrating Bayesian methodologies for hyperparameters and inducing points with dynamic SDE pos-terior estimation leads to a more flexible and expressive poste-rior estimation for DIFFGPs. This advancement improves the model's adaptability in capturing complex system dynamics and enhances predictive capabilities, providing a powerful tool for robust and informed model predictions."}, {"title": "D. Related Work", "content": "Sparse Gaussian Processes are an ex-tension of GPs that address scalability issues in modeling large datasets. Traditional GPs involve inverting the covariance matrix, which becomes computationally expensive as the size of the dataset increases. Sparse GPs alleviate this issue by introducing a smaller set of \"inducing points\" that approximate the latent function properties over the entire dataset. By assuming a joint distribution over the function values at the inducing points and the entire data points, Sparse GPs can approximate the true GP model while significantly reducing the computational complexity. Sparse GPs have gained popu-larity in various applications, including machine learning [11], robotics [30], and computer vision [31], where dealing with large datasets is common. Modeling and inference with Sparse GPs have evolved considerably over the last few years with key contributions in the direction of scalability to virtually any number of datapoints and generality within automatic differentiation frameworks [32], [33], [34]. This has been possible thanks to the combination of stochastic variational inference techniques [29] with representations based on induc-ing variables [35], [36], [11]. These advancements have now made GPs attractive to a variety of applications and likelihoods [32], [37], [38], [39]. However, it is worth noting that Sparse GPs still require selecting the appropriate hyperparameters and inducing points, which can be challenging in some cases."}, {"title": "IV. EXPERIMENTS", "content": "In this section, we evaluate the performance of our proposed approximate inference method, FB-DIFFGP, on UCI datasets for regression and classification tasks. We compare it against state-of-the-art techniques like SVGP [11], DGP [15], and DIFFGP [4]. The number of inducing points $M$ is manually selected, balancing accuracy and computation time. We opti-mize all parameters jointly using the evidence lower bound and employ stochastic optimization with mini-batches and the Adam optimizer. Numerical solutions of SDEs are obtained using the Euler-Maruyama solver with 20 time steps. The number of time steps changes if $T$ is increased. For larger $T$, we would typically need to increase the number of time steps to maintain the same level of accuracy in the discretization of the SDE. This ensures that the solution remains precise and the numerical methods used are effective for longer time intervals. Other solvers, such as higher-order or adaptive methods, can also be easily implemented in Python toolkits.\nOur model primarily handles classification and regression tasks, employing a simple network architecture with a few fully connected layers. The mini-batch size chosen is 10,000, and the learning rate is set to 0.01. We plan to compare more architectures in future work and explore their differences and applicability. Our implementation utilizes GPyTorch [34], a Gaussian processes framework based on PyTorch. For compar-ison, we used a simple two-layer BNN. The network consists of one hidden layer with a specified number of neurons, followed by an output layer. The DNN used for comparison is deployed as described in [57]. This network architecture includes several layers, with specifics provided in the paper."}, {"title": "A. Toy Dataset for Unsupervised Task", "content": "We applied our proposed model architecture to an unsu-pervised dimensionality reduction task using the Bayesian Gaussian Process Latent Variable Model (GPLVM) [58] for data reconstruction. Our toy dataset is the multi-phase Oilflow"}, {"title": "B. UCI Regression Benchmarks", "content": "We compared our model against the state-of-the-art results reported in [4] on eight regression benchmarks. The datasets were tested with different flow time values ranging from 1 to 5."}, {"title": "b) Computational efficiency: In a similar manner to the baseline algorithms, each training iteration of FB-DIFFGP requires computing the inverse covariance with a complex-ity of O(M\u00b3).", "content": "In Table V, we compare our method, FB-DIFFGP, with baseline DIFFGP trained for a fixed epoch. The experiment is repeated five times on the same fold, and the results are averaged. Each run is conducted on a dedicated instance in a cloud computing platform equipped with a single Tesla A100 GPU. The results demonstrate that FB-DIFFGP does not significantly increase computational costs, thanks to the efficient parallel processing capabilities of deep learning GPUs."}, {"title": "c) Comparison for the proposed algorithm with different numbers of inducing points.:", "content": "We compared the performance of our proposed algorithm with M = 100 and M = 500 inducing points in Table VI. Our findings indicate that, similar to classical sparse GP methods, the performance improves with a higher number of inducing points, resulting in lower RMSE values. However, this improvement comes at the cost of increased training time, as the computational complexity grows with the number of inducing points."}, {"title": "C. UCI Classification Benchmarks", "content": "As a large-scale example, we conducted experiments on the Higgs dataset, which consists of 11 million data points with 28 features. This dataset was generated through Monte Carlo simulations of particle dynamics in accelerators for Higgs boson detection. We randomly allocated 90% of the data for training and kept the remaining 10% for testing. To evaluate the performance, we utilized the area under the curve (AUC) metric and compared our results with previously reported methods. Table VII presents the obtained test performance, demonstrating that our FB-DIFFGP method outperforms the competing approaches. Additionally, we conducted experi-ments on the SUSY dataset, and the results showcased the competitive performance of our proposed algorithm."}, {"title": "V. CONCLUSION", "content": "Our research introduces a cutting-edge fully Bayesian ap-proach that treats kernel hyperparameters as random variables and utilizes interconnected stochastic differential equations (SDEs) to infer the posterior distribution of DIFFGPs. By cap-turing uncertainty in hyperparameter estimation, our method significantly enhances model adaptability in capturing complex system dynamics. Through compelling experimental results, we demonstrate the superiority of our methodology over conventional techniques, showcasing improved performance in flexibility and accuracy. This research opens doors for advancements in Bayesian inference and provides a powerful tool for modeling continuous-time Gaussian processes. Future exploration includes expanding the application of our FB-DIFFGP model in diverse domains such as image analysis and financial datasets, offering exciting opportunities for further discovery in probabilistic modeling."}]}