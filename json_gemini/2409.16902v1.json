{"title": "Towards Underwater Camouflaged Object Tracking: An Experimental Evaluation of SAM and SAM 2", "authors": ["Chunhui Zhang", "Li Liu", "Guanjie Huang", "Hao Wen", "Xi Zhou", "Yanfeng Wang"], "abstract": "Over the past decade, significant progress has been made in visual object tracking, largely due to the availability of large-scale training datasets. However, existing tracking datasets are primarily focused on open-air scenarios, which greatly limits the development of object tracking in underwater environments. To address this issue, we take a step forward by proposing the first large-scale underwater camouflaged object tracking dataset, namely UW-COT. Based on the proposed dataset, this paper presents an experimental evaluation of several advanced visual object tracking methods and the latest advancements in image and video segmentation. Specifically, we compare the performance of the Segment Anything Model (SAM) and its updated version, SAM 2, in challenging underwater environments. Our findings highlight the improvements in SAM 2 over SAM, demonstrating its enhanced capability to handle the complexities of underwater camouflaged objects. Compared to current advanced visual object tracking methods, the latest video segmentation foundation model SAM 2 also exhibits significant advantages, providing valuable insights into the development of more effective tracking technologies for underwater scenarios. The dataset will be accessible at https://github.com/983632847/Awesome-Multimodal-Object-Tracking.", "sections": [{"title": "1 Introduction", "content": "Visual object tracking (VOT) involves continuously locating a target object within a video sequence and has applications in autonomous vehicles [28, 25, 26], surveillance [35, 5], and robotics [33, 36]. Its significance lies in enabling machines to perceive and interpret dynamic environments, supporting tasks like motion analysis and decision-making [22, 15, 23]. Although significant progress has been made in terrestrial and open-air scenarios [17, 9], tracking in underwater environments remains challenging due to factors like visual camouflage, light scattering, and low contrast, which limit the effectiveness of conventional algorithms [34, 1, 2]. Consequently, there is a pressing need for specialized datasets and methods to tackle the complexities of underwater tracking, especially when objects blend with their surroundings, known as camouflaged objects. However, despite its importance, underwater camouflaged object tracking remains an unexplored field.\nCurrent VOT methods can be broadly categorized into several types. Traditional correlation filter-based methods [31, 13, 12, 32] utilize efficient convolution operations to track objects, whereas Siamese-based methods [3, 20, 21] employ dual-stream networks to learn a similarity function between the target object and the search region. Transformer-based methods, such as OSTrack [30], SeqTrack [6], and ARTrack [27], leverage the attention mechanism to model complex dependencies"}, {"title": "2 UW-COT Dataset", "content": "Our goal is to construct a large-scale underwater camouflaged object tracking dataset that involves a rich variety of categories and various real underwater scenes for evaluating and developing general underwater camouflaged object tracking methods. To achieve this, we collect underwater videos from video-sharing platforms (e.g., YouTube\u00b2) and existing tracking datasets (e.g., WebUOT-1M [34] and"}, {"title": "3 Experimental Results", "content": "Main Results. We evaluate SAM-based tracking methods (i.e., SAM-DA [11], and Tracking Anything [29]), SAM 2, and three current SOTA visual object tracking methods (i.e., OSTrack [30], SeqTrack [6], and ARTrack [27]) on the proposed UW-COT dataset. The results are shown in Fig. 2. Our observations are as follows: 1) SAM 2 outperforms SAM-based trackers (SAM-DA and Tracking-Anything) on UW-COT, which can be attributed to a series of improvements SAM 2 introduces over SAM for video and image tasks, such as improving temporal consistency, robustness to occlusions, feature embeddings, computational efficiency, motion estimation accuracy, generalization to new domains, and integration of contextual information. 2) SAM 2 achieves the best performance, surpassing current state-of-the-art VOT methods. As a foundation model for video segmentation, SAM 2's success reflects a promising effort to address the dynamic challenges present in video data, such as fast motion, deformation, similar distractors, and occlusion, and to provide a more generalized solution for video object tracking and beyond."}, {"title": "Ablation Studies", "content": "We take SAM 2 as an example to explore the impact of different ways of point prompts (i.e., center point and random point within the initial target box) and model sizes. From Tab. 2, we find that using the center point as a prompt yields significantly better results than using random points. This suggests that for the interactive segmentation model SAM 2, the quality of the prompt is very important. The results in Tab. 3 demonstrate that larger model sizes generally lead to better performance, but the speed of the model decreases significantly. We also discovered an interesting phenomenon: when the number of model parameters is relatively small, a smaller model (e.g., SAM 2-tiny) can even outperform a larger model (e.g., SAM 2-small). We suspect this may be due to overfitting, or that small models are more sensitive to the quality of the training data."}, {"title": "4 Conclusion", "content": "In this paper, we introduce UW-COT, the first large-scale benchmark for underwater camouflaged object tracking, and demonstrate the superior performance of SAM 2 over other tracking methods, showcasing its potential for enhancing underwater tracking technologies. In the future, we plan to expand the scale and modalities of this dataset, as well as explore various underwater vision tasks."}]}