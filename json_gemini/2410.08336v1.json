{"title": "KERNEL BANZHAF: A FAST AND ROBUST ESTIMATOR FOR BANZHAF VALUES", "authors": ["Yurong Liu", "R. Teal Witter", "Flip Korn", "Tarfah Alrashed", "Dimitris Paparas", "Juliana Freire"], "abstract": "Banzhaf values offer a simple and interpretable alternative to the widely-used Shapley values. We introduce Kernel Banzhaf, a novel algorithm inspired by KernelSHAP, that leverages an elegant connection between Banzhaf values and linear regression. Through extensive experiments on feature attribution tasks, we demonstrate that Kernel Banzhaf substantially outperforms other algorithms for estimating Banzhaf values in both sample efficiency and robustness to noise. Furthermore, we prove theoretical guarantees on the algorithm's performance, establishing Kernel Banzhaf as a valuable tool for interpretable machine learning.", "sections": [{"title": "1 INTRODUCTION", "content": "The increasing complexity of AI models has intensified the challenges associated with model interpretability. Modern machine learning models, such as deep neural networks and complex ensemble methods, often operate as \"opaque boxes.\u201d This opacity makes it difficult for users to understand and trust model predictions, especially in decision-making scenarios like healthcare, finance, and legal applications, which require rigorous justifications. Thus, there is a pressing need for reliable explainability tools to bridge the gap between complex model behaviors and human understanding.\nAmong the various methods employed within explainable AI, game-theoretic approaches have gained prominence for quantifying the contribution of features in predictive modeling and enhancing model interpretability. While primarily associated with feature attribution (Lundberg & Lee, 2017; Karczmarz et al., 2022), these methods also contribute to broader machine learning tasks such as feature selection (Covert et al., 2020) and data valuation (Ghorbani & Zou, 2019; Wang & Jia, 2023). Such applications extend the utility of explainable AI, fostering greater trust in AI systems by providing insights beyond traditional explanations.\nShapley values, rooted in cooperative game theory, provide a principled way to attribute the contribution of n individual players to the overall outcome of a game (Shapley, 1953). In the context of feature attribution, each \u201cplayer\" is a feature and the \u201cgame\u201d is defined by a set function that maps a subset of features to the prediction score of an AI model on that subset. For a given feature, the Shapley value quantifies the average marginal contribution of the feature on the model's prediction, computed as the weighted average over all possible combinations of features included in the model (see e.g., Equation 1) (Lundberg & Lee, 2017).\nAn alternative to Shapley values are Banzhaf values, which also compute each individual's contribution to the system's overall outcome (Banzhaf, 1965). While Shapley values are more widely used, Banzhaf values are often considered more intuitive for AI applications since they treat each subset of players as equally important, directly measuring the impact of each player across all possible combinations (see e.g., Equation 2). Additionally, Banzhaf values can be computed more efficiently and tend to be more numerically robust (Karczmarz et al., 2022; Wang & Jia, 2023)."}, {"title": "2 BACKGROUND", "content": "Let n be the number of players and $v : 2^{[n]} \\rightarrow \\mathbb{R}$ be a set function. The Shapley value of player i for $i \\in [n] := \\{1, ..., n\\}$ is\n$\\phi_i^{\\text{Shapley}} = \\frac{1}{n} \\sum_{S \\subseteq [n]\\setminus \\{i\\}} \\frac{(n-1 - |S|)!}{|S|!(n-1)!} (v(S \\cup \\{i\\}) - v(S))$\nwhile the Banzhaf value is\n$\\phi_i^{\\text{Banzhaf}} = \\frac{1}{2^{n-1}} \\sum_{S \\subseteq [n]\\setminus \\{i\\}} [v(S \\cup \\{i\\}) - v(S)]$\nShapley values and Banzhaf values each uniquely satisfy four different properties. We defer the description of these properties to Appendix H. By default, we shall use $\\phi$ to denote Banzhaf unless explicitly stated otherwise and use $\\phi \\in \\mathbb{R}^n$ to denote the vector $[\\phi_1, ..., \\phi_n]$.\nWe can recover various tasks in machine learning by choosing different ways of defining the set function. In this work, we will consider one of the most popular tasks in explainable AI: feature attribution (also known as feature importance and feature influence). Let M be some model which takes in input $x \\in \\mathbb{R}^n$. In the version we consider, the feature attribution seeks to explain the predictions of the model on an explicand observation $x_e$, which is the target data point for which we want to understand the contributions of individual features. Given a subset of features S, define $x_S$ as the observation where $x^i = x^i_e$ if feature $i \\in S$ and, otherwise, $x^i_S$ is sampled from a distribution, as discussed in Appendix B. $v(S) = \\mathbb{E}[M(x_S)]$, where the expectation is over the sampling of the features $i \\& S. We can adapt the algorithm to other machine learning tasks such as feature (or data) selection by redefining v(S) as the loss of a model trained using only the features (or observations) within subset S."}, {"title": "3 KERNEL BANZHAF", "content": "The starting point of our work is a formulation of Banzhaf values in terms of a specially structured linear regression problem, and in Theorem 3.2, we show that Banzhaf values are the exact solution to this linear regression problem. Then we propose the Kernel Banzhaf algorithm for estimating Banzhaf values."}, {"title": "3.1 LINEAR REGRESSION FORMULATION", "content": "Consider binary vectors $z \\in \\{-1,1\\}^n$. In a slight abuse of notation, we will use z as input to the set function where the corresponding set is induced by z. We will also use z as an index for the following matrices.\n\u2022 Let A \u2208 $[\\mathbb{R}^{2^n} \\times n$ where the row corresponding to z is given by $[A]_z = z^T$.\n\u2022 Let b \u2208 $[\\mathbb{R}^{2^n}$ where the entry corresponding to z is given by $b_z = v(z)$.\nThe following observation about A will be helpful in our analysis.\nObservation 3.1. $A^T A = 2^{n-2}I$\nProof. The (i, j) entry in $A^T A$ is given by\n$[A^T A]_{i,j} = \\frac{1}{4} \\sum_z z_i z_j$\nIf $i \\neq j$, there are $2^{n-1}$ terms of $\\frac{1}{4}$ when $z_i \\neq z_j$ and $2^{n-1}$ terms of $\\frac{1}{4}$ when $z_i = z_j$, hence Equation 3 is 0. If $i = j$, we have $2^n$ terms of $\\frac{1}{4}$ hence Equation 3 is $2^{n-2}$. Together, this gives that $A^T A = 2^{n-2}I$.\nWith this observation, we will establish that Banzhaf values are the solution to the linear regression problem defined on A and b. A similar result was known but only for the case where v is a simple set function (the output is binary {0, 1} and the function satisfies a monotonicity property) (Hammer & Holzman, 1992).\nTheorem 3.2 (Linear Regression Equivalence). The Banzhaf values are the solution to the linear regression problem induced by A and b, i.e.,\n$\\phi = arg \\min_x ||Ax - b||_2$.\nThe proof shows that the optimal linear regression solution is equal to the Banzhaf values.\nProof. By setting the gradient of the objective function to 0, we have that\n$arg \\min_x ||Ax - b||_2 = (A^T A)^{-1} A^T b$.\nWe will analyze the right hand side. By Observation 3.1, we have $A^T A = 2^{n-2}I$. Then $(A^T A)^{-1} = \\frac{1}{2^{n-2}} I$. Continuing, we have\n$(A^T A)^{-1} A^T b = \\frac{1}{2^{n-2}} A^T b = \\frac{1}{2^{n-2}} \\frac{1}{2} \\sum_z z v(z) \\sum_z z$.\nNow consider entry i given by\n$[(A^T A)^{-1} A^T b]_i = \\frac{1}{2^{n-2}} \\frac{1}{2} \\sum_z z_i v(z) = \\frac{1}{2^{n-1}} \\sum_{S \\subset [n] \\backslash \\{i\\}} [v(S \\cup \\{i\\}) - v(S)]$\nwhich is exactly Equation 2. The statement follows."}, {"title": "3.2 THE KERNEL BANZHAF ALGORITHM", "content": "Since A and b are exponentially large, constructing the linear regression problem to calculate the Banzhaf values is computationally prohibitive. Instead, we construct a smaller linear regression problem with m samples. Let the subsampled matrix be $\\tilde{A} \\in \\mathbb{R}^{m \\times n}$ and the target vector be $b \\in \\mathbb{R}^m$. The estimate we produce is\n$\\tilde{\\phi} = arg \\min_x ||\\tilde{A}x - \\tilde{b}||_2$."}, {"title": "3.3 APPROXIMATION GUARANTEES", "content": "Theorem 3.3. If $m = O(n \\log \\frac{n}{\\delta} + \\frac{n}{\\epsilon^2})$, Algorithm 1 produces an estimate $\\tilde{\\phi}$ that satisfies\n$||A \\tilde{\\phi} - A \\phi||_2 \\le (1 + \\epsilon) ||A \\phi - b||_2$\nwith probability $1 - \\delta$.\nTheorem 3.3 is a standard guarantee for leverage score sampling. However, because rows are sampled in pairs, we need to substantially modify the standard analysis. In particular, both the spectral guarantee that the sampling matrix preserves eigenvalues and the Frobenius guarantee that the sampling matrix preserves Frobenius norm need to be reproved."}, {"title": "5 RELATED WORK", "content": "Game-Theoretic Explainable AI Semivalues like Shapley and Banzhaf values, derived from game theory, are widely used for machine learning tasks. Feature attribution involves determining the impact of individual features on model predictions, with Shapley values notably used in Lundberg & Lee (2017). This method also facilitates feature selection by modifying set functions to measure the feature's impact on model performance via loss metrics (Covert et al., 2020). Data valuation extends to treat individual data points as players, assessing their influence on model training outcomes like accuracy or AUC (Ghorbani & Zou, 2019).\nA parallel trend in utilizing Banzhaf values has been noted, with studies indicating their robustness compared to Shapley values, particularly under conditions of low numerical precision (Karczmarz et al., 2022). Furthermore, Wang & Jia (2023) established the superiority of Banzhaf values among semivalues regarding safety margin, the threshold of set function perturbations that the value order can withstand without changing. These properties have led to extensive application of Banzhaf"}, {"title": "6 CONCLUSION", "content": "In this paper, we presented Kernel Banzhaf, an innovative estimator for Banzhaf values that leverages linear regression to improve the efficiency and robustness of Banzhaf value estimation for explainable AI. Our empirical and theoretical analysis reveal that Kernel Banzhaf outperforms existing"}, {"title": "B IMPLEMENTATION DETAILS", "content": "Feature perturbation and exact Banzhaf value calculation There are generally two approaches to handling removed features in feature perturbation for general set functions, as discussed in Chen et al. (2020) and Kumar et al. (2020). Given an explicand x and a subset of features S, define xs as the observation where $x^i = x^i_e$ if feature $i \\in S$ and, otherwise, $x^i_S$ is sampled from a distribution. The first method involves sampling from the conditional distribution of the removed features, where replacement values for the absent features are sampled according to $x_S \\sim p(x | x_S)$. This approach, while precise, is computationally expensive. Alternatively, the marginal distribution can be used where the observed features $x_S$ are ignored, and replacement values are sampled according to $x \\sim p(x^S)$. Due to its lower computational complexity, we adopt the latter approach.\nFor implementation, distinct feature perturbation methods are applied depending on the set function, i.e. model type. For tree-based models, as we need to use the tree-based algorithm for calculating the ground truth Banzhaf values to measure errors, we utilize a method aligned with Algorithm 1 from Karczmarz et al. (2022), which computes predictions using partial features. Specifically, during tree traversal, if feature $i \\in S$, we proceed according to the threshold to select the child node; if $i \\notin S$, we traverse both children and compute a weighted average of the predictions, effectively nullifying the influence of features not in S without any feature value replacement.\nFor neural network models, instead of using fixed baseline values for the removed features, we compute the average of the model's predictions using replacement values randomly sampled from 50 baseline points, different from the explicand. The explicand $x_e$ is repeated 50 times, with the non-selected features replaced by values from these baseline points, and the average of $M(x_S)$ is taken to estimate the impact of marginalizing out the non-selected features. To calculate ground truth Banzhaf values, we evaluate all $2^n$ subsets of features in this way.\nSample size for Monte Carlo Given a sample size of n, the MSR and Kernel Banzhaf estimators effectively use n samples to estimate Banzhaf values for all features concurrently. In contrast, the Monte Carlo method estimates each feature independently and requires a fair allocation of the total m samples. To achieve this, we implement a loop where for each iteration i = 1, ..., m, we use i mod n + 1 samples when i is divisible by n, and i mod n samples otherwise. This approach ensures that the Monte Carlo method also utilizes exactly m samples, maintaining consistency in sample usage across different estimators."}]}