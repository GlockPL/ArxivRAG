{"title": "Convolutional Neural Network Design and Evaluation for Real-Time Multivariate Time Series Fault Detection in Spacecraft Attitude Sensors", "authors": ["Riccardo Gallon", "Fabian Schiemenz", "Alessandra Menicucci", "Eberhard Gill"], "abstract": "Traditional anomaly detection techniques onboard satellites are based on reliable, yet limited, thresholding mechanisms which are designed to monitor univariate signals and trigger recovery actions according to specific European Cooperation for Space Standard-ization (ECSS) standards. However, Artificial Intelligence-based Fault Detection, Isola-tion and Recovery (FDIR) solutions have recently raised with the prospect to overcome the limitations of these standard methods, expanding the range of detectable failures and improving response times.\nThis paper presents a novel approach to detecting stuck values within the Accelerometer and Inertial Measurement Unit of a drone-like spacecraft for the exploration of Small Solar System Bodies (SSSB), leveraging a multi-channel Convolutional Neural Network (CNN) to perform multi-target classification and independently detect faults in the sensors. Significant attention has been dedicated to ensuring the compatibility of the algorithm within the onboard FDIR system, representing a step forward to the in-orbit validation of a technology that remains experimental until its robustness is thoroughly proven. An inte-gration methodology is proposed to enable the network to effectively detect anomalies and trigger recovery actions at the system level. The detection performances and the capabil-ity of the algorithm in reaction triggering are evaluated employing a set of custom-defined detection and system metrics, showing the outstanding performances of the algorithm in performing its FDIR task.", "sections": [{"title": "Introduction", "content": "Failure Detection, Isolation, and Recovery (FDIR) is critical in every operational spacecraft, as undetected failures can have severe consequences, potentially jeopardizing mission uptime. Traditional FDIR approaches typically employ straightforward thresholding techniques on onboard parameters. While these methods offer robustness, they may lack efficiency in detecting certain types of failures. Operational FDIR systems in European satellites are based on the so-called Packet Utilization Standard (PUS, [7]), which defines a number of different Services regulating space-ground communications. Among these, Service 12 (Onboard Monitoring), Ser-vice 5 (Event Reporting), Service 19 (Event-Action), and action-type services like Service 18 (Onboard Control Procedure) or 21 (Request Sequencing) are mostly used in FDIR.\nService 12 (S12) is responsible for onboard parameter and functional monitoring (pMon and fMon) for failure detection purposes. The monitoring can apply to the value of a signal, its expected value or its variation, checking instances where they fall Out-of-Limit (OOL) beyond intervals defined during mission design. Typically, a logical combination (AND/OR) of pMons is associated to an fMon, which triggers upon the associated pMons registering OOL for a specified number of consecutive samples over a defined time interval (persistency). Service 5 is employed to link the triggered fMon to an Event ID, which usually represents the cause of the detected failure. Service 19 links the Event ID to a recovery action. Finally, action-type services (e.g. S18 or S21) are used to execute the recovery actions.\nThe FDIR subsystem typically includes multiple chains of the above-mentioned PUS Services, structured across five hierarchical levels defining how to address failures. The levels go from unit to subsystem to system level and can be activated by the adjacent lower level only when the latter cannot resolve or isolate a fault.\nAlthough representing the operational state of the art, PUS-based FDIR presents several well-known limitations, which mainly relate to its specific design for univariate time series and to the parameter monitoring mechanism. On the one hand, failures impacting several telemetry signals coming from different components and/or subsystems, as well as inherently multivariate data (e.g images) cannot efficiently be analyzed through PUS-based FDIR because they do not fit into the univariate time series definition. On the other hand, failures affecting univariate time series where the signal evolves anomalously within the boundaries set by the thresholds exist, and are traditionally undetectable unless their consequences become visible to the PUS Services on higher levels. Usually, this means the faults propagated and increased in severity.\nStuck values in multivariate time series data are a typical example of faults where the PUS-based detection shows inefficiency. These faults cause the signal to remain stuck on the same value over time, either involving one or all the components, eventually not exceeding the threshold boundaries. The most common detection methodology for stuck values is based on the consequences that they cause in other parameters of the system, eventually falling OOL, and are detected through higher-level FDIR. This approach, while representing the operational state of the art, lets the fault evolve uncontrollably for a certain time, thus constitutes a limi-tation which is worth trying to mitigate or solve. The application of Artificial Intelligence (AI) algorithms to the problem of stuck values arises from the need to enhance the detection of these faults, especially in terms of early detection and accuracy. To this purpose, this work employs the use case of the Astrone KI spacecraft to provide data and demonstrate the validity of the presented approach.\nAstrone KI is a drone-like spacecraft designed for autonomous flight within the challenging en-vironment of an SSSB, including take-off and landing. The distinctive mission profile motivates the selection of an accelerometer and an Inertial Measurement Unit (IMU), deliberately kept separate to measure both accelerations and angular rates. This setup aims to achieve precise attitude determination, particularly when coupled with cameras and LiDARs, that also serve the broader purpose of enabling vision-based navigation and guiding the drone's relocation"}, {"title": "Background", "content": "AI-based onboard FDIR, especially about time series, is a recent trend, but it has been already identified as one of the most promising fields of research due to the foreseen benefits that AI may bring to this specific functionality ([18], [19], [22], [4]). More specifically, scientific liter-ature concentrates more on the field of Failure Detection and Isolation than on the Recovery part, which typically relies on conventional methods (e.g. configuration change, power-cycle, redundancy switch). A variety of AI methodologies are employed to address the FDI task, where Deep Learning (DL) is the recently-emerged alternative to the more traditional Machine Learning (ML).\nML applications to anomaly detection in time series include mainly Support Vector Machines (SVM, [26], [9]), Clustering Methods ([15], [1], [8]) and Decision Trees ([11]). These approaches, together with their very well-established state in academic literature, are also the ones that meet the desired interpretability features in the onboard FDIR. They are indeed based on fully deter-ministic algorithms, in contrast to Deep Learning algorithms which are essentially black boxes. An example of ML-based FDIR is provided in [26] and [9], which present the application of an SVM for anomaly detection in real telemetry data including voltages, currents and tem-peratures. A first pre-processing step is carried out by expressing data in terms of statistical descriptors and applying Principal Component Analysis (PCA). Following, the anomaly detec-tion is performed by the SVM. Clearly, the classifiers SVMs in [26] and [9] are guided by the"}, {"title": "Fault Injection and Dataset Generation", "content": "In the present study, the generation of the dataset to be subject to anomaly detection utilizes components of the AOCS Offline Simulation Environment (AOSE, [24]) employed in the As-trone KI project, developed within Airbus Defence and Space GmbH. This simulator includes proprietary models of sensors, actuators, dynamics, attitude determination and control algo-rithms, as well as a PUS-based FDIR module which is used to test the proposed AI-based FDIR functionalities.\nThe unit models of the accelerometer and IMU are simulated in AOSE providing as input the spacecraft position and velocity over predefined trajectories and commanding the fault injection based on specific requirements.\nSpacecraft position and velocity are obtained simulating random monodirectional trajectories, equally spaced over the yaw angle and departing from the same starting point, assuming a hypothetical flat asteroid surface"}, {"title": "Fault Detection", "content": "Special attention has been given in this work to proper data scaling as it plays a particularly relevant role in this study, besides being a well-recognized practice in AI literature ([21]). Due to the presence of stuck at random value faults, the dataset can extend far beyond the nominal operational range of the accelerometer and IMU signals, ultimately approaching in-finity. Hence, the resulting dataset is characterized by a large portion of data in proximity of the nominal range of the signal, with a reduced percentage of outliers assuming different random values. This spread of the dataset over a wide range of values is generally leading to deterioration of the Neural Network detection performances, unless a proper scaling is applied.\nA comparison of different scalers from the scikit-learn Python library was carried out with the objective of filtering the outliers from the nominal range of the signal, trying to provide a clear separation between the two and consequently enhance the fault detection. At the same time, an excessive shrink of the unfaulty signal shall be avoided, because it may deteriorate the performances of the Network in recognizing faults within its nominal range, especially stuck at last values.\nA simple standardization of the entire dataset distribution would lead to excessive flattening of the nominal-range data near the zero line, as all data are centered and scaled based on their standard deviation, which is spoilt by the presence of infinite-like values. Hence, although a clear separation between the infinite-like values and the nominal is maintained, the stuck value cases other than these extreme values and the nominal signal are bounded within a range of a few orders of magnitude, leading to a consistent drop of the capability to distinguish one from the other, especially when noise is involved. To address this issue, scikit-learn's RobustScaler has been selected to especially exclude infinite-value faults from the scaling computation. This scaler disregards a portion of the dataset when computing scaling factors by only keeping a specific quantile range, which means a percentage of the sorted data.\nIn the RobustScaler, setting an upper bound to the quantile range is useful to exclude infinite-like values from computation, but may also help with those faults where the stuck value slightly deviates from the nominal range. This consideration applies equally to both the signal and its derivative, which is also a feature in the input of the neural network, as detailed in Section 4.2. Similar reasoning applies to the lower bound of the quantile range. Excluding the lowest values from scaling is particularly beneficial in the derivative of the signal, which sharply drops close to zero when a stuck value occurs, and thus can be adequately distinguished after the scaling stage."}, {"title": "Convolutional Neural Network", "content": "In the specific FDI task addressed in this work, a CNN is employed for binary classification of input data into \"fault\" and \"no fault\". This decision was favored over its multi-class counter-part because, from the perspective of FDIR, there is no distinction among the recovery actions associated with the nature of the injected stuck value cases. However, the classification task must be multi-target, meaning that fault/no fault predictions must be obtained for both sensors under analysis. This is crucial for understanding where the fault is occurring and directing the recovery to the correct sensor.\nThe network structure must consider the interconnection between the signals of the two sensors, making it necessary to include a joint signal processing step. This ensures that complex scenar-ios requiring a comparison of the two signals to distinguish a fault are appropriately handled. For instance, a straight flight may result in a flat IMU signal, which could be misinterpreted as a stuck value if considered alone without cross-referencing the accelerometer output, which would instead be changing due to local gravity variations.\nInspired by the architecture proposed in [5], this work proposes a multi-channel convolutional network where the input time series come from the two mentioned sensors, departing from the original idea of [5], who proposed different manipulations of the very same time series as input. The output is instead made by two different failure indices, again corresponding to the two sensors in analysis\nThe neural network takes input from a sliding window applied to the sensor signal, continu-ally updating with new samples received from the simulator interface. This window comprises the current sample along with a fixed-length history of past samples, aiming to detect the evolution of a stuck value, which typically requires multiple samples to realize over time. In addition, the input window consists of six features: three representing the signal itself and three representing the derivative of the signal, computed at each time sample. The derivative"}, {"title": "Integration with onboard FDIR", "content": "The requirement of integrating the AI side-by-side with the PUS chain, coming from the project, led this study to consider different integration possibilities, which can eventually be linked to two main categories, either processing the AI failure index as an Event or as a pMon. The main difference between the two is that in the first case a single failure prediction from the AI is straightly translated to a recovery action, while in the second case the same prediction is first monitored as a pMon having its associated fMon, which eventually triggers the Event and the recovery afterwards.\nIn this specific case, the AI output has been decided to be processed as a single pMon with a single associated functional monitoring, with the expected value of the pMon set to zero. Since the output index is a Boolean value, the pMon is triggered whenever the AI output predicts a non-zero value (failure), and the associated fMon is triggered accordingly.\nThis approach offers several advantages. First, it enhances the robustness of the method to outliers compared to directly linking the prediction to event triggering. This is because it incorporates the persistency check between the failure prediction and event triggering. Addi-tionally, it allows greater flexibility in implementation, particularly regarding the infrastructure surrounding the management of pMons and fMons. Indeed, the disabling of a pMon or fMon is a mechanism already embedded in the PUS-based FDIR ([7]), which can be reused for the AI output pMon, therefore enhancing its dependability as it is relying on well-established onboard procedures."}, {"title": "Performances Evaluation", "content": "Building on the research of [20] and [17], this study shares the objective of evaluating the CNN\u2019s ability to detect intervals rather than individual samples. However, unlike those works, this research does not explore intervals within the context of a signal reconstruction architecture. Instead, it addresses the classification of entire faulty intervals. Evaluating whether the CNN correctly classifies an interval is crucial, especially concerning the triggering of reactions in onboard FDIR through the mechanism of persistency of positive failure predictions (see Section 1). In this context, the developed set of metrics serves to assess both the capability of the AI algorithm to detect faults (Detection Metrics) and the effects of this detection on the onboard FDIR subsystem (System Metrics)."}, {"title": "Detection Performances", "content": "The Detection Metrics only assess the performance of the algorithm. Effectively substituting the classic precision, recall and F1-score metrics used to evaluate classification tasks, the set of metrics proposed in this work is meant to evaluate the capability of an algorithm to detect faults by measuring case-specific quantities that are more representative in the specific AI-based onboard FDIR framework.\nBefore properly defining the set of metrics, a few initial definitions need to be given.\nThe labels vector y and the predicted labels vector ypred are divided into intervals of True (fault) and False (no fault) values. These intervals are referred to as faults or fault intervals. A Missed Fault occurs when there is a complete interval of disagreement between y and Ypred, meaning that the algorithm misses the whole fault. On the other hand, if the algorithm detects a fault with a positive prediction immediately after an interval of disagreement between y and Ypred, it is referred to as a Delay in prediction. Situations where ypred shows oscillations in the prediction while y is consistently faulty are called Uncertain Prediction. According to the given definitions, the Detection Metrics are presented in Table 2."}, {"title": "System Performances", "content": "Related to the integration of the AI algorithm in a much broader system (i.e. the rest of the spacecraft), the system performances are related to the capability of impacting the components they interface with. More specifically, the AI-based FDIR is meant to exchange telemetry and telecommands with e.g. the OBC, the sensors themselves, etc. From some of these components it only receives data, from the other it establishes a bilateral link and is capable of triggering recovery actions to react to the detected failures. Therefore, the definition of System Metrics is tightly bounded to the integration strategy of the AI algorithm inside the PUS-based onboard FDIR subsystem.\nIn order to evaluate the performances of the architecture as defined in Section 4.3, a redefinition of the well-established concepts of Precision and Recall was carried out, starting from True Positives (TP), False Positives (FP) and False Negatives (FN), which are now reinterpreted in terms of the recovery actions triggered by the AI output within onboard FDIR. On one side, a predicted fault longer than the persistency time frame and with no real fault subtended is a FP because it triggers an unnecessary recovery action. Conversely, a real fault where no failure prediction is present constitutes a FN because it triggers no reaction. Besides these two extreme cases, it can also happen that a failure prediction with a real fault subtended does not meet the persistency duration requirement to trigger a reaction, therefore it has no impact on the system level and does not take part to the System Metrics computation. This case is particularly present in situations where the model is not well optimized, leading to high prediction delays which push the fault detection too late after the actual start, or leading to fragmented failure prediction within the same real faults where all the single fragmented prediction intervals are not able to reach the persistency threshold. Table 3 summarizes all the defined System Metrics."}, {"title": "Optimization", "content": "To understand how Detection and System Metrics are utilized for evaluating a specific AI-based FDIR solution, it is crucial to emphasize the underlying requirements. From the perspective of the FDIR subsystem, minimizing false positive-triggered reactions is paramount, as these could affect mission availability, potentially leading to the activation of safe mode. Conversely, while detecting faults is important, it is less critical compared to minimizing false positives, given the nature of the examined scenario. Indeed stuck values can always be indirectly identified by con-ventional FDIR methods through the propagation of their consequences over time. Hence, even if the AI is not perfect in detecting these faults, they can eventually be identified by PUS as time progresses. This mechanism is remarkable from a system engineering point of view because, since it is clear that an AI-based FDIR solution is not enough dependable (rather experimental) to be applied to an operational scenario, the stuck value faults provide a framework to prove the effectiveness of the AI on a critical functionality, without loading it with critical decision power.\nThe optimization of the specific AI-based FDIR solution has to focus on the System Metrics, which give a quantitative shape to the requirements mentioned above. However, the Detection Metrics also have to enter the optimization process by being used to double check if the value reached in the system performances is realistic or is subject to bias. Algorithm 1 shows the complete optimization procedure.\nThe introduction of persistency in the hyperparameter tuning loop is related to the need to compute and optimize the System Metrics, but is not conceptually against the independence of the System Metrics from the Detection Metrics. Indeed, the independence embedded in the design will be reflected in the optimization loop with the persistency value being optimized on its own, not depending on the rest of the hyperparameters, therefore making identical the process of optimizing the persistency aside the main loop or inside it. In addition, once the algorithm has given the optimized persistency value as output, the task of tuning the parameter for maximizing the system performances is already embedded and may eventually need minor adjustment based on the specific requirements.\nConcerning the last step of Algorithm 1, the need to double-check the Detection Metrics at the end of the whole process arises from the idea that biases in metrics could occur if the algorithm excels in detecting long-lasting faults but struggles with shorter ones or sparse outliers. The optimization process may then lead to a high value of persistency following the long-lasting well-detected faults and even reach very good performances, while a check of the Detection Metrics would potentially show a high rate of Delays, False Positives, and Missed Faults. The"}, {"title": "Results", "content": "The training of the Neural Network occurs in a supervised way employing labels available from the fault injection stage. Due to the binary classification task, the binary crossentropy loss function is employed, together with Adam optimizer with learning rate subject to optimization, and an EarlyStopping callback is set with patience 5. The batch size is 32768. The rest of the hyperparameters are subject to the optimization process detailed in Algorithm 1 and are shown in Table 4.\nIt is remarkable to notice that the particular Windows Length obtained after the optimiza-tion is smaller than the Distance Between Subsequent Faults (Table 1). The choice of the latter has been specifically done to ensure that each window would include maximum one fault, while including sufficient samples to allow the CNN to gather significant information on the stuck value eventually present. In other words, the network needs to see sufficient samples history to recognize a fault, if present, but cannot see windows where multiple faults are present, since this situation is not realistic. This consideration is equally valid for both sensors. Hence, the specific value chosen for the Distance Between Subsequent Faults in Table 1 allows the optimizer to iterate in a significant range of windows length values, seeking optimal performances while ensuring the presence of one fault at a time.\nThe resulting Detection and System Metrics, evaluated on a validation dataset obtained by the very same Monte Carlo analysis described in Section 3, are presented in Tables 5 and 6."}, {"title": "Conclusions and Future Work", "content": "The different stuck value faults considered in the simulation comprehensively represent the various realizations of this class of faults in realistic scenarios on a functional level, making the presented solution applicable on different FDIR levels. The employed simulation method also claims to be representative of realistic occurrences of stuck values, based on RAMS analysis, to enhance the learning of the CNN which can more easily adapt to a potential deployment. Since the dataset construction methodology, detailed in Section 3, is focused on an early de-tection of the faults, it does not need to include realistic fault duration, thus enhancing the generalization of the detection to stuck values occurring at very different time scales, i.e. in very different components. The only limitation is in the end constituted by the earliest fault detection capability, expressed in the Prediction Delays metric which set the lower bound to the duration of the detectable faults. Clearly, this reasoning has to take into account the persistency value, which has to stay coherent with the targeted faults.\nBased on the accelerometer and IMU of Astrone KI, the proposed dataset has been subject to fault detection via a Convolutional Neural Network (Section 4.2), which has proven its effective-ness in the diagnosis of the faults, achieving outstanding performances. The convolutions-based approach guarantees a partially interpretable algorithm which, in this particular case, allows a clear separation between the analysis of the single sensors and the joint-channel operations. Besides, it is particularly useful for the analysis of different time scales trends in time series, thus to address the stuck values faults presented in this work. Distinguishing a stuck derivative value behind the white noise to classify it is the most obvious situation, that the present anal-ysis faced, where convolutions served the scope of recognizing trends at different time scales. A set of case-specific metrics is then proposed to evaluate the CNN in its fault detection task. The design of the metrics focused on the real-time scenario, as well as on the interval-based nature of the faults. The latter is an element of innovation because it detaches from the classic point-wise conception of the fault classification, adapting to a problem which is very common in the field of anomaly detection in time series. Consequently, the developed metrics add a further layer of complexity to the network output processing, but makes it way more interpretable than classic evaluation approaches (i.e. F1-score, Precision, Recall).\nWhile the present research shows promising baseline performances on the Astrone KI use-case, it is just meant to prove the feasibility of the approach to accomplish the specific stuck value fault detection task. A deployment of the presented CNN onboard a flying mission shall first pass through the definition of application-dependent requirements (e.g. Precision and False Positives Percentage). These performance criteria shall be meant to guide the tuning process, as described in Section 5.3, thus shall be defined a priori based on the specific objectives of the mission, on the type of failure to be addressed and their required recovery actions. A first complement to the approach presented in this paper can be represented by a fine-tuning of wi and \u03b2 in Equation to obtain performances tailored to the specific needs. Plus, a sensitivity analysis over these parameters can also be an asset to evaluate the optimality of the obtained solution and enhance its robustness.\nConcerning the qualification of the presented model for space applications, the deployment on space-representative hardware (e.g. FPGAs) is certainly important, aiming to validate the solu-tion in realistic scenarios and identify any necessary adjustments or redesigns. This innovation would be eventually needed to prove the compatibility of the algorithm with field-specific edge devices in a real-time scenario, but also that it is able to achieve a similar performance as the theoretical one shown in the present work.\nSimilarly, another important step to the qualification for space is to test the robustness of the presented algorithm to different sensor models, coming from various producers in the space domain. This procedure would ensure the algorithm to fit various applications, enhancing its reusability across different missions and use-cases."}]}