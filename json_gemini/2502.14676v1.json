{"title": "BP-SGCN: Behavioral Pseudo-Label Informed Sparse Graph Convolution Network for Pedestrian and Heterogeneous Trajectory Prediction", "authors": ["Ruochen Li", "Stamos Katsigiannis", "Tae-Kyun Kim", "Hubert P. H. Shum"], "abstract": "Trajectory prediction allows better decision-making in applications of autonomous vehicles or surveillance by predicting the short-term future movement of traffic agents. It is classified into pedestrian or heterogeneous trajectory prediction. The former exploits the relatively consistent behavior of pedestrians, but is limited in real-world scenarios with heterogeneous traffic agents such as cyclists and vehicles. The latter typically relies on extra class label information to distinguish the heterogeneous agents, but such labels are costly to annotate and cannot be generalized to represent different behaviors within the same class of agents. In this work, we introduce the behavioral pseudo-labels that effectively capture the behavior distributions of pedestrians and heterogeneous agents solely based on their motion features, significantly improving the accuracy of trajectory prediction. To implement the framework, we propose the Behavioral Pseudo-Label Informed Sparse Graph Convolution Network (BP-SGCN) that learns pseudo-labels and informs to a trajectory predictor. For optimization, we propose a cascaded training scheme, in which we first learn the pseudo-labels in an unsupervised manner, and then perform end-to-end fine-tuning on the labels in the direction of increasing the trajectory prediction accuracy. Experiments show that our pseudo-labels effectively model different behavior clusters and improve trajectory prediction. Our proposed BP-SGCN outperforms existing methods using both pedestrian (ETH/UCY, pedestrian-only SDD) and heterogeneous agent datasets (SDD, Argoverse 1).", "sections": [{"title": "I. INTRODUCTION", "content": "Predicting the future movement of traffic agents, known as trajectory prediction, is crucial for safe and efficient decision-making in applications such as autonomous vehicles [1]. Thanks to reliable data-driven [2] object tracking methods [3], accurate geometric trajectories can be extracted from videos, serving as a more representative feature set for modeling. Graph Convolutional Networks (GCNs) [4] have shown exceptional performance across diverse fields due to their adeptness at capturing spatial relationships [5]\u2013[9]. This enables them to excel in applications ranging from trajectory agent interaction modeling [10]\u2013[13] to human skeleton-based behavior modeling [14]\u2013[18], highlighting the superior capabilities in handling graph-based data structures. Similarly, recognizing distinct movement behavior patterns among agents is pivotal to model the temporal dependency [19]. These patterns, when integrated with GCN, further enhance the precision of predictions by accounting for the inherent behavioral tendencies.\nExisting trajectory prediction methods can be broadly classified into two categories. The first focuses on predicting pedestrian trajectories in datasets that are exclusively composed of pedestrians [20], [21] or deliberately omit non-pedestrian traffic agents [22]\u2013[24]. These methods primarily employ neural networks to account for pedestrian social interactions, such as the pooling window mechanism [25] and social interaction graphs [10]\u2013[12]. The second category encompasses heterogeneous trajectory prediction, considering a diverse range of traffic agents (e.g. cars, cyclists, pedestrians, etc.). Recent methods [26]\u2013[28] exploit the annotated class labels of traffic agents to better model agent interactions in intricate urban scenarios. These labels facilitate the system's understanding on multifaceted interactions among various agent types [28].\nA notable research gap can be observed between pedestrian-only and heterogeneous trajectory prediction. Methods tailored solely for pedestrian behavior excel due to its predictable patterns but lack applicability in real-world scenarios like autonomous driving, since pedestrians behave very differently from heterogeneous agents [26], [28]. The fundamental differences in modeling the motion patterns of different types of agents stem from their distinct dynamics, speed ranges, spatial needs, interaction behaviors, decision-making processes, and ways of perceiving the environment, necessitating varied modeling approaches to accurately predict their trajectories. For heterogeneous trajectory prediction, ground-truth (GT) labels for agent types have traditionally been used to guide discriminative learning [26]\u2013[29]. However, these labels often fail to capture diverse within-class behaviors: for example, 'vans' and 'compact cars' are both labeled simply as 'cars,' while 'pedestrians' can range from ordinary walkers to skate-"}, {"title": "II. RELATED WORK", "content": "Deep learning models have driven the latest advancement of trajectory prediction. Social-LSTM [25] introduces RNN-based neural networks [36] to model the trajectories of pedestrians and a pooling window mechanism to describe the interactions among them. Social-GAN [37] incorporates the ideas of Generative Adversarial Networks [38] to predict multiple multi-modal trajectories with distance-based interaction modeling. Diffusion models [39] are adopted into trajectory prediction [40], [41], showing significant improvement.\nGraph representations are increasingly recognized for their prowess in modeling relational features. TrafficPredict [42] incorporates soft-attention-based interaction graphs with LSTM to represent social interactions. STGAT [11] models the trajectories using Spatial-Temporal Graph Attention Networks based on the sequence-to-sequence architecture. Social-STGCNN [12] introduces weighted graph edges, providing an interpretable measurement of pedestrian interactions. STAR [43] takes advantage of the Transformer [44] to construct a spatial-temporal graph transformer for trajectory representation. SGCN [10] advances this by proposing sparse directed spatial-temporal graph representations to model spatial interactions and motion tendencies for each pedestrian. However, these methods primarily focus on modeling pedestrian interactions, overlooking the intricate interactions among heterogeneous agents.\nFuture trajectory or goal information enhances the trajectory prediction as it provides valuable insights into the long-term intentions of individual agents [19], [22]\u2013[24], [40], [45]\u2013[49]. CVAE [50] based methods [45]\u2013[47] employ the future and past trajectory encoder during the training phase to train the latent representation for each agent. Such latent is used to generate future trajectories during inference. Goal retrieval methods sample goal points and incorporate them as guides to model the prediction diversity [22]\u2013[24]. We employs the goal retrieval approach proposed in [23], as it does not require training a separate models as in the CVAE-based method.\nAs trajectories are influenced by their surroundings, some studies employ image contextual features as auxiliary infor-"}, {"title": "III. BEHAVIOR PSEUDO-LABEL INFORMED SPARSE GRAPH CONVOLUTION NETWORK", "content": "We observe a research gap in pedestrian and heterogeneous trajectory prediction. Existing pedestrian prediction approaches have limited applicability to heterogeneous traffic agents due to the diverse behaviors of agents.\nAlthough introducing annotated class labels for heterogeneous agents leads to better prediction performance [26]\u2013[28], such labels are only a proxy of movement behaviors, which cannot represent intra-class behavioral differences and inter-class behavioral similarity.\nTo this end, we present the concept of behavioral pseudo-labels, which capture movement behaviors to enhance trajectory prediction. Our pseudo-labels do not require annotations, mitigating the risk of mislabeling and reducing labor costs. It can be applied to both pedestrian-only and heterogeneous datasets, resulting in superior prediction performance.\nTo realize pseudo-label informed trajectory prediction, we propose the Behavioral Pseudo-Label Informed Sparse Graph Convolution Network (BP-SGCN).\nBP-SGCN includes two modules: deep unsupervised clustering and pseudo-label informed trajectory prediction. The former learns the pseudo-labels in an unsupervised manner, while the latter performs end-to-end optimization to improve pseudo-label clustering while predicting trajectories with such labels.\nWe propose the cascaded training scheme to obtain the pseudo-labels and thus high-quality trajectory prediction.\n\nB. Deep Unsupervised Behavior Clustering\nHere, we explain how we obtain behavior clusters, which serve as powerful features for effective trajectory prediction.\n1) Geometric Representation of Trajectories\nGiven a series of observed video frames of N agents over time t\u2208 [1, Tobs], and the corresponding 2-D trajectory coordinates (x,y), \u0456 \u2208 [1, N], our objective is to predict the future trajectory coordinates pi = (x, y) of each traffic agent i within a time horizon t \u2208 [Tobs+1,Tpred].\nWe introduce relative angle and acceleration magnitude to learn behavior latents. While global velocity is an effective feature for trajectory prediction [10], [28], it is less representative of behaviors, as it depends on global movement directions, and is less sensitive to velocity changes. Relative angles provide a representation that is invariant to the initial facing direction,\nwhich is complemented with the magnitude of acceleration that has been shown to be effective for modeling behaviors. For each traffic agent i, we calculate its velocity vector at time t. For simplicity, we remove the notation i in the following equation:\n$V_t = \\left(\\frac{x_t - x_{t-1}}{t - (t-1)}, \\frac{y_t - y_{t-1}}{t - (t-1)}\\right).$\n(1)\nwhere \u2200t \u2208 [1,Tobs], we compute the cosine of the angle, cos (\u03b8t) between velocity vectors, vt and vt-1:\ncos(\u03b8t) = \\frac{v_t \\cdot v_{t-1}}{|v_t| |v_{t-1}|},\nand the magnitude of corresponding acceleration at time t:\n|a_t| = \\frac{|v_t - v_{t-1}|}{t - (t-1)}\n(3)\nThe geometric feature is constructed as gt = (cos(\u03b8t), |at|).\n2) Behavior Representation Learning\nWe adapt VRNN to learn latent representations for behavior clustering [31], [66]. VRNN learns the temporal dependencies of a sequence by modeling the distribution over its hidden states with an encoder-decoder architecture. Compared to LSTM-based autoencoders [66], it effectively models the highly nonlinear dynamics and captures the uncertainties of latent space. Its probabilistic nature of variational inference improves the learning of implicit sequential data distributions.\nIn particular, the encoder network enc(\u00b7) receives the embedded geometric data \u03c8(gt) and recurrent hidden state ht-1 to approximate the posterior distribution q\u03c6(\u00b7):\nq_\\phi(z_t | g_{<t}, z_{<t}) = N(z_t |(\\mu_{z,t}, \\sigma_{z,t}^2)),\n[\\mu_{z,t}, \\sigma_{z,t}] = \\varphi_{enc}(\\psi(g_t), h_{t-1}),\n(4)\nwhere zt is sampled using a reparameterization trick [67]. The decoder network \u03c6dec(\u00b7) takes the embedded latent \u03be(zt) and ht-1 to approximate the reconstruction distribution p\u03b8(\u00b7):\np_\\theta(g_t | z_{<t}, g_{<t}) = N(g_t |(\\mu_{g,t}, \\sigma_{g,t}^2)),\n[\\mu_{g,t}, \\sigma_{g,t}] = \\varphi_{dec}(\\lambda(z_t), h_{t-1}).\n(5)"}]}