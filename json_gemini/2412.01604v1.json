{"title": "Agentic-HLS: An agentic reasoning based high-level synthesis system using large language models (AI for EDA workshop 2024)", "authors": ["Ali Emre Oztas", "Mahdi Jelodari"], "abstract": "Our aim for the ML Contest for Chip Design with HLS 2024 was to predict the validity, running latency in the form of cycle counts, utilization rate of BRAM (util-BRAM), utilization rate of lookup tables (uti-LUT), utilization rate of flip flops (util-FF), and the utilization rate of digital signal processors (util-DSP). We used Chain-of-thought techniques with large language models to perform classification and regression tasks. Our prediction is that with larger models reasoning was much improved. We release our prompts and propose a HLS benchmarking task for LLMs.", "sections": [{"title": "1 Introduction", "content": "High-level synthesis (HLS) has revolutionised the landscape of hardware design by raising the level of abstraction, making it feasible to develop domain-specific accelerators (DSAs), such as field-programmable gate arrays (FPGAs), using high-level programming languages like C/C++ instead of traditional hardware description languages (HDLs). The figure to the right illustrates a typical HLS design, where the functionality is described using C++ code, and performance-related compiler directives, known as pragmas, dictate the microarchitectural transformations within the HLS framework. These pragmas influence key performance metrics, including latency and resource utilization rates.\nDespite these advancements, the optimisation space for microarchitectures expands exponentially with the inclusion of pragmas, creating an overwhelming design space. Evaluating each candidate architecture through HLS tools requires substantial time-ranging from several minutes to hours-making the optimization process both labor-intensive and time-consuming. Machine learning models have been leveraged to expedite this process, allowing for design quality predictions in milliseconds [2,3].\nIn the ML Contest for Chip Design with HLS [8], we used a novel approach that introduces agentic high-level synthesis, leveraging large language models (LLMs) equipped with specialised tools for reasoning and optimisation. By imbuing these models, specifically over 100 billion parameter models, with agent-like capabilities, they can autonomously explore, assess, and optimise HLS designs, enhancing the automation and intelligence embedded in the design flow. Our method bridges machine learning and hardware design, empowering LLMs to understand and interact with the design space to produce superior configurations more efficiently."}, {"title": "2 Methodology", "content": "Our proposed approach for the contest relies on an extended informative representation of an input design for high-quality performance prediction shown in Figure 1. Our approach consists of several steps: (a) HARP fine-tuning, (b) source code sequence analysis, (c) reasoning steps based on the training data points, and (d) an agentic predictor/criticiser to evaluate the results."}, {"title": "2.1 Fine-tuning HARP", "content": "HARP [3] is a GNN-based methodology that enhances FPGA HLS optimization by using a hierarchical graph representation to model program structure and pragma transformations separately, allowing for improved accuracy and adaptability. Through its modular design, HARP efficiently captures the dynamic impact of design choices, enabling faster and more accurate design space exploration. We utilized the HARP encoder to create comprehensive graph embeddings that encapsulate critical design features. The graph embeddings provide a representation from which reasoning about the critical path and latency measurements can be derived. The structure of these embeddings facilitates an in-depth analysis that highlights potential performance bottlenecks."}, {"title": "2.2 Source Code Analysis", "content": "The source code is analyzed using a large language model (LLM) to identify key program structures such as blocks and loops, aiding in the construction of data and control flow graphs. As illustrated in Figure 2, the LLM-generated analysis serves as an initial step prior to further optimizations."}, {"title": "2.2.1 Reasoning", "content": "We provide a high-level explanation of the impact that the target pragmas may have on the control/data flow graphs. The model incorporates graph-level reasoning to assess the influence of each pragma and its effect on the design's critical path and validity. This capability enables the prediction model to evaluate potential performance variations induced by different pragmas. Figure 3 shows impact of various optimisations on the spmv-ellpack kernel. Outliers were mostly identified as invalid designs. Graph embeddings carry specific control/data flow information that enables the LLM to attend to node-edge relationships and enhances their overall reasoning."}, {"title": "2.2.2 Agentic Evaluation", "content": "An iterative evaluation process is employed, wherein the predictor agent performs self-reflection based on available training data batches. This process runs for three cycles due to its computational expense but is crucial for enabling the predictor to rationalize its performance predictions. The predictor-agent iteratively refines its analysis by providing justifications for specific optimizations and then reflecting on feedback from the criticiser agent, enhancing overall prediction reliability."}, {"title": "3 Results", "content": "We initially began with a solution entirely based on large language models (LLMs), employing GPT-40 solely for generating predictions. Preliminary evaluations indicated that the classification task (i.e., distinguishing valid from invalid designs) significantly affected the root mean square error (RMSE) score. Consequently, our primary focus shifted towards developing a highly accurate classifier. Concurrently, we explored the design space exploration (GNN-DSE) method and deployed a local LLaMA2 7B model for classification. However, this model lacked sufficient depth for complex reasoning tasks.\nSubsequently, we concentrated on running HARP locally and contributed a pull request (PR) to resolve several bugs, enabling us to fine-tune HARP on the training dataset. We leveraged the reasoning capabilities provided by HARP graph embeddings and combined them with source code sequencing, which yielded a notable improvement over LLaMA2 (27%). Our final solution integrated GPT-40 and included several reasoning components along with an evaluator agent to iteratively (3 iterations) assess the predicted outcomes using the training samples available to the model. The results are detailed in Table 1. For the final submission, we selected the best-performing models, including the fine-tuned HARP."}, {"title": "4 Discussion", "content": "Limitation of CoT prompting: The technique is less effective with smaller models. To achieve meaningful gains, it's best to apply CoT in proportion to the model's size, as smaller models (less than 100B parameter) may produce less coherent reasoning with CoT prompting.\nWe plan to use models such LLAMA3 to conduct this experiment however we were short of tie. Tat why we chose GPT40. With emerge of larger models, we predict that agents will become more effective in reasoning and predicting design performances. As future work, we plan to extend the reasoning with synthesiser version considerations to achieve more accurate results. We believe our Agentic-HLS approach once published can attract attention of agentic workflow researchers and designers to the Neurips 2024 AI for EDA community and we are keen to explore the opportunity with larger models such as GPT-401 capable of deep reasoning."}]}