{"title": "DREAMS: A python framework to train deep learning\nmodels with model card reporting for medical and\nhealth applications", "authors": ["Rabindra Khadka", "Pedro G. Linda", "Anis Yazidi", "Asma Belhadi"], "abstract": "Electroencephalography (EEG) data provides a non-invasive method for re-\nsearchers and clinicians to observe brain activity in real time. The integra-\ntion of deep learning techniques with EEG data has significantly improved\nthe ability to identify meaningful patterns, leading to valuable insights for\nboth clinical and research purposes. However, most of the frameworks so\nfar, designed for EEG data analysis, are either too focused on pre-processing\nor in deep learning methods per, making their use for both clinician and\ndeveloper communities problematic. Moreover, critical issues such as ethi-\ncal considerations, biases, uncertainties, and the limitations inherent in AI\nmodels for EEG data analysis are frequently overlooked, posing challenges\nto the responsible implementation of these technologies. In this paper, we\nintroduce a comprehensive deep learning framework tailored for EEG data\nprocessing, model training and report generation. While constructed in way\nto be adapted and developed further by AI developers, it enables to report,\nthrough model cards, the outcome and specific information of use for both\ndevelopers and clinicians. In this way, we discuss how this framework can, in\nthe future, provide clinical researchers and developers with the tools needed\nto create transparent and accountable AI models for EEG data analysis and\ndiagnosis.", "sections": [{"title": "1. Motivation and significance", "content": "Existing frameworks dedicated to analyzing EEG data are relatively scarce\nand those that do exist tend to either cover a wide range of topics inade-\nquately or prioritize either the initial steps of data preparation or the uti-\nlization of advanced machine learning techniques [1]. Preprocessing-centric\nframeworks offer tools tailored to tasks such as noise removal, artifact correc-\ntion and data segmentation, but may lack advanced analysis capabilities [2].\nDeep learning-centric frameworks emphasize using sophisticated algorithms\nfor tasks like classification and feature extraction, assuming preprocessed\ndata [3]. Indeed, this lack of comprehensive frameworks presents challenges\nfor researchers and clinicians seeking effective tools for EEG data analysis.\nFurthermore, in the realm of EEG data analysis, ethical considerations\nplay a critical role [4], requiring strict adherence to ethical standards through-\nout the process of data collection and analysis. This includes securing in-\nformed consent from participants and safeguarding their privacy. Biases [5]\nrepresent a crucial concern in EEG data analysis, as they can distort results\nif left unaddressed. These biases, which include selection bias and interpreta-\ntion bias, must be carefully managed to ensure accurate findings. Uncertain-\nties arising from the complexity of EEG signals present another significant\nfactor that requires acknowledgment and quantification to ensure reliable in-\nterpretation. Al models utilized in EEG analysis have inherent limitations,\nsuch as interpretability issues, which must be accounted for to prevent mis-\nleading conclusions and ensure responsible research and clinical practices [6].\nUnfortunately, it is all too common for these critical considerations to be\ndisregarded or given insufficient attention.\nWithout proper documentation, it becomes difficult to evaluate reliability\nof the models, effectiveness and potential biases, which are critical factors in"}, {"title": "2. Related work", "content": "Some previous works must be highlighted, which will better contextualize\nand motivate the novelty of DREMS. Moons et al. [7] introduced the Trans-\nparent Reporting of Multivariable Prediction Model for Individual Prognosis\nor Diagnosis (TRIPOD) statement, which aimed to enhance the reporting of\nprediction models. The TRIPOD statement is a checklist comprising items\nessential for the transparent reporting of prediction model studies. This ex-\nplanation document details the rationale behind each item, clarifies their\nmeanings, and serves as a valuable reference for considerations when report-\ning the design and analysis of prediction model studies.\nSendak et al. [8] introduced the Model Facts label, designed for clinicians\nwho make decisions supported by machine learning models. Its purpose\nis to collect relevant, actionable information into a single page. Its major\nsections include the model name, locale and version, a summary of the model,\nthe mechanism of risk score calculation, validation and performance metrics,\nusage directions, warnings and additional information.\nCrisan et al. [9] explored interactive model cards, which enhance tradi-\ntional static model cards by allowing users to explore documentation and\ninteract with models. It includes a conceptual study with ML, NLP and AI\nEthics experts, followed by an evaluative study with non-expert analysts.\nMitchell et al. [10] presented a framework for transparent model report-\ning, primarily targeting human-centered models in computer vision and nat-\nural language processing, though it can be applied to any machine learning\nmodel. They illustrated the concept using model cards for two examples:\none that detects smiling faces in images and another that identifies toxic\ncomments in text. All of the architectures mentioned have certain limita-\ntions: they may oversimplify complex details and are often tailored to spe-\ncific settings. Some of these approaches require technical infrastructure for\nimplementation and others are presented as guidelines on particular domains,\nlimiting their broader applicability."}, {"title": "3. Software description", "content": "To illustrate the concept of DREAMS, we present a case study in which\nmodel cards (MC) are utilized to highlight the key aspects of the data, model,"}, {"title": "3.1. Software architecture", "content": "DREAMS, developed as a Python package, offers a comprehensive frame-\nwork aimed at simplifying the process of creating comprehensive model cards\nfor deep learning models. Model cards (MC) serve as vital documentation\ntools, outlining the performance metrics, usage guidelines and limitations of\nAI models. They play a pivotal role in enhancing transparency and promot-\ning the ethical utilization of AI technologies.\nThe DREAMS architecture is modular, comprising several key compo-\nnents. It starts with exploratory data analysis (EDA) on the provided\ndataset, with the visualizations saved in a designated folder. As the model\nprogresses through training and validation, this folder is further enriched\nwith additional plots, such as loss, accuracy and confusion matrix. Finally,\nthe model card function is invoked, using a configuration file that contains\nall the necessary details to generate the model card. An overview of the\narchitecture of DREAMS' library is shown in Figure 1."}, {"title": "3.2. Software functionalities", "content": null}, {"title": "3.2.1. Data preprocessing", "content": "The pipeline typically begins with data collection and preprocessing,\nwhere the raw data is gathered from various sources and prepared for model\ninput. Preprocessing steps may include normalization, data augmentation\nand transformation into formats that are compatible with the model, such as"}, {"title": "3.2.2. Model training and evaluation", "content": "The training pipeline of a deep learning model is a comprehensive pro-\ncess that transforms raw data into a well-trained model capable of making\naccurate predictions or classifications. During the training phase, the model\nprocesses batches of data iteratively, adjusting its internal parameters to\nminimize the error between its predictions and the actual outcomes. This\nis achieved through an optimization algorithm like stochastic gradient de-\nscent, which updates the model's parameters based on the gradients of the\nloss function. Throughout the training pipeline, performance metrics such\nas accuracy, loss, precision, recall, and F1-score are monitored to assess the\nmodel's progress. Visualization tools such as confusion matrices are often\nused to gain deeper insights into the model's performance. The model is\nthen ready for inference, where it can be used to make predictions on new,\nunseen data.\nAt this stage, we meticulously document all the paths to vital informa-\ntion related to both training and evaluation within the YAML file. This\nDREAMS comprehensive record encompasses not only paths to graphics but\nalso to other essential data, ensuring that every critical component is easily\naccessible and well-organized. This approach ensures efficient management\nand retrieval of information throughout the training and evaluation processes."}, {"title": "3.2.3. Model card generation", "content": "Once all the necessary information for generating the model card has been\ngathered, we proceed to invoke the generate_modelcard() function. This func-\ntion requires three input parameters: the path to the YAML configuration\nfile, which contains the essential details for the model card; the output path,\nwhere the generated model card will be saved; and the version number of the\nmodel card, which helps track its iterations and updates."}, {"title": "4. An illustrative example for EEG data analysis", "content": "To exemplify our approach, we utilize the training pipeline of a deep\nlearning model in conjunction with the Finer-grained Affective Computing\nEEG Dataset (FACED) dataset [11], which is compatible with TorchEEG 1.\nThe EEG data were collected from 123 subjects using 32 electrodes po-\nsitioned according to the international 10\u201320 system. During the recording\nsessions, participants viewed 28 different video clips designed to elicit various\nemotional responses. These video clips spanned nine distinct emotion cate-\ngories: amusement, inspiration, joy, tenderness, anger, fear, disgust, sadness,\nand neutral emotion.\nThe model described in this example classifies EEG data into three main\ncategories: negative (0), which includes emotions such as anger, disgust,\nfear, and sadness; neutral (1); and positive (2), which includes emotions like\namusement, inspiration, joy and tenderness.\nTo prepare the data for this classification, it is processed through online\ntransformation into tensors and a 2D format. Then, the labels are pro-\ncessed by adjusting their values accordingly. Following this preprocessing,\nthe dataset is divided into training and validation sets. Subsequently, Dat-\naLoaders are created for each set, facilitating the management and batching\nof data for the training and validation processes. Implementing these steps\ncan be as follows:"}, {"title": "5. Impact", "content": "In the context of EEG applications, DREAMS offers a smooth solution\nfor generating comprehensive model cards, providing detailed sections that\ninclude overviews of EEG analysis projects, dataset descriptions specific to\nEEG recordings, results with corresponding plots (such as EEG waveforms or\nbrain activity patterns), uncertainty estimations related to signal interpreta-\ntion, and relevant references. Additionally, users can customize the content\nof these model cards using a YAML configuration file, enabling adaptability\nto various EEG-based projects and models, ensuring flexibility in presenting\nkey insights and findings.\nDREAMS is entirely model-agnostic, deliberately engineered to be com-\npatible with any type of model. Its design ensures versatility, allowing it to\ngenerate model cards regardless of the underlying model architecture or type.\nThis flexibility is a fundamental aspect of DREAMS, enabling it to adapt\nto various machine learning and deep learning models, including but not\nlimited to convolutional neural networks (CNNs), recurrent neural networks\n(RNNs), transformer models and random forests. Whether it's a classifica-\ntion, regression or any other type of model, DREAMS generates comprehen-\nsive model cards, providing valuable insights and documentation irrespec-\ntive of the model's complexity or structure. The model-agnostic nature of\nDREAMS enables users to apply it across a diverse array of projects and ap-\nplications, ensuring its relevance and usefulness in various machine-learning\nendeavors.\nThis versatility allows DREAMS to find applicability across a wide range\nof domains where transparency and ethical use of AI are paramount. For\ninstance, within the healthcare sector [13, 14], DREAMS could be utilized to\ndocument the performance and limitations of deep learning models used for\nmedical analysis. Through the generation of detailed model cards, health-\ncare practitioners and regulatory bodies can gain insights into the model's\naccuracy, potential biases, and areas of uncertainty, facilitating informed\ndecision-making and ensuring patient safety.\nSimilarly, in the financial sector [15, 16], DREAMS can aid in document-\ning AI models used for credit risk assessment or fraud detection, providing\ntransparency into the model's decision-making process and potential biases.\nThis transparency is essential for ensuring fairness and accountability in al-\ngorithmic decision-making processes.\nFurthermore, in intelligent transportation systems [17] such as, autonomous\nvehicles, DREAMS can be employed to document the performance and safety\nconsiderations of deep learning models used for object detection and navi-\ngation, promoting trust and transparency among regulators and the general"}, {"title": "6. Conclusions and future perspectives", "content": "This paper introduces DREAMS, a Python library designed to simplify\nthe creation of comprehensive model cards for deep learning models.\nIn fact, DREAMS offers efficient generation of detailed model cards with\ncustomizable content through YAML configuration, covering project overviews,\ndataset descriptions, results with plots, uncertainty estimations, and refer-\nences. It also supports various plot types, enhancing clarity and comprehen-\nsion.\nAs such, DREAMS serves as a valuable tool for promoting transparency\nand ethical use of AI across various domains, facilitating informed decision-\nmaking, and fostering trust in AI systems. Whether in healthcare, finance,\nintelligent transportation systems, or any other domain where AI is utilized,\nDREAMS enables the documentation of model performance, usage, and lim-\nitations through comprehensive model cards. This documentation not only\nenhances understanding but also promotes accountability and ensures that\nAI systems are deployed responsibly and ethically."}]}