{"title": "Class-Imbalanced-Aware Adaptive Dataset Distillation for\nScalable Pretrained Model on Credit Scoring", "authors": ["Xia Li", "Hanghang Zheng", "Xiao Chen", "Hong Liu", "Mao Mao"], "abstract": "The advent of artificial intelligence has significantly enhanced credit scoring technologies. Despite the\nremarkable efficacy of advanced deep learning models, mainstream adoption continues to favor\ntree-structured models due to their robust predictive performance on tabular data. Although pretrained\nmodels have seen considerable development, their application within the financial realm predominantly\nrevolves around question-answering tasks and the use of such models for tabular-structured credit\nscoring datasets remains largely unexplored. Tabular-oriented large models, such as TabPFN, has made\nthe application of large models in credit scoring feasible, albeit can only processing with limited\nsample sizes. This paper provides a novel framework to combine tabular-tailored dataset distillation\ntechnique with the pretrained model, empowers the scalability for TabPFN. Furthermore, though class\nimbalance distribution is the common nature in financial datasets, its influence during dataset\ndistillation has not been explored. We thus integrate the imbalance-aware techniques during dataset\ndistillation, resulting in improved performance in financial datasets (e.g., a 2.5% enhancement in AUC).\nThis study presents a novel framework for scaling up the application of large pretrained models on\nfinancial tabular datasets and offers a comparative analysis of the influence of class imbalance on the\ndataset distillation process. We believe this approach can broaden the applications and downstream\ntasks of large models in the financial domain.", "sections": [{"title": "1. Introduction", "content": "The field of financial technology has experienced significant advancements due to the emergence of\ndeep learning and machine learning\u00b9. These computational paradigms have driven transformative\nchanges across various financial operations, ushering in a new era of data-driven decision-making\nprocesses. Notably, machine learning methodologies have been effectively applied to forecast stock\nprices and movement\u00b2, evaluate creditworthiness\u00b3, and combat money laundering activities4. Among\nthese applications, stock price forecasting predominantly relies on time series data, while credit scoring\nand anti-money laundering initiatives often utilize multimodal5,6 on tabular structured data 7,8. The\ndomain of credit scoring has garnered considerable attention as customer data repositories have become\nmore robust and comprehensive. Credit scoring, like credit rating, whose output is the probability of\ndefault (PD), is usually defined as the measurement of how a customer is going to default within one\nyear. Improving corporate credit scoring forecasts is crucial to prevent substantial financial losses.\nHowever, There are several main challenges in improving the credit scoring prediction capacity.\nFirstly, datasets with high quality and adequate quantity are usually hard to acquire, due to business\nprivacy or the high cost of information collection10. Secondly, the distribution of the data profiles\nvaried across different industries, regions and the nature of the borrowers. For instance, it has been seen\nthat the default rate of mortgage portfolios is 0.5%11,12, while the Small and Medium Enterprises'\ndefault rate is as high as 5%-10% in UK and Italy 11,13. Segmenting these industries/regions further\nreduces the sample size for each sector which might be too small for any model fitting process14, also\nseen the considerations for sovereign bond issuers. Thus, enhancing the reliability of corporate credit\nscoring, particularly in scenarios with limited sample sizes and uneven sample distributions but\nhigh-profit risk, emerges as a critical challenge.\nThe rapid advancement of pretrained large models has garnered considerable attention, particularly due\nto their remarkable achievements and commercial applications in dialogue systems15, recommendation\nsystems16 and other domains. The financial sector has witnessed notable progress through the\nintegration of these models17. For instance, pretrained models such as GPT-418, BERT19,20,\nROBERTa21,22, and specialized variants like FinGPT23 and BloombergGPT24 have demonstrated their\npotential to revolutionize various facets of the Fintech industry, including risk assessment25 and"}, {"title": "2. Literature review", "content": "Traditional credit scoring protocols, such as survival analysis32 and statistical methods have long been\nthe cornerstone for assessing creditworthiness. Machine learning methods, including\nLightGBM(LightGBM)33,34, XGBoost(XGB)35, Random Forest36,37 along with logistic regression38 and\ntheir derivatives39,40, have emerged as dominant players in credit scoring. Logistic Regression is\npreferred due to its good explainability, tree-based LightGBM/XGB is known for its superior\nperformance for large scaled tabular dataset\u2074\u00b9. These methods enhance predictive power by adeptly\ncapturing non-linear patterns and interactions among features. However, these models may exhibit\nsuboptimal performance in certain small-sample tasks. Therefore, exploring approaches like pretraining\nlearning10,39 and data augmentation could be a promising solution. These techniques aim to leverage\nlimited data effectively, addressing the unique challenges posed by small sample sizes in credit risk\nassessment.\nThe advent of large models, particularly large language models (LLMs), has opened new avenues for\nfinancial applications, which have demonstrated remarkable capabilities in understanding and\ngenerating natural language, making them valuable for tasks such as sentiment analysis42,43, risk\nassessment, and automated customer service44 in finance. These models can be fine-tuned on\ndomain-specific data or trained from scratch to cater to the unique requirements of financial tasks,\noffering a level of flexibility and adaptability that traditional ML methods cannot match. There have\nbeen some studies that began to explore the potential and paradigm of new technologies for processing\ntabular data45,46. TabPFN26, a transformer-based large model designed specifically for tabular data, has\nbeen trained on extensive synthetic datasets to learn causal relationships in the tabular representations26,\nenabling fast and accurate predictions on new tasks with a single forward pass and no need for\nadditional training. The limitation is that its maximum inference sample size is limited.\nGiven the wide range of financial datasets, dataset distillation(DD) emerges as a preferred technique in\nthis context. It aims to condense large datasets into smaller, more manageable coresets without"}, {"title": "3. Experiments", "content": "The methodology is visually represented in the workflow depicted in Figure 2. Initially, each dataset\nundergoes a rigorous data cleaning process, wherein samples with missing features are deleted.\nSubsequently, the dataset distillation process is carried out, employing a variety of objective functions\nsuch as Mean Squared Error (MSE), Cross-Entropy (CE), re-balancing, Focal Loss (FL), and\nAsymmetric Sigmoid Adjusted Function (ASIG). The distilled datasets are curated to encompass a\nrange of 10 to 900 samples. Thereafter, a suite of machine learning methodologies is trained on both\nthe original and distilled datasets to evaluate performance improvements and ensure robustness."}, {"title": "4. Discussion", "content": "Class imbalance can lead to biased synthetic datasets that overrepresent the majority class and\nunderrepresent the minority class. This bias can skew the model's learning process, resulting in a\nclassifier that performs well on the majority class but poorly on the minority class. We first discussed\nthe distillation effects of the training datasets distilled from various objective functions. We then\napplied several classifiers for evaluating the effects of class imbalance on distillation process."}, {"title": "4.1 Dataset distilled from different objective functions", "content": "The objective functions of the Knowledge-Infused pretraining methods were meticulously tuned,\nincorporating the baseline objective function (MSE), general used classification method (CE) and the\nclass imbalanced specific protocol (re-balancing CE, FL and ASIG). Visualizing the distribution\npatterns of the generated distilled datasets, Figure 4 and Figure 5 showcase the data distribution after"}, {"title": "5. Conclusion", "content": "In this study, we emphasize two essential problems related to the use of artificial intelligence in credit\nscoring. Firstly, we introduce a novel framework to address financial datasets addressing the\nscalability limitation and privacy consideration by employing modified dataset distillation\ntechnique and pretrained large model. By implementing a tabular-tailored dataset distillation process,\nwe effectively scale up the limited scope of pretrained large models for financial datasets. Secondly, we\nfocus on the class imbalance problem and delve into multiple imbalance-aware objective\nfunctions during the distillation process to enhance classifiers' performance. Our results show that\nintroducing imbalance-aware factors during dataset distillation leads to the creation of distilled datasets\nthat better represent the original patterns of highly imbalanced distributions. Notably, datasets distilled\nusing the ASIG and Focal Loss functions consistently provide an enhanced representation of the data\ncompared to other objective functions. This advantage is attributed to the introduction of asymmetric\ncharacteristics during distillation. Future research will focus on gaining a deeper understanding of the\nrepresentation of the distillation process on class-imbalancedd datasets, with the goal of continuing to\nimprove model performance in highly biased credit scoring tasks."}]}