{"title": "Quantum-inspired Interpretable Deep Learning Architecture for Text Sentiment Analysis", "authors": ["Bingyu Li", "Da Zhang", "Zhiyuan Zhao", "Junyu Gao", "Yuan Yuan"], "abstract": "Text has become the predominant form of communication on social media, embedding a wealth of emotional nuances. Consequently, the extraction of emotional information from text is of paramount importance. Despite previous research making some progress, existing text sentiment analysis models still face challenges in integrating diverse semantic information and lack interpretability. To address these issues, we propose a quantum-inspired deep learning architecture that combines fundamental principles of quantum mechanics (QM principles) with deep learning models for text sentiment analysis. Specifically, we analyze the commonalities between text representation and QM principles to design a quantum-inspired text representation method and further develop a quantum-inspired text embedding layer. Additionally, we design a feature extraction layer based on long short-term memory (LSTM) networks and self-attention mechanisms (SAMs). Finally, we calculate the text density matrix using the quantum complex numbers principle and apply 2D-convolution neural networks (CNNs) for feature condensation and dimensionality reduction. Through a series of visualization, comparative, and ablation experiments, we demonstrate that our model not only shows significant advantages in accuracy and efficiency compared to previous related models but also achieves a certain level of interpretability by integrating QM principles. Our code is available at QISA.", "sections": [{"title": "Introduction", "content": "The volume of textual information generated online is continuously increasing (Xu et al. 2019). Analyzing the sentiment of this textual information is essential for understanding social opinion trends and overall product evaluations (Niu, Zhong, and Yu 2021). Consequently, sentiment analysis technology is becoming increasingly vital in fields such as social media analysis, market sentiment tracking, and public opinion monitoring (Kim 2014). Text sentiment analysis, a method for extracting emotional tendencies from texts, has garnered widespread attention (Wang et al. 2017). Mainstream text sentiment analysis models follow three primary routes. The first approach is based on sentiment lexicons, which rely on manually annotated word sentiment lexicons (Rice and Zorn 2021). Although sentiment lexicons have made significant progress, the precision of this method depends entirely on the coverage and accuracy of the sentiment lexicon, making it overly reliant on its construction. To enhance model generalizability, classic machine learning methods have been explored. However, these methods often ignore the contextual semantic dependencies of the text (Wang et al. 2017; Muthusankar et al. 2023). To address this issue, many researchers have conducted in-depth studies using deep learning models, achieving considerable success with models based on CNNs, Recurrent Neural Networks (RNNs), and SAMs. These models have demonstrated excellent performance and have been widely applied.\nDespite the contributions of previous models to improving analysis accuracy, two notable shortcomings remain: 1) prior models fail to integrate multiple semantic information, and 2) the models lack interpretability. Text sentiment analysis tasks need to consider not only words' semantic dependency but also sentiment-bearing words' dependency (Hu and Liu 2004; Sachin et al. 2020). Therefore, a comprehensive analysis of various semantic features is necessary. However, existing methods struggle to integrate multiple features for comprehensive analysis (Shobana and Murali 2021; Huang et al. 2021). Additionally, the underlying mechanisms of these models remain difficult to interpret, and the design motivations lack deep physical underpinnings.\nIn this paper, we first analyze the commonalities between text representation and QM principles from the perspective of combining text features with QM principles (Fig.1). In light of this analysis, we propose a text sentiment analysis architecture, dubbed Quantum-inspired Interpretable Text Sentiment Analysis Architecture (QITSA). Drawing on the commonalities between text representation and QM principles, we develop a quantum-inspired text representation method and a corresponding word embedding layer. Unlike previous forms that embedded only one type of information (Fig.1(b)), This layer leverages complex numbers to integrate various semantic information, achieving adaptive fusion and embedding multiple types of information (Fig.1 (c)). To further extract textual features, we designed a text feature extraction layer based on LSTM networks and SAMs, which model the text's contextual and global dependencies, thereby enabling deeper feature extraction. We achieve the final results by representing text vectors as real and imaginary parts in two separate processing tracks, calculating density matrices for each, and using two-dimensional convolutional neural networks (2D-CNNs) for final feature fusion. To validate the effectiveness of the proposed model, we conducted tests on multiple text sentiment analysis datasets, demonstrating that our framework outperforms related algorithms in the field. To further assess the effectiveness of modal fusion and the contribution of the proposed modules, we conducted visualization experiments and ablation studies, exploring the impact of various factors on model performance.\nIn summary, our contributions can be summarized as follows:\n\u2022 We analyze the commonalities between fundamental QM principles and text representation, proposing a quantum-inspired deep learning architecture that enhances model accuracy and interpretability.\n\u2022 A quantum-inspired text sentiment word embedding layer is designed, integrating semantic information and sentiment polarity information using quantum complex principles to guide sentiment analysis tasks.\n\u2022 We develop a quantum-inspired feature extraction layer based on the quantum complex-number principle and deep learning model for feature concentration and classification.\n\u2022 Extensive visualization of text vectors and numerical comparison analysis verify the model's effectiveness."}, {"title": "Related Work", "content": "Text Sentiment Analysis\nText Sentiment analysis has been studied using various methods, including lexicons-based and deep-learning techniques. Lexicons-based methods which rely on predefined lexicons were among the earliest to be developed. Based on this approach, some studies have applied it to domain-specific semantic analysis (Rice and Zorn 2021) and customer reviews summary, while others have extended it to different languages (Xu et al. 2019). However, the lexicons-based method faces challenges in scalability and in effectively addressing semantic dependencies and ambiguities in text. To tackle these issues, more deep-learning methods have been thoroughly investigated. CNNs, known for their ability to extract both local and global features, have been applied to text sentiment analysis (Kim 2014; Wang et al. 2017). To capture longer semantic dependencies, RNNs have been developed, with Long Short-Term Memory (LSTM) networks showing excellent performance in establishing long-term semantic dependencies (Muthusankar et al. 2023; Shobana and Murali 2021). However, RNN-based methods often suffer from gradient vanishing problems, making it difficult to model dependencies in long text sequences. To address this issue, attention mechanisms have been introduced to model the global dependencies of the text (Vaswani et al. 2017; Huang et al. 2021).\nDespite the significant effectiveness of the aforementioned methods, they still struggle to integrate multiple sentiment information, and the models lack interpretability. In this article, we design QITSA based on the QM principles to integrate various types of semantic information and enhance the interpretability of deep learning models."}, {"title": "Quantum-Inspired Deep Learning Model", "content": "The QM principles are increasingly applied to natural language processing (NLP) tasks due to their commonalities with text representation. Initially, pure quantum computing algorithms were extended to text sentiment analysis (Zhang et al. 2018; Li, Wang, and Melucci 2019). Subsequently, researchers developed Lambeq (Kartsaklis et al. 2021), an advanced Python library designed to facilitate the implementation of quantum NLP models. While pure quantum computing algorithms enhance model interpretability, they face limitations in processing large-scale textual data. Therefore, researchers have proposed quantum-inspired deep learning models by combining the interpretability of quantum mechanics with the ability of deep learning to handle large-scale data and benefit from hardware acceleration (Liu, Zhang, and Song 2023; Santur 2019). Leveraging these characteristics, some studies have introduced quantum-inspired complex word embeddings (Li et al. 2018), which represent words in a complex vector space, capturing intricate semantic relationships more effectively than traditional embeddings. In the field of text sentiment analysis, researchers have designed two end-to-end quantum-inspired deep neural networks for text classification, illustrating how the QM principle can be integrated into neural network architectures to improve performance (Shi et al. 2021). Additionally, other researchers have been inspired by these commonalities to design more fine-grained quantum-inspired text sentiment analysis models (Wang and Hou 2023).\nIn this paper, we explore the enhancement of multimodal sentiment semantic information embedding and fusion through the QM principles. Additionally, we have designed an end-to-end quantum-inspired deep learning architecture that combines the interpretability of quantum computing with the superior feature extraction capabilities of deep learning."}, {"title": "Method", "content": "Preliminary\nQuantum Superposition. The quantum superposition principle is one of the foundations of quantum mechanics, describing the superposition of states that a microscopic particle can be in. According to the superposition principle, a quantum system can exist in a linear combination of multiple states until it is observed or measured.\nAn individual quantum is typically represented as:\n$\\left| \\psi \\right> = \\sum C_i\\left| i \\right> ,$ (1)\nwhere $c_i$ represents the probability amplitudes for the quantum to be in state $|i\\rangle$ when measured.\nGenerally, a quantum physical system often contains multiple particles. We refer to this system as a mixed state, while a single-quantum system is referred to as a pure state. To describe a quantum system composed of multiple particles, the superposition state of a can be described as follows:\n$\\left| \\psi \\right> = \\sum r_je^{i\\beta_j}\\left| \\phi_j \\right> ,$ (2)\nwhere i is the imaginary unit, $r_j$ and $\\beta_j$ represent the amplitude and phase of the j-th orthogonal superposition state, respectively, and $|\\phi_j\\rangle$ represents the orthonormal basis state in the Hilbert space.\nQuantum Density Matrix. The quantum density matrix is a mathematical tool used to describe the state of a quantum system. A quantum physical system containing multiple particles can be represented by a density matrix, which is expressed as:\n$\\rho = \\sum p_i\\left| \\psi_i \\right>\\left< \\psi_i \\right| ,$ (3)\nwhere $p_i$ represents the probability value, satisfying $\\sum_i p_i = 1, \\left| \\psi_i \\right>$ is the superposition state of a single quantum in Eq. 2, and $\\left< \\psi_i \\right|$ is the transpose of $\\left| \\psi_i \\right>$. $\\left| \\psi_i \\right>$ is a pure state vector with probability $p_i$. The density matrix $\\rho$ is symmetric, semi-positive definite, and has a trace of 1, i.e., $Tr(\\rho) = 1$. According to the Gleason theorem, there is a bijective correspondence between quantum probability measures P and density matrices $\\rho$, denoted as $P \\leftrightarrow \\rho$.\nIn text representation, we consider a sentence as a multibody system, with each word corresponding to a component in the system. By using the quantum density matrix, we can more accurately describe the relationships and interactions between words in a sentence.\nQuantum-Inspired Language Representation\nIn sentiment analysis tasks, accurately understanding the meaning of words is crucial. Quantum mechanics offers a unique perspective by viewing the multiple meanings of a word as a quantum superposition. We represent the semantic state of a sentence using a density matrix, capturing word associations and interactions.\nThe multiple meanings of a word can be viewed as a quantum superposition (Fig.1(a) and (b)), with the word's embedding vector $|v_j\\rangle$ mapped to a Hilbert space, forming basic events used to construct a density matrix $p_j = |v_j\\rangle\\langle v_j|$. Multiple words in a sentence form a quantum mixed system, with the sentence's density matrix being the weighted sum of individual word density matrices:\n$\\rho = \\sum w_jp_j$ (4)\nwhere $w_j$ is the weight of word i in the sentence.\nAs demonstrated in Fig. 1(c), the emotional polarity scores of words are regarded as phase information, while semantic information serves as amplitude. By calculating these, we obtain a quantum superposition text representation that integrates both semantic and emotional information:\n$v_j = SemInfo(v_j) \\cdot e^{i EmoPhase(v_j)} = r_j \\cdot e^{i \\cdot \\beta_j},$ (5)\nwhere, $SemInfo(\\cdot)$ and $EmoPhase(\\cdot)$ obtain the semantic and sentiment information of $\\left| v_i \\right>$. This method can capture complex interactions between words, providing a more comprehensive representation of sentence semantics and emotions, and potentially improving model performance and accuracy."}, {"title": "Quantum-Inspired Text Embedding Layer", "content": "Using the quantum exponential representation, where a complex number has an amplitude and a phase, we treat word embedding information as the amplitude and sentiment information as the phase, as shown in Fig.2 (a). This fusion into a complex-valued word vector is expressed as Eq. 5.\nFor semantic information, we extract the frequency of each word in the text to obtain its one-hot vector representation which is input into the BERT model (Devlin et al. 2018) to obtain the word embedding vector matrix. For sentiment information, we extract the polarity scores of multiple words from large lexicons (such as WordNet) (Rice and Zorn 2021; Husnain et al. 2021; Alrashidi and Joy 2020).\nDirectly handling the complex representation of words on classical computers may pose computational complexity challenges. Therefore, we adopt Euler's formula, $Ae^{i\\beta} = A(cos + i sin \\beta)$, to convert the complex exponential form into its real and imaginary components representation. Specifically, for a given word embedding vector, we compute its real part $Re(\\left| v_j \\right>)$ and imaginary part $Im(\\left| v_j \\right>)$. This transformation simplifies the originally complex exponential operations into more tractable real and imaginary parts.\n$y = \\sum Re(\\left| v_j \\right>) + iIm(\\left| v_j \\right>)$ (6)\nj\nSubsequently, we map the word representation vectors to quantum events and calculate the quantum density matrix as follows.\n$\\rho = \\sum\\left| v_j \\right>\\left< v_j \\right|$\nj\n$= \\sum r_j (cos(\\beta_j) + i sin(\\beta_j))) (r_j (cos(\\beta_j) + i sin(\\beta_j))|$\nj\n$= [r_jr_j (|cos(\\beta_j))\\langle cos(\\beta_j)| - | sin(\\beta_j))\\langle sin(\\beta_j)|)\n$\\quad +i[r_jr_j (| sin(\\beta_j))\\langle cos(\\beta_j)| + | cos(\\beta_j))\\langle sin(\\beta_j)|)]$\n$\\quad = [r_jr_j (Re(v_j)Re(v_j) - Im(v_j)Im(v_j))] + i[r_jr_j (Re(v_j)Im(v_j) + Im(v_j)Re(v_j))]$\n$= \\sum r_jr_j (p_j^{real} + ip_j^{imag})$, (7)\nWe leverage the values of the real and imaginary parts to perform the corresponding operations and obtain the density matrix, the calculation process is shown in Fig.2 (b). Although the final complex density matrix is the sum of the real and imaginary parts, extracting information from the real and imaginary parts separately and then fusing them can capture more information. The practical implementation is:\n$\\rho = \\sum w_i (\\rho_i^{real} + \\rho_i^{imag}),$ (8)\nwhere $\\rho^{real}$ and $\\rho^{imag}$ are the density matrices of the real and imaginary parts, and $w_i$ are learnable parameter values."}, {"title": "Quantum-Inspired Feature Extraction Layer for Text Sentiment Analysis", "content": "Based on the aforementioned architecture, we design an end-to-end quantum-inspired deep learning model for text sentiment analysis (Fig. 3(a)).\nFeature Extraction and Input. As shown in Fig.3(a), before applying quantum-inspired word embedding to the word vector matrix, we utilize an LSTM-attention mechanism to model the dependencies within the text (Shobana and Murali 2021).\nFor any given semantic and sentiment information of a word $v_j)$, we establish the context dependency:\n$\\begin{array}{l}r_j = LSTM(SemInfo(|v_j))),\\\\\\beta_j = LSTM(EmoPhase(|v_j)))\\\\\\\\\\end{array}$ (9)\nWe use LSTM to extract the semantic information of amplitude and the sentiment information of phase, thus avoiding the problem of syntactic confusion caused by random combinations of semantics by other non-sequential models, ensuring that \"I like cat\" does not become \"Like I cat\" or \"Cat like I,\" etc.\nIn addition to LSTM, we introduce the self-attention mechanism to extract the key semantic information of amplitude r. The self-attention mechanism focuses on the keywords in the sentence, which is crucial for judging the sentiment polarity of the sentence. The calculation of the self-attention mechanism is as follows:\n$E = rW_qW,$ (10)\n$F(r) = softmax(\\frac{E}{\\sqrt d}),$\n$O(r) = F(r)Wv,$\nwhere $W_q, W_k, W_v$ are trainable weight matrices, d is the dimension of the input word embedding vectors, and X is the input word embedding vector matrix.\nQuantum-inspired word embedding layer. After obtaining the semantic and sentiment information from LSTM and the self-attention mechanism. we calculate the words density matrix representation using Equ. (7) and fuse them into a sentence text embedding matrix representation. This fusion enhances the model's ability to understand and process the sentiment information in NLP using the QM principle.\nFor sentence density matrix fusion, we propose a Q-Attention mechanism. This mechanism calculates the attention scores between two density matrices and weights their contributions in the fusion process, thereby enhancing the model's attention to keywords in the text. The calculation of attention scores is as follows:\n$F_Q(p_i, p_j) = softmax( \\sum_{k=1}^n T_r(p_i \\odot p_j))$, (11)\nwhere, $\\odot$ is Hadamard product, $p_i$ and $p_j$ are the density matrices of two words, Tr is to take the diagonal element.\nThe output matrix is the weighted sum of the density matrices, with the weights as the attention scores:\n$\\rho_1 = \\sum F_Q (p_i, p_j) \\cdot \\rho,$ (12)\ni,j\nwhere $\\rho_1$ is the output density matrix, $\\rho$ is the density matrices of a sentence, and $F_Q(p_i, p_j)$ is the attention score between two words of the sentence.\nFeature Aggregation and Output. In the final step in Fig.3(c), we use CNNs to further extract features from the density matrix representation of the text (Behera et al. 2021). Because the density matrix serves as a two-dimensional representation of text, we use 2-D CNNs to extract information. The calculation of the convolutional layer is essentially a special fully connected layer:\n$\\rho_2 = Conv2D(\\rho_1),$ (13)\nAfter the CNNs obtain the feature map, we use max-pooling to generate the vector representations for imaginary and real parts:\n$f = MaxPooling(\\rho_2).$ (14)\nFinally, we concatenate these vectors to form the final text embedding representation, which is then passed through a fully connected layer to obtain the final result.\n$Output = FC(Concatenate(f^{img}, f^{real})).$ (15)\nThe overall architecture of the end-to-end deep learning model for text sentiment analysis is illustrated in Fig.3."}, {"title": "Experimental Result", "content": "Experimental Details\nGiven that all experimental parameters are consistent. The experiments were conducted on a single NVIDIA 3090 GPU. All experiments used AdamW as the optimizer, running for 51 epochs. We set the batch size to 16 and the learning rate to 0.001. The binary cross-entropy loss function was chosen as the loss function. The trained GloVe word vector model (Pennington, Socher, and Manning 2014) is selected as the pre-trained model, with an output dimension of 100, used as the embedding data for the amplitude part of the embedding layer."}, {"title": "Dataset", "content": "Five different binary classification benchmark test sets (Shi et al. 2021) are chosen to evaluate the performance of the proposed model. Table 1 provides specific information about the test sets, including the dataset splits and labels, for comparison with baseline models. The details of the datasets can be found in Appendix A."}, {"title": "Evaluation Metric", "content": "For Evaluation, accuracy, recall, and F1 score are chosen as metrics to evaluate the model's generalization ability. They are calculated as follows:\n$Accuracy = \\frac{TP+TN}{TP+TN+FP + FN},$ (16)\n$Recall = \\frac{TP}{TP + FN},$ (17)\n$F1 Score = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall},$ (18)\nwhere TP (True Positive) is the number of correctly predicted positive cases, TN (True Negative) is the number of correctly predicted negative cases, FP (False Positive) is the number of incorrectly predicted positive cases, and FN (False Negative) is the number of incorrectly predicted negative cases."}, {"title": "Experimental Results", "content": "Results on different datasets. The comparative analysis of different models (table 2) on test accuracy across five benchmark datasets reveals that our proposed model consistently outperforms others, achieving the highest accuracy in most datasets. Specifically, our model achieves an accuracy of 80.30 on MR, surpassing the second-best model, CE-Mix, by 0.5. On SST, our model scores 84.76, which is slightly lower than CICWE-QNN's 85.0 but still significantly higher than most other models. In the SUBJ dataset, our model achieves 92.96, closely following CICWE-QNN's 93.2. For the CR dataset, our model attains 85.16, outperforming the next best model, CICWE-QNN, by 1.86. On the MPQA dataset, our model achieves 87.50, which is the highest among all models and surpasses CICWE-QNN's 87.2 by 0.3. Our model secures the top final rank. This comprehensive evaluation underscores the superior efficacy of our model in text classification, providing valuable insights for future research in this domain.\nRecall on different datasets. As shown in table 3, our model demonstrates consistent performance across five benchmark test sets (MR, SST, SUBJ, CR, MPQA) with F1 Scores ranging from 72.77 to 91.04 and Recall Rates from 81.24 to 93.26. Its high precision and recall, particularly on the SUBJ dataset (F1 Score: 91.04, Recall: 93.26), highlight its robustness and reliability in diverse text classification tasks."}, {"title": "Visualization", "content": "To better compare the effectiveness of quantum-inspired text embedding layers that integrate various semantic information for subsequent classification, we input different information combinations as shown in Fig. 4.\nAfter modeling with LSTM and attention mechanisms, the analysis results are displayed in Fig. 5. The figures show the model's capability to establish global dependency and long-context dependency.\nFurthermore, After processing the two input combinations using the quantum-inspired word embedding method, we visualized the real and imaginary parts of the information (Fig.6). Comparing Example 1 and Example 2 reveals that the sentiment integration method, guided by sentiment polarity scores, enables the model to focus on words with significant sentiment polarity changes."}, {"title": "Ablation Experiment", "content": "This section conducted a series of extended experiments on the proposed model. By comparing the experimental results, we deeply analyzed the specific contributions of each module to the model performance.\nImpact of Different Embedding Data on Test Accuracy. To verify the enhancement effect of sentiment embedding on sentiment polarity analysis, we conducted six experiments to study the impact of different embedding data on sentiment polarity analysis (Table 4). The data included sentiment polarity score vectors (Sentiment), trainabd word embedding vectors (Word_Embedding), and BERT word embedding representations (BERT), combined in various ways. Integrating BERT word embeddings with sentiment polarity information consistently improved performance across multiple datasets. For the MR dataset, this combination achieved the highest test accuracy of 80.3%, demonstrating its effectiveness. Similar enhancements were observed on the CR, SUBJ, MPQA, and SST datasets, indicating that sentiment polarity information complements BERT embeddings well and adapts to various dataset characteristics, ultimately enhancing sentiment analysis model performance.\nEffectiveness Analysis of Q-Attention Mechanism. Q-Attention demonstrated effectiveness in sentiment text analysis across various datasets. It notably improved accuracy on MR, SUBJ, and MPQA datasets, showcasing its ability to capture sentiment information, especially with keywords. However, its performance on the SST dataset was comparatively lower, suggesting the need to choose the appropriate attention mechanism based on dataset characteristics.\nAnalysis of the Effects of Different Feature Concentration and Extraction Modules. As shown in table 5, there are four different types of modules, including two-dimensional convolutional max-pooling operation (CNN-Maxing Pooling), max-pooling operation (Maxing Pooling), diagonal data acquisition operation with two-dimensional convolution (CNN-Getting Diagonal Data), and diagonal data acquisition operation (Getting Diagonal Data).\nThe CNN-Diagonal model ranked first with an average score of 1.52, demonstrating superior text classification accuracy by effectively capturing local features and long-distance dependencies. The CNN-Max Pooling model followed closely, ranking second with an average of 1.89. Models using only Max Pooling or Diagonal pooling ranked lower, with averages of 3.37 and 2.05, respectively, though the Diagonal model outperformed Max Pooling in some tasks. These results highlight the critical role of CNNs and the benefits of diagonal pooling in text classification."}, {"title": "Conclusion", "content": "This study explores theoretical and empirical research in text sentiment analysis using quantum-inspired deep learning models. Firstly, a Quantum-Inspired Text Information Representation method is proposed, which efficiently captures semantic features of text using quantum superposition principles and density matrices. Words and sentences are viewed as quantum particles and mixed quantum systems, enhancing the model's interpretability. Secondly, a feature extraction and classification layer that combines long short-term memory with self-attention mechanisms to enhance the model's sentiment judgment capability is designed. It deeply integrates semantic and sentiment information through complex word embedding layers and text density matrix representations. Future research directions include enriching datasets, optimizing the model, expanding the types of embedding data, extending application areas, and enhancing the interpretability of deep learning models, with the expectation of advancing the field."}, {"title": "Appendices", "content": "In the supplementary material, we first add some description of the chosen dataset. After that some results of the visualizations mentioned in the main text are shown, followed by more graphs of the vector visualization results. After that, we show iterative plots of the evaluation metrics during the training process.\nA. Description of the Chosen Dataset\nWe describe the categories and content of the selected datasets in detail. The datasets fall into two categories: those used to evaluate the model's ability to predict the sentiment of sentences, including the Movie Review dataset (MR), the Stanford Sentiment Treebank dataset (SST), the Customer Review dataset (CR), and the Opinion polarity dataset (MPQA); and those used to classify subjective and objective sentences, such as the Subjectivity dataset (SUBJ).\nMovie Review Dataset (MR). The Movie Review dataset (MR) is commonly used for evaluating sentiment analysis models. This dataset consists of movie reviews that have been labeled with their respective sentiment, either positive or negative. The goal is to predict the sentiment of each review based on its textual content.\nStanford Sentiment Treebank (SST). The Stanford Sentiment Treebank (SST) is a more granular sentiment analysis dataset developed by the Stanford NLP Group. It includes a large number of movie reviews, each labeled not only with an overall sentiment score but also with sentiment annotations at the phrase level. This fine-grained labeling allows models to learn sentiment patterns at different levels of granularity, from single words to entire sentences.\nCustomer Review Dataset (CR). The Customer Review dataset (CR) focuses on sentiment analysis in the context of product reviews. It comprises customer reviews from a variety of product categories, each labeled with a sentiment score indicating whether the review is positive or negative. This dataset helps in assessing the performance of sentiment analysis models in understanding and interpreting opinions expressed by customers in their reviews, which is crucial for applications like recommendation systems and market analysis.\nOpinion Polarity Dataset (MPQA). The Opinion Polarity Dataset (MPQA) is designed to evaluate sentiment analysis and opinion mining models. It contains a collection of news articles annotated for opinions and other private states such as beliefs, speculations, and sentiments. The dataset is annotated at multiple levels, including the polarity (positive, negative, or neutral) of expressions, making it useful for fine-grained sentiment analysis tasks.\nSubjectivity Dataset (SUBJ). The Subjectivity Dataset (SUBJ) is used to classify sentences as either subjective or objective. Subjective sentences express personal opinions, emotions, or judgments, while objective sentences present factual information. This dataset contains labeled sentences from various sources, allowing models to learn the characteristics that distinguish subjective content from objective statements. The ability to differentiate between these two types of sentences is important for applications like information retrieval and text summarization, where the nature of the content needs to be accurately identified.\nB. Visualization of Sentiment Information Extracted by Wordnet\nWe supplemented our analysis with a visualization of the sentiment information extracted using SentiWordNet to verify the validity of the input data, as shown in Fig. 8. The vertical axis represents each word in the sentence, while the horizontal axis indicates the sentiment polarity, which is directly entered as the content of the Phase item without further processing.\nC. Visualization of Text Semantic Vectors\nWe conducted further visualization experiments on the aforementioned four datasets, and the experimental results are shown in Fig. 9-Fig. 12. We continue to showcase the visualization of text information vectors in three stages: different input combinations, vectors after feature extraction, and vectors after the quantum-inspired word embedding layer.\nIn the figures, the horizontal axis represents different inputs of the same sentence, and the vertical axis illustrates various results of vector-matrix visualization. Notably, vectors enriched with sentiment information tend to focus more on words exhibiting significant sentiment polarity changes.\nD. Training Curve\nThis section presents train convergence plots of the proposed model on CR, MPQA, MR, SST, and SUBJ datasets, depicted in Fig. 13.\nTraining Loss. The training loss on 5 datasets, shows a gradual decrease with increasing training epochs, stabilizing in later stages, indicating effective error reduction by the model. However, fluctuations in training loss during mid-training phases, particularly noticeable in CR and MPQA datasets, suggest challenges in handling complex samples.\nTraining and test accuracies. Training and test accuracies show steady improvement and stabilization during training, highlighting the model's learning capability. However, test accuracies generally lag behind training, with noticeable fluctuations in datasets like CR and MR, indicating potential overfitting.\nF1 scores. F1 scores demonstrate rapid improvement and sustained high performance on training data across all datasets, reflecting balanced precision and recall. Lower test F1 scores and fluctuations in datasets like SUBJ and MPQA suggest challenges in generalization.\nRecall. Training recall rates improve significantly across all datasets, stabilizing in later stages, demonstrating the model's strength in identifying positive instances. Test recall rates show slower improvement, with fluctuations in datasets like MPQA and MR, indicating varying generalization capabilities."}]}