{"title": "Quantum-inspired Interpretable Deep Learning Architecture for Text Sentiment Analysis", "authors": ["Bingyu Li", "Da Zhang", "Zhiyuan Zhao", "Junyu Gao", "Yuan Yuan"], "abstract": "Text has become the predominant form of communication on social media, embedding a wealth of emotional nuances. Consequently, the extraction of emotional information from text is of paramount importance. Despite previous research making some progress, existing text sentiment analysis models still face challenges in integrating diverse semantic information and lack interpretability. To address these issues, we propose a quantum-inspired deep learning architecture that combines fundamental principles of quantum mechanics (QM principles) with deep learning models for text sentiment analysis. Specifically, we analyze the commonalities between text representation and QM principles to design a quantum-inspired text representation method and further develop a quantum-inspired text embedding layer. Additionally, we design a feature extraction layer based on long short-term memory (LSTM) networks and self-attention mechanisms (SAMs). Finally, we calculate the text density matrix using the quantum complex numbers principle and apply 2D-convolution neural networks (CNNs) for feature condensation and dimensionality reduction. Through a series of visualization, comparative, and ablation experiments, we demonstrate that our model not only shows significant advantages in accuracy and efficiency compared to previous related models but also achieves a certain level of interpretability by integrating QM principles. Our code is available at QISA.", "sections": [{"title": "Introduction", "content": "The volume of textual information generated online is continuously increasing (Xu et al. 2019). Analyzing the sentiment of this textual information is essential for understanding social opinion trends and overall product evaluations (Niu, Zhong, and Yu 2021). Consequently, sentiment analysis technology is becoming increasingly vital in fields such as social media analysis, market sentiment tracking, and public opinion monitoring (Kim 2014). Text sentiment analysis, a method for extracting emotional tendencies from texts, has garnered widespread attention (Wang et al. 2017). Mainstream text sentiment analysis models follow three primary routes. The first approach is based on sentiment"}, {"title": "Related Work", "content": "Text Sentiment Analysis\nText Sentiment analysis has been studied using various methods, including lexicons-based and deep-learning techniques. Lexicons-based methods which rely on predefined lexicons were among the earliest to be developed. Based on this approach, some studies have applied it to domain-specific semantic analysis (Rice and Zorn 2021) and customer reviews summary, while others have extended it to different languages (Xu et al. 2019). However, the lexicons-based method faces challenges in scalability and in effectively addressing semantic dependencies and ambiguities in text. To tackle these issues, more deep-learning methods have been thoroughly investigated. CNNs, known for their ability to extract both local and global features, have been applied to text sentiment analysis (Kim 2014; Wang et al. 2017). To capture longer semantic dependencies, RNNs have been developed, with Long Short-Term Memory (LSTM) networks showing excellent performance in establishing long-term semantic dependencies (Muthusankar et al. 2023; Shobana and Murali 2021). However, RNN-based methods often suffer from gradient vanishing problems, making it difficult to model dependencies in long text sequences. To address this issue, attention mechanisms have been introduced to model the global dependencies of the text (Vaswani et al. 2017; Huang et al. 2021).\nDespite the significant effectiveness of the aforementioned methods, they still struggle to integrate multiple sentiment information, and the models lack interpretability. In this article, we design QITSA based on the QM principles to integrate various types of semantic information and enhance the interpretability of deep learning models."}, {"title": "Quantum-Inspired Deep Learning Model", "content": "The QM principles are increasingly applied to natural language processing (NLP) tasks due to their commonalities with text representation. Initially, pure quantum computing algorithms were extended to text sentiment analysis (Zhang et al. 2018; Li, Wang, and Melucci 2019). Subsequently, researchers developed Lambeq (Kartsaklis et al. 2021), an advanced Python library designed to facilitate the implementation of quantum NLP models. While pure quantum computing algorithms enhance model interpretability, they face limitations in processing large-scale textual data. Therefore, researchers have proposed quantum-inspired deep learning models by combining the interpretability of quantum mechanics with the ability of deep learning to handle large-scale data and benefit from hardware acceleration (Liu, Zhang, and Song 2023; Santur 2019). Leveraging these characteristics, some studies have introduced quantum-inspired complex word embeddings (Li et al. 2018), which represent words in a complex vector space, capturing intricate semantic relationships more effectively than traditional embeddings. In the field of text sentiment analysis, researchers have designed two end-to-end quantum-inspired deep neural networks for text classification, illustrating how the QM principle can be integrated into neural network architectures to improve performance (Shi et al. 2021). Additionally, other researchers have been inspired by these commonalities to design more fine-grained quantum-inspired text sentiment analysis models (Wang and Hou 2023).\nIn this paper, we explore the enhancement of multimodal sentiment semantic information embedding and fusion through the QM principles. Additionally, we have designed an end-to-end quantum-inspired deep learning architecture that combines the interpretability of quantum computing with the superior feature extraction capabilities of deep learning."}, {"title": "Method", "content": "Preliminary\nQuantum Superposition. The quantum superposition principle is one of the foundations of quantum mechanics, describing the superposition of states that a microscopic particle can be in. According to the superposition principle, a quantum system can exist in a linear combination of multiple states until it is observed or measured.\nAn individual quantum is typically represented as:\n$\\left| \\psi \\right\\rangle = \\sum C_i\\left| i \\right\\rangle$,\nwhere $c_i$ represents the probability amplitudes for the quantum to be in state $ \\left| i \\right\\rangle $ when measured.\nGenerally, a quantum physical system often contains multiple particles. We refer to this system as a mixed state, while a single-quantum system is referred to as a pure state. To describe a quantum system composed of multiple particles, the superposition state of a can be described as follows:\n$\\left| \\psi \\right\\rangle = \\sum r_j e^{i \\beta_j} \\left| \\psi_j \\right\\rangle$,\nwhere $i$ is the imaginary unit, $r_j$ and $ \\beta_j$ represent the amplitude and phase of the j-th orthogonal superposition state, respectively, and $ \\left| \\psi_j \\right\\rangle $ represents the orthonormal basis state in the Hilbert space.\nQuantum Density Matrix. The quantum density matrix is a mathematical tool used to describe the state of a quantum system. A quantum physical system containing multiple particles can be represented by a density matrix, which is expressed as:\n$ \\rho = \\sum p_i \\left| \\psi_i \\right\\rangle \\left\\langle \\psi_i \\right|$,\nwhere $p_i$ represents the probability value, satisfying $ \\sum_i p_i = 1$,$ \\left| \\psi_i \\right\\rangle$ is the superposition state of a single quantum in Eq. 2, and $ \\left\\langle \\psi_i \\right|$ is the transpose of $ \\left| \\psi_i \\right\\rangle $. $ \\left| \\psi_i \\right\\rangle$ is a pure state vector with probability $p_i$. The density matrix $ \\rho $ is symmetric, semi-positive definite, and has a trace of 1, i.e., $Tr(\\rho) = 1$. According to the Gleason theorem, there is a bijective correspondence between quantum probability measures P and density matrices $ \\rho$, denoted as $ P \\leftrightarrow \\rho$.\nIn text representation, we consider a sentence as a multi-body system, with each word corresponding to a component in the system. By using the quantum density matrix, we can more accurately describe the relationships and interactions between words in a sentence."}, {"title": "Quantum-Inspired Language Representation", "content": "In sentiment analysis tasks, accurately understanding the meaning of words is crucial. Quantum mechanics offers a unique perspective by viewing the multiple meanings of a word as a quantum superposition. We represent the semantic state of a sentence using a density matrix, capturing word associations and interactions.\nThe multiple meanings of a word can be viewed as a quantum superposition (Fig.1(a) and (b)), with the word's embedding vector $v_j$ mapped to a Hilbert space, forming basic"}, {"title": "Quantum-Inspired Text Embedding Layer", "content": "Using the quantum exponential representation, where a complex number has an amplitude and a phase, we treat word embedding information as the amplitude and sentiment information as the phase, as shown in Fig.2 (a). This fusion into a complex-valued word vector is expressed as Eq. 5.\nFor semantic information, we extract the frequency of each word in the text to obtain its one-hot vector representation which is input into the BERT model (Devlin et al. 2018) to obtain the word embedding vector matrix. For sentiment information, we extract the polarity scores of multiple words from large lexicons (such as WordNet) (Rice and Zorn 2021; Husnain et al. 2021; Alrashidi and Joy 2020).\nDirectly handling the complex representation of words on classical computers may pose computational complexity"}, {"title": "Quantum-Inspired Feature Extraction Layer for Text Sentiment Analysis", "content": "Based on the aforementioned architecture, we design an end-to-end quantum-inspired deep learning model for text sentiment analysis (Fig. 3(a)).\nFeature Extraction and Input. As shown in Fig.3(a), before applying quantum-inspired word embedding to the word vector matrix, we utilize an LSTM-attention mechanism to model the dependencies within the text (Shobana and Murali 2021).\nFor any given semantic and sentiment information of a word $v_j$, we establish the context dependency:\n$r_j = LSTM(SemInfo(|v_j|))$\n$ \\beta_j = LSTM(EmoPhase(|v_j|))$\nWe use LSTM to extract the semantic information of amplitude and the sentiment information of phase, thus avoiding the problem of syntactic confusion caused by random combinations of semantics by other non-sequential models, ensuring that \"I like cat\" does not become \"Like I cat\" or \"Cat like I,\" etc.\nIn addition to LSTM, we introduce the self-attention mechanism to extract the key semantic information of amplitude $r$. The self-attention mechanism focuses on the keywords in the sentence, which is crucial for judging the sentiment polarity of the sentence. The calculation of the self-attention mechanism is as follows:\n$E = rW_q W_k^T$,\n$F(r) = softmax(\\frac{E}{\\sqrt d})$,      \n$O(r) = F(r)W_v$,\nwhere $W_q$, $W_k$, $W_v$ are trainable weight matrices, $d$ is the dimension of the input word embedding vectors, and X is the input word embedding vector matrix.\nQuantum-inspired word embedding layer. After obtaining the semantic and sentiment information from LSTM and the self-attention mechanism. we calculate the words density matrix representation using Equ. (7) and fuse them into a sentence text embedding matrix representation. This fusion enhances the model's ability to understand and process the sentiment information in NLP using the QM principle."}, {"title": "Experimental Result", "content": "Experimental Details\nGiven that all experimental parameters are consistent. The experiments were conducted on a single NVIDIA 3090 GPU. All experiments used AdamW as the optimizer, running for 51 epochs. We set the batch size to 16 and the learning rate to 0.001. The binary cross-entropy loss function was chosen as the loss function. The trained GloVe word vector model (Pennington, Socher, and Manning 2014) is selected as the pre-trained model, with an output dimension of 100, used as the embedding data for the amplitude part of the embedding layer."}, {"title": "Conclusion", "content": "This study explores theoretical and empirical research in text sentiment analysis using quantum-inspired deep learning models. Firstly, a Quantum-Inspired Text Information Representation method is proposed, which efficiently captures semantic features of text using quantum superposition principles and density matrices. Words and sentences are viewed as quantum particles and mixed quantum systems, enhancing the model's interpretability. Secondly, a feature extraction and classification layer that combines long short-term memory with self-attention mechanisms to enhance the model's sentiment judgment capability is designed. It deeply integrates semantic and sentiment information through complex word embedding layers and text density matrix representations. Future research directions include enriching datasets, optimizing the model, expanding the types of embedding data, extending application areas, and enhancing the interpretability of deep learning models, with the expectation of advancing the field."}, {"title": "Appendices", "content": "In the supplementary material, we first add some description of the chosen dataset. After that some results of the visualizations mentioned in the main text are shown, followed by more graphs of the vector visualization results. After that, we show iterative plots of the evaluation metrics during the training process.\nA. Description of the Chosen Dataset\nWe describe the categories and content of the selected datasets in detail. The datasets fall into two categories: those used to evaluate the model's ability to predict the sentiment of sentences, including the Movie Review dataset (MR), the Stanford Sentiment Treebank dataset (SST), the Customer Review dataset (CR), and the Opinion polarity dataset (MPQA); and those used to classify subjective and objective sentences, such as the Subjectivity dataset (SUBJ).\nMovie Review Dataset (MR). The Movie Review dataset (MR) is commonly used for evaluating sentiment analysis models. This dataset consists of movie reviews that have been labeled with their respective sentiment, either positive or negative. The goal is to predict the sentiment of each review based on its textual content.\nStanford Sentiment Treebank (SST). The Stanford Sentiment Treebank (SST) is a more granular sentiment analysis dataset developed by the Stanford NLP Group. It includes a large number of movie reviews, each labeled not only with an overall sentiment score but also with sentiment annotations at the phrase level. This fine-grained labeling allows models to learn sentiment patterns at different levels of granularity, from single words to entire sentences.\nCustomer Review Dataset (CR). The Customer Review dataset (CR) focuses on sentiment analysis in the context of product reviews. It comprises customer reviews from a variety of product categories, each labeled with a sentiment score indicating whether the review is positive or negative. This dataset helps in assessing the performance of sentiment analysis models in understanding and interpreting opinions expressed by customers in their reviews, which is crucial for applications like recommendation systems and market analysis.\nOpinion Polarity Dataset (MPQA). The Opinion Polarity Dataset (MPQA) is designed to evaluate sentiment analysis and opinion mining models. It contains a collection of news articles annotated for opinions and other private states such as beliefs, speculations, and sentiments. The dataset is annotated at multiple levels, including the polarity (positive, negative, or neutral) of expressions, making it useful for fine-grained sentiment analysis tasks.\nSubjectivity Dataset (SUBJ). The Subjectivity Dataset (SUBJ) is used to classify sentences as either subjective or objective. Subjective sentences express personal opinions, emotions, or judgments, while objective sentences present factual information. This dataset contains labeled sentences from various sources, allowing models to learn the characteristics that distinguish subjective content from objective statements. The ability to differentiate between these two types of sentences is important for applications like information retrieval and text summarization, where the nature of the content needs to be accurately identified."}, {"title": "B. Visualization of Sentiment Information Extracted by Wordnet", "content": "We supplemented our analysis with a visualization of the sentiment information extracted using SentiWordNet to verify the validity of the input data, as shown in Fig. 8. The vertical axis represents each word in the sentence, while the horizontal axis indicates the sentiment polarity, which is directly entered as the content of the Phase item without further processing."}, {"title": "C. Visualization of Text Semantic Vectors", "content": "We conducted further visualization experiments on the aforementioned four datasets, and the experimental results are shown in Fig. 9-Fig. 12. We continue to showcase the visualization of text information vectors in three stages: different input combinations, vectors after feature extraction, and vectors after the quantum-inspired word embedding layer.\nIn the figures, the horizontal axis represents different inputs of the same sentence, and the vertical axis illustrates various results of vector-matrix visualization. Notably, vectors enriched with sentiment information tend to focus more on words exhibiting significant sentiment polarity changes."}, {"title": "D. Training Curve", "content": "This section presents train convergence plots of the proposed model on CR, MPQA, MR, SST, and SUBJ datasets, depicted in Fig. 13.\nTraining Loss. The training loss on 5 datasets, shows a gradual decrease with increasing training epochs, stabilizing in later stages, indicating effective error reduction by the model. However, fluctuations in training loss during mid-training phases, particularly noticeable in CR and MPQA datasets, suggest challenges in handling complex samples.\nTraining and test accuracies. Training and test accuracies show steady improvement and stabilization during training, highlighting the model's learning capability. However, test accuracies generally lag behind training, with noticeable fluctuations in datasets like CR and MR, indicating potential overfitting.\nF1 scores. F1 scores demonstrate rapid improvement and sustained high performance on training data across all datasets, reflecting balanced precision and recall. Lower test F1 scores and fluctuations in datasets like SUBJ and MPQA suggest challenges in generalization.\nRecall. Training recall rates improve significantly across all datasets, stabilizing in later stages, demonstrating the model's strength in identifying positive instances. Test recall rates show slower improvement, with fluctuations in datasets like MPQA and MR, indicating varying generalization capabilities."}]}