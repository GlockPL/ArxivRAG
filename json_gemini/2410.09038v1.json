{"title": "SIMPLESTRAT: DIVERSIFYING LANGUAGE MODEL GENERATION WITH STRATIFICATION", "authors": ["Justin Wong", "Yury Orlovskiy", "Michael Luo", "Sanjit A. Seshia", "Joseph E. Gonzalez"], "abstract": "Generating diverse responses from large language models (LLMs) is crucial for applications such as planning/search and synthetic data generation, where diversity provides distinct answers across generations. Prior approaches rely on increasing temperature to increase diversity. However, contrary to popular belief, we show not only does this approach produce lower quality individual generations as temperature increases, but it depends on model's next-token probabilities being similar to the true distribution of answers. We propose SimpleStrat, an alternative approach that uses the language model itself to partition the space into strata. At inference, a random stratum is selected and a sample drawn from within the strata. To measure diversity, we introduce CoverageQA, a dataset of underspecified questions with multiple equally plausible answers, and assess diversity by measuring KL Divergence between the output distribution and uniform distribution over valid ground truth answers. As computing probability per response/solution for proprietary models is infeasible, we measure recall on ground truth solutions. Our evaluation show using SimpleStrat achieves higher recall by 0.05 compared to GPT-40 and 0.36 average reduction in KL Divergence compared to Llama 3.", "sections": [{"title": "1 INTRODUCTION.", "content": "Large language models (LLMs) are routinely resampled in order to get a wide set of plausible generations. Three key settings where this is important are: 1) improving downstream accuracy with planning or search for agentic tasks (i.e. Tree-of-thought (Yao et al., 2024), AgentQ (Putta et al., 2024)), 2) estimating prediction uncertainty (Aichberger et al., 2024), and 3) generating diverse datasets for post-training (Dubey et al., 2024) and fine-tuning (Dai et al., 2023). All these use cases rely on the model generating multiple plausible generations for the same prompt when multiple answers exists."}, {"title": "2 METHOD", "content": ""}, {"title": "3.1 WORKFLOW OVERVIEW", "content": "As illustrated in 2, SimpleStrat consist of three stages, 1) auto-stratification, 2) heuristic estimation, and 3) probabilistic prompting. For each unique user prompt, the outputs of the first two stages can be cached to avoid recomputing feed-forwards."}, {"title": "3.2 AUTO-STRATIFICATION", "content": "For a given user request, $r_{user}$, we call S, the space of valid solutions. In many settings, the space of potential solutions, S may be naturally partitioned based on geography, parity, or demographics. The partition function, $P : S \\rightarrow L$, assigns any solution s from S to a partition label l; in L the set of partition labels. Partition functions are most useful if they're as balanced as possible. A balanced partition function minimizes imbalance$(P, L) = max_{i \\in L} (|\\{s | P(s) = l\\}|) \u2013 min_{l\\in L} (|\\{s | P(s) = l\\}|)$.\nThe goal of auto-stratification is to search for a set of partition functions $P = \\{P_1, P_2, ..., P_n\\}$, that are balanced. Traditionally, in settings where there are oft-overlooked or a large or infinite number of valid solutions, stratified sampling can ensure our limited budget of samples covers the space of solutions evenly.\nBased on this insight, we prompt the language model to identify promising dimensions of diversity. Concretely, the language model proposes good clarifying questions that will potentially eliminate half of the potential solutions based on the user request. These clarifying questions tend to align with semantically significant differences. In the running example, when asked, \"Name a US State,\" the states can be partitioned based on East or West of the Mississippi River. See App. C for full prompt."}, {"title": "3.3 HEURISTIC ESTIMATION", "content": "As previously observed in Zou et al. (2022); Yan et al. (2023); Halawi et al. (2024), LLMs can used in forecasting to estimate well-calibrated probabilities of events that have not yet occured. For forecasting, the model success benefits substantially from having updated news through web search. Although our unnecessary for the offline benchmarks we consider, this may be helpful for accurate estimation depending on the application. However, as our goal is diversity, we stand to benefit even from coarse-grain approximate proportions. We employ a similar reasoning template as Halawi et al. (2024) to estimate the proportion of valid solutions lie within each strata.\nIn heuristic estimation, we look to estimate the joint distribution for each stratum, $l = [l_1, l_2, l_3, ...]$.\nFormally, we define the weighted-stratification as $W = (P, \\rho)$, where $p(1) = Pr_{s\\sim s}[P_1(s) = l_{1,j}, P_2(s) = l_{2,j}, P_3(s) = l_{1,j}, ...]$ for P identified in auto-stratification. To improve scalability, we assume the partition functions are independent and multiply the marginal probabilities to get the joint probabilities associated with each stratum.\n$p(l_1, l_2, ..., l_m) = \\prod P_i(l_i)  (1)$\nWe ask the LLM for each $l_j$, to estimate the marginal proportion of solutions this holds for. As this may not add up to 1, we normalize the estimates to form a proper probability distribution. For simplicity, we focus in this work on settings where all solution in the solution space is equally like. As noted in Sec. 3.2, we encourage the LLM to propose balanced partitions. However, heuristic estimation allow us to support imbalanced partitions by reweighing the sampling to favor stratum with more potential solutions. More details on prompting in App. D. In Fig. 2, the LLM determines the joint probabilities across two stratas, the Mississippi River and the Missouri Compromise Line."}, {"title": "3.4 PROBABILISTIC PROMPTING.", "content": "Post heuristic estimation, a set of statum is sampled from the joint probability distribution in Eqn. 1. This implicitly forms a probabilistic prompt, which specifies a distribution over concrete language model prompts. After a prompt is sampled, the LLM is then used to sample from within the stratum. Back to Fig. 2, East and South are sampled from the Mississippi and Missouri strata respectively, augmenting the final prompt with diverse specifications.\nFormally, call $l$ a stratum defined by choices of $l_{i,j}$ for each $P_i$ across all i. Call Prompt a function that maps the stratum, $\\bar{l}$ to a concrete prompt, $Prompt(\\bar{l})$. Intuitively, the probabilities of the prompt distribution is defined by $Pr[Prompt(\\bar{l}] = p(\\bar{l})$. We can then compute the probability of a solution\n$Pr[s] = \\sum_i Pr[Prompt(l)] * Pr[s | Prompt(l)] = \\sum_i \\rho(l) * Pr[s | Prompt(l)]  (2)$\nThe specific language model's next-token probabilities define $Pr[s | Prompt(l)]$.\nAs the probabilistic prompt is human readable form, the user can inspect the properties and the proportions and modify it to adjust for unwanted bias or remove unwanted factors. For instance, when proposing English baby names, we may want the model to propose male vs female names equally often, even though there are more female than male baby names 2. This interpretability and controllability is a major advantage of SimpleStrat in practice."}, {"title": "4 COVERAGEQA DATASET", "content": ""}, {"title": "4.1 OVERVIEW", "content": "We wish to evaluate generation diversity in settings where 1) user requests have more than one distinct correct answer, 2) and answers are equally likely, and 3) answers do not require hidden or implicit"}, {"title": "4.2 COVERAGEQA-WIKIPEDIA APPROACH", "content": "To generate CoverageQA-Wikipedia, we leverage the Wikidata knowledge base which contains all relational mappings between entities and properties in Wikipedia. Our generation process starts with an initial item-property pairing and a constraint on the number of correct answers. We then perform a recursive search through Wikidata to find all sets of item-property constraints and their corresponding answers that meet our criteria. These constraints are subsequently transformed into natural language questions using GPT-4.\nConsider an initial pairing of the Wikidata item \"country\" with the property \"instance of\". We might specify that we want between 20 and 40 valid answers. Our search would then yield a set of all constraints from the knowledge base that fit the initial conditions, such as \"instance of country, located in Europe, uses Euro as currency\". GPT-4 would convert this into a natural language question like \"Name a country located in Europe that uses the Euro as its currency.\"\nThis approach has several advantages: 1) it allows us to create a diverse and extensive benchmark that can be easily updated with weekly updates to Wikidata, 2) it allows us to arbitrarily specify the size of the solution space as constraints can be added or removed to form; and 3) this process in principle can curate a large dataset with little manual effort or supervision. In the initial instantiation of CoverageQA dataset, we publish 105 questions across 4 domains, each corresponding to a different initial seed item-property pair. To ensure quality, we employ both automatic filters (e.g., excluding certain generic properties) and manual curation to remove redundant or unsuitable questions. This dataset can be substantially expanded as we only used 4 domains, but we leave this for future work. For a details on the dataset breakdown and details on the question generation process, please refer to Appendix A.1."}, {"title": "5 RESULTS", "content": ""}, {"title": "5.1 EVALUATION SETUP", "content": "For the primary empirical evaluation of SimpleStrat, we use gpt4o-2024-08-06. To obtain true answer distributions and perform divergence from uniform analysis, we use open-source models from the Llama 3 and 3.1 families, specifically the 8B and 70B variants. The inference of these models were run on 8 A100-80GB GPUs. Additionally, we leverage claude-3.5-sonnet-20240620 for baseline evaluations on two datasets: CoverageQA Curated and CoverageQA Wikipedia. For CoverageQA, we used WikiData version from 07-03-2024."}, {"title": "5.2 MEASURING DIVERSITY", "content": "We consider two measures of diversity. For models with accessible softmax next-token probabilities, we compute the probability of each solution in the solution space. We then define distributional diversity as the distributional distance between the response distribution implied by the sampling process and logits and the ground-truth distribution derived from these probabilities. For CoverageQA, the ground-truth distribution is uniform over valid solutions and zero elsewhere. In general, it can be more complex.\nIn setting where we do not have access to the next-token distribution, we evaluate diversity by resampling responses to CoverageQA 100 times per question. This allows us to empirically observe the diversity in the form of coverage. We call this coverage diversity. To measure coverage, we report the recall (unique valid solutions/total unique valid solutions) on the reference solutions. Note"}, {"title": "5.3 QUALITATIVE EXAMPLE", "content": "Consider the question \"Name one Great Lake in the United States.\" as shown in Fig. 3. We see that temperature scaling with GPT-40 results in a strong preference/bias for Lake Erie. This is certainly a correct continuation and under the language modeling objective should be incentivized. Increasing the temperature helps sample the next most likely candidate solutions more often. However, even when increasing the temperature past 1 there is still low coverage over the solutions space. Specifically, Huron is only seen once out of 100 samples at 1.5 temperature, and Lake Ontario is never observed. This is undesirable if the data is used to proposing candidate plans, generating test cases, or generating training data. Not only is there insufficient coverage over all possible solutions, but the model consistently has a strong preference for Lake Erie. This undesired biases in generations may lead to problems in downstream use cases.\nIn Fig. 3, we observe a much more uniform distribution over valid solutions when using SimpleStrat. Notably, we observe full coverage over all 5 Great Lakes. At lower temperatures, there is still a preference of a single lake over the others, in this case Lake Huron. However, this is less pronounced at higher temperatures and is a significant improvement over GPT-40 without SimpleStrat."}, {"title": "5.4 COVERAGE DIVERSITY ON PROPRIETARY MODELS", "content": "We first assess coverage diversity, specifically, the model's ability to recall all the valid solutions upon resampling. This measure is clearly impacted by temperature as temperature zero or greedy decoding of LLMs leads to a single deterministic result. We compare the coverage diversity (recall) of SimpleStrat, GPT-40, and Claude 3.5 Sonnet as a function of temperature. We sweep over temperatures from 0.15 to 1.5. Although not shown in the evaluation, note that SimpleStrat has the advantage of providing diversity even when sampled at temperature zero. SimpleStrat with GPT-40 leads to an improvement to recall across all temperatures as shown in Fig.4. On the CoverageQA-Curated, we see a consistent 0.2 increase in recall over the same base model, GPT-40. On CoverageQA-Wikipedia, we see as much as 0.05 increase in recall\nOur quantitative results are consistent with the Great Lakes example in Fig. 3. Scaling temperature alone does not lead to as much coverage diversity as combining with SimpleStrat. The recall importantly does not come at the expense of quality as measure by precision as shown in App. B."}, {"title": "5.5 DISTRIBUTIONAL DIVERSITY WITH LLAMA 3", "content": "We use the Llama 3 model family to analyze answer distributional diversity in CoverageQA. Open-source models let us calculate exact expected distributions by examining logits of all valid continua-tions for a prompt. This is not possible with GPT-40 and Claude 3.5 Sonnet, where reliably estimating the true probabilities would require extensive sampling. Our approach efficiently determines true expected distributions of valid answers for any input, improving analysis accuracy, and overcoming the resource constraints of high count sampling.\nFor our baseline, we prompt the models and directly compute $Pr[s|Prompt(l)]$ for each solution, s. This is simply the product of the individual next-token probabilities. For SimpleStrat, the probability involves the next-token probability conditioned on the prompt weighted by the probability the prompt is selected. Concretely, the probability an answer is sampled by SimpleStrat can be computed based on Eqn.2. The next-token probability based response distribution $Pr[s|Prompt(l)]$ computed just as the baseline, and we do a sum weighted by the joint probabilities assigned in heuristic estimation. We assign remaining probability density to an \"Invalid\" category to form a proper distribution. The probabilistic formulation allows us to easily compute the response distribution of SimpleStrat."}, {"title": "6 LIMITATIONS", "content": "Although SimpleStrat shows improvement empirically, it is sensitive to the model selecting good meaningful axis in auto-stratification and correct joint probabilities in heuristic estimation. As work on LLMs for forecasting improve, we expect LLMs to produce better estimates especially when given access to external data and data analysis tools. For our prototype, we restricted to studying the model's intrinsic capabilities. Further, the model may have biases concerning race and gender that may be reflected also in the auto-stratification and heuristic estimation. As such, it is recommended the probabilistic prompt distribution of SimpleStrat is carefully inspected for critical applications. Finally, CoverageQA is a dataset of short responses. Although this make evaluation more practical, we believe SimpleStrat will be especially impactful in settings that require low temperature especially multi-step reasoning as identified by Zhang et al. (2024)."}, {"title": "7 CONCLUSION", "content": "In this paper, we propose SimpleStrat which offers an innovative alternative by leveraging the LLM itself to partition the solution space into distinct strata. This process we call auto-stratification. At inference time, a random stratum is selected, and a sample is drawn from within that stratum. This approach achieves better diversity without sacrificing quality as increasing temperature would.\nTo quantitatively measure diversity, we introduced the CoverageQA dataset, which consists of underspecified questions with multiple equally valid answers. We measure diversity with two metrics: for open-source models, we measure distributional difference with KL Divergence and for proprietary models, we measure coverage over the set of ground-truth solutions. Our rigorous evaluation on both proprietary and open-source LLMs demonstrated that SimpleStrat achieves significantly higher recall and produces answer distributions closer to uniform compared to traditional temperature-based sampling methods."}, {"title": "A APPENDIX", "content": ""}, {"title": "A.1 COVERAGEQA DATASET", "content": ""}, {"title": "Generation Procedure", "content": "To generate the questions, we manually came up with initial item and property pairings to run the recursive search. We constrain the recursive search to yield between 20-40 possible answers to keep the questions within common and relevant categories. We found that with fewer than 20 answers, the questions become too obvious, while with more than 40, they tend to get too specific and stray from general knowledge. The recursive search first finds all items that satisfy the initial conditions, then iteratively adds properties in steps until either the maximum depth (number of constraints) is reached or the number of answers falls outside the desired range. We blacklist properties that are detrimental to high-quality question generation, such as an item's presence in a specific database, numeric properties like population, and properties that introduce high ambiguity. We then manually evaluate the generated conditions and answers to ensure they meet our criteria. With an appropriate initial condition, one query can generate hundreds of valid constraints that can later be turned into questions. Finally, we use GPT-4 to convert these constraints into natural language."}, {"title": "B F1 SCORES", "content": "We show F1 scores in Fig. 7 to emphasize that the precision does not change substantially as a result of our method. Precision is calculated over the set of 100 attempts how many are in the ground truth. Recall as mentioned is calculated as how many unique ground truth solutions were observed in the 100 attempts."}, {"title": "C AUTO-STRATIFICATION PROMPT", "content": "We provide the full prompt in Tbl. 3. To improve prompt adherence, we provide one in context example in the form of one simulated round of multi-turn conversation, i.e. we provide an example set of reasoning following the template."}, {"title": "D HEURISTIC ESTIMATION PROMPT", "content": "We first take each partition function from auto-stratification and estimate a starting probability with the prompt in Table 4. This prompt is heavily inspired by Halawi et al. (2024). We then collect all the proportions and pass it through a final Heuristic Estimation prompt to remove redundant properties (negations for instance) and give the model a chance to correct any incorrect probabilities. See Table 5 for full prompt. Finally, we ask the model to select at most 3.\nNote that for performance reasons, we estimate the marginal probabilities and make a simplifying assumption of independence. This is not strictly true if one partition function is the negation of the other. This leads potential stratum assigned positive probability but actually the stratum has no solutions. Otherwise, there would be $2^{\\text{# of Partition Functions}}$ strata to estimate probabilities of. Further, LLMs seem less reliable when asked to estimate fine-grained probabilities, whereas most marginal probabilities are by design close to 0.5.\nFormally, if $P = \\neg Q$, the the stratum $P \\land Q$ has zero probability, even though we assumed it to be $Pr[P] * Pr[Q]$. We handle approximation error in estimating the true prompt distribution by"}, {"title": "E ADDITIONAL PLOTS: DISTRIBUTIONAL ANALYSIS WITH LLAMA", "content": "We provide additional examples in Fig 9 and scatter plots for Llama 3 in Fig 8"}]}