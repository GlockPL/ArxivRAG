{"title": "ROUTERRETRIEVER: Exploring the Benefits of Routing over Multiple Expert Embedding Models", "authors": ["Hyunji Lee", "Luca Soldaini", "Arman Cohan", "Minjoon Seok", "Kyle Lo"], "abstract": "Information retrieval methods often rely on a single embedding model trained on large, general-domain datasets like MSMARCO. While this approach can produce a retriever with reasonable overall performance, models trained on domain-specific data often yield better results within their respective domains. While prior work in information retrieval has tackled this through multi-task training, the topic of combining multiple domain-specific expert retrievers remains unexplored, despite its popularity in language model generation. In this work, we introduce ROUTERRETRIEVER, a retrieval model that leverages multiple domain-specific experts along with a routing mechanism to select the most appropriate expert for each query. It is lightweight and allows easy addition or removal of experts without additional training. Evaluation on the BEIR benchmark demonstrates that ROUTERRETRIEVER outperforms both MSMARCO-trained (+2.1 absolute nDCG@10) and multi-task trained (+3.2) models. This is achieved by employing our routing mechanism, which surpasses other routing techniques (+1.8 on average) commonly used in language modeling. Furthermore, the benefit generalizes well to other datasets, even in the absence of a specific expert on the dataset. To our knowledge, ROUTERRETRIEVER is the first work to demonstrate the advantages of using multiple domain-specific expert embedding models with effective routing over a single, general-purpose embedding model in retrieval tasks\u00b9.", "sections": [{"title": "Introduction", "content": "While a single embedding model trained on large-scale general-domain datasets like MSMARCO (Campos et al. 2016) often performs well, research shows that models trained on domain-specific datasets, even if smaller, can achieve superior results within those domains (Izacard et al. 2021; Bonifacio et al. 2022). Moreover, finetuning on MS-MARCO after pretraining with contrastive learning can sometimes degrade performance on specific datasets (Wang et al. 2023; Lee et al. 2023). To improve embedding models for domain-specific datasets, previous studies have explored approaches such as data construction (Wang et al. 2021; Ma et al. 2020) and domain adaptation methods (Xin et al. 2021; Fang et al. 2024). However, less attention has been paid to leveraging multiple expert embedding models and routing among them to select the most suitable one during inference.\nIn this work, we introduce ROUTERRETRIEVER, a retrieval model that leverages multiple domain-specific experts with a routing mechanism to select the most suitable expert for each instance. For each domain, we train gates (experts), and during inference, the model determines the most relevant expert by computing the average similarity between the query and a set of pilot embeddings representing each expert, selecting the expert with the highest similarity score. ROUTERRETRIEVER is lightweight, as it only requires the training of parameter-efficient LoRA module (Hu et al. 2021) for each expert, resulting in a minimal increase in parameters. Additionally, ROUTERRETRIEVER offers significant flexibility: unlike a single model that requires retraining when domains are added or removed, ROUTERRETRIEVER simply adds or removes experts without the need for further training.\nEvaluation on the BEIR benchmark (Thakur et al. 2021) with various combinations of experts highlights the benefits of having multiple expert embedding models with a routing mechanism compared to using a single embedding model. When keeping the total number of training datasets constant, ROUTERRETRIEVER consisted of only domain-specific experts without an MSMARCO expert outperforms both a model trained on the same dataset in a multi-task manner and a model trained with MSMARCO. Also, adding domain-specific experts tends to improve performance even when an expert trained on a large-scale general-domain dataset like MSMARCO is already present, suggesting that, despite the capabilities of a general-domain experts, domain-specific experts provide additional benefits, underscoring their importance. Moreover, ROUTERRETRIEVER consistently improves performance as new experts are added, whereas multi-task training tends to show performance degradation when a certain number of domains are included. This indicates the advantage of having separate experts for each domain and using a routing mechanism to select among them. Notably, the benefits of ROUTERRETRIEVER generalize not only to datasets that have corresponding experts but also to additional datasets without specific experts.\nWe further explore the factors behind these performance benefits. First, ROUTERRETRIEVER consistently shows im-"}, {"title": "Related Works", "content": "Domain Specific Retriever There exists substantial research on retrieval models that aim to improve performance on domain-specific tasks. One approach focuses on dataset augmentation. As domain-specific training datasets are often unavailable and can be costly to construct, researchers have developed methods that either train models in an unsupervised manner (Lee, Chang, and Toutanova 2019; Gao, Yao, and Chen 2021; Gao and Callan 2021) or fine-tune models on pseudo-queries generated for domain-specific datasets (Bonifacio et al. 2022; Ma et al. 2020; Wang et al. 2021). Another approach is developing domain-specific embeddings. A common approach is training in a multi-task manner over domain-specific datasets (Lin et al. 2023; Wang et al. 2021). Recent works have aimed to improve domain-specific retrievers by developing instruction-following retrieval models (Asai et al. 2022; Weller et al. 2024; Oh et al. 2024; Su et al. 2022; Wang et al. 2023); instruction contains such domain knowledge. Another example is Fang et al. (2024) which trains a soft token for domain-specific knowledge. While these methods also aim to extract good representative embeddings for the input text, these methods rely on a single embedding model and produce domain-specific embeddings by additionally including domain-specific knowledge (e.g., appended as instructions) to the input. ROUTERRETRIEVER differs from these prior methods by allowing for the employment of multiple embedding models where rather than providing the domain knowledge to the input, added to the model as parametric knowledge to produce the domain representative embeddings.\nRouting Techniques Various works have focused on developing domain-specific experts and routing mechanisms to improve general performance in generation tasks. One approach simultaneously trains experts (gates) and the routing mechanism (Sukhbaatar et al. 2024; Muqeeth et al. 2024). Another line of work includes post-hoc techniques"}, {"title": "Router Retriever", "content": "In this section, we introduce ROUTERRETRIEVER, a retrieval model composed of a base retrieval model and multiple domain-specific experts (gates). As shown in Figure 1, for a given input query, \u2460 the most appropriate embedding is selected using a routing mechanism. Then, \u2461 the query embedding is generated by passing the query through the selected gate alongside the base encoder.\nIn the offline time, we train the experts (gates) with"}, {"title": "Experts (Gates)", "content": "For each domain $D_i$, where $i = 1, . . ., T$ and $T$ is the total number of domains, we train a separate expert (gate) $g_i$ using the corresponding domain dataset. After the training step, we have a total of $T$ different gates, $G = {g_1,g_2,..., g_T}$, with each gate $g_i$ specialized for a specific domain."}, {"title": "Pilot Embedding Library", "content": "Given a domain-specific training dataset $D_i = {x_1,...,X_k}$ where $x_j$ is an instance in $D_i$, we perform inference using all gates $G$ to iden-\ntify which gate provides the most suitable representative embedding for each instance (line 4-7 in Alg. 1). For each instance $x_j$, we select $g_{max}$, the gate that demonstrates the highest performance, defined as $g_{max}(x_i) = arg max_{g_j \\in G} Performance(g_j,x_i)$. This process produces pairs $(x_j, g_{max})$ for all instances in the dataset $D_i$.\nNext, we group these pairs by $g_{max}$, constructing $T$ groups, one for each domain. Then for each group, we perform k-means clustering with cluster size 1 to get the pilot embedding (line 8-19 in Alg. 1). In specific, with the constructed pairs $(x_j,g_{max})$, we group them by the ones that have the same $g_{max}$, $Group_m$, which contains list of instances $x_j$ with same gate as the max gate. This results in T groups, one for each domain (m = 1,\u2026\u2026,T). If the $Group_m$ is not empty, we first extract all embeddings for instances in the group with the base encoder (BaseModel). We then apply k-means clustering ($cmk-means()$) to these embeddings with a cluster size of one. The centroid of this cluster $c_m$ is taken as the pilot embedding for the domain. This results in one pilot embedding per group, yielding a maximum of T pilot embeddings for the training dataset $D_i$. Each of these embeddings is associated with a different gate, representing the most suitable one for that domain. Please note that since when $Group_m$ is empty, we do not extract pilot embedding for the empty group (cluster), thereby the number of pilot embeddings for the training dataset could be less than T.\nBy repeating this process across all domain-specific training datasets $D_1, ..., D_T$, we obtain T pilot embeddings for each gate, one from each domain-specific training dataset (repeating line 3-19 in Alg. 1 for all training dataset $D_1 , ..., D_T$). Consequently, the pilot embeddings contains"}, {"title": "Routing Mechanism", "content": "When given an input query, we calculate the similarity between the query embedding extracted from the base encoder and the $T^2$ pilot embeddings in the pilot embedding library. We then average the similarity scores for $T$ pilot embeddings associated with the same gate, resulting in a mean similarity score for each gate. The gate corresponding to the highest mean similarity score is selected as the most suitable embedding model."}, {"title": "Experimental Setup", "content": "Baselines We compare the performance of ROUTERRETRIEVER with when training on the same dataset in a multi-task manner (Multi-Task) and training on a large-scale general-domain dataset MSMARCO (MSMARCO-Trained). Additionally, following previous works (Muqeeth et al. 2024; Jang et al. 2023), we evaluate performance using two oracle settings: Best Individual and Oracle. The Best Individual setting is a dataset-level oracle that routes all queries in a dataset to the expert with the highest average performance for that dataset, while the Oracle setting is an instance-level oracle that routes each individual instance to its best-performing expert.\nWe also conduct experiments with various other routing techniques commonly used in language modeling tasks; ExpertClassifierRouter (Shen et al. 2024), Classification-HeadRouter (Muqeeth et al. 2024), and DatasetRouter (Ye et al. 2022; Jang et al. 2023). ExpertClassifierRouter employs a binary classifier for each gate to calculate the probability of that gate being selected. The gate with the high-"}, {"title": "Affect of Dataset Size when Training Experts", "content": "Figure 3 shows the relationship between performance (y-axis) and the number of training samples (x-axis) across"}, {"title": "Impact of Number of Gates", "content": "Figure 4 shows that adding gates (x-axis) consistently improves the performance of ROUTERRETRIEVER (y-axis). Notably, ROUTERRETRIEVER outperforms the MSMARCO-trained model even with just three gates, indicating that despite not having as diverse or large a training dataset as MSMARCO, the advantage of having multiple embedding models and the ability to select the most suitable one leads to better performance. ROUTERRETRIEVER also shows a small gap with the Best Individual performance which is the in-domain performance for each expert (Oracle performance for dataset-wise). The performance in multi-task training tends to fluctuate as the number of domains (gates) increases. We hypothesize that with a large number of domains, the model struggles to find the optimal embedding for general cases due to the high variance across training datasets.\nFigure 5 illustrates the performance when we use 7 gates and increase the number of experts that the model can choose from, selecting the one with the maximum perfor-"}, {"title": "Routing Mechanism Error Analysis", "content": "Figure 7 illustrates the rate at which each router selects a gate, while Figure 6 shows the rate at which each gate tends to deliver high performance for the dataset. The discrepancy between these two heatmaps highlights the gap between ROUTERRETRIEVER and the oracle performance. For Arguana, the maximum gate distribution is evenly spread, and the routing tends to follow this distribution closely. For Quora, while the maximum gate rate is high overall, the routing often favors the HotpotQA gate in many cases. For MSMARCO, the gate trained on MSMARCO generally shows"}, {"title": "General Performance of ROUTERRETRIEVER over various datasets", "content": "Table 3 demonstrates that ROUTERRETRIEVER consistently outperforms other baselines that rely on a single general-purpose embedding model\u2075. This is evident not only in datasets that have their experts (w/ Experts) but also across various other datasets that do not have their experts (w/o Experts). These findings suggest that the benefits of having multiple experts and routing across them extend well beyond the datasets for which specific experts were trained."}, {"title": "Where does the benefit come from?", "content": "We hypothesize that the benefit of having domain-specific gates comes from the model's tendency to be influenced by its parametric knowledge; models trained on domain-specific datasets are likely to have domain-specific knowledge embedded in their parametric space, enabling them to produce more meaningful embeddings related to those domains. To test the hypothesis, we conduct experiments with the dataset from Zhou et al. (2023), which contains both original NQ (Kwiatkowski et al. 2019) contexts that align with the retriever's parametric knowledge and conflicting contexts for each instance. We experiment with RepLlama (Ma et al. 2024) and E5-Mistral (Wang et al. 2023)\u2076 and found that the retrievers surprisingly for all case prefer contexts that align with their parametric knowledge; they consistently retrieve the original NQ contexts over conflicting contexts\u2077. This finding supports our hypothesis that embedding models are influenced by parametric knowledge when extracting embedding thus their knowledge of domain-specific datasets are better able to extract meaningful embeddings relevant to their domain knowledge. Further details are in the supplementary."}, {"title": "Efficiency", "content": "ROUTERRETRIEVER achieves high efficiency by using parameter-efficient LoRA gates, which account for only about 0.5% of the parameters per gate. This makes the addition of new gates relatively insignificant in terms of parameter count. In terms of training, it uses the same amount of training data as in a multi-task approach. However, unlike multi-task training, which requires retraining the entire model when adding, removing, or changing domains, ROUTERRETRIEVER allows for these modifications without additional training, as our routing technique is training-free. However, during inference, computing the query embedding involves two forward passes: the first to identify the appropriate gate (routing), and the second to generate the final query embedding. Improving the computation efficiency of this routing technique is a direction for future work."}, {"title": "Conclusion", "content": "In this paper, we present ROUTERRETRIEVER, a retrieval model that integrates multiple domain-specific experts with a routing mechanism to extract the most suitable embedding for each query. This approach is both lightweight and flexible, allowing for the addition or removal of experts without additional training. Our experiments demonstrate that it consistently outperforms single embedding models, showcasing the advantages of integrating domain-specific experts. Additionally, it surpasses various widely used routing techniques in language modeling, emphasizing the significance of effective routing for information retrieval tasks. These results highlight the crucial role of domain-specific experts in improving retrieval performance and suggest that combining them with efficient routing techniques can significantly enhance results, potentially approaching oracle performance."}]}