{"title": "ALTA: Compiler-Based Analysis of Transformers", "authors": ["Peter Shaw", "James Cohan", "Jacob Eisenstein", "Kenton Lee", "Jonathan Berant", "Kristina Toutanova"], "abstract": "We propose a new programming language called ALTA and a compiler that can map ALTA\nprograms to Transformer weights. ALTA is inspired by RASP, a language proposed by\nWeiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler from RASP programs to\nTransformer weights. ALTA complements and extends this prior work, offering the ability to\nexpress loops and to compile programs to Universal Transformers, among other advantages.\nALTA allows us to constructively show how Transformers can represent length-invariant\nalgorithms for computing parity and addition, as well as a solution to the SCAN benchmark\nof compositional generalization tasks, without requiring intermediate scratchpad decoding\nsteps. We also propose tools to analyze cases where the expressibility of an algorithm is es-\ntablished, but end-to-end training on a given training set fails to induce behavior consistent\nwith the desired algorithm. To this end, we explore training from ALTA execution traces as\na more fine-grained supervision signal. This enables additional experiments and theoretical\nanalyses relating the learnability of various algorithms to data availability and modeling\ndecisions, such as positional encodings. We make the ALTA framework language speci-\nfication, symbolic interpreter, and weight compiler \u2013 available to the community to enable\nfurther applications and insights.", "sections": [{"title": "1 Introduction", "content": "There has been significant discussion and debate about the degree to which Transformers can perform\ncompositional generalization and \"System 2\" reasoning, prompted by negative results on various evaluations\nfor certain classes of Transformers (e.g., Dziri et al., 2023; Qiu et al., 2023; Shaw et al., 2021; Wu et al.,\n2024; Del\u00e9tang et al., 2022; Mitchell et al., 2023; Valmeekam et al., 2023). Do such negative results reflect\nsome mutable aspect of how such models were trained, or more fundamental architectural limitations? To\nbetter understand the conceptual limitations of Transformers, it would be useful to have an interpretable\nframework for understanding whether and how Transformers can represent and learn solutions to various\ntasks of interest. Such a framework could also potentially help elucidate a path towards improving these\ncapabilities.\nWe present a new framework for compiling interpretable, symbolic programs to Transformer model weights.\nThe framework is based on a new programming language called ALTA, A Language for Transformer Analysis.\nIt includes an interpreter for symbolically executing ALTA programs, and a compiler for converting ALTA\nprograms to Transformer model weights. ALTA is inspired by prior work that introduced a programming\nlanguage for Transformers called RASP (Weiss et al., 2021), and prior work that built a compiler from RASP\nprograms to model weights called Tracr (Lindner et al., 2023). ALTA complements and extends this prior\nwork, with two key conceptual differences.\nFirst, ALTA supports dynamic control flow operations such as loops. While Zhou et al. (2023b) showed how\nRASP programs can be executed within the context of an auto-regressive decoder to implement some forms\nof loops by leveraging scratchpads (Nye et al., 2021; Wei et al., 2022), ALTA can implicitly support such"}, {"title": "2 Proposed Framework", "content": "Here we give an overview of how ALTA programs are specified, their computational model, and how they can\nbe compiled to Transformers. More details on the ALTA program API is in Appendix A.1, and compilation\ndetails and examples are in Appendix A.2."}, {"title": "2.1 Overview", "content": "We give an example of an ALTA program in Figure 2. An ALTA program specification includes three key\ncomponents: a set of variables, a set of attention heads, and a \"MLP function\". We explain each of these\nbelow in the context of how they affect the execution of an ALTA program. The computational model of\nan ALTA program aligns closely with the computational model of a Transformer (Vaswani et al., 2017). In\nthis paper we focus on encoder-only Transformers for simplicity. However, we note that ALTA programs\ncan alternatively be executed in the context of a decoder-only Transformer. This involves adding a causal\nattention mask and outer auto-regressive decoding loop, but does not otherwise affect the definition and\ncompilation of ALTA programs. We also focus on Transformers with layer-wise weight sharing, i.e. where\nall attention and MLP parameters are shared across layers. We also support Universal Transformers which\nhave an input-dependent number of layers.\nNotably, not all types of computation expressible by Transformers can be represented in ALTA, i.e., the range\nof the ALTA compiler is a relatively small subspace of all possible parameter values. For example, ALTA has\nlimited support for numeric computation and does not support modeling of probabilistic output distributions.\nHowever, ALTA provides broad support for implementing various types of deterministic algorithms.\nThe ALTA framework includes an interpreter, which symbolically executes a program, and a compiler which\ncompiles programs to Transformer weights. The input to an ALTA program $P \\in \\mathcal{P}$ is a sequence of integers\ninputs $(\\in \\mathcal{X})$ and the output is a sequence of integers of equal length $(\\in \\mathcal{Y})$. The interpreter implements a"}, {"title": "2.2 Variables", "content": "Similarly to Lindner et al. (2023), we adopt the residual stream view of Transformers as proposed by Elhage\net al. (2021). In this view, the attention and MLP sub-layers within the Transformer read and write to\nthe residual stream, which is represented by the activations between these sub-layers. While Transformers\nrepresent the residual stream for each element as a vector, our interpreter represents the residual stream\nfor each element symbolically as a mapping of variables to values. The residual stream of the interpreter\nfor the parity program of Figure 2 is shown in Figure 3. The set of variables and their possible values are\nspecified by the program. There are three kinds of variables in ALTA: categorical variables have bounded\ninteger values, numerical variables have real-valued values, and set variables have sets of bounded integer\nvalues. Variables representing the output of attention heads can also take on a null or undefined value (see\n\u00a72.3). We establish a bijective mapping between variable assignments and activation vectors. Each possible\nvalue of a categorical variable is assigned a standard basis vector in the activation space, i.e., a one-hot\nencoding. Set variables are similarly represented, but with a multi-hot encoding. The scalar value of a\nnumerical variable is directly represented in a single dimension. This mapping can be seen as establishing an\napproximate isomorphism with respect to the sub-layer operations of the interpreter and those of a compiled\nTransformer."}, {"title": "2.3 Execution", "content": "In this section, we explain the execution of an ALTA program in the interpreter, and summarize how each\noperation is encoded in a compiled Transformer, with more details in Appendix A. We denote the value of\nvariable foo for element $i$ at sub-layer $k$ as $z^{(k)}_{i, \\text{foo}}$. Let $\\vec{z}^{(k)}_{:,\\text{foo}}$ denote the vector of values for foo across all\nelements at sub-layer $k$."}, {"title": "3 Expressibility and Learnability", "content": "While there are many potential applications for ALTA, we focus on two applications in this paper: new\nconstructive expressivity demonstrations, and analysis of whether such algorithms are learnable given a\nparticular training set, with varying amounts of supervision. We give an overview of these applications and\nour proposed analytical tools here, with results in Section 4."}, {"title": "3.1 Expressibility", "content": "There has been considerable interest in establishing the theoretical expressivity of various classes of Trans-\nformers (P\u00e9rez et al., 2021; Chiang et al., 2023; Yun et al., 2020; Feng et al., 2023; Merrill & Sabharwal, 2024).\nHowever, such theoretical works often do not demonstrate specific constructions of how Transformers can"}, {"title": "3.2 Learnability", "content": "In many cases, we can establish that an algorithm is expressible by a given class of Transformers, but training\na model from this class on input and output examples of a particular algorithm can fail to induce a model\nthat generalizes outside of the training set. It can be difficult to diagnose the reason for such failures, and\nto determine what to change regarding the architecture, training objective, or training data to improve\ngeneralization. We provide two tools to help bridge the gap between expressibility and learnability, which\nwe discuss next.\nTrace Supervision We propose to use intermediate supervision from ALTA execution traces over a given\ntraining set as a learning signal. Given a program $P$ and a set of model inputs $\\mathcal{X}$, we run $P$ for every input\nin $\\mathcal{X}$, and extract the variable assignments at the input and output of every sub-layer, for every position.\nThese traces can be used to derive trace supervision, which encourages the behavior of the model to align\nwith that of the program being used to provide supervision. In our experiments, for simplicity, we focus on\ntraining the MLP parameters to reconstruct the desired output vector for each input vector, and compile the\nremaining parameters. In some cases, we show this additional supervision is sufficient to learn the desired\nalgorithm, but in other cases failures can highlight limitations of the underlying architecture due to, e.g.,\nthe type of positional encoding used. We report results on the parity task in \u00a74, and details of the training\nprocedure in Appendix C.1.\nTheoretical Analysis To complement the empirical results from trace supervision, we also take a step\ntowards analytically characterizing the conditions under which any particular ALTA program can be learned\nfrom a given training set. To this end, we introduce criteria for determining whether a program is minimal\nwith respect to a training set, which depends on whether certain components of a program could be removed\nwithout affecting the training set predictions.\nHere we give an overview of our theoretical analysis, which is detailed in Appendix B. We focus on the set of\nMLP parameters, and consider a setting similar to that of training with trace supervision, where we derive a\nset of MLP inputs, $\\mathcal{D}$, corresponding to running a given program over some set of model inputs. The MLP\nparameters are specified by the set of transition rules, $\\mathcal{R}$, in the given program. A rule set is minimal with\nrespect to a set of MLP inputs, $\\mathcal{D}$, if it is not possible to remove any rule or any constraint from any rule\nwithout changing the program output on some input in $\\mathcal{D}$. Similarly to training with trace supervison, we\nconsider a reconstruction loss over $\\mathcal{D}$ that quantifies how well the MLP outputs correspond to the outputs\nspecified by $\\mathcal{R}$. Our results are with respect to a training objective that combines this reconstruction loss\nwith a regularizer on the parameter weights. We show that:\nTheorem 1 (Informal). If the rule set $\\mathcal{R}$ is not minimal with respect to $\\mathcal{D}$, then the compiled MLP parameters\nare not a strict coordinate-wise local optimum of the regularized reconstruction loss."}, {"title": "4 Experiments and Analysis", "content": "We detail experiments and analysis on several tasks, with further details and results in Appendix D."}, {"title": "4.1 Parity", "content": "The parity task requires the model to compute whether a binary sequence contains an even or odd number\nof ones. The ability of transformers to learn parity has been studied extensively (Hahn, 2020), particularly\nthe degree to which they exhibit length generalization (Bhattamishra et al., 2020; Chiang & Cholak, 2022;\nRuoss et al., 2023; Del\u00e9tang et al., 2022). Empirically successful solutions have relied on scratchpads (Anil\net al., 2022; Zhou et al., 2022). Zhou et al. (2023b) used a variant of RASP to investigate why Transformers\nstruggle with length generalization on parity and why scratchpads help.\nWe study three ALTA programs for computing parity detailed in Appendix D.1. First, the Sequential\n(Absolute) program computes parity by iterating through each position (one per layer), flipping a parity\nbit every time a one is encountered. While this program uses absolute positions to enable propagating"}, {"title": "4.2 Addition", "content": "Another common benchmark for evaluating Transformer generalization is multi-digit addition. This task\nhas been studied extensively (Nogueira et al., 2021; Liu et al., 2022), particularly with respect to length\ngeneralization (Zhou et al., 2024; Shen et al., 2023; Zhou et al., 2023b; Lee et al., 2024; Kazemnejad et al.,\n2024; Ruoss et al., 2023). While new positional encodings such as FIRE (Li et al., 2024) can improve\nperformance, Transformers still struggle with length generalization on this task, unless provided with carefully\nconstructed supervision over intermediate decoding steps (Zhou et al., 2023b; 2024).\nIn Appendix D.2 we detail an ALTA program with dynamic halting that can add two positive integers of\nunbounded size. This program compiles to a Universal Transformer encoder with relative position repre-\nsentations (as mentioned in Section 2, we use the parameterization of Raffel et al. (2020)). The number of\nlayers required to compute the sum is N +2, where N is the number of digits in the larger of the two inputs.\nNotably, the minimal version of this program with respect to a training set that includes only inputs with\n< 3 digits can generalize to unbounded input lengths."}, {"title": "4.3 SUBLEQ", "content": "SUBLEQ is a single instruction language that has been shown to be Turing-complete when given access\nto infinite memory (Mavaddat & Parhami, 1988). Giannou et al. (2023) previously showed how a Looped\nTransformer can implement an interpreter for a variant of SUBLEQ. In Appendix D.3 we demonstrate an\nALTA program for implementing an interpreter for a less restrictive version of SUBLEQ in a Universal\nTransformer encoder."}, {"title": "4.4 SCAN", "content": "The SCAN (Lake & Baroni, 2018) suite of compositional generalization tasks requires mapping natural lan-\nguage commands (e.g., \u201cjump twice\") to action sequences (e.g., JUMP JUMP). Certain train and test splits\nhave been shown to be challenging for Transformer-based models (Keysers et al., 2020; Furrer et al., 2020;\nQiu et al., 2022b; Kazemnejad et al., 2024). Empirically successful solutions have involved symbolic decom-\npositions of some form (Shaw et al., 2021; Chen et al., 2020; Herzig & Berant, 2021; Qiu et al., 2022a; Zhou\net al., 2023a).\nIn Appendix D.4, we demonstrate an ALTA program that solves the SCAN task. First, the program\nexecutes a shift-reduce parse of the input sequence, representing the parse as a tree. Second, the ALTA\nprogram decodes the output sequence by traversing the parse tree. The program represents the necessary\nvariable-length data structures (a stack, parse tree, and buffer) using a variable number of input tokens.\nCompiled models require fewer than 2,000 MLP hidden dimensions despite there being more than $10^{60}$\npossible variable combinations in the program. This highlights the importance of sparsity, which ALTA\nenables by representing the MLP computation as a set of transition rules.\nNotably, the minimal version of our program with respect to the training set generalizes to the test set,\nfor all of the most challenging length-based and Maximum Compound Divergence (MCD) (Keysers et al.,\n2020) splits. Our ALTA program for SCAN thus gives a constructive demonstration of how Transformers\ncan represent algorithms exhibiting systematic generalization: a finite set of transition rules and attention\noperations can be recombined in novel ways to process novel inputs.\nWe also trained several Transformer variants using standard, end-to-end supervision on the same splits,\nvarying the total number of layers up to a maximum of 256 encoder layers and 256 decoder layers (as our\nALTA program requires at most 512 total layers). However, all generalize poorly on the test splits, and\nincreasing the number of layers does not improve generalization. Consistent with the parity results, end-"}, {"title": "5 Discussion", "content": "Limitations ALTA has many of the same limitations as RASP and Tracr with respect to the potential\ndifferences between compiled models and those learned in practice, as discussed by Lindner et al. (2023). In\nparticular, the framework provides limited support for numerical computations and modeling probabilistic\noutput distributions. The properties of compiled models may not reflect those of models learned in practice.\nHowever, ALTA can still be a useful tool if these limitations are kept in mind when interpreting results.\nOpportunities In this paper, we focused on analysis related to expressibility and learnability. However,\nthere are many potential applications of the ALTA framework that could be interesting for future work. For\nexample, we discuss more flexible alternatives for learning from trace supervision in Appendix C.1. Addition-\nally, ALTA could potentially help develop test cases for interpretability tools. This was one of the primary\nmotivations for Tracr, which has been applied to help design interpretability benchmarks (Thurnherr &\nScheurer, 2024) and more interpretable Transformers (Friedman et al., 2023). Finally, compiled components\ncan potentially be integrated within learned models, such as circuits for arithmetic (Nanda et al., 2023) or\ninduction heads (Aky\u00fcrek et al., 2024). More broadly, we hope the ALTA framework can help the community\nbetter understand how Transformers can represent and learn various algorithms, and inspire new methods\nand insights."}, {"title": "A Framework Details", "content": "In this section we provide additional details about the ALTA Framework, as introduced in \u00a72. First, we\ndetail the program API in \u00a7A.1, which is referenced by the ALTA programs in this paper. Second, we provide\nmore details and examples of how programs are compiled to Transformer weights in \u00a7A.2."}, {"title": "A.1 Program API Details", "content": "Here we detail the functions of the ALTA API used to build the programs shown in this paper. We refer the\nreader to our open-source implementation for further details.\nVariables and Attention Heads The module contains several methods for defining variable specifica-\ntions:\n\u2022 var defines a categorical variable, the most common variable type. The cardinality must be specified.\n\u2022\n\u2022 set_var defines a set variable. A set of sets of possible values must be specified.\nFor each of these functions, it is also necessary to specify how the variable is initialized.\nThere are two methods for defining attention heads:\n\u2022 qkv defines an attention head, with arguments that specify the query, key, and value variables.\nOptionally, a set of relative positions can also be passed, as well as an explicit specification for the\noutput variable.\n\u2022 relative_v is a shorthand function for defining an attention head that attends to a specific relative\nposition. The query and key are implicitly set to a single-valued categorical variable.\nThe output variable specification can be optionally specified explicitly, or is otherwise inferred from the\ntype of the value variable. The output variable for each head is also included in the overall set of program\nvariables.\nMLP Functions There are two ways to specify the MLP function, as mentioned in \u00a72. For simplicity, the\nprograms listed in this paper specify the MLP function as a Python function, which is passed a dictionary-like\nobject for accessing and updating variable values. Alternatively, the set of transition rules can be specified\ndirectly, allowing more control to manage the scope of variables included in the antecedent of each rule, and\navoid the combinatorial explosion of possible variable values for more complex programs. Figure 6 gives an\nexample of specifying the transition rules for the parity program of Figure 2 using the MLPBuilder class.\nThe class has two methods. The get method returns a generator over possible variable values. The class\nautomatically tracks which variables and variable values are in scope. The set method generates a transition\nrule, generating the antecedent of the rule automatically based on the current scope. In almost all cases, this\nresults in a more compact set of transition rules than specifying the MLP function as a Python function. All\nof the results in this paper related to analyzing the minimal versions of programs or computing the number\nof MLP hidden dimensions in compiled models are based on versions of programs where the transition rule\nset has been specified directly."}, {"title": "A.2 Compiler Details", "content": "In this section we will give an example of the compilation process introduced in \u00a72, using the parity program\nof Figure 2 as an example.\nNotation Let $v^{(k)}_i$ denote the activation vector in a compiled model for element $i$ at sub-layer $k$.\nEncoding Variable Assignments Consider a set of variable assignments:\nFor brevity, we only include a subset of program variables in this example. This set of assignments is\nrepresented as the following vector in a compiled model:\nInitialization The input embedding is computed as: $z_i = W^X x_i + W^P i$, where $x_i$ is the input token ID\nat position $i$, and $W^X$ and $W^P$ represent the embedding matrices for token and positional embeddings,\nrespectively. For brevity, we only consider up to 3 positional indices for this example. We also omit some\nvariables in the matrices below, and transpose them for clarity of the row and column labels. Note that"}, {"title": "B Theoretical Analysis of Minimal Rule Sets and MLP Parameters", "content": "If a program is minimal with respect to some training set, can we draw any conclusions about whether the\ntransformer implementation of that program will be learned on that same training set? We now explore\nthis question from the perspective of the MLP parameters in the trace supervision setting. Specifically, we\nidentify conditions under which the compiled MLP parameters are a strict coordinate-wise\nlocal optimum of a regularized reconstruction loss. Extensions to consider all parameters of the\ncompiled transformer, end-to-end training objectives, or non-coordinate-wise local optima are left to future\nwork."}, {"title": "B.1 MLP Specification", "content": "Here we introduce notation that differs from that in other sections, but is more appropriate for the goals\nof this section. Let us focus on two components of an ALTA program $P$ for this analysis: a set of possible\nvariable assignments, $\\mathcal{V}$, and a set of rules, $\\mathcal{R}$. The rules implicitly define an MLP function, $f_R : \\mathcal{V} \\to \\mathcal{V}$,\nwhich is a sub-component of the overall program. For simplicity, we consider only programs with categorical\nvariables for this analysis, and exclude transition rules related to attention outputs.\nVariable Assignments An assignment $V \\in \\mathcal{V}$ is a tuple of $N_V$ elements, with $V = (V_0, V_1,\\dots, V_{N_V-1})$,\nwhere $V_i \\in \\{0, 1, . . ., D_i - 1\\}$ and $D_i$ is the dimensionality of variable $V$. The number and dimensionality of\nvariables is given by the program specification.\nTransition Rules Let $\\mathcal{R} = \\langle R_1, R_2,\\dots, R_{N_R} \\rangle$, where $R_i$ is a transition rule. As described informally in\nSection 2.3, transition rules consist of the following components:\n\u2022 The antecedent of $R_i$, denoted $A_{R_i}$, consists of a set of $N_{R_i}$ constraints $(k,v)$ where each $k \\in\n\\{0,\\dots, N_V-1\\}$ refers to a variable index, and each $v \\in \\{0,\\dots, D_k - 1\\}$ refers to a variable value. A\ntransition rule is satisfied by an assignment $V \\in \\mathcal{V}$ if and only if $V_k = v$ for all $(k, v)$ in the rule's\nantecedent.\n\u2022 The consequent of $R_i$, includes an the output variable index, denoted $K_{R_i}$, and a new value for this\nvariable, denoted $U'_{R_i}$. Per construction, for every $R_i$ we require that the output variable appears in\nthe antecedent of the rule. Let $U_{R_i}$ denote to the value associated with the output variable in the\nantecedent.\nThe rule $R_i$ can therefore be interpreted as updating the value of the variable $K_{R_i}$ from $U_{R_i}$ to $U'_{R_i}$ if $R_i$ is\nsatisfied.\nFinally, we also require that for any assignment $V \\in \\mathcal{V}$, no more than one rule is satisfied for a given output\nvariable. In other words, if two rules share the same output variable index, then they should never both be\nsatisfied for any assignment $V \\in \\mathcal{V}$."}, {"title": "B.2 Compiling MLP Parameters", "content": "As described in Section 2.3 and Appendix A.2, in our compiled models, we represent variable assignments\nas vectors, and compile the MLP function into the parameters of an MLP. Here we introduce notation and\na more detailed description of the compilation procedure to support our theoretical analysis."}, {"title": "B.3 Minimal Rule Set", "content": "In Section 3 we introduced the notion of a minimal program. Here we focus on the minimality conditions\nrelating only to the rule set and the corresponding MLP layer. We define a minimal rule set, encompassing\nthe conditions necessary to obtain guarantees about a reconstruction loss landscape around the parameters\nof the compiled MLP.\nDefinition 1. (minimal rule set) Given a dataset of $N$ variable assignments $\\mathcal{D} = \\{V_1, V_2,\\dots, V_N\\}$, a set of\nrules $\\mathcal{R}$ is a minimal rule set over $\\mathcal{D}$ if:\n\u2022 It is not possible to remove any individual rule in $\\mathcal{R}$ and not change the output of $f_R$ for some\nexample $V_n \\in \\mathcal{D}$.\n\u2022 It is not possible to remove any individual constraint of the antecedent of any rule in $\\mathcal{R}$ without\nchanging the output of $f_R$ for some example $V_n \\in \\mathcal{D}$."}, {"title": "B.4 Reconstruction Loss", "content": "We consider a setting related to that of training models with trace supervision, as discussed in \u00a7C.1. For\nprogram $P$ and set of model inputs $\\mathcal{X}$, let $\\mathcal{D} = \\{V_1, V_2, \\dots, V_v\\}$ be the set of variable assignments at the\ninput to the MLP for every position and layer when we run $P$ over $\\mathcal{X}$. We use the shorthand:\n$z^n := e_V(V_n)$,\nto denote the vector encoding of assignment $V_n$.\nNow let us define a reconstruction loss, $L_R$, over individual predictions. For model parameters $\\theta$ and a given\nvariable assignment $V_n$ with corresponding vector encoding $z^n = e_V(V_n)$, the reconstruction loss quantifies\nhow well the predicted variable encodings $f(\\theta, z^n)$ match the variable encodings specified by $\\mathcal{R}$, $e_V(f_R(V_n))$.\nPer equation 13, this vector can alternatively be written in terms of compiled parameters $\\theta$ as $f(\\hat{\\theta}, z^n)$. For\nsimplicity, we consider an $L_1$ loss over the predicted and expected encodings, which simplifies the analysis\nof the local minimum point. We write $L_R$ as:\n$L_R(\\hat{\\theta}, z^n) = ||f(\\theta, z^n) - f(\\hat{\\theta}, z^n)||_1$.\nNote that for all n:\n$L_R(\\hat{\\theta}, z^n) = 0$."}, {"title": "B.5 Coordinate-wise Local Minimum", "content": "As it is difficult to analyze whether a point is a strict local minimum, we will instead analyze whether a\npoint is a coordinate-wise local minimum. Prior work has defined the notion of a coordinate-wise minimum,\nwhich is defined in terms of axis-aligned movements of parameter values (e.g., Tseng, 2001).\nDefinition 2. (coordinate-wise local minimum) For a multivariate function $f : \\mathcal{X}_1 \\times \\mathcal{X}_2 \\times ... \\times \\mathcal{X}_n \\to \\mathbb{R}$,\nthe value $X = (x_1,x_2,\\dots, x_n)$ is a strict coordinate-wise local minimum iff for each $i \\exists \\lambda > 0$, such that\n$f(x_1,\\dots, x_i - \\epsilon,\\dots x_n) < f(x_1,\\dots, x_i + \\epsilon, \\dots x_n)$ for all $\\epsilon \\in (-\\lambda, \\lambda)$."}, {"title": "B.6 Main theorems", "content": "Suppose we learn $\\theta$ by optimizing a regularized sum of reconstruction losses over a dataset,\n\\mathcal{L}(\\theta, \\mathcal{D}, \\alpha) = \\alpha \\mathcal{L}_1(\\theta) + \\sum_n L_R(\\theta, e_V(V_n))\n= \\alpha \\mathcal{L}_1(\\theta) + \\sum_n L_R(\\theta, z^n),\nwith $\\alpha > 0$ penalizing the sum of $L_1$ norms $||W^2||_1 + ||W^1||_1 + ||b^1||_1$. We consider the $L_1$ norm as the\nregularization term for simplicity.\nWe want to show that when the weights are generated by compiling a set of rules that is minimal with\nrespect to $\\mathcal{D}$, then $\\theta$ is a coordinate-wise local optimum of $\\mathcal{L}$ for $\\alpha < 1$.\nTheorem 1 (Formal). If $\\hat{\\theta}$ is the compilation of a rule set $\\mathcal{R}$ that is not minimal for $\\mathcal{D}$, then $\\hat{\\theta}$ is not a\nstrict coordinate-wise local optimum of $\\mathcal{L}(\\theta, \\mathcal{D}, \\alpha)$.\nTheorem 2 (Formal). If $\\hat{\\theta}$ is the compilation of a rule set $\\mathcal{R}$ that is minimal for $\\mathcal{D}$, then $\\hat{\\theta}$ is a strict\ncoordinate-wise local optimum of $\\mathcal{L}(\\theta, \\mathcal{D}, \\alpha)$ for $\\alpha < 1$.\nRemark. Both theorems can also be proved for a squared $L_2$ regularizer with coefficient $\\alpha \\in (0, 1/(2K))$,\nwhere $K = max(1, max_i N_{R_i} - 1)$ is the largest parameter magnitude in $\\theta$ and $2K$ is therefore the largest\nelement of the gradient of the squared $L_2$ regularizer evaluated at $\\hat{\\theta}$."}, {"title": "B.7 Proof of Theorem 1", "content": "Proof. There are two ways in which a ruleset might violate minimality with respect to $\\mathcal{D}$.\n\u2022 We can remove rule $R_j$ without affecting the output of $f_R$ on any example. All rules\naffect the output when their antecedent conditions are met, so we can infer that the conditions of\n$R_j$ are never met. In this case, there is guaranteed to be a parameter $W^2_{i,j} \\neq 0$, setting the value\nof $f_i(\\theta, z^n)$ when the conditions of $R_j$ are met. If $R_j$ is never active for any $z^n$, then $W^2_{i,j}$ does not\naffect the reconstrution loss $L_R$.\n\u2022 There is a condition of $R_j$ that we can remove without affecting the output of $f_R$ on\nany example. This condition is represented as a nonzero element in $W^1_{j,k}$ (and also in $b_j$, which is\nnot necessary for the proof). By construction this parameter does not affect the reconstruction loss.\nIn both cases, the gradient with respect to the nonzero parameter ($W^2_{i,j}$ and $W^1_{j,k}$) is set only by the\nregularizer. The right and left derivatives have the same sign, violating the conditions of strict coordinate-\nwise local optimality."}, {"title": "B.8 Proof of Theorem 2", "content": "To prove Theorem 2, we will analyze the left and right derivatives of the loss function (eq. 17) with respect\nto each parameter in the compiled parameters $\\theta$, and show that the left derivative is positive and the right"}, {"title": "C Learnability Analysis Details", "content": "In this section, we provide additional discussion and details related to trace supervision (\u00a7C.1) and the\nprocedure for determining the minimal version of a program with respect to a training set (\u00a7C.2)."}, {"title": "C.1 Procedure for Training with Trace Supervision", "content": "Given a program $P$ and a set of model inputs $\\mathcal{X}$, we can run $P$ for every input in $\\mathcal{X}$, and extract the\nvariable assignments at the input and output of every sub-layer, for every position. In our experiments,\nfor simplicity, we focus on training the MLP parameters. After using the ALTA"}]}