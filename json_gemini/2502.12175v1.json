{"title": "Spatiotemporal Graph Neural Networks in short-term load forecasting: Does adding Graph Structure in Consumption Data Improve Predictions?", "authors": ["Quoc Viet NGUYEN", "Joaquin DELGADO FERNANDEZ", "Sergio POTENCIANO MENCI"], "abstract": "Short-term Load Forecasting (STLF) plays an important role in traditional and modern power systems. Most STLF models predominantly exploit temporal dependencies from historical data to predict future consumption. Nowadays, with the widespread deployment of smart meters, their data can contain spatial-temporal dependencies. In particular, their consumption data is not only correlated to historical values but also to the values of 'neighboring' smart meters. This new characteristic motivates researchers to explore and experiment with new models that can effectively integrate spatial-temporal interrelations to increase forecasting performance. Spatiotemporal Graph Neural Networks (STGNNs) can leverage such interrelations by modeling relationships between smart meters as a graph and using these relationships as additional features to predict future energy consumption. While extensively studied in other spatiotemporal forecasting domains such as traffic, environments, or renewable energy generation, their application to load forecasting remains relatively unexplored, particularly in scenarios where the graph structure is not inherently available. This paper overviews the current literature focusing on STGNNs with application in STLF. Additionally, from a technical perspective, it also benchmarks selected STGNN models for STLF at the residential and aggregate levels. The results indicate that incorporating graph features can improve forecasting accuracy at the residential level; however, this effect is not reflected at the aggregate level.", "sections": [{"title": "1 Introduction", "content": "Short-term Load Forecasting (STLF) plays a vital role in power systems by supporting grid and market operations and, consequently, helping with the reliability of traditional and modern power systems [2]. Its importance grows as power systems become more complex and decentralized [3]. In particular, modern power systems require better forecasts to deal with the increasing grid (e.g. dispatch, reconfiguration) and market operations (e.g. portfolio balancing) caused by dynamic fluctuations in generation and consumption [3]. Tackling the dynamic fluctuations appropriately beforehand also has a significant economic impact affecting all power system players. For instance, a one-percent increase in forecast accuracy could save up to \u00a310 million annually in the UK [4].\nIn general, most STLF models emerge from statistical or machine learning models [5]. Statistical models usually assume the property of time series such as stationarity or invertibility [4], which might be unsuitable to model volatile energy consumption data down at the residential level [6]. The alternative is to shift to data-driven approaches, such as machine learning and especially deep learning, to effectively model the expanding space of available data, mainly caused by the introduction of smart meters. Currently, most STLF models rely solely on the temporal dependency of historical data for forecasting. However, since consumption data can be collected from multiple smart meters at the household level, the interrelation between different households can also be discovered and used [7]. Incorporating information from 'neighboring' households with strong interconnections could potentially improve forecasting accuracy for a specific household. Consequently, forecasting models should integrate both temporal and spatial dependencies to effectively capture the data's dynamics.\nA solution to capture these dependencies is to use Spatiotemporal Graph Neural Network (STGNN) because, in addition to processing data in temporal order, STGNN accounts for spatial dependencies through a graph-based approach. This deep learning-based method has been the subject of substantial research in fields such as traffic prediction, environmental studies, and energy generation, where spatio-temporal characteristics are evident [8]. Recently, more energy research has applied this architecture to forecast energy consumption at the residential level [4, 9]. Although graphs in other problems such as traffic or energy generation can be derived from geographic locations, spatial proximity does not fully reflect the similarity in energy consumption patterns. This is because consumption behaviors at the residential level are stochastic, and the similarity between usage patterns lies on sociodemographic factors rather than spatial proximity [10]. To represent the relationship between households, many STLF studies have directly extracted the similarity of signals among them [11]. Another, more flexible way is to model graph structure as learnable parameters and optimize it during training to produce the best forecast [9, 12]. These strategies add the spatial notion in the energy consumption data as a graph and make the application of STGNNs on the STLF problem feasible. However, the absence of an inherent graph structure in energy consumption behaviors necessitates constructing one from historical data. This raises an important question: Does a temporally informed graph model predict more effectively load that a model based solely on temporal features?\nThis question combined with increasing research on STGNN for STLF has motivated our research. Our goal is to summarize the current literature on STLF using STGNNs and to identify the key components that influence the performance of the models by:\n\u2022 Evaluating the performance of representative STGNN models in residential STLF.\n\u2022 Identifying relevant factors in the construction of STGNNs that affect performance in STLF.\nThe remainder of the paper is structured as follows. Section 2 gives a brief overview of the existing STGNN architectures and models for spatiotemporal forecasting in general and load forecasting in particular. In Section 3, we designed experiments to validate and compare the performance of STGNN on STLF in different time scales. Building upon these results, we provide insight and explanations of the results specific to load forecasting. The study concludes with a summary and future directions in Section 5."}, {"title": "2 Overview of STGNN for STLF", "content": "STGNNs are models designed to handle time series data collected from various locations [13]. In the context of STLF, we consider a dataset collected from N consumers (e.g. households). In the simplest case, we assume for each consumer, data only contain historical energy consumption from smart meters. Let $x_i^t \\in \\mathbb{R}$ be the energy consumption of consumer i at time step t; each time series ${x_i^t}_{t:t+T}$ is the energy consumption of consumer i in period t \u2192 t + T. Consequently, by stacking all consumers, the matrix $X_{t:t+T} \\in \\mathbb{R}^{N \\times T}$ represents the consumption records of N consumers in the period t\u2192t+T. Given the consumption data $X_{t-w:t}$ from W previous steps, STGNN models forecast consumption $X_{t:t+H}$ in H next steps for all consumers.\nIn doing so, STGNN represents consumers and their relationships by a graph structure. A graph G = (V, E) consists of a set of nodes V = {$V_1, V_2, ..., V_v $} and a set of edges E\u2282 V \u00d7 V, where (vi, vj) \u2208 E if node vi connects to node vj. This connectivity is compactly represented by an adjacency matrix A, where an entry aij > 0 signifies the edge weight between nodes vi and vj. In the context of residential STLF, each household is assigned to one node and its features contain time series of its historical energy consumption. Respectively, the edges can be derived based on the patterns between residential load profiles [14].\nIn what follows, we first describe how graph structures are usually constructed, then detail the components of STGNN and how those components interact with each other. Finally, we present some representative models in the literature."}, {"title": "2.1 Graph Formation", "content": "To capture the spatial dependency between different nodes, it is necessary to provide a spatial structure in the form of a graph. The topology of the graph dictates how the features are aggregated between the nodes. Based on how the graph is constructed, the graph formation methods in the literature can be classified as follows [11]:\n\u2022 Predefined graph: The topology of the graph is fixed during training. The edge of the graph may be established using supplementary information and by assessing the similarity between time series. The similarity measure can be based on Pearson coefficient [15], Euclidean distance, DTW distance [16], or correntropy [17]. An edge is considered to exist when the similarity surpasses a defined threshold value [11].\n\u2022 Learnable graph: Some models integrate graph formation into the learning process. This technique does not require a graph from the dataset before training but self-organizes the graph during training so that it can facilitate the flow of information for graph neural network [18]. We identify some learning algorithms that incorporate graph structure learning for downstream tasks (i.e., forecasting) later in section 2.4."}, {"title": "2.2 Temporal and Spatial Processing Unit as components of STGNN", "content": "To model spatiotemporal data as in load forecasting, one must process information in temporal and spatial dimensions. The most popular deep learning models to process temporal information are through Recurrent Neural Network (RNN) [19], Convolutional Neural Network (CNN) models, or Multilayer Perceptron (MLP) [20].\nRespectively, the most dominant method to propagate information along the graph is through the Message Passing (MS) paradigm [13] which involves 2 steps:\n1. Message Aggregation: Each node collects information (or \"messages\") from its neighboring nodes. This step captures the local structure and features of the graph by pooling or combining the attributes of connected nodes.\n2. Feature Update: After aggregation, each node updates its own representation by combining the aggregated information with its existing attributes. This step refines the node's state, embedding its local and neighboring information into a new feature representation.\nThere are several models fit into this paradigm, but one of the most popular is Graph Convolutional Network (GCN) [21]. It is present in numerous examples of STGNN within our study."}, {"title": "2.3 STGNN architecture", "content": "We refer to the structure of STGNNs in the literature. The most prominent architectures of STGNN are Time-then-Space (TTS), Time-and-Space (T&S) [22]."}, {"title": "2.3.1 Time-then-Space (TTS) architecture", "content": "In TTS architecture, the models encode information in the temporal dimension first, as depicted by the solid arrow in Fig. 1. The abstract representation of each node is now broadcast (dashed arrow in Fig. 1) to their neighbors through the spatial unit to incorporate useful information in the spatial dimension."}, {"title": "2.3.2 Time-and-Space (T&S) architecture", "content": "Alternatively, the T&S architecture integrates the processing of temporal and spatial features more cohesively. At each time step, the features of individual nodes are propagated and abstracted through a spatial processing unit, updating the node representations in the spatial dimension (dashed arrow in Fig. 2). Then, the node representation is processed using a recurrent unit, producing a hidden state at that time step. Subsequently, this internal hidden state is combined with the upcoming observation to produce the hidden state in the next step (as illustrated by the curved arrow in Fig. 2). It is worth noting that a recurrent model is employed as the temporal processing unit in this context [22]."}, {"title": "2.4 Examples of STGNN models", "content": "Given the different architectures of STGNN models, we review existing models that are representatives of the described architectures. We present and compare the similarity between models based on the components and architectures in Section 2.2 and 2.3.\nGRUGCN [22] This model is of type TTS. It uses the Gated Recurrent Unit (GRU) (a variant of RNN) as a temporal processing unit to represent temporal characteristics of each node and then applies GCN on top of the encoded features to account for spatial dependencies.\nGCGRU [4] This model uses T&S architecture. In particular, it uses GCN as the spatial processing unit to capture the spatial dependency at time step t. This unit acts as a cell in the GRU model, which recursively calculates the hidden state of the entire graph. Note that for a more consistent comparison, we replace the Long Short-Term Memory (LSTM) model in [4] by GRU as in other models.\nT-GCN [23] This model updates node features by a 2-layer GCN before processing them by GRU model. It is similar to GCGRU but updates only node features through the GCN, not the hidden state.\nAGCRN [24] This model is similar to GCGRU in terms of encoding both spatial and temporal dimensions. However, to model the relationships between nodes more flexibly, this approach introduces a learnable embedding for each node. Consequently, the feature in each node is not only determined by the historical data but also by the embedding. This allows the model to determine the optimal embeddings that maximize the forecast performance.\nGraph Wavenet [25] Similar to AGCRN, this model assigns each node a learnable embedding. In terms of forecasting, it employs a temporal convolutional layer to encode historical data of each consumer, followed by a graph convolutional layer to incorporate features in the spatial dimension. By stacking multiple layers of this unit with different parameters, the model can capture various patterns at different temporal and spatial scales. As described, it is of type TTS.\nFully-Connected Graph Neural Network (FC-GNN) [26] This model presumes that every node is interconnected, resulting in a complete graph. However, in the Message Aggregation step, the weight of each \"message\" from neighbors will be adjusted due to the attention mechanism, allowing an adaptable edge weight between nodes even though the topology of the graph does not reflect the relation between time series. In terms of forecasting, it follows the TTS architecture with MLP as a temporal processing unit and the attention mechanism in the spatial processing unit.\nBipartite-Graph Neural Network (BP-GNN) [26] This model is a variant of the FC-GNN model. However, instead of full connectivity, it defines virtual nodes that connect to all original nodes, forming a bipartite graph. These nodes act as hubs, aggregating, updating, and relaying information between original nodes.\nThe selected models are arranged in Table 1, following the structure outlined in Sections 2.1 and 2.2."}, {"title": "3 Experiments", "content": "We used an open dataset to train and evaluate the performance of STGNN. The dataset is Low Carbon London (LCL) dataset [27], containing historical smart-meter data from 5,567 households over 2013 with a 30-minute resolution. We selected 228 load profiles from one specific sociodemographic group within the dataset (Acorn - D [28]). We selected consumers of the same sociodemographic group so that the pairwise relationship is solely based on the historical data. The selected dataset also has no missing values and zero values, which enables the use of MAPE metrics (Section 3.3). As all algorithms are designed to operate solely with past consumption data [4], we use only historical data as input for all models, as outlined in Section 2. For data partitioning, to avoid information leakage between training and testing, our proposed train-validation-test split is indicated in Fig. 3."}, {"title": "3.1 Dataset and data partition", "content": "We used an open dataset to train and evaluate the performance of STGNN. The dataset is Low Carbon London (LCL) dataset [27], containing historical smart-meter data from 5,567 households over 2013 with a 30-minute resolution. We selected 228 load profiles from one specific sociodemographic group within the dataset (Acorn - D [28]). We selected consumers of the same sociodemographic group so that the pairwise relationship is solely based on the historical data. The selected dataset also has no missing values and zero values, which enables the use of MAPE metrics (Section 3.3). As all algorithms are designed to operate solely with past consumption data [4], we use only historical data as input for all models, as outlined in Section 2. For data partitioning, to avoid information leakage between training and testing, our proposed train-validation-test split is indicated in Fig. 3."}, {"title": "3.2 Model training", "content": "For all models, we do hyperparameter tuning in learning rate, batch size, training window W (Section 2). The other hyperparameter is fixed for each experiment.\nFor training, we use MAE as the loss function.\n$MAE = \\frac{1}{N \\cdot W} \\sum_{n=1}^{N} \\sum_{t=1}^{W} |x_i - \\hat{x}_i| \\text{(1)}$\nwith $x_i$ being the measured energy consumption and $\\hat{x}_i$ being the predicted consumption of consumers i at time t.\nThe maximum epoch for training is 300 with early stopping options. To facilitate the implementation of the code, we build the experiment from the tsl package [29]. The details of the implementation of each model can be found in specified Github repository\u00b9. All the training is carried out in the IRIS cluster of the high-performance computer (HPC) facilities of the University of Luxembourg [1]."}, {"title": "3.3 Model benchmark", "content": "To validate the performance of the STGNN models, we compare them with several benchmark models widely used in time series forecasting.\n\u2022 Seasonal Naive: This simple baseline model uses the value of the same hour on the previous day to predict the corresponding hour on the next day.\n\u2022 Vector Autoregressive (VAR): The Vector Autoregressive (VAR) model is a statistical approach that extends the univariate autoregression (AR) model to multivariate time series.\n\u2022 GRU: Recurrent Neural Networks (RNNs) are extensively used in the literature to model sequential data because of their ability to capture temporal dependencies. In this study, we use a variant of RNN, the Gated Recurrent Unit (GRU). This architecture is also used in many STGNN models in our research.\n\u2022 Transformer: Transformer models [30] represent a paradigm shift in sequence modeling by using self-attention mechanisms to compute pairwise dependencies between elements in a sequence. This architecture has been increasingly applied to STLF [31].\nEach of these benchmark models offers unique characteristics, allowing us to comprehensively assess the performance of STGNN against a diverse set of approaches that vary in complexity, interpretability, and scalability. Note that all the models above only take into account the temporal dependency in the sequence. The training configuration for these models is the same as STGNN models.\nThe error metrics to evaluate the performance of each model are:\n$MAE = \\frac{1}{NT} \\sum_{n=1}^{N} \\sum_{t=1}^{T} |x_i - \\hat{x}_i|$ (2)\n$MAPE = \\frac{1}{NT} \\sum_{n=1}^{N} \\sum_{t=1}^{T} \\frac{|x_i - \\hat{x}_i|}{x_i}$ (3)\n$RMSE = \\sqrt{\\frac{1}{NT} \\sum_{n=1}^{N} \\sum_{t=1}^{T} (x_i - \\hat{x}_i)^2}$ (4)\nwhere N is the number of households and T is the time steps of the testing period."}, {"title": "4 Results and discussion", "content": "In each experiment, we perform the procedure 5 times using identical parameters to calculate the statistics of the experiment. The results will be displayed as the mean, followed by the standard deviation from the 5 trials. To enhance the presentation of the results, we use bold font to highlight instances where the performance of STGNN models surpasses all benchmark models, and underlining to indicate the best performance according to the error metrics."}, {"title": "4.1 Comparison between graph formation methods", "content": "Methods for graph formation can produce various topologies that facilitate the aggregation of information. This section aims to explore whether creating graphs based on different types of similarities between time series impacts forecasting performance. The focus is exclusively on the 3 first models in Table 1 which require signal-based predefined graphs.\nThe results in Table 2 suggest that graph construction methods do not significantly impact the effectiveness of learning, even though the resulting topologies may vary. STGNNs, as a data-focused method, adapts by learning with different topologies to achieve comparable outcomes. In the following section, for each predefined-graph model, we employ the graph formation technique that results in the minimal MAE."}, {"title": "4.2 Model benchmark with different temporal scale at the residential level", "content": "Compared to benchmark models that process only temporal features, the practice of adding relationships between households in STGNN models increases forecasting performance. Especially, in contrast to GRU, which uses matrix multiplication as the unit cell of the recurrent network, GCGRU and T-GCN always achieve better performance by applying GCN as the unit cell. Similarly, GRUGCN also outperforms GRU by applying GCN on top of it to account for spatial dependency. It showcases the effective use of graph neural networks to model spatial relationships (see Table 3).\nMoreover, although models with a learnable graph theoretically offer more flexibility, this approach does not deliver promising outcomes; only AGCRN model performs compatible results with the best benchmark models (GRU). However, when comparing with GCGRU, which uses a predefined graph from signals, there is a downgrade in performance in some metrics. This is because the learnable graph offers a more flexible way to model the spatial relationship. However, it could make the forecasting task more susceptible to overfitting. When testing on a more distant future (one month after training, as outlined in Fig. 3), the model actually performs worse than the counterpart that uses a predefined graph.\nWhen testing with 3 splits, the BP-GNN and FC-GNN models often perform better than their counterparts. These models presume the topology of the graph without relying on the data (fully connected or bipartite); instead, when aggregating information from neighbor nodes, the models utilize a weighted sum of neighboring information, where the weights are derived from the input. This makes the \"message aggregation\" step more adaptable to the input. However, despite the naive assumption of graph topology, their better performance questions if the graph formation based on signals or learnable parameters is effective in the context of STLF. An interesting case is the BP-GNN model. Although it performs slightly worse than FC-GNN, it is more scalable since the interaction between the nodes of FC-GNN is N\u00b2, while for the BP-GNN model, it is only 2KN with K being the number of virtual nodes. It also outperforms other models most of the time. One reason might be that, due to the nature of the load profile dataset, the consumption pattern of users is grouped by latent factors such as socio-demographic status [28]. The virtual nodes defined by the model can account for latent factors that can influence the original nodes (households). The bipartite topology allows these virtual nodes to gather information in a cluster-like manner; then, the aggregated information is passed down to each node as additional information for learning."}, {"title": "4.3 Model benchmark with different temporal scale at the aggregate level", "content": "We investigate the performance of load forecasting at the aggregate level simply by aggregating all the forecasts at the residential level (see Table 4). At the aggregate level, the forecast results obtained through aggregation are inferior to those of the baseline model (SeasonalNaive). This behavior is also observed in other deep learning models such as GRU and Transformer. To explain this behavior, we visualize in Fig.4 the histogram of the errors among all the households at peak hour (2013-12-23 19:00). The x-axis represents errors, the y-axis lists top-performing models (Table 4), and the z-axis shows frequency."}, {"title": "5 Conclusion", "content": "In this paper, we provide an overview of the literature on STGNNs in short-term load forecasting and benchmark selected algorithms. Our findings show that integrating spatial relationships with temporal features improves forecasting accuracy for household energy consumption compared to models using only temporal features. Nevertheless, the most effective method for creating a graph to represent the proximity of energy consumption among households remains undetermined, given that even rudimentary graphs, like bipartite or fully connected graphs, can perform better than signal-based graphs. We also discuss how different components of STGNNs can affect the performance of models. Notably, bipartite graphs effectively capture energy consumption dynamics, outperforming direct relationships from raw signals or embeddings.\nHowever, at the aggregate level, simple models such as SeasonalNaive outperform STGNN models.\nHowever, our research has its limitations; we acknowledge that, for instance, our forecasting scenarios focus on one forecasting horizon (day ahead), which may not provide a comprehensive comparison of the strengths and weaknesses of the models. Furthermore, we did not consider the incorporation of exogenous variables into the STGNN models. Since energy consumption is significantly influenced by exogenous factors, such as weather or time indicators, the inclusion of these variables could improve model performance and provide deeper insight. Finally, given the growing scientific literature around STGNN for residential STLF, our selected models for benchmarking may not represent the entire research landscape in this domain. We believe that this incompleteness can motivate future research to provide a broader overview of STGNN into the residential STLF problem."}, {"title": "Declaration of Generative AI and AI-assisted technologies in the writing process", "content": "Statement: During the preparation of this work, the author(s) used ChatGPT [33] to paraphrase and fix grammatical mistakes. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication."}]}