{"title": "An Adaptive Framework for Multi-View Clustering Leveraging Conditional Entropy Optimization", "authors": ["Lijian Li"], "abstract": "Multi-view clustering (MVC) has emerged as a powerful technique for extracting valuable insights from data characterized by multiple perspectives or modalities. Despite significant advancements, existing MVC methods struggle with effectively quantifying the consistency and complementarity among views, and are particularly susceptible to the adverse effects of noisy views, known as the Noisy-View Drawback (NVD). To address these challenges, we propose CE-MVC, a novel framework that integrates an adaptive weighting algorithm with a parameter-decoupled deep model. Leveraging the concept of conditional entropy and normalized mutual information, CE-MVC quantitatively assesses and weights the informative contribution of each view, facilitating the construction of robust unified representations. The parameter-decoupled design enables independent processing of each view, effectively mitigating the influence of noise and enhancing overall clustering performance. Extensive experiments demonstrate that CE-MVC outperforms existing approaches, offering a more resilient and accurate solution for multi-view clustering tasks.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent times, multi-view data has become increasingly prevalent, with each instance being described from multiple perspectives or modalities [1]. However, the lack of reliable labeled data makes it challenging to extract useful information from multi-view data. To address this issue, researchers have proposed an effective self-supervised clustering technique known as multi-view clustering (MVC), which is used to identify pattern structures in various unlabeled data, particularly in fields such as medical image analysis and drug discovery [2], [3]. Numerous methods [4]\u2013[6] based on graph learning, subspace learning, and matrix factorization have been introduced and achieved some success with multi-view data. Additionally, deep learning-based MVC methods [7]\u2013[11], utilizing self-supervised techniques such as adversarial learning and self-training, have also garnered significant attention.\n The integration of evidence-based learning approaches [12], [13] into MVC has proven useful in enhancing the accuracy and robustness of clustering. By leveraging evidence from different modalities or views [14]-[16], the model can better understand the underlying relationships between data points, which is particularly important for classification tasks [17], [18] where precise decision boundaries are essential. In particular, evidence aggregation strategies, such as those based on consensus or majority voting, have been shown to improve the final cluster quality by reducing the impact of noisy or ambiguous data from individual views.\n Furthermore, the application of visual models in MVC has seen notable advancements [19], [20]. Convolutional neural networks (CNNs) [21] and transformer-based architectures, which are well-known for their strength in visual perception tasks, have been incorporated into multi-view clustering frameworks to handle image data. These models not only help extract rich visual features from each view but also facilitate the alignment of information across views, contributing to more accurate and consistent clustering results. The synergy between visual models and MVC can particularly benefit domains like medical imaging, where fine-grained classification and robust clustering are critical for tasks such as disease detection or organ segmentation.\n The effectiveness of current MVC approaches stems from their ability to leverage both consistency and complementarity [10], [22], [23] inherent in multi-view data, leading to superior performance compared to single-view clustering (SVC) methods. Consistency refers to the shared information across multiple views that aids in identifying the same category. For instance, consistent categorical information across different views can enhance the understanding of category semantics, thereby reducing the impact of irrelevant or non-semantic data. Complementarity, on the other hand, suggests that diverse views offer supplementary information that can mutually correct and enhance each other [24], [25]. By integrating these different perspectives, it becomes possible to uncover category structures that remain hidden when considering individual views alone. Despite these advantages, a significant challenge remains: the concepts of consistency and complementarity across multiple views are still conceptually abstract and difficult to quantify. Beyond the abstract attributes of multi-view data, the presence of noisy views significantly exacerbates the complexity of clustering tasks. Unlike informative views that contribute complementary insights, thereby facilitating the accurate identification of shared categories, the information derived from noisy views is not only irrelevant but may also mislead existing semantic representations, ultimately resulting in a deterioration of clustering performance, which is entitled as Noisy-View Drawback (NVD). For existing MVC methods [26], NVD undermines their effectiveness because they often rely on shared neural networks to fuse representations across views. When clustering objectives prioritize the noisy view, the shared parameters tend to overfit this view, neglecting valuable information from more informative views. Additionally, enforcing consistent clustering predictions across all views [6], [10], [27]-[29], including the noisy ones, can degrade the overall representation learning and clustering performance."}, {"title": "II. METHODS", "content": "In this paper, to address these issues, we propose a quantifiable multi-view clustering framework, CE-MVC, which integrates an adaptive weighting algorithm with a parameter-decoupled deep model. Inspired by entropy [30]-[35] as a measure of information content, we design a conditional entropy metric to quantify complementary information within each view. This metric, combined with NMI, is used to weigh views during the formation of a unified representation. To address the Noisy-View Drawback (NVD) issue, we propose a parameter-decoupled deep model that processes data representations and generates soft labels for different views, aiming to effectively mitigate the adverse impact of noisy views on the overall clustering performance."}, {"title": "A. Annotation", "content": "We consider a multi-view dataset denoted as {X \u2208 $\\mathbb{R}^{N\\times D}$}$_{V=1}^{V}$, comprising N samples observed from V distinct views. For each view v, the learned feature representations and corresponding soft labels are represented by R\u201d \u2208 $\\mathbb{R}^{N\\times d_v}$ and SL$^{v}$ \u2208 $\\mathbb{R}^{N\\times K}$, respectively. $D_{v,d}$ indicate the dimensionality of input data $X^v$ and the latent representation $R^v$ for the v-th view. The parameter K refers to the number of clusters."}, {"title": "B. Preliminary", "content": "The learning paradigm in MVC typically involves learning feature representations R and soft labels SL, followed by using fusion strategies (e.g., early or late fusion) to leverage valuable information across views. Despite advancements in weighting strategies to account for view diversity, most MVC methods rely on shared network parameters and consistent clustering across views, which can lead to reduced robustness, especially when faced with low-quality or noisy views. The common clustering objective for them is defined as follows:\n\nmin \u2211 ||T \u2013 $F_{\\Theta}$(SL$^{v}$ | {$R^v$}$_{v=1}^{V}$)||, \n\nwhere {$R^v$}$_{v=1}^{V}$ denotes feature representations of all views and $F_{\\Theta}$(Y$^{u}$ | {$R^v$}$_{v=1}^{V}$) indicates that soft labels are derived through the fusion module Fapplied to the representations {$R^v$}$_{v=1}^{V}$ using the parameter set $\\Theta$ shared across all views. The matrix T serves as a unified learning target to ensure consistency in the soft labels {SL$^{v}$}$_{v=1}^{V}$ across all views."}, {"title": "C. Asymptotic adaptive weighting optimization based on conditional entropy", "content": "To eliminate the reliance on shared networks and parameters, we propose an asymptotic adaptive weighting strategy based on conditional entropy to effectively leverage the complementary and consistent information in multi-view data. This strategy involves learning a reliable target T while keeping model parameters fixed, thereby ensuring the condition of parameter decoupling is met. We define a weighting matrix $W^{(t)}$ to automatically explore the complementary information within each view at t-th iteration, quantified by specifically designed conditional entropy and NMI metrics. Subsequently, The weighting matrix is then used to produce well-scaled feature representations $R^{(t)}$, which are utilized to generate reliable soft labels SL$^{t}$ and learning targets T$^{t}$.\n Specifically, in the initial iteration, we assume that the amount of effective information across all views is equivalent. Therefore, we initialize a diagonal weighting matrix with values set to 1, corresponding to the weight of each view. This weighting matrix $W^{(t)}$ \u2208 $\\mathbb{R}^{\\sum_{v} d_v \\times \\sum_{v} d_v}$ is then used to generate scaled feature representation $R^{(t)}$ \u2208 $\\mathbb{R}^{N\\times \\sum d_v}$ by adjusting the latent representations of each view accordingly, which is formulated as:\n\n$R^{(0)}$ = O($W^{(0)}$ | $R^{(t)}$, $R^1$, $R^2$, \u2026, $R^V$)\n\nIn the t-th iteration, We first utilize weight matrix $W^{(t)}$ generated from t \u2212 1-th iteration to weight current feature representations of each view. Then, the optimized feature representations $R^t$ are employed to further refine weight matrix $W^{(t)}$. The conditional entropy for $R^v$ is calculated. When calculating the entropy of feature representations, we typically use kernel density estimation (KDE) to estimate the entropy. Therefore, the entropy formula based on KDE is defined as follows:\n\n$\\mathcal{E}(R) = - \\int p(R) \\log p(R) dR$\n\nwhere p(R) denotes the probability density function of feature representation. To compute the conditional entropy for the current view $R^v$, we first concatenate its feature representation with that of another view $R^u$ and calculate the entropy of the combined representation, $\\mathcal{E}(R^v, R^u)$. We then subtract the entropy of $R^u$ alone, $\\mathcal{E}(R^u)$, to obtain the partial conditional entropy for $R^v$ relative to $R^u$. The total conditional entropy for $R^v$, denoted as $\\mathcal{E}(R^v | {$R^u$}$_{u \\neq v}$), is computed by summing all these partial conditional entropies:\n\n$\\mathcal{E}(R^v|{$R^u$}$_{u \\neq v}) = \\sum_{u \\neq v} [\\mathcal{E}(R^v, R^u) \u2212 \\mathcal{E}(R^u)]$\n\nIf the current view contains complementary information that is useful for the other views, its conditional entropy will be relatively low. Conversely, if the current view is a noisy one, its conditional entropy will be the highest, as it lacks any complementary information. Thus, conditional entropy effectively quantifies the extent of complementary information shared among different views.\n Except for the derivation of conditional entropy, the scale feature representation $R^t$ is also utilized to generate reliable soft labels SL$^{(t)}$ \u2208 $\\mathbb{R}^{N\\times K}$, which encapsulates the shared cluster structure of $R^t$. Previous approaches predominantly utilize NMI to assess the similarity between clustering outcomes from individual views and the unified clustering result, subsequently applying it as a weighting factor. However, NMI primarily captures the consistency between clustering results, thereby failing to capture the complementary information across different views. Relying exclusively on NMI for weighting might lead to the underestimation of views that, despite having lower NMI scores, contribute significant complementary information, potentially overlooking critical data that can enhance clustering performance. To address this limitation, we propose integrating conditional entropy with NMI to generate a weight matrix $W^{(t+1)}$ = K($W^{(t+1)}$ | SL$^{t}$, SL$^1$, SL$^2$, \u2026\u2026\u2026, SL$^V$) that simultaneously accounts for both consistency and complementarity of views, which is formulated as follows:\n\n$W^{(t+1)} = \\frac{exp(\\frac{\\mathcal{E}(SL^{t}) + \\mathcal{E}(SL^{v})}{2M})-1}{Norm(\\mathcal{E}(R^v|{$R^u$}$_{u \\neq v}))} \\in W^{(t+1)}$\n\nwhere M, E denotes mutual information and entropy, and Norm represents normalization. The rationale for using conditional entropy in the denominator lies in the observation that views offering significant complementary information are characterized by lower conditional entropy, while those with less complementary information exhibit higher conditional entropy. Consequently, when a view demonstrates limited consistency but substantial complementarity, the division by a relatively low conditional entropy serves to amplify its weight, thereby effectively balancing and integrating both consistency and complementarity in the weighting process."}, {"title": "D. Parameter-decoupled models", "content": "Previous asymptotic adaptive weighting optimization is designed to learn a reliable learning objective T while keeping model parameters fixed. Subsequently, within the parameter-decoupled model, we aim to train different parameters {$\\Theta^v$}$_{v=1}^{V}$ for individual views by optimizing the clustering objective, which is defined as follows:\n\n$\\mathcal{L}_c = \\min_{\\Theta^v} || T^u \u2212 F_{\\Theta^v}(SL^v|R^v)||$.\n\nBuilding on some existing deep MVC methods [11], [36]-[39], we employ deep autoencoders\u2014a widely used self-supervised representation learning technique to extract new representations from multi-view data. $H_{\\Omega^v}$ and $D_{\\Delta^v}$ represent the encoder and decoder for the v-th view, respectively. Due to the unshared network parameters $\\Omega^v$ and $\\Delta^v$ for each view, the reconstruction $\\hat{X^v} = D_{\\Delta^v} (H_{\\Omega^v} (X^v))$ relies solely on its representation $R^v = H_{\\Omega^v} (X^v)$. Therefore, the corresponding representation learning objective $\\mathcal{L}_r$ is defined as follows:\n\n$\\mathcal{L}_r = \\min_{\\{\\Omega^v, \\Delta^v\\}} ||X^v - D_{\\Delta^v} (H_{\\Omega^v} (X^v))||$.\n\nAnd the loss function for training the parameter-decoupled model of each view is composed of two parts:\n\n$\\mathcal{L} = \\mathcal{L}_c + \\lambda \\mathcal{L}_r$.\n\nwhere The parameter \u03bb balances the trade-off between the reconstruction loss $\\mathcal{L}_r$ and the clustering loss $\\mathcal{L}_c$. In this context, different views can't interfere with each other during the training of their respective network parameters, which can be formulated as:{$\\Theta^i$, $\\Omega^i$, $\\Delta^i$} \u2229 {$\\Theta^j$, $\\Omega^j$, $\\Delta^j$} = \u00d8,\u2200i \\neq j, i, j\u2208 {1,2,..., V}. In this process, parameter-decoupled models further refine the representations and soft labels {$R^v$, SL$^v$}$_{v=1}^{V}$, which are then used to improve the learning target T. Finally, the clustering results for all multi-view data are produced by SL$^{(t)}$."}, {"title": "III. EXPERIMENTS", "content": "1) Datasets: To evaluate the performance of the proposed framework, we conduct experiments on two normal multi-view clustering datasets (including DIGIT and COIL) which are easy for clustering, as well as their noise-contaminated versions. The noise-contaminated datasets are constructed by constructing an additional view with randomly sampled noise for each dataset, effectively testing the robustness of our model under extreme circumstances. In addition, several real-world multi-view datasets that are challenging for clustering are utilized to further verify the performance, such as RGB-D and Caltech, which are hard for clustering.\n 2) Compared methods: We compare our proposed CE-MVC with ten state-of-the-art self-supervised clustering algorithms. Specifically, DEC [40] is a well-established deep SVC method that we use as a baseline to assess the impact of NVD on MVC methods. Among the compared methods, DMJC [38], DIMC-net [37], GP-MVC [36], DIMVC [42], and SDMVC [39] are deep MVC approaches that extend DEC, often employing consistent soft labels to ensure clustering consistency. Additionally, DMJC [38], DIMC-net [37], GP-MVC [36], and DSMVC [10] incorporate weighting strategies to derive fused representations. On the other hand, CoMVC [41], DSIMVC [11], and CPSPAN [28] are deep MVC methods based on contrastive learning which is capable of learning shared representations across multiple views."}, {"title": "B. Comparison Results and Analysis", "content": "Tables I and II provide a comprehensive comparison of clustering performance across various datasets, evaluated using clustering accuracy (ACC) and normalized mutual information (NMI). DEC-BestV and DEC-WorstV represent the results of the SVC method DEC on the best and worst views, respectively. The significant performance drop observed in DEC-WorstV across all datasets, such as the 68.5% decrease in ACC and 78.5 in NMI on the NoisyDIGIT dataset, highlights the variability in view quality and the challenges posed by noisy views in multi-view clustering. However, on datasets like COIL and NoisyCOIL, some MVC methods, including GP-MVC, exhibit performance degradation compared to DEC-BestV, with ACC dropping by 31.8% on NoisyDIGIT and NMI by 15.4. Despite these challenges, CE-MVC consistently outperforms DEC-BestV and most other MVC methods, demonstrating significant improvements across all datasets, such as a 23.3% increase in ACC and an 18.4 boost in NMI on the COIL dataset. In simulated noisy environments, CE-MVC further proves its robustness by surpassing the best comparison methods with substantial gains, particularly on NoisyDIGIT, where it achieves an 18.8% improvement in ACC and 20.2 in NMI. Additionally, CE-MVC consistently outperforms all other methods across two real-world datasets, achieving the highest ACC and NMI scores. Particularly on the Caltech dataset, CE-MVC improves ACC by 5.6% and NMI by 7.5. In contrast, traditional single-view methods like DEC-WorstV show significantly poor performance in noisy view scenarios, with notable drops in both ACC and NMI. This consistent performance superiority indicates CE-MVC's ability to effectively handle noisy views and extract useful, complementary information, making it highly effective in both simulated and real-world multi-view clustering scenarios.\n To further validate the effectiveness of the CE-MVC framework, we visualize the clustering results on the DIGIT and COIL datasets, as well as their corresponding noise-contaminated versions, as shown in Figure 1. It can be observed that despite the noise introducing some disturbance to the clustering boundaries, the model is still able to achieve distinguishable clustering boundaries, suggesting the robustness of the CE-MVC framework under challenging conditions."}, {"title": "C. Ablation study", "content": "Table III presents the results of an ablation study conducted to assess the impact of different weighting strategies on the performance of the CE-MVC framework, on RGB-D and Caltech datasets. The table evaluates three distinct strategies: NMI, Exponential NMI (ENMI), and Conditional Entropy (CE). It can be observed that when both ENMI and CE are employed together as weighting strategies, the results show further improvement, particularly evident in the RGB-D dataset where ACC and NMI increase to 49.6% and 42.6%, respectively, which confirms that simultaneously considering NMI and conditional entropy metrics allows for better utilization of valuable consistency and complementarity information from different views for clustering."}, {"title": "IV. CONCLUSION", "content": "This study proposes CE-MVC, a robust multi-view clustering framework that optimizes clustering performance by addressing view consistency, complementarity, and noise. Using parameter-decoupled model and adaptive weighting based on conditional entropy and NMI, CE-MVC outperforms existing methods, particularly in noisy settings, making it an effective solution for complex clustering tasks."}]}