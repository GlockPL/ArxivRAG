{"title": "AGENT SKILL ACQUISITION FOR LARGE LANGUAGE MODELS VIA CYCLEQD", "authors": ["So Kuroki", "Taishi Nakamura", "Takuya Akiba", "Yujin Tang"], "abstract": "Training large language models to acquire specific skills remains a challenging endeavor. Conventional training approaches often struggle with data distribution imbalances and inadequacies in objective functions that do not align well with task-specific performance. To address these challenges, we introduce CycleQD, a novel approach that leverages the Quality Diversity framework through a cyclic adaptation of the algorithm, along with a model merging based crossover and an SVD-based mutation. In CycleQD, each task's performance metric is alternated as the quality measure while the others serve as the behavioral characteristics. This cyclic focus on individual tasks allows for concentrated effort on one task at a time, eliminating the need for data ratio tuning and simplifying the design of the objective function. Empirical results from AgentBench indicate that applying CycleQD to LLAMA3-8B-INSTRUCT based models not only enables them to surpass traditional fine-tuning methods in coding, operating systems, and database tasks, but also achieves performance on par with GPT-3.5-TURBO, which potentially contains much more parameters, across these domains. Crucially, this enhanced performance is achieved while retaining robust language capabilities, as evidenced by its performance on widely adopted language benchmark tasks. We highlight the key design choices in CycleQD, detailing how these contribute to its effectiveness. Furthermore, our method is general and can be applied to image segmentation models, highlighting its applicability across different domains\u00b9.", "sections": [{"title": "1 INTRODUCTION", "content": "Large Language Models (LLMs) have established themselves as powerful tools in the machine learning and artificial intelligence landscape, initially gaining prominence through their effectiveness in conversational tasks (Achiam et al., 2023). As the demand grows for LLMs to perform a broader range of cognitive tasks, the ability to integrate linguistic understanding with actionable outputs becomes essential. This integration facilitates the creation of intelligent LLM-based agents, making continual agentic fine-tuning a critical development in the field (Gur et al., 2023; Liu et al., 2023b; Xi et al., 2023; 2024; Wang et al., 2024b). However, training LLMs to acquire various agent skills presents two major challenges that complicate their development.\nA significant difficulty arises from the need to balance data ratios during training, to ensure that the model learns effectively from datasets representing different skills without favoring any particular"}, {"title": "2 RELATED WORKS", "content": "LLM Skill Acquisition: Beyond conversational tasks, increasing attention has been given to enabling LLMs to acquire skills to take action. This allows LLMs to function as agents capable of solving problems autonomously, and this approach is known as LLM-as-Agent (Xi et al., 2023; Wang et al., 2024b). Benchmarks for LLM-as-Agent have been developed, and research has demonstrated that LLMs can successfully perform tasks such as computer operations and web browsing to a certain extent (Gur et al., 2023; Liu et al., 2023b; Xi et al., 2024; Xu et al., 2024; Tan et al., 2024; Ye et al., 2024). ReAct (Yao et al., 2023) is the most frequently used approach for constructing LLM-as-Agent systems, which integrates CoT reasoning with action. ReAct is typically employed through prompting and few-shot in-context learning, where models learn skills from a small number of examples. However, attempts to equip LLMs with such skills through actual training with more examples are still quite limited, with a few studies focusing only on standard fine-tuning (Zeng et al., 2024; Qin et al., 2024). This fine-tuning approach often struggles with balancing multiple agent skills and suffers from the gap between next token prediction loss and actual task performance. Our proposed method uses QD techniques to optimize each skill independently and directly.\nQuality Diversity: QD is an emerging paradigm in evolutionary computation that aims to discover a diverse collection of high-performing solutions rather than a single optimal result (Pugh et al., 2016). QD algorithms balance two key aspects: quality, which represents a solution's performance, and behavior characterization (BC), which describes its observable properties. These algorithms maintain an archive of diverse, high-quality solutions, continuously updated through an evolutionary process. MAP-Elites (Mouret & Clune, 2015) is a prominent QD algorithm that maintains an archive defined by the BCs, discretizes it into tessellation, and stores the best-performing solutions in each cell to preserve diversity. In each generation, it samples parents from the archive, creates offspring through crossover and mutation, and evaluates their quality and BCs. Offspring replace existing elites if they perform better in their respective cells. This process simultaneously explores diverse behaviors and optimizes performance within each niche, resulting in a map of high-quality, diverse solutions. Recent improvements to MAP-Elites include a new selection method for better diversity (Wang et al., 2023) and an approach that removes the need for predefined niches (Wickman et al., 2023). Additionally, MOQD (Pierrot et al., 2022) has been proposed to address problems with multiple, potentially conflicting objectives while maintaining diversity. Instead of the fitness, it maximizes a Pareto front hyper-volume in each niche of the descriptor space. CycleQD is a simplified form of MOQD in the sense that it uses task metrics as both BCs and the quality, the product of which approximates the hyper-volume, and the coordinate-ascent style of optimization allows it to avoid complex hyper-volume calculations for higher-dimensional archives.\nQuality Diversity for LLMs: Evolutionary computation, particularly QD, has occasionally been applied to neural networks and LLMs (Guo et al., 2024; Xue et al., 2024; Akiba et al., 2024). However, there has been no prior research that evolves the main weights of LLMs using QD. Samvelyan et al. (2024) proposed Rainbow Teaming, which applies QD to evolve diverse adversarial prompts for evaluating LLM safety. Bradley et al. (2024) introduced QDAIF, which applies QD with LLM feedback to evolve populations of generated creative texts. Our work represents the first attempt to merge LLMs through QD. We believe this approach holds great promise, as it allows individual components of the model to be preserved even when they are temporarily sub-optimal, with the potential to contribute to future performance improvements. Given the cost and complexity of optimizing the many layers of LLMs, QD offers a unique advantage by retaining useful configurations in archives that may later enhance overall model performance.\nModel Merging: Model merging refers to combining multiple pre-trained models into a single model. This technique is gaining attention because it can enhance model performance and integrate multiple capabilities at a much lower training cost. Additionally, unlike ensemble methods, model merging does not increase inference costs either. This technique is particularly effective when applied to different fine-tuned versions of the same base model. The most basic method involves a linear combination of weights (Wortsman et al., 2022; Ilharco et al., 2023). More advanced merging techniques have been proposed, incorporating methods such as election and sparsification (Yadav et al., 2023; Yu et al., 2024; Wang et al., 2024a; Stoica et al., 2024). Furthermore, the applicability and performance of these methods have been significantly improved through optimization (Akiba et al., 2024; Yang et al., 2024). Inspired by these merging strategies, CycleQD combines QD with model merging, allowing for more effective synthesis of multiple capabilities in LLMs."}, {"title": "3 METHODS", "content": "To avoid the laborious tuning of the data mixing ratio and the objective function, we introduce CycleQD. It is built on MAP-Elites, a recognized implementation of QD, but distinguishes itself from traditional MAP-Elites systems in three key ways (see Algorithm 1 for the pseudo-code):\n1.  Alternating Quality and BCs: Pugh et al. (2016) emphasizes the importance of well-aligned BCs with the quality (i.e., task metric that needs to be optimized). Traditional systems typically set the design at the onset and do not alter them throughout the QD process. In contrast, CycleQD uses task metrics as both quality and BCs, ensuring alignment and dynamically alternating them during the QD process (lines 6-7 in Algorithm 1).\n2.  Model Merging as Crossover: Unlike existing systems that optimize model parameters directly, CycleQD leverages a model merging algorithm as a crossover operation, replacing the heuristic, hand-designed rules often seen in practice (line 12 in Algorithm 1). In CycleQD, we fine-tune expert agents, each of which only needs to specialize in one task, and use them as the seed models to initialize the model archives (lines 2-4 in Algorithm 1).\n3.  SVD-based Mutation: Traditional mutation operations in genetic algorithms like MAP-Elites typically introduce random perturbations from a pre-defined distribution to explore new regions. In contrast, CycleQD utilizes perturbations aligned with the principal components of the models' parameters matrices, facilitating exploration outside the convex regions formed by the parent models while avoiding overfitting (line 13 in Algorithm 1)."}, {"title": "3.1 ALTERNATING QUALITY AND BEHAVIOR CHARACTERISTICS", "content": "CycleQD manages $K$ archives, each dedicated to tracking the LLMs that specialize in one of the $K$ agent skills. Each archive evaluates LLM performance using $K$ tasks, which serve dual roles as both the quality and BCs. An archive is structured as a lattice, the size of which is defined by $\\prod_{k\\neq i} d_k$, where $d_k$ is the number of bins defined by the $k$-th BC, and the $i$-th BC is excluded from this particular archive as it is treated as the quality metric. In generation $t$, the $i$-th archive is selected for QD computation where $i = t \\mod K$ (see Figure 1 for an illustration with $K = 3$). This process utilizes all available data from the $K$ tasks to evaluate and update the archives without the need for adjusting data ratios or objective functions.\nCycleQD shares knowledge across $K$ archives for efficient optimization. Specifically, in generation $t$, a new model is created from the $i$-th archive by sampling, crossover, and mutation. This model is used to update not only the $i$-th archive but all $K$ archives (lines 14-15 in Algorithm 1). This allows for more effective utilization of the new model and helps facilitate optimization across $K$ tasks."}, {"title": "3.2 MODEL MERGING BASED CROSSOVER", "content": "Training an LLM to specialize in a single task does not suffer from problems such as the data ratio tuning, the complex combinations of objective functions, and etc. It is therefore straightforward to initially train a set of single-task experts using conventional fine-tuning methods, and then use model merging algorithms to develop more capable agents. In CycleQD, our model merging crossover operator employs the parameter space merging scheme described in Akiba et al. (2024), which creates a new model by merging task vectors at the model level (Ilharco et al., 2022). Specifically, for a pre-trained base LLM with parameters $\\theta_{base} \\in \\mathbb{R}^{d}$ and its fine-tuned LLM with parameters $\\theta \\in \\mathbb{R}^{d}$, we define a task vector as $\\tau = \\theta - \\theta_{base}$. The crossover operator then generates a model's parameters by combining these task vectors: $\\theta_{child} = \\theta_{base} + (\\frac{w_1}{w_1 + w_2}) \\tau_{p_1} + (\\frac{w_2}{w_1 + w_2}) \\tau_{p_2}$, where $\\tau_{p_1}$ and $\\tau_{p_2}$ are the parents' task vectors. Here, $w_1$ and $w_2$ are i.i.d samples from $\\mathcal{N}(\\mu, \\sigma^2)$, and $(\\mu, \\sigma)$ are predetermined hyper-parameters that remain fixed during the experiments. We normalize $(\\tau_{p_1}, \\tau_{p_2})'$s mixing coefficients to ensure the merged weights do not become outliers and cause problems for the downstream layers.\nAdditionally, there is potential to enhance the model merging process by training a neural network policy $(\\mu, \\sigma) \\leftarrow \\pi_{\\phi}(\\{bc_1,..., bc_k\\}_{p_1}, \\{bc_1,..., bc_k\\}_{p_2})$ that learns the optimal distribution parameters conditioned on the BC grid IDs $\\{bc_1, ..., bc_k\\}$ of the parents ($k = K-1$ in total for each parent because one serves as the quality). However, while this approach could improve the efficiency of model merging, it also introduces a greater initial learning burden in CycleQD."}, {"title": "3.3 SVD-BASED MUTATION", "content": "The formulation of our model merging based crossover bears one obvious limitation: The construction of $\\theta_{child}$ is a linear combination of $(\\tau_{p_1}, \\tau_{p_2})$, which are themselves linear combination of their parents. The entire process then reduces to finding the optimal linear combination of the expert models' parameters. Due to this, $\\theta_{child}$ will likely be trapped in the \u201cconvex region\" in the performance space formed by the expert models, yet extrapolation that leads to improved performance is desired. We introduce a mutation function $\\theta_{child} = h(\\theta_{child})$ after the crossover to get rid of this limitation.\nIn conventional methods, the mutation function $h(\\theta_{child})$ is often an operator that samples perturbations from a pre-defined distribution (e.g., Gaussian with pre-determined mean and covariance matrix) and add them to the gene being mutated. We find this setting introduce excess freedom and lead to overfitting in the final model. Instead, we propose to sample perturbations along the \u201cdirections\" of the components from the model's parameter matrices. This mutation operation is mathematically defined as: $h(\\theta_{child}) = \\theta_{base} + \\text{concat}([U_l(\\Sigma_l w)V_l^\\dagger]_{l=1}^L)$, where $U_l \\in \\mathbb{R}^{m \\times r}$, $\\Sigma_l \\in \\mathbb{R}^{r \\times r}$ and $V_l \\in \\mathbb{R}^{n \\times r}$ are the SVD components of $\\tau_l = U_l \\Sigma_l V_l^\\dagger$, the $l$-th parameter matrix in the task vector $\\tau_{child} = \\theta_{child} - \\theta_{base}$ (i.e., $\\tau_l$ is a reshaped subarray of $\\tau_{child}$). The perturbation vector $w \\in \\mathbb{R}^{r}$ is sampled from a uniform distribution of boundaries $[0, W_{max}]$, where $W_{max} \\in \\mathbb{R}^+$ is a hyper-parameter. Our SVD-based mutation becomes a pass-through operation for parameter matrices whose rank is one (e.g., those belonging to layer-normalization layers)."}, {"title": "3.4 MODEL AGGREGATION", "content": "CycleQD maintains $K$ archives during the optimization process, LLMs in each of these archives are trained to acquire one of the $K$ agent skills. In the end, CycleQD returns hundreds or even thousands of LLM agents with various specialties and characteristics. These LLM-based agents are versatile and can facilitate multi-agent research in a diverse set of directions (we discuss this topic in Section 5). On the other hand, an aggregated LLM agent that possesses the top skills acquired by the best models in each archive is useful on its own and is important for the evaluation of CycleQD.\nOur model aggregation algorithm is straightforward, and can be summarized as: $\\theta_{agg} = \\theta_{base} + \\sum_{k=1}^{K} \\beta_k T_k$, where $T_k$ is the task vector from the elite model in the $k$-th archive, with ties resolved by selecting the most recent model. $\\beta_k = \\text{exp}(f_k) / \\sum_i \\text{exp}(f_i)$ (i.e., softmax function) is the mixing coefficient calculated from the elite model's task performance $f_k$ in the $k$-th archive. In this paper, all experimental results from CycleQD are produced with this aggregated model $\\theta_{agg}$."}, {"title": "4 EXPERIMENTS", "content": "We evaluate CycleQD extensively and conduct analysis to answer the following questions:\n*   Does CycleQD allow LLMs to effectively acquire various agent skills? If so, how good is it when compared with baseline methods?\n*   What are the critical design choices that lead to its effectiveness?\n*   What are the benefits and limitations of CycleQD?"}, {"title": "4.1 EVALUATION ON COMPUTER SCIENCE TASKS", "content": null}, {"title": "4.1.1 TASK DESCRIPTION", "content": "In this experiment, our goal is to train LLMs to master three agent skills in computer science: coding, Operation System (OS) manipulation and Database (DB) query generation. We adopt the MBPP+ (Mostly Basic Python Programming) dataset from EvalPlus (Liu et al., 2023a) for coding skill development, and utilize the OS and DB datasets from AgentBench (Liu et al., 2024) for training. For the coding task, we optimize and report the pass@1 metric, whereas in OS and DB tasks we use the success rate. Please refer to Appendix A.1.1 for extra and detailed task related setups."}, {"title": "4.1.2 CYCLEQD SETUPS", "content": "Experts: We employ LLAMA-3-8B-INSTRUCT MODEL (Dubey et al., 2024) as our base model, and use supervised fine-tuning to create LLM experts in coding, OS and DB. For the OS and DB experts, we use the OS and DB training datasets from Agent-FLAN Chen et al. (2024). The coding expert is fine-tuned on a combination of the MAGICODER-EVOL-INSTRUCT-110K and MAGICODER-OSS-INSTRUCT-75K datasets (Wei et al., 2024). See detailed configuration in Appendix A.1.2"}, {"title": "4.1.3 BASELINES", "content": "Our baselines can be categorized into fine-tuning based and merging based models.\nFine-tuning Based Models: These are models 3-6 in Table 1. In addition to the expert LLMs mentioned earlier, we also combine all the data from the three tasks (including the extra MAGICODER-EVOL-INSTRUCT-110K and MAGICODER-OSS-INSTRUCT-75K datasets) and continue training the LLAMA3-8B-INSTRUCT base model with supervised fine-tuning to develop an extra baseline (model 6 in Table 1). In this baseline, we don't tune the data ratio and use cross-entropy (i.e., next token prediction) as our objective function.\nMerging Based Models: These are models 7-9 in Table 1. We first introduce a naive merging method where the merged model is produced by taking an average of the three experts' task vectors (model 7). Similar to this baseline, we introduce two additional learning based model merging methods where, instead of taking an average, the coefficients of a linear combination of these task vectors is learned through gradient descent on policy gradients (model 8), and CMA-ES, an evolutionary algorithm on the raw rewards (model 9) separately."}, {"title": "4.1.4 RESULTS", "content": "Overall: We summarize our results from this experiment in Table 1. In addition to the baselines, we also include the base model and the GPT models for references (highlighted with a lightgray background). The first thing to notice is that each expert model (models 3-5), fine-tuned specifically for its assigned task, performs better than the LLAMA3-8B-INSTRUCT base model (model 2), laying the stepping stones for CycleQD and other model merging based methods. After evolutionary computing, our method, averaged across the three tasks, outperforms all baselines, and is approaching the performance of GPT-3.5-TURBO. Specifically, CycleQD achieves the highest scores on the coding and the OS tasks among the baselines, and has only a mild performance drop on the DB tasks compared with the expert. Figure 3 gives the archives in CycleQD at the end of the experiment. It is easy to see that CycleQD has managed to \"illuminate\" the three archives.\nComparison with Fine-tune Based Methods: A notable result from the table is that, the model fine-tuned on all the datasets (model 6) is only partially and marginally better than the three experts,"}, {"title": "4.1.5 ABLATION STUDIES", "content": "To get insights into the design choices in CycleQD and show how they contribute its effectiveness, we conduct a series of ablation studies and summarize the results in Table 2.\nCycleQD vs QD: We compare conventional QD with CycleQD in trials 0 and 1. Specifically, we run QD for three runs. Within each run, one of the task's metric is treated as the quality while the others are regarded as the BCs. We control each trial to have an equal computing budget as for CycleQD, and all other hyper-parameters are identical to CycleQD. We use the same model aggregation method to merge the best models from these three runs (see Section 3.4). The better performance from CycleQD suggests the importance of alternating the quality and BCs.\nMutation Methods: We focus on the impact of different mutation operations with trials 1-3. Although we mentioned earlier that mutation helps the merged model extrapolate in the performance space, naively designed mutations give excess freedom and can lead to overfitting. This is what happens to trial 2, the performance of which is even worse than trial 1 that does not have any mutation operations. On the other hand, our SVD-based mutation (trial 3) successfully avoids the problem and delivers a much better performance.\nSampling Methods: Finally, we demonstrate the importance of Elite sampling in CycleQD in trial 4, which has the identical settings as model 10 in Table 1, and gives the best score in the ablation studies. Elite sampling is effective because it prioritizes merging high-performing models, the result of which helps expand the Pareto frontier in each archive more effectively."}, {"title": "4.1.6 SKILL GENERALIZATION AND LANGUAGE CAPABILITIES", "content": "In addition to agent skills, we evaluate our model on out-of-distribution coding tasks and language understanding across six categories, please see Appendix A.1.5 for detailed task descriptions. Table 3 shows the results across these tasks, where we normalize the scores against the LLAMA3-8B-INSTRUCT base model. On average, CycleQD outperforms the three fine-tuned experts, providing better overall generalization across tasks. Our method generalizes well on the coding tasks while retraining performance on language tasks. In contrast, the Coding expert, while delivering competitive scores on the coding tasks, shows significantly lower performance on specific tasks in the Reasoning category. This sharp decline in performance suggests the occurrence of catastrophic forgetting during fine-tuning, where the model loses its ability to generalize across tasks outside its specialization. These findings once again underscore the efficacy of CycleQD in achieving superior and more consistent performance across diverse tasks compared to traditional fine-tuning approaches."}, {"title": "4.2 EVALUATION ON IMAGE SEGMENTATION TASKS", "content": null}, {"title": "4.2.1 TASK DESCRIPTION", "content": "In addition to its applications for LLMs, CycleQD serves as a versatile method for integrating expert models across various data modalities beyond text. In this experiment, we extend CycleQD to the fusion of multiple Segment Anything Models (SAM), which are state-of-the-art computer vision models designed for image segmentation tasks. Specifically, our objective is to merge pairs of SAM models, A and B, to create models whose capabilities encompass the skill sets of both A and B."}, {"title": "4.2.2 CYCLEQD SETUPS", "content": "Experts: We select four tasks within the image segmentation domain, each supported by extensive datasets, for training specialized models: Camouflaged Object Segmentation (CAM), Polyp Segmentation (POL), Skin Lesion Segmentation (SKL), and Leaf Segmentation (LEA). CAM detects objects in cluttered environments, making segmentation more challenging than standard tasks. POL identifies polyps in endoscopic images, essential for early colorectal cancer detection. SKL detects various skin lesions in medical images. LEA identifies plant leaves in agricultural images, supporting disease control and improving crop quality. We employ SAM-ViT Huge model as our base model, which we fine-tune to develop these experts. See Appendix A.2.1 for details on the datasets used for fine-tuning and CycleQD setups.\nHyper-parameters: CycleQD's hyper-parameters remain the same as in Section 4.1.2."}, {"title": "4.2.3 RESULTS", "content": "Overall: Table 4 shows the performance of the models merged by CycleQD, where scores are normalized against the expert models. You can see visualization results in Appendix A.2.2. In general, CycleQD is able to merge the experts successfully, with top models retaining more than 90% of the experts' performance (e.g., models 0, 1, and 3). On the other hand, models 2, 4 and 5 are less successful. This leads us to conduct further analysis and we report the findings next.\nAnalysis: We report the similarities between experts A and B in the last column in Table 4. A strong correlation of 0.83 between the averaged scores and these similarities indicate both the limitations and potential areas for enhancement in CycleQD. We define the similarity between models A and B as the average cosine similarity of the singular value vectors (derived from the task vectors) across all layers in both models: $s = (1/L) \\sum_{i=1}^{L} cos(diag(\\Sigma_{i,A}), diag(\\Sigma_{i,B}))$. Here, L is the number of weight matrices with a rank greater than 1, and $\\Sigma_{i}$ denotes a diagonal matrix of singular values from the i-th weight matrix in the task vector. Although this summarizing metric does not fully encapsulate the models' characteristics, CycleQD tends to perform well when the models exhibit high similarity. This observation underpins our approach of incorporating this similarity metric as a regularization technique during model fine-tuning. Notably, a similar metric has been employed as the \"proximal term\u201d in optimizing heterogeneous networks within the realm of federated learning, as evidenced by research documented in (Li et al., 2020). This precedent lends credence to our strategy, suggesting it is grounded in established methodologies."}, {"title": "5 CONCLUSIONS AND FUTURE WORKS", "content": "In this work, we introduced CycleQD, a compelling modification of the conventional LLM fine-tuning pipeline, integrating evolutionary algorithms for agent skill acquisition. CycleQD begins with single-task experts and utilizes QD to continuously generate hundreds of LLM-based agents, possessing diverse characteristics and exhibiting a broader range of skills than the initial experts. Through a dynamic process that cyclically swaps quality and BCs, coupled with a model merging crossover operation and an SVD-based mutation operator, CycleQD has successfully enabled LLMs to master computer science skills. Our method not only outperforms baseline approaches but also achieves on-par performance with GPT-3.5-TURBO, while generalizing to out-of-distribution tasks and retaining the language capabilities. Furthermore, CycleQD's applicability extends across domains to image segmentation models, demonstrating its broad utility.\nIn terms of limitations, we acknowledge that the success of model merging hinges on the compatibility of the source models. CycleQD may encounter challenges when the expert models originate from highly divergent settings. One way to address this is incorporating model similarity as a regularization term during the expert training. Furthermore, this research represents an initial foray into the integration of QD and evolutionary model merging for agent skill acquisition. There is substantial potential for improvement by leveraging advanced methodologies from both fields, such as integrating strategies from CMA-ME (Fontaine et al., 2020) and PGA-MAP-Elites (Nilsson & Cully, 2021) to enhance the efficiency of the learning process. Looking ahead, a promising direction for future research lies in multi-agent systems. Considering CycleQD generates an archive of diverse agents, orchestrating these agents to collaborate and compete opens up exciting possibilities for scientific exploration and practical applications."}, {"title": "A APPENDIX", "content": null}, {"title": "A.1 COMPUTER SCIENCE TASKS", "content": null}, {"title": "A.1.1 EXTRA TASK SETUPS", "content": "The MBPP+ dataset, based on the original MBPP, uses a subset of 399 hand-verified problems from MBPP-sanitized to ensure well-formed programming tasks. Each problem includes a problem statement, function signature, and test cases. EvalPlus extends this dataset with additional test cases to provide a more rigorous evaluation of code generation capabilities. For our evaluation, we use the pass@1 metric on the Base Tests of MBPP+, which reflects the model's ability to generate correct code on the first attempt using the original test cases. The OS dataset evaluates LLMs in genuine interactive bash environments (Ubuntu Docker) on human questions with deterministic answers and practical operational tasks. The DB dataset assesses LLMs' abilities to operate on real databases via SQL, encompassing the complete pipeline of database analysis with authentic SQL interfaces and multiple tables. Both OS and DB datasets use success rate as the primary evaluation metric. The OS tasks are designed to be solved within a maximum of 5 interaction turns and employ a 1-shot setup. The DB tasks have a similar interaction limit but are evaluated in a 0-shot manner."}, {"title": "A.1.2 TRAINING CONFIGURATION FOR EXPERTS", "content": "We adopt the AdamW optimizer (Loshchilov & Hutter, 2019) with $\\beta_1 = 0.9$ and $\\beta_2 = 0.95$. A global batch size of 64 is used across all fine-tuning processes. We employ cosine learning rate scheduling with a range of $[4 \\times 10^{-6}, 2 \\times 10^{-5}]$, starting with a linear warmup for the first 10% of the total training steps. The OS and DB experts are trained for 1 epoch, while the code model is trained for 3 epochs due to its larger training data size."}, {"title": "A.1.3 CYCLEQD HYPER-PARAMETERS", "content": "We set $\\alpha_{low} = 0.5$ and $\\alpha_{high} = 0.8$ in Elite sampling, $\\mu = 1.0$ and $\\sigma = 0.03$ in model merging-based crossover, and $W_{max} = 0.3$ in our SVD-based mutations."}, {"title": "A.1.4 CYCLEQD DEVELOPMENT OF ARCHIVES ACROSS GENERATIONS.", "content": "Figure 4 shows the development of archives across generations. The archives are shown in increments of 300 generations from top to bottom. The corresponding generation for each archive is displayed on the left side of the figure. The red bounding boxes indicate the grids where expert policies were present in each archive. It can be observed that the frontier of the archives expands with each passing generation."}, {"title": "A.1.5 BENCHMARK DATASETS FOR SKILL GENERALIZATION AND LANGUAGE UNDERSTANDING", "content": "In the Coding category, we employ two key benchmarks: HUMANEVAL+ (Liu et al., 2023a), evaluated in a 0-shot setting using the pass@1 metric on the Base Tests, and BigCodeBench (Zhuo et al., 2024), which is designed to assess code generation with diverse function calls and complex instructions. We report the average Pass@1 scores for both BigCodeBench-Complete and BigCodeBench-Instruct variants in the full setting, using 0-shot evaluation. For the General Knowledge and Reasoning (Reasoning) category, we utilize two comprehensive benchmarks: MMLU (Hendrycks et al., 2021) with a 5-shot evaluation, and BBH (Big Bench Hard) (Suzgun et al., 2023) using a 3-shot chain-of-thought (Wei et al., 2022) prompting approach. These benchmarks provide a holistic assessment of our model's ability to handle a wide range of knowledge-based and reasoning tasks. To evaluate Mathematical Reasoning, we employ the GSM8K benchmark (Cobbe et al., 2021) with a 4-shot evaluation, challenging our model's ability to solve complex mathematical problems. For Reading Comprehension (RC), we use two established benchmarks: SQuAD2 (Rajpurkar et al., 2018) and TriviaQA (Joshi et al., 2017), both evaluated using a 4-shot approach. These datasets assess the model's capacity to understand and reason over complex textual information. In the Commonsense Reasoning (CommonSense) category, we employ three diverse benchmarks: HellaSwag (Zellers et al., 2019) for commonsense inference, OpenBookQA (Mihaylov et al., 2018) for elementary-level science question answering that requires both core scientific knowledge and broader common"}, {"title": "A.2 IMAGE SEGMENTATION TASKS", "content": null}, {"title": "A.2.1 DATASETS FOR FINE-TUNING EXPERTS AND CYCLEQD TRAINING", "content": "We followed Zhong et al. (2024) to prepare the datasets. For Camouflaged Object Segmentation, we use three datasets: COD10K (Fan et al., 2020a), CHAMELEON (Skurowski et al., 2018), and CAMO (Le et al., 2019). Following Fan et al. (2020a) we train on a combined dataset consisting of the 4040 training images from COD10K and CAMO for 20 epochs, randomly splitting 10% of the images from the training set for validation. The model is then tested on the 250 COMO test images. For Polyp Segmentation, we use two datasets: Kvasir (Jha et al., 2019) and CVC-ClinicDB/CVC-612 (Bernal et al., 2015). Following Fan et al. (2020b), we divide the images into a 9:1 ratio for training and testing, resulting in 1450 training images. We then randomly split 20% of the training set for validation. The model is trained for 30 epochs and tested on the 101 Kvasir test images. For Skin Lesion Segmentation, we use the ISIC 2017 dataset (Codella et al., 2018). We train the model on the 2000 training and 150 validation images for 30 epochs and evaluate it on the 600 test images. For Leaf Segmentation, we use the Leaf Disease Segmentation Dataset (Rath, 2023). We train the model on the 498 training image, using 80% for training and 20% for validation for 30 epochs, and evaluate it on 90 test images."}, {"title": "A.2.2 VISUALIZATION RESULT", "content": "The visualization results are shown in Figure 5 for SKL and POL, and Figure 6 for SKL and"}]}