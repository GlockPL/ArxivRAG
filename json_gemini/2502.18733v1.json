{"title": "Cross-Modality Investigation on WESAD Stress Classification", "authors": ["ERIC OLIVER", "SAGNIK DAKSHIT"], "abstract": "Deep learning's growing prevalence has driven its widespread use in healthcare, where AI and sensor advancements enhance diagnosis, treatment, and monitoring. In mobile health, Al-powered tools enable early diagnosis and continuous monitoring of conditions like stress. Wearable technologies and multimodal physiological data have made stress detection increasingly viable, but model efficacy depends on data quality, quantity, and modality. This study develops transformer models for stress detection using the WESAD dataset, training on electrocardiograms (ECG), electrodermal activity (EDA), electromyography (EMG), respiration rate (RESP), temperature (TEMP), and 3-axis accelerometer (ACC) signals. The results demonstrate the effectiveness of single-modality transformers in analyzing physiological signals, achieving state-of-the-art performance with accuracy, precision and recall values in the range of 99.73% to 99.95% for stress detection. Furthermore, this study explores cross-modal performance and also explains the same using 2D visualization of the learned embedding space and quantitative analysis based on data variance. Despite the large body of work on stress detection and monitoring, the robustness and generalization of these models across different modalities has not been explored. This research represents one of the initial efforts to interpret embedding spaces for stress detection, providing valuable information on cross-modal performance.", "sections": [{"title": "1 Introduction", "content": "The growing interest in deep learning has led to its widespread adoption across diverse applications, particularly due to its capacity to extract meaningful patterns from raw multimedia data. One of the most transformative domains benefiting from deep learning advancements is healthcare, especially with the emergence of mobile health (mHealth) technologies. The integration of artificial intelligence (AI) into healthcare has revolutionized treatment, diagnosis, and continuous monitoring, enabling more accurate early detection of medical conditions and improved long-term disease management. Al-driven tools now facilitate real-time monitoring, personalized interventions, and predictive analytics, significantly enhancing patient outcomes while reducing the burden on healthcare providers. A key driver of this AI adoption in healthcare is the increasing availability of diverse data modalities, facilitated by advancements in sensor technologies."}, {"title": "2 Related Works", "content": "Stress detection utilizing physiological signals has been extensively investigated through various machine learning (ML) and deep learning (DL) approaches. Research has focused on optimizing model architectures, feature engineering, and dataset preprocessing to enhance classification performance. This section reviews studies employing different physiological signals and particularly discusses those using the WESAD dataset for stress classification."}, {"title": "2.1 Traditional and Early Machine Learning Approaches", "content": "Early studies in stress detection utilized conventional machine learning techniques that required significant feature engineering. For instance, Heyat et al. [7] demonstrated stress classification using decision trees applied to ECG signals collected from a smart T-shirt with an embedded cardiac electrode, while AlShorman et al. [2] employed methods such as Support Vector Machines and Naive Bayes on features extracted via Fast Fourier Transform. Andric et al. [3] employed a Random Forest classifier on WESAD and the Stress-Predict dataset, achieving 96% accuracy. While their preprocessing and feature extraction methods increase computational complexity, the approach in this study achieves high precision and recall with minimal preprocessing. Nazeer et al. [27] explored preprocessing strategies, context modeling, and branch classifiers using XGBoost for stress detection. Their feature extraction pipeline is comprehensive, but this study achieves comparable accuracy with less preprocessing. Mazumdar et al. [21] analyzed various classifiers and identified ECG, EDA, and temperature as key features, with XGBoost achieving the highest accuracy. Bhanushali et al. [30] employed Decision Tree, Random Forest, and XGBoost classifiers for stress classification on WESAD. Although pioneering, these approaches frequently necessitated carefully designed preprocessing pipelines to address noise and variability in physiological data."}, {"title": "2.2 Deep Learning Approaches", "content": "With the advent of deep learning and its aptness in ingesting raw unstructured data, researchers initiated investigations into Convolutional Neural Networks (CNNs), Long Short-Term Memory networks (LSTMs) and Transformer models to automatically learn representations from raw or minimally processed signals. Narwat et al. [25] evaluated KNN, XGBoost, and CNN on WESAD, demonstrating the advantages of deep learning. Investigations such as those conducted by Mohapatra [24] and Gil-Martin et al. [13] used CNN models for stress detection on speech data across seven emotional categories from a Kaggle dataset and combined CNNs with Fourier Transform preprocessing and Leave-One-Subject-Out cross-validation, for classification across multiple stress and emotional states. LSTM-based models have demonstrated improvements over CNNs in capturing longitudinal relationships, as reported by Nigam et al. [28] utilized Respiban chest sensors with LSTM to classify stress, optimizing hyperparameters to improve performance. Similarly, Nath et al. [26] implemented an LSTM-based stress detection model for older adults using BVP and EDA signals, comparing its performance to traditional machine learning approaches of logistic regression, KNN, SVM, and Random Forest. Malviya and Mal et al. [20] developed hybrid a CNN-BLSTM model incorporating Discrete Wavelet Transform (DWT) for stress classification, while Song et al. [33] employed a combination of LSTM and Xception models to fuse 1D and spectrogram-based ECG features, achieving 99.51% accuracy. While their approach slightly outperforms others in ECG classification, it requires higher computational resources. Additionally, Kumar et al. [15] employed CNNs and time-frequency representations (TFRs), such as Short-Time Fourier Transformation (STFT) and Continuous Wavelet Transform (CWT) for ECG and EDA-based stress classification. More recently, transformer architectures have emerged as a promising alternative, primarily due to their capacity to capture long-range dependencies without substantial reliance on handcrafted features. Wu et al. [37] proposed a multimodal transformer incorporating EDA, BVP, and temperature signals for stress classification across multiple datasets. Self-supervised learning (SSL) has been investigated for emotion recognition by Gotz et al. [14] who proposed a modality-agnostic Transformer (MATS2L) trained on ECG and EDA signals, demonstrating the benefits of SSL for feature extraction, while mitigating the necessity for extensive preprocessing."}, {"title": "2.3 Gaps and the Current Contribution", "content": "The extant literature demonstrates significant advancements from traditional methodologies to sophisticated deep learning models. However, the majority of prior research exhibits two notable limitations. First, there exists a substantial reliance on complex feature extraction and preprocessing for traditional machine learning approaches, which may impede real-time application. Second, existing studies predominantly focus on optimizing performance within individual modalities, resulting in a paucity of understanding regarding cross-modal generalization. In contrast, this study not only adapts transformer models for direct application to raw physiological data but also systematically evaluates both intramodality accuracy and cross-modality generalization. Through the utilization of UMAP visualizations and quantitative variance analysis, this research provides novel insights into the transferability of learned representations across diverse sensor types, thereby addressing a critical gap in stress detection research."}, {"title": "3 Background and Methodology", "content": "In this section, we introduce the WESAD dataset, which was used for training and evaluation of transformer models on the task of stress detection, followed by an introduction to the transformer architecture and the proposed architecture for this study."}, {"title": "3.1 Dataset", "content": "In this investigation, the Wearable Stress and Affect Detection (WESAD) dataset [32], specifically on the raw physiological data obtained from a chest-worn RespiBAN device, was used for experimentation. WESAD is a widely recognized resource in the field of affective computing, particularly for the detection and classification of emotional states, such as stress, amusement, and neutrality. The dataset comprised recordings of 15 participants, aged between 24 and 31 years, who were subjected to a series of controlled experimental conditions designed to elicit specific emotional states. Each participant underwent a sequence of activities including a neutral baseline period, an amusement phase induced by watching humorous video clips, a stress phase induced by the Trier Social Stress Test (TSST), and a recovery period. The labels in the WESAD dataset are structured as 0 for the neutral state, 1 for stress, and 2 for amusement. For this analysis, we exclusively utilized raw data collected from the RespiBAN chest device, which provides high-resolution physiological signals at a uniform sampling rate of 700 Hz. The signal modalities of interest include electrocardiogram (ECG), electrodermal activity (EDA), electromyography (EMG), respiration rate (RESP), temperature (TEMP), and three-axis accelerometer (ACC) data. All 15 participants in the dataset were included in the training and testing set in a random 85:15 ratio, allowing for a comprehensive analysis across a diverse group of subjects. This inclusive approach enables the development of robust models capable of generalizing across different individuals, thus enhancing the reliability and applicability of our findings for stress detection."}, {"title": "3.2 Transformer Architecture", "content": "3.2.1 Transformers. The transformer architecture [35], represents a significant advance in the design of neural networks, particularly for natural language processing (NLP) tasks. The transformer introduced the self-attention mechanism, enabling effective representation of both long-range dependencies and relationships within data using an encoder-decoder structure with a self-attention mechanism, which computes the relative importance of each element in a sequence with respect to all other elements. The encoder traditionally consists of a multihead self-attention mechanism and a position-wise fully connected feed-forward network, while the decoder mirrors this structure, but includes an additional layer for attending to the encoder's output allowing superior performance. Their success in NLP has led to variants and adaptations, such as Vision Transformers (ViTs) on 2D image modalities and 1D time-series signals, although in limited capacity. Two key components that enable this adaptation are patch embeddings and positional embeddings, which allow the model to effectively capture the spatial and sequential relationships in the data. Since Transformers lack an inherent understanding of the spatial structure of images, authors Dosovitskiy et al. [10] proposed the use of positional embeddings alongside patch embeddings for encoding the relative positions of the patches within the original image. This ensures that the model can recognize the spatial arrangement of patches, which is crucial for classification. For 1D time-series signals, the signal is divided into overlapping or non-overlapping segments, referred to as patches, which capture the temporal dynamics over a fixed window and is flattened and projected into a higher dimensional space to create a patch embedding [36].\n3.2.2 Proposed Architecture. Our transformer architecture follows a hierarchical design, beginning with an Input Layer where data is divided into smaller segments through Patch Creation and transformed into high-dimensional vectors via Patch Embedding. To retain spatial relationships, Positional Encoding is applied, allowing the model to capture sequential dependencies. The core of the model consists of multiple Attention Blocks, each incorporating multihead Self-Attention to focus on different aspects of the input simultaneously, followed by Dropout Layers for regularization, Layer Normalization for stable training, and Dense Layers with Relu activation functions to refine feature representations. These blocks process information iteratively, enhancing feature extraction and representation learning. Finally, the model outputs predictions through a Dense Layer followed by a Softmax Activation, producing a probability distribution over the target classes. In this model, we used the Adam optimizer for computational efficiency and minimal hyper-parameter tuning, with a learning rate of 0.0001, to ensure gradual, stable weight updates. Categorical cross entropy was employed as the loss function for multi-class classification. All models were trained for 50 epochs with a batch size of 32 balancing efficiency and generalization while benefiting from mini-batch gradient descent. This architecture enables scalable, robust processing of structured data, ensuring generalization across diverse learning tasks."}, {"title": "3.3 Experimental Design", "content": "In this study, we focused on developing a state-of-the-art stress classifier using 1D transformer architecture and investigated cross-modality performance on the same task. Additionally, we discuss interpretations of the cross-modal performance through reduced dimensional visualizations and high-dimensional data variance.. Our proposed workflow adheres to a structured processing of physiological data and classifying stress levels utilizing transformer-based deep learning models. This study uses raw physiological signals, including ECG, EDA, RESP, TEMP, EMG, and 3-axis ACC modalities obtained from the WESAD dataset as illustrated in Section 3.1. We trained multiple transformer models as illustrated in Section 3.2 on the individual physiological modalities and evaluated them on the"}, {"title": "4 Experiments and Results", "content": "In this section, we train and evaluate our model through two sets of experiments for a comprehensive evaluation of models of all the modalities of physiological data as well as the cross-generalization ability of the models trained and test on different physiological signals for the task of neutral, stress, and amusement classification. To the best of author's knowledge, this is the first investigation of cross-modal performance for stress detection. Our two experiments are structured as follows:\n\u2022 Experiment A: Models trained and tested on the same modality.\n\u2022 Experiment B: Models trained and tested on different modalities.\nFor experiment B, to evaluate the cross-modal performance, the models trained in experiment A were reused and tested on the other modalities to avoid introducing any biases from random initialization of weights or data batches during retraining."}, {"title": "4.1 Experiment A: Models trained and tested on the same modality", "content": "The results of this investigation on stress detection, for various physiological modalities as achieved through the transformer model illustrated in Section 3.2, are recorded in Table 1. Each of the six modalities and three channels for the accelerometer data were evaluated based on validation accuracy, precision, and recall. Comparable performances were observed for all the modalities with EDA and Respiration emerging as the best performing modalities. As recorded in table 1, EDA achieved a validation accuracy of 99.95%, with equally high validation precision and recall of 99.95%. Similarly, Respiration demonstrated exceptional results, with a validation accuracy of 99.95%, precision of 99.95%, and recall of 99.95%. In comparison, other modalities such as ECG achieved a comparable validation accuracy of 99.94%, with validation precision and recall of 99.95% and 99.94%, respectively. Temperature also performed strongly, with a validation accuracy of 99.93%, as well as precision and recall of 99.93%. EMG with a comparable performance, achieved a validation accuracy of 99.91%, with validation precision and recall of 99.91%. The accelerometer data is 3-channel and thus three separate models were trained on each of the three axes represented as C1,C2, and C3 respectively to comprehensively evaluate the viability and performance of each channel. Among the accelerometer channels, ACC_C1, ACC_C2, and"}, {"title": "4.2 Experiment B: Models trained and tested on different modalities", "content": "In this section, we report the results of cross-modality generalization using the models trained in Experiment A on particular modalities. This is particularly done to avoid introducing any biases from random initialization of weights or data batches during retraining. To the best of author's knowledge, this is the first investigation on cross-modal generalization for the task of stress classification. The results summarized in Table 2 elucidate the performance of stress detection models trained with individual modalities and evaluated on various target modalities. Across the"}, {"title": "5 Interpreting Cross-Modality Performance", "content": "In this section, we discuss the importance of embedding space, it's visualization and quantification to understand the cross-modal performances observed and reported in Section 4.2."}, {"title": "5.1 Embedding Space", "content": "Embedding space refers to a mathematical construct where high-dimensional data points, are represented as vectors in a lower-dimensional space. This space is structured such that similar data points are positioned in closer proximity, while dissimilar points are more distant. Embeddings are widely utilized in machine learning and deep learning to interpret the underlying relationships in data, facilitating tasks such as classification, clustering, or retrieval. Techniques such as Principal Component Analysis (PCA) [19], t-SNE [34], and UMAP [22] are frequently employed to visualize and analyze these spaces, elucidating the inherent patterns and structures within the data, including the development of prototypical spaces [9]. The structure of the embedding space is critical for model performance, as it directly influences the capacity to generalize and transfer learn representations to novel tasks or data [5, 8, 23, 31]."}, {"title": "5.2 Visualization of embedding space", "content": "Uniform Manifold Approximation and Projection (UMAP) [22] is a dimensionality reduction technique extensively utilized to visualize high-dimensional data in a lower-dimensional space, predominantly 2D or 3D. It is particularly effective for embedding space visualization, in which complex high-dimensional feature representations are projected into an interpretable form. UMAP operates by constructing a high-dimensional graph representation of the data and subsequently optimizing a low-dimensional embedding that preserves the local and global structure of the original data. Compared to alternative methods such as t-SNE [34], UMAP demonstrates superior computational efficiency and enhanced preservation of global structure while maintaining meaningful local clusters. In our study, UMAP is used to project the high-dimensional embeddings generated by the transformer models into a 2D space. This visualization aids in understanding how well the model differentiates between the three stress states-Neutral, Stress, and Amusement across different physiological modalities through clustering."}, {"title": "5.3 Quantitative variance explanation", "content": "Understanding the role of data variance is crucial in evaluating a model's generalization capabilities. Generalization refers to a model's ability to perform accurately on novel, previously unseen data, and is influenced by the bias-variance trade-off. High variance in a model can lead to overfitting, wherein the model captures noise in the training data, resulting in poor performance on unseen data. Conversely, low variance may cause underfitting, wherein the model oversimplifies the data patterns, also leading to suboptimal generalization. Balancing bias and variance is essential to"}, {"title": "6 Comparison to Existing Work", "content": "In this section, we compare the performance of our proposed model with existing research literature. The literature on stress detection using WESAD is extensive; therefore, only comparable works with either reported accuracy and F1 score (Figure 3) or Precision, Recall and Accuracy (Figure 4) are discussed in this section. It is important to note that, to the best of our knowledge and search efforts, we did not identify any research on cross-modality investigation, which is consequently not compared in this section.\nGarg et al. [12] focused on stress detection using multimodal data, emphasizing the role of wearable sensors and machine learning (ML)-based classifiers. The authors integrated physiological signals with contextual data to enhance classification accuracy. A significant contribution of their work is the fusion of multiple sensor data streams for more robust stress detection. Their study reports F1-scores of 67.6% and 65.73% for three-class classification. Additionally, Schmidt et al. [32] introduced the WESAD dataset, which has become a benchmark for numerous stress detection models, significantly contributing to reproducibility in stress research. Their models achieved an accuracy of 76. 5% and an F1 score of 72. 5% for the classification of three classes. Kumar et al. [16] employed convolutional neural networks (CNNs) and recurrent neural networks (RNNs), reporting an accuracy of 87.7% and an F1-score of 85.2%. Similarly, Li et al. [17] achieved a precision of 95.1% and an F1 score of 91.7% using a CNN-based encoder with a feedforward neural network. Narwat et al. [25] report high performance across three machine learning models for stress classification, achieving 96.8% with XGBoost, 95.5% with KNN. In comparison, Mazumdar et al. [21] achieved a precision of 98.8%"}, {"title": "7 Conclusion", "content": "Stress detection utilizing physiological signals has emerged as a critical area of research, particularly with the increasing adoption of wearable technologies for real-time health monitoring. However, ensuring robust classification performance across diverse sensor modalities remains a significant challenge due to variations in physiological responses and data distributions. This study develops and evaluates transformer-based models for stress classification using the WESAD dataset, demonstrating state-of-the-art accuracy across multiple physiological modalities, including ECG, EDA, RESP, TEMP, EMG, and 3-axis ACC on data collected from a wearable chest sensor. Our investigation elucidates the effectiveness of self-attention mechanisms in capturing intricate temporal dependencies within physiological signals, enabling high-performance stress classification, achieving scores up to 99.9%, without extensive preprocessing."}]}