{"title": "FAST DIRECT: QUERY-EFFICIENT ONLINE BLACK-BOX GUIDANCE FOR DIFFUSION-MODEL TARGET GENERATION", "authors": ["Kim Yong Tan", "Yueming Lyu", "Ivor Tsang", "Yew-Soon Ong"], "abstract": "Guided diffusion-model generation is a promising direction for customizing the generation process of a pre-trained diffusion-model to address the specific downstream tasks. Existing guided diffusion models either rely on training of the guidance model with pre-collected datasets or require the objective functions to be differentiable. However, for most real-world tasks, the offline datasets are often unavailable, and their objective functions are often not differentiable, such as image generation with human preferences, molecular generation for drug discovery, and material design. Thus, we need an online algorithm capable of collecting data during runtime and supporting a black-box objective function. Moreover, the query efficiency of the algorithm is also critical because the objective evaluation of the query is often expensive in the real-world scenarios. In this work, we propose a novel and simple algorithm, Fast Direct, for query-efficient online black-box target generation. Our Fast Direct builds a pseudo-target on the data manifold to update the noise sequence of the diffusion model with a universal direction, which is promising to perform query-efficient guided generation. Extensive experiments on twelve high-resolution (1024 \u00d7 1024) image target generation tasks and six 3D-molecule target generation tasks show 6x up to 10x query efficiency improvement and 11\u00d7 up to 44\u00d7 query efficiency improvement, respectively. Our implementation is publicly available at: https://github. com/kimyong95/guide-stable-diffusion/tree/fast-direct", "sections": [{"title": "1 INTRODUCTION", "content": "Diffusion models have become the state-of-the-art generative model for image synthesis (Ho et al., 2020; Nichol & Dhariwal, 2021; Dhariwal & Nichol, 2021) and video synthesis (Ho et al., 2022), etc. Its remarkable success is due to its powerful capability in modeling the complex multi-mode high-dimensional data distributions.\nOne promising direction for utilizing the generative power of diffusion models is through target generation. This allows users to customize the generation process to meet specific downstream objectives, effectively extending the models' capabilities beyond synthesis problems to engineering optimization and science discovery problems, such as image generation with human preferences, drug discovery (Corso et al., 2022; Guan et al., 2023) and material design (Vlassis & Sun, 2023; Giannone et al., 2023).\nThe pre-trained diffusion models often struggle to generate desired samples for these applications, especially when the target data lies out of the training data distribution. Therefore, the target generation often involves model fine-tuning or guidance techniques. Krishnamoorthy et al. (2023) proposes to train the diffusion model with re-weighted training loss, while Clark et al. (2023); Black et al. (2023); Fan et al. (2024); Yang et al. (2024) advocates for fine-tuning the parameters of the pre-"}, {"title": "2 RELATED WORKS", "content": "Diffusion guided generation (also called inference-time guidance) refers to the technique to guide the sampling trajectory of the pre-trained diffusion to generate target data (Croitoru et al., 2023;"}, {"title": "2.1 GUIDED GENERATION", "content": "Chen et al., 2024). The key advantage of this approach is that it does not require updating the model parameters, which is computationally expensive, especially for large models.\nDhariwal & Nichol (2021) proposed classifier guidance. However, it requires a guidance model that trained on noisy images with different noise scales, which generally not readily available and often requires training from scratch for each domain. Chung et al. (2022); Bansal et al. (2023); He et al. (2023) extend the classifier guidance by using a differentiable objective function that is defined only for clean data. Instead of using noisy images, the predicted clean images at each sampling steps are used as the input for the guidance objective function. In this way, the guidance process can operate on the clean image space. While the predicted clean image is naturally imperfect, empirically it still provide informative feedback to guide image generation (Bansal et al., 2023).\nHowever, this approximation can harm image quality. Bansal et al. (2023) proposed universal guidance that comprises of backward guidance followed by a self-recurrence step to preserve image quality. On the other hand, He et al. (2023) leverages the differentiability of a well-trained auto-encoder to project the image to the data manifold and thus preserve image quality during the guidance process. Instead of guiding the sampling trajectory, Karunratanakul et al. (2024); Eyring et al. (2024) treat the diffusion process as a black-box and only optimize the initial (prior) noise.\nWhile the aforementioned approaches assume a differentiable objective function, Lu et al. (2023) tackles black-box objective f by learning a differentiable proxy neural network h to match their gradients, i.e., \u2207f \u2248 \u2207h. Li et al. (2024) eliminates the need for a differentiable proxy model by employing importance sampling weighted by the objective values during the sampling process. Most recently, DNO (Tang et al., 2024) proposes optimize the diffusion noise sequence by using ZO-SGD (Nesterov & Spokoiny, 2017) to tackle black-box objective function. However, it runs at the instance level; namely, each run only produces one image."}, {"title": "2.2 DIFFUSION-MODEL FINE-TUNING", "content": "Diffusion-model fine-tuning refer to the technique that updating the pre-trained diffusion-model parameters to improve its performance on a specific use case. In this section, we review the fine-tuning methods that support online learning of the black-box objective function.\nBlack et al. (2023); Fan et al. (2024) formulate the diffusion fine-tuning problem as a reinforcement learning (RL) problem within Markov Decision Processes (MDPs), and proposes an iterative algorithm to fine-tune diffusion model by using Proximal Policy Optimization (PPO) (Schulman et al., 2017; Uehara et al., 2024) loss function. Fan et al. (2024) integrates the PPO with a KL regularization to prevent the fine-tuned model deviated too much from the pre-trained model.\nOn the other hand, Yang et al. (2024) does not requires an absolute objective values, instead it uses the relative reward on pair of samples by integrating DPO (Direct Preference Optimization) (Rafailov et al., 2024), a technique for fine-tuning large language models, into diffusion model.\nFine-tuning diffusion model requires large amount of GPU memory. Existing works mitigates the memory consumption by using LoRA (Low-Rank Adaptation) (Hu et al., 2021) technique, and only fine-tune parameters of the attention blocks in UNet. We categorize the related works based on whether they support the online and black-box objective tasks in Appendix F Table 2."}, {"title": "3 METHODS", "content": "In this section, we first present a novel inference-time guidance generation method by guided noise sequence optimization. Based on this method, we further present our query-efficient online black-box guidance algorithm, Fast Direct, to address online black-box guidance tasks."}, {"title": "3.1 NOISE SEQUENCE OPTIMIZATION WITH TARGET GUIDANCE", "content": "Take i.i.d. Gaussian samples {\u20ac0,\u2026\u2026,\u20acK} ~ N(0, I), for k \u2208 {1,\u2026\u2026\u2026, K}, the inference process of the diffusion model can be formulated as follows:\nXk = So(Xk-1,\u2208k),"}, {"title": "3.2 QUERY-EFFICIENT ONLINE BLACK-BOX GUIDANCE", "content": "In section 3.1, we address the diffusion guidance sampling with a given optimal target input. However, in reality, we often only have access to the black-box objective function f(x), where the optimal target data x* = arg min f(x) is unknown. In this section, we further investigate the diffusion guidance sampling with only black-box objective feedback. For this task, it is natural to ask the following question.\nQuestion 2: Can we guide a pre-trained diffusion model at inference time to generate target data with only black-box objective feedback in a query-efficient online manner?\nTo answer this question, we need to address two challenges: (1) Black-box challenge and (2) Online guidance challenge. The black-box challenge means that we cannot access the gradient of the objective. The online guidance challenge means we don't have a prior dataset to train a surrogate (classifier) for guidance; we can only access the black-box objective through query feedback online. Usually, the query evaluation is expensive. Thus, the query efficiency is critical.\nWe start addressing the above two challenges based on our target guidance generation Algorithm 1. Although Algorithm 1 itself cannot handle black-box guidance tasks because it needs input a target x*, it provides a basis for us to design query efficient online black-box guidance methods. To be specific, Algorithm 1 enables us to generate a target even updating with a noisy direction x* \u2013 XK.\nThis property is important for black-box guidance tasks because we can use a noisy estimation of the gradient of the black-box objective to guide the generation.\nThe key idea is to set a pseudo target 2* to guide the generation process based on our Algorithm 1. We present our Fast Direct method as in Algorithm 2. In Algorithm 2, we call Algorithm 1 inside the for-loop w.r.t. the number of batch queries t. The only difference compared with Alg. 1 is that we set a pseudo target 2* in Line 10 of Algorithm 2 instead of a given fixed target x*.\nThe choice of models for updating the pseudo target 2* in Algorithm 2 is flexible, which supports various black-box target generation method designs based on our Fast Direct algorithm framework. In this work, we set the pseudo target * through nonparametric methods without additional training. Specifically, we employ two methods for setting the pseudo target 2*, namely, Gaussian process (GP) update and historical optimal update."}, {"title": "4 EXPERIMENTS", "content": "In this section, we evaluate our algorithm in two domains, images and molecules, and compare it against four baseline methods: DDPO (Black et al., 2023), DPOK (Fan et al., 2024), D3PO (Yang et al., 2024), DNO (Tang et al., 2024). Moreover, we further evaluate our algorithm in compressibility, incompressibility, and aesthetic quality tasks in Appendix A."}, {"title": "4.1 IMAGE BLACK-BOX TARGET GENERATION TASK", "content": "Problem: Prompt Alignment. We consider the image-prompt alignment problem. While the current state-of-the-art image generative models excel at generating highly realistic images, they sometime struggle to faithfully generate images that accurately aligned with the input prompts, especially those complex prompts involving rare object combinations, object counting, or specific object positioning.\nPre-trained Model: SDXL-Lightning. We use SDXL (Podell et al., 2023) diffusion model as the backbone text-to-image model. It is able to generate 1024\u00d71024 high resolution realistic image. In our experiment, we use the distilled version, SDXL-Lightning (Lin et al., 2024), for its high sampling efficiency, which can generate image with comparable quality with just K = 8 steps. We use the official implementation 2\nObjective Function: Gemini 1.5. We leverage Gemini 1.5 (Reid et al., 2024), an advanced multi-modal LLM service, as our black-box objective function to evaluate the alignment between input prompts and generated images. To avoid confusion, the term query refers to the input to Gemini, while prompt refers to the text used for image generation.\nThe query to Gemini 1.5 composes of the generated images with the question like: \"Does the prompt $prompt accurately describe the image? Rate from 1 to 5\". We state the complete query in Appendix G.\nBecause it is a closed-source paid service, we limit the number of batch queries in our experiments, referred to as the batch queries budget. We use the Gemini 1.5 Flash model (code: gemini-1.5-flash-001) for its cost-efficiency, and set the temperature as 0 for experiments consistency and reproducibility. For conciseness, we call it simply Gemini in the following section.\nExperiment Procedure. We identify 12 prompts that the pre-trained model SDXL-Lighning struggles to generate, and refer these as the 12 tasks in our experiment, where the goal is to generate images that accurately aligned with the input prompts. We compare our Fast Direct algorithm against each baselines methods, and each experiment is constrained with 50 of batch queries budget.\nWe perform inference-time guidance using Fast Direct (Algorithm 2) to maximize the Gemini rating. We use the GP model in Eq. 2 for the pseudo-target, and set the kernel as Gaussian kernel, and we follow (Hvarfner et al., 2024) to set the lengthscale as x = \u221ad, where d = 4\u00d7128\u00d7128 is the latents dimensionality of SDXL. We use N = 50 iterations to utilize 50 batch queries budget, and set the batch size as B = 32 and step size as a = 80. We use the EularDescreteScheduler (Karras et al., 2022) sampler as suggested by the SDXL-Lightning implementation (Lin et al., 2024), and the DDIMScheduler (Song et al., 2020) (DDIM) sampler for a fair comparison with the baselines."}, {"title": "4.2 MOLECULE BLACK-BOX TARGET GENERATION TASK", "content": "Problem: Drug Discovery. We consider the drug discovery problem. One of the key problem is to find drug molecules that has a strong binding affinity with the target protein receptor. The binding"}, {"title": "5 CONCLUSION", "content": "In this work, we proposed Fast Direct for diffusion model target generation, which effectively addresses the challenges of limited batch query budgets and black-box objective functions, demonstrating its potential for various applications, including image generation and drug discovery. Fast Direct is highly practical, as it is easy to implement, supports any type of SDE solver, and has only one hyper-parameter to tune (step size a). Our algorithm is based on the surprising empirical observation that the universal update direction (i.e., x* \u2013 XK in Algorithm 1) can efficiently guide the diffusion trajectory toward the target, even when the target \u00e6* is extremely noisy. This phenomenon suggests an intriguing robustness in the diffusion inference process. Future research could investigation for its underlying theoretical principles."}, {"title": "A MORE EXPERIMENTS: COMPRESSIBILITY, INCOMPRESSIBILITY, AND AESTHETIC QUALITY", "content": "Problem. We follow DDPO (Black et al., 2023) to evaluate our algorithm on the three black-box optimization tasks for images: compressibility, incompressibility, and aesthetic quality.\nObjective Function. For compressibility, we aimed to minimize the compressed JPEG size (MB) of the generated images. For incompressibility, it's simply the inverse. For aesthetic quality, the aesthetic score is evaluated by the pre-trained LAION aesthetics predictor (?), which is trained on human rating of the images aesthetic quality, and we aimed to maximize the aesthetic score.\nExperiment Procedure. For each task, we uniformly sample from the 45 common animals (as proposed by DDPO (Black et al., 2023)) as input prompts and optimize the objective using Fast Direct in Algorithm 2. The prompt for each instance within a batch is sampled randomly and independently. We set N = 50 batch queries budget for compressibility and incompressibility, and N = 100 for aesthetic quality. We use the same pre-trained model, hyper-parameters, and GP settings as in Section 4.1. The 45 common animals prompts used in the experiment is as follows:\nFor DNO, where each experimental trial generates only a single image and the objective score is highly dependent on the specific prompt. To ensure a more accurate evaluation, we run 45 independent experiment trials using each prompt and report the average results. Consequently, DNO requires 45\u00d7 more batch queries per task compared to other methods.\nExperiment Result. We present the objective scores for each task in the left column of Fig. 6 and provide the generated images for the three tasks in the supplementary materials. For compressibility and incompressibility, we observe that Fast Direct achieves significantly better scores than the baselines. For aesthetic quality, Fast Direct with the EDM sampler achieves significantly better scores than with DDIM, likely due to EDM being a more advanced sampler, capable of generating higher-quality images. DNO achieves comparable scores; however, note that each experiment optimizes and generates only a single image.\nGeneralization Ability. We follow DDPO to evaluate generalization ability. For Fast Direct, we freeze the learned GP model to generate 16 unseen images using distinct unseen animal prompts. Specifically, in this phase, Lines 17 and 18 are removed from Algorithm 2, and our algorithm does not access the objective function. For DDPO, DPOK, and D3PO, the fine-tuned models are frozen to generate images with the 16 unseen animal prompts. DNO is not applicable to this experiment because DNO needs to perform optimization for each image without generalization. For the unseen prompts, since DDPO didn't publish the unseen prompts, we created our own as follows:"}, {"title": "BABLATION STUDY", "content": "We perform an ablation study on the target image generation Task-1. For step size analysis, we fix the batch size as 32, then perform experiment with different step size a = {20,40, 80, 160, 320}; for batch size analysis, we fix the step size as 80, then perform experiment with different batch size B = {4, 8, 16, 32, 64}. Additionally, we report the run time for different batch size. We report the result in Fig. 9.\nWe can observe that the performance steadily increase for any step size and any batch size, suggests that our algorithm is not sensitive to the hyper-parameters settings. The run time scales linearly with the batch size. In our target image generation experiments in Section 4.1, as the batch size is set as 32, each experiment takes approximately 6.4 hours to process 32 images in parallel."}, {"title": "C ANALYSIS OF UNIVERSAL DIRECTION", "content": "In Fig. 10, we demonstrate Algorithm 1 with update direction d = x* \u2013 xK' for K' \u2208 {K, K/2, K/4, K/8}. It shows that the generated image quality decreases as the K' decreases. This is because as K' decreases, the x K' becomes noisier and may move further away from the data manifold."}, {"title": "D BASELINES DETAILS", "content": "For DDPO, DPOK and D3PO, we fine-tune the model to maximize the Gemini rating. We fine-tune the model with 50 epochs; each epoch utilizes one batch query for model updating. For DDPO and DPOK, we set the batch size to 32; for D3PO, it requires a relative reward, so we doubled the batch size to 64.7 As these RL-based methods require closed-form expression of the logarithm probabilities, we follow their official implementation to use the DDIMScheduler (Song et al., 2020) sampler."}, {"title": "E PROOF OF PROPOSITION 1", "content": "Proof. Let a = (K(X\", X\") + \u03bbI)\u00af\u00b9y = [a1,\u2026,an]T, for GP with a shift-invariant kernel that can be rewritten as k(z1, z2) = g(||Z1 - z2||2), the gradient of the GP prediction is\n\u2207 f(x; X\") = \u2207k(x,Xn)\u03a4\u03b1\n= \u2211 Ai\u2207||x \u2212 x\u00b2 ||2\nn\ni=1\n= \u2211Ai\u2212x\u2212x\u00b2||9\u2032 (||x \u2212 x\u00b2 ||2)(x \u2013 x\u00b2)\nn\ni=1\n= \u2211ci(x) (x \u2013 x\u00b2)\nn\ni=1\nwhere x\u00b2 denotes the ith sample in Xn = [x\u00b9,\u2026\u2026,x"}, {"title": "F OVERVIEW OF RELATED WORKS", "content": "We present the summary of related works according to its category and supported problem scenarios in Table 2."}, {"title": "G EXPERIMENT DETAILS", "content": "We use the following query question to the Gemini:\nDoes the prompt $prompt accurately describe the image?\nRate from 1 (inaccurate) to 5 (accurate).\nAnswer in the format: Score=(score), Reason=(reason)."}, {"title": "H MORE EXPERIMENT RESULTS", "content": "We report the accumulated objective values over number of batch queries for images task in Fig. 11, and for molecules task in Fig. 12."}]}