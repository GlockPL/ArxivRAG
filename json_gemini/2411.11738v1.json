{"title": "WOODYOLO: A NOVEL OBJECT DETECTOR FOR WOOD SPECIES DETECTION IN MICROSCOPIC IMAGES", "authors": ["Lars Nieradzik", "J\u00f6rdis Sieburg-Rockel", "Andrea Olbrich", "Henrike Stephani", "Stephanie Helmling", "Stephanie Wrage", "Janis Keuper"], "abstract": "Wood species identification plays a crucial role in various industries, from ensuring the legality of timber products to advancing ecological conservation efforts. This paper introduces WoodYOLO, a novel object detection algorithm specifically designed for microscopic wood fiber analysis. Our approach adapts the YOLO architecture to address the challenges posed by large, high-resolution microscopy images and the need for high recall in localization of the cell type of interest (vessel elements). Our results show that WoodYOLO significantly outperforms state-of-the-art models, achieving performance gains of 12.9% and 6.5% in F2 score over YOLOv10 and YOLOv7, respectively. This improvement in automated wood cell type localization capabilities contributes to enhancing regulatory compliance, supporting sustainable forestry practices, and promoting biodiversity conservation efforts globally.", "sections": [{"title": "Introduction", "content": "Global deforestation is a cause of biodiversity loss and climate change. The European Union's recently adopted EU Deforestation Regulation (EUDR, Parliament [2023]), which replaces the EU Timber Regulation (EUTR), requires that products traded in the EU are based on deforestation-free supply chains. This increases the demand for confirming the declaration of wood products regarding the wood species and origin."}, {"title": "Related Work", "content": "The automated identification of wood species in microscopic images of fibrous materials has gained significant attention in recent years. This interest is driven by the need for efficient and accurate methods to support global wood fiber product controls.\n\nA pioneering approach for the identification of hardwood species in microscopic images using deep learning techniques was introduced by Nieradzik et al. [2023]. They developed a methodology for generating a large dataset of macerated wood references, focusing on nine hardwood genera. This approach utilized a two-step process: first, detecting vessel elements using YOLOv7 [Wang et al., 2022], and then classifying these elements using convolutional neural networks (CNNs).\n\nWhile the localization of objects achieved promising results, there remains room for improvement. Recently developed object detection algorithms, particularly those based on transformers, such as the DETR (DEtection TRansformer) model family [Carion et al., 2020, Zhao et al., 2024, Zhang et al., 2022, Ouyang-Zhang et al., 2022], have shown potential. However, they have not seen widespread use due to higher time complexity, slower training speeds or lower mAP on real-world datasets.\n\nAnother line of research is the continuation of YOLO. It is important to note that a higher version number in YOLO does not necessarily indicate an improvement; instead, different techniques are applied, which may or may not work on particular datasets. Since the original YOLO publication [Redmon et al., 2016], only YOLOv2 [Redmon and Farhadi, 2016] and YOLOv3 [Redmon and Farhadi, 2018] were developed by the original authors. Other versions have been introduced by different institutes or companies, including YOLOv4 [Bochkovskiy et al., 2020], Scaled-YOLOv4 [Wang et al., 2021], YOLOX [Ge et al., 2021a], YOLOv6 [Li et al., 2022], DAMO-YOLO [Xu et al., 2023], YOLOv9 [Wang et al., 2024a], YOLOv10 [Wang et al., 2024b], PP-YOLO [Long et al., 2020], PP-YOLOv2 [Huang et al., 2021], and PP-YOLOE [Xu et al., 2022]. Notably, YOLOv5 and YOLOv8 have never been published. In our method section, we will analyze some of the different components found in these papers.\n\nA recent study by Qamar et al. [2024] titled \"Segmentation and characterization of macerated fibers and vessels using deep learning\" demonstrated the application of YOLOv8 for analyzing microscopy images of wood fibers.\n\nIn most practical machine learning research and data competitions, YOLO remains the state-of-the-art. Therefore, our focus is on developing an object detector based on this literature. Our current work builds upon these foundations by introducing a novel object detection algorithm specifically tailored for vessel element detection in microscopic images of fibrous materials. By designing our detection algorithm with this task in mind, we can make better optimizations and avoid focusing on general-purpose detection datasets such as COCO.\n\nAlthough there are numerous papers in the microscopy and satellite imaging literature that adapt YOLO for high-resolution image analysis, they generally rely on the original YOLO code base and make only minor changes. For example, L\u00f3pez Fl\u00f3rez et al. [2023], Aldughayfiq et al. [2023] adapted YOLOv5 for cell counting. There are also various studies in the field of satellite images in which YOLO [Meng et al., 2023, Li and Che, 2021] has been slightly modified. As a result, the improvements compared to the baseline are often only marginal. In contrast, we have developed our version of YOLO from scratch and tested components from different versions. This allows for more significant and customized improvements specifically for our application."}, {"title": "Materials and methods", "content": "Frequently processed woods that are cultivated in plantations for pulp, paper and fiberboard production were selected, such as poplar or eucalypt. The exact genera can be found in Nieradzik et al. [2023]. Vouchered specimens of the Th\u00fcnen Institute's wood collection and other documented sources served as reference material for training and testing. Analogous to pulp production, the cell structure of the wood tissue was broken down into individual cells by maceration according to the method of Franklin [1945]. At least 3 macerates per genus were produced. Maceration and staining are described in detail in Helmling et al. [2016] and Helmling et al. [2018]. For each macerate, 20 slides were prepared. Ten of these were stained with Alexander Herzberg solution and ten with nigrosine (1 wt%).\n\nOur detection framework is tailored to localize vessel elements in microscopic images, a crucial step for automating hardwood species identification in fibrous materials. Vessel elements, the cell elements for conducting water in deciduous trees, contain characteristic morphological features that differ within the genera, in contrast to fibers. We adapted the YOLO architecture for this domain, addressing the challenges posed by large image sizes (up to 54,000 x 31,000 pixels) and the need for high recall. Unlike algorithms such as DETR, which do not scale well for very large images and have slower training times, YOLO has proven effective in real-world applications, making it a suitable choice for our task.\n\nAlthough the YOLO family includes various models optimized for general datasets like COCO, these models are not directly applicable to our problem due to their design for multiple classes and general-purpose images. Therefore, we customized YOLO by integrating components from different versions to optimize it for vessel detection without the need for classification.\n\nIn this section, we describe our model's architecture, loss function, metric, and additional approaches evaluated to enhance detection performance."}, {"title": "Architecture", "content": "Our model architecture begins with selecting a backbone capable of efficiently extracting features from large microscopic images. The backbone processes the input to generate multi-scale feature maps. We tested several backbones such as VGG11 [Simonyan and Zisserman, 2015], ConvNext [Liu et al., 2022], and ResNet [He et al., 2015], and combined their feature maps through a component known as the neck, which outputs three feature maps. Although more than three feature maps can be used, our evaluation showed no significant advantage in doing so.\n\nOur neck architecture is based on YOLOv7-tiny. We also tested YOLOX's CSPNet[Wang et al., 2019] but found the former to be better. The use of a smaller architecture is due to the need for memory efficiency. Since we want to train the network with a higher image resolution than the usual 640x640 or 1280x1280, we need to reduce the memory requirements. Also, deeper networks are usually chosen when many features are needed to distinguish between different classes. Here it is only a matter of finding objects without the need for classification. Therefore, simpler networks work better.\n\nFigure 2 shows that our neck consists of several convolutional layers that are combined in different ways. A \"c\" block consists of a simple convolution followed by a batch normalization and a ReLU function. The \"b\" block consists of parallel convolutions that are combined by concatenation. Figure 3 shows the \"b\" block in detail."}, {"title": "Loss Function", "content": "Our loss function consists of two components:\n\n$L = L_r + L_p,$\nwhere $L_r$ is the regression loss and $L_p$ is the classification loss.\n\nRegression Loss The regression loss measures the alignment between predicted bounding boxes b and ground truth b using the Intersection over Union (IoU):\n\n$L_r = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{m} \\sum_{j=1}^{m} (1 - IoU(b_{ij}, b_{i,j})),$\nwhere n is the number of feature pyramid layers (in our case, n = 3) and m is the number of bounding boxes. The regression loss is either evaluated with the corresponding bounding box at that grid cell or additionally with neighboring grid cells (multi-positives).\n\nThere are different variants of IoU: Complete IoU (cIoU)[Zheng et al., 2021], Distance IoU (DIoU)[Zheng et al., 2019], Generalized IoU (GIoU) [Rezatofighi et al., 2019] and standard IoU. In the evaluation section, we evaluate the different approaches to see which maximizes our metric.\n\nClassification Loss The classification loss evaluates the confidence score \u00f4 using binary cross entropy (BCE), with the ground truth confidence o derived from IoU:\n\n$L_p = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{m} \\sum_{j=1}^{m} BCE(\\hat{o}_{i,j}, IOU(b_{i,j}, b_{i,j})).$\n\nUnlike the regression loss, we evaluate BCE at all locations of the grid. However, we set IoU(bi,j, bi,j) = 0 when there is no ground truth box at a specific grid cell."}, {"title": "Metric", "content": "The predominant metric in object detection is average precision (AP) [Everingham et al., 2010] computed at different thresholds, which summarizes both precision and recall:\n\n$AP = \\int_0^1 p(r) dr,$\nwhere r denotes recall and p(r) denotes precision as a function of recall. A detection is considered correct if the IoU between the predicted and the true bounding box exceeds a predefined threshold.\n\nIn our specific application, however, the use of AP would not be a good choice. Recall takes precedence over precision as our goal is to find all objects.\n\nFurthermore, we are less interested in an exact overlap with the ground truth. Minor shifts or size variations in the bounding box should not be penalized by the metric. Therefore, we want to consider only a single low IoU threshold. Often AP is computed at multiple thresholds.\n\nHence, we propose an alternative metric: the F2 score, which is computed with a fixed IoU threshold of 0.3. This choice emphasizes recall over precision. False positives can be handled in a postprocessing step by training a classifier to distinguish between correct and wrong detections. We see in fig. 4 two examples where the overlap of 30% is sufficient.\n\nWhile the usual threshold is 0.5, we choose a lower threshold of 0.3. This threshold takes into account the fact that perfect alignment with the ground truth bounding box is not essential for our objectives."}, {"title": "Additional Approaches", "content": "We explored several innovations from the YOLO series to further enhance our detection framework, evaluating their impact on performance. Some of these results will be shown in the evaluation section.\n\nCenter Sampling and Multi-Positives We explored the use of neighboring grid cells for matching ground truth boxes, a technique known in the literature as multi-positives [Ge et al., 2021a] or center sampling [Tian et al., 2019].\n\nIn the standard loss function $L_r$, we compute the IoU loss only between boxes at coordinates (i, j). Center sampling extends this concept by also comparing boxes at (i + k1, j + k2), where k\u2081 and k2 are integer offsets. The ground truth box is duplicated for these new coordinates (i + k1, j + k2) to make a comparison with the ground truth box at those positions possible. We investigated three variants:\n\n$\\begin{bmatrix} 0 & \\times & 0 \\\\ 0 & & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ 0 Neighbors: $\\begin{bmatrix} 0 & 0 & 0 \\\\ \\times & & \\times \\\\ 0 & 0 & 0 \\end{bmatrix}$ 2 Neighbors: $\\begin{bmatrix} \\times & & \\times \\\\ & & \\\\ \\times & & \\times \\end{bmatrix}$ 4 Neighbors:\nHere, denotes the original bounding box, while \u00d7 represents neighboring boxes and 0 means \"empty cell\". For the 0 neighbors configuration, the loss Lr remains unchanged as it only considers the original box. In the 2 neighbors configuration, the nearest bounding boxes within the grid are selected, in this case, the right and upper boxes. For the 4 neighbors configuration, we use bounding boxes from all directions: left, right, up, and down. Note that the diagonal boxes are never selected.\n\nSince object detection is a one-to-many mapping (one ground-truth box corresponds to many correctly predicted boxes), this strategy attempts to simulate this mapping using the loss function.\n\nLabel Assignment Bounding boxes are predicted for every feature map. The use of center sampling further increases the number of predicted boxes. To manage this increase of bounding boxes, we evaluated label assignment strategies designed to reduce the number of valid boxes per object.\n\nWe experimented with modern label assignment techniques such as SimOTA and TAL [Ge et al., 2021b, Feng et al., 2021]. However, these methods did not yield improved results in our scenario. We attribute this to our metric, which prioritizes maximizing recall rather than balancing precision and recall.\n\nAuxiliary Head Loss Deep supervision techniques, such as those used in YOLOv7 [Wang et al., 2022], involve adding auxiliary losses to guide deeper networks. Our experiments with additional model layers showed no benefit, so this approach was excluded from our final model.\n\nAnchor Boxes Anchor boxes, introduced in YOLOv2 [Redmon and Farhadi, 2016], are used to predict object locations. Consistent with YOLOX findings [Ge et al., 2021a], our results showed no improvement with anchor boxes, leading us to exclude them for simplicity. Instead, we incorporate parameters m\u0127 and mw in the range [0, 1] to constrain the predicted width and height of bounding boxes, as discussed previously.\n\nNMS-Free Detection NMS-free approaches from models like YOLOv10 did not perform as well in our tests. We retained traditional Non-Maximum Suppression (NMS) for its robustness and simplicity."}, {"title": "Results", "content": "We evaluate WoodYOLO on a dataset constructed for automating the detection and identification of vessel elements in hardwood species, a critical step toward wood species classification. Vessel elements are the water-conducting cells in hardwoods, that differ from genus to genus due to their characteristic morphological features. These vessel elements provide vital information for wood identification and are easily to distinguish from other cell types like fibers or parenchyma cells.\n\nIn this paper, we are specifically concerned with improving the localization of these vessel elements. The dataset comprises high-resolution microscope images of macerated hardwood samples, captured with a ZEISS Axioscan 7 microscope. Each image, originally in the czi format with a resolution of approximately 54,000 x 31,000 pixels and file size of 1 GB, was scaled down by 10% (5,400 x 3,100 pixels) to enhance training efficiency and reduce memory usage. The final dataset consists of 767 images annotated with 118,287 bounding boxes identifying vessel elements.\n\nOnly the third of five focal planes of each image was utilized for training, as additional planes did not contribute significant information for detecting the vessel elements. The annotated dataset was split into 613 images for training and 154 images for validation. We have conducted initial experiments with 5-fold cross-validations, but found that the metrics are relatively stable across different folds. Due to time constraints, we use a simple train-validation split.\n\nIn this section, we evaluate the performance of our vessel detection framework across various configurations and compare it to other state-of-the-art models. The evaluations were conducted using the F2 score at a fixed IoU threshold of 0.3, as described before."}, {"title": "Detection Model and backbone comparison", "content": "Since we use YOLO as a basis, it is useful to compare our model with other YOLO variants. In table 1, we present the F2 scores for different detection models."}, {"title": "Effect of Neighboring Cells and IoU Loss function", "content": "We assessed the impact of considering neighboring grid cells (multi-positives) for matching ground truth boxes. As shown in Table 3, using 0 neighboring cells produced the highest F2 score (0.8481).\n\nAdding more neighboring cells led to a decrease in performance, suggesting that the decrease in precision is too high.\n\nNext, we compared different IoU-based loss functions to determine their effectiveness in our model. Table 4 shows that the generalized IoU (GIoU) loss yielded the best performance with a F2 score of 0.8340.\n\nHowever, the differences at F2 are quite small. This parameter therefore has no major influence on the result."}, {"title": "Impact of Image Size and training techniques", "content": "Table 5 evaluates the impact of varying image sizes on detection performance. Training on images of size 2048 provided the highest F2 score (0.8316).\n\nThis confirms that we do not need the full resolution of 54000 x 31000 to find the vessel elements. Therefore, it is also not necessary to split the images to perform the detection for individual patches. Since only a single image needs to be predicted with our approach, we have a higher prediction speed.\n\nWe have successfully trained a model with a resolution of 6144 x 6144 on an A100 GPU with 40 GB VRAM. Even higher resolutions are possible with further adjustments to the architecture. It is important to emphasize that our standard model, which operates at a resolution of 2048 x 2048, is designed to be more accessible. It can be trained on consumer-grade hardware and requires only about 8 GB of VRAM for training.\n\nIn training our YOLO-based model, we explored several advanced techniques to enhance performance, including mosaic augmentation and gradient accumulation. Mosaic augmentation is a data augmentation strategy that creates a new training image by combining four different images from the dataset. This technique is intended to provide more context and variability during training, potentially improving the model's generalization ability. However, as shown in table 6, mosaic augmentation did not lead to an improvement in the F2 score for our task.\n\nGradient accumulation is another technique we evaluated. It allows for effective training with larger batch sizes than can fit in GPU memory by accumulating gradients over multiple mini-batches before updating the model weights."}, {"title": "Summary of the results", "content": "We have demonstrated that WoodYOLO outperforms other YOLO variants in our specific use case. Interestingly, certain techniques that have consistently shown improvements in mAP on COCO do not yield similar benefits here. For instance, mosaic augmentation, introduced in YOLOv4 [Bochkovskiy et al., 2020], showed a 1.8% increase in AP50 in their ablation study. In contrast, our experiments reveal a substantial decrease of 6.2% in F2 score when applying this technique. Similarly, we observed no advantage in using multi-positives, despite YOLOX reporting a 2.1% improvement.\n\nWe attribute these discrepancies to several factors:\n\n\u2022 Metric difference: Our focus is on recall and approximate bounding box overlap, rather than the standard COCO metrics.\n\n\u2022 Task simplification: As we only need to localize objects, our architecture can be shallower compared to those designed for more complex tasks.\n\n\u2022 Reproducibility challenges: Deep learning, particularly in object detection, often faces reproducibility issues. Many YOLO implementations use legacy code with undocumented workarounds to improve AP, which are not mentioned in the original papers. These may include arbitrary loss function weightings or different weight decay strategies [He et al., 2018].\n\nTo mitigate these confounding factors, we developed our detector from scratch, avoiding reliance on previous codebases. This approach allows us to more accurately assess the impact of individual modifications.\n\nIn conclusion, our findings suggest that for specialized domains that diverge significantly from the standard COCO use-case, developing customized detectors can be more beneficial than adapting existing general-purpose models. This approach enables a more tailored solution that better addresses the specific requirements of the task at hand."}, {"title": "Discussion and Conclusion", "content": "In this paper, we presented WoodYOLO, a novel object detection algorithm specifically designed for microscopic wood fiber analysis. Our approach builds upon the YOLO architecture, incorporating tailored optimizations to enhance performance in high-resolution microscopy images. We introduced several key innovations, including a customized YOLO-based architecture optimized for microscopic images and a novel anchor box specification method.\n\nOur comprehensive evaluation demonstrated that WoodYOLO outperforms state-of-the-art models such as YOLOv10 and YOLOv7 by significant margins in terms of F2 score. We also provided insights into the effectiveness of various architectural decisions and training techniques in the context of wood vessel detection.\n\nThe superior performance of WoodYOLO in detecting vessel elements in microscopic images of fibrous materials represents a significant advancement in automated wood species identification. This contribution has far-reaching implications for enhancing regulatory compliance, supporting sustainable forestry practices, and promoting biodiversity conservation efforts globally."}, {"title": "Future Work", "content": "The development of WoodYOLO opens up several promising avenues for future research and improvement. A key area for exploration is the integration of rotated bounding boxes to improve the accuracy of vessel element localization, particularly for elongated or angled structures. This further development requires adjustments to both the model architecture and the dataset annotations and offers considerable potential for improving detection accuracy.\n\nAt the same time, further optimization of the WoodYOLO architecture can be worked on to reduce the GPU requirements and increase the recall. Reducing the model's memory requirements is crucial to enable the processing of larger, higher-resolution microscopic images."}]}