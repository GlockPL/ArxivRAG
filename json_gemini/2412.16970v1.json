{"title": "Environment Descriptions for Usability and Generalisation in Reinforcement Learning", "authors": ["Dennis J.N.J. Soemers", "Spyridon Samothrakis", "Kurt Driessens", "Mark H.M. Winands"], "abstract": "The majority of current reinforcement learning (RL) research involves training and deploying agents in environments that are implemented by engineers in general-purpose programming languages and more advanced frameworks such as CUDA or JAX. This makes the application of RL to novel problems of interest inaccessible to small organisations or private individuals with insufficient engineering expertise. This position paper argues that, to enable more widespread adoption of RL, it is important for the research community to shift focus towards methodologies where environments are described in user-friendly domain-specific or natural languages. Aside from improving the usability of RL, such language-based environment descriptions may also provide valuable context and boost the ability of trained agents to generalise to unseen environments within the set of all environments that can be described in any language of choice.", "sections": [{"title": "1 INTRODUCTION", "content": "Reinforcement learning (RL) (Sutton and Barto, 2018) researchers have largely converged on common APIs for the development of benchmark domains used to evaluate RL algorithms for sequential decision-making problems. New environments (problems) are customarily written in general-purpose programming languages such as C++ or Python, implementing a Gym-like (Brockman et al., 2016) API for algorithms to interface with environments.\nWe may distinguish two broad categories of RL research. On the one hand, there is research focusing on the development of (modifications of) training algorithms, typically not focused on any specific task. There may be a focus on certain categories of tasks (single-agent RL, multi-agent RL, RL for partially observable environments, and so on), but existing and established frameworks with a suite of applicable domains are typically used for empirical evaluations. Researchers typically aim to demonstrate a high level of generality, by showing that an algorithm can effectively learn on a large collection of different environments within such a suite, as opposed to only a single environment. These environments are often games or other simulations (Machado et al., 2018; Tassa et al., 2018; Cobbe et al., 2020; Ellis et al., 2023), with arguably limited direct real-world impact outside of their use as benchmarks for RL research. On the other hand, there is research in which a concrete, high-impact \"real-world\u201d task is selected, and RL is used to improve performance on that one task. Substantial engineering effort is often dedicated towards implementing and optimising a simulator for such a task. This engineering effort often requires specialised knowledge of, for example, programming for GPUs or other hardware accelerators, and of the inner workings of deep learning and RL algorithms.\nWhile discussions on experimental methodologies in RL have been on the rise (Henderson et al., 2018; Agarwal et al., 2021; Jordan, 2022; Patterson et al., 2023; Jordan et al., 2024; Voelcker et al., 2024), we see little discussion on how (or by whom) tasks (or environments) are described or implemented in the first place. In this position paper, we argue that the standard assumption that environments can be implemented (and heavily optimised) in general-purpose programming languages, by engineers familiar with machine learning, (i) poses a challenge to widespread adoption of RL for real-world use cases, and (ii) also leads the research community to miss out on interesting research directions with respect to generalisation and transfer in RL. While it may be acceptable to invest substantial engineering resources for the implementation of environments for large-scale projects with high potential impact, it impedes the application of RL by smaller organisations or private individuals. We posit that more widespread applications of RL will be greatly aided if the latter groups can express their tasks in user-friendly domain-specific languages (DSLs) (Mernik et al., 2005; Aram and Neumann, 2015), or even in natural language. There are many possible definitions and interpretations of the term \"user-friendly\" (Stevens, 1983), but as a working definition, we will say that a language is user-friendly if it is easy to use for users who may be experts in their application domain of interest, but may not have any RL, AI, or programming expertise, and is designed with their needs in mind.\nOnce we adopt a methodology where environments are represented in explicit forms that can be provided as inputs to an agent (e.g., DSL or natural language snippets), we can also explore new forms of generalisation or transfer in RL, where effective generalisation or zero-shot transfer to unseen environments may become feasible given sufficient understanding of the task descriptions. Figure la depicts the setting where the environment is implemented directly in a general-purpose programming language, and Figure 1b depicts the proposed settings, with Figure 1c providing three examples of how the translation from a user-friendly environment description to a simulator may work. For tasks that take place in the physical world, such as non-simulated robotics tasks, a description of the reward function can suffice, as hardware and the real world already define aspects such as the action space and transition dynamics. However, even in these cases, the ability to automatically generate a sufficiently accurate simulator from user-friendly descriptions would, in combination with sim-to-real transfer (Zhao et al., 2020), still be highly beneficial (Yang et al., 2024)."}, {"title": "2 DESCRIPTION LANGUAGES FOR ENVIRONMENTS", "content": "Subsection 2.1 describes the established practice where RL research uses environments implemented, conforming to a standardised API, in general-purpose programming languages. As an initial step towards more user-friendly descriptions, Subsection 2.2 discusses the use of DSLs for describing environments used in RL research. Subsection 2.3 explores the possibility of using natural languages to define environments-arguably one of the most user-friendly modalities. Finally, Subsection 2.4 presents the central position of this paper: a call for more (research attention for) benchmarks in which environments are described in DSLs or natural language."}, {"title": "2.1 Defining Environments in Programming Languages", "content": "Outside of robotics work applied directly in the physical world, it is customary to implement the environments used for RL research in programming languages such as C++ or Python. In a recent trend, more specialised toolkits, such as CUDA or JAX (Bradbury et al., 2018) are used to enable the environments themselves and not just DNN forward and backward passes-to make efficient use of hardware accelerators (Dalton and Frosio, 2020; Freeman et al., 2021; Lange, 2022; Koyamada et al., 2023). This can provide dramatic speed increases, but also imposes additional constraints on programming style and requires more specialised engineering skills.\nMost developers of RL environments have converged to the API popularised by OpenAI Gym (Brockman et al., 2016). This API requires developers to implement:\n\u2022 A definition of the observation space. For any state that an agent may ever reach in an environment, it will receive an observation from this space as input.\n\u2022 A definition of the action space A. It is typically assumed that agents must select any one element from this space as their action in each non-terminal state.\n\u2022 A function to reset the environment to an initial state.\n\u2022 A step function, which takes an action from A as input, transitions from a current state s \u2208 S to a successor state s' \u2208 S, and returns a real-valued reward r and an observation of s'."}, {"title": "2.2 DSLs for Environments", "content": "A potential alternative to the standard practice of programming environments, is to use DSLs to describe sets of environments. This approach still requires significant engineering effort to develop a compiler that can translate descriptions from the DSL to a runnable simulator with an API for (learning) agents. However, once this compiler has been built, users with little to no programming experience may-depending on the complexity and user-friendliness of the DSL in question-use it to describe new environments that fit within the overarching domain supported by the DSL.\nNumerous examples of DSLs for describing sequential decision-making problems already exist, though their adoption as benchmarks in the RL community is limited compared to benchmarks such as the Arcade Learning Environment (Bellemare et al., 2013; Machado et al., 2018) or the DeepMind Control Suite (Tassa et al., 2018), which are not based on DSLs. Examples include PDDL (McDermott et al., 1998) for planning problems, and the Stanford Game Description Language (Love et al., 2008; Genesereth and Thielscher, 2014), Ludii (Piette et al., 2020), and MiniHack (Samvelyan et al., 2021) for various ranges of games. PDDLGym (Silver and Chitnis, 2020) provides Gym environment wrappers around PDDL problems."}, {"title": "2.3 Describing Environments in Natural Language", "content": "While DSLs may already be considered a more user-friendly alternative to general-purpose programming languages (Mernik et al., 2005; Aram and Neumann, 2015) for describing environments, natural language would be even more accessible to a wider userbase. Although the state of the art of large language models (LLMs) is highly impressive (Zhao et al., 2023), there are still concerns surrounding reliability and correctness (Marcus et al., 2023). Ambiguities typically present in natural languages, as well as the tendency for humans to underspecify task descriptions (e.g., rules of games), present challenges that require further research. Recently, Afshar and Li (2024) demonstrated promising initial results for an LLM generating executable environment code from natural language descriptions, but it still requires an expert human who is able to interpret the generated code and provide feedback on potential mistakes. In the short term, it may be more realistically feasible to use a combination of natural language and DSLs, where an LLM first translates a natural language description to a DSL-based description (Desai et al., 2016; Oswald et al., 2024; Zuo et al., 2024), and a user can inspect the generated description and make corrections if necessary. In the long term, if LLMs can be made sufficiently reliable, natural languages would likely be the most accessible modality for describing environments."}, {"title": "2.4 Research Focus on Description Languages for Environments", "content": "Before formally stating the central position of this paper, we make two assumptions relating to the user-friendliness of DSLs and natural languages (Assumption 1), and the desirability of this user-friendliness (Assumption 2).\nAssumption 1. Defining environments in DSLs or natural languages can be more user-friendly than general-purpose programming languages.\nIncreasing user-friendliness and lowering barriers to entry is a well-established motivation for the use of DSLs (Mernik et al., 2005; Aram and Neumann, 2015). Note that there may also be other reasons for using DSLs, and there can be DSLs that do not substantially lower barriers to entry: this depends on the design of the DSL in question. For example, the logic-based Stanford Game Description Language (Love et al., 2008; Genesereth and Thielscher, 2014) arguably still requires substantial technical expertise, and writing games in it may be considered error-prone due to the large file size required for many games. In contrast, allowing for clear and succinct descriptions that are easy to read and write was an explicit design goal for Ludii's description language (Piette et al., 2020). Likely in no small part due to the language's level of accessibility, Ludii has amassed a library of over 1200 distinct official game descriptions, including third-party contributions from game designers with little or no programming experience.\nIn the case of natural languages, if any concerns around ambiguities and underspecification of environments can be adequately addressed, we see little reason to doubt that many users would indeed find them more accessible than programming languages. If procedures translating natural language descriptions directly into executable simulations cannot be made sufficiently reliable, a potential solution may be to use DSLs as an intermediate step. Users could first describe their tasks in natural languages, and ideally only have to verify or fix small issues in automatically generated DSL descriptions afterwards.\nAssumption 2. Enabling environments to be defined in more user-friendly ways is desirable."}, {"title": "Position", "content": "The RL research community should place greater focus on benchmarks with environments defined in user-friendly DSLs or natural languages."}, {"title": "3 DESCRIPTIONS AS CONTEXT FOR GENERALISATION", "content": "The previous section argues for the importance of developing and benchmarking RL techniques that can operate on environments defined in DSLs or natural language, as opposed to general-purpose programming languages, and potential issues that may surface and are underexplored in the current research landscape. However, in addition to potential issues, we also see opportunities. In particular, succinct-but complete-environment descriptions may serve as a powerful tool to improve (zero-shot) generalisation (Kirk et al., 2023) across the set of all environments that may be described in the language of choice."}, {"title": "3.1 Generalisation in RL", "content": "The most straightforward setting in RL is to have an agent training in a single environment for some time, and to subsequently evaluate its performance in the same environment. This approach has a high risk of producing agents that overfit, in the sense that they may become overly reliant on spurious features, largely ignore state observations altogether and simply memorise trajectories of states or actions, or otherwise be incapable of handling even minor variations on the environment after training (Whiteson et al., 2011; Machado et al., 2018; Zhang et al., 2018, 2020).\nA popular category of RL research with a higher degree of generalisation involves training agents on a subset of one or more closely-related environments, and evaluating them in the same set, or a different set of similar environments (Farebrother et al., 2018; Justesen et al., 2018; Nichol et al., 2018; Cobbe et al., 2019, 2020; Stone et al., 2021). Different environments in this case may be different levels of the same video game, or subtle variants of an environment with, for example, modified background or foreground colours or patterns, different values for the velocities of certain entities or other numeric parameters, or different reward functions. While prior research collectively covers variation along all dimensions of environments (variation in transition dynamics, in colours used in state observations, in goals or reward functions, etc.), the work described in each publication individually tends to be restricted to a smaller subset of these dimensions. Soemers et al. (2023) used DSL-based environment descriptions for (zero-shot) transfer learning between different board games, but only to a relatively small degree, where the transfer mechanism was not automatically learnt. Banerjee and Stone (2007); Kuhlmann and Stone (2007) automatically identified mappings or transferable features between games, but they used a low-level logic-based DSL, which is arguably lacking in user-friendliness."}, {"title": "3.2 Generalisation through Context", "content": "Theoretical work suggests that, in the worst case, strong assumptions on the similarity between different environments are required for efficient generalisation to be possible (Malik et al., 2021). One reason for the difficulty of generalisation to unseen environments, without strong restrictions on the degree of variation, is that epistemic uncertainty about relevant parameters of the current environment essentially turns the collection of all environments that the agent may face into a partially observable environment-even if the current state of each individual environment is fully observable (Ghosh et al., 2021).\nThe notion of such a collection of environments, each of which may be identified by certain parameters (a context), of which some may never be used for training and only appear at test time, may be formalised as a contextual (Kirk et al., 2023) Markov decision process. Contexts may be as simple as just the value of a random seed that is used for procedural level generation, or take a more complex form such as a vector of parameters that describe important properties of the environment. Contexts may or may not be observable to the agent(s), although the ability to observe contexts-which should also carry sufficient information to enable disambiguation between environments-is required to resolve partial observability (Ghosh et al., 2021) induced by epistemic uncertainty.\nResearch on multi-task RL often involves providing contexts as inputs to agents, but these contexts tend to be far from full environment descriptions. For example, Deisenroth et al. (2014) provide goal coordinates for robotic control tasks as context. It is common to provide short, language-based instructions or hints to guide the agent (Luketina et al., 2019; Lifschitz et al., 2023; Kharyal et al., 2024), but such instructions do not (fully) describe the environment. Lee et al. (2023); Raparthy et al. (2023); Reed et al. (2023) prompt agents with demonstrations of interactions by experts for disambiguation between environments and in-context learning, which is a form of context that is arguably more difficult to acquire than environment descriptions (requiring an environment-specific expert to have already been trained), whilst simultaneously carrying less information (it does not reveal information about any parts of the environment that are not explored in the demonstration). Sun et al. (2020) use a DSL to prescribe policies that an agent should execute, as opposed to describing the environment itself. The textual descriptions provided to agents by Zhong et al. (2020) are perhaps closest to what we propose, although their descriptions are not sufficiently detailed to the extent that they could be compiled into a correct simulator, and are not meant to serve as a substitute for implementing the environment in a programming language."}, {"title": "3.3 Environment Descriptions as Context", "content": "If it is often desirable to describe environments in succinct DSLs or in natural language, as posited in Section 2, then these descriptions may also be used to improve generalisation by serving as contexts. Leveraging such descriptions as context should not be viewed as a reduction in generality, or being restricted to a particular DSL, as the general workflow of providing environments in such a language is arguably more accessible and more general than using a programming language for many potential end users. An important property of such environment descriptions is that they come from a shared language, and it ought to be possible for humans as well as programs to generate novel environment descriptions in the same language. We cannot only generate contexts from environments, but also generate environments (in the form of fully executable simulators) from contexts. From the researchers' point of view, this is valuable as it makes environments easily controllable and enables a wide variety of evaluation protocols (Kirk et al., 2023). From the learning agent's point of view, this property may also be valuable in that a program could actively learn about the description language that is used by procedurally generating new descriptions (Browne, 2009; Todd et al., 2024), translating them into executable simulators, and learning in them-effectively forming their own curriculum of environments (Dennis et al., 2020; Rigter et al., 2024).\nFurthermore, it could be argued that contexts that completely describe an environment to the extent that they could be translated into executable simulators are likely to be a prerequisite for unrestricted, zero-shot generalisation in RL (Irpan and Song, 2019). Consider the generalisation abilities of humans. In some cases, humans can effectively generalise to unseen situations without relying on explicit task descriptions, but in others they cannot. For example, if a human plays a new video game for the first time, in which there is something that looks like fire, they can infer that they should likely avoid the fire-based on their related experience in the physical world and other video games. However, if a human is faced with a brand new board game, they cannot be expected to play it well if they are not explained the rules of the game. Once the rules are explained, they may be able to play well immediately-based on their experience with related board games and ability to reason-without any direct experience with the game in question."}, {"title": "4 RELATED WORK", "content": "Mannor and Tamar (2023) caution against excessive focus of the research community on algorithms in existing benchmarks, with little attention for deploying to novel problems, but they do not discuss ease of use, or user-friendly environment description languages as a potential solution. Rodriguez-Sanchez et al. (2023) introduce RLang as a DSL that can be used to provide background knowledge on any aspect of an environment. However, they propose for such descriptions to be provided in addition to environment implementations in general-purpose programming language, rather than as a replacement. Nevertheless, this could be an example of a DSL that could be used for our proposed research agenda. Jothimurugan et al. (2019) describe a DSL used to specify reward functions via, e.g., goals and constraints, but no other aspects of the environment. Focusing specifically on the problem of representing goals (rather than full environments), and not necessarily from the perspective of users who are not engineering or RL experts, Davidson and Gureckis (2024) also consider goal representations based on programs (essentially DSLs) (Davidson et al., 2024) and natural languages, among other solutions."}, {"title": "5 CONCLUSION", "content": "It is common practice in reinforcement learning (RL) research to implement environments in general-purpose programming languages or frameworks such as CUDA or JAX for hardware acceleration. Such implementations require engineering skills and effort, and often leverage RL expertise to handcraft efficient representations of the state and action spaces. In this position paper, we have argued that this established workflow is not accessible to smaller organisations or private individuals who may not have access to this expertise, and therefore hinders widespread adoption of RL for real-world applications outside of larger projects by teams with substantial resources.\nWe envision a path to addressing this concern based on using more user-friendly languages, ranging from domain-specific languages to natural languages, for describing environments. Such languages may democratise the ability to apply policies trained with RL to novel problems. This research agenda is expected to involve numerous aspects. DSL-based solutions will require studies of how to develop user-friendly DSLs for describing RL problems, evaluations of their user-friendliness (e.g., via user studies), and the development of efficient compilers or even JAX wrappers for such DSLs. Solutions based on natural languages will require advances in the reliability and consistency of LLMs. Improving the sample efficiency of RL may become even more crucial than it already is. Our focus in this paper has been on democratising the ability to describe RL problems, but this will likely need to be paired up with advances in e.g. AutoRL (Parker-Holder et al., 2022) to also democratise the ability to effectively train policies. Finally, using succinct, information-rich descriptions of environments as context may open up new opportunities for generalisation and transfer in RL."}]}