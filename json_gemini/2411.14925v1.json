{"title": "Purrfessor: A Fine-tuned LLaVA Diet Health Chatbot", "authors": ["Linqi Lu", "Yifan Deng", "Chuan Tian", "Sijia Yang", "Dhavan Shah"], "abstract": "This study introduces Purrfessor, an innovative AI chatbot designed to provide personalized dietary guidance through interactive, multimodal engagement. Leveraging the Large Language-and-Vision Assistant (LLaVA) model fine-tuned with food and nutrition data and a human-in-the-loop approach, Purrfessor integrates visual meal analysis with contextual advice to enhance user experience and engagement. Two studies were conducted to evaluate the chatbot's performance and user experience: (a) simulation assessments and human validation examined the performance of the fine-tuned model; (b) a 2 (Profile: Bot vs. Pet) by 3 (Model: GPT-4 vs. LLaVA vs. Fine-tuned LLaVA) experiment revealed that Purrfessor (Pet + Fine-tuned LLaVA) significantly enhanced users' perceptions of care (\u03b2 = 1.59, p < 0.04) and interest (\u03b2 = 2.26, p = 0.005) compared to a GPT-4 bot. Additionally, user interviews highlighted the importance of interaction design details, emphasizing the need for responsiveness, personalization, and guidance to improve user engagement.", "sections": [{"title": "1. Introduction", "content": "Chatbots are increasingly shaping healthcare and lifestyle management solutions in the evolving field of artificial intelligence (AI)-powered conversational agents. The progression of chatbot technology, especially in health management, has transitioned from simple, rule-based systems to sophisticated conversational agents powered by natural language processing (NLP), machine learning (ML), and large language models (LLMs). This shift has enabled chatbots to engage in real-time, context-sensitive interactions, offering advice tailored to individual behaviors. While traditional apps (e.g., MyFitnessPal) provide static tracking of health metrics, AI-enhanced chatbots have the potential to actively guide users through interactive and personalized experiences that adapt over time [12, 13]. AI-chatbots designed for health interventions offer immense potential, especially in addressing dietary habits and promoting physical activity, two key behaviors linked to chronic conditions such as cardiovascular disease, type 2 diabetes, and obesity [5, 8].\nDespite the proliferation of general health tracking apps, many, such as MyFitnessPal and Lifesum, fall short in offering interactive and personalized health dialogues that adapt in real-time to user behaviors or contexts. Recent studies emphasize the potential of AI-driven health chatbots in providing on-demand guidance, including multimodal inputs, overcoming limitations associated with static health apps and accessibility barriers [6, 26]. For example, leveraging computer vision alongside NLP, chatbots can now assess user-uploaded images of meals to provide immediate feedback, a capability that elevates their role in dietary management [15, 21].\nBuilding on this work, this study introduces an innovative AI chatbot, Purrfessor, designed with advanced interactive functionalities, including personalized feedback facilitated by the LLAVA model (LLaVA-v1.6-13b) [14] fine-tuned through instructional datasets, to provide personalized dietary guidance based on user-uploaded food images and text prompts. With a structured data approach that maps food types to nutritional information and recipe suggestions, the chatbot offers users customized meal analysis to enhance the relevance and accuracy of nutritional assessments [17, 21]. Our exploration of this chatbot's interactive design aims to reveal insights into how AI chatbots can become compelling health companions, fostering positive dietary habits and potentially reshaping the landscape of AI health interventions [2, 15].\nOne of the primary goals of the Purrfessor system is to address pressing dietary and health-related challenges faced by specific populations, particularly those in low socioeconomic status (SES) groups and historically disadvantaged groups where time and resource constraints can hinder healthy meal planning. By providing accessible, rapid suggestions for balanced meals based on ingredients users have on hand, Purrfessor is positioned to support families with limited grocery budgets or time to prepare nutritious meals, offering a tailored solution to concerns like childhood obesity and nutrition insufficiencies common in many low-SES and/or historically disadvantaged communities."}, {"title": "2. System Design and Structure", "content": "The system architecture for the AI-powered dietary chatbot, illustrated in Figure 1, is designed to facilitate seamless interaction between users and an advanced conversational AI model, with a focus on dietary guidance and health recommendations. The architecture leverages cloud-based resources, a structured database, and front-end web applications to create an interactive, user-friendly experience."}, {"title": "2.1. System Architecture for Testing", "content": "The system architecture for the AI-powered dietary chatbot, illustrated in Figure 1, is designed to facilitate seamless interaction between users and an advanced conversational AI model, with a focus on dietary guidance and health recommendations. The architecture leverages cloud-based resources, a structured database, and front-end web applications to create an interactive, user-friendly experience."}, {"title": "2.2. Components", "content": ""}, {"title": "2.2.1 User Interface", "content": "The main user interface is accessible via a web page, referred to as \"Pet vs Bot\". This webpage serves as the primary interaction point for users, allowing them to converse with the chatbot, upload images for analysis, and receive dietary advice."}, {"title": "2.2.2 User Accounts Management", "content": "The system includes a user account feature that enables personalized interactions and user-specific recommendations. User account data is stored and managed within a secure environment, allowing the chatbot to remember user preferences, past interactions, and provide tailored guidance."}, {"title": "2.2.3 Server", "content": "Node.js serves as the central hub of the system, orchestrating the flow of data between the front end, database, and AI models. The Node.js server is responsible for:\n\u2022 Handling HTTP requests from the user interface and sending responses back to the webpage.\n\u2022 Processing API requests to interact with the ChatGPT and fine-tuned LLaVA models, facilitating real-time responses.\n\u2022 Routing data to and from the ConversationDB, ensuring smooth storage and retrieval of user conversations."}, {"title": "2.2.4 Conversation Database (ConversationDB in\nMongoDB)", "content": "MongoDB is used as the database management system to store user interactions and chat history. Known as ConversationDB, this database enables the system to:\n\u2022 Log user inputs and chatbot responses to ensure continuity in user interactions by referencing past conversations.\n\u2022 Analyze user behavior to refine chatbot responses and enhance personalization.\n\u2022 Support model fine-tuning by storing real user interaction data for improving chatbot accuracy over time."}, {"title": "2.2.5 Cloud-Based Model Hosting", "content": "The fine-tuned LLaVA model is deployed on a cloud server, allowing the system to perform complex computations and ensure scalability. The cloud-based hosting provides:\n\u2022 Efficient processing of image data and response generation for multiple concurrent users.\n\u2022 Scalability to handle increased demand without compromising performance.\n\u2022 Model updates and improvements, enabling the team to fine-tune and enhance response accuracy over time."}, {"title": "2.3. Chatbot Profile", "content": "The Purrfessor chatbot's visual persona is represented by a cat-themed avatar with large, inviting eyes, glasses, and a bowtie, projecting a scholarly yet charming personality. This profile is designed to create a warm and engaging experience, encouraging users to return for guidance on meal planning."}, {"title": "2.4. Interface Design and Interaction Flow", "content": ""}, {"title": "2.4.1 Conversation Bar with Prompt Suggestions", "content": "The interface displays a set of prompt suggestions just above the conversation bar to inspire user interaction, especially for new users. Examples include:\n\u2022 \"Please take a look at my refrigerator and tell me what healthy meals I can cook!\"\n\u2022 \u201cHave a dish in mind? Upload an image, and we'll find a matching recipe.\"\n\u2022 \"Looking for a Seafood Pasta recipe today?\"\n\u2022 \"Want to explore high-protein vegetarian meals?\"\nThese prompts can be clicked to auto-populate the conversation bar, streamlining the user experience."}, {"title": "2.4.2 Menu Icon Hints with Tooltip-Based Approach", "content": "To improve navigation, the menu includes tooltip hints that appear when users hover over or tap on icons. For example:\n\u2022 Hovering over the \"Meal Plan\u201d icon reveals the tooltip: \u201cClick here to generate a custom meal plan based on your preferences.\"\n\u2022 Other features include a \"?\" icon, allowing users to view a short description of their purpose."}, {"title": "2.4.3 Cue for Uploading Images", "content": "An interactive image upload button is integrated into the conversation bar for features involving image-based recipe suggestions. This button changes color or provides visual cues to encourage users to upload images of ingredients or meals."}, {"title": "2.4.4 Interactive Walkthrough on First Use", "content": "New users are guided through the main features of the chatbot via an interactive walkthrough. This onboarding process highlights:\n\u2022 Key interface elements, such as prompt suggestions, the image upload feature, and menu icons.\n\u2022 Demonstrations on how to start a conversation by selecting example prompts or typing custom questions."}, {"title": "2.4.5 Menu Functions", "content": "\u2022 Chat Interface: Utilizing image recognition capabilities, Purrfessor identifies foods in user-provided images, assessing nutritional indices to offer personalized food recommendations.\n\u2022 Misinformation Clarification: By integrating verified information from authoritative sources, Purrfessor addresses common misconceptions related to diet and nutrition, promoting accurate knowledge.\n\u2022 Recipe Showcase: Purrfessor displays cooking inspiration aligned with dietary preferences and nutritional needs."}, {"title": "3. Chatbot Fine-tuning Methods", "content": "LLaVA is a refined large language model (LLM) that integrates \"an open-set visual encoder from CLIP with the Vicuna language decoder\" to bridge visual and linguistic understanding in multimodal contexts [14]. This architecture allows LLaVA to process and interpret both images and text, enabling it to handle diverse instruction types such as image descriptions, dialogue, and complex reasoning-by leveraging the strengths of both its visual and language model components. During our experiments, we used the LLaVA-Vicuna-13b 1.6 version as the starting point. Since LLaVA has not been specifically trained on food and nutrition-related data, we performed fine-tuning using a custom training dataset."}, {"title": "3.1. Training Dataset", "content": "The training dataset was constructed by integrating multiple data sources:\n1. FoodData Central: Foundation Foods from the U.S.\nDepartment of Agriculture (USDA) (https://fdc.nal.usda.gov/).\n2. Recipe1M dataset [21]: This dataset, designed for learning cross-modal embeddings between cooking recipes and food images, includes cooking instructions, nutrition data, and ingredients. It was used to construct the instruction tuning dataset.\n3. Human-Annotated Dataset: A dataset of 500 human-annotated food-related images was included to enhance the model's capability to provide healthy cooking instructions starting from visual inputs of ingredients.\nTo ensure the model could generate precise nutritional information, we incorporated the FoodData Central: Foundation Foods dataset and conducted knowledge injection into the model. The instruction tuning dataset also included caring and supportive language at the beginning and end of responses to enhance the emotional support provided to users."}, {"title": "3.2. Human-annotated Data", "content": ""}, {"title": "3.2.1 Image Collection Using Google Image Search", "content": "A Google Image Search (GIS) method was implemented to systematically collect food-related images from online sources using Python and the Google Custom Search API. This approach follows established practices in data-intensive research for image retrieval [20, 27]. The collection process utilized the googleapiclient package [9], with a custom search engine ID and API key configured to automate retrieval.\nA set of pre-defined search queries, tailored with keywords related to raw produce and cooking ingredients, was employed to filter relevant images and metadata. Example queries included:\n\u2022 \"raw food\"\n\u2022 \u201cproduce and meat in fridge\"\n\u2022 \"fresh produce\"\n\u2022 \u201cproduce in fridge\"\n\u2022 \u201cfood ingredients\"\n\u2022 \u201craw meat and produce\"\n\u2022 \u201ccooking raw meat and vegetables\"\n\u2022 \"fresh produce for cooking\"\nMetadata extracted for each image included:\n\u2022 Collection date\n\u2022 Page title\n\u2022 Source website\n\u2022 Image URL\n\u2022 Page URL\nWhere available, dates were extracted directly from URLs using regular expressions, following established methodologies for metadata organization [1]. This enabled chronological organization of the dataset for subsequent analysis and validation."}, {"title": "3.2.2 Image Captioning and Q&A Generation", "content": "Each image in the dataset was processed through GPT-4o using a structured prompt designed to elicit detailed captions and chatbot-friendly Q&A examples. The prompt instructed the model to generate the following outputs:\n\u2022 A detailed caption describing visible ingredients.\n\u2022 A Q&A response including:\n   - A greeting.\n   - Nutritional information for the identified ingredients.\n   - Healthy recipe suggestions.\n   - A step-by-step guide for each recipe.\n   - A closing message encouraging user engagement.\nTo ensure consistency, each prompt followed a structured output format, facilitating straightforward parsing and subsequent training of the LLaVA model. The inclusion of nutritional information and recipe suggestions aimed to simulate real-world interactions, enabling the model to respond both informatively and engagingly [19]."}, {"title": "3.2.3 Human-in-the-Loop", "content": "After the initial output generation, human annotators reviewed each caption and Q&A example to ensure clarity, accuracy, and alignment with expected chatbot responses. Key aspects of the review process included:\n\u2022 Verifying language appropriateness and grammatical correctness.\n\u2022 Ensuring logical flow and alignment with user expectations.\n\u2022 Handling edge cases and special characters appropriately.\nFor ambiguous or non-food images, annotators crafted captions and Q&A responses neutrally, avoiding refusals and maintaining factual descriptions of the content in line with the prompt guidelines [27]. Edge cases were explicitly included in the dataset, with Q&A examples refined by human reviewers to ensure robust training data. This approach prepared the model to handle diverse real-world scenarios effectively."}, {"title": "3.3. Fine-Tuning Strategy", "content": "Initially, we attempted to perform full tuning on the LLaVA-Vicuna-13b model, as the abundance of examples in the Recipe1M dataset provided a strong foundation. However, the GPU memory required to fully tune a 13B-parameter model exceeded the capacity of the available hardware. To address this limitation, we adopted the Low-Rank Adaptation (LoRA) technique, which enables fine-tuning of large models with reduced computational requirements.\nWhile LoRA proved effective for reducing the hardware burden, we encountered overfitting issues with the Recipe1M dataset. Specifically, the model tended to respond with cooking instructions for every query, regardless of context. To mitigate this, we diversified the training set by integrating the human-annotated visual dataset, enabling the model to provide healthy cooking instructions starting from visual inputs, such as raw ingredients.\nThe fine-tuned version of the Purrfessor chatbot represents a state-of-the-art approach in AI-driven dietary guidance. By combining advanced multimodal technology with user-centric design principles, the chatbot offers evidence-based nutritional information, personalized recipe suggestions, and emotionally supportive interactions, setting a new benchmark for dietary chatbots."}, {"title": "4. Study A. Chatbot Simulation Testing", "content": ""}, {"title": "4.1. Methodology", "content": "To evaluate the performance of our fine-tuned chatbot, Purrfessor, we adopted a two-phase evaluation framework that combined automated metrics and human-in-the-loop validation. This approach ensured a rigorous assessment of both quantitative and qualitative aspects of the model's performance."}, {"title": "4.1.1 Dataset and Q&A Generation", "content": "The dataset for this study consisted of 500 real-world images sourced via the Google Image Search API, paired with synthetically generated prompts designed to simulate a wide range of user queries. The images encompassed diverse food categories, including everyday meals, beverages, and culturally specific dishes, reflecting the variety users might encounter in real-world applications. Prompt diversity included direct identification tasks (e.g., \"What food-related items appeared in this image?\") and contextual queries (e.g., \"Do you have ideas on recipes with low-fat per the current ingredients I provide?\u201d). This ensured that the Q&A pairs captured both fundamental object detection and contextual reasoning challenges."}, {"title": "4.1.2 Evaluation Metrics", "content": "For automated assessment, we employed a text overlap metric to measure consistency between detected food-related nouns in chatbot responses and expected terms. Using an NLP-based approach, we extracted food-related words and analyzed the overlap rate among food-related nouns from GPT-4 and Purrfessor. This overlap score served as an initial indicator of accuracy, with a threshold of 0.6 used to identify low-performing cases. Recognizing the limitations of simple overlap-based metrics in capturing semantic nuances (e.g., \"greens\" vs. \"lettuce\"), we adopted a human-in-the-loop approach to address these gaps. Future studies could incorporate semantic similarity measures, such as cosine similarity of word embeddings, to provide a more robust evaluation."}, {"title": "4.1.3 Human Validation Process", "content": "Human validation was conducted by three human coders who assessed the responses from the fine-tuned LLaVA model, Purrfessor, using four main criteria (see Table 1):\n1. Correctness: Accuracy of food item detection in the images.\n2. Relevance: Pertinence of the chatbot's responses to the user queries.\n3. Clarity: Coherence and ease of understanding of the responses.\n4. Handling Edge Cases: Ability to address ambiguous or non-food images appropriately.\nEach criterion was rated on a 10-point scale following established methodologies for scaled evaluation in chatbot performance studies [18]. Detailed scoring guidelines were provided to ensure consistency (see Appendix I). For example, correctness was evaluated based on the accurate identification of food items in an image, while handling edge cases examined responses to ambiguous or non-food images.\nInter-coder reliability was calculated using Krippendorff's alpha, yielding high agreement among evaluators:\n\u2022 Accuracy = 0.86\n\u2022 Relevance = 0.96\n\u2022 clarity = 0.91\n\u2022 Edge case = 0.85\nThe responses were categorized using a three-level scale: low (1-3), medium (4\u20137), and high (8-10). These scores provided a comprehensive evaluation of the chatbot's performance, highlighting its strengths and areas for improvement."}, {"title": "4.2. Results", "content": ""}, {"title": "4.2.1 Automated Metrics", "content": "The text overlap score for image object detection tasks averaged 0.67, indicating moderate alignment between the chatbot's outputs and expected responses. This score reflects performance differences between GPT-4 and the fine-tuned LLaVA model. Discrepancies in low-scoring cases often arose from nuanced distinctions (e.g., \"pasta\" vs. \"spaghetti\") or the omission of less visually salient items (e.g., garnishes). To address these limitations, a human review of low-overlap cases (<0.6, n = 100) was conducted to validate the results and provide qualitative insights into performance gaps."}, {"title": "4.2.2 Comparison with GPT-4", "content": "A comparison between Purrfessor and GPT-4 highlighted differences in descriptive depth and contextual richness. While GPT-4 often provided elaborative responses that included nutritional context (e.g., \u201ca vibrant dish high in fiber, featuring fresh vegetables and whole grains\"), Purrfessor prioritized concise and factual outputs (e.g., \"vegetable salad with carrots and spinach\"). Although the succinct responses from Purrfessor were generally accurate, they provided fewer contextual details that users might find helpful in decision-making scenarios.\""}, {"title": "4.2.3 Human Evaluation", "content": "The human validation scores demonstrated the chatbot's strengths and areas for improvement across the four evaluation criteria:\nCorrectness (M = 7.87): Responses were largely accurate, though minor discrepancies were noted in images containing overlapping or visually similar items (e.g., distin-"}, {"title": "5. Study B. User Experience Testing", "content": ""}, {"title": "5.1. Study Design", "content": "This study utilized a 2 (Chatbot Profile: Bot vs. Anthropomorphic) by 3 (Chatbot Model: GPT-4 vs. Raw LLaVA vs. Fine-tuned LLaVA) between-subject design, with an additional Baseline condition (ChatGPT only). The independent variables were visual profile (Bot, Anthropomorphic) and chatbot algorithm (ChatGPT-4, Fine-tuned LLaVA), while the dependent variables included user experience, attitudes, and intentions to adhere to the chatbot-recommended recipes. Participants interacted with the chatbot by asking questions, uploading photos, and receiving personalized healthy recipe recommendations."}, {"title": "5.2. Data Collection and Participants", "content": "Participants were undergraduate students aged 18-25 (N = 51) from a Midwestern university who received extra credit for their participation. Each participant was randomly assigned to one of six experimental conditions. Prior to the experiment, participants provided informed consent and completed a pre-experiment questionnaire collecting demographic information, assessing technology literacy, and gauging their predisposition toward AI-powered chatbots.\nParticipants engaged in a 15-minute conversation with their assigned chatbot, during which they received personalized dietary recommendations and guidance. Post-interaction, they completed a questionnaire evaluating user experience, attitudes toward the chatbot, engagement levels, and perceptions of the sequenced conversation. At the study's conclusion, participants were debriefed about the chatbot's information sources and thanked for their participation."}, {"title": "5.3. Measures", "content": ""}, {"title": "Manipulation Check", "content": "Two questions were designed to verify participants' recall of the chatbot they interacted with during the experiment. Participants were asked to identify the chatbot's name and describe its profile image."}, {"title": "User Experience Questionnaire (UEQ)", "content": "The User Experience Questionnaire (UEQ) evaluated user interactions with the chatbot, covering aesthetic impressions and functional effectiveness [22]. Participants rated eight items (M = 3.69, SD = 0.71, \u03b1 = .92). Key dimensions included:\n\u2022 Attractiveness: Assessed overall aesthetic appeal (e.g., \"annoying/enjoyable,\u201d \u201cattractive/unattractive\").\n\u2022 Perspicuity: Evaluated ease of use (e.g., \"difficult to use,\u201d \"clear/confusing\").\n\u2022 Stimulation: Determined the product's excitement and motivation to use (e.g., \u201cboring/exciting\").\n\u2022 Novelty: Gauged innovation and creativity (e.g., \"conservative/innovative\")."}, {"title": "Care Perceptions", "content": "Care perceptions were measured using four items rated on a 5-point Likert scale (M = 4.97, SD = 1.33, \u03b1 = .91). Example items included: \u201cThis chatbot cares about our well-being\u201d and \u201cThis chatbot makes me feel a kind of emotional support.\""}, {"title": "User Interest", "content": "User interest was assessed through three 5-point Likert scale questions (M = 4.97, SD = 1.33, \u03b1 = .91). Sample items included: \u201cThis chatbot is appealing\" and \"This chatbot piques my interest in engaging in conversations.\""}, {"title": "Compliance Intention", "content": "Compliance intention measured participants' likelihood of adopting chatbot recommendations using three items (M = 3.43, SD = 0.76, \u03b1 = .89). Statements included: \"I will consider adopting the suggestions from the chatbot that was just used.\""}, {"title": "5.4. Regression Analysis Results", "content": "The multiple linear regression analysis, controlling for demographic characteristics and predispositions, showed the following:\n\u2022 The fine-tuned LLaVA anthropomorphic chatbot Purrfessor (\u03b2 = 1.59, p = 0.04) and the raw LLaVA anthropomorphic chatbot (\u03b2 = 1.58, p = 0.02) were both positively associated with care, showing more effective engagement compared to the GPT-4 bot.\n\u2022 The fine-tuned LLaVA anthropomorphic chatbot Purrfessor (\u03b2 = 2.26, p = 0.01) and the raw LLaVA anthropomorphic chatbot (\u03b2 = 2.50, p < 0.001) were positively associated with user interest compared to the GPT-4 bot.\n\u2022 For user experience quality, the fine-tuned LLaVA bot-like chatbot (\u03b2 = 1.10, p = 0.02) and the raw LLaVA cat chatbot (\u03b2 = 0.88, p = 0.02) showed slight improvements compared to the GPT-4 bot.\n\u2022 Regarding overall satisfaction, the fine-tuned LLaVA bot-like chatbot emerged as a significant enhancer of satisfaction (\u03b2 = 1.01, p = 0.03) compared to the GPT-4 bot.\n\u2022 Compliance intentions to the chatbot's suggestions did not show statistical significance, F(14,36) = 1.25, p = 0.29."}, {"title": "5.5. User Interview", "content": "An in-depth interview was conducted with 8 participants who interacted with the fine-tuned LLaVA chatbot Purrfessor (in April 24 version). The goal was to gather personal feedback and refine system design. Two interview coders independently reviewed transcripts to ensure consistency in thematic coding, confirmed through cross-validation to enhance accuracy and credibility [3]. A qualitative thematic analysis revealed three primary themes for future improvement: Interaction and Responsiveness, Personalization and Relevance, and Guidance and Instructions."}, {"title": "5.5.1 Interaction and Responsiveness", "content": "Participants expressed a desire for more seamless and dynamic interactions. Long response times disrupted engagement, reducing the fluidity of conversations. Suggestions included displaying user input immediately and generating chatbot responses progressively to enhance real-time interaction.\n\"The waiting time is long. You can make it same time typing to add interaction.\"\n\"Whenever I ask a question, I have to wait, with my question still in the input box, until the chatbot finishes its response.\"\n\"The version of output can be improved and the answer format like greetings can add more fun language. Emoji to fit the robot personality.\"\nThese insights suggest improvements in conversational design, such as real-time responsiveness and playful, context-sensitive language, to enhance user satisfaction and engagement. Adding personality-enhancing language may better align the chatbot's tone with its anthropomorphic persona, creating a more entertaining and personable experience [3, 25]."}, {"title": "5.5.2 Personalization and Relevance", "content": "Participants emphasized the importance of personalized and context-aware interactions. While chatbot responses were accurate and relevant, the inability to reference previous interactions limited conversational richness.\n\"The answers seem accurate, useful, and on point; however, when I ask follow-up questions, it does not consider the prior questions I asked.\"\n\"Adapt the recipe based on the user's preference and hometown.\""}, {"title": "5.5.3 Guidance and Instructions", "content": "Participants indicated a need for clearer guidance on how to engage with the chatbot effectively. Uncertainty during initial interactions led to hesitation or confusion.\n\"At the beginning, I didn't know what to do. If the initial page gave me some hints or introductions, I might be clearer.\"\n\"You could add some suggestions for users to start a conversation with the chatbot.\"\nIntroducing conversational prompts or visual guides at the outset may reduce cognitive load and empower users to make full use of the chatbot's functions. Providing accessible guidance aligns with findings in digital interface studies, which emphasize the importance of clear onboarding processes to facilitate user engagement [23, 25]."}, {"title": "6. Discussion and Conclusion", "content": "Our simulation test reveals a distinction in descriptive nuance between GPT-4 and LLaVA. While GPT-4 generated responses that were rich in context, offering nutritional insights and detailed descriptions, LLaVA's responses were more straightforward and focused on item identification. This difference highlights GPT-4's strength in generating comprehensive responses, potentially enhancing user understanding and satisfaction. However, LLaVA's simpler descriptions may appeal to users who prefer direct and accessible information. This discrepancy between the models emphasizes the need to balance narrative richness and simplicity based on user preference and context.\nThe results suggest that the fine-tuned LLaVA chatbot, designed with an anthropomorphic persona enhanced user perception of care and engagement intentions compared to the GPT-4 chatbot with a bot profile. Both the fine-tuned and raw versions of LLaVA outperformed GPT-4 in eliciting perceptions of care and interest, likely due to the integration of a relatable, visually engaging avatar. This aligns with literature suggesting that personality-driven chatbots can increase user satisfaction and emotional engagement [18]. However, while Purrfessor performed well in increasing user interest and engagement, the study did not observe significant improvements in compliance behaviors. This suggests that, for health intervention chatbots, simply improving conversational quality or introducing an endearing avatar may not be sufficient to influence behavior adherence in the short term. Future studies could investigate whether sustained interaction with personality-driven bots leads to greater behavioral compliance over time, an area unexplored in current literature.\nThe qualitative data obtained from user interviews revealed three major themes: interaction responsiveness, personalization, and guidance for effective interaction. Users expressed a desire for quicker response times, suggesting progressive answer displays or real-time typing feedback to enhance the chatbot's interactivity. This feedback aligns with prior research that emphasizes the role of prompt response in user satisfaction with digital interfaces [10]. Additionally, users sought more personalized interactions, wanting the chatbot to remember prior conversations and adapt to individual preferences, which points toward the importance of adaptive AI systems in fostering long-term user engagement. Finally, users noted that introductory hints or interaction examples would make the chatbot experience more intuitive, underscoring the need for clear guidance to improve first-time user experience. Despite its insights, this study faces limitations, including limited sample size and the specificity of AI conditions tested, which might not generalize across all types of AI applications. Future research should explore a broader array of AI configurations and include a more diverse demographic to enhance the generalizability of the findings, which could provide deeper insights into the subjective experiences of users interacting with AI systems, complementing the quantitative data presented.\nIn conclusion, this study advances the field of computational communication by providing concrete evidence on how specific design enhancements\u2014such as personalized visual profiles and refined language-image processing-can significantly impact user engagement and satisfaction in health chatbots. The findings suggest that user-centered design, which incorporates tailored interactions and context-sensitive responses, holds promise for developing chatbots that are not only engaging but also more effective in delivering health-related advice. This study also sets a foundation for future Al experimental research in health chatbot ap-"}]}