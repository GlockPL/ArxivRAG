{"title": "Transforming Location Retrieval at Airbnb: A Journey from Heuristics to Reinforcement Learning", "authors": ["Dillon Davis", "Huiji Gao", "Weiwei Guo", "Thomas Legrand", "Malay Haldar", "Alex Deng", "Han Zhao", "Liwei He", "Sanjeev Katariya"], "abstract": "The Airbnb search system grapples with many unique challenges as it continues to evolve. We oversee a marketplace that is nuanced by geography, diversity of homes, and guests with a variety of preferences. Crafting an efficient search system that can accommodate diverse guest needs, while showcasing relevant homes lies at the heart of Airbnb's success. Airbnb search has many challenges that parallel other recommendation and search systems but it has a unique information retrieval problem, upstream of ranking, called location retrieval. It requires defining a topological map area that is relevant to the searched query for homes listing retrieval. The purpose of this paper is to demonstrate the methodology, challenges, and impact of building a machine learning based location retrieval product from the ground up. Despite the lack of suitable, prevalent machine learning based approaches, we tackle cold start, generalization, differentiation and algorithmic bias. We detail the efficacy of heuristics, statistics, machine learning, and reinforcement learning approaches to solve these challenges, particularly for systems that are often unexplored by current literature.", "sections": [{"title": "1 Introduction", "content": "Airbnb is a trusted platform for hosts with diverse homes everywhere around the world. It serves guests with increasingly unique preferences about location, amenities, style, price, and more. Traditional travel accommodations are often concentrated in a few limited areas of a searched location. However, Airbnb often has inventory spread throughout the surrounding areas with varying density, amenities, styles, prices, space, and environments. For example, a family who may not like the limited inventory available in a city with short term rental regulations, typically might stay at a hotel for a trip. However, single family home inventory in cities right outside of the regulated city may suit them much better than the semiprivate, smaller accommodations in the city. This is evidenced by the extensive booking behavior of San Francisco searchers in surrounding areas like Daly City.\nThis presents Airbnb the opportunity to truly allow any guest to belong anywhere, regardless of their needs. We can infer where guests might be willing to stay for any given destination and expose different kinds of inventory available across those destinations. If we can do this, while respecting their flexibility and preferences, we can provide guests with much better travel experiences and appeal to a wider audience.\nA typical guest journey starts by entering a destination into the search bar (a location search) and receiving a list of the top ranked, most bookable results for their search. Some guests (~52%) then pan and zoom the displayed map (a map search) to find more listings that may be more suitable for them. Many guests never go beyond the initial location search to explore Airbnb's diverse inventory in more detail. Exposing this unique, differentiated, bookable inventory in the initial location search can help all guests better understand the breadth and depth of Airbnb's offerings.\nAirbnb has incredible scale with over 7M+ active listings, ~390M nights booked per year and proportionately large search volume. It also has complex ranking systems with strict performance and product expectations. As a result, it is infeasible to rank every listing for every search. We also cannot simply filter by whether a listing matches the exact searched location, due to the value and"}, {"title": "2 Cold Start Heuristics for Location Retrieval", "content": "The initial approach for location retrieval was simple heuristics based on the type of location that was searched, i.e., country, state, city, neighborhood, address, etc. They typically took advantage of the administrative bounds that outline the exact map area corresponding to the searched location. The heuristics for each location type are outlined below.\n(1) Countries, states, neighborhoods (Heuristic 1): Use the administrative bounds from geocoding services to retrieve listings that are exactly within the searched location.\n(2) Cities (Heuristic 2): We construct retrieval bounds with a 25 mile radius around the searched location's center\n(3) Addresses and buildings (Heuristic 3): We used retrieval bounds constructed by scaling the administrative bounds from geocoding services by 2.5X to prevent showing little to no results and better match booking behavior.\nThese heuristics served as simple cold start techniques that allowed the product to function as intended as well as collect information over time about booking preferences. We also improved Heuristic 3 by introducing a parameterized smooth function that computes an expansion factor for the original diagonal size of the administrative bounds (Heuristic 4). The log scale function $f$ scaled the original diagonal size by a hyperparameter $\u03b2$ and offset $\u03b1$ shown below. This function better captured inventory in the surrounding areas of these very specific locations, providing guests with more options.\n$f(d) = max(1.0, \u03b1 + \u03b2 * ln(d + 1)).$\nwhere $d$ is the administrative bounds diagonal size, $\u03b1$ = 2.9 and $\u03b2$ = -0.5. Hyperparameter values were chosen by maximizing expansion while still respecting the performance constraints of our search system."}, {"title": "3 Statistics based Location Retrieval", "content": ""}, {"title": "4 Machine Learning based Location Retrieval", "content": ""}, {"title": "4.1 The opportunity", "content": "Beyond naively applying where Airbnb's guests had booked in the past for a location, we believed that there was an opportunity to learn from this data. This could generalize better for locations with little data, differentiate search experiences based on specific search parameters, and improve the experiences of non-bookers by learning from booker behavior.\nFor example, large group travelers searching for San Francisco book in significantly different locations than San Francisco searchers overall, demonstrated in Figure 1 and 3. Differentiating search experiences based on parameters like guest count and lead time could potentially provide more succinct, relevant results for guests."}, {"title": "4.2 The Approach", "content": "The location retrieval problem can be formulated in the following way in order to generalize and differentiate searches based on prior data and search parameters. We define the location retrieval model as a function $f$, that takes features derived from a search request $x$ and produces a location bound $y$, which contains 4 floats\n$y = [swLatOffset, neLatOffset, swLngOf fset, neLngOffset]$"}, {"title": "5 Reinforcement Learning Based Location Retrieval", "content": ""}, {"title": "5.1 The opportunity", "content": "The initial machine learning approach was cyclical in nature. We only learned booking preferences relative to search parameters within the map areas that were selected by the preexisting model. Exploring and learning for searches where the model has little confidence and updating the model with newly collected data could address this bias and improve the experience."}, {"title": "5.2 The challenge of location retrieval exploration", "content": "Location retrieval can be reformulated as a reinforcement learning problem, more specifically a contextual multi-armed bandit task, in order to explore for new locations and exploit the known. The context is defined by a search with location, dates, etc. There are 4 continuous actions, defined as northern, southern, eastern and western expansion from the center of the searched location with the potential reward of a booking.\nApproaches for contextual multi armed bandits require the following three components\n(1) Active Contextual Estimation: A method to estimate actions and rewards given a context that is regularly updated based on new exploration and feedback\n(2) Uncertainty Estimation: A method to determine the confidence of the estimator's predictions\n(3) Exploration Strategy: A method to facilitate exploration and data collection for actions\nAdditionally, potential solutions had to fulfill the following product constraints\n(1) Deterministic: The prediction should be stable and consistent across different guests for the same query on the same day while ranking handles personalization.\n(2) Optimistic Confidence Based: Only optimistically explore using reasonably, larger retrieval bounds for searches with low confidence predictions\n(3) Performant: Solutions must satisfy the latency and performance requirements to serve Airbnb traffic.\nFormulating a solution to the contextual multi-armed bandit problem for location retrieval with common methods that satisfied these constraints proved to be challenging."}, {"title": "5.3 Active Contextual Estimation", "content": "The existing model based location retrieval solution would satisfy the requirement for a contextual estimator. Given the frequency of bookings on Airbnb, we employed daily retraining so that the estimator could be regularly updated based on new booking behavior from exploration."}, {"title": "5.4 Uncertainty Estimation", "content": "Uncertainty estimation proved to be the most challenging to construct with the existing unusual model formulation and loss. We initially considered the following traditional methods.\n(1) Ridge regression [10]: regularized linear regression with least squares loss that allows for uncertainty estimation based on the standard errors of its coefficients\n(2) Bayesian deep learning [14][11]: Deep neural networks where weights and biases are constructed as random variables with distributions for uncertainty estimation.\n(3) Deep ensembles [12]: Ensemble of deep neural networks that are jointly use to compute the prediction mean and variance that can be used for uncertainty estimation.\n(4) Evidential Networks [15]: Utilizes learned belief functions to model the predictors uncertainty\nThese prevalent methods did not fit this use case for a variety of reasons. Ridge regression assumes a linear relationship between predictor variables and the target variable which is untrue for location retrieval. It also requires using the regularized least squares loss which is not compatible with the location retrieval objective defined above. Bayesian deep learning has slower training and inference, in addition to having twice as many parameters. Meanwhile, deep ensembles would require N times more parameters increasing code, training, and operational complexity. Finally, evidential networks would increase parameters, complexity, and latency in order to score the learned belief function for uncertainty estimation. These considerations made them unfavorable for our production use case.\nGiven these considerations, we employ Monte Carlo Dropout[5] [6] to handle uncertainty estimation. Gal et. al demonstrates that any deep neural network of arbitrary depth, non linearities, and architecture with a dropout layer is equivalent to an approximation to the probabilistic deep Gaussian process. Given an example, we can score it N unique times to generate N unique predictions which is equivalent to the score distribution for the example. This score distribution can be used for uncertainty estimation. This approach requires minimal modification to the existing model architecture and any additional overhead for training and serving can be minimized through parallelization unlike some of the other methods."}, {"title": "5.5 Exploration Strategy", "content": "There were three exploration strategies that we considered:\n(1) E-greedy[16]: Greedily recommends the actions with the highest reward with probability 1-e and randomly selects other actions uniformly with probability e.\n(2) Thompson sampling[2]: Samples from the posterior distribution of the action reward space with current knowledge; recommends the action with the highest sampled reward estimate.\n(3) Upper Confidence Bound[3]: Computes upper confidence bounds for each action using the mean estimate for an action plus a bonus based on the uncertainty of the estimate and tuneable parameter \u03bb. It then chooses the action with the highest upper confidence bound."}, {"title": "5.6 The Approach for Location Retrieval Exploration", "content": "Algorithm 1 gives an overview of the proposed approach to solve the contextual multi armed bandit problem for location retrieval with the existing estimator, Monte Carlo Dropout, and the Upper Confidence Bound algorithm. We selected a dropout rate of 0.95 based on an offline parameter sweep to find the highest dropout rate with minimal impact to model performance. We selected N=32 for uncertainty estimation by choosing the minimum value where \u03bc and \u03c3 are stable across different scoring runs with the same example. We chose \u03bb = 2 for exploration with UCB by choosing the maximum value that still satisfied latency constraints. The model architecture consists of one hidden layer, one random dropout layer, one hidden layer and the output layer which computes the 4 coordinate offsets. This architecture is outlined in Figure 4. Model training also remains unchanged from the previous method."}, {"title": "6 Experimental Results", "content": ""}, {"title": "6.1 Overview", "content": "We evaluate location retrieval models offline on held out test data. The held out data is composed of 1 weeks worth of bookings and searches from dates not included in training dataset construction equating to roughly 7 million examples. We consider the following two metrics based on the losses described above. These two metrics are typically inversely correlated, i.e., the larger, less relevant the bounds are the higher the recall of booked listing locations.\n(1) Booked Listing Location Recall: Percentage of booked listing locations that are contained within the predicted retrieval bounds of attributed searches\n(2) Retrieval Bounds Size: The average size in kilometers of the predicted retrieval bounds\n(3) Number of Listings Retrieved: The average number of listings retrieved using the predicted bounds\nThe primary evaluation to determine whether a new approach will be launched to 100% of production traffic is to test whether it has a statistically significant (p-val < 0.05) increase in the following business metric in a massive online A/B experiment.\nUncancelled Bookers: The unique number of guests that complete a homes booking reservation on Airbnb that did not cancel the reservation during the experiment period.\nAll methods were tested in 3 week 50/50 A/B experiments with ~54M guests worldwide. Advancements in location retrieval primarily increase uncancelled booker conversion by surfacing new listings that were not shown before that offer differing values, amenities, or style. Given Airbnb's scale and the long tail booking objective, an improvement of even just 0.2% is very significant and difficult to achieve for optimizations within search. The impact of each method on offline and online evaluation criteria are detailed"}, {"title": "6.2 Cold Start Heuristic based Location Retrieval", "content": "The log scale expansion function (Heuristic 4) was tested in online A/B experiments against the baseline method (Heuristic 3) outlined in Section 2 for each location type. It significantly improved the launch criterion of uncancelled bookers by 0.35% and was launched to 100% of production traffic. Offline impact is not shown in Table 1 because it was developed and tested before our offline evaluation criteria was defined and tracked.\nThese improvements proved that location retrieval was an impactful lever to improve experiences for guests and booking behavior. These heuristics improved searches that had disproportionately low inventory states and unbookable inventory. For example searches for a specific building in Ibiza, Spain previously resulted in 5 results with the baseline while the new heuristic surfaced several pages of bookable results by expanding the bounds less than a mile. This is demonstrated in Figures 5 and 6."}, {"title": "6.3 Statistics based Location Retrieval", "content": "The statistics based method was tested in an online A/B experiment against the three heuristics for each searched location typed defined in Section 1. However, it did not have a stat sig impact on uncancelled bookers so it was never launched to 100% of production traffic. This experiment showed that naively taking advantage of booking data segmented only by searched location was not enough to materially improve the amount of bookers on the platform. We believed this was likely due to the methods inability to generalize across different searches and differentiate guest experiences because it was coarsely keyed by searched location. The need for this is evidenced by the difference in booking behavior between different guest counts, demonstrated in Figure 1 and 3 above."}, {"title": "6.4 Machine Learning based Location Retrieval", "content": "Applying machine learning for location retrieval was profoundly impactful. The methodology described and the following impact are the result of the initial model launch and two successive iterations on the input features and attribution. The feature engineering effort added features indicating the business market and a unique identifier for the specific cell on the Earth's surface that corresponds to the search location center in order to generalize better for rare locations. It also introduced trip dates to better handle seasonality. The attribution iteration expanded the training data to include booked listing locations that were found through map pan and zoom searches. The initial model launch was tested against the three heuristics for each searched location type defined in Section 2 and each iteration was tested successively with the previous model as a baseline for offline evaluation and online experiments. The methods cumulatively increased booked listing location recall by 7.12% and reduced retrieval bounds sizes by 40.83%, according to offline evaluation on held out test data compared to the baseline method.\nThe machine learning based location retrieval solutions were also tested successively in online A/B experiments resulting in a cumulative +1.8% uncancelled bookers by showing guests more bookable inventory near their travel destinations. Each iteration had statistically significant positive impact to uncancelled bookers, was launched to 100% of production traffic for a period of time, and served as the following iteration's baseline for offline and online evaluation.\nWe also qualitatively evaluated searches to verify whether the model generalizes for uncommon locations. For example, the baseline retrieval bounds are arbitrarily large with many results that were extremely far away and irrelevant for a search for a small street in Lima, Peru such that the searched street is not visible in the UI. The machine learning based retrieval bounds results in much smaller bounds and more relevant results near the street demonstrating its ability to generalize for uncommon locations. This is shown in Figures 7 and 8."}, {"title": "6.5 Reinforcement Learning based Location Retrieval", "content": "The MC Dropout Location Retrieval model performs better than the baseline machine learning model when evaluating offline using the mean prediction u for each test example with +0.25% in recall and -9.3% in retrieval size. We also qualitatively verified whether the MC Dropout Location Retrieval model explores more for locations with little prior data versus locations that are often searched and booked. For example, the difference between the mean bounds and UCB bounds for San Francisco, California is very small. However, the difference is much larger for Smith Mountain Lake, Virginia where we have little prior data. This is demonstrated in Figure 9.\nThe MC Dropout Location Retrieval Model was also tested in an online A/B experiment against the baseline production machine learning model retrained on data up to the start of the experiment and the production model trained on data up to 8 months before the start of the experiment. There was no statistically significant difference in performance between the production and retrained production models. The MC Dropout model showed a statistically significant increase of +0.51% in uncancelled bookers compared to the retrained production model, which was primarily driven by surfacing more bookable, affordable, and diverse inventory to guests. This is the result of two successive experiments. The first tested the method described against the preexisting machine learning solution. The second optimized the 32 forward passes required for uncertainty estimation by embedding it into the tensorflow graph instead of manually scoring the model 32 separate times which resulted in a significant latency improvement. Traditional multi-armed bandit regret analysis is infeasible for the nontraditional recall maximizing application but model confidence for each prediction offset has increased by 7.33% on average since launch."}, {"title": "7 Conclusion", "content": "We presented how location retrieval was built from the ground up in Airbnb search by solving cold start, generalization, and algorithmic bias. The system evolved from heuristics all the way to the application of reinforcement learning with significant cumulative impact of +2.66% in uncancelled bookers. This is comparable or more impactful than many previously published machine learning techniques within Airbnb search such as [1] [8] [9] [17] [7]. We outlined the successes and failures along the way and the motivation for more advanced techniques to tackle the aforementioned challenges. The Monte Carlo Dropout model, the application of reinforcement learning, proved that it performed better than previous baselines offline and online for business metrics and now serves all production traffic at Airbnb. For future work, there is opportunity to advance the model's understanding with more complex features. There is also an opportunity to reformulate the retrieval mechanism from retrieval bounds to map cells. This would allow for organically learning booking probabilities for each cell instead of training with hand tuned weights."}]}