{"title": "CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network", "authors": ["Zijian Zhao", "Tingwei Chen", "Zhijie Cai", "Xiaoyang Li", "Hang Li", "Qimei Chen", "Guangxu Zhu"], "abstract": "In recent years, Wi-Fi sensing has garnered significant attention due to its numerous benefits, such as privacy protection, low cost, and penetration ability. Extensive research has been conducted in this field, focusing on areas such as gesture recognition, people identification, and fall detection. However, many data-driven methods encounter challenges related to domain shift, where the model fails to perform well in environments different from the training data. One major factor contributing to this issue is the limited availability of Wi-Fi sensing datasets, which makes models learn excessive irrelevant information and over-fit to the training set. Unfortunately, collecting large-scale Wi-Fi sensing datasets across diverse scenarios is a challenging task. To address this problem, we propose CrossFi, a siamese network-based approach that excels in both in-domain scenario and cross-domain scenario, including few-shot, zero-shot scenarios, and even works in few-shot new-class scenario where testing set contains new categories. The core component of CrossFi is a sample-similarity calculation network called CSi-Net, which improves the structure of the siamese network by using an attention mechanism to capture similarity information, instead of simply calculating the distance or cosine similarity. Based on it, we develop an extra Weight-Net that can generate a template for each class, so that our CrossFi can work in different scenarios. Experimental results demonstrate that our CrossFi achieves state-of-the-art performance across various scenarios. In gesture recognition task, our CrossFi achieves an accuracy of 98.17% in in-domain scenario, 91.72% in one-shot cross-domain scenario, 64.81% in zero-shot cross-domain scenario, and 84.75% in one-shot new-class scenario. To facilitate future research, we will release the code for our model upon publication.", "sections": [{"title": "I. INTRODUCTION", "content": "Recently, Integrated Sensing and Communications (ISAC) has emerged as a prominent and popular technology direction aimed at enhancing the efficiency and intelligence of communication systems. Wi-Fi, as one of the key technologies in the realm of Internet of Things (IoT) communications, has found widespread application in various settings such as homes, offices, and public spaces [1]. In addition to its role in facilitating communication, Wi-Fi also holds promise as a sensing tool, owing to its characteristics including privacy protection, affordability, and penetration capability. In passive Wi-Fi sensing [2], by leveraging the variations in signal strength and multipath propagation caused by different objects and actions, it is possible to extract valuable information like Channel Statement Information (CSI) and Received Signal Strength Indicator (RSSI) to sense the environment and detect specific actions.\nWi-Fi sensing has attracted significant research attention, particularly in areas such as fall detection [3], [4], gesture recognition [5], and people identification [6]. These advancements have demonstrated the immense potential of Wi-Fi sensing in domains such as elderly care, military applications, and medical fields. However, a major challenge faced by existing Wi-Fi sensing models lies in their limited robustness. Even a slight change in the environment can lead to a significant deterioration in model performance or even complete failure. Addressing this critical issue is crucial for the practical deployment and utilization of Wi-Fi sensing devices.\nCurrent Wi-Fi sensing methods can be categorized into two types: model-based methods [7] and data-driven methods [8]. Model-based methods require significant expertise and extract different signal features for different tasks. However, these methods are challenging to design and often have low accuracy, particularly in complex Wi-Fi sensing scenarios. Moreover, most of these methods are not easily transferable to other tasks. On the other hand, data-driven methods, with deep learning as a prime example, can address these challenges by directly learning from the data, without any explicit assumption on the underlying model.\nHowever, data-driven Wi-Fi sensing methods face a significant challenge in cross-domain scenarios [9]. The Wi-Fi signal is highly influenced by the environment, making models trained in specific environments ineffective when applied to new environments. While collecting large amounts of data in diverse environments might seem like an intuitive solution, acquiring signal data is much more challenging compared to other modalities such as images or text. This is because signal data always requires specialist equipment to collect, and there is a lack of rich resources available on the web. Additionally, the data format of the signal is device-dependent, making it nearly impossible to utilize signal data from different public datasets simultaneously. To address this issue, it is crucial to develop a robust framework that can be applied across different environments with minimal modifications.\nSeveral research studies have focused on the cross-domain topic in Wi-Fi sensing and machine learning [10]\u2013[12]. Among these, the siamese network [13] has been proven to be an efficient method. For traditional neural networks, the upstream layers capture the feature embedding of the input, and the downstream layers realize the specific tasks like classification based on it. Shown as Fig. 1, when there is a significant gap between the distribution of training data and testing data, which corresponds to the scenario of cross-domain tasks, the embedding distribution between them also has a huge difference. This can lead to a significant decrease in performance or even failure of the downstream classifier. In contrast, the siamese network calculates the similarity or distance (referred to as \"similarity\" for simplicity) of embeddings from the upstream layers between two samples instead of directly outputting the classification result. By this approach, even though the embedding distribution of the target domain may not be similar to the source domain, the model can still capture the similarity relationship between samples from the same domain, which has been proved by many works [14]. By employing the idea of comparative learning, it can capture more information between positive and negative pairs. With its structure, the siamese network has a unique advantage in one-shot scenarios.\nHowever, in the traditional siamese network, the similarity between different samples is evaluated by computing the Gaussian distance [13] or cosine similarity [15] between the embeddings of the two samples, which may not capture enough relationship between samples' feature. Therefore, we propose an attention-based method to calculate the similarity within the network, where we call the improved siamese network as Cross Domain Siamese Network (CSi-Net). Furthermore, as the siamese network solves the cross-domain task well in one-shot tasks, we hope to extend its success to more scenarios. As a result, in each scenario, we design a corresponding template generation method for each category and, during inference, identify the most similar template for each sample as its category result. Specifically, we propose a Weight-Net to generate templates based on the relationship between different samples adaptively. The whole workflow of our method is shown as Fig. 2, called CrossFi. We evaluate our model on the WiGesture dataset [6] for cross-domain and new-class gesture recognition and people identification tasks. The experimental results demonstrate that our model achieves the most advanced performance in most scenarios.\nIn summary, the main contributions of this work are:\n(1) CrossFi - A Universal Framework for Cross Domain Wi-Fi Sensing: Aiming at cross-domain Wi-Fi sensing, we propose a universal framework called CrossFi that can work in in-domain, few-shot cross-domain, zero-shot cross-domain scenarios, and even few-shot new-class scenario where testing set contains new class samples not present in training set. The framework consists of two components: CSi-Net, which is used to calculate the similarity between samples, and Weight-Net, which is used to generate templates for each class in the source domain and target domain, respectively. During inference, CSi-Net can classify samples by calculating the similarity between them and each template.\n(2) CSi-Net - Similarity Calculator: In view of the low information usage of traditional siamese networks, we propose CSi-Net to improve its structure. To this end, we design an attention mechanism-based method to allow the model extract similarity information through a learning process, rather than directly calculating the distance or cosine similarity.\n(3) Weight-Net - Adaptive Template Generator: To extend siamese network to other scenarios beyond one-shot setting, we design a Weight-Net to generate templates of each class for classification. It uses the similarity matrix output by CSi-Net to identify the quality of samples, which can then be used as the mixing ratio to generate templates by weighted averaging samples. Instead of randomly selecting samples as templates to imitate the one-shot scenario, our Weight-Net provides high-quality templates, which can improve the model's performance.\n(4) Experiment Evaluation: We evaluate our model's performance in different in-domain, cross-domain and new-class scenarios on a public dataset, for gesture recognition and people identification tasks. The results confirm the superiority of the proposed method. We also use a series of ablation studies to prove the efficiency of our modifications to the siamese network and our template generation method.\nThe rest of this paper is structured as follows: Section II introduces previous few-shot learning and zero-shot learning methods. Section III provides the basic principles of CSI and Wi-Fi sensing. Section IV introduces our method structure and system workflow according to different scenarios in detail. Section V presents comparative experiments and ablation studies to demonstrate the superiority of our method. Finally, Section VI concludes the paper and points to potential directions for further research."}, {"title": "II. RELATED WORK", "content": "For better understanding, we first provide a description of the scenarios discussed in this paper. According to the domain distribution of training set and testing set, we can divide Wi-Fi sensing task into in-domain Wi-Fi sensing, where the data domains in the training set and testing set are the same, and cross-domain Wi-Fi sensing, which can be further split based on the availability of data in the source and target domains. In the few-shot (also known as k-shot) scenario, the training set consists of a large amount of data from the source domain and only a few data from the target domain. Specifically, in the k-shot scenario, there are only k samples available in the training set for each class in the target domain. To clarify the problem further, we refer to this subset of data as the support set and the remaining data as the training set. In the one-shot scenario, k is equal to 1. Finally, in the zero-shot scenario, the training set consists entirely of data from the source domain, while the testing set consists entirely of data from the target domain. Additionally, in this paper, we also investigate the few-shot scenario in the context of a new category task, where the testing set is from the same domain as the training set, but includes new classes. We provide k samples for each new category in the training set.\nCurrently, most cross-domain Wi-Fi sensing methods can be divided into three types. (1) The domain-invariant feature extraction method [16] aims to extract features of CSI independent of the domain. However, this method always requires extensive experimental knowledge and some prerequisites. When the task or prerequisites change, significant effort is needed to redesign the feature extractor. (2) The data generation method [17] seeks to synthesize samples in the target domain. Unlike image and text data, evaluating the quality of generated samples in this context is challenging. Current methods mostly rely on the accuracy in downstream tasks and the confusion degree of the discriminator for evaluation, but they have limitations in certain contexts. (3) The domain adaptation method [18] seeks to transfer the knowledge learnt from source domain to the target domain. This approach is seen as the most promising solution in cross-domain Wi-Fi sensing, due to its high performance, versatility, robustness, and low workload compared to the above two methods [9]. Therefore, we focus on domain adaptation method in this paper. Depending on whether labeled data from target domain is available at the training phase, two major scenarios, i.e., few-shot learning and zero-shot learning are considered in the literature as surveyed below."}, {"title": "A. Few-shot Learning", "content": "Most research on cross-domain Wi-Fi sensing focuses on the few-shot scenario, particularly the one-shot scenario, which is a special case within few-shot learning. The siamese network [13] has emerged as a powerful framework widely utilized in this area [5], [12], [19], either directly or indirectly. Current few-shot learning-based Wi-Fi sensing methods can be divided into two types: contrastive learning methods like the siamese network and clustering methods like the prototypical network [20]. Among them, most research focuses on contrastive learning methods, where there are many similar or variant structures to the siamese network, such as the matching network [21], deep similarity evaluation network [22], and triplet network [23]. Additionally, several other works, although not directly utilizing the siamese network, exhibit similar overall frameworks. Specifically, Yin et al. [18] and Shi et al. [24] replaced the similarity metric of Gaussian distance with cosine similarity.\nFurthermore, some works in Wi-Fi sensing [25], [26] have extended the siamese network to the in-domain scenario and demonstrated superior performance. This paper further expands this method to the zero-shot scenario, presenting a unified framework applicable to all scenarios and demonstrating the best performance."}, {"title": "B. Zero-shot Learning", "content": "Currently, there are few studies on zero-shot scenarios in the field of Wi-Fi sensing. Even Airfi [11] realized it by introducing the domain generalization method, it requires multi-domain information in the training set, which cannot always be satisfied. In the field of machine learning, the most popular methods can be divided into two types. The first type focuses on designing appropriate loss functions to ensure that the conditional probability in the source domain and target domain are the same [27], [28]. The second type is based on network design like Domain Adversarial Neural Networks (DANN) [29], which first employ neural networks to extract domain-independent features and then train classifiers on these domain-invariant features. For example, Shu et al. [30] combined DANN with curriculum learning, while Yu et al. [31] proposed a method based on local domain adversarial adaptation and global domain adversarial adaptation. However, both types of methods have their own limitations. In the case of loss function-based methods, achieving an exact match between the conditional probabilities learned in the source domain and the target domain is challenging (as demonstrated in a simple proof in Section IV-D2). This is because the labels in the target domain are inaccessible during training, leading to an unknown data distribution in each category. As for DANN-based methods, while extracting domain-invariant features, the feature extractor may unintentionally ignore some important features related to the classification task, resulting in low classification accuracy in both the source and target domains. Our experiments in Section V-D demonstrate that traditional zero-shot learning methods do not perform well in Wi-Fi sensing tasks. Furthermore, both methods share the common disadvantage of requiring raw data from testing set during the training phase, which is not always feasible. In contrast, the method proposed in this paper overcomes this limitation.\nIn addition to these two types of methods, there are also other representative approaches. Pinheiro [32] proposed a method similar to the siamese network [13], but trained the feature extractor separately on the source domain and target domain. Additionally, templates based on the centers of samples from the source domain were employed for each category. However, due to the significant domain gap, the templates from the source domain may not perform well in the target domain. Saito et al. [33] introduced a novel method that generates pseudo-labels for target domain samples based on confidence levels computed by the classifier trained on the source domain. Similarly, due to the domain gap, the pseudo-labels may have low accuracy because the classifier trained on the source domain often fails to perform well on the target domain."}, {"title": "III. WI-FI SENSING BASICS", "content": "CSI is utilized to provide feedback on the characteristics of a wireless channel. Considering a scenario where both the transmitter and receiver are situated within the same indoor space, the transmitted signal traverses multiple paths, experiencing reflections, refractions, or scattering, before reaching the receiver. Mathematically, this channel can be represented as:\n$Y = HX + N,$\nwhere Y and X are the matrices of the received and transmitted signals, respectively, N is the vector of noise signals, and H represents the channel matrix.\nThe channel frequency response can be represented as:\n$H(f,t) = H_s(f,t) + H_d(f,t),$\nwhere f is the subcarrier frequency, and t is the time-domain sampling point. The equation can be divided into $H_s(f,t)$, the static component, and $H_d(f,t)$, the dynamic component. The CSI tensor includes dimensions for the number of transmit and receive antennas. However, since our setup is that each transmitter and receiver has one antenna, these dimensions can be disregarded.\nIn tasks such as gesture recognition and identification, different gestures and the extent of individual movements cause variations in the dynamic component. By capturing these variations, we can predict actions and identify people through CSI."}, {"title": "IV. METHODOLOGY", "content": "The workflow of our CrossFi is shown in Fig. 2, encompassing four main phases: data collection, data pre-processing, training, and inference. The method is realized by two neural networks: CSi-Net, which is used to calculate the similarity between samples, and Weight-Net, which is used to evaluate the sample quality and further to generate template for each class. For each scenario, we design a proper training method respectively. In the inference phase, users can use the trained CSi-Net and generated template to realize the final classification.\nIn this section, we first provide a detailed introduction to the networks structure in Section IV-B. Subsequently, we describe the whole workflow in Section IV-C. Finally, we discuss the different designs of the training process in different scenarios, addressed in Section IV-D."}, {"title": "B. Model Structure", "content": "In this section, we describe the structure of CSi-Net and Weight-Net in detail. As depicted in Fig. 3, CSi-Net is based on a traditional Siamese network [13], where two twin networks with tied parameters serve as bottom feature extractors, and the top layer combines the extracted features for similarity calculation. Differently, CSi-Net enhances the original structure by incorporating a multi-attention layer [34] to assess the similarity between two inputs, rather than relying solely on computing the distance between the output of the final model layer. This modification is motivated by the remarkable performance of attention mechanisms in capturing relationships between objects across various domains [35]. However, unlike the traditional attention mechanism, we only utilize the \"query\" and \"key\" components, omitting the \"value\" component, which means we only employ the attention matrix as shown in Eq. 3:\n$\\frac{1}{h} \\sum_{i=1}^{h} (qW_i^Q)^T(kW_i^K) + b_i^Q + b_i^K,$\n$S = Sigmoid(Multi-Attn(q, k)),$\nwhere h represents the number of attention heads, $q \\in \\mathbb{R}^{b_1,d_1}$, $k \\in \\mathbb{R}^{b_2,d_1}$ represent the outputs from two branches of the bottom embedding layers, which we call the query branch and key branch, $W_i^Q, W_i^K \\in \\mathbb{R}^{d_1,d_2}$, $b_i^Q, b_i^K \\in \\mathbb{R}^{d_2}$ represent the weights and biases of each linear layer in the query layer and key layer, t represents the temperature which can control the smooth level of sigmoid, $S \\in \\mathbb{R}^{b_1,b_2}$ represents the similarity score matrix, $b_1, b_2$ represent the batch sizes of the query branch and the key branch, $d_1, d_2$ represent the output dimensions of the bottom embedding layers and linear layers in the multi-attention layer. By this mechanism, when there are $b_1$ samples input to the query branch and $b_2$ samples input to the key branch, the model will output a similarity score matrix S of size $b_1 \\times b_2$, representing the similarity between each sample pair from the two branches. The attention mechanism, which essentially involves matrix multiplication, offers the same computational complexity as computing Gaussian Distance while yielding more valuable information.\nHere, we do not make the parameters of the query layer and weight layer shared as the bottom twin networks. The original idea of parameter sharing is to keep the symmetry of the network, which means the order of the input pair does not affect the output. However, in our method, we introduce extra templates that are generated, not real samples. When computing the similarity between real samples and templates, we input real samples to the query branch and templates to the key branch. By using dependent parameters in the query layer and key layer, we can make the key layer have better capacity to extract features of the template while not influencing the performance of the query layer, which can focus on the feature extraction of real samples.\nFurthermore, we still keep the parameters shared in the bottom twin networks, which is viewed as common feature extractors. We choose ResNet [36] as the feature extractor due to its excellent performance in numerous previous wireless sensing works [37], [38]. Inspired by transfer learning [39], we also use the pre-trained parameters of ResNet from image tasks, which can help increase the model's convergence speed and improve its performance. To align the structure of CSI with ResNet, we represent each CSI sample as $c_i \\in \\mathbb{R}^{2\\times t\\times D}$, where i represents the sample index, t denotes the number of CSI samples in each sample, and D represents the number of sub-carriers across all antennas. Each CSI sample consists of two channels, corresponding to the amplitude and phase, respectively. We also modify the first convolution layer of ResNet to adapt to the 2-channel input.\nThen we introduce Weight-Net through template generation process, shown as Fig. 4. The network is a ResNet with an extra sigmoid function in top layer. In template generation process, some samples are first duplicated and input to the two branches of CSi-Net. Then Weight-Net takes the similarity score matrix output by CSi-Net as input and output an weight vector, which represents the quality of each samples. The intuition of using similarity score to evaluate sample quality is that: if a sample has high similarity to some samples and low similarity to others, it has a high quality; if a sample has similar similarity to all samples, it may include too much noise and has a low quality. After getting the weight vector, a function \u2018f' will use the original input samples and weight vector to generate templates. In in-domain and few-shot scenario, 'f' represents weighted average operation, which takes the weight vector as the weight for each sample. And"}, {"title": "C. Workflow Description", "content": "1) Data Collection and Data Pre-processing: After collecting data from different domains, we split them as training set, support set, and testing set. In training phase, we will use the labeled training set and support set and unlabeled testing set, which is optional. In the data pre-processing phase, we initially compute the amplitude and phase of the CSI since the network cannot directly process complex CSI data. Next, we calculate the cosine value of the phase, as the original phase values may exhibit discontinuities between \u2013\u03c0 and \u3160, which can impact the network's performance. Finally, we employ an interpolation method to fill in any missing CSI positions, ensuring consistent data dimensions are maintained.\n2) Training Phase: As shown in the yellow part of Fig. 2, the training phase includes two alternate steps: comparative learning, where we train the CSi-Net to evaluate the similarity of two samples, and template learning, where we train the Weight-Net for template generation and CSi-Net to evaluate the similarity between samples and templates simultaneously. Since the input of CSi-Net is different in these two steps, we choose to execute them alternately instead of in order, to ensure the model can calculate the similarity both within samples and between samples and templates, and avoid catastrophic forgetting.\nIn the comparative learning step, we follow the same approach as the traditional siamese network, utilizing the loss function shown in Eq. 4:\n$L_{com} = \\sum_{i,j} L_{i,j}^{com},$\n$L_{i,j}^{com} = a[label(c_i) == label(c'_j)](1 \u2013 S_{i,j})^2 + [label(c_i) \\neq label(c'_j)]S_{i,j}^2,$\n$S_{i,j} =CSi-Net(c_i, c'_j),$\nwhere $c_i, c'_j$ represent the ith sample in the query branch and the jth sample in the key branch, $S_{i,j}$ represents the similarity between $c_i$ and $c'_j$ calculated by the CSi-Net, label($c_i$) indicates the category to which $c_i$ belongs, and a is a weight factor for positive pairs to solve the long-tail problem, as the number of positive pairs is usually significantly fewer than negative pairs.\nIn the template learning phase, the Weight-Net first generates templates for each class, which will be introduced in the next section. Then we still use the comparative learning method to train the Weight-Net and CSi-Net simultaneously, incorporating the loss function shown in Eq. 5:\n$L_{tem} = \\sum_{i,j} L_{i,j}^{tem},$\n$L_{i,j}^{tem} = a[label(c_i) == j](1 \u2013 S_{i,j})^2 + [label(c_i) \\neq j]S_{i,j}^2,$\n$S_{i,j} = CSi-Net(c_i, T_j),$\nwhere $T \\in \\mathbb{R}^{n,2,t,D}$ represents the template matrix, n represents class number, $T_j$ represents the template of class j, and $S_{i,j}$ represents the similarity between sample $c_i$ and template $T_j$.\nWe can abstract the processing of the template learning step as follows:\n$s = f(x,x, u),$\n$t = g(s, \\theta_t),$\n$\\hat{y} = f(x',t,v),$\n$L = l(\\hat{y}, y),$\n$u = v = \\theta_f,$\nwhere f, g represent CSi-Net and Weight-Net, $\\theta_f$, $\\theta_t$ are their parameters, x, x' are CSI samples, s is the similarity score, t is the template, y, $\\hat{y}$ are the ground truth and prediction result, and l, L are the loss function and its value. Then the gradient descent can be executed according to the partial derivative of the network parameters:\n$\\frac{\\partial L}{\\partial \\theta_f} = \\frac{\\partial L}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial v} (\\frac{\\partial v}{\\partial \\theta_f} + \\frac{\\partial v}{\\partial t} \\frac{\\partial t}{\\partial s} \\frac{\\partial s}{\\partial u}),$\n$\\frac{\\partial L}{\\partial \\theta_t} = \\frac{\\partial L}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial v} \\frac{\\partial v}{\\partial t} \\frac{\\partial t}{\\partial \\theta_t}.$\n3) Inference Phase: In the inference phase, we can calculate the similarity score matrix between the testing samples and the template of each class, using the trained CSi-Net and the generated templates in the target domain. The classification result is given by Eq. 8:\n$S_{i,j}=CSi-Net(c_i, T_j),$\n$Y_i =argmax(S_{i,j}),$\nwhere $Y_i$ is the classification result of sample $c_i$."}, {"title": "D. Key Scenarios", "content": "1) In-domain: Even though the in-domain scenario is not the highlight of this paper", "40": ".", "Few-shot": "In the few-shot learning scenario", "27": ".", "phi_j(\u00b7)": "mathbb{R"}, "D \\rightarrow H$ is a function that maps from the real number space to the Reproducing Kernel Hilbert Space (RKHS), $\\beta_j$ is a hyper-parameter that satisfies $\\sum_j \\beta_j = 1$. The main purpose of using the MK-MMD loss is to narrow the distance between the source domain and the target domain, which helps improve the efficiency of the feature extractor as shown in Fig. 5.\nAs mentioned before, we found that MK-MMD does not seem to directly help the classifier in the field of Wi-Fi sensing (refer to the experiment result in Section V-D). Here we use a simple proof to illustrate that it cannot be guaranteed that $P_s(y|x;\\theta) = P_t(y|x;\\theta)$ if we only make $P_s(x) = P_t(x)$. However, this is what MK-MMD does. The proof is shown in Eq. 10.\n$P_t(y|x) = \\frac{P_t(x|y)P_t(y)}{P_t(x)},$\n$P_s(y|x) = P_t(y|x) \\frac{P_s(x)}{P_t(x)} = P_t(y|x) \\frac{P_t(x|y)P_t(y)}{P_s(x|y)P_s(y)}.$,\nHowever, despite the lack of direct impact on the classifier, we have observed that both in our work and in a previous siamese network-based method [24"], "Zero-shot": "In the zero-shot scenario, we cannot obtain a template as we do in the few-shot scenario. Simply using the method from the in-domain scenario may also encounter the same problem as in few-shot scenario caused by the domain gap. As a result, we need to find a method to bridge the source domain and target domain. To address this, we propose a combination of the two methods, as outlined in Algorithm 2. In this scenario, we generate different templates for the training set and the testing set, respectively.\nFirst, we select k samples from the training set and testing set, respectively. Then, we compute the weights for the samples in the training set using the Weight-Net. Unlike Algorithm 1, we choose the samples in each category with the largest weight as templates to maintain consistency with the testing set. These samples form the template for the training set.\nIn the inference phase, for the samples in the testing set, we find the most similar ones to the templates of the training set using the similarity scores generated by the CSi-Net. These samples are used as templates for the testing set. The principle of this template generation method is shown in Fig."}