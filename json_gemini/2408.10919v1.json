{"title": "CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network", "authors": ["Zijian Zhao", "Tingwei Chen", "Zhijie Cai", "Xiaoyang Li", "Hang Li", "Qimei Chen", "Guangxu Zhu"], "abstract": "In recent years, Wi-Fi sensing has garnered significant attention due to its numerous benefits, such as privacy protection, low cost, and penetration ability. Extensive research has been conducted in this field, focusing on areas such as gesture recognition, people identification, and fall detection. However, many data-driven methods encounter challenges related to domain shift, where the model fails to perform well in environments different from the training data. One major factor contributing to this issue is the limited availability of Wi-Fi sensing datasets, which makes models learn excessive irrelevant information and over-fit to the training set. Unfortunately, collecting large-scale Wi-Fi sensing datasets across diverse scenarios is a challenging task. To address this problem, we propose CrossFi, a siamese network-based approach that excels in both in-domain scenario and cross-domain scenario, including few-shot, zero-shot scenarios, and even works in few-shot new-class scenario where testing set contains new categories. The core component of CrossFi is a sample-similarity calculation network called CSi-Net, which improves the structure of the siamese network by using an attention mechanism to capture similarity information, instead of simply calculating the distance or cosine similarity. Based on it, we develop an extra Weight-Net that can generate a template for each class, so that our CrossFi can work in different scenarios. Experimental results demonstrate that our CrossFi achieves state-of-the-art performance across various scenarios. In gesture recognition task, our CrossFi achieves an accuracy of 98.17% in in-domain scenario, 91.72% in one-shot cross-domain scenario, 64.81% in zero-shot cross-domain scenario, and 84.75% in one-shot new-class scenario. To facilitate future research, we will release the code for our model upon publication.", "sections": [{"title": "I. INTRODUCTION", "content": "Recently, Integrated Sensing and Communications (ISAC) has emerged as a prominent and popular technology direction aimed at enhancing the efficiency and intelligence of communication systems. Wi-Fi, as one of the key technologies in the realm of Internet of Things (IoT) communications, has found widespread application in various settings such as homes, offices, and public spaces [1]. In addition to its role in facilitating communication, Wi-Fi also holds promise as a sensing tool, owing to its characteristics including privacy protection, affordability, and penetration capability. In passive Wi-Fi sensing [2], by leveraging the variations in signal strength and multipath propagation caused by different objects and actions, it is possible to extract valuable information like Channel Statement Information (CSI) and Received Signal Strength Indicator (RSSI) to sense the environment and detect specific actions.\nWi-Fi sensing has attracted significant research attention, particularly in areas such as fall detection [3], [4], gesture recognition [5], and people identification [6]. These advancements have demonstrated the immense potential of Wi-Fi sensing in domains such as elderly care, military applications, and medical fields. However, a major challenge faced by existing Wi-Fi sensing models lies in their limited robustness. Even a slight change in the environment can lead to a significant deterioration in model performance or even complete failure. Addressing this critical issue is crucial for the practical deployment and utilization of Wi-Fi sensing devices.\nCurrent Wi-Fi sensing methods can be categorized into two types: model-based methods [7] and data-driven methods [8]. Model-based methods require significant expertise and extract different signal features for different tasks. However, these methods are challenging to design and often have low accuracy, particularly in complex Wi-Fi sensing scenarios. Moreover, most of these methods are not easily transferable to other tasks. On the other hand, data-driven methods, with deep learning as a prime example, can address these challenges by directly learning from the data, without any explicit assumption on the underlying model.\nHowever, data-driven Wi-Fi sensing methods face a significant challenge in cross-domain scenarios [9]. The Wi-Fi signal is highly influenced by the environment, making models trained in specific environments ineffective when applied to new environments. While collecting large amounts of data in diverse environments might seem like an intuitive solution, acquiring signal data is much more challenging compared to other modalities such as images or text. This is because signal data always requires specialist equipment to collect, and there is a lack of rich resources available on the web. Additionally, the data format of the signal is device-dependent, making it nearly impossible to utilize signal data from different public datasets simultaneously. To address this issue, it is crucial to develop a robust framework that can be applied across different environments with minimal modifications.\nSeveral research studies have focused on the cross-domain topic in Wi-Fi sensing and machine learning [10]\u2013[12]. Among"}, {"title": "II. RELATED WORK", "content": "For better understanding, we first provide a description of the scenarios discussed in this paper. According to the domain distribution of training set and testing set, we can divide Wi-Fi sensing task into in-domain Wi-Fi sensing, where the data domains in the training set and testing set are the same, and cross-domain Wi-Fi sensing, which can be further split based"}, {"title": "III. WI-FI SENSING BASICS", "content": "CSI is utilized to provide feedback on the characteristics of a wireless channel. Considering a scenario where both the transmitter and receiver are situated within the same indoor space, the transmitted signal traverses multiple paths, experiencing reflections, refractions, or scattering, before reaching the receiver. Mathematically, this channel can be represented as:\n$Y = HX + N$,\nwhere $Y$ and $X$ are the matrices of the received and transmitted signals, respectively, $N$ is the vector of noise signals, and $H$ represents the channel matrix.\nThe channel frequency response can be represented as:\n$H(f,t) = H_s(f,t) + H_d(f,t)$,\nwhere $f$ is the subcarrier frequency, and $t$ is the time-domain sampling point. The equation can be divided into $H_s(f,t)$, the static component, and $H_d(f, t)$, the dynamic component. The CSI tensor includes dimensions for the number of transmit and receive antennas. However, since our setup is that each transmitter and receiver has one antenna, these dimensions can be disregarded.\nIn tasks such as gesture recognition and identification, different gestures and the extent of individual movements cause variations in the dynamic component. By capturing these variations, we can predict actions and identify people through CSI."}, {"title": "IV. METHODOLOGY", "content": "The workflow of our CrossFi is shown in Fig. 2, encompassing four main phases: data collection, data pre-processing, training, and inference. The method is realized by two neural networks: CSi-Net, which is used to calculate the similarity between samples, and Weight-Net, which is used to evaluate the sample quality and further to generate template for each class. For each scenario, we design a proper training method respectively. In the inference phase, users can use the trained CSi-Net and generated template to realize the final classification.\nIn this section, we first provide a detailed introduction to the networks structure in Section IV-B. Subsequently, we describe the whole workflow in Section IV-C. Finally, we discuss the different designs of the training process in different scenarios, addressed in Section IV-D."}, {"title": "B. Model Structure", "content": "In this section, we describe the structure of CSi-Net and Weight-Net in detail. As depicted in Fig. 3, CSi-Net is based on a traditional Siamese network [13], where two twin networks with tied parameters serve as bottom feature extractors, and the top layer combines the extracted features for similarity calculation. Differently, CSi-Net enhances the original structure by incorporating a multi-attention layer [34] to assess the similarity between two inputs, rather than relying solely on computing the distance between the output of the final model layer. This modification is motivated by the remarkable performance of attention mechanisms in capturing relationships between objects across various domains [35]. However, unlike the traditional attention mechanism, we only utilize the \"query\" and \"key\" components, omitting the \"value\" component, which means we only employ the attention matrix as shown in Eq. 3:\n$Multi-Attn(q, k) = \\frac{1}{t}\\sum_{i=1}^{h} (qW_i^Q + b_i^Q)(kW_i^K + b_i^K)^T$,\n$S = Sigmoid(Multi-Attn(q, k))$,\nwhere $h$ represents the number of attention heads, $q \\in \\mathbb{R}^{b_1,d_1}, k \\in \\mathbb{R}^{b_2,d_1}$ represent the outputs from two branches of the bottom embedding layers, which we call the query branch and key branch, $W_i^Q, W_i^K \\in \\mathbb{R}^{d_1,d_2}, b_i^Q, b_i^K \\in \\mathbb{R}^{d_2}$ represent the weights and biases of each linear layer in the query layer and key layer, $t$ represents the temperature which can control the smooth level of sigmoid, $S \\in \\mathbb{R}^{b_1,b_2}$ represents the similarity score matrix, $b_1, b_2$ represent the batch sizes of the query branch and the key branch, $d_1, d_2$ represent the output dimensions of the bottom embedding layers and linear layers in the multi-attention layer. By this mechanism, when there are $b_1$ samples input to the query branch and $b_2$ samples input to the key branch, the model will output a similarity score matrix $S$ of size $b_1 \\times b_2$, representing the similarity between each sample pair from the two branches. The attention mechanism, which essentially involves matrix multiplication, offers the same computational complexity as computing Gaussian Distance while yielding more valuable information.\nHere, we do not make the parameters of the query layer and weight layer shared as the bottom twin networks. The original idea of parameter sharing is to keep the symmetry of the network, which means the order of the input pair does not affect the output. However, in our method, we introduce extra templates that are generated, not real samples. When computing the similarity between real samples and templates, we input real samples to the query branch and templates to the key branch. By using dependent parameters in the query layer and key layer, we can make the key layer have better capacity to extract features of the template while not influencing the performance of the query layer, which can focus on the feature extraction of real samples.\nFurthermore, we still keep the parameters shared in the bottom twin networks, which is viewed as common feature extractors. We choose ResNet [36] as the feature extractor due to its excellent performance in numerous previous wireless sensing works [37], [38]. Inspired by transfer learning [39], we also use the pre-trained parameters of ResNet from image tasks, which can help increase the model's convergence speed and improve its performance. To align the structure of CSI with ResNet, we represent each CSI sample as $c_i \\in \\mathbb{R}^{2\\times t\\times D}$, where $i$ represents the sample index, $t$ denotes the number of CSI samples in each sample, and $D$ represents the number of sub-carriers across all antennas. Each CSI sample consists of two channels, corresponding to the amplitude and phase, respectively. We also modify the first convolution layer of ResNet to adapt to the 2-channel input.\nThen we introduce Weight-Net through template generation process, shown as Fig. 4. The network is a ResNet with an extra sigmoid function in top layer. In template generation process, some samples are first duplicated and input to the two branches of CSi-Net. Then Weight-Net takes the similarity score matrix output by CSi-Net as input and output an weight vector, which represents the quality of each samples. The intuition of using similarity score to evaluate sample quality is that: if a sample has high similarity to some samples and low similarity to others, it has a high quality; if a sample has similar similarity to all samples, it may include too much noise and has a low quality. After getting the weight vector, a function \u2018f' will use the original input samples and weight vector to generate templates. In in-domain and few-shot scenario, 'f' represents weighted average operation, which takes the weight vector as the weight for each sample. And"}, {"title": "C. Workflow Description", "content": "1) Data Collection and Data Pre-processing: After collecting data from different domains, we split them as training set, support set, and testing set. In training phase, we will use the labeled training set and support set and unlabeled testing set, which is optional. In the data pre-processing phase, we initially compute the amplitude and phase of the CSI since the network cannot directly process complex CSI data. Next, we calculate the cosine value of the phase, as the original phase values may exhibit discontinuities between \u2013\u03c0 and \u3160, which can impact the network's performance. Finally, we employ an interpolation method to fill in any missing CSI positions, ensuring consistent data dimensions are maintained.\n2) Training Phase: As shown in the yellow part of Fig. 2, the training phase includes two alternate steps: comparative learning, where we train the CSi-Net to evaluate the similarity of two samples, and template learning, where we train the Weight-Net for template generation and CSi-Net to evaluate the similarity between samples and templates simultaneously. Since the input of CSi-Net is different in these two steps, we choose to execute them alternately instead of in order, to ensure the model can calculate the similarity both within samples and between samples and templates, and avoid catastrophic forgetting.\nIn the comparative learning step, we follow the same approach as the traditional siamese network, utilizing the loss function shown in Eq. 4:\n$L_{com} = \\sum_{i,j} L_{i,j}^{'com'}$,\n$L_{i,j}^{'com'} = \\alpha[label(c_i) == label(c'_j)](1 - S_{i,j})^2 + [label(c_i) \\neq label(c'_j)]S_{i,j}^2$,\n$S_{i,j} =CSi-Net(c_i, c'_j)$,\nwhere $c_i, c'_j$ represent the $i$th sample in the query branch and the $j$th sample in the key branch, $S_{i,j}$ represents the similarity between $c_i$ and $c'_j$ calculated by the CSi-Net, $label(c_i)$ indicates the category to which $c_i$ belongs, and $\\alpha$ is a weight factor for positive pairs to solve the long-tail problem, as the number of positive pairs is usually significantly fewer than negative pairs.\nIn the template learning phase, the Weight-Net first generates templates for each class, which will be introduced in the next section. Then we still use the comparative learning method to train the Weight-Net and CSi-Net simultaneously, incorporating the loss function shown in Eq. 5:\n$L_{tem} = \\sum_{i,j} L_{i,j}^{'tem'}$,\n$L_{i,j}^{'tem'} = \\alpha[label(c_i) == j](1 - S_{i,j})^2 + [label(c_i) \\neq j]S_{i,j}^2$,\n$S_{i,j} =CSi-Net(c_i, T_j)$,\nwhere $T \\in \\mathbb{R}^{n,2,t,D}$ represents the template matrix, $n$ represents class number, $T_j$ represents the template of class $j$, and $S_{i,j}$ represents the similarity between sample $c_i$ and template $T_j$.\nWe can abstract the processing of the template learning step as follows:\n$s = f(x,x', u)$,\n$t = g(s, \\theta_t)$,\n$\\hat{y} = f(x',t,v)$,\n$L = l(\\hat{y}, y)$,\n$u = v = \\theta_e$,\nwhere $f, g$ represent CSi-Net and Weight-Net, $\\theta_e, \\theta_t$ are their parameters, $x, x'$ are CSI samples, $s$ is the similarity score, $t$ is the template, $y, \\hat{y}$ are the ground truth and prediction result, and $l, L$ are the loss function and its value. Then the gradient descent can be executed according to the partial derivative of the network parameters:\n$\\frac{\\partial L}{\\partial \\theta_e} = \\frac{\\partial L}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial v}$,\n$\\frac{\\partial L}{\\partial \\theta_t} = \\frac{\\partial L}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial t} \\frac{\\partial t}{\\partial \\theta_t}$,\n$\\frac{\\partial L}{\\partial u} = \\frac{\\partial L}{\\partial \\hat{y}} (\\frac{\\partial \\hat{y}}{\\partial t} \\frac{\\partial t}{\\partial s} \\frac{\\partial s}{\\partial u}+ \\frac{\\partial \\hat{y}}{\\partial v}) \\frac{\\partial v}{\\partial \\theta_e}$.\n3) Inference Phase: In the inference phase, we can calculate the similarity score matrix between the testing samples and the template of each class, using the trained CSi-Net and the generated templates in the target domain. The classification result is given by Eq. 8:\n$S_{i,j}=CSi-Net(c_i, T_j)$,\n$Y_i = \\underset{j}{argmax}(S_{i,j})$,\nwhere $Y_i$ is the classification result of sample $c_i$."}, {"title": "D. Key Scenarios", "content": "1) In-domain: Even though the in-domain scenario is not the highlight of this paper, we first introduce how our model works in this scenario as it serves as the base for the few-shot and zero-shot scenarios. Moreover, the experiment results in the next section also show that our model outperforms other in-domain Wi-Fi sensing methods significantly.\nThe main challenge in the in-domain scenario is to find the optimal template for each category. Previous template generation methods in siamese networks often randomly select samples from the training set or simply take the average of the training set as the template [40]. However, these approaches do not capture the full range of features for each category. To address this limitation, we use Weight-Net to generate templates adaptively.\nIn detail, we first randomly select k samples from the training set and calculate their weight vector following Fig. 4. By combining the weighted average of the selected samples according to their corresponding weights, we generate the adaptive templates. Weight-Net dynamically determines the weight by analyzing the quality of each sample using the"}, {"title": "V. EXPERIMENT", "content": "1) Dataset: For the experiments, we utilized the dynamic part of the WiGesture Dataset [6]. The dataset was collected using an ESP32-S3 as the RX (receiver) and a home Wi-Fi router as the transmitter. The ESP device is equipped with an antenna and operates at a frequency of 2.4GHz with a sampling rate of 100 samples/s. The data collection environment is depicted in Fig. 8, with the transmitter and receiver positioned 1.5 meters apart. The dataset consists of a total of 8 individuals who performed various gestures, including left-right, forward-backward, and up-down motions, clockwise circling, clapping, and waving. These gestures are illustrated in Fig. 9.\n2) Training Setup: In our experiments, we implement the CSi-Net and Weight-Net based on ResNet-18 [36]. The total number of parameters in our models is approximately 2.2 million. We observe that our model occupies around 1.5 GB of GPU memory when using a batch size of 64. For optimization, we use the Adam optimizer with an initial learning rate of"}, {"title": "E. Ablation Study", "content": "In this section, we make a series of ablation experiment to illustrate the efficiency of each module of our CrossFi."}]}