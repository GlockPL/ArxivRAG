{"title": "MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance", "authors": ["Jihye Choi", "Nils Palumbo", "Prasad Chalasani", "Matthew M. Engelhard", "Somesh Jha", "Anivarya Kumar", "David Page"], "abstract": "In the era of Large Language Models (LLMs), given their remarkable text under- standing and generation abilities, there is an unprecedented opportunity to develop new, LLM-based methods for trustworthy medical knowledge synthesis, extrac- tion and summarization. This paper focuses on the problem of Pharmacovigilance (PhV), where the significance and challenges lie in identifying Adverse Drug Events (ADEs) from diverse text sources, such as medical literature, clinical notes, and drug labels. Unfortunately, this task is hindered by factors including variations in the terminologies of drugs and outcomes, and ADE descriptions often being buried in large amounts of narrative text. We present MALADE, the first effective col- laborative multi-agent system powered by LLM with Retrieval Augmented Gener- ation for ADE extraction from drug label data. This technique involves augmenting a query to an LLM with relevant information extracted from text resources, and instructing the LLM to compose a response consistent with the augmented data. MALADE is a general LLM-agnostic architecture, and its unique capabilities are: (1) leveraging a variety of external sources, such as medical literature, drug labels, and FDA tools (e.g., OpenFDA drug information API), (2) extracting drug-outcome association in a structured format along with the strength of the association, and (3) providing explanations for established associations. Instantiated with GPT-4 Turbo or GPT-40, and FDA drug label data, MALADE demonstrates its efficacy with an Area Under ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our implementation leverages the Langroid multi-agent LLM framework and can be found at https://github.com/jihyechoi77/malade.", "sections": [{"title": "Introduction", "content": "Pharmacovigilance (PhV) is the science of identification and prevention of adverse drug events (ADEs) caused by pharmaceutical products after they are introduced to the market. PhV is of enormous importance to both the pharmaceutical industry and public health, as it aims to safeguard the well-being of patients by detecting new safety concerns and intervening when necessary. A central problem in PhV is ADE Extraction: given a drug category C and an adverse event E, determine whether (and how strongly) C is associated with E. This task demands the analysis of a vast corpus of textual data sources from a variety of sources, such as patient medical records, clinical notes, social media, spontaneous reporting systems, drug labels, medical literature, and clinical trial reports. Besides the sheer volume of text from these sources, ADE extraction is further complicated by variability in the names of drugs and outcomes, and the fact that ADE descriptions are often buried in large amounts of narrative text [14].\nTraditionally, various classical natural language processing (NLP) and deep learning techniques have been used to address this problem [22, 21, 35, 2]. Compared to classical NLP methods, today's best Large Language Models (LLMs) (and even weaker open-source/local LLMs [36, 11]) exhibit a significant advancement in text understanding and generation capabilities, and there is a great opportunity to use these models to not only improve existing ADE extraction methods, but also consider data sources that were previously not feasible to use. Recent attempts to apply LLMs to ADE Extraction only leverage off-the-shelf ChatGPT [38], with limited performance and inconsistent reasoning for their extraction rationales [32]. These limitations stem primarily from two factors: (a) accurate ADE Extraction requires access to specific data sources which LLMs may not have \"seen\" during their pre-training, hence relying on an LLM's \u201cbuilt-in\u201d knowledge yields inaccurate results, and (b) LLMs, being probabilistic next-token predictors, may produce incorrect or unreliable results when used naively without carefully breaking down the task into simpler sub-tasks, or without mechanisms to validate and correct their responses.\nIn this paper, we introduce MALADE2(Multiple Agents powered by LLMs for ADE Extraction), the first effective multi-agent Retrieval-Augmented Generation (RAG) system for ADE Extraction. Our approach leverages two key techniques to address the above two limitations respectively: (a) RAG, equipping an LLM with up-to-date knowledge by augmenting an input query with relevant"}, {"title": "Related Work", "content": "The advent of highly-capable Large Language Models (LLMs) has sparked significant inter- est in applying these models to medical tasks, including diagnostics [28], medical question- answering [29, 23], and medical evidence summarization [33]. An important application area is pharmacovigilance, the science of identifying and preventing adverse drug events (ADEs) caused by pharmaceutical products after they are introduced to the market. The specific problem of ADE Extraction, namely, identifying whether a specific drug (or category) is associated with a specific adverse event, is a challenging task due to variations in drug and outcome terminologies, the pres- ence of ADE descriptions in large amounts of narrative text, and the disparate sources of such text data, which can include patient medical records, clinical notes, drug labels, medical literature, clinical trials, message boards, social media. Prior research in this field, notably works drawing on large-scale research initiatives including Sentinel [25], OMOP [27], and OHDSI [31], has focused on developing new methods for causal discovery from purely observational data. Huang et al. [10] investigate the use of social forums for constructing predictive models of ADEs, focusing on the performance of different data processing techniques and BERT architectures. von Csefalvay [37] introduces a novel LLM, DAEDRA, for detecting regulatory-relevant outcomes from passive phar- macovigilance reports. Sorbello et al. [30] use LLMs like GPT to improve the capture of opioid drug and adverse event mentions from electronic health records. Finally, Sun et al. [32] investigate the performance of ChatGPT for extracting adverse events from medical text sources.\nThese early applications of LLMs to ADE Extraction are limited in at least one of two ways: (a) they either use only the bare LLM (such as ChatGPT, or its API) without access to any external APIs, tools, or knowledge bases [38]. ADE extraction using only the LLM's \u201cbuilt-in\u201d knowledge (i.e., text it was exposed to during pre-training) is likely to be inaccurate and incomplete, since adverse events may be discovered in any new studies or reports; (b) all prior works use a single LLM (even when augmented with external data/tools) without any collaboration or feedback from other LLMs. Since LLMs are after all probabilistic next-token prediction models, there is no guarantee that the generated text is accurate or complete. The only way to improve the reliability of an LLM's responses in this scenario is to either resort to elaborate prompting techniques [40, 45], or have a human (or an LLM [18]) in the loop to verify the generated text and iteratively refine the prompts until a satisfactory response is obtained.\nTo address these limitations, three paradigms have emerged in LLM practitioners' toolboxes. The first limitation is addressed by two techniques: Retrieval Augmented Generation (RAG) and tool- use. RAG addresses the knowledge limitations of LLMs by augmenting the input prompt or query with relevant information retrieved from external knowledge bases (using similarity based on vec- tor embeddings, keywords, or a combination of both), and instructing the LLM to respond to the original query in a way that is consistent with the augmented data, and also to provide a justifica-"}, {"title": "Preliminaries on LLM-based Agents", "content": "While today's LLMs exhibit impressive capabilities, they remain constrained by technical and practical limitations such as brittleness, non-determinism, limited context window, inference costs, and latency [17], with the implication that one cannot simply give high-level instructions to an LLM and expect it to accomplish a complex task. Consequently, to best harness the capabilities of LLMs as components of a complex application, it is necessary to decompose the task into smaller sub-tasks and manage multiple LLM conversations, each with its own set of specifically- defined instructions, state, and data sources. This leads naturally to the notion of an agent as an LLM-powered entity responsible for a well-defined small sub-task. In Section 3.1, we introduce the key abstractions and components needed for agent-oriented programming, and Section 3.2 describes multi-agent orchestration. Our implementation leverages the open-source multi-agent LLM framework Langroid [3], which supports these abstractions and mechanisms."}, {"title": "Agent-oriented Programming", "content": "Agent, as an intelligent message transformer. A natural and convenient abstraction in design- ing a complex LLM-powered system is the notion of an agent that is instructed to be responsible for a specific aspect of the overall task. In terms of code, an Agent is essentially a class rep- resenting an intelligent entity that can respond to messages, i.e., an agent is simply a message transformer. An agent typically encapsulates an (interface to an) LLM, and may also be equipped with so-called tools (as described below) and external documents/data (e.g., a vector database, as described below). Much like a team of humans, agents interact by exchanging messages, in a manner reminiscent of the actor framework in programming languages [8]. An orchestration mechanism is needed to manage the flow of messages between agents, to ensure that progress is made towards completion of the task, and to handle the inevitable cases where an agent deviates from instructions. In this work we adopt this multi-agent programming paradigm, where agents are first-class citizens, acting as message transformers, and communicate by exchanging messages.\nTo build useful applications with LLMs, we need to endow them with the ability to trigger actions (such as API calls, computations, database queries, etc) and access external documents. Tools and Retrieval Augmented Generation (RAG) provide these capabilities, described next.\nTools, also known as functions or plugins. An LLM is essentially a text transformer; i.e., in response to some input text (known as a prompt), it produces a response. Free-form text responses are ideal when we want to generate a description, answer, or summary for human consumption, or even a question for another agent to answer. However, in some cases, we would like the responses to trigger external actions, such as an API call, code execution, or a database query. In such cases, we would instruct the LLM to produce a structured output, typically in JSON format, with various pre-specified fields, such as code, an SQL query, parameters of an API call, and so on. These structured responses have come to be known as tools, and the LLM is said to use a tool when it produces a structured response corresponding to a specific tool. To elicit a tool response from an LLM, it needs to be instructed on the expected tool format and the conditions under which it should use the tool. To actually use a tool emitted by an LLM, a tool handler method must be defined as well. The tool handler for a given tool is triggered when it is recognized in the LLM's response. See Appendix A.1 for a description of the LLM's interaction with a database.\nStarting with the view of an LLM as a text transformer, it turns out that one can express the notion of an agent, a tool, and other related concepts in terms of different function signatures, as shown in Table 4 in Appendix A.3.\nRetrieval Augmented Generation (RAG). Using an LLM in isolation has two major con- straints: (a) the responses are confined to the knowledge from its pre-training, hence cannot answer questions specific to private/enterprise documents, or up-to-date information past its training cutoff date; and (b) there is no way to verify the validity of the generated answers. RAG is the most pop- ular technique to address both limitations by making LLMs generate responses based on specific documents or data and justify the answer by presenting source citations [15]. The basic idea of RAG is as follows: when a query Q is made to an LLM-agent, a set of k documents (or portions thereof) D = {d1,d2, ...,dk} most \u201crelevant\u201d to the query are retrieved from a document-store, and the original query Q is augmented with D to a new prompt of the form, \u201cGiven the passages below: [d1, d2, ..., dk], answer this question: Q based ONLY on these passages, and indicate which passages support your answer\u201d. See Appendix A.2 for more details on RAG."}, {"title": "Multi-Agent Orchestration", "content": "As mentioned above, when building an LLM-based multi-agent system, an orchestration mech- anism is critical to manage the flow of messages between agents, to ensure task progress, and handle deviations from instructions. In this work, we leverage a simple yet versatile orchestra- tion mechanism that seamlessly handles user interaction, tool handling, and sub-task delegation. As in Figure 2, the orchestration mechanism is encapsulated in a Task class that wraps an Agent, and one initiates a task by invoking its run method which has type signature string \u2192 string, identical to the type signature of an Agent's own native \u201cresponse\" methods (corresponding to the LLM, tool-handler, and human user). The Task maintains a \u201ccurrent pending message\u201d (CPM)"}, {"title": "MALADE: Proposed Multi-Agent System for ADE Extraction", "content": "In this section, we describe our RAG-based Multi-Agent architecture, MALADE, for identifying associations between drug categories and outcomes. We first give a high-level outline of the objec- tives of the key sub-tasks in Section 4.1, and delve into their implementation details in Section 4.2 - 4.5. See Figure 1 for an illustrative depiction of the overall pipeline.\nWe emphasize that developing a multi-agent RAG system tailored for ADE extraction is a highly non-trivial undertaking, requiring careful handling of several issues: (a) the complex structure of FDA label data, which can be challenging for naively applied RAG techniques; (b) the difficulty of correctly grouping prescribed drugs (e.g., assigning the appropriate National Drug Code) based on the varied text descriptions present in medical databases; (c) LLM brittleness such as deviation from instructions, hallucinations, and inaccurate or incorrect responses; (d) Infinite loops, fixed points, and deadlocks, which can arise in inter-agent interactions unless carefully managed."}, {"title": "Objectives of Key Sub-tasks", "content": "Our ultimate goal is to identify the risk of an adverse event associated with a drug category. We developed our system, MALADE, to be able to respond to questions of the form:\n\"Does drug category C increases the risk of a specific (adverse) health outcome H, decrease it, or is there no clear effect?. And what is the evidence?\" For instance, C could be \"ACE inhibitors\u201d, and H could be \u201cangioedema\"."}, {"title": "Agent-Critic Interaction", "content": "This is the core multi-agent interaction pattern that underlies our system, and is reminiscent of Actor/Critic methods in reinforcement learning [13].\nAgent. In an Agent-Critic pair, the Agent is the primary entity that handles external-facing input and output. It receives a specific goal, instructions on how to accomplish the goal, and access to tools and resources. In our context, the goal is generally a form of specialized question-answering; resources can be data sources, or even other agents or multi-agent systems, that the agent can draw upon when answering the question; tools are structured responses needed to trigger calls to APIs, database look-ups, or computations.\nThe primary function of the Agent is to construct a sequence of queries to these resources to fulfill its goal. The Agent is instructed to compose a semi-structured message consisting of its answer, its reasoning steps and a justification (citing sources where possible) of its answer in a semi-structured format, and seek feedback on these from the Critic, as below.\nCritic. This is another agent, paired with the one described above. The Critic's role is to validate the Agent's reasoning steps and compliance with instructions, and provide feedback to the Agent,"}, {"title": "STEP 1: Finding Representative Drugs", "content": "We first construct a reasonably complete set of all drugs that can possibly belong to the category, by querying FDA's NDC database, which contains records of specific drugs, tagged with pharma- cological class information of various types (including chemical classes, mechanisms of action, and established pharmacologic classes). Specifically, we extract all drugs with names or classes matching the relevant search term or terms (e.g., \u201cantibiotic\u201d or any of the sub-categories consid- ered by OMOP, for example, erythromycin). Since this list may contain some drugs that do not actually belong to the class (e.g., a search for \u201ctypical antipsychotics\u201d returns atypical antipsy- chotics as well), we rely on an additional filtering phase to construct the final, reasonably accurate list of drugs in the category. For each drug D in this \"complete\" list, we obtain its prescription rate via a SQL query to the MIMIC-IV prescriptions table.\nNote that we chose to implement the above two SQL query steps directly without using an LLM to generate the queries. This is an instance of an important design principle we adhere to in our system, which we call the LLM Minimization principle: for tasks that can be expressed determin- istically and explicitly in a standard programming paradigm, handle them directly without using LLMs to enhance reliability and reduce token and latency costs."}, {"title": "STEP 2: Identifying Drug-Outcome Associations", "content": "DrugAgent is an Agent/Critic system whose task is to identify whether a given drug has an es- tablished effect on the risk of a given outcome, based on FDA drug label database, and output a summary of relevant information, including the level of identified risk and the evidence for such an effect. This agent does not have direct access to the FDA Drug Label data, but can receive this information via another agent, FDAHandler. FDAHandler is equipped with tools to invoke the OpenFDA API for drug label data, and answers questions in the context of information retrieved based on the queries. Information received from this API is ingested into a vector database, so the agent first uses a tool to query this vector database, and only resorts to the OpenFDA API tool if the vector database does not contain the relevant information."}, {"title": "STEP 3: Labeling Drug Category-Outcome Associations", "content": "To identify the association between a drug category C and an adverse health outcome H, we concurrently run a batch of queries to copies of DrugAgent, one for each drug D in the category, of the form: \"Does drug D increase or decrease the risk of condition H?\u201d. The results are sent to CategoryAgent, described next.\nCategoryAgent is an Agent/Critic system that performs the final classification step; its goal is to generate a label identifying whether a category of drugs increases or decreases the risk of a condition, or has no effect. In addition to the label, CategoryAgent produces a num- ber of additional outputs, all of which are combined into a JSON-structured string, including: (a) a confidence score in [0,1], indicating the confidence in the assigned label, (c) strength of evidence, one of \u201cnone\u201d, \u201cweak\u201d, or \u201cstrong\u201d, and (d) frequency of the effect, one of \u201cnone,\u201d \"rare\u201d, or \u201ccommon\u201d. In this sense, DrugAgent serves as a function of the following type: [string]\u2192{\u2018\u2018increase\u2019\u2019,\u2018\u2018decrease\u2019\u2019,\u2018\u2018no-effect\u2019\u2019} \u00d7 [0,1] \u00d7 {\u2018\u2018non- e\u2019\u2019,\u2018\u2018weak\u2019\u2019,\u2018\u2018strong\u2019\u2019}\u00d7{\u2018\u2018none\u2019\u2019,\u2018\u2018rare,\u2019\u2019,\u2018\u2018common\u2019'}. The structured output"}, {"title": "Experiments", "content": "This paper presents MALADE, the first LLM-based multi-agent architecture that is capable of pro- ducing a structured report with characterizations and scores related to the risk of an adverse health outcome H from a drug category C, based on FDA drug label data. We evaluate our method against a widely used benchmark, the OMOP Evaluation Ground Truth task [19], henceforth referred to as the OMOP ADE task (Section 5.1), to answer the following three research questions:\nRQ1: How effectively does MALADE identify ADEs? (Section 5.2)\nRQ2: Does Agent-Critic interaction, the core design pattern underlying MALADE, effectively enhance the reliability of the system? (Section 5.3)\nRQ3: What useful insights do the justifications by MALADE provide for further system im- provement? (Section 5.4)"}, {"title": "Evaluation Setup", "content": "The objective of OMOP ADE task is to assign one of three labels (\u201cincrease,\u201d \u201cdecrease,\u201d and \u201cno-effect\u201d) to each (C', H) pair, denoting whether C increases, decreases, or has no effect on the risk of H, respectively. There are 10 drug categories, some of which consist of a single drug, and 10 health outcomes (refer to Table 6 for the complete list). Notably, while only three labels are valid outputs, not all (C, H) pairs are deemed sufficiently certain to be used in the evaluation. The authors of OMOP ADE task mark certain pairs as uncertain, to which we assign \u201cno-effect\" labels with the special restriction that it should not be used in the evaluation. See Appendix B.3 for further details.\nMetrics. For quantitative evaluation, we convert the task into binary classification with two different focuses of analysis: (1) classifying effect vs no-effect, where the labels \u201cincrease\" and \u201cdecrease\u201d are considered the positive class, and \u201cno-effect\u201d is the negative class (namely, effect- based classification); and (2) classifying ADE vs. non-ADE, where only \u201cincrease\u201d is considered the positive class, and the other two labels are the negative class (namely, ADE-based classifica-\""}, {"title": "RQ1: MALADE effectively identifies ADES", "content": "In the evaluations of MALADE, we consider two LLMs, GPT-4 Turbo and GPT-40. For GPT-40, we limit the number of rounds of feedback from Critics to 5, after which it is required to accept. Figure 4 compares the ground truth labels of OMOP ADE task with ADE labels identified by MALADE (with GPT-4 Turbo). Considering the uncertainty inherent in the label of certain (drug category, outcome) pairs [19], these indicate strong performance on the task. See Figure 10 of Appendix B for results on GPT-40. We also present the confusion matrix of the MALADE labels in Figure 5.\nMoreover, we report the performance of MALADE in terms of AUC and F1 metrics (see Table 1). Recall that CategoryAgent outputs a confidence score ranging from 0 to 1 for its predicted labels, namely \"increase,\u201d \"no-effect,\" or \"decrease.\u201d. This score reflects the agent's certainty regarding the accuracy of the predicted outcome. For quantitative evaluation as in Table 1, we transform these tripartite label-confidence scores into binary classification probabilities, suitable for effect- based or adverse drug event (ADE)-based analysis. Converting the three-class labels to a binary format requires a clear method for correlating each confidence score with a probabilistic value for the respective binary classification task.\nThe three labels exhibit a natural progression: \u201cdecrease\u201d, \u201cno-effect\u201d, and \u201cincrease\u201d imply an ascending likelihood that a drug category is associated with the adverse outcome of interest, signi- fying a rising probability score for the positive class in ADE-based classification. Furthermore, an increase in confidence of \"no-effect\" or \"decrease\u201d corresponds to a decrease in the ADE score, while an increase in confidence of the \"increase\u201d label corresponds to an increase in the ADE score. These observations guide us in formulating an intuitive conversion of the label-confidence scores into ADE probability scores; taking (1 \u2013 Cde)/3, (2 \u2013 Cno)/3, and (2 + Cin)/3, respectively, where Cde, Cno, and Cin are the LLM output confidence score when the assigned label is \u201cdecrease\u201d, \"no-effect\", and \"increase\", respectively. This transformation preserves the semantic ordering of the classes, as well as the valence of confidence in each class. To illustrate, increasing confidence in \"decrease\u201d or \u201cno-effect\u201d suggests that the LLM is less confident that C causes H. We derive an effect-score similarly, except that both \u201cincrease\u201d and \u201cdecrease\u201d are now positive classes; taking (1 + Cin/de)/2 and (1 - Cno)/2, respectively.\nThe results in Table 1 indicate that the confidence scores output by the model are well-calibrated. We observe that MALADE performs well both at distinguishing ADEs from non-ADEs and at identifying the presence/absence of an effect in general. We include ROC curves and sensitivity vs. specificity curves in Figure 11 and Figure 12 of Appendix B, respectively. We conduct experiments with additional scoring functions, in particular, the model's estimates of the probabilities that C will cause or prevent H; see Appendix B.1.\""}, {"title": "RQ2: Agent-Critic interaction enhances reliability", "content": "Our primary tool to analyze the effectiveness of the Agent-Critic pattern in MALADE is by abla- tion; in particular, we evaluate modified versions of MALADE, with and without feedback from the Critic components of DrugAgent and CategoryAgent, with and without RAG for FDAHandler. The results are shown in Table 2.\nWe observe that, both in the case with and without RAG, Critics improve the quality of the confi- dence scores, increasing both ADE-based and Effect-based AUCs. We additionally observe strong performance without RAG (in which case Critics slightly improve AUCs but decrease F1 scores),"}, {"title": "RQ3: MALADE provides justifications that are aligned with human expert reasoning, and help understand its failure modes", "content": "We extract the justifications produced by CategoryAgent from a full run of MALADE for OMOP ADE task for review by a clinician. We observe that the agent exhibits valid medical reasoning in most cases, in particular, 85% of its justifications align with the reasoning of the clinician.\nMore importantly, examining the provided justifications helps us understand the common pat- terns of failures and provides guidance on the further improvement of the system. For instance, CategoryAgent occasionally assigns \u201cincrease\" to drug categories based on weak evidence, over- estimating its strength It may also overlook risks not explicitly mentioned in the drug label data, particularly when DrugAgent fails to provide sufficient context. In addition, CategoryAgent may fail to identify potential therapeutic effects not specified in the drug label data in association with a condition. We observe that it does not recognize the antihistamine properties of tricyclic antide- pressants. In one case, evidence against gastric and duodenal ulcers caused by alendronate led CategoryAgent to dismiss results regarding esophageal ulcers.\nWhile MALADE exhibits correct medical reasoning in general and hence achieves strong and reliable performance on ADE identification, we highlight that understanding its failures is essential for its further improvements, as discussed in Section 6. Extracts from the logs showing both correct"}, {"title": "Discussion", "content": "Generalizable insights about collaborative LLM-powered agents in the context of health- care. We have observed the strong performance of MALADE for ADE extraction, indicating the potential of multi-agent systems toward broader PhV application. Importantly, the principles guiding the design of our system, including 1) the Agent-Critic interaction, 2) the decomposition of a complex task into sub-tasks, and 3) LLM minimization, are quite general. These principles extend beyond PhV, and can be applied to many other problems in clinical medicine which require trustworthy, automated responses to challenging questions that must be answered based on multi- ple competing, and potentially conflicting, sources of knowledge or data. Thus, MALADE may be viewed not only as a system for ADE extraction, but also as a roadmap for development of other multi-agent systems that generate precise, evidence-based responses to such questions.\nGeneral principle 1) Agent-Critic interaction. The Agent/Critic pattern, as discussed in Sec- tion 4, is essential to the design of our system, and serves as a powerful tool to enhance accuracy of an LLM-based system. Indeed, we have observed several instances where the Critic corrected the parent Agent's initial response, as in the example mentioned in Section 4.2. However, we should note that if improperly configured, Critics can be harmful to the performance of a sys- tem, both in terms of efficiency (since the repeated rounds of interaction between the Agent and Critic can significantly increase token cost and runtime), and reliability. Since a Critic strictly en- forces the provided guidelines, incorrect guidelines can significantly harm performance; in some cases, excessively strict requirements can lead to infinite loops, as the Agent and Critic will dead- lock, neither able to satisfy the other's requirements. We observed this effect in early versions of MALADE; resolving the infinite loop issue required specific instructions listing acceptable behav- ior. For instance, the Critic for DrugAgent needed to be explicitly told to accept statements that the effect of a drug was uncertain due to a lack of information from the FDA labels; without this, infinite loops occurred in some drug-outcome combinations.\nGeneral principle 2) Decomposition of a complex task. The principle of decomposition, mir- roring the analogous principle of general software development, is the Unix philosophy as applied to multi-agent systems. Individual agents should be minimal, in that they should \u201cdo one thing and do it well", "LLM-maximalist": "pproach, where LLMs are responsible for all aspects of the task. Unfortunately, this can be both costly and unreliable, since using proprietary LLMs (e.g., GPT-4) behind paid APIs incurs a significant \u201ctoken cost\u201d as well as \u201ctime cost"}, {"title": "Conclusion", "content": "We consider the problem of ADE Extraction from FDA Drug Labels, a key task in Pharmacovig- ilance (PhV), and propose a solution using MALADE, based on collaboration among multiple LLM-powered agents equipped with Retrieval Augmented Generation (RAG). Our system goes significantly beyond simplistic techniques that only produce a binary label of presence/absence of"}, {"title": "Supplementary Material", "content": "Section A includes an in-depth description of the core primitives of our multi-agent framework. Section B offers the experimental details, including the system prompts for each agent, the de- tails on our OMOP evaluation, and discussions of the postprocessing of the generated scores and justifications. In Section C, we analyze both successful and unsuccessful instances of MALADE, presenting comprehensive logs for selected examples. Section D presents an ablation study that evaluates the individual contributions of key components to the overall system efficacy; namely, the iterative refinement facilitated by Agent-Critic interactions, and the integration of external knowl- edge through RAG. Finally, in Section E, we assess how much the variance of numerical outputs by the random sampling of LLMs affects the variance of scores output by the entire MALADE system."}, {"title": "Agent-Oriented Programming", "content": "This section describes the core abstractions needed to implement a complex LLM-based applica- tion such as MALADE. The open-source multi-agent LLM framework langroid [3] has an elegant, intuitive and flexible implementation of these abstractions, and MALADE is built on top of this library."}, {"title": "Tool Use: Example", "content": "As a simple example, a SQL query tool can be specified as a JSON structure with a sql field (containing the SQL query) and a db field (containing the name of the database). The LLM may be instructed with a system prompt of the form:\nWhen the user asks a question about employees,\nuse the SQLTool described in the below schema,\nand the results of this tool will be sent back to you, and you can use these\nto respond to the user's question, or correct your SQL query\nif there is a syntax error.\nThe tool handler would detect this specific tool in the LLM's response, parse this JSON structure, extract the sql and db fields, run the query on the specified database, and return the result if the query ran successfully, otherwise return an error message. Depending on how the multi-agent system is organized, the query result or error message may be handled by the same agent (i.e., its LLM), which may either summarize the results in narrative form, or revise the query if the error message indicates a syntax error."}, {"title": "Retrieval Augmented Generation", "content": "RAG involves two phases: (a) a ingestion phase, where documents are sharded into reasonable- size chunks and ingested into a suitable type of document-store, and (b) a query phase, where top-k document-chunks most relevant to the query are retrieved from the document-store, and the LLM is prompted to answer the query given these chunks (see Figure 6 for illustrative description). Not surprisingly, the performance (i.e., precision and recall of answers) of a RAG system depends crit- ically on how we define the relevance of document chunks to the query so that they will contain"}, {"title": "From LLM to Agent-Oriented Programming", "content": "If we view an LLM as a function with signature string \u2192 string, it is possible to express the concept of an agent, tool, and other constructs in terms of derived function signatures, as shown in Table 4."}, {"title": "Detailed Description of Multi-Agent Orchestration", "content": "When building an LLM-based multi-agent system, an orchestration mechanism is critical to man- age the flow of messages between agents, to ensure task progress, and handle deviations from instructions. In this work, we leverage Langroid's simple yet versatile orchestration mechanism that seamlessly handles:\n\u2022 user interaction\n\u2022 tool handling\n\u2022 sub-task delegation"}, {"title": "Prompts to Each Agent", "content": "STEP1: finding representative drugs under each drug category. This is the full prompt to DrugFinder:\nYou are a helpful assistant with general medical and pharmacological knowledge. I will provide you with a list of drugs, and the result of a query on a medical database with their usage rates; your goal is to find N representative drugs in category {cat} out of the provided drugs.\nPrefer generic names if possible, and do not include both a brand and generic name for the same drug in your list."}, {"title": "Probability-based scoring", "content": "In addition to the confidence-based scoring discussed in Section 5, we consider probability-based scoring. In particular, we ask the model to specify the probability of an evant, specifically, the event that a drug in category C causes or prevents H.\nAs in Section 5, we must derive confidence scores in ADE and effects from the output probability estimate; as the probability is already in terms of the probability of any effect, either harmful or beneficial, we use the probability directly for Effect AUC. For ADE AUC, we use the tranformation shown in Figure 7.\nWe make the assumption that, if the LLM specifies a probability p with a label other than \u201cde- crease,\" that probability expresses the probability of a harmful effect. Hence, the derived score decreases linearly with increasing probability when the label is \u201cdecrease,\u201d and increases linearly when the label is anything else. With this assumption, we additionally maintain the semantic or- dering of the LLM's implied confidence in ADE, and hence this is a well-defined confidence score.\""}, {"title": "OMOP ADE task Details", "content": "The ground truth for the OMOP ADE task is shown in Figure 8. As noted in Section 5.1, while the OMOP ADE task permits only three output labels for the effect of a drug category on an outcome, some drug category, outcome pairs are considered uncertain (which we treat as a \u201cno-effect\" label which is"}]}