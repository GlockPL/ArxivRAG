{"title": "DiM: f-Divergence Minimization Guided Sharpness-Aware Optimization for Semi-supervised Medical Image Segmentation", "authors": ["Bingli Wang", "Houcheng Su", "Nan Yin", "Mengzhu Wang", "Li Shen"], "abstract": "As a technique to alleviate the pressure of data annotation, semi-supervised learning (SSL) has attracted widespread attention. In the specific domain of medical image segmentation, semi-supervised methods (SSMIS) have become a research hotspot due to their ability to reduce the need for large amounts of precisely annotated data. SSMIS focuses on enhancing the model's generalization performance by leveraging a small number of labeled samples and a large number of unlabeled samples. The latest sharpness-aware optimization (SAM) technique, which optimizes the model by reducing the sharpness of the loss function, has shown significant success in SSMIS. However, SAM and its variants may not fully account for the distribution differences between different datasets. To address this issue, we propose a sharpness-aware optimization method based on f-divergence minimization (DiM) for semi-supervised medical image segmentation. This method enhances the model's stability by fine-tuning the sensitivity of model parameters and improves the model's adaptability to different datasets through the introduction of f-divergence. By reducing f-divergence, the DiM method not only improves the performance balance between the source and target datasets but also prevents performance degradation due to overfitting on the source dataset.", "sections": [{"title": "1. Introduction", "content": "Medical Image Segmentation (MIS) [3, 14, 33] plays a crucial role in assisting computers with disease diagnosis and treatment research by helping identify key organs or lesions in abnormal images. Recently, numerous supervised learning-based encoder-decoder network architectures have made significant advancements in medical image segmentation, such as U-Net[24], U-Net++[46], and H-DenseUNet [13]. However, the success of these technologies largely relies on large-scale, pixel-level annotated data. In practice, annotating medical images is not only costly but also challenging due to issues such as low contrast and noise, making it difficult to clearly display images. Moreover, medical images require more specialized knowledge compared to natural images, which makes constructing a large-scale, accurately annotated medical image database nearly an impossible task. In contrast, semi-supervised learning [23, 35] offers a new solution to the problem of insufficient data supervision in weakly supervised learning [47]. It primarily utilizes a small amount of labeled data and a large amount of unlabeled data for joint training. Clearly, semi-supervised learning is significantly more suitable for medical image segmentation and adapting to real-world clinical scenarios than traditional supervised learning methods.\nDue to the easy availability of unlabeled data, doctors may not have the time to verify its distribution when faced with massive amounts of data. This \"domain shift\" [7, 25] issue can lead to significant performance degradation in models, and it is a critical concern when developing semi-supervised medical image segmentation (SSMIS) [21] models. In fact, we should allow unlabeled data to come from one or more different distributions. However, existing unsupervised domain adaptation (UDA) [11, 43, 44] methods do not directly address this issue because they rely on large amounts of labeled source domain data, which is exactly what SSMIS aims to resolve.\nRecent studies, such as Sharpness-Aware Minimization (SAM)[8], enhance model generalization performance by reducing the sharpness of the loss function. Here, L represents the loss function to be minimized, and 0 represents the parameters of the neural network. SAM first computes a weight perturbation \u03f5 that maximizes the empirical risk L(\u03b8), and then minimizes the loss of the perturbed network. In short, SAM aims to reduce the maximum loss near the model parameters \u03b8. Due to the complexity of this minimization-maximization optimization problem, SAM approximates L with a surrogate loss function L_p(\u03b8) for minimization. However, it is important to note that minimizing L_p(\u03b8) does not guarantee reaching the flat minimum region for SSMIS [48]. KL divergence [32] has demonstrated strong performance in SSMIS. The application of KL divergence in SSMIS primarily improves model training efficiency and accuracy by measuring the differences between different probability distributions. This is particularly useful when dealing with limited labeled data and a large amount of unlabeled data, as it helps guide the model to learn more useful information in a semi-supervised setting. For example, MMLBF [6] propose a region-based multi-phase level set method based on KL divergence. Lu et al.[18] estimate uncertainty by calculating the Kullback-Leibler divergence between the predictions of the student and teacher models, and directly use this uncertainty to correct the learning of noisy pseudo-labels, rather than setting a fixed threshold to filter pseudo-labels. SwinMM[37] includes a masked multi-view encoder and a novel proxy task based on mutual learning, which contributes to effective self-supervised pretraining.\nHowever, all of these methods are considered from the perspective of KL divergence, which is highly sensitive to probability values close to zero in the target distribution, often leading to an infinite divergence. In contrast, f-divergence can reduce this sensitivity by selecting an appropriate function, making it more stable and robust, especially when dealing with sparse or extreme distributions. In SSMIS, SAM emphasizes achieving stability by controlling the sensitivity of model parameters, while the introduction of f-divergence helps further regulate the model's adaptability across different domains. By minimizing f-divergence, SAM can enhance the balanced performance of the model across both the source and target domains, while avoiding performance degradation due to overfitting the source domain. In this work, to overcome the limitation of SAM and explore the full potential of f-divergence, we present a novel method f-divergence minimization guided sharpness-aware optimization for semi-supervised medical image segmentation (DiM). By consider the f-divergence and sharpness-aware minimization, which can still be effectively computed even when the support sets of the distributions are different. Our main contributions can be summarized as follows:\n\u2022 we analyze the limitations of SAM-like methods and propose f-divergence to ensure the model convergence to a flat region with a small loss.\n\u2022 To the best of our knowledge, this is the first work to apply f-divergence constraints to SAM paradigm.\n\u2022 we demonstrate the superior performance of DiM to state-of-the-arts on three SSMIS benchmarks."}, {"title": "2. Related Work", "content": ""}, {"title": "2.1. Semi-supervised Medical Image Segmentation", "content": "Due to the complexity of medical images, extensive manual annotation by experts is both challenging and costly [49]. To address this, semi-supervised medical image segmentation approaches have emerged as effective solutions that leverage limited labeled data [3]. Luo et al. [19] proposed a dual-task consistency-based semi-supervised framework to simultaneously predict per-pixel segmentation maps and geometrically-aware level set representations, introducing a dual-task consistency regularization to enhance performance. Wu et al. [39] presented MC-Net++, which employs a shared encoder and multiple distinct decoders and introduced a new mutual consistency constraint. This approach statistically identifies uncertain regions, particularly hard regions within unlabeled data. Luo et al. [20] incorporated a cross-teaching approach between CNNs and Transformers, resulting in a simple yet efficient semi-supervised learning framework. Miao et al. [23] highlighted the importance of model independence between networks or branches in semi-supervised medical segmentation (SSMS). Ma et al. [22] identified the issue of performance degradation in semi-supervised medical image segmentation due to shared domain distributions, proposing Mixed-domain Semi-supervised Medical Image Segmentation (MIDSS). They emphasized that generating reliable pseudo-labels for unlabeled data is crucial in domain shifts in labeled data. Nevertheless, due to the inherent complexity of medical images, these models often exhibit limited generalization ability and convergence instability, which remains a challenging problem."}, {"title": "2.2. Unsupervised Domain Adaptation", "content": "Unsupervised Domain Adaptation (UDA) [9, 15, 34] aims to adapt models from a labeled source domain to an unlabeled target domain by minimizing the domain shift. This alignment of feature distributions enables knowledge transfer from source to target, enhancing classification performance [10, 38]. Many UDA approaches use a domain classifier to distinguish source from target features, while the feature extractor learns to match feature distributions [16, 30]. UDA is widely used in tasks like image classification [15], semantic segmentation [28], and object detection [27]. Semi-supervised domain adaptation further incorporates a small amount of labeled target data to improve transfer [26]."}, {"title": "2.3. Sharpness-Aware Minimization (SAM)", "content": "Foret et al. [8] observed that solely minimizing training loss can lead to suboptimal model quality. They proposed Sharpness-Aware Minimization (SAM), which seeks parameters in neighborhoods of uniformly low loss, resulting in a Min-Max optimization problem suitable for gradient descent. Andriushchenko et al. [1] provided theoretical insights on SAM's implicit bias in diagonal linear networks and empirically examined its behavior in nonlinear networks. Zhou et al. [45] addressed SAM's limitation in handling class imbalance, particularly overfitting to tail classes, by introducing Imbalanced-SAM (ImbSAM), a class-aware smoothing approach effective in long-tailed classification and semi-supervised anomaly detection tasks. Wang et al. [36] introduced a model integrating MedSAM with an uncertainty-aware loss function and SharpMin optimizer, enhancing segmentation accuracy and robustness. However, a tailored solution for semi-supervised medical image segmentation remains absent."}, {"title": "3. Methods", "content": ""}, {"title": "3.1. Aligning Features via f-Divergence", "content": "Semi-supervised medical image segmentation is challenging due to the scarcity of labeled data and the high-dimensional complexity of medical images. In this setting, models must leverage both labeled and unlabeled data to learn precise segmentation boundaries. However, limited labeled data can lead to feature drift, where the representations learned from unlabeled data deviate from those based on labeled data. This misalignment between labeled and unlabeled feature distributions reduces segmentation accuracy and limits generalization on unseen data.\nTo address this, we utilize f-divergence to align the high-dimensional logits from labeled and unlabeled data, constraining the features of unlabeled data based on a limited set of labeled data. Let P_{label} and P_{unlabel} denote the distributions of logits for the labeled and unlabeled data over a discrete set X. Our goal is to guide P_{unlabel} by minimizing the f-divergence between these distributions in high-dimensional space.\nThis alignment mitigates feature drift, improving generalization in the target domain. Additionally, f-divergence operates effectively in high-dimensional spaces, making it well-suited for capturing subtle but critical variations in medical image features. By aligning feature distributions, f-divergence fosters a stable and consistent feature representation, enhancing segmentation accuracy in semi-supervised conditions.\nFor a convex function f(x) : R+ \u2192 R with f(1) = 0, the f-divergence D_f(P_{label}||P_{unlabel}) is defined as:\nD_f(P_{label}||P_{unlabel}) = E_{x \\sim P_{unlabel}} [\\frac{P_{label}(x)}{P_{unlabel}(x)}] - 1 + f'(\\infty)P_{label}(P_{unlabel}=0), (1)\nwhere f'(\\infty) = lim_{t \\rightarrow \\infty} f'(t). The second term represents the contribution of points x in the support of P_{label} where P_{unlabel}(x) = 0, which accounts for cases where the labeled and unlabeled data distributions do not overlap.\nTo align P_{label} and P_{unlabel}, we define the alignment loss:\nL_{align} = D_f(P_{label}||P_{unlabel})\n= E_{x \\sim P_{unlabel}} [f'(\\frac{P_{label}(x)}{P_{unlabel}(x)})]. (2)\nMinimizing L_{align} encourages the logits of unlabeled data to approximate those of labeled data, enhancing feature consistency for semi-supervised learning.\nTo quantify this alignment, we utilize specific f-divergence variants frequently used in machine learning, including Jeffrey divergence, Jensen-Shannon divergence, and Pearson divergence. Each variant has a unique form of f(x), f'(x), and f''(x), as shown in Table 1, enabling flexible divergence calculations between P_{label} and P_{unlabel}. The f-divergences are computed via Monte Carlo estimation based on samples from P_{unlabel}, applying the respective values in Table 1 to evaluate L_{align} and facilitate back-propagation during training."}, {"title": "3.2. Sharpness-Aware Entropy Minimization", "content": "Semi-supervised medical image segmentation leverages both labeled and unlabeled data for accurate boundary detection. However, limited labeled data and distribution shifts often lead to feature inconsistency and unreliable predictions, especially on unseen test samples, necessitating methods that improve model robustness to distributional variations. Sharpness-aware minimization (SAM) enhances model generalization by optimizing within low-loss neighborhoods, stabilizing performance under distribution shifts. However, directly filtering unreliable test samples using gradient norms is challenging due to variations in scale across models and shifts.\nDirectly using gradient norms to filter out unreliable test samples is challenging due to variability in scale across models and types of distribution shifts. Instead, we leverage entropy as a proxy for gradient magnitude, selecting samples with low entropy values to focus adaptation on confident predictions. Given an entropy function E(x; \u03b8) for a sample x with model parameters \u03b8, we define the selective entropy minimization as:\nmin_{\u03b8} S(x)E(x; \u03b8), S(x) = I\\{E(x;\u03b8)<E_o\\}(x) (3)\nwhere S(x) is an indicator function that activates when the entropy E(x; \u03b8) is below a pre-defined threshold E_o. This approach ensures that only samples with low entropy (i.e., high confidence) contribute to the training, effectively filtering out unreliable samples that might otherwise induce large gradients.\nFor further stability, we aim to guide the model towards flatter regions of the entropy loss landscape, which reduces sensitivity to noisy gradients. We define a sharpness-aware entropy objective, E^{SA}(x; \u03b8), that measures the maximum entropy within a perturbation neighborhood around the current parameters:\nmin_{\u03b8} E^{SA}(x; \u03b8), E^{SA}(x;\u03b8) = max_{||\u03f5||_2\u2264\u03c1} E(x;\u03b8 + \u03f5) (4)\nwhere \u03f5 is a perturbation vector constrained within a Euclidean ball of radius \u03c1. This inner maximization encourages the model to be robust against perturbations, promoting a flat minimum for the entropy loss. Following the SAM approach, we approximate \u03f5^\u2217(\u03b8) by:\n\u03f5(\u03b8) = \u03c1 sign (\u2207_\u03b8E(x; \u03b8)) \\frac{\u2207_\u03b8E(x;\u03b8)}{||\u2207_\u03b8E(x; \u03b8) ||_2} (5)\nSubstituting \u03f5(\u03b8) back into the objective, we obtain an approximation for the gradient that encourages flat minima:\n\u2207_\u03b8E^{SA}(x; \u03b8) \u2248 \u2207_\u03b8E(x;\u03b8)|_{\u03b8+\u03f5(\u03b8)} (6)\nOur final objective for Reliable Sharpness-Aware Entropy Minimization combines selective entropy minimization and sharpness-aware optimization:\nmin_{\u03b8} S(x) E^{SA}(x; \u03b8) (7)\nIn this study, we introduce Sharpness-Aware Entropy Minimization(SAEM), an approach that combines entropy minimization with sharpness-aware training to achieve adaptive entropy reduction, enhancing model stability under challenging conditions. Here, S(x) and E^{SA}(x; \u03b8) represent entropy measures as defined in Equations (3) and (4), respectively. The learnable parameters designated for adaptation are denoted as \u03b8 \u2286 \u0398.\nIn essence, SAEM offers a robust framework by integrating entropy filtering with sharpness-aware training, yielding adaptive entropy reduction while ensuring model resilience, particularly under demanding conditions."}, {"title": "3.3. Loss Function", "content": "The overall loss L_{total} is composed of the following components:\n1. Supervised Loss (L_s): Applied to labeled data to guide predictions with ground truth, combining cross-entropy and dice losses for accurate segmentation.\n2. Intermediate Losses (L_{in} and L_{out}): Defined for intermediate samples u_n and u_{sut}, each using weighted cross-entropy (L_{ce}) and dice loss (L_{dice}) to enforce consistency between pseudo labels and model predictions.\nL_{in} = L_{ce} (P_{in}, \\hat{P}_{in}, w_{in}) + L_{dice} (P_{in}, \\hat{P}_{in}, w_{in}) (8)\nL_{out} = L_{ce}(P_{out}, \\hat{P}_{out}, w_{out}) + L_{dice} (P_{out}, \\hat{P}_{out}, w_{out}) (9)\nwhere w_{in} and w_{out} are pixel-wise weights set by a confidence threshold to filter unreliable pseudo labels.\nEach component plays a crucial role in enforcing robust supervision on both labeled and unlabeled data, supporting reliable predictions across domains. The overall loss L_{total} is defined as follows:\nL_{total} = L_s + \u03bb (L_{in} + L_{out} + \u03bbL_{sym}) + L_{align} (10)\nwhere \u03bb is a time-dependent coefficient that scales unsupervised components as training progresses, defined by:\n\u03bb(t) = e^{-5(1-t/t_{total})^2}. (11)"}, {"title": "4. Experiments", "content": ""}, {"title": "4.1. Experiment Datasets", "content": "Fundus dataset consists of retinal fundus images gathered from four medical centers, mainly intended for tasks involving the segmentation of the optic cup and disc. Each image has been cropped to create a region of interest within an 800\u00d7800 bounding box. We then resize and randomly crop these images to a size of 256 \u00d7 256.\nProstate dataset includes prostate T2-weighted MRI data, complete with segmentation masks, sourced from six different locations across three public datasets. We randomly divide the dataset into training and testing sets at a ratio of 4:1, resizing and randomly cropping each 2D slice to 384 \u00d7 384. Labeled samples are chosen from consecutive slices within individual cases, ensuring there is at most one case overlap and no overlap of slices with unlabeled samples."}, {"title": "4.2. Comparison Methods and Settings", "content": "Our method is implemented in PyTorch and utilizes an NVIDIA GeForce RTX 3090 GPU. We establish default experimental parameters for training. Optimization is performed using the SAM optimizer, with a base optimizer of Stochastic Gradient Descent (SGD) set to a momentum of 0.9, a weight decay of 0.0001, and an initial learning rate of 0.03. The batch size is set to 8, comprising 4 labeled and 4 unlabeled samples. We conduct a total of 30,000 iterations for the Fundus dataset and 60,000 iterations for the Prostate dataset.\nDuring testing, the final segmentation results are generated by the student model. Our approach is benchmarked against several state-of-the-art (SOTA) methods, including supervised techniques such as UA-MT [42], FixMatch [31], CPS [5], CoraNet [29], SS-Net [40], BCP [2], CauSSL [23], and MiDSS [21], as well as domain-unsupervised adaptation methods like FDA [41], SIFA [4], and UDA-VAE++ [17].\nIn each experiment, a limited amount of data from a designated domain (e.g., Domain 1 in Tab. 2) is labeled, while the remaining data are treated as unlabeled. For the upper-bound comparison, we utilized the f-divergence, specifically employing the Jensen-Shannon divergence to calculate the distance between logits, and used the most naive SAM optimizer in our experiments. For the upper bound, we followed the results of the MiDSS paper, which applied UCP within the FixMatch framework, utilizing all available training data from a specific domain as labeled data, providing the model with comprehensive source domain information.\nOur evaluation metrics include the Dice coefficient (DC), Jaccard coefficient (JC), 95% Hausdorff Distance (HD), and Average Surface Distance (ASD). Except for SIFA, which incorporates ResNet blocks [12] for its generator and decoder, all methods employ the U-Net backbone [24]."}, {"title": "4.3. Comparison with State-of-the-Art Methods", "content": "Results on Fundus dataset. With only 20 labeled samples, DiM achieves superior performance across all domains in the optic cup/disc segmentation task, as illustrated in Table 2. DiM consistently outperforms competing methods in all metrics, which achieves the highest average DC and JC scores while maintaining the lowest HD and ASD, highlighting its robustness and precision in segmenting dual objects with overlapping regions. These results suggest that DiM effectively mitigates issues faced by other semi-supervised and unsupervised domain adaptation methods, such as error accumulation and limited knowledge transfer, ensuring both high accuracy and generalizability across multiple domains.\nResults on Prostate dataset. As shown in Table 3, DiM achieves outstanding performance across all metrics on Prostate dataset. It is also noteworthy that DiM achieves the highest DC and JC averages while maintaining the lowest HD and ASD scores, suggesting higher segmentation accuracy and boundary precision. The inclusion of SAM likely contributes to improved generalization by mitigating sharp minima, while f-divergence loss enhances alignment of the predicted and true distributions, reducing segmentation errors. These results underscore the robustness and effectiveness of our method."}, {"title": "4.4. Ablation Study", "content": "Firstly, We conduct ablation studies to show the impact of each component in DiM . Sencondly, our objective is to assess whether varying types of f-divergences lead to notable performance differences in the model and to identify the optimal form for superior outcomes.\nThe effectiveness of SAM. As demonstrated in Table 4, incorporating the Sharpness-Aware Minimization (SAM) optimizer (as seen in Method #2 and #4 compared to #1.) enhances model performance on the Optic Cup/Disc segmentation task. SAM effectively reduces the model's loss, increasing robustness to minor data distribution shifts and enabling more efficient capture of inter-sample similarity. Consequently, SAM improves the DC and JC scores while reducing the HD and ASD. These results indicate that SAM not only strengthens the model's generalization ability but also enhances segmentation accuracy and boundary precision.\nThe effectiveness of f-Divergence. The incorporation of f-divergence (as seen in Method #3 and #4 compared to #1.) contributes to notable improvements in model performance, particularly through a marked reduction in ASD and HD metrics, as shown in Table 4. By quantifying the discrepancy between probability distributions of labeled and unlabeled data, f-divergence enhances the model's capacity to represent features within the unlabeled dataset. Experimental results demonstrate that introducing f-divergence allows the model to more precisely capture the boundaries of structurally similar regions. This results in further gains in DC and JC metrics, along with substantial reductions in HD and ASD, thereby indicating improved accuracy in segmentation, especially along edge details.\nf-Divergence strategies. Based on the experimental results shown in the Table 5, different f-divergence strategies demonstrate varying degrees of effectiveness for optic cup and disc segmentation across four domains in the Fundus dataset. Generally, the JS divergence and Jeffrey divergence strategies perform well, often yielding higher DC and JC while reducing HD and ASD. Specifically, JS divergence tends to provide more consistent results in edge cases, as evidenced by lower HD and ASD values, while also achieving competitive segmentation accuracy. Pearson divergence, on the other hand, exhibits a balanced performance, particularly excelling as the second-best in some metrics."}, {"title": "4.5. Visualization Analysis", "content": "T-SNE visualization. We adopt the T-SNE visualization method, which graphically represents the learning representation obtained from our method, as shown in Figure. 1(a) and 1(b). DiM significantly improves the feature alignment between different domains compared to MiDSS, resulting in a tighter and more coherent data distribution.\nSegmentation visualization. As shown in Figure 2, DiM achieves higher accuracy and better preservation of edge details in optic disc and cup segmentation tasks compared to other methods. Models such as U-Net, UA-MT, and SS-Net show noticeable boundary blurring, with segmentation results that lack precision, particularly at the structural boundaries of the optic disc and cup. These models tend to either miss segments or over-segment certain regions. In contrast, our model produces clearer boundaries with more precise edge detail retention, and the segmentation within the optic disc and cup regions is more cohesive, closely matching the ground truth (GT).\nWe also conducted visualization experiments on the prostate segmentation task in Figure 3. Results indicate that DiM continues to outperform other methods, such as BCP, CauSSL, and MiDSS, by achieving clearer boundary delineation and better edge detail preservation. The segmentation closely matches the GT, demonstrating improved accuracy and cohesion within the prostate region, even in challenging boundary areas.\nModel Performance. The validation loss and Dice coefficient curves across the four domains on the Fundus dataset demonstrate stable model performance, which are depicted in Figure 5. Loss decreases rapidly in the early epochs and converges across all domains, indicating effective training. Dice scores for both the optic cup and disc steadily increase and plateau at high values, with the optic disc achieving near-perfect accuracy."}, {"title": "5. Conclusion", "content": "This study addresses the challenge of data annotation in medical image segmentation by introducing a sharpness-aware optimization method based on f-divergence minimization (DiM) for semi-supervised learning. While existing semi-supervised methods (SSMIS), including sharpness-aware optimization (SAM), have shown success, they often overlook distribution differences between datasets. The proposed DiM method enhances model stability by adjusting the sensitivity of model parameters and improves adaptability to varying datasets. By reducing f-divergence, DiM achieves a better balance in performance between source and target datasets and mitigates overfitting. Experimental results demonstrate that DiM significantly improves performance, as evidenced by its groundbreaking progress in Dice scores on the prostate dataset, with similar success across three public datasets."}]}