{"title": "Enhancing Distribution and Label Consistency for Graph Out-of-Distribution Generalization", "authors": ["Song Wang", "Xiaodong Yang", "Rashidul Islam", "Huiyuan Chen", "Minghua Xu", "Jundong Li", "Yiwei Cai"], "abstract": "To deal with distribution shifts in graph data, various graph out-of-distribution (OOD) generalization techniques have been recently proposed. These methods often employ a two-step strategy that first creates augmented environments and subsequently identifies invariant subgraphs to improve generalizability. Nevertheless, this approach could be suboptimal from the perspective of consistency. First, the process of augmenting environments by altering the graphs while preserving labels may lead to graphs that are not realistic or meaningfully related to the origin distribution, thus lacking distribution consistency. Second, the extracted subgraphs are obtained from directly modifying graphs, and may not necessarily maintain a consistent predictive relationship with their labels, thereby impacting label consistency. In response to these challenges, we introduce an innovative approach that aims to enhance these two types of consistency for graph OOD generalization. We propose a modifier to obtain both augmented and invariant graphs in a unified manner. With the augmented graphs, we enrich the training data without compromising the integrity of label-graph relationships. The label consistency enhancement in our framework further preserves the supervision information in the invariant graph. We conduct extensive experiments on real-world datasets to demonstrate the superiority of our framework over other state-of-the-art baselines.", "sections": [{"title": "I. INTRODUCTION", "content": "Graph data is prevalent in various applications, such as molecular property predictions and financial analysis [1], [2], [3], [4], [5], [6]. Recently, techniques in graph machine learning have significantly advanced. For example, Graph Neural Networks (GNNs) have been developed to effectively handle graph data [7], [8], [9]. GNNs learn representations of individual nodes by aggregating information from their neighboring nodes [10], [11], [12], [13]. Despite the notable success of graph machine learning, a significant challenge remains. GNNs typically assume that the training data follows the same distribution as the test data. However, this assumption often does not hold true in real-world scenarios [14], [15], [16], [17]. Consequently, when the test data distribution differs significantly, the performance of GNNs trained on the training data deteriorates. This issue is commonly referred to as distribution shift [18], [19], [20].\nAlthough numerous solutions to distribution shifts have been proposed for Euclidean data (e.g., images) [21], [22], [23], [24], [25], [26], these techniques are challenging to apply to graphs due to their complex node connections [27], [28], [29]. To address distribution shifts in graphs, recent methods have proposed generating augmented environments through data augmentation [30], [31]. By training on this augmented data, GNNs can learn the decisive information for classification while ignoring the spurious information of each environment, thereby achieving the robustness necessary to perform well on test data [32], [33].\nHowever, such a strategy can be suboptimal, facing two crucial challenges: \u25cf Distribution Consistency: When generating augmented environments, the graphs are obtained via modification, which might diverge significantly from real-world examples. For example, in molecular property prediction, minor alterations to molecular structures can result in significant changes in chemical properties, thus disrupting the distribution consistency of augmented graphs [34]. This inconsistency arises because the augmented graphs may not accurately reflect realistic or probable molecular configurations. \u25cf Label Consistency: The process of extracting invariant subgraphs, without careful consideration of how these changes impact label relevance, risks impairing the learned relationship between graph structures and labels. This is because the identified invariant subgraphs may not accurately reflect the labels they should belong to, which diminishes the preserved supervision information.\nTo deal with these challenges, we propose a novel framework named DLG, which aims to enhance Distribution- and Label-consistency for Graph OOD generalization. Specifically, we design a novel graph modifier to produce both augmented and invariant graphs by sampling edges from the learned edge masks. Using such a strategy enables us to unify the processes of augmenting existing graphs and extracting invariant graphs by formulating them both as modifications, in order to enhance consistency from perspectives of distributions and labels. \u25cf Distribution Consistency Enhancement. To obtain augmented graphs during training while preserving distribution consistency, we propose to maximize the information between augmented graphs and existing graphs. In this manner, we could ensure the augmented graphs are informative and align with existing graphs to preserve distribution consistency. \u25cf Label Consistency Enhancement. To ensure the generated invariant graphs remain consistent across different domains regarding their labels, we explicitly enhance label consistency by ensuring that the extracted invariant subgraphs share maximal supervision information with the original graph G. In summary, our contributions are as follows:\n* Investigation. We investigate the challenges of invariant"}, {"title": "III. PROBLEM FORMULATION", "content": "We first denote the set of training graphs as $\\mathcal{D}_{tr} = \\{(G_i, Y_i) | i \\in [1, |\\mathcal{D}_{tr}|]\\}$. Here $G \\in \\mathcal{G}$ and $Y \\in \\mathcal{Y}$ are graph samples and their labels. We further denote each graph as $G = (A, X)$, where $A \\in \\mathbb{R}^{N \\times N}$ and $X \\in \\mathbb{R}^{N \\times d_X}$ represents the adjacency matrix and feature matrix, respectively. Here $N$ is the number of nodes in $G$, and the $j$-th row vector of $X$ is the $d_X$-dimensional attributes of the $j$-th node. Following existing works [48], [47], [34], the goal of OOD graph generalization is to learn a classification function $f_c(\\cdot): \\mathcal{G} \\rightarrow \\mathcal{Y}$ that takes a graph as input and predicts its label $Y$. The ultimate goal of OOD graph generalization is to learn the optimal classification function $f^*$ that could precisely predict the labels of graphs in the test set, i.e., $\\mathcal{D}_{te} = \\{(G, Y^*) | i \\in [1, |\\mathcal{D}_{te}|]\\}$"}, {"title": "IV. METHODOLOGY", "content": "We elaborate on our framework DLG for graph OOD generalization problem via enhancing distribution and label consistency. As illustrated in Fig. 1, our framework leverages a classifier $f_c(\\cdot)$ and two graph modifiers $g_v(\\cdot)$ and $g_a(\\cdot)$, which generate augmented and invariant graphs, respectively. The encoder and modifiers are optimized based on our designed objectives for the two types of consistency. Note that our modifier only considers the edges in each graph, i.e., only modifying the adjacency matrix. That being said, we could potentially create edges that do not exist in the original graph.\nModification\nConsidering an input graph $G = (A, X)$ from the training dataset $\\mathcal{D}_{tr}$, we first aim to learn its invariant graph $G_v = (A_v, X_v)$ that preserves label consistency for classification. Additionally, during training, we also generate an augmented graph $G_a = (A_a, X_a)$ that preserves distribution consistency. The augmented graph $G_a$ is also classified by the classifier $f_c(\\cdot)$ with the same label as $G$.\nIn the following, we describe the process of obtaining the invariant graph $G_v$ and the augmented graph $G_a$ in detail. Particularly, we first learn the representations for modification:\n$H_v = GNN_v(A, X)$ and $H_a = GNN_a(A, X + Y)$.\nHere $GNN_v$ and $GNN_a$ are two GNNs used in $g_v(\\cdot)$ and $g_a(\\cdot)$, respectively. $H_v$ (or $H_a$) represents the learned embedding matrix of $G_v$ (or $G_a$). Notably, for the input to $GNN_a$, we additionally incorporate the information from label $Y$ of $G$. This is because the augmented graphs are only used during training, which means its label information is always available. Moreover, with label information added, it also benefits our label consistency enhancement when used for training, as introduced in the following section. During the inference stage, the label information is unavailable, and thus we do not incorporate label $Y$ in $g_v(\\cdot)$.\nWith the learned representations, we illustrate the detailed process of modification. As the process applies to both invariant and augmented graphs, here we use $H$ for simplicity. Particularly, given $H$, our target is to learn from edge masks $\\{e_{i,j} | i, j = 1, 2, ..., N\\}$. Here each mask is in $[0, 1]$, denoting the sampling probability of a specific edge. In general, a larger mask leads to a higher sampling probability, indicating that the edge is more likely to appear in the invariant graphs or augmented graphs.\nTo learn the edge masks, we apply a Multi-Layer Perceptron (MLP) and calculate the dot product:\n$e_{i,j} = \\text{Sigmoid} \\Big((MLP(h_i))^T \\cdot MLP(h_j)\\Big),$\nwhere $h_i$ denotes the representation of the $i$-th node, i.e., the $i$-th row vector in $H$. With the learned masks, we could perform sampling for edges. Nevertheless, such a sampling"}, {"title": "B. Distribution Consistency Enhancement", "content": "Although we generate augmented graphs to expand the training data distribution, the strategy cannot guarantee that the generated graphs preserve consistency with existing graphs. In other words, the generated graphs may largely deviate from the distribution of existing data. Moreover, the labels of augmented graphs may also be different from the graph before augmentation.\nTo deal with this, we propose to maximize the mutual information between augmented graphs $G_a$ and other existing graphs with the same label. Specifically, we first randomly sample a batch of graphs from all training data as the support set $S = \\{G_i | i = 1, 2, ..., C\\}$, containing one graph for each class. Here $C$ is the number of classes. Moreover, the label of $G_i$ is $y_i$, i.e., the $i$-th label in the label space $\\mathcal{Y}$. In this manner, the objective of maximizing the mutual information between $G_a$ and $S$ can be represented as follows:\n$\\underset{i=1}{\\text{max}} I(G_a; S) = \\underset{i=1}{\\text{max}} \\sum_{i=1}^C p(G_a, G_i) \\text{log} \\frac{p(G_a, G_i)}{p(G_a)p(G_i)}$.\nSince the mutual information $I(G_a; S)$ is intractable and thus infeasible to maximize [53], we transform the objective into a more accessible form:\n$I(G_a; S) = \\sum_{i=1}^C p(G_i) \\sum_{i=1}^C p(G_a | G_i) \\text{log} \\frac{p(G_i | G_a)}{p(G_i)}$,\nThis form is easier to optimize as it contains the term $p(G_i)$. As we randomly sample $G_i$ from each class, we assume that the prior probability, i.e., $p(G_i)$, follows a uniform distribution and set it $p(G_i) = 1/C$. According to Bayes\u2019 theorem, the objective then becomes:\n$I(G_a; S) = \\sum_{i=1}^C p(G_a | G_i) \\text{log} \\frac{p(G_i|G_a)}{\\frac{1}{C}} = \\sum_{i=1}^C p(G_a | G_i) \\Big(\\text{log} \\frac{p(G_i|G_a)}{}- \\text{log} \\frac{1}{C}\\Big)$.\nTo achieve the value of $p(G_a | G_i)$, we estimate it as $p(G_a | G_i) = \\mathbb{1}(Y = y_i)$, where $Y$ and $y_i$ are the labels of $G$ and $G_i$, respectively. Here $\\mathbb{1}(Y = y_i) = 1$ if $G$ and $G_i$ share the same label; otherwise $\\mathbb{1}(Y = y_i) = 0$. In this manner, considering that $\\text{log}(1/C)$ is a constant, the above objective can be further simplified as follows:\n$\\text{max} I(G_a; S) = \\text{max} \\sum_{i=1}^C \\mathbb{1}(Y = y_i) \\text{log } p(G_i | G_a)$.\nTo further estimate $\\text{log } p(G_i | G_a)$, we can define the probability of $G_i$ sharing the same label as $G$ (i.e., $y_i = Y$) according to the squared $l_2$ norm of the embedding distance. Specifically, we first apply the same $GNN_a$ on $G_i$ to obtain its representation:\n$h_i = \\frac{1}{\\sqrt{V_i}} \\sum_{j=1}^{V_i} H_i(j), \\text{ where } H_i = GNN_a(A_i, X_i \\oplus y_i)$,\nwhere $A_i$ and $X_i$ are adjacency matrix and feature matrix of $G_i$, respectively. $y_i$ is the corresponding one-hot vector of the label of $G_i$. Based on the representation, the term $p(G_i | G_a)$ can be formulated as below, after normalization with a softmax function:\n$p(G_i | G_a) = \\frac{\\text{exp} \\Big( - ||h_a - h_i||^2 \\Big)}{\\sum_{j=1}^C \\text{exp} \\Big( - ||h_a - h_j||^2 \\Big)}$,\nwhere $h_a$ and $h_i$ are graph-level representations of $G$ and $G_i$, respectively. Note that as $G_a$ is generated from $G$, here we use the graph representation of $G_a$ as $h_a$ to obtain the objective. If we further apply the $l_2$ normalization to both $h_a$ and $h_i$, we obtain $||h_a - h_i||^2 = 2 - 2 h_a \\cdot h_i$. Additionally, to enhance diversity, we still need to ensure the obtained $G_a$ is"}, {"title": "C. Label Consistency Enhancement", "content": "As our goal for the extracted invariant graph is to ensure label consistency, we strive to preserve as much useful in-formation from the original graph $G$ as possible. Therefore, we formulate our objective as maximizing the conditional likelihood of $P(G_v | G, Y)$, representing the probability of the generated consistent graph $G_v$ conditioned given the origi-nal graph $G$. That being said, we aim to ensure that the generated $G_v$ share maximal supervision information with $G$ while ignoring unrelated information. Therefore, we obtain the classification losses: $q_v = f(G_v)$, $q_a = f(G_a)$, and\n$L_c = - \\sum_{i=1}^C \\Big(\\mathbb{1}(Y = y_i) \\text{log}(q_v(i)) + q_v(i) \\text{log}(q_a(i)) \\Big)$,\nwhere $q_v \\in \\mathbb{R}^C$ (or $q_a \\in \\mathbb{R}^C$) is the probability that $G_v$ (or $G_a$) belongs to each class in the label space $\\mathcal{Y}$, and $C$ is the number of classes. Moreover, $q_v(i)$ (or $q_a(i)$) is the $i$-th element in $q_v$ (or $q_a$). Here $\\mathbb{1}(Y = y_i) = 1$ if the label $Y$ of $G$ is $y_i$; otherwise $\\mathbb{1}(Y = y_i) = 0$. In this way, we enforce the class probability distributions of $G_v$ and $G_a$ to be close to each other while utilizing label information of $G$.\nOptimization\nIn this subsection, we introduce the detailed optimization steps of DLG. As described in Sec. IV-C and Sec. IV-B, we propose two losses to optimize our framework, i.e., $L_a$ and $L_c$. However, directly applying all two losses can be detrimental to the overall performance, as the modules in our framework maintain different objectives. Let us denote the parameters of $GNN_v$ and $GNN_a$ as $\\theta_v$ and $\\theta_a$, respectively. We apply both losses for optimization:\n$\\{\\theta^*_v, \\theta^*_a\\} = \\text{arg min} \\alpha L_a + (1 - \\alpha) L_c$,\nwhere $\\theta^*_v$ and $\\theta^*_a$ are the optimal parameters for $GNN_v$ and $GNN_a$, respectively. $\\alpha \\in [0, 1]$ is a hyper-parameter that controls the importance of $L_a$.\nMoreover, as the classifier is only involved in the classification loss, we optimize it with $L_c$:\n$\\theta^*_f = \\text{arg min} L_c$,"}, {"title": "V. EXPERIMENTS", "content": "In this section, we evaluate our framework DLG on a variety of synthetic and real-world graph datasets for out-of-distribution generalization.\nDatasets and Settings\nGraph-Level OOD Datasets. For experiments, we utilize a combination of synthetic and real datasets for OOD generalization on graph classification tasks. Specifically, we first consider graph-level datasets used in GALA [50]. The included datasets are as follows: \u25cf TPG (Two-Piece Graph) datasets constructed based on the BA-2motifs [54], resulting in four variants of 3-class two-piece graph datasets. Each variant is controlled by a hyperparameter that adjusts the correlations between the label and the spurious information in the graph, ranging from +0.2 to -0.2. Six Datasets from the DrugOOD benchmark [55], which is centered on the challenging real-world task of AI-aided drug affinity prediction. The DrugOOD datasets include splits based on Assay, Scaffold, and Size from two categories: EC50 (denoted as EC50-) and Ki (denoted as Ki-). These datasets provide a diverse range of scenarios to evaluate the effectiveness of various methods in predicting drug affinities across different biological and chemical contexts. We further consider four graph-level datasets used in DIR [34]: \u25cf SP-Motif [56] is a synthetic dataset, in which the degree of bias can be manually controlled. Each graph consists of a base and a motif (with structures from Cycle, House, and Crane). The label is entirely decided by the structure of the motif in each graph. We consider the average results of four bias degrees: 1/3, 0.5, 0.7, and 0.9. \u25cf OMNIST-75sp [57] is converted from the MNIST image dataset, and random noises are added to create distribution shifts. There exist 10 labels in the dataset. Moreover, the node features contain random noises in the test set. \u25cf Molhiv (OGBG-Molhiv) [58], [59], [60] is a molecular property prediction dataset, and the distribution shift is based on different structures of molecules. \u25cf Graph-SST2 contains graphs constructed from sentimental sentences, and the distribution shift originates from different partitions of graphs. Note that due to the different properties of graph structures in these datasets, we follow DIR [34] to use different GNN backbones for various datasets. Among these four datasets, the SP-Motif dataset is synthetic, while the other three datasets are obtained from real-world data. Our code is provided at https://github.com/SongW-SW/DLG.\nBaselines. To evaluate our proposed framework DLG while comparing other state-of-the-art methods, we consider the following baselines: \u25cf OOD methods proposed for Euclidean data (e.g. images), which include IRM [35] and V-REx [30]. \u25cf OOD methods proposed for graph data, which include DIR [34], GIL [47], CIGA [48], and GALA [50]."}, {"title": "VI. CONCLUSION", "content": "In this work, we have investigated the problem of graph out-of-distribution (OOD) generalization on both graph classification and node classification. We demonstrate that the two traditional steps: augmentations and invariant subgraph extraction, may fail to achieve distribution consistency and label consistency, respectively. To deal with this, we propose a novel framework DLG to enhance these two types of consistency. Based on learning edge masks with our designed modifiers, we are able to preserve the consistency in augmented graphs and invariant graphs. We conduct extensive experiments on a variety of both graph-level and node-level OOD generalization datasets. The results demonstrate that our framework DLG consistently outperforms other state-of-the-art graph OOD generalization methods."}]}