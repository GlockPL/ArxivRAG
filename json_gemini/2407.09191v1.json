{"title": "From Easy to Hard: Learning Curricular Shape-aware Features for Robust Panoptic Scene Graph Generation", "authors": ["Hanrong Shi", "Lin Li", "Jun Xiao", "Yueting Zhuang", "Long Chen"], "abstract": "Panoptic Scene Graph Generation (PSG) aims to generate a comprehensive graph-structure representation based on panoptic segmentation masks. Despite remarkable progress in PSG, almost all existing methods neglect the importance of shape-aware features, which inherently focus on the contours and boundaries of objects. To bridge this gap, we propose a model-agnostic Curricular shApe-aware FEature (CAFE) learning strategy for PSG. Specifically, we incorporate shape-aware features (i.e., mask features and boundary features) into PSG, moving beyond reliance solely on bbox features. Furthermore, drawing inspiration from human cognition, we propose to integrate shape-aware features in an easy-to-hard manner. To achieve this, we categorize the predicates into three groups based on cognition learning difficulty and correspondingly divide the training process into three stages. Each stage utilizes a specialized relation classifier to distinguish specific groups of predicates. As the learning difficulty of predicates increases, these classifiers are equipped with features of ascending complexity. We also incorporate knowledge distillation to retain knowledge acquired in earlier stages. Due to its model-agnostic nature, CAFE can be seamlessly incorporated into any PSG model. Extensive experiments and ablations on two PSG tasks under both robust and zero-shot PSG have attested to the superiority and robustness of our proposed CAFE, which outperforms existing state-of-the-art methods by a large margin.", "sections": [{"title": "1 Introduction", "content": "Scene Graph Generation (SGG) [59, 8] is a fundamental scene understanding task [75, 28, 50, 7] that surpasses mere object classification and localization by predicting relations between objects in a scene [73, 68, 30, 65]. However, due to its reliance on the bounding box-based paradigm, traditional SGG suffers from inaccurate object localization and limited background annotation. To address these issues, a novel variant of SGG called Panoptic Scene Graph Generation (PSG) [62] has emerged. As shown in Fig. 1, PSG leverages more fine-grained scene mask representations (i.e., panoptic segmentation) and defines relations for background stuff (e.g., playingfiled), thus providing a more precise and comprehensive understanding of the scene [33, 5, 40].\nAlthough PSG has made notable progress [62, 31, 76], almost all existing approaches draw inspiration from the strategies established in SGG [74, 6, 29, 38]. Unfortunately, almost all existing approaches overlook the importance of Shape-aware Features, which inherently concentrate more on the contours and boundaries of objects. To be more specific, state-of-the-art PSG methods just replace object features with better representations from panoptic segmentors, and they all still utilize spatial features derived from the minimum bounding boxes (bbox) of these masks, neglecting the critical shape-aware features. This limitation can hinder a holistic grasp of the scene, potentially resulting in semantic confusion in fine-grained visual relation prediction.\nTake person-playingfiled in Fig. 2(b) as an example, the similarity in their bbox-based spatial features can easily lead to confusion between relations like walking on and running on.\nTo this end, we argue that it is essential to incorporate shape-aware features into PSG rather than relying solely on spatial features based on bboxes. By \u201cshape-aware features\u201d, we mainly mean two types of features: 1) Mask Features: These features exploit the details encompassed in fine-grained mask representations, including the shape and contour of the objects. This inclusion captures a wealth of visual intricacies that significantly enhance the accuracy of relation prediction. As shown in Fig. 2(b), for predicates representing actions like walking on, there is a commonality in the shape and contour of the subject (e.g., person). In such scenarios, by using mask features, even when faced with identical subject-object pairs (e.g., person-playingfiled), the model can still alleviate semantic confusion and disambiguate relationships (e.g., running on and standing on). 2) Boundary Features: These features are extracted from the intersection of subject and object masks, which provide unique advantages in cases of interaction and contact between subject-object pairs. When dealing with predicates like enclosing (cf., Fig. 2(c)), the mask features of separate subjects (e.g., tree) or objects (e.g., horse) display a range of diversity. This diversity can result in semantic confusion, rendering the use of mask features alone inadequate for making accurate predictions. However, there is a notable resemblance (e.g., encirclement) between tree-horse and tree-giraffe. Thus, the incorporation of boundary features that represent the intersection of subject-object pairs can aid in enhancing prediction accuracy.\nDrawing inspiration from cognitive psychology research [48] that indicates humans tend to learn concepts progressively, starting from easier concepts and gradually advancing to comprehend harder ones, we propose to integrate shape-aware features in an easy-to-hard manner. Specifically, as the difficulty of learning predicates increases, we progressively enhance the complexity of features. For example, certain simple positional relations like over (cf., Fig. 2(a)) can be accurately predicted using traditional bbox features alone. For more complex relations like walking on (cf., Fig. 2(b)), relying solely on bbox features can lead to semantic confusion, while incorporating mask features can help disambiguate the relationships. When facing more challenging predicates like enclosing (cf., Fig. 2(c)), accurate predictions heavily rely on the effective utilization of boundary features, which capture the interaction between subject-object pairs.\nIn this paper, we propose a novel Curricular shApe-aware FEature (CAFE) learning strategy for PSG. CAFE is a model-agnostic strategy which skillfully weaves into the training process via a curriculum learning strategy. Specifically, we first categorize the predicates into three groups based on cognitive difficulty, i.e., predicate distribution and semantic diversity. Then, we divide the training process into three stages, with each stage utilizing its own relation classifier. These classifiers are tailored to handle predicates with increasing learning difficulties and are equipped with corresponding sets of features of ascending complexity (i.e., bbox features, mask features, and boundary features). We also incorporate knowledge distillation [35, 36] to retain knowledge acquired in earlier stages.\nWe conducted comprehensive experiments on the challenging PSG dataset [62], exploring both robust PSG and"}, {"title": "2 Related Work", "content": "Panoptic Scene Graph Generation (PSG). PSG aims to transform an image into a structured graph representation, formulated as a series of visual relation triplets. Contrary to SGG [23, 46, 66, 45], PSG not only employs a more fine-grained scene representation but also addresses the challenge of missing background context. Existing PSG models can be divided into two groups: 1) Two-stage PSG: They first utilize a pretrained panoptic segmentation model (e.g., Panoptic FPN [24] or Panoptic Segformer [41]) to generate masks and then predict the classes of objects and their pairwise relations [31, 21]. This paradigm allows classic SGG models [59, 43, 37] to be adapted with minimal modifications. 2) One-stage PSG: These models construct an end-to-end model to detect the objects and relations from image features directly [62, 76, 56]. In this paper, we build upon two-stage baselines and propose a model-agnostic approach that can be incorporated into any PSG model.\nShape-Aware Features for Vision Tasks. Shape-aware features are a type of visual information representation that place a stronger emphasis on the shape of objects within an image, which benefits various vision tasks [53, 2, 13, 22]. Among these features, boundary-aware features play a pivotal role in enhancing the understanding of object boundaries. For example, in semantic segmentation tasks [72], several methods have been proposed to incorporate boundary-aware information, including feature propagation [10], geometric encoding [14], and graph convolution [19]. Unlike these methods, we are the first approach that leverages shape-aware features to represent interaction information between objects, enhancing relation prediction.\nCurriculum Learning (CL). Curriculum learning [1, 20, 57] is a training strategy that trains the model from easier data to harder data, which mimics the human recognition process [49, 15, 67]. It has been demonstrated to significantly enhance performance across a variety of machine"}, {"title": "3 Approach", "content": "Problem Formulation. PSG task aims to generate a panoptic scene graph G for a given image $I \\in \\mathbb{R}^{H\\times W\\times 3}$. The scene graph consists of a set of nodes N and a set of edges E, denoted as $G = \\{N = \\{o_i; m_i\\}; E = \\{r_{ij}\\}\\}$. Each object\u00b9 is represented by a binary mask $m_i \\in M$ associated with an object category $o_i \\in O$. The relation category between the i-th and j-th objects is denoted by $r_{ij} \\in R$. M, O, and R represent the sets of all object masks, object categories, and relation categories, respectively. Besides, the binary masks $m_i \\in \\{0,1\\}^{H\\times W}$ do not overlap, i.e., $\\sum_{i=1}^{n} m_i < 1^{H\\times W}$. Hence, the PSG task models the following distribution:\n$P(G|I) = P(M, O, R|I)$.\n3.1 Overview: Two-Stage PSG Approach\nSimilar to SGG, PSG has two-stage and one-stage baselines. In this paper, we build upon the two-stage framework and propose a model-agnostic approach to enhance the performance. A typical two-stage PSG model involves three steps: mask generation, object classification, and relation classification. Thus, the PSG task P(G|I) is decomposed into:\n$P(G|I) = P(M|I) \\cdot P(O|M,I) \\cdot P(R|O, M, I)$.\nMask Generation $P(M|I)$. This step aims to segment an image into a set of masks M with panoptic segmentation.\nObject Classification $P(O|M,I)$. This step predicts the object category of each $m_i \\in M$. It consists of an object context encoder $Enc_{obj}$ to extract the object feature $F_i$ and an object classifier $Cls_{obj}$ to predict the object categories $o_i$.\nRelation Classification $P(R|O, M, I)$. This step predicts the relation of every two masks in M along with their object categories in O. It comprises a relation context encoder $Enc_{rel}$ and a relation classifier $Cls_{rel}$. The former performs context modeling to extract refined object features $F_i$ for"}, {"title": "4 Experiments", "content": "4.1 Experimental Settings\nDatasets. We conducted experiments on the challenging Panoptic Scene Graph Generation (PSG) dataset [62], which contains 48,749 images with 133 object classes (80 thing and 53 stuff classes) and 56 relation classes. Each image is annotated with panoptic segmentation and scene graphs. Our data processing pipelines closely align with [62].\nTasks. Follow [62], we evaluated the model on two tasks: 1) Predicate Classification (PredCls): Given all ground-truth object labels and localizations, we need to predict pairwise predicate categories. 2) Scene Graph Generation (SGDet): Given an image, we need to detect all objects and predict both the object categories and their pairwise predicates.\nMetrics. For robust PSG, we evaluated the model on three classic metrics: 1) Recall@K (R@K): It calculates the proportion of ground-truths that appear among the top-K confident predicted relation triplets. Following prior work, we used K = {20, 50, 100}. 2) mean Recall@K (mR@K): It is the average of R@K scores that are calculated for each predicate category separately, i.e., it puts relatively more emphasis on the tail predicates. 3) Mean: It is the average of all R@K and mR@K scores. Since R@K favors head predicates and mR@K favors tail predicates, Mean is a comprehensive metric that can better evaluate the overall performance [29]. For zero-shot PSG, we adopted two metrics: 1) Zero-Shot Recall@K (zR@K): It only calculates the R@K for subject-predicate-object triplets that have not occurred in the training set, offering a focused measure of the generalization ability to novel instances [44]. 2) Average: It calculates the average value of all zR@K scores, which is a comprehensive metric to assess the zero-shot learning ability. In"}, {"title": "5 Conclusion and Future Work", "content": "In this paper, we revealed the drawbacks of relying solely on spatial features based on bboxes and discovered that the key to PSG task lies in the integration of shape-aware features. Thus, we proposed a model-agnostic CAFE framework that integrates shape-aware features in an easy-to-hard manner. Specifically, our approach deployed three classifiers, each specialized to handle predicates with increasing learning difficulties and equipped with corresponding sets of features of ascending complexity. Comprehensive experiments on the challenging PSG dataset showed that CAFE significantly improves the performance of both robust PSG and zero-shot PSG. In the future, we would like to extend CAFE to panoptic video scene graph generation task to construct comprehensive real-world visual perception systems.\nData Availability All experiments are conducted on publicly available datasets; see the references cited."}, {"title": "Appendix", "content": "This appendix is organized as follows:\nDetailed performance comparison analyses are presented in\nSec. A.\nStatistics of computation cost and parameters are provided in\nSec. B.\nLimitation is discussed in Sec. C.\nA Detailed Performance Comparison Analyses\nA.1 Performance of Each Component of CAFE\nTo better illustrate the reasons behind performance improvements,\nwe visualized the performance of each component within the CAFE\nmodel, under the Motifs [69] in the PredCls setting in Fig. 11. The met-\nrics used for performance comparison are R@50/100 and mR@50/100,\nwhile the orange line represents the Mean metric across different con-\nfigurations. For conciseness, we denote \"CAFE w/o CL\" to indicate\nthe model variant that solely employs the resampling strategy, and\n\"CAFE w/o Resample\" for the variant that exclusively uses curriculum\nlearning. The features utilized by each CAFE component are specified\nwithin the parentheses.\nAs shown in Fig. 11, we can have the following observations:\nThe significance of predicate resampling strategy. In scenarios\nwhere shape-aware features are absent (i.e., only using bbox fea-\nture), the resampling strategy exhibits performance degradation on\nthe head predicates (i.e., R@K), while yielding a slight improve-\nment on the tail predicates (i.e., mR@K). This occurs because the re-\nsampling strategy aims to mitigate the extreme dataset imbalance by\nundersampling the head predicates and oversampling the tail pred-\nicates. The bbox feature's strength in identifying simple positional\nrelations, primarily in head predicates, results in a marked decline\nin the R@K metric. However, the introduction of shape-aware fea-\ntures (i.e., mask and boundary features) turns the resampling strat-\negy into a positive force for performance enhancement, achieving a\nhigher Mean metric than the baseline. Crucially, when these three\nfeatures are incorporated into the model training via a curriculum\nlearning approach, the resampling strategy manifests a significant\nadvantage. This is attributed to shape-aware features' ability to cap-\nture the shape of objects and the interaction information between\nobject pairs, thereby effectively aiding in relation prediction. More-\nover, balanced data can effectively prevent biased predictions and\nenhance the overall performance. We also conducted ablations on\npredicate sampling strategies in Table 9.\nThe importance of curricular feature training. Curricular feature\ntraining constitutes a pivotal innovation in CAFE, playing a crucial\nrole in enhancing model performance (e.g., higher Mean). Taking\nthe use of a single feature as an example, the integration of the cur-\nriculum learning approach significantly improves the model's ability\nto predict tail predicates (e.g., higher mR@K). This improvement\nstems from the introduction of cognition-based predicate grouping\nand the division of the training process into three distinct stages. The\nformer segregates predicates with semantic similarity into different\ngroups, effectively mitigating semantic confusion within the relation\nclassifier. The latter assigns a dedicated relation classifier to each\nstage and configures the classification space, ensuring that each clas-\nsifier demonstrates strong discriminative abilities. Moreover, since\nour curriculum feature training incorporates knowledge distillation\nto preserve knowledge acquired in earlier stages, it can maintain the\nperformance of head predicates (e.g., competitive R@K). We also\nperformed detailed analyses through ablation studies on curriculum\nlearning in Table 7.\nThe combination of shape-aware features. The integration of\nshape-aware features into PSG marks a notable advancement, as we\nnot only pinpoint a crucial flaw in current PSG research (i.e., over-\nreliance on tight bounding boxes), but also offer a novel perspective\non addressing segmentation challenges. Given that CAFE comprises\na training process with three stages, each tailored to a specific set of\nfeatures, the combination of these features is crucial for the model's\nperformance. Firstly, the combination of any two features generally\nshows superior performance compared to using each feature on its\nown, which indicates a synergistic effect between the features. Sec-\nondly, incrementally adding complexity to the features leads to a\ngradual improvement in the Mean metric. Lastly, integrating all fea-\ntures culminates in achieving the best mR@K and the highest Mean\nscore. This occurs because CAFE structures its training process in\nphases, progressively increasing the complexity of features in ac-\ncordance with the rising difficulty of predicates. For instance, the\nboundary feature, capable of capturing interactions between object\npairs, is introduced in the third stage to better predict relations of\nhigher cognitive difficulty. Hence, by amalgamating all features, we\ncapitalize on the distinct advantages of each to predict predicates ac-\ncurately within their targeted groups, maximizing the performance\nto its fullest potential. Additionally, the ablation studies on different\nfeatures can be found in Table 5.\nA.2 Performance Comparison over All Predicates\nTo provide a more comprehensive illustration of model performance\nover all predicates, we presented recall statistics for each predicate\nusing CAFE and Motifs [69] under both the PredCls and SGDet set-\ntings, as depicted in Fig. 12 and Fig. 13. We divided predicates into\n\"Head\", \"Body\", and \"Tail\" groups based on the distribution in differ-\nent ground-truth annotations in the PSG dataset. Notably, our proposed\nCAFE model demonstrates a favorable balance across various predi-\ncate categories in both task scenarios. To delve into specifics, while a\nslight decrease is observed in the head group, CAFE exhibits notewor-\nthy enhancements in both the body and tail groups.\nA.3 Performance under Different Panoptic Segmentors\nTo demonstrate the influence of panoptic segmentors with varying\ncapabilities in generating panoptic segmentation masks, we adopted\nPanoptic FPN [24] and Panoptic Segformer [41] as panoptic segmen-\ntors. Subsequently, we compared performance of CAFE with VC-\nTree [51] and RCpsg [63] under the SGDet setting. As shown in Ta-\nble 12, we can observe that: 1) The performance of all three models is\ninfluenced by the accuracy of the panoptic segmentation masks. When\nthe quality of masks improves, the overall performance of the mod-\nels also improves. 2) Even when the panoptic segmentation masks are\nof low quality (e.g., Panoptic FPN), CAFE consistently produces su-\nperior performance compared to the baseline models, which indicates\nthat CAFE has a relatively low dependency on panoptic segmenta-\ntion masks. This is because the performance benefits of CAFE are not\nsolely derived from shape-aware features but are also influenced by\nthe resampling strategy and curricular training mode. 3) With the im-\nprovement in mask accuracy, CAFE demonstrates larger performance\ngains. This is attributed to the fact that when the quality of panop-\ntic segmentation masks improves, the extracted shape-aware features\nachieve higher precision. This enhancement enables the model to more\neffectively capture interactions between objects, thereby resulting in\nimproved performance.\nAdditionally, we also selected Mask2Former [9], which can gen-\nerate higher quality masks, as one of the panoptic segmentors. We\nconducted experiments under the SGDet setting across two baselines"}]}