{"title": "Brain-inspired Chaotic Graph Backpropagation for Large-scale Combinatorial Optimization", "authors": ["Peng Tao", "Kazuyuki Aihara", "Luonan Chen"], "abstract": "Graph neural networks (GNNs) with unsupervised learning can solve large-scale combinatorial optimization problems (COPs) with efficient time complexity, making them versatile for various applications. However, since this method maps the combinatorial optimization problem to the training process of a graph neural network, and the current mainstream backpropagation-based training algorithms are prone to fall into local minima, the optimization performance is still inferior to the current state-of-the-art (SOTA) COP methods. To address this issue, inspired by possibly chaotic dynamics of real brain learning, we introduce a chaotic training algorithm, i.e. chaotic graph backpropagation (CGBP), which introduces a local loss function in GNN that makes the training process not only chaotic but also highly efficient. Different from existing methods, we show that the global ergodicity and pseudo-randomness of such chaotic dynamics enable CGBP to learn each optimal GNN effectively and globally, thus solving the COP efficiently. We have applied CGBP to solve various COPs, such as the maximum independent set, maximum cut, and graph coloring. Results on several large-scale benchmark datasets showcase that CGBP can outperform not only existing GNN algorithms but also SOTA methods. In addition to solving large-scale COPs, CGBP as a universal learning algorithm for GNNs, i.e. as a plug-in unit, can be easily integrated into any existing method for improving the performance.", "sections": [{"title": "1 Introduction", "content": "The goal of combinatorial optimization problems (COPs) is to find the solution corresponding to the smallest objective function among a limited but often a large number of candidates, which is closely related to many hard problems in science and industry, such as logistics and transportation, circuit design and drug development. During the long research history of combinatorial optimization, many classical methods have been proposed, such as branch-and-bound and Tabu search methods, but with the advent of the era of big data, the scale of real-world COPs is often very large, and traditional methods usually have difficulty in obtaining high-quality feasible solutions in an acceptable time. Therefore, it is of great theoretical and practical importance to develop new generalized solution methods suitable for large-scale COPs.\nIn recent years, new combinatorial optimization algorithms different from traditional operations research-based methods have been developed. Among them, machine learning-based methods are currently a hot topic in research. This type of algorithm can be further divided into three subclasses based on the learning paradigm, namely supervised learning, reinforcement learning, and unsupervised learning. Early combinatorial optimization methods mainly used supervised learning, which minimizes some empirical loss functions to complete the complex, nonlinear mapping from the input representation of a problem to a target solution. For example, the classic Pointer network (Ptr-Net) uses a Seq2Seq model to generate variable-length permutation combinations and then solve the traveling salesman problem (TSP). However, the feasibility and performance of supervised learning-based methods largely depend on the availability of a large amount of pre-solved high-quality training data, which is often difficult to obtain. In contrast, reinforcement learning techniques aim to learn a policy that maximizes some expected reward function and can therefore bypass the need for training labels. Specifically, COPs can usually be described by an objective function, which can be used as the reward function in reinforcement learning. For instance, Bello et al. constructed an actor-critic model by combining a Ptr-Net-based decoder with a recurrent neural network (RNN) encoder and using the expected length of a tour as the reward signal, which served as an approximate solver for the TSP. Khali et al. further combined reinforcement learning and graph embedding to gradually construct feasible solutions through learning an efficient greedy meta-heuristic method, which achieves decent results in problems like minimum vertex cover (MVC), maximum cut (MC) and TSP. However, reinforcement learning-based methods often require manual modeling of the target problem, such as defining states and actions, which typically demands rich prior knowledge. Consequently, some works have attempted to use reinforcement learning to assist traditional combinatorial optimization methods. For instance, NeuroLKH uses reinforcement learning to assist the Lin-Kernighan-Helsgaun (LKH) algorithm in selecting candidate sets of edges, thereby improving the quality of the TSP solution. Nonetheless, strategies learned in this manner are difficult to extend from one COP class to another. To address the above issues, Schuetz et al. recently proposed a more general framework, called physics-inspired graph neural network (PI-GNN), which transforms combinatorial optimization problems into quadratic unconstrained binary optimization (QUBO) problems. The corresponding Hamiltonians of these problems are encoded as the loss functions of GNNs, and the GNNs are then trained in an unsupervised manner to obtain the solution to the corresponding COP. It should be noted that although PI-GNN has advantages such as high computational efficiency (as it can solve combinatorial optimization problems of up to one million variables) and strong scalability, the quality of its solutions is not superior to that of traditional state-of-the-art (SOTA) methods. The reason for this issue is that the solution of PI-GNN depends significantly on the performance of the GNN learning algorithm. Currently, GNN learning still uses gradient dynamics-based backpropagation (BP) algorithms and its variants, such as Adam, thus making GNN models prone to local minima, which limits the quality of the solution. Therefore, developing a new gradient-free dynamic universal GNN learning algorithm to overcome the local minima problem is of great importance for solving large-scale combinatorial optimization problems.\nOn the other hand, chaotic dynamics is one of the most important theoretical discoveries in natural sciences in the 20th century, which describes unpredictable global dynamics generated by deterministic systems. Specifically, chaotic dynamics is highly sensitive to initial conditions, and exhibits randomness and unpredictability in the long-term evolution. Yet since its dynamics is fundamentally deterministic, this randomness is known as pseudo-randomness. Moreover, theoretical studies have shown that chaos has global exploratory properties due to the ergodicity in a fractal space of a strange attractor. It is due to these dynamic properties that chaotic dynamics has been widely used to solve global optimization problems. In addition, chaotic dynamics has been observed in the heart, neurons, and even the brain, and it is very important for many biological processes, such as gene expression and regulation, signal processing, and sleep. Among them, Skarda and Freeman's experiments showed that the dynamics of the rabbit brain is chaotic at the resting state and works for learning new odor patterns. Matsumoto et al. found that squid giant axons show chaotic responses to periodic external stimulation. Moreover, recent experiments have also found that the neural networks of animal brains are in a critical or quasi-critical state between order and chaos. These studies imply a possibility that over long periods of evolution, animal brains have been able to use chaotic dynamics for cognition or learning. Therefore, is it possible to draw on the chaotic dynamics of the brain to establish a new, universal GNN learning theory and method?\nBased on the above motivation, we developed the chaotic graph backpropagation (CGBP) algorithm in this work (Fig. 1). By introducing a local loss function to simulate chaotic dynamics in the brain and utilizing its pseudo-randomness and global ergodicity, CGBP overcomes the drawbacks that existing BP-based GNN learning algorithms are prone to local minima, and achieves high-precision results in large-scale COPs, outperforming not only the existing GNN learning algorithms but also SOTA methods. In addition to solving COPs, CGBP can be used as a universal learning algorithm for training GNNs, i.e. it can be easily integrated into any existing method as a plug-in unit for improving the performance. From both computational and theoretical viewpoints, we can show that there is indeed chaotic dynamics in CGBP, i.e. Marotto chaos generated from a snapback repeller when hyperparameter z is sufficiently large. In the following, we will introduce the CGBP algorithm in detail and then compare it with existing SOTA methods on large-scale benchmark COP datasets."}, {"title": "2 Chaotic graph backpropagation", "content": null}, {"title": "2.1 Combinatorial optimization", "content": "Typical combinatorial optimization problems include TSP, MC, MVC, maximum independent set (MIS) and graph coloring (GC). Assuming that the number of variables in a combinatorial optimization problem (COP) is n, a feasible solution can be represented as a vector x = (x1,x2,\u2026, x\u2099). The objective of a COP is to find the feasible solution with the smallest objective function value.\nWhen the state of each variable is binary (x\u1d62 \u2208 {0,1}), many COPs can be represented under the QUBO framework, such as MIS and MC. At this time, the COP corresponds to the Ising model in physics, and its objective function is equivalent to the Hamiltonian of the Ising model, given by\n\n$H = x^T Q x = \\sum_{i,j} x_i Q_{ij} x_j,$\n\nwhere Q is a constant matrix encoding the COP. For example, for the MIS problem, the objective is to find a subset of nodes V\u209b \u2286 V from a given graph (denoted as G(V,E), where V and E are the sets of nodes and edges, respectively) such that the number of nodes in V\u209b is maximized under the premise that there is no edge between any two nodes in V\u209b, and the corresponding Hamiltonian is\n\n$H_{MIS} = -\\sum_{i \\in V} x_i + P \\sum_{(i, j)\\in E} x_i x_j,$\n\nwhere P is a penalty parameter, usually set to 2.\nWhen the number of the state is higher than 2, these COPs correspond to the Potts model (a generalization of the Ising model), and the form of its Hamiltonian is similar to that in Eq. (1). At this time, it is only necessary to perform one-hot encoding on the variable x\u1d62, and this will be further introduced in the Method section."}, {"title": "2.2 Graph neural networks", "content": "Graph neural networks (GNNs) are neural networks that can aggregate and represent information on graphs. Typically, a GNN layer consists of three functional units: message passing, aggregation and nonlinear activation. When multiple GNN layers are stacked, the feature information of nodes can be propagated along edges on the graph, and the greater the number of layers, the wider the range of information propagation. For example, the computation process of a graph convolutional network (GCN) can be represented by the following updating formula\n\n$h_i^{(l+1)} = \\sigma (\\sum_{j \\in N(i)} \\frac{1}{c_{ij}} W^{(l)} h_j^{(l)} + B^{(l)}),$\n\nwhere h\u1d62\u207d\u02e1\u207e represents the feature vector of the ith node in the Ith layer, W\u207d\u02e1\u207e and B\u207d\u02e1\u207e represent the weights and biases in the Ith layer, N(i) represents the set of neighbors of node i. c\u1d62\u2c7c is the production of the square root of the degree of node i and j, namely |N(i)|\u221a|N(j)|. \u03c3 represents a nonlinear activation function. In addition to GCN, commonly used GNN models include GraphSAGE and GAT. These models differ from GCN mainly in their information aggregation and feature updating methods, which will be further introduced in the Method section."}, {"title": "2.3 Solving combinatorial optimization problems with GNNs", "content": "In order to enable GNNs to solve COPs in an unsupervised manner, a recently proposed method, PI-GNN, transforms the Hamiltonian H of a COP into a differentiable loss function lossH (\u03b8). The key to this transformation is to replace the decision variable xi by pi(\u03b8), where \u03b8 represents all parameters in a GNN and pi(\u03b8)\u2208 [0,1] represents the final output of the GNN model on node i. Based on this transformation, the loss function of the network model can be defined as\n\n$loss_H(\\theta) = \\sum_{i,j} p_i(\\theta) Q_{ij} p_j(\\theta).$\n\nSpecifically, one can input randomly initialized embedding node features h\u1d62\u207d\u2070\u207e and train a GNN with the CGBP algorithm to obtain the final output pi(\u03b8). Then, a projection strategy can be used to map pi(\u03b8) to the decision variable xi, which generates the solution of the COP. The simplest projection strategy is to use a threshold of 0.5, where pi(\u03b8) above the threshold are set to 1 and values below the threshold are set to 0."}, {"title": "2.4 Chaotic graph backpropagation", "content": "Recently, we proposed a chaotic backpropagation (CBP) algorithm for multilayer perceptron (MLP), which introduces a loss function to simulate chaotic dynamics in the brain. Here, we use a similar strategy as CBP to construct the chaotic graph backpropagation (CGBP) algorithm. That is, an additional chaotic loss function lossc is added to the original loss function lossh, given by\n\n$lossc = -\\sum_{lj} z_{lj} (I_o ln(o_{dj}^{l}) + (1-I_o) ln(1-o_{dj}^{l})),$\n\nwhere zlj is the corresponding chaotic strength for odj off, Io is a constant between 0 and 1 (usually set to 0.65), odj is the jth element of off, the intermediate output of node d in the Ith layer. The mathematical expression of off for the GCN in Eq. (3) is given as follows:\n\n$o_{dj}^{l} = sigmoid (\\sum_{k \\in N(d)} \\frac{1}{c_{dk}} h_{ki}^{(l-1)} W_{ij}^{(l)} + B^{(l)} )$.\n\nIt should be noted that compared to the lossc introduced in CBP, the lossc in CGBP needs to consider not only the output of the neurons but also the selection of node d, because in GNN all nodes share the same parameters \u03b8, which makes CGBP more complex than CBP. To further explain the mechanism that how lossc generates chaotic dynamics, we calculate the gradient of lossc with respect to the weight wij\u207d\u02e1\u207e,\n\n$\\frac{\\partial lossc}{\\partial w_{ij}^{(l)}} = -z_{lj} \\frac{(I_o - o_{dj}^{l}) \\frac{\\partial o_{dj}^{l}}{\\partial w_{ij}^{(l)}}}{o_{dj}^{l} (1-o_{dj}^{l})} = -z_{lj} \\frac{(I_o - o_{dj}^{l}) \\frac{1}{c_{dk}} h_{ki}^{(l-1)}}{o_{dj}^{l} (1-o_{dj}^{l})} = \\frac{1}{c_{dk}} h_{ki}^{(l-1)} z_{lj}(I_o - o_{dj}^{l}).$\n\nSimilarly, the gradient of the bias \u2202lossc/\u2202b\u207d\u02e1\u207e can also be obtained, but for simplicity, we will not discuss it here. At this point, after introducing lossc, the total loss of the model is loss = lossH+lossc, and in the standard BP algorithm, the updating dynamics of w\u1d62\u2c7c\u207d\u02e1\u207e can be expressed as\n\n$w_{ij}^{(l)} = w_{ij}^{(l)} - \\eta \\frac{\\partial (loss_H + lossc)}{\\partial w_{ij}^{(l)}} = w_{ij}^{(l)} - \\eta (\\frac{\\partial loss_H}{\\partial w_{ij}^{(l)}} + \\frac{\\partial lossc}{\\partial w_{ij}^{(l)}} ) =  w_{ij}^{(l)} - \\eta (\\frac{\\partial loss_H}{\\partial w_{ij}^{(l)}} + \\sum_{k} \\frac{1}{c_{dk}} h_{ki}^{(l-1)} z_{lj}(I_o - o_{dj}^{l})),$ \n\nwhere \u03b7 is the learning rate. Considering that z is a tunable parameter, we can always define a new zki so that z lj \\frac{1}{c_{dk}} h_{ki}^{(l-1)} = zki , and then Eq. (8) can be simplified as\n\n$w_{ij}^{(l)} \\leftarrow w_{ij}^{(l)} - \\eta \\frac{\\partial loss_H}{\\partial w_{ij}^{(l)}} + z_{lj} (I_o - o_{dj}^{l}).$ \n\nFrom a dynamical viewpoint, we can describe these updating equations (9) as difference equations in a vector or matrix form when taking iteration number as time t, i.e.\n\nW(t+1) = F(W(t))\n\nwhere W(t) is the vector representing all w\u1d62\u2c7c\u207d\u02e1\u207e at the iteration t, and F is the corresponding function vector describing the right-hand side of Eq. (9). Thus, we can analyze this updating process from the perspective of dynamical systems. From the above equation, it can be seen that the introduction of lossc is equivalent to adding negative feedback to the weight wij\u207d\u02e1\u207e (note that odj is the monotone function of wij\u207d\u02e1\u207e), and it is theoretically proven that when z is sufficiently large, the dynamics in Eq. (9) exhibit Marotto chaos (high-dimensional topological chaos). It should be noted that the dynamics in Eq. (9) is based on the Nagumo-Sato model and the chaotic neuron model, which models real neurons, thus the chaotic term or chaotic dynamics in Eq. (9) has biological significance. In addition, although Eq. (9) is derived from the standard BP algorithm, it can be easily extended to other improved versions, such as SGDM and Adam, as detailed in Supplementary Information.\nOn the other hand, in order to ensure the convergence of the learning process, we adopt a chaotic simulated annealing strategy, that is\n\nz\u2190\u03b2z,\n\nwhere \u03b2 is an annealing constant close to 1 (such as 0.999), and in this work, we set all zkl to the same value z. Similarly, we can also describe Eq. (11) as difference equations z(t+1) = \u03b2z(t), and analyze their dynamical features combined with the above difference equations W(t+1) = F(W(t)).\nClearly, the proposed updating dynamics (9) and (11) begin with chaotic dynamics due to high z, then enter a bifurcation process with intermediate z with the evolution of iteration t, and eventually reduce to gradient dynamics (or traditional BP updating dynamics) when z is sufficiently small. As shown in the additional term of Eq. (9), another significant feature is that CGBP can be added to any existing algorithm as a plug-in unit for improving its performance, thus it can be considered as a universal learning algorithm for GNNs."}, {"title": "3 Results", "content": null}, {"title": "3.1 Testing the performance of CGBP on a 3-node graph", "content": "In order to illustrate the working principle of the CGBP algorithm, we take a 2-regular graph with 3 nodes shown in Fig. 2a as an example to verify the chaotic dynamics and convergence of CGBP. As an example, the input features of these three nodes are set to 0.1, 0.9 and 0.7, respectively, and their corresponding target values (labels) are set to 0, 1 and 1, respectively. For any node i, if we use the single neuron model shown in Fig. 2b, we can define a loss function that measures the difference between the output of node i and the target, such as the mean squared error (MSE) loss, to learn the model parameters w and b. Based on this, the CGBP algorithm introduces a brain-inspired chaotic loss, and we first verify that this chaotic loss can cause the parameters w and b training process to exhibit chaotic dynamics. As shown in Fig. 2c, when the chaotic strength z = 0, the CGBP algorithm is equivalent to the traditional BP algorithm. At this time, both w and b are updated using continuous gradient dynamics, and the node output oi and total loss (loss) are also updated in the same way. When z 10 (i is always set as 1, denoted as CGBP-1) i.e. high z, in the early training stages (epoch < 1000), the dynamics of w and b is discrete (as shown in Fig. 2d). Numerically, it can be found that the dynamics has positive Lyapunov exponents, which means their dynamics is chaotic (as shown in Supplementary Fig. S1). In addition, from Fig. 2d, it can be seen that as z is annealed (with annealing constant \u03b2 = 0.999), the chaotic dynamics of w and b gradually disappears through a series of bifurcations (with middle z) and degenerate into gradient dynamics (with small z), and finally converge as z approaches 0. It should be noted that in each updating of w and b, i can be set as a constant value or randomly selected from {1,2,3} (as shown in Fig. 2e, denoted as CGBP-R). At this time, in addition to gradient and chaotic dynamics, w and b are also affected by stochastic dynamics, but they still converge with the annealing of z. Considering that these two selected ways of i have little impact on the performance of CGBP in practical use, we do not distinguish between them later."}, {"title": "3.2 Testing the performance of CGBP on large-scale 3-regular graphs", "content": "In the previous section, we have verified the chaotic dynamics and convergence of CGBP on a toy graph. Next, we further test the performance and robustness of CGBP on large-scale 3-regular graphs.\nFirst, we discuss the MIS problem on a 3-regular graph with 100 nodes. We selected three BP-based optimization algorithms, SGD, SGDM, and Adam. For each optimization algorithm, we trained a GCN model (see Methods for details) 100 times with different random number seeds, and recorded the minimum loss and the maximum MIS (where the size of the set is denoted as NMIS) that the algorithm can reach during the training process. In addition, by introducing the chaotic loss, we implemented the CGBP versions of these three optimization algorithms and performed similar statistics. In Figs. 3a and 3b, the minimum loss and Nmis of BP and CGBP methods are compared under different optimizers. It can be seen that regardless of the optimizer used, the minimum loss that CGBP can achieve is significantly smaller than that of BP, and NMIS is greater than that of BP. Moreover, the performance of BP on these two indicators significantly depends on the optimization algorithm, while CGBP has strong and stable performance under different optimization algorithms. Fig. 3c shows the solution obtained by the CGBP algorithm for an MIS problem, where the red point set forms the final MIS with corresponding NMIS = 45. In addition to the MIS problem, we also discussed the MC problem (see Methods for the detailed definition) on this graph. Figs. 3d and 3e compare the minimum loss and maximum cut (NMc) of the BP and CGBP methods under different optimizers for the MC problem, and it can be seen that the result obtained in the MC problem is highly consistent with that in the MIS problem. Fig. 3f shows the solution obtained by the CGBP algorithm for an MC problem, which is the set of red edges, with NMC = 138."}, {"title": "4 Discussion", "content": "In this work, we draw inspiration from the chaotic dynamics in the real brain and develop a universal learning algorithm for GNNs, which is applied to PI-GNN to efficiently solve large-scale COPs, outperforming the SOTA methods. Compared with existing combinatorial optimization methods, the CGBP method has the following advantages: (1) The optimization performance of CGBP on multiple publicly available benchmark datasets can surpass existing SOTA methods; (2) The time complexity of CGBP is linear, that is, the computation time increases linearly with the increase of the system variables, enabling it to handle super-large-scale COPs (currently it can handle graphs of millions of nodes, but note that the obtained solution may not optimal); (3) CGBP is robust, that is, its optimization performance is less affected by the hyperparameters z and \u03b2; (4) Compared with other machine learning-based methods, CGBP directly transforms the solving process of a COP into the GNN training process, hence there is no need to give the training set in advance; (5) CGBP can be directly extended to other COPs, such as the constraint satisfaction problem (CSP); (6) CGBP, as a universal learning algorithm for GNNs, can be used as a plug-in unit to easily integrate into any existing algorithm for improving global searching ability and performance.\nSpecifically, we believe that the strong optimization performance of CGBP can be attributed to three main reasons. The first reason is that chaotic dynamics has been widely used to solve optimization problems due to its theoretically guaranteed global ergodicity and pseudo-randomness, and existing theory has shown that the chaotic loss introduced by the CGBP method can induce chaotic dynamics when z is sufficiently large, which generates Marotto chaos and thus makes the training dynamics rich and global. The second reason is that the chaotic loss introduced by CGBP is inspired by the real brain, which is more biologically plausible compared to other methods that generate chaos by adjusting the learning rate or introducing chaotic mappings. It should be noted that the chaotic loss introduced by CGBP is a local loss, which is equivalent to introducing local negative feedback to the weight parameters. This local regulatory feature is consistent with some biological experiments on synaptic plasticity mechanisms, such as spike-timing-dependent plasticity (STDP). Interestingly, the recently proposed Forward-Forward learning algorithm by Hinton also uses local losses, and the use of local learning may be more competitive in the future. The third reason is that the chaotic loss introduced by CGBP has the form of cross-entropy, so when the chaotic loss dominates in the early stages of learning, the output of neurons tends to be Io, which may make the network more plastic. Furthermore, from an optimization perspective, this is similar to the idea of interior point methods for solving linear programming problems.\nAlthough CGBP has made important progress in COPs, there is still a lot of room for improvement in its optimization performance. Here are some possible ways to further improve it. Firstly, the hyperparameters z and \u03b2 in the CGBP method need to be set manually, and how to adaptively adjust these two hyperparameters to achieve the optimal performance of CGBP is still an unresolved issue. Secondly, the optimization algorithm and architecture of the neural network also have a certain impact on the optimization performance of CGBP. In this work, we only tried SGD, SGDM and Adam optimizers, and considered only GCN and GraphSAGE architectures. So far, the combination of Adam and GraphSAGE has achieved the best results. Using more advanced optimizers, such as Adablief and Adan, and GNN architectures, such as GAT and SGAT, may further improve the performance of CGBP. Finally, the physics-inspired Hamilton loss used in PI-GNN may not correspond well to the solutions of COPs, and sometimes the solution with a lower loss has a worse quality. Therefore, how to encode the solution of combinatorial optimization more rationally is also an important research direction in the future."}, {"title": "5 Methods", "content": null}, {"title": "5.1 Encoding of MC and GC problems", "content": "The objective of the MC problem is to divide the vertex set V of a given graph G(V", "Title": "Brain-inspired Chaotic Graph Backpropagation for Large-scale Combinatorial Optimization", "Abstract": "Graph neural networks (GNNs) with unsupervised learning can solve large-scale combinatorial optimization problems (COPs) with efficient time complexity, making them versatile for various applications. However, since this method maps the combinatorial optimization problem to the training process of a graph neural network, and the current mainstream backpropagation-based training algorithms are prone to fall into local minima, the optimization performance is still inferior to the current state-of-the-art (SOTA) COP methods. To address this issue, inspired by possibly chaotic dynamics of real brain learning, we introduce a chaotic training algorithm, i.e. chaotic graph backpropagation (CGBP), which introduces a local loss function in GNN that makes the training process not only chaotic but also highly efficient. Different from existing methods, we show that the global ergodicity and pseudo-randomness of such chaotic dynamics enable CGBP to learn each optimal GNN effectively and globally, thus solving the COP efficiently. We have applied CGBP to solve various COPs, such as the maximum independent set, maximum cut, and graph coloring. Results on several large-scale benchmark datasets showcase that CGBP can outperform not only existing GNN algorithms but also SOTA methods. In addition to solving large-scale COPs, CGBP as a universal learning algorithm for GNNs, i.e. as a plug-in unit, can be easily integrated into any existing method for improving the performance.", "Authors": ["Peng Tao", "Kazuyuki Aihara", "Luonan Chen"], "Sections": [{"Title": "1 Introduction", "Content": "The goal of combinatorial optimization problems (COPs) is to find the solution corresponding to the smallest objective function among a limited but often a large number of candidates, which is closely related to many hard problems in science and industry, such as logistics and transportation, circuit design and drug development1-5. During the long research history of combinatorial optimization, many classical methods have been proposed, such as branch-and-bound and Tabu search methods, but with the advent of the era of big data, the scale of real-world COPs is often very large, and traditional methods usually have difficulty in obtaining high-quality feasible solutions in an acceptable time. Therefore, it is of great theoretical and practical importance to develop new generalized solution methods suitable for large-scale COPs.\nIn recent years, new combinatorial optimization algorithms different from traditional operations research-based methods have been developed. Among them, machine learning-based methods are currently a hot topic in research. This type of algorithm can be further divided into three subclasses based on the learning paradigm, namely supervised learning, reinforcement learning, and unsupervised learning. Early combinatorial optimization methods mainly used supervised learning, which minimizes some empirical loss functions to complete the complex, nonlinear mapping from the input representation of a problem to a target solution. For example, the classic Pointer network (Ptr-Net) uses a Seq2Seq model to generate variable-length permutation combinations and then solve the traveling salesman problem (TSP). However, the feasibility and performance of supervised learning-based methods largely depend on the availability of a large amount of pre-solved high-quality training data, which is often difficult to obtain7. In contrast, reinforcement learning techniques aim to learn a policy that maximizes some expected reward function and can therefore bypass the need for training labels. Specifically, COPs can usually be described by an objective function, which can be used as the reward function in reinforcement learning. For instance, Bello et al. constructed an actor-critic model by combining a Ptr-Net-based decoder with a recurrent neural network (RNN) encoder and using the expected length of a tour as the reward signal, which served as an approximate solver for the TSP. Khali et al. further combined reinforcement learning and graph embedding to gradually construct feasible solutions through learning an efficient greedy meta-heuristic method, which achieves decent results in problems like minimum vertex cover (MVC), maximum cut (MC) and TSP. However, reinforcement learning-based methods often require manual modeling of the target problem, such as defining states and actions, which typically demands rich prior knowledge. Consequently, some works have attempted to use reinforcement learning to assist traditional combinatorial optimization methods. For instance, NeuroLKH10 uses reinforcement learning to assist the Lin-Kernighan-Helsgaun (LKH)\u00b9\u00b9 algorithm in selecting candidate sets of edges, thereby improving the quality of the TSP solution. Nonetheless, strategies learned in this manner are difficult to extend from one COP class to another. To address the above issues, Schuetz et al. recently proposed a more general framework, called physics-inspired graph neural network (PI-GNN)\u00b9\u00b2, which transforms combinatorial optimization problems into quadratic unconstrained binary optimization (QUBO) problems. The corresponding Hamiltonians of these problems are encoded as the loss functions of GNNs, and the GNNs are then trained in an unsupervised manner to obtain the solution to the corresponding COP. It should be noted that although PI-GNN has advantages such as high computational efficiency (as it can solve combinatorial optimization problems of up to one million variables\u00b9\u00b2) and strong scalability, the quality of its solutions is not superior to that of traditional state-of-the-art (SOTA) methods. The reason for this issue is that the solution of PI-GNN depends significantly on the performance of the GNN learning algorithm. Currently, GNN learning still uses gradient dynamics-based backpropagation (BP) algorithms and its variants, such as Adam\u00b9\u00b3, thus making GNN models prone to local minima, which limits the quality of the solution. Therefore, developing a new gradient-free dynamic universal GNN learning algorithm to overcome the local minima problem is of great importance for solving large-scale combinatorial optimization problems.\nOn the other hand, chaotic dynamics is one of the most important theoretical discoveries in natural sciences in the 20th century, which describes unpredictable global dynamics generated by deterministic systems\u00b9\u2074. Specifically, chaotic dynamics is highly sensitive to initial conditions, and exhibits randomness and unpredictability in the long-term evolution. Yet since its dynamics is fundamentally deterministic, this randomness is known as pseudo-randomness\u00b9\u2074. Moreover, theoretical studies have shown that chaos has global exploratory properties due to the ergodicity in a fractal space of a strange attractor\u00b9\u2075. It is due to these dynamic properties that chaotic dynamics has been widely used to solve global optimization problems\u00b9\u2075-19. In addition, chaotic dynamics has been observed in the heart\u00b2\u2070, neurons\u00b2\u00b9, \u00b2\u00b2, and even the brain\u00b2\u00b3, and it is very important for many biological processes\u00b2\u2074, such as gene expression and regulation\u00b2\u2075, signal processing \u00b2\u2076, and sleep\u00b2\u2077. Among them, Skarda and Freeman's experiments showed that the dynamics of the rabbit brain is chaotic at the resting state and works for learning new odor patterns\u00b2\u00b3. Matsumoto et al. found that squid giant axons show chaotic responses to periodic external stimulation\u00b2\u2078. Moreover, recent experiments have also found that the neural networks of animal brains are in a critical or quasi-critical state between order and chaos\u00b2\u2079, \u00b3\u2070. These studies imply a possibility that over long periods of evolution, animal brains have been able to use chaotic dynamics for cognition or learning. Therefore, is it possible to draw on the chaotic dynamics of the brain to establish a new, universal GNN learning theory and method?\nBased on the above motivation, we developed the chaotic graph backpropagation (CGBP) algorithm in this work (Fig. 1). By introducing a local loss function to simulate chaotic dynamics in the brain and utilizing its pseudo-randomness and global ergodicity, CGBP overcomes the drawbacks that existing BP-based GNN learning algorithms are prone to local minima, and achieves high-precision results in large-scale COPs, outperforming not only the existing GNN learning algorithms but also SOTA methods. In addition to solving COPs, CGBP can be used as a universal learning algorithm for training GNNs, i.e. it can be easily integrated into any existing method as a plug-in unit for improving the performance. From both computational and theoretical viewpoints, we can show that there is indeed chaotic dynamics in CGBP, i.e. Marotto chaos\u00b3\u00b9 generated from a snapback repeller when hyperparameter z is sufficiently large. In the following, we will introduce the CGBP algorithm in detail and then compare it with existing SOTA methods on large-scale benchmark COP datasets."}, {"Title": "2 Chaotic graph backpropagation", "Content": null}, {"Title": "2.1 Combinatorial optimization", "Content": "Typical combinatorial optimization problems include TSP, MC, MVC, maximum independent set (MIS) and graph coloring (GC). Assuming that the number of variables in a combinatorial optimization problem (COP) is n, a feasible solution can be represented as a vector x = (x1,x2,\u2026, x\u2081). The objective of a COP is to find the feasible solution with the smallest objective function value.\nWhen the state of each variable is binary (x\u2081 \u2208 {0,1}), many COPs can be represented under the QUBO\u00b3\u00b2 framework, such as MIS and MC. At this time, the COP corresponds to the Ising model in physics\u00b3\u00b3, and its objective function is equivalent to the Hamiltonian of the Ising model, given by\n\nH = x^T"}]}]}