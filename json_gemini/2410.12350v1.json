{"title": "GECTurk WEB: An Explainable Online Platform for Turkish Grammatical Error Detection and Correction", "authors": ["Ali Gebe\u015f\u00e7e", "G\u00f6zde G\u00fcl \u015eahin"], "abstract": "Sophisticated grammatical error detection/correction tools are available for a small set of languages such as English and Chinese. However, it is not straightforward-if not impossible-to adapt them to morphologically rich languages with complex writing rules like Turkish which has more than 80 million speakers. Even though several tools exist for Turkish, they primarily focus on spelling errors rather than grammatical errors and lack features such as web interfaces, error explanations and feedback mechanisms. To fill this gap, we introduce GECTURK WEB, a light, open-source, and flexible web-based system that can detect and correct the most common forms of Turkish writing errors, such as the misuse of diacritics, compound and foreign words, pronouns, light verbs along with spelling mistakes. Our system provides native speakers and second language learners an easily accessible tool to detect/correct such mistakes and also to learn from their mistakes by showing the explanation for the violated rule(s). The proposed system achieves 88,3 system usability score, and is shown to help learn/remember a grammatical rule (confirmed by 80% of the participants). The GECTURK WEB is available both as an offline tool \u00b9 or at www.gecturk.net.", "sections": [{"title": "Introduction", "content": "Grammatical Error Correction/Detection (GEC/D) (Bryant et al., 2023) is a well-established NLP task, that aims to detect and correct various errors in text, including grammatical issues like missing prepositions, mismatched subject-verb agreement, as well as orthographic and semantic errors such as misspellings and inappropriate word choices. Tools that can perform GEC/D have recently gained attention due to the rise in digital communication, remote work, and global interactions, which demand clear and professional writing. With the inclusion of the detection module, GEC/D formulation facilitates the teaching of grammar rules, empowering users not only to produce error-free writing but also to enhance their language skills and comprehension gradually.\nTherefore, developing open-source GEC/D tools is particularly crucial, yet challenging for languages with complex writing rules, such as Turkish. The writing rules for such languages generally involve multiple linguistic layers\u2014phonetic, syntactic, and semantic-which makes them difficult to follow and remember even for native speakers. While several tools exist for high-resource languages such as GECko+ (Cal\u00f2 et al., 2021) and ALLECS (Qorib et al., 2023), they often suffer from discontinuation of support or lack adaptability for languages such as Turkish. Moreover, while advanced commercial tools such as LanguageTool2 offer support for 31 languages, yet Turkish is notably absent from their list. Furthermore, as highlighted in \u00a7 2, numerous offline tools are accessible for Turkish spelling correction, whereas only two models (not tools) (Uz and Eryi\u011fit, 2023; Kara et al., 2023) are dedicated to Turkish GEC/D.\nTo bridge this gap, we leverage the state-of-the-art pretrained GEC/D (Kara et al., 2023)\u00b3 and spelling correction models; and, for the first time, provide a user-friendly web-interface to them. Our system does not only correct errors but also display them in different colors, while providing explanations for each correction through interactive elements in the interface. Additionally, the system includes a feedback mechanism to foster continuous improvement and enhance user engagement. Our system is lightweight and flexible, allowing easy adaptation to other languages through pretrained sequence tagging models. The results of"}, {"title": "Previous Systems", "content": "High-Resource Languages: Numerous GEC/D models exist for high-resource languages such as English (Lai et al., 2022; Tarnavskyi et al., 2022; Sorokin, 2022; Qorib et al., 2022a) and Chinese (Ren et al., 2018; Qiu and Qu, 2019; Wu and Wu, 2022; Xu et al., 2022). However, these models lack user interfaces, which are crucial for accessibility to non-specialists. Although fewer in number compared to models, several GEC/D tools are available. For instance, GECko+ (Cal\u00f2 et al., 2021) integrates the GECTOR XLNet model for sentence-level grammatical correction with a sentence ordering model (Prabhumoye et al., 2020). It processes texts by segmenting them into sentences, applying corrections, and then reordering them. Initially, GECko+ offered a web interface, but it is currently inactive. Now, the only access is through downloading the source code and running it locally, which is inconvenient for general users. Similarly, MiSS (Li et al., 2021), a Multi-Style Simultaneous Translation system that includes a GEC/D feature using GECTOR XLNet, initially had a web interface which is now inactive.\nThe most recent non-commercial GEC/D tool is ALLECS (Qorib et al., 2023), which uses GECTOR-ROBERTa, GECToR-XLNet, and T5-Large models, alongside two combination methods: ESC (Qorib et al., 2022b) and MEMT (Heafield and Lavie, 2010). ALLECS takes input and displays corrected errors with clickable buttons, and has an easy-to-use web interface. Despite its advantages, ALLECS lacks a feedback mechanism and an enhanced interface that uses color coding to distinguish between different types of errors. Moreover, its implementation is not flexible enough to be extended to other languages, i.e., one cannot simply upload a Turkish GEC/D model and expect the application to function without significant modifications to the source code.\nMorphologically Rich Languages: In the case of morphologically rich languages, there are fewer GEC/D models available. Examples include Arabic (Solyman et al., 2022), Bengali (Hossain et al.,"}, {"title": "GECTURK WEB", "content": "Our system has four main components: i) frontend, ii) backend, iii) grammatical error correction/detection (GEC/D), and iv) spelling correction modules. GECTURK WEB is based on the Python Django framework, 10 which manages everything related to performance, security, scalability, and database handling. The architecture of our system, incorporating these components along with the data flow,"}, {"title": "Frontend", "content": "For the user interface, we use the Bootstrap framework 11 that provides us with modern, responsive, and mobile compatible HTML and CSS. Initially, empty \"Input\u201d and \u201cOutput\u201d fields are shown. After identifying and correcting grammatical and spelling errors in the input, the output is enriched with error types (see Figure 1). For each correction, HTML snippets are created to wrap the corrected words and transforms them to actionable buttons. These snippets use Bootstrap's pop-over functionality to provide an interactive way to display the error type, an explanation, and the correction. Each correction is highlighted with a specified background color and font size for visibility. Additional information about each error type is retrieved from a predefined set of rules given in Table 212. This information includes a textual explanation and a title for the error, which are both used in the content of the pop-over. For instance, if there is a misspelling of \"-de/da\", this is displayed as Conjunction \"-de/da\" is always written separately. The tokens within the input text are replaced with the generated HTML snippets, respecting the original"}, {"title": "Backend", "content": "Our system uses Django, a high-level Python web framework, to create a strong backend infrastructure. The architecture of Django, known as Model-View-Template (MVT), supports a clear separation of responsibilities. Here, the Model is responsible for data storage and retrieval. The View handles user requests and provides responses, and the Template dynamically generates HTML pages for user interaction.\nView The send_data function is used for accommodating various actions including text submission for correction, feedback submission, and API interactions. Upon receiving a POST request given the input text, the function invokes a text correction process through get_text_corrector. Text correction process starts with sentence tokenization using NLTK's sent_tokenize function (Bird et al., 2009) and continues with the grammatical error correction process, which is described in detail in \u00a73.3. The corrected text, alongside original input and HTML-formatted output for interactive display, is then encapsulated within a TEXT model instance for persistence. Feedback submission, whether specific to text corrections or general website feedback, is similarly processed and stored.\nModel Our data model chas two main entities: TEXT and GENERALFEEDBACK. The TEXT model captures the essence of each correction session, storing original and corrected texts, HTML-tagged corrected text for frontend display, and any user feedback. This allows for a comprehensive audit trail of user interactions and system outputs. The GENERALFEEDBACK model, on the other hand, aggregates general user impressions and feedback about the website, enabling continuous improvement based on user insights.\nDatabase and Server Thanks to Django's ORM capabilities, we easily integrate these models with our MySQL13 database, as the database manage-"}, {"title": "Grammatical Correction", "content": "We employ the state-of-the-art GEC/D model, SequenceTagger, previously described in Kara et al. (2023). Briefly, SequenceTagger finetunes a strong encoder model (e.g., BERTurk (Schweter, 2020)) to classify tokens into grammatical error classes, enabling efficient error detection rather than merely correction. For illustrative purposes, we provide one sample error type from each category in Table 2. Then, corrections are performed with reverse transformations. The model weights and associated files, such as the tokenizer and vocabulary, are securely stored on Amazon S315. Deployment is simplified through the use of AWS Elastic Beanstalk, requiring only the compression of the project (including the model itself) and uploading it to the AWS Elastic Beanstalk application. We have adapted the original code from (Kara et al., 2023) into a class named TEXTCORRECTOR and an API function process_text for performing correction operations with this model. For further details, we encourage consulting the source code of Kara et al. 16 and our implementation 17."}, {"title": "Spelling Correction", "content": "It should be noted that users not only make grammatical mistakes but also commonly commit spelling errors. Since the GEC/D model is not designed for spelling error correction, we employ external tools to extend our system. For mistakes in proper nouns and common typos, we survey external Turkish spelling correction tools. After evaluating different options, we find VNLP (Turker, 2021), StarlangSoftware (Y\u0131ld\u0131z, 2019), and TurkishNLP (\u00c7etinkaya, 2018) unsatisfactory by means of efficiency and accuracy. As a result, we integrated TrNlp (Bayol, 2018) and ZemberekNLP (Ak\u0131n and Ak\u0131n, 2007; Ak\u0131n, 2017; Uz, 2020) to our system. We apply corrections using TrNlp for proper noun capitalization (e.g., \u201cankara\u201d \u2192 \"Ankara\")-e.g., any proper noun violating it is capitalized by the tool. Following the proper noun corrections, we leverage ZemberekNLP's TURKISH-SENTENCENORMALIZER for the common typos. Sentences are processed to ensure that the words"}, {"title": "Evaluation", "content": "To evaluate GECTURK WEB, we conduct an in-depth user study. This study aims to assess the usability and effectiveness of the tool in facilitating learning and retention.\nThe user study is structured into two parts. First, participants are asked to follow a user scenario, where they input 10 short sentences into GECTURK WEB. These sentences are selected to cover all four possible outcomes: True Positives (TP), where the system accurately identifies and corrects an error; True Negatives (TN), where no error exists and the system appropriately refrains from making changes; False Positives (FP), where the system erroneously alters a correct sentence; and False Negatives (FN), where the system overlooks an error. Reflecting on the performance of GECTURK (Kara et al., 2023), which demonstrated a detection precision of 0.89 and a correction F1-score of 0.84, we have designed a representative sample to mirror these results. Therefore, the set of 10 sentences includes 7 True Positives (TPs) and 1 of each other outcome types. It is important to note that the participants are unaware of this distribution. To guide the participants on each potential outcome, we create four videos and present them to participants before they begin experimenting with GECTURK WEB, which is described in detail in \u00a7A.1. After viewing these videos, participants are instructed to input each sentence and classify it according to one of the possible outcomes. The complete list of 10 sentences can be found in \u00a7A.1. We restrict the average duration of this part to be 45 minutes to align with findings from studies (Lavrakas, 2008; Kost and da Rosa, 2018; Sharma, 2022) on the optimal length for questionnaires. After completing this part, participants are asked several questions to assess the system based on the evaluation metrics. We employ two established metrics to test usability and user satisfaction: the System Usability Scale (SUS) (Brooke, 1995) and the Standardized User Experience Percentile Rank Questionnaire (SUPR-Q) (Sauro, 2015). These metrics are widely recognized for their reliability in assessing user sat-"}, {"title": "Extension to Other Languages", "content": "As depicted in Figure 2, our system exhibits flexibility and seamless adaptability for multilingual support. Expanding our system to support other languages merely requires the replacement of the GED/C model and the spelling error correction module. Specifically, the sequence tagger model must be trained to identify the distinct grammatical error patterns of the target language. Similarly, the spelling error correction module can be replaced with an existing spelling corrector for the target language. Both modules can be adjusted by modifying the \"text_corrector.py\" script and the associated model weights files, facilitating straightforward integration."}, {"title": "Conclusion", "content": "In this work, we present GECTURK WEB, a practical online platform for Turkish grammatical error detection and correction (GED/C) along with spelling error correction (SEC). Our system aims to not only correct mistakes but also to facilitate learning of complex writing rules via user-friendly rule explanations. Furthermore, the user feedback mechanism allows for continual support and training of the tool. The high SUS and SUPR-Q scores, significantly above average benchmarks, alongside the positive feedback on learning outcomes, validate the platform's design philosophy and its focus on user-centric development. Furthermore, GECTURK WEB is built with a flexible architecture, suggesting that adaptation to additional languages is within reach. Source code and the web-based tool is publicly and freely available."}, {"title": "Limitations", "content": "Major limitation of our system is the number of concurrent user interactions it can process. Currently, the system operates on a single AWS i4i.large instance, which can efficiently manage up to ten simultaneous users. Beyond this threshold, performance begins to degrade, necessitating additional instances to preserve service quality. However, it's essential to highlight that this limitation can easily be overcome by enhancing our infrastructure given the budget. Should the GECTURK WEB platform experience a surge in popularity, we are prepared to scale our resources horizontally by incorporating more instances."}, {"title": "Ethics Statement", "content": "The development and deployment of GECTURK WEB adhere to ethical considerations crucial for language processing tools. We ensure that user data is handled with the utmost confidentiality and integrity, in accordance with data protection regulations. The feedback system is designed to be non-intrusive and respectful of user privacy."}, {"title": "User Study", "content": "The user scenario\nParticipants are given 10 short sentences and are requested to input them into GECTurk WEB. To help participants understand the potential outcomes, we produced four instructional videos and showed them to the participants before they started using GECTurk WEB. Figures 3 through 6 display screenshots of each scenario along with its English transcription. Following the video demonstration, participants are directed to input each sentence and categorize it based on the possible outcomes. The full list of the 10 sentences is provided in Table 3."}, {"title": "User Evaluation", "content": "In the second part of the user study, participants are asked to complete the SUS and SUPR-Q questionnaires based on their experience in the first half of the study. Additionally, participants are asked a yes/no question regarding whether they learned or remembered a grammatical rule. The SUS questionnaire comprises ten five-level Likert scale questions, while the SUPR-Q consists of seven five-level Likert scale questions and one ten-level Likert scale question, making a total of 19 questions including the yes/no question."}, {"title": "Time Efficiency", "content": "This section highlights the model's performance in terms of time efficiency, demonstrating a linear relationship between the volume of words processed and the response time. The data suggests that the system can process up to 14,000 words in under 90 seconds, affirming its ability to scale effectively while retaining user engagement. This performance is supported by robust hardware specifications of an AWS i4i.large instance, including 2 vCPUs, 16.0 GiB of memory, and a 3.5 GHz Intel Xeon 8375C processor, which collectively ensure minimal latency even under significant text processing loads. For visual representation, see Figure 7."}]}