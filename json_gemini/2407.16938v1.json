{"title": "Synthetic Trajectory Generation Through Convolutional Neural Networks", "authors": ["Jesse Merhi", "Erik Buchholz", "Salil S. Kanhere"], "abstract": "Location trajectories provide valuable insights for applications from urban planning to pandemic control. However, mobility data can also reveal sensitive information about individuals, such as political opinions, religious beliefs, or sexual orientations. Existing privacy-preserving approaches for publishing this data face a significant utility-privacy trade-off. Releasing synthetic trajectory data generated through deep learning offers a promising solution. Due to the trajectories' sequential nature, most existing models are based on recurrent neural networks (RNNs). However, research in generative adversarial networks (GANs) largely employs convolutional neural networks (CNNs) for image generation. This discrepancy raises the question of whether advances in computer vision can be applied to trajectory generation. In this work, we introduce a Reversible Trajectory-to-CNN Transformation (RTCT) that adapts trajectories into a format suitable for CNN-based models. We integrated this transformation with the well-known DCGAN in a proof-of-concept (PoC) and evaluated its performance against an RNN-based trajectory GAN using four metrics across two datasets. The PoC was superior in capturing spatial distributions compared to the RNN model but had difficulty replicating sequential and temporal properties. Although the PoC's utility is not sufficient for practical applications, the results demonstrate the transformation's potential to facilitate the use of CNNs for trajectory generation, opening up avenues for future research. To support continued research, all source code has been made available under an open-source license.", "sections": [{"title": "I. INTRODUCTION", "content": "Due to the omnipresence of sensor-equipped devices like smartphones, large quantities of location data are collected daily. These trajectory datasets offer the potential for various use cases, such as public transport optimisation and pandemic control. However, location data yields severe privacy implications as it allows the re-identification of individuals [1], [2] and the inference of personal attributes [3], [4]. To highlight the high information content of location traces, De Montjoye et al. [1] managed to identify 95% of users in a mobile phone dataset based on four locations only. Moreover, researchers determined Islamic taxi drivers in an anonymised dataset by correlating the mandatory prayer times with their breaks [5].\nResearchers have proposed various methods for the privacy-preserving release of trajectory datasets [3], [6], [7], [8]. These methods focus on syntactic privacy, such as k-anonymity [9], and semantic privacy, notably Differential Privacy (DP) [10]. DP has become the de facto standard due to its strong formal guarantees. However, these methods involve a privacy-utility trade-off, requiring data perturbation to ensure privacy [11]. Current approaches often fail to maintain sufficient utility in the protected data for effective analysis [12], [13], [14]. Inappropriate protection can also lead to structural anomalies, such as cars not adhering to roads or ships traversing land [15], [16], [17], [8]. These anomalies may facilitate reconstruction attacks, thus reducing the achieved privacy level [18], [16].\nFor these reasons, Liu et al. [19] proposed using Generative Adversarial Networks (GANs) to generate synthetic trajectory datasets. The Deep Learning (DL) model retains the original dataset's key characteristics but produces inherently private, synthetic data. Models such as LSTM-TrajGAN [12] show the potential utility of this method. Yet, these solutions lack strong privacy guarantees. There are risks of the model memorising and replicating real trajectories with minimal alterations. To guarantee that the model does not remember training data, the usage of DP-SGD [20] has been proposed [21]. However, LSTM-TrajGAN uses a real trajectory as input, unlike standard GAN models like Deep Convolutional Generative Adversarial Network (DCGAN) [22] that use Gaussian noise. DP-SGD only secures training data, thus it is ineffective for architectures that rely on real data during generation [21].\nTo incorporate DP-SGD in trajectory GANs, a noise-only model is required. As trajectories represent sequences of locations, Recurrent Neural Network (RNN)-based models are the obvious choice. However, most GAN research has centred on computer vision, focusing on Convolutional Neural Network (CNN)-based models. RNN-based GANs often train less stably than CNN models and struggle with convergence [21]. This raises the question of whether a CNN-based architecture could be utilised for trajectory generation.\nIn other sequential domains, the move from RNN-based models to CNN-based models showed success. Wave-GAN [23] adapts DCGAN for audio data generation, employing Conv1D layers and outperforming an RNN-based model. Similarly, PAC-GAN [24] utilises a CNN-GAN for the generation of network traffic packets where most related work had used RNNs. These examples highlight the potential of CNN-based architecture's in sequential domains.\nThis work introduces a Reversible Trajectory-to-CNN Transformations (RTCT) to facilitate the use of CNN-based"}, {"title": "II. BACKGROUND", "content": "This section lays out the background knowledge for the remainder of this paper. Section II-A defines a trajectory dataset. Section II-B provides an overview of DP, emphasising its application in deep learning via DP-SGD. In Section II-C, we explore Generative Adversarial Networks. Section II-D provides further details on the DCGAN architecture.\nA. Trajectory Datasets\nA trajectory dataset consists of a number of trajectories: DT = {T1,\u2026\u2026\u2026, Tn}. Each trajectory Ti itself represents an ordered sequence of locations Ti = (li1,..., lin), where each location consists of multiple attributes. We assume the minimal information content of a location to be spatial coordinates such as latitude and longitude, i.e., lij = (latij,lonij). However, locations might be enriched with additional information. For instance, some datasets record altitude [26], while others contain temporal information [26], [25], or semantic information such as Point of Interests (POIs), i.e., the type of location. Within this work, we assume spatial details to be minimally present. Temporal and semantic information are optional and can extend all proposed approaches.\nB. Differential Privacy\nDifferential Privacy (DP) [10] is a rigorous semantic privacy notion. In contrast to syntactic privacy notions like k-Anonymity, DP offers protection against any adversary independent of their background knowledge. DP is founded on the principle of plausible deniability, i.e., participation in a query should not (significantly) affect the outcome. Accordingly, participation in a dataset does not harm one's privacy. Mathematically [10]:\nDefinition 1 (Differential Privacy): A mechanism K provides (\u03b5, \u03b4)-differential privacy if for all neighbouring datasets D\u2081 and D2, and all S \u2286 Range(K) holds\nP[K(D\u2081) \u2208 S] < e^\u03b5 \u00d7 P[K(D2) \u2208 S] + \u03b4\nIn the original definition, neighbouring means that dataset D2 can be obtained from D\u2081 by removing all user records u from the dataset: D2 = D1\\{rxi|X = u}. In practice, different neighbourhood definitions, also called unit of privacy [21], are deployed. Most commonly, especially in machine learning, instance-level DP is used, which assumes that each user"}, {"title": "C. Generative Adversarial Networks", "content": "Generative Adversarial Networks (GANs) [32] are a DL algorithm used in unsupervised machine learning. These networks consist of two main components: a generator (G) and a discriminator (D). G generates data from random noise, aiming to mimic real data samples. D assesses whether a sample is real or produced by G. This interaction forms a competitive framework, described by the adversarial loss:\nmin_G max_D E_{x~P_{data}} [log D(x)] + E_{z~p_z} [log(1 \u2013 D(G(z)))]\nIn this equation, Pdata is the real data distribution, and pz is the distribution of the noise input for G. The training process refines G and D until G can produce data almost identical to real samples. One advantage of traditional GANs architecture in regard to privacy is that the generator receives only random noise as an input during generation. Real data samples in GANs are necessary only during the training phase. This characteristic facilitates seamless integration with DP-SGD. In contrast, accessing the real data during generation can lead to privacy leakage [21]. Building on this understanding of GANs, we explore the well-known DCGAN architecture next."}, {"title": "D. DCGAN", "content": "Most current GAN models are loosely based on DC-GAN [22], owing to its effectiveness in generating valid synthetic data across various applications [33]. DCGAN is a GAN utilising convolutional layers in both its generator and discriminator that was developed for image generation. Its five key architectural features include:\n\u2022\tStrided and transposed convolutions for downsampling and upsampling, replacing pooling layers.\n\u2022\tBatch normalisation in both generator and discriminator.\n\u2022\tReLU activation in the generator, except for tanh in the output layer. Note that we used sigmoid for the output layer due to our normalisation to [0; 1].\n\u2022\tLeakyReLU activation in the discriminator, except for sigmoid in the output layer.\n\u2022\tElimination of Fully Connected (FC) hidden layers.\nThese modifications lead to DCGAN's training stability and broad applicability."}, {"title": "III. METRICS", "content": "This section outlines the metrics for our utility evaluation. We first discuss two metrics for evaluating spatial distribution: HD (Section III-A) and WD (Section III-B). We then describe TTD (Section III-C) for sequential quality and introduce the novel TRR (Section III-D) to assess temporal properties.\nA. Hausdorff Distance\nThe Hausdorff Distance (HD) is a distance metric that quantifies the similarity between two sets of points. It calculates the maximum distance from a point in one set to the nearest point in the other set. Formally, for two point sets A, B and a distance function d [34]:\nHD(A, B) = max {max_{a\u2208A} min_{b\u2208B} d(a, b), max_{b\u2208B} min_{a\u2208A} d(a, b)}\nThis metric is widely used for evaluating spatial utility in trajectory protection and generation [35], [36], [37], [12], [14]. We generate trajectories until their combined point count matches the real test set's point count. Then, we compute the HD between both sets. However, the HD is significantly affected by outliers [21], such that we also use the WD.\nB. Wasserstein Distance\nThe HD is prevalent in trajectory comparison but is highly susceptible to outliers, where a single misplaced point can lead to a drastically different HD. To address this, we compare the point distributions directly as proposed in [21]. A key aspect is assessing if the generated data mimics the real data's distribution, such as urban concentration versus rural sparsity. Intuitively, the Wasserstein Distance (WD) treats distributions as piles of dirt, measuring how much 'dirt' must be shifted to transform one distribution into another. Hence, this metric is also known as Earth Mover's Distance (EMD). However,"}, {"title": "C. Total Travelled Distance", "content": "The Total Travelled Distance (TTD) represents the length of the entire trajectory. For a trajectory t = ((X1,Y1), (X2,Y2), ..., (Xn, Yn)), the TTD is defined as:\nTTD(t) = \u2211_{i=1}^{n-1} \u221a(xi+1 - Xi)^2 + (Yi+1 \u2013 Yi)^2\nThe TTD is calculated by computing the total travelled distance for each trajectory in both the real and generated datasets, creating two sets of travel distances. We then use the WD to compare these sets by measuring the discrepancy between their underlying distributions, quantifying how similar the generated data is to the real data regarding travel distances.\nD. Time Reversal Ratio"}, {"title": "V. PROBLEM STATEMENT", "content": "As noted in Section I, location trajectories are valuable for analyses but contain sensitive information. Related work indicates a limiting privacy-utility trade-off in traditional pro-tection methods. Therefore, the generation of synthetic data represents a promising alternative. However, while achieving high utility, current models struggle to provide rigid privacy guarantees [21]. Moreover, while most current methods rely on RNNs, CNN-based architectures have shown success in other sequential domains, and initial experiments with convolutional layers for trajectory generation yield promising results [21]. This leads to our research question: Can a CNN-based GAN produce high-quality synthetic trajectories? To the best of our knowledge, this is the first attempt to utilise a fully CNN-based architecture for trajectory generation. Our primary research question is subdivided into four sub-goals:\nG1: Transformation: Develop a Reversible Trajectory-to-CNN Transformations (RTCT) algorithm that transforms lo-cation trajectories into CNN-compatible inputs. This transfor-mation represents the main contribution of this research.\nG2: Integration: Integrate our transformation with a standard CNN-based GAN, specifically DCGAN (ref. Section II-D), to assess its performance in a PoC. We have chosen an estab-lished GAN model to highlight the flexibility and potential of our proposed transformation. The development of a specialised CNN-based GAN tailored for trajectory synthesis remains an objective for future work.\nG3: Differential Privacy: Apply DP-SGD to both our model and the considered baseline model NTG to determine the impact of formal privacy guarantees on model performance. To the best of our knowledge, this is the first work using DP-SGD for privacy-preserving trajectory generation, providing formal privacy guarantees.\nG4: Evaluation: Evaluate the potential of CNN-based GANs for trajectory generation by conducting an extensive evaluation on two real-world datasets, FS-NYC and Geolife, with the four metrics outlined in Section III. Additionally, we compare our model's performance with the RNN-based model NTG, de-scribed in Section IV. Moreover, we compare the performance of both models trained with DP-SGD to measure the impact of formal privacy guarantees on utility."}, {"title": "VI. REVERSIBLE TRANSFORMATION DESIGN", "content": "To enable the usage of CNN-based GANs for trajectory generation, we propose a Reversible Trajectory-to-CNN Trans-formations (RTCT) addressing G1: Transformation. This transformation, depicted in Figure 1, comprises:\n1) Normalising the trajectories' latitude, longitude, day and hour values (Section VI-A).\n2) Inserting these normalised values into a 12\u00d712\u00d73 matrix (Section VI-B).\n3) Upsampling the resulting matrix to 24 \u00d7 24 \u00d7 3 (Sec-tion VI-B).\nAfter generation, the synthetic trajectories are reverted into sequential form, as detailed in Figure 2 and Section VI-C. Additionally, we demonstrate the potential of using CNN-based models for trajectory generation by integrating our trans-formation with DCGAN [22] into a Proof-of-Concept (POC) implementation, addressing G2: Integration (Section VII).\nA. Normalisation\nNormalisation adjusts dataset features to a common scale, which is essential for deep learning. Typically, data is nor-malised to the range [-1;1] or [0;1] using techniques such as mean and standard deviation, and tanh normalisation [52]. We employ min-max normalisation, which is reversible and scales data features into the range [0; 1], making it ideal for the denormalisation of generated trajectories. For a feature f, with minimum value min and maximum value max, the normalisation value v is defined as:\nv = (f-min) / (max - min)\nThis normalisation method is applied to all features before using the trajectories for model training.\nB. Trajectory Encoding"}, {"title": "VII. DCGAN INTEGRATION", "content": "As highlighted in Section II-D, DCGAN is a popular GAN choice due to its ease of use and versatility. Therefore, we integrated DCGAN with RTCT as a Proof-of-Concept2. Al-though DCGAN was primarily designed for image generation and may not be ideal for trajectories, its adaptability makes it suitable for our PoC addressing G2: Integration, as this work focuses on transformation rather than the generative model itself. In the following, we provide details on the implementation and optimisation strategies.\nA. Implementation\nWe based our PoC on the DCGAN implementation from the PyTorch GAN repository [54]. PyTorch data loaders facilitate dynamic access to data, crucial for training. Our transforma-tion is embedded in the data loader, managing loading raw trajectories from files to the encoding with RTCT.\nPadding and Masking. As described in Section VI-B, CNNs require constant length inputs, unlike RNNs. Therefore, we pad trajectories shorter than the upper limit of 144 points using 0-post padding. Masks based on the trajectories' original lengths are generated, with a vector for a trajectory of length I comprising I ones and 144 I zeros. When applied to trajectories, this masking excludes zero-padding from affecting computations within the computational graph.\nB. Optimising DCGAN"}, {"title": "VIII. DP-SGD", "content": "As discussed in Section IV, the core limitation of existing deep learning models for trajectory generation are the missing formal privacy guarantees. Today's de-facto standard is DP described in Section II-B. Despite efforts to deploy DP for trajectory generation, studies [8], [21] show frequent mis-application, affecting the integrity of the privacy guarantees. Thus, [21] recommends using the established method of DP-SGD, which ensures instance-level DP if each training sample corresponds to one trajectory (see Section II-B).\nTo address G3: Differential Privacy, we implemented DP-SGD for our PoC and the baseline NTG (ref. Section IX-B) to evaluate the impact of DP and allow for comparative analysis. We employed the Opacus [59] library to integrate DP-SGD due to its straightforward interface. This established framework helps us avoid the common pitfalls of custom DP implementations, which have compromised the integrity of privacy guarantees in other studies [21], [8]. Any layers incompatible with DP-SGD were automatically replaced by Opacus' model fixer, in particular, DCGAN's BatchNorm layers were replaced by GroupNorm. Typically, DP-SGD is applied to the discriminator in a GAN [48]. This approach ensures that the generator also adheres to DP through the post-processing property of DP since it only receives indirect data access via feedback from the discriminator. However, we aimed at enabling usage of the WGAN-LP loss, which is reported to yield better results than the standard adversarial loss [60], [61], [21]. Opacus does not support DP-SGD for models trained with gradient penalty at this time. Moreover, the discriminator is updated more frequently than the generator when using WGAN [62] (usually \u2248 5\u00d7 as often), such that adding noise to the discriminator would result in more noise being added by DP-SGD. Therefore, we decided to train the generator with DP-SGD instead, i.e., the noise is added to the generator's gradients instead of the discriminator's gradients. Utilising the MNIST Sequential (MNIST-Seq) as a toy dataset [21], we confirmed that the baseline model NTG could produce samples of comparable quality with DP-SGD applied to the generator as it did without DP-SGD. Due to a bug in the underlying framework, we had to use the standard WGAN loss instead of WGAN-LP for the DP version of the baseline model NTG. The DP version of our PoC was successfully trained with WGAN-LP."}, {"title": "IX. EVALUATION", "content": "This chapter addresses goal G4: Evaluation. Section IX-A details the datasets used and their preprocessing methods. Section IX-B introduces the baseline model, NTG. Subse-quent sections discuss evaluation results: Section IX-C cov-ers parameter choices, Section IX-D outlines the hardware setup, Section IX-E presents results from standard models, Section IX-F focuses on outcomes from training with DP-SGD, and Section IX-G provides a qualitative analysis.\nA. Datasets\nTo demonstrate the generalisability of our approach, we evaluate our implementation on two different datasets. First, the FS-NYC dataset [25], used as a benchmark in LSTM-TrajGAN [12], comprises 3,079 trajectories with a maximum of 144 locations each, primarily within New York City's bounds. We use the dataset as provided in [49] without further preprocessing. Second, the Geolife dataset [26] covers a larger geographical area around Beijing. Moreover, 91% of the dataset's trajectory have a sampling rate of 1-5s or 5-10 m [26] yielding more fine granular trajectories. For con-sistency with FS-NYC, we constrained Geolife's data within the fourth ring road of Beijing4. We capped trajectories at 144 locations and discarded those with fewer than 96 locations to prevent extensive padding. This preprocessing reduced the available trajectories from 17621 to 7270.\nB. Baseline Model"}, {"title": "X. DISCUSSION", "content": "This study's exploration into using CNN-based GANs for trajectory generation has yielded promising insights despite not achieving state-of-the-art results. Our findings indicate that CNN-based models are superior at capturing spatial distributions, whereas RNN-based models better capture se-quential properties, aligning with observations from related work [21]. This difference in performance is likely attributed to the architecture of each model. CNN-based models find patterns in inputs using a sliding window that processes several inputs at once. The RTCT transformation places values in a matrix, such that values within the same window are not necessarily sequentially adjacent. Therefore, sequentiality is not necessarily the model's focus. In contrast, RNN-based layers always process values in a sequential manner, such that sequential dependencies are emphasised. When comparing our prototype with state-of-the-art models such as LSTM-TrajGAN, it is important to note that these models exhibit higher utility because they modify real trajectories rather than generating new samples from Gaussian noise, as our PoC does. While such approaches can improve utility, they may compromise privacy by handling real data directly. Our model, by generating synthetic trajectories, does not incur these privacy issues. Additionally, the primary focus of our work was on the proposed RTCTtransformation, hence the use of DCGAN \"as-is\" without tailoring it for trajectory generation.\nWhile the prototype's ability to approximate spatial distri-butions is promising, its failure to capture finer details like specific street layouts underscores the limitations of the current DCGAN model. This suggests a need for more sophisticated or"}, {"title": "XI. CONCLUSION", "content": "Location trajectories, while valuable for various applica-tions, inherently contain sensitive information, posing signifi-cant privacy concerns. Traditional trajectory privacy-protection mechanisms face a restrictive privacy-utility trade-off. There-fore, deep learning-based generative models have been pro-posed as a promising alternative. Yet, current models do not provide formal privacy guarantees, such as DP. Moreover, they mostly rely on RNN-based architectures. In this work, we 1) introduced a Reversible Trajectory-to-CNN Transforma-tions enabling the usage of CNN-based GANs from computer vision for trajectory generation, 2) integrated this transfor-mation with the well-known DCGAN in a Proof-of-Concept implementation, 3) integrated both this PoC and the baseline work NTG with DP-SGD, and 4) evaluated the resulting four models across two datasets and four metrics. To the best of our knowledge, this is the first instance of a fully CNN-based GAN applied to trajectory generation and the initial application of DP-SGD to ensure privacy in this context. Although our PoC reproduces major density patterns of the datasets, it fails to capture details and is less adept at capturing sequential and temporal patterns. While the Proof-of-Concept does not provide sufficient utility for real-world application, this de-velopment opens promising avenues for further research into the application of generative models from computer vision. This study underlines the potential of CNN-based generative models to either supplement or replace existing RNN-based architectures in trajectory data privacy, encouraging further exploration in this promising research direction."}]}