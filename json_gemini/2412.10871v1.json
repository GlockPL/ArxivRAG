{"title": "Fully Test-time Adaptation for Tabular Data", "authors": ["Zhi Zhou", "Kun-Yang Yu", "Lan-Zhe Guo", "Yu-Feng Li"], "abstract": "Tabular data plays a vital role in various real-world scenarios and finds extensive applications. Although recent deep tabular models have shown remarkable success, they still struggle to handle data distribution shifts, leading to performance degradation when testing distributions change. To remedy this, a robust tabular model must adapt to generalize to unknown distributions during testing. In this paper, we investigate the problem of fully test-time adaptation (FTTA) for tabular data, where the model is adapted using only the testing data. We identify three key challenges: the existence of label and covariate distribution shifts, the lack of effective data augmentation, and the sensitivity of adaptation, which render existing FTTA methods ineffective for tabular data. To this end, we propose the Fully Test-time Adaptation for Tabular data, namely FTAT, which enables FTTA methods to robustly optimize the label distribution of predictions, adapt to shifted covariate distributions, and suit a variety of tasks and models effectively. We conduct comprehensive experiments on six benchmark datasets, which are evaluated using three metrics. The experimental results demonstrate that FTAT outperforms state-of-the-art methods by a margin.", "sections": [{"title": "1 Introduction", "content": "Tabular data (Altman and Krzywinski 2017) plays a vital role in numerous practical applications, including economics (Salehpour and Samadzamini 2024), health-care (Ching et al. 2018), finance (Ozbayoglu, Gudelek, and Sezer 2020), and manufacturing (Hein et al. 2017). Deep neural networks (DNNs) have recently shown remarkable success in handling tabular data, often surpassing traditional statistical methods when training and test data share the same distribution (Arik and Pfister 2021; Gorishniy et al. 2021). However, real-world applications often experience shifts in data distributions during testing, leading to significant performance degradation in existing methods (Kolesnikov 2023).\nTo address distribution shifts during testing, fully test-time adaptation (FTTA) algorithms have emerged, enhancing the performance of pre-trained DNNs using only testing data. These methods are particularly designed to deal with covariate distribution shift (Wang et al. 2021), label distribution shift (Wu et al. 2021), or both (Zhou et al. 2023), adapting the model parameters (Wang et al. 2022) or optimizing the predictions (Boudiaf et al. 2022). However, they are primarily designed for image tasks and heavily rely on image augmentation strategies (Wang et al. 2022) and image-specific data assumptions (Boudiaf et al. 2022; Zhou et al. 2023), rendering them less effective for tabular data. As a result, fully test-time adaptation for tabular data remains underexplored, despite its significance in real applications.\nTo this end, we study the fully test-time adaptation problem setting for tabular data, namely AdaTab, which holds significant practical value (Altman and Krzywinski 2017). For example, in financial applications (Kritzman, Page, and Turkington 2012), the non-stationary financial market environment can cause significant changes in the data distribution between training and testing. For instance, shifts in the stock market can significantly affect market behavior and investor sentiment. These distribution shifts degrade the model performance and seriously affect investment decision-making and risk management, thereby leading to financial losses (Guo, Hu, and Yang 2023). The goal of the AdaTab problem setting is to adapt the trained deep tabular model to unknown distributions using only testing data, preventing the performance degradation caused by distribution shifts in downstream tabular applications.\nIn this paper, we conduct an in-depth investigation into the AdaTab problem. Our four observations reveal three key challenges in designing FTTA methods for tabular data: (a) Covariate and label distribution shifts exist in tabular data, but they cannot be effectively addressed by existing FTTA methods; (b) Typical augmentation for test-time adaptation is often ineffective for tabular data, limiting the ability of FTTA methods to compute consistency; (c) Adaptation is sensitive to both tasks and models for tabular data.\nTo address these challenges, we propose a novel FTTA approach, FTAT. It comprises three essential modules: Confident Distribution Optimizer, Local Consistent Weighter, and Dynamic Model Ensembler, which robustly track and optimize the label distribution of predictions, adapt the model to shifted covariate distribution, and dynamically adapt the model for various tasks and models. To summarize, the contributions of this paper are threefold:"}, {"title": "2 Problem and Analysis", "content": "In this section, we first introduce the AdaTab problem setting, including the notations and problem formulation. We then present four observations of AdaTab, which highlight three main challenges and underscore the necessity of designing FTTA methods specifically for tabular data."}, {"title": "2.1 Problem Formulation", "content": "We consider the fully test-time adaptation problem setting for tabular classification problem, namely, AdaTab. The input space is $X \\in \\mathbb{R}^d$, where d is the number of features. Each feature can be a continuous or discrete value. The label space is $Y \\in \\{0,1\\}^K$, where the K is the number of classes. In this setting, we are given a well-trained source tabular model $f_{\\theta_0}: X \\rightarrow Y$ with the initial parameters $\\theta_0$. During the testing phase, the model is solely adapted based on the unlabeled batched testing data $D_t$ at each timestamp t, updating its parameters from $\\Theta_t$ to $\\Theta_{t+1}$. The goal of AdaTab problem is to adapt the initial given model for during the testing phase, so that the adapted model $f_{\\theta_t}$ can generalize better on the test data $D_t$ at each timestamp t."}, {"title": "2.2 Problem Analysis", "content": "In the context of the AdaTab problem, we have identified four observations that also serve as key challenges hindering FTTA methods from effectively working with tabular data, in contrast to the standard fully test-time adaptation designed for image tasks.\nObservation 1: Covariate distribution and label distribution shifts in tabular data hinder performance of FTTA methods. Our first observation reveals that both covariate distribution and label distribution shifts exist in tabular data, and both contribute to performance degradation. To estimate the distribution shifts between the training and testing datasets, we use the optimal transport dataset distance with Gaussian approximation (Alvarez-Melis and Fusi 2020) to measure covariate distribution shifts and the $L_2$ distance (Gardner, Popovic, and Schmidt 2023) to assess label distribution shifts. However, as our experimental results reveal, existing robust FTTA methods, such as ODS (Zhou et al. 2023), designed to address covariate and label distribution shifts in tabular data, do not perform well in practice. This observation highlights the challenges faced by FTTA methods designed for tabular data in addressing both covariate and label distribution shifts simultaneously. We also estimate the label distribution of data whose model prediction entropy is lower than thresholds on DIABETES dataset. The results demonstrate that we can still accurately estimate the label distribution using only low-entropy data.\nObservation 2: Typical Augmentation used in test-time adaptation is ineffective for tabular data. Existing FTTA methods, rely heavily on data augmentation. However, augmentation for tabular data is not as effective as it is for images. We conduct experiments based on COTTA methods with perturb augmentation with different perturbation strengths controlled by $\\sigma$. As shown in Table 1, the performance of COTTA degrades as the augmentation strength increases, and it fails to surpasses the non-adaptation baseline. This observation highlights the challenges of FTTA methods designed for tabular data, particularly their inability to rely on data augmentation method when dealing with tabular data.\nObservation 3: Adaptation is sensitive to both tasks and models for tabular data. Therefore, for specific tabular tasks and the backbone models used, FTTA methods require tuning for optimal performance. As shown in Fig. 3, the optimal learning rates for different backbone models on the same task and same backbone model on different tasks varies. This observation indicates that the AdaTab problem requires a model capable of dynamically tuning the learning rates, rather than relying on a fixed learning rate.\nObservation 4: Existing FTTA methods degradates when dealing with tabular data. Observations 1, 2, and 3 also serve as key challenges in designing FTTA methods for tabular data, causing existing FTTA methods to fail to improve performance compared to the baseline."}, {"title": "3 Methodology", "content": "In this section, we introduce our FTAT approach for AdaTab problem setting. As discussed in the analysis section, the AdaTab problem encompasses three challenges:\n(a) Covariate and label distribution shifts exist in tabular data, but cannot be effectively addressed by existing FTTA methods;\n(b) Typical augmentation used for test-time adaptation is not very effective for tabular data, limiting the ability of FTTA methods to adopt consistency;\n(c) Adaptation is sensitive to both tasks and models for tabular data.\nTo address the above challenges, we introduce three modules specifically designed for AdaTab problem, i.e., Confident Distribution Optimizer, Local Consistent Weighter, and Dynamic Model Ensembler. Specifically, the Confident Distribution Optimizer optimizes the original model predictions $f_{\\theta_t}(x)$ to $f_{\\theta_t^+}(x)$ for a data point $x$ at timestamp $t$. The Local Consistent Weighter affects the adaptation objective:\n$\\theta_{t+1} = \\arg \\min_{\\theta} \\sum_{i=1}^{D_t} W(x_i, D_t, \\Theta_t) \\cdot Loss(f_{\\theta_t}(x_i)) \\qquad(1)$\nusing a weighting function W, where $Loss(\\cdot)$ represents the unsupervised loss for test-time adaptation, and we employ entropy loss in accordance with classical methods. The Dynamic Model Ensembler maintains multiple models and ensembles their predictions in an online manner. We will introduce them in detail."}, {"title": "3.1 Confident Distribution Optimizer", "content": "First, we aim to optimize the model predictions to align with the current shifted label distribution. The existing solution (Zhou et al. 2023) fails because the challenging nature of tabular data prevents the model from making accurate predictions, which in turn hinders the estimation of the label distribution. Therefore, the key challenge is how to robustly track the shifted label distribution $P_t$ at each timestamp t. With original label distribution $P_0$ and esitmated label distribution $P_t$, the optimized model prediction $f_{\\theta_{t+1}}(x_k)$ for next timestamp on data point $x_k$ is\n$f_{\\theta_{t+1}}(x_k) = f_{\\theta_t}(x_k) \\cdot \\frac{P_t}{P_0} \\qquad(2)$\nMotivated by our observations, we recognize that we can estimate the label distribution $P_t$ with bias from model $f_{\\theta_t}$ at each timestamp t using only data with low-entropy predictions (i.e., data with confident predictions):\n$P_t = \\frac{\\sum_{i=1}^{|D_t|} \\mathbb{I} [\\text{Entropy} (f_{\\theta_t} (x_i)) < \\epsilon] \\cdot f_{\\theta_t} (x_i)}{\\sum_{i=1}^{|D_t|} \\mathbb{I} [\\text{Entropy} (f_{\\theta_t} (x_i)) < \\epsilon]} \\qquad(3)$\nwhere $D_t$ is current data batch, $\\epsilon$ is a threshold, and $\\text{Entropy}(\\cdot)$ is the function for computing entropy of predictions. Note that there exists bias in esitmated $P_t$ as the model predictions may contains errors. To address this issue, we compute the covariate matrix $\\hat{C}_t$ at the current timestamp t, where its k-th row is equal to\n$\\hat{C}_t^{(k)} = \\frac{\\sum_{i=1}^{|D_t|} \\mathbb{I} [\\arg \\max_j f_{\\theta_t} (x_i)_j = k] \\cdot f_{\\theta_t} (x_i)}{\\sum_{i=1}^{|D_t|} \\mathbb{I} [\\arg \\max_j f_{\\theta_t} (x_i)_j = k]} \\qquad(4)$\nThen, the unbiased label distribution is $\\hat{P}_t = \\hat{C}_t P_0$. We additionally adopt a temperal ensemble method to robustly track estimated label distribution smoothly with a factor $\\alpha$ and previous estimated shift $P_{t-1}$:\n$P_t = \\text{Norm} (P_{t-1} - \\alpha \\cdot (\\hat{C}_t - P_t)) \\qquad(5)$\nwhere Norm(.) normalizes the distribution to sum to one, and we use the Softmax function for this purpose."}, {"title": "3.2 Local Consistent Weighter", "content": "Second, to mitigate the adverse effects of shifted covariate distribution, we propose filtering testing data with low-quality predictions to ensure robust test-time adaptation and avoiding error accumulation. However, for tabular data, computing consistency through data augmentation is non-trivial because our observation indicates that augmentation for tabular data is not as reliable as it is for image data.\nTo address this issue, we propose replacing the consistency between a data point and its augmentations with the consistency between a data point and its neighborhood, under the inspiration of one existing tablar study. Specifically, we define the neighborhood set $\\mathcal{N}(x_k, D_t)$ of each data point $x_k$ in current batch $D_t$ measured by one distance function Dist(., .):\n$\\mathcal{N}(x_k, D_t) = \\{x | \\text{Dist}(x, x_k) < \\text{Dist}_t, x \\in D_t\\} \\qquad(6)$\nwhere $\\text{Dist}_t = \\frac{2}{|D_t|(|D_t|-1)} \\sum_{i=1}^{|D_t|-1} \\sum_{j=i+1}^{|D_t|} \\text{Dist}(x_i, x_j)$ is the average pair-wise distance in $D_t$ and we adopt $L_2$ distance as the distance function. Next, we define the prediction of one data point $x_k$ is consistent if its soft pseudo-label vector is close to the average soft pseudo-label vectors in its neighborhood $\\mathcal{N}(x_k, D_t)$. Then, we define the indication function $\\mathbb{I}(x_k, D_t, \\Theta_t)$ to decide whether one data point $x_k$ in current batch $D_t$ is consistent:\n$\\mathbb{I}(x_k, D_t, \\Theta_t) = \\begin{cases} 1, \\quad \\big\\| f_{\\theta_t}(x_k) - \\frac{\\sum_{x \\in \\mathcal{N}(x_k, D_t)} f_{\\theta_t}(x)}{|\\mathcal{N}(x_k, D_t)|} \\big\\| < \\beta, \\\\ 0, \\quad \\text{Otherwise}. \\end{cases} \\qquad(7)$\nwhere $\\Theta_t$ is the parameters of model at timestamp t, $f_{\\theta_t}(\\cdot)$ predicts pseudo-label of data point, and $\\beta$ is a hyperparameter to control the degree of consistency. To additionally ensure the robustness of adaptation, we compute the uncertainty of each data point using margin of prediction as $\\max f_{\\theta_t}(x_k) - \\min f_{\\theta_t}(x_k)$. Finally, our proposed local consistent weighter $W(x_k, D_t, \\Theta_t)$ is formulated as follows:\n$W(x_k, D_t, \\Theta_t) = [\\max f_{\\theta_t}(x_k) - \\min f_{\\theta_t}(x_k)] \\cdot \\mathbb{I}(x_k, D_t, \\Theta_t) \\qquad(8)$"}, {"title": "3.3 Dynamic Model Ensembler", "content": "Third, to address the sensitivity issue of adaptation, we employ the online ensemble learning paradigm to optimize multiple models with different learning rates and ensemble their outputs through weighted averaging to obtain the overall robust prediction. Specifically, we maintain M models using different learning rates during the testing, denoted as the set of base models $\\{f_{\\theta_i}\\}_{i=1}^M$. Then, model predictions are weighted according to corresponding loss values $w_i \\propto 1 - \\mathcal{R}_i(D_t)$, where $\\mathcal{R}_i(D_t)$ is the loss value of i-th model for evaluated on current batched data $D_t$ and satisfies the constraint $\\sum_{i=1}^{M} w_i = 1$. The final prediction of the FTAT approach is obtained by weighted ensemble for a data point x, that is, $\\sum_{i=1}^{M} w_i f_{\\theta_i}(x)$."}, {"title": "4 Experiments", "content": "In this section, we first introduce the experimental setup. Next, we present our empirical results, comparing our FTAT approach with existing FTTA methods. Finally, we conduct an ablation study and provide further analysis for our proposed method."}, {"title": "4.1 Experimental Setup", "content": "Evaluation Protocol. In our experiments on tabular tasks, we follow the fully test-time adaptation setting, where the source model is trained on training data and adapted to shifted test data without any access to the source training data. Specifically, we train the source model on training data and select the best model based on the validation set following the TableShift benchmark. Then, FTAT approach and existing FTTA methods are evaluated on the shifted test set. We select six common tabular benchmark datasets from the TableShift benchmark, which exhibit significant performance gaps under distribution shifts. Therfore, these datasets contains samples from 10K to 5M and features from 26 to 365, which can cover a wide range of tabular scenarios under distribution shifts. All experiments are repeated with different random seeds, and the mean and standard deviation are reported.\nComparison Methods. To compare our FTAT apporach with various FTTA methods, including typical FTTA methods, continual FTTA methods, and recently proposed robust FTTA methods.\n4.2 Main Results\nTo evaluate the effectiveness of FTAT, we report the detailed experimental results using three backbone models. The performance are measured by three metrics including accuracy, balanced accuracy, and F1 score. The experimental results show our FTAT approach outperforms existing methods by a margin on all metrics.\nMoreover, we report the detailed results on each dataset using MLP backbone model in Tab. 4. FTAT achieves the best performance on major cases and give competitive performance on the resting cases, demonstrating the effectiveness of FTAT on various tabular datasets with different backbone models. The detailed results using FT-Transformer and TabTransformer are included in our supplementary material due to the space limits.\nOur experimental results confirm our last observation, showing that existing FTTA methods face performance degradation on tabular data with distribution shifts, thereby demonstrating the necessity to study the AdaTab problem. Our FTAT approach consistently outperforms non-adaptation baseline and existing FTTA methods in most cases, offering insights into this challenging problem."}, {"title": "4.3 Further Analysis", "content": "Ablation Study. We analyze the effectiveness of the Confident Distribution Optimizer and the Local Consistent Weighter  in Tab. 5 on DIABETE and HELOC datasets using the MLP backbone model. Without CDO, the performance of FTAT approach improves marginally, which indicates that the label distribution shift hinders the performance and CDO addressing the label distribution shift plays a more important role in the FTAT approach. Without LCW, the performance of FTAT cannot achieve the optimal level, demonstrating the essential role of LCW to robustly update the model. Overall, our FTAT approach achieves the best performance when both CDO and LCW are employed, demonstrating their effectiveness in addressing challenges of FTTA for tabular data.\nEstimation of Label Distribution. We compare the performance in estimating label distribution on the DIABETE dataset using the MLP backbone model. We adopt KL divergence to measure the distance between the ground-truth label distribution and its estimation. The LAME method cannot accurately estimate the label distribution. While the ODS method can robustly track the label distribution, it requires several iterations to converge to an accurate estimation. In contrast, our FTAT approach achieves accurate label distribution estimation at a much faster speed. This result demonstrates the superiority of FTAT approach.\nEffects of Dynamic Model Ensembler.  To validate the effectiveness of Dynamic Model Ensembler, we conduct experiments running with base models with different learning rates, ensemble baseline, and FTAT approach. Here, we compare with four base models with different learning rates $\\{1e - 3, 1e - 4, 5e - 4, 1e - 5\\}$. The ensemble baseline are the direct ensemble of these base models.  The results show that our Dynamic Model Ensembler module consistently outperforms the average ensemble baseline, demonstrating the its effectiveness. Moreover, the FTAT approach can achieve the best performance or competitive performance when compared to base learners with the optimal learning rate without requiring tuning, indicating the advantage of our Dynamic Model Ensembler module.\nRobustness of Batch Size.  In the main experiments, the batch size of the data stream is set to 512 due to the large quantity of testing data. A natural question that arises is how the batch size affects the performance of the proposed method. We conduct experiments on the DIABETE dataset using an MLP backbone model, with batch sizes set to $\\{64, 128, 256, 512, 1024\\}$. , the results indicate that the accuracy and balanced accuracy metrics are robust across different batch sizes. Regarding the F1 score, it decreases as the batch size increases. Nevertheless, FTAT consistently outperforms existing methods by a margin.\nRobustness of Hyperparameters. To validate whether our proposed FTAT approach is robust to the choices of hyperparameters, we conduct hyperparameter robustness experiments on DIABETE dataset evaluated by three metrics using MLP backbone model. Specifically, FTAT contains three hyperparameters, i.e., $\\epsilon$, $\\alpha$ and $\\beta$. The hyperparameter $\\alpha$ controls the rate at which the estimated label distribution is updated, enhancing the robustness of the FTAT to estimation errors in certain batches. The hyperparameter $\\epsilon$ governs the entropy-based confident samples selection to accurately estimate the label distribution. $\\beta$ determines the construction of the neighbor set for entropy minimization, contributing to robust model adaptation. We conducted three runs of experiments for each set of hyperparameters with $\\alpha$ in $\\{0.08, 0.09, 0.10, 0.11, 0.15, 0.20\\}$, $\\epsilon = Entropy([p, 1 \u2013 p])$ where p was set to $\\{0.72, 0.71, 0.70, 0.69, 0.65, 0.60\\}$, and $\\beta$ in $\\{0.28, 0.29, 0.30, 0.31, 0.40, 0.50\\}$. The results demonstrate that FTAT is robust to slight changes in all hyperparameters."}, {"title": "5 Related Work", "content": "In this section, we mainly discuss two lines of related work, including test-time adaptation and deep tabular learning.\nTest-time Adaptation. Test-time adaptation aims to adapt a source model to the distribution shift in testing data without using any source data. Previously, test-time training studies, such as TTT  and TTT+ , manipulated the model in both the training and testing phases. They introduce self-supervised objectives at training time and adapt the model parameters by optimizing self-supervised objectives at testing time. However, when training data is inaccessible and model training cannot be controlled, test-time training paradigms become ineffective. Fully test-time adaptation aims to tackle this limitation by adapting the model without assumptions on the source model. Tent  updates the parameters of the BN layer at test time. EATA additionally conducts active sample selection and weighting strategies for efficiency. Other studies also propose diverse methods to adapt the BN layer to the test data distribution to ensure performance. In practice, SAR introduces a flat minimum optimization method to ensure generalization performance when the test batch size varies. CoTTA  works on continually non-i.i.d. scenarios using weight-averaged models, augmentation-averaged predictions, and stochastically restoring. LAME  proposes a conservative approach to revise the model's predictions instead of model parameters. ODS  focuses on test-time adaptation settings where covariate and label distributions change together. Recent TTA studies mainly focus on images and natural language, paying little attention to tabular data. AdapTable  studies test-time adaptation for tabular data, effectively designing a graph-based module to address label shifts and providing insightful theoretical analyses. TabLog  is the first to examine the structure of invariant rules for tabular data in the context of test-time adaptation. However, these stduies require the training data to be available, which cannot be applied in our AdaTab problem setting and is not practical in real-world scenarios. Therefore, our paper focuses on the fully test-time adaptation problem for tabular data, an area that remains underexplored.\nDeep Tabular Learning. Deep Tabular Learning aims to model tabular data for tasks such as classification and regression through deep learning methods. Unlike image and language data, the heterogeneity and high dimensionality make it difficult for models to extract spatial and semantic information. Recently, attention-based architectures have been introduced to the tabular data domain. FT-Transformer  applies a feature tokenizer to heterogeneous feature columns and learns an optimal representation in embedding space. Additionally, TabTransformer , TabNet , and other deep tabular models are proposed for better representation of tabular data. However, these methods typically works well in an i.i.d. setting, and may suffer from performance degradation when the test data distribution shifts."}, {"title": "6 Conclusion", "content": "In this paper, we investigate the problem of fully test-time adaptation for tabular data (AdaTab), an important and practically valuable issue that remains underexplored. Our observations highlight three key challenges in the AdaTab problem: the existence of label and covariate distribution shifts, the lack of effective data augmentation, and the sensitivity of model adaptation. To address these challenges, we propose the FTAT approach, which includes three novel modules: Confident Distribution Optimizer, Local Consistent Weighter, and Dynamic Model Ensembler. Our experimental results demonstrate that the FTAT approach outperforms existing FTTA methods, demonstrating its effectiveness in addressing tabular tasks.\nOne limitation of this paper is that the design of FTAT approach lacks deep theoretical understanding and we will explore in this direction in the future to provide deep insights for the following researchers."}, {"title": "Appendix", "content": "The structure of Appendix is as follows:\n\u2022 Section A provides detailed experimental setup and implementations.\n\u2022 Section B presents detailed experimental results.\n\u2022 Section C discusses the border impact."}, {"title": "A Detailed Experimental Setup", "content": "We have briefly introduced experimental setup in our main manuscript. Here, we provide detailed experimental setup and implementations in this section."}, {"title": "A.1 Details of Comparison Methods", "content": "To compare our FTAT apporach with various FTTA algorithms, including typical FTTA methods, continual FTTA methods, and recently proposed robust FTTA methods. For typical TTA methods, we take two novel method into comparison:\n(1) TENT (Wang et al. 2021) updates the model parameters with entropy minimization loss;\n(2) EATA (Niu et al. 2022) performs activate sample selection for adaptation and Fisher regularization for anti-forgetting to achieve strong predicting performance.\nFor continual TTA methods, we compare with:\n(3) COTTA (Wang et al. 2022) eliminates error accumulated in the data stream via weight-and-augmentation averaged pseudo-labels and parameters stochastic restoration. We adopt the perturb augmentation (Fang et al. 2022) as data augmentation methods for tabular data.\nFor robust TTA methods, we take various proposed methods into comparison:\n(4) SAR (Niu et al. 2023) conducts sample filtering based on test entropy and update model parameters to a flat minimum to achieve well and robust performance;\n(5) LAME (Boudiaf et al. 2022) modifies model output by adopting a conservative adaptation approach;\n(6) ODS (Zhou et al. 2023) decouples the mixed distribution shift and then addresses covariate and label distribution shifts accordingly."}, {"title": "A.2 Implementations Details", "content": "In this subsection, we provide the details of backbone model, configuration of training and testing phase to enhance the repor-ducibility. All experiments are conducted on a Linux server with one NVIDIA GeForce RTX 3050Ti GPU.\nBackbone Models. For all experiments, we use three representative deep tabular models: MLP, Tabtransformer and FT-Transformer as the backbone model.\nTraining Phase. For training the source model, we follow the TableShift benchmark (Gardner, Popovic, and Schmidt 2023) for all setting of training hyperparameters. Specifically, we train each backbone model with a batch size of 512 for several epochs, depending on the model's convergence as evaluated on the validation set. The AdamW optimizer is used with a learning rate of 0.01 and a weight decay of 0.01.\nTesting Phase. For test-time adaptation, we set the batch size to 512 due to the large number of samples in each test set. For the online model ensemble, we configure three base learners with different learning rates: le - 5, 5e - 4, and le - 4. We set the hyperparameters of FTAT to a = 0.1, \u03b5 = 0.611, \u03b2 = 0.3 for all experiments to demonstrate its robustness to hyperparameters. The value of e is computed by the function E(p) = Entropy([p, 1 \u2013 p]), with p set to 0.7. For comparison methods, we use their original hyperparameters in their paper. We report mean \u00b1 stdev accuracy, balanced accuracy and F1 score over three runs using different random seeds."}, {"title": "A.3 Dataset Details", "content": "We conduct experiments on tabular datasets with natural distribution shifts from the TableShift benchmark. We selected six datasets suffering notable performance degradation under distribution shifts and containing sufficient sample sizes for adaptation, to demonstrate the effectiveness of our FTAT approach. Overall, we conduct experiments with samples from 10K to 5M and features from 26 to 365, including HELOC, ANES, ASSISTMENTS, DIABETES, Hypertension and Health Ins, which are widely used in various applications. We give the details of each dataset as follows.\nDIABETES. Effective management and treatment of diabetic patients admitted to the hospital can have a significant impact on their health outcomes. Several factors can affect the quality of treatment patients receive. One of the costliest and potentially most adverse outcomes after a patient is released from the hospital is for that patient to be readmitted soon after their initial release. Thus, predicting the readmission of patients is a priority from both a medical and economic perspective. DIABETE dataset which contains 1,444,176 samples predict whether a diabetic patient is readmitted to the hospital within 30 days of their initial release using 183 related features.\nHypertension. Hypertension, or systolic blood pressure (typically systolic pressure 130 mm Hg or higher or diastolic 80 or higher) affects nearly half of Americans. When left untreated, hypertension is associated with the strongest evidence for causation of all risk factors for heart attack and other cardiovascular disease . As a result, it is important to predict blood pressure accurately and efficitively. Hypertension dataset has a goal to achieve efficitive blood pressure measurement and increase the prediction accuracy. Hypertension dataset contains 846,781 samples with 100 features related to several risk factors for hypertension.\nHealth Ins. Public health insurance makes a significant performance in providing affordable and accessible medical care for individuals. A high level of health insurance ownership is important for the healthy development of the individual. So, it is important to raise the rate of owning health insurance. Health Ins. dataset is related to public coverage field and the goal is to predict whether an individual is covered by public health insurance using 135 features. The number of samples in Health Ins. dataset is 5,916,565."}, {"title": "B Detailed Experimental Results", "content": "We neglect the detailed experimental results of TabTransformer and FT-Transformer backbone models in our main manuscript due to the space limit. The neglected results are presented in Tab. 8 and Tab. 7. The results show that our FTAT approach gives the best performance on majority of datasets, demonstrating the effectiveness of our approach. In the remaining cases, FTAT approach achieves competitive performance compared to the best-performing method."}, {"title": "C Broader Impact", "content": "This paper aims to advance the field of deep tabular learning by addressing the negative effects of distribution shifts that occur during the testing phase. We believe our work has many potential societal impacts, the majority of which are positive and none of which need to be highlighted here."}]}