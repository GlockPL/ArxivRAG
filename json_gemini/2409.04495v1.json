[{"title": "Learning to Solve Combinatorial Optimization under Positive Linear Constraints via Non-Autoregressive Neural Networks", "authors": ["Runzhong WANG", "Yang LI", "Junchi YAN", "Xiaokang YANG"], "abstract": "Combinatorial optimization (CO) is the fundamental problem at the intersection of computer science, applied mathematics, etc. The inherent hardness in CO problems brings up challenge for solving CO exactly, making deep-neural-network-based solvers a research frontier. In this paper, we design a family of non-autoregressive neural networks to solve CO problems under positive linear constraints with the following merits. First, the positive linear constraint covers a wide range of CO problems, indicating that our approach breaks the generality bottleneck of existing non-autoregressive networks. Second, compared to existing autoregressive neural network solvers, our non-autoregressive networks have the advantages of higher efficiency and preserving permutation invariance. Third, our offline unsupervised learning has lower demand on high-quality labels, getting rid of the demand of optimal labels in supervised learning. Fourth, our online differentiable search method significantly improves the generalizability of our neural network solver to unseen problems. We validate the effectiveness of this framework in solving representative CO problems including facility location, max-set covering, and traveling salesman problem. Our non-autoregressive neural solvers are competitive to and can be even superior to state-of-the-art solvers such as SCIP and Gurobi, especially when both efficiency and efficacy are considered. Code is available at https://github.com/Thinklab-SJTU/NAR-CO-Solver", "sections": [{"title": "Introduction", "content": "Combinatorial optimization (CO) refers to a class of non-convex optimization problems with discrete decision spaces, named for its decision space often \"exploding combinatorially\" with increasing parameters. As a shared problem in computer science, applied mathematics, and management science, CO has a long research history, e.g., Euler [1] in the 18th century initiated the study of graph theory, and the pioneering big names such as Birkhoff[2], von Neumann [3], and Dantzig[4] systematically studied CO in the 1940s-1950s. Most researchers agree that apart from a few \"simple\" problems, most CO problems are NP-hard and thus cannot be solved exactly in polynomial time. Nonetheless, with the growth of computational power and machine learning advancements, improving the performance boundaries of current solvers remains an active research direction."}, {"title": null, "content": "This is the English version of the paper published on Scientia Sinica Informationis. Please cite this paper as \"Wang et al, Learning to Solve Combinatorial Optimization under Positive Linear Constraints via Non-Autoregressive Neural Networks. Scientia Sinica Informationis (2024)\". Submitted 2023-09-17; Accepted 2024-06-17; English version 2024-09-05.\nCorresponding to: Junchi YAN (yanjunchi@sjtu.edu.cn)"}, {"title": null, "content": "In particular, Turing Award laureate Prof. Yoshua Bengio noted that fitting and solving CO problems under a specific distribution is often easier than developing a general-purpose solver [5] . Compared to traditional solvers that typically run on CPUs [6-7], neural network algorithms running on GPUs can fully exploit the power of parallelism. Moreover, due to their ability to fit data distributions, neural networks hold significant potential as CO solvers. However, how to design a neural CO solver with the expected performance improvement remains an open problem [8-9], with the primary challenge being ensuring that the network output satisfies specific discrete constraints.\nA common solution is to build autoregressive neural networks, which output solutions step- by-step, applying rules at each step to ensure the final solution lies in the feasible domain [10-11]. While autoregressive networks have gained wide application in CO due to their generality, they face challenges such as error accumulation, large action spaces, sparse reward signals, and the difficulty in modeling the permutation invariance of the problem space.\nThis paper introduces a non-autoregressive neural network architecture as a CO solver. The non-autoregressive network outputs all decision variables in one forward pass, avoiding the issues of autoregressive models. Additionally, non-autoregressive networks are a mature architecture with proven efficiency and accuracy in fields such as computer vision [12-14] . The latest theoretical research also shows that neural networks (especially graph neural networks that break symmetry with random features) can solve CO problems, such as mixed-integer programming [15]. To tackle the technical challenges (i.e., neural network outputs are typically unconstrained, while CO problems require the network to output constrained solutions), this paper introduces the Linear Satisfiability Network (LinSATNet) [16], which projects network outputs into the feasible domain defined by positive linear constraints:"}, {"title": null, "content": "$Ax < b, Cx > d, Ex = f, where A, b, C, D, E, f > 0, x \u2208 [0, 1]^l.$\nThis covers many common CO problems, such as the knapsack problem, where constraints w\u00afx \u2264 m can be handled as \"positive linear constraints.\""}, {"title": "Related Work", "content": "We follow the survey[18] to categorize neural CO solvers into autoregressive and non-autoregressive.\nAutoregressive Neural Solvers for Combinatorial Optimization. Autoregressive neural networks are widely used in sequence learning, where the output at time (t+1) depends on the output at time t. In the context of CO, autoregressive neural solvers gradually construct a complete solution step by step. Thus, for problems where decision variables have a dimension of l, autoregressive neural networks need O(l) steps. The advantage of autoregressive networks lies in their ability to restrict the action space at each step, eliminating invalid solutions. This paradigm was first applied to CO in [10]. Later, Khalil et al. [11] showed that this multi-step decision process could naturally be modeled as a Markov decision process, allowing reinforcement learning algorithms to train the network [19]. Due to their flexibility, the \"autoregressive network + reinforcement learning\" paradigm has become a mainstream research direction, with applications in scheduling [20],"}, {"title": null, "content": "task assignment [21], quadratic assignment [22], bin packing [23], and more. However, autoregressive networks are prone to accumulating errors over long decision sequences and struggle to model permutation invariance, which may limit their performance and generalization.\nNon-Autoregressive Neural Solvers for Combinatorial Optimization. Many CO prob- lems are offline and unrelated to sequential processes. Therefore, non-autoregressive networks, which are widely adopted in other machine learning tasks, seem to be a more natural choice for CO. As early as the 1980s, Hopfield networks were proposed to solve the traveling salesman problem (TSP) [24], using neural networks and gradient descent for direct search, demonstrating the advantages of search in continuous space. More recently, Karalias et al. [25] proposed a more efficient non-autoregressive neural network, where constraints are handled as penalty terms during training. However, this approach struggles to strictly enforce constraints, and learned constraint information often fails to generalize to new problems [26] . Our prior study [26] further explored different network designs and derived theoretical upper bounds on constraint violations, experimentally verifying that higher violation rates lead to worse neural solver performance.\nThis paper demonstrates that the gradient-based search capabilities of non-autoregressive networks provide an advantage, allowing the solver to search for better solutions during inference. The work by Qiu et al. [27] emphasizes the importance of gradient search for CO problems. Though they used the higher-variance REINFORCE technique [28] for constraint handling, their approach differs from ours, which combines Gumbel reparameterization and the LinSAT layer."}, {"title": "Non-Autoregressive Neural Solvers for Combinatorial Opti- mization", "content": null}, {"title": "Problem Formulation", "content": "Unless otherwise stated, lowercase bold letters mean vectors, and uppercase bold letters mean matri- ces. The non-autoregressive network framework proposed in this paper solves binary combinatorial optimization problems with the following form of positive linear constraints:"}, {"title": null, "content": "$\\min J(x, w),$\ns.t. $Ax < b, Cx > d, Ex = f, x \u2208 {0,1}^l.$\nHere, x represents the decision variables, also known as the solution; w represents the problem parameters; J(x, w) is the objective function (for maximization problems, we minimize the negative objective); the elements in A, b, C, d, E, f are non-negative, and the three sets of constraints may not all exist simultaneously. The input to a CO problem is w and the constraints, and the output is a solution x that (as much as possible) minimizes J(x, w) within a given time."}, {"title": "Framework Building Blocks", "content": "This section describes the building blocks of the non-autoregressive CO solving framework shown in Figure 1.\nGraph Modeling: Neural networks struggle to process inputs directly in the mathematical form of (2), so a general solution is to model the problem parameters as a graph. Different problems have different graph modeling methods, but there is a general best practice: decision variables must correspond to node classification or edge classification tasks on the graph. For single-graph"}, {"title": null, "content": "CO problems (e.g., graph cuts, node covers, TSP), the modeling process is relatively straightfor- ward [11,29-30]; if there are two graphs (e.g., graph matching), an auxiliary graph that integrates the structures of both graphs can be constructed [31]; for Boolean satisfiability problems, there is also a corresponding graph modeling method, where the conjunctive normal form is represented as a bipartite graph [32]; for general matrix-form problems (e.g., linear integer programming), a common approach is to construct a bipartite graph with Ax < b constraints [33] . In summary, for most CO problems, there exists a reasonable graph modeling method. Readers are encouraged to refer to the literature mentioned above for specific problem modeling methods.\nGraph Neural Networks (GNNs): Node classification or edge classification problems on graphs are naturally handled by GNNs [34]. There are many GNN variants, but node classification GNNs typically follow the general framework shown in Figure 3 [35]: in each layer of a GNN, when node 0 needs to be updated, it only considers its neighboring nodes (a, b, c, d). For each neighbor, a message function ($f_{msg}$, typically a multi-layer neural network) transforms its current node feature into a message (e.g., msga). Next, an aggregation function ($f_{agg}$, which could be mean, sum, or attention mechanism [36]) aggregates the messages from all neighbors into the current node. In every GNN layer, the weights of $f_{msg}$ and $f_{agg}$ are shared across all nodes. The choice of $f_{msg}$ and $f_{agg}$ determines the GNN variant used, with common choices including GCN [34], GraphSage [37], and GIN [38]. For edge classification problems, features can be propagated to edges from neighboring nodes, or node classification can be performed on the dual graph.\nLatent Code: For problems modeled as node classification, if the decision variable dimension is l, a GNN with a Sigmoid activation function will output a vector of dimension l with values in [0, 1], referred to as latent code. The l-dimensional real-valued space forms a latent space, where each point corresponds to a distribution of feasible solutions. This mapping is achieved using Gumbel reparameterization and the LinSAT constraint layer. Importantly, the latent space is continuous; by searching and optimizing within the latent space, better decision variables can be found.\nGumbel Reparameterization: The purpose of this step is to treat the latent code as a distribution over feasible solutions and sample from this distribution to obtain feasible solutions. However, discrete sampling is not differentiable, so we use Gumbel reparameterization [17,39-40] to approximate discrete sampling. Given the Gumbel distribution"}, {"title": null, "content": "$g_{\\sigma}(u) = -\\sigma \\log(-\\log(u)),$\nwhere \u03c3 controls variance and u is sampled from a uniform (0, 1) distribution, we apply this to the GNN's output y \u2208 $R^l$:\n$\\tilde{y} = [y_1 + g_{\\sigma}(u)_1, y_2 + g_{\\sigma}(u)_2,\\ldots, y_l + g_{\\sigma}(u)_l],$."}, {"title": null, "content": "where all $g_{\\sigma}(u)_i$ are independent and identically distributed. To better estimate the feasible solution distribution, this sampling process needs to be repeated. Sampling can be done in parallel using batch processing on GPUs. More samples provide a more accurate estimate of the distribution but increase computational cost.\nLinSAT Constraint Layer: After Gumbel reparameterization, we project \u1ef9 into the constraint space:\n$x = \\text{LinSAT}(\\tilde{y}, A, b, C, d, E, f),$\nresulting in x \u2208 [0,1]\u00b9, a quasi-discrete solution that remains continuous and differentiable. As introduced in Wang et al. [16], LinSAT ensures that the solution satisfies the given constraints, while Gumbel reparameterization ensures that the output is quasi-discrete without cutting off gradients. The larger the Gumbel coefficient \u03c3, the closer the output is to a discrete solution.\nThe underlying mechanism of LinSAT is based on optimal transport. Optimal transport studies how to transform one marginal distribution u into another marginal distribution v with minimal cost, given a distance matrix. By constructing appropriate marginal distributions, we find that the projection process for a single linear constraint can be formalized as an optimal transport problem. For instance, for the constraint $a^T x < b$, a matrix \u0393 satisfying the following distribution is a feasible projection (with d being dummy variables):"}, {"title": null, "content": "$\\Gamma = \\begin{bmatrix} \\delta_0 & \\delta_1 & \\delta_2 & \\cdots & \\delta_l & b \\\\\\ x_1 & x_2 & \\cdots & x_l & d \\end{bmatrix};$\n$u = [a_1\\  a_2 \\  \\cdots\\ a_l\\  b], v = [\\frac{b}{ \\sum_{i=1}^l a_i },\\  \\cdots, \\frac{b}{ \\sum_{i=1}^l a_i }],$\nwhere optimal transport ensures the row sums equal v and the column sums equal u. For the other two constraints $c^T x > d$ and $e^T x = f$, a similar optimal transport form can be constructed. The optimal transport problem can be solved approximately using a differentiable algorithm [41], naturally compatible with neural networks. LinSAT extends the optimal transport algorithm to handle multiple sets of constraints simultaneously while maintaining differentiability and convergence.\nObjective Function Estimation: One of the key advantages of non-autoregressive networks is their ability to directly estimate the objective function, which can be used as the loss function for unsupervised learning (assuming minimization problems):\n$L(\\theta) = E_{u \\sim N(0, I^{l \\times l})}[J(f(u, y_\\theta), w)],$\nwhere $y_\\theta$ is the GNN's output, and f(\u00b7) represents Gumbel reparameterization (with u sampled from a standard normal distribution) and the LinSAT layer. Equation (7) computes the mean objective value under the Gumbel distribution, providing a more accurate estimate than directly using the network's output. Once x = f (u, yo) is obtained, computing J(x, w) is straightforward. For linear objective functions like J(x, w) = $x^T w$, it can be directly computed. However, some CO problems involve more complex objectives, such as min/max operations, which should be avoided in practice because they truncate gradients. In the facility location problem discussed in Section 4.1, the objective function $ \\sum_{i=1}^m \\min( \\{\\Delta_{i,j}| \\forall x_i = 1\\})$ can lead to poor results. Replacing min with a softmin operator, such as a softmax with temperature \u1e9e, significantly improves performance. The best practice for objective function estimation is to retain gradients as much as possible and replace min/max operators with softmin/softmax to ensure smoothness.\nUnsupervised Offline Pretraining: The differentiable nature of non-autoregressive networks supports unsupervised pretraining. During training, the mean objective function in equation (7) can serve as an unsupervised loss function. The forward propagation during training is shown with"}, {"title": null, "content": "black arrows in Figure 1, and backpropagation is shown with brown arrows. By minimizing this loss function during training and updating the GNN weights, the network learns to map the problem's graph representation to a good latent space.\nOnline Gradient Search and Inference: A single network output often cannot provide a sufficiently good solution, and several studies highlight the necessity of further optimization and search based on the neural network's output [42,27,43-44,25,45]. Our non-autoregressive network paradigm supports classic search methods like beam search and Monte Carlo tree search (MCTS). More importantly, the differentiable nature of our framework provides the gradient direction to optimize the objective function in the latent space, and the parallel nature allows both forward computation and gradient propagation to be done efficiently on GPUs. During the inference stage, with the network parameters \u03b8 fixed, equation (7) can be rewritten as\n$L(y) = E_{u \\sim N(0, I^{l \\times l})}[J(f (u, y), w)],$\nwhere the gradient is propagated to update the latent code y rather than the network parameters. This is analogous to a new neural network training problem, where the goal is to optimize and search for better solutions via gradient optimization in the latent space. As shown in Figure 2, for a specific problem instance, better latent code can be found through this process. Compared to the full dataset training, optimization on a single problem instance is more efficient and converges faster. Additionally, problem-specific neighborhood search algorithms can be designed to quickly search around the current best solution in each iteration. Experiments show that, when combined with offline training, this gradient-based search method can rival or even outperform professional solvers like SCIP and Gurobi."}, {"title": "Further Discussions", "content": null}, {"title": "Expressive Power of Graph Neural Networks for Combinatorial Opti- mization", "content": "GNNs were initially developed to process \"common\" graph structures such as social networks. However, current theoretical studies on GNN expressivity often begin with graph isomorphism problems, which are a form of CO. The mainstream view is that the expressivity of GNNs is comparable to the Weisfeiler-Lehman (WL) graph isomorphism test [46,38]. Although the graph isomorphism problem is also a CO problem, it should be noted that the WL test is an approximate algorithm, a sufficient but not necessary condition for graph isomorphism. Whether GNNs have the expressivity to solve any CO problem remains an open question. However, practical experience in machine learning for CO shows that GNNs are up to the task [11,33,25]. Furthermore, recent theoretical research has shown positive results. For example, Chen et al. [47,15] proved that GNNs have enough expressivity to predict feasibility, optimal objective values, and optimal solutions for linear and mixed-integer programming problems. Hence, this paper chooses GNNs as the primary neural network architecture, though the framework is flexible enough to support more expressive neural networks."}, {"title": "Advantages of Gumbel Reparameterization", "content": "This paper adopts Gumbel reparameterization [17] to enable differentiable sampling in (nearly) discrete spaces, offering two main advantages."}, {"title": null, "content": "First, Gumbel reparameterization allows more accurate gradient computation. A defining char- acteristic of CO problems is that the feasible domain of decision variables is non-continuous, which conflicts with the continuous nature of neural networks. The non-continuous feasible domain presents a challenge for end-to-end gradient computation: if the network output is discrete, the input-output mapping becomes a piecewise function [48]. A piecewise function has gradients that are impulse (delta) functions, providing little meaningful information for the network. Discarding the discrete part of the constraints retains gradients, but this turns the training problem into a relaxed continuous optimization problem. In many cases, this is a simpler convex optimization problem, fundamentally different from the actual CO problem, and a network trained on convex optimization may not generalize to more difficult CO problems. By introducing Gumbel reparameterization, we ensure that the network outputs are as close to the discrete domain as possible without cutting off gradients, resulting in more accurate gradients during optimization.\nSecond, Gumbel reparameterization enables parallel sampling during inference. In this paper, each latent variable corresponds to a distribution over feasible solutions. During inference, Gumbel reparameterization samples from this distribution. More precise gradients lead to faster latent variable updates during optimization, and the randomness introduced by Gumbel reparameterization gives the network a higher chance of finding better solutions. Furthermore, the sampling process is parallelizable, and batch operations allow it to be efficiently executed on GPUs, making it more efficient than traditional sampling and search algorithms [31,49]."}, {"title": "Revisiting Deep Learning Frameworks", "content": "The success of deep learning in recent years is largely due to the development of GPU computing and efficient open-source deep learning frameworks (especially the highly optimized low-level implementations). One reason for the success of the proposed non-autoregressive framework is its ability to leverage these high-efficiency deep learning frameworks. With good support for GPUs and efficient low-level code, operations like Gumbel sampling and objective function estimation for multiple quasi-discrete solutions can be performed in parallel on GPUs. Additionally, deep learning frameworks provide highly efficient large-scale gradient optimization algorithms. Our framework reuses the automatic differentiation capabilities of deep learning frameworks, especially during inference, where automatic differentiation is used to update latent code, enabling efficient online gradient-based search."}, {"title": "A Meta-Learning Perspective on Combinatorial Optimization", "content": "Qiu et al. [27] were the first to propose a meta-learning perspective (more precisely, model-agnostic meta-learning [50]) for CO. In the pretraining stage, the neural network learns a set of initial weights that are effective across the entire dataset. In specific CO problems, the network weights can be further updated to obtain better solutions. Our framework can also be understood from a similar meta-learning perspective, but here the meta-learning object shifts from the neural network weights to the lighter latent code: in the pretraining stage, the network outputs learn to map to a set of latent codes that are effective across the entire dataset; for specific CO problems, the latent code can be further optimized via gradient descent to obtain better solutions."}, {"title": "Experiments and Analysis", "content": "This paper demonstrates the effectiveness of non-autoregressive networks on facility location, max- set covering, and traveling salesman problems, comparing our approach to existing neural network methods [25-26] and traditional MILP solvers [51-52]. In the facility location and max-set covering experiments, the primary goal is to compare the performance of non-autoregressive neural networks with traditional solvers (integer programming solvers like SCIP and Gurobi); in the traveling salesman problem, the focus is on comparing our framework with other neural network-based solvers. Facility location and max-set covering experiments were run on a workstation with an i7-9700K CPU, 16GB RAM, and an RTX 2080Ti GPU, while the traveling salesman problem experiments were conducted on a workstation with an AMD 3970X CPU, 32GB RAM, and an RTX 3090 GPU."}, {"title": "Facility Location Problem", "content": "The facility location problem (FLP) is formulated as follows: Given m locations, we are to choose k locations to build new facilities, where each facility will serve other locations based on proximity (subject to capacity limits). The objective is to minimize the sum of distances from each location to the nearest facility. In the simplified version without capacity limits, the problem is formulated as:"}, {"title": null, "content": "$\\min \\sum_{j=1}^m \\min(\\{\\Delta_{i,j}| \\forall x_i = 1\\}), \\text{s.t.} x \\in \\{0,1\\}^m, \\sum_{i=1}^m x_i \\leq k,$\nwhere x represents the decision variables, and Ai,j means the distance between locations i and j. For this problem, the implementation of the non-autoregressive neural network is as follows:\n\u2022 Graph Modeling: The problem is modeled as a graph, where each location is a node, and edges are defined between locations with a distance less than 2% of the total area diameter. The facility location problem is equivalent to node classification on this graph.\n\u2022 Graph Neural Network: A spline convolutional network [53] is used, with 3 layers and a hidden dimension of 16 and 5 spline kernels.\n\u2022 Gumbel Reparameterization and LinSAT Layer: These steps ensure that the network output is projected into the feasible region with constraints from (9).\n\u2022 Objective Function Estimation: Since the min operator in (9) truncates gradients, we use a smooth softmin operator (i.e., applying softmax after negating the input). Specifically, we replace"}, {"title": null, "content": "$\\min(\\{\\Delta_{i,j}| \\forall x_i = 1\\})$ with softmax($-\\beta \\Delta \\circ x$), where \u25e6 denotes element-wise multiplication, and B is a temperature parameter.\n\u2022 Neighborhood Search in Inference: In the facility location problem, we apply k-median clustering for fast search around the best solutions found in the batch.\nWe follow the experiment design in [26], where m locations are randomly generated in a 2D unit area to form training/testing data. All neural methods were trained without any optimal solution information during training. In the experiments, we compare our method with greedy algorithms and professional solvers (SCIP [51] and Gurobi [52]), with time limits of 120 seconds and 200 seconds for Figures 4(a) and (b), respectively. We also compare with neural solvers such as EGN [25] and CardNN [16], with results shown in Figure 4. The figure compares different solvers in terms of both solution quality (measured by the gap relative to the optimal solution) and runtime, with each circle representing a test instance, and the average performance of each solver shown by an \"X\". Our non-autoregressive neural solver (red points) achieves Pareto-optimality in terms of both solution accuracy and runtime, surpassing even commercial solvers like Gurobi in both efficiency and performance.\nTo test the generalization ability of the neural solver to unseen distributions, we constructed a real-world dataset: using the actual geographic coordinates of all Starbucks stores in Shanghai, New York, London, and Seoul as inputs, calculating Euclidean and Manhattan distances, and solving the facility location problem. The neural network was trained on simulated data but tested directly on real data. As shown in Figure 5, the neural network exhibits strong generalization, outperforming Gurobi on unseen real-world data. Tables 1 and 2 provide ablation studies on the main components of our framework, demonstrating the importance of online gradient search and inference, as well as the significance of softmin operators and hyperparameter selection for the facility location problem.\nCapacitated Facility Location Problem. To further demonstrate the practicality of our method, we also consider the capacitated facility location problem, where each facility can only serve a limited number of locations. The optimization problem is formulated as:"}, {"title": null, "content": "$\\min \\sum_{i=1}^m \\sum_{j=1}^m \\Delta_{i,j} P_{i,j}, \\text{s.t.} x \\in \\{0,1\\}^m, \\sum_{i=1}^m x_i \\leq k, \\sum_{j=1}^m x_i d_i,$"}, {"title": null, "content": "$P \\in \\mathbb{R}^{m \\times m}, P_{i,j} \\leq d_j, P_{i,j} \\leq x_i$\nHere, Pij represents how much demand from location j is served by facility i. The implementation for the capacitated version of the problem is largely similar to the uncapacitated case, with a few modifications:\n\u2022 LinSAT Layer: The constraints for decision variables x are updated to account for the capacity limits, but these still fall under the class of positive linear constraints and can be handled by the LinSAT layer.1\n\u2022 Objective Function Estimation: The objective is more complex due to the capacity limits, as each location cannot simply choose the nearest facility. After determining x, the remaining part of the problem is a linear programming problem, specifically an optimal transport problem. While linear programming problems are theoretically differentiable [55], solving multiple linear programs in a batch during training would be computationally expensive. We use a GPU-parallelizable approximation method [54] to solve the optimal transport problem and employ a more efficient backpropagation technique [56] .\nThe experiments use the same data distribution as in Figure 4(a), with each facility able to serve up to 50 locations. Table 3 compares our method with Gurobi. For shorter time limits (around 30 seconds), our non-autoregressive network outperforms Gurobi; for longer time limits (around 100 seconds), Gurobi outperforms our method, though the difference is small. In this problem setting, existing neural methods like CardNN [26] do not apply due to the constraint changes; methods like EGN [25] and SCIP [51] were omitted from Table 3 for brevity, as they did not outperform the best neural network and traditional solver.\nIn summary, for the facility location problem, our non-autoregressive neural network solver outperforms existing (non-autoregressive) neural solvers in terms of applicability and accuracy. Its performance is comparable to, and in some cases surpasses, professional solvers like Gurobi."}, {"title": "Max-Set Covering Problem", "content": "The max-set covering problem (MCP) is formulated as follows: Given m sets and n items, each set covers some items from the universe. We are to select k sets such that the total value of the items covered by the selected sets is maximized. A typical case of MCP arises in social networks,"}, {"title": null, "content": "where sets represent m influencers, and items represent n users. An advertiser can solve MCP to maximize the impact of an advertisement within a limited budget. The MCP is formulated as:\n$\\max \\sum_{j=1}^n v_j \\left( 1 - \\prod_{i=1}^m (1 - A_{i,j}) x_i \\right), \\text{s.t.} x \\in \\{0,1\\}^m, \\sum_{i=1}^m x_i <k.$\nHere, $v \\in \\mathbb{R}^n$ represents the value of each item, Ai,j = 1 means set i covers item j, and I() is an indicator function that outputs 1 if the internal sum is greater than 1, and 0 otherwise. The implementation of our non-autoregressive network for MCP is as follows:\n\u2022 Graph Modeling: The MCP is modeled as a bipartite graph where sets and items are the two partitions. An edge exists between set i and item j if Ai,j = 1, and solving MCP is equivalent to node classification on the \"sets\" partition.\n\u2022 Graph Neural Network: A GraphSage [37] is used, with three layers. The message passing from \"sets\" to \"items\" and vice versa is handled by two separate networks. The hidden dimension is 16.\n\u2022 Gumbel Reparameterization and LinSAT Constraint Layer: These steps ensure that the network output satisfies the constraints in (11).\n\u2022 Objective Function Estimation: Compared to the facility location problem, the objective in (11) is more straightforward: after predicting x, the objective function is directly calculated based on (11).\n\u2022 Neighborhood Search in Inference: MCP did not employ a specific neighborhood search in this case, but online gradient search is still utilized.\nWe generate two sets of training/testing data with distributions similar to ORLIB [57], following the setup in [26]. We compare our method with greedy algorithms, professional solvers (SCIP [51], Gurobi [52], with 100-second and 120-second time limits for Figures 6(a) and (b), respectively), and neural solvers such as EGN [25] and CardNN [16]. The results are shown in Figure 6, where the gap relative to the best-known incumbent solution is compared against runtime. Each circle represents a test instance, and the average performance of each solver is denoted by an \"X.\" In MCP, even state-of-the-art solvers like Gurobi cannot return the optimal solution within 24 hours for some instances, so the gap is measured relative to the best-known incumbent solution. Our non-autoregressive solver (purple) achieves Pareto-optimal performance, outperforming Gurobi in both runtime and solution quality. Additionally, our method finds the best-known solutions on many test instances."}, {"title": "Traveling Salesman Problem", "content": "The traveling salesman problem (TSP) is formulated as follows: Given m cities with known coordinates, a traveling salesman needs to visit all cities and return to the starting city, minimizing the total travel distance. The mathematical formulation is:"}, {"title": null, "content": "$\\min \\operatorname{tr"}, "D^T X), \\text{s.t.} X \\in \\{0, 1\\}^{m \\times m} \\forall j: \\sum_{i=1}^m X_{i,j} = 2, \\forall i: \\sum_{j=1}^m X_{i,j} = 2, X \\in H,$\nwhere $D \\in \\mathbb{R}^{m \\times m}$ represents the pairwise distances between cities, Xi,j = 1 indicates that the salesman travels between cities i and j, and X \u2208 H represents a Hamiltonian cycle. Our non- autoregressive solver for TSP is implemented as follows:\n\u2022 Graph Modeling: The cities' coordinates are used as node features, and pairwise distances are used as edge features to construct a fully connected graph. For the larger TSP-500 task, the graph is sparsified using a k-nearest neighbors approach (k = 50).\n\u2022 Graph Neural Network: We use an anisotropic graph neural network [58"], "Layer": "The Hamiltonian cycle constraint cannot be directly handled by LinSAT", "j": "sum_{i=1"}, {"i": "sum_{j=1"}, {"Training": "To ensure a fair comparison with other neural solvers for TSP", "Inference": "For TSP, we apply greedy output combined with 2-Opt search and Monte Carlo tree search (MCTS) strategies, which are commonly used in solving TSP.\nAs shown in Table 4, we validate the effectiveness of our method on TSP instances with m = 50,100,500. Following common practice in the field"}]