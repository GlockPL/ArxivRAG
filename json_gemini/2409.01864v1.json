{"title": "The Role of Large Language Models in Musicology: Are We Ready to Trust the Machines?", "authors": ["Pedro Ramoneda", "Emilia Parada-Cabaleiro", "Benno Weck", "Xavier Serra"], "abstract": "In this work, we explore the use and reliability of Large Language Models (LLMs) in musicology. From a discussion with experts and students, we assess the current acceptance and concerns regarding this, nowadays ubiquitous, technology. We aim to go one step further, proposing a semi-automatic method to create an initial benchmark using retrieval-augmented generation models and multiple-choice question generation, validated by human experts. Our evaluation on 400 human-validated questions shows that current vanilla LLMs are less reliable than retrieval augmented generation from music dictionaries. This paper suggests that the potential of LLMS in musicology requires musicology driven research that can specialized LLMs by including accurate and reliable domain knowledge.", "sections": [{"title": "1 Introduction", "content": "In recent years, research on Large Language Models (LLMs) has led to notable advancements within the text generation domain (Wei et al., 2022a; Minaee et al., 2024). This is the result of training large models on vast non-domain-specific data (Gao et al., 2020; Hoffmann et al., 2022). Well-known families of models include Llama (AI@Meta, 2024) or GPT (Achiam et al., 2023), which can generate coherent and contextually relevant text, making them valuable tools in numerous applications and professions such as healthcare (Thirunavukarasu et al., 2023), journalism (Petridis et al., 2023), customer support (Kolasani, 2023) or education (Kasneci et al., 2023). Despite their potential, LLMs' so-called hallucinations (Alkaissi and McFarlane, 2023), i. e., the lack of confidence and accuracy in the text they generate, prevents the use of this technology in most arts and humanities research tasks (Rane, 2023; Lozi\u0107 and \u0160tular, 2023; Rane and Choudhary, 2024). Issues include a lack of contextual understanding, bias perpetuation (Gallegos et al., 2024), and ethical concerns such as generating misleading content (Weidinger et al., 2021). The lack of credible source attribution (Rashkin et al., 2023) almost render them nugatory for fields like literature, history (Walters and Wilder, 2023), and law (Weiser, 2024). However, LLMs can aid research through a variety of tasks, such as, translation, text analysis, data organization, historical context retrieval, or summarization. In this regard, interdisciplinary research involving the use and further development of LLMs within the humanities should be carried out. This will enable to constructively address existing risks and concerns while developing LLMs' full potential, by this delivering their benefits across disciplines.\nIn this work, we focus on musicology, a field where the impact of LLMs still needs to be explored. Musicology, the scholarly study of music, spans from historical research to theoretical analysis (Harap, 1937; Duckles et al., 2020). Our research mainly focuses on the former, an area which might be greatly supported by LLMs, e. g., by breaking language barriers, enhancing information retrieval, or supporting teaching and learning. However, reliable sources, such as music-specialized lexica, monographies, and research articles, are often, unlike in more technical disciplines, not open-access, which prevents LLMs to"}, {"title": "2 Pilot-survey: LLMs in musicology", "content": "We conducted a survey targeting professionals related to musicology. The survey included questions to identify the respondent's domain of study (e.g., musicology, composition, music pedagogy, music performance), the highest level of music education completed or being pursued, and their familiarity with technologies known as LLMs such as ChatGPT. Additionally, the survey inquired about the frequency of interactions with LLMs, particularly in the context of musical topics like Music Theory and Music History. Participants were asked to rate the trustworthiness and usefulness of LLMs for these subjects, as well as to consider its revolutionary impact on the field of musicology. Lastly, the survey explored the possible consequences of LLMs on music professionals, both presently and in the future.\nA total of 33 participants, having or pursuing a Bachelor's degree in music, completed the survey: 20 students, 7 lecturers, 11 researchers, and 8 mu-"}, {"title": "3 Musicology Benchmark: TrustMus", "content": "This section outlines our strategy for evaluating how much LLMs hallucinate in musicology. It summarizes the creation of the human-validated"}, {"title": "4 Results and Discussion", "content": "4.1 Human validation insights\nSome examples of hallucinations of Llama3 without RAG and CoT, the difficulty filter, are as follows: What does the natural sign (\u266e) do in music notation? A) Raises a note by one semitone, B) Raises a note by two semitones, C) Lowers a note by one semitone, D) Cancels a previous sharp or flat. The correct answer is D, but Llama3 chose A, which any musician should know is incorrect.\nAnother type of limitation of LLMs in the context of musicology, is the need of the models for"}, {"title": "4.2 TrustMus evaluation", "content": "Table 1 presents the benchmark results for various models evaluated on TrustMus.4 The models tested include the best open source performing models in LiveBench \u2013 LB (White et al., 2024) excluding coding and math categories, i. e., a benchmark for LLMs without contamination and reduced biases containing non-musicology knowledge. Due to its' leading performance, results of OpenAI's GPT models are also given for comparison. Models with less than 8B parameters were deployed in a computer with two RTX 2080ti GPUs with 16-bit precision, the largest models in a Colab A100 GPU with 4-bit quantization, and the GPT models through their official API.\nThe model gpt-4o-2024-05-13 clearly outperforms others with an accuracy of 58.75% (cf. TrustMus score in Table 1), excelling in the categories Ppl, Thr, and C&H. This is not surprising as it is the leading model in LB as well, with a score of 58.38%. However, comparing the LB and TrustMus rankings reveals important differences about how the models perform in terms of general and in domain-specific knowledge. For instance, unlike in LB, the model mixtral-8x22b-instruct-v0.1 performs well in our benchmark, ranking second with a score of 40.5%. It is important to note the simi-"}, {"title": "5 Conclusions", "content": "Our paper shows that while current usage and trust in LLMs in musicology are low, there is a strong expectation of future impact. However, LLMs are not yet at the required level for the field and do not meet the minimum quality, ethical and likely legal standards currently being discussed. Through the proposed semi-automatic benchmark, we present a first attempt to measure LLMs hallucinations on musicology-related tasks. This approach aims to facilitate the evaluation of future models, which promotes transparency and trustworthiness of the technology. Despite the effort, this initial experiments are insufficient. Besides a more thorough evaluation, there is the need to specialize current models for musicology-related tasks, while reducing their environmental footprint. Further research should focus on ensuring LLMs reliability to avoid misinformation, protecting user privacy and data security, and mitigating training data biases to promote responsible use in musicology. Collaboration between the technological, musicological, and content owner communities is essential for the proper development of this technology."}]}