{"title": "Do Large Language Models Possess Sensitive to Sentiment?", "authors": ["Yang Liu", "Xichou Zhu", "Zhou Shen", "Yi Liu", "Min Li", "Yujun Chen", "Benzi John", "Zhenzhen Ma", "Tao Hu", "Zhiyang Xu", "Wei Luo", "Junhui Wang"], "abstract": "Large Language Models (LLMs) have recently displayed their extraordinary capabilities in language understanding. However, how to comprehensively assess the sentiment capabilities of LLMs continues to be a challenge. This paper investigates the ability of LLMs to detect and react to sentiment in text modal. As the integration of LLMs into diverse applications is on the rise, it becomes highly critical to comprehend their sensitivity to emotional tone, as it can influence the user experience and the efficacy of sentiment-driven tasks. We conduct a series of experiments to evaluate the performance of several prominent LLMs in identifying and responding appropriately to sentiments like positive, negative, and neutral emotions. The models' outputs are analyzed across various sentiment benchmarks, and their responses are compared with human evaluations. Our discoveries indicate that although LLMs show a basic sensitivity to sentiment, there are substantial variations in their accuracy and consistency, emphasizing the requirement for further enhancements in their training processes to better capture subtle emotional cues. Take an example in our findings, in some cases, the models might wrongly classify a strongly positive sentiment as neutral, or fail to recognize sarcasm or irony in the text. Such misclassifications highlight the complexity of sentiment analysis and the areas where the models need to be refined. Another aspect is that different LLMs might perform differently on the same set of data, depending on their architecture and training datasets. This variance calls for a more in-depth study of the factors that contribute to the performance differences and how they can be optimized.", "sections": [{"title": "1 Introduction", "content": "Recently, large language models (LLMs) have made groundbreaking strides that have dramatically reshaped the artificial intelligence landscape (Brown et al., 2020; Chowdhery et al., 2023). These models have become a cornerstone in natural language processing (NLP), enabling advances in various tasks, from text generation (Mo et al., 2024; Li et al., 2024; Abburi et al., 2023) to question answering (Zhuang et al., 2024; Saito et al., 2024). Despite their widespread adoption, one crucial area that remains insufficiently explored is their capability to accurately perceive and respond to sentiment. Sentiment analysis-the process of identifying the emotional tone within text\u2014is vital for applications such as customer feedback analysis, social media monitoring, and conversational agents (Liao et al., 2023; Zhang et al., 2024b). This raises an important question:\nAre these advanced LLMs, trained on extensive datasets, truly capable of understanding sentiment, or are they simply replicating the sentiment patterns they have learned from their training data?\nThis paper aims to thoroughly evaluate the performance of large language models (LLMs) in sentiment analysis, specifically assessing their ability to detect and generate responses that correspond to the sentiment present in the input text. We explore models with varying architectures and sizes to identify both the strengths and the areas needing improvement in sentiment-related tasks. Our evaluation process follows a structured workflow, as illustrated in Fig 2. We begin by selecting a diverse set of prompts, which are then processed by various LLMs to produce soft outputs. These outputs undergo a similarity evaluation using word vector similarity techniques to assess their alignment with the intended sentiment. This systematic approach allows for a comprehensive analysis of the models' performance, offering insights into their ability to capture nuanced sentiment. The workflow's design not only ensures thoroughness in evaluation but also facilitates the identification of specific areas where LLMs excel or require improvement, ultimately contributing to more targeted advancements in sentiment analysis capabilities. Our research not only contributes to the ongoing discourse surrounding LLM evaluation but also highlights the necessary enhancements required to bolster the sentiment sensitivity of these models.\nOur contributions are summarized as follows:\n\u2022 Incorporating the sentiment analysis, we develop and introduce the 'Sentiment Knowledge Workflow' for LLMs. This innovative framework is pivotal in defining and advancing the self-awareness capacities of LLMs.\n\u2022 We evaluate the sentiment sensitivity of a diverse array of LLMs across multiple public datasets. Our comprehensive analysis reveals that while these models exhibit a basic ability to detect sentiment, there are significant discrepancies in their accuracy and consistency. These findings underscore the need for further refinements in their training processes to improve their capacity to recognize and respond to subtle emotional cues more effectively."}, {"title": "2 Related Works", "content": "LLMs Development. The development of Large Language Models (LLMs) represents a significant milestone in the field of artificial intelligence, particularly in natural language processing (NLP) (Yuan et al., 2023; Yang et al., 2024). Originating from earlier efforts in neural networks and deep learning, LLMs have evolved rapidly, driven by advancements in computational power, algorithmic innovations, and the availability of vast amounts of textual data. These models, exemplified by architectures like GPT (Floridi and Chiriatti, 2020; Achiam et al., 2023) and BERT (Devlin et al., 2019), are trained on diverse and extensive datasets, enabling them to generate human-like text, perform complex language tasks, and even demonstrate an understanding of context and nuance. The scaling of model parameters (Zhang et al., 2024a) and data has been a crucial factor in enhancing the capabilities of LLMs, allowing them to achieve state-of-the-art performance across a wide range of applications, from translation (Lu et al., 2024) and summarization (Tang et al., 2024) to more specialized tasks like code generation (Ugare et al., 2024; Zheng et al., 2024) and creative writing (G\u00f3mez-Rodr\u00edguez and Williams, 2023). As research continues, LLMs are poised to further revolutionize how we interact with and understand language in both digital and real-world environments.\nLLMs Sentiment Capability. Large Language Models (LLMs) have increasingly been designed to understand and emulate human emotions (Zou et al., 2024), enhancing their role in more nuanced and empathetic communication (Sorin et al., 2023; Hasan et al., 2024). These models are trained on vast datasets that include emotionally rich language, enabling them to recognize and generate text that reflects various emotional tones. By interpreting subtle cues (Shukla et al., 2023) in language, such as word choice, tone, and context, LLMs can respond in ways that align with the emotional state of the user. This emotional capability is particularly valuable in applications like virtual assistants (Vu et al., 2024), mental health support (Lai et al., 2023), and customer service (Pandya and Holia, 2023), where understanding and responding to emotions is crucial for effective interaction. However, the development of these capabilities also raises important ethical considerations, as LLMs must navigate complex emotional landscapes without reinforcing biases or generating inappropriate responses. As this technology continues to advance, the emotional intelligence of LLMs (Sabour et al., 2024; Wang et al., 2023) is expected to become increasingly sophisticated, allowing for more personalized and empathetic interactions between humans and machines."}, {"title": "3 Background", "content": "3.1 Self-awareness.\nSelf-awareness (Wang et al., 2024; Yin et al., 2023; Liu et al., 2024) refers to the ability to recognize and comprehend one's own existence, emotions, thoughts, and behaviors. It encompasses an understanding of one's identity, abilities, strengths, and weaknesses, as well as an awareness of one's role and influence within various social and environmental contexts. Self-awareness (Camacho et al., 2012; Hall, 2004; Ortiz and Patton, 2012) can be further categorized into several key aspects, including:\n1. Personal Identity Awareness. Knowing who you are, including your name, age, gender, occupation, interests, and hobbies.\n2. Sentiment Awareness. The ability to identify and understand your own emotional states, such as happiness, sadness, anger, and fear.\n3. Cognitive Self-awareness. Being aware of and reflecting on your own thoughts and beliefs, including how you make decisions, solve problems, and perceive the world.\n4. Social Self-awareness. Understanding your role and status in society, as well as being aware of how others perceive and expect from you.\n5. Physical Self-awareness. Recognizing your physical state and sensations, including your appearance, health, and bodily movements.\nSelf-awareness is a unique characteristic of humans that enables individuals to reflect on their actions, set goals, adjust behavior to adapt to changing environments, and interact effectively in complex social settings. Developing self-awareness can be achieved through self-reflection, psychological counseling, meditation, and communication with others. In this paper, we focus on the sentiment part.\n3.2 Evaluation of LLMs.\nWe perform a thorough evaluation of the LLMs using a detailed question-answer workflow, as illustrated in Figure 2. The process begins with the creation of precise prompts, leading to the generation of initial outputs by the LLMs. These outputs are then analyzed for similarity. The workflow further includes evaluating multiple word vector similarities and categorizing responses based on emotional tones such as stunning, sentimental, positive, inspiring, uplifting, heartwarming, and hopeful. The evaluation concludes with an in-depth assessment of the overall performance and effectiveness of the LLMs.\nVarious metrics based on multiple-choice questions have been utilized in prominent benchmarks such as CommonsenseQA (Talmor et al., 2018), HellaSwag (Zellers et al., 2019), and MMLU (Hendrycks et al., 2020). These benchmarks have laid the groundwork for evaluating the accuracy of knowledge within language models by focusing on the correct responses to these questions. Building on the methodologies employed in these foundational studies (Pan and Zeng, 2023), our approach extends their insights by leveraging questions from our specific target tasks. These questions, which are designed to be seamlessly integrated into our evaluation framework, allow us to assess not only the accuracy of the responses but also the depth of understanding and reasoning capabilities exhibited by the models. By incorporating these metrics, we aim to provide a comprehensive evaluation that mirrors the rigor of the original benchmarks while adapting them to the nuanced requirements of our tasks."}, {"title": "4 Experimental Settings", "content": "4.1 Dataset.\nIn this study, we utilized three publicly available datasets: Sentiment140, MyPersonality, and IMDB Reviews. The specific details of each dataset are outlined below.\n\u2022 Sentiment140. It is a dataset developed by Stanford University for sentiment analysis research. It consists of 1.6 million tweets collected from Twitter, each labeled as positive, negative, or neutral. What sets Sentiment140 apart is its unique approach to labeling: it uses emoticons in the tweets (such as :-) or :-() as sentiment indicators, which are then removed to create a more authentic representation of social media content. This dataset is particularly valuable for handling the challenges of noisy text, including abbreviations, spelling errors, and informal language typical of Twitter. Sentiment140 is widely used for training and evaluating sentiment analysis models, especially those designed to analyze social media data.\n\u2022 Mypersonality. It is a well-known dataset in the fields of psychology and data science, originally created by researchers at the University of Cambridge in 2007. It was generated through an online personality test application hosted on the Facebook platform, where users could take various personality assessments and voluntarily share their Facebook data. This data includes profile information, social network activities, and the results of psychological assessments like the \"Big Five Personality Traits\" (OCEAN model). Mypersonality offers a unique opportunity for researchers to study the relationship between social media behavior and personality traits. Although the dataset has been controversial due to privacy concerns and data collection methods, it remains a valuable resource for research in psychology and social network analysis.\n\u2022 IMDB Reviews. It is a widely-used sentiment analysis dataset composed of movie reviews from the Internet Movie Database (IMDb). The dataset typically includes 50,000 reviews, each labeled as either positive or negative, and is used for text classification tasks, particularly sentiment analysis. Unlike shorter text datasets, IMDB Reviews features longer reviews, rich with semantic information such as opinions, emotions, and arguments. This makes it an ideal dataset for evaluating and training deep learning models that need to handle more complex semantics and contextual information. Given IMDb's global reach, the dataset encompasses a wide range of expressions and cultural backgrounds, making it valuable for testing the generalization capabilities of sentiment analysis models.\n4.2 Tasks\nThe focus of this paper is on the task of multi-label classification, where each input query q can be linked to multiple labels simultaneously, rather than being limited to a single label. Formally, given a query q, the model outputs a set of labels y = {Y1, Y2, ..., Yk }, with each yi \u2208 {0,1} representing the presence (1) or absence (0) of the corresponding label. Large language models (LLMs) address this task by leveraging their advanced ability to comprehend complex textual contexts, enabling them to effectively predict multiple relevant labels by identifying and capturing intricate patterns embedded within the data.\n4.3 Evaluation.\nMetrics for multi-class classification are used to evaluate the performance of models that predict multiple classes. Key metrics include accuracy, precision, recall, and F1 score, each providing insights into different aspects of the model's performance. Accuracy measures the proportion of correctly predicted samples out of the total samples. Precision and recall assess the model's performance for each class, with precision indicating how many of the predicted positives are actually correct, and recall showing how many actual positives were correctly identified. The F1 score, the harmonic mean of precision and recall, offers a balanced evaluation of the model's effectiveness.\n4.4 Baselines.\nWe utilize well-established LLMs, such as LLaMA, as baseline models in our experiments. Unless specified otherwise, all baseline models are implemented using the parameters provided in their respective original APIs.\n\u2022 ChatGPT4. It is an advanced conversational Al developed by OpenAI, designed to generate human-like text based on given prompts. It comes in various versions, including GPT-3.5-turbo, GPT-4, and GPT-4-turbo. GPT-3.5-turbo offers efficient performance and responsiveness, making it well-suited for a wide range of applications. GPT-4, a more powerful and sophisticated model, provides enhanced language understanding and generation capabilities, ideal for complex tasks. GPT-4-turbo further optimizes performance, delivering faster responses while maintaining the high quality and depth of GPT-4's output.\n\u2022 LLaMA5 (Large Language Model Meta AI). It is a family of advanced language models developed by Meta, designed to generate and understand human-like text. LLaMA models are known for their efficiency and effectiveness in various natural language processing tasks. Within this family, Mistral is a notable variant that focuses on optimizing performance and resource usage, offering high-quality outputs while being more computationally efficient. Mistral represents a key innovation within the LLaMA series, combining state-of-the-art language generation with enhanced scalability and accessibility for diverse applications.\n\u2022 Doubao7. It is an advanced language model designed to excel in a wide range of natural language processing tasks, from text generation and sentiment analysis to machine translation. Built with cutting-edge deep learning techniques and trained on extensive data, Doubao captures intricate linguistic patterns and contextual meanings, enabling it to generate human-like text across various contexts."}, {"title": "5 Results and Insights", "content": "5.1 Results\nWe present a comprehensive overview of our evaluation results across three different datasets, which are shown in Table 1, Table 2, and Table 3. These tables encompass a range of models and configurations, offering detailed insights into their performance. Additionally, we provide a demonstration analysis in Table 4, where we apply various prompt templates to the IMDB dataset. For further clarity, the specific details of the prompt templates can be found in Table 5. In the following sections, we discuss key findings and insights, addressing each observation individually for a more in-depth understanding.\n5.2 Interesting Insights\nInsight 1. Some LLMs possess a unique ability to be sensitive to sentiment. (Refer to Table 1, 2 and 3)\nInsight 2. Processing prompts cannot obscure or eliminate LLMs ability to detect sentiment with neutral prompts. (Refer to Table 3 and 4)\nInsight 3. Different versions of the same LLM can exhibit varying behaviors and performance. (Refer to Table 1, 2 and 3)"}, {"title": "6 Discussion", "content": "The evaluation results across different datasets and models shed light on the varying capabilities of LLMs, particularly when it comes to sentiment detection.\nLLMs exhibit a certain sensitivity towards sentiment that appears to be a unique characteristic across multiple models, as shown in Table 1, Table 2, and Table 3. For example, the Doubao-pro model consistently performs well in sentiment tasks, demonstrating strong scores in both precision and recall across multiple datasets. This suggests that the underlying architecture of some LLMs might be more adept at capturing emotional subtleties in text, despite the varying nature of the input data. This sensitivity indicates that certain LLMs can be fine-tuned or selected specifically for sentiment-related tasks, even in a competitive landscape of multiple LLM options.\nThe ability of LLMs to detect sentiment is not easily obscured by prompt processing, particularly when dealing with neutral prompts, as evident from Table 4. Doubao-pro maintains a relatively high performance with neutral prompts, despite changes in input structure. This suggests that the model's internal mechanisms for identifying sentiment are robust enough to operate even when the prompt is neutral, implying that sentiment detection in LLMs may be deeply ingrained in the model's learned representations, rather than being highly sensitive to prompt formulations. This highlights the model's flexibility and adaptability in different real-world scenarios where the exact phrasing of the input may vary.\nThe comparison between different versions of the same LLM, such as the Doubao and Doubao-pro models, reveals that even slight modifications to the architecture or training procedures can lead to notable differences in performance, as shown in Table 1, Table 2, and Table 3. Doubao-pro consistently outperforms its predecessor across multiple datasets and metrics, showing that model refinement plays a crucial role in enhancing the ability of LLMs to perform on sentiment tasks. This variability underscores the importance of continuous model development and experimentation to achieve optimal results in practical applications. These detailed insights together provide a deeper understanding of how LLMs behave under various conditions and prompt configurations, suggesting potential strategies for optimizing LLMs for sentiment analysis tasks in diverse applications."}, {"title": "Appendix", "content": "A Prompt Design\nFor each task, we apply a consistent prompt engineering template to generate the input prompt. The templates are listed below."}]}