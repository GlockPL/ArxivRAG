{"title": "Meta-Learning for Federated Face Recognition in Imbalanced Data Regimes", "authors": ["Arwin Gansekoele", "Emiel Hess", "Sandjai Bhulai"], "abstract": "The growing privacy concerns surrounding face image data demand new techniques that can guarantee user privacy. One such face recognition technique that claims to achieve better user privacy is Federated Face Recognition (FRR), a subfield of Federated Learning (FL). However, FFR faces challenges due to the heterogeneity of the data, given the large number of classes that need to be handled. To overcome this problem, solutions are sought in the field of personalized FL. This work introduces three new data partitions based on the CelebA dataset, each with a different form of data heterogeneity. It also proposes Hessian-Free Model Agnostic Meta-Learning (HF-MAML) in an FFR setting. We show that HF-MAML scores higher in verification tests than current FFR models on three different CelebA data partitions. In particular, the verification scores improve the most in heterogeneous data partitions. To balance personalization with the development of an effective global model, an embedding regularization term is introduced for the loss function. This term can be combined with HF-MAML and is shown to increase global model verification performance. Lastly, this work performs a fairness analysis, showing that HF-MAML and its embedding regularization extension can improve fairness by reducing the standard deviation over the client evaluation scores.", "sections": [{"title": "I. INTRODUCTION", "content": "During the past decade, significant advances have been made in artificial intelligence (AI) and machine learning (ML). The surge in available data and computing power has enabled the development of technologies such as large language models, image classification, and image generation. However, these advancements also bring challenges related to data collection and storage. Issues such as data ownership and privacy are becoming more relevant in a world that is becoming increasingly digital. A domain with a particular sensitivity to privacy concerns is face recognition (FR). Datasets such as LFW [9], MegaFace [18], MS-Celeb-1M [7], and IJB-C [16] have been instrumental in advancing FR technology. Of these datasets, both MegaFace and MS-Celeb-1M have been redacted due to privacy issues at the time of writing. Addressing these privacy concerns is essential for the ethical advancement of face recognition technologies.\nAn approach to using large-scale datasets while respecting privacy constraints is federated learning (FL) [17]. By aggregating data from multiple parties, we can share large amounts of information while alleviating privacy issues. In the context of FR, this approach is referred to as federated face recognition (FFR). A significant challenge with FFR is that making i.i.d. data assumptions across clients is unrealistic. Different data owners typically have distinct identities, which means that everyone is solving their own local classification problem. Furthermore, identities may vary in terms of attributes depending on the part of the world the data originate from. Ideally, these algorithms should be not only effective but fair as well. Disparities in model performance could discourage participation from certain parties.\nThis challenge of data heterogeneity is not new in the field of FL [23, 24]. Attempts to address data heterogeneity can be dubbed personalized federated learning (PFL). Multiple authors have proposed algorithms to address this issue in FL and FFR [1, 14]. One approach that is underexplored, yet interesting in the context of FFR is meta-learning. Meta-learning algorithms, such as model-agnostic meta learning MAML [6], optimize the model in such a way that it can quickly adapt to any new task. MAML has previously been adapted to an FL setting by [5] and [10]. Their application in data heterogeneous settings is interesting, as meta-learning provides a natural multi-task framework. In this work, we propose the use of MAML in an FFR setting and analyze its performance. We make the following contributions.\n1) We introduce the use of meta-learning in the context of FFR and propose an additional regularization term to alleviate the problem of global/local model mismatch;\n2) We introduce two new splits for the dataset CelebA [15] that allow us to evaluate FFR models under data heterogeneity;\n3) We evaluate our approach and demonstrate that meta-learning, in the absence of a global dataset, outperforms FedAvg [17] in both TAR@FAR and fairness under data heterogeneity."}, {"title": "II. RELATED WORK", "content": "a) Federated Face Recognition: While the naming of FFR is new, the CelebA dataset has long been included in FL benchmarks such as LEAF [2]. The introduction of face recognition functions such as CosFace [21] in an FL setup followed later [1, 19, 14]. FedFace [1] identified the issue of sensitive information being stored in the classification head of the global model. Another problem occurs when the assumption is made that every client only has one identity to train on; there are no negative samples to balance out the loss. They addressed this by pre-training a classifier on a global dataset and then regularizing the embeddings at the server during FL. FedFR [14] relaxed the assumption of a single identity per client, demonstrating improvements through a multi-task learning approach. However, note that both these approaches assume the availability of a large global dataset to start training. We drop this assumption in our work.\nb) Meta Learning: MAML was first introduced in [6] with [4] providing convergence guarantees for this approach. Work by [3], [5], and [10] demonstrated that meta-learning can be applied in an FL setting. Work by [10] showed that the FedAvg algorithm can be interpreted as a form of meta-learning. Work In work by [22], the authors proposed an adaptive method to divide clients into groups, where each group is selected to be similar in terms of data heterogeneity. An issue with MAML is that you need to compute an expensive second derivative. That is why [4] proposed Hessian-Free MAML (HF-MAML), which provides an approximation to the second derivative that avoids the need to compute the Hessian. We use this approximation in our meta-learning approach.\nc) Non-IID Data: The issue of data heterogeneity is well-known in FL. While FedAvg is robust to non-i.i.d. data in certain cases [17], other papers have reported accuracy reductions of up to 55% in highly imbalanced data regimes [23]. To properly evaluate our models, we need data partitions that allow exploring performance under non-i.i.d. settings. The most common data partition in FFR is one class per client [2]. Another commonly used partition was used by [14, 20], where each client received an equal number of classes > 1.\nd) Fairness: An algorithm needs to be fair to be compliant with legislation and for broader adoption. Multiple works have examined how to define fairness in an FL system [12, 11]. In work by [12], q-FedAvg is proposed to balance the performance across clients. They do so using a q parameter that weights the parameter updates by their loss values. Clients with a lower loss value are less influential for the final parameter update. They also proposed a variant with meta-learning."}, {"title": "III. METHODS", "content": "A. Federated HF-MAML for FFR\nTo improve the personalization in an FL setup for FFR, we propose the use of HF-MAML. MAML is model-agnostic, which means it is compatible with any model that uses gradient descent [6]. MAML (and HF-MAML) has been shown to work well with classification models [10, 5, 6], but is more complicated in FR since we have to assume that we know the total number of identities of all clients combined beforehand.\nPrevious works have shown that one can naturally interpret meta-learning in an FL setup. Meta-learning normally works with different sets of tasks and computes the gradient of the model in such a way that the distance is minimal for all tasks. In FL, one can interchange 'task' with 'client' and take the same approach. FL is essentially multitask learning where each client forms their own task. To perform meta-learning on gradient-based approaches, one would normally compute the Hessian to minimize the needed gradient update, as this matrix represents the rate of change of functions. However, this is expensive in terms of computation and memory. We make an estimate of the Hessian by sampling multiple datasets and performing the following weight update:\n$$W_{t+1}^{k} = w - \\beta \\nabla_{w} f(w, D_{i}) [I - \\alpha \\nabla^{2} f(w, D_{i})].$$\nHere, we define \\(D_{k}\\) as the dataset of client k, w the weights at timestep t for client k, f the differentiable function. We denote \\(D_{i}^{k}\\) and \\(D_{i}^{k'}\\) as two extra datasets sampled from client k to get an estimate for the 2nd derivative. We define \\(\\tilde{w}_{i}^{k}\\) as\n$$\\tilde{w}_{i}^{k} = w - \\alpha \\nabla f(w, D_{i}).$$\nWe then approximate \\(\\nabla^{2} f(w, D_{i}) \\nabla_{w} f(\\tilde{w}_{i}^{k}, D_{i}')\\) using\n$$\\nabla^{2} f(w, D_{i}) \\nabla_{w} f(\\tilde{w}_{i}^{k}, D_{i}') = \\frac{1}{2 \\delta} [\\nabla_{w} f(w + \\delta \\nabla_{w} f(w, D_{i}), D_{i}') - \\nabla_{w} f(w - \\delta \\nabla_{w} f(\\tilde{w}_{i}^{k}, D_{i}')), D_{i}')].$$\nThis provides us with the weight update that we need for our approaches.\na) Global Classification: The classification layer of the model refers to the part of the model after the backbone. This module is usually optimized by a loss function, such as Softmax, CosFace, or ArcFace. If we send all clients these weights as well, they all get access to the embeddings within this module. This poses privacy risks, as it is known that the original face could be reconstructed from the final embedding. As this is often still considered a valid approach, we include this approach in our evaluation suite as a global classification. Another issue with sharing the global classification layer occurs because not all clients possess data from all classes. Computing, e.g., a softmax over all classes, does not make sense when not all classes are seen during training. That is why if a client knows that they do not possess data from some class \\(c_{i}\\), they set the logits for the class to \\(-\\infty\\). This essentially removes the influence of that class on the final classification problem, meaning they only use the local classes for optimization.\nb) Local Classification: A safer alternative to maintaining a global classification layer is to keep the classification layer local and not share the weights of this layer with the global model. This approach is intuitive in the context of FFR, as the assumption that no classes are shared between clients is realistic. Instead of sending weight updates for all layers, we only send weight updates for the backbone layer to the global model.\nc) Embedding regularization: Note that the lack of overlap between classes could cause local models to drift apart. We propose adding an additional loss term to the local classification layer to alleviate the model drift issue. Adding a regularization term to the local loss function in FFR is not new. Both [13] and [14] added regularization terms to reduce the divergence of local weights. Instead of adding a penalty to the divergence between weights, we propose to reduce the divergence between the embeddings generated as in Eq. 4.\n$$Loss = f(x) + C (1 - S_{c}(f_{global}(x), f_{local}(x))),$$\nwhere \\(S_{c}\\) refers to the cosine similarity. With the regularization penalty, every client computes the cosine distance between the starting model's embeddings and the current model's embeddings. This term is weighted by a factor of C, which allows a trade-off between increasing personalization and reducing model divergence.\nd) Combined algorithm: Algorithm 1 shows the federated HF-MAML algorithm that we propose for FFR. The parts marked dark blue indicate algorithm additions for the implementation of the local classification layer, the parts marked green refer to using a global classification layer, the part marked red represents embedding regularization, and the parts with cyan color are algorithm additions to make HF-MAML work in an FFR setting. It describes our HF-MAML based approach that we use for effective personalized FFR.\nB. Data Partitions\nWe evaluate three types of data partitions, two of which we propose in this work. We assume the possibility of multiple identities per client, which gives us an equal class partition as a starting point. This partition tries to divide the number of identities and examples as evenly as possible per client. To better explore the effect of data heterogeneity on different algorithms, we propose two new data partitions: the lognormal partition and the attribute-based partition.\na) Lognormal class partition:\n$$S_{i} = \\frac{C}{\\sum_{i} S_{i}}, S_{i} \\sim lognormal(\\mu, \\sigma), 1 \\leq i \\leq n.$$\nFirst, we propose the lognormal class partition as defined in Eq. 5. For each client, we draw a sample from the lognormal distribution. We normalize these samples by the sum of all random samples and multiply them by the total number of identities. The result then gives the number of identities a client should be randomly assigned. Using the lognormal distribution in such a way gives us a few clients with many identities and many clients with few identities. The idea of using a lognormal distribution has been proposed previously [19]. However, they instead partition the data itself instead of the identities, which creates a quantity skewness in the data. We found it more intuitive for FFR to create an identity skew, as this classification problem already inherently consists of many classes with few samples per identity.\nb) Attribute-based partition: Finally, we propose a data partition type based on an attribute partition. The images in the CelebA dataset have not only been labeled based on identity but on more features, such as whether the person has a beard or not, or if the person is wearing make-up. These attributes can be used for classification or to improve face recognition based on the dependence of attributes [8]. Different attributes can be combined to create more specific partitions. For example, a client has a dataset that contains only images of men with beards and glasses.\nThis data partition is based on the idea of the FEMNIST dataset that is included in the LEAF benchmark. For FEM-"}, {"title": "IV. EXPERIMENTAL SETUP", "content": "A. Data partitioning\nThis section provides the concrete partitions generated using our approach. We will make these partitions available for future research. In total, there are 20 clients, 15 of which are used for training and 5 for evaluation. A total of 1,500 classes were used for the experiment. Data for each client are divided into a train, validation and test set, in a 70%/10%/20% split. We used around 10% of the original dataset due to resource constraints. All samples were cropped using Haar cascades.\na) Equal class partition: In the equal class partition, the data set for each client consists of images belonging to 75 randomly assigned identities, without overlap between clients. Since each class has a different sample size, the total number of images per client can differ.\nb) Lognormal class partition: For the lognormal distribution, we used \u03bc = 3 and \u03c3 = 3. We sample a partition once and store this partition for all runs. The amount of test data and training data per client is shown in Tab. I.\nc) Attribute-based partition: The CelebA dataset has a set of 40 binary attributes per image. These attributes range from hair color to whether or not the person is wearing glasses. Since some attributes are more common than others, different combinations of attributes are used to create subsets of data that can be assigned to clients. Tab. II shows how we have assigned attributes for each client. For example, client 5 has images with both male and female images. It is the only client with people without glasses. They wear hats, they can be both old and young, and the client has images of people with all types of hair color. In short, the focus of client 5 is on people with hats. Client 12 only contains images of men who do not wear glasses or hats. The people in the images are old people without blond hair, which means they can have any hair color except blond. The people in the images do not have goatees, which means that all men with goatees are filtered out. Lastly, all have bushy eyebrows. When an attribute is not mentioned it means that the client is agnostic towards this attribute; it has both people with or without this attribute in its dataset. An identity may have images with different attribute distributions. As can be seen in Tab. II, dataset sizes are kept as consistent as possible to reduce the effect of quantity skew as much as possible."}, {"title": "B. Model Setup", "content": "The model architecture used to train both the HF-MAML and FL models is shown in Tab. III. We used the Arcface loss function with s = 8 and m = 0.5, which were chosen through tuning. Important to note is that Tab III depicts the global classification layer scenario with 1,500 identities. For the local classification layer, the output of the Arcface part depends on the number of local identities. The linear layer between ResNet and Arcface is used to cast the ResNet output vector of size 1,000 to the size required for the embedding vector. In this paper, the embedding vector will have a length of 512. This embedding vector is used to compute the cosine similarity. As described previously, this cosine similarity is used for model evaluation and embedding regularization."}, {"title": "V. RESULTS", "content": "A. Convergence analysis\nFig. 1 shows the average validation score per communication round for the first 15 clients. We compared the global model with the tuned model for both. Figure 2 shows the same validation score per round but for the 5 clients not included during the training. The tuning of the clients included during the training seems to improve the scores, while we do not see this for the clients included later. We found similar training curves for the other methods.\nB. Performance Comparison\nFirst, we compared the global and local models for both FedAvg and HF-MAML in Tab. V under an equal class partition. We observed that HF-MAML achieves a better TAR@FAR than FedAvg, especially after tuning locally. We also saw little difference between the local and global models, which implies that it is sufficient to keep the classification layer local.\nSecond, we looked at the performance under the lognormal partition in Tab. VI. We observed that the difference between HF-MAML and FedAvg is greater than for the equal partition. While there was initially no difference in TAR@FAR0.1 for the clients added after training under the equal partition, the lognormal partition showed a larger and more significant difference between FedAvg and HF-MAML. This suggests that HF-MAML may be more effective under quantity skew. Another interesting result is that adding model regularization seems best when one does not tune locally afterward. Embedding regularization seems to be effective in addressing embedding drift, especially for new clients.\nFinally, we compared our test bench under the attribute-based partition in Tab. VII. This partition has the same amount of data per client but has mixed attributes. This partition thus allows us to evaluate under feature skew. In this partition, we see a clear improvement from FedAvg to HF-MAML after tuning the local data. This effect is visible for both the clients known during training and the clients added after training. We also see the same effect as observed under lognormal for embedding regularization.\nC. Fairness Analysis\nAnother vital aspect of PFR is fairness between clients. If clients know in advance that they will mostly contribute and do not receive much from collaborative training, they are unlikely to participate. To evaluate the fairness of our approaches, we note the standard deviation of our TAR@FAR 0.1 scores. The variance of the evaluation metrics is commonly used to measure the fairness of an approach.\nIn Tab. VIII, we noted the standard deviation of the compared methods under the equal partition. We see that local tuning of the global model improves the fairness of the model for both the FedAvg and HF-MAML models. We also see that the difference between the two under equal class partitions is small. This implies that using meta-learning when the data is approximately balanced does not add much to fairness.\nIn Tab. IX, we show the fairness results for the lognormal partition. We see that the variance between clients is overall higher than what we observed in Tab. VIII, which is a logical consequence of the skew in the quantity between clients. However, this partition shows a difference between FedAvg and HF-MAML. After tuning locally, the trained clients achieve a significantly lower standard deviation than under FedAvg. Interestingly, we do not see this effect for the clients added later.\nHowever, we note that some of these test clients, particularly 17 and 18, possess some of the largest local datasets in our evaluation. On average, their variance is also lower than that of the clients involved in training.\nFinally, we noted the fairness results for the attribute-based partition in Tab. X. Here, we observe the largest difference between FedAvg and HF-MAML. The difference is small but significant for the 15 trained clients before tuning. After tuning, the standard deviation of HF-MAML becomes smaller, and the difference between FedAvg and HF-MAML becomes even larger. Under feature skew, HF-MAML seems to achieve the fairest results.\nFinally, to better evaluate why our HF-MAML-based approach achieved fairer results, we compared the per-client performance for both FedAvg and HF-MAML in Fig. 3. We observed that HF-MAML achieved a higher TAR@FAR 0.1 for all clients. However, the weakest clients under FedAvg achieved the greatest improvement percentage-wise with HF-MAML. This indicates that HF-MAML gives fairer results primarily by improving the performance of the weakest clients. Note that the last 5 clients were not seen during training, which implies that HF-MAML is a better alternative when new clients also want a personalized model."}, {"title": "VI. DISCUSSION & CONCLUSION", "content": "In general, our results indicate that the effectiveness of HF-MAML varies depending on the level and type of data heterogeneity. Under the equal partition, HF-MAML was similar to FedAvg. Thus, it is hard to justify the additional cost and complexity of approximating the second derivative in this scenario. However, if we assume that there is some form of data heterogeneity, HF-MAML is beneficial compared to FedAvg. We observe that, especially after tuning locally, HF-MAML achieves better local TAR@FAR scores and lower variance between clients compared to FedAvg.\nWhen it comes to embedding regularization, we observe that it helps to transfer the model to new clients. By not allowing the model to drift too much, we avoid a model that is too specific to a set of clients and, thus, transfers better to new clients. This improvement is not retained under local tuning, so regularization is primarily interesting when local tuning is not an option.\nIn conclusion, we propose using HF-MAML in the context of FFR. We proposed new data partitions based on the CelebA dataset that help evaluate FR in a data-heterogeneous setting and demonstrated that HF-MAML can add value in such settings. The limitations of the work entail the limited performance of our approach. By not including a global dataset, our work is unable to reach practically useful TAR@FAR scores. Our work is intended as an investigation of whether HF-MAML can be useful in FFR and should provide a stepping stone in cases where a global dataset is no longer feasible. Future work should also look at applying our approach to more datasets with different types of data heterogeneity."}]}