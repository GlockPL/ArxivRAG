{"title": "Generative AI in Health Economics and Outcomes Research: A Taxonomy of Key Definitions and Emerging Applications \u2013 an ISPOR Working Group Report", "authors": ["Rachael L. Fleurence", "Xiaoyan Wang", "Jiang Bian", "Mitchell K. Higashi", "Turgay Ayer", "Hua Xu", "Dalia Dawoud", "Jagpreet Chhatwal"], "abstract": "This article offers a taxonomy of generative artificial intelligence (AI) for health economics and outcomes research (HEOR), explores its emerging applications, and outlines methods to enhance the accuracy and reliability of AI-generated outputs.\n\nThe review defines foundational generative AI concepts and highlights current HEOR applications, including systematic literature reviews, health economic modeling, real-world evidence generation, and dossier development. Approaches such as prompt engineering (zeroshot, few-shot, chain-of-thought, persona pattern prompting), retrieval-augmented generation, model fine-tuning, and the use of domain-specific models are introduced to improve AI accuracy and reliability.\n\nGenerative AI shows significant potential in HEOR, enhancing efficiency, productivity, and offering novel solutions to complex challenges. Foundation models are promising in automating complex tasks, though challenges remain in scientific reliability, bias, interpretability, and workflow integration. The article discusses strategies to improve the accuracy of these AI tools.\n\nGenerative AI could transform HEOR by increasing efficiency and accuracy across various applications. However, its full potential can only be realized by building HEOR expertise and addressing the limitations of current AI technologies. As Al evolves, ongoing research and innovation will shape its future role in the field.", "sections": [{"title": "Introduction", "content": "The field of Artificial Intelligence (AI) has been investigating approaches to use machine intelligence to augment human endeavors since the 1950s\u00b9. By the 1990s, machine learning techniques were advancing pattern recognition and decision-making processes. By the 2000s, researchers had developed deep learning models based on neural networks enabling a wide range of complex applications from image recognition to natural language processing (NLP). A breakthrough structural biology occurred in 2021, when AlphaFold, a neural networks-based deep learning program created by DeepMind, accurately predicted protein folding, significantly accelerating the process of drug discovery2,3. The scientists leading this effort were awarded a Nobel Prize in Chemistry in October 20244.\n\nIn the past decade, foundation models, which are large-scale AI systems trained on extensive, unlabeled datasets through self-supervised learning, have emerged. These models represent a significant shift in healthcare AI, transitioning from task-specific, single-purpose models to more versatile and adaptable generalist AI systems for medical applications5,6. One of the major paradigm shifts occurred in November 2022 with the launch of OpenAI's ChatGPT7, a type of generative AI, that produces text, images, or other content based on input prompts7,8. Available as a user-friendly web interface, it interacts with large language models (LLMs) to answer user queries in natural language. LLMs are a type of foundation model, trained on massive datasets enabling them to recognize, summarize, and generate text, producing coherent and contextually relevant outputs. In recent years, several major foundation models emerged, including Google's Gemini, OpenAI's GPT models, Anthropic's Claude, and Meta's Llama.\n\nIn science and medicine, generative AI and foundation models have begun to impact many areas 10. Applications in health economics and outcomes research (HEOR) are also emerging11, with Health Technology Assessment (HTA) agencies, such as NICE in the process of developing guidelines for their use in submissions12. Foundation models have the potential to drive innovation across a number of important HTA domains such as systematic literature reviews, economic models, real-world evidence (RWE), and the generation of value dossiers by augmenting and streamlining existing research processes and potentially dramatically boosting productivity. As the field progresses, emerging techniques, such as prompt engineering, retrievalaugmented generation (RAG), and other advanced techniques are being explored, with the goal of improving the accuracy and usefulness of these models in the field of health and medicine and by extension in HEOR11.\n\nThis article introduces HEOR professionals to the taxonomy of concepts associated with generative AI and foundation models, highlighting their application in HEOR-related areas. It explores emerging approaches and tools to improve the accuracy and reliability of AI-generated content."}, {"title": "Key concepts: Understanding the building blocks of AI", "content": "As generative AI and foundation models are increasingly being explored to support activities in HEOR, it is helpful for the HEOR community to understand the core concepts that underpin its capabilities and applications. The following sections define the key components, focusing on their relevance and application to HEOR."}, {"title": "Artificial Intelligence (AI)", "content": "Artificial intelligence refers to machines performing tasks that typically require human intelligence, such as pattern recognition, language understanding, reasoning and even decisionmaking\u00b9. In HEOR, AI is increasingly being explored to automate complex tasks (e.g. data extraction, statistical analysis, and predictive modeling)13"}, {"title": "Machine Learning (ML)", "content": "Machine learning, an important subset of AI, allows algorithms to learn from data to perform tasks without explicit programming. ML enables computers to adapt and improve their ability to solve problems over time. ML began to take root in the 1990s with the development of groundbreaking techniques such as Support Vector Machines (SVM) and Random Forests14,15. These methods transformed ML by facilitating complex pattern recognition and decision-making across various fields, moving from traditional rule-based systems to more flexible, data-driven approaches 11,16. In HEOR, ML offers significant potential by improving the accuracy and efficiency of economic modeling\u00b97, leading to more precise predictions of healthcare costs and outcomes18. ML can optimize cohort selection by identifying key predictors of health outcomes, reduce uncertainty in cost-effectiveness analyses by enhancing model structures and improving parameter estimation and predict long-term health outcomes with greater accuracy19."}, {"title": "Generative AI", "content": "Generative Al represents a more advanced application of AI, capable of creating new content, synthesizing data, and providing innovative solutions to complex problems 11. Generative AI models, particularly foundation models, can process and produce natural language text, perform tasks that require reasoning, generate computer code, summarize research findings, draft reports, and much more 8,9,20 . These models are continuously improving and can be deployed to assist in various HEOR tasks, potentially providing greater accuracy and efficiency in research11."}, {"title": "Foundation Models and Large Language Models (LLMs)", "content": "At the heart of generative AI are foundation models, such as LLMs, which are trained on massive datasets and designed to handle a wide array of tasks 8,20. Models, such as GPT-4, Gemini, Claude, and LlaMA, demonstrate remarkable versatility and effectiveness across various natural language processing tasks. These tasks include information extraction, language understanding, text summarization, question answering, and many more. They can perform competitively with task-specific models (e.g. specialized models that have been trained on clinical and health information) even with little to no task-specific training21."}, {"title": "Applications of generative AI in HEOR: Bridging theory with practice", "content": "The integration of generative AI, particularly through foundation models, has the potential to enhance HEOR by supporting and streamlining a range of tasks and activities, though early efforts come with limitations\u00b9\u00b9. Below, we explore key applications where generative AI shows potential, along with the challenges that accompany these advances."}, {"title": "Applications of Generative AI to Systematic Literature Reviews (SLRs)", "content": "An early exploration of generative AI and foundation models has focused on systematic literature reviews (SLRs), a critical process for evidence synthesis in health research\u00b9\u00b9. SLRs are timeconsuming and labor-intensive, requiring detailed and careful screening of abstracts and full text articles, bias assessment, precise and sometimes extensive data extraction, and may include quantitative meta-analyses involving a vast number of studies. Foundation models can streamline this process by assisting with several key tasks in a SLR. Specifically, foundation models can assist in developing the literature search strategies and screening abstracts and full text articles for inclusion and exclusion using predefined criteria22-25. For example, a recent study demonstrated high accuracy using a GPT-4-based reviewer in PRISMA-based medical systematic literature reviews26. Foundation models can also provide reasoning for excluding certain abstracts and full text articles27. They can assist with bias assessment by applying a list of questions to full text articles28,29. These models can extract structured data from unstructured text from research papers30. They can be trained to identify key data points, such as population characteristics, interventions, comparators, and outcomes (PICOs), improving the speed of data extraction31-33. Foundation models also generate code for running meta-analyses in R and Python33. Finally, they can generate concise summaries of the included studies, helping researchers synthesize findings more efficiently33. While foundation models have shown promise in automating SLR tasks, there are limitations. For example, there have been reports of hallucinations when providing mesh terms, and fabricated citations34. Accuracy of abstract disposition and data extraction is not always 100% accurate and continues to require manual validation28. Continued manual verification and human oversight is highly recommended11,12."}, {"title": "Applications of Generative AI to Health Economic Modeling", "content": "Foundation models present several applications in health economic modeling that have the potential to transform how models are conceptualized, developed, and utilized\u00b9\u00b9. LLMs can efficiently summarize existing economic models, providing a rapid synthesis of their methodologies and outcomes35. This capability is helpful for model parameterization and data extraction, where LLMs can expedite the identification and integration of relevant data points36. LLMs can assist with the creation of new, or de novo, health economic models by leveraging (sometimes extensive amounts of) existing literature and data to generate robust model frameworks37. One study demonstrated that a foundation model could replicate a three-state partition model for non-small cell lung cancer and renal cell carcinoma38. Another proof-ofconcept study showed that an LLM could fully replicate a published 'simple' health economic model evaluating the cost-effectiveness of combination therapy for HIV infection, including extraction of model structure, parameters idenfications, code development, and results evaluation39. LLMs might also be able to assist in other tasks associated with model development. For example, they could contribute to the validation of previously developed models by cross-verifying model assumptions and outputs against new data or parallel models. They could also enable the adaptation of existing models to different geographic or demographic contexts, enhancing their applicability and accuracy across varied settings. Transitioning models between platforms, such as from Excel to R Shiny, could also streamlined by LLMs, which can automate and error-check the conversion process. One of the more resource-intensive applications is conducting structural uncertainty analysis40. Here, LLMs can automate part of the workflow, significantly reducing the labor and time involved. Collectively, these applications of LLMs in health economic modeling highlight their potential to refine and accelerate economic evaluations. Despite the promise of AI in model development, human expertise is still necessary, and standards for the accuracy and reliability of AI-generated models must be established11,12."}, {"title": "Applications of Generative AI to Real-World Evidence (RWE) Generation", "content": "Generative AI and foundation models, have the potential to assist in generating RWE by improving efficiency, accuracy, and scale of real-world data that might be available for research. Only a small portion of EHR data is structured and in a format that lends itself to statistical analysis with minimal processing41. Most EHR clinical documentation and reports, exist as unstructured text. This unstructured data requires additional processing before it can be included in analytical datasets. For decades, advances in artificial intelligence (AI), particularly in natural language processing (NLP), have notably accelerated data extraction, information retrieval and summarization for RWE generation42. Emerging applications include deploying generative Al tools to extract information from unstructured electronic health records (EHRs) with the potential to accelerate their integration of this data into analyzable datasets, reduce manual efforts and minimize human errors21,43. For example, LLMs were shown to be successful in extracting biomarker testing details from EHR documents44. However some studies have questioned the accuracy of foundation models in their ability to map descriptive text to medical codes, finding that accuracy remains below 50%45. Approches to improve this include the use of specialized models (see also section below), such as GatorTron, NYUTron and Me Llama which are trained using large clinical texts46-48,49, and improving the prompts provided to GPT-3.5 and GPT-421. Additionally, by integrating multimodal data sources and adding imaging and genomics' information as well as structured clinical data, unstructured texts, foundation models might assist in developing more comprehensive datasets with a wider set of health outcomes50,51. For example, foundation models could accurately forecast COVID-19 cases and hospitalizations using real-time, complex, non-numerical information\u2014such as textual policies and genomic surveillance data\u2014previously unattainable in traditional forecasting models. 52."}, {"title": "Applications of Generative AI to Dossier Development and Reporting", "content": "Generative AI and foundation models can be used to enhance the efficiency of dossier development for pharmaceutical product reporting and submissions to HTA agencies12. LLMs excel at writing, can follow instructions for required styles, and can mimic the same style provided in other documents53,54. By automating the collation and presentation of evidence, generative Al might reduce the time and resources needed to produce comprehensive reports. Additionally, since LLMs are language-agnostic, they can generate documents suitable for different countries, facilitating international submissions and communications. Foundation models can also tailor communication materials to specific stakeholders, creating customized messages and visual aids that effectively convey the results of HEOR studies55. This makes them useful for example in developing lay summaries of technical reports 12."}, {"title": "Techniques to improve the use of generative AI in HEOR", "content": "As generative AI and foundation models continue to provide emerging opportunities to transform HEOR, applying specific techniques can significantly enhance the utility, accuracy, and reliability of Al models in this field 11."}, {"title": "Tokens: The Building Blocks of LLMs", "content": "In the realm of LLMs, tokens are the fundamental units of text that the models process. A token can represent a word, subword, or character. The way text is broken down into tokens affects how the model understands and generates language, influencing both the coherence and relevance of the output. Understanding tokens is important because it impacts tasks such as prompt crafting, data extraction, and the generation of reports. Awareness of tokenization helps in optimizing prompts to elicit more accurate and relevant responses from Al models. Additionally, since many AI service providers charge based on token usage, efficient token management can also have cost implications for HEOR projects."}, {"title": "Prompt Engineering", "content": "Prompt engineering involves techniques for providing instructions to foundation models to maximize the quality of generated outputs generated56. It includes designing instructions, or prompts, that guide LLMs to produce specific outputs through various strategies such as zeroshot, few-shot, chain-of-thought, and persona pattern prompting57,58,59. Zero-shot prompting enables LLMs to respond to novel queries based solely on the question posed without providing any examples (\u201czero\u201d), while few-shot prompting enhances accuracy by offering a few relevant examples (\u201cfew shot\u201d) 60. Chain-of-thought prompting facilitates complex decision-making by guiding the model to display its reasoning process step-by-step 61. Persona pattern prompting tailors outputs to align with the expertise and style expected of particular professional personas like health economists or policy makers . Several prompt engineering techniques have been utilized for conducting systematic literature reviews and economic modeling25,32,33 38. However, prompt engineering is not without limitations. Zero-shot and few-shot prompting may miss important nuances in complex tasks, chain-of-thought can generate overly verbose outputs, and persona pattern prompting requires accurate replication of professional personas which can be challenging."}, {"title": "Model Fine Tuning", "content": "Fine-tuning is a specialized technique where a pre-trained LLM undergoes additional training using targeted datasets to refine its capabilities for specific tasks62. Fine tuning might also take the shape of instruction tuning, using high-quality instruction-response pairs (i.e. pairs of questions and answers, known to be correct) 63,64. Fine-tuning can significantly improve the model's performance on niche or complex tasks by adjusting its parameters to better reflect the unique needs of the application44. Self-improving feedback loops and reinforcement learning from human feedback (RLHF) is a form of fine-tuning63. Self-improving feedback loops iteratively refine prompts based on the outputs received, at the request of the model, to enhance model performance over time. RLFH also has limitations which are described in detail in this study65. Fine-tuning is different from training a specialized model from scratch. An example in the HEOR space is Bio-SIEVE is a LLM developed to automate systematic review processes particularly title and abstract screening. Bio-SIEVE is instruction-tuned on Llama and Guanaco models to classify studies for inclusion or exclusion based on predefined criteria and it can reason through exclusion justifications further enhancing the efficiency of systematic reviews across multiple domains27. While fine-tuning offers significant benefits, it is not without challenges. It can be resource-intensive, requiring substantial computational power and expert knowledge to perform the fine-tuning. There is also a risk of overfitting to the specific data used for training, which might limit the model's generalizability to other tasks."}, {"title": "Domain-specific Foundation Models", "content": "Domain-specific foundation models are tailored for particular tasks or domains, like biomedical research or healthcare by utilizing domain-specific datasets to train the foundation model in more specific domains. For example, in healthcare, these models can be trained on clinical notes from electronic health records (EHRs) and other biomedical literature and texts, enhancing their performance on tasks like clinical named entity recognition, reasoning tasks, question and answering, and text summarization. Domain-specific foundation models can be trained from scratch using domain-specific data. For example, NYUTron, a large language model for medical language is trained on unstructured clinical notes to predict important clinical outcomes such as 30-day all cause readmission, in hospital mortality, and length of stay and showed improvement compared to traditional models47. GatorTron and GatorTronGPT are a generative clinical LLM developed using GPT-3 architecture and trained on clinical text from clinical departments and patients at the University of Florida Health, in addition to diverse English language text 48,46. Both NYUTron and GatorTron have been shown to achieve superior performance in clinical NLP tasks, like named entity recognition, compared to their general domain counterparts. In addition, domain specific foundation models can be built by continuously pre-training of opendoamin LLMs (e.g. Llama) using domain specific data. Examples of specialized models in this category include Me-LlaMA49 and BioClinicalBERT, which are based on Llama and BERT respectively and are continuously trained on biomedical and clinical texts67. Increased performance of domain-specific foundation models on certain tasks should be weighed against some limitations. Training such models can be prohibitively expensive and technically demanding, often making them inaccessible for smaller organizations. Nevertheless, some domain-specific foundation models, such as GatorTron, are available for free to researchers using a license agreement46. When deciding to use a such a model, researchers should weight the improved performance with the additional burden (cost, time to learn the model, expertise needed to use a specific model)."}, {"title": "Retrieval-Augmented Generation (RAG)", "content": "Retrieval-Augmented Generation (RAG) is a sophisticated method that combines the broad knowledge base of LLMs with precise, domain-specific data retrieval68. Conceptually a RAG system retrieves more up-to-date information, or task specific information from external knowledge or data sources (often stored in vector databases or knowledge graphs) than the LLM was pre-trained on\u00ba. For example, an application like ChatGPT can employ RAG to verify facts by accessing external databases or websites in real-time, ensuring responses not only draw from a vast internal dataset but are also cross verified with the latest external references. This capability significantly enhances the accuracy and reliability of the information provided, especially in rapidly evolving fields where the LLM might not have been trained on the most up to date data61. RAG could also facilitate the update of economic model parameters with the latest cost and utility data and create detailed market access analyses by retrieving and synthesizing pricing and reimbursement information across different markets. One limitation of RAG is the presence of conflicting information retrieval which can detrimentally affect RAG's output quality and is an active area of research 68,70."}, {"title": "Advanced Topics: Agent Driven Interactions and Tool Use:", "content": ""}, {"title": "Agent-Driven Interactions in LLMs", "content": "In artificial intelligence, \"agents\" are systems designed to carry out tasks or make decisions based on what they learn from their environment7\u00b9. For example, when smart assistants (like Alexa or Siri) are used, they are acting as an agent, responding to voice commands and performing tasks72. In HEOR, AI agents can be trained to complete specific roles, such as analyzing data or building economic models. In agent-based workflows, different AI systems (or agents) are each assigned a particular job within a project. These AI agents can collaborate, critique each other's outputs, and complete complex tasks more efficiently. For instance, one agent may be responsible for data extraction, another agent cross-checking the extracted values, and third agent feed extracted values directly into an economic modeling agent. While agentdriven approaches offer a lot of potential, it's still in early stages of development and requires significant expertise to manage effectively. More practice is needed to make these workflows fully reliable and scalable73,74."}, {"title": "Tool Use and API (Application Programming Interface) Integration", "content": "An effective method to enhance the use of LLMs involves the integration of external tools and API calls75. By augmenting LLMs with access to real-time data sources, specialized databases, or computational tools, researchers can leverage LLMs not only for text generation but also for more advanced tasks like real-world data analysis, economic modeling, or querying medical and healthcare databases. APIs can enable LLMs to interact with external software for specific calculations, thus improving precision and expanding the functional scope of these models in HEOR applications. For example, for systematic literature reviews, LLMs can query PubMed via API to pull relevant research studies and citations, facilitating comprehensive and automated searches on specific health topics, treatments, or diseases24,30,76."}, {"title": "Limitations of Gen AI as applied to HEOR", "content": "While generative AI and foundation models present promising opportunities in HEOR, several limitations must be acknowledged to ensure a balanced understanding and appropriate application of these technologies."}, {"title": "Scientific Validity and Reliability:", "content": "The outputs generated by AI models, particularly in complex fields like HEOR, can vary in terms of accuracy and reliability. Although models like GPT and other LLMs are continually improving, their ability to generate scientifically valid outputs that would not require human oversight remains limited. In addition, human users are still in a learning curve, optimizing their interactions with these models (e.g. through prompt engineering, or including external validation techniques such as RAG). Misinterpretations of data or overreliance on Al without proper validation can lead to errors that may compromise the quality of research and decision-making processes."}, {"title": "Bias and Equity:", "content": "A concern in the outputs of AI models is that they can inadvertently perpetuate or even exacerbate existing biases (e.g. systemic biases in a health care system, or underrepresentation of historically marginalized groups) present in their training data. In the context of HEOR, where decisions can impact health policies and patient outcomes, biased AI outputs can lead to unequal treatment or resource distribution among populations. Ensuring fairness and equity in AI applications is crucial but challenging, requiring constant monitoring and updates to the models. In HEOR, synthetic datasets and bias assessment tools play crucial roles in minimizing these risks and enhancing equity77. For instance, fairness indicators can analyze if Al models disproportionately favor wealthier regions in healthcare resource allocation, allowing for corrective measures to ensure more equitable distribution across socioeconomic groups ps78,79. The evaluation and identification of bias in models is an ongoing area of research11."}, {"title": "Regulatory and Ethical Considerations:", "content": "Foundation models must follow the regulatory frameworks that govern AI in the appropriate countries. The use of AI in HEOR must navigate complex regulatory landscapes that govern patient data privacy, consent, and transparency. Foundation models may memorize the data that they were trained on, posing a risk of reproducing protected health information (PHI) that they memorized during training80. Private companies providing the models may have access to the data uploaded or generated by uses for further model training or other purposes. With open-source models, leaks could also occur through improper use of the data by a user. Ethical considerations around the use of Al-generated insights in decision-making processes also demand stringent guidelines to avoid misuse and ensure that AI recommendations are always in the best interest of patients and public health11."}, {"title": "Adoption and Integration Challenges by the HEOR community:", "content": "Integrating AI into existing HEOR workflows can be technically and organizationally challenging. Resistance to change from traditional methods, lack of expertise in AI, and the high costs associated with implementing and maintaining AI solutions can hinder their widespread adoption and will require opportunities for HEOR professionals to have access to the appropriate training in a fastevolving field81."}, {"title": "Explainability and Interpretability in AI Models:", "content": "Explainability refers to the extent to which the internal mechanics of an AI system can be explained in human terms, while interpretability is about the degree to which a human can understand the cause of a decision made by an AI model. Generative Al models, such as LLMs, are often described as \"black boxes\" due to their complex architectures and the vast amounts of data they process. The nonlinear interactions within deep learning models make it difficult to trace specific outputs back to individual inputs or model parameters. Despite advances, achieving full explainability in complex generative AI models remains challenging. Ongoing research aims to develop methods that balance model performance with interpretability, ensuring that AI tools are both powerful and transparent82."}, {"title": "Conclusion", "content": "This article provides a taxonomy of key concepts in AI, especially generative AI, for the HEOR community as they engage with this new and promising field. Generative AI and foundation models have the potential to significantly enhance the field of HEOR research by streamlining workflows, increasing productivity, and offering innovative solutions to complex problems. However, this technology is not without its challenges. As we advance, it is crucial to critically assess the validity and reliability of AI outputs, actively address biases, and ensure adherence to ethical and regulatory standards. The article presents some advanced techniques which are being used to improve the accuracy of outputs using generative AI tools. For HEOR professionals, embracing generative AI and foundation models, involves not just the adoption of new technologies but also a commitment to ongoing education and collaboration across disciplines. Moving forward, the integration of AI into HEOR should be accompanied by robust frameworks for validation, bias mitigation, and ethical oversight, ensuring that these powerful tools are useful, transparent, trustworthy and ultimately serve to improve patient health outcomes by identifying equitable and effective healthcare solutions."}]}