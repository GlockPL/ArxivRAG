{"title": "Dynamic Demand Management for Parcel Lockers", "authors": ["Daniela Sailer", "Robert Klein", "Claudius Steinhardt"], "abstract": "In pursuit of a more sustainable and cost-efficient last mile, parcel lockers have gained a firm foothold in the parcel delivery landscape. To fully exploit their potential and simultaneously ensure customer satisfaction, successful management of the locker's limited capacity is crucial. This is challenging as future delivery requests and pickup times are stochastic from the provider's perspective. In response, we propose to dynamically control whether the locker is presented as an available delivery option to each incoming customer with the goal of maximizing the number of served requests weighted by their priority. Additionally, we take different compartment sizes into account, which entails a second type of decision as parcels scheduled for delivery must be allocated. We formalize the problem as an infinite-horizon sequential decision problem and find that exact methods are intractable due to the curses of dimensionality. In light of this, we develop a solution framework that orchestrates multiple algorithmic techniques rooted in Sequential Decision Analytics and Reinforcement Learning, namely cost function approximation and an offline trained parametric value function approximation together with a truncated online rollout. Our innovative approach to combine these techniques enables us to address the strong interrelations between the two decision types. As a general methodological contribution, we enhance the training of our value function approximation with a modified version of experience replay that enforces structure in the value function. Our computational study shows that our method outperforms a myopic benchmark by 13.7% and an industry-inspired policy by 12.6%.", "sections": [{"title": "1 Introduction", "content": "Parcel lockers have evolved into a viable alternative to traditional home delivery and are gaining increasing popularity worldwide. Recent surveys show, e.g., that 54% of online shoppers in Poland prefer to receive their parcels via parcel lockers (DHL 2022), 57% in China (Statista 2022), and in Estonia, 70% favor parcel lockers over other delivery options such as home delivery (Venipak 2023). As these lockers offer a huge potential to consolidate deliveries and decrease failed delivery"}, {"title": "2 Related Work", "content": "In this section, we give a concise review of the three major literature streams related to the DPLDMP. Section 2.1 focuses on demand management for out-of-home delivery, thereby covering publications in a similar application context. Taking on a more theoretical perspective, Section 2.2 is dedicated to relevant publications on demand management with reusable resources, and Section 2.3 addresses research involving upgrades. We summarize our findings with a tabular overview and delineate the paper at hand from the most closely related existing work in Section 2.4."}, {"title": "2.1 Demand Management for Out-of-Home Delivery", "content": "The last leg of the parcel delivery process, also known as the last mile, is notoriously cost-intensive, incentivizing researchers and practitioners to innovate. This manifests itself in two key trends: First, demand management has been integrated into various existing logistics services such as attended home delivery or same-day delivery in recent years (Fleckenstein et al. 2023). By controlling the availability or prices of delivery options, providers can actively steer demand and increase profitability (Wa\u00dfmuth et al. 2023). Second, various novel delivery concepts have emerged (Boysen et al. 2021). A prominent example is out-of-home delivery (OOHD), i.e., the delivery to parcel lockers or parcel shops instead of the recipient's home address. The DPLDMP is directly at the intersection of these two trends.\nThe review by Janinhoff et al. (2024) documents a surge in publications on OOHD, especially for location planning and routing problems. By contrast, research on demand management for OOHD is still in its nascent stage. While there is work on the satisfaction of customer preferences on an aggregate level (Dumez et al. 2021) and OOHD product design (Janinhoff et al. 2023), our analysis focuses on publications that explicitly take into account operational demand management, thereby also excluding work on dynamic OOHD problems without any demand steering component (e.g., Ulmer and Streng 2019). To the best of our knowledge, there exist only three publications matching these criteria, which we present in the following.\nGaliullina et al. (2024) consider demand management at the start of a retailer's fulfillment planning phase where all orders due for delivery on a specific day are known. The default delivery location is the home address, but the retailer can offer selected recipients a monetary incentive to switch to OOHD. Intervening at an earlier stage, Akkerman et al. (2023) investigate joint availability control and dynamic pricing of delivery options during the order arrival phase for a single delivery day. In cooperation with retailer Amazon, Sethuraman et al. (2024) study availability control for a parcel locker with uniform compartments."}, {"title": "2.2 Reusable Resources", "content": "From a theoretical perspective, the DPLDMP can be cast as a revenue management problem with reusable resources. Basically, revenue management is a special case of demand management where"}, {"title": "2.3 Upgrading", "content": "If alternatives can be ordered in a hierarchy, a seller can make use of upgrading by satisfying the demand for a specific product with another product higher in the hierarchical order. This enables the seller to alleviate short-term mismatches between capacity and demand. In the context of parcel lockers, this mechanism is relevant due to the compartment sizes, i.e., a parcel can be 'upgraded' to a larger compartment size than strictly necessary. While customers generally do not care about the compartment size as long as it is compatible with their parcel, methodology-wise this still equals a setting with upgrades.\nOut of the corresponding literature stream, we focus on publications with full cascading up-grades, i.e., upgrades to any product higher in the hierarchical order. Given that the resulting papers exhibit largely identical characteristics with regard to our classification scheme in Section 2.4, we center the discussion around three representative publications and refer the interested reader to the review by G\u00f6nsch (2020). Gallego and Stefanescu (2009) compare different up-grade mechanisms and incorporate fairness considerations. G\u00f6nsch and Steinhardt (2015) apply"}, {"title": "2.4 Summary and Research Gap", "content": "Table 1 summarizes the literature related to the DPLDMP. We characterize the publications according to the following dimensions: The column 'Decision' indicates the type of demand management decision (availability control (A) or pricing (P)). The next five columns track whether the problem features multiple types of resources, upgrading, advance reservations, stochastic us-age durations, and an infinite planning horizon. The last column classifies the solution approach as myopic (M) or anticipatory (A). As a special case of the latter, we highlight papers drawing on the deterministic linear program (DLP) or its choice-based variant (CDLP) because this is a fundamental revenue management concept (Gallego and Topaloglu 2019).\nIn line with the reviews by Ma et al. (2022) and Janinhoff et al. (2024), we find that demand management in OOHD is an emerging topic addressed by only a handful of very recent publi-cations. For all of them, one major line of distinction to our work is how capacity is modeled. Akkerman et al. (2023) and Galiullina et al. (2024) assume uncapacitated facilities, while Sethu-raman et al. (2024) consider a capacitated locker with uniform compartments. In contrast, we take into account multiple compartment sizes, thereby modeling capacity on a more granular and realistic level.\nAlthough problems similar to the DPLDMP have been covered in the context of reusable resources or upgrading, our analysis reveals a substantial research gap. Essentially, there are no publications on problems with stochastic usage durations that simultaneously feature upgrading. Note that upgrading introduces an additional decision to the problem as customers need to be allocated to a specific resource type. Vice versa, papers which do take into account upgrading"}, {"title": "3 Problem Statement", "content": "In this section, we give a detailed description of the DPLDMP and formalize it as a sequential decision problem. Appendix A provides a tabular overview of the notation. We conclude the section with an example."}, {"title": "3.1 Problem Definition", "content": "In short, the DPLDMP considers a single parcel locker to which parcels are delivered once every day. The availability of the compartments is uncertain and depends on the customer's pickup time, which is in turn bounded by the maximum storage time. New delivery requests arrive stochastically over the course of each day. After performing a feasibility check, the provider makes a demand control decision, i.e., accepts or rejects the request. In case of acceptance, the request turns into an order. At the end of each day, orders due for delivery are allocated to locker compartments. The objective is to maximize the expected number of accepted requests weighted by their priority.\nSection 3.1.1 introduces the main problem components on a more granular level together with the corresponding notation. In Section 3.1.2, we discuss our key assumptions."}, {"title": "3.1.1 Description and Notation.", "content": "We define the setting of the DPLDMP as follows:\nResources. We consider a single parcel locker. The locker consists of a limited number of compartments that differ in their size \u03b4 \u2208 D = {1,...,D}. The compartment sizes are indexed"}, {"title": "3.1.2 Main Assumptions.", "content": "Our definition of the DPLDMP draws on the following assumptions:\n1. The assumption of locker compartments allowing full cascading upgrades aligns with the locker layout configurations commonly encountered in practice. Typically, parcel lockers consist of multiple tower modules of uniform width such that the compartments sizes merely differ in their height.\n2. For ease of exposition, one can imagine the actual delivery to the locker happening immedi-ately after the allocation decision (for the parcels that are due for delivery on the subsequent day). Nevertheless, our problem definition does not rely on this simplification as long as the delivery is executed once each day and roughly at the same time. Consequently, we do exclude detailed operational planning such as vehicle routing and same-day delivery be-cause it creates a highly complex setting in its own right, even without any demand steering component (e.g., Ulmer and Streng 2019)."}, {"title": "3.2 Sequential Decision Problem", "content": "Leveraging the framework by Powell (2022), we model the DPLDMP as a sequential decision problem."}, {"title": "3.2.1 Decision Epoch.", "content": "A decision epoch k = 1, ...,\u221e is triggered by one of two possible events:\n1. Request arrival. Whenever a request arrives at t\u2208T, new information is revealed that necessitates a demand control decision."}, {"title": "3.2.2 Pre-Decision State.", "content": "The pre-decision state variable Sk encompasses all information necessary to make a decision in k and model the system from k onward:\n\u2022 Temporal information. We keep track of time with the current day Tk and point in time tk. Note that including T\u03b7 is only strictly necessary if the arrival or pickup probability distributions depend on it (e.g., the day of the week) and could otherwise be omitted. In contrast, incorporating tk is mandatory to know how much time remains until the next allocation decision.\n\u2022 Locker occupancy. To determine the available capacity, we require information on which locker compartments are presently occupied as well as the amount of time each parcel has already been waiting in the locker. We use the dwell time h \u2208 H = {1, . . ., B-1} to indicate that a parcel is spending its hth day in the locker (starting with the day immediately after its allocation) with B representing the maximum storage time. Note that we do not need to track parcels with a dwell time of B as we know for certain that they will either be picked up or removed from the locker by the end of the current day. We represent the number of compartments of size 8 that are occupied by a parcel belonging to a customer of type c on the hth day since its allocation with $l_{\u03b4ch}^{k}$. th Overall, we can write $L_{k} = (l_{\u03b4ch}^{k})_{\u03b4\u2208D,c\u2208C,h\u2208H}$ for the locker occupancy in k.\n\u2022 Pending orders. Besides the orders already delivered to the locker, we need to keep track of the orders scheduled for delivery in the following days, which result from previously accepted requests. We use the remaining fulfillment time_f \u2208 F = {1,...,F} to indicate that an order must be assigned to a compartment in the fth allocation decision from now with f = 1 symbolizing that the order must be allocated at T + 1 of the current day. Directly after accepting a request, its remaining fulfillment time is equal to its lead time. In other words, we use f as a countdown to track the amount of time until the actual delivery, i.e., the remaining fulfillment time of each order decreases by one unit with each passing day as a part of the transition function (Section 3.2.5). Letting $o_{\u03b4c}^{f}$ refer to the number of parcels of size d belonging to a customer of type c that must be allocated in the fth allocation decision from now, we model the pending orders in k with $O_{k} = (o_{\u03b4c}^{f})_{d\u2208D,c\u2208C,f\u2208F}$.\n\u2022 Request type. Based on the three request attributes, we construct request types r\u2208 R = {1, ..., C. D .E} with the associated customer type cr, parcel size dr, and lead time er."}, {"title": "3.2.3 Decision.", "content": "The decision space X(Sk) encompasses all feasible decisions in Sk. We generally use Xk \u2208 X(Sk) to refer to the decision in k. The specific type of decision depends on tk (Section 3.2.1):\nDemand control. If tk \u2208 T, the provider must make a demand control decision regarding request rk. We denote it by gk with gk = 0 encoding rejection and gk = 1 acceptance. For ease of exposition, we model rejections due to infeasibility as a special case with a reduced decision space. To determine the demand control decision space X(Sk) = G(Sk) \u2286 {0,1}, the provider performs a feasibility check.\nTo classify a newly arrived request in decision epoch k as feasible, the provider must prove that it can be feasibly allocated for any pickup time realization of itself as well as the parcels represented by Ok and Lk. Therefore, we need to check whether a tentative allocation plan spanning the next F days exists where all orders in Ok and the request are allocated to sufficiently large compartments without reallocation over time while maintaining the assignment of orders in Lk and respecting the limited number of compartments Qs. Assuming for the sake of the feasibility check that all customers make use of the maximum storage time, we formalize these constraints in Appendix B. If a feasible solution to constraints (6)-(10) in Appendix B exists, G(Sk) = {0,1} and G(Sk) = {0} otherwise. Note that the tentative allocation plan only serves to determine the demand control decision space and is discarded afterwards.\nAllocation. In tk = T + 1, the provider must allocate parcels scheduled for delivery on the following day, i.e., all pending orders in Ok with f = 1, to available and compatible locker compartments. Let $a_{\u03b4c}^{\u03b4k}$ encode the number of parcels of size d belonging to a customer of type c that are allocated to a compartment of size 6 (with d \u2265 d) in k with $A_{k} = (a_{\u03b4c}^{\u03b4k})_{d\u2208D,\u03b4\u20ac{d,...,D},c\u2208C}$.\nTo maintain feasibility, we require the allocation decision to comply with the constraints imposed by the feasibility check. The allocation decision space X(Sk) = A(Sk) encompasses all feasible solutions to constraints (6)-(13) in Appendix B."}, {"title": "3.2.4 Post-Decision State.", "content": "After making a decision in Sk, the system deterministically transitions into the post-decision state $S_{k}^{\\prime} = (T_{k}, t_{k}, L_{k}^{\\prime}, O_{k}^{\\prime})$. We model this with the transition function $S_{k}^{\\prime} = S^{M x}\\left(S_{k}, X_{k}\right)$. In case of demand control, the locker occupancy remains unchanged ($L_{k}^{\\prime} = L_{k}$). The pending orders $O_{k}$ are updated to $O_{k}^{\\prime}$ with $o_{dc}^{k}\\\ndef= o_{dc}^{f} +\\\nmathbb{1}(d=d_{r_{k}}, c=c_{r_{k}}, f=f_{r_{k}}, g_{k}=1)$ and $\\mathbb{1}(\\cdot)$ symbolizing"}, {"title": "3.2.5 Exogenous Information.", "content": "The exogenous information $W_{k+1} = (T_{k+1},t_{k+1}, r_{k+1}, P_{k+1}) \u2208 W(S)$ comprises all information that is revealed when transitioning from $S_{k}^{\\prime}$ to $S_{k+1}$. We formalize this with the transition function $S_{k+1} = S^{M W}(S_{k}^{\\prime}, W_{k+1})$ and represent the probability of observing $W_{k+1}$ when in $S_{k}^{\\prime}$ with $P(W_{k+1}|S_{k}^{\\prime})$. Note that while we can deterministically infer $T_{k+1}$ from $S_{k}^{\\prime}$, we model it as part of $W_{k+1}$ for the sake of readability. In contrast, $t_{k+1}$ and $r_{k+1}$ depend on the stochastic request arrival process. To model the second source of uncertainty, the parcel pickup, $p_{\u03b4ch}^{k+1}$ denotes the number of compartments of size 8 that had been occupied by a parcel belonging to a customer of type c for a dwell time of h in $S_{k}^{\\prime}$ and become available again during the transition to $S_{k+1}$.\nIn aggregated form, we can write $P_{k+1} = (p_{\u03b4ch}^{k+1})_{\u03b4\u2208D, c\u2208C, h\u2208H}$. Starting from $S_{k}^{\\prime}$, we determine the pending orders and locker occupancy in the next pre-decision state $S_{k+1}$ through $O_{k+1} = O_{k}^{\\prime}$ and $l_{\u03b4ch}^{k+1} = p_{\u03b4ch}^{k+1}$."}, {"title": "3.2.6 Reward, Policy, and Objective Function.", "content": "We define the reward function R(Sk, Xk) as follows: If the provider accepts a request during demand control, the reward function takes on the value of the priority weight mc associated with the request's customer type $c_{r_{k}}$, i.e., $R(S_{k},g_{k} = 1) = m_{c_{r_{k}}}$, and $R(S_{k},g_{k} = 0) = 0$ in case of rejection. The allocation decision yields no immediate reward (R(Sk, Ak) = 0).\nThe solution to a sequential decision problem is a policy \u03c0\u2208 \u03a0. The policy maps states to decisions, denoted by $X_{\u03c0}(S_{k})$. The optimal policy $\u03c0^{*}$ maximizes the objective function. Due to the infinite planning horizon of the DPLDMP, we cannot simply formulate the objective as the expected sum of rewards over all decision epochs as it would grow to infinity. To avoid this, we could introduce a discount factor. However, from a theoretical perspective, discount factors are not well-suited for value function approximation in an infinite-horizon setting, which is an essential part of our solution strategy (see Sutton and Barto 2018, Chapter 10.4 for details). An alternative option, which fits better to our needs, is to define the objective as the expected average reward per decision epoch with reward rate $R^{*}$ (Sutton and Barto 2018, Chapter 10.3):\n$R^{*} = \\max _{\\pi \\in \\Pi} \\lim _{K \\rightarrow \\infty} \\frac{1}{K} E_{\\tau^{\\pi}}\\left[\\sum_{k=1}^{K} R\\left(S_{k}, X_{\\pi}\\left(S_{k}\\right)\\right) | S_{0}\\right]$"}, {"title": "3.2.7 Value Function and Opportunity Cost.", "content": "The value function V(S) represents the value of being in a given state $S \\in S \\cup S^{\\prime}$ and, in the average reward setting, equals the expected sum of rewards adjusted by $R^{*}$ if we start in S and apply the optimal policy \u03c0* from that point onward (Mahadevan 1996). We can define the value function recursively with the Bellman equation (Sutton and Barto 2018):\n$V(S_{k}) = \\max _{X_{k} \\in X(S_{k})}\\left{R\\left(S_{k}, X_{k}\\right)-R^{*}+E_{\\mathbb{W}_{k+1}}\\left[V\\left(S_{k+1}\\right)\\right]\\right} = \\max _{X_{k} \\in X(S_{k})}\\left{R\\left(S_{k}, X_{k}\\right)-R^{*}+\\sum_{\\mathbb{W}_{k+1} \\in \\mathbb{W}(S^{\\prime})} P\\left(W_{k+1} | S_{k}^{\\prime}\\right) V\\left(S_{k+1}\\right)\\right}$\nConsidering the demand control decision for a feasible request, the first expression can be reformulated to $V(S_{k}) = \\max\\left\\{m_{c_{r_{k}}}-R^{*}+V\\left(S^{M x}\\left(S_{k}, g_{k}=1\\right)\\right) ;-R^{*}+V\\left(S^{M x}\\left(S_{k}, g_{k}=0\\right)\\right)\\right\\}$.\nDefining AV(Sk) as the opportunity cost (Talluri and Van Ryzin 2004), i.e., the difference in post-decision state values caused by accepting the request in decision epoch k, we can rearrange the terms and observe that under the optimal policy \u03c0*, a feasible request is accepted if and only if the following holds:\n$m_{c_{r_{k}}} \\geq V\\left(S^{M x}\\left(S_{k}, g_{k}=0\\right)\\right)-V\\left(S^{M x}\\left(S_{k}, g_{k}=1\\right)\\right) = \\Delta V\\left(S_{k}\\right)$ (3)\nIn other words, the immediate reward of accepting the request, which is equal to merk, must be at least as large as the request's opportunity cost due to the expected displacement of future customers.\nInsight 1: AV(Sk) is nondecreasing with increasing parcel size (proof in Appendix C). From this, we infer that requests with smaller parcels tend to be, ceteris paribus, more likely to get accepted under \u03c0* than larger parcels. Intuitively speaking, smaller parcels offer more 'upgrading' possibilities and can therefore be allocated with more flexibility."}, {"title": "3.3 Example", "content": "To illustrate the sequential decision problem presented in the previous section, we provide a stylized example in Figure 2. For clarification, we index parcels by i and compartments by j to explicitly refer to the respective elements in the figure. Note that we introduce these indices for didactic purposes only.\nThe example includes two compartment and parcel sizes \u03b4, d \u2208 {1,2} and a parcel locker with Q2 = 2 large (j = 1,2) and Q1 = 3 small compartments (j = 3,4,5). Each day consists of T = 9 points in time and the allocation decision in T + 1 = 10. We focus on a given day \u03c4. For ease of exposition, we consider a single customer type (C = 1) with priority weight m\u2081 = 1 such that Lk and Ok can be represented by two-dimensional matrices. The maximum storage time is B = 3 days, and the lead time is up to E = 6 days. For the sake of brevity, we omit request types and"}, {"title": "4 Solution Approach", "content": "In this section, we present our solution approach to obtain a policy for the DPLDMP. First, we outline our framework and the core ideas behind it in Section 4.1. Second, we specify the cost function approximation (CFA) that governs allocation decisions in Section 4.2. Third, Section 4.3 is dedicated to the parametric value function approximation (VFA) responsible for demand control."}, {"title": "4.1 Outline and Motivation", "content": "The well-known 'curses of dimensionality' (Powell 2022) render the computation of \u03c0* intractable for realistic problem sizes. While G(Sk) is manageable because |G(Sk)| \u2264 2, A(Sk) corresponds to a multidimensional resource allocation decision space that grows combinatorially in its dimensions. Similarly, the multidimensional matrices in Sk, S and Wk lead to prohibitively large state and outcome spaces S, S, W(Sk) for real-world applications. To overcome these challenges, we need to develop a suitable solution approach.\nApart from the two sources of uncertainty induced by request arrivals and parcel pickups, a key characteristic of the DPLDMP stems from the two types of strongly interrelated decisions arising at different points in time. Consequently, the solution framework must not only encompass tailored components to handle each decision type on its own, but also properly address their interdependencies:\n\u2022 Well-performing allocation decisions ensure that the locker's limited capacity is utilized efficiently and simultaneously create favorable conditions for subsequent demand control. This requires anticipating allocation decisions for pending orders and predicting new orders resulting from future demand control.\n\u2022 As shown in (3), optimal demand control essentially trades off a request's immediate reward with its opportunity cost. As a result, demand control should factor in allocation decisions as they influence the available capacity in the compartments, shape the decision space for future demand control, and affect the capacity consumption caused by accepting the request, which is all reflected in the opportunity cost.\nTo handle the interdependencies between the two decision types, we propose a hierarchical approach. More precisely, our solution framework comprises two components, one for demand control and one for allocation, with different levels of sophistication. Given that demand con-trol determines which requests turn into orders and aims at reserving capacity for higher-priority customers, it presents itself as a more promising lever to improve overall performance. By com-parison, allocation merely serves as a secondary decision. Intuitively speaking, it is harder to compensate bad demand control decisions with good allocation decisions than vice versa. Bearing this in mind, we consciously limit the computational effort of the allocation component in favor of an elaborate demand control component.\nDrawing on the framework by Powell (2022), we design the individual components as follows:\n\u2022 Allocation is characterized by its extensive decision space. In light of this, we employ cost function approximation (CFA), which yields a parameterized deterministic optimization model. This allows us to efficiently search the decision space through standard solvers.\n\u2022 By contrast, the demand control decision space is limited to at most two options, namely acceptance or rejection of the current request. If the provider accepts a feasible request, it"}, {"title": "4.2 Cost Function Approximation", "content": "Cost function approximation (CFA) involves solving a parameterized deterministic optimization model where the objective or constraints are modified to induce decisions that perform well over time and under uncertainty. For the problem at hand, we apply this concept to the allocation decision and tweak the immediate reward such that it provokes decisions conducive to demand control. This entails two steps: First, designing the parameterization (Section 4.2.1), and second, determining the parameter values (Section 4.2.2)."}, {"title": "4.2.1 Design of Parameterization.", "content": "As a starting point for modifying the immediate reward function of allocation decisions, we identify two favorable circumstances for subsequent demand control:\n1. In general, larger compartments tend to be more valuable as they fit more parcel sizes and offer more flexibility. Although the example in Section 3.3 proves that it is not optimal"}, {"title": "4.2.2 Parameter Selection.", "content": "After specifying the CFA design, we need to determine suitable values for $\u03c5_{\u03b4\u03bb}$. A key challenge is posed by the large space of potential parameterizations that grows combinatorially with the number of compartment sizes D and window lengths F. To tackle it, one would typically resort to methods from the realm of stochastic search (Powell 2022, Chapter 11.12). However, these methods require evaluating each generated parameter configuration. In our case, this is computa-tionally expensive as the CFA parameters are also embedded in the VFA feature design and part of the VFA training procedure. More specifically, we have to retrain the VFA whenever the CFA parameters are adapted and then measure the performance of the resulting policy through sim-ulation. Consequently, evaluating a sizeable number of parameters is hardly tractable. Instead, we limit the number of candidate parameterizations a priori through domain knowledge, thereby sidestepping the issue of excessive computational effort for parameter tuning."}, {"title": "4.3 Value Function Approximation", "content": "If an oracle were to provide us the optimal value function V(S), applying the decision criterion in (3) becomes trivial. Essentially, it boils down to trading off the request's immediate reward, i.e., its priority weight, with the opportunity cost. The opportunity cost captures the potential displacement of future customers: Each accepted request consumes capacity, which might force the provider to reject future requests.\nAs laid out in Section 4.1, the curses of dimensionality render the computation of V(S) intractable for realistic problem sizes, compelling us to rely on approximation. Specifically, we employ a parametric value function approximation (VFA) to overcome the curse of dimensionality in the state space. Instead of computing the value for each state individually, we learn a parametric function with a vector of weights 0 to obtain value estimates $V (S|0)$. As an input for the VFA, we devise a set of features $(S)$ to extract relevant information from the state variable and combine them in a suitable functional form, which is detailed in Section 4.3.1. Subsequently, Section 4.3.2 sheds light on the procedure to learn the parameter weights 0."}, {"title": "4.3.1 Feature Design.", "content": "As a preliminary consideration, we first establish which values we seek to approximate given that the value function can be computed for pre-decision states Sk, post-decision states S or pairs of pre-decision states and decisions (Sk, Xk). The latter corresponds to the 'Q-values' typically used in RL, where rewards are modeled as a random variable. By contrast, we want to exploit"}, {"title": "4.3.2 Training.", "content": "To train the VFA parameter weights 0, we combine different RL techniques in a simulation-based learning process that is executed offline. Our algorithmic procedure encompasses two types of updates: Upon each simulated demand control decision, we update the parameter weights"}, {"title": "5 Computational Study", "content": "In the following, we present our computational study. After explaining its setup in Section 5.1, the subsequent analysis of our experiments serves two purposes: Firstly, we aim to assess the overall performance of our solution framework and gain an understanding of the contribution of individual algorithmic components (Section 5.2). Secondly, we aspire to provide managerial insights (Section 5.3)."}, {"title": "5.1 Design", "content": "Our study encompasses nine settings that differ with regard to the customer prioritization scheme and pickup behavior. In this section, we introduce the corresponding parameters (Sections 5.1.1 and 5.1.2) and the investigated policies (Section 5.1.3). Furthermore, we define the metrics used for evaluation (Section 5.1.4)."}, {"title": "5.1.1 Setting-invariant Parameters.", "content": "The following parameters apply to all settings:\nResources. We include three compartment sizes D = {1,2,3} with Q1 = 15, Q2 = 10 and Q3 = 5. For readability, we encode the compartment sizes as S, M, L for d = 1,2,3 respectively.\nTime. Each day consists of T = 20 discrete points in time with the allocation decision in T + 1 = 21.\nRequests. In all settings, there are two customer types C = {1,2}. At each point in time t, a customer of type c = 1 arrives with probability 0.3, of type c = 2 with probability 0.6, and with probability 0.1 there is no customer arrival. We consider c = 1 to be premium customers with expedited shipping, leading to a lead time of e = 1 with probability 1. For standard customers (c = 2), the lead time e equals 1, 2, 3, 4, or 5 days with a respective probability of 0.2, 0.2, 0.3, 0.2, and 0.1. The probabilities for the parcel sizes are identical for both customer types and are proportional to the number of compartments per size (,,for S, M, L).\nParcel pickups. The maximum storage time is B = 3 days."}, {"title": "5.1.2 Setting-dependent Parameters.", "content": "The settings result from combinations of different customer priorities and pickup probability distributions. Regarding the former, we vary the priority weight of premium customers m\u2081 \u2208 {1,2,3} while keeping the weight of standard customers constant (m2 = 1). This allows us to gauge the impact of the priority weights, which is a central input parameter to the DPLDMP.\nFor parcel pickups, we examine three probability distributions: With the first one, premium and standard customers exhibit the same pickup behavior (id for 'identical'). Under the second one, premium customers collect their parcels faster (pf for 'premium fast'), which is motivated by empirical evidence (Sethuraman et al. 2024). Lastly, with the third distribution, we make this difference in pickup speed even more pronounced (pu for \u2018premium ultrafast'). Remember that we express the pickup time as a tuple \u03c8 = (b,q) where b represents the number of days after allocation and q the point in time (Section 3.1). We state the probabilities for b in Table 3. To make our settings realistic, we select the probabilities for id based on the fact that about 60% of parcels are picked up within one day after delivery in practice (Hovi et al. 2023). For comparability, we specify the probabilities for pf and pu such that the aggregated distribution over the entire customer population remains unchanged, i.e., in each setting, 60% of all parcels are picked up within one day, 20% on the second day, and 20% on the third day. We assume a uniform distribution for q, leading to a probability of = for each point in time t \u2208 T in all settings.\nWe consider all 3.3 = 9 combinations of prioritizations and pickup distributions. As shown in Table 4, we encode the settings by concatenating m\u2081 with the respective abbreviation for the pickup distribution."}, {"title": "5.1.3 Policies.", "content": "Because of the two types of decisions present in the DPLDMP, each of our policies consists"}]}