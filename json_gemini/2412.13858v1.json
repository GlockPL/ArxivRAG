{"title": "IDEQ: an improved diffusion model for the TSP", "authors": ["Mickael Basson", "Philippe Preux"], "abstract": "We investigate diffusion models to solve the Traveling Salesman Problem. Building on the recent DIFUSCO and T2TCO approaches, we propose IDEQ (constrained Inverse Diffusion and Equivalence class-based retraining of diffusion models for combinatorial optimization). IDEQ improves the quality of the solutions by leveraging the constrained structure of the state space of the TSP. Another key component of IDEQ consists in replacing the last stages of DIFUSCO curriculum learning by considering a uniform distribution over the Hamiltonian tours whose orbits by the 2-opt operator converge to the optimal solution as the training objective. Our experiments show that IDEQ improves the state of the art for such neural network based techniques on synthetic instances. More importantly, our experiments show that IDEQ performs very well on the instances of the TSPlib, a reference benchmark in the TSP community: it closely matches the performance of the best heuristics, LKH3, being even able to obtain better solutions than LKH3 on 2 instances of the TSPlib defined on 1577 and 3795 cities. IDEQ obtains 0.3% optimality gap on TSP instances made of 500 cities, and 0.5% on TSP instances with 1000 cities. This sets a new SOTA for neural based methods solving the TSP. Moreover, IDEQ exhibits a lower variance and better scales-up with the number of cities with regards to DIFUSCO and T2TCO.", "sections": [{"title": "1 Introduction", "content": "Recent years have seen a surge in machine learning models to solve combinatorial optimization (CO) problems. The field of combinatorial optimization is a historical field of research and application in computer science. After decades of progress, very efficient algorithms exist to provide exact solutions or approximate solutions to many CO problems. The Traveling Salesman Problem (TSP) stands as a prominent example of this fact: the TSP is very appealing as it is very simple to understand, it has a wide range of applications, and we are able to solve exactly rather large instances of this problem on a mere laptop (an instance defined over a few thousands cities can be solved within one hour), and we have approximate algorithms that are able to find tours that are very close to optimality (LKH3 [4] can solve instances of 40,000 cities in about one hour on a laptop but we have no guarantee that the result is optimal). These facts can not be forgotten when we try to propose alternate approaches to solve the TSP.\nBecause of its appeal, the TSP has also drawn the attention of researchers in deep neural networks in the recent years. If the first attempts had difficulties solving even small TSP instances of a dozen cities, progress has been made. In this paper, we build on these previous works and go a step further. In terms"}, {"title": "2 Background and related works", "content": "Our approach, IDEQ, relies on diffusion-based models [25, 5, 26, 20, ?], and particularly the recent DIFUSCO and T2TCO [27, 15]. Solving a supervised learning problem, IDEQ aims at learning an optimal tour for a given TSP instance. With regards to DIFUSCO and T2TCO, we improve the inference by leveraging the highly constrained structure of the solution space of the TSP. We also replace the later stage of the training curriculum of DIFUSCO by adding a simplified objective replacing the unique instance-conditioned ground truth solution by a uniform distribution of solutions.\nOur presentation goes as follows: after a review of the related literature, we describe IDEQ, a new diffusion-based combinatorial optimization solver for the TSP. In applied combinatorial optimization, the criterion is the experimental performance. So we took a great care to investigate the experimental performance of IDEQ: in the case when the authors made their software program available, we carefully reviewed their code which led us to the conclusion that at least in one case, the implementation differs from the description made in the paper and that this unreported difference is key in the experimental performance. Following the CO community practices, we experimented IDEQ on the TSPlib which is a well-known benchmark on which we report unprecedented performance using a neural net based approach, competitive with regards to state-of-the-art (SOTA) non neural approaches. We report on these experimental performance, and perform a detailed analysis of the various components of IDEQ to disentangle the contribution of each."}, {"title": "2.1 About the TSP", "content": "Let us consider the basic, and usual definition of the Traveling Salesman Problem. An instance of the TSP is defined in the Euclidean plane by a set of N cities. N is also known as the \"size\" of the instance. We will denote TSP-N a TSP instance of size N. The goal is to find a shortest tour that visits at least once each of the N cities. An instance may be defined either by the location of the cities, or by a distance matrix between the cities. There exists many variations of this definition in Euclidean and non Euclidean spaces. In this paper, TSP refers to this particular family of planar Euclidean instances. The TSP is a well-known example of a NP-hard problem: the time/memory requirements to solve an instance of size N grow in O(exp (N)) so that the size of the instances that can be solved within a reasonable amount of time is very limited. For instance, today, the state-of-the-art exact solver Concorde solves an instance of the TSP of size N = 103 in about 10 minutes on a laptop. For"}, {"title": "2.2 Denoising diffusion models", "content": "Denoising diffusion models have been initially introduced by [25] and further expanded by various authors [5, 26, 20, ?]. The aim is to sample a complex data distribution. The idea is to start from an easy to sample distribution and then going through a set of iterative Markovian transformations which mimics the reverse of a diffusion process, to sample from more and more complex distributions which converge toward the target complex distribution. The training of these models is done in a supervised manner.\nThese family of generative models have now become SOTA for (conditioned) image and video generation [23, 22, 6, 24]. They have also achieved great performance in areas like audio synthesis [12, 33] or molecule generation [30, 29, 8]. They have also shown their usefulness for image or text generation [1], and combinatorial optimization [27]. They can be defined in continuous or discrete time or space. Most of denoising diffusion models are using continuous state space but discrete models, initially introduced by [25] and further expanded by [1, 7]."}, {"title": "2.3 Diffusion models for combinatorial optimization", "content": "A solution to a TSP can be represented by an $N\\times N$ adjacency matrix $A = (a_{i,j})$ where $a_{i,j} = 1$ if there exists a link between city $i$ and city $j$, 0 otherwise. A is symmetrical. One may soften this definition and define $a_{i,j}$ as the probability that there exits a link between $i$ and $j$. This produces a heatmap which may be seen a stochastic adjacency matrix. A diffusion model can be used to sample from this heatmap starting from an easy to sample, all off-diagonal terms being equal to some value $p$.\nDiffusion models to predict the instance-conditionned adjacency matrix of graph-based combinatorial optimization problems have been introduced by DIFUSCO [27]. In DIFUSCO, a denoising diffusion process is used to predict the heatmap of the solution for a given TSP instance starting with $p = 1/2$. Inference time is rather short. The training is done in a supervised manner on large synthetic datasets. One such dataset is made of thousands of random instances of a certain size N labeled with their optimal (or best known) tour. Training requires significant computational resources to create the dataset (we need to compute the optimal tour of each instance of the dataset) and then to train the network. DIFUSCO is trained by curriculum learning: the network is first trained on TSP-100 random 2D instances. Then, this first checkpoint (the weights of the network) is trained on TSP-500 instances. Then, the TSP-500 checkpoint is trained on TSP-1000 instances. We call \"TSP-N checkpoint\" the checkpoint of the model trained up to (and including) the TSP-N instances of the curriculum learning. The first training stage of the curriculum (the TSP-100 checkpoint) is the bottleneck in terms of computational needs, requiring an order of magnitude greater training steps than the subsequent trainings. It is noteworthy that the size of instances a checkpoint is trained on does not constrain the size of instances that can be solved: as we will see in the experiments, with a TSP-1000 checkpoint, we predict instances which size ranges from 100 to 7397. DIFUSCO can be used with either continuous, discrete, or discretrized diffusion. Then, T2TCO [15] have introduced a search procedure during the inference to improve the quality of the solution. Published results are impressive. However, while carefully inspecting and testing their code, we have found that their \"gradient based search\" is not responsible for the improvement. Indeed, this search is based on sequential steps of partial diffusion and subsequent inverse diffusion, but replacing these steps by the original, non guided, inverse diffusion steps does not affect the results. This approach generates an initial solution which can be improved by a search procedure such as 2-opt, or MCTS, or by some sampling procedure.\nDISCO [31] is another diffusion-based combinatorial optimization solver that uses an analytically solvable diffusion to speed-up inference. Similar to our work, they leverage the constrained structure of the solution space but unlike IDEQ, they do so by using a residual diffusion [17] to restrict the sampling space to a more contrained domain.\nIDEQ builds further on the discrete state space version of DIFUSCO and T2TCO."}, {"title": "2.4 Other constructive neural solvers for combinatorial optimization", "content": "To avoid the costly generation of the supervised training dataset, other approaches leverage unsupervised learning or reinforcement learning. UTSP [18] uses scattering attention GNN [19] to generate a soft indicator matrix that can be simply transformed into a heatmap. The network parameters are optimized through gradient descent on the tour length augmented with a carefully chosen penalty terms. The tour is then refined with extensive Monte-Carlo tree search. They achieve results similar to DIFUSCO using lower training time.\nThe majority of the neural combinatorial optimization solvers rely on reinforcement learning. These can be either autoregressive (incremental construction of the solution) or generating the full solution in one-shot. The former category includes BQNCO [3]], POMO [14] and SymNCO [11] while the latter category includes DIMES [21]. DIMES employs a meta-learning framework and a continuous parameterization of the solution space which enables a stable REINFORCE-based training. In BQ-NCO the state space of the MDP associated with the problem is simplified by bisimulation quotienting. The policy network architecture is based on a transformer [28] or a perceiver [9] architecture. POMO builds on the attention-based model of [13] but leverages symmetries by data augmentation and stabilizes REINFORCE training by using multiple initiations. SymNCO also leverages symmetries by introducing regularization in REINFORCE and by learning invariant representation for pre-identified symmetries. SymNCO and POMO do not scale well beyond 200 cities for the TSP. ICAM [32] builds upon POMO, modifying the attention mechanism and the reinforcement learning training scheme to significantly improve performance on larger TSP instances (up to 103 cities)."}, {"title": "3 Methods", "content": "This section describes the two main ingredients of IDEQ and then specifies IDEQ itself."}, {"title": "3.1 Background on discrete diffusion models for combinatorial optimization", "content": "Given a random variable $x_o$ drawn from a certain distribution $P_{complex}$, a variational diffusion model is a latent variable model that progressively adds noise to $x_o$ following a Markovian forward process, denoted as $q(x_t \\vert X_{t-1})$ which generates a sequence $x_{1:T}$ recursively defined as $q(x_{1:T} | x_o) = \\Pi_{t=1}^T q(x_t \\vert x_{t-1})$ such that $q(x_T) \\sim P_{simple}$ where $P_{simple}$ is an easy to sample from distribution such as a Gaussian for continuous state diffusion, or a multinomial for discrete state diffusion. The reverse process, called the backward process, $p(x_{t-1}|x_t, x_0)$ is approximated by a Markovian process parameterized by a neural network:"}, {"title": "3.2 Key ingredient 1: leveraging the constrained structure of the solution space to improve inference-time solution generation", "content": "In the TSP, the true probability distribution $x_o(x_t, t | I)$ lies on a very constrained manifold of optimal Hamiltonian tours. In the original implementation of DIFUSCO, such a constraint is not enforced, the network has to learn it, leading to sub-optimal convergence of the solution to possibly non-Hamiltonian adjacency matrices.\nIn order to circumvent this problem, we propose to modify the parameterization of the backward process by applying a Hamiltonian tour reconstruction operator $H$ to the predicted $x_o$ to enforce the Hamiltonian constraint. This tour reconstruction operator is the one used at the end of the backward process in DIFUSCO and T2TCO to reconstruct the tour from the generated heatmap.\nSimilarly, to guide the backward process towards an optimal tour, we apply the 2-opt. Let us denote $R_2$ the 2-opt operator. As $H \\vert x_o$ is now a Hamiltonian"}, {"title": "3.3 Key ingredient 2: leveraging equivalence class over target distribution to fine-tune diffusion checkpoints", "content": "If $x_o$ is an optimal tour then $R_2x_o = R_2x_o = x_0$ where $R_n$ denotes n successive applications of 2-opt: an optimal (locally or globally) tour is a fixed point of 2-opt. Let us further denote by $R_2$ the following equivalence relation: $x R_2 y$ if n $\\in$ N such that either $x=R_n y$ or $y=R_2 x$. We propose to replace the training objective of the diffusion model to be the uniform distribution over the equivalence class of $x_o$ for the relation $R_2$ instead of a Dirac mass located on $x_o$ for a given instance $I$. This procedure increases the dimensionality of the set supporting the target distribution which we hypothesize will drive the diffusion process towards a more robust distribution. The initial distribution is supported by a single point from the new distribution. This procedure allows us to leverage the curriculum learning of DIFUSCO where the most resource-consuming step is the training of the TSP-100 checkpoint. Each of the subsequent trainings is initialized with the previous checkpoint and it requires approximately an order of magnitude less training steps making these subsequent curriculum learning steps a very good fit for this fine-tuning. This requires to sample solutions from the equivalence class of $x_o (I)$ by the equivalence relation $R_2$ for any instance $I$.\nThis procedure is expensive in terms of computations due to the local minima that can be generated when naively inverting the 2-change several times. To circumvent this problem while keeping the computational time low, we use only 2 applications of 2-change. This creates a set of diverse members of the equivalence class which cardinality is several orders of magnitude above the sampling steps needed for the later stages of the curriculum where we use it. while creating O(N-1) local minimal which is at least one order of magnitude lower than the number of epoches for TSP instance > 500 as considered here."}, {"title": "3.4 IDEQ", "content": "Building on these two ingredients, let us specify the training and the inference phases of IDEQ, sketched in Algorithm 1.\n\u2022 Training phase:\n\nwe train an IDEQ TSP-500 checkpoint, by initializing the network with DIFUSCO original TSP-100 checkpoint, and using their TSP-500 training set. The training objective is modified as follows: instead"}, {"title": "4 Experimental study", "content": "In computational combinatorial optimization, experimental results are key. Henceforth, in this section, we present our experimental results. The most important result is that IDEQ reaches SOTA performance on the TSPlib benchmark, achieving significantly better results than the previous SOTA DIFUSCO and T2TCO, and getting close to those of LKH3, even on TSP instances with several thousands of cities. We also show that IDEQ performance does not degrade very much with N. Overall, these results set unprecedented performance for a neural network approach on the TSP."}, {"title": "4.1 Experimental setup", "content": "We used the same hyperparameters as in T2TCO. For model retraining we used a batch-size of 8, using the published DIFUSCO checkpoint. Running times"}, {"title": "4.2 Experimental methodology", "content": "First, we compare IDEQ to other approaches on 2D Euclidean instances made of N cities drawn uniformly at random, provided by the authors of DIFUSCO. This gives a rough first insight into the performance of IDEQ versus the others. However, real TSP instances are not random in this way; instances are structured because they correspond to real-world problems. It is well-known in combinatorial optimization that the performance on uniformly random instances does not say much about the performance on structured instances. With this in mind, we run IDEQ and other approaches on the TSPlib, a highly renown benchmark in the TSP community. On the TSPlib instances, we compare the optimality gap of the solutions found by the different approaches. We also compare the variance of the optimality gap obtained when repeatedly solving a given instance and we consider how the optimality gap varies with the size of the instances.\nFinally, to get a better understanding on how IDEQ works, we perform an ablation study.\nResults are reported in the next 2 sections."}, {"title": "4.3 Experimental results", "content": "Table 1 reports on the first experiments in which we compare the performance of the different approaches on random instances. IDEQ clearly demonstrates smaller optimality gaps as well as a better scaling behavior when going from 500 cities instances to 1000 cities instances.\nOn the TSPlib, we used the TSP-1000 checkpoint on all instances with size ranging from 100 to 104 cities. Table 2 shows both the consistency of IDEQ performance and its ability to generalize beyond the training distribution. Instances up to 1,000 cities have been solved by Concorde, and instances larger than 1000 have been solved by LKH3 (default settings). In 2 cases (instances"}, {"title": "4.4 Ablation studies", "content": "We conducted ablation studies on the two components of IDEQ: the re-training of the later stages of DIFUSCO curriculum learning and the updated estimator of $x_o (x_t, t | I)$. The ablation of both brings back to T2TCO. Removal of the late stage re-training was explored by using the original DIFUSCO checkpoints and keeping the Hamiltonian tour reconstruction operator and the 2-opt at inference time. The effect of the late stage re-training alone was explored by using the IDEQ checkpoints in DIFUSCO and T2TCO.\nTable 4 shows the results of these ablation studies. These results are consistent with the two effects adding up independently as we could anticipate based on the methodology.\nAs a side note, let us mention that only iterating 2-opt on a random Hamiltonian tour produces a tour which optimality gap is at least a few percents: hence, the diffusion model is really useful to obtain such small optimality gaps."}, {"title": "5 Conclusion and future work", "content": "Building on DIFUSCO and T2TCO, we have introduced IDEQ which leads to a significant improvement of the state-of-the-art neural diffusion-based solver for the Traveling Salesman Problem. The optimality gap is significantly reduced"}]}