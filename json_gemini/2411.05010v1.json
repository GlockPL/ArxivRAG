{"title": "SCATTERED FOREST SEARCH: SMARTER CODE SPACE EXPLORATION WITH LLMS", "authors": ["Jonathan Light", "Yue Wu", "Yiyou Sun", "Wenchao Yu", "Yanchi liu", "Xujiang Zhao", "Ziniu Hu", "Haifeng Chen", "Wei Cheng"], "abstract": "We propose a novel approach to scaling LLM inference for code generation. We frame code generation as a black box optimization problem within the code space, and employ optimization-inspired techniques to enhance exploration. Specifically, we introduce SCATTERED FOREST SEARCH to enhance solution diversity while searching for solutions. Our theoretical analysis illustrates how these methods avoid local optima during optimization. Extensive experiments on HumanEval, MBPP, APPS, CodeContests, and Leetcode reveal significant performance improvements. For instance, our method achieves a pass@1 rate of 67.1% on HumanEval+ and 87.2% on HumanEval with GPT-3.5, marking improvements of 8.6% and 4.3% over the state-of-the-art, while also halving the iterations needed to find the correct solution. Furthermore, our method scales more efficiently than existing search techniques, including tree search, line search, and repeated sampling.", "sections": [{"title": "1 INTRODUCTION", "content": "Recent work highlights the effectiveness of scaling infer-ence compute over training compute (Snell et al., 2024;Brown et al., 2024; Gandhi et al., 2024). The most com-mon approach by far is to repeatedly sample from the LLMwith the same prompt and filter out the best response usinga verifier, also known as best-of-N sampling (Cobbe et al.,2021; Lightman et al., 2023). Methods that leverage feed-back from the verifier to revise previous solutions in a lineor tree-like fashion have also been explored (Feng et al.,2023; Chen et al., 2024a). Code generation is one suchsetting where scaling LLM inference through repeatedsampling has also been effective (Wang et al., 2024; Chenet al., 2022).\nInference scaling is effective because, given enough at-tempts, the LLM is likely to sample the correct solutioneventually (Snell et al., 2024; Brown et al., 2024). There-fore, generating diverse solutions is crucial for effectiveexploration. Our experiments show that existing methodssuch as best-of-N (BoN) and tree search often producesimilar solutions, leading to insufficient exploration of thesolution space (refer to Sec.3.5). Hence, a sampling andtesting approach that balances exploration and exploitation can greatly improve inference scaling.\nTo tackle this issue, we propose framing solution generation as a black-box optimization problem(Golovin et al., 2017) (as illustrated in Figure 1), in which validation tests serve as the black boxand the LLM functions as the optimizer (Yang et al., 2024). Drawing from optimization theory, we develop SCATTERED FOREST SEARCH (SFS) to efficiently search for code solutions that successfullypass the maximum number of validation tests. Our method: 1) enhances exploration by enabling theLLM to propose diverse search directions, 2) improves exploitation by leveraging feedback and priorsearch experiences, and 3) initializes various random seed code solutions to ensure broader searchcoverage."}, {"title": "2 BACKGROUND", "content": ""}, {"title": "2.1 PROBLEM DESCRIPTION", "content": "In the task x = <p, H) of program synthesis, the solver is given a prompt p in natural language, which asks the solver to write code for some object s. The goal is to complete the code implementation of s such that it passes all the hidden tests H. The solver is not allowed to see the hidden tests. Sometimes, the solver is also given validation (visible) tests V that they can test their solution s on before they submit it for evaluation on the hidden tests H. They can also generate their own validation tests V."}, {"title": "2.2 PRIOR METHODS", "content": "A couple of different inference time methods have been tried in prior works to enhance the code generation capabilities of the LLM, which are shown in Figure 3. We elaborate more on the pros and cons of each method under a code space optimization framework below:\nBest of N (BON), or repeated sampling, involves sampling multiple independent solutions $[s]_n, s \\sim LLM(p)$ from a language model using the same prompt p. The best solution $s^*$ is then selected based on a verifier, commonly the number of validation tests passed (Li et al., 2022; Chen et al., 2024a).\nLine search begins by sampling an initial seed code $s_0 \\sim LLM(p)$. It then iteratively refines the previous solution $s_{i-1}$ based on its test feedback $f_{i-1}$ (Shinn et al., 2023; Madaan et al., 2023). This iterative self-refinement leverages test execution feedback to guide the model toward sampling successful solutions, i.e. $s_i \\sim LLM(p|s_{i-1}, f_{i-1})$. However, line search is limited by its rigidity requiring improvements on the most recent solution, even if the latest edits are incorrect. Thus, it struggles to effectively explore the search space and is more likely to get stuck in local optima.\nTree search overcomes the rigidity of line search by generating multiple child solutions for each parent solution, utilizing tree-structured exploration methods such as BFS, DFS, and MCTS (Feng et al., 2023; Chen et al., 2024a; Hao et al., 2023; Yao et al., 2023; Zhou et al., 2024; Tian et al., 2024). Given a parent solution $s_i$ and its feedback $f_i$, the LLM produces k child solutions $s_{i0}, s_{i1}, ..., s_{ik}$. Although higher temperatures can produce diverse solutions, in practice, these solutions often resemble each other because they originate from the same prompt (refer to Sec. 3.5). Consequently, tree search still faces challenges in fully exploring the search space."}, {"title": "3 METHODOLOGY", "content": "Our method incorporates three optimization inspired techniques to enhance both exploration and exploitation of tree search (MCTS) using LLMs."}, {"title": "3.1 TREE BRANCH SCATTERING", "content": "In tree search, children solutions of the same parent solution tend to be highly similar to one another since the LLM is given the same prompt to generate the children. We encourage more exploration when generating children solutions by querying the LLM to generate possible improvement directions $[d]_n$ first. The LLM is then instructed to implement a specific direction $d_j$ for each child $s_{ij}$ that it"}, {"title": "3.2 FOREST SEARCH AND FOREST SCATTERING", "content": "Iterative refinement faces the challenge that a very faulty initial seed solution may be difficult to correct effectively during the search process. An intuitive approach to address this issue is to"}, {"title": "3.3 BRANCH SCOUTING", "content": "Inspired by traditional optimization techniques like Ant Colony Optimization and Particle Swarm optimization, we utilize insights from other branches-specifically, which improvement directions are effective to enhance the current solution. Specifically, after generating a new solution $d_{i-1}$ by applying improvement $d_{i-2}$ to solution $d_{i-3}$, we provide feedback on the new solution $f_{i-1}$ to the LLM, inquiring whether the improvement was effective and what general insights it can derive from this. The insights will then be store in global memory, and in future iterations when the LLM is prompted to generate improvement directions, the global insights will be included in the prompt. This approach enables knowledge about effective and ineffective improvement directions to be shared across branches, facilitating more efficient exploitation of the search feedback and thereby enhancing our SCATTERING technique."}, {"title": "3.4 A THEORETICAL PERSPECTIVE", "content": "The proposed techniques-SCATTERING and FORESTING \u2014can be analyzed via the Markov chain theory, particularly focusing on the concepts of diverse transition kernels, conductance, and mixing times (Levin & Peres, 2020). We can define the search strategy as a Markov transition kernel P(s, s') which denotes the probability of generating a new solution s' given the current solution s. A chain of self-refined solutions $s_0, s_1, s_2,...$ are generated following the transition kernel P.\nIn previous methods including line search and tree search, the transition is realized by an LLM $\\pi$ that is conditioned on the previous solution s and the feedback f = F(s), denoted by $\\pi(s'|s, f)$. The transition kernel is\n$P_{previous} (s, s') = \\pi_c(s'|s, F(s)),$ (3)\nwhere we use $\\pi_c$ to emphasize that the LLM $\\pi$ is prompted to output code. We know $\\pi(c)$ can be extremely concentrated and outputs highly similar solutions.\nWith SCATTERING, we first sample an improvement direction d generated by the LLM with prompt $\\pi(\\cdot|s, F(s))$. And then prompt LLM $\\pi$ to generate the next solution s' given the current solution s,"}, {"title": "3.5 EMPIRICAL VALIDATION", "content": "We varied the types of seed instructions usedto generate seed code during BoN sampling tovalidate the effects of increasing solution diver-sity with SCATTERING. In the Jabberwocky setting, the model was prompted with differ-ent lines from the humorous nonsense poem\"Jabberwocky\" before generating seed code. Inthe Style setting the model was prompted withdifferent coding style instructions such as writ-ing code in a 'highly modular way' or 'fo-cus on brevity and clarity'. In the Role setting, the model was prompted with differentsoftware engineer personalities such as \u2018Youare an innovator.\u2019 or 'You are a perfection-ist'. All input prompts were LLM generated bygpt-3.5-turbo around a common theme."}, {"title": "4 EXPERIMENTS", "content": "We demonstrate that our search method outperforms prior methods by showing that it 1) achieves higher accuracy, 2) finds correct solutions faster and scales better, and 3) explores more diverse solutions without sacrificing exploitation of good ones."}, {"title": "4.1 EVALUATION BENCHMARKS", "content": "We evaluate our method on several popular code generation benchmarks. HumanEval consists of 164 human-generated Python questions (Chen et al., 2021), and MBPP includes 399 problems (Austin et al., 2021). The original sets included only 3 to 8 hidden tests H, which researchers found inadequate for thoroughly evaluating correctness in edge cases. Additional hidden tests were added, resulting in the HumanEval+ and MBPP+ sets (Liu et al., 2024a).\nBoth APPS (Hendrycks et al., 2021) and CodeContests (Li et al., 2022) feature challenging code competition problems. From the 10,000 problems in APPS, we randomly sample 200 for evaluation due to budget constraints. We adapt the competition format of both datasets to resemble the HumanEval format for Python evaluation. Leetcode (Guo et al., 2024) includes recent problems scraped from the website, ensuring that LLMs released before July 2023 have not been trained on these data."}, {"title": "4.2 ACCURACY", "content": "We conduct experiments on a variety of code generation benchmarks as shown in Table 2, where we see that our method achieves a higher pass@1 rate than other search methods and the base accuracy (i.e., evaluating the first solution that the LLM model generates). Methods were given the same search budget (10 solutions), they used 6 self-generated validation tests."}, {"title": "4.3 SCALABILITY", "content": "We report the average number of iterations (solutions generated) it takes before the search algorithm discovers the correct solution in Table 6. Iters. (incl) is the average number of iterations it takes including problems where the algorithm succeeds on the first try. Iters. (excl) is the average number of iterations it takes excluding first try successes, where the search algorithm is actually used to find the correct solution. On both metrics, our method demonstrates the ability to discover the correct solution much more quickly than the other methods. Moreover, we see in Figure 2 and 12 that our method also scales better than the other methods on all datasets."}, {"title": "4.4 SOLUTION DIVERSITY", "content": "We see in Table 6 that our proposed search method is able to propose more diverse candidate solutions with a lower semantic similarity score, while maintaining high quality search with by generating solutions with high validation scores. This shows that our methods help both exploration and exploitation without sacrificing too much of one for the other. Detailed stats shown in App. F."}, {"title": "4.5 ABLATION ON TECHNIQUES", "content": "We performed an ablation study on the three introduced techniques as shown in Table 7 (and App. G), all of which enhanced performance and efficiency, with SCATTERING yielding the highest gains."}, {"title": "4.6 VERIFIER (VALIDATION TEST) ACCURACY", "content": "Previous work emphasized the importance of a reliable verifier (Liu et al., 2024a; Chen et al., 2022; Zhang et al., 2023a). In our case, we use self-generated validation tests as noisy as a black-box verifer."}, {"title": "4.7 ABLATION ON MODEL", "content": "As shown in Figure 14, weaker models scale bet-ter with our method. This supports the trade-offbetween training and inference compute: bettertrained models scale worse with inference com-pute, and vice versa. Detailed stats in App. E."}, {"title": "5 ADDITIONAL RELATED WORK", "content": "Code generation with large language mod-els. Some works focus on either training their own model (Guo et al., 2024) or fine tuning existing models to adapt them towards code re-lated tasks (Roziere et al., 2023; Jain et al., 2023; Roziere et al., 2023). Recent literature has shown a flora of methods to improve LLM code generation performance during inference time, including agentic approaches (Qian et al., 2023; Liu et al., 2024b), multi-agent approaches (Tao et al., 2024; Hong et al., 2023; Islam et al., 2024), tool usage (Zhang et al., 2024), and self-revision (Le et al., 2023). Our work compliments these works by showing that increasing solution diversity and exploration can have a large impact on inference scaling.\nSolution validation and feedback. Prior work has demonstrated that effective and accurate validation methods significantly boost performance in code generation (Chen et al., 2022; 2024b) and related tasks like math theorem proving (Cobbe et al., 2021; Uesato et al., 2022). The importance of a reliable evaluation metric is critical (Liu et al., 2024a), and incorporating natural language feedback and reflection on execution results further enhances performance (Zhang et al., 2023c; Bai et al., 2022). Our work complements this by introducing new search methods that more effectively discover solutions meeting these validation and evaluation criteria. Combining a strong search method with a robust validation approach leads to improved solution generation performance.\nBlack box optimization. While many of these methods are domain specific, we adapt many of the insights behind these methods into using LLMs to search over language and code space. Our textual optimization steps can be thought of as 'textual gradients', though we do not use them to conduct backpropogation (Yuksekgonul et al., 2024). There have been some recent works exploring the usage of LLMs as optimizers for different problems (Zhang et al., 2023b; Liu et al., 2024c), including using evolutionary optimization algorithms (Lange et al., 2024; Liu et al., 2024b).\nTree search. Tree search has proven effective in decision-making domains. Previous works have applied tree search to multi-step tasks, such as determining the next reasoning step (Silver et al., 2017; Zhou et al., 2024; Yao et al., 2023; Besta et al., 2024) or generating the next code token (Zhang et al., 2023c). While prior work primarily uses tree search for planning (Jiang et al., 2023; Feng et al., 2023; Bairi et al., 2024), we show that tree search can also be used for optimization, functioning as a black-box method for exploring a region rather than a line."}, {"title": "6 CONCLUSION", "content": "We have shown that framing code generation as an optimization task over the code space and applying SCATTERED FOREST SEARCH is highly effective. The simple yet powerful SCATTERING technique, which encourages the LLM to produce more diverse outputs, underscores the importance of exploration in optimization and search processes. This framework and these techniques can offer valuable insights for other code or language generation tasks.\nThe integration of search-based methods could significantly reduce computational costs while main-taining or enhancing performance, making them attractive for large-scale deployments, especially in real-time applications or those requiring resource efficiency. This framework also lays the ground-work for future research into optimization strategies for language models, potentially leading to more advanced search algorithms, hybrid models, and novel techniques that push the limits of generative models."}, {"title": "APPENDIX: SMARTER CODE SPACE EXPLORATION WITH LLMS", "content": ""}, {"title": "A ETHICS STATEMENT", "content": "All contributing authors of this paper confirm that they have read and pledged to uphold the ICLR Code of Ethics. Our proposed method is specifically designed for code generation using LLMs. We acknowledge the potential for LLMs to generate code that may inadvertently introduce vulnerabilities or ethical concerns. Our research prioritizes the development of methodologies that emphasize responsible usage, ensuring that generated code adheres to best practices in security and ethics. We recognize that LLMs can perpetuate and amplify biases present in training data. We aim to contribute positively to the field of code generation while addressing the potential challenges and responsibilities that arise from the use of advanced AI technologies."}, {"title": "B CODING PROBLEM EXAMPLE", "content": "Example code generation prompt, solution, and tests\nPrompt: Write a function greatest_common_divisor(a,b) that returns the GCD of two integers a and b\nValidation tests:\nassert (greatest_common_divisor(3,5) == 1)\nassert (greatest_common_divisor(25,15) == 5)\nassert (greatest_common_divisor(0,3) == 3)\nProposed solution 1:\ndef greatest_common_divisor(a, b):\n for i in range(min(a, b), 0, -1):\n if a % i == 0 and b % i == 0:\n return i\nTest feedback:\nassert (greatest_common_divisor(3,5) == 1) #output 1 is correct\nassert (greatest_common_divisor(25,15) == 5) #output 5 is correct\nassert (greatest_common_divisor(0,3) == 3) #output None is incorrect"}, {"title": "C SCALING", "content": "Our method scales well with increased iterations. We show scaling curves for each dataset as shown in Figures 15, 16, 17."}, {"title": "D PRIOR WORKS BENCHMARK", "content": "In the LATS experimental setup, in each iteration after a solution is generated, the algorithm is allowed to check if the new solution is correct on the ground truth tests before proceeding (Zhou et al., 2024). We show the performance of our method in the same setup here, with the same solution budget. We see that given the same setup, our method still achieves higher performance."}, {"title": "E ABLATION ON MODELS", "content": "In this section, we provide a detailed ablation study on the performance of different base language models, focusing on metrics relevant to the HumanEval benchmark."}, {"title": "F PERFORMANCE METRICS FOR DIFFERENT DATASETS", "content": "We display detailed performance metrics for MBPP (Table 13), HumanEval (Table 12), CodeContests (Table 16), Leetcode (Table 14), and APPS (Table 15).\nThe performance metrics across various datasets, including MBPP, HumanEval, CodeContests, Leetcode, and APPS, offer a comprehensive comparison of different search methods used to evaluate large language model (LLM) performance. Each table highlights the results of different strategies, such as Line, Tree-based search (MCTS), Best of N, and our proposed method. Key metrics, such as Pass @1, Pass@Any, validation score, and various similarity metrics (e.g., BERT, TF-IDF, and Levenshtein), illustrate the effectiveness of each search method in terms of accuracy and relevance.\nAdditionally, false positive and false negative rates provide insight into the errors made by each approach, while true positive and negative rates reflect the precision and recall of each method. These metrics give a holistic view of model performance, especially in scenarios involving iterative search, with the number of iterations (both inclusive and exclusive) further contextualizing the computational complexity of each method."}, {"title": "G TECHNIQUE ABLATION", "content": "In this section, we present the results of an ablation study to assess the impact of different com-ponents of our method on performance, as shown in Table 17. We evaluate four variations: the full method with all components enabled (\u201cEverything\"), and three ablations where we remove key techniques-SCATTERING, FORESTING, and SCOUTING -one at a time.\nThe ablation results highlight how critical each technique is for achieving high performance. Re-moving SCATTERING leads to a noticeable drop in Pass@Any, decreasing from 89.0% to 78.1%, while removing FORESTING has a milder effect, with Pass@Any only falling to 86.3%. Notably, FORESTING removal significantly affects similarity scores, with a drop in TF-IDF similarity from 0.743 to 0.419. Similarly, removing SCOUTING results in a slight reduction in performance metrics, but Pass@1 remains comparable to the full method, indicating its robustness.\""}, {"title": "H VERIFIER ACCURACY AND GROUND-TRUTH VALIDATION TESTS", "content": "In this section, we assess the impact of incorporating ground-truth validation tests on verifier accuracy, as shown in Table 18. We compare three configurations: no ground-truth tests (\u201cNone\"), using 3 ground-truth tests, and utilizing all available tests. These variations allow us to explore how different amounts of external validation influence the performance of our verifier.\nThe results demonstrate a clear improvement in Pass@1 and validation scores when ground-truth tests are introduced. With no external tests, the Pass@1 rate is 82.5%, which increases to 87.2% when 3 tests are used and further to 89.0% with all tests. Similarly, the validation score improves from 0.813 to 0.862 and 0.864, respectively. These enhancements reflect the verifier's increased accuracy when more reliable validation signals are available.\""}, {"title": "I SEED SCATTERING THEME", "content": "We calculate the validation score as shown below:\nMean validation score =$\\frac{1}{|X|}$$\\sum_{(p,H)\\in X}$$\\frac{1}{|S_p|}$$\\sum_{s \\in S_p}$ proportion of validation tests passed(s) (6)\nWe explore four themes: \u201cNone\u201d, \u201cJabberwocky\u201d, \u201cStyle\u201d, and \u201cRole\" to assess their impact on various evaluation metrics, including Pass@1, validation score, and similarity measures (BERT, TF-IDF, Levenshtein, and token sequence). Additionally, we provide false positive and negative rates, as well as true positive and negative rates, to further analyze the effects of the seed themes on performance in Table 19.\"\n    }"}]}