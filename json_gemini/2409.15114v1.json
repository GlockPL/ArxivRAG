{"title": "Evaluating ML Robustness in GNSS Interference Classification, Characterization & Localization", "authors": ["Lucas Heublein", "Tobias Feigl", "Thorsten Nowak", "Alexander R\u00fcgamer", "Christopher Mutschler", "Felix Ott"], "abstract": "Jamming devices present a significant threat by disrupting signals from the global navigation satellite system (GNSS), compromising the robustness of accurate positioning. The detection of anomalies within frequency snapshots is crucial to counteract these interferences effectively. A critical preliminary measure involves the reliable classification of interferences and characterization and localization of jamming devices. This paper introduces an extensive dataset compromising snapshots obtained from a low-frequency antenna, capturing diverse generated interferences within a large-scale environment including controlled multipath effects. Our objective is to assess the resilience of ML models against environmental changes, such as multipath effects, variations in interference attributes, such as the interference class, bandwidth, and signal-to-noise ratio, the accuracy jamming device localization, and the constraints imposed by snapshot input lengths. By analyzing the aleatoric and epistemic uncertainties, we demonstrate the adaptness of our model in generalizing across diverse facets, thus establishing its suitability for real-world applications.", "sections": [{"title": "I. INTRODUCTION", "content": "Anomaly detection involves the identification of deviations within data patterns from the expected standard. Within the domain of GNSS-based applications [1]-[5], the detection of interference assumes a pivotal role. The accuracy of GNSS receivers' localization is significantly compromised by interference signals emanating from jammers [6], [7]. This issue has significantly intensified in recent years (see the latest news-paper [8]) due to the increased prevalence of cost-effective and easily accessible jamming devices [9]. Consequently, the imperative task include the detection, classification, characterization, localization, and mitigation of potential interference signals [10]. Given the unpredictable emergence of novel jammer types, the objective is to develop resilient ML models. The data may exhibit substantial variance in jammer devices, interference characteristics, antenna changes, and environmental alterations. Therefore, it is paramount to assess the robustness of ML models in terms of their generalization capabilities against these variables. Ensuring a dependable deployment of ML models in real-world scenarios is of utmost importance.\nAssessing the robustness of a model stands as a critical aspect, typically necessitating its application across multiple independent datasets. Given the constraints associated with collecting extensive datasets, attention is often directed towards analyzing the distributions wherein the algorithm exhibits suboptimal performance [11], [12]. Notably, shifts in datasets between training and testing sets commonly lead to a decline in model efficacy, prompting efforts to alleviate such distributional discrepancies [13], [14]. One viable approach involves evaluating either the latent space or the predictive uncertainty [15]. However, model robustness is often assessed on synthetic datasets, leaving uncertainties regarding the model's resilience in the face of distributional shifts observed in authentic data scenarios [16]. Numerous real-world datasets exhibit such distributional shifts, evident in domains like handwriting recognition [17] and EEG signal classification [15], where the origins of data shifts are multi-faceted. The recording of datasets within controlled settings [18] facilitates an exploration of the limitations of ML models. In the context of GNSS, particular emphasis is placed on the detection of non-line-of-sight [6] and multipath [7] signals within specific environments [19]. However, datasets suitable for certain applications are often sparse, synthetic, or not publicly available. Hence, our approach involves the evaluation of our models using data acquired in controlled environments, with and without multipath effects.\nThe primary objective of this work is to assess the robustness of ML models when applied to GNSS data. Figure 1 illustrates the pipeline employed. Our contributions are outlined as follows: (1) We introduce a GNSS dataset collected within a large-scale industrial setting. To emulate multipath effects, we situate a GNSS antenna and a jamming device (i.e., a signal generator) in a controlled environment, incorporating absorber walls between the antenna and the jammer. (2) Various classification and regression tasks are defined to evaluate the efficacy of ML models. These tasks encompass the classification of interference type, the characterization of interference parameters such as bandwidth and signal-to-noise ratio, and the localization of jammer source. (3) We evaluate the robustness of model predictions amidst environmental variations, notably the generalization from minimal absorption to near-complete absorption of jamming signals. (4) The reliability of model predictions is assessed through the computation of both aleatoric and epistemic uncertainty.\nThe remainder of this paper is organized as follows. Section II provides an overview of the existing literature for GNSS interference classification and evaluating ML robustness. In Section III, we introduce our dataset of interference snapshots. Section IV summarizes evaluation results, followed by the concluding remarks in Section V."}, {"title": "II. RELATED WORK", "content": "GNSS Interference Classification. Ott et al. [3] proposed an uncertainty-based Quadruplet loss aiming a more continuous representation between positive and negative interference pairs. They utilize a dataset resembling a snapshot-based real-world dataset, featuring similar interference classes, however, with varying sampling rates. Raichur et al. [4] used the same dataset to adapt to novel interference classes through continual learning. Jdidi et al. [2] proposed an unsupervised method of adapting to diverse environment-specific factors, i.e., multipath effects, dynamics, and variations in signal strength. Raichur et al. [1] introduced a crowdsourcing method utilizing smartphone-based features to localize the source of any detected interference. Brieger et al. [10] integrated both the spatial and temporal relationships between samples using a joint loss function and a late fusion technique. Their dataset was acquired in a controlled indoor environment. As ResNet18 [20] proved to be robust for interference classification, we also employ ResNet18 for feature extraction.\nML Model Robustness. Koiloth et al. [19] benchmarked 14 ML methods to investigate the analysis of multipath data induced by sea waves, however, solely encompassed the consideration of elevation angle, signal strength, and pseudorange residuals. Yuan et al. [7] focused on alleviating estimated multipath biases. Crespillo et al. [6] proposed a logistic regression approach to mitigate biased estimation, thereby enhancing ML generalization. In assessing model robustness, rather than merely detecting outliers within datasets [12], [14], it is imperative to analyze the distributions among evaluation data [11]. While Taori et al. [16] evaluated the distributional shift from synthetic to real data, our evaluation focuses on assessing model robustness across different scenarios within a controlled environment. Similar to Wagh et al. [15], we analyze the predictive uncertainty between dataset shifts."}, {"title": "III. EXPERIMENTS", "content": "First, we introduce our GNSS-based dataset in Section III-A. Next, we define all experiments in Section III-B and present the evaluated model in Section III-C.\nThe primary aim is to develop ML models characterized by resilience against an array of jammer types, interference profiles, antenna variations, environmental fluctuations, shifts in location, and disparate receiver stations. Consequently, we propose the utilization of a GNSS-based dataset to facilitate the analysis of model robustness, accompanied by detailed experiment definitions. The data recording setup is structured as follows: A spacious indoor hall measuring 1,320 m\u00b2 is designated as the recording environment to enable controlled data collection encompassing multipath effects. A receiver antenna is situated on one end of the hall and an MXG vector-signal generator on the opposite end (refer to Figure 1). The signal generator is designed to produce high-quality radio frequency (RF) signals across a broad spectrum of frequencies, characterized by excellent signal purity, high output power, extensive frequency coverage, and adaptable modulation capabilities. Subsequently, the antenna's signals are recorded as snapshots that include various interferences from the signal generator. A substantial dataset is recorded under diverse setups, encompassing scenarios within an unoccupied environment and configurations featuring absorber walls interposed between the antenna and the generator (refer to Figure 2). This setup facilitates the recording of distinct multipath effects, spanning from minor manifestations (Figure 2a and Figure 2b) to pronounced effects (Figure 2d), and instances of significant absorption (Figure 2g). The antenna captures snapshots at a frequency of 100 MHz with a duration of 10 \u00b5s. Each snapshot comprises 1,024 timesteps and has dimensions of 1,024 \u00d7 Nt, where Nt is the snapshot length that we set to a maximum of 34. Figure 3 illustrates a variety of snapshots, with each image displaying 10 randomly selected samples. Figure 3a depicts snapshots devoid of interference. To introduce interference, six distinct types are generated, namely Chirp, FreqHopper, Modulated, Multitone, Pulsed, and Noise (refer to Figure 3b to Figure 3g). For further information on common interference typologies, consult [10]. The primary goal is to detect and accurately classify these interferences. Additionally, the jammer types necessitate characterization, including the bandwidth (BW) and signal-to-noise (StN) ratio. Thus, we record various BWs, spanning from 0.1 to 60 (observe a wider interference spectrum across multiple channels in Figure 3h to Figure 3j for Chirp), and StN ratios, ranging from -10 to 10 (note heightened intensity from Figure 3k to Figure 3m). Enhanced multipath effects correspond to diminished interference intensity (refer to Figure 30 for scenario 7).\nAn overview of all recorded scenarios, interferences, and the corresponding sample counts is presented in Table II. Scenario 1 is characterized by the absence of absorber walls. Initially, we captured data from 16 distinct positions of the signal generator across the hall, maintaining a StN ratio of 10. Subsequently, the generator was stationed at a fixed position while we recorded data encompassing various StN ratios, either [6, 8, 10] across all interference types or spanning from -10 to 10 with a step increment of 2 for a subset of interferences. Additionally, interferences were recorded at 30 generator positions situated on the gallery of the top of the hall, with a StN ratio of 6. For scenarios 2 to 11, a variable number of absorber walls were introduced as depicted in Figure 2. In total, the dataset comprises 42,592 samples, of which 576 samples are devoid of any interferences.\nIn this section, we articulate the experiments feasible with the proposed datasets, aimed at assessing the model's robustness. These experiments encompass: (1) Classification of seven distinct categories, comprising six types of interference and a single category denoting non-interference. (2) Characterization of interference by categorizing the enery level; the StN ratio with noise. (3) Characterization of interference by categorizing the bandwidth. (4) Evaluation of diverse train-test splits: a dependent split, where both the training and testing sets possess identical interference characteristics (i.e., BW), and an independent split, where such characteristics differ. This facilitates the assessment of model generalizability. (5) Classification of antenna regions to anticipate the angle of interference. (6) Utilization of the recorded dataset for interference localization, entailing prediction of the signal generator's position. Accordingly, the model is trained to predict positions within the open hall (16 positions), on the gallery (30 positions), or a combination of both (46 positions). (7) Cross-validation across 12 distinct training and testing scenarios, enabling analysis of environmental variability and robustness against multipath effects, particularly increased absorption. (8) Investigation of snapshot length, initially set at a maximum of 34, which is systematically reduced to a minimum of 1. This exploration aims to determine the minimal data requirement for achieving high classification accuracies across each task.\nFor the purpose of evaluation, we employ the subsequent pipeline. The dimensions of the model are 1,024 \u00d7 Nt, where Nt represents the snapshot length. Initially, we train with a sample length of N\u2081 = 34, which we subsequently reduce to Nt = 1 to explore the minimum requisite of data information. Each sample comprises three image channels, and we apply min-max normalization with values of -182.77 and -17.12. Considering the notable performance of ResNet18 [20] across interference classification tasks [3], [4], [10], we employ ResNet18 for conducting our experiments. Initially, we pre-train ResNet18 on the ImageNet dataset. We then remove the final fully connected (FC) layer and append, for each task, a distinct FC layer of dimensions 512\u00d7Nc, where Nc denotes the number of classes. Specifically, the interference classification task involves Nc = 7 classes, the antenna area task comprises Nc = 4 classes, and the regression task entails the prediction of single values for the StN ratio, BW, and direction angle. To address both classification and regression objectives, we combine cross-entropy loss for classification and root mean squared error loss for regression. This is achieved by aggregating up to three loss functions, each weighted equally at 1.\nThe primary objective is to enhance model robustness concerning specific environmental factors through the utilization of Bayesian inference. This involves computing the posterior distribution $p(\\theta|D)$, which represents the neural network (NN) weights, given the training dataset D and the model parameters $\\theta$. However, due to the typical intractability of computing the posterior, a (local) approximation is commonly employed [21]. We utilize Deep Ensembles, comprising a committee of M individual NNs initialized with distinct seeds, where the initialization serves as the sole source of stochasticity in the model parameters. The results are derived by aggregating predictions from M = 10 independently trained NNs. Next, we decompose uncertainty into aleatoric (represents stochasticity inherent within the data) and epistemic (can be diminished with an increasing amount of observations) uncertainty by the methodology proposed by Kwon et al. [22] based on the variability of the softmax output [21]."}, {"title": "IV. EVALUATION", "content": "For all experiments, we use Nvidia Tesla V100-SXM2 GPUs with 32 GB VRAM equipped with Core Xeon CPUs and 192 GB RAM. We use the vanilla SGD optimizer with a multi-step learning rate of 0.01, decay of 0.0005, and train the models for 200 epochs. We train each model 10 times and present the mean and standard variance accuracy and weighted F2-score for classification tasks, as well as the mean absolute error (MAE) for regression tasks. Interference Type. The model attains a classification accuracy of 99.88% in distinguishing interferences, with only a solitary misclassification evident (see the confusion matrix depicted in Figure 4a). The aleatoric uncertainty manifests an equitable distribution due to the availability of all necessary information within snapshots of a length of 34. Nonetheless, the model encounters challenges in discerning classes 2, 3, 4, and 6, due to similar snapshots, which results in higher epistemic uncertainty.\nStN Ratio. The model yields an accuracy of 86.42% on the StN ratio classification task, yet it exhibits misclassifications between StN ratio 6 and 8, as well as between 8 and 10 (see Figure 4b). However, detecting no interference remains reliable. The model's capability to accurately distinguish between various StN ratios is hindered by an increase of aleatoric and epistemic uncertainty. An alternative normalization procedure could potentially amplify the distinctions among snapshots.\nThe regression task poses a challenge for the model, resulting in an error of 0.81 dB. Although the classification accuracy marginally reduces to 96.15% in an independent task, the accuracy on the StN ratio drops significantly to 55.96% (refer to Table III), due to the intricate generalization toward unfamiliar StN ratios.\nAntenna Area. Although the model demonstrates near-perfect classification capability in distinguishing antenna areas, achieving 98.26%, notable uncertainty persists, particularly concerning the differentiation between area 1 and 2 (see Figure 4c). This uncertainty primarily stems from the minimal spatial separation of merely 5 cm between the respective areas.\nBandwidth. We conduct regression analysis on the bandwidth, yielding an error of 0.87BW. This error remains low, owing to the large bandwidth range spanning from 0.2 to 60.0 (refer to Table I).\nInterference Localization. The classification of positions within the open area, achieving an accuracy of 86.38%, as well as those on the gallery (91.93%), is notably robust. However, to train a regression task necessitates a substantially larger amount of snapshots from diverse spread positions.\nAnalysis of Snapshot Length. In Figure 5, we conduct an analysis of task accuracy relative to snapshot length. Concerning interference classification, accuracy exhibits only marginal decline at lower lengths, i.e., when N\u2081 = 1 (see Figure 5a). However, for the antenna area task, robust performance is evident only for signal lengths higher than N\u2081 = 5, while falling below 70% for the StN ratio estimation. Regarding BW estimation, a complete length of Nt = 34 is imperative (see Figure 5c), a requirement similarly observed in the StN ratio regression task (see Figure 5d). The model demonstrates robustness across all input lengths for the four localization tasks (see Figure 5f to 5i). Hence, there exists potential to reduce the snapshot length to approximately N\u2081 = 10, while still maintaining high accuracies.\nMultipath. When combining all 11 scenarios, the model achieves a multipath classification accuracy of 82.14%. This outcome can be explained by the comprehensive cross-validation across all scenarios (refer to Figure 6). Notably, a considerable performance decline is observed in scenarios 4, 7, and 8 (falling below 40%, refer to Table IV), attributed to complete signal absorption within these scenarios (see Figures 2c, 2f, and 2g). Successful classification of the StN ratio is feasible solely under conditions of equal train and test scenarios (refer to Figure 6b), owing to the comparable influence of multipath effects and various StN ratios. Confusion arises in the classification of antenna area due to multipath effects, evident across scenarios 1 to 5 and 6 to 11"}, {"title": "V. CONCLUSION", "content": "We recorded a large snapshot-based GNSS dataset in a controlled indoor environment. This dataset serves as the foundation for evaluating the robustness of ML techniques for interference classification, characterization, and localization tasks derived from a signal generator. We captured diverse scenarios for classification of interference type, StN ratio, bandwidth, antenna area, localization, and multipath scenario. Through meticulous analysis involving uncertainty computation and snapshot length, we demonstrated that the ResNet18 model exhibits resilience under challenging setups, even when subjected to brief input lengths. Owing to the significant influence on the performance of ML models, including the diverse array of potential (hardware) jammer types with distinct interference patterns, antenna properties, as well as environmental dynamics, necessitates the exploration of distinct research pathways, such as data augmentation, transfer learning, continual learning, and federated learning."}]}