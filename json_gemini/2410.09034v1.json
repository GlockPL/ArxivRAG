{"title": "PEAR: A Robust and Flexible Automation Framework for Ptychography Enabled by Multiple Large Language Model Agents", "authors": ["Xiangyu Yin", "Chuqiao Shi", "Yimo Han", "Yi Jiang"], "abstract": "Ptychography is an advanced computational imaging technique in X-ray and electron microscopy. It has been widely adopted across scientific research fields, including physics, chemistry, biology, and materials science, as well as in industrial applications such as semiconductor characterization. In practice, obtaining high-quality ptychographic images requires simultaneous optimization of numerous experimental and algorithmic parameters. Traditionally, parameter selection often relies on trial and error, leading to low-throughput workflows and potential human bias. In this work, we develop the \u201cPtychographic Experiment and Analysis Robot\" (PEAR), a framework that leverages large language models (LLMs) to automate data analysis in ptychography. To ensure high robustness and accuracy, PEAR employs multiple LLM agents for tasks including knowledge retrieval, code generation, parameter recommendation, and image reasoning. Our study demonstrates that PEAR's multi-agent design significantly improves the workflow success rate, even with smaller open-weight models such as LLaMA 3.1 8B. PEAR also supports various automation levels and is designed to work with customized local knowledge bases, ensuring flexibility and adaptability across different research environments.", "sections": [{"title": "1 Introduction", "content": "Ptychography [Hoppe, 1969] is a powerful computational imaging technique widely used in optical, X-ray, and electron microscopy. Unlike conventional imaging methods, whose spatial resolution is fundamentally limited by focusing optics, modern ptychography employs optimization-based algorithms to directly reconstruct sample structures from a series of scanning diffraction patterns[Rodenburg and Faulkner, 2004]. This approach overcomes physical limitations imposed by the lenses, enabling much higher resolution under similar conditions. Currently, electron ptychography holds the world record for the highest spatial resolution among all microscopy techniques. To date, ptychography has enabled numerous scientific applications, ranging from in-situ studies of battery particles[Liu et al., 2022] and 3D imaging of integrated circuits[Aidukas et al., 2024] to single oxygen vacancy detection in superconducting materials[Dong et al., 2024].\nDespite its popularity, achieving high-resolution ptychography remains challenging due to various parameters that significantly impact reconstruction quality and require careful adjustment for different"}, {"title": "2 Method", "content": "In this section, we introduce the main design features of PEAR, which are critical for the workflow to consistently produce accurate parameters and high-quality ptychographic reconstructions."}, {"title": "2.1 Custom Knowledge Base", "content": "Effectively utilizing domain knowledge is crucial in applying LLMs for scientific applications to ensure that their outcomes are both scientifically accurate and tailored to specific scientific tasks at hand. In PEAR, we decouple the workflow from the knowledge bases. The workflow itself contains no specific information about ptychography, while the knowledge bases serve as dedicated repositories for problem- and user-specific information, such as experiment settings, example scripts, related"}, {"title": "2.2 Human-in-the-Loop (HITL)", "content": "Despite their impressive capabilities, Large Language Models (LLMs) can sometimes produce errors or inconsistencies, particularly when dealing with complex scientific concepts. Human-in-the-Loop (HITL) serves as a critical quality control mechanism, allowing human experts to intervene and correct subtle errors that might otherwise go unnoticed by LLMs. Scientific research often involves navigating conflicting information, scenarios where standard protocols do not apply, and outcomes that are inherently uncertain. HITL plays a vital role in managing these edge cases and preventing catastrophic failures.\nIn PEAR, the HITL approach is integrated at various stages of the workflow, performing several essential functions:\n\u2022 Providing Contextual Information: Human users can offer context-specific details, such as experimental setups or prior knowledge about the sample that are not captured in the general knowledge base. This input is facilitated through responses to targeted questions generated by LLM agents, ensuring that the workflow remains grounded in realistic experimental conditions.\n\u2022 Validation and Error Correction: Human users can verify LLM-generated values and rec- ommendations, ensuring alignment with scientific principles and experimental constraints. Experienced researchers can identify and correct errors early in the workflow, preventing the propagation of inaccuracies and maintaining the integrity of the scientific analysis.\n\u2022 Assessment and Feedback: Experts can evaluate ptychographic reconstructions, enabling an iterative process where their assessments guide LLM agents in refining the workflow. Feedback from human experts is logged and can be used to enhance the knowledge base over time, contributing to continuous improvement and adaptation of the system."}, {"title": "2.3 Multi-agent Workflow", "content": "To further enhance the reliability and effectiveness of LLM-powered scientific workflows, particularly in complex tasks like ptychography data analysis, PEAR employs multiple LLM agents for each sub-task instead of relying on a single agent. This design choice enables PEAR to achieve nearly 100% accuracy in its outputs. One of the core tasks in PEAR is the HITL code generation task, where experimental information is gathered from users to generate a corresponding reconstruction script. We use this task as an example to compare single-agent and multi-agent approaches, illustrating the benefits of the multi-agent design.\nIn a single-agent system, one LLM agent manages the entire process, including user interaction, parameter collection, and script generation. Although simpler, this approach is more susceptible to errors and inconsistencies, especially when handling complex parameter relationships and domain- specific constraints. In contrast, the multi-agent approach in PEAR distributes these tasks among specialized agents, each responsible for a specific aspect of the workflow."}, {"title": "2.4 Automation Levels", "content": "Inspired by the self-driving car industry, PEAR offers different levels of automation to enhance the framework's versatility and user-friendliness. These levels accommodate users with varying degrees of expertise and familiarity with ptychography and autonomous systems, allowing both novice and experienced users to effectively utilize the platform. Newcomers to ptychography can begin with lower levels of automation and gradually advance to more sophisticated features as they gain confidence and understanding in data analysis. Additionally, as users interact with PEAR at different automation levels, the system automatically tracks and saves valuable data on user behavior, decision-making processes, and problem-solving strategies. This multi-modal data, comprising both text and images, is rare in the scientific community and is crucial for developing improved knowledge bases and more intelligent LLM agents.\nCurrently, PEAR implements three primary levels of automation, as shown in Figure 3, each offering an increasing degree of AI assistance and autonomous operation:\n\u2022 Level 0: Manual Workflow Steering: This level represents the most basic form of automa- tion in PEAR, designed for users who prefer maximum control over the ptychographic reconstruction process or for scenarios requiring careful human oversight.\n\u2022 Level 1: AI-Assisted Recommendations: At this level, PEAR provides AI-generated recom- mendations based on the user's knowledge base while maintaining significant user involve- ment. It is ideal for users who wish to leverage AI insights but still retain decision-making control.\n\u2022 Level 2: Automated Quality Assessment: The highest level currently implemented in PEAR, Level 2 incorporates automated quality assessment of reconstruction results. This level is particularly suited for experienced users or for handling large datasets where manual inspection of each result would be inefficient and time-consuming.\nThe multi-level design of PEAR is flexible and adaptable, allowing the framework to be easily modified for use in other computational imaging techniques and beyond."}, {"title": "3 A Case Study in Electron Ptychography", "content": "To further demonstrate PEAR's workflow, we applied it to an experimental electron ptychography dataset of 2D Van der Waals SnSe, a material with structures that are crucial for understanding the electronic properties of ferroelectrics [Zhang et al., 2023]. Figure 4 shows selected ptychographic reconstructions along with the corresponding evaluations and recommendations recorded by PEAR. The complete log of the parameter tuning process is provided in the appendix, with some sensitive data redacted to protect user privacy.\nAt automation Level 1, PEAR leverages user feedback on the reconstruction quality to suggest adjustments to reconstruction parameters. In a few reconstructions, the reconstructed atomic structures become notably sharper and exhibit fewer noisy artifacts when using parameters recommended by PEAR's knowledge base. These optimized choices closely align with those made by experienced scientists. Without the knowledge about ptychography, conventional BO approaches could require tens of reconstructions to achieve similar quality [Cao et al., 2022]."}, {"title": "4 Conclusions", "content": "In this work, we present PEAR, an automatic parameter-tuning workflow for ptychography powered by Large Language Models. To ensure more robust and accurate results, PEAR incorporates several key strategies, including custom knowledge bases, human-in-the-loop integration, and a multi-agent workflow. These features enable PEAR to achieve high success rates even when using smaller LLM models, such as LLaMA 3.1 8B. Despite the great improvement, we acknowledge that errors and hallucinations can still happen given the nature of current foundation model technologies. The different levels of automation provide flexibility and adaptability, allowing PEAR to cater to a wide range of users and extend automation capabilities to computational imaging techniques beyond ptychography. Looking ahead, the log files generated by PEAR users have the potential to serve as valuable training data for the development of future foundation models."}, {"title": "A Computational Experiment Setup", "content": "In the computational experiment described in Section 2.3, we used an advanced LLM to simulate human responses to the LLM agents' questions, enabling us to efficiently conduct a large number of tests. Specifically, we employed the GPT-4 model via Azure OpenAI Service to simulate human responses. For the LLM agents, we utilized a range of models, including LLaMA 3.1 (8b, 70b, 405b) through Together AI, and ChatGPT models (gpt-40, chatgpt-4o-latest, gpt-40-mini) via OpenAI. The exact prompts used in these experiments are detailed in Figure 5.\nThe hypothetical experiment conditions and computational experiment logs are available in the supplementary materials."}, {"title": "B User Case Study Log", "content": "Initializaing PEAR...\n########## Settings ##########\nAutomation level: 1\nKnowledge base: neurips_demo\nData's base directory: /Modified/to/Hide/User/Info/\nLLM: gpt-40-mini\nScript directory: /Modified/to/Hide/User/Info/ptycho\nUser name: User\nComputer name: lamda\nMatlab directory: /usr/local/bin/matlab\nExternal reconstruction script:\n##############################\nPEAR: A driver file exists in the current working directory", "overwritten\nPEAR": "Driver file created at driver.m\n20240913-00:02:56 PEAR: Hello User. Thank you for letting me assist with your ptychographic\n20240913-00:02:56 Agent: Params Collector\nreconstruction today.\n20240913-00:02:56\nPEAR: First I'd like to ask some questions about your data:\n20240913-00:02:56\nPEAR: What is the scan number?\n20240913-00:02:59 User: 31\n20240913-00:03:00 PEAR: What is the beam energy (in keV)?\n20240913-00:03:03 User: 300\n20240913-00:03:03 PEAR: What is the radius of the bright field disk (in pixels)?\n20240913-00:03:14 User: 23.25\n20240913-00:03:14 PEAR: What is the convergence angle (in mrad)?\n20240913-00:03:17 User: 25\n20240913-00:03:18\n20240913-00:03:19\nPEAR: What is the detector size (in #2 of pixels)?\nUser: 128\n20240913-00:03:20 PEAR: Do you want to load the initial object from an existing reconstruction? If so\nplease provide the path to the reconstruction file.\n20240913-00:03:22 User: no\n20240913-00:03:22 PEAR: Do you want to generate the initial probe based on the ideal model or load it\nfrom an existing reconstruction? If use ideal model", "file.\n20240913-00": 3, "44\n20240913-00": 3}, {"44\n20240913-00": 3, "46\nUser": "load an existing probe from /Modified/to/Hide/User/Info/Niter1000.mat\nPEAR: Is the initial probe accurate (similar size to the real probe)?\nUser: yes\n20240913-00:03:47 PEAR: Do you want to generate scan positions assuming a perfect grid or load them\nfrom an existing reconstruction? If you want to generate scan positions", "file.\n20240913-00": 4, "User": 128, "A\n20240913-00": 4, "06\n20240913-00": 4, "07\nPEAR": "How many mixed-state probe modes do you want to use?\nUser: 3\n20240913-00:04:07 PEAR: Which GPU do you want to use for reconstruction?\n20240913-00:04:09 User: 1\n20240913-00:04:10\nPEAR: How many diffraction patterns does the scan have in total?\n20240913-00:04:14 User: 128 x 128\n20240913-00:04:15 PEAR: Did the sample drift during scan?\n20240913-00:04:17 User: no\n20240913-00:04:17 PEAR: What's the estimated sample thickness (in angstroms)?\n20240913-00:04:20 User: 100\n20240913-00:04:20 PEAR: Thank you for answering my questions.\n20240913-00:04:20\n20240913-00:04:20\n20240913-00:04:20\n20240913-00:04:20\n20240913-00:04:23\nAgent: Params Recommender\nPEAR: Next I will initialize some reconstruction parameters based on your inputs.\nAgent: summarize_conversation\nPEAR: Summarizing previous conversation...\nThe scan number is 31.\nThe beam energy is 300 keV.\nThe radius of the bright field disk is 23.25 pixels.\nThe convergence angle is 25 mrad.\nThe detector size is 128 pixels.\nThe initial object will not be loaded from an existing reconstruction.\nAn existing probe will be loaded from the path provided.\nThe initial probe is accurate and similar in size to the real probe.\nThe scan positions will be generated assuming a perfect grid with a step size of 0.2546 angstrom and\n128 x 128 scan points.\nThree mixed-state probe modes will be used.\nGPU 1 will be used for reconstruction.\nThe total number of diffraction patterns for the scan is 128 x 128.\nThe sample did not drift during the scan.\nThe estimated sample thickness is 100 angstrom.\n20240913-00:04:25 PEAR: Based on the provided information and the recommendations", "parameters": "n1. **Update Batch Size**: Set the update batch size to $\\lfloor \\sqrt{128 \\times 128"}], "Blurring**": "Since the beam energy is 300 keV", "Correction**": "Since the sample did not drift during the scan", "Ptychography**": "Given that the estimated sample thickness is 100 angstrom", "Iterations**": "Since the initial probe is accurate", "process.\n20240913-00": 4, "Agent": "Params Formatter\n20240913-00:04:28 PEAR: Here are the current parameters:\n20240913-00:04:28\n{\n\"data_directory\": \"/Modified/to/Hide/User/Info/\"", "n\"scan_number\"": 31, "n\"beam_energy\"": 300, "n\"radius_bright_field\"": 23.2, "n\"convergence_angle\"": 25, "n\"size_of_diffraction_patterns\"": 128, "n\"use_external_object\"": false, "n\"initial_object_path\"": "\"", "n\"use_external_probe\"": true, "n\"initial_probe_file\"": "/Modified/to/Hide/User/Info/Niter1000.mat\"", "n\"defocus\"": 0, "n\"use_external_positions\"": false, "n\"initial_position_file\"": "n\"\"", "n\"grid_scan_positions\"": true, "n\"scan_step_size_x\"": 0.2546, "n\"scan_step_size_y\"": 0.2546, "n\"number_scan_points_x\"": 128, "n\"number_scan_points_y\"": 128, "n\"number_of_iterations\"": 50, "n\"update_batch_size\"": 128, "n\"number_of_probe_modes\"": 6, "n\"position_correction\"": false, "n\"multislice_ptycho\"": true, "n\"object_thickness\"": 100, "n\"number_of_layers\"": 10, "n\"layer_regularization_coefficient\"": 0, "n\"diff_pattern_blur\"": 1, "n\"gpu_id\"": 1, "n}\n20240913-00": 13, "28\n20240913-00": 4, "No.1": "nAgent: Params Confirmer\n20240913-00:04:28 PEAR: Let me know any changes you would like to make. If it looks good to you", "LGTM\".\n20240913-00": 13, "User": 1, "gtm\n20240913-00": 13, "51\nparameters.\n20240913-00": 4, "51\nPEAR": "Thank you for the feedback. I will create a reconstruction script using these\nAgent: ScriptGenerator\n20240913-00:04:51\nPEAR: Generating a reconstruction script.\n20240913-00:04:57 PEAR: The reconstruction script has been generated at /Modified/to/Hide/User/Info/\nptycho/neurips_demo_gpt4o_mini_11_ptycho_script_1.m\n20240913-00:04:57 Agent: ScriptRunner\n20240913-00:04:57 PEAR: Running ptychographic reconstruction...\n20240913-00:04:57 PEAR: Executing script using /usr/local/bin/matlab on Modified-to-Hide-User-Info...\n20240913-00:04:57 PEAR: The MATLAB command used for reconstruction: /usr/local/bin/matlab -batch \"\ndriver('/Modified/to/Hide/User/Info/ptycho/neurips_demo_gpt4o_mini_11_ptycho_script_1.m')\"\n20240913-00:04:57\nPEAR: Executing command /usr/local/bin/matlab -batch \"driver('/Modified/to/Hide/\nUser/Info/ptycho/neurips_demo_gpt4o_mini_11_ptycho_script_1.m')\"\n20240913-00:12:23 - (init): Preparing paths.\n[Warning: Applying custom scan flip: 111]\n[> In scans.positions.matlab_pos (line 14)\nIn scans.read_positions (line 20)\nIn core.initialize_ptycho (line 107)\nIn core.ptycho_recons/ptycho_call (line 172)\nIn core.ptycho_recons (line 289)\nIn ptycho_recon (line 576)\nIn ptycho_recon_pear (line 114)\nIn neurips_demo_gpt4o_mini_11_ptycho_script_1 (line 44)\nIn run (line 99)\nIn driver (line 11)]\n[init]: Preparing initial guess.\n[init]: Preparing data using matlab APS data preparation.\n[init]: Finished data preparation and initialization.\n[ptycho]: Reconstructing S00031\n[ptycho]: Calling engine GPU_MS\n[GPU/CPU_MS-engine): Intermediate results will be saved in the directory below every 50 iterations.\n[GPU/CPU_MS-engine) : /Modified/to/Hide/User/Info/\n[Warning: Applying custom data flip: 010]\n[ptycho]: Elapsed time for engine GPU_MS: 425.7 s\nElapsed time is 438.322446 seconds.\n20240913-00:12:23\nfeedback.\n20240913-00:12:23\n20240913-00:12:23\nPEAR: Your command execution is successful :) Please take a look and give me some\nAgent: Quality Collector\nPEAR: Please check your reconstructions and answer some questions:\n20240913-00:12:24 PEAR: Did the reconstruction converge?\n20240913-00:12:44 User: yes\n20240913-00:12:44 PEAR: Do you see any grid artifacts in the object?\n20240913-00:12:47 User: no\n20240913-00:12:48 PEAR: Is the initial probe accurate enough?\n20240913-00:12:50 User: yes\n20240913-00:12:50 PEAR: Do you see any structures in the last probe mode?\n20240913-00:12:53 User: yes\n20240913-00:12:53 PEAR: Is there anything else you want to tell me about the results?\n20240913-00:13:01 User: nothing at this moment\n20240913-00:13:01 PEAR: Thank you for your feedback!\n20240913-00:13:01\nAgent: Updates Recommender\n20240913-00:13:01\nPEAR: Next I will suggest some changes to the parameters:\n20240913-00:13:01\nAgent: summarize_conversation\n20240913-00:13:01\nPEAR: Summarizing previous conversation...\n20240913-00:13:02\nThe reconstruction converged successfully.\nThere are no grid artifacts present in the object.\nThe initial probe is accurate enough.\nStructures are visible in the last probe mode.\nThere is nothing else to report about the results at this moment.\n20240913-00:13:03 Based on the CONVERSATION SUMMARY", "follows": "nThe initial probe is accurate enough.\nThe reconstruction has converged.\nThe last probe mode has structures.\n### Recommendation:\n* Increase the number of probe modes by 3.\n20240913-00:13:03\nAgent: Params Updater\n20240913-00:13:07 PEAR: Here are the updated parameters that will be used to create the next\nreconstruction script\n20240913-00:13:07\n{\n\"data_directory\": \"/Modified/to/Hide/User/Info/\"", "PEAR": "Do you want to run another reconstruction? If so", "yes\".\n20240913-00": 13, "18\n20240913-00": 13, "18\nUser": "yes\n########## Reconstruction No.2: ##########\nAgent: Params Confirmer\n20240913-00:13:18 PEAR: Let me know any changes you would like to make. If it looks good to you", "21\nparameters.\n20240913-00": 13, "21\nPEAR": "Thank you for the feedback. I will create a reconstruction script using these\nAgent: ScriptGenerator\n20240913-00:13:21\nPEAR: Generating a reconstruction script.\n20240913-00:13:26 PEAR: The reconstruction script has been generated at /Modified/to/Hide/User/Info/\nptycho/neurips_demo_gpt4o_mini_11_ptycho_script_2.m\n20240913-00:13:26 Agent: ScriptRunner\n20240913-00:13:26 PEAR: Running ptychographic reconstruction...\n20240913-00:13:26 PEAR: Executing script using /usr/local/bin/matlab on Modified-to-Hide-User-Info...\n20240913-00:13:26 PEAR: The MATLAB command used for reconstruction: /usr/local/bin/matlab -batch \"\ndriver('/Modified/to/Hide/User/Info/ptycho/neurips_demo_gpt4o_mini_11_ptycho_script_2.m')\"\n20240913-00:13:26\nPEAR: Executing command /usr/local/bin/matlab -batch \"driver('/Modified/to/Hide/\nUser/Info/ptycho/neurips_demo_gpt4o_mini_11_ptycho_script_2.m')\"\n20240913-00:25:12 [init] Preparing paths.\n[Warning: Applying custom scan flip: 111]\n[> In scans.positions.matlab_pos (line 14)\nIn scans.read_positions (line 20)\nIn core.initialize_ptycho (line 107)\nIn core.ptycho_recons/ptycho_call (line 172)\nIn core.ptycho_recons (line 289)\nIn ptycho_recon (line 576)\nIn ptycho_recon_pear (line 114)\nIn neurips_demo_gpt4o_mini_11_ptycho_script_2 (line 44)\nIn run (line 99)\nIn driver (line 11)]\n[init]: Preparing initial guess.\n[init]: Preparing data using matlab APS data preparation.\n[init]: Finished data preparation and initialization.\n[ptycho]: Reconstructing S00031\n[ptycho]: Calling engine GPU_MS\n[GPU/CPU_MS-engine): Intermediate results will be saved in the directory below every 50 iterations.\n[GPU/CPU_MS-engine) : /Modified/to/Hide/User/Info/\n[Warning: Applying custom data flip: 010]\n[ptycho]: Elapsed time for engine GPU_MS: 684.4 s\nElapsed time is 697.096650 seconds.\n20240913-00:25:12\nfeedback.\n20240913-00:25:12\n20240913-00:25:12\nPEAR: Your command execution is successful :) Please take a look and give me some\nAgent: Quality Collector\nPEAR: Please check your reconstructions and answer some questions:\n20240913-00:25:13 PEAR: Did the reconstruction converge?\n20240913-00:25:27 User: yes\n20240913-00:25:27 PEAR: Do you see any grid artifacts in the object?\n20240913-00:25:30 User: no\n20240913-00:25:30 PEAR: Is the initial probe accurate enough?\n20240913-00:25:34 User: yes\n20240913-00:25:34 PEAR: Do you see any structures in the last probe mode?\n20240913-00:25:42\n20240913-00:25:43\n20240913-00:26:19\nnot real\n20240913-00:26:20\n20240913-00:26:20\n20240913-00:26:20\n20240913-00:26:20\n20240913-00:26:20\n20240913-00:26:21\nUser: not anymore\nPEAR: Is there anything else you want to tell me about the results?\nUser: each layer in the reconstructed object seems to have random features that are\nPEAR: Thank you for your feedback!\nAgent: Updates Recommender\nPEAR: Next I will suggest some changes to the parameters:\nAgent: summarize_conversation\nPEAR: Summarizing previous conversation...\nThe reconstruction converged successfully.\nThere are no grid artifacts present in the object.\nThe initial probe is accurate enough.\nThere are no visible structures in the last probe mode.\nEach layer in the reconstructed object seems to have random features that are not real.\n20240913-00:26:21\n* Increase the layer regularization by 0.3.\nAgent: Params Updater\n20240913-00:26:25 PEAR: Here are the updated parameters that will be used to create the next\nreconstruction script\n20240913-00:26:25\n{\n\"data_directory\": \"/Modified/to/Hide/User/Info/\""}