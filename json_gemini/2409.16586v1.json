{"title": "AutoSTF: Decoupled Neural Architecture Search for Cost-Effective Automated Spatio-Temporal Forecasting", "authors": ["Tengfei Lyu", "Weijia Zhang", "Jinliang Deng", "Hao Liu"], "abstract": "Spatio-temporal forecasting is a critical component of various smart city applications, such as transportation optimization, energy management, and socio-economic analysis. Recently, several automated spatio-temporal forecasting methods have been proposed to automatically search the optimal neural network architecture for capturing complex spatio-temporal dependencies. However, the existing automated approaches suffer from expensive neural architecture search overhead, which hinders their practical use and the further exploration of diverse spatio-temporal operators in a finer granularity. In this paper, we propose AutoSTF, a decoupled automatic neural architecture search framework for cost-effective automated spatio-temporal forecasting. From the efficiency perspective, we first decouple the mixed search space into temporal space and spatial space and respectively devise representation compression and parameter-sharing schemes to mitigate the parameter explosion. The decoupled spatio-temporal search not only expedites the model optimization process but also leaves new room for more effective spatio-temporal dependency modeling. From the effectiveness perspective, we propose a multi-patch transfer module to jointly capture multi-granularity temporal dependencies and extend the spatial search space to enable finer-grained layer-wise spatial dependency search. Extensive experiments on eight datasets demonstrate the superiority of AutoSTF in terms of both accuracy and efficiency. Specifically, our proposed method achieves up to 13.48\u00d7 speed-up compared to state-of-the-art automatic spatio-temporal forecasting methods while maintaining the best forecasting accuracy.", "sections": [{"title": "1 INTRODUCTION", "content": "Spatio-temporal forecasting is the process of predicting future states that depend on both spatial and temporal contexts [12, 16, 30]. For example, in transportation systems, the future traffic flow and speed can be estimated by simultaneously learning the spatio-temporal dependencies of historical traffic conditions generated by geo-distributed roadside sensors [9, 35, 59]. Accurate spatio-temporal forecasting plays a pivotal role in various smart city applications, such as human mobility modeling [3, 14, 27], demand-supply rebalancing [31, 58], and urban anomaly event detection [11, 32, 33, 47].\nIn the past decade, extensive efforts have been made to capture spatio-temporal dependencies by leveraging advanced deep learning techniques [8, 29, 41]. To name a few, D2STGNN [44] incorporates Graph Neural Network (GNN) and Recurrent Neural Network (RNN) to model the diffusion process of traffic dynamics, while STEP [43] devise pre-training to encode temporal patterns into segment-level representations. As another example, METRO [4] is a versatile framework that utilizes a multi-scale temporal graph neural network to model dynamic and cross-scale variable correlations simultaneously. Despite adopting various neural network blocks that have proven effective in preserving spatio-temporal dependencies, it requires substantial domain knowledge and extensive expert efforts to design an optimal model architecture [37, 49].\nAs an emerging trend, recently a few automated spatio-temporal methods have been proposed to determine the optimal neural architecture [37, 49, 50]. In general, such methods automatically search the model architecture by exploiting a pre-defined spatial and temporal operator space in an end-to-end manner. However, the combinatorial nature of diverse spatio-temporal operators leads to a vast number of potential model architectures, making the search process computationally expensive and time-consuming. As depicted in Figure 1, existing automated spatio-temporal forecasting methods take an order of magnitude longer than manually-designed methods while yielding marginal prediction accuracy improvements. The extensive computational overhead of automated approaches not only prevents their practical use in real-world tasks, but also hinders further optimization of the forecasting accuracy. It is imperative to develop an efficient and effective automated spatio-temporal forecasting method. In fact, after analyzing the performance of automated methods on various spatio-temporal forecasting datasets, we identify two aspects that were previously overlooked by existing approaches, which provide great potential for us to improve the efficiency and effectiveness of automated spatio-temporal forecasting. We detail our research insights below.\nMixed spatio-temporal search space. Existing automated models search for the optimal neural architecture within a unified search space, which combines various temporal and spatial operators. From an efficiency perspective, such a mixed space entangles the search process for spatial and temporal correlation modeling blocks, resulting in exponential search complexity. However, current spatio-temporal forecasting models typically capture spatio-temporal correlations separately, e.g., using GNNs to capture spatial dependency and RNNs for temporal dependency [20]. Searching for a forecasting model in a mixed search space may lead to high computational redundancy and potentially suboptimal neural architecture due to insufficient exploration. Thus, we propose a decoupled spatio-temporal search framework wherein the spatial dependency block and temporal dependency block are determined separately. Moreover, we devise a representation compression scheme to distill key temporal knowledge and introduce a parameter-sharing scheme to reduce the optimization overhead of the searched spatial dependency network. By decoupling the mixed search space and minimizing the parameter size, the search process can be significantly accelerated, allowing for more flexible exploration in both the parameter optimization and advanced search space design.\nCoarse-grained spatio-temporal correlation search. Limited by computational inefficiency, current automated forecasting methods typically leverage spatio-temporal dependencies at a coarse granularity. In the temporal domain, previous works have commonly applied the same spatial operator to all previous T time steps, disregarding the possibility that the correlation may vary across different time steps. Furthermore, existing studies have adopted an identical message-passing scheme in different GNN layers, which overlooks distinct spatial dependencies in different multi-hop neighbors. We detail the effectiveness bottleneck with more empirical evidence in Section A.3. In this paper, we propose a multi-patch transfer module that divides temporal representations into different patches so that time-varying pair-wise dependency can be preserved in different patches. Besides, we introduce the spatial adjacency matrix as a new class of spatial operators and search the adjacency for each layer to strengthen the spatial dependency modeling. By incorporating fine-grained temporal and spatial dependencies, the accuracy of spatio-temporal forecasting can be further improved.\nAlong these lines, in this paper, we develop AutoSTF, a cost-effective decoupled Automated Spatio-Temporal Forecasting framework. Our main contributions are summarized as follows. From the efficiency perspective, we propose a decoupled automated spatio-temporal forecasting framework to reduce the neural architecture search overhead. By incorporating representation compression and parameter sharing schemes, AutoSTF not only expedites the model optimization process but also leaves new room for more effective spatio-temporal forecasting. From the effectiveness perspective, we propose a multi-patch transfer module and layer-wise message-passing spatial operators to respectively capture fine-grained temporal and spatial dependencies, thereby enhancing the forecasting accuracy. We conduct extensive experiments on eight datasets from different application domains to demonstrate that our proposed framework outperforms state-of-the-art automated spatio-temporal forecasting models in terms of both efficiency and effectiveness."}, {"title": "2 PRELIMINARIES", "content": "Definition 2.1 (Spatial Graph). We denote the spatial graph as G = (V, &), where |V| = N is the set of nodes (sensors), indicating each node in V corresponds to a time series; N is the number of nodes; and & denotes the set of edges that represent spatial correlations between different nodes. A \u2208 \\mathbb{R}^{N\u00d7N} is the adjacency matrix of spatial graph G.\nIn this work, the adjacency matrix A can be predefined, e.g., based on the node distances, or adaptive by a data-driven approach, e.g., based on time series or node embedding. The time series on the spatial graph can be denoted as graph signal matrix.\nDefinition 2.2 (Graph Signal Matrix). We use X \u2208 \\mathbb{R}^{T\u00d7N\u00d7C} to denote the graph signal matrix, where T denotes the number of time steps, and C denotes the number of features, e.g., traffic speed.\nSpatio-temporal Forecasting. We consider both single-step and multi-step spatio-temporal forecasting. Given G, X, and the historical time steps P, the goal of multi-step forecasting is to predict the value at all Q future time steps:\n(\\widehat{Y}_{t+1},\\widehat{Y}_{t+2},..,\\widehat{Y}_{t+Q}) \u2190 F (H_{t-P+1}, H_{t-P+2}, ... H_t), (1)\nwhere H_t = (G_t, X_t), and \\widehat{Y}_t denotes the predictive value at time step t; F denotes the forecasting model. While single-step forecasting aims to predict the value of Q-th future time step.\nProblem Statement. In this work, we aim to design an efficient and effective automated spatio-temporal forecasting model F. We try to search for an optimal neural architecture M* that contains both architecture parameters \u0398 and model parameters \u03c9. The objective function is as follows:\nM^* = min L(w^*, \u0398, D_{val}),\ns.t. w^* = arg min L(\u03c9, \u0398, D_{train}), (2)\nwhere M* \u2208 M denotes the optimal neural architecture after the search phase, and M denotes the search space of model architecture. L is the loss function. D_{train} and D_{val} are the training dataset and validation dataset, respectively."}, {"title": "3 THE AUTOSTF FRAMEWORK", "content": "In this section, we provide a comprehensive overview of our proposed model. Additionally, we give a detailed analysis in Appendix A to explain why the model is designed in this way."}, {"title": "3.1 Embedding Layers", "content": "Here we introduce the three kinds of embeddings preprocessed in the Embedding Layers, including time series embedding, node embedding, and time embedding.\nThe original time series X \u2208 \\mathbb{R}^{T\u00d7N\u00d7C} is processed through a linear layer to obtain an initial latent representation: Z^{(0)} = XW_t + b_t, where Z^{(0)} \u2208 \\mathbb{R}^{T\u00d7N\u00d7D} is time series embedding, and W_t denotes the learnable matrix and D is the hidden dimension. Node embedding aims to identify and encode the spatial locations of different sensors and can be expressed as E_N \u2208 \\mathbb{R}^{N\u00d7D}. Time embedding is designed to map the inherent time feature that can be extracted from raw time series. E_{ToD} \u2208 \\mathbb{R}^{Na\u00d7D} and E_{DoW} \u2208 \\mathbb{R}^{Nw\u00d7D} denote the embedding of day-of-week and time-of-day, respectively. N_a denotes the time slots in a day, and N_w denotes the day-of-week.\nWe concatenate these three embeddings and feed it into the fully connected layers, as shown E_{emb} = FC(concat [E_{ToD}, E_{DoW}, E_N]), where FC denotes the fully connected layers and E_{emb} \u2208 \\mathbb{R}^{N\u00d7D} represents the corresponding embedding, which will be fully utilized in subsequent processes."}, {"title": "3.2 Temporal Search Module", "content": "In this section, we first introduce the temporal search space and temporal-DAG, then explain how to address the temporal search.\nTemporal search space. The temporal search operator should prioritize two key factors: the capacity to accurately model both short-term and long-term temporal dependencies and the efficiency of temporal operators [49]. Based on these findings, we select the Gated Dilated Causal Convolution (GDCC) [7, 15] and informer [64] to construct the temporal search space. Furthermore, to enhance the flexibility of temporal search, we also incorporate two commonly used operators, namely Zero and Identity, into our temporal search space, similar to the works in [36, 37, 49]. We define the temporal search space as O_T = {GDCC, Informer, Zero, Identity}.\nTemporal-DAG. In line with previous works [18, 36, 37, 49], we have also employed a directed acyclic graph (DAG) to facilitate the search for various combinations of temporal operators, as shown in Figure 2 (c). The temporal-DAG has N_T nodes, and each node denotes a latent representation. T_0 = Z^{(0)} represents the output from the Embedding Layer and serves as the input for this temporal-DAG. The edge in temporal-DAG denotes the search operation [37] and will search for an optimal temporal operator in the temporal search space. Specifically, for the edge between node T_0 and T_1, we have O_T choice to determine a temporal operator. The latent representation of T_i can only be transmitted to T_j using the selected operator, if i < j. In other words, the latent representation of the current node is enhanced by its previous nodes in the temporal-DAG. For example, in Figure 2 (c), the latent representation of node T_3 is aggregated with the information from nodes T_0, T_1, and T_2.\nParameterizing temporal-DAG. Following DARTS framework [36], we perform the temporal search within a temporal-DAG, as shown in Figure 2(c). Each operator in the temporal search space is capable of transforming a latent representation (e.g., T_0) into a new one (e.g., T_1) in the temporal-DAG. We denote \u03b1 as the architecture parameters of temporal-DAG and introduce the search operation between node T_i and T_j with \u03b1(i\u2192j) \u2208 \\mathbb{R}^{|O_T|}. Specifically, the weight of the operator o \u2208 O_T between node T_i and T_j is formulate as follow:\n\u03b1_o^{(i\u2192j)} = \\frac{exp(\u03b1_o^{(i\u2192j)})}{\\sum_{o'\u2208 O_T} exp(\u03b1_{o'}^{(i\u2192j)})}, (3)\nwhere o represents an operator, e.g., Informer, and \u03b1_o^{(i\u2192j)} \u2208 \\mathbb{R} is a weight parameter of operator o.\nAfter calculating the weight of each operator between node T_i and T_j, we can obtain the latent representation T^{(i\u2192j)} by computing the weighted sum of all operators between node T_i and T_j in the temporal-DAG. The formula is as follows:\nT_j = \\sum_{o \u2208 O_T} \u03b1_o o(T_i), (4)\nwhere o(T_i) denotes the latent representation generated by applying operator o with input T_i.\nFinally, we can obtain the latent representation H_T of the temporal-DAG. The formula is as follows:\nH_T = \\sum_{j=1}^{N_T} \\sum_{i=0}^{i<j} T^{(i\u2192j)}, (5)\nwhere N_T is the number of node in the temporal-DAG, and H_T \u2208 \\mathbb{R}^{N\u00d7P\u00d7D} denotes the outputs embedding of the temporal search. By performing the temporal search, we can automatically select the optimal operator to model temporal dependencies accordingly."}, {"title": "3.3 Multi-patch Transfer Module", "content": "In this module, we segment the output embedding of the temporal search into several patches along the temporal feature axis and compress each patch into a dense semantic representation. Implementing these strategies can explore the finer-grained spatial and temporal dependencies in subsequential spatial search, and decrease redundant computations in the temporal feature dimension.\nSpecifically, after obtaining the temporal search embedding H_T \u2208 \\mathbb{R}^{N\u00d7P\u00d7D} from the temporal search, we divide the temporal feature (the P dimension of H_T) into several patches to explore the finer-grained spatio-temporal dependencies and effective compress the temporal feature for spatial search. As illustrated in Figure 3, we initially divide the temporal embedding H_T into M patches:\nH_T = {h_{p_1}, h_{p_2}, ..., h_{p_M}}, (6)\nwhere h_{p_m} \u2208 \\mathbb{R}^{N\u00d7 \\frac{P}{M} \u00d7 D} denotes embedding of one patch and M is the number of patches. To reduce the redundant temporal information in subsequent spatial search, we compress the temporal feature with a linear layer, as shown in the following:\nh'_{p_m} = h_{p_m} W_1 + b_1, (7)\nwhere W_1 \u2208 \\mathbb{R}^{\\frac{P}{M} \u00d7 1} is the learnable weights, and h'_{p_m} \u2208 \\mathbb{R}^{N\u00d7 1 \u00d7 D} = \\mathbb{R}^{N\u00d7 D} denotes the compressed embedding of one patch.\nTo more precisely capture the finer-grained spatio-temporal dependencies, we concat embedding E_{emb} with h'_{p_m}, where embedding E_{emb} comprises both time embedding and node embedding (refer to Section 3.1): h_{s_m} = Linear(h'_{p_m} E_{emb}), and h_{s_m} \u2208 \\mathbb{R}^{N\u00d7 D} is then used as the input embedding for the spatial search. Finally, the output of multi-patch transfer can be denoted as H_p = {h_{s_1}, h_{s_2}, ..., h_{s_m}}.\nThe multi-patch transfer module serves as the bridge between temporal search and spatial search. It involves segmenting the temporal feature and conducting the spatial search for each patch to investigate fine-grained spatio-temporal dependencies. It converts the temporal search embedding H_T from \\mathbb{R}^{N\u00d7P\u00d7D} to M \u00d7 \\mathbb{R}^{N\u00d7D}, resulting in a significant reduction in computation time (refer to Table 6). In addition, it combines the embedding E_{emb} for the input of each spatial search, which preserves the temporal information and improves the accuracy of modeling spatio-temporal dependencies."}, {"title": "3.4 Spatial Search Module", "content": "To model fine-grained spatio-temporal dependencies for each patch embedding h_{s_m}, we design a new spatial search space to cover a wide range of spatial modeling paradigms and automatically optimize messages-passing across different layers, leading to more accurate forecasting. Figure 4 is the detailed framework of the spatial search module.\nSpatial search space. After analyzing existing literature (refer to Section A.3), we classify the adjacency matrix into three categories: fully fixed, semi-adaptive, and fully adaptive (see table 7). To enhance the flexibility and capacity of exploring spatio-temporal dependencies, we also incorporate Zero and Identity into the spatial search space. We define the spatial search space as O_s = {GNN_{fixed}, GNN_{adap}, GNN_{att}, Zero, Identity}, where GNN_{fixed}, GNN_{adap}, and GNN_{att} denote fully fixed, semi-adaptive, and fully adaptive matrix used in GNN layer, respectively.\nGNN_{fixed}. This operator employs a distance-based matrix for message-passing aggregation and is the predefined adjacency matrix, fixed in both the training and inference phases. The formal formulation is as follows:\nGNN_{fixed} (X) = \\sum_{k=0}^{K} (A_{dis})^k X W_{fixed}, (8)\nwhere A_{dis} is the distance matrix and k is the finite steps. W_{fixed} is the learnable weights and X is the input of GNN_{fixed} operator.\nGNN_{adap}. This operator utilizes an adaptive matrix that is learned from node embedding. We refer to GNN_{adap} as a semi-adaptive matrix because the adjacency matrix in this operator is trainable during the training phase but remains fixed during the inference phase. The adaptive matrix has a strong ability to model spatial dependencies and is commonly used in many spatio-temporal forecasting models [1, 51, 52, 57]. As is common in many models, we randomly generate two sets of node embeddings E_1 \u2208 \\mathbb{R}^{N\u00d7d} and E_2 \u2208 \\mathbb{R}^{N\u00d7d} that are represented by learnable weights. We then compute the adaptive matrix using these two node embeddings: A_{adap} = SoftMax(ReLU(E_1E_2^T)). We use this adaptive matrix to tackle the massage-passing aggregation of the information for their neighborhood. The formal formulation is as follows:\nGNN_{adap} (X) = \\sum_{k=0}^{K} A_{adap}^k X W_{adap}, (9)\nwhere W_{adap} is learnable weights and X is the input of this operator.\nGNN_{att}. Attentions are utilized in many state-of-the-art spatio-temporal forecasting models. This operator utilizes multi-head attention to compute a fully adaptive matrix based on the input time series. Notably, this fully adaptive matrix in operator GNN_{att} is automatically generated during the training and inference phases. We briefly introduce the multi-attention mechanism, which is a concatenation of t self-attention heads. Specifically, given attention head t, the learnable matrices W_Q, W_K, W_V \u2208 \\mathbb{R}^{D\u00d7\\frac{D}{t}}, the attention function can be written as:\nQ_t = XW_Q, K_t = XW_K, V_t = XW_V, (10)\nA_{att} = softmax(\\frac{Q_tK_t^T}{\\sqrt{D/t}}), (11)\nwhere A_{att} represents the fully adaptive matrix. D denotes the number of hidden dimensions. Then, we can compute the message-passing aggregation from neighboring nodes:\nh' = concat({A_{att}\u00b7 V_t}_{t=1}^k). (12)\nAfter this, the embedding h' is fed into linear layers, which outputs the final embedding calculated by this operator. The formal formulation is as follows:\nGNN_{att} (X) = (ReLU(h' \u00b7 W_1 + b_1)) W_2 + b_2. (13)\nDrawing inspiration from [20], we also adopt a grouping strategy in the GNN_{att} operator. The input X of this operator is initially partitioned into several groups, and Equation 12 is subsequently applied to each group, which can enhance computational efficiency.\nSpatial-DAG. To explore the fine-grained temporal and spatial dependencies (refer to Figure 3), we construct M spatial-DAGs for each patch embedding (e.g., h_{s_m}) in the H_p. In each spatial-DAG, spatio-temporal dependencies are explored by automatically selecting the optimal message-passing aggregation in different layers. It is important to note that in order to address the issue of parameter explosion, the network parameters of spatial operators on the same type edge (e.g., the edge between S_0 and S_1) are shared among different spatial-DAGs. However, the architecture parameters \u03b2 on different spatial-DAG are trained separately. In other words, optimal spatial operators can be automatically selected for different spatial-DAGs.\nParameterizing spatial-DAG. To provide a clearer explanation, we consider the parameterizing process of one spatial-DAG for one patch embedding as an example. Similar to the temporal-DAG, we denote \u03b2 as the architecture parameters of the spatial-DAG. \u03b2_o^{(i\u2192j)} is the weight of spatial operator o (e.g., GNN_{adap}) from the node S_i and S_j in the spatial-DAG. For the patch embeddings h_{s_m}, the formulation of parameterizing this spatial-DAG is as follows:\nh'_{s_m} = \\sum_{j=1}^{N_s} \\sum_{i=0}^{i<j} \\sum_{o\u2208 O_s} \\frac{exp(\u03b2_o^{(i\u2192j)})}{\\sum_{o'\u2208 O_s} exp(\u03b2_{o'}^{(i\u2192j)})} o(S_i), (14)\nwhere S_0 = h_{s_m} server as the input of this spatial-DAG. N_s is the number of nodes in this spatial-DAG, and h'_{s_m} denotes the output embedding of this m-th spatial-DAG.\nFinally, using the same method, all the patch embeddings can be calculated to obtain the output of each spatial-DAG, denoted as H_s = {h'_{s_1}, h'_{s_2}, ..., h'_{s_m}}. We sum the outputs of each spatial-DAG to obtain the final output of the spatial search module, the formulation is as follows:\nH_s = \\sum_{m=0}^{M} h'_{s_m}, (15)\nwhere H_s denotes the output of spatial search module."}, {"title": "3.5 Output Layer and Search Strategy", "content": "In the output layer, we concatenate the skip embedding as the final representation: H' = E_{emb} + H_T + H_S, where \u2295 denotes the concatenation operation. Then, the final presentation is fed into the linear layers to make the spatio-temporal forecasting.\nIn our AutoSTF, there are mainly two types of parameters: architecture parameters, such as weights of candidate operators, and network parameters, such as internal parameters of spatial and temporal operators. We denote the architecture parameters and network weight parameters as \u0398 = {\u03b1, \u03b2} and \u03c9, respectively, and all computations are differentiable. Therefore, we can employ a bi-level gradient-based optimization algorithm like DARTS [36], which is a gradient-based neural network architecture search algorithm.:\nmin L_{val} (w^*, \u0398),\ns.t. w^* = arg min L_{train} (\u03c9, \u0398), (16)\nwhere L_{train} and L_{val} denote the loss value on the training dataset and validation dataset, respectively. In other words, we iteratively update weight parameters using the training dataset D_{train} and architecture parameters using the validation dataset D_{val}."}, {"title": "4 EXPERIMENTS", "content": "In this section, we conducted experiments on both multi- and single-step spatio-temporal forecasting to evaluate AutoSTF. We introduce the experimental settings, overall results of AutoSTF, efficiency study, and ablation study. Due to page limitations, we have provided the parameter sensitivity analysis and case study in Appendices B.5 and B.6, respectively. In Appendix B.7, we include a detailed figure to demonstrate the significant improvements of our model compared to other automated models. We analyze the algorithmic complexity of AutoSTF in Appendix B.8. In addition, we conducted a comprehensive analysis and extensive experiments of decoupled the search space in Appendices C, which involved comparing the model's performance and efficiency before and after decoupling, as well as its ability to maintain spatiotemporal correlations."}, {"title": "4.1 Experimental Settings", "content": "Datasets. We performed experiments on eight benchmark datasets to evaluate both multi-step and single-step forecasting. For multi-step forecasting, we utilized traffic speed datasets (METR-LA and PEMS-BAY) provided by Li et al. [26] and traffic flow datasets (PEMS03, PEMS04, PEMS07, and PEMS08) released by Song et al. [45]. As for single-step forecasting, we employed solar-energy and electricity datasets made available by Lai et al. [19]. We provide the detailed statistics of the datasets in Appendix B.1.\nEvaluation Metrics. We followed previous works [37, 49, 50] to evaluate the model's performance in multi- and single-step forecasting. Specifically, Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE) were utilized to assess the accuracy of multi-step forecasting. For single-step forecasting, we utilized Root Relative Squared Error (RRSE) and Empirical Correlation Coefficient (CORR) as evaluation metrics. More details are stated in Appendix B.3.\nBaselines. We compare AutoSTF with 11 manual-designed methods, including DCRNN [26], STGCN [55], Graph WaveNet [52], AGCRN [1], MTGNN [51], STID [42], STHODE [53], DeepSTUQ [40], STJGCN [62], STAEformer [34] and LightCTS [20], and 3 automated models including AutoSTG [37], AutoCTS+ [50] and AutoCTS [49]. We provide the detailed description of baselines in Appendix B.2.\nDetailed information on hyper-parameters and implementation specifics can be found in Appendix B.4."}, {"title": "4.2 Overall Results of AutoSTF", "content": "Firstly, we present the main experiments for both multi-step (refer to Table 1 and 2) and single-step (see Table 3) spatio-temporal forecasting. We adopt the convention of highlighting the best accuracy in bold and underlining the second best accuracy.\nMulti-step forecasting. As demonstrated in Tables 1 and 2, AutoSTF outperforms all baseline models on all multi-step forecasting tasks across all evaluation metrics. In summary, the results demonstrate that AutoSTF can produce highly competitive architectures adept at capturing spatio-temporal dependencies, leading to enhanced forecasting accuracy.\nIn particular, compared with the most advanced manual-designed baseline LightCTS, our model achieved significant improvements on all datasets. For example, our model resulted in a (2.05%, 1.32%, 0.76%) and (4.23%, 3.11%, 2.31%) reduction in MAE for long-term (60 min), medium-term (30 min), and short-term (15 min) forecasting on METR-LA and PEMS-BAY datasets, respectively. Furthermore, our model demonstrated enhanced performance on other traffic flow datasets compared to LightCTS, achieving a reduction in MAE (2.18%), RMSE (0.93%), and MAPE (1.72%) for PEMS04, as well as a decrease in the same metrics for PEMS08, with MAE (3.83%), RMSE (1.36%), and MAPE (3.08%). Two crucial insights can be drawn from our observations. Firstly, the experimental outcomes reveal that AutoSTF is capable of automatically generating highly competitive neural architectures that surpass human-designed models in performance. secondly, no hand-designed model consistently outperforms others across various traffic flow datasets. This implies that different datasets require distinct model architectures. Nonetheless, our AutoSTF can adapt to these requirements by automatically designing optimal neural architectures for different traffic flow datasets, ultimately yielding the most accurate forecasting results.\nMoreover, when compared to the automated models, our proposed AutoSTF demonstrates significant advancements across all datasets in terms of multi-step forecasting performance. Specifically, compared with AutoCTS on long-term forecasting, our AutoSTF results in a (3.46%, 0.70%, 2.34%), (4.23%, 1.65%, 2.98%), (3.92%, 1.91%, 2.40%), and (5.06%, 1.99%, 3.89%) improvement on the METR-LA, PEMS-BAY, PEMS04, and PEMS08 datasets, respectively, under the MAE, RMSE, and MAPE metrics. We can draw two key observations as follows: Firstly, compared to other automated models, our proposed AutoSTF achieves superior performance on both traffic speed and traffic flow datasets, demonstrating the effectiveness of our framework in accurately capturing spatio-temporal dependencies. Secondly, the experimental results also indicate that fine-grained spatial search and adaptive selection of the optimal message-passing aggregation in different layers can significantly improve accuracy.\nSingle-step forecasting. In this experiment, we compared AutoSTF with other automated spatio-temporal forecasting models"}, {"title": "4.3 Efficiency Study", "content": "For efficiency, in this study, we place significant emphasis on optimizing the search efficiency. We selected AutoCTS and AutoSTG, which are among the most advanced automated spatio-temporal forecasting models, as baselines for comparing the search time and memory consumption in the search phase. It is important to note that the experimental setup for AutoCTS+ [50] is significantly different from that of AutoSTF, AutoCTS, and AutoSTG, as it involves training an Architecture-Hyperparameter Comparator using a large volume of samples to predict the final neural architecture. Therefore, to ensure an accurate comparison, we excluded AutoCTS+ from the efficiency evaluation. The efficiency experiments were conducted on a Linux Ubuntu server equipped with 2 V100 GPUs. Figures 5 and 6 present a comparison of the average search time per epoch and the memory consumption across different datasets, respectively. Our AutoSTF consistently demonstrates the best performance in terms of search time across all datasets, highlighting the efficiency of our proposed framework. From the results, we can draw two key insights as follows. Firstly, AutoCTS takes thousands of seconds to complete an epoch search on most datasets, resulting in excessive computational overhead and presenting significant challenges. In contrast, AutoSTF only takes hundreds of seconds to complete the one epoch search, significantly improving computational efficiency. This demonstrates that decoupling the mixed search space, reducing redundant temporal features and parameter-sharing schemes for spatial search can effectively enhance computational efficiency. Secondly, regarding memory computations, AutoSTF exhibits the smallest consumption on most datasets, indicating its superior performance in terms of memory efficiency. In conclusion. the experimental results clearly demonstrate that our model is significantly more efficient than AutoCTS and AutoSTG in terms of search time and memory consumption across all datasets."}, {"title": "4.4 Ablation Study", "content": "To investigate the contribution of each key module to improving the performance and efficiency of the search phase of the proposed AutoSTF model, we performed an ablation study on three variants of AutoSTF. The three variants are described as follows: (1) \"w/o TS\" refers to the model variant that omits the Temporal Search module, instead utilizing a Linear layer as its replacement. (2) \"w/o MPT\" is the model variant that removed the Multi-Patch Transfer module,"}, {"title": "5 RELATED WORK", "content": "This section emphasizes related work in two aspects: manually-designed and automated models in spatio-temporal forecasting.\nThe manually-designed models. Existing manually-designed models often propose complex algorithms to model the spatial-temporal dependencies using domain-specific knowledge [5, 34, 53, 62]. In particular, many works [6, 16, 25, 38, 43, 55] involve Spatial-Temporal Graph Neural Networks (STGNN) to explore the temporal dependencies within time series and spatial correlations across different locations for spatio-temporal forecasting. For temporal modeling, techniques such as Gated Recurrent Units (GRU), Long Short-Term Memory (LSTM) [46], and Temporal Convolutional Networks (TCN) [56] are commonly employed to extract information from time series data. In addition, various Graph Neural Network approaches have been proposed for modeling spatial dependencies using different adjacency matrices, including predefined and adaptive matrices [26, 52]. Graph WaveNet [52], as proposed by Wu et al., utilizes both predefined and adaptive matrices to capture spatiotemporal dependencies. Furthermore, several studies have proposed methods to model dynamic spatial dependencies [13, 44, 54, 60]. These methods primarily focus on learning the hidden relationships between nodes using dynamic node features, which are generally characterized by a combination of real-time traffic attributes. For example, ESG [54] presents a flexible graph neural network that models multi-scale time series interactions to simultaneously capture pairwise correlations and temporal dependencies. However, manually-designed models necessitate substantial domain-specific expertise, as well as extensive parameter adjustments.\nThe automated models. Recently, there has been a growing trend toward developing automated methods for designing efficient model architectures, aiming to enhance the accuracy of forecasting predictions [18, 24, 61]. The existing automated time series forecasting models aim to search the optimal architecture in the mixed search space for modeling the spatio-temporal dependencies. For instance, AutoSTG [37] employs an adaptive matrix learned from node features using meta-learning and explores spatio-temporal dependencies within a mixed search space. AutoCTS [49] employs micro and macro search strategies to identify optimal blocks from a mixed search space and determine the topology among heterogeneous blocks, ultimately constructing a novel architecture. Additionally, a recent study, AutoCTS+ [50], introduces a unified search strategy that incorporates both operators and hyperparameters, making it the first work to include hyperparameters in the search space. However, the current automated approaches face challenges due to the high computational cost of neural architecture search, which limits their practical application and the exploration of a wider range of spatio-temporal operators at in finer granularity."}, {"title": "6 CONCLUSION", "content": "In this paper, we propose AutoSTF, a novel decoupled neural architecture search framework for cost-effective"}]}