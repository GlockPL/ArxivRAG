{"title": "Cyber Physical Games", "authors": ["Warisa Sritriratanarak", "Paulo Garcia"], "abstract": "We describe a formulation of multi-agents operating within a Cyber-Physical System, resulting in collaborative or adversarial games. We show that the non-determinism inherent in the communication medium between agents and the underlying physical environment gives rise to environment evolution that is a probabilistic function of agents' strategies. We name these emergent properties Cyber Physical Games and study its properties. We present an algorithmic model that determines the most likely system evolution, approximating Cyber Physical Games through Probabilistic Finite State Automata, and evaluate it on collaborative and adversarial versions of the Iterated Boolean Game, comparing theoretical results with simulated ones. Results support the validity of the proposed model, and suggest several required research directions to continue evolving our understanding of Cyber Physical System, as well as how to best design agents that must operate within such environments.", "sections": [{"title": "1 Introduction", "content": "Cyber Physical Systems (CPSs) are characterized as the integration of concurrent embedded systems (the \"cyber\" components) each executing a local control loop2, in a shared physical environment. Whilst the Internet of Things (IoT) describes distributed systems that are capable of internet communication, exposing data and control access points, CPSs exist at a higher level of abstraction. A system of systems is meaningfully described as a Cyber Physical System if and only if the collective behavior of its constituent systems exhibits properties of interest4, and each system can thus influence the others (either directly, or indirectly by affecting relevant properties). A CPS may be designed holistically, in a top-down approach; or, incrementally, in a bottom-up approach, depending on the properties of the physical environment dictated by the domain of application. For example, industrial automation environments7 may be designed completely top-down, starting from functional specifications which are iteratively refined into a concurrent system design. Networks of autonomous automobile systems, on the other hand, must necessarily exhibit some degree of bottom-up instantiation, as autonomous vehicles enter and leave the macro system. Cyber-system to cyber-system communication is often prevalent (typically, on top of some IoT architecture), but not strictly necessary.\nBecause the cyber-components of a CPS may have substantial degrees of computational power, significant effect on the underlying shared physical system, and well-specified local goals, it is often desirable to formalize them as agents8. Thus, a natural next step is to formalize the macro behavior of a CPS as a game, either adversarial or collaborative. A significant body or work on distributed games exists: notably, the work of Gutierrez et al10\u201312, which has developed a temporal logic to reason about distributed games strategies.\nBecause CPSs are real instances of distributed systems, and operate on top of communication networks and protocols without strict hard-real time guarantees, the ordering of events obeys Lamport's rules13: they are not necessarily perceived in the same partial order by any frame of reference in the system (i.e., from the underlying physical system's frame of reference, or by the internal frame of reference of each cyber system). Whilst causality can never be broken, a cyber system may, e.g., effect two actions at distinct times that affect the physical system in the opposite order than expected. Thus, the formalization of CPSs as games must account for relative orderings and possible consensus (or lack thereof) within the system.\nThus, this paper explores Cyber Physical Games: scenarios where cyber agents act rationally in pursuit of their own goals, in adversarial and/or collaborative contexts, in the presence (and knowledge of) unpredictable and heterogeneous (across frames of reference) ordering of events. Specifically, this paper offers the following contributions:\n\u2022 We present a formal description of Cyber Physical Games, and how they arise from emergent properties of multi-agent Cyber Physical Systems. We further specify the behavior of collaborative and adversarial Cyber Physical Games using examples from the classical Iterated Boolean Game.\n\u2022 We show that there exist collaborative Cyber Physical Games where collaboration can diminish payoffs for both agents, if the non-deterministic properties of CPSs are not taken into account. Conversely, we show that employing knowledge"}, {"title": "", "content": "of such properties can improve payoffs for both agents.\n\u2022 We show that adversarial strategies can (and should) take into account the non-deterministic properties of CPSs, as these greatly influence the evolution of adversarial games.\n\u2022 We show that multiple agents operating within a Cyber Physical System give rise to behavior that can be modeled as probabilistic finite state automata.\n\u2022 We introduce an algorithm for determining the most likely sequence of events (i.e., agents' payoffs) in a game ruled by a probabilistic finite state automata, and show this algorithm can be used to predict system evolution. We further discuss how this model can be used in the future to guide the design of agents operating in CPSs.\nThis paper is organized as follows: we begin some required background (Section 2), pointing readers to the relevant literature to understand the remainder of the paper. We then present a description of CPSs (Section 3) that underpins our game formalism, which we use to explore the execution of games when agents are in collaborative and adversarial scenarios. We then explore the modeling of game strategies as probabilistic finite state automate (Section 4), describing an algorithm to predict game evolution. We evaluate these strategies through simulation techniques in Section 5, and describe related work in the field in Section 6, with Section 7 offering concluding remarks and highlighting the need for future research directions."}, {"title": "2 Background", "content": "An agent is a goal-oriented system, operating in an environment; i.e., a set of physical and/or digital objects with various properties and relationships between objects, which contains the agent itself. An agent is capable of acting upon the environment, modifying some (or all) of its properties. A specific combination of properties' values (including of the agent itself) is defined as a state s of the environment. The set of all possible states is referred to as the environment's state space. A rational agent will attempt to meet its goal by performing actions that maximize or minimize its utility function14.\nWithin the context of this work, the environment is a Cyber Physical System15: a super-system that \"combines cyber systems (computational systems such as microprocessors and digital communication networks) with other physical systems (electromechanical, chemical, structural, and biological systems)16\". Of particular interest to us is the communication between the cyber systems and the environment; particularly, the lack of determinism in such a distributed system whose emergent properties give rise to Cyber Physical Games.\nAs first formally described by Lamport in his seminal 1978 paper13: \"In a distributed system, it is sometimes impossible to say that one of two events occurred first. The relation \"happened before\" is therefore only a partial ordering of the events in the system.\". This property gives rise to interesting phenomena in Cyber Physical Games, that introduces additional complexity compared to traditional turn-based17 or distributed12 games."}, {"title": "3 Cyber Physical Games", "content": "3.1 Modeling Cyber Physical Systems\nLet a CPS be defined as the tuple {E,C,M}. E denotes the physical shared environment, which is a set of k properties\nPk such that E = {P0, P1,\u2026Pk\u22122,Pk\u22121}. C denotes the set of n cyber agents operating on the environment, such that C =\n{C0, C1,...Cn-2,Cn-1}. The internal behavior of each cyber agent is not relevant for this work; we point interested readers to the\nbody of work on modeling embedded systems18. M denotes the message channels exchanging between the environment E\nand the cyber agents C, such that M = { {mC0i, mC0o}, {mC1i, mC1o}, ... {mCn\u22122i, mCn\u22122o}, {mCn\u22121i, mCn\u22121o}}, where mxi denotes an input\nmessage channel for cyber agent x, i.e., sensing the values of the environment, and mxo denotes an output message channel\nfrom cyber agent x, i.e., acting on the environment. Messages conceptually represent all possible interactions between each\nagent and features of the environment, which we notate using the following notation: mxi \u2190 py denotes sensing by the cyber\nagent of environment property py; several properties may be sensed at once; e.g., mxi \u2190 Py, Pz. Py \u2190 mxo = z denotes updating\nproperty py by agent cx, with a value of z.\nLet Mo denote the set of all output message channels (acting on the environment) and Mi denote the set of all input message\nchannels (sensing the environment), such that Mo \u2282 M,Mi \u2282 M,Mo\u2229Mi = \u2205,Mo\u222aMi = M. To keep notation simpler, instead\nof adding additional message channels for inter cyber agent communication, we consider the communication link to be a hidden\npart of the environment E, and we notate direct messages with content s from cyber agent x to y through mx \u2190 (s) \u2190 mcx.\nWhilst environment evolution obeys continuous laws (typically, differential equations), it is convenient for our purposes to\nmodel it discretely. Let EtE denote the state (i.e., the combination of specific values of all its properties) of the environment at\ntime te, where the subscript denotes that this is time from the frame of reference of the environment. Similarly, inputs to the\nenvironment at time te are denoted by M. Then, the environment is governed by some system function f : (E,Mo) \u2192 (E),"}, {"title": "", "content": "such that \\(E_{t_E} = f(E_{t_E-1},M^o_{t_E-1})\\). Throughout the rest of this paper, unless otherwise stated, time t is assumed to be discrete, regardless of which frame of reference is used.\nA specific message m, either to/from the environment from/to a cyber agent, takes a non-deterministic amount of time to be effected, denoted as transfer latency l. For a given sender cx, a message m to the environment E has \\(l_{c_x}(m) = l_o(m^{c_x}_o) + w\\), \\(w \\sim N(\\mu,\\sigma^2)\\), where \u03bc and \u03c32 are the mean and the variance of the distribution of the random variable w, and latency is subject to \\(l_{c_x}(m) > 0\\). A consequence of this, well known in the distributed systems canon19, is that a sequence of messages m1 emitted at \\(t_{c_{x1}}\\) and m2 emitted at \\(t_{c_{x2}}\\), with \\(t_{c_{x2}} > t_{c_{x1}}\\), may be received by the environment as the sequence m2 received at tE1 and m1 received at tE2, with te2 > te1. This holds for an arbitrary number of messages among an arbitrary number of cyber agents such that, even under the assumption that all frames of reference are synchronized, each cyber agent and the environment may perceive the sequence of visible events thus far as any possible permutation of events that does not violate causality. Of course, if our assumption that w is normally distributed holds, some permutations are more likely than others.\nIt it noteworthy that, in purely digital systems such as in the case of distributed computing, consistency, control, synchronization, and consensus algorithms rely on (a) not immediately committing the implications of a message; and/or (b) potentially rolling back the state of the distributed system to a previous one. In a CPS, the function f : (E,Mo) \u2192 (E) might not allow for such luxuries: i.e., actions upon the environment may be permanent."}, {"title": "3.2 Types of Cyber Physical Games", "content": "The goals of agents in CPSs are more likely to be concerned with the evolution of the state of the environment, rather than with a specific state. For example, in the case of networks of autonomous automobile systems, the goal is the efficient and safe conclusion of vehicles' routes (potentially, until they leave the environment), rather than any specific configuration of vehicles (albeit these may constitute meaningful sub-goals). Thus, iterated, infinite games such as Iterated Boolean Games are reasonable models to reason about the evolution of CPSs. Unlike traditional turn-based runs, agents in a CPS may issue actions at any time. A game is said to be collaborative if agents' goals are not in contradiction (in these cases, cooperation may be beneficial, but this is not a necessary condition). A game is said to be adversarial if agents' goals are in contradiction.\nA (traditional, non-iterative) Boolean game is one where there exists a finite set of propositional variables, typically denoted V = {a,b,c,...}, with Ly denoting the propositional language that is built from V, T (true), \u22a5 (false), and the typical logical operators. Each agent controls a non-intersecting subset of V, and their goal is to satisfy a propositional formula of Ly, typically denoted \u03d5 or \u03c8. In Iterated Boolean Games, agents' goals are instead given by formulae of Linear Temporal Logic (LTL)22. LTL extends propositional language with the temporal operators X (next), F (finally), G (globally), U (until), R (release), W (weak until), and M (strong release). Furthermore, \u2192 denotes a sequence from one temporal state to another, sometime in the future, but not necessarily the next one. An agent's strategy is its decision function, which performs a given available action, based on current and past input, to attempt to satisfy its goal. Notice that, unlike the scenarios explored in20, in Cyber Physical Games an agent's strategy does not induce a unique run, because of the non-deterministic properties of CPSs.\nAdversarial games arise in CPSs when agents' goals are contradictory. This is the case of, e.g., intelligent adverting systems, modifying what is displayed on screens in a commercial area to direct (indirectly, through psychological influence) consumer traffic towards desired commercial venues. Whilst the morality of such scenarios is dubious at best, their study from a theoretical perspective remains quite interesting. As before, Iterated Boolean Games are a reasonable model; the path from an initial state to a terminal state can represent the evolution of the environment in such systems.\nThroughout the remainder of this paper, we will implicitly assume that games are limited to two players. Our contributions can scale trivially to an arbitrary number of agents, but two agents provides the simplest case to most clearly describe the behavior of Cyber Physical Games."}, {"title": "3.2.1 The Collaborative Iterated Boolean Game", "content": "Consider two cyber agents c0 and c1, and an environment E with properties {a,b} \u2208 V, where both agents can observe and affect the entire set of properties. However, only one variable update can occur at any point in time (i.e., agents cannot simultaneously update both variables under their control). This corresponds to environment update function\n\\(E_{t_E} = f(M^o_{t_E-1}) = \\begin{cases}\na_{t_E-1}, & x,a \\leftarrow m_0^{c_0} = x  \\\\\nb_{t_E-1}, & x,b \\leftarrow m_0^{c_0} = x \\\\\na_{t_E-1}, & \\notherwise\\n\\end{cases}\\) \\({\\begin{cases}\nx,b \\leftarrow m_0^{c_0} = x  \\\\\nx,a \\leftarrow m_0^{c_0} = x \\\\\np_{t_E-1}, & otherwise \\\\\n\\end{cases}}\\)_{t_E-1}\nIn this case, the environment update function can be obviously derived by the agents' control capabilities; notice this may not be true in the general case (e.g., when the environment has internal state update rules that are not immediately derivable from its inputs)."}, {"title": "", "content": "Agent c0's goal is to satisfy an LTL formula \u03d5, and agent c1's goal is to satisfy an LTL formula \u03c8. Informally, satisfying \u03d5 and \u03c8 throughout system execution corresponds to positive evolution of the system: e.g., successful movement of autonomous vehicles along the desired paths. System execution traces that do not satisfy either formulae correspond to system execution that does not positively evolve the system. Agents' strategies are to maximize the satisfaction of \u03d5 and \u03c8 over time.\nLet the evolution of the environment (a run) be denoted using angled brackets: \u27e8EtE=0, EtE=1,..., EtE=k\u22121, EtE=k\u27e9. Being able to write an evolution that satisfies both \u03d5 and \u03c8 fairly suffices to show the game is collaborative. Two different agent modes affect how the game plays out. An agent is deemed social if it is aware of the other agent in the environment and is willing to cooperate with it towards the best mutual payoff, and unsocial otherwise. An agent is deemed optimistic if it assumes its messages are perceived by the environment in the same order as the agent issues them, and that all frames of reference are synchronized, and realistic otherwise. Recall that if agent c0 issues the message sequence \u27e8{a \u2190 mc0 = x0}tc0=0, {b \u2190 mc0 = x1}tc0=1\u27e9 and agent c1 issues the message sequence \u27e8{a \u2190 mc1 = x2}tc1=0, {b \u2190 mc1 = x3}tc2=1\u27e9, where tc0 and tc1 are in different frames of reference, the environment may perceive the sequences \u27e8{a \u2190 mc0 = x0}tE=0, {b \u2190 mc0 = x1}tE=1, {a \u2190 mc1 = x2}tE=2, {b \u2190 mc1 = x3}tE=3\u27e9, \u27e8{a \u2190 mc1 = x2}tE=2, {b \u2190 mc1 = x3}tE=3,a \u2190 mc0 = x0}tE=0, {b \u2190 mc0 = x1}tE=1\u27e9, or any of the 24 permutations of the 4 individual messages, assuming all messages arrive sequentially in time. The environment may additionally perceive an arbitrarily large number of sequences, corresponding to messages arriving non-sequentially, with arbitrary delays between messages, as given by \\(l_{c_x}(m) = l_o(m^{c_x}_o) + w\\), \\(w \\sim N(\\mu, \\sigma^2)\\). Throughout the rest of this paper, we assume all messages arrive sequentially without any delays: i.e., assuming a model where \\(l_{c_x}(m) \\leq 1, \\forall m \\in M\\), and messages are queued. Exploring the impact of message delays > 1 is left for future work. For a specific set of n messages mn = {m0,m1,...,mn\u22121}, we denote its possible no-delay permutations as P(mn), where ||P(mn)|| = n!. We assume social agents have negotiated the common strategy at the beginning of the game, through inter-agent message passing.\nUnsocial, optimistic agents care not for collaboration, and assume their actions are immediately, and in the same order, effected on the environment. Thus, agents c0 and c1 issue only the messages that would evolve the environment according to \u03d5 and \u03c8, respectively. Unsocial but realistic agents can observe the state of the environment to ensure the outcome of their actions successfully occurred. In this case, they can ensure that their first state transition successfully occurred, before issuing the second message. Social but optimistic agents collaborate to satisfy the compound state transition sequences that satisfies both \u03d5, fairly, distributing the work among themselves. Social and realistic agents collaborate, timing their actions to ensure mutual benefit, with agents monitoring the environment to preemptively abort failed strategies, if any."}, {"title": "3.2.2 The Adversarial Iterated Boolean Game", "content": "Consider two cyber agents c0 and c1, and an environment E with properties {a,b,c} \u2208 V, where both agents can observe all variables, but affect non-intersecting subsets of properties. Agent c0 has control over variables a and c, and agent c1 has control over variable b. As in the collaborative case, only one variable update can occur at any point in time (i.e., agents cannot simultaneously update both variables under their control). This corresponds to environment update function\n\\(E_{t_E} = f(M^o_{t_E-1}) = \\begin{cases}\n{{\\begin{cases}\nx,a \\leftarrow m_0^{c_0} = x  \\\\\na_{t_E-1}, & otherwise\\\\\n\\end{cases}}\n{{\\begin{cases}\nx,b \\leftarrow m_1^{c_1} = x  \\\\\nb_{t_E-1}, & otherwise\\\\\n\\end{cases}}\n{{\\begin{cases}\nx,c \\leftarrow m_0^{c_0} = x  \\\\\nc_{t_E-1}, & otherwise\\\\\n\\end{cases}}\n\n\\end{cases}\\)_{t_E-1}\n\n\n\\)\n\\)\n\n\\)\nAs before, agent c0's goal is to satisfy an LTL formula \u03d5, and agent c1's goal is to satisfy an LTL formula \u03c8. As in the collaborative case, an agent is deemed social if it's aware of the other agent operating in the environment and, in the adversarial case, actively tries to minimize the other agent's payoff, or unsocial otherwise. An agent is deemed optimistic if it assumes its messages are perceived by the environment in the same order as the agent issues them, and that all frames of reference are synchronized, and realistic otherwise. We assume each agent is aware of the other agent's LTL formula.\nIn the collaborative case, we assumed a a sequence of agents' messages could be partitioned uniformly, regardless of total sequence size. That assumption does not result in an unmanageable number of scenarios, since both agents were aligned in wanting to return to the same initial state after either a successful or unsuccessful run. In the depicted adversarial case, where agents have (potentially) several options to satisfy their formulae, that permutation assumption explodes the state space of the problem. Thus, let us begin the analysis with a simplification of the partitioning assumption.\nAssuming both agents issue messages at all points in time within their frames of reference and that their frames of reference are synchronized with each other, the environment processes messages issued by both agents in the same order as issued, but with random ordering within message pairs. I.e., give two messages m0 and m1 emitted by agents c0 and c1 synchronously, the environment may process first m0, first m1, or both at the same time (the latter is equivalent to a traditional turn-based game, where both players must commit to an action at any turn, and both actions are executed concurrently). Because the game is infinite, we construct not a game tree from the current to terminal states, but rather a closed game graph, where payoffs are associated with specific walks within the graph."}, {"title": "", "content": "Unsocial, optimistic agents believe they are alone in operating in the environment, and assume their actions are immediate and permanent; i.e., they do not conceive of environment state change without performing an action (leading to potential mismatch between actual state and their belief of state). An agent attempts to satisfy its formula, prioritizing the graph sub-run that allows it to do so most quickly. Unsocial but realistic agents, are aware the environment may not respond to their actions responsively; thus, they probe for action effect prior to issuing the next action in a sequence. Social, optimistic agents are aware of the competition. Thus, they attempt to chart the path that maximizes the satisfaction of their formula, whilst minimizing the satisfaction of the adversary's formula. Because they conceive of a responsive environment, they assume an action issued at a given moment in time will have effect immediately, synchronously with the adversary's action, such that the total effect on the environment is the sum of both actions (i.e., as in a classical concurrent game). Traditional minimaxing strategies cannot be applied in the absence of terminal game states23; interested readers may consult Devroye et al24 for meaningful strategies in these scenarios. Since the study of strategy optimality is beyond the scope of this paper, we employ a simple strategy that, whilst not necessarily optimal, suffices to illustrate the main points: each agent assumes its adversary will attempt to either carry out a formula satisfaction sequence, if it's within a formula path state, or reach the nearest root state for a formula satisfaction sequence otherwise. Under that assumption, each agent attempt to steer the state using the same reasoning for its own formula satisfaction (both agents look only one state in the future). Social but realistic agents, employing the same strategic principles as in the previous case, can now take advantage of the non-deterministic behavior of CPSs to probabilistically attempt to satisfy their formula in situations that would be impossible in a deterministic concurrent game. With knowledge that it is possible their actions are effected before the adversary's action (regardless of issue order), or vice-versa, agents can now employ a \"best case\" strategy that will satisfy their formula if the right action is executed first. Again, we are assuming agents plan one state into the future, and assume that the order of actions issued by both agents at the same time step is random, but the ordering of message sequences per agent is preserved."}, {"title": "4 Stochastic Strategies for Cyber Physical Games' Payoff", "content": "Analyzing payoffs, for a system with a small number of states, can be done by listing all run permutations and determine average payoff for each agent. This, of course, does not scale; the general case is more challenging, and requires realizing that the problem must be formulated as determining the probabilities that certain sequences of state transition occur. Notice that, e.g., the transition from state {\u0101b\u0113} to state {\u0101bc} might happen because:\n\u2022 At state {\u0101b\u0113}, co issues action c \u2190 mc0 = T and c1 issues action b \u2190 mc1 = 1, both interpreted by the environment simultaneously.\n\u2022 At state {\u0101b\u0113}, co issues action c \u2190 mc0 = T and c1 issues action b \u2190 mc1 = T, but the environment interprets co's action first.\n\u2022 At state {\u0101b\u0101}, co issues action c \u2190 mc0 = T and c1 issues action b \u2190 mc1 = 1, but the environment interprets c1's action first.\n\u2022 Etc.\nThus, rather than look at state transitions, we must look at the probabilities of transition sequences, in function of the environment's interpretation of each message sequence, and of agents' strategies. Notice that, because there is dependence on sequence, rather than just current state, it is not possible to perfectly model this behavior as a Markov Chain25, which assumes unique dependence on just current state; rather, the problem is intractable (specifically, it is NP-hard in the general case26).\nBecause we are dealing with instances of real systems obeying (partially) known constraints, rather than abstract mathematical models, we may approximate the behavior by taking advantage of our knowledge of CPSs. Recall that a message m to the environment E has \\(l_{c_x}(m) = l_o(m) +w\\), \\(w \\sim N(\\mu, \\sigma^2)\\): thus, messages are more likely to be interpreted simultaneously rather than sequentially, and each message is equally likely to be interpreted first27, with possibilities: c0 action effect, followed by c1 action effect; c1 action effect, followed by c0 action effect; or, simultaneous effect of c0's and c1's actions. Let us denote these probabilities P(co, c1), P(c1, co), and P(co||c1), respectively, where index k represents the environment's frame of reference, where time progresses twice as fast as in the agents' frame of reference.\nThe conditional probability P(t|ek) that a state transition t : ek \u2192 ek+1,e \u2208 E occurs, given that we are in state ek, can thus be approximated by the sum of possible sequences that include t, weighted by the probabilities of simultaneous or sequential interpretation, normalized so the sum of probabilities of all transitions that begin in ek add up to 1. Let Isimt denote the set of all simultaneous interpretations in er that result in t (this set has either 0 or 1 element); Iseq1t denote the set of all sequential interpretations that contain ek as the first state (one interpretation) and Iseq2t, denote the set of all sequential interpretations that"}, {"title": "", "content": "contain ek as the intermediate state (second interpretation), including t; and g denote the required scaling factor per state to satisfy probability sums; then:\n\\(P(t|e_k) = \\frac{P(c_0||c_1)|||I_{sim}^t||| +P(c_0,c_1)|||I_{seq1}^t||| + P(c_1, c_0)|||I_{seq2}^t|||}{g}\\)\n\\(\\sum_{i=t_E \\ni T} P(i|e_k) = 1\\)\n\n\\(P(c_0||c_1)+P(c_0, c_1)+P(c_1, c_0) = 1\\)\nFor each game, we can construct the state sequence matrix T, where row index i denotes the state at time k and column index j represents the next state at time k + 1, and entry ti,j denotes the probability of transitioning to state j given current state i. The value for each entry tij is given by Equation 3; e.g.:\n\\(T = \\begin{bmatrix}\n0 & P(0 \\rightarrow 1|0) & ... & P(0 \\rightarrow n|0) \\\\\nP(1 \\rightarrow 0|1) & 0 & ... & P(1 \\rightarrow n|1) \\\\\n\\vdots & \\vdots & 0 & \\vdots \\\\\nP(n \\rightarrow 0|n) & P(n \\rightarrow 1|n) & ... & 0\n\\end{bmatrix}\\)\nThus, we approximate the behavior of a game graph as a probabilistic finite automaton (PFA)28, where the probabilities of transitioning between states are a function of agents' strategies. These classes of processes are also sometimes called generative finite automata29: an automaton stochastically generates a path (a substring, in the traditional formulation as a grammar30).\nRequire: state sequence matrix T\nSet of most likely paths \u03a0 \u2190 ()\nfor all i rows \u2208 T do\nPath \u03c0 - i\nCurrent \u2190 i\nNext \u2190 Max(j) \u2208 row i of T\nwhile Next \u2209 \u03c0 do\nEnqueue(Next, \u03c0)\nCurrent \u2190 Next\nNext \u2190 Max(j) \u2208 row Current of T\nend while\nCurrent \u2190 FirstElement(\u03c0)\nwhile Current \u2260 Next do\nRemoveFirstElement(\u03c0)\nCurrent \u2190 FirstElement(\u03c0)\nend while\nif \u03c0 \u2208 \u03a0 then\n\u03a0 - \u03a0 \u222a \u03c0\nend if\nend for\nreturn Set of most likely paths \u03a0\nOur goal is to find the likelihood of generating a path satisfying each formula; we point readers to the 2-part review by Vidal et al28 of (tractable) closed-form solutions for particular cases of such problems in PFAs. In the general case, no closed form solution exists31; algorithmically, this can be achieved in polynomial time through Monte-Carlo methods26. Algorithms for finding particular properties, such as finding the most likely generated string, also exist32.\nWe simplify the problem heuristically, and make use of Equation 3 to identify the most likely closed path. Since there are no idle transitions (i.e., transitions where the source and target states are the same), choosing a single transition per source state must necessarily result in a closed path (through the pigeonhole principle). As long as there exists a unique transition, per source state, with highest probability, this path is identifiable and suffices to predict agents' payoffs. Should a unique transition"}, {"title": "", "content": "with highest probability not exist in any given state, multiple equally likely closed paths can be analyzed in the same manner. It is also possible that several most likely paths without any states in common exist; these can be identified in the same way. The procedure for determining the most likely path, assuming a single transition with highest probability exists, is described in Algorithm 1.\nThe set of most likely paths per PFA can be determined, for each matrix, through Algorithm 1, for specific values or distributions of P(co, c1), P(c1, co), and P(co||c1) (these can be determined empirically through CPS profiling)."}, {"title": "5 Experiments and Results", "content": "Our goal here is to analyze whether our models for the evolution of Cyber Physical Games provide an accurate prediction of behavior. Toward this purpose, we develop a computer simulation of two examples (corresponding to the collaborative and adversarial Iterated Boolean Game) and explore the predictive power of the models (particularly, the developed heuristics) for different versions of CPS parameters. All code and data for those wanting to reproduce or extend our results is available here\u00b9."}, {"title": "5.1 Evaluating the Collaborative Game", "content": "For the collaborative case, we define that agent c0's goal is to satisfy a formula \u03d5, and agent c1's goal is to satisfy a formula \u03c8, given by:\n\\( \\phi : \\{\\overline{ab}\\} \\rightarrow F\\{\\overline{ab}\\} \\rightarrow X\\{\\overline{ab}\\} \\)\n\\( \\psi : \\{\\overline{ab}\\} \\rightarrow X\\{\\overline{ab}\\} \\rightarrow F\\{\\overline{ab}\\} \\)\nFor the collaborative case, if agents do not sense the environment after the initial set up, we simply permute the set of agents' actions per iteration, and apply a the generated sequence to the environment. All permutations are equally likely through the Fisher-Yates method33. For the cases where agents sense the environment (potentially aborting their action issuing in the case of a failed application of their action), we permute in a staggered fashion, interleaving sets bookmarked by agent sensing.\nIt is unnecessary to list all possible runs, but assuming an initial state of {ab}, it is trivial to deduce the two optimal runs that satisfy both \u03d5 and \u03c8 fairly:\n\u27e8{\u0101b}tE=0, {ab}tE=1,{ab}tE=2,{ab}tE=3, {ab}tE=4\u27e9\n\u27e8{\u0101b}tE=0, {ab}tE=1,{ab}tE=2,{ab}tE=3, {ab}tE=4\u27e9\nThat these exist suffices to show the game is collaborative. Notice that the former satisfies both formulae at the same time, whilst the latter satisfies \u03c8 before \u03a6. Continuous evolution requires the run to resume to the initial state {ab} (not depicted)."}, {"title": "5.2 Evaluating the Adversarial Game", "content": "Agent c0's goal is to satisfy a formula \u03d5, and agent c1's goal is to satisfy a formula \u03c8, given by:\n\\( \\phi : (\\{\\overline{abc}\\} \\rightarrow X\\{\\overline{abc}\\} \\rightarrow X\\{abc}\\} )U (\\{\\overline{ab}\\overline{c}\\} \\rightarrow X\\{\\overline{abc}\\} \\rightarrow X\\{abc}\\} )U (\\{abc\\} \\rightarrow X\\{abc\\} \\rightarrow X\\{\\overline{abc}\\} )\n\\psi : (\\{\\overline{abc}\\} \\rightarrow X\\{\\overline{abc}\\} \\cup (\\{\\overline{abc}\\overline{c}\\} \\rightarrow X\\{abc\\}\n)\n\n\n\n\nIn this scenario, there are more options for \u03d5 satisfiability than for \u03c8; \u03d5 can be satisfied by three different sub-runs, but all require two successive successful state transitions. \u03c8 can only be satisfied by two different sub-runs, but each just requires one successful state transition."}, {"title": "5.3 Discussion", "content": "Simulation results for the collaborative game show are consistent with predicted values, with very small Mean Square Error (MSE) for all cases except Unsocial and Realistic agents, where our model is pessimistic: being aware of environment progression and aborting failed runs preemptively seems to work out better than expected (it's possible that this is an artifact of the small state space). In the adversarial game, Unsocial agents lead to the satisfaction of one agent's formula, closely aligned with predicted most likely state sequence (in this case, we see \u00de satisfaction because there is no active adversarial action, thus the higher number of options for leads to victory). When agents behave socially, \u03a8 allows for a dominant strategy, but still"}]}