{"title": "Barlow Twins Deep Neural Network for Advanced 1D Drug-Target Interaction Prediction", "authors": ["Maximilian G. Schuh", "Davide Boldini", "Stephan A. Sieber"], "abstract": "Accurate prediction of drug-target interactions is critical for advancing drug discovery. By reducing time and cost, machine learning and deep learning can accelerate this discovery process. Our approach utilises the powerful Barlow Twins architecture for feature-extraction while considering the structure of the target protein, achieving state-of-the-art predictive performance against multiple established benchmarks. The use of gradient boosting machine as the underlying predictor ensures fast and efficient predictions without the need for large computational resources. In addition, we further benchmarked new baselines against existing methods. Together, these innovations improve the efficiency and effectiveness of drug-target interaction predictions, providing robust tools for accelerating drug development and deepening the understanding of molecular interactions.", "sections": [{"title": "1 Introduction", "content": "Studying drug-target interactions (DTIs) is crucial for understanding the biochemical mechanisms that govern how molecules interact with proteins.\u00b9 Key challenges in drug discovery are the identification of proteins that can be used as targets for the treatment of diseases.\u00b2 To achieve the desired therapeutic effects, the discovery of molecules that interact with and activate or inhibit target proteins is essential. 3-5\nRecent advances in computational methods have transformed the drug discovery landscape, providing robust tools for cost-effective exploration of the chemical space. These in silico approaches facilitate the prediction and analysis of DTIs, aiding in the identification of potential drug candidates and their corresponding protein targets. 6,7 The use of computational techniques allows researchers to gain a comprehensive understanding of the molecular mechanisms underlying DTIs, thereby accelerating the drug discovery process and minimising reliance on traditional, resource-intensive experimental methods. 8,9 Different methods have been used to understand how drugs interact with target proteins. These methods are grouped into three main categories: structure-agnostic, structure-based and complex-based.\nStructure-agnostic approaches use one-dimensional (1D) inputs like molecule simplified molecular-input line-entry system (SMILES) and protein amino acid sequences, or two-dimensional (2D) inputs like graphs and predicted contact maps. 10-13 These methods are cost-effective and and sufficiently accurate compared to experimental or in silico structure prediction, 14 as they are independent of the protein's structure when predicting effects.\nStructure-based approaches require three-dimensional (3D) protein structures and 1D or 2D molecular inputs. 3D structures are usually derived from experimental data, although computational predictions are increasingly employed. 15\u201319 These methods have great potential but can be unreliable. They depend on accurate 3D protein structures and may be limited in their ability to generalise beyond experimentally observed DTIs. 20 Due to the complexity of the experimental setup, 3D protein structures can be difficult to obtain.\nIn addition, models often overlook the fact that proteins are not rigid structures, but are generally in motion, e.g., ligand binding induces a conformational change. 16,18,19\nFinally, complex-based approaches require protein-ligand co-complex structures, which addi-tionally require 3D information, as well as protein interaction information about the ligand. 21 For this reason, complex-based approaches can provide a more detailed insight into the interactions, but they are by far the most difficult to obtain data for.\nConsidering these different approaches, we designed BARLOWDTI as a fully data-driven, sequence-based approach that relies on SMILES and amino acid sequences as the most accessible data, avoiding costly and time-consuming experimental data such as crystal structures. Additionally, we use a specialised bilingual protein language model (PLM) to embed the 1D amino acid sequence, which uses a 3D-alignment method that results in a \u201cstructure-sequence\u201d representation. 22,23 This approach makes BARLOWDTI input data structure-agnostic, yet benefits from \u201cstructure-sequence\u201d PLM embeddings. Unlike most other methods, we have developed a system that uses a hybrid \"best of both worlds\u201d machine learning (ML) and deep learning (DL) approach to improve DTI prediction performance in low data regimes where training data is limited. 24,25 We have found that DL architectures such as Barlow Twins 26,27 are excellent at learning features 25 that can then be used for gradient boosting machine (GBM) training to achieve state-of-the-art performance, as the size of datasets is usually too small to reliably train a DL model that will perform competitively."}, {"title": "2 Results and Discussion", "content": "BARLOWDTI design. We propose a novel method for predicting DTIs using SMILES notations, primary amino acid sequences and annotated interaction properties. BARLOWDTI relies on a three key components, visualised in Fig. 1:\n1. Firstly, the input needs to be vectorised. This is achieved by converting SMILES to an extended-connectivity fingerprint (ECFP). The amino acid sequences are processed by a PLM that uses both modalities, combining 1D protein sequences and 3D protein structure. 22\n2. Secondly, we teach the self-supervised learning (SSL) based Barlow Twins model interaction of molecule and protein without considering labels. 26,27 The objective function implements invariance of both representation of one interaction while ensuring non-redundancy of the features. 26,27\n3. Finally, BARLOWDTI takes a combination of embeddings generated by the encoders from the Barlow Twins DL model and uses them as features to train a GBM based on the interaction annotations. 24 This approach exploits two key strengths: it uses DL to refine representations, and it leverages the power of ML in scenarios with limited data. This is particularly relevant for DTI datasets, where only around 50 000 annotated pairs are publicly available. 28\u201331\nBenchmark selection. We select a comprehensive set of literature-based benchmarks to evaluate the performance of BARLOWDTI against several leading methods. The benchmarks considered in this study are derived from several key sources. These sources include biomedical networks, 28 the US patent database, 29 and data detailing the interactions of 72 kinase inhibitors with 442 kinases, representing over 80 % of the human catalytic protein kinome. 30 These datasets provide DTIs as pairs of molecules and amino acid sequences, each coupled to an interaction annotation.\nTo ensure a fair comparison, BarlowDTI is retrained across all benchmarks. Finally, we evaluate performance in a binary classification setting:\n\u2022 We compare BARLOWDTI with a total of seven established models: the model by Kang et al., MolTrans, 33 DLM-DTI, 13 ConPLex, 34 DrugBAN, 35 PSICHIC, 12 and STAMP-DTI. 36 Overall, various structure-agnostic, structure-based and complex-based methods have demonstrated state-of-the-art performance in benchmarks."}, {"title": "3 Conclusions", "content": "Our proposed method, BARLOWDTI, integrates sequence information with the Barlow Twins SSL architecture and GBM models, representing a powerful fusion of ML and DL techniques.\nThis approach demonstrates state-of-the-art DTI prediction capabilities, validated across multi-ple benchmarks and data splits. Notably, our method outperforms existing literature benchmarks in ten out of twelve datasets evaluated.\nTo elucidate the efficacy of BARLOWDTI, we conducted an ablation study to investigate the contribution of its core components and their impact on performance. In addition, we re-evaluated the choice of baselines in numerous publications and advocate the inclusion of GBM baselines.\nGiven its exceptional performance, we are confident that BARLOWDTI can significantly acceler-ate the drug discovery process and offer significant time and cost savings through the use of virtual screening campaigns."}, {"title": "4 Methods", "content": "4.1 Datasets\nTo evaluate the performance of BARLOWDTI, three established benchmarks are used. They all provide fixed splits for training, evaluation and testing. In some publications the training and evaluation is merged to improve predictive performance. To endure comparability, this was not done in this work. All metrics listed from other publications are also listed where only the training set is used.\nIn addition, Kang et al. first proposed splits for large DTI datasets, BioSNAP, 28 BindingDB 29 and DAVIS. 30,32\nThe addition of a variety of splits with an additional benchmark Human 33 (based on DAVIS) are proposed by Koh et al., we evaluate these separately. 12\nFor all datasets, to reduce bias and improve model performance, the SMILES are cleaned using the Python ChEMBL curation pipeline. 44 All duplicate and erroneous molecule and protein information that could not be parsed is removed. Training is performed on the predefined training splits.\n4.2 Representations\nMolecular information. The SMILES are converted into ECFPs using RDKit. 45 We used them with 1024 bit and a radius of 2.\nAmino acid sequence information. The amino acid sequences are converted into vectors, by using the PLM ProstT5. 22\n4.3 Barlow Twins model configuration\nThe proposed method is based on the Barlow Twins 26 network architecture, which employs one encoder for each modality and a unified projector. The encoders and projector are multilayer perceptron (MLP) based. The loss function is adapted from the original Barlow Twins publication and enforces cross-correlation between the projections of the modalities. 26\nThe BARLOWDTI architecture is coded in Python using PyTorch. 46,47\nPre-training Barlow Twins. Here we pre-train the Barlow Twins architecture on our joint DTI dataset, based on BioSNAP, BindingDB, DAVIS and DrugBank, 31 removing duplicates and without labels to teach DTIs. Early stopping is implemented to avoid overfitting, which is carried out using a 15% validation split.\nHyperparameter optimisation Manual hyperparameter optimisation is performed, shown in Tab. 3.\n4.4 Baseline model configuration\nAs a baseline, we have selected a GBM. Similar to our feature-extraction implementation, for all features we concatenate both ECFP and PLM embeddings. Finally, a GBM, XGBoost Python implementation, is trained on the ECFP and PLM embedding concatenation in combination with the labels for each training set, respectively."}, {"title": "A Additional Results and Discussion", "content": "Statistical testing. We focus on PR AUC as our metric because it is an established performance indicator in unbalanced scenarios. Secondly, it shows a more pronounced separation between different methods, as most methods show very high values of ROC AUC.\nWe apply the two-sided Welch's t-test, 40,41 with Benjamini-Hochberg42 multiple test correction. This is done for all methods for which the required performance information exists in the published literature.\nIn Fig. 2, our primary focus is on the overall change in performance. We therefore make com-parisons across all datasets collectively rather than individually. Detailed individual comparisons are provided in Tabs. 1 and 2."}]}