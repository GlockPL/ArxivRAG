{"title": "FedSA: A Unified Representation Learning via Semantic Anchors for Prototype-based Federated Learning", "authors": ["Yanbing Zhou", "Xiangmou Qu", "Chenlong You", "Jiyang Zhou", "Jingyue Tang", "Xin Zheng", "Chunmao Cai", "Yingbo Wu"], "abstract": "Prototype-based federated learning has emerged as a promising approach that shares lightweight prototypes to transfer knowledge among clients with data heterogeneity in a model-agnostic manner. However, existing methods often collect prototypes directly from local models, which inevitably introduce inconsistencies into representation learning due to the biased data distributions and differing model architectures among clients. In this paper, we identify that both statistical and model heterogeneity create a vicious cycle of representation inconsistency, classifier divergence, and skewed prototype alignment, which negatively impacts the performance of clients. To break the vicious cycle, we propose a novel framework named Federated Learning via Semantic Anchors (FedSA) to decouple the generation of prototypes from local representation learning. We introduce a novel perspective that uses simple yet effective semantic anchors serving as prototypes to guide local models in learning consistent representations. By incorporating semantic anchors, we further propose anchor-based regularization with margin-enhanced contrastive learning and anchor-based classifier calibration to correct feature extractors and calibrate classifiers across clients, achieving intra-class compactness and inter-class separability of prototypes while ensuring consistent decision boundaries. We then update the semantic anchors with these consistent and discriminative prototypes, which iteratively encourage clients to collaboratively learn a unified data representation with robust generalization. Extensive experiments under both statistical and model heterogeneity settings show that FedSA significantly outperforms existing prototype-based FL methods on various classification tasks.", "sections": [{"title": "Introduction", "content": "Federated Learning (FL) has been proposed to collaboratively train a global model to address the increasingly significant privacy concerns (Li et al. 2020; Kairouz et al. 2021). Despite its advantages, traditional FL methods (McMahan et al. 2017) struggle with statistical heterogeneity, where heterogeneous data among clients can bias the global model towards clients with dominant data characteristics (Wang et al. 2020). To remedy this, personalized FL (Tan et al. 2022a) aims to train a personalized model for each client by leveraging the benefits of FL rather than pursuing a global model. Many researchers have concentrated on model-based FL approaches that split the model into a body for universality and a head for personalization, requiring the same model architectures across all clients to facilitate the aggregation of the body at the server (Oh, Kim, and Yun 2021). However, model heterogeneity frequently arises when clients may design their own local model architectures to meet individual requirements and hardware constraints. Such model-based FL approaches not only incur significant communication costs but also risk exposing model details, which may further raise concerns about privacy and commercial proprietary information (Ye et al. 2023; Wang et al. 2023).\nTo address these issues, knowledge-based FL approaches have emerged as a novel FL paradigm that transfers various types of global knowledge among clients with heterogeneous data and diverse model architectures (Tan et al. 2022b). For example, knowledge distillation (KD)-based FL methods transfer logits outputs from a teacher model as global knowledge to instruct the student models (Li and Wang 2019; Lin et al. 2020; Zhang et al. 2021). However, these methods require a public dataset to align the outputs and are highly dependent on the quality of this dataset (Zhang et al. 2023a). Researchers further explore KD in a data-free manner by employing additional auxiliary models as global knowledge (Wu et al. 2022; Zhang et al. 2022), but the communication costs for transmitting the auxiliary models remain considerable. Recently, prototype learning has garnered increasing interest due to its exemplar-driven nature and intuitive interpretation (Snell, Swersky, and Zemel 2017). Prototypes, which are essentially averages of class representations, serve as abstract concepts that can effectively integrate feature representations from diverse data distributions. By transferring lightweight prototypes as global knowledge, prototype-based FL methods significantly address privacy concerns and reduce communication costs (Tan et al. 2022b,c; Zhang et al. 2024).\nHowever, existing prototype-based FL methods directly collect prototypes from biased data distributions of clients, which inherently introduces inconsistencies into representation learning (Zhou, Zhang, and Tsang 2023). Moreover, the prototypes extracted from different model architectures have diverse scales and separation margins (Zhang et al. 2024), further exacerbating these inconsistencies. These issues demonstrate that the traditional prototype generation is sub-optimal for heterogeneous FL since prototypes are heavily bound to the representation learning process and data distribution across clients, which can potentially lead to learning collapse (Ge et al. 2024). To investigate the impact of representation inconsistencies on the generation of prototypes, we revisit and reinterpret the biases arising from heterogeneity in feature extractors and classifiers, from the perspective of representation learning (Guo, Tang, and Lin 2023): 1) Biased feature extractors tend to produce inconsistent data representations in the semantic space; 2) Biased classifiers often diverge, learning skewed decision boundaries due to local class distributions; 3) Skewed prototype alignment occurs as local prototypes, generated from these inconsistent representations, naturally exhibit a skewed alignment in the semantic space. The naive averaging aggregation of these skewed local prototypes (Tan et al. 2022b) leads to the margin shrink problem, where the global prototypes tend to converge closely together, reducing the overall separability and effectiveness in distinguishing between different classes (Zhang et al. 2024). Moreover, the global prototypes then serve to guide the representation learning of local models, potentially creating a vicious cycle of representation inconsistency, classifier divergence, and skewed prototype alignment. Specifically, representation inconsistency causes classifier updates to diverge and prototype alignment to skew. Subsequently, these diverged classifiers and skewed prototypes force the feature extractors to map to more inconsistent representation space, thereby exacerbating the vicious cycle.\nMotivated by these insights, we propose a novel framework named Federated Learning via Semantic Anchors (FedSA) to break the vicious cycle. Specifically, we first introduce simple yet effective semantic anchors, serving as prototypes, to decouple the generation of prototypes from local representation learning and guide local models in learning consistent representations. Instead of collecting prototypes from biased models, we project pre-defined class anchors for all categories into the semantic space through a lightweight embedding layer, thereby obtaining semantic anchors that are independent of representation learning and well-separated. By incorporating semantic anchors, we further propose: 1) Anchor-based Regularization with Margin-enhanced Contrastive Learning (RMCL) to correct the biased feature extractors, enabling them to learn consistent prototypes that exhibit both intra-class compactness and inter-class separability; 2) Anchor-based Classifier Calibration (CC) to correct the biased classifiers, assisting them in learning consistent decision boundaries across different classes. We then update the semantic anchors with these enhanced prototypes via an Exponential Moving Average (EMA) update, which iteratively encourages clients to collaboratively learn a unified data representation in the semantic space. Our contributions are summarized as follows:\n\u2022 We demonstrate that in prototype-based FL methods, heterogeneity creates a vicious cycle of representation inconsistency, classifier divergence, and skewed prototype alignment across client models.\n\u2022 To break the vicious cycle, we propose a novel framework named FedSA that corrects biased feature extractors and classifiers, guiding local models in learning a unified data representation.\n\u2022 We evaluate the proposed method under both statistical and model heterogeneity settings. Extensive experiments and ablation studies demonstrate the superiority of FedSA over prototype-based FL methods."}, {"title": "Related Work", "content": "Model-based FL approaches are inspired by the training scheme that decouples the entire model into a general body and a personalized head (Kang et al. 2019; Devlin et al. 2019). For example, methods like FedRep (Collins et al. 2021), FedBABU (Oh, Kim, and Yun 2021), FedRoD (Chen and Chao 2022) and FedGC (Niu and Deng 2022) split the model into a feature extractor and a classifier. This approach allows clients to share a global feature extractor to mitigate data heterogeneity while maintaining client-specific classifiers for personalization. LG-FedAvg (Liang et al. 2020) and FedGen (Zhu, Hong, and Zhou 2021) treat the top layers as the general body for sharing while allowing the bottom layers to have different architectures. However, these methods commonly involve significant communication costs as model parameters are transmitted between clients. Recent studies initialize class anchors (Zhou, Zhang, and Tsang 2023) or use prototypes (Xu, Tong, and Huang 2023; Dai et al. 2023), serving as additional knowledge to align feature representations from different feature extractors. Nevertheless, these class anchors or prototypes are also updated or generated based on locally inconsistent representations. In this paper, we only share lightweight semantic anchors across clients in a model-agnostic manner.\nKnowledge-based FL approaches transfer various types of global knowledge instead of model parameters, making them well-suited for model heterogeneity setting. The typical method in these approaches (Jeong et al. 2018; Li and Wang 2019; Lin et al. 2020) involves incorporating KD methods (Hinton, Vinyals, and Dean 2015) to transfer knowledge from a teacher model on the server to enhance the performance of student models on the client side. FML (Shen et al. 2020) and FedKD (Wu et al. 2022) advance KD methods in a data-free manner, where they share a small auxiliary model as global knowledge, rather than relying on a global dataset. However, the majority of these methods are not suitable for heterogeneous FL, as their effectiveness heavily relies on the quality of the public dataset or the auxiliary model. Another popular approach is to transfer abstract class representations, i.e., prototypes, between the server and clients. FedProto (Tan et al. 2022b) regularizes the local prototypes to align closer to the aggregated global prototypes. FedPCL (Tan et al. 2022c) employs prototype-wise contrastive learning to enhance the inter-class separability among prototypes. Additionally, FedTGP (Zhang et al. 2024) treats prototypes as trainable elements and enforces"}, {"title": "Method", "content": "In prototype-based FL settings, we consider a central server and m clients collaboratively training their models with heterogeneous architectures on their heterogeneous local datasets {Di}m\ni=1. Following FedProto (Tan et al. 2022b), we split each client i's model wi into a feature extractor fi parameterized by \u03b8i and a classifier hi parameterized by \u03c6i \u2208 RC\u00d7D, where D is the dimension of the last representations and C is the number of classes. The goal is for clients to collaborate by sharing global prototypes P with the central server. The overall collaborative training objective is:\n$\\min_{\\{\\theta_i,\\phi_i\\}\\}_{i=1}^m \\frac{1}{m}\\sum_{i=1}^m L_i (D_i, \\theta_i, \\phi_i, P)$  (1)\nDuring local training, each client i first computes its local prototype for each class c as follows:\n$\\overline{P}_{i}^{c}=\\frac{1}{|D_{i, c}|}\\sum_{(x,y) \\in D_{i,c}} f_i(x;\\theta_i)$ (2)\nwhere Di,c denotes the subset of the local dataset Di consisting of all data samples belonging to class c. After receiving all local prototypes from clients, the server performs weighted-averaging aggregation for each class prototype to obtain the global prototypes:\n$P^{c}=\\frac{1}{|N_c|}\\sum_{i \\in N_c} \\overline{P}_{i}^{c}$ (3)\nwhere Nc denotes the set of clients that have class c, and Nc represents the total number of data samples of class c among all clients. The server then sends the global prototypes P = {Pc}C\nc=1 to each client to guide local training:\n$L_i = L_s (h_i (f_i (x; \\theta_i) ; \\phi_i), y) + \\lambda L_R (\\overline{P}, P^{c})$ (4)\nwhere Ls is a typical loss term (e.g., cross-entropy loss) in supervised learning. \u03bb is a hyperparameter, and LR is a regularization term that minimizes the Euclidean distances between the local prototype $\\overline{P}_{i}^{c}$ and the global prototype Pc.\nAlthough prototype-based FL methods have achieved significant results by sharing lightweight prototypes, they have overlooked the biases arising from heterogeneity. Building on previous findings (Oh, Kim, and Yun 2021; Guo, Tang, and Lin 2023), which link the feature extractor to representation learning and the classifier to linear decision boundary learning, we seek to understand how heterogeneity affects the generation of prototypes through these components. Due to statistical heterogeneity, the dataset of each client is inherently biased. Consider different local models wi and wj, each trained on its respective local datasets Di and Dj. As shown in Fig. 1, we use a toy example to show the existence of biases in local models.\nObservation 1 (Representation inconsistency). Given the same inputs x, the outputs fi(x) could deviate significantly from fj(x). Fig. 1(a) shows the data representations learned by different feature extractors. As local models are trained on biased datasets, we observe that the representations extracted by different local feature extractors are inconsistent in the semantic space.\nObservation 2 (Classifier divergence). As illustrated in Fig. 1(a), we visualize the decision boundaries learned by different classifiers hi(\u00b7) and hj(\u00b7) for the same input. The observation confirms that inconsistent representations significantly cause local classifiers to diverge, resulting in skewed decision boundaries among clients."}, {"title": "Semantic Anchors", "content": "With a total of C classes in the whole dataset, we randomly initialize pre-defined class anchors A = {Ac}C\nc=1 where each Ac \u2208 RD. Then, we project them into the semantic space through a trainable embedding layer hap(A) to improve their separability, obtaining semantic anchors $\\overline{A} = {\\overline{A}^{c}}_{c=1}^{C} \\in \\mathbb{R}^{C \\times D}$. In each communication round t, the server sends these semantic anchors At to each client to guide their local training. The goal is for clients to collaboratively learn a unified data representation that exhibits intra-class compactness and inter-class separability via the FL paradigm. To achieve this, we further propose Anchor-based Regularization with Margin-enhanced Contrastive Learning (RMCL) and Anchor-based Classifier Calibration (CC). An overview of the proposed framework is shown in Fig. 2.\nTo achieve intra-class compactness, we propose anchor-based regularization by directly minimizing the distance between class representations and corresponding semantic anchors. In Eq.4, we redefine the regularization loss as follows:\n$L_R = \\sum_{c \\in D_i}d (\\overline{P}_{i}^{c}, \\overline{A}^c)$ (5)\nwhere d measures the Euclidean distance between the local prototype $\\overline{P}_{i}^{c}$ and the semantic anchor $\\overline{A}^c$. Although guiding class representations toward corresponding semantic anchors can achieve an intra-class compact embedding space, due to statistical and model heterogeneity, clients often extract highly diverse data representations that vary in separability and prototype margins across different classes.\nInspired by previous works (Deng et al. 2019; Chen et al. 2021; Zhang et al. 2024), we propose anchor-based margin-enhanced contrastive learning that enforces a client-specific margin \u03b4 between classes to facilitate the learning of a large-margin data representation and ensure consistent prototype margins across clients. Specifically, we calculate the average margin among semantic anchors, referred to as the global margin \u03b4global, and the average margin among local prototypes for each client, referred to as the local margin \u03b4i. For client i, the local margin is computed:\n$\\delta_i=\\frac{1}{(N-1)^2} \\sum_{a} \\sum_{b \\ne a} d(\\overline{P}_{i}^{a},\\overline{P}_{i}^{b})$ (6)\nwhere N is the number of classes maintained by client i. The client-specific margin \u03b4i for each client is determined by taking the larger value between the local and global margins, i.e., $\\delta_i = \\max \\{\\delta_{\\text{global}}, \\delta_i\\}$. Our goal is to decrease the distance between $\\overline{P}_{i}^{c}$ and $\\overline{A}^c$, and to increase the distance between $\\overline{P}_{i}^{c}$ and $\\overline{A}^{c'}$ with the client-specific margin \u03b4i. Accordingly, we define the anchor-based margin-enhanced contrastive loss as follows:\n$L_{MCL} = -\\log \\frac{e^{-(d(\\overline{P}_{i}^{c},\\overline{A}^{c})+\\delta_i)}}{e^{-(d(\\overline{P}_{i}^{c},\\overline{A}^{c})+\\delta_i)} + \\sum_{c' \\ne c}^{}e^{-d(\\overline{P}_{i}^{c},\\overline{A}^{c'})}}$ (7)\nwhere c'\u2208 [C], c' \\ne c. The client-specific margin adaptively guides each client toward better data representations and consistent prototype margins. Specifically, when the local model learns well-separated and clustered class representations, the client adopts its local margin \u03b4i as the client-specific margin. Otherwise, the client uses the global margin \u03b4global to encourage the local model to learn class representations with a larger margin separation. Through repeated collaborative training in FL, clients reach a consensus on the margins among local prototypes. By aggregating these uniformly adjusted local prototypes at the server, we can obtain global prototypes with enhanced separability.\nBeyond correcting biased feature extractors to learn consistent representations, we also propose anchor-based classifier calibration to correct biased classifiers toward achieving consistent decision boundaries. Specifically, each client i uses the semantic anchors as inputs for its classifier, calibrating the classifiers according to the following objective:\n$L_{CC} = -\\frac{1}{C} \\sum_{c \\in C} \\log \\frac{e^{h_i(\\overline{A}^{c})}}{\\sum_{c' \\in C} e^{h_i(\\overline{A}^{c'})}}$ (8)\nwhere Lcc is the classifier calibration loss, which reduces the distance between the c-th class proxy and the corresponding semantic anchor. By applying this loss across different clients, we not only reduce the discrepancies in decision boundaries between different model architectures but also promote the learning of consistent representations.\nBy integrating all components, the semantic anchors effectively guide each client to learn a unified data representation by minimizing the overall loss:\n$L_i = L_s + \\lambda_1L_R + \\lambda_2L_{MCL} + \\lambda_3L_{CC}$ (9)"}, {"title": "FedSA Framework", "content": "Following the prototype-based communication protocol, each client collects local prototypes and sends them to the server. The server then performs weighted-averaging aggregation to obtain global prototypes. To facilitate collaboration in FL, we update the semantic anchors with these global prototypes using the EMA update as follows:\n$\\overline{A}^{t+1} = \\alpha \\overline{A}^{t} + (1 - \\alpha)P^{t}$ (10)\nwhere \u03b1 is a decay factor that controls the update rate. Similar to prototype-based FL methods, FedSA transmits only compact 1D-class semantic anchors, which naturally bring benefits for both privacy preservation and communication efficiency. Moreover, by integrating the anchor-based components and the EMA update, FedSA builds a positive feedback loop that iteratively encourages clients to collaboratively learn a unified data representation that exhibits intra-class compactness and inter-class separability."}, {"title": "Experiments", "content": "We consider image classification tasks and evaluate our method on three popular datasets, including Cifar10, Cifar100 (Deng et al. 2009), and Tiny-Imagenet (Chrabaszcz, Loshchilov, and Hutter 2017).\nTo evaluate our proposed method FedSA, we consider both statistical and model heterogeneous settings and compare it with popular methods including LG-FedAvg (Liang et al. 2020), FedGen (Zhu, Hong, and Zhou 2021), FML (Shen et al. 2020), FedKD (Wu et al. 2022), FedDistill (Jeong et al. 2018), FedProto (Tan et al. 2022b), and FedTGP (Zhang et al. 2024).\nLike previous studies (Li, He, and Song 2021; Li et al. 2022), we simulate statistical heterogeneity among clients by using Dirichlet distribution. Specifically, we first sample qc,i ~ Dir(\u03b2) for each class c and client i. We then allocate the proportion qc,i of data points from class c in the dataset to client i, where Dir(\u03b2) is the Dirichlet distribution with a concentration parameter B set to 0.1 by default. All clients use a 4-layer CNN (McMahan et al. 2017) for a homogeneous model setting.\nFollowing FedTGP (Zhang et al. 2024), we simulate model heterogeneity among clients by assigning different model architectures. Specifically, we denote this setting as \"HtFEx\", where FEx represents the X distinct feature extractors used. Each client i is assigned the (i mod X)th model architecture. For instance, the \"HtFE8\" setting includes eight architectures: 4-layer CNN, GoogleNet (Szegedy et al. 2015), MobileNet_v2 (Sandler et al. 2018), ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152 (He et al. 2016), used in our main experiments. To generate feature representations with an identical feature dimension K, an average pooling layer is added after each feature extractor, with K set to 512 by default.\nWe consider two widely used FL settings, the cross-silo setting and the cross-device setting (Kairouz et al. 2021). In the cross-silo setting, we set the total number of clients to 20 with a client participation ratio p"}, {"title": "Conclusion", "content": "In this paper, we propose a novel framework named FedSA, which introduces simple yet effective semantic anchors to decouple the generation of prototypes from local representation learning. By using these semantic anchors to serve as prototypes, we further propose RMCL and CC to correct local models, enabling them to learn consistent representations and decision boundaries. We then update the semantic anchors with global prototypes via an EMA update to facilitate FL collaboration, which iteratively encourages clients to learn a unified data representation. Extensive experiments and ablation studies under both statistical and model heterogeneity settings demonstrate the superiority of FedSA over prototype-based FL methods."}]}