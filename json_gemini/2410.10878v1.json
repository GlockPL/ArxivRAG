{"title": "HERALD: A NATURAL LANGUAGE ANNOTATED LEAN 4 DATASET", "authors": ["Guoxiong Gao", "Yutong Wang", "Jiedong Jiang", "Qi Gao", "Zihan Qin", "Tianyi Xu", "Bin Dong"], "abstract": "Verifiable formal languages like Lean have profoundly impacted mathematical reasoning, particularly through the use of large language models (LLMs) for automated reasoning. A significant challenge in training LLMs for these formal languages is the lack of parallel datasets that align natural language with formal language proofs. To address this challenge, this paper introduces a novel framework for translating the Mathlib4 corpus (a unified library of mathematics in formal language Lean 4) into natural language. Building upon this, we employ a dual augmentation strategy that combines tactic-based and informal-based approaches, leveraging the Lean-jixia system, a Lean 4 analyzer. We present the results of this pipeline on Mathlib4 as Herald (Hierarchy and Retrieval-based Translated Lean Dataset). We also propose the Herald Translator, which is fine-tuned on Herald. Herald translator achieves a 93.2% accuracy (Pass@128) on formalizing statements in the miniF2F-test and a 22.5% accuracy on our internal graduate-level textbook dataset, outperforming InternLM2-Math-Plus-7B (74.0% and 7.5%) and TheoremLlama (50.1% and 4.0%). Furthermore, we propose a section-level translation framework for real-world applications. As a direct application of Herald translator, we have successfully translated a template section in the Stack project, marking a notable progress in the automatic formalization of graduate-level mathematical literature. Our model, along with the datasets, will be open-sourced to the public soon.", "sections": [{"title": "1 INTRODUCTION", "content": "In modern mathematics, the increasing complexity of proofs has made peer review more difficult. Errors in proofs often go unnoticed for extended periods, as critical flaws are usually subtle and require expert scrutiny. As a solution, formal mathematical languages, also known as Interactive Theorem Provers (ITP), such as HOL Light (Harrison, 1996), Coq (Barras et al., 1999), Isabelle (Paulson, 1994), and Lean (Moura & Ullrich, 2021), allow for automated verification of proofs, reducing the risk of human oversight.\nHowever, writing proofs in these formal languages requires significant effort and expertise. Mathematicians must navigate through unfamiliar theorem libraries and often engage in repetitive tasks due to the strict requirements of formal languages, which can be burdensome for those accustomed to writing high-level, natural language proofs.\nThis highlights the importance of autoformalization, which seeks to translate natural language (NL) reasoning into formal language (FL), with the reverse process referred to as autoinformalization,"}, {"title": "2 RELATED WORK", "content": "Auto-formalization The field of auto-formalization has advanced notably with the integration of LLMs. Early efforts, like Wang et al. (2018), trained specialized neural models for statement auto-formalization. Recent studies, including Wu et al. (2022), Patel et al. (2023), and Zhou et al. (2024), employ LLMs with few-shot in-context learning, while Agrawal et al. (2022) introduces input-dependent few-shot learning. Additionally, Azerbayev et al. (2023) and Jiang et al. (2023a) fine-tune LLMs on natural language-formal language pairs to improve accuracy without in-context learning.\nExtending beyond statements, auto-formalization of proofs presents a more complex challenge. Jiang et al. (2023b) and Xin et al. (2024c) propose frameworks that use in-context learning to generate formal proof sketches from LLM-produced natural language proofs. These sketches are then complemented by auto-theorem-proving tools such as sledgehammer in Isabelle to fill in any gaps. Wang et al. (2024) and Shao et al. (2024) generate complete formal proofs with natural language"}, {"title": "3 METHODOLOGY", "content": "In this section, we outline our methodology for constructing and utilizing the Herald dataset to improve LLMs' ability to translate mathematical statements and proofs between NL and FL. Our approach centers around generating high-quality NL-FL pairs from Mathlib4 through providing LLM with sufficient structural information, followed by strategic augmentation techniques to address data scarcity and distribution imbalance. Section 3.1 explains the generation process of NL-FL data, while Sections 3.2 and 3.3 describe our augmentation strategies and the training of our statement formalization model on the Herald dataset. These steps collectively contribute to enhancing the autoformalization performance of LLMs within the Lean4 environment."}, {"title": "3.1 NL-FL DATA GENERATION", "content": "This subsection details the process behind creating the Herald dataset, a large-scale collection of NL-FL language pairs specifically designed to enhance the performance of LLMs in autoformalization. Using Mathlib4 as our source of formal statements and proofs, we apply a RAG approach to produce high-quality natural language translations. The Herald dataset consists of 580k NL-FL statement pairs and 45k NL-FL proof pairs, making it one of the largest resources for training models on translating between natural and formal mathematical languages. This section describes the detailed extraction and augmentation methodologies that were employed to construct this dataset."}, {"title": "3.1.1 STATEMENTS INFORMALIZATION", "content": "Structured Information and Contextual Augmentation The first step in our methodology involves extracting essential components from Lean code that encapsulate formal statements. We utilize Lean-Jixia, a static analysis tool specifically designed for Lean 4, to extract structured information from Mathlib4. Lean-Jixia parses Lean files to extract key metadata, including theorem declarations, proof structures, and dependency relationships. We select five main components to enhance the FL to NL translation process:\n\u2022 Head statements. These include foundational theorems, definitions, and other significant statements within the mathematical field relevant to the theorem. The extraction of head statements ensures that the context and background of the theorem are well-understood by the LLM.\n\u2022 Kind. The kind of statement, which can be a theorem, instance, definition, structure, class, inductive, class Inductive, or opaque, provides essential information about the nature of the statement. This classification aids the LLM in applying appropriate translation strategies tailored to the specific type of mathematical entity being processed. Different prompts are employed for translating different kinds of statements, adapting to the varying language habits of mathematical statements.\n\u2022 Docstrings often contain NL explanations written by humans, which are crucial for translating formal statements into more understandable language. The LLM is trained to leverage these docstrings effectively, ensuring that all relevant mathematical information is included while filtering out implementation notes that are not pertinent to the translation.\n\u2022 Neighbor statements in the Lean code, including those with similar names or located within the same namespace or file, are indicative of related theorems or definitions. By considering these neighbor statements, the LLM can better understand the interconnectedness of mathematical concepts and ensure that the translation reflects these relationships.\n\u2022 Dependent theorems. The inclusion of dependent theorems is crucial for maintaining the logical integrity of the translation. These theorems form the basis upon which the main theorem is built, and their inclusion ensures that the LLM can accurately reflect the proof's logical flow and dependencies.\nBy utilizing this information, LLM can better understand the FL statement and follow the principles of NL statements when it translates the FL statements into NL statements."}, {"title": "Dependency Level and Translation Order", "content": "We identify a critical issue where the lack of natural language translations for dependent definitions often led to incorrectly fabricated translations of these dependencies, thereby affecting the translation of the original theorem. To address this, we utilize Lean-Jixia to extract the dependency graph of all statements, forming a directed acyclic graph (DAG). We stratify all statements into levels based on their distance to the root nodes, which are statements not dependent on any others. Statements in each level only depend on those in lower levels. By translating statements in the level order, we ensure that the natural language translations of dependent theorems are available during the translation process, thereby providing missing dependent information that does not exist in the formal statements."}, {"title": "Retrieving Related Instances", "content": "Following previous work (Gao et al., 2024) on the semantic search engine of Mathlib4, we identified the theorem most similar to the one to be translated through 1,000 manually annotated examples. To elaborate, we represent the formal language of the manually annotated theorems as embeddings. The human-annotated theorem that is closest in distance to the theorem to be translated in this embedding space is then placed in the instruction set of the LLM, thereby enhancing the quality of translation."}, {"title": "Human Feedback Iteration", "content": "Human feedback is integral to refining and improving the translation process. We collect feedback from five human experts, all PhD students in pure mathematics with extensive expertise in Lean. These experts observe translation examples across various mathematical branches, identifying common issues in the natural language translations. They summarize these issues into principles and illustrative examples, which are then incorporated into the prompts used to guide the translation models. The iteration took place over six rounds of feedback and refinement, culminating in the development of over a dozen principles. By integrating these principles into the prompts, we ensure that the translations align with the precise and concise language habits of human mathematicians."}, {"title": "3.1.2 PROOFS INFORMALIZATION", "content": "In the previous section, we detailed the methodology for generating NL-FL statement pairs from Mathlib4. This section extends our approach to include the generation of NL-FL proof pairs, leveraging the same structure of principles and tools."}, {"title": "Stepwise Translation and Integration", "content": "The initial step in generating NL-FL proof pairs involves extracting proof line information using Lean-Jixia. Lean 4 supports two styles of proofs: tactic-based and term-based. A detailed comparison of these styles is provided in Appendix A. Term-based proofs, though concise, often present a series of formal theorems without a clear expression of logical reasoning. This makes them less effective in enhancing LLMs' inference capabilities during training, as they lack the logical chain that aids comprehension. Therefore, we focus on extracting and translating tactic-based proofs. We begin by translating each line of the formal proof into natural language. Once each line is translated, these individual translations are combined to form a complete informal proof.\nThis approach allows us to supplement the formal proof with extensive Lean information that would otherwise be missing, such as the proof state before and after each proof step. This additional context helps the LLM understand how each proof step contributes to the overall proof, thereby enhancing the model's comprehension and the accuracy of the NL translations."}, {"title": "Structured Information for Proof Translation", "content": "In addition to the structured information provided during the translation of statements, we further extract more detailed components for the translation of proofs. These components include:\n\u2022 Formal Statement. The formal statement being proved.\n\u2022 Informal Statement. The informal translation of the formal statement generated by LLM provides a natural language overview. This natural language translation is precisely the result generated as described in the previous section.\n\u2022 Tactic Information. Details about the tactics used, including their effect in proving the theorem and how they should be translated into natural language. This is provided for each proof step.\n\u2022 Proof States. Intermediate proof states presenting the current goal after using a tactic and how values of variables change by using the tactic, ensuring a comprehensive view of the proof's progression."}, {"title": "Tactic Explanation", "content": "A significant limitation of LLMs in translating mathematical proofs is their lack of understanding of the logical relationships between the proof steps and the goal. To address this issue, we employ human annotation to explain the logical structure inherent in each type of tactic. By adding these detailed explanations of the logical structure into the prompts, we significantly enhance the logical coherence of the natural language translations of mathematical proofs."}, {"title": "3.2 AUGMENTATION", "content": "When training models on NL-FL pairs in the context of Lean 4, two major challenges arise: Data Scarcity and Distribution Imbalance. The limited availability of NL-FL pairs leads to model over fitting, while the deformalization process often produces informal statements that deviate from the natural distribution found in textbooks, resulting in rigid, repetitive, or overly precise content that hinders generalization.\nTo address these challenges, we introduce 2 innovative augmentation techniques designed to both expand the dataset, and align it more closely with the real-world distribution of mathematical statements, proving to be highly effective in practice."}, {"title": "3.2.1 TACTIC-BASED AUGMENTATION", "content": "Natural language theorem proving presents a significant challenge due to the inherent complexity of proofs, where theorems are often established through the interplay of various lemmas, techniques, and proof strategies. Learning the \u2018global' properties of theorems from such complex proofs is difficult because the entire structure is often too intricate for direct modeling. However, we observe that during the proof process, each proof step often a tactic-addresses a smaller, localized 'statement', which is simpler and more easily understood in isolation. In fact, each such local statement is fully captured by the prove state (or tactic state) in Lean's interactive prover. Given this insight, we developed an augmentation strategy based on extracting prove states from Lean 4. Typically, the proof of theorem comprises of prove states or tactic states. For each prove state, which contains the conditions and the goal at that specific proof step, we construct a new formal language statement."}, {"title": "3.2.2 AUGMENTATION VIA MATHEMATICS-PRETRAINED LLM", "content": "Our second method (Figure 4) capitalizes on LLMs pre-trained on extensive mathematical corpora. To ensure that the augmented natural language statements maintain both semantic consistency and variability, we employ LLM pre-trained on extensive mathematical data. This allows us to generate multiple equivalent informal statements for each formal statement."}, {"title": "Omission of Implicit Condition", "content": "In natural language mathematical discourse, especially in textbooks and research papers, certain conditions are often omitted because they are considered obvious or conventionally understood by the reader.\nExample A theorem might not explicitly mention the requirement that a function be continuous if that is implied by the context."}, {"title": "Multi-linguistic Translation", "content": "We generate additional informal statements by translating the formal statements into Chinese, French and Russian. This results in a set of informal statements that represent how theorems might be articulated in a different linguistic context."}, {"title": "3.3 TRAINING STATEMENT FORMALIZING MODEL ON THE HERALD DATASET", "content": "After establishing the Herald dataset (Table 1), we then perform Supervised Fine-Tuning (SFT) on a pre-trained LLM using this combined dataset. Training on NL-FL datasets can enhance the LLM's ability to translate natural language mathematical propositions into Lean4 propositions. Mixing in an appropriate proportion of general natural language data can prevent potential overfitting phenomena and catastrophic forgetting. This balanced approach ensures that the model maintains its general language understanding while developing specialized skills in formal mathematical translation."}, {"title": "4 EXPERIMENTS", "content": "We conduct extensive experiments to evaluate the Herald dataset and translator. In Section 4.1, we test the Herald translator on three statement datasets from different topics and compare its performance with other formalization models. Section 4.2 assesses the quality of the Herald dataset through expert inspection, while in Section 4.3, we apply our autoformalization pipeline to a section of the Stack Project and analyze the results."}, {"title": "4.1 STATEMENT FORMALIZING MODEL", "content": "We selected DeepSeek-Prover-Base 7B as our base model due to its extensive training on formal programming languages like Lean, which provides a strong foundation for formal reasoning tasks.\nOur data preparation process involved several key steps to ensure a comprehensive and balanced dataset. We began by collecting 580k NL-FL pairs from the Herald dataset. From this, we created two datasets: one for translating informal to formal (NL\u2192FL) mathematical statements and another for the reverse direction (FL\u2192NL). This process yielded a total of 1.16M examples. The distribution of examples followed a 1:2:1 ratio among original statements, tactic-augmented data, and informal-augmented data. To further enhance model performance and mitigate overfitting or catastrophic forgetting, we combined our NL\u2192FL and FL\u2192NL datasets with the OpenHermes2.5 dataset (Teknium, 2023), a general-domain dataset. The final training data maintained a 2:2:1 ratio among NL\u2192FL, FL\u2192NL, and OpenHermes2.5 examples, respectively, for fine-tuning.\nOur fine-tuning process consisted of two stages: first, we conducted a 2000-step warm-up using the OpenHermes2.5 dataset, followed by training on the mixed dataset. We used a learning rate of 4e-5 with a cosine decay schedule across 5 training epochs."}, {"title": "4.1.2 VALIDATION PIPELINE", "content": "For validation, we adopt the pipeline from the LeanWorkbook project (Ying et al., 2024a), which includes several key steps:\n1. Translation: Using our trained model to translate informal statements from the test set into formal statements.\n2. Validation: Using a REPL (Read-Eval-Print Loop) based framework to verify that the translated Lean 4 statements are valid and pass compiler checks. This step ensures that our translations are syntactically correct in Lean4.\n3. Back-translation: For statements that pass the validation in step 2, we used InternLM2-Math-Plus-7B to translate the formal statements back to natural language to assess the preservation of meaning.\n4. Nli check: We use the DeepSeek Chat v2.5 model to compare the back-translated statements with the original informal statements, ensuring that our translations are mathematically accurate and preserve the intended meaning.\nWe perform 128 parallel translations and consider the translation successful if any of these passes both the compiler check and the nil check. Our results will be shown in the next subsection."}, {"title": "4.1.3 RESULT", "content": "To evaluate the performance of our model, we conducted comprehensive tests comparing Herald with several models in similar settings. Our test suite included a diverse range of datasets:\nminiF2F (Zheng et al., 2022) A widely-used benchmark dataset for formal mathematics.\nExtract Theorem A custom dataset compiled by extracting theorems from advanced undergraduate-level textbooks using OCR on scanned materials. It covers a wide range of mathematical topics and includes multilingual content.\nCollege CoT A curated dataset derived from digital mathematics resources across the internet, with content verified and filtered using a large language model (LLM) to ensure quality and relevance.\nThese datasets were carefully chosen to assess the models' capabilities across various levels of difficulty and categories of mathematics."}, {"title": "4.2 SUMMARY OF CASE STUDY IN HERALD QUALITY EXAMINATION", "content": "To assess the mathematical rigor and language style in the Herald dataset, we conducted several case studies. For a comprehensive result, see Appendix C.\nIn summary, the informal data in Herald demonstrates significant advantages in mathematical rigor and alignment with formal proofs. Lean-jixia extracts more complete Lean information (e.g., theorem names, variables), which aids in generating more precise theorem descriptions."}, {"title": "4.3 AUTOFORMALIZATION PRACTICE", "content": "To evaluate the performance of our Herald translator in real-world formalization tasks, we applied the proposed autoformalization pipeline (Figure 2.(b)) to a section of the Stacks Project, using DeepSeek Prover 1.5 (Xin et al., 2024b) as the prover. The Stacks Project (Stacks Project Authors, 2018) is an open-source, collaborative online encyclopedia focused on modern algebraic geometry and related fields, making it an ideal test case for complex formalization challenges.\nTo demonstrate the capabilities of the Herald translator in auto-formalizing modern mathematics, we selected the Normal Extensions section (Stacks Project Authors, 2018, Tag 09HL) from the Field Theory chapter of the Stacks Project. This section was successfully formalized into a runnable Lean 4 source file, showcasing the effectiveness of our pipeline. For more details on the Stacks Project, see Appendix B.1, and for the formalized output, refer to Appendix B.2.\nThe generation was completed efficiently using a 16-pass setting, with human checks revealing only two necessary theorem modifications: correcting the conclusion in two of the auto-formalized theorems, and removing an unnecessary condition in one of them. Notably, the model demonstrated strong understanding of the content, achieving both mathematical and programming correctness. For prover configuration, we use DeepSeek-Prover-V1.5-RL + RMaxTS with 4 \u00d7 512 sample budget), which successfully proved only one two-line theorem relying on an existing lemma from Mathlib4. This highlights the need for a more capable prover model to handle advanced topics, a key focus of our future work."}, {"title": "5 CONCLUSIONS", "content": "In this paper, we present Herald, a structural-information-aware pipeline for generating a rich NL-FL dataset from Lean projects, specifically Mathlib4. Our approach augments the traditional process by providing hierarchical, context-rich annotations, ensuring that dependencies are fully accounted for before translating target theorems. This methodology not only facilitates better natural language explanations but also breaks down complex formal proofs into more manageable components, improving the performance of LLMs in the formalization process.\nWe release the Herald dataset, which includes 580k valid statements and 44k NL-FL theorem pairs, providing a significant resource for formalization research. Additionally, we fine-tuned a statement formalizer on this dataset, which achieves state-of-the-art accuracy-93.2% on the miniF2F-test and 22.5% on a graduate-level textbook dataset-substantially outperforming existing baselines such as InternLM2-Math-Plus-7B and TheoremLlama. By applying our translator to a section of the Stack Project and leveraging the DeepSeek Prover V1.5, we further demonstrate the practical viability of our approach in auto-formalization.\nOur work contributes to the field in several ways: the development of a scalable NL-FL dataset generation process that incorporates hierarchical dependencies, the introduction of the Herald dataset, and the release of a high-performing translation model. These contributions mark a significant step toward automating formalization tasks at a project-wide scale, and we believe the methodologies and resources presented here will facilitate further advancements in the field of mathematical formalization and LLM-based theorem proving."}, {"title": "A INTRODUCTION TO FORMAL LANGUAGES", "content": "There are various approaches and tools of formalized mathematics. Among them, type-theory based theorem provers are prominent. They include Lean (Moura & Ullrich, 2021), Coq (Barras et al., 1999), Agda (Norell, 2009), Isabelle (Paulson, 1994), and many others.\nType-theory based provers utilize Curry-Howard Isomorphism, or the Proposition-as-Type paradigm (Wadler, 2015) to encode mathematical statements as types. In this paradigm, proofs for a statement $P$ are no different from a programmatic value of type $P$. The practice of writing mathematical proofs is thus unified with the practice of programming.\nInteractive theorem provers also have a distinct tactic mode, where the prover keeps track of currently available hypotheses and the goal to be proved. A set of concise, mid- to high-level commands called tactics can be used to manipulate the state. When all goals are solved, the proof is considered to be complete and the prover automatically generates the low-level code. The tactics are often designed to reflect common patterns in natural language proofs, making it easier for the users to write and understand proofs.\nThus, in tactic mode, the user simply writes a sequence of tactics to describe the steps (i.e., the tactic-based proof) required to prove the problem at hand, rather than manually writing down the detailed term-based proofs.\nLean 4 is an interactive, type-theory based prover. (Moura & Ullrich, 2021) Lean 4 is designed to be highly extensible via its metaprogramming capability, enabling Lean-Jixia to extract important metadata accurately and concisely.\nMathlib4 (mathlib Community, 2020) is a community-driven effort to build a unified library of mathematics in Lean 4. It has a substantial part of modern mathematics formalized. Hence it can act as a reliable source for LLMs to learn research-level mathematics.\nBelow is a comparison of the two styles:"}, {"title": "B GRADUATE TEXTBOOK AUTO-FORMALIZATION", "content": ""}, {"title": "B.1 THE STACKS PROJECT", "content": "The Stacks Project (Stacks Project Authors, 2018) is an open-source, collaborative online resource that aims to provide a comprehensive and rigorous treatment of algebraic geometry and related fields. Initiated by Johan de Jong, it has grown into a vast repository of mathematical knowledge, encompassing topics from commutative algebra to complex algebraic geometry. As of its latest update, the Stacks Project comprises over 7,609 pages of text and 21,319 tags of lemmas, theorems, and definitions, making it one of the most extensive and detailed resources in modern mathematics. By offering a freely accessible and continuously updated reference, the Stacks Project has become an invaluable tool for researchers, educators, and students, significantly advancing the accessibility and dissemination of modern mathematical ideas."}, {"title": "B.2 FORMALIZATION OF STACKS PROJECT SECTION NORMAL EXTENSIONS", "content": "import Mathlib\nopen Polynomial\n/-- Let $K / E / F$ be a tower of algebraic field extensions. If $K$ is normal over $F$, then $K$ is normal over $E$.-/ \ntheorem tower_top_of_normal (F E K: Type*) (Field F) (Field E]\n [Algebra F E]\n [Field K] (Algebra F K) [Algebra E K) [IsScalarTower F E K) (h: Normal F K] :\nNormal E K := by\n We use the fact that normality is equivalent to being a normal\n extension.\n have: h.out\n The above statement is a direct consequence of the transitivity of\n normality.\n exact Normal.tower_top_of_normal F E K\n/-- Let $F$ be a field. Let $M / F$ be an algebraic extension. Let $M /\nE_i / F$, $i \\in I$ be subextensions with $E_ i / F$ normal. Then $\\bigcap E_i$ is normal over $F$.-/ \ntheorem normal_iInf_of_normal_extracted {F M: Type*} (Field F) (Field\nM] [Algebra F M) {E : 1 \u2192 IntermediateField F M}\n[Algebra.IsAlgebraic F M] : ((1:1), Normal F \u2191 (Ei)) \u2192 Normal F \u2191\u03a0(\ni, Ei) := by sorry\n/-- Let $E / F$ be an algebraic field extension. Let $E / F$ be a\nnormal algebraic field extension. There exists a unique\nsubextension $E / E_{ ext {sep } } / F$ such that $E_{ ext {sep }} /\nF$ is separable and $E / E_{ ext {sep } } $ is purely inseparable.\nThe subextension $E / E_{ ext {sep } } / F$ is normal. -/\ntheorem normal_ext_sep_ext'_ext_tac_28642 (Field F) (Field E] [Algebra\nF E] [Algebra. IsAlgebraic F E) (h : Normal F E) (this: Algebra\n\u2191 (separableClosure F E) E) : Normal \u2191 (separableClosure F E) E := by\nsorry\n/-- Let $E / F$ be an algebraic extension of fields. Let $\\bar{F}$ be\nan algebraic closure of $F$. The following are equivalent\n(1) $E$ is normal over $F$, and\n(2) for every pair $\\sigma, \\sigma^{\\prime} \\in \\operatorname {Mor}_F(E,\n\\bar{F})$ we have $\\sigma(E)=\\sigma^{\\prime} (E) $. -/\ntheorem normal_iff_forall_map_eq_of_isAlgebraic_ext_ext {F E : Type*}\n[Field F]\n[Field E] [Algebra F E) (Algebra. IsAlgebraic F E) (overlineF: Type*]\n[Field overlineF]\n[Algebra F overlineF) (IsAlgClosure F overlineF] :\nNormal F E \u2194 \u2200 (\u03c3 \u03c3' : Ea [F] overlineF), Set.range \u2191 = Set.range \u03c3\nsorry\n:= by\n/-- Let $E / F$ be an algebraic extension of fields. If $E$ is\ngenerated by $\\alpha_i \\in E, i \\in I$ over $F$ and if for each $i$\nthe minimal polynomial of $\\alpha_i$ over $F$ splits completely in $\nE$, then $E / F$ is normal. -/"}, {"title": "The Normal Extensions section", "content": "is presented as a runnable Lean 4 source file, generated theorem by theorem and concatenated into a complete formalization. For opened namespaces, we manually selected a minimal feasible subset from the union of namespaces across all theorems. The generation was completed efficiently using a 16-pass setting. The faithfulness was checked by humans, and only two places were modified. Specifically, the conclusion theorem extends_to_aut_of_normal_tac_7047 was corrected from \u2200 (z : \u2191M), \u03c3z\u2208\u00ceM to \u2203 s : E \u2243a[F] E, \u2200 (z : M), SZ = \u03c3z, and the conclusion of embeddings_aut_eq_of_isAlgNormal_tac_12245 was corrected from Algebra.IsAlgebraic F Gto f: Ga [F] H, \u2203 s : G\u2243a [F] G, f = eos and an unnecessary condition [FiniteDimensional F G] was removed. Notably, the model demonstrates a strong understanding of the content, achieving both mathematical and programming correctness.\nFor prover integration, we used DeepSeek Prover 1.5 (using DeepSeek-Prover-V1.5-RL + RMaxTS with 4 x 512 sample budget) to run inference on the generated file. Only one theorem, a two-line proof relying on an existing lemma from Mathlib 4, was successfully proved. In our broader experiments with the Stacks Project, we observed that the prover struggles with longer or more complex proofs, showing instability and reduced capability. While our translator model performs well, this highlights the need for a prover model capable of handling advanced topics in modern mathematics, which will be a key focus of our future work."}, {"title": "C CASE STUDY", "content": "In this section, we will conduct a comparative analysis of the Open Bootstrapped Theorems (OBT) dataset in Wang et al. (2024) and our Herald dataset. By examining multiple representative examples from both datasets, we aim to exhibit the differences arising from how each handles the alignment of natural language and formal language. Through this examination, we seek to highlight the unique contributions of Herald while also identifying areas where further improvement may be necessary.\nPlease note that in the Herald dataset, the stepwise natural language proof is generated first and then summarized into a natural language whole proof. In contrast, in the OBT dataset, the informal statement and proof are first created, which are subsequently distributed into inline comments to form"}, {"title": "EXAMPLES OF STATEMENTS", "content": "In this section, we examine examples of statements, each containing five components: the formal name, Herald formal statement, Herald informal statement, OBT formal statement, and OBT informal statement. Following these data, a comparison analysis is presented. Please note that the OBT informal statement is cut out from the generated informal statement and proof."}, {"title": "STATEMENT EXAMPLE 1", "content": "FORMAL NAME\ndite_eq_or_eq\nHERALD FORMAL STATEMENT\n$\\forall{a: Sort u_1} (P : Prop) (inst : Decidable P) {A : P \\to a} {B : \\neg P \\to a},$\n$( \\exists h, dite P A B = A h) \\lor \\exists h, dite P A B = B h$\nHERALD INFORMAL STATEMENT\nDependent If-Then-Else Equals One of the Branches: For any type a, any proposition P, and any decidable instance of P, if $A : P \\to a$ and $B : \\neg P \\to a$ are functions, then the dependent if-then-else construct`dite P A B` is equal to either A(h) for some proof h of P, or B(h) for some proof h of P. In other words, the value of `dite P A B` is either the value of A when P is true, or the value of B when P is false.\nOBT FORMAL STATEMENT\ntheorem dite_eq_or_eq : (\\exists h, dite P A B = A h) \\lor \\exists h, dite P A B = B h := \nOBT INFORMAL STATEMENT\nFor any propositions `P`, `A`, and `B`, the value of 'dite P A B is either `A` or `B`. Prove this by cases. Show that either there exists an `h` such that dite P A B = A h or there exists an `h` such that dite P A B = B h.\nANALYSIS\ndite is a shorthand for 'dependent if-then-else' in Lean. It is unreasonable to expect the LLM to accurately interpret dite without referring to its definition. In the OBT dataset, dite is treated as a black box without any explanation. In contrast, the Herald dataset correctly expands the meaning of dite with the aid of dependency information. This further enables the LLM to recognize that h is a proof of P and translate '\u2203h,' into 'when P is true,' which aligns more closely with natural language."}, {"title": "STATEMENT EXAMPLE 2", "content": "FORMAL NAME\nCongruenceSubgroup.Gamma_zero_bot\nHERALD FORMAL STATEMENT\nCongruenceSubgroup.Gamma 0 = 1\nHERALD INFORMAL STATEMENT\nThe full level 0 congruence subgroup of SL(2, Z), denoted by \u0393(0), is equal to the trivial subgroup, i.\u0435., \u0413(0) = {1}.\nOBT FORMAL STATEMENT\ntheorem Gamma_zero_bot : Gamma 0 = 1\nOBT INFORMAL STATEMENT\nGiven the group homomorphism Gamma : Z \u2192 Mat 2 \u00d7 2Z, where\nshow that F(0) = bot.\nANALYSIS\nThis theorem is about the definition of the congruence subgroup \u0393(n) \u2286 SL2(Z), stating that \u0393(0) is the trivial subgroup. In the OBT dataset, this theorem is extracted under the formal name Gamma_zero_bot. Using Lean-jixia, the Herald dataset extracts the theorem with its full name. Additionally, note the difference between Gamma in the formal statement of the OBT dataset and CongruenceSubgroup.Gamma in the formal statement of Herald. These distinctions aid the LLM in correctly deducing that Gamma refers to the congruence subgroup. Please note that in the original OBT data, the LATEX formula is Gamma : Z \u2192 Mat 2 \u00d7 2Z instead of \u0393 : Z \u2192 Mat2\u00d72(Z)."}, {"title": "STATEMENT EXAMPLE 3", "content": "FORMAL NAME\nSet.preimage"}]}