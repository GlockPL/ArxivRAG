{"title": "Capturing the security expert knowledge in feature selection for\nweb application attack detection", "authors": ["Amanda Riverol", "Rodrigo Mart\u00ednez", "Gustavo Betarte", "\u00c1lvaro Pardo"], "abstract": "This article puts forward the use of mutual information values to\nreplicate the expertise of security professionals in selecting features\nfor detecting web attacks. The goal is to enhance the effectiveness of\nweb application firewalls (WAFs). Web applications are frequently\nvulnerable to various security threats, making WAFs essential for\ntheir protection. WAFs analyze HTTP traffic using rule-based ap-\nproaches to identify known attack patterns and to detect and block\npotential malicious requests. However, a major challenge is the\noccurrence of false positives, which can lead to blocking legiti-\nmate traffic and impact the normal functioning of the application.\nThe problem is addressed as an approach that combines super-\nvised learning for feature selection with a semi-supervised learning\nscenario for training a One-Class SVM model. The experimental\nfindings show that the model trained with features selected by the\nproposed algorithm outperformed the expert-based selection ap-\nproach in terms of performance. Additionally, the results obtained\nby the traditional rule-based WAF ModSecurity, configured with a\nvanilla set of OWASP CRS rules, were also improved.", "sections": [{"title": "1 Introduction", "content": "A web application operates within a client-server architecture,\nwhere the server handles computational tasks like data transmis-\nsion, processing, and storage, while the client interacts via a web\nbrowser. These applications face significant security risks [31]. Vul-\nnerabilities, spanning from design through implementation and\nconfiguration, pose threats to data integrity, confidentiality, and\navailability.\nTo address these concerns, the Open Web Application Security\nProject (OWASP) [28] maintains the OWASP Top Ten, listing the\nmost critical security risks to web applications. Web Application\nFirewalls (WAFs), as defined by Ghanbari [14], act as security check-\npoints, analyzing and blocking HTTP traffic to identify potential\nmalicious requests. ModSecurity, a widely used open-source WAF,\nrelies on the Core Rule Set (CRS) compiled by OWASP to detect\nknown attack patterns. The CRS, recognized as a standard in the\nindustry, includes rules crafted by experts to detect variants of\nattacks with different levels of severity [25].\nWAF solutions like ModSecurity assess HTTP requests by com-\nputing an overall score based on activated rules. However, false\npositives remain a challenge, potentially disrupting legitimate traf-\nfic and normal application functions. Addressing this issue involves\nconfiguring the CRS, a task that can be complex for non-security\nprofessionals. Recent research [7, 22, 26] indicates that machine\nlearning models can enhance attack detection, often outperforming\ntraditional methods such as rule-based static analysis and signature-\nbased attack patterns without requiring extensive security expertise\n[26].\nThe biggest problem when trying to differentiate valid from\nanomalous requests is their similarity. Consider the following ex-\nample: distinguishing between a valid request (Figure 1) and an\nattack request, such as a SQL injection attempt (Figure 2). While\nboth requests may initially appear similar in terms of standard\nHTTP headers and parameters, the fundamental distinction lies in\nspecific tokens within the query. For example, the presence of the\ntoken OR '1'='1' in a SQL injection request (Figure 2) denotes an\nattempt to bypass authentication by injecting malicious SQL code,\na clear indicator of an attack. In contrast, valid request typically do\nnot feature these types of constructions."}, {"title": "2 Background", "content": "Below is a brief overview of web applications and their security\nissues. We will examine attack detection models in web applications\nfor protection and the issues and limitations they face in terms of\ngeneralization and adaptability. Additionally, we will delve into\nvarious learning techniques used in anomaly detection to gain\na better understanding of their effectiveness and applicability in\nweb security environments. This analysis will form the basis for\nexploring the techniques used in the later stages of the research."}, {"title": "2.1 Web Applications and Vulnerabilities", "content": "Web applications are fundamental in our lives, used in organizations\nand daily activities, handling large amounts of data and personal\ninformation. This type of information is crucial for the internal func-\ntioning of organizations and is of interest to third parties and even\ngovernments. However, accessing this information often comes at a\nhigh cost, leading some individuals to resort to illegal means, such\nas attacks on web applications, to obtain the desired information.\nThese attacks can have various intentions, from extortion, fraud,\nand identity theft to manipulating the web application's reputation.\nThe lack of security in web applications constantly exposes them\nto risks as attackers exploit vulnerabilities in their infrastructure.\nOne of the leading causes is the absence of security properties, such\nas logical correctness, input validity, state integrity, or adequate\nsecurity configuration. For example, the lack of input validation\nand sanitization can introduce untrusted special characters, leading\nto common attacks like SQL injection, cross-site scripting (XSS)\nvulnerabilities, and cross-site request forgery (CSRF) attacks. This\ntopic is addressed in a survey conducted on [10], which provides a\nstate-of-the-art web application security analysis focusing on the\nchallenges of creating secure web applications. This study high-\nlights the importance of addressing existing security vulnerabilities\nto ensure adequate protection of web applications.\nTherefore, it is essential to implement effective security measures,\nsuch as proper input validation and data sanitization, along with the\nuse of tools like Web Application Firewalls (WAFs), which, as pre-\nviously mentioned, act as a security checkpoint between users and\nthe web application. Traditional WAFs use rule-based approaches\nto identify known attack patterns. However, these systems have\nsignificant limitations, especially against zero-day attacks, where\nexisting rules cannot recognize new threats. Moreover, configuring\nand maintaining these systems can be complex and prone to errors,"}, {"title": "2.2 Automated learning for improving WAF\nperformance", "content": "Recent research [7, 23, 26] indicates that the detection of attacks us-\ning machine learning models reduces false positives when compared\nwith the detection performed by the ModSecurity WAF configured\nwith the CRS as a baseline. The model discussed in [26] overcomes\nthese results without requiring extensive security experience using\na one-class approach combined with an automatic estimation of\nthe best operational point.\nTo build a machine learning model for attack detection, there\nare two alternatives. The multiclass approach assumes that you\nhave valid and attack requests for the application. We have imple-\nmented this approach using several classifiers for attack detection\nand including a preprocessing stage that uses knowledge of the\nHTTP structure to improve feature extraction [6, 23]. Our experi-\nments have validated the effectiveness of this approach. However,\naccording to our extensive study, training the model with generic\ndata sets and testing it with application-specific data, has revealed\nthat classifiers built this way do not generalize well. This means\nthat a model trained for one application cannot be directly applied\nto protect a different one.\nIn situations where there are only available requests that belong\nto the valid or attack class, we have explored a one-class classi-\nfication approach. This approach is discussed in [26] in which\nrequests are analyzed by counting the occurrence of specific at-\ntributes. These attributes, which best define the different attacks\non web applications, were determined with the input of a security\nexpert. A key aspect of this approach is the threshold that adjusts\nthe classification into valid or attack. Each potential threshold value\nrepresents an operating point of the model, allowing the expert to\nmodify the attack detection or false positive rate simply by altering\nthis value.\nRegarding the one-class approach model, we have been exploring\nalternatives to automatically select the optimal operating point\nusing sampling or synthetic attacks. We have experimented with\nalgorithms of a class like SVM and deep learning techniques to\nextract the features. The first results of this line of work have been\npresented in [26].\nThe article [15] delves into advances in anomaly detection us-\ning natural language processing techniques. It underlines the need\nfor an improved tokenizer capable of handling tokens beyond the\nstandard vocabulary, crucial for detecting emerging attack patterns.\nWhile most data sets showed consistent results, there was a notable\ndecrease in the performance of the RoBERTa model, highlighting"}, {"title": "2.3 Preprocessing and Tokenization", "content": "In the anomaly detection process, each stage can vary depending\non the specific approach applied, and errors or deficiencies in any of\nthese stages can significantly affect the performance of the resulting\nmodels [32].\nThe tokenization stage is what allows a text to be divided into\nsmaller parts called tokens. These tokens are later used to find\npatterns and are considered a basic step in stemming. Tokenization\nalso helps replace sensitive data elements with non-sensitive data\nelements.\nBelow we will explore the most common techniques used for\nrepresentating or vectorizing of these tokens, which serve as input\nfor machine learning models.\nThen, we will emphasize the next stage of feature selection and\nits contribution to anomaly detection. We focus our work with the\nhypothesis that the tokens selected in this stage influence the final\nresults of the methods."}, {"title": "2.3.1 Vectorization methods", "content": "Vectorization methods are techniques\nused to convert textual or categorical data into a numerical rep-\nresentation that machine learning models can process. Below are\nsome of the most common vectorization methods used in machine\nlearning-based WAF implementations:\nBoW. BoW (Bag-of-words) is a simple model that represents\na document using the frequency of words (every position in the\nvector corresponds to a word) or, in our example, tokens obtained\nfrom the tokenization stage. The vector size is limited by using\nonly the most common tokens. Ren et al. [29] demonstrate the\neffectiveness of BoW in extracting features for web attack detection\nusing hidden Markov algorithms. Their research shows improved\ndetection rates and reduced false positives compared to previous\nexperiments utilizing N-grams. Mathematically, the vectorization\nusing BoW can be expressed as:\n$Xi = [Xi1, Xi2, ..., XiM]$\nwhere\n$xij = count(wj, di)$\nHere, $count(wj, di)$ denotes the number of occurrences of the word\n$wj$ in the document $di$.\nThe Bag-of-Words (BoW) model simplifies text analysis by rep-\nresenting documents as word frequency vectors. It's versatile, in-\nterpretable, and efficient for various Natural Language Processing\n(NLP) tasks. However, it loses context, creates high-dimensional\nfeatue vectors, suffers from sparsity, and lacks semantic understand-\ning.\nTF-IDF: (Term Frequency-Inverse Document Frequency) stands\nas another common technique for feature extraction in cyber threat\ndetection. Unlike BoW, TF-IDF counts the frequency of occurrence"}, {"title": "2.4 Feature Selection", "content": "Feature selection, as a dimensionality reduction technique, aims\nto choose a small subset of relevant features from the original fea tures by removing irrelevant, redundant, or noisy features. Feature\nselection can lead to higher learning performance, lower computa tional cost, and better model interpretability. Recently, researchers\nin computer vision, text mining, etc., have proposed a variety of\nfeature selection algorithms and shown the effectiveness of their\nworks in terms of theory and experiment.\nIn a review of the state of the art on these techniques [24], a\ncomprehensive experiment is conducted to test whether feature\nselection can improve learning performance by showing that fea ture selection benefits machine learning tasks. Feature selection\nmethods are usually classified into three main types: filter, envelope,\nand embedded.\n\u2022 Filter methods evaluate features independently of the learn ing model, using statistical measures such as Pearson corre lation, Linear Discriminant Analysis (LDA), ANOVA, Chi square test, Wilcoxon Mann Whitney test, and Mutual In Formation. Mutual Information measures the dependency\nbetween two variables and selects features with the highest\ndependency on the target variable [11]. These techniques\nreduce dimensionality by selecting features based on their\nrelationship with the response variable before applying any\nlearning algorithm.\n\u2022 Wrapper methods consider the interaction between fea tures and the learning algorithm. These methods evaluate\nsubsets of features by building and assessing a model. Al though potentially more accurate, wrapper methods are com putationally intensive. Examples include Recursive Feature\nElimination (RFE) [16] and forward selection algorithms\n[17].\n\u2022 Embedded Methods perform feature selection during the model training process. Examples include decision trees [8]\nand regularization methods like Lasso [33], which penalize model complexity by including only significant features.\nAmong the various feature selection methods available, we have\nspecifically chosen mutual information because it can measure\nthe dependence between features and the target variable (class).\nMutual information is a powerful statistical measure that evaluates\nthe relevance of features based on their relationship with the target\nvariable before applying any learning algorithm.\nEntropy and Mutual Information: Mutual information is\nan effective statistical tool for performing feature selection using\nfiltering methods [5]. In this context we will introduce entropy and\nmutual information.\nThe entropy $H(X)$ of a random variable $X$, with probability\ndensity function $p$, measures uncertainty:\n$H(X) := Ex [\u2212 log p(X)] = \u2212\\int p(x) log p(x) dx.$\nThe integral calculates the expected value of the quantity \u2212 log $p(x)$,\nwhich represents the \"self-information\" associated with each value\nof $X$. The result is the mean information of $X$, or in other words, a\nglobal measure of the uncertainty in $X$."}, {"title": "3 Feature Selection using Mutual Information", "content": "In previous studies [23], supervised machine learning models\nwere implemented that required the intervention of a security ex- pert to select features relevant to attack detection. Although these\nstudies demonstrated good results, the need for a labeled set of valid\ntraffic and attacks makes their application in real environments\ndifficult. As an alternative, a supervised model of one class [26]\nwas implemented that combined RoBERTa as a feature extractor\nand One-Class SVM. This approach managed to reduce false posi-\ntives and demonstrated good performance, as well as eliminating\nthe dependency on application-specific attack sets and the need\nfor experts for feature selection. However, once trained cannot\nbe reused in other applications and the training stage has a high\ncomputational cost.\nThe implementation we present in this section proposes to train\na semi-supervised model of a One-Class SVM using Bag of Words\nas an extraction method, and incorporate a feature selection stage\nbased on mutual information values.\nTo allow mutual information to capture distinctive features\npresent in attacks, distinguishing between a valid request and an\nattack, we use a dataset with several types of attacks. This data\nset is intended to increase the likelihood that the algorithm will\nvalue tokens associated with attacks and not just limit itself to\ntokens present in valid requests. The objective is to demonstrate\nthat these attacks do not necessarily have to be specific to the ap- plication; they can be generic or evolve over time, incorporating\nattacks from various applications, and still yield good results. This\napproach is feasible because constructing this dataset is more prac- tical than obtaining specifically labeled attacks for the application\nbeing protected."}, {"title": "3.1 Datasets", "content": "To implement our proposed methodology for feature selection in\nweb attack detection, we have developed a dataset of diverse types\nof attack. Additionally, to complement this attack dataset, it is\nnecessary to generate a set of normal requests from the target\napplication. These requests will represent the typical traffic that the\napplication experiences during legitimate use. The inclusion of this\nnormal data is crucial as it provides a clear contrast with attacks,\nenabling the model to distinguish between benign behaviors and\nsuspicious activities.\nOur proposed methodology relies on the combination of these\ntwo datasets: the diverse attack dataset and the set of normal appli- cation requests. By utilizing both datasets, we can select features\nrelevant to both attacks and normal application operations."}, {"title": "3.1.1 Attack Datasets", "content": "Creating a dataset of attacks for a specific\napplication is a complex process involving the collection and la- beling of representative data from various types of web attacks.\nSamples of network traffic containing malicious activities are se- lected for this purpose. This dataset should include a wide variety\nof attacks such as SQL injections, cross-site scripting (XSS) and\nCommand Injection. Proper construction of this dataset requires\nthe involvement of cybersecurity experts to accurately label the\ndata, ensuring each instance is correctly classified.\nAdding complexity to the process, it is essential that the dis- tribution of attacks in the dataset is balanced to ensure detection\nmodels are not biased towards a specific type of attack. A proper\nrepresentation of each type of attack is crucial for generalizing the\nmodel to real-world scenarios.\nThe goal of constructing a generic attack dataset lies in the\nneed for a dataset that can be used in feature selection processes,\nregardless of the specific application, combined with valid traffic\nfrom the application itself. The advantages of a generic dataset\ninclude its applicability across multiple contexts and the ability to\ncompare different detection methods under similar conditions."}, {"title": "3.1.2 Classification and Distribution of Attacks", "content": "The construction\nof the attack dataset used attacks present in the SR-BH 2020 [30]\ndatasets, which include a wide variety of attacks classified as seen\nin the Figure 3."}, {"title": "3.2 Preprocessing Stage", "content": "This stage is aimed to enhance the quality and coherence of data,\nwhich is crucial for the performance of anomaly detection models.\nThe following steps were applied:\n(1) Header filters: Applied to control which information is included in HTTP headers during analysis. This helps elim- inate redundant or noisy data, improving the relevance of the analyzed information.\n(2) urlDecode: Next, decoding the input to prevent it from being URL-encoded (e.g., converting \"%20\" to blank spaces) to handle data from URLs. This ensures that information is correctly interpreted and prevents errors due to malformed data.\n(3) decode('utf-8'): Then, converting UTF-8 encoded byte se- quences into Unicode strings. This is crucial for handling data containing special or international characters, ensuring subsequent analysis can properly process this data.\n(4) urlDecode (second time): Similar to step 2, decoding the input again in URL format to correctly interpret it and avoid misinterpretation or malicious data manipulation errors from URLs. Attackers often use double encoding to mask attacks in the URL.\n(5) lowercase: Finally, converting all input characters to lower- case to normalize the data. This facilitates comparison and feature search regardless of whether characters are upper- case or lowercase, helping to avoid case sensitivity issues.\nThese steps adequately prepare the data for subsequent analysis stages, improving the accuracy and efficiency of anomaly detection models in web applications."}, {"title": "3.3 Dictionary Creation", "content": "The algorithm for constructing a dictionary of terms, described in\nAlgorithm 1, uses CountVectorizer to create a set of tokens from\ngeneric attack datasets and valid application datasets. The process\nis divided into three main steps: data preprocessing, tokenization,\nand dictionary construction."}, {"title": "3.4 Applying Mutual Information", "content": "Mutual Information is a measure used in data analysis to assess\nthe dependence between two random variables. It helps in select- ing relevant features. In the context of web attack detection, it is\nused to identify which features or tokens are more informative in\ndifferentiating between normal requests and potentially malicious\nones."}, {"title": "Algorithm 2 Mutual Information with TF-IDF Vectorization", "content": "Require: Dataset D, Set of web requests $R = {1, 2, ..., rn}$\nEnsure: Set of tokens ordered by mutual information value T\n1: DIC\u2190 dictionary initialization {DIC = {$f1, f2, ..., fn $}}\n2: X\u2190 D-target\n3: Y\u2190 Dtarget { Y is target vector {$ti$}}\n4: TFIDF \u2190 Tfidf Vectorizer(vocabulary=DIC)\n5: Xtfidf \u2190 TFIDF.fit_transform(X) { where Xtfidf is the fea-\nture matrix {$r\u00a1 \u00d7 fi$}, applying TF-IDF vectorization to all re-\nquests in R}\n6: ICM \u2190 mutual_info_classif(Xtfidf, Y)\n7: for fi \u2208 DIC do\n8: Fi\u2190 (fi, ICMi)\n9: end for\n10: F sorted(F)\n11: return F\nThe feature selection process, described in Algorithm 2, utilizes\nthe set of valid web requests from the application and the set of\nattacks defined in Subsection 3.1.1. The union of these sets is defined\nas R = {1,2,..., n}.The dictionary is then constructed using\nAlgorithm 1. Subsequently, all requests are vectorized using TF-IDF,\ngenerating the matrix Xtfidf. Mutual information values between\neach feature and the target are calculated for each feature in the\ndictionary, using Xtfidf and the set of labels Y. Finally, the ordered\nset of feature, based on mutual information, F is returned.\nOnce the characteristics are ordered according to the correspond- ing mutual information value, Algorithm 3 is applied, which uses a\nbag-of-words model that tokenizes each request ri in a sequence\nri = {$tokeni1,..., tokenin\u2081 $}, where ni denotes the number of to- kens selected in the request. These representations transform the\nset of normal HTTP requests into input vectors for use in the one- class classification (OCC) model using a one-class support vector\nmachine (OCSVM). This approach assumes a scenario where only\nvalid requests are available, without the need for labeled attack\nsamples. The OCSVM is trained using these representations, with\nthe goal of distinguishing normal traffic from possible anomalies.\nBy mapping data to the feature space defined by the kernel, OCSVM\nidentifies inliers (normal requests) and outliers (potential attacks)\nbased on their distance from a separating hyperplane.\nThe optimal operational threshold @ is determined using a grid\nsearch approach, varying @ across a range and evaluating its impact\non the Receiver Operating Characteristic (ROC) curve to achieve\noptimal performance metrics. Specifically, parameter optimization\ninvolves selecting v and y, where y defines the kernel's frontier\nand v represents the probability of encountering a new, but normal,\nobservation outside this frontier. The grid search method employs a\nmodified performance metric F, akin to the F1-score, derived from\nnormal and unlabeled examples, to determine the best parameters\nv = 0.05 and y = 0.5 for the OCSVM classifier, ensuring robust\nanomaly detection in web application security contexts [26]."}, {"title": "Algorithm 3 Anomaly Detection with BoW and One-Class SVM", "content": "1: Input: Set of normal HTTP requests $D = {1, 2,...,rm}$\n2: Output: One-Class SVM Model model\n3: Step 1: Preprocessing\n4: for each request $ri \u2208 D$ do\n5: Apply header filters, URL decoding, and Unicode conversion to $ri$\n6: Convert $ri$ to lowercase\n7: end for\n8: Step 2: Feature Selection and Tokenization\n9: Select N relevant tokens T based on Algorithm 2\n10: Tokenize $ri$ into tokens $ri$ = {tokeni1, ..., tokenin}\n11: Step 3: Vectorization using Bag of Words (BoW)\n12: Create BoW representations for each request:\n13: for each request $ri \u2208 D$ do\n14: Construct a BoW vector $vi$ using selected tokens T\n15: end for\n16: Step 4: One-Class SVM Training\n17: Train One-Class SVM model using BoW vectors {$V1,..., vm$}\n18: Step 5: Parameter Optimization\n19: Perform grid search to optimize parameters v and y for the\nOCSVM model\n20: Output: Trained One-Class SVM Model model"}, {"title": "4 Discussion", "content": "This section discusses the outcomes of our experiment, which\nwas designed to assess the effectiveness of the proposed feature\nselection algorithm in identifying web attacks.\nAs an initial stage of the experiment, we combined:\n(1) Valid data from the Drupal application with the set of varied\nattacks (in this case built with SR-BH 2020)\n(2) Valid data from the SR-BH 2020 application with the set of\nvaried attacks (in this case built using PKDD)\nUsing Algorithm 2, feature sets of sizes 50, 100, 150, and 200\nwere selected to evaluate the effectiveness of training the model\nwith different dimensions. The experiment was conducted on both\nsets to assess the adaptability of the approach to different attack\nscenarios and traffic types."}, {"title": "5 Related Work", "content": "The research discussed in [7, 23] uses machine learning and\npattern recognition methodologies to address false positives. The\nstudy presents four different approaches to detect web application\nattacks in various scenarios. It employs the Bag-of-Words model for\nfeature extraction, and feature selection is carried out by experts.\nThe study further evaluates the performance of several supervised\nclassification models in comparison to each other and a reference\nModSecurity web application firewall (WAF).\nThe application of deep learning techniques for the detection and\nprevention of attacks on web applications is explored in the study\nreported in [26]. Unlike prior research, this work frames the prob- lem as a supervised classification task and employs a pre-trained\nROBERTa model to the dataset. This pre-trained model is utilized\nto extract features from HTTP requests, which are subsequently\nemployed to train a one-class classifier.\nWhile the approaches presented in [7, 23, 26] have shown promis- ing results in terms of TPR/FPR, they both also have weaknesses.\nThe approach in [7, 23] is distinguished by its computational effi- ciency and TPR/FPR rate, although it has limitations such as the\nneed for labeled data to train the model and a security expert to\ndefine the set of features to be used. On the other hand, the method\npresented in [26] has slightly better results without requiring the in- tervention of a security expert considering contextual information.\nHowever, this approach has the limitation of requiring training\nthe ROBERTa model for each dataset, which is computationally\nexpensive, and classification time increases significantly.\nThese limitations give rise to two distinct challenges. The first\nchallenge is to devise a pipeline design that makes use of RoBERTa\nand enables the utilization of a RoBERTa model trained on one\ndataset for a different one. One potential solution could involve\nreducing dimensionality and disregarding certain context features,\ninstead focusing solely on the important ones. However, this gives\nrise to the second challenge, which also existed in more traditional\napproaches: the necessity for an expert to select relevant features.\nIn the work [21], SHAP is analyzed as a feature selection mech- anism. SHAP is a model-agnostic approach that assigns feature\nimportance based on their contribution to the model's outcome.\nThe proposal uses these contributions to rank features according\nto their importance as a feature selection strategy, demonstrating\nsuperiority over other more common mechanisms.\nThe comparative study conducted in [4] compares mutual infor- mation with sensitivity analysis (DSA) for feature selection in a\nbanking telemarketing data set concluding that mutual information\nefficiently identifies relevant features, which reduces the redun- dancy and enables faster and more accurate customer subscription modeling. It highlights the model's ability to handle large data sets by quickly evaluating the information content. It establishes that despite MI's older methodology, it competes favorably with newer approaches in this case DSA proving to be effective and making it a solid choice for applications that prioritize prediction accuracy over computational complexity.\nThe work presented in [3] investigates the use of feature selection\ntechniques to improve the detection of distributed denial of service\n(DDoS) attacks employing machine learning algorithms. Features\nare selected from the UNSW-NB 15 dataset [27] using methods such\nas information gain and data reduction. Then, the selected features\nare classified using Artificial Neural Network (ANN), Na\u00efve Bayes\nand Decision Table algorithms. Comparative analysis with previous studies using the same data set confirms the effectiveness of the feature selection approach, demonstrating higher accuracy of the classifier in detecting DDoS attacks."}, {"title": "6 Conclusion and Further Work", "content": "We have presented a method for training and evaluating an anom- aly detection model using One-Class SVM. The approach involves\nusing feature selection based on mutual information. The results\nindicate that a 100-dimensional feature set achieved the best bal- ance between true positive rate (TPR) and false positive rate (FPR),\noutperforming the expert-assisted method. This demonstrates the\neffectiveness of feature selection based on mutual information in\nidentifying the most relevant features and improving model perfor- mance. Even though the expert-assisted method achieved higher\naccuracy, it had a lower true positive rate, highlighting the impor- tance of automated approaches in feature selection.\nFor future research, we aim to investigate feature selection using\nwrapper-based methods, such as Recursive Feature Elimination\n(RFE) and forward selection algorithms [9]. As observed in the\nsecond experiment of the preceding section 4, these methods may\npositively impact performance by considering feature interactions\nwith the learning algorithm, leading to more precise and tailored\nmodel selection. Although more computationally intensive, they\ncan yield significant improvements in model performance compared\nto the current mutual information-based approach.\nThe tokenizer used in this research is a general natural language\ntokenizer. In future work, we intend to create a tokenizer tailored for\nthe HTTP language, which will consider the context and structure\nof the language, potentially resulting in enhanced accuracy. This\nspecialized tokenizer would more effectively capture the syntactic\nand semantic relationships between request features, consequently\nhelping to improve the overall effectiveness of anomaly detection\nsystems in web security."}]}