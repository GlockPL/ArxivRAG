{"title": "TabDeco: A Comprehensive Contrastive Framework for Decoupled Representations in Tabular Data", "authors": ["Suiyao Chen", "Jing Wu", "Yunxiao Wang", "Cheng Ji", "Tianpei Xie", "Daniel Cociorva", "Michael Sharps", "Cecile Levasseur", "Hakan Brunzell"], "abstract": "Representation learning is a fundamental aspect of modern artificial intelligence, driving substantial improvements across diverse applications. While self-supervised contrastive learning has led to significant advancements in fields like computer vision and natural language processing, its adaptation to tabular data presents unique challenges. Traditional approaches often prioritize optimizing model architecture and loss functions but may overlook the crucial task of constructing meaningful positive and negative sample pairs from various perspectives like feature interactions, instance-level patterns and batch-specific contexts. To address these challenges, we introduce TabDeco, a novel method that leverages attention-based encoding strategies across both rows and columns and employs contrastive learning framework to effectively disentangle feature representations at multiple levels, including features, instances and data batches. With the innovative feature decoupling hierarchies, TabDeco consistently surpasses existing deep learning methods and leading gradient boosting algorithms, including XGBoost, CatBoost, and LightGBM, across various benchmark tasks, underscoring its effectiveness in advancing tabular data representation learning.", "sections": [{"title": "Introduction", "content": "Self-supervised learning methods, particularly contrastive learning, have gained popularity in response to the challenges of acquiring labeled data. This approach often rivals or even surpasses supervised learning, especially in computer vision and natural language processing [52, 53, 48, 29, 30], by creating embeddings that distinctly separate similar and dissimilar data points. In visual tasks, techniques like image rotation or puzzle assembly enhance positive pair similarities, while token masking in text processing helps capture robust, invariant features. However, several critical industries, including healthcare[40, 8, 9, 10], manufacturing[4, 11, 46, 7], agriculture[31, 57, 54, 45, 55, 56] and various engineering fields [37, 12, 28, 41], still heavily rely on structured tabular data. Researchers traditionally leverage domain expertise for feature selection and uncertainty quantification [62, 60, 59, 61, 63].\nHowever, when applied to tabular data, contrastive learning encounters unique challenges in constructing meaningful positive and negative samples. Traditional methods frequently alter individual features or use entirely different samples, lacking a deeper exploration of feature interactions, instance-level patterns and batch-specific contexts, which could be essential for enhancing the learning process.\nTo produce more structured representations for tabular data, one notable attempt is SwitchTab [51], which employs an asymmetric encoder-decoder framework to decouple shared and unique features within data pairs. This feature decoupling process could naturally construct meaningful positive and negative samples, thus facilitating the contrastive learning process. However, this decoupling process faces notable difficulties. The linear projector used in SwitchTab often struggles to effectively delineate feature boundaries, leading to embeddings that are poorly organized and difficult to interpret, ultimately limiting the robustness of the approach. Another recent innovation, Self-Attention and Intersample Attention Transformer (SAINT) [43], which has enhanced feature learning by integrating attention mechanisms at both column and row levels, however, may struggle with dataset complexity, especially when faced with high-dimensional, heterogeneous, and noisy data.\nThe complementary strengths and limitations of SwitchTab and SAINT present an opportunity to develop a more robust framework for tabular data representation learning, focusing on effective feature decoupling to generate meaningful positive and negative sample pairs for contrastive learning, as well as capturing the data complexities to ehance model performance. Therefore, we propose TabDeco, an innovative contrastive learning framework that utilizes attention mechanisms to achieve finer-grained decoupling of local and global features across multiple levels in tabular data. TabDeco constructs positive and negative pairs from multiple perspectives, including local and global contrasts, feature-level and instance-level contrasts, enabling a more refined separation of feature hierarchies. By integrating attention-based encoding and feature decoupling strategies, TabDeco enhances the model's capacity to isolate and emphasize relevant features and instances, surpassing the limitations of existing approaches and enhancing the representation learning performance.\nOur contributions can be summarized as follows:\n\u2022 We propose TabDeco, a novel contrastive learning framework for decoupled representation learning for tabular data. To the best of our knowledge, this is the first attempt to explore and explicitly facilitate structured embeddings learning through contrasting for tabular data.\n\u2022 By integrating the strengths from feature decoupling and attention-based learning, we demonstrate out method to achieve competitive results across extensive datasets and benchmarks.\n\u2022 We develop the comprehensive framework for contrastive learning on decoupled features and construct positive and negative pairs from diverse perspectives, enhancing the exploration of feature interactions at local, global, and instance levels."}, {"title": "Related Work", "content": null}, {"title": "Classical vs Deep Learning Models", "content": "For tasks like classification and regression in tabular data, traditional machine learning methods remain effective. Logistic Regression (LR) [50] and Generalized Linear Models (GLM) [19] are commonly used for modeling linear relationships. In contrast, tree-based models such as Decision Trees (DT) [6], XGBoost [14], Random Forest [5], CatBoost [39], and LightGBM [23] are preferred for their ability to handle complex non-linear relationships. These models are noted for their interpretability and effectiveness in dealing with diverse feature types, including missing values and categorical features.\nRecent trends in the tabular data domain have seen the adoption of deep learning models designed to enhance performance. These include a variety of neural architectures such as ResNet [21], SNN [27], AutoInt [44], and DCN V2 [47], which are primarily supervised methods. Additionally, hybrid approaches combine decision trees with neural networks for end-to-end training, examples of which include NODE [38], GrowNet [2], TabNN [25], and DeepGBM [24]. There are also emerging focuses on representation learning methods that utilize self- and semi-supervised learning for effective information extraction, such as VIME [65], SCARF [3], and Recontab [13]."}, {"title": "Transformer-based Models", "content": "In the realm of tabular data, transformer-based methods have become increasingly prominent, leveraging attention mechanisms to discern relationships across features and data samples. Notable models in this category include TabNet [1], TabTransformer [22], FT-Transformer [17], and SAINT [43]. These models exemplify the integration of transformer technology in tabular learning, offering enhanced modeling capabilities through attention-driven feature interactions."}, {"title": "Contrastive Representation Learning", "content": "Contrastive Representation Learning (CRL) has been substantively developed through significant contributions across various fields. The introduction of MoCo, a dynamic dictionary technique for unsupervised visual representation learning, marked a major advancement in the efficiency of learning algorithms [20]. Following this, the SimCLR framework simplified and improved the process by applying a straightforward contrastive loss to visual representations [15]. In the natural language processing arena, enhancements in sentence embeddings have been demonstrated through an efficient learning framework that applies CRL principles [33]. Furthermore, the application of CRL to supervised learning scenarios has shown substantial improvements in classifier robustness and accuracy, broadening the potential uses of this approach [26]. Recently, efforts inspired by CRL have been extended to the tabular domain. However, these initiatives primarily focus on instance-level contrast, which may limit their broader applicability [13, 43, 65]."}, {"title": "Feature Decoupling", "content": "Feature decoupling is integral to advancing machine learning models, enhancing both interpretability and performance by separating complex, intertwined data elements. In computer vision, techniques such as unsupervised domain-specific deblurring leverage disentangled representations to improve image clarity by effectively isolating content from blur features [34]. The introduction of disentangled non-local neural networks demonstrates significant improvements in context modeling, benefiting tasks like semantic segmentation and object detection [64]. In multimodal transformers, decoupling strategies have been particularly effective, as demonstrated in zero-shot semantic segmentation, where the separation of components allows for better utilization of vision-language pre-trained models [16]. Moreover, in the tabular data domain, SwitchTab [51] showcases feature decoupling to enhance self-supervised learning by effectively isolating mutual and salient features to improve decision-making and model robustness in downstream tasks. This work has inspired us to propose a more comprehensive contrastive learning framework to enhance the decoupled feature learning."}, {"title": "Method", "content": "In this section, we introduce TabDeco, our comprehensive framework for contrastive learning tailored to tabular data representation. We begin with outlining the supervised training process of TabDeco, setting the foundation for effective feature extraction, decoupling and contrastive learning approaches. We then introduce the core component of TabDeco, the global-local feature decoupling mechanisms, to enhance the model's adaptability and robustness across diverse datasets. Furthermore, we explore the integration of various contrastive loss combinations, illustrating how each tailored loss function uniquely contributes to improving the model's performance by optimizing representation learning with better separation and alignment in feature space. Finally, we summarize the supervised learning algorithm and discuss the training strategies."}, {"title": "Supervised Training Framework", "content": "The supervised training architecture in our framework integrates column and row attention blocks with feature decoupling and contrastive learning, specifically tailored for tabular data. The attention blocks are from the state-of-the-art transformer-based model architectures considering both column-wise attentions for feature representation [22, 17] and row-wise attentions for intersample representation [43]. The feature decoupling module is inspired by the breakthrough idea in SwitchTab [51], further enhanced by the comprehensive contrastive learning process. Meanwhile, the natural integration of highly-resolved attention mechanism and fine-grained feature distinction could systematically enhance the model's ability to capture complex interactions among features and instances, making the most out of the unique characteristics of tabular data.\nGiven a tabular dataset represented by $\\mathcal{D} = \\{(X_i, Y_i)\\}_{i=1}^N$, where each $x_i$ is a $m$-dimensional feature vector with $y_i$ as its associated label. $N$ is the total number of samples. As shown in Figure 1, we append a [CLS] token with a learned embedding to each data sample, making $x_i = [[CLS], f_1, f_2,\\cdots, f_m]$ be the single data point with categorical or numerical features. $E$ is the embedding layer using different embedding functions to embed each feature into a $d$-dimensional space, i.e., $x_i \\in \\mathbb{R}^{(m+1)} \\rightarrow E(x_i) \\in \\mathbb{R}^{(m+1)\\times d}$. The encoded representations are then passed through $L$-layer attention blocks composed of feature-level and instance-level attention mechanisms. Feature-level attention focuses on refining relationships among features (columns), while instance-level attention blocks handle the interactions among instances (rows). This dual attention mechanism ensures the model's adaptability to complex feature interactions and intersample relationships.\nThe outputs from these attention blocks are projected into local and global spaces via respective projectors: the Local Projector $L(\\cdot)$ generates a local feature vector to represent both feature-level and instance-level local features, whereas the Global Projector $G(\\cdot)$ produces a global feature vector which could simutaneously represent feature-level, instance-level, and batch-level global features. The local and global feature vectors are then used to compute various contrastive losses (e.g., InfoNCE) to enhance the selected distinctions among feature, instance and/or global patterns. Additionally, supervised loss (e.g., Cross Entropy), is integrated to directly guide the learning process towards label prediction. This structured approach allows the model to capture fine-grained feature relationships and improve predictive performance across different data distributions and complexities."}, {"title": "Global-Local Decoupling", "content": "We introduce the global-local decoupling mechanism to effectively capture information at multiple levels. Specifically, each feature vector $x_i$ is decomposed into two distinct representations: a global feature vector $g_i$ and a local feature vector $l_i$. The global vector $g_i$ captures broad patterns and shared characteristics across the entire dataset, focusing on the correlations among features and interrelationships across different samples. In contrast, the local vector $l_i$ captures instance-specific variations that highlights the individual distinctions within each sample as well as the feature-specific uniqueness to distinguish one feature from the others. Mathematically, we define the global and local feature mappings as:\n$g_i = G(x_i; \\theta_g), l_i = L(x_i; \\theta_l)$  (1)\nwhere $G(.)$ and $L(\\cdot)$ are learnable functions parameterized by $\\theta_g$ and $\\theta_l$ respectively."}, {"title": "Contrastive Losses", "content": "Given the decoupled global and local feature vectors $g_i$ and $l_i$, we are constructing positive and negative pairs to distinguish between broader feature distributions and fine-grained individual characteristics. In general, we are encouraging global features to be similar to other global features, and discouraging local features from being similar to other local features. In addition, global features are discouraged from being similar to local features. The loss functions are demoted as\n$\\mathcal{L}_{global} = - log \\frac{exp(\\text{sim}(g_i, g_j)/\\tau)}{\\sum_k exp(\\text{sim}(g_i, g_k)/\\tau)}$  (2)\n$\\mathcal{L}_{local} = - log \\frac{exp(-\\text{sim}(l_i, l_j)/\\tau)}{\\sum_k exp(-\\text{sim}(l_i, l_k)/\\tau)}$  (3)\n$\\mathcal{L}_{cross} = - log \\frac{exp(-\\text{sim}(g_i, l_j)/\\tau)}{\\sum_k exp(-\\text{sim}(g_i, l_k)/\\tau)}$  (4)\nwhere $\\tau$ is the temperature parameter used to scale the similarity values and $k$ is the index across the entire set of features to compute the normalization factor for the similarity scores. $\\text{sim}(\\cdot)$ represents the similarity measure between two vectors, e.g., cosine similarity.\nDepending on the level of distinctiveness to be achieved, we proposed six types of contrastive losses, as shown in Table 1. Each loss function consists of the three loss components shown in Equation (2-4) with its corresponding similarity measure aggregating from the decoupled global and local feature vectors $g_i$ and $l_i$. The major difference lies in the similarity measures with different summation logic to distinguish aspects of global and local features. Specifically, $\\mathcal{L}_{all}$ aims to contrast each feature of each instance across the entire batch, creating a comprehensive similarity matrix of size $(b*m, b*m)$. It ensures that every data point is contrasted against all others, enforcing a comprehensive alignment that helps the model to learn subtle distinctions between different features and instances. Intuitively, this broad-level contrasting pushes the model to learn detailed, high-granularity representations by maximizing the separation between different feature-instance combinations. $\\mathcal{L}_{gg}$ compares each batch of features to a shared, global feature representation randomly initialized with dimension $(m, d)$, producing a $(b, m, m)$ similarity structure. By contrasting batch-level features against a global standard, this loss encourages the model to align local features with global patterns, improving consistency across batches. The intuition here is to synchronize individual batches with a common global feature representation, promoting a unified feature understanding across diverse instances.\nThe feature-level loss $\\mathcal{L}_{f}$ contrasts each feature across all instances within the same batch and captures relationships between different features within the same batch, encouraging the model to differentiate features that frequently occur together while still learning their distinct roles. The intuition is to refine feature boundaries, making the model more adept at identifying individual feature influences within complex interactions. $\\mathcal{L}_{fs}$ further contrasts each feature for each single instance across the batch and targets the fine-grained relationships of specific features of individual instances and fosters detailed understanding of how particular features vary between samples. Similarly, this sample-level loss $\\mathcal{L}_{s}$ contrasts each instance by comparing all features within that instance against others in the batch. This approach focuses on enhancing the discriminative ability of the model at the instance level, making it better at distinguishing between different samples based on their overall feature profiles. The intuitive aim is to fine-tune how the model distinguishes between individual data points, aiding in more accurate instance-level classification. Furthermore, $\\mathcal{L}_{sf}$ contrasts instances one feature at a time to emphasize on unique features with more differentiating power. The intuition is to enhance the model's sensitivity to how each feature contributes to instance-level differences, sharpening the model's ability to make precise comparisons between instances. Algorithm 1 shows the details on how to integrate the global-local decoupling with contrastive learning through different types of losses and positive and negative pairs generation. In practices, different types of contrastive losses can be combined together to learn the feature and instance representations with different granularities."}, {"title": "Experiments and Results", "content": null}, {"title": "Datasets, Setup, and Baselines", "content": null}, {"title": "Datasets", "content": "We evaluate the proposed method using a selection of widely recognized datasets, as utilized in recent studies [43]. These datasets include Bank (BK) [35], Blastchar (BC) [36], Shoppers (SH) [42], Volkert (VO) [18] and MNIST (MN) [58], among others. The datasets are diverse, ranging in size from 200 to 495,141 samples and spanning 8 to 784 features, incorporating both categorical and continuous variables. Some datasets contain missing data, while others are complete; similarly, some are well-balanced, whereas others exhibit highly skewed class distributions. All of these datasets are publicly accessible as shown in table 4."}, {"title": "Model variants", "content": "The TabDeco architecture discussed above follows similar design in SAINT to define three variants of model structures with different choices of attention block. TabDeco has the attention transformer encoder stacking both feature-level and instance-level attention blocks. TabDeco-s has only instance-level attention (e.g., SAINT-s) while TabDeco-f has only feature-level attention (e.g., SAINT-f)."}, {"title": "Training Details", "content": "We train all models, including those with pre-training, using the AdamW optimizer with parameters set to $\\beta_1 = 0.9$, $\\beta_2 = 0.999$, a weight decay of 0.01, and a learning rate of 0.0001. The batch size is set to 128, except for datasets with a large number of features, such as MNIST and Volkert, where we use smaller batch sizes. The data is split into 65% for training, 15% for validation, and 20% for testing. For the contrastive losses, we use temperature $\\tau = 0.5$. In each of our experiments, we use one NVIDIA A10G Tensor Core GPU. Individual training runs take between 5 minutes and 10 hours. For most of the datasets, we use embedding size $d = 32$. Due to the memory constraints of a single GPU, we use $d = 4$ for MNIST and $d = 8$ for Volkert. We used $L = 6$ layers and $h = 8$ attention heads in all datasets except MNIST and Volkert, where we reduce to $L = 2$ and $h = 4$. We leverage the implementations of various methods in TALENT toolbox [32] for training and comparisons."}, {"title": "Metrics", "content": "Since most of the tasks in our analysis focus on binary classification, we primarily use the Area Under the Receiver Operating Characteristic curve (AUROC) to evaluate performance. AUROC provides a robust measure of the model's ability to differentiate between the two classes within the dataset. For the two multi-class datasets, Volkert (VO) and MNIST (MN), we instead use accuracy on the test set"}, {"title": "Baselines", "content": "Following the previous paradigm [43, 51], we conduct a comprehensive comparison of our model against a range of established techniques, including traditional algorithms like logistic regression and random forests, as well as advanced boosting frameworks such as XGBoost, LightGBM, and CatBoost. Additionally, we evaluate our model's performance alongside state-of-the-art deep learning models, including multi-layer perceptrons, VIME[65], TabNet[1], TabTransformer[49] and the three variants of SAINT [43]. SAINT by itself include both feature-level attention block and instance-level attention block in each stage. For the two variants, SAINT-f has only feature-level attention and SAINT-s has only intersample attention. For models that incorporate unsupervised pre-training, We focus on comparing the supervised performance and only considering the classification tasks."}, {"title": "Main Results", "content": "We report performance comparisons on the set of public datasets, with the AUROC results summarized in Table 2 for model predicting power. The corresponding standard errors are reported in Appendix in Table 5 for model robustness. Each number reported in the two tables represents the mean of 10 trials with different random seeds.\nIn Table 2, TabDeco demonstrates significant predicting power ranking the best or second best across all datasets. Specifically, in 7 out of 11 datasets, one of the TabDeco variants outperforms all baseline models. In the remaining 4 datasets, TabDeco achieves the second best twice in Bank, outperformed by LightGBM and SAINT-f respectively. Income and Spambase datasets are also getting inferior performance from TabDeco, for which boosting methods have dominating predicting power. Meanwhile, TabDeco variants have shown the consistency to outperform their corresponding SAINT variants and SwitchTab for 10 datasets except Blastchar, which indicates the comprehensive enhancement from feature decoupling and constrastive learning. Table 5 further demonstrates the robustness of model performance for TabDeco, which exhibits better consistency than boosting methods and SAINT variants, especially for the datasets with better predicting power, such as Shoppers, HTRU2, etc."}, {"title": "Ablation Studies", "content": "In this section, we conduct experiments on different contrastive loss combinations to evaluate how they could performance differently for various datasets. We test adding the loss combination to the total loss for each TabDeco variant and report the best performance for each combination from all variants. The baseline noted by \"-\" is without any contrastive losses or feature decoupling, deteriorating to the SAINT variants for classification-only tasks. To determine whether the loss combinations are useful, we count the ones outperforming baseline for each dataset. Similarly, we count the outperforming ones for each loss combination across the datasets to check the consistency. As shown in Table'3, out of the 11 datasets, losses for more comprehensive feature-level (e.g., $\\mathcal{L}_{fs}$) and/or instance-level (e.g., $\\mathcal{L}_{sf}$) and/or cross-batch contrasting (e.g., $\\mathcal{L}_{gg}$) and their combinations are demonstrated to be significantly superior on getting better performance, outperforming the baseline for at least 6 and up to 11 datasets. For each datasets, the performance may vary across different contrastive losses. Out of the 14 combinations we test, the counts that outperform baseline varies from 1 to 10. Specifically the simplified feature-level or instance-level losses $\\mathcal{L}_{f}$ and $\\mathcal{L}_{s}$ can hardly get better performance. The global contrastive loss $\\mathcal{L}_{gg}$ as well as the one capturing more granular level feature and/or instance characteristics generally perform better."}, {"title": "Conclusion", "content": "In conclusion, the complexities inherent in tabular data demand innovative approaches that go beyond traditional deep learning and tree-based models. While methods like SwitchTab and SAINT have made strides in enhancing representation learning through feature decoupling and attention mechanisms, they fall short in fully addressing the challenges of dataset complexity and the generation of meaningful sample pairs. Our proposed framework, TabDeco, synthesizes the strengths of these methods by integrating attention-based contrastive learning with feature decoupling, enabling a deeper exploration of local and global interactions within the data. Extensive experiments demonstrate that TabDeco consistently outperforms existing models, including leading gradient boosting algorithms, across various benchmark tasks, underscoring its effectiveness and adaptability. By advancing the construction of positive and negative samples through multi-perspective contrastive learning, TabDeco sets a new standard for tabular data representation, offering a robust and interpretable solution for complex tabular scenarios. This work not only addresses current limitations but also paves the way for future innovations in contrastive learning for tabular data."}, {"title": "Appendix / supplemental material", "content": null}, {"title": "Datasets Details", "content": null}, {"title": "Additional Results", "content": null}]}