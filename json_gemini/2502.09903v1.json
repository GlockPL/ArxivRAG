{"title": "The Ann Arbor Architecture for Agent-Oriented Programming", "authors": ["Wei Dong"], "abstract": "In this paper, we reexamine prompt engineering for large language models through the lens of automata theory. We argue that language models function as automata and, like all automata, should be programmed in the languages they accept, a unified collection of all natural and formal languages. Therefore, traditional software engineering practices-conditioned on the clear separation of programming languages and natural languages-must be rethought. We introduce the Ann Arbor Architecture, a conceptual framework for agent-oriented programming of language models, as a higher-level abstraction over raw token generation, and provide a new perspective on in-context learning. Based on this framework, we present the design of our agent platform Postline, and report on our initial experiments in agent training.", "sections": [{"title": "Introduction", "content": ""}, {"title": "Large Language Models Are Automata", "content": "The foundation of modern computing was established by early pioneers striving to formalize computation through various theoretical models, with automata theory becoming a central framework [11]. Alan Turing's introduction of the Turing machine[23] provided a universal model for computation, employing an imaginary tape as a conceptual memory device and programming medium. This focus on theoretical machines and symbol manipulation ultimately culminated in the unification of automata and formal languages, exemplified by Noam Chomsky's classification of formal languages [3], and firmly established the role of languages in computer science.\nBuilding on this foundation, software engineering evolved as a discipline dedicated to creating higher-level abstractions that enhance programming efficiency and organization. Programming languages progressed from machine code to assembly, structured programming and beyond, each serving as a virtual machine that facilitates the translation of code into executable instructions for a Turing-equivalent system. The adoption of design patterns and software engineering methodologies provided structured approaches to managing complexity and improving software development workflows. While these methodologies did not extend the fundamental computational capabilities of the Turing machine, they optimized the way computational processes are expressed, organized, and refined.\nLarge language models, such as ChatGPT, represent a major advancement in artificial intelligence, capable of processing and generating text like humans do across a broad array of topics. Although they operate atop an extensive computational infrastructure and draw upon vast resources, basic language models excluding reasoning-augmented models like GPT-01 still largely conform to the original definition of an automaton (Figure 1): they read input tokens, update internal hidden states, and produce output tokens.\nA defining feature of large language models is their ability to process both natural and formal languages. Unlike conventional compilers and interpreters which are limited to predefined programming languages, large language models seamlessly handle diverse linguistic structures, spanning human languages, mathematical expressions, and code. Just like an automaton is programmed in the language it accepts, we argue that a large language model should be programmed in the same languages it processes, that is, the full range of natural and formal languages. This paradigm shift necessitates rethinking software engineering methodologies to maximize the potential of large language models as a computing platform."}, {"title": "Agent-Oriented Programming", "content": "From the perspective of software engineering as discussed above, language models operate at the abstraction level of finite automata, or programmable virtual machines. While they can produce coherent text and engage in sophisticated interactions, their responses remain bound to token-level transitions. Just as programming methodologies have enabled the growth of software engineering, higher-level abstractions will unlock greater potential in language models. The full scope of language model programming is still unfolding, being developed in ways that are largely unconcious, and overshadowed by the dominant efforts aimed at improve model reasoning through machine learning approaches [19, 4]. Among the various emerging directions, many point to agents as a promising paradigm for organizing and managing language model-based applications [16, 24, 26]. We too consider agents of foundational importance and advocate for the term agent-oriented programming as a formal methodology, following the tradition of structured, object-oriented, and functional programming.\nAn agent is a natural progression beyond language models, intended to endow AI systems with more human-like behavior. While existing survey papers often assume the value of agents with minimal explanation, we take an epistemological perspective to underscore why agents are critical in successful application of language models. Language models possess vast amounts of knowledge, but due to the diverse and sometimes contradictory data on which they are trained, these models do not hold a consistent worldview, set of values, or unified objectives, rendering them sometimes too flexible and unreliable for tasks requiring stable perspectives. In essence, an language model functions like an \"average\" human who may exhibit contradictory views, rather than a distinct individual with a coherent perspective.\nThe concept of an agent addresses this limitation by filtering the language model's vast knowledge to emphasize only the subset relevant to a particular individual. The agent remains aware of the broader knowledge encoded within the model but, in cases of conflicting perspectives, maintains a defined stance, ensuring consistency and reliability. Because an agent narrows the capacity of an raw language model, it naturally follows that an agent-based platform must support multiple agents to compensate for the loss of generality in any single agent. The platform must facilitate efficient information exchange between agents, effective conflict resolution, and dynamic adaptation to evolving objectives. The different agents adopt distinct perspectives or roles and collectively leverage the full breadth of the language model's capabilities.\nMany agent platforms have been developed. Google's Vertex AI Agent Builder/Dialogflow [8] and Microsoft's Copilot Studio[18] are two leading enterprise platforms. There are also popular open-source projects like AutoGen[17] and CrewAI[1]. These platforms provide a variety of interfaces and approaches for building and managing agents, but they mostly constrain themselves to a common paradigm:\n\u2022 The user (designer or engineer) has to assume a specific task to be au-"}, {"title": "Rethinking In-Context Learning", "content": "The rapid advancement of language models has been largely driven by scaling laws [13], where continually increasing model size and training data has yielded steady gains in performance. However, recent evidence [12] suggests that this strategy may be approaching its limits, as further scaling appears to offer diminishing returns. While vast efforts are currently dedicated to refining reasoning algorithms, we argue that the form of training data must also be reexamined.\nOne major gap in current training paradigms is the absence of learning through multi-round interactions. The standard training process, as exemplified by Llama 3[21], is to pre-train a model with a large amount of free text, and then to post-train the model to follow instructions using supervised training. The post training examples follow a rigid structure, typically in the form of either (input, expected output) pairs for SFT [25, 5, 6] or (input, preferred output, rejected output) triplets for DPO (direct preference optimization) [20]. In the case of DPO, the rejected mistakes are not made by the AI being trained but are staged. While these approaches provide clear guidance on the end goal, they lack the iterative, trial-and-error learning process fundamental to human skill acquisition. Effective training should involve opportunities for an AI model to make mistakes, receive feedback with explanations of why, and adjust its behavior accordingly - mirroring how humans refine their skills under the guidance of a mentor.\nBased on this observation, we propose to redefine in-context learning or in-context training as an evolving process occurring through message exchanges"}, {"title": "Paper Organization", "content": "Section 2 elaborates on the proposed Ann Arbor Architecture. Section 3 presents the design of Postline, our prototype platform. Section 4 presents a series of experiments on an early version of Postline. Section 5 provides further thinkings and concludes the paper."}, {"title": "The Ann Arbor Architecture", "content": ""}, {"title": "Overview", "content": "The Ann Arbor Architecture aims to create a framework for understanding agents, their connection with language models, and their engagement with tasks and environments. It is a mind framework rather than the architecture of a realized system. We challenge the current task-centric agent architectures by highlighting agents' collaboration with engineers, their persistence, long-term growth and even evolution. Our goal is to unify various engineering processes, a goal naturally called for by the language model's unification of natural and formal languages.\nAt its core, the proposed framework models agents and their interactions after the email system. Each agent is assigned a unique identifier an email address-through which it exchanges messages. All messages with the agent's address appearing in either the \"From\" or the \"To\"-like fields form a persistent, chronological record of the agent's communication history, collectively referred to as the agent's journal. This persistent journal serves as the primary memory mechanism for the agent, ensuring that all past interactions remain accessible and can inform future decision-making.\nUnder the proposed framework, there is only one form of information exchange: sending emails. This entails two important distinctions between the proposed framework and the existing approaches.\nFirst, our proposed framework does not separate the design/training phase from the deployment phase. We illustrate this using the development of a customer service conversational agent (Figure 2). In existing systems, engineering"}, {"title": "Emails and the MBox Format", "content": "The MBox format was first implemented in Fifth Edition of Unix and was standardized in RFC4155 [9].\nUnder the proposed framework, agent communication is modeled after email systems, utilizing the MBox format as the conceptual data format for both agent memory and agent communication. Below is a sample MBox file containing two messages, separated by a blank line followed by a line starting with From. A separating line starting with From is not considered a part of the message that follows it.\nFrom alice@example.com Fri Feb 14 14:30:00 2025\nFrom: alice@example.com\nTo: bob@example.com\nSubject: Project Update\nHi Bob,\nJust wanted to give you a quick update on the project status.\nWe're on track to meet our deadlines and the initial test results\nlook promising.\nBest regards,\nAlice\nFrom bob@example.com Fri Feb 14 15:45:00 2025\nFrom: bob@example.com\nTo: alice@example.com"}, {"title": "The Role of Language Models", "content": "Under the proposed framework, language models function as a shared computational resource, akin to fuels or electricity in the physical world. However, unlike electricity, which is uniform in nature, language models exhibit diversity in their capabilities, performance, and cost, making the selection of an appropriate language models at any given moment a scheduling opportunity and a challenge. Agents operating within this framework dynamically decide, potentially by itself, which model to invoke for the next inference.\nThe volume of agent-involving information exchanges will increase substantially in the future. These messages will contain the latest human insights, ideas, and problem-solving discussions. Since language models require visibility into relevant messages to perform inference, portions of these communications naturally become available as training data for subsequent iterations of model training. Over time, this cyclical process will foster a symbiotic evolution between agents and language models. Model freshness will be increasingly relied upon, so the time towards the next update and the recall of latest knowledge will become two key measurements of language model technology. This will eventually drive language models from machine learning models to storages of public information."}, {"title": "Memory Management and Reproduction", "content": "Agent memory management plays a critical role in system performance. The size of an agent's memory directly affects inference cost and efficiency. A larger memory size also increases the difficulty for model to attend to relevant information, potentially degrading the quality of the inference output.\nAgents can regulate their memory through two primary mechanisms: memory pruning/compression and reproduction by split. The first approach involves selectively filtering or summarizing past messages to retain only the most relevant information. The Memory Segment Rewrite (MSR) primitive provides a method for agents to autonomously modify their own memory, allowing them to refine stored knowledge while maintaining coherence. Model inference is a special case of MSR, as it is equivalent to rewriting the empty segment at the end of the memory. Because the memory is the agent's program, MSR is a primitive that enables self-modifying programs.\nThe second mechanism, reproduction by split, enables an agent to partition its memory when its memory size grows beyond an optimal threshold and cannot be effectively compressed. The split can also occur simply when resources allow. By dividing its journal into multiple subsets, an agent can create descendants, each inheriting a portion of its memory while diverging into specialized roles over time. Memory episode clustering might serve as a man-made algorithm to guide the split process, but eventually AI will evolve its own way.\nA special case of this process is cloning, where an agent duplicates its memory at a specific moment, allowing multiple versions of itself to evolve independently. This facilitates parallel exploration of different strategies, or parallel processing"}, {"title": "Unification of Engineering Processes", "content": "The unification of natural and formal languages by language models allows us to design a unified engineering process that blurs some boundaries that we have been accustomed to and are still using today to divide the world in certain ways. In addition to the boundary between development and deployment stages as we have already discussed, so is the boundary between code and documentation.\nHistorically, code has been written in programming languages while documentation has been composed in natural language. With the unification of these linguistic modalities, language models can generate both seamlessly, eliminating the need for strict separation. The core product will no longer be static code or documentation but rather memory journals that capture ideas and experiences.\nCode or documents will be generated just in time, tailored to specific needs and execution contexts. An explicit workflow or computational graph as heavily depended upon in existing agent platforms may not even be necessary, as the agent will be able to dynamically respond to the task or delegate it to other agents according to information stored in the memory."}, {"title": "Postline: A Prototype", "content": ""}, {"title": "Overview", "content": "To realize the Ann Arbor Architecture, we developed a prototype platform called Postline. The name was chosen by the AI to reflect the system's messaging-based nature.\nPostline operates on top of language models and is designed to work with both types of APIs available today: text completion APIs and chat APIs. The agent's memory, represented as an MBox file, is both textual and conversational, making adaptation to different APIs straightforward.\nWe designed the system with the assumption that context size limits will continue to expand and that language models will become increasingly capable of handling longer contexts. As a result, we have not placed a strong emphasis on automatic memory size management. A more comprehensive episodic memory design is planned for future work.\nFigure 4 illustrates the system architecture of Postline. The platform is fully scalable on the cloud."}, {"title": "Agent Memory Representation", "content": "The fundamental unit of data in the system is an email message. At its core, the system's data structure revolves around the representation of an agent's memory. To ensure both efficiency and persistence, we employ a dual-representation design, storing information in two distinct forms: the journal and the context. This approach is inspired by standard database and filesystem journals.\nJournal: The journal is an append-only, persistent log of all messages an agent sends and receives. It enables retrospective analysis and the replay of past events. For journal storage, we use Kafka, ensuring performant and scalable message logging."}, {"title": "Worlds, Realms and Realm Servers", "content": "A world is a namespace of addresses. There is no cross-world communication, meaning agents, users, and robots in one world cannot interact with those in another. This design ensures a clean separation of environments, allowing independent agent ecosystems to coexist without interference.\nThe computation in Postline primarily involves message processing and language model API invocations. To ensure scalability, we partition this computation based on spatial and temporal locality, as we model by the concept realm. This parallelism is achieved at the operating system process level through realm servers. A realm server is a software process that can be started on demand to process messages, and the platform is designed to support an indefinite number of realm server processes.\nThe realm server maintains multiple WebSocket connections with clients for message exchange. Its primary data structure is a queue of unprocessed messages. In scenarios such as those shown in Figure 3, users, agents, and robots across different tools all connect to the same realm server. The client always connects to the realm server via a frontend proxy (nginx) so load balancing is transparent to the client.\nWe allow multiple realm servers to run in parallel within the same world. In some cases, the same agent may be needed in multiple realms. To support this, we implement a context locking mechanism, ensuring that at any given time, an agent's context is held by at most one realm server.\nThe relationship between agent addresses and their assigned realm servers is managed by lock servers. If a new realm server requires access to a context that is currently locked, it contacts the current lock owner, which then writes the context to storage and releases the lock. The new realm server subsequently acquires the lock and loads the context from backing storage.\nWe expect realm switching to be an infrequent operation. Most of the time, an active agent's context remains in the memory of a single realm server, readily available for inference.\nThree types of resources consumed by the realm server affect operational costs and hardware configuration:\n\u2022 Computational cost for processing messages and invoking APIs.\n\u2022 Memory cost for maintaining active contexts.\n\u2022 Open file descriptor (or port) usage for all parallel connections.\nWe expect a pattern of long-standing connections with relatively low activity.\nOur design allows each computation node to run thousands of realm servers in parallel."}, {"title": "Privacy", "content": "All messages originating from the user and those addressed to the user are naturally accessible to them. The user also has access to communications involving the robots if they have control over them. However, communication between the agents and the system, primarily memory manipulation operations initiated by the agents, is hidden from the user by default. The journal, or the agent's memory as seen by the user, has all memory manipulation instructions filtered out, while the context remains internal to the system and is not visible to the user. This approach potentially allows the agent memory management to be transparent to the user."}, {"title": "Experiments", "content": "In this section, we report experiments conducted with an early version of Post-line. These are the first steps in our engineering efforts, and the functions achieved are neither novel nor complicated. We use these experiments to demonstrate the experience with the proposed framework. All experiments were run on gpt-40. Raw messages in the agent's journal are displayed with some headers omitted.\nThe experimental code and logs are available on Github.\nhttps://github.com/aaalgo/postline_0.1"}, {"title": "Shell Robot", "content": "Integrating the robot that represents the system shell (terminal) was one of our earliest experiments and opened up many possibilities. The agent is allowed to send a JSON message to the shell robot, specifying the command to run. The shell robot executes the command and returns the stdout and stderr as email attachments. The agent then interprets the outcome and sends a message back to the user. In the session below the agent was asked to figure out the system's storage configuration.\nFrom: user1@localdomain\nTo: ai_30@agents.localdomain\nSubject:\nYou are the middleman AI, which sits between the user and the bash command line of a recent Ubuntu system. Both the user and the shell are represented by email addresses. You'll receive user input from the user email address, and you'll send the commands to the email address shell@localdomain, in a JSON format (detailed below). After you get response from the shell, you'll interpret the outcome and send a message back to the user.\nThe address shell@localdomain only processes messages of Content-Type application/json with the following schema:\n{\n\"prompt\": \"The prompt to display to the user\",\n\"command\": \"echo Hello, world!\",\n\"confirm\": false\n}\nprompt: the prompt to display to the user before the command is run\ncommand: the command to run on the system\nconfirm: whether to ask the user to confirm whether to run the command. Please confirm for commands that might potentially damage the system.\nFrom"}, {"title": "Code Generation and Execution", "content": "The command-line interface is, by itself, a complete programming environment. There was a time when early programmers had access only to a teletype and wrote code directly in the command line using the line-oriented editor ed, and in theory the agent should be able to do the same.\nWith minimal effort, we succeeded in making the agent generate simple"}, {"title": "Handling Binary Image Data", "content": "This is a simple experiment to demonstrate the capability of the MBox format in handling non-text attachments. We ask the agent to generate a simple image using the ImageMagick tool and then use the base64 command to encode the image in textual base64 format. Next, we ask the agent to generate an email with the image attached, conforming to the MBox format. Viewing the image, of course, requires importing the MBox file into an email client. Below are the final few message exchanges of the experiment. The agent initially failed to attach the image properly, and some in-context training was applied to fix it.\nFrom: ai_30@agents.localdomain\nTo: user1@localdomain\nSubject: Attached Sample Image\nHere is the sample image 'sample.png' encoded in base64 format:\n\u060c\u060c\u060c\niVBORw0KGgoAAAANSUhEUgAAAGQAAABKAQMAAABKLACXAAAAIG...\n\u060c\u060c\u060c\nYou can decode this base64 string to retrieve the original image. If you need further assistance, just let me know!\nFrom\nFrom: user1@localdomain\nTo: ai_30@agents.localdomain\nYou are not generating an attachment. Remember you are generating mbox email in order to communicate with me. The mbox format allows the email to carry attachment. Attach the image in that way to me. Try again!\nFrom\nFrom: ai_30@agents.localdomain\nTo: user1@localdomain\nSubject: Attached Sample Image\nContent-Type: multipart/mixed; boundary=\"----Boundary\"\n------Boundary\nContent-Type: text/plain; charset=\"utf-8\""}, {"title": "Creating New Agents", "content": "Our platform dynamically creates new agents for non-existent addresses as needed. The command line interface we used to communicate with the agent at that time did not support switching to a new agent, but rather always replied to the sender of the latest message. We overcame this limitation without modifying our code by instructing the agent to send a message to the new agent (or the required one) and have it report back to us.\nWe also explored the possibility of recursively cloning a series of agents and achieved limited success. We realized that stricter behavior and resource control are needed to make such flexibility safely applicable without accidentally overwhelming the system."}, {"title": "Memory Segment Rewriting", "content": "In the experiment below, the agent is informed about the MSR primitive and is asked to identify a wasteful memory segment to remove. The agent decided to remove the memory of a python code debugging session. The MSR message itself is not visible, as it has taken the position of the removed range. The saving of the context can be observed from the reduction of the X-Total-Tokens header towards the end of the conversation (from 17,727 to 16,919). Note that X-Total-Tokens is what is involved in generating one message, mainly determined by the context length, and is filled in by the system according to API responses."}, {"title": "Failure of Agent Initialization with Bible", "content": "After achieving the series of positive experiences as previously described, mostly within a single long conversation with the agent ai 30, the authors became increasingly uneasy with the growing length of the journal. Conditioned by conventional software engineering practices, we felt an instinctive urge to refine, condense, and package the working \"prompt\" into a more compact and elegant, presentable form.\nThe idea was straightforward: instead of cloning lengthy journals for new agents, we attempted to condense all accumulated knowledge into a single comprehensive document a Bible for Postline Agents to serve as an initialization mechanism. This document was intended to encapsulate all necessary information for new agents, providing a self-contained knowledge base in place of an evolving journal. The agent ai_30 was instructed to organize and dump its memory into this document, with no constraints imposed on the document's length, and we experimented with different formats, first attaching it as an email attachment and later embedding it directly into the email body.\nDespite extensive efforts, including human-crafted amendments to the Bible, the approach proved unsuccessful. Agents initialized with the Bible invariably failed to reproduce the expected behaviors, exhibiting various forms of degradation. In almost all cases, these agents immediately struggled to produce messages that adhere to our communication protocol, especially the JSON-based protocol for the shell robot.\nThis failure highlighted a fundamental insight and forced us to rethink in-context learning: the journal is not merely a static repository of knowledge but an active record of evolving interactions. The process of learning is inherently tied to the sequence of experiences, corrections, and adaptations that an agent undergoes. Attempting to distill this into a single document overlooks the role of in-context learning. The experiment reinforced our understanding that agent memory must remain dynamic, preserving the episodic nature of interactions rather than reducing them to a static knowledge artifact.\nThis experience also shaped our perspective on software engineering with language models, as discussed in Section 2.5. Unlike formal languages, where equivalent trans-"}, {"title": "Conclusion and Future Directions", "content": "This paper challenges today's common paradigm of agent programming, which remains heavily influenced by traditional software engineering practices rooted in the now fading separation of programming languages and natural languages. We introduced the Ann Arbor Architecture as a new conceptual framework for agent-oriented programming of language models. To validate our key ideas, we developed Postline and reported our experiences in agent training.\nMoving forward, our primary focus will be on developing a more advanced system of episodic memory. Episodic memory is fundamental to human cognition [22] and has long been considered a crucial component of AI [14]. In our framework, episodic memory will serve as a higher-level organizational structure beyond individual messages. To enable this, mechanisms must be designed for agents to autonomously create episode boundaries as interactions evolve, to selectively swap out older, less relevant episodes through MSRs (replacing them with concise summaries with keys for retrieval), and a new primitive must be introduced to allow agents to retrieve out-of-core episodes when needed. We envision the full episodic memory as a tree-like structure, with the context covering the portion closest to the root. External data sources might be naturally incorporated via mechanisms that are referred to as retrieval-augmented generation [15, 7] today. Furthermore, episode clustering will provide a starting point to investigate agent reproduction and evolution.\nRegarding the application of our platform, we observe that most existing agent frameworks are designed primarily to automate repetitive tasks, such as customer service, itinerary planning, and payment processing tasks that have traditionally been challenging for rule-based software due to their reliance on adaptive intelligence. While our proposed framework can be applied to such automation, we believe that the greatest strength of language models lies in their learning ability and creativity. Therefore, we intend to focus our agent development on applications in scientific and industrial research, where a higher failure rate is more acceptable as long as occasional breakthroughs can be achieved."}]}