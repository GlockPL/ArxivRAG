{"title": "LECTURE I: GOVERNING THE ALGORITHMIC CITY", "authors": ["Seth Lazar"], "abstract": "A century ago, John Dewey observed that '[s]team and electricity have done more to alter\nthe conditions under which men associate together than all the agencies which affected\nhuman relationships before our time'. In the last few decades, computing technologies have\nhad a similar effect. Political philosophy's central task is to help us decide how to live\ntogether, by analysing our social relations, diagnosing their failings, and articulating ideals\nto guide their revision. But these profound social changes have left scarcely a dent in the\nmodel of social relations that (analytical) political philosophers assume. This essay aims to\nreverse that trend. It first builds a model of our novel social relations - as they are now, and\nas they are likely to evolve-and then explores how those differences affect our theories of\nhow to live together. I introduce the 'Algorithmic City' \u2013 the network of algorithmically-\nmediated social relations \u2013 then characterise the intermediary power by which it is\ngoverned. I show how algorithmic governance raises new challenges for political\nphilosophy concerning the justification of authority, the foundations of procedural\nlegitimacy, and the possibility of justificatory neutrality.", "sections": [{"title": "1. INTRODUCTION", "content": "Political philosophy's central task is to help us determine how to live together. It\nanalyses our social relations, diagnoses their failings, and articulates ideals to\nguide their revision. A century ago, John Dewey argued that '[s]team and\nelectricity have done more to alter the conditions under which [people] associate\ntogether than all the agencies which affected human relationships before our\ntime', and called for political philosophy to be revised in light of these changes. In\nrecent decades, computing technologies have had no less significant an impact on\nhow we associate together than did steam and electricity. And political philosophy\nis overdue another update. Our social relations are now infused with, sometimes\neven constituted by, computational systems. These may not enable, as Lessig\nthought, entirely new modalities of power. But the prevailing means of governing\npower have undoubtedly shifted. And political philosophers must determine\nwhether and how that power can be properly exercised.\nLecture I begins that task. The first step is to clarify how social relations have\nchanged in the information age. I introduce 'the Algorithmic City' \u2013 the network of\nalgorithmically mediated social relations of which we are now all part. I then\ncharacterise how power operates through these algorithmic intermediaries,\nhighlighting a shift in both the means and prevailing modalities of power\ncompared to our pre-algorithmic social relations. I argue that algorithmic\ngoverning power should not simply be eliminated but can be properly exercised \u2013\nprovided it aims at substantively justified ends and is used according to legitimate\nprocedures by those with authority to do so. I then show how algorithmic\ngovernance raises presumptive challenges for familiar political philosophical\napproaches to these three normative standards. In the second Lecture, I use the\napproach developed at a high level here to consider a particular dimension of the\nAlgorithmic City: the digital public sphere."}, {"title": "2. THE ALGORITHMIC CITY", "content": "John Rawls argued that we cannot select principles of justice for a society if we lack\nunderstanding of how that society works. To make normative claims about how\nour social relations should be governed, we must understand those social relations'\nnature. Yet while some dimensions of our social relations-for example, sex,\ngender, race, nationality, and climate-have progressively garnered more of our\nphilosophical attention, another set of fundamental social changes has been too\nmuch ignored. \u2018The information age' describes the changes wrought by\ninformation and communication technologies grounded in computing. Political\nphilosophy urgently needs updating for the information age. The task ahead is\nmammoth. This Lecture contributes by identifying and analysing what I consider\nthe most significant political change computing has made: the advent of the\nnetwork of algorithmically-mediated social relations, the Algorithmic City.\nSocial relations are stable patterns of communication and interaction between\npeople. This includes deeper connections, such as those between family members\nand friends; weaker ties, such as between colleagues, co-citizens, or participants in\neconomic exchange; and even the thin connection of indirectly communicating\nthrough contribution to the same public discourse over time. I am most interested\nin social relations that are significant in people's lives, either individually or in the\naggregate.\nIn the information age, our social relations are, to a growing degree, partly or\nwholly constituted by algorithmic intermediaries. These are the computational\nsystems by which we now connect-social media, e-commerce, search engines,\ngenerative AI, email and messaging, and so on. I call them algorithmic\nintermediaries in the spirit of recent work in sociology and communication studies,\nwhich uses the term as a synecdoche. Algorithms are programmed instructions\nexecuted by a computational system-either direct instructions detailing\nexhaustively what the system should do under different conditions or indirect\ninstructions to the system to learn from a set of training data and then (in effect)\nwrite its own direct instructions. Algorithms are the tip of a long spear, part of a\nbroader sociotechnical assemblage that includes other software and hardware\nelements of computational systems, human labour and material resources.\nArtificial Intelligence (AI) picks out a suite of algorithmic approaches to enabling\ncomputational systems to represent their environment and then act on it to achieve\nan intended outcome. These approaches are functionally unified by this task\ndescription but are highly heterogeneous. Machine Learning (ML) algorithms are\nundoubtedly the ascendant force in AI, with transformer-based self-supervised\nneural networks having enabled remarkable progress in Natural Language\nProcessing (NLP), text generation, image recognition, image generation, and even\nagentic behaviour. But other AI techniques-planning, knowledge\nrepresentation, and logic, among others -are also highly societally influential. And\nother non-Al algorithmic methods play a prominent role in the Algorithmic City,\nsuch as algorithmic mechanism design, blockchain, hash-matching, and some non-\nML varieties of information retrieval. Most of the algorithmic intermediaries that I\nfocus on make prominent use of AI, but my analysis extends to other algorithmic\nsystems that would not typically be considered in that (slightly amorphous)\ncategory.\nWhy call these algorithmic intermediaries rather than digital intermediaries? Here I\nam using 'algorithmic' metonymically, to pick out the feature of these\nsociotechnical systems that is most salient. Their crucial feature is that they are\ndynamic and adaptive, able to monitor the social relations that they mediate and to\nintervene in them in real-time. In other words, the algorithmic is the agential\ndimension of computing-the functional ability of computational systems to\nperceive changes in their environment and act on them. This (functionally) agential\ndimension of algorithmic intermediaries explains their ability to operate at such\nextraordinary speed and scale. The algorithmic component of these computational\nsystems accounts for the transformative impact they have already had on our\neconomies, our culture, our politics and our personal relationships, as well as the\nstill greater changes that they portend. It also proves crucial to understanding\nwhether and how the power relations they enable can be justified.\nIntermediaries are go-betweens. They mediate between two or more mediatees,\nconveying information or action from one to another. Social relations are\nconstituted by mutual communication and interaction. If and to the extent that an\nintermediary conveys communication and interaction, then the intermediary at\nleast part constitutes those social relations. Intermediaries can be passive\nconduits; algorithmic intermediaries, however, actively shape the social relations\nthat they constitute.\nThe early days of the internet saw many scholars explore urban and other\nmetaphors at length; metaphors in general can be fertile but also misleading. I use\nthe concept of 'the Algorithmic City' strictly as shorthand for 'the network of\nalgorithmically mediated social relations'. This network is not a space \u2014 like\n'cyberspace' - supposedly distinct from the physical, non-algorithmic world.\nAlgorithmic intermediaries infuse almost all our social relations, including those\nwith substantial non-algorithmic dimensions. And the Algorithmic City describes\nhow humans, in all our visceral, physical reality, connect to one another (and\nsometimes to bots). The algorithmic intermediaries connecting us are just software\ntools implemented on physical infrastructure\u2014from servers and GPUs to cables\nand broadcast towers.\nThe Algorithmic City is also different from the 'Society of Algorithms' \u2013 the latter\nconcept aims to encompass every way algorithmic systems infuse society at large.\nPolitical philosophy must urgently address the full gamut of algorithmic impacts\non our social lives; but the Algorithmic City focuses on one specific dimension: the\nnetwork of social relations mediated by algorithmic intermediaries. The \u2018Network\nSociety' is an obvious ancestor to the Algorithmic City. However, that concept\nplaces too much emphasis on the nodes of the network, and not enough on the\nedges (the connections between the nodes), which it presents as passive or neutral\nconduits. In the Algorithmic City the edges of the network are themselves able to\ndynamically update in order to reshape the social relations that they mediate and\nconstitute. Although some algorithmic intermediaries can fairly be described as\ncontent-independent 'pipes', I am primarily interested in intermediaries that\ndynamically adapt and reshape the social relations that they mediate.\nProminent examples of algorithmic intermediaries in the wild are: social\nnetworking sites, such as Facebook, Instagram, X (formerly known as Twitter),\nTikTok, YouTube, and Mastodon; e-commerce sites, like Amazon and eBay; other\ntwo-sided markets for services, like Uber and AirBnB; cultural two-sided markets\nlike Spotify and Apple Music. We must also consider search engines, generative\nAI systems like ChatGPT, Claude, and Gemini, app stores, operating systems, and\neven digital infrastructure like cloud and security services (e.g. AWS, Microsoft\nAzure, Google Cloud, Cloudflare, CrowdStrike). Even mundane technologies like"}, {"title": "3. THE NATURE AND JUSTIFICATION OF ALGORITHMIC POWER", "content": "3.1. Dimensions of Algorithmic Power\nThe Algorithmic City is a model of how digital technologies transform our social\nrelations. A model's worth comes down to its explanatory utility. Drawing\nattention to algorithmic intermediaries foregrounds adapted and intensified power\nrelations that urgently demand normative evaluation.\nPower is, roughly, the ability to shape others' prospects, options, and attitudes\n(beliefs and desires). A has power over B just in case A can exercise power over B,\nso defined. One of political philosophy's central questions is, in Lessig's terms,\nwhen is power properly exercised? So political philosophers should closely attend\nto the ways in which new technologies introduce new or newly intense power\nrelations, or alter the distribution of power. The first step in this process is to\nempirically identify the variety of ways in which the new technology affects the\nsocial distribution of power. Second, we need to analyse these new distributions of\npower, to identify whether the new technology raises new kinds of questions\nabout power's justification. And third, we must determine whether and how this\nnew distribution of power can be justified.\nI want to start by drawing attention to three dimensions of how algorithmic\nintermediaries shape social power relations. First, algorithmic intermediaries\nenable those who design or deploy them to exercise power over the people whose\nsocial relationships the algorithmic intermediaries mediate. Second, algorithmic\nintermediaries shape power relations between the mediatees. Third, through\nexercising power over us, and reshaping power relations within our social\nrelations, over time algorithmic intermediaries reshape our broader social\nstructures. I'll elaborate on each in turn.\nFirst, power over. Algorithmic intermediaries do not spring up from the ground\nlike mushrooms. They are complex sociotechnical systems designed and deployed\nby self-interested actors in the (often disappointed!) hopes to achieve their own\ngoals. As such, they enable those behind these systems to exercise power over\nthose whose social relations the systems mediate. To say that an algorithmic\nintermediary exercises power over its mediatees is, in general, just to say this: the\nintermediary enables those who design or deploy the system to exercise that\npower. Since this is the most common case, this is what I will mean when I say that\n'algorithmic intermediaries exercise power over their mediatees'. I consider\nexceptions to this rule \u2013 where the algorithmic intermediary itself exercises\npower-in the next subsection.\nAlgorithmic intermediaries exercise power over their mediatees by directly\naffecting their prospects-making them better or worse off. This might come\nthrough, for example, amplifying or demoting your communications, suggesting\nand enabling new connections, or banning and removing you from a platform.\nSearch algorithms in two-sided markets can make or break a business.\nAlgorithmic management tools can make a worker's life intolerable. Given that\nalgorithmic intermediaries can in-principle access and record every aspect of the\nsocial relations they mediate, they also have unprecedented enforcement powers\nover mediatees. Scholars since the 1990s have recognised the quasi-legal power of\ncode-what Reidenberg called Lex Informatica. Algorithmic intermediaries add\nanother layer: they shape our access to other people. Exclusion by the intermediary\ncould lock you out of a vital market, or disrupt a meaningful relationship.\nAlgorithmic intermediaries' power derives not only from the disciplining\ndimension of code but from how they can enable or limit access to the people with\nwhom we wish to interact.\nBy constituting the relationships they mediate, algorithmic intermediaries\nsubstantially determine our options in those relationships. Everything we can\ncommunicate or do to one another via an algorithmic intermediary is made\npossible by that intermediary. This productive power is pervasive in digital\nenvironments, often enabling new kinds of action. Generative AI Systems provide\nperhaps the most striking example of this in recent years, as they enable people to\ncommunicate with others in ways that they were literally incapable of just months\nago; Language Model Agents promise to do the same for many more domains of\nhuman action besides simply generating text and images. Algorithmic\nintermediaries also remove options, making certain behaviours impossible for\nthose whose relationships they mediate (at least, through that intermediary).\nDigital 'locks' like Digital Rights Management, take this form. Meta's personal\nboundary in its Horizons virtual world is another example. Rather than mandating\nthat users ought not to grope one another's avatars, the algorithmic intermediary\nsimply removes the option of invading another avatar's personal space. And\nefforts by leading AI research companies to 'align' their Generative AI Systems to\n'human values' are most often further examples of just this kind of option-\nelimination, as people are prevented from using the models to generate certain\nkinds of content, or performing certain kinds of actions. These options are stripped\naway, sometimes, by filters that prevent either certain kinds of instructions from\nbeing acted on, or certain outputs being generated; even more interestingly, they\nalso train the models to recognise potentially harmful instructions, and steer them\ntowards safer ground.\nAll technologies afford some options and push against others. Algorithmic\nintermediaries are particularly well adapted to shape our choice architectures.\nSimple design choices, such as what kinds of response a platform allows to another\nperson's communications, as well as more intentional \u2018dark patterns' nudging us\ntowards particular outcomes, make some options for communication more\nappealing than others, raising barriers to disfavoured behaviour, and encouraging\nfavoured behaviour. In the extreme, this includes adding penalties to some\noptions (and incentives to others). This approach is typically used when pre-\nemptively removing disfavoured options is undesirable.\nAnd algorithmic intermediaries shape our beliefs and desires. We learn about the\nworld through recommender systems, search engines, and now LLM-enabled tools\nlike ChatGPT and Perplexity. Algorithmic advertising and the dependence of our\ninformation environment on recommender systems anticipate and cultivate our\ncurrent appetites, and generate new ones, such as the opportunity to win a\nminimal form of approbation from strangers on the internet (a like, upvote, or\nrepost). This trend will radically accelerate as Language Model Agents enable\nuniversal intermediaries to digital technologies \u2013 instead of simply receiving\nrecommendations in the form of a ranked list, we will routinely interact more with\nAl-generated summaries (including selection and editorialising) of other people's\nspeech than with those people themselves.\nSecond, power between. Critics often think of digital technologies as simply\ndominating-vehicles for the arbitrary power of Big Tech companies, digital\nthumbs pressing us down. But while that is clearly happening too, as just\ndescribed, many (perhaps most) digital pathologies are caused by other people-\nwho can communicate with and act on us because of the algorithmic\nintermediaries mediating our social relations. As well as enabling those who\ndesign and deploy them to exercise power over those they mediate between,\nalgorithmic intermediaries also shape power relations between mediatees,\nenabling some of them to exercise power over others.\nAlgorithmic intermediaries enable some to directly affect others' prospects. For\nexample, as I discuss in Lecture II of this book, in the digital public sphere\nalgorithmic intermediaries can incentivise forms of individual and collective\nharassment and abuse that very clearly make their victims much worse off,\nsometimes causally contributing to serious material harms, like suicide and even\ngenocide. Algorithmic intermediaries also empower some to shape others'\noptions, by enabling various kinds of economic, social, and cultural interactions\nand by determining which are encouraged and which discouraged. And they\nallow some to shape others' beliefs and desires. Commentators lament how 'the\nalgorithm' is leading people astray, manipulating them, filling their heads with\nmisinformation, and so on. But while recommender systems undoubtedly play a\nrole, the bottom line is that a person (or bot) is producing manipulative content, and\nthen, through algorithmic intermediaries, manipulating others. Whether or not 'the\nalgorithm' is manipulating people, algorithmic intermediaries have created great\nincentives and opportunities for people to deceive and manipulate one another.\nLike any city, the Algorithmic City is fundamentally a site for interaction between\npeople. It enables us to connect to one another - to forge new social relations of\ncommerce, culture, sociality and politics. And any medium that enables interaction\nand communication will either help some people to have unjustified power over\nother people, or else support egalitarian social relations. People's propensity to\ndominate one another, to use the means available to them to seize resources and\npower, is parametric. The means we have for communicating and acting on one\nanother will shape the degree to which we are able to realise those goals, thereby\nshaping power relations between the mediatees. This will ultimately prove\nessential to the evaluation of algorithmic power.\nThird, power through. Algorithmic intermediaries shape our social structures over\ntime by shaping the social relations they mediate. Social structures are, roughly,\nnetworks of roles, relationships, incentives, norms, cultural schemas (widely\nshared sets of evaluative and doxastic attitudes), and institutions, which can be\npopulated or observed by different people at different times; they are generally the\nemergent result of patterns of human interaction over time, and they reliably\npattern outcomes for people who are within or otherwise affected by them. They\nare partly constituted by social relations, so if algorithmic intermediaries change"}, {"title": "3.2. Analysing Algorithmic Power", "content": "Whenever new technologies enable new or newly intensified power relations to\nemerge, or otherwise shift the distribution of power in our social relations, political\nphilosophers should take notice. And we face a dual challenge: first to come to\nunderstand the nature of these new distributions of power, and then to morally\nevaluate them.\nTo attempt the former task, it will help to distinguish between means and modalities\nof power. A means of power is a tool, practice, or technology that enables the\nexercise of power. The law, for example, is a canonical means of power. But so is\nthe parental voice, so are the competitive pressures of a free market, or the physical\ninfrastructure of an analogue city, or the extra-legal norms and conventions that\nshape human behaviour. Modalities of power are the ways in which a particular\nmeans of power can be used to exercise power. In the foregoing section, I\ndistinguished between exercising power by directly affecting people's prospects,\nby shaping their options, and by shaping their beliefs and desires. These are all\ndifferent modalities of power, at one level of description. In this subsection, I\nintroduce further modalities of power that cut across those.\nA priori, any means of power can be used according to any modality of power.\nNonetheless, different means are likely to favour different modalities, just as in\ngeneral the nature of technologies shapes the functions that they can successfully\nbe used to perform. Algorithmic intermediaries are an historically novel means of\nexercising power. And\u2014like all means of exercising power \u2013 they favour a\ndistinctive combination of modalities of power, which demands careful evaluation\nin its own right. Intriguingly, the advent of new means for exercising power offers\nthe prospect of a kind of natural experiment in understanding the modalities of\npower-by coming to understand the nature and justification of the new mix of\nmodalities, we can learn more about our other means of exercising power, and\nperhaps shine a light on modalities of power that have previously received\ninadequate attention.\nTo support this point, I want to introduce some further distinctions in the modality\nof power. The most important is the distinction between extrinsic and intermediary\npower.\nExtrinsic power shapes social relations from the outside in: it creates physical\nspaces and institutional parameters within which people can engage in\nunmediated interaction. Our analogue cities involve much extrinsic power.\nPhysical spaces shape which kinds of interaction are feasible, and laws determine\nboundaries for permissible behaviour. Compliance with those laws is up to you -\nthough choosing non-compliance risks penalty. This extrinsic structure permits\nparticipants in social relations to interact and communicate in an agentially-\nunmediated way. To adapt a metaphor from Dewey: extrinsic power governs\nsocial relations the way a river's banks govern the water's flow.\nIntermediary power is more like the bonds knitting the water's molecules together.\nIt constitutes (in whole or part) the social relations that it mediates, thereby\ndetermining what shape they can take\u2014what is possible or impossible,\nencouraged or frustrated. It progressively eliminates the possibility of agentially-\nunmediated communication and reduces the scope of feasible non-compliance,\nsince refusal is impossible unless it is intentionally designed in. Intermediary\npower shapes social relations from the inside out.\nAlgorithmic intermediaries, like most means of power, can operate both\nextrinsically and instrumentally. When algorithmic intermediaries are used by the\nagents of extrinsic power to surveil populations, monitor them for compliance with\nsome set of rules, and subject them to penalties for non-compliance, they are\nimplicated in the exercise of extrinsic power. However, as the name suggests,\nalgorithmic intermediaries also make extensive use of intermediary power. Indeed,\nin one sense, they bring it to an unprecedented apotheosis.\nTo be clear, intermediary power is not new to the Algorithmic City. This modality\nof power has always been present, just as there have always been intermediaries,\nsuch as negotiators, bureaucracies, brokers, curators, critics, media companies and\nmatchmakers. In literature, we have characters like Iago from Shakespeare's\nOthello, or the Lawyer in Kafka's trial. They have always been able to exercise\npower over those they mediate between. They monitor the behaviour of their\nmediatees, learn and shape their beliefs and desires, and then shape their\nrelationship, typically in ways that profit the intermediary. Call this kind of\nadaptive, individualised intermediary power agential intermediary power.\nOther means of power, like the law, also manifest this modality of power. For\nexample, the law often plays a constitutive role, in which it makes certain kinds of\nsocially recognised options legally possible (for example, in how it defines\nmarriage, or other types of contractual relationship, or the merger of two\ncorporations). Some would also argue that social norms exercise a kind of\nintermediary power, and more broadly that social structures such as economic\nsystems, or even the language that we use, shape what is possible for people\nwithin their social relations, just as human or algorithmic intermediaries do, and\ntherefore also exercise intermediary power. Language makes some intentions\nunsayable, some actions unthinkable, and directs us, through the terms we must\nuse, towards some outcomes and away from others. Let's call this structural\nintermediary power, because it imbues social structures like laws, norms, and\ninstitutions, is never within the voluntary or unilateral control of any particular\nagent, and is hard to update (it is a 'precipitate of the past').\nAlgorithmic power stands apart for how it combines these two dimensions of\nintermediary power. It is both structural and agential. Algorithmic intermediaries'\nability to operate at vast scale and lightning speed enables them to imbue social\nrelations to a degree that is simply unmatched by any other agential\nintermediaries. They can shape social relations through shaping billions of\nmicrotransactions a second, as with the complex systems of real-time bidding on\nonline advertising, and algorithmic stock trading. Online platforms' ability to\nshape our options, beliefs and desires at scale is truly structural - a change in\nGoogle's search algorithm will radically change economic opportunities within\naffected communities; if Facebook, Instagram, YouTube, TikTok, or X (Twitter as"}, {"title": "3.3. Eliminate or Justify Algorithmic Intermediary Power?", "content": "Much normative work on the Algorithmic City has been reflexively critical,\nidentifying moral shortcomings of existing technologies but rarely offering deep\njustification for why they constitute moral shortcomings, relying instead on implicit\nnormative foundations, presumptively shared with the audience, assumed not to\nneed support. On this view, naming power is enough to criticise it; distinguishing\nbetween permissible and impermissible power is anathema. An alternative\napproach moves directly from criticism to intervention, proposing regulations or\ntechnological solutions to mitigate these agreed-upon harms.\nBoth approaches are missing an important further step: the step where we reflect\non and argue for the guiding principles that should shape power relations in the\nAlgorithmic City. This is not the anaemic process of agreeing on 'AI Ethics\nPrinciples', but rather is about determining what we care about, so our moral\ndiagnoses have depth and our regulatory or technical interventions have purpose.\nThis is political philosophy's task (whether undertaken by those trained as\nphilosophers or not). In the present context, its first objective is to consider the\nforegoing descriptive and interpretative account of how algorithmic intermediaries\nshift power relations, and explain whether their doing so is morally defensible.\nThe first step is to explain why the critics are right to be presumptively suspicious\nof new, and newly intensified, power relations. Presumptive hostility to power\nmakes sense if you endorse one or all of three values which, for the purposes of\nthis book, constitute the bedrock of my normative analysis of the Algorithmic City:\nindividual liberty, relational equality, and collective self-determination. Together\nthese form the bedrock of a liberal egalitarian democracy. Each value can be\ninterpreted differently, and the ensuing discussion should be robust across most\nreasonable interpretations. However, for clarity, I will precisify them as follows.\nI understand liberty as negative liberty or protection from wrongful interference\nand the risk of wrongful interference by others. Negative liberty contrasts with\npositive liberty, which prioritises the ability to make authentic choices between\ndesirable options, and republican liberty, which prioritises not minimising the risk\nof interference but eliminating its possibility.\nThe ideal of relational equality has deep roots, but it came to prominence in\ncontrast with the philosophical focus on distributive equality. Rather than\nfocusing on the distribution of some good within a population, it describes an\naspiration that we should live in a society where we recognise one another as\nmoral equals, and where the institutions structuring our interactions reflect and\nsupport that equality.\nOver time, societies collectively, and largely unintentionally, create and sustain\nsocial structures that affect our choices, making some things possible and others\nimpossible, shaping our beliefs and desires. Collective self-determination is the\nprocess of reducing our subjection to heteronomous social structures that\ninadequately reflect our values. It involves jointly seizing the reins of our shared\nlives, so that we are not only formally equal, but we actually have positive political\npower to shape the shared terms of our social existence.\nI call these democratic values because, in this world, democratic institutions are the\nonly means by which all three will be realised. Moreover, democratic institutions\nconstitutively enable relational equality and collective self-determination: they are\nnot simply means to realise those values (as is I think the case for individual\nliberty), but rather democratic institutions themselves realise egalitarian social\nrelations, and constitute collective self-determination. The institutions of\ndemocracy are many and complex, and I will not attempt a catalogue. And\ndemocracy is in practice always an imperfect ideal. But no other institutional\narrangement has yet instrumentally or constitutively enabled the fulfilment of\nthese foundational values. Democracy's enduring appeal is reflected in our\nappetite to defend it when it is threatened.\nWith these three values in mind, we can see why new power relations warrant\nsuspicion and how they must be justified or resisted. Very simply put: if A has\npower over B, then B is subject to the risk of wrongful interference by A. So, power\nis presumptively in tension with negative liberty. If A has power over B, then they\npresumptively stand in hierarchical social relations, undermining relational\nequality. And if A has power over B, C, and D, then, presumptively, the society\ncomprising [A, B, C, D] together are not collectively self-determining.\nAlgorithmic intermediaries exercise power over us. They are used to exercise\npower over us by those who develop and deploy them. They also shape power\nrelations between those they mediate between-and by all accounts, they do so in"}, {"title": "3.4. Justifying Algorithmic Governance", "content": "One could be forgiven for thinking this story is yet another version of the familiar\ntale: this exciting technology can do much good! But it also involves risks! Let's\nbuild it so we get one without the other! Thus go a million opening paragraphs to\ngrant proposals and policy briefs the world over. But we're not just weighing\nbenefits and harms here; we're talking about the justification of governing power.\nTo justify governing power, cost-benefit analysis is not enough. Suppose A has\ngoverning power over B, C, and D. If A uses that power for sufficiently justified\nends, that might protect B-D's negative liberty, but if A is unconstrained by\nprocedural norms that ensure he robustly acts correctly, then B-D still face the risk\nof unjustified interference, and so are unfree. And if A unilaterally decides what\ncount as the right ends, and B-D disagree, but cannot hold A to account or\notherwise influence his decisions, then clearly relational equality and collective\nself-determination have been thwarted.\nSometimes, unaccountable power might be A's only means to achieve ends that\nmatter enough to override these objections. Think, for example, of emergency\npowers assumed in the face of some grave and urgent threat. But outside these\nemergencies (which should be rare), we should aim not just to override these\nobjections with some countervailing value but to resolve them. Indeed, if resolving\nthese objections is possible at a reasonable cost, then the proportionality of"}, {"title": "4. AUTHORITY, COERCION, AND PRE-EMPTION", "content": "Because algorithmic governance is interestingly different from other", "governance": "the law", "pre-emptive governance": "nhas three dimensions. First", "technological\nmanagement'": "the choice simply not to design non-compliant options", "regulation by\ndesign": "s a familiar practice", "exercise": "walls can be surmounted"}]}