{"title": "Adversarial Federated Consensus Learning for Surface Defect Classification Under Data Heterogeneity in IIoT", "authors": ["Jixuan Cui", "Jun Li", "Zhen Mei", "Yiyang Ni", "Wen Chen", "Zengxiang Li"], "abstract": "The challenge of data scarcity hinders the application of deep learning in industrial surface defect classification (SDC), as it's difficult to collect and centralize sufficient training data from various entities in Industrial Internet of Things (IIoT) due to privacy concerns. Federated learning (FL) provides a solution by enabling collaborative global model training across clients while maintaining privacy. However, performance may suffer due to data heterogeneity-discrepancies in data distributions among clients. In this paper, we propose a novel personalized FL (PFL) approach, named Adversarial Federated Consensus Learning (AFedCL), for the challenge of data heterogeneity across different clients in SDC. First, we develop a dynamic consensus construction strategy to mitigate the performance degradation caused by data heterogeneity. Through adversarial training, local models from different clients utilize the global model as a bridge to achieve distribution alignment, alleviating the problem of global knowledge forgetting. Complementing this strategy, we propose a consensus-aware aggregation mechanism. It assigns aggregation weights to different clients based on their efficacy in global knowledge learning, thereby enhancing the global model's generalization capabilities. Finally, we design an adaptive feature fusion module to further enhance global knowledge utilization efficiency. Personalized fusion weights are gradually adjusted for each client to optimally balance global and local features, tailored to their individual global knowledge learning efficacy. Compared with state-of-the-art FL methods like FedALA, the proposed AFedCL method achieves an accuracy increase of up to 5.67% on three SDC datasets.", "sections": [{"title": "I. INTRODUCTION", "content": "INDUSTRIAL Internet of Things (IIoT) has been widely deployed across various industrial sectors, facilitating distributed data acquisition and real-time monitoring among geographically dispersed industrial entities. Surface defect inspection, as one of the critical tasks of IIoT, has gained significant attention due to its impact on the quality and safety of industrial products. In recent decades, substantial research has focused on developing methods to detect and classify surface defects, thereby enabling production line adjustments and quality improvements [1]\u2013[6]. Traditional surface defect classification (SDC) methods often rely on manual inspection, which is labor-intensive, time-consuming, and susceptible to human errors.\nIn recent years, the integration of artificial intelligence with IIoT has provided new automation solutions across various industries, significantly enhancing efficiency and effectiveness [7]\u2013[14]. Traditional machine learning classifiers, such as support vector machine (SVM) and random forest [7]\u2013[9], have been utilized for automated SDC. These classifiers are typically coupled with some shape-based and texture-based feature extraction methods [10], such as Fourier descriptor and local binary pattern. However, they suffer from limited feature extraction capabilities due to reliance on manual features, inadequately capturing the diversity of surface defects, thus limiting generalization and adaptability in SDC tasks. On the contrary, deep learning (DL)-based methods are capable of learning abstract representations autonomously, without the need for manual feature engineering. In particular, DL-based classifiers built on convolutional neural network (CNN) architectures, such as ResNet and MobileNet, consistently demonstrate superior performance in SDC tasks [11]\u2013[13].\nNonetheless, DL-based SDC methods require sufficient data to develop robust models, which a single entity often cannot provide [15]. To overcome this limitation, data must be collected from multiple entities, and aggregated at a centralized location, such as a central server. This process of data aggregation not only exposes sensitive information to potential breaches but also conflicts with privacy regulations. Federated learning (FL), a paradigm enabling model training across distributed participants, known as clients, while preserving data privacy and security, effectively addresses the aforementioned challenge of data scarcity and privacy [16]\u2013[25]. By allowing data to remain local and only merging model parameters trained with local data, FL effectively enhances DL model performance without compromising data privacy.\nHowever, the practical implementation of FL encounters significant challenges due to data heterogeneity. Variations in production conditions, such as differences in equipment and environmental factors, result in non-independent and identically distributed (non-IID) data across participating clients. For instance, different industrial entities may encounter varying categories of defect samples, leading to discrepancies in the"}, {"title": "II. RELATED WORKS", "content": "Previous studies have addressed the issue of data scarcity through two main aspects. On one hand, some research focuses on leveraging few-shot learning algorithms. For instance, Kim et al. [15] proposed a siamese neural network with CNN structure to overcome the data scarcity challenge in steel SDC. Similarly, Xiao et al. [31] applied graph embedding and distribution transformation modules, coupled with optimal transport for transductive classification. On the other hand, an alternative strategy involves the use of a generative adversarial network (GAN) to synthesize defect samples, thus enlarging the sample volume. In [32], three GANs are trained to augment the data for surface defects. Furthermore, a cycle-consistent adversarial network with attention mechanism, named AttenC-GAN, was proposed to address the challenges of small intra-class differences and data scarcity [33].\nDespite some progress in overcoming the challenges posed by limited data, the performance of these models is still held back by the small size of local datasets. In the scenario of distributed industrial data sources, the efficient exploitation of distributed data sources, while maintaining privacy, can significantly boost model performance and unlock the full potential of the data."}, {"title": "III. PROBLEM FORMULATION", "content": "The core problems of SDC in practical applications can be summarized as follows:\n1) Data scarcity and privacy: While the collection of raw industrial data is often straightforward, acquiring high-quality data labels is both difficult and expensive in IIoT. The data from a single entity is often insufficient for training robust DL models, and privacy issues restrict the sharing of data among entities, thus obstructing the deployment of DL models.\n2) Data heterogeneity: Variations in production conditions between different industrial entities result in non-IID data. As shown in Fig. 2, different clients hold data with distinct distributions. Since most learning algorithms assume data to be IID, model performance will be degraded due to data heterogeneity.\nIn the typical FL setting, a federation is established comprising a central server and a collection of K participating clients. Each client k possesses a private dataset $S_k = \\{(x, y)\\}$, consisting of $|S_k|$ image-label pairs, where each image x and its corresponding label y (indicating the class or category of the image) are sampled from a unique distribution $P_k$. Importantly, the dataset held by each client is relatively small, and the data distribution is unique for every client.\nEach client k possesses a local model $W_k$, comprising an encoder $E_k$ and a classifier $C_k$. The encoder is responsible for extracting informative feature representations from raw images, typically employing a CNN-based backbone. Meanwhile,"}, {"title": "IV. PROPOSED METHOD", "content": "This work proposes a PFL method to address data heterogeneity in SDC through three key components: a dynamic consensus construction strategy for improved global knowledge learning during local training, a consensus-aware aggregation mechanism for enhanced generalization ability of the global model, and an adaptive feature fusion module for further global knowledge utilization efficiency. Together, they collaboratively train personalized models in a privacy-preserving manner.\nAs shown in Fig. 3, the overall system consists of a central server and several clients. The entire training process can be summarized into six main steps as follows: :\n1) Clients download the global encoder $E_G$ from the server;\n2) Clients update their local encoder $E_k^t$, classifier $C_k^t$, and discriminator $D_k^t$ according to the dynamic consensus construction strategy;\n3) Clients return the updated local encoder $E_k^t$ and the discrimination loss $L_D^{k,t}$ to the server;\n4) The server aggregates the encoders following the consensus-aware aggregation mechanism;\n5) Clients update local encoder $E_k^t$, classifier $C_k^t$, and fusion weight $A_k^t$ employing the adaptive feature fusion module;\n6) Repeat steps 1) through 5) until the end of training.\nThe three components of the proposed AFedCL method will be introduced in detail."}, {"title": "B. Dynamic Consensus Construction", "content": "In scenarios where local data distributions vary significantly, models may focus on learning specific characteristics of local data, risking the loss of global knowledge acquired from the global model. To ensure the persistent retention of global knowledge during local training, we develop the first stage of local training (step 2) with ongoing evaluation of global knowledge acquisition and immediate feedback based on adversarial training. Specifically, beyond the classification task, a local discriminator is trained to differentiate between the features extracted by global and local encoders from the identical samples. Concurrently, the local encoder endeavors to confound the discriminator, creating an adversarial game process with the discriminator's training.\nThe dynamic consensus construction strategy involves the computation of two types of loss: classification loss and discrimination loss. As shown in Fig. 3, at the t-th communication round, client k receives global encoder $E_G$ from the server. For a singular sample x, its global feature $E_G(x)$ and local feature $E_k^t(x)$ are obtained by inputting x into the global encoder $E_G$ and local encoder $E_k^t$, respectively.\nFor the classification loss $L_C^{k,t}$, we adopt the cross entropy loss function. The local classifier $C_k^t$ manages the local feature $E_k^t(x)$ to produce a predictive probability distribution vector $C_k^t(E_k^t(x))$. The classification loss $L_C^{k,t}$ is calculated by\n$L_C^{k,t} = \\frac{1}{|S_k|} \\sum_{(x,y) \\in S_k} l(C_k^t(E_k^t(x)), y)$\n$=\\sum_{c=1}^{N} \\sum_{(x,y) \\in S_k} \\frac{1}{|S_k|} 1[y=c] log(C_k^t(E_k^t(x))_c)$"}, {"title": "C. Consensus-Aware Aggregation", "content": "To clearly demonstrate the adversarial process and lay the groundwork for our designed consensus-aware aggregation mechanism, we conducted a sub experiment by omitting the update of $E_k^t$ based on $L_D^{k,t}$. As shown in Fig. 4, without updating $E_k^t$ with $L_D^{k,t}$, discrimination loss decreases to zero, reflecting the discriminator's enhanced ability to differentiate local features from global features, as evidenced by improved discrimination accuracy. Conversely, updating $E_k^t$ with $L_D^{k,t}$ during dynamic consensus construction results in fluctuating discrimination loss and lower discrimination accuracy levels. It reveals that the discriminator struggles to distinguish between global and local features, indicating that local encoder features closely align with global features.\nThis alignment helps effectively retain global knowledge during training on private data. Reflecting these changes in final classification accuracy, the AFedCL without updating $E_k^t$ based on $L_D^{k,t}$ achieved only 54.68%, significantly lower than the complete algorithm's 70.75%, highlighting the essential role of the proposed strategy.\nFollowing the adversarial training at the t-th communication round, each client k uploads $E_k^t$ and $L_D^{k,t}$ into the server for aggregation. In the server, the objective is to generate a global model with stronger generalization ability. As we discussed before, a higher discrimination loss value leads to a more similar pattern between the global and local features, indicating a greater contribution of global knowledge. Therefore, during the model aggregation stage (step 4), our designed consensus-aware aggregation mechanism assigns higher weights to clients with greater discrimination loss values. At the t-th round, the server aggregates models using\n$E_G^{t+1} = \\sum_{k=1}^{K} \\frac{L_D^{k,t}}{\\sum_{k=1}^{K} L_D^{k,t}} E_k^{t}$"}, {"title": "D. Adaptive Feature Fusion", "content": "Considering the variations in global knowledge learning among clients, we aim to balance these differences and enhance the utilization efficiency of the global knowledge embedded in the global model. Therefore, we design an adaptive feature fusion module for the second stage of local training (step 5). It gradually optimizes personalized fusion weights for each client to get an optimal balance between global and local features, combining them into more comprehensive representations for robust prediction.\nAt the t-th communication round, the global feature $E_G(x)$ and the local feature $E_k^t(x)$ of sample x are computed by inputting x into the global encoder $E_G$ and the local encoder $E_k^t$. Then the adaptive fusion weight $A_k^t$ is used to generate an interpolation of them as\n$f = A_k^t E_G(x) + (1 - A_k^t) E_k^t(x)$\nwhere $f$ is the fusion representation, and it is then fed into the local classifier $C_k^t$ to generate the final class prediction $C(f)$. The classification loss $L_C^{k,t'}$ will be computed as\n$L_C^{k,t'} = \\frac{1}{|S_k|} \\sum_{(x,y) \\in S_k} l(C(A_k^t E_G(x) + (1 - A_k^t) E_k^t(x)), y)$\nAfter that, $L_C^{k,t'}$ is minimized to update the fusion weight $A_k^t$ and the local model $W_k$, comprising the encoder $E_k^t$ and the classifier $C_k^t$, shown as\n$W_k \\leftarrow W_k - \\alpha (\\frac{\\partial L_C^{k,t'}}{\\partial W_k})$\n$A_k^{t+1} \\leftarrow A_k^{t} - \\alpha (\\frac{\\partial L_C^{k,t'}}{\\partial A_k^t})$"}, {"title": "V. EXPERIMENTS", "content": "In this section, we demonstrate the necessity of adopting FL within IIoT environments and evaluate the effectiveness of the proposed AFedCL method using three real-world datasets, including two hot-rolled strip steal datasets and one cold-rolled strip steal dataset. The experiments are conducted under two non-IID settings to simulate real-world production line conditions, and we assess the method's performance under three different local training sample sizes to verify its robustness in the face of varying degrees of data scarcity."}, {"title": "A. Datasets", "content": "1) NEU-CLS: The Northeastern University Classification (NEU-CLS) dataset [34] is a hot-rolled strip steel SDC dataset, featuring six typical surface defect types: rolled-in scale, patches, pitted surface, crazing, inclusion, and scratches."}, {"title": "VI. CONCLUSION", "content": "In this paper, we have developed a novel PFL approach, AFedCL, to tackle the challenge of data heterogeneity in SDC. It enables multiple industrial entities in IIoT to collaboratively train personalized models while preserving privacy. Specifically, a dynamic consensus construction strategy has been invented to achieve distribution alignment among different clients through an adversarial game process, thus mitigating performance degradation caused by global knowledge forgetting under non-IID data. Building on this, a consensus-aware aggregation mechanism has been introduced. It assigns aggregating weights based on the global knowledge learning efficacy, measured by each client's discrimination loss, improving the generalization ability of the global model, and facilitating better consensus construction. Furthermore, an adaptive feature fusion module has been designed. Through the optimization of personalized scalar fusion weights of global and local features, the utilization efficiency of global knowledge is enhanced, thus boosting model performance. The proposed method demonstrates promising results across extensive experiments on three real-world SDC datasets, achieving a notable increase in accuracy of up to 5.67%."}]}