{"title": "The Physics of Learning: From Autoencoders to\nTruly Autonomous Learning Machines", "authors": ["Alex Ushveridze"], "abstract": "The fact that accurately predicted information can serve as an energy source paves the way for new\napproaches to autonomous learning. The energy derived from a sequence of successful predictions can\nbe recycled as an immediate incentive and resource, driving the enhancement of predictive capabilities in\nAl agents. We propose that, through a series of straightforward meta-architectural adjustments, any\nunsupervised learning apparatus could achieve complete independence from external energy sources,\nevolving into a self-sustaining physical system with a strong intrinsic 'drive' for continual learning. This\nconcept, while still purely theoretical, is exemplified through the autoencoder, a quintessential model for\nunsupervised efficient coding. We use this model to demonstrate how progressive paradigm shifts can\nprofoundly alter our comprehension of learning and intelligence. By reconceptualizing learning as an\nenergy-seeking process, we highlight the potential for achieving true autonomy in learning systems,\nthereby bridging the gap between algorithmic concepts and physical models of intelligence.", "sections": [{"title": "0. Introduction", "content": "In recent years, machine learning (ML) has made significant strides toward creating systems that are not\nonly smarter but also more self-reliant [1]. The most notable advancements in this area have largely\nstemmed from employing techniques such as meta-learning [2-4], self-supervised learning [5-7],\nreinforcement learning [8-10], and continuous learning [11-13]. The systems developed using these\nmethods have been designed to enhance their own learning processes actively. They are equipped to\nfunction independently, adapt to new problems, and continuously improve themselves. For the sake of\nclarity, let's refer to these as artificial autonomous learning systems.\nAlongside these developments, there's another dimension of autonomy that hasn't been as extensively\nexplored in Al and ML discussions. This involves the ongoing inquiry into how the so-called natural\nautonomous learning systems might naturally arise from non-intelligent matter. While this question\nmight appear theoretical at first glance, its potential practical implications are substantial. Deciphering\nthe processes that lead to the spontaneous emergence of such systems and grasping the nature of the\nsustaining forces is crucial. This understanding not only expands our knowledge of the origins of\nintelligence in the universe but also opens up extensive practical opportunities for the creation and\noptimization of autonomous systems."}, {"title": "1. The Classical Autoencoder", "content": "Intelligence can be informally characterized by its ability to forge a reciprocal link between big data and\nsmall data. Here, \"big data\" refers to the observable attributes of real-world processes, while \"small\ndata\" denotes our internal understanding (or, in other words, models) of these processes. This dual-\npathway connection embodies two fundamental facets of intelligence: the capacity to learn,\ndemonstrated by transforming extensive, real-world data into concise, internal knowledge, and the\nability to apply this acquired knowledge practically, evident in the process of translating compact data\nback into actions or decisions that impact the larger world.\nThis concept is exemplified in one of the most significant breakthroughs in data science-the\nautoencoder [25-27]. An autoencoder (or, more exactly, its classical version, which we are planning to\ndiscuss in this section) is a specialized form of artificial neural network designed for the unsupervised\nlearning of efficient data encoding. Its high-level architectural form is shown in the picture below:\nAs it is seen, the classical autoencoder takes some external (big) data F and converts it into its internal\n(small) representation \\(f = E(a)F\\) utilizing a lossy compression algorithm E (a) characterized by a set of\ntunable parameters a. This process aims to distill essential regularities from the original data F thereby"}, {"title": "2. The Parroting Autoencoder", "content": "The redesigned architecture of the autoencoder is depicted in the updated illustration below:\nThis new setup introduces a feedback loop that links the output of the decoder directly back to the input\nof the encoder, effectively internalizing the process that was previously governed by an external error\nfunction. This loop, which we hereafter will call the 'internal learning loop', will play a decisive role in\nframing up the true physical mechanism of learning. As we will see later, in the next two sections, this\nloop will evolve into an energy extraction engine ensuring a full autonomy of the learning device. Here\nwe are still treating it in ML manner, as an internal error control and minimization mechanism. The fact\nthat it operates solely with compressed data ensures that all adjustments and learning processes are\nbased on the system's own, internalized criteria. This approach eliminates the need for external error\nevaluation, fostering a more autonomous learning environment within the autoencoder."}, {"title": "3. Learning as Digital Resonance", "content": "The challenge of autonomous learning that we're exploring in this article is fundamentally rooted in the\nfield of physics, specifically within the branch known as non-equilibrium thermodynamics. This area of\nstudy aims to uncover the processes behind self-organization in open physical systems, aspiring to\nelucidate a wide range of phenomena. This includes the origins and development of life and the"}, {"title": "4. Learning as Analog Resonance", "content": "Before we start, let's first recall the definition of learning given in ref. [23], in which it was characterized\nas \"a process wherein a system attempts to replicate the dynamic patterns of external forces using\nentirely internal mechanisms\u201d. We see that this definition essentially mirrors the concept of parroting\ndiscussed earlier, resonating with our intuitive understanding of learning as an internally motivated\nprocess. At the same time, by framing this process in terms associated with forces and their dynamics,\nthis definition highlights the intrinsic link between learning and physics.\nTo better understand the nature of this link, it's crucial to recognize that any learning system, or\n'learner,' operates as an open physical system in active interaction with its environment, which plays the\nrole of its 'teacher.' This interaction is characterized by external forces applied by the teacher and the\nlearner's responsive actions. During these exchanges, the energy within the learner is not necessarily\nconserved; it can either decrease due to destructive forces or increase through constructive\nengagement. Now, consider a learner aiming to augment its internal energy by strategically engaging\nwith its surroundings. In theory, this could be achieved either by altering the environment or by the\nlearner modifying its own internal structure. While large, powerful systems might have the luxury of\nchoosing either approach, smaller, less powerful learners may only feasibly opt for self-adaptation to\nexternal forces. To address the question of necessary internal modifications for adaptation, physics\noffers a compelling answer: the learner can leverage the phenomenon of resonance, one of the most\nrecognized effects in physics. The core principle of resonance is the synchronization of movements\nbetween two interacting systems, which dramatically amplifies the energy exchange between them. In\nthis dynamic, the smaller system stands to gain substantially, as it can enhance its internal energy by\nefficiently absorbing energy from the larger system. This process of resonance not only facilitates a\nmore significant energy transfer but also exemplifies how strategic alignment with external forces can\nlead to an advantageous increase in a system's internal energy reserves.\nIn educational contexts, resonance is typically discussed with reference to the impact of periodic\nexternal forces on harmonic (linear) oscillators, with its practical uses often confined to tasks involving\nfrequency matching. Yet, the concept of resonance encompasses a far wider scope than these specific\ninstances suggest. To explore this, consider the learner as a mechanical system interacting with its\nenvironment via a dynamic variable, labeled here as the position variable x. Classical mechanics tells us\nthat the change in the system's internal energy over time, dt, is dictated by the mechanical work done\nby an external force f acting on x within that timeframe. This work is quantified by the equation: \\(E =\nf dx\\), where dx is the change in x over dt. Dividing both sides of this equation by dt yields \\(dE/dt = fv\\),\nwith v representing the system's velocity. It's clear from this formulation that for the learner to augment\nits energy, the product of the external force and the system's velocity, represented on the right side of\nthe equation, must remain positive. Given that both f and v vary over time, maintaining the positivity of\nthis product necessitates that the system's velocity v aligns or synchronizes with the external force f,\nmeaning their behaviors should mirror each other. Symbolically, this can be denoted as: \\(v ~ f\\).\nTermed the 'resonance condition,' this relationship offers a straightforward strategy for smaller systems\nto harness energy from larger ones, such as the external environment. Achieving this requires the\nsystem to emulate the behavior of the external force f through one of its internal variables, like velocity\nv, effectively adopting a resonance-based approach to energy extraction."}, {"title": "5. Discussion and the Next Steps", "content": "The core idea we have endeavored to convey in this article is the reconceptualization of learning as a\nform of resource-seeking behavior. Generally, the distinction between seeking knowledge and resources\nis largely semantic, as knowledge is often regarded as a resource. However, in our context, this\ndistinction takes on a unique significance. By saying that the motivation of systems to learn can be\nexplained through the motivation of having more resource, we do not mean a generic and typically\nvague concept of resource but rather its very tangible and quantifiable form: the energy. This\nperspective is critical, because it allows us to understand the dynamics of learning through dynamics\ndescribable within the laws of physics, providing an alternative framework for exploring the\nphenomenon of learning. This obviously complements traditional approaches in AI/ML, neuroscience,\nand psychology. Within this purely physical framework, the term 'motivation' obviously transcends its\nmetaphorical usage, approaching a nearly physical concept that describes the forces driving open\nsystems (learners) to interact with their environments (teachers) in manners akin to learning.\nTranslating the learning process from the domain of information to that of physics underscores its\ninherently dynamic character. A pivotal aspect of this dynamism and its driving force is that any\nsuccessful learning act-such as the accurate internal reproduction of external patterns-is immediately"}, {"title": "Appendix. Collective Perception in Parroting Autoencoders", "content": "In this appendix, we explore a scenario where multiple parroting autoencoders communicate to 'discuss'\ntheir observations of an external object or event, F. Our focus is on the mechanism through which an\nobjective image of this event, which we denote as Obj(F), emerges from the subjective images\ngenerated by each autoencoder.\nConsider a certain large set of autoencoder agents A\u2081, each equipped with an encoder-decoder pair\n{Ei, Di}, i = 1, ..., N\nand assume that all receive an external signal F. Each agent generates an internal visual image of F\nrepresented by\nfi = EiF, i = 1, ..., N\nThese visual images are inherently private and subjective, thus not directly sharable. However, the\nagents can respond to F by generating an audio signal through their audio decoder, transforming the\ninternal visual signal:\nFi = Difi = DiEiF, i = 1, ..., N\nSubsequently, each agent receives two types of secondary signals: one from itself:\nfii = EiFi = EiDiEiF, i = 1, ..., N\nand others from the rest of the agents:\nfik = EiFk = EiDkEkF, i, k = 1, ..., N, i \u2260 k\nThrough the \"parrot effect,\" agents adjust their decoder parameters to align their own secondary signals\nwith those from others, aiming for:\nEiDiEiF \u2248 EiDkEkF, i \u2260 k\nOnce this iterative process converges, the distinctions between the signals diminish, leading to a\nuniform perception by all agents. If the number of agents is sufficiently large, the average\nObj (F) = Avg{ik}(EiDkEkF)\nserves as an objective representation of the original signal F, illustrating how collective interaction\namong parroting autoencoders can lead to a shared, objective understanding of an observed\nphenomenon."}]}