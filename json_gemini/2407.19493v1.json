{"title": "OFFICIAL-NV: A NEWS VIDEO DATASET FOR MULTIMODAL FAKE NEWS DETECTION", "authors": ["Yihao Wang", "Lizhi Chen", "Zhong Qian", "Peifeng Li"], "abstract": "News media, especially video news media, have penetrated into every aspect of daily life, which also brings the risk of fake news. Therefore, multimodal fake news detection has recently received more attention. However, the number of fake news detection data sets for video modal is small, and these data sets are composed of unofficial videos uploaded by users, so there is too much useless data. To solve this problem, we present in this paper a dataset named Official-NV, which consists of officially published news videos on Xinhua. We crawled videos on Xinhua, and then extended the data set using LLM generation and manual modification. In addition, we benchmarked the data set presented in this paper using a baseline model to demonstrate the advantage of Official-NV in multimodal fake news detection.", "sections": [{"title": "1. INTRODUCTION", "content": "With the video-oriented trend of news media and the rise of video platforms, multimodal fake news has become increasingly prevalent, mixing text, images, and videos to mislead the public. Detecting fake news videos via human beings only is labor-intensive and inefficient, which is insufficient for the the large number of emerging video platforms. Multimodal fake news detection (MFND) aims to detect such fake information by using advanced techniques like natural language processing and computer vision. By analyzing multiple media modalities, we can more accurately identify and flag fabricated news, enhancing the reliability of online content.\nThere have been several attempts to apply deep learning techniques to the task of multimodal fake news detection. Some existing MFND datasets include FVC-2018[1], VAVD[2], COVID-VTS[3], and FakeSV[4]. Papadopoulou et al.[1] presented an annotated dataset of user-generated videos, including debunked and verified videos along with their near-duplicate reposted versions, and conducts automatic verification experiments to establish a baseline for future comparisons. Liu et al.[3] presented a dataset called COVID-VTS, which contains 10k English videos posted by verified users"}, {"title": "2. THE OFFICIAL-NV DATASET", "content": "In this section, we will introduce Official-NV from three aspects: (1) data collection, (2) data processing, (3) data distribution."}, {"title": "2.1. DATA COLLECTION", "content": "videos of most of other datasets are collected from user generated content platforms such as Tiktok, Twitter and Youtube.\nThese platforms have less official content, so their credibility is not enough. Therefore, we choose Xinhua as our target platform for obtaining videos. Xinhua is a comprehensive news information service portal hosted by the news agency Xinhuashe. It is the most influential online media in China and a multi-language website with global influence. Specifically, we used web crawler technology to obtain news videos from 2021 to 2024 under Xinhua's 'China', 'World' and 'others' three categories, and then we manually checked and removed some videos that were too short in duration or had repetitive content. A total of 2,500 news videos were kept and classified as 'True Origin' (OT). Each video consists of the title, speech text and video frame three modal of information. As part of the videos has no dubbing, their speech text is empty. The information contained in the three modal of video in the OT category is consistent."}, {"title": "2.2. DATA PROCESSING", "content": "After collecting 2,500 OT news videos, we processed this data using LLM to generate fake news data and expand on real news data.\nTitle and Speech Text. For the text content, we leverage ChatGPT to generate new data. Specifically, we provide prompt to ChatGPT, asking it to change the provided text to the same or completely different meaning from one of the angle of direction, position, quantity, action, object and time change. After that, we manually check the generate errors due to too long text or generate poor content and modify them. Changing the Title to the same or completely different meaning are classified as 'True Title' (TT) and 'Fake Title'(FT). Changing the speech text to the same or completely different meaning are classified as 'True Speech'(TS) and 'Fake Speech'(FS). Table 1 shows some examples of the data after large model generation and manual modification.\nVideo Frame. When generating incorrect video frame data, we replace all video frames of one video with video frames of another similar video by comparing the cosine similarity of two videos[5]. These data is classified as 'Fake Frame' (FF).\nFor each video, we obtained TO, TT, TS, FT, FS, FF six categories of data. Then we randomly selected two True and two Fake data from them, forming a total of 10,000 data entries as our final dataset."}, {"title": "2.3. DATA DISTRIBUTION", "content": "The Official-NV consists of 10,000 news Video data, of which 800 videos contain the Title, Speech Text and Video Frame modal, and 1700 videos contain the Title and Video Frame modal. There are 5000 pieces of real news and fake news, of which the number of categories is TO: 1500, TT: 2500, TS: 1000, FT: 2167, FS: 650, FF: 2183. News is obtained from three divisions of Xinhua: CHINA, THE WORLD, and OTHERS, with a total of 3,392, 3,176, and 3,432. Fig. 2 shows the distribution of news videos and Table 2 shows the comparison of datasets for MFND."}, {"title": "3. EXPERIMENTS", "content": "We benchmarked with bart[6] on the proposed Official-NV. In order to reduce random bias, we measured the model with 5-fold cross-validation. The results in which all three modal are entered into the model are 0.1 points higher than the results in which separate title features are entered into the model. Before training, we first used bart to extract the features of text information and video frame image information respectively, and adopted Normal scheme to initialize the new layer. We trained the models with the AdamW[7] optimizer and categorical crossentropy loss function, and the title, title and speech text, title and frames, frames and speech text, and all modal information were separately input into 10,000 data sets for experiments. Accuracy, F1 value, accuracy and regression value were used as evaluation indexes to evaluate their performance."}, {"title": "3.2. RESULTS", "content": "Table 3 shows the results of the baseline model inputting different modal information on the Official-NV, from which we can draw the following conclusions: 1) When inputting the features of all modal, the accuracy reaches 0.775, which is a very impressive result. 2) The title features contain the most important information, and the accuracy rate is 0.679 when only the title features are input, which is higher than 0.566 when the speech text features and frames features are input at the same time. 3) The performance of the model will be improved after new modal features are added, so more modal information of the video needs to be developed. This provides an opportunity for subsequent research on MFND."}, {"title": "4. CONCLUSION", "content": "In this paper, we propose a video dataset for multimodal fake news detection. We used crawler technology to crawl the public news videos on Xinhua, and extended the dataset by LLM generation and manual modification. Then, we analyze the object distribution on the dataset and conduct a large number of experiments to show the performance of the baseline method on the dataset. By comparing the experimental results, we find that the performance of the model is significantly better when information of all three modalities is utilized compared to using a single modality. In the future, we will continue to investigate more promising and approachable methods to improve the prediction effect on this dataset. We hope this dataset can bring more development to the research of multimodal fake news detection."}]}