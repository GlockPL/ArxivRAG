[{"title": "INTRODUCTION", "authors": ["Ermis Soumalias", "Jakob Heiss", "Jakob Weissteiner", "Sven Seuken"], "abstract": "We study the design of iterative combinatorial auctions (ICAs). The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, several papers have recently proposed machine learning (ML)-based preference elicitation algorithms that aim to elicit only the most important information from bidders to maximize efficiency. The SOTA ML-based algorithms elicit bidders' preferences via value queries (i.e., \u201cWhat is your value for the bundle {A, B}?", "At prices p, what is your most preferred bundle of items?": ".", "impact.": "sections", "content": "Combinatorial auctions (CAs) are used to allocate multiple items among several bidders who may view those items as complements or substitutes. In a CA, bidders are can submit bids for whole bundles/packages of items. CAs have enjoyed widespread adoption in practice, with their applications ranging from allocating spectrum licences (Cramton, 2013) to TV ad slots (Goetzendorff et al., 2015) and airport landing/take-off slots (Rassenti et al., 1982).\nThe key challenge in CAs is that the bundle space grows exponentially in the number of items, making it impossible for bidders to report their full value function in all but the smallest domains. Moreover, Nisan & Segal (2006) showed that for arbitrary value functions, CAs require an exponential number of bids in order to guarantee full efficiency. Thus, practical CA mechanisms cannot provide efficiency guarantees in real world settings with more than a modest number of items. Instead, the focus has shifted towards iterative combinatorial auctions (ICAs), where bidders interact with the auctioneer over a series of rounds, providing only a limited (i.e., practically feasible) amount of information, with the aim to maximize the efficiency of the final allocation."}, {"title": "1.1 ML-POWERED ITERATIVE COMBINATORIAL AUCTIONS", "content": "To address this challenge, researchers have proposed various ways of using machine learning (ML) to improve the efficiency of ICAs. The seminal works by Blum et al. (2004) and Lahaie & Parkes (2004) were the first to frame preference elicitation in CAs as a learning problem. In more recent years, Brero et al. (2018; 2021), Weissteiner & Seuken (2020); Weissteiner et al. (2022b;a; 2023) proposed ML-powered ICAs. At the heart of those approaches lies an ML-powered preference elicitation algorithm that uses an ML model to learn each bidder's value function to generate an informative value query (i.e., \u201cWhat is your value for the bundle {A, B}?\u201d), which in turn refines that bidder's ML model.\nWhile those value-query based ML-powered ICAs lead to significant efficiency gains redefining the state-of-the-art (SOTA) efficiency results in many realistic auction domains, those approaches suffer from one common practical limitation: they fundamentally rely throughout the whole ICA on value queries (VQs). Prior research in auction design has identified demand queries (DQs) as the best way to run an auction (Cramton, 2013). Their advantages compared to value queries include elimination of tacit collusion and bid signaling, as well as simplified bidder decision-making that keeps the bidders focused on what is most relevant: the relationship between prices and aggregate demand. Additionally, value queries are cognitively complex, and thus typically should be only used sparsely in real-world ICAs. For these reasons, DQs are the most prominent interaction paradigm for auctions in practice. Following this rationale, Soumalias et al. (2024b) addressed the common limitation of prior work by designing the first practical ML-powered ICA that elicits information from bidders via DQs instead of VQs and only makes use of VQs in supplementary rounds, when bidders have already obtained a clearer picture on which bundles they can realistically hope to clinch and how much they should approximately value such bundles.\nWhile this DQ-based ICA represented a significant leap towards making ML-powered ICAs practical and at the same time outperformed the baseline CCA that is typically used in real-world applications, it still suffered from the following two important deficiencies: First, it could not reach the SOTA efficiency of the impractical VQ-based ML-powered ICAs. Second, to improve efficiency, just like the CCA, it required the use of a supplementary round, in which the bidders must decide on which additional value bids to submit to the mechanism, a cognitive complicated task for the bidders.\nThe present paper closes these two last gaps in the realm of ICAs by designing a hybrid ML-powered ICA that combines DQ-based rounds with a sophisticated yet practical VQ-based supplementary round. Importantly, this hybrid ML-powered ICA clearly outperforms the previous SOTA ICA while still being practical in real-world applications."}, {"title": "1.2 OUR CONTRIBUTIONS", "content": "In this paper, we introduce the Machine Learning-powered Hybrid Combinatorial Auction (ML-HCA), a practical ICA that achieves unprecedented efficiency. Our contributions are as follows:\n1. In Section 3, we provide a theoretical foundation and illustrative examples that demonstrate the advantages and limitations of DQs and VQs as input mechanisms for auctions and learning algorithms.\n2. In Section 4, we introduce a learning algorithm capable of leveraging both types of queries. We provide strong experimental evidence of the learning benefits of combining both query types, as well as the advantages of starting an auction with DQs instead of VQs.\n3. In Section 5 we combine our auction and ML insights to develop MLHCA, the first ICA to incorporate both sophisticated DQ and VQ generation algorithm. Simulations in realistic domains show that MLHCA significantly outperforms the previous SOTA, achieving higher efficiency with 40% fewer queries (Section 6), setting a new benchmark for both efficiency and practicality."}, {"title": "1.3 FURTHER RELATED WORK", "content": "In the field of automated mechanism design, D\u00fctting et al. (2015; 2019), Golowich et al. (2018) and Narasimhan et al. (2016) used ML to learn new mechanisms from data, while Cole & Roughgarden (2014); Morgenstern & Roughgarden (2015) and Balcan et al. (2023) bounded the sample complexity of learning approximately optimal mechanisms. In contrast to this prior work, our design incorporates an ML algorithm into the mechanism itself, i.e., the ML algorithm is part of the mechanism. Lahaie & Lubin (2019) suggest an adaptive price update rule that increases price expressivity as the rounds progress in order to improve efficiency and speed of convergence. Unlike that work, we aim to improve preference elicitation in the main rounds while still using linear prices. Preference elicitation is a key market design challenge outside of CAs too. Soumalias et al. (2024a) introduce an ML-powered mechanism for course allocation that improves preference elicitation by asking students comparison queries.\nDespite the prominence of DQs in real-world applications, the only prior work apart from Soumalias et al. (2024b) on ML-based DQs that we are aware of is that of Brero & Lahaie (2018) and Brero et al. (2019), who proposed integrating ML in a price-based ICA to generate the next price vector in order to achieve faster convergence. However, this prior work does not exploit any notion of similarity between bundles that contain overlapping items, only incorporates a fraction of the information revealed by the agents' bidding (i.e., for the bundle an agent bids on, her value for that bundle must be larger than its price), and is computationally intractable already in medium-sized auction domains. See Appendix D for further related work."}, {"title": "1.4 PRACTICAL CONSIDERATIONS AND INCENTIVES", "content": "MLHCA integrates both ML-powered DQ and VQ rounds. In DQ-based auctions like the CCA or ML-CCA, ensuring truthful bidding depends heavily on well-chosen activity rules and payment rules. In Appendix A.3, we provide a detailed discussion of the most common activity rules used in the CCA to align incentives, and detail how MLHCA can also leverage these rules to achieve the same goal.\nThe VQ rounds in MLHCA extend the MLCA framework (Brero et al., 2021) by incorporating information from earlier DQ rounds into bidders' ML models. Brero et al. (2021) argued that MLCA offers strong practical incentives, and under two additional assumptions, truthful bidding is an ex-post Nash equilibrium. In Appendix A.4 we provide a detailed discussion of these arguments, and detail why they also apply to MLHCA's VQ rounds.\nBy effectively combining activity rules in the DQ rounds and leveraging the established incentive structure of MLCA in the VQ rounds, MLHCA achieves a robust incentive alignment across all its stages."}, {"title": "2 PRELIMINARIES", "content": ""}, {"title": "2.1 FORMAL MODEL FOR ICAS", "content": "We consider multiset CA domains with a set $\\mathcal{N} = \\{1, ..., n\\}$ of bidders and a set $\\mathcal{M} = \\{1, ...,m\\}$ of distinct items with corresponding capacities, i.e., number of available copies, $c = (c_1, . . . , c_m) \\in \\mathbb{N}^m$."}, {"title": "3 ADVANTAGES OF DQS AND VQS AND WHY ONE SHOULD COMBINE THEM", "content": "In this section, we examine the limitations of using only VQs or only DQs in auctions and highlight the benefits of combining them. All deferred proofs can be found in Appendix E."}, {"title": "3.1 DISADVANTAGES OF ONLY USING VQS", "content": "Almost all ML-powered VQ-based auctions including the current SOTA, BOCA (Weissteiner et al., 2023) first ask each bidder multiple random VQs (i.e., VQs for randomly selected bundles). These VQs are necessary to initialize the ML estimates of the bidder's value functions. In practice, it is very hard for bidders to answer random VQs since they are not aligned with their preferences. The most popular ICAs in practice (e.g., the CCA) ask the bidders DQs, which have been argued can be answered by the bidders sufficiently well (Cramton, 2013).\nEven if bidders manage to respond perfectly to random VQs, the information obtained is limited. This is because, in large combinatorial domains, bidders typically have high values for only a small subset of possible bundles, making the probability of querying one of these high-value bundles at random exceedingly low. On the other hand, querying bidders with DQs at a random price vector is more likely to prompt responses that reveal their high-value bundles. Formally:\nLemma 1. The difference in expected social welfare between an auction that uses a single random demand query and an auction that uses $k < 2^m$ random value queries can be arbitrarily large.\nRemark 1. This limitation of random VQs is evidenced in practice. Empirical comparisons between VQ-based ML-powered mechanisms, such as Weissteiner et al. (2023), and DQ-based mechanisms, such as Soumalias et al. (2024b), reveal that efficiency after initial queries is significantly lower for VQ-based approaches across all tested domains (see Figure 4 in Section 6).\nBeyond auction efficiency, the limited information provided by random VQs poses challenges for learning algorithms in ML-powered ICAS. In contrast, DQs provide global information about bidder preferences across the entire bundle space. When bidder i responds to a DQ at prices p, she solves the optimization problem: $x(p) \\in \\arg \\max_{x\\in X} \\{v_i(x) \u2013 \\langle p, x\\rangle\\}$, which reveals valuable information about her preferences across all possible bundles. Strong evidence for this is presented inSection 4.2, where we show that the network trained only on DQs exhibits better generalization performance than one trained on random VQs.\nAdditionally, if DQ prices are sufficiently low, bidders respond with their value-maximizing bundles, which may be hard to recover through VQs alone. By incorporating this information, the learning algorithm can more effectively identify critical regions in the allocation space and subsequently focus on refining those areas. This advantage is further supported by our experiments (Figure 4 in Section 6). We show that in our ML-powered hybrid auction, the first ML-powered VQ after a series of DQs achieves significantly higher efficiency compared to the first ML-powered VQ after an equivalent number of random VQs in the current SOTA VQ-based auction.\nMoreover, even if the auction finds an efficient allocation by using VQs, it cannot terminate early as there is no way for the auctioneer to certify that the auction has reached 100% efficiency. In contrast, for DQ-based auctions there is an easy condition that allows the auction to terminate early:\nProposition 1. If clearing prices exist, an auction using DQs can provide a guarantee of optimal efficiency and terminate early.\nProof. If clearing prices have been found, the corresponding allocation constitutes a Walrasian equilibrium, and thus has an efficiency equal to 100%. See (Soumalias et al., 2024b, Appendix C.1) for a detailed proof.\nRemark 2. This is indeed an issue in practice. In Section 6, we experimentally show that, in realistic domains, our MLHCA can often reach 100% efficiency before the common maximum number of 100 rounds used by most ML-powered ICAs (e.g. Weissteiner & Seuken (2020); Weissteiner et al. (2022b;a; 2023); Soumalias et al. (2024b)) is reached."}, {"title": "3.2 DISADVANTAGES OF ONLY USING DQS", "content": "In this section, we show the disadvantages of using DQs to elicit the bidders' preferences.\nThe first major disadvantage of an auction employing only DQs is that the auction's efficiency can actually drop by adding more DQs.\nLemma 2. In a DQ-based ICA, adding DQs can actually reduce efficiency. A single DQ can cause an efficiency drop arbitrarily close to 100%. By comparison, in a VQ-based ICA, adding additional queries can never reduce efficiency (assuming truthful bidding).\nProof. Let $m = 2, n = 2, c_1 = 1, c_2 = 1$,\n$\\begin{aligned}\nv_1 &= \\max \\{400 \\cdot \\mathbb{I}_{\\{x_1 \\geq 1\\}}, 2 \\cdot \\mathbb{I}_{\\{x_2 \\geq 1\\}} \\} \\text{ and }\\\\\nv_2 &= 1.1 \\cdot \\mathbb{I}_{\\{x_1 \\geq 1\\}}.\n\\end{aligned}$\nSuppose the auction has asked two DQs. The first DQ $p = (1,1)$ is responded by both bidders with $(1,0) \\in \\arg \\max_{x\\in X} \\{v_i(x) \u2013 \\langle p, x \\rangle\\}$. The second DQ $p = (1.2, 1)$ is responded by bidder 1 with $(1,0) \\in \\arg \\max_{x\\in X} \\{v_1(x) \u2013 \\langle p, x \\rangle\\}$ and by bidder 2 with $(0,0) \\in \\arg \\max_{x\\in X} \\{v_2(x) \u2013 \\langle p, x \\rangle\\}$.\nAfter these 2 DQs the WDP based on the inferred values (see Equation (3)), would assign item 1 to bidder 1 (resulting in an inferred social welfare of 1.2 + 0 = 1.2). This is the efficient allocation with a true SCW of 400, i.e., an efficiency equal to 100%.\nNow suppose that a third DQ $p = (401,1)$ is added to the auction. Bidder 1's demand response is $(0,1) \\in \\arg \\max_{x\\in X} \\{v_1(x) \u2013 \\langle p, x \\rangle\\}$ and bidder 2's response is $(0,0) \\in \\arg \\max_{x\\in X} \\{v_2(x) \u2013 \\langle p, x \\rangle\\}$. The WDP would now assign item 2 to bidder 1 and item 1 to bidder 2, resulting in an inferred SCW of 1+1 = 2). This would result only in an efficiency of $\\frac{2+1.1}{400} < 1\\%$.\nWhile the inferred SCW obviously cannot decrease in any round (since the set we maximize over cannot decrease in any round and inferred values cannot decrease), we have shown here that the true SCW can decrease substantially. In this example, the SCW dropped by more than 99%. One could easily modify this example to even obtain an efficiency drop arbitrarily close to 100% if one decreases the values 1, 1.2 and 2 (the prices and the values inside the value functions) by any small factor or increases the numbers 400 and 401, by any large factor. Then the proof would still work, which shows that the efficiency can even fall from 100% to values arbitrarily close to 0%."}, {"title": "3.3 THE ADVANTAGES OF COMBINING DQS AND VQS", "content": "DQs are cognitively simpler than VQs early in the auction. All ML-powered, VQ-based ICAs in the literature begin by asking bidders their values for uniformly at random selected bundles to initialize the ML models. In contrast, the SOTA ML-powered DQ-based approach (Brero & Lahaie, 2018; Brero et al., 2019; Soumalias et al., 2024b) starts by asking bidders for their preferred bundles at low initial prices that gradually increase over rounds. From a practical standpoint, it is nearly impossible for bidders to accurately assess VQs for randomly chosen bundles, whereas responding to DQs with low prices is far easier. As the auction progresses and the bidders' ML models become more accurate, a VQ-based ML-powered ICA can ask targeted VQs that align better with bidder interests, making them easier to answer.\nDQs are more effective in the early stages of the auction. Initially, the auctioneer lacks knowledge of which bundles align with bidders' interests. Beginning with DQs allows the auctioneer to gather early insights about the bidders' preferences over the whole bundle space, facilitating the use of more targeted queries later on. This practice is well-established in the combinatorial auction community. For instance, the initial DQ phase in the CCA is often referred to as a \u201cprice discovery phase\" (Ausubel et al., 2006). We argue that the same concept holds even in ML-powered auctions. Our experiments in Section 6 confirm that DQ-based approaches (e.g., ML-CCA (Soumalias et al., 2024b)) outperform VQ-based approaches (Weissteiner & Seuken, 2020; Weissteiner et al., 2022b;a; 2023) during the early rounds of the auction. However, as suggested by Theorem 1 and Lemma 5, VQ-based approaches eventually surpass DQ-based mechanisms in later iterations.\nA key contributing factor as to why VQ-based ML-powered approaches perform better than DQ-based approaches is that they can take into account the WDP, i.e., the downstream optimization problem that will determine the final allocation. In contrast, responses to a single DQ often lead to over-demand for certain items or leave some items unassigned (under-demand). In Example 1, bidder 2 lacks information to know she should bid for 9 items. Only the auctioneer, having information from all bidders, knows that assigning 9 items to bidder 2 would complement bidder 1's preferences. The auctioneer can leverage this aggregated knowledge by asking bidder 2 a VQ for 9 items, whereas DQs alone would not provide this opportunity.\""}, {"title": "4 MIXED QUERY LEARNING", "content": "In this section, we introduce our mixed training algorithm and provide experimental evidence supporting our theoretical analysis from Section 3. Specifically, we demonstrate the learning benefits of initializing auctions with DQs rather than VQs and highlight how combining DQs with VQs leads to superior learning performance."}, {"title": "4.1 MIXED TRAINING ALGORITHM", "content": "To leverage the advantages of both DQs and VQs, we propose a two-stage training algorithm. In each epoch, the ML model is first trained on all DQ responses using the loss function from (Soumalias et al., 2024b). The main idea behind this loss is that for each DQ, an optimization problem is solved to predict the bidder's utility-maximizing bundle at the given prices, treating her ML model as her true value function. In case the predicted reply disagrees with the bidder's true reply, the loss is the difference in predicted utilities between these 2 bundles. This loss provably incorporates the full information that the DQ responses provide. Then, the model is trained on the VQ responses using a standard regression loss. For more details, see Appendix F."}, {"title": "4.2 EXPERIMENTAL ANALYSIS", "content": "In this section, we demonstrate the learning benefits of initializing auctions with DQs rather than VQs and highlight how combining both query types leads to superior learning performance.\nWe conduct the following experiment: We perform hyperparameter optimization (HPO) to train an mMVNN for the most critical bidder type in the most realistic domain-the national bidder in the MRVM domain. In Appendix G we present the same experiment for all other domains. Our HPO procedure is the following. For a single bidder of that type, we generate three distinct training sets:\n1. The first training set contains 40 DQs simulating 40 CCA clock rounds, along with 20 VQs for bundles chosen uniformly at random."}, {"title": "5 THE MECHANISM", "content": "In this section, we describe our ML-powered Hybrid Combinatorial Auction (MLHCA), which combines the auction and ML insights of how to combine DQs and VQs from Sections 3 and 4.\nWe present a simplified version of MLHCA in Algorithm 1. In Lines 3 to 6, we generate the first $Q^{QCCA}$ DQs using the same price update rule as the CCA (with larger price increments). In each of the next $Q^{DQ} \\in \\mathbb{N}$ ML-powered rounds, we first train, for each bidder, an mMVNN on her demand responses (Line 9). Next, in Line 10, we call NEXTPRICE (Soumalias et al., 2024b) to generate the next DQ based on the agents' trained mMVNNs (see Appendix C). If MLHCA has found market-clearing prices, then the corresponding allocation is efficient and is returned, along with payments $\\pi(R)$ according to the deployed payment rule (Line 16). MLHCA is plug-and-play compatible with many different payment rules. If, by the end of the ML-powered DQs the market has not cleared we switch to VQ rounds. In the first VQ round (Line 18) we ask each bidder for her bridge bid (see Definition 4). This single VQ bid ensures that the MLHCA's efficiency is lower bounded by the efficiency after just the DQ rounds (Lemma 4). In the final $Q^{VQ} \u2013 1$ VQ rounds, for each bidder, we query her her value for the bundle she is allocated in the predicted optimal allocation (based on all ML models), under the constraint that she has not answered a VQ for that bundle in the past. The final allocation and payments are then determined based on all reports (Lines 25 to 26). Note that ML-CCA can be combined with various possible payment rules $\\pi(R)$, such as VCG or VCG-nearest. We present the detailed description of the mechanism in Appendix H."}, {"title": "6 EXPERIMENTS", "content": "In this section, we experimentally evaluate MLHCA. We compare its efficiency against BOCA (Weissteiner et al., 2023) and ML-CCA (Soumalias et al., 2024a) the SOTA VQ-based and DQ-based ICAs, respectively."}, {"title": "6.1 EXPERIMENT SETUP", "content": "To generate synthetic CA instances, we use the spectrum auction test suite (SATS) (Weiss et al., 2017). SATS gives us access to the true optimal allocation $a^* \\in F$, which we use to measure the efficiency loss, i.e., 1 \u2013 V(a*)/V(a*(R)) when eliciting reports R. As in all mechanisms we compare against (e.g. (Soumalias et al., 2024b; Weissteiner et al., 2023)), we focus of efficiency (and not revenue). The main application of ICAs is in spectrum allocation, a government-run operation with a mandate to maximize welfare (Cramton, 2013). See Appendix J for a discussion of the corresponding results on revenue. To enable a fair comparison against prior work, we use 100 total queries for all auction mechanisms. Those are 100 VQs for BOCA, 100 DQs for ML-CCA, and 40 DQs and 60 VQs for MLHCA. For BOCA and ML-CCA, we use the best mechanism configuration and hyperparameters as reported in their corresponding papers.\nFor MLHCA's VQ rounds, we performed HPO separately for each bidder type in each domain, as detailed in Section 4.2. For the DQ rounds, we adopted the HPO parameters reported by Soumalias et al. (2024b), since our learning algorithm, when restricted to DQs, is equivalent to theirs. For further details, please refer to Appendix K.1."}, {"title": "6.2 EVALUATING THE EFFECTIVENESS OF THE BRIDGE BID", "content": "In this section, we experimentally evaluate the effectiveness of the bridge bid from Section 3.\nIn Figure 2a, we plot MLHCA's efficiency in the MRVM domain as a function of the number of elicited bids, comparing performance with and without the bridge bid. Without the bridge bid, we observe a significant efficiency drop of 7.3% points when MLHCA transitions to its VQ rounds. This"}, {"title": "6.3 EFFICIENCY RESULTS", "content": "In this section, we present the efficiency of MLHCA, comparing its performance against the current alternatives discussed in Section 2.2. These results build on the theoretical insights discussed in Sections 3 and 4, showcasing both the advantages of starting with DQs and the efficacy of our hybrid approach.\nIn Table 2, we show the average efficiency loss of each mechanism after 100 queries. For ML-CCA, we also report results if it were supplemented with the clock bids raised heuristic (see Section 2.2), which would involve up to an additional 100 VQs per bidder. Finally, we report the number of queries that MLHCA requires to outperform the final efficiency of each other mechanism, i.e., in GSVM, with 42 queries (40 DQs and 2 VQs) MLHCA statistically outperforms ML-CCA, even if ML-CCA were supplemented with 100 VQs from the clock bids raised heuristic.\nIn Table 2, we observe that across all domains, MLHCA significantly outperforms all other mechanisms. First, MLHCA is the only mechanism that can achieve a perfect 100% efficiency in SRVM. As a matter of fact, it can do this using less than 60 queries, while the other auctions cannot do that even with 100 queries. In the LSVM domain, MLHCA achieves a 10-fold reduction in efficiency loss compared to BOCA, the previous SOTA. But the most realistic domain is MRVM, designed to simulate the data from the 2014 Canadian spectrum auction (Weiss et al., 2017). In that domain, MLHCA is the first mechanism to cause a significant efficiency increase versus the CCA, increasing efficiency compared to all other mechanisms by over 2.5% points. If MLHCA were used in the latest Canadian Spectrum Auction, based on the value of goods traded (Innovation, Science and Economic"}, {"title": "7 CONCLUSION", "content": "We have introduced MLHCA, the first ICA that combines ML-powered VQ and DQ generation algorithms. MLHCA provably incorporates the full information that both query types provide, and leverages the theoretical and practical insights developed in this work to combine these queries effectively and achieve unprecedented efficiency-clearly surpassing current SOTA mechanisms.\nOur results demonstrate that MLHCA consistently outperforms previous SOTA mechanisms across all tested domains, achieving substantial efficiency gains with significantly fewer queries. Notably, MLHCA reduces efficiency loss by up to a factor of 10 compared to the previous SOTA while surpassing all previous mechanisms with at most 74% of their queries. In the most realistic domain, MLHCA's efficiency gains translate into welfare improvements exceeding 50 million USD in a single auction instance. Importantly, MLHCA achieves these gains while simplifying bidder participation: compared to the previous SOTA VQ-based mechanism, MLHCA primarily relies on the more practical DQs, requiring only a few cognitively demanding VQs to reach similar efficiency levels. Compared to the SOTA DQ-based mechanism, MLHCA can achieve equivalent efficiency with just 40% of the DQs and only two VQs in most domains, eliminating the need for a supplementary round and thus streamlining the bidding process.\nIn conclusion, by effectively integrating both query types, MLHCA sets a new benchmark in both allocative efficiency and speed of convergence. This work lays the foundation for future combinatorial auction designs, where ML techniques not only enhance efficiency but also simplify the bidding process, ultimately increasing bidder participation and thus impact potential."}, {"title": "B A MACHINE LEARNING-POWERED ICA", "content": "In this section, we present in detail the machine learning-powered combinatorial auction (MLCA) by Brero et al. (2021).\nAt the core of MLCA is a query module (Algorithm 2), which, for each bidder $i \\in \\mathcal{I} \\in \\mathcal{N}$, determines a new value query $q_i$. First, in the estimation step (Line 1), an ML algorithm $A_i$ is used to learn bidder $i$'s valuation from reports $R_i$. Next, in the optimization step (Line 2), an ML-based WDP is solved to find a candidate $q$ of value queries. In principle, any ML algorithm $A_i$ that allows for solving the corresponding ML-based WDP in a fast way could be used. Finally, if $q_i$ has already been queried before (Line 4), another, more restricted ML-based WDP (Line 6) is solved and $q_i$ is updated correspondingly. This ensures that all final queries $q$ are new."}, {"title": "C ML-POWERED DEMAND QUERY GENERATION", "content": "In this section"}, 8, 9, 11, 2, 2002, 3.1, "definitions", 2, 2024, 10, 11, "v)", 2, 2002, ".", 2, 10, "following", "M^i", "R_"]