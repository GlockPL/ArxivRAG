{"title": "Applying Conditional Generative Adversarial Networks for Imaging Diagnosis", "authors": ["Haowei Yang", "Yuxiang Hu", "Shuyao He", "Ting Xu", "Jiajie Yuan", "Xingxin Gu"], "abstract": "This study introduces an innovative application of Conditional Generative Adversarial Networks (C-GAN) integrated with Stacked Hourglass Networks (SHGN) aimed at enhancing image segmentation, particularly in the challenging environment of medical imaging. We address the problem of overfitting, common in deep learning models applied to complex imaging datasets, by augmenting data through rotation and scaling. A hybrid loss function combining L1 and L2 reconstruction losses, enriched with adversarial training, is introduced to refine segmentation processes in intravascular ultrasound (IVUS) imaging. Our approach is unique in its capacity to accurately delineate distinct regions within medical images, such as tissue boundaries and vascular structures, without extensive reliance on domain-specific knowledge. The algorithm was evaluated using a standard medical image library, showing superior performance metrics compared to existing methods, thereby demonstrating its potential for enhancing automated medical diagnostics through deep learning", "sections": [{"title": "I. INTRODUCTION", "content": "Intravascular ultrasound (IVUS) is an important method in the diagnosis and intervention of coronary artery disease. The extraction and identification of the boundary between the endovascular intima (LU) and the meso-outer membrane (MA) is the key to accurately evaluate the difficult lesions of coronary artery imaging and to intervene in coronary heart disease. In practical application, endovascular ultrasound imaging of the intima and the meso-outer membrane has a rich theoretical basis and rich clinical experience for doctors. The critical edge of intravascular ultrasound images is subjective and easy to be affected by artifacts and other perturbations. The analysis of images with several to one hundred frames is time-consuming and difficult to reproduce. The subjective judgment errors between and within physicians can be effectively eliminated, the image artifacts and disturbance effects can be reduced, and the time of diagnosis and treatment can be shortened. It is of great theoretical and practical value for the diagnosis and treatment of congenital heart disease to study the method of detecting the edge of the middle and outer membrane of the coronary artery.\nMost existing algorithms can be divided into three aspects. The first type is based on direct detection and mining low- level features, including graph search, active contour, and graph-cutting algorithms. This method has a great effect on calcium plaques in intravascular ultrasound images. The second is based on statistics and probability, using the optimal energy equation and the probability of the region of the largest possible pixel to obtain the optimal edge geometry. However, the influence of intravascular ultrasound shadow, vascular bifurcation and fibrous plaque often leads to the local extreme value of its evolution curve, resulting in huge protrusions or pits between the intima or meso-outer membrane [10]. The third stage is based on machine learning and consists of two stages: hand- set feature extraction and classifier optimization[11-14]. Among them, support vector machine[15], AdaBoost, error correction output code, and shallow ANN based on manual characteristics are important components of such algorithms. Although there have been many research results, the recognition rate is easily affected by external disturbance because only low-level features designed by humans are used. In addition, due to the complexity of feature extraction, the generalization ability and applicability of this method are not high[16]. In this paper, C-ivus GAN-SHGN, an algorithm based on the layered hourglass structure[17], was constructed and used to extract the edges of the inner and outer"}, {"title": "II. RELEVANCE THEORY", "content": "The network can be regarded as a mapping between the random noise Z and the output screen[18]. The algorithm generates data by introducing a random noise C in the generation process, and then sends this process to the discriminator[19]. The results are then fed back to the synthesizer.\n$$\\min_G \\max_F Q(S, F) = W_{u \\sim G_{data}(u)}[\\log(S(u))] +W_{u \\sim G(c)} [\\log(1-S(F(c)))]$$where is the actual data distribution. is the data(u)\ngenerated data distribution."}, {"title": "A. Medical image enhancement based on CGAN", "content": "CGAN adds additional label information to production and discriminative networks, and uses additional constraints to guide the generation of samples [20]. This project intends to use the medical image with random noise C as the constraint information, and train the original image to make it correspond to the real image, so as to realize the effective enhancement of the image. The objective function Q (S, F) of CGAN is as follows:\n$$\\min_F \\max_S Q(S, F) = W_{u \\sim G_{data}(u)} [\\log(S(u, v))]+\nW_{u \\sim G(c)} [\\log(1-S(u, F(u,c)))]$$The function S (u, v) is the possibility that the image input to the discriminator S is true, and the image S(u,F(u,c))\ninput to the discriminator S is generated by the generator F.\nIn this paper, the CGAN architecture is mainly used, and U-Net network is used instead of CNN to retain the original image in the image to the maximum extent. Its construction is similar to the codec, but it uses the skip connection technology[21]. This structure is shown in Figure 1. This method makes full use of the bottom and top feature maps,\nwhich can better preserve the details of the image."}, {"title": "B. Loss function", "content": "In the test model, CGAN loss function is introduced and Loss\u2081 loss function is added to ensure the similarity of the two images, considering that there is a large amount of data sharing between the two systems. In a standard CGAN network, the loss function is as follows\n$$\\text{LOSS}_{CGAN}(F, S) = W_v [\\log S(u, v)] +W_v [\\log(1-S(u, F(u,c))]$$\nWhere F is the generator, S is the discriminator, u is the input medical image, and V is the actual image. To get more low-frequency information and improve the sharpness of the resulting image, add penalty Loss, to F,\n$$\\text{Loss}_{Loss}(F) = W_{u,v,c}[|| v \u2212 F (U, C) ||]$$\nBy introducing the super parameter n to achieve the balance of the two losses, it not only retains the characteristics of the high frequency band of the image, but also retains part of the low frequency information, so as to obtain a more accurate imaging effect. The loss function used in the final paper is as follows\n$$\\text{Loss} = \\arg \\min_F \\max_S \\text{Loss}_{CGAN}(F, S) + \\eta \\text{Loss}_{Loss}$$"}, {"title": "III. SYSTEM WORKFLOW", "content": "An adversarial modeling method based on Civus GAN- SHGN was used to divide the segmented IVUS images into three categories: surrounding tissue, plaque and lumen. Then the Civus GAN-SHGN image was binarized to obtain the"}, {"title": "IV. RESULTS", "content": "The former is a user-specified probability density function of the image, with an explicit distribution. The latter can be used for image data without explicit function assignment. The generator is designed to produce real, authentic biological or medical image data, which contains the segmentation of human organs.\nThe above research work is carried out based on the TensorFlow open-source development platform. The negative slope of LU activation in encoder, decoder and discriminator groups is 0.2."}, {"title": "A. Comprehensive loss function", "content": "The comprehensive loss function of C-ivus GAN-SHGN is divided into two parts: reconstruction loss and resistance loss. The L1 and L2 spacing is used as the cost of resisting network reconstruction so that the resulting image is consistent with the single contour obtained by the physician. Only L1 or L2 reconstruction loss can be used to obtain the optimal score. The concept of adversarial learning is introduced into the algorithm, which makes the generated image have better segmentation effect. The reason is that the spatial distribution between the images obtained by the anti-loss algorithm and the contours of multiple patients on the same sample is basically the same (Table 1)."}, {"title": "B. Impact of generator network structure", "content": "FCN, U-Net, SegNet, Deconv Net, etc. are typical image partitioning networks with semantic features, and they can all be used to construct C-ivus GAN-SHGN. This paper discusses the influence of three construction methods on image cutting, namely Pix2Pix-1 based on U-Net structure and codec structure. During the refactoring process, the user can reuse the low-level features inside the encoder to accurately restore the details of the original image. The main feature of the system is the combination of encoder and decoder (Figure 5 cited in Appl.Sci.2022, 12(1), 403)."}, {"title": "V. CONCLUSION", "content": "This paper constructs an algorithm based on a hierarchical structure for modeling research. First, the adversarial training and CGAN methods were used to take the ultrasonic image as the constraint and corresponding it to the segmented image, so as to realize the three main regions of the IVUS image: surrounding tissue, plaque and lumen. According to the image segmentation results, the edge between the middle outer membrane and the inner outer membrane is extracted by threshold analysis method. C-ivus GAN-SHGN takes layered hourglass neural network as its basic structure, which is compact and has fewer parameters, and is superior to Pix2Pix UNet. Our results, indicating a marked improvement over existing methods, confirm the robustness and applicability of our model. Looking forward, the integration of C-GAN with SHGN presents a promising avenue for further research in other areas of medical imaging and could potentially be adapted for real-time diagnostic systems. The adaptability of our model to different types of medical imaging modalities also suggests extensive possibilities for future interdisciplinary research, aimed at bridging the gap between advanced machine learning techniques and clinical applications."}]}