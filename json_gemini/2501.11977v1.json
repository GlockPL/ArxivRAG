{"title": "LEVERAGING GRAPH STRUCTURES AND LARGE LANGUAGE\nMODELS FOR END-TO-END SYNTHETIC TASK-ORIENTED\nDIALOGUES", "authors": ["Maya Medjad", "Hugo Imbert", "Bruno Yun", "Rapha\u00ebl Szymocha", "Fr\u00e9d\u00e9ric Armetta"], "abstract": "Training task-oriented dialogue systems is both costly and time-consuming, due to the need for\nhigh-quality datasets encompassing diverse intents. Traditional methods depend on extensive human\nannotation, while recent advancements leverage large language models (LLMs) to generate synthetic\ndata. However, these approaches often require custom prompts or code, limiting accessibility for\nnon-technical users. We introduce GraphTOD, an end-to-end framework that simplifies the generation\nof task-oriented dialogues. Users can create dialogues by specifying transition graphs in JSON format.\nOur evaluation demonstrates that GraphTOD generates high-quality dialogues across various domains,\nsignificantly lowering the cost and complexity of dataset creation.", "sections": [{"title": "1 Introduction", "content": "Task-Oriented Dialogue Systems (TODS) are increasingly used in domains like customer support, personal assistants,\nand enterprise solutions to help users achieve specific objectives through natural language conversations [1, 2, 3, 4].\nTraditional TODS rely on machine learning models trained on predefined schemas [5, 2], but they struggle with\ncomplex/nuanced dialogues, especially when domain-specific data is scarce. In contrast, LLM-based TODS enable\nmore human-like and engaging responses [6, 7, 8, 1]. However, these systems are prone to hallucinations [9, 10],\nneeding fine-tuning for specific use cases [11, 12].\nFine-tuning LLM-based TODS requires large amounts of training data, with diverse and high-quality structures, which\nare costly and time-consuming to collect [13]. A diverse dataset of realistic dialogues is essential to allow these systems"}, {"title": "2 The GraphTOD generation pipeline", "content": "GraphTOD is based on two agents (system and user) which simulate dialogue utterances by navigating an action\ntransition graph (see Figure 1). We formalize each of those elements.\nAn action transition graph is a tuple $G = (V, A_c, E, t, s, f)$, where $V$ is a set of nodes, $A_c$ is a set of actions,\n$s, f \\in V$ are the initial and final states, $E \\subseteq (V \\\\ {f}) \\times A_c$ is a set of available actions at each non-final node, and\n$t : (V \\\\ {f}) \\times A_c \\rightarrow V$ is the transition function. The action transition graph serves as the link between the two\nagents and can be specified quickly in JSON format.\nGiven an action transition graph $G$, a subset of actions $F \\subset A_c$, called function calls, are associated with APIs to obtain\nexternal knowledge. For a node $v \\in V$, the possible actions at $v$ are denoted $Act_v = \\{a \\in A_c | (v, a) \\in E\\}$. Our\npipeline makes use of five carefully crafted prompt templates denoted by $p_i$, $1 \\leq i \\leq 5$. These prompt templates take\nas input a set of parameters and return a formatted string for an LLM. A dialogue history is $H = (u_1, u_2, u_3, ..., u_n)$,\nwhere $u_{2j}$ and $u_{2j+1}$ represent the user's and system's utterances, respectively, at time $j \\geq 0$. We denote an LLM as a\n(possibly non-deterministic) function $l$ that outputs $l(x)$ for input $x$.\nThe system agent is defined as $A_s = (G, F, P_s, K, u_1)$, where $G$ is an action transition graph, $F$ is a set of function\ncalls, $P_s = \\{p_1, ..., p_4 \\}$ is a set of system prompt templates, $K$ is an agent knowledge database initialized at $(\u00d8$, and\n$u_1$ is a starting utterance. Considering a dialogue history $H = (u_1, u_2, ..., u_{2j+1})$, a user utterance $u_{2j+2}$, and the\ncurrent node $v \\in V$, the system agent performs a two-steps reasoning. First, $p_1(H, u_{2j+2}, K, Act_v)$ is used to make the\nLLM detect the user's intention. Second, depending on the detected intention, potential APIs are triggered to collect\nknowledge, and the system utterance is generated to either state that the intent was not recognized, end the conversation,\nor continue the conversation (using the corresponding prompt templates $p_2$, $p_3$, or $p_4$)."}, {"title": "Evaluation", "content": "We generated 150 conversations on four domain scenarios (Recipe, Hotel, RentCar, Doctor) using our pipeline and\nOpenAI's GPT-4. We evaluate the dialogues using three metrics (naturalness, coherence, understandability) from the\npre-trained T5-based UniEval metrics [17] as classic NLP metrics (e.g., BLEU [18] or ROUGE [19]) are not sufficient to\nportray the difference between the advanced generation models. As shown in Table 1, GraphTOD performs consistently\nwell overall and reports similar performances to human-in-the-loop approaches based on LLMs such as LAPS [20]."}, {"title": "4 Conclusion", "content": "GraphTOD is an end-to-end LLM-based pipeline designed to generate task-oriented conversations efficiently. By using\nan action transition graph in JSON format, GraphTOD simulates high-quality dialogues between two agents across\nvarious domains, thanks to a generalized prompting approach. GraphTOD also includes the automatic generation of\nuser-agent preferences from the input graph and LLM-powered intent detection, resulting in a fully automated and\nfault-tolerant pipeline."}]}