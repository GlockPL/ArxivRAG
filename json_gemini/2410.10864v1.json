{"title": "Fill In The Gaps: Model Calibration and Generalization with Synthetic Data", "authors": ["Yang Ba", "Michelle V. Mancenido", "Rong Pan"], "abstract": "As machine learning models continue to swiftly advance, calibrating their performance has become a major concern prior to practical and widespread implementation. Most existing calibration methods often negatively impact model accuracy due to the lack of diversity of validation data, resulting in reduced general-izability. To address this, we propose a calibration method that incorporates synthetic data without compromising accuracy. We derive the expected calibration error (ECE) bound us-ing the Probably Approximately Correct (PAC) learning framework. Large language models (LLMs), known for their ability to mimic real data and generate text with mixed class la-bels, are utilized as a synthetic data generation strategy to lower the ECE bound and improve model accuracy on real test data. Additionally, we propose data generation mechanisms for ef-ficient calibration. Testing our method on four different natural language processing tasks, we observed an average up to 34% increase in ac-curacy and 33% decrease in ECE.", "sections": [{"title": "1 Introduction", "content": "Natural Language Processing (NLP) models have fundamentally advanced the syntactic and seman-tic analysis, information retrieval, and automated generation of textual data. State-of-the-art (SOTA) models (e.g., transformers (Vaswani et al., 2017), BERT (Devlin et al., 2019), and RoBERTa (Liu et al., 2019)) have excelled in practical, user-centric applications such as automated customer support chatbots, personalized content curation, and real-time multilingual text translation. Other NLP models, which are typically trained for a spe-cialized use context, have also been developed and fine-tuned for numerous downstream tasks, including sentiment analysis, named entity recog-nition (NER), and text classification, as parts of a decision-support system (DSS). Powered by deep learning algorithms, these classification models have achieved remarkable levels of performance in terms of their accuracy, F1 scores, and AUCs (Li et al., 2020; Cohan et al., 2019).\nAs machine learning philosophies continue to evolve, growing attention is placed on metrics beyond simple classification accuracy. In recent years, socially responsible artificial intelligence (AI) has been strongly advocated by algorithmic regulatory frameworks (e.g., the US Algorithmic Accountability Act (Donovan et al., 2018)), espe-cially in safety-critical domains, such as health-care (Pfohl et al., 2022) and law enforcement (Sal-vador et al., 2021). Some key pillars of socially re-sponsible AI include accountability, transparency, and robustness (Cooper et al., 2022). Ensuring a calibrated ML model accountable for its deci-sion means that it must provide clear justifications for any decision being made, while transparency requires that these justifications are understand-able and interpretable (Kadavath et al., 2022); ad-ditionally, robustness requires that the ML model performs consistently well under various condi-tions. In classification tasks, these requirements can be addressed by properly managing model out-put uncertainty, i.e., quantifying, calibrating, and communicating the proper confidence level associ-ated with each prediction to the end user. Among the three aspects of uncertainty management, cal-ibration directly improves model performance by ensuring that model predictions are congruent with empirically observed outcomes.\nAI risk management is an emerging field that emphasizes understanding the limitations of model predictions. Model calibration techniques are used to address the fact that high accuracy does not always mean high confidence in a model's predic-tions. For example, consider a classifier trained to recognize handwritten digits. This model might achieve high accuracy on a test set, but it also provides the predicted probability for each class, which reflects its level of uncertainty. If it classi-"}, {"title": "2 Calibration Concept", "content": "This section introduces some basic concepts related to model calibration, which would lay a foundation to derive our methodology.", "formula": ["Acc(Bm) = \\frac{1}{|B_m|} \\sum_{x_i \\in B_m} 1(\\hat{Y}_i = Y_i),", "Conf(Bm) = \\frac{1}{|B_m|} \\sum_{x_i \\in B_m} p_i", "ECE = \\sum_{m=1}^{M} \\frac{|B_m|}{n} |Acc(B_m) - Conf(B_m) |"]}, {"title": "3 Methodology", "content": "In this section, we utilize the Probably Approxi-mately Correct (PAC) learning framework to derive the expected calibration error(ECE) bound and dis-cuss the benefits of using synthetic data to improve models' calibration and generalization. Moreover, we use a toy sample to demonstrate our methodol-ogy.", "formula": ["P(|E(h) - E(h^*)| > \\epsilon) \\leq 2 exp(-2\\epsilon^2n)"]}, {"title": "3.1 From PAC Learning to Expected Calibration Error Bound", "content": "Probably Approximately Correct (PAC) learning (Valiant, 1984) offers a theoretical framework that establishes the bounds on learning model parame-ters with specified levels of error and confidence, relating model accuracy to confidence level and sample size. According to Hoeffding's inequality,", "formula": ["P(Acc(X) - Acc(X^*)| > \\epsilon_a) < 2 exp(-2\\epsilon_a^2 n)", "\\epsilon_{ECE} = \\epsilon_a + |Conf(X) - Conf(X^*)| = \\epsilon_a + \\sum_{m=1}^{M} \\frac{|B_m|}{n} |Conf(B_m) - Conf(B_m)|"]}, {"title": "3.2 Synthetic Data Generation Strategy", "content": "Synthetic data generation consists of two stages: First, we specify the gaps against the perfect cal-ibration line in the reliability diagram. Bins over the line are underconfident while those under the line are overconfident. The data points in those bins are the target data samples for synthetic data generation. With the predicted probability 0.5 as the cutoff, we categorize the reliability diagram into four scenarios: Low Probability & Over Confidence, Low Probability & Under Confi-dence, High Probability & Over Confidence, and High Probability & Under Confidence, as shown in Table 1.\nNext, LLMs, which serve as text generators, are used to create synthetic text data. Since LLMs are trained on diverse and extensive data spanning a wide range of sources, we can distill the knowl-edge from LLMs to generate synthetic data that is considered out-of-distribution of training data. We ask LLMs to imitate the classifier we trained by generating similar instances using data samples we collected from the target bin. Specifically, we pass the data instance $x_i$ and $P(y_i|x_i)$ from a trained classifier to LLMs and ask it to generate a similar instance $x_{syn}$ with $P(y_i|x_{syn})$, where $|P(y_i|x_i) - P(y_i|x_{syn})| = |Conf(B_m) - Conf(B_m)|$. For ex-ample, suppose there are $N_{bins}$ bins, if the target text is from $m_2^{th}$ bin and $|Conf(B_m) \u2013 Conf(B_m)|$ is $\\alpha$, then we will ask LLMs to generate the syn-thetic texts that have the $m \\pm \\alpha$ probability be-longing to one class and the $1 - \\frac{m}{N_{bins}} \\pm \\alpha )$ prob-ability for the other class.\nTo illustrate our method, in Figure 2b a hidden predicted probability line is shown orthogonal to the estimated decision boundary. Data points close"}, {"title": "3.3 Toy Example", "content": "We use a 1D logistic regression classifier as an ex-ample to demonstrate that adding appropriate syn-thetic data in the target bins can produce a better-calibrated and more accurate model. Parameters of the true model are defined: $\u03b2_1$ = -1 and $\u03b2_1$ = 2. We randomly simulate 300 data points from the range between -10 and 10 and classify them based on the true model as the label. A logistic regression model is fitted on these data points. The fitted parameters are $\u03b2_0$ = -0.06 and $\u03b2_1$ = 1.13. The model achieves an accuracy of 0.95 and an ECE of 0.0405 (Figure 3a).\nFigure 3b shows us that the fitted logistic regres-sion is overconfident about its predictions in the 2nd bin and 4th bin. Now we target these two bins to generate some synthetic data points to fill the gap. The function we used to generate synthetic data points is a left-sided truncated normal distri-bution, whose parameters are: $\u03bc = \u03bc_{B_in_i}, SD = SD_{B_in_i}, n = |B_{in_i}|$, i = {2, 4}. We add new data points step by step to see how the logistic curve changes: 1) add synthetic data of the 2nd bin, 2) then add synthetic data of the 4th bin based on pre-"}, {"title": "4 Experiment", "content": "We employ four datasets on text classification tasks across multiple domains with varying sam-ple sizes and proportions of class. To better eval-uate our approach, we select two balanced and two imbalanced datasets, respectively, and the sam-ple size varies from hundreds to thousands. The Complaints dataset (TC) (Preo\u0163iuc-Pietro et al.,"}, {"title": "4.2 Training", "content": "All datasets are split into training, validation, and test sets. For the TC dataset, we split the entire data into training, validation, and test sets with a ratio of 80:10:10. For other datasets, the validation sets are created by randomly sampling 20% from"}, {"title": "4.3 Synthetic Data Generation", "content": "Synthetic text generation is performed using ver-sion Llama-2-7b-chat-hf of Llama 2 at a temper-ature T = 0.1. We apply the two-stage and three-shot learning generation method proposed in the paper (Sahu et al., 2023) to guarantee diversity and authenticity. First, we define each label and provide three examples for each one (Appendix C). Then, we present the example text from the previous selection stage along with the predicted"}, {"title": "4.4 Evaluation", "content": "Results are assessed on real test set. Baseline refers to the results trained on the model in Step 1. Sup-pose we have a total of N original data points in the training and validation set, and there are $S_1$ data points in target bins from the validation set. Let LLMs generate $S_2$ synthetic data points, and $S_2 = S_1$. Synthesis refers to the results that we retrain the model by replacing $S_1$ original data points with $S_2$ synthetic data points. Synthesis+ indicates that we add $S_2$ synthetic samples into the original N data points.\nIn addition to the baseline, we also compare the performance of our methods against some widely used model calibration techniques. Isotonic re-gression (Zadrozny and Elkan, 2001) employs a non-parametric method that adjusts predicted prob-abilities to align with observed outcomes, and Platt scaling (Platt et al., 1999) fits a logistic regression model to calibrate classifier scores based on pre-dicted probabilities. Monte Carlo dropout (Gal"}, {"title": "4.5 Results", "content": "We run each experiment for three random seeds and report the average value (with standard devia-tion in brackets) of accuracy and ECE in Table 4. By adding synthetic data with a size of 7%-18% of the training set, we would have a 21-33% ECE decrease. Taking both accuracy and ECE into ac-count, our synthetic data replacement (synthesis) and synthetic data add-on (synthesis+) methods"}, {"title": "4.6 Ablation Study", "content": "To discuss if the LLM's self-calibration capability strongly impacts our approach, we instruct Llama-2-7b-chat-hf with few-shot learning and set topk = 1 in which we obtain the conditional probability of one class $P(label|text)$. Then we computer the"}, {"title": "5 Related Work", "content": "Model calibration has emerged as an open chal-lenge in machine learning as concerns arise regard-ing the responsible and ethical use of ML-enabled systems. Several methods have been proposed, in-cluding Platt Scaling (Platt et al., 1999), Isotonic regression (Zadrozny and Elkan, 2001), among oth-ers. Both of them somewhat change the predicted probability, which could lower the predicted accu-racy. In the computer vision field, a mixup method (Zhang et al., 2018) has been proposed to overcome"}, {"title": "6 Conclusion", "content": "In the era of large models, we believe smaller mod-els still hold tremendous values in, e.g., edge com-puting and specialized downstream machine learn-ing tasks. We derive the expected calibration error bound for ML models and explore the possibility of leveraging synthetic data to mitigate calibration"}, {"title": "Limitations and Future Work", "content": "While increasing the sample size generally helps reduce the Expected Calibration Error (ECE), sim-"}, {"title": "A Appendix", "content": "Our code is implemented based on Pytorch 2.2.1 and the pre-trained Bertbase model is downloaded"}, {"title": "B Appendix", "content": "The Expected Calibration Bound Proof:\nFrom equation (1) in section 2, we extend the definition of accuracy and confidence from bin-wise to data-wise:", "formula": ["Acc(X) = \\frac{\\sum_{m=1}^{M} \\frac{|B_m|}{n} Acc(B_m).", "Conf(X) = \\frac{\\sum_{m=1}^{M} \\frac{|B_m|}{n} Conf(B_m)", "Acc(X^*) = \\frac{\\sum_{m=1}^{M} \\frac{|B_m|}{n} Acc(B_m),", "Conf(X^*) = \\frac{\\sum_{m=1}^{M} \\frac{|B_m|}{n} Conf(B_m)", "P(|Acc(X) - Acc(X^*)| > \\epsilon_a) < 2 exp(-2\\epsilon_a^2 n).", "\\sum_{m=1}^{M} P|\\frac{|B_m|}{n} Acc(B_m) - \\frac{|B_m|}{n} Acc(B_m) > \\epsilon_a", "\\frac{|B_m|}{n} Acc(B_m) - Conf(B_m) + Conf(B_m) + Conf(B_m) - Conf(B_m) - \\frac{|B_m|}{n} Acc(B_m)| > \\epsilon_a", "\\frac{|B_m|}{n} Acc(B_m) - Conf(B_m) - [\\frac{|B_m|}{n} Acc(B_m) - Conf(B_m)] + Conf(B_m) - Conf(B_m)| > \\epsilon_a", "P|\\frac{|B_m|}{n} Acc(B_m) - Conf(B_m) - [\\frac{|B_m|}{n} Acc(B_m) - Conf(B_m)]| > \\epsilon_a +  \\sum_{m=1}^{M}  \\frac{|B_m|}{n} Conf(B_m) - Conf(B_m)|", "\\frac{|B_m|}{n} Acc(B_m) - Conf(B_m) - [\\frac{|B_m|}{n} Acc(B_m) - Conf(B_m)]| > \\epsilon_a + |Conf(X) - Conf(X^*)|", "P (ECE(X) - ECE(X^*) > \\epsilon_a + |Conf(X) - Conf(X^*)|) < 2 exp(-2\\epsilon^2\\eta)", "P (|ECE(X) - ECE(X^*)| > \\epsilon_a + |Conf(X) - Conf(X^*)|) < 4exp(-2\\epsilon^2\\eta)", "P (|ECE(X) - ECE(X^*)| > \\epsilon_{ECE}) < 4 exp(-2\\epsilon^2\\eta)", "P (|ECE(X) - ECE(X^*)| > \\epsilon_{ECE}) < 4 exp(-2(E_{ECE} - |Conf(X) - Conf(X^*)|)^2\\eta)", "\\epsilon_{ECE} = \\epsilon_a + |Conf(X) - Conf(X^*)| = \\epsilon_a + \\sum_{m=1}^{M} \\frac{|B_m|}{n} |Conf(B_m) - Conf(B_m)|"]}, {"title": "C Appendix", "content": "System Prompt"}, {"title": "D Appendix", "content": "Table 8: An example of generating synthetic data via LLM. Input contains the original text (xi) and the average predictive probability of the bin it comes from (P(yi|xi)). Generated Text is the one after the relabeling process. Note: during re-fine tuning of the downstream model, we exclude P(yi|x syn) and retain only x xsyn in the dataset."}]}