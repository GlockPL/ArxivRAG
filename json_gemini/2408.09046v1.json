{"title": "Keep Calm and Relax", "authors": ["TIMA M. YEKTA", "JULIUS SCH\u00d6NING"], "abstract": "The growing popularity of self-driving, so-called autonomous vehicles has increased the need for human-machine interfaces (HMI) and user interaction (UI) to enhance passenger trust and comfort. While fallback drivers significantly influence the perceived trustfulness of self-driving vehicles, fallback drivers are an expensive solution that may not even improve vehicle safety in emergency situations. Based on a comprehensive literature review, this work delves into the potential of H\u039c\u0399 and UI in enhancing trustfulness and emotion regulation in driverless vehicles. By analyzing the impact of various HMI and UI on passenger emotions, innovative and cost-effective concepts for improving human-vehicle interaction are conceptualized. To enable a trustful, highly comfortable, and safe ride, this work concludes by discussing whether HMI and UI are suitable for calming passengers down in emergencies, leading to smarter mobility for all.", "sections": [{"title": "1 INTRODUCTION", "content": "Trust and autonomous vehicles are two words that increased the demand for user interaction (UI) and human-machine interface (HMI) design. Trust is one of the essential factors in autonomous and automated technology [1, 51] and will become more urgent in driverless vehicles in the upcoming decade. Human drivers have become superfluous within driverless, automated, and self-driving vehicles. Thus, in the cases of fully and highly automated driving, trust can no longer be provided by the presence of a driver or a fallback driver. The driving system itself must provide trust. Especially where these vehicles are required to operate in challenging environments and unexpected scenarios, the innovative and cost-effective HMI and UI must enhance passenger trust by, e.g., emotion regulation [9, 18]. Active emotion regulation in inevitable fear and stress-provoking situations increased the trust, comfort, and pleasure in self-driving vehicles. By effectively addressing passengers' emotional needs and expectations, automotive UI and HMI enable trustworthy autonomous vehicles in sustainable transportation systems.\nThis paper explores the potential of HMI and UI in achieving trust and emotion regulation for self-driving vehicles. Through a comprehensive literature review, this work examines the impact of various HMI and UI concepts on passenger emotions and proposes innovative solutions for improving human-vehicle interaction. Finally, the paper discusses whether HMI and UI are suitable for calming passengers down in emergencies and challenging environments to enable smart and trustful mobility."}, {"title": "2 USER INTERACTION CLUSTERS IN PARTIAL AND FULL AUTOMATED VEHICLES", "content": "Considering the needs of the passenger in fully automated vehicles and the needs of both the diver and the passenger in partially automated vehicles, nine interaction clusters can be defined. As illustrated in Fig. 1, seven interaction clusters, I) to VII), are essential for partial automation according to levels 2 and 3 of the SAE J3016, and six interaction clusters, I) to IV), VIII) and IX), for automated driving according to levels 4 and 5.\nWithin the well-known interaction clusters I) and II), cluster I) informs the driver and the passengers about the vehicle status, like the remaining driving range, and cluster II) about non-vehicle related status, like driving distance to the destination. Along with non-urgent responses II) like maintenance information and multimedia settings as part of the cluster comfort IV), these four clusters are available in current vehicles from 0 to 3 and will be present in automated vehicles, i.e., levels 4 and 5. For partial automation levels 2 and 3, the interaction clusters situational awareness V), i.e., making the driver aware of obstacles, urgent response VI) demand like the takeover from the autopilot to the driver and urgent communication VII) like error state information are vital only to the drivers. Currently mostly neglected are the interaction clusters of building trust VIII) in the system and regulating emotion and relaxation IX). However, two clusters VIII) and IX) are important since in levels 4 and 5, only passengers are in the vehicles.\nBased on these nine interaction clusters, existing literature on how UI and HMI interact with users is reviewed in the remaining and summarized in Table 1. There are numerous different modalities used for user interaction. These modalities are used for various use cases within the vehicle and rely on one single modality, cf. Section 3, or multiple modalities cf. Section 4 to engage with users. Each modality has its strengths and weaknesses. For instance, auditory output produces better reaction times, while visual output improves drivers' efficiency. It is generally accepted that multimodal interventions [4] have a higher impact as their reaction and process time are shorter and lead to fewer error-prone actions."}, {"title": "3 \u039c\u039f\u039d\u039f-MODAL USER INTERFACES", "content": "Mono-model UI uses visual, auditory or haptic channels to communicate with the passengers and drivers\u2014the olfactory channel has not yet been used in the context of self-driving vehicles. However, olfactory UI is already taken into account for recognizing the system"}, {"title": "3.1 Visual", "content": "Visual UI uses text, graphics, augmented reality (AR), and lights to communicate verbal and non-verbal."}, {"title": "3.1.1 Text", "content": "Much information is typically transmitted via text during the interaction between the driver and passenger. Text UI and HMI can be employed both to alert users and provide non-urgent information. Text is processed faster than unknown graphics and icons; however, the user must be capable of reading and understanding the text. As a result, the use of alerting words like Danger, Warning, and Error is helpful to users. The text allows for comprehensive and detailed communication with users. Large display areas are needed to ensure a readable character size in these cases."}, {"title": "3.1.2 Graphic and Icons", "content": "Graphics and icons allow users to communicate information effectively in limited display areas. Graphics and icons with emotional components are processed faster than neutral images. Thus, when using these methods for urgent communication, it is suggested that emotionally arousing graphics and icons should be used in the design. Users need domain knowledge for some graphics and icons, like the brake and the headlights icons; thus, processing unknown pictures might become infeasible."}, {"title": "3.1.3 Augmented Reality", "content": "AR is used as a form of dynamic output to communicate with users. It is usually employed to increase situational awareness and drive performance. However, it combines real-world items with projected texts, graphics, and icons. Headup displays can be used as AR displays but are used primarily as transparent displays that do not embed real-world items in the HMI."}, {"title": "3.1.4 Light", "content": "Various implementations of light have been used in HMI. They are used in vehicles' dashboards, glasses, and general light fixtures. Lights are a dynamic output for alerting users about vehicle status, increasing situational awareness, and communicating urgent messages."}, {"title": "3.2 Auditory", "content": "Verbal and non-verbal UI via the ears are performed with speech, music, and earcons."}, {"title": "3.2.1 Earcon", "content": "These are often used for brief and urgent user communication. Although it is not possible to use them for detailed communication, they have the advantage of incurring a low cognitive load. Like other auditory output mediums, it is possible to arouse users' attention to them when they are not actively engaged with driving tasks."}, {"title": "3.2.2 Speech", "content": "Although not preferable for urgent situations due to the high cognitive load it needs, speech has the distinct benefit of anthropomorphizing interaction with the vehicle and creating a welcoming atmosphere inside the vehicle."}, {"title": "3.2.3 Music", "content": "Music is almost exclusively used as an intervention for emotional regulation."}, {"title": "3.3 Haptics", "content": "Haptics are almost exclusively used for non-verbal UI."}, {"title": "3.3.1 Vibration", "content": "Most vibrations in vehicles are delivered through vehicle seats, wearable technology, and steering wheel. Vibrations are an excellent medium of brief communication with users."}, {"title": "3.3.2 Steering Wheel dynamics", "content": "Shape-shifting steering wheels and resistance of the wheel to dangerous choices by drivers are some of the ways steering wheels have been used to communicate with users."}, {"title": "4 MULTI-MODAL USER INTERFACES", "content": "The previous overview of mono-modal interfaces, as well as Table 1, makes it clear that multisensory processing is an area of interest for the interface designs of the interaction clusters VIII) and IX) in self-driving vehicles. Thus, this section briefly reviews the theoretical framework in this field. The research of a multisensory perspective toward perception goes back to the Gestalt movement. The Gestalt movement resulted from a backlash against the dominance of the reductionist theories. The Gestalt movement circles the idea that perception should be viewed as a holistic phenomenon [27].\nThe idea of a holistic phenomenon is translated into one of the central notions of Gestalt theory, namely holism or the principle of totality. According to this principle, a sensory whole transcends its parts and becomes something else in its quality [58]. Gestalt theory paved the way for research on multisensory integration. Stein and Meredith [52] introduced integrative rules for multisensory integration. The first rule, the spatial rule, states that spatial coincidence enhances the responses of multimodal neurons while spatial non-alignment depresses their responses. The second or temporal rule suggests that temporal proximity enhances neural responses. The final rule, or the inverse effectiveness rule, proposes that the magnitude of response enhancement is inversely related to the intensity of a stimulus. A stimulus with a weak intensity results in a more significant response enhancement than a stimulus with high intensity [31].\nOne problem with sensory processing is how noisy neural processes are. As a result, an essential component of these processes has to be the reduction of the variance to create the best sensory estimates. One influential model that strives to explain this outcome in the multisensory integration processes is the maximum likelihood estimation model based on forced-fusion and Gaussian assumptions. This model proposes that multisensory integration is based on the weighted average of the signal and that these weights are consistent with the relative reliabilities of the signals [52].\nIn working memory, the research revolves around whether or not the information is stored in separate or integrated representations based on modality or domain. One of the pioneering work in this field is by Atkinson and Shiffrin [2]. They proposed that after the initial modality-based processing of information, the information is stored in an amodal form in the working memory. In contrast to this model, Baddeley and Hitch [3], proposed a model that stores information based on its modality-the Visual-spatial sketchpad and phonological loop.\nAs the evidence mounted in favor of interaction between processes linked to different modalities, this model was amended, and an episodic buffer was added to the model to link the other components [44].\nAnother area of interest is attention. Crossmodal sensory stimuli compete for attention. This competence could lead to the extinction of the stimuli. This phenomenon has been famously observed in the Colavita effect. In this task, participants are asked to respond to auditory and visual stimuli with different keys. However, sometimes, both stimuli are presented at the same time. Simultaneous processing of stimuli could result in failure, in which one only responds to auditory stimuli but not visual ones. Other studies have shown visual dominance in haptic vs. visual stimuli Colavita task and absence of any modality dominance in a tri-sensory task of visual, auditory, and haptic stimulus [40]."}, {"title": "5 TRUST AND EMOTION USER INTERFACES", "content": "Fully automated self-driving vehicles present unique difficulties when it comes to users' comfort, cf. interaction cluster IV), users' trust cf. cluster VIII) and users' emotions cf. cluster IX). Although the burden of driving tasks is lifted from users, it does not guarantee a comfortable experience for passengers. Focussing on unexpected events and automation surprise, i.e., the consequence of the system doing something the user did not expect [12] UI and HMI for level 4 and 5 vehicles are explored in this section.\nUnexpected events and automation surprises can cause negative emotions such as stress in users [14, 53]. Thus, examining how users handle these circumstances and regulate their negative emotions is essential. Emotion regulation refers to efforts to control what, when, and how emotions are experienced and expressed. Gross [21] divides strategies of emotion regulation into two categories of: antecedent-focused and response-focused strategies. Antecedent-focused strategies include strategies that focus on regulating emotion before the response to it emerges. These include situation selection, situation modification, attention deployment, and cognitive change. Response-focused strategies are those strategies that commence after the emotional response has already started. These strategies aim to affect emotional response's behavioral, physiological, and experiential aspects [20]. These strategies could also be categorized along the dimensions of emotion regulation goal-explicit and implicit-and emotion regulation process (controlled and automatic) [10]. Users may use any of these strategies to deal with discomfort. However, some of these strategies are maladaptive and can lead to avoidance and distrust of automation.\nMoreover, interventions to help users successfully regulate their emotions could be implemented to prevent such outcomes. As reviewed by Braun et al. [8] there is a range of studies investigating possible interventions to regulate stress and discomfort during driving. These interventions use various techniques such as implicit influencing using ambient lights[22], temperature [47], and music [28]. It is useful to review these strategies even if this work focuses on fully automated vehicles and improving user experience and comfort."}, {"title": "6 CONCEPTS ON USER INTERFACES FOR BUILDING TRUST AND REGULATING EMOTIONS", "content": "Building trust and regulating emotions must be tailored to each passenger's needs as discussed in Section 5. For handling the UI in emergency situations, like a sudden appearance of a deer ahead of an automated vehicle cf. Fig. 2 (a), this section first conceptualized an ideal HMI based on the literature reviewed in Table 1 and the previous sections. Based on this concept, the research directions that are needed are discussed in the remainder.\nFocusing on regulating negative emotions triggered by unexpected events and emergency situations on every single passenger, UI must focus on every single passenger's needs. Consequently, the first step is detecting signals of stress in each user. Measures of physiological and physical responses related to stress include a wide range of signals such as heart rate, skin conductance, pupil size, and respiratory rate. Measuring multiple signals is preferable as multimodal biosignal analysis allows for capturing a more accurate picture of the emotional state [30].\nHMI should be able to incorporate such measures and thus provide multimodal emotional regulation interventions at appropriate times for each passenger. One possible way to incorporate these measures and deliver emotional regulation intervention is by utilizing wearable technology. Wearable technology has been repeatedly used in previous research in this field. They can measure various physiological responses and are easy to use for each passenger. E-textiles are similarly capable of delivering interventions and measuring stress-related signals. As seen in Fig. 3, a smartwatch measures the individual stress level of higher levels of automation can present particular challenges regarding users' acceptance, trust, and comfort. It has been shown that higher automation is correlated with lower perceived control and fun [45] and lower perceived levels of safety and higher anxiety [25]. Moreover, higher automation can jeopardize the sense of agency of users [61]. The increase in automation is linked to a decrease in the sense of agency as shown by intentional bidding measures [5]. Even with interventions to improve the sense of agency, an increase in automation beyond 90% strains the sense of agency [56].\nNot only a lower sense of agency and control can cause and aggravate negative emotional experiences [24], but it can also negatively influence emotion regulation itself [13, 41]. Implementing emotion regulation strategies in self-driving vehicles starts with understanding situations that can give rise to negative emotions. One study has shown that sources of tension in highly automated vehicles can be divided into crosswalks, roundabouts, straight intersections, left-turns with on-coming traffic, left-turns without on-coming traffic, and right turns with right turns with right-of-way and right turns without right-of-way [11]. While this highlights the possible scenarios that can lead to discomfort, it fails to consider the factor of expected and unexpected automation action and surprise. This factor is even more significant in highly automated vehicles as It is envisioned that in highly automated vehicles, users do not attend to the road and instead engage in non-driving related tasks. As a result, it is necessary to address specific problems related to negative emotion and emotion regulation in higher automated vehicles and develop appropriate solutions for them.\nBeing well-informed is a possible route to reducing discomfort by heightening a sense of control during travel. For example, one study showed that a higher level of visual information inspires more trust in users of automated vehicles [35]. However, it should be noted that the need for information is dynamic and highly dependent on the individual. Experience can change the level of information that users seek [15]. Overall, all interventions should be tailored and modified according to individual needs."}]}