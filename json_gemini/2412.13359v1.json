{"title": "Multi-Agent Motion Planning For Differential Drive Robots Through Stationary State Search", "authors": ["Jingtian Yan", "Jiaoyang Li"], "abstract": "Multi-Agent Motion Planning (MAMP) finds various ap- plications in fields such as traffic management, airport op- erations, and warehouse automation. In many of these en- vironments, differential drive robots are commonly used. These robots have a kinodynamic model that allows only in-place rotation and movement along their current orienta- tion, subject to speed and acceleration limits. However, ex- isting Multi-Agent Path Finding (MAPF)-based methods of- ten use simplified models for robot kinodynamics, which lim- its their practicality and realism. In this paper, we introduce a three-level framework called MASS to address these chal- lenges. MASS combines MAPF-based methods with our pro- posed stationary state search planner to generate high-quality kinodynamically-feasible plans. We further extend MASS us- ing an adaptive window mechanism to address the lifelong MAMP problem. Empirically, we tested our methods on the single-shot grid map domain and the lifelong warehouse do- main. Our method shows up to 400% improvements in terms of throughput compared to existing methods.", "sections": [{"title": "1 Introduction", "content": "We study the Multi-Agent Motion Planning (MAMP) prob- lem which aims to find collision-free kinodynamically fea- sible paths for a team of agents in a fully observable en- vironment while minimizing their arrival time. This prob- lem finds various real-world applications, including traffic management (Ho et al. 2019), airport operations (Li et al. 2019), and warehouse automation (Kou et al. 2019). Dif- ferential drive robots are widely used in many of these en- vironments. These robots, often navigating on a grid map, can move forward along their orientation with bounded ve- locity and acceleration. They can only change their orienta- tion through in-place rotation when at zero speed. Although much work has been done to address the MAMP problem, existing methods often either fail to account for the orienta- tions of robots or overlook continuous dynamic constraints.\nMulti-Agent Path Finding (MAPF) (Stern et al. 2019) methods are a promising solution that scales to hundreds of agents. However, they assume instantaneous movement and infinite acceleration capabilities, resulting in plans that are"}, {"title": "2 Background", "content": "In this section, we begin with a review of MAPF algorithms. After that, we go through the related work in MAMP.\nMAPF Algorithms MAPF methods have achieved re- markable progress in finding discrete collision-free paths for hundreds of agents. Most state-of-the-art MAPF meth- ods, such as Conflict-Based Search (CBS) (Sharon et al. 2015; Andreychuk et al. 2022) and Priority-Based Search (PBS) (Ma et al. 2019), use a bi-level structure. At the high level, they resolve collisions among agents by introduc- ing temporal obstacles into low-level single-agent solvers. These solvers then plan paths for individual agents trying to avoid those temporal obstacles. In our experiments, we test MASS with two MAPF algorithms, PP and PBS. In Priority Planning (PP) (Erdmann and Lozano-Perez 1987), the planner begins by assigning a total priority ordering to all agents requiring lower-priority agents to avoid collisions with higher-priority ones. Then, the PP plans paths for each agent from high priority to low priority. During this process, agents treat the path from higher priority agents as tempo- ral obstacles. Priority-Based Search (PBS) (Ma et al. 2019) searches for a good priority ordering that prevents collisions among agents. PBS explores a binary Priority Tree (PT) in a depth-first manner, where each PT node contains a set of partial priority orderings and corresponding paths. The root node starts with no priority orderings. When a collision be-"}, {"title": "3 Problem Formulation", "content": "We define our MAMP problem with differential-drive agents as the MAMPD problem on an undirected graph G = (V, E) and a set of M agents R = {a1, ..., aM}. We adopt the grid model from the MAPFR problem (Walker, Sturtevant, and Felner 2018) and represent G as a four-neighbor grid map. Vertices in V represent grid cells in the map, with their lo- cations the same as the center of each cell and shapes equal to the cell size. An edge (vi, vj) \u2208 E corresponds to pos- sible transitions between vi and vj. We use a differential"}, {"title": "4 MASS", "content": "In this section, we begin with a system overview of our proposed method, MASS, followed by the specifics of the SSIPP used in Level 2. Next, we introduce a partial station- ary expansion mechanism to improve its scalability. Then, we present the formulation for speed profile optimization and two example solvers. Finally, we discuss the techniques used to extend MASS to the lifelong MAMP scenario."}, {"title": "4.1 System Overview", "content": "MAPF-based Planner At Level 1, we borrow the MAPF- based planner to resolve collisions between agents. Our framework is compatible with any MAPF solver employing a bi-level structure as discussed in related work. Empirically, we use PP and PBS as the Level-1 planner.\nStationary SIPP (SSIPP) The task of Level 2 is to find a plan for an agent with minimum arrival time while avoid- ing temporal obstacles (e.g., paths of higher priority agents from PP or PBS) given by Level 1. As shown in Fig. 2 (b), we first build a safe interval table T based on those tempo- ral obstacles. This table associated each vertex of G with a set of safe intervals, which are time intervals not occupied by the temporal obstacles. Then, Level 2 performs an SSIPP search on T to find the neighbor stationary states along with the actions that lead to them, where the speed profile of these"}, {"title": "4.2 Stationary SIPP (SSIPP)", "content": "Given a safe interval table T, the task of Level 2 is to find a collision-free plan for agent a m while minimizing its ar- rival time. In our problem, agents move in continuous time with continuous dynamics, leading to an infinite number of possible states at each vertex. To address this, Level 2 em- ploys SSIPP, which performs an A* search on T to avoid directly searching through such states. Compared to stan- dard SIPP (Phillips and Likhachev 2011), SSIPP uses sta- tionary node expansion to find stationary states and dynam- ically feasible actions connecting them. In the rest of this section, we omit subscript m for simplicity.\nSSIPP Node The search node of SSIPP is defined as n = {v, \u03b8, a, [lb, ub)}. v \u2208 V and \u03b8\u2208 \u0398 are the vertex and ori- entation of the agent. a is the previous action that leads the agent to node n. [lb, ub) is a stationary safe interval, a spe- cific safe interval in which the agent can maintain a station- ary state at v.\nMain Algorithm Algorithm 1 shows the pseudo-code of SSIPP. We begin by initializing the root node with start ver- tex vs, start orientation \u03b8s, and the first interval at vs in T [Line 1]. Then we push the root node to an open list OPEN [Line 2]. The arrival time of the best plan p* is initially set to infinity [Line 3]. We define the g-value of a node n as its lb-value, its h-value as the minimum time to move from its vertex to the goal, and its f-value as the sum of its g- and h- values, which is a lower bound on the arrival time of any plan that goes through n (i.e. stops at n within its time interval). At each iteration, we select the node n with the smallest f- value from OPEN [Line 5]. If the f-value of n is bigger than the arrival time of p*, it indicates that p* is the optimal plan. We terminate the search [Line 6] and return p* [Line 11]. If n is at the goal with infinite n.ub, we check if its g-value is smaller than the arrival time of p*. If true, we update p* by backtracking all ancestor nodes of n [Line 7-8]. In either case, we proceed to the next iteration. For all other nodes, we use stationary node expansion to generate new neighbor nodes and push them to OPEN [Line 10]. This search pro- ceeds until the optimal plan is found or OPEN is empty.\nStationary Node Expansion At each stationary state, we let the agent perform an action different from its previous action; otherwise, two identical actions can be combined into one. Accordingly, stationary node expansion includes two types: move expansion and rotate expansion. Rotate ex- pansion finds all neighbor nodes reachable through rotation, while move expansion does the same for movement.\nRotate Expansion: Since the orientation is discretized, dur- ing rotation expansion, we apply all the possible prede-"}, {"title": "4.3 Partial Stationary Expansion (PE)", "content": "During move expansion, we need to find the speed pro- files for all reachable safe intervals. This branching factor can be very high, especially in large maps. To tackle this, we use a partial stationary expansion mechanism extended from (Goldenberg et al. 2014).\nPE Node This node extends the SSIPP node by n = {v, \u03b8, a, F, [lb, ub)}, where Reachable interval list F is a list that contains all the reachable safe intervals, denoted as {[lbo, ubo), ...}. The intervals in F are sorted in ascending order of their p-value (= lb plus h-value at its associated ver- tex), which is an underestimate of the arrival time through this interval.\nPartial Stationary Node Expansion In partial stationary node expansion, instead of finding the speed profiles for all reachable intervals at once, we only generate the node based on the reachable interval that is most promising. As shown in Algorithm 2, if n.F is empty and its previous action is move, we do rotate expansion to retrieve its neighbor nodes [Line 4-5]. Otherwise, instead of performing move expan- sion, we only retrieve all the reachable intervals for n.F [Line 7]. In case n.F is not empty, we pop the reachable in- terval with the smallest p-value in n.F and generate a neigh- bor node based on it [Line 10]. Finally, if n.F remains non- empty, we update the heuristic value of n using the smallest p-value in n.F and reinsert n into OPEN [Line 12-13].\nTheorem 2 (Completeness and optimality of SSIPP with PE). The partial expansion mechanism preserves the com- pleteness and optimality of SSIPP. Detailed proof is provided in the Appendix."}, {"title": "4.4 Speed Profile Solver (SPS)", "content": "Given the line segment \u03d5i,j and safe intervals S from Level 2, SPS aims to find a speed profile li,j(t) with the shortest action time that satisfies both the dynamic constraints shown in Eqs. (1) and (2) and temporal constraints introduced by S (i.e., the agent remains within the safe interval while pass- ing a vertex). This section introduces two SPS as examples. Notably, MASS is adaptable to other solvers, as long as it meets the specified constraints.\nBinary Acceleration Solver (BAS) We adopt BAS from (Kou et al. 2019). This solver assumes that the agent begins by waiting at the first vertex vi of the line segment \u03d5i,j for a duration of twait. Then, it moves with its maxi- mum acceleration until reaching its maximum speed, moves at this speed for a duration of tmove, and finally decelerates with its maximum deceleration to stop at vj. However, when the length of \u03d5i,j is small, the speed profile forms a triangle shape, where the agent accelerates to a lower peak speed and then decelerates to stop at vj. tmove can be computed based on the length of \u03d5i,j. Our task is to get the twait that minimizes action time while ensuring that li,j(t) satisfies"}, {"title": "4.5 Lifelong MAMPD", "content": "In this section, we extend MASS to address the lifelong MAMPD problem. Many works have been done to extend the single-shot MAPF problem to the lifelong scenario. In this work, we adapt the state-of-the-art method Rolling- Horizon Collision Resolution (RHCR) (Li et al. 2021) to MASS. RHCR decomposes the lifelong MAPF problem into a sequence of windowed MAPF instances. Specifically, it plans collision-free paths for tw timesteps and replans paths once every th timesteps (tw \u2265 th). However, in MASS, the actions can have arbitrary action time. As a result, we can no longer determine a fixed replanning window size tw that guarantees that all agents have just completed their actions and arrived at vertices at time tw. In this work, we incor- porate an adaptive window mechanism that apply different window sizes for different agents.\nAdaptive Window Similar to RHCR, we trigger replan- ning every th time duration to plan for the next episode. However, since planning for a fixed episode length tw is not feasible, tw serves only as the minimum size of the replan-"}, {"title": "5 Empirical Evaluation", "content": "We implemented both our and baseline methods in C++. We conducted all experiments on an Ubuntu 20.04 machine equipped with an AMD 3990x processor and 188 GB of memory. Our code was executed using a single core for all computations. The source code for our method is publicly accessible at https://github.com/JingtianYan/MASS-AAAI."}, {"title": "5.1 Single-Shot MAMPD", "content": "In this experiment, we use PBS as Level 1 and both BAS and BCS as Level 3. We denote the resulting two vari- ants as MASS(BAS) and MASS(BCS). They are further combined with the partial expansion mechanism, denoted as MASS(BAS) w/ PE and MASS(BCS) w/ PE. We com- pare these methods with a straightforward extension of SIPP-IP (Ali and Yakovlev 2023). SIPP-IP is a state-of- the-art single-agent safe interval path planner designed to accommodate kinodynamic constraints and temporal obsta- cles, making it a suitable representation of motion-primitive- based methods. To adapt SIPP-IP for multi-agent scenarios, we replaced Level 2 and Level 3 in MASS with the SIPP-IP.\nSimulation Setup We evaluated all methods on four-neighbor grid maps, including empty (empty-32-32, size: 32\u00d732), random (random-32-32-10, size: 32\u00d732), room (room-64-64-8, size: 64\u00d764), den520d (den520d, size: 256\u00d7257), Boston (Boston_0_256, size: 256\u00d7256), warehouse-small (warehouse-10-20-10-2-1, size:"}, {"title": "5.2 Lifelong MAMPD", "content": "In this experiment, we use PP with random start as Level 1 for MASS(BAS) and MASS(BCS), incorporating the partial expansion mechanism. We use PP w/ ADG (Varambally, Li, and Koenig 2022) to represent methods that combine MAPF with a robust execution framework. PP w/ ADG uses RHCR"}, {"title": "Theoretical Proofs", "content": "Lemma 1. Given travel time for rotate(\u03b8i, \u03b8j) is no greater than the sum of travel time for rotate(\u03b8i, \u03b8k) and rotate(\u03b8k, \u03b8j), \u2200\u03b8k, duplicate detection mechanism does not affect the completeness of SSIPP.\nProof. Assume we have two SSIPP nodes n and n' where n.v = n'.v, n.\u03b8 = n'.\u03b8, and n.ub = n'.ub, if n.lb < n'.lb, we can only keep n in the OPEN without losing complete- ness. If n.a = n'.a, since both n and n' can perform the same type of node expansion (either rotate expansion or move expansion), we can easily prove that pruning n' does not compromise completeness.\nIn the case where n.a \u2260 n'.a, it indicates that n' can generate different child nodes during expansion. Let np de- note the parent node of n, with np.a = n'.a. For any child node generated by n', np can generate a correspond- ing node at the same vertex and orientation. To prove com- pleteness, we show that the child nodes generated by np at the same vertex and orientation always have a smaller lower bound than those generated by n'. Let \u02dcnp and \u02dcn' represent the nodes generated at a given vertex and orientation by np and n', respectively. We define D(n1, n2) as the mini- mum time required to transition from the state in n1 to the state in n2. The lower bound for \u02dcnp can be represented by \u02dcnp.lb = np.lb + D(np, \u02dcnp), while \u02dcn'.lb = n'.lb + D(n', \u02dcn'). From definition, we can have:\nn.lb = np.lb + D(np, n) (3)\n\u02dcnp.lb = n.lb \u2212 D(np, n) + D(np, \u02dcnp) (4)\nD(\u02dcn', n') = D(\u02dcnp, np) (5)\nGiven D(\u02dcnp, np) \u2264 D(np, n) + D(n, \u02dcnp), this means mov- ing directly from np to \u02dcnp takes no more time than taking two steps. Combine this with Eq. (4) we can have:\n\u02dcnp.lb = n.lb \u2212 D(np, n) + D(np, \u02dcnp) (6)\n < n.lb + D(n, \u02dcnp) (7)\nSince n.lb < n'.lb, using Eqs. (5) and (7) we can have:\n\u02dcnp.lb \u2264 n.lb + D(n, \u02dcnp) (8)\n < n'.lb + D(n', \u02dcn') (9)\n\u02dcn'.lb (10)\nThus, we prove that the child nodes generated by n' always have a higher lower bound than those generated by np at the same vertex and orientation.\nTheorem 1. (Completeness and optimality of SSIPP). SSIPP is complete and returns the optimal solution if one exists when Level 3 is complete and optimal.\nProof. We begin by proving the completeness of SSIPP fol- lowed by the proof of its optimality. Since T contains a fi- nite number of safe intervals, the search space of SSIPP is finite. Thus, SSIPP can terminate within a finite time if no solution exists. During the stationary node expansion, given that Level 3 is complete, we can explore all reachable safe"}, {"title": "Appendix", "content": "intervals, ensuring that a solution will be found if it exists. We then prove the optimality of SSIPP. Since the f-value of an SSIPP node is a lower bound on the arrival times of its corresponding plan, the smallest f-value of the SSIPP nodes in OPEN, denoted as f (n), is a lower bound on the ar- rival times of the corresponding paths of the SSIPP nodes in OPEN. When f(n) \u2265 travel_time(p*), no corresponding paths of the SSIPP nodes in OPEN can have shorter arrival times than p*. SSIPP is complete and optimal.\nTheorem 2. (Completeness and optimality of SSIPP with PE). The partial expansion mechanism does not change the completeness and optimality of SSIPP.\nProof. The completeness of SSIPP is maintained because the partial stationary expansion mechanism, while delaying the exploration of some nodes, does not exclude any node from eventual expansion. As the search progresses, all nodes with the potential to lead to a solution are eventually ex- panded, ensuring that a solution, if one exists, will be found. We then prove the optimality is preserved when using partial stationary expansion. Even though not all children of a node are expanded immediately, we re-insert their parent node with updated f-value back to OPEN. The updated f-value is an underestimation of those child nodes. Thus, we can reuse the proof from Theorem 1. Therefore, partial expan- sion retains the completeness and optimality in SSIPP. \udbff\udc1e"}, {"title": "Definition 1. (Rotate)", "content": "A rotate(\u03b8i, \u03b8j) lets an agent change its orientation from \u03b8i \u2208 \u0398 to \u03b8j \u2208 \u0398 on its current vertex. This action begins and ends with the agent at zero speed and follows a predefined angular velocity profile. The action time of rotate(\u03b8i, \u03b8j) is no greater than the sum of the action time of rotate(\u03b8i, \u03b8k) and rotate(\u03b8k, \u03b8j) for all \u03b8k."}, {"title": "Definition 2. (Move)", "content": "A move(vi, vj) lets an agent move for- ward in its current orientation from vi to vj along a straight line segment \u02dcvi,j, which may include one or more vertices. This action begins and ends with the agent at zero speed and follows a speed profile li,j(t | \u03a6i,j), denoted as the distance traveled by an agent as a function of time t along a given line segment \u02dcvi,j. For agent am, the speed profile of its move action is constrained by the following dynamic constraints:\nUkm < \\frac{d^k li,j(t | \u03a6i,j)}{dt^k} < Ukm, k \u2208 {1, 2} (1)\n\u02dc \nli,j(t | \u03a6i,j)\ndtt=0,Tm = U1m (2)\nwhere U1m and U2m represent the lower and upper bounds of speed (when k = 1) and acceleration (when k = 2), respec- tively, with the minimum speed being U0m = 0. The planner needs to determine a speed profile (including Tm) for each move action. We define a move action as dynamically feasi- ble if its speed profile satisfies these constraints."}]}