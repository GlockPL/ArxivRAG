{"title": "Abduction of Domain Relationships from Data for VQA", "authors": ["Al Mehdi Saadat Chowdhury", "Paulo Shakarian", "Gerardo I. Simari"], "abstract": "In this paper, we study the problem of visual question answering (VQA) where the image and query\nare represented by ASP programs that lack domain data. We provide an approach that is orthogo-\nnal and complementary to existing knowledge augmentation techniques where we abduce domain\nrelationships of image constructs from past examples. After framing the abduction problem, we pro-\nvide a baseline approach, and an implementation that significantly improves the accuracy of query\nanswering yet requires few examples.", "sections": [{"title": "Introduction", "content": "Visual Question Answering (VQA) is an AI task designed to reason about images. Commonly, the im-\nage is transformed into a \u201cscene graph\u201d that enables the deployment of more formal reasoning tools.\nFor example, in recent work, both the scene graph and associated query were represented as an ASP\nProgram [2, 1]; however, notably the scene graph itself only contains information about the scene, but\nlacks commonsense knowledge \u2013 in particular, knowledge about the domains of attributes identified by\nthe scene. Existing work to address this shortcoming relies on leveraging large commonsense knowl-\nedge graphs for obtaining domain knowledge [5, 6, 7]. However, such approaches require the ability\nto accurately align the language of the knowledge graph with the language of the scene graph. Fur-\nther, for some applications, this does not guarantee that the aligned knowledge graph will necessarily\nimprove VQA performance (e.g., if domain knowledge relevant to the queries is not possessed in the\nknowledge graph). In this paper, we provide an orthogonal and complementary approach that leverages\nlogical representations of the scene graph and query to abduce domain relationships that can improve\nquery answering performance. We frame the abduction problem and provide a simple algorithm that\nprovides a valid solution. We also provide an implementation and show on a standard dataset that we can\nimprove question answering accuracy from 59.98% to 81.01%, and provide comparable results with few\nhistorical examples.\nMotivating Example. Consider the simple scene graph depicted in Figure 1 and the query \u201cWhat is the\ncolor of the fruit to the right of the juice?\". Without the shaded nodes (which indicate domain information\nexternal to the image) there is no attribute of any constant associated with banana that is associated with\nthe domain color or the domain fruit. Hence, the only answer would be to assume that there is no fruit or\nthe color information is not given, or randomly guess large (while not a color, it is an attribute) or yellow.\nIn this paper, we will look to abduce these domain relationships from a limited number of examples.\""}, {"title": "Technical Preliminaries", "content": "We extend the framework of [2], which represents both images and queries as ASP programs (and the\nprograms can be directly represented as an equivalent scene graph as shown in Figure 1). Their approach\nto VQA leverages a neurosymbolic framework and was tested on synthetic datasets (e.g., CLEVR [4])\nthat involve limited objects and attributes. We seek to extend their results to real-world datasets such\nas GQA [3], which are more complex. We follow the logic programming construct as [2] in that we\nhave logical facts representing the scene graphs (\u03a0\u00b9), the query to be answered (\u03a0\u00ba), as well as standard\n\u201cVQA helper\u201d rules (\u03a0R).\nWe assume the existence of a first order logical language (constants &, variables V, predicates P).\nSet & has several subsets: objects (Cobj), attributes (Catt), domains (Cdom), and single choice questions\n(CsinChoice). Additionally, we will have a special binary predicate assign where the first argument is an\nattribute and the second is a domain. Every attribute can thus be associated with one or more domains via\natom assign(a,d), meaning that attribute a has domain d. We will also define Answer Set Programming\n(ASP) rules in the usual manner; a rule with no body is a fact and a set of rules is a program. Given a\nprogram II, the subset of facts in II where the head is formed with assign is called the \"domain relation-\nships\", and denoted ID. Likewise, we assume programs representing an image and a query, \u03a0I and \u03a0\u00ba,\nrespectively, that do not contain domain relationships, and a common set of rules \u03a0R that answers the\nquery using \u03a0\u00b9 and \u03a0\u00ba. Also, we shall use the standard ASP semantics based on interpretations [2], and\nuse the notation I |= \u03a0 to denote that interpretation I satisfies program \u03a0. Further, we say that program\n\u041f\u2081 |= \u03a02 (read \u201c\u03a0\u2081 entails \u03a02\u201d) meaning that all interpretations that satisfy \u03a0\u2081 also satisfy \u03a02.\nIn this work, we are primarily concerned with the case where there is a common ID for a collection\nof image-query program pairs (\u201cexamples\") denoted (\u03a0,\u03a0), ..., (\u03a0, \u03a0). We may also know that a\ngiven (\u03a0, \u03a0) is associated with some set of ground truth IT. Due to the lack of domain knowledge,\nIUIUI may not entail IT. However if an oracle provides a correct ID, we have that I U\u03a0\u03a1\u039f\nUND |= HT. We show an example of this case below taken from the scene graph dataset of [3]\n(depicted in Figure 1), which we also use in our experiments.\""}, {"title": "Fallback Rules", "content": "In this framework, where we may have an absent or partial ID, it is useful to have\n\u201cfallback rules\u201d of the form: assign(att, default) \u2190 \u00ac assign(att,DOM). This assumes\na special attribute constant \"default\" to which an object without an attribute falls back. The next example\naugments Example 2.1 with fallback rules:"}, {"title": "Abducing Domain Relationships", "content": "We now formalize our problem. Given examples EX = {(\u03a0,\u03a0),\n..., (\u03a0, \u03a0)} with a common rule set I^ (which may or may not include fallback rules) and correspond-\ning ground truth GT = {\u03a07,...,\u03a0\u039f\u03a4 }, then (EX, GT, IR) is a domain abduction problem (DAP).\nAny ID containing only facts formed with assign in the head is a hypothesis for a DAP. A hypothesis\nID is an explanation for DAP (EX, GT, I^) if and only if for all i we have IUHUHUID |= HET.\nHowever, when EX, GT are noisy (e.g., produced from a machine learning system) there may be no\nexplanation; in such cases, we may be able to find a hypothesis ID that maximizes some accuracy or\nrecall metric. For example, finding ID that maximizes |GT\u2229{\u03a0\u0218T \u2208 GT s.t. IUIUIUID |= \u03a0\u0218T }|\n(where || is set cardinality) would lead to maximized accuracy."}, {"title": "A Practical Heuristic Algorithm", "content": "In this section, we present a practical, heuristic algorithm for finding a DAP, that while is not guaranteed\nto maximize the accuracy of question answering, we show to perform very well in practice. There are\nseveral reasons as to why we adopt this more practical approach. First, in the general case, a brute-force\napproach is intractable. Second, even if it is possible to exactly optimize an accuracy metric as described\nin the previous section, it may still perform poorly when confronted with unseen data due to overfitting.\nThird, in some cases, the query itself can reveal portions of the ground truth. To address all of these is-\nsues, we introduce our practical heuristic algorithm FAST DAP (Algorithm 1). Regarding the first point,\nthe algorithm is highly performant, requiring only one pass over all examples in EX \u2013 this also allows for\ntrivial parallelization. Second, we only add facts to ID that support a certain number of examples, which\nacts as a form of regularization; we then tune this threshold to maximize accuracy. To address the third"}, {"title": "Evaluation", "content": "We now report on the results of our experimental evaluation. We use the GQA dataset [3], allowing us to\nbuild on the results of [2], which uses the CLEVR [4] synthetic data. Note that we use ground truth ASP\nrepresentations of the images and queries. We examine our practical heuristic in four different ways.\nFirst, we examine the accuracy improvements when employing FAST-DAP. Second, we examine its data\nefficiency (e.g., how many examples in EX are required to provide useful results). Third, we examine the\nsensitivity of the support threshold for elements of ID. Finally, we examine running time. We created\nour implementation in Python 3.11.7 and use the Clingo solver for the ASP engine. Experiments were\nrun on an Apple M2 machine with a 10-core CPU, and 32GB of RAM. All computations were carried out\nusing only the CPU (the system's GPU was not used). We now present the results of each experiment.\nAccuracy. We assess our approach's accuracy against the baseline (no \u03a0D), evaluating improvements\nwith and without fallback rules (FBR and No FBR), both utilizing FAST-DAP. For the baseline (no\nFAST-DAP), the ASP solver either provides an answer or returns \u201cempty\u201d if it cannot deduce one. On our\ntest set (disjoint from the examples), the baseline accuracy across all question types was 59.98% with-\nout domain information. Incorporating domain information learned from the training set significantly\nboosted accuracy to 80.62% without fallback rules, and 81.01% with them. To gain deeper insights, we\nanalyze specific question types, a subset of which is presented in Table 1. Some types, such as verifica-\ntion questions, show minimal dependence on domain categorization, while others rely more heavily on\nit. Additionally, certain questions require translating specific concepts into general terms (FAST-DAP,\nlines 9-14), like generalizing \u201cbanana\u201d to \u201cfruit\u201d or \u201cjuice\u201d to \u201cdrink.\u201d In Table 1, all non-choice queries\nrequire such generalization."}, {"title": "Conclusion", "content": "In this paper, we introduced a practical heuristic algorithm designed to infer domain relationships from\na logical representation of data specifically for visual question answering. Our algorithm is highly ef-\nficient, requiring just a single pass over the data, and it significantly enhances accuracy compared to\nusing a logical representation that does not leverage domain information. Despite its strong practical\nperformance, an important limitation of our approach is that there are no theoretical guarantees for the\nsolutions it obtains. A promising direction for future research focused on addressing this limitation is to\nrefine our approach by incorporating meta-cognitive AI [8] techniques."}]}