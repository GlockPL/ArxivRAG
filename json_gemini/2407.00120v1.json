{"title": "Automated Web-Based Malaria Detection System with Machine Learning and Deep Learning Techniques", "authors": ["Abraham G Taye", "Eshetu Negash", "Moges Abebe", "Sador Yonas", "Yared Minwyelet", "Melkamu Hunegnaw Asmare"], "abstract": "Malaria parasites pose a significant global health burden, causing widespread suffering and mortality. Detecting malaria infection accurately is crucial for effective treatment and control. However, existing automated detection techniques have shown limitations in terms of accuracy and generalizability. Many studies have focused on specific features without exploring more comprehensive approaches. In our case, we formulate a deep learning technique for malaria-infected cell classification using traditional CNNs and transfer learning models notably VGG19, InceptionV3, and Xception. The models were trained using NIH datasets and tested using different performance metrics such as accuracy, precision, re- call, and F1-score. The test results showed that deep CNNs achieved the highest accuracy - 97%, followed by Xception with an accuracy of 95%. A machine learning model SVM achieved an accuracy of 83%, while an Inception-V3 achieved an accuracy of 94%. Furthermore, the system can be accessed through a web interface, where users can upload blood smear images for malaria detection.", "sections": [{"title": "Introduction", "content": "Malaria is a life-threatening infectious disease, that has a significant impact on global health. As of more recent data, it is estimated that around half of the world's population is at risk of contracting malaria. In 2019, there were approximately 229 million cases of malaria reported worldwide. This resulted in an estimated 409,000 deaths, affecting vulnerable populations such as pregnant women and infants and small children five years old. Malaria continues to pose a substantial burden on public health, emphasizing the urgent need for effective prevention, diagnosis, and treatment strategies [1].\nMalaria is a deadly human disease caused by organisms called Plasmodium genus. Malaria infections are largely spread among humans via the bites of so-called malaria vectors adult females belonging to Anopheles-type mosquitos. Widely speaking, Plasmodium infection is caused by many species of Plasmodium genus protozoa [2]. Figure one shows the lifecycle of the Plasmodium parasite. All five species' life and infective cycles are similar. And their morphology and body shapes look alike on animals [3].\nAccording to the World Health Organization (WHO) statistics, malaria infection causes over one million human infections each year, with a particularly alarming impact in certain regions. For instance, as referenced in [5], there were approximately 219 million reported cases of malaria across 87 countries affected by the epidemic. Africa is the most affected continent with 95% of all malaria cases reported and 96% of all deaths [4,5]. The WHO report also highlights the devastating toll of malaria in Africa, where it accounts for a significant proportion of the top ten causes of mortality."}, {"title": null, "content": "Malaria is among the most prominent reasons for being ill or dying. Malaria infections have been recorded in more than 75 percent of the landscapes below 2000m (about 1.24 mi) elevated levels in Ethiopia [7]. In Ethiopia, the main epidemics happen every five-eight years while focal ones are happening annually [8]. The population of Ethiopia is more than 100 million and over 68 percent of this population is at risk [7, 9]. Annually, there are approximately 2.9 million of the malaria patients and this leads to malaria death, increasing sharply in epidemics while morbidity and mortality dramatically increase.\nThere is a need for early detection and quick care and management of malaria. It is a paramount importance in reducing death rates linked with the disease. It is recommended to initiate treatment promptly, preferably 24 hours after having had a fever, particularly in vulnerable populations such as children under five years of age [10]. Early intervention is fundamental in preventing severe complications and reducing mortality rates.\nIn Sub-Saharan countries, one of the major priorities is the installation of early-warning mechanisms for epidemics against malaria. There is a need for novel diagnostic approaches because current methods used in diagnostics like microscopic vision analysis of blood smears and RDTs have their drawbacks. An exciting breakthrough in this area is the introduction of image analysis methods using deep learning which is a sub-domain of Artificial Intelligence. This automated approach holds great potential to complement and enhance current diagnostic tools for more accurate and efficient malaria diagnosis.\nComputer-aided diagnosis using deep learning techniques has shown promising results in medical imaging analysis, including malaria classification. In this context, a promising new avenue emerges with the application of supervised machine learning techniques on health sector. By leveraging machine learning algorithms in malaria classification systems, we can achieve a significant improvement in the automation of medical image analysis. By implementing an automated malaria detection system that utilizes images extracted from blood smear films, we can ensure more precise measurements in malaria diagnosis. This, in turn, would lead to reduced delays in treating patients and alleviate the burden on physicians who currently spend considerable time on diagnosis.\nBearing the above-mentioned malaria diagnostic techniques, automated detection systems are being developed by different researchers to enhance and combat the prevalence of the disease. The application of supervised machine learning techniques has revolutionized medical image analysis, particularly in the field of malaria detection systems.\nThis paper is motivated by the objective of implementing an automatic malaria detection system that utilizes supervised machine learning methods to achieve precise diagnosis and efficient detection of the malaria parasite. We analyzed a deep learning approach for malaria classification using traditional CNNs and transfer learning models such as VGG19, InceptionV3, and Xception.\nTherefore, the motivation behind this paper lies in the imperative to develop an automated malaria classification system that empowers accurate and precise diagnosis by employing supervised machine learning approaches. By harnessing the power of these advanced techniques, we aim to enhance the efficiency of malaria parasite detection, contributing to improved healthcare outcomes for individuals affected by this devastating disease."}, {"title": "Literature Review", "content": "The existing literature on malaria detection encompasses a wide range of studies conducted in both endemic and non-endemic regions. Researchers have explored various aspects of malaria detection, including the identification and classification of malaria parasites, feature extraction techniques, machine learning algorithms, and the integration of innovative diagnostic tools. These studies have yielded valuable insights into the strengths, limitations, and potential applications of different detection approaches."}, {"title": "Literatures on Automated Malaria Diagnosis", "content": "In this section, we provide comprehensive information about our findings on automated microscopy for diagnosing malaria. We have compiled a vast number of references, covering many articles published on this topic, especially those from the past decade.\nThe field of automated cell microscopy for malaria diagnosis encompasses a wide range of research. Generally, most systems adhere to a set of essential processes. The subsequent step usually revolves around detecting and segmenting individual blood cells, such as infected or uninfected. The RBC detection and segmentation section provides various segmentation methods utilized for diagnosing malaria microscopically. After cell segmentation, many articles have proposed methods for characterizing an attribute vector summarizing the appearance of the segments. Different features, as well as strategies of feature selection presented in the literature are presented in the Feature Extraction and Selection section.\nIn the field of malaria detection, researchers have employed diverse techniques and methodologies, ranging from traditional microscopic examination of blood smears to advanced computer-based analysis using machine learning and image processing algorithms. These algorithms have shown promise in improving the speed and efficiency of conducting malaria diagnosis."}, {"title": "Deep Learning and Transfer Learning for Malaria Detection", "content": "The paper \"Deep Learning and Transfer Learning for Malaria Detection\" by Singh et al advocates for automated diagnostic processes using deep learning technologies. The objective of the paper is to enhance diagnostic accuracy by evaluating parasitemia in microscopic blood slides. The paper discusses using transfer learning and fine-tuning methods for training CNNs such as ResNet50, ResNet34, and VGG-19 on a dataset of stained pictures of infected and uninfected erythrocyte. This approach uses the variance principle as it characterizes both the intensity of the Plasmodium parasites and the RBCs. On this note, the study reveals that the VGG-19 model had the highest accuracy scores, based on the parameters considered and employed data set. This study is consistent with previous findings that show that deep learning algorithms can detect malaria. The results have been applied in constructing more advanced deep learning-based malaria disease diagnosis device. [35]"}, {"title": "Malarial Parasite Classification using Recurrent Neural Network", "content": "The paper proposes use of a recurrent neural network (RNN) for classification of segmented red blood cells (RBCs) into normal RBCs and infected cells. The infected cells are further classified into falciparum and vivax plasmodium. The paper acknowledges that the complexity of cell nature and image uncertainties make cell segmentation and morphological analysis among the challenging"}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "content": "The paper titled \"ImageNet Classification with Deep Convolutional Neural Networks\" by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton obtained the top-1 and top-5 percentages of 37.5% and 17.0% respectively, with this being superior to the best reported results until that time. It was made up of five Convolutional layers with most of their preceding max-pooling layers followed by three final fully connected layers which ended in a 1K-way SoftMax Authors used non-saturated neurons, and the implemented convolution operation on the GPU allowed to make the training faster. Additionally, they implemented dropout a modern, and regularization method for minimized overfitting of the fully connected layers. Nevertheless, the variants of these models were submitted to the ILSVRC-2012 competition and achieved the first five test errors of 15.3%. [37]"}, {"title": "Towards Low-Cost and Efficient Malaria Detection", "content": "This paper Towards Low Cost and Efficient Malaria Detection contributes to additional research into malaria microscopy using low magnifications at affordable cost. The authors highlight the importance of early and correct diagnosis of malaria to avoid health complications, which is currently dependent access to expensive microscopes and experienced professionals in reading smears. The model implies that we can assist expert's load by improving cheap microscopes diagnostic accuracy using deep learning-derived methods. However, the absence of a reasonable-size dataset is a challenge in this area.\nHowever, in order to solve this problem, the article presents a large database of images containing photographs of smears in the blood of various malaria-infected patients examined using microscopes from distinct levels of cost and in multiple degrees of magnification. An extension of a partially supervised domain adapter is also proposed to apply the object detector in images obtained using the low-cost microscope. In essence, the work serves a good cause in developing cost-effective and efficient malaria detecting techniques with the aid of a large-scale data set as well as deep learning concepts. [38]"}, {"title": "Intelligent Deep Transfer Learning Based Malaria Parasite Detection and Classification Model Using Biomedical Image", "content": "An intelligent deep transfer learning-based malaria parasite detection and classification (IDTL-MPDC) model using Biomedical images in this paper. Firstly, this approach entails performing a digital filtering method called median filtering on the input image to remove digital noise and thereafter the denoising process is carried out. The Res2Net model with its best-tuned input parameters implemented through DE method is used as a classifier for extracting the relevant feature vectors. KNN classifier is employed to determine the appropriate classes and the blood smear images are classified. A benchmark data set is used for evaluating the performance of the IDTL-MPDC technique whose accuracy is 95.86%, sensitivity of 95.82%, specificity of 95.98%, and F1 score of 95.69% [41]\nIn this study, we discussed various ways of applying deep-learning techniques in medical imaging, looked at Convolutional Neural Networks, and studied some aspects of Transfer Learning as its application."}, {"title": "Methods and Materials", "content": "In our study, we utilized datasets sourced from the National Institute of Health (NIH) website, specifically accessing a malaria dataset that proved to be a valuable resource for our research [42]. The NIH dataset consisted of a total of 27,557 images, with 13,778 categorized as parasitized (malaria-infected) and 13,779 categorized as healthy (non-infected) samples. To ensure consistency and facilitate our analysis, we initially categorized the image files based on their corresponding tags, distinguishing between healthy and malaria-infected samples.\nIn addition to the challenges of limited availability, the local datasets we collected posed another issue. These datasets had low resolution due to the utilization of low-cost microscopes, resulting in blurry images that lacked the necessary level of detail for accurate segmentation and training of our model. In contrast, the NIH datasets were extracted from high-cost microscopes, providing more detailed features that were essential for training our model effectively. The disparity in image quality between the local datasets and the NIH dataset further emphasized the need for us to rely on the NIH dataset as a valuable resource for our research on malaria detection using transfer learning."}, {"title": "Pre-Processing of Datasets", "content": "Preprocessing includes transforming raw data into a format that can be easily used by the model. In this case, the pre-processing includes resizing and rescaling the images in the dataset to improve performance and reduce computation time. By performing data augmentation, normalization, and splitting, the models can learn meaningful features from the data and achieve better performance in image classification tasks. [45]\nData augmentation: Different types of transformation were performed on the training images such as horizontal and vertical flipping, rotation, shear and movement.\nData normalization: Standardization of the pixel values among the image files was achieved by scaling the pixel values down to a 0-1 range.\nData splitting: Train, valid, and test datasets were partitioned from that dataset. For the training of the machine learning models, we used the training set, for tuning of hyperparameters and evaluation of the performance of the models \u2013 the validation set, and finally to test the final performance of the models \u2013 the test set."}, {"title": "Training Methods", "content": "In the development of an automated malaria classification system, various machine learning and deep learning methods can be used to train the models. In this project, we utilized three core training methods, which are machine learning, deep learning, and transfer learning algorithms.\nMachine Learning: We used a Support Vector Machine (SVM) algorithm to train the model. SVM is a supervised learning algorithm that can be used to identify the boundary between the classes and classify the images as either infected or uninfected.\nDeep Learning: Convolutional neural networks (CNNs) are used to train the model that can learn features from the images by applying convolution operations on the pixels.\nTransfer Learning: We used pre-trained models such as VGG19, InceptionV3, and Xception to train the model to classify the cell images as either infected or uninfected."}, {"title": "Machine Learning Experiments", "content": "Machine learning encompasses the development of algorithms and techniques that enable machines to automatically learn and make precise predictions based on past observations. It involves the extraction of information from data through computational and statistical methods. As highlighted by [44], machine learning (ML) is a subfield of computer science that focuses on studying and constructing algorithms capable of learning from data and making predictions."}, {"title": "Support Vector Machines", "content": "In our paper, the emphasis lies on SVM, which is a powerful supervised machine learning algorithm known for its capability to find optimal decision boundaries in high-dimensional spaces, making it well-suited for classification tasks. Support Vector Machines (SVM) is a supervised machine learning algorithm that has gained significant attention and proven to be effective in various domains, including medical image analysis. In the case of malaria detection, where blood smear images can contain numerous features, SVM can effectively handle the complexity and variability of the data. By employing a kernel function."}, {"title": null, "content": "Nonetheless, SVM can deal with linearly separable and non-linearly separable data. The purpose of SVM is to find the best dividing line (hyperplane) in the data space (feature space), which will distinguish one class from another as much as possible. This characteristic allows SVM to handle complex and overlapping class distributions, which can be crucial in distinguishing between infected and uninfected blood smear images in malaria diagnosis.[45]"}, {"title": "Deep Learning Experiments", "content": "We designed a traditional CNN with three convolutional layers followed by max-pooling layers and two fully connected layers.\nCNNs have been shown to be highly effective for a wide range of image classification tasks, including malaria detection. They can learn complex features and patterns in the images, and can generalize well to new, unseen samples."}, {"title": null, "content": "We used a deep convolutional neural network (CNN) model with dropout, batch normalization, and RMSprop optimizer to perform image classification on a dataset of images. The model was implemented using the Keras Sequential API in Python. The model architecture consisted of a series of convolutional layers followed by max pooling layers, with dropout layers to reduce overfitting.\nThe specific architecture of the model included a series of three stacked convolutional layers comprising increasing number of filters, which are then followed by batch normalization and a layer of dropout.\nIt consisted of converting convolutional layers outputs to a vector and feeding this vector to the 256-unit dense layer with ReLU activation and batch normal and dropout after.\nDenser output layer of 2 units with the softmax activation function yielding probability distribution across two the classes.\nOverall, the use of a deep CNN with dropout and batch normalization can improve the performance of image classification models by reducing overfitting and improving the ability of the network to learn complex features from the input images.\nOur study utilized a deep convolutional neural network (CNN) model with dropout, weight initialization, and zero padding to perform image classification on a dataset of images. The model architecture consisted of a series of convolutional layers followed by max pooling layers, with dropout layers to reduce overfitting. The specific architecture of the model was as follows:\nThe first layer was a 2D convolutional layer with 32 filters of size 3x3 and the ReLU, with an input shape of (224, 224, 3). This was followed by a zero-padding layer\nNext, there were two more 2D convolutional layers with 32 filters of size 3x3 and the ReLU, followed by a max pooling layer with a pool size of 2x2, and a dropout layer\nThe next three sets of layers followed a similar pattern, with 64 filters of size 3x3 in the convolutional layers, and a max pooling layer with a pool size of 2x2, and a dropout layer\nThe final convolutional layer had 128 filters of size 3x3, followed by another max pooling layer with a pool size of 2x2, and a dropout layer with a rate of dropout_conv.\nThe output of the convolutional layers was flattened and fed into a dense layer with 256 units and the ReLU activation function, followed by another dropout layer.\nThe final output layer was a dense layer with 2 units and the softmax activation function, which output a probability distribution over the two classes.\nThe model was evaluated on the testing set using accuracy, precision, recall, and F1-score metrics, and the results were compared to a baseline model to assess the efficiency."}, {"title": "Transfer Learning", "content": "Traditional machine learning utilizes training and testing datasets with identical data distributions and feature spaces. The optimization and training of the model is a difficult and time-consuming process. The training requires a strong graphics processing unit (GPU) as well as millions of training dataset. [45] The transfer-learning is one of such powerful techniques because it utilizes knowledge acquired during the training of the pre-trained model for its initialization phase, and further adjusts itself by incorporating new information.\nIn this study, we will be exploring the use of transfer learning for malaria detection, using different pre-trained CNN models such as VGG, Xception, and InceptionV3. These models have been trained on large image datasets and have learned a set of general features that are transferable to other image classification tasks, including malaria detection.\nOur transfer learning approach involves training three different model architectures to demonstrate the impact of incremental unfreezing and fine-tuning on model accuracy. The three models are as follows:\ni. Model Architecture 1: Pre-trained model as a feature extractor with frozen layers\nii. Model Architecture 2: Pre-trained model as a feature extractor with incremental unfreezing and fine-tuning\niii. Model Architecture 3: Pre-trained model as a feature extractor with entire network unfreezing and fine-tuning\nIn the first model architecture, we used the pre-trained ImageNet model such as InceptionV3, VGG19, and Xception as a feature extractor and added fully connected layers on top to classify images. We froze the weights of the pre-trained model and trained only the top layers using categorical cross-entropy loss and the stochastic gradient descent (SGD) optimizer.\nUsed pre-trained model as feature extractor.\nAdded fully connected layers on top for classification\nFroze pre-trained model weights and trained only top layers\nUsed categorical cross-entropy loss and SGD optimizer\nTrained on training set, evaluated on validation set with accuracy and loss\nImplemented callbacks including early stopping, model, and learning rate reduction on plateau.\nIn the second model architecture, we used the pre-trained ImageNet model as a feature extractor and incrementally unfroze layers to fine-tune the entire network. We first set all layers except the last two blocks to non-trainable and trained the top layers using categorical cross-entropy loss and the SGD optimizer. Then, we unfroze the last two blocks and fine-tuned the entire network using the same loss function and optimizer.\nUsed pre-trained model as feature extractor\nIncrementally unfroze layers to fine-tune entire network\nTrained top layers with non-trainable layers (except last 2 blocks)\nUnfroze last 2 blocks and fine-tuned entire network\nUsed categorical cross-entropy loss, SGD optimizer,\nImplemented callbacks including early stopping, model checkpointing, and learning rate reduction on plateau\nPreprocessed images by resizing to 128x128 and normalizing pixel values\nTrained on training set, evaluated on validation set with accuracy and loss metrics.\nIn the third model architecture, we fine-tuned the entire pretrained ImageNet model from scratch for our binary classification task. We initialized the weights of the model with pre-trained weights and trained the entire network using categorical cross-entropy loss and the SGD optimizer. We also implemented the same callbacks.\nFine-tuned entire network from scratch with pre-trained weights\nUsed categorical cross-entropy loss, SGD optimizer, and implemented callbacks including early stopping, model checkpointing, and learning rate reduction on plateau.\nPreprocessed images by resizing to 128x128 and normalizing pixel values\nTrained on training set, evaluated on validation set with accuracy and loss metrics."}, {"title": "VGG-19", "content": "VGG-19 is a 19-layer deep Convolutional Neural Network is made up of 16 convolutional layers, 3 fully linked layers, and five max-pool layers. It is an image database with 14,197,122 pictures arranged in the WordNet hierarchy.[45] We used the pre-trained VGG19 model, which consists of 19 layers, including 16 convolutional layers and three fully connected layers."}, {"title": "Inception-V3", "content": "Inception-v3 is a convolutional neural network architecture from the Inception family that has been shown to attain greater than 78.1% accuracy on the ImageNet dataset1.[45] The Inception architecture introduces various inception blocks, which contain multiple convolutional and pooling layers stacked together, to give better results and reduce computation costs."}, {"title": "Xception", "content": "Xception is a deep convolutional neural network architecture that has shown excellent performance on the ImageNet dataset. It is based on the idea of depth-wise separable convolutions, which can reduce the number of parameters and computation while maintaining high accuracy."}, {"title": "Web Demo using TensorFlow.js.", "content": "In this section, we discuss the architecture and implementation of the web demo using TensorFlow.js for malaria detection. The web demo allows users to upload an image of a blood smear and receive a prediction of whether it is infected with malaria or not.[45]\nThe figure depicts the conventional ML architecture with a diverse tech stack that requires coordination and communication between multiple services, making it challenging to deploy machine learning models on websites. In contrast, TensorFlow.js has the potential to revolutionize the future of machine learning by offering a streamlined approach to deploying and executing machine learning models directly within web applications, enabling developers to build intelligent applications that can process data and make predictions in real-time. [54]\nIn this section, we discuss the deployment and testing of the web demo using TensorFlow.js for malaria detection. The web demo is deployed on a cloud-based platform, which allows for easy scalability and accessibility.\nThe architecture and implementation of the web demo are based on a front-end and back-end model, with the back end using TensorFlow.js to perform the prediction. The deployment and testing of the web demo involves several steps, including continuous integration and deployment and various types of testing."}, {"title": "Result and Discussion", "content": "In this section, we discuss the metrics used for performance evaluation of malaria detection. The selection of appropriate performance metrics is crucial in assessing the effectiveness of the models in real-world applications.\nAccuracy: The accuracy is the fraction of correctly classified samples over the total number of samples. It is computed as follow\nAccuracy = \\frac{(True Positive + True Negative)}{(True Positive + True Negative + False Positive + False Negative)}\nPrecision: The precision is the fraction of true positives (TP) over the sum of true positives and false positives (FP). It represents the proportion of positive predictions that are correct. It is computed as follows:\nPrecision = \\frac{(TP)}{(TP + FP)}\nRecall (Sensitivity): The recall (or sensitivity) is the fraction of true positives over the sum of true positives and false negatives (FN). It is computed as follows:\nRecall = \\frac{(TP)}{(TP + FN)}\nSpecificity: The specificity is the fraction of true negatives (TN) over the sum of true negatives and false positives (FP). Specificity represents the proportion of actual negatives that are correctly identified by the model. It is computed as follows:\nSpecificity = \\frac{(TN)}{(TN + FP)}\nF1-score: The F1-score is the harmonic mean of precision and recall, defined as 2 * (precision * recall) / (precision + recall). It represents the balance between the precision and recall.\nF1 score = 2 \\times \\frac{(Precision \\times Recall)}{(Precision + Recal)}\nSensitivity (Recall): Sensitivity is another name for recall, which is the division of true positives over the sum of TP and FN. It represents the proportion of actual positives that are correctly identified by the model.\nSpecificity: Specificity is the fraction of true negatives over the sum of true negatives and false positives. It represents the proportion of actual negatives that are identified\nMacro Average: Macro average computes the metric independently for each class and takes the average across all classes."}, {"title": "Machine Learning Results", "content": "The dataset used for this SVM machine learning model consists of malaria-infected and uninfected cells, totaling 13,779 images. The dataset was randomly split into two sets: 11,023 images for the training set, and 2,756 images for the testing set. In addition to the data split, a typical train- validate-test split was used to further divide the data into three subsets: a training set, a validation set, and a testing set. The training set consisted of 70% of the data (11,023 images), the validation set consisted of 15% of the data (approximately 2,067 images), and the test set consisted of 15% of the data (approximately 2,067 images).\nThe test set was kept hidden throughout the model development and training process to ensure that the model's performance could be accurately evaluated on unseen data. The data split was done randomly to ensure that each subset was representative of the entire dataset. The images were randomly shuffled and then split into the desired subsets to avoid any biases that might arise if the data were split in a non-random way. Overall, an SVM model was developed for malaria classification that achieved high accuracy on the testing set.\nThe hyperparameters for the SVM model were tuned using a exhaustive search over the hyperparameters in the specified ranges of values. The C and gamma hyperparameters for the RBF kernel were tuned over a range of values to identify a good starting point for the grid search. The grid search was performed over a wider range of hyperparameters using cross-validation to estimate the performance of each combination of hyperparameters. The range of hyperparameters searched over were C values from 0.1 to 100 and gamma values from 0.001 to 1."}, {"title": null, "content": "The optimal hyperparameters for the SVM model were determined to be C=1 and gamma=0.01. These hyperparameters were used to train the final SVM model, which achieved an accuracy of 84% on the testing dataset.\nThe SVM model achieved an accuracy of 83% on the testing dataset, with an average precision of 83%, recall of 83.5%, and F1-score of 83%. The Matthews correlation coefficient (MCC) was calculated to be 0.665, indicating a moderate level of agreement between the predicted and actual labels.\nThese results suggest that the SVM model performed reasonably well on the classification task, with a good balance between precision and recall. The values obtained for these metrics suggest that the model can perform well in both areas, with a slightly higher specificity than sensitivity. it suggests that the model is better at correctly identifying negatives than positives. In other words, the model may be more conservative in its predictions and more likely to classify a sample as negative to avoid false positives. This may be desirable in certain use cases, such as medical diagnosis where false positives can lead to unnecessary treatment or testing. sensitivity.\nThe confusion matrix for the model showed that it correctly classified 2,253 infected cells and 2,335 uninfected cells but misclassified 421 uninfected cells and 503 infected cells. This corresponds to a false positive rate of 15% and a false negative rate of 18%."}, {"title": "Deep Learning Results", "content": "The dataset used for this classification task consisted of images of malaria-infected and uninfected cells, totaling 27,358 samples. The dataset was split into three subsets using a train-validate-test split, with 23,254 samples randomly selected for the training set, while the remaining 4,104 samples were further split equally into the validation and testing sets. The purpose of this split was to train the model on the training set, tune the model's hyperparameters on the validation set, and evaluate the model's performance on the testing set. The split was done randomly to ensure that each subset was representative of the entire dataset, and the images were shuffled before being split to avoid any biases.\nA deep CNN model was developed with dropout, weight initialization, and batch normalization for the classification task. The model achieved an accuracy of 96% on the testing set, with an average precision, recall, and F1-score of 96%. The high accuracy, precision, and recall of the model suggest that it was able to effectively classify both infected and uninfected cells.\nA confusion matrix and classification report were provided to evaluate the model's performance in more detail. The confusion matrix showed that the model correctly classified 3,925 samples, including 1,994 uninfected cells and 1,931 parasitized cells. The model misclassified only 59 uninfected cells and 120 parasitized cells, resulting in a false positive rate of 3% and a false negative rate of 6%. The precision, recall, and F1-score were all high for both classes, indicating that the model had a balanced trade-off between false positives and false negatives.\nThe dataset used for this classification task consisted of images of malaria-infected and uninfected cells, totaling 27,358 samples. The dataset was split into three subsets using a train-validate-test split, with 23,254 samples randomly selected for the training set, while the remaining 4,104 samples were further split equally into the validation and testing sets. The split was done randomly to ensure that each subset was representative of the entire dataset, and the images were shuffled before being split to avoid any biases.\nA deep CNN model was developed with dropout, weight initialization, and batch normalization for the classification task. The model achieved an accuracy of 96% on the testing set, with an average precision, recall, and F1-score of 96%. The high accuracy, precision, and recall of the model suggest that it was able to effectively classify both infected and uninfected cells.\nTo evaluate the model's performance in more detail, a confusion matrix and classification report were generated. The confusion matrix showed that the model correctly classified 3,982 samples, including 2,004 uninfected cells and 1,978 parasitized cells. The model misclassified only 49 uninfected cells and 73 parasitized cells, resulting in a false positive rate of 2.39% and a false negative rate of 3.56%"}, {"title": "Transfer learning Results", "content": "For this classification task, we used a dataset consisting of 27,558 images of malaria-infected and uninfected cells. The dataset was split into three subsets using a train-validate-test split. Specifically, we randomly selected 16,000 images, with 8,000 images from each class, for the training set. We then randomly selected 6,000 images, with 3,000 images from each class, for the validation set. The remaining 5,558 images, with 2,751 images from each class, were selected for the testing set This split was done randomly to ensure each subset was representative of the entire dataset, and the images were shuffled before being split to avoid any biases. The split was chosen to allocate approximately 58% of the dataset to the training set, 22% to the validation set, and 20% to the testing set.\nWe used transfer learning with the VGG19 model to classify malaria-infected and uninfected cells, with the CNN layers frozen. The model was trained on a dataset consisting of 16,000 images, with 8,000 images from each class, and validated on a dataset consisting of 6,000 images, with 3,000 images from each class. The model was then tested on a dataset consisting of 5,558 images, with 2,751 images from each class.\nWe implemented a transfer learning approach with VGG19 architecture with frozen convolutional neural network. The model achieved a validation accuracy of 0.83 and a test accuracy of 0.83.\nThe precision, recall, and F1-score for both classes were 0.85, 0.80, and 0.82 for the healthy class, and 0.81, 0.86, and 0.83 for the infected class.\nWe found that the model had a moderate precision, recall, and F1-score for both healthy and infected classes. Specifically, the model had a precision of 0.85 and recall of 0.80 for the healthy class, and a precision of 0.81 and recall of 0.86 for the infected class.\nThe confusion matrix shows that the model correctly classified 2215 healthy cells and 2383 infected cells, while misclassifying 565 healthy cells and 397 infected cells. The AUC score for this model was 0.827."}, {"title": null, "content": "Overall, the model performed well, achieving high accuracy and AUC, despite the CNN layers being frozen. The frozen CNN layers allowed us to leverage the pre-trained weights and extract useful features from the images. The model was able to effectively differentiate between healthy and infected cells, which is crucial for accurately diagnosing and treating malaria.\nWe implemented a transfer learning approach with VGG19 architecture using incremental unfreezing and fine-tuning. The model achieved a validation accuracy of 0.87 and a test accuracy of 0.88.\nWe found that the model had a high precision, recall, and F1-score for both healthy and infected classes. Specifically, the"}]}