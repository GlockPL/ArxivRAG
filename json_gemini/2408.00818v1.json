{"title": "Y SOCIAL: AN LLM-POWERED SOCIAL MEDIA DIGITAL TWIN", "authors": ["Giulio Rossetti", "Massimo Stella", "R\u00e9my Cazabet", "Katherine Abramski", "Erica Cau", "Salvatore Citraro", "Andrea Failla", "Riccardo Improta", "Virginia Morini", "Valentina Pansanella"], "abstract": "In this paper we introduce Y, a new-generation digital twin designed to replicate an online social media platform. Digital twins are virtual replicas of physical systems that allow for advanced analyses and experimentation. In the case of social media, a digital twin such as Y provides a powerful tool for researchers to simulate and understand complex online interactions. Y leverages state-of-the-art Large Language Models (LLMs) to replicate sophisticated agent behaviors, enabling accurate simulations of user interactions, content dissemination, and network dynamics. By integrating these aspects, Y offers valuable insights into user engagement, information spread, and the impact of platform policies. Moreover, the integration of LLMs allows Y to generate nuanced textual content and predict user responses, facilitating the study of emergent phenomena in online environments.\nTo better characterize the proposed digital twin, in this paper we describe the rationale behind its implementation, provide examples of the analyses that can be performed on the data it enables to be generated, and discuss its relevance for multidisciplinary research.", "sections": [{"title": "1 Introduction", "content": "Online social media (OSM henceforth) have revolutionized the way we exchange information. From the user's perspective, these digital ecosystems are largely effortless [136], enabling convenient ways of exchanging personal content [1], seeking information [129] and synchronizing with others [37]. This convenience has catalyzed a massive digital shift in social and information exchanges from offline to online settings [136], which has provided novel access to massive amounts of online data regarding human behaviour [141]. Unconstrained by geographical barriers, the massive adoption of social media has given rise to novel phenomena that are absent in in-person interactions, such as the influence of complexity and artificial intelligence. Complexity in social media is strongly related to the motto \"more is different\" [7]: the idea that the co-occurrence of many, even similar, interactions within the same context can lead to unexpected phenomena. Examples include acts as simple and seemingly insignificant as following another user, or re-sharing content. Taken individually, these actions can be understood in terms of a user's activity, psychology, and engagement [91, 97, 141], but when repeated by vast amounts of users, these actions can determine the unexpected rise"}, {"title": "Y: Where the Digital World Comes to Life", "content": "and fall of a massively followed account (influencer) or they can create cascades of information re-sharing (viral content) [136]. Artificial intelligences (AIs) also influence online interactions since social media actions such as following, re-sharing, posting, and commenting can nowadays also be performed by non-human users. Social bots are AIs that pose as humans [49] and interact with human users, either beneficially or maliciously [140]. For instance, social bots can contribute positively to social media pluralism by automatically diffusing news and links that are external to social media platforms [139, 151]. However, social bots can also act by broadcasting biased content or diffusing misinformation, which exposes human users to a wider variety of harmful content [36, 140].\nDespite existing online, content engagement on social media can deeply affect humans in their real-world surroundings [78, 126]. Besides acting as a distraction [126], online posts can influence the emotions experienced by an individual, a phenomenon known as emotional contagion, which has been identified on platforms like Facebook [78]. Furthermore, social media interactions are mainly textual in nature, which can lead to some unresolved ambiguity in understanding communicative intents [141]. Dissonance is further exacerbated by the fact that social media content is often rich in cognitive, emotional, and psychological features [24, 141]. For instance, a post that expresses ideas in words or hashtags can also contain a familiar picture or emoticons that resemble recognizable facial expressions [140]. The negative impact of unresolved ambiguity and toxic or dissonant content in social media on mental health remains poorly understood [17]. While a causal relationship has yet to be determined, several recent studies have begun to link the longer hours spent on social media to depression disorders [17, 20].\nSocial media interactions might not depend solely on users themselves [96]. In contrast to in-person interactions, the experiences of online users are often reinforced by platform-specific algorithmic curation [46], i.e. embedding recommender or ranking systems in social media for bolstering user engagement. Recommender and ranking systems are algorithms that constantly suggest or re-direct engagement towards specific users or content. These algorithms ultimately guide the attention of vast audiences towards specific trending topics, influencers, or conversations with leanings similar to one's own [22, 32]. Algorithmic curation can reinforce users' biases while preventing healthy discussions, thus contributing to users' fragmentation across cognitive or social groups [69, 97]. These aspects raise crucial technical and ethical questions about balancing possibilities and risks concerning the role of human-AI interactions on social dynamics regarding information diffusion, opinion formation, and mental health [96, 115].\nWhy does having a Digital Twin of online social media platforms make sense?\nOSMs are complex systems characterized by countless emerging behaviors - both at the structural and social levels. Data-driven social studies provide valuable insights into such complexity and the phenomena it might generate. However, they suffer from natural limitations that often reduce their potential impact. Particularly, such studies often rely on limited - nonlongitudinal - data samples, cannot explicitly account for the \u201cinvisible\" although impactful hands of algorithmic curation, and are prone to noise due to the not always measurable impact the selected data sampling strategy has on the observed results. Moreover, they are dependent on the data access provided by online social media platforms (e.g., X/Twitter, Meta's Facebook/Instagram/Threads, Reddit, and others): access that is reducing over time even for research purposes - notwithstanding national and international efforts to regulate it (e.g., through the EU's Digital Service Act\u00b9).\nAll such considerations vouch for identifying complementary data sources that can offer completeness and algorithmic control and are not tied to access policies set by third-party entities. Online Social Media digital twins offer a first step in such a direction: they allow researchers to formulate hypotheses and test them in OSM-like controlled environments - accounting for such variables that open-ended data studies cannot model/infer. Indeed, such tools - supported by recent advances in Artificial Intelligence - cannot substitute data-driven studies; however, they can support in-vitro experiments fitted on real-world data and allow for a better understanding of the phenomena observed in the wild.\nWhich phenomena can emerge as a result of OSM simulated environments powered by LLM agents?\nThe rapid evolution of AI [115] has produced novel gaps in understanding last-generation social bots, powered by Large Language Models (LLMs) [3, 5]. LLMs are generative AI systems capable of understanding and generating human-like text even within social media ecosystems. They can generate convincing human texts with minimal human instructions - just simple prompts \u2013 without syntactic or grammatical errors [2, 3]. They can even impersonate specific profiles [39], e.g. posing as a statistics expert with a right-wing political leaning and high creativity, or express nuanced human emotions [73]. Such human-like capabilities are enabled by the fact that LLMs are trained on billions and billions of human-generated text.\nExploring LLMs' role within social media remains a crucial yet largely unexplored research question. While research on human-LLM interactions in social media considerably overlaps with past studies about humans and social bots [36, 49], the current research literature leaves a more interesting and unique research gap. Digital twins are reference\""}, {"title": "Y: Where the Digital World Comes to Life", "content": "models, simulated to gain insights about a physical counterpart [131]. For instance, an LLM might impersonate a patient in clinical therapy and thus be considered its digital twin [39]. Adopting LLMs as synthetic agents/online users can crucially proxy human behaviour, in line with several upcoming studies exploring \"artificial humans\" as digital twins of real-world users [39, 40]. Milestone research suggests that populations of these models can exhibit emergent behaviors similar to those found in humans, such as scale-free networks [40], patterns of information diffusion [52] and affective biases [2]. These preliminary results offer new opportunities for developing controlled environments in which researchers can gain a scientifically sound and interpretable understanding of real-world complex systems by investigating which empirical phenomena also arise in digital twins endowed with a limited set of rules.\nY: Where the Digital World Comes to Life. In view of the above research gap and the promising opportunities opened up by LLMs, in this work we introduce Y, a social media platform powered by LLMs, serving as a digital twin for complex agent-based social simulations.\nSo, why Y?\nDeveloping a platform like Y has several implications and motivations.\n\u2022 Firstly, by observing how LLMs interact with each other in a social media setting, researchers can gain insights into AI behavior, biases and cognitive capabilities within simulated social contexts.\n\u2022 Secondly, enabling algorithmic curation in a digital twin of social systems makes it possible to study how recommendation systems can impact user behaviors.\n\u2022 Last but not least, using digital twins to simulate social media interactions via LLMs sets the stage for unprecedented experiments that can test the cognitive, psychological, social, and communicative facets of real social media.\nIn the subsequent sections, we first review the recent research literature that has been pivotal in the development of Y (Section 2). Following this, we present a detailed technical overview of the system (Section 3) and illustrate its capabilities through a simple case study (Section 4) to provide better context for its behaviors. Finally, we explore the potential impacts of a social media digital twin on multidisciplinary computational social science research (Section 5), and conclude with a brief discussion on the future evolution of the project (Section 6)."}, {"title": "2 Related Works", "content": "This section gives an overview of the relevant literature concerning the development of Y. We consider research on Online Social Platforms (OSP) as either simulation studies or empirical studies, following the highest level of the taxonomy defined in [110]. Focusing on simulation studies, we delve into agent-based simulations, discussing how OSPs are integrated, and we discuss recent advancements since the advent of LLMs, considering the move towards creating OSP \"digital twins\". We also provide an overview of some of the main tools for social simulations.\nComputational Social Science. Collections of things can have properties that don't apply to their individual parts. For example, the property of pressure pertains to gases as a whole, resulting from the interactions among molecules. The same idea that applies in physical substances also applies to societies, though humans are far more complex than molecules. The field of computational social science [33] - at the crossroads of complex systems, network science, and big data analytics - seeks to discover universal laws of human behavior through computational methods. In the natural sciences, experimental designs allow stringent control over variables, enabling precise isolation and examination of causal relationships. This control aids in replicating experiments and validating results. On the contrary, in the social sciences, experiments are challenging due to both practical and ethical constraints. Fortunately, the advent of the digital age has not only led to the production of an unprecedented amount of data traces from human activities, but enhancements in computational means has also opened possibilities for more complex experimental setups, overcoming previous difficulties. Social sciences studies utilize a variety of methods, such as surveys [19], computer simulations [58], observational research \u2013 encompassing statistical analysis [99], network analysis [156] and data mining [8] \u2013, and experimental and quasi-experimental approaches [72, 134].\nDefined at a high level, social simulations [138] are computational models designed to replicate the behavior and interactions of individuals or groups within a social system. Simulations can be implemented using different frameworks, Agent-Based Modeling [18] being one of the most commonly employed. In any case humans \u2013 and other individual elements, such as institutions, technologies, etc. can be seen as software entities called agents which can be part of an environment and can be embedded in a social network [59] influencing their decisions and behaviours. As the latter is often represented as a graph \u2013 being fully connected [137] or having a more complex configuration [106] \u2013, agents can have a set of edges, representing their social relationships, which can be static or dynamics and may hold attributes representing characteristics of the relationship, e.g., strength, trust, or influence. For example, it may be that the network of interactions evolves as a simulation progresses as a consequence of a pre-defined rule of the model, as in the Barabasi-Albert model [12] of network formation, or of the evolution of other agent's attributes, as in adaptive networks models [107]. Agents can, in fact, be enriched with attributes, such as demographic factors or cognitive biases [41], which are mainly static during a single simulation and with states, i.e., dynamic attributes dependent on social influence, representing factors like infection [87], adoption [133], opinions [41], or emotions [132], generally modelled as simple numerical variables and often the core element of the social simulation study. To execute the social simulation, each agent follows a set of rules, which are algorithms dictating when an agent becomes active, the actions they can take, and the impact of these actions on themselves and the population, which can be more or less strict, giving the agent different degrees of autonomy. This flexible framework allows for high degrees of heterogeneity across different dimensions, creating agents with different beliefs, preferences, behaviours, values and positions in the social systems [138]. Social simulation studies has been used in different fields to explore and understand emergent behaviours [57] in social systems since the 1960s, with prominent examples from Conway's Game of Life [34], to the Schelling model of segregation [130], and Axelrod's prisoner dilemma [9]. More recently, social simulations have been used to study epidemics [87], diffusion of information [61], belief and emotion dynamics [41], economics and finance [10], urban dynamics [35], political sciences [45], and others.\nSimulations of online platforms. In recent years a great deal of attention has been dedicated to the study of such social dynamics within socio-technical systems [152]. Many simulation studies try to explain online-specific phenomena, such as polarization, echo chambers or misinformation diffusion, with simple social characteristics (e.g. bounded confidence, homophily), without incorporating any specific characteristic of online environments [16, 26, 42, 43, 53, 120, 124]. Online-platforms are often explicitly modelled by incorporating recommender systems into the simulation. In several studies, a recommender system is used as a parameter in simulations to modify the probability of agent interactions [32, 106, 107, 108, 118, 119, 137, 149], to alter the ordering of news feed posts [55, 122, 125, 128], or to create new links in the network [28] Some research has incorporated state-of-the-art recommender systems [74], e.g., collaborative-filtering algorithms to suggest content or to suggest new links [46, 48]. However, characteristics of Online Social Platforms are not limited to their algorithms. Other works simulate online social platforms by incorporating specific behaviors like posting, retweeting, and user sessions, often tailored to specific platforms [100]. Simulations also make use of different data from online social platforms [94, 108, 149] to calibrate micro-behaviours and/or validate macro-results."}, {"title": "Y: Where the Digital World Comes to Life", "content": "LLM-enhanced Social Simulations Recent advancements have introduced generative agents that leverage generative models - especially language models [23] \u2013 to simulate realistic human behavior, achieving believable individual and collective behaviors [112]. Among these, LLMs have garnered significant attention for their ability to produce emergent behaviors akin to human societies [82]. The use of this framework is in its infancy and thus we see the use of very different methodologies and implementations that make it difficult to compare the results obtained, in the same way as in classical agent-based models. The number of different LLMs tested ranges from 1 [21, 30, 40, 82, 84, 98, 112, 114], to 2 or a few, [51, 135, 148, 158], to 10 or more [81, 123]. Tested models vary from closed-source, such as the GPT series [30, 40, 82, 84, 98, 112, 113, 114, 147], to open-sources, such as Llama, Mistral and others [21, 81], or a mixture of the two [51, 123, 135, 158]. In general, the aim of these latter studies is to compare results across different models. In these studies each agent is not a simple \"software\" following a pre-defined algorithm, but an instance of an LLM, interacting with humans, other agents and/or the environment through textual means. Exceptions create mixed populations of human and LLMs [82, 112] or classical agents and LLM-agents [98] Agents are often assigned different \"personas\" \u2013 name, age, gender, different interests, personality traits, political leanings \u2013, through textual prompts. Besides manually assigning different personas, in [65] authors demonstrate the ability of fine-tuned LLMs agents to align with beliefs and opinions of different online communities (such as Subreddits) and replicate human responses in surveys. The implementation of a \"memory module\", that the agent can query to make decisions and take future actions is present in several studies [21, 30, 84, 98, 112]. Environments can be absent [40, 81, 82, 158] \u2013 with just a population of agents interacting with humans or with each other \u2013, but also very complex. For example, in [112], authors created Smallville, a sandbox environment resembling a small village where agents are represented similarly to characters of The Sims. In [114], agents interacted within SimReddit, a web-based prototyping tool designed for those who need to implement systems like Reddit. In [98] there is a Twitter-like environment with timelines where LLM-agents generated content is published and can be read by other agents. Authors in [148] implement a general social media platform with different possible timeline curation algorithms. In [40, 112] authors studied whether generative agents were able of information diffusion, relationship formation and coordination, while in [114] they simulated participation in online communities. In [82], authors examined whether LLMs can display social learning, preference and indirect reciprocity. Some studies replicate classical opinion evolution simulations, testing one or multiple models [21, 30, 51, 98]. These recent studies also focus on understanding the interplay between such social dynamics and language [21], e.g. levels of toxicity in online discussions [148], which was unfeasible exploiting classical agents. Without considering collective dynamics, some studies focus on assessing individual characteristics of generative agents.In [81], for example, LLM-agents performed multiple rounds of MBTI tests. Generative agents show human-like collective behaviours such as the formation of scale-free networks [38] and information diffusion [52]. Moreover, these enhanced models outperform traditional ones in replicating echo-chambers dynamics in Twitter-like environments [98], while showing consistent results on the role of confirmation bias as a cause of polarization and fragmentation [30]. In absence of possible comparisons with classical agents, generative agents showed the ability to generate persuasive arguments, in line with psycho-linguistic theories of opinion change [21, 93], and less toxic behaviours, being more polite and respectful than real social media users [148]. Similarities and differences of such agents with humans and of these simulations to real social systems need careful consideration to avoid oversimplified conclusions.\nDespite having advanced social simulations with generative agents, we are still far from creating a social platform digital twin. Digital-Twins (DT) are defined as physical/virtual machines or computer-based models that are simulating or \"twinning\" a physical entity, continuously predicting future statuses and allowing simulations and testing [14]. Digital-Twins are already vastly employed in different fields from engineering [145] to healthcare [143], becoming one of the top 10 strategic technology trends for 2019 in Gartner's list\u00b2. Relatively new directions involve, but are not limited to, fields like sports [68] and city science and urban computing [121, 159, 161]. Having a social platform digital twin would allow researchers to perform different social experiments, investigate feedback loops between social and technical components of such systems, test different what-if scenarios, use insights to inform policy makers, in a more cost-effective and ethically-compliant way. However, for the additional complexity of the system society, creating such a twin is not a trivial task. Efforts have been made in this direction by defining a digital twin for complex networks systems, where data from the real systems are used to represent and model the digital system, mimicking both network characteristics and processes (e.g. spreading) [157]. Simulations in [157] involve both network evolution and infection spreading processes to assess network resilience. Other studies move towards the creation of a human digital twin, a digital replica of a real human. Besides replicating physical characteristics, as in healthcare, replicating cognitive capabilities and heterogeneous behaviours is the greatest challenge of creating a comprehensive twin of online social platforms. LLM-enhanced agents have been extensively explored in their ability to autonomously replicate human characteristics when prompted and/or fine-tuned. However, to date there has been no social platform digital twin mirroring characteristics of one or more platforms, and enriched with agents that mimic human behaviour - which is the core of our proposal."}, {"title": "3 Y Social - Digital Twin", "content": "Y Social is meant to allow for profound flexibility in simulation scenario development.\nTo fulfill such a goal, we designed our social media platform digital twin to be composed of three interacting modules:\ni. a REST API server designed to expose all those primitives describing the actions implemented by the social platform and to store the simulation data;\nii. a Large Language Model (LLM) server that serves requests related to agent interrogations (e.g., simulating decision-making protocols, text generations...);\nii. a simulation client that implements the agent logic and acts as a middle layer that interfaces the REST API server with the LLM (Large Language Model) one.\nGiven its modular design, as visually simplified in Figure 1, Y allows several clients to coordinate during every simulation, thus distributing the computational power needed to simulate agents' behaviors. It is worth underlining that Y makes it possible to leverage commercial models (i.e., OpenAI) as well as self-hosted ones\u00b3 (e.g., served through ollama, LM Studio or similar services) as a LLM server. Moreover, if specified in the simulation configuration, each Y client can assign multiple LLM models to the simulated agents, thus generating a population reflecting heterogeneous behaviors, linguistic capabilities, and adherence to the provided profiles.\nIn the following, we discuss the REST API server (i.e., y_server) and the simulation client (i.e., y_client) modules, describing their rationale and the implementation choices made while implementing them."}, {"title": "3.1 y_server: Social Media platform primitives", "content": "To properly describe a Social Media digital twin, the first thing to specify is the primitives that the agents can use to describe their social actions. We designed Y's primitives to resemble the ones offered by platforms like X/Twitter, Mastodon, and BlueSky Social. In particular, we defined the following REST endpoints to identify agents actions:\n/read: returns a selection of agent posts as filtered by a specified content recommender system;\n/post: registers a new post on the database (along with all the metadata attached to it - e.g., mentions, hashtags, inferred emotions. . . );\n/comment: makes its possible to register a comment to existing user-generated content (along with its metadata);\n/reply: provides a (recommender system-curated) list of posts that mention a given agent;\n/news: allows agents to publish news gathered from an online resource (e.g., from a news media outlet), adding a personal comment to it;\n/share: allow agents to share previously published news articles generating new discussion threads;\n/reaction: registers the reactions (e.g., like/dislike) of a given agent to a given content on the database;\n/follow_suggestions: provides a selection of potential contacts for a target agent leveraging a recommender system;\n/follow: allows agents to establish new social connections (follow) or break existing ones (unfollow).\ny_server exposes additional endpoints to handle system authentication, other articulated actions (e.g., timeline construction, content/follow recommendation pipelines), and multiple client synchronization. We now focus on Y's algorithmic curation from the perspective of the platform-user dynamics, namely content and follower recommendation pipelines."}, {"title": "3.1.1 Introducing Algorithmic Bias: Recommender System(s)", "content": "Content Recommendations. Several of the actions introduced - namely, read, comment, reaction, share, reply - focus on allowing agents to \"react\" to contents produced by peers. Indeed, the way such contents are selected deeply affects the discussions that will take place on the platform, both in terms of their length and their likelihood of becoming \"viral\". For such a reason, Y natively integrates several standard recommender systems for content suggestion (and allows for an easy implementation of alternative ones), namely:\n\u2022 Random: suggests a random sample of k recent agents' generated contents;\n\u2022 ReverseChrono: suggests k agents' generated contents in reverse chronological order (i.e., from the most recent to the least recent);\n\u2022 ReverseChronoPopularity: suggests k recent agents' generated contents ordered by their popularity score computed on as sum of the like/dislike received;\n\u2022 ReverseChronoFollowers: suggests recent contents generated by the agent's follower - it allows to specify the percentage of the k contents to be sampled from non-followers;\n\u2022 ReverseChronoFollowersPopularity suggests recent contents generated by the agent's follower ordered by their popularity - it allows to specify the percentage of the k contents to be sampled from non-followers;\nEach content recommender system is parametric on the number k of elements to suggest. To increase the scenario development potential of Y (e.g., to design A/B tests), each instance of the simulation client (y_client) can assign a specific instance/configuration of the available recommender systems to each of the generated agents.\nFollows Recommendations. Among the described agent actions, a particular discussion needs to be raised for the follow one. Y agents are allowed to establish (and break) social ties following two different criteria: i) as a result of a content interaction (e.g., after the evaluation of a content posted by a peer); ii) selecting a peer to connect with among a shortlist proposed by a dedicated recommender system.\nAs for the content recommendations, Y integrates multiple strategies to select and shortlist candidates when an agent a starts a follow action.\n\u2022 Random: it suggest a random selection of k agents;\n\u2022 Common Neighbours: it suggests the top k agents ranked by the number of shared social contacts with the target agent a [101];\n\u2022 Jaccard: it suggests the top k agents ranked by the ratio of shared social contacts among the candidate and the target agents over the total friends of the two [29];"}, {"title": "Y: Where the Digital World Comes to Life", "content": "\u2022 Adamic Adar: the top k agents are ranked based on the concept that common elements with very large neighborhoods are less significant when predicting a connection between two agents compared with elements shared between a small number of agents [4];\n\u2022 Preferential Attachment: it suggests the top k nodes ranked by maximizing the product of a's neighbor set cardinality with their own [103].\nEach of the implemented methodologies, borrowed from classic unsupervised link prediction scores [85], allow agents to grow their local neighborhood following different local strategies - each having an impact on the overall social topology of the system (e.g., producing a heavy-tailed degree distribution [11, 12]). Moreover, Y allows for specifying if the follower recommendations should be biased (and to what extent) toward agents sharing the same political leaning so as to implement homophilic connectivity behaviors."}, {"title": "3.2 y_client: Simulating Agents' social interactions", "content": "As discussed, the primary function of y_server is to expose, through a REST API, access to all those primitives that allow for the execution of the Digital Twin simulation. If y_server can be seen as a \"light\" interface toward the database storing the simulation results (see Figure 2 for an overview of the DB diagram), the y_client is the module that implements most of the business logic of the Y.\nIn particular, y_client defines the simulation agents and their characteristics, implements the agents' actions selection process (i.e., the strategy used to select which endpoint exposed by y_server to connect to and how to interpret the obtained responses), handle the access to external online resources and, finally orchestrate the simulation by synchronizing with other clients' activities through dedicated y_server's primitives. In the following, we review the main facilities offered for each task - starting from the most important component of a social media platform Digital Twin: the agents that populate it."}, {"title": "3.2.1 LLM-powered agents", "content": "Y's main peculiarity lies in the kind of agents that independently perform the actions it exposes. Conversely, from a classic mechanistic simulation environment, where action selection is often implemented as a sampling from a given probability distribution - that implicitly fixes their expected volume distribution - Y leverages LLMs as chaos engines, leaving each agent the choice w.r.t. the actions to take.\nMoreover, to increase the heterogeneity of agents' behaviors - and generated contents -, Y leverages the ability of LLMs to impersonate different users' profiles (persona).\nThrough agent profiling, Y allows for control of the population segmentation over multiple dimensions (that can be expanded if needed by the specific simulation scenario).\nAgent profile. While instantiating an agent, y_client allows to specify the following descriptive dimensions:\n\u2022 Agent Name and Ownership: Name is the unique identifier for the generated agent, while ownership links the agent to the client execution that generated it. This latter information is useful for checking the simulation status while multiple clients (having different configurations) are active.\n\u2022 LLM model: This field identifies the model used for interpreting the agent's actions. Each agent can be impersonated by a different model (e.g., mistral, llama3, phi3, chatgpt...).\n\u2022 Age, Spoken Language(s), Education level: Such demographic information has been shown to affect the content generated by LLMs. In particular, Age and Education can be used to tune the expected writing styles of agents. At the same time, the list of spoken languages will filter the contents and (the modality) the agents interact with.\n\u2022 Political leaning: This dimension is crucial for social simulations to generate social interactions centered on socio-political themes. It can be used to coarse-grain pre-set the expected agent's opinion.\n\u2022 Topic(s) of Interest: The list of interest topics represents the background of the agent and acts as a starting point for the generation of posts and to make consistent contributions to discussion threads. Moreover, specifying a reasonable set of topics per agent increases the heterogeneity of produced texts. The global topic selection also allows for the setup of topical-oriented simulations (e.g., describing a digital twin of a political forum rather than of a self-help community).\n\u2022 Recommender system(s): As previously described, each agent is allowed to decide - at instantiation time - which content/follow recommendation strategies to leverage among the ones provided by the y_server.\n\u2022 Big Five personality traits: The Big Five personality traits, also known as the Five-Factor Model (FFM [89]), describe five broad dimensions of human personality. Such five dimensions are used to fine-tune the agent's expected behavior while interacting with other users' contents (and generating its own)."}, {"title": "Y: Where the Digital World Comes to Life", "content": "Focusing on the last dimension, each agent is characterized by five dichotomic variables, each capturing the extreme values of one of the Big Five personality traits, namely:\n\u2022 Openness to Experience (oe): This trait features characteristics such as imagination, insight, and a broad range of interests. Highly open people are often creative, curious, and open to new experiences. Those low in this trait may be more conventional and prefer routine.\n\u2022 Conscientiousness (co): This dimension involves high levels of thoughtfulness, good impulse control, and goal-directed behaviors. Highly conscientious people tend to be organized, mindful of details, and responsible. Those low in Conscientiousness may be more spontaneous and less structured.\n\u2022 Extraversion (ex): This trait includes excitability, sociability, talkativeness, assertiveness, and high emotional expressiveness. Extroverted individuals are energetic and enjoy being around people. Introverts, who are lower in extraversion, may be more reserved and prefer solitary activities.\n\u2022 Agreeableness (ag): This personality dimension includes trust, altruism, kindness, and affection. Agreeable individuals tend to be cooperative, compassionate, and good-natured. Those lower in Agreeableness may be more competitive and sometimes less empathetic.\n\u2022 Neuroticism (ne): This trait refers to the tendency to experience negative emotions, such as anger, anxiety, or depression. Individuals high in Neuroticism are more likely to experience emotional instability and mood swings. Those low in this trait are generally more stable and resilient.\nThese five traits are considered relatively stable and provide a comprehensive framework for understanding human personality. Y allows each agent to be characterized by a high/low value for each of the five traits, allowing for 32 different personalities.\nThe defined agent profile dimensions concur with the description of detailed and consistent characters that the LLM can interpret in its role-playing. In particular, defining the Big Five personality trait profiles affects agents' choices in content generation modality.\nIn order to leverage the defined profile, each LLM action prompt is anticipated by the following role-play directives:\nYou are a {age} year old {leaning} interested in {"}, {"title": "Y: Where the Digital World Comes to Life", "content": "READ. The read action allows agents to react to peers' posts/comments. Firstly", "activated": "nRead the following text, write YES if you like it, NO if you don't, NEUTRAL otherwise.\n## START TEXT\n{post_text}\n## END TEXT\nThe outcome of the prompt is then used to associate a like/dislike reaction to the selected content from the active agent. Multiple reaction types can be easily integrated by adapting the prompt request.\nAdditionally, depending on the reaction outcome, the LLM"}]}