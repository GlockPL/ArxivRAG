{"title": "Magazine supply optimization: a case-study", "authors": ["Duong Nguyen", "Ana Ulianovici", "Sami Achour", "Soline Aubry", "Nicolas Chesneau"], "abstract": "Supply optimization is a complex and challenging task in the magazine retail industry because of the fixed inventory assumption, irregular sales patterns, and varying product and point-of-sale characteristics. We introduce AthenIA, an industrialized magazine supply optimization solution that plans the supply for over 20,000 points of sale in France. We modularize the supply planning process into a four-step pipeline: demand sensing, optimization, business rules, and operating. The core of the solution is a novel group conformalized quantile regression method that integrates domain expert insights, coupled with a supply optimization technique that balances the costs of out-of-stock against the costs of over-supply. AthenIA has proven to be a valuable tool for magazine publishers, particularly in the context of evolving economic and ecological challenges.", "sections": [{"title": "I. INTRODUCTION", "content": "The print magazine has long been a staple in our culture, serving as a source of information, entertainment, and education. However, the rapid evolution of the Internet and digital media has profoundly transformed the media industry. In the last decades, there has been a marked shift in customer preferences toward digital platforms, which offer faster and more accessible content that appeals to the visual sensibilities of modern audiences. As newer generations increasingly favor instant online content over traditional print sources, print magazines are facing significant difficulties in maintaining both relevance and profitability [1]. This ongoing shift has profound implications for print media companies, as they struggle to adapt to a landscape where digital media continues to gain domination. Moreover, the print magazine industry is confronting emerging sustainability challenges. Growing societal awareness of environmental impacts, shifting consumer preferences, rising production costs, and increasing sustainability-related taxes [2], [3] have made sustainable practices within the industry essential.\nIn this context, the role of supply optimization becomes crucial, bearing significant impacts. On one hand, efficient supply helps increase profit by minimizing the losses due to out-of-stock (oos) and reducing the costs associated with excess supply. On the other hand, by curbing oversupply, the industry can mitigate its environmental footprint by reducing waste and the ecological ramifications of unsold print papers.\nHowever, magazine supply optimization presents significant challenges. In magazine retail, the inventory is fixed. At the beginning of the selling period of an issue of a title, a predefined number of copies is sent to a specific list of Points Of Sale (POSes), referred to as the \"plate\" in this paper. Replenishment is rare because the costs generally outweigh the benefits. At the end of the selling period, unsold copies are returned to the publisher, often to be destroyed. There are several layers of costs: production costs, registration costs (the costs of registering a title to the magazine retail network), distribution costs, and unsold costs (the costs related to the return and treatment-usually destruction-of unsold copies). The POSes also take commissions on the sold copies. To optimize the profit, the publisher must define which POSes to send magazine copies to (i.e., the plate of the issue) and estimate the optimal number of copies to send to each POS. With the decline of the print media industry and the rise of environmental awareness, this optimization has become crucial, both economically and ecologically.\nOne of the key factors in supply optimization is the estimation of the demand, which encounters several other challenges: for each title, the content of one issue to another varies significantly, hence the demand. The demands are highly seasonal and greatly influenced by public holidays. Some POSes may be partially closed during the selling period. For new titles or when new POSes join the network, there are no historical data, leading to a cold-starting problem. Another challenge arises when issues are sold with \u201cextra-products\" (a.k.a gift-on-purchase, they can be a toy model of a car, or a set of colored pencils, etc.), which can significantly affect the demand. For example, an issue sold with a toy dinosaur typically sees a 10% sales increase compared to normal. In this paper, for simplicity, we use the term \"product\" for the package sold to consumers, whether it is a copy of an issue alone or a copy of an issue with extra-product(s).\nIn magazine retail, magazines are sold through an extensive network of POSes (from a few thousand to tens of thousands). This vast network, combined with the high variability in sales, poses significant challenges. As shown in Figure 1, most POSes sell only 0, 1 or 2 copies of most issues, while a"}, {"title": "II. PROBLEM FORMULATION", "content": "Let us denote < m,i > issue i of title m. Mathematically, the objective of the solution is to optimize the profit under constraints, as follows:\n$\\max_{s_{m,i}} \\sum_{j \\in P_{m,i}} (z_{m,j}^{m,i} * pricem,i - costmi (S_{m,i}, s_{m,j}^{m,i}, z_{m,j}^{m,i}))$\ns.t.\n$s_{m,j}^{m,i} \\in Z0+,\nj \\in P_{m,i}$\n$S_{m,i} \\in [N_{total} \u2013 \u2206, N_{total} + \u0394].$\n(1)\nwith\n\u2022 Pmi denotes the plate of < m, i >,\n\u2022 smi denotes the supply of < m, i > for POS j (i.e. how many copies of < m, i > sent to POS j),\n\u2022 Z0+ denotes the set of non-negative integers,\n\u2022 $S_{m,i} = \\sum_{j \\in P_{m,i}} s_{m,j}^{m,i}$ denotes the total supply of < m, i >,\n\u2022 Ntotal denotes the total supply constraint of < m,i >, imposed by the publisher,\n\u2022 \u2206 denotes the tolerance of the total supply constraint,\n\u2022 zmi denotes the sales of < m,i > at POS j,\n\u2022 pricem,i denotes the price of < m, i >,\n\u2022 $costmi (s_{m,j}^{m,i}, S_{m,i}, z_{m,j}^{m,i})$ denotes the costs and commission taken by POS j when it is supplied smi of sm,i total copies, and it sells zmi copies.\nIn layman's terms, Eq. (1) means to \u201cfind the number of copies sent to each POS in plate Pm,i to maximize the profit of issue i of title m, given the cost structure costmi and the total supply constraint Ntotal \u00b1 \u0394\u201d.\nIn Eq. (1), pricem,i, Ntotal, and \u2206 are known. Pm,i is provided by a set of business rules to maintain the presence of the title and to conform to the regulations of the retail network. The formula of costmi is also known. However, the value of costmi ($s_{m,j}^{m,i}$, Sm,i, zmi) depends not only on $s_{m,j}^{m,i}$ and zmi but also on the total supply Sm,i. Another difficulty of Eq. (1) is the sales zmi depends on the supply smi. Note that zmi denotes the sales, not the demand. Let us denote $d_{m,i}^j \\in RO+$ ($R0+$ denotes the set of non-negative real numbers) the demand of < m,i > at POS j. We have:\nzmi = min(dj,smi).\n(2)\nWhen smi > Zmi, the sales are equal to the demand. However, when there is an out-of-stock (i.e. smi = zmi), there is potentially an unobserved demand that was missing. We can measure only the sales, not the actual demand. Moreover, the demand also depends on the supply. For instance, suppose that we send 4 copies to a POS and it sells 3. This does not imply that if we sent 10 copies to this POS, it would sell the same 3. This \"visibility effect\" is common in retail [4], [5].\nWe detail in the next section how AthenIA addresses these challenges."}, {"title": "III. ATHENIA SUPPLY OPTIMIZATION SOLUTION", "content": "The variability in the products' characteristics and in the demand poses significant challenges for building a fully au-tomatic supply optimization solution. A purely data-driven approach falls short of capturing all the nuances of the prod-ucts. To address this, we built a data-centric solution that not only leverages patterns in the data but also integrates insights of Subjet-Matter-Experts (SMEs) and accommodates various business constraints and publisher's operational strategies. This approach ensures that the solution is not only theoretically optimal but also practically useful and usable. The details will"}, {"title": "A. Pipeline", "content": "We modularize the supply optimization process into four stages, as shown in Figure 2.\n\u2022 Stage 1 (Demand sensing): at this initial stage, we estimate the demand for each issue at each POS. It is important to note that we are predicting the demand, not the sales. This estimation is at the heart of the whole process.\n\u2022 Stage 2 (Optimization): based on the demand estimated from Stage 1, we calculate the optimal supply for various scenarios, taking into account different costs, constraints, and strategies.\n\u2022 Stage 3 (Business rules): at this stage, we apply some predefined rules to sanity-check the proposed supply plans and make ad-hoc adjustments to adapt to unplanned changes.\n\u2022 Stage 4 (Operating): the solution generates several opti-mal supply plans, each corresponding to a specific strat-egy. The supply planner then selects the most appropriate plan for each issue and makes any necessary manual adjustments.\nModularizing the supply planning process into several sub-stages provides several benefits:\n\u2022 Impact measurement and decision making: by breaking the process into smaller stages, we can measure the im-pact of each step individually. This allows us to identify which stages add value and which need improvement.\n\u2022 Flexibility: in our pipeline, from left to right the pro-cess changes from highly automatic, data-influenced to manual, domain-expertise-influenced. This design allows users to bring in the more up-to-date knowledge of the products and the nuances that can not be fully captured by an automatic model. This flexibility is advantageous for operational utility. When market conditions, regulations, or cost structures change, we can easily adapt specific stages of the pipeline, especially the later stages (op-erating, business rules), without overhauling the entire system, thereby reducing update and maintenance costs. The following sections will provide detailed descriptions of each stage."}, {"title": "B. Human-in-the-loop demand sensing using group conformalized quantile regression", "content": "The demand of issue i of title m at POS j depends on several factors: the quality, the popularity, and the trends of the title; the quality of this particular issue; the extra-product (if any); the market trends; the selling period; the characteristics of the POS; the visibility of the product on the shelf; the sales of concurrent products; among others. Although $d_{m,i}^j$ is also influenced by the supply smi, incorporating this dependence into the modeling would make the problem intractable. More-over, we can not observe the demand directly, we can only observe the sales. When an out-of-stock situation occurs, the actual demand may exceed the observed sales. To work around these complexities, we make the following simplifications:\n\u2022 Simplification 1: if the supply exceeds the sales, the demand is considered equal to the sales. Conversely, in cases of out-of-stock, we assume that the POS could have sold an additional r%:\n$d_{m,i}^j = \\begin{cases}\nz_{m,j}^{m,i} & \\text{if } z_{m,j}^{m,i} < s_{m,j}^{m,i} \\\\\n(100+ r)\\% * z_{m,j}^{m,i} & \\text{if } z_{m,j}^{m,i} = s_{m,j}^{m,i}\n\\end{cases}$\n(3)\n\u2022 Simplification 2: $d_{m,i}^j$ does not depend on $s_{m,j}^{m,i}$\nSimplification 1 allows us to approximate the demands of historical issues using observed sales data, while Simplification 2 makes the supply optimization problem tractable.\nWe build a demand sensing model to estimate $d_{m,i}^j$ using historical demands, product characteristics, sales characteris-tics, and contextual information. The irregularity in the sales of the magazines limits the possible choices of models for this"}, {"title": "Group Conformalized Quantile Regression (GCQR):", "content": "In supply optimization, the costs associated with oversupply and undersupply are different. Quantile regression [13] is a commonly used approach in these cases. Recall that the ath conditional quantile function is defined as:\n$qa(xm,i) = inf{d: Pr[Dm,j \u2264 d | xmi] \u2265 a}$\n(4)\nwith Dim, denotes the random variable of the demand and xi denotes the input features. Conditional quantile regres-sion estimates $q_a(x_{m,i}^j)$ using a regression model with the following pinball loss function:\n$loss_a(d, \\hat{d}) = \\begin{cases}\n\\hspace{0.1in} a * (d-\\hat{d}) & \\text{if } \\hat{d} <= d\\\\\n(1-a) * (\\hat{d} - d), & \\text{if } \\hat{d} > d\n\\end{cases}$\n(5)\nwith d and $\\hat{d}$ denote the true target value and the predicted value of the regression, respectively. However, quantile regres-sion often gives prediction intervals that are too wide [14]. As a result, using standard quantile regression for demand sensing in supply optimization often leads to oversupply. To address this problem, Conformalized Quantile Prediction (CQP) [14]\u2013[16] uses a calibration set to calibrate the outputs of quantile regression, resulting in more accurate and narrower prediction intervals. Based on this idea, we designed a new group conformalized quantile regression, tailored to our problem, as follows:\n\u2022 Step 1 (Split): for each title m, we split the historical data into two sets: a calibration set Calm containing the observations of the two latest observed issues if the title's periodicity is more frequent than quarterly (e.g. weekly, monthly, bimonthly), otherwise the lastest observed issue; and a training set Trm containing the rest of the historical data (which means there are not only the observations of title m but also those of other titles in Trm).\n\u2022 Step 2 (Training): we train a quantile LightGBM regres-sion model Mm,a using the data in the training set Trm.\n\u2022 Step 3 (Calibration): we apply Mm,a on Calm. Let us denote emia Calm the prediction error of Mm,a at POS j for issue i of title m in the calibration set Calm.\n\u2022 Step 4 (Grouping): we split the observations in all the calibration sets into G groups {G1, G2, ..., GG} based on the average sales over the last 12 months lagged 3 months (mean_sales_12m).\n\u2022 Step 5 (Correction): for each group Gg, we calculate the ath quantile $q_g^a$ of the set of the calibration prediction errors {em.i.a Calm} of the observations in this group.\n\u2022 Step 6 (Prediction): for each observation in the test set, its group is determined using the same rule as in Step 4. The final ath quantile prediction of this observation is $\\hat{d}_{m,i}^j = Mm,a(x_{m,i}^j) + q_g^a$."}, {"title": "C. Supply optimization", "content": "The demand sensing model in Stage 1 gives us the pre-diction $d_{m,i,a}^j$ of the ath quantile of the demand. If we use $d_{m,i,a}^j$ as the supply, the out-of-stock rate is expected to be 1 \u2013 a. However, there are several problems. Firstly, $d_{m,i,a}^j$ is a real number, whereas the supply smi must be a non-negative integer. Given that the majority of the sales are 0, 1, or 2 copies, the rounding residuals will negate the precision of the demand sensing model. For example, rounding up $d_{m,i,a}^j$ = 0.8 to 1 introduces a rounding residual of 0.2, which is 25% of $d_{m,i,a}^j$. Secondly, using a fixed rule to map $d_{m,i,a}^j$ to smi does not guarantee that the sum of smi across all the POSes in the plate $j\\epsilon P_{m,i}$ will fall within the supply constraint interval $N_{total} \\pm \u2206$. One may increase or decrease proportionally smi to meet the supply constraint. However, that means we undermine the efforts done in the demand sensing step. Another possible solution is to sweep a in the ath quantile regression over different values until the sum of the supply meets the constraint. However, this approach does not guarantee that the final profit will be optimized, since the costs are not taken into account.\nTo address these challenges, we design a new technique to optimize the supply for each < m, i > as follows:\n\u2022 Step 1: instead of estimating one quantile $d_{m,i,a}^j$, we estimate several quantiles $d_{m,i,a'}^j$ corresponding to different values of \u03b1\u2019$\\epsilon$ {0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 0.99}.\n\u2022 Step 2: we construct several \u201cscenarios\u201d, each scenario is represented by a vector [$\u03b1_1,\u03b1_2,...,\u03b1_G$] where \u03b1g corresponds to the value of a for group Gg. An example is shown in Table. I. The number of scenarios to test is a trade-off between the exhaustiveness and the calculation costs.\n\u2022 Step 3: for each scenario, we obtain the ath quantile predictions dimia of the observations in the calibration set Calm, and define the scenario supply $s_{m,i}^j$ as the ceiling of $d_{m,i,a}^j$. The corresponding estimated sales are defined as the minimum between the real observed sales and the scenario supply: $z_{m,i}^j = min(z_{m,i}^j, s_{m,i}^j)$.\n\u2022 Step 4: given the scenario supply, the corresponding sales, and the cost structure, we calculate business KPIs (Key Performance Indicators): total supply, revenue, costs, and profit for each scenario.\n\u2022 Step 5: We compare the KPIs of the scenarios with the real KPIs and select a set of \"optimal\" scenarios (the green dots in Figure 5). The criteria for selecting the optimal scenarios are predefined by the business stakeholders. These criteria are mainly based on the total supply, the revenue, and the profit. The best optimal scenario is referred to as max_kpi_efficiency.\n\u2022 Step 6: During the inference phase, for each issue < m,i >, we calculate the supply corresponding to each scenario in the set of optimal scenarios obtained in Step 5. AthenIA outputs three supply plans. The first plan, dubbed as the optimal supply plan corresponds to the max_kpi_efficiency scenario. The second plan, dubbed as the optimal distribution plan is the supply plan cor-responding to the optimal scenario that gives the total supply closest to the constraint Ntotal. The third supply plan, not reported in this paper, uses a similar supply optimization strategy as the optimal supply plan's but on a larger plate than Pm,i. This plan is used when the publisher wants to widen the presence of the magazine.\nThis method enables AthenIA to accommodate complex cost structures and business strategies. The optimal supply plan gives us the supply plan that would maximize the profit, while the optimal distribution plan gives the plan that would optimize the distribution of the predefined total supply among the POSes in the plate. Occasionally, the optimal supply plan and the optimal distribution plan can be identical."}, {"title": "D. Business rules and Operating", "content": "We apply a set of rule-based checks and adjustments to control the outputs of Stage 2. These rules serve two purposes:\n\u2022 Sanity check: since Stages 1 and 2 are run automatically using machine learning models, it is essential to apply sanity checks to verify whether the proposed supply of each POS is too high or too low compared to historical trends and yearly lags.\n\u2022 Fast adjustment: When the supply planners acquire new market insights that need to be incorporated into the sup-ply plans, or when they want to apply some new supply strategies for atypical products, rule-based adjustments offer a quick and efficient way to implement the planners' intentions. Modifying the demand sensing model or the optimization strategies would be more time-consuming and require rigorous testing.\n\u2022 Constraint adjustment: Occasionally, none of the plans provided by AthenIA meets the total supply constraint Ntotal \u00b1 A. In these rare instances, we review with the supply planner to decide whether to adjust the supply constraint or to scale the supply proportionally to meet the constraint. This situation is infrequent because the range of the total supplies from different optimal scenar-ios is extensive, and the supply planners typically have sufficient prior knowledge of their products' sales to set reasonable total supply constraints.\nThese rule-based checks and adjustments ensure that the final supply plans are not only optimized but also practical and aligned with current market conditions and constraints.\nThe last stage in the process is called the Operating stage. At this stage, the supply planners review the three supply plans generated by AthenIA and select the most suitable one. If necessary, the planners make ad-hoc adjustments to better align with current conditions or unforeseen changes. Once the adjustments are made, the finalized supply plan is sent to the production and shipping departments for execution. AthenIA logs the planners' choice and any modifications made for future analysis."}, {"title": "IV. EVALUATION", "content": "The ultimate goal of the solution is to optimize the profit within given constraints. However, due to the multi-stage nature of the process, it is essential to evaluate the relevance and the performance of each stage individually. Without this evaluation, the number of potential combinations of options for each stage becomes unmanageably high. By assessing each stage separately, we can ensure that each component contributes effectively to the overall optimization, thereby streamlining the process and enhancing the solution's effi-ciency. This approach allows us to identify and fine-tune the critical elements that drive the most significant impact on profit optimization, ensuring that our methodology remains both robust and practical."}, {"title": "A. Evaluation of the demand sensing model", "content": "To evaluate the performance of the demand sensing model, we tested it on a dataset containing sales records of issues put on sale from 01/01/2021 to 31/05/2023. We simulated the situation as of 01/04/2023: we used all the sales records available on that date to train the model, then predicted the demands of issues put on sale from 01/04/2023 to 31/05/2023. This setup is intended solely to facilitate the reproducibility of the results presented in this paper. In operation, we retrain the model on a weekly basis with the latest data.\nWe compared the performance of the AthenIA demand sensing model with several baselines and alternative options:\n\u2022 Naive: The latest observation is used as the prediction.\n\u2022 S-Naive: The 1-year lag is used as the prediction.\n\u2022 LightGBM_standard: A LightGBM model that uses the features in Table IV, excluding mean_ref and max_ref, as inputs. The target variable is transformed onto a log scale during the training phase.\n\u2022 LightGBM_linear: A LightGBM that uses all the features in Table IV as inputs. However, the target variable is NOT transformed onto a log scale during the training phase.\n\u2022 LightGBM_log: A LightGBM that uses all the features in Table IV as the inputs. The target variable is transformed onto a log scale during the training phase.\n\u2022 LightGBM_log_GCQR (AthenIA): the LightGBM_log model with GCQR correction. This is the model used in production.\nWe set r% = 30% and compared the performance of differ-ent models using the mean pinball loss (Eq. (5)) on the test set with various values of \u03b1. Although we cannot guarantee that the model with the lowest pinball loss will always be the best model for the downstream supply optimization task, the pinball loss remains the most suitable evaluation metric for our purposes."}, {"title": "B. Evaluation of the supply optimization method", "content": "Table III shows the total supply, the profit, and the number of out-of-stock instances of different supply plans using the same setting as in Section IV-A. The \"quantile regression\" plan is a supply plan that uses a quantile regression with \u03b1 = 0.75, then scales the supply proportionally to meet the total supply constraint. Both the optimal distribution plan and optimal supply plan yielded better profits (101.91% and 102.54% of the actual profit, respectively) and fewer out-of-stock. Both these plans reduced the total supply and the number of out-of-stock instances at the same time, indicating that the estimations of the demand were more accurate. The optimal supply plan tends to cut the supply to reduce the costs of oversupply. Reducing the supply without sacrificing the profit is highly beneficial ecologically since it reduces the carbon footprints related to the production, distribution, and destruction of unsold copies. However, consistently using this supply plan might be counterproductive, as some level of oversupply can be beneficial. Maintaining a certain amount of unsold copies helps reduce the risk of out-of-stock and keeps the products visible to consumers. The total supply constraint Ntotal serves as an anchor to balance these considerations, ensuring that the supply level supports both profitability and product visibility."}, {"title": "V. DEPLOYMENT", "content": "AthenIA is a fully industrialized solution. The data are securely hosted in an Azure Data Lake, ensuring robust data management and security. Computational tasks, including data"}, {"title": "VI. RELATED WORK", "content": "Magazine supply optimization: There are limited pub-lished works on magazine supply optimization, with most studies focusing primarily on demand estimation, which is only a sub-task of the overall supply optimization process. In [17], the authors addressed the challenge of forecasting newspaper and magazine sales amidst the shift toward digi-tal media consumption. They highlighted the inadequacy of traditional linear regression models, which often suffer from overfitting, and introduced Support Vector Regression (SVR) as an alternative. The authors estimated the sales based on the POS's geographical characteristics and the issue's selling period. A similar approach was studied in [18]. In [19] the au-thors utilized time series analysis to predict daily demand and minimized unsold copies. The research focused on customized forecasting models tailored to the unique characteristics of individual dealers, influenced by factors such as location and proximity to key institutions. Various forecasting techniques were compared, with a particular emphasis on a nonlinear approach for managing returns. The study highlighted the challenges of predicting sales on special days influenced by promotions and events, and concluded that ExponenTial Smoothing (ETS) yielded satisfactory results. However, that analysis was made on only one POS with sufficiently long historical data. Hence, it can not be generalized. In contrast, AthenIA is an end-to-end industrialized supply optimization operating at a much larger scale.\nDemand sensing: Demand sensing is at the heart of sup-ply chain management, especially in retail operations where accurate forecast of future demand can significantly enhance inventory management and profitability [20], [21]. Various methods have been explored for demand sensing, each presents unique advantages and limitations. Statistical methods, such as Naive prediction, SARIMA [22], and exponential smoothing [23], have been widely used [24], [25] because of their sim-plicity and ease of implementation. These models are effective in capturing trends and seasonality in historical sales data and perform well for products with stable demand patterns. However, they often struggle with the high variability and unpredictability inherent in cases where demand can be influ-enced by numerous factors including trends, external events economic conditions. Recently, machine learning methods such as LightGBM [9], CatBoost [10], DeepAR [6], N-BEATS [7], and TFT [8] have emerged as the state-of-the-art for demand sensing and demand forecasting [20], [21]. These methods can handle non-linear relationships and complex interactions within the data, providing more accurate demand forecasts in dynamic environments. Each method, however, is suitable for specific use cases. In our case, the irregularity in the sales precludes the use of time series models such as DeepAR, N-BEATS, TFT. LightGBM is a more suitable choice.\nA critical aspect of effective demand sensing is feature engineering. The feature engineering step needs to adapt to the context and the objective of the use case. AthenIA allows SMEs to incorporate their insights and prior knowledge of the products into the model. This human-in-the-loop approach enhances the model's ability to capture the nuances of the product characteristics and market dynamics, leading to more accurate and actionable forecasts.\nConformalized quantile regression: The idea of using different sets of {training set, calibration set} and training one prediction model for each set is similar to EnbPI [26]. However, unlike EnbPI, which utilizes random sampling to generate different bootstrap sets, our approach involves de-liberately choosing splits that are adaptive to each title. The grouping step is to tackle the problem of heavy tail distribution of the demand. In contrast to [14], our approach focuses on predicting a one-sided coverage interval. Specifically, we aim to estimate the upper bound, represented by the ath quantile of Dmi.\nSupply optimization: The fixed inventory nature of our case precludes the use of traditional inventory management techniques such as Economic Order Quantity (EOQ), First-In-First-Out (FIFO), Last-In-First-Out (LIFO), Vendor-Managed Inventory (VMI), and Just-In-Time (JIT) [27]. These methods rely on the ability to reorder stock, which is not applicable in scenarios where the inventory is predetermined and can-not be adjusted during the selling period. Modern algorith-mic approaches for inventory management, such as dynamic programming [28] and stochastic programming [29], offer"}, {"title": "VII. CONCLUSION", "content": "In this paper, we presented AthenIA, a supply optimization solution designed to address the intricate challenges faced by a French magazine publisher selling magazines at over 20,000 points of sale. We introduced a standardized yet agile pipeline for supply optimization, which stands out for its methodological rigor and flexibility. This pipeline is not only effective in the context of magazine distribution but also has the potential for application across other sectors thanks to its adaptability to diverse market conditions and business strategies.\nA central innovation of AthenIA is the development of a novel demand sensing approach that significantly enhances the integration of domain expert knowledge into the forecasting process. We designed a new group conformalized quantile regression technique to improve the performance of standard quantile regression. Furthermore, we introduced a tailored op-timization model that maximizes the profit while considering different operational constraints, complex cost structures, and business strategies.\nAthenIA is an example of the integration of advanced machine learning techniques with practical business insights to build a solution that is both innovative and applicable. The development of AthenIA is also proof of the publisher's com-mitment to sustainability. The solution has been instrumental in helping significantly reduce the carbon footprint associated with over-supply in publishing. Through these concerted ef-forts, we are not only optimizing our supply chain but are also paving the way for a more sustainable and responsible operational model that other publishers can look to as a benchmark.\nIn AthenIA, Subject Matter Experts (SMEs) play a critical role in several steps of the supply optimization process. Their expertise is essential for accurately capturing the nuances of the product characteristics and market conditions. However, this reliance on human input introduces the potential for human bias and error. To mitigate these risks and use the solution effectively, it is crucial to maintain close collaboration with SMEs throughout the process. Future work may involve assessing the impact of the simplification that the demand is independent of the supply, which may not accurately reflect re-ality. Additionally, to further enhance the sustainability aspects of AthenIA, we could introduce carbon costs into the optimiza-tion equations. By incorporating these environmental costs, the solution would not only optimize for economic efficiency but also contribute to reducing the overall carbon footprint of the magazine supply chain. This holistic approach would align with broader sustainability goals and set a benchmark for responsible business practices in the publishing industry. On the innovation side, a potential research direction is to leverage recent advances in natural language processing and multimodal processing to extract features from the contents of products and use them to estimate demand."}]}