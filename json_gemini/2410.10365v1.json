{"title": "SpeGCL: Self-supervised Graph Spectrum Contrastive Learning without Positive Samples", "authors": ["Yuntao Shou", "Xiangyong Cao", "Deyu Meng"], "abstract": "Graph Contrastive Learning (GCL) excels at managing noise and fluctuations in input data, making it popular in various fields (e.g., social networks, and knowledge graphs). Our study finds that the difference in high-frequency information between augmented graphs is greater than that in low-frequency information. However, most existing GCL methods focus mainly on the time domain (low-frequency information) for node feature representations and cannot make good use of high-frequency information to speed up model convergence. Furthermore, existing GCL paradigms optimize graph embedding representations by pulling the distance between positive sample pairs closer and pushing the distance between positive and negative sample pairs farther away, but our theoretical analysis shows that graph contrastive learning benefits from pushing negative pairs farther away rather than pulling positive pairs closer. To solve the above-mentioned problems, we propose a novel spectral GCL framework without positive samples, named SpeGCL. Specifically, to solve the problem that existing GCL methods cannot utilize high-frequency information, SpeGCL uses a Fourier transform to extract high-frequency and low-frequency information of node features, and constructs a contrastive learning mechanism in a Fourier space to obtain better node feature representation. Furthermore, SpeGCL relies entirely on negative samples to refine the graph embedding. We also provide a theoretical justification for the efficacy of using only negative samples in SpeGCL. Extensive experiments on un-supervised learning, transfer learning, and semi-supervised learning have validated the superiority of our SpeGCL framework over the state-of-the-art GCL methods.", "sections": [{"title": "I. INTRODUCTION", "content": "THE proliferation of social networks and the advent of vast graph datasets have propelled Graph Neural Networks (GNNs) to the forefront as a potent tool for graph data processing and knowledge extraction. GNNs are now extensively utilized in various sectors [1]\u2013[8], including recommendation systems [9], bioinformatics [10], and a myriad of other domains [11]\u2013[16]. Traditionally, GNNs have been optimized through supervised learning, which is heavily dependent on high-quality, expert-annotated labels. However, acquiring such detailed labels necessitates significant domain expertise and is resource-intensive. To address these challenges, approaches such as Variational Graph Autoencoder (VGAE) [17] and Graph Sample and Aggregation (GraphSAGE) [18] have been developed to facilitate unsupervised learning by reconstructing the adjacency matrix of the graph. Additionally, the DeepWalk [19] algorithm employs a random walk strategy to generate node embedding representations in a self-supervised manner, further enhancing the capabilities of GNNs without the need for extensive manual labelling.\nRecently, with the development of graph contrastive learning (GCL), the performance of some self-supervised training methods is comparable to supervised learning methods [20], [21]. Specifically, GCL operates by creating various graph perspectives through data augmentation, an approach that minimizes the distance between input positive pairs in feature space and maximizes the distance between negative pairs. For instance, Deep Graph Infomax (DGI) [22] leverages mutual information (MI) to enhance the model's ability to distill valuable insights from the node's local context. Meanwhile, Graph Contrastive Learning (GraphCL) [23] aims to refine node representations so that they more accurately reflect the graph's structural and semantic attributes within the embedding space through contrastive techniques. Additionally, Spectral Feature Augmentation (SFA) [24] employs feature-level augmentation to estimate low-rank feature approximations across different graphs, offering a complementary strategy to other existing graph augmentation methods.\nAs depicted in Figure 1, we notice that the low-frequency components exhibit relatively mild variations, whereas the high-frequency components undergo significant changes. This observation leads us to posit that high-frequency components are pivotal in GCLs, given the substantial disparities between each \"pixel\". SpCo [20] also has theoretically established that high-frequency information holds greater significance than low-frequency information in GCL. Nonetheless, SpCo necessitates eigendecomposition of the Laplacian matrix, leading to considerable computational overhead (i.e., O(n\u00b3)). However, many current GCL methods focus on feature transformation in the time domain and fail to capture the high-frequency aspects of node features. Furthermore, existing GCLs methods mainly obtain better node feature representation by sampling positive and negative samples pairs, but our theoretical analysis shows that graph contrastive learning actually benefits from pushing negative pairs farther away rather than pulling positive pairs closer. Drawing inspiration from SpCo, we propose a novel spectral graph contrastive learning framework, named SpeGCL, to address the aforementioned issues. In our approach, we regard the embedded representations of historical interactions between nodes as self-supervised signals and utilize Fourier transform [25] to isolate both low-frequency and high-frequency components of node embeddings. Furthermore, we construct multiple graph contrastive views to preserve the most expressive information within node embeddings. Contrary to prior GCL methods [26] that concurrently sample both positive and negative pairs for contrastive learning, we contend that the contrastive learning mechanism primarily relies on negative sample pairs for parameter tuning. We have also provided a theoretical demonstration that the model can achieve convergence utilizing solely negative samples. Our contributions can be summarized as follows."}, {"title": "II. RELATED WORK", "content": "Inspired by the remarkable success of contrastive learning in computer vision (CV) and natural language processing (NLP) [27]\u2013[34], many graph contrastive learning methods (GCLs) [35]\u2013[42] have been proposed in recent years. These methods introduce data augmentation strategies, utilize the perturbations of nodes and edges in the graph structure, generate two augmented views, and learn graph representations by maximizing the mutual information (MI) between the two views. Specifically, the core idea of GCLs is to capture the structural information and semantic features in the graph by comparing different graph views, thereby improving the representation ability of the model. For example, Deep Graph Infomax (DGI) [22], as one of the early representative methods, adopts the InfoMax loss function to improve the graph representation learning effect by maximizing the mutual information between the representation of the correct node in the graph and the representation of other nodes. DGI emphasizes the learning of global graph representations, aiming to improve the model's understanding of the entire graph structure. Different from DGI, InfoGraph [43] focuses on comparing the graph representations of different substructures, which can not only capture the characteristics of the global graph structure, but also obtain the fine-grained information of local nodes, thereby optimizing the representation learning of nodes and substructures at different levels. GCC [44] learns a common representation that can be generalized in multiple graphs by designing cross-graph comparison tasks. This method adopts a structure-based graph data augmentation strategy and improves generalization ability by maximizing local and global information between nodes. Sub-GCL [45] enhances graph representation by learning comparisons between subgraphs. This method proposes to extract subgraphs from the global graph and designs subgraph comparison tasks to capture different levels of graph information. Sub-GCL improves the sensitivity of graph models to local structures by comparing the representations of different subgraphs. InfoGCL [46] proposes a graph comparison learning framework based on information theory. The key to this method is to automatically select important graph structure features to participate in comparison learning through a learnable selection mechanism. By introducing different graph enhancement strategies, InfoGCL can adaptively select the structural information that best represents the graph, thereby better capturing the key information in the graph. MVGRL [47] is a multi-view graph comparison learning method that generates multiple views and performs comparison learning between different views to improve the robustness of graph representation.\nAnother influential model is GRACE [48], whose core idea is to improve representation capabilities at the node level by maximizing the similarity between positive contrast terms and minimizing the similarity between negative contrast terms. Similarly, GraphCL [23] focuses on learning graph-level representations, and by maximizing the mutual information between different enhanced views, the graph model can capture the global structural characteristics of the graph.\nBased on these pioneering works, new GCL methods have been proposed in recent years, which have made significant progress in learning both graph-level representations and node-level representations. However, unlike the above methods, our work is not limited to designing specific graph enhancement views. Instead, we explore whether it is necessary to rely on high-frequency information in the process of graph representation learning from a broader graph spectrum perspective. We try to reveal the role of high-frequency information in graph contrastive learning and propose a new framework that enables the model to more effectively utilize different frequency information in the graph, thereby improving the quality of representation learning.\nFrequency-domain Deep Learning. The frequency domain analysis method has always been a classic tool in the field"}, {"title": "III. PRELIMINARTIES", "content": "We assume that a graph is represented as G = {V,E}, where V = {v\u2081, v\u2082,...,v\u2099} represents the set of nodes and E \u2208 V \u00d7 V represents the set of edges. X = {x\u1d62}\u1d62=\u2081\u1d3a and A \u2208 {0,1}\u1d3a\u00d7\u1d3a are the feature matrix and adjacency matrix of the graph, where x\u1d62 represents the feature vectors of node v\u1d62, a\u1d62\u2c7c = 1 indicates that there is an edge relationship between v\u1d62 and v\u2c7c, otherwise a\u1d62\u2c7c = 0."}, {"title": "B. Fourier Transform", "content": "Fourier transform [59] is widely used in signal processing, which can convert time domain signals into frequency domain signals. In this article, we use Discrete Fourier Transform (DFT) to perform signal conversion as follows:\n```latex\nF(m, n) = \\sum_{x=0}^{M-1} \\sum_{y=0}^{N-1} f(x,y)e^{-j2\\pi(\\frac{xm}{M}+\\frac{yn}{N})}\n```\nwhere j represents the imaginary unit, f(x,y) represents the time domain signals, F(m, n) represents the frequency domain signals, (m,n), and (x,y) is the coordinates of the Fourier space and time domain space, respectively. F\u207b\u00b9(x) is the inverse Fourier transform. We reconstruct the original signals via the IDFT:\n```latex\nf(x,y) = \\frac{1}{MN}\\sum_{m=0}^{M-1}\\sum_{z=0}^{N-1}F(m, n) e^{i2\\pi(\\frac{xm}{M}+\\frac{yn}{N})}\n```\nSince the computational complexity of DFT/IDFT is large and difficult to adapt to large-scale data sets, in this paper we apply fast Fourier transform (FFT) and inverse fast Fourier transform (IFFT) to reduce the complexity from O(n\u00b2) to O(nlogn). The amplitude component A(m,n) and phase component P(m, n) is defined as follows:\n```latex\nA(m, n) = \\sqrt{R^2(m, n) + I^2(m, n)}\n```\n```latex\nP(m, n) = arctan[\\frac{I(m, n)}{R(m, n)}]\n```\nwhere R\u00b2(m, n) and I\u00b2(m, n) are the real and imaginary parts respectively."}, {"title": "C. Training Objective", "content": "The main goal of GCLs [22], [47], [60] is to learn discriminative embeddings without supervision. The method is to generate two augmented views in a predefined way (e.g., masked nodes and edge perturbations, etc.) and encode them by GCN to obtain the node embeddings of the two augmented views. Subsequently, for a target node, its embedding in an enhanced view is designed to be close to its positive samples and far away from its negative samples. The GCLs method [23], [39] uses the classic InfoNCE loss [61] as the optimization objective to distinguish similar nodes from dissimilar nodes. The optimization objective is defined as follows:\n```latex\n\\mathcal{L}_{NCE} \\triangleq -\\mathbb{E}_{(\\mathbf{x},\\mathbf{y}) \\sim p_{pos}}\\left[ \\log \\frac{e^{\\mathbf{f}(\\mathbf{x})^T \\mathbf{f}(\\mathbf{y}) / \\tau}}{e^{\\mathbf{f}(\\mathbf{x})^T \\mathbf{f}(\\mathbf{y}) / \\tau} + \\sum_{i=1}^{M} e^{\\mathbf{f}(\\mathbf{x})^T \\mathbf{f}(\\mathbf{y}_i) / \\tau}} \\right]\n```\n```latex\n  = \\mathbb{E}_{(\\mathbf{x},\\mathbf{y}) \\sim p_{pos}}\\left[ -\\mathbf{f}(\\mathbf{x})^T \\mathbf{f}(\\mathbf{y}) + \\log \\left( e^{\\mathbf{f}(\\mathbf{x})^T \\mathbf{f}(\\mathbf{y}) / \\tau} + \\sum_{i=1}^{M} e^{\\mathbf{f}(\\mathbf{x})^T \\mathbf{f}(\\mathbf{y}_i) / \\tau} \\right) \\right]\n```\n```latex\nalignment uniformity\n```\nwhere (x, y) ~ ppos is the positive pair, ppos is the probability distribution of the positive pair, \u03c4 is a decay coefficient, and {y\u1d62}\u1d62=\u2081 \u1d39\u1d62\u2024 \u1d62\u2024 \u1d48 \u223c p\u1d67 is the negative samples."}, {"title": "IV. PROPOSED METHOD", "content": "As shown in Fig. 2, the overall process of the proposed SpeGCL method includes four modules: data augmentation, Fourier graph convolutional neural network, contrastive learning and graph classification. In the following sections, we will describe their implementation process in detail."}, {"title": "A. Generated Multi-view Augmentation", "content": "Node-Masking View We perform automatic learnable node masking before each information aggregation and feature update of GCN to generate the augmented node-masking views. The node-masking view is as:\n```latex\nG_{ND}^{(1)} = \\left\\{v_i \\odot \\eta_i^{(1)} | v_i \\in V, \\varepsilon\\right\\}\n```\nwhere \u03b7\u1d62\u2208 {0,1} is sampled from a parameterized Bernoulli distribution Bern(w\u1d62), and \u03b7\u1d62 = 0 represents masking node v\u1d62, \u03b7\u1d62 = 1 represents keeping node v\u1d62.\nEdge Perturbation View Edge perturbation can be seen as a subtle adjustment to the original graph structure to create a new graph view that enables the model to better understand the relationship between nodes during training and improve its robustness. By properly perturbing the edges, useful edge"}, {"title": "B. Fourier Graph Convolutional Network", "content": "The classical graph networks (e.g., GCN [62] and GAT [63]) cannot compute in the frequency domain and obtain feature representations of hidden layer nodes, and their computational complexity is high (quadratic complexity). Therefore, we design a more efficient and effective method to obtain the feature representation of nodes within Fourier space based on the convolution theorem [64]. The graph convolution operation can be rewritten as follows:\n```latex\n\\mathcal{F}(X) \\circledast \\mathcal{F}(k) = \\mathcal{F} \\left( (X * k) [i] \\right)\n```\n```latex\n= \\mathcal{F} \\left(\\sum_{j} X [j] \\kappa [i - j]\\right) = \\mathcal{F} \\left(\\sum_{j} X [j] \\kappa [i, j]\\right)\n```\n```latex\n= \\mathcal{F} \\left(A_{i j} X [j] W\\right) = \\mathcal{F} \\left(A X W\\right)\n```\nwhere (X * \u03ba) [i] represents the convolution of X and \u03ba in the fourier spaces, and \u03ba[i, j] = A\u1d62\u2c7cW."}, {"title": "C. Graph Contrastive Learning", "content": "The low-frequency bias of deep learning models limits the usefulness of graph encoders [65]. To solve the above problems, we constructed samples containing low-frequency information and high-frequency information for graph contrastive learning to improve the feature discrimination ability of the encoder. Unlike previous GCL work [26] that used positive and negative pairs to achieve contrastive learning, we only use negative pairs."}, {"title": "V. EXPERIMENTS", "content": "We use the TUDataset dataset\u00b9 [67] to verify the effectiveness of the proposed SpeGCL under experimental settings of unsupervised and semi-supervised learning. Under the experimental setting of transfer learning, we pre-trained on the ChEMBL dataset [68] and fine-tuned the model using the MoleculeNet dataset\u00b2 [69]. The detail information of those used datasets can be found in Tables I, and II.\nTo evaluate the effectiveness of the proposed SpeGCL, we conduct extensive experiments under different experimental settings and different datasets. Specifically, for unsupervised"}, {"title": "VII. CONCLUSIONS", "content": "In this paper, we explore the application of Fourier graph networks for graph classification from the perspective of graph spectrum. To solve the problem that existing methods cannot fully utilize the high-frequency information of node features and require time-consuming construction of positive and negative sample pairs, we propose a novel spectral graph contrastive learning framework without positive samples (SpeGCL). Specifically, SpeGCL uses Fourier operations to obtain high-frequency and low-frequency information of node features. While the graph view performs contrastive learning to retain the most expressive local context information in the nodes. Furthermore, SpeGCL uses only negative samples to optimize the embedding representation of the graph. We also theoretically demonstrate the rationality of using only negative samples on GCL. Extensive experiments have been conducted to prove the superiority of our SpeGCL framework over the state-of-the-art GCLs."}, {"title": "APPENDIX", "content": "A. Convolution Theorem\nThe convolution theorem [64] is a core concept in the field of Fourier transforms, which reveals the direct connection between the convolution operation in the time domain and the product operation in the frequency domain. Specifically, the convolution theorem states that if there are two signals, such as an input signal x[n] and an impulse response h[n] of a system or filter, their convolution result y[n] in the time domain can be obtained by performing a point-by-point product of the Fourier transforms of the two signals and then performing an inverse Fourier transform on the result:\n```latex\n\\mathcal{F}\\{(x*h)[n]\\} = \\mathcal{F}\\{x[n]\\} \\cdot \\mathcal{F}\\{h[n]\\}\n```\nwhere \\mathcal{F}\\{\\cdot\\} represents the Fourier transform, (x * h)[n] is the convolution of a signal x[n] and a filter h[n].\nB. Proof of Theorem 1.\nTheorem 1. For a fixed \u03c4 > 0, when the number of negative samples M \u2192 \u221e, the contrastive loss L_{NCE} converges and the absolute deviation decays with O(M^{-2/3}). If there exists a perfectly uniform encoder f, it is able to obtain the minimum value.\nProof. Note that for any x, y \u2208 \u211d\u207f and {x\u1d62}\u1d62=\u2081 \u1d39 \u1d62\u2024 \u1d62\u2024 \u1d48 \u209adata, according to the strong law of large number (SLLN) and the continuous mapping theorem we have\n```latex\n\\lim_{M \\rightarrow \\infty} \\frac{1}{M} \\sum_{i=1}^{M} e^{f(x)f(y_i) / \\tau} = E_{x \\sim P_{data}} [e^{f(x)f(y) / \\tau}]\n```\n```latex\n= E_{x \\sim P_{data}} [e^{f(x)f(y) / \\tau}] + O(M^{-2/3})\n```\nAccording to the Dominated Convergence Theorem (DCT) [82], we can derive"}]}