{"title": "ErgoChat - a Visual Query System for the Ergonomic Risk Assessment of Construction Workers", "authors": ["Chao Fan", "Qipei Mei", "Xiaonan Wang", "Xinming Li"], "abstract": "In the construction sector, workers often endure prolonged periods of high-intensity physical work and prolonged use of tools, resulting in injuries and illnesses primarily linked to postural ergonomic risks, a longstanding predominant health concern. To mitigate these risks, researchers have applied various technological methods to identify the ergonomic risks that construction workers face. However, traditional ergonomic risk assessment (ERA) techniques do not offer interactive feedback. The rapidly developing vision-language models (VLMs), capable of generating textual descriptions or answering questions about ergonomic risks based on image inputs, have not yet received widespread attention. This research introduces an interactive visual query system tailored to assess the postural ergonomic risks of construction workers. The system's capabilities include visual question answering (VQA), which responds to visual queries regarding workers' exposure to postural ergonomic risks, and image captioning (IC), which generates textual descriptions of these risks from images. Additionally, this study proposes a dataset designed for training and testing such methodologies. Systematic testing indicates that the VQA functionality delivers an accuracy of 96.5%. Moreover, evaluations using nine metrics for IC and assessments from human experts indicate that the proposed approach surpasses the performance of a method using the same architecture trained solely on generic datasets. This study sets a new direction for future developments in interactive ERA using generative artificial intelligence (AI) technologies.", "sections": [{"title": "1\nIntroduction", "content": "Prompt and effective identification and mitigation of workplace hazards are essential for maintaining safety, health, and productivity within the work environment. In the construction industry, workers are often subject to conditions that require awkward body postures, repetitive motions, and intense physical effort, which can detrimentally impact their health [1]. Such conditions in construction tasks usually lead to the emergence of work-related musculoskeletal disorders (WMSDs). Statistics from the United States Bureau of Labor Statistics show that the construction industry's injuries and illnesses caused by WMSDs ranked fifth among all industries. Moreover, in the same year, WMSDs represented 30% of all occupational injuries and illnesses [1]. According to the Association of Workers' Compensation Boards of Canada, the manufacturing and construction sectors reported the second and third-highest rates of lost- time injury claims in 2021, representing 13.6% and 10.4% of claims, respectively [2]. European Agency for Safety and Health at Work indicated that the construction and manufacturing sectors reported the highest sick leave rates due to WMSDs [3]. Therefore, early identification and proactive prevention of WMSDs caused by postural ergonomic risks are crucial for companies and construction industry workers.\nTraditional methods of postural ERA include self-reporting, observation, and direct measurements [4-11]. Self-reporting and observational methods are limited by the need for manual data collection, which includes the significant time required by ergonomic experts and inconsistencies in data interpretation. Alternatively, the direct measurement method employs sensors or markers attached to workers and uses a motion capture system to evaluate their postural ergonomic risks. While this type of method is more time-efficient and objective compared to self-reporting and observational techniques, the attached sensors or markers can create psychological and physical burdens on the workers, potentially impacting their work performance. Additionally, motion capture systems that use markers demand specific environmental conditions to function effectively, such as adequate ambient lighting and clear visibility of markers. In summary, the limitations inherent in traditional approaches substantially detract from the effectiveness of ERA methods.\nTo overcome the challenges of subjectivity, inconsistency, intrusiveness, and the time-intensive nature of traditional ERA methods, predictive Al has become a popular tool for researchers. Predictive Al encompasses Al systems that employ statistical analysis and machine learning algorithms to forecast potential outcomes, determine causation, assess risk exposure, and more. In the context of ERA, predictive AI typically involves the application of these trained models to interpret data gathered from sensors worn on the body; these trained models are used to determine whether workers are exposed to ergonomic risks based on the data received from the sensors on the workers [12]. However, it is crucial to acknowledge that while these sensor- based or marker-based predictive AI methods address the issues of low time efficiency, subjectivity, and inconsistency inherent in traditional approaches, they do not resolve the problem of intrusiveness [10]. On the other hand, computer vision (CV)-based predictive AI methods [5-9,13] can avoid introducing intrusiveness into ERA while overcoming the drawbacks of subjectivity, inconsistency, and time consumption. However, an unavoidable drawback of CV-based ERA methods is that occlusions in images or videos can significantly impact accuracy [13].\nUnlike predictive AI, generative Al encompasses deep-learning models capable of processing raw data to \"learn\" and produce statistically probable outputs upon request. Fundamentally, these generative models encapsulate a simplified representation of their training data, which they utilize to generate new outputs that are similar yet distinct from the original data. The innovations brought about by transformers, particularly noticeable in large language models (LLM) tools such as ChatGPT, have ignited widespread interest, leading to investigations into their potential applications across various domains [14]. This surge in interest in LLMs using transformers suggests a range of promising research opportunities within the ERA field. In this context, existing ERA methods present two key limitations. First, predictive AI-based ERA"}, {"title": "2\nRelated Work", "content": "Construction safety has long been an actively explored research field. Although injuries and deaths resulting from safety accidents are more catastrophic, the damage to workers' physical health caused by WMSDs due to ergonomic risks is a widespread issue that should not be overlooked [15]. As researchers and safety practitioners become increasingly aware of the prevalence of WMSDs caused by ergonomic risks in the workplace, more postural ERA tools have been proposed [16]. The widely recognized classification categorizes these postural ERA"}, {"title": "2.1 Traditional ERA", "content": "Self-report methods. Self-report methods require researchers to collect ergonomic risk information from workers through surveys, interviews, or worker diaries [17]. The Standardized Nordic Questionnaire is an example of a self-report-based assessment method [18]. The Standardized Nordic Musculoskeletal Questionnaire was designed to identify ergonomic risks in the workplace by assessing the prevalence of WMSD. The Standardized Nordic Musculoskeletal Questionnaire was created for repeated screening and monitoring of WMSD and related ergonomic risk factors in the work environment, and it is not intended for clinical diagnosis [18]. A key advantage of the questionnaire is that it is standardized, allowing for the comparison of results across different studies. A more detailed version of the Standardized Nordic Musculoskeletal Questionnaire builds on the original one by adding questions about pain and the consequences of pain. The detailed version has been proven to be very reliable in identifying WMSD related to occupational and general population health [19]. Researchers and safety practitioners have also developed questionnaires tailored to particular industry sectors. Although many self-report methods have been proposed and even optimized, these self-report methods inevitably share common drawbacks. The drawbacks arise from the inconsistent perception, comprehension, or interpretation among those who respond to and process the questionnaires [19]. Other disadvantages include being time-consuming and prone to errors [20,21].\nObservational methods. Observational methods evaluate the ergonomic risks associated with workers' postures using established tools according to the guidelines provided by these tools. Observational methods can be implemented through direct observation of workers or by analyzing video recordings of workers. The most common observation method-based assessment tools include Rapid Entire Body Assessment (REBA), Rapid Upper Limb Assessment (RULA), and the revised National Institute for Occupational Safety & Health (NIOSH) lifting equation [22,23]. REBA is an ergonomic assessment tool used to evaluate workers' risk of entire body WMSDs [24]. A key feature of REBA is its ability to rapidly assess the risk of WMSDs across the whole body, facilitating the improvement of worker tasks or interventions in improper movements. RULA is an ergonomic evaluation tool designed to assess workers' risk of upper body WMSDs [25]. Both RULA and REBA employ posture diagrams and scoring tables to identify potential sources of muscular fatigue. However, in contrast to REBA, a notable limitation of RULA is its exclusion of the lower limbs in its assessment, potentially overlooking WMSDs that could develop in the lower limbs. The Revised NIOSH Lifting Equation serves as an observational method for evaluating the physical demands associated with manual lifting tasks and assessing the potential risk of WMSD. The Revised NIOSH Lifting Equation output is a recommended weight limit calculated using six variables related to the task. The recommended weight limit defines the load an average worker"}, {"title": "2.2 Predictive AI-based ERA", "content": "Predictive AI-based ERA uses various AI algorithms to learn from past data and analyze future data based on the knowledge acquired to perform risk assessments. Predictive AI-based ERA can be divided into three steps. The first step begins with collecting sufficient data to train the AI algorithms, which must be relevant to the desired prediction task. The second step involves using the data collected in the first step to train the AI algorithm, thereby continuously optimizing the model to accurately recognize patterns in future data. The third step involves deploying the trained AI model to predict outcomes based on its acquired knowledge from the historical data. Previous studies on Predictive AI-based ERA have commonly used Al techniques, including Support Vector Machines, Decision Trees, Long Short-Term Memory, Linear Regression, Artificial Neural Networks, Recurrent Neural Networks, and Convolutional Neural Networks, among others [12,33]. Significant potential for further exploration in deploying AI-based ERA methods within the construction industry remains. In contrast, the application of AI in ERA has been more extensively researched in general contexts. It is worth noting that these general methods can also be adapted for use in the construction industry through modification and improvement. This study only discusses construction industry- specific methods.\nFrom Table 2, it can be observed that the majority of predictive AI-based ERA methods are implemented using sensors attached to the human body. Such methods share a common drawback - intrusiveness, which inevitably imposes psychological and physical burdens on workers. It is worth noting that the fundamental distinction between predictive AI-based and direct measurement methods lies in integrating AI for risk assessment. While both types utilize devices for data collection, predictive AI methods employ AI to automate the ERA process. In contrast, direct measurement methods rely on human evaluation for ERA. Approaches that use only video as the input for AI algorithms offer an alternative to sensor-based methods by eliminating the need to attach sensors or markers to workers. For instance, Fan et al. [13] have developed a technique using a CNN-based CV algorithm for the real-time tracking of workers' movements. This algorithm is trained using a previously collected construction workers' 3D dataset. Following this, the REBA method is applied to evaluate ergonomic risks from the predicted pose data obtained through the CV algorithm. The technique developed by Cai et al. [34] leverages a CV-based pose-tracking algorithm to track workers' movements. The next step is using an LSTM model to classify ergonomic poses, culminating in assessing these poses for ergonomic risks using the OWAS method. This methodology also demonstrates a non-intrusive way of conducting ergonomic assessments."}, {"title": "2.3 Potential applications of generative AI in ERA", "content": "The fundamental difference between generative AI and predictive AI methods centers on their respective functionalities; generative AI is adept at generating new content, whereas predictive Al is primarily employed for classification or prediction tasks based on input data [44,45]. Generative Al distinguishes itself by its ability to produce original content, including texts, images, videos, and audio. This content creation capability allows for its innovative applications in ERA. When given specific prompts, generative AI has the potential to deliver straightforward yes or no responses to queries regarding the identification of ergonomic risks, elaborate on detected ergonomic risks with detailed descriptions, and even propose strategies to alleviate or prevent these risks. Nevertheless, predictive AI-driven ERA, which primarily concentrates on quantifying ergonomic risk levels through the detection of specific variables, has been limited"}, {"title": "3 Methodology", "content": "The proposed ErgoChat is an interactive chatbot capable of providing textual descriptions of the ergonomic risks faced by workers in an image input and identifying these ergonomic risks. The proposed ErgoChat can achieve VQA and IC regarding ergonomic risks for construction scenarios. Its architecture is adopted from MiniGPT-v2, comprising a visual backbone, a linear projection layer, and an LLM.\nThe parts can be summarized as follows:\n1) The visual backbone of ErgoChat utilizes the EVA ViT [57]. A ViT employs a self-attention mechanism for image processing. It is structured as a sequence of transformer modules, each containing two primary sub-layers: a self-attention layer and a feed-forward layer. The self- attention layer computes attention weights by evaluating the relationships among all pixels in the image, while the feed-forward layer performs nonlinear transformations on the outputs from the self-attention layer [57]. During the training of ErgoChat, this visual backbone remains frozen. An image resolution of 448x448 for training is employed. Additionally, interpolation techniques are utilized to handle position encoding, adapting to higher image resolutions.\n2) The role of the linear projection layer in ErgoChat is to project visual tokens [57] from the frozen visual encoder into the feature space of the LLM [58]. The visual tokens and textual instructions/questions were provided/projected as inputs to the LLM for visual reasoning. Visual tokens represent the image patches into which an input image is divided, consisting of grids of fixed-size pixels. To mitigate the issue of decreased training and inference speed due to high-resolution images, ErgoChat employs a method similar to MiniGPTv2 [53] for handling visual tokens. These visual tokens are concatenated in groups of four adjacent tokens, and then these concatenated tokens are projected into the same feature space of the LLM. The feature space encodes diverse linguistic elements, including words, phrases, sentences, and extended text sequences, into numerical vectors that the model can process and analyze. As a result, this approach reduces the number of visual tokens to one-fourth of the original number, significantly enhancing training and inference speed when using high-resolution images.\n3) ErgoChat adopts the open-source LLaMA2-7B [58] as the backbone for its LLM. The architecture of ErgoChat incorporates the LLM as an interface for inputs regarding vision-"}, {"title": "3.1 Pre-training ErgoChat with generic image-text pair datasets", "content": "ErgoChat was trained with publicly available generic image-text pair datasets not explicitly designed for ergonomic risk identification/knowledge, resulting in a large VLM with generic visual knowledge. The ErgoChat training using the generic dataset was divided into pre-train 1 to 3; the model underwent three pre-training sessions utilizing different combinations of those generic datasets. These datasets encompassed a broad spectrum of contents, including but not limited to humans, other animals, plants, architectural structures, vehicles, and landscapes. Pre- train 1 involves equipping ErgoChat with broad generic vision-language knowledge by leveraging a combination of numerous weakly-labeled image-text datasets and high-quality, fine-grained vision-language annotation datasets. Pre-train 2 involves refining the model using only fine-grained data for various tasks, such as VQA and IC. The rationale is to improve the model's performance in tasks such as VQA and IC. Therefore, the weakly-supervised dataset used previously was not utilized again in this training step. In pre-train 3, the model undergoes further fine-tuning with additional multimodal instruction and language datasets to enhance its capability to respond to diverse multimodal instructions and function effectively as a multimodal chatbot. The fine-tuning enables the model to gain more robust reasoning abilities while also addressing the issue where, after training on the GRIT-20M dataset (which contains very few grounded visual objects in its captions), the model could only visually recognize a limited range of objects [53]."}, {"title": "3.2 Dataset curation for fine-tuning and testing", "content": "An image-text pair dataset was curated to fine-tune and test the VLM obtained in the last step. The partition for fine-tuning contained 1,700 distinct image-text pairs, and the partition for performance testing contained 200 image-text pairs. The images in both fine-tuning and testing partitions were obtained by searching 'construction works' in online resources with free-to-use licenses.\nDescriptions of ergonomic risks in the text part of image-text pairs were based on using the REBA. The REBA employs a systematic approach to assess the upper and lower segments of the musculoskeletal system, identifying risks of WMSDs associated with a work task. The REBA classifies risk levels into five categories, spanning from negligible, low, medium, and high to very high risk [24]. The assessment of the presence of ergonomic risk in the textual descriptions associated with each image in the dataset relies on whether the REBA risk level of any worker depicted in the image equals or exceeds the medium risk threshold. If the REBA risk level meets or exceeds the medium risk threshold, the textual description will denote that the depicted worker is exposed to ergonomic risk; conversely, if the REBA risk level falls below the medium risk threshold, the textual description will indicate a lack of exposure to ergonomic risk. Alongside determining whether the workers depicted in the images are exposed to ergonomic risk, the text also describes the actions/tasks that lead to workers being exposed to ergonomic risk. A Python program was developed to convert these textual descriptions into a JavaScript Object Notation (JSON) file in MSCOCO format. The construction worker images and the JSON-formatted annotation file constitute this image-text pair dataset, which was utilized during the fine-tuning and testing of ErgoChat."}, {"title": "3.3 Fine-tuning ErgoChat with the specific dataset for ergonomic risk identification", "content": "The large VLM obtained from step 1 was fine-tuned with the fine-tuning dataset created in the second step. Using the ergonomic-specific dataset for construction workers proposed in this study, the fine-tuning serves to equip ErgoChat with knowledge of the ergonomic risks commonly faced by construction workers, thereby enhancing its performance in VQA and IC for ergonomic risks in the construction industry. This process yielded a large VLM with more ergonomic risk identification knowledge and capability. In this step, the ErgoChat pre-trained through the pre-train 1 to 3 underwent fine-tuning with the ergonomic risk-specific dataset. The dataset utilized in fine-tuning was precisely the fine-tuning partition created in step 2.\nAfter this fine-tuning stage, it was anticipated that ErgoChat would demonstrate notably improved performance in terms of ergonomic risk identification-related VQA and IC."}, {"title": "3.4 Performance evaluation of the fine-tuned ErgoChat", "content": "The performance was measured from two perspectives: (1) accuracy in VQA related to ergonomic risk identification and (2) the ability to generate textual descriptions concerning ergonomic risk identification for workers."}, {"title": "3.4.1 Accuracy of VQA", "content": "The large VLM obtained after fine-tuning was tested with the testing dataset curated in step 2. The model obtained without fine-tuning (after pre-train 1 to 3) was also tested with the same testing partition so that the performance of ErgoChat before and after fine-tuning can be compared. In order to alleviate ambiguity encountered across various queries and tasks, the proposed dataset incorporates task identifier tokens designated for [caption] and [vqa]. In this dataset, [caption] is designated as the task identifier token for IC, while [vqa] serves as the task identifier token for VQA annotations. These identifiers are included at the beginning of the prompts to reduce ambiguity. Regarding VQA, the results before and after fine-tuning were compared with ground truth. For example, the VQA prompt for the test image was \"[vqa] Is the worker exposed to postural ergonomic risks?\" and both before and after fine-tuning, ErgoChat's responses were \"yes.\" The same prompt \"[vqa] Is the worker exposed to postural ergonomic risks?\" was used for all the cases in the testing partition. Since the ground truth value for the VQA was \"yes,\" the responses from ErgoChat both before and after fine-tuning were correct. Finally, the accuracy of VQA that the two models can achieve for the 200 test data points (percentage of correct answers out of the total) was calculated. Eq. 1 was used to calculate the percentage of correct risk identification using VQA."}, {"title": "3.4.2 Quality of generated text descriptions", "content": "In terms of textual description of ergonomic risks generated by ErgoChat, the text generated before and after fine-tuning was compared with ground truth. The prompt used to create text descriptions was \"[caption]Describe the workers and their postures in the image and tell me if they are exposed to ergonomic risks due to their postures?\" The same prompt was used for all the cases in the testing partition. The performance of ErgoChat was measured by calculating the similarities between generated and ground truth descriptions. The perplexity [78] was used for VQA. A total of 9 metrics were used to calculate the similarities between the generated text and the ground truth text for every image in the testing dataset.\nThe perplexity was used to test the probability that the generated textual descriptions for ergonomic risk identification were correct. If the generated description indicates that the worker is performing an ergonomically unsafe action, the corresponding score for identifying the ergonomic risk will be lower. A lower perplexity score indicates a higher probability that the description concludes the worker is exposed to ergonomic risk. A more detailed description of perplexity could be found in [78]. Perplexity is employed to estimate the likelihood of workers being exposed to ergonomic risks based on text descriptions generated by the two models compared in this study. When a text description's perplexity score indicates a higher probability of ergonomic risk and aligns with the ground truth, it implies that the VLM responsible for generating the description offers a more accurate image representation. ROUGE is a set of metrics designed explicitly for evaluating automatic summarization, which can also be applied to machine translation. The metrics compare a generated summary or translation against reference summaries or translations that are high-quality and produced by humans [78]."}, {"title": "3.5 Human evaluation of generated textual descriptions", "content": "In addition to the nine metrics, human evaluation was also employed to assess the improvement of fine-tuning on ErgoChat in terms of text description generation related to ergonomic risk identification. A questionnaire was devised to solicit assessments from individuals knowledgeable in ergonomics regarding the accuracy of descriptions generated by the post- fine-tuned ErgoChat versus those generated by the pre-fine-tuned ErgoChat for the testing"}, {"title": "4 Results and Discussion", "content": "4.1 Performance of VQA\nThe testing dataset was utilized to assess the performance of the proposed ErgoChat in ergonomic risk identification in VQA. For the performance of ErgoChat and the general VLM models in ergonomic risk identification, this study calculated the accuracy of ergonomic risk identification by computing the results from the descriptions' perplexity scores and VQA.\nConsequently, the proposed ErgoChat exhibits a slight improvement over the other VLM. It is worth noting that although the VLM used for comparison did not undergo fine-tuning, it demonstrated commendable performance in VQA for ergonomic risk identification. These findings suggest that the method, pre-trained on generic datasets, can determine whether workers face ergonomic risks in images. Nevertheless, its capacity to generate human-like descriptions of ergonomic risks and elucidate actions leading to such risks remains notably deficient."}, {"title": "4.2 Performance of IC of ergonomic risk-related descriptions", "content": "For the performance of fine-tuned ErgoChat and the general VLM in generating textual descriptions of ergonomic risks from images, this study utilized multiple metrics to calculate the similarity between the generated text and the descriptions provided by ergonomic experts.\nSince cosine similarity ranges from -1 to 1, the values obtained from equations 3, 4, and 5 are not particularly informative. Moreover, a smaller Euclidean distance signifies higher accuracy in the generated text. Consequently, the data presented in Table 7 and Table 8 demonstrate that, apart from cosine similarity, other metrics indicate that ErgoChat is more accurate than the general VLM in delivering ergonomic risk-related information to construction workers. Results from 9 metrics employed to gauge the similarity between the generated descriptions of ergonomic risk identification and the ground truth affirm the superior accuracy of the proposed approach. Across the entire testing dataset, the average similarity scores obtained under the evaluation of the 9 metrics with the ground truth are higher for the proposed ErgoChat than the same architecture VLM. Specifically, the average ROUGE_r score of the proposed method surpasses that of the alternative method by 0.25531, indicating a 25.53% improvement because the ROUGE_r metric ranges from 0 to 1. Moreover, the proposed method demonstrates higher similarity scores for 97% of the data in the entire testing dataset than the alternative model."}, {"title": "5 Conclusion and Future Work", "content": "The primary objective in developing ErgoChat was to address the generation of textual descriptions concerning ergonomic risks linked to WMSD and VQA for ergonomic risk recognition in the construction sector. In these areas, traditional AI approaches have been limited in pinpointing the root ergonomic issues and proposing corresponding remedies. Built on the prevalent GPT architecture, similar methods still have significant room for improvements in the above functionalities, even after training solely on generic datasets. To explore the feasibility and potential for performance improvement of ErgoChat, this study introduced a dataset for fine-tuning and testing. To mitigate ambiguity across different queries and tasks, the dataset includes task identifier tokens for [caption] and [vqa].\nOne of our technical contributions is the proposed large VLM method for automatically or interactively identifying ergonomic risks related to WMSDs that construction workers face. Another technical contribution involves the creation of an image-text pair dataset designed explicitly for large VLM methods, incorporating task identifier tokens and addressing ergonomic risks faced by construction workers. The last technical contribution is a thorough evaluation of the method, incorporating both quantitative and qualitative approaches. This evaluation includes analysis across nine distinct metrics and insights gathered from 50 ergonomic experts. Unlike generic VLM methods, the proposed approach emphasizes the recognition and description of WMSD in construction workers in real-world scenarios.\nThe 9 metrics and human evaluation for IC all indicate that the proposed method outperforms the method of the same architecture in terms of ergonomic IC performance. Additionally, both the perplexity and VQA results demonstrate that the proposed method surpasses the method of the same architecture in ergonomic identification VQA performance. The evaluation experiments conducted in this study reasonably suggest that the practical application serves as a tool to enhance awareness of safety on construction sites and reduce the risk of WMSD among construction workers.\nIn the context of VQA evaluation, ErgoChat realizes a 1.5% increase in accuracy, achieving a total of 96.5%. Human evaluation results suggest that 84.4% of the text descriptions generated by ErgoChat are more accurate than those from the other model, with an average accuracy for these descriptions being 69.7% higher than that of the other model's outputs.\nIn terms of IC, the evaluation metric results reveal that while the average difference in cosine similarity between the two models is negligible, the remaining eight metrics indicate that ErgoChat outperforms the other model in terms of IC. Specifically, six of these metrics demonstrate that ErgoChat achieves superior IC results for over 90% of the data in the test set. The other two metrics show improved IC for more than 65% of the test dataset. Human evaluation results demonstrated that 84.4% of the text descriptions produced by the fine-tuned ErgoChat model were more accurate than those generated by the unmodified VLM model.\nAs mentioned earlier, ErgoChat can offer early alerts of ergonomic risks and associated safety concerns encountered by construction workers. As an interactive tool, it can be used as an ergonomic risk query tool and to train construction site safety personnel who lack ergonomic risk knowledge. Since insurance companies and government occupational safety agencies both require injury reports, ErgoChat can be used to automatically generate ergonomic injury reports on construction sites. It can also assist safety personnel in fully automating risk identification and safety inspections. The ErgoChat proposed in this study is expected to play a role in identifying ergonomic risks for construction workers, thereby enhancing the well-being of workers and the safety of their work environment. Additionally, this study is anticipated to inspire further research on safety measures and VLMs to identify ergonomic risks.\nAlthough this method exhibits significant accuracy, akin to applying visual language models in other domains, it also has limitations. These limitations pertain to challenges like language hallucinations and inadequate perceptual abilities. VLMs, built upon LLMs, inherit the LLM's limitations in language hallucinations primarily due to unreliable reasoning capabilities and a lack of understanding of non-existent hallucinations. The deficiency in perceptual abilities is attributed mainly to ErgoChat's restricted visual perception capacities. Additionally, we did not attempt different prompts. Prompt engineering is a separate research field, and it is not the focus of this study. Therefore, we did not explore the impact of different prompts on the results of IC and VQA. Future research endeavors could mitigate language hallucinations by leveraging high-quality image-text pairs containing ergonomic data and refined LLMs. To address the issue of limited perceptual capabilities, it might be necessary to integrate multiple layers within the projection layer to develop a more resilient visual perception model and employ more consistently coherent datasets."}]}