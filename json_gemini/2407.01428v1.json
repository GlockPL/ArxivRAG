{"title": "Reinforcement Learning-driven Data-intensive Workflow Scheduling for Volunteer Edge-Cloud", "authors": ["Motahare Mounesan", "Mauro Lemus", "Hemanth Yeddulapalli", "Prasad Calyam", "Saptarshi Debroy"], "abstract": "In recent times, Volunteer Edge-Cloud (VEC) has gained traction as a cost-effective, community computing paradigm to support data-intensive scientific workflows. However, due to the highly distributed and heterogeneous nature of VEC resources, centralized workflow task scheduling remains a challenge. In this paper, we propose a Reinforcement Learning (RL)-driven data-intensive scientific workflow scheduling approach that takes into consideration: i) workflow requirements, ii) VEC resources' preference on workflows, and iii) diverse VEC resource policies, to ensure robust resource allocation. We formulate the long-term average performance optimization problem as a Markov Decision Process, which is solved using an event-based Asynchronous Advantage Actor-Critic based RL approach. Our extensive simulations and testbed implementations demonstrate our approach's benefits over popular baseline strategies in terms of workflow requirement satisfaction, VEC preference satisfaction, and available VEC resource utilization.", "sections": [{"title": "I. INTRODUCTION", "content": "Data-intensive scientific workflows in areas characterized by considerable on-demand resource needs and stringent security requirements (e.g., bioinformatics, high-energy physics, and healthcare), have traditionally been hosted by cloud environments, thanks to the availability of resources, advanced security protocols, and performance assurances through Service Level Agreements (SLAs) [1] offered by such environments.\nHowever, processing such data- and resource-intensive workloads at cloud scale incurs substantial costs. To address this, in recent times, \"volunteer edge-cloud\" (VEC) computing has emerged as an alternative [2], [3], harnessing distributed computing to provide cost-effective resources [4] for on-demand processing. Figure 1 illustrates an exemplary VEC environment that leverages the collective computational resources of VEC nodes (i.e., VNs) to process data-intensive workflows; thereby shifting the processing from centralized cloud infrastructures to the edge, where resources are more affordable and abundant, albeit diverse and geographically distributed.\nThese VNs can range from small devices (e.g., IoTs) to large systems (e.g., servers) that are owned and operated by individuals, laboratories, or organizations who willingly contribute them for collaborative computing.\nA central scheduler is designated to assign workflow tasks to available VNs that can satisfy workflows' quality of service (QoS) and security requirements without violating the diverse VEC resource policies.\nWhile traditional cloud environments provide theoretically unlimited resources to fulfill workflow requirements within specific SLA bounds, VNs within a VEC environment, due to their heterogeneity in terms of resource capacity, intermittent availability, and diverse usage policies, may not always guarantee strict requirement satisfaction. Additionally, VNs belonging to specific research labs/facilities within institutions/universities form isolated VEC clusters, while being part of the same VEC environment. These clusters may prefer to host specific workflows or users (generating such workflows) in their VNs due to a variety of preferential reasons, such as workflow data type, reputation of the workflow users, and history of prior collaborations between the data and resource sites. Thus, unlike in cloud environments, task scheduling in VEC environments needs to not only satisfy workflow demands, but also accommodate VNs' preferences. This is on top of optimizing task execution and efficiently managing resource scalability like any other task scheduling strategy. Most related literature within VEC ecosystem focuses on establishing trust between the resource providers and users [5], [6], while mostly using generic task scheduling. Therefore, management of workflow tasks, resource assignment, and ensuring workflow requirement satisfaction, while honoring VNs' preferences for users/workflows remain some of the central challenges for VEC resource management [7].\nUnlike traditional cloud and edge systems [8], [9], [10], [11], where resource allocation is typically formulated as an optimization problem and solved using sub-optimal heuristics, resources in VEC systems are complicated to manage, due to their highly decentralized nature and heterogeneity. A VEC environment, comprising of multitude of VEC clusters, suffer from:"}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "In this section, we present an overview of VEC environments, challenges in VEC resource management, and the current state-of-the-art and knowledge gaps."}, {"title": "A. VEC computing ecosystem", "content": "Figure 1 portrays the foundational framework of a typical VEC system, comprising of: VEC users submitting workflows with specific requirements, a centralized scheduler tasked with assigning the workflow tasks to VNs, and VNs belonging to VEC clusters with their local job queue and user/workflow preferences.\nThe users, i.e., scientists and researchers, strive to efficiently and affordably execute data-intensive workflows through on-demand computational resources delivered via a VEC service, often handled by a cloud-native, centralized task scheduler. The scheduler\norchestrates intricate logic to align submitted workflow requirements with the best-fit resources from the available VNs. On the other hand, the VNs or the clusters the VNs belong to, suggest user/workflow preferences that the scheduler tries to accommodate when assigning workflow tasks.\nThe VNs encompass a diverse range of hardware, spanning from rack servers to desktops, and from laptops to GPU acceler-ators with varied computational capabilities. The specific hardware configuration of VNs is contingent upon the contributions made by individual researcher labs/institutions that act as volunteers, donating their equipment when not in use. Consequently, the VEC ecosystem embraces a heterogeneous collection of resources, accommodating the availability and capabilities of participating volunteers' hardware. This flexible and decentralized nature of VNs enable the ecosystem to leverage a wide array of computational resources, fostering a collaborative and distributed environment for data-intensive scientific workflow execution."}, {"title": "B. Resources management in VEC environments", "content": "Various mechanisms are proposed to address the scheduling challenges of heterogeneous VEC environments. Maheshwari et al. [18] propose a hybrid edge cloud model that supports latency-sensitive applications in urban areas, optimizing resource provisioning as per requirements. Galletta et al. [19] introduce the CESIO architecture, enhancing video content delivery quality within the same edge. Funai et al. [20] suggest an ad-hoc model where devices with internet access act as local task distribution points (TDPs), inviting other users to participate. Mengistu et al. [21], [7] leverage idle home IoT devices to expand the volunteer resource pool. Inspired by these concepts, Ali et al. [22] propose a fog-cloud based task distribution layer, bringing cloud services closer to end users through fog nodes. Sebastio et al. [23] present a holistic volunteer cloud model that employs Ant Colony Optimization (ACO) to optimize task-resource assignments. Pandey et al. [5] propose a trust-based mechanism for allocating computational resources. Alarcon et al. [6] and Rodrigues et al. [24] use Particle Swarm Optimization (PSO) to dynamically assign users to volunteer resources.\nUnlike these existing works, we take a holistic approach that performs long-term joint optimization of workflow requirements and VN preferences, while considering VN resource policies and long-term trust, using a black-box approach which is more practical, yet challenging to solve."}, {"title": "C. RL for distributed resource management", "content": "Reinforcement Learning (RL), particularly the Actor-Critic method, shows great promise in enhancing resource allocation, task scheduling, and overall system performance, especially in dynamic and black-box environments like VEC computing. Fu et al. [25] propose an innovative Actor-Critic mechanism to manage offloading decisions and resource allocation in Mobile Edge Computing (MEC) environments. Similarly, Wei et al. [26] focus on optimizing user scheduling and resource allocation in heterogeneous mobile networks using a policy-gradient-based Actor-Critic approach. Shah et al. [27] address network utility maximization in massive IoT environments by proposing a hierarchical deep Actor-Critic model for network management and resource allocation.\nAdditionally, Chen et al. [28] introduce an Actor-Critic method-based framework to optimize resource allocation in cloud data centers, targeting improved job execution latency and resource utilization. Meanwhile, Tathe et al. [29] focus on down-link Transmission for Long Term Evaluation Advanced (LTE-A) radio resource allocation, proposing an Actor-Critic based architecture to maintain QoS and user fairness amidst dynamic scheduling challenges. These collective results demonstrate the"}, {"title": "III. SYSTEM MODEL AND PROBLEM FORMULATION", "content": "In this section, we describe the system model and formulate the optimization problem."}, {"title": "A. System model", "content": "The main components of our VEC system are as follows:\nWorkflows and tasks: We define a set of m workflows $W = \\{W_a, W_b, ..., W_m\\}$ that uses the VEC environment. An instance of a workflow is referred to as a task. Each task is a sextuple (w, data, time, userID,QSpecs, SSpecs) representing the workflow, input data, submission time, user ID of the task submitter, QoS requirements, and security requirements of the specific task within the workflow, respectively. QSpecs is a formalized and quantifiable way of representing a workflow task's desired performance requirements that includes QoS metrics, such as throughput, latency, and response time. Whereas, SSpecs specifies a task's security requirements across certain (say F) security factors, as recommended by NIST SP 800E guidelines [30], [14]. The level of each of these factors is set as High/Moderate/Low based on the NIST guidelines. Both QSpecs and SSpecs concepts are borrowed from the seminal work by Dickinson et al. [14], while the process of generating QSpecs and SSpecs for data-intensive workflow tasks can be found in [31].\nVEC cluster: The VEC environment is composed of a collection of C clusters denoted as $C = \\{VEC_1,...,VEC_{|c|}\\}$, where each cluster consists of a varying number of VNs. From the perspective of the scheduler, VNs are considered as individual entities that operate independently. Thus, in the formulation and management of tasks, we consider VNs as distinct entities, each with its own characteristics and specifications.\nVEC nodes (VNs): We define a set of N VNs $V = \\{VN_1, VN_2, ..., VN_N\\}$ in the environment. Each $VN \\in V$ is another sextuple (deviceID, RSpecs, P, config, T, Q)\nrepresenting VN's identification number, resource specification, preference list, configuration, trust, and local queue, respectively. The resource specifications, denoted as RSpecs, define a set of factors that describe the security posture and usage policies of a VN, also adopted from [14]. Additionally, the preference list P is an ordered list of p workflow users. As described earlier, the preferences can be based on a variety of factors, such as, workflow data type, reputation of the workflow users, and history of prior collaborations between the data and resource sites. The VNs exhibit heterogeneous configurations, yet VNs within the same cluster share common specifications in terms of guaranteed security measures and policies as well as a preference list. Furthermore, we consider a local job queue of maximum size $\\Gamma_j$ for each $VN_j$.\nTrust: The trustworthiness of a $VN_j$ is denoted by a quantifiable trust metric $T_j$ and is defined as the level of consistency the VNs exhibit over time in terms of performance, agility, cost, and security (PACS) factors, as defined in [5]. Given the voluntary nature of VEC resources, the VEC clusters may incidentally modify configurations, such as adjusting capacity or availability, or change security settings. Consequently, consistent provisioning of resources and configurations becomes indicative of reliable VNs.\nTask assignment: Depending on the the task requirements and VN availability, a task maybe accepted and assigned to a VN or rejected. We use the symbol NULL to represent rejection of a task. Let g denote the assignment function that maps tasks into the elements of $V\\cup \\{NULL\\}$:"}, {"title": "B. Task satisfaction score", "content": "The task satisfaction score measures the alignment of task's QSpecs and SSpecs with the resource configuration and RSpecs of the assigned VN, respectively. It has two parts:\n\u2022 QoS satisfaction score: The QoS satisfaction score, i.e., QSpecsS measures the alignment of task QSpecs with the estimated performance that VNj offers. Let WT and Exe represent the estimated waiting time in the queue and estimated execution time of VNj, respectively. Here, WT in VN's queue (Q) is sum of the execution times of all the existing jobs in the queue. Thus,\n$W_{T(VN_j)} = \\sum_{i=0}^{Q_j} Exe(task_i, VN_j)$"}, {"title": "C. VN preference satisfaction score", "content": "The VN preference satisfaction score, denoted by VNS, is described as a function of an assigned users' rank in the VN's preference list. Specifically, we define VNS as a logarithmic function of taski's rank in Pj (denoted by rank(taski, Pj))."}, {"title": "D. Overall satisfaction score", "content": "The overall satisfaction score S of a task assignment to a VN is a function of TS, VNS, and trust T of the VN at the time of assignment. Thus:"}, {"title": "E. Formulating the optimization problem", "content": "We formulate the following optimization problem with the objective of jointly maximizing the average overall satisfaction score of the assignment strategy (over long-term), subject to the capacity of VNs' local queues and the hard-security requirement constraints explained earlier:"}, {"title": "IV. ASYNCHRONOUS REINFORCEMENT LEARNING", "content": "Here, we reframe the optimization problem as a Markov Decision Process (MDP) as it perfectly captures the dynamism of the VEC environment and introduces an event-based decision-making approach grounded in asynchronous deep reinforcement learning in order to solve the problem. More precisely, we utilize Asynchronous Advantage Actor-Critic (A3C) [32] architecture to implement our scheduler strategy. This strategy is purposefully crafted to optimize the long-term average performance, as articulated in Eq. (10). We deploy parallel agents to learn an environment characterized by a finite set of states denoted as S and a finite set of actions denoted as A. Next, we describe our A3C approach."}, {"title": "A. Learning agents for the scheduler", "content": "The combination of task information and task load within VNs' queues encapsulates a comprehensive representation of the system's state, fully discernible by our scheduler agent. This state encapsulates the specifics of the current task, as well as the status of local queues.\nStates: Let S denote the state space of the environment (i.e., our scheduler agent). The state of our scheduler agent at time t, denoted by s(t) \u2208 S, captures the particulars of the current submitted task taski, including the task associated workflow (wi), data (data), and userID (userIDi). Additionally, it consists of information about the VN's local queue status in relation to its respective load. For quantization, we consider four categories for a VN queue load based on the queue utilization: Low (L), Medium (M), High (H), and Full (F). We define queue utilization as the ratio of the number of tasks in the queue (|Q|) over the queue capacity (\u0393\u2081) of the VNj, and define the state of the VNj queue load at time t by:"}, {"title": "B. A3C network architecture and algorithm", "content": "As shown in Fig. 2, our A3C [32] architecture comprises of two components: the actor network and the critic network. The actor network learns a policy that guides scheduler action selection, while the critic assesses the value of states, offering feedback for policy enhancement. A3C employs a parallelized approach by deploying multiple worker agents simultaneously, each operating within its own independent environment. This strategy fosters a diverse training experience and accelerates the learning process, particularly beneficial when handling larger observation spaces, such as ours as encountered when the number of VNs increases.\nWe design an offline learning algorithm (as shown in Algo. 1) for A3C driven task scheduling. In the initialization phase, the agents build actor and critic networks with random weights. Then the scheduler agent continuously interacts with the current environment and makes assignment decisions after each task submission. At the end of each episode, both actor and critic networks' weights are updated with a batch of experienced transitions. Our network is structured with a basic architecture, consisting of two fully connected layers, each with a feature size of 512 and 256, respectively. We've open-sourced the study's source code on GitHub [33]."}, {"title": "V. EVALUATION", "content": "In this section, we evaluate the performance of our proposed task scheduling approach through an extensive simulation, followed by a testbed implementation on Nautilus Kubernetes cloud platform [17]."}, {"title": "A. Simulation environment", "content": "We begin by outlining the workflows used, their requirements, and the VEC environment.\n\u2022 Workflows: In this work, we choose two high-throughput and typically cloud-native bioinformatics data analysis workflows in the SoyKB [15] science gateway developed for soybean and other related organisms.\nThe complex PGen workflow is used to efficiently facilitate analysis of large-scale next generation sequencing (NGS) data for genomic variations. We also use a comparatively simpler RNA-Seq analysis workflow that is used to perform quantization of gene expression from transcriptomics data and statistical analysis to discover differential expressed gen/isoform between experimental groups/conditions. Given the frequency at which they are run (typically once or twice a week per user) and the total cost incurred for cloud adoption, they are ideal for VEC migration and an event-based task scheduling approach, such as ours. We also generate two synthetic workflows in order to add diversity and scale to our workflow pool. Overall, the combined workflow tasks arrival rate to the task scheduler follows classic Poisson distribution.\n\u2022 SSpecs: The details of the SSpecs of PGen and RNASeq workflows are explained in [31]. SSpecs for the synthetic workflows are simulated to add diversity to the SSpecs pool. For this work, we only use 5 out of 18 security factors (as recommended by NIST) as they are the most relevant for VEC environments. These include: Access Control (AC), Security Assessment and Authorization (CA), Identification and Authorization (IA), System and Communication Protection (SC), and System and information Integrity (SI). The SSpecs details are listed in Table I.\n\u2022 QSpecs: Due to the scale-down of workflow datasize to fit the simulation scenario, simulated QSpecs differ from real QSpecs described in [31]. The determination of QSpec for a workflow task involves assessing the average execution time when running that workflow with a specific data size on one of the standardized configuration. Additionally, we estimate the projected execution time of a task on a VN by analyzing data acquired from executing the same workflow with different data sizes within that specific configuration."}, {"title": "B. Simulation results", "content": "Below, we discuss different aspects of the simulation results.\nRequirement satisfaction: In Fig. 3, we first show how our A3C based RL approach performs in terms of satisfying task QoS and security requirements, and VN preference requirements, for different task arrival rates (\u03bb). We observe that both QSpecs and SSpecs satisfaction performance is close to 100% for lower job arrival rates. However, at very high \u03bb, workflow satisfaction goes down due to high competition among workflows for limited VNs. Overall, we can observe that our proposed RL-driven task scheduling ensures requirement satisfaction, for more than 50% of the workflows. Fig. 4 shows requirement satisfaction performance against varying number of available VNs. We observe that both QSpecs and SSpecs satisfaction improve with more VNs in the environment as with more VNs, the probability of finding VNs with the right RSpecs to match workflow requirements increases. It is interesting to observe that the synthetic workflows have higher probabilities of requirement satisfaction than PGen and RNASeq as the latter ones have stricter SSpecs to satisfy.\nAverage utilization: In Fig. 5, we seek to ascertain the performance of our proposed approach in terms of average utilization of available VNs across the VEC environment. Figs. 5(a) and (b) show the percentage of different levels of utilization of two specific VNs (characterized by their RSpecs) for the entire duration of the simulation. Fig. 5(a) shows a VN with RSpecs1 which has the lowest average utilization over the simulation period. The figure shows that even for the most under-utilized VN, the job queue is more than 50% full (i.e., with at least 2 jobs) for more than half the time. The utilization performance is even more impressive for the VN which is most utilized (i.e., VN with with RSpecs6), as shown in Fig. 5(b).\nThe average performance of all VNs (with all Rspecs) for different job arrival rates (i.e., \u03bb) is shown in Fig. 5(c) which shows that even with lower \u03bb, many VNs are more than 50% full for more than 50% of the time.\nSatisfaction comparison: Next in Fig. 6, we compare our proposed approach (i.e., \u2018RL') against two of the baseline approaches (i.e., 'Random' and 'VECFlex') in terms of task requirement satisfaction. Overall, the comparisons are carried out by running"}, {"title": "C. Testbed implementation and results", "content": "We implement our RL-driven scheduling solution on a VEC environment testbed, built on the Nautilus Kubernetes cloud platform [17], a specialized platform optimized for cloud-native applications and orchestrated containerized processes. The core components of the system consist of the proposed scheduler and the VEC environment. The scheduler, featuring a robust backend, integrates a database system and a dedicated service for efficient task scheduling. It is hosted on containers created from the golang:1.20 Docker image [34]. Communication occurs over ports 8080 and 3306 for backend and database services, respectively. The VNs, are constructed using the latest Go Docker image and are equipped with a suite of bioinformatics tools and software, capable of running RNASeq workflow."}, {"title": "VI. CONCLUSIONS", "content": "In this paper, we introduced an A3C based RL-driven approach to data-intensive workflow task scheduling for VEC environments. We showed how our solution not only considered workflow QoS and security requirements, but also took into account diverse VEC resource policies dictated by various clusters (i.e., universities/labs/institutions) and their user/workflow preferences. Using extensive simulations and testbed implementation, we demonstrated how our proposed solution performed significantly better than other baseline strategies in terms of requirement satisfaction, task rejection rate, and available VN utilization."}]}