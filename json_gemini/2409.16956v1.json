{"title": "Informed deep hierarchical classification: a non-standard analysis inspired approach", "authors": ["Lorenzo Fiaschi", "Marco Cococcionia"], "abstract": "This work proposes a novel approach to the deep hierarchical classification task, i.e., the problem of classifying data according to multiple labels organized in a rigid parent-child structure. It consists in a multi-output deep neural network equipped with specific projection operators placed before each output layer. The design of such an architecture, called lexicographic hybrid deep neural network (LH-DNN), has been possible by combining tools from different and quite distant research fields: lexicographic multi-objective optimization, non-standard analysis, and deep learning. To assess the efficacy of the approach, the resulting network is compared against the B-CNN, a convolutional neural network tailored for hierarchical classification tasks, on the CIFAR10, CIFAR100 (where it has been originally and recently proposed before being adopted and tuned for multiple real-world applications) and Fashion-MNIST benchmarks. Evidence states that an LH-DNN can achieve comparable if not superior performance, especially in the learning of the hierarchical relations, in the face of a drastic reduction of the learning parameters, training epochs, and computational time, without the need for ad-hoc loss functions weighting values.", "sections": [{"title": "1. Introduction", "content": "Hierarchical classification (HC) is a challenging machine learning problem where data are supposed to be classified by assigning them a set of labels arranged according to a hierarchy. According to the taxonomy proposed by Silla and Freitas (2011), HC problems can be represented by a triple (\u03a5, \u03a8, \u03a6) where Y specifies the type of graph representing the hierarchy, \u03a8 indicates whether a data instance is allowed to have class labels associated with single or multiple paths in the class hierarchy, and I describes the label depth of the data instance. The present work focuses on triplets of the form (T, S, F), that is HC problems where labels are organized according to a tree-like structure (T), each data point is associated with one single path through the hierarchy (S), and each path travels the full depth of the tree (F). The use of more general HC configurations is currently under investigation.\nHC naturally arises in many applications of interest: Lewis et al. (2004); Peng et al. (2018); Rousu et al. (2006) applied it to text categorization, Deng et al. (2009); Mendon\u00e7a et al. (2021); Taoufiq et al. (2020) to image recognition and segmentation, Murtaza et al. (2020); Xie and Xing (2018) to medicine, Dimitrovski et al. (2012); Mahmood et al. (2020)"}, {"title": "2. Non-standard analysis and the Alpha theory", "content": "Non-standard analysis is a branch of mathematical logic aiming at developing models of analysis where infinite and infinitesimal numbers are allowed along with the more common finite, real ones. Anticipated by numerous debates in ancient Greece and pioneered by the infinitesimal calculus of Leibniz and Newton, the first rigorous non-standard model of analysis saw the light of day in the \u201860s with the book \u201cNon-standard Analysis\" by Robinson (1966). From that moment on, several alternatives have been proposed, each with its own upsides and downsides. Among them, one relevant to the present work is the \u201cAlpha theory\" by Benci and Di Nasso (2018), which introduces the non-standard model of analysis through a very lightweight and logic-free axiomatization. There are two reasons for which such a"}, {"title": "Theorem.", "content": "E\u2283 R is a field, a \u2208 \u0395.\nThe theorem states that E contains other numbers than the real ones, e.g., a and n := a\u00af\u00b9. Since R contains all and only the finite numbers, the remaining numbers must be infinite and infinitesimal. The next three definitions formally state when a number can be addressed as finite, infinite, or infinitesimal."}, {"title": "Definition (Infinite number).", "content": "x \u2208 E is infinite$\\Leftrightarrow$ #k\u2208 N such that k > |x|."}, {"title": "Definition (Finite number).", "content": "x \u2208 E is finite$\\Leftrightarrow$\u2203k \u2208 N such that k > |x| > $\\frac{1}{k}$."}, {"title": "Definition (Infinitesimal number).", "content": "x \u2208 E is infinitesimal$\\Leftrightarrow$ #k\u2208N such that |x| > $\\frac{1}{k}$."}, {"title": "Theorem 1.", "content": "Any function f : R \u2192 R can be coherently and uniquely extended to a function *f: E \u2192 E such that * f(x) = f(x) \u2200x \u2208 R.\nThe fact that the previous theorem holds is necessary to state the next one without ambiguities. Its role is to characterize the elements in E, that is to explicit what are the non-standard numbers which can be used within the Alpha theory.\nTheorem. The numbers in E are all and only the values at the point a of all the real functions extended to E."}, {"title": null, "content": "With the purpose of an example and according to the last theorem, the following values belong to E\n$\\frac{\\alpha}{2}$+ \u03b7,\n3 \u2013 \u03b7\u00b2,\n$\\frac{\\alpha\u00b2 + \u03b1\u00b2 + \u03b7\u00b2}{-3+5e\u03b7}$,\nand the following relations hold\n\u03b1. (2\u03b1 \u2013 3) = 2a\u00b2 \u2013 3\u03b1,\n0 < n < a\u00b0 = 1 < a < a + 1,\n$\\frac{8.06a\u00b2 + 4.28 \u2013 2.08\u03b7\u00b3}{6.2a\u00b2 + 5.2}$ = 1.3 + 0.4\u03b7\u00b3."}, {"title": "Definition (Monosemium).", "content": "Any value \u00a7 = rak \u2208 E, r, k \u2208 R, is called monosemium"}, {"title": "Corollary.", "content": "\u03be\u03b5\u0395 \u2203{ri}\u221ei=1, ri \u2208 R Vi and \u2203{ki}\u221ei=1, ki \u2208 R Vi, ki > kj \u2200i > j, such that\n\u0664 = \u2211\u221ei=1riak\u1d62."}, {"title": null, "content": "The next theorem is fundamental in any non-standard model of analysis: informally, it guarantees that all the \u201celementary properties\u201d that are true for certain mathematical objects in the standard model, say R, are also true for their non-standard counterparts in the non-standard model, say E, and vice-versa. Again, the reader is pointed to Benci and Di Nasso (2018) for a rigorous statement of the theorem and a proper definition of elementary property, which would have provided a tedious and unnecessary complex presentation of non-standard analysis."}, {"title": "Theorem 2 (Transfer principle).", "content": "An \u201celementary property\u201d o is satisfied by mathematical objects 41,..., Ok if and only if o is satisfied by their non-standard extensions *1,...,*\u03c6k:\n\u03c3(\u03c61,..., \u03c6\u03ba)\u21d4 \u03c3(*\u00a21,...,*\u03c6k).\nFinally, Fiaschi and Cococcioni (2022) proved a theorem of equivalence between any standard lexicographic multi-objective optimization problem (LMOP) and a non-standard scalar program. Informally, an LMOP is a problem where multiple functions are meant to be optimized but there exists a strict priority ordering among them. Below, it is reported the formal definition."}, {"title": "Definition (Lexicographic optimization problem).", "content": "Let f1,..., fn be real function and there exists a strict priority ordering among them induced by the natural ordering. Then, the following sequence of programs constitutes a lexicographic optimization problem:\nmin f1(x)\ns.t. \u03a7\u0395\u03a9\nmin\nfi(x)\ns.t.\nf(x) = f; \u2200j = 1, ..., i-1,\n\u03a7\u0395\u03a9\nwhere f; is the optimal value found for f; in the previous optimization problems."}, {"title": "Theorem 3.", "content": "Consider a LMOP whose objective functions f1,..., fn are real functions and the priority is induced by the natural order. Then, there exists an equivalent scalar program over the same domain, whose objective function is non-standard and has the following form:\nf(x) = \u03b21f1(x) + ... + \u03b2nfn(x),\nwhere \u03b21,..., \u03b2\u03b7 are non-standard values such that $\\frac{Bi+1}{Bi}$ \u2248 0 (i.e., is infinitesimal), i =\n1,..., n-1.\nBefore concluding, it is worth mentioning that where no ambiguities subsist, the prescript * is omitted for the sake of readability. An example is the expected value function in Equation (4)."}, {"title": "3. Hierarchical Classification and Branch Neural Networks", "content": "In order to list the most modern and effective approaches present in the rich and everyday- growing literature on HC, which saw numerous innovative research activities in the last 15 years thanks to the advent of deep learning, it is worth recalling the algorithms categorization introduced, again, by Silla and Freitas (2011). Each HC algorithm can be classified according to a four-tuple (\u03a5, \u03a8, \u03a6, \u0398), where the first three entries have the same meaning as before, while the fourth parameter, \u04e8, indicates how the topological information of the class relationships is managed and used. According to it, HC algorithms can be split into four families: local classifiers per node, local classifiers per level, local classifiers per parent node, and global classifiers. In general, global approaches are usually cheaper than local ones, and they do not suffer from error-propagation issues at inference time, though they are less likely to capture local information from the hierarchy, risking underfitting. Local approaches are much more computationally expensive since they rely on a cascade of classifiers, but they are much more suitable for extracting information from regions of the class hierarchy, risking overfitting.\nLocal classifiers per node are HC algorithms constituted of multiple binary classifiers meant to discern whether or not a certain data point belongs to one specific class in the hierarchy. An example is the model HMC-MLPN by Feng et al. (2018), where the authors implement a separate fully connected DNN for each label. Since this approach scales poorly with respect to the number of labels and structurally suffers from class instances imbalance, it is rarely used in practice.\nLocal classifiers per parent node approaches train one classifier for each splitting node of the hierarchy, i.e., each parent node. HC algorithms of this family, as those by Kowsari et al. (2017) for texts or Kulmanov et al. (2018) for gene ontologies, categorize data points feeding them to the various classifiers in cascade, starting from the root of the hierarchy and following the path induced by the predictions at each node. Even if more common than the previous ones, local classifiers per parent node still struggle in scaling with respect to the number of labels, limiting their usability.\nLocal classifiers per level are HC algorithms constituted of a very limited number of classifiers: one for each level of the hierarchy. The possibility to scale better with the number of labels and the absence of imbalance-inducing properties allowed this approach to become by far the most popular strategy to deal with HC problems locally. Among the notable works,"}, {"title": "3.1. Branching Networks", "content": "Branching networks (B-DNNs) are DNNs meant to output multiple predictions possessing a certain logical order, e.g., a priority among them. The original and main application that saw their use concerns HC problems, where each prediction is dedicated to a specific level of the hierarchy. To facilitate the presentation, Figure 1 reports an illustrative description of a B-DNN for a three-level HC problem."}, {"title": "4. Lexicographic Hybrid DNNs: hierarchical classification from a non-standard perspective", "content": "The errors made at each level of the hierarchy are gathered in one single value through a convex combination having time-dependent scalarization weights. With reference to Figure 1, the sub-network hi is specialized for the i-th level classification, and the error made by it is scaled by a factor wi before being summed with the other losses.\nThe reason for the time-varying scalarization is the will to mimic hierarchical learning during the network training. The weights are initialized with the triple (w1, W2, W3) = [1,0,0], and smoothly shifted towards [0, 0, 1] passing through a configuration where w\u2082 is significantly larger than the others. In this way, the network starts learning the coarser classification task and gradually takes into consideration the other levels too, preserving their order in the hierarchy. Moreover, the training of the feature extraction process manifests a similar behavior. In the beginning, only the early shared weights (s\u2081 in Figure 1) are optimized: the goal of such learning is to extract useful features for the coarser classification. While the importance of lower hierarchy levels grows, also the other shared weights (S2) start to be optimized. Since they follow already trained parameters, it is like they are modified to improve the feature extraction from an already existing but coarser knowledge."}, {"title": "4.1. Hierarchical classification as a lexicographic problem", "content": "The first step towards an NSA-inspired DNN requires the reformulation of an HC problem into an LMOP. Generally speaking, an HC problem can be seen as the minimization problem in Equation (1)\nmin\n\u03b8\nE[L(f(0;x), Y, Y)]\ns.t. (x, Y) ~ D\n(1)\nwhere the expected value of a certain loss function L(\u00b7) is meant to be minimized by adjusting the free parameters \u03b8 of a classification map f, e.g., a DNN, considering the data x, its set-labels Y, and the hierarchy structure \u03a5. As anticipated, the work focuses on tree-like hierarchies, i.e., \u03a5 = T, and so each set-label possesses a well-defined structure Y = (y1, \u2026\u2026\u2026, Yn), where yi indicates the label of i-th level of the hierarchy for the data point, and such that there exists a parent-child relation between labels yi and Yi+1\u00b7\nEmbedding and leveraging the hierarchy structure Y in the learning of the parameters \u03b8 is crucial for the design of a well-performing classifier. Hybrid approaches combining local and global losses, e.g., B-DNNs seem to more or less implicitly suggest training the classifier parameters prioritizing the performance on the coarser levels of the tree. The main benefit consists of a classifier learning inner representations of the data that are not only discriminant for the categorization at the higher levels of the hierarchy but also helpful for discerning at lower ones, as a sort of knowledge propagation typical of human reasoning. However, explicit reasoning in terms of priorities has never been elaborated in literature, and its introduction would turn the HC problem into an LMOP of the form as in Equation (2):\nlexmin E[L(f1(0; x), y1)], . . ., E[L(fn(0; x), yn)]\n\u03b8\ns.t.\n(x, Y1,..., Yn) ~ D\n(2)"}, {"title": null, "content": "where fi refers to the part of the global classifier f dedicated to the i-th hierarchy level.\nLexicographic optimization in the presence of a single, potentially multi-head, DNN is still heavily under-explored. One of the most relevant approaches is proposed by Kissel et al. (2020) and consists of projecting the side-optimization goals gradient in the null space of the batch activations. Tercan (2022) proposed an analogous idea in the context of reinforcement learning. Even if effective, such techniques do not scale with the network dimensions, drastically undermining the time performance and their usability in applications.\nA domain closely related to lexicographic optimization is the long-studied constrained optimization (Martins and Ning, 2021), for which a large number of (not necessarily deep learning) techniques have been proposed: from penalty methods to sequential programming, from duality-based approaches to feasible directions method (Gong and Liu, 2021). Nevertheless, none of them properly suits a general purpose LMOP as they may lack rigorous respect of the priorities, as for the penalization methods, or are not designed for non-convex problems, as Lagrange multiplier and primal-dual methods (Bertsekas, 2014). On the contrary, a theoretically compliant and efficiently implementable approach is the bi-objective gradient descent algorithm proposed by Gong and Liu (2021), whose main limitation is the possibility of coping with up to two levels of priority."}, {"title": "4.2. From lexicographic to non-standard deep learning", "content": "To proceed toward non-standard deep learning, one needs to rewrite (2) as\nmin E[C(0, x, Y)]\n\u03b8\n(3)\ns.t. (X, Y1, ..., Yn) ~ D\nwhere L is an ad-hoc non-standard function defined according to Proposition 1. Such a result suggests an alternative approach to HC problems: a non-standard one."}, {"title": "Proposition 1.", "content": "There exists a non-standard function L for which problems (2) and (3) are equivalent."}, {"title": "Proof.", "content": "Theorem 3 guarantees that (2) can be equivalently rewritten in the form\nmin E[L(fi(0; x), Yi)]n\u00b2\u00af\u00b9\n\u03b8\ni=1\ns.t. (x, Y1, ..., Yn) ~ D\n(4)\nBy linearity of the (non-standard) expected value, (4) is equivalent to\nmin E L(fi(0; x), yi)n\u00b2-1\n\u03b8\n\u03a3\ni=1\ns.t. (x, Y1,..., Yn) ~ D\n(5)\nEach function f; in (5) is parametrized according to weights @ that can be split in three disjoint sets: 0s, i.e., parameters shared with the other fj, j \u2260 i; 0\u2081, i.e., parameters contributing to fi only; \u03b8\u00aci, i.e., parameters not contributing to f; at all. This allows the rewriting of"}, {"title": null, "content": "fi as the composition of two functions, gi and gs, only depending on parameters \u03b8i and \u03b8\u03c2, respectively:\nfi(0; x) = gi(0i, gs(0s;x)) \u2200i = 1, ..., n.\nAccording to the universal approximation theorem (Haykin, 1998; Hornik et al., 1989), gs can be chosen sufficiently complex to guarantee that any g\u2081 is linear, i.e.,\nfi(0; x) = (\u03b8i, gs(0s; x)) \u2200i = 1, . . ., n.1\nSubstituting Equation (6) into (5), one gets\nmin EC((\u03b8i, gs (0s; x)), Yi)n\u00b2-1\n\u03b8\ni=1\ns.t. (x, Y1, ..., Yn) ~ D\nDefining Las the following non-standard function\n\u2211(\u03b8, x, Y) := \u2211L((0i, gs (0s; x)), Yi)n\u00b2\u00af\u00b9\ni=1\ncompletes the proof."}, {"title": null, "content": "The DNN induced by (8) is non-standard but depends on standard weights, from here the name Hybrid in LH-DNN. The network can be drawn as in Figure 2, where the green blocks represent the standard and non-standard sections of the LH-DNN, the orange block identifies the computation of the non-standard loss function, the light blue one is the input data. Figure 2 also allows one to evince some topology-induced properties. The learning can be split into two phases, provided by two different partitions of the network: the left- most part, from the input to the hidden layer z, and the right-most part, from z to the computation of the errors L(\u00b7, y\u2081)n\u00b2\u00af\u00b9. The first phase can be seen as a feature learning from raw input data, a process that must necessarily be in common with the classification at each level of the hierarchy. The second phase represents the per-layer categorization and consists of multiple independent learning flaws originating from the common hidden representation z of the sample x to classify."}, {"title": "4.3. Implementation", "content": "The transfer principle (Theorem 2) guarantees that an H-DNN can be trained by back- propagation. In particular, the gradient VoL is non-standard and such that the level-related parameters \u03b8i, i = 1, ..., n, are adjusted independently from the performance on the other levels, while the shared parameters \u03b8s are adapted considering the overall categorization quality, with the losses of higher hierarchical levels having an impact infinitely larger than those of lower ones. This phenomenon induces learning where parameters 0; specialize for"}, {"title": null, "content": "\u01771\n\u2192 (01,.)\n\u2192\n2\nYi\nX\n\u2192 gs(0s; \u00b7)\n\u2192 (\u03b8\u03b5,\u00b7)\nL(, Y1)\n:\n\u2192L(, Yi)n\u00b2-1\n\u0177n\n\u2192 \u3008\u03b8\u03b7,\u00b7)\nn\nL(, Yn)nn-1"}, {"title": null, "content": "the specific level-oriented classification task, while parameters 05 adapt to provide the most informative data inner representation, prioritizing their usefulness for coarser categorizations. This behavior is perfectly aligned with human hierarchical learning, where the feature extraction for a correct classification at the first levels is fundamental and preparatory for finer discrimination, which contributes to the learning by refining such an already effective process of feature retrieval.\nHowever, the fact that the loss function gradient VoL is non-standard raises concerns about its naive use to update the network parameters, as it is in contrast with 3 that guar- antees the problems equivalence, i.e., the non-standard rewriting of the problem if and only if the domain, i.e., the parameters are standard values. Even if workarounds can be im- plemented for the level-oriented part of the network, as discussed later, this issue might be non-trivial for the shared part, suggesting that a more sophisticated way to propagate the non-standard gradient is needed. More formally, there is the need to extrapolate standard improving direction from non-standard ones.\nConcerning parameters \u03b8\u017c, the issue can be easily solved by leveraging the common tech- nique of using a different learning rate for each gradient VoL. Indeed, by construction, it holds\ni-1\nVoL = VoLn1,\nwhich implies that VoL is a vector whose entries are single monosemia. Thus, using a learning rate X, for the parameters \u03b8\u2081 of the form \u5165\u2081 := \u03bb\u03b1\u00bf\u00af\u00b9, \u03bb\u2081 \u2208 R+, guarantees that the first order update rule\n\u03b8\u03b5 \u03b8\u2081 \u2013 XiVo L = \u03b8\u2081 \u2013 dia\u00b2\u00af\u00b9\u2207o\u2081Ln\u00b2\u22121 = 0; \u2212 1\u00bf\u22070;L\n\u03b8\u03b5\n\u2212\n\u03b8\u03b5"}, {"title": null, "content": "preserves the parameters' property of being standard without altering the optimization di- rection.\nUnfortunately, such an approach cannot be used for parameters \u03b85, as the gradient VoL is not constituted of single monosemia. Two trivial alternatives that might come to mind are i) the backpropagation of only the standard part of the gradient, as it is at most finite; ii) the use of different (infinite) learning rates for each monosemium of the gradient, so as to turn it into a standard one. Both proposals suffer from severe flaws that are highlighted in the next lines.\nThe first approach allows only the loss on the higher level of the hierarchy to backprop- agate through the shared part of the network, as it corresponds to the finite part of the gradient. Such a choice can only have detrimental effects on the overall learning, as no infor- mation about finer labels, which are typically the most relevant ones for application purposes, is used to adjust the hidden data representation. Thus, it would be equivalent to turning the categorization problem of the labels in lower levels of the hierarchy into the transfer of the already learned parameters 05 and the tuning of the free parameters \u03b8i, i = 2,...,n. Referring to Figure 2, it would be like n separate optimization taking place in cascade, where at the beginning only parameters \u03b8s and 0\u2081 are optimized, then only 02, then 03 and so on, keeping all the other fixed.\nSk\nThe second approach is explicitly in contrast with the transfer principle, which guarantees the usability and efficacy of the backpropagation to train the network only if one single learning rate is used to update each scalar parameter Ost. Intuitively, the second solution proposes, instead, to \u201cpromoting\" the infinitesimal gradients at the \u201cimportance\u201d of the finite one, altering the priority among the per-level losses and making the per-level learning conflict with each other, as in any common standard scalarization approach. Formally, assuming to use as learning rate for the i-th monosemium \u5165\u2081 = \u03bb\u03b1\u00b2\u00af\u00b9, the parameters update rule would become\nOsk \u2013 \u03a3\u03bb\u03af\u03b8sk L = Osk \u2013 \u03bb\u03b1 \u03a3 \u03b1\u00b2\u00af\u00b9\u03b8sk Lin-1 = Osk \u2013 \u03bb \u03a3\u03b8sk Lin-1\ni=1\nOsk\nn\ni=1\nn\ni=1\nwhich coincides with the one where the naive sum of the error at all levels of the hierarchy constitutes the loss function.\nA more principled approach seems to be suggested by the results of Fiaschi and Cococcioni (2022), where a non-standard interior point method for lexicographic problems has been proposed and implemented. The following theorem resumes it."}, {"title": "Theorem 4.", "content": "Let f1, f2: Rn \u2192 R, f1, f2 \u2208 C\u00b9(Rn), and f: Rn \u2192 E be defined as f(x) :=\nf1(x) + f2(x)\u03b7. Let also x \u2208 R\u201d be a local minimum for f\u0131 but not for f2. Then, given any arbitrary small x \u2208 R+, \u2207xf|z identifies a standard improving direction for f at x if and only if\nf(-xaf2) = f(x).\nProof. According to the transfer principle (Theorem 2), the non-standard gradient is a linear operator, and so it holds\n$\\nabla_xf|_x = \\nabla_x f_1|_x + \\nabla_x f_2|_x \\eta = \\nabla_x f_2|_x \\eta$"}, {"title": null, "content": "since \u2207xf1 = 0 as I is a local minimum for f\u2081 by hypothesis. However, by definition, \u25bdxf\u2208 En, which means that it is a non-standard improving direction for f at x, i.e., it is an improving direction for the function\nf: En \u2192 E, f(x) = *f1(x)+*f2(x)n.\nA standard direction parallel to it is \u2207xf2|\u5143, for instance, as the two coincide up to a non- standard multiplicative scaling factor. Thus, \u2207xf|z identifies a standard locally improving direction for fat if and only if \u2207xf2 does. To be true, this requires that\nf(x \u2212 x\u2207xf2x) \u2264 f(x) = f\u2081(x) + f2(x)n.\n(9)\nBy definition,\nf(x - XVxf2|x) = f1(x - \u5165\u2207xf2|x) + f2(X - \u5165\u2207xf2|x)n < f1(x \u2212 1\u2207xf2|x) + f2(x)\u03b7,\nas \u2207xf2 is a decreasing direction for f2 at 7. To guarantee the satisfaction of (9), it is necessary that\nf1(x - X\u2207xf2x) \u2264 f1(x),\nhowever, I is a local minimum for f\u2081, i.e.,\nf1(x - X\u2207xf2x) \u2265 f1(x),\nforcing the condition\nf1(x-xf2x) = f1(x),\nwhich proves the thesis."}, {"title": "Corollary 1.", "content": "Let f1, f2, f, and x be defined according to Theorem 4. Then d\u2208 Rn identifies the standard direction of maximum improvement for f at x if and only if\n8 = arg max (8,212)\n\u2206f\u2081 := {\u03b4 \u20ac Sm\u22121 \u222a {0} | f1(x \u2212 1d) = f1(x)}\n(10)\nfor any arbitrary small X \u2208 R+ (Sn-1 refers to the n-dimensional unit sphere centered in 0, as usual).\nProof. As already mentioned in Theorem 4, the assumption that is a local minimum for the standard function f\u2081 implies that\nf(x \u2212 xd) < f(x)\nf1(x \u2212 1d) = f1(x),\ni.e., the request \u03b4\u2208 \u2206f\u2081 is a necessary condition for d to be a standard improving direction (up to a standard multiplicative factor) for f at 7."}, {"title": null, "content": "By construction, \u2206f\u2081 \u2260 0 as 0 \u2208 \u0394f\u2081. Moreover, \u2207xf2|\u5143 \u2260 0 as 7 is not an extreme point for f2. The two imply that Equation (10) is always well-defined. Furthermore, (\u03b4, xf2x) \u2265 0 as 0 \u2208 \u2206f\u2081, i.e., \u03b4 is a non-increasing direction for f2 at 7. This means that\nf(x - 1) =f1(x \u2013 \u03bb\u03b4) + f2(x \u2013 \u03bb\u03b4)\u03b7 =\n=f1(x) + f2(x \u2212 \u03bb\u03b4\u03b7 \u2264 f1(x) + f2(x)n = f(x),\ni.e., \u03b4 is a non-increasing direction for f.\nFinally, by using a first-order approximation, which is justified by the first-order update of 7, it holds that\nf(x-1) - f(x) = (f2(x \u2212 1) \u2212 f2(x))\u03b7 ~\n~ (f2(x)-(8,212) -f2(x)) n = -1 (8,212) 7,\nthat is, the decrease of f is linearly proportional to the inner product\n(8,2).\nThis completes the proof, as the standard direction \u03b4 maximizes such an inner product and so the decreasing f."}, {"title": null, "content": "Such a result can be exploited to manipulate the gradient VL in a way that: i) VoL is standard; ii) the contribution to the gradient of L(\u00b7, yk), k > 1, is not conflicting with the losses L(, yh), h < k. First, the approach will be presented in the simplified version with only two objectives and where gs consists of only one linear hidden layer. Figure 3 graphically reports such a scenario, while Equation (11) analytically presents it (p indicates a generic non-linear function).2 Then, its generalization to deep multi-objective networks will be discussed.\nmin E [L((01, z), Y\u2081) + NL((02, z), Y2)]\n\u03b8\ns.t.\nz = \u03c1(\u03b8\u03b5 x),\n(x, Y1, ..., Yn) ~ D\n(11)\nTheorem 5. Given the problem in (11), let one indicate\nf1(01, 0s; x, y1) = L((01, z), y1), f2(02, 0s; x, Y2) = L((02, z), Y2),\nf(01, 02, 0s; x, Y1, Y2) = f1(01, 0s; x, y1) + f2(02, 0s; x, Y2)\u03b7.\nLet one also indicate with Pa the following (symmetric) projection operator parametrized by a full row-rank matrix (or row-vector) A\nPA := I \u2013 AT (AAT)\u00af\u00b9 A = I \u2013 AT AT\u2020.\n(12)"}, {"title": null, "content": "X\n\u03b8\u03b5\n\u03ba\u03c1(.)\n2\n\u01771\n(01,.)\nL(,Y1)\n\u2192 (02,.)\n\u00db2 L(,Y2)n"}, {"title": null, "content": "Now, assume that L, p \u2208 C'\u00b9 and consider a generic feasible point (01,0s,x,y1). Then,\n\u03b4 := V0f2 \u2207es.\nPok\n02,0s,x,y2\nis a standard improving direction for f at (01, 02, 0s, x, Y1, Y2), where p' is the diagonal matrix obtained by computing the derivative of p at the point k = (0s,x).\nProof. The hypotheses satisfy those of Theorem 4, so the thesis is true if and only if\nf1(01, \u03b8\u03c2 \u2013 \u03bb\u03b4; x, y1) = f1(01, 0s; x, Y1)\n(13)\nand is such that\n(\u014d, Venf2(\u307b\u3063)) \u22650.\n(02,0s,x,y2)\nHereinafter, for the sake of conciseness, the labels yi are omitted.\n(14)\nVerification of condition (13). Given a generic point u, the first order approximation of\np(u \u2013 \u03b4) is\n\u03c1(\u03c5 \u2013 \u03b4) \u2248 \u03c1(u) \u2013 \u0440'\u0431,\nwhere p' the derivative of p at the point u. Thus, it holds true that\nf1(01, \u03b8\u03c2 \u2013 \u03bb\u03b4; x) = L((\u03b8\u2081, \u03c1((\u03b8\u03c2 \u2013 \u03bb\u03b4)x))) = L((01, \u03c1(\u0398\u03b5x \u2013 \u03bb\u03b4x))) ~\nS\nS\n~ L((\u03b8\u03b9, \u03c1(\u03b8\u03b5x) \u2013 \u03c1\u03bb\u03b4\u03b1)))) = L((\u03b81, \u03c1(k) \u2013 \u03c1'\u03b9\u03bb\u03b4\u03b1))) =\n= L((\u03b81, 2 \u2013 \u03c1'\u03ba\u03bb\u03b4x))) = L((\u03b81, z \u2212 \u03c1\u03b9\u03bb\u03b4\u03b1))) =\n= C(012 \u2013 \u03b8\u03c1\u03af\u03ba\u03bb\u03b4\u03b1),\nf1(01, 0s; x) = L(012).\nThus, condition (13) surely holds if\n\u03b8\u03c1\u03b9\u03b4 = 0.\n(15)"}, {"title": null, "content": "By definition", "as\nE": 20, "\u307b\u3093\u3063\u3068))": 0.12}]}