{"title": "A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment", "authors": ["Zefan Zeng", "Qing Cheng", "Xingchen Hu", "Yuehang Si", "Zhong Liu"], "abstract": "Event Causality Identification (ECI) has become a crucial task in Natural Language Processing (NLP), aimed at automatically extracting causalities from textual data. In this survey, we systematically address the foundational principles, technical frameworks, and challenges of ECI, offering a comprehensive taxonomy to categorize and clarify current research methodologies, as well as a quantitative assessment of existing models. We first establish a conceptual framework for ECI, outlining key definitions, problem formulations, and evaluation standards. Our taxonomy classifies ECI methods according to the two primary tasks of sentence-level (SECI) and document-level (DECI) event causality identification. For SECI, we examine feature pattern-based matching, deep semantic encoding, causal knowledge pre-training and prompt-based fine-tuning, and external knowledge enhancement methods. For DECI, we highlight approaches focused on event graph reasoning and prompt-based techniques to address the complexity of cross-sentence causal inference. Additionally, we analyze the strengths, limitations, and open challenges of each approach. We further conduct an extensive quantitative evaluation of various ECI methods on two benchmark datasets. Finally, we explore future research directions, highlighting promising pathways to overcome current limitations and broaden ECI applications.", "sections": [{"title": "1 INTRODUCTION", "content": "As big data continues to proliferate, the channels and methods for acquiring unstructured text are constantly expanding. One of the primary challenges now lies in how to automatically extract valuable information and knowledge from these texts. This has become a significant area of research in Natural Language Processing (NLP) and Knowledge Reasoning. Events form the core content of texts, and various research directions have emerged around events, such as Event Extraction (EE) [1], Event Relation Extraction (ERE), and Event Coreference Resolution (ECR) [2]. In recent years, Event Causality Identification (ECI) has gained increasing attention as an important and challenging task [3]. As a critical subtask of ERE, ECI aims to predict whether there is a causal relationship between given events in a text. ECI has been widely applied in tasks such as question answering systems [4], information retrieval [5], event prediction [6], knowledge graph construction [7], and reading comprehension [8].\nIn the ECI task, events are represented by their triggers, known as \"event mentions.\" The task then becomes determining which event mentions in a given text have a causal relationship. ECI is vital for text understanding and decision-making, as it uncovers the causes and effects of events, helping to analyze risks and opportunities for more informed, data-driven decisions. This capability is particularly essential in domains that require complex reasoning, such as finance [9], law [10], healthcare [11], and the military [12].\nECI focuses solely on extracting specific types of relations\u2014cause and effect. However, compared to the general ERE task, identifying causalities, this task is more challenging due to several factors:\n1) Implicitness: Causal links are often implied rather than directly stated, requiring deeper contextual and semantic understanding.\n2) Long-distance dependencies: Causalities may span multiple sentences or paragraphs, requiring models to capture distant interactions.\n3) Complexity: Causal chains can involve multi-step links (e.g., \"earthquake\u2192collapsed\u2192trapped\"), adding complexity to identification.\n4) Sample imbalance: In supervised settings, negative samples (non-causal pairs) dominate, challenging models to learn effectively from fewer positive cases.\n5) Limited labeled training data: Most datasets are small, requiring models to parse semantics well and generalize causal patterns from limited annotations.\nEarly ECI relied on feature pattern recognition, using cues like lexical signals [13]\u2013[15], temporal features [16], [17], and co-occurrences [18], [19]. With the rise of Deep Learning (DL), more advanced methods emerged, enabling models to better capture contextual information by deeply encoding text semantics [20]. Transformer-based [21] Pre-trained Language Models (PLMs) [22] have revolutionized ECI, as they are trained on large corpora, enhancing semantic understanding and producing high-quality event and context representations, thereby improving causal identification [23]-[25]. Since 2023, Large Language Models (LLMs) have become widely popular. Using vast datasets and large-scale self-supervised learning, LLMs have gained stronger knowledge and contextual understanding, enabling them to handle few-shot and zero-shot tasks [26], [27]. This has advanced research in event extraction, relation extraction, and question answering. However, research by Gao et al. [26] highlights that while LLMs can perform zero-shot ECI with simple prompts, they are prone to \"causal hallucination,\" leading to many false positives. Hence, even though LLMs have significantly advanced tasks related to textual event analysis, ECI remains highly challenging.\nResearch on ECI is still in its early stages, but the field is expanding rapidly. Recent years have seen a notable increase in ECI-related publications, particularly between 2022 and 2024, indicating growing interest and engagement. Though still a relatively small area, ECI research is diversifying in methodological approaches and gaining visibility in high-impact venues. This upward trend suggests that ECI will continue to attract significant attention in the near future.\nSeveral surveys have examined event causality and ERE in natural language. Asghar [28] reviewed early rule-based and statistical methods for causal extraction but did not cover deep learning (DL) approaches. Zhao et al. [29] and Xie et al. [30] provided overviews of advances in ERE, with Zhao et al. summarizing general trends in entity causality and Xie et al. comparing DL-based supervision methods. Liu et al. [31] focused on causal and temporal relationships but with limited coverage of recent methods, while Yang et al. [32] and Ali et al. [33] reviewed explicit and implicit causality extraction, limited to work prior to 2021. Liu et al. [34] covered methods, challenges, and datasets for event relation identification but lacked detailed method classification.\nIn this paper, we provide a comprehensive review and analysis of the current state of research on ECI. We systematically outline the core concepts, key technologies, and methodological frameworks in this field, and conduct a quantitative evaluation and comparison of existing approaches. Furthermore, we present a thorough outlook on the future development trends of this promising research area. Our main contributions are as follows:\n\u2022 We detail several concepts of ECI, including problem formalization, datasets, evaluation protocols, and key technologies.\n\u2022 We propose the first comprehensive classification framework for ECI (Figure 2), summarizing the technical features of various methods, evaluating their strengths and limitations.\n\u2022 We perform a quantitative comparison of different ECI methods using experimental data reproduced on two common datasets.\n\u2022 We discuss future directions in ECI, highlighting key challenges and potential solutions for advancing the field.\nThe remainder of this paper is organized as follows: Section 2 presents the relevant concepts of ECI, reviews commonly used datasets, and evaluation metrics. Section 3 introduces key technologies for ECI. Section 4 provides a comprehensive overview of the classification framework for ECI, summarizes core techniques of various models, and analyzes their strengths and weaknesses. Section 5 presents a quantitative evaluation of the performance of existing classical methods on two datasets. Section 6 outlines future research directions for ECI."}, {"title": "2 BACKGROUND", "content": "In this section, we begin by defining key concepts, including events, event causality, and ECI. We then provide a comprehensive review of the benchmark corpora commonly used for extracting event causalities in recent years. Lastly, we outline the evaluation metrics employed to assess the performance of ECI models."}, {"title": "2.1 Definitions and Problem Formalization", "content": ""}, {"title": "2.1.1 Event", "content": "An \"event\" is an objective fact defined by specific individuals, objects, and actions at a certain time and place, typically stored in unstructured formats like text, images, and videos. This study focuses on events contained within textual data.\nFor example, the sentence \"Around 8:40 AM on February 6, shortly after a subway train left a station in Moscow, the second carriage suddenly exploded, and the train caught fire.\" describes two events: \"the train exploded after departure\" and \"the train caught fire.\" Textual events often include elements like triggers and arguments. To facilitate analysis, triggers are used as event mentions. In this example, \"exploded\" and \"fire\" serve as the trigger words for the respective events."}, {"title": "2.1.2 Event Causality", "content": "Broadly speaking, causalities between events refer to the driving connections between them. If two events, A and B, have a causality represented as A\u2192B, it means that the occurrence of A is likely to lead to the occurrence of B, with A being the cause and B being the effect. In this context, the causality between events in a text can be defined as follows:\nDefinition 1: Event Causality. In a given text D, if events \u20ac1,\u20ac2 \u2208 D have a causality e1 \u2192 e2, it implies that e1 directly or indirectly leads to the occurrence of e2, while e2 does not lead to e1.\nExample 1:\nText: \"A car bomb explosion in Algeria resulted in 11 deaths and 31 injuries.\"\nCausalities: explosion\u2192death, explosion\u2192injury\nExample 2:\nText: \"The earthquake killed 14 people, hundreds of people trapped in collapsed buildings.\"\nCausalities: earthquake\u2192killed, earthquake\u2192collapsed, collapsed\u2192trapped, earthquake\u2192trapped\nExample 3:\nText: \"1. Warship INS Sukanya on Thursday foiled a piracy attempt in the Gulf of Aden between Somalia and Yemen. 2. The ship was escorting a group of five merchant vessels through the IRTC when the bid occurred.\"\nCausalities: foiled\u2192escorting, foiled\u2192bid\nIn Example 1, the word \"resulted\" clearly indicates the causality between the events \"explosion\" and \"death\" as well as \"injury,\" which is referred to as \"explicit causality.\" In contrast, Example 2 lacks explicit connecting words or cues to indicate causalities, leading to three pairs of \"implicit causality.\""}, {"title": "2.1.3 Event Causality Identification", "content": "Event causality identification (ECI) is a subtask within event relation extraction, aimed specifically at identifying the causalities between designated events. ECI focuses on extracting specific causal relationships, such as cause or caused_by. Based on the definitions of ERE in the literature [2], event causality identification can be formally defined as follows:\nDefinition 2: Event Causality Identification. Given a text D = [W1,..., Wn] containing n words and k events \u20ac1,\u20ac2,...,ek along with their mentions m1, m2,\u2026\u2026\u2026, Mk, where each event mention is a subset of D. For any two events ei and ej, determine their relationship type as one of {cause, caused_by, None}.\nBased on whether the target event pairs are within the same sentence, ECI can be divided into two main research domains: Sentence-level Event Causality Identification (SECI) and Document-level Event Causality Identification (DECI)."}, {"title": "2.2 Datasets", "content": "Annotated datasets are critical to advancing research in ECI. At present, several datasets are either specifically crafted for ECI tasks or can be adapted to evaluate ECI performance. Here, we provide a curated overview of 9 widely adopted datasets for ECI evaluation, detailing each dataset's origin, version, and statistics.\n\u2022 SemEval-2010 Task 8 [35]: An enhanced version of SemEval-2007 [36] for classifying semantic relations between noun pairs, featuring nine relations (including causality) and an \"OTHER\" category. It emphasizes contextual clarity and reduces category overlap.\n\u2022 Chinese Event Causality (CEC) [37]: A Chinese causality dataset, extracted using layered Conditional Random Fields (CRFs). It includes many-to-many, explicit, inter-sentence, cross-sentence, cross-paragraph, embedded, and overlapping causalities.\n\u2022 Causal-TimeBank (CTB) [38]: Based on the TempEval-3 corpus [39], CTB tags events in TimeML (Temporal Markup Language) format. It uses CLINK tags for causal links between events and C \u2013 SIGNAL tags for words or phrases that indicate causality, with a focus on explicit causalities.\n\u2022 CaTeRS [40]: Based on 320 five-sentence stories from the ROCStories corpus [41], this dataset covers everyday scenarios with 13 types of causal and temporal relationships, focusing on narrative structure and story-driven causality.\n\u2022 BECauSE Corpus 2.0 [42]: An updated BECauSE corpus with texts from The Wall Street Journal, The New York Times, and the Penn Treebank. It includes detailed annotations of causal language and seven other semantic relations often linked with causality, focusing on explicit causalities.\n\u2022 EventStoryLine Corpus (ESL) [18]: Drawn from 22 topics in the ECB+ dataset on events like disasters, shootings, and trials, ESC supports cross-document reasoning and narrative generation. Available versions include v0.9, v1.0, v1.5, and v2.1.\n\u2022 FinReason [43]: A Chinese corpus in the financial domain aimed at extracting reasons for significant events in public company announcements. Each document may include multiple structured events, each with zero, one, or more reasons.\n\u2022 MAVEN-ERE [44]: The first large-scale, human-annotated ERE dataset, using documents from various topics on Wikipedia. It builds on [45] with an enhanced annotation scheme to support various relationship types, including event coreference, temporal, causal, and sub-event relationships.\n\u2022 MECI [46]: The first multilingual dataset for event causality identification, sourced from Wikipedia in five languages (English, Danish, Spanish, Turkish, and Urdu). It offers valuable resources for multilingual recognition and cross-lingual transfer learning."}, {"title": "2.3 Evaluation Metrics", "content": "As with most classification tasks, existing research commonly evaluates the performance of ECI using three metrics: precision, recall, and F1-score. Precision is defined as the percentage of true positives (causal event pairs) among all samples classified as positive by the model. Recall is calculated as the ratio of correctly identified positives to the total number of true positives. The F1-score, which is the harmonic mean of precision and recall, provides a balanced measure of precision and recall, evaluating the overall performance of causality identification.\nEquations 1-3 present the formulas for these three evaluation metrics:\nprecision = $\\frac{Pt}{|P|}$ (1)\nrecall = $\\frac{Pt}{|P|'}$ (2)\nF1-score = $\\frac{2 \\times precision \\times recall}{precision + recall}$ (3)\nwhere $P^t$ represents the set of correctly identified causal event pairs, $P$ is the set of all identified causal event pairs, and $P'$ is the set of all true causal event pairs."}, {"title": "3 KEY TECHNOLOGIES", "content": "This section covers four essential techniques for ECI: syntactic analysis, pattern matching, text embeddings (word-level and contextual), and graph embeddings. These techniques encompass all current methods for ECI, serving as the foundation for implementing and understanding related models."}, {"title": "3.1 Syntactic Parsing", "content": "Syntactic parsing is an intuitive and straightforward approach for SECI. It analyzes a sentence's grammatical structure by breaking it down according to grammar rules and building a syntactic tree or dependency graph. This process clarifies the structural relationships between elements like subjects, predicates, and objects. Syntactic parsing encompasses constituent parsing, dependency parsing, and semantic dependency analysis."}, {"title": "3.1.1 Constituent Parsing", "content": "Constituent parsing, based on Context-Free Grammar (CFG), breaks a sentence into phrases. CFG is defined as G = (V, \u03a3, R, S), where V is non-terminal symbols, \u03a3 is terminal symbols, R is production rules, and S is the start symbol. Parsing starts from S and applies rules to form a parse tree, with the root as the sentence, leaves as words, and internal nodes as phrase components."}, {"title": "3.1.2 Dependency Syntax Parsing", "content": "Dependency syntax parsing emphasizes grammatical relationships directly between words, without focusing on phrase structure. In this approach, a sentence is represented as a dependency tree, where each node is a word and edges illustrate dependencies between them. The root node typically represents the sentence's predicate, with other nodes linked either to the root or to other words. Common dependency types include subject-verb, verb-object, and modifier relationships."}, {"title": "3.1.3 Semantic Dependency Parsing", "content": "Semantic Dependency Parsing (SDP) reveals both syntactic and semantic relationships in a sentence, producing a graph that captures the true meaning and logical links between words. It focuses on the semantic roles and event participation of words to uncover deeper meanings beyond surface syntax. Unlike traditional parsing methods that often use dynamic programming or graph search, semantic dependency analysis typically relies on deep learning models."}, {"title": "3.1.4 Summary", "content": "In traditional ECI models, syntax parsing is a key tool for understanding semantics. It effectively identifies word roles and relationships with minimal training, making it suitable for detecting clear, explicit causal links. With proper processing, it can also recognize cross-sentence causality. However, it struggles with implicit causality and may produce redundant links, and often requiring pattern-matching support."}, {"title": "3.2 Pattern Matching", "content": "Pattern matching uses predefined rules to identify segments that fit specific patterns, such as fixed strings, regular expressions, or syntactic structures. Patterns are defined based on the application needs, then matched with input text or syntax-parsed data. Regular expressions and part-of-speech (POS) tags are handled by annotation engines, while syntactic matching relies on graph-based similarity.\nPattern matching was a primary method in early text ECI tasks, effective for identifying explicit causal links but limited in detecting implicit ones. Its performance depends on syntax analysis results and is influenced by parser accuracy."}, {"title": "3.3 Text Embedding", "content": "Text embedding transforms language elements (words, sentences, or documents) into a continuous vector space, capturing semantic information for computational processing. With advancements in deep learning and PLMs, text embedding is essential for modeling complex semantics, identifying implicit causal links, and improving cross-domain generalization in ECI."}, {"title": "3.3.1 Word-Level Embedding", "content": "Word-level embeddings are essential for representing events in text, mapping each word to a vector. These embeddings fall into two types: static and dynamic.\nStatic embeddings (e.g., Word2Vec [49], GloVe [50]) assign fixed vectors to words, which limits their ability to handle polysemy and context sensitivity. They lack flexibility, as they can't be fine-tuned for specific tasks.\nDynamic embeddings (e.g., BERT, RoBERTa [51]) are pre-trained on large corpora using self-supervised methods, capturing word dependencies and context through self-attention. These models generate context-aware vectors, handle polysemy, and can adapt to various downstream tasks through fine-tuning. They also create sentence-level embeddings to represent complex internal relationships.\nDynamic embeddings are generally applied to encode event mentions. These embeddings are then combined with the sentence's global representation to create a context-aware event embedding. For an input sentence X = [X1, ..., xn], the encoding process is as follows:\nX = [X0, X1, ..., Xn] = Encode([x1, ..., xn]), (4)\nwhere x is the embedding vector for each word $x_i$. For an event mention e = $[x_m, ..., x_{m+l}]$ (with m > 0, m + l \u2264 n), the initial embedding e is calculated as:\ne = $\\frac{1}{l+1} \\sum_{i=1}^{l+1} X_{m+i}$ (5)"}, {"title": "3.3.2 Contextual Embedding", "content": "Contextual embedding captures relevant contextual information, learning sentence-level features by filtering out unrelated details. In ECI tasks, it helps identify long-range and cross-sentence causalities. Typically, words are first encoded into vectors, then processed by sequence models to learn context-based features.\nCNNs [52] capture local context through 1D convolutions with sliding windows, building from local to global context. RNNs [53] (and variants like LSTM [54], GRU [55]) process each word sequentially, carrying information forward to capture dependencies, while bidirectional RNNs [56] enhance context awareness with bidirectional modeling.\nTransformer-based pre-trained language models (PLMs) use self-attention to process entire sequences, capturing long-range dependencies by adjusting word representations based on the full context. PLMs provide rich contextual embeddings, which can be fine-tuned to meet specific semantic requirements. In equation 4, xo is the embedding of the [CLS] token (sentence embedding), which is also the contextual embedding."}, {"title": "3.3.3 Graph Embedding", "content": "In identifying causalities in long sentences and documents, irrelevant content can introduce noise, affecting performance. Modeling events as causality graphs addresses this issue. A causality graph is a directed graph represented as G = (V, E), where V consists of nodes (event mentions or other event-related features) and E consists of edges (causalities). Graph embedding techniques are increasingly used in ECI research. These techniques map nodes, edges, or entire subgraphs into a high-dimensional vector space, enabling embedded vectors to effectively capture relationships and features within the graph.\nGraph embedding commonly uses Graph Neural Networks (GNNs) as encoders. GNNs operate on a message-passing mechanism, aggregating information from a node and its neighbors to update the node representation, reflecting both local structure and the node's features. In a causality graph G, for each node v \u2208 V, the neighboring nodes are denoted as N(v). The representation of node v at layer l is $h_v^l$. The aggregation and update process in a GNN can be described as:\n$h_v^{(l+1)}$ = UPDATE($h_v^l$, AGGREGATE($\\{h_u^l | u \u2208 N(v)\\}$)), (6)\nAGGREGATE(\u00b7) aggregates the representations of neighboring nodes at layer l, while UPDATE(\u00b7) updates the representation of node v using its previous state $h_v^l$ and the aggregated neighbor information.\nIn ECI, commonly used GNNs include GCN [57], GAT [58], and GraphSAGE [59]. GCN captures graph structure by normalizing the graph Laplacian or adjacency matrix, aggregating neighboring nodes' features to update the current node's representation. GAT introduces a self-attention mechanism that assigns varying weights to neighboring nodes' features, dynamically adjusting their influence on the target node based on importance. GraphSAGE is a scalable embedding model for large graphs. It samples neighboring nodes for embedding calculation, making it efficient for large-scale data."}, {"title": "4 TAXONOMY", "content": "This section distinguishes SECI from DECI, presenting relevant methods and models. SECI and DECI are reviewed separately due to differences in task complexity, model demands, and challenges, with DECI being the more difficult. Methods are first categorized by their characteristics, followed by a discussion of their core techniques, classic models, strengths, and open challenges."}, {"title": "4.1 Sentence-Level Event Causality Identification", "content": "Sentence-Level event causality often conveyed through specific words and syntax, with many explicit cues and typical causal structures. Since SECI requires limited context, semantic interpretation is relatively straightforward. We categorize current SECI methods into four main types: feature pattern-based matching, deep semantic encoding, causal knowledge pretraining and prompt-based fine-tuning, and external knowledge enhancement."}, {"title": "4.1.1 Feature Pattern-Based Matching", "content": "Before deep learning became prevalent, feature pattern-based matching was the main approach for SECI. These methods leverage lexical cues, syntax, and pattern recognition to detect causal patterns and determine event relationships. This approach includes four types: template matching, syntactic patterns, co-occurrence, and feature-based classification.\nTemplate matching-based methods identify causalities using predefined patterns, such as role or graph templates. [60] provides an in-depth analysis of causality templates and structures. [14] outlines five templates for causal patterns: (1) causal conjunctions, (2) causative verbs, (3) resultative complements, (4) conditional sentences, and (5) adverbs/adjectives with causal meaning, achieving a 68% identification rate on test data. [13] proposes constructing templates that represent roles and attributes within causal contexts. When text matches a template, matched words populate template slots to represent causalities. [61] enhances accuracy and scalability by using syntactic graph templates, which align with parse trees to pinpoint cause and effect segments in text, making template matching more precise. Template matching methods are interpretable and sensitive to explicit causalities. However, they can only identify causalities that fit predefined templates, making it challenging to address implicit, complex, or irregular expressions of causality.\nSyntactic pattern-based methods identify causalities using predefined structures. Ishii and Ma [62], [63] created a topic-event causal model that represents text as a causal network graph. Their incremental approach merges similar event vertices based on thematic and event keywords, calculating importance scores to optimize the network. Caselli and Vossen [18] introduced the Order Presentation (OP) method, pairing each event with subsequent events based on their order, assuming earlier events may cause later ones (also for DECI). Girju and Moldvan [64] developed a semi-automated method to identify causal syntactic patterns. They extract noun phrase pairs from WordNet [65] and search for sentences containing these pairs. They then identify sentences that fit the pattern \"NP1 verb/verb expression NP2\", assessing whether the pattern indicates causality. Ittoo and Bouma [66] modeled events as a causality graph, using shortest paths to represent relationships corresponding to syntactic patterns, then iteratively identified linking patterns and scored their reliability based on event pair purity. Building on this, Ittoo et al. [67] proposed a selection strategy for causal event pairs to ensure diverse representation of causality subtypes. Syntactic pattern-based methods can identify more complex causalities than template matching. They automatically generate patterns using parsing tools, minimizing manual construction. They can also differentiate causal meanings and resolve ambiguities. However, reliance on parsers for analysis increases computational demands and may affect performance if the parser is inaccurate.\nCo-occurrence pattern-based methods identify causalities based on event co-occurrence frequency and semantic associations. Do et al. [19] proposed a minimally supervised learning approach that uses pointwise mutual information and inverse document frequency to measure relationships between events. They calculate co-occurrence counts to predict causalities and leverage discourse connectives for additional context. They then use Integer Linear Programming (ILP) to ensure causal consistency. Caselli and Vossen [18] employed Positive Pointwise Mutual Information (PPMI) to evaluate the semantic relevance of event pairs by analyzing co-occurrence frequencies in large datasets. The improved PPMI-CONTAINS model adds temporal constraints, requiring event pairs to have PPMI values within a specified range and to share the same time frame. Co-occurrence-based methods use statistical information from large corpora instead of predefined templates, enabling them to address implicit causalities and adapt to different domains. However, reliance on statistical associations can result in many false positives.\nFeature classification-based methods utilize machine learning techniques to model ECI as a binary classification task. Zhao et al. [68] introduced method to measure similarity in sentences with causal connectives and categorizing these connectives to enhance understanding of causality. They ultimately used a naive Bayes model for causal learning. Mirza and Tonelli [17] inferred causal chains by analyzing causal verbs and their dependencies, using feature-based classification to identify causalities. They also proposed an SVM-based model [69], which uses lexical-syntactic features and dependency paths for classification. Mirza [16] incorporated temporal rules and introduced causal signals and causal links between events, utilizing features from lexical-syntactic information and context for classification. Aforementioned models automatically learn diverse feature combinations to improve accuracy. However, their performance declines significantly when annotated data is sparse. Furthermore, these models often capture only shallow semantic features.\nOpen Challenges. Pattern matching-based methods are simple, efficient, and interpretable, with low computational demands, making them popular in early research. However, they lack the ability to capture deep semantic information and rely heavily on external parsers and predefined lexical or syntactic patterns. This dependence limits their scalability, flexibility, and generalizability, causing performance to degrade significantly with complex semantics, unfamiliar structures, or noisy text."}, {"title": "4.1.2 Deep Semantic Encoding", "content": "With advancements in deep learning, neural sequence models have enabled richer representations for text and events, particularly in managing long-distance dependencies. PLMs generate context-sensitive, dynamic word embeddings through large-scale pre-training, thereby capturing more intricate semantic relationships.\nDeep semantic encoding-based ECI methods employ deep sequence models or PLMs as encoders, applying tailored encoding strategies to capture the semantic and contextual information of events and generate high-dimensional embeddings. The embeddings of two target events are concatenated and input into a classifier (e.g., a multilayer perceptron), which learns the features of these high-dimensional embeddings through neural networks to assess the presence of causality.\n4.1.2.1 Simple Encoding Strategy\nSimple encoding strategies leverage sequence models (e.g., RNNs, LSTMs) and PLMs (e.g., BERT, ROBERTa, and Longformer [70]) as encoders to obtain contextual embeddings of event pairs, which are then input into a classifier to determine their relationship type. Although few of them are specifically covered in dedicated literature [71], these methods are frequently used as baseline comparisons in research.\nFor sequence models, an input sentence X = [x1,..., xn] is processed by first obtaining static word embeddings for each word, followed by encoding with a sequence model to capture contextual information, generating event embeddings as follows:\n$x_i$ = Emb($x_i$), (7)\nX = [$X_1, X_2, ..., X_n$] = SeqModel ([$x_1, x_2,...,x_n$]), (8)\nEmb and SeqModel denote static embedding model encoding and sequence model encoding, respectively. The event embeddings are calculated based on the words corresponding to event mentions. For PLMs, event embeddings are derived using equation 4.\nThe embeddings of two events, $e_i$ and $e_j$, are concatenated to form the event pair representation, either as $e_{pij}$ = [$e_i$; $e_j$] or $e_{pij}$ = [$e_{[CLS]}$; $e_i$; $e_j$]. This concatenated vector $e_{pij}$ is then input to a classifier, typically a Multi-Layer Perceptron (MLP), as follows:\np = MLP($e_{pij}$) = softmax(W$e_{pij}$ + b), (9)\nW and b are learnable parameter matrices, and p\u2208 R2 (ignoring direction) or p\u2208 R\u00b3 (considering direction). Each dimension of p corresponds to the probability of the causality or non-causality.\nDuring training, parameters are optimized on a annotated dataset using cross-entropy loss to enable causality classification:\nL = -$\\sum_{j=1}^{NC} \\sum_{i=1}^{C} y_{ij}$ log ($p_{ij}$), (10)\nC = 2 or 3 corresponds to the output dimension of p, y represents the true label, p the predicted probability, and N the number of labeled event pairs. Encoder parameters can also be updated as needed.\nSimple encoding strategies have limited capacity for capturing context and often generate low-quality embeddings. They require large amounts of labeled data for training, are prone to false positives, and exhibit relatively weak cross-domain generalization.\n4.1.2.2 Enhanced Encoding Strategy\nEnhanced encoding strategies leverage sequence models or PLMs combined with rich feature to capture context, improving the quality of event and event-pair representations. These strategies integrate additional information into embeddings before classification. Current research include three main approaches: semantic structure enhancement, event information enhancement, and causal label enhancement. Table 2 summarizes the enhancement details of these encoding models.\nSemantic structure enhancement encoding strategies use structured semantic information, like dependency relations, syntactic paths, and semantic graphs, to enrich event representations. Tri-CNN [72] combines syntactic and contextual information through a three-channel CNN, integrating paths and event-pair embeddings for a comprehensive global representation. SemSIn [24] captures implicit relationships by encoding events with BERT, parsing text into semantic graphs with AMR, and aggregating event and neighbor information using GNNs. SemDI [73] uses sentence-level semantic dependencies with three modules: ROBERTa for word dependencies, a Cloze test for context prediction, and multi-head attention to evaluate causal associations. These strategies, although effective for handling complex sentences, can be computationally demanding, particularly when dealing with long or cross-sentence causalities. This results in increased training and inference times.\nEvent information enhancement encoding strategies improve event representations by capturing various elements such as semantics, location, time, and participants, enriching the context and detail of each event. Kadowaki et al. [23] use BERT to encode event-specific elements (e.g., roles, positions) and train multiple classifiers to learn different annotator perspectives, combining their outputs for final predictions. DualCor [74] propose a dual grid tagging scheme with BERT to capture event correlations, integrating event type information with contextual representations to distinguish cause-effect pairs. Yang et al. [75] employ a Bi-LSTM-based Siamese network to incorporate event triggers and associated arguments (like time and location), enhancing event embeddings. A knowledge graph-inspired approach is then used to infer causalities based on event similarity. These methods incorporate multiple event elements and features, enriching the representation of events and causalities. However, they are computationally intensive and require well-designed event elements and features to be effective.\nLabel information enhancement encoding strategies refine event pair embeddings by using causal labels, applying techniques like contrastive learning, graph interactions, and counterfactual reasoning. SCL [76] enhances event representations by leveraging causal labels, constructing triplets (positive and negative event pairs) and uses contrastive loss to create more distinctive embeddings. ECLEP [77] combines causal label information with event pair interactions. ECLEP builds an event-pair interaction graph, integrating causal labels and using GAT to update representations. CF-ECI [78] uses counterfactual reasoning to mitigate bias in ECI. The model assesses biases from context and event pairs separately, using causal labels to adjust predictions through weighted debiasing. These methods maintain high accuracy even with noisy data or ambiguous context. However, they rely heavily on causal labels and require extensive labeled data.\nSummary. Simple encoding strategies are easy to implement and train, offering high computational efficiency but are only suited for clear, low-noise texts within a single domain. Enhanced encoding strategies provide a more comprehensive modeling of event causality, improving accuracy and robustness in ECI, especially in complex contexts and long-distance dependencies. They are effective in handling complex semantic structures and exhibit stronger cross-domain generalizability. However, deep semantic encoding-based methods require a substantial amount of labeled data. Without sufficient supervised learning, these models struggle to learn high-quality encoding and classification capabilities, which impacts inference accuracy."}, {"title": "4.1.3 Causal Knowledge Pretraining and Prompt-Based Fine-Tuning", "content": "With advancements in PLMs and prompt learning", "emerged": 1}]}