{"title": "LLM Generated Distribution-Based Prediction of US Electoral Results, Part I", "authors": ["Caleb Bradshaw", "Caelen Miller", "Sean Warnick"], "abstract": "This paper introduces distribution-based prediction, a novel approach to using Large Language Models (LLMs) as predictive tools by interpreting output token probabilities as distributions representing the models' learned representation of the world. This distribution-based nature offers an alternative perspective for analyzing algorithmic fidelity, complementing the approach used in silicon sampling. We demonstrate the use of distribution-based prediction in the context of recent United States presidential election, showing that this method can be used to determine task specific bias, prompt noise, and algorithmic fidelity. This approach has significant implications for assessing the reliability and increasing transparency of LLM-based predictions across various domains.", "sections": [{"title": "Introduction", "content": "Language is a symbolic system used to convey semantics a vehicle for representing meaning. By translating thoughts, experiences, and concepts into structured expressions, language serves as a bridge between abstract ideas and tangible communication. Large Language Models (LLMs) extend this function into the realm of artificial intelligence, demonstrating emergent abilities to handle complex and context rich tasks beyond the scope of smaller language models through natural language [16]. Furthermore, research indicates that LLMs contain coherent and grounded representations that reflect real world distributions [6, 7, 3]. This emergent property of LLMs is demonstrated in Appendix A. These internal world models are informed strongly by training data, frequently resulting in significant biases [4, 11, 15]. The accurate representation of real world distributions through LLM outputs is known as algorithmic fidelity, a concept that has fueled methods such as silicon sampling, the generation of simulated personas in an attempt to simulate real populations [1]. This technique leverages the internal model of LLMs to simulate human-like responses, potentially providing insights into diverse demographic samples without the need for actual data.\nA key limitation of silicon sampling lies in its tendency to stereotype demographics, as demonstrated in Appendix B. Additionally, recent results have suggested that the success of silicon sampling is due in part to input shortcut features [18]. Prompt noise, such as the ordering of options, can also significantly impact voting results [17, 14]. Furthermore, LLMs tend to assume that people act more rationally then they actually do, thereby deviating from actual human behavior [8]. Despite these challenges, silicon sampling has powerful use cases, and when properly applied can generate realistic survey results [13, 12, 9].\nBuilding on these insights, our paper introduces a novel approach that leverages LLMs as non-persona based predictive models. Rather than having the model simulate individuals, we analyze output probabilities as predictive distributions, interpreting them as indicative of model expectations. We term this approach Distribution Based Prediction. This perspective enables a unique set of investigations, including bias detection through distributional analysis, examination of case by case algorithmic fidelity, robustness testing against variations in prompt design, and evaluation of LLMs' effectiveness as predictive tools.\nTo demonstrate this approach, we apply it to a real-world prediction task: predicting the outcome of the U.S. presidential election by generating distributions of voter share per state for each candidate. Voter prediction is a significant task for testing the efficacy of LLMs at gathering, synthesizing, and making predictions with data [5, 15]. This context serves as both a testing ground for an LLMs predictive accuracy and a framework to analyze bias, prompt noise sensitivity, and algorithmic fidelity."}, {"title": "Methods", "content": ""}, {"title": "Distribution Based Prediction", "content": "Given the limitations observed in demographic-based sampling, we propose a distribution based prediction methodology that bypasses individual persona simulation. Instead, we prompt the model directly to forecast electoral outcomes by requesting specific vote shares for each candidate within a designated state, treating the output token probabilities as a distribution representative of the model's embedded knowledge of demographic, geographic, and historical voting trends.\nIn this approach, we formulate a straightforward, task-oriented prompt structure aimed at obtaining a vote distribution across regions while allowing the model to express uncertainty implicitly in its probability outputs. Specifically, we provide the model with a \"system prompt\" role as a neutral election predictor, with a targeted output representing candidate vote share as a single integer token:\n\u2022 System Prompt:\n\u201cYou are an impartial election prediction machine. Respond with a single"}, {"title": "Condensing State Distributions", "content": "Let \\(S = \\{s_1, s_2,...,s_{51}\\}\\) denote the set of states, including the District of Columbia, and let \\(C = \\{c_1, c_2\\}\\) represent the two candidates. Define the discrete voter percentage set as \\(Y = \\{0\\%, 1\\%, 2\\%, ...,100\\%\\}\\).\nFor each state \\(s \\in S\\) and candidate \\(c\\in C\\), let \\(P_{s,c}(y)\\) denote the probability that candidate c receives exactly y% of the vote in state s. These probability distributions satisfy the normalization condition:\n\\[\\sum_{y\\in Y} P_{s,c}(y) = 1 \\quad \\forall s \\in S, c \\in C\\]\nThe objective is to compute the win probabilities for each candidate in each state by determining the likelihood that one candidate's voter percentage exceeds the other's. Tied outcomes are excluded from consideration.\nThe probability that candidate \\(c_1\\) wins in state s is given by:\n\\[P_s(c_1 \\text{ wins}) = \\sum_{y_1 \\in Y} P_{s,c_1}(y_1) \\cdot \\left(\\sum_{y_2 < y_1} P_{s,c_2}(y_2)\\right)\\]\nSimilarly, the probability that candidate \\(c_2\\) wins in state s is:\n\\[P_s(c_2 \\text{ wins}) = \\sum_{y_2 \\in Y} P_{s,c_2}(y_2) \\cdot \\left(\\sum_{y_1 < y_2} P_{s,c_1}(y_1)\\right)\\]\nSince ties are disregarded and only one candidate can win in each state, the win probabilities satisfy:\n\\[P_s(c_1 \\text{ wins}) + P_s(c_2 \\text{ wins}) = 1 \\quad \\forall s \\in S\\]\nFor each state \\(s \\in S\\), the win probabilities for candidates \\(c_1\\) and \\(c_2\\) are computed as:\n\\[P_s(c_1 \\text{ wins}) = \\sum_{y_1 \\in Y} P_{s,c_1}(y_1) \\cdot \\left(\\sum_{y_2 < y_1} P_{s,c_2}(y_2)\\right)\\]\n\\[P_s(c_2 \\text{ wins}) = \\sum_{y_2 \\in Y} P_{s,c_2}(y_2) \\cdot \\left(\\sum_{y_1 < y_2} P_{s,c_1}(y_1)\\right)\\]\nThese equations ensure that for each states, the sum of the win probabilities for both candidates equals unity, thereby providing a complete probabilistic model of the election outcomes based on discrete voter percentages."}, {"title": "Electoral College Simulation", "content": "Let \\(S = \\{s_1, s_2,...,s_{51}\\}\\) denote the set of states, including the District of Columbia, where each state \\(s \\in S\\) is assigned a fixed number of electoral votes \\(e_s\\). Define the total number of electoral votes as \\(E = \\sum_{s \\in S} e_s\\).\nFor each state s, let \\(P_s(c_1)\\) and \\(P_s(c_2) = 1-P_s(c_1)\\) represent the probabilities that candidates \\(c_1\\) and \\(c_2\\) win state s, respectively. Define a random variable \\(V_s\\) to represent the electoral votes allocated to \\(c_1\\) from state s:\n\\[V_s = \\begin{cases} e_s & \\text{with probability } P_s(c_1), \\\\ 0 & \\text{with probability } P_s(c_2). \\end{cases}\\]\nThe total electoral votes V for candidate \\(c_1\\) is the sum of electoral votes from all states:\n\\[V = \\sum_{s \\in S} V_s.\\]\nThe probability that \\(c_1\\) receives exactly k electoral votes is given by the probability mass function:\n\\[P(V = k) = \\sum_{A \\subseteq S,\\atop \\sum_{s \\in A} e_s = k} \\left(\\prod_{s \\in A} P_s(c_1)\\right) \\left(\\prod_{s \\in S \\setminus A} P_s(c_2)\\right).\\]\nDue to the computational complexity of enumerating all subsets \\(A \\subseteq S\\), a generating function approach is employed. The generating function \\(G_V(z)\\) for V is defined as:\n\\[G_V(z) = \\prod_{s \\in S} [P_s(c_2) + P_s(c_1) \\cdot z^{e_s}].\\]\nThe probability \\(P(V = k)\\) is the coefficient of \\(z^k\\) in the expanded form of \\(G_V(z)\\):\n\\[P(V = k) = [z^k]G_V(z).\\]For example, if there is a 5% probability that \\(c_1\\) accumulates 272 electoral votes, then \\(c_2\\) has a 5% probability of receiving \\(E - 272\\) electoral votes:\n\\[P(V = 272) = 0.05 \\implies P(V = E - 272) = 0.05.\\]\nFinally, the probabilities across all possible electoral vote outcomes satisfy the normalization condition:\n\\[\\sum_{k=0}^E P(V = k) = 1.\\]\nThis formulation provides a comprehensive framework for determining the probability distribution of Electoral College outcomes based on state-level win probabilities."}, {"title": "Experiments and Results", "content": ""}, {"title": "Comparison to 2020 Election Results", "content": "Our model's performance in \"predicting\" the 2020 U.S. presidential election provides a useful benchmark for evaluating its algorithmic fidelity on historic data. When prompted to forecast state-by-state outcomes for the candidates, the model generated distributions that were notably concentrated around the actual vote percentages, with most states showing over 90% of their probability mass within a percent of the true results.\nWe analyze the distributional error by comparing the model's predicted vote shares for Joe Biden and Donald Trump with the actual percentages from 2020. As shown in Table 1, the model achieved an average prediction error of 0.4490 for Joe Biden and 0.4354 for Donald Trump across all states, meaning that the model's outputs deviate by less than half a percentage point on average. This precision and accuracy is evident in Iowa (see Figure 1), where the predicted distributions tightly align with the actual vote shares."}, {"title": "State Distributions for the 2024 Election", "content": "We now prompt the model on the future 2024 election between Donald Trump and Kamala Harris to get expected probability distributions for each state."}, {"title": "Predicted Electoral Outcomes", "content": "Using these predicted state vote distributions, we run our electoral college simulation for each contest and calculate the result of a simulated presidential election between Donald Trump and Kamala Harris. Our output is a probability distribution over all possible electoral college outcomes. To produce a single electoral map, however, we simply pit the weighted average of each candidate-state distribution against their opponent to produce an average case result."}, {"title": "Simulating Hypothetical Elections", "content": "Using this method of generating electoral results, it's trivial to change the input names and specified election to simulate election results for any two individuals in a given contest. We simulate hypothetical match-ups between five Republican and five Democratic politicians in the 2016, 2020, and 2024 presidential elections. Even though the first two elections have already occurred and the results figure in the LLM's training data, we still phrase the prompt as if it were a prediction."}, {"title": "Discussion", "content": ""}, {"title": "Prompt Noise", "content": "One of the major challenges with using LLMs is the impact that prompt noise can have on generated outputs, to the extent that using different wordings can significantly alter the output distribution [14]. Our proposed approach is not exempt from this issue, but it may provide an additional tool set for analyzing the impact of prompt noise on applicable tasks by comparing output distributions across a variety of similar prompts."}, {"title": "Measuring Bias", "content": "Using direct prediction, extracted distributions can be compared to actual results as a means of assessing an LLMs world model bias for a given task. This would be most effective on tasks with more data points, as it would ideally reduce the impact of outliers. This is one of the key motivations for our simulating the election starting at the state rather than national level, as it provides 102 data points rather than 2.\nGiven the context of United States politics, several major LLMs have been shown to have left leaning biases [10]. Initial testing with direct prediction has reflected this biased world model, with LLMs generally favoring Democratic candidates over Republican candidates in swing states, where the vote could go to either party. Notably, this bias does not seem to impact non-swing states, where a given party is assumed to have an easy victory. As shown in Figure 8, the LLM's predictions consistently favor Democratic candidates, except in the case of Donald Trump's dominance in the 2016 election predictions. This exception likely reflects the influence of his victory, which is included in the model's training data."}, {"title": "Limitations of Training Data Cutoff", "content": "Retraining or repeatedly fine tuning an LLM is computationally expensive and runs the risk of issues such as catastrophic forgetting. Furthermore, the data must be carefully filtered to limit harmful content or misinformation. As such, an LLM's training data is generally cut off significantly before its release, preventing its world model from accounting for current events. For example, the cut off for GPT-40 was October 2023, 7 months before its May 2024 release.\nThe two most straightforward techniques for overcoming this limitation are supplementing the prompt or fine tuning with current information. However, both of these approaches introduce additional challenge, such as determining what information should be included in a summary of current events.\nThis limitation also provides opportunity for the study of an LLM as a predictive model, as we can compare output distributions of current events not seen by the model to the actual events."}, {"title": "Measure of Algorithmic Fidelity For LLMs as Predictive Models", "content": "By extracting distributions that can be compared to actual data, we obtain a new method of determining a models algorithmic fidelity. Although limited to a case by case basis (fidelity to voting trends does not inform us about a model's ability to predict sports games), measuring algorithmic fidelity in this way can provide a measure of an LLM's effectiveness as a predictive model in a given domain. To what extent this approach to measuring algorithmic fidelity is valid or consistent is yet to be seen."}, {"title": "Conclusion", "content": "In this paper we propose Distribution Based Prediction, a technique that involves treating an LLM's output probabilities as a distribution representative of the LLM's internal world model. This method allows for a comparison against ground truth data as a means of assessing model bias and algorithmic fidelity.\nInitial testing of this approach for simulating the US presidential election indicates that Distribution Based Prediction could be a viable method of utilizing and analyzing LLMs as predictive models."}, {"title": "Future Work", "content": "A great deal of work is needed to verify the effectiveness of distribution based prediction as a framework. This includes determining this method's robustness against prompt noise, creating a rigorous measure of algorithmic fidelity in this context, and testing across additional domains.\nOne of the key aspects of distribution based prediction is its generalization nearly any task where the data can be expressed as a two dimensional distribution may be modeled. Use cases could include predicting the results of sports games, forecasting the weather, predicting stock market trends, and much more. Additional research into any of these topics using this approach could be valuable, both to the study of LLMs and the specific domain.\nAs far as US presidential election electoral prediction, additional work is needed to probe model bias, compare model outputs to real data, and measure the effect of adding more up to date information. In particular, the actual results in each state may be compared to an aggregation of model outputs across many prompts, allowing us to determine how likely it is that the real distribution that reality drew from matches the LLM's world model."}, {"title": "Tendency of Models to Stereotype During Silicon Sampling", "content": "Initially, we explored a demographic-based simulation approach, aiming to leverage the model's embedded knowledge about voter demographics across geographic regions. The idea was to simulate a diverse population of \"voters\" through Silicon Sampling, prompting the model to generate responses based on specific demographic information (e.g., rural Christians in Pennsylvania). This approach, however, revealed limitations: the LLM frequently displayed strong stereotypical biases, repeatedly associating certain demographic groups with uniform voting behaviors. For instance, when prompted to \"sample\" the preferences of a rural Christian Pennsylvanian, the model overwhelmingly leaned toward the voting patterns of the majority demographic preference, with minimal variance in outcomes.\nTo illustrate this process, we used the following structured prompts for guiding the model's responses in the demographic sampling approach:\n\u2022 System Prompt:\n\u201cYou are a {demographic} American. Not the average of all {demographic} Americans. You are literally a random {demographic} American sampled from the population. You respond by picking between two candidates for"}]}