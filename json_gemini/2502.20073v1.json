{"title": "Collab-Overcooked: Benchmarking and Evaluating Large Language Models as Collaborative Agents", "authors": ["Haochen Sun", "Shuwen Zhang", "Lei Ren", "Hao Xu", "Hao Fu", "Caixia Yuan", "Xiaojie Wang"], "abstract": "Large language models (LLMs) based agent systems have made great strides in real-world applications beyond traditional NLP tasks. This paper proposes a new LLM-powered Multi-Agent System (LLM-MAS) benchmark, Collab-Overcooked, built on the popular Overcooked-AI game with more applicable and challenging tasks in interactive environments. Collab-Overcooked extends existing benchmarks from two novel perspectives. First, it provides a multi-agent framework supporting diverse tasks and objectives and encourages collaboration through natural language communication. Second, it introduces a spectrum of process-oriented evaluation metrics to assess the fine-grained collaboration capabilities of different LLM agents, a dimension often overlooked in prior work. We conduct extensive experiments over 10 popular LLMs and show that, while the LLMs present a strong ability in goal interpretation, there is a significant discrepancy in active collaboration and continuous adaption that are critical for efficiently fulfilling complicated tasks. Notably, we highlight the strengths and weaknesses in LLM-MAS and provide insights for improving and evaluating LLM-MAS on a unified and open-sourced benchmark. Environments, 30 open-ended tasks, and an integrated evaluation package are now publicly available at https://github.com/YusaeMeow/Collab-Overcooked.", "sections": [{"title": "1 Introduction", "content": "Leveraging the remarkable zero-shot and few-shot learning ability of Large Language Models (LLMs), LLM-based agents are demonstrating their potential in complex task decomposition and planning (Wang et al., 2023a,c; Li et al., 2024). Inspired by human collaborative behaviors in social activities, recent research reveals that multi-agent systems can significantly enhance task efficiency and tackle challenges surpassing single-agent capabilities (Li et al., 2023; Hong et al., 2023; Zhang et al., 2023). To effectively address complex real-world tasks, LLM-powered Multi-Agent Systems (LLM-MAS) require three essential collaboration capabilities beyond goal interpretation: (a) Competence boundary awareness: the ability to analyze task flows and environmental states to determine feasible actions, recognize limitations, and identify when external assistance is needed; (b) Communication: proficiency in utilizing standardized protocols for transmitting task-critical information and resource requests; and (c) Dynamic adaptation: responsiveness to collaboration requests and dynamically adjusting their action sequences accordingly.\nGiven these fundamental requirements, establishing evaluation frameworks becomes crucial for assessing LLM-MAS collaboration effectiveness. Researchers have developed specialized benchmarks to quantify collaborative agents in specific environments. Representative platforms like (Agashe et al., 2023), RocoBench (Mandi et al., 2024) and LLMARENA (Chen et al., 2024) create virtual scenarios requiring collaborative problem-solving through intricate workflows. These frameworks are complemented by novel metrics, such as Collaboration Score (CoS) (Gong et al., 2023), which evaluates end-to-end collaboration capability.\nDespite recent progress in evaluating LLM-MAS collaboration capability, existing approaches exhibit three critical limitations. First, they prioritize task completion efficiency without imposing strict collaboration requirements, allowing individual agents to accomplish tasks that are nominally \"collaborative\" independently. This design flaw introduces assessment biases by obscuring the role of collaboration in performance gains, which contrasts with real-world applications where collaboration is often essential for task success. Second, existing benchmarks conflate collaboration"}, {"title": "2 Related Work", "content": "LLM-Powered Multi-Agent System LLM-MAS enables agents to collaboratively engage in planning, discussing, and decision-making. Collaboration is a pivotal capability in task-oriented LLM-MAS, as it not only enhances task completion efficiency (Zhang et al., 2024b; Tao et al., 2024) but also enables the pursuit of complex goals beyond the reach of single agent (Park et al., 2023; Hong et al., 2023). Recent methods for improving collaboration can be broadly categorized into (a) Structural optimization (e.g., DyLAN's (Liu et al., 2023) dynamic framework), (b) Role specialization (e.g., AutoGen's (Wu et al., 2023) personas and AgentVerse's (Chen et al., 2023) role assignments), and (c) Communication paradigm (e.g., MetaGPT's (Hong et al., 2023) message pool). Despite these advancements, the inherent complexity and diversity of multi-agent tasks make it difficult to compare methods directly, driving the emergence of standardized benchmarks that enable quantitative evaluations under unified conditions.\nLLM-MAS Benchmark and Evaluation Benchmark testing in virtual environments is the primary method for evaluating multi-agent collaboration capability. As shown in Table 1, existing studies establish diverse tasks and commonly use End-to-End (E2E) metrics to assess LLM-MAS collaboration capability, with some benchmarks offering environmental scalability. However, several limitations persist. A key issue is the lack of a formal collaboration definition in most benchmarks, leading to ambiguous assessments and inconsistent comparisons across different benchmarks. Furthermore, the absence of enforced collaboration mechanisms allows agents to achieve objectives independently (e.g., in CuisineWorld, where many tasks can be completed by a single agent), undermining the true assessment of collaboration. Finally, the predominant focus on outcome-based metrics such as E2E performance overlooks the critical role of process-driven dynamics. Approaches like (Song et al., 2024), LTC (Wang et al., 2023b), and EvoMAC (Hu et al., 2024) suggest refining LLMs through process behaviors to enhance adaptation and collaboration, indicating that incorporating process-oriented metrics could offer more comprehensive insights."}, {"title": "3 Task-Oriented Collaboration", "content": "A task in LLM-MAS can be formulated as a 4-tuple: T = (G,E,P, R), where G is a natural language description of the task goal, such as \u201cmake a dish of tomato soup\"; E is a description of the environment, which can be either the layout of a simulated scenario or the visual input of real-world surroundings; P is optional natural language guidance, providing recipes, helpful hints, or task constraints; and R is a Referential Action Trajectory (RAT) that leads to the successful completion of the task and is used to assess the agents' performance. It is worth noting that there are often multiple RATs for a task, especially in dynamic environments.\nCollaboration often involves agents relying on each other to solve tasks. As shown in Figure 1 Part I, we define collaboration capability as comprising two essential components: the capability to initiate collaboration, where agents, upon realizing that their competence boundary prevents them from completing the task according to G and P at environmental state \\(s_t \\in E\\) at time t, generate a request for collaborative actions \\(\\bar{a}_{req}\\) to solicit assistance from other agents; and the capability to respond to collaboration, where agents, upon receiving \\(\\bar{a}_{req}\\) from another agent, adjust their action sequence based on their own \\(s_t\\) and generate collaborative actions \\(\\bar{a}_{resp}\\)."}, {"title": "3.2 TES and ITES", "content": "Trajectory Efficiency Score (TES) is designed to compare the difference between two trajectories and is defined as:"}, {"title": "3.2.1 TES", "content": "\\(TES(h_k) = max_{j} {\\frac{(1 + \\beta^2)D_{max}(h_k, g^i)}{m_k + \\beta^2 n_k}}\\) (1)\nwhere \\(h_k = \\cup_{t=1}^{T} a_t = \\{a_1, a_2, ..., a_{n_k}\\}\\) is the historical action sequence up to timestep T of agent k, \\(g = \\{g^i\\} \\in R\\) is j-th RAT of agent k, \\(\\beta\\) is the hyper-parameter balancing the weight of task progress and redundancy, and \\(D_{max}(h_k, g^i)\\) computes the length of the longest order-preserving subsequence in \\(h_k\\) that matches \\(g^i\\): \\(D_{max}^d = max\\{d | \\forall 1 < i_1 < ... < i_d \\le n_k, \\s.t. a_{i_1} = g_1, a_{i_2} = g_2, ..., a_{i_k} = g_k \\}\\) (2)\nUnlike other existing sequence alignment scores (such as ROUGE-L (Lin, 2004)), TES takes into account sequence order and redundancy punishment simultaneously, therefore suitable for assessing a rationally planned action sequence (detailed in Appendix B.1)."}, {"title": "3.2.2 ITES", "content": "Incremental Trajectory Efficiency Score (ITES) introduces an incremental assessment to quantify the task-progress contribution of an individual collaborative action. Formally, given a historical action sequence \\(h_k\\) of agent k and newly executed actions \\(\\bar{a}\\) (either a request \\(\\bar{a}_{req}\\) or response \\(\\bar{a}_{resp}\\)), the ITES is computed as:\n\\(ITES(\\bar{a}, h_k) = TES(h_k \\cup \\bar{a}) - TES(h_k)\\) (3)\nThis differential formulation measures the marginal utility of action \\(\\bar{a}\\) by evaluating its impact on trajectory alignment with the RATs. It can be established that: \\(ITES(\\bar{a}, h_k) > 0\\) indicates \\(\\bar{a}\\) advances task progress, \\(ITES(\\bar{a}, h_k) \\le 0\\) suggests \\(\\bar{a}\\) fails to advance task progress (i.e., \\(\\bar{a}\\) is redundant / premature action or incorrect response)."}, {"title": "3.3 Evaluation Metrics", "content": "Built upon the TES which quantifies a piece of trajectory, PC measures the task progress of all involved agents while penalizing redundancy as a whole, and is defined as:\n\\(PC = \\frac{1}{K} \\sum_{k=1}^{K} TES(h_k)\\) (4)\nwhere K is the number of agents, \\(h_k = \\cup_{t=1}^{T_{max}} a_t^k\\) denotes the historical action sequence of agent k at time \\(T_{max}\\), which occurs either upon task completion or when the maximum time limit is reached. The PC offers a finer-grained assessment of task completion efficiency compared to boolean success label or success rate.\nIC evaluates the correctness of the LLM agent's collaboration initiation. IC is defined as:\n\\(IC = \\frac{1}{N} \\sum_{i=1}^{N} I (ITES(\\bar{a}_{req}^i, h_j) > 0)\\) (5)\nwhere N is the number of required collaborations, \\(I(\\cdot)\\) is the indicator function.  determines whether the i-th initiating collaboration request advances the task progress, thereby indicating whether the initiation is correct.   Similarly, RC assesses the correctness of the LLM agent's response to a collaboration request:\n\\(RC = \\frac{1}{N} \\sum_{i=1}^{N} I (ITES(\\bar{a}_{resp}^i, h_j) > 0)\\). (6)"}, {"title": "4 Benchmark", "content": "The proposed Collab-Overcooked benchmark builds upon the open-source Overcooked-AI (Carroll et al., 2019) and ProAgent (Zhang et al., 2024a), introducing two key upgrades: (1) The environment is divided into two parts, featuring resource isolation and asymmetric task knowledge for Agent Bob and Agent Alice respectively. This contrasts with Overcooked-AI, where all agents share a single environment with the same set of items\u00b9; (2) The benchmark encourages collaboration through natural language interactions, with some cases enforcing collaboration as a requirement for task success. Additionally, Collab-Overcooked provides APIs to configure new tasks and environmental settings, enabling the enhancement of LLM-MAS through scenario adaptation."}, {"title": "4.1 Environment", "content": "Our simulation environment is a grid-based kitchen simulation designed as a comprehensive testbed for analyzing collaboration behaviors in LLM-MAS. The environment comprises agents and configurable interactive elements. The interactive elements are dispensers, utensils, counters, and delivery location. Agents can freely retrieve raw materials from dispensers, place them into utensils for processing, and finally transfer the processed materials to other agents via counters or submit the required order through the delivery location. Notably, utensils process materials according to customizable synthesis tables, with each utensil having its distinct synthesis table. Agents can interact with these elements through predefined action primitives formatted as \u201cfunc(args)\u201d. For example, \"pickup(apple, ingredient_dispenser)\" clarifies action type, target material, and interactive element. Detailed information is provided in the Appendix A.1.\nThe environment executes agents' actions sequentially and broadcasts the global state at each timestep, encompassing agents' positions and the status of interactive elements. We have developed a comprehensive rule-based identification method for different types of invalid actions. The action validator evaluates the feasibility of actions, detecting issues such as mismatches between actions and the environment or incorrect action parameters. Upon rule violations, the validator issues error messages, prompting the agent to identify the error and regenerate the action accordingly."}, {"title": "4.1.1 Tasks Construction", "content": "Sequential process-specific tasks are commonly encountered in real-world scenarios, where a series of interdependent actions must be completed in a specific order to achieve a goal. We curate 30 process-specific tasks stratified into 6 complexity levels, requiring two agents to complete collaboratively. The task complexity level is determined by the minimum number of collaborative actions required, increasing linearly with difficulty. To mitigate LLM biases toward specific ingredients,"}, {"title": "4.1.2 Collaboration Designs", "content": "Collab-Overcooked benchmark imposes strict collaboration among agents. For this, we have two special designs: (a) Resource Isolation: agents operate in resource-isolated sub-environments, necessitating resource exchange via a shared \"counter\". This enforces collaborative dependency. (b) Asymmetric Task Knowledge: only one agent knows how to complete the task. Agents must communicate to synchronize task information."}, {"title": "4.2 Baseline", "content": "To evaluate the performance of LLM-MAS driven by different LLMs on our benchmark, we provide an in-context learning baseline. The baseline incorporates both memory and reflection mechanisms, enabling agents to communicate and collaborate freely using natural language while also incorporating error-handling capabilities. Additionally, we provide prompts in detail, which include the game rules, communication formats, and action space definitions, as well as error correction and reflection procedures. Figure 1 Part II illustrates an example of how agents advance task progress through collaborative communication in our benchmark. Detailed information regarding the baseline can be found in Appendix A.3 and Figure 7."}, {"title": "5 Experiment and Analysis", "content": ""}, {"title": "5.1 Benchmark Overview", "content": "Figure 2 presents key statistics of our benchmark, summarizing the minimum completion timesteps and collaborative actions across 6 complexity levels, which show monotonically increasing trends with task complexity. Two agents perform 8 and 6 actions respectively. The environment layout indicates asymmetric interactivity, with two agents accessing 4 and 5 interactive elements, respectively, while sharing observation. Additional statistics are provided in Appendix A.1."}, {"title": "5.2 Experiment Setting", "content": "We leverage 10 representative LLMs with parameter sizes ranging from 7B to over 671B+ as the foundation models for LLM-MAS. The open-source models include DeepSeek-V3 (Liu et al., 2024), different parameter versions of Qwen2.5 (7B, 14B, 32B, 72B) (Yang et al., 2024) and Llama3.1 (8B, 70B) (Dubey et al., 2024), all with instruction-tuned configurations. The closed-source models include: GPT-4o-1120, 01-mini, and GPT-3.5-turbo-0125. For the open-source models except for DeepSeek-V3, inference is performed using VLLM (Kwon et al., 2023) with temperature of 0.7 and top-p of 1. For each task, the task time limit factor is set to \\(\\gamma\\) = 1.5, and each task is evaluated through 10 repetitions. The hyper-parameter \\(\\beta\\) in TES is set to 0.95."}, {"title": "5.3 Results and Analysis", "content": ""}, {"title": "5.3.1 Task Completion Efficiency", "content": "Table 2 presents the Success Rate (SR) and PC of 10 LLMs across 6 task complexity levels. From these results, we derive three key insights: (1) Smaller LLMs (8B parameters or fewer) struggle with simple tasks, whereas increasing model size significantly enhances performance. This indicates the existence of a clear emergent scaling threshold for this task. (2) Scaling up LLMs effectively improves task completion efficiency for lower-level tasks but fails to enhance performance on high-complexity tasks. This suggests that current performance gains primarily stem from pattern memorization rather than cognitive reasoning. (3) When task complexity surpasses a critical threshold (level 4+), both closed and open-source models experience a performance collapse. This highlights the current limitations of LLMs in modeling long reasoning chains and capturing the complex, dynamic logic between tasks and environments."}, {"title": "5.3.2 Process-Oriented Evaluation", "content": "Figure 3 shows the process-oriented evaluation of LLM-MAS. Among closed-source models, GPT-4o demonstrates the strongest collaboration capability, while DeepSeek-V3 performs comparably to other open-source models. We derived three key insights from the experimental results. First, most models (14B+) exhibit higher RC than IC, indicating that LLMs are better at responding to collaboration than initiating collaboration. This is a result of their strong instruction-following capabilities, which make initiating collaboration the primary bottleneck for most LLMs. Second, the collaboration capability of all LLMs declines with increasing task complexity. Moreover, the decline rate is similar across all models, indicating that their ability to maintain collaboration capability performance is similar. Despite the scale-up of the models, there is no corresponding improvement in their ability to sustain collaboration capability. Third, compared to GPT-3.5, the CoT-trained model 01-mini demonstrates superior collaboration performance on simpler tasks. Despite the inability to maintain collaboration capability performance as task complexity increases, the improved performance on simpler tasks underscores the potential for further exploration of the CoT-training paradigm in the context of agent collaboration."}, {"title": "5.3.3 Human Performance Evaluation", "content": "To establish a performance ceiling, we experimented with 10 human participants completing tasks across 6 complexity levels. We designed a human-computer interaction interface to enable human participants to simulate agent interactions within the environment. Detailed experimental design can be found in Appendix C.2.\nAs shown in Figure 4, human participants achieved near-perfect and stable performance across all complexity levels, while GPT-4o, the state-of-the-art model in our benchmark, showed a decline in collaboration capability as task complexity increased. This highlights the limitations of LLM-MAS in completing sequential, process-specific tasks in a zero-shot setting, where simply scaling up the LLM is insufficient to improve collaboration performance to human-like levels. The model's reliance on pre-trained knowledge does not fully enable it to adapt to the dynamic and collaborative environment of complex tasks, emphasizing the need for more advanced mechanisms or parameter fine-tuning to enhance its collaborative capabilities to human-like levels."}, {"title": "5.3.4 Failure Analysis", "content": "To investigate the temporal dynamics of initiating and responding to collaboration, we selected 4 LLMs and tested them on 5 collaborative actions from level 3 tasks. Using environmental states and memory fragments from interaction trajectories, we constructed prompts to elicit both initiation and response behaviors, evaluated using the ITES function. As shown in Figure 5(a), all models perform well on the first collaborative action, but performance declines in subsequent actions. Regarding initiating collaboration capability, agents fail to identify the appropriate actions needed to advance the task in later steps, revealing a misalignment between environmental states and task flow (further analysis in Appendix C.3.1). The confusion matrix shows a correlation between initiating collaboration and responding to collaboration, indicating that response accuracy depends on the correctness of initiation, confirming that initiating collaboration capability is the primary bottleneck.\nWe isolate the influence of task decomposition by redesigning the recipes with explicit step-to-action mappings, where each step corresponds to a single action in recipe (details in Appendix C.3.2). Figure 5(b) shows this modification leads to performance improvements. However, the gradual decline in accuracy persists, indicating that the degradation of collaboration capabilities is not attributable to limitations in LLM task decomposition abilities.\nWhile maintaining step-to-action mappings, we further examined the sensitivity of collaboration performance to position dependencies by rearranging the task workflow (details in Appendix C.3.3). Moving the target collaborative action to the first step led to significant performance improvement, as shown in Figure 5(c). Previously underperforming subsequent actions, when placed at step 1, showed notable gains, and performance degradation largely disappeared. This highlights strong positional dependence in sequential, process-specific tasks, which we attribute to pretraining biases favoring early-sequence elements and limited context tracking in extended action chains."}, {"title": "5.4 Future Challenges", "content": "To enhance collaboration, we propose using process-oriented metrics, such as IC and RC, which evaluate the capabilities of initiating and responding to collaboration by scoring each collaborative interaction. Targeted improvements based on these metrics, particularly for smaller models, may help address existing weaknesses and enhance overall performance.\nA key challenge in LLM-MAS collaboration is maintaining stable performance, whether within a single task or across tasks of varying complexity. Additionally, a significant gap persists between LLMs and human collaborators, with humans consistently outperforming models. Closing this gap requires improving models' adaptability and robustness to better emulate human collaboration."}, {"title": "6 Conclusion", "content": "We introduce the Collab-Overcooked Benchmark, a framework for evaluating LLM-MAS collaboration from both end-to-end and process-oriented perspectives. Experiments across 10 LLMs reveal notable performance gaps, with a key bottleneck in maintaining consistent performance across a single task or tasks of varying complexity. These findings highlight the challenge for further advancements in model adaptability and robustness to enhance collaboration capability across diverse scenarios."}, {"title": "Limitations", "content": "The Collab-Overcooked Benchmark is introduced in our paper and we explore methods for evaluating the collaboration capabilities of LLM-MAS using both end-to-end and process-oriented approaches. However, there are three limitations to our work. First, all of our tasks are sequential and process-specific. While we assume that RATs can be exhaustively enumerated, making it possible to use exhaustive RATs as labeled data for evaluating the collaboration capabilities of LLM-MAS. However, in environments with highly complex state and action spaces, RATs are difficult to exhaustively enumerate. In such cases, only representative RATS can be listed as evaluation data, which introduces potential bias into our evaluation methodology. Second, due to the complex mechanisms of LLM-MAS, such as communication, memory, and reflection, the prompts are relatively long (approximately 2,000 tokens, with variation depending on the tokenizer used by the LLM). Additionally, process-oriented evaluation requires substantial interaction data, which leads to both low evaluation efficiency and significant token consumption, which is the common challenge across current methods for evaluating LLM-MAS capabilities. Third, the baseline used to evaluate LLM-MAS is composed of relatively simple structures, with the agent possessing only basic memory and reflection mechanisms, leaving substantial room for optimization."}, {"title": "A Benchmark Detail", "content": "In this section, we provide a detailed overview of the Collab-Overcooked Benchmark environment design. We first introduce the interactive elements within the environment along with their layout. Next, we describe the action space available to agents. Finally, we present the methodology for defining layouts, enabling flexible modifications to the environment."}, {"title": "A.1 Environment", "content": "Due to our resource isolation design, the interactive elements available to each agent differ. Figure 6 illustrates the interactive elements that both agents can engage with. We adopt the \"Forced Coordination\" level design from Overcooked-AI (Carroll et al., 2019), where the two agents share only a single interactive element: the counter. This design necessitates resource exchange between agents to complete tasks.\nWe categorize interactive elements into three types: utensils, dispensers, and others. The details are as follows:\n\u2022 Utensils: These interactive elements take one or more ingredients as input and process them according to a predefined synthesis table, transforming them into new ingredients.\n\u2022 Dispensers: Agents can retrieve ingredients or dishes from these elements, with the available items being predefined.\n\u2022 Others: The counter serves as a critical interactive element for resource exchange between agents, allowing them to freely place or retrieve ingredients. The delivery location is where agents submit task outcomes. If the submitted ingredient meets the task requirements, the task is considered successful. Otherwise, incorrect submissions result in the removal of the submitted ingredient from the environment, often leading to task failure."}, {"title": "A.1.1 Interactive Elements", "content": "The action space of each agent consists of a series of functions in the format \u201cfunc(args)\u201d, which facilitate interactions with the environment or collaboration with other agents. Agent actions are categorized into shared actions and exclusive actions. Shared actions are common to both agents and include actions such as \"pickup\" (for picking up ingredients), \u201cplace_obj_on_counter\" (for interacting with the counter), \u201cput_obj_in_utensil\" (for placing ingredients into utensils), and \u201cwait\u201d. Exclusive actions, on the other hand, arise from the differing interactive elements in each agent's environment. For example, Agent Bob has access to a pot, allowing it to perform the \u201ccook\u201d action, whereas Agent Alice, lacking a pot, cannot perform this action. Conversely, Agent Alice can interact with the chopping board to perform the \"cut\" action, which Agent Bob cannot. The specific actions available to Agent Alice and Agent Bob are listed as follows:"}, {"title": "A.1.2 Action Space", "content": "To accurately assess collaboration capabilities, we require that when an agent initiates collaboration, the initiating agent must encapsulate the desired action for the responding agent within a \"request\". This mechanism is utilized for calculating IC and RC. For example, if Agent Bob wants Agent Alice to retrieve an apple for it, Agent Bob will generate the following output: \"request(pickup(apple, ingredient_dispenser)); request(place_obj_on_counter())\u201d. This request explicitly specifies the sequence of actions that Agent Alice is expected to execute, ensuring that the collaboration process is systematically coordinated."}, {"title": "A.1.3 Layout Definition Method", "content": "We follow the environment design principles of Overcooked-AI (Carroll et al., 2019) and ProAgent (Zhang et al., 2024a), enabling customization through external layout files. Compared to these prior works, our framework offers a broader range of configurable elements. For instance, the \u201corder_probability\u201d parameter allows users to adjust the probability of tasks appearing randomly in the environment, while the \u201crecipes\u201d parameter enables customization of the synthesis list for each utensil. Further details can be found in the examples provided in our GitHub repository's layout files. Through our enhancements, nearly all aspects of the environment can be customized via a single external file, significantly enhancing the flexibility and scalability of our framework."}, {"title": "A.2 Tasks Construction", "content": "In this section, we provide detailed information about tasks, including task complexity level, task list, task recipe, and task RATs."}, {"title": "A.2.1 Task complexity level", "content": "To distinguish the complexity level of each task, we define four types of collaborative behaviors performed by the agents. The complexity level of a task is determined based on the minimum number of collaborative behaviors required to complete the task. The four types of collaborative behaviors are as follows:\n\u2022 Acquiring New Ingredients: This behavior involves retrieving an ingredient from the Ingredient Dispenser. For example, Agent Alice might pick up an onion or an apple from the dispenser.\n\u2022 Processing the Ingredients: This behavior involves placing ingredients into a cooking utensil. For example, Agent Alice might place an ingredient into a chopping board or a blender.\n\u2022 Acquiring a New Dish: This behavior involves retrieving a new dish from the Dish Dispenser. This action consists of a single step where Agent Alice picks up a dish.\n\u2022 Processing the Ingredients by Agent Bob: Similar to the first behavior, but performed by Agent Bob. This includes behaviors like placing an ingredient into a pot or an oven.\nEach collaborative behavior corresponds to several collaborative actions. The complexity level of a task is calculated by summing the total number of collaborative actions required from each behavior. Specifically, the number of actions in each of the four categories is counted based on the task's requirements. This approach ensures that tasks with more complex or numerous collaboration requirements are considered more difficult than those with fewer actions. Table 3 provides statistical data on collaborative behaviors and collaborative actions.\nEach task's RATs provide the exact number of actions for each type of collaboration, which is used to determine the total complexity level for that task. The complexity calculation allows for a comparison of tasks, ensuring that they are evaluated on the basis of their collaborative complexity."}, {"title": "A.2.2 Task List", "content": "Table 4 presents a list of task names across 6 complexity levels, comprising a total of 30 tasks. As indicated by the task names, tasks within the same complexity level share identical workflows, with the only variation being the selection of ingredients. This design aims to mitigate potential biases in LLMs towards specific ingredients, thereby reducing evaluation discrepancies caused by such biases."}, {"title": "A.2.3 Recipes", "content": "Each task corresponds to a recipe that outlines the workflow required to complete the task, including the necessary ingredients and cooking steps. There are two important aspects to note regarding the recipe: First, one cooking step typically involves multiple actions by the agents. This necessitates that the agents carefully decompose the cooking step into specific actions after thoroughly understanding both the recipe and the environment. Second, some cooking steps can be executed in a different order. For instance, when multiple ingredients require pre-processing, followed by combining the processed ingredients into a utensil for further preparation, the order in which the ingredients are preprocessed can be interchanged. This decision is typically made by the agents, leading to the possibility of multiple valid RATs for the same task. Allowing such flexibility is both reasonable and aligned with real-world practices. Listing 2 is an example of the recipe for \u201cBaked Pumpkin Soup\u201d, which includes the recipe name, required ingredients with quantities, and detailed cooking"}, {"title": "A.2.4 Referential Action Trajectory", "content": "To evaluate the agents' collaboration capabilities both in terms of end-to-end and process-oriented metrics, we provide the RATs for each task. Given that our tasks are sequential process-specific, we assume that the RATs can be exhaustively enumerated or largely known. We have annotated the RATS for each task, which include the optimal referential action sequences for both agents to complete the task. Each RAT ensures that the agents can accomplish the task with a minimal number of actions, while also employing the optimal strategy to parallelize certain actions for efficiency. A task may have multiple valid RATs, for example, the order in which two ingredients are retrieved may not affect the overall task completion time. During evaluation, the TES and ITES functions select the RAT with the highest matching score as the reference for assessment. Listing 3 provides an example of the RATs for the \"Baked Pumpkin Soup\" task, with separate RATs for each of the two agents. Because the \"Baked Pumpkin Soup\" task has only one completed route, there is only one RAT."}, {"title": "A.3 Baseline", "content": "In this section, we introduce the baseline structure and prompt design we use to test different LLMs."}, {"title": "A.3.1 Baseline Construction", "content": "Figure 7 illustrates the structure of the baseline and provides an example of agents interacting and collaborating to complete a task within our benchmark. The baseline architecture consists of an Instruction-Builder, Planner, Communication, Error-Handling, Memory, and Reflection modules. The structure remains identical across different agents, with variations arising only in the environment descriptions, action spaces, and task-specific knowledge provided within the prompts.\nThe Instruction-builder is a rule-based module responsible for managing and integrating the prompts for each agent. It reads the state dictionary from the environment and fills in a prompt template. The prompt template includes both fixed prompts and slot-based prompts. Fixed"}, {"title": "A.3.2 Prompt", "content": "In this section, we provide a detailed description of the prompts used to drive LLM-based agents. Since LLM-MAS involves multiple agents interacting within an environment, the prompt design is inherently more complex than that of a single-agent system. Each request to the LLM typically consumes approximately 2,000 tokens, with slight variations depending on the specific tokenizer used by the LLM. To structure this complexity, we categorize the prompts into three key components: game rules, action space definitions, and input-output format specifications. We will elaborate on each component and provide illustrative examples to demonstrate their implementation.\nThe game rules part of the prompt defines the task objective, agent roles, and interaction constraints. It outlines the step-by-step workflow for completing an order, emphasizing task division, coordination, and strict adherence to recipe instructions. Figure 10 shows all the content of the game rule prompt.\nThis part of the prompt defines the action space for Agent Bob, following the action specification method used in ProAgent (Zhang et al., 2024a). It categorizes actions into operation actions (directly executable by the agent) and collaborative actions (requests for the teammate to perform an action). Figure 11 shows the prompt of Agent Bob's action space.\nThe input-output format part defines the structured information provided to the agent at each step and the required response format. The input includes past action history, lessons from failures, available utensils, the current order, the planned sequence of actions, and past conversations. The output consists of three fields: analysis (environment assessment and reasoning for actions), plan (the agent's planned actions for the next step), and say (communication with the teammate, if necessary). This structured format ensures that the agent can make informed decisions, coordinate effectively, and execute tasks systematically. shows all the content of the input-output format prompt."}, {"title": "B Evaluation", "content": ""}, {"title": "B.1 Details in TES", "content": "The TES is formally expressed as:\n\\(TES(h_k) = max_{j} {\\frac{(1 + \\beta^2)D_{max}(h_k, g^i)}{m_k + \\beta^2 n_k}}\\) (7)\nwhere \\(h_k = \\cup_{t=1}^{T} a_t = \\{a_1, a_2, ..., a_{n_k}\\}\\) is the historical action sequence up to timestep T of agent k, \\(g = \\{g^i\\} \\in R\\) is j-th RAT of agent k, \\(\\beta\\) is the hyper-parameter balancing the weight of task progress and redundancy, and \\(D_{max}(h_k, g^i)\\) computes the length of the longest"}]}