{"title": "Just Leaf It: Accelerating Diffusion Classifiers with Hierarchical Class Pruning", "authors": ["Arundhati S. Shanbhag", "Brian B. Moser", "Tobias C. Nauen", "Stanislav Frolov", "Federico Raue", "Andreas Dengel"], "abstract": "Diffusion models, known for their generative capabilities, have recently shown unexpected potential in image classification tasks by using Bayes' theorem. However, most diffusion classifiers require evaluating all class labels for a single classification, leading to significant computational costs that can hinder their application in large-scale scenarios. To address this, we present a Hierarchical Diffusion Classifier (HDC) that exploits the inherent hierarchical label structure of a dataset. By progressively pruning irrelevant high-level categories and refining predictions only within relevant sub-categories, i.e., leaf nodes, HDC reduces the total number of class evaluations. As a result, HDC can accelerate inference by up to 60% while maintaining and, in some cases, improving classification accuracy. Our work enables a new control mechanism of the trade-off between speed and precision, making diffusion-based classification more viable for real-world applications, particularly in large-scale image classification tasks.", "sections": [{"title": "1. Introduction", "content": "Generative models are designed to capture the full spectrum of a dataset distribution, offering a rich and detailed understanding of the data they represent [14, 22]. This comprehensive grasp of data allows them to not only create new content but also provide deep insights into their characteristics and structures [15, 19]. Moreover, these insights can significantly benefit downstream tasks like image classification [4, 5, 9]. Nonetheless, over the past decade, the focus of many generative techniques has predominantly been on content generation rather than harnessing their potential for discriminative tasks [2, 11, 18, 26, 27].\nAmong generative models, diffusion models emerge as a particularly powerful subclass due to their ability to produce exceptionally high-quality output images through an iterative Markovian process of adding and removing noise [1, 12, 16, 18, 20]. Recently, the research community has shifted towards repurposing pre-trained diffusion models for classification tasks in a zero-shot manner, signaling a pivotal move toward using generative models as discriminators, so-called diffusion classifiers [3, 6, 17]. More specifically, diffusion models that learned $p(x | c)$ can be easily converted into classifiers by exploiting the Bayes' theorem to derive $p(c | x)$. Thus, given an image x and a set of $N_C$ possible classes ${c_i}_{i=1}^{N_c}$, we can calculate the likelihood of x belonging to each class $c_i$.\nIn practice, this means adding noise to x and estimating the expected loss of noise reconstruction via Monte Carlo, i.e., through repeated calculations and averaging. This pro-"}, {"title": "2. Related Work", "content": "Diffusion models have disrupted the landscape of generative models, challenging the longstanding dominance of GANs [11,14] and setting a new standard in generating high-quality, realistic data [8]. Broadly speaking, they capture"}, {"title": "3. Methodology", "content": "This section provides a brief overview of diffusion classifiers and introduces our proposed Hierarchical Diffusion Classifier (HDC), as shown in Figure 2 and outlined in Algorithm 1."}, {"title": "3.1. Diffusion Classifier Preliminaries", "content": "The diffusion classifier is based on the formulation introduced by Li et al. [17]. The key idea is that, given a trained diffusion model $p_\\theta$, we can leverage the predictions of the diffusion model, $p_\\theta(x | c_i)$, to infer the probability of a class $c_i$ given an input x using Bayes' theorem to derive"}, {"title": "3.2. Hierarchical Diffusion Classifier (HDC)", "content": "As shown in Equation 5 and in our introductory example Figure 1, the traditional diffusion classifiers need to evaluate all possible classes, which can be computationally expensive and time-consuming. To ease the computational burden, we propose a Hierarchical Diffusion Classifier (HDC), which leverages the hierarchical label structure of a dataset to perform more efficient and accurate classification.\nThe core idea is to evaluate labels hierarchically and to progressively narrow down the possible classes by pruning higher-level categories (such as \"animals\" or \"tools\") into more specific categories and actual classes (such as \"Hammerhead Shark\u201d or \u201cScrewdriver\"). The higher-level categories are called \u201csynonym-sets\u201d or \u201csynsets\u201d. By iterating over the labels hierarchically, we can significantly reduce the number of classes that need to be evaluated, leading to faster predictions with potentially higher accuracy.\nMore formally, let $T_h = (N, E)$ represent a hierarchical label tree of depth h, nodes N, and edges E. Each node $n \\in N$ in the tree corresponds to a synset (or class for leaf nodes), and $n_{root}$ is the root. Moreover, let $Children(n) \\subseteq N$ denote the set of child nodes of n, and $c_n$ represent the synset or class label of a node n. We set $Children(n) := n$ if n is a leaf node to address imbalanced label trees.\nOur proposed HDC aims to prune irrelevant classes and only considers more relevant classes (nodes) as we descend the tree within a selected set of nodes. The set of selected nodes is denoted as $S_d^{selected}$ where d denotes the traverse step count starting from 1 and ending in h (depth of the label tree). We start with the root node $n_{root}$, i.e., $S_1^{selected} = \\{ n_{root} \\}$, which contains the highest-level categories as children."}, {"title": "3.3. Tree Setup", "content": "Our proposed HDC leverages the Wordnet hierarchy upon which the ImageNet-1K ontology is constructed [7]. The images in the ImageNet-1K dataset are grouped into \"synonym-sets\" or \"synsets\" with 12 subtrees comprising around 80,000"}, {"title": "3.4. Pruning Strategies", "content": "Our proposed HDC method allows many pruning strategies to be implemented that balance accuracy and computational efficiency. We implemented two primary pruning strategies, one that works with fixed ratios of pruned nodes and one that adapts dynamically depending on the distribution of error predictions. In more detail:\n\u2022 Strategy 1 - Fixed Pruning: We select the top-k nodes with the lowest errors at each hierarchy level, defined by a pruning ratio $K_d$.\n\u2022 Strategy 2 - Dynamic Pruning: In this approach, we keep only nodes within two standard deviations of the minimum error at each level, allowing a more adaptive, data-driven selection.\nIn contrast to Dynamic Pruning, Fixed Pruning allows for finer control over the trade-off between accuracy and runtime. Our proposed pruning strategies offer varying degrees of control over the balance between accuracy and runtime, adapting to unique hierarchical structures for greater scalability. Unlike traditional diffusion classifiers, which evaluate all classes for each input image, our pruning strategies strategically select candidate classes at each level, reducing computational load while maintaining similar class precision."}, {"title": "4. Experimental Setup", "content": "This section describes our experimental setup for testing the performance and reliability of HDC on ImageNet-1K, which includes a discussion about how to construct the hierarchical label tree and specifics to the classifier itself, prompting, and pruning strategies. Our code can be found on GitHub\u00b9."}, {"title": "4.1. Classifier Setup", "content": "For our classifier, we built on the efficient framework established by Li et al. [17], with added modifications tailored for hierarchical processing and pruning of candidate"}, {"title": "4.2. Prompt Engineering", "content": "The class labels are converted to the form \u201ca photo of a <class label>\u201d using the template from the original experiments. Additionally, inspired by Radford et al. [21], we experiment with prompt templates \"A bad photo of a <class label>\", \"A low-resolution photo of a <class label>\" and \u201citap of a <class label>\u201d for ImageNet-1K."}, {"title": "5. Results", "content": "This section presents our experimental results, evaluating different aspects of HDC, which were outlined previously: pruning strategies, prompt engineering, stable diffusion variations, and, finally, an overall evaluation of per-class accuracy."}, {"title": "5.1. Pruning Strategies", "content": "Table 1 highlights the results of our HDC across different pruning strategies compared to the classical diffusion classifier. As observed, both strategies (as outlined in subsection 3.4) show marked improvements in runtime compared to classical diffusion classifiers, and each is suited to different prioritizations of speed versus accuracy.\nFor instance, Strategy 1 yields the best trade-off results on ImageNet-1K, achieving significant runtime reductions (up to 980 seconds) with an top-1 accuracy boost of 0.20 percentage points. By employing Strategy 2 (selecting candidates"}, {"title": "5.2. Stable Diffusion Versions", "content": "We evaluated the HDC using different Stable Diffusion (SD) versions to assess its flexibility and performance across generative backbones, as summarized in Table 2. The results reveal that SD 2.0 provides the best trade-off between accuracy and inference time. Specifically, when using Strategy 1, SD 2.0 achieved the highest Top-1 accuracy at 64.14% with an inference time of 980 seconds. In contrast, SD 1.4 demonstrates the fastest inference time of 710 seconds when paired with Strategy 2, albeit with a significant top-1 class-accuracy reduction to 54.77%."}, {"title": "5.3. Prompt Engineering", "content": "Inspired by Radford et al. [21], we evaluated different prompt templates to assess their impact on accuracy and inference time, as shown in Table 3. The default prompt, \u201ca photo of a <class label>,\u201d consistently achieved the best performance, suggesting that a straightforward prompt yields robust results across classes. Other templates, such as \u201ca bad photo of a <class label>\u201d and \u201ca low-resolution photo of a <class label>,\u201d resulted in a slight drop in accuracy without significantly affecting inference time.\nThe rationale for testing alternative prompts stems from a hypothesis that prompts hinting at lower-quality images might help the classifier generalize better to real-world cases with variable quality, capturing diverse visual characteristics. For instance, using terms like \u201cbad\u201d or \u201clow-resolution\u201d was expected to enhance robustness to noisy or degraded inputs. Interestingly, however, the results show that the simpler, unmodified prompt performs best, indicating that the hierarchical model likely benefits from a more neutral prompt"}, {"title": "5.4. Overall Accuracy vs. Inference Time", "content": "In summary, Table 4 shows the overall accuracy and inference time across different pruning strategies. The baseline diffusion classifier achieves an accuracy of 64.90% with an inference time of 1600 seconds, providing a reference for both speed and precision.\nOur HDC using Strategy 1 demonstrates new state-of-the-art accuracy for diffusion classifiers with 65.16%, while reducing the inference time by nearly 40% to 980 seconds. This indicates that HDC can not only improve classification performance but also benefits from a considerable reduction in computational load. The reduction in processing time while maintaining similar accuracy makes Strategy 1 a balanced choice for high-accuracy applications where inference speed is also a priority.\nSimilarly, HDC with Strategy 2 leverages dynamic pruning to further accelerate inference. While it records a slight drop in accuracy to 63.33%, Strategy 2 reduces inference time to 650 seconds - approximately 60% faster than the baseline. This strategy demonstrates the potential of HDC for use cases requiring faster response times, with only a marginal trade-off in classification performance."}, {"title": "6. Limitations & Future Work", "content": "While our method substantially improves inference time and maintains competitive accuracy, several limitations must be addressed in future work.\nThe efficiency gains provided by the hierarchical pruning strategy heavily depend on the depth and balance of the underlying label tree. Datasets with shallow hierarchies or those lacking well-defined parent-child relationships may not benefit as significantly from our method. Furthermore,"}, {"title": "7. Conclusion", "content": "In this work, we introduced the Hierarchical Diffusion Classifier (HDC), a novel approach for accelerating diffusion-based classification by utilizing hierarchical class pruning. Our results on the ImageNet-1K dataset demonstrate that HDC significantly reduces inference time, achieving up to a 60% speedup over traditional diffusion classifiers while maintaining and, in some cases, even improving classification accuracy. This improvement is achieved by progressively narrowing down relevant class candidates, pruning out high-level categories early in the process, and focusing only on specific, contextually relevant subcategories.\nOur experiments highlight HDC's adaptability, showing that different pruning strategies (such as Top-k Pruning and Threshold Pruning) offer customizable trade-offs between inference speed and accuracy. This versatility makes HDC suitable for diverse applications, from high-accuracy image classification tasks to real-time scenarios where rapid inference is critical."}], "equations": [{"number": "1", "content": "Po(ci | x) = \\frac{p(ci) po(x | ci)}{\\sum_{j=1}^{N_c}p(cj) po(x | cj)}"}, {"number": "2", "content": "Po(ci|x) = \\frac{po(x | ci)}{\\sum_{j=1}^{N_c} Po(x | cj)}"}, {"number": "3", "content": "d (\u03b5, x, c) = ||\u03b5 \u2013 \u03b5\u03b8(x, c) ||2"}, {"number": "4", "content": "Po(ci|x) = \\frac{exp{-E_{t,\\epsilon}d (\\epsilon, x_t, C_i)}}{\\sum_{j=1}^{N_c} exp{-E_{t,\\epsilon}d (\\epsilon, x_t, C_j)}}"}, {"number": "5", "content": "Po (Ci|x) \u2248 \\frac{\\frac{1}{M} exp {E_{t, \\epsilon} (\\delta, X_t, C_i, C_j)}}{\\Delta (\\epsilon, x_t, c_i, C_j) = d (\\epsilon, x_t, c_i) \u2212 d (\\epsilon, x_t, c_j)}"}, {"number": "6", "content": "E_{t,\\epsilon}d (\\epsilon, x_t, c_j) \u2248 \\frac{1}{M} \\sum_{i=1}^{M} d (\\epsilon_i, X_i, c),\nxi = \\sqrt{\\bar{a}_{t_i}}x + \\sqrt{1 - \\bar{a}_{t_i}}\\epsilon_i"}, {"number": "7", "content": "\u2200ns \u2208 Sselected: \u2200n \u2208 Children (ns) :\nEn = Et,ed (E, Xt, Cn)."}, {"number": "8", "content": "Sd+1\\text{selected}\n= {n \u2208 Children (ns) | ns \u2208 Sselected\n\u0394 en < threshold(Ka)}."}, {"number": "9", "content": "Cn final \\text{where }nfinal = arg min en\\n\u2208Sh select"}]}