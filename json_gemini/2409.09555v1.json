{"title": "ENHANCING PRINTED CIRCUIT BOARD DEFECT DETECTION THROUGH ENSEMBLE LEARNING", "authors": ["Ka Nam Canaan Law", "Mingshuo Yu", "Lianglei Zhang", "Yiyi Zhang", "Peng Xu", "Jun Liu", "Jerry Gao"], "abstract": "The quality control of printed circuit boards (PCBs) is paramount in advancing electronic device\ntechnology. While numerous machine learning methodologies have been utilized to augment defect\ndetection efficiency and accuracy, previous studies have predominantly focused on optimizing\nindividual models for specific defect types, often overlooking the potential synergies between different\napproaches. This paper introduces a comprehensive inspection framework leveraging an ensemble\nlearning strategy to address this gap. Initially, we utilize four distinct PCB defect detection models\nutilizing state-of-the-art methods: EfficientDet, MobileNet SSDv2, Faster RCNN, and YOLOv5.\nEach method is capable of identifying PCB defects independently. Subsequently, we integrate these\nmodels into an ensemble learning framework to enhance detection performance. A comparative\nanalysis reveals that our ensemble learning framework significantly outperforms individual methods,\nachieving a 95% accuracy in detecting diverse PCB defects. These findings underscore the efficacy\nof our proposed ensemble learning framework in enhancing PCB quality control processes.", "sections": [{"title": "Introduction", "content": "A printed circuit board (PCB) is a medium used to mechanically support and electrically connect various electronic\ncomponents in a circuit. PCBs play a crucial role in almost every electronic device, from smartphones, computers,\nand self-driving cars to data centers [1]. As electronic devices become increasingly complex, and PCBs must be\nmanufactured with higher quality to meet customer demand [2]. Images of PCBs exist in two types: component\nPCB and bare PCB images. As component PCB images are composed of diverse individual semiconductor cells, it is\nchallenging to use computer vision to detect defects. Bare PCBs do not include through-holes or electronic components,\nmaking it easy to identify and recognize defects or missing components [3]. This paper focuses on detecting the defects\nof bare PCBs. If defects cannot be detected precisely, many produced boards will likely be scrapped eventually, which\nis both wasteful and costly [4]. Thus, defect detection is a critical step in quality control to improve yield and profit in\nmanufacturing PCBs."}, {"title": "Related Work", "content": "PCB defect detection is an organized process that includes multiple stages designed to pinpoint faults within the PCBs.\nThis process encompasses a range of inspection techniques, data analysis strategies, and quality assurance practices to\nguarantee the reliability and quality of electronic devices. In this section, we will explore the related work that applies\nvarious methods for detecting PCB defects under diverse conditions.\nAutomatic optical inspection (AOI) refers to using automated optical systems and technologies to identify faults. A\ncommon approach is to visually scan the surface of PCBs for various surface feature defects. These systems employ a\ncombination of hardware and software components to analyze PCBs quickly and accurately and reduce the reliance on\nmanual inspection. The main hardware components of automatic inspection systems are the material and component\nhandling system, illumination system, image acquisition system, and processor [6]. It should be noted that each\nmanufacturer of automatic inspection systems utilizes different inspection algorithms and lighting techniques, and each\nof these systems may have varying strengths and weaknesses depending upon the item/product it inspects [7].\nImage processing methods play a critical role in analyzing the captured images of AOI systems. Image processing\nmethods are used to enhance the quality of images, extract relevant features, and identify anomalies that may indicate\ndefects [8]. For example, dust and strain may reduce image quality during inspection. In general, there are three\ncommon methods to deal with these quality issues. The first method is called histogram equalization, which enhances\nimages by remapping the grayscale levels to remove the noise of the data [3]. While this method can make images\nmore detailed with higher quality, it may compress some grayscales during the remapping process. The second method\nleverages wavelet transform that is widely used in signal and image processing [9\u201311]. This method has characteristics\nsuch as low entropy, multi-resolution, and decorrelation. It is also good at removing image noises because it can\novercome the issue of window size not varying with frequency. However, the selection of wavelet basis is complex, and\nthe results of wavelet basis analysis are different.\nThe third method is based on machine learning methods, such as convolutional neural networks (CNN), generative\nadversarial networks (GAN), and random forest regression (RFR) [12]. For example, Gampala et al. [13] used a fully\nconnected neural network (FCNN) to solve motion blur problems and enhance the quality of images. The input can be\npartial images that save the storage. However, there is some lack of noise training for multi-frame deblurring. Lin and\nMenendez [14] proposed an image-generating and processing method that denoises the target region of images. This\nmethod can be applied in different pad positions. However, some defects in generated images remain, such as blurred\nimage edges and low resolution. Mironic [15] presented a GAN-based method that can remove dust and scratches from\nthe scanning of films. This method achieved better performance than previous solutions in terms of PSNR and SSIM\nquality metrics. However, GAN can result in a blurry image after dirt cleaning, and it is possible to miss some scratches.\nBuilding a deep learning model typically involves several stages, including data collection, framework design, model\ntraining, and performance evaluation [16\u201320]. CNN-based models have achieved a lot of success in computer vision\nfields, such as image classification, recognizing faces, instance segmentation, and tracking targets [21]. The success\nof CNN-based models can be attributed to two advantages [2]. First, CNN-based methods are able to extract image\nfeatures efficiently, simplifying the image pre-processing process so that the detection accuracy and speed can be\npromoted effectively. Second, the methods are robust to the environment and noise.\nRecently, many architectures have been applied in a wide range of industrial defect detection, such as PCB defect\ndetection [2], cosmetic defect detection [22], and automotive defect defection [23]. Various models have been proposed\nto solve the detection problems, including ResNet, RCNN, AlexNet, CNN-VGG16, and RB-CNN. For example, Hu and\nWang [24] proposed Faster RCNN with ResNet50 to detect six types of PCB defects: solder ball, pinhole, spur, mouse\nbite, and short. Their model has better accuracy than other benchmark methods but is sensitive to different datasets. Lu\net al. [25] presented AlexNet to recognize defects in PCB images. A ReLU Nonlinearity function is used to solve the\ngradient vanishing problem in deep networks. However, this model has higher requirements on GPU. Ge et al. [26]\nproposed an improved model YOPCB for PCB images. However, an annotation step is required before model training.\nRevaud et al. developed a model called [27] CNN-VGG-16 to detect five types of defects: short, mouse bite, coppers,\nopen, and spur. However, their model is limited by the feature selection algorithm.\nAll models above have their advantages and disadvantages, and their performance also depends on specific datasets.\nFor example, Faster-RCNN with ResNet50-FPN outperforms RetinaNet and YOLOv3 in some datasets [24]. Zhang\net al. [22] showed that CS-ResNet has the highest sensitivity, G-mean, and the lowest misclassification cost. Zhang\net al. [28] demonstrated that VGG obtains the highest mAP and high precision and recall, which means it has high\naccuracy. Therefore, how to reduce the impact of errors caused by datasets or training processes is critical in practice.\nEnsemble learning is an effective technique that has increasingly been adopted to combine multiple learning models to\nimprove overall prediction accuracy [29]. These ensemble techniques have the advantage of alleviating the small sample\nsize problem by incorporating multiple learning models to reduce the potential for overfitting the training data [30,31]."}, {"title": "Ensemble Learning for PCB Defects Detection and Classification", "content": "In this section, we present the proposed framework, consisting of data preprocessing methods and an ensemble learning\nmodel for defect detection. Specifically, this work focuses on detecting the following types of defects: mouse bite,\npinhole, spurious copper, open circuit, spur, scratch, short, missing hole.\nData preprocessing is a crucial step in building models for defect detection. It involves preparing and transforming\nraw data into a format suitable for the training requirements of methods. We use PCB images from electronics and\nsemiconductor industries as primary datasets to collect raw defect information. During the data preprocessing process,\nthere are three challenges in dealing with PCB images. The first challenge comes from the diversity of data sources. All\nPCB images are collected from outside sources, and each outside source has its format standards, such as image size and\nresolution. The second one is related to image quality. The raw images are collected from a camera or computer vision\nand may contain noise, artifacts, or irrelevant information. Such noise information could interfere with the model's\nability to detect defects. For example, if an image is blurred or its details are not precise, it would be hard to distinguish\nan open circuit from a mouse bite according to this image. The third one is about the ground truth information of PCB\ndefects. After raw images are collected, the ground truth information of PCB defects is unknown in each image. While\nsome PCBs have no defects, others may have multiple defects. How to capture defect information from images is\ncritical to the performance evaluation. To handle these challenges, we leverage different data preprocessing methods to\ntransform collected datasets.\nTo solve the first challenge, we combine and uniform all datasets from different data sources. Because the high\nresolution of image data affects the detection accuracy of the model and the cost of computing resources, all image\nsizes are uniformed to 600 \u00d7 600 pixels in our framework. The denoising method is also used to enhance object edges\nand improve the resolution of images. We choose the open Python source package Scikit-image to make image sizes\nuniform. In order to avoid contrast disturbance and unify all input data formats, we binarize all color images into black\nand white. First, we convert all color images into grayscale. Lastly, all images are unified to the same color scale and\nformat before labeling, as shown in Figure 3.\nTo solve the second challenge, we leverage data augmentation to enhance image quality by applying various transforma-\ntions to the original images. The primary goal of data augmentation is to introduce variations in the training data that\nmimic real-world scenarios. By doing so, data augmentation helps improve the model's ability to generalize to unseen\ndata and reduces the risk of overfitting. Some common image data augmentation techniques include random rotating,\nrescaling, zooming, color modification, image flipping, etc. These methods are common used in different applications,\nsuch as image classification, visual detection, and object segmentation [34]. The methods used in our approach include"}, {"title": "Fundamental Models for Ensemble Learning", "content": "EfficientDet EfficientDet is a one-stage object detection model developed by Tan et al. [35]. The architecture of\nEfficientDet contains three components, including backbone, feature fusion, and class/box network. An ImageNet-\npretrained EfficientNets is employed as the backbone network. The bi-directional feature pyramid network (BiFPN)\nproposed in [36] serves as the feature network, which takes level 3-7 features from the backbone network and repeatedly\napplies top-down and bottom-up bidirectional feature fusion. These fused features are fed to a class and box network to\nproduce object class and bounding box predictions respectively. With its ability to scale up model complexity while\nmaintaining memory and computational constraints, EfficientDet can achieve an optimal balance between accuracy,\nefficiency, and computational cost. This advantage is attributed to weighted feature fusion and compound scaling\nmethods. As EfficientDet achieves the best performance on some datasets, such as COCO and Pascal VOC, over other\nmodels, it is considered in our ensemble learning model. The original work of EfficientDet provides seven variants from\nEfficientDet-D0 to EfficientDet-D7. Even though EfficientDet-D7 comes with higher computational requirements and\nresource constraints, it has the highest accuracy and better generalization performance among all variants. Therefore,\nwe adopt this variant in our model.\nMobileNet SSDv2 MobileNet-SSDv2 is a lightweight object detection model that combines the backbone network\nMobileNet with the one-stage object detector Single Shot Multibox Detector (SSD) for real-time object detection\ntasks [37], as shown in Figure 5. MobileNet utilizes depthwise separable convolutions to reduce the number of\nparameters and computational costs while maintaining strong feature representation capabilities [38]. This allows\nMobileNet-SSDv2 to achieve real-time inference speed without compromising on detection accuracy. SSD is a single\ndeep neural network that discretizes input images into a set of default boxes at multiple scales and predicts scores for\neach object category in each default box [39]. This multi-scale approach enables Single Shot Multibox Detector to\ndetect objects of various sizes and aspect ratios in a single forward pass, making it well-suited for real-time applications.\nBy optimizing MobileNet and Single Shot Multibox Detector, MobileNet-SSDv2 achieves better performance in object\ndetection while maintaining low computational overhead. With its compact architecture and real-time inference speed,\nMobileNet-SSDv2 is widely adopted for various image recognition applications, especially for resource-constrained\ndevices..\nFaster RCNN Faster R-CNN (Region-based Convolutional Neural Network) is a two-stage object detection model\nintroduced by Shaoqing Ren et al. in 2016 [40] as an improvement over earlier object detection models R-CNN and\nFast R-CNN. Faster RCNN consists of three key components: region proposal network (RPN), region of interest\n(ROI) pooling, and object detection network. RPN is the most critical part of Faster R-CNN as it can share full-image\nconvolutional features with the detection network to enable nearly cost-free region proposals. As RPNs are trained\nto generate high-quality region proposals, Faster RCNN performs better than those earlier models. RPN also shares\nthe same last convolutional layer with the Fast RCNN when processing the output image feature map. So, the data\ntraining is finished only once, which saves training time. Due to the introduction of ROI Pooling, Faster RCNN can\ndetect images of arbitrary sizes. So, it's more flexible when applying object detection to the images. Thus, it is also\nutilized in our ensemble learning model.\nYOLOv5 The framework of YOLO5 has three components, including backbone, neck, and prediction networks [41],\nas shown in Figure 6. CSPDarknet53 is used to extract features in the backbone network to reduce memory and\ncomputational usage. Three resolution feature maps were extracted as the output of the backbone network. Feature\npyramid network (FPN) and pyramid attention network (PAN) are utilized in the neck network. The basic idea of\nFPN is to up-sampling the output feature maps to generate multiple new feature maps for detecting different scale\ntargets. The prediction networks use anchor boxes to predict the detection labels based on the feature maps. This model\nalso has some other functional components, i.e., auto-anchoring and default augmentation, to achieve better detection\nperformance. It has also gained higher performance than its previous version in certain situations. This model also acts\nas a suitable object detector for small objects. Therefore, YOLOv5 is selected as part of our ensemble learning model."}, {"title": "Ensemble Learning Model", "content": "In this work, we utilize a hybrid voting strategy that ensembles the previous four models in two steps. First, all object\nboxes identified by the base models are considered valid. Thus, the results of all base models are saved in the ensemble"}, {"title": "Experimental Results", "content": "In this section, we will present the details of the experimental design to verify the detection performance of our ensemble\nlearning model.\nThree data sources are collected to support model building and testing in this experiment. The first data source is\nfrom [42]. This dataset contains 692 images that cover six defect types: a missing hole, mouse bite, open circuit, short,\nspur, and spurious copper. All the image samples are based on ten template PCBs checked manually by industry experts\nto be used as standards. The second data source is from [43], and the images are cropped to 600 \u00d7 600. This dataset\nhas 9, 920 images for training data and 2, 508 images for testing data. The third data source is from [44]. There are\n1,500 image pairs in size 640 \u00d7 640, and each pair consists of defect-free and defective versions. This dataset includes\nthe same six defects as the first data source. As two types of defects, including pinhole and scratch, are missing, we\nmanually add these two types to the original PCB images. Thus, all eight types of PCB defects are covered in our\ndatasets. All these datasets are processed with the data preprocessing methods to obtain a complete dataset with a\nunified image format in Section 3.\nNext, the preprocessed dataset is split into training, testing, and validation sets. While 70% of the dataset is allocated as\nthe training set, testing and validation sets constitute 15% of the dataset separately. To improve the training performance,\nthe splitting process is enhanced by a balanced allocation method. That is, even though different types of defects have\ndifferent defect counts, all types of defects are adjusted to follow the 70% - 15% - 15% rule.\nWith the collected sets, we utilized the four different models independently as benchmark models of PCB defect\ndetection. Each model is trained with the same image dataset of PCBs and then detects and classifies the problematic\narea. Two model training techniques are applied to enhance model performance. The first one is to tune hyper-\nparameters, including learning rate, batch size, and optimizer. For EfficientDet, the batch size is set as 16, and the\nlearning rate is 0.001. For MobileNet, the batch size is set as 12. For Faster RCNN, the batch size is set as 8, and the\nlearning rate is 0.01. For YOLOv5, the batch size is 16, and the learning rate is 0.01 with a decay method. An RMS\nprop optimizer is chosen for MobileNet, and momentum optimizers are selected for three other models to optimize\nnetwork parameters. The second one is to validate detection results by visualizing defect types and confidence values\non images. Then, we utilized the proposed ensemble learning model to improve the detection performance with regard\nto benchmark models. We use mAP (mean Average Precision) [27] as the metric to assess the detection performance of\ndifferent models. It calculates the average precision while stating the accuracy of the PCB defect detection as follows:\n$\\MAP = \\frac{\\sum_{i=1}^{C} AP_i}{C}$ (2)\nwhere C is the total number of samples and $AP_i$ is the Average Precision of $i$th sample. As the precision depends on\nthe Intersection over the Union (IoU) threshold, we leverage two mAP metrics. The first metric mAP0.5 is the mAP\nunder the IoU threshold 0.5. The second metric mAP0.5:0.95 is the mAP under multiple IoU thresholds, ranging from\n0.50 to 0.95, with a step size of 0.05. Other metrics used in the experiment are accuracy, precision, and recall, which\nare defined as follows:\n$\\accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$ (3)\n$\\precision = \\frac{TP}{TP + FP}$ (4)\n$\\recall = \\frac{TP}{TP + FN}$ (5)\nwhere TP is true positive, TN is true negative, FP is false positive, and FN is false negative.\nWe use two metrics, including training time and average run time, to evaluate the time performance of defect detection\nmodels. The training time only refers to the training time length of a detection model. The average run time means the\naverage time length it takes to process a single image."}, {"title": "Experimental Results", "content": "We utilize the four base models sequentially to detect PCB defects. The first model, EfficientDet, is trained with all\nsample images. The loss value became stable after the 30k round of the training process. The trained model can identify\nall eight types of PCB defects. Among them, the defect pinhole has the most significant F1 score.\nThe second model, MobileNetV2, is also utilized on the same dataset. It can be observed that the loss of the model\ndecreases from epoch 0 to epoch 30 during the whole training process, which indicates that the model works well\nwith defect detection on PCB with coordinates. While the object loss dropped to the lowest value around epoch 10, it\nbounced back and increased significantly during epoch 10 to 30. This indicates poor prediction performance. More\nhyper-parameter tuning work may boost this outcome. The classification loss is constantly decreasing, which shows the\nmodel is well-trained to predict the types of defects after locating them on PCB."}, {"title": "Conclusion and Future Work", "content": "In this paper, we introduced a novel inspection framework designed to detect defects in printed circuit boards (PCBs).\nThis comprehensive approach involves stages of data collection, preprocessing, model development, evaluation, and the\ndevelopment of a web application. We utilized four established models, i.e., EfficientDet, MobileNet, FasterRCNN,\nand YOLOv5, to identify PCB defects independently. These models were integrated using a hybrid voting strategy\nin our ensemble learning model, which achieved a detection accuracy of 95%. The proposed method is versatile\nenough to detect various types of PCB defects and can be adapted for defect detection in other manufacturing contexts,\ndemonstrating its potential as a generalized approach to enhance performance. This adaptability underscores its\ncapability to improve defect detection across different manufacturing scenarios.\nFuture research directions for this framework include extending its capabilities to support real-time video inputs and\nexploring other ways to improve defect detection performance. These initiatives will help to advance the field of PCB\nquality control and broaden the applicability of our methods."}]}