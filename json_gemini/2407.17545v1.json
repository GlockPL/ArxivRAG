{"title": "Large Language Models for Anomaly Detection in Computational Workflows: from Supervised Fine-Tuning to In-Context Learning", "authors": ["Hongwei Jin", "George Papadimitriou", "Krishnan Raghavan", "Pawel Zuk", "Prasanna Balaprakash", "Cong Wang", "Anirban Mandal", "Ewa Deelman"], "abstract": "Anomaly detection in computational workflows is critical for ensuring system reliability and security. However, traditional rule-based methods struggle to detect novel anomalies. This paper leverages large language models (LLMs) for workflow anomaly detection by exploiting their ability to learn complex data patterns. Two approaches are investigated: 1) supervised fine-tuning (SFT), where pre-trained LLMs are fine-tuned on labeled data for sentence classification to identify anomalies, and 2) in-context learning (ICL) where prompts containing task descriptions and examples guide LLMs in few-shot anomaly detection without fine-tuning. The paper evaluates the performance, efficiency, generalization of SFT models, and explores zero-shot and few-shot ICL prompts and interpretability enhancement via chain-of-thought prompting. Experiments across multiple workflow datasets demonstrate the promising potential of LLMs for effective anomaly detection in complex executions.", "sections": [{"title": "I. INTRODUCTION", "content": "With the increasing complexity and scale of modern systems, computational workflows are growing in complexity while their reliability, security, and performance are becoming rather important. A critical factor in ensuring workflow execution reliability is the ability to detect anomalies. These anomalies can be indicators of various system issues, and they are manifested by unexpected behavior in hardware, such as high usage of computing resources, memory consumption, and I/O operations. To address the problem of anomaly detection in modern systems, methods that rely on rule-based systems, statistical analysis, and machine learning techniques [1]\u2013[4] have become quite popular in recent years.\nDespite their effectiveness, a considerable amount of data preprocessing must be done to perform this detection because typical methods are limited to analyzing images or numerical values. Furthermore, to facilitate this data preprocessing, a lot of expert knowledge is needed to be put into carefully collecting and correlating low-level system statistics with workflow execution metadata that can be used to convert the raw logs into other formats. Adding to the complexity is the need for substantial ML expertise to navigate the wide array of available anomaly detection methodologies effectively. The field of ML presents a vast spectrum of models and techniques, each with its customization and application nuances. This diversity, while beneficial, also imposes a steep learning curve and necessitates a deep understanding of ML principles to tailor these models to specific anomaly detection tasks. Furthermore, the process of setting up and training these models\u2014integrating them into a system's workflow\u2014poses an additional challenge. This aspect of ML model deployment and maintenance may not align well with the skill set of system administrators, who are typically more versed in direct system maintenance rather than in the nuances of ML model training and tuning.\nLarge Language Models (LLMs) and their wide-spread democratization efforts have the potential to significantly transform anomaly detection in HPC systems by streamlining data preprocessing, enhancing pattern recognition, simplifying the deployment of machine learning models, enabling real-time monitoring, and fostering a supportive community ecosystem. By automating complex data processing tasks and offering advanced analytical capabilities, LLMs reduce the need for extensive expert knowledge, making sophisticated anomaly detection accessible to system administrators without deep technical backgrounds. Furthermore, their ability to process and analyze streaming data in real-time can ensure prompt detection and mitigation of potential system issues.\nA primary critique of LLMs concerns their energy/power consumption and model size, which are seen as barriers to their practical application in HPC data analysis. However, this perspective overlooks the significant advances in energy-efficient technologies and the optimization of LLMs for operation on a wide range of devices, from high-end servers to compact, low-power devices such as smartphones. These emerging technologies not only mitigate the energy and resource demands of running sophisticated LLMs but also expand their accessibility and usability across various platforms. Consequently, as these energy-efficient techniques continue to evolve and LLMs become increasingly optimized for smaller devices, the practicality of deploying LLMs for anomaly detection in HPC systems\u2014and beyond\u2014becomes ever more feasible. This trajectory underscores the viability of LLMs as a transformative tool in anomaly detection, promising significant advancements in HPC system management and maintenance.\nWe develop an approach that leverages pre-trained Large Language Models (LLMs) to directly detect anomalies from log files generated during the execution of computational workflows. Specifically, we adapt these pre-trained models through Supervised Fine-Tuning (SFT) and Prompt Engineering via In-Context Learning (ICL). SFT employs a pre-trained model and trains on a smaller dataset of labeled examples for a specific task [5]. Unlike the training of LLMs in an unsupervised way, the SFT often consists of an input and a desired output. By updating the parameters of LLMs again through SFT, the model improves the performance for a downstream task. However, one common issue with LLMs is that they can perpetuate biases present in the data used to train them [6], especially when for the binary classification problem. Another common issue is catastrophic forgetting (CF) [7], which occurs in machine learning when a model forgets previously learned information as it learns new information. This is a common problem in supervised fine-tuned models, where the model is trained on a new task after it has already been trained on one or more previous tasks.\nIn-context learning (ICL), on the other hand, is an emerging paradigm where LLMs perform tasks by leveraging a few examples provided within the context of query [8] rather than relying on supervised fine-tuning with labeled data. ICL heavily relies on prompt engineering, providing examples and contextual cues that guide the LLMs in efficiently understanding and executing the desired task. A well-engineered prompt not only presents the LLM with relevant information but subtly instructs it on generating the appropriate output. It involves structuring the examples in a way that highlights patterns or relationships, using natural language templates that align with the task's goals, or including explicit instructions that direct the model's attention to critical aspects of the problem. This alignment can be performed specifically for the anomaly detection problem where the prompts contain information about the job features and brief statistics about the job execution facilitating anomaly detection in the workflow. Furthermore, prompts can also include the instruction for reasoning steps through Chain-of-Thought (CoT [9]), providing explainable output from LLMs.\nTo this end, we make the following contributions to the scope of this paper:\n1) Investigate the efficacy of LLMs for anomaly detection and evaluate the performance of supervised fine-tuning models and in-context learning in detecting anomalies in computational workflows.\n2) Address the biases, overcome the catastrophic forgetting, and explore the generalization through transfer learning and online detection.\n3) Explore the ability of ICL with zero-shot, few-shot learning, and study the interpretable output from ICL through Chain-of-Thought (CoT).\nWith the use of LLMs for anomaly detection in computational workflows, we seek to contribute to the development of effective and efficient methods for detecting anomalies in computational workflows."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "Several approaches have been proposed in the literature for anomaly detection in computational workflows. These approaches can be broadly classified into rule-based systems, statistical analysis, and machine-learning techniques. Rule-based systems rely on predefined thresholds and patterns to detect anomalies. For example, [10] proposed a rule-based system that uses a set of heuristics to identify anomalies in Linux computational workflows.\nWhile rule-based systems are simple to implement, they are limited by their inability to adapt to changing patterns in behavior and are often brittle in the face of new anomalies. Statistical analysis techniques, that use statistical information such as mean, median, and standard deviation, have been used to detect anomalies in computational workflows as well. For example, [11] proposed an approach that uses statistical methods to identify anomalies in network traffic logs. However, statistical analysis techniques are sensitive to outliers and may not be effective in detecting anomalies that do not deviate significantly from the mean.\nMachine learning techniques, such as decision trees, random forests, and clustering, have also been applied to anomaly detection in computational workflows. For example, [12] presented a simple and effective algorithm for spectral clustering, a method for grouping data points based on their pairwise similarities. The algorithm utilizes the eigenvectors of the graph Laplacian to represent similarities between the data points. The authors also provide a theoretical analysis of the algorithm and show that it can be used to cluster data in a variety of settings.\nMore recently, deep learning techniques, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs), have been applied to anomaly detection in computational workflows. For example, [13] proposed a general methodology for mining console logs to detect large-scale system problems. The authors first parse the logs by combining source code analysis with information retrieval to create composite features. They then analyze these features using machine learning to detect operational problems. The authors evaluate their methodology on a dataset of console logs from a large-scale production system and show that it can be used"}, {"title": "III. LLMS FOR ANOMALY DETECTION", "content": "In this section, we will describe the supervised fine-tuning and in-context learning in details, and their advantages in anomaly detection tasks. An overview of our approach is provided in Figure 1.\nA. Supervised Fine-Tuning\nSupervised fine-tuning (SFT) is used to adapt pre-trained language models to new tasks or domains. The process involves feeding a labeled dataset of the target task or domain to the pre-trained model and adjusting the model's parameters while minimizing the loss on the new task. By using labeled data from the target task, the model can learn to recognize patterns and features that are specific to the new task, while still leveraging the knowledge it has gained from the large amounts of data it was pre-trained on.\nFollowing this, we detect the anomalies in computational workflows by fine-tuning the pre-trained models on the labeled dataset of the target task, i.e., sentence classification. Our approach involves treating the logs generated by the computational workflows as a sequence of sentences and applying the fine-tuned model to classify each sentence as normal or anomalous. Toward this end, we use a combination of pre-trained models and evaluate their performance on Flow-Bench dataset. A template that parses a system log entry into a sentence with labels is provided in Figure 2.\nInstead of training LLMs from scratch as done in [15], [18], there are several advantages of using the SFT approach:\n\u2022 Reduced training time and resources: SFT allows us to leverage the knowledge gained by the pre-trained model, reducing the amount of training time and resources required to achieve good performance on the target task. This can save a significant amount of time and computational resources.\n\u2022 Improved performance: SFT has been shown to improve the performance of pre-trained models on a wide range of NLP tasks, including text classification, sentiment analysis, and question answering. By adapting pre-trained models to the target task, we can achieve better performance than training a model from scratch.\n\u2022 Easy domain adaptation: SFT allows us to adapt pre-trained models to new domains, enabling them to learn domain-specific features and patterns. This can be useful for tasks like anomaly detection, where the target domain may be different from the domain the model was pre-trained on.\n\u2022 Better Generalization: SFT can lead to better generalization to unseen data compared to training a model from scratch since the pre-trained model has already learned to recognize many features that are useful for the target task.\n\u2022 Smaller dataset requirements: SFT can be more effective with smaller datasets than training a model from scratch since the pre-trained model has already learned to recognize many features that are useful for the target task. This can be particularly useful for tasks where labeled data is scarce or difficult to obtain, e.g., anomalies in computational workflows.\nB. In-Context Learning\nIn-context learning (ICL) explores the LLMs' ability to enable few-shot learning and improve the generalization capabilities of the model. In contrast to the SFT, ICL does not train the model explicitly, instead, it applies prompts (input context) to guide the LLMs applying on downstream tasks. To highlight the ICL approach, we highlight several advantages of using ICL as follows:\n\u2022 Improved generalization: ICL enables models to learn from the context provided in the input data, which can improve their generalization capabilities. This can be especially useful for anomaly detection in system logs, where the data can be highly variable and complex.\n\u2022 Reduced need for labeled data: ICL can enable models to learn from unlabeled data, reducing the need for expensive and time-consuming labeling efforts. This can be particularly beneficial in the context of anomaly detection, where labeling data can be difficult and resource-intensive.\n\u2022 Improved interpretability: ICL also provides insights into the features and patterns that are important for detecting anomalies, making it easier to interpret the model's predictions and identify false positives or negatives. Especially, Chain-of-Thought (CoT) [9] is a method that can be used to generate prompts that guide the model to generate the desired output by providing explainable results.\nUnder the ICL paradigms, there are different types of prompts that can be used to guide the LLMs' learning, including zero-shot prompts, one-shot prompts, and few-shot prompts. Zero-shot prompts provide the model with a natural language description of the task, without any examples. In this case, the model must rely solely on its prior knowledge and the context provided to explore the ability of LLMs. One-shot prompts and few-shot prompts provide the model with either a single example or a few examples of the task, respectively. Generally, the examples provided involve the label of cases, particularly in the anomaly detection task, the example could be either the normal, anomalous or even mixed examples together. This is useful for tasks where labeled data is scarce or difficult to obtain, as it allows the model to learn from a small amount of data. Figure 3 provides the template of the prompt for ICL. It contains two parts in general, the task description, which guides the LLMs to understand the task, and the examples, which provide the context for the task. In our case, we explicitly ask the model to output the category of job described, without any reasoning or explanation. The contextual example, in this case, is the sentences that describe the job with its features extracted from the raw log file, and explicitly note the label of the job.\nBesides, another key advantage of ICL is that it can be fine-tuned based on domain-specific datasets as well, enabling it to adapt to new domains and tasks. Similar to SFT, fine-tuning on ICL also applies the labeled data from the target domain, capturing the specific features and patterns that are relevant to the task.\nC. Pre-trained Models\nPre-trained models, such as BERT [19], GPT [20], and ALBERT [21] leverage the Transformer architecture [22] to ascertain statistical patterns and linguistic structures in the data. These models, trained on the large corpus of freely available text data have become the backbone of many state-of-the-art NLP systems, empowering researchers and practitioners to achieve remarkable performance with reduced training time and resources. These models have accelerated progress in NLP and continue to drive advancements in various language understanding and generation tasks.\nFor text classification tasks, where the goal is to assign a category or label to a given text input, encoder-only models are commonly employed. These models, such as BERT [19] (Bidirectional Encoder Representations from Transformers) and ROBERTa [23] (Robustly Optimized BERT Approach), process the input text in its entirety and generate contextualized representations, which can then be used for classification. Typically, the SFT for classification tasks involves adding a classification head on top of the pre-trained model and fine-tuning the model on a labeled dataset.\nOn the other hand, for causal language modeling tasks, where the objective is to predict the next token in a sequence given the preceding context, decoder-only models are well-suited. These models, such as GPT [20] (Generative Pre-trained Transformer) and its variants, generate text in an autoregressive manner, making them suitable for tasks like text generation, machine translation, and summarization. Unlike"}, {"title": "IV. EXPERIMENTS", "content": "Our experiments are conducted on a single NVIDIA A100 GPU with 40GB memory. We implemented in PyTorch [24", "25": "for our experiments. The detailed configurations of each individual model and optimizer are presented in the Artifact Appendix.\nA. Dataset and Data Processing\nTo conduct our experiments we adopted the workflow data from Flow-Bench [26", "27": "in order to provide a null distribution for rigorous statistical evaluation of potential disease-related mutations across populations. The instance of the workflow DAG available in the dataset", "28": "to transform astronomical images", "29": "into custom mosaics for further analysis of the deep sky. The instance of the workflow DAG available in the dataset", "26": ".", "8": 1, "30": "our results demonstrate that the SFT models achieve comparable performance to these classical machine learning models. However", "\"": "from the pre-trained models with 10 independent runs. The figure shows that for a couple of models", "31": ".", "32": "Mistral-7B-v0.1 [33", "34": ".", "Quantization.": "To save memory and reduce the inference time", "35": "to the fine-tuned model. Quantization is a model compression technique that reduces the memory footprint and improves the inference speed of deep learning models by converting the model's weights from floating-point to fixed-point numbers. More specifically", "36": "with enabled 4bit quantization to replace the linear layers and enabled float16 computational type for the tensors which might be different than the input time.\nb) LoRA.: To further reduce the memory footprint and improve the inference speed, we apply the Low-Rank Adaptation (LoRA) [37"}, {"26": ".", "9": "reasoning. The chain-of-thought approach in ICL involves breaking down the decision-making process into a series of logical steps, similar to how humans reason through a problem. Instead of providing a single opaque prediction, ICL models can generate a sequence of intermediate steps that explicitly outline the thought process leading to the final output. This transparency allows for a deeper understanding of the model's decision-making rationale, enabling users to scrutinize the validity of the reasoning and identify potential flaws or biases.\nFigure 13 provides the examples of CoT under ICL, wherein the model input, we explicitly remove the instruction that asks the model to only output the category of the job, and instead, we ask the model to think about it \"step-by-step\". It clearly prompts the model's output to be more explainable and interpretable, which can be used to validate the model's decision-making process. In this case, the model reasons through the value of each feature, and determines its decision based on simple statistics of those features. Finally, the model outputs the category of the job, which is normal in this case. By exposing the chain of thought, ICL models become more interpretable and trustworthy, particularly in high-stakes domains where decisions can have significant consequences.\nI. Transfer Learning with ICL\nSimilar to the SFT models, we also explore the potential of transfer learning with the ICL approach, and we report the accuracy based on the Mistral-7B model. Figure 14 presents the transfer learning results of the fine-tuned models (10 epochs) from one dataset to another. In the inference stage, we randomly select 10 examples from both positive and negative examples in the prompts. The diagonal values in a prediction matrix indicate the model's performance on the dataset used for training, while the off-diagonal values show its performance in a transferred setting. To give an example, a pre-trained Mistral-7B model trained on the 1000 Genome dataset was used to make predictions on the Montage dataset. In this case, the accuracy achieved was 0.753. Note that fine-tuning a model from observations in one dataset can enable it to make inferences on a similar dataset that has the same contextual information but different values in detail. This allows the model to leverage the additional examples introduced in its prompts to improve its performance on the new dataset. Additionally, when comparing the results of transfer learning and fine-tuning in Figure"}]}