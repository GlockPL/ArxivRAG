{"title": "APPLICATIONS AND CHALLENGES OF AI AND MICROSCOPY IN\nLIFE SCIENCE RESEARCH: A REVIEW", "authors": ["Himanshu Buckchash", "Gyanendra Kumar Verma", "Dilip K. Prasad"], "abstract": "The complexity of human biology and its intricate systems holds immense potential for advancing\nhuman health, disease treatment, and scientific discovery. However, traditional manual methods\nfor studying biological interactions are often constrained by the sheer volume and complexity of\nbiological data. Artificial Intelligence (AI), with its proven ability to analyze vast datasets, offers a\ntransformative approach to addressing these challenges. This paper explores the intersection of AI\nand microscopy in life sciences, emphasizing their potential applications and associated challenges.\nWe provide a detailed review of how various biological systems can benefit from AI, highlighting\nthe types of data and labeling requirements unique to this domain. Particular attention is given\nto microscopy data, exploring the specific AI techniques required to process and interpret this\ninformation. By addressing challenges such as data heterogeneity and annotation scarcity, we outline\npotential solutions and emerging trends in the field. Written primarily from an AI perspective, this\npaper aims to serve as a valuable resource for researchers working at the intersection of AI, microscopy,\nand biology. It summarizes current advancements, key insights, and open problems, fostering an\nunderstanding that encourages interdisciplinary collaborations. By offering a comprehensive yet\nconcise synthesis of the field, this paper aspires to catalyze innovation, promote cross-disciplinary\nengagement, and accelerate the adoption of AI in life science research.", "sections": [{"title": "1 Introduction", "content": "Life science is a core research domain with profound implications for human well-being. It addresses myriad questions\nacross diverse directions, all ultimately geared towards advancing human health. However, resolving these challenges\nis time intensive, as countless experiments are needed to develop effective therapies or robust understanding, each\ngenerating extensive data. Manually analyzing such data demands substantial expertise (already in short supply) and\nis exceedingly time consuming. A notable example is the decades of labor by researchers to empirically determine\naround 100000 protein structures [1]. Recent years, however, have witnessed substantial advances through AI [2, 1].\nUtilizing AI to propel life science research is inevitable, given their mutual synergy. AI relies on extensive data to refine\nits predictive models, while life science generates vast datasets that exceed feasible manual analysis. This synergy is\nreflected in numerous breakthroughs [1, 3, 4, 2]. This paper aims to elucidate key challenges in microscopy and life\nscience, their interconnections, how AI and microscopy can be harnessed to address them, and prospective research\ndirections.\nAs illustrated in Fig. 1, the major challenges in life science research (LSR) can be stratified into three hierarchical tiers.\nThe first category encompasses sequence- and structure-focused tasks, such as protein or nucleic acid sequence prediction\nand omics data analysis, all of which revolve around the molecular level. Algorithms typically employed in these\ntasks include recurrent neural networks (RNNs), transformers, or graph neural networks, due to their ability to capture\ncomplex relationships within molecular data. At a higher spatial scale, the second tier involves subcellular components,\nincluding organelles, and aims to elucidate their morphology and dynamics to better understand connections between"}, {"title": "2 Synergetic relation between microscopy and AI", "content": "As depicted in Fig. 2a, a typical microscopy setup involves preparing the specimen on a slide and illuminating it\nusing an appropriate light or wave source. The objective lens then magnifies the resulting signal, and variations in\nwave patterns or fluorescence provide insights into the sample's structural and functional features. These interactions\nenable the formation of detailed images that reveal critical information about the underlying biology. Such images\ncan be exceptionally large and complex, requiring substantial human effort to interpret. Indeed, a single dataset might\nencompass millions or even billions of subcellular interactions, reflecting intricate biological dynamics [7]. Microscopy\noutputs frequently take the form of 3D, 4D, or 5D tensor data, capturing spatial, temporal, and sometimes spectral\ndimensions. The sheer scale and complexity of these multidimensional datasets highlight the growing need for AI,\nfueled both by the success of unsupervised and self-supervised algorithms and the scarcity of labeled data available for\ntraining.\nAI can play a pivotal role in microscopy by modeling the morphological state and dynamics of subcellular structures,\nthereby facilitating a deeper understanding of underlying biological processes. Recent efforts [7] are dealing with\nthe enormous scale of these interactions to elucidate how diseases manifest in living organisms. A common strategy\nin such investigations involves applying a perturbation - a controlled alteration or stimulus to the organism or\nsystem of interest [8, 9]. Subsequently, researchers monitor how this perturbation propagates across one or multiple\ntiers of biological organization, from molecules and organelles to entire organs (see Fig. 1). By capturing the resulting\nchanges at one or multiple levels, this approach provides a more comprehensive perspective on the complex interplay\nthat governs health and disease.\nTypes of image based microscopy. Fig. 3 illustrates a comprehensive hierarchical classification of diverse imaging\nmethods in microscopy. This classification is structured around three primary functional objectives: (1) visualizing fine\nstructures through static imaging, (2) tracking dynamic processes such as motion and molecular interactions, and (3)\nprobing molecular composition to reveal chemical or elemental properties. Techniques are further grouped based on\ntheir underlying principles, including spectroscopy-based, electron-based, force-based, and light-based approaches,\nwith subdivision into conventional, advanced, and specialized types. This organization captures the broad range of\ntools available for structural visualization, molecular analysis, dynamic behavior tracking, and multimodal integration.\nAmong the commonly used techniques are confocal microscopy, phase-contrast microscopy, fluorescence microscopy,\nquantitative phase microscopy, atomic force microscopy (AFM), and scanning electron microscopy (SEM). Each\nmethod has unique advantages and limitations. For instance, confocal microscopy enables optical sectioning for 3D\nimaging but requires longer acquisition times, whereas phase-contrast microscopy provides label-free visualization of\nlive cells but lacks molecular specificity. While the classification provides clarity, the boundaries between categories\nare not absolute. Many methods exhibit properties that span multiple functions. For example, total internal reflection\nfluorescence (TIRF) microscopy is fluorescence-based and can be kept under optical microscopy, but it is classified\nunder dynamic imaging due to its primary application in studying near-surface events. Also, this classification is not\nexhaustive. Numerous techniques and their variants, including emerging modalities and niche applications, remain\noutside the scope of this review. However, the techniques presented here represent some of the most widely used and\nimpactful methods in life science research.\nThere are also other noteworthy binary classifications that offer valuable perspectives. Fluorescence vs label-free:\nfluorescence microscopy employs chemical or genetic tags to label specific structures, whereas label-free methods\n(e.g. phase-contrast) do not require exogenous markers. In Fig. 2b, for instance, fluorescence distinctly visualizes\nnuclear envelopes and nuclei, while phase-contrast records all features in a single image without labels from the\nsame sample. Transparent vs opaque samples: techniques based on light transmission (e.g. brightfield, phase-contrast,\nfluorescence) require minimal preparation and support live specimen imaging but are ineffective for highly scattering\nor opaque samples. In such cases, reflection or scattering methods (e.g. SEM, TEM, AFM, TIRF) are more suitable.\nThin vs thick specimens: techniques like TEM excel with thin samples, offering high resolution but limiting live or\nintact specimen studies. Confocal and multiphoton microscopy handle thick samples, preserving 3D structures but with\nreduced resolution in deeper layers. Live-cell vs static samples: live-cell imaging captures dynamic processes but is\nlimited by phototoxicity and lower resolution. Fixed-sample methods, such as electron microscopy, provide detailed\nstatic images but lack the ability to track ongoing biological events. Overall, image-based microscopy is essential for\nstudying biological structures at various scales but faces many challenges due to its complexity, as further discussed in\nthe next section."}, {"title": "3 Challenges in image based microscopy and AI", "content": "Image based microscopy holds immense potential for transformative applications and advancements through the\nintegration of AI. However, the field faces several critical challenges, including the lack of sufficient labeled data,\nvariability in data quality, and the pervasive presence of noise and artifacts in microscopy datasets. In this section, we\ndelve into some of the key obstacles in the field, highlighting their implications.\nFluorescence vs label-free microscopy. In microscopy, both label-free and fluorescence techniques are vital for\nimaging biological processes, yet each has inherent trade-offs and challenges. Label-free methods, such as phase-\ncontrast or quantitative phase microscopy, preserve the natural state and vitality of samples, making them ideal for\nlive-cell imaging. However, they often lack molecular specificity i.e blurred edges, making it difficult to isolate or\nstudy particular biomolecules or pathways. Conversely, fluorescence microscopy offers high specificity and sensitivity,\nenabling the visualization of targeted molecules. Yet, it can disrupt the sample's natural state, reduce viability through\nphototoxicity, and cause off-target binding, potentially compromising reproducibility [12]. These limitations highlight\nthe complementary nature of the two approaches and the need for innovative methods to bridge the gap between\nspecificity and sample preservation.\nData labeling problem. Labeling biological data for AI applications, such as segmentation and tracking, is a significant\nchallenge due to the complexity, size, and dynamic nature of biological systems. Biological entities often interact and\nexhibit intricate dynamics, requiring extensive and precise annotations to define distinct features for algorithm training\n[13]. This task is labor intensive and prone to errors, as biological images often involve large datasets with subtle\nvariations that are difficult to interpret consistently. The lack of sufficient labeled data hampers the ability to train and\nverify robust AI systems, creating a bottleneck for advancements in biological image analysis [3, 9]. Addressing this\nissue requires innovative solutions, such as semi-supervised learning, active learning, or leveraging synthetic data to\nreduce the dependency on manual labeling."}, {"title": "Point spread function (PSF).", "content": "It is a fundamental characteristic of a microscopy system that quantifies how a point\nsource of light is imaged and represented by the system. It describes the response of the optical setup to a point source,\neffectively encapsulating how the inherent physical and optical properties of the system distort or blur the representation\nof an object. Mathematically, the PSF represents the intensity distribution of light in the image plane resulting from a\npoint source located at the focal plane [15]. Fig. 4a demonstrates the formation of the output image as the object is\nconvolved with the PSF, leading to image blurring. Fig. 4b shows different types of PSFs. To estimate the PSF, beads of\nknown shapes are imaged under the microscope (see details in Sec.2). Due to the diffraction limit and the nature of\nPSF, multiple distinct objects can produce similar output images, making the inverse problem ill-posed. This ambiguity\npresents significant challenges in training AI systems, even with labeled data, as the many-to-one mapping often leads\nto suboptimal convergence of AI training algorithms."}, {"title": "Noise types and their impact.", "content": "Various factors contribute to noise in microscopy images, including variation in PSFs,\nthe process of image formation, optical aberrations, disturbances caused by mismatched refractive indices within\nthe sample, out-of-focus sample and light originating from out-of-focus regions. Additionally, variations in sample\npreparation methods further exacerbate these challenges [14]. Noise characteristics can range from well defined types,\nsuch as textured noise, which can be modeled and estimated with known approaches [16], to more complex noise that\nresists straightforward characterization and modeling [9]. AI algorithms trained to handle specific types of noise often\nfail to generalize effectively, resulting in suboptimal performance when applied to images of the same biological sample\nbut affected by different noise types."}, {"title": "Dynamic nature of biological events.", "content": "Modeling interactions among biological structures presents significant challenges\ndue to their inherently dynamic behavior. These structures often exhibit continuous motion, frequently moving in and\nout of the imaging field of view. This characteristic of biological samples complicates their tracking and makes their\ninteraction analysis highly challenging. Furthermore, the rapid and often non linear nature of these movements adds\nadditional complexity to the extraction of meaningful insights [17]."}, {"title": "Cellular vs subcellular level microscopy.", "content": "Cellular level microscopy typically operates within the diffraction limit,\nproviding clear boundaries and well defined structures. In contrast, subcellular imaging often exceeds the diffraction\nlimit, leading to challenges in resolving fine structural details and demarcating boundaries. This limitation results\nin reduced resolution, complicating data analysis and hindering AI model training. Similar issues arise in nanoscale\nimaging of subcellular interactions, which is an active area of research. Advanced techniques, such as Single Molecule\nLocalization Microscopy and correlative microscopy, have been developed to overcome these challenges and enhance\nresolution at the subcellular scale."}, {"title": "Toxicity and bleaching.", "content": "Phototoxicity and cytotoxicity pose significant challenges in live-cell imaging, as prolonged\nexposure to light or staining agents can compromise cellular viability and physiology, leading to artifacts. Additionally,\nfluorophore bleaching during imaging results in signal loss, reducing the quality and reliability of long term observations\nand quantitative analyses [11]."}, {"title": "Multidisciplinary nature of research.", "content": "Effective collaboration in this multidisciplinary field may be hindered by\ncommunication gaps, including technical jargon and unclear task delegation, such as deciding who should label data for\npreliminary analysis. Biologists typically have the domain expertise but limited time, whereas informaticians, while\nmore available, might lack the necessary expertise. This dilemma can impede project efficiency and compromise data\nquality."}, {"title": "4 Possible solutions", "content": "Because these challenges are inherently multidisciplinary, strengthening collaboration among researchers from diverse\nfields is crucial for addressing them effectively. Collaboration fosters innovative problem solving and efficient sharing\nof resources. This section outlines potential solutions to the identified challenges.\nSynthetic data. Synthetic data addresses the challenge of limited labeled data by providing an alternative source\nfor training and testing models. It can be generated through simulators [9, 16], which approximate real-world data\ngeneration processes, or via generative AI models [18], offering flexibility to create abundant datasets with distributions\nresembling real data.\nPhysics-based AI. Physics-based AI helps in training AI models by reducing their dependence on labeled datasets by\neither incorporating the physics constraints during the training data generation process [16], or by modifying the design\nof an AI model to bypass its dependency on labeled data by incorporating physics-based priors into the model [19, 4].\nPhysics-based models not only overcome data scarcity but also often yield models with improved interpretability.\nCross-microscope or cross-noise distribution models. Cross-modal (or cross-microscope) approaches can effectively\naddress challenges such as data scarcity or the lack of labeled datasets. These methods leverage complementary\nmodalities either for information fusion [13] or by incorporating priors extracted from one modality into the analysis of\nanother [4, 20]. Such cross-modality strategies are particularly valuable in tackling subcellular imaging challenges,\nwhere the integration of information across modalities enhances resolution and interpretability, and reduces toxicity.\nAdditionally, these challenges can be conceptualized as problems of distributional shifts, where domain adaptation\ntechniques offer robust solutions to align disparate data distributions and mitigate noise [21].\nSelf supervised learning (SSL). SSL is a machine learning paradigm that leverages large amounts of unlabeled data to\nderive meaningful representations through automatically generated supervisory signals. In microscopy, both live-cell\nand static imaging applications benefit from SSL by employing tailored objective functions, such as contrastive learning,\nto effectively extract biologically relevant features from unlabeled datasets [22, 23, 24].\nTransfer learning. Because of large scale training on diverse datasets, pretrained models often capture robust and\nbroadly applicable feature representations, surpassing those learned from scratch. Consequently, they can be efficiently\nfinetuned for new tasks when domains overlap and labeled data are scarce [25]. Another progressive approach within\ntransfer learning is active learning, wherein each generation of models benefits from knowledge transferred by the\nprevious one. This methodology has enabled the development of foundational models such as [2], which demonstrate\nhigh generalizability and can accelerate training in low-labeled-data contexts. Additionally, transfer learning facilitates\nmulti-task learning across various imaging applications [26]."}, {"title": "5 Current and future areas of research", "content": "In this section, we examine current and prospective research areas in life science. Each area includes its primary\nchallenge, followed by secondary challenges, then its classification as either current or future, and key references.\nCurrent areas are those undergoing active investigation, whereas future areas are those where minimal or no research\nhas yet been conducted.\nVideo analysis. Involves investigation of microscopic videos for activity recognition, event detection, tracking, event\ndetection in untrimmed videos, detection of dynamic events (e.g. entities moving in and out of the frame), and\nunsupervised event clustering [27]. Future.\nAmodal segmentation. Segmentation is an essential precursor to downstream tasks such as tracking or event analysis.\nContemporary methods, including semantic or instance segmentation, often fail to handle overlapping structures\nadequately, resulting in incomplete analyses. These limitations can be addressed by developing amodal segmentation\nalgorithms, which infer hidden object regions beyond visible boundaries. Future.\nMorphology analysis. Involves segmenting and quantifying shape and size of diverse biological structures. This\nremains especially demanding when conducted fully automatically. Subfields may include segmentation, morphological\ncharacterization, metric learning [9, 20]. Current."}, {"title": "Anomaly detection.", "content": "Involves grouping or modeling irregular behaviors to identify anomalous events that may serve as\nearly disease indicators. Subfields include clustering, anomalous event analysis, and morphological anomaly detection\n[28]. Future."}, {"title": "Application of foundation models.", "content": "Involves leveraging large scale foundation models (e.g. LLMs, SAM variants) for\ncaptioning, segmentation, and tracking in microscopy, using minimal labeled data. Subfields include refining transfer\nlearning strategies for diverse imaging applications; language based annotation of events and morphology, as well as\nspecialized segmentation frameworks [2]. Current."}, {"title": "Sustainable and efficient AI for microscopy.", "content": "Microscopy data requires massive storage and computational power for\nprocessing, necessitating the development of energy efficient algorithms. Subfields include data compression, efficient\nmodel design, and lightweight models tailored for large scale image analysis; leading to scalable and environmentally\nresponsible solutions [29]. Future."}, {"title": "Event grounding.", "content": "Involves prompt based (text or visual) retrieval of information within image or video data. Subfields\nmay include target event grounding, biological entity grounding, symptom grounding (to facilitate confirmatory or risk\nfactor analyses), specific interaction searches. Future."}, {"title": "6 Resources", "content": "Open science initiatives have significantly increased the availability of data repositories and tools for researchers in this\nfield. Prominent research institutions include the European Bioinformatics Institute (EBI), the National Cancer Institute\n(NCI), the European Molecular Biology Laboratory (EMBL), the Janelia Research Campus (JRC), the RIKEN Center\nfor Biosystems Dynamics Research (BDR), and the MRC Laboratory of Molecular Biology (LMB). Below is a list of\nuseful data repositories and tools.\n\u2022 BioImage Archive: https://www.ebi.ac.uk/bioimage-archive\n\u2022 Dataverse (hosted by different countries): https://dataverse.org/installations\n\u2022 Electron Microscopy Data Bank (EMDB): https://www.ebi.ac.uk/emdb\n\u2022 The Cancer Imaging Archive (TCIA) https://www.cancerimagingarchive.net\n\u2022 SciLifeLab: https://www.scilifelab.se/data/repository\n\u2022 The cell: https://www.cellimagelibrary.org/pages/datasets\n\u2022 Image Data Resource (IDR): https://idr.openmicroscopy.org\n\u2022 Zenodo: https://zenodo.org\n\u2022 NeuroVault: https://neurovault.org\n\u2022 BrainMaps: https://brainmaps.org\n\u2022 DeepCell https://www.deepcell.org\n\u2022 PyTorch: https://pytorch.org\n\u2022 https://imagej.net/ij\n\u2022 Royal Microscopical Society (RMS): https://www.rms.org.uk\n\u2022 MicroscopyDB: https://microscopydb.io\n\u2022 ZEISS: https://zeiss-campus.magnet.fsu.edu/index.html"}, {"title": "7 Conclusion", "content": "This work provides a comprehensive introduction to microscopy and its relationship to both life science and AI. A\ndetailed classification of different microscopy techniques, alongside key research challenges, is offered to establish a\nfoundational and experimental understanding of the imaging process. We have also explored various obstacles and\nproposed potential solutions, while highlighting a number of future application ideas and relevant resources. It is our\nhope that this work equips researchers with the necessary background, insights, and tools to accelerate their efforts."}]}