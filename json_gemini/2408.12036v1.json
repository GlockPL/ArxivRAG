{"title": "Reasoning and Tools for Human-Level Forecasting", "authors": ["Elvis Hsieh", "Preston Fu", "Jonathan Chen"], "abstract": "Language models (LMs) trained on web-scale datasets are largely successful due to their ability to memorize large amounts of training data, even if only present in a few examples. These capabilities are often desirable in evaluation on tasks such as question answering but raise questions about whether these models can exhibit genuine reasoning or succeed only at mimicking patterns from the training data. This distinction is particularly salient in forecasting tasks, where the answer is not present in the training data, and the model must reason to make logical deductions. We present Reasoning and Tools for Forecasting (RTF), a framework of reasoning-and-acting (ReAct) agents that can dynamically retrieve updated information and run numerical simulation with equipped tools. We evaluate our model with questions from competitive forecasting platforms and demonstrate that our method is competitive with and can outperform human predictions. This suggests that LMs, with the right tools, can indeed think and adapt like humans, offering valuable insights for real-world decision-making.", "sections": [{"title": "1 Introduction", "content": "Forecasting is an essential tool today, playing a critical role in government, corporate, and personal decision-making. Weather forecasting provides essential information for agriculture, natural disaster preparedness for governments, and travel plans for individuals. During the COVID-19 pandemic, lockdown policies were largely determined by forecasts, which were required to be sufficiently accurate due to their global impact (Dub\u00e9 et al., 2020).\nForecasting methodologies fall into two main categories (Webby and O'Connor, 1996): statistical and judgmental. Statistical forecasting leverages time-series modeling and excels with abundant data under stable conditions. Conversely, judgmental forecasting, which we refer to simply as \"forecasting,\" typically relies on human expertise, integrating historical data, domain knowledge, and intuition to make predictions, and is particularly useful when data are sparse or conditions are volatile.\nBy nature, forecasting requires not only accuracy but also the ability to continuously adapt to dynamic data streams. This is where traditional LMs often struggle: timely data updates may cause predictions to change considerably and past data to be irrelevant."}, {"title": "2 Related Work", "content": "Information retrieval Reliable and accurate predictions are largely dependent on the information available to the predictor. This is especially the case of LMs, which are trained on data preceding a knowledge cutoff and have been shown to perform better with information retrieval (Shuster et al., 2021).\nLanguage models model the likelihood $P_{\\theta}(y|x, y_{<i})$ for input sequences x and target sequences y. Retrieval-augmented generation (RAG) (Lewis et al., 2021) proposes augmenting this approach with non-parametric memory, i.e. retrieving the top-k text documents z via $p_{\\eta}(z|x)$ and conditioning the generator on the retrieved passages, $p_{\\theta}(y_i|x, z, y_{<i})$. In a forecasting context, RAG enables us to search for relevant documents z that may contain timely information about the forecasting task x not present in the training data.\nPrior approaches to LLM forecasting (Zou et al., 2022a) propose using neural networks to automate prediction in prediction markets. While language models can be trained to improve their performance on forecasting tasks, their accuracy remains significantly below those of human experts.\nCurrent methods aim to improve the accuracy of LLM forecasting by fine-tuning and scratchpad prompting (Nye et al., 2021; Halawi et al., 2024) or ensembling (Bassamboo et al., 2018; Schoenegger et al., 2024) to first approach human-level forecasting. Concurrent work (Pratt et al., 2024) benchmarks LLMs' forecasting capabilities using the GleanGen prediction market, an internal tool at Google. However, this approach did not accurately reflect real human crowd prediction distributions, and it relied on PaLM2 (Anil et al., 2023), which was suboptimal than GPT models.\nWe propose a zero-shot tool-usage LLM framework without costly fine-tuning and laborious tedious scratchpad format prompting.\nEnsembles Leveraging multiple LLM agents has demonstrated strong performance on a variety of tasks, and improve performance beyond that of a single agent (Talebirad and Nadiri, 2023; Liu et al., 2023). Recent work in tool learning has implemented task planning and execution with separate agents (Song et al., 2023; Shi et al., 2024). LLM forecasting in particular has relied on the wisdom of crowds effect, and has shown that taking ensemble sizes up to 36 outperforms any individual forecasting agent (Bassamboo et al., 2018; Schoenegger et al., 2024).\nWe propose bridging this gap with a hierarchical structure to facilitate cooperation between high-level reasoning and low-level execution agents, and demonstrate that a small ensemble suffices for human-level performance."}, {"title": "3 Reasoning and Tools for Forecasting", "content": "Forecasting is a complex task solving environment, for which we would like to leverage a frozen LM $p_{\\theta}$ as reasoning. Successful forecasting agents rely on the most up-to-date information, and accordingly operate as agents that collect observations $o_t \\in O$ and take actions $a_t \\in A$. The observation space O is natural language, as collected from the prompt itself or information on the internet. The agent's actions are distributed according to $a_t \\sim \\pi(a_t|c_t)$, where $c_t = (o_1, a_1, ..., o_{t-1}, a_{t-1})$ is the context to the agent.\nOur proposed approach $\\pi$ satisfies the following criteria:\n(i) It is simple, scalable, and time-invariant. As we consider different datasets of forecasting questions or language models at least as capable as the current state-of-the-art, we would like our approach to work at least as well.\n(ii) It can produce comprehensive responses through zero-shot prompting from factual information, which can be used to reliably support decision-making in downstream scenarios.\n(iii) These responses should be consistent, i.e. they should correctly synthesize the up-to-date information the model collects.\n(Yao et al., 2023) shows that CoT prompting, even with in-context examples, can iteratively hallucinate to produce incorrect responses on complex tasks. CoT satisfies (i) but neither (ii) nor (iii). We find that CoT's lack of interaction with the environment (i.e. sole reliance on its training data) limits its reasoning abilities and over-emphasizes irrelevant information.\n(Yao et al., 2023) proposes ReAct for this setting: $A = \\{search, lookup, finish\\}$, and observations $o_t$ from search and lookup are collected from $O \\subseteq Wikipedia \\cup web \\,API$. The context is then augmented a thought $\\hat{a}_t \\sim p_{\\theta}(\\hat{a}_t| c_t)$ that composes information about the existing context. This method has shown to significantly enhance the model's ability to refine its responses continuously, reducing the likelihood of erroneous outputs due to lacking critical context information. Vanilla ReAct satisfies (i); as part of our framework, we show that it can additionally satisfy (ii) and (iii)."}, {"title": "4 Experiments", "content": "4.1 Setup\nModels and data (Jin et al., 2021; Zou et al., 2022b) have proposed forecasting benchmarks to assess models' forecasting abilities, simulating forecasting by leveraging that models are only trained up to a cutoff date. However, these benchmarks, consisting of questions that resolved in 2022, are now outdated for evaluating the performance of models such as GPT-40 due to answer leakage in training data (knowledge cutoff October 2023; see Appendix A.1).\nWe curated the dataset on April 15, 2024, when we scraped the platform for questions resolving within the next two weeks and corresponding human crowd predictions. We then filtered out vague questions, and ran every prediction method on these questions, enabling a fair comparison between each method and the human crowd. To prevent answer leakage from the Google API, we set the search range to prior to this date.\nNone of our baselines have direct access to prediction market data, and empirically we found that this information was never scraped via Google search. That is, the prediction given by the ensemble of agents relies on only the agents themselves, with no human crowd influence. (By contrast, if deployed in the real world, this approach could benefit from incorporating the current human crowd performance as an input to the prediction due to the wisdom-of-crowds effect. Indeed, we observe in our experiments that human crowds are fairly well-calibrated.)\nPerformance metrics Our n forecasting questions have true outcomes $o_i \\in \\{0, 1\\}$ and probabilistic forecasts $f_i \\in [0, 1]$. We evaluate our forecasts using Brier scores (Brier, 1950), i.e. $\\frac{1}{n} \\sum_{i=1}^{n} (f_i - o_i)^2$, and accuracy, i.e. $\\sum_{i=1}^{n} 1\\{1\\{f_i > 0.5\\} = o_i\\}$. In case LMs decline to give numerical answers, the question is dropped over all methods when evaluating scores.\nBaselines In Table 1, we compare RTF ensemble to multiple baselines: (a) crowd scores given by the current traded values on Manifold Markets (see Appendix A.2), (b) scratchpad prompting, ensemble, and fine-tuning (Halawi et al., 2024), and (c) base models from different providers.\n4.2 Results and Observations\nTable 1 demonstrates that RTF significantly improves over CoT and scratchpad with fine-tuning. We also achieve comparable Brier score (0.169 vs. 0.172) and superior accuracy (73.9% vs. 73.8%) compared to human predictors using the median and mean of our ensemble, respectively.\nThe optimal strategy to minimize Brier scores is to forecast $f_i = P(o_i = 1)$, so this scoring metric is unbiased. It is typical to compare Brier scores to 0.25, which can be achieved by $f_i = 0.5$ for all i."}, {"title": "5 Conclusion", "content": "We present Reasoning and Tools for Forecasting, a framework to leverage LMs' reasoning capabilities by interacting with the latest information. It is competitive with the predictive capabilities of human forecasters on forecasting platforms. The RTF synthesizes information through a structured decision-making process, ensuring that the predictions are both current and relevant. Additionally, while previous work has shown that ensembling can improve prediction accuracy, a carefully calibrated smaller set of models is often more cost-effective than larger ensembles.\nBy advancing LMs' abilities to reason and dynamically interact with new data, RTF offers a robust tool for real-world decision-making for tasks like forecasting.\nLimitations The evaluation dataset is based on prediction market data and popular questions rather than domain-specific questions. This facilitates a comparison with crowd prediction performance, but may not fully capture the nuances of more specialized domains. In addition, our work focused on predicting binary rather than numerical outcomes."}, {"title": "A.1 Models", "content": "We list the details of models we evaluated in Table 3, where the cutoffs have been retrieved from the model cards. For GPT models, we run them via the OpenAI API. We host Llama-3-7B on a single NVIDIA TITAN RTX 24GB via Ollama for roughly 0.5 GPU-hours. All other approaches are run through the OpenAI API, for roughly 1 hour per naive baseline, 6 hours for our reproduction of (Halawi et al., 2024), and 2.5 hours for our proposed method. For GPT models, we use temperature 0.5 for all the experiments.\n(Halawi et al., 2024) finds that GPT-3.5 and GPT-4 do not have leakage due to post-training. We find that the same is true of GPT-40 and Llama-3-7B: prompting with \u201cAnswer this question without searching the web: Who was appointed to the Governor-General of Australia in 2024?\" yielded a statement about its cutoff date, whereas the correct answer was given when prompted for the answer in 2019.\""}, {"title": "A.2 Crowd Predictions", "content": "On Manifold Markets, players make bets on the outcome of various events where the prices of bets are determined by a current aggregate of crowd predictions, which are prices in [0, 1]. As bets are made, the prices are adjusted by their automated market-makers (Markets, 2022). As shown in (Metaculus, 2023), the crowd prediction is a strong baseline and consistently outperform top forecaster in the prediction market."}, {"title": "B.1 Calibration Index", "content": "The calibration index is a statistical measure used to assess the reliability of a forecasting system; specifically it quantifies the extent to which observed outcomes correspond to forecast probabilities. A well-calibrated model means that if a forecast predicts an event with a certain probability, the event should occur approximately that fraction of the time over many predictions.\nWe calculate the calibration index as\n$CI = \\frac{1}{N} \\sum_{k=1}^{K} N_k (f_k \u2013 o_k)^2$,\nwhere N is the total number of forecasts, $N_k$ is the number of forecasts in bin k, $f_k$ is the mean forecast probability in bin k, and $o_k$ is the observed probability with which events occur in bin k. We select bins as the K-quantiles of the forecasts."}, {"title": "C.1 Questions", "content": "Our final dataset consisted of 201 questions from Manifold Markets. These question were all resolved after April 15, 2024, which was the knowledge cutoff date for our low-level agent supporting the Google Search API. We include a subset of the dataset for reference."}, {"title": "C.2 Knowledge Evaluation by Category", "content": "We show the diversity of our dataset in Table 5, with categories determined by GPT-3.5. Due to the popularity of Economics & Business and Politics & Governance questions on the forecasting platform, we have higher proportions of data in those categories."}, {"title": "D Forecasting Principles Guidance", "content": "Our system prompt requested that the output satisfy elementary forecasting principles. Due to its length, the full prompt will be released along with the codebase and dataset. The forecasting principles are as follows:\n\u2022 You may find relevant time series data online. If the data is recent, you can use zeroth-order or first-order approximations (but for longer time horizons, recall that these may break down due to saturation effects).\n\u2022 Don't ignore base rates for low-probability events that haven't happened, but rather attempt to estimate those probabilities to inform your estimate.\n\u2022 Attempt to approximate the same quantity in multiple different ways. You are welcome to split your reasoning into multiple sections, where in each section you describe how you reached an estimate independently. If your estimates in these sections are very far off, reason through why the estimates are so different, potentially update those estimates, and theorize how confident you are in each estimate. Then, combine those forecasts using a weighted or trimmed mean or median.\n\u2022 Some data can be modeled well using a common distribution, e.g., normal, log-normal, power law, or Poisson distribution (but this is by no means a guarantee). If there's a good reason to believe this is the case, you should use information about those distributions."}, {"title": "E Prompts and Workflows", "content": "Due to length, we have only included one full sample below. In general, we observe that RTF yields more robust CoT-style outputs, whereas base LMs use more linear reasoning that may result in outputs unnecessarily biased towards specific considerations."}, {"title": "E.1 Prompt", "content": "Will ETH close above $3700?\nBackground: None\nResolution criteria: None\nClosure time: April 30, 2024\nFor reference, this prompt resolved as NO (0)."}, {"title": "E.2 RTF Output", "content": "[Entering new AgentExecutor chain...]\nTo forecast the probability that ETH (Ethereum) will close above $3700 on April 30, 2024, I'll follow a structured approach:\n1. **Reference Classes and Base Rates**:\nHistorical price trends of Ethereum.\nHistorical performance of similar cryptocurrencies.\nGeneral market conditions and trends in the cryptocurrency market.\n2. **Recent News and Distinctive Features**:\nRecent developments in Ethereum technology.\nRegulatory news affecting cryptocurrencies.\nBroader economic conditions impacting the cryptocurrency market.\n3. **Statistical Modeling**:\nUse historical price data to model potential future price movements.\nConsider volatility and distribution patterns typical for Ethereum.\n### Step-by-Step Analysis\n#### 1. Reference Classes and Base Rates\nFirst, let's look at the historical price data of Ethereum. We want to understand how often Ethereum has closed above $3700 in the past and under what conditions it has done SO.\nThought: Do I need to use a tool? Yes\nAction: Google Search Snippets\nAction Input: \"historical price data of Ethereum\"\nTo forecast the probability that ETH (Ethereum) will close above $3700 on April 30, 2024, I'll follow a structured approach:\n1. **Reference Classes and Base Rates**:\nHistorical price trends of Ethereum.\nHistorical performance of similar cryptocurrencies.\nGeneral market conditions and trends in the cryptocurrency market.\n2. **Recent News and Distinctive Features**:\nRecent developments in Ethereum technology.\nRegulatory news affecting cryptocurrencies.\nBroader economic conditions impacting the cryptocurrency market.\n3. **Statistical Modeling**:\nUse historical price data to model potential future price movements.\nConsider volatility and distribution patterns typical for Ethereum.\n### Step-by-Step Analysis\n#### 1. Reference Classes and Base Rates\nFirst, let's look at the historical price data of Ethereum. We want to understand how often Ethereum has closed above $3700 in the past and under what conditions it has done so.\nThought: Do I need to use a tool? Yes\nAction: Google Search Snippets\nAction Input: \"historical price data of Ethereum\"\nEthereum Price History. Daily. Weekly. Monthly. 3/28\nHistorical Data. Frequently Asked Questions (FAQS)\nWhat Does Ethereum's Market Cap History Reveal About...Jan 8, 2023 Price history of ETH: On August 7, 2015, the first Ethereum transaction was carried out using the transaction hash of block 46147. Since its...Ethereum's (ETH) highest price in late 2021 was much higher than any other price seen in a chart that looks at the previous 5 years as well as 2023. Track the latest Ethereum price, market cap, trading volume, news and more with CoinGecko's live ETH price chart and popular... Features real-time (live) charts, ethereum blockchain, news and videos. Learn about ETH, the current hashrate, crypto trading and more. Dec 18, 2016 There is no canonical ETH or BTC price, each exchange has its own. Exchange may or may not collect historical data, and granularity of such data... Sep 1, 2017Ethereum price history API? I am working on a"}, {"title": "E.3 GPT-40 Output", "content": "To forecast whether ETH (Ethereum) will close above $3700 by April 30, 2024, we need to consider several factors, including historical price data, market trends, and current events that could influence the price. Let's break down the analysis step-by-step.\n### Step 1: Historical Data and Base Rates\nFirst, we need to look at the historical price data for ETH to understand its past performance and volatility. We can use this data to establish a base rate for how often ETH has closed above $3700 in the past.\n#### Historical Price Data\nETH has been highly volatile, with significant price swings over the past few years.\nETH reached an all-time high of around $4800 in November 2021.\nSince then, the price has fluctuated, with periods of both significant gains and losses. Let's assume we have the following historical data for ETH closing prices over the past few years: 2021: ETH closed above $3700 on 50 days.\n2022: ETH closed above $3700 on 20 days.\n2023 (up to October): ETH closed above $3700 on 10 days.\nGiven this data, we can calculate the base rate for ETH closing above $3700.\n#### Base Rate Calculation Total number of days in the dataset: 365 (2021) + 365 (2022) + 273 (2023 up to October) =\n1003 days Total number of days ETH closed above $3700: 50 (2021) + 20 (2022) + 10 (2023) = 80 days Base rate =\n80/1003 approximate to 0.08 (8%)\n### Step 2: Current Market Trends and News\nNext, we need to consider the current market trends and any recent news that could impact the price of ETH.\n#### Market Trends\nThe cryptocurrency market has been experiencing increased institutional interest and adoption.\nRegulatory developments could either positively or negatively impact the market.\nMacroeconomic factors, such as inflation and interest rates, could influence investor sentiment. #### Recent News\nEthereum's transition to a proof-of-stake (PoS)\nconsensus mechanism (Ethereum 2.0) could have a significant impact on its price.\nAny major security breaches or technological advancements could also affect the price. ### Step 3: Adjusting the\nBase Rate Based on the current market trends and recent news, we need to adjust our base rate. #### Positive Factors\nIncreased institutional interest and adoption could drive the price higher.\nThe successful implementation of Ethereum 2.0 could boost investor confidence.\n#### Negative Factors\nRegulatory crackdowns could negatively impact the price.\nMacroeconomic factors such as rising interest rates could lead to reduced investment in riskier assets like cryptocurrencies.\n### Step 4: Combining Estimates\nWe can combine our base rate with adjustments for current trends and news to arrive at a final probability estimate.\n#### Adjusted Probability\nBase rate: 8%\nPositive adjustment: +5% (for increased adoption and Ethereum 2.0)\nNegative adjustment: -3% (for potential regulatory and macroeconomic risks)\nFinal adjusted probability = 8% + 5% - 3% = 10%\n### Step 5: Final Probability Estimate\nAfter considering all factors, my best prediction for the probability of ETH closing above $3700 by April 30, 2024, is: **0.10 (10%)**\nThis estimate balances the historical base rate with current market trends and potential risks, aiming to minimize the Brier score by being well-calibrated and resolved."}]}