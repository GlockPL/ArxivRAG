{"title": "Generalizability analysis of deep learning predictions of human brain responses to augmented and semantically novel visual stimuli", "authors": ["Valentyn Piskovskyi", "Riccardo Chimisso", "Sabrina Patania", "Tom Foulsham", "Giuseppe Vizzari", "Dimitri Ognibene"], "abstract": "The purpose of this work is to investigate the soundness and utility of a neural network-based approach as a framework for exploring the impact of image enhancement techniques on visual cortex activation. In a preliminary study, we prepare a set of state-of-the-art brain encoding models, selected among the top 10 methods that participated in The Algonauts Project 2023 Challenge [16]. We analyze their ability to make valid predictions about the effects of various image enhancement techniques on neural responses. Given the impossibility of acquiring the actual data due to the high costs associated with brain imaging procedures, our investigation builds up on a series of experiments. Specifically, we analyze the ability of brain encoders to estimate the cerebral reaction to various augmentations by evaluating the response to augmentations targeting objects (i.e., faces and words) with known impact on specific areas. Moreover, we study the predicted activation in response to objects unseen during training, exploring the impact of semantically out-of-distribution stimuli. We provide relevant evidence for the generalization ability of the models forming the proposed framework, which appears to be promising for the identification of the optimal visual augmentation filter for a given task, model-driven design strategies as well as for AR and VR applications.", "sections": [{"title": "1 Introduction", "content": "The historical connection between computer vision and brain modeling has long been a driving force in the field of artificial intelligence and machine learning. This interdisciplinary approach has been fueling advancements in both domains, drawing strong inspiration from our understanding of the brain's layered, distributed, and \"active\" processing mechanisms [12,20,21,32,57]. Modern machine learning models have progressed beyond traditional computer vision tasks, now capable of predicting rich brain activation patterns based on presented natural stimuli [27,37]. Although these models do not achieve spatially and temporally"}, {"title": "2 Related Work", "content": "There are a variety of studies analyzing image enhancement techniques, typically with the aim of identifying the optimal technique, which explicitly rely on the human perception of these augmentations. Some of these approaches are focused solely on properties of the Human Visual System (HVS) known from theory, such as [7], while others involve more explicit models of visual mechanisms. For instance, [53,54,60] analyzed several enhancement algorithms, adopting a mathematical approach based on Logarithmic Image Processing [40,49] for simulating the HVS. However, explicit investigation of the impact of image enhancement on the human brain appears to be an under-explored area in this field. The problem of simulating how various image transformations are perceived by the visual cortex is largely unaddressed.\nWith the advent of Deep Neural Networks (DNN), their ability to learn both low-level and more complex visual features [59], proved to be useful for the brain encoding task. Numerous studies, conducted with the aim of investigating various brain processes, employed this method as a means to simulate and explain such mechanisms. For instance, [11] presented an original DNN-based fMRI encoder to investigate the characteristics of the Human Visual System by drawing parallels between its architecture and the hierarchical organization of Convolutional Neural Networks. [17] adopted a DNN to map natural images to neural signals with the objective of studying the representation of complex visual features in the human brain. An interesting conclusion reported in that study is that this approach, based on deep learning models, still has considerable drawbacks and is not capable of precisely replicating all the complex neural processes. Many other examples of studies, employing or investigating this category of brain encoding solutions, can be found. The specific models adopted in this work are [1,16, 28, 34, 38, 58].\nCreating a single framework for studying heterogeneous image enhancement techniques is challenging. Empirical studies have demonstrated that models with similar in-distribution performance can exhibit significantly different out-of-distribution performance [35, 50]. This suggests that a model's ability to generalize beyond its training data can vary greatly, and performance metrics within the training distribution may not accurately predict performance"}, {"title": "3 Methodology: Brain Encoding Models", "content": "In order to develop the proposed framework upon high-performance brain encoding neural networks, we selected the best-ranked models that participated in The Algonauts Project 2023 Challenge [16]. These solutions were built to accurately predict human brain responses to images of natural scenes, in the form of Blood Oxygenation Level Dependent (BOLD) functional Magnetic Resonance Imaging (fMRI) values observed in a series of voxels.\nWe followed the training procedures reported in the original papers of the 2nd [1], 3rd [38] and 6th [28] classified models. We also employed the baseline approach [16] presented by the organizers. In order to increase the diversity of the set of neural networks, we included our original brain encoding model based on VMamba [30] (Appendix). We plan also to test positional encoding based methods [8]. We trained the neural networks, using only the Subject 1 data from the Natural Scenes Dataset (NSD) [2], which was adopted in the Algonauts Challenge. Given that the training procedure of the 6th classified model does not provide for such a separation, we trained this network on the entire set of stimuli and extracted predictions using the module specific to Subject 1. Due to hardware limitations and time constraints we were not able to exactly replicate the training recipes proposed by the authors. Specifically, in most cases, the ensembles of various configurations described in the original reports were not fully reproduced.\nWe estimated the reliability of the models' predictions by measuring their intrinsic entropy, which is independent of data diversity. As suggested in [14] and previously shown in [18], the ensembling method exhibits superior performance as a model uncertainty metric. Its main point is to introduce as much variety as"}, {"title": "4 Results", "content": "We use all the 1956 images from the test sets of all the subjects from NSD to create 5 differently augmented versions of each of them (Figures 1a to 1f). These augmentations aim at highlighting one or more objects, which correspond to the original annotated segments of the COCO dataset [29] adopted by [2]. We use all the trained models to predict visual cortex response to all the stimuli. \nTo have a better understanding of the reliability of the predictions in this out of distribution setting, we analyzed the model's performance on particular classes of augmentations: text and faces (chosen due to the presence of the corresponding brain areas in the dataset [2]), as shown in Figure 2. We observed that the models perform reasonably well on these augmentations. In fact, as illustrated in the plots in Figures 13-16 in the Appendix, the brain regions associated with these specific types of object are sensitive to their occlusion (i.e., when they are obscured). This sensitivity highlights the ability of the model to accurately predict neural responses to altered stimuli. Since the neural correlates of faces and text are well-established, the model's effective performance on these objects suggests its overall robustness and reliability in predicting brain responses to various augmentations.\nTo further evaluate the robustness of the models' predictions we trained the 6th classified model on 5 different folds, comprising 20% of all the images for Subject 1. We observe that the mean standard deviation across all the images is higher than the same metric computed over all the images (for a single model or fold). This means that the variation of the predicted responses is mainly due to the intrinsic variability of the stimuli, indicating a high consistency of the predictions made by this network. We also notice that although the standard deviation is low, the model remains sensible to augmentations, exhibiting a significant variation of predicted activation (columns 14-17 of Table 1). In the appendix we report the area specific analysis."}, {"title": "4.2 Models trained without images of specific object classes", "content": "First, considering a relatively high performance of both the 3rd and 6th classified models in the previous experiment, we perform the training of these models on the original dataset, from which we separately remove images depicting cats, dogs, mobile phones, and TVs (two natural entities and two man-made objects). Second, we train the same brain encoders, excluding only 100 stimuli for each category, in order to use them as the test set. In the latter case we also eliminate some randomly selected pictures to obtain two datasets of the same size for each type of object. We evaluate the error of the predictions made by the two versions of models on the test set containing 100 images, each depicting the corresponding entities (cats, dogs, mobile phones, TVs). For each of the obtained instances (8 in total) of the original dataset, the 6th classified model is also trained on 5 randomly generated folds, each containing 20% of all images (remaining after the mentioned removal of certain stimuli). We evaluate the consistency of the predictions by computing the mean voxel-wise standard deviation across the 5 instances, each trained on a separate fold. These results are summarized in Table 2. In the appendix we report the area specific analysis."}, {"title": "5 Conclusion", "content": "The generalization ability of the analyzed neural networks and, thus, the validity of the proposed framework as a means of studying image enhancement techniques are supported by relevant evidence. Some sensible and explainable patterns are observed when evaluating and comparing various changes in the fMRI signal predicted by the models as a response to augmentations applied to visual stimuli. Specifically, the impact of some augmentations is found to be consistent with the results of neuroscientific studies concerning object selectivity (the reactions to individual images observed in certain brain areas) and color sensitivity of brain regions (the responses of early visual ROIs to transformations affecting colors). Relatively low variability of predictions indicates low uncertainty of the models regarding the expected impact of augmentations. For most of the areas of the visual cortex, several neural networks (and in some cases all of them) agree on the changes induced by various enhancement techniques, which suggests the soundness of the proposed framework.\nFurthermore, the generalizability of the fMRI encoders is supported by the results of a series of experiments aimed at verifying the sensitivity of certain brain"}]}