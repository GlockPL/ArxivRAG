{"title": "A logical alarm for misaligned binary classifiers", "authors": ["Andr\u00e9s Corrada-Emmanuel", "Ilya Parker", "Ramesh Bharadwaj"], "abstract": "If two agents disagree in their decisions, we may suspect they are not both correct. This intuition is formalized for evaluating agents that have carried out a binary classification task. Their agreements and disagreements on a joint test allow us to establish the only group evaluations logically consistent with their responses. This is done by establishing a set of axioms (algebraic relations) that must be universally obeyed by all evaluations of binary responders. A complete set of such axioms are possible for each ensemble of size N. The axioms for N = 1,2 are used to construct a fully logical alarm one that can prove that at least one ensemble member is malfunctioning using only unlabeled data. The similarities of this approach to formal software verification and its utility for recent agendas of safe guaranteed AI are discussed.", "sections": [{"title": "Introduction", "content": "Formal verification of AI systems has recently been proposed as a way to make them safer[18, 3]. So far, these proposals have focused on aspects of machine training and decision making - how do we train and/or certify AI agents to make them safer? Here we consider formal verification of unsupervised agent evaluations, whether human or robotic.\nConsider an ensemble of N agents given a task. No matter how complex the task, we can engage other agents to evaluate or supervise them. This has become a popular methodology for making safer and more trustworthy LLM systems. Weak-to-strong supervision [1] has been proposed to tackle the fundamental challenge of aligning superhuman models. LLMs criticizing LLM code generators reduce bugs [11]. Adversarial AI debates help weaker or non-expert humans answer questions more accurately [5, 8]. All such schemes inevitably raise the specter of infinite regression (supervisors that supervise supervisors that ...) or are unverifiable themselves. This problem is not inherently an AI problem but rather a classic problem in epistemology and economics - the principal/agent monitoring problem. Agents whether human or robotic are employed to carry out tasks. The principal, the one responsible for giving them the task, does not have the ability or time to supervise them. How can the principal make sure that the agents are doing their work correctly and safely?\nThe approach taken here is that we can formalize unsupervised evaluations so as to ameliorate this bottleneck problem in operating safe AI systems. Formal verification of software systems is well known and has notable, direct applications to the safety of complex engineering systems such as nuclear plants [9]. Here we consider how to formalize verification of unsupervised evaluations. In such settings there is no answer key that can help us grade or evaluate noisy agents that have taken a test. A logic in such settings cannot prove the soundness of group evaluations. But it can prove their logical consistency - what are the group evaluations that are consistent with how they responded on the test?"}, {"title": "A verification formalism for binary evaluations", "content": "There are many evaluation models for a binary response test. The ones used here are associated with the 2^N possible decision patterns when we observe the joint decisions of an ensemble on a given item or question. We will detail the models for the N = 1 and N = 2 cases."}, {"title": "An evaluation model for the trivial ensemble, N = 1", "content": "The evaluation model for the trivial ensemble (N = 1) is defined by the observable response statistics Rai and Rb - the number of times a classifier i gave a A or B response (our generic designation of the two possible responses on each question in the test). For any finite test of size Q, we can enumerate all the triples (Ra\u2081,a, Rb\u2081,b, Qa) that will contain the true evaluation of any responder These are the number of correct responses for each label, Ra\u2081,a and Rb\u2081,b.\nThere are 1/6(Q + 1)(Q + 2)(Q + 3) possible evaluations for a single classifier in (Raz,a, Rb\u2081,b, Qa) space. No triplet outside this set can be considered a correct evaluation for any classifier. Enumerating the points in (Rai,a, Rbi,b, Qa) is not enough to fix an evaluation model and how it is being used in its application context. There are two possible models, both with the same algebraic logic. The first model is where we are directly evaluating binary classifiers. In this model there is a fixed semantic equality between label responses to questions. The second model is used when we are grading a binary response test and there need not be any semantic equality between correct responses to questions. Each has its own safety specification.\nIn the case of evaluating binary classifiers we can formulate a safety specification such as,\nP_{a,a} := \\frac{R_{ai,a}}{Q_a} > 50\\%, P_{b,b} := \\frac{R_{bi,b}}{Q-Q_a} > 50\\,%\n(1)\na safe binary classifier is one that is better than 50% on both labels. In the case of binary response tests there is no relation between labels so the only meaningful safety specification is that a responder was better than x per cent correct on the test,\nP_aP_{aa} + P_bP_{bb} > x\\%,%\n(2)\nwhere Pa and Po give the prevalence of A and B type questions on the test. Neither of these prevalences has any semantic meaning outside the test.\nIn either of these two interpretations of a binary test, we can establish an algebraic relation between observed responses and how correct the responder was on the test,\nR_{a_i} = R_{ai,a} + (Q_b - R_{bi,b})\nR_{b_i} =(Q_a - R_{ai,a}) + R_{b,b}.\n(3)\n(4)\nThese equations are complete but not independent. This follows from the equation,\nQ = R_a + R_b.\n(5)\nHaving observed Ra\u2081 or Rb\u2081, either of these equations defines the same plane in (Rai,a, Rbi,b, Qa) space. This reduces the number of possible evaluations for a classifier from O(Q\u00b3) to O(Q2). This variety and any equation that generates it defines the N = 1 axiom for our evaluation model of binary tests. All the members of an ensemble of binary responders must obey it."}, {"title": "The N=2 construction", "content": "Two binary classifiers have four possible decisions patterns (Rai,aj, Rai,bj, Rbi,aj, Rb,b;) when we align their decisions by item/question in the test. The counts for each of these patterns can be expressed in terms of their individual (Ra\u017c,a, Rbi,b, Raj,a, Rbj,b) and joint correctness on the test (Rai,aj,a, Rbi,bj,b). In the appendix we discuss how this generating set is equivalent to two copies of the single classifier axiom (one for each classifier) and a new axiom for the pair,\nR_{ai,aj,a} + R_{bi,bj,b} - Q_a + (R_{a_i} + R_{aj}) \u2013 (R_{ai,aj}) \u2013 (R_{az,a} + R_{aj,a})\n(6)\nSimilar to the case of the single classifier axiom, this has two versions. The one shown here is the label A version. Observing a pair classifiers introduces a new relation between test observables and statistics of correctness on it. And as we would expect, each member of the pair still obeys the single classifier axiom. This confirms what we would suspect intuitively since the single classifier axiom only involves quantities related to one classifier alone. It may seem overkill to claim these relations are \"axioms\" for the logic of unsupervised evaluations of binary classifiers. This topic is discussed further in the appendix in the context of detecting corrupted or spoofed test summaries thereby showing the connection of this logic with trustworthiness."}, {"title": "Verifying at least one classifier is malfunctioning", "content": "The axioms in the previous section are, themselves, verifiers of group evaluations. Given observed responses, we can ask - what group evaluations satisfy them? Any evaluation algorithm that returned evaluations that violated them would be certifiably wrong. This ability to prove that a group evaluation is logically consistent with test response statistics can be used to create a logical alarm for misaligned classifiers. We will do so using the semantic interpretation of the binary test. Our arbitrary safety specification will be that all classifiers are required to be better than 50% on each label (Equations 1). In general, any range is possible as will become clear from the geometrical nature of the algorithm.\nThe general idea of the alarm is that all the classifiers in an ensemble must satisfy the single classifier axiom. We do not know the actual value of Qa in a fully unsupervised setting. But we know that the true value must be an integer between 0 and Q. At each fixed Qa value, the first classifier axiom defines a line establishing a dependency relation between Rai,a and Rb,b - the plane defined by the axiom is intersected by the horizontal plane at the assumed Qa value. This allows us to define the only pair evaluations consistent with test responses at that value of Qa. If no group evaluation satisfies the safety specification, the system is malfunctioning at the assumed Qa value. We can continue this procedure for all possible values of Qa and if at each assumed setting the ensemble fails the safety specification, we know that at least one classifier is malfunctioning."}, {"title": "The rectangle of logically consistent label evaluations at fixed Qa", "content": "At fixed Qa we can compare pairs of classifiers (i, j) by finding the set of possible evaluations in two separate spaces, one for each label. For the A space, we use the variables (Rai,a, Raj,a). The B space is defined by the variables (Rb\u2081,6, Rb;,b). Since Qa is fixed, the set of possible evaluations in each space defines a square of points. For label A, the square is an integer lattice going from 0 to Qa. And for label B, the square is an integer lattice from 0 to Q \u2013 Qa. These are the possible group evaluations for the pair before we use the axioms.\nThe single classifier axiom restricts the set of possible correct responses in each of the label spaces. We illustrate how with the label A. The single classifier axiom can be written expressing Rb,b in terms of Q, Qa, Rai, and Raza as\nR_{b,b}=Q-Q_a - R_{ai} + R_{az,a}.\n(7)\nBut we know that the number of correct B responses, Rb\u2081,b, must be between 0 and Qt for any given classifier i\n0\u2264Q-Q_a-R_{ai} + R_{ai,a} \u2264 Q - Q_a.\n(8)\nThis equation thus defines the values of Rai,a that are consistent with the single classifier axiom at the assumed Qa value. Since we can do this for both members of a pair, the subset of group evaluations is a rectangle in A space. A similar argument can be used to define the logically consistent rectangle in B space starting with the B version of the single classifier axiom,\n0 \u2264 Q_a-R_{b_i} + R_{bi,b} \u2264 Q_a.\n(9)"}, {"title": "Testing at all possible values of Qa", "content": "In a fully unsupervised setting the value of Qa, itself, is not known. But its value is finite and we know that it lies between 0 and Q. It thus becomes possible to test if the ensemble violates the safety specification at all assumed values of Qa- if not we know that at least one member of the ensemble is malfunctioning.\nThis logical argument cannot tells us under what conditions - other than possible values of the evaluation sketch - this detection becomes possible. In other words, what constitutes enough of a difference in agreement to trigger the alarm remains an engineering problem. This is similar to how the sensitivity of fire or gas alarms are determined by their application context. What is notable here is that this alarm is purely based on logical consistency of test responses.\nThe alarm is not foolproof. If all members of an ensemble are malfunctioning in the same manner, this algorithm cannot detect anything wrong. The algorithm can only detect that the classifiers are misaligned. In this regard, engineering use of the alarm should follow a defense in depth design - creating ensembles large enough that the failure of a few members is more likely than all of them at once. Additionally, in semi-supervised evaluation settings, we may have side information that can ground the alarm. For example, the range of possible Qa values may be known. For misaligned classifiers, correctly satisfying the safety specification occurs at Qa values that are not the true one."}, {"title": "Discussion and previous work", "content": "We have constructed a series of evaluation models for binary evaluations of N noisy agents. These allow us to identify a nested set of axioms (all singletons, all pairs, etc...) that must be satisfied by any binary evaluation. These axioms define the set of all group evaluations consistent with just their observed responses. The axioms serve as verifiers and can reject incorrect evaluations. They can also be used to detect ensembles that violate safety specifications expressible in terms of statistics of correctness on binary tests. This logic for unsupervised evaluation is therefore a concrete example of how formal verification methods can be used to help us monitor noisy agents. As we can see, it is much easier to formulate and formalize evaluation models than world models. Another advantage of a logic of fully unsupervised evaluation is that we can apply it to circumstances where an answer key exists but we suspect it is wrong or has been spoofed - it is a tool for checking trustworthiness.\nMost work in the ML/AI literature on unsupervised evaluation is about creating evaluation algorithms. The seminal paper by Dawid and Skeene [4] used a likelihood minimized with the EM algorith to estimate the accuracy of doctors reviewing medical charts for diagnosis. Subsequently, it has received many probabilistic treatments at this conference and others. One stream could be characterized as the Bayesian approach [16, 21, 23, 10, 22]. A spectral approach was initiated by Parisi et al [12] and further developed by Jaffe et al [7, 6]. Evaluation is an abstract task that can occur anywhere in the ML cycle. Unsupervised evaluation issues occur during supervised training of classifiers [17]. The work closest to the algebraic, logical approach taken here is by Platanios et al and their agreement equations [14, 15]. They correctly noted the purely algebraic and logical basis for their work and that of others. Agreements, however, are just 2 out of 2N events so the agreement equations do not form a complete generating set and therefore cannot be used for verification. The Platanios solution to evaluation for error-independent classifiers [14] is incorrect as discussed in the appendix.\nThe use of algebraic geometry in statistics was pioneered by Pistone et al [13]. They were not concerned with sample statistics as we are here, but rather on experimental design and inference problems with distributions. Using sample statistics for evaluation has many similarities to data streaming algorithms and error-correcting codes as discussed further in the appendix."}, {"title": "Limitations and societal impacts", "content": "Formalization of verifying measurements cannot resolve the problem of interpreting them. For that one requires a world model. Formalization of unsupervised evaluation is possible because it deals with evaluation models of sample statistics of an evaluation. As such, it cannot tells us anything about future or past values for those statistics. That is the job of evaluation models that incorporate probability assumptions or other domain knowledge rules. An analogy with safety engineering in other realms may help the reader circumscribe properly the power and limitations of any logic of unsupervised evaluation.\nThermometers and smoke detectors are used as alarm components within safety frameworks. A thermometer can be used to alarm the on-board computer that a car engine is overheating. A smoke detector can bring attention to a possible fire. Neither the thermometer nor the smoke alarm have much intelligence of their own. They cannot tell you what causes the over heating or smoke. Nor can they diagnose how to fix the problem. Logics of unsupervised evaluation can serve a similar role within safety frameworks of noisy agents. Doctors use thermometers to help keep patients safe.\nResponsible use of any measurement methodology requires that we understand the effects of over reliance on it. This has been noted in the AI safety literature. For example, Dalrymple et al's [3] mention of Goode's Law. Or even the misalignment of single measures with human values [20]. Formalization also can lull its users into believing all its well. We see here how misguided that can be in how the logical alarm is constructed. It can never prove that all the classifiers are working correctly. It can only detect when they are not. That it can certify with logical certainty. But the logical converse is not possible. All true group evaluations where the ensemble members are behaving roughly similar, whether correctly or not, will not trigger the logical alarm presented here.\nOne positive societal benefit of this formalization follows directly from the previous statement. It is a direct demonstration of the utility of noisy agents when performing any difficult task. It is only when agents disagree that we can use their own decisions to self-evaluate them. Even in cases where there is a high performing agent, whether human or robotic, an ensemble of noisy, weaker agents can be used to supervise it via this evaluation logic.\nA second benefit from logics of unsupervised evaluation is the role they play in the economic problems related to principal/agent interactions. As is discussed in the Appendix, exact, fully algebraic evaluation is possible when the noisy agents are error independent on a test. Even in that exact solution, two possible group evaluations exist. There always has to be some principal that establishes the correct one. Supervision is always necessary even for something so simple as binary response evaluations. But this logic makes it much easier since it serves as sieve for possible evaluations. Any Bayesian calculation that computes the number of questions that need to be ground checked to establish a desired range of possible evaluations would be able to start with a set at least 1/Q smaller than the fully ignorant set (all possible evaluations). This could be as small as 1 for certain test results. If we detect that one of the classifiers is 100% or 0% correct on both labels, we would just need to check one question to ascertain which evaluation was correct. This would simultaneously ground the evaluation of all the other members of the ensemble in the case of error-independent test results.\nFinally, some researchers are concerned that the problem of super-alignment - being able to supervise agents smarter than us is fundamentally unsolvable. If that was the case, it would be the first technology for which we cannot build controls than are simpler and less intelligent than the systems they control. Special case solutions like the error-independent evaluation model allow us to engineer systems that we can evaluate on any binary test - the algorithms are devoid of any semantics of the world. In this way, it is a tool like the steam governor controls runaway locomotives, the car thermometer alarms us about overheating engines, and the smoke alarm warns us about possible fires. If fires are not usually controlled by building bigger fires, so we should consider that less-intelligent mechanisms are an integral component of any safe and trustworthy system."}, {"title": "Appendix / supplemental material", "content": "The machinery for formalizing the logic of unsupervised evaluation already exists in the field of Algebraic Geometry (AG). Theorem provers in geometry are another example of how AG is used in formal verification (Chapter 10 in Cox [2]). This appendix is written in a gentler style that is going to sketch the AG proofs. This may help the reader become familiar with AG if this is their first encounter."}, {"title": "Definitions and the set of all possible evaluations for tests of size Q", "content": "The paper discussed evaluation models in response space or R-space. Researchers in ML and AI usually discuss evaluation in percentage space or P-space. This section provides definitions for all the relevant statistics discussed in the paper in both spaces."}, {"title": "R-space definitions", "content": "The observable statistics are,\n\u2022 Q: number of items/questions in the evaluation.\n\u2022 Ra: number of times classifier i responded A."}, {"title": "P-space definitions", "content": "The observable statistics are,\n\u2022 Q: number of items/questions in the evaluation.\n\u2022 fa\u2081 = Ra/Q: percentage of times classifier i responded A.\n\u2022 fb\u2081 = Rbz/Q: percentage of times classifier i responded B.\nThe unobservable statistics are,\n\u2022 Pa = Qa/Q: percentage of correct A responses.\n\u2022 P\u2081 = Qb/Q: percentage of correct B responses.\n\u2022 Para = Raza/Qa: percentage of correct A responses.\n\u2022 Pb,b = Rbi,b/Q\u266d: percentage of correct B responses."}, {"title": "The set of all possible single binary classifier evaluations of size Q", "content": "Evaluation models are much easier than world models. We can enumerate all the possible evaluations for a single binary classifier in R-space, (Rai,a, Rb\u2081,b, Qa). The following algorithm generates all of them for a test of size Q,"}, {"title": "The evaluation ideals in R-space and P-space", "content": "The set of all possible points for the single classifier test summary looks different in each space. After we have observed a classifier responses, we can invoke the single classifier axiom which can be written in each space,\nP_a(P_{ai,a} - f_{ai}) - P_b(P_{bi,b} - f_{bi})\n(10)\n(QR_{ai,a} - Q_aR_{ai}) - (QR_{bi,b} - Q_bR_{bi}).\n(11)\nThe R-space version of the axiom can be manipulated into the forms necessary for the construction of the consistent cuboid by using the identity,\nQ = R_{ai} + R_{bi}.\n(12)"}, {"title": "Construction of the N=2 axiom", "content": "There are two approaches to deriving the N = 2 axiom, one in R-space the other in P-space. We first show the hardest approach, using P-space, because it highlights test statistics related to decision error correlations between the members of an ensemble. The second approach, using R-space, is direct and readily generalized to any ensemble of size N."}, {"title": "The N = 2 generating set in P-space and its axioms", "content": "In P-space one uses sample frequencies of all the possible 2^N patterns, the observed count of the patterns divided by the size of the test. This is what guarantees their completeness - there are no other patterns that we do not know about. For ensembles of size N = 2 with classifiers, {i, j}, that completeness is given by,\nf_{ai,aj} + f_{ai,bj} + f_{bi,aj} + f_{bi,bj} = 1.\n(13)\nFor each of the 4 decision patterns, we can write a polynomial of variables in P-space,\nf_{ai,aj} = P_a (P_{aia} P_{aja} + \\Gamma_{ij}) + P_b ((1-P_{b,b}) (1-P_{bj,b}) + \\Gamma_{ij})\nf_{ai,bj} = P_a (P_{aisa} (1 - P_{aj,a}) - \\Gamma_{ij}) + P_b ((1-P_{b,b}) P_{bi,b}- \\Gamma_{ij})\nf_{bi,aj} = P_a ((1 \u2013 P_{aia}) P_{aja} - \\Gamma_{ij}) + P_b (P_{b,j} (1 - P_{bj,b})-\\Gamma_{ij})\nf_{bi,bj} = P_a ((1 - P_{aia}) (1 - P_{aja}) + \\Gamma_{ij}) + P_b (P_{bi,b} P_{bj,b} + \\Gamma_{ij})\nSince all the observable decision frequencies are on the left and all the statistics of correctness are on the right, this is a map from P-space to what we can call F-space. This justifies calling them a generating set - given the statistics of correctness for one's chosen evaluation model, they generate the decision frequencies we have seen on the test.\nAlthough more complicated, the P-space generating set for the pair ensemble introduces new sample statistics of correctness that are needed to generate all the possible decision patterns we could see from a binary evaluation. Sample statistics are needed to represent the decision correlations between the members of the ensemble. We only need two, one for each label, for binary evaluations - \u0393; and \u0393. In general we need R^R \u2013 R for classifications/tests with R labels/responses. They are defined as,\n\\Gamma_{ij} := \\frac{R_{ai,aj}}{Q_a} - \\frac{R_{ai} R_{aj,a}}{Q_a Q_a}\n(14)\n\\Gamma_{ij} := \\frac{R_{bi,bj}}{Q_b} - \\frac{R_{bib} R_{bj,b}}{Q_b Q_b}\n(15)\nThese are algebraic definitions. They define a different notion of independence from that of distri-butional independence that is used in probability theory. Notions of independence occur in many"}, {"title": "The N = 2 axiom in R-space", "content": "The generating set in R-space can be derived from that in P-space. It is shown here so the reader can compare it with the P-space representation.It generates the (Rai,aj, Rai,bj, Rbi,aj, Rbi,bj) test summaries,\nR_{ai,aj} = R_{ai,aj,a} + (Q_b - R_{b,b} - R_{bj,b} + R_{bi,bj,b})\n(25)\nR_{ai,bj} = (R_{ai,a} - R_{ai,aj,a}) + (R_{bj,b} - R_{bi,bj,b})\n(26)\nR_{bi,aj} = (R_{aja} - R_{ai,aj,a}) + (R_{bi,b} - R_{bi,bj,b})\n(27)\nR_{bi,bj} = (Q_a - R_{ai,a Raj,a + R_{ai,aj,a}) + R_{bi,bj,b}\n(28)\nThe reader can see this R-space representation is not as symmetric as the P-space representation. It also does not make clear what is the role of error correlation between the members of the pair. Instead of using this generating set to find the N = 2 axiom in R-space, we are just going to construct it directly. There are two equivalent constructions as we have mentioned before. We will detail the label A construction. The construction for label B merely changes the label.\nWe want to derive an expression for the quantity Rb,bj,b, the number of observed counts were both responders answered B to B type questions. To do that, we write it as Qb minus the number of times each alone gave an A response incorrectly minus the number of times they both said A incorrectly. The number of times related to both making the mistake alone gives us our first terms,\nR_{bi,bj,b} = Q_b - (R_{ai} + R_{aj}) + (R_{ai,a} + R_{aj,a})...\n(29)\nBut this under counts by one each time they both got it wrong so we correct with the joint decision observed and correct counts,\nR_{bi,bj,b} = Q_b - ((R_{ai}+R_{aj}) - (R_{ai,a} + R_{aj,a})) + (R_{ai,aj} - R_{ai,aj,a})\n(30)"}, {"title": "Using the N = 2 axiom to further restrict logically consistent evaluations", "content": "The pair evaluation axiom allows us to restrict further the set of member group evaluations consistent with their aligned responses on a test. We can rearrange the axiom to give us an expression for the sum of their jointly correct response counts,\nR_{ai,aj,a} + R_{bi,bj,b}\n(31)\nThis expression has two equivalent formulations, just like in the single classifier axiom case. These are,\nQ_b-(R_{ai}+R_{aj}) + R_{ai,aj} + (R_{ai,a} + R_{aj,a})\n(32)\nQ_a - (R_{b} + R_{bj}) + R_{bi,bj} + (R_{bi,b}+ R_{bj,b})\n(33)\nThese expressions can be used to restrict further the possible group evaluations for a pair. For example, in label A space, small values of the sum Rai,a + Raj,a may not be enough to cause this expression to be zero or positive. Since the sum of correct joint responses can never be below zero, this would prove that the individual correct counts must be larger at the assumed value of Qa. An example of how this restriction \"cuts the corners\" of the admissible pair evaluation rectangle is given in the section discussing the BIG-Bench-Mistake multistep arithmetic evaluation."}, {"title": "LLMs grading other LLMs: an evaluation using the BIG-Bench-Mistake multistep-arithmetic CoT task", "content": "Completeness in a logic of unsupervised evaluation has an important practical use - it terminates evaluation chains. This is being demonstrated in this paper by building a logical alarm that can certify that at least one ensemble member is failing the safety specification. In this section we illustrate this use for the formalism by discussing a binary evaluation used when three LLMs (Claude, Mistral, and GPT4) graded a PaLM2 LLM that had been given the multistep-arithmetic task from the BIG-Bench-Mistake dataset [19].\nTyen at al [19] created the dataset to study the reasoning abilities of LLMs. The multistep-arithmetic task consists of 300 problems of the form,\n(((-9-5-0) \u2013 (4 + 3 + \u22125)) \u2013 ((3 * 4 * 5) * (7 \u2212 \u22127 * 4))) =?\n(34)"}, {"title": "Detecting spoofed inputs to the evaluation model", "content": "There are various reasons to call the algebraic relations obtained from the generating set for an ensemble axiomatic. As already noted, they are universal and apply to all binary evaluations. There are no free parameters in these expressions to learn or train.\nOne very practical reason to consider them axioms is that their violation would immediately tell us that something is wrong. We have already encountered one use of this verification role for the axioms - verify that the group evaluations calculated by an evaluating algorithm lie in the logically consistent set. Another use of this verification is the detection of spoofed test summaries.\nWe already discussed global transformations of the label decisions that are guaranteed to be part of the generating set and are thus undetectable. But other transformations could occur, whether malicious or not. Can we detect them? This connects the work here further with notions from error detection and correction. We only remark briefly on it.\nOne way to create a spoofed test summary is to use a different generating set for the observed counts of agreements and disagreements. For example, we could randomly pick positive integers for the 2N patterns represented by the generating set,\nR_{ai,aj} = x\n(42)\nR_{ai,bj} = y\n(43)\nR_{bi,aj} = w\n(44)\nR_{bi,bj} = v,\n(45)\nand x + y + w + v = Q. We can view the generating sets as maps from unobservable statistics to observable ones. This spoofed generating set looks quite different from the one associated with a binary evaluation. Therefore, there is no guarantee that a spoofed test summary would actually be possible during any binary evaluation. This turns detection into a geometrical problem. Does the generating set with the spoofed summary have an empty variety - there are no points in R-space that satisfy the relations?"}, {"title": "Exact evaluation for error-independent classifiers", "content": "The generating set for an ensemble of size N = 3 error-independent classifiers has the form,\nf_{ai,aj,ak} = P_aP_{ia}P_{ja}P_{ka} + P_b(1 \u2013 P_{ib})(1 \u2013 P_{jb})(1 \u2013 P_{kb}) (46)\nf_{ai,aj,bk} = P_aP_{ia}P_{ja}(1 \u2013 P_{ka}) + P_b(1 \u2013 P_{ib}) (1 \u2013 P_{jb}) P_{kb}\n(47)\nf_{ai,bj,ak} = P_aP_{ia}(1 \u2013 P_{ja})P_{ka} + P_b(1 \u2013 P_{ib}) P_{jb}(1 \u2013 P_{kb})\n(48)\nf_{bi,aj,ak} = P_a(1 - P_{ia}) P_{ja}P_{ka} + P_bP_{ib}(1 - P_{jb}) (1 \u2013 P_{kb})\n(49)\nf_{bi,bj,ak} = P_a(1 - P_{ia}) (1 \u2013 P_{ja})P_{ka} + P_bP_{ib}P_{jb}(1 - P_{kb})\n(50)\nf_{bi,aj,bk} = P_a(1 - P_{ia}) P_{ja} (1 \u2013 P_{ka}) + P_bP_{ib}(1 \u2013 P_{jb}) P_{kb}\n(51)\nf_{ai,bj,bk} = P_aP_{ia}(1 \u2013 P_{ja})(1 \u2013 P_{ka}) + P_b(1 - P_{ib}) P_{jb}P_{kb}\n(52)\nf_{bi,bj,bk} = P_a(1 - P_{ia}) (1 \u2013 P_{ja}) (1 \u2013 P_{ka}) + P_bP_{ib}P_{jb}P_{kb}.\n(53)\nThis generating set has an algebraic variety (set of points that satisfy the polynomials) that consists of two points. One is the true performance of the ensemble. The second one is related by the transformations,\nP_a\u2192 (1-P_a)\n(54)\nP_{aia} \u2192 (1 - P_{aia})\n(55)\nP_{b,b} (1 - P_{b,b}).\n(56)\nThese solutions are easily obtained in any software package that contains implementations of Buch-berger's algorithm. For example, in the Wolfram language, the solution can be obtained with the built-in function Solve in seconds.\nThis solution is hardly known in the ML/AI literature. It is an algorithm that uses the decisions of the ensemble to evaluate itself. As such, it is the evaluation version of the well-known decision algorithm"}, {"title": "Formalisms for multi-label classification", "content": "The formalism presented here for binary classification, denoted by R = 2, can be readily extended to more labels. Binary classification has the property that there is only one way to be wrong. But with R > 2 classifications, there are more ways to be wrong than right. We could have presented all the formalism for binary classification in terms of inacurracies rather than accuracies. For three or more labels the generating sets look more symmetric if we do all the computations in terms of being wrong about a label. For example, in R = 3 evaluations we would use,\nP_{aia} = 1 - P_{ba} - P_{cia}\n(61)\nfor the percentage of times A questions where answered correctly - one minus the percentage of times it was wrong by saying it was B and C.\nBinary classification also makes it possible to talk about only one error correlation per label. In general we have to consider many more correlations. Take the case of pair correlations. Its general form can be written as,\n\\Gamma_{ij}^{true} = ?\n(62)\nSo we have to consider tensors of correlation statistics.\nAny measurement can be digitized to a finite number of ranges. If one had the formalism for evaluation logic of tests with R responses, the verification formalism presented here could be used to make sure agents using or producing them are working correctly. Evaluation models of other evaluations are possible so as to simplify them and thereby gain an easy way to verify them."}]}