{"title": "PERSONALIZED MULTI-TIER FEDERATED LEARNING", "authors": ["Sourasekhar Banerjee", "Ali Dadras", "Alp Yurtsever", "Monowar Bhuyan"], "abstract": "The key challenge of personalized federated learning (PerFL) is to capture the statistical heterogeneity properties of data with inexpensive communications and gain customized performance for participat- ing devices. To address these, we introduced personalized federated learning in multi-tier architecture (PerMFL) to obtain optimized and personalized local models when there are known team structures across devices. We provide theoretical guarantees of PerMFL, which offers linear convergence rates for smooth strongly convex problems and sub-linear convergence rates for smooth non-convex problems. We conduct numerical experiments demonstrating the robust empirical performance of PerMFL, outperforming the state-of-the-art in multiple personalized federated learning tasks.", "sections": [{"title": "1 Introduction", "content": "Federated learning (FL) is a distributed on-device learning framework that employs the heterogeneous data privately available at the edge for learning. In classical machine learning, edge devices are supposed to send data to the centralized server for training. However, FL relaxes this restriction by enabling the training of each model on the end devices and aggregating them on the global server. Classical FL learns a single global model by utilizing the private data of the devices locally and exchanging only the model information in a communication-efficient and privacy-preserving manner [1].\nThe early FL literature focuses mainly on a simplistic network architecture where all devices communicate directly with a single server [1]. An example of such a network architecture is typical on a local area network (LAN) with all devices connected to a single server. However, real-world Internet applications often occur on more complex, multi-tiered network architecture, e.g., wide area networks (WAN) that span multiple geographic locations and connect heterogeneous LANs. Hence, the conventional FL architecture is not suitable for such a setting. To address this, we study a multi-tier FL model Figure 1b where an intermediate layer of mediators, called team servers (TS\u00bf), acts as a bridge between the end devices (N\u00bf) and the global server (GS) and facilitates intermediate aggregations. From a systems standpoint, this multi-tier FL model resembles the cloud-edge continuum architecture [2]. In this model, the distant cloud serves as a central server responsible for generating a global model, and the edge servers located in various geographical regions act as team servers that establish connections with both the distant cloud and end devices. In contrast, the end devices perform local model computations. Multi-tier FL models, which are also referred to as hierarchical FL, have been studied by researchers in various applications and have shown significant advantages such as cost efficiency and scalability [3], reduced communication overheads [4, 5], enhanced privacy [6], improved system adaptability and performance [7], and faster convergence speeds (both theoretically and empirically) and reduced training time [8].\nData heterogeneity poses a significant challenge in FL, as data across different devices may exhibit varying characteristics and originate from diverse data distributions. The conventional FL systems assume that a single global model fits all devices, hindering the convergence speed and more crucially, the model accuracy when data is disseminated in a non-independent and identically distributed (non-IID) manner. In this scenario, using a 'global model for all' disallows adaptation to unique needs and preferences embedded in each user's data characteristics, possibly leading to subpar performance and user dissatisfaction [9]. To tackle this challenge, personalized FL (PerFL) methods learn local models suitable for each user's unique needs for downstream tasks while still benefiting from collaborative training to achieve customized performance. Popular PerFL approaches include regularization techniques that penalize the distance between local and global models [10], smoothing techniques such as Moreau envelopes [11], and other heuristics such as taking extra local steps after the global model has converged [12, 13].\nMulti-tier FL also suffers from data heterogeneity, but the existing literature on personalized multi-tier FL is limited. To address this challenge, we introduce a personalized multi-tier federated learning method (PerMFL). Our method is based on a new problem formulation that explicitly incorporates individual models for each team and device, in addition to the global server's model. We enforce the proximity between team models and the global model and between device models and their associated team models using squared Euclidean distance regularization. As a result, our method leverages the multi-tiered architecture and simultaneously learns three models: (1) a global model, (2) a personalized model for each team, and (3) a personalized model for each device. Geometrically, the global model serves as a central estimate that is agreed upon by all teams and end devices. On the contrary, personalized models are designed to deviate from the global model in specific directions that align with their local data distributions. To facilitate efficient communication, our algorithm restricts direct communication between devices and the global server, allowing devices to communicate only with the team servers, which in turn communicate with the global server. Our primary goal with PerMFL is to achieve personalized on-device model performance while still maintaining comparably high accuracy for the global model, which can compete with conventional FL methods, all while ensuring efficient communication and collaboration among the devices and team servers.\nOur key contributions are as follows:\n1. We formulate an optimization problem for multi-tier personalized FL by introducing personal decision variables for teams and devices through squared Euclidean distance regularization, and we propose an algorithm (PerMFL) to solve this problem. Our algorithm flexibly accommodates local objectives during joint training of global and personalized models.\n2. To provide a theoretical basis for our approach, we analyze the convergence guarantees of the proposed algorithm under the assumptions of smooth strongly convex and smooth non-convex loss functions. We show that the method converges with linear and sublinear rates, respectively, and we derive explicit theoretical bounds on hyperparameter settings to provide guidance for implementation.\n3. We conduct extensive numerical experiments to evaluate the empirical performance of PerMFL. We compare our method to state-of-the-art (SOTA) approaches for both conventional and multi-tier FL settings using benchmark datasets (MNIST, FMNIST, EMNIST-10, FEMNIST,CIFAR100) and non-image tabular synthetic datasets with non-IID data dissemination. Moreover, we have examined the effect of hyperparameters on the convergence of PerMFL, ablation studies on different team formations, and ablation studies on team and client participation on the convergence of PerMFL."}, {"title": "2 Related Work", "content": "This section reviews existing studies and summarizes the differences between existing works and proposed efforts. We emphasize three different categories of FL models - multi-tier and personalized FL.\nMulti-tier FL. A multi-tier (aka hierarchical) FL model leverages the combined capabilities of cloud and edge devices within the FL framework. In [8], the authors demonstrated that a multi-tier FL strategy, both theoretically and empirically, exhibits a faster convergence rate compared to traditional FL algorithms. In [14], the concept of \"upward\" and \"downward\u201d divergences were introduced, exploring their implications in the context of multi-tier FL. Additionally, [15] presented Cross-Silo FL, which encompasses multi-tier networks and utilizes vertical and horizontal data partitioning strategies. In [3], they introduced FEDn, a multi-tier FL framework designed explicitly for horizontally scalable distributed deployments. [6] identified several potential advantages of multi-tier FL in addressing privacy concerns. Firstly, multi-tier FL helps reduce the concentration of power and control in a central server, promoting a more distributed and decentralized approach. Secondly, multi-tier FL allows for the flexible placement of defense and verification mechanisms within the hierarchical structure, enabling the practical application of these methods. Lastly, multi-tier FL leverages the trust between users to mitigate the number of potential threats."}, {"title": "3 PerMFL", "content": "A multi-tier FL framework (see Figure 1b) is different from the conventional FL framework (see Figure 1a) as it follows a hierarchy. All devices are divided into M teams. Each team has a team server (TS\u2081), which is connected with Ni devices of the respective team. Global server (GS) only communicates with TSi's team."}, {"title": "3.1 Team formation", "content": "By definition, FL can be seen as a cross-silo or cross-device setting [27]. In cross-silo settings, a limited number of devices, typically between 2 and 100, participate in each round, and their participation remains fixed. On the other hand, in cross-device setups, the client pool is extensive, potentially in the millions, but only a small fraction of devices take part in each iteration [27]. In a multi-tier structure, teams can be constituted in four ways: (1) Both teams and devices within teams have full participation, (2) Teams have full participation, whereas devices within teams are participating partially, (3) Teams have partial participation, but all devices within teams are participating, and (4) Teams and devices both have partial participation.\nVarious FL methods with different team formation strategies have been proposed in the literature [28, 29]. PerMFL does not explicitly address the creation of teams. Instead, it exhibits adaptability to accommodate any team formation mechanism. It is important to note that PerMFL is most efficient when communication with the team servers is cheaper compared to communication with the global server. This situation often occurs when devices are geographically distributed and connected to their nearest teams, similar to the Cloud-Edge model [30]. We can also argue that team-level personalization is more effective when the data within each team exhibits distinctive characteristics that differentiate it from the data in other teams. Nonetheless, we provide a comprehensive ablation study that thoroughly examines different types of team selection, including poorly constructed and randomly constructed team formations. In cases where teams do not exhibit such distinctive characteristics, our model can still benefit from device-level personalization and reduced communication costs with the global server."}, {"title": "3.2 PerMFL formulation", "content": "We consider a multi-tier FL setup, consisting of M teams, each with N\u2081 devices (i = 1, . . ., M). In this setup, empirical risk minimization can be expressed as:\n$\\min_{x\\in \\mathbb{R}^d}  \\frac{1}{M} \\sum_{i=1}^{M} \\frac{1}{N_i} \\sum_{j=1}^{N_i} f_{ij}(x).$\nHere, fi,j(\u00b7) represents the loss function of the jth device from the ith team. This formulation relies on a single decision variable x that all clients are expected to converge upon. However, this model is unsuitable for scenarios involving non-homogeneous data distributions, as the existence of a global model capable of accommodating all devices becomes unreasonable.\nTo address this challenge, we introduce decision variables for every team and device, denoted as w\u2081 and di,j, respectively. Our goal is to find a global model representing a rough average, capturing common characteristics across all teams and devices; personalized team models that are close to the global model but can deviate from aligning with shared features within each team; and personalized device models that resemble the team model but can deviate to accommodate the unique characteristics of each device. We adopt a quadratic penalty approach to enforce that the device models are close to the team models and the team models to the global model. The parameters \u03b3 > 0 and \u03bb \u2265 0 control the degree of personalization impact at the team and device levels respectively.\n$\\min_{x\\in \\mathbb{R}^d} \\min_{w_i\\in \\mathbb{R}^d} \\min_{\\theta_{i,j} \\in \\mathbb{R}^d} \\frac{1}{M} \\sum_{i=1}^{M} \\frac{1}{N_i} \\sum_{j=1}^{N_i} f_{i,j}(\\theta_{i,j}) + \\frac{\\lambda}{2} ||\\theta_{i,j} - w_i||^2 + \\frac{\\gamma}{2} ||w_i - x||^2.$\nWe are now prepared to outline the algorithm design. Our approach involves the use of three iteration counters: t for the global rounds, k for team-level rounds, and l for device-level rounds.\nDevice-level updates. Given a team model work, the objective of the device (i, j) is to solve the following subproblem:\n$\\theta_{i,j}^{(t,k)} := \\argmin_{\\theta_{i,j} \\in \\mathbb{R}^d} f_{i,j} (\\theta_{i,j}) + \\frac{\\lambda}{2} ||\\theta_{i,j} - w_i^{(t,k)}||^2.$\nThe exact solution to this problem is $prox_{f_{i,j}/\\lambda}(w)$; however, in general, there is no closed-form solution available for this proximal operator. Consequently, each device employs the gradient method to approximate the solution to (3). Starting with an initial value of $\\theta_{i,j}^{t,0} = w_i^{t,0}$, and utilizing a positive step-size a, we perform the following update rule for l = 0, 1, ..., L \u2013 1:\n$\\theta_{i,j}^{t,k,l+1} = \\theta_{i,j}^{t,k,l} - \\alpha (\\nabla f_{i,j} (\\theta_{i,j}^{t,k,l}) - \\lambda (\\theta_{i,j}^{t,k} - w_i^{t,k})).$\nTeam-level updates. Similarly, the goal in team-level updates is to solve a regularized subproblem. We define the team-level loss function as\n$F_i(w_i) := \\frac{1}{N_i} \\sum_{j=1}^{N_i} \\nabla f_{i,j} (w_i).$\nWith the addition of regularization towards the global server's model xt, Team (i) aims to solve the following subproblem:\n$\\argmin_{w_i \\in \\mathbb{R}^d} F_i(w_i) + \\frac{\\gamma}{2} ||w_i - x^t||^2.$\nOnce again, the solution is given by the proximal operator, $prox_{F_i/\\gamma}(x^t)$, which can be difficult to compute. Instead, we can find an approximate solution by using the gradient method. Starting from w\u2070 = xt, and using a positive step-size \u03b7 > 0, the gradient method update becomes\n$w_i^{t,k+1} = w_i^{t,k} - \\eta_i \\nabla F_i(w_i^{t,k}) - \\eta_i \\gamma (w_i^{t,k} - x^t)$\n$= w_i^{t,k} - \\frac{\\eta_i}{N_i} \\sum_{j=1}^{N_i}(\\nabla f_{i,j} (w_i^{t,k}) - \\gamma (w_i^{t,k} - x^t)).$\nHere, the second line follows from the definition of F\u2081. Since we do not have the exact gradient fi,j (wk), we approximate it by:\n$\\nabla \\nabla f_{i,j} (w_i^{t,k}) = \\lambda (w_i^{t,k} - prox_{f_{i,j}/\\lambda} (w_i^{t,k})) = \\lambda (w_i^{t,k} - \\theta_{i,j}^{t,k,L}).$\nBy combining (7) and (8), we construct the following update rule for k = 0, 1, ..., K \u2212 1:\n$w_i^{k+1} = (1-\\eta(\\lambda + \\gamma))w_i^{k} + \\eta\\gamma x^t + \\frac{\\lambda\\eta}{N_i}\\sum_{j=1}^{N_i} \\theta_{i,j}^{t,k,L}.$\nServer-level updates. Finally, the server applies the gradient method for\n$\\min_{x\\in \\mathbb{R}^d} \\Phi (x) := \\frac{1}{M} \\sum_{i=1}^{M} F_i (x).$\nStarting from an initial state x\u2070 \u2208 Rd and using a positive step-size \u03b2, the gradient update becomes:\n$x^{t+1} = x^t - \\frac{\\beta}{M} \\sum_{i=1}^{M} \\nabla F_i(x^t).$\nAgain, we use an approximation for VF;(xt) based on the team-level models:\n$\\nabla F_i(x^t) = \\gamma(x^t - prox_{F_i/\\gamma}(x^t)) \\approx \\gamma(x^t - w_i^{t,K}).$\nFinally, we construct the server-level update rule by combining (11) and (12). For t = 0,1,...,T 1, the server performs the following update rule:\n$x^{t+1} = (1 - \\beta \\gamma) x^t + \\frac{\\beta \\gamma}{M} \\sum_{i=1}^{M} w_i^{t,K}.$\nSynthesis. By combining device, team, and server-level updates, we propose PerMFL (Algorithm 1) for personalized multi-tier FL."}, {"title": "3.3 Convergence guarantees", "content": "This section presents the convergence guarantees of PerMFL. We consider two different settings, with strongly convex and non-convex loss functions. In both cases, we assume that the loss functions are smooth in the sense that they have Lipschitz continuous gradients. The next Theorem formalizes the guarantees of when fi,j is strongly convex.\nTheorem 1 (Strongly convex). Consider the minimization problem $\\min_x \\Phi (x)$ when $\\Phi (x)$ is defined in (10) with Lf-smooth and pf-strongly convex loss functions fi,j(x). For large enough numbers of inner iterations of orders L = \u03a9(K) and K = \u03a9(\u03a4), see the supplementary copy for the bounds, estimation ${x^t}_{t=0}^f$ generated by PerMFL with step-size \u1e9e satisfies:\n$||x^T - x^*||^2 < 2(1 - \\beta)^T ||x^0 - x^*||^2.$\nwhere learning rates should satisfy $\\beta < \\frac{1}{4L_f+1}$,$\\eta_i < \\frac{N_i}{2(\\lambda+\\gamma)}$, $a_{i,j} \\leq \\frac{\\lambda}{1+\\lambda}$, $M_p := \\frac{\\lambda}{\\lambda+\\gamma} + \\frac{\\gamma}{\\lambda+\\gamma} + \\frac{\\lambda\\gamma}{(\\lambda+\\gamma)^2}$, and$\\gamma > 2\\lambda > 4L_f$.\nProof sketch. We analyze the algorithm in three levels: (i) The devices find approximate solutions to problem (3) by using the gradient method. We can control the accuracy of this stage by choosing L (the number of iterations for the gradient method) large enough. (ii) The teams solve problem (6) approximately, again by using a gradient method. We use an inexact gradient at this stage since the exact gradient requires exact solutions from the devices to which we do not have access. At this stage, K is the number of iterations, and L modulates the accuracy of our gradients. By choosing both K and L large enough, we can control the solution accuracy achieved at the teams' level. (iii) Finally, the Server solves the problem (10), the original FL problem, by using the information provided by the Teams. It is worth noting that for a fixed T, we can decrease the error (down to a threshold) by increasing K and L. More precisely, we achieve linear convergence rates when we choose K and L in the order of \u03a9(\u03a4). The complete proof is left to the supplementary material.\nThe next Theorem shows that PerMFL finds a first-order stationary point with sublinear rates when fi,j are smooth but non-convex.\nTheorem 2 (Non-convex). Consider the minimization problem $\\min_x \\Phi (x)$ when $\\Phi (x)$ is defined in (10) with non-convex Lf-smooth loss functions fi,j(x). For large enough numbers of inner iterations of orders L = \u03a9(K) and K = \u03a9(\u03a4), see the appendix for the bounds, then, estimation ${x^t}_{t=0}^f$ generated by PerMFL with step-size \u1e9e satisfies:\n$E[||\\nabla \\Phi(x_\\tau)||^2] \\le \\frac{\\Phi(x^0) - \\Phi(x^*)}{\\beta T}$\nwhere $\\beta \\leq \\frac{1}{4L_f}$,$\\eta_i \\leq \\frac{N_i}{\\lambda+\\gamma}$, $a_{i,j} = 1$, $\\gamma > 2\\lambda > 4L_f$, and $\\tau$ is uniformly sampled from ${0,...,T-1}$\nProof sketch. The analysis follows a similar structure to the previous setting. The main difference is that the errors in subproblems are guaranteed as a bound on the gradient norms, which we translate to error bounds on objective residual by tuning A and y. The proof can be found in the supplementary material.\nRemark 2. At first glance, it may come as a surprise that our guarantees do not necessitate a bounded drift condition, which is common in FL methods involving multiple local steps. It is important to note a fundamental distinction between the conventional FL template (1) and our personalized multi-tier FL template (2). The former lacks consideration for data heterogeneity as it relies solely on a single global variable. This can result in 'drift-away' issues when multiple local steps are taken, especially in the presence of data heterogeneity. In contrast, our formulation explicitly incorporates team and device-level variables, and our local steps are tailored to solve device and team-level subproblems (3) and (6). The regularization employed in these subproblems prevents \u2018over-drifting\u2019 by explicitly penalizing the divergence between device, team, and global models in a suitable manner."}, {"title": "4 Experiments", "content": "We studied classification problems to validate PerMFL using both benchmarks (MNIST [31], FMNIST [32] EMNIST [33] with 10 classes (EMNIST-10), EMNIST with 62 classes (FEMNIST), CIFAR100 [34]) and non-image synthetic datasets. For the MNIST, FMNIST, EMNIST-10, and synthetic datasets, the data was distributed among multiple devices in a non-iid manner, ensuring each device had data from at most two classes. Subsequently, the devices were randomly grouped into four teams, each consisting of 10 devices, before performing PerMFL. We considered the full participation of teams and devices in each global round for the performance and convergence evaluation. For the FEMNIST and CIFAR100 datasets, the data was distributed to 3,500 and 350 devices, respectively, with each device holding data from the 3 classes. The devices are arranged into 5 teams. All datasets are split into training and validation sets with a 3:1 ratio.\nWe considered a multi-class logistic regression (MCLR) model with a softmax activation function for strongly convex scenarios. For synthetic datasets, we constructed deep neural networks with two hidden layers, while for image datasets, we built two-layered convolutional neural networks for non-convex scenarios. More details of the experimental setup, datasets, and learning models are in the supplementary copy.\nIn this paper, we conducted (1) the performance comparison between PerMFL with FedAvg [1], pFedMe[11], Per- FedAvg [13], pFedBayes [20], Ditto [10], and performance and convergence comparison with two hierarchical FL algorithms, such as hierarchical-SGD (h-SGD)[5], Asynchronous L2GD (AL2GD)[18], and a hierarchical-clustered FL algorithm DemLearn [19]. (2) We investigated the impact of \u03b2, \u03b3, and A on the convergence of PerMFL. (3) An ablation study to explore team formation. (4) An ablation study to analyze the influence of team and device participation. Moreover, in the supplementary copy, we gave an ablation study that explores the effects of team iterations on the convergence of PerMFL. Throughout the experiments, we denoted the personalized model and global model as (PM) and (GM), respectively We have made the implementation of PerMFL available at https://github.com/sourasb05/PerMFL_1.git"}, {"title": "4.1 Results and Analysis", "content": "4.1.1 Performance:\nFrom table 1, we observed that PerMFL(PM) outperformed the state-of-the-art for non-convex cases in all datasets. PerMFL(GM) outperformed other global models, including FedAvg(GM), pFedMe(GM), and Ditto(GM), and nearly equivalent with h-SGD(GM) and DemLearn(GM) for the MNIST dataset. For the synthetic dataset, PerMFL(GM) outperformed the state-of-the-art. For FMNIST and EMNIST-10 datasets, the performance of PerMFL(GM) is better than the conventional FL models and DemLearn(GM). For strongly convex cases, PerMFL(PM) outperformed the state of the art in MNIST and Synthetic datasets. For the FMNIST dataset, PerMFL(PM)'s performance is better than the conventional FL state-of-the-art. Moreover, the performance of PerMFL(PM) is nearly equivalent to the DemLearn(PM) for FMNIST and EMNIST-10. PerMFL(PM) also achieved better performance than h-SGD and AL2GD on FEMNIST and CIFAR100 given in the supplementary copy. PerMFL(GM) outperformed the state-of-the-art in Synthetic and FMNIST datasets. PerMFL(GM) performs better than conventional methods in all datasets and is nearly equivalent to h-SGD(GM) on MNIST and EMNIST-10. From these observations, we can infer that PerMFL(PM) performs better than the 7 state-of-the-art methods on 6 out of 8 experiments. The reason could be, the personalization in both team and devices helps to get better performance.\n4.1.2 Convergence:\nFrom fig. 2, we observed that the convergence of PerMFL(PM) is equivalent to DemLearn and is faster than h-SGD and AL2GD. Similar findings were also observed in EMNIST-10, Synthetic, and MNIST datasets given in the supplementary copy. It is because, inside each team multiple iterations are happening, that helps the personalized model to converge quickly.\n4.1.3 Effect of hyghperparameters \u03b2, \u03b3, and \u5165:\nFrom fig. 3, we observed if we increase the value of \u03b2, \u03b3, and A separately then PerMFL(PM) converge faster. A similar observation is found for FMNIST, and the synthetic dataset is given in the supplementary copy. In all experiments, the hyperparameters followed the bounds given in theorem 1 for strongly convex and theorem 2 for non-convex and smooth problems."}, {"title": "4.1.4 Ablation studies on team formation:", "content": "In table 2, we evaluated PerMFL for both worst-case (team 1 with labels {0, 1, 2, 3, 4} and team 2 with {5, 6, 7, 8, 9}) and average-case (teams with overlapping labels, team 1 with labels {0, 1, 2, 3, 4, 5, 6} and team 2 with {5, 6, 7, 8, 9,0, 1}) over 400 global iterations which include 10 and 20, team and local iterations respectively, with the hyperparameter settings X = 0.5, \u03b3 = 1.5, \u03b2 = 0.6, and, a = 0.01. PerMFL(GM) showed a 4% improvement in average-case over the worst-case with FMNIST data. Likewise, PerMFL(PM) had slightly better results in average-case than worst-case for non-convex setups (CNN) with MNIST and FMNIST datasets, indicating PerMFL(PM)'s performance is mostly unaffected by team formation."}, {"title": "4.1.5 Ablation study on teams and clients participation:", "content": "PerMFL achieves quick convergence with complete participation from both teams and devices (fig. 4a) or when teams fully participate but devices do so partially (fig. 4b), in contrast to slower convergence under partial participation from both teams and devices (fig. 4d). Moreover, expanding the number of teams does not impact the convergence speed of PerMFL(PM) when there is full participation from all teams and devices throughout all global rounds (fig. 4a). Increased device involvement leads to faster convergence (fig. 4b), whereas lower team engagement (fig. 4c) decelerates it. Nonetheless, when team participation reaches 50% in each global round, the convergence rate is comparable to that observed in scenarios with complete participation (fig. 4a). When all teams are fully participating, increasing the number of team iterations leads to quicker convergence. However, in scenarios where both team and device participation is minimal (2%) as shown in fig. 4d, PerMFL(PM) requires more global and team iterations to achieve convergence. Extended experimental results are reported in the supplementary copy."}, {"title": "5 Conclusions", "content": "We introduced, PerMFL, a personalized multi-tier federated learning approach involving global servers, teams, and devices. PerMFL utilized squared euclidean distance regularization on both devices and teams. By employing PerMFL, we are able to generate personalized models for each device and simultaneously obtain a global model. The performance of PerMFL demonstrates linear baseline rates for strongly convex scenarios and sublinear baseline rates for non-convex and smooth scenarios. Empirically we observed that PerMFL(PM) converges quickly and outperformed the state-of- the-art. PerMFL performs best when both teams and devices participate fully. Very low team and device participation degrade the performance of PerMFL(GM). It requires more global and team iterations to converge. Also, in worst-case team formation, the performance of the global model decreases, while the personalized model is able to maintain its performance. Moreover right combination of \u03bb, \u03b2, and y enhances the convergence of PerMFL."}, {"title": "A Preliminaries and Supporting Lemmas", "content": "Definition 1 (Strong convexity). A differentiable function g : Rd \u2192 R is \u00b5g-strongly convex if there exists a positive constant \u00b5g such that\n$g(x) \\le g(y) + \\langle \\nabla g(x), x - y \\rangle - \\frac{\\mu_g}{2} ||x-y||^2, \\forall x, y \\in \\mathbb{R}^d.$\nIf g is \u00b5g-strongly convex, then\n$\\mu_g ||x \u2212 y || \\le ||\\nabla g(x) \u2013 \\nabla g(y)||, \\forall x, y \\in \\mathbb{R}^d.$\nDefinition 2 (Smoothness). A differentiable function g : Rd \u2192 R is Lg-smooth if there exists a non-negative constant Lg such that\n$||\\nabla g(y) \u2013 \\nabla g(x)|| \\le L_g ||x \u2212 y||, \\forall x, y \\in \\mathbb{R}^d.$\nIf g is Lg-smooth, then\n$\\vert g(y) - g(x) \u2013 \\langle \\nabla g(x), y - x \\rangle \\vert \\le \\frac{L_g}{2} ||y-x||^2, \\forall x, y \\in \\mathbb{R}^d.$\nDefinition 3 (Expected Smoothness). The second moment of the stochastic gradient \u2207g(x) sattisfies\n$\\mathbb{E}||\\nabla g(x)||^2 \\le 2A(g(x) - g(x^*)) + B \\cdot ||\\nabla g(x)||^2 + C,$\nfor some A, B, C > 0 and \u2200x \u2208 Rd.\nDefinition 4 (Moreau Envelope). For a function g, its Moreau envelope \u011f is defined as\n$\\tilde{g}(x) = \\min_{u} \\{g(u) + \\frac{\\lambda}{2} ||u-x||^2 \\}.$\nProposition 1. Let g be a convex function and \u011f be its Moreau Envelope with parameter \u5165. Then\n1. \u011f is convex.\n2. \u011f is continuously differentiable (even if f is not) and\n$\\nabla \\tilde{g}(x) = \\lambda (x \u2013 prox_{g/\\lambda}(x)), $where $prox_{g/\\lambda}(x) := arg min_{u\\in \\mathbb{R}^d} \\{ g(u) + \\frac{\\lambda}{2} ||u \u2013 x||^2 \\}.$\nMoreover \u011f is A-smooth.\n3. If g is \u00b5-strongly convex, then \u011f is \u00b5\u1ef9-strongly convex with $\\mu_{\\tilde{g}} = \\frac{\\mu_{\\lambda}}{\\mu+\\lambda}$.\nProposition 2. If g is non-convex and Lg-smooth, then \u2207\u011f(x) is A-smooth with the condition that > > 2Lg.\nProposition 3. If g : Rd \u2192 R is convex and Lg-smooth, then\n$||\\nabla g(x) \u2013 \\nabla g(y)||^2 \\le 2L_g (g(x) - g(y) \u2013 \\langle (g(y), x - y \\rangle ), \\forall x,y \\in \\mathbb{R}^d.$\nProposition 4. If g : Rd \u2192 R is \u00b5g-strongly convex, then\n$\\frac{4 \\mu_g}{\\mu^2} ||x - x^*||^2 \\le g(x) - g(x^*), \\forall x \\in \\mathbb{R}^d.$\nRemark 3. For any set of vectors ${y_i}_{i=1}^n$, we have\n$\\vert\\vert \\sum_{i=1}^{n} y_i \\vert\\vert^2 = \\sum_{i=1}^{n} \\vert\\vert y_i \\vert\\vert^2 + \\sum_{i \\neq j} \\langle y_i,y_j \\rangle,$\nthat leads to\n$\\vert\\vert \\sum_{i=1}^{n} y_i \\vert\\vert^2 \\le n\\sum_{i=1}^{n} \\vert\\vert y_i \\vert\\vert^2.$\nwhere $y := \\frac{1}{n}\\sum_{i=1}^{n} y_i$\nRemark 4 (Young's inequality). For any \u0454 > 0 and vectors y, z \u2208 Rd, we have\n$2\\langle y, z \\rangle\\le \\frac{\\epsilon}{2} \\vert\\vert y \\vert\\vert^2 + \\frac{1}{\\epsilon} \\vert\\vert z \\vert\\vert^2$"}, {"title": "Remark 5 (Parameters in PerMFL). Here, we consider two setups.", "content": "\u2022 If fi"}, {"title": "PERSONALIZED MULTI-TIER FEDERATED LEARNING", "authors": ["Sourasekhar Banerjee", "Ali Dadras", "Alp Yurtsever", "Monowar Bhuyan"], "abstract": "The key challenge of personalized federated learning (PerFL) is to capture the statistical heterogeneity properties of data with inexpensive communications and gain customized performance for participat- ing devices. To address these, we introduced personalized federated learning in multi-tier architecture (PerMFL) to obtain optimized and personalized local models when there are known team structures across devices. We provide theoretical guarantees of PerMFL, which offers linear convergence rates for smooth strongly convex problems and sub-linear convergence rates for smooth non-convex problems. We conduct numerical experiments demonstrating the robust empirical performance of PerMFL, outperforming the state-of-the-art in multiple personalized federated learning tasks.", "sections": [{"title": "1 Introduction", "content": "Federated learning (FL) is a distributed on-device learning framework that employs the heterogeneous data privately available at the edge for learning. In classical machine learning, edge devices are supposed to send data to the centralized server for training. However, FL relaxes this restriction by enabling the training of each model on the end devices and aggregating them on the global server. Classical FL learns a single global model by utilizing the private data of the devices locally and exchanging only the model information in a communication-efficient and privacy-preserving manner [1].\nThe early FL literature focuses mainly on a simplistic network architecture where all devices communicate directly with a single server [1]. An example of such a network architecture is typical on a local area network (LAN) with all devices connected to a single server. However, real-world Internet applications often occur on more complex, multi-tiered network architecture, e.g., wide area networks (WAN) that span multiple geographic locations and connect heterogeneous LANs. Hence, the conventional FL architecture is not suitable for such a setting. To address this, we study a multi-tier FL model Figure 1b where an intermediate layer of mediators, called team servers (TS\u00bf), acts as a bridge between the end devices (N\u00bf) and the global server (GS) and facilitates intermediate aggregations. From a systems standpoint, this multi-tier FL model resembles the cloud-edge continuum architecture [2]. In this model, the distant cloud serves as a central server responsible for generating a global model, and the edge servers located in various geographical regions act as team servers that establish connections with both the distant cloud and end devices. In contrast, the end devices perform local model computations. Multi-tier FL models, which are also referred to as hierarchical FL, have been studied by researchers in various applications and have shown significant advantages such as cost efficiency and scalability [3], reduced communication overheads [4, 5], enhanced privacy [6], improved system adaptability and performance [7], and faster convergence speeds (both theoretically and empirically) and reduced training time [8].\nData heterogeneity poses a significant challenge in FL, as data across different devices may exhibit varying characteristics and originate from diverse data distributions. The conventional FL systems assume that a single global model fits all devices, hindering the convergence speed and more crucially, the model accuracy when data is disseminated in a non-independent and identically distributed (non-IID) manner. In this scenario, using a 'global model for all' disallows adaptation to unique needs and preferences embedded in each user's data characteristics, possibly leading to subpar performance and user dissatisfaction [9]. To tackle this challenge, personalized FL (PerFL) methods learn local models suitable for each user's unique needs for downstream tasks while still benefiting from collaborative training to achieve customized performance. Popular PerFL approaches include regularization techniques that penalize the distance between local and global models [10], smoothing techniques such as Moreau envelopes [11], and other heuristics such as taking extra local steps after the global model has converged [12, 13].\nMulti-tier FL also suffers from data heterogeneity, but the existing literature on personalized multi-tier FL is limited. To address this challenge, we introduce a personalized multi-tier federated learning method (PerMFL). Our method is based on a new problem formulation that explicitly incorporates individual models for each team and device, in addition to the global server's model. We enforce the proximity between team models and the global model and between device models and their associated team models using squared Euclidean distance regularization. As a result, our method leverages the multi-tiered architecture and simultaneously learns three models: (1) a global model, (2) a personalized model for each team, and (3) a personalized model for each device. Geometrically, the global model serves as a central estimate that is agreed upon by all teams and end devices. On the contrary, personalized models are designed to deviate from the global model in specific directions that align with their local data distributions. To facilitate efficient communication, our algorithm restricts direct communication between devices and the global server, allowing devices to communicate only with the team servers, which in turn communicate with the global server. Our primary goal with PerMFL is to achieve personalized on-device model performance while still maintaining comparably high accuracy for the global model, which can compete with conventional FL methods, all while ensuring efficient communication and collaboration among the devices and team servers.\nOur key contributions are as follows:\n1. We formulate an optimization problem for multi-tier personalized FL by introducing personal decision variables for teams and devices through squared Euclidean distance regularization, and we propose an algorithm (PerMFL) to solve this problem. Our algorithm flexibly accommodates local objectives during joint training of global and personalized models.\n2. To provide a theoretical basis for our approach, we analyze the convergence guarantees of the proposed algorithm under the assumptions of smooth strongly convex and smooth non-convex loss functions. We show that the method converges with linear and sublinear rates, respectively, and we derive explicit theoretical bounds on hyperparameter settings to provide guidance for implementation.\n3. We conduct extensive numerical experiments to evaluate the empirical performance of PerMFL. We compare our method to state-of-the-art (SOTA) approaches for both conventional and multi-tier FL settings using benchmark datasets (MNIST, FMNIST, EMNIST-10, FEMNIST,CIFAR100) and non-image tabular synthetic datasets with non-IID data dissemination. Moreover, we have examined the effect of hyperparameters on the convergence of PerMFL, ablation studies on different team formations, and ablation studies on team and client participation on the convergence of PerMFL."}, {"title": "2 Related Work", "content": "This section reviews existing studies and summarizes the differences between existing works and proposed efforts. We emphasize three different categories of FL models - multi-tier and personalized FL.\nMulti-tier FL. A multi-tier (aka hierarchical) FL model leverages the combined capabilities of cloud and edge devices within the FL framework. In [8], the authors demonstrated that a multi-tier FL strategy, both theoretically and empirically, exhibits a faster convergence rate compared to traditional FL algorithms. In [14], the concept of \"upward\" and \"downward\u201d divergences were introduced, exploring their implications in the context of multi-tier FL. Additionally, [15] presented Cross-Silo FL, which encompasses multi-tier networks and utilizes vertical and horizontal data partitioning strategies. In [3], they introduced FEDn, a multi-tier FL framework designed explicitly for horizontally scalable distributed deployments. [6] identified several potential advantages of multi-tier FL in addressing privacy concerns. Firstly, multi-tier FL helps reduce the concentration of power and control in a central server, promoting a more distributed and decentralized approach. Secondly, multi-tier FL allows for the flexible placement of defense and verification mechanisms within the hierarchical structure, enabling the practical application of these methods. Lastly, multi-tier FL leverages the trust between users to mitigate the number of potential threats."}, {"title": "3 PerMFL", "content": "A multi-tier FL framework (see Figure 1b) is different from the conventional FL framework (see Figure 1a) as it follows a hierarchy. All devices are divided into M teams. Each team has a team server (TS\u2081), which is connected with Ni devices of the respective team. Global server (GS) only communicates with TSi's team."}, {"title": "3.1 Team formation", "content": "By definition, FL can be seen as a cross-silo or cross-device setting [27]. In cross-silo settings, a limited number of devices, typically between 2 and 100, participate in each round, and their participation remains fixed. On the other hand, in cross-device setups, the client pool is extensive, potentially in the millions, but only a small fraction of devices take part in each iteration [27]. In a multi-tier structure, teams can be constituted in four ways: (1) Both teams and devices within teams have full participation, (2) Teams have full participation, whereas devices within teams are participating partially, (3) Teams have partial participation, but all devices within teams are participating, and (4) Teams and devices both have partial participation.\nVarious FL methods with different team formation strategies have been proposed in the literature [28, 29]. PerMFL does not explicitly address the creation of teams. Instead, it exhibits adaptability to accommodate any team formation mechanism. It is important to note that PerMFL is most efficient when communication with the team servers is cheaper compared to communication with the global server. This situation often occurs when devices are geographically distributed and connected to their nearest teams, similar to the Cloud-Edge model [30]. We can also argue that team-level personalization is more effective when the data within each team exhibits distinctive characteristics that differentiate it from the data in other teams. Nonetheless, we provide a comprehensive ablation study that thoroughly examines different types of team selection, including poorly constructed and randomly constructed team formations. In cases where teams do not exhibit such distinctive characteristics, our model can still benefit from device-level personalization and reduced communication costs with the global server."}, {"title": "3.2 PerMFL formulation", "content": "We consider a multi-tier FL setup, consisting of M teams, each with N\u2081 devices (i = 1, . . ., M). In this setup, empirical risk minimization can be expressed as:\n$\\min_{x\\in \\mathbb{R}^d}  \\frac{1}{M} \\sum_{i=1}^{M} \\frac{1}{N_i} \\sum_{j=1}^{N_i} f_{ij}(x).$\nHere, fi,j(\u00b7) represents the loss function of the jth device from the ith team. This formulation relies on a single decision variable x that all clients are expected to converge upon. However, this model is unsuitable for scenarios involving non-homogeneous data distributions, as the existence of a global model capable of accommodating all devices becomes unreasonable.\nTo address this challenge, we introduce decision variables for every team and device, denoted as w\u2081 and di,j, respectively. Our goal is to find a global model representing a rough average, capturing common characteristics across all teams and devices; personalized team models that are close to the global model but can deviate from aligning with shared features within each team; and personalized device models that resemble the team model but can deviate to accommodate the unique characteristics of each device. We adopt a quadratic penalty approach to enforce that the device models are close to the team models and the team models to the global model. The parameters \u03b3 > 0 and \u03bb \u2265 0 control the degree of personalization impact at the team and device levels respectively.\n$\\min_{x\\in \\mathbb{R}^d} \\min_{w_i\\in \\mathbb{R}^d} \\min_{\\theta_{i,j} \\in \\mathbb{R}^d} \\frac{1}{M} \\sum_{i=1}^{M} \\frac{1}{N_i} \\sum_{j=1}^{N_i} f_{i,j}(\\theta_{i,j}) + \\frac{\\lambda}{2} ||\\theta_{i,j} - w_i||^2 + \\frac{\\gamma}{2} ||w_i - x||^2.$\nWe are now prepared to outline the algorithm design. Our approach involves the use of three iteration counters: t for the global rounds, k for team-level rounds, and l for device-level rounds.\nDevice-level updates. Given a team model work, the objective of the device (i, j) is to solve the following subproblem:\n$\\theta_{i,j}^{(t,k)} := \\argmin_{\\theta_{i,j} \\in \\mathbb{R}^d} f_{i,j} (\\theta_{i,j}) + \\frac{\\lambda}{2} ||\\theta_{i,j} - w_i^{(t,k)}||^2.$\nThe exact solution to this problem is $prox_{f_{i,j}/\\lambda}(w)$; however, in general, there is no closed-form solution available for this proximal operator. Consequently, each device employs the gradient method to approximate the solution to (3). Starting with an initial value of $\\theta_{i,j}^{t,0} = w_i^{t,0}$, and utilizing a positive step-size a, we perform the following update rule for l = 0, 1, ..., L \u2013 1:\n$\\theta_{i,j}^{t,k,l+1} = \\theta_{i,j}^{t,k,l} - \\alpha (\\nabla f_{i,j} (\\theta_{i,j}^{t,k,l}) - \\lambda (\\theta_{i,j}^{t,k} - w_i^{t,k})).$\nTeam-level updates. Similarly, the goal in team-level updates is to solve a regularized subproblem. We define the team-level loss function as\n$F_i(w_i) := \\frac{1}{N_i} \\sum_{j=1}^{N_i} \\nabla f_{i,j} (w_i).$\nWith the addition of regularization towards the global server's model xt, Team (i) aims to solve the following subproblem:\n$\\argmin_{w_i \\in \\mathbb{R}^d} F_i(w_i) + \\frac{\\gamma}{2} ||w_i - x^t||^2.$\nOnce again, the solution is given by the proximal operator, $prox_{F_i/\\gamma}(x^t)$, which can be difficult to compute. Instead, we can find an approximate solution by using the gradient method. Starting from w\u2070 = xt, and using a positive step-size \u03b7 > 0, the gradient method update becomes\n$w_i^{t,k+1} = w_i^{t,k} - \\eta_i \\nabla F_i(w_i^{t,k}) - \\eta_i \\gamma (w_i^{t,k} - x^t)$\n$= w_i^{t,k} - \\frac{\\eta_i}{N_i} \\sum_{j=1}^{N_i}(\\nabla f_{i,j} (w_i^{t,k}) - \\gamma (w_i^{t,k} - x^t)).$\nHere, the second line follows from the definition of F\u2081. Since we do not have the exact gradient fi,j (wk), we approximate it by:\n$\\nabla \\nabla f_{i,j} (w_i^{t,k}) = \\lambda (w_i^{t,k} - prox_{f_{i,j}/\\lambda} (w_i^{t,k})) = \\lambda (w_i^{t,k} - \\theta_{i,j}^{t,k,L}).$\nBy combining (7) and (8), we construct the following update rule for k = 0, 1, ..., K \u2212 1:\n$w_i^{k+1} = (1-\\eta(\\lambda + \\gamma))w_i^{k} + \\eta\\gamma x^t + \\frac{\\lambda\\eta}{N_i}\\sum_{j=1}^{N_i} \\theta_{i,j}^{t,k,L}.$\nServer-level updates. Finally, the server applies the gradient method for\n$\\min_{x\\in \\mathbb{R}^d} \\Phi (x) := \\frac{1}{M} \\sum_{i=1}^{M} F_i (x).$\nStarting from an initial state x\u2070 \u2208 Rd and using a positive step-size \u03b2, the gradient update becomes:\n$x^{t+1} = x^t - \\frac{\\beta}{M} \\sum_{i=1}^{M} \\nabla F_i(x^t).$\nAgain, we use an approximation for VF;(xt) based on the team-level models:\n$\\nabla F_i(x^t) = \\gamma(x^t - prox_{F_i/\\gamma}(x^t)) \\approx \\gamma(x^t - w_i^{t,K}).$\nFinally, we construct the server-level update rule by combining (11) and (12). For t = 0,1,...,T 1, the server performs the following update rule:\n$x^{t+1} = (1 - \\beta \\gamma) x^t + \\frac{\\beta \\gamma}{M} \\sum_{i=1}^{M} w_i^{t,K}.$\nSynthesis. By combining device, team, and server-level updates, we propose PerMFL (Algorithm 1) for personalized multi-tier FL."}, {"title": "3.3 Convergence guarantees", "content": "This section presents the convergence guarantees of PerMFL. We consider two different settings, with strongly convex and non-convex loss functions. In both cases, we assume that the loss functions are smooth in the sense that they have Lipschitz continuous gradients. The next Theorem formalizes the guarantees of when fi,j is strongly convex.\nTheorem 1 (Strongly convex). Consider the minimization problem $\\min_x \\Phi (x)$ when $\\Phi (x)$ is defined in (10) with Lf-smooth and pf-strongly convex loss functions fi,j(x). For large enough numbers of inner iterations of orders L = \u03a9(K) and K = \u03a9(\u03a4), see the supplementary copy for the bounds, estimation ${x^t}_{t=0}^f$ generated by PerMFL with step-size \u1e9e satisfies:\n$||x^T - x^*||^2 < 2(1 - \\beta)^T ||x^0 - x^*||^2.$\nwhere learning rates should satisfy $\\beta < \\frac{1}{4L_f+1}$,$\\eta_i < \\frac{N_i}{2(\\lambda+\\gamma)}$, $a_{i,j} \\leq \\frac{\\lambda}{1+\\lambda}$, $M_p := \\frac{\\lambda}{\\lambda+\\gamma} + \\frac{\\gamma}{\\lambda+\\gamma} + \\frac{\\lambda\\gamma}{(\\lambda+\\gamma)^2}$, and$\\gamma > 2\\lambda > 4L_f$.\nProof sketch. We analyze the algorithm in three levels: (i) The devices find approximate solutions to problem (3) by using the gradient method. We can control the accuracy of this stage by choosing L (the number of iterations for the gradient method) large enough. (ii) The teams solve problem (6) approximately, again by using a gradient method. We use an inexact gradient at this stage since the exact gradient requires exact solutions from the devices to which we do not have access. At this stage, K is the number of iterations, and L modulates the accuracy of our gradients. By choosing both K and L large enough, we can control the solution accuracy achieved at the teams' level. (iii) Finally, the Server solves the problem (10), the original FL problem, by using the information provided by the Teams. It is worth noting that for a fixed T, we can decrease the error (down to a threshold) by increasing K and L. More precisely, we achieve linear convergence rates when we choose K and L in the order of \u03a9(\u03a4). The complete proof is left to the supplementary material.\nThe next Theorem shows that PerMFL finds a first-order stationary point with sublinear rates when fi,j are smooth but non-convex.\nTheorem 2 (Non-convex). Consider the minimization problem $\\min_x \\Phi (x)$ when $\\Phi (x)$ is defined in (10) with non-convex Lf-smooth loss functions fi,j(x). For large enough numbers of inner iterations of orders L = \u03a9(K) and K = \u03a9(\u03a4), see the appendix for the bounds, then, estimation ${x^t}_{t=0}^f$ generated by PerMFL with step-size \u1e9e satisfies:\n$E[||\\nabla \\Phi(x_\\tau)||^2] \\le \\frac{\\Phi(x^0) - \\Phi(x^*)}{\\beta T}$\nwhere $\\beta \\leq \\frac{1}{4L_f}$,$\\eta_i \\leq \\frac{N_i}{\\lambda+\\gamma}$, $a_{i,j} = 1$, $\\gamma > 2\\lambda > 4L_f$, and $\\tau$ is uniformly sampled from ${0,...,T-1}$\nProof sketch. The analysis follows a similar structure to the previous setting. The main difference is that the errors in subproblems are guaranteed as a bound on the gradient norms, which we translate to error bounds on objective residual by tuning A and y. The proof can be found in the supplementary material.\nRemark 2. At first glance, it may come as a surprise that our guarantees do not necessitate a bounded drift condition, which is common in FL methods involving multiple local steps. It is important to note a fundamental distinction between the conventional FL template (1) and our personalized multi-tier FL template (2). The former lacks consideration for data heterogeneity as it relies solely on a single global variable. This can result in 'drift-away' issues when multiple local steps are taken, especially in the presence of data heterogeneity. In contrast, our formulation explicitly incorporates team and device-level variables, and our local steps are tailored to solve device and team-level subproblems (3) and (6). The regularization employed in these subproblems prevents \u2018over-drifting\u2019 by explicitly penalizing the divergence between device, team, and global models in a suitable manner."}, {"title": "4 Experiments", "content": "We studied classification problems to validate PerMFL using both benchmarks (MNIST [31], FMNIST [32] EMNIST [33] with 10 classes (EMNIST-10), EMNIST with 62 classes (FEMNIST), CIFAR100 [34]) and non-image synthetic datasets. For the MNIST, FMNIST, EMNIST-10, and synthetic datasets, the data was distributed among multiple devices in a non-iid manner, ensuring each device had data from at most two classes. Subsequently, the devices were randomly grouped into four teams, each consisting of 10 devices, before performing PerMFL. We considered the full participation of teams and devices in each global round for the performance and convergence evaluation. For the FEMNIST and CIFAR100 datasets, the data was distributed to 3,500 and 350 devices, respectively, with each device holding data from the 3 classes. The devices are arranged into 5 teams. All datasets are split into training and validation sets with a 3:1 ratio.\nWe considered a multi-class logistic regression (MCLR) model with a softmax activation function for strongly convex scenarios. For synthetic datasets, we constructed deep neural networks with two hidden layers, while for image datasets, we built two-layered convolutional neural networks for non-convex scenarios. More details of the experimental setup, datasets, and learning models are in the supplementary copy.\nIn this paper, we conducted (1) the performance comparison between PerMFL with FedAvg [1], pFedMe[11], Per- FedAvg [13], pFedBayes [20], Ditto [10], and performance and convergence comparison with two hierarchical FL algorithms, such as hierarchical-SGD (h-SGD)[5], Asynchronous L2GD (AL2GD)[18], and a hierarchical-clustered FL algorithm DemLearn [19]. (2) We investigated the impact of \u03b2, \u03b3, and A on the convergence of PerMFL. (3) An ablation study to explore team formation. (4) An ablation study to analyze the influence of team and device participation. Moreover, in the supplementary copy, we gave an ablation study that explores the effects of team iterations on the convergence of PerMFL. Throughout the experiments, we denoted the personalized model and global model as (PM) and (GM), respectively We have made the implementation of PerMFL available at https://github.com/sourasb05/PerMFL_1.git"}, {"title": "4.1 Results and Analysis", "content": "4.1.1 Performance:\nFrom table 1, we observed that PerMFL(PM) outperformed the state-of-the-art for non-convex cases in all datasets. PerMFL(GM) outperformed other global models, including FedAvg(GM), pFedMe(GM), and Ditto(GM), and nearly equivalent with h-SGD(GM) and DemLearn(GM) for the MNIST dataset. For the synthetic dataset, PerMFL(GM) outperformed the state-of-the-art. For FMNIST and EMNIST-10 datasets, the performance of PerMFL(GM) is better than the conventional FL models and DemLearn(GM). For strongly convex cases, PerMFL(PM) outperformed the state of the art in MNIST and Synthetic datasets. For the FMNIST dataset, PerMFL(PM)'s performance is better than the conventional FL state-of-the-art. Moreover, the performance of PerMFL(PM) is nearly equivalent to the DemLearn(PM) for FMNIST and EMNIST-10. PerMFL(PM) also achieved better performance than h-SGD and AL2GD on FEMNIST and CIFAR100 given in the supplementary copy. PerMFL(GM) outperformed the state-of-the-art in Synthetic and FMNIST datasets. PerMFL(GM) performs better than conventional methods in all datasets and is nearly equivalent to h-SGD(GM) on MNIST and EMNIST-10. From these observations, we can infer that PerMFL(PM) performs better than the 7 state-of-the-art methods on 6 out of 8 experiments. The reason could be, the personalization in both team and devices helps to get better performance.\n4.1.2 Convergence:\nFrom fig. 2, we observed that the convergence of PerMFL(PM) is equivalent to DemLearn and is faster than h-SGD and AL2GD. Similar findings were also observed in EMNIST-10, Synthetic, and MNIST datasets given in the supplementary copy. It is because, inside each team multiple iterations are happening, that helps the personalized model to converge quickly.\n4.1.3 Effect of hyghperparameters \u03b2, \u03b3, and \u5165:\nFrom fig. 3, we observed if we increase the value of \u03b2, \u03b3, and A separately then PerMFL(PM) converge faster. A similar observation is found for FMNIST, and the synthetic dataset is given in the supplementary copy. In all experiments, the hyperparameters followed the bounds given in theorem 1 for strongly convex and theorem 2 for non-convex and smooth problems."}, {"title": "4.1.4 Ablation studies on team formation:", "content": "In table 2, we evaluated PerMFL for both worst-case (team 1 with labels {0, 1, 2, 3, 4} and team 2 with {5, 6, 7, 8, 9}) and average-case (teams with overlapping labels, team 1 with labels {0, 1, 2, 3, 4, 5, 6} and team 2 with {5, 6, 7, 8, 9,0, 1}) over 400 global iterations which include 10 and 20, team and local iterations respectively, with the hyperparameter settings X = 0.5, \u03b3 = 1.5, \u03b2 = 0.6, and, a = 0.01. PerMFL(GM) showed a 4% improvement in average-case over the worst-case with FMNIST data. Likewise, PerMFL(PM) had slightly better results in average-case than worst-case for non-convex setups (CNN) with MNIST and FMNIST datasets, indicating PerMFL(PM)'s performance is mostly unaffected by team formation."}, {"title": "4.1.5 Ablation study on teams and clients participation:", "content": "PerMFL achieves quick convergence with complete participation from both teams and devices (fig. 4a) or when teams fully participate but devices do so partially (fig. 4b), in contrast to slower convergence under partial participation from both teams and devices (fig. 4d). Moreover, expanding the number of teams does not impact the convergence speed of PerMFL(PM) when there is full participation from all teams and devices throughout all global rounds (fig. 4a). Increased device involvement leads to faster convergence (fig. 4b), whereas lower team engagement (fig. 4c) decelerates it. Nonetheless, when team participation reaches 50% in each global round, the convergence rate is comparable to that observed in scenarios with complete participation (fig. 4a). When all teams are fully participating, increasing the number of team iterations leads to quicker convergence. However, in scenarios where both team and device participation is minimal (2%) as shown in fig. 4d, PerMFL(PM) requires more global and team iterations to achieve convergence. Extended experimental results are reported in the supplementary copy."}, {"title": "5 Conclusions", "content": "We introduced, PerMFL, a personalized multi-tier federated learning approach involving global servers, teams, and devices. PerMFL utilized squared euclidean distance regularization on both devices and teams. By employing PerMFL, we are able to generate personalized models for each device and simultaneously obtain a global model. The performance of PerMFL demonstrates linear baseline rates for strongly convex scenarios and sublinear baseline rates for non-convex and smooth scenarios. Empirically we observed that PerMFL(PM) converges quickly and outperformed the state-of- the-art. PerMFL performs best when both teams and devices participate fully. Very low team and device participation degrade the performance of PerMFL(GM). It requires more global and team iterations to converge. Also, in worst-case team formation, the performance of the global model decreases, while the personalized model is able to maintain its performance. Moreover right combination of \u03bb, \u03b2, and y enhances the convergence of PerMFL."}, {"title": "A Preliminaries and Supporting Lemmas", "content": "Definition 1 (Strong convexity). A differentiable function g : Rd \u2192 R is \u00b5g-strongly convex if there exists a positive constant \u00b5g such that\n$g(x) \\le g(y) + \\langle \\nabla g(x), x - y \\rangle - \\frac{\\mu_g}{2} ||x-y||^2, \\forall x, y \\in \\mathbb{R}^d.$\nIf g is \u00b5g-strongly convex, then\n$\\mu_g ||x \u2212 y || \\le ||\\nabla g(x) \u2013 \\nabla g(y)||, \\forall x, y \\in \\mathbb{R}^d.$\nDefinition 2 (Smoothness). A differentiable function g : Rd \u2192 R is Lg-smooth if there exists a non-negative constant Lg such that\n$||\\nabla g(y) \u2013 \\nabla g(x)|| \\le L_g ||x \u2212 y||, \\forall x, y \\in \\mathbb{R}^d.$\nIf g is Lg-smooth, then\n$\\vert g(y) - g(x) \u2013 \\langle \\nabla g(x), y - x \\rangle \\vert \\le \\frac{L_g}{2} ||y-x||^2, \\forall x, y \\in \\mathbb{R}^d.$\nDefinition 3 (Expected Smoothness). The second moment of the stochastic gradient \u2207g(x) sattisfies\n$\\mathbb{E}||\\nabla g(x)||^2 \\le 2A(g(x) - g(x^*)) + B \\cdot ||\\nabla g(x)||^2 + C,$\nfor some A, B, C > 0 and \u2200x \u2208 Rd.\nDefinition 4 (Moreau Envelope). For a function g, its Moreau envelope \u011f is defined as\n$\\tilde{g}(x) = \\min_{u} \\{g(u) + \\frac{\\lambda}{2} ||u-x||^2 \\}.$\nProposition 1. Let g be a convex function and \u011f be its Moreau Envelope with parameter \u5165. Then\n1. \u011f is convex.\n2. \u011f is continuously differentiable (even if f is not) and\n$\\nabla \\tilde{g}(x) = \\lambda (x \u2013 prox_{g/\\lambda}(x)), $where $prox_{g/\\lambda}(x) := arg min_{u\\in \\mathbb{R}^d} \\{ g(u) + \\frac{\\lambda}{2} ||u \u2013 x||^2 \\}.$\nMoreover \u011f is A-smooth.\n3. If g is \u00b5-strongly convex, then \u011f is \u00b5\u1ef9-strongly convex with $\\mu_{\\tilde{g}} = \\frac{\\mu_{\\lambda}}{\\mu+\\lambda}$.\nProposition 2. If g is non-convex and Lg-smooth, then \u2207\u011f(x) is A-smooth with the condition that > > 2Lg.\nProposition 3. If g : Rd \u2192 R is convex and Lg-smooth, then\n$||\\nabla g(x) \u2013 \\nabla g(y)||^2 \\le 2L_g (g(x) - g(y) \u2013 \\langle (g(y), x - y \\rangle ), \\forall x,y \\in \\mathbb{R}^d.$\nProposition 4. If g : Rd \u2192 R is \u00b5g-strongly convex, then\n$\\frac{4 \\mu_g}{\\mu^2} ||x - x^*||^2 \\le g(x) - g(x^*), \\forall x \\in \\mathbb{R}^d.$\nRemark 3. For any set of vectors ${y_i}_{i=1}^n$, we have\n$\\vert\\vert \\sum_{i=1}^{n} y_i \\vert\\vert^2 = \\sum_{i=1}^{n} \\vert\\vert y_i \\vert\\vert^2 + \\sum_{i \\neq j} \\langle y_i,y_j \\rangle,$\nthat leads to\n$\\vert\\vert \\sum_{i=1}^{n} y_i \\vert\\vert^2 \\le n\\sum_{i=1}^{n} \\vert\\vert y_i \\vert\\vert^2.$\nwhere $y := \\frac{1}{n}\\sum_{i=1}^{n} y_i$\nRemark 4 (Young's inequality). For any \u0454 > 0 and vectors y, z \u2208 Rd, we have\n$2\\langle y, z \\rangle\\le \\frac{\\epsilon}{2} \\vert\\vert y \\vert\\vert^2 + \\frac{1}{\\epsilon} \\vert\\vert z \\vert\\vert^2$"}, {"title": "Remark 5 (Parameters in PerMFL). Here, we consider two setups.", "content": "\u2022 If fi,j is pf-strongly convex, then\n- fi,j is up-strongly convex where $\\mu_{\\tilde{f}} = \\frac{\\lambda\\mu_f}{\\lambda+\\mu_f}$\n- fi,j is A-smooth.\n- Fi is \u00b5F-strongly convex where $\\mu_F = \\frac{\\lambda}{\\lambda+\\mu_f} \\mu_f$\n- Fi is \u00b5\u1fc7-strongly convex where\n$\\mu_{\\Phi} = \\frac{\\mu_F\\gamma}{\\mu_F + \\gamma} = \\gamma \\frac{\\frac{\\lambda\\mu_f}{\\lambda+\\mu_f}}{\\frac{\\lambda\\mu_f}{\\lambda+\\mu_f} + \\gamma} = \\frac{\\lambda\\gamma\\mu_f}{\\lambda\\mu_f + \\gamma\\mu_f + \\lambda\\gamma}$"}]}]}