{"title": "PERSONALIZED MULTI-TIER FEDERATED LEARNING", "authors": ["Sourasekhar Banerjee", "Ali Dadras", "Alp Yurtsever", "Monowar Bhuyan"], "abstract": "The key challenge of personalized federated learning (PerFL) is to capture the statistical heterogeneity properties of data with inexpensive communications and gain customized performance for participating devices. To address these, we introduced personalized federated learning in multi-tier architecture (PerMFL\u00b9) to obtain optimized and personalized local models when there are known team structures across devices. We provide theoretical guarantees of PerMFL, which offers linear convergence rates for smooth strongly convex problems and sub-linear convergence rates for smooth non-convex problems. We conduct numerical experiments demonstrating the robust empirical performance of PerMFL, outperforming the state-of-the-art in multiple personalized federated learning tasks.", "sections": [{"title": "1 Introduction", "content": "Federated learning (FL) is a distributed on-device learning framework that employs the heterogeneous data privately available at the edge for learning. In classical machine learning, edge devices are supposed to send data to the centralized server for training. However, FL relaxes this restriction by enabling the training of each model on the end devices and aggregating them on the global server. Classical FL learns a single global model by utilizing the private data of the devices locally and exchanging only the model information in a communication-efficient and privacy-preserving manner [1].\n\nThe early FL literature focuses mainly on a simplistic network architecture where all devices communicate directly with a single server [1]. An example of such a network architecture is typical on a local area network (LAN) with all devices connected to a single server. However, real-world Internet applications often occur on more complex, multi-tiered network architecture, e.g., wide area networks (WAN) that span multiple geographic locations and connect heterogeneous LANs. Hence, the conventional FL architecture is not suitable for such a setting. To address this, we study a multi-tier FL model Figure 1b where an intermediate layer of mediators, called team servers (TS\u00bf), acts as a bridge between the end devices (N\u00bf) and the global server (GS) and facilitates intermediate aggregations. From a systems standpoint, this multi-tier FL model resembles the cloud-edge continuum architecture [2]. In this model, the distant cloud serves as a central server responsible for generating a global model, and the edge servers located in various geographical regions act as team servers that establish connections with both the distant cloud and end devices. In contrast, the end devices perform local model computations. Multi-tier FL models, which are also referred to as hierarchical FL, have been studied by researchers in various applications and have shown significant advantages such as cost efficiency and scalability [3], reduced communication overheads [4, 5], enhanced privacy [6], improved system adaptability and performance [7], and faster convergence speeds (both theoretically and empirically) and reduced training time [8].\n\nData heterogeneity poses a significant challenge in FL, as data across different devices may exhibit varying characteristics and originate from diverse data distributions. The conventional FL systems assume that a single global model fits all devices, hindering the convergence speed and more crucially, the model accuracy when data is disseminated in a"}, {"title": "2 Related Work", "content": "This section reviews existing studies and summarizes the differences between existing works and proposed efforts. We emphasize three different categories of FL models - multi-tier and personalized FL.\n\nMulti-tier FL. A multi-tier (aka hierarchical) FL model leverages the combined capabilities of cloud and edge devices within the FL framework. In [8], the authors demonstrated that a multi-tier FL strategy, both theoretically and empirically, exhibits a faster convergence rate compared to traditional FL algorithms. In [14], the concept of \"upward\" and \"downward\u201d divergences were introduced, exploring their implications in the context of multi-tier FL. Additionally, [15] presented Cross-Silo FL, which encompasses multi-tier networks and utilizes vertical and horizontal data partitioning strategies. In [3], they introduced FEDn, a multi-tier FL framework designed explicitly for horizontally scalable distributed deployments. [6] identified several potential advantages of multi-tier FL in addressing privacy concerns. Firstly, multi-tier FL helps reduce the concentration of power and control in a central server, promoting a more distributed and decentralized approach. Secondly, multi-tier FL allows for the flexible placement of defense and verification mechanisms within the hierarchical structure, enabling the practical application of these methods. Lastly, multi-tier FL leverages the trust between users to mitigate the number of potential threats."}, {"title": "Personalized FL", "content": "FedAvg [1] is a classical baseline method in FL, renowned for its simplicity and low communication cost. However, it faces challenges when dealing with heterogeneous (non-iid) data, leading to unstable performance due to the concept drift problem. Concept drift arises when a single global model does not perform well for all clients. To address these issues, FL has increasingly leaned toward personalized models [16, 17, 9]. In [12], the authors proposed a personalized version of model-agnostic meta-learning (MAML) for FL. They identified the problem of how fast the initial shared model adapts to their local dataset with fewer gradient descent steps using individual client data. In [17], a systematic learning-theoretic study of personalization led to the proposal of three model-agnostic approaches: user clustering, data interpolation, and model interpolation. Another approach, presented in [11], formulated a personalized FL problem that utilized Moreau envelopes to regularize devices' loss functions. In [18], the authors introduced an Asynchronous Loopless Local Gradient Descent (Async-L2GD) method for users from multiple known clusters, simultaneously training three models: a global model, a model-specific cluster, and a personalized model for each device. The architecture is similar to PerMFL, except that L2GD is an asynchronous approach. [19] introduced DemLearn, an FL algorithm that employs hierarchical agglomeration clustering. Unlike our model, where teams remain static throughout the FL process, DemLearn dynamically assembles teams after each global round. Recent research on personalized FL also includes works such as [20, 21, 22, 23, 9, 24, 10].\n\nMotivation. A hierarchical structure in FL addresses the scalability and failure tolerance limitations observed in the centralized architecture [6]. In addition, it is also beneficial in addressing the management difficulties, system adaptivity, and performance [7] that arise due to fully decentralized architecture [6]. The key challenge of personalization is the heterogeneity of data, locally customized models, and identifying and collaborating among clients those having similar information [18]. By adding personalization at team and device levels, we aim to capture customized and refined personalized properties of the model that align well with real-world applications [2, 25]. Communication with the global server is often the most expensive step in FL [26], and communications within a team are typically cheaper [8]. By employing the multi-tier architecture and accommodating a large portion of the communication within the teams, PerMFL economizes significantly on the communication iterations with the global server, preventing biases to local clients, and achieving faster convergence [6]. These advantages motivated us to propose multi-tier FL."}, {"title": "3 PerMFL", "content": "A multi-tier FL framework (see Figure 1b) is different from the conventional FL framework (see Figure 1a) as it follows a hierarchy. All devices are divided into M teams. Each team has a team server (TS\u2081), which is connected with Ni devices of the respective team. Global server (GS) only communicates with TSi's team."}, {"title": "3.1 Team formation", "content": "By definition, FL can be seen as a cross-silo or cross-device setting [27]. In cross-silo settings, a limited number of devices, typically between 2 and 100, participate in each round, and their participation remains fixed. On the other hand, in cross-device setups, the client pool is extensive, potentially in the millions, but only a small fraction of devices take part in each iteration [27]. In a multi-tier structure, teams can be constituted in four ways: (1) Both teams and devices within teams have full participation, (2) Teams have full participation, whereas devices within teams are participating partially, (3) Teams have partial participation, but all devices within teams are participating, and (4) Teams and devices both have partial participation.\n\nVarious FL methods with different team formation strategies have been proposed in the literature [28, 29]. PerMFL does not explicitly address the creation of teams. Instead, it exhibits adaptability to accommodate any team formation mechanism. It is important to note that PerMFL is most efficient when communication with the team servers is cheaper compared to communication with the global server. This situation often occurs when devices are geographically"}, {"title": "3.2 PerMFL formulation", "content": "We consider a multi-tier FL setup, consisting of M teams, each with N\u2081 devices (i = 1, . . ., M). In this setup, empirical risk minimization can be expressed as:\n$$min_{x \\in \\mathbb{R}^d} \\frac{1}{M} \\sum_{i=1}^M \\frac{1}{N_i} \\sum_{j=1}^{N_i} f_{ij}(x).$$\nHere, fi,j(\u00b7) represents the loss function of the jth device from the ith team. This formulation relies on a single decision variable x that all clients are expected to converge upon. However, this model is unsuitable for scenarios involving non-homogeneous data distributions, as the existence of a global model capable of accommodating all devices becomes unreasonable.\n\nTo address this challenge, we introduce decision variables for every team and device, denoted as w\u2081 and di,j, respectively. Our goal is to find a global model representing a rough average, capturing common characteristics across all teams and devices; personalized team models that are close to the global model but can deviate from aligning with shared features within each team; and personalized device models that resemble the team model but can deviate to accommodate the unique characteristics of each device. We adopt a quadratic penalty approach to enforce that the device models are close to the team models and the team models to the global model. The parameters \u03b3 > 0 and \u5165 \u2265 0 control the degree of personalization impact at the team and device levels respectively.\n$$min_{x \\in \\mathbb{R}^d} min_{w_i \\in \\mathbb{R}^d} min_{\\theta_{i,j} \\in \\mathbb{R}^d} \\frac{1}{M} \\sum_{i=1}^M \\frac{1}{N_i} \\sum_{j=1}^{N_i} f_{i,j}(\\theta_{i,j}) + \\frac{\\lambda}{2} || \\theta_{i,j} - w_i ||^2 + \\frac{\\gamma}{2} || w_i - x ||^2 .$$\nWe are now prepared to outline the algorithm design. Our approach involves the use of three iteration counters: t for the global rounds, k for team-level rounds, and l for device-level rounds.\n\nDevice-level updates. Given a team model work, the objective of the device (i, j) is to solve the following subproblem:\n$$\\theta_{i,j}^{(w^{t,k})} := argmin_{\\theta_{i,j} \\in \\mathbb{R}^d} f_{i,j} (\\theta_{i,j}) + \\frac{\\lambda}{2} || \\theta_{i,j} - w^{t,k} ||^2$$\nThe exact solution to this problem is $prox_{f_{i,j}/\\lambda}(w)$; however, in general, there is no closed-form solution available for this proximal operator. Consequently, each device employs the gradient method to approximate the solution to (3). Starting with an initial value of 0,0 i,j= wt,k, and utilizing a positive step-size a, we perform the following update rule for l = 0, 1, ..., L \u2013 1:\n$$\\theta_{i,j}^{t,k,l+1} = \\theta_{i,j}^{t,k} - a_i,j \\nabla f_{i,j} (\\theta_{i,j}^{t,k}) - \\lambda (\\theta_{i,j}^{t,k} - w^{t,k}).$$\nTeam-level updates. Similarly, the goal in team-level updates is to solve a regularized subproblem. We define the team-level loss function as\n$$F_i(w_i) := \\frac{1}{N_i} \\sum_{j=1}^{N_i} f_{i,j}(w_i).$$\nWith the addition of regularization towards the global server's model xt, Team (i) aims to solve the following subproblem:\n$$clustF_i(x) := min_{w_i \\in \\mathbb{R}^d} F_i(w_i) + \\frac{\\gamma}{2} ||w_i - x^t||^2.$$\nOnce again, the solution is given by the proximal operator, $prox_{F_i/\\gamma}(x^t)$, which can be difficult to compute. Instead, we can find an approximate solution by using the gradient method. Starting from w\u2070 = xt, and using a positive step-size \u03b7 > 0, the gradient method update becomes\n$$\\begin{aligned}w_i^{t,k+1} &= w_i^{t,k} - \\eta_i \\nabla F_i(w_i^{t,k}) - \\eta_i \\gamma (w_i^{t,k} - x^t)\\\\&= w_i^{t,k} - \\frac{\\eta_i}{N_i} \\sum_{j=1}^{N_i} \\nabla f_{i,j}(w_i^{t,k}) - \\gamma (w_i^{t,k} - x^t). \\end{aligned}$$"}, {"title": "Server-level updates", "content": "Finally, the server applies the gradient method for\n$$min_{x \\in \\mathbb{R}^d} \\phi(x) := \\frac{1}{M} \\sum_{i=1}^M F_i(x).$$\nStarting from an initial state x\u2070 \u2208 Rd and using a positive step-size \u03b2, the gradient update becomes:\n$$x^{t+1} = x^t - \\frac{\\beta}{M} \\sum_{i=1}^M \\nabla F_i(x^t).$$\nAgain, we use an approximation for \u2207F;(xt) based on the team-level models:\n$$\\nabla F_i(x^t) = \\gamma(x^t \u2013 prox_{F_i/\\gamma}(x^t)) \\approx \\gamma(x^t \u2013 w_i^{t,K}).$$\nFinally, we construct the server-level update rule by combining (11) and (12). For t = 0,1,...,T 1, the server performs the following update rule:\n$$x^{t+1} = (1 - \\beta \\gamma)x^t + \\frac{\\beta \\gamma}{M} \\sum_{i=1}^M w_i^{t,K}$$\nSynthesis. By combining device, team, and server-level updates, we propose PerMFL (Algorithm 1) for personalized multi-tier FL."}, {"title": "4 Experiments", "content": "We studied classification problems to validate PerMFL using both benchmarks (MNIST [31], FMNIST [32] EMNIST [33] with 10 classes (EMNIST-10), EMNIST with 62 classes (FEMNIST), CIFAR100 [34]) and non-image synthetic datasets. For the MNIST, FMNIST, EMNIST-10, and synthetic datasets, the data was distributed among multiple devices in a non-iid manner, ensuring each device had data from at most two classes. Subsequently, the devices were randomly grouped into four teams, each consisting of 10 devices, before performing PerMFL. We considered the full participation of teams and devices in each global round for the performance and convergence evaluation. For the FEMNIST and CIFAR100 datasets, the data was distributed to 3,500 and 350 devices, respectively, with each device holding data from the 3 classes. The devices are arranged into 5 teams. All datasets are split into training and validation sets with a 3:1 ratio.\n\nWe considered a multi-class logistic regression (MCLR) model with a softmax activation function for strongly convex scenarios. For synthetic datasets, we constructed deep neural networks with two hidden layers, while for image datasets, we built two-layered convolutional neural networks for non-convex scenarios. More details of the experimental setup, datasets, and learning models are in the supplementary copy.\n\nIn this paper, we conducted (1) the performance comparison between PerMFL with FedAvg [1], pFedMe[11], Per-FedAvg [13], pFedBayes [20], Ditto [10], and performance and convergence comparison with two hierarchical FL algorithms, such as hierarchical-SGD (h-SGD)[5], Asynchronous L2GD (AL2GD)[18], and a hierarchical-clustered FL algorithm DemLearn [19]. (2) We investigated the impact of \u03b2, \u03b3, and \u03bb on the convergence of PerMFL. (3) An ablation study to explore team formation. (4) An ablation study to analyze the influence of team and device participation. Moreover, in the supplementary copy, we gave an ablation study that explores the effects of team iterations on the convergence of PerMFL. Throughout the experiments, we denoted the personalized model and global model as (PM) and (GM), respectively We have made the implementation of PerMFL available at https://github.com/sourasb05/PerMFL_1.git"}, {"title": "4.1 Results and Analysis", "content": null}, {"title": "4.1.1 Performance:", "content": "From table 1, we observed that PerMFL(PM) outperformed the state-of-the-art for non-convex cases in all datasets. PerMFL(GM) outperformed other global models, including FedAvg(GM), pFedMe(GM), and Ditto(GM), and nearly equivalent with h-SGD(GM) and DemLearn(GM) for the MNIST dataset. For the synthetic dataset, PerMFL(GM) outperformed the state-of-the-art. For FMNIST and EMNIST-10 datasets, the performance of PerMFL(GM) is better than the conventional FL models and DemLearn(GM). For strongly convex cases, PerMFL(PM) outperformed the state of the art in MNIST and Synthetic datasets. For the FMNIST dataset, PerMFL(PM)'s performance is better than the conventional FL state-of-the-art. Moreover, the performance of PerMFL(PM) is nearly equivalent to the DemLearn(PM) for FMNIST and EMNIST-10. PerMFL(PM) also achieved better performance than h-SGD and AL2GD on FEMNIST and CIFAR100 given in the supplementary copy. PerMFL(GM) outperformed the state-of-the-art in Synthetic and FMNIST datasets. PerMFL(GM) performs better than conventional methods in all datasets and is nearly equivalent to h-SGD(GM) on MNIST and EMNIST-10. From these observations, we can infer that PerMFL(PM) performs better than the 7 state-of-the-art methods on 6 out of 8 experiments. The reason could be, the personalization in both team and devices helps to get better performance."}, {"title": "4.1.2 Convergence:", "content": "From fig. 2, we observed that the convergence of PerMFL(PM) is equivalent to DemLearn and is faster than h-SGD and AL2GD. Similar findings were also observed in EMNIST-10, Synthetic, and MNIST datasets given in the supplementary copy. It is because, inside each team multiple iterations are happening, that helps the personalized model to converge quickly."}, {"title": "4.1.3 Effect of hyghperparameters \u03b2, \u03b3, and \u03bb:", "content": "From fig. 3, we observed if we increase the value of \u03b2, \u03b3, and \u03bb separately then PerMFL(PM) converge faster. A similar observation is found for FMNIST, and the synthetic dataset is given in the supplementary copy. In all experiments, the hyperparameters followed the bounds given in theorem 1 for strongly convex and theorem 2 for non-convex and smooth problems."}, {"title": "4.1.4 Ablation studies on team formation:", "content": "In table 2, we evaluated PerMFL for both worst-case (team 1 with labels {0, 1, 2, 3, 4} and team 2 with {5, 6, 7, 8, 9}) and average-case (teams with overlapping labels, team 1 with labels {0, 1, 2, 3, 4, 5, 6} and team 2 with {5, 6, 7, 8, 9,0, 1})"}, {"title": "4.1.5 Ablation study on teams and clients participation:", "content": "PerMFL achieves quick convergence with complete participation from both teams and devices (fig. 4a) or when teams fully participate but devices do so partially (fig. 4b), in contrast to slower convergence under partial participation from both teams and devices (fig. 4d). Moreover, expanding the number of teams does not impact the convergence speed of PerMFL(PM) when there is full participation from all teams and devices throughout all global rounds (fig. 4a). Increased device involvement leads to faster convergence (fig. 4b), whereas lower team engagement (fig. 4c) decelerates it. Nonetheless, when team participation reaches 50% in each global round, the convergence rate is comparable to that observed in scenarios with complete participation (fig. 4a). When all teams are fully participating, increasing the number of team iterations leads to quicker convergence. However, in scenarios where both team and device participation is minimal (2%) as shown in fig. 4d, PerMFL(PM) requires more global and team iterations to achieve convergence. Extended experimental results are reported in the supplementary copy."}, {"title": "5 Conclusions", "content": "We introduced, PerMFL, a personalized multi-tier federated learning approach involving global servers, teams, and devices. PerMFL utilized squared euclidean distance regularization on both devices and teams. By employing PerMFL, we are able to generate personalized models for each device and simultaneously obtain a global model. The performance of PerMFL demonstrates linear baseline rates for strongly convex scenarios and sublinear baseline rates for non-convex and smooth scenarios. Empirically we observed that PerMFL(PM) converges quickly and outperformed the state-of-the-art. PerMFL performs best when both teams and devices participate fully. Very low team and device participation degrade the performance of PerMFL(GM). It requires more global and team iterations to converge. Also, in worst-case team formation, the performance of the global model decreases, while the personalized model is able to maintain its performance. Moreover right combination of \u03bb, \u03b2, and \u03b3 enhances the convergence of PerMFL."}, {"title": "A Preliminaries and Supporting Lemmas", "content": "Definition 1 (Strong convexity). A differentiable function g : Rd \u2192 R is \u00b5g-strongly convex if there exists a positive constant \u00b5g such that\n$$g(x) \\leq g(y) + <\\nabla g(x),x - y> - \\frac{\\mu_g}{2} ||x-y||^2, \\forall x,y \\in \\mathbb{R}^d.$$\nIf g is \u00b5g-strongly convex, then\n$$\\mu_g ||x \u2013 y || \\leq ||\\nabla g(x) \u2013 \\nabla g(y)||, \\forall x, y \\in \\mathbb{R}^d.$$\nDefinition 2 (Smoothness). A differentiable function g : Rd \u2192 R is Lg-smooth if there exists a non-negative constant Lg such that\n$$||\\nabla g(y) \u2013 \\nabla g(x)|| \\leq L_g ||x \u2013 y||, \\forall x, y \\in \\mathbb{R}^d.$$\nIf g is Lg-smooth, then\n$$|g(y) - g(x) - <\\nabla g(x), y \u2013 x>| \\leq \\frac{L_g}{2} ||y - x||^2, \\forall x, y \\in \\mathbb{R}^d.$$\nDefinition 3 (Expected Smoothness). The second moment of the stochastic gradient \u2207g(x) sattisfies\n$$E||\\nabla g(x)||^2 \\leq 2A(g(x) \u2013 g(x^*)) + B \u00b7 ||\\nabla g(x)||^2 + C,$$\nfor some A, B, C > 0 and \u2200x \u2208 Rd.\nDefinition 4 (Moreau Envelope). For a function g, its Moreau envelope \u011f is defined as\n$$\\bar{g}(x) = min_u \\{ g(u) + \\frac{\\lambda}{2} ||u - x||^2 \\}$$\nProposition 1. Let g be a convex function and \u011f be its Moreau Envelope with parameter \u03bb. Then\n1. \u011f is convex.\n2. \u011f is continuously differentiable (even if f is not) and\n$$\\nabla \\bar{g}(x) = \\lambda (x \u2013 prox_{g/\\lambda}(x)), where prox_{g/\\lambda}(x) := argmin_u \\{ g(u) + \\frac{\\lambda}{2} ||u - x||^2 \\}$$\nMoreover \u011f is A-smooth.\n3. If g is \u00b5-strongly convex, then \u011f is \u00b5-strongly convex with\nProposition 2. If g is non-convex and Lg-smooth, then \u2207\u011f(x) is A-smooth with the condition that \u03bb > 2Lg.\nProposition 3. If g : Rd \u2192 R is convex and Lg-smooth, then\n$$||\\nabla g(x) \u2013 \\nabla g(y)||^2 \\leq 2L_g (g(x) - g(y) \u2013 <\\nabla g(y), x - y>), \\forall x,y \\in \\mathbb{R}^d.$$\nProposition 4. If g : Rd \u2192 R is \u00b5g-strongly convex, then\n$$\\frac{\\mu_g}{4} ||x - x^*||^2 \\leq g(x) - g(x^*), \\forall x \\in \\mathbb{R}^d.$$\nRemark 3. For any set of vectors {yi}_{i=1}^n, we have\n$$(\\sum_{i=1}^n y_i)^2 \\leq n \\sum_{i=1}^n ||y_i||^2$$\nthat leads to\n$$||\\frac{1}{n} \\sum_{i=1}^n y_i||^2 \\leq \\frac{1}{n} \\sum_{i=1}^n ||y_i||^2.$$\nwhere y := \\frac{1}{n} \\sum_{i=1}^n y_i.\nRemark 4 (Young's inequality). For any \u03f5 > 0 and vectors y, z \u2208 Rd, we have\n$$2|<y, z)| \\leq \\frac{\\epsilon}{2} ||y||^2 + \\frac{1}{\\epsilon} ||z||^2$$"}, {"title": "B Convergence of PerMFL (strongly convex case)", "content": "Let us consider the team-level update as in Algorithm 2. We start with analyzing the convergence of this algorithm when having access to the approximate solution to prox F\u2081/\u03b3(.) in Theorem 3. Secondly we upper bound the approximation error in Theorem 4. We analyze the client level convergence in Theorem 5. Finally, we combine these results in Appendix B.3 and complete the proof of Theorem 1."}]}