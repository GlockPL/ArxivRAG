{"title": "Evolved Developmental Artificial Neural Networks for Multitasking with Advanced Activity Dependence", "authors": ["Yintong Zhang", "Jason A. Yoder"], "abstract": "Recently, Cartesian Genetic Programming has been used to evolve developmental programs to guide the formation of artificial neural networks (ANNs). This approach has demonstrated success in enabling ANNs to perform multiple tasks while avoiding catastrophic forgetting. One unique aspect of this approach is the use of separate developmental programs evolved to regulate the development of separate soma and dendrite units. An opportunity afforded by this approach is the ability to incorporate Activity Dependence (AD) into the model such that environmental feedback can help to regulate the behavior of each type of unit. Previous work has shown a limited version of AD (influencing neural bias) to provide marginal improvements over non-AD ANNs. In this work, we present promising results from new extensions to AD. Specifically, we demonstrate a more significant improvement via AD on new neural parameters including health and position, as well as a combination of all of these along with bias. We report on the implications of this work and suggest several promising directions for future work.", "sections": [{"title": "Introduction", "content": "Artificial Neural Networks (ANNs) are central to the ongoing revolution in Artificial Intelligence today. Most models involving artificial neural networks (ANNs) use fixed-structure networks, and their connection weights are trained via gradient descent. Because the task information is mainly encoded in the connection weights of the artificial neural network (ANN), which can be overwritten by training with a new task, they are likely to undergo catastrophic forgetting when being used to solve more than one problem. On the other hand, biological neural networks show more flexibility, incorporating environmental feedback during development to solve many tasks at once. Recently, more research has looked to biology for inspiration (Kudithipudi et al., 2022) for mechanisms that enable natural organisms to achieve flexible, adaptive intelligence desired by the field. According to the theory of Darwinian evolution, biological organisms start with simple structures and over time increase their complexity through development and evolution. Specifically, the process of development has allowed a wide range of organisms to grow from a single cell into multicellular organisms over an individual's lifespan. There are many factors that influence the developmental process including the internal and external environment, but also genetic factors. The genetic encoding that helps to regulate this process is still not well understood, but our knowledge and ability to model or imitate it continues to expand. What we do know is that in the natural world, many individuals undergo random mutations, and only sufficiently fit individuals are selected to survive and produce offspring. The phenotypes of these individuals are based on their genotypes and their environment, and their complex structures are produced through a sequence of developmental stages using the rules encoded by the genomes. In this paper, we look to expand upon an existing model (Miller, 2020b) that attempts to simulate the evolution of a developmental process. Specifically, a developmental program to build a multitasking neural network is found using an evolutionary algorithm. In this work, we reproduce comparable results to prior work while also simplifying the implementation. Most crucially, however, we conduct and report on results from experiments with an extended model of Activity Dependence (AD). AD is a mechanism that enhances the learning process of the neural network. AD allows the model to adjust its parameters based on feedback from tasks it performs. The key contribution of this work is the identification of the strong potential of previously unexplored targets of AD. In the remainder of this paper, we will start by reviewing approaches to developmental neural networks and related fields. Following this, we will discuss in more depth the particular model we build upon including relevant differences in our models and important details for implementation. Next, we lay out the specific methodology for the experiments we conduct and the results of those experiments. Finally, we discuss the significance and implications of those results, concluding with a summary of the overall work and highlighting promising avenues for future research."}, {"title": "Related Work", "content": "In this section, we will provide a brief review of related and similarly motivated work. There have been a number of different approaches to exploring the space of possible neural network architectures along with synaptic weights such as Neural Architecture Search (Liu et al., 2021), Hypernetworks (Chauhan et al., 2023), and neuroevolution(Stanley et al., 2019). As a whole, neuroevolution has benefited from biology inspirations. The artificial neural network models in this field include varying forms of plasticity, although not necessarily as part of a developmental process (Mouret and Tonelli, 2014). These forms of plasticity have been utilized in a wide range of works (Soltoggio et al., 2018), however, many are focused primarily on learning mechanisms and less on development. Work focused on development has helped produce a taxonomy of artificial embryogeny (Stanley and Miikkulainen, 2003) enabling classification of models along five key dimensions. By abstracting away the process of growth in development, Compositional Pattern Producing Networks (CPPNs) (Stanley, 2007) manage to capture many of the desirable features of development, but in a highly efficient manner. CPPNs form the groundwork for the HyperNEAT (Stanley et al., 2009) approach to neuroevolution, which is highly efficient and scalable. The underlying CPPN in HyperNEAT provides an indirect encoding of a neural network's structure and weights (as opposed to the direct encoding of the NEAT algorithm (Stanley and Miikkulainen, 2002)). However, as suggested by Hiesinger (2021), the way that a developmental process unfolds over time (via local interactions) could be a crucial component enabling the complexity of biological networks such as the human brain. A subset of the expanding collection of efforts to incorporate structural changes into the learning process of neural networks has been reviewed by Maile et al. (2023), who both provide connections to neuroscience, but also suggest a common neural operator framework to better relate different approaches. Despite these efforts, there have been relatively few attempts to allow neural networks which grow utilizing bottom-up approaches, with many of them presented in Kowaliw et al. (2014) Several recent works have been inspired by the process of neurogenesis (Maile et al., 2022; Huang et al., 2023). Another unique model is the Hyper-NCA (Najarro et al., 2022), which trains a Neural Cellular Automata to guide a developmental process and acts as a Hypernetwork. Aside from the work we directly build on in this paper (Miller, 2020b), the most closely related model is the Neural Developmental Program (NDP) (Najarro et al., 2023), which also takes a bottom-up approach. In this approach a neural network guides the process of regulating the growth of another target neural network. We believe that our results imply strong promise for similar future extensions of the NDP model as well."}, {"title": "Neural Network Model", "content": "This section introduces the architecture of our model which builds upon an existing model (Miller, 2020b). Specifically, we focus on how the model encodes the developmental rules of ANNs, which allows them to be evolved by evolutionary algorithms. We also discuss the developmental process of a single ANN and how we added new features for Activity Dependence (AD). The model (Miller, 2020b) we build upon focuses on ANN-generating programs evolved by evolutionary algorithms in the form of Cartesian Genetic Programming (CGP). The model takes inspiration from the same processes that have produced natural, biological brains, which include evolution, development, and learning. The model thus produces artificial feed-forward networks that are grown (development) according to rules from evolved programs (evolution) and adjusted by self-regulation via external feedback (learning). Past work demonstrated this model can solve multiple problems with a single network (Miller, 2020b). The model used Cartesian Genetic Programming (CGP) to transform encoded genomes into programs that grow a neural network. CGP builds a connection between genotypes encoded as strings and functioning computer programs by transforming one to the other, allowing the evolution of computer programs via the mutation of genotypes. Specifically, it uses numbers and strings to denote different kinds of computational operations and connections between inputs and outputs of operations. Any program encoded by CGP can be represented by a graph of operations, which can then be translated into string genotypes (Miller and Harding, 2008). A key feature of Miller's system is the self-learning behavior realized by AD. AD adjusts internal neural variables based on external signals, such as task performance, similar to a reward signal in reinforcement learning. AD is one dimension of the model that has been previously explored, albeit in a limited fashion. More details about the original model and AD can be found in the original paper (Miller, 2020b). Miller's model uses CGP to encode two programs as developmental rules for nodes (soma) and connections (dendrites). The populations, each involving two genotypes for both of the programs, are initialized randomly and they will be updated using the Evolutionary Algorithm. Each individual's initial neural network starts with a few input and output nodes in a 2-D space for the different tasks to solve. The output nodes have a few randomly initialized connections with their own positions in the space as well as other parameters including health and weight. In each developmental iteration, each node and connection are updated according to these programs and then the parameters of the whole network are generated for the next iteration. Based on the output parameters, each of the nodes will have different properties such as x and y positions and health after each iteration. In this way, the structure of the neural network is updated due to the changing positions of nodes"}, {"title": "Methodology", "content": "In previous work (Miller, 2020b), the model was tested with AD neuron bias by solving four problems. Two of them were reinforcement learning (RL) problems and the other two were classification problems. In this work, we use one RL task and one classification task for testing. Our system was able to demonstrate solving both problems simultaneously. We used the cartpole problem as our RL task and we used a bank authentication dataset (Ban, 2018) for the classification task. Although we did not use the exact same problems as the original work, we found that the combination of two kinds of problems produced comparable results for evaluating the ability of the new model. For all experiments, an initially random population of size ten was used. At the end of the evolution loop, the individual with the best fitness was selected for producing the next generation. Specifically, we made nine mutated individuals based on the selected one, along with the original one unmutated (elite). All experiments were run for 100 generations. All other predefined parameters inside the model, if not specified here, follow the details specified in (Miller, 2020a) regarding the base model. For example, our experiments use the same number of development cycles and theta values for neuron creation/deletion as the original model used. Since the basic model architecture is the same, using the same parameters could prove the functionality and produce comparable results to the best effort. For our first experiment, we used the model without AD to solve a single problem to test its basic functionality. In solving the cartpole only, the model perfectly reaches a thousand steps and solves the problem within fifty generations (the"}, {"title": "Results", "content": "For experimental results, we seek to compare the relative performances between experiments with different AD parameter configurations. In all cases, we run multiple experiments and report on the average score calculated on the best fitness of each run. Multiple experiments were conducted to compare the effects of AD behavior for different parameters present in the neural network. The experiments focused on soma parameters, which refer to the properties of nodes in a neural network: bias, health, and position (x and y). There are fifty evolutionary runs with each of the parameters modified by AD behavior, in which there are 100 generations within each run. Along with the fifty runs performed with the base model without AD, the effects of including AD on different parameters on the average performance can be directly compared to the base model. Finally, the AD behavior using all neuron parameters is evaluated to see the effects of a possible combination of AD, opening the door in the future for fine-tuning or evolving AD behavior. The average performance from fifty runs during 100 generations is plotted in the graph. For the experiments in which AD influences neuron health or position, we see increased performances relative to the base model. While the plotted graphs have similar shapes, the performance scores for AD health and position are higher than the base model and AD bias at the end of 100 generations. Since they have similar starting points at around 800, the AD behaviors on a single parameter have been demonstrated to make the neural networks adapt to the problem more efficiently than without any AD. Finally, AD on all neuron parameters showed the greatest performance of all. The last result implies that AD behavior for all neuron parameters may have minimal interference with each other, allowing their improvements to accumulate and achieve a better performance score when solving the problems."}, {"title": "Discussion", "content": "In the experiments, the results have shown promising improvements with different AD behaviors. Each of the experiments led to a noticeable increase in performance and a combination of all parameters could lead to larger improvements. However, there are several differences between the original model and the assumptions in our model, leading to"}, {"title": "Conclusion and future work", "content": "In this work, the implementation and experiments have focused on the improvement of learning efficiency in multitasking neural networks made by AD on neuron parameters. Although there are some uncertainties to be resolved in the experiments, we can safely conclude that AD with other neuron parameters leads to a greater performance increase compared to the previous work (Miller 2020). Moreover, combining AD behavior on different parameters can further improve the learning efficiency of this model. These results are promising and show notable improvements over the previous results. For related work, the results also increase the confidence of applying AD in other developmental models. For instance, a previous paper (Najarro et al., 2023) mentions the possibility of incorporating AD into the NDP model to enhance the model's learning ability. Therefore, the effects of different combinations of AD behavior could be explored with this model. On the other hand, a complete analysis of AD is not fully covered in this work. In addition to further analysis, we see great potential for future work in three directions: 1) exploring AD on other neural parameters, 2) optimizing combinations of parameters for AD, and 3) finding ways to increase the efficiency of the overall process. The first direction is to incorporate and evaluate the dendrite's parameters for AD behavior. By updating dendrite parameters using AD, the model can regulate the arrangement of connections between neurons, as well as the biases/weights of different dendrites. Given the results of AD on neuron parameters, this approach could further increase the learning efficiency of the model. Upon introducing this feature and evaluating the components, one could produce a baseline measurement of the individual utilities of the different AD neural parameters. A second direction for the future is based on the observed benefits of combined AD behavior. Seeing potential synergy, or at least minimal interference, between different AD behaviors with neural parameters opens the possibility of AD being parameterized for specific neural features. One approach to searching such a parameter space is evolutionary algorithms (EA). Thus, one could use an EA to find an optimal AD combination to maximize learning capabilities. Therefore, an important direction for future work is introducing an evolvable AD behavior, which means using a genotype to represent the set of parameters to be changed for each neural network. A final direction for future work is to focus on increasing the efficiency of the model. Although some steps in the algorithm have been simplified to speed up the execution, the model is still relatively slow due to the updating of a large brain network. Similarly, this model is inefficient because of the nature of evolutionary algorithms: every time the program is running with a large number of individuals only a small portion of them undergoes a good mutation. To address these problems, other applicable techniques, such as Quality Diversity (Pugh et al., 2016), could be implemented to allow more systematic exploration of meaningfully different developmental behaviors."}]}