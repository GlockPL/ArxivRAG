{"title": "Revisiting Structured Sentiment Analysis\nas Latent Dependency Graph Parsing", "authors": ["Chengjie Zhou", "Bobo Li", "Hao Fei", "Fei Li", "Chong Teng", "Donghong Ji"], "abstract": "Structured Sentiment Analysis (SSA) was cast\nas a problem of bi-lexical dependency graph\nparsing by prior studies. Multiple formula-\ntions have been proposed to construct the graph,\nwhich share several intrinsic drawbacks: (1)\nThe internal structures of spans are neglected,\nthus only the boundary tokens of spans are used\nfor relation prediction and span recognition,\nthus hindering the model's expressiveness; (2)\nLong spans occupy a significant proportion in\nthe SSA datasets, which further exacerbates the\nproblem of internal structure neglect. In this\npaper, we treat the SSA task as a dependency\nparsing task on partially-observed dependency\ntrees, regarding flat spans without determined\ntree annotations as latent subtrees to consider\ninternal structures of spans. We propose a two-\nstage parsing method and leverage TreeCRFs\nwith a novel constrained inside algorithm to\nmodel latent structures explicitly, which also\ntakes advantages of joint scoring graph arcs\nand headed spans for global optimization and\ninference. Results of extensive experiments on\nfive benchmark datasets reveal that our method\nperforms significantly better than all previous\nbi-lexical methods, achieving new state-of-the-\nart.", "sections": [{"title": "1 Introduction", "content": "Structured Sentiment Analysis (SSA) aims to ex-\ntract the complete opinion tuple from a sentence.\nAs shown in Figure 1(a), the complete opinion tu-\nple includes an opinion expression e with sentiment\npolarity p, an opinion holder h, and the correspond-\ning target t. Given the complexity of detecting\nthree items and classifying one, SSA presents more\nchallenges than other related tasks, such as Opinion\nMining (Katiyar and Cardie, 2016; Xia et al., 2021),\nABSA (Aspect-based Sentiment Analysis) (Pon-\ntiki et al., 2014, 2016; Wang et al., 2016), TOWE\n(Target-oriented Opinion Words Extraction) (Fan\net al., 2019; Mao et al., 2021), ASTE (Aspect Sen-\ntiment Triplet Extraction) (Peng et al., 2020; Mao\net al., 2021; Zhai et al., 2022; Fei et al., 2022a; Li\net al., 2023, 2024), etc.\nRecent works of SSA mainly cast it as a problem\nof bi-lexical dependency graph parsing and propose\nmultiple formulations: (1) Barnes et al. (2021) pro-\nposed formulations namely head-first/head-final as\nillustrated in Figure 1(b). Their method cannot\nresolve the problem because head-first/head-final\ntreats the first/final word as the head of the span and\nstrictly restricts any word inside the span directly\nhead to span head, which decreases the height of\nthe converted trees to 2 and excludes the latent\nstructures completely. (2) Another label strategy\nwas proposed by Shi et al. (2022), which simplifies\nthe label set to only arcs linking spans boundaries,\nas shown in Figure 1(c). Despite the special label\nfor discontinuous span decoding, Zhai et al. (2023)\nutilize the same label set. Without distinct formu-\nlation about inside words, they attempt to utilize\nthe powerful neural models like Graph Attention\nNetwork (Velickovic et al., 2018) or Axial-based\nAttention Network (Huang et al., 2019; Wang et al.,\n2020) to implicitly encoder the inside structure in-\nformation, which is found lagging behind large\nwith explicitly modeling with graph-based parsing\nmethods (Wang and Tu, 2020; Fonseca and Martins,\n2020; Zhang et al., 2020; Yang and Tu, 2022a). It is\nevident that previous work does not address the key\nchallenge focused on the prediction of boundary\nwords (First/Final/Both) of spans, and neglect the\nwords and structures inside spans, which hinders\nthe model expressiveness seriously.\nShould we neglect the structure inside spans as\nprevious works have done? Table 1 list the statistics\nof span length and the max length of spans in the\nbenchmark datasets respectively. We present a real\nexample to illustrate our point, focusing on the ex-\npression \"conceded\" and the target \"US President\nlast year\" for brevity.\nTang conceded there had been \"twists\nand turns\" following US President\nGeorge W. Bush 's accession to the US\npresidency in early last year.\nFrom this example, it is evident that the target span\nis considerably long, making it challenging for the\nboundaries (\"US\" and \"year\") to effectively repre-\nsent the entire span. Conversely, the internal word\n\"accession\" provides significant clues for identify-\ning it as the target of the expression \u201cconceded\".\nFurthermore, the other words within the target span\nact as modifiers, aiding in the detection of the\nspan's boundaries. Based on these observations,\nthe necessity of addressing the internal structure of\nspans in the SSA task is clear. It remains a signifi-\ncant challenge to develop an effective and unified\nmethod that can handle such structures.\nTo address this issue, we propose a novel ap-\nproach to structured sentiment analysis: treating\nflat spans as latent subtrees. This perspective\nconsiders expression-holder/target structures as\npartially-observed trees, where the exact subtrees\nfor each span are yet to be determined. We employ\nTreeCRF (Eisner, 1997; Eisner and Satta, 1999)\nto model these partially-observed trees. This in-\nvolves enumerating all possible arcs and spans in a\nlatent tree form of a flat span and calculating their\nprobabilities using a constrained inside algorithm.\nThe scores for all possible arcs and spans are deter-\nmined using biaffine or triaffine attention methods\n(Dozat and Manning, 2017; Zhang et al., 2020),\ncommonly applied in Dependency Parsing. During\nthe decoding stage, we parse the highest-scoring\ndependency tree and reconstruct the SSA structure\nfrom it. Span boundaries are accurately inferred\nfrom the descendant words of a head word. Ad-\nditionally, using the labels from the dependency\ntree, we can globally predict span-span relation-\nships. This method not only explicitly accounts\nfor internal span structures but also maintains the\nend-to-end nature characteristic of previous work.\nWe conduct extensive experiments on five bench-\nmarks, including NoReCFine (\u00d8vrelid et al., 2020),\nMultiBEU, MultiBCA (Barnes et al., 2018), MPQA\n(Wiebe et al., 2005) and DSUnis (Toprak et al.,\n2010). The results affirm that our model achieves\""}, {"title": "new state-of-the-art in performance for SSA task.\nOur contributions are summarized as follows:", "content": "new state-of-the-art in performance for SSA task.\nOur contributions are summarized as follows:\n\u2022 We cast SSA as a novel latent trees formula-\ntion to address the neglecting of span struc-\ntures in prior work. Concretely, we treat flat\nspans as latent trees and marginalize the ex-\nplicit structure via a novel constraint inside\nalgorithm.\n\u2022 We propose an effective two-stage parsing\nmethod to well collaborate with our latent\ntree formulation, which employs dependency\nparsing with high-order scoring and global\noptimization, modeling sentiment structures\nexplicitly.\n\u2022 The experimental results show that our model\nhas achieved the SOTA performance in five\ndatasets for structured sentiment analysis, es-\npecially in terms of long spans boundary de-\ntection and relation prediction."}, {"title": "2 Related Work", "content": "As a key topic in the Sentiment Analysis commu-\nnity (Fei et al., 2023a; Wu et al., 2021), Structured\nSentiment Analysis (SSA) encompasses several\nsub-tasks, each targeting a specific component of\nthe goal tuple (holder, target, expression, polarity).\nSSA also involves closely with structure predic-\ntions (Fei et al., 2022c) and relevant tasks (Fei\net al., 2023b; Wu et al., 2023a,b).\nOM Opinion Mining primarily aims to extract\nthe (h, t, e) tuple. Existing OM studies generally\nadopt one of two approaches: 1) BIO-based ap-\nproach, which views OM as a sequence labeling\ntask (Katiyar and Cardie, 2016); and 2) span-based\napproach, which jointly predicts all span pairs and\ntheir interrelations (Xia et al., 2021). Additionally,\nZhang et al. (2019); Wu et al. (2022) introduced\na transition-based model for OM. However, these\nmethodologies neglect the sentiment polarity clas-\nsification sub-task.\nABSA Aspect-Based Sentiment Analysis is an-\nother important sentiment analysis task. Various\nmethods have been proposed to address ABSA,\nincluding: 1) Pipeline (Peng et al., 2020), which se-\nquentially predicts spans and their relationships; 2)\nEnd-to-End (Chen and Qian, 2020), utilizing inter-\nactive information from each pair of sub-tasks; and\n3) MRC (Mao et al., 2021; Zhai et al., 2022), which\nemploy a machine reading comprehension frame-\nwork to extract triplets. However, these method-"}, {"title": "ologies neglect the sentiment holder extraction sub-task.", "content": "ologies neglect the sentiment holder extraction sub-task.\nSSA Barnes et al. (2021) propose the conversion\nnamed head-first/head-final and applied first-order\nparsing method. Shi et al. (2022) proposed a new\nlabel strategy and apply Graph Attention Network\nfor aggregation on span boundaries for decoding,\nSamuel et al. (2022) apply Transformer to predict\nthe graph directly from the text, Zhai et al. (2023)\nadd new labels to model the boundaries of discon-\ntinuous spans and apply axial-attention encoder\nand table filling scheme to decode the relations.\nHowever, all these works neglect the internal struc-\nture of the spans and rely on powerful encoders to\nimplicitly incorporate internal span structure infor-\nmation.\nDifferent from previous work, we are the first\nto cast SSA task as partially-observed dependency\ntree and apply dependency parsing method to ex-\nplicitly model the internal structures of spans. Ow-\ning to the structural similarities, leveraging NLP\ntasks such as parsing proves to be an effective strat-\negy for structured prediction. Our research builds\nupon the successes observed in partially-observed\ntree reduction and parsing methods across vari-\nous NLP tasks including named entity recognition\n(NER) (Yu et al., 2020), nested NER (Fu et al.,\n2021; Lou et al., 2022; Li et al., 2022; Fei et al.,\n2022b) and semantic role labeling (Zhang et al.,\n2022)."}, {"title": "3 SSA as Latent Graph Parsing Scheme", "content": "In the formulation of SSA as Latent Dependency\nGraph, we treat each sentiment span as latent tree.\nTo build the Dependency Graph, we deal with each\nexpression span separately and assumes each of\nthem corresponds to a single-root tree. In this tree,\nthe sentiment head word of the expression span\nserves as the dependency root, with each subtree\nof the corresponding holder/target span attaching\nto it. Consequently, our proposed latent depen-\ndency parsing task can be divided into two sub-\ntasks: (1) expression extraction; (2) corresponding\nholder/target extraction. Note that both of these\nsubtasks are solved by a consistent graph-based\nand headed-span-based parsing method, trained\njointly and decoded step-by-step, which is named\nas Two-stage Parsing 1."}, {"title": "3.1 Conversion and Training on Latent Tree", "content": "Formally, given an input sentence x = x1,..., Xn,\nour object is to obtain the corresponding tree struc-\ntures for each expression e \u2208 E and compose them\nto construct the Latent Dependency Graph ulti-\nmately.\nA directed dependency tree t is defined by as-\nsigning a head h\u2208 {x0,x1,..., xn}, accompanied\nby a relation label l\u2208 L to each modifier mex.\nHere, x0 is typically positioned before \u00e6, serving\nas the root node.\nFor an expression e \u2208 E within a consecutive\nword span xi,...,xj and assigned a sentiment\nlabel l\u2208 L, we constraint all potential subtrees\nwithin this span to be single-rooted at a potential\nheadword h, which is not realized yet. This concept\nis illustrated in Figure 2(a), where the sentiment la-\nbel l is allocated as the label of the dependency (i.e.,\nthe expression label with polarity) originating from\nxo to the headword. A parallel approach is adopted\nfor non-expression spans, with the distinction of\nsetting the label to \u00d8 and omitting the single-root\nconstraint. Subsequently, we designate all corre-\nsponding latent span subtrees as descendants of\nTe.\nFor a corresponding holder/target span with a\nconsecutive word span xi, . . ., xj and a sentiment\nlabel l \u2208 L, we impose a similar single-rooted con-\nstraint as with expression, as shown in Figure 2(b).\nAccordingly, the sentiment label l denotes the label\nof the dependency extending from each word in\ne to the headword. Spans deemed irrelevant are\ntreated akin to non-expression spans.\nBy enumerating all possible subtrees and accu-\nmulating them together, the resultant tree sets Te\nand Th/t expand exponential in size. To manage\nthis during training, we develop a constrained In-\nside algorithm to perform the enumeration (\u00a7 4.4),\ndesigned to prevent the formation of illegal struc-"}, {"title": "3.2 Decoding and Recovery on Latent Tree", "content": "Assuming that we have trained a parser, our\nnext step involves recovering expression and cor-\nresponding holder/target structures after decod-\ning/parsing the highest-scoring dependency tree.\nWe give illustration in Figure 2(c), we initially\nidentify all expression spans by obtaining the\nhighest-scoring expression tree t* rooted at xo\nthrough our parsing method:\n$$t* = \\text{arg max } s(x, t)$$\nFollowing this, we determine the highest-scoring\ncorresponding tree t** for e using the same algo-\nrithm:\n$$t** = \\text{arg max } s(x, t)$$\nwhere s(x, t) represents the score of the tree, with\np denoting the polarity label of expression spans\nrelative to xo. The tree is constrained to have its\nroot in one of the words in e. We then recover cor-\nresponding holder/target spans of the expression\nby transforming all subtrees headed by e into flat\nspans. If the label I of the dependency e \u2192 h is not\n\"\u00d8\" (indicating irrelevant spans), then a complete\nspan is formed, comprising h and its descendants,\nand is assigned l as its sentiment label. The fi-\nnal SSA output consists of a compilation of all\nrecovered expression spans and their respective\nholder/target spans."}, {"title": "4 Methodology", "content": "Following previous work on dependency parsing\n(Dozat and Manning, 2017; Zhang et al., 2020;\nYang and Tu, 2022a), our model consists of a con-\ntextualized encoder and scoring modules. We fur-\nther propose a constraint TreeCRF to compute the\nprobabilities of the partially-observed trees of SSA."}, {"title": "4.1 Encoder", "content": "For a given sentence x = X1,X1,...,Xn, we in-\ntroduce special tokens <bos> and <eos> as xo and\nXn+1, respectively. The vector representation for\neach token xi \u2208 \u00e6 is an amalgamation of five dis-\ntinct components:\nei =  [eword; vord; elemma; epos; echar; BERT\nIn this composition, eword, epos, and elemma repre-\nsent word, part-of-speech (POS), and lemma em-\nbeddings, respectively. echar is derived from the"}, {"title": "outputs of a CharLSTM layer (Lample et al., 2016).", "content": "outputs of a CharLSTM layer (Lample et al., 2016).\nLastly, eBERT constitutes the word-level embed-\ndings obtained through mean-pooling at the last\nlayer of BERT (Devlin et al., 2019), specifically by\naveraging all subword embeddings.\nThen we obtain the hidden representation and\nthe of each vectorial token representations xi via\na deep BiLSTMs (Gal and Ghahramani, 2016) en-\ncoder.\n$$ho, h1,..., hn = BiLSTMs(eo,\u20ac1,...,&n)$$\n$$C0, C1,..., Cn = BiLSTMs (eo, e1,..., en)$$\nwhere fi and b\u2081 are the forward and backward hid-\nden states of the last BiLSTM layer at position i\nrespectively, hi = [fi, bi] is the token representa-\ntion of xi, Ci = [fi, bi+1] is the boundary represen-\ntation for the ith boundary lying between xi and\nXi+1."}, {"title": "4.2 Tree Scoring", "content": "We decompose a tree t into two distinct compo-\nnents: y, representing an unlabeled skeletal tree,\nand I, signifying the corresponding sequence of la-\nbels. The process of scoring an unlabeled skeletal\ntree involves the aggregation of arcs and head-span\nscores. For each head-modifier pair h\u2192 m\u0454\u0443,\nwe score them using two MLPs followed by a Bi-\naffine layer (first-order scorer on arcs in the tree):\n$$Sh\u2192m = MLp^{head/mod} (hi)^T W [rmod; 1]$$\n$$S_{ki/j}^{left/right} = [r_{i/j}^{left/right}; 1]^T W [r_k^{head} ; 1]$$\nThe scoring of the dependency h \u2192 m with label\nle Lis calculated in a similar manner. We use two\nadditional MLPs and |L| Biaffine layers to compute\nall label scores.\nEnhancing the first-order biaffine parser for the\nunlabeled tree, we leverage adjacent-sibling infor-\nmation as mentioned in McDonald and Pereira\n(2006) and headed-span information as described\nin Yang and Tu (2022b). Additional MLPs and\nbiaffine/ triaffine layers are included to perform the\nscoring,\n$$Sh\u2192s,m^{sib} = TriAff(r_s^{sib}, r_h^{head}, r_m^{mod})$$"}, {"title": "4.3 Training Objective", "content": "During training, the objective is to maximize the\nprobability of tree Te and Th/t for each expression\ne \u2208 E. Consequently, we formulate the loss func-\ntion in the following manner:\n$$L = - log P(Te | x) P(Th/t | x)$$\nIn this equation, the term P(Te | x) and P(Th/t |\nx) are expanded as:\n$$P(T | x) = \u2211 P(y | x) \u2022 P(l | x, y)$$\n$$= \\frac{1}{Z(x)} exp(s(x, y)). P(l | x,y)$$"}, {"title": "4.4 Inside Algorithm", "content": "The calculation of the partition function Z(x) in\nEq. (10) can be resolved by the Inside algorithm\nof TreeCRF. Follow (Zhang et al., 2022), we loga-\nrithm the scores and define the labeled tree score\nas:\n$$s(x,t) = s(x, y) + log P(l | x, y)$$\nConsequently, the score represents the summation\nof the exponential scores of all legal labeled trees,\nas the logarithmic label probability of illegal trees\nis set to 0 in our conversion formulation.\nTo enumerate legal trees, we introduce con-\nstraints to the Inside Algorithm as proposed by\nEisner (1997); Li et al. (2016)\u00b2. The constraints\nare categorized into two groups, each defined by\nits specific purpose: (1) To prevent the arc h \u2192 m\nfrom crossing different spans, we apply a constraint\nto the rule (R-LINK), thereby prohibiting merging\nwith the relevant incomplete span Ih,m. (2) To pre-\nvent the presence of multiple headwords within\na single span, we restrict any word in expression\nspans e to merge solely with the completed span\nFh,i (R-COMB). Additionally, we permit a span\nto be considered complete only when i is posi-\ntioned at the endpoint of a span (R-FINISH). We\ndemonstrate the deduction rules via the parsing-as-\ndeduction framework (Pereira and Warren, 1983)\nin Appendix B, specifically in Figure 4. For addi-\ntional insights into the Eisner Algorithm, Appendix\nB provides further details."}, {"title": "5 Experiments", "content": "5.1 Datasets\nFollowing the previous work, we conduct exper-\niments on five benchmark datasets in four lan-\nguages. NoReCFine (\u00d8vrelid et al., 2020) is a multi-\ndomain professional reviews dataset in Norwegian.\nMultiBEU and MultiBCA (Barnes et al., 2018) are\nannotated hotel views in Basque and Catalan, re-\nspectively. MPQA (Wiebe et al., 2005)contains En-\nglish news and the main content of DSUnis (Toprak\net al., 2010) is online university reviews in English\nas well.\n5.2 Baselines\nWe compare our proposed method with six state-of-\nthe-art baselines. RACL-BERT (Chen and Qian,"}, {"title": "5.3 Evaluation Metrics", "content": "Following the previous work (Zhai et al., 2023), we\nuse Holder F1, Target F1 and Exp. F1 for the to-"}, {"title": "5.4 Main Results", "content": "Table 2 shows the comparison of our method\nagainst other baselines across multiple evaluation\nmetrics. In terms of the Span F1 metric, our method\ndemonstrates superior performance on all datasets,\nincluding a notable 7.2% F1 score increase in\nholder extraction on the MPQA dataset. Further-\nmore, when evaluating the Sentiment Graph metric,\ndesigned to assess both span extraction and relation\nprediction accuracy, our method consistently out-"}, {"title": "5.5 Efficiency Comparison", "content": "Table 3 presents a comparative analysis of differ-\nent models based on their processing speeds. The\nspeed metrics for previous works were derived by\nrerunning their publicly available code. Our mod-\nels, the first-order scoring only method and the\ncomprehensive scoring method, demonstrate supe-\nrior performance, processing approximately 212\nand 174 sentences per second, respectively. This\nrate significantly surpasses that of prior models.\nTGLS (Shi et al., 2022) and USSA (Zhai et al.,\n2023) employ deeper networks and engage in com-\nputationally intensive tasks, which contributes to\ntheir slower processing speeds."}, {"title": "6 Discussion", "content": "6.1 Can SSA as latent tree formulation handle\noverlap and discontinuous cases?\nSSA as a latent tree formulation effectively ad-\ndresses not only latent tree modeling but also the\nmanagement of overlap and discontinuous scenar-\nios, as highlighted by Zhai et al. (2023). We offer a\nsuccinct proof as follows: (1) Overlap Case: Our\napproach handles overlaps efficiently by treating\neach expression separately. This allows different\nexpressions to share the same target/holder without\nconflict in our framework. (2) Discontinuous Case:\nThis more complex scenario, predominantly found\nin expressions\u00b3, is also addressed in our scheme.\n6.2 Does the latent tree structure benefit for\nlong spans/tuples?\nWe address the question through results from two\nkey experiments: (1) Experiment on NoReCFine\n(Figure 3) investigates the model's performance in\nlonger spans/tuples. The Expression F1 and Tu-"}, {"title": "7 Conclusion", "content": "In this study, we approach Structured Sentiment\nAnalysis (SSA) through latent dependency graph\nparsing, conceptualizing flat sentiment spans as\nlatent subtrees. We introduce an innovative pars-\ning methodology grounded in TreeCRF, designed\nto effectively integrate span structures. Our ex-\nperimental findings demonstrate that this method\nsurpasses all previous approaches across five bench-\nmark datasets. Comprehensive analyses validate\nthe efficacy and consistency of our method in en-\nhancing SSA."}, {"title": "Acknowledgments", "content": "This work is supported by the National Natural\nScience Foundation of China (No. 62176187)."}, {"title": "Limitations", "content": "We propose a two-stage parsing method to model\nthe converted latent tree derived from the origi-\nnal SSA structure. The experiments demonstrate\nthat our method outperforms the previous meth-\nods on benchmark datasets and proves its temporal\nefficiency. However, inevitable error propagation\noccurs in our decoding stage due to the sequential\nnature of the two-stage decoding process. Another\nchallenge is that considering each expression span\nseparately to construct their corresponding trees\nincurs increased space requirements for storing in-\ntermediate results."}, {"title": "Ethics Statement", "content": "Our work on the Structured Sentiment Analysis\n(SSA) as Latent Graph Parsing Scheme adheres to\nethical guidelines emphasizing transparency, fair-\nness, and responsible AI development. We rec-\nognize the ethical implications of this work and\nhave conducted our research with a commitment\nto minimizing biases, ensuring data privacy, and\npromoting the explainability of AI decisions. Our\nevaluations utilized publicly available or ethically\nsourced datasets, and we have made efforts to ad-\ndress and mitigate potential biases within these\ndatasets to ensure fairness and objectivity in our\nfindings.\nThe broader impact of Latent Graph Parsing\nScheme, aimed at improving sentiment analysis\nfor a more complete conceptualization, has the\npotential to contribute positively to various fields,\nincluding negation resolution, uncertainty/hedge\ndetection, and event extraction. By introducing\na graph parsing method, we foster more faithful,\nflexible, and explainable sentence-level sentiment\nanalysis capabilities. We encourage the responsible\nuse of our findings and technologies, and we com-\nmit to ongoing evaluation of our work's societal\nand ethical implications."}, {"title": "4.4 Inside Algorithm", "content": "The calculation of the partition function Z(x) in\nEq. (10) can be resolved by the Inside algorithm\nof TreeCRF. Follow (Zhang et al., 2022), we loga-\nrithm the scores and define the labeled tree score\nas:\n$$s(x,t) = s(x, y) + log P(l | x, y)$$\nConsequently, the score represents the summation\nof the exponential scores of all legal labeled trees,\nas the logarithmic label probability of illegal trees\nis set to 0 in our conversion formulation.\nTo enumerate legal trees, we introduce con-\nstraints to the Inside Algorithm as proposed by\nEisner (1997); Li et al. (2016)\u00b2. The constraints\nare categorized into two groups, each defined by\nits specific purpose: (1) To prevent the arc h \u2192 m\nfrom crossing different spans, we apply a constraint\nto the rule (R-LINK), thereby prohibiting merging\nwith the relevant incomplete span Ih,m. (2) To pre-\nvent the presence of multiple headwords within\na single span, we restrict any word in expression\nspans e to merge solely with the completed span\nFh,i (R-COMB). Additionally, we permit a span\nto be considered complete only when i is posi-\ntioned at the endpoint of a span (R-FINISH). We\ndemonstrate the deduction rules via the parsing-as-\ndeduction framework (Pereira and Warren, 1983)\nin Appendix B, specifically in Figure 4. For addi-\ntional insights into the Eisner Algorithm, Appendix\nB provides further details."}]}