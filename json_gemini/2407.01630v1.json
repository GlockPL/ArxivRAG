{"title": "A survey on the impact of Al-based recommenders on human behaviours: methodologies, outcomes and future directions", "authors": ["LUCA PAPPALARDO", "EMANUELE FERRAGINA", "SALVATORE CITRARO", "GIULIANO CORNACCHIA", "MIRCO NANNI", "GIULIO ROSSETTI", "GIZEM GEZICI", "FOSCA GIANNOTTI", "MARGHERITA LALLI", "DANIELE GAMBETTA", "GIOVANNI MAURO", "VIRGINIA MORINI", "VALENTINA PANSANELLA", "DINO PEDRESCHI"], "abstract": "Recommendation systems and assistants (in short, recommenders) are ubiquitous in online platforms and influence most actions of our day-to-day lives, suggesting items or providing solutions based on users' preferences or requests. This survey analyses the impact of recommenders in four human-AI ecosystems: social media, online retail, urban mapping and generative AI ecosystems. Its scope is to systematise a fast-growing field in which terminologies employed to classify methodologies and outcomes are fragmented and unsystematic. We follow the customary steps of qualitative systematic review, gathering 144 articles from different disciplines to develop a parsimonious taxonomy of: methodologies employed (empirical, simulation, observational, controlled), outcomes observed (concentration, model collapse, diversity, echo chamber, filter bubble, inequality, polarisation, radicalisation, volume), and their level of analysis (individual, item, model, and systemic). We systematically discuss all findings of our survey substantively and methodologically, highlighting also potential avenues for future research. This survey is addressed to scholars and practitioners interested in different human-AI ecosystems, policymakers and institutional stakeholders who want to understand better the measurable outcomes of recommenders, and tech companies who wish to obtain a systematic view of the impact of their recommenders.", "sections": [{"title": "1 INTRODUCTION", "content": "Recommendation systems and assistants (from now on, recommenders) \u2013 algorithms suggesting items or providing solutions based on users' preferences or requests [99, 105, 141, 166] \u2013 influence through online platforms most actions of our day to day life. For example, recommendations on social media suggest new social connections, those on online retail platforms guide users' product choices, navigation services offer routes to desired destinations, and generative AI platforms produce content based on users' requests. Unlike other Al tools, such as medical diagnostic support systems, robotic vision systems, or autonomous driving, which assist in specific tasks or functions, recommenders are ubiquitous in online platforms, shaping our decisions and interactions instantly and profoundly. The influence recommenders exert on users' behaviour may generate long-lasting and often unintended effects on human-Al ecosystems [131], such as amplifying political radicalisation processes [82], increasing CO2 emissions in the environment [36] and amplifying inequality, biases and discriminations [120]. The interaction between humans and recommenders has been examined in various fields using different nomenclatures, research methods and datasets, often producing incongruent findings. Consequently, the current understanding of the impact of this interaction remains fragmentary and unsystematic.\nIn this survey, we analyse the impact of recommenders in four largely studied human-AI ecosystems, i.e., social media, online retail, urban mapping and generative AI ecosystems. Online platforms within these four ecosystems recommend users to follow or items to consume (social media and online retail recommenders) and provide a range of solutions to users' requests (urban mapping and generative AI recommenders). These ecosystems are characterised by a pervasive influence of AI and are prototypical instances that help investigate how recommenders influence human behaviour. Therefore, their study is a vantage point for broadly understanding user-recommender interactions.\nAlthough the attention of the literature in this regard is growing fast [27, 131, 133], the terminologies employed to define the outcomes and the methods deployed to measure them are highly fragmented. To bridge this gap, our survey provides a holistic overview of recent advances in the literature:\n(1) It categorises the methodologies employed to assess the influence of recommenders on users' behaviour (empirical, simulation, observational and controlled studies) in four prominent human-Al ecosystems (social media, online retail, urban mapping, and generative AI ecosystems) ;\n(2) It gathers the outcomes observed in the literature (collapse, concentration, diversity, echo chamber, filter bubble, inequality, polarisation, radicalisation, volume) and standardises the terminologies in a new parsimonious taxonomy;\n(3) It disentangles the level at which the outcomes are measured (individual, item, model, and systemic levels);\n(4) It suggests new avenues for future research and unveils some technical and methodological gaps in the literature from a holistic point of view.\nSeveral surveys on recommenders have been published recently, systematising domains like explainable recommendations, knowledge-based recommendations, and deep learning-based recommendations [155, 166, 167], applications of recommenders [105] and how to evaluate them [149], the impact of diversity in recommenders [91], and bias/debias in recommenders [27]. To the best of our knowledge, this is the first work that reviews recommenders' outcomes at various levels in different human-AI ecosystems, as well as the methodologies employed to assess these impacts.\nOur survey can be helpful to several public and private stakeholders. First, scholars and practitioners may obtain guidance on recent advancements in different ecosystems. Second, policymakers and institutional stakeholders may better understand measurable outcomes of actual or potential recommenders and their societal consequences, such as polarisation, congestion, segregation, etc. Third, tech companies employing recommenders may obtain a systematic view of the impact of their services to increase revenues and contribute to societal development."}, {"title": "2 CONSTRUCTION OF THE SURVEY", "content": "The remainder of the paper is organised as follows. Section 2 details how we collected and classified the articles and built our taxonomy. In Sections 3-6, we discuss the methodologies employed and the outcomes in the four human-Al ecosystems under investigation. In Section 7, we summarise our survey findings and suggest new avenues for future research."}, {"title": "2.1 Articles collection", "content": "We gathered 144 articles from different disciplines (e.g., complexity science, computational social science, computer science, marketing, management, network science, urban studies) in leading journals, conferences as well as recent unpublished material on the basis of the customary steps of qualitative systematic reviews [66]. Studies were collected from Google Scholar, Web of Science, EBSCO, and JSTOR by scanning titles and abstracts for keywords related to recommenders' outcomes in social media, online retail, urban mapping and generative AI ecosystems.\nOur original results were refined by four additional steps. First, we browsed all issues of journals where the original articles were gathered in the initial search. Second, we cross-checked the bibliography of each selected article. Third, we called upon the expertise of two senior scholars and presented the article selection in a group meeting with all authors. Fourth, we eliminated the articles that did not fit our search definition after the initial classification process (see Section 2.2). Note that we only consider articles that measure the effect of recommenders on human-Al ecosystems; therefore, we exclude those only aiming to improve recommenders' performance."}, {"title": "2.2 Classification process", "content": "We classified each article through the following process. We split the pool of authors into four teams, one for each ecosystem. Each article was assigned to two coders, who independently read the paper, evaluated its relevance for the survey, and classified it based on a preliminary taxonomy. Ecosystem teams discussed each article, solving disagreements on the coders' classification. This step allowed each team to present a preliminary classification of the articles to the entire research group. During this presentation, the ecosystem teams illustrated doubts concerning the keywords employed and the articles that were difficult to classify under the preliminary taxonomy. These doubts were progressively solved through a series of meetings to build the final taxonomy. Our outcomes and their definitions are summarised in Table 1."}, {"title": "2.3 Taxonomy", "content": "We designed a taxonomy that classifies articles based on the methodologies employed (Figure 2) and the outcomes measured with their level of analysis (Table 1). We built the taxonomy through a consensus exercise among the authors. Initially, the taxonomy was built through a deductive process based on the characteristics of a sample of articles already known by the authors. All these articles have been then reclassified by the authors to validate or question each category in the taxonomy. The iterative nature of the process allowed us to progressively improve the initial taxonomy, proposing, in the end, a robust and comprehensive framework for the analysis of recommenders' outcomes.\nHuman-AI Ecosystems. We gather articles from four human-AI ecosystems: social media, online retail, urban mapping, and generative AI ecosystems (see Figure 1). Articles in the social media ecosystem examine recommenders that filter and suggest content or users to follow. Platforms in this ecosystem include Facebook, Google News, Apple News, Instagram, X, Reddit, Gab, YouTube, and TikTok. Research in the online retail ecosystem primarily focuses on recommenders suggesting products and services for consumption, encompassing consumer goods, songs and movies. Platforms in this ecosystem include e-commerce and streaming giants like Amazon, Alibaba, eBay, Netflix, and Spotify. Studies within the urban mapping ecosystem focus on recommenders"}, {"title": "Methodologies.", "content": "We systematically categorise articles within each human-AI ecosystem into empirical and simulation studies. Within each category, we distinguish between controlled and observational studies. Empirical studies derive insights from data produced by user and recommenders' interactions. When datasets are large and diverse, these studies allow for broad generalisations. However, the ability to draw universal conclusions is constrained by specific geographic, temporal and contextual circumstances. Moreover, reproducing these studies is challenging because data are often owned by big tech companies that are generally reluctant to share them. Simulation studies are anchored to model-generated data, whether mechanistic, AI-driven, or based on digital twins. They offer an alternative methodological pathway to deal with large-scale ecosystems or when data is not readily available. These studies allow reproducibility under the same initial conditions, facilitating result validation and verification. By manipulating parameters, scholars can scrutinise recommenders' impacts on the human-Al ecosystem, improving the understanding of intricate human-recommender interactions. However, as they are based on heavy assumptions, simulations do not necessarily reflect real-world dynamics and are limited in unveiling unexpected or unintended outcomes. Simulation studies can be realised as prototypes for a preliminary feasibility evaluation of subsequent empirical and controlled studies."}, {"title": "Outcomes.", "content": "We define an outcome as the result of a recommender's influence on a human-AI ecosystem. We initially defined outcomes inductively and then refined them deductively. First, we let the team classify the outcomes using the keywords in the articles. Then, in subsequent meetings, we uniformed the categories using terms that could broadly cover these keywords. For example, popularity bias and concentration refer to a similar kind of outcome. We opt for concentration because it fits different ecosystems. We also extend the term concentration to describe situations with consensus around an attribute (e.g., opinions in social media ecosystems). This parsimonious classification is a crucial contribution of this paper because it allows for the standardisation of outcomes terminology across different fields of study.\nIn the literature, outcomes are measured at different levels: individual, item, model, and systemic. Individual outcomes refer to the effects of recommenders on users. Users may be drivers and passengers in the urban mapping ecosystem and sellers and buyers in the online retail ecosystem. Item outcomes refer to the effects of"}, {"title": "3 SOCIAL MEDIA ECOSYSTEM", "content": "What the ecosystem is about. The social media ecosystem includes social networking platforms, community and non-community content systems that promote content creation and sharing, and interaction among users. Social networking platforms include Facebook, Instagram, TikTok, and X (previously, Twitter). Community content platforms encourage users to join interest-based communities (e.g., Reddit and Gab) or engage in video consumption (e.g., YouTube). Non-community content platforms, like Google News or Apple News, diffuse their own content.\nMain methodologies employed. There is a marked preference for observational studies (see Figure 4). This is because empirical research can also be conducted by researchers external to the platform via data sharing or APIs. Moreover, synthetic data may be easily gathered from agent-based and opinion dynamics models, allowing a successive analysis. Typically, empirical observational studies in this ecosystem exploit bots to simulate user behaviours (sock-puppet studies), collect information about the provided recommendations, or perform user surveys. Simulation observational studies are primarily based on agent-based modelling, with a minority of works focusing on a single user. Only a few empirical studies are controlled (see Figure 4), and this is because they require direct access to users' data to build control and treatment groups and to enable/disable recommenders'"}, {"title": "3.1 Empirical studies", "content": "Observational studies. Ribeiro et al. [139] audit radicalisation pathways on YouTube's video and channel recommendations. By analysing users' migration patterns across 330k videos from 349 politically related channels, the study finds a recommendation flow from milder to more extreme (alt-right) content. Radicalization\nBrown et al. [25] likewise explore whether YouTube's algorithm pushes users into filter bubbles and echo chambers or displays biases towards some political content. Through analysing videos' political orientation and surveying 527 users who navigate the platform according to randomly assigned rules, the study finds minimal evidence of filter bubbles and echo chambers. However, it identifies a platform bias leading to a stronger amplification of moderately conservative content. Radicalization Filter Bubble Echo Chamber Diversity.Individual\nVolume.Item\nSimilarly, Santini et al. [145] focus on Brazilian elections to examine YouTube's promotion of hyperpartisan content. They use a non-probabilistic sampling technique and analyse the news sources recommended on the platform by simulating the browsing behaviour of new users. The findings highlight an increase in inequality with preferential treatment for right-wing media outlets over similar content from left-wing media outlets. Inequality\nVolume.Item\nHaroon et al. [72] investigate YouTube's recommender tendency to generate filter bubbles, radicalisation pathways, and extremist or problematic content recommendations. They rely on a sock-puppet audit using 100k accounts designed to represent various political leanings. The study discovers a filter bubble effect, particularly pronounced for right-leaning users. It also finds an increase in recommendations from channels linked to extremist or conspiratorial content, particularly for users characterised by views of extreme right-wing content.\nFilter Bubble Diversity.Individual Volume.Item Radicalization\nHosseinmardi et al. [79] investigate the role of users' preferences on received recommendations. They retrieve browsing histories of 310k users and profile these users based on viewing habits. The researchers then analyse on-vs. off-platform consumption habits of users, pathways to radical political content, and the effect of session length on content type exposure. In contrast with previous research, this study finds little evidence of the amplification of political content and radicalisation pathways. Radicalization\nLedwich and Zaitsev [94] examine the role that YouTube's recommender plays in encouraging online radicalisation. By examining the recommendation patterns among 800 political channels, the research finds that rather than promoting radical or extremist content, the algorithm amplifies views for mainstream media and politically neutral content. Radicalization Inequality Concentration Volume.Item\nHeuer et al. [76] investigate the biases behind YouTube's video recommender. The study selects nine relevant political topics in Germany and performs a sock-puppet audit based on random walks to select video recommendations. The findings support the disparities highlighted by Ledwich and Zaitsev [94], showing that YouTube increases recommendations for popular and mainstream content rather than radical and extreme ones, but these recommendations do not focus on a particular topic. The study also finds an emotional shift effect in recommendation trails: videos perceived by users as sad and negative are increasingly replaced by videos conveying happier content. Filter Bubble Inequality Concentration Volume.Item\nIbrahim et al. [83] focus on YouTube's recommender propensity to create political filter bubbles. The study collects video recommendations via a sock-puppet audit with 360 bots that represent six personas across the US political spectrum. The findings show that the recommender steers users away from political extremes toward more moderate content. This effect is more pronounced for far-right than for far-left content. Radicalization\nVolume.Individual\nCho et al. [33] investigate the impact of YouTube's personalised recommender on political polarisation. The researchers conduct a laboratory experiment with 108 undergraduate students, where they manipulate the participants' search and watch histories related to the 2016 US presidential election. The findings indicate that algorithmic recommendations contribute to the creation of a filter bubble, reinforcing individuals' existing political beliefs. Filter Bubble Polarization Diversity.Individual\nHosseinmardi et al. [80] estimate the causal impact of YouTube recommendations on the consumption of highly partisan and radical content. The study compares the behaviours of bots designed to mimic real users' viewing patterns with those of bots following predefined rule-based trajectories. The findings show that the recommender does not steer users towards radical content. On the contrary, when users with strong political views start watching moderate content, the recommender shifts their recommendations after approximately 30 videos, assisting users in breaking out of their filter bubbles. Radicalization Filter Bubble\nLe Merrer et al. [93] examine the impact of YouTube's personalised recommendations on generating filter bubbles and rabbit holes. The researchers conduct a sock-puppet audit to gather video recommendations and propose a straightforward theoretical model explaining why and how rabbit holes form on YouTube. The results indicate that user interactions could influence recommendations, but users are not consistently led further into specialised content. In fact, after a certain number of interactions, YouTube's recommender may forget previous user preferences, breaking down users' filter bubbles. Filter Bubble\nZhou et al. [169] investigate the impact of various YouTube features on video views, with a focus on the recommender's effectiveness in driving video popularity. By analysing metadata, related video lists, and view statistics for hundreds of thousands of videos, the study finds that recommendations increase video views and promote a wider variety of videos rather than just promoting the most popular ones. Volume.Item Diversity.Item\nKirdemir et al. [87] inspects YouTube's recommendation biases across different topics, languages, and entry points. The study analyses the structure of video recommendation networks through PageRank distributions, covering 257k videos and 803k recommendations. Despite variations based on factors like video language, content topic, and the source of seed videos, all experiments reveal an increase in recommendations for a small fraction of videos, fostering inequalities and a \"richer get richer\" effect. Volume.Item Concentration Inequality\nYang et al. [162] explore the dynamics of personalised search on Twitter using a sock-puppet audit. The findings indicate that factors such as following behaviour, cookies, and previous searches have a limited impact on personalisation. However, when it comes to polarised searches, the results reveal a noticeable bias toward one-sided views, raising concerns about filter bubbles. Filter Bubble Polarization Diversity.Individual\nUsing a similar sock-puppet audit methodology, Chen et al. [30] evaluate the impact of Twitter's content curation mechanism on the creation of political filter bubbles. The study finds that although the political alignment of a bot's initial connections influences its exposure to political content, there is weak evidence to support the presence of inherent political bias in the recommender. Filter Bubble Diversity.Individual\nSu et al. [153] examine the impact of Twitter's \"Who-To-Follow\u201d recommender, comparing the social networks collected before and after the recommender was implemented. The findings reveal that there is a concentration of \u201cfollow\u201d recommendations for the most influential users, leading to a rich-get-richer phenomenon. The study also identifies a feedback loop where recommendations for popular users often result in more followers, exacerbating existing network inequalities. Inequality Concentration Volume.Item\nBouchaud [22] explore how Twitter's engagement-maximising recommender affects the visibility of tweets by Members of Parliament in users' timelines. The researchers use tunable engagement predictive models to simulate users' timelines and a Twitter dataset collected via a browser add-on installed by volunteers. The findings show that engagement-based timelines display lower ideological diversity, leading to the creation of a political filter bubble. Additionally, the study uncovers inequalities in reach among political groups, with right-wing parties being prioritised over left-wing ones. Filter Bubble Diversity.Individual Volume.Item\nBakshy et al. [14] explores the impact of Facebook's recommender on the formation of filter bubbles and echo chambers. The researchers examine the news consumption patterns of 10 million users in the US, focusing on how their political beliefs align with the content they encountered in their news feeds and through their connections with friends. The study finds that individual choices have a more significant impact than Face-book's recommender in limiting exposure to diverse political news. Additionally, the researchers emphasise"}, {"title": "3.2 Simulation studies", "content": "Observational studies. S\u00eerbu et al. [150] examine the impact of biasing interactions towards like-minded individuals in synthetic social networks. The researchers introduce a recommender parameter that influences the probability of interacting with users who hold similar opinions. By simulating opinion evolution on a fully connected network under bounded confidence, the study reveals that stronger semantic bias in the recommender leads to increased opinion polarisation. Polarization\nPansanella et al. [128] builds upon S\u00eerbu et al.'s research by exploring various network topologies, including random, scale-free, and clustered networks. The study reveals that opinion polarisation persists across different network topologies. Additionally, introducing a certain degree of sparsity in the network amplifies the divisive impact of recommenders on the distribution of opinions within the population. Furthermore, the researchers indicate that the presence of homophilic communities, combined with cognitive biases, leads to the formation of echo chambers. In an expanded version of this model, Pansanella et al. [129] explore the impact of adaptive topologies, which allow connections to be changed from conflicting agents to those with similar views. The study finds that recommenders may intensify polarisation and hinder the formation of echo chambers. This is due to the homophilic rewiring process and the evolution of opinions. Polarization Echo Chamber\nBuilding on a different opinion evolution model, Valensise et al. [159] simulate social network sessions exposed to a feed algorithm that adjusts the range of opinions viewed by users. The simulation accounts for bounded confidence and adaptive topologies. The study finds that a strong filtering algorithm increases polarisation, while milder personalisation is necessary for echo chamber formation. Polarization Echo Chamber\nChitra and Musco [32] explore the impact of recommenders on social network polarisation using an opinion dynamics model. A recommender encourages connections among users with similar viewpoints, thus creating a similarity bias. The findings show that a greater bias results in increased polarisation and the creation of echo chambers within clustered networks. Polarization Echo Chamber\nPerra and Rocha [137] examine the impact of different network topologies and timeline filtering strategies, such as random, chronological, reverse chronological, semantic ordering, and nudging. The researchers represent users' opinions as binary variables, simulating a two-party system, and find that algorithmic filtering exacerbates initial inequalities and reduces the visibility of minority opinions. The study also highlights that semantic or temporal biases in highly clustered networks lead to opinion polarisation and the formation of echo chambers. Additionally, combining semantic filtering and nudging in networks with spatial correlations impedes convergence, reinforcing echo chambers that resist nudged opinions. Polarization Echo Chamber Inequality Concentration\nDiversity.System Volume.Individual\nPeralta et al. [135] investigate the interactions between semantic filtering and network topology. Semantic filtering is adjusted using a bias parameter that hides a portion of the population from the agent. The stronger the bias, the more contrasting opinions are hidden. The study employs mathematical analyses and simulations of"}, {"title": "4 ONLINE RETAIL ECOSYSTEM", "content": "What the ecosystem is about. The online retail ecosystem includes platforms that allow customers to buy products or services, e.g., Amazon, eBay or Alibaba for products, Netflix or Spotify for movie and music streaming, respectively. This ecosystem appears more heterogeneous than the others and includes studies from various disciplines (e.g., computer science, marketing, management and economics).\nMain methodologies employed. Overall, empirical studies outweigh the simulations. This is mainly because platforms have a strong interest in maximising revenues, and therefore, understanding the impact of recom-menders in real situations is crucial. Most empirical studies analyse users' activity on e-commerce platforms, while simulation studies tend to build models of user tastes based on ad-hoc assumptions or data gathered from platforms. Typically, they also compare content-based recommenders and collaborative filtering. Among empirical studies, there is a prevalence of controlled over observational studies (see Figure 4), as it is easier than in other"}, {"title": "4.1 Empirical studies", "content": "Observational studies. Dias et al. [44] examine the impact of LeShop's recommender on sales over 21 months. The study finds that the amount of money shoppers spend on recommended items increases over time. This leads to accrued sales at the item level and the growth of direct revenues. Additionally, the study finds an increase in indirect revenues, i.e., those related to purchases of items recommended in previous sessions and purchases of non-recommended items from previously recommender categories. Volume.Item\nNguyen et al. [124] explore the impact of item-item collaborative filtering on MovieLens users. The findings reveal an overall diversity decrease in the movies viewed and purchased. However, this effect is less pronounced for users who follow recommendations, as they tend to consume a wider variety of movies compared to those who\nignore recommendations. Additionally, the recommendation-following users actively seek out diverse movies, which helps reduce the risk of creating filter bubbles. These users also tend to give more positive ratings to the recommended items. Diversity.Individual Filter Bubble Volume.Individual\nGe et al. [63] analyse clicking and purchasing behaviours using real-world data consisting of user clicks, purchases and browse logs from Alibaba Taobao. To measure the impact of recommenders on users, the researchers follow the strategy proposed by Nguyen et al. [124] and separate all users into \"following\" and \"ignoring\u201d groups. The study shows that personalised recommendations reinforce cluster formation in click-behaviors (echo chambers), i.e., there is a strengthening trend over time for the \"following\" group of users. Moreover, the set of suggested products is less diverse for the \"following\" group in comparison to the \"ignoring\" group. This is because personalised recommendations shrink the scope of the offered content, and therefore, the gap further enlarges over time. Echo Chamber Diversity.Individual\nAnderson et al. [9] investigate how Spotify's recommender impacts the diversity of streaming content users listen to. The researchers split user streaming behaviour into two categories: user-driven listening, where users actively seek out specific music or listen to playlists created by other users, and algorithm-driven listening, where users listen to algorithmically personalised playlists (e.g., Discover Weekly) or radio stations generated by Spotify's algorithm. The study finds that personalised recommendations lead to greater diversity in streaming at the individual level, with user-driven listening showing more diversity than algorithm-driven listening. Furthermore, users who listen to a diverse range of songs are significantly less likely to leave the platform and more likely to become paying subscribers. Diversity.Individual\nChen et al. [28] analyse a dataset sourced from Amazon to examine the effects of recommendations and consumer feedback on sales. The findings indicate that more recommendations are associated with high sales volume, but consumer ratings do not have a significant impact on sales. However, the number of consumer reviews positively correlates with sales volume. The study also finds that recommendations lead to increased diversity at the systemic level, indicating that they are more effective for less-popular books than for popular ones. Diversity.Systemic Volume.Item\nPathak et al. [130] analyse a dataset from Amazon and Barnes & Noble to explore how the strength of recommendations (i.e., the number of books pointing to a particular book and their popularity) impacts book sales and prices. The study finds that stronger recommendations lead to increased sales volume and higher prices. Additionally, the recommender may contribute to increased diversity in book sales, a phenomenon referred to in the paper as a long-tail effect. Diversity.Systemic Volume.Item\nFleder et al. [58] analyse consumer behaviour in time in an online music store. The store uses a free software add-on to Apple's iTunes to provide personalised recommendations to registered users through a combination of content- and user-based collaborative filtering. To account for potential confounding factors, the researchers employ propensity score matching to match registered and registered users. The findings show that recommenda-tions lead to an increase in commonality among consumers. This occurs because individual consumers purchase a greater volume of songs and a more similar mix of products after receiving the recommendations. Concentration\nVolume.Individual\nHosanagar et al. [78] employ the same research design and reveal that personalised recommendations have two main effects. On an individual level, personalised recommendations increase sales volume, making it more likely for users to purchase the same songs. At a systemic level, there is a concentration of purchases as consumers tend to buy a more similar mix of products after receiving the recommendations. Concentration Volume.Individual"}, {"title": "4.2 Simulation studies", "content": "Observational studies. Noordeh et al. [125] measure the impact of collaborative filtering on content consumption on MovieLens. The study reveals that prolonged exposure to recommendations decreases content diversity and fosters the emergence of filter bubbles. Furthermore, once a filter bubble is established, it becomes challenging for users to break out of it. Diversity.Individual Filter Bubble\nHazrati and Ricci [74] employ log data from three Amazon services (Kindle, Games, and Apps) to analyse the effects of recommendations on the evolution of users' choices over time. The simulation combines a choice model with five recommenders. Three recommenders offer personalised recommendations: popularity-based collabo-rative filtering, low popularity-based collaborative filtering (penalising the score with the inverse popularity), and factor model (mapping users and items into a common latent factor space). Additionally, the study includes two non-personalised recommenders, namely popularity-based and average rating, as well as a baseline case with no recommendations. The study finds that personalised recommendations lead to a greater increase in sales diversity compared to non-personalised recommendations, both at the item and systemic levels. Furthermore, at the systemic level, the low popularity-based collaborative filtering and the factor model increase sales diversity for the Kindle dataset. However, for the Games dataset, only the low popularity-based collaborative filtering increased sales diversity compared to the baseline case. Diversity.Item Diversity.Systemic\nMansoury et al. [111] design a method for simulating the feedback loop of user-recommender interactions by analysing the progressive effects of three different recommenders: user-based collaborative filtering, Bayesian personalised ranking, and a recommender suggesting the most popular items. The findings reveal that all recommenders lead to a progressive reduction in diversity and increased concentration. This effect is particularly pronounced for users who are underrepresented in the training dataset (e.g., female users). Concentration\nDiversity.Systemic\nWu et al. [161] compare various recommenders trained on MovieLens data, specifically a user-based collabora-tive filtering, a content-based recommender and a baseline condition with no recommendations. The findings reveal that the content-based recommender decreases sales concentration, whereas user-based collaborative filtering increases it. Moreover, the impact of these effects depends on how well the recommendations align with consumer awareness. For instance, suggesting popular products to consumers already aware of them has little impact. Recommending niche products could significantly influence consumer behaviour. Concentration\nAridor et al. [10] design a model in which products have both intrinsic and user-specific values. In this model, users (unaware of item values) make choices on the basis of their beliefs and risk aversion. This baseline condition is compared to one where users are exposed to recommendations that allow them to combine their value with the intrinsic value of items. The study shows that the more users become risk-averse, the more they consume items"}, {"title": "5 URBAN MAPPING ECOSYSTEM", "content": "What the ecosystem is about. The urban mapping ecosystem encompasses a variety of recommenders designed to satisfy the needs of city dwellers. It includes navigation platforms suggesting travel routes (e.g. Google Maps or TomTom); house-renting services helping users find accommodation (e.g., Airbnb, Booking.com); e-mobility platforms providing users with taxi, ride-hailing or car-pooling services (e.g., Uber and Lyft); and platforms suggesting point-of-interest to users (e.g., Tripadvisor and Yelp).\nMain employed methodologies. There is a predominance of simulation over empirical studies (see Figure 4), mainly because data are typically owned by big-tech companies that are reluctant to share them. For what concerns navigation and e-mobility platforms, empirical controlled studies are difficult to perform. This is because it is unlikely to avoid interactions between users in the control and treatment groups and other vehicles travelling on the streets. This would mean a violation of the Stable Unit Treatment Value Assumption for causal inference [39]. Moreover, several exogenous factors (e.g., sudden storms, strikes, accidents) may potentially bias the effect of the recommender at any time. These factors complicate the attribution of the observed outcomes to the recommender. Scholars tend to choose simulation-controlled studies to mitigate these issues.\nMain outcomes. Most studies focus on the systemic level, investigating inequality, diversity, and traffic congestion (extreme urban concentration). Most studies are concerned with volume at all levels of analysis, assessing the impact of recommenders on various quantities (e.g., CO2 emissions, travel time, and cost for users in ride-hailing and car-sharing platforms). See Table 4 for a comprehensive outlook."}, {"title": "5.1 Empirical studies", "content": "Observational studies. Falek et al. [55] perform a comparative analysis of various routing algorithms, finding that a strategy without re-routing (the route is established before vehicle departure based on actual travel times) consistently yields travel times that closely approach the best possible solution. In contrast, a strategy based on continuous re-routing (the route is adjusted while the vehicle is travelling based on actual travel times) is the best algorithm for congested areas. Concentration"}, {"title": "5.2 Simulation studies", "content": "Observational studies. Johnson et al. [86] investigate the impact on urban traffic of three routing criteria: scenic routing optimises routes for aesthetic enjoyment; safety routing avoids areas with higher rates of accidents or crime; and simplicity routing, where route complexity is reduced on the basis of the number of intersections and actions needed to traverse it (i.e., going straight or turning). Simulations in San Francisco, New York City, London, and Manila show that scenic routing leads to more complex routes, potentially increasing the risk of accidents and negatively affecting driver safety. Additionally, it diverts traffic from highways to parks, popular areas, tourist destinations, and slower roads. Safety routing, though to a lesser degree than scenic routing, also generates more complex routes and redirects traffic away from identified unsafe zones. Simplicity routing amplifies traffic on highways but does not explicitly favour or avoid any particular region. Concentration Inequality\nMehrvarz et al. [121] compare the impact of vehicle routing incorporating sustainability variables (e.g., fuel consumption, engine load, acceleration rate, speed, road slope) with traditional routing that prioritises travel time or distance. The study finds that fastest routes are not necessarily the most sustainable and that sustainable routing might reduce fuel consumption by about 5%. Volume.Systemic\nBarth et al. [15] introduce a method for reducing energy consumption and emissions in navigation services. The method combines mobile-source energy and emission models with advanced route optimisation algorithms. The study applies this method in several case studies across Southern California, showing substantial energy savings and reduced emissions compared to navigation services that minimise distance or travel time. Volume.Systemic\nColak et al. [35] introduce a centralised strategy that optimises route choices to alleviate urban congestion while considering varying levels of social good awareness. The study shows that routing solutions mimicking"}, {"title": "6 GENERATIVE AI ECOSYSTEM", "content": "What the ecosystem is about. The generative AI ecosystem includes studies that analyse the impacts of the recent spread of conversational and generative AI models in society. In particular, research in this field focuses on"}, {"title": "6.1 Simulation studies", "content": "Observational studies. Palma et al. [127] evaluate ChatGPT's ability to provide helpful recommendations based on users' requests. They compare ChatGPT with other large language models (GPT3.5 and PaLM-2) and standard recommenders (collaborative filtering and content-based filtering recommenders) using three datasets (MovieLens Small, Last.FM, and Facebook Book). The study finds that ChatGPT provides more accurate music and book recommendations than other language models, while PaLM-2 performs better in movie recommendations. Overall, the research concludes that LLM's recommendations have a similar accuracy to standard recommenders."}, {"title": 7, "AVENUES": "content\": \"This conclusive section has three objectives. The first is to summarise the key findings that emerged from our survey at the methodological and outcome levels. The second is to highlight what is missing and envisageable for future research on human-recommender interaction. The third goes beyond offering broader suggestions to rethinking the field of human-AI coevolution technically and methodologically."}, {"title": "7.1 What we learned", "content": "Methodologies. Our survey endeavour reveals two important differences across the human-Al ecosystems explored. First, the use of empirical data characterises most studies within the social media and online retail ecosystems. On the opposite, simulations prevail within the urban mapping and generative AI ecosystems. The main reason for this difference is the availability of data describing human choices. Indeed, social media platforms typically provide APIs that enable scholars to download relevant information regarding users' choices. This contributed to the construction of many datasets employed for empirical analysis. For the online retail ecosystem, studies are often conducted within companies or in collaboration with them, facilitating the usage of empirical data. In contrast, platforms in the urban mapping ecosystem are typically reluctant to share their data, and APIs do not provide enough information due to privacy reasons. In the generative AI ecosystem, there is a paucity of empirical studies because prompts and corresponding content generated are currently not made available to external researchers, and commercial platforms are too recent.\nSecond, observational studies prevail in all ecosystems. However, the online retail ecosystem displays the largest share of controlled studies. This is due to economic and technical reasons. On the one hand, there is a strong incentive to maximise revenues, which requires a causal understanding of recommenders' influence on users. On the other, it is easy to create control and treatment groups such that interactions among the two groups are weak and manageable. In the social media ecosystem, companies sometimes perform controlled studies but are reluctant to share the results. A notable example is the Facebook files, a leak of reports describing controlled"}, {"title": "7.2 What we do not know", "content": "Methodology. With the exception of the online retail ecosystem, there is a scarcity of empirical controlled studies. This is because there can be strong interactions between users (e.g., urban mapping); access to data and the possibility to manipulate recommendations on real platforms are limited (social media); and online platforms are too recent (generative AI). Despite often violating the Stable Unit Treatment Value Assumption for causal inference [39], controlled studies are considered the gold standard to test the effects of recommenders on users' choices as they intervene in platform users' experiences. A thorough understanding of the impact of recommenders requires the realisation of more controlled studies in social media, urban mapping, and generative Al ecosystems.\nOutcomes. A comprehensive understanding of human-recommender interaction also requires additional research on under-investigated outcomes. For example, model collapse is only studied within the generative AI ecosystem. However, it is unclear how recommenders evolve in the other ecosystems. This evolution may be studied both structurally (e.g., how the set of model weights change in time) or behaviorally (e.g., how the model behaviour changes). Is continual re-training causing recommenders to systematically avoid certain items (e.g., users, roads)? At what rate do recommenders reduce the diversity of recommended content? In other words, while existing studies focus on the effect that recommenders have on users' choices, we need more research in the opposite direction \u2013 i.e., the effect that users' choices have on the structure and behaviour of recommenders. More research on inequality is also needed in the online retail ecosystem. Many studies showed a decrease in systemic diversity, but this has not been linked to the inequality of visibility of brands, products, and product categories. To what extent do recommenders promote popular brands and products while making others even"}, {"title": "7.3 Going beyond: avenues for research from a holistic perspective", "content": "Our systematic review of recommenders' outcomes in four human-Al ecosystems unveils several technical and methodological gaps in the literature from the holistic point of view of human-AI coevolution [132].\nTechnical perspective. Since recommenders are based on AI, and machine learning in particular, their interactions with users always give rise to a feedback loop [132]: users' choices determine the datasets on which recommenders are trained; the trained recommenders then exert an influence on users' subsequent choices, which in turn affect the next round of training, initiating a potentially never-ending cycle. Understanding human-AI coevolution [132] requires a holistic approach, where the reciprocal impact of humans and recommenders is studied in both directions. Despite notable attempts [49, 85, 112, 124, 154], we lack a comprehensive understanding of feedback loop mechanisms, how they influence ecosystems in the long run, and how to manage them. We have to measure the feedback loop's impact continuously, tracking step-wise how the measured outcomes change every time the recommender is re-trained.\nAnother avenue of future research regards the standardisation of datasets and analytical and simulation frameworks. This is because results measuring outcomes of human-AI interactions are often contradictory due to different datasets and methodologies employed. Constructing standard datasets and making them public may be achieved only by solving critical legal challenges [88]. One way might be allowing vetted researchers to access online platforms, conduct controlled studies, and collect empirical data. Initiatives like the EU's Digital Services Act are going towards this direction; however, it remains unclear how vetted researchers will be allowed to access privately owned platforms.\nMethodological perspective. We could develop new types of studies that combine observational and con-trolled approaches (quasi-controlled studies) as well as empirical and simulation ones (quasi-simulations). For example, quasi-simulations could use real data or real recommenders within a simulation framework. The recom-menders may be trained on data from real platforms to capture the actual recommender's functioning. Then, simulations may be employed using these recommenders to mimic user behaviour on the platform.\nAnother crucial point regards the development of next-generation controlled studies. In human-Al ecosystems, preventing interactions between users in the control and treatment groups is difficult. This situation violates"}]}