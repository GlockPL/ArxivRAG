{"title": "FedAH: Aggregated Head for Personalized Federated Learning", "authors": ["Pengzhan Zhou", "Yuepeng He", "Yijun Zhai", "Kaixin Gao", "Chao Chen", "Zhida Qin", "Chong Zhang", "Songtao Guo"], "abstract": "Recently, Federated Learning (FL) has gained popularity for its privacy-preserving and collaborative learning capabilities. Personalized Federated Learning (PFL), building upon FL, aims to address the issue of statistical heterogeneity and achieve personalization. Personalized-head-based PFL is a common and effective PFL method that splits the model into a feature extractor and a head, where the feature extractor is collaboratively trained and shared, while the head is locally trained and not shared. However, retaining the head locally, although achieving personalization, prevents the model from learning global knowledge in the head, thus affecting the performance of the personalized model. To solve this problem, we propose a novel PFL method called Federated Learning with Aggregated Head (FedAH), which initializes the head with an Aggregated Head at each iteration. The key feature of FedAH is to perform element-level aggregation between the local model head and the global model head to introduce global information from the global model head. To evaluate the effectiveness of FedAH, we conduct extensive experiments on five benchmark datasets in the fields of computer vision and natural language processing. FedAH outperforms ten state-of-the-art FL methods in terms of test accuracy by 2.87%. Additionally, FedAH maintains its advantage even in scenarios where some clients drop out unexpectedly. Our code is open-accessed at https://github.com/heyuepeng/FedAH.", "sections": [{"title": "I. INTRODUCTION", "content": "The traditional centralized training approach in machine learning is facing significant challenges due to the increasing importance of user data privacy [1]\u2013[3]. On the other hand, it is difficult to achieve well-performing models on individual clients due to the sparsity of data on each client [4]\u2013[6]. Federated Learning (FL), as a popular distributed machine learning paradigm, offers excellent privacy protection and collaborative learning capabilities [7]. The learning tasks in FL are coordinated by a server and solved collaboratively by a network of multiple participating devices (clients). FedAvg [8] is the original FL method and serves as the fundamental framework for subsequent FL methods. Its iterative process can be described in five steps: (1) The server randomly selects a subset of clients to join FL and distributes the same global model to them for initialization; (2) Clients overwrite their local model parameters with the parameters of the downloaded global model to acquire global knowledge; (3) Clients train their local models on their private local data; (4) Clients upload their trained local models to the server; (5) The server receives the local models from clients and performs weighted averaging on the model parameters to obtain a new global model. FedAvg aims to learn a single global model that performs well across all clients. However, this approach often suffers in statistically heterogeneous environments, such as when facing not independent and identically distributed (Non- IID) and unbalanced data [5], [9], leading to degraded model performance [4], [10], [11].\nPersonalized Federated Learning (PFL) has been proposed to address statistical heterogeneity and achieve personalization in FL [6]. PFL focuses on learning personalized models rather than a single global model [11]. For each client participating in FL, the global model distributed by the server contains global information, which can enhance the local model and address the data scarcity issue of clients. Most existing PFL methods use the global model as a container for global information and exploit global/personalized information by leveraging the parameters of the global/local models [3]. Specifically, meta- learning-based PFL methods (such as Per-FedAvg [12] and FedMeta [13]) adapt the global model parameters to het- erogeneous client data through fine-tuning. Regularization- based PFL methods (such as FedProx [5], pFedMe [11], and Ditto [14]) regularize the model parameters during local training. Personalized-aggregation-based PFL methods (such as FedFomo [15], APPLE [16], FedAMP [10], and FedALA [17]) achieve better local initialization by aggregating the models of other clients or combining global and local models. Personalized-head-based PFL methods (such as FedPer [18] and FedRep [19]) split the model into a global part (feature extractor) and a personalized part (head), with the feature extractor trained collaboratively and shared among clients, while the head is trained locally and not shared. This approach aims to utilize both global and personalized information in the model parameters. However, training the head only with local data can result in the loss of some global information in the head, negatively impacting the performance of the personalized model."}, {"title": "RELATED WORK", "content": "To address the issue of losing global information in the personalized head of personalized-head-based PFL methods, we propose a novel PFL method, Federated Learning with Aggregated Head (FedAH). As shown in Figure 1, FedAH combines the ideas of personalized-aggregation-based PFL by aggregating the local model head from the previous iteration and the global model head from the current iteration at the element level to obtain an Aggregated Head, thereby integrating global information into the global model head. Apart from using the Aggregated Head as the initialization head for a new iteration, the rest of the processes are motivated by FedRep, and the aggregation weights of the Aggregated Head are learned through gradient descent. By combining the aforementioned strategies, FedAH can achieve personalization while more comprehensively benefiting from global knowl- edge, thereby improving the performance of personalized models.\nTo evaluate the effectiveness of FedAH, we conduct ex- tensive experiments in two widely adopted scenarios [8], [20] (i.e., the pathological and practical heterogeneous settings) and five benchmark datasets. The experimental results demonstrate that FedAH outperforms ten state-of-the-art (SOTA) FL meth- ods. In summary, our contributions are mainly three-fold:\n\u2022 To the best of our knowledge, we are the first to con- sider introducing global information through personalized aggregation in the model head. This approach is more fine-grained and effective compared to most existing personalized-aggregation-based PFL and personalized- head-based PFL methods.\n\u2022 We propose a novel PFL method, named FedAH, which, based on personalized-head-based PFL methods, per- forms element-wise aggregation between the local model head and the global model head to obtain an Aggregated Head, ensuring that global information is not lost in the personalized part of the model.\nWe conduct extensive experiments in the fields of com- puter vision (CV) and natural language processing (NLP) under two widely used scenarios. The results validate that our proposed FedAH outperforms SOTA FL methods in terms of effectiveness, scalability, and stability."}, {"title": "A. Personalized Federated Learning", "content": "Traditional Federated Learning (FL) methods perform dis- tributed machine learning through iterative communication and computation between a server and multiple clients [7]. Due to the statistical heterogeneity problem in FL, a single global model often struggles to adapt well to different clients [4], [10], [11]. Unlike traditional FL, Personalized Federated Learning (PFL) not only learns a global model on the server but also learns personalized models (or modules) on the clients, which has garnered significant attention for addressing the statistical heterogeneity issue in FL [4]. In this paper, we categorize PFL methods into the following four types:\n(1) Meta-learning-based PFL: Per-FedAvg [12] and Fed- Meta [13] combine meta-learning frameworks, leveraging the average aggregation trend of model updates to learn a global model, and obtaining personalized models by locally fine-tuning the global model on each client. However, this strategy makes it challenging for Per-FedAvg and FedMeta to find a consistent learning trend through averaging in statistically heterogeneous scenarios [7].\n(2) Regularization-based PFL: FedProx [5] regularizes the difference between local model parameters and global model parameters during local model training on clients, while pFedMe [11] and Ditto [14] learn additional personalized models for each client and use proximal terms for the per- sonalized models. Nevertheless, FedProx still learns a single global model, while pFedMe and Ditto require more memory and computational resources to store and train additional personalized models.\n(3) Personalized-aggregation-based PFL: FedFomo [15] and APPLE [16] initialize local models by aggregating models of other clients locally on each client. FedAMP [10] generates aggregated models for individual clients through an attention- inducing function and personalized aggregation. FedALA [17] adaptively aggregates global and local models based on the local data of each client, achieving finer-grained element- level model aggregation to initialize local models before each training iteration. However, FedALA still has room for improvement as it does not split the model into a feature extractor and a head, FedFomo and APPLE require more communication overhead, and the model-level personalized aggregation of FedAMP is not precise enough.\n(4) Personalized-head-based PFL: FedPer [18] and FedRep [19] learn a global feature extractor and a client-specific head, with the former training the head locally using the feature extractor and the latter locally fine-tuning the head before each training iteration of the feature extractor. However, the lack of head sharing in FedPer and FedRep leads to the loss of general information in the head, which affects the final performance of the personalized model.\nOur proposed FedAH combines strategies from the third and fourth categories. Similar to FedRep, it splits the given backbone into a global feature extractor and client-specific heads, fine-tuning the heads before each training iteration of the feature extractor. Unlike FedRep, it fine-tunes the Aggregated Head, which is the element-wise aggregation of the local model head and the global model head, instead of the local model head from the previous iteration. The Aggregated Head adopts the personalized aggregation strategy of the third category, improving model performance by learning general information while achieving personalization."}, {"title": "III. METHODOLOGY", "content": "In this section, we first provide an overview of the local learning process of FedAH, then state the objectives of FL optimization, and finally perform a theoretical derivation of FedAH."}, {"title": "A. Overview of FedAH on the client", "content": "Figure 2 illustrates the local learning process of the pro- posed FedAH method on the client, which can be divided into four steps: (1) The client splits the global model downloaded from the server into a global feature extractor and a global head, and trains the aggregation weights for the head by freezing the global head and the local head from the previous iteration. (2) The client uses the new aggregation weights to perform element-wise aggregation of the global head and the local head from the previous iteration to obtain the Aggregated Head. (3) The client freezes the global feature extractor parameters and trains the Aggregated Head to get the local head for the current iteration. (4) The client freezes the local head parameters and trains the feature extractor parameters. Finally, the client obtains the trained local model and uploads it to the server, concluding the local learning process."}, {"title": "B. Problem Statement", "content": "In the process of FL under statistically heterogeneous settings, suppose there are N clients, each with its own Non-IID and unbalanced dataset $D_1,..., D_N$. Specifically, $D_1,..., D_N$ are sampled from N different distributions, and the data volumes are different. The overall objective of PFL is to collaboratively learn independent personalized models $\u0398_1,..., \\hat{\u0398}_N$ for each client under the coordination of a central server. The global loss function is minimized to obtain the reasonable personalized models:\n$\\left\\{ \\hat{\u0398}_1, ..., \\hat{\u0398}_N \\right\\} = arg \\min_{\\Theta} G(L_1, ..., L_N)$,  (1)\nwhere $L_i = L_i(\\hat{\u0398}_i, D_i), \\forall i \\in [1, N]$, and $L_i(\\cdot)$ is the local loss function of client i. Typically, $G(L_1, ..., L_N) = \\sum_{i=1}^{N} k_iL_i$, where $k_i = |D_i|/\\sum_{j=1}^{N}|D_j|$, and $|D_i|$ is the number of local data samples for client i.\nSimilar to personalized-head-based methods like FedPer and FedRep, we split the neural network model $\\Theta$ into a feature extractor $\u0398_r: R^D \\rightarrow R^K$, which maps input samples to a low-dimensional representation space, and a head $\u0398_h: R^K \\rightarrow R^C$, which maps the representation space to the label space. Like FedRep, we treat the last fully connected (FC) layer of the neural network model as the head, and the remaining bottom layers as the feature extractor. D is the dimension of the input space, K is the dimension of the representation space, and C is the dimension of the label space, typically K \u226a D. As shown in Figure 3, after splitting the model into the feature extractor and head, the input sample is processed by the feature extractor to extract a low-dimensional feature representation, which is then passed through the head to obtain the label.\nThus, the local model i of client i can be transformed into a combination of its feature extractor $\u0398_{i,r}$ and head $\u0398_{i,h}$, i.e., $\u0398_i := \\{\u0398_{i,r}, \u0398_{i,h}\\}$. For simplicity, it is transformed to"}, {"title": "C. Aggregated Head for Personalized Federated Learning (FedAH)", "content": "In traditional FL (e.g., FedAvg), during iteration t, the server randomly selects a subset $S_t$ of N clients for training and aggregates all local models, $i \\in S_t$ to obtain the global model $\u0398^t$. Formally, $\u0398^t$ can be derived through:\n$\u0398^t = \\sum_{i \\in S_t} k_i \u0398_i$. (2)\nThen, the server sends the global model $\u0398^t$ to client i, which overwrites the local model $\u0398^{t-1}$ from the previous iteration, resulting in the initialized local model for local training, i.e., $\u0398_i^t := \u0398^t$. However, for FedPer and FedRep, the server sends the global feature extractor $r^t$ to client i to overwrite it, while the head $h^{t-1}$ from the local model of the previous iteration is retained, i.e., $\\{r_i^t, h_i^t\\} := \\{r^t, h_i^{t-1}\\}$. For FedAH, instead of simply retaining the local head $h^{t-1}$, we perform element-wise aggregation between the local head $h^{t-1}$ from the previous iteration and the global head $h^t$ from the current iteration to obtain the Aggregated Head $h_i^t$. Formally:\n$h_i^t := h_i^{t-1} + (h^t - h_i^{t-1}) \\odot W_i^t$,  (3)\nwhere $\\odot$ denotes the Hadamard product, representing the element-wise multiplication of two matrices, and $W_i^t$ denotes the aggregation weights for the model head of client i, where $w \\in [0, 1], \\forall w \\in W_i^t$. For FedAvg, the elements of $W_i^t$ are all one, while for FedPer and FedRep, the elements of $W_i^t$ are all zero.\nClient i trains $W_i^t$ using a gradient-based learning method, initializing each element of $W_i^t$ with one and continuously learning the new $W_i^t$ based on the former $W_i^{t-1}$. Formally,\n$W_i^t \\leftarrow W_i^{t-1} - \\eta \\nabla_{W_i^t} L_i(\\{r_i^t, h_i^t \\}, D_i)$,  (4)\nwhere \u03b7 is the learning rate for weight learning, and all other trainable parameters, including $r_i^t$, $h_i^t$, and $h_i^{t-1}$ are frozen during each iteration. The goal of updating the weights $W_i^t$ is to obtain a better Aggregated Head $h_i^t$. Additionally, to ensure $w \\in [0, 1], \\forall w \\in W_i^t$ during gradient descent, element- wise weight clipping $\u03c3(w) = max(0, min(1, w))$ is used for regularization [17].\nNext, the feature extractor parameters of the model are frozen, and the Aggregated Head $h_i^t$ is trained to obtain the local head $h_i^t$ for this iteration:\n$h_i^t \\leftarrow h_i^t - \u03b1 \\nabla_{h_i^t} L_i(\\{r_i^t, h_i^t \\}, D_i)$.  (5)\nThen, the local head parameters are frozen, and the feature extractor parameters are trained:\n$r_i^t \\leftarrow r_i^t - \u03b1 \\nabla_{r_i^t} L_i(\\{r_i^t, h_i^t \\}, D_i)$.  (6)\nFinally, clients upload the trained local models $\\{r_i^t, h_i^t\\}, \\forall i \\in S_t$ to the server for the next iteration of aggregation. Algorithm 1 describes the entire process of FedAH."}, {"title": "IV. EXPERIMENTS", "content": "In this section, FedAH is evaluated on various image/text classification tasks and compared with ten state-of-the-art (SOTA) FL methods including FedAvg [8], FedProx [5], Per-FedAvg [12], pFedMe [11], FedAMP [10], Ditto [14], FedPer [18], FedRep [19], FedFomo [15], and FedALA [17]. For image classification tasks, four datasets are used: MNIST [21], Cifar10 [22], Cifar100 [22], and Tiny-ImageNet [23] (100K images, 200 classes). A 4-layer CNN [8] is used as the model, with an additional ResNet-18 [24] for Tiny-ImageNet. The local learning rate \u03b7 is set to 0.005 for the 4-layer CNN and 0.01 for ResNet-18. For text classification tasks, the AG News [25] dataset with fastText [26] is used, and the local learning rate for fastText is set to \u03b7 = 0.01, with other settings the same as image classification tasks.\nThe experiments follow the FedAvg methodology, setting the batch size to 10 and the number of local model training epochs to 1. All tasks are run for 2000 iterations until all methods empirically converge. Following the methods of pFedMe and FedFomo, the total number of clients is set to 20, with a client joining ratio p = 1. The evaluation metrics used are the same as those in pFedMe, where traditional FL uses the test accuracy of the best single global model, and PFL uses the average test accuracy of the best local models. To simulate real PFL scenarios, the learned models are evaluated on the clients. 25% of the client's local data is used as the test dataset, and the remaining 75% is used as the training dataset. To avoid randomness, all experiments are run five times, and the mean and standard deviation are derived.\nThe experiments adopt two widely used scenarios to simu- late heterogeneous settings. The first is the pathological het- erogeneous setting [8], [27], where 2/2/10 classes are sampled from a total of 10/10/100 classes for MNIST/Cifar10/Cifar100, respectively, with non-overlapping data samples. Specifically, similar to FedAvg, clients are grouped with the same labels but with imbalanced data. The second scenario is the practical heterogeneous setting [20], [28], controlled by a Dirichlet distribution denoted as $Dir(\u03b2)$. The smaller the \u1e9e, the greater the heterogeneity of the environment is. In the experiments, \u03b2 = 0.1 is set as the default heterogeneity setting [17], [28].\nIn the experiments, our proposed FedAH is implemented using PyTorch-1.12.1 and simulate FL on a server equipped with an AMD Epyc 7302 16-core processor x 64, 8 NVIDIA GeForce RTX 3090 GPUs, 472.2GB of memory, and running Ubuntu 20.04.5 operating system."}, {"title": "B. Effectiveness", "content": "The experiments denote \u201cTINY\u201d and \u201cTINY*\u201d to represent the use of a 4-layer CNN and ResNet-18 on Tiny-ImageNet, respectively. In our experiments, the learning rate of the aggregation weights in FedAH is set to be the same as the local learning rate, with the number of training epochs per iteration set to 1. Table I shows that, except for the MNIST dataset under the default practical heterogeneous setting, FedAH outperforms all FL methods in terms of test accuracy across five benchmark datasets in CV and NLP, particularly on larger datasets (Cifar100 and TINY) and with more complex models (ResNet-18). On the Cifar100 dataset under the default practical heterogeneous setting, FedAH exceeds the second- best method, FedALA, by 2.87%. The poor performance of FedAvg in Table I is evident, as a single global model trained by traditional FL methods cannot fit well to the local data of all clients in a heterogeneous setting. Next, we analyze the reasons that FedAH outperforms the other four categories of PFL methods.\nMeta-learning-based PFL. Compared to traditional FL methods, PFL methods generally perform better. However, among these PFL methods, Per-FedAvg has the lowest test accuracy because it only obtains an initial global model that corresponds to the learning trend of all clients, making it difficult to meet the trends of each personalized model. In contrast, FedAH splits the model into a feature extractor and a head, achieving personalization through the client-specific head, which better fits the heterogeneous data of different clients, thus performing better.\nRegularization-based PFL. FedProx performs similarly to FedAvg because it still learns a single global model. Both pFedMe and Ditto use proximal terms to learn additional personalized models, but pFedMe learns from the local model while Ditto learns from the global model. Since Ditto can extract global information from the global model, its perfor- mance is better than that of pFedMe. However, using proximal terms to learn personalized models is an implicit method, and its effect is not as good as the explicit method of FedAH, which splits and aggregates the head.\nPersonalized-aggregation-based PFL. The model-level per- sonalized aggregation of FedFomo and FedAMP is not precise enough and may introduce useless information from the global model into the local model. Additionally, FedFomo requires downloading multiple other clients' models in each iteration, resulting in higher communication overhead. FedALA, by adaptively learning aggregation weights, can accurately cap- ture the required information from the global model, thus out-performing FedFomo and FedAMP. However, FedALA does not explicitly split the model into feature extractor and head, and alternating training of these two parts can significantly improve model performance, making FedALA perform worse than FedAH in most of the experiments.\nPersonalized-head-based PFL. Although FedPer and Fe- dRep split the model like FedAH, they only share the feature extractor but not the head, losing the global information of the model head. FedAH aggregates the local model head and the global model head at the element level to obtain the Ag- gregated Head. It thereby introduces global information from the global model head,and improves the overall performance of the model, thus performing better.\nOverall, by adaptively learning the aggregation weights of the head, FedAH can accurately capture the required global information in the global head and utilize the Aggregated Head with global information introduced as the initialized local head. This addresses the shortcomings of FedPer and FedRep. Additionally, FedAH follows the training methods of FedPer and FedRep, alternating the training of the head and the feature extractor, which is more effective than the way of directly training the entire model. Therefore, by combining the advantages of personalized-aggregation-based and personalized-head-based PFL methods, FedAH performs the best among all the SOTA methods."}, {"title": "C. Different Heterogeneity", "content": "To verify the effectiveness of FedAH under different degrees of heterogeneity settings, experiments are conducted on the Tiny-ImageNet and AG News datasets by changing the \u1e9e of $Dir(\u03b2)$. The smaller the B, the greater the heterogeneity of the settings is. As shown in Table II, the test accuracy of FedAH remains superior to all methods. Most PFL methods perform better in settings with stronger heterogeneity, while their test accuracy drops significantly when the heterogeneity is weaker, i.e., with larger B. When the degree of heterogene- ity in Tiny-ImageNet reaches \u03b2 = 0.5, only FedALA and FedAH have test accuracy higher than the traditional FedAvg, as they can accurately capture global information from the global model/head through adaptive model/head aggregation during local learning, thus maintaining excellent performance in settings with weaker heterogeneity."}, {"title": "D. Scalability", "content": "To verify the scalability of FedAH, five experiments are conducted following the methodology of MOON [20] on the Cifar100 dataset under the default heterogeneous setting, with the number of clients N set to N = 10, 30, 50, 100, and 200. Since the total data volume on the Cifar100 dataset is fixed, the local data volume (average) of each client decreases as the number of clients increases. As shown in Table II, when the number of clients increases to 100 and 200, the test accuracy of most PFL methods drops significantly due to the lack of local data on clients, while the test accuracy of FedAH remains superior to all other methods. This is because, in the case of sparse local data, it is more important to accurately capture global information from the collaboratively trained global model (or head), which can learn more global knowledge."}, {"title": "E. Computation and Communication Overhead", "content": "As shown in Table III, the experiments record the total time and the number of iterations required for convergence (determined by an early stopping mechanism) for each FL method, and calculate the average computation time per iter- ation. Per-FedAvg requires more time per iteration than most methods because it needs to fine-tune the local model. Since learning personalized models requires additional training steps, pFedMe has the highest computation overhead per iteration, and Ditto faces a similar situation. FedAH requires more training time per iteration, only less than the aforementioned three methods, because FedAH needs to additionally train the aggregation weights of the head and fine-tune the Aggregated Head in each iteration. However, using the Aggregated Head as a better initial head allows the model to converge quickly, resulting in relatively low total computation time and number of iterations.\nAs shown in Table III, we can theoretically compare the communication overhead of each FL method in a single iteration for one client. Most methods only need to upload and download the model once per iteration, so with the same number of model parameters and iterations, their communi- cation overhead is the same. FedPer and FedRep transmit only the feature extractor part in each iteration, resulting in the lowest communication overhead per iteration. FedFomo requires downloading multiple other client models in each iteration, leading to higher communication overhead. FedAH has lower communication overhead since it converges fast, requiring fewer iterations."}, {"title": "F. Stability", "content": "In real-world scenarios, some clients may unexpectedly drop out in a certain iteration and rejoin in a subsequent iteration due to reasons like insufficient battery power, lack of computing and storage resources, or network instability. To compare the performance of different PFL methods under such conditions, we simulate this scenario by changing the client joining ratio p in each iteration on the Cifar100 dataset. Specifically, instead of fixing the p value, p values are uni- formly sampled within a given range in each iteration. A larger range of p indicates a more unstable scenario. Compared to the settings of other FL methods with a fixed client joining ratio, our experiment is significantly closer to real-world scenarios.\nAs shown in Table IV, with the increase in the range of p, i.e., the more frequent the random dropout and joining behavior of clients happen, leading to the decrease of the mean and standard deviation of test accuracy for most methods. Some PFL methods, such as pFedMe and Ditto, perform much worse with a larger range of p. Compared to p = 1, their test accuracy decrease by 6.65% and 2.26%, respectively, when p\u2208 [0.1, 1]. For p in the same range, the standard deviations of Per- FedAvg, pFedMe, and Ditto are all greater than 1%, indicating their unstable performance in dynamic scenarios. However, The test accuracy of FedAH remains superior to all methods in such dynamic scenarios, with only a slight increase in standard deviation, demonstrating its stability. This is because clients joining FedAH train the aggregation weights of the head at the beginning of each iteration, allowing the Aggregated Head to quickly adapt to the changing environment. Thus, FedAH maintains its advantage and stable performance in these dynamic scenarios."}, {"title": "G. Different Local Epochs", "content": "To verify the effectiveness of FedAH under different local epochs, four experiments are conducted on the Cifar10 dataset under the default heterogeneous setting, with local epochs set to 5, 10, 20, and 40 while keeping other conditions unchanged. For most FL methods, increasing local epochs can reduce the total number of communication iterations but also increases the computational overhead per iteration and carries the risk of overfitting [8]. As shown in Table V, the test accuracy of FedAH remains superior to all methods across different local epochs settings. In heterogeneous settings, more local training increases the disparity of models on different clients, which is detrimental to server model aggregation and prone to overfitting. Therefore, the test accuracy of most FL methods decreases with the increase in local epochs, and FedAH follows the same trend."}, {"title": "V. CONCLUSION", "content": "In this paper, we propose Federated Learning with Aggre- gated Head (FedAH), a novel personalized federated learning method that addresses the loss of global information of the model head in personalized-head-based PFL methods. By performing element-level aggregation between the local model head and the global model head, FedAH introduces global knowledge into the personalized model heads, thereby enhanc- ing the overall model performance. Our extensive experiments on five benchmark datasets in computer vision and natural language processing demonstrate that FedAH outperforms ten state-of-the-art FL methods by 2.87% in test accuracy. Additionally, FedAH maintains its advantage under different degrees of heterogeneity, with increasing numbers of clients, and in scenarios where clients drop out unexpectedly, show- casing its effectiveness, scalability, and stability."}]}