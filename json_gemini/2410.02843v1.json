{"title": "Neural DDEs with Learnable Delays for Partially Observed Dynamical Systems", "authors": ["Thibault Monsel", "Emmanuel Menier", "Lionel Mathelin", "Onofrio Semeraro", "Guillaume Charpiat"], "abstract": "Many successful methods to learn dynamical systems from data have recently been intro- duced. Such methods often rely on the availability of the system's full state. However, this underlying hypothesis is rather restrictive as it is typically not confirmed in practice, leaving us with partially observed systems. Utilizing the Mori-Zwanzig (MZ) formalism from statis- tical physics, we demonstrate that Constant Lag Neural Delay Differential Equations (ND- DEs) naturally serve as suitable models for partially observed states. In empirical evaluation, we show that such models outperform existing methods on both synthetic and experimental data. Code is available at https://anonymous.4open.science/r/DynamicalSysDDE-F86C/", "sections": [{"title": "1 Introduction", "content": "Learning system dynamics is essential in many domains such as biology (Roussel, 1996; Epstein, 1990), climate research (Ghil et al., 2008; Keane et al., 2019) or finance (Achdou et al., 2012). In a data-driven context, given a dataset {(to, x), ..., (tv,x)}{=1 of observations of a unknown system:\n$\\frac{dx}{dt} = f(t, x(t))$\nx(0) = xo  (1)\nwe wish to learn a model for the dynamics of x(t) with x : R \u2192 R\" and f : R \u00d7 R\u2033 \u2192 R\". Such an approach is valid if the system's state is fully observed and the system is Markovian. Neural Ordinary Differential Equations (NODEs), introduced in Chen et al. (2018), follows this exact formulation. NODEs gave rise to the class of continuous depth models and can be viewed as a continuous extension of Residual Networks (He et al., 2016). An immediate extension of NODEs, known as Augmented NODEs (Dupont et al., 2019), addresses the expressivity limitation of NODEs by augmenting the dimension of the solution space from Rn"}, {"title": "2 Modelling Partially Observed Dynamical Systems", "content": "In this section we first introduce the Mori-Zwanzig formalism, suitable for partially-observed dynamical systems, then discuss the limitations of the usual way to solve them in practice with Integro-Differential Equations, and propose our new approach based on Takens' theorem to tackle these issues."}, {"title": "2.1 The Mori-Zwanzig (MZ) formalism", "content": "The Mori-Zwanzig formalism, rooted in statistical mechanics, provides a method to construct accurate evo- lution equations for relevant quantities, such as macroscopic observables, within high-dimensional dynamical systems (Mori, 1965; Zwanzig, 1966; Zwanzig et al., 1972). This framework is instrumental in situations where the full state x(t) is unavailable, and one can only access lower dimensional observations. Addition- ally, the MZ formalism is relevant for addressing dimension reduction problems (Zhu, 2019). We will operate within the first scenario, i.e. with partially-observed dynamical systems.\nTheorem 2.1. Mori-Zwanzig equation formalism Let us consider a nonlinear system evolving on a smooth manifold SCR\":\n$\\frac{dx}{dt} = G(x), x(0) = xo,  (4)\nwhere the full state x \u2208 S can be accessed only through the lens of an arbitrary number of scalar-valued observables gi :S \u2192 R. Then, under reasonable assumptions (see Appendix B), the dynamics of the vector of observables g = [91,\u2026,9m] follow the Integro-Differential Equation (IDE) :\n$\\frac{dg}{dt} = M(g(t)) - \\int_0^S K(g(t-s), s)ds. (5)\nwhere M is a Markovian term, i.e. a function involving current observables g(t), and where the function K, which depends on past observables, is integrated over the whole time since the initial condition.\nThis equation, derived within the framework of the Mori-Zwanzig theory (see Appendix A), is sometimes referred to as the Generalized Langevin Equation (GLE). It provides a rigorous governing equation for the observables g. This elegant formulation of partially observed dynamics yields an exact evolution equation that takes the form of an Integro-Differential Equation. Therefore, learning the dynamics of partially observed systems boils down to estimating each term of the differential equation above."}, {"title": "2.2 Approximations of Integro-Differential Equations (IDE)", "content": "The statement in Theorem 2.1 outlines the structure of the vector field dynamics. However, solving this dynamical equation can prove challenging due to the complexity implied by the integral term. We now discuss several approaches from the literature to estimate this integral.\nA simplistic approximation consists in just disregarding the integral term, focusing solely on the impact of the observable g at the current time step t. This corresponds to NODE Chen et al. (2018), where the dynamics are approximated as:\n$\\frac{dg}{dt} \u2248 fo(t, g(t)).$\nwhere fe is a neural network with parameters 0.\nInstead of neglecting it, an approach to approximate the integral consists in studying particular asymptotic regimes. Among the many different models proposed in the literature (Stinis, 2003; Chorin & Stinis, 2005; Stinis, 2006), one of the the most popular consists in approximating the integral under assumptions of very short memory or very long memory regimes.\nFor example, the t-model, also commonly called slowly decaying memory approximation (Chorin et al., 2002) leads to Markovian equations with time-dependent coefficients (see Appendix C for full derivation). However these remain asymptotic approximations, and, more problematically, they are not extendable to intermediate-range memory in general.\nAnother approach consists in performing Monte Carlo integration (Robert et al., 1999). This work has been extended in a neural network-based formulation (Neural IDE) Zappala et al. (2022), where the memory integrand is decomposed as a product of type K(t,s)F(g(s)). However the number of function evaluations required to accurately integrate Equation 5 scales with the increasing value of t, making the process compu- tationally intensive. In practice, experiments indicate that Neural IDE is at least 150 times slower compared to other models introduced subsequently (cf Appendix E). In a similar spirit, under assumptions of short memory, one can restrict the integral to a short past and discretize it in time, leading to an equation of the form (Gallage, 2017):\n$\\frac{dg}{dt} \u2248 M(g(t)) + \\sum_{i=1}^{k}K (g(t - Ti), \u03a4\u03b5) (6)$\nusing k delays T\u2081 uniformly spaced instead of sampling them by Monte Carlo. Such approximations can be improved using high-order discretization schemes, yet, as for Neural IDE, they require an unaffordable number of delays Ti if the integrand varies quickly or if the interval is too large."}, {"title": "2.3 Exact representation with Neural DDE", "content": "While Equation (6) only provides an approximation of the true dynamics and requires many delays, we show that using a more complex function of a small number of delays it is actually possible to represent the dynamics exactly:\nProposition 2.2 (Exact representation with delays). If a dynamical system follows an ODE: $\\frac{dx}{dt} = G(x)$, then, under the same weak hypotheses as Theorem 2.1, there exists almost surely a function M of the current observables, a finite number k of delays T1, ..., Tk > 0 and a function f such that the observables exactly follow the dynamics:\n$\\frac{dg}{dt} = M(g(t)) + f(t,g(t), g(t \u2013 \u04421), g(t \u2212 T2), ..., g(t \u2212 Tk)). (7)$"}, {"title": "3 Neural Delay Differential Equations with Learnable Delays", "content": "A constant lag NDDE is part of the larger family of continuous depth models that emerged with NODE Chen et al. (2018), it is defined by:\n$\\frac{dx}{dt} = fo(t, x(t), x(t \u2212 T1), . . ., x(t - Tk))$\nx(t < 0) = y(t)  (8)\nwhere y : R \u2192 R\" be the history function, Vi, Ti \u2208 R+ be a delay constant and fo : [0, T] \u00d7 R\u2033 \u00d7\u2026\u00d7Rn \u2192 Rn be neural network.\nThere are two possible ways of training continuous-depth models: discretize-then-optimize or optimize-then- discretize (Kidger, 2022). In the former, the library's inherent auto-differentiation capabilities are leveraged. In the latter, the adjoint dynamics are employed to compute the gradient's loss. Theorem 3.1 provides the adjoint method for constant lag NDDEs.\nTheorem 3.1. Let us consider the continuous-depth DDE model below where \u0442 \u0441\u0430n appear in the parameters vector 0 and the notation x(t) = xt for conciseness :\nxt = fo(t, xt, Xt\u2212r), \u03c4\u2208R+\nXt<0 = $t  (9)"}, {"title": "4 Experiments", "content": "Numerous experiments have been carried out, categorically addressing two aspects: firstly, validating the existing adjoint approach and assessing the benefits of incorporating learnable constant delays; secondly, examining how neural DDEs with learnable delays is essential to effectively approximate partially observed systems, demonstrated on both synthetic data and experimental data. Additional experiments are also provided in Appendix F.\nIn a nutshell, the Brusselator and KS System experiments introduced below showcase multiple delays learn- ing. NDDE is the only model that accurately captures the statistics of the KS System. In the Cavity experiment presented below, learning delays is crucial, as fixed delays fail to capture the system's dynamics correctly."}, {"title": "4.1 Dynamical systems", "content": "Toy Dataset We demonstrate that the current approach with the adjoint method can learn jointly the delay and the dynamics of a system used to model population dynamics in biology Arino et al. (2009); Banks et al.\n(2017). Such a described system is formulated through the following DDE :\n$\\frac{dx}{dt} = x(t) (1 - x(t \u2212 \u0442)),$\nx(t < 0) = y(t)  (12)\nwhere we integrate from t \u2208 [0,10], \u0442 = 1, y(t) = x0 and 20 is sampled from the uniform distribution U(2.0, 3.0).\nThe following experiments showcase how NDDEs can effectively model partially observed systems with the systems past state values rather than with opaque latent variables.\nBrusselator The Belousov-Zhabotinsky kinetic equation Belousov (1959); Zhabotinskii (1964) can be mod- elled by the Brusselator system:\n}$\\frac{d41}{dt} = \u0410 \u2013 \u04121 - 1 + \u0444\u0456\u04242\\$\n$\\frac{d$2}{dt} = \u0392\u03a61 \u2013 \u03a6\u0399\u03a62.  (13)\nwhere we integrate in the time domain t \u2208 [0,25], the initial condition $1 is sampled from the uniform distribution U(0,2.0) and $2 = 0.0. We set ourselves in the partially observable case where we only have $1's dynamics and wish to reconstruct its dynamics.\nKuramoto-Sivashinsky (KS) System We set ourselves in another experiment with the chaotic Ku- ramoto-Sivashinsky System whose 1D dynamics u(x, t) is :\n$\\frac{\u2202u}{Ot} + \\frac{\u2202u}{\u042d\u04452} + \\frac{Ju}{\u042d\u04454} + \\frac{1}{2}(\\frac{\u2202u}{\u2202x})^2 = 0$\nThe system is integrated over the time domain t \u2208 [0,30], and its spatial domain D\u2081 = [0,22] is discretized into 128 points. To put ourselves in the partially observed setting we choose to observe k features uniformly spread across the spatial domain (here k = 5).\nIncompressible open cavity flow We consider here as experimental demonstrator the modelling based on time-series derived from wind tunnel experiments of an open cavity flow represented in Figure 3; the facility is described in Tuerke et al. (2020), where the data we provide in open access with this work are discussed. Open cavity flow attracted numerous research efforts in the last decades for the interesting dynamics at work: the flow is characterized by an impinging shear layer activating a centrifugal instability in a cavity; this interplay, reminiscent of the feedback acoustic mechanisms described in Rossiter (1964), leads to a self-sustained oscillation. A broad range of dynamics is observed, ranging from limit cycles, to toroidal and chaotic dynamics. The data obtained is for a Reynolds number Re = 9190. More details on the experimental setup is given in Tuerke et al. (2020)."}, {"title": "5 Conclusion", "content": "In this study, we showcased the capability of constant lag neural delay differential equations (NDDEs) to effectively represent partially observed systems. The theoretical support for this assertion comes from the Mori-Zwanzig formalism and with its simplification that introduces DDE dynamics. We applied NDDEs to synthetic, chaotic, and real-world noisy data, and conducted comparisons with other continuous-depth and memory based models. The performed experiments revealed two key insights: firstly, the essential role of memory in accurately capturing dynamics; secondly, it was demonstrated that LSTMs' and Latent ODEs' hidden latent states or ANODEs' latent variables are not the exclusive means or sometimes come short to achieve optimal performance, emphasizing the efficacy of delayed terms as an efficient dynamic memory mechanism.\nNDDEs come with inherent limitations, such as the linear scaling of its adjoint method with the number of delays (refer to Appendix G for the case of multiple constant delays). Another question is how to determine the optimal number of delays to consider; this said, overestimating the number of delays does not hurt the final performance. Promising directions for future research involve exploring an equivalent version of ANODEs with NDDEs to assess whether simpler flows can be learned. Additionally, there is a research opportunity to investigate regularization terms that could enhance the NDDE training process. Specifically, we are contemplating the inclusion of a penalty term resembling of a delayed mutual information, inspired by the work of (Fraser & Swinney, 1986)."}, {"title": "A Derivation of Theorem 2.1", "content": "The dynamics of a physical model can be written as the evolution equation of the form\n$\\frac{\u2202}{Ot} -etgu(0) = Gu(0)$\nwhere the et is the evolution operator and G is the corresponding infinitesimal generator and u an observable function Zhu (2019). The goal is to find an appropriate projector P and Q = 1 \u2212 P that splits the dynamics of the original high-dimensional system into resolved variables, unresolved variables and the interaction between these two.\nIf we consider a nonlinear system evolving on a smooth manifold SCRn.\n$\\frac{dx}{dt} = F(x), x(0) XO$\nThe system can be seen through the lens of an arbitrary number of scalar-valued observables Vi, gi : S \u2192 C. The dynamics of any scalar-valued observable gi (x) (quantity of interest) can be expressed with the Koopman operator K(t,s) Koopman (1931),\ngi(x(t)) = [K(t,s)gi](x(s))  (14)\nK(t,s) = e(t-s)L, Lg\u2081(x) = F(x)\u00b7\u2207gi(x)  (15)\nwith L the Liouville operator. Often rather than not, instead of computing the dynamics of all observables, it is better to compute the evolution of a subset of quantities of interest. This subspace can be modelled with a bounded linear operator P (projector) and its orthogonal projector Q = I-P. Since we are only considering a subset of observable we seek to get the dynamics of PK(t,s). With the definition of the Koopman operator and the Dyson identity\net\u00a3 = et\u00a3PL + $\\int_0^t esLPLe(t-s)QL ds$  (16)\nwe obtain the Mori-Zwanzig operator equation\n$\\frac{d}{dt}$ etc = et\u00a3PL + $\\int_0^t esLPLe(t-s)QL QLds$  (17)\nThe three terms at the right hand side are respectively the streaming (or Markovian) term, the fluctuation (or noise) term and the memory term.\nThen, one can apply Eq. equation 17 to an arbitrary observable function gi and evaluate it at x to get the dynamics of the projected (or not) resolved variables of the system.\nOne can rewrite also the MZ's functional form equation (Tian et al., 2021) by applying equation 17 to all observables gi at their initial condition gi(t = 0) = gio and concatenating all observable gi together into g = [91,..., 9m].\n$\\frac{dg(t)}{dt} = M(g(t)) + F(t) \u2013 \\int_0^t K(g(t - s), s)ds$  (18)"}, {"title": "E Neural IDE and Neural DDE Benchmark", "content": "Firstly, let us compare both Neural IDE and Neural DDE analytically where any function fo denotes a parameterized network:\n$\\frac{dg}{dt} = Mo(g(t)) - \\int_0^t Ko(g(t-s s), s)ds$  (24)\n$\\frac{dg}{dt} = fo\u2081(g(t)) + fo\u2082(t, g(t), g(t \u2212 T1), ..., 9(t \u2212 Tn))$  (25)\nThe second term on the right hand side of Equation 24 is much more computationally involved than that of the second term on the right hand side of Equation 25. Indeed, Equation 25 only needs 2 function evaluations to evaluate it's right hand side(RHS). On the other hand, the number of function evaluation required to integrate Equation 24 will scale as t grows in order to get a correct evaluation of the integral term."}, {"title": "G Proof of Theorem 3.1", "content": "Proof is inspired from Calver & Enright (2017) and put into ML context.\nFor conciseness, we use the following notation x(t) = xt, x(t) = xt, etc...\nWe want to solve the optimization problem where may appear in our parameter vector 0:\narg min L(xt),\n\u03b8\ns.t. $\\frac{T}{\\int_0^} fo l(xt)dt,$\nXt - f (xt, Xt\u2212r; 0) = 0,\nXt<0 = $(t).  (26)\nWe consider the following Lagrangian:\n$\\frac{T}{\\int_0^} J = L+ At (Xt - f(xt, Xt\u22127;0))dt. (27)\n$\nIntegration by parts yields:\n$\\frac{T}{\\int_0^} J = Atxt + At f (xt, Xt-r;0)dt. (28)$\nTaking the derivative w.r.t. 0:\n$\\frac{d.J}{de} =  + [xi]- +$\n$-\\int_0^T At \\frac{df (xt, xt-r; 0)}{\u0434xt} dt + \\frac{dxT}{20}-At \\frac{df (xt, xt-7; 0) dxt}{-At} \\frac{df (xt, xt-r; 0)}{\u0434xt}dt + \\frac{dxT}{20}  (29)$\nSince St--1 the following equation simplifies to :\n$\\frac{d.J}{de} =  +  +$\n$-\\int_0^T At \\frac{df (xt, xt-r; 0)}{\u0434xt} dt -\\int_0^T At \\frac{df(xt, xt-r; 0) Axt}{\\int_0^T dt +} d  (30)$\nRearranging integrals\nWe rework the first part of the last term to close the equation on xt:\n$\\int_0^T At \\frac{df(xt, xt-r; 0)}{\u0434xt-} dt = \\int_0^ At\\frac{df (xt+7, xt; 0) Axt}{dxt}dt  (31)$\nChoosing the multipliers so that At>T = 0, we get :\n$\\int_0^T At \\frac{df(xt, xt-r; 0)}{\u0434xt-} dt = \\int_0^ At\\frac{df (xt+7, xt; 0) Axt}{dxt}dt. (32)$\nFinally, observing that == 0, the last term becomes :\n$\\int_0^T At \\frac{df(xt, xt-r; 0)}{\u0434xt-} dt = \\int_0^ At\\frac{df (xt+7, xt; 0) Axt}{dxt}dt. (34)$\n\nFinally, injecting this result, we rearrange the terms in Eq.29 :"}, {"title": "Adjont Equation", "content": "$\\frac{T}{\\int_0^}  = +At+\n+\\int_0^T At d+ dt-At++ d+  (35)\nThe last term vanishes because of the chosen adjoint final condition At>T = 0, thus we get the following adjoint dynamics, to be integrated backwards in time:\nAt =\nAt>T = 0. (36)\n(37)\nHence, the gradient's loss w.r.t to the parameters is :\n = -\n+T+\n+T++At+dt. (38)\nThe last term is more often than null since the history function is parameter independent simplifying ever further the equation.\nNotes on the derivative of the loss\nPractically, the loss L(xt) is evaluated from a finite number N of points in time :\n = T 1(xt)dt(39)0=\nTNN11(xt)t. (40)With la function computing the objective for each sampled point. This yields the following gradient :\nlT=Nx8tti. (41)This term is then always null, except for t = ti, this is why the adjoint dynamics in Eq.equation 35 are integrated from one sampling point ti to the previous ti\u22121, where the adjoint state is incremented as follows :\nAdjont Equation\nFinally, injecting this result, we rearrange the terms in Eq.29 :\nTdJ dlxtdfxtxt;0dfxtxt7;07Tdfxtxr;0dTd+At+-+At+dtt-+=- de dxt dxt dxt +7T0d7TddtAt1+1+2+At+(35)0de TxtThe last term vanishes because of the chosen adjoint final condition At>T = 0, thus we get the followingadjoint dynamics, to be integrated backwards in time :\nlxtdfxtxt7;0dfxt7,xt;0=At =At+-+ , (36)dxt dx7 dTdTAt0. (37)0.t>7t+1dx7xtHencethegradientslossw.rttheparametersisd.Jdlxt++T70dfxtr70dfxt++xr,0dTd+1dd+++dt1++++(38)de dtxtTTTT+1+2+1++++007-dx1+1+2+1+The last term is more often than null since the history function is parameter independent simplifying everfurther the equation.Notes on the derivative of the lossPractically, the loss L(xt) is evaluated from a finite number N of points in time :LxtT1xtdttTNN11xt-tti dtt1-(39)0=TTTT(40)0=1+1+2+1++Witthlafunctioncomputingtheobjectiveforeachsampledpoint.Thisyieldsthefollowinggradient :dlxtNN1dlxt1-tti. (41)dxT+=dxtii==1+++This term is then always null, except for t = ti, this is why the adjoint dynamics in Eq.equation 35 areintegrated from one sampling point ti to the previous ti\u22121, where the adjoint state is incremented as follows :21"}, {"title": "H Proof of Proposition 2.2", "content": "Let us start by stating Takens' theorem as expressed by (Noakes, 1991; Takens, 1981):\nTheorem H.1. Takens' embedding theorem Let M be compact. There is an open dense subset D of Diff(M) \u00d7 Ck (M,R) with the property that the Takens map\nh:MR2m+1\ngiven by h(x) = (g(x), g(\u00a2(x)), g(\u00a20 \u00a2(x)), ...g($2m(x))) is an embedding of Ck manifolds, when (\u03c6, g) \u2208 D.\nHere, & stands for the operator that advances the dynamical system by a time step 7, i.e. that sends x(t) to x(t + r), and g is the observable operator, that sends a full state x(t) to actual observables g(x(t)) =: g(t). Variants of this Theorem, e.g. Sauer et al. (1991), include the consideration of any set of different delays Ti instead of uniformly spaces ones. The representation h(x(t)) = (g(x(t)), g(x(t \u2212 \u0442)), g(x(t \u2212 2\u0442)), ...g(x(t \u2212 2mT)) then becomes h(x(t)) = (g(x(t)), g(x(t \u2212 \u0442\u2081)), g(x(t \u2212 T2)), ...g(x(t \u2212 T2m)). In the proof of Takens' theorem, m is the intrinsic dimension of the dynamical system, i.e. the one of the manifold M.\nNow, given the full state x that follows the dynamics :\n$\\frac{dx}{dt} = G(x), x(0) = xo  (46)$\nwe use the chain rule on the observable g:\n$\\frac{dg}{dt} = g'(x(t))G(x)  (47)$"}, {"title": "I The importance of relevant delays", "content": "Let us consider a dynamical system evolving on a compact smooth manifold S C Rd, assumed to be an attractor. Let us consider a C\u00b2 observable function g: S\u2192 R.\nTakens' theorem (Takens, 1981) rigorously discusses conditions under which a delay vector of a scalar-valued observable (g(x(t)), g(x(t \u2212 \u0433)), ..., g(x(t \u2212 p\u0442))), p \u2208 N defines an embedding, a smooth diffeomorphism onto its image. It guarantees a topological equivalence between the original dynamical system and the one constructed from the memory of the observable. The dynamics of the system can then be reformulated on the set (g(x(t)), g(x(t \u2212 \u315c)), ..., g(x(t \u2212 \u0440\u0442))).\nThe Takens' theorem, later extended by Sauer et al. (1991), establishes a sufficient condition but does not provide information about the time delay \u0442. From a mathematical viewpoint, the delay could be arbitrary, besides some pointwise values excluded by the theorem. In practice however, its value is instrumental in a successful embedding. If too small, entries of the delay vector data are too similar; if too large, the entries tend to be completely uncorrelated and cannot be numerically linked to a consistent dynamical system.\nWe here illustrate the impact of suitable delays in the relevance of the information available to inform the future evolution of the observable. We consider a simple 2-delay dynamical system described by:\ng(t + \u2206t) = cos(g(t-1)) sin(g(t \u2212 T2)) \u2013 a sinc(3 g(t \u2212 +1)) + a cos(g(t \u2212 T2)),\ng(t < 0) = \u03c8(t),\nwith a = 0.2, T\u2081 = p\u2081 \u2206t, T2 = p\u00bd \u2206t, p\u2081 = 125, p = 200.\nFigure 17: {T\u2081 = P1 \u2206t, T2 = P2 At}-map of Delayed Mutual Information, I ((g(t \u2212 \u0442\u2081), g(t \u2013 T2)), g(t)). The maximum is exhibited at (125, 200) and (200, 125), in accordance with p\u2081 = 125, p = 200.\nThe relevance of the delays {T1,T2} for informing g(t + \u2206t) is assessed in terms of the mutual informa- tion I ((g(t - T\u2081), g(t \u2212 T2)), g(t)) and shown in Fig. 17 as a 2-D map in terms of p\u2081 and p2. The map is symmetric, consistently with the symmetry of the mutual information, I ((g(t \u2212 T1), g(t \u2013 T2)), g(t)) =\nI ((g(t - T2), g(t \u2013 T1)), g(t))."}, {"title": "J Training hyperparameters", "content": "To train our models we progressively feed them longer trajectory chunks if the patience hyperparameter is exceeded; this is done until the desired trajectory length is attained. Table 7 displays the patience hyper- parameter and how much trajectory length was given initially. Table 8 refers to the number of parameters of each model. The loss function used across all experiments is the MSE loss, and we employ the Adam optimizer with a weight decay of 10-7. Table 13 provides the initial and final learning rates (lri, lrf) for each experiment, which are associated with the scheduler. The scheduler is a StepLR scheduler with a gamma factor (\u03b3 = P{exp"}]}