{"title": "Sustainable broadcasting in Blockchain Network with Reinforcement Learning", "authors": ["Danila Valko", "Daniel Kudenko"], "abstract": "Recent estimates put the carbon footprint of Bitcoin and Ethereum at an average of 64 and 26 million tonnes of CO2 per year, respectively. To address this growing problem, several possible approaches have been proposed in the literature: creating alternative blockchain consensus mechanisms, applying redundancy reduction techniques, utilizing renewable energy sources, and employing energy-efficient devices, etc. In this paper, we follow the second avenue and propose an efficient approach based on reinforcement learning that improves the block broadcasting scheme in blockchain networks. Such an improvement concerns both the block propagation time and the number of messages to be broadcast before the network reaches consistency. The latter determines the amount of traffic and distributed energy consumption across the blockchain network infrastructure.\nIn particular, we implemented a reinforcement learning (RL) agent to efficiently re-prioritize the broadcast order in the default blockchain block propagation protocol based on real-time transport layer network information. This approach reduces the average propagation time as well as the number of messages needed to reach network consistency. Since blockchain networks are highly distributed around the world, this seemingly small improvement could make a big difference in the context of overall energy consumption and the network's impact on the environment.\nTo train the agent and validate the approach, we used a blockchain simulator that was extended by adding a broadcast monitoring interface and was integrated into the RL envi- ronment. We then ran a series of simulations and general statistical analyses to compare the performance of the default block propagation scheme and the scheme with the RL agent involved. The analysis and experimental results confirmed that the proposed improvement of the block propagation scheme could cleverly handle network dynamics and achieve better results than the default approach. Additionally, our technical integration of the simulator and developed RL environment can be used as a complete solution for further study of new schemes and protocols that use RL or other ML techniques.", "sections": [{"title": "I. INTRODUCTION", "content": "Bitcoin and Ethereum are the most carbon-intensive blockchain-based P2P payment networks. They consume a growing amount of energy and emit an average of 64 and 26 million tons of CO2 per year, respectively [1], [2]. Besides Bitcoin and Ethereum, several other large blockchains produce on average more than 750 tons of CO2 equivalent each year [2]. Consequently, new environmental, social, and economic challenges confront inventors, researchers, and gov-"}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "A. Blockchain network and block propagation\nIt is well known that the blockchain concept was introduced with the Bitcoin cryptocurrency system by Satoshi Nakamoto in 2008 [6]. The blockchain can be regarded as an immutable and decentralized database maintaining a continuously grow- ing list of ordered records, called blocks, that are secured from tampering and shared among participating members. The blockchain is an important approach for open environments [7], as it is dedicated to memorizing data, executing trans- actions, performing functions, and providing trust and secure computations [8].\nBitcoin and Ethereum are the most common blockchain cryptocurrency architectures built on an unstructured peer-to- peer (P2P) network model. The P2P architecture of blockchain allows all cryptocurrencies to be transferred worldwide with- out the need for any middleman, intermediaries, or central server. With the distributed P2P network, anyone who wishes to participate in the process of verifying and validating blocks can set up a node [9].\nNew blocks in Bitcoin and Ethereum can only join the chain when other nodes validate these blocks, which occurs after executing a decentralized consensus procedure [10]. The number of blocks increases over time, and these blocks are linked together using cryptography to form a chain. Each individual block holds a cryptographic hash of the antecedent one.\nWhen a node initializes, it attempts to discover a set of peers to establish outgoing or incoming transport layer network connections that are based on the TCP protocol. These TCP connections are used for transaction and block propagation. Each node maintains a list of peers' IP addresses. For instance,"}, {"title": "B. Reinforcement learning for distributed networks", "content": "Reinforcement learning has shown excellent ability in solving some complex problems, including those related to blockchain [16]. It uses rewards to enable the algorithm to continuously optimize decision-making in the learning pro- cess, thereby learning an optimal mapping from state to action [17]. The rewards for performing actions are delayed; that is to say, the pros and cons of the current action cannot be judged immediately. Only after the action has an impact on the state, the cumulative reward obtained from the execution of the action up to a certain moment afterward is calculated. Then, the model accomplishes the optimization of the action by reward [18].\nBasically, a task in RL is modeled as a Markov Decision Process (MDP). An MDP, denoted as M = (S, A, T, R, \u03b3), where S and A are the state and action space respectively. T(s, a, s') : S \u00d7 A \u00d7 S \u2192 [0, 1] is the probability of reaching state s' from state s after executing action a. The reward function R(s, a,s') : S \u00d7 A \u00d7 S \u2192 R assigns a numerical reward to a state transition from s to s' with respect to the executed action a. A policy \u03c0(s,a) : S \u00d7 A \u2192 [0,1] defines how the agents should act in the environment through the probability distribution over all actions in every state. The decay factor y \u2264 1 is used to define the expected discounted return Dt = \u2211k=0YkRt+k and the value function V(s) = \u0395\u0391\u03b5~\u03c0(St) [t=0&Rt|So = s]. The RL agent learns a policy that maximizes the expected discounted return, where the optimal policy has the maximum expected discounted return [19].\nThe use of the RL-based approach to solve routing problems in different types of networks has been widely discussed in the literature (see for review [3]). For example, Boyan et al. [20] first combined the Q-learning algorithm with packet routing to dynamically learn the routing situation and find the shortest path in the network. Gao et al. [21] proposed a multi-agent routing algorithm with Q-learning and backpressure, where each routing node needs only local information about the neighbor routing nodes to solve this problem. Mayadunna et al. [22] and Yang et al. [4] proposed RL-based malicious routing node detection schemes for mobile ad-hoc networks and wireless sensor networks, respectively."}, {"title": "C. Related work and sustainability concern", "content": "Several schemes and protocols have been proposed to re- duce propagation time and related traffic load in blockchain- based networks, while also ensuring network security: compact block propagation [12], hybrid compact block propagation [13], bodiless block propagation [23], etc. These proposals mainly focus on algorithms and technical improvements of the Bitcoin or Ethereum core protocol itself. Such enhance- ments often necessitate significant changes in network design and infrastructure, and in some cases, even a fork of Bit- coin/Ethereum. Therefore, our work emphasizes the network transport layer, which is typically invariant of the underlying top-level protocols and requires relatively small changes in client software. By slightly modifying the previously men- tioned default propagation procedure (BPP) at the broadcasting step with a RL-based approach, technically, such an approach can be implemented with any other propagation scheme that usually does not depend on the transport layer of the network.\nAs mentioned above, recent works consider RL implementa- tions for blockchain-based networks to improve their methods and algorithms. For instance, in [7], by combining RL and blockchain for IoT networks, a decentralized communication structure for scalable and trustworthy information allocation was developed (for a review on RL for IoT, see [24], [25]). In [26], deep RL was used to optimize the performance of the recently invented Prism proof-of-work blockchain protocol [27] and enhance the number of votes without violating security and latency performance guarantees [26]. In [28], RL was used to auto-tune network fabric in permissioned blockchain systems and demonstrated an ability to identify optimal network configurations.\nThere are also a number of papers devoted to RL solutions in the context of improving cryptocurrency operations in Bitcoin and Ethereum: cryptocurrency exchanges [29], trad- ing [30], [31], portfolio management [32], and for example, detecting specific agent behaviors [29], etc. Some new works combine blockchain technologies and RL to improve even economic and social systems, e.g., the healthcare system [33]. However, these works do not directly address the broadcast- ing problem in global peer-to-peer networks, namely Bitcoin and Ethereum, and do not pay much attention to the overall environmental impact.\nThe work most closely related to ours [4] has already stated that existing blockchain routing schemes based on randomiza- tion or fixed-order broadcasting struggle to cope with network dynamics and, in some cases, cannot avoid poorly connected or even malicious nodes when routing changes are made in real- time. In the case of wireless sensor networks, they showed that RL can improve the self-adaptability of the routing scheme by dynamically selecting more reliable and efficient routing channels [4]. We extended this idea to Bitcoin and Ethereum networks and showed that a well-trained RL agent can effi- ciently re-prioritize initially randomized broadcasting orders to achieve network consistency earlier and reduce possible traffic redundancy."}, {"title": "III. METHODS", "content": "A. The proposed block propagation protocol\nAs mentioned earlier, the standard blockchain propagation scheme (BPP) in the Ethereum blockchain implies that a sending node forwards a new block to randomly selected \u221aN neighboring nodes after verifying the block head information. However, this selection may not be optimal in terms of achieving consistency quickly. In some cases, a neighboring node may have a poor direct connection to the sending node, relatively high latency, or even be a black hole node [4]. In such cases, it may be beneficial to send the block to"}, {"title": "B. Blockchain simulator, network topology and RL-agent", "content": "Our approach is tested on the blockchain simulator devel- oped by Faria et al. [5]. This simulator is a discrete-event simulator flexible enough to evaluate different blockchain implementations, such as Bitcoin and Ethereum. It follows a stochastic simulation model, capable of representing random phenomena by sampling from a probability distribution. The network model in the simulator is responsible for tracking the state of each node during the simulation, establishing connection channels between nodes, and applying network latency to the messages being exchanged. We extended the network model by implementing BPP broadcasting in a re- cursive manner and modified network monitoring to collect appropriate statistics. Consequently, the simulator reproduces the standard broadcasting protocol more accurately.\nThe network latency delay in the simulator is applied depending on the geographic location of the destination and origin nodes. Three geographic locations with corresponding latency distributions were provided out of the box (Ohio, Tokyo, and Ireland), and they showed identical results for average propagation time as in real blockchain, but with a slightly oscillating standard deviation [5]. Based on the limited number of TCP connections of the average node (approxi- mately 125), we constructed a minimal, but sufficiently large fully connected P2P network architecture of size 150 nodes. Each geographical location consisted of 50 nodes, with half of them marked as miners with equal hash rate (this is a prerequisite for proper simulation).\nNext, we constructed an OpenAI Gym RL-environment [34] and integrated a simulator instance so that it can be inde- pendently executed at each step of training after a RL agent performs its action. We also modified the node model of the simulator so that it requests the RL agent to reorder the node connections list before starting broadcasting. Thus, the active RL agent might be involved (or not) independently during the simulation.\nBased on the tracked information in the simulator, we rep- resent the dynamic network state (s) from a node's perspective as an ordered set of neighbor latencies (corresponding to the node connections list) that change after each communication step. For technical simplicity, we use delay estimates obtained from the transaction propagation process, which is performed before the block propagation phase in the simulation. We define an action function as an ordering function over the"}, {"title": "C. Key metrics and reward function", "content": "Block propagation time is the most critical metric for blockchains as it determines the fork rate [38], [39] and also limits the frequency of payments. For BPP in Ethereum, the block propagation time is predominantly influenced by the transmission time of the full block [14], which can be expressed as:\n$t_{bpp} = l + size * (b^{-1} + t_{proc})$,\nwhere $t_{bpp}$ indicates block propagation time or total trans- mission delay; l indicates network latency; size indicates block size; $t_{proc}$ indicates block processing delay; b denotes bandwidth.\nHence, block propagation time should be considered the most important metric when comparing block propagation schemes. Due to the continuous block mining and propagation process, we opt to estimate an average block propagation time over the blocks that were successfully propagated to at least 50% of nodes in the network (synchronized blocks) and consider this metric as a practical approximation of network consistency \u2013 synchronization time."}, {"title": "IV. RESULTS", "content": "Since we intended to test whether a well-trained RL agent can efficiently re-prioritize broadcasting order and improve the default block propagation protocol by doing so, we ran a series of fixed-duration Ethereum blockchain simulations and evaluated the key metrics mentioned above. To fairly compare BPP with the RL-agent and without it, we performed k = 1000 simulations with a 60-second duration. This duration is minimally sufficient to introduce up to 5 blocks within a single simulation with comparatively less computation time and overall execution time.\nAt each of the k iterations, one simulation with and one simulation without the RL agent was run using the same random seed and network topology. We then recorded key metrics: synchronization time, synchronized blocks rate, and messages per synchronized block.\nSimulation results confirmed that RL-based broadcasting is able to achieve statistically significant improvements of network dynamics. On average over 1000 simulations, synchronization time was reduced by 1.7%, and synchronized blocks rate was increased by 3.4 percentage points. The total number of messages per synchronized block was reduced by 5.0%.\nTo estimate the environmental impact of proposed improve- ments, it is necessary to consider various emission factors"}, {"title": "V. LIMITATIONS AND FUTURE WORK", "content": "Using blockchain simulations in experiments is a trade- off between realism and control. Simulations provide a cost- effective, controlled, and safe environment for research and experimentation, but they come with inherent limitations in replicating the complexity of real-world blockchain networks. For instance, simulations can never fully replicate the com- plexity and dynamics of a real blockchain network; they often rely on simplifications and assumptions, such as uniform network conditions or idealized node behaviors; simulating large-scale blockchain networks with thousands or millions of nodes can be computationally intensive and may not be feasible due to hardware and software constraints etc.\nSince we wanted to make not only a controllable and reproducible but also a fair comparison between the default and our improved block propagation protocol, we constructed a simulation-based experimental design. However, in future work we plan to build a small real blockchain testbed, and also consider deeply exploring the proposed approach imple- mentation for other Ethereum-like networks. We also plan to continue experimenting with increasing the degrees of freedom of the solution. For example, by extending the agent's actions with the ability to determine the number of nodes to broadcast the block, instead of being limited by the Ethereum protocol."}, {"title": "VI. CONCLUSION", "content": "In this paper, we have attempted to address the environ- mental issues associated with blockchain-based P2P payment networks and explicitly discuss the environmental implications of the proposed improvements. We believe that every small improvement in blockchain protocols and its key metrics should also be considered in terms of energy consumption, data flow, and network load. Therefore, in this work, we:\n1) Developed an improved Ethereum blockchain peer-to- peer network propagation scheme that involves a RL agent to efficiently re-prioritize the broadcast order based on real-time transport layer network information.\n2) Enhanced an event-driven blockchain simulator by in- volving a RL agent and created a simulator-based inte- grated RL learning environment.\n3) Validated the proposed scheme improvement on a num- ber of simulations and showed that the approach reduces the average block propagation time while maintaining a good blockchain synchronization rate.\n4) Emphasized the environmental impact and estimated the required number of broadcast messages before the blockchain network achieved its consistency."}]}