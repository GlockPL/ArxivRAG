{"title": "Neurosymbolic Conformal Classification", "authors": ["Arthur Ledaguenel", "C\u00e9line Hudelot", "Mostepha Khouadjia"], "abstract": "The last decades have seen a drastic improvement of Machine Learning (ML), mainly driven by Deep Learning (DL). However, despite the resounding successes of ML in many domains, the impossibility to provide guarantees of conformity and the fragility of ML systems (faced with distribution shifts, adversarial attacks, etc.) have prevented the design of trustworthy AI systems. Several research paths have been investigated to mitigate this fragility and provide some guarantees regarding the behavior of ML systems, among which are neurosymbolic AI and conformal prediction. Neurosymbolic artificial intelligence is a growing field of research aiming to combine neural network learning capabilities with the reasoning abilities of symbolic systems. One of the objective of this hybridization can be to provide theoritical guarantees that the output of the system will comply with some prior knowledge. Conformal prediction is a set of techniques that enable to take into account the uncertainty of ML systems by transforming the unique pre-diction into a set of predictions, called a confidence set. Interestingly, this comes with statistical guarantees regarding the presence of the true label inside the confidence set. Both approaches are distribution-free and model-agnostic. In this paper, we see how these two approaches can complement one another. We introduce several neurosymbolic conformal prediction techniques and explore their different characteristics (size of confidence sets, computational complexity, etc.).", "sections": [{"title": "1 Introduction", "content": "The last decades have seen a drastic improvement of Machine Learning (ML), mainly driven by Deep Learning (DL). However, despite the resounding successes of ML in many domains, the impossibility to provide guarantees of conformity and the fragility\n1"}, {"title": "2 Preliminaries", "content": null}, {"title": "2.1 Informed supervised classification", "content": "In machine learning, the objective is usually to learn a functional relationship f : X \u21a6 Y between an input domain X and an output domain Y from data samples. Super-vised multi-label classification is a subset of machine learning where input samples are labeled with subsets of a finite set of classes Y. Therefore, labels can be under-stood as states on the set of variables Y. In this case, the output space of the task, i.e. the set of all labels, is Y = BY. In informed supervised (multi-label) classifica-tion, prior knowledge (sometimes called background knowledge) specifies which states\n2"}, {"title": "2.2 Propositional Logic", "content": "A propositional signature is a set Y of symbols called variables (e.g. Y = {a,b}). A propositional formula is formed inductively from variables and other formulas by using unary (\u00ac, which expresses negation) or binary (v, ^, which express disjunction and conjunction respectively) connectives (e.\u0434. \u043a = a^b which is true if both variables a and b are true). We note F(Y) the set of formulas that can be formed in this way. A state y \u2208 BY can be inductively extended to define a valuation y* on all formulas using the standard semantics of propositional logic (e.g. y*(a^b) = y(a) \u00d7 y(b)). We say that a state y satisfies a formula k, noted y \u22a8 \u03ba, if y*(\u043a) = 1. We say that a formula is satisfiable when it is satisfied by at least one state. We use the symbol T to represent tautologies (i. e. formulas which are satisfied by all states). Two formulas \u03ba and \u03b3 are said equivalent, noted \u03ba \u2261 \u03b3, if they are satisfied by exactly the same states. We refer to [9] for more details on propositional logic."}, {"title": "2.3 Probabilistic reasoning", "content": "One challenge of neurosymbolic AI is to bridge the gap between the discrete nature of logic and the continuous nature of neural networks. Probabilistic reasoning can provide the interface between these two realms by allowing us to reason about uncertain facts. In this section, we introduce two probabilistic reasoning problems: Probabilistic Query Estimation (PQE), i. e. computing the probability of a formula to be satisfied, and Most Probable Explanation (MPE), i.e. finding the most probable state that satisfies a given formula.\nA probability distribution on a set of boolean variables Y is an application P: BY \u2192 R+ that maps each state y to a probability P(y) such that \u2211y\u2208BY P(y) = 1. To define internal operations between distributions, like multiplication, we extend this definition to un-normalized distributions E: BY \u2192 R+. The null distribution is the application that maps all states to 0. The partition function Z : E \u2194 \u2211y\u2208BYE(y) maps each distribution to its sum, and we note E' := E/Z the normalized distribution (when E is non-null). The mode of a distribution & is its most probable state, i.e argmax(y).\nYEBY\nThe independent multi-label classification system (see Example ??) is build by following the probabilistic interpretation based on the exponential probability dis-tribution, which is parameterized by a vector of logits a \u2208 Rk, one for each variable in Y, and corresponds to the joint distribution of independent Bernoulli variables B(Pi)1\u2264i\u2264k with pi = \u03c3(ai).\n3"}, {"title": "Definition 1. Given a vector $a \\in \\mathbb{R}^k$, the exponential distribution is:", "content": "$E(a) : y\\mapsto \\prod_{i<k} e^{a_i*y_i}$  (1)\nWe will note $P(a) = E(a) / Z$ the corresponding normalized probability distribution. Typically, when belief about random variables is expressed through a probability distribution and new information is collected in the form of evidence (i.e. a partial assignment of the variables), we are interested in two things: computing the probabil-ity of such evidence and updating our beliefs using Bayes' rules by conditioning the distribution on the evidence. Probabilistic reasoning allows us to perform the same operations with logical knowledge in place of evidence. Let's assume a probability dis-tribution P on variables Y := {$Y_j$}$_{1\u2264j\u2264k}$ and a satisfiable propositional formula \u03ba. Notice that P defines a probability distribution on the set of states of Y. We also note 1k the indicator function of K which maps satisfying states to 1 and others to 0:\n\u0443\u043a\n$1_k(y) = \\begin{cases} 1 &\\text{if } y \\models k\\\\ 0 &\\text{otherwise} \\end{cases}$"}, {"title": "Definition 2. The probability of k under P is:", "content": "$P(\u03ba) := Z(P\u00b7 1\u2084) = \\sum_{y\u2208BY} P(y) \u00b7 1_x(y)$ (2)\nThe distribution P conditioned on \u043a, noted P(\u00b7|\u043a), is:\n$P(\u00b7|\u043a) := \\frac{P \u00b7 1_\u043a}{P(\u043a)}$  (3)\nSince P(a) is strictly positive (for all a), if kis satisfiable then its probability under P(a) is also strictly positive. We note:\n$P(\u0430) \\models \u03ba := Z(P(a) \u00b7 1)$\\\n$P(\u0430) \\models \u03ba\\ = \\frac{P(a) \u00b7 1}{P(a)}$"}, {"title": "2.4 Conformal classification", "content": "One of the great limitations of Machine Learning algorithms is their lack of guarantee regarding the validity of their predictions. Even when the algorithm is underpinned by a probabilistic interpretation, like often in Deep Learning, many experiments show that these probabilities are poorly calibrated: they do not correspond to the validity of the predictions. Indeed, it is not uncommon that an ML system makes a wrong prediction with a high degree of confidence. This results in a lack of trust in Machine Learning systems and is a major obstacle to their widespread adoption.\nConformal Prediction (CP) is a distribution-free and model agnostic framework that can solve this issue by transforming a Machine Learning algorithm from a point-wise predictor into a conformal predictor that outputs sets of predictions (called confidence sets) guaranteed to include the ground truth with a confidence level 1 \u2212 \u03b1, where \u03b1 is a user-defined miscoverage rate."}, {"title": "2.4.1 Transductive Conformal classification", "content": "Assume an input space X, an output space Y and a collection of samples $(x_i, Y_i)_{1\u2264i\u2264n}$ i.i.d. according to a probability law Px\u00d7Y. We are given a new input Xn+1 and we would like to make a confident guess about what could be the corresponding out-put Yn+1 knowing that (xn+1, Yn+1) was sampled according to Px\u00d7Y. To do so, we define a non-conformity measure A : (X \u00d7 V) \u00d7 (X \u00d7 Y) \u2192 R+ such that A({(x1, y1), ..., (Xn, Yn)}, (Xn+1, Yn+1)) measures how likely it is that a new sample (Xn+1, Yn+1) is i.i.d. with {(x1, Y1), ..., (Xn, Yn)}. For every possible output y ey we compute:\n$\u03bc_i^y := A(\\{(x_1, y_1), (x_{i\u22121}, y_{i\u22121}), (x_{i+1}, y_{i+1}), ..., (x_{n+1}, y)\\}, (x_i, y_i))$, 1 \u2264 i \u2264 n\n$\u03bc_{n+1}^y := A(\\{(x_1, y_1), (x_{i\u22121}, y_{i\u22121}), (x_{i+1}, y_{i+1}), ..., (x_n, y_n)\\}, (x_{n+1},y))$  (5)\nThen, we compute how likely (xn+1, y) is to belong to the sequence compared to every other sample in the sequence, called the p-value of y:\n$p(y) := p((x_1,Y_1), ..., (X_n, Y_n), (X_{n+1},y)) := \\frac{\\{1 \u2264 i \u2264 n + 1|\u03bc_i^y \u2265 \u03bc_{n+1}^y\\}}{n+1}$ (6)\nThe key property of the p-value is the following:\n$Px\u00d7Y(\\{y \u2208 Y|p(y) > \u03b1\\}) \u2265 1 \u2212 \u03b1$ (7)\nIn other terms, the p-values give us a way to select a set of outputs $C_\u03b1(x) := \\{y \u2208 Y|p(y) > \u03b1\\}$ which contains the true label with probability at least 1 \u2212 \u03b1.\nEven though it has no effect on the probabilistic guarantee, the challenge in CP is in the design of the non-conformity measure. If it does not correctly discriminates\n5"}, {"title": "2.4.2 Inductive conformal classification", "content": "To avoid this, Inductive Conformal Prediction (ICP) split available data into two sets:\na training set Dtrain = (x, y)1\u2264i\u2264ntrain used to train the model and produce the non-conformity measure and a calibration set Deal = (x, y)1\u2264i\u2264ncal used to compare the likeliness of outputs. Therefore, the non-conformity measure A : (X \u00d7 V) \u00d7 (X \u00d7 V) \u2192 R+ is replaced with a parametric functions: \u2299 \u00d7 X \u00d7 Y) \u21a6\u2192 R+ such that so(x,y) represents how likely it is that (x, y) is iid with Dtrain where the parameters are learned from the training set.\nWith this method, the model is only trained once then evaluated once for each sample in the calibration and evaluation sets. Besides, non-conformity scores for sam-ples in the calibration set must not be re-computed for every possible output. For a given miscoverage rate \u03b1, we can compute the $(n_{cal+1})(1-\u03b1)$-quantile $q_\u03b1$ of the non-conformity scores on the calibration set $(s(x_i, Y_i, \u03b8))_{1\u2264i\u2264ncal}$. This allows to shortcut the computation of the p-values by directly comparing the value of $\u03bc_{n_{cal+1}}$ to $q_\u03b1$, which gives us the confidence sets:\n$C_\u03b1(x) := \\{y \u2208 Y|s_\u03b8(x, y) < q_\u03b1\\}$  (8)\nFortunately, confidence sets defined defined in Equation 8 preserve the statistical guarantee expressed in Equation 7, i.e. :\n$P(y \u2208 C(x)) \u2265 1-\u03b1$ (9)"}, {"title": "2.4.3 Multi-label conformal classification", "content": "Non-conformity measures based on neural networks were first developed for in cate-gorical case [10]. Later, [11] proposed an adapted version to tackle tasks of multi-label classification using the following non-conformity measure:\n$s_\u03b8(x, y) = \\sum_{i=1}^k |y_i - p_i|^d$\n6"}, {"title": "3 A new method for conformal multi-label classification", "content": "In this section we introduce several new methods for inductive conformal multi-label classification. We first define a new un-informed method that deals with the expo-nential size of the output space. Then we introduce two methods that integrate prior knowledge about the classification task.\nOur new un-informed method for inductive conformal multi-label classification is based on the following non-conformity measure:\n$s_\u03b8(x, y) = 1 \u2212 P(y|M_\u03b8(x))$\nMore specifically, we exploit two interesting properties of this non-conformity measure:\n1.  Computing the confidence set $C_\u03b1(x) := \\{y \u2208 Y|s_\u03b8(x,y) < q_\u03b1\\}$ is equivalent to enumerating all states with a probability superior to a threshold $t_\u03b1 = 1 - q_\u03b1$. This can be done efficiently in time polynomial in the number of variables and in the number of states.\n7"}, {"title": "4 Informed inductive conformal classification", "content": "When a task of multi-label classification is informed by a propositional formula k, it is possible to integrate this knowledge into the conformal classification method to tighten the size of confidence sets produced by a given miscoverage rate \u03b1. We introduce to this end two conformal classification methods that integrate prior knowledge and detail their computational complexity.\n:"}, {"title": "4.1 Semantic filtering", "content": "A first approach works as an extension of any inductive conformal classification method by simply filtering the states that do not satisfy \u03ba in the confidence set:\n$C^\u03ba_\u03b1(x) := \\{y \u2208 Y|s_\u03b8(x, y) < q_\u03b1, y \\models \u03ba\\}$ (12)\nImportantly, as long as the consistency hypothesis about the test set (i.e. all labels in the test set satisfy the prior knowledge K) is maintained, this does not impact the statistical guarantee that comes with conformal prediction.\nSince satisfaction of a propositional formula can be done in a time linear in the size of the formula, this approach represents a minor overhead to the un-informed inductive conformal classification method in terms of computational complexity.\nBesides, when the chosen non-conformity measure is $s_\u03b8(x, y) = 1-P(y|M_\u03b8(x))$, an alternative implementation of filtering consists in computing $C^\u03ba_\u03b1(x)$ directly instead of computing $C_\u03b1(x)$ then apply filtering. This can be done efficiently when P(y) can be compiled into a DNNF circuit of reasonable size and brings down the complexity from |$C_\u03b1(x)$| to |$C^\u03ba_\u03b1(x)$|"}, {"title": "4.2 Semantic conditioning", "content": "The effectiveness of a given non-conformity measure is greatly determined by its align-ment to the model's training. Therefore, when the model is trained using semantic conditioning, the parameters are optimized to minimize the conditioned negative like-lyhood, and the standard negative likelihood often becomes uninformative. Therefore, prior knowledge can be integrated in the non-conformity measure itself (by condition-ing the probability distribution on the prior knowledge) to restore the alignment, i.e.\n$s_\u03b8(x, y) = 1 - P(y|M_\u03b8(x), \u03ba)$\n8"}]}