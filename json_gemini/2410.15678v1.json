{"title": "Revealing and Mitigating the Local Pattern Shortcuts of Mamba", "authors": ["Wangjie You", "Zecheng Tang", "Juntao Li", "Lili Yao", "Min Zhang"], "abstract": "Large language models (LLMs) have advanced significantly due to the attention mechanism, but their quadratic complexity and linear memory demands limit their performance on long-context tasks. Recently, researchers introduced Mamba, an advanced model built upon State Space Models (SSMs) that offers linear complexity and constant memory. Although Mamba is reported to match or surpass the performance of attention-based models, our analysis reveals a performance gap: Mamba excels in tasks that involve localized key information but faces challenges with tasks that require handling distributed key information. Our controlled experiments suggest that this inconsistency arises from Mamba's reliance on local pattern shortcuts, which enable the model to remember local key information within its limited memory but hinder its ability to retain more dispersed information. Therefore, we introduce a global selection module into the Mamba model to address this issue. Experiments on both existing and proposed synthetic tasks, as well as real-world tasks, demonstrate the effectiveness of our method. Notably, with the introduction of only 4M extra parameters, our approach enables the Mamba model (130M) to achieve a significant improvement on tasks with distributed information, increasing its performance from 0 to 80.54 points.", "sections": [{"title": "1 Introduction", "content": "In recent years, State Space Model (SSM) has emerged as a promising successor to the attention-based models (Vaswani et al., 2017) for long sequence modeling due to its linear computational complexity and constant memory requirements (Gu et al., 2022a; Gupta et al., 2022; Gu et al., 2022b; Smith et al., 2023). Different from the attention mechanism, which stores information for each token and performs pairwise computations between them, SSMs use a fixed-size state space to store history. This allows all computations to involve only the constant-sized state space. Mamba (Gu and Dao, 2023), built upon SSMs, is claimed to have achieved performance on par with, or even surpassing, that of attention-based models with the same parameters across language modeling and various synthetic tasks (Dao and Gu, 2024; Waleffe et al., 2024).\nHowever, we observe an intriguing discrepancy in Mamba's performance on two settings of the MQAR task: one requires the model to retrieve information from a local segment (single Key-Value pair) within the context, while the other requires re-"}, {"title": "2 Background", "content": ""}, {"title": "2.1 State Space Model (SSM)", "content": "Structured state space sequence models (S4) (Gu et al., 2021, 2022b; Goel et al., 2022; Ma et al., 2023; Hasani et al., 2023; Smith et al., 2023), represent a recent class of sequence models closely related to classical state space models. These models are inspired by a specific continuous system that facilitates the mapping of a one-dimensional function or sequence x(t) \u2208 R to an output y(t) \u2208 R through an implicit latent state h(t) \u2208 RN. Concretely, S4 models are characterized by four parameters (\u0394, A, B, C), which define a sequence-to-sequence transformation as follows:\n$$h'(t) = Ah(t-1) + Bx(t)$$\n$$y(t) = Ch(t)$$\nwhere (\u0394, A, B) are the discrete parameters, A \u2208 RN\u00d7N, B \u2208 RN\u00d71,C \u2208 R1\u00d7N, A = fa(\u2206, A), B = fB(\u2206, A, B). Additionally, fa(\u00b7), fB(\u00b7) are the pre-defined discretization functions."}, {"title": "2.2 Selective State Space Model (Mamba)", "content": "Selective State Space Model, as known as Mamba, is different from previous SSMs where the model's dynamics remain constant over time, it can efficiently update its hidden state based on the current input by introducing selective parameters. Specifically, Mamba accomplishes this by employing specialized trainable linear layers that map the input to the matrices B, C, and the time step \u0394t for each processing step. Mamba conditions the discrete time-variant matrices dynamically based on the input as follows:\n$$\u2206t = \u03c4(S\u2206Xt), Bt = SBXt,$$\n$$Ct = (ScXt)T,$$\n$$At = exp(At\u2206t), Bt = Bt\u2206$$\nwhere At represents the discretization step, \u03c4 denotes the softplus function, and S\u2206, SB, and Sc are linear transformation functions. This enhancement empowers Mamba to execute more flexible sequence modeling, particularly for tasks demanding extensive historical information e.g., the Selective Copying task (Arjovsky et al., 2016) and the Induction Heads task (Olsson et al., 2022), surpassing the performance of other SSMs. Further discussions on other SSM variants and efficient model structures can be found in Appendix A.2."}, {"title": "2.3 Multi-Query Associative Recall", "content": "To make evaluations more controllable and eliminate the influence of the models' intrinsic knowledge, synthetic tasks are often employed (Hsieh et al., 2024). We conduct a further discussion of the synthetic tasks in Appendix A. Among them, the Multi-Query Associative Recall (MQAR is a widely adopted synthetic task for SSMs. In MQAR, an input x is structured as a sequence of bigrams representing key-value pairs, which are randomly drawn from a predefined dictionary. Queries, i.e., the keys of key-value pairs, are then appended to this sequence, requiring the model to retrieve the corresponding value for the queried key. As depicted in Fig. 2, formally, the input context C = (Co,..., CN\u22121) consists of N tokens, where ci \u2208 \u03bd and V is the vocabulary of the model. We define N as the context length, representing the length of the input sequence. The input sequence C can be divided into three parts: key-value pairs KV, queries Q, and padding tokens P. The key-value pairs are KV = {(k1, 1), (k2, U2), ..., (kn, Un)}, where n is the predefined number of key-value pairs. In the standard MQAR task, these key-value pairs are placed at the beginning of the sequence. Queries are represented as Q = {q1,q2,..., qn}, where qi = ki, and are inserted at random positions after the key-value pairs. Padding tokens are defined as P = C \\ (QUKV), and they occupy the remaining positions in C, filled with random tokens. The objective of the MQAR task is to predict:\n$$Oi = arg max fo (oi | qi, KV,P),$$\n$$\u039f \u0395\u03bd$$\nwhere the model aims to output the most probable token o\u00a1 from the vocabulary, given the padding tokens, key-value pairs, and the query qi. MQAR requires models to memorize key-value pairs in their hidden state, which presents a significant challenge for rnn-based models, as they maintain a fixed-size state to handle all historical information."}, {"title": "3 Analysis of Local Pattern Shortcuts in Mamba", "content": "Previous studies (Gu and Dao, 2023; Arora et al., 2024a,b) have shown that Mamba's success stems from its data-dependent features, where Mamba can dynamically gate the previous information based on the current input. However, based on our preliminary study (as shown in Fig. 1), we observe that Mamba performs poorly when the key information with the context becomes denser or more dispersed, regardless of various context lengths. To discover the underlying reasons, we study the changes in the state space of the Mamba model during the inference process. In Sec. 3.1, we first reformulate Mamba's process of assigning weights to each token into an attention-like matrix. Then, we test the mamba model with the synthetic retrieval tasks and analyze the model's state space during the inference process. Specifically, we utilize the 130M version of Mamba in all the experiments and design three different testing sets based on the MQAR task: (1) Positional Pattern Change, which alters the distribution of information in the context, moving beyond the previous MQAR task that places key information at the beginning (Sec. 3.3); (2) N-gram Gathering, which controls the degree of aggregation of key information in the context by introducing more information within local segments, rather than solely testing the model's recall ability of single token (Sec. 3.2); and (3) Noise Injection, which adds noise tokens into the key information to perturb the model predictions, aiming to test the robustness of Mamba model (Sec. 3.4)."}, {"title": "3.1 Reformulating Selection Process of Mamba into Attention-like Matrix", "content": "Give the sequence Y = {Y1, Y2, , YL} that contains L tokens, we leverage Eq. 1 to calculate each Yi and reformulate the calculation process into ma-"}, {"title": "3.2 Positional Pattern Change", "content": "Task Description As depicted in Fig. 3, in the standard MQAR task, all Key-Value pairs are placed at the beginning of the sequence. This setup may lead the model to learn that it only requires \u201cremembering\" content from the initial portion of the sequence during training. To avoid such a fixed pattern of information distribution, we concentrate them at the end of the sequence (Last) as well as disperse the key-value pairs from the beginning to arbitrary positions throughout the sequence (Shuffle). As depicted in Fig. 3, after adopting the aforementioned settings, i.e., Last and Shuffle, queries (Q) are inserted at the random positions in the remaining padding sequence (P). Then, we train the Mamba model separately with training data containing three different positional patterns and evaluate it on all three test sets.\nResults As shown in Table 1, we can observe that when trained on the standard MQAR setup, Mamba achieved near-perfect accuracy on the in-domain"}, {"title": "3.3 N-gram Gathering", "content": "Task Description In the standard MQAR task, models are required to predict the correct value given a key, where both the key and value are single tokens, i.e., (ki, vi) \u2208 KV and |ki| = |vi| = 1. We refer to this configuration as the KIVI setting, primarily evaluating the model's 2-gram recall ca-"}, {"title": "3.4 Noise Injection", "content": "Task Description We further explore Mamba's robustness, specifically its ability to generalize beyond the shortcuts mentioned above. As shown in Fig. 6, we place n sets of Key-Value pairs at the beginning of the sequence and divide these Key-Value pairs into four regions: KV = {(k1, U1), (k2, U2), (k3, v3), (k4, v4)}. Then, two settings are adopted: K1V1* and K2V2*. In K1V1*, all the keys ki are identical, i.e., k\u2081 = k2 = k3 = k4, and we utilize symbol ki to denote those tokens. In K2V2*, the last token of ki are identical. All the values vi are different in the above two settings. Then, we let the model predict the corresponding value by providing ki."}, {"title": "4 Mitigating the Shortcuts of Mamba", "content": ""}, {"title": "4.1 Key to Selectivity of Mamba", "content": "For attention-based models, the recurrent state grows with the length of the sequence, enabling perfect recall accuracy but at the cost of efficiency. In contrast, rnn-based models maintain a fixed recurrent state size, making it critical to optimize the use of their limited memory resources. Mamba stands out by efficiently balancing the memory-"}, {"title": "4.2 Incorperating Global Selection Mechanism", "content": "To address this issue, we propose incorporating more global information into At through a fine-grained global selection mechanism. Specifically, we introduce a long convolution module to model distant context and integrate its output into the orig-"}, {"title": "5 Experiment", "content": "In this section, we conduct more comprehensive experiments across different models with varying foundational mechanisms, i.e., attention-based and rnn-based, to explore whether they exhibit similar behavior as observed in Mamba. Meanwhile, we evaluate whether our proposed prototype, which incorporates global selection, can mitigate Mamba's local pattern shortcut issue and assess its performance on real-world downstream tasks."}, {"title": "5.1 Experimential Settings", "content": "Datasets We selected tasks where the original Mamba exhibited clear shortcuts and performed poorly. The settings are the same as outlined in Sec. 3. For the Shuffle and K2V2 settings, models are trained and tested on the same corresponding setting. We evaluate the model's in-domain capabilities in scenarios with increased information density and dispersion. In contrast, the Last and Std-Shuffle tasks test the model's out-of-domain performance, where the testing mode is inconsistent with the training one, i.e., training on the standard position pattern and testing on the Last and Shuffle pattern. In the K2V2-Robustness and K4V8-Shuffle settings, we evaluate whether the models can mitigate the influence of noise as well as handle tasks with both high information density and divergence.\nFor downstream tasks, we evaluate whether the global selection strategy negatively impacts or enhances downstream task performance. Following previous works, we report perplexity on Wikitext (Wiki.) (Paine et al., 2016) and additional tasks such as PIQA (Bisk et al., 2020), HellaSwag (Zellers et al., 2019), and Winogrande (Sak-"}, {"title": "5.2 Main Result", "content": ""}, {"title": "5.2.1 Synthetic Tasks", "content": "Attention-based Model As depicted in Tab. 3, Pythia performs nearly perfectly across all tasks, as expected, given that attention-based models excel at accurately identifying the corresponding correct answers through pairwise token interactions. Unlike models constrained by state size, attention-based models inherently capture long-range dependencies by attending to the entire input sequence.\nOther RNN-based Models In contrast to attention-based models, rnn-based models perform significantly worse across all tasks, reflecting their inherent limitations on the MQAR task requiring dynamic state adaptation due to their fixed state space size. However, neither Hyena nor RWKV exhibits the positional pattern shortcut observed in Mamba, as they do not show an obvious gap between in-domain and out-of-domain performance. Additionally, despite trailing Mamba in the standard K2V2 tasks, both models show comparable performance against Mamba in the K2V2-Robustness setting. This suggests that Mamba is more susceptible to noise, likely due to its reliance on n-gram shortcuts. These observations further suggest that Mamba's shortcut behavior is closely tied to its unique selective mechanism, which prioritizes local patterns over the global context due to the constrained At.\nMamba With regard to the strategies posed on Mamba, they both yield improvements across most"}, {"title": "5.3 Downstream Task", "content": "While the synthetic tasks provide valuable insights into how Global Selection mitigates shortcut behavior in Mamba, it is critical to assess how these improvements transform into real-world downstream tasks. As shown in Table 4, Mamba has already demonstrated notable success on downstream tasks, surpassing the performance of the attention-based baseline model, Pythia. The introduction of Global Selection further enhances Mamba's performance in language modeling and commonsense reasoning tasks. The Global Selection strategy consistently achieves the best results across all evaluated tasks, underscoring its effectiveness across different domains. The most significant improvements are observed in the language modeling task, where the perplexity is reduced by 1.54 when compared to the original Mamba, underscoring the model's enhanced ability to handle long-range dependencies and avoid over-reliance on local patterns."}, {"title": "6 Conclusion", "content": "In this work, we extend the MQAR task to investigate Mamba's underlying behavior. Our controlled"}, {"title": "Limitation", "content": "Our approach is primarily focused on experimentally analyzing the shortcut phenomenon in Mamba; further exploration of theoretical insights is needed. The proposed method aims to address the shortcut issues observed in Mamba on synthetic tasks. However, further improving performance on downstream tasks may require additional adaptations and comprehensive testing across a wider range of models with varying scales. While preliminary results indicate that similar shortcuts were not present in other rnn-based models, further validation is needed to determine whether our findings generalize across diverse architectures."}, {"title": "7 Appendix", "content": ""}, {"title": "4.3.1 Model Architecture", "content": "Give the sequence Y = {Y1, Y2, , YL} that contains L tokens, we leverage Equ. 1 to calculate each Yi and reformulate the calculation process into matrix multiplication, which can be written as:\n$$Y = \\begin{pmatrix}Y_1 \\\\ Y_2 \\\\ : \\\\ Y_L\\end{pmatrix} = \\begin{pmatrix} a_{1,1} & a_{1,2} & ... & a_{1,L} \\\\ a_{2,1} & a_{2,2} & ... & a_{2,L} \\\\ : & : & ... & : \\\\ a_{L,1} & a_{L,2} & ... & a_{L,L}\\end{pmatrix} \\begin{pmatrix}X_1 \\\\ X_2 \\\\ : \\\\ X_L\\end{pmatrix}$$\nwhere ai,j = Ci (\u220fk=j+1 Ak) Bj (i, j \u2208 [1, L]). Then, we can transform Equ. 4 into an attention-like matrix by substituting and expanding ai,j:\n$$\\begin{pmatrix}Y_1 \\\\ Y_2 \\\\ : \\\\ Y_L\\end{pmatrix} = \\begin{pmatrix}C_1 B_1 & 0 & ... & 0 \\\\ C_2A_2 B_1 & C_2 B_2 & ... & 0 \\\\ : & : & ... & : \\\\ C_L \u220fk=2 A_k B_1 & C_L \u220fk=3 A_k B_2 & ... & C_L B_L\\end{pmatrix} \\begin{pmatrix}X_1 \\\\ X_2 \\\\ : \\\\ X_L\\end{pmatrix}$$\nwhere the portion enclosed by the underbrace represents the weights allocated by Mamba across the sequence, and we visualize this part to explore Mamba's state space."}]}