{"title": "A Comprehensive Evaluation of Cognitive Biases in LLMS", "authors": ["Simon Malberg", "Roman Poletukhin", "Carolin M. Schuster", "Georg Groh"], "abstract": "We present a large-scale evaluation of 30\ncognitive biases in 20 state-of-the-art large\nlanguage models (LLMs) under various\ndecision-making scenarios. Our contributions\ninclude a novel general-purpose test framework\nfor reliable and large-scale generation of\ntests for LLMs, a benchmark dataset with\n30,000 tests for detecting cognitive biases in\nLLMs, and a comprehensive assessment of\nthe biases found in the 20 evaluated LLMs.\nOur work confirms and broadens previous\nfindings suggesting the presence of cognitive\nbiases in LLMs by reporting evidence of all\n30 tested biases in at least some of the 20\nLLMs. We publish our framework code to\nencourage future research on biases in LLMs:\nhttps://github.com/simonmalberg/cognitive-\nbiases-in-llms.", "sections": [{"title": "Introduction", "content": "Transformer-based LLMs (Vaswani, 2017) and\nother Foundation Models (e.g., Gu and Dao, 2023)\nhave gained significant attention in recent years. At\nan accelerating pace, models are becoming larger\nand more capable, conquering additional modal-\nities such as vision and speech (Shahriar et al.,\n2024). This makes LLMs increasingly attractive\nfor complex reasoning (Dziri et al., 2024; Saparov\nand He, 2022) and decision-making tasks (Eigner\nand H\u00e4ndler, 2024; Echterhoff et al., 2024). How-\never, using LLMs for high-stakes decision-making\ncomes with severe risks, as they may produce\nflawed yet convincingly articulated outputs, such\nas hallucinations (Zhang et al., 2023).\nHumans are at most boundedly rational (Simon,\n1990) and biased (Tversky and Kahneman, 1974).\nLLMs are trained on human-created data and typ-\nically fine-tuned on human-defined instructions\n(Ouyang et al., 2022) and through Reinforcement\nLearning from Human Feedback (RLHF) (Bai et al.,\n2022). Therefore, it is likely that human biases also"}, {"title": "Related Work", "content": "Cognitive Biases in LLMs Recently, LLMs'\npresence in high-stakes decision-making has\nrapidly become ubiquitous (Wu et al., 2023; Sing-\nhal et al., 2023). In the pursuit of explainable and\ntrustworthy models, it is imperative to extend the\ntraditional scope of biases, e.g., gender and ethical\nones (Gallegos et al., 2024), to account for biases\nand heuristics of cognition that directly impact the\nrationality of LLMs' judgments (Hagendorff et al.,\n2023).\nEarlier works in this direction (Talboy and Fuller,\n2023; Macmillan-Scott and Musolesi, 2024) fo-\ncused on detecting effects on the level of individual\nprompts. Separate research directions investigated\nchallenges of cognitive bias detection and mitiga-\ntion for lists of less than six cognitive biases (Tju-\natja et al., 2024; Itzhak et al., 2024), particular\nLLM roles (Pilli, 2023; Koo et al., 2023; Ye et al.,\n2024), or specific domains (Schmidgall et al., 2024;\nOpedal et al., 2024).\nWith the aim of having a large-scale benchmark\nfor cognitive biases in LLMs, follow-up works pro-\nposed a number of frameworks. Notably, a frame-\nwork proposed by Echterhoff et al. (2024) encap-\nsulates quantitative evaluation and automatic miti-\ngation of cognitive biases; however, its variability\nis constrained to only five biases and a single sce-\nnario of student admissions \u2013 two limitations we\ndirectly address in this paper. The recent contribu-\ntion of Xie et al. (2024) explores a similar direction\nthrough multi-agent systems. Their framework,\nsimilar to our approach, requires user-defined, bias-\nspecific input and employs an LLM for the gen-\neration of the dataset; however, their construction\nadditionally involves expert post-validation as the\ntests are entirely generated by the LLM. We pro-\npose a way to overcome this limitation while not\ncompromising on the validity and diversity of the\ndataset (see Section 3).\nThe development of a scaleable, systematic, and\nexpandable benchmark would allow for further\nprogress in the task of comprehensive mitigation of\ncognitive biases in LLMs (e.g., Wang et al., 2024a)\nand thus comprises the main motivation for this\npaper.\nLLMs as Data Generators Labeling, assem-\nbling, or creating large amounts of data with de-\nsired properties have always been associated with\nhigh costs and significant labor. Moreover, this pro-\ncess is inherently intricate due to the annotator's"}, {"title": "Test Framework", "content": "We introduce a novel framework for reliably gener-\nating diverse and large-scale sets of tests for evalu-\nating LLMs. The main motivation for the creation\nof the framework was to efficiently scale tests that\nhave a static abstract paradigm (that is based on\ncorresponding research and has to be strictly fol-\nlowed) by generating diverse contexts around it.\nThe framework comprises four entities and three\nfunctions. Entities hold together certain pieces\nof information, while functions transform entities\ninto other entities. All entities and functions are\nexplained in the following. We use lower case let-\nters t, s, c, r, b, ... to denote entities and their con-\ntents. Functions are denoted by upper case letters\nG, D, E. Some functions use an LLM internally.\nWe use $f_\\theta$ (inside G) or $h_\\theta$ (inside D) to denote a\npre-trained LLMs with parameters \u03b8.\nAmong the entities, only a few starting entities\nare human-created; all other entities are created\nby applying functions to the starting entities. Ta-\nble 1 provides an example illustrating the main en-\ntities and Figure 2 shows the pipeline of functions\nthrough which entities flow."}, {"title": "Entities", "content": "Template A template t = [x, g,p] includes a\nlanguage sequence x = ($x_1$,..., $x_n$) of n tokens\n$x_i$. Some of these tokens represent gaps, with g =\n{$x_j, x_k$, ...} being the set of all gaps in x. Each gap\n$x_i$ \u2208 g comes with a corresponding instruction $p_i$\nexplaining the rules of what may be inserted into\nthe gap, with p = {$p_j, p_k$, ...} being the set of all\ngap instructions.\nIntuitively, a template is a generalized descrip-\ntion of a decision task with x including a situ-\nation description, a prompt or question, and a\nset of options to choose from. Given a template\nt, multiple specific instances t' of that template\ncan be created by inserting additional information\n$x_i$\u2190 ($z_1$, ..., $z_m$) into all gaps $x_i$ \u2208 g according to\nthe instructions $p_i$. See Table 1 for an illustration\nof how templates work.\nTest Case A test case c = [$t_1, t_2$, v, m] binds\ntogether two templates $t_1$ and $t_2$, a set of custom\nvalue generators v = {$v_1, v_2$, ...} and a metric m."}, {"title": "Functions", "content": "Decision Result A decision result $r_{c'}^{h_\\theta}$ =\n[$a_1, a_2$] stores the answers of an LLM $h_\\theta$ to a test\ncase c'. The answers $a_1$ and $a_2$ are provided to\ntemplate instances $t_1, t_2$ \u2208 c', respectively. A valid\nanswer chooses exactly one of the options defined\nin a template instance.\nGenerate A test generator G($f_\\theta$, c, s) takes an\nLLM $f_\\theta$, a test case c, and a scenario s to sample\na test case c' ~ G($f_\\theta$, c, s) by inserting values\ninto the template gaps. These insertions can be ei-\nther sampled from the LLM $f_\\theta$ or from the custom\nvalue generators {$v_1, v_2$, ...} \u2208 e according to the\ntemplate instructions p and scenario s. Which in-\nsertions are sampled from the LLM versus from the\ncustom values generators is defined in the specific\ntest generator, which is designed in close alignment\nwith the corresponding templates.\nIn our framework implementation, the two\ntemplate instances are sampled in two indepen-\ndent LLM calls $t'_1$ ~$f_{GEN}$($t_1$,s) and $t'_2$ ~\n$f_{GEN}$($t_2$, s), where GEN denotes the particular\nLLM prompt used for generation (see Appendix D).\nHowever, identical gaps that exist in both templates,\ni.e., $g_1$ \u2229 $g_2$, $g_1$ \u2208 $t_1$,$g_2$ \u2208 $t_2$, will only be filled\nonce for $t_1$ and their insertions will then be copied\nover to $t_2$ to ensure consistency between the tem-\nplate instances. The GEN prompt provides the\nLLM with the template as illustrated in Table 1 and\ninstructs the LLM to suggest suitable insertions for\nthe gaps resembling the scenario.\nDecide The decide function D($h_\\theta$, c') uses a po-\ntentially different LLM $h_\\theta$ to decide on answers\n$a_1$ and $a_2$ to the two templates $t'_1, t'_2$ \u2208 c', respec-\ntively. The answers are sampled in two independent\nLLM calls, $a_1$ ~ $h_{DEC}$($t'_1$) and $a_2$ ~ $h_{DEC}$($t'_2$),\nwhere DEC is the LLM prompt used for retrieving\ndecisions (see Appendix D). We implement DEC\nas two prompts, where the first lets the LLM freely\nreason about the answer options before ultimately\nchoosing one and the second instructs the LLM to\nextract only the chosen option from its previous\nresponse. Once both answers have been obtained\nfrom the LLM, they are returned in a decision result\n$r_{c'}^{h_\\theta}$ ~ D($h_\\theta$, c').\nEstimate The estimate function E(c', $r_{c'}^{h_\\theta}$) = b estimates the score of the test case, a value b,\nusing the metric m \u2208 c' on the answers $a_1, a_2$ \u0395\n$r_{c'}^{h_\\theta}$. For simplicity, we suggest to define m such\nthat b\u2208 [-1,1]. The exact metric used in our\nimplementation is introduced in Section 4.5."}, {"title": "Framework Application to Cognitive Bias Tests for LLMs", "content": "The general-purpose framework described in Sec-\ntion 3 allows for conducting scaleable tests of vari-\nous kinds (see Appendix A for examples). In this\nsection, we introduce our specific application of the\nframework to measuring cognitive biases in LLMs."}, {"title": "Bias Selection", "content": "We aim to identify a subset of cognitive biases most\nrelevant to managerial decision-making. As a start-\ning point, we chose the Cognitive Bias Codex info\ngraphic (III and Benson, 2016), as also done by\nAtreides and Kelley (2023). The graphic lists and\ncategorizes 188 cognitive biases. To identify the\nsubset of these biases most relevant in managerial\ndecision-making, we assessed the number of pub-\nlications that mention the bias in a management\ncontext, as found through Google Scholar\u00b9. The\nexact search query we used is\n\"{bias}\" AND (\"decision-making\"\nOR\n\"decision\")\nAND\n(intitle:\"management\"\nOR\nintitle:\"managerial\")\nWe ranked all 188 cognitive biases by the num-\nber of identified search results and selected the\n30 most frequently discussed biases. We removed\nthree biases from the list where we found no testing\nprocedure applicable to LLMs and two biases that\nappeared to be semantic duplicates of other biases\nwe already included. We replaced them with the\nfive biases following in the ranked list (see Table 5\nin Appendix C for details).\nBased on the available scientific literature, we\ndesigned a unique test case c and corresponding\ntest generator G for each of the top 30 cognitive bi-\nases. We aimed to define the test case templates to\nreflect the minimum viable test design and included\ngaps for specifics about a scenario. An example\ntest can be seen in Table 1. A detailed collection\nof scientific references and description of the ex-\nact test designs for all 30 biases can be found in\nAppendix B."}, {"title": "Scenario Generation", "content": "To increase the diversity of our tests, we generated\na set of 200 unique management decision-making\nscenarios. A scenario includes a specific manager\nposition, industry, and decision-making task, e.g.,\n\"A clinical operations manager at a com-\npany from the pharmaceuticals, biotech-\nnology & life sciences industry deciding\non whether to proceed with Phase 3 trials\nafter reviewing initial Phase 2 results.\"\nWe generated these scenarios in three steps.\nFirstly, we extracted the 25 industry groups de-\nfined in the Global Industry Classification Stan-\ndard (GICS) industry taxonomy (MSCI and Global,\n2023). Secondly, we prompted a GPT-40 LLM with\ntemperature=1.0 to return 8 commonly found\nmanager positions per industry group. Thirdly, we\nprompted the LLM a second time to generate a suit-\nable decision-making situation for each manager\nposition in an industry group.\nWe combined industry groups, manager posi-\ntions, and decision-making situations into 200 sce-\nnario strings and manually reviewed all of them.\nWe identified three industry groups with at least one\nimplausible scenario and regenerated their scenario\nstrings using a different seed."}, {"title": "Dataset Generation", "content": "Our full dataset is generated by sampling 5 test\ncases for each of the 200 scenarios and 30 cogni-\ntive biases, resulting in 30,000 test cases in total.\nWhile the 200 scenarios serve as the main source"}, {"title": "Dataset Validation", "content": "We performed validation of the generated dataset\nfrom two perspectives: correctness, i.e., how well\nthe gap insertions in test cases are aligned with\ntheir corresponding instructions $p_i$, and diversity,\ni.e., how dissimilar the test cases c' are to each\nother.\nCorrectness This stage comprises two proce-\ndures. Firstly, we randomly selected 300 samples\nfrom our dataset, 10 samples per each of the 30\nbiases, and performed manual verification. In total,\nwe identified 3 test cases with flaws that could po-\ntentially impact the test logic; of these, 2 tests fall\ninto the scope of the validation procedure on the\nnext step.\nSecondly, we used the IFEVAL framework\n(Zhou et al., 2023) to evaluate the instruction-\nfollowing performance w.r.t. verifiable instructions\n(e.g., \"Do not include any numbers.\u201d). Test cases\nof 7 biases include instructions $p_i$ that contain con-\nstraints crucial for the cognitive biases' testing de-"}, {"title": "Bias Measurement", "content": "To consistently obtain decisions $a_1$ and $a_2$, two\noption scales are defined for our test cases. More\nconcretely, we use a 7-point Likert scale $\\sigma_1$ for\nsome test cases and an 11-point percentage scale\n$\\sigma_2$ for others to define the domain of answers. In\nline with common practice (Wu and Leung, 2017),\nwe treat the Likert scale as an interval one.\nIn order to quantify the presence and strength of\ncognitive biases based on the decisions $a_1$ and $a_2$,\nwe introduce the following single universal metric\nm\u2208 [-1,1]:\n$m\\ (a_1,a_2,\\gamma_1,\\gamma_2,k)=\\kappa\\cdot\\frac{\\left(\\vert\\Delta_{a_1,\\gamma_1}\\vert -\\vert\\Delta_{a_2,\\gamma_2}\\vert \\right)}{\\max \\left[\\vert\\Delta_{a_1,\\gamma_1}\\vert ,\\vert\\Delta_{a_2,\\gamma_2}\\vert \\right]}$", "number": 1}, {"title": "Selection of LLMs", "content": "We hypothesize that the susceptibility of LLMs for\ncognitive biases may be influenced by factors such\nas model size, architecture, and training procedure.\nTherefore, we decide to evaluate a broad selection\nof 20 state-of-the-art LLMs from 8 different de-\nvelopers and of vastly different sizes. A list of all\nevaluated models with further details is included\nin Appendix E. As baseline, we also add a Random\nmodel that chooses answer options at random. We\nevaluate all LLMs with temperature=0.0. To ac-\ncount for the well-observed LLMs' bias w.r.t. the\norder of options (Zheng et al., 2023), we reverse\noptions' order in randomly selected 50% of tests."}, {"title": "Results & Discussion", "content": "A perspective on the absolute biasedness of the\nmodels in relation to other model characteristics"}, {"title": "Limitations", "content": "Our paper provides a systematic framework for\ndefining and conducting cognitive bias tests with\nLLMs. While we have demonstrated our pipeline\nusing management decision-making as an example\nand established a respective dataset with 30,000\ntest cases for cognitive biases, our framework is\ntheoretically generalizable beyond just this domain\nand task. We provide some illustrative examples\nof applying our framework to other domains and\ntest kinds in Appendix A but rely on future work\nto assess the framework's versatility at scale. Our\nframework balances LLM generation and its bene-\nfit of cost-effectiveness with human control through\ntemplates with generalized instructions, which are\nsimilarly beneficial for other decision-making do-\nmains and use cases.\nWhile over 180 cognitive biases are known in\nhumans (III and Benson, 2016), our current dataset\nprovides test cases for 30 of these biases. Our se-\nlection procedure utilized mentions in publications\nas an indicator for the relevance of biases in the\nchosen domain of managerial decision-making. As\nthis may not be a perfectly reliable indicator for\nrelevance and there are still over 150 cognitive bi-\nases not covered in our dataset, we invite other\nresearchers to design tests for additional biases and\ndomains.\nOur test cases were generated with only one\nmodel, a GPT-40 LLM, chosen for its capabilities\nat the time of development. We also evaluate the\nsame LLM on the dataset, which may give it an un-\nfair advantage. We assume this influence to be low\ndue to the detailed instructions in the templates giv-\ning the generating LLM clear restrictions on what\nto generate and how. Looking ahead, we anticipate\nthat the majority of LLMs will soon possess the\ncapability of generating test cases reliably. This\ndevelopment paves the way for a more widespread\nand effective application of our framework in the\nfuture.\nIn our evaluation, biasedness was calculated us-\ning discrete decisions made by the LLMs. Future\nwork can also take into account token probabili-\nties for an even more nuanced measurement and\ncomparison of cognitive biases in LLMs."}, {"title": "Ethical Considerations", "content": "Our cognitive bias dataset of 30,000 test cases is\none of the significant contributions of this paper.\nWith this dataset, we also provide test cases for"}, {"title": "Framework: Application Examples", "content": "We demonstrate two examples of the framework's\nuniversality feature. Table 4 features an adaptation\nof the Bandwagon Effect testing procedure to the\nmedical domain. Table 3 provides an example of a\ncommon testing procedure from the theory of mind\nresearch."}]}