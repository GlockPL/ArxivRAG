{"title": "A Review of Mechanistic Models of Event Comprehension", "authors": ["Tan T. Nguyen"], "abstract": "This review examines theoretical assumptions and computational models of event comprehension, tracing the evolution from discourse comprehension theories to contemporary event cognition frameworks. The review covers key discourse comprehension accounts, including Construction- Integration, Event Indexing, Causal Network, and Resonance models, highlighting their contributions to understanding cognitive processes in comprehension. I then discuss contemporary theoretical frameworks of event comprehension, including Event Segmentation Theory (Zacks et al., 2007), the Event Horizon Model (Radvansky & Zacks, 2014), and Hierarchical Generative Framework (Kuperberg, 2021), which emphasize prediction, causality, and multilevel representations in event understanding. Building on these theories, I evaluate five computational models of event comprehension: REPRISE (Butz et al., 2019), Structured Event Memory (SEM; Franklin et al., 2020), the Lu model (Lu et al., 2022), the Gumbsch model (Gumbsch et al., 2022), and the Elman and McRae model (2019). The analysis focuses on their approaches to hierarchical processing, prediction mechanisms, and representation learning. Key themes that emerge include the use of hierarchical structures as inductive biases, the importance of prediction in comprehension, and diverse strategies for learning event dynamics. The review identifies critical areas for future research, including the need for more sophisticated approaches to learning structured representations, integrating episodic memory mechanisms, and developing adaptive updating algorithms for working event models. By synthesizing insights from both theoretical frameworks and computational implementations, this review aims to advance our understanding of human event comprehension and guide future modeling efforts in cognitive science.", "sections": [{"title": "Introduction", "content": "Since the advent of the concept \u201csituational model\u201d (Johnson-Laird, 1983), many researchers have argued that the construction of a coherent situation model is tantamount to the successful comprehension of a text (van Dijk and Kintsch 1983; Glenberg and Langston 1992; Graesser, Millis, and Zwaan 1997; Graesser, Singer, and Trabasso 1994; Zwaan, Graesser, and Magliano 1995). This change in the definition of the notion of comprehension shifts the research problem from the general, \"How do readers comprehend a text?,\" to the more specific, \"How do readers construct a coherent situation model?\" (Zwaan and Radvansky 1998). This shift in focus underscores the importance of coherence in the mental representation of a text. Coherence itself can be further dissected into two: local and global coherence. Local coherence pertains to the immediate connections made between adjacent units of text, such as words, ideas, or sentences. These local connections facilitate a reader's understanding of the text in small chunks. Global coherence, on the other hand, refers to the organizational structure established within a broader discourse context, where local chunks of information are organized and interrelated into higher order chunks (Graesser et al. 1994). Both types of coherence emphasize the process of connecting disparate elements within a text to form a mental representation of interrelated elements.\nCognitive scientists have developed theories of the representation of knowledge, characterizing the way in which knowledge is structured so that progress can be made toward other important questions: how is old memory employed in the acquisition of new memory? How does structured knowledge facilitate comprehension? How does our current knowledge state modulate our actions? (Rumelhart and Ortony 1977). Accounts of knowledge representation proposed that knowledge is represented as frames"}, {"title": "Conceptual models of discourse and event comprehension", "content": "In the early days, researchers use discourses (texts) to study comprehension and memory processes. Part of the reason is that texts provide a convenient modality for presenting stimuli, and another reason is that text comprehension is supported by a variety of cognitive processes, many of which are assumed to be relevant to comprehension beyond text (McNamara and Magliano 2009:9). In what follows, I will briefly describe key features of four theories of discourse comprehension: Construction-Integration, Event Indexing Model, Causal Network Model, and Resonance model, and identify points that are relevant to modeling event comprehension. For a more comprehensive review of discourse comprehension theories, please see (McNamara and Magliano 2009).\nThe Construction-Integration (CI) model focused on the processes that give rise to discourse comprehension. The model essentially assumes a two-step cognitive process: construction and integration. Initially, when you read a sentence, the Construction phase kicks off by activating information in the text and related knowledge. Then, this cloud of activated concepts undergoes a refining process-Integration-where closely related concepts are strengthened, while isolated concepts are weakened. This leads to a stable state where the activation of concepts doesn't change much. The Cl model assumes that a sentence that is read comprises three levels of representation: surface structure, propositional textbase, and situation model (van Dijk and Kintsch 1983; Kintsch 1988, 1998; Sanjose, Vidal-Abarca, and Padilla 2006). Of interest is the propositional textbase level, which is assumed to be the fundamental unit of representation. A proposition consists of a \"predicate\" and its \"arguments,\" and typically conveys a single complete idea in the form predicate(argument, argument). For example, the sentence \u201ca dog chases a cat\u201d can be represented symbolically as chase(dog, cat). Discourse and event comprehension computational models must be able to address the challenge of extracting propositions from texts or videos. The Cl model argues that 'argument overlap' is a sufficient basis for connecting propositions, effectively linking mental representations to achieve coherence (Giora 1985; Magliano, Trabasso, and Graesser 1999; Zwaan et al. 1995)."}, {"title": "Contemporary event comprehension accounts", "content": "Researchers started to develop event comprehension theories applicable to other modalities (audio/visual). Although discourse models assume predictive inferences are strategic processes and readers do not always engage in predicting the future (Allbritton 2004; McDaniel, Schmalhofer, and Keefe 2001), event comprehension accounts assume that prediction is a key component in comprehension and memory processes and people generate predictions continually during comprehension. In what follows, I will describe prevalent event comprehension theories while identifying key computational challenges that event modelers need to address. Then, I will try to set up a framework to describe contemporary computational models of event comprehension.\nEvent Segmentation Theory (EST) (Zacks et al. 2007) posits that our cognition is inherently predictive. It suggests that humans and animals are continuously trying to forecast what will happen in their immediate future. This is useful because it helps us prepare for what's coming. In real life, it is common to encounter situations where all necessary information is not available. This could be due to lapses in attention, inability to see certain things, or even the inherent limitations of our sensory systems. To bridge these gaps, the mind employs \"event models.\" These are mental representations that blend immediate sensory input with long-term schematic knowledge (event schemas), offering a stable picture of the immediate situation. Event schemas encode knowledge about how an event (e.g. going to a restaurant) typically unfold, and they are acquired by learning from repeated experiences. This raises an important question: how are event schemas represented and learned? Event models encode what is currently relevant to one's goals and are multimodal, meaning they combine different kinds of sensory. One of the key features of event models is that they are generally kept stable by isolating them from continuous sensory input. This is crucial because it allows the model to provide a consistent interpretation of the world, especially when faced with transitory information. However, this doesn't mean that working models are static. They need to be adaptable to changing circumstances. When and how are the stable working event models updated? EST suggests that the mechanism for this adaptability lies in monitoring \"prediction error,\" the difference between our anticipations and actual occurrences. When this error spikes, it indicates that our current working model is no longer sufficiently accurate, triggering an update. This updating process opens the event model to new information for a brief window, both from our current sensory perceptions and from our long-term understanding of similar situations (schematic knowledge), thereby forming a revised mental representation. Updating event models based on prediction errors implements a form of cognitive control: when to actively takes in sensory input and update working memory content. Event Segmentation Theory (EST) proposes that individuals maintain event models across different timescales simultaneously. This raises a mechanistic question: How does coarser event models influence finer event models, and vice versa? In other words, how does information flow across hierarchies?\nEvent Horizon Model (Radvansky and Zacks 2014) elaborates EST further. According to the Event Horizon Model, humans innately track the cause-and-effect relationships between events. This aids in forecasting future events and acting adaptively. For instance, if you learn that a specific cloud formation often leads to rain, you might carry an umbrella the next time you see those clouds. Causality can also help segment events. From the viewpoint of EST, causal breaks serve as cues for event segmentation because they correspond to moments where prediction becomes difficult. Additionally, when there is a causal discontinuity in a narrative text, a plausible cause must be inferred, and this causes a new event model to be created. Causal relations are part of schematic knowledge, and the centrality of causality in discourse and event comprehension theories raise an important question: how causal relations are learned?\nKuperberg (2021) proposed a hierarchical generative framework to model event comprehension. The core of this proposal is a three-level hierarchical generative model. Level 3 represents probabilities over possible goals of the agent. Each goal is associated with a relevant schema, and a range of possible end states. Event models are represented at level 2, encoding what has happened, what is happening, and what might happen next. The predicted and observed stimuli are represented at level 1. This framework provides an account how information flows across different levels of representations. Within each two- level, information represented at the higher level is actively propagated down, through feedback connections, to reconstruct activity at the lower level: goals probabilistically predict possible event models, event models probabilistically predict possible upcoming stimuli. The reconstructed state of activity at the lower level (e.g. level 1) is then subtracted from the state that is induced when new stimuli appear. Only the difference in activity (i.e. errors) is passed back up to the higher level (e.g. level 2) via feedforward connections (Clark 2013; Friston 2005; Friston et al. 2016; Rao and Ballard 1999). When this bottom-up prediction error reaches the higher level (e.g. level 2), it induces an update in level 2 representations. As each new input becomes available from the environment, this process is repeated until the magnitude of the bottom-up prediction error is minimized. For example, when a new scene is observed at the first level, prediction error is computed and fed to the second level, and the event model is updated. The newly inferred event model, in turn, probabilistically predicts upcoming scenes at that moment in time. In short, higher levels project predictions to the lower levels, and only errors are propagated backward. Under this framework, an event boundary is experienced by the observer when there is a shift the probability distribution over possible goals-when the observer believes that the goal of the agent has changed. This detection can be achieved through two means. First, the model monitors prediction errors and update goal distribution because of errors propagated from level 2. Second, the model monitors uncertainty over goals, which rises when end state associated with the current goal is attained, to update goal distribution. This raises a question: how are end states associated with a goal or an event schema is learned?"}, {"title": "Computational models of event comprehension", "content": "In this section, I will describe how each model addresses questions posed in the previous section through operationalizing placeholders in Fig. 1. Note that all computational event models are tasked to predict the next sensory information given what has been observed."}, {"title": "Comprehension processes give rise to hierarchical structured representations", "content": "Schematic knowledge about events specifies how an event might unfold, and a range of possible end states. The human event comprehension system needs to learn various capacities to achieve that end. Schematic knowledge encodes how information in the space of modality-specific perceptual details used to construct higher-level multimodal representations where changes are smoother and slower. Schematic knowledge encodes how multimodal representations might evolve over time. Schematic knowledge also encodes how multimodal representations exert predictions of upcoming perceptual details. Event comprehension models propose mechanisms to achieve those computational goals. Thus, to compare how different models represent and learn event schemas, we need to compare their assumptions regarding: 1) hierarchical structure, 2) top-down influences, 3) bottom-up propagations, and 4) lateral dynamics within each level, 5) event schema learning, and 6) end states learning."}, {"title": "Hierarchical Structure", "content": "In the SEM and REPRISE models, event representations are organized across three distinct levels. The first level, the scene level, is essentially the input/output of recurrent neural networks (RNNs). This level captures the immediate features of an event. The second level, referred to as the latent states, is represented by the hidden units within the RNNs. These hidden units capture underlying factors that are not be directly observable but play a critical role in influencing the scenes. Finally, the third level represents event types. In REPRISE (Butz et al., 2019), event type is defined by a vector while in SEM event type is defined by a categorical variable. This difference has implications in how top-down influence is assumed in the two models, described in the next section.\nThe Lu model (Lu et al. 2022), the Gumbsch model (Gumbsch et al. 2022) and the Elman and McRae (Elman and McRae 2019) model implemented two-level architectures: level 1 representing observable scenes, level 2 representing latent states of scenes using hidden units of an RNN. These models do not dedicate specific components to represent event types. The reason that the Lu model and the Elman and McRae model do not have representations of event types is that modelers are not interested in how or when humans detect changes in event types-event boundaries. In the Gumbsch model, event boundaries are conceptualized as changes in the hidden layer vector, whereas, in SEM and REPRISE, event boundaries are conceptualized as changes in the context vector.\nIn the five models, one general theme is that hierarchy is an inductive bias that modelers embed in their models. Moreover, the number of hierarchies is a hyper-parameter. However, one could assume that the shape of the hierarchy that a model comes to represent depends on the hierarchical structure of the environment. This raises two important questions for future modeling work: Is there a way to non- parametrically learn the number of hierarchical levels instead of treating it as a hyper-parameter? Relatedly, what are the mechanisms to spawn a new level? After a new level is spawn, one also need to specify top-down, bottom-up, and lateral dynamics. One approach is to first learn one level of representation and then gradually chunk these units into higher level representation, as demonstrated by the Hierarchical Chunking Model (Wu et al. 2021). Hierarchical Chunking Model works like hierarchical clustering algorithms, and thus it requires a hyper-parameter to decide when and how to group units into larger chunks."}, {"title": "Mechanisms for top-down influence", "content": "SEM and REPRISE proposed three-level models while the Lu, the Gumbsch, and the Elman and McRae models proposed two-level models. In REPRISE, between context layer (level 3) and hidden layer (level 2), representations at the higher level (context layer) is propagated down, through feedback connections, to modulate activity at the lower level (hidden layer). In SEM, because each event schema is defined as a separate set of RNN weights (W_hidden, W_out, W_in), hidden layer vector is influenced by event type (via W_hidden). Moreover, top-down influence from hidden layer to sensory layer is also modulated by event type (via W_out) in SEM. In other four models, sensory predictions at level 1 are determined solely by the hidden layer vector at level 2. The common assumption among models is that sensory prediction of the next timestep is a function of latent states and event types, which is also the assumption in latent cause inference models (Gershman et al. 2014; Shin and DuBrow 2021)."}, {"title": "Mechanisms for bottom-up propagation", "content": "In a hierarchy, representations of a higher level can be constructed through two means. The first way is to construct increasingly abstract feature hierarchies, by using larger input context later in the hierarchy; this approach is typically implemented in convolutional networks, where units in a higher level have a larger receptive field and compute non-linear transformations of lower units, or recurrent neural networks, where units in a higher level serves as a low-dimensional information compression of the lower level. In this view, the feedforward information includes representations of the lower level. The second way is to infer representations of a higher level that best explain representations in a lower level, based on learned knowledge. The learned knowledge encodes a generative model to reconstruct representations of the lower level given activations of the higher level. Reconstructed representations are compared against observed representations at the lower level, and prediction errors are propagated upward (feedforward) to adjust higher level representations. In this view, feedback connections carry representations, but feedforward connections carry prediction errors.\nIn all five models, between sensory layer (level 1) and hidden layer (level 2), sensory observation is propagated upward to hidden layer through feedforward connections to construct representations at level 2. In REPRISE, sensory prediction errors are propagated upward to both hidden layer (level 2) and context layer (level 3), through retrospective neural inference-updating unit activations of hidden layer vector and context vector based on errors. In SEM, prediction errors at level 1 do not influence level 2 representations (hidden layer vector) but could directly influence representations at level 3: if sensory prediction errors at level 1 is high, the models will infer a different event type (level 3). This comparison highlights that SEM and REPRISE models implicitly adopt the view that both representations and errors are propagated upward, whereas the other three models implicitly assume that only representations are propagated upward.\nEvent segmentation theory proposed that perceptual information is gated and could only get through the gate after event boundaries. Only in the Gumbsch model, sensory observation is gated by a learnable module (GateLORD). In addition, the Gumbsch model also adds a latent gate, assuming that the content of event models are constant most of the time. Future work might add perceptual or latent gates to other models to evaluate these hypotheses."}, {"title": "Mechanisms for lateral dynamics at each hierarchical level", "content": "All five models all use variants of a recurrent neural network. In a typical recurrent neural network, previous scenes (level 1) do not directly influence the current scene. However, previous hidden unit activations (level 2) directly influence the current hidden unit activations (via W_hidden)-this defines how working event models evolve over time. These features of the typical RNNs are true for all models.\nIn REPRISE, previous event type representations (level 3) are copied directly to the current event type representations. In SEM, event type dynamics is governed by sticky-Chinese Restaurant Process, which assigns a high probability on the previous event type relative to the possibility of switching to a different event type (fig. 3A, Bayesian Inference module); these are hyper-parameters in the model. In short, level 3 lateral dynamics are not learned but are priors in the two models. One can imagine extend these models by specifying learning rules at this level. For REPRISE, since the representation at level 3 is a context vector, it is reasonable to impose recurrent connections among context vectors across time, parallel to the level 2 connections among hidden unit vectors. Inductive biases about timescales of updating at each level can be embedded by adding penalization terms into loss functions, an approach that was used in GateLORD. For SEM, since representation at level 3 is a categorical variable and not a vector, learning lateral dynamics across event types can be implemented by a learnable Markov transition matrix. This approach might provide a better prior than the sticky Chinese Restaurant Process."}, {"title": "How event schemas are learned", "content": "One common component among the five models is that they use variants of an RNN, and even though the hierarchical structures are different among models, as described above, event dynamics are encoded in weight matrices. All models learn these weight matrices by predicting the upcoming sensory stimuli, and back-propagate prediction errors to adjust weights. One notable difference is that for SEM, REPRISE, and GateLORD, the models need to infer when there is a transition between events so that they can activate relevant schemas and/or update their internal representations. The Lu model and the Elman and McRae model do not need to solve this challenge, there is only one schema in the Lu model and the transitions are given in the Elman and McRae model.\nFor models that learn dynamics for more than one event types, they differ mainly on how shared and specific event dynamics are learned for all event types. REPRISE and GateLORD have a single RNN to learn dynamics for all event types, whereas SEM encode dynamics of each event type in a single RNN. Sharing the same RNN means that event dynamics across event types are learned jointly in REPRISE and GateLORD, thus the RNN can benefit from shared dynamics across event types. Having separate RNNs deprives SEM of the ability to learn shared dynamics across event types. In SEM-2.0 (Bezdek el al., 2023), the authors added a mechanism to initialize a new RNN based on a generic RNN trained on all stimuli observed thus far, effectively conferring the generic dynamics of the environment on the newly created schema. Having a shared RNN helps learn regularities across event types, but might also lead to interference (Tetko et al. 2019; Yu et al. 2020). This comparison between SEM and REPRISE and GateLORD highlights different computational strategies to model the same cognitive mechanism, which is learning shared dynamics across event schemas. The models make different predictions: in SEM, if an event schema is already created, future learnings of other event schemas do not affect that event schema, whereas in REPRISE and GateLORD, future learnings affect all event schemas."}, {"title": "Mechanisms to learn end states at each hierarchical level", "content": "End states have a special status because they mark the completion of a goal-directed event, prompting observers to proactively disengage the current event model and prepare to construct the next event model (Kuperberg 2021). Moreover, end states can contain potential cues for the next event. For example, as we see a person reaching to a cup of coffee, depending on whether they grasp the cup handle or the spoon in the cup, the next event would be drinking coffee or stirring coffee. In the Gumbsch model, there are two levels of prediction: A skip network predicts the sensory state at the end of an event and a forward network predicts the next sensory state. Event boundaries, which are timepoints where hidden states change, are used to identify end states, which are used to train the skip network. The skip network is trained to predict the final observation of an event from an arbitrary timepoint within event.\nThe Gumbsch model defines end states as timepoints where the latent states (represented by the hidden layer vector) tend to change. Alternatively, instead of relying on patterns of latent states to identify end states, the model could also rely on prediction quality to identify end states. Two candidate measures of prediction quality are prediction error and prediction uncertainty. The intuition is that at the end of an event, prediction error and/or prediction uncertainty tend to rise.\nIn short, learning end states is an important computational challenge in modeling event comprehension. To learn end states in an unsupervised manner (no external signals of when an event ends and another begins), there are at least two mechanisms to self-generate end states: 1) to rely on moments when the content of working event model shift, which was proposed by the Gumbsch model and 2) to rely on moments when prediction quality degrades, which has not been tested in any model."}, {"title": "When and how event models are updated", "content": "In the REPRISE model, working event models are represented by two primary components: the context vector and the hidden layer vector. Key to this model is the continuous, un-gated adjustment of both the hidden layer vector and the context vector through the feedback mechanism of prediction errors.\nThe SEM model uses the hidden layer vector and the event type categorical variable to represent working event models. Different from REPRISE, in SEM updates to the event type is punctuated: event types remain the same most of the times and are likely to change when prediction errors are high. Like REPRISE, updates to the event type are influenced by prediction errors. Updates to the hidden layer vector are continual: small drifts to incorporate new sensory information when consecutive timesteps share the same event type, and dramatic shifts to establish a new working event model when there is a change in event types.\nThe Gumbsch model introduces a unique mechanism: a gate that controls the stability and updating of the hidden layer vector, which also represent the working event model. This gate is influenced by prior activations of the hidden layer and current sensory information.\nThe Lu Model is primarily interested in the role of episodic memory in prediction and only learn one event schema. The hidden layer vector, representing the working event model, is continually updated with sensory information. A distinctive feature of this model is the influence of stored episodic memories on the activations of the hidden layer vector, enabling a form of memory retrieval in the process.\nIn the Elman and McRae model, event boundaries are not explicitly modeled. The working event model, represented by the hidden layer vector, is continuously updated to incorporate new sensory information.\nEach of these models offers a unique perspective on how working event models are updated, reflecting various theoretical underpinnings and computational strategies. REPRISE and SEM emphasize the role of prediction errors on event model updating, whereas the other three models do not rely on prediction errors to update the content of working event models. In other words, REPRISE and SEM implicitly assume that comprehension process works like generative models: hidden latent states generate observations, and errors are propagated upward to revise latent states. The Lu model integrates the influence of memory retrieval, assuming humans rely on episodic memories as schema-based prediction becomes difficult. The Gumbsch model emphasizes a learnable gating mechanism, which is complementary to error-based gating proposed by event segmentation theory (Zacks et al. 2007)."}, {"title": "Learning components comprising an event", "content": "Elaborative inference-the ability to fill in missing information in partially observable scenes-is crucial for understanding events or discourses. The Elman and McRae connectionist model of event knowledge (2019) learns co-occurrence patterns among components of activities, such as entities, actions, and contexts, by a feature of their network: constraint satisfaction. Specifically, the input units representing components of an event are fully connected to hidden units, and hidden units project recurrent connections to input units. The two-way connection between input layer and hidden layer confers the model constraint satisfaction property, which aids elaborative inference: \u201cpartially\u201d complete input symbols activate a certain pattern in hidden units, which in turn refine activations of input symbols (inferring missing components), which in turn activate another pattern in the hidden units. These updating cycles continue until the activations in both input layer and hidden layer settle into stable patterns (hence constraint satisfaction).\nThe Elman and McRae models is the only event comprehension model trying to capture how a system learns to fill missing information. However, it's unclear how elaborative inference and prediction interact. For example, inferring missing information before making predictions might help increase prediction accuracy. Or, suppose that the system only make elaborative inference when necessary, timepoints where the system make elaborative inference could be when prediction quality degrades, or when predictions are abnormal under the distribution of observed sensory information. Future modeling efforts are needed to characterize prediction-elaboration interaction."}, {"title": "Learning when to retrieve from memory", "content": "As discussed earlier, the Lu model proposes a computational model of event comprehension, suggesting that people selectively retrieve episodic memories (Chen et al. 2016). The researchers trained a memory-augmented neural network using reinforcement learning to predict a feature (e.g. mood) in an environment where features that inform the prediction might have been observed (e.g. weather). The network learned to decide whether it has observed the feature and answer or say \u201cdon't know\" (uncertain about the feature). If it decides that it doesn't know the feature, it will retrieve memories based on their similarities with the current LSTM hidden unit representations and integrate them into LSTM hidden unit representations. In addition, the author invites us to think about other factors affecting whether we retrieve memory, such as familiarity signal pushed the model into \"retrieval mode\" while high between-event similarity environments made the model less likely to retrieve. The model predicts that people selectively encode at the end of the event instead of the middle of the event-the model's prediction accuracy is higher if it encodes end-event memories.\nIn this model, episodic memory encoding and retrieval are assumed to be lossless and static. These assumptions are reasonable given that the authors are interested in when to encode and retrieve memories. For researchers who are interested in lossy (presumably more realistic) encoding and retrieval processes, the Structured Event Memory (SEM) model offers an approach. Unlike traditional stationary models like the Hidden Markov Machine (HMM), SEM emphasizes the dynamic nature of events. The goal of both HMM and SEM is to reconstruct the original scene as close as possible, given a noisy memory trace. The two models compensate noisiness combining learned semantic knowledge with the noisy memory trace to reconstruct the original scene. This can be thought of as using semantic knowledge to regularize memory traces. What sets SEM apart from an HMM is the way it regularizes recalled memories. Whereas HMMs rely on central tendencies or \"averages\u201d of scenes within an event to regularize a recalled scene, SEM relies on the learned dynamics of the event to regularize recalled scenes. Stationary models like HMMs are suitable to model static memories such as memories for fruits and animals, whereas SEM is more suitable to model dynamic memories such as event memories.\nEpisodic memories are important to comprehend events or detect event changes (Stawarczyk et al. 2020; Wahlheim and Zacks 2019). Although existing models like the Lu model offer valuable insights into when and how memories are retrieved, there is still much to explore. For one, when memories should be encoded could be framed as a mechanistic solution to a computational challenge, such as reconstructing the events with few episodic memories. For another, memory about association between observations and latent causes can be used to efficiently infer latent causes given the current observation, as studied by (Lu et al. 2023)."}, {"title": "Mechanisms for attentional control", "content": "The Gumbsch model architecture allows for comparisons between three different versions of attention selection: Minimizing uncertainty within the current event (intra-event uncertainty), minimizing uncertainty about the next event boundary (inter-event uncertainty), or minimizing both uncertainties. Recall that the model has two networks: the forward network and the skip network. Intra-event uncertainty is modeled as prediction uncertainty over the next timestep, in the forward network. Inter- event uncertainty is modeled as prediction uncertainty over the end state of the current event, in the skip network. Importantly, the entity that the system decides to attend to at a given timepoint depends on the degree of both intra-event uncertainty and inter-event uncertainty associated with that entity.\nWhen only reducing intra-event uncertainty, the model primarily focused on the hand well before the hand made contact with the object. Focusing on the hand in this way aids in forecasting immediate hand movements as it reaches for the object. In the case of minimizing only inter-event uncertainty, the system generally directed its attention first to the object before the hand reached it. It appears that the system has learned that concentrating on the object helps to reduce uncertainty regarding when and where the reaching event will conclude, and which future events will follow (e.g. lift the object). Crucially, when combining both types of uncertainties, the system displays attention shifts that are similar to 7- to 11-month-old infants. In the event sequence of reaching, grasping, and transporting, the system generally first focused on the hand, and then shifted its attention to the object before the hand made contact with the object. These patterns are similar to the gaze behaviors observed in infants while they watch videos of a hand grabbing and lifting a toy, as studied by (Adam and Elsner 2020). At 6 months old, infants mainly track the hand with their gaze. However, older infants, at 7 and 11 months, transition their gaze from the hand to the object before the hand reaches it. These results make an interesting prediction: During online comprehension, the level of representation that is most relevant to the observer will control where the observer looks to minimize uncertainty over representations at that level.\nIn the realm of episodic memory control, uncertainty plays a pivotal role in shaping how the network utilizes its stored memories for future predictions (Lu et al. 2022). As discussed, the network employs a gating mechanism that adjusts the influence of episodic memories on the hidden units. This adjustment is guided by the current state of the network's working memory, also represented by hidden units. For instance, if the network is tasked with predicting emotional states like happiness or anger but hasn't yet received data on the weather, a known influencing factor, it adjusts its episodic memory gate to be more open. The level of this gate's openness is determined by the current state of the network's working memory, which in this case, lacks information about the weather. The lack of information about the weather has a signature: When faced with insufficient data to make a specific prediction, the ac'Ivity of hidden units is reduced. This reduced activity is interpreted as the network being\u201c'uncertain\"", "an\u201c'unknow\u201d": "hoice as its output.\nThis mechanism of episodic memory control based on uncertainty complements the attentional control mechanism described by Gumbsch et al., 2022. Both mechanisms aim to minimize uncertainty, but they do so in different domains: attentional control focuses on sensory input, while episodic memory control focuses on leveraging past experiences stored in memory."}, {"title": "Constructing structured representations", "content": "Thus far", "dimensions": "time, space, causality, intentionality, and protagonist. The Event Horizon Model proposes the content of event models includes spatiotemporal frameworks, entities and their properties, structural relations and linking relations (Radvansky and Zacks 2014). Some examples of structural relations are spatial relations, ownership relations, kinship relations, social relations, and so forth. Linking relations serve to link different events into a sequence. The most common types of linking relations are temporal and causal relations. Temporal relations often covary with causal relations because causes always precede their effects. However, causal relations are usually much more important because they license predictions about the future. Both theories emphasize representations of not just entities involved in activities but their structural and linking relations, especially causal relations. Propositional representation is a good medium to capture entities, their properties, and relations among entities (Kintsch 1998, 2001). The computational models reviewed so far either give relational information directly to the model (e.g., Elman and McRae model, SEM model with Holographic Reduced Representation) or operate in a constructed world where relational information is not critical to comprehend events (The Gumbsch model, the Lu model, and REPRISE model). Moreover, there is an implicit assumption that the RNN (or its variants such as long short-term memory or gated recurrent unit) might be able to extract underlying structural relations and temporal relations among entities to be able to predict how the event will unfold. This assumption needs to be tested if modelers of event comprehension want to use these networks to model dynamics governing naturalistic events. Alternatively, we can rely on advances in computer vision methods to automatically extract entities and their structural relations on the scene (Ji et al. 2020) and use symbolic techniques such as Holographic Reduced Representations (Plate 1995, 1997) or Tensor Products (Smolensky 1994; Smolensky et al. 2016) to translate this information into a continuous vector space as input to connectionist architectures such as RNNs. Another approach is to augment an RNN with modules that are designed to progressively extract abstract representations such as in convolutional neural networks. (Lotter, Kreiman, and Cox 2017, 2018) used convolutional LSTMS (CLSTMs) as representation modules for the task of next frame video prediction. A convolutional LSTM (cLSTM) is an enhanced version of the standard LSTM neural network, designed specifically for image sequence processing like in video analysis. While traditional"}]}