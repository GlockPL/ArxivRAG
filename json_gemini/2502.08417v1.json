{"title": "Handwritten Text Recognition: A Survey", "authors": ["Carlos Garrido-Munoz", "Antonio Rios-Vila", "Jorge Calvo-Zaragoza"], "abstract": "Handwritten Text Recognition (HTR) has become an essential field within pattern recognition and machine learning, with applications spanning historical document preservation to modern data entry and accessibility solutions. The complexity of HTR lies in the high variability of handwriting, which makes it challenging to develop robust recognition systems. This survey examines the evolution of HTR models, tracing their progression from early heuristic-based approaches to contemporary state-of-the-art neural models, which leverage deep learning techniques. The scope of the field has also expanded, with models initially capable of recognizing only word-level content progressing to recent end-to-end document-level approaches. Our paper categorizes existing work into two primary levels of recognition: (1) up to line-level, encompassing word and line recognition, and (2) beyond line-level, addressing paragraph- and document-level challenges. We provide a unified framework that examines research methodologies, recent advances in benchmarking, key datasets in the field, and a discussion of the results reported in the literature. Finally, we identify pressing research challenges and outline promising future directions, aiming to equip researchers and practitioners with a roadmap for advancing the field.", "sections": [{"title": "I. INTRODUCTION", "content": "Handwritten Text Recognition (HTR) represents a cornerstone challenge within the fields of pattern recognition and machine learning. The task of converting handwritten text into a machine-encoded format has profound implications across several domains, including historical document preservation, automated data entry, digital note-taking, and accessibility for the visually impaired [1]. As we advance further into the digital age, the necessity for accurate and efficient HTR systems continues to grow, driven by the ever-increasing amount of handwritten data generated daily.\nThe complexity of HTR arises from the inherent variability in human handwriting. Unlike printed text, which adheres to standardized fonts and spacing, handwritten text exhibits a broad variety of styles, slants, sizes, and embellishments that are influenced by individual writing habits, cultural contexts, and even emotional states [2]. These variations present significant challenges for recognition systems, requiring algorithms capable of generalizing across diverse handwriting samples.\nHistorically, HTR systems have evolved through several technological waves. Early approaches relied on heuristic and rule-based methods, leveraging handcrafted features to recognize characters and words [3]-[7]. These systems were limited in their capacity to handle the high variability of handwritten text and often required significant preprocessing and segmentation of individual characters [8], [9]. The advent of machine learning introduced a paradigm shift, enabling the development of more adaptable and robust recognition systems. Statistical methods, such as Hidden Markov Models (HMM) [5], [10], offered improved performance by learning from labeled data to recognize complete words or lines [11]-[14].\nThe emergence of deep learning [15] has revolutionized the field of HTR, bringing forth unprecedented advancements in recognition performance. Convolutional Neural Networks (CNN) [16] and Recurrent Neural Networks (RNN) [17] have demonstrated remarkable success in capturing spatial and sequential dependencies in handwriting. More recently, Transformer models have further pushed the boundaries [18]. These architectures have shown immense potential in HTR due to their ability to model long-range dependencies and handle variable-length sequences effectively.\nIn addition to advances in performance, these technological breakthroughs have also diversified the approaches to HTR. The scope of recognition has expanded in complexity over time, from transcribing words and lines [19]-[22] to approaches that directly output the content of entire paragraphs or documents [23]-[25]. Within this context, this survey aims to provide a comprehensive examination of the current state of HTR focusing on its different levels of granularity. We broadly categorize the possibilities into two main groups (see Fig. 1): up to line-level, comprising word-level and line-level; and beyond line-level, involving paragraph-level and document-level recognition. The need for this distinction is evident in the different ways of approaching the associated challenges, which we will discuss later.\nOur survey focuses on the transcription process itself. We will not delve into auxiliary processes such as character segmentation or layout analysis, which are often necessary to prepare the input for HTR systems. This distinction is crucial as it emphasizes methods that perform the handwriting recognition process. Therefore, when we discuss about up to line-level HTR, we refer to approaches that directly process an image containing, at most, one line of text. Similarly, when we review paragraph- or document-level literature, we refer to approaches that directly transcribe the handwritten content at those levels, without relying on prior segmentation. Following this perspective, we purposely exclude character-level recognition from this survey, as it essentially reduces to a classification task, an area already well-covered in the vast existing literature."}, {"title": "A. Purpose and contribution", "content": "HTR has seen significant progress in recent years, driven by the development of sophisticated deep learning techniques and the growing availability of diverse datasets (see Fig. 2). These advancements have transformed the field.\nExisting surveys, such as those by Wang et al. [26] and AlKendi et al. [27] provide comprehensive overviews of text detection and recognition across various contexts. Wang et al. cover a wide range of text recognition tasks, including printed and scene text, addressing both detection and recognition phases. AlKendi et al. [27] offer a detailed examination of HTR systems with a specific focus on historical French documents and a broad range of languages. Additionally, Chen et al. [28] focus on text recognition in the wild, dealing with text in natural scenes, which presents different challenges compared to HTR (as discussed later). Therefore, it is both timely and necessary to conduct a comprehensive survey of the current state of HTR that reflects the new landscape of the field.\nOur survey provides a specialized and focused examination of HTR, delving into the end-to-end transcription processes and categorizing methodologies based on the granularity of recognition. We provide a comprehensive review with a general and unifying view of the formulation. Our survey also explores the implications of these advancements on benchmarking practices, offering insights into the datasets and metrics most relevant for evaluating HTR systems. In addition, this work unifies and discusses the results reported by the most notable advances in the field through a common benchmark, providing perspective on the evolution of methodological impact in the field.\nIt is important to emphasize that this evolution analysis is framed within the transcription of Latin scripts, as most technological advancements in the field have been reported on these sources."}, {"title": "B. Structure of the survey", "content": "The structure of this survey is organized as follows: Section II covers the foundational preliminaries, including the historical background of HTR, the formal problem formulation, and its connections to related fields. Section III explores the different methodologies employed in HTR, categorized by its inherent complexity levels, and examines the architectural designs and strategies used in each category. Section IV focuses on the benchmarking of HTR systems, providing an in-depth review of the datasets, evaluation metrics, and the performance reported in the literature. Finally, Section V concludes the survey by summarizing the key insights and identifying open research challenges, outlining potential directions for future work in HTR technologies."}, {"title": "II. PRELIMINARIES", "content": "In this section, we provide an overview of the foundational concepts and historical development of HTR, covering the shift from early heuristic-based approaches to modern deep learning techniques. This background sets the stage for a detailed exploration of the methodologies and advancements that have emerged in recent years. Initial attempts in HTR focused on classifying individual characters [16]. However, within the scope of this survey, this task is considered a general classification challenge, that is extensively covered in the broader literature. Therefore, we will directly move on to the background of the sequential challenges of HTR."}, {"title": "A. Background of HTR", "content": "Historically, HTR has adapted advancements from the field of Automatic Speech Recognition (ASR) [12], [29]\u2013[31] because of the similarities in their problem formulations. Both fields deal with sequential data and require models that can handle variability and context dependencies. For years, the field of HTR relied on HMM [32]-[35]. Further advances favored the use of RNNs due to their capacity to model sequential data [36]-[39]. In particular, the use of bidirectional Long Short-Term Memory (LSTM) networks with Connectionist Temporal Classification (CTC) [36] dominated the state of the art in HTR for decades [40]-[43]. Despite this prevalence of CTC, attention-based encoder-decoder approaches [44] gained popularity for their competitive results [45]\u2013[48]. The work of Michael et al. [49], provides a comprehensive comparison of the different sequence-to-sequence approaches for line-level HTR.\nAs occurred in many other areas, there has been a growing interest in scalable and parallelizable architectures such as the Transformer [18] by adapting the Vision Transformer [50] to the HTR field [51]-[56]. HTR has benefited from this adaptation, either in isolation with an encoder-decoder [57]-[60] or in combination with the CTC objective function [61]-[63]. Diaz et al. [55] explore universal architectures for text recognition, concluding that a CNN backbone with a Transformer encoder, a CTC-based decoder, plus an explicit language model, is the most effective strategy to date for line-level transcriptions. Regardless of this progress, however, the need for large labeled corpora as a pre-training strategy in Transformer-based models has become increasingly evident [55], [57], [64]-[66].\nGiven the increase in computational capacity, the paradigm has shifted towards end-to-end methods capable of reading beyond the line level. This current trend in the field began to develop with attention masking mechanisms that replace the explicit Layout Analysis (LA) [25], [67], [68]. Later advances also extended the single-line transcription state of the art to work with multiple lines. The CTC-based methodologies were extended to work in a multi-line setting, with reshaping mechanisms that alleviate its constraints [69], [70]. The Transformer architecture also emerged in this paradigm, enabling the adaptation of attention-based encoder-decoder architectures to transcribe documents of any structure, thanks to its unconstrained nature and the ability to produce large synthetic datasets [24], [71], [72]. This approach currently represents the state of the art of the field and lays the foundation for future development (see Fig. 2)."}, {"title": "B. Levels of complexity", "content": "The field of HTR encompasses a wide range of challenges that vary significantly in their complexity. While existing literature provides various perspectives on these challenges, it often lacks clear differentiation between input types and their inherent difficulties. To advance our understanding and properly evaluate different methodologies, establishing a precise framework that defines and categorizes the different levels of complexity is essential.\nThe task of HTR involves converting handwritten text into an encoded format that can be interpreted by a machine. However, the transcription challenge can be narrowed down in different ways. At the most fundamental level, we find individual characters,\u00b9 which represent the simplest unit of recognition and complexity. As stated above, character recognition is outside the scope of this paper, as it can be reduced to a classification problem.\nBeyond character recognition, the concept of Reading Order (RO) becomes an important aspect to consider. The RO is the sequence in which text elements are read to preserve the logical flow and conceptual meaning, following linguistic and cultural conventions. At the first level of complexity concerning RO, we focus on words, which are formed by the sequential arrangement of characters. For word-level recognition, the RO follows a single and consistent direction, which is determined by the reading rules of the writing system. For example, in Latin sources it is left-to-right, while it is top-to-bottom in traditional Japanese and Chinese books.\nAt a similar level of complexity, we also encounter lines, which are understood as a sequence of words separated by a delimiter character (commonly a space: ' '). This increase in complexity does not alter the RO; instead, it lies in the need to transcribe a greater number of characters while incorporating this additional delimiter. In this context, HTR involves processing images that might span the full width of the page. These lines are read following the same RO type as words, remaining consistent and unidirectional, as illustrated in Fig. 3. Therefore, we establish the first level of complexity in the field.\nDefinition 1: Line-level HTR is the process of transcribing handwritten text from an input image containing a single line of text, which must be interpreted following a single RO, as determined by the rules of the language in which it is encoded. This level encompasses both words and lines.\nGiven the spatial limitations of paper, it is unfeasible to write complete texts in a single line. For this reason, the stacking of lines in an additional dimension is traditionally employed. In this case, an additional RO is introduced, where the text is interpreted first in a line-level direction and then typically follows a perpendicular direction to continue reading the subsequent lines, as depicted in Fig. 4. This structure is commonly known as paragraphs and establishes the next complexity level of HTR, since a new RO is introduced.\nDefinition 2: Paragraph-level HTR is the process of transcribing handwritten text from an input image containing multiple lines of text, where two predetermined RO directions must be followed: one for reading individual lines and another for traversing between lines. These directions are commonly perpendicular.\nUltimately, the highest level of complexity arises when dealing with sources that contain multiple paragraphs. The arrangement of these blocks may not be straightforward, as shown in Fig. 5. In this case, a third RO across paragraphs is introduced, depending on the layout of each source.\nThis layout may be either a static geometric arrangement, such as two-column sources, or a dynamic one, where artifacts such as images and tables may be introduced between text blocks. Therefore, we present the final definition.\nDefinition 3: Document-level HTR is the process of transcribing handwritten text from sources that contain multiple paragraphs arranged in an arbitrary, non-trivial RO.\nNote that this definition excludes page images where a simple stack of paragraphs is found, which are sometimes understood as \u201cfull-page HTR\u201d [70], [71]. In our view, the transcription challenge remains the same as for a single paragraph, since the RO for transitioning between lines also applies to transitioning between paragraphs. Therefore, from a technical perspective, such pages fall within the scope of the definition given for \"paragraph-level HTR\".\nOur hierarchical categorization of complexity levels provides a robust framework for understanding and addressing HTR challenges. These distinctions are fundamental to the comprehension of HTR methods, as different approaches may be better suited to different complexities. Accordingly, we structure the different methodologies based on where the most significant shift in complexity occurs due to the RO. Specifically, this refers to the transition from transcription up to line level (words and lines) to beyond the line level (paragraphs and documents)."}, {"title": "C. Formulation of HTR", "content": "Let us denote by X the space of images containing handwritten text. Each element of X is represented as a three-dimensional tensor in $R^{H \\times W \\times C}$, where H, W, and C represent the height, width, and number of channels of the image, respectively, and their dimensions may vary across instances. Given an input $x \\in X$, the goal of HTR is to retrieve its corresponding textual representation $y = (y_1, y_2,..., y_N)$, where $y_i \\in \\Sigma$ denotes individual characters from a predefined alphabet $\\Sigma$. The alphabet $\\Sigma$ may include alphanumeric characters, punctuation symbols, or other special tokens such as spaces or line breaks. Statistically, this retrieval task can be formally defined as:\n\n$y^* = \\arg \\max_{y \\in \\Sigma^*} P(y | x)$, (1)\n\nwhere $\\Sigma*$ is the Kleene closure over the alphabet $\\Sigma$, representing all possible sequences of characters.\nIt is known that solving Eq. 1 exactly is computationally intractable [73]. Therefore, most HTR methods rely on approximate inference strategies to solve this problem efficiently. These methods differ in how they approximate Eq. 1 and how they estimate the probabilities involved.\nUsing Bayes' theorem, Eq. 1 can be reformulated as:\n\n$P(y | x) = \\frac{P(x | y) P(y)}{P(x)}$ (2)\n\nSince P(x) is independent of y during the maximization process, the problem can be equivalently expressed as:\n$\\hat{y} = \\arg \\max_{y \\in \\Sigma^*} P(x | y) P(y)$, (3)\nwhere:\n* P(x | y) represents the likelihood, which models how well the transcription y explains the input image x. This is implemented using a statistical model, such as a neural network.\n* P(y) represents the prior probability of the transcription y, often estimated using a language model (LM).\nThe prior probability P(y) can be modeled using statistical LM such as n-grams, where n defines the context size. A LM is formally defined as a function:\n$p : \\Sigma^* \\rightarrow [0, 1]$, such that $\\sum_{y \\in \\Sigma^*} P(y) = 1$.\nLMs provide prior knowledge about the structure of valid sequences and are often integrated into the recognition process through techniques such as re-scoring. Alternatively, in some domains, stricter constraints can be imposed by using a formal language or lexicon. Let L$\\subset \\Sigma^*$ denote the set of valid transcriptions defined by such constraints. In this case, the HTR problem is reformulated as:\n$\\hat{y} = \\arg \\max_{y \\in L} P(x | y) P(y)$. (4)\nAt a formulation level, the challenge in HTR is consistent across different levels of complexity, but the alphabet $\\Sigma$ changes depending on such level: at the character level, $\\Sigma$ represents the basic charset; at the word level, $\\Sigma$ includes additional symbols such punctuation marks; at the line level, $\\Sigma$ incorporates spaces; at the paragraph level, $\\Sigma$ includes line breaks; and at the document level, $\\Sigma$ might be further expanded to include paragraph breaks or other structural"}, {"title": "D. Relation with other fields", "content": "HTR relates to diverse domains, many of which share both challenges and techniques. In this section, we introduce the fields most related to the focus of this survey, placing special emphasis on the differences that make HTR worthy of specific investigation. We illustrate the differences between HTR and the related fields in Fig. 6.\n1) Online HTR: Online, or pen-based HTR [74]-[76], involves recognizing text as it is written using a digital pen or stylus, leveraging dynamic temporal information such as pen tip coordinates, pressure, and tilt. This data provides contextual clues about stroke order and direction, which are absent in \"offline HTR\". While online HTR can be converted into an offline problem by rendering pen movements into images, the reverse is not possible. Offline HTR requires handling handwriting variability without access to temporal data, making it a distinct challenge with broader applicability, particularly for historical documents and scanned notes.\n2) Scene Text Recognition: Scene Text Recognition (STR) [77]\u2013[80] focuses on recognizing text in natural scenes, where varying fonts, distortions, and complex backgrounds pose unique challenges. While both leverage similar advances in pattern recognition and computer vision, the primary challenge in HTR lies in handling handwriting variability, while STR must address environmental noise and background interference, making them distinct fields despite their methodological overlaps.\n3) Keyword Spotting: Keyword Spotting (KWS) [81]\u2013[84] involves identifying and locating specific keywords within a set of document images. This field is particularly relevant for searching and retrieving information from large collections of handwritten documents. While KWS and HTR share the goal of identifying handwritten text, they approach the problem from different angles. HTR focuses on the comprehensive transcription of handwritten text into machine-readable format, while KWS is concerned with locating specific words or sentences within the text without necessarily transcribing the entire document.\n4) Layout Analysis: Layout Analysis (LA) [85]\u2013[87] focuses on segmenting and categorizing document components such as text blocks, tables, and images to understand their spatial arrangement. While both LA and HTR deal with document images, they address different aspects of document interpretation. LA focuses on the structural analysis and segmentation of the document, ensuring that various elements are correctly identified and classified. In contrast, HTR specifically concentrates on transcribing the handwritten text within these segmented areas.\n5) Document Understanding: Document Understanding (DU) [88]\u2013[91] encompasses a comprehensive set of tasks aimed at interpreting and extracting meaningful information from documents. This includes text recognition, entity extraction, or document question answering. While HTR provides the fundamental transcription of handwritten text, DU extends beyond this by analyzing relationships between text blocks, extracting key information, and generating structured representations. This requires additional layers of analysis, which are beyond the primary focus of HTR.\n6) Handwritten Text Generation: Handwritten Text Generation (HTG) [92]\u2013[94] focuses on synthesizing realistic handwritten text images from digital input, leveraging techniques such as Generative Adversarial Networks [92] and Transformers [93], [94]. This has applications in personalized handwriting synthesis, CAPTCHA systems, and augmenting datasets for training HTR models."}, {"title": "III. METHODOLOGIES", "content": "This section outlines the methodologies employed in the field of HTR, categorizing them based on the recognition level: up to line-level and beyond line-level. It examines the historical developments, methodological distinctions, and complementary techniques that enhance performance in the transcription of handwritten text images. HTR models are a class of probabilistic models that attempt to estimate the most probable transcription y given an image x, thus in the form of Eq. 4. Conceptually they all address the same task, that of aligning an input image with the most probable output sequence. The differences are encountered in (1) the alphabet $\\Sigma$, which differs depending on the level at which recognition is performed, and (2) how they align the input image with the output sequence.\nWe divide this section into two main categories: transcription models up to the line level (word and lines) and models beyond the line level (paragraph and documents)."}, {"title": "A. Up-to-line level transcription", "content": "The challenges up to line level involve two categories: (1) word level, in which only characters without spaces are predicted or (2) line level, in which characters are predicted by adding the space character to $\\Sigma$, which both share one single RO (one single direction). Before we start to unify the different approaches, we shall make a distinction between the models that go up to the line level. In the early days of HTR, due to the lack of computational and methodological resources, transcription was done in a more manual and laborious pipeline as shown in Fig. 8 and mainly focused on word recognition [13], [14], [95]\u2013[102]. These steps consisted first of a pre-processing stage where the objective was to remove uninformative elements such as the background, lines or other elements and a posterior binarization to facilitate the extraction of information [103], [104]. The next step was normalization, which involved \u201crectifying\u201d the image to keep the image invariant to the writer's style. Typical operations in this case were skew [105]\u2013[108] and slant correction [3], [10], [105], [108]-[111], smoothing (denoising) and image scaling. The next step was segmentation (also called fragmentation), in which the information appearing in the word was separated to be further recognized [112], [113].\nAt the methodological level, this does not change in that all still have to estimate Eq. 4, but these factors led to a series of work in which alignment had to occur after a number of manually extracted features. Specifically, these methods differed in whether the alignment was done after isolating the characters from the sequence (explicit segmentation) [4], [13], [97], [112], [114]-[124] or whether this separation was done implicitly (implicit segmentation) [5]-[7], [96], [98], [121], [122], [125]-[135], so we consider this series of methods as two leaves of the same branch and group them into one: handcrafted methods. Therefore, we will divide up-to-line methodologies according to the \u201cmanual\u201d learning process: handcrafted (manual) and end-to-end (automatic) approaches.\n1) Handcrafted approaches: Early methods for HTR relied on handcrafted processes, focusing on segmenting word images into smaller components that could be matched to character models [112], [114]. We summarize this \u201cclassical\" pipeline in Fig. 8. These segmentation-based approaches required manually designed processes to identify primitive segments, introducing significant challenges due to segmentation errors. Among these approaches, we identify two main categories: (1) explicit segmentation-based methods, which require the individual segmentation of each character, and (2) implicit segmentation-based methods, where the segments do not necessarily correspond to individual characters. Recognition performance depended heavily on accurately matching segments to corresponding characters. According to the segmentation methods, we find:\na) Explicit segmentation: Each character was segmented and used the following methods to perform the recognition.\n* Dynamic Programming (DP). DP was a widely adopted technique for matching segments to letters [3], [131], [136]-[140]. By constructing an optimal path through a cost matrix, DP minimized the mismatch between observed segments and hypothesized letters. The method handled gaps and substitutions effectively but required carefully defined cost functions, often tailored to specific datasets or writing styles.\n* Shortest path in graphs. Graph-based methods reformulated the segmentation problem as finding the shortest path in a graph, where nodes represented segment-letter pairs and edges encoded transition costs between them [115]-[117]. These methods evaluated all possible segment-to-letter matches in a structured way, leveraging graph traversal algorithms to find the least costly alignment. This approach allowed greater flexibility in handling overlapping or ambiguous segments.\n* Hidden Markov Models (HMMs). HMMs became a prominent tool in HTR due to their capability to model sequential data with hidden states [4], [13], [97], [118]\u2013[124]. Each letter was modeled as a sub-HMM, and these were concatenated to represent entire words. The Viterbi algorithm [141] was used to identify the most probable sequence of matches between observed segments and model states. HMMs were particularly effective for handling variability in writing styles and sequential dependencies between letters.\nb) Implicit segmentation: While early methods relied on explicit segmentation, later approaches explored segmentation-free paradigms [103], where features were learned automatically rather than manually defined. However, these approaches still used handcrafted features, such as:\n* Low-level features: Basic elements like word contours, strokes, and skeleton approximations of segments [5]-[7], [96], [125]-[130].\n* Medium-level primitives: Aggregations of low-level features, forming more complex patterns like complete letters or stroke groups [133].\n* High-level holistic features: Global characteristics of word images, such as ascenders, descenders, loops, or stroke patterns [98], [121], [122], [134], [135].\nDespite these advancements, both segmentation-based and segmentation-free methods often relied on alignment techniques like Minimum Edit Distance [98], [127]\u2013[129], [133], [134] or HMMs [5]\u2013[7], [121], [122], [125], [126], [130], [132], [135]. These techniques provided a framework for aligning observed features or segments to target words, regardless of the feature abstraction level or segmentation method. Due to the laboriousness of the process, the error-prone series of steps in the classical pipeline and the lack of computational resources, almost all the work described focused on word recognition.\n2) End-to-end approaches: With the advent of Deep Learning (DL), all features are learned automatically in an end-to-end manner, which is what the field is based on [15]. Under DL-based methods, these differ essentially in how they automatically align the learned features with the output sequence, which we have previously referred to as \u201calignment\u201d i.e. to approximate Eq. 4. Depending on the method employed to align the features with the output sequence, one can find (1) CTC-based methods [19], [20], [25], [40], [70], [77], [99], [142]-[144], (2) sequence-to-sequence approaches [21], [45], [54], [55], [57], [61] and (3) hybrid techniques [49], [51], [63]. For an outline of the Deep Learning-based methods up-to-line level, see Fig. 9. Note that, in the HTR literature, we adopt the terminology used in Machine Translation [145], referring to the encoder as the architectural component that encodes the maps the input signal into a set of features, while the decoder processes them, generally transcribing in an autoregressive manner. As we will see, some models employ encoder-only architectures, while others integrate both an encoder and a decoder. In the following sections we describe how these different methods align and approximate (4).\na) CTC-based methods: In order to align the image x with the sequence y, CTC introduces the notion of \"valid alignments\" of y, which are all the possible character sequences of the alphabet $\\Sigma' = \\Sigma \\cup \\{e\\}$ such that collapsing results in the output sequence y. This collapse is produced by merging repeated characters and removing the $e$ (typically named blank) token. Therefore, with CTC, for each labelled sequence y there is a set of $B(y) \\in B$ valid alignments where B represents the complete space of alignments. Note that the length of the alignments is given by |x|, which typically corresponds to the number of columns $x_1, x_2,... x_T$ of the image, typically referred to as frames. In this section, the methodologies explored assume a frame-wise reading. This means that all the frames contained in the feature map represent exclusively one character. This allows up-to-line methods to only read in a single RO direction. To reach this assumption, all methods resort to an image collapse step, where data is transformed from an image space to a sequence one. This is defined as a function $r : R^{w,h,c} \\rightarrow R^{l,z}$, where h is the height of the feature map, w its width, c the number of channels, l is the output sequence length and z the number of features. This function reshapes the input feature map to merge their features along the horizontal axis. Therefore, they"}, {"title": "B. Beyond-line level transcription", "content": "The maturation of up-to-line level transcription techniques in Handwritten Text Recognition (HTR) has catalyzed a significant paradigm shift toward more ambitious challenges: the direct transcription of complete paragraphs and documents without requiring preliminary segmentation steps for isolating lines. This evolution represents not merely an incremental advancement but a fundamental reconceptualization of the transcription process.\nA critical technical barrier in this transition stems from the vertical collapse function inherent to up-to-line level methods. While this approach effectively processes single lines by assuming that vertical features correspond to individual characters, it becomes problematic when scaling to multiple line scenarios. In paragraph or full-page transcription tasks, individual vertical slices of the image frequently contain several characters from different lines that must be independently recognized. The collapse function, by compressing these multiple characters into a single feature representation, fundamentally compromises the ability of the model to maintain proper RO and accurately distinguish between characters from different lines. Modern beyond-line level approaches specifically address this limitation through methodological adaptations and extensions. Note that the foundation of these methods is still the one that formulates the HTR field. Beyond line-level transcription methods mainly seek to address the r() function to retrieve a sequence-like data structure that represents the whole content of the page, aligned with ground truth.\nGiven the emerging nature of this paradigm and its profound implications for the field, we perform an individual analysis of current methodological approaches and their technical foundations.\nHereby, we find three different approaches: attention masking and line unfolding, where methods downscale the complexity of the problem into an up-to-line level challenge, either through attention-based segmentation or reshape functions, and (ii) unconstrained methods, where the already established sequence-to-sequence formulation from up-to-line level is adapted to learn more complex inputs. Figure 11 depicts a summary of the reviewed approaches.\n1) Attention masking: The earliest publications beyond line-level applications found in the literature are those that apply attention matrices masking as the transcription method. These methods implement $r(\\cdot)$ as $r(x) = a \\cdot x$, where a is a learned mask that is applied to the input feature map. These methods are applied \u201cautoregressively\u201d, as the mask has to be recalculated to extract all the lines from the input document, simplifying the multi-line complexity of the problem into a sequential line-by-line transcription. The presented methods in this particular approach propose different ways of computing $\\alpha$.\nThe first publications referred to these methods are the Joint Line Segmentation and Transcription (JLSAT) [25] and the Scan, Attend and Read (SAAR) [67] models. Both methods are based on a combination of Convolutional Neural Networks and Multi Dimensional LSTM (MDLSTM) [100]. The first model, the SAAR, is a sequence-to-sequence approach where attention and inference are computed at the character level. The second one, JLSAT, is an optimization of the first approach that computes attention at the line level and training with the CTC loss function.\nAlthough these approaches provided groundbreaking results\u2014since they were the first segmentation-free models published\u2014they were based in MDLSTM networks, which are inefficient in both training and inference. As a result, these approaches have been left behind over time, thanks to the income of Transformer-based autoregressive architectures. Despite this, the philosophy from these papers still prevails both in unconstrained methods, described in Section III-B3, and in the Vertical Attention Network (VAN) [24]. This network replaces the slow-to-train MDLSTM blocks with a convolutional network and a line-wise hybrid attention. The VAN specifically finds, approximately, the rows of a document that, at least, contain a character to transcribe. This method, although it is more efficient both in training and inference, is limited to transcribe only text paragraphs, as the rows are approximated in the vertical axis, assuming therefore that a row contains the full width of the image.\n2) Line unfolding: In parallel to the development of masking methods, the unfolding systems started being developed. This approach works under a single-step end-to-end philosophy, as state-of-the-art line transcription does. In this case, the r() function is approached through a reshape operation that substitutes the vertical collapse between the feature extraction and the decoding stages.\nThe first publication that addresses this formulation is the Origaminet network [69]. The unfolding method is driven by a network composed of convolutional networks and upsampling operations. Authors assume that the produced line is long enough to contain the input document. Hereby, the network learns how to place its elements into the resulting feature map that is read in the correct RO, driven by the ground truth. This operation is done along the horizontal axis, forcing the network to implicitly learn to read from top to bottom and from left to right. Authors claim, with empirical evidence, that the model is able to transcribe full-page documents with non-trivial ROs. Although this network produced substantial results, it relies on user-defined hyperparameters, such as the line-like structure length and a fixed-size image, suggesting that the model performance is corpus-dependent.\nThe Simple Predict and Align Network (SPAN) network came briefly after Origaminet, and it is proposed as an unconstrained upgrade of this network [70]. Instead of relying on fixed-sized parameters, authors rely on an automatic unfolding operation that concatenates the rows from the feature map produced by the encoder. The concatenation step is performed from top to bottom. This operation is computed after the"}, {"title": "C. Complementary techniques", "content": "In the evolving field of HTR", "decoding": "Greedy decoding is a straightforward method for converting a neural network's"}]}