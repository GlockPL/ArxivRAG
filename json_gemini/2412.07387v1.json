{"title": "Enhanced MRI Representation via Cross-series Masking", "authors": ["Churan Wang", "Fei Gao", "Lijun Yan", "Siwen Wang", "Yizhou Yu", "Yizhou Wang"], "abstract": "Magnetic resonance imaging (MRI) is indispensable for diagnosing and planning treatment in various medical conditions due to its ability to produce multi-series images that reveal different tissue characteristics. However, integrating these diverse series to form a coherent analysis presents significant challenges, such as differing spatial resolutions and contrast patterns meanwhile requiring extensive annotated data, which is scarce in clinical practice. Due to these issues, we introduce a novel Cross-Series Masking (CSM) Strategy for effectively learning MRI representation in a self-supervised manner. Specifically, CSM commences by randomly sampling a subset of regions and series, which are then strategically masked. In the training process, the cross-series representation is learned by utilizing the unmasked data to reconstruct the masked portions. This process not only integrates information across different series but also facilitates the ability to model both intra-series and inter-series correlations and complementarities. With the learned representation, the downstream tasks like segmentation and classification are also enhanced. Taking brain tissue segmentation, breast tumor benign/malignant classification, and prostate cancer diagnosis as examples, our method achieves state-of-the-art performance on both public and in-house datasets.", "sections": [{"title": "I. INTRODUCTION", "content": "Magnetic resonance imaging (MRI) is a widely used medical technology that can provide rich and diverse information about the anatomy and pathology of human tissues [15], [20]. MRI can produce different types of images, called series, by varying many factors such as the acquisition parameters and the contrast mechanisms [15], [16], [45]. As shown in Figure 1(a), different series can highlight different aspects of the same tissue, such as morphology, function, metabolism, or diffusion. And Figure 1(b) gives the quantitative comparisons and illustrates that combining multiple series can achieve higher performances. Therefore, multi-series MRI analysis is essential for accurate and comprehensive diagnosis [12]\u2013[14].\nHowever, multi-series MRI analysis poses significant challenges in medical image computing. One of the main challenge of multi-series representation learning is how to effectively integrate and fuse the information from different series, which may have different factors such as spatial resolutions, signal-to-noise ratios, intensity distributions, and contrast patterns [15]. Traditional methods often rely on hand-crafted features or predefined rules to combine different series, which may not capture the complex and subtle relationships among them [10], [11], [17]. Deep learning methods have shown great potential in learning high-level and abstract features from multi-series data. For example, Zhang et al. [7] propose a deformable aggregation module for multiseries feature fusion. A2FSeg [8] design two stages of feature fusion, including a simple average fusion and an adaptive fusion based on an attention mechanism. However, these methods often require a substantial amount of annotated data. The acquisition of such annotated data is frequently challenging due to the demands for time, cost, and specialized expertise. Compared to annotated data, unannotated data is more readily accessible in clinical practice.\nTo fully leverage unlabeled data to enhance model performance, self-supervised learning (SSL) has emerged as a promising approach in recent years. Initially, SSL has demonstrated significant performances in natural images [30], [33]\u2013[35], [39], [46]. In terms of supervision types, the current methods are primarily divided into two major categories: contrast-based and reconstruction-based approaches. The core idea of Contrast-based methods such as DINO [3] is to minimize the feature distances between different views of the same image while maximizing the distances between features of different images, thereby forcing the model to learn discriminative representations for different instances. However, contrast-based methods primarily focus on learning global representations but lack in capturing local features under single series. This limitation results in suboptimal performance on dense prediction tasks such as segmentation and lack of multi-series representation learning. Reconstruction-based methods are primarily centered around mask image modeling [53]. By masking a significant portion of the image content for reconstruction, the model is capable of learning both comprehensive global and fine-grained local representations. However, existing approaches such as MAE3D [2] and the work of Zhou et al. [1] have only concentrated on single image series representation, but ignoring the potential of multi-series representation.\nDue to the scarcity of annotated data, SSL has also garnered significant attention in the field of medical image analysis [47], [47]-[49]. Initially, researchers in this field have also designed proxy tasks [50]-[52] that focus on the characteristics of medical images, such as Vox2vec [5] and Pcrlv2 [4]. The core strategy they use is to apply various perturbations to the original images and then perform precise restoration, which enables the model to learn fine-grained image features. Despite being tailored for medical imaging, existing methods are limited to single series, neglecting the crucial aspect of multi-series self-supervised representation learning. This oversight limits the potential for models to capture comprehensive features inherent in the diverse information present across multiple series.\nTo address this, we propose a SSL method to enhance multi-series representation learning by Cross-Series Masking (CSM) including intra-series and inter-series masking strategies. Specifically, for intra-series masking, each series is independently masked of a portion of regions. By utilizing the mask-image-modeling strategy with multiple series that have been randomly masked, the target is to reconstruct the masked content within each series. This process enables the model to learn the commonalities and complementarities between different series, as well as the contextual information within each individual series. Furthermore, for inter-series masking, some series are randomly and entirely masked, and these series are reconstructed based on the other series. This allows the model to learn the distinctive features of each series as well as the inter-series relationships. By combining these two masking strategies, the model can acquire powerful multi-series representations that can benefit downstream tasks. Compared with barely using a single series, employing multi-series images can enhance the models' diagnostic performance in our proposed method as well as in other methods. Additionally, our method outperforms other compared baselines, which is displayed in the bar chart in Figure 1(b).\nOur main contributions are as follows:\nWe propose a novel self-supervised learning method for multi-series MRI representation learning, which uses cross-series masking as a preset task to learn the representation that can fuse the information from different series.\nWe meticulously design a cross-series masking strategy that encompasses both intra-series and inter-series masking approaches. By employing mask image modeling to reconstruct the original images, the model can learn comprehensive multi-series representations.\nWe conduct extensive experiments on two public datasets and one in-house dataset. Our method can achieve state-of-the-art results on various downstream tasks, such as brain tissue segmentation, breast tumor malignant diagnosis, and prostate tumor malignant diagnosis. We also show that our method can effectively reduce the annotation cost."}, {"title": "II. RELATED WORK", "content": "The core idea of self-supervised learning (SSL) is to leverage the inherent characteristics of the data to obtain data representations, rather than relying on manually labeled data. In recent years, prevalent self-supervised learning (SSL) methods roughly reveal two dominant categories: contrast-based and reconstruction-based.\nContrast-based Contrast-based methods focus on learning data features from the contrastive information of data samples [3], [5], [30]-[37] by contrastive learning which is one of the common methods in SSL. For example, Dino [3] introduced the self-distillation strategy and avoided model collapse by the centering and sharpening operations. Pcrlv2 [4] proposed by Zhou et al. conducted multi-scale feature comparison to learn multi-scale representations. This demonstrated that contrastive learning could achieve significant results without explicit negative samples.\nWith the the success of Transformers in natural language processing, Transformers have also begun to explore application to visual tasks in SSL. Chen et al. [32] conducted empirical studies on self-supervised training of vision transformers, providing valuable insights into the behavior of these models in a self-supervised setting."}, {"title": "B. Multi-series representation learning", "content": "In clinical practice, multi-series MRI plays a crucial role in diagnosing various diseases. Common MRI series include T1-weighted imaging, T2w-weighted imaging, dynamic contrast-enhanced T1-weighted imaging, and diffusion-weighted imaging (DWI). Studies have underscored the significance of this approach in diagnosing a spectrum of conditions, with notable research advancements in areas such as prostate cancer, bladder cancer, breast cancer, and glioblastoma, as documented in the literature [21]\u2013[24], [28], [29]. Furthermore, the research in [26], [27] has illuminated the broader applicability of multi-series MRI, highlighting its potential to augment diagnostic accuracy across various medical disciplines. The integration of data from multiple MRI series has consistently demonstrated enhanced diagnostic efficacy, a finding corroborated by the prevalence of these diseases on a global scale [25]. These insights underscore the broader relevance of multi-series representation learning in advancing medical imaging diagnostics.\nFor example, Roussel et al. [21] have mentioned that contemporary multi-series MRI protocols provide anatomical insights and offer qualitative, semi-quantitative, and fully quantitative imaging biomarkers that correlate with histological subtypes, tumor grades, and clinical behavior. Winfield et al. [26] details the essential role of multi-series MRI in three high-incidence but diagnostically challenging diseases: prostate cancer, breast cancer, and glioblastoma. The sensitivity or specificity of single-series MRI for these diseases is relatively low (e.g., the specificity for breast cancer is at most around 71%), and clinical practice tends to favor multi-series MRI to enhance diagnostic performance.\nIn summary, multi-series MRI significantly improves diagnostic accuracy by integrating diverse imaging information, making it an indispensable tool in clinical diagnostics. Compared to single-series MRI, the importance of combining multiple series lies in its ability to provide more comprehensive and precise diagnostic information, thus playing a crucial role in the early detection and accurate diagnosis of diseases."}, {"title": "III. METHOD", "content": "Multi-series fusion plays an important role in MRI analysis. Each MRI series can provide unique and complementary information about the tissues. However, these series differ in many aspects, such as acquisition parameters, spatial resolutions, and contrast mechanisms. Traditional supervised learning methods rely heavily on labeled data. To address these issues, we propose a self-supervised learning strategy that employs cross-series masking to learn the representation from multi-series images. We can efficiently fine-tune the encoder with a task-specific head for each downstream task using even a small set of annotated data."}, {"title": "A. Problem Setup.", "content": "Our dataset contains {x^{i}, Y_{i}}_{i\u2208{1,...,n}}, in which X^{i} denotes the ith patient that has s series images x^{i}=(x^{i}_{1}, x^{i}_{2}, ..., x^{i}_{s}), Y_{i} denotes the ground truth in different downstream tasks (e.g., lesion regions from manual annotations in segmentation tasks, the binary disease label in malignant diagnosis tasks).\nFigure 2 outlines the overall pipeline of our method. As shown, our method contains two stages: Self-supervised Representation Learning (SSL) stage and Downstream Fine-tuning stage. During the SSL stage. In the SSL stage, only the image data is provided for general image representation learning without any annotation. During the Downstream Fine-tuning stage, we utilize the pre-trained encoder in SSL stage to fine-tune specific downstream tasks using manually annotated data. This process allows us to achieve great results even with a minimal amount of data."}, {"title": "B. Self-supervised Representation Learning.", "content": "In this stage, our goal is to learn the representation that captures the essential features across multiple series. Thus we design a cross-series masking strategy including intra-series masking and inter-series masking, shown in Figure 3. Each series is divided into N non-overlapping patches, with each patch representing a visual token.\nFor intra-series masking, we randomly mask a substantial proportion of the tokens within each series, which is depicted in Figure 3(a). The random masked patches are denoted as set P_{m}, and the remaining unmasked patches are denoted as set P_{u}. In this strategy, each series is subjected to independent random masking, meaning that the regions masked in each series are distinct from one another. The motivation behind this design is that, for a given invisible token, its reconstruction primarily relies on other regions within the current series, and the corresponding regions in other series. In this way, the model can first learn the context within the same series, and on the other hand, it can learn the interdependence and complementarities between different series. However, if all series are masked in the same regions, the model can only learn the intra-series and inter-series context. This limitation would prevent the model from grasping the inter-series relationships and complementarities which are essential for effective multi-series representation learning. Consequently, such a deficiency would impede the model's performance in capturing the comprehensive information present across different MRI series.\nRegarding inter-series masking, we randomly select a subset of the series and fully mask them, meaning that the mask ratio for these series is 100%, which is outlined in Figure 3(b). The number of masked series is k, which is a random variable ranging from [1, s \u2013 1]. The masked series are denoted as set S_{m}. By reconstructing these fully masked series, it is akin to forcing the model to address the issue of series absence, thereby learning the overall commonalities and complementarities between different series. The aforementioned intra-series masking primarily focuses on learning local commonalities and complementarities, whereas inter-series masking is holistic, posing a higher level of difficulty and compelling the model to learn stronger inter-series representations.\nBy combining these two masking strategies, the model can learn comprehensive features within and between series from both local and global perspectives.\nSpecifically, we employ an encoder \\(E_{lenc}\\), which processes the unmasked patches P_{u}, to produce a latent representation. A decoder \\(D_{dec}\\) then attempts to reconstruct the masked patches P_{m} and series S_{m} from this representation:\n\\[\\hat{x} = D_{dec}(E_{lenc}(P_{u}))\\]\nThe reconstruction loss \\(L_{reconstruction}\\) is defined to measure the differences between the reconstructed series and the original unmasked series in mean squared error:\n\\[L_{reconstruction} (\\Theta_{enc}, \\Theta_{dec}) := \\sum_{x \\in clus(P_{m}, S_{m})} ||x - (\\Theta_{enc}, \\Theta_{dec})||_{2}\\]\nBy minimizing this loss, the encoder-decoder pair learns to recover the complete set of series from partially observed data. Through this self-supervised learning stage, our CSM acquires the capability to infer missing information and generate a comprehensive representation of multi-series MRI data, which is crucial for downstream tasks."}, {"title": "C. Downstream Fine-tuning.", "content": "After the above stage, we obtain a pre-trained encoder \\(f_{enc}\\) that has learned a rich representation of the multi-series MRI images. The next step is to adapt these representations to specific downstream tasks, such as segmentation and classification, which we denote as T.\nGiven a small set of annotated data \\(D_{T} = {(x_{i}, Y_{i})}_{i=1}^{N}\\), we fine-tune the encoder along with a task-specific head \\(H_{T}\\) by solving the following problem:\n\\[\\min_{E,H_{T}} \\frac{1}{N} \\sum_{i=1}^{N} L_{T} (H_{T} (E (x_{i})), Y_{i})\\]\n\\(L_{T}\\) is the loss function relevant to the task T, such as cross-entropy for classification or Dice coefficient for segmentation. The task-specific head \\(H_{T}\\) can be a variable set of layers that map the features extracted by the encoder E (initialized by \\(E_{lenc}\\)) to the output space of the task T.\nThrough this adaptation process, the encoder fine-tuned on task-specific annotated data is expected to achieve superior performance on the target task, demonstrating the practical utility of the learned representations."}, {"title": "IV. EXPERIMENTS", "content": "To evaluate the effectiveness of our method CSM, we verify it on brain tissue segmentation, breast tumor benign/malignant classification, and prostate cancer diagnosis (benign/malignant classification). We consider both the public dataset Brain Tumour task in Medical Segmentation Decathlon (BT-MSD) Challenge [18], the in-house dataset Breast2023, and a public dataset Prostate158 as shown in Figure 4.\nBT-MSD. BT-MSD has 484 multi-series MRI brain scans (Flair, T1w, Tlce, and T2w) [1], [18], which provides comprehensive information about brain structures and tumoral information. The dataset includes manual segmentations by radiologists, identifying enhancing tumor regions (ET), necrotic tumor core regions (NCR), and peritumoral edematous/invaded tissues (ED). During the evaluation process, we use the Dice coefficients for three categories: tumor core (TC), whole tumor (WT), and enhancing tumor (ET), where tumor core = NCR, whole tumor = ET + NCR + ED, and enhancing tumor = ET.Breast2023. Breast2023 is an in-house dataset that includes multi-series MRI images from 515 lesions, which contains tlce, DWI, and T2w series. Each lesion's benignity or malignancy has been pathologically confirmed. Based on the delineation by radiologists, We extract the lesion areas from each MRI series. To leverage the edge information of the lesions, we slightly expand the lesion regions to include the surrounding areas of the lesions."}, {"title": "C. Ablation Study", "content": "Random patch-mask: in Self-supervised Representation Learning pretraining stage, whether randomly masking position of patches on different series. \u00d7 represents masking patches in the same position on different series; \u2713 represents masking patches in the random position on different series.\nSeries-mask: in Self-supervised Representation Learning pre-training stage, whether randomly masking MRI series. \u00d7 represents not masking any series, \u2713 represents randomly masking partial series meanwhile reconstructing the masked series and represents randomly masking partial series but does not reconstruct the masked series.\nComplete-series: in Downstream Finetuning stage, \u2713 represents all series in using multi-series data are complete. x represents that some series of some data in using multi-series data are missing (different subjects have different numbers of series). To ensure consistency in the test data, we artificially created such scenarios (\u00d7) where some series of the data are missing by randomly eliminating one or two series. In finetuning and inference, such missing series can be padded with zeros to ensure uniformity of input length.\nTo evaluate the impact of different masking strategies and whether different subjects have different numbers of series on the performance using multiple series, we conduct the ablation study in Table VII for BT-MSD, Table VIII for Breast2023 and Prostate158. The study is structured around three main variables: the mask ratio, the masking strategy, and whether series are completely applied to the series or patches. We observed a high mask ratio of 87.5% consistently yielded better performance compared to a lower mask ratio of 50%. This suggests that a greater degree of information occlusion during training can lead to more robust cross-series representation learning.\nThe application of randomly patch-masking across different series (indicated by \u221a) generally resulted in higher performance metrics than masking the same position of patches across series (indicated by \u00d7). This indicates that introducing variability in the masked regions across series can be beneficial for the model's ability to generalize. Furthermore, when comparing series-masking strategies, we find that randomly masking partial series while reconstructing the masked series (indicated by) outperformed strategies where no series were masked (indicated by \u00d7) and those where partial series were masked without reconstruction (indicated by \u0970). This highlights the importance of reconstructing the masked series as it seems to encourage the model to learn more comprehensive and detailed representations. The results of this ablation study provide valuable insights into the optimization of masking strategy for improving multi-series analysis.\nIn clinical practice, subjects typically may present with varying numbers of image series, a variability we have emulated in our study (indicated by \u00d7). The comparative analysis in Table VII and Table VIII demonstrates that our method maintains efficacy with only a minor performance decrement between Row 5 and Row 1. Consequently, our approach holds promise for clinical applications."}, {"title": "V. CONCLUSION", "content": "In this paper, we propose a novel method CSM for learning a robust representation from multiple series MRI data. CSM leverages cross-series masking to encourage the model to learn common and complementary information from different MRI series. We evaluate our method and achieve state-of-the-art performances on three downstream tasks: MSD brain tumor segmentation, breast MRI cancer and prostate cancer diagnosis. Moreover, CSM can achieve competitive results with different amounts of annotated data, demonstrating its potential for practical applications with limited annotations."}]}