{"title": "MIND: Towards Immersive Psychological Healing with Multi-agent Inner Dialogue", "authors": ["Yujia Chen", "Changsong Li", "Yiming Wang", "Qingqing Xiao", "Nan Zhang", "Zifan Kong", "Peng Wang", "Binyu Yan"], "abstract": "Mental health issues are worsening in today's competitive society, such as depression and anxiety. Traditional healings like counseling and chatbots fail to engage effectively, they often provide generic responses lacking emotional depth. Although large language models (LLMs) have the potential to create more human-like interactions, they still struggle to capture subtle emotions. This requires LLMs to be equipped with human-like adaptability and warmth.\nTo fill this gap, we propose the MIND (Multi-agent INner Dialogue), a novel paradigm that provides more immersive psychological healing environments. Considering the strong generative and role-playing ability of LLM agents, we predefine an interactive healing framework and assign LLM agents different roles within the framework to engage in interactive inner dialogues with users, thereby providing an immersive healing experience. We conduct extensive human experiments in various real-world healing dimensions, and find that MIND provides a more user-friendly experience than traditional paradigms. This demonstrates that MIND effectively leverages the significant potential of LLMs in psychological healing.", "sections": [{"title": "1 Introduction", "content": "Mental health issues are worsening in today's competitive society, with rising cases of disorders like depression (Moitra et al., 2023). This lead to a growing market for psychological healing. Traditional healing paradigms like Cognitive Behavioral Therapy (Beck, 1979) and Dialectical Behavior Therapy (Lynch et al., 2007) are widely used but rely on face-to-face interactions, making them time-consuming and costly (Duruz et al., 2003) that limits large-scale accessibility. Another healing paradigm is VR-based Empathy Training (Halim et al., 2023; Hidding et al., 2024; D\u00f6llinger et al., 2024), which is rooted in the mechanisms of virtual body ownership illusion. This method involves the creation of a virtual self-image within VR, where the individual provides verbal encouragement to this virtual self. Subsequently, the individual swaps perspectives to adopt the role of the one being comforted, receiving the previously offered words of comfort. This \u201cself-dialogue\" process enables patients to experience and understand empathy from a new vantage point, thereby promoting self-compassion and reducing self-criticism. However, current systems are limited by static scenarios and scripted interactions. The lack of counselor-guided mechanisms and dynamic responsiveness in these predefined frameworks hampers the effectiveness of emotional regulation and reduces the adaptability of the therapeutic process, potentially leading to emotional deterioration in self-administered interventions.\nRecently, large language models (LLMs) have quickly advanced (Minaee et al., 2024; Zhao et al., 2024), gaining strong abilities in generation (Li, 2025), reasoning (Huang and Chang, 2023), and role-playing (Wang et al., 2024b). They also show great promise in mental health support (Hu et al.,"}, {"title": "2 MIND: Multi-agent Inner Dialogue", "content": ""}, {"title": "2.1 Overall Framework", "content": "The overall framework of our MIND paradigm is shown in Figure 2, composed of four agents responsible for inner dialogue generation, in addition to an agent simulating patients with cognitive distortions. The subsequent section will commence with an overview of the workflow: the trigger, the devil,"}, {"title": "2.2 Trigger: Scenario Generation", "content": "The trigger generates artificial scenes within the interactive fiction game, drawing from the chosen theme and the player's concerns. It begins by creating an initial scene that reflects the player's psychological state and evolves the narrative based on previous interactions. The agent adapts the storyline according to the player's emotional context and worries, ensuring a coherent progression in the scene's development. Through this process, the trigger sets the stage for therapeutic reflection by crafting a dynamic and consistent narrative that mirrors the player's thoughts and psychological growth.\nLet the first-round trigger agent be \\( \\pi_{\\tau_0} \\) and non-first rounds trigger agent be \\( \\pi_{\\tau_i} \\), the process can be formulated as:\n\\[\n\\begin{aligned}\nS_0 &= \\pi_{\\tau_0}(W,T), \\\\\nS_i &= \\pi_{\\tau_i}(C_{i-1}, P_{i-1}; W, T) \\ (i > 0),\n\\end{aligned}\n\\]\nwhere W is the player's concerns and T is the theme, \\( C_{i-1} \\) is the player's last-round comforting words and \\( P_{i-1} \\) is the strategist's last-round storyline progression.\nWe adopt the chain-of-thought prompting technique (Wei et al., 2022) to enhance the quality of the trigger in scenario generation. Specifically, the trigger is instructed to generate a simulation scene based on the theme and the patient's concerns, while also explaining how to incorporate the scene history and the patient's thought processes to create a logical extension."}, {"title": "2.3 Devil: Cognitive Distortion Simulation", "content": "The devil simulates the cognitive distortions that a patient might experience within the context of the scenario. It functions as the player's \"virtual embodiment\" representing an \u201calternate self\u201d within the simulated environment.\nBased on the simulated scenario provided by the trigger, the devil produces thoughts that align with common cognitive distortions, such as catastrophizing or emotional reasoning. These distortions are personalized to the player's specific context, offering an authentic simulation of how negative thinking can influence behavior and perceptions.\nLet the first-round devil agent be \\( \\pi_{d_0} \\) and non-first rounds devil agent be \\( \\pi_{d_i} \\), the process can be formulated as:\n\\[\n\\begin{aligned}\nD_0 &= \\pi_{d_0}(W, S_0), \\\\\nD_i &= \\pi_{d_i}(C_{i-1}, P_{i-1}, S_i) \\ (i > 0),\n\\end{aligned}\n\\]\nTo refine the simulation of the player's psychological state, we incorporate descriptions and definitions of five personality traits into the prompt design, aiming to create a more precise and personalized cognitive model. In the initial iteration, the devil agent generates responses solely based on the player's initial input and the scenario created by the trigger. However, in each subsequent iteration, the devil reacts to the player's comforting words, gradually weakening its cognitive distortions over time. This dynamic adjustment optimizes the player's interactive experience by allowing the devil's responses to evolve in alignment with the player's engagement and cognitive restructuring efforts."}, {"title": "2.4 Guide: Cognitive Restructuring Guidance", "content": "The guide aims to assist the player in recognizing, challenging, and reframing negative thought patterns through cognitive restructuring. The process begins with the guide identifying cognitive distortions in the player's thinking, which may have been amplified by the devil. The guide then offers alternative perspectives to counter these irrational beliefs and provides practical suggestions, such as taking a deep breath or writing down worries to evaluate their validity. The guide's goal is not to enforce immediate change, but to support gradual shifts in thinking, ensuring that each new perspective is integrated at the player's own pace.\nDenote the guide agent as \\( \\pi_g \\). The process can be formulated as:\n\\[\n(G_i, M_i) = \\pi_g(S_i, D_i) \n\\]\nAs the game progresses, the growing history becomes burdensome for the LLM to process efficiently. To mitigate this issue, a summarization mechanism is employed to maintain coherent narrative memory (Zhou et al., 2023). By operating in this way, the guide ensures that the player is not only challenged but also supported in a structured, manageable way, encouraging long-term emotional resilience and rational thinking. Ultimately, the guide helps transform the player from a passive recipient of distorted thoughts, as influenced by the devil, into an active participant in their own cognitive change, laying the foundation for healthier thought patterns and emotional well-being."}, {"title": "2.5 Strategist: Storyline Progression", "content": "The strategist is responsible for planning the next stage of the narrative and determining the mental shifts of the antagonist based on previous events and the comfort provided by the player. The primary goal of the strategist is to ensure that the protagonist's cognitive distortions are gradually restructured through the unfolding of the story.\nDenote the strategist agent as \\( \\pi_s \\). The process can be formulated as:\n\\[\nP_i = \\pi_s(M_i, C_i)\n\\]\nwhere \\( C_i \\) is the player's this round comforting words.\nIn each iteration, the strategist carefully evaluates whether the devil's mindset has evolved. If the comforting words successfully address the devil's cognitive distortions, a shift in their thought process occurs, leading to a more balanced and realistic perspective on their circumstances. This change catalyzes the natural progression of the story, with the devil's actions and decisions reflecting a healthier mindset. Conversely, if no change takes place, the narrative remains consistent with the devil's previous emotional state, allowing the player's guidance to continue influencing their emotional transformation. The objective is to ensure that every story development is not only logically coherent but also aligns with the devil's cognitive journey toward self-awareness and emotional resilience."}, {"title": "2.6 Human Simulated Patient: Empathy and Interaction", "content": "To facilitate the automated operation and evaluation of our framework, and drawing upon the validated psychological characteristics and annotation capabilities of LLM, we employ LLMs to simulate human interactions by providing comforting words to the devil. Based on the guidance from the guide, the virtual scenario generated by the trigger, and the cognitive distortions produced by the devil, human simulated patient assumes the role of the Player, en-"}, {"title": "3 Experiments", "content": ""}, {"title": "3.1 Setup", "content": "Scenario Setting. The real-life scenarios, thinking patterns, and cognitive distortion types of the Human Simulated Patient simulated by the LLM are derived from the C2D2 dataset (Wang et al., 2023). This dataset is the first publicly available resource focused on cognitive distortion analysis, solving the problem of data scarcity in this field. The dataset covers eight major topics, including work issues, interpersonal issues, economic issues, random negative events, family issues, physical stress, and discrepancy between ideal and reality.\nBaseline Paradigms. To evaluate the effectiveness of our MIND paradigm, we compare it with traditional counseling methods(face-to-face dialogue and Q&A) and the traditional empathy training paradigm (Halim et al., 2023; Hidding et al., 2024; D\u00f6llinger et al., 2024).\nLLM Agents. We used several LLM agents including both open-source and closed-sourced models with varying parameter scales. For closed-source models, we chose Gemini-2.0-flash (gem, 2025), GPT-4o (OpenAI et al., 2024), GPT-3.5-Turbo (Ye et al., 2023). For open-source models, we chose Llama-3.1-8B-Instruct (Grattafiori et al., 2024), Qwen2.5-72B-Instruct (Qwen et al., 2025), Qwen2.5-7B-Instruct (Qwen et al., 2025) and Deepseek-R1 (DeepSeek-AI et al., 2025). To control variables, we set the temperature of each model to 0.7.\nIn Section 3.2, a preliminary role-playing experiment was conducted to evaluate the performance of various models in the SP role-playing task. Based on the results of this initial assessment, we selected the Gemini-2.0-flash model, which exhibited the best performance, for our main experiments. This model was chosen due to its superior ability to handle the complexities of the role-playing scenario, making it the most appropriate candidate for further investigation in the primary phase of our study.\nEvaluation Metrics. The generation quality of the devil agent is crucial for the implementation of this framework, as it mirrors the player's internal \"cognitive distortions\" and can better serve its purpose only if it closely aligns with the player's \u201cinner voice.\u201d Therefore, before conducting our main experiments, we have specifically designed an Simulated Patient(SP) role-playing evaluation system to verify that the model can correctly identify the player's type of cognitive distortion and accurately reflect the patient's thoughts, achieving a realistic effect. We recruited 5 mental health professionals. Each evaluator had 10 rounds of conversation with each model."}, {"title": "3.2 Prelinimary: SP Role-playing Evaluation", "content": "The Gemini-2.0-flash model emerged as the best performer among the tested LLMs. In comparison, GPT-40 performed well in some areas but lagged in Emotional Expression and Personalization. Models like GPT-3.5-Turbo, Llama-3.1-8B-Instruct, and Deepseek-R1 showed weaker results, particularly in emotional and personalized responses. Qwen2.5 models performed the poorest, especially in emotional expression and accuracy, with scores not surpassing 3.2 in any dimension."}, {"title": "3.3 Main Results", "content": "The mean scores of each paradigm are shown in Figure 4. MIND demonstrated significant strengths in all six core assessment dimensions. Quantitative analysis showed that our paradigm performed particularly well on the dimensions of interest and satisfaction, reaching a perfect score of 5, compared to all the baseline methods of traditional counseling, traditional empathy training, and chatbot. Notably, in terms of the engagement index, MIND achieved an absolute improvement of 17.1% over the suboptimal method of traditional counseling, which reflects the increased motivation of the caller users that MIND can improve, so that they cooperate and participate in psychotherapy. On the dimensions of immersion, coherence and emotional relief, MIND also outperforms/equals the remaining three paradigms, which fully demonstrates that MIND has the potential to advance psychological interventions by combining the scalability of LLMs with human-centered interaction design."}, {"title": "4 Analysis", "content": ""}, {"title": "4.1 Thematic Scenarios Ablation", "content": "This framework is applicable to a variety of thematic scenarios, including but not limited to work, family, and interpersonal issues. To analyze the differences in effectiveness across different themes within this framework, we independently generated five examples for each of the seven themes in the C2D2 dataset. Similarly, we invited evaluators with psychological therapy expertise to score these examples. As shown in Table 3, the performance of different themes varies under our framework. Most themes perform well in \u201cImmersion\" and \"Coherence,\" indicating that the system effectively engages users and maintains logical consistency. Emotional relief and satisfaction are high, especially in themes like \u201cWork issues\u201d and \u201cDiscrepancy between ideal and reality.\u201d However, \u201cRandom negative events\u201d and \u201cFamily issues\u201d score lower in certain dimensions, such as engagement and interest, and may require further optimization."}, {"title": "4.2 Agent Involvement Ablation", "content": "Our framework consists of four agents: trigger, devil, guide, and strategist. To evaluate the effectiveness of MIND's two core agents (i.e., the guide and strategist) as well as the memorization mechanism, we conducted several ablation experiments to assess their impact on user experience and demonstrate the importance of each component. Specifically, we randomly generated three examples for each ablation experiment. We recruited 7 clinical psychology researchers with professional expertise to evaluate six content evaluation metrics. The experimental results, presented in Figure 5, show that each agent significantly contributes to the overall framework. The removal of any agent or the memorization mechanism notably diminishes the quality of the generated content, underscoring the collective importance of all agents in the framework."}, {"title": "4.3 Case Study", "content": "To demonstrate MIND's effectiveness in real-world applications, we present a case study in Appendix D, featuring a four-round dialogue on the theme of \"work issues,\" with the concern: \u201cDespite studying hard, my grades remain poor, and effort seems useless in a talent-driven society.\u201d The case study shows how the devil agent gains confidence through the player's comforting words, while the player also develops greater self-compassion and reconciles with their own concerns."}, {"title": "5 Related Work", "content": ""}, {"title": "5.1 LLM Agent", "content": "An agent refers to an entity capable of perceiving its environment and taking action to achieve its goals. AI agents are increasingly seen as a promising direction toward achieving Artificial General Intelligence (AGI) (Durante et al., 2024). Agents leverage the capabilities of Large Language Models (LLMs) to perform various tasks. In the construction of LLM agents, two of the most crucial aspects are (1) the architecture and (2) the method of acquiring capabilities. The architecture of LLM agents consists of four parts: Profile (primarily involving character background, written as prompts), Memory (including environmental and contextual information), Planning (allowing the agent to rationally execute according to a plan), and Action (transforming the agent's decisions into reasonable outputs)(Wang et al., 2024a). The method of acquiring capabilities is mainly divided into whether fine-tuning is performed. ReAct (Yao et al., 2022) proposed a framework that combines reasoning and action, utilizing prompt engineering for task decomposition. Later, AutoGPT (Yang et al., 2023) introduced memory mechanisms and tool invocation capabilities, supporting multi-step task execution. HuggingGPT (Shen et al., 2024) coordinated multimodal models through LLMs, validating the potential of LLMs as the control hub. In multi-agent systems, early research borrowed from traditional multi-agent system architecture designs, proposing two mainstream frameworks: hierarchical (e.g., MetaGPT (Hong et al., 2023)) and decentralized (e.g., AutoGen (Wu et al., 2023)). To enhance collaboration efficiency, researchers have explored various interaction paradigms, such as role-playing (CAMEL (Li et al., 2023) promotes task decomposition through predefined role divisions), debate negotiation (e.g., the debate decision-making framework MAD (Liang et al., 2024)), and knowledge sharing (AgentVerse (Chen et al., 2023a) uses dynamic memory banks to achieve experience transfer)."}, {"title": "5.2 LLM-assisted Psychology", "content": "The powerful capabilities of LLMs in natural language processing and simulating interpersonal interactions have provided opportunities to assist in mental health. LLMs can play a role in various areas such as medical diagnosis, expansion of mental health resources, and therapy (Hua et al., 2024). In diagnosis, LLMs are widely used for screening and diagnosing mental health issues, including depression, anxiety, and post-traumatic stress disorder (PTSD). In mental health resource development, LLMs address the scarcity of mental health data by generating synthetic data (e.g., simulated counseling dialogues) or expanding existing clinical questionnaires. In psychological therapy, the application of LLMs offers new possibilities for improving mental health services. By increasing accessibility, providing personalized treatment plans, and reducing treatment costs, LLMs have the potential to enhance mental health care. SMILE utilizes ChatGPT to convert single-turn long conversations into multi-turn dialogues for the development of specialized dialogue systems for mental health support (Qiu et al., 2023). SoulChat constructs the SoulChatCorpus dataset based on psychological consultation questions and answers, fine-tuning it to significantly enhance LLMs' abilities to provide empathy, listening, and comfort when offering emotional support (Chen et al., 2023b). MindChat is trained on one million high-quality multi-turn mental health conversation data to communicate in a more empathetic and guiding manner with users (Xin Yan, 2023)."}, {"title": "6 Conclusion", "content": "In this study, we propose MIND paradigm, a novel paradigm for psychological healing. Our framework consists of four LLM agents: trigger, devil, guide, and strategist. Through iterative interactions between these agents and the player, the system comforts the player's \u201cinner self\u201d within a virtual scenario, thereby enhancing empathy and emotional resonance, reducing self-criticism, and fostering a stronger sense of self-identity. Experimental results validate the significant potential of this paradigm, demonstrating an improved user experience compared to both traditional psychological counseling models and the prototype of our framework. Our work provides a new perspective on gamified psychological healing and opens an innovative path for utilizing LLM agents in therapeutic applications. We hope this research offers a fresh outlook on the intersection of LLMs and psychological healing, encouraging the public to pay greater attention to and improve their mental health."}, {"title": "Ethics Statement", "content": "The system used in this study is not intended to replace professional psychological treatment but rather to provide an effective option for clinical therapy. Before deployment, it is essential to ensure the presence of licensed professionals for supervision. Our evaluation method ensures the participation of mental health professionals aged 18 and above. The human evaluators' ages range from 25 to 45 years, and their professions include one psychiatrist, two rehabilitation therapists, two psychotherapists, and two nurses. Prior to the experiment, we provided the human evaluators with detailed experimental guidelines.\nWe have taken rigorous precautions to exclude individuals currently experiencing mental illness or those at risk of self-harm or suicidal tendencies. Our experiments are designed to avoid exposing participants to potentially harmful or misleading content. Participation in our evaluation experiment is entirely voluntary, and participants may withdraw at any time. We also ensured that a member of the research team was present throughout the process to guarantee its safety and effectiveness.\nIn our human study, we refrained from collecting any personally identifiable information, ensuring the anonymization of data before analysis. All research data were securely stored in a dedicated computing environment, accessible exclusively to trained research personnel."}, {"title": "Limitations", "content": "This framework has been evaluated exclusively in a Chinese-language context, which poses a limitation in terms of localizing psychological healing applications for different linguistic and cultural settings. While this study represents a significant step forward in shifting the paradigm of psychological healing, moving beyond the focus on training LLMs specifically for the psychological domain., it remains an initial attempt. To effectively implement this research into everyday psychological therapy, further extensive studies and clinical trials involving real mental health patients are necessary. Additionally, the framework's guide agent could benefit from being replaced with a more specialized therapeutic model, which could enhance the system's performance. Moreover, the framework used in this study is a simplified prototype. In the original theory, characters interact within a VR setting. There is significant potential for expanding this framework into more sophisticated formats, such as VR-based applications, to provide users with a more immersive and enriching therapeutic experience. Further exploration is required to address challenges related to the scalability of the system across various therapeutic scenarios and languages. Additionally, it remains unclear how the integration of this framework will scale in real-world settings with diverse patient populations, which presents another area for future research."}, {"title": "A Baseline Methods", "content": "This section provides a comprehensive overview of the baseline methods that we have employed. These methods serve as the foundational approaches in our study, and we introduce two distinct LLM-based baselines: (1) Chat-Bot; (2) Traditional Empathy Training.\nChat-Bot employs a simulated psychologist agent to engage in communication with patients suffering from cognitive distortions. During the conversation, it identifies the types of cognitive distortions and provides comfort and cognitive restructuring to the patients.\nTraditional Empathy Training employs role reversal in four phases to address cognitive distortions. In Phase 1, self-critical participants interact with a crying child avatar as an adult, demonstrating empathy. In Phase 2, some participants switch to the child avatar to receive comfort from their past selves, while others observe from a third-person perspective as a control. Phase 3 involves adapting to new perspectives: first-person participants embody the child avatar, while third-person participants observe without a virtual body. In Phase 4, participants re-experience empathy from the child's perspective, with real-time replays of the adult's gestures and voice. To better align with our current work, we simulated this process using LLMs. An agent, describing actions, demeanor, and emotions, played the role of the crying child. Participants provided verbal comfort and interacted with the agent, observing changes in the crying child. Once the interaction concluded (i.e., when the crying child stopped crying), the comforter assumed the child's perspective to review their comforting words and the child's responses, describing their psychological state. This approach, using agents, replicated the role reversal process typically conducted in Virtual Reality (VR), with specific prompts detailed in Appendix C."}, {"title": "B SP Role-playing Assessment", "content": "We provide mental health professionals with the following statement to help them better comprehend tasks and assess models' all-round abilities.\n(1) Dialogue Stability\nDoes the model consistently exhibit characteristics of cognitive distortion across all rounds of dialogue, rather than intermittently deviating from these traits? The simulated patient should maintain a stable mental state throughout the conversation, with consistency in the display of cognitive distortions. Furthermore, the content generated should reflect varying degrees of the same cognitive distortion type.\n(2) Language Fluency\nIs the language coherent and fluent? Cognitive distortion patients may demonstrate features such as slowed speech, increased pauses, and disrupted speech patterns. The SP should replicate these linguistic tendencies, ensuring the language style aligns with the patient's condition and avoids inconsistencies.\n(3) Emotional Expression\nDoes the emotional content generated align with the emotional traits typical of cognitive distortion patients? The simulation should accurately reflect common emotional responses observed in these patients, such as persistent low mood, anhedonia, feelings of helplessness, and hopelessness.\n(4) Personalization & Diversity\nIn addition to core characteristics, does the model incorporate a wide range of individualized traits, such as how different personality traits, life experiences, and educational backgrounds influence the patient's expression and behavior? For example, introverted patients may exhibit more passive and reticent communication styles, while extroverted patients may display more outward and active engagement. The model should construct diverse cognitive profiles to ensure the simulated patient is both authentic and personalized by considering various influencing factors.\n(5) Accuracy\nIs the identification of cognitive distortion types precise? This should be particularly evident in distinguishing the predominant distortion types when multiple cognitive distortions are present in the same interaction."}]}